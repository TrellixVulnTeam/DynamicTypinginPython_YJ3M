commit 1dcdbaabb85cee1a872e8fab947bc77a6779c732
Author: Neal Wu <neal@nealwu.com>
Date:   Mon Mar 27 13:45:19 2017 -0700

    Fixed formatting for the comment

diff --git a/inception/inception/inception_distributed_train.py b/inception/inception/inception_distributed_train.py
index 80847cb9..979abfc9 100644
--- a/inception/inception/inception_distributed_train.py
+++ b/inception/inception/inception_distributed_train.py
@@ -221,9 +221,8 @@ def train(target, dataset, cluster_spec):
       with tf.control_dependencies([apply_gradients_op]):
         train_op = tf.identity(total_loss, name='train_op')
 
-      # Get chief queue_runners and init_tokens, which is used to
-      # synchronize replicas.
-      # More details can be found in sync_replicas_optimizer.
+      # Get chief queue_runners and init_tokens, which is used to synchronize
+      # replicas. More details can be found in sync_replicas_optimizer.
       chief_queue_runners = [opt.get_chief_queue_runner()]
       init_tokens_op = opt.get_init_tokens_op()
 
