commit 4364390adbf16b57c093a05217897831f48da7d3
Author: Ivan Bogatyy <bogatyy@google.com>
Date:   Mon Nov 13 16:06:54 2017 -0800

     Release DRAGNN bulk networks (#2785)
    
    * Release DRAGNN bulk networks

diff --git a/research/syntaxnet/Dockerfile b/research/syntaxnet/Dockerfile
index 47e8b9d5..d651c344 100644
--- a/research/syntaxnet/Dockerfile
+++ b/research/syntaxnet/Dockerfile
@@ -1,5 +1,4 @@
-# Java baseimage, for Bazel.
-FROM openjdk:8
+FROM ubuntu:16.10
 
 ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
 
@@ -21,13 +20,15 @@ RUN mkdir -p $SYNTAXNETDIR \
           libopenblas-dev \
           libpng-dev \
           libxft-dev \
-          patch \
+          openjdk-8-jdk \
           python-dev \
           python-mock \
           python-pip \
           python2.7 \
           swig \
+          unzip \
           vim \
+          wget \
           zlib1g-dev \
     && apt-get clean \
     && (rm -f /var/cache/apt/archives/*.deb \
@@ -55,7 +56,7 @@ RUN python -m pip install \
           --py --sys-prefix widgetsnbextension \
     && rm -rf /root/.cache/pip /tmp/pip*
 
-# Installs the latest version of Bazel.
+# Installs Bazel.
 RUN wget --quiet https://github.com/bazelbuild/bazel/releases/download/0.5.4/bazel-0.5.4-installer-linux-x86_64.sh \
     && chmod +x bazel-0.5.4-installer-linux-x86_64.sh \
     && ./bazel-0.5.4-installer-linux-x86_64.sh \
@@ -65,13 +66,11 @@ COPY WORKSPACE $SYNTAXNETDIR/syntaxnet/WORKSPACE
 COPY tools/bazel.rc $SYNTAXNETDIR/syntaxnet/tools/bazel.rc
 COPY tensorflow $SYNTAXNETDIR/syntaxnet/tensorflow
 
-# Workaround solving the PYTHON_BIN_PATH not found problem
-ENV PYTHON_BIN_PATH=/usr/bin/python
 # Compile common TensorFlow targets, which don't depend on DRAGNN / SyntaxNet
 # source. This makes it more convenient to re-compile DRAGNN / SyntaxNet for
 # development (though not as convenient as the docker-devel scripts).
 RUN cd $SYNTAXNETDIR/syntaxnet/tensorflow \
-    && ./configure CPU \
+    && tensorflow/tools/ci_build/builds/configured CPU \
     && cd $SYNTAXNETDIR/syntaxnet \
     && bazel build -c opt @org_tensorflow//tensorflow:tensorflow_py
 
@@ -92,4 +91,4 @@ EXPOSE 8888
 COPY examples $SYNTAXNETDIR/syntaxnet/examples
 # Todo: Move this earlier in the file (don't want to invalidate caches for now).
 
-CMD /bin/bash -c "bazel-bin/dragnn/tools/oss_notebook_launcher notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples --allow-root"
+CMD /bin/bash -c "bazel-bin/dragnn/tools/oss_notebook_launcher notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples"
diff --git a/research/syntaxnet/README.md b/research/syntaxnet/README.md
index 078c630a..f813895b 100644
--- a/research/syntaxnet/README.md
+++ b/research/syntaxnet/README.md
@@ -23,8 +23,8 @@ This repository is largely divided into two sub-packages:
     [documentation](g3doc/DRAGNN.md),
     [paper](https://arxiv.org/pdf/1703.04474.pdf)** implements Dynamic Recurrent
     Acyclic Graphical Neural Networks (DRAGNN), a framework for building
-    multi-task, fully dynamically constructed computation graphs. Practically, we
-    use DRAGNN to extend our prior work from [Andor et al.
+    multi-task, fully dynamically constructed computation graphs. Practically,
+    we use DRAGNN to extend our prior work from [Andor et al.
     (2016)](http://arxiv.org/abs/1603.06042) with end-to-end, deep recurrent
     models and to provide a much easier to use interface to SyntaxNet. *DRAGNN
     is designed first and foremost as a Python library, and therefore much
@@ -54,20 +54,47 @@ There are three ways to use SyntaxNet:
 
 ### Docker installation
 
+_This process takes ~10 minutes._
+
 The simplest way to get started with DRAGNN is by loading our Docker container.
 [Here](g3doc/CLOUD.md) is a tutorial for running the DRAGNN container on
 [GCP](https://cloud.google.com) (just as applicable to your own computer).
 
+### Ubuntu 16.10+ binary installation
+
+_This process takes ~5 minutes, but is only compatible with Linux using GNU libc
+3.4.22 and above (e.g. Ubuntu 16.10)._
+
+Binary wheel packages are provided for TensorFlow and SyntaxNet. If you do not
+need to write new binary TensorFlow ops, these should suffice.
+
+*   `apt-get install -y graphviz libgraphviz-dev libopenblas-base libpng16-16
+    libxft2 python-pip python-mock`
+*   `pip install pygraphviz
+    --install-option="--include-path=/usr/include/graphviz"
+    --install-option="--library-path=/usr/lib/graphviz/"`
+*   `pip install 'ipython<6.0' protobuf numpy scipy jupyter
+    syntaxnet-with-tensorflow`
+*   `python -m jupyter_core.command nbextension enable --py --sys-prefix
+    widgetsnbextension`
+
+You can test that binary modules can be successfully imported by running,
+
+*   `python -c 'import dragnn.python.load_dragnn_cc_impl,
+    syntaxnet.load_parser_ops'`
+
 ### Manual installation
 
+_This process takes 1-2 hours._
+
 Running and training SyntaxNet/DRAGNN models requires building this package from
 source. You'll need to install:
 
 *   python 2.7:
     *   Python 3 support is not available yet
-*   bazel:
+*   bazel 0.5.4:
     *   Follow the instructions [here](http://bazel.build/docs/install.html)
-    *   Alternately, Download bazel <.deb> from
+    *   Alternately, Download bazel 0.5.4 <.deb> from
         [https://github.com/bazelbuild/bazel/releases](https://github.com/bazelbuild/bazel/releases)
         for your system configuration.
     *   Install it using the command: sudo dpkg -i <.deb file>
@@ -103,9 +130,12 @@ following commands:
   bazel test --linkopt=-headerpad_max_install_names \
     dragnn/... syntaxnet/... util/utf8/...
 ```
+
 Bazel should complete reporting all tests passed.
 
-Now you can install the SyntaxNet and DRAGNN Python modules with the following commands:
+Now you can install the SyntaxNet and DRAGNN Python modules with the following
+commands:
+
 ```shell
   mkdir /tmp/syntaxnet_pkg
   bazel-bin/dragnn/tools/build_pip_package --output-dir=/tmp/syntaxnet_pkg
@@ -116,8 +146,6 @@ Now you can install the SyntaxNet and DRAGNN Python modules with the following c
 To build SyntaxNet with GPU support please refer to the instructions in
 [issues/248](https://github.com/tensorflow/models/issues/248).
 
-
-
 **Note:** If you are running Docker on OSX, make sure that you have enough
 memory allocated for your Docker VM.
 
diff --git a/research/syntaxnet/docker-devel/Dockerfile-test b/research/syntaxnet/docker-devel/Dockerfile-test
new file mode 100644
index 00000000..24b28b0f
--- /dev/null
+++ b/research/syntaxnet/docker-devel/Dockerfile-test
@@ -0,0 +1,11 @@
+FROM dragnn-oss-test-base:latest
+
+RUN rm -rf \
+  $SYNTAXNETDIR/syntaxnet/dragnn \
+  $SYNTAXNETDIR/syntaxnet/syntaxnet \
+  $SYNTAXNETDIR/syntaxnet/third_party \
+  $SYNTAXNETDIR/syntaxnet/util/utf8
+COPY dragnn $SYNTAXNETDIR/syntaxnet/dragnn
+COPY syntaxnet $SYNTAXNETDIR/syntaxnet/syntaxnet
+COPY third_party $SYNTAXNETDIR/syntaxnet/third_party
+COPY util/utf8 $SYNTAXNETDIR/syntaxnet/util/utf8
diff --git a/research/syntaxnet/docker-devel/Dockerfile-test-base b/research/syntaxnet/docker-devel/Dockerfile-test-base
new file mode 100644
index 00000000..96f6e084
--- /dev/null
+++ b/research/syntaxnet/docker-devel/Dockerfile-test-base
@@ -0,0 +1,91 @@
+FROM ubuntu:16.10
+
+ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
+
+# Install system packages. This doesn't include everything the TensorFlow
+# dockerfile specifies, so if anything goes awry, maybe install more packages
+# from there. Also, running apt-get clean before further commands will make the
+# Docker images smaller.
+RUN mkdir -p $SYNTAXNETDIR \
+    && cd $SYNTAXNETDIR \
+    && apt-get update \
+    && apt-get install -y \
+          file \
+          git \
+          graphviz \
+          libcurl3-dev \
+          libfreetype6-dev \
+          libgraphviz-dev \
+          liblapack-dev \
+          libopenblas-dev \
+          libpng-dev \
+          libxft-dev \
+          openjdk-8-jdk \
+          python-dev \
+          python-mock \
+          python-pip \
+          python2.7 \
+          swig \
+          unzip \
+          vim \
+          wget \
+          zlib1g-dev \
+    && apt-get clean \
+    && (rm -f /var/cache/apt/archives/*.deb \
+        /var/cache/apt/archives/partial/*.deb /var/cache/apt/*.bin || true)
+
+# Install common Python dependencies. Similar to above, remove caches
+# afterwards to help keep Docker images smaller.
+RUN pip install --ignore-installed pip \
+    && python -m pip install numpy \
+    && rm -rf /root/.cache/pip /tmp/pip*
+RUN python -m pip install \
+          asciitree \
+          ipykernel \
+          jupyter \
+          matplotlib \
+          pandas \
+          protobuf \
+          scipy \
+          sklearn \
+    && python -m ipykernel.kernelspec \
+    && python -m pip install pygraphviz \
+          --install-option="--include-path=/usr/include/graphviz" \
+          --install-option="--library-path=/usr/lib/graphviz/" \
+    && python -m jupyter_core.command nbextension enable \
+          --py --sys-prefix widgetsnbextension \
+    && rm -rf /root/.cache/pip /tmp/pip*
+
+# Installs Bazel.
+RUN wget --quiet https://github.com/bazelbuild/bazel/releases/download/0.5.3/bazel-0.5.3-installer-linux-x86_64.sh \
+    && chmod +x bazel-0.5.3-installer-linux-x86_64.sh \
+    && JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ ./bazel-0.5.3-installer-linux-x86_64.sh \
+    && rm ./bazel-0.5.3-installer-linux-x86_64.sh
+
+COPY WORKSPACE $SYNTAXNETDIR/syntaxnet/WORKSPACE
+COPY tools/bazel.rc $SYNTAXNETDIR/syntaxnet/tools/bazel.rc
+
+# Compile common TensorFlow targets, which don't depend on DRAGNN / SyntaxNet
+# source. This makes it more convenient to re-compile DRAGNN / SyntaxNet for
+# development (though not as convenient as the docker-devel scripts).
+RUN cd $SYNTAXNETDIR/syntaxnet \
+    && git clone --branch r1.3 --recurse-submodules https://github.com/tensorflow/tensorflow \
+    && cd tensorflow \
+    # This line removes a bad archive target which causes Tensorflow install
+    # to fail.
+    && sed -i '\@https://github.com/google/protobuf/archive/0b059a3d8a8f8aa40dde7bea55edca4ec5dfea66.tar.gz@d' tensorflow/workspace.bzl \
+    && tensorflow/tools/ci_build/builds/configured CPU \\
+    && cd $SYNTAXNETDIR/syntaxnet \
+    && bazel build -c opt @org_tensorflow//tensorflow:tensorflow_py
+
+# Just copy the code and run tests. The build and test flags differ enough that
+# doing a normal build of TensorFlow targets doesn't save much test time.
+WORKDIR $SYNTAXNETDIR/syntaxnet
+COPY dragnn $SYNTAXNETDIR/syntaxnet/dragnn
+COPY syntaxnet $SYNTAXNETDIR/syntaxnet/syntaxnet
+COPY third_party $SYNTAXNETDIR/syntaxnet/third_party
+COPY util/utf8 $SYNTAXNETDIR/syntaxnet/util/utf8
+
+# Doesn't matter if the tests pass or not, since we're going to re-copy over the
+# code.
+RUN bazel test -c opt ... || true
diff --git a/research/syntaxnet/docker-devel/Dockerfile.min b/research/syntaxnet/docker-devel/Dockerfile.min
index 876f69d9..1acfb691 100644
--- a/research/syntaxnet/docker-devel/Dockerfile.min
+++ b/research/syntaxnet/docker-devel/Dockerfile.min
@@ -1,11 +1,9 @@
 # You need to build wheels before building this image. Please consult
 # docker-devel/README.txt.
-
-# This is the base of the openjdk image.
 #
 # It might be more efficient to use a minimal distribution, like Alpine. But
 # the upside of this being popular is that people might already have it.
-FROM buildpack-deps:jessie-curl
+FROM ubuntu:16.10
 
 ENV SYNTAXNETDIR=/opt/tensorflow PATH=$PATH:/root/bin
 
@@ -19,7 +17,7 @@ RUN apt-get update \
           libgraphviz-dev \
           liblapack3 \
           libopenblas-base \
-          libpng12-0 \
+          libpng16-16 \
           libxft2 \
           python-dev \
           python-mock \
@@ -48,11 +46,13 @@ RUN python -m pip install \
     && python -m pip install pygraphviz \
           --install-option="--include-path=/usr/include/graphviz" \
           --install-option="--library-path=/usr/lib/graphviz/" \
+    && python -m jupyter_core.command nbextension enable \
+          --py --sys-prefix widgetsnbextension \
     && rm -rf /root/.cache/pip /tmp/pip*
 
-COPY syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl $SYNTAXNETDIR/
+COPY syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl $SYNTAXNETDIR/
 RUN python -m pip install \
-        $SYNTAXNETDIR/syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl \
+        $SYNTAXNETDIR/syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl \
     && rm -rf /root/.cache/pip /tmp/pip*
 
 # This makes the IP exposed actually "*"; we'll do host restrictions by passing
@@ -63,4 +63,4 @@ EXPOSE 8888
 # This does not need to be compiled, only copied.
 COPY examples $SYNTAXNETDIR/syntaxnet/examples
 # For some reason, this works if we run it in a bash shell :/ :/ :/
-CMD /bin/bash -c "python -m jupyter_core.command notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples"
+CMD /bin/bash -c "python -m jupyter_core.command notebook --debug --notebook-dir=/opt/tensorflow/syntaxnet/examples --allow-root"
diff --git a/research/syntaxnet/docker-devel/README.txt b/research/syntaxnet/docker-devel/README.txt
index e190d599..029242e7 100644
--- a/research/syntaxnet/docker-devel/README.txt
+++ b/research/syntaxnet/docker-devel/README.txt
@@ -43,11 +43,11 @@ Step 3: Building the development image
 
 First, ensure you have the file
 
-  syntaxnet_with_tensorflow-0.2-cp27-none-linux_x86_64.whl
+  syntaxnet_with_tensorflow-0.2-cp27-cp27mu-linux_x86_64.whl
 
 in your working directory, from step 2. Then run,
 
-  docker build -t dragnn-oss:latest-minimal -f docker-devel/Dockerfile.min
+  docker build -t dragnn-oss:latest-minimal -f docker-devel/Dockerfile.min .
 
 If the filename changes (e.g. you are on a different architecture), just update
 Dockerfile.min.
diff --git a/research/syntaxnet/dragnn/__init__.py b/research/syntaxnet/dragnn/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/research/syntaxnet/dragnn/components/stateless/BUILD b/research/syntaxnet/dragnn/components/stateless/BUILD
index dd8caf23..bdd86771 100644
--- a/research/syntaxnet/dragnn/components/stateless/BUILD
+++ b/research/syntaxnet/dragnn/components/stateless/BUILD
@@ -10,7 +10,6 @@ cc_library(
         "//dragnn/core:component_registry",
         "//dragnn/core/interfaces:component",
         "//dragnn/core/interfaces:transition_state",
-        "//dragnn/io:sentence_input_batch",
         "//dragnn/protos:data_proto",
         "//syntaxnet:base",
     ],
diff --git a/research/syntaxnet/dragnn/components/stateless/stateless_component.cc b/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
index 47a7b70b..4820ff80 100644
--- a/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
+++ b/research/syntaxnet/dragnn/components/stateless/stateless_component.cc
@@ -16,7 +16,6 @@
 #include "dragnn/core/component_registry.h"
 #include "dragnn/core/interfaces/component.h"
 #include "dragnn/core/interfaces/transition_state.h"
-#include "dragnn/io/sentence_input_batch.h"
 #include "dragnn/protos/data.pb.h"
 #include "syntaxnet/base.h"
 
@@ -25,7 +24,8 @@ namespace dragnn {
 namespace {
 
 // A component that does not create its own transition states; instead, it
-// simply forwards the states of the previous component.  Does not support all
+// simply forwards the states of the previous component.  Requires that some
+// previous component has converted the input batch.  Does not support all
 // methods.  Intended for "compute-only" bulk components that only use linked
 // features, which use only a small subset of DRAGNN functionality.
 class StatelessComponent : public Component {
@@ -38,8 +38,7 @@ class StatelessComponent : public Component {
   void InitializeData(
       const std::vector<std::vector<const TransitionState *>> &parent_states,
       int max_beam_size, InputBatchCache *input_data) override {
-    // Must use SentenceInputBatch to match SyntaxNetComponent.
-    batch_size_ = input_data->GetAs<SentenceInputBatch>()->data()->size();
+    batch_size_ = input_data->Size();
     beam_size_ = max_beam_size;
     parent_states_ = parent_states;
 
@@ -84,31 +83,34 @@ class StatelessComponent : public Component {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
     return nullptr;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {
-    LOG(FATAL) << "[" << name_ << "] Method not supported";
+  bool AdvanceFromPrediction(const float *transition_matrix, int num_items,
+                             int num_actions) override {
+    LOG(FATAL) << "[" << name_ << "] AdvanceFromPrediction not supported";
   }
   void AdvanceFromOracle() override {
-    LOG(FATAL) << "[" << name_ << "] Method not supported";
+    LOG(FATAL) << "[" << name_ << "] AdvanceFromOracle not supported";
   }
   std::vector<std::vector<int>> GetOracleLabels() const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return {};
   }
   int GetFixedFeatures(std::function<int32 *(int)> allocate_indices,
                        std::function<int64 *(int)> allocate_ids,
                        std::function<float *(int)> allocate_weights,
                        int channel_id) const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return 0;
   }
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {
+    LOG(FATAL) << "[" << name_ << "] Method not supported";
+  }
+
   std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override {
     LOG(FATAL) << "[" << name_ << "] Method not supported";
-    return {};
   }
   void AddTranslatedLinkFeaturesToTrace(
       const std::vector<LinkFeatures> &features, int channel_id) override {
diff --git a/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc b/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
index 4a7d4331..a0126466 100644
--- a/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
+++ b/research/syntaxnet/dragnn/components/stateless/stateless_component_test.cc
@@ -18,6 +18,7 @@
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_transition_state.h"
 #include "dragnn/io/sentence_input_batch.h"
+#include "dragnn/protos/data.pb.h"
 #include "syntaxnet/base.h"
 #include "syntaxnet/sentence.pb.h"
 #include "tensorflow/core/lib/core/errors.h"
@@ -119,6 +120,10 @@ class StatelessComponentTest : public ::testing::Test {
     CHECK(TextFormat::ParseFromString(kMasterSpec, &master_spec));
     data_.reset(new InputBatchCache(data));
 
+    // The stateless component does not use any particular input batch type, and
+    // relies on the preceding components to convert the input batch.
+    data_->GetAs<SentenceInputBatch>();
+
     // Create a parser component with the specified beam size.
     std::unique_ptr<Component> parser_component(
         Component::Create("StatelessComponent"));
@@ -167,5 +172,37 @@ TEST_F(StatelessComponentTest, ForwardsTransitionStates) {
   EXPECT_EQ(parent_states, forwarded_states);
 }
 
+TEST_F(StatelessComponentTest, UnimplementedMethodsDie) {
+  MockTransitionState mock_state_1, mock_state_2, mock_state_3;
+  const std::vector<std::vector<const TransitionState *>> parent_states;
+  std::vector<string> data;
+  for (const string &textproto : {kSentence0, kSentence1, kLongSentence}) {
+    Sentence sentence;
+    CHECK(TextFormat::ParseFromString(textproto, &sentence));
+    data.emplace_back();
+    CHECK(sentence.SerializeToString(&data.back()));
+  }
+
+  const int kBeamSize = 2;
+  auto test_parser = CreateParser(kBeamSize, parent_states, data);
+
+  EXPECT_TRUE(test_parser->IsReady());
+  EXPECT_DEATH(test_parser->AdvanceFromPrediction({}, 0, 0),
+               "AdvanceFromPrediction not supported");
+  EXPECT_DEATH(test_parser->AdvanceFromOracle(),
+               "AdvanceFromOracle not supported");
+  EXPECT_DEATH(test_parser->GetOracleLabels(), "Method not supported");
+  EXPECT_DEATH(test_parser->GetFixedFeatures(nullptr, nullptr, nullptr, 0),
+               "Method not supported");
+  BulkFeatureExtractor extractor(nullptr, nullptr, nullptr);
+  EXPECT_DEATH(test_parser->BulkEmbedFixedFeatures(0, 0, 0, {nullptr}, nullptr),
+               "Method not supported");
+  EXPECT_DEATH(test_parser->BulkGetFixedFeatures(extractor),
+               "Method not supported");
+  EXPECT_DEATH(test_parser->GetRawLinkFeatures(0), "Method not supported");
+  EXPECT_DEATH(test_parser->AddTranslatedLinkFeaturesToTrace({}, 0),
+               "Method not supported");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
index f5df9e6b..6ebef622 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.cc
@@ -28,6 +28,7 @@
 #include "syntaxnet/sparse.pb.h"
 #include "syntaxnet/task_spec.pb.h"
 #include "syntaxnet/utils.h"
+#include "tensorflow/core/lib/strings/str_util.h"
 #include "tensorflow/core/platform/logging.h"
 
 namespace syntaxnet {
@@ -105,7 +106,7 @@ void SyntaxNetComponent::InitializeComponent(const ComponentSpec &spec) {
     dims.push_back(StrCat(channel.embedding_dim()));
   }
 
-  context.SetParameter("neurosis_feature_syntax_version", "2");
+
   context.SetParameter("brain_parser_embedding_dims", utils::Join(dims, ";"));
   context.SetParameter("brain_parser_predicate_maps",
                        utils::Join(predicate_maps, ";"));
@@ -187,8 +188,9 @@ std::unique_ptr<Beam<SyntaxNetTransitionState>> SyntaxNetComponent::CreateBeam(
     return this->IsFinal(state);
   };
   auto oracle_function = [this](SyntaxNetTransitionState *state) {
-    VLOG(2) << "oracle_function action:" << this->GetOracleLabel(state);
-    return this->GetOracleLabel(state);
+    VLOG(2) << "oracle_function action:"
+            << tensorflow::str_util::Join(this->GetOracleVector(state), ", ");
+    return this->GetOracleVector(state);
   };
   auto beam_ptr = beam.get();
   auto advance_function = [this, beam_ptr](SyntaxNetTransitionState *state,
@@ -335,25 +337,32 @@ std::function<int(int, int, int)> SyntaxNetComponent::GetStepLookupFunction(
   }
 }
 
-void SyntaxNetComponent::AdvanceFromPrediction(const float transition_matrix[],
-                                               int transition_matrix_length) {
-  VLOG(2) << "Advancing from prediction.";
-  int matrix_index = 0;
-  int num_labels = transition_system_->NumActions(label_map_->Size());
+bool SyntaxNetComponent::AdvanceFromPrediction(const float *transition_matrix,
+                                               int num_items, int num_actions) {
+  VLOG(2) << "Advancing from prediction, component = " << spec_.name();
+  const int num_static_actions =
+      transition_system_->NumActions(label_map_->Size());
+  if (num_static_actions != ParserTransitionSystem::kDynamicNumActions) {
+    CHECK_EQ(num_static_actions, num_actions)
+        << "[" << spec_.name()
+        << "] static action set does not match transition matrix";
+  }
   for (int i = 0; i < batch_.size(); ++i) {
-    int max_beam_size = batch_.at(i)->max_size();
-    int matrix_size = num_labels * max_beam_size;
-    CHECK_LE(matrix_index + matrix_size, transition_matrix_length);
-    if (!batch_.at(i)->IsTerminal()) {
-      batch_.at(i)->AdvanceFromPrediction(&transition_matrix[matrix_index],
-                                          matrix_size, num_labels);
+    const int size = num_actions * batch_[i]->max_size();
+    if (!batch_[i]->IsTerminal()) {
+      bool success = batch_[i]->AdvanceFromPrediction(transition_matrix, size,
+                                                      num_actions);
+      if (!success) {
+        return false;
+      }
     }
-    matrix_index += num_labels * max_beam_size;
+    transition_matrix += size;
   }
+  return true;
 }
 
 void SyntaxNetComponent::AdvanceFromOracle() {
-  VLOG(2) << "Advancing from oracle.";
+  VLOG(2) << "Advancing from oracle, component = " << spec_.name();
   for (auto &beam : batch_) {
     beam->AdvanceFromOracle();
   }
@@ -404,8 +413,18 @@ int SyntaxNetComponent::GetFixedFeatures(
         features.emplace_back(f);
         if (do_tracing_) {
           FixedFeatures fixed_features;
-          for (const string &name : f.description()) {
-            fixed_features.add_value_name(name);
+          CHECK_EQ(f.description_size(), f.id_size());
+          CHECK(f.weight_size() == 0 || f.weight_size() == f.id_size());
+          const bool has_weights = f.weight_size() != 0;
+          for (int i = 0; i < f.description_size(); ++i) {
+            if (has_weights) {
+              fixed_features.add_value_name(StrCat("id: ", f.id(i),
+                                                   " name: ", f.description(i),
+                                                   " weight: ", f.weight(i)));
+            } else {
+              fixed_features.add_value_name(
+                  StrCat("id: ", f.id(i), " name: ", f.description(i)));
+            }
           }
           fixed_features.set_feature_name("");
           auto *trace = GetLastStepInTrace(state->mutable_trace());
@@ -522,8 +541,8 @@ int SyntaxNetComponent::BulkGetFixedFeatures(
   // This would be a good place to add threading.
   for (int channel_id = 0; channel_id < num_channels; ++channel_id) {
     int feature_count = feature_counts[channel_id];
-    LOG(INFO) << "Feature count is " << feature_count << " for channel "
-              << channel_id;
+    VLOG(2) << "Feature count is " << feature_count << " for channel "
+            << channel_id;
     int32 *indices_tensor =
         extractor.AllocateIndexMemory(channel_id, feature_count);
     int64 *ids_tensor = extractor.AllocateIdMemory(channel_id, feature_count);
@@ -603,7 +622,9 @@ std::vector<std::vector<int>> SyntaxNetComponent::GetOracleLabels() const {
     for (int beam_idx = 0; beam_idx < beam->size(); ++beam_idx) {
       // Get the raw link features from the linked feature extractor.
       auto state = beam->beam_state(beam_idx);
-      oracle_labels.back().push_back(GetOracleLabel(state));
+
+      // Arbitrarily choose the first vector element.
+      oracle_labels.back().push_back(GetOracleVector(state).front());
     }
   }
   return oracle_labels;
@@ -661,13 +682,17 @@ bool SyntaxNetComponent::IsFinal(SyntaxNetTransitionState *state) const {
   return transition_system_->IsFinalState(*(state->parser_state()));
 }
 
-int SyntaxNetComponent::GetOracleLabel(SyntaxNetTransitionState *state) const {
+std::vector<int> SyntaxNetComponent::GetOracleVector(
+    SyntaxNetTransitionState *state) const {
   if (IsFinal(state)) {
     // It is not permitted to request an oracle label from a sentence that is
     // in a final state.
-    return -1;
+    return {-1};
   } else {
-    return transition_system_->GetNextGoldAction(*(state->parser_state()));
+    // TODO(googleuser): This should use the 'ParserAction' typedef.
+    std::vector<int> golds;
+    transition_system_->GetAllNextGoldActions(*(state->parser_state()), &golds);
+    return golds;
   }
 }
 
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
index 303fcf77..02b0b3dc 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
 
 #include <vector>
 
@@ -81,9 +81,10 @@ class SyntaxNetComponent : public Component {
   std::function<int(int, int, int)> GetStepLookupFunction(
       const string &method) override;
 
-  // Advances this component from the given transition matrix.
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int transition_matrix_length) override;
+  // Advances this component from the given transition matrix.Returns false
+  // if the component could not be advanced.
+  bool AdvanceFromPrediction(const float *transition_matrix, int num_items,
+                             int num_actions) override;
 
   // Advances this component from the state oracles.
   void AdvanceFromOracle() override;
@@ -105,6 +106,13 @@ class SyntaxNetComponent : public Component {
   // component via the oracle until it is terminal.
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override;
 
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_matrix) override {
+    LOG(FATAL) << "Method not supported";
+  }
+
   // Extracts and returns the vector of LinkFeatures for the specified
   // channel. Note: these are NOT translated.
   std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override;
@@ -145,13 +153,13 @@ class SyntaxNetComponent : public Component {
   bool IsFinal(SyntaxNetTransitionState *state) const;
 
   // Oracle function for this component.
-  int GetOracleLabel(SyntaxNetTransitionState *state) const;
+  std::vector<int> GetOracleVector(SyntaxNetTransitionState *state) const;
 
   // State advance function for this component.
   void Advance(SyntaxNetTransitionState *state, int action,
                Beam<SyntaxNetTransitionState> *beam);
 
-  // Creates a new state for the given nlp_saft::SentenceExample.
+  // Creates a new state for the given example.
   std::unique_ptr<SyntaxNetTransitionState> CreateState(
       SyntaxNetSentence *example);
 
@@ -195,4 +203,4 @@ class SyntaxNetComponent : public Component {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
index 52441ad3..62571187 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_component_test.cc
@@ -15,6 +15,8 @@
 
 #include "dragnn/components/syntaxnet/syntaxnet_component.h"
 
+#include <limits>
+
 #include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_transition_state.h"
@@ -197,8 +199,8 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionAndTerminates) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -225,6 +227,29 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionAndTerminates) {
   // TODO(googleuser): What should the finalized data look like?
 }
 
+TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionFailsWithNanWeights) {
+  // Create an empty input batch and beam vector to initialize the parser.
+  Sentence sentence_0;
+  TextFormat::ParseFromString(kSentence0, &sentence_0);
+  string sentence_0_str;
+  sentence_0.SerializeToString(&sentence_0_str);
+
+  auto test_parser = CreateParser({}, {sentence_0_str});
+
+  // There are 93 possible transitions for any given state. Create a transition
+  // array with a score of 10.0 for each transition.
+  constexpr int kBeamSize = 2;
+  constexpr int kNumPossibleTransitions = 93;
+  float transition_matrix[kNumPossibleTransitions * kBeamSize];
+  for (int i = 0; i < kNumPossibleTransitions * kBeamSize; ++i) {
+    transition_matrix[i] = std::numeric_limits<double>::quiet_NaN();
+  }
+
+  EXPECT_FALSE(test_parser->IsTerminal());
+  EXPECT_FALSE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                  kNumPossibleTransitions));
+}
+
 TEST_F(SyntaxNetComponentTest, RetainsPassedTransitionStateData) {
   // Create and initialize the state->
   MockTransitionState mock_state_one;
@@ -269,8 +294,8 @@ TEST_F(SyntaxNetComponentTest, RetainsPassedTransitionStateData) {
   // Transition the expected number of times
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -326,8 +351,8 @@ TEST_F(SyntaxNetComponentTest, AdvancesFromPredictionForMultiSentenceBatches) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -382,8 +407,8 @@ TEST_F(SyntaxNetComponentTest,
   constexpr int kExpectedNumTransitions = kNumTokensInLongSentence * 2;
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -467,7 +492,7 @@ TEST_F(SyntaxNetComponentTest, ResetAllowsReductionInBatchSize) {
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(parser_component->IsTerminal());
     parser_component->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions);
   }
 
   // At this point, the test parser should be terminal.
@@ -553,7 +578,7 @@ TEST_F(SyntaxNetComponentTest, ResetAllowsIncreaseInBatchSize) {
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(parser_component->IsTerminal());
     parser_component->AdvanceFromPrediction(
-        transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+        transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions);
   }
 
   // At this point, the test parser should be terminal.
@@ -611,8 +636,8 @@ TEST_F(SyntaxNetComponentTest, ResetCausesBeamToReset) {
   // Transition the expected number of times.
   for (int i = 0; i < kExpectedNumTransitions; ++i) {
     EXPECT_FALSE(test_parser->IsTerminal());
-    test_parser->AdvanceFromPrediction(transition_matrix,
-                                       kNumPossibleTransitions * kBeamSize);
+    EXPECT_TRUE(test_parser->AdvanceFromPrediction(transition_matrix, kBeamSize,
+                                                   kNumPossibleTransitions));
   }
 
   // At this point, the test parser should be terminal.
@@ -823,10 +848,10 @@ TEST_F(SyntaxNetComponentTest, ExportsFixedFeatures) {
   }
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   vector<int32> indices;
@@ -907,10 +932,10 @@ TEST_F(SyntaxNetComponentTest, AdvancesAccordingToHighestWeightedInputOption) {
   transition_matrix[kBatchOffset + 5] = 2 * kTransitionValue;
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   vector<int32> indices;
@@ -1112,10 +1137,10 @@ TEST_F(SyntaxNetComponentTest, ExportsRawLinkFeatures) {
   }
 
   // Advance twice, so that the underlying parser fills the beam.
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
-  test_parser->AdvanceFromPrediction(
-      transition_matrix, kNumPossibleTransitions * kBeamSize * kBatchSize);
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
+  EXPECT_TRUE(test_parser->AdvanceFromPrediction(
+      transition_matrix, kBeamSize * kBatchSize, kNumPossibleTransitions));
 
   // Get and check the raw link features.
   constexpr int kNumLinkFeatures = 2;
@@ -1269,5 +1294,21 @@ TEST_F(SyntaxNetComponentTest, TracingOutputsFeatureNames) {
   EXPECT_EQ(link_features.at(1).feature_name(), "stack(1).focus");
 }
 
+TEST_F(SyntaxNetComponentTest, BulkEmbedFixedFeaturesIsNotSupported) {
+  // Create an empty input batch and beam vector to initialize the parser.
+  Sentence sentence_0;
+
+  // TODO(googleuser): Wrap this in a lint-friendly helper function.
+  TextFormat::ParseFromString(kSentence0, &sentence_0);
+  string sentence_0_str;
+  sentence_0.SerializeToString(&sentence_0_str);
+
+  constexpr int kBeamSize = 1;
+  auto test_parser = CreateParserWithBeamSize(kBeamSize, {}, {sentence_0_str});
+  EXPECT_TRUE(test_parser->IsReady());
+  EXPECT_DEATH(test_parser->BulkEmbedFixedFeatures(0, 0, 0, {nullptr}, nullptr),
+               "Method not supported");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
index 4d94cfb5..d58aac88 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
 
 #include <string>
 #include <vector>
@@ -29,12 +29,8 @@ namespace syntaxnet {
 namespace dragnn {
 
 // Provides feature extraction for linked features in the
-// WrapperParserComponent. This re-ues the EmbeddingFeatureExtractor
-// architecture to get another set of feature extractors. Note that we should
-// ignore predicate maps here, and we don't care about the vocabulary size
-// because all the feature values will be used for translation, but this means
-// we can configure the extractor from the GCL using the standard
-// neurosis-lib.wf syntax.
+// WrapperParserComponent. This re-uses the EmbeddingFeatureExtractor
+// architecture to get another set of feature extractors.
 //
 // Because it uses a different prefix, it can be executed in the same wf.stage
 // as the regular fixed extractor.
@@ -67,4 +63,4 @@ class SyntaxNetLinkFeatureExtractor : public ParserEmbeddingFeatureExtractor {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_LINK_FEATURE_EXTRACTOR_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
index 7d5f2188..b4baa95f 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_link_feature_extractor_test.cc
@@ -34,7 +34,7 @@ class ExportSpecTest : public ::testing::Test {
 TEST_F(ExportSpecTest, WritesChannelSpec) {
   TaskContext context;
 
-  context.SetParameter("neurosis_feature_syntax_version", "2");
+
   context.SetParameter("link_features", "input.focus;stack.focus");
   context.SetParameter("link_embedding_names", "tagger;parser");
   context.SetParameter("link_predicate_maps", "none;none");
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
index a15e883b..b41c9ec3 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.cc
@@ -23,7 +23,9 @@ namespace dragnn {
 
 SyntaxNetTransitionState::SyntaxNetTransitionState(
     std::unique_ptr<ParserState> parser_state, SyntaxNetSentence *sentence)
-    : parser_state_(std::move(parser_state)), sentence_(sentence) {
+    : parser_state_(std::move(parser_state)),
+      sentence_(sentence),
+      is_gold_(false) {
   score_ = 0;
   current_beam_index_ = -1;
   parent_beam_index_ = 0;
@@ -60,21 +62,25 @@ std::unique_ptr<SyntaxNetTransitionState> SyntaxNetTransitionState::Clone()
   return new_state;
 }
 
-const int SyntaxNetTransitionState::ParentBeamIndex() const {
+int SyntaxNetTransitionState::ParentBeamIndex() const {
   return parent_beam_index_;
 }
 
-const int SyntaxNetTransitionState::GetBeamIndex() const {
+int SyntaxNetTransitionState::GetBeamIndex() const {
   return current_beam_index_;
 }
 
-void SyntaxNetTransitionState::SetBeamIndex(const int index) {
+bool SyntaxNetTransitionState::IsGold() const { return is_gold_; }
+
+void SyntaxNetTransitionState::SetGold(bool is_gold) { is_gold_ = is_gold; }
+
+void SyntaxNetTransitionState::SetBeamIndex(int index) {
   current_beam_index_ = index;
 }
 
-const float SyntaxNetTransitionState::GetScore() const { return score_; }
+float SyntaxNetTransitionState::GetScore() const { return score_; }
 
-void SyntaxNetTransitionState::SetScore(const float score) { score_ = score; }
+void SyntaxNetTransitionState::SetScore(float score) { score_ = score; }
 
 string SyntaxNetTransitionState::HTMLRepresentation() const {
   // Crude HTML string showing the stack and the word on the input.
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
index 193b33f5..3b37d762 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#ifndef DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#define DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
 
 #include <vector>
 
@@ -31,11 +31,11 @@ namespace dragnn {
 class SyntaxNetTransitionState
     : public CloneableTransitionState<SyntaxNetTransitionState> {
  public:
-  // Create a SyntaxNetTransitionState to wrap this nlp_saft::ParserState.
+  // Creates a SyntaxNetTransitionState to wrap this ParserState.
   SyntaxNetTransitionState(std::unique_ptr<ParserState> parser_state,
                            SyntaxNetSentence *sentence);
 
-  // Initialize this TransitionState from a previous TransitionState. The
+  // Initializes this TransitionState from a previous TransitionState. The
   // ParentBeamIndex is the location of that previous TransitionState in the
   // provided beam.
   void Init(const TransitionState &parent) override;
@@ -43,21 +43,27 @@ class SyntaxNetTransitionState
   // Produces a new state with the same backing data as this state.
   std::unique_ptr<SyntaxNetTransitionState> Clone() const override;
 
-  // Return the beam index of the state passed into the initializer of this
+  // Returns the beam index of the state passed into the initializer of this
   // TransitionState.
-  const int ParentBeamIndex() const override;
+  int ParentBeamIndex() const override;
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override;
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override;
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override;
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override;
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override;
+  // Gets the score associated with this transition state.
+  float GetScore() const override;
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override;
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override;
+
+  // Gets the state's gold-ness (if it is on or consistent with the oracle path)
+  bool IsGold() const override;
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override;
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override;
@@ -108,7 +114,7 @@ class SyntaxNetTransitionState
     parent_for_token_.insert(parent_for_token_.begin() + token, parent);
   }
 
-  // Accessor for the underlying nlp_saft::ParserState.
+  // Accessor for the underlying ParserState.
   ParserState *parser_state() { return parser_state_.get(); }
 
   // Accessor for the underlying sentence object.
@@ -151,9 +157,12 @@ class SyntaxNetTransitionState
 
   // Trace of the history to produce this state.
   std::unique_ptr<ComponentTrace> trace_;
+
+  // True if this state is gold.
+  bool is_gold_;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
+#endif  // DRAGNN_COMPONENTS_SYNTAXNET_SYNTAXNET_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
index ab4ab303..a30b09ce 100644
--- a/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
+++ b/research/syntaxnet/dragnn/components/syntaxnet/syntaxnet_transition_state_test.cc
@@ -134,6 +134,22 @@ TEST_F(SyntaxNetTransitionStateTest, CanSetAndGetScore) {
   EXPECT_EQ(test_state->GetScore(), kNewScore);
 }
 
+// Validates the consistency of the goldness setter and getter.
+TEST_F(SyntaxNetTransitionStateTest, CanSetAndGetGold) {
+  // Create and initialize a test state.
+  MockTransitionState mock_state;
+  auto test_state = CreateState();
+  test_state->Init(mock_state);
+
+  constexpr bool kOldGold = true;
+  test_state->SetGold(kOldGold);
+  EXPECT_EQ(test_state->IsGold(), kOldGold);
+
+  constexpr bool kNewGold = false;
+  test_state->SetGold(kNewGold);
+  EXPECT_EQ(test_state->IsGold(), kNewGold);
+}
+
 // This test ensures that the initializing state's current index is saved
 // as the parent beam index of the state being initialized.
 TEST_F(SyntaxNetTransitionStateTest, ReportsParentBeamIndex) {
diff --git a/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h b/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
index 9fbd08a2..6e07f688 100644
--- a/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
+++ b/research/syntaxnet/dragnn/components/util/bulk_feature_extractor.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#ifndef DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#define DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
 
 #include <functional>
 #include <utility>
@@ -107,4 +107,4 @@ class BulkFeatureExtractor {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
+#endif  // DRAGNN_COMPONENTS_UTIL_BULK_FEATURE_EXTRACTOR_H_
diff --git a/research/syntaxnet/dragnn/config_builder/__init__.py b/research/syntaxnet/dragnn/config_builder/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/research/syntaxnet/dragnn/core/BUILD b/research/syntaxnet/dragnn/core/BUILD
index 24978ab7..a52e91fb 100644
--- a/research/syntaxnet/dragnn/core/BUILD
+++ b/research/syntaxnet/dragnn/core/BUILD
@@ -33,8 +33,9 @@ cc_library(
     name = "compute_session",
     hdrs = ["compute_session.h"],
     deps = [
+        ":index_translator",
+        ":input_batch_cache",
         "//dragnn/components/util:bulk_feature_extractor",
-        "//dragnn/core:index_translator",
         "//dragnn/core/interfaces:component",
         "//dragnn/protos:spec_proto",
         "//dragnn/protos:trace_proto",
@@ -120,8 +121,10 @@ cc_test(
         ":compute_session",
         ":compute_session_impl",
         ":compute_session_pool",
+        ":input_batch_cache",
         "//dragnn/components/util:bulk_feature_extractor",
         "//dragnn/core/interfaces:component",
+        "//dragnn/core/interfaces:input_batch",
         "//dragnn/core/test:generic",
         "//dragnn/core/test:mock_component",
         "//dragnn/core/test:mock_transition_state",
@@ -248,6 +251,7 @@ cc_library(
         "//syntaxnet:base",
         "@org_tensorflow//third_party/eigen3",
     ],
+    alwayslink = 1,
 )
 
 # Tensorflow kernel libraries, for use with unit tests.
diff --git a/research/syntaxnet/dragnn/core/beam.h b/research/syntaxnet/dragnn/core/beam.h
index 534cfcd0..1529aef9 100644
--- a/research/syntaxnet/dragnn/core/beam.h
+++ b/research/syntaxnet/dragnn/core/beam.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
+#ifndef DRAGNN_CORE_BEAM_H_
+#define DRAGNN_CORE_BEAM_H_
 
 #include <algorithm>
 #include <cmath>
@@ -43,19 +43,23 @@ class Beam {
     static_assert(
         std::is_base_of<CloneableTransitionState<T>, T>::value,
         "This class must be instantiated to use a CloneableTransitionState");
+    track_gold_ = false;
   }
 
+  // Sets whether or not the beam should track gold states.
+  void SetGoldTracking(bool track_gold) { track_gold_ = track_gold; }
+
   // Sets the Beam functions, as follows:
   // bool is_allowed(TransitionState *, int): Return true if transition 'int' is
   //   allowed for transition state 'TransitionState *'.
   // void perform_transition(TransitionState *, int): Performs transition 'int'
   //   on transition state 'TransitionState *'.
-  // int oracle_function(TransitionState *): Returns the oracle-specified action
-  //   for transition state 'TransitionState *'.
+  // vector<int> oracle_function(TransitionState *): Returns the oracle-
+  //   specified actions for transition state 'TransitionState *'.
   void SetFunctions(std::function<bool(T *, int)> is_allowed,
                     std::function<bool(T *)> is_final,
                     std::function<void(T *, int)> perform_transition,
-                    std::function<int(T *)> oracle_function) {
+                    std::function<vector<int>(T *)> oracle_function) {
     is_allowed_ = is_allowed;
     is_final_ = is_final;
     perform_transition_ = perform_transition;
@@ -74,12 +78,17 @@ class Beam {
     for (int i = 0; i < beam_.size(); ++i) {
       previous_beam_indices.at(i) = beam_[i]->ParentBeamIndex();
       beam_[i]->SetBeamIndex(i);
+
+      // TODO(googleuser): Add gold tracking to component-level state creation.
+      if (!track_gold_) {
+        beam_[i]->SetGold(false);
+      }
     }
     beam_index_history_.emplace_back(previous_beam_indices);
   }
 
   // Advances the Beam from the given transition matrix.
-  void AdvanceFromPrediction(const float transition_matrix[], int matrix_length,
+  bool AdvanceFromPrediction(const float *transition_matrix, int matrix_length,
                              int num_actions) {
     // Ensure that the transition matrix is the correct size. All underlying
     // states should have the same transition profile, so using the one at 0
@@ -89,91 +98,20 @@ class Beam {
            "state transitions!";
 
     if (max_size_ == 1) {
-      // In the case where beam size is 1, we can advance by simply finding the
-      // highest score and advancing the beam state in place.
-      VLOG(2) << "Beam size is 1. Using fast beam path.";
-      int best_action = -1;
-      float best_score = -INFINITY;
-      auto &state = beam_[0];
-      for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
-        if (is_allowed_(state.get(), action_idx) &&
-            transition_matrix[action_idx] > best_score) {
-          best_score = transition_matrix[action_idx];
-          best_action = action_idx;
-        }
+      bool success = FastAdvanceFromPrediction(transition_matrix, num_actions);
+      if (!success) {
+        return false;
       }
-      CHECK_GE(best_action, 0) << "Num actions: " << num_actions
-                               << " score[0]: " << transition_matrix[0];
-      perform_transition_(state.get(), best_action);
-      const float new_score = state->GetScore() + best_score;
-      state->SetScore(new_score);
-      state->SetBeamIndex(0);
     } else {
-      // Create the vector of all possible transitions, along with their scores.
-      std::vector<Transition> candidates;
-
-      // Iterate through all beams, examining all actions for each beam.
-      for (int beam_idx = 0; beam_idx < beam_.size(); ++beam_idx) {
-        const auto &state = beam_[beam_idx];
-        for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
-          // If the action is allowed, calculate the proposed new score and add
-          // the candidate action to the vector of all actions at this state.
-          if (is_allowed_(state.get(), action_idx)) {
-            Transition candidate;
-
-            // The matrix is laid out by beam index, with a linear set of
-            // actions for that index - so beam N's actions start at [nr. of
-            // actions]*[N].
-            const int matrix_idx = action_idx + beam_idx * num_actions;
-            CHECK_LT(matrix_idx, matrix_length)
-                << "Matrix index out of bounds!";
-            const double score_delta = transition_matrix[matrix_idx];
-            CHECK(!std::isnan(score_delta));
-            candidate.source_idx = beam_idx;
-            candidate.action = action_idx;
-            candidate.resulting_score = state->GetScore() + score_delta;
-            candidates.emplace_back(candidate);
-          }
-        }
-      }
-
-      // Sort the vector of all possible transitions and scores.
-      const auto comparator = [](const Transition &a, const Transition &b) {
-        return a.resulting_score > b.resulting_score;
-      };
-      std::stable_sort(candidates.begin(), candidates.end(), comparator);
-
-      // Apply the top transitions, up to a maximum of 'max_size_'.
-      std::vector<std::unique_ptr<T>> new_beam;
-      std::vector<int> previous_beam_indices(max_size_, -1);
-      const int beam_size =
-          std::min(max_size_, static_cast<int>(candidates.size()));
-      VLOG(2) << "Previous beam size = " << beam_.size();
-      VLOG(2) << "New beam size = " << beam_size;
-      VLOG(2) << "Maximum beam size = " << max_size_;
-      for (int i = 0; i < beam_size; ++i) {
-        // Get the source of the i'th transition.
-        const auto &transition = candidates[i];
-        VLOG(2) << "Taking transition with score: "
-                << transition.resulting_score
-                << " and action: " << transition.action;
-        VLOG(2) << "transition.source_idx = " << transition.source_idx;
-        const auto &source = beam_[transition.source_idx];
-
-        // Put the new transition on the new state beam.
-        auto new_state = source->Clone();
-        perform_transition_(new_state.get(), transition.action);
-        new_state->SetScore(transition.resulting_score);
-        new_state->SetBeamIndex(i);
-        previous_beam_indices.at(i) = transition.source_idx;
-        new_beam.emplace_back(std::move(new_state));
+      bool success = BeamAdvanceFromPrediction(transition_matrix, matrix_length,
+                                               num_actions);
+      if (!success) {
+        return false;
       }
-
-      beam_ = std::move(new_beam);
-      beam_index_history_.emplace_back(previous_beam_indices);
     }
 
     ++num_steps_;
+    return true;
   }
 
   // Advances the Beam from the state oracles.
@@ -182,7 +120,10 @@ class Beam {
     for (int i = 0; i < beam_.size(); ++i) {
       previous_beam_indices.at(i) = i;
       if (is_final_(beam_[i].get())) continue;
-      const auto oracle_label = oracle_function_(beam_[i].get());
+
+      // There will always be at least one oracular transition, and taking the
+      // first returned transition is never worse than any other option.
+      const int oracle_label = oracle_function_(beam_[i].get()).at(0);
       VLOG(2) << "AdvanceFromOracle beam_index:" << i
               << " oracle_label:" << oracle_label;
       perform_transition_(beam_[i].get(), oracle_label);
@@ -312,19 +253,180 @@ class Beam {
   // Returns the current size of the beam.
   const int size() const { return beam_.size(); }
 
+  // Returns true if at least one of the states in the beam is gold.
+  bool ContainsGold() {
+    if (!track_gold_) {
+      return false;
+    }
+    for (const auto &state : beam_) {
+      if (state->IsGold()) {
+        return true;
+      }
+    }
+    return false;
+  }
+
  private:
-  // Associates an action taken on an index into current_state_ with a score.
+  friend void BM_FastAdvance(int num_iters, int num_transitions);
+  friend void BM_BeamAdvance(int num_iters, int num_transitions,
+                             int max_beam_size);
+
+  // Associates an action taken with its source index.
   struct Transition {
     // The index of the source item.
     int source_idx;
 
     // The index of the action being taken.
     int action;
-
-    // The score of the full derivation.
-    double resulting_score;
   };
 
+  // In the case where beam size is 1, we can advance by simply finding the
+  // highest score and advancing the beam state in place.
+  bool FastAdvanceFromPrediction(const float *transition_matrix,
+                                 int num_actions) {
+    CHECK_EQ(1, max_size_)
+        << "Using fast advance on invalid beam. This should never happen.";
+    VLOG(2) << "Beam size is 1. Using fast beam path.";
+    constexpr int kNoActionChosen = -1;
+    int best_action = kNoActionChosen;
+    float best_score = -INFINITY;
+    auto &state = beam_[0];
+    for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
+      if (std::isnan(transition_matrix[action_idx])) {
+        LOG(ERROR) << "Found a NaN in the transition matrix! Unable to "
+                      "continue. Num actions: "
+                   << num_actions << " index: " << action_idx;
+        return false;
+      }
+      if (is_allowed_(state.get(), action_idx) &&
+          transition_matrix[action_idx] > best_score) {
+        best_score = transition_matrix[action_idx];
+        best_action = action_idx;
+      }
+    }
+    if (best_action == kNoActionChosen) {
+      LOG(ERROR) << "No action was chosen! Unable to continue. Num actions: "
+                 << num_actions << " score[0]: " << transition_matrix[0];
+      return false;
+    }
+    bool is_gold = false;
+    if (track_gold_ && state->IsGold()) {
+      for (const auto &gold_transition : oracle_function_(state.get())) {
+        VLOG(3) << "Examining gold transition " << gold_transition
+                << " for source index 1";
+        if (gold_transition == best_action) {
+          is_gold = true;
+          break;
+        }
+      }
+    }
+    perform_transition_(state.get(), best_action);
+    const float new_score = state->GetScore() + best_score;
+    state->SetScore(new_score);
+    state->SetBeamIndex(0);
+    state->SetGold(is_gold);
+    return true;
+  }
+
+  // In case the beam size is greater than 1, we need to advance using
+  // standard beam search.
+  bool BeamAdvanceFromPrediction(const float *transition_matrix,
+                                 int matrix_length, int num_actions) {
+    VLOG(2) << "Beam size is " << max_size_ << ". Using standard beam search.";
+
+    // Keep the multimap sorted high to low. The sort order for
+    // identical keys is stable.
+    std::multimap<float, Transition, std::greater<float>> candidates;
+    float threshold = -INFINITY;
+
+    // Iterate through all beams, examining all actions for each beam.
+    for (int beam_idx = 0; beam_idx < beam_.size(); ++beam_idx) {
+      const auto &state = beam_[beam_idx];
+      const float score = state->GetScore();
+      for (int action_idx = 0; action_idx < num_actions; ++action_idx) {
+        if (is_allowed_(state.get(), action_idx)) {
+          // The matrix is laid out by beam index, with a linear set of
+          // actions for that index - so beam N's actions start at [nr. of
+          // actions]*[N].
+          const int matrix_idx = action_idx + beam_idx * num_actions;
+          CHECK_LT(matrix_idx, matrix_length) << "Matrix index out of bounds!";
+          const float resulting_score = score + transition_matrix[matrix_idx];
+          if (std::isnan(resulting_score)) {
+            LOG(ERROR) << "Resulting score was a NaN! Unable to continue. Num "
+                          "actions: "
+                       << num_actions << " action index " << action_idx;
+            return false;
+          }
+          if (candidates.size() == max_size_) {
+            // If the new score is lower than the bottom of the beam, move on.
+            if (resulting_score < threshold) {
+              continue;
+            }
+
+            // Otherwise, remove the bottom of the beam, making space
+            // for the new candidate.
+            candidates.erase(std::prev(candidates.end()));
+          }
+
+          // Add the new candidate, and update the threshold score.
+          const Transition candidate{beam_idx, action_idx};
+          candidates.emplace(resulting_score, candidate);
+          threshold = candidates.rbegin()->first;
+        }
+      }
+    }
+
+    // Apply the top transitions, up to a maximum of 'max_size_'.
+    std::vector<std::unique_ptr<T>> new_beam;
+    std::vector<int> previous_beam_indices(max_size_, -1);
+    const int beam_size = candidates.size();
+    new_beam.reserve(max_size_);
+    VLOG(2) << "Previous beam size = " << beam_.size();
+    VLOG(2) << "New beam size = " << beam_size;
+    VLOG(2) << "Maximum beam size = " << max_size_;
+    auto candidate_iterator = candidates.cbegin();
+    for (int i = 0; i < beam_size; ++i) {
+      // Get the score and source of the i'th transition.
+      const float resulting_score = candidate_iterator->first;
+      const auto &transition = candidate_iterator->second;
+      ++candidate_iterator;
+      VLOG(2) << "Taking transition with score: " << resulting_score
+              << " and action: " << transition.action;
+      VLOG(2) << "transition.source_idx = " << transition.source_idx;
+      const auto &source = beam_[transition.source_idx];
+
+      // Determine if the transition being taken will result in a gold state.
+      bool is_gold = false;
+      if (track_gold_ && source->IsGold()) {
+        for (const auto &gold_transition : oracle_function_(source.get())) {
+          VLOG(3) << "Examining gold transition " << gold_transition
+                  << " for source index " << transition.source_idx;
+          if (gold_transition == transition.action) {
+            VLOG(2) << "State from index " << transition.source_idx
+                    << " is gold.";
+            is_gold = true;
+            break;
+          }
+        }
+      }
+      VLOG(2) << "Gold examination complete for source index "
+              << transition.source_idx;
+
+      // Put the new transition on the new state beam.
+      auto new_state = source->Clone();
+      perform_transition_(new_state.get(), transition.action);
+      new_state->SetScore(resulting_score);
+      new_state->SetBeamIndex(i);
+      new_state->SetGold(is_gold);
+      previous_beam_indices.at(i) = transition.source_idx;
+      new_beam.emplace_back(std::move(new_state));
+    }
+
+    beam_ = std::move(new_beam);
+    beam_index_history_.emplace_back(previous_beam_indices);
+    return true;
+  }
+
   // The maximum beam size.
   int max_size_;
 
@@ -341,7 +443,7 @@ class Beam {
   std::function<void(T *, int)> perform_transition_;
 
   // Function to provide the oracle action for a given state.
-  std::function<int(T *)> oracle_function_;
+  std::function<vector<int>(T *)> oracle_function_;
 
   // The history of the states in this beam. The vector indexes across steps.
   // For every step, there is a vector in the vector. This inner vector denotes
@@ -355,9 +457,12 @@ class Beam {
 
   // The number of steps taken so far.
   int num_steps_;
+
+  // Whether to track golden states.
+  bool track_gold_;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_BEAM_H_
+#endif  // DRAGNN_CORE_BEAM_H_
diff --git a/research/syntaxnet/dragnn/core/beam_test.cc b/research/syntaxnet/dragnn/core/beam_test.cc
index 7ff1f329..f4b8dc8d 100644
--- a/research/syntaxnet/dragnn/core/beam_test.cc
+++ b/research/syntaxnet/dragnn/core/beam_test.cc
@@ -15,11 +15,15 @@
 
 #include "dragnn/core/beam.h"
 
+#include <limits>
+#include <random>
+
 #include "dragnn/core/interfaces/cloneable_transition_state.h"
 #include "dragnn/core/interfaces/transition_state.h"
 #include "dragnn/core/test/mock_transition_state.h"
 #include <gmock/gmock.h>
 #include "tensorflow/core/platform/test.h"
+#include "tensorflow/core/platform/test_benchmark.h"
 
 namespace syntaxnet {
 namespace dragnn {
@@ -43,7 +47,7 @@ namespace {
 class TestTransitionState
     : public CloneableTransitionState<TestTransitionState> {
  public:
-  TestTransitionState() {}
+  TestTransitionState() : is_gold_(false) {}
 
   void Init(const TransitionState &parent) override {}
 
@@ -52,19 +56,25 @@ class TestTransitionState
     return ptr;
   }
 
-  const int ParentBeamIndex() const override { return parent_beam_index_; }
+  int ParentBeamIndex() const override { return parent_beam_index_; }
+
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override { return beam_index_; }
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override { return beam_index_; }
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override { beam_index_ = index; }
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override { beam_index_ = index; }
+  // Gets the score associated with this transition state.
+  float GetScore() const override { return score_; }
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override { return score_; }
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override { score_ = score; }
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override { score_ = score; }
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override { return is_gold_; }
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override { is_gold_ = is_gold; }
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override { return ""; }
@@ -76,6 +86,8 @@ class TestTransitionState
   float score_;
 
   int transition_action_;
+
+  bool is_gold_;
 };
 
 // This transition function annotates a TestTransitionState with the action that
@@ -85,12 +97,14 @@ auto transition_function = [](TestTransitionState *state, int action) {
   cast_state->transition_action_ = action;
 };
 
-// Create oracle and permission functions that do nothing.
-auto null_oracle = [](TestTransitionState *) { return 0; };
+// Creates oracle and permission functions that do nothing.
+auto null_oracle = [](TestTransitionState *) -> const vector<int> {
+  return {0};
+};
 auto null_permissions = [](TestTransitionState *, int) { return true; };
 auto null_finality = [](TestTransitionState *) { return false; };
 
-// Create a unique_ptr with a test transition state in it and set its initial
+// Creates a unique_ptr with a test transition state in it and set its initial
 // score.
 std::unique_ptr<TestTransitionState> CreateState(float score) {
   std::unique_ptr<TestTransitionState> state;
@@ -99,6 +113,16 @@ std::unique_ptr<TestTransitionState> CreateState(float score) {
   return state;
 }
 
+// Creates a unique_ptr with a test transition state in it and set its initial
+// score. Also, set gold-ness to TRUE.
+std::unique_ptr<TestTransitionState> CreateGoldState(float score) {
+  std::unique_ptr<TestTransitionState> state;
+  state.reset(new TestTransitionState());
+  state->SetScore(score);
+  state->SetGold(true);
+  return state;
+}
+
 // Convenience accessor for the action field in TestTransitionState.
 int GetTransition(const TransitionState *state) {
   return (dynamic_cast<const TestTransitionState *>(state))->transition_action_;
@@ -114,11 +138,51 @@ void SetParentBeamIndex(TransitionState *state, int index) {
 // *****************************************************************************
 // Tests begin here.
 // *****************************************************************************
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamReturnsFalseOnNan) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kNan = std::numeric_limits<double>::quiet_NaN();
+  constexpr float kTransitionMatrix[kMatrixSize] = {1.0, kNan, 2.0, 3.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamReturnsFalseOnNoneAllowed) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+  auto empty_permissions = [](TestTransitionState *, int) { return false; };
+  beam.SetFunctions(empty_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
 TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions;
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
   constexpr int kBestTransition = 2;
   constexpr float kOldScore = 3.0;
 
@@ -130,7 +194,7 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), kBeamSize);
@@ -139,7 +203,8 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   EXPECT_EQ(GetTransition(beam.beam().at(0)), kBestTransition);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[kBestTransition]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   EXPECT_EQ(beam.beam().at(0)->GetBeamIndex(), 0);
@@ -152,12 +217,166 @@ TEST(BeamTest, AdvancesFromPredictionWithSingleBeam) {
   EXPECT_EQ(history.at(1).at(0), 0);
 }
 
+TEST(BeamTest, NewlyCreatedStatesWithTrackingOffAreNotGold) {
+  // Create the beam.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 3.0;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+
+  // SetGoldTracking is false by default.
+  beam.SetGoldTracking(false);
+  beam.Init(std::move(states));
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamAndGoldTracking) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr int kBestTransition = 2;
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {1, 2};
+  EXPECT_CALL(mock_oracle_function, Call(_)).WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), kBeamSize);
+
+  // Make sure the state has performed the expected transition.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), kBestTransition);
+
+  // Make sure the state has had its score updated properly.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
+
+  // Make sure that the beam index field is consistent with the actual beam idx.
+  EXPECT_EQ(beam.beam()[0]->GetBeamIndex(), 0);
+
+  // Make sure that the beam_state accessor actually accesses the beam.
+  EXPECT_EQ(beam.beam()[0], beam.beam_state(0));
+
+  // Validate the beam history field.
+  auto history = beam.history();
+  EXPECT_EQ(history[1][0], 0);
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithSingleBeamAndGoldTrackingFalloff) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr int kBestTransition = 2;
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is NOT index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 1};
+  EXPECT_CALL(mock_oracle_function, Call(_)).WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), kBeamSize);
+
+  // Make sure the state has performed the expected transition.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), kBestTransition);
+
+  // Make sure the state has had its score updated properly.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScore + kTransitionMatrix[kBestTransition]);
+
+  // Make sure that the beam index field is consistent with the actual beam idx.
+  EXPECT_EQ(beam.beam()[0]->GetBeamIndex(), 0);
+
+  // Make sure that the beam_state accessor actually accesses the beam.
+  EXPECT_EQ(beam.beam()[0], beam.beam_state(0));
+
+  // Validate the beam history field.
+  auto history = beam.history();
+  EXPECT_EQ(history[1][0], 0);
+
+  // Validate that the beam has no gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+}
+
+TEST(BeamTest, NonGoldBeamDoesNotInvokeOracle) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions;
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kOldScore = 3.0;
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScore));
+  auto first_state = states[0].get();
+  constexpr int kBeamSize = 1;
+  Beam<TestTransitionState> beam(kBeamSize);
+
+  // Create an oracle that indicates the best transition is NOT index 2.
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 1};
+  EXPECT_CALL(mock_oracle_function, Call(first_state))
+      .WillOnce(Return(oracle_labels));
+
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate that the beam has no gold state in it.
+  EXPECT_FALSE(beam.ContainsGold());
+
+  // Advance again. Since the oracle function above expects to be called exactly
+  // once, another call should not match and cause a failure.
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+}
+
 TEST(BeamTest, AdvancingCreatesNewTransitions) {
   // Create a matrix of transitions.
   constexpr int kMaxBeamSize = 8;
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0};
@@ -171,7 +390,7 @@ TEST(BeamTest, AdvancingCreatesNewTransitions) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 4);
@@ -183,10 +402,10 @@ TEST(BeamTest, AdvancingCreatesNewTransitions) {
   EXPECT_EQ(GetTransition(beam.beam().at(3)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[2]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + matrix[0]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + matrix[1]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScore + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScore + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -212,7 +431,7 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
 
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0,  // State 0
       31.0, 21.0, 41.0, 11.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
@@ -229,7 +448,7 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -247,14 +466,22 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   EXPECT_EQ(GetTransition(beam.beam().at(7)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScores[1] + matrix[6]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScores[0] + matrix[2]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScores[1] + matrix[4]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScores[0] + matrix[0]);
-  EXPECT_EQ(beam.beam().at(4)->GetScore(), kOldScores[1] + matrix[5]);
-  EXPECT_EQ(beam.beam().at(5)->GetScore(), kOldScores[0] + matrix[1]);
-  EXPECT_EQ(beam.beam().at(6)->GetScore(), kOldScores[1] + matrix[7]);
-  EXPECT_EQ(beam.beam().at(7)->GetScore(), kOldScores[0] + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[6]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[4]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(4)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[5]);
+  EXPECT_EQ(beam.beam().at(5)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(6)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[7]);
+  EXPECT_EQ(beam.beam().at(7)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -273,19 +500,255 @@ TEST(BeamTest, MultipleElementBeamsAdvanceAllElements) {
   EXPECT_EQ(history.at(1).at(7), 0);
 }
 
+TEST(BeamTest, MultipleElementBeamsFailOnNan) {
+  // Create a matrix of transitions.
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kNumTransitions = 4;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kNan = std::numeric_limits<double>::quiet_NaN();
+
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,  // State 0
+      31.0, 21.0, kNan, 11.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
+      00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
+      00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0};
+
+  constexpr float kOldScores[] = {5.0, 7.0};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScores[0]));
+  states.push_back(CreateState(kOldScores[1]));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+
+  EXPECT_FALSE(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions));
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithMultipleStateBeamAndGoldTracking) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      34.0, 24.0, 44.0, 14.0,   // State 4
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateGoldState(kOldScores[0]));
+  states.push_back(CreateGoldState(kOldScores[1]));
+  states.push_back(CreateGoldState(kOldScores[2]));
+  states.push_back(CreateGoldState(kOldScores[3]));
+  states.push_back(CreateGoldState(kOldScores[4]));
+  states.push_back(CreateGoldState(kOldScores[5]));
+  states.push_back(CreateGoldState(kOldScores[6]));
+  states.push_back(CreateGoldState(kOldScores[7]));
+
+  // Arbitrarily choose state 4 as the golden state.
+  auto gold_state = states[4].get();
+
+  // Create an oracle that will only return one gold transition - on transition
+  // 2 for state 6 (arbitrarily).
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 2};
+  vector<int> null_labels = {};
+  EXPECT_CALL(mock_oracle_function, Call(testing::Ne(gold_state)))
+      .WillRepeatedly(Return(null_labels));
+  EXPECT_CALL(mock_oracle_function, Call(gold_state))
+      .WillOnce(Return(oracle_labels));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), 8);
+
+  // Make sure the state has performed the expected transition.
+  // In this case, every state will perform transition 2.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[1]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[2]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[3]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[4]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[5]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[6]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[7]), 2);
+
+  // Make sure the state has had its score updated properly. (Note that row
+  // 0 had the smallest transition score, so it ends up on the bottom of the
+  // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
+  // correct state row and we add 2 since that was the transition index.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[0]->IsGold());
+
+  EXPECT_EQ(beam.beam()[1]->GetScore(),
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[1]->IsGold());
+
+  EXPECT_EQ(beam.beam()[2]->GetScore(),
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[2]->IsGold());
+
+  // This should be the gold state.
+  EXPECT_EQ(beam.beam()[3]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
+  EXPECT_TRUE(beam.beam()[3]->IsGold());
+
+  EXPECT_EQ(beam.beam()[4]->GetScore(),
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[4]->IsGold());
+
+  EXPECT_EQ(beam.beam()[5]->GetScore(),
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[5]->IsGold());
+
+  EXPECT_EQ(beam.beam()[6]->GetScore(),
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[6]->IsGold());
+
+  EXPECT_EQ(beam.beam()[7]->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[7]->IsGold());
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
+TEST(BeamTest, AdvancesFromPredictionWithMultipleGoldStates) {
+  // Create a matrix of transitions.
+  constexpr int kNumTransitions = 4;
+  constexpr int kMaxBeamSize = 8;
+  constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      54.0, 24.0, 44.0, 14.0,   // State 4 (gold - next will have both states)
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.push_back(CreateState(kOldScores[0]));
+  states.push_back(CreateState(kOldScores[1]));
+  states.push_back(CreateState(kOldScores[2]));
+  states.push_back(CreateState(kOldScores[3]));
+  states.push_back(CreateGoldState(kOldScores[4]));
+  states.push_back(CreateState(kOldScores[5]));
+  states.push_back(CreateState(kOldScores[6]));
+  states.push_back(CreateState(kOldScores[7]));
+
+  // Arbitrarily choose state 4 as the golden state.
+  auto gold_state = states[4].get();
+
+  // Create an oracle that will only return one gold transition - on transition
+  // 2 for state 6 (arbitrarily).
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
+  vector<int> oracle_labels = {0, 2};
+  vector<int> null_labels = {};
+  EXPECT_CALL(mock_oracle_function, Call(gold_state))
+      .WillOnce(Return(oracle_labels))
+      .WillOnce(Return(oracle_labels));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    mock_oracle_function.AsStdFunction());
+  beam.SetGoldTracking(true);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
+
+  // Validate the new beam.
+  EXPECT_EQ(beam.beam().size(), 8);
+
+  // Make sure the state has performed the expected transition.
+  // In this case, every state will perform transition 2.
+  EXPECT_EQ(GetTransition(beam.beam()[0]), 0);
+  EXPECT_EQ(GetTransition(beam.beam()[1]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[2]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[3]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[4]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[5]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[6]), 2);
+  EXPECT_EQ(GetTransition(beam.beam()[7]), 2);
+
+  // Make sure the state has had its score updated properly. (Note that row
+  // 0 had the smallest transition score, so it ends up on the bottom of the
+  // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
+  // correct state row and we add 2 since that was the transition index.
+  // This should be a gold state.
+  EXPECT_EQ(beam.beam()[0]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 0]);
+  EXPECT_TRUE(beam.beam()[0]->IsGold());
+
+  EXPECT_EQ(beam.beam()[1]->GetScore(),
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[1]->IsGold());
+
+  EXPECT_EQ(beam.beam()[2]->GetScore(),
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[2]->IsGold());
+
+  EXPECT_EQ(beam.beam()[3]->GetScore(),
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[3]->IsGold());
+
+  // This should be a gold state.
+  EXPECT_EQ(beam.beam()[4]->GetScore(),
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
+  EXPECT_TRUE(beam.beam()[4]->IsGold());
+
+  EXPECT_EQ(beam.beam()[5]->GetScore(),
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[5]->IsGold());
+
+  EXPECT_EQ(beam.beam()[6]->GetScore(),
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[6]->IsGold());
+
+  EXPECT_EQ(beam.beam()[7]->GetScore(),
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
+  EXPECT_FALSE(beam.beam()[7]->IsGold());
+
+  // Validate that the beam still has a gold state in it.
+  EXPECT_TRUE(beam.ContainsGold());
+}
+
 TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMaxBeamSize = 8;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0,   // State 0
-                                         31.0, 21.0, 41.0, 11.0,   // State 1
-                                         32.0, 22.0, 42.0, 12.0,   // State 2
-                                         33.0, 23.0, 43.0, 13.0,   // State 3
-                                         34.0, 24.0, 44.0, 14.0,   // State 4
-                                         35.0, 25.0, 45.0, 15.0,   // State 5
-                                         36.0, 26.0, 46.0, 16.0,   // State 6
-                                         37.0, 27.0, 47.0, 17.0};  // State 7
+  constexpr float kTransitionMatrix[kMatrixSize] = {
+      30.0, 20.0, 40.0, 10.0,   // State 0
+      31.0, 21.0, 41.0, 11.0,   // State 1
+      32.0, 22.0, 42.0, 12.0,   // State 2
+      33.0, 23.0, 43.0, 13.0,   // State 3
+      34.0, 24.0, 44.0, 14.0,   // State 4
+      35.0, 25.0, 45.0, 15.0,   // State 5
+      36.0, 26.0, 46.0, 16.0,   // State 6
+      37.0, 27.0, 47.0, 17.0};  // State 7
   constexpr float kOldScores[] = {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8};
 
   // Create the beam and transition it.
@@ -302,7 +765,7 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -323,21 +786,21 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
   // beam, and so forth.) For the matrix index, N*kNumTransitions gets into the
   // correct state row and we add 2 since that was the transition index.
   EXPECT_EQ(beam.beam().at(0)->GetScore(),
-            kOldScores[7] + matrix[7 * kNumTransitions + 2]);
+            kOldScores[7] + kTransitionMatrix[7 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(1)->GetScore(),
-            kOldScores[6] + matrix[6 * kNumTransitions + 2]);
+            kOldScores[6] + kTransitionMatrix[6 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(2)->GetScore(),
-            kOldScores[5] + matrix[5 * kNumTransitions + 2]);
+            kOldScores[5] + kTransitionMatrix[5 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(3)->GetScore(),
-            kOldScores[4] + matrix[4 * kNumTransitions + 2]);
+            kOldScores[4] + kTransitionMatrix[4 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(4)->GetScore(),
-            kOldScores[3] + matrix[3 * kNumTransitions + 2]);
+            kOldScores[3] + kTransitionMatrix[3 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(5)->GetScore(),
-            kOldScores[2] + matrix[2 * kNumTransitions + 2]);
+            kOldScores[2] + kTransitionMatrix[2 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(6)->GetScore(),
-            kOldScores[1] + matrix[1 * kNumTransitions + 2]);
+            kOldScores[1] + kTransitionMatrix[1 * kNumTransitions + 2]);
   EXPECT_EQ(beam.beam().at(7)->GetScore(),
-            kOldScores[0] + matrix[0 * kNumTransitions + 2]);
+            kOldScores[0] + kTransitionMatrix[0 * kNumTransitions + 2]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -358,7 +821,9 @@ TEST(BeamTest, AdvancingDropsLowValuePredictions) {
 TEST(BeamTest, AdvancesFromOracleWithSingleBeam) {
   // Create an oracle function for this state.
   constexpr int kOracleLabel = 3;
-  auto oracle_function = [](TransitionState *) { return kOracleLabel; };
+  auto oracle_function = [](TransitionState *) -> const vector<int> {
+    return {kOracleLabel};
+  };
 
   // Create the beam and transition it.
   std::vector<std::unique_ptr<TestTransitionState>> states;
@@ -392,21 +857,24 @@ TEST(BeamTest, AdvancesFromOracleWithMultipleStates) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
-    // This is nonzero to test the oracle holding scores to 0.
+    // This is nonzero to test the oracle holding scores constant.
     states.push_back(CreateState(10.0));
   }
 
   std::vector<int> expected_actions;
 
   // Create an oracle function for this state. Use mocks for finer control.
-  testing::MockFunction<int(TestTransitionState *)> mock_oracle_function;
+  testing::MockFunction<const vector<int>(TestTransitionState *)>
+      mock_oracle_function;
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // We expect each state to be queried for its oracle label,
     // and then to be transitioned in place with its oracle label.
     int oracle_label = i % 3;  // 3 is arbitrary.
+    vector<int> oracle_labels = {oracle_label};
     EXPECT_CALL(mock_oracle_function, Call(states.at(i).get()))
-        .WillOnce(Return(oracle_label));
+        .WillOnce(Return(oracle_labels));
     expected_actions.push_back(oracle_label);
   }
 
@@ -435,6 +903,7 @@ TEST(BeamTest, ReportsNonFinality) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // This is nonzero to test the oracle holding scores to 0.
     states.push_back(CreateState(10.0));
@@ -467,6 +936,7 @@ TEST(BeamTest, ReportsFinality) {
 
   // Create a beam with 8 transition states.
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     // This is nonzero to test the oracle holding scores to 0.
     states.push_back(CreateState(10.0));
@@ -493,7 +963,7 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   constexpr int kMaxBeamSize = 4;
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       10.0, 1000.0, 40.0, 30.0, 00.0, 0000.0, 00.0, 00.0,
       00.0, 0000.0, 00.0, 00.0, 00.0, 0000.0, 00.0, 00.0};
   constexpr float kOldScore = 4.0;
@@ -518,7 +988,7 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   beam.SetFunctions(mock_permission_function.AsStdFunction(), null_finality,
                     transition_function, null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 3);
@@ -529,9 +999,9 @@ TEST(BeamTest, IgnoresForbiddenTransitionActions) {
   EXPECT_EQ(GetTransition(beam.beam().at(2)), 0);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + matrix[2]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + matrix[3]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + matrix[0]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScore + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScore + kTransitionMatrix[3]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScore + kTransitionMatrix[0]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
@@ -551,7 +1021,7 @@ TEST(BeamTest, BadlySizedMatrixDies) {
   // Create a matrix of transitions.
   constexpr int kNumTransitions = 4;
   constexpr int kMatrixSize = 4;  // We have a max beam size of 4; should be 16.
-  constexpr float matrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
+  constexpr float kTransitionMatrix[kMatrixSize] = {30.0, 20.0, 40.0, 10.0};
 
   // Create the beam and transition it.
   std::vector<std::unique_ptr<TestTransitionState>> states;
@@ -564,7 +1034,8 @@ TEST(BeamTest, BadlySizedMatrixDies) {
   beam.Init(std::move(states));
 
   // This matrix should have 8 elements, not 4, so this should die.
-  EXPECT_DEATH(beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions),
+  EXPECT_DEATH(beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize,
+                                          kNumTransitions),
                "Transition matrix size does not match max beam size \\* number "
                "of state transitions");
 }
@@ -573,6 +1044,7 @@ TEST(BeamTest, BadlySizedBeamInitializationDies) {
   // Create an initialization beam too large for the max beam size.
   constexpr int kMaxBeamSize = 4;
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize + 1);
   for (int i = 0; i < kMaxBeamSize + 1; ++i) {
     states.push_back(CreateState(0.0));
   }
@@ -590,6 +1062,7 @@ TEST(BeamTest, ValidBeamIndicesAfterBeamInitialization) {
   // Create a standard beam.
   constexpr int kMaxBeamSize = 4;
   std::vector<std::unique_ptr<TestTransitionState>> states;
+  states.reserve(kMaxBeamSize);
   for (int i = 0; i < kMaxBeamSize; ++i) {
     states.push_back(CreateState(0.0));
   }
@@ -611,7 +1084,7 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   constexpr int kNumTransitions = 4;
   constexpr int kMaxBeamSize = 8;
   constexpr int kMatrixSize = kNumTransitions * kMaxBeamSize;
-  constexpr float matrix[kMatrixSize] = {
+  constexpr float kTransitionMatrix[kMatrixSize] = {
       30.0, 20.0, 40.0, 10.0,  // State 0
       31.0, 21.0, 41.0, 11.0,  // State 1
       00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0, 00.0,
@@ -632,7 +1105,7 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   beam.SetFunctions(null_permissions, null_finality, transition_function,
                     null_oracle);
   beam.Init(std::move(states));
-  beam.AdvanceFromPrediction(matrix, kMatrixSize, kNumTransitions);
+  beam.AdvanceFromPrediction(kTransitionMatrix, kMatrixSize, kNumTransitions);
 
   // Validate the new beam.
   EXPECT_EQ(beam.beam().size(), 8);
@@ -650,14 +1123,22 @@ TEST(BeamTest, FindPreviousIndexTracesHistory) {
   EXPECT_EQ(GetTransition(beam.beam().at(7)), 3);
 
   // Make sure the state has had its score updated properly.
-  EXPECT_EQ(beam.beam().at(0)->GetScore(), kOldScores[1] + matrix[6]);
-  EXPECT_EQ(beam.beam().at(1)->GetScore(), kOldScores[0] + matrix[2]);
-  EXPECT_EQ(beam.beam().at(2)->GetScore(), kOldScores[1] + matrix[4]);
-  EXPECT_EQ(beam.beam().at(3)->GetScore(), kOldScores[0] + matrix[0]);
-  EXPECT_EQ(beam.beam().at(4)->GetScore(), kOldScores[1] + matrix[5]);
-  EXPECT_EQ(beam.beam().at(5)->GetScore(), kOldScores[0] + matrix[1]);
-  EXPECT_EQ(beam.beam().at(6)->GetScore(), kOldScores[1] + matrix[7]);
-  EXPECT_EQ(beam.beam().at(7)->GetScore(), kOldScores[0] + matrix[3]);
+  EXPECT_EQ(beam.beam().at(0)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[6]);
+  EXPECT_EQ(beam.beam().at(1)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[2]);
+  EXPECT_EQ(beam.beam().at(2)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[4]);
+  EXPECT_EQ(beam.beam().at(3)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[0]);
+  EXPECT_EQ(beam.beam().at(4)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[5]);
+  EXPECT_EQ(beam.beam().at(5)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[1]);
+  EXPECT_EQ(beam.beam().at(6)->GetScore(),
+            kOldScores[1] + kTransitionMatrix[7]);
+  EXPECT_EQ(beam.beam().at(7)->GetScore(),
+            kOldScores[0] + kTransitionMatrix[3]);
 
   // Make sure that the beam index field is consistent with the actual beam idx.
   for (int i = 0; i < beam.beam().size(); ++i) {
diff --git a/research/syntaxnet/dragnn/core/component_registry.h b/research/syntaxnet/dragnn/core/component_registry.h
index 72449762..09baeca3 100644
--- a/research/syntaxnet/dragnn/core/component_registry.h
+++ b/research/syntaxnet/dragnn/core/component_registry.h
@@ -13,12 +13,17 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#ifndef DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#define DRAGNN_CORE_COMPONENT_REGISTRY_H_
 
 #include "dragnn/core/interfaces/component.h"
 #include "syntaxnet/registry.h"
 
+namespace syntaxnet {
+// Class registry for DRAGNN components.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("DRAGNN Component", dragnn::Component);
+}  // namespace syntaxnet
+
 // Macro to add a component to the registry. This macro associates a class with
 // its class name as a string, so FooComponent would be associated with the
 // string "FooComponent".
@@ -26,4 +31,4 @@
   REGISTER_SYNTAXNET_CLASS_COMPONENT(syntaxnet::dragnn::Component, #component, \
                                      component)
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPONENT_REGISTRY_H_
+#endif  // DRAGNN_CORE_COMPONENT_REGISTRY_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session.h b/research/syntaxnet/dragnn/core/compute_session.h
index 74cbc677..5ccfa720 100644
--- a/research/syntaxnet/dragnn/core/compute_session.h
+++ b/research/syntaxnet/dragnn/core/compute_session.h
@@ -13,13 +13,14 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_H_
 
 #include <string>
 
 #include "dragnn/components/util/bulk_feature_extractor.h"
 #include "dragnn/core/index_translator.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/interfaces/component.h"
 #include "dragnn/protos/spec.pb.h"
 #include "dragnn/protos/trace.pb.h"
@@ -64,10 +65,11 @@ class ComputeSession {
   // Advance the given component using the component's oracle.
   virtual void AdvanceFromOracle(const string &component_name) = 0;
 
-  // Advance the given component using the given score matrix.
-  virtual void AdvanceFromPrediction(const string &component_name,
-                                     const float score_matrix[],
-                                     int score_matrix_length) = 0;
+  // Advance the given component using the given score matrix, which is
+  // |num_items| x |num_actions|.
+  virtual bool AdvanceFromPrediction(const string &component_name,
+                                     const float *score_matrix, int num_items,
+                                     int num_actions) = 0;
 
   // Get the input features for the given component and channel. This passes
   // through to the relevant Component's GetFixedFeatures() call.
@@ -84,6 +86,15 @@ class ComputeSession {
   virtual int BulkGetInputFeatures(const string &component_name,
                                    const BulkFeatureExtractor &extractor) = 0;
 
+  // Directly computes the embedding matrix for all channels, advancing the
+  // component via the oracle until it is terminal. This call takes a vector
+  // of float embedding matrices, one per channel, in channel order.
+  virtual void BulkEmbedFixedFeatures(
+      const string &component_name, int batch_size_padding,
+      int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) = 0;
+
   // Get the input features for the given component and channel. This function
   // can return empty LinkFeatures protos, which represent unused padding slots
   // in the output weight tensor.
@@ -111,6 +122,10 @@ class ComputeSession {
   // Provides the ComputeSession with a batch of data to compute.
   virtual void SetInputData(const std::vector<string> &data) = 0;
 
+  // Like SetInputData(), but accepts an InputBatchCache directly, potentially
+  // bypassing de-serialization.
+  virtual void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) = 0;
+
   // Resets all components owned by this ComputeSession.
   virtual void ResetSession() = 0;
 
@@ -127,9 +142,14 @@ class ComputeSession {
   // validate correct construction of translators in tests.
   virtual const std::vector<const IndexTranslator *> Translators(
       const string &component_name) const = 0;
+
+  // Get a given component. CHECK-fail if the component's IsReady method
+  // returns false.
+  virtual Component *GetReadiedComponent(
+      const string &component_name) const = 0;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl.cc b/research/syntaxnet/dragnn/core/compute_session_impl.cc
index e83db32d..097a01b6 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_impl.cc
@@ -161,11 +161,11 @@ void ComputeSessionImpl::AdvanceFromOracle(const string &component_name) {
   GetReadiedComponent(component_name)->AdvanceFromOracle();
 }
 
-void ComputeSessionImpl::AdvanceFromPrediction(const string &component_name,
-                                               const float score_matrix[],
-                                               int score_matrix_length) {
-  GetReadiedComponent(component_name)
-      ->AdvanceFromPrediction(score_matrix, score_matrix_length);
+bool ComputeSessionImpl::AdvanceFromPrediction(const string &component_name,
+                                               const float *score_matrix,
+                                               int num_items, int num_actions) {
+  return GetReadiedComponent(component_name)
+      ->AdvanceFromPrediction(score_matrix, num_items, num_actions);
 }
 
 int ComputeSessionImpl::GetInputFeatures(
@@ -182,6 +182,16 @@ int ComputeSessionImpl::BulkGetInputFeatures(
   return GetReadiedComponent(component_name)->BulkGetFixedFeatures(extractor);
 }
 
+void ComputeSessionImpl::BulkEmbedFixedFeatures(
+    const string &component_name, int batch_size_padding, int num_steps_padding,
+    int output_array_size, const vector<const float *> &per_channel_embeddings,
+    float *embedding_output) {
+  return GetReadiedComponent(component_name)
+      ->BulkEmbedFixedFeatures(batch_size_padding, num_steps_padding,
+                               output_array_size, per_channel_embeddings,
+                               embedding_output);
+}
+
 std::vector<LinkFeatures> ComputeSessionImpl::GetTranslatedLinkFeatures(
     const string &component_name, int channel_id) {
   auto *component = GetReadiedComponent(component_name);
@@ -288,6 +298,11 @@ void ComputeSessionImpl::SetInputData(const std::vector<string> &data) {
   input_data_.reset(new InputBatchCache(data));
 }
 
+void ComputeSessionImpl::SetInputBatchCache(
+    std::unique_ptr<InputBatchCache> batch) {
+  input_data_ = std::move(batch);
+}
+
 void ComputeSessionImpl::ResetSession() {
   // Reset all component states.
   for (auto &component_pair : components_) {
@@ -308,6 +323,7 @@ const std::vector<const IndexTranslator *> ComputeSessionImpl::Translators(
     const string &component_name) const {
   auto translators = GetTranslators(component_name);
   std::vector<const IndexTranslator *> const_translators;
+  const_translators.reserve(translators.size());
   for (const auto &translator : translators) {
     const_translators.push_back(translator);
   }
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl.h b/research/syntaxnet/dragnn/core/compute_session_impl.h
index 3e219d4e..59d1f9db 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl.h
+++ b/research/syntaxnet/dragnn/core/compute_session_impl.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
 
 #include <memory>
 
@@ -55,9 +55,9 @@ class ComputeSessionImpl : public ComputeSession {
 
   void AdvanceFromOracle(const string &component_name) override;
 
-  void AdvanceFromPrediction(const string &component_name,
-                             const float score_matrix[],
-                             int score_matrix_length) override;
+  bool AdvanceFromPrediction(const string &component_name,
+                             const float *score_matrix, int num_items,
+                             int num_actions) override;
 
   int GetInputFeatures(const string &component_name,
                        std::function<int32 *(int)> allocate_indices,
@@ -68,6 +68,12 @@ class ComputeSessionImpl : public ComputeSession {
   int BulkGetInputFeatures(const string &component_name,
                            const BulkFeatureExtractor &extractor) override;
 
+  void BulkEmbedFixedFeatures(
+      const string &component_name, int batch_size_padding,
+      int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override;
+
   std::vector<LinkFeatures> GetTranslatedLinkFeatures(
       const string &component_name, int channel_id) override;
 
@@ -84,6 +90,8 @@ class ComputeSessionImpl : public ComputeSession {
 
   void SetInputData(const std::vector<string> &data) override;
 
+  void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) override;
+
   void ResetSession() override;
 
   void SetTracing(bool tracing_on) override;
@@ -95,14 +103,14 @@ class ComputeSessionImpl : public ComputeSession {
   const std::vector<const IndexTranslator *> Translators(
       const string &component_name) const override;
 
+  // Get a given component. CHECK-fail if the component's IsReady method
+  // returns false.
+  Component *GetReadiedComponent(const string &component_name) const override;
+
  private:
   // Get a given component. Fails if the component is not found.
   Component *GetComponent(const string &component_name) const;
 
-  // Get a given component. CHECK-fail if the component's IsReady method
-  // returns false.
-  Component *GetReadiedComponent(const string &component_name) const;
-
   // Get the index translators for the given component.
   const std::vector<IndexTranslator *> &GetTranslators(
       const string &component_name) const;
@@ -154,4 +162,4 @@ class ComputeSessionImpl : public ComputeSession {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_IMPL_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_impl_test.cc b/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
index 74bef1f5..f615a5da 100644
--- a/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_impl_test.cc
@@ -22,7 +22,9 @@
 #include "dragnn/core/component_registry.h"
 #include "dragnn/core/compute_session.h"
 #include "dragnn/core/compute_session_pool.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/core/interfaces/component.h"
+#include "dragnn/core/interfaces/input_batch.h"
 #include "dragnn/core/test/generic.h"
 #include "dragnn/core/test/mock_component.h"
 #include "dragnn/core/test/mock_transition_state.h"
@@ -65,8 +67,10 @@ class TestComponentType1 : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return true; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -83,6 +87,10 @@ class TestComponentType1 : public Component {
                        int channel_id) const override {
     return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     return 0;
   }
@@ -133,8 +141,10 @@ class TestComponentType2 : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return true; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -151,6 +161,10 @@ class TestComponentType2 : public Component {
                        int channel_id) const override {
     return 0;
   }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
     return 0;
   }
@@ -201,8 +215,14 @@ class UnreadyComponent : public Component {
   int GetSourceBeamIndex(int current_index, int batch) const override {
     return 0;
   }
-  void AdvanceFromPrediction(const float transition_matrix[],
-                             int matrix_length) override {}
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int embedding_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) override {}
   void AdvanceFromOracle() override {}
   bool IsTerminal() const override { return false; }
   std::function<int(int, int, int)> GetStepLookupFunction(
@@ -254,6 +274,18 @@ class ComputeSessionImplTestPoolAccessor {
   }
 };
 
+// An InputBatch that uses the serialized data directly.
+class IdentityBatch : public InputBatch {
+ public:
+  // Implements InputBatch.
+  void SetData(const std::vector<string> &data) override { data_ = data; }
+  int GetSize() const override { return data_.size(); }
+  const std::vector<string> GetSerializedData() const override { return data_; }
+
+ private:
+  std::vector<string> data_;  // the batch data
+};
+
 // *****************************************************************************
 // Tests begin here.
 // *****************************************************************************
@@ -739,7 +771,7 @@ TEST(ComputeSessionImplTest, InitializesComponentWithSource) {
   EXPECT_CALL(*mock_components["component_one"], GetBeam())
       .WillOnce(Return(beam));
 
-  // Expect that the second component will recieve that beam.
+  // Expect that the second component will receive that beam.
   EXPECT_CALL(*mock_components["component_two"],
               InitializeData(beam, kMaxBeamSize, NotNull()));
 
@@ -899,7 +931,7 @@ TEST(ComputeSessionImplTest, SetTracingPropagatesToAllComponents) {
   EXPECT_CALL(*mock_components["component_one"], GetBeam())
       .WillOnce(Return(beam));
 
-  // Expect that the second component will recieve that beam, and then its
+  // Expect that the second component will receive that beam, and then its
   // tracing will be initialized.
   EXPECT_CALL(*mock_components["component_two"],
               InitializeData(beam, kMaxBeamSize, NotNull()));
@@ -1084,12 +1116,12 @@ TEST(ComputeSessionImplTest, InterfacePassesThrough) {
   session->AdvanceFromOracle("component_one");
 
   // AdvanceFromPrediction()
-  constexpr int kScoreMatrixLength = 3;
-  const float score_matrix[kScoreMatrixLength] = {1.0, 2.3, 4.5};
+  const int kNumActions = 1;
+  const float score_matrix[] = {1.0, 2.3, 4.5};
   EXPECT_CALL(*mock_components["component_one"],
-              AdvanceFromPrediction(score_matrix, kScoreMatrixLength));
-  session->AdvanceFromPrediction("component_one", score_matrix,
-                                 kScoreMatrixLength);
+              AdvanceFromPrediction(score_matrix, batch_size, kNumActions));
+  session->AdvanceFromPrediction("component_one", score_matrix, batch_size,
+                                 kNumActions);
 
   // GetFixedFeatures
   auto allocate_indices = [](int size) -> int32 * { return nullptr; };
@@ -1109,6 +1141,11 @@ TEST(ComputeSessionImplTest, InterfacePassesThrough) {
       .WillOnce(Return(0));
   EXPECT_EQ(0, session->BulkGetInputFeatures("component_one", extractor));
 
+  // BulkEmbedFixedFeatures
+  EXPECT_CALL(*mock_components["component_one"],
+              BulkEmbedFixedFeatures(1, 2, 3, _, _));
+  session->BulkEmbedFixedFeatures("component_one", 1, 2, 3, {nullptr}, nullptr);
+
   // EmitOracleLabels()
   std::vector<std::vector<int>> oracle_labels = {{0, 1}, {2, 3}};
   EXPECT_CALL(*mock_components["component_one"], GetOracleLabels())
@@ -1154,7 +1191,7 @@ TEST(ComputeSessionImplTest, InterfaceRequiresReady) {
   constexpr int kScoreMatrixLength = 3;
   const float score_matrix[kScoreMatrixLength] = {1.0, 2.3, 4.5};
   EXPECT_DEATH(session->AdvanceFromPrediction("component_one", score_matrix,
-                                              kScoreMatrixLength),
+                                              kScoreMatrixLength, 1),
                "without first initializing it");
   constexpr int kArbitraryChannelId = 3;
   EXPECT_DEATH(session->GetInputFeatures("component_one", nullptr, nullptr,
@@ -1163,10 +1200,32 @@ TEST(ComputeSessionImplTest, InterfaceRequiresReady) {
   BulkFeatureExtractor extractor(nullptr, nullptr, nullptr, false, 0, 0);
   EXPECT_DEATH(session->BulkGetInputFeatures("component_one", extractor),
                "without first initializing it");
+  EXPECT_DEATH(session->BulkEmbedFixedFeatures("component_one", 0, 0, 0,
+                                               {nullptr}, nullptr),
+               "without first initializing it");
   EXPECT_DEATH(
       session->GetTranslatedLinkFeatures("component_one", kArbitraryChannelId),
       "without first initializing it");
 }
 
+TEST(ComputeSessionImplTest, SetInputBatchCache) {
+  // Use empty protos since we won't interact with components.
+  MasterSpec spec;
+  GridPoint hyperparams;
+  ComputeSessionPool pool(spec, hyperparams);
+  auto session = pool.GetSession();
+
+  // Initialize a cached IdentityBatch.
+  const std::vector<string> data = {"foo", "bar", "baz"};
+  std::unique_ptr<InputBatchCache> input_batch_cache(new InputBatchCache(data));
+  input_batch_cache->GetAs<IdentityBatch>();
+
+  // Inject the cache into the session.
+  session->SetInputBatchCache(std::move(input_batch_cache));
+
+  // Check that the injected batch can be retrieved.
+  EXPECT_EQ(session->GetSerializedPredictions(), data);
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/compute_session_pool.h b/research/syntaxnet/dragnn/core/compute_session_pool.h
index fba1e71e..f049f5f2 100644
--- a/research/syntaxnet/dragnn/core/compute_session_pool.h
+++ b/research/syntaxnet/dragnn/core/compute_session_pool.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#ifndef DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#define DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
 
 #include <memory>
 
@@ -29,14 +29,14 @@ namespace dragnn {
 
 class ComputeSessionPool {
  public:
-  // Create a ComputeSessionPool that creates ComputeSessions for the given
+  // Creates a ComputeSessionPool that creates ComputeSessions for the given
   // MasterSpec and hyperparameters.
   ComputeSessionPool(const MasterSpec &master_spec,
                      const GridPoint &hyperparams);
 
   virtual ~ComputeSessionPool();
 
-  // Get a ComputeSession. This function will attempt to use an already-created
+  // Gets a ComputeSession. This function will attempt to use an already-created
   // ComputeSession, but if none are available a new one will be created.
   std::unique_ptr<ComputeSession> GetSession();
 
@@ -49,6 +49,12 @@ class ComputeSessionPool {
     return num_unique_sessions_ - sessions_.size();
   }
 
+  // Returns the number of unique sessions that have been created.
+  int num_unique_sessions() { return num_unique_sessions_; }
+
+  // Returns a reference to the underlying spec for this pool.
+  const MasterSpec &GetSpec() const { return master_spec_; }
+
  private:
   friend class ComputeSessionImplTestPoolAccessor;
   friend class ComputeSessionPoolTestPoolAccessor;
@@ -99,4 +105,4 @@ class ComputeSessionPool {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
+#endif  // DRAGNN_CORE_COMPUTE_SESSION_POOL_H_
diff --git a/research/syntaxnet/dragnn/core/compute_session_pool_test.cc b/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
index 82d0735d..1e868802 100644
--- a/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
+++ b/research/syntaxnet/dragnn/core/compute_session_pool_test.cc
@@ -207,6 +207,7 @@ TEST(ComputeSessionPoolTest, SupportsMultithreadedAccess) {
 
   std::vector<std::unique_ptr<tensorflow::Thread>> request_threads;
   constexpr int kNumThreadsToTest = 100;
+  request_threads.reserve(kNumThreadsToTest);
   for (int i = 0; i < kNumThreadsToTest; ++i) {
     request_threads.push_back(std::unique_ptr<tensorflow::Thread>(
         tensorflow::Env::Default()->StartThread(
diff --git a/research/syntaxnet/dragnn/core/index_translator.h b/research/syntaxnet/dragnn/core/index_translator.h
index 556e3588..2cb0ce06 100644
--- a/research/syntaxnet/dragnn/core/index_translator.h
+++ b/research/syntaxnet/dragnn/core/index_translator.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#ifndef DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#define DRAGNN_CORE_INDEX_TRANSLATOR_H_
 
 #include <memory>
 #include <vector>
@@ -80,4 +80,4 @@ class IndexTranslator {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INDEX_TRANSLATOR_H_
+#endif  // DRAGNN_CORE_INDEX_TRANSLATOR_H_
diff --git a/research/syntaxnet/dragnn/core/input_batch_cache.h b/research/syntaxnet/dragnn/core/input_batch_cache.h
index 1f3ef977..7d9d70a3 100644
--- a/research/syntaxnet/dragnn/core/input_batch_cache.h
+++ b/research/syntaxnet/dragnn/core/input_batch_cache.h
@@ -13,12 +13,15 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#ifndef DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#define DRAGNN_CORE_INPUT_BATCH_CACHE_H_
 
 #include <memory>
 #include <string>
+#include <type_traits>
 #include <typeindex>
+#include <typeinfo>
+#include <utility>
 
 #include "dragnn/core/interfaces/input_batch.h"
 #include "tensorflow/core/platform/logging.h"
@@ -42,6 +45,18 @@ class InputBatchCache {
   explicit InputBatchCache(const std::vector<string> &data)
       : stored_type_(std::type_index(typeid(void))), source_data_(data) {}
 
+  // Creates a InputBatchCache from the |batch|.  InputBatchSubclass must be a
+  // strict subclass of InputBatch, and |batch| must be non-null.  All calls to
+  // GetAs must match InputBatchSubclass.
+  template <class InputBatchSubclass>
+  explicit InputBatchCache(std::unique_ptr<InputBatchSubclass> batch)
+      : stored_type_(std::type_index(typeid(InputBatchSubclass))),
+        converted_data_(std::move(batch)) {
+    static_assert(IsStrictInputBatchSubclass<InputBatchSubclass>(),
+                  "InputBatchCache requires a strict subclass of InputBatch");
+    CHECK(converted_data_) << "Cannot initialize from a null InputBatch";
+  }
+
   // Adds a single string to the cache. Only useable before GetAs() has been
   // called.
   void AddData(const string &data) {
@@ -52,10 +67,14 @@ class InputBatchCache {
   }
 
   // Converts the stored strings into protos and return them in a specific
-  // InputBatch subclass. T should always be of type InputBatch. After this
-  // method is called once, all further calls must be of the same data type.
+  // InputBatch subclass. T should always be a strict subclass of InputBatch.
+  // After this method is called once, all further calls must be of the same
+  // data type.
   template <class T>
   T *GetAs() {
+    static_assert(
+        IsStrictInputBatchSubclass<T>(),
+        "GetAs<T>() requires that T is a strict subclass of InputBatch");
     if (!converted_data_) {
       stored_type_ = std::type_index(typeid(T));
       converted_data_.reset(new T());
@@ -69,14 +88,27 @@ class InputBatchCache {
     return dynamic_cast<T *>(converted_data_.get());
   }
 
+  // Returns the size of the batch.  Requires that GetAs() has been called.
+  int Size() const {
+    CHECK(converted_data_) << "Cannot return batch size without data.";
+    return converted_data_->GetSize();
+  }
+
   // Returns the serialized representation of the data held in the input batch
-  // object within this cache.
+  // object within this cache.  Requires that GetAs() has been called.
   const std::vector<string> SerializedData() const {
     CHECK(converted_data_) << "Cannot return batch without data.";
     return converted_data_->GetSerializedData();
   }
 
  private:
+  // Returns true if InputBatchSubclass is a strict subclass of InputBatch.
+  template <class InputBatchSubclass>
+  static constexpr bool IsStrictInputBatchSubclass() {
+    return std::is_base_of<InputBatch, InputBatchSubclass>::value &&
+           !std::is_same<InputBatch, InputBatchSubclass>::value;
+  }
+
   // The typeid of the stored data.
   std::type_index stored_type_;
 
@@ -90,4 +122,4 @@ class InputBatchCache {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INPUT_BATCH_CACHE_H_
+#endif  // DRAGNN_CORE_INPUT_BATCH_CACHE_H_
diff --git a/research/syntaxnet/dragnn/core/input_batch_cache_test.cc b/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
index 46366344..3043acfb 100644
--- a/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
+++ b/research/syntaxnet/dragnn/core/input_batch_cache_test.cc
@@ -32,6 +32,8 @@ class StringData : public InputBatch {
     }
   }
 
+  int GetSize() const override { return data_.size(); }
+
   const std::vector<string> GetSerializedData() const override { return data_; }
 
   std::vector<string> *data() { return &data_; }
@@ -50,6 +52,8 @@ class DifferentStringData : public InputBatch {
     }
   }
 
+  int GetSize() const override { return data_.size(); }
+
   const std::vector<string> GetSerializedData() const override { return data_; }
 
   std::vector<string> *data() { return &data_; }
@@ -58,6 +62,11 @@ class DifferentStringData : public InputBatch {
   std::vector<string> data_;
 };
 
+// Expects that two pointers have the same address.
+void ExpectSameAddress(const void *pointer1, const void *pointer2) {
+  EXPECT_EQ(pointer1, pointer2);
+}
+
 TEST(InputBatchCacheTest, ConvertsSingleInput) {
   string test_string = "Foo";
   InputBatchCache generic_set(test_string);
@@ -118,5 +127,48 @@ TEST(InputBatchCacheTest, ConvertsAddedInputDiesAfterGetAs) {
                "after the cache has been converted");
 }
 
+TEST(InputBatchCacheTest, SerializedDataAndSize) {
+  InputBatchCache generic_set;
+  generic_set.AddData("Foo");
+  generic_set.AddData("Bar");
+  generic_set.GetAs<StringData>();
+
+  const std::vector<string> expected_data = {"Foo_converted", "Bar_converted"};
+  EXPECT_EQ(expected_data, generic_set.SerializedData());
+  EXPECT_EQ(2, generic_set.Size());
+}
+
+TEST(InputBatchCacheTest, InitializeFromInputBatch) {
+  const std::vector<string> kInputData = {"foo", "bar", "baz"};
+  const std::vector<string> kExpectedData = {"foo_converted",  //
+                                             "bar_converted",  //
+                                             "baz_converted"};
+
+  std::unique_ptr<StringData> string_data(new StringData());
+  string_data->SetData(kInputData);
+  const StringData *string_data_ptr = string_data.get();
+
+  InputBatchCache generic_set(std::move(string_data));
+  auto data = generic_set.GetAs<StringData>();
+
+  ExpectSameAddress(string_data_ptr, data);
+  EXPECT_EQ(data->GetSize(), 3);
+  EXPECT_EQ(data->GetSerializedData(), kExpectedData);
+  EXPECT_EQ(*data->data(), kExpectedData);
+
+  // AddData() shouldn't work since the cache is already populated.
+  EXPECT_DEATH(generic_set.AddData("YOU MAY NOT DO THIS AND IT WILL DIE."),
+               "after the cache has been converted");
+
+  // GetAs() shouldn't work with a different type.
+  EXPECT_DEATH(generic_set.GetAs<DifferentStringData>(),
+               "Attempted to convert to two object types!");
+}
+
+TEST(InputBatchCacheTest, CannotInitializeFromNullInputBatch) {
+  EXPECT_DEATH(InputBatchCache(std::unique_ptr<StringData>()),
+               "Cannot initialize from a null InputBatch");
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h b/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
index aa1355b0..1ad3fb00 100644
--- a/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
+++ b/research/syntaxnet/dragnn/core/interfaces/cloneable_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#define DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
 
 #include <memory>
 #include <vector>
@@ -33,26 +33,32 @@ class CloneableTransitionState : public TransitionState {
  public:
   ~CloneableTransitionState<T>() override {}
 
-  // Initialize this TransitionState from a previous TransitionState. The
+  // Initializes this TransitionState from a previous TransitionState. The
   // ParentBeamIndex is the location of that previous TransitionState in the
   // provided beam.
   void Init(const TransitionState &parent) override = 0;
 
-  // Return the beam index of the state passed into the initializer of this
+  // Returns the beam index of the state passed into the initializer of this
   // TransitionState.
-  const int ParentBeamIndex() const override = 0;
+  int ParentBeamIndex() const override = 0;
 
-  // Get the current beam index for this state.
-  const int GetBeamIndex() const override = 0;
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override = 0;
 
-  // Set the current beam index for this state.
-  void SetBeamIndex(const int index) override = 0;
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override = 0;
 
-  // Get the score associated with this transition state.
-  const float GetScore() const override = 0;
+  // Gets the score associated with this transition state.
+  float GetScore() const override = 0;
 
-  // Set the score associated with this transition state.
-  void SetScore(const float score) override = 0;
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override = 0;
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override = 0;
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override = 0;
 
   // Depicts this state as an HTML-language string.
   string HTMLRepresentation() const override = 0;
@@ -64,4 +70,4 @@ class CloneableTransitionState : public TransitionState {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_INTERFACES_CLONEABLE_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/component.h b/research/syntaxnet/dragnn/core/interfaces/component.h
index b382ab0a..a1bea275 100644
--- a/research/syntaxnet/dragnn/core/interfaces/component.h
+++ b/research/syntaxnet/dragnn/core/interfaces/component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#ifndef DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#define DRAGNN_CORE_INTERFACES_COMPONENT_H_
 
 #include <vector>
 
@@ -83,11 +83,13 @@ class Component : public RegisterableClass<Component> {
   virtual std::function<int(int, int, int)> GetStepLookupFunction(
       const string &method) = 0;
 
-  // Advances this component from the given transition matrix.
-  virtual void AdvanceFromPrediction(const float transition_matrix[],
-                                     int transition_matrix_length) = 0;
+  // Advances this component from the given transition matrix, which is
+  // |num_items| x |num_actions|.
+  virtual bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                                     int num_actions) = 0;
 
-  // Advances this component from the state oracles.
+  // Advances this component from the state oracles. There is no return from
+  // this, since it should always succeed.
   virtual void AdvanceFromOracle() = 0;
 
   // Returns true if all states within this component are terminal.
@@ -110,6 +112,14 @@ class Component : public RegisterableClass<Component> {
   // BulkFeatureExtractor object to contain the functors and other information.
   virtual int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) = 0;
 
+  // Directly computes the embedding matrix for all channels, advancing the
+  // component via the oracle until it is terminal. This call takes a vector
+  // of EmbeddingMatrix structs, one per channel, in channel order.
+  virtual void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_output) = 0;
+
   // Extracts and returns the vector of LinkFeatures for the specified
   // channel. Note: these are NOT translated.
   virtual std::vector<LinkFeatures> GetRawLinkFeatures(
@@ -138,4 +148,4 @@ class Component : public RegisterableClass<Component> {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_COMPONENT_H_
+#endif  // DRAGNN_CORE_INTERFACES_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/input_batch.h b/research/syntaxnet/dragnn/core/interfaces/input_batch.h
index 100ec76b..d087c7ef 100644
--- a/research/syntaxnet/dragnn/core/interfaces/input_batch.h
+++ b/research/syntaxnet/dragnn/core/interfaces/input_batch.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#ifndef DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#define DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
 
 #include <string>
 #include <vector>
@@ -32,14 +32,17 @@ class InputBatch {
  public:
   virtual ~InputBatch() {}
 
-  // Set the data to translate to the subclass' data type.
+  // Sets the data to translate to the subclass' data type.  Call at most once.
   virtual void SetData(const std::vector<string> &data) = 0;
 
-  // Translate the underlying data back to a vector of strings, as appropriate.
+  // Returns the size of the batch.
+  virtual int GetSize() const = 0;
+
+  // Translates the underlying data back to a vector of strings, as appropriate.
   virtual const std::vector<string> GetSerializedData() const = 0;
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
+#endif  // DRAGNN_CORE_INTERFACES_INPUT_BATCH_H_
diff --git a/research/syntaxnet/dragnn/core/interfaces/transition_state.h b/research/syntaxnet/dragnn/core/interfaces/transition_state.h
index c00409b9..24b52441 100644
--- a/research/syntaxnet/dragnn/core/interfaces/transition_state.h
+++ b/research/syntaxnet/dragnn/core/interfaces/transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#define DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
 
 #include <memory>
 #include <vector>
@@ -44,19 +44,25 @@ class TransitionState {
 
   // Return the beam index of the state passed into the initializer of this
   // TransitionState.
-  virtual const int ParentBeamIndex() const = 0;
+  virtual int ParentBeamIndex() const = 0;
 
-  // Get the current beam index for this state.
-  virtual const int GetBeamIndex() const = 0;
+  // Gets the current beam index for this state.
+  virtual int GetBeamIndex() const = 0;
 
-  // Set the current beam index for this state.
-  virtual void SetBeamIndex(const int index) = 0;
+  // Sets the current beam index for this state.
+  virtual void SetBeamIndex(int index) = 0;
 
-  // Get the score associated with this transition state.
-  virtual const float GetScore() const = 0;
+  // Gets the score associated with this transition state.
+  virtual float GetScore() const = 0;
 
-  // Set the score associated with this transition state.
-  virtual void SetScore(const float score) = 0;
+  // Sets the score associated with this transition state.
+  virtual void SetScore(float score) = 0;
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  virtual bool IsGold() const = 0;
+
+  // Sets the gold-ness of this state.
+  virtual void SetGold(bool is_gold) = 0;
 
   // Depicts this state as an HTML-language string.
   virtual string HTMLRepresentation() const = 0;
@@ -65,4 +71,4 @@ class TransitionState {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_INTERFACES_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/ops/compute_session_op.h b/research/syntaxnet/dragnn/core/ops/compute_session_op.h
index 9780ca81..88bc18c8 100644
--- a/research/syntaxnet/dragnn/core/ops/compute_session_op.h
+++ b/research/syntaxnet/dragnn/core/ops/compute_session_op.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#ifndef DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#define DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
 
 #include <string>
 
@@ -66,4 +66,4 @@ class ComputeSessionOp : public tensorflow::OpKernel {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
+#endif  // DRAGNN_CORE_OPS_COMPUTE_SESSION_OP_H_
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
index 28355557..761b28c7 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels.cc
@@ -303,6 +303,73 @@ class BulkFixedEmbeddings : public ComputeSessionOp {
 REGISTER_KERNEL_BUILDER(Name("BulkFixedEmbeddings").Device(DEVICE_CPU),
                         BulkFixedEmbeddings);
 
+// See docstring in dragnn_bulk_ops.cc.
+class BulkEmbedFixedFeatures : public ComputeSessionOp {
+ public:
+  explicit BulkEmbedFixedFeatures(OpKernelConstruction *context)
+      : ComputeSessionOp(context) {
+    OP_REQUIRES_OK(context, context->GetAttr("num_channels", &num_channels_));
+
+    // The input vector's zeroth element is the state handle, and the remaining
+    // num_channels_ elements are tensors of float embeddings, one per channel.
+    vector<DataType> input_types(num_channels_ + 1, DT_FLOAT);
+    input_types[0] = DT_STRING;
+    const vector<DataType> output_types = {DT_STRING, DT_FLOAT, DT_INT32};
+    OP_REQUIRES_OK(context, context->MatchSignature(input_types, output_types));
+    OP_REQUIRES_OK(context, context->GetAttr("pad_to_batch", &pad_to_batch_));
+    OP_REQUIRES_OK(context, context->GetAttr("pad_to_steps", &pad_to_steps_));
+  }
+
+  bool OutputsHandle() const override { return true; }
+  bool RequiresComponentName() const override { return true; }
+
+  void ComputeWithState(OpKernelContext *context,
+                        ComputeSession *session) override {
+    const auto &spec = session->Spec(component_name());
+    int embedding_size = 0;
+    std::vector<const float *> embeddings(num_channels_);
+    for (int channel = 0; channel < num_channels_; ++channel) {
+      const int embeddings_index = channel + 1;
+      embedding_size += context->input(embeddings_index).shape().dim_size(1) *
+                        spec.fixed_feature(channel).size();
+      embeddings[channel] =
+          context->input(embeddings_index).flat<float>().data();
+    }
+    Tensor *embedding_vectors;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(
+                       1,
+                       TensorShape({pad_to_steps_ * pad_to_batch_ *
+                                        session->BeamSize(component_name()),
+                                    embedding_size}),
+                       &embedding_vectors));
+    Tensor *num_steps_tensor;
+    OP_REQUIRES_OK(context, context->allocate_output(2, TensorShape({}),
+                                                     &num_steps_tensor));
+    embedding_vectors->flat<float>().setZero();
+    int output_size = embedding_vectors->NumElements();
+    session->BulkEmbedFixedFeatures(component_name(), pad_to_batch_,
+                                    pad_to_steps_, output_size, embeddings,
+                                    embedding_vectors->flat<float>().data());
+    num_steps_tensor->scalar<int32>()() = pad_to_steps_;
+  }
+
+ private:
+  // Number of fixed feature channels.
+  int num_channels_;
+
+  // Will pad output to this many batch elements.
+  int pad_to_batch_;
+
+  // Will pad output to this many steps.
+  int pad_to_steps_;
+
+  TF_DISALLOW_COPY_AND_ASSIGN(BulkEmbedFixedFeatures);
+};
+
+REGISTER_KERNEL_BUILDER(Name("BulkEmbedFixedFeatures").Device(DEVICE_CPU),
+                        BulkEmbedFixedFeatures);
+
 // See docstring in dragnn_bulk_ops.cc.
 class BulkAdvanceFromOracle : public ComputeSessionOp {
  public:
@@ -387,8 +454,11 @@ class BulkAdvanceFromPrediction : public ComputeSessionOp {
         }
       }
       if (!session->IsTerminal(component_name())) {
-        session->AdvanceFromPrediction(component_name(), scores_per_step.data(),
-                                       scores_per_step.size());
+        bool success = session->AdvanceFromPrediction(
+            component_name(), scores_per_step.data(), num_items, num_actions);
+        OP_REQUIRES(
+            context, success,
+            tensorflow::errors::Internal("Unable to advance from prediction."));
       }
     }
   }
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
index 01b776f6..8a4e368c 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_op_kernels_test.cc
@@ -375,6 +375,114 @@ TEST_F(DragnnBulkOpKernelsTest, BulkFixedEmbeddings) {
   EXPECT_EQ(kNumSteps, GetOutput(2)->scalar<int32>()());
 }
 
+TEST_F(DragnnBulkOpKernelsTest, BulkEmbedFixedFeatures) {
+  // Create and initialize the kernel under test.
+  constexpr int kBatchPad = 7;
+  constexpr int kStepPad = 5;
+  constexpr int kMaxBeamSize = 3;
+  TF_ASSERT_OK(
+      NodeDefBuilder("BulkEmbedFixedFeatures", "BulkEmbedFixedFeatures")
+          .Attr("component", kComponentName)
+          .Attr("num_channels", kNumChannels)
+          .Attr("pad_to_batch", kBatchPad)
+          .Attr("pad_to_steps", kStepPad)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // Embedding matrices.
+          .Finalize(node_def()));
+  MockComputeSession *mock_session = GetMockSession();
+  ComponentSpec spec;
+  spec.set_name(kComponentName);
+  auto chan0_spec = spec.add_fixed_feature();
+  constexpr int kChan0FeatureCount = 2;
+  chan0_spec->set_size(kChan0FeatureCount);
+  auto chan1_spec = spec.add_fixed_feature();
+  constexpr int kChan1FeatureCount = 1;
+  chan1_spec->set_size(kChan1FeatureCount);
+  EXPECT_CALL(*mock_session, Spec(kComponentName))
+      .WillOnce(testing::ReturnRef(spec));
+  EXPECT_CALL(*mock_session, BeamSize(kComponentName))
+      .WillOnce(testing::Return(kMaxBeamSize));
+
+  // Embedding matrices as additional inputs.
+  // For channel 0, the embeddings are [id, id, id].
+  // For channel 1, the embeddings are [id^2, id^2, id^2, ... ,id^2].
+  vector<float> embedding_matrix_0;
+  constexpr int kEmbedding0Size = 3;
+  vector<float> embedding_matrix_1;
+  constexpr int kEmbedding1Size = 9;
+  for (int id = 0; id < kNumIds; ++id) {
+    for (int i = 0; i < kEmbedding0Size; ++i) {
+      embedding_matrix_0.push_back(id);
+      LOG(INFO) << embedding_matrix_0.back();
+    }
+    for (int i = 0; i < kEmbedding1Size; ++i) {
+      embedding_matrix_1.push_back(id * id);
+      LOG(INFO) << embedding_matrix_0.back();
+    }
+  }
+
+  AddInputFromArray<float>(TensorShape({kNumIds, kEmbedding0Size}),
+                           embedding_matrix_0);
+  AddInputFromArray<float>(TensorShape({kNumIds, kEmbedding1Size}),
+                           embedding_matrix_1);
+
+  constexpr int kExpectedEmbeddingSize = kChan0FeatureCount * kEmbedding0Size +
+                                         kChan1FeatureCount * kEmbedding1Size;
+  constexpr int kExpectedOutputSize =
+      kExpectedEmbeddingSize * kBatchPad * kStepPad * kMaxBeamSize;
+
+  // This function takes the allocator functions passed into GetBulkFF, uses
+  // them to allocate a tensor, then fills that tensor based on channel.
+  auto eval_function = [=](const string &component_name, int batch_size_padding,
+                           int num_steps_padding, int output_array_size,
+                           const vector<const float *> &per_channel_embeddings,
+                           float *embedding_output) {
+    // Validate the control variables.
+    EXPECT_EQ(batch_size_padding, kBatchPad);
+    EXPECT_EQ(num_steps_padding, kStepPad);
+    EXPECT_EQ(output_array_size, kExpectedOutputSize);
+
+    // Validate the passed embeddings.
+    for (int i = 0; i < kNumIds; ++i) {
+      for (int j = 0; j < kEmbedding0Size; ++j) {
+        float ch0_embedding =
+            per_channel_embeddings.at(0)[i * kEmbedding0Size + j];
+        EXPECT_FLOAT_EQ(ch0_embedding, i)
+            << "Failed match at " << i << "," << j;
+      }
+      for (int j = 0; j < kEmbedding1Size; ++j) {
+        float ch1_embedding =
+            per_channel_embeddings.at(1)[i * kEmbedding1Size + j];
+        EXPECT_FLOAT_EQ(ch1_embedding, i * i)
+            << "Failed match at " << i << "," << j;
+      }
+    }
+
+    // Fill the output matrix to the expected size. This will trigger msan
+    // if the allocation wasn't big enough.
+    for (int i = 0; i < kExpectedOutputSize; ++i) {
+      embedding_output[i] = i;
+    }
+  };
+
+  EXPECT_CALL(*mock_session,
+              BulkEmbedFixedFeatures(kComponentName, _, _, _, _, _))
+      .WillOnce(testing::Invoke(eval_function));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Validate outputs.
+  EXPECT_EQ(kBatchPad * kStepPad * kMaxBeamSize,
+            GetOutput(1)->shape().dim_size(0));
+  EXPECT_EQ(kExpectedEmbeddingSize, GetOutput(1)->shape().dim_size(1));
+  auto output_data = GetOutput(1)->flat<float>();
+  for (int i = 0; i < kExpectedOutputSize; ++i) {
+    EXPECT_FLOAT_EQ(i, output_data(i));
+  }
+  EXPECT_EQ(kStepPad, GetOutput(2)->scalar<int32>()());
+}
+
 TEST_F(DragnnBulkOpKernelsTest, BulkFixedEmbeddingsWithPadding) {
   // Create and initialize the kernel under test.
   constexpr int kPaddedNumSteps = 5;
@@ -592,12 +700,54 @@ TEST_F(DragnnBulkOpKernelsTest, BulkAdvanceFromPrediction) {
   EXPECT_CALL(*mock_session,
               AdvanceFromPrediction(kComponentName,
                                     CheckScoresAreConsecutiveIntegersDivTen(),
-                                    kNumItems * kNumActions))
-      .Times(kNumSteps);
+                                    kNumItems, kNumActions))
+      .Times(kNumSteps)
+      .WillRepeatedly(Return(true));
 
   // Run the kernel.
   TF_EXPECT_OK(RunOpKernelWithContext());
 }
 
+TEST_F(DragnnBulkOpKernelsTest, BulkAdvanceFromPredictionFailsIfAdvanceFails) {
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("BulkAdvanceFromPrediction", "BulkAdvanceFromPrediction")
+          .Attr("component", kComponentName)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // Prediction scores for advancing.
+          .Finalize(node_def()));
+  MockComputeSession *mock_session = GetMockSession();
+
+  // Creates an input tensor such that each step will see a list of consecutive
+  // integers divided by 10 as scores.
+  vector<float> scores(kNumItems * kNumSteps * kNumActions);
+  for (int step(0), cnt(0); step < kNumSteps; ++step) {
+    for (int item = 0; item < kNumItems; ++item) {
+      for (int action = 0; action < kNumActions; ++action, ++cnt) {
+        scores[action + kNumActions * (step + item * kNumSteps)] = cnt / 10.0f;
+      }
+    }
+  }
+  AddInputFromArray<float>(TensorShape({kNumItems * kNumSteps, kNumActions}),
+                           scores);
+
+  EXPECT_CALL(*mock_session, BeamSize(kComponentName)).WillOnce(Return(1));
+  EXPECT_CALL(*mock_session, BatchSize(kComponentName))
+      .WillOnce(Return(kNumItems));
+  EXPECT_CALL(*mock_session, IsTerminal(kComponentName))
+      .Times(2)
+      .WillRepeatedly(Return(false));
+  EXPECT_CALL(*mock_session,
+              AdvanceFromPrediction(kComponentName,
+                                    CheckScoresAreConsecutiveIntegersDivTen(),
+                                    kNumItems, kNumActions))
+      .WillOnce(Return(true))
+      .WillOnce(Return(false));
+
+  // Run the kernel.
+  auto result = RunOpKernelWithContext();
+  EXPECT_FALSE(result.ok());
+}
+
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
index 4c2d444d..654b2c7f 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_bulk_ops.cc
@@ -80,6 +80,38 @@ pad_to_batch: If set, the op will pad/truncate to this number of elements.
 pad_to_steps: If set, the op will pad/truncate to this number of steps.
 )doc");
 
+REGISTER_OP("BulkEmbedFixedFeatures")
+    .Input("handle: string")
+    .Input("embedding_matrix: num_channels * float")
+    .Output("output_handle: string")
+    .Output("embedding_vectors: float")
+    .Output("num_steps: int32")
+    .Attr("component: string")
+    .Attr("num_channels: int")
+    .Attr("pad_to_batch: int")
+    .Attr("pad_to_steps: int")
+    .SetIsStateful()
+    .Doc(R"doc(
+This op is a more efficient version of BulkFixedFeatures.
+
+It is intended to be run with large batch sizes at inference time. The op takes
+a handle to ComputeSession and embedding matrices as tensor inputs, and directly
+outputs concatenated embedding vectors. It calls the BulkEmbedFixedFeatures
+method on the underlying component directly, so it requires a padding vector
+to be passed.
+
+handle: A handle to ComputeSession.
+embedding_matrix: Embedding matrices.
+output_handle: A handle to the same ComputeSession after advancement.
+embedding_vectors: (matrix of float) Concatenated embeddings,
+  shaped as (batch * beam * token) x sum_channel(embedding_dim[channel]).
+num_steps: The batch was unrolled for these many steps.
+component: The name of a Component instance, matching the ComponentSpec.name.
+num_channels: The number of FixedFeature channels.
+pad_to_batch: The op will pad/truncate to this number of elements.
+pad_to_steps: The op will pad/truncate to this number of steps.
+)doc");
+
 REGISTER_OP("BulkAdvanceFromOracle")
     .Input("handle: string")
     .Output("output_handle: string")
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
index a01b3772..cc6e9b20 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels.cc
@@ -30,6 +30,7 @@
 #include "tensorflow/core/framework/tensor_shape.h"
 #include "tensorflow/core/lib/core/status.h"
 #include "tensorflow/core/lib/core/threadpool.h"
+#include "tensorflow/core/lib/io/path.h"
 #include "tensorflow/core/platform/logging.h"
 #include "tensorflow/core/platform/mutex.h"
 
@@ -40,6 +41,8 @@ using tensorflow::DT_INT32;
 using tensorflow::DT_INT64;
 using tensorflow::DT_STRING;
 using tensorflow::DataType;
+using tensorflow::io::Dirname;
+using tensorflow::io::JoinPath;
 using tensorflow::OpKernel;
 using tensorflow::OpKernelConstruction;
 using tensorflow::OpKernelContext;
@@ -53,6 +56,59 @@ namespace dragnn {
 
 typedef ResourceContainer<ComputeSession> ComputeSessionResource;
 typedef ResourceContainer<ComputeSessionPool> ComputeSessionPoolResource;
+typedef ResourceContainer<string> StringResource;
+
+namespace {
+
+const char kGlobalContainer[] = "__reserved_global_container";
+const char kBasePathTag[] = "__reserved_asset_base_path";
+const char kUnmanagedAssetDirectory[] = "assets.extra";
+
+// When restoring a graph from a SavedModel, this op will rewrite the MasterSpec
+// to point the DRAGNN components to the new resource locations. It will then
+// add a string resource to the resource manager, which will be used to
+// rebuild the masterspec before it is acquired in the GetComputeSession op.
+class SetAssetDirectory : public OpKernel {
+ public:
+  explicit SetAssetDirectory(OpKernelConstruction *context)
+      : OpKernel(context) {
+    OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_STRING}));
+  }
+
+  void Compute(OpKernelContext *context) override {
+    ResourceMgr *rmgr = context->resource_manager();
+    const string asset_path = context->input(0).scalar<string>()();
+
+    // TODO(googleuser): Get this data in a way that isn't fragile as all hell.
+    // "I've done stuff I ain't proud of... and the stuff I am proud of is
+    // disgusting." -- Moe
+    auto extra_asset_dir =
+        JoinPath(Dirname(Dirname(asset_path)), kUnmanagedAssetDirectory);
+    LOG(INFO) << "Found extra assets path at:" << extra_asset_dir;
+
+    // Rather than attempt to rewrite the MasterSpec here, we save off a
+    // StringResource containing the new asset path. It will be used in
+    // the GetSession op, if it exists.
+    std::unique_ptr<string> asset_path_ptr(new string(extra_asset_dir));
+
+    OP_REQUIRES_OK(context, rmgr->Create<StringResource>(
+                                kGlobalContainer, kBasePathTag,
+                                new StringResource(std::move(asset_path_ptr))));
+
+    // This isn't used anywhere - it just allows us to have an output so that
+    // it's easier to reason about Tensorflow's graph execution.
+    Tensor *output;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(0, TensorShape({1}), &output));
+    output->vec<string>()(0) = asset_path;
+  }
+
+ private:
+  TF_DISALLOW_COPY_AND_ASSIGN(SetAssetDirectory);
+};
+
+REGISTER_KERNEL_BUILDER(Name("SetAssetDirectory").Device(DEVICE_CPU),
+                        SetAssetDirectory);
 
 // Given a MasterSpec proto, outputs a handle to a ComputeSession.
 class GetSession : public OpKernel {
@@ -66,6 +122,7 @@ class GetSession : public OpKernel {
     CHECK(master_spec_.ParseFromString(master_spec_str));
     CHECK(grid_point_.ParseFromString(grid_point_spec_str));
     OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_STRING}));
+    has_overwritten_spec_ = false;
   }
 
   void Compute(OpKernelContext *context) override {
@@ -74,10 +131,32 @@ class GetSession : public OpKernel {
 
     // Create the pool for this container, or re-use one that was allocated in a
     // previous call.
-    auto create_pool = [this,
+    auto create_pool = [this, &rmgr,
                         &container](ComputeSessionPoolResource **resource) {
-      LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
-      << container;
+      if (has_overwritten_spec_) {
+        // TODO(googleuser): Figure out a way to test this.
+        // If there's already an overwritten spec, use that.
+        LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                  << container << " with previously overwritten master spec.";
+      } else {
+        // If not, try to find the resource base.
+        StringResource *resource_base;
+        auto resource_base_lookup = rmgr->Lookup<StringResource>(
+            kGlobalContainer, kBasePathTag, &resource_base);
+        if (resource_base_lookup.ok()) {
+          // If that exists, the spec must be rewritten.
+          string resource_base_path = *resource_base->get();
+          LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                    << container << " using resource directory base "
+                    << resource_base_path;
+          RewriteMasterSpec(resource_base_path);
+          resource_base->Unref();
+        } else {
+          // If not, just use the spec as is.
+          LOG(INFO) << "Creating new ComputeSessionPool in container handle: "
+                    << container << " without editing master spec.";
+        }
+      }
       std::unique_ptr<ComputeSessionPool> pool(
           new ComputeSessionPool(master_spec_, grid_point_));
       *resource = new ComputeSessionPoolResource(std::move(pool));
@@ -120,6 +199,23 @@ class GetSession : public OpKernel {
   }
 
  private:
+  // Rewrites this op's saved MasterSpec, appending the new base directory.
+  void RewriteMasterSpec(const string &new_base) {
+    for (auto &component_spec : *master_spec_.mutable_component()) {
+      for (auto &resource_def : *component_spec.mutable_resource()) {
+        for (auto &part_def : *resource_def.mutable_part()) {
+          part_def.set_file_pattern(
+              JoinPath(new_base, part_def.file_pattern()));
+          VLOG(2) << "New path: " << part_def.file_pattern();
+        }
+      }
+    }
+
+    VLOG(3) << "Rewritten spec: " << master_spec_.DebugString();
+    has_overwritten_spec_ = true;
+  }
+
+  bool has_overwritten_spec_;
   MasterSpec master_spec_;
   GridPoint grid_point_;
 
@@ -141,7 +237,6 @@ REGISTER_KERNEL_BUILDER(Name("GetSession").Device(DEVICE_CPU), GetSession);
 class ReleaseSession : public OpKernel {
  public:
   explicit ReleaseSession(OpKernelConstruction *context) : OpKernel(context) {
-    string master_spec_str;
     OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {}));
   }
 
@@ -188,6 +283,53 @@ class ReleaseSession : public OpKernel {
 REGISTER_KERNEL_BUILDER(Name("ReleaseSession").Device(DEVICE_CPU),
                         ReleaseSession);
 
+// Returns statistics about session loads to the graph. This op returns the
+// total number of created Session objects and the number of those objects
+// that are currently being used in the ComputeSessionPool.
+class GetSessionCounts : public OpKernel {
+ public:
+  explicit GetSessionCounts(OpKernelConstruction *context) : OpKernel(context) {
+    OP_REQUIRES_OK(context, context->MatchSignature({DT_STRING}, {DT_INT64}));
+  }
+
+  void Compute(OpKernelContext *context) override {
+    const string container = context->input(0).scalar<string>()();
+    VLOG(1) << "Getting stats for container: " << container;
+    ResourceMgr *rmgr = context->resource_manager();
+
+    // Allocate the output tensors.
+    Tensor *output;
+    OP_REQUIRES_OK(context,
+                   context->allocate_output(0, TensorShape({2}), &output));
+
+    // Get the pool for this container.
+    ComputeSessionPoolResource *pool_resource;
+    auto result = rmgr->Lookup<ComputeSessionPoolResource>(container, "pool",
+                                                           &pool_resource);
+    if (!result.ok()) {
+      // If there's no ComputeSessionPoolResource, report 0 sessions created
+      // and 0 available.
+      output->vec<int64>()(0) = 0;
+      output->vec<int64>()(1) = 0;
+      return;
+    }
+
+    auto *pool = pool_resource->get();
+    CHECK(pool != nullptr);
+
+    output->vec<int64>()(0) = pool->num_unique_sessions();
+    output->vec<int64>()(1) = pool->num_outstanding_sessions();
+
+    pool_resource->Unref();
+  }
+
+ private:
+  TF_DISALLOW_COPY_AND_ASSIGN(GetSessionCounts);
+};
+
+REGISTER_KERNEL_BUILDER(Name("GetSessionCounts").Device(DEVICE_CPU),
+                        GetSessionCounts);
+
 /*******************************************************************************
  *                   ComputeSessionOps below here.
  ******************************************************************************/
@@ -233,9 +375,17 @@ class AdvanceFromPrediction : public ComputeSessionOp {
   void ComputeWithState(OpKernelContext *context,
                         ComputeSession *session) override {
     const Tensor &scores = context->input(1);
-    session->AdvanceFromPrediction(component_name(),
-                                   scores.tensor<float, 2>().data(),
-                                   scores.NumElements());
+    const int num_items = scores.shape().dim_size(0);
+    const int num_actions = scores.shape().dim_size(1);
+    bool success = session->AdvanceFromPrediction(
+        component_name(), scores.tensor<float, 2>().data(), num_items,
+        num_actions);
+    if (success) {
+      VLOG(2) << "Score: " << scores.tensor<float, 2>();
+    }
+    OP_REQUIRES(
+        context, success,
+        tensorflow::errors::Internal("Unable to advance from prediction."));
   }
 
  private:
@@ -247,13 +397,12 @@ REGISTER_KERNEL_BUILDER(Name("AdvanceFromPrediction").Device(DEVICE_CPU),
 
 // Given a handle to a ComputeSession and a channel index, outputs fixed
 // features.
-// Fixed features are returned as 3 vectors or equal length:
+// Fixed features are returned as 3 vectors of equal length:
 //   - ids: specifies which rows should be looked up in the embedding
 //   matrix,
 //   - weights: specifies a scale for each embedding vector,
 //   - indices: sorted vector that assigns the same index to embedding
-//   vectors
-//       that should be summed together.
+//   vectors that should be summed together.
 //
 // For example if we have 3 features, for a given channel, we might have:
 //   feature a: (5, 1)
@@ -300,7 +449,10 @@ class ExtractFixedFeatures : public ComputeSessionOp {
     int num_features = session->GetInputFeatures(
         component_name(), indices_allocator, ids_allocator, weights_allocator,
         channel_id_);
-    VLOG(2) << "Extracted " << num_features;
+    VLOG(2) << "Extracted features (" << num_features << "): "
+            << " ids="     << context->mutable_output(1)->vec<int64>()
+            << " weights=" <<  context->mutable_output(2)->vec<float>()
+            << " indices=" << context->mutable_output(0)->vec<int32>();
   }
 
  private:
@@ -524,6 +676,7 @@ class AttachDataReader : public ComputeSessionOp {
     auto input_data(context->input(1).vec<string>());
 
     std::vector<string> data;
+    data.reserve(input_data.size());
     for (int i = 0; i < input_data.size(); ++i) {
       data.push_back(input_data(i));
     }
@@ -642,5 +795,6 @@ class GetComponentTrace : public ComputeSessionOp {
 REGISTER_KERNEL_BUILDER(Name("GetComponentTrace").Device(DEVICE_CPU),
                         GetComponentTrace);
 
+}  // namespace
 }  // namespace dragnn
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
index 92444fa9..f615b035 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_op_kernels_test.cc
@@ -17,6 +17,7 @@
 #include <memory>
 #include <vector>
 
+#include "dragnn/core/component_registry.h"
 #include "dragnn/core/compute_session.h"
 #include "dragnn/core/compute_session_pool.h"
 #include "dragnn/core/resource_container.h"
@@ -66,6 +67,87 @@ using testing::Return;
 
 typedef ResourceContainer<ComputeSession> ComputeSessionResource;
 typedef ResourceContainer<ComputeSessionPool> ComputeSessionPoolResource;
+typedef ResourceContainer<string> StringResource;
+
+namespace {
+const char kGlobalContainer[] = "__reserved_global_container";
+const char kBasePathTag[] = "__reserved_asset_base_path";
+const char kUnmanagedAssetDirectory[] = "assets.extra";
+}  // namespace
+
+// Define a test component to validate registered construction.
+class TestComponent : public Component {
+ public:
+  TestComponent() {}
+  void InitializeComponent(const ComponentSpec &spec) override {
+    name_ = spec.name();
+  }
+  void InitializeData(
+      const std::vector<std::vector<const TransitionState *>> &states,
+      int max_beam_size, InputBatchCache *input_data) override {}
+  void InitializeTracing() override {}
+  void DisableTracing() override {}
+  bool IsReady() const override { return true; }
+  string Name() const override { return name_; }
+  int BeamSize() const override { return 3; }
+  int BatchSize() const override { return 1; }
+  int StepsTaken(int batch_index) const override { return 0; }
+  int GetBeamIndexAtStep(int step, int current_index,
+                         int batch) const override {
+    return 0;
+  }
+  int GetSourceBeamIndex(int current_index, int batch) const override {
+    return 0;
+  }
+  bool AdvanceFromPrediction(const float *score_matrix, int num_items,
+                             int num_actions) override {
+    return true;
+  }
+  void AdvanceFromOracle() override {}
+  bool IsTerminal() const override { return true; }
+  std::function<int(int, int, int)> GetStepLookupFunction(
+      const string &method) override {
+    return nullptr;
+  }
+  std::vector<std::vector<const TransitionState *>> GetBeam() override {
+    std::vector<std::vector<const TransitionState *>> states;
+    return states;
+  }
+  int GetFixedFeatures(std::function<int32 *(int)> allocate_indices,
+                       std::function<int64 *(int)> allocate_ids,
+                       std::function<float *(int)> allocate_weights,
+                       int channel_id) const override {
+    return 0;
+  }
+  int BulkGetFixedFeatures(const BulkFeatureExtractor &extractor) override {
+    return 0;
+  }
+  void BulkEmbedFixedFeatures(
+      int batch_size_padding, int num_steps_padding, int output_array_size,
+      const vector<const float *> &per_channel_embeddings,
+      float *embedding_matrix) override {}
+  std::vector<LinkFeatures> GetRawLinkFeatures(int channel_id) const override {
+    std::vector<LinkFeatures> ret;
+    return ret;
+  }
+  std::vector<std::vector<int>> GetOracleLabels() const override {
+    std::vector<std::vector<int>> ret;
+    return ret;
+  }
+  void FinalizeData() override {}
+  void ResetComponent() override {}
+
+  std::vector<std::vector<ComponentTrace>> GetTraceProtos() const override {
+    std::vector<std::vector<ComponentTrace>> ret;
+    return ret;
+  }
+  void AddTranslatedLinkFeaturesToTrace(
+      const std::vector<LinkFeatures> &features, int channel_id) override {}
+
+  string name_;
+};
+
+REGISTER_DRAGNN_COMPONENT(TestComponent);
 
 class DragnnOpKernelsTest : public tensorflow::OpsTestBase {
  public:
@@ -106,6 +188,42 @@ LinkFeatures MakeFeatures(int batch_index, int beam_index, int step) {
   return features;
 }
 
+// The SetAssetDirectory op should
+// 1. When given an asset path (foo/bar/baz/asset/thing), strip the path to
+//    foo/bar/baz and add 'assets.extra' to it.
+// 2. Store that path in the resource manager.
+TEST_F(DragnnOpKernelsTest, SetAssetDirectoryTest) {
+  // Create a MasterSpec and GridPoint string to pass into the attrs for this
+  // op.
+  const string new_asset_path = "new/directory/path/asset/master_spec";
+  const string expected_asset_path =
+      StrCat("new/directory/path/", kUnmanagedAssetDirectory);
+
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(NodeDefBuilder("set_asset_directory", "SetAssetDirectory")
+                   .Input(FakeInput(DT_STRING))  // The new asset path.
+                   .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  AddInputFromList<string>(TensorShape({1}), {new_asset_path});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Expect that the ResourceMgr contains a the correct string.
+  StringResource *resource;
+  TF_EXPECT_OK(resource_mgr()->Lookup<StringResource>(kGlobalContainer,
+                                                      kBasePathTag, &resource));
+
+  EXPECT_EQ(*resource->get(), expected_asset_path);
+
+  resource->Unref();
+}
+
 // The GetSessionOp should
 // 1. create a ComputeSessionPool resource and store it in the ResourceMgr,
 // 2. create a ComputeSession resource and store it in the ResourceMgr,
@@ -164,6 +282,103 @@ TEST_F(DragnnOpKernelsTest, GetSessionOpTest) {
   pool_resource->Unref();
 }
 
+// If an asset_base_path resource exists, the GetSession op should prepend
+// that path to all paths in the MasterSpec before creating a session.
+TEST_F(DragnnOpKernelsTest, GetSessionWithAssetBasePathTest) {
+  // Create a MasterSpec and GridPoint string to pass into the attrs for this
+  // op.
+  const string new_asset_path = "new/base";
+  MasterSpec spec;
+
+  // The first component in the MasterSpec has one resource with one part.
+  auto component_one = spec.add_component();
+  auto backend_one = component_one->mutable_backend();
+  backend_one->set_registered_name("TestComponent");
+  component_one->add_resource()->add_part()->set_file_pattern(
+      "path/to/an/asset.txt");
+  const string expected_component_one_asset = "new/base/path/to/an/asset.txt";
+
+  auto component_two = spec.add_component();
+  auto backend_two = component_two->mutable_backend();
+  backend_two->set_registered_name("TestComponent");
+
+  // The second component's first resource has no assets.
+  component_two->add_resource();
+
+  // The second component's second resource has one part.
+  vector<string> expected_component_two_assets;
+  component_two->add_resource()->add_part()->set_file_pattern(
+      "another/dir/with/an/asset.txt");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset.txt");
+
+  // The second component's third resource has two parts.
+  auto third_resource = component_two->add_resource();
+  third_resource->add_part()->set_file_pattern(
+      "another/dir/with/an/asset3.jif");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset3.jif");
+  third_resource->add_part()->set_file_pattern(
+      "another/dir/with/an/asset4.jif");
+  expected_component_two_assets.push_back(
+      "new/base/another/dir/with/an/asset4.jif");
+
+  LOG(INFO) << spec.DebugString();
+
+  string master_spec_str;
+  spec.SerializeToString(&master_spec_str);
+
+  GridPoint hyperparams;
+  string hyperparams_str;
+  hyperparams.SerializeToString(&hyperparams_str);
+
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("get_session", "GetSession")
+          .Attr("master_spec", master_spec_str)
+          .Attr("grid_point", hyperparams_str)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  AddInputFromList<string>(TensorShape({1}), {container_string});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create the string in the resource manager.
+  std::unique_ptr<string> asset_path_ptr(new string(new_asset_path));
+
+  TF_EXPECT_OK(resource_mgr()->Create<StringResource>(
+      kGlobalContainer, kBasePathTag,
+      new StringResource(std::move(asset_path_ptr))));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  // Expect that the ResourceMgr contains a ComputeSessionPoolResource.
+  const string pool_id_str = "pool";
+  ComputeSessionPoolResource *pool_resource;
+  TF_EXPECT_OK(resource_mgr()->Lookup<ComputeSessionPoolResource>(
+      container_string, pool_id_str, &pool_resource));
+
+  // Validate that the master spec held by the pool has the new directory names.
+  auto rewritten_spec = pool_resource->get()->GetSpec();
+  EXPECT_EQ(rewritten_spec.component(0).resource(0).part(0).file_pattern(),
+            expected_component_one_asset);
+  EXPECT_EQ(rewritten_spec.component(1).resource(1).part(0).file_pattern(),
+            expected_component_two_assets.at(0));
+  EXPECT_EQ(rewritten_spec.component(1).resource(2).part(0).file_pattern(),
+            expected_component_two_assets.at(1));
+  EXPECT_EQ(rewritten_spec.component(1).resource(2).part(1).file_pattern(),
+            expected_component_two_assets.at(2));
+
+  // Unref the managed resources so they get destroyed properly.
+  pool_resource->Unref();
+}
+
 // The GetSessionOp should take a session stored in the resource manager
 // and return it to the ComputeSessionPool.
 TEST_F(DragnnOpKernelsTest, ReleaseSessionOpTest) {
@@ -217,6 +432,56 @@ TEST_F(DragnnOpKernelsTest, ReleaseSessionOpTest) {
   EXPECT_EQ(null_resource, nullptr);
 }
 
+// The GetSessionCounts op should report the number of sessions created and
+// free.
+TEST_F(DragnnOpKernelsTest, GetSessionCountsOpTest) {
+  // Create and initialize the kernel under test.
+  TF_ASSERT_OK(
+      NodeDefBuilder("get_session_counts", "GetSessionCounts")
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  AddInputFromList<string>(TensorShape({1}), {container_string});
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create a ComputeSessionPool.
+  MasterSpec spec;
+  GridPoint hyperparams;
+  std::unique_ptr<ComputeSessionPool> pool(
+      new ComputeSessionPool(spec, hyperparams));
+
+  // Get an unowned pointer to the ComputeSessionPool before moving
+  // the pool to the resource manager.
+  ComputeSessionPool *pool_ptr = pool.get();
+  TF_ASSERT_OK(resource_mgr()->Create<ComputeSessionPoolResource>(
+      container_string, "pool",
+      new ComputeSessionPoolResource(std::move(pool))));
+
+  // Create two ComputeSessions.
+  auto session_one = pool_ptr->GetSession();
+  auto session_two = pool_ptr->GetSession();
+
+  // Retun one of them.
+  pool_ptr->ReturnSession(std::move(session_two));
+
+  // At this point, the pool should report that it has one outstanding session
+  // and two sessions total.
+  EXPECT_EQ(1, pool_ptr->num_outstanding_sessions());
+  EXPECT_EQ(2, pool_ptr->num_unique_sessions());
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+
+  EXPECT_EQ(pool_ptr->num_unique_sessions(), GetOutput(0)->vec<int64>()(0));
+  EXPECT_EQ(pool_ptr->num_outstanding_sessions(),
+            GetOutput(0)->vec<int64>()(1));
+}
+
 // The AdvanceFromOracle op should call AdvanceFromOracle on the specified
 // component name.
 TEST_F(DragnnOpKernelsTest, AdvanceFromOracleOpTest) {
@@ -287,14 +552,65 @@ TEST_F(DragnnOpKernelsTest, AdvanceFromPredictionOpTest) {
 
   // Set expectations on the mock session.
   auto validator_function = [weights](const string &component_name,
-                                      const float score_matrix[],
-                                      int score_matrix_length) {
-    EXPECT_EQ(weights.size(), score_matrix_length);
+                                      const float *score_matrix, int num_items,
+                                      int num_actions) {
+    EXPECT_EQ(weights.size(), num_items * num_actions);
+    for (int i = 0; i < weights.size(); ++i) {
+      EXPECT_EQ(weights[i], score_matrix[i]);
+    }
+    return true;
+  };
+  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _, _))
+      .WillOnce(Invoke(validator_function));
+
+  // Run the kernel.
+  TF_EXPECT_OK(RunOpKernelWithContext());
+}
+
+// The AdvanceFromPredicton op should call AdvanceFromPrediction on the
+// specified component with the passed scores. If it returns false, the op
+// should not return OK.
+TEST_F(DragnnOpKernelsTest, AdvanceFromPredictionFailureTest) {
+  // Create and initialize the kernel under test.
+  const string component_name = "TESTING_COMPONENT_NAME";
+  TF_ASSERT_OK(
+      NodeDefBuilder("advance_from_prediction", "AdvanceFromPrediction")
+          .Attr("component", component_name)
+          .Input(FakeInput(DT_STRING))  // The handle for the ComputeSession.
+          .Input(FakeInput(DT_FLOAT))   // The prediction tensor.
+          .Finalize(node_def()));
+  TF_ASSERT_OK(InitOp());
+
+  // Set the input data.
+  const string container_string = "container_str";
+  const string id_string = "id_str";
+  AddInputFromList<string>(TensorShape({2}), {container_string, id_string});
+  const std::vector<float> weights = {1.1, 2.2, 3.3, 4.4};
+  AddInputFromArray<float>(TensorShape({2, 2}), weights);
+
+  // Reset the test context to ensure it's clean.
+  ResetOpKernelContext();
+
+  // Create a MockComputeSession and set expectations.
+  std::unique_ptr<MockComputeSession> mock_session(new MockComputeSession());
+  MockComputeSession *mock_session_ptr = mock_session.get();
+
+  // Wrap the ComputeSessionResource and put it into the resource manager.
+  TF_ASSERT_OK(resource_mgr()->Create<ComputeSessionResource>(
+      container_string, id_string,
+      new ComputeSessionResource(std::move(mock_session))));
+
+  // Set expectations on the mock session.
+  auto validator_function = [weights](const string &component_name,
+                                      const float *score_matrix, int num_items,
+                                      int num_actions) {
+    EXPECT_EQ(weights.size(), num_items * num_actions);
     for (int i = 0; i < weights.size(); ++i) {
       EXPECT_EQ(weights[i], score_matrix[i]);
     }
+    return true;
   };
-  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _))
+  EXPECT_CALL(*mock_session_ptr, AdvanceFromPrediction(component_name, _, _, _))
       .WillOnce(Invoke(validator_function));
 
   // Run the kernel.
diff --git a/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc b/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
index f2bd653b..c7d3c639 100644
--- a/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
+++ b/research/syntaxnet/dragnn/core/ops/dragnn_ops.cc
@@ -18,6 +18,20 @@
 namespace syntaxnet {
 namespace dragnn {
 
+REGISTER_OP("SetAssetDirectory")
+    .Input("asset_directory: string")
+    .Output("asset_directory_out: string")
+    .SetIsStateful()
+    .Doc(R"doc(
+Override the paths to assets specified in the MasterSpec with the given
+asset_directory. This op must be called before any calls to GetSession, as it
+will create a new session pool with the overridden master spec.
+
+asset_directory: The directory containing all the assets. Note that all assets
+    must be in a single flat directory.
+asset_directory_out: The input, just as an output.
+)doc");
+
 REGISTER_OP("GetSession")
     .Input("container: string")
     .Attr("master_spec: string")
@@ -42,6 +56,18 @@ This ComputeSession will no longer be available after this op returns.
 handle: A handle to a ComputeSession that will be returned to the backing pool.
 )doc");
 
+REGISTER_OP("GetSessionCounts")
+    .Input("container: string")
+    .Output("stats: int64")
+    .SetIsStateful()
+    .Doc(R"doc(
+Given a container string, output session counts for that ComputeSessionPool.
+
+container: A unique identifier for the ComputeSessionPool to analyze.
+stats: A vector of stats. [0] is the total number of created sessions. [1] is
+the number of sessions that are currently not in the pool.
+)doc");
+
 REGISTER_OP("InitComponentData")
     .Input("handle: string")
     .Input("beam_size: int32")
@@ -123,28 +149,6 @@ component: The name of a Component instance, matching the ComponentSpec.name.
 output_handle: A handle to the same ComputeSession after advancement.
 )doc");
 
-REGISTER_OP("DragnnEmbeddingInitializer")
-    .Output("embeddings: float")
-    .Attr("embedding_input: string")
-    .Attr("vocab: string")
-    .Attr("scaling_coefficient: float = 1.0")
-    .Attr("seed: int = 0")
-    .Attr("seed2: int = 0")
-    .Doc(R"doc(
-*** PLACEHOLDER OP - FUNCTIONALITY NOT YET IMPLEMENTED ***
-
-Read embeddings from an an input for every key specified in a text vocab file.
-
-embeddings: A tensor containing embeddings from the specified sstable.
-embedding_input: Path to location with embedding vectors.
-vocab: Path to list of keys corresponding to the input.
-scaling_coefficient: A scaling coefficient for the embedding matrix.
-seed: If either `seed` or `seed2` are set to be non-zero, the random number
-      generator is seeded by the given seed.  Otherwise, it is seeded by a
-      random seed.
-seed2: A second seed to avoid seed collision.
-)doc");
-
 REGISTER_OP("ExtractFixedFeatures")
     .Input("handle: string")
     .Output("indices: int32")
diff --git a/research/syntaxnet/dragnn/core/resource_container.h b/research/syntaxnet/dragnn/core/resource_container.h
index 7ca72a05..7e06b856 100644
--- a/research/syntaxnet/dragnn/core/resource_container.h
+++ b/research/syntaxnet/dragnn/core/resource_container.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#ifndef DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#define DRAGNN_CORE_RESOURCE_CONTAINER_H_
 
 #include <memory>
 
@@ -48,4 +48,4 @@ class ResourceContainer : public tensorflow::ResourceBase {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_RESOURCE_CONTAINER_H_
+#endif  // DRAGNN_CORE_RESOURCE_CONTAINER_H_
diff --git a/research/syntaxnet/dragnn/core/test/BUILD b/research/syntaxnet/dragnn/core/test/BUILD
index 9810bd25..157b019f 100644
--- a/research/syntaxnet/dragnn/core/test/BUILD
+++ b/research/syntaxnet/dragnn/core/test/BUILD
@@ -26,6 +26,7 @@ cc_library(
     deps = [
         "//dragnn/components/util:bulk_feature_extractor",
         "//dragnn/core:compute_session",
+        "//dragnn/core:input_batch_cache",
         "//dragnn/protos:data_proto",
         "//dragnn/protos:spec_proto",
         "//syntaxnet:base",
diff --git a/research/syntaxnet/dragnn/core/test/generic.h b/research/syntaxnet/dragnn/core/test/generic.h
index 5624856b..b8e93d14 100644
--- a/research/syntaxnet/dragnn/core/test/generic.h
+++ b/research/syntaxnet/dragnn/core/test/generic.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
+#ifndef DRAGNN_CORE_TEST_GENERIC_H_
+#define DRAGNN_CORE_TEST_GENERIC_H_
 
 #include <utility>
 
@@ -31,10 +31,18 @@ MATCHER_P(EqualsProto, a, "Protos are not equivalent:") {
   return a.DebugString() == arg.DebugString();
 }
 
+// Matches an error status whose message matches |substr|.
+MATCHER_P(IsErrorWithSubstr, substr,
+          string(negation ? "isn't" : "is") +
+          " an error Status whose message matches the substring '" +
+          ::testing::PrintToString(substr) + "'") {
+  return !arg.ok() && arg.error_message().find(substr) != string::npos;
+}
+
 // Returns the prefix for where the test data is stored.
 string GetTestDataPrefix();
 
 }  // namespace test
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_GENERIC_H_
+#endif  // DRAGNN_CORE_TEST_GENERIC_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_component.h b/research/syntaxnet/dragnn/core/test/mock_component.h
index 74d9986b..52373351 100644
--- a/research/syntaxnet/dragnn/core/test/mock_component.h
+++ b/research/syntaxnet/dragnn/core/test/mock_component.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#define DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
 
 #include <gmock/gmock.h>
 
@@ -47,8 +47,8 @@ class MockComponent : public Component {
   MOCK_CONST_METHOD3(GetBeamIndexAtStep,
                      int(int step, int current_index, int batch));
   MOCK_CONST_METHOD2(GetSourceBeamIndex, int(int current_index, int batch));
-  MOCK_METHOD2(AdvanceFromPrediction,
-               void(const float transition_matrix[], int matrix_length));
+  MOCK_METHOD3(AdvanceFromPrediction, bool(const float *transition_matrix,
+                                           int num_items, int num_actions));
   MOCK_METHOD0(AdvanceFromOracle, void());
   MOCK_CONST_METHOD0(IsTerminal, bool());
   MOCK_METHOD0(GetBeam, std::vector<std::vector<const TransitionState *>>());
@@ -59,6 +59,11 @@ class MockComponent : public Component {
                          int channel_id));
   MOCK_METHOD1(BulkGetFixedFeatures,
                int(const BulkFeatureExtractor &extractor));
+  MOCK_METHOD5(BulkEmbedFixedFeatures,
+               void(int batch_size_padding, int num_steps_padding,
+                    int output_array_size,
+                    const vector<const float *> &per_channel_embeddings,
+                    float *embedding_output));
   MOCK_CONST_METHOD1(GetRawLinkFeatures,
                      std::vector<LinkFeatures>(int channel_id));
   MOCK_CONST_METHOD0(GetOracleLabels, std::vector<std::vector<int>>());
@@ -75,4 +80,4 @@ class MockComponent : public Component {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_COMPONENT_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_compute_session.h b/research/syntaxnet/dragnn/core/test/mock_compute_session.h
index 8df455c4..26458968 100644
--- a/research/syntaxnet/dragnn/core/test/mock_compute_session.h
+++ b/research/syntaxnet/dragnn/core/test/mock_compute_session.h
@@ -13,16 +13,18 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#define DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
 
-#include <gmock/gmock.h>
+#include <memory>
 
 #include "dragnn/components/util/bulk_feature_extractor.h"
 #include "dragnn/core/compute_session.h"
+#include "dragnn/core/input_batch_cache.h"
 #include "dragnn/protos/data.pb.h"
 #include "dragnn/protos/spec.pb.h"
 #include "syntaxnet/base.h"
+#include <gmock/gmock.h>
 #include "tensorflow/core/platform/test.h"
 
 namespace syntaxnet {
@@ -40,9 +42,9 @@ class MockComputeSession : public ComputeSession {
   MOCK_METHOD2(SourceComponentBeamSize,
                int(const string &component_name, int channel_id));
   MOCK_METHOD1(AdvanceFromOracle, void(const string &component_name));
-  MOCK_METHOD3(AdvanceFromPrediction,
-               void(const string &component_name, const float score_matrix[],
-                    int score_matrix_length));
+  MOCK_METHOD4(AdvanceFromPrediction,
+               bool(const string &component_name, const float *score_matrix,
+                    int num_items, int num_actions));
   MOCK_CONST_METHOD5(GetInputFeatures,
                      int(const string &component_name,
                          std::function<int32 *(int)> allocate_indices,
@@ -52,6 +54,11 @@ class MockComputeSession : public ComputeSession {
   MOCK_METHOD2(BulkGetInputFeatures,
                int(const string &component_name,
                    const BulkFeatureExtractor &extractor));
+  MOCK_METHOD6(BulkEmbedFixedFeatures,
+               void(const string &component_name, int batch_size_padding,
+                    int num_steps_padding, int output_array_size,
+                    const vector<const float *> &per_channel_embedding,
+                    float *embedding_output));
   MOCK_METHOD2(GetTranslatedLinkFeatures,
                std::vector<LinkFeatures>(const string &component_name,
                                          int channel_id));
@@ -68,9 +75,17 @@ class MockComputeSession : public ComputeSession {
   MOCK_CONST_METHOD1(GetDescription, string(const string &component_name));
   MOCK_CONST_METHOD1(Translators, const std::vector<const IndexTranslator *>(
                                       const string &component_name));
+  MOCK_CONST_METHOD1(GetReadiedComponent, Component *(const string &name));
+
+  // TODO(googleuser): Upgrade gMock to a version that supports mocking methods
+  // with move-only types, then remove this workaround.
+  MOCK_METHOD1(DoSetInputBatchCache, void(InputBatchCache *batch));
+  void SetInputBatchCache(std::unique_ptr<InputBatchCache> batch) override {
+    DoSetInputBatchCache(batch.get());
+  }
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_COMPUTE_SESSION_H_
diff --git a/research/syntaxnet/dragnn/core/test/mock_transition_state.h b/research/syntaxnet/dragnn/core/test/mock_transition_state.h
index a6737cb3..a90ff74e 100644
--- a/research/syntaxnet/dragnn/core/test/mock_transition_state.h
+++ b/research/syntaxnet/dragnn/core/test/mock_transition_state.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#ifndef DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#define DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
 
 #include <memory>
 
@@ -31,15 +31,17 @@ class MockTransitionState : public TransitionState {
  public:
   MOCK_METHOD1(Init, void(const TransitionState &parent));
   MOCK_CONST_METHOD0(Clone, std::unique_ptr<TransitionState>());
-  MOCK_CONST_METHOD0(ParentBeamIndex, const int());
-  MOCK_METHOD1(SetBeamIndex, void(const int index));
-  MOCK_CONST_METHOD0(GetBeamIndex, const int());
-  MOCK_CONST_METHOD0(GetScore, const float());
-  MOCK_METHOD1(SetScore, void(const float score));
+  MOCK_CONST_METHOD0(ParentBeamIndex, int());
+  MOCK_METHOD1(SetBeamIndex, void(int index));
+  MOCK_CONST_METHOD0(GetBeamIndex, int());
+  MOCK_CONST_METHOD0(GetScore, float());
+  MOCK_METHOD1(SetScore, void(float score));
+  MOCK_CONST_METHOD0(IsGold, bool());
+  MOCK_METHOD1(SetGold, void(bool is_gold));
   MOCK_CONST_METHOD0(HTMLRepresentation, string());
 };
 
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
+#endif  // DRAGNN_CORE_TEST_MOCK_TRANSITION_STATE_H_
diff --git a/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto b/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
index aea09690..6e991e03 100644
--- a/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
+++ b/research/syntaxnet/dragnn/core/testdata/master_spec_link.textproto
@@ -11,10 +11,6 @@ component {
       key: "language"
       value: "en"
     }
-    parameters {
-      key: "neurosis_feature_syntax_version"
-      value: "2"
-    }
     parameters {
       key: "parser_skip_deterministic"
       value: "false"
diff --git a/research/syntaxnet/dragnn/io/sentence_input_batch.h b/research/syntaxnet/dragnn/io/sentence_input_batch.h
index 7c355813..0343d470 100644
--- a/research/syntaxnet/dragnn/io/sentence_input_batch.h
+++ b/research/syntaxnet/dragnn/io/sentence_input_batch.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#ifndef DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#define DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
 
 #include <string>
 #include <vector>
@@ -35,6 +35,9 @@ class SentenceInputBatch : public InputBatch {
   void SetData(
       const std::vector<string> &stringified_sentence_protos) override;
 
+  // Returns the size of the batch.
+  int GetSize() const override { return data_.size(); }
+
   // Translates to a vector of stringified Sentence protos.
   const std::vector<string> GetSerializedData() const override;
 
@@ -49,4 +52,4 @@ class SentenceInputBatch : public InputBatch {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
+#endif  // DRAGNN_IO_SENTENCE_INPUT_BATCH_H_
diff --git a/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc b/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
index 0a3f6e69..516feecc 100644
--- a/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
+++ b/research/syntaxnet/dragnn/io/sentence_input_batch_test.cc
@@ -49,6 +49,9 @@ TEST(SentenceInputBatchTest, ConvertsFromStringifiedProtos) {
     EXPECT_NE(converted_data->at(i).workspace(), nullptr);
   }
 
+  // Check the batch size.
+  EXPECT_EQ(strings.size(), set.GetSize());
+
   // Get the data back out. The strings should be identical.
   auto output = set.GetSerializedData();
   EXPECT_EQ(output.size(), strings.size());
diff --git a/research/syntaxnet/dragnn/io/syntaxnet_sentence.h b/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
index d9076b44..aaf19b6d 100644
--- a/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
+++ b/research/syntaxnet/dragnn/io/syntaxnet_sentence.h
@@ -13,8 +13,8 @@
 // limitations under the License.
 // =============================================================================
 
-#ifndef NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
-#define NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#ifndef DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#define DRAGNN_IO_SYNTAXNET_SENTENCE_H_
 
 #include "syntaxnet/sentence.pb.h"
 #include "syntaxnet/workspace.h"
@@ -39,4 +39,4 @@ class SyntaxNetSentence {
 }  // namespace dragnn
 }  // namespace syntaxnet
 
-#endif  // NLP_SAFT_OPENSOURCE_DRAGNN_IO_SYNTAXNET_SENTENCE_H_
+#endif  // DRAGNN_IO_SYNTAXNET_SENTENCE_H_
diff --git a/research/syntaxnet/dragnn/protos/BUILD b/research/syntaxnet/dragnn/protos/BUILD
index 15592327..f4ae023a 100644
--- a/research/syntaxnet/dragnn/protos/BUILD
+++ b/research/syntaxnet/dragnn/protos/BUILD
@@ -26,6 +26,12 @@ tf_proto_library(
     srcs = ["spec.proto"],
 )
 
+tf_proto_library(
+    name = "runtime_proto",
+    srcs = ["runtime.proto"],
+    deps = [":spec_proto"],
+)
+
 tf_proto_library_py(
     name = "data_py_pb2",
     srcs = ["data.proto"],
diff --git a/research/syntaxnet/dragnn/protos/runtime.proto b/research/syntaxnet/dragnn/protos/runtime.proto
new file mode 100644
index 00000000..550a5d3c
--- /dev/null
+++ b/research/syntaxnet/dragnn/protos/runtime.proto
@@ -0,0 +1,81 @@
+syntax = "proto2";
+
+import "dragnn/protos/spec.proto";
+
+package syntaxnet.dragnn.runtime;
+
+// Performance tuning settings that only affect resource usage, not annotated
+// output or correctness.  This should be attached to the MasterSpec used to
+// initialize a Master.
+//
+// NEXT ID: 2
+message MasterPerformanceSettings {
+  extend MasterSpec {
+    optional MasterPerformanceSettings master_spec_extension = 160848628;
+  }
+
+  // Maximum size of the free list in the SessionStatePool.  NB: The default
+  // value may occasionally change.
+  optional uint64 session_state_pool_max_free_states = 1 [default = 4];
+}
+
+// As above, but for component-specific performance tuning settings.
+//
+// NEXT ID: 2
+message ComponentPerformanceSettings {
+  extend ComponentSpec {
+    optional ComponentPerformanceSettings component_spec_extension = 160999422;
+  }
+
+  // Number of steps to pre-allocate for the relevant component.  NB: The
+  // default value may occasionally change.
+  optional uint32 pre_allocate_num_steps = 1 [default = 50];
+}
+
+// Specification of an ArrayVariableStore.
+//
+// NEXT ID: 5
+message ArrayVariableStoreSpec {
+  // Characteristics of the variable data.  The binary that loads the variables
+  // must match these characteristics.
+  optional uint32 version = 1;  // required version of the byte array format
+  optional uint32 alignment_bytes = 2;  // required alignment of the byte array
+  optional bool is_little_endian = 3;  // required endian-ness of the byte array
+
+  // Variable specifications, in order of appearance in the byte array.
+  repeated VariableSpec variable = 4;
+}
+
+// Specification of a single serialized variable.
+//
+// NEXT ID: 6
+message VariableSpec {
+  // Formats for serialized pre-trained variables.  See VariableStore::Lookup()
+  // for descriptions of the enumerators.
+  enum Format {
+    FORMAT_UNKNOWN = 0;
+    FORMAT_FLAT = 1;
+    FORMAT_ROW_MAJOR_MATRIX = 2;
+    FORMAT_COLUMN_BLOCKED_ROW_MAJOR_MATRIX = 3;
+  }
+
+  // Name of the variable.
+  optional string name = 1;
+
+  // Format of the variable.
+  optional Format format = 2 [default = FORMAT_UNKNOWN];
+
+  // Dimensions of variables. The semantics depends on the format, but is always
+  // in logical units (number of floats, etc.) rather than bytes,
+  //
+  //  * flat: single value with the length of the vector
+  //  * row-major and column-major: two values, [rows, columns]
+  //  * row-blocked column-major: three values, [rows, columns, row_block_size]
+  repeated uint32 dimension = 5;
+
+  // Number of sub-views in the AlignedArea that contained the variable.
+  optional uint64 num_views = 3;
+
+  // Sub-view size in bytes for the AlignedArea that contained the variable.
+  optional uint64 view_size = 4;
+}
diff --git a/research/syntaxnet/dragnn/protos/spec.proto b/research/syntaxnet/dragnn/protos/spec.proto
index e4d4fd31..3e42ac1d 100644
--- a/research/syntaxnet/dragnn/protos/spec.proto
+++ b/research/syntaxnet/dragnn/protos/spec.proto
@@ -16,6 +16,7 @@ message MasterSpec {
   // Whether to extract debug traces.
   optional bool debug_tracing = 4 [default = false];
 
+  extensions 1000 to max;
   reserved 2, 3, 5;
 }
 
@@ -28,8 +29,7 @@ message ComponentSpec {
   // TransitionSystem to use.
   optional RegisteredModuleSpec transition_system = 2;
 
-  // Resources that this component depends on. These are copied to TaskInputs
-  // when calling SAFT code.
+  // Resources that this component depends on.
   repeated Resource resource = 3;
 
   // Feature space configurations.
@@ -58,6 +58,8 @@ message ComponentSpec {
 
   // Default max number of active states for beam inference.
   optional int32 inference_beam_size = 12 [default = 1];
+
+  extensions 1000 to max;
 }
 
 // Super generic container for any registered sub-piece of DRAGNN.
@@ -65,14 +67,11 @@ message RegisteredModuleSpec {
   // Name of the registered class.
   optional string registered_name = 1;
 
-  // Parameters to set while initializing this system; these are copied to
-  // Parameters in a TaskSpec when calling SAFT code, or via kwargs in TF Python
-  // code.
+  // Parameters to set while initializing this system.
   map<string, string> parameters = 2;
 }
 
-// Fixed resources that will be converted into TaskInput's when calling SAFT
-// code.
+// Fixed resource.
 message Resource {
   optional string name = 1;
   repeated Part part = 2;
@@ -218,6 +217,9 @@ message GridPoint {
   optional double gradient_clip_norm = 11 [default = 0.0];
 
   // A spec for using multiple optimization methods.
+  //
+  // This is not guaranteed to work for recursively-defined composite
+  // optimizers.
   message CompositeOptimizerSpec {
     // First optimizer.
     optional GridPoint method1 = 1;
@@ -227,6 +229,11 @@ message GridPoint {
 
     // After this number of steps, switch from first to second.
     optional int32 switch_after_steps = 3;
+
+    // Whether to reset the learning rate (which normally decays) after
+    // switching optimizers. Limitations: It will only reset to the initial
+    // learning rate, and won't work for recursively-defined optimizers.
+    optional bool reset_learning_rate = 4 [default = false];
   }
   optional CompositeOptimizerSpec composite_optimizer_spec = 12;
 
@@ -247,6 +254,7 @@ message GridPoint {
   // place. Typically a single component.
   optional string self_norm_components_filter = 21;
 
+  extensions 1000 to max;
   reserved 5, 6;
 }
 
diff --git a/research/syntaxnet/dragnn/python/BUILD b/research/syntaxnet/dragnn/python/BUILD
index 60ba4080..f1c528ab 100644
--- a/research/syntaxnet/dragnn/python/BUILD
+++ b/research/syntaxnet/dragnn/python/BUILD
@@ -16,6 +16,11 @@ cc_binary(
     ],
 )
 
+filegroup(
+    name = "testdata",
+    data = glob(["testdata/**"]),
+)
+
 py_library(
     name = "load_dragnn_cc_impl_py",
     srcs = ["load_dragnn_cc_impl.py"],
@@ -64,7 +69,51 @@ py_library(
 py_library(
     name = "dragnn_ops",
     srcs = ["dragnn_ops.py"],
-    deps = [],
+    deps = [
+        ":load_dragnn_cc_impl_py",
+        "//dragnn/core:dragnn_bulk_ops",
+        "//dragnn/core:dragnn_ops",
+        "//syntaxnet:load_parser_ops_py",
+    ],
+)
+
+py_library(
+    name = "dragnn_model_saver_lib",
+    srcs = ["dragnn_model_saver_lib.py"],
+    deps = [
+        ":dragnn_ops",
+        ":graph_builder",
+        ":load_dragnn_cc_impl_py",
+        ":network_units",
+        "//dragnn/protos:spec_py_pb2",
+        "//syntaxnet:load_parser_ops_py",
+        "//syntaxnet:sentence_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
+py_test(
+    name = "dragnn_model_saver_lib_test",
+    srcs = ["dragnn_model_saver_lib_test.py"],
+    data = [":testdata"],
+    deps = [
+        ":dragnn_model_saver_lib",
+        "//dragnn/protos:spec_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
+
+py_binary(
+    name = "dragnn_model_saver",
+    srcs = ["dragnn_model_saver.py"],
+    deps = [
+        ":dragnn_model_saver_lib",
+        ":spec_builder",
+        "//dragnn/protos:spec_py_pb2",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
 )
 
 py_library(
@@ -76,6 +125,7 @@ py_library(
         ":composite_optimizer",
         ":dragnn_ops",
         ":network_units",
+        ":transformer_units",
         ":wrapped_units",
         "//dragnn/protos:spec_py_pb2",
         "//syntaxnet/util:check",
@@ -184,10 +234,7 @@ py_test(
         ":bulk_component",
         ":components",
         ":dragnn_ops",
-        ":load_dragnn_cc_impl_py",
         ":network_units",
-        "//dragnn/core:dragnn_bulk_ops",
-        "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:sentence_py_pb2",
@@ -201,7 +248,6 @@ py_test(
     srcs = ["composite_optimizer_test.py"],
     deps = [
         ":composite_optimizer",
-        ":load_dragnn_cc_impl_py",
         "//dragnn/core:dragnn_bulk_ops",
         "//dragnn/core:dragnn_ops",
         "//syntaxnet:load_parser_ops_py",
@@ -217,15 +263,13 @@ py_test(
     data = [
         "//dragnn/core:testdata",
     ],
+    shard_count = 5,
     tags = [
         "notsan",
     ],
     deps = [
         ":dragnn_ops",
         ":graph_builder",
-        ":load_dragnn_cc_impl_py",
-        "//dragnn/core:dragnn_bulk_ops",
-        "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/protos:trace_py_pb2",
         "//syntaxnet:load_parser_ops_py",
@@ -240,7 +284,6 @@ py_test(
     size = "small",
     srcs = ["network_units_test.py"],
     deps = [
-        ":load_dragnn_cc_impl_py",
         ":network_units",
         "//dragnn/core:dragnn_bulk_ops",
         "//dragnn/core:dragnn_ops",
@@ -256,6 +299,7 @@ py_test(
     srcs = ["sentence_io_test.py"],
     data = ["//syntaxnet:testdata"],
     deps = [
+        ":dragnn_ops",
         ":sentence_io",
         "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
@@ -373,3 +417,30 @@ py_library(
         "@org_tensorflow//tensorflow:tensorflow_py",
     ],
 )
+
+py_library(
+    name = "transformer_units",
+    srcs = ["transformer_units.py"],
+    deps = [
+        ":network_units",
+        "//syntaxnet/util:check",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
+
+py_test(
+    name = "transformer_units_test",
+    size = "small",
+    srcs = ["transformer_units_test.py"],
+    deps = [
+        ":network_units",
+        ":transformer_units",
+        "//dragnn/core:dragnn_bulk_ops",
+        "//dragnn/core:dragnn_ops",
+        "//dragnn/protos:spec_py_pb2",
+        "//syntaxnet:load_parser_ops_py",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
diff --git a/research/syntaxnet/dragnn/python/biaffine_units.py b/research/syntaxnet/dragnn/python/biaffine_units.py
index c34a2ed6..7c70e157 100644
--- a/research/syntaxnet/dragnn/python/biaffine_units.py
+++ b/research/syntaxnet/dragnn/python/biaffine_units.py
@@ -95,7 +95,7 @@ class BiaffineDigraphNetwork(network_units.NetworkUnitInterface):
     self._regularized_weights.extend(self._weights)
 
     # Negative Layer.dim indicates that the dimension is dynamic.
-    self._layers.append(network_units.Layer(self, 'adjacency', -1))
+    self._layers.append(network_units.Layer(component, 'adjacency', -1))
 
   def create(self,
              fixed_embeddings,
@@ -209,7 +209,8 @@ class BiaffineLabelNetwork(network_units.NetworkUnitInterface):
     self._params.extend(self._weights + self._biases)
     self._regularized_weights.extend(self._weights)
 
-    self._layers.append(network_units.Layer(self, 'labels', self._num_labels))
+    self._layers.append(
+        network_units.Layer(component, 'labels', self._num_labels))
 
   def create(self,
              fixed_embeddings,
diff --git a/research/syntaxnet/dragnn/python/bulk_component.py b/research/syntaxnet/dragnn/python/bulk_component.py
index f00ac92f..86ebefd0 100644
--- a/research/syntaxnet/dragnn/python/bulk_component.py
+++ b/research/syntaxnet/dragnn/python/bulk_component.py
@@ -216,9 +216,11 @@ def build_cross_entropy_loss(logits, gold):
   logits = tf.gather(logits, valid)
   correct = tf.reduce_sum(tf.to_int32(tf.nn.in_top_k(logits, gold, 1)))
   total = tf.size(gold)
-  cost = tf.reduce_sum(
-      tf.contrib.nn.deprecated_flipped_sparse_softmax_cross_entropy_with_logits(
-          logits, tf.cast(gold, tf.int64))) / tf.cast(total, tf.float32)
+  with tf.control_dependencies([tf.assert_positive(total)]):
+    cost = tf.reduce_sum(
+        tf.nn.sparse_softmax_cross_entropy_with_logits(
+            labels=tf.cast(gold, tf.int64), logits=logits)) / tf.cast(
+                total, tf.float32)
   return cost, correct, total
 
 
@@ -267,6 +269,22 @@ class BulkFeatureExtractorComponentBuilder(component.ComponentBuilderBase):
     correct, total = tf.constant(0), tf.constant(0)
     return state.handle, cost, correct, total
 
+  def build_post_restore_hook(self):
+    """Builds a graph that should be executed after the restore op.
+
+    This graph is intended to be run once, before the inference pipeline is
+    run.
+
+    Returns:
+      setup_op - An op that, when run, guarantees all setup ops will run.
+    """
+    logging.info('Building restore hook for component: %s', self.spec.name)
+    with tf.variable_scope(self.name):
+      if callable(getattr(self.network, 'build_post_restore_hook', None)):
+        return [self.network.build_post_restore_hook()]
+      else:
+        return []
+
   def build_greedy_inference(self, state, network_states,
                              during_training=False):
     """Extracts features and advances a batch using the oracle path.
diff --git a/research/syntaxnet/dragnn/python/bulk_component_test.py b/research/syntaxnet/dragnn/python/bulk_component_test.py
index 5db5f056..99cb97e0 100644
--- a/research/syntaxnet/dragnn/python/bulk_component_test.py
+++ b/research/syntaxnet/dragnn/python/bulk_component_test.py
@@ -41,9 +41,6 @@ from dragnn.python import dragnn_ops
 from dragnn.python import network_units
 from syntaxnet import sentence_pb2
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
 
 
@@ -473,6 +470,17 @@ class BulkComponentTest(test_util.TensorFlowTestCase):
              [2], [-1], [-1], [-1],
              [2], [3], [-1], [-1]])
 
+  def testBuildLossFailsOnNoExamples(self):
+    with tf.Graph().as_default():
+      logits = tf.constant([[0.5], [-0.5], [0.5], [-0.5]])
+      gold = tf.constant([-1, -1, -1, -1])
+      result = bulk_component.build_cross_entropy_loss(logits, gold)
+
+      # Expect loss computation to generate a runtime error due to the gold
+      # tensor containing no valid examples.
+      with self.test_session() as sess:
+        with self.assertRaises(tf.errors.InvalidArgumentError):
+          sess.run(result)
 
 if __name__ == '__main__':
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/component.py b/research/syntaxnet/dragnn/python/component.py
index e38a216f..51dc89d9 100644
--- a/research/syntaxnet/dragnn/python/component.py
+++ b/research/syntaxnet/dragnn/python/component.py
@@ -46,9 +46,8 @@ class MasterState(object):
   """Simple utility to encapsulate tensors associated with the master state.
 
   Attributes:
-    handle: string tensor handle to the underlying nlp_saft::dragnn::MasterState
-    current_batch_size: int tensor containing the batch size following the most
-        recent MasterState::Reset().
+    handle: string tensor handle to the underlying ComputeSession.
+    current_batch_size: int tensor containing the current batch size.
   """
 
   def __init__(self, handle, current_batch_size):
@@ -390,7 +389,11 @@ class DynamicComponentBuilder(ComponentBuilderBase):
       correctly predicted actions, and the total number of actions.
     """
     logging.info('Building component: %s', self.spec.name)
-    with tf.control_dependencies([tf.assert_equal(self.training_beam_size, 1)]):
+    # Add 0 to training_beam_size to disable eager static evaluation.
+    # This is possible because tensorflow's constant_value does not
+    # propagate arithmetic operations.
+    with tf.control_dependencies([
+        tf.assert_equal(self.training_beam_size + 0, 1)]):
       stride = state.current_batch_size * self.training_beam_size
 
     cost = tf.constant(0.)
@@ -462,10 +465,10 @@ class DynamicComponentBuilder(ComponentBuilderBase):
 
     # Saves completed arrays and return final state and cost.
     state.handle = output[0]
+    cost = output[1]
     correct = output[2]
     total = output[3]
     arrays = output[4:]
-    cost = output[1]
 
     # Store handles to the final output for use in subsequent tasks.
     network_state = network_states[self.name]
@@ -475,6 +478,9 @@ class DynamicComponentBuilder(ComponentBuilderBase):
             array=arrays[index])
 
     # Normalize the objective by the total # of steps taken.
+    # Note: Total could be zero by a number of reasons, including:
+    #   * Oracle labels not being emitted.
+    #   * No steps being taken if component is terminal at the start of a batch.
     with tf.control_dependencies([tf.assert_greater(total, 0)]):
       cost /= tf.to_float(total)
 
@@ -524,11 +530,14 @@ class DynamicComponentBuilder(ComponentBuilderBase):
             during_training=during_training)
         next_arrays = update_tensor_arrays(network_tensors, arrays)
         with tf.control_dependencies([x.flow for x in next_arrays]):
-          logits = self.network.get_logits(network_tensors)
-          logits = tf.cond(self.locally_normalize,
-                           lambda: tf.nn.log_softmax(logits), lambda: logits)
-          handle = dragnn_ops.advance_from_prediction(
-              handle, logits, component=self.name)
+          if self.num_actions == 1:  # deterministic; take oracle transition
+            handle = dragnn_ops.advance_from_oracle(handle, component=self.name)
+          else:  # predict next transition using network logits
+            logits = self.network.get_logits(network_tensors)
+            logits = tf.cond(self.locally_normalize,
+                             lambda: tf.nn.log_softmax(logits), lambda: logits)
+            handle = dragnn_ops.advance_from_prediction(
+                handle, logits, component=self.name)
         return [handle] + next_arrays
 
     # Create the TensorArray's to store activations for downstream/recurrent
diff --git a/research/syntaxnet/dragnn/python/composite_optimizer.py b/research/syntaxnet/dragnn/python/composite_optimizer.py
index 71aff9b2..0ae69d6d 100644
--- a/research/syntaxnet/dragnn/python/composite_optimizer.py
+++ b/research/syntaxnet/dragnn/python/composite_optimizer.py
@@ -12,8 +12,9 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """An optimizer that switches between several methods."""
+import functools
+
 
 import tensorflow as tf
 from tensorflow.python.training import optimizer
@@ -28,7 +29,7 @@ class CompositeOptimizer(optimizer.Optimizer):
                optimizer2,
                switch,
                use_locking=False,
-               name='Composite'):
+               name="Composite"):
     """Construct a new Composite optimizer.
 
     Args:
@@ -47,24 +48,20 @@ class CompositeOptimizer(optimizer.Optimizer):
     self._switch = switch
 
   def apply_gradients(self, grads_and_vars, global_step=None, name=None):
-
-    return tf.cond(
-        self._switch,
-        lambda: self._optimizer1.apply_gradients(grads_and_vars,
-                                                 global_step, name),
-        lambda: self._optimizer2.apply_gradients(grads_and_vars,
-                                                 global_step, name)
-    )
-
+    return tf.cond(self._switch,
+                   functools.partial(self._optimizer1.apply_gradients,
+                                     grads_and_vars, global_step, name),
+                   functools.partial(self._optimizer2.apply_gradients,
+                                     grads_and_vars, global_step, name))
 
   def get_slot(self, var, name):
-    slot1 = self._optimizer1.get_slot(var, name)
-    slot2 = self._optimizer2.get_slot(var, name)
-    if slot1 and slot2:
-      raise LookupError('Slot named %s for variable %s populated for both '
-                        'optimizers' % (name, var.name))
-    return slot1 or slot2
+    if name.startswith("c1-"):
+      return self._optimizer1.get_slot(var, name[3:])
+    else:
+      return self._optimizer2.get_slot(var, name[3:])
 
   def get_slot_names(self):
-    return sorted(self._optimizer1.get_slot_names() +
-                  self._optimizer2.get_slot_names())
+    opt1_names = self._optimizer1.get_slot_names()
+    opt2_names = self._optimizer2.get_slot_names()
+    return sorted(["c1-{}".format(name) for name in opt1_names] +
+                  ["c2-{}".format(name) for name in opt2_names])
diff --git a/research/syntaxnet/dragnn/python/composite_optimizer_test.py b/research/syntaxnet/dragnn/python/composite_optimizer_test.py
index ea18982d..464c31f4 100644
--- a/research/syntaxnet/dragnn/python/composite_optimizer_test.py
+++ b/research/syntaxnet/dragnn/python/composite_optimizer_test.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Tests for CompositeOptimizer."""
 
 
@@ -99,8 +98,8 @@ class CompositeOptimizerTest(test_util.TensorFlowTestCase):
       optimizer1 = MockAdamOptimizer(0.05)
       optimizer2 = MockMomentumOptimizer(0.05, 0.5)
       switch = tf.less(step, 100)
-      optimizer = composite_optimizer.CompositeOptimizer(optimizer1, optimizer2,
-                                                         switch)
+      optimizer = composite_optimizer.CompositeOptimizer(
+          optimizer1, optimizer2, switch)
       train_op = optimizer.minimize(loss)
 
       sess.run(tf.global_variables_initializer())
@@ -111,16 +110,19 @@ class CompositeOptimizerTest(test_util.TensorFlowTestCase):
         sess.run(train_op)
         sess.run(tf.assign_add(step, 1))
         slot_names = optimizer.get_slot_names()
-        self.assertItemsEqual(
-            slot_names,
-            ["m", "v", "momentum", "adam_counter", "momentum_counter"])
-        adam_counter = sess.run(optimizer.get_slot(w, "adam_counter"))
-        momentum_counter = sess.run(optimizer.get_slot(w, "momentum_counter"))
+        adam_slots = ["c1-m", "c1-v", "c1-adam_counter"]
+        momentum_slots = ["c2-momentum", "c2-momentum_counter"]
+        self.assertItemsEqual(slot_names, adam_slots + momentum_slots)
+        adam_counter = sess.run(optimizer.get_slot(w, "c1-adam_counter"))
+        momentum_counter = sess.run(
+            optimizer.get_slot(w, "c2-momentum_counter"))
         self.assertEqual(adam_counter, min(iteration + 1, 100))
         self.assertEqual(momentum_counter, max(iteration - 99, 0))
         if iteration % 20 == 0:
-          logging.info("%d %s %d %d", iteration, sess.run([switch, step, w, b]),
-                       adam_counter, momentum_counter)
+          logging.info("%d %s %d %d", iteration,
+                       sess.run([switch, step, w, b]), adam_counter,
+                       momentum_counter)
+
 
 if __name__ == "__main__":
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver.py b/research/syntaxnet/dragnn/python/dragnn_model_saver.py
new file mode 100644
index 00000000..bb0170d8
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver.py
@@ -0,0 +1,85 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Converter for DRAGNN checkpoint+master-spec files to TF SavedModels.
+
+This script loads a DRAGNN model from a checkpoint and master-spec and saves it
+to a TF SavedModel checkpoint. The checkpoint and master-spec together must
+form a complete model - see the conll_checkpoint_converter.py for an example
+of how to convert CONLL checkpoints, since they are not complete.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib as saver_lib
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string('master_spec', None, 'Path to task context with '
+                    'inputs and parameters for feature extractors.')
+flags.DEFINE_string('params_path', None, 'Path to trained model parameters.')
+flags.DEFINE_string('export_path', '', 'Output path for exported servo model.')
+flags.DEFINE_bool('export_moving_averages', False,
+                  'Whether to export the moving average parameters.')
+
+
+def export(master_spec_path, params_path, export_path,
+           export_moving_averages):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the spec at master_spec_path and the
+  params in params_path. It then saves the model in SavedModel format to the
+  location specified in export_path.
+
+  Args:
+    master_spec_path: Path to a proto-text master spec.
+    params_path: Path to the parameters file to export.
+    export_path: Path to export the SavedModel to.
+    export_moving_averages: Whether to export the moving average parameters.
+  """
+
+  graph = tf.Graph()
+  master_spec = spec_pb2.MasterSpec()
+  with tf.gfile.FastGFile(master_spec_path) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  # Remove '/' if it exists at the end of the export path, ensuring that
+  # path utils work correctly.
+  stripped_path = export_path.rstrip('/')
+  saver_lib.clean_output_paths(stripped_path)
+
+  short_to_original = saver_lib.shorten_resource_paths(master_spec)
+  saver_lib.export_master_spec(master_spec, graph)
+  saver_lib.export_to_graph(master_spec, params_path, stripped_path, graph,
+                            export_moving_averages)
+  saver_lib.export_assets(master_spec, short_to_original, stripped_path)
+
+
+def main(unused_argv):
+  # Run the exporter.
+  export(FLAGS.master_spec, FLAGS.params_path,
+         FLAGS.export_path, FLAGS.export_moving_averages)
+  tf.logging.info('Export complete.')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py
new file mode 100644
index 00000000..a4c4a075
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib.py
@@ -0,0 +1,244 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""A program to export a DRAGNN model via SavedModel."""
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import tempfile
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import graph_builder
+
+# The saved model tags to export.  The same set of tags must be specified when
+# loading the saved model.
+_SAVED_MODEL_TAGS = [tf.saved_model.tag_constants.SERVING]
+
+
+def clean_output_paths(stripped_path):
+  """Ensures that the output path is cleaned and ready to receive a model."""
+  # If the export path's directory doesn't exist, create it.
+  export_directory = os.path.dirname(stripped_path)
+  if not tf.gfile.Exists(export_directory):
+    tf.logging.info('%s does not exist; creating it.' % export_directory)
+    tf.gfile.MakeDirs(export_directory)
+
+  # Remove any existing model on this export path, since exporting will fail
+  # if the model directory already exists.
+  if tf.gfile.Exists(stripped_path):
+    tf.logging.info('%s already exists; deleting it.' % stripped_path)
+    tf.gfile.DeleteRecursively(stripped_path)
+
+
+def shorten_resource_paths(master_spec):
+  """Shortens the resource file paths in a MasterSpec.
+
+  Replaces resource paths in the MasterSpec with shortened paths and builds a
+  mapping from the shortened path to the original path. Note that shortened
+  paths are relative to the 'assets.extra' directory of the SavedModel. Also
+  removes resources from FixedFeatureChannel, since they are not exported.
+
+  NB: The format of the shortened resource paths should be considered an
+  implementation detail and may change.
+
+  Args:
+    master_spec: MasterSpec proto to sanitize.
+
+  Returns:
+    Dict mapping from shortened resource path to original resource path.
+  """
+  for component_spec in master_spec.component:
+    for feature_spec in component_spec.fixed_feature:
+      feature_spec.ClearField('pretrained_embedding_matrix')
+      feature_spec.ClearField('vocab')
+
+  shortened_to_original = {}
+  original_to_shortened = {}
+  for component_index, component_spec in enumerate(master_spec.component):
+    component_name = 'component_{}_{}'.format(component_index,
+                                              component_spec.name)
+    for resource_index, resource_spec in enumerate(component_spec.resource):
+      resource_name = 'resource_{}_{}'.format(resource_index,
+                                              resource_spec.name)
+      for part_index, part in enumerate(resource_spec.part):
+        part_name = 'part_{}'.format(part_index)
+        shortened_path = os.path.join('resources', component_name,
+                                      resource_name, part_name)
+        if part.file_pattern not in original_to_shortened:
+          shortened_to_original[shortened_path] = part.file_pattern
+          original_to_shortened[part.file_pattern] = shortened_path
+
+        part.file_pattern = original_to_shortened[part.file_pattern]
+
+  return shortened_to_original
+
+
+def export_master_spec(master_spec, external_graph):
+  """Exports a MasterSpec.
+
+  Args:
+    master_spec: MasterSpec proto.
+    external_graph: tf.Graph that will be used to export the SavedModel.
+  """
+  # Implementation note: We can't export the original MasterSpec file directly
+  # because it uses short paths.  We also can't replace the original MasterSpec
+  # file with the new version, because the file may have other users.
+
+  # Write the new spec to a temp file and export it.  The basename will be
+  # exported in the SavedModel, so use mkdtemp() with a fixed basename.
+  master_spec_path = os.path.join(tempfile.mkdtemp(), 'master_spec')
+  with tf.gfile.FastGFile(master_spec_path, 'w') as fout:
+    fout.write(text_format.MessageToString(master_spec))
+  with external_graph.as_default():
+    asset_file_tensor = tf.constant(
+        master_spec_path, name='master_spec_filepath')
+    tf.add_to_collection(tf.GraphKeys.ASSET_FILEPATHS, asset_file_tensor)
+
+
+def export_assets(master_spec, shortened_to_original, saved_model_path):
+  """Exports the assets in a master_spec into a SavedModel directory.
+
+  This method exports a master_spec and associated files into the SavedModel's
+  'assets.extra' directory (which is unmanaged). All resources are added to the
+  'assets.extra' directory using sanitized paths. The master spec itself is
+  located at the base of the assets.extra directory.
+
+  NB: Only exports resource files in MasterSpec.component.resource, not the
+  embedding init resources in FixedFeatureChannel.
+
+  Args:
+    master_spec: Proto master spec.
+    shortened_to_original: Mapping returned by shorten_resource_paths().
+    saved_model_path: Path to an already-created SavedModel directory.
+  """
+  if not tf.gfile.Exists(saved_model_path):
+    tf.logging.fatal('Unable to export assets - directory %s does not exist!' %
+                     saved_model_path)
+  asset_dir = os.path.join(saved_model_path, 'assets.extra')
+  tf.logging.info('Exporting assets to model at %s' % asset_dir)
+
+  # First, write the MasterSpec that will be used to export the data.
+  tf.gfile.MakeDirs(asset_dir)
+  with tf.gfile.FastGFile(os.path.join(asset_dir, 'master_spec'),
+                          'w') as out_file:
+    out_file.write(text_format.MessageToString(master_spec))
+
+  # Then, copy all the asset files.
+  for component_spec in master_spec.component:
+    for resource_spec in component_spec.resource:
+      tf.logging.info('Copying assets for resource %s/%s.' %
+                      (component_spec.name, resource_spec.name))
+      for part in resource_spec.part:
+        original_file = shortened_to_original[part.file_pattern]
+        new_file = os.path.join(asset_dir, part.file_pattern)
+        tf.logging.info('Asset %s was renamed to %s.' % (original_file,
+                                                         new_file))
+        if tf.gfile.Exists(new_file):
+          tf.logging.info('%s already exists, skipping copy.' % (new_file))
+        else:
+          new_dir = os.path.dirname(new_file)
+          tf.gfile.MakeDirs(new_dir)
+          tf.logging.info('Copying %s to %s' % (original_file, new_dir))
+          tf.gfile.Copy(original_file, new_file, overwrite=True)
+  tf.logging.info('Asset export complete.')
+
+
+def export_to_graph(master_spec,
+                    params_path,
+                    export_path,
+                    external_graph,
+                    export_moving_averages,
+                    signature_name='model'):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the master_spec and the params in
+  params_path into the graph given in external_graph. It then saves the model
+  in SavedModel format to the location specified in export_path.
+
+  Args:
+    master_spec: Proto master spec.
+    params_path: Path to the parameters file to export.
+    export_path: Path to export the SavedModel to.
+    external_graph: A tf.Graph() object to build the graph inside.
+    export_moving_averages: Whether to export the moving average parameters.
+    signature_name: Name of the signature to insert.
+  """
+  tf.logging.info(
+      'Exporting graph with signature_name "%s" and use_moving_averages = %s' %
+      (signature_name, export_moving_averages))
+
+  tf.logging.info('Building the graph')
+  with external_graph.as_default(), tf.device('/device:CPU:0'):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.use_moving_average = export_moving_averages
+    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+    post_restore_hook = builder.build_post_restore_hook()
+    annotation = builder.add_annotation()
+    builder.add_saver()
+
+  # Resets session.
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=10,
+      inter_op_parallelism_threads=10)
+
+  with tf.Session(graph=external_graph, config=session_config) as session:
+    tf.logging.info('Initializing variables...')
+    session.run(tf.global_variables_initializer())
+
+    tf.logging.info('Loading params...')
+    session.run('save/restore_all', {'save/Const:0': params_path})
+
+    tf.logging.info('Saving.')
+
+    with tf.device('/device:CPU:0'):
+      saved_model_builder = tf.saved_model.builder.SavedModelBuilder(
+          export_path)
+
+      signature_map = {
+          signature_name:
+              tf.saved_model.signature_def_utils.build_signature_def(
+                  inputs={
+                      'inputs':
+                          tf.saved_model.utils.build_tensor_info(
+                              annotation['input_batch'])
+                  },
+                  outputs={
+                      'annotations':
+                          tf.saved_model.utils.build_tensor_info(
+                              annotation['annotations'])
+                  },
+                  method_name=tf.saved_model.signature_constants.
+                  PREDICT_METHOD_NAME),
+      }
+
+      tf.logging.info('Input is: %s', annotation['input_batch'].name)
+      tf.logging.info('Output is: %s', annotation['annotations'].name)
+
+      saved_model_builder.add_meta_graph_and_variables(
+          session,
+          tags=_SAVED_MODEL_TAGS,
+          legacy_init_op=tf.group(
+              post_restore_hook,
+              builder.build_warmup_graph(
+                  tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS)[0])),
+          signature_def_map=signature_map,
+          assets_collection=tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS))
+
+      saved_model_builder.save()
diff --git a/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py
new file mode 100644
index 00000000..be93846d
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/dragnn_model_saver_lib_test.py
@@ -0,0 +1,131 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Test for dragnn.python.dragnn_model_saver_lib."""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from tensorflow.python.framework import test_util
+from tensorflow.python.platform import googletest
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib
+
+FLAGS = tf.app.flags.FLAGS
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+class DragnnModelSaverLibTest(test_util.TensorFlowTestCase):
+
+  def LoadSpec(self, spec_path):
+    master_spec = spec_pb2.MasterSpec()
+    root_dir = os.path.join(FLAGS.test_srcdir,
+                            'dragnn/python')
+    with file(os.path.join(root_dir, 'testdata', spec_path), 'r') as fin:
+      text_format.Parse(fin.read().replace('TOPDIR', root_dir), master_spec)
+      return master_spec
+
+  def CreateLocalSpec(self, spec_path):
+    master_spec = self.LoadSpec(spec_path)
+    master_spec_name = os.path.basename(spec_path)
+    outfile = os.path.join(FLAGS.test_tmpdir, master_spec_name)
+    fout = open(outfile, 'w')
+    fout.write(text_format.MessageToString(master_spec))
+    return outfile
+
+  def ValidateAssetExistence(self, master_spec, export_path):
+    asset_path = os.path.join(export_path, 'assets.extra')
+
+    # The master spec should exist.
+    expected_path = os.path.join(asset_path, 'master_spec')
+    tf.logging.info('Validating existence of %s' % expected_path)
+    self.assertTrue(os.path.isfile(expected_path))
+
+    # For every part in every resource in every component, the resource should
+    # exist at [export_path]/assets.extra/[component file path]
+    path_list = []
+    for component_spec in master_spec.component:
+      for resource_spec in component_spec.resource:
+        for part in resource_spec.part:
+          expected_path = os.path.join(asset_path,
+                                       part.file_pattern.strip(os.path.sep))
+          tf.logging.info('Validating existence of %s' % expected_path)
+          self.assertTrue(os.path.isfile(expected_path))
+          path_list.append(expected_path)
+
+    # Return a set of all unique paths.
+    return set(path_list)
+
+  def testModelExport(self):
+    # Get the master spec and params for this graph.
+    master_spec = self.LoadSpec('ud-hungarian.master-spec')
+    params_path = os.path.join(
+        FLAGS.test_srcdir, 'dragnn/python/testdata'
+        '/ud-hungarian.params')
+
+    # Export the graph via SavedModel. (Here, we maintain a handle to the graph
+    # for comparison, but that's usually not necessary.)
+    export_path = os.path.join(FLAGS.test_tmpdir, 'export')
+    saver_graph = tf.Graph()
+
+    shortened_to_original = dragnn_model_saver_lib.shorten_resource_paths(
+        master_spec)
+
+    dragnn_model_saver_lib.export_master_spec(master_spec, saver_graph)
+
+    dragnn_model_saver_lib.export_to_graph(
+        master_spec,
+        params_path,
+        export_path,
+        saver_graph,
+        export_moving_averages=False)
+
+    # Export the assets as well.
+    dragnn_model_saver_lib.export_assets(master_spec, shortened_to_original,
+                                         export_path)
+
+    # Validate that the assets are all in the exported directory.
+    path_set = self.ValidateAssetExistence(master_spec, export_path)
+
+    # This master-spec has 4 unique assets. If there are more, we have not
+    # uniquified the assets properly.
+    self.assertEqual(len(path_set), 4)
+
+    # Restore the graph from the checkpoint into a new Graph object.
+    restored_graph = tf.Graph()
+    restoration_config = tf.ConfigProto(
+        log_device_placement=False,
+        intra_op_parallelism_threads=10,
+        inter_op_parallelism_threads=10)
+
+    with tf.Session(graph=restored_graph, config=restoration_config) as sess:
+      tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                                 export_path)
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/dragnn/python/dragnn_ops.py b/research/syntaxnet/dragnn/python/dragnn_ops.py
index 8a640107..299e9ba8 100644
--- a/research/syntaxnet/dragnn/python/dragnn_ops.py
+++ b/research/syntaxnet/dragnn/python/dragnn_ops.py
@@ -16,9 +16,9 @@
 """Groups the DRAGNN TensorFlow ops in one module."""
 
 
-try:
-  from dragnn.core.ops.gen_dragnn_bulk_ops import *
-  from dragnn.core.ops.gen_dragnn_ops import *
-except ImportError as e:
-    raise e
+from dragnn.core.ops.gen_dragnn_bulk_ops import *
+from dragnn.core.ops.gen_dragnn_ops import *
 
+
+import dragnn.python.load_dragnn_cc_impl
+import syntaxnet.load_parser_ops
diff --git a/research/syntaxnet/dragnn/python/graph_builder.py b/research/syntaxnet/dragnn/python/graph_builder.py
index 014fd4a9..fe68ff12 100644
--- a/research/syntaxnet/dragnn/python/graph_builder.py
+++ b/research/syntaxnet/dragnn/python/graph_builder.py
@@ -12,11 +12,11 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Builds a DRAGNN graph for local training."""
 
-
+import collections
 import tensorflow as tf
+
 from tensorflow.core.protobuf import saver_pb2
 from tensorflow.python.platform import tf_logging as logging
 
@@ -32,6 +32,37 @@ except KeyError, e:
   logging.info(str(e))
 
 
+def _validate_grid_point(hyperparams, is_sub_optimizer=False):
+  """Validates that a grid point's configuration is reasonable.
+
+  Args:
+    hyperparams (spec_pb2.GridPoint): Grid point to validate.
+    is_sub_optimizer (bool): Whether this optimizer is a sub-optimizer of
+      a composite optimizer.
+
+  Raises:
+    ValueError: If the grid point is not valid.
+  """
+  valid_methods = ('gradient_descent', 'adam', 'lazyadam', 'momentum',
+                   'composite')
+  if hyperparams.learning_method not in valid_methods:
+    raise ValueError('Unknown learning method (optimizer)')
+
+  if is_sub_optimizer:
+    for base_only_field in ('decay_steps', 'decay_base', 'decay_staircase'):
+      if hyperparams.HasField(base_only_field):
+        raise ValueError('Field {} is not valid for sub-optimizers of a '
+                         'composite optimizer.'.format(base_only_field))
+
+  if hyperparams.learning_method == 'composite':
+    spec = hyperparams.composite_optimizer_spec
+    if spec.switch_after_steps < 1:
+      raise ValueError('switch_after_steps {} not valid for composite '
+                       'optimizer!'.format(spec.switch_after_steps))
+    for sub_optimizer in (spec.method1, spec.method2):
+      _validate_grid_point(sub_optimizer, is_sub_optimizer=True)
+
+
 def _create_learning_rate(hyperparams, step_var):
   """Creates learning rate var, with decay and switching for CompositeOptimizer.
 
@@ -40,21 +71,31 @@ def _create_learning_rate(hyperparams, step_var):
       learning_method to determine optimizer class to use.
     step_var: tf.Variable, global training step.
 
+  Raises:
+    ValueError: If the composite optimizer is set, but not correctly configured.
+
   Returns:
     a scalar `Tensor`, the learning rate based on current step and hyperparams.
   """
   if hyperparams.learning_method != 'composite':
     base_rate = hyperparams.learning_rate
+    adjusted_steps = step_var
   else:
     spec = hyperparams.composite_optimizer_spec
     switch = tf.less(step_var, spec.switch_after_steps)
     base_rate = tf.cond(switch, lambda: tf.constant(spec.method1.learning_rate),
                         lambda: tf.constant(spec.method2.learning_rate))
+    if spec.reset_learning_rate:
+      adjusted_steps = tf.cond(switch, lambda: step_var,
+                               lambda: step_var - spec.switch_after_steps)
+    else:
+      adjusted_steps = step_var
+
   return tf.train.exponential_decay(
-      base_rate,
-      step_var,
-      hyperparams.decay_steps,
-      hyperparams.decay_base,
+      learning_rate=base_rate,
+      global_step=adjusted_steps,
+      decay_steps=hyperparams.decay_steps,
+      decay_rate=hyperparams.decay_base,
       staircase=hyperparams.decay_staircase)
 
 
@@ -158,6 +199,7 @@ class MasterBuilder(object):
     self.spec = master_spec
     self.hyperparams = (spec_pb2.GridPoint()
                         if hyperparam_config is None else hyperparam_config)
+    _validate_grid_point(self.hyperparams)
     self.pool_scope = pool_scope
 
     # Set the graph-level random seed before creating the Components so the ops
@@ -260,6 +302,25 @@ class MasterBuilder(object):
     all_nodes['run'] = run_op
     return all_nodes
 
+  def build_warmup_graph(self, asset_dir):
+    """Builds a warmup graph.
+
+    This graph performs a MasterSpec asset location rewrite via
+    SetAssetDirectory, then grabs a ComputeSession and immediately returns it.
+    By grabbing a session, we cause the underlying transition systems to cache
+    their static data reads.
+
+    Args:
+      asset_dir: The base directory to append to all resources.
+
+    Returns:
+      A single op suitable for passing to the legacy_init_op of the ModelSaver.
+    """
+    with tf.control_dependencies([dragnn_ops.set_asset_directory(asset_dir)]):
+      session = self._get_compute_session()
+      release_op = dragnn_ops.release_session(session)
+    return tf.group(release_op, name='run')
+
   def build_training(self,
                      handle,
                      compute_gradients=True,
@@ -408,6 +469,8 @@ class MasterBuilder(object):
     # Restore that subsequent builds don't use average by default.
     self.read_from_avg = False
 
+    cost = tf.check_numerics(cost, message='Cost is not finite.')
+
     # Returns named access to common outputs.
     outputs = {
         'cost': cost,
@@ -447,8 +510,14 @@ class MasterBuilder(object):
     Returns:
       setup_op - An op that, when run, guarantees all setup ops will run.
     """
-    with tf.control_dependencies(
-        [comp.build_post_restore_hook() for comp in self.components]):
+    control_ops = []
+    for comp in self.components:
+      hook = comp.build_post_restore_hook()
+      if isinstance(hook, collections.Iterable):
+        control_ops.extend(hook)
+      else:
+        control_ops.append(hook)
+    with tf.control_dependencies(control_ops):
       return tf.no_op(name='post_restore_hook_master')
 
   def build_inference(self, handle, use_moving_average=False):
@@ -597,10 +666,8 @@ class MasterBuilder(object):
 
   def add_saver(self):
     """Adds a Saver for all variables in the graph."""
-    logging.info('Saving non-quantized variables:\n\t%s', '\n\t'.join(
-        [x.name for x in tf.global_variables() if 'quantized' not in x.name]))
+    logging.info('Saving variables:\n\t%s',
+                 '\n\t'.join([x.name for x in tf.global_variables()]))
     self.saver = tf.train.Saver(
-        var_list=[
-            x for x in tf.global_variables() if 'quantized' not in x.name
-        ],
+        var_list=[x for x in tf.global_variables()],
         write_version=saver_pb2.SaverDef.V1)
diff --git a/research/syntaxnet/dragnn/python/graph_builder_test.py b/research/syntaxnet/dragnn/python/graph_builder_test.py
index 3ca81599..b1f712ea 100644
--- a/research/syntaxnet/dragnn/python/graph_builder_test.py
+++ b/research/syntaxnet/dragnn/python/graph_builder_test.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Tests for graph_builder."""
 
 
@@ -35,14 +34,8 @@ from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 from tensorflow.python.platform import tf_logging as logging
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
 
 _DUMMY_GOLD_SENTENCE = """
 token {
@@ -157,6 +150,13 @@ token {
 ]
 
 
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
 def _as_op(x):
   """Always returns the tf.Operation associated with a node."""
   return x.op if isinstance(x, tf.Tensor) else x
@@ -264,7 +264,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     gold_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_GOLD_SENTENCE_2, gold_doc_2)
     reader_strings = [
-        gold_doc.SerializeToString(), gold_doc_2.SerializeToString()
+        gold_doc.SerializeToString(),
+        gold_doc_2.SerializeToString()
     ]
     tf.logging.info('Generating graph with config: %s', hyperparam_config)
     with tf.Graph().as_default():
@@ -294,18 +295,35 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     self.RunTraining(
         self.MakeHyperparams(learning_method='adam', use_moving_average=True))
 
+  def testTrainingWithLazyAdamAndNoAveraging(self):
+    """Adds code coverage for lazy ADAM without the use of moving averaging."""
+    self.RunTraining(
+        self.MakeHyperparams(
+            learning_method='lazyadam', use_moving_average=False))
+
   def testTrainingWithCompositeOptimizer(self):
     """Adds code coverage for CompositeOptimizer."""
+    self.RunCompositeOptimizerTraining(False)
+
+  def testTrainingWithCompositeOptimizerResetLearningRate(self):
+    """Adds code coverage for CompositeOptimizer."""
+    self.RunCompositeOptimizerTraining(True)
+
+  def RunCompositeOptimizerTraining(self, reset_learning_rate):
     grid_point = self.MakeHyperparams(learning_method='composite')
-    grid_point.composite_optimizer_spec.method1.learning_method = 'adam'
-    grid_point.composite_optimizer_spec.method2.learning_method = 'momentum'
-    grid_point.composite_optimizer_spec.method2.momentum = 0.9
+    spec = grid_point.composite_optimizer_spec
+    spec.reset_learning_rate = reset_learning_rate
+    spec.switch_after_steps = 1
+    spec.method1.learning_method = 'adam'
+    spec.method2.learning_method = 'momentum'
+    spec.method2.momentum = 0.9
     self.RunTraining(grid_point)
 
   def RunFullTrainingAndInference(self,
                                   test_name,
                                   master_spec_path=None,
                                   master_spec=None,
+                                  hyperparam_config=None,
                                   component_weights=None,
                                   unroll_using_oracle=None,
                                   num_evaluated_components=1,
@@ -320,7 +338,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     gold_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_GOLD_SENTENCE_2, gold_doc_2)
     gold_reader_strings = [
-        gold_doc.SerializeToString(), gold_doc_2.SerializeToString()
+        gold_doc.SerializeToString(),
+        gold_doc_2.SerializeToString()
     ]
 
     test_doc = sentence_pb2.Sentence()
@@ -328,8 +347,10 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
     test_doc_2 = sentence_pb2.Sentence()
     text_format.Parse(_DUMMY_TEST_SENTENCE_2, test_doc_2)
     test_reader_strings = [
-        test_doc.SerializeToString(), test_doc.SerializeToString(),
-        test_doc_2.SerializeToString(), test_doc.SerializeToString()
+        test_doc.SerializeToString(),
+        test_doc.SerializeToString(),
+        test_doc_2.SerializeToString(),
+        test_doc.SerializeToString()
     ]
 
     if batch_size_limit is not None:
@@ -338,7 +359,8 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
 
     with tf.Graph().as_default():
       tf.set_random_seed(1)
-      hyperparam_config = spec_pb2.GridPoint()
+      if not hyperparam_config:
+        hyperparam_config = spec_pb2.GridPoint()
       builder = graph_builder.MasterBuilder(
           master_spec, hyperparam_config, pool_scope=test_name)
       target = spec_pb2.TrainTarget()
@@ -493,6 +515,22 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
         expected_num_actions=12,
         expected=_TAGGER_PARSER_EXPECTED_SENTENCES)
 
+  def testTaggerParserNanDeath(self):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.learning_rate = 1.0
+
+    # The large learning rate should trigger check_numerics.
+    with self.assertRaisesRegexp(tf.errors.InvalidArgumentError,
+                                 'Cost is not finite'):
+      self.RunFullTrainingAndInference(
+          'tagger-parser',
+          'tagger_parser_master_spec.textproto',
+          hyperparam_config=hyperparam_config,
+          component_weights=[0., 1., 1.],
+          unroll_using_oracle=[False, True, True],
+          expected_num_actions=12,
+          expected=_TAGGER_PARSER_EXPECTED_SENTENCES)
+
   def testTaggerParserWithAttention(self):
     spec = self.LoadSpec('tagger_parser_master_spec.textproto')
 
@@ -621,6 +659,18 @@ class GraphBuilderTest(test_util.TensorFlowTestCase):
       self.checkOpOrder('annotations', anno['annotations'],
                         ['GetSession', 'ReleaseSession'])
 
+  def testWarmupGetsAndReleasesSession(self):
+    """Checks that create_warmup_graph creates Get and ReleaseSession."""
+    test_name = 'warmup-graph-structure'
+
+    with tf.Graph().as_default():
+      # Build the actual graphs. The choice of spec is arbitrary, as long as
+      # training and annotation nodes can be constructed.
+      builder, _ = self.getBuilderAndTarget(test_name)
+      warmup = builder.build_warmup_graph('foo')
+      self.checkOpOrder('annotations', warmup,
+                        ['SetAssetDirectory', 'GetSession', 'ReleaseSession'])
+
   def testAttachDataReader(self):
     """Checks that train['run'] and 'annotations' call AttachDataReader."""
     test_name = 'attach-data-reader'
diff --git a/research/syntaxnet/dragnn/python/lexicon.py b/research/syntaxnet/dragnn/python/lexicon.py
index b56ca0e8..bdd61f1c 100644
--- a/research/syntaxnet/dragnn/python/lexicon.py
+++ b/research/syntaxnet/dragnn/python/lexicon.py
@@ -28,7 +28,8 @@ def create_lexicon_context(path):
   context = task_spec_pb2.TaskSpec()
   for name in [
       'word-map', 'tag-map', 'tag-to-category', 'lcword-map', 'category-map',
-      'char-map', 'char-ngram-map', 'label-map', 'prefix-table', 'suffix-table'
+      'char-map', 'char-ngram-map', 'label-map', 'prefix-table', 'suffix-table',
+      'known-word-map'
   ]:
     context.input.add(name=name).part.add(file_pattern=os.path.join(path, name))
   return context
diff --git a/research/syntaxnet/dragnn/python/lexicon_test.py b/research/syntaxnet/dragnn/python/lexicon_test.py
index d23442bc..340d9250 100644
--- a/research/syntaxnet/dragnn/python/lexicon_test.py
+++ b/research/syntaxnet/dragnn/python/lexicon_test.py
@@ -28,13 +28,7 @@ from dragnn.python import lexicon
 from syntaxnet import parser_trainer
 from syntaxnet import task_spec_pb2
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 _EXPECTED_CONTEXT = r"""
@@ -48,9 +42,17 @@ input { name: "char-ngram-map" Part { file_pattern: "/tmp/char-ngram-map" } }
 input { name: "label-map" Part { file_pattern: "/tmp/label-map" } }
 input { name: "prefix-table" Part { file_pattern: "/tmp/prefix-table" } }
 input { name: "suffix-table" Part { file_pattern: "/tmp/suffix-table" } }
+input { name: "known-word-map" Part { file_pattern: "/tmp/known-word-map" } }
 """
 
 
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
 class LexiconTest(tf.test.TestCase):
 
   def testCreateLexiconContext(self):
diff --git a/research/syntaxnet/dragnn/python/network_units.py b/research/syntaxnet/dragnn/python/network_units.py
index a42c5dc3..ebf4241d 100644
--- a/research/syntaxnet/dragnn/python/network_units.py
+++ b/research/syntaxnet/dragnn/python/network_units.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Basic network units used in assembling DRAGNN graphs."""
 
 from __future__ import absolute_import
@@ -21,6 +20,8 @@ from __future__ import print_function
 
 import abc
 
+
+import numpy as np
 import tensorflow as tf
 from tensorflow.python.ops import nn
 from tensorflow.python.ops import tensor_array_ops as ta
@@ -141,17 +142,22 @@ def add_embeddings(channel_id, feature_spec, seed=None):
     embeddings = syntaxnet_ops.word_embedding_initializer(
         vectors=feature_spec.pretrained_embedding_matrix.part[0].file_pattern,
         vocabulary=feature_spec.vocab.part[0].file_pattern,
+
         num_special_embeddings=1,
         embedding_init=1.0,
         seed=seed1,
         seed2=seed2)
-    return tf.get_variable(name, initializer=tf.reshape(embeddings, shape))
+    return tf.get_variable(
+        name,
+        initializer=tf.reshape(embeddings, shape),
+        trainable=not feature_spec.is_constant)
   else:
     return tf.get_variable(
         name,
         shape,
         initializer=tf.random_normal_initializer(
-            stddev=1.0 / feature_spec.embedding_dim**.5, seed=seed))
+            stddev=1.0 / feature_spec.embedding_dim**.5, seed=seed),
+        trainable=not feature_spec.is_constant)
 
 
 def embedding_lookup(embedding_matrix, indices, ids, weights, size):
@@ -183,7 +189,7 @@ def fixed_feature_lookup(component, state, channel_id, stride):
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     stride: int Tensor of current batch * beam size.
 
@@ -228,6 +234,100 @@ def get_input_tensor(fixed_embeddings, linked_embeddings):
   return tf.concat([e.tensor for e in embeddings], 1)
 
 
+def add_var_initialized(name, shape, init_type, divisor=1.0, stddev=1e-4):
+  """Creates a tf.Variable with the given shape and initialization.
+
+  Args:
+    name: variable name
+    shape: variable shape
+    init_type: type of initialization (random, xavier, identity, varscale)
+    divisor: numerator for identity initialization where in_dim != out_dim,
+      should divide both in_dim and out_dim
+    stddev: standard deviation for random normal initialization
+
+  Returns:
+    tf.Variable object with the given shape and initialization
+
+  Raises:
+    ValueError: if identity initialization is specified for a tensor of rank < 4
+    NotImplementedError: if an unimplemented type of initialization is specified
+  """
+  if init_type == 'random':
+    # Random normal initialization
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.random_normal_initializer(stddev=stddev),
+        dtype=tf.float32)
+  if init_type == 'xavier':
+    # Xavier normal initialization (Glorot and Bengio, 2010):
+    # http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.contrib.layers.xavier_initializer(),
+        dtype=tf.float32)
+  if init_type == 'varscale':
+    # Variance scaling initialization (He at al. 2015):
+    # https://arxiv.org/abs/1502.01852
+    return tf.get_variable(
+        name,
+        shape=shape,
+        initializer=tf.contrib.layers.variance_scaling_initializer(),
+        dtype=tf.float32)
+  if init_type == 'identity':
+    # "Identity initialization" described in Yu and Koltun (2015):
+    # https://arxiv.org/abs/1511.07122v3 eqns. (4) and (5)
+    rank = len(shape)
+    square = shape[-1] == shape[-2]
+    if rank < 2:
+      raise ValueError(
+          'Identity initialization requires a tensor with rank >= 2. The given '
+          'shape has rank ' + str(rank))
+
+    if shape[-1] % divisor != 0 or shape[-2] % divisor != 0:
+      raise ValueError('Divisor must divide both shape[-1]=' + str(shape[-1]) +
+                       ' and shape[-2]=' + str(shape[-2]) + '. Divisor is: ' +
+                       str(divisor))
+
+    # If the desired shape is > 2 dimensions, we only want to set the values
+    # in the middle along the last two dims.
+    middle_indices = [int(s / 2) for s in shape]
+    middle_indices = middle_indices[:-2]
+
+    base_array = NotImplemented
+    if square:
+      if rank == 2:
+        base_array = np.eye(shape[-1])
+      else:
+        base_array = np.zeros(shape, dtype=np.float32)
+        base_array[[[i] for i in middle_indices]] = np.eye(shape[-1])
+    else:
+      # NOTE(strubell): We use NumPy's RNG here and not TensorFlow's because
+      # constructing this matrix with tf ops is tedious and harder to read.
+      base_array = np.random.normal(
+          size=shape, loc=0, scale=stddev).astype(np.float32)
+      m = divisor / shape[-1]
+
+      identity = np.eye(int(divisor))
+      x_stretch = int(shape[-1] / divisor)
+      y_stretch = int(shape[-2] / divisor)
+      x_stretched_ident = np.repeat(identity, x_stretch, 1)
+      xy_stretched_ident = np.repeat(x_stretched_ident, y_stretch, 0)
+      indices = np.where(xy_stretched_ident == 1.0)
+
+      if rank == 2:
+        base_array[indices[0], indices[1]] = m
+      else:
+        arr = base_array[[[i] for i in middle_indices]][0]
+        arr[indices[0], indices[1]] = m
+        base_array[[[i] for i in middle_indices]] = arr
+    return tf.get_variable(name, initializer=base_array)
+
+  raise NotImplementedError('Initialization type ' + init_type +
+                            ' is not implemented.')
+
+
 def get_input_tensor_with_stride(fixed_embeddings, linked_embeddings, stride):
   """Constructs an input tensor with a separate dimension for steps.
 
@@ -304,8 +404,8 @@ def lookup_named_tensor(name, named_tensors):
   for named_tensor in named_tensors:
     if named_tensor.name == name:
       return named_tensor
-  raise KeyError('Name "%s" not found in named tensors: %s' %
-                 (name, named_tensors))
+  raise KeyError('Name "%s" not found in named tensors: %s' % (name,
+                                                               named_tensors))
 
 
 def activation_lookup_recurrent(component, state, channel_id, source_array,
@@ -317,7 +417,7 @@ def activation_lookup_recurrent(component, state, channel_id, source_array,
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     source_array: TensorArray from which to fetch feature vectors, expected to
         have size [steps + 1] elements of shape [stride, D] each.
@@ -381,7 +481,7 @@ def activation_lookup_other(component, state, channel_id, source_tensor,
 
   Args:
     component: Component object in which to look up the fixed features.
-    state: MasterState object for the live nlp_saft::dragnn::MasterState.
+    state: MasterState object for the live ComputeSession.
     channel_id: int id of the fixed feature to look up.
     source_tensor: Tensor from which to fetch feature vectors. Expected to have
         have shape [steps + 1, stride, D].
@@ -494,8 +594,8 @@ class LayerNorm(object):
 
       # Compute layer normalization using the batch_normalization function.
       variance_epsilon = 1E-12
-      outputs = nn.batch_normalization(
-          inputs, mean, variance, beta, gamma, variance_epsilon)
+      outputs = nn.batch_normalization(inputs, mean, variance, beta, gamma,
+                                       variance_epsilon)
       outputs.set_shape(inputs_shape)
       return outputs
 
@@ -529,12 +629,13 @@ class Layer(object):
       TensorArray object
     """
     check.Gt(self.dim, 0, 'Cannot create array when dimension is dynamic')
-    tensor_array = ta.TensorArray(dtype=tf.float32,
-                                  size=0,
-                                  dynamic_size=True,
-                                  clear_after_read=False,
-                                  infer_shape=False,
-                                  name='%s_array' % self.name)
+    tensor_array = ta.TensorArray(
+        dtype=tf.float32,
+        size=0,
+        dynamic_size=True,
+        clear_after_read=False,
+        infer_shape=False,
+        name='%s_array' % self.name)
 
     # Start each array with all zeros. Special values will still be learned via
     # the extra embedding dimension stored for each linked feature channel.
@@ -588,9 +689,6 @@ def maybe_apply_dropout(inputs, keep_prob, per_sequence, stride=None):
     shape of |inputs|, containing the masked or original inputs, depending on
     whether dropout was actually performed.
   """
-  check.Ge(inputs.get_shape().ndims, 2, 'inputs must be rank 2 or 3')
-  check.Le(inputs.get_shape().ndims, 3, 'inputs must be rank 2 or 3')
-  flat = (inputs.get_shape().ndims == 2)
 
   if keep_prob >= 1.0:
     return inputs
@@ -598,6 +696,11 @@ def maybe_apply_dropout(inputs, keep_prob, per_sequence, stride=None):
   if not per_sequence:
     return tf.nn.dropout(inputs, keep_prob)
 
+  # We only check the dims if we are applying per-sequence dropout
+  check.Ge(inputs.get_shape().ndims, 2, 'inputs must be rank 2 or 3')
+  check.Le(inputs.get_shape().ndims, 3, 'inputs must be rank 2 or 3')
+  flat = (inputs.get_shape().ndims == 2)
+
   check.NotNone(stride, 'per-sequence dropout requires stride')
   dim = inputs.get_shape().as_list()[-1]
   check.NotNone(dim, 'inputs must have static activation dimension, but have '
@@ -629,7 +732,7 @@ class NetworkUnitInterface(object):
     layers (list): List of Layer objects to track network layers that should
       be written to Tensors during training and inference.
   """
-  __metaclass__ = abc.ABCMeta  # required for @abstractmethod
+  __metaclass__ = abc.ABCMeta  # required for @abc.abstractmethod
 
   def __init__(self, component, init_layers=None, init_context_layers=None):
     """Initializes parameters for embedding matrices.
@@ -692,8 +795,8 @@ class NetworkUnitInterface(object):
 
     # Compute the cumulative dimension of all inputs.  If any input has dynamic
     # dimension, then the result is -1.
-    input_dims = (self._fixed_feature_dims.values() +
-                  self._linked_feature_dims.values())
+    input_dims = (
+        self._fixed_feature_dims.values() + self._linked_feature_dims.values())
     if any(x < 0 for x in input_dims):
       self._concatenated_input_dim = -1
     else:
@@ -844,8 +947,7 @@ class NetworkUnitInterface(object):
         tf.reduce_sum(
             tf.multiply(
                 h_tensor, tf.reshape(p_vec, [-1, 1]), name='time_together2'),
-            0),
-        0)
+            0), 0)
     return tf.matmul(
         r_vec,
         self._component.get_variable('attention_weights_pu'),
@@ -908,6 +1010,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
     Parameters used to construct the network:
       hidden_layer_sizes: comma-separated list of ints, indicating the
         number of hidden units in each hidden layer.
+      omit_logits (False): Whether to elide the logits layer.
       layer_norm_input (False): Whether or not to apply layer normalization
         on the concatenated input to the network.
       layer_norm_hidden (False): Whether or not to apply layer normalization
@@ -928,21 +1031,24 @@ class FeedForwardNetwork(NetworkUnitInterface):
           when the |dropout_keep_prob| parameter is negative.
     """
     self._attrs = get_attrs_with_defaults(
-        component.spec.network_unit.parameters, defaults={
+        component.spec.network_unit.parameters,
+        defaults={
             'hidden_layer_sizes': '',
+            'omit_logits': False,
             'layer_norm_input': False,
             'layer_norm_hidden': False,
             'nonlinearity': 'relu',
             'dropout_keep_prob': -1.0,
             'dropout_per_sequence': False,
-            'dropout_all_layers': False})
+            'dropout_all_layers': False
+        })
 
     # Initialize the hidden layer sizes before running the base initializer, as
-    # the base initializer may need to know the size of of the hidden layer for
+    # the base initializer may need to know the size of the hidden layer for
     # recurrent connections.
-    self._hidden_layer_sizes = (
-        map(int, self._attrs['hidden_layer_sizes'].split(','))
-        if self._attrs['hidden_layer_sizes'] else [])
+    self._hidden_layer_sizes = (map(
+        int, self._attrs['hidden_layer_sizes'].split(','))
+                                if self._attrs['hidden_layer_sizes'] else [])
     super(FeedForwardNetwork, self).__init__(component)
 
     # Infer dropout rate from network parameters and grid hyperparameters.
@@ -960,9 +1066,8 @@ class FeedForwardNetwork(NetworkUnitInterface):
       self._params.extend(self._layer_norm_input.params)
 
     if self._attrs['layer_norm_hidden']:
-      self._layer_norm_hidden = LayerNorm(self._component, 'layer_0',
-                                          self._hidden_layer_sizes[0],
-                                          tf.float32)
+      self._layer_norm_hidden = LayerNorm(
+          self._component, 'layer_0', self._hidden_layer_sizes[0], tf.float32)
       self._params.extend(self._layer_norm_hidden.params)
 
     # Extract nonlinearity from |tf.nn|.
@@ -984,13 +1089,11 @@ class FeedForwardNetwork(NetworkUnitInterface):
         self._params.append(
             tf.get_variable(
                 'bias_%d' % index, [hidden_layer_size],
-                initializer=tf.constant_initializer(
-                    0.2, dtype=tf.float32)))
+                initializer=tf.constant_initializer(0.2, dtype=tf.float32)))
 
       self._weights.append(weights)
       self._layers.append(
-          Layer(
-              component, name='layer_%d' % index, dim=hidden_layer_size))
+          Layer(component, name='layer_%d' % index, dim=hidden_layer_size))
       last_layer_dim = hidden_layer_size
 
     # Add a convenience alias for the last hidden layer, if any.
@@ -1000,7 +1103,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
     # By default, regularize only the weights.
     self._regularized_weights.extend(self._weights)
 
-    if component.num_actions:
+    if component.num_actions and not self._attrs['omit_logits']:
       self._params.append(
           tf.get_variable(
               'weights_softmax', [last_layer_dim, component.num_actions],
@@ -1010,8 +1113,7 @@ class FeedForwardNetwork(NetworkUnitInterface):
               'bias_softmax', [component.num_actions],
               initializer=tf.zeros_initializer()))
       self._layers.append(
-          Layer(
-              component, name='logits', dim=component.num_actions))
+          Layer(component, name='logits', dim=component.num_actions))
 
   def create(self,
              fixed_embeddings,
@@ -1078,10 +1180,8 @@ class FeedForwardNetwork(NetworkUnitInterface):
       return self._hidden_layer_sizes[-1]
 
     if not layer_name.startswith('layer_'):
-      logging.fatal(
-          'Invalid layer name: "%s" Can only retrieve from "logits", '
-          '"last_layer", and "layer_*".',
-          layer_name)
+      logging.fatal('Invalid layer name: "%s" Can only retrieve from "logits", '
+                    '"last_layer", and "layer_*".', layer_name)
 
     # NOTE(danielandor): Since get_layer_size is called before the
     # model has been built, we compute the layer size directly from
@@ -1157,7 +1257,8 @@ class LSTMNetwork(NetworkUnitInterface):
 
     self._params.extend([
         self._x2i, self._h2i, self._c2i, self._bi, self._x2o, self._h2o,
-        self._c2o, self._bo, self._x2c, self._h2c, self._bc])
+        self._c2o, self._bo, self._x2c, self._h2c, self._bc
+    ])
 
     lstm_h_layer = Layer(component, name='lstm_h', dim=self._hidden_layer_sizes)
     lstm_c_layer = Layer(component, name='lstm_c', dim=self._hidden_layer_sizes)
@@ -1168,20 +1269,20 @@ class LSTMNetwork(NetworkUnitInterface):
     self._layers.extend(self._context_layers)
 
     self._layers.append(
-        Layer(
-            component, name='layer_0', dim=self._hidden_layer_sizes))
+        Layer(component, name='layer_0', dim=self._hidden_layer_sizes))
 
-    self.params.append(tf.get_variable(
-        'weights_softmax', [self._hidden_layer_sizes, component.num_actions],
-        initializer=tf.random_normal_initializer(stddev=1e-4)))
+    self.params.append(
+        tf.get_variable(
+            'weights_softmax',
+            [self._hidden_layer_sizes, component.num_actions],
+            initializer=tf.random_normal_initializer(stddev=1e-4)))
     self.params.append(
         tf.get_variable(
             'bias_softmax', [component.num_actions],
             initializer=tf.zeros_initializer()))
 
     self._layers.append(
-        Layer(
-            component, name='logits', dim=component.num_actions))
+        Layer(component, name='logits', dim=component.num_actions))
 
   def create(self,
              fixed_embeddings,
@@ -1215,6 +1316,13 @@ class LSTMNetwork(NetworkUnitInterface):
     i_h_tm1 = context_tensor_arrays[0].read(length - 1)
     i_c_tm1 = context_tensor_arrays[1].read(length - 1)
 
+    # label c and h inputs
+    i_c_tm1 = tf.identity(i_c_tm1, name='lstm_c_in')
+    i_h_tm1 = tf.identity(i_h_tm1, name='lstm_h_in')
+
+    # label the feature input (for debugging purposes)
+    input_tensor = tf.identity(input_tensor, name='input_tensor')
+
     # apply dropout according to http://arxiv.org/pdf/1409.2329v5.pdf
     if during_training and self._input_dropout_rate < 1:
       input_tensor = tf.nn.dropout(input_tensor, self._input_dropout_rate)
@@ -1251,7 +1359,8 @@ class LSTMNetwork(NetworkUnitInterface):
 
     h = tf.identity(ht, name='layer_0')
 
-    logits = tf.nn.xw_plus_b(ht, tf.get_variable('weights_softmax'),
+    logits = tf.nn.xw_plus_b(ht,
+                             tf.get_variable('weights_softmax'),
                              tf.get_variable('bias_softmax'))
 
     if self._component.spec.attention_component:
@@ -1284,7 +1393,7 @@ class ConvNetwork(NetworkUnitInterface):
       widths: comma separated list of ints, number of steps input to the
               convolutional kernel at every layer.
       depths: comma separated list of ints, number of channels input to the
-              convolutional kernel at every layer.
+              convolutional kernel at every layer except the first.
       output_embedding_dim: int, number of output channels for the convolutional
               kernel of the last layer, which receives no ReLU activation and
               therefore can be used in a softmax output. If zero, this final
@@ -1298,6 +1407,13 @@ class ConvNetwork(NetworkUnitInterface):
         sequence, instead of once per step.  See Gal and Ghahramani
         (https://arxiv.org/abs/1512.05287).
 
+    Raises:
+      RuntimeError: if the number of widths is not equal to the number of
+          depths - 1.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features.
+
     Hyperparameters used:
       dropout_rate: The probability that an input is not dropped.  Only used
           when the |dropout_keep_prob| parameter is negative.
@@ -1305,21 +1421,34 @@ class ConvNetwork(NetworkUnitInterface):
 
     super(ConvNetwork, self).__init__(component)
     self._attrs = get_attrs_with_defaults(
-        component.spec.network_unit.parameters, defaults={
+        component.spec.network_unit.parameters,
+        defaults={
             'widths': '',
             'depths': '',
             'output_embedding_dim': 0,
             'nonlinearity': 'relu',
             'dropout_keep_prob': -1.0,
-            'dropout_per_sequence': False})
+            'dropout_per_sequence': False
+        })
 
     self._weights = []
     self._biases = []
     self._widths = map(int, self._attrs['widths'].split(','))
-    self._depths = map(int, self._attrs['depths'].split(','))
+    self._depths = [self._concatenated_input_dim]
+
+    # Since we infer the input dimension, depths could be empty
+    if self._attrs['depths']:
+      self._depths.extend(map(int, self._attrs['depths'].split(',')))
+
     self._output_dim = self._attrs['output_embedding_dim']
     if self._output_dim:
       self._depths.append(self._output_dim)
+
+    if len(self._widths) != len(self._depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
     self.kernel_shapes = []
     for i in range(len(self._depths) - 1):
       self.kernel_shapes.append(
@@ -1350,10 +1479,9 @@ class ConvNetwork(NetworkUnitInterface):
 
     self._params.extend(self._weights + self._biases)
     self._layers.append(
-        Layer(
-            component, name='conv_output', dim=self._depths[-1]))
-    self._regularized_weights.extend(self._weights[:-1] if self._output_dim else
-                                     self._weights)
+        Layer(component, name='conv_output', dim=self._depths[-1]))
+    self._regularized_weights.extend(self._weights[:-1]
+                                     if self._output_dim else self._weights)
 
   def create(self,
              fixed_embeddings,
@@ -1365,7 +1493,7 @@ class ConvNetwork(NetworkUnitInterface):
     """Requires |stride|; otherwise see base class."""
     if stride is None:
       raise RuntimeError("ConvNetwork needs 'stride' and must be called in the "
-                         "bulk feature extractor component.")
+                         'bulk feature extractor component.')
     input_tensor = get_input_tensor_with_stride(fixed_embeddings,
                                                 linked_embeddings, stride)
 
@@ -1388,8 +1516,253 @@ class ConvNetwork(NetworkUnitInterface):
         if i < (len(self._weights) - 1) or not self._output_dim:
           conv = self._nonlinearity(conv, name=scope.name)
     return [
+        tf.reshape(conv, [-1, self._depths[-1]], name='reshape_activations')
+    ]
+
+  def _maybe_apply_dropout(self, inputs, stride):
+    # The |inputs| are rank 4 (one 1xN "image" per sequence).  Squeeze out and
+    # restore the singleton image height, so dropout is applied to the normal
+    # rank 3 batched input tensor.
+    inputs = tf.squeeze(inputs, [1])
+    inputs = maybe_apply_dropout(inputs, self._dropout_rate,
+                                 self._attrs['dropout_per_sequence'], stride)
+    inputs = tf.expand_dims(inputs, 1)
+    return inputs
+
+
+class ConvMultiNetwork(NetworkUnitInterface):
+  """Implementation of a convolutional feed forward net with a side tower."""
+
+  def __init__(self, component):
+    """Initializes kernels and biases for this convolutional net.
+
+    Args:
+      component: parent ComponentBuilderBase object.
+
+    Parameters used to construct the network:
+      widths: comma separated list of ints, number of steps input to the
+              convolutional kernel at every layer.
+      depths: comma separated list of ints, number of channels input to the
+              convolutional kernel at every layer except the first.
+      output_embedding_dim: int, number of output channels for the convolutional
+              kernel of the last layer, which receives no ReLU activation and
+              therefore can be used in a softmax output. If zero, this final
+              layer is disabled entirely.
+      side_tower_index: An int representing the layer of the tower that the
+              side tower will start from. 0 is the input data and 'num_layers'
+              is the output.
+      side_tower_widths: comma separated list of ints, number of steps input to
+              the convolutional kernel at every layer of the side tower.
+      side_tower_depths: comma separated list of ints, number of channels input
+              to the convolutional kernel at every layer of the side tower save
+              the first.
+      side_tower_output_embedding_dim: int, number of output channels for the
+              kernel of the last layer, which receives no ReLU activation and
+              therefore can be used in a softmax output. If zero, this final
+              layer is disabled entirely.
+      nonlinearity ('relu'): Name of function from module "tf.nn" to apply to
+        each hidden layer; e.g., "relu" or "elu".
+      dropout_keep_prob (-1.0): The probability that an input is not dropped.
+        If >= 1.0, disables dropout.  If < 0.0, uses the global |dropout_rate|
+        hyperparameter.
+      dropout_per_sequence (False): If true, sample the dropout mask once per
+        sequence, instead of once per step.  See Gal and Ghahramani
+        (https://arxiv.org/abs/1512.05287).
+
+    Raises:
+      RuntimeError: if the number of widths is not equal to the number of
+          depths - 1.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features.
+
+    Hyperparameters used:
+      dropout_rate: The probability that an input is not dropped.  Only used
+          when the |dropout_keep_prob| parameter is negative.
+    """
+
+    super(ConvMultiNetwork, self).__init__(component)
+    self._attrs = get_attrs_with_defaults(
+        component.spec.network_unit.parameters,
+        defaults={
+            'widths': '',
+            'depths': '',
+            'output_embedding_dim': 0,
+            'side_tower_index': 0,
+            'side_tower_widths': '',
+            'side_tower_depths': '',
+            'side_tower_output_embedding_dim': 0,
+            'nonlinearity': 'relu',
+            'dropout_keep_prob': -1.0,
+            'dropout_per_sequence': False
+        })
+
+    # Examine the widths and depths for the primary tower.
+    self._weights = []
+    self._biases = []
+    self._widths = map(int, self._attrs['widths'].split(','))
+    self._depths = [self._concatenated_input_dim]
+
+    # Since we infer the input dimension, depths could be empty.
+    if self._attrs['depths']:
+      self._depths.extend(map(int, self._attrs['depths'].split(',')))
+
+    self._output_dim = self._attrs['output_embedding_dim']
+    if self._output_dim:
+      self._depths.append(self._output_dim)
+
+    if len(self._widths) != len(self._depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
+    # Create the kernels for the primary tower.
+    self.kernel_shapes = []
+    for i in range(len(self._depths) - 1):
+      self.kernel_shapes.append(
+          [1, self._widths[i], self._depths[i], self._depths[i + 1]])
+    for i in range(len(self._depths) - 1):
+      with tf.variable_scope('conv%d' % i):
+        self._weights.append(
+            tf.get_variable(
+                'weights',
+                self.kernel_shapes[i],
+                initializer=tf.random_normal_initializer(stddev=1e-4),
+                dtype=tf.float32))
+        bias_init = 0.0 if (i == len(self._widths) - 1) else 0.2
+        self._biases.append(
+            tf.get_variable(
+                'biases',
+                self.kernel_shapes[i][-1],
+                initializer=tf.constant_initializer(bias_init),
+                dtype=tf.float32))
+
+    # Examine the widths and depths for the side tower.
+    self._side_index = self._attrs['side_tower_index']
+    self._side_weights = []
+    self._side_biases = []
+    self._side_widths = map(int, self._attrs['side_tower_widths'].split(','))
+    self._side_depths = [self._depths[self._side_index]]
+
+    # Since we infer the input dimension, depths could be empty.
+    if self._attrs['side_tower_depths']:
+      self._side_depths.extend(
+          map(int, self._attrs['side_tower_depths'].split(',')))
+
+    self._side_output_dim = self._attrs['side_tower_output_embedding_dim']
+    if self._side_output_dim:
+      self._depths.append(self._side_output_dim)
+
+    if len(self._side_widths) != len(self._side_depths) - 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._side_widths), len(self._side_depths)))
+
+    # Create the kernels for the side tower, if there is more than one layer.
+    self.side_kernel_shapes = []
+    for i in range(len(self._side_depths) - 1):
+      self.side_kernel_shapes.append([
+          1, self._side_widths[i], self._side_depths[i], self._side_depths[i
+                                                                           + 1]
+      ])
+    for i in range(len(self._side_depths) - 1):
+      with tf.variable_scope('side_conv%d' % i):
+        self._side_weights.append(
+            tf.get_variable(
+                'weights',
+                self.side_kernel_shapes[i],
+                initializer=tf.random_normal_initializer(stddev=1e-4),
+                dtype=tf.float32))
+        bias_init = 0.0 if (i == len(self._side_widths) - 1) else 0.2
+        self._side_biases.append(
+            tf.get_variable(
+                'biases',
+                self.side_kernel_shapes[i][-1],
+                initializer=tf.constant_initializer(bias_init),
+                dtype=tf.float32))
+
+    # Extract nonlinearity from |tf.nn|.
+    self._nonlinearity = getattr(tf.nn, self._attrs['nonlinearity'])
+
+    # Infer dropout rate from network parameters and grid hyperparameters.
+    self._dropout_rate = self._attrs['dropout_keep_prob']
+    if self._dropout_rate < 0.0:
+      self._dropout_rate = component.master.hyperparams.dropout_rate
+
+    self._params.extend(self._weights + self._biases + self._side_weights +
+                        self._side_biases)
+
+    # Append primary tower layers to the data structure.
+    self._layers.append(
+        Layer(component, name='conv_output', dim=self._depths[-1]))
+    if self._output_dim:
+      self._regularized_weights.extend(self._weights[:-1])
+    else:
+      self._regularized_weights.extend(self._weights)
+
+    # Append side tower layers to the data structure.
+    self._layers.append(
+        Layer(component, name='conv_side_output', dim=self._side_depths[-1]))
+    if self._side_output_dim:
+      self._regularized_weights.extend(self._side_weights[:-1])
+    else:
+      self._regularized_weights.extend(self._side_weights)
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    if stride is None:
+      raise RuntimeError("ConvNetwork needs 'stride' and must be called in the "
+                         'bulk feature extractor component.')
+    input_tensor = get_input_tensor_with_stride(fixed_embeddings,
+                                                linked_embeddings, stride)
+
+    # TODO(googleuser): Add context and attention.
+    del context_tensor_arrays, attention_tensor
+
+    # On CPU, add a dimension so that the 'image' has shape
+    # [stride, 1, num_steps, D].
+    conv = tf.expand_dims(input_tensor, 1)
+    for i in range(len(self._depths) - 1):
+      if i == self._side_index:
+        logging.info('Creating side tower at index %d', i)
+        side_conv = conv
+        for j in range(len(self._side_depths) - 1):
+          with tf.variable_scope('side_conv%d' % j, reuse=True) as scope:
+            if during_training:
+              side_conv.set_shape([None, 1, None, self._side_depths[j]])
+              side_conv = self._maybe_apply_dropout(side_conv, stride)
+            side_conv = tf.nn.conv2d(
+                side_conv,
+                self._component.get_variable('weights'), [1, 1, 1, 1],
+                padding='SAME')
+            side_conv = tf.nn.bias_add(side_conv,
+                                       self._component.get_variable('biases'))
+            if j < (len(self._side_weights) - 1) or not self._side_output_dim:
+              side_conv = self._nonlinearity(side_conv, name=scope.name)
+
+      with tf.variable_scope('conv%d' % i, reuse=True) as scope:
+        if during_training:
+          conv.set_shape([None, 1, None, self._depths[i]])
+          conv = self._maybe_apply_dropout(conv, stride)
+        conv = tf.nn.conv2d(
+            conv,
+            self._component.get_variable('weights'), [1, 1, 1, 1],
+            padding='SAME')
+        conv = tf.nn.bias_add(conv, self._component.get_variable('biases'))
+        if i < (len(self._weights) - 1) or not self._output_dim:
+          conv = self._nonlinearity(conv, name=scope.name)
+
+    return [
+        tf.reshape(conv, [-1, self._depths[-1]], name='reshape_activations'),
         tf.reshape(
-            conv, [-1, self._depths[-1]], name='reshape_activations')
+            side_conv, [-1, self._side_depths[-1]],
+            name='reshape_side_activations'),
     ]
 
   def _maybe_apply_dropout(self, inputs, stride):
@@ -1406,20 +1779,17 @@ class ConvNetwork(NetworkUnitInterface):
 class PairwiseConvNetwork(NetworkUnitInterface):
   """Implementation of a pairwise 2D convolutional feed forward network.
 
-  For a sequence of N tokens, all N^2 pairs of concatenated input features are
-  constructed. If each input vector is of length D, then the sequence is
-  represented by an image of dimensions [N, N] with 2*D channels per pixel.
-  I.e. pixel [i, j] has a representation that is the concatenation of the
-  representations of the tokens at i and at j.
-
-  To use this network for graph edge scoring, for instance by using the "heads"
-  transition system, the output layer needs to have dimensions [N, N] and only
-  a single channel. The network takes care of outputting an [N, N] sized layer,
-  but the user needs to ensure that the output depth equals 1.
-
-  TODO(googleuser): Like Dozat and Manning, we will need an
-  additional network to label the edges, and the ability to read head
-  and modifier representations from different inputs.
+  For two sequences of representations of N tokens, all N^2 pairs of
+  concatenated input features are constructed. If each input vector is of
+  length D, then the sequence is represented by an image of dimensions [N, N]
+  with 2*D channels per pixel. I.e. pixel [i, j] has a representation that is
+  the concatenation of the representations of the tokens at i and at j.
+
+  To use this network for graph edge scoring, for instance by using the
+  "heads_labels" transition system, the output layer needs to have dimensions
+  [N, N*num_labels]. The network takes care of outputting an [N, N*last_dim]
+  sized layer, but the user needs to ensure that the output depth equals the
+  desired number of output labels.
   """
 
   def __init__(self, component):
@@ -1430,62 +1800,98 @@ class PairwiseConvNetwork(NetworkUnitInterface):
           convolutional kernel at every layer.
       widths: comma separated list of ints, number of steps input to the
           convolutional kernel at every layer.
-      relu_layers: comma separate list of ints, the id of layers after which
-          to apply a relu activation. *By default, all but the final layer will
-          have a relu activation applied.*
-
-    To generate a network with M layers, both 'depths' and 'widths' must be of
-    length M. The input depth of the first layer is inferred from the total
-    concatenated size of the input features.
+      dropout: comma separated list of floats, dropout keep probability for each
+          layer.
+      bias_init: comma separated list of floats, constant bias initializer for
+          each layer.
+      initialization: comma separated list of strings, initialization for each
+          layer. See add_var_initialized() for available initialization schemes.
+      activation_layers: comma separated list of ints, the id of layers after
+          which to apply an activation. *By default, all but the final layer
+          will have an activation applied.*
+      activation: anything defined in tf.nn.
+
+    To generate a network with M layers, 'depths', 'widths', 'dropout',
+    'bias_init' and 'initialization' must be of length M. The input depth of the
+    first layer is inferred from the total concatenated size of the input
+    features.
 
     Args:
       component: parent ComponentBuilderBase object.
 
     Raises:
-      RuntimeError: if the number of depths and weights are not equal.
-      ValueError: if the final depth is not equal to 1.
+      RuntimeError: if the lists of dropout, bias_init, initialization, and
+          widths do not have equal length, or the number of widths is not
+          equal to the number of depths - 1.
     """
     parameters = component.spec.network_unit.parameters
     super(PairwiseConvNetwork, self).__init__(component)
 
+    self._source_dim = self._linked_feature_dims['sources']
+    self._target_dim = self._linked_feature_dims['targets']
+
     # Each input pixel will comprise the concatenation of two tokens, so the
     # input depth is double that for a single token.
-    self._depths = [self._concatenated_input_dim * 2]
-    self._depths.extend(map(int, parameters['depths'].split(',')))
+    self._depths = [self._source_dim + self._target_dim]
     self._widths = map(int, parameters['widths'].split(','))
     self._num_layers = len(self._widths)
-    if len(self._depths) != self._num_layers + 1:
-      raise RuntimeError('Unmatched depths/weights %s/%s' %
-                         (parameters['depths'], parameters['weights']))
-    if self._depths[-1] != 1:
-      raise ValueError('Final depth is not equal to 1 in %s' %
-                       parameters['depths'])
+    self._dropout = map(float, parameters['dropout'].split(',')) if parameters[
+        'dropout'] else [1.0] * self._num_layers
+    self._bias_init = map(float, parameters['bias_init'].split(
+        ',')) if parameters['bias_init'] else [0.01] * self._num_layers
+    self._initialization = parameters['initialization'].split(
+        ',') if parameters['initialization'] else ['xavier'] * self._num_layers
+    param_lengths = map(len, [
+        self._widths, self._dropout, self._bias_init, self._initialization
+    ])
+    if not all(param_lengths[0] == param_len for param_len in param_lengths):
+      raise RuntimeError(
+          'Unmatched widths/dropout/bias_init/initialization: ' +
+          '%d/%d/%d/%d' % (param_lengths[0], param_lengths[1],
+                           param_lengths[2], param_lengths[3]))
+
+    self._depths.extend(map(int, parameters['depths'].split(',')))
+    if len(self._depths) != len(self._widths) + 1:
+      raise RuntimeError(
+          'Unmatched widths/depths: %d/%d (depths should equal widths + 1)' %
+          (len(self._widths), len(self._depths)))
+
+    if parameters['activation']:
+      self._activation = parameters['activation']
+    else:
+      self._activation = 'relu'
+    self._activation_fn = getattr(tf.nn, self._activation)
+
+    self._num_labels = self._depths[-1]
+
+    if parameters['activation_layers']:
+      self._activation_layers = set(map(int,
+                                        parameters['activation_layers'].split(
+                                            ',')))
+    else:
+      self._activation_layers = set(range(self._num_layers - 1))
 
     self._kernel_shapes = []
     for i, width in enumerate(self._widths):
-      self._kernel_shapes.append(
-          [width, width, self._depths[i], self._depths[i + 1]])
-    if parameters['relu_layers']:
-      self._relu_layers = set(map(int, parameters['relu_layers'].split(',')))
-    else:
-      self._relu_layers = set(range(self._num_layers - 1))
+      if self._activation == 'glu' and i in self._activation_layers:
+        self._kernel_shapes.append(
+            [width, width, self._depths[i], 2*self._depths[i + 1]])
+      else:
+        self._kernel_shapes.append(
+            [width, width, self._depths[i], self._depths[i + 1]])
 
     self._weights = []
     self._biases = []
     for i, kernel_shape in enumerate(self._kernel_shapes):
       with tf.variable_scope('conv%d' % i):
         self._weights.append(
-            tf.get_variable(
-                'weights',
-                kernel_shape,
-                initializer=tf.random_normal_initializer(stddev=1e-4),
-                dtype=tf.float32))
-        bias_init = 0.0 if i in self._relu_layers else 0.2
+            add_var_initialized('weights', kernel_shape, self._initialization[
+                i]))
         self._biases.append(
             tf.get_variable(
                 'biases',
                 kernel_shape[-1],
-                initializer=tf.constant_initializer(bias_init),
+                initializer=tf.constant_initializer(self._bias_init[i]),
                 dtype=tf.float32))
 
     self._params.extend(self._weights + self._biases)
@@ -1500,34 +1906,46 @@ class PairwiseConvNetwork(NetworkUnitInterface):
              during_training,
              stride=None):
     """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor  # Unused.
     # TODO(googleuser): Normalize the arguments to create(). 'stride'
     # is unused by the recurrent network units, while 'context_tensor_arrays'
     # and 'attenion_tensor_array' is unused by bulk network units. b/33587044
     if stride is None:
       raise ValueError("PairwiseConvNetwork needs 'stride'")
 
-    input_tensor = get_input_tensor_with_stride(fixed_embeddings,
-                                                linked_embeddings, stride)
-
-    # TODO(googleuser): Add dropout.
-    del context_tensor_arrays, attention_tensor, during_training  # Unused.
-
-    num_steps = tf.shape(input_tensor)[1]
-    arg1 = tf.expand_dims(input_tensor, 1)
-    arg1 = tf.tile(arg1, tf.stack([1, num_steps, 1, 1]))
-    arg2 = tf.expand_dims(input_tensor, 2)
-    arg2 = tf.tile(arg2, tf.stack([1, 1, num_steps, 1]))
+    sources = lookup_named_tensor('sources', linked_embeddings).tensor
+    targets = lookup_named_tensor('targets', linked_embeddings).tensor
+
+    source_tokens = tf.reshape(sources, [stride, -1, 1, self._source_dim])
+    target_tokens = tf.reshape(targets, [stride, 1, -1, self._target_dim])
+
+    # sources and targets should have shapes [b, n, 1, s] and [b, 1, n, t],
+    # respectively. Since we just reshaped them, we can check that all dims are
+    # as expected by checking the one unknown dim, i.e. their num_steps (n) dim.
+    sources_shape = tf.shape(source_tokens)
+    targets_shape = tf.shape(target_tokens)
+    num_steps = sources_shape[1]
+    with tf.control_dependencies([tf.assert_equal(num_steps, targets_shape[2],
+                                                  name='num_steps_mismatch')]):
+      arg1 = tf.tile(source_tokens, tf.stack([1, 1, num_steps, 1]))
+      arg2 = tf.tile(target_tokens, tf.stack([1, num_steps, 1, 1]))
     conv = tf.concat([arg1, arg2], 3)
     for i in xrange(self._num_layers):
       with tf.variable_scope('conv%d' % i, reuse=True) as scope:
-        conv = tf.nn.conv2d(
-            conv,
-            self._component.get_variable('weights'), [1, 1, 1, 1],
-            padding='SAME')
+        if during_training:
+          conv = maybe_apply_dropout(conv, self._dropout[i], False)
+        conv = tf.nn.conv2d(conv,
+                            self._component.get_variable('weights'),
+                            [1, 1, 1, 1],
+                            padding='SAME')
         conv = tf.nn.bias_add(conv, self._component.get_variable('biases'))
-        if i in self._relu_layers:
-          conv = tf.nn.relu(conv, name=scope.name)
-    return [tf.reshape(conv, [-1, num_steps], name='reshape_activations')]
+        if i in self._activation_layers:
+          conv = self._activation_fn(conv, name=scope.name)
+    return [
+        tf.reshape(
+            conv, [-1, num_steps * self._num_labels],
+            name='reshape_activations')
+    ]
 
 
 class ExportFixedFeaturesNetwork(NetworkUnitInterface):
@@ -1593,7 +2011,7 @@ class SplitNetwork(NetworkUnitInterface):
 
     for slice_index in xrange(self._num_slices):
       self._layers.append(
-          Layer(self, 'slice_%s' % slice_index, self._slice_dim))
+          Layer(component, 'slice_%s' % slice_index, self._slice_dim))
 
   def create(self,
              fixed_embeddings,
@@ -1602,5 +2020,103 @@ class SplitNetwork(NetworkUnitInterface):
              attention_tensor,
              during_training,
              stride=None):
+    """See base class."""
     input_bnxd = get_input_tensor(fixed_embeddings, linked_embeddings)
     return tf.split(input_bnxd, self._num_slices, axis=1)
+
+
+class GatherNetwork(NetworkUnitInterface):
+  """Network unit that gathers input according to specified step indices.
+
+  This can be used to implement a non-trivial linked feature (i.e., where the
+  link mapping is more complex than 'input.focus').  Extract the step indices
+  using a BulkFeatureIdExtractorComponentBuilder, and then gather activations
+  using this network.
+
+  Note that the step index -1 is special: gathering it will retrieve a padding
+  vector, which can be constant (zeros) or trainable.
+
+  Parameters:
+    trainable_padding (False): Whether the padding vector is trainable.
+
+  Features:
+    indices: [B * N, 1] The step indices to gather, local to each batch item.
+      These are local in the sense that, for each batch item, the step indices
+      are in the range [-1,N).
+    All other features are concatenated into a [B * N, D] matrix.
+
+  Layers:
+    outputs: [B * N, D] The first slice of the input.
+  """
+
+  def __init__(self, component):
+    """Initializes weights and layers.
+
+    Args:
+      component: Parent ComponentBuilderBase object.
+    """
+    super(GatherNetwork, self).__init__(component)
+    self._attrs = get_attrs_with_defaults(
+        component.spec.network_unit.parameters, {'trainable_padding': False})
+
+    check.In('indices', self._linked_feature_dims,
+             'Missing required linked feature')
+    check.Eq(self._linked_feature_dims['indices'], 1,
+             'Wrong dimension for "indices" feature')
+    self._dim = self._concatenated_input_dim - 1  # exclude 'indices'
+    self._layers.append(Layer(component, 'outputs', self._dim))
+
+    if self._attrs['trainable_padding']:
+      self._params.append(
+          tf.get_variable(
+              'pre_padding', [1, 1, self._dim],
+              initializer=tf.random_normal_initializer(stddev=1e-4),
+              dtype=tf.float32))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    check.NotNone(stride,
+                  'BulkBiLSTMNetwork requires "stride" and must be called '
+                  'in the bulk feature extractor component.')
+
+    # Extract the batched local step indices.
+    local_indices = lookup_named_tensor('indices', linked_embeddings)
+    local_indices_bxn = tf.reshape(local_indices.tensor, [stride, -1])
+    local_indices_bxn = tf.to_int32(local_indices_bxn)
+    num_steps = tf.shape(local_indices_bxn)[1]
+
+    # Collect all other inputs as a batched tensor.
+    linked_embeddings = [
+        named_tensor for named_tensor in linked_embeddings
+        if named_tensor.name != 'indices'
+    ]
+    inputs_bnxd = get_input_tensor(fixed_embeddings, linked_embeddings)
+
+    # Prepend the padding vector, which may be trainable or constant.
+    inputs_bxnxd = tf.reshape(inputs_bnxd, [stride, -1, self._dim])
+    if self._attrs['trainable_padding']:
+      padding_1x1xd = self._component.get_variable('pre_padding')
+      padding_bx1xd = tf.tile(padding_1x1xd, [stride, 1, 1])
+    else:
+      padding_bx1xd = tf.zeros([stride, 1, self._dim], tf.float32)
+    inputs_bxnxd = tf.concat([padding_bx1xd, inputs_bxnxd], 1)
+    inputs_bnxd = tf.reshape(inputs_bxnxd, [-1, self._dim])
+
+    # As mentioned above, for each batch item the local step indices are in the
+    # range [-1,N).  To compensate for batching and padding, the local indices
+    # must be progressively offset into "global" indices such that batch item b
+    # is in the range [b*(N+1),(b+1)*(N+1)).
+    batch_indices_b = tf.range(stride)
+    batch_indices_bx1 = tf.expand_dims(batch_indices_b, 1)
+    local_to_global_offsets_bx1 = batch_indices_bx1 * (num_steps + 1) + 1
+    global_indices_bxn = local_indices_bxn + local_to_global_offsets_bx1
+    global_indices_bn = tf.reshape(global_indices_bxn, [-1])
+
+    outputs_bnxd = tf.gather(inputs_bnxd, global_indices_bn)
+    return [outputs_bnxd]
diff --git a/research/syntaxnet/dragnn/python/network_units_test.py b/research/syntaxnet/dragnn/python/network_units_test.py
index d913c526..fa4ae17c 100644
--- a/research/syntaxnet/dragnn/python/network_units_test.py
+++ b/research/syntaxnet/dragnn/python/network_units_test.py
@@ -16,16 +16,16 @@
 """Tests for network_units."""
 
 
+import numpy as np
 import tensorflow as tf
+
+from google.protobuf import text_format
 from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 
 from dragnn.protos import spec_pb2
 from dragnn.python import network_units
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
 
 
@@ -66,6 +66,9 @@ class MockComponent(object):
   def attr(self, name):
     return self._attrs[name]
 
+  def get_variable(self, name):
+    return tf.get_variable(name)
+
 
 class MockMaster(object):
 
@@ -77,6 +80,15 @@ class MockMaster(object):
     }
 
 
+class MockNetwork(object):
+
+  def __init__(self, **dims):
+    self._dims = dims
+
+  def get_layer_size(self, name):
+    return self._dims[name]
+
+
 class NetworkUnitsLookupTest(test_util.TensorFlowTestCase):
 
   def setUp(self):
@@ -155,5 +167,256 @@ class GetAttrsWithDefaultsTest(test_util.TensorFlowTestCase):
     _assert_attr_is_true('TRUE')
 
 
+class GatherNetworkTest(test_util.TensorFlowTestCase):
+
+  def setUp(self):
+    # Clear the graph and all existing variables.  Otherwise, variables created
+    # in different tests may collide with each other.
+    tf.reset_default_graph()
+
+    self._master = MockMaster()
+    self._master.spec = spec_pb2.MasterSpec()
+    text_format.Parse("""
+      component {
+        name: 'test'
+        backend { registered_name: 'TestComponent' }
+        linked_feature {
+          name: 'indices'
+          fml: 'input.focus'
+          size: 1
+          embedding_dim: -1
+          source_component: 'previous'
+          source_translator: 'identity'
+          source_layer: 'index_layer'
+        }
+        linked_feature {
+          name: 'features'
+          fml: 'input.focus'
+          size: 1
+          embedding_dim: -1
+          source_component: 'previous'
+          source_translator: 'identity'
+          source_layer: 'feature_layer'
+        }
+        network_unit {
+          registered_name: 'GatherNetwork'
+        }
+      }
+    """, self._master.spec)
+    self._component = MockComponent(self._master,
+                                    self._master.spec.component[0])
+    self._master.lookup_component['previous'].network = MockNetwork(
+        index_layer=1, feature_layer=2)
+
+  def testConstantPadding(self):
+    with tf.Graph().as_default(), self.test_session():
+      with tf.variable_scope('test_scope'):
+        network = network_units.GatherNetwork(self._component)
+
+      # Construct a batch of two items with 3 and 2 steps, respectively.
+      indices = tf.constant([[1], [2], [0],  # item 1
+                             [-1], [0], [-1]],  # item 2
+                            dtype=tf.int64)
+      features = tf.constant([[1.0, 1.5], [2.0, 2.5], [3.0, 3.5],  # item 1
+                              [4.0, 4.5], [5.0, 5.5], [6.0, 6.5]],  # item 2
+                             dtype=tf.float32)
+
+      fixed_embeddings = []
+      linked_embeddings = [
+          network_units.NamedTensor(indices, 'indices', 1),
+          network_units.NamedTensor(features, 'features', 2)
+      ]
+
+      with tf.variable_scope('test_scope', reuse=True):
+        outputs = network.create(fixed_embeddings, linked_embeddings, None,
+                                 None, True, 2)
+      gathered = outputs[0]
+
+      # Zeros will be substituted for index -1.
+      self.assertAllEqual(gathered.eval(),
+                          [[2.0, 2.5],  # gathered from 1
+                           [3.0, 3.5],  # gathered from 2
+                           [1.0, 1.5],  # gathered from 0
+                           [0.0, 0.0],  # gathered from -1
+                           [4.0, 4.5],  # gathered from 0
+                           [0.0, 0.0]])  # gathered from -1
+
+  def testTrainablePadding(self):
+    self._component.spec.network_unit.parameters['trainable_padding'] = 'true'
+    with tf.Graph().as_default(), self.test_session():
+      with tf.variable_scope('test_scope'):
+        network = network_units.GatherNetwork(self._component)
+
+      # Construct a batch of two items with 3 and 2 steps, respectively.
+      indices = tf.constant([[1], [2], [0],  # item 1
+                             [-1], [0], [-1]],  # item 2
+                            dtype=tf.int64)
+      features = tf.constant([[1.0, 1.5], [2.0, 2.5], [3.0, 3.5],  # item 1
+                              [4.0, 4.5], [5.0, 5.5], [6.0, 6.5]],  # item 2
+                             dtype=tf.float32)
+
+      fixed_embeddings = []
+      linked_embeddings = [
+          network_units.NamedTensor(indices, 'indices', 1),
+          network_units.NamedTensor(features, 'features', 2)
+      ]
+
+      with tf.variable_scope('test_scope', reuse=True):
+        outputs = network.create(fixed_embeddings, linked_embeddings, None,
+                                 None, True, 2)
+      gathered = outputs[0]
+
+      # Ensure that the padding variable is initialized.
+      tf.global_variables_initializer().run()
+
+      # Randomly-initialized padding will be substituted for index -1.
+      self.assertAllEqual(gathered[0].eval(), [2.0, 2.5])  # gathered from 1
+      self.assertAllEqual(gathered[1].eval(), [3.0, 3.5])  # gathered from 2
+      self.assertAllEqual(gathered[2].eval(), [1.0, 1.5])  # gathered from 0
+      tf.logging.info('padding = %s', gathered[3].eval())  # gathered from -1
+      self.assertAllEqual(gathered[4].eval(), [4.0, 4.5])  # gathered from 0
+      tf.logging.info('padding = %s', gathered[5].eval())  # gathered from -1
+
+      # Though random, the padding must identical.
+      self.assertAllEqual(gathered[3].eval(), gathered[5].eval())
+
+
+class IdentityInitializerTest(test_util.TensorFlowTestCase):
+
+  def IdentityInitializerHelper(self, shape, expected, divisor=1.0, std=1e-4):
+    """Tests identity initialization by comparing expected to actual array.
+
+    Tests the given expected array against the result of calling
+    network_units.add_var_initialized() with the given params and
+    init_type='identity'.
+
+    Args:
+      shape: shape of the array
+      expected: expected contents of the array to initialize
+      divisor: numerator for identity initialization where the last two dims
+        of the array are not equal; should divide both of the last two dims
+      std: standard deviation for random normal samples
+    """
+    with tf.Graph().as_default(), self.test_session() as session:
+      np.random.seed(4)
+      tensor = network_units.add_var_initialized('tensor', shape, 'identity',
+                                                 divisor=divisor, stddev=std)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+      self.assertAllClose(actual, expected, 1e-8, 1e-8)
+
+  def IdentityInitializerSquareHelper(self, shape, middles):
+    """Tests identity initialization when last two dims are equal.
+
+    When the last two dims of the array are equal, identity initialization
+    should simply set the center matrix in the last two dimensions to the
+    identity, with all other entries set to zero.
+
+    Args:
+      shape: shape of the array to initialize
+      middles: indices into the middle of all axes except the last two. It
+          must be the case that len(middles) == len(shape) - 2.
+    """
+    expected = np.zeros(shape, dtype='float32')
+    expected[[[m] for m in middles]] = np.eye(shape[-1])
+    self.IdentityInitializerHelper(shape, expected)
+
+  def testIdentityInitializerSquareRank2(self):
+    shape = (3, 3)
+    expected = np.eye(shape[-1]).astype('float32')
+    self.IdentityInitializerHelper(shape, expected)
+
+  def testIdentityInitializerSquareRank3(self):
+    shape = (2, 4, 4)
+    middles = [1]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerSquareRank4(self):
+    shape = (2, 3, 4, 4)
+    middles = [1, 1]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerSquareRank5(self):
+    shape = (2, 3, 4, 5, 5)
+    middles = [1, 1, 2]
+    self.IdentityInitializerSquareHelper(shape, middles)
+
+  def testIdentityInitializerNonSquareRank2FirstDimLarger(self):
+    divisor = 3.
+    std = 1e-3
+    shape = (6, 3)
+    m = divisor/shape[-1]
+    expected = [[m, 4.99951362e-04, -9.95908980e-04],
+                [m, -4.18301526e-04, -1.58457726e-03],
+                [-6.47706795e-04, m, 3.32250027e-04],
+                [-1.14747661e-03, m, -8.79869258e-05],
+                [4.25072387e-04, 3.32253141e-04, m],
+                [3.50997143e-04, -6.06887275e-04, m]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank2FirstDimSmaller(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 4)
+    m = divisor / shape[-1]
+    expected = [[m, m, -9.95908980e-04, 6.93598529e-04],
+                [-4.18301526e-04, -1.58457726e-03, m, m]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank3(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 2, 6)
+    m = divisor / shape[-1]
+    expected = [[[5.05617063e-05, 4.99951362e-04, -9.95908980e-04,
+                  6.93598529e-04, -4.18301526e-04, -1.58457726e-03],
+                 [-6.47706795e-04, 5.98575163e-04, 3.32250027e-04,
+                  -1.14747661e-03, 6.18669670e-04, -8.79869258e-05]],
+                [[m, m, m,
+                  3.50997143e-04, -6.06887275e-04, 1.54697930e-03],
+                 [7.23341596e-04, 4.61355667e-05, -9.82991653e-04,
+                  m, m, m]]]
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+  def testIdentityInitializerNonSquareRank4(self):
+    divisor = 2.
+    std = 1e-3
+    shape = (2, 3, 2, 8)
+    m = divisor / float(shape[-1])
+    expected = [
+        [[[5.05617063e-05, 4.99951362e-04, -9.95908980e-04, 6.93598529e-04,
+           -4.18301526e-04, -1.58457726e-03, -6.47706795e-04, 5.98575163e-04],
+          [3.32250027e-04, -1.14747661e-03, 6.18669670e-04, -8.79869258e-05,
+           4.25072387e-04, 3.32253141e-04, -1.15681626e-03, 3.50997143e-04]],
+
+         [[-6.06887275e-04, 1.54697930e-03, 7.23341596e-04, 4.61355667e-05,
+           -9.82991653e-04, 5.44327377e-05, 1.59892938e-04, -1.20894820e-03],
+          [2.22336012e-03, 3.94295203e-04, 1.69235771e-03, -1.11281220e-03,
+           1.63574750e-03, -1.36096554e-03, -6.51225855e-04, 5.42451337e-04]],
+
+         [[4.80062481e-05, -2.35807360e-03, -1.10558409e-03, 8.37836356e-04,
+           2.08787085e-03, 9.14840959e-04, -2.76203355e-04, 7.96511886e-04],
+          [-1.14379858e-03, 5.09919773e-04, -1.34746032e-03, -9.36010019e-06,
+           -1.30704633e-04, 8.02086608e-04, -3.02963977e-04, 1.20200263e-03]]],
+
+        [[[-1.96745284e-04, 8.36528721e-04, 7.86602264e-04, -1.84087583e-03,
+           3.75474883e-05, 3.59280530e-05, -7.78739923e-04, 1.79410708e-04],
+          [-1.45553437e-03, 5.56185201e-04, 5.09778853e-04, 3.00445536e-04,
+           2.47658417e-03, 3.52343399e-04, 6.74710027e-05, -7.32264714e-04]],
+
+         [[m, m, m, m,
+           1.58469542e-04, 1.99008291e-03, 1.16418756e-03, 2.42660157e-04],
+          [1.37992005e-03, -5.45587063e-05, 7.95233937e-04, 1.90899627e-05,
+           m, m, m, m]],
+
+         [[-1.09712186e-03, -5.28196048e-04, -2.37977528e-03, -6.07683673e-04,
+           -1.07529014e-03, 2.02240516e-03, -5.64875314e-04, -1.54292909e-03],
+          [8.70841788e-04, -1.75210531e-04, 4.86030076e-05, 1.88646198e-04,
+           2.09313483e-04, -3.74444906e-04, 9.54698597e-04, 5.23247640e-04]]]
+    ]
+
+    self.IdentityInitializerHelper(shape, expected, divisor, std)
+
+
 if __name__ == '__main__':
   googletest.main()
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/master-spec b/research/syntaxnet/dragnn/python/perf_test_data/master-spec
new file mode 100644
index 00000000..6f50eaed
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/perf_test_data/master-spec
@@ -0,0 +1,171 @@
+component {
+  name: "convnet"
+  transition_system {
+    registered_name: "shift-only"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "lexifuse-repository"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexifuse-repository/repository"
+      file_format: "repository"
+      record_format: "entity"
+    }
+  }
+  resource {
+    name: "brain-parser-model"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/brain-parser-model"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "transition-system-data"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/transition-system-data"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "words-embedding-input"
+    part {
+      file_pattern: "/readahead/512M/cns/lg-d/home/saft/corpora/word-embeddings/en/word2vec/1billion/word2vec-embedding-bi-true-32.sst"
+      file_format: "sstable"
+      record_format: "dist_belief.TokenEmbedding"
+    }
+  }
+  resource {
+    name: "words-vocab-input"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.model-init/vocab"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "component-builder-module"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.convnet.component-builder-module/module-spec"
+      file_format: "pbtxt"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "char_ngram"
+    fml: "input.token.lexifuse-char-ngram"
+    embedding_dim: 16
+    vocabulary_size: 16500
+    size: 1
+    predicate_map: "hashed"
+  }
+  fixed_feature {
+    name: "words"
+    fml: "input.word"
+    embedding_dim: 32
+    vocabulary_size: 39395
+    size: 1
+    predicate_map: "hashed"
+  }
+  network_unit {
+    registered_name: "IdentityNetwork"
+  }
+  backend {
+    registered_name: "ParserComponent"
+  }
+  num_actions: 1
+  attention_component: ""
+  component_builder {
+    registered_name: "components.common.dragnn.python.conv_component.ConvComponentBuilder"
+    parameters {
+      key: "depths"
+      value: "48,128"
+    }
+    parameters {
+      key: "output_dims"
+      value: "45"
+    }
+    parameters {
+      key: "widths"
+      value: "7"
+    }
+  }
+  training_beam_size: 1
+  inference_beam_size: 1
+}
+component {
+  name: "tagger"
+  transition_system {
+    registered_name: "tagger"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "tag-map"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexicon/tag-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "lexifuse-repository"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/lexifuse.lexifuse-repository/repository"
+      file_format: "repository"
+      record_format: "entity"
+    }
+  }
+  resource {
+    name: "brain-parser-model"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.model-init/brain-parser-model"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "transition-system-data"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.model-init/transition-system-data"
+      file_format: "model"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "component-builder-module"
+    part {
+      file_pattern: "/cns/lg-d/home/chrisalberti/e/conv/dragnn-parser.tagger.component-builder-module/module-spec"
+      file_format: "pbtxt"
+      record_format: ""
+    }
+  }
+  linked_feature {
+    name: "convnet"
+    fml: "input.focus"
+    embedding_dim: -1
+    size: 1
+    source_component: "convnet"
+    source_translator: "identity"
+    source_layer: "conv0_logits"
+  }
+  network_unit {
+    registered_name: "IdentityNetwork"
+  }
+  backend {
+    registered_name: "ParserComponent"
+  }
+  num_actions: 45
+  attention_component: ""
+  component_builder {
+    registered_name: "bulk_component.BulkAnnotatorComponentBuilder"
+  }
+  training_beam_size: 1
+  inference_beam_size: 1
+}
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/params b/research/syntaxnet/dragnn/python/perf_test_data/params
new file mode 100644
index 00000000..62fd9d27
Binary files /dev/null and b/research/syntaxnet/dragnn/python/perf_test_data/params differ
diff --git a/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle b/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle
new file mode 100644
index 00000000..842ad77d
Binary files /dev/null and b/research/syntaxnet/dragnn/python/perf_test_data/sample_docs.pickle differ
diff --git a/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py b/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
index 5dfb0013..beac7c97 100644
--- a/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
+++ b/research/syntaxnet/dragnn/python/render_spec_with_graphviz_test.py
@@ -28,7 +28,7 @@ from dragnn.python import spec_builder
 def _make_basic_master_spec():
   """Constructs a simple spec.
 
-  Modified version of nlp/saft/opensource/dragnn/tools/parser_trainer.py
+  Modified version of dragnn/tools/parser_trainer.py
 
   Returns:
     spec_pb2.MasterSpec instance.
diff --git a/research/syntaxnet/dragnn/python/sentence_io.py b/research/syntaxnet/dragnn/python/sentence_io.py
index 6f70c98c..534ee54b 100644
--- a/research/syntaxnet/dragnn/python/sentence_io.py
+++ b/research/syntaxnet/dragnn/python/sentence_io.py
@@ -18,21 +18,26 @@ import tensorflow as tf
 from syntaxnet.ops import gen_parser_ops
 
 
-class ConllSentenceReader(object):
-  """A reader for conll files, with optional projectivizing."""
+class FormatSentenceReader(object):
+  """A reader for formatted files, with optional projectivizing."""
 
-  def __init__(self, filepath, batch_size=32,
-               projectivize=False, morph_to_pos=False):
+  def __init__(self,
+               filepath,
+               record_format,
+               batch_size=32,
+               check_well_formed=False,
+               projectivize=False,
+               morph_to_pos=False):
     self._graph = tf.Graph()
     self._session = tf.Session(graph=self._graph)
     task_context_str = """
           input {
             name: 'documents'
-            record_format: 'conll-sentence'
+            record_format: '%s'
             Part {
              file_pattern: '%s'
             }
-          }""" % filepath
+          }""" % (record_format, filepath)
     if morph_to_pos:
       task_context_str += """
           Parameter {
@@ -51,7 +56,8 @@ class ConllSentenceReader(object):
     with self._graph.as_default():
       self._source, self._is_last = gen_parser_ops.document_source(
           task_context_str=task_context_str, batch_size=batch_size)
-      self._source = gen_parser_ops.well_formed_filter(self._source)
+      if check_well_formed:
+        self._source = gen_parser_ops.well_formed_filter(self._source)
       if projectivize:
         self._source = gen_parser_ops.projectivize_filter(self._source)
 
@@ -77,3 +83,20 @@ class ConllSentenceReader(object):
         break
     tf.logging.info('Read %d sentences.' % len(corpus))
     return corpus
+
+
+class ConllSentenceReader(FormatSentenceReader):
+  """A sentence reader that uses an underlying 'conll-sentence' reader."""
+
+  def __init__(self,
+               filepath,
+               batch_size=32,
+               projectivize=False,
+               morph_to_pos=False):
+    super(ConllSentenceReader, self).__init__(
+        filepath,
+        'conll-sentence',
+        check_well_formed=True,
+        batch_size=batch_size,
+        projectivize=projectivize,
+        morph_to_pos=morph_to_pos)
diff --git a/research/syntaxnet/dragnn/python/sentence_io_test.py b/research/syntaxnet/dragnn/python/sentence_io_test.py
index f7adc0ad..305158f1 100644
--- a/research/syntaxnet/dragnn/python/sentence_io_test.py
+++ b/research/syntaxnet/dragnn/python/sentence_io_test.py
@@ -19,16 +19,19 @@ import tensorflow as tf
 from tensorflow.python.framework import test_util
 from tensorflow.python.platform import googletest
 
+from dragnn.python import dragnn_ops
+
 from dragnn.python import sentence_io
 from syntaxnet import sentence_pb2
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 class ConllSentenceReaderTest(test_util.TensorFlowTestCase):
diff --git a/research/syntaxnet/dragnn/python/spec_builder.py b/research/syntaxnet/dragnn/python/spec_builder.py
index 08ae2bcc..718931f3 100644
--- a/research/syntaxnet/dragnn/python/spec_builder.py
+++ b/research/syntaxnet/dragnn/python/spec_builder.py
@@ -174,16 +174,22 @@ class ComponentSpecBuilder(object):
     """Shorthand to add a fixed_feature using kwargs."""
     self.spec.fixed_feature.add(**kwargs)
 
-  def add_link(self, source, source_layer=None, source_translator='identity',
-               name=None, **kwargs):
+  def add_link(self,
+               source,
+               source_layer=None,
+               source_translator='identity',
+               name=None,
+               **kwargs):
     """Add a link using default naming and layers only."""
     if source_layer is None:
       source_layer = source.default_source_layer()
     if name is None:
       name = source.spec.name
     self.spec.linked_feature.add(
-        source_component=source.spec.name, source_layer=source_layer,
-        name=name, source_translator=source_translator,
+        source_component=source.spec.name,
+        source_layer=source_layer,
+        name=name,
+        source_translator=source_translator,
         **kwargs)
 
   def fill_from_resources(self, resource_path, tf_master=''):
@@ -209,13 +215,18 @@ class ComponentSpecBuilder(object):
         'Set a transition system before calling fill_from_resources().')
 
     context = lexicon.create_lexicon_context(resource_path)
+
+    # If there are any transition system-specific params or resources,
+    # copy them over into the context.
+    for resource in self.spec.resource:
+      context.input.add(name=resource.name).part.add(
+          file_pattern=resource.part[0].file_pattern)
     for key, value in self.spec.transition_system.parameters.iteritems():
       context.parameter.add(name=key, value=value)
 
     context.parameter.add(
         name='brain_parser_embedding_dims',
-        value=';'.join(
-            [str(x.embedding_dim) for x in self.spec.fixed_feature]))
+        value=';'.join([str(x.embedding_dim) for x in self.spec.fixed_feature]))
     context.parameter.add(
         name='brain_parser_features',
         value=';'.join([x.fml for x in self.spec.fixed_feature]))
@@ -243,6 +254,7 @@ class ComponentSpecBuilder(object):
       self.spec.linked_feature[i].size = len(
           self.spec.linked_feature[i].fml.split(' '))
 
+    del self.spec.resource[:]
     for resource in context.input:
       self.spec.resource.add(name=resource.name).part.add(
           file_pattern=resource.part[0].file_pattern)
diff --git a/research/syntaxnet/dragnn/python/spec_builder_test.py b/research/syntaxnet/dragnn/python/spec_builder_test.py
index abae0120..4b5e9693 100644
--- a/research/syntaxnet/dragnn/python/spec_builder_test.py
+++ b/research/syntaxnet/dragnn/python/spec_builder_test.py
@@ -27,13 +27,14 @@ from dragnn.python import spec_builder
 
 from syntaxnet import parser_trainer
 
-import syntaxnet.load_parser_ops
-
 FLAGS = tf.app.flags.FLAGS
-if not hasattr(FLAGS, 'test_srcdir'):
-  FLAGS.test_srcdir = ''
-if not hasattr(FLAGS, 'test_tmpdir'):
-  FLAGS.test_tmpdir = tf.test.get_temp_dir()
+
+
+def setUpModule():
+  if not hasattr(FLAGS, 'test_srcdir'):
+    FLAGS.test_srcdir = ''
+  if not hasattr(FLAGS, 'test_tmpdir'):
+    FLAGS.test_tmpdir = tf.test.get_temp_dir()
 
 
 class SpecBuilderTest(tf.test.TestCase):
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map
new file mode 100644
index 00000000..90abab4f
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.char-ngram-map
@@ -0,0 +1,9943 @@
+9942
+e 15965
+a 14481
+t 13195
+l 10226
+s 9856
+n 9295
+k 8323
+z 7517
+i 7336
+r 7230
+o 6691
+á 6265
+é 5700
+g 5129
+m 5093
+y 3359
+b 3341
+v 3177
+d 3166
+sz 2925
+el 2499
+h 2290
+, 2250
+en 1925
+et 1899
+ö 1880
+j 1827
+ó 1744
+gy 1727
+u 1683
+p 1670
+er 1584
+ő 1567
+te 1549
+le 1475
+. 1465
+ze 1387
+és 1358
+eg 1357
+al 1355
+az 1338
+an 1331
+at 1310
+f 1299
+c 1271
+ta 1241
+tt 1192
+ak 1163
+ek 1154
+me 1032
+ár 1029
+or 1027
+ne 1017
+re 983
+em 980
+ke 977
+es 970
+nt 962
+la 960
+ny 952
+is 930
+ál 929
+be 923
+í 900
+ás 894
+ve 886
+in 884
+ü 883
+tá 872
+on 867
+ll 857
+ko 843
+án 834
+lt 829
+ol 809
+na 780
+mi 763
+sze 763
+A 758
+zt 756
+os 751
+ez 738
+se 729
+ok 710
+rt 709
+ra 697
+ba 690
+to 688
+ar 673
+ég 662
+én 662
+té 660
+kö 644
+zá 640
+ér 638
+ha 635
+ka 635
+ik 603
+cs 585
+og 582
+ho 580
+ly 579
+ot 568
+sa 557
+lá 555
+sé 554
+ag 544
+ye 543
+de 540
+egy 536
+át 533
+ül 529
+za 526
+ú 522
+ni 520
+vá 516
+ti 514
+ki 513
+- 510
+va 509
+nd 508
+sá 504
+lé 498
+ma 497
+zo 497
+bb 496
+am 493
+ké 492
+ro 491
+ág 490
+oz 487
+él 486
+ban 484
+má 484
+ri 478
+zer 478
+as 473
+ga 472
+ít 460
+ét 453
+li 451
+meg 446
+he 443
+ad 438
+so 435
+ed 433
+ben 427
+ék 421
+szá 419
+tó 417
+il 415
+ett 407
+szt 405
+nak 398
+ya 398
+mé 395
+ele 394
+st 388
+öz 388
+ogy 383
+int 382
+ott 382
+fe 380
+fo 380
+nek 378
+ap 373
+hog 358
+nem 357
+len 355
+zet 354
+it 350
+ere 349
+ge 344
+köz 341
+ja 338
+ss 335
+ség 334
+zé 330
+tő 328
+ut 323
+vé 322
+kor 321
+je 320
+— 320
+rá 317
+ű 315
+já 314
+ai 311
+mo 311
+agy 310
+si 309
+vi 307
+da 306
+ig 306
+áll 303
+ság 302
+rs 301
+áb 301
+do 300
+tás 300
+di 299
+let 299
+ány 297
+M 294
+1 293
+ter 285
+pe 283
+lő 280
+min 277
+nk 277
+tö 276
+0 273
+ák 273
+ul 272
+ör 272
+po 270
+K 268
+év 266
+tet 265
+om 264
+aj 259
+né 258
+eze 256
+gya 255
+ép 251
+ól 251
+szo 248
+tal 248
+zi 247
+áz 247
+lm 246
+rd 246
+ala 244
+ia 244
+ell 243
+rm 243
+ely 242
+esz 242
+yi 240
+lk 238
+ért 238
+ény 237
+E 236
+hat 235
+9 231
+tés 231
+fel 230
+nn 230
+dé 229
+S 227
+gye 227
+us 225
+mel 223
+tel 223
+ci 222
+isz 222
+vo 222
+lle 221
+ln 220
+go 219
+leg 218
+sza 218
+elő 216
+gi 215
+yo 215
+ész 215
+ete 214
+het 213
+pa 212
+" 209
+iá 208
+gé 206
+ts 205
+öv 205
+dá 204
+osz 203
+tot 203
+ám 202
+ab 201
+ló 201
+vez 201
+ió 200
+gá 199
+rin 199
+eke 198
+rv 198
+iz 197
+lo 197
+ná 196
+ent 195
+ká 195
+lla 194
+ill 193
+vál 192
+id 189
+ren 189
+bi 186
+mb 186
+ró 186
+eh 184
+hi 183
+ré 183
+ato 182
+kk 182
+Az 181
+ev 181
+ön 181
+ök 180
+B 179
+no 179
+ld 178
+nye 178
+2 177
+csa 177
+ált 177
+vet 176
+ése 176
+öt 176
+ov 175
+atá 174
+sok 174
+tat 174
+ros 173
+asz 172
+kat 172
+mán 172
+há 171
+olt 171
+zö 170
+val 169
+tu 168
+ked 167
+ők 167
+T 166
+ssz 164
+tár 164
+ei 163
+eté 163
+lés 161
+un 161
+end 160
+ir 160
+ng 160
+ker 159
+ető 158
+tte 158
+zó 157
+ől 157
+ind 156
+lat 156
+nc 156
+for 154
+már 154
+dt 153
+eri 152
+rb 151
+ésé 151
+kel 150
+mag 150
+nte 150
+tk 150
+ős 150
+lam 149
+áro 149
+alá 148
+rü 148
+av 147
+ene 147
+kez 147
+tj 147
+tl 147
+ese 145
+gaz 145
+jel 145
+koz 145
+ls 145
+ége 145
+nö 144
+öve 144
+ame 143
+lta 143
+tek 143
+ára 143
+ásá 143
+art 142
+tta 140
+hel 139
+G 138
+dő 138
+elm 138
+mu 138
+zd 138
+ej 137
+orm 137
+rül 137
+ték 137
+zte 137
+ami 136
+kb 136
+H 135
+ont 135
+éb 135
+öl 135
+ös 135
+ző 134
+nde 133
+bo 132
+emb 132
+sak 132
+sen 132
+tak 132
+ába 132
+elé 131
+mbe 131
+ós 131
+ors 130
+ír 130
+ató 129
+kü 129
+lj 129
+tn 129
+áso 129
+lás 128
+zn 128
+zon 128
+ber 127
+eti 127
+ku 127
+th 127
+kr 126
+mil 126
+rsz 126
+ók 126
+dés 125
+rő 125
+tr 125
+zal 125
+P 124
+ket 124
+nag 124
+rg 124
+rr 124
+vol 124
+éve 124
+att 123
+hoz 123
+mű 123
+rmá 123
+ud 123
+5 122
+fő 122
+áj 122
+lye 121
+ug 121
+záz 121
+: 120
+elt 120
+gat 120
+lli 120
+lék 120
+tán 120
+tör 120
+áza 120
+dó 119
+iv 119
+zta 119
+zü 119
+új 119
+zám 118
+V 117
+eb 117
+ep 117
+tik 117
+ztá 117
+ött 117
+tar 116
+yan 116
+éle 116
+ara 115
+ata 115
+lát 115
+vel 115
+asá 114
+ehe 114
+kül 114
+tes 114
+zen 114
+fi 113
+od 113
+tan 113
+ond 112
+éte 112
+3 111
+pé 111
+zel 111
+fog 110
+lí 110
+szé 110
+zot 110
+úl 110
+F 109
+öb 109
+alé 108
+est 108
+kén 108
+lg 108
+zs 108
+zág 108
+19 107
+dig 107
+lv 107
+ob 107
+sí 107
+vár 107
+yar 107
+zem 107
+ása 107
+mén 106
+rk 106
+sk 106
+ten 106
+unk 106
+vis 106
+zl 106
+ébe 106
+öbb 106
+D 105
+I 105
+bá 105
+ció 105
+oro 105
+uk 105
+ác 105
+éne 105
+ava 104
+még 104
+nap 104
+ént 104
+ót 104
+erü 103
+lap 103
+rn 103
+dás 102
+ert 102
+kt 102
+pr 102
+özö 102
+rté 101
+ső 101
+ves 101
+erv 100
+tv 100
+ább 100
+N 99
+eln 99
+eme 99
+nz 99
+res 99
+töb 99
+zat 99
+zás 99
+els 98
+kép 98
+őr 98
+gyo 97
+lak 97
+sem 97
+lít 96
+nté 96
+nyi 96
+oka 96
+rés 96
+őt 96
+azo 95
+dol 95
+gyi 95
+két 95
+lh 95
+oly 95
+sít 95
+zés 95
+Ma 94
+men 94
+szi 94
+vő 94
+yt 94
+ítá 94
+kn 93
+sek 93
+tsé 93
+kal 92
+kos 92
+pá 92
+ób 92
+ur 91
+L 90
+enn 90
+ezé 90
+más 90
+nál 90
+tos 90
+ac 89
+mon 89
+nis 89
+ták 89
+R 88
+aka 88
+alk 88
+edi 88
+par 88
+uta 88
+zí 88
+ére 88
+( 87
+) 87
+ce 87
+cse 87
+den 87
+ege 87
+lte 87
+rz 87
+tok 87
+ána 87
+7 86
+azt 86
+edé 86
+jo 86
+ju 86
+ját 86
+lem 86
+yá 86
+üg 86
+aki 85
+ani 85
+bel 85
+leh 85
+ns 85
+tle 85
+zz 85
+ála 85
+4 84
+ori 84
+osa 84
+sb 84
+tb 84
+éz 84
+99 83
+Z 83
+iu 83
+jé 83
+oga 83
+tén 83
+zak 83
+áv 83
+ült 83
+abb 82
+gs 82
+lal 82
+les 82
+lko 82
+llá 82
+nyo 82
+nök 82
+olg 82
+ton 82
+um 82
+ági 82
+cé 81
+jd 81
+ály 80
+ési 80
+öss 80
+Sz 79
+eve 79
+gb 79
+ic 79
+pi 79
+rl 79
+rán 79
+szü 79
+vég 79
+yen 79
+ód 79
+azd 78
+bó 78
+cso 78
+du 78
+get 78
+gr 78
+ie 78
+kör 78
+utó 78
+adá 77
+del 77
+kér 77
+las 77
+mer 77
+utá 77
+árs 77
+ív 77
+8 76
+ah 76
+ajd 76
+dta 76
+ebb 76
+elk 76
+ezt 76
+rve 76
+ágo 76
+ási 76
+ügy 76
+ede 75
+etl 75
+jt 75
+ják 75
+jö 75
+kon 75
+lan 75
+00 74
+apo 74
+im 74
+ort 74
+ru 74
+tja 74
+vek 74
+6 73
+au 73
+biz 73
+erb 73
+iár 73
+lső 73
+ról 73
+san 73
+zér 73
+ém 73
+út 73
+J 72
+egé 72
+ide 72
+ika 72
+lnö 72
+lya 72
+ony 72
+rsa 72
+sor 72
+szí 72
+yb 72
+zda 72
+alm 71
+ból 71
+das 71
+kí 71
+laj 71
+nb 71
+nto 71
+rö 71
+yé 71
+árd 71
+adó 70
+dik 70
+llí 70
+yes 70
+zöt 70
+éke 70
+ük 70
+üle 70
+199 69
+alo 69
+köv 69
+mos 69
+ozt 69
+van 69
+éko 69
+ór 69
+O 68
+bbi 68
+gn 68
+ken 68
+liá 68
+nok 68
+ola 68
+rto 68
+sel 68
+tem 68
+árt 68
+érd 68
+íté 68
+Mi 67
+dö 67
+ező 67
+mun 67
+nne 67
+nya 67
+ová 67
+ped 67
+rte 67
+yel 67
+ys 67
+zül 67
+ch 66
+dn 66
+han 66
+ib 66
+lek 66
+lis 66
+nna 66
+tm 66
+ván 66
+vén 66
+yer 66
+égi 66
+emé 65
+kés 65
+mm 65
+pes 65
+su 65
+tér 65
+yek 65
+yz 65
+zik 65
+zk 65
+ást 65
+őz 65
+ako 64
+fé 64
+gal 64
+kka 64
+lö 64
+pol 64
+szl 64
+tők 64
+vil 64
+ély 64
+ölt 64
+Ko 63
+ann 63
+ks 63
+mú 63
+ncs 63
+rc 63
+ult 63
+zek 63
+ati 62
+dj 62
+don 62
+erm 62
+gál 62
+kba 62
+mér 62
+oss 62
+ozó 62
+rh 62
+rom 62
+yet 62
+égé 62
+ój 62
+ház 61
+kar 61
+lke 61
+ozá 61
+pon 61
+tha 61
+zab 61
+ülé 61
+őd 61
+ec 60
+fö 60
+gl 60
+ilá 60
+ini 60
+lom 60
+nl 60
+obb 60
+pí 60
+zto 60
+ef 59
+emz 59
+gf 59
+gu 59
+iga 59
+jár 59
+lü 59
+mz 59
+nti 59
+por 59
+ről 59
+sú 59
+tób 59
+áci 59
+-e 58
+akk 58
+etn 58
+fol 58
+föl 58
+gv 58
+ise 58
+kra 58
+lel 58
+met 58
+nél 58
+sü 58
+tud 58
+zol 58
+zál 58
+ést 58
+ón 58
+ün 58
+C 57
+ank 57
+egf 57
+etk 57
+hé 57
+iva 57
+kko 57
+lf 57
+lna 57
+mar 57
+nos 57
+oli 57
+sik 57
+szó 57
+tjá 57
+ugy 57
+vat 57
+épe 57
+bu 56
+gt 56
+kai 56
+kap 56
+lma 56
+mí 56
+sal 56
+sét 56
+yik 56
+dr 55
+ds 55
+elj 55
+erő 55
+gg 55
+lts 55
+op 55
+pro 55
+rat 55
+tsz 55
+yn 55
+bba 54
+bő 54
+elv 54
+enc 54
+evé 54
+gh 54
+gés 54
+iku 54
+ip 54
+ján 54
+jöv 54
+kus 54
+oko 54
+pít 54
+ran 54
+sr 54
+tók 54
+tü 54
+usz 54
+ói 54
+bor 53
+fa 53
+lb 53
+lmi 53
+lág 53
+nu 53
+okb 53
+pén 53
+rbe 53
+rde 53
+rek 53
+sm 53
+sol 53
+son 53
+ste 53
+teg 53
+tál 53
+tú 53
+von 53
+zár 53
+ád 53
+őtt 53
+Ez 52
+eny 52
+hó 52
+kes 52
+lőt 52
+oc 52
+ret 52
+ámo 52
+ört 52
+-b 51
+adt 51
+cég 51
+dul 51
+ess 51
+jó 51
+kbe 51
+kke 51
+lál 51
+ord 51
+rvé 51
+rás 51
+sát 51
+tól 51
+ver 51
+zok 51
+zv 51
+öd 51
+20 50
+ali 50
+egn 50
+egs 50
+eng 50
+izá 50
+múl 50
+ndo 50
+ost 50
+ozo 50
+tko 50
+tor 50
+zg 50
+zor 50
+zté 50
+énz 50
+últ 50
+ada 49
+aro 49
+arr 49
+eli 49
+gsz 49
+iat 49
+mik 49
+ono 49
+rep 49
+rme 49
+rra 49
+set 49
+sn 49
+vag 49
+vas 49
+övő 49
+ői 49
+őv 49
+ang 48
+fej 48
+ges 48
+gj 48
+hal 48
+iti 48
+kad 48
+lha 48
+omá 48
+per 48
+sér 48
+éd 48
+öld 48
+örö 48
+őb 48
+aga 47
+aza 47
+dal 47
+dot 47
+ize 47
+lit 47
+mia 47
+rú 47
+ssá 47
+szö 47
+yk 47
+zm 47
+íg 47
+íto 47
+ana 46
+ari 46
+ből 46
+dv 46
+eré 46
+has 46
+ism 46
+ist 46
+kol 46
+lad 46
+lió 46
+lu 46
+nf 46
+orá 46
+pp 46
+rj 46
+sba 46
+ssé 46
+ven 46
+yv 46
+zni 46
+óp 46
+ülö 46
+Mag 45
+agá 45
+atk 45
+bán 45
+det 45
+ers 45
+hez 45
+jl 45
+kv 45
+lgá 45
+lni 45
+lán 45
+rta 45
+sár 45
+tve 45
+tí 45
+zp 45
+ín 45
+íte 45
+üt 45
+ama 44
+gna 44
+hí 44
+kis 44
+kna 44
+lje 44
+lyi 44
+mat 44
+mok 44
+mét 44
+nka 44
+oln 44
+tla 44
+ula 44
+ysz 44
+zb 44
+zin 44
+áli 44
+ósá 44
+U 43
+dsz 43
+dí 43
+ekb 43
+eni 43
+epe 43
+gk 43
+hét 43
+lár 43
+nyt 43
+okr 43
+ona 43
+pü 43
+rad 43
+rgy 43
+rke 43
+tis 43
+uda 43
+váb 43
+vét 43
+yu 43
+ács 43
+ító 43
+óbb 43
+óta 43
+aló 42
+ará 42
+bí 42
+dat 42
+elh 42
+elü 42
+fél 42
+gok 42
+gon 42
+idő 42
+ite 42
+iál 42
+lik 42
+ltá 42
+mut 42
+nká 42
+nő 42
+oll 42
+szk 42
+szn 42
+tbe 42
+tke 42
+yze 42
+áno 42
+őj 42
+Ba 41
+Ha 41
+ane 41
+any 41
+dd 41
+gos 41
+his 41
+ine 41
+lag 41
+lme 41
+lyt 41
+mze 41
+nba 41
+nev 41
+növ 41
+oza 41
+ráb 41
+rök 41
+tol 41
+tét 41
+x 41
+úg 41
+őre 41
+10 40
+and 40
+atj 40
+aut 40
+bes 40
+ela 40
+kia 40
+kin 40
+kár 40
+mít 40
+olá 40
+rem 40
+seb 40
+től 40
+tű 40
+zov 40
+zék 40
+zél 40
+ász 40
+áto 40
+éri 40
+íz 40
+őn 40
+-t 39
+SZ 39
+aho 39
+anc 39
+csi 39
+egk 39
+fon 39
+iko 39
+itá 39
+izo 39
+kot 39
+ldá 39
+net 39
+rak 39
+sai 39
+tős 39
+ub 39
+uró 39
+yez 39
+éld 39
+óz 39
+őké 39
+űk 39
+bs 38
+dek 38
+dez 38
+ené 38
+gba 38
+gys 38
+gyé 38
+gár 38
+hiv 38
+ina 38
+ire 38
+jes 38
+kul 38
+köl 38
+maj 38
+mél 38
+ozz 38
+pél 38
+rok 38
+roz 38
+sas 38
+ske 38
+sül 38
+toz 38
+vél 38
+zav 38
+zle 38
+zu 38
+zín 38
+áló 38
+ím 38
+öze 38
+ősz 38
+anu 37
+atn 37
+br 37
+cí 37
+cím 37
+ezd 37
+gek 37
+gén 37
+kát 37
+lc 37
+lön 37
+mp 37
+nge 37
+old 37
+oná 37
+pj 37
+pül 37
+rba 37
+sö 37
+tté 37
+tám 37
+vó 37
+ym 37
+yob 37
+yr 37
+üz 37
+ant 36
+apa 36
+bé 36
+ca 36
+ega 36
+gym 36
+gó 36
+ipa 36
+irá 36
+jdo 36
+kne 36
+lgo 36
+lhe 36
+lyo 36
+ml 36
+mó 36
+ndt 36
+ndő 36
+nny 36
+nyb 36
+onb 36
+ser 36
+ssa 36
+t. 36
+tam 36
+the 36
+tra 36
+yak 36
+ári 36
+Fe 35
+aná 35
+ea 35
+ejé 35
+elf 35
+etv 35
+goz 35
+har 35
+kc 35
+köd 35
+köt 35
+mes 35
+mis 35
+pt 35
+ron 35
+sko 35
+sl 35
+tag 35
+tav 35
+tov 35
+tós 35
+yü 35
+zga 35
+ága 35
+ágb 35
+érk 35
+örv 35
+őe 35
+0- 34
+aly 34
+co 34
+esü 34
+hol 34
+ntő 34
+odá 34
+pv 34
+rel 34
+rla 34
+ror 34
+rre 34
+róp 34
+sta 34
+tiz 34
+tul 34
+táv 34
+téz 34
+ybe 34
+yű 34
+Á 34
+álá 34
+ámí 34
+áva 34
+éh 34
+élk 34
+önt 34
+özt 34
+őke 34
+Bu 33
+Or 33
+ajt 33
+alb 33
+amo 33
+ciá 33
+dem 33
+egt 33
+emo 33
+erz 33
+esk 33
+gad 33
+gas 33
+hiá 33
+if 33
+ike 33
+iká 33
+jut 33
+jén 33
+kci 33
+lja 33
+lég 33
+maz 33
+mód 33
+műk 33
+nes 33
+nko 33
+ném 33
+pia 33
+pu 33
+red 33
+rű 33
+sén 33
+tna 33
+tsá 33
+tti 33
+uá 33
+vés 33
+áts 33
+égv 33
+éme 33
+íta 33
+ője 33
+-be 32
+Me 32
+ado 32
+ape 32
+bbe 32
+dni 32
+enk 32
+esí 32
+etb 32
+gel 32
+got 32
+iac 32
+idé 32
+inc 32
+ing 32
+izt 32
+ián 32
+kh 32
+lez 32
+láb 32
+nci 32
+nds 32
+pen 32
+tne 32
+tni 32
+yne 32
+zh 32
+óv 32
+özi 32
+özl 32
+úgy 32
+ően 32
+űv 32
+200 31
+Cs 31
+Ga 31
+Gy 31
+Ka 31
+all 31
+apj 31
+bev 31
+dön 31
+edd 31
+eje 31
+fen 31
+gen 31
+iss 31
+ius 31
+jn 31
+lsz 31
+lyn 31
+lép 31
+orv 31
+ppe 31
+pár 31
+rtá 31
+sab 31
+seh 31
+tkö 31
+yta 31
+ábo 31
+áma 31
+áró 31
+óa 31
+ójá 31
+ópa 31
+-k 30
+30 30
+Kö 30
+ae 30
+ajá 30
+csö 30
+dap 30
+dáu 30
+ens 30
+erk 30
+err 30
+ezn 30
+gm 30
+gyü 30
+gz 30
+hár 30
+ics 30
+ila 30
+kl 30
+kre 30
+kít 30
+kív 30
+man 30
+osí 30
+ovó 30
+pvi 30
+rmé 30
+til 30
+É 30
+áu 30
+ául 30
+épí 30
+óna 30
+ütt 30
+űkö 30
+Eg 29
+Sze 29
+ajn 29
+ass 29
+bal 29
+bbs 29
+bsé 29
+cél 29
+enz 29
+erg 29
+ex 29
+gra 29
+gve 29
+gyá 29
+kó 29
+lda 29
+lev 29
+lmé 29
+lyz 29
+lér 29
+lét 29
+lül 29
+műv 29
+nyu 29
+orl 29
+rsé 29
+rtó 29
+rős 29
+sei 29
+tre 29
+tvá 29
+túl 29
+vit 29
+yos 29
+zzá 29
+zít 29
+éká 29
+épp 29
+épv 29
+óg 29
+ősé 29
+ale 28
+alt 28
+apí 28
+dar 28
+dve 28
+dén 28
+egh 28
+eit 28
+eki 28
+ets 28
+eá 28
+haj 28
+ily 28
+isk 28
+jú 28
+kik 28
+kod 28
+kön 28
+l- 28
+lej 28
+lto 28
+lté 28
+mba 28
+mek 28
+nik 28
+nv 28
+orú 28
+ozn 28
+rit 28
+sv 28
+tas 28
+uto 28
+yh 28
+yre 28
+yéb 28
+yüt 28
+zbe 28
+zsé 28
+zól 28
+árg 28
+árm 28
+áss 28
+ója 28
+ővá 28
+űs 28
+Egy 27
+Min 27
+Ta 27
+aké 27
+akí 27
+aso 27
+atl 27
+azg 27
+baj 27
+bet 27
+bl 27
+ddi 27
+des 27
+dja 27
+ejl 27
+ekr 27
+emm 27
+esé 27
+gfe 27
+gyű 27
+gép 27
+jáb 27
+kan 27
+mad 27
+mr 27
+ner 27
+nh 27
+ogl 27
+org 27
+r- 27
+rdu 27
+rdé 27
+rga 27
+rha 27
+rál 27
+sme 27
+sán 27
+teh 27
+tom 27
+tts 27
+yba 27
+yil 27
+yom 27
+zán 27
+zú 27
+ágá 27
+árn 27
+élt 27
+üli 27
+ür 27
+űl 27
+? 26
+Bud 26
+W 26
+aku 26
+bef 26
+bek 26
+cia 26
+epü 26
+eu 26
+ged 26
+gí 26
+iai 26
+io 26
+itk 26
+jr 26
+kit 26
+ksz 26
+ldi 26
+ljá 26
+lké 26
+lkü 26
+mit 26
+moz 26
+nda 26
+nia 26
+ntj 26
+nul 26
+orb 26
+pc 26
+saj 26
+seg 26
+sse 26
+sti 26
+stá 26
+tba 26
+ttá 26
+uár 26
+vás 26
+w 26
+yag 26
+yf 26
+yol 26
+yug 26
+yve 26
+ánt 26
+árá 26
+ásr 26
+óba 26
+ökk 26
+Ki 25
+Ne 25
+aba 25
+api 25
+bír 25
+dh 25
+dos 25
+dál 25
+dőr 25
+ecs 25
+edv 25
+egi 25
+fiz 25
+főv 25
+ger 25
+gla 25
+gre 25
+gán 25
+gér 25
+haz 25
+ium 25
+jav 25
+jog 25
+jra 25
+kok 25
+kő 25
+los 25
+lov 25
+ltó 25
+mt 25
+ndi 25
+nle 25
+nác 25
+okk 25
+orr 25
+pcs 25
+sap 25
+sra 25
+sök 25
+tit 25
+tél 25
+up 25
+yei 25
+zmé 25
+zna 25
+zza 25
+ábó 25
+ájá 25
+érő 25
+évi 25
+így 25
+író 25
+ódo 25
+örü 25
+ünt 25
+űz 25
+-es 24
+Kf 24
+Mo 24
+Va 24
+ain 24
+ait 24
+dok 24
+ekk 24
+erh 24
+gfo 24
+ih 24
+ili 24
+ito 24
+iós 24
+jno 24
+kiv 24
+lló 24
+lvá 24
+lyb 24
+mot 24
+nj 24
+ntr 24
+néz 24
+oci 24
+olj 24
+oma 24
+onn 24
+pet 24
+rab 24
+rny 24
+rol 24
+sh 24
+sla 24
+ty 24
+táb 24
+tőe 24
+ulá 24
+yed 24
+yoz 24
+yö 24
+zde 24
+zes 24
+zlo 24
+zoc 24
+ája 24
+ámá 24
+óan 24
+úr 24
+űn 24
+El 23
+Köz 23
+Ti 23
+acs 23
+apc 23
+arc 23
+bad 23
+dei 23
+dm 23
+dre 23
+dte 23
+dék 23
+dós 23
+enl 23
+era 23
+erű 23
+ezi 23
+gle 23
+gyk 23
+gü 23
+hát 23
+hír 23
+iad 23
+igy 23
+imi 23
+jan 23
+lfo 23
+lka 23
+lve 23
+lyá 23
+lós 23
+lők 23
+mmi 23
+mog 23
+nké 23
+nta 23
+nyá 23
+omb 23
+ons 23
+pál 23
+rev 23
+rhe 23
+rtő 23
+rén 23
+sod 23
+só 23
+táj 23
+tőj 23
+vák 23
+véd 23
+yal 23
+yon 23
+yár 23
+zná 23
+zr 23
+zép 23
+zös 23
+ávo 23
+égy 23
+ékk 23
+újr 23
+1- 22
+97 22
+azé 22
+csá 22
+dz 22
+dél 22
+efo 22
+egm 22
+ein 22
+ekt 22
+eml 22
+etr 22
+gbe 22
+gha 22
+gus 22
+gyv 22
+hón 22
+lcs 22
+lep 22
+lva 22
+lád 22
+lév 22
+máj 22
+nys 22
+nyé 22
+ora 22
+pai 22
+ps 22
+rna 22
+smé 22
+sév 22
+uló 22
+vid 22
+yok 22
+yí 22
+zre 22
+ztó 22
+zze 22
+áju 22
+árh 22
+áth 22
+élé 22
+őbb 22
+,5 21
+Tö 21
+arl 21
+bus 21
+dej 21
+der 21
+dít 21
+elo 21
+ern 21
+eál 21
+fr 21
+gát 21
+gét 21
+gít 21
+hán 21
+inf 21
+ink 21
+jai 21
+jle 21
+jék 21
+kom 21
+káb 21
+kán 21
+lfö 21
+lód 21
+mas 21
+mol 21
+nce 21
+nin 21
+nov 21
+nyk 21
+nyv 21
+nyz 21
+nég 21
+oló 21
+opo 21
+osi 21
+pte 21
+ris 21
+riu 21
+rma 21
+rti 21
+s- 21
+sop 21
+tho 21
+tus 21
+tát 21
+vb 21
+yas 21
+zeg 21
+zvé 21
+zác 21
+álj 21
+ásb 21
+áta 21
+égü 21
+öm 21
+özb 21
+ús 21
+őbe 21
+-i 20
+-á 20
+Gaz 20
+Ho 20
+Já 20
+Nem 20
+abi 20
+aci 20
+adi 20
+ard 20
+bál 20
+edő 20
+ema 20
+erd 20
+eur 20
+gis 20
+gja 20
+gte 20
+gyr 20
+hag 20
+hit 20
+hor 20
+ij 20
+iná 20
+jon 20
+kam 20
+kiá 20
+kál 20
+ldo 20
+lsá 20
+mez 20
+nal 20
+nat 20
+ndu 20
+niu 20
+nsá 20
+nsé 20
+nzé 20
+nü 20
+okn 20
+okt 20
+omo 20
+onl 20
+pat 20
+pok 20
+pán 20
+reg 20
+rge 20
+rni 20
+rog 20
+rvá 20
+rze 20
+rí 20
+sna 20
+sp 20
+sul 20
+sáb 20
+trá 20
+tój 20
+uni 20
+ymi 20
+yő 20
+zlá 20
+zét 20
+zók 20
+züg 20
+áld 20
+álk 20
+átl 20
+éj 20
+éze 20
+ímű 20
+írt 20
+írá 20
+íth 20
+önk 20
+öny 20
+úly 20
+50 19
+Bo 19
+Eu 19
+Eur 19
+ago 19
+akt 19
+asl 19
+azá 19
+bol 19
+cha 19
+dmé 19
+dán 19
+dü 19
+edm 19
+efe 19
+egb 19
+egr 19
+enü 19
+ft 19
+hir 19
+ive 19
+kie 19
+ksé 19
+lbá 19
+lne 19
+lüg 19
+lőr 19
+neg 19
+ngé 19
+nyf 19
+nyí 19
+néh 19
+ocs 19
+oh 19
+oks 19
+olc 19
+pjá 19
+pl 19
+pot 19
+pri 19
+pó 19
+ral 19
+rod 19
+rró 19
+rse 19
+rth 19
+rtj 19
+rvo 19
+szv 19
+súl 19
+tf 19
+téb 19
+vü 19
+yor 19
+yú 19
+yűl 19
+zpo 19
+zpr 19
+áh 19
+éhá 19
+érn 19
+ívá 19
+óva 19
+ög 19
+újt 19
+őzé 19
+űvé 19
+997 18
+Da 18
+En 18
+Fer 18
+Fi 18
+Kft 18
+Pe 18
+a- 18
+abá 18
+adn 18
+aik 18
+akc 18
+azó 18
+bon 18
+dk 18
+döt 18
+egj 18
+egv 18
+egá 18
+egí 18
+ekn 18
+ew 18
+gge 18
+ham 18
+ich 18
+ikt 18
+iro 18
+iáb 18
+job 18
+juk 18
+k- 18
+kil 18
+koc 18
+kta 18
+kás 18
+kőz 18
+lin 18
+liz 18
+lz 18
+lőd 18
+lős 18
+mj 18
+ndó 18
+ngo 18
+nzü 18
+nül 18
+olo 18
+oni 18
+orn 18
+pos 18
+rac 18
+rdá 18
+rác 18
+rát 18
+sbe 18
+sre 18
+séb 18
+t- 18
+tc 18
+tmá 18
+tíz 18
+tük 18
+tűz 18
+utc 18
+vaz 18
+vbe 18
+vos 18
+vt 18
+vül 18
+y- 18
+yít 18
+yör 18
+zan 18
+zep 18
+zkv 18
+zne 18
+zöv 18
+zút 18
+áho 18
+ázt 18
+ésr 18
+ítj 18
+óla 18
+óra 18
+öke 18
+özü 18
+üze 18
+őze 18
+űlé 18
+-s 17
+000 17
+11 17
+5- 17
+7- 17
+An 17
+Br 17
+Tu 17
+aká 17
+amb 17
+atb 17
+bar 17
+bk 17
+bü 17
+cen 17
+ck 17
+ece 17
+ee 17
+ft. 17
+gkö 17
+gás 17
+hál 17
+hív 17
+ial 17
+itt 17
+iut 17
+jeg 17
+kem 17
+kev 17
+kto 17
+leb 17
+lig 17
+lmo 17
+lmú 17
+mai 17
+ms 17
+műs 17
+nam 17
+ndk 17
+nló 17
+nni 17
+nsz 17
+ntá 17
+nék 17
+ní 17
+nös 17
+odi 17
+oo 17
+raj 17
+ram 17
+reá 17
+rkő 17
+rző 17
+rég 17
+rít 17
+svá 17
+szs 17
+tai 17
+tev 17
+tin 17
+tmé 17
+tun 17
+tív 17
+uga 17
+ved 17
+vói 17
+yko 17
+ysé 17
+yás 17
+zed 17
+zsi 17
+ztr 17
+zve 17
+zót 17
+zők 17
+ádi 17
+ájé 17
+áni 17
+égr 17
+éli 17
+élő 17
+ésb 17
+éss 17
+íj 17
+ítm 17
+íts 17
+ödé 17
+öse 17
+özp 17
+özé 17
+őse 17
+-n 16
+2- 16
+Ak 16
+Cse 16
+Er 16
+HV 16
+Mar 16
+NS 16
+NSZ 16
+Po 16
+Re 16
+Rt 16
+Rt. 16
+af 16
+agj 16
+ajl 16
+azp 16
+azz 16
+bké 16
+csu 16
+dne 16
+dzs 16
+díj 16
+erj 16
+győ 16
+hos 16
+hu 16
+ige 16
+isé 16
+jez 16
+kif 16
+ldr 16
+mir 16
+mpo 16
+ndr 16
+nuá 16
+oda 16
+onz 16
+oso 16
+ovi 16
+pad 16
+pel 16
+rf 16
+rlá 16
+rzé 16
+sad 16
+sin 16
+str 16
+sős 16
+uc 16
+udo 16
+uln 16
+uso 16
+vic 16
+viz 16
+yeg 16
+yza 16
+zai 16
+zdő 16
+zhe 16
+zob 16
+zti 16
+zör 16
+zük 16
+ződ 16
+ágg 16
+ánd 16
+árc 16
+ásu 16
+ébk 16
+éde 16
+éka 16
+érs 16
+érz 16
+íc 16
+íci 16
+óf 16
+óka 16
+ökö 16
+öme 16
+önn 16
+önö 16
+ún 16
+őa 16
+12 15
+2, 15
+4- 15
+9- 15
+Am 15
+HVG 15
+Ke 15
+Kl 15
+Kos 15
+Le 15
+Má 15
+VG 15
+Vi 15
+Ze 15
+Zs 15
+aco 15
+adj 15
+ans 15
+bn 15
+dec 15
+doz 15
+drá 15
+dőd 15
+ebe 15
+ebo 15
+edn 15
+ego 15
+eig 15
+eik 15
+exp 15
+fal 15
+fek 15
+fes 15
+fil 15
+fl 15
+fra 15
+gga 15
+gin 15
+gp 15
+gyz 15
+hon 15
+háb 15
+ilt 15
+ion 15
+ita 15
+iój 15
+iók 15
+jab 15
+jus 15
+jét 15
+jól 15
+kas 15
+kov 15
+log 15
+lot 15
+mző 15
+ndé 15
+nió 15
+nki 15
+nth 15
+nyn 15
+nép 15
+nó 15
+omm 15
+onc 15
+ope 15
+ore 15
+osb 15
+ozi 15
+pek 15
+psz 15
+pz 15
+rai 15
+rje 15
+rák 15
+rós 15
+suk 15
+sáv 15
+tné 15
+tog 15
+tév 15
+tői 15
+udt 15
+ugo 15
+uh 15
+uka 15
+uz 15
+xp 15
+xpo 15
+yam 15
+yfő 15
+yit 15
+yőz 15
+zf 15
+zom 15
+zön 15
+Í 15
+Íg 15
+Így 15
+ágr 15
+ái 15
+áko 15
+áln 15
+átá 15
+áté 15
+átó 15
+ázi 15
+émi 15
+éts 15
+évb 15
+évő 15
+ívü 15
+óri 15
+órá 15
+örz 15
+öte 15
+úz 15
+üks 15
+ülf 15
+üln 15
+ünk 15
+őad 15
+! 14
+-c 14
+-f 14
+0. 14
+1, 14
+25 14
+6- 14
+60 14
+8- 14
+80 14
+98 14
+Be 14
+He 14
+Is 14
+La 14
+Na 14
+Pr 14
+Pé 14
+Sza 14
+abo 14
+agu 14
+ate 14
+cem 14
+che 14
+dai 14
+dan 14
+dha 14
+dna 14
+dón 14
+dül 14
+dőb 14
+eké 14
+ept 14
+erc 14
+faj 14
+ggy 14
+ibe 14
+ibo 14
+ji 14
+jön 14
+kek 14
+kho 14
+llt 14
+lp 14
+lr 14
+láv 14
+lén 14
+lőa 14
+mc 14
+més 14
+míg 14
+nfl 14
+nga 14
+nyl 14
+nyú 14
+nér 14
+ogr 14
+otó 14
+pk 14
+pod 14
+pót 14
+rce 14
+rig 14
+riá 14
+rob 14
+sáj 14
+tap 14
+tká 14
+ttó 14
+tóa 14
+tói 14
+túr 14
+vai 14
+vj 14
+vs 14
+vőr 14
+yl 14
+yén 14
+yó 14
+yúj 14
+zéd 14
+zün 14
+Ál 14
+ádo 14
+áls 14
+árb 14
+árk 14
+átt 14
+égb 14
+éhe 14
+ékb 14
+éké 14
+épz 14
+évé 14
+íro 14
+ítő 14
+óll 14
+óm 14
+özv 14
+úja 14
+üld 14
+ülü 14
+üzd 14
+őh 14
+őne 14
+,2 13
+-K 13
+-a 13
+-ba 13
+-sz 13
+-é 13
+.- 13
+9. 13
+96 13
+999 13
+; 13
+Al 13
+EN 13
+ENS 13
+Ján 13
+Li 13
+Lá 13
+Meg 13
+Pi 13
+SP 13
+SZ- 13
+Z- 13
+ajo 13
+akn 13
+apu 13
+asa 13
+bér 13
+bö 13
+csk 13
+csé 13
+dag 13
+edt 13
+ejt 13
+ekv 13
+ezz 13
+fia 13
+fig 13
+fu 13
+fér 13
+főn 13
+gar 13
+gol 13
+grá 13
+guk 13
+gél 13
+gú 13
+hú 13
+iba 13
+ikö 13
+ile 13
+ilm 13
+ivá 13
+jla 13
+jto 13
+kbó 13
+któ 13
+kut 13
+küz 13
+lde 13
+lga 13
+llé 13
+lmá 13
+lon 13
+lub 13
+lác 13
+lám 13
+lői 13
+mcs 13
+mf 13
+miu 13
+mme 13
+méb 13
+nai 13
+nbe 13
+ndj 13
+nep 13
+nie 13
+nná 13
+nák 13
+nít 13
+oha 13
+ou 13
+pan 13
+pas 13
+pja 13
+pn 13
+ras 13
+rea 13
+rej 13
+rez 13
+rjá 13
+rle 13
+rul 13
+rus 13
+sec 13
+sup 13
+sáh 13
+tth 13
+töl 13
+töm 13
+tül 13
+udj 13
+utt 13
+voz 13
+vr 13
+yis 13
+zke 13
+ztu 13
+Ú 13
+ánc 13
+ázá 13
+áé 13
+égz 13
+éki 13
+émá 13
+ítv 13
+ódi 13
+öké 13
+önb 13
+özg 13
+úni 13
+útt 13
+ünn 13
+ődö 13
+őrs 13
+őso 13
+ősí 13
+űt 13
+-j 12
+-m 12
+-o 12
+-r 12
+-án 12
+.. 12
+Bá 12
+De 12
+Enn 12
+Gyö 12
+Ja 12
+Ju 12
+Kor 12
+Kr 12
+Mos 12
+Né 12
+Rá 12
+Te 12
+Tud 12
+Tör 12
+adé 12
+agó 12
+ark 12
+ath 12
+atr 12
+azi 12
+bok 12
+bár 12
+bíz 12
+cb 12
+cc 12
+db 12
+dtá 12
+ehá 12
+eld 12
+emc 12
+emp 12
+erá 12
+fer 12
+fin 12
+flá 12
+gje 12
+gke 12
+gny 12
+gyh 12
+had 12
+hes 12
+hn 12
+iek 12
+igé 12
+ilo 12
+ilv 12
+ira 12
+ié 12
+jc 12
+jen 12
+js 12
+jtó 12
+jún 12
+km 12
+kvő 12
+kéz 12
+lbe 12
+ldö 12
+lib 12
+llo 12
+lun 12
+lvi 12
+lél 12
+lőz 12
+mlé 12
+mék 12
+nfe 12
+nnt 12
+nné 12
+nom 12
+nve 12
+náb 12
+név 12
+oká 12
+olv 12
+onv 12
+otm 12
+ppa 12
+pra 12
+pze 12
+rag 12
+rah 12
+ria 12
+rik 12
+riv 12
+ráz 12
+sat 12
+sho 12
+sne 12
+som 12
+szp 12
+t.- 12
+tme 12
+tró 12
+tva 12
+töt 12
+ung 12
+upá 12
+var 12
+vád 12
+ví 12
+yha 12
+ymá 12
+yna 12
+z- 12
+zgy 12
+zha 12
+zló 12
+zöl 12
+zű 12
+ásk 12
+él- 12
+érv 12
+íre 12
+óbe 12
+óh 12
+ókn 12
+óss 12
+örg 12
+öré 12
+úli 12
+ülh 12
+ődé 12
+őle 12
+űve 12
+űzo 12
+-cs 11
+-h 11
+40 11
+92 11
+94 11
+95 11
+AT 11
+ATO 11
+Dae 11
+Du 11
+Dub 11
+EU 11
+Gye 11
+In 11
+Jó 11
+Lás 11
+MF 11
+Mik 11
+NA 11
+NAT 11
+PD 11
+RT 11
+SPD 11
+TO 11
+Ve 11
+ads 11
+adv 11
+aew 11
+ake 11
+akr 11
+apá 11
+arb 11
+aug 11
+avá 11
+bc 11
+bia 11
+blé 11
+cek 11
+cel 11
+con 11
+csn 11
+dhe 11
+dkí 11
+dor 11
+egg 11
+ehé 11
+eks 11
+ekö 11
+elg 11
+emt 11
+eru 11
+esi 11
+evő 11
+ewo 11
+ezm 11
+ezr 11
+feg 11
+fők 11
+gia 11
+gyb 11
+her 11
+ibá 11
+iem 11
+igl 11
+igá 11
+iké 11
+imm 11
+ivi 11
+iáj 11
+iát 11
+iót 11
+jet 11
+jte 11
+kab 11
+kim 11
+ksá 11
+kva 11
+kvá 11
+káz 11
+lab 11
+lju 11
+lok 11
+ltö 11
+lyé 11
+lém 11
+lóz 11
+mal 11
+msz 11
+neh 11
+ngz 11
+nhá 11
+nm 11
+np 11
+nr 11
+nzi 11
+nár 11
+nás 11
+obl 11
+ova 11
+pal 11
+pus 11
+rbá 11
+ril 11
+rko 11
+rot 11
+sg 11
+ska 11
+szu 11
+sés 11
+tlé 11
+tum 11
+tót 11
+udn 11
+ugu 11
+umo 11
+veg 11
+vem 11
+vsz 11
+vv 11
+váj 11
+vát 11
+vék 11
+wo 11
+woo 11
+yj 11
+ykö 11
+yp 11
+yul 11
+zis 11
+zko 11
+zva 11
+Áll 11
+ájc 11
+álo 11
+áp 11
+árj 11
+árv 11
+ású 11
+áte 11
+átv 11
+ázb 11
+éi 11
+éln 11
+épü 11
+éré 11
+ézm 11
+íja 11
+ís 11
+íti 11
+őo 11
+őss 11
+űso 11
+-v 10
+13 10
+3, 10
+4. 10
+Co 10
+Csa 10
+DS 10
+Eze 10
+I. 10
+Kon 10
+Orb 10
+Ra 10
+Si 10
+So 10
+Tit 10
+Vik 10
+ahi 10
+amf 10
+até 10
+atí 10
+bce 10
+bil 10
+bin 10
+bű 10
+chn 10
+cit 10
+cz 10
+dde 10
+deg 10
+djá 10
+dom 10
+dók 10
+eda 10
+egl 10
+egu 10
+ekl 10
+elí 10
+emr 10
+enb 10
+epl 10
+eto 10
+etö 10
+ezá 10
+fá 10
+gan 10
+gpi 10
+gta 10
+gáb 10
+góg 10
+gö 10
+i- 10
+iak 10
+ifi 10
+igi 10
+iné 10
+ird 10
+iró 10
+izs 10
+iák 10
+jj 10
+jok 10
+jta 10
+jtá 10
+jz 10
+jű 10
+kbő 10
+khe 10
+kid 10
+klő 10
+kte 10
+ktú 10
+ky 10
+kéb 10
+kös 10
+lei 10
+ler 10
+lné 10
+lol 10
+lsó 10
+lti 10
+lyh 10
+lyr 10
+mbu 10
+mfő 10
+mus 10
+n- 10
+ndí 10
+ngs 10
+nén 10
+nőt 10
+odo 10
+of 10
+ogo 10
+ogá 10
+oki 10
+olh 10
+omi 10
+oms 10
+onf 10
+oto 10
+pil 10
+pró 10
+pés 10
+rca 10
+rdo 10
+riz 10
+rja 10
+rub 10
+ruk 10
+rva 10
+ráj 10
+rár 10
+sf 10
+ské 10
+sno 10
+stv 10
+szű 10
+sék 10
+sőt 10
+tca 10
+tje 10
+tro 10
+tse 10
+tőz 10
+tűn 10
+ubc 10
+ube 10
+uhá 10
+ukc 10
+und 10
+uri 10
+usi 10
+vje 10
+yir 10
+yle 10
+ytá 10
+yán 10
+zad 10
+zaj 10
+zba 10
+zig 10
+zió 10
+ztü 10
+zát 10
+És 10
+ágp 10
+ánl 10
+árl 10
+átn 10
+átu 10
+épé 10
+érf 10
+étő 10
+ézk 10
+ính 10
+íve 10
+ódá 10
+ógy 10
+óso 10
+óza 10
+öko 10
+örn 10
+ösz 10
+úra 10
+úsz 10
+ügg 10
+ülő 10
+üs 10
+ődő 10
+őri 10
+14 9
+18 9
+2. 9
+992 9
+998 9
+Ami 9
+And 9
+Bar 9
+Eb 9
+Ezé 9
+Gá 9
+Hi 9
+Ist 9
+Klu 9
+Kov 9
+Kü 9
+Már 9
+Ném 9
+Oro 9
+Ped 9
+RTL 9
+Ro 9
+TL 9
+Tal 9
+Val 9
+Vo 9
+abd 9
+aeb 9
+ajz 9
+aln 9
+app 9
+apr 9
+apt 9
+arm 9
+bd 9
+bru 9
+bud 9
+bur 9
+bűn 9
+cai 9
+cba 9
+ced 9
+dak 9
+din 9
+dit 9
+dió 9
+dvá 9
+dár 9
+dém 9
+e- 9
+edh 9
+eha 9
+eir 9
+elz 9
+emi 9
+env 9
+enő 9
+esb 9
+ezh 9
+fot 9
+fű 9
+gai 9
+gjá 9
+gvá 9
+gy- 9
+gyn 9
+gyt 9
+gyó 9
+gáz 9
+gű 9
+hae 9
+hh 9
+hid 9
+hr 9
+ida 9
+ido 9
+iel 9
+ihe 9
+ino 9
+jb 9
+jóv 9
+kee 9
+kih 9
+kéj 9
+kór 9
+lav 9
+lba 9
+lic 9
+lid 9
+liu 9
+llg 9
+lre 9
+lvé 9
+léb 9
+lój 9
+lók 9
+lú 9
+mma 9
+mmu 9
+mn 9
+mát 9
+mö 9
+mög 9
+ndü 9
+nel 9
+ngy 9
+nhe 9
+nor 9
+npa 9
+oa 9
+obo 9
+ogi 9
+okh 9
+onu 9
+ove 9
+ovj 9
+ozg 9
+ozv 9
+pir 9
+pta 9
+rbi 9
+rcs 9
+rda 9
+ref 9
+rei 9
+rgi 9
+rip 9
+rka 9
+rká 9
+rso 9
+ruh 9
+rág 9
+rék 9
+rét 9
+sc 9
+sgá 9
+sun 9
+szú 9
+tab 9
+taz 9
+tmű 9
+tru 9
+ttm 9
+tyá 9
+tón 9
+tün 9
+ull 9
+usb 9
+vak 9
+vei 9
+vti 9
+vve 9
+vác 9
+yai 9
+yék 9
+yóg 9
+zaz 9
+zsg 9
+ztj 9
+zéb 9
+zív 9
+zőn 9
+Ö 9
+ágh 9
+álh 9
+ásh 9
+ásn 9
+éig 9
+élv 9
+éni 9
+épk 9
+éps 9
+érl 9
+étr 9
+évv 9
+ínp 9
+óni 9
+ópá 9
+ótl 9
+örb 9
+övi 9
+özú 9
+úto 9
+üke 9
+ülk 9
+ülm 9
+őve 9
+űsz 9
+,3 8
+,6 8
+-1 8
+-ne 8
+-tő 8
+-én 8
+1-j 8
+17 8
+195 8
+8, 8
+90 8
+97- 8
+99. 8
+Azt 8
+Ban 8
+Do 8
+Dé 8
+Fel 8
+Ge 8
+Her 8
+Há 8
+II 8
+Ig 8
+Kar 8
+Ny 8
+Pá 8
+Pét 8
+Sa 8
+Sc 8
+Sch 8
+Sv 8
+Svá 8
+To 8
+Un 8
+Uni 8
+Vj 8
+Vja 8
+Vl 8
+Vla 8
+We 8
+Zo 8
+Zso 8
+ace 8
+air 8
+akm 8
+als 8
+alu 8
+alí 8
+amp 8
+atv 8
+auk 8
+bbn 8
+bbá 8
+bej 8
+bj 8
+bos 8
+bra 8
+bün 8
+ccs 8
+cok 8
+csú 8
+cá 8
+diá 8
+dje 8
+dők 8
+dős 8
+eak 8
+edz 8
+edó 8
+efi 8
+eho 8
+emj 8
+enf 8
+esn 8
+eth 8
+etá 8
+etű 8
+fed 8
+fik 8
+fős 8
+gma 8
+gsé 8
+gsú 8
+gtö 8
+gut 8
+güg 8
+gük 8
+gő 8
+hav 8
+héz 8
+ici 8
+ier 8
+ikn 8
+imp 8
+iér 8
+j- 8
+jah 8
+jk 8
+jsá 8
+júl 8
+kiz 8
+kma 8
+koa 8
+krő 8
+ktu 8
+kél 8
+kök 8
+lef 8
+lln 8
+líc 8
+lób 8
+lük 8
+lőí 8
+m- 8
+mjo 8
+mmá 8
+mpá 8
+mra 8
+mre 8
+mré 8
+muz 8
+máb 8
+mál 8
+ndá 8
+nán 8
+nát 8
+nés 8
+nú 8
+oal 8
+ogj 8
+ols 8
+olu 8
+onk 8
+oru 8
+osn 8
+ozs 8
+pei 8
+poz 8
+pun 8
+rfi 8
+rhá 8
+rmű 8
+rno 8
+rrá 8
+rst 8
+rsu 8
+rtn 8
+rtu 8
+rzi 8
+rzs 8
+réb 8
+rév 8
+rók 8
+röv 8
+rúg 8
+rút 8
+rők 8
+rőr 8
+sd 8
+stü 8
+stő 8
+sák 8
+sön 8
+sút 8
+tfő 8
+tny 8
+tód 8
+tóz 8
+ui 8
+ume 8
+umi 8
+urg 8
+urá 8
+uzs 8
+vők 8
+yin 8
+yke 8
+yké 8
+zkö 8
+zse 8
+áa 8
+áad 8
+ágs 8
+áka 8
+álu 8
+áng 8
+áná 8
+éc 8
+écs 8
+égg 8
+égű 8
+ékh 8
+ékr 8
+élj 8
+éné 8
+étf 8
+évt 8
+ézi 8
+ímm 8
+ógu 8
+órh 8
+ósí 8
+ótá 8
+ölc 8
+öre 8
+öző 8
+újs 8
+üd 8
+ülj 8
+őf 8
+őol 8
+őí 8
+,8 7
+-3 7
+-as 7
+-el 7
+-jé 7
+-ka 7
+-ko 7
+-p 7
+00- 7
+00. 7
+100 7
+16 7
+194 7
+22 7
+3- 7
+31 7
+33 7
+7-b 7
+At 7
+Bé 7
+D- 7
+DP 7
+Dél 7
+Em 7
+GD 7
+GDP 7
+Gal 7
+Gr 7
+Gáb 7
+IM 7
+IMF 7
+Il 7
+Je 7
+Jár 7
+Kül 7
+LS 7
+LSZ 7
+Lo 7
+ML 7
+MLS 7
+Mer 7
+O- 7
+Szo 7
+TO- 7
+Tib 7
+Töb 7
+Ug 7
+Zen 7
+adr 7
+agé 7
+aha 7
+ahh 7
+aib 7
+akó 7
+amt 7
+amu 7
+ané 7
+aní 7
+anú 7
+apn 7
+ash 7
+asú 7
+bat 7
+bem 7
+bis 7
+bro 7
+bul 7
+bőv 7
+cer 7
+chi 7
+cső 7
+cv 7
+dbe 7
+dra 7
+dös 7
+eem 7
+ejű 7
+eko 7
+ekü 7
+elb 7
+elr 7
+ená 7
+epé 7
+er- 7
+esl 7
+et- 7
+ezú 7
+eé 7
+fü 7
+gbí 7
+gd 7
+gez 7
+ghá 7
+gig 7
+gmu 7
+gor 7
+gse 7
+gvi 7
+gze 7
+gzo 7
+gól 7
+heg 7
+hho 7
+hin 7
+hov 7
+húz 7
+hő 7
+ice 7
+idi 7
+iet 7
+iha 7
+ins 7
+isb 7
+iuk 7
+ivő 7
+iás 7
+jeb 7
+jko 7
+jm 7
+jug 7
+jáv 7
+kak 7
+kij 7
+kir 7
+krá 7
+kró 7
+kum 7
+kur 7
+l-k 7
+lac 7
+lká 7
+lly 7
+lob 7
+loz 7
+ltb 7
+ltj 7
+ltu 7
+löv 7
+lőb 7
+lőj 7
+lőn 7
+mec 7
+med 7
+mh 7
+mic 7
+miv 7
+mor 7
+mti 7
+mté 7
+mv 7
+mák 7
+műf 7
+nke 7
+nlí 7
+nts 7
+ntu 7
+nvé 7
+nyp 7
+nze 7
+nzt 7
+obr 7
+odn 7
+oml 7
+ong 7
+onj 7
+ozd 7
+pb 7
+pko 7
+rav 7
+rci 7
+rco 7
+rmo 7
+rne 7
+rád 7
+rój 7
+rös 7
+rűs 7
+sbé 7
+sed 7
+sig 7
+sle 7
+soh 7
+sso 7
+sz- 7
+szm 7
+sél 7
+sőb 7
+sű 7
+tei 7
+tké 7
+tná 7
+ttő 7
+tóp 7
+tök 7
+tön 7
+tőv 7
+ukr 7
+uma 7
+umb 7
+ura 7
+usa 7
+uss 7
+uál 7
+vac 7
+viv 7
+vot 7
+yhá 7
+yjá 7
+yvá 7
+yák 7
+yát 7
+yér 7
+yűj 7
+zdt 7
+zdá 7
+zim 7
+zum 7
+zén 7
+zód 7
+zői 7
+ágí 7
+ájo 7
+áki 7
+ámú 7
+ánb 7
+árr 7
+áru 7
+árő 7
+átj 7
+átm 7
+ávi 7
+ázn 7
+ázu 7
+áér 7
+ébő 7
+égs 7
+ékt 7
+épt 7
+étb 7
+étl 7
+ígé 7
+ízi 7
+ó- 7
+óds 7
+óke 7
+ósz 7
+ödi 7
+ögö 7
+öki 7
+ötö 7
+úc 7
+úd 7
+úgó 7
+úti 7
+ődi 7
+őny 7
+őrz 7
+ővé 7
+őzö 7
+őír 7
+űf 7
+űj 7
+űjt 7
+űnt 7
+űr 7
+-Ko 6
+-or 6
+-ta 6
+-te 6
+.-t 6
+... 6
+15 6
+196 6
+2,5 6
+28 6
+30- 6
+5, 6
+7. 6
+70 6
+75 6
+AI 6
+AID 6
+BE 6
+BES 6
+Bal 6
+Bi 6
+Bor 6
+Bár 6
+EB 6
+EBE 6
+ES 6
+ESZ 6
+Fa 6
+Fid 6
+Fr 6
+Ger 6
+Gi 6
+Go 6
+Ham 6
+Hu 6
+ID 6
+IDS 6
+II. 6
+Im 6
+Imr 6
+K- 6
+Kfo 6
+Kra 6
+Ké 6
+Man 6
+Mit 6
+Mé 6
+Ol 6
+Ors 6
+PD- 6
+Pa 6
+Pil 6
+Pri 6
+Sim 6
+Sp 6
+Sá 6
+Tr 6
+Tra 6
+Tő 6
+Ugy 6
+Vol 6
+Vá 6
+Vé 6
+Wa 6
+Wel 6
+Zol 6
+Zsi 6
+aa 6
+abj 6
+ach 6
+adh 6
+ajb 6
+ak- 6
+alh 6
+alj 6
+alp 6
+alv 6
+ano 6
+apb 6
+ar- 6
+arj 6
+aró 6
+arú 6
+ast 6
+ave 6
+avo 6
+b- 6
+bbő 6
+bda 6
+bei 6
+bja 6
+bne 6
+bri 6
+bsz 6
+báz 6
+bör 6
+böz 6
+büd 6
+chr 6
+ciu 6
+col 6
+csó 6
+cu 6
+daz 6
+dké 6
+dsá 6
+duk 6
+dva 6
+dák 6
+dég 6
+ebr 6
+ech 6
+eji 6
+ejá 6
+el- 6
+elá 6
+elö 6
+erí 6
+etm 6
+etü 6
+feb 6
+fg 6
+fga 6
+fok 6
+fú 6
+füg 6
+főb 6
+fűt 6
+g- 6
+gbó 6
+geg 6
+gei 6
+gho 6
+gmé 6
+gne 6
+gro 6
+gva 6
+gyö 6
+géb 6
+géi 6
+göt 6
+hib 6
+hne 6
+hrö 6
+hóm 6
+hús 6
+hős 6
+ica 6
+ifo 6
+igh 6
+ikk 6
+inő 6
+iso 6
+iór 6
+jba 6
+jlő 6
+jos 6
+jts 6
+jun 6
+jér 6
+jöt 6
+kig 6
+kj 6
+kné 6
+kri 6
+kro 6
+ktő 6
+l-K 6
+ldt 6
+lie 6
+lim 6
+lki 6
+lmu 6
+lná 6
+lpo 6
+lys 6
+lóa 6
+löl 6
+mak 6
+mbo 6
+mio 6
+mié 6
+nan 6
+nas 6
+nbö 6
+ndö 6
+ned 6
+nfo 6
+nkb 6
+nkr 6
+nkt 6
+ntk 6
+nyh 6
+nyr 6
+nyö 6
+nős 6
+oba 6
+ock 6
+odu 6
+odó 6
+ogn 6
+oj 6
+omp 6
+omé 6
+orí 6
+otá 6
+ovs 6
+ozí 6
+pa- 6
+pap 6
+ph 6
+pna 6
+pír 6
+pö 6
+pök 6
+püs 6
+rap 6
+rcb 6
+rdí 6
+rló 6
+rná 6
+rp 6
+rsá 6
+ruá 6
+rza 6
+rób 6
+róf 6
+röd 6
+sot 6
+spö 6
+stó 6
+szf 6
+szr 6
+tg 6
+thá 6
+tmu 6
+ttj 6
+ttu 6
+tur 6
+tuá 6
+tór 6
+tüz 6
+tőd 6
+tőn 6
+tőr 6
+ukt 6
+uká 6
+uli 6
+una 6
+ust 6
+vir 6
+vok 6
+vre 6
+véb 6
+vér 6
+vót 6
+vű 6
+wa 6
+xi 6
+yg 6
+yét 6
+zeb 6
+zez 6
+zeá 6
+zfi 6
+zla 6
+zmi 6
+zné 6
+zpé 6
+zso 6
+zts 6
+zus 6
+zák 6
+zíc 6
+zóv 6
+águ 6
+ámi 6
+ánk 6
+ápr 6
+átr 6
+ázo 6
+édő 6
+égt 6
+élp 6
+éls 6
+érü 6
+ésü 6
+éső 6
+éto 6
+évs 6
+ísé 6
+íze 6
+ízo 6
+óak 6
+óbá 6
+ódj 6
+ódt 6
+ófa 6
+ógé 6
+óló 6
+óto 6
+óvi 6
+óvá 6
+ózs 6
+öde 6
+ödö 6
+önh 6
+önl 6
+örl 6
+örú 6
+örű 6
+öté 6
+úk 6
+üdz 6
+ürg 6
+ürk 6
+üsp 6
+Ő 6
+ődn 6
+őkn 6
+őlt 6
+őp 6
+űfa 6
+űsé 6
+űtő 6
+,1 5
+,9 5
+-5 5
+-d 5
+-eg 5
+-fo 5
+-he 5
+-ig 5
+-ke 5
+-os 5
+-ö 5
+0-á 5
+10- 5
+120 5
+198 5
+27 5
+3. 5
+35 5
+4, 5
+500 5
+57 5
+6-o 5
+6-á 5
+64 5
+7-e 5
+8. 5
+80- 5
+9, 5
+9-b 5
+9-e 5
+98- 5
+996 5
+Ad 5
+Aki 5
+Ale 5
+Ar 5
+Baj 5
+Ber 5
+Bró 5
+Bun 5
+EU- 5
+Elő 5
+Ers 5
+Far 5
+Fen 5
+Fil 5
+Fo 5
+Fü 5
+Hav 5
+Hor 5
+Hun 5
+Hy 5
+Iv 5
+Jo 5
+Józ 5
+Kia 5
+Kou 5
+Két 5
+Laj 5
+Lon 5
+Lu 5
+Mac 5
+Mel 5
+Mic 5
+Mil 5
+Mu 5
+Még 5
+Mű 5
+Ni 5
+Oly 5
+Op 5
+Pén 5
+S- 5
+Se 5
+Sok 5
+St 5
+Szt 5
+Sán 5
+Th 5
+Tv 5
+U- 5
+Vag 5
+Van 5
+Y 5
+Z-k 5
+Zem 5
+a-b 5
+abe 5
+abó 5
+add 5
+adí 5
+agg 5
+agi 5
+ahe 5
+ail 5
+aks 5
+alú 5
+amh 5
+amj 5
+amá 5
+apk 5
+aps 5
+apv 5
+ars 5
+aru 5
+aré 5
+aty 5
+ax 5
+azn 5
+azu 5
+bak 5
+bbr 5
+bbé 5
+bea 5
+bec 5
+beh 5
+bir 5
+bot 5
+bum 5
+cal 5
+cio 5
+cká 5
+def 5
+dg 5
+dip 5
+djm 5
+dté 5
+dát 5
+dís 5
+dóa 5
+dór 5
+eau 5
+ecc 5
+egú 5
+eib 5
+ejö 5
+eo 5
+epi 5
+eta 5
+etf 5
+ey 5
+ezv 5
+eér 5
+fan 5
+ff 5
+fic 5
+fut 5
+fén 5
+fői 5
+főt 5
+gak 5
+gdí 5
+gem 5
+gjo 5
+gmo 5
+gul 5
+gvé 5
+gáj 5
+gáé 5
+gír 5
+hai 5
+hek 5
+ht 5
+huz 5
+hö 5
+ias 5
+ibu 5
+ieg 5
+ife 5
+ii 5
+ije 5
+ikl 5
+ima 5
+imá 5
+inó 5
+ior 5
+iri 5
+irt 5
+ivé 5
+izm 5
+ióv 5
+iü 5
+jat 5
+jed 5
+jei 5
+jma 5
+jü 5
+kav 5
+keg 5
+kei 5
+kná 5
+kop 5
+ktá 5
+kái 5
+káj 5
+kín 5
+kís 5
+kói 5
+lbu 5
+lfe 5
+lge 5
+ljö 5
+llő 5
+lod 5
+lse 5
+ltű 5
+lul 5
+láj 5
+láz 5
+lír 5
+lór 5
+löt 5
+lőh 5
+mam 5
+mhá 5
+miá 5
+mjá 5
+mlá 5
+mlí 5
+mna 5
+mul 5
+mác 5
+mü 5
+műt 5
+nad 5
+nar 5
+nch 5
+nco 5
+neb 5
+nfr 5
+nfé 5
+ngá 5
+nij 5
+nit 5
+niá 5
+nja 5
+nju 5
+njá 5
+nla 5
+nme 5
+nst 5
+ntn 5
+ntt 5
+ny- 5
+odt 5
+oe 5
+ofi 5
+ogh 5
+oku 5
+or- 5
+orc 5
+orz 5
+osl 5
+osu 5
+ota 5
+ouc 5
+ozh 5
+p- 5
+plő 5
+pás 5
+pét 5
+pő 5
+r-i 5
+raf 5
+rdó 5
+reh 5
+rgb 5
+ric 5
+rie 5
+rof 5
+rop 5
+rov 5
+rty 5
+rtö 5
+rum 5
+ry 5
+rám 5
+rér 5
+sbó 5
+sfé 5
+shi 5
+sid 5
+sit 5
+sos 5
+spo 5
+sté 5
+sve 5
+szh 5
+séh 5
+sír 5
+sük 5
+sür 5
+tbó 5
+tec 5
+tej 5
+tex 5
+tfo 5
+tim 5
+tsa 5
+tuk 5
+tut 5
+tvi 5
+tvé 5
+tít 5
+tóg 5
+tóv 5
+tür 5
+tőo 5
+uch 5
+udi 5
+ugd 5
+ugá 5
+ukb 5
+ulh 5
+ulm 5
+ux 5
+uza 5
+vev 5
+vf 5
+vfo 5
+via 5
+vk 5
+vtá 5
+vö 5
+vőb 5
+y-e 5
+yfo 5
+yga 5
+yot 5
+yte 5
+yáb 5
+zas 5
+zei 5
+zic 5
+zit 5
+zky 5
+zme 5
+zmu 5
+zno 5
+zsá 5
+zth 5
+ztv 5
+zzo 5
+záj 5
+zói 5
+zöm 5
+zűk 5
+Én 5
+Úg 5
+Úgy 5
+Új 5
+ágt 5
+áig 5
+ámu 5
+ánj 5
+ánn 5
+ár- 5
+árp 5
+ásf 5
+ázs 5
+ázó 5
+édi 5
+égl 5
+élo 5
+élr 5
+épn 5
+érb 5
+ésn 5
+ésű 5
+été 5
+évf 5
+évr 5
+éző 5
+íl 5
+íne 5
+íná 5
+íra 5
+írj 5
+ísz 5
+ívo 5
+óc 5
+ógi 5
+óit 5
+ólí 5
+ónk 5
+ödő 5
+ökv 5
+önm 5
+öns 5
+ötv 5
+özz 5
+úcs 5
+údi 5
+úrá 5
+úth 5
+útv 5
+ülb 5
+ülv 5
+üre 5
+üte 5
+ő- 5
+ődj 5
+ődt 5
+őhá 5
+őip 5
+őjé 5
+őnö 5
+őzs 5
+őző 5
+űle 5
+,25 4
+,4 4
+,5- 4
+,7 4
+-2 4
+-30 4
+-M 4
+-eu 4
+-g 4
+-ip 4
+-re 4
+-ös 4
+0, 4
+0-a 4
+0-b 4
+02 4
+1,5 4
+1-b 4
+1-e 4
+180 4
+2-b 4
+23 4
+29 4
+3,5 4
+300 4
+43 4
+45 4
+47 4
+55 4
+6, 4
+7, 4
+91 4
+92- 4
+93 4
+96- 4
+991 4
+994 4
+Akk 4
+Bat 4
+Bel 4
+Bro 4
+Bán 4
+Béc 4
+Ca 4
+Cor 4
+DSZ 4
+Di 4
+Ele 4
+Emi 4
+Ezt 4
+Ezz 4
+FB 4
+Fej 4
+Fio 4
+Fra 4
+FÁ 4
+FÁK 4
+G- 4
+Gro 4
+Gyu 4
+Has 4
+Hiá 4
+Hol 4
+Hyu 4
+Id 4
+Ik 4
+Ika 4
+Int 4
+Iva 4
+Jel 4
+Jug 4
+Kam 4
+Kap 4
+Kel 4
+Ker 4
+Kis 4
+Kre 4
+Ku 4
+Ká 4
+Kár 4
+Lig 4
+Lis 4
+MFB 4
+Nag 4
+Nap 4
+Naw 4
+Nyu 4
+Ope 4
+Ora 4
+Per 4
+Por 4
+Poz 4
+Rad 4
+Rob 4
+Ráa 4
+SZD 4
+Szl 4
+Szá 4
+Szö 4
+Tam 4
+Tan 4
+Tar 4
+Tha 4
+VG- 4
+Ves 4
+ZD 4
+ZDS 4
+Za 4
+acb 4
+ack 4
+ael 4
+afg 4
+agn 4
+ags 4
+agt 4
+ahá 4
+ajk 4
+aju 4
+akh 4
+amn 4
+amú 4
+arg 4
+arz 4
+asé 4
+así 4
+atü 4
+aus 4
+aw 4
+awa 4
+axi 4
+ay 4
+azs 4
+azí 4
+aé 4
+bez 4
+bik 4
+bli 4
+blá 4
+bny 4
+bás 4
+bát 4
+bék 4
+bít 4
+bú 4
+cke 4
+cl 4
+cla 4
+cot 4
+cs- 4
+cve 4
+d- 4
+df 4
+dib 4
+djé 4
+dl 4
+dse 4
+dtu 4
+dur 4
+dző 4
+dév 4
+dój 4
+döz 4
+dőj 4
+dől 4
+ead 4
+ean 4
+edj 4
+edü 4
+elc 4
+emű 4
+erl 4
+etí 4
+eum 4
+evo 4
+ezs 4
+fag 4
+fat 4
+fj 4
+fó 4
+főr 4
+gbé 4
+gc 4
+gfő 4
+ggá 4
+ghe 4
+ghi 4
+ghí 4
+git 4
+gka 4
+gké 4
+glo 4
+gme 4
+gsá 4
+gti 4
+gto 4
+gtu 4
+gtó 4
+guá 4
+gyj 4
+gyú 4
+gzi 4
+gül 4
+hen 4
+hni 4
+hs 4
+hul 4
+hum 4
+hér 4
+hót 4
+idó 4
+ifj 4
+igm 4
+ihi 4
+ilk 4
+ime 4
+ipl 4
+isi 4
+isí 4
+itj 4
+itm 4
+itó 4
+ivo 4
+iza 4
+izi 4
+iób 4
+iói 4
+ióz 4
+jaz 4
+jda 4
+jh 4
+jjá 4
+jzf 4
+jós 4
+jük 4
+kah 4
+kep 4
+kf 4
+kló 4
+kp 4
+kpa 4
+kso 4
+ktí 4
+kvi 4
+kác 4
+kév 4
+kű 4
+lau 4
+lca 4
+led 4
+leá 4
+leé 4
+lgy 4
+lkö 4
+llö 4
+lny 4
+lnő 4
+ltú 4
+lum 4
+lut 4
+lvo 4
+lyf 4
+lyó 4
+lzá 4
+láí 4
+lói 4
+lót 4
+lök 4
+lőe 4
+lőf 4
+lől 4
+lőv 4
+mac 4
+mib 4
+mid 4
+mle 4
+mlo 4
+mod 4
+muk 4
+mvá 4
+mái 4
+múg 4
+nay 4
+nbs 4
+ncz 4
+ndh 4
+nea 4
+nei 4
+nen 4
+ngb 4
+ngj 4
+ngt 4
+nho 4
+niv 4
+niz 4
+nji 4
+nkn 4
+nku 4
+nlé 4
+nma 4
+nre 4
+nt- 4
+nuk 4
+nun 4
+nva 4
+nyj 4
+nyű 4
+nzb 4
+nzu 4
+nzá 4
+nét 4
+nők 4
+nű 4
+ode 4
+oné 4
+oor 4
+opj 4
+opt 4
+osv 4
+ote 4
+ovo 4
+pak 4
+pba 4
+pez 4
+phe 4
+pig 4
+plo 4
+plé 4
+pni 4
+psé 4
+pti 4
+páb 4
+rae 4
+rau 4
+raz 4
+rgő 4
+rid 4
+rió 4
+rkö 4
+rli 4
+rné 4
+rnö 4
+rri 4
+rrő 4
+rtb 4
+rtt 4
+ráa 4
+rót 4
+rög 4
+rúk 4
+rús 4
+sar 4
+sch 4
+sef 4
+she 4
+skö 4
+spa 4
+sré 4
+sró 4
+stu 4
+súf 4
+súj 4
+sün 4
+süt 4
+sőd 4
+t-e 4
+tcá 4
+tcé 4
+td 4
+tez 4
+tif 4
+tiv 4
+tka 4
+tlá 4
+trő 4
+ttb 4
+ttü 4
+tvo 4
+tém 4
+túd 4
+ucc 4
+udó 4
+ukk 4
+ulc 4
+upa 4
+use 4
+utn 4
+uty 4
+uv 4
+veh 4
+vg 4
+vh 4
+vri 4
+vu 4
+vág 4
+vír 4
+víz 4
+vú 4
+xis 4
+yat 4
+yau 4
+ybó 4
+yc 4
+yeb 4
+yim 4
+yja 4
+yny 4
+ypa 4
+ypá 4
+yun 4
+yáj 4
+yál 4
+zah 4
+zev 4
+zfö 4
+zia 4
+zlé 4
+zmá 4
+zsd 4
+zsu 4
+zsz 4
+zsú 4
+ztö 4
+ztő 4
+zul 4
+zup 4
+zur 4
+zzé 4
+zír 4
+zök 4
+zöu 4
+zőb 4
+zőe 4
+zős 4
+zőt 4
+zűn 4
+ÁK 4
+ÁK- 4
+Ár 4
+Él 4
+Ép 4
+Ör 4
+ábl 4
+áf 4
+ágn 4
+áj- 4
+ákb 4
+ákk 4
+álé 4
+áns 4
+áré 4
+árí 4
+átk 4
+ázh 4
+ázm 4
+áí 4
+áír 4
+éje 4
+éjé 4
+ékl 4
+ékű 4
+élh 4
+élz 4
+érg 4
+érh 4
+érm 4
+ésk 4
+étt 4
+ézt 4
+ézz 4
+éé 4
+éér 4
+ík 4
+ímé 4
+ínű 4
+íp 4
+óbu 4
+óho 4
+ókk 4
+ókr 4
+óké 4
+ólt 4
+ólá 4
+ómu 4
+ózk 4
+ózt 4
+ózu 4
+ögé 4
+ökn 4
+öks 4
+ölé 4
+ölö 4
+ötő 4
+öu 4
+öul 4
+özh 4
+özs 4
+úf 4
+úfo 4
+újj 4
+úls 4
+úlz 4
+útj 4
+üls 4
+üne 4
+ürü 4
+ütő 4
+üzl 4
+őfo 4
+őg 4
+őir 4
+őpo 4
+őrö 4
+őte 4
+űe 4
+űtá 4
+űzé 4
+-0 3
+-B 3
+-D 3
+-H 3
+-cí 3
+-dí 3
+-fe 3
+-fé 3
+-ho 3
+-ké 3
+-kö 3
+-me 3
+-má 3
+-mé 3
+-pa 3
+-ve 3
+-ví 3
+0-1 3
+0-3 3
+0-e 3
+0-r 3
+002 3
+02- 3
+07 3
+1,1 3
+1-é 3
+1. 3
+10. 3
+110 3
+14. 3
+19- 3
+2,2 3
+2,6 3
+2-e 3
+20- 3
+21 3
+24 3
+25- 3
+26 3
+31- 3
+32 3
+34 3
+350 3
+37 3
+39 3
+4-5 3
+4-b 3
+4-e 3
+48 3
+49 3
+5-3 3
+5-b 3
+5-ö 3
+5. 3
+50- 3
+59 3
+600 3
+69 3
+7,2 3
+79 3
+8,2 3
+8-a 3
+8-b 3
+8-i 3
+85 3
+86 3
+91- 3
+92. 3
+94- 3
+964 3
+97. 3
+993 3
+Af 3
+Aka 3
+Ama 3
+Any 3
+Att 3
+Au 3
+Bab 3
+Bad 3
+Bib 3
+Bl 3
+Bla 3
+Bon 3
+Boz 3
+Bra 3
+Car 3
+Ch 3
+Csi 3
+D-t 3
+DF 3
+Don 3
+Dr 3
+Eb- 3
+Ebb 3
+Ec 3
+Ed 3
+Ei 3
+Eic 3
+Ell 3
+Elm 3
+Erz 3
+Es 3
+F- 3
+For 3
+Fül 3
+Fő 3
+G-n 3
+GB 3
+Gl 3
+Gö 3
+Göd 3
+Han 3
+His 3
+Hí 3
+Hír 3
+Hü 3
+Hüb 3
+IK 3
+Iga 3
+Ily 3
+Isk 3
+Jan 3
+Jar 3
+KG 3
+KGB 3
+Kal 3
+Kat 3
+Kea 3
+Kh 3
+Kie 3
+Kim 3
+Kla 3
+Kli 3
+Kok 3
+Kön 3
+Leg 3
+Lib 3
+MD 3
+MDF 3
+MT 3
+MU 3
+Mak 3
+Mal 3
+Mas 3
+Mez 3
+Miu 3
+Miv 3
+Moz 3
+Más 3
+Mú 3
+Múz 3
+Műs 3
+Nis 3
+No 3
+Om 3
+Omá 3
+Pel 3
+Pir 3
+Pol 3
+Pre 3
+Pu 3
+Pár 3
+Páz 3
+Q 3
+Rei 3
+Rez 3
+Ri 3
+Ric 3
+Ru 3
+Rák 3
+SA 3
+SZK 3
+Saa 3
+Spa 3
+Szé 3
+TK 3
+Tav 3
+Teg 3
+Ter 3
+Tie 3
+Tor 3
+Tui 3
+Té 3
+Tén 3
+Tők 3
+Tőz 3
+U-t 3
+Veg 3
+Vil 3
+Vác 3
+Vö 3
+Vör 3
+Wi 3
+Wo 3
+X 3
+Z-n 3
+ZK 3
+a, 3
+aar 3
+abs 3
+adu 3
+afe 3
+ag- 3
+age 3
+agú 3
+aim 3
+aiv 3
+aje 3
+ajr 3
+akö 3
+al- 3
+ams 3
+anj 3
+anó 3
+asu 3
+asó 3
+at- 3
+aud 3
+aux 3
+avu 3
+aá 3
+aü 3
+aüg 3
+b-c 3
+bbí 3
+bdá 3
+biu 3
+bna 3
+boc 3
+bog 3
+bom 3
+brá 3
+bt 3
+bta 3
+bél 3
+bén 3
+cad 3
+cbe 3
+cca 3
+ceg 3
+ces 3
+cik 3
+cin 3
+cr 3
+csb 3
+csr 3
+csü 3
+cva 3
+cze 3
+dba 3
+dda 3
+dea 3
+dfo 3
+dgá 3
+dia 3
+dil 3
+dim 3
+dis 3
+djo 3
+djö 3
+dog 3
+dov 3
+dro 3
+dug 3
+dup 3
+dus 3
+dáb 3
+déb 3
+déz 3
+dóz 3
+dög 3
+dőn 3
+dű 3
+eai 3
+eav 3
+edb 3
+egp 3
+egz 3
+ehs 3
+eiv 3
+ejü 3
+ekh 3
+ekm 3
+ekí 3
+enj 3
+ero 3
+ery 3
+erú 3
+eső 3
+etu 3
+eva 3
+evi 3
+evá 3
+eví 3
+ews 3
+eye 3
+eáb 3
+eí 3
+eír 3
+fak 3
+feh 3
+fir 3
+fiú 3
+fjú 3
+fos 3
+fri 3
+fáj 3
+fák 3
+fék 3
+fúj 3
+főh 3
+főo 3
+fűz 3
+gab 3
+gam 3
+gcs 3
+gfi 3
+giá 3
+gió 3
+gpr 3
+gró 3
+gur 3
+gyf 3
+gzé 3
+gző 3
+géd 3
+géj 3
+gév 3
+gók 3
+gús 3
+gün 3
+gős 3
+hev 3
+hih 3
+hm 3
+hsz 3
+ht. 3
+hób 3
+hóf 3
+höz 3
+iah 3
+ian 3
+ibő 3
+ien 3
+ies 3
+igo 3
+iho 3
+ija 3
+ijt 3
+ikv 3
+imo 3
+inn 3
+ipo 3
+irg 3
+irk 3
+is- 3
+isa 3
+isc 3
+isn 3
+isv 3
+isá 3
+itr 3
+itu 3
+itü 3
+iuc 3
+ióf 3
+ióh 3
+iú 3
+iür 3
+jal 3
+jci 3
+jek 3
+jf 3
+jho 3
+jip 3
+jja 3
+jli 3
+jna 3
+jná 3
+jsz 3
+jth 3
+jtő 3
+jv 3
+jéb 3
+jév 3
+jók 3
+k-k 3
+kau 3
+kaü 3
+kef 3
+kic 3
+kiü 3
+kli 3
+klu 3
+klá 3
+klé 3
+ktr 3
+kvó 3
+kád 3
+kám 3
+káv 3
+kém 3
+kód 3
+kú 3
+kőo 3
+lar 3
+lcv 3
+ldg 3
+lec 3
+lex 3
+leí 3
+lgr 3
+lho 3
+lhá 3
+lhí 3
+lia 3
+ljo 3
+ljé 3
+llh 3
+lm- 3
+lpa 3
+ltü 3
+ltő 3
+lud 3
+lvt 3
+lvű 3
+lyg 3
+lyk 3
+lyv 3
+lyű 3
+lze 3
+lzo 3
+lzó 3
+lóg 3
+löp 3
+mbi 3
+mei 3
+mey 3
+mie 3
+mif 3
+mja 3
+mk 3
+mpi 3
+mpó 3
+mta 3
+mvé 3
+mzé 3
+ncv 3
+ndv 3
+ngu 3
+nir 3
+nje 3
+nkc 3
+nol 3
+nri 3
+ntb 3
+ntó 3
+ntö 3
+ntú 3
+nvo 3
+nyc 3
+nyg 3
+nyü 3
+nzó 3
+náz 3
+ník 3
+nús 3
+nőr 3
+nűl 3
+o- 3
+obi 3
+obá 3
+ofő 3
+ogv 3
+oke 3
+okó 3
+ole 3
+olf 3
+olk 3
+om- 3
+omr 3
+omí 3
+onm 3
+onr 3
+onó 3
+oo- 3
+opp 3
+orj 3
+os- 3
+ose 3
+osá 3
+otj 3
+our 3
+p-s 3
+pac 3
+pit 3
+piá 3
+pje 3
+pka 3
+plá 3
+pov 3
+pré 3
+puc 3
+pul 3
+pve 3
+pér 3
+pők 3
+q 3
+qu 3
+r-e 3
+r-k 3
+r-o 3
+r-v 3
+rch 3
+rdt 3
+reé 3
+rfe 3
+rjé 3
+rké 3
+rmi 3
+rpe 3
+rro 3
+rsi 3
+rsv 3
+run 3
+rut 3
+rvg 3
+rzö 3
+rém 3
+ró- 3
+rói 3
+röz 3
+rúj 3
+rüg 3
+rük 3
+rőt 3
+scs 3
+sdé 3
+sep 3
+sev 3
+sic 3
+sie 3
+sil 3
+sim 3
+sip 3
+siv 3
+ski 3
+sni 3
+sof 3
+srő 3
+ssu 3
+sug 3
+szj 3
+sál 3
+sób 3
+són 3
+söd 3
+súc 3
+sőj 3
+t-K 3
+tax 3
+teb 3
+tgy 3
+tid 3
+tio 3
+tjé 3
+tso 3
+tto 3
+tya 3
+tyi 3
+tyj 3
+táz 3
+tég 3
+típ 3
+tóm 3
+töz 3
+ua 3
+ubi 3
+ubl 3
+uca 3
+udh 3
+udv 3
+uis 3
+ukn 3
+ulo 3
+umr 3
+umá 3
+upl 3
+ure 3
+urt 3
+urv 3
+us- 3
+usá 3
+usú 3
+v- 3
+vgy 3
+vig 3
+vul 3
+vév 3
+vób 3
+vör 3
+vőj 3
+ws 3
+y-t 3
+yab 3
+ybí 3
+ycs 3
+yfa 3
+yho 3
+yhí 3
+yki 3
+yla 3
+yme 3
+ynö 3
+yré 3
+yrő 3
+ysá 3
+yzi 3
+yáz 3
+yés 3
+yíl 3
+yön 3
+yük 3
+yül 3
+yőr 3
+zau 3
+zbő 3
+zdu 3
+zec 3
+zeh 3
+zeu 3
+zj 3
+zki 3
+zní 3
+zog 3
+zst 3
+zsv 3
+zug 3
+zuk 3
+zój 3
+zór 3
+zög 3
+zőg 3
+Ált 3
+Ám 3
+Ér 3
+Ész 3
+Ön 3
+ábi 3
+ácl 3
+ágm 3
+ágú 3
+ákr 3
+álg 3
+áml 3
+ánu 3
+ápo 3
+árz 3
+átf 3
+áti 3
+áty 3
+áén 3
+édo 3
+édé 3
+égh 3
+éjs 3
+éjá 3
+éjű 3
+ék- 3
+ékn 3
+élg 3
+élm 3
+éma 3
+éna 3
+énh 3
+énő 3
+ép- 3
+épő 3
+ésh 3
+étk 3
+évá 3
+ézv 3
+ézé 3
+íli 3
+ímv 3
+íni 3
+ípu 3
+írn 3
+íru 3
+írv 3
+ívj 3
+ívt 3
+ócs 3
+ódó 3
+óha 3
+óip 3
+óky 3
+ómű 3
+ópi 3
+ópo 3
+óre 3
+óré 3
+ózo 3
+ózá 3
+óé 3
+óér 3
+ödn 3
+öge 3
+ök- 3
+önf 3
+önz 3
+öná 3
+öp 3
+ösv 3
+övé 3
+öza 3
+özn 3
+özo 3
+özr 3
+újd 3
+úlv 3
+úlé 3
+úsá 3
+útk 3
+útl 3
+úts 3
+úze 3
+úzá 3
+üb 3
+übn 3
+üh 3
+üll 3
+ütö 3
+őfe 3
+őga 3
+őha 3
+őhe 3
+őin 3
+őis 3
+őm 3
+őmű 3
+őrj 3
+őrr 3
+őrü 3
+őrő 3
+ősö 3
+őti 3
+őtl 3
+őté 3
+ővü 3
+őzn 3
+űki 3
+űnb 3
+űni 3
+űnő 3
+' 2
+,37 2
+-10 2
+-12 2
+-4 2
+-6 2
+-7 2
+-Ba 2
+-C 2
+-G 2
+-Ka 2
+-Ki 2
+-Kő 2
+-Ma 2
+-T 2
+-Tő 2
+-bo 2
+-bő 2
+-de 2
+-ei 2
+-em 2
+-er 2
+-fő 2
+-gé 2
+-je 2
+-ku 2
+-né 2
+-po 2
+-ra 2
+-ré 2
+-rő 2
+-tá 2
+-tí 2
+-tö 2
+-u 2
+-vi 2
+-vá 2
+-ái 2
+-ár 2
+-át 2
+-áz 2
+-éi 2
+-ér 2
+.-b 2
+.-v 2
+0-i 2
+007 2
+05 2
+07- 2
+1,8 2
+10, 2
+105 2
+11, 2
+130 2
+150 2
+16- 2
+160 2
+17- 2
+18- 2
+19. 2
+190 2
+192 2
+197 2
+2-n 2
+21- 2
+220 2
+24. 2
+26- 2
+28. 2
+29- 2
+3,6 2
+3-0 2
+31. 2
+32, 2
+33. 2
+38 2
+4,2 2
+4,5 2
+4-r 2
+400 2
+41 2
+42 2
+44 2
+48- 2
+5,3 2
+5-é 2
+51 2
+56 2
+58 2
+59- 2
+6,3 2
+6-b 2
+61 2
+61, 2
+64- 2
+65 2
+68 2
+7-i 2
+7-t 2
+71 2
+72 2
+77 2
+8,5 2
+8-r 2
+8-á 2
+800 2
+81 2
+84 2
+860 2
+9-1 2
+9-é 2
+90- 2
+947 2
+948 2
+949 2
+95- 2
+950 2
+957 2
+959 2
+969 2
+98. 2
+99- 2
+990 2
+995 2
+AP 2
+APE 2
+Ada 2
+Afg 2
+Alb 2
+Alk 2
+Ani 2
+Ank 2
+Ara 2
+Ata 2
+Av 2
+Azé 2
+B- 2
+BL 2
+Bak 2
+Beh 2
+Biz 2
+Bod 2
+Bos 2
+Bre 2
+Brü 2
+Bur 2
+Bác 2
+Bő 2
+CD 2
+Ce 2
+Chi 2
+Con 2
+Cso 2
+DF- 2
+DS- 2
+Dag 2
+Dar 2
+Dem 2
+Dis 2
+Dn 2
+Dny 2
+Dob 2
+Dz 2
+Dzu 2
+EF 2
+EFA 2
+EH 2
+EH- 2
+Eco 2
+Egé 2
+Ek 2
+Ekö 2
+Elh 2
+Els 2
+Enr 2
+Erc 2
+Err 2
+Et 2
+FA 2
+FI 2
+FIK 2
+Fé 2
+Fó 2
+Fór 2
+Gam 2
+Gim 2
+Gio 2
+Gir 2
+Gla 2
+Gn 2
+Gnj 2
+God 2
+Goe 2
+Gu 2
+Győ 2
+Gán 2
+Gé 2
+H- 2
+H-e 2
+HI 2
+HIV 2
+Haj 2
+Hat 2
+Hel 2
+Hon 2
+Hot 2
+HÉ 2
+HÉV 2
+Hár 2
+Hát 2
+Ház 2
+Hé 2
+III 2
+IS 2
+IV 2
+IV- 2
+Ide 2
+Idé 2
+Ige 2
+Igo 2
+Ild 2
+Ind 2
+Ing 2
+Ir 2
+Isz 2
+Iz 2
+Izm 2
+Jac 2
+Jag 2
+Jam 2
+Jos 2
+Jud 2
+Jus 2
+Jól 2
+Jö 2
+Jöv 2
+Jú 2
+K-o 2
+Kan 2
+Kau 2
+Kaz 2
+Kht 2
+Kir 2
+Kj 2
+Kn 2
+Koh 2
+Kol 2
+Kom 2
+Kri 2
+Kul 2
+Kup 2
+Kör 2
+Kő 2
+Lab 2
+Lak 2
+Las 2
+Leh 2
+Lek 2
+Lem 2
+Len 2
+Lou 2
+Lé 2
+MTK 2
+Mai 2
+Men 2
+Mih 2
+Mié 2
+Mol 2
+Mom 2
+Mun 2
+MÁ 2
+MÁV 2
+Mát 2
+Mü 2
+Mül 2
+Műv 2
+Nek 2
+Nyi 2
+Nép 2
+Nö 2
+Növ 2
+O-e 2
+O-t 2
+Ok 2
+Okt 2
+Orv 2
+Os 2
+PE 2
+PEH 2
+PO 2
+PT 2
+PTF 2
+Pes 2
+Pie 2
+Pon 2
+Pos 2
+Pra 2
+Pro 2
+Put 2
+QI 2
+RTS 2
+Rab 2
+Raj 2
+Ran 2
+Ruh 2
+Ráb 2
+Ré 2
+Rég 2
+Rö 2
+S-b 2
+SPO 2
+Sad 2
+Sen 2
+Sió 2
+Sk 2
+Sko 2
+Sor 2
+Spo 2
+Ste 2
+Stú 2
+Szi 2
+Szí 2
+Ső 2
+Sőt 2
+TF 2
+TS 2
+Tel 2
+Tet 2
+Tis 2
+Tup 2
+Tü 2
+Tür 2
+UE 2
+UEF 2
+US 2
+USA 2
+Uk 2
+Ukr 2
+Ut 2
+V- 2
+V-v 2
+VI 2
+VII 2
+Vat 2
+Vid 2
+Voo 2
+Vu 2
+Vál 2
+Vég 2
+Wal 2
+Was 2
+Wes 2
+Wh 2
+Whi 2
+Wil 2
+Wor 2
+Wü 2
+Wür 2
+XV 2
+XVI 2
+Yb 2
+Ybl 2
+Yo 2
+Z-e 2
+Z-f 2
+Zor 2
+a-m 2
+a-t 2
+aad 2
+abh 2
+abl 2
+abr 2
+abu 2
+adb 2
+ade 2
+adl 2
+aer 2
+aes 2
+aff 2
+afr 2
+agb 2
+agr 2
+agv 2
+aif 2
+aih 2
+aj- 2
+aja 2
+ajh 2
+aji 2
+ajj 2
+ajm 2
+ajv 2
+akb 2
+akj 2
+akp 2
+alc 2
+amm 2
+amr 2
+anr 2
+apú 2
+are 2
+asd 2
+asi 2
+asn 2
+asr 2
+ats 2
+atu 2
+atú 2
+atő 2
+avr 2
+avt 2
+avú 2
+ay- 2
+azf 2
+azk 2
+aél 2
+aö 2
+aön 2
+bbl 2
+beg 2
+beo 2
+bh 2
+bhá 2
+bic 2
+bie 2
+bit 2
+biá 2
+bla 2
+ble 2
+blo 2
+bm 2
+bmé 2
+bni 2
+bob 2
+bod 2
+bre 2
+brü 2
+bso 2
+buk 2
+báj 2
+béc 2
+búc 2
+búz 2
+bül 2
+can 2
+cat 2
+cet 2
+cig 2
+cip 2
+cir 2
+civ 2
+cks 2
+cn 2
+cos 2
+cró 2
+csl 2
+czi 2
+cáb 2
+cár 2
+dam 2
+dex 2
+dic 2
+die 2
+dir 2
+div 2
+dle 2
+dmo 2
+dob 2
+drő 2
+dua 2
+dum 2
+dze 2
+dét 2
+dó- 2
+dód 2
+dóh 2
+dót 2
+döl 2
+dú 2
+düg 2
+düh 2
+dői 2
+dőp 2
+dőv 2
+dőz 2
+e-a 2
+eal 2
+ebi 2
+eci 2
+eck 2
+edf 2
+eeg 2
+een 2
+eer 2
+efa 2
+efú 2
+egó 2
+egö 2
+egő 2
+ehh 2
+ehí 2
+eic 2
+eis 2
+eka 2
+ekc 2
+elp 2
+elu 2
+elú 2
+elű 2
+emk 2
+ems 2
+emu 2
+emá 2
+en- 2
+enh 2
+ení 2
+epa 2
+eph 2
+eps 2
+erf 2
+es- 2
+esa 2
+esf 2
+esh 2
+evr 2
+evű 2
+ewi 2
+exa 2
+exk 2
+ext 2
+ezb 2
+eán 2
+eép 2
+ffe 2
+ffi 2
+fi- 2
+fid 2
+fie 2
+fiá 2
+fió 2
+fli 2
+fro 2
+fur 2
+fus 2
+fór 2
+fúv 2
+főp 2
+g! 2
+g-i 2
+gap 2
+gib 2
+gik 2
+giu 2
+gjó 2
+gkr 2
+gli 2
+glé 2
+gno 2
+gná 2
+god 2
+gov 2
+gső 2
+gtá 2
+gug 2
+gyí 2
+gza 2
+gzí 2
+gád 2
+géh 2
+gó- 2
+gór 2
+gúj 2
+hac 2
+hhe 2
+hie 2
+hil 2
+hl 2
+hom 2
+hrg 2
+hus 2
+hág 2
+híd 2
+hít 2
+hól 2
+hóv 2
+hü 2
+hül 2
+hű 2
+ia- 2
+iav 2
+ibi 2
+idr 2
+idu 2
+idz 2
+iej 2
+iew 2
+iff 2
+ifé 2
+ifö 2
+igr 2
+igu 2
+ijö 2
+iki 2
+ikr 2
+ikó 2
+imn 2
+imu 2
+in- 2
+inj 2
+inr 2
+inv 2
+iov 2
+ipr 2
+ipó 2
+ipő 2
+iq 2
+iqu 2
+irc 2
+irr 2
+iru 2
+irő 2
+itb 2
+its 2
+ity 2
+ité 2
+itú 2
+itű 2
+iáv 2
+iáé 2
+iód 2
+ióm 2
+ión 2
+iük 2
+j-s 2
+jag 2
+jak 2
+jap 2
+jas 2
+jbó 2
+jcb 2
+jdn 2
+jev 2
+jfa 2
+jil 2
+jje 2
+jov 2
+jté 2
+jud 2
+juh 2
+jza 2
+jzi 2
+jás 2
+jáé 2
+jí 2
+jít 2
+jór 2
+jót 2
+jűl 2
+k-K 2
+k-h 2
+kae 2
+keb 2
+kfu 2
+kha 2
+khö 2
+ki- 2
+kib 2
+kii 2
+kié 2
+kja 2
+kje 2
+kk- 2
+kké 2
+kla 2
+kmé 2
+kmű 2
+kny 2
+kré 2
+krí 2
+ksa 2
+kti 2
+kté 2
+ktö 2
+kud 2
+kun 2
+kve 2
+kvé 2
+kák 2
+köb 2
+lah 2
+lai 2
+lbo 2
+lbő 2
+lci 2
+lcz 2
+ldu 2
+lee 2
+lfi 2
+li- 2
+lir 2
+lku 2
+llj 2
+lmü 2
+lmű 2
+lno 2
+lor 2
+lpe 2
+lpr 2
+lra 2
+lrő 2
+lso 2
+lsü 2
+ltt 2
+lvh 2
+lyp 2
+lyü 2
+lzé 2
+lző 2
+lák 2
+léd 2
+lól 2
+löz 2
+lúj 2
+lün 2
+lő- 2
+lű 2
+maf 2
+mbá 2
+mem 2
+mfi 2
+mih 2
+mla 2
+mmé 2
+mne 2
+mná 2
+mpa 2
+mpu 2
+mró 2
+msá 2
+mte 2
+móp 2
+mün 2
+műh 2
+n-k 2
+n-m 2
+nac 2
+naz 2
+nbu 2
+nbü 2
+ncu 2
+ncé 2
+ndb 2
+ndű 2
+ney 2
+nfa 2
+nfö 2
+ngl 2
+ngú 2
+nim 2
+niü 2
+njo 2
+nkf 2
+nkk 2
+nks 2
+nkö 2
+nkü 2
+nmű 2
+nnh 2
+noj 2
+not 2
+noz 2
+npó 2
+nra 2
+nso 2
+nsv 2
+nsú 2
+ntg 2
+ntű 2
+nvi 2
+nyő 2
+nz- 2
+nza 2
+nzn 2
+nzo 2
+nzí 2
+nző 2
+náé 2
+nóm 2
+nós 2
+nóz 2
+nöt 2
+núj 2
+nüt 2
+nőe 2
+o-á 2
+obe 2
+obs 2
+ods 2
+oeb 2
+oge 2
+ogg 2
+ogs 2
+ogt 2
+ohl 2
+ojk 2
+okj 2
+okl 2
+ol- 2
+ome 2
+omf 2
+omt 2
+omó 2
+one 2
+onh 2
+oní 2
+oon 2
+opu 2
+orh 2
+osk 2
+osm 2
+osú 2
+otb 2
+oti 2
+oui 2
+ox 2
+oxi 2
+pbé 2
+pin 2
+pkö 2
+pla 2
+pm 2
+pmű 2
+pne 2
+prá 2
+pub 2
+puk 2
+put 2
+pác 2
+páp 2
+pát 2
+péc 2
+pój 2
+pú 2
+púr 2
+que 2
+r-f 2
+r. 2
+raö 2
+rbo 2
+rbr 2
+rbó 2
+rbő 2
+rdd 2
+rdi 2
+rdr 2
+rdö 2
+rdő 2
+rec 2
+rfo 2
+rg- 2
+rgu 2
+rgá 2
+rho 2
+rib 2
+rim 2
+riq 2
+rjo 2
+rjú 2
+rld 2
+rlé 2
+rnj 2
+roc 2
+roh 2
+rsm 2
+rsó 2
+rt- 2
+rtm 2
+rtv 2
+rtü 2
+rvb 2
+rvh 2
+rvi 2
+rzo 2
+rzu 2
+rzó 2
+ráf 2
+ráv 2
+rél 2
+rép 2
+ríz 2
+róg 2
+rón 2
+róz 2
+rún 2
+rúz 2
+rüc 2
+rüs 2
+rőf 2
+rői 2
+rőz 2
+rűb 2
+rűe 2
+rűl 2
+s-K 2
+s-c 2
+s-f 2
+s-k 2
+s-t 2
+sbö 2
+sbő 2
+see 2
+sej 2
+sfe 2
+sfo 2
+sha 2
+sia 2
+sib 2
+sir 2
+siá 2
+sj 2
+sku 2
+sky 2
+slé 2
+sló 2
+smi 2
+smó 2
+sná 2
+sné 2
+sov 2
+spe 2
+stm 2
+sto 2
+stú 2
+sum 2
+sva 2
+své 2
+sző 2
+síf 2
+sót 2
+sús 2
+süp 2
+sűr 2
+t, 2
+t-á 2
+tad 2
+tbi 2
+tbá 2
+tbő 2
+tda 2
+ted 2
+tee 2
+tfe 2
+tfú 2
+tge 2
+tic 2
+tie 2
+tig 2
+tiá 2
+tju 2
+tki 2
+tmi 2
+tox 2
+tri 2
+tré 2
+tss 2
+ttn 2
+ttö 2
+tuc 2
+tug 2
+tye 2
+tz 2
+töd 2
+túc 2
+tüt 2
+tő- 2
+tőb 2
+tőh 2
+tőt 2
+ual 2
+ubo 2
+ucr 2
+udá 2
+ue 2
+uf 2
+ugg 2
+ugr 2
+ugt 2
+ugó 2
+uha 2
+uhr 2
+uin 2
+ukh 2
+ulb 2
+ulj 2
+umn 2
+umt 2
+upe 2
+upo 2
+upr 2
+urk 2
+uru 2
+usr 2
+uth 2
+uva 2
+uxe 2
+vaj 2
+vha 2
+vhe 2
+vih 2
+vin 2
+vja 2
+vjá 2
+vkö 2
+vn 2
+vsk 2
+vte 2
+vám 2
+véh 2
+vít 2
+vív 2
+vór 2
+vúr 2
+vői 2
+was 2
+wi 2
+wsk 2
+x- 2
+xa 2
+xan 2
+xe 2
+xem 2
+xik 2
+xk 2
+xko 2
+xt 2
+y-d 2
+y-k 2
+ybő 2
+yem 2
+yep 2
+yfi 2
+yhü 2
+yid 2
+yie 2
+yij 2
+yip 2
+yná 2
+yog 2
+yra 2
+yv- 2
+yzo 2
+yév 2
+z-M 2
+z-t 2
+zae 2
+zam 2
+zap 2
+zar 2
+zaé 2
+zc 2
+zdo 2
+zdé 2
+zef 2
+zej 2
+zew 2
+zex 2
+zgá 2
+zhi 2
+zho 2
+zib 2
+zio 2
+ziu 2
+ziá 2
+zja 2
+zké 2
+zsa 2
+zsk 2
+ztg 2
+zty 2
+ztí 2
+zut 2
+záb 2
+zéh 2
+zóa 2
+zób 2
+zóf 2
+zóh 2
+zón 2
+zúd 2
+zől 2
+ÁP 2
+ÁPT 2
+ÁV 2
+ÉV 2
+Élő 2
+Épp 2
+Épí 2
+Ért 2
+Önk 2
+Ús 2
+Úst 2
+ábe 2
+áda 2
+ádb 2
+ádl 2
+ádn 2
+ádü 2
+ág! 2
+ágy 2
+ágó 2
+ágü 2
+áim 2
+ájd 2
+ájú 2
+álm 2
+ámb 2
+ámr 2
+ámt 2
+ámv 2
+án- 2
+ánp 2
+ánv 2
+ápa 2
+árf 2
+ás- 2
+ásm 2
+ásp 2
+ásv 2
+átü 2
+áve 2
+ává 2
+ávé 2
+ávú 2
+ázz 2
+áép 2
+éba 2
+ébr 2
+édb 2
+édj 2
+édt 2
+égc 2
+égk 2
+égp 2
+éja 2
+ékp 2
+éks 2
+ékv 2
+ékú 2
+élb 2
+élu 2
+élá 2
+éló 2
+énk 2
+énn 2
+éní 2
+épc 2
+éph 2
+épi 2
+épm 2
+érj 2
+ét, 2
+éta 2
+éti 2
+étn 2
+étv 2
+ézb 2
+ézh 2
+ézn 2
+íd 2
+íf 2
+ífe 2
+íjb 2
+ínf 2
+ínm 2
+íné 2
+írh 2
+íri 2
+írs 2
+írü 2
+íva 2
+ívé 2
+ívó 2
+íz- 2
+ízb 2
+ódu 2
+óe 2
+ófi 2
+ófo 2
+ófú 2
+óhe 2
+óhi 2
+óia 2
+óje 2
+ókb 2
+ókh 2
+óku 2
+ókö 2
+ólv 2
+óma 2
+ómi 2
+óro 2
+óru 2
+óró 2
+ósa 2
+ózó 2
+öbm 2
+ödt 2
+ögn 2
+ögz 2
+ökr 2
+öll 2
+önd 2
+öp- 2
+öri 2
+örm 2
+örr 2
+ötl 2
+úb 2
+úci 2
+úgá 2
+újf 2
+úju 2
+újá 2
+újí 2
+úró 2
+úsi 2
+útm 2
+útn 2
+úv 2
+úvá 2
+úzn 2
+úzt 2
+üc 2
+ück 2
+ühö 2
+ükb 2
+ükh 2
+üki 2
+üp 2
+üpp 2
+üsz 2
+ütk 2
+üv 2
+üve 2
+ő-h 2
+ő-p 2
+őbi 2
+őbí 2
+őib 2
+őit 2
+őjá 2
+őka 2
+őkb 2
+őné 2
+őor 2
+őpr 2
+őr- 2
+ősr 2
+ősü 2
+őví 2
+őzh 2
+őzm 2
+űb 2
+űbb 2
+űek 2
+űen 2
+űh 2
+űlt 2
+űlá 2
+űnc 2
+űnö 2
+űrű 2
+űte 2
+űző 2
+!- 1
+!-g 1
+"- 1
+"-n 1
+"J 1
+"Jö 1
+"P 1
+"Pr 1
+'9 1
+'99 1
+(i 1
+(i) 1
++ 1
++3 1
+,12 1
+,19 1
+,33 1
+,4- 1
+,45 1
+,64 1
+,8- 1
+,9- 1
+,93 1
+-1, 1
+-14 1
+-15 1
+-22 1
+-23 1
+-3, 1
+-40 1
+-5- 1
+-50 1
+-8 1
+-80 1
+-9 1
+-96 1
+-A 1
+-Am 1
+-Br 1
+-Co 1
+-Cs 1
+-Da 1
+-De 1
+-Di 1
+-E 1
+-Eu 1
+-F 1
+-Fi 1
+-Gi 1
+-Gy 1
+-He 1
+-Hi 1
+-Ho 1
+-Kö 1
+-MP 1
+-MT 1
+-P 1
+-Pr 1
+-W 1
+-Wü 1
+-Z 1
+-Ze 1
+-ab 1
+-ai 1
+-al 1
+-am 1
+-au 1
+-bi 1
+-bá 1
+-fr 1
+-ga 1
+-gy 1
+-hi 1
+-há 1
+-hí 1
+-id 1
+-il 1
+-jo 1
+-já 1
+-jú 1
+-ki 1
+-kí 1
+-kü 1
+-l 1
+-le 1
+-ma 1
+-mó 1
+-na 1
+-nö 1
+-od 1
+-pi 1
+-ps 1
+-ro 1
+-ró 1
+-se 1
+-ti 1
+-tu 1
+-tó 1
+-uk 1
+-ut 1
+-z 1
+-ze 1
+-ét 1
+-öt 1
+-ü 1
+-üg 1
+.-j 1
+.-n 1
+.j 1
+.jú 1
+0" 1
+0"- 1
+0,1 1
+0,5 1
+0,7 1
+0,8 1
+0-2 1
+0-4 1
+0-5 1
+0-8 1
+0-s 1
+0-t 1
+0-é 1
+0.- 1
+00" 1
+001 1
+003 1
+01 1
+01- 1
+02, 1
+03 1
+04 1
+1,2 1
+1,3 1
+1,4 1
+1,7 1
+1,9 1
+1-1 1
+1-i 1
+1-t 1
+102 1
+104 1
+107 1
+112 1
+12, 1
+12- 1
+12. 1
+13- 1
+13. 1
+134 1
+135 1
+139 1
+14, 1
+140 1
+147 1
+15- 1
+16+ 1
+164 1
+17. 1
+170 1
+171 1
+175 1
+188 1
+19, 1
+2,3 1
+2,4 1
+2,9 1
+2-0 1
+2-2 1
+2-3 1
+2-6 1
+2-r 1
+2-t 1
+2-á 1
+20, 1
+20. 1
+214 1
+22, 1
+22- 1
+23, 1
+23- 1
+24- 1
+25. 1
+27- 1
+270 1
+279 1
+28, 1
+28- 1
+280 1
+29. 1
+2K 1
+3,3 1
+3,4 1
+3,7 1
+3,9 1
+3-2 1
+3-4 1
+3-5 1
+3-a 1
+3-á 1
+311 1
+330 1
+338 1
+35, 1
+35- 1
+36 1
+38, 1
+39. 1
+396 1
+4,1 1
+4-1 1
+4-9 1
+4-f 1
+4-é 1
+40. 1
+413 1
+42, 1
+430 1
+434 1
+44, 1
+44. 1
+450 1
+46 1
+47, 1
+47- 1
+47. 1
+485 1
+49- 1
+49. 1
+5,5 1
+5,6 1
+5,7 1
+5,8 1
+5-1 1
+5-2 1
+5-6 1
+5-7 1
+5-e 1
+5-i 1
+52 1
+52. 1
+53 1
+53, 1
+55- 1
+553 1
+56- 1
+57- 1
+6+ 1
+6+3 1
+6,6 1
+6,8 1
+6-7 1
+6-a 1
+6. 1
+60. 1
+62 1
+66 1
+660 1
+67 1
+67- 1
+68. 1
+69- 1
+7,8 1
+7-é 1
+70- 1
+700 1
+71, 1
+73 1
+76 1
+76, 1
+77. 1
+79- 1
+8,3 1
+8,6 1
+8,9 1
+8-t 1
+81- 1
+82 1
+84- 1
+84. 1
+85, 1
+85. 1
+87 1
+88 1
+880 1
+89 1
+9,2 1
+9,4 1
+9,5 1
+9,8 1
+9,9 1
+9-d 1
+9.j 1
+90. 1
+900 1
+925 1
+927 1
+93- 1
+93. 1
+94. 1
+944 1
+955 1
+96. 1
+967 1
+970 1
+973 1
+979 1
+980 1
+981 1
+984 1
+989 1
+AG 1
+AS 1
+AS- 1
+AW 1
+AWS 1
+Ab 1
+Abo 1
+Add 1
+Adi 1
+Ado 1
+Afr 1
+Ah 1
+Ahm 1
+Akc 1
+Ako 1
+Aks 1
+Akt 1
+Alf 1
+All 1
+Alm 1
+Alt 1
+Amb 1
+Ame 1
+Amí 1
+Ant 1
+Arb 1
+Aro 1
+Arr 1
+As 1
+Asz 1
+Ate 1
+Atr 1
+Aud 1
+Aus 1
+Aut 1
+Avr 1
+Avt 1
+Aze 1
+Azz 1
+B-s 1
+B-ü 1
+BL- 1
+BM 1
+BMW 1
+BS 1
+BS- 1
+Baá 1
+Bef 1
+Ben 1
+Bil 1
+Bok 1
+Bol 1
+Bom 1
+Bp 1
+Bp. 1
+Brd 1
+Bék 1
+Bél 1
+Bér 1
+Bí 1
+Bír 1
+Bö 1
+Bör 1
+Bü 1
+Bül 1
+Bőh 1
+Bőv 1
+CB 1
+CD- 1
+CK 1
+CT 1
+CTK 1
+Cam 1
+Cen 1
+Ces 1
+Che 1
+Ci 1
+Cig 1
+Col 1
+Coo 1
+Cos 1
+Cot 1
+D-h 1
+D-m 1
+D-n 1
+D-s 1
+DP- 1
+Dan 1
+Dat 1
+Dau 1
+Den 1
+Dep 1
+Der 1
+Die 1
+Dj 1
+Dji 1
+Dol 1
+Dom 1
+Dor 1
+Dr. 1
+Dra 1
+Dru 1
+Dá 1
+Dán 1
+Dén 1
+Dö 1
+Dön 1
+Ea 1
+Eas 1
+Ece 1
+Edd 1
+Edg 1
+Edu 1
+Elk 1
+Elu 1
+Elv 1
+Elé 1
+Emb 1
+Eme 1
+Eml 1
+End 1
+Ene 1
+Eng 1
+Eny 1
+Ere 1
+Ern 1
+Ero 1
+Erő 1
+Ess 1
+Est 1
+Esz 1
+Eti 1
+Ett 1
+Ezú 1
+Eö 1
+Eör 1
+F-F 1
+F-e 1
+F-n 1
+FO 1
+FOR 1
+Fal 1
+Fig 1
+Fir 1
+Fiu 1
+Fj 1
+Fjo 1
+Fod 1
+Fok 1
+Fre 1
+Fri 1
+Fu 1
+Ful 1
+Fél 1
+Fés 1
+Füg 1
+Für 1
+Főb 1
+Fői 1
+Főv 1
+G-t 1
+GB- 1
+Gaa 1
+Gab 1
+Gel 1
+Gen 1
+Glo 1
+Gog 1
+Gon 1
+Gra 1
+Grá 1
+Grú 1
+Gug 1
+Gur 1
+Gyá 1
+Gyó 1
+Gép 1
+Géz 1
+Gü 1
+Gün 1
+Gő 1
+Gőz 1
+HVM 1
+Hab 1
+Hac 1
+Had 1
+Hah 1
+Haz 1
+Heg 1
+Hei 1
+Hen 1
+Hep 1
+Hic 1
+Hit 1
+Hoe 1
+Hog 1
+Hom 1
+Hos 1
+Hov 1
+Hoz 1
+Hus 1
+Hya 1
+Hág 1
+Hán 1
+Héj 1
+Hét 1
+Hú 1
+Hús 1
+I- 1
+I-é 1
+IK- 1
+ISE 1
+ISM 1
+Igy 1
+Ili 1
+Ilj 1
+Inf 1
+Inv 1
+Ip 1
+Ipa 1
+Iro 1
+Irá 1
+It 1
+Itt 1
+Ive 1
+Jee 1
+Jer 1
+Jev 1
+Joa 1
+Jog 1
+Joh 1
+Jun 1
+Jur 1
+Jut 1
+Juv 1
+Júl 1
+Jún 1
+Jü 1
+Jür 1
+K-b 1
+K-p 1
+K-r 1
+K-t 1
+KF 1
+KFO 1
+KH 1
+KHV 1
+Kab 1
+Kas 1
+Kav 1
+Kec 1
+Ked 1
+Kem 1
+Kev 1
+Khu 1
+Kic 1
+Kij 1
+Kil 1
+Kiv 1
+Kiz 1
+Kje 1
+Kju 1
+Kno 1
+Knu 1
+Kob 1
+Kod 1
+Kop 1
+Kés 1
+Kí 1
+Kís 1
+Köd 1
+Köl 1
+Küh 1
+Küz 1
+L- 1
+L-b 1
+L. 1
+Lad 1
+Laf 1
+Lap 1
+Lel 1
+Lep 1
+Les 1
+Lew 1
+Lip 1
+Liv 1
+Lp 1
+Lpu 1
+Lt 1
+Ltd 1
+Luc 1
+Lui 1
+Luj 1
+Lut 1
+Lux 1
+Lán 1
+Lát 1
+Lék 1
+Lét 1
+M0 1
+M0- 1
+M1 1
+M1- 1
+MI 1
+MIK 1
+MP 1
+MPP 1
+MS 1
+MSZ 1
+MTA 1
+MW 1
+MZ 1
+MZE 1
+Mab 1
+Mad 1
+Mah 1
+Maj 1
+Mat 1
+Maz 1
+Mec 1
+Mek 1
+Mie 1
+Mir 1
+Mis 1
+Moh 1
+Mon 1
+Moo 1
+Mor 1
+Mov 1
+Mr 1
+Mro 1
+Mul 1
+Mum 1
+Mus 1
+Mád 1
+Mét 1
+Mí 1
+Míg 1
+Mó 1
+Món 1
+NB 1
+NB- 1
+NM 1
+NMI 1
+Nac 1
+Nas 1
+Neh 1
+Nev 1
+New 1
+Nic 1
+Nik 1
+Nob 1
+Noh 1
+Nor 1
+Nyá 1
+Nyí 1
+Ná 1
+Nád 1
+Nég 1
+O-b 1
+O-h 1
+O-o 1
+OR 1
+OR- 1
+Od 1
+Oda 1
+Olü 1
+On 1
+Oni 1
+Opt 1
+Ore 1
+Orw 1
+Osk 1
+Oss 1
+Ot 1
+Ott 1
+P- 1
+P-t 1
+PN 1
+PNB 1
+PP 1
+Pac 1
+Paj 1
+Pak 1
+Pal 1
+Par 1
+Paz 1
+Pf 1
+Pfe 1
+Ph 1
+Phi 1
+Pik 1
+Pit 1
+Pof 1
+Prá 1
+Ps 1
+Psz 1
+Pul 1
+Pák 1
+Pál 1
+Pél 1
+Pó 1
+Pód 1
+QI- 1
+Qu 1
+Qua 1
+R- 1
+R-g 1
+RH 1
+Rea 1
+Red 1
+Reg 1
+Rek 1
+Rem 1
+Ren 1
+Rep 1
+Res 1
+Reu 1
+Rev 1
+Rod 1
+Rog 1
+Roh 1
+Rom 1
+Ros 1
+Rus 1
+Rád 1
+Ráj 1
+Rám 1
+Ró 1
+Róz 1
+Röb 1
+Röv 1
+S-e 1
+S-s 1
+S-t 1
+SAS 1
+SE 1
+SM 1
+SS 1
+SS- 1
+SZP 1
+SZT 1
+Sah 1
+Sak 1
+Sam 1
+Sea 1
+Seo 1
+Ser 1
+Sie 1
+Sir 1
+Soh 1
+Som 1
+Sop 1
+Spi 1
+Str 1
+Sy 1
+Sys 1
+Szm 1
+Szu 1
+Szó 1
+Sző 1
+Szű 1
+Sár 1
+Sú 1
+Súl 1
+TA 1
+TF- 1
+Tab 1
+Tap 1
+Tat 1
+Tes 1
+Tev 1
+The 1
+Tim 1
+Tod 1
+Tol 1
+Ton 1
+Top 1
+Tov 1
+TÁ 1
+TÁR 1
+Tá 1
+Tár 1
+Töm 1
+Töt 1
+Tű 1
+Tűz 1
+U-c 1
+U-n 1
+UC 1
+UCK 1
+UM 1
+UMZ 1
+UN 1
+UNM 1
+UR 1
+URH 1
+Ue 1
+Uec 1
+Uga 1
+Ur 1
+Uru 1
+Uta 1
+Uto 1
+VM 1
+Vaj 1
+Var 1
+Vas 1
+Vec 1
+Vek 1
+Vel 1
+Vez 1
+Voc 1
+Vuk 1
+Vár 1
+Véd 1
+Vék 1
+Vél 1
+Vér 1
+Ví 1
+Víz 1
+WS 1
+Wag 1
+Wat 1
+Wie 1
+Wol 1
+XI 1
+XII 1
+Y2 1
+Y2K 1
+Yol 1
+Yor 1
+Z-c 1
+ZE 1
+ZK- 1
+ZP 1
+ZT 1
+ZTÁ 1
+Zac 1
+Zal 1
+Zap 1
+Zav 1
+Zef 1
+Zei 1
+Zet 1
+Zsa 1
+Zy 1
+Zyc 1
+a-B 1
+a-G 1
+a-H 1
+a-T 1
+a-c 1
+a-d 1
+a-h 1
+a-p 1
+a-á 1
+aal 1
+abn 1
+abt 1
+acg 1
+acv 1
+acá 1
+acé 1
+ad- 1
+adf 1
+adg 1
+adm 1
+adö 1
+adú 1
+aeg 1
+aek 1
+afi 1
+afo 1
+afu 1
+afó 1
+afö 1
+agd 1
+agh 1
+agk 1
+agl 1
+agm 1
+agz 1
+ahí 1
+ahó 1
+ai- 1
+aid 1
+aig 1
+ais 1
+aié 1
+ajc 1
+ajf 1
+ajö 1
+ald 1
+alf 1
+alr 1
+aml 1
+amv 1
+amé 1
+amí 1
+amü 1
+anv 1
+anz 1
+ao 1
+aot 1
+apd 1
+aph 1
+apz 1
+apé 1
+apó 1
+aq 1
+aqu 1
+arn 1
+ary 1
+arű 1
+as- 1
+asb 1
+ase 1
+asf 1
+ask 1
+atf 1
+atg 1
+atp 1
+atz 1
+atö 1
+atű 1
+aul 1
+aur 1
+auz 1
+avs 1
+avy 1
+avé 1
+axá 1
+aze 1
+azl 1
+aál 1
+aán 1
+aár 1
+aén 1
+aér 1
+aí 1
+aít 1
+aú 1
+aúd 1
+b-n 1
+b-u 1
+bac 1
+bae 1
+bag 1
+bah 1
+bai 1
+bam 1
+bas 1
+bav 1
+baz 1
+bb- 1
+bbf 1
+bbj 1
+bbk 1
+bbt 1
+bbó 1
+bbü 1
+bch 1
+be- 1
+beb 1
+bee 1
+bf 1
+bfo 1
+bi- 1
+bib 1
+big 1
+bju 1
+bjá 1
+bkö 1
+bl- 1
+boj 1
+bou 1
+bsb 1
+buc 1
+buf 1
+bun 1
+by 1
+bz 1
+bzó 1
+báb 1
+bác 1
+bám 1
+báv 1
+bév 1
+bíc 1
+bók 1
+bón 1
+bóz 1
+böl 1
+bür 1
+bőr 1
+bűv 1
+cak 1
+cas 1
+cce 1
+cd 1
+cde 1
+ce" 1
+ce- 1
+ceW 1
+cea 1
+cev 1
+cg 1
+cga 1
+chb 1
+cho 1
+cht 1
+chu 1
+ché 1
+cid 1
+cie 1
+cif 1
+cim 1
+cié 1
+cka 1
+ckb 1
+ckl 1
+ckő 1
+cna 1
+cni 1
+com 1
+cop 1
+cp 1
+cpe 1
+cre 1
+csf 1
+csj 1
+css 1
+csz 1
+csí 1
+csű 1
+cud 1
+cuk 1
+cul 1
+cum 1
+cun 1
+cur 1
+czo 1
+czy 1
+cáf 1
+cák 1
+cán 1
+cát 1
+céz 1
+d-B 1
+d-c 1
+d-f 1
+d. 1
+dab 1
+dac 1
+dah 1
+daj 1
+dav 1
+dbó 1
+dbő 1
+ddá 1
+de- 1
+ded 1
+deh 1
+deo 1
+deá 1
+dfe 1
+dga 1
+dgo 1
+did 1
+dif 1
+dii 1
+diu 1
+dji 1
+dju 1
+dkö 1
+dlo 1
+dmá 1
+dmű 1
+dny 1
+dná 1
+dné 1
+dnó 1
+doh 1
+dp 1
+dpe 1
+dr. 1
+dri 1
+dré 1
+drö 1
+drú 1
+dsé 1
+dts 1
+dtó 1
+dtü 1
+dun 1
+duu 1
+duv 1
+dvé 1
+dvö 1
+dvű 1
+dy 1
+dáh 1
+dái 1
+dáv 1
+dáz 1
+déd 1
+déi 1
+dér 1
+díz 1
+dób 1
+dóc 1
+dóf 1
+dói 1
+dóv 1
+dök 1
+döm 1
+dúr 1
+dük 1
+dőe 1
+dőh 1
+dőt 1
+dűe 1
+dűr 1
+dűs 1
+e" 1
+e-C 1
+e-e 1
+e-i 1
+e-k 1
+e-l 1
+e-o 1
+e-t 1
+eW 1
+eWa 1
+eag 1
+eat 1
+eaz 1
+eba 1
+ebá 1
+ebé 1
+eco 1
+ecz 1
+ecé 1
+eds 1
+edu 1
+edű 1
+ee- 1
+eel 1
+eep 1
+eet 1
+efl 1
+efn 1
+efű 1
+egc 1
+egd 1
+egű 1
+eh- 1
+ehg 1
+ehm 1
+ehű 1
+ei- 1
+eid 1
+eif 1
+eih 1
+eim 1
+ej- 1
+ejj 1
+ejo 1
+ek- 1
+ekd 1
+eku 1
+eká 1
+em- 1
+emf 1
+emh 1
+emn 1
+emó 1
+emü 1
+eno 1
+enö 1
+eol 1
+eos 1
+eot 1
+eou 1
+eoz 1
+epj 1
+epo 1
+eró 1
+esc 1
+esg 1
+esr 1
+esv 1
+esú 1
+ety 1
+eud 1
+eut 1
+ev- 1
+evg 1
+evj 1
+evü 1
+ex- 1
+exu 1
+ey- 1
+ez- 1
+ezf 1
+ezk 1
+ezo 1
+ezü 1
+eák 1
+eát 1
+fa- 1
+fae 1
+far 1
+fei 1
+ffo 1
+fii 1
+fis 1
+fit 1
+fj. 1
+fle 1
+fn 1
+fne 1
+foz 1
+frá 1
+fuk 1
+fun 1
+fuv 1
+fy 1
+fáb 1
+fár 1
+fát 1
+fáz 1
+fém 1
+fób 1
+fók 1
+fön 1
+föz 1
+fúr 1
+fül 1
+főa 1
+főg 1
+fől 1
+főm 1
+főu 1
+főá 1
+főú 1
+főü 1
+g!- 1
+g-k 1
+g-t 1
+g-á 1
+ga- 1
+gbi 1
+gbő 1
+gcé 1
+gdo 1
+gdu 1
+ge- 1
+gej 1
+gfé 1
+ggó 1
+ggö 1
+ghr 1
+ghs 1
+ght 1
+ghú 1
+gid 1
+gie 1
+gio 1
+gip 1
+gki 1
+gko 1
+gku 1
+gkí 1
+glu 1
+glá 1
+gló 1
+glő 1
+gni 1
+gné 1
+gom 1
+gop 1
+gpe 1
+gpé 1
+gri 1
+grú 1
+gsi 1
+gso 1
+gsp 1
+gst 1
+gum 1
+gun 1
+gvo 1
+gvó 1
+gyp 1
+gyu 1
+gzs 1
+gzó 1
+gáh 1
+gáv 1
+gég 1
+gék 1
+géé 1
+gób 1
+góc 1
+góh 1
+gós 1
+gök 1
+göl 1
+göm 1
+gör 1
+gún 1
+gőb 1
+gőd 1
+gőr 1
+gőz 1
+h- 1
+h-s 1
+ha- 1
+hab 1
+hb 1
+hbó 1
+hed 1
+hei 1
+hg 1
+hgj 1
+hip 1
+hll 1
+hma 1
+hme 1
+hnn 1
+hno 1
+hoc 1
+hod 1
+hok 1
+hot 1
+hou 1
+hra 1
+htj 1
+hur 1
+hák 1
+hás 1
+hä 1
+häu 1
+hén 1
+hés 1
+hóa 1
+hóc 1
+hóz 1
+höd 1
+höt 1
+hőf 1
+hűl 1
+hűt 1
+i) 1
+i-c 1
+i-f 1
+i-j 1
+i-k 1
+i-s 1
+i-t 1
+i-v 1
+i-é 1
+iag 1
+iam 1
+iar 1
+iaá 1
+ibb 1
+ibc 1
+ibl 1
+ibó 1
+icc 1
+ick 1
+icn 1
+ico 1
+icu 1
+icz 1
+idt 1
+idá 1
+ieb 1
+ifu 1
+ifá 1
+ihá 1
+iim 1
+iin 1
+iip 1
+iir 1
+iiz 1
+ijn 1
+iju 1
+ik- 1
+ikb 1
+iks 1
+ild 1
+ilh 1
+ilé 1
+iló 1
+imb 1
+imr 1
+imí 1
+inh 1
+iog 1
+iol 1
+ipn 1
+ipp 1
+ips 1
+ipu 1
+irb 1
+irs 1
+isg 1
+ish 1
+isp 1
+isu 1
+itf 1
+itv 1
+ití 1
+itö 1
+itő 1
+ivb 1
+ivk 1
+ivó 1
+iy 1
+iye 1
+izd 1
+izg 1
+izn 1
+izr 1
+izu 1
+izz 1
+iék 1
+iél 1
+iép 1
+ií 1
+iír 1
+ióa 1
+ióé 1
+iúg 1
+iúi 1
+iúk 1
+j-C 1
+j-b 1
+j-c 1
+j. 1
+ja- 1
+jam 1
+jbá 1
+jcé 1
+jdu 1
+jdú 1
+je- 1
+jer 1
+jfu 1
+jha 1
+jic 1
+jim 1
+jin 1
+jiv 1
+jjö 1
+jkh 1
+jlé 1
+jló 1
+jme 1
+jmi 1
+jne 1
+jod 1
+jor 1
+jou 1
+jrá 1
+jso 1
+jtj 1
+jtv 1
+jub 1
+jul 1
+juz 1
+jve 1
+jvi 1
+jvá 1
+jzo 1
+jzs 1
+jáh 1
+jáz 1
+jéh 1
+jéi 1
+jöj 1
+júj 1
+jús 1
+jút 1
+jüg 1
+k-Z 1
+k-b 1
+k-c 1
+k-f 1
+k-i 1
+k-j 1
+k-n 1
+k-s 1
+k-v 1
+ka- 1
+kaa 1
+kag 1
+kao 1
+kce 1
+kcs 1
+kd 1
+kda 1
+ke- 1
+kfe 1
+kft 1
+kg 1
+kga 1
+kht 1
+khu 1
+khá 1
+kio 1
+kiu 1
+kií 1
+kió 1
+kju 1
+kjá 1
+kkc 1
+kks 1
+kkü 1
+kl- 1
+klí 1
+koh 1
+koo 1
+ksu 1
+kts 1
+kup 1
+kuv 1
+kyt 1
+káo 1
+káé 1
+kéh 1
+kím 1
+kóc 1
+kój 1
+kók 1
+kóm 1
+kóp 1
+kóz 1
+kút 1
+kün 1
+küs 1
+kőd 1
+kől 1
+l-A 1
+l-P 1
+l-a 1
+l-b 1
+l-c 1
+l-d 1
+l-g 1
+l-h 1
+l-i 1
+l-j 1
+l-m 1
+l-p 1
+l-s 1
+l-ö 1
+la, 1
+la- 1
+lax 1
+laz 1
+laé 1
+lbr 1
+lbé 1
+lbó 1
+lbú 1
+ld- 1
+ldd 1
+ldj 1
+ldm 1
+ldv 1
+ldó 1
+ldü 1
+le- 1
+lea 1
+leu 1
+lfa 1
+lfr 1
+lfu 1
+lfü 1
+lgu 1
+lgő 1
+lhi 1
+lhú 1
+lij 1
+lip 1
+liy 1
+ljh 1
+lkí 1
+ll- 1
+llk 1
+llu 1
+lmb 1
+lmj 1
+lms 1
+lmv 1
+lnb 1
+lpá 1
+lró 1
+lsi 1
+lss 1
+lth 1
+ltn 1
+lur 1
+lus 1
+lux 1
+lvb 1
+ly( 1
+lyu 1
+lza 1
+lái 1
+léj 1
+léz 1
+lív 1
+lóe 1
+lóh 1
+lóp 1
+lút 1
+lüm 1
+lőp 1
+lűe 1
+lűz 1
+m-D 1
+m-f 1
+m-r 1
+m-t 1
+mbn 1
+mbr 1
+mbí 1
+mbó 1
+mbő 1
+mce 1
+md 1
+mdo 1
+meh 1
+mfé 1
+mhi 1
+mho 1
+mij 1
+miz 1
+mió 1
+mje 1
+mjé 1
+mke 1
+mki 1
+mkí 1
+mli 1
+mmt 1
+mob 1
+moc 1
+mou 1
+mpe 1
+mpr 1
+mpé 1
+mrő 1
+mse 1
+msu 1
+mtu 1
+mtó 1
+mtő 1
+mud 1
+mum 1
+mád 1
+máh 1
+mám 1
+máz 1
+méd 1
+mév 1
+mír 1
+mív 1
+món 1
+müg 1
+mük 1
+müv 1
+műp 1
+műr 1
+n-W 1
+n-e 1
+n-s 1
+n-v 1
+n-é 1
+na, 1
+naf 1
+nbo 1
+nbó 1
+nbű 1
+ncc 1
+ncp 1
+ncr 1
+ndf 1
+ndm 1
+new 1
+nez 1
+ngi 1
+ngr 1
+ngv 1
+ngó 1
+nha 1
+nhi 1
+nhä 1
+nid 1
+nii 1
+nip 1
+nkj 1
+nkv 1
+nkő 1
+nlj 1
+nlá 1
+nn- 1
+nnf 1
+nnl 1
+noc 1
+non 1
+nró 1
+nrő 1
+ns- 1
+nsc 1
+nse 1
+nsk 1
+nsu 1
+nsó 1
+nsü 1
+ntv 1
+nty 1
+ntü 1
+nuf 1
+num 1
+nut 1
+nyd 1
+nym 1
+nzk 1
+nzm 1
+nzr 1
+nzö 1
+nzú 1
+nzű 1
+nád 1
+náj 1
+néb 1
+néi 1
+néj 1
+níc 1
+nóa 1
+nód 1
+nóh 1
+nój 1
+nón 1
+nót 1
+nön 1
+nöz 1
+nút 1
+nő- 1
+női 1
+nűn 1
+o-m 1
+oan 1
+obn 1
+obt 1
+obu 1
+obz 1
+ocd 1
+och 1
+odm 1
+odp 1
+odv 1
+ody 1
+odz 1
+oem 1
+oet 1
+oex 1
+ofe 1
+ofo 1
+ogf 1
+ogu 1
+ogé 1
+ogó 1
+ohi 1
+ohn 1
+oho 1
+ohá 1
+oi 1
+ois 1
+oje 1
+ojj 1
+ojü 1
+ok- 1
+oké 1
+okú 1
+olb 1
+olí 1
+olú 1
+omc 1
+omd 1
+omj 1
+onö 1
+onú 1
+ook 1
+oop 1
+oov 1
+ooé 1
+opa 1
+opc 1
+oph 1
+opi 1
+opy 1
+opó 1
+ork 1
+osc 1
+osh 1
+osp 1
+otr 1
+oté 1
+otí 1
+oug 1
+oul 1
+ous 1
+ovn 1
+ovv 1
+ové 1
+oze 1
+ozm 1
+ozu 1
+oá 1
+oár 1
+oé 1
+oéh 1
+p-E 1
+p-k 1
+p. 1
+paj 1
+pbe 1
+pci 1
+pd 1
+pdá 1
+pea 1
+pec 1
+peh 1
+pg 1
+pgy 1
+pha 1
+phi 1
+pic 1
+pie 1
+pih 1
+pik 1
+pip 1
+pis 1
+piu 1
+pjo 1
+pjé 1
+pká 1
+pkő 1
+ple 1
+pnó 1
+poc 1
+poe 1
+pom 1
+pop 1
+ppo 1
+pre 1
+psi 1
+pso 1
+psá 1
+ptő 1
+puh 1
+pvá 1
+py 1
+pyr 1
+pzá 1
+pzé 1
+pző 1
+pád 1
+pám 1
+páv 1
+pób 1
+pór 1
+pós 1
+pői 1
+qui 1
+r-B 1
+r-H 1
+r-M 1
+r-h 1
+r-m 1
+r-r 1
+r-u 1
+ra- 1
+rax 1
+raé 1
+raí 1
+rbé 1
+rbü 1
+rck 1
+rcn 1
+rcz 1
+rcá 1
+rd- 1
+rdj 1
+rdn 1
+rds 1
+rdü 1
+reb 1
+reu 1
+rfa 1
+rfy 1
+rfö 1
+rgh 1
+rgé 1
+rgó 1
+rhi 1
+rhu 1
+rif 1
+rij 1
+rio 1
+rir 1
+rju 1
+rk- 1
+rkk 1
+rkó 1
+rmj 1
+rml 1
+rn- 1
+rns 1
+rnó 1
+roj 1
+roo 1
+rou 1
+rpa 1
+rpá 1
+rpó 1
+rr- 1
+rru 1
+rré 1
+rsf 1
+rsp 1
+rtd 1
+rtf 1
+rtk 1
+rts 1
+rtí 1
+rtú 1
+ruc 1
+rug 1
+rvs 1
+rvu 1
+rw 1
+rwe 1
+ryb 1
+rzb 1
+rzá 1
+rái 1
+rín 1
+róa 1
+ród 1
+róv 1
+róé 1
+röl 1
+röt 1
+rúb 1
+rúl 1
+rúr 1
+rün 1
+rőa 1
+rőb 1
+rőh 1
+rőn 1
+rőv 1
+rőé 1
+rűt 1
+rűz 1
+s-D 1
+s-H 1
+s-e 1
+s-i 1
+s-m 1
+s-p 1
+s-z 1
+s-ö 1
+sav 1
+sbl 1
+sbo 1
+sbu 1
+sbí 1
+scu 1
+scé 1
+sda 1
+sde 1
+sdi 1
+se- 1
+sea 1
+ses 1
+sfü 1
+sga 1
+sge 1
+shá 1
+sij 1
+sis 1
+sió 1
+sje 1
+sjá 1
+ská 1
+sob 1
+spi 1
+spé 1
+spó 1
+ssú 1
+ssü 1
+stb 1
+stj 1
+stt 1
+sty 1
+stí 1
+sub 1
+sus 1
+sut 1
+svi 1
+svö 1
+szb 1
+szc 1
+szd 1
+sáz 1
+sáé 1
+séj 1
+sép 1
+séé 1
+síe 1
+sík 1
+sín 1
+sío 1
+síp 1
+sóh 1
+sói 1
+sók 1
+sós 1
+söt 1
+súg 1
+súz 1
+sőh 1
+sők 1
+sőn 1
+t-D 1
+t-G 1
+t-M 1
+t-T 1
+t-b 1
+t-f 1
+t-h 1
+t-n 1
+t-s 1
+ta- 1
+tb- 1
+tbo 1
+tbu 1
+td. 1
+tdí 1
+tfa 1
+tfi 1
+tga 1
+thé 1
+tib 1
+tih 1
+tip 1
+tir 1
+tió 1
+tjo 1
+tli 1
+tló 1
+tlő 1
+tmo 1
+tmó 1
+tno 1
+tnó 1
+tob 1
+toe 1
+tof 1
+toh 1
+toi 1
+toj 1
+toá 1
+tp 1
+tpo 1
+trí 1
+tsc 1
+tsd 1
+tsu 1
+ttk 1
+ttl 1
+tui 1
+typ 1
+tyú 1
+tác 1
+tád 1
+táh 1
+téh 1
+tíl 1
+tír 1
+tóc 1
+tóe 1
+tóf 1
+tóh 1
+tóo 1
+tóé 1
+túj 1
+tüg 1
+tőm 1
+tőö 1
+tűk 1
+tűr 1
+uar 1
+ubb 1
+ubr 1
+ubó 1
+uck 1
+uco 1
+ud- 1
+ude 1
+ufa 1
+uff 1
+ugh 1
+ugl 1
+ugs 1
+uho 1
+uj 1
+ujz 1
+uki 1
+uko 1
+uké 1
+ukó 1
+uld 1
+ulf 1
+uls 1
+ulé 1
+um- 1
+umm 1
+ump 1
+ums 1
+umé 1
+unb 1
+uno 1
+unt 1
+uné 1
+uní 1
+urb 1
+urd 1
+urn 1
+urr 1
+ush 1
+usk 1
+usn 1
+usu 1
+usé 1
+ute 1
+uti 1
+utj 1
+utv 1
+utz 1
+uu 1
+uum 1
+uve 1
+uvá 1
+ux- 1
+uze 1
+v-f 1
+vad 1
+vb- 1
+vba 1
+vbő 1
+vec 1
+vge 1
+vie 1
+vio 1
+vip 1
+viá 1
+vki 1
+vko 1
+vké 1
+vl 1
+vla 1
+vna 1
+vni 1
+voj 1
+vra 1
+vru 1
+vrő 1
+vso 1
+vto 1
+vtu 1
+vuk 1
+vva 1
+vvi 1
+vy 1
+váh 1
+váz 1
+véé 1
+vös 1
+vöz 1
+vük 1
+vőp 1
+vős 1
+vőt 1
+wa- 1
+we 1
+wel 1
+wh 1
+whi 1
+wic 1
+wis 1
+wsp 1
+x-h 1
+x-t 1
+xte 1
+xti 1
+xu 1
+xuá 1
+xá 1
+xác 1
+y( 1
+y(i 1
+y-a 1
+y-f 1
+ya, 1
+yac 1
+yaf 1
+yap 1
+yav 1
+ybi 1
+ybá 1
+yci 1
+yd 1
+yde 1
+yec 1
+yfá 1
+ygé 1
+yhő 1
+yi- 1
+yia 1
+yib 1
+yig 1
+yih 1
+yiv 1
+ylő 1
+ymo 1
+ymé 1
+yni 1
+yné 1
+yod 1
+ypo 1
+ypr 1
+yps 1
+yri 1
+yso 1
+yst 1
+ysú 1
+yto 1
+ytő 1
+yuk 1
+yur 1
+yva 1
+yvb 1
+yvi 1
+yvk 1
+yvo 1
+yvr 1
+yvt 1
+yvv 1
+yvé 1
+yví 1
+yzé 1
+yzó 1
+yág 1
+yái 1
+yám 1
+yáv 1
+yép 1
+yéé 1
+yír 1
+yós 1
+yök 1
+yös 1
+yöt 1
+yúb 1
+yúk 1
+yúl 1
+yút 1
+yüz 1
+yőf 1
+yőj 1
+yűr 1
+z-c 1
+z-k 1
+z-m 1
+z-p 1
+z-s 1
+za- 1
+zaa 1
+zag 1
+zaá 1
+zaú 1
+zbu 1
+zbí 1
+zbü 1
+zce 1
+zcé 1
+zdh 1
+zdi 1
+zdí 1
+zdö 1
+zea 1
+zfa 1
+zfe 1
+zfo 1
+zfé 1
+zfő 1
+zgó 1
+zid 1
+zie 1
+zil 1
+zir 1
+ziv 1
+ziz 1
+zjo 1
+zkb 1
+zku 1
+zká 1
+zkó 1
+zli 1
+zlu 1
+zmo 1
+zmű 1
+znu 1
+zny 1
+zod 1
+zos 1
+zpa 1
+zra 1
+zsb 1
+zsj 1
+zsl 1
+zsm 1
+zsn 1
+zsí 1
+zsö 1
+ztb 1
+ztk 1
+ztm 1
+zub 1
+zud 1
+zuh 1
+zun 1
+zvi 1
+zvá 1
+zy 1
+zy- 1
+záv 1
+zég 1
+zév 1
+zíj 1
+zíl 1
+zós 1
+zúr 1
+zür 1
+züs 1
+zőc 1
+zőj 1
+zőm 1
+zőv 1
+zőz 1
+zűc 1
+zűz 1
+ÁR 1
+Ák 1
+Áko 1
+Árg 1
+Áro 1
+Árp 1
+Árv 1
+Ás 1
+Ásv 1
+Át 1
+Átm 1
+Áz 1
+Ázs 1
+Éle 1
+Élv 1
+Éne 1
+Érd 1
+Ét 1
+Éta 1
+Év 1
+Éva 1
+Örd 1
+Öre 1
+Örö 1
+Örü 1
+Ös 1
+Ösz 1
+Öt 1
+Ötö 1
+Úja 1
+Újl 1
+Újs 1
+Úr 1
+Úri 1
+ábj 1
+ábn 1
+ábr 1
+áde 1
+ádj 1
+ádt 1
+ádz 1
+áfa 1
+áfi 1
+áfo 1
+áfu 1
+ág- 1
+ágc 1
+ágk 1
+ágv 1
+áha 1
+áik 1
+áin 1
+áir 1
+áit 1
+ájk 1
+ájl 1
+ájö 1
+ákl 1
+ákn 1
+ákt 1
+ákó 1
+ákö 1
+álb 1
+ále 1
+álf 1
+álr 1
+álv 1
+álz 1
+álő 1
+ámc 1
+áme 1
+ámj 1
+ánh 1
+áné 1
+ánö 1
+áo 1
+áos 1
+áre 1
+áry 1
+ásc 1
+ásd 1
+áse 1
+ásé 1
+átb 1
+átg 1
+átí 1
+ávk 1
+ávl 1
+ávr 1
+áze 1
+ázf 1
+ázk 1
+ázö 1
+ázü 1
+áét 1
+ä 1
+äu 1
+äus 1
+éda 1
+édh 1
+édk 1
+éds 1
+édü 1
+éga 1
+égf 1
+égj 1
+égn 1
+égo 1
+égá 1
+égí 1
+ého 1
+éin 1
+éjj 1
+ékf 1
+ékg 1
+ékm 1
+ékó 1
+éla 1
+éll 1
+élú 1
+élü 1
+émh 1
+émj 1
+émk 1
+émí 1
+énu 1
+éná 1
+épa 1
+épb 1
+épg 1
+épj 1
+épr 1
+érc 1
+éro 1
+érr 1
+érá 1
+és- 1
+ésc 1
+ésv 1
+ésí 1
+ét- 1
+étd 1
+éth 1
+étm 1
+étü 1
+évj 1
+évk 1
+éza 1
+ézl 1
+ézr 1
+ézs 1
+ídi 1
+íe 1
+íel 1
+íj- 1
+íjk 1
+íjá 1
+íke 1
+íko 1
+íkr 1
+ílt 1
+ílu 1
+íme 1
+íml 1
+ímo 1
+ín- 1
+ína 1
+ínr 1
+ío 1
+íok 1
+ípá 1
+ír- 1
+írf 1
+írk 1
+írm 1
+írű 1
+ítk 1
+ítt 1
+ívk 1
+ívn 1
+ívr 1
+ízh 1
+ízk 1
+ízm 1
+ízn 1
+ízt 1
+ízá 1
+ízü 1
+ó-g 1
+ó-k 1
+ó-m 1
+ó-r 1
+ó-s 1
+ó-t 1
+óas 1
+óbó 1
+ócc 1
+ócz 1
+óda 1
+ódh 1
+ódn 1
+ódr 1
+ódv 1
+óeg 1
+óel 1
+ófe 1
+ófu 1
+ófá 1
+óhá 1
+óik 1
+óiv 1
+óiá 1
+ójú 1
+óki 1
+ókí 1
+ólh 1
+óli 1
+óln 1
+óme 1
+ómá 1
+óny 1
+óné 1
+óo 1
+óos 1
+órt 1
+ósl 1
+ósu 1
+ót- 1
+óte 1
+óti 1
+ótm 1
+ótó 1
+óve 1
+ózi 1
+ózn 1
+ózv 1
+öbe 1
+ödj 1
+ödr 1
+ögg 1
+öj 1
+öjj 1
+ökj 1
+ökl 1
+ökő 1
+öle 1
+ölj 1
+öln 1
+ölv 1
+ömb 1
+ömm 1
+ömp 1
+ömé 1
+ön- 1
+öni 1
+önr 1
+önv 1
+örd 1
+örf 1
+örs 1
+ösn 1
+ösí 1
+ösö 1
+ötm 1
+öts 1
+özc 1
+özf 1
+özk 1
+özm 1
+özá 1
+úba 1
+úbó 1
+úi 1
+újb 1
+újh 1
+újn 1
+újv 1
+úla 1
+úld 1
+úlm 1
+úln 1
+úlá 1
+úna 1
+úná 1
+úri 1
+úrk 1
+úrn 1
+úro 1
+úrr 1
+ús- 1
+úsí 1
+útd 1
+úza 1
+úzi 1
+úzo 1
+úzz 1
+úzó 1
+üdv 1
+üdí 1
+ühn 1
+ükö 1
+ül- 1
+ülí 1
+üm 1
+ümp 1
+ünc 1
+ürd 1
+üri 1
+üro 1
+ürt 1
+ürz 1
+ürí 1
+üss 1
+üst 1
+üti 1
+üzé 1
+Ők 1
+Őke 1
+Ős 1
+Ősz 1
+ő-m 1
+őau 1
+őbő 1
+őc 1
+őcs 1
+őda 1
+ődb 1
+őek 1
+őel 1
+őer 1
+őfá 1
+őgo 1
+őhi 1
+őhm 1
+őhú 1
+őik 1
+őiv 1
+őjo 1
+őjü 1
+őkk 1
+őkr 1
+őkö 1
+ől- 1
+őlü 1
+őnk 1
+őos 1
+őra 1
+őrk 1
+őrn 1
+őré 1
+őu 1
+őut 1
+őzi 1
+őzk 1
+őzt 1
+őá 1
+őál 1
+őé 1
+őér 1
+őít 1
+őö 1
+őöv 1
+őú 1
+őút 1
+őü 1
+őüg 1
+űc 1
+űcs 1
+űfo 1
+űhe 1
+űhö 1
+űke 1
+űkn 1
+űké 1
+űkü 1
+űne 1
+űnm 1
+űnn 1
+űnü 1
+űp 1
+űpa 1
+űre 1
+űré 1
+űrő 1
+űsö 1
+űvö 1
+űze 1
+űzi 1
+űzk 1
+űzn 1
+űzö 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map
new file mode 100644
index 00000000..3e7d7e64
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.label-map
@@ -0,0 +1,55 @@
+54
+punct 4368
+det 3909
+amod:att 3717
+nmod:obl 2587
+nsubj 1968
+nmod:att 1853
+cc 1386
+conj 1373
+root 1361
+dobj 1269
+advmod:mode 1057
+name 733
+nmod 636
+case 568
+mark 552
+advmod:tlocy 544
+compound:preverb 339
+neg 322
+advcl 315
+nummod 253
+acl 235
+xcomp 229
+appos 198
+amod:mode 165
+remnant 159
+parataxis 138
+cop 137
+ccomp:obj 130
+compound 122
+csubj 121
+ccomp:obl 114
+iobj 78
+advmod:locy 63
+ccomp 55
+amod:obl 45
+advmod:tto 31
+dobj:lvc 31
+aux 23
+advmod:to 20
+list 19
+ccomp:pred 13
+advmod:que 12
+advmod:tfrom 12
+nmod:obllvc 8
+nsubj:lvc 3
+advmod:obl 2
+amod:attlvc 2
+goeswith 2
+advmod 1
+dep 1
+discourse 1
+dislocated 1
+nmod:attlvc 1
+vocative 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec
new file mode 100644
index 00000000..9fe100ff
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.master-spec
@@ -0,0 +1,213 @@
+component {
+  name: "rl_rnn"
+  transition_system {
+    registered_name: "shift-only"
+    parameters {
+      key: "left-to-right"
+      value: "false"
+    }
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "char-ngram-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.char-ngram-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "word-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.word-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "char_ngram"
+    fml: "input.token.char-ngram"
+    embedding_dim: 16
+    vocabulary_size: 9943
+    size: 1
+  }
+  fixed_feature {
+    name: "other"
+    fml: "input.token {digit hyphen punctuation-amount quote }"
+    embedding_dim: 8
+    vocabulary_size: 5
+    size: 4
+  }
+  fixed_feature {
+    name: "words"
+    fml: "input.word"
+    embedding_dim: 64
+    vocabulary_size: 11090
+    size: 1
+  }
+  network_unit {
+    registered_name: "wrapped_units.LayerNormBasicLSTMNetwork"
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 1
+  attention_component: ""
+}
+component {
+  name: "tagger"
+  transition_system {
+    registered_name: "tagger"
+    parameters {
+      key: "join_category_to_pos"
+      value: "true"
+    }
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "tag-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.tag-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "action"
+    fml: "last-action"
+    embedding_dim: 32
+    vocabulary_size: 100
+    size: 1
+  }
+  linked_feature {
+    name: "encoder"
+    fml: "input.focus"
+    embedding_dim: 64
+    size: 1
+    source_component: "rl_rnn"
+    source_translator: "reverse-token"
+    source_layer: "state_h_0"
+  }
+  network_unit {
+    registered_name: "wrapped_units.LayerNormBasicLSTMNetwork"
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 642
+  attention_component: ""
+}
+component {
+  name: "parser"
+  transition_system {
+    registered_name: "arc-standard"
+    parameters {
+      key: "parser_skip_deterministic"
+      value: "false"
+    }
+  }
+  resource {
+    name: "label-map"
+    part {
+      file_pattern: "TOPDIR/testdata/ud-hungarian.label-map"
+      file_format: "text"
+      record_format: ""
+    }
+  }
+  fixed_feature {
+    name: "action"
+    fml: "last-action"
+    embedding_dim: 32
+    vocabulary_size: 100
+    size: 1
+  }
+  fixed_feature {
+    name: "labels"
+    fml: "stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(2).label stack(1).child(-2).label"
+    embedding_dim: 16
+    vocabulary_size: 57
+    size: 12
+  }
+  linked_feature {
+    name: "encoder"
+    fml: "input.focus"
+    embedding_dim: 64
+    size: 1
+    source_component: "rl_rnn"
+    source_translator: "reverse-token"
+    source_layer: "state_h_0"
+  }
+  linked_feature {
+    name: "parser-rnn"
+    fml: "stack.focus stack(1).focus"
+    embedding_dim: 64
+    size: 2
+    source_component: "parser"
+    source_translator: "shift-reduce-step"
+    source_layer: "layer_0"
+  }
+  linked_feature {
+    name: "tagger"
+    fml: "input.focus stack.focus stack(1).focus"
+    embedding_dim: 64
+    size: 3
+    source_component: "tagger"
+    source_translator: "identity"
+    source_layer: "state_h_0"
+  }
+  network_unit {
+    registered_name: 'FeedForwardNetwork'
+    parameters {
+      key: "hidden_layer_sizes"
+      value: "256,256"
+    }
+    parameters {
+      key: "layer_norm_hidden"
+      value: "True"
+    }
+  }
+  component_builder {
+    registered_name: 'DynamicComponentBuilder'
+  }
+  backend {
+    registered_name: "SyntaxNetComponent"
+  }
+  num_actions: 109
+  attention_component: ""
+}
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params
new file mode 100644
index 00000000..637082c4
Binary files /dev/null and b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.params differ
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map
new file mode 100644
index 00000000..fd798701
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.tag-map
@@ -0,0 +1,643 @@
+642
+attribute { name: "POS" value: "PUNCT" } 4371
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Art" } attribute { name: "POS" value: "DET" } 3595
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1633
+attribute { name: "POS" value: "CONJ" } 1397
+attribute { name: "POS" value: "ADV" } 1321
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1280
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1097
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 987
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 784
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 609
+attribute { name: "POS" value: "ADP" } 576
+attribute { name: "POS" value: "SCONJ" } 558
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 530
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 483
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 441
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 377
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 371
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 366
+attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "ADV" } 335
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 319
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 286
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 285
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 266
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 232
+attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 216
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 210
+attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "ADV" } 207
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 206
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 188
+attribute { name: "Degree" value: "Pos" } attribute { name: "POS" value: "ADV" } 177
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 170
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 167
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 161
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 155
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 151
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 136
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 134
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 132
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 125
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 118
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 115
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 107
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 106
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 103
+attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "ADV" } 97
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 95
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 89
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Art" } attribute { name: "POS" value: "DET" } 88
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 87
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 84
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 83
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 81
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 79
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 78
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Ord" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 77
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 76
+attribute { name: "POS" value: "PART" } 74
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 71
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 69
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 69
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 64
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 61
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 61
+attribute { name: "VerbForm" value: "Trans" } attribute { name: "POS" value: "ADV" } 60
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 58
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 58
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 57
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 53
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 49
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 49
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Ord" } attribute { name: "POS" value: "ADJ" } 46
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 46
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 45
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 41
+attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "ADV" } 41
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 40
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 39
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 37
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 37
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 36
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 35
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 35
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 34
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 34
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 33
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 33
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 33
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 31
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 31
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 31
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 31
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 30
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 30
+attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "ADV" } 30
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 29
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 28
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 27
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 27
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 27
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 26
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 26
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 25
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 25
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 25
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 24
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 24
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 23
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 23
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 23
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 22
+attribute { name: "Degree" value: "Cmp" } attribute { name: "POS" value: "ADV" } 22
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 21
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 21
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 21
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "DET" } 21
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 20
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 20
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 20
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 19
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 19
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 19
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 18
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 18
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 18
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 18
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 18
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 18
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 17
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 17
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 16
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 16
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 16
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 15
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 15
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 15
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 15
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 14
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 14
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 14
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 13
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 13
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 13
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 13
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 13
+attribute { name: "POS" value: "X" } 13
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 12
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 12
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "ADJ" } 12
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 12
+attribute { name: "POS" value: "INTJ" } 12
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 11
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 11
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 11
+attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "ADV" } 11
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 10
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 10
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 10
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 10
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 10
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 9
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 9
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 9
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 9
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 9
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Acc" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 8
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 8
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 8
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Poss" value: "Yes" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 8
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 8
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 8
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 7
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 7
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 7
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 7
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 7
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartFut" } attribute { name: "POS" value: "ADJ" } 7
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 7
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 7
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 6
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 6
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 6
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 5
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 5
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 5
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 5
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 5
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "DET" } 5
+attribute { name: "Degree" value: "Pos" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "ADV" } 5
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 5
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 4
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "PROPN" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Dist" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 4
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 4
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 4
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 4
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "All" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Dis" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartFut" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 3
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 3
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 3
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "DET" } 3
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 3
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 3
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Abs" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Abs" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 2
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Dis" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 2
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 2
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 2
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "DET" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 2
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Degree" value: "Sup" } attribute { name: "POS" value: "ADV" } 2
+attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 2
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Aspect" value: "Freq" } attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Abl" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "2" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Acc" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ade" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "All" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Cau" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "2" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Dat" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Del" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Dis" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ela" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ess" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Gen" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ill" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "3" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ine" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Tot" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rcp" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Ins" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Loc" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Degree" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "NumType" value: "Card" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Ord" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Dist" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "PROPN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Nom" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Plur" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "VerbForm" value: "PartPast" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "1" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Sub" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "NumType" value: "Frac" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Prs" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Sup" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "PronType" value: "Rel" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "NumType" value: "Card" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NUM" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tem" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Plur" } attribute { name: "Person[psor]" value: "1" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Plur" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Ter" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person" value: "3" } attribute { name: "Person[psor]" value: "None" } attribute { name: "PronType" value: "Dem" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Cmp" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "None" } attribute { name: "Person[psor]" value: "None" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Degree" value: "Pos" } attribute { name: "Number" value: "Sing" } attribute { name: "VerbForm" value: "PartPres" } attribute { name: "POS" value: "ADJ" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "None" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Plur" } attribute { name: "Number[psed]" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Reflex" value: "Yes" } attribute { name: "POS" value: "PRON" } 1
+attribute { name: "Case" value: "Tra" } attribute { name: "Number" value: "Sing" } attribute { name: "Number[psor]" value: "Sing" } attribute { name: "Person[psor]" value: "3" } attribute { name: "POS" value: "NOUN" } 1
+attribute { name: "Definite" value: "2" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "AUX" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Def" } attribute { name: "PronType" value: "Neg" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Cnd,Pot" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Imp,Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Past" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Ind" } attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "2" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "Mood" value: "Pot" } attribute { name: "Number" value: "Plur" } attribute { name: "Person" value: "3" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Fin" } attribute { name: "Voice" value: "Cau" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Definite" value: "Ind" } attribute { name: "PronType" value: "Int" } attribute { name: "POS" value: "DET" } 1
+attribute { name: "Degree" value: "Pos" } attribute { name: "PronType" value: "Ind" } attribute { name: "POS" value: "ADV" } 1
+attribute { name: "Mood" value: "Pot" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
+attribute { name: "Number" value: "Sing" } attribute { name: "Person" value: "1" } attribute { name: "Tense" value: "Pres" } attribute { name: "VerbForm" value: "Inf" } attribute { name: "Voice" value: "Act" } attribute { name: "POS" value: "VERB" } 1
diff --git a/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map
new file mode 100644
index 00000000..5ef85ce5
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/testdata/ud-hungarian.word-map
@@ -0,0 +1,11088 @@
+11087
+a 2185
+, 2170
+. 1326
+az 857
+A 461
+és 438
+is 338
+hogy 331
+— 320
+nem 247
+" 205
+Az 169
+: 120
+egy 120
+s 111
+szerint 107
+már 99
+még 90
+csak 87
+( 86
+) 86
+de 86
+volt 84
+meg 77
+azt 75
+ki 63
+sem 62
+két 59
+milliárd 58
+el 56
+ha 54
+mint 53
+kell 52
+pedig 51
+több 51
+után 47
+között 46
+egyik 42
+kormány 41
+magyar 41
+van 41
+millió 39
+első 37
+lehet 37
+majd 37
+aki 36
+hiszen 36
+által 36
+új 36
+orosz 35
+vagy 35
+azonban 33
+hanem 33
+nagy 33
+amely 32
+arra 32
+ez 32
+miatt 32
+annak 31
+év 31
+fel 30
+gazdasági 30
+illetve 30
+most 30
+be 29
+például 29
+akkor 28
+ami 28
+forint 28
+olyan 28
+? 26
+százalékos 26
+át 26
+óta 26
+úgy 26
+ezt 25
+mert 25
+minden 25
+szerb 25
+így 25
+Ez 24
+múlt 24
+nemzetközi 24
+amelynek 23
+jövő 23
+legnagyobb 23
+ma 23
+politikai 23
+azért 22
+mintegy 22
+utóbbi 22
+cég 21
+ugyanis 21
+című 20
+százalékkal 20
+tavaly 20
+ahol 19
+előtt 19
+idén 19
+mellett 19
+mondta 19
+számára 19
+viszont 19
+ám 19
+ő 19
+amikor 18
+ezer 18
+ezért 18
+lesz 18
+néhány 18
+szemben 18
+ugyan 18
+évi 18
+Magyar 17
+belül 17
+cseh 17
+egész 17
+három 17
+héten 17
+korábban 17
+valamint 17
+évek 17
+alatt 16
+elnök 16
+jó 16
+éppen 16
+Nem 15
+koszovói 15
+költségvetési 15
+mindig 15
+name 15
+német 15
+török 15
+Így 15
+állami 15
+10 14
+30 14
+Ferenc 14
+Ha 14
+arról 14
+egyes 14
+egyre 14
+fontos 14
+helyzet 14
+jövőre 14
+kellene 14
+került 14
+közül 14
+lenne 14
+lévő 14
+más 14
+nagyon 14
+nincs 14
+ott 14
+volna 14
+állam 14
+éves 14
+újra 14
+; 13
+albánok 13
+amit 13
+egyelőre 13
+egyébként 13
+elején 13
+ellenére 13
+földrengés 13
+követően 13
+le 13
+miután 13
+másik 13
+saját 13
+szlovák 13
+százaléka 13
+való 13
+vannak 13
+vezetője 13
+évben 13
+! 12
+Ennek 12
+Gazprom 12
+János 12
+Rt. 12
+alapján 12
+csupán 12
+egyetlen 12
+ellen 12
+elnöke 12
+elsősorban 12
+ember 12
+hazai 12
+helyi 12
+kellett 12
+kerül 12
+kormányfő 12
+míg 12
+nagyobb 12
+sok 12
+százalékát 12
+voltak 12
+álló 12
+újabb 12
+-e 11
+HVG 11
+László 11
+alig 11
+azzal 11
+bank 11
+csecsen 11
+cégek 11
+elé 11
+este 11
+európai 11
+hivatalos 11
+hét 11
+idején 11
+ilyen 11
+ismét 11
+január 11
+jelentette 11
+közötti 11
+külföldi 11
+legalább 11
+lehetett 11
+május 11
+második 11
+nélkül 11
+ország 11
+semmi 11
+szakértők 11
+szerbek 11
+szerdán 11
+tehát 11
+tovább 11
+11 10
+20 10
+abban 10
+amelyben 10
+augusztus 10
+egykori 10
+elleni 10
+elmúlt 10
+először 10
+fél 10
+gazdaság 10
+hozzá 10
+idő 10
+jelenleg 10
+jelentős 10
+közös 10
+legfontosabb 10
+magas 10
+mi 10
+miközben 10
+moszkvai 10
+mégis 10
+négy 10
+rendkívüli 10
+részt 10
+százalék 10
+sőt 10
+teljes 10
+történt 10
+törvény 10
+vezető 10
+vált 10
+végén 10
+éve 10
+őket 10
+Ezért 9
+István 9
+Kft. 9
+Kovács 9
+Magyarországon 9
+RTL 9
+Viktor 9
+adott 9
+akik 9
+akár 9
+alá 9
+azaz 9
+családi 9
+dolláros 9
+együtt 9
+elő 9
+ezek 9
+ezen 9
+idei 9
+inkább 9
+jegyzett 9
+kis 9
+legyen 9
+maga 9
+miniszterelnök 9
+napokban 9
+nemcsak 9
+sikerült 9
+tagja 9
+teljesen 9
+terv 9
+tette 9
+tájékoztatta 9
+túl 9
+államfő 9
+élő 9
+én 9
+évvel 9
+öt 9
+úton 9
+1997 8
+2 8
+Budapest 8
+ENSZ 8
+Klub 8
+Orbán 8
+Pedig 8
+Tito 8
+ad 8
+akit 8
+bizottság 8
+ebben 8
+eddig 8
+egyszer 8
+ellenzék 8
+elmondta 8
+elég 8
+emberek 8
+ennek 8
+erre 8
+ezzel 8
+főként 8
+hamarosan 8
+hasonló 8
+hatalom 8
+helyett 8
+itt 8
+jogi 8
+jól 8
+június 8
+katonai 8
+korábbi 8
+képviselő 8
+készült 8
+különösen 8
+lett 8
+mind 8
+miniszter 8
+nemzeti 8
+parlamenti 8
+persze 8
+szeptember 8
+száma 8
+talán 8
+tartott 8
+további 8
+tíz 8
+ugyancsak 8
+várható 8
+várhatóan 8
+áll 8
+ára 8
+értelmében 8
+években 8
+éven 8
+önkormányzat 8
+100 7
+1999. 7
+2000. 7
+50 7
+7 7
+De 7
+Dubcek 7
+Gyerev 7
+György 7
+IMF 7
+Mint 7
+ahhoz 7
+attól 7
+aztán 7
+azóta 7
+belső 7
+bár 7
+dollár 7
+export 7
+ezúttal 7
+fejlesztési 7
+fő 7
+főváros 7
+fővárosi 7
+hogyan 7
+horvát 7
+hosszabb 7
+hó 7
+javaslat 7
+jóllehet 7
+jóval 7
+kapott 7
+katolikus 7
+kedden 7
+keleti 7
+következő 7
+közlekedési 7
+legfeljebb 7
+lehetővé 7
+látható 7
+lépett 7
+magát 7
+parlament 7
+pénzügyi 7
+részét 7
+sor 7
+szinte 7
+szociáldemokraták 7
+száz 7
+szép 7
+talált 7
+tavalyi 7
+tegnap 7
+teszi 7
+tett 7
+tudni 7
+társaság 7
+választások 7
+válság 7
+város 7
+És 7
+állt 7
+életben 7
+érdekében 7
+érintett 7
+ők 7
+- 6
+... 6
+200 6
+25 6
+40 6
+5 6
+60 6
+Azt 6
+Bank 6
+Budapesti 6
+Bár 6
+EU 6
+Európai 6
+GDP 6
+Imre 6
+Koszovó 6
+Köztársaság 6
+Magyarország 6
+S 6
+Simicska 6
+Svájc 6
+Szemjonov 6
+Szerb 6
+Zoltán 6
+adatok 6
+ahogy 6
+akiknek 6
+amelyek 6
+azonnal 6
+baleset 6
+budapesti 6
+bíróság 6
+csökkent 6
+célja 6
+december 6
+eddigi 6
+ellenzéki 6
+erők 6
+fog 6
+folyamatosan 6
+forintos 6
+forintra 6
+gyorsan 6
+hajlandó 6
+hat 6
+hatóságok 6
+hivatkozva 6
+hiába 6
+ideiglenes 6
+időben 6
+immár 6
+ipari 6
+ismert 6
+javaslatot 6
+jugoszláv 6
+kereskedelmi 6
+kevesebb 6
+kezdődött 6
+képes 6
+kérdés 6
+költségvetés 6
+körülmények 6
+központi 6
+közvetlen 6
+közölte 6
+legalábbis 6
+magyarországi 6
+marad 6
+megfelelő 6
+megyében 6
+mely 6
+melynek 6
+milyen 6
+mindössze 6
+munkát 6
+nappal 6
+nemrég 6
+november 6
+nálunk 6
+nő 6
+okozta 6
+olasz 6
+pontosan 6
+pénzügyminiszter 6
+rossz 6
+rá 6
+soha 6
+során 6
+szavak 6
+szeretné 6
+szintén 6
+számos 6
+szó 6
+szóló 6
+szövetségi 6
+tervét 6
+területén 6
+testület 6
+továbbá 6
+tudott 6
+tudta 6
+többek 6
+tűzoltók 6
+uniós 6
+utal 6
+utcai 6
+vele 6
+vett 6
+vezette 6
+vezetők 6
+világ 6
+világpiaci 6
+választási 6
+vállalatok 6
+végre 6
+végéig 6
+élére 6
+írta 6
+összesen 6
+ülésén 6
+őszi 6
+őt 6
+12 5
+4 5
+6 5
+75 5
+8 5
+András 5
+Egy 5
+Egyesült 5
+Ezek 5
+Gerhard 5
+Gábor 5
+London 5
+MLSZ 5
+Ma 5
+Magyarországra 5
+Péter 5
+SPD 5
+Tibor 5
+Tv 5
+Törökország 5
+Unió 5
+Van 5
+Zeman 5
+adó 5
+ahogyan 5
+akar 5
+akinek 5
+akkori 5
+alakult 5
+albán 5
+amelyet 5
+anyagi 5
+aránya 5
+bajnoki 5
+balkáni 5
+belföldi 5
+benne 5
+cserkeszek 5
+dollárnyi 5
+döntés 5
+e 5
+elemzők 5
+ellentétben 5
+embere 5
+ennél 5
+etnikai 5
+ezelőtt 5
+felé 5
+fogja 5
+foglalkozó 5
+forgalom 5
+forintot 5
+hasonlóan 5
+helyen 5
+hosszú 5
+hozott 5
+hétfőn 5
+híres 5
+hónap 5
+igazgatója 5
+igen 5
+infláció 5
+jelenlegi 5
+jobban 5
+jutott 5
+karacsájok 5
+kedvező 5
+kereslet 5
+kerülhet 5
+kezében 5
+kizárólag 5
+kiállítás 5
+korántsem 5
+képest 5
+kérdést 5
+készül 5
+körülbelül 5
+körüli 5
+következtében 5
+követő 5
+közgyűlés 5
+köztársaság 5
+köztársasági 5
+közúti 5
+külkereskedelmi 5
+különböző 5
+különleges 5
+lakosság 5
+lapunkat 5
+lép 5
+magasabb 5
+magukat 5
+megkezdett 5
+megye 5
+megyei 5
+megállapodás 5
+mikor 5
+mindenki 5
+minél 5
+miért 5
+mondja 5
+máris 5
+mérleg 5
+méter 5
+módon 5
+mögött 5
+működik 5
+nehéz 5
+nyert 5
+némi 5
+növekvő 5
+nőtt 5
+okozott 5
+olaj 5
+oroszok 5
+orvos 5
+osztrák 5
+piacon 5
+párt 5
+rendszer 5
+rendszerváltás 5
+rendőrség 5
+révén 5
+rövid 5
+sokkal 5
+szakmai 5
+szerbiai 5
+szerepet 5
+szeretem 5
+szociális 5
+szovjet 5
+számít 5
+számú 5
+szükséges 5
+született 5
+tartani 5
+települések 5
+termelés 5
+természetesen 5
+tervet 5
+továbbra 5
+tud 5
+tudja 5
+tulajdonosa 5
+tárca 5
+távozott 5
+törvényt 5
+ugyanakkor 5
+utáni 5
+valamennyi 5
+viszony 5
+városban 5
+végi 5
+Úgy 5
+átmeneti 5
+élelmiszeriparban 5
+életét 5
+érte 5
+ígért 5
+össze 5
+út 5
+1 4
+1-jétől 4
+1997-ben 4
+2. 4
+2000 4
+80 4
+AIDS 4
+Aki 4
+Ami 4
+Amikor 4
+Bajnokok 4
+Daewoo 4
+Erste 4
+Európa 4
+Ezt 4
+Ezzel 4
+Fenyves 4
+Fillér 4
+Hiába 4
+I. 4
+Járai 4
+Jó 4
+Kiadó 4
+Konzumbank 4
+Kouchner 4
+Lajos 4
+MFB 4
+Martonyi 4
+Mert 4
+Miklós 4
+Minden 4
+Minisztérium 4
+Moszkvában 4
+Még 4
+NATO 4
+Olyan 4
+Persze 4
+Ráadásul 4
+Schröder 4
+Szabó 4
+Tudjman 4
+Ugyanakkor 4
+Vlagyimir 4
+Zsigmond 4
+adja 4
+adtak 4
+adventi 4
+afganisztáni 4
+alaposan 4
+alapítója 4
+amerikai 4
+amint 4
+amúgy 4
+azokat 4
+azokban 4
+azon 4
+azonos 4
+beruházások 4
+bizonyos 4
+biztos 4
+boszniai 4
+busz 4
+büdzsé 4
+csaknem 4
+csapat 4
+cserkesz 4
+címmel 4
+decemberben 4
+dolgozók 4
+ebből 4
+egy-egy 4
+egyaránt 4
+egyben 4
+egyedi 4
+egyesület 4
+egymás 4
+egyszerű 4
+egyáltalán 4
+egyéni 4
+együttműködés 4
+elfogadott 4
+ellene 4
+elnöki 4
+előtti 4
+emelkedik 4
+energetikai 4
+erről 4
+erősebb 4
+esetben 4
+esetleg 4
+esetében 4
+esik 4
+ezekben 4
+ezelőtti 4
+fekvő 4
+feladat 4
+fizetett 4
+fognak 4
+fogyasztói 4
+forintnyi 4
+francia 4
+fővárosban 4
+gyors 4
+góllövők 4
+hagyják 4
+hangsúlyozta 4
+hatalmas 4
+helyet 4
+hiányában 4
+hordónkénti 4
+huzavona 4
+házak 4
+ideiglenesen 4
+igazi 4
+iskolát 4
+jelent 4
+jellemző 4
+jobb 4
+jár 4
+járt 4
+jövőben 4
+kabinet 4
+kapcsolatban 4
+kapnak 4
+keresztül 4
+keretében 4
+kezdődő 4
+kiadások 4
+kialakult 4
+kitevő 4
+kiváló 4
+koalíció 4
+kormánynak 4
+kortárs 4
+koszorúk 4
+képviselője 4
+kérdések 4
+kért 4
+kétoldalú 4
+kézzel 4
+kívül 4
+kórházba 4
+könnyen 4
+körút 4
+közel 4
+közelmúltban 4
+köztük 4
+közösen 4
+közösség 4
+külügyminiszter 4
+leginkább 4
+legmagasabb 4
+legutóbbi 4
+lehetőség 4
+levél 4
+látszik 4
+makrogazdasági 4
+maradt 4
+megerősítette 4
+ment 4
+mindenesetre 4
+mindkét 4
+mit 4
+mivel 4
+mutatott 4
+márkát 4
+másfél 4
+mértékű 4
+nap 4
+napig 4
+napra 4
+nekem 4
+nekik 4
+nevezte 4
+nincsenek 4
+norvég 4
+nyelv 4
+nyolc 4
+nyugati 4
+nélküli 4
+október 4
+októberben 4
+oroszországi 4
+parancsnoka 4
+piaci 4
+polgári 4
+pénteken 4
+pénzt 4
+rendelkezik 4
+része 4
+sikeres 4
+sokan 4
+sorban 4
+szempontjából 4
+szerepel 4
+szerepét 4
+szervezetek 4
+szobor 4
+szobrot 4
+szombati 4
+számító 4
+százalékot 4
+szét 4
+színpadra 4
+szót 4
+szükség 4
+takarékossági 4
+tartja 4
+tartomány 4
+tartományban 4
+tartományi 4
+termelési 4
+tervek 4
+tervezett 4
+titkos 4
+titkára 4
+tonna 4
+tábornok 4
+tálibok 4
+támogatást 4
+távon 4
+tényező 4
+többi 4
+többsége 4
+történelmi 4
+történik 4
+túlságosan 4
+vagyok 4
+valóban 4
+vasárnap 4
+verseny 4
+veszi 4
+veszélyt 4
+vissza 4
+vonatkozó 4
+válik 4
+végzett 4
+végére 4
+vélik 4
+zsidó 4
+Államok 4
+Én 4
+államháztartási 4
+államtitkára 4
+állnak 4
+állítja 4
+állítólag 4
+árának 4
+élelmiszer-ipari 4
+élet 4
+érdekes 4
+érvényes 4
+ír 4
+írója 4
+óriási 4
+órás 4
+önkéntes 4
+ül 4
+Ő 4
+ősszel 4
+1-jén 3
+14. 3
+1992. 3
+1997. 3
+1999 3
+3 3
+3,5 3
+30-án 3
+57 3
+8,25 3
+Akadémia 3
+Akkor 3
+Batistuta 3
+Bernard 3
+Bond 3
+Bozóky 3
+Budapesten 3
+Budapestre 3
+Bundesbank 3
+Corso 3
+Csak 3
+Csehszlovákia 3
+Dél-Koreában 3
+E 3
+EBESZ 3
+Eb 3
+Egyetem 3
+Egyébként 3
+Emiatt 3
+Erzsébet 3
+Európában 3
+Fidesz 3
+Fiorentina 3
+Fortuna 3
+Gyula 3
+HVG-nek 3
+Hertha 3
+Hiszen 3
+Hungária 3
+Hyundai 3
+II. 3
+Igaz 3
+Ilyen 3
+Jugoszlávia 3
+József 3
+Keane 3
+Kereskedelmi 3
+Ki 3
+Kiemelt 3
+Kim 3
+Kokó 3
+Kontra 3
+Koszovóban 3
+Kreml 3
+Két 3
+Közben 3
+Különösen 3
+Ligája 3
+MU 3
+Macedónia 3
+Manchester 3
+Meg 3
+Megyei 3
+Merthogy 3
+Milos 3
+Miután 3
+Mivel 3
+Már 3
+Márpedig 3
+Műszaki 3
+Nawa 3
+Németország 3
+Németországban 3
+Omár 3
+Orahovacban 3
+Oroszország 3
+Országgyűlés 3
+Sándor 3
+Talibán 3
+Tarzan 3
+Tegnap 3
+Tui 3
+Több 3
+Valencia 3
+Veszprém 3
+Vjahirev 3
+Václav 3
+Welteke 3
+Zsolt 3
+akarja 3
+akció 3
+aktív 3
+alacsony 3
+alapítvány 3
+album 3
+aligha 3
+alkalmas 3
+alkotmányban 3
+alkotmányerejű 3
+amelyen 3
+amire 3
+annyira 3
+autók 3
+azoknak 3
+bankok 3
+bele 3
+belügyi 3
+berlini 3
+beszélt 3
+betegség 3
+bevezetett 3
+bizonnyal 3
+bizonyult 3
+biztonsági 3
+budai 3
+buszok 3
+chaebolnak 3
+család 3
+csehországi 3
+csoport 3
+csökken 3
+céget 3
+célzó 3
+címvédő 3
+demokratikus 3
+dokumentum 3
+dolgozott 3
+dolgozó 3
+dollárra 3
+dollárért 3
+döntést 3
+eddiginél 3
+egyedül 3
+egyesülések 3
+egykor 3
+egymással 3
+együttes 3
+ekkor 3
+elakadt 3
+eleji 3
+elhangzott 3
+eljuttatott 3
+elképzelhető 3
+ellátni 3
+ellátáshoz 3
+eltelt 3
+elérte 3
+előadásában 3
+előbb 3
+elől 3
+emberi 3
+embert 3
+emlegetik 3
+eredménye 3
+erős 3
+esetleges 3
+esztendőben 3
+exportilleték 3
+ezeket 3
+fal 3
+fegyveresek 3
+fele 3
+fellendülés 3
+felében 3
+fiatal 3
+fogadta 3
+fogják 3
+fogyasztás 3
+fogyasztók 3
+folytatni 3
+folyó 3
+forgalmi 3
+fénykép 3
+fölé 3
+függetlenül 3
+garantált 3
+gazdaságra 3
+gondolják 3
+gondolt 3
+gyakorolt 3
+gyilkos 3
+győzelmét 3
+hajlandóak 3
+hangzott 3
+harcolnak 3
+hatással 3
+haza 3
+hegyekben 3
+helyettes 3
+helyettesítés 3
+helyezett 3
+hivatalba 3
+hivatali 3
+hiány 3
+hiánya 3
+holott 3
+hozta 3
+háború 3
+hírt 3
+hómunkások 3
+hónapban 3
+hónapok 3
+időre 3
+igaz 3
+igazgatóság 3
+igazán 3
+igyekeznek 3
+indul 3
+iraki 3
+irodák 3
+iránti 3
+irány 3
+irányító 3
+ismételten 3
+iszlámista 3
+isztambuli 3
+jelen 3
+jelenti 3
+jelentés 3
+jelentősen 3
+jelezte 3
+jut 3
+járó 3
+jönnek 3
+július 3
+júliusban 3
+júniusi 3
+kamionok 3
+kapcsolatos 3
+karacsáj 3
+katasztrófa 3
+katonák 3
+keddi 3
+kegytárgyak 3
+kerestek 3
+kerületi 3
+kerüljön 3
+kerülnek 3
+kevés 3
+kevésbé 3
+kiadvány 3
+kialakítása 3
+kiderült 3
+kidolgozott 3
+kiemelkedő 3
+kisebb 3
+kiskereskedelmi 3
+kiszemelt 3
+kommunikációs 3
+komoly 3
+koncentráció 3
+kormányt 3
+kultúra 3
+kár 3
+képei 3
+kérni 3
+kérték 3
+készültek 3
+kívánja 3
+kör 3
+körben 3
+körzetekben 3
+körének 3
+köszönhető 3
+kötelező 3
+közvetlenül 3
+közé 3
+külső 3
+labdarúgó 3
+lakta 3
+lakói 3
+legfelsőbb 3
+legfőbb 3
+legjobb 3
+legkevésbé 3
+legszebb 3
+lehetőséget 3
+lesznek 3
+látszólag 3
+lélek 3
+macedón 3
+maguknak 3
+magyar-orosz 3
+magára 3
+magáénak 3
+mamutcégek 3
+maradnak 3
+megfelelően 3
+meghaladta 3
+megjelenő 3
+megnyerte 3
+megtartott 3
+megteremtése 3
+menjen 3
+mindazonáltal 3
+mindenkori 3
+mire 3
+mondott 3
+mondván 3
+mostani 3
+munkaügyi 3
+mutatók 3
+mások 3
+mérkőzést 3
+módosításának 3
+módosító 3
+mögé 3
+múltban 3
+múlva 3
+műsor 3
+műszaki 3
+műtárgyak 3
+nagykövetség 3
+napilap 3
+napirendre 3
+napon 3
+negatív 3
+neki 3
+nevezett 3
+nyelvi 3
+nyilatkozatában 3
+nyilván 3
+nyolcvanas 3
+nyomást 3
+németek 3
+nép 3
+név 3
+növekedése 3
+növelésére 3
+ok 3
+oka 3
+okozza 3
+oktatási 3
+oldalon 3
+országok 3
+orvosi 3
+partizánok 3
+pedagógus 3
+percben 3
+piac 3
+polgármester 3
+politikus 3
+politikusok 3
+problémát 3
+pár 3
+pártja 3
+példa 3
+pénz 3
+pénzintézet 3
+rajta 3
+ratifikálta 3
+rendelkező 3
+rendszerének 3
+rengeteg 3
+roppant 3
+rubeles 3
+rubelt 3
+ráadásul 3
+rájuk 3
+régi 3
+részvények 3
+sajátos 3
+se 3
+segítségét 3
+senki 3
+sikert 3
+sincs 3
+sokak 3
+sokat 3
+spanyol 3
+svájci 3
+szabad 3
+szabadon 3
+szakemberek 3
+szemantikai 3
+szemmel 3
+szempontból 3
+személyes 3
+személyi 3
+szenvedett 3
+szeptemberben 3
+szerda 3
+szerdára 3
+szeretnék 3
+szerkezetátalakítás 3
+szervezett 3
+szerzett 3
+szerződést 3
+szerény 3
+szolgáló 3
+számon 3
+számítani 3
+szánt 3
+százalékának 3
+százalékára 3
+székhelyű 3
+szívesen 3
+szólt 3
+szóvivője 3
+sújtott 3
+súlyos 3
+sürgősségi 3
+tanács 3
+tart 3
+tartanak 3
+tartják 3
+tartó 3
+tartós 3
+tekinthető 3
+teljesítmény 3
+teret 3
+terén 3
+területeken 3
+területi 3
+tesz 3
+tevékenységét 3
+tiszteletben 3
+tudnak 3
+tulajdonos 3
+tulajdonába 3
+tulajdonában 3
+támadások 3
+tárgyalások 3
+térség 3
+többségi 3
+tömeges 3
+tömegközlekedés 3
+történet 3
+történő 3
+törvényben 3
+tőkéje 3
+tűnik 3
+utas 3
+utolsó 3
+vagyis 3
+valaki 3
+valószínűleg 3
+venni 3
+vesztette 3
+vezetése 3
+vezetői 3
+vezérkari 3
+villamos 3
+világpiacon 3
+vitás 3
+vonatkozik 3
+vádolja 3
+választott 3
+vállalkozások 3
+várnak 3
+vártnál 3
+végleg 3
+végül 3
+véletlen 3
+véletlenül 3
+zajlik 3
+zárta 3
+Állami 3
+Ám 3
+államadósság 3
+államnak 3
+állítják 3
+általános 3
+április 3
+ár 3
+árak 3
+árbevétel 3
+áron 3
+átlagosan 3
+él 3
+élelmet 3
+életre 3
+élnek 3
+élt 3
+építmény 3
+érdeklődők 3
+érdemes 3
+érintő 3
+érkezett 3
+ért 3
+értéke 3
+értékesíteni 3
+évig 3
+évre 3
+írva 3
+óra 3
+órára 3
+öreg 3
+összege 3
+össztermék 3
+útján 3
+ügy 3
+ünnepek 3
+üresség 3
+őrizetbe 3
+10. 2
+105 2
+110 2
+13 2
+15 2
+160 2
+17 2
+18 2
+180 2
+180-as 2
+19. 2
+190 2
+1959-es 2
+1964-ben 2
+1990-es 2
+1991-ben 2
+1992 2
+1992-ben 2
+1992-es 2
+1996-ban 2
+1998 2
+1998-ban 2
+1998-ig 2
+1998. 2
+1999-ben 2
+2,5 2
+2,6 2
+20-30 2
+2000-ben 2
+2000-re 2
+2002-ben 2
+21-én 2
+22 2
+220 2
+24. 2
+26-án 2
+28. 2
+3-0 2
+30-áig 2
+300 2
+31. 2
+33 2
+33. 2
+350 2
+4,2 2
+4-5 2
+4-es 2
+4. 2
+400 2
+43 2
+45 2
+500 2
+51 2
+55 2
+58 2
+6,3 2
+6-os 2
+6-án 2
+600 2
+65 2
+7,2 2
+70 2
+72 2
+8-án 2
+90 2
+APEH-elnök 2
+Adams 2
+Alexander 2
+Amadinda 2
+Andrással 2
+Attila 2
+Aztán 2
+Azért 2
+B 2
+Babiucról 2
+Bad 2
+Balbo 2
+Balogh 2
+Barcelona 2
+Black 2
+Bordeaux 2
+Bróker 2
+Brókernél 2
+Bács-Kiskun 2
+Bányászati 2
+Bécsben 2
+Csakhogy 2
+Családok 2
+Cseh 2
+Csernomirgyin 2
+Daewoo-átalakítás 2
+Dariusz 2
+Dobson 2
+Don 2
+Dzurinda 2
+Dél-Korea 2
+Ebből 2
+Egyelőre 2
+Egyes 2
+Egyre 2
+Egyrészt 2
+Eichel 2
+Eközben 2
+Elemzők 2
+Elmondta 2
+Első 2
+Enrique 2
+Erre 2
+Európa-bajnok 2
+Ezen 2
+Farinós 2
+Fejér 2
+Felügyelet 2
+Franjo 2
+Fórián 2
+Galéria 2
+Gaming 2
+Godesberg-i 2
+Groznijt 2
+Gyerevet 2
+Györök 2
+Gánt-Kő 2
+Hamburgba 2
+Hamed 2
+Hans 2
+Hasonló 2
+Havril 2
+Helmut 2
+Hotel 2
+HÉV 2
+Három 2
+Hübner 2
+Idén 2
+Igen 2
+Igor 2
+Ikar 2
+Ikarus 2
+Ildikó 2
+International 2
+Ivanov 2
+Izmitben 2
+Jackson 2
+James 2
+Jaroslav 2
+Jelcin 2
+Juszupov 2
+Jóllehet 2
+KGB 2
+Kapera 2
+Karacsáj- 2
+Katolikus 2
+Kfor-erők 2
+Kft.-t 2
+Kft.-től 2
+Kht. 2
+Kiss 2
+Klicsko 2
+Korábban 2
+Kosovska 2
+Koszovót 2
+Krankovics 2
+Kravtex 2
+Krisán 2
+Könnyen 2
+Körvasútsori 2
+Közútkezelő 2
+Közülük 2
+Las 2
+Legutóbb 2
+Leksa 2
+Lemberg 2
+List 2
+Liszt 2
+Mai 2
+Makkabi 2
+Manó 2
+Mark 2
+Maszúd 2
+Melis 2
+Michalczewski 2
+Michalke 2
+Mikulás 2
+Miként 2
+Mindez 2
+Mindezt 2
+Mitrovica 2
+Miért 2
+Molnár 2
+Most 2
+Moszkvába 2
+Mozgalom 2
+MÁV 2
+Márvány-tenger 2
+Más 2
+Mátyás 2
+Múzeumban 2
+Müller 2
+NATO-t 2
+NSZK 2
+Nagy 2
+Napok 2
+Nekem 2
+Nemcsak 2
+Nemzeti 2
+Nyugatra 2
+Operaházban 2
+Orosz 2
+Pelagéját 2
+Pest 2
+Pilinszky 2
+Pirot 2
+Porto 2
+Praha 2
+Preininger 2
+Putyin 2
+Pázmány 2
+Pénz- 2
+Pénzügyminisztérium 2
+RTS 2
+Rabobank 2
+Rankovic 2
+Reichardt 2
+Robinson 2
+Rt.-vel 2
+Ruhrgas 2
+Rába 2
+Régen 2
+SPO 2
+Saarbrückenben 2
+Sadler 2
+Schrödert 2
+Sió 2
+Sokan 2
+Sparta 2
+Sport 2
+Svájcban 2
+Szemjonovot 2
+Szeptember 2
+Szlovákia 2
+Szovjetunió 2
+Számos 2
+Szépművészeti 2
+Sőt 2
+Talics 2
+Talicsot 2
+Tamás 2
+Tavaly 2
+Tietmeyer 2
+Titót 2
+Torgyán 2
+Trajkovics 2
+Tudományos 2
+Tupras 2
+Türk 2
+Tőkepiaci 2
+UEFA 2
+USA 2
+United 2
+Vagyis 2
+Vjahirevet 2
+Vjahirevre 2
+Volf 2
+Voorbergen 2
+Vörös 2
+Wesselényi 2
+White 2
+World 2
+XVIII. 2
+Zeneakadémián 2
+Zoran 2
+Zsolnay 2
+abba 2
+adatokat 2
+addig 2
+adni 2
+adta 2
+adók 2
+adósság 2
+adózás 2
+afrikai 2
+aggasztó 2
+ajánlatával 2
+akad 2
+akadnak 2
+akadályait 2
+akadályozta 2
+akarata 2
+akkora 2
+aktuális 2
+alakította 2
+alakítottam 2
+alapja 2
+alapvető 2
+alapított 2
+alapította 2
+alapítványnak 2
+alapító 2
+alatti 2
+alelnök 2
+alezredes 2
+alkalmazása 2
+alkalommal 2
+alkotja 2
+alkotmány 2
+alkotó 2
+alpesi 2
+alsó 2
+aláírt 2
+alól 2
+amatőr 2
+amellyel 2
+amelyik 2
+amihez 2
+amin 2
+amolyan 2
+and 2
+angol 2
+ankarai 2
+annál 2
+anyag 2
+apadt 2
+apja 2
+autóbuszok 2
+autópályán 2
+azok 2
+azután 2
+bajnokságban 2
+bankszektor 2
+becslések 2
+befektetésre 2
+befektetők 2
+bejelentette 2
+belváros 2
+belüli 2
+benzin 2
+beszámolója 2
+beszélő 2
+betiltott 2
+betöltő 2
+bevezetése 2
+bevezetésére 2
+bevételből 2
+bevételek 2
+bizonygatta 2
+bizonytalankodás 2
+bizottsága 2
+biztonság 2
+biztosan 2
+bonyolult 2
+brit 2
+bruttó 2
+bármelyik 2
+bécsi 2
+bírák 2
+bírálatokat 2
+bízik 2
+börtönbüntetés 2
+bőven 2
+chaebol 2
+cigány 2
+csapatot 2
+csapást 2
+csatáját 2
+csehek 2
+csepeli 2
+cserkeszeknek 2
+csinál 2
+csináltam 2
+csomagtervet 2
+csökkentését 2
+csütörtökön 2
+cégegyesülésekre 2
+célpontja 2
+címét 2
+darab 2
+decemberi 2
+deficitet 2
+deficitje 2
+diákok 2
+diákot 2
+dolgok 2
+dolgoztam 2
+dollárt 2
+drasztikus 2
+dél-koreai 2
+délelőtt 2
+déli 2
+délkelet-ázsiai 2
+délnyugatra 2
+délre 2
+díjazottak 2
+dönt 2
+döntöttek 2
+döntőbíráskodást 2
+edző 2
+egyenesen 2
+egyesítésével 2
+egyesült 2
+egyetértenek 2
+egyház 2
+egymásba 2
+egymást 2
+egyszersmind 2
+egyszerűen 2
+egységes 2
+egységre 2
+egyéb 2
+együttesben 2
+egészen 2
+egészségi 2
+egészségügyi 2
+egészében 2
+ehhez 2
+eladását 2
+elegendő 2
+eleje 2
+elejétől 2
+elemző 2
+elengedhetetlen 2
+elfogadta 2
+elhalasztott 2
+elindulni 2
+elindított 2
+elismerte 2
+elkerülni 2
+elképesztő 2
+elkövetett 2
+ellenfél 2
+ellenkezőleg 2
+ellentétek 2
+ellenzékiek 2
+ellátási 2
+elmaradt 2
+elnökválasztás 2
+elnökének 2
+elnökét 2
+elnökön 2
+elnököt 2
+eltérések 2
+eltűnt 2
+elveszíti 2
+elvetette 2
+elébe 2
+elégedetten 2
+elérni 2
+elérték 2
+előadás 2
+előadást 2
+elődje 2
+előfordult 2
+előirányzott 2
+előre 2
+előtte 2
+előzetes 2
+előző 2
+emelkedett 2
+emellett 2
+emelnék 2
+emelte 2
+emelése 2
+emelésére 2
+emelését 2
+emiatt 2
+említik 2
+eredeti 2
+eredmény 2
+eredményeit 2
+eredményt 2
+erejük 2
+erő 2
+erőlteti 2
+esemény 2
+esett 2
+esti 2
+estét, 2
+eszembe 2
+eszközzel 2
+esélyt 2
+eső 2
+eurós 2
+ezredfordulós 2
+fatális 2
+februárban 2
+februári 2
+fegyverek 2
+fejlődését 2
+feladatként 2
+feladatnak 2
+feladatok 2
+feladatokkal 2
+feladta 2
+felett 2
+feletti 2
+felkértek 2
+fellendülése 2
+felnőtt 2
+feloldását 2
+felső 2
+feltehetően 2
+feltűnt 2
+felvonása 2
+fennakadást 2
+fenntartott 2
+fennálló 2
+fenyeget 2
+fenyegetőznek 2
+fertőzött 2
+festett 2
+feszültség 2
+fia 2
+fideszes 2
+figyelemre 2
+figyelmet 2
+film- 2
+fizetőképes 2
+foglalkozott 2
+fogva 2
+fogyasztókat 2
+folyamatos 2
+folytatja 2
+folytatott 2
+folytatása 2
+folytatódik 2
+fordulnak 2
+forduló 2
+forinttal 2
+forma 2
+formában 2
+források 2
+forrásokból 2
+fotóművész 2
+félidőben 2
+féléves 2
+fölött 2
+függ 2
+főbb 2
+főiskolán 2
+főnök 2
+főorvos 2
+fős 2
+fővárost 2
+fűtőolajhoz 2
+garancia 2
+gazdaságban 2
+gazdaságot 2
+gondolom 2
+gondolunk 2
+gyakorlat 2
+gyakorlatilag 2
+gyakorta 2
+gyakran 2
+gyanújukat 2
+gyarapodik 2
+gyerekek 2
+gyermek 2
+gyermekek 2
+gyermeket 2
+gyorsabb 2
+gyár 2
+győri 2
+győzelem 2
+győzelme 2
+győzött 2
+gyűjtsenek 2
+hagyott 2
+hagyta 2
+hajnalban 2
+hajtott 2
+hallgatók 2
+halottak 2
+halála 2
+halálát 2
+hamarabb 2
+hangsúlyozó 2
+harcba 2
+harcosok 2
+harmadik 2
+hasznos 2
+használják 2
+hatalmának 2
+hatvan 2
+hatálya 2
+hatályba 2
+határ 2
+határos 2
+határozott 2
+határőrség 2
+hatására 2
+havazás 2
+hazája 2
+hely 2
+helyben 2
+helyettesítheti 2
+helyettesítésének 2
+helyezte 2
+helyhatósági 2
+helyzetben 2
+helyzete 2
+helyzetüket 2
+helyére 2
+hetekben 2
+heti 2
+heves 2
+hibátlan 2
+hihetetlen 2
+hiteleire 2
+hiteleket 2
+hitelekre 2
+hitelintézeti 2
+hivatalában 2
+hivatkozó 2
+hiányzik 2
+hiányát 2
+hoztak 2
+hozzálátott 2
+hozzátette 2
+hozó 2
+humorral 2
+háborút 2
+háromszorosára 2
+hátterében 2
+háttérben 2
+hétköznapi 2
+héttel 2
+hétéves 2
+hírek 2
+hívei 2
+hónapokban 2
+hónapos 2
+hónappal 2
+hőse 2
+ideig 2
+ideje 2
+idény 2
+időszak 2
+időszakban 2
+igazgatótanács 2
+igazolások 2
+igazolásokat 2
+igazságügyi 2
+igencsak 2
+igyekszik 2
+igyekvő 2
+igényt 2
+illeték 2
+illetékes 2
+illetékesek 2
+illetően 2
+ilyenek 2
+ilyenkor 2
+indokolja 2
+indulnak 2
+indult 2
+inflációs 2
+inflációt 2
+infrastruktúra 2
+ingyen 2
+integráció 2
+intenzív 2
+intett 2
+intézkedés 2
+intézmények 2
+intézményekben 2
+intézményt 2
+intézte 2
+invitálta 2
+irányba 2
+irányból 2
+irányítását 2
+iskola 2
+iskolák 2
+iskoláztatási 2
+ismeretlen 2
+itthon 2
+jaguár 2
+januári 2
+japán 2
+javaslatát 2
+jele 2
+jelenség 2
+jelentett 2
+jelentések 2
+jelentését 2
+jelentősebb 2
+jelentősége 2
+jelentőségű 2
+jelez 2
+jogot 2
+jutnak 2
+jutottak 2
+járatot 2
+jármű 2
+játszik 2
+játszott 2
+játéktér 2
+jórészt 2
+jót 2
+jött 2
+jövedéki 2
+kalapács 2
+kantonizáció 2
+kap 2
+kapacitással 2
+kapcsolódik 2
+kapcsán 2
+kaptak 2
+kaptam 2
+karácsonyfatüzek 2
+kedvelte 2
+keletkezett 2
+kellőképpen 2
+kenyereskocsi 2
+kereskedelemben 2
+kereskedők 2
+kerámiatárgyak 2
+kerülhetnek 2
+kerüljenek 2
+kettő 2
+kezdte 2
+kezdték 2
+kezeli 2
+kezére 2
+kiadott 2
+kialakulását 2
+kifizetni 2
+kihirdetését 2
+kijelentette 2
+kikiáltási 2
+kilencvenes 2
+kilométer 2
+kilátásba 2
+kimaradt 2
+kinevezett 2
+kinevezése 2
+kisebbségi 2
+kiállításon 2
+koalíciós 2
+kockáztatja 2
+komolyabb 2
+koncerten 2
+konferencia 2
+konferencián 2
+konjunktúra 2
+kor 2
+kora 2
+korig 2
+korlátai 2
+korlátozást 2
+kormánnyal 2
+kormánya 2
+kormányoldalon 2
+kormánypárt 2
+koronáért 2
+koszorú 2
+kuriózum 2
+kutatások 2
+kárt 2
+kényszerült 2
+kénytelenek 2
+képezik 2
+képtelen 2
+képviselőház 2
+képviselők 2
+képviselőknek 2
+kérdésekről 2
+kérte 2
+kész 2
+készített 2
+később 2
+kétszer 2
+kínálati 2
+kíván 2
+kívánják 2
+kívánt 2
+kórházban 2
+köd 2
+kölcsönös 2
+könnyű 2
+könyv- 2
+környezet 2
+környékén 2
+körre 2
+körözési 2
+körül 2
+körű 2
+köszönhetően 2
+kötelezően 2
+kötet 2
+kötött 2
+következménye 2
+következményekkel 2
+közelebb 2
+közeledik 2
+közeli 2
+közelről 2
+közelében 2
+közgyűlésen 2
+közgyűlést 2
+közgyűlésén 2
+közigazgatási 2
+közlekedik 2
+közlekedés 2
+közlemény 2
+közoktatási 2
+központ 2
+közpénzekből 2
+köztisztviselői 2
+közzé 2
+közölt 2
+közölték 2
+közönség 2
+közösségek 2
+közülük 2
+küldték 2
+külföldiek 2
+külvilágtól 2
+külön 2
+különbség 2
+különféle 2
+különmegbízottja 2
+külügyi 2
+küzdelem 2
+küzdelme 2
+küzdelmet 2
+lakosú 2
+lakásokban 2
+lap 2
+lapunknak 2
+lebontása 2
+lefolytatását 2
+legjobban 2
+legkritikusabb 2
+legközelebb 2
+legtöbb 2
+legyenek 2
+lehetne 2
+lehetőségét 2
+lejátszott 2
+lelkesedett 2
+lemezből 2
+lemondani 2
+lemondott 2
+lengyel 2
+lennének 2
+levelet 2
+levelében 2
+levélpapírján 2
+lezárni 2
+lezárta 2
+likviditású 2
+listán 2
+láncok 2
+lánya 2
+lát 2
+láthatatlan 2
+láthattunk 2
+láthatóan 2
+látják 2
+látni 2
+látogatott 2
+látogatásán 2
+látom 2
+látszott 2
+látványosan 2
+légitársaság 2
+lépést 2
+létre 2
+létrejött 2
+lévén 2
+lírai 2
+magam 2
+magának 2
+mai 2
+maradáshoz 2
+maradó 2
+matematikánál 2
+megbeszéléseken 2
+megbízott 2
+megerősített 2
+megfogalmazott 2
+megfontolások 2
+meggyújtott 2
+meghaltak 2
+meghatározott 2
+meghívták 2
+megint 2
+megjelent 2
+megjelenése 2
+megkaptam 2
+megközelíteni 2
+megrendezni 2
+megszüntetése 2
+megszüntetéséről 2
+megtudtuk 2
+megugrott 2
+megvalósítására 2
+megvált 2
+megvásárolja 2
+megy 2
+megyeszékhelyen 2
+megállapodni 2
+megállapodást 2
+megérkezett 2
+megérkezik 2
+mellé 2
+melyen 2
+melyről 2
+menedzsere 2
+menekültek 2
+mentén 2
+merénylet 2
+merényletet 2
+metró 2
+miatti 2
+milliárddal 2
+milliós 2
+minap 2
+mindenekelőtt 2
+mindenhol 2
+mindenkinek 2
+mindenképpen 2
+mindent 2
+mindenáron 2
+mindenütt 2
+mintha 2
+minőségű 2
+minősítette 2
+mond 2
+mondták 2
+motorolajok 2
+mozgalom 2
+mozog 2
+multinacionális 2
+munkakörben 2
+munkanélküliek 2
+mutat 2
+mutatja 2
+mutatják 2
+mutatkozik 2
+mutatnak 2
+májusban 2
+mára 2
+márciusában 2
+márkás 2
+másodszor 2
+másrészt 2
+mást 2
+mégsem 2
+mélygarázs 2
+mértékben 2
+módosítása 2
+módszerek 2
+múltán 2
+műfaj 2
+műfajban 2
+működési 2
+működését 2
+műveket 2
+művészeti 2
+nad 2
+nagykövet 2
+nagymester 2
+nagyobbik 2
+nagyok 2
+nagyszabású 2
+nagyszerű 2
+napjainkban 2
+napján 2
+napvilágot 2
+negyedik 2
+negyedében 2
+negyedévben 2
+negyedéves 2
+nehezen 2
+nemet 2
+nemrégiben 2
+nettó 2
+netán 2
+neves 2
+nevet 2
+nevezi 2
+nevével 2
+nevű 2
+nyelvhasználat 2
+nyereséget 2
+nyersolaj 2
+nyersolajárakat 2
+nyilvánosságra 2
+nyitott 2
+nyitottak 2
+nyolcadik 2
+nyomban 2
+nyomán 2
+nyugat-európai 2
+nyugatra 2
+nyugdíjba 2
+nyugodtan 2
+nyílik 2
+nyújtott 2
+népszerűségéből 2
+néven 2
+nézettsége 2
+nézve 2
+nézők 2
+növekedés 2
+növekedési 2
+növekedést 2
+növekedését 2
+növekedésével 2
+növekszik 2
+növelheti 2
+növelését 2
+oda 2
+okán 2
+olajtársaságok 2
+olcsóbban 2
+olcsón 2
+oldalát 2
+olvasható 2
+oly 2
+operatív 2
+országgyűlési 2
+országokban 2
+országos 2
+országszerte 2
+osszák 2
+osztályvezetője 2
+parlamentje 2
+parlamenttel 2
+partner 2
+pedagógiai 2
+pedagógusok 2
+perc 2
+periódus 2
+pesti 2
+pillanatnyi 2
+plakátot 2
+polgármesteri 2
+politika 2
+pontja 2
+pontos 2
+pontot 2
+porondon 2
+portugál 2
+posztjáról 2
+posztról 2
+pozícióját 2
+pristinai 2
+probléma 2
+produkciójában 2
+profi 2
+program 2
+programjában 2
+prágai 2
+puccs 2
+pálya 2
+pályákon 2
+pályázatot 2
+pápa 2
+pártelnök 2
+párton 2
+példaként 2
+példányban 2
+pótlékot 2
+püspöki 2
+püspökök 2
+rajzfilm 2
+rakpart 2
+rangú 2
+reformok 2
+reklámozó 2
+remekel 2
+reménykedhet 2
+reménykedhetnek 2
+rendezni 2
+rendezvény 2
+rendezés 2
+rendszerek 2
+rendszerében 2
+rendőr 2
+rendőrségi 2
+rendőrök 2
+repülőtér 2
+reális 2
+ringbe 2
+rokon 2
+roma 2
+rubel 2
+régen 2
+régió 2
+résztvevők 2
+részére 2
+segély 2
+segélyt 2
+segítséget 2
+sehova 2
+semmiképpen 2
+sikerül 2
+sorozatot 2
+sorsukról 2
+stabilitás 2
+sugárzott 2
+szabadság 2
+szabadítani 2
+szabályozott 2
+szabályozó 2
+szakmailag 2
+szakértői 2
+szankciók 2
+szavai 2
+szavakat 2
+szavazatok 2
+szegedi 2
+szegény 2
+szekta 2
+szembe 2
+szembeni 2
+személyében 2
+szentendrei 2
+szenátornak 2
+szerbeket 2
+szerdai 2
+szerelem 2
+szerencsére 2
+szerencsés 2
+szerencsétlenség 2
+szerepelnek 2
+szerepéről 2
+szerette 2
+szerinte 2
+szervezetnek 2
+szervezésében 2
+szerződés 2
+szerzői 2
+szigorú 2
+szinten 2
+szintet 2
+szintre 2
+szintű 2
+szobrász 2
+szocialisták 2
+szociáldemokrata 2
+szociáldemokratákat 2
+szokásos 2
+szomszédos 2
+szorgalmazó 2
+szorzó 2
+szállít 2
+szállítani 2
+szállító 2
+szám 2
+számolva 2
+számukra 2
+számában 2
+számának 2
+számítanak 2
+számíthat 2
+számíthatnak 2
+számított 2
+számítások 2
+számítógépes 2
+szán 2
+szándékát 2
+szárazföldi 2
+származású 2
+származó 2
+szárnyalása 2
+százalékban 2
+százalékra 2
+szélsőséges 2
+szépen 2
+színes 2
+színházi 2
+színháznak 2
+színpadi 2
+színpadon 2
+színész 2
+szólva 2
+szólásszabadság 2
+szóvivő 2
+szöuli 2
+szövetség 2
+szüksége 2
+sífelszereléseket 2
+süppedt 2
+tagjának 2
+tagok 2
+talpra 2
+találkozni 2
+találkozott 2
+találkozókat 2
+találták 2
+tanköteles 2
+tanácsadási 2
+tapasztalatai 2
+tapasztalja 2
+tarthat 2
+tartományt 2
+tartotta 2
+tartották 2
+tartozott 2
+tartozást 2
+tartósítóipari 2
+tartózkodása 2
+tartózkodó 2
+tavasszal 2
+taxisok 2
+tb 2
+teherautó 2
+tejipari 2
+tekintette 2
+tekintik 2
+tekintélyelvű 2
+település 2
+települést 2
+televízió 2
+tengerentúli 2
+tenni 2
+teremt 2
+terhelő 2
+terhestanácsadás 2
+termék 2
+termékek 2
+természetes 2
+természeti 2
+terveket 2
+területe 2
+területen 2
+területre 2
+teszik 2
+tetszenek 2
+tetszik 2
+tettem 2
+tevékenykedő 2
+tevékenység 2
+tiltja 2
+tiszt 2
+tisztán 2
+tizedik 2
+tonnánként 2
+tragédia 2
+tudják 2
+tudok 2
+tulajdonban 2
+tulajdoni 2
+tulajdonukban 2
+tájékoztatott 2
+támadók 2
+támogatja 2
+támogatják 2
+támogatás 2
+tárgyak 2
+tárgyalni 2
+társadalmat 2
+társadalomban 2
+társait 2
+távol-keleti 2
+távolsági 2
+tél 2
+télen 2
+témája 2
+tény 2
+tényezők 2
+tényleg 2
+tér 2
+térdre 2
+téren 2
+térni 2
+térségben 2
+tétele 2
+tévé 2
+típusú 2
+tíz-tíz 2
+tízezer 2
+többen 2
+többet 2
+többnyire 2
+többször 2
+többség 2
+többségben 2
+többségében 2
+többségét 2
+tökéletesen 2
+tömeg 2
+tömegközlekedési 2
+töri 2
+története 2
+történetének 2
+törvények 2
+törvényes 2
+törvényszék 2
+törzstőkéjű 2
+törökországi 2
+törökök 2
+túlélők 2
+tüzet 2
+tőkeemelés 2
+tőkeerős 2
+tőkéjét 2
+tőkét 2
+tűzoltóknak 2
+tűzoltóság 2
+ugyanaz 2
+utakon 2
+utat 2
+utcában 2
+utol 2
+utoljára 2
+utóbbit 2
+vajon 2
+valami 2
+vallás 2
+vehetnek 2
+velük 2
+vennie 2
+versenyt 2
+veszik 2
+vesztesége 2
+veszteséget 2
+veszélybe 2
+veszít 2
+vették 2
+vezér 2
+világgazdasági 2
+világháború 2
+világi 2
+világméretű 2
+virradóra 2
+virtuális 2
+viszonyok 2
+vitát 2
+vizet 2
+vizitet 2
+vizsgálni 2
+voltaképpen 2
+voltunk 2
+von 2
+vonatok 2
+vádolt 2
+válasz 2
+választ 2
+választhatják 2
+választotta 2
+választották 2
+választásokat 2
+választók 2
+vállalhatnak 2
+vállalkozás 2
+válnak 2
+válogatott 2
+válogatottat 2
+válogatottban 2
+válságból 2
+váltak 2
+váltott 2
+változat 2
+váltsák 2
+vár 2
+várakozások 2
+várhatók 2
+várja 2
+városba 2
+városi 2
+várostól 2
+vásárolja 2
+védelmi 2
+vége 2
+végleges 2
+végrehajtását 2
+végső 2
+végzetes 2
+végzős 2
+végéhez 2
+vélekedett 2
+vélem 2
+véleménye 2
+véli 2
+vélte 2
+washingtoni 2
+zenét 2
+zenével 2
+zsúfolt 2
+zágrábi 2
+zárva 2
+zöme 2
+Általános 2
+Éppen 2
+Új 2
+Ústi 2
+ágazatban 2
+ágazatokban 2
+állambiztonsági 2
+állammal 2
+államot 2
+állapota 2
+állította 2
+állították 2
+állítása 2
+általában 2
+árokba 2
+árverésen 2
+árából 2
+átalakulás 2
+átlagos 2
+élek 2
+életbe 2
+életemben 2
+életük 2
+élveztem 2
+élénkülése 2
+építési 2
+építészeti 2
+építését 2
+éri 2
+érkeztek 2
+érthető 2
+érték 2
+értékben 2
+értékekre 2
+értékes 2
+értékét 2
+értük 2
+érzik 2
+észak-kaukázusi 2
+észre 2
+éveken 2
+évszámváltás 2
+évszázad 2
+évtizede 2
+évtizedek 2
+évtizedeken 2
+írja 2
+írt 2
+ítélet 2
+ítélte 2
+ítélték 2
+ízben 2
+ön 2
+önmagában 2
+önálló 2
+összedőlt 2
+összeg 2
+összegekkel 2
+összehasonlításban 2
+összejövetelét 2
+összekötése 2
+ösztönző 2
+ötlet 2
+újfajta 2
+újraelosztás 2
+újságokban 2
+úthálózaton 2
+útlevélolvasó 2
+úttorlaszokat 2
+ügyben 2
+ügyvezetője 2
+ünneplés 2
+ütőhangszerek 2
+üzletek 2
+őrzött 2
+őrült 2
+"Jövőprogram 1
+"Prince" 1
+' 1
+'99 1
+0,7 1
+0-2 1
+007-esből 1
+1,1 1
+1,12 1
+1,19-es 1
+1,2 1
+1,4-1,5-ös 1
+1,5-2 1
+1,8 1
+1,9 1
+1-1 1
+1-es 1
+1-je 1
+1-től 1
+1. 1
+10,1 1
+10,8 1
+10-12 1
+10-15 1
+10-ig 1
+10-éig 1
+10.-július 1
+102,9 1
+104 1
+107 1
+11,5 1
+11,7 1
+110-120 1
+112-es 1
+12,2 1
+12. 1
+120 1
+120,5 1
+120. 1
+1200 1
+13-22 1
+13. 1
+130 1
+1300 1
+134 1
+135,3 1
+139 1
+14 1
+14,1 1
+140 1
+147,2 1
+15-én 1
+150 1
+1500 1
+16 1
+16+3 1
+16-ai 1
+16-án 1
+164 1
+17-ből 1
+17-es 1
+17. 1
+1700 1
+171 1
+175 1
+18-a 1
+18-i 1
+1880-as 1
+19,5 1
+19-e 1
+19-es 1
+1925-ben 1
+1927 1
+1944. 1
+1947-es 1
+1947. 1
+1948-ban 1
+1948-tól 1
+1949-ben 1
+1949. 1
+195 1
+1950-ben 1
+1950-es 1
+1955-ben 1
+1957 1
+1957-től 1
+1964 1
+1967-ben 1
+1969 1
+1969-ben 1
+1970 1
+1979-ben 1
+198 1
+1980-ban 1
+1981-ben 1
+1984-ről 1
+1989 1
+1991 1
+1991-es 1
+1993 1
+1993-as 1
+1993. 1
+1994-96-os 1
+1994-ben 1
+1994-es 1
+1994. 1
+1995-ben 1
+1995-ös 1
+1996 1
+1996-os 1
+1996. 1
+1997-es 1
+1997-eshez 1
+1997-től 1
+1998-as 1
+1999.június 1
+2,2 1
+2,25 1
+2,33 1
+2,5-3 1
+2,5-3,5 1
+2-0 1
+2-3 1
+2-6 1
+2-n 1
+2-nél 1
+2-től 1
+2-án 1
+20-40 1
+200-300 1
+2000"-nek 1
+2000-től 1
+2001-ben 1
+2002-re 1
+2003 1
+2007-ig 1
+214 1
+22,6 1
+22-23 1
+23 1
+23,64 1
+23-án 1
+24-féle 1
+25-30 1
+25-ei 1
+25. 1
+26 1
+27 1
+27-i 1
+270 1
+279 1
+28 1
+28,5 1
+28-ról 1
+2800 1
+29 1
+29-én 1
+29-étől 1
+29. 1
+3,37 1
+3,4 1
+3,6 1
+3,9 1
+3-4 1
+3-5 1
+3. 1
+30-i 1
+31 1
+31-ei 1
+31-i 1
+31-éig 1
+311 1
+32 1
+32,4 1
+32,5 1
+330 1
+338 1
+34 1
+35-öt 1
+3500-ra 1
+36 1
+37 1
+38,37 1
+39. 1
+396 1
+4,5 1
+4-5-én 1
+4-ről 1
+4-én 1
+40. 1
+41 1
+413 1
+42 1
+42,5 1
+430 1
+434 1
+44,5 1
+4500 1
+46 1
+47 1
+485,7 1
+49 1
+5,3 1
+5,5 1
+5,6 1
+5,8 1
+5-10 1
+5-6 1
+5-7 1
+5-ig 1
+5. 1
+50-50 1
+52. 1
+553,7 1
+56 1
+56-os 1
+59 1
+6,6 1
+6-7 1
+60. 1
+61,5 1
+61,8 1
+62 1
+660 1
+68 1
+68. 1
+69 1
+7,8 1
+7-én 1
+70-80 1
+71,3 1
+76,8-ra 1
+77 1
+77. 1
+79 1
+8,5 1
+8,6 1
+8,9-del 1
+8-as 1
+80-as 1
+800 1
+81 1
+82 1
+84. 1
+85 1
+85. 1
+86 1
+860 1
+8600 1
+87 1
+9 1
+9,2 1
+9,45 1
+9,8 1
+9,93 1
+9-10 1
+9-14 1
+90. 1
+900 1
+95 1
+97-ben 1
+973 1
+AG 1
+AIDS-esek 1
+AIDS-szel 1
+AWS 1
+Abonyi 1
+Addig 1
+Adige 1
+Adorján 1
+Afganisztán 1
+Afganisztánban 1
+Afrika 1
+Ahmed 1
+Akció 1
+Akinek 1
+Akkoriban 1
+Akopjan 1
+Akszjonyenko 1
+Aktuális 1
+Albatroszt 1
+Albert 1
+Alechinsky 1
+Alekszander 1
+Alex 1
+Alfonsót 1
+Alkotmánybírósághoz 1
+Alkotmánysértőnek 1
+Allgemeine 1
+Almási 1
+Altenkirchenben 1
+Amadindának 1
+Ambrus 1
+Amint 1
+Amíg 1
+Andrástól 1
+Andrásé 1
+Anita 1
+Anitával 1
+Ankarába 1
+Ankarából 1
+Antoni 1
+Anya 1
+Anyegin 1
+Anynyit 1
+Aracsicsnak 1
+Arahamija 1
+Arbour 1
+Aronyian 1
+Arról 1
+Aszlan 1
+Atatürk 1
+Atatürkkel 1
+Atex-holding 1
+Atrium 1
+Attól 1
+Audit 1
+Ausev 1
+Autó 1
+Avrukh 1
+Avtoexport 1
+Azelőtt 1
+Azzal 1
+BL 1
+BL-ben 1
+BMW 1
+BS-beli 1
+Babiucot 1
+Baden-Württemberg 1
+Bajorországban 1
+Bakonyba 1
+Baku 1
+Balekok 1
+Bankot 1
+Banktól 1
+Barankovics 1
+Baranya, 1
+Baranyai 1
+Barca 1
+Barcelonát 1
+Barátunkat 1
+Batumiban 1
+Baán 1
+Be 1
+Befejezte 1
+Behavazódtak 1
+Behgjet 1
+Belarusz 1
+Belgrád 1
+Belgrádba 1
+Beljavszkij 1
+Benkő 1
+Berg 1
+Berzi 1
+Biberachot 1
+Bibical 1
+Biblical 1
+Bildt 1
+Bizonyos 1
+Biztonsági 1
+Blair 1
+Bodmérre 1
+Bodo 1
+Bokros 1
+Boldoggá 1
+Bomba 1
+Borba 1
+Borban 1
+Bordeaux-t 1
+Borisz 1
+Bosznia-Hercegovina 1
+Boszniában 1
+Bp. 1
+Brandenburgban 1
+Brandt 1
+Brazíliában 1
+Brdjanin 1
+Brent 1
+Bronzanyagát 1
+Brosnan 1
+Brosnannek 1
+Brozt 1
+Brókerhez 1
+Brüsszelben 1
+Brüszszelben 1
+Budalakk 1
+Budapestet 1
+Budapestig 1
+Budapestről 1
+Budapesttől 1
+Budejovice-i 1
+Bundesrat 1
+Bundestagban 1
+Burroughs 1
+Burány 1
+Bán 1
+Bánk 1
+Bécs 1
+Bécset 1
+Békesi 1
+Béla 1
+Bér 1
+Bírósági 1
+Börzsönyi 1
+Bülent 1
+Bőhm 1
+Bőven 1
+C 1
+CB 1
+CD 1
+CD-m 1
+CTK 1
+Camus 1
+Carl 1
+Carmen-előadás 1
+Carmenben 1
+Center 1
+Ceské 1
+Cherokeet 1
+Chillida 1
+Chironis 1
+Cigánybáró 1
+Collins 1
+Connery 1
+Consulting 1
+Corriere 1
+Cosi 1
+Cottbusban 1
+Csabával 1
+Családügyi 1
+Csapody 1
+Csecsenföldre 1
+Csellóegyüttestől 1
+Csepel 1
+Cserkassziban 1
+Cserkesszkben 1
+Cserkeszfölddel 1
+Cserkeszföldön 1
+Csernyin 1
+Csiburdanidze 1
+Csillagszem 1
+Csirkefejének 1
+Csobánka 1
+Csong 1
+D 1
+Daewoo-megállapodásban 1
+Daewoonak 1
+Daewoonál 1
+Daewooval 1
+Daewooéhoz 1
+Dagesztán 1
+Dagesztánban 1
+Dante 1
+Dautov 1
+Demokrata 1
+Demszky 1
+Denise 1
+Deportivót 1
+Di 1
+Disney 1
+Disney-feldolgozás 1
+Djindjics 1
+Dnyeper 1
+Dnyipropetrovszk 1
+Dolomit 1
+Domonkos 1
+Donyeckben 1
+Dorny 1
+Dr. 1
+Draskovics 1
+Drulovics 1
+Dubceket 1
+Dubceknak 1
+Dubcekről 1
+Dubrava 1
+Dániel 1
+Dél-Amerikában 1
+Dél-Koreát 1
+Dénes 1
+Döntő 1
+EBESZ-csúcson 1
+EBESZ-konferenciát 1
+EBESZ-küldöttség 1
+ENSZ-főtitkár 1
+ENSZ-kormányzat 1
+ENSZ-közigazgatás 1
+ENSZ-nagykövete 1
+ENSZ-nek 1
+EU-csatlakozás 1
+EU-n 1
+EU-tagság 1
+EU-tagállamok 1
+EU-tagállamokhoz 1
+Eastern 1
+Eb-címmeccsre 1
+Eb-címmérkőzése 1
+Eb-n 1
+Ebben 1
+Ecevit 1
+Economic 1
+Economist 1
+Eddig 1
+Edgar 1
+Eduardo 1
+Egyesület 1
+Egyesülete 1
+Egyidejűleg 1
+Egészséget 1
+Egészségügyi 1
+Eichel-csomagot 1
+Eleinte 1
+Elengedhetetlen 1
+Elhangzik 1
+Elhitették 1
+Elképzelhető 1
+Ellenfelei 1
+Ellenállási 1
+Eller 1
+Elmegy 1
+Eluralkodott 1
+Elvi 1
+Elég 1
+Előszállásnál 1
+Először 1
+Elővárosi 1
+Előzetes 1
+Előző 1
+Emberfeletti 1
+Emellett 1
+Emil 1
+Emlékezni 1
+Endrének 1
+Energia 1
+Engem 1
+Enying 1
+Ercel 1
+Ercsi 1
+Eredmények 1
+Ernst 1
+Erol 1
+Ersténél 1
+Erős 1
+Essenben 1
+Este 1
+Eszerint 1
+Etienne 1
+Ettől 1
+Európa-bajnoki 1
+Európa-bajnokságon 1
+Európa-bajnokságra 1
+Ezekben 1
+Ezeket 1
+Ezenfelül 1
+Ezúttal 1
+Eörsi 1
+FIK 1
+FIK-részvényeit 1
+Faludi 1
+Far 1
+Faragó 1
+Farit 1
+Fejlesztési 1
+Fejérben 1
+Felhozták 1
+Felkészítő 1
+Felsenstein 1
+Felszabadultak 1
+Felszabadítási 1
+Felvetődik 1
+Fennállása 1
+Ferencet 1
+Ferencsik 1
+Ferguson 1
+Ferke 1
+Fidesz-MPP 1
+Fidesz-közeli 1
+Figo 1
+Filippov 1
+Fiorentinából 1
+First 1
+Fiuméban 1
+Fjodorovna 1
+Fodor 1
+Fokozatosan 1
+France 1
+Frankfurter 1
+Freud 1
+Frigyes 1
+Full 1
+FÁK-országi 1
+FÁK-országok 1
+FÁK-piacon 1
+FÁK-tagállamok 1
+Félhold 1
+Fészek 1
+Független 1
+Fülöp 1
+Fülöp-szigetek 1
+Fülöp-szigeteki 1
+Fürdés 1
+Főbiztosságának 1
+Főiskolán 1
+Fővárosi 1
+GDP-t 1
+Gaal 1
+Gabriel 1
+Galambos 1
+Galkin 1
+Gallery 1
+Galleryben 1
+Galériában 1
+Gazda 1
+Gazekszportot 1
+Gazi 1
+Gazizullin 1
+Gazprom-részvénypakettet 1
+Gazpromban 1
+Gazprommal 1
+Gazpromot 1
+Gelfand 1
+Genscher 1
+Gergely 1
+Gimnázium 1
+Gimnáziumot 1
+Giovanni 1
+Giovannira 1
+Girondins 1
+Glamour 1
+Glatz 1
+Globus 1
+Gnjilane 1
+Gnjilanéban 1
+Goebbelset 1
+Goebbelsi 1
+Goghra 1
+Gonzales 1
+Gratulálunk 1
+Groznij 1
+Groznijtól 1
+Grábics 1
+Grúziától 1
+Guglielmo 1
+Gurieli 1
+Gyerektörténet 1
+Gyerevék 1
+Gyuri 1
+Gyár 1
+Gyógyszer 1
+Gyönyörű 1
+Györgyöt 1
+Győr-MTK 1
+Győző 1
+Gáborral 1
+Gábort 1
+Gépgyár 1
+Géza 1
+Gödrös 1
+Gödöllő 1
+Gödöllőn 1
+Günther 1
+Gőz 1
+HIV-vírus 1
+HIV-vírushordozó 1
+HVG-t 1
+Habsburg 1
+Hacsak 1
+Hadsereg 1
+Hahót-Tőzeg 1
+Hajdu 1
+Hajdú 1
+Hamburg 1
+Hameddel 1
+Hans-Dietrich 1
+Hasim 1
+Hasonlóan 1
+Hatezer 1
+Határozatképtelenség 1
+Hava 1
+Havel 1
+Havellal 1
+Hazudik 1
+Hegedűs 1
+Heinrich 1
+Henoch 1
+Hepta-csoporté 1
+Hercegével 1
+Herendi 1
+Hernádi 1
+Hertha-Barcelona 1
+Hitel 1
+Ho 1
+Hoeme 1
+Hogy 1
+Hol 1
+Holbrooke 1
+Holyfield 1
+Hombach 1
+Honvédelmi 1
+Honvédség 1
+Horn 1
+Horn-kabinet 1
+Horváth 1
+Horvátországban 1
+Horvátországot 1
+Hosszú 1
+Hová 1
+Hozzátette 1
+Hungary 1
+Hunor 1
+Huszár 1
+Hyatt 1
+Hyundait 1
+Hágába 1
+Hány 1
+Hát 1
+Hátrányos 1
+Ház 1
+Házban 1
+Héja 1
+Hétfői 1
+Híradó 1
+Híradóját 1
+Hírközlési 1
+Húsz 1
+Hübner-Hickl-összecsapás 1
+ISE 1
+ISM 1
+Ide 1
+Ideiglenes 1
+Igyekezetét 1
+Ilie 1
+Ilja 1
+In 1
+Indonézia 1
+Indonéziában 1
+Infernóját 1
+Ingatlaniroda 1
+Ingatlankezelő 1
+Intézet 1
+Intézetben 1
+Invest 1
+Iparkamara 1
+Irodalom 1
+Iránt 1
+Iskola 1
+Iskola, 1
+Iskolát 1
+Isztambul 1
+Isztambulból 1
+Itt 1
+Ivancsuk 1
+Ivanovval 1
+Iveco 1
+Jaguár 1
+Jaguárról 1
+Jan 1
+Jane 1
+Januártól 1
+Jardel 1
+Jeep 1
+Jeles 1
+Jellemzőbb 1
+Jerusalem 1
+Jevgenyij 1
+Joan 1
+Jogtudományi 1
+Johann 1
+Josip 1
+Joszeliani 1
+Judaika 1
+Judit 1
+Jugoszláviáért 1
+Jung 1
+Jurij 1
+Jutarnji 1
+Juventus 1
+Ján 1
+Járai-csomagot 1
+Járdányi 1
+Járni 1
+Józsefnek 1
+Józsi 1
+Jövő 1
+Július 1
+Június 1
+Jürgen 1
+KFOR-gépek 1
+KGB-ügynök 1
+KHVM 1
+Kabard-Balkár 1
+Kalauz 1
+Kaljuzsnij 1
+Kalmár 1
+Kamara 1
+Kambodzsa 1
+Kamionok 1
+Kamondi 1
+Kandahárban 1
+Kang 1
+Kapolyi 1
+Kaposvár 1
+Karacsáj-Cserkesz 1
+Karbonát 1
+Kardelj 1
+Karl 1
+Karosa 1
+Karán 1
+Kaszjanov 1
+Katircioglu 1
+Kavan 1
+Kazimierz 1
+Kazinczy-díjat 1
+Kecskemétről 1
+Kedvezőbbnek 1
+Kelebiától 1
+Kelenföldi 1
+Kelet 1
+Kelet-Közép-Európa 1
+Kemal 1
+Kereszty 1
+Kevésbé 1
+Kfor 1
+Kfor-illetékesek 1
+Kfor-katona 1
+Kfor-katonákat 1
+Kft 1
+Kft.- 1
+Kft.-be 1
+Kft.-ből 1
+Kft.-nek 1
+Khurtidze 1
+Kia 1
+Kicserélték 1
+Kijev 1
+Kily 1
+Király 1
+Király(i) 1
+Kivételes 1
+Kizárólag 1
+Kjetil 1
+Kjung 1
+Klapka 1
+Klaus-kabinet 1
+Klausszal 1
+Klimmt 1
+Klubban 1
+Knorr-Bremse 1
+Knut 1
+Kobalija 1
+Kodály 1
+Kohl 1
+Kohllal 1
+Kollarits 1
+Kolozsvárhoz 1
+Komische 1
+Kompozíciói 1
+Konculj 1
+Koncz 1
+Konzervgyártók 1
+Kopint-Datorg 1
+Korcsnoj 1
+Korcsnojjal 1
+Korea 1
+Korábbi 1
+Koszovói 1
+Koszovóra 1
+Kouchnerhez 1
+Kraszenkov 1
+Kravola 1
+Krecz 1
+Kulcskérdés 1
+Kulturális 1
+Kupa 1
+Kupa-mérkőzés 1
+Kár 1
+Kármán 1
+Károllyal 1
+Károly 1
+Készítek 1
+Kétszer 1
+Kétszáz 1
+Kísértetek 1
+Köd 1
+Kölnben 1
+Könyvkiadó 1
+Közalapítvány 1
+Közel 1
+Közlekedési 1
+Központi 1
+Közterület-fenntartó 1
+Köztársaságban 1
+Közös 1
+Közösségének 1
+Közöttük 1
+Kühne 1
+Külső 1
+Külön 1
+Különleges 1
+Külügyminisztérium 1
+Küzdenek 1
+L. 1
+Labem 1
+Labemben 1
+Laden 1
+Lafontaine 1
+Lajossal 1
+Lakner 1
+Lakos 1
+Lapunknak 1
+Legfőképpen 1
+Lehetőleg 1
+Lehmannhoz 1
+Lelkileg 1
+Lengyelországban 1
+Lenszkijnek 1
+Lepsény 1
+Lesz 1
+Lewis-Holyfield-csúcsrangadóját 1
+Libahara 1
+Libchavy 1
+Liboslav 1
+Ligája-mérkőzésen 1
+Lipótmezőn 1
+Livio 1
+Louis 1
+Louise 1
+Lputjan 1
+Ltd. 1
+Lucane 1
+Luis 1
+Lujza 1
+Lutz 1
+Luxemburgba 1
+Lánczos 1
+Látni 1
+Lékó 1
+Léteznek 1
+M0-s 1
+M1-es 1
+MDF 1
+MDF-Fidesz-székházügy 1
+MDF-es 1
+MLSZ-elnök 1
+MLSZ-nek 1
+MSZP 1
+MTA 1
+MTK 1
+Mabetex 1
+Macedóniában 1
+Macedóniából 1
+Madridot 1
+Magdolnának 1
+Maglódtól 1
+Magvető 1
+Magyarország! 1
+Magyarország!-gal 1
+Magyarországi 1
+Magánlevelet 1
+Mahir 1
+Majdnem 1
+Makk 1
+Malajzia 1
+Malakov 1
+Maldoror 1
+Mangurina 1
+Marceau 1
+Marczibányi 1
+Marghescuné 1
+Margit 1
+Maria 1
+Marina 1
+Mario 1
+Martinónak 1
+Martonyi-vizittől 1
+Maszhadov 1
+Maticni 1
+Mazlum-Der 1
+Meciar 1
+Megközelíthetetlenné 1
+Meglepett 1
+Meglepetésre 1
+Megszervezték 1
+Megtisztelő 1
+Megy 1
+Megújhodási 1
+Mekkora 1
+Mellette 1
+Mello 1
+Melnyik-csoport 1
+Mendelssohnnak 1
+Menekültügyi 1
+Mező 1
+Mezőgazdasági 1
+Mezőnyjátékban 1
+Micurinak 1
+Mielőtt 1
+Mihail 1
+Mihály 1
+Mike 1
+Mikolajivban 1
+Mikor 1
+Milliyet 1
+Milosevics 1
+Mindaz 1
+Mindazonáltal 1
+Mindegyik 1
+Mindenesetre 1
+Mindenkinek 1
+Mindig 1
+Mindkét 1
+Minisztériumának 1
+Miró 1
+Misszió 1
+Mit 1
+Mitrohin 1
+Mitsubishi 1
+Mituinak 1
+Mohamed 1
+Momcsilo 1
+Momir 1
+Monokli 1
+Moore 1
+Moraleséről 1
+Moses 1
+Mostanában 1
+Moszkva 1
+Moszkvának 1
+Movszeszian 1
+Mozart 1
+Mroziewicz 1
+Mulomedicina 1
+Mumadi 1
+Munka 1
+Munkás 1
+Music 1
+Mádl 1
+Mária 1
+Másrészt 1
+Mégis 1
+Méteres 1
+Míg 1
+Mónika 1
+Múzeum 1
+Művek 1
+Művészeti 1
+NATO-bombázások 1
+NATO-ellenes 1
+NATO-ellenőrzés 1
+NATO-hoz 1
+NATO-orosz 1
+NSZK-ban 1
+Nachtjournal 1
+Nagymező 1
+Nagyon 1
+Napi 1
+Napjainkban 1
+Naseem 1
+Nawa-tulajdonos 1
+Nehéz 1
+Nemzetközi 1
+Nevezetes 1
+New 1
+Nicola 1
+Nikolett 1
+Nis 1
+Nisbe 1
+Nisen 1
+Nobel-díjas 1
+Noha 1
+Norvégiának 1
+Nyikolaj 1
+Nyitott 1
+Nyugat 1
+Nyugattól 1
+Nyáry 1
+Nyírfa 1
+Nádasdi 1
+Négy 1
+Német 1
+Németh 1
+Németországból 1
+Néprajzi 1
+Népszabadság 1
+Növekednek 1
+Növelheti 1
+Oda 1
+Oktatási 1
+Októberben 1
+Olykor 1
+Olümpuszát 1
+Oniscsuk 1
+Opera 1
+Operbe 1
+Optimista 1
+Orahovac 1
+Orbán-érdekeltségű 1
+Orbánék 1
+Oregon 1
+Oroszországba 1
+Oroszországban 1
+Oroszországból 1
+Oroszországot 1
+Országgyűlésnek 1
+Országos 1
+Országszerte 1
+Orvosi 1
+Orvosnak 1
+Orwell 1
+Oskar 1
+Osszáma 1
+Ottó 1
+PNB-s 1
+Pacolli 1
+Pajerót 1
+Pakisztánban 1
+Palló 1
+Parancsnokságának 1
+Pazar 1
+Pedagógiai 1
+Pelikán 1
+Pfeiffer 1
+Phil 1
+Pierce 1
+Pierre 1
+Piket 1
+Pilis 1
+Pilisszántóba 1
+Pilisszántóval 1
+Pilisvörösvárt 1
+Pirotba 1
+Pitypang 1
+Pofozások 1
+Polgár 1
+Polgári 1
+Poltavában 1
+Ponomarjov 1
+Pontosan 1
+Portisch 1
+Portofinó 1
+Poszeidonnal 1
+Posztját 1
+Pozsony 1
+Pozsonyba 1
+Pozsonyban 1
+Pozsonynak 1
+PriceWaterhouse-Coopers 1
+Primakov 1
+Pristinában 1
+Pristinától 1
+Privatizációs 1
+Probléma 1
+Promotion 1
+Prága 1
+Pszahisz 1
+Pulmann-kocsi 1
+Pákozdi 1
+Pál 1
+Párizsban 1
+Párt 1
+Pártja 1
+Pázmándi 1
+Például 1
+Pénzügyi 1
+Péterfy 1
+Péternek 1
+Péterrel 1
+Pódium 1
+QI 1
+QI-érdekeltség 1
+Quality 1
+Radikal 1
+Radnóti 1
+Radoslav 1
+Radovan 1
+Raj 1
+Rajfu 1
+Real 1
+Redmont 1
+Reggel 1
+Reinhard 1
+Rekdalnak 1
+Rem 1
+Rendezőként 1
+Repülj 1
+Restaro 1
+Reuter 1
+Review 1
+Rezník 1
+Rezníket 1
+Rezníkről 1
+Rice 1
+Richard 1
+Richards 1
+Robbanóanyaggal 1
+Robert 1
+Rod 1
+Roger 1
+Rohamosan 1
+Romanisin 1
+Rosszul 1
+Rt.-t 1
+Rt.-től 1
+Ruszlan 1
+Rádió 1
+Rájuk 1
+Rákosi 1
+Rákosinak 1
+Rákóczi 1
+Rám 1
+Rózsa 1
+Röber 1
+Rövidtávú 1
+SAS-behívó 1
+SPD-híveknek 1
+SPD-n 1
+SPD-s 1
+SPD-t 1
+SPD-tag 1
+SPD-többség 1
+SS-tiszt 1
+SZDSZ 1
+SZDSZ-es 1
+SZDSZ-frakciójának 1
+SZDSZ-képviselőnek 1
+SZTÁR 1
+Saar-vidéken 1
+Sah 1
+Sakkszövetség 1
+Samsung 1
+Schieber 1
+Schumacher 1
+Sean 1
+Senki 1
+Senkálszky 1
+Seoul 1
+Sera 1
+Siemens 1
+Sir 1
+Skopje 1
+Skopjéhez 1
+Soha 1
+Sok 1
+Sokkal 1
+Sokáig 1
+Somogyszobon 1
+Sophie 1
+Sor 1
+Soros-ösztöndíjat 1
+Spanyolországban 1
+Spiró 1
+Stein 1
+Steve 1
+Strauss 1
+Stúdió 1
+Stúdiójának 1
+System 1
+Szabóné 1
+Szaharától 1
+Szajdajev 1
+Szakadár 1
+Szakemberek 1
+Szakmailag 1
+Szakszolgálatot 1
+Szakértői 1
+Szakértők 1
+Szamos-parti 1
+Szebeni 1
+Szekszárdon 1
+Szent-Györgyi 1
+Szentgyörgyi 1
+Szenvedélyes 1
+Szerbia 1
+Szerbiával 1
+Szerdán 1
+Szerencsére 1
+Szergej 1
+Szerinte 1
+Szervezete 1
+Szerényen 1
+Szik 1
+Szingapúr 1
+Szlobodan 1
+Szlovák 1
+Szmirin 1
+Szociáldemokrata 1
+Szociális 1
+Szolgáltató 1
+Szolidaritás 1
+Szovjetunióba 1
+Sztanyiszlav 1
+Sztojkovszki 1
+Sztyepasin 1
+Sztálin 1
+Sztálin-szobor 1
+Szupeszu 1
+Szász 1
+Százhalombatta 1
+Székesfehérváron 1
+Színházhoz 1
+Színháznak 1
+Szóval 1
+Szöulban 1
+Szöultól 1
+Szövetség 1
+Szövetségének 1
+Szőcs 1
+Szűcs 1
+Sándorral 1
+Sándortól 1
+Sárospataki 1
+Súlyosnak 1
+Tab 1
+Talmud-fordítás 1
+Talán 1
+Tampában 1
+Tamási 1
+Tannhäuser 1
+Tanács 1
+Tanácsa 1
+Tanácsához 1
+Tapies 1
+Tarzannak 1
+Tatyjána 1
+Tavasszal 1
+Telekom 1
+Teljesen 1
+Termelésük 1
+Természetesen 1
+Tervek 1
+Testületi 1
+Tetejükig 1
+Tették 1
+Tevje-alakítására 1
+Thaci 1
+Thaciék 1
+Thaiföld 1
+Thaiföldön 1
+The 1
+Tiborné 1
+Tibort 1
+Tietmeyerrel 1
+Timmant 1
+Tisza-parti 1
+Tisztségviselők 1
+Todt 1
+Tolna, 1
+Tony 1
+Topalov 1
+Torricelli 1
+További 1
+Trafóban 1
+Trajkovics-féle 1
+Trajkovics-tervezet 1
+Trapattoni 1
+Tudatosan 1
+Tudjmant 1
+Tudják 1
+Tudom 1
+Tudomásunk 1
+Tudtuk 1
+Tárnok 1
+Tények 1
+Tényekkel 1
+Tényleg 1
+Többnyire 1
+Többször 1
+Többségüket 1
+Többéves 1
+Tömegbalesetet 1
+Történelmi 1
+Törvényszék 1
+Török 1
+Törökországban 1
+Törökországnak 1
+Törökországot 1
+Törökvész 1
+Tötschinger 1
+Tőkepiacban 1
+Tőzeg 1
+Tűzoltó 1
+UCK 1
+UMZE 1
+UNMIK 1
+URH 1
+Uecker 1
+Ugatják 1
+Ugyan 1
+Ugyanez 1
+Ukrajna 1
+Ukrajnában 1
+Universumnak 1
+Urusz-Martan 1
+Utalt 1
+Utoljára 1
+Vaganjan 1
+Vagy 1
+Vagyonkezelő 1
+Vajon 1
+Valami 1
+Valamikor 1
+Valencia-Girondens 1
+Valentyin 1
+Valló 1
+Valóban 1
+Varsó 1
+Vas 1
+Vatikán 1
+Vatikánban 1
+Vecernji 1
+Vegas-i 1
+Vegasban 1
+Vegyük 1
+Vekker 1
+Vele 1
+Vesztére 1
+Vezér 1
+Vida 1
+Vidovszky 1
+Viktornak 1
+Villamos 1
+Világbank 1
+Világszervezet 1
+Vjahirev-féle 1
+Vladimir 1
+Vladimír 1
+Vlaszov 1
+Vlaszovot 1
+Vocke 1
+Vollebaekkel 1
+Volt 1
+Volán 1
+Volánbusz 1
+Vu 1
+Vuk 1
+Választási 1
+Vállalat 1
+Várpalota 1
+Védelem 1
+Végh 1
+Végül 1
+Vékás 1
+Véleménye 1
+Vértesboglárra 1
+Vízügyi 1
+Vörösvári 1
+Wagner 1
+Walt 1
+Walter 1
+Washington 1
+Washingtont 1
+Well-Press 1
+Weltekére 1
+Wely 1
+Wien 1
+Wilhelm 1
+Willy 1
+Wolframját 1
+Würzburgban 1
+XII. 1
+Y2K 1
+Ybl 1
+Ybl-palota 1
+Yollari 1
+York-i 1
+Zacher 1
+Zala-Tőzeg 1
+Zaporozsje 1
+Zavart 1
+Zefirus-csoportnak 1
+Zeitung 1
+Zeneakadémia 1
+Zeneiskola 1
+Zeneiskolát 1
+Zeneművészeti 1
+Zetorok 1
+Zsaroló 1
+Zsiga 1
+Zsivkovics 1
+Zsoldos 1
+Zsolnay-díszváza 1
+Zsolnay-tárgyak 1
+Zycie 1
+abazinok 1
+abból 1
+abházokhoz 1
+ablakát 1
+abortuszon 1
+abszolút 1
+adandó 1
+adat 1
+adatai 1
+adatait 1
+adatbázisok 1
+adatbázissal 1
+adatvédelmi 1
+addigra 1
+adhatnák 1
+adige-abház 1
+adják 1
+adnak 1
+adná 1
+adományaikat 1
+aduvá 1
+adó- 1
+adóbevételeket 1
+adódóan 1
+adófajták 1
+adóhatóság 1
+adóhivatal 1
+adóját 1
+adókedvezmény 1
+adórendszer 1
+adórendőre 1
+adósok 1
+adóssága 1
+adósságainak 1
+adóssághegy 1
+adóssághegyet 1
+adósságot 1
+adósságállomány 1
+adósságállománya 1
+adót 1
+adóval 1
+agresszióra 1
+agrár- 1
+ahelyett 1
+ajándéka 1
+ajánlani 1
+ajánlat 1
+ajánlják 1
+ajánlásainak 1
+akadtak 1
+akadálya 1
+akadályozni 1
+akadályoztatás 1
+akadályoztatását 1
+akadályoztatásától 1
+akadályt 1
+akadémiai 1
+akadémiára 1
+akarat 1
+akaratának 1
+akarjuk 1
+akarják 1
+akart 1
+akartam 1
+akarunk 1
+akcentussal 1
+akciófilm-forgatókönyvírói 1
+akcióknak 1
+akcióra 1
+akciót 1
+akcióval 1
+akiktől 1
+akire 1
+akivel 1
+aknázhatják 1
+aktivistaként 1
+aktívan 1
+alacsonyak 1
+alakja 1
+alakul 1
+alakultak 1
+alakulása 1
+alakulására 1
+alakítania 1
+alakítanák 1
+alakítja 1
+alakítottak 1
+alakításai 1
+alakításával 1
+alanyi 1
+alap 1
+alapanyag-termelők 1
+alapbérek 1
+alapbérüket 1
+alapját 1
+alapkamat 1
+alapkövetelményem 1
+alapkőletételen 1
+alapozva 1
+alapozzák 1
+alapszabály 1
+alapszik 1
+alaptalanul 1
+alaptőke-emelést 1
+alapuljon 1
+alapvetően 1
+alapítványokat 1
+albertfalvai 1
+albuma 1
+albumot 1
+albánokkal 1
+alelnöke 1
+alighanem 1
+alkalmasak 1
+alkalmasnak 1
+alkalmazkodás 1
+alkalmazkodási 1
+alkalmazott 1
+alkalmazottaiból 1
+alkalmazottakra 1
+alkalmazottal 1
+alkalmazottja 1
+alkalmazta 1
+alkalmi 1
+alkalmából 1
+alkalomból 1
+alkimista 1
+alkoholtól 1
+alkotják 1
+alkotmánybíróságnál 1
+alkotmánybíróságtól 1
+alkotása 1
+alkotásához 1
+alkotói 1
+alkotójával 1
+alkotópáros 1
+alma 1
+alsóbb 1
+alsóház 1
+altatja 1
+altábornagy 1
+altábornagyot 1
+aludt 1
+alulfejlett 1
+alvilági 1
+alvás 1
+alább 1
+alámerülés 1
+aláterveznék 1
+alátervezésének 1
+aláírta 1
+aláírási 1
+ambícióit 1
+amelyből 1
+amelyekben 1
+amelyeket 1
+amelyeknek 1
+amelyiktől 1
+amelyre 1
+amerikait 1
+amiben 1
+amik 1
+amiket 1
+amiknek 1
+amikorra 1
+amilyen 1
+amilyenben 1
+amivel 1
+amióta 1
+amnesztiát 1
+amputálja 1
+amíg 1
+angliai 1
+angolok 1
+angolos 1
+angolszász 1
+angolt 1
+angolul 1
+annyiban 1
+annyit 1
+annyival 1
+antidemokratikus 1
+antikommunista 1
+anyaga 1
+anyagban 1
+anyagok 1
+anyagot 1
+anyagát 1
+apad 1
+apai 1
+apokalypsise 1
+apropóján 1
+apróságot 1
+apámat 1
+apósomat 1
+aquincumi 1
+arany 1
+aranykincs 1
+aranykincset 1
+araszoló 1
+arat 1
+aratva 1
+archaikus 1
+archetípusok 1
+argentin 1
+ars 1
+arány 1
+aránylag 1
+aránynak 1
+arányosan 1
+arányt 1
+arányának 1
+asszimilálódott 1
+asszonyt 1
+aszfalton 1
+athéni 1
+atom-tengeralattjáró 1
+atomtudós 1
+atrocitások 1
+attasé 1
+attaséja 1
+attasét 1
+atyja 1
+atyját 1
+atyáskodó 1
+auditorok 1
+augusztusi 1
+aukció 1
+aukciójára 1
+aulájában 1
+automata 1
+automatikus 1
+automatikusan 1
+autonómia 1
+autonómiát 1
+autó 1
+autóba 1
+autóbaleset 1
+autóbusz 1
+autócsoda 1
+autóeladások 1
+autógyártási 1
+autói 1
+autóját 1
+autókat 1
+autókkal 1
+autópályáján 1
+autópályává 1
+autós 1
+autósok 1
+autósoknak 1
+autót 1
+autóval 1
+avarok 1
+aznap 1
+azokból 1
+azokkal 1
+azonnali 1
+azonosítania 1
+baj 1
+bajbajutottak 1
+bajbajutottakon 1
+bajnokság 1
+bajnokságon 1
+bajnokságot 1
+bajnokságában 1
+bajok 1
+bajtársat 1
+bal-jobb 1
+balesetekben 1
+balesetet 1
+baleseti 1
+balkárok 1
+baloldalon 1
+balszerencsével 1
+bambán 1
+banditák 1
+banditákban 1
+bankra 1
+bankvilág 1
+bankárgeneráció 1
+bariton 1
+baritonistából 1
+baritonjával 1
+baritonrepertoárt 1
+baritonszerep 1
+barokk 1
+baromfi- 1
+baráti 1
+barátja 1
+barátjához 1
+barátom 1
+barátomra 1
+barátsággal 1
+barátunknak 1
+beadta 1
+beavatkozik 1
+beavatkoznak 1
+beavatkoznia 1
+beazonosított 1
+bebizonyosodott 1
+becsúszott 1
+becézett 1
+beengedését 1
+befagyasztott 1
+befagyasztották 1
+befejezendő 1
+befejezetlen 1
+befejezi 1
+befejezni 1
+befejezésében 1
+befejezésére 1
+befejezését 1
+befejeződik 1
+befektetések 1
+befizetése 1
+befogadásával 1
+befolyásolhatja 1
+befolyásolja 1
+befolyásos 1
+befolyásuk 1
+befolyását 1
+befordul 1
+befűtenek 1
+begépelni 1
+behavazott 1
+behozatali 1
+behálózó 1
+beigazolódik 1
+beigazolódtak 1
+beiktatják 1
+beiktatott 1
+beiktatása 1
+bejelentett 1
+bejelentés 1
+bejelentések 1
+bejelentést 1
+bejárás 1
+bejáró 1
+bekövetkezhet 1
+bekövetkezte 1
+bel- 1
+belebonyolódtak 1
+belebámulni 1
+beleegyezett 1
+beleegyezése 1
+belement 1
+belerohant 1
+beleszólni 1
+beleértve 1
+belföldön 1
+belga-holland 1
+belgrádi 1
+belgyógyász 1
+belgyógyász-pszichiátert 1
+belgyógyászati 1
+belpolitika 1
+belpolitikai 1
+belseje 1
+beláthatatlan 1
+belügyminiszter 1
+belőlük 1
+bemenekíteni 1
+bemutatkoznak 1
+bemásznak 1
+benn 1
+bennem 1
+bennfentes 1
+benyomás 1
+benzinkutak 1
+benzinár-emelkedés 1
+beolvasztják 1
+beosztásokba 1
+beragad 1
+berendezéseiben 1
+beruházásaik 1
+beruházási 1
+beruházásnak 1
+beruházástól 1
+beruházók 1
+beszerzett 1
+beszámolt 1
+beszámolói 1
+beszéd 1
+beszédből 1
+beszédhez 1
+beszédtechnikát 1
+beszédét 1
+beszélek 1
+beszélget 1
+beszélgettünk 1
+beszélgetésre 1
+beszélni 1
+besúgók 1
+betegeket 1
+betegellátás 1
+betegségük 1
+betesz 1
+betiltotta 1
+betonfal 1
+betársult 1
+betétdalait 1
+betöltött 1
+betűk 1
+bevallom 1
+bevallotta 1
+bevetésével 1
+bevezetés 1
+bevezetésének 1
+bevezetésével 1
+bevált 1
+bevásárlóközpontok 1
+bevétel 1
+bevételeit 1
+bevételeket 1
+bevételt 1
+bezárni 1
+bezárás 1
+bin 1
+birodalmat 1
+birtokolta 1
+birtokában 1
+bizalmas 1
+bizalmasát 1
+bizalmat 1
+bizalom 1
+bizonytalan 1
+bizonyulnak 1
+bizonyultak 1
+bizonyára 1
+bizonyítania 1
+bizonyítja 1
+bizonyította 1
+bizonyíték 1
+bizottságban 1
+bizottságokat 1
+biztató 1
+biztonságot 1
+biztonságának 1
+biztonságáról 1
+biztonságát 1
+biztosnak 1
+biztosít 1
+biztosítaniuk 1
+biztosította 1
+biztosítottnak 1
+biztosítva 1
+biztosításból 1
+biztosítási 1
+blokád 1
+bojkottálására 1
+boksz 1
+bokszol 1
+bokszolni 1
+boldog 1
+boldoggá 1
+bolgároknál 1
+bolognai 1
+boltját 1
+bomba 1
+bombagólt 1
+boncolás 1
+bontja 1
+bontják 1
+bontás 1
+bonyodalom 1
+bonyolultsága 1
+borult 1
+borzasztó 1
+borászat 1
+borít 1
+boríthatja 1
+borúlátóbbak 1
+bosszút 1
+botrányt 1
+bravúrok 1
+bravúrra 1
+brigádnak 1
+brigádokkal 1
+bronzérmet 1
+buffoszerepeit 1
+bukkantak 1
+bukása 1
+bulikon 1
+busszal 1
+buszközlekedés 1
+buszmegálló 1
+buszokból 1
+by 1
+bácsi 1
+bán 1
+bántalmaztak 1
+bányacég 1
+bányavárosba 1
+bányái 1
+bányásztasson 1
+bánásmód 1
+bánásmódja 1
+bársonyos 1
+bázis 1
+bázisokat 1
+békefenntartók 1
+békésen 1
+bélátfúródása 1
+bénította 1
+bér 1
+bérbe 1
+bére 1
+bérfejlesztés 1
+bérfejlesztése 1
+bérkocsit 1
+bérnövekedést 1
+bértáblát 1
+bérét 1
+bír 1
+bírálat 1
+bírálatból 1
+bírálatözön 1
+bírálni 1
+bíráltak 1
+bírálói 1
+bírósági 1
+bíróságokat 1
+bíznak 1
+bízott 1
+bízták 1
+bók 1
+bölcsőjeként 1
+börzéhez 1
+börzék 1
+búcsút 1
+búza 1
+búzát 1
+büdzsét 1
+büdzsétervekben 1
+büntetlenséget 1
+büntetnek 1
+büntetőeljárás 1
+büntetőjogi 1
+büntetőt 1
+bürokrácia 1
+bőrén 1
+bővítsék 1
+bővítésében 1
+bővül 1
+bővülhetnek 1
+bővülése 1
+bűnbakok 1
+bűnbocsánathoz 1
+bűncselekmények 1
+bűncselekményeket 1
+bűnmegelőzési 1
+bűnösnek 1
+bűnözés 1
+bűnüldözési 1
+bűvös 1
+ceglédi 1
+centis 1
+centralizáció 1
+cenzúrázza 1
+ceremóniára 1
+chaebolcsődöt 1
+chaebolellenes 1
+chaeboljának 1
+chaebolok 1
+cikke 1
+cikket 1
+cikkünket 1
+cimborálna 1
+cipők 1
+cipőkereskedelmi 1
+cirkalmas 1
+cirkáló 1
+civil 1
+civileknek 1
+clausus 1
+combnyaktörést 1
+copyright 1
+családipótlék-folyósító 1
+családnak 1
+családok 1
+családot 1
+családtagjai 1
+családügyi 1
+csalódás 1
+csapata 1
+csapatból 1
+csapatkapitánya 1
+csapatok 1
+csapattal 1
+csapnak 1
+csapott 1
+csatlakozzanak 1
+csatlakozást 1
+csatolnák 1
+csatolt 1
+csatornának 1
+csatár 1
+csatározásokban 1
+cseh-szlovákiai 1
+cseheknél 1
+csekély 1
+cselekedtünk 1
+cselédkönyvezni 1
+cserépkályha 1
+csevegésekre 1
+csigatempóban 1
+csillagszóró 1
+csinálja 1
+csinálják 1
+csinálni 1
+csinált 1
+csoda 1
+csodaketyerék 1
+csodálatos 1
+csodálkoznunk 1
+csomagterv 1
+csomagtervhez 1
+csomópontja 1
+csomópontok 1
+csoportba 1
+csoporthoz 1
+csoportja 1
+csoportjában 1
+csoportját 1
+csoportmérkőzései 1
+csoportnak 1
+csoportok 1
+csoportoknak 1
+csoportokra 1
+csoporttal 1
+csupadísz 1
+csírái 1
+csökkentek 1
+csökkenteni 1
+csökkentené 1
+csökkentik 1
+csökkentése 1
+csökkentésére 1
+csökkentésével 1
+csökkenését 1
+csökkenő 1
+csökkenően 1
+csöndes 1
+csúcsidőben 1
+csúszós 1
+csütörtökre 1
+csőd 1
+csődbe 1
+csődöt 1
+csűrés-csavarásra 1
+cudar 1
+cukorrépa 1
+cáfolta 1
+cár 1
+cégalapító 1
+cégcsoport 1
+cégcsoporthoz 1
+cége 1
+cégeknek 1
+céginformáció 1
+cél 1
+célba 1
+célirányosan 1
+céljuk 1
+céljából 1
+célkitűzéseinek 1
+célkitűzésének 1
+célokra 1
+célozta 1
+célozzák 1
+célpontjai 1
+célt 1
+céltartalékot 1
+célunk 1
+célállomásra 1
+címek 1
+címlapjának 1
+címmeccsét 1
+címoldalán 1
+címért 1
+da 1
+dacára 1
+dalmát 1
+dalszínházban 1
+dalszínháznak 1
+dalénekes 1
+dandártábornok 1
+darabban 1
+darabjai 1
+darabjaiban 1
+darabjaim 1
+darabjában 1
+darabok 1
+darabokat 1
+darabokban 1
+darabot 1
+decembere 1
+decemberében 1
+decentralizált 1
+deficit 1
+dehonesztáló 1
+dekabrista 1
+delegál 1
+della 1
+demokratizálódáshoz 1
+demokrácia 1
+demokráciára 1
+demokráciát 1
+derekán 1
+derül 1
+derűlátás 1
+derűlátásának 1
+destabilizálja 1
+detoxikálókban 1
+di 1
+dideregni 1
+differenciált 1
+digitalizált 1
+diktálnak 1
+dilemmáit 1
+diligyógyász 1
+dinamikusan 1
+dinamikája 1
+dinoszaurusz 1
+diploma 1
+diplomácia 1
+diplomája 1
+diplomák 1
+dirigense 1
+dirigálásával 1
+diszpécserük 1
+diáklétszámra 1
+diákokat 1
+diákoknak 1
+dobni 1
+dobtak 1
+dohány 1
+doktora 1
+doktrína 1
+dokumentumban 1
+dokumentumot 1
+dolgom 1
+dolgot 1
+dolgozhattam 1
+dolgozik 1
+dolgoznak 1
+dolgozni 1
+dolgozom 1
+dolgoztassák 1
+dolgozzon 1
+dolgozói 1
+dolguk 1
+dollárban 1
+dollárral 1
+dolog 1
+domborzata 1
+donorokat 1
+dortmundiként 1
+dr. 1
+drogfogyasztók 1
+drogok 1
+drága 1
+drágulnak 1
+drágulása 1
+drágítja 1
+drámai 1
+dugóban 1
+dugók 1
+duma 1
+dunaföldvári 1
+duplájára 1
+dupláját 1
+durva 1
+durvasága 1
+durvuló 1
+dzsungel 1
+dzsungelkutató 1
+dzsungelt 1
+dzsungelélet 1
+dátum 1
+dátumról 1
+dátumáról 1
+dédelgette 1
+dél-amerikai 1
+dél-szerbiai 1
+délkeleti 1
+délszláv 1
+délután 1
+díjakat 1
+díjamért 1
+díjaz 1
+díjazott 1
+díjátadóként 1
+díszvendég 1
+díszített 1
+díszítik 1
+dízelolajra 1
+dömpingbe 1
+döntenek 1
+dönteniük 1
+döntetlent 1
+dönti 1
+döntése 1
+döntéseikkel 1
+döntéshozó 1
+döntését 1
+döntötték 1
+döntő 1
+döntőnek 1
+dühöt 1
+dőlt 1
+ebbe 1
+edződő 1
+edényben 1
+egekig 1
+egy-két 1
+egybehangzóan 1
+egybekötött 1
+egyebek 1
+egyedisége 1
+egyeduralomra 1
+egyenlített 1
+egyenlítették 1
+egyensúly 1
+egyensúlyban 1
+egyes-egyedül 1
+egyesek 1
+egyeseket 1
+egyesítés 1
+egyesítése 1
+egyesületi 1
+egyesülnek 1
+egyesülésekre 1
+egyetem 1
+egyetemben 1
+egyetemen 1
+egyetemet 1
+egyetemi 1
+egyetért 1
+egyezményt 1
+egyezség 1
+egyezséget 1
+egyfajta 1
+egyforma 1
+egyhamar 1
+egyházfőnek 1
+egyházi 1
+egyházuk 1
+egyidejűleg 1
+egyig 1
+egyikének 1
+egymilliárd 1
+egymásnak 1
+egynapos 1
+egynémelyikében 1
+egyrészt 1
+egyszeri 1
+egyszerűbb 1
+egység 1
+egységek 1
+egységesen 1
+egytől 1
+egyének 1
+egyértelmű 1
+egyévi 1
+egyúttal 1
+együttessel 1
+együttlétek 1
+együttműködni 1
+együttműködési 1
+együttműködésre 1
+együttműködéssel 1
+együttműködést 1
+egzisztenciája 1
+egészségbiztosítási 1
+egészséges 1
+egészségpénztárak 1
+egészségét 1
+egészségügy 1
+egészségügyireformlépéseket 1
+egészét 1
+ejtett 1
+ejtette 1
+ejtőernyőjével 1
+ekkora 1
+eladása 1
+eladási 1
+eladások 1
+eladásra 1
+eladásából 1
+eladó 1
+eladók 1
+eladósodott 1
+eladósodást 1
+elapadt 1
+elbeszélésünk 1
+elbúcsúztassa 1
+elcsigázottan 1
+eldugott 1
+eldönteni 1
+eleganciája 1
+eleget 1
+elejére 1
+elektromos 1
+elektronikai 1
+eleme 1
+elemek 1
+elemekkel 1
+elemzés 1
+elemzése 1
+elemzési 1
+elemében 1
+elengedte 1
+elevenednek 1
+elfelejtettük 1
+elfelejtheti 1
+elfogad 1
+elfogad- 1
+elfogadható 1
+elfogadhatónak 1
+elfogadni 1
+elfoglalt 1
+elfoglaltság 1
+elfoglaltságot 1
+elfoglalták 1
+elfoglalva 1
+elfogott 1
+elfogultak 1
+elfolyik 1
+elfutottak 1
+elgondolt 1
+elhagyták 1
+elhangzottak 1
+elhatározott 1
+elhatározták 1
+elhelyezkedő 1
+elhelyezzék 1
+elhányja 1
+elhíresült 1
+elindulnak 1
+elindult 1
+elismerik 1
+elismerésemért 1
+elismerésére 1
+elismerését 1
+elisztai 1
+eljutni 1
+eljutottunk 1
+eljuttatja 1
+eljuttatni 1
+eljárása 1
+elkendőzésében 1
+elkendőzésével 1
+elkeresztelt 1
+elkerülje 1
+elkeseredés 1
+elképzelhetőnek 1
+elképzelés 1
+elképzelései 1
+elképzelések 1
+elképzeléseket 1
+elképzelését 1
+elkötelezettségét 1
+elkövetkezendő 1
+elküldte 1
+ellenben 1
+ellenség 1
+ellenségének 1
+ellentétekben 1
+ellentétes 1
+ellenőrzése 1
+ellenőrzött 1
+ellátnia 1
+ellátogasson 1
+elláttam 1
+ellátás 1
+ellátások 1
+elmaradás 1
+elmegy 1
+elmenekült 1
+elmesélnek 1
+elmondja 1
+elmondottakra 1
+elmondták 1
+elmozdítani 1
+elméletet 1
+elméleti 1
+elnagyolt 1
+elnapolt 1
+elnapolta 1
+elnevezett 1
+elnevezésű 1
+elnyerése 1
+elnémítására 1
+elnézése 1
+elnézést 1
+elnök-vezérigazgatója 1
+elnökjelölt 1
+elnökké 1
+elnöklő 1
+elnökség 1
+elnökválasztáson 1
+elnökválasztást 1
+elnökéhez 1
+elnökévé 1
+elodázó 1
+eloltották 1
+elolvad 1
+elosztanák 1
+elosztás 1
+elosztási 1
+elosztására 1
+elrablásával 1
+elsejei 1
+elszakadni 1
+elszakadással 1
+elszenvedni 1
+elszigeteltség 1
+elszigeteléséhez 1
+elszállításához 1
+elszállítását 1
+elszármazott 1
+elsül 1
+elsülhet 1
+elsőként 1
+elsőszámú 1
+elteltével 1
+elterjedése 1
+eltiltással 1
+eltérése 1
+eltökéltségnek 1
+eltörlik 1
+eltörléséről 1
+eltörlését 1
+eltüntette 1
+eltüntették 1
+eluntam 1
+elutasított 1
+elvben 1
+elvesztette 1
+elvetették 1
+elvileg 1
+elviselése 1
+elvitték 1
+elvonták 1
+elvonásai 1
+elvtárs 1
+elvtársi 1
+elválassza 1
+elválasztófal 1
+elválik 1
+elvárás 1
+elvárásai 1
+elvárásoknak 1
+elvégzett 1
+elzavarták 1
+elzárják 1
+elzárt 1
+elzártaknak 1
+elágazás 1
+elárulta 1
+elégedetlenebbek 1
+elégedetlenebbül 1
+elégedetlenséget 1
+elégedettebbek 1
+elégséges 1
+elégtelen 1
+elénekelte 1
+elért 1
+elérzékenyülten 1
+elüldözik 1
+előadni 1
+előadásra 1
+előadással 1
+előadásunkkal 1
+előadójának 1
+előadók 1
+előbb-utóbb 1
+előbbibe 1
+előbbiek 1
+elődjével 1
+elődök 1
+előfeltevése 1
+előfordulhat 1
+előirányzatokhoz 1
+előkészítettek 1
+előkészítettnek 1
+előkészítéséből 1
+előnye 1
+előnyeit 1
+előnyös 1
+előprivatizáció 1
+előrejelzéseik 1
+előszeretettel 1
+előszerződés 1
+előterjesztett 1
+előterjesztését 1
+elővárosi 1
+előzetesen 1
+előzménye 1
+előírni 1
+előírnának 1
+előírt 1
+előírta 1
+előírás 1
+előírásaival 1
+előírások 1
+előítéletek 1
+elűzését 1
+embereit 1
+embereket 1
+embergyerek 1
+emberiség 1
+emberiséget 1
+emberrel 1
+emberére 1
+emberünk 1
+emelhesse 1
+emelkedni 1
+emelkedése 1
+emelkedésével 1
+emelt 1
+emelték 1
+emelés 1
+emelésével 1
+emlékeik 1
+emlékezet 1
+emlékezni 1
+emlékezve 1
+emlékműként 1
+emlékszem 1
+említett 1
+említést 1
+energia 1
+energiahordozók 1
+energiahordozókért 1
+energiaszektorban 1
+energiaáramlásban 1
+energikusak 1
+engedett 1
+engedik 1
+engedményekre 1
+engedve 1
+engedélyt 1
+engedésének 1
+ennyien 1
+ennyire 1
+enyhíteni 1
+enyhítő 1
+enyhült 1
+eozin-mázzal 1
+epicentruma 1
+eredetileg 1
+eredményei 1
+eredményekhez 1
+eredményes 1
+eredményez 1
+eredményének 1
+eredményük 1
+erejét 1
+erejű 1
+erkölcs 1
+erőfeszítéseit 1
+erőfeszítésekben 1
+erői 1
+erőik 1
+erőltetése 1
+erősen 1
+erőssége 1
+erőszak 1
+erőszakkal 1
+erőszakos 1
+erősített 1
+erősítsék 1
+erősítése 1
+erősítő 1
+erőt 1
+erőteljesen 1
+erőtlen 1
+erővel 1
+esedékes 1
+esetekben 1
+esetre 1
+esettanulmányok 1
+esetén 1
+esetére 1
+esetükben 1
+esnek 1
+esten 1
+estje 1
+estés 1
+eszközének 1
+eszközök 1
+eszközöket 1
+eszmecsere 1
+eszmecserét 1
+esztendeje 1
+esztendős 1
+esztendővel 1
+esély 1
+esélyét 1
+etnikuma 1
+etnozenét 1
+etnóhoz 1
+ettől 1
+euró 1
+eurót 1
+euróért 1
+exkormányfő 1
+exkormányfőt 1
+exportilletéket 1
+exportját 1
+exportjával 1
+exportőröknek 1
+ezekből 1
+ezeken 1
+ezekkel 1
+ezekre 1
+ezerrel 1
+ezredes 1
+ezren 1
+ezres 1
+ezáltal 1
+ezüstérmesének 1
+fa 1
+fagyos 1
+fagyott 1
+faj 1
+fajjal 1
+fajta 1
+fajult 1
+fakadtak 1
+fakadóan 1
+fala 1
+falat 1
+falatot 1
+fallal 1
+falu 1
+faluból 1
+falvak 1
+fan 1
+fantasztikus 1
+fantommá 1
+fantázia 1
+farmert 1
+februárjában 1
+februárjától 1
+fedezi 1
+fedezni 1
+fedezésére 1
+fedte 1
+fedélzeten 1
+fedőnéven 1
+fegyelmező 1
+fegyházbüntetésre 1
+fegyveres 1
+fegyvereseknek 1
+fegyverraktárokat 1
+fegyvert 1
+fehér 1
+fejezi 1
+fejeznék 1
+fejezte 1
+fejeztük 1
+fejeződne 1
+fejeződtek 1
+fejjel 1
+fejlesztése 1
+fejlesztéseit 1
+fejlesztések 1
+fejlesztésekben 1
+fejlesztéseket 1
+fejlesztését 1
+fejlett 1
+fejlődjön 1
+fejlődésének 1
+fejlődött 1
+fejtette 1
+fejére 1
+fekete 1
+feketegazdaság 1
+feketelevest 1
+feladata 1
+feladatait 1
+feladatellátáshoz 1
+feladatokat 1
+feladatot 1
+feldarabolása 1
+feldarabolására 1
+feldolgozóipar 1
+feldolgozók 1
+feldolgozókkal 1
+feldolgozóknak 1
+feldühödött 1
+feledést 1
+felejtsd 1
+felek 1
+felelt 1
+felelősek 1
+felelőssége 1
+felelősséget 1
+felelősségre 1
+felemelése 1
+felemás 1
+felengedjen 1
+felesége 1
+felfelé 1
+felfigyelnek 1
+felfogható 1
+felfogással 1
+felfüggesztette 1
+felgyorsulhatnak 1
+felhajtotta 1
+felhasználható 1
+felhasználják 1
+felhasznált 1
+felháborodott 1
+felhívja 1
+felhívott 1
+felhúzása 1
+felidézésével 1
+feljelentettjeit 1
+feljelentését 1
+felkelés 1
+felkiáltójelként 1
+felkérte 1
+felkérést 1
+felkérését 1
+felkészült 1
+felkínált 1
+fellebbezést 1
+fellelhető 1
+fellendült 1
+fellendülést 1
+fellendülésének 1
+fellépésre 1
+fellépéséről 1
+felmehet 1
+felmentette 1
+felmerülnek 1
+felmérhetik 1
+felnőttet 1
+felnőttkorunk 1
+feloldanák 1
+feloldódást 1
+feloszlatását 1
+felosztásával 1
+felsorakoztatni 1
+felsorolták 1
+felszolgálták 1
+felszállását 1
+felszámolása 1
+felszámolását 1
+felszínre 1
+felszólalásokban 1
+felszólított 1
+felszólította 1
+felszólításnak 1
+felsőház 1
+feltehető 1
+feltehetőleg 1
+felturbózott 1
+feltétel 1
+feltételeit 1
+feltételezik 1
+feltételezné 1
+feltételezések 1
+feltételként 1
+feltöltéséhez 1
+feltöltődtek 1
+feltűnően 1
+felvilágosodás 1
+felváltaniuk 1
+felváltó 1
+felvásárlásokra 1
+felvásárlásával 1
+felvételeknek 1
+felvételre 1
+feláll 1
+felélednek 1
+felére 1
+felét 1
+felírták 1
+felívelését 1
+felújított 1
+felújítás 1
+felügyelet 1
+felügyeleti 1
+felügyelőbizottság 1
+felül 1
+felületes 1
+felülíratásával 1
+fennakadásokat 1
+fennakadásra 1
+fenntartani 1
+fenntartja 1
+fenntartsa 1
+fenntartása 1
+fenntartásai 1
+fenntartásait 1
+fennállnak 1
+fennállt 1
+fenyegette 1
+fenyegették 1
+fenyegető 1
+fenyőfák 1
+fertőzöttek 1
+festmény- 1
+festmények 1
+fesztiválok 1
+feszít 1
+feszültebbé 1
+feszültségek 1
+feszültséget 1
+feszültséggóccal 1
+fiam 1
+fiatalabb 1
+fiatalember 1
+fiatalembert 1
+figura 1
+figurája 1
+figyelmeztettek 1
+figyelmeztetés 1
+figyelmünk 1
+filmadagot 1
+filmben 1
+filmet 1
+filmjének 1
+filmszemlén 1
+filmvásznakról 1
+filozófiákra 1
+filozófus 1
+finanszírozott 1
+finanszírozás 1
+finanszírozásban 1
+finanszírozási 1
+finoman 1
+finomsága 1
+finomságok 1
+finomítóban 1
+finomítója 1
+finomítók 1
+fináléjával 1
+fiskális 1
+fizessék 1
+fizet 1
+fizetik 1
+fizetni 1
+fizetésemelés 1
+fizetési 1
+fizetésképtelenné 1
+fizetésképtelenség 1
+fizetéssel 1
+fizetésének 1
+fiára 1
+fiúgyermeke 1
+fogadja 1
+fogadnia 1
+fogadott 1
+fogadtatott 1
+fogadták 1
+fogadócsoportban 1
+fogadószöveg 1
+fogalmazzon 1
+fogalmát 1
+foglalkozik 1
+foglalkozom 1
+foglalkoztam 1
+foglalkoztatottak 1
+foglalkoztatottságot 1
+foglalkoztatta 1
+foglalkoztatás 1
+foglalkoztatáshoz 1
+foglalkoztató 1
+foglalt 1
+foglaltakat 1
+foglaltaknak 1
+fogságából 1
+fogtak 1
+fogyaszt 1
+fogyaszthatja 1
+fogyasztott 1
+fogyasztóiár-változásra 1
+fogyasztókhoz 1
+fogyatékosságuk 1
+fogyott 1
+fokozott 1
+fokozása 1
+fokozásához 1
+folyamat 1
+folyamatok 1
+folyamatokba 1
+folyamatokkal 1
+folyamán 1
+folyhat 1
+folyik 1
+folyt 1
+folytassa 1
+folytassák 1
+folytathatta 1
+folytatják 1
+folytatnak 1
+folytatás 1
+folytatásaként 1
+folytatására 1
+folytatását 1
+folytatódjék 1
+folyton 1
+fontolóra 1
+fonémák 1
+fonódva 1
+fordulat 1
+fordulatot 1
+fordulok 1
+fordult 1
+fordulóban 1
+fordulójában 1
+fordulóponthoz 1
+fordulós 1
+fordulót 1
+fordítani 1
+fordítania 1
+fordítható 1
+fordítottak 1
+forgalma 1
+forgalmuk 1
+forgatta 1
+forgatások 1
+forgó 1
+forintnál 1
+forintról 1
+forintért 1
+formagazdagsága 1
+formaságokhoz 1
+formáinak 1
+formája 1
+formájában 1
+formáját 1
+formák 1
+formálisan 1
+formálódott 1
+formát 1
+forradalom 1
+forrása 1
+forró 1
+fortélyát 1
+fosztotta 1
+fotográfusnak 1
+fotó 1
+fotók 1
+fotókra 1
+fotón 1
+fotós 1
+fotózta 1
+frakcióján 1
+frakciójának 1
+frakciók 1
+frakcióvezető-helyettese 1
+frankfurti 1
+frontról 1
+frázisok 1
+fukar 1
+funkcionál 1
+futamidejű 1
+futóművet 1
+fuvarozókat 1
+fából 1
+fájdalmas 1
+fájdalmasra 1
+fájlalja 1
+fáradtság 1
+fázik 1
+fékberendezéseket 1
+féken 1
+féktelenebb 1
+félelmet 1
+félig 1
+félmilliárd 1
+félpályánál 1
+félreértenék 1
+félreértés 1
+félreértéseket 1
+félévi 1
+félévre 1
+félóránként 1
+félórás 1
+fémjelzett 1
+fényes 1
+fényképeket 1
+férfi 1
+férfi-énekszextettől 1
+férfiak 1
+férfiaknál 1
+férfias 1
+férfiimitátor 1
+férfire 1
+férfiúi 1
+férhet 1
+férjének 1
+férne 1
+férőhelyeit 1
+fókuszáljon 1
+fórumon 1
+fórumra 1
+föl 1
+földgáz 1
+földgázt 1
+földgáztermelésének 1
+földmozgás 1
+földrengéstől 1
+fölvetőknek 1
+fölénye 1
+fölötte 1
+fölötti 1
+fönt 1
+főadószedő 1
+főből 1
+főgonoszt 1
+főhadiszállásra 1
+főhivatal 1
+főhálózat 1
+főkatona 1
+főleg 1
+főműsoridőben 1
+főnemesek 1
+főnél 1
+főnöki 1
+főnökét 1
+főosztályvezető-helyettese 1
+főpolgármester 1
+főpolgármesterével 1
+főre 1
+fősre 1
+főszemlélői 1
+főszerepet 1
+főszereplői 1
+főszereplője 1
+főszerkesztője 1
+főtiszt 1
+főtitkára 1
+főutakon 1
+főváros-kormány 1
+fővárosba 1
+fővároshoz 1
+fővárosnak 1
+fővárosában 1
+főállamügyésznek 1
+főútvonalakon 1
+főügyész 1
+fűtőolaj-szállítmány 1
+fűtőolaj-szállítmányból 1
+fűtőolajat 1
+fűzik 1
+fűződik 1
+fűződött 1
+gabonatanács 1
+galériája 1
+garanciavállalása 1
+garanciát 1
+garantáltan 1
+gazdaságba 1
+gazdaságkutatók 1
+gazdaságunkra 1
+gazdaságában 1
+gazdáiról 1
+gazdálkodni 1
+gazdálkodniuk 1
+gazdálkodása 1
+gazdálkodó 1
+gerillavezérek 1
+gerjeszti 1
+gigantikus 1
+gipszminta 1
+giusto 1
+globalizáció 1
+globalizációról 1
+globalizált 1
+gnosztikusok 1
+gondja 1
+gondjait 1
+gondolataimat 1
+gondolkodásra 1
+gondolkodói 1
+gondolok 1
+gondoltam 1
+gondosságáról 1
+gondot 1
+gondozásában 1
+gonosz 1
+gorillacsaládban 1
+grafikái 1
+gróf 1
+grúzok 1
+gumival 1
+gyakoribb 1
+gyakorlata 1
+gyakorlati 1
+gyakorlatok 1
+gyakorlatokra 1
+gyakorlórepüléseket 1
+gyakorolhatják 1
+gyakoroltak 1
+gyakrabban 1
+gyanú 1
+gyanús 1
+gyanúsít 1
+gyanútlanul 1
+gyarapítja 1
+gyarapította 1
+gyed 1
+gyengéjét 1
+gyengélkedő 1
+gyengének 1
+gyerek 1
+gyerekeket 1
+gyerekekkel 1
+gyermekkorunk 1
+gyermekvédelmi 1
+gyertyaláng 1
+gyertyákat 1
+gyertyákkal 1
+gyertyát 1
+gyorsabban 1
+gyorsforgalmi 1
+gyorsvasút 1
+gyorsvasúttá 1
+gyorsvillamossal 1
+gyárak 1
+gyárakhoz 1
+gyárban 1
+gyárból 1
+gyártó 1
+gyártók 1
+gyógyszerhiány 1
+gyógyszermérgezetteket 1
+gyógyíthatatlan 1
+gyógyított 1
+gyökeres 1
+gyönyörű 1
+gyönyörűséges 1
+gyülekezést 1
+győzni 1
+győzte 1
+gyűjteményéből 1
+gyűjteményének 1
+gyűjthetnek 1
+gyűjtők 1
+gála 1
+gálán 1
+gánti 1
+gárda 1
+gárdához 1
+gátja 1
+gáz 1
+gázkondenzátumot 1
+gázolaj 1
+gáztársaság 1
+gép 1
+gépei 1
+gépek 1
+gépi 1
+gépipari 1
+gépkocsiba 1
+gépkocsivezetőjét 1
+gépkocsivezetőről 1
+gépkocsiáradat 1
+gépészmérnököket 1
+gól 1
+góllal 1
+gőzmozdonyok 1
+habár 1
+hadi 1
+hadiipari 1
+hadműveleteket 1
+hadosztályparancsnok 1
+hadsereggel 1
+hadseregnek 1
+hadseregének 1
+hadvezetés 1
+hadállását 1
+hadúrnak 1
+hagyniuk 1
+hagyná 1
+hagyománnyá 1
+hagyomány 1
+hagyományokhoz 1
+hagyományos 1
+hagyományosan 1
+hagyományteremtő 1
+hagyó 1
+hajdani 1
+hajlandósággal 1
+hajléktalanról 1
+hajrában 1
+hajtogatják 1
+hajtották 1
+hajtsák 1
+hajtva 1
+hajtóanyag 1
+halad 1
+haladja 1
+haladjon 1
+haladt 1
+haladva 1
+halasztott 1
+halasztó 1
+hallatlanul 1
+hallatott 1
+hallatán 1
+hallgathatóbb 1
+hallgatok 1
+hallgatóknak 1
+halmaza 1
+halmozott 1
+halmoztak 1
+halott 1
+haltak 1
+halálesetekre 1
+halálraítélt 1
+haláláig 1
+halálának 1
+hamar 1
+hamisnak 1
+hamissá 1
+hangjegyre 1
+hangjával 1
+hangos 1
+hangosan 1
+hangot 1
+hangoztatott 1
+hangoztatta 1
+hangoztatva 1
+hangszereket 1
+hangvételűek 1
+hangzanak 1
+hangzik 1
+harag 1
+haragja 1
+haragvó 1
+harca 1
+harcban 1
+harcnak 1
+harcok 1
+hard 1
+harmada 1
+harmincperces 1
+harmonikus 1
+hashártyagyulladást 1
+hasonlítható 1
+hasonlóságát 1
+hasson 1
+hasznosítják 1
+hasznot 1
+használata 1
+használhatatlansága 1
+használja 1
+használta 1
+használták 1
+haszonélvezői 1
+hatalmasságaival 1
+hatalmi 1
+hatalmukkal 1
+hatalomba 1
+hatalomra 1
+hatszorosa 1
+hatállyal 1
+hatálybalépéstől 1
+hatályon 1
+határa 1
+határain 1
+határait 1
+határideje 1
+határozata 1
+határozathoz 1
+határozottsága 1
+határoztak 1
+határozzák 1
+határszakasz 1
+határállomások 1
+határára 1
+határátkelőhelyek 1
+határátlépők 1
+határőrizeti 1
+határőrségi 1
+hatása 1
+hatásairól 1
+hatáskörében 1
+hatásköréről 1
+hatáskörök 1
+hatását 1
+hatékonyabb 1
+hatósági 1
+hatóságokat 1
+hatóságokkal 1
+hatóságoknak 1
+hatóságokra 1
+havas 1
+havat 1
+havazások 1
+hazahozatalára 1
+hazahívják 1
+hazajött 1
+hazatér 1
+hazatért 1
+hazautalásainak 1
+hazavezényelték 1
+hazugságon 1
+hegyei 1
+hegyi 1
+helikoptereikkel 1
+helyettese 1
+helyettük 1
+helyeztetik 1
+helyieknek 1
+helyileg 1
+helyiséget 1
+helyre 1
+helyreállítani 1
+helyreállítják 1
+helyreállítás 1
+helyreállítása 1
+helyszínen 1
+helyszíni 1
+helytelen 1
+helytállásban 1
+helyzetbe 1
+helyzetekben 1
+helyzetet 1
+helyzethez 1
+helyzeti 1
+helyzetről 1
+helyzetét 1
+helyén 1
+helyükön 1
+helyütt 1
+hengergetik 1
+hete 1
+heteken 1
+hetem 1
+hetilap 1
+hetilapja 1
+hetében 1
+hevesen 1
+hibából 1
+hibája 1
+hibátlanul 1
+hibázott 1
+hidak 1
+hidakon 1
+hidat 1
+hideg 1
+hidegháború 1
+hidegháborús 1
+hidegvére 1
+hihetetlenül 1
+hipnózisban 1
+hirdeti 1
+hirdettek 1
+hirdették 1
+hirdető 1
+hiszek 1
+hiszem 1
+hitelcsomagot 1
+hiteleit 1
+hitelező 1
+hitelezői 1
+hitelezője 1
+hitelkeretről 1
+hitelképtelensége 1
+hitelt 1
+hivatalban 1
+hivatallal 1
+hivatalnokok 1
+hivatalosan 1
+hivataltól 1
+hivatkoznak 1
+hivatott 1
+hiábavaló 1
+hiányai 1
+hiánynak 1
+hiányt 1
+hiányzó 1
+hiányérzetem 1
+hoc 1
+hogyha 1
+hollandok 1
+hollandokat 1
+holnap 1
+holttestet 1
+holttestre 1
+homokját 1
+homoszexuálisokat 1
+honvédelem 1
+honvédelmi 1
+hordoz 1
+hordták 1
+hordónként 1
+hosszan 1
+hosszas 1
+hoz 1
+hozhat 1
+hozni 1
+hozná 1
+hoznának 1
+hozták 1
+hozza 1
+hozzon 1
+hozzájuk 1
+hozzájárulhat 1
+hozzájárult 1
+hozzáláttak 1
+hozzányúlni 1
+hozzásegített 1
+hozzászokhattak 1
+hozzátéve 1
+hozzávetőleg 1
+hull 1
+hullám 1
+hullámot 1
+humor 1
+huszonkét 1
+huszonöt 1
+háborúban 1
+háborúról 1
+háborús 1
+hágai 1
+hágókat 1
+hál 1
+hálájuk 1
+hálásak 1
+háló 1
+hálós 1
+hálózatok 1
+hálózatán 1
+hálózatának 1
+hány 1
+hármas 1
+háromféleképp 1
+háromszázalékos 1
+hároméves 1
+hárítani 1
+hárítja 1
+hát 1
+hátgerincsérülés 1
+hátra 1
+hátralévő 1
+hátrányból 1
+hátteret 1
+háttérmagazinjának 1
+ház 1
+házhoz 1
+háziorvosok 1
+háztartások 1
+háztetőn 1
+házát 1
+házától 1
+hérosza 1
+hétfői 1
+hétre 1
+héttagú 1
+hétvégékre 1
+híd 1
+hídig 1
+hír 1
+híreket 1
+hírességei 1
+híresztelésekkel 1
+hírhedten 1
+hírigazgatója 1
+hírműsorok 1
+hírosztályának 1
+hírszerzésnek 1
+hírügynökség 1
+hírül 1
+híve 1
+hívni 1
+hívott 1
+hívásokat 1
+hívást 1
+hóakadályok 1
+hóba 1
+hóban 1
+hóbuckákból 1
+hócsapdába 1
+hófogó 1
+hófúvás 1
+hófúvások 1
+hólánc 1
+hólánccal 1
+hómaró 1
+hómarógépei 1
+hómentesítésre 1
+hónapja 1
+hónapjaira 1
+hónapokkal 1
+hónapon 1
+hónapra 1
+hótakarót 1
+hótorlasz 1
+hótorlaszokon 1
+hóval 1
+hóvihar 1
+hózuhatag 1
+hús- 1
+húsipar 1
+húsipari 1
+húsz 1
+húszas 1
+húszezren 1
+húznak 1
+húzná 1
+húztak 1
+húzza 1
+hőfokon 1
+hősök 1
+hősünkből 1
+hősünket 1
+hűtőipar 1
+ice 1
+ide 1
+ide-oda 1
+idegen 1
+idegrendszerét 1
+idegállapotának 1
+idejében 1
+idejét 1
+identitásának 1
+ideák 1
+idilli 1
+idénynek 1
+idézi 1
+idézte 1
+időhúzásra 1
+időjárása 1
+időjárást 1
+időközben 1
+időlegesen 1
+időpontjáról 1
+időpontját 1
+időről 1
+időről-időre 1
+időszakát 1
+időszerű 1
+idővel 1
+ifj. 1
+ifjú 1
+ifjúsági 1
+ifjút 1
+igazgató 1
+igazgatójának 1
+igazgatóját 1
+igazgatón 1
+igazgatóságát 1
+igazgatótanácsban 1
+igazgatótanácsi 1
+igazgatótanácsába 1
+igazolni 1
+igazolást 1
+igazságosság 1
+igazságszolgáltatás 1
+igazuk 1
+igazából 1
+igazítani 1
+igazítják 1
+igazítva 1
+igenis 1
+igent 1
+igyekezhet 1
+igyekeztek 1
+igény 1
+igénybe 1
+igénye 1
+igényeit 1
+igények 1
+igényel 1
+igényelnek 1
+igénylő 1
+ijesztgette 1
+illek 1
+illem 1
+illene 1
+illeti 1
+illetményalapot 1
+illetni 1
+illetékesei 1
+illetőleg 1
+illően 1
+ily 1
+ilyeneket 1
+immunbetegség 1
+import 1
+import-szeszesital 1
+imádják 1
+incidens 1
+index 1
+individualistább 1
+individuum 1
+indoklásában 1
+indokolják 1
+indokolták 1
+indulatok 1
+indulatokat 1
+indulás 1
+indítanak 1
+indított 1
+indította 1
+indítottak 1
+indítványozta 1
+indítványt 1
+inflációhoz 1
+inflációkiegyenlítésben 1
+inflációtól 1
+informatikusokat 1
+információ 1
+információszolgáltatást 1
+információért 1
+infrastrukturális 1
+infrastruktúrája 1
+ingadozásai 1
+ingatlan 1
+ingatlanadó 1
+ingatlanvagyonának 1
+ingerült 1
+ingus 1
+ingyenes 1
+ingyenesen 1
+ingázók 1
+innia 1
+integrálása 1
+intellektus 1
+interjú 1
+interjújában 1
+intermodális 1
+intervallum 1
+intézett 1
+intézik 1
+intézkedések 1
+intézkedéseket 1
+intézkedési 1
+intézkedéssorozat 1
+intézkedést 1
+intézmény 1
+intézményben 1
+intézményeket 1
+intézményrendszer 1
+intézményrendszere 1
+ipar 1
+iparágat 1
+iparűzési 1
+irdatlan 1
+irgalmazzon 1
+irigy 1
+iroda 1
+irodát 1
+irtózom 1
+iránta 1
+irányelvek 1
+irányoz 1
+irányul 1
+irányuló 1
+irányítja 1
+irányított 1
+irányítás 1
+irányítói 1
+irányú 1
+irónia 1
+iskolaérett 1
+iskolába 1
+iskoláskorú 1
+ismeretes 1
+ismeretlenségre 1
+ismerhetik 1
+ismerkedtem 1
+ismerte 1
+ismertette 1
+ismertté 1
+ismerve 1
+ismételni 1
+ismételt 1
+isten 1
+iszlám 1
+iszlámbarát 1
+iszlámisták 1
+iszogatnak 1
+itthoni 1
+itáliai 1
+izgalmas 1
+izmiti 1
+izraeliek 1
+januárban 1
+januárjában 1
+javaslatokat 1
+javasol 1
+javasolja 1
+javasolta 1
+javult 1
+javulásának 1
+javában 1
+jegybanki 1
+jegybankja 1
+jegyzettel 1
+jegyzi 1
+jegyzékben 1
+jegyéért 1
+jel 1
+jelek 1
+jelenben 1
+jelenik 1
+jelenlétre 1
+jelenlétében 1
+jelensége 1
+jelentene 1
+jelentenek 1
+jelentenének 1
+jelentet 1
+jelenthet 1
+jelentik 1
+jelentkezhetnek 1
+jelentkeztek 1
+jelentkező 1
+jelentkezőt 1
+jelentéseiben 1
+jelentéseket 1
+jelentésében 1
+jelentésének 1
+jelentésére 1
+jelentésüket 1
+jelentő 1
+jelentőségének 1
+jelené 1
+jelképes 1
+jelleggel 1
+jellemezte 1
+jellemezték 1
+jellemzőivel 1
+jelzőnek 1
+jelzőt 1
+jelöltje 1
+jelöltjei 1
+jobbik 1
+jobbközép 1
+jobbnak 1
+jog 1
+jogaikat 1
+jogerősen 1
+jogokat 1
+jogon 1
+jogosult 1
+jogosultságát 1
+jogosító 1
+jogrendszerrel 1
+jogszabály 1
+jogvédő 1
+jogán 1
+jogásza 1
+jogászi 1
+jubileumi 1
+judaika-árverés 1
+judaisztika 1
+jugoszláviai 1
+juhokat 1
+juhászkutyák 1
+jussanak 1
+jutalmaznak 1
+juthat 1
+juthattak 1
+jutni 1
+juttassanak 1
+juttatta 1
+juttattak 1
+juttatásaik 1
+jutó 1
+járandóság 1
+járatai 1
+járhatóvá 1
+járműhöz 1
+járműpark 1
+járműveiket 1
+járművek 1
+járművével 1
+járni 1
+járta 1
+járulnak 1
+járását 1
+járőrre 1
+járőrözik 1
+játssza 1
+játszanak 1
+játszani 1
+játszanunk 1
+játszhattam 1
+játszhattunk 1
+játszmát 1
+játszottak 1
+játszottunk 1
+játszották 1
+játéknap 1
+játékosaira 1
+játékosokat 1
+játékostársának 1
+játékszenvedélyemből 1
+játékvezető 1
+játékvezetőn 1
+játékában 1
+jók 1
+jókedvű 1
+jókívánságok 1
+jóslata 1
+jósolnak 1
+jóvá 1
+jóváhagyásra 1
+jön 1
+jönne 1
+jövedelemcentralizáció 1
+jövedelemkiegészítési 1
+jövedelempótló 1
+jövedelmek 1
+jövedelmeket 1
+jövedelmekre 1
+jövőképhez 1
+júliusi 1
+kabardok 1
+kabinetfőnöke 1
+kaland 1
+kalandjai 1
+kalandok 1
+kalandos 1
+kamara 1
+kamaraegyüttes 1
+kamatadóra 1
+kamatfizetésre 1
+kamatpolitika 1
+kamattámogatás 1
+kamattámogatást 1
+kamerahasználat 1
+kamerákra 1
+kamion 1
+kamionokra 1
+kampánya 1
+kampányfogásként 1
+kampányolnia 1
+kampányának 1
+kanadai 1
+kancellár 1
+kancellárja 1
+kancellárjának 1
+kancellárénál 1
+kandalló 1
+kandallók 1
+kantonizálását 1
+kantonoknak 1
+kantonokra 1
+kantonra 1
+kaotikus 1
+kapacitásaikat 1
+kapcsolat 1
+kapcsolatait 1
+kapcsolatba 1
+kapcsolatok 1
+kapcsolatokat 1
+kapcsolatokban 1
+kapcsolatokról 1
+kapcsolatát 1
+kapcsolja 1
+kapcsolódó 1
+kapitalizációja 1
+kapjon 1
+kapni 1
+kapu 1
+kapusa 1
+kapusedzőnek 1
+kar 1
+karacsáj-cserkesz 1
+karacsájokkal 1
+karacsájoknak 1
+karakterisztikus 1
+karambolt 1
+karitatív 1
+karon 1
+karrier 1
+karrieristák 1
+karácsonyfák 1
+karácsonyi 1
+katalógusból 1
+katasztrófaelhárítási 1
+katasztrófát 1
+kategóriájú 1
+katona 1
+katonatiszt 1
+katonát 1
+kaukázusi 1
+kavart 1
+kedvelem 1
+kedvelt 1
+kedves 1
+kedvez 1
+kedvezményes 1
+kedvezményezett 1
+kedvezőbb 1
+kedvezőbben 1
+kedvezőek 1
+kedvezőtlen 1
+kedvezőtlenül 1
+kedvéért 1
+kefir 1
+kegyetlenkedéseiről 1
+kegytárgy- 1
+kelet-európai 1
+keletkezhetnek 1
+keletkeznek 1
+keletnémetek 1
+kelt 1
+keltették 1
+kemény 1
+kenyeret 1
+kerekedett 1
+keresetemelkedés 1
+keresetkiegészítés 1
+kereshettem 1
+kereskedelmét 1
+kereskedés 1
+kereskedő 1
+keresleti 1
+keresletre 1
+keresnek 1
+keressük 1
+keresztbe 1
+keresztelkedjen 1
+kereszténydemokrata 1
+keresztül-kasul 1
+kereső 1
+keretek 1
+kereteken 1
+keretlegények 1
+keretén 1
+keréknyomokból 1
+kerített 1
+kerítések 1
+kerületekből 1
+kerülhetett 1
+kerülni 1
+kerülnének 1
+kerülök 1
+kerülővel 1
+kettéválása 1
+kettéválását 1
+keveréke 1
+keveset 1
+kezdeményezett 1
+kezdeményezheti 1
+kezdeményezés 1
+kezdeni 1
+kezdetben 1
+kezdetnek 1
+kezdhette 1
+kezdtek 1
+kezdtem 1
+kezdési 1
+kezdődik 1
+kezdődne 1
+kezdődnek 1
+kezelheti 1
+kezelik 1
+kezelte 1
+kezelték 1
+kezelés 1
+kezelésére 1
+kezelésével 1
+kezelő 1
+kezelői 1
+kezelőjük 1
+kezem 1
+kezességet 1
+kezességvállalás 1
+kezességvállalást 1
+kezet 1
+kezéhez 1
+kezén 1
+kft 1
+kht. 1
+ki- 1
+kiadni 1
+kiadványa 1
+kiadványban 1
+kiadása 1
+kiadásai 1
+kiadásokat 1
+kiadásunk 1
+kiadásában 1
+kiadó 1
+kiagyalói 1
+kialakulni 1
+kialakulásához 1
+kialakításához 1
+kialakítására 1
+kibocsátásához 1
+kibogarászniuk 1
+kicsempészni 1
+kicserélték 1
+kicsit 1
+kiderül 1
+kidolgozatlan 1
+kidolgozása 1
+kidolgozói 1
+kiegyenlítése 1
+kiegészülve 1
+kiejteni 1
+kiejtésért 1
+kielégíteni 1
+kiemelt 1
+kiemelten 1
+kiemeltnek 1
+kiemelték 1
+kiesése 1
+kifejezetten 1
+kifejtette 1
+kifejtették 1
+kifejtésére 1
+kifelé 1
+kifizetetlen 1
+kifizetnie 1
+kifogyhatatlan 1
+kifogásolják 1
+kifogásolt 1
+kifogásolták 1
+kifogással 1
+kifosztania 1
+kifutópályáját 1
+kihalt 1
+kihasználni 1
+kihasználnák 1
+kihasználtsága 1
+kihasználva 1
+kihelyezéseinek 1
+kihirdetni 1
+kiindulási 1
+kiizzadni 1
+kijelölte 1
+kijutott 1
+kijönni 1
+kik 1
+kikapcsolni 1
+kikezdték 1
+kikényszerítse 1
+kiköltöztették 1
+kikövetelje 1
+kilencven 1
+kilométerre 1
+kilométerrel 1
+kilábalni 1
+kilábalásnak 1
+kilábaló 1
+kilátásaikat 1
+kilétüket 1
+kilós 1
+kimaradtak 1
+kimegy 1
+kimenekíteni 1
+kimenekítését 1
+kimondhatóvá 1
+kimondták 1
+kimunkálása 1
+kimutatható 1
+kinevezni 1
+kineveztek 1
+kinnlevőségét 1
+kiolvasni 1
+kirendeltségeihez 1
+kirobbant 1
+kirobbanásáért 1
+kiruccanás 1
+kirándulások 1
+kis- 1
+kisbankban 1
+kisbefektető 1
+kisbefektetők 1
+kisebbik 1
+kisebbség 1
+kisebbségben 1
+kisgazdák 1
+kiskapuk 1
+kiskereskedelemben 1
+kisméretű 1
+kispénzű 1
+kisugárzású 1
+kisvárosokban 1
+kisvártatva 1
+kiszabadítása 1
+kiszabott 1
+kiszabását 1
+kiszámíthatatlan 1
+kiszámíthatóságon 1
+kiszáradt 1
+kitaláljuk 1
+kitartóknak 1
+kiterjedt 1
+kiterjedésével 1
+kiterjedő 1
+kiterjesztette 1
+kitermelési 1
+kitér 1
+kitörése 1
+kitüntetetteknek 1
+kitüntetés 1
+kitüntetést 1
+kiutat 1
+kivel 1
+kivetett 1
+kivitel 1
+kiviteli 1
+kivizsgálását 1
+kivizsgáló 1
+kivonul 1
+kivonult 1
+kivonuló 1
+kiválasztását 1
+kiválnak 1
+kivált 1
+kiváltó 1
+kiválóság 1
+kivásárolták 1
+kivégeztek 1
+kivételek 1
+kivételével 1
+kizárja 1
+kizárt 1
+kizárta 1
+kiállt 1
+kiállítani 1
+kiállítása 1
+kiállításból 1
+kiállításnak 1
+kiállítások 1
+kiállításról 1
+kiállítást 1
+kiállításán 1
+kiállítótermeket 1
+kiéleződtek 1
+kiépítését 1
+kiírását 1
+kiürített 1
+kiürült 1
+kiürülésének 1
+klasszikus 1
+klinikai 1
+klubigazgatója 1
+klubok 1
+kluboknak 1
+klíringelszámolás 1
+kockázatos 1
+kocsija 1
+kocsinak 1
+kocsit 1
+kokettált 1
+koldust 1
+kollégiumi 1
+kollégájának 1
+kolozsvári 1
+kolozsváriak 1
+kommentált 1
+kommentálta 1
+kommunikáljanak 1
+kommunista 1
+kommunisták 1
+komorult 1
+kompenzációként 1
+kompozíciókat 1
+kompromittáló 1
+koncentrációra 1
+koncentráltam 1
+koncentrálunk 1
+koncertanyagát 1
+koncertdarabjaim 1
+koncessziós 1
+konferenciatermet 1
+konfliktusok 1
+konfliktust 1
+konfrontáció 1
+konglomerátum 1
+konjunktúra-dekonjunktúra 1
+konjunktúratesztjében 1
+konkrét 1
+konkurencia 1
+konkurencián 1
+konkurens 1
+konstellációk 1
+konstrukcióban 1
+konszolidálódásra 1
+kontakt 1
+kontinensvetélkedő 1
+kontinensvetélkedőt 1
+konvenció 1
+konvertibilis 1
+konvertálható 1
+konvojügy 1
+konzervgyár 1
+konzervgyárak 1
+konzerviparban 1
+konzorciumnak 1
+koordinált 1
+korban 1
+kordában 1
+koreai 1
+korhatár 1
+korlátait 1
+korlátlanul 1
+korlátozni 1
+korlátozott 1
+korlátozza 1
+korlátozások 1
+korlátozásokat 1
+kormány-előterjesztéssé 1
+kormánybizottság 1
+kormánycsapatok 1
+kormányfői 1
+kormányhatározat 1
+kormányjavaslatokból 1
+kormánykoalíció 1
+kormánykoalíciós 1
+kormánynál 1
+kormányok 1
+kormányokat 1
+kormányprogramban 1
+kormánypárti 1
+kormánypártok 1
+kormányra 1
+kormányváltás 1
+kormányzat 1
+kormányának 1
+kormányülést 1
+koronába 1
+koronát 1
+korosztály 1
+korosztályban 1
+korrektségen 1
+korrumpálásával 1
+korszakot 1
+korszerű 1
+korszerűséggel 1
+korszerűsödő 1
+kort 1
+korú 1
+korúnál 1
+koszorún 1
+kozmetikázásával 1
+krachból 1
+kreatív 1
+kreált 1
+kritika 1
+kritikus 1
+krízis 1
+krízisei 1
+kudarca 1
+kudarcot 1
+kulcsfontosságú 1
+kulcsjátékosai 1
+kultikus 1
+kultikust 1
+kulturális-történeti 1
+kultusza 1
+kultusztárca 1
+kultúrák 1
+kumikok 1
+kupadöntőt 1
+kuratóriuma 1
+kutatott 1
+kutatva 1
+kutatási 1
+kutatói 1
+kutatók 1
+kutyák 1
+kuvaszok 1
+kvótarendszer 1
+kvótához 1
+kvótát 1
+kádereket 1
+kályhagyártó 1
+kályhák 1
+káosz 1
+károk 1
+károkat 1
+károkkal 1
+károkról 1
+kárpótolhatja 1
+kátyúból 1
+kávéházi 1
+kávészünetre 1
+kél 1
+kémhistóriájukhoz 1
+kémkedtek 1
+kényelmetlenebb 1
+kényszerleállás 1
+kényszertől 1
+kényszerítsék 1
+kényszerítése 1
+kényszerülhet 1
+kénytelen 1
+képeket 1
+képesek 1
+képességeiket 1
+képet 1
+képeznie 1
+képeztek 1
+képtelenek 1
+képviseletét 1
+képviselik 1
+képviselőházat 1
+képviselői 1
+képviselőiből 1
+képviselőinek 1
+képviselőt 1
+képviselővel 1
+képzeletszülte 1
+képzeltek 1
+képzése 1
+képzőművészei 1
+képén 1
+kérdezhetné 1
+kérdezné 1
+kérdezte 1
+kérdései 1
+kérdéseiben 1
+kérdéseket 1
+kérdésről 1
+kérdésében 1
+kérdését 1
+kérdésünkre 1
+kéri 1
+kérik 1
+kérlelik 1
+kérnek 1
+kérnie 1
+kérő 1
+késik 1
+késtek 1
+készek 1
+készenlétben 1
+készenlétihitel-megállapodáshoz 1
+készfizető 1
+készleteinek 1
+készpénzben 1
+készpénznek 1
+készpénzt 1
+készségét 1
+késztermék 1
+késztermékárak 1
+készítenek 1
+készítésekor 1
+készítésénél 1
+készítő 1
+készítői 1
+készülhetett 1
+készülnek 1
+készülni 1
+készülnének 1
+készültség 1
+készültségben 1
+készülék 1
+készülékkel 1
+késéseket 1
+késéssel 1
+késő 1
+későbbiekben 1
+későn 1
+két-három 1
+kétharmados 1
+kétmilliárd 1
+kétnapos 1
+kétnyelvű 1
+kétosztatú 1
+kétszázezer 1
+kétszázötven 1
+kétségbe 1
+kétségtelen 1
+kétévesen 1
+kézben 1
+kézbentartása 1
+kézenfekvő 1
+kézhezvétele 1
+kézi 1
+kézigránátokat 1
+kéziratok 1
+kézre 1
+kíméletlen 1
+kínálják 1
+kísér 1
+kísérte 1
+kísérőzenéi 1
+kísérőzenéje 1
+kíváncsi 1
+kívánnak 1
+kívánságának 1
+kívánunk 1
+kódja 1
+kókuszszőnyegre 1
+kómában 1
+kórház 1
+kórházukban 1
+kórokozó 1
+köbméter 1
+köbméterre 1
+ködösítés 1
+kölcsönt 1
+kölcsönzött 1
+kölcsönösen 1
+kölcsönössége 1
+költségei 1
+költségek 1
+költségvetésbe 1
+költségvetésből 1
+költségvetésekből 1
+költségvetésként 1
+költségvetésének 1
+költségét 1
+könnyebb 1
+könnyedén 1
+könynyezett 1
+könyvben 1
+könyve 1
+könyvek 1
+könyvritkaság 1
+könyvtár 1
+könyvviteli 1
+könyörtelen 1
+könyörögnek 1
+körbe-körbe 1
+körbevették 1
+körből 1
+köre 1
+körgyűrűt 1
+környezeti 1
+környezetvédelmi 1
+környékbeli 1
+környéken 1
+környéki 1
+környékét 1
+körvonalazódna 1
+körzetbe 1
+körzetben 1
+körzethez 1
+köré 1
+körében 1
+körökre 1
+körúti 1
+körútnak 1
+körülményei 1
+körülményeinek 1
+körülményekről 1
+körülvett 1
+körülötte 1
+köszönhetem 1
+köszöntik 1
+kötelessége 1
+kötelességük 1
+kötelezettségekkel 1
+kötelezte 1
+kötetlen 1
+kötvény 1
+kötöttek 1
+kötötték 1
+kötődjön 1
+kötődnek 1
+kövessenek 1
+követel 1
+követelik 1
+követelményeket 1
+követelés 1
+követett 1
+követi 1
+követik 1
+következetes 1
+következett 1
+következmény 1
+következményeire 1
+következményeit 1
+követtek 1
+követőnek 1
+közakaratra 1
+közalkalmazotti 1
+közbeszerzési 1
+közbeszéd 1
+közbeszédben 1
+közcélú 1
+köze 1
+közegbe 1
+közelgő 1
+közeljövőben 1
+közelmúlt 1
+közelít 1
+közelítik 1
+közelítésére 1
+közepes 1
+közepesnél 1
+közepette 1
+közepén 1
+közforgalmú 1
+közgazdászok 1
+közgyűlése 1
+közhangulatnak 1
+közhivatalnoktól 1
+közhivataltól 1
+közismert 1
+közkedvelt 1
+közlekedett 1
+közlekedhet 1
+közlekedni 1
+közlekedésre 1
+közlekedést 1
+közlekedésének 1
+közleményre 1
+közlés 1
+közlések 1
+közműkiváltás 1
+köznemesek 1
+közoktatás 1
+központilag 1
+központja 1
+központjai 1
+központjában 1
+közre 1
+közreadták 1
+közreműködéssel 1
+közszereplő 1
+közszolgálati 1
+község 1
+községekben 1
+köztartozásaik 1
+közteherviselést 1
+köztiszteletnek 1
+köztársaságba 1
+köztársaságban 1
+köztársaságból 1
+köztársaságában 1
+közvetített 1
+közvetítik 1
+közvetítésében 1
+közvélemény-kutatások 1
+közvéleményt 1
+közzétett 1
+közállapotokba 1
+közéletből 1
+közép-kelet-európai 1
+közép-szerbiai 1
+középkategóriájú 1
+középvállalkozások 1
+közölje 1
+közönsége 1
+közönséget 1
+közösségi 1
+közöttieket 1
+közúthálózat 1
+közútkezelő 1
+küldi 1
+küldjék 1
+küldte 1
+küldtek 1
+küldöttsége 1
+külföldről 1
+külföldön 1
+külkereskedelem 1
+külkereskedelme 1
+külképviselet 1
+külvilággal 1
+különben 1
+különbségek 1
+különbséget 1
+különbözőségét 1
+különmegbízott 1
+különvonatnak 1
+külügyminiszteri 1
+külügyminiszterrel 1
+külügyminisztériumtól 1
+küszködött 1
+küzdelmek 1
+küzdelmeket 1
+küzdelmüket 1
+küzdenek 1
+küzdenie 1
+küzdöttek 1
+küzdőszellemének 1
+kődarab 1
+kőolajimportot 1
+kőolajra 1
+kőolajtermékekre 1
+labdarúgás-fejlesztési 1
+labdarúgó-mérkőzéseket 1
+labdarúgó-szövetség 1
+labdára 1
+labdát 1
+labdával 1
+lakhatatlan 1
+lakosa 1
+lakosokat 1
+lakossági 1
+lakost 1
+lakozott 1
+lakásban 1
+lakóit 1
+lakóitól 1
+lakója 1
+lankad 1
+lapockaveregetéssel 1
+lappangó 1
+lapzártánkkor 1
+lapát 1
+lapértesülések 1
+lassan 1
+lassult 1
+lassú 1
+le-lecsukódik 1
+leadták 1
+lebegett 1
+lebontották 1
+lebontásának 1
+lebonyolítani 1
+lebélyegzése 1
+lecsökkent 1
+lefedi 1
+lefújná 1
+lefújást 1
+legbékésebbnek 1
+legeltetik 1
+legenda 1
+legendának 1
+legerősebb 1
+legfelkészültebb 1
+leggazdagabb 1
+leggyorsabb 1
+leghamarabb 1
+legkeményebb 1
+legkisebb 1
+legkésőbb 1
+leglényegesebb 1
+legméltóbbnak 1
+legmélyebben 1
+legnehezebb 1
+legnépesebb 1
+legoptimistábbak 1
+legritkább 1
+legrosszabb 1
+legsimább 1
+legstabilabb 1
+legszebben 1
+legsúlyosabb 1
+legtöbbet 1
+legtöbbször 1
+legutolsó 1
+legutóbb 1
+legyőzhetetlen 1
+legyőzhetetlennek 1
+legzsírosabb 1
+legáltalánosabb 1
+legújabb 1
+lehessen 1
+lehetetlen 1
+lehetőleg 1
+lehetősége 1
+lehetőségeit 1
+lehetőségekről 1
+lehetőségük 1
+lehűlt 1
+lejáratú 1
+lejátssza 1
+lekerült 1
+lektora 1
+lelassult 1
+leleplezéseit 1
+lelkes 1
+lelkesedés 1
+lelkesen 1
+lelkületű 1
+lelte 1
+leltek 1
+lelépett 1
+lemaradtak 1
+lemez- 1
+lemezfelvétel 1
+lemondás 1
+lemondásra 1
+lemondását 1
+lendületet 1
+lengyeleknél 1
+lenni 1
+leromlottakat 1
+leszakadt 1
+leszek 1
+leszerelése 1
+leszállított 1
+leszállította 1
+leszögezi 1
+leszögezte 1
+leszünk 1
+letartóztatásban 1
+letartóztatását 1
+leteltével 1
+leteszik 1
+lettem 1
+letétbe 1
+letöltendő 1
+letöltött 1
+letörése 1
+levegőbe 1
+levele 1
+levelét 1
+levetette 1
+levezetése 1
+levonva 1
+leváltott 1
+levélben 1
+lezáratta 1
+lezárták 1
+lezárását 1
+leállítani 1
+leányvállalatok 1
+leányvállalatából 1
+leépítését 1
+leépülés 1
+leértékelődéséből 1
+leírhatatlan 1
+leírtak 1
+libasorban 1
+liberalizáció 1
+liberalizálja 1
+liberalizálódó 1
+licence 1
+licitet 1
+likviditási 1
+limina 1
+listája 1
+listákon 1
+listát 1
+literenkénti 1
+lobbantja 1
+lobogott 1
+lokalizálódtak 1
+lokomotívként 1
+lomposan 1
+londoni 1
+luxemburgi 1
+lyukasztgatás 1
+láb 1
+lába 1
+lábainál 1
+lábal 1
+lábbeli-kiskereskedelmi 1
+lám 1
+lánc 1
+láncokkal 1
+láncreakciót 1
+lángba 1
+lángjait 1
+lángok 1
+lángokban 1
+lángra 1
+lányt 1
+lásd 1
+láthatatlannak 1
+láthatták 1
+láthatók 1
+láthatóvá 1
+látja 1
+látjuk 1
+látnak 1
+látná 1
+látogasson 1
+látogatása 1
+látogatásuk 1
+látogatásának 1
+látogató 1
+látogatóit 1
+látogatókra 1
+látott 1
+látszanak 1
+látszó 1
+láttatja 1
+látták 1
+látva 1
+látván 1
+látvánnyá 1
+látványa 1
+látványos 1
+látványosság 1
+láza 1
+léggömb 1
+légideszantost 1
+légierő 1
+légiközlekedési 1
+légkör 1
+légkört 1
+légsúlyban 1
+légzési 1
+légügyi 1
+lélegeztető 1
+lélektől 1
+lényege 1
+lényeges 1
+lényegesebb 1
+lényről 1
+lépcsőjéig 1
+lépcsőjéről 1
+léphettem 1
+lépni 1
+lépnie 1
+lépésben 1
+lépését 1
+lépő 1
+létesíteni 1
+létesítmény 1
+létesítményt 1
+létesült 1
+létezik 1
+létfontosságú 1
+létrehozását 1
+létrejötte 1
+létszáma 1
+létszámcsökkentést 1
+létszámának 1
+létét 1
+lézerirányítású 1
+lórévi 1
+lökést 1
+lövéssel 1
+lövészdandár 1
+lövését 1
+madárcsontú 1
+maffia 1
+maffiózók 1
+magabiztosan 1
+magasak 1
+magaslatán 1
+magasztos 1
+magasépítéssel 1
+magazinját 1
+maguk 1
+magukévá 1
+magyar-román 1
+magyar-ukrán 1
+magyardemokraták 1
+magyarul 1
+magyarázta 1
+magzatelhajtást 1
+magában 1
+magánbűnbe 1
+magángazdaságban 1
+magángyűjtemény 1
+magánlevelet 1
+magánlevél 1
+magánosítás 1
+magánszemély 1
+magánszemélyként 1
+magánvéleményként 1
+magányosan 1
+magánöntődében 1
+magáról 1
+magától 1
+magával 1
+magáért 1
+magáét 1
+majdnem 1
+malom- 1
+maláj 1
+mamutcég 1
+mamutvállalkozások 1
+manapság 1
+manchesteri 1
+manipuláltságát 1
+manufakturális 1
+maradandó 1
+maradhat 1
+maradjanak 1
+maradtak 1
+maradék 1
+marketingigazgatója 1
+marosvásárhelyi 1
+marsall 1
+marsallnak 1
+marógép 1
+materben 1
+matracot 1
+meccs 1
+meccseit 1
+meccsről 1
+meddig 1
+megadóztatásáról 1
+megakadhat 1
+megakadályozni 1
+megakadályozta 1
+megakaszthatja 1
+megalakult 1
+megalakulása 1
+megalapító 1
+megaláztatás 1
+megannyi 1
+megbeszélésen 1
+megbetegedéseket 1
+megbékélést 1
+megbénult 1
+megbénította 1
+megbízhatósággal 1
+megbízásából 1
+megcsúfolta 1
+megduplázódott 1
+megegyezett 1
+megegyezik 1
+megegyezéssel 1
+megegyező 1
+megelégedett 1
+megelégelte 1
+megelőzendő 1
+megelőzi 1
+megelőzést 1
+megemészteni 1
+megenyhült 1
+megerősödtek 1
+megesik 1
+megeszik 1
+megfelel 1
+megfelelni 1
+megfelelt 1
+megfelelőnek 1
+megfellebbezte 1
+megfenyegetik 1
+megfenyegette 1
+megfigyelés 1
+megfigyelési 1
+megfigyelők 1
+megfogadják 1
+megfogadtam 1
+megfogadták 1
+megfogyatkozott 1
+megfontolásaikat 1
+megfontolásokból 1
+megformálás 1
+megformálása 1
+megfélemlítés 1
+meggyilkoltak 1
+meggyőzően 1
+meggátolni 1
+meghaladja 1
+meghaladni 1
+meghallgathatja 1
+meghallgatja 1
+meghallgatta 1
+meghatározná 1
+meghatározó 1
+meghatározónak 1
+meghirdetett 1
+meghirdették 1
+meghosszabbítsák 1
+meghosszabbítása 1
+meghozatala 1
+meghozatalával 1
+meghátrált 1
+meghívása 1
+megindul 1
+megindult 1
+megingott 1
+megismerkedést 1
+megismerték 1
+megismerése 1
+megismétli 1
+megismétlése 1
+megismétlését 1
+megjelentek 1
+megjelenésével 1
+megjelenítés 1
+megjárt 1
+megjósolható 1
+megjósolni 1
+megkaphassák 1
+megkapta 1
+megkereste 1
+megkezdődtek 1
+megkezdődött 1
+megkockáztatható 1
+megkérdezett 1
+megkérdőjelezhető 1
+megkérdőjeleződik 1
+megkísérelte 1
+megkötésekor 1
+megkötött 1
+megkövetelt 1
+megköveti 1
+meglehetősen 1
+meglengették 1
+meglepetéscsapata 1
+meglepetése 1
+meglepetésre 1
+megmagyarázni 1
+megmaradó 1
+megmenteni 1
+megmenthesse 1
+megmentésre 1
+megmunkálásának 1
+megmutatja 1
+megmutatják 1
+megmutatkozása 1
+megmutatkozástól 1
+megmutatni 1
+megmutatta 1
+megmérkőzöm 1
+megmérkőzött 1
+megnyilvánulása 1
+megnyilvánuló 1
+megnyirbálásához 1
+megnyitja 1
+megnyitott 1
+megnyitották 1
+megnyitásának 1
+megnyugtatóan 1
+megnyílt 1
+megoldani 1
+megoldotta 1
+megoldásairól 1
+megoldást 1
+megoldásához 1
+megoldását 1
+megosztottság 1
+megosztottságát 1
+megosztásról 1
+megosztást 1
+megosztását 1
+megpróbálják 1
+megpróbálkoztak 1
+megpróbáltatásairól 1
+megragadhatja 1
+megrakott 1
+megrendítheti 1
+megromlott 1
+megromlásához 1
+megrostálta 1
+megrázó 1
+megsebesült 1
+megsebesültek 1
+megsemmisítés 1
+megsemmisítésében 1
+megsemmisítését 1
+megspórolására 1
+megszabni 1
+megszakítását 1
+megszavazni 1
+megszavazná 1
+megszerették 1
+megszerezzen 1
+megszervezése 1
+megszerzett 1
+megszerzése 1
+megszorongatását 1
+megszorításait 1
+megszorítások 1
+megszorító 1
+megszégyenítések 1
+megszépítheti 1
+megszólalnak 1
+megszülethet 1
+megszületéséhez 1
+megszüntetve 1
+megszüntetés 1
+megszüntetésekre 1
+megszűnne 1
+megszűntek 1
+megszűnő 1
+megsértése 1
+megtalálhatják 1
+megtalálták 1
+megtanult 1
+megtapasztalták 1
+megtehetne 1
+megtekinthetik 1
+megtekinthetők 1
+megteremtéséhez 1
+megteremtésének 1
+megteremtését 1
+megtette 1
+megtiltotta 1
+megtiltották 1
+megtiltó 1
+megtudta 1
+megtölteni 1
+megtörténhet 1
+megtörténhetésének 1
+megtörtént 1
+megvalósítani 1
+megvalósításában 1
+megvenni 1
+megverte 1
+megviselték 1
+megvizsgálja 1
+megvonták 1
+megváltoztak 1
+megvásárolhatók 1
+megvédte 1
+megvételére 1
+megálltam 1
+megállítani 1
+megátalkodott 1
+megélhetéshez 1
+megélni 1
+megépíteni 1
+megépítésében 1
+megépítését 1
+megépülni 1
+megépült 1
+megérkeznek 1
+megérkezni 1
+megérkezés 1
+megért 1
+megérzés 1
+megírt 1
+megöltétek 1
+megörültek 1
+megúszta 1
+megúsztuk 1
+megúszták 1
+megőrzésével 1
+mekkora 1
+meleg 1
+melegség 1
+melletti 1
+mellkasukig 1
+melléki 1
+mellékútvonalon 1
+melyben 1
+melyből 1
+melyeket 1
+memorandumot 1
+menedzserek 1
+menedzsment 1
+menedéket 1
+menekülés 1
+menekülési 1
+meneküléséről 1
+menetére 1
+mennek 1
+mennem 1
+menni 1
+mennyire 1
+mennyiséget 1
+mentette 1
+mentették 1
+menti 1
+mentés 1
+mentésben 1
+mentési 1
+mentésirányítás 1
+mentők 1
+mentőszolgálat 1
+mentőövet 1
+meredekebb 1
+meredeken 1
+merengett 1
+merre 1
+mertek 1
+merénylethez 1
+merényletre 1
+merőben 1
+meseautó 1
+meseelem 1
+mester 1
+mestere 1
+mesterségbeli 1
+mesékre 1
+meséli 1
+mesélnek 1
+metrót 1
+mezőgazdasági 1
+mezőgazdaságot 1
+mezőnyben 1
+mezőnyt 1
+miből 1
+midibusz 1
+midibuszainál 1
+midibuszokba 1
+mielőtt 1
+miként 1
+miképpen 1
+milliárdnyi 1
+milliárdos 1
+milliárdot 1
+millióan 1
+millióban 1
+milliót 1
+minapi 1
+mindazokhoz 1
+mindeddig 1
+mindegyik 1
+mindeközben 1
+mindenbe 1
+mindenek 1
+mindenféle 1
+mindennapi 1
+mindennel 1
+mindezt 1
+mindmáig 1
+miniatűr 1
+minimálbérnél 1
+minimálzenéhez 1
+minisztere 1
+miniszterek 1
+miniszterelnök-helyettes 1
+miniszterelnök-helyettessel 1
+miniszterelnökkel 1
+miniszterelnöknek 1
+minisztert 1
+minisztérium 1
+minisztériumi 1
+minisztériumához 1
+minthogy 1
+minősége 1
+minősítették 1
+miszerint 1
+mivoltára 1
+miáltal 1
+mobiltelefonok 1
+mocskos 1
+modern 1
+modernizáció 1
+modor 1
+mondani 1
+mondanivalója 1
+mondaná 1
+mondat 1
+mondataiban 1
+mondatok 1
+mondhat 1
+mondhatnak 1
+mondhatni 1
+mondjon 1
+mondják 1
+mondtak 1
+mondtam 1
+monetáris 1
+monolitikus 1
+monstrum 1
+montenegrói 1
+montenegróiak 1
+moratóriumot 1
+mosolyog 1
+mosonmagyaróvári 1
+mostanra 1
+mostoha 1
+motorbenzinre 1
+motorcsónakon 1
+motorja 1
+motoron 1
+mozaikszerű 1
+mozdulat 1
+mozdulhattak 1
+mozgatása 1
+mozgatásával 1
+mozgását 1
+mozgósító 1
+mozinézők 1
+mozivásznon 1
+mulattat 1
+mullah 1
+mumifikált 1
+munka 1
+munkaadóknak 1
+munkaerő 1
+munkaerőért 1
+munkagép 1
+munkahelyeken 1
+munkahelyeket 1
+munkahelyi 1
+munkahelyéről 1
+munkaigényesnek 1
+munkalehetőség 1
+munkanélküli 1
+munkanélküli-járulékot 1
+munkanélküliség 1
+munkaszervezéssel 1
+munkaszázad 1
+munkatársa 1
+munkatársainak 1
+munkatársától 1
+munkavállalók 1
+munkavállalókat 1
+munkavégzéséért 1
+munkába 1
+munkáik 1
+munkáim 1
+munkáimmal 1
+munkájába 1
+munkáján 1
+munkájáról 1
+munkáltatóhoz 1
+munkám 1
+munkámat 1
+munkásságáról 1
+munkáért 1
+muníciót 1
+musicaljében 1
+muszlimok 1
+mutassák 1
+mutatta 1
+mutattak 1
+mutatták 1
+mutatós 1
+muzeális 1
+muzsika 1
+muzsikus-zeneszerző 1
+muzsikusok 1
+muzsikákkal 1
+muzsikám 1
+muzsikának 1
+muzsikát 1
+májusról 1
+már-már 1
+március 1
+márciusban 1
+márciusra 1
+márka 1
+márkanév 1
+márkától 1
+mármint 1
+mártírokat 1
+más-más 1
+másfél-kétszeres 1
+másikról 1
+máskor 1
+másként 1
+másnak 1
+másodpercen 1
+másokat 1
+mással 1
+másznak 1
+médiahatóság 1
+méghozzá 1
+mégpedig 1
+méltó 1
+méltóan 1
+mély 1
+mélyrepülés 1
+mélységbe 1
+mélyépítésű 1
+méretekben 1
+mérgelődik 1
+mérgezési 1
+mérkőzéseire 1
+mérkőzések 1
+mérkőzésen 1
+mérkőzéssel 1
+mérkőzésére 1
+mérlegből 1
+mérlege 1
+mérleggel 1
+mérni 1
+mérsékeljék 1
+mérséklése 1
+mérséklő 1
+mérséklődik 1
+mérséklődött 1
+mért 1
+mértek 1
+mértékadónak 1
+mértéke 1
+mértékhez 1
+mértékkel 1
+mértékének 1
+mértékét 1
+méterre 1
+méterrel 1
+mítoszait 1
+mítoszrendszer 1
+míves 1
+mód 1
+módja 1
+módosítani 1
+módosítás 1
+módosítások 1
+módosításról 1
+módosításával 1
+módot 1
+módozatait 1
+módszer 1
+módszereit 1
+módszereket 1
+módszerhez 1
+módszert 1
+mögötti 1
+múlik 1
+múltat 1
+múltjával 1
+müncheni 1
+mű 1
+műfajból 1
+műfajában 1
+műfordításában 1
+műhely 1
+műkincseinek 1
+műkincsek 1
+működjön 1
+működnek 1
+működni 1
+működtetési 1
+működése 1
+működésében 1
+működésén 1
+működött 1
+működő 1
+működők 1
+műről 1
+műsora 1
+műsornak 1
+műsorokat 1
+műsoroknak 1
+műsorukkal 1
+műsorára 1
+műszak 1
+műszakjukat 1
+műszer 1
+műteremben 1
+műtárgy-aukcióknak 1
+műve 1
+műveimről 1
+műveit 1
+műveivel 1
+művet 1
+művének 1
+művész 1
+művészetükhöz 1
+művészi 1
+művészként 1
+művésznevem 1
+na 1
+nadrágszíjat 1
+nagy- 1
+nagyapjának 1
+nagyban 1
+nagyfokú 1
+nagyhatalmak 1
+nagyhatalom 1
+nagykövete 1
+nagyköveti 1
+nagykövetségének 1
+nagykövetével 1
+nagyméretű 1
+nagypolitikában 1
+nagysága 1
+nagyságáról 1
+nagyvonalú 1
+nagyvállalat 1
+nagyvállalatok 1
+nagyvállalkozások 1
+nagyvárosokban 1
+nagyágyúk 1
+nagyérdemű 1
+nagyüzem 1
+napban 1
+napilapnak 1
+napirend 1
+napirendjén 1
+napirendről 1
+napja 1
+napját 1
+napközben 1
+napok 1
+napokig 1
+narancssárga 1
+negatívokat 1
+negyedbe 1
+negyedszázaddal 1
+negyedét 1
+negyvenen 1
+negyvenöt 1
+neheze 1
+nehézkes 1
+nehézsúly 1
+nemesebb 1
+nemesedett 1
+nemesi 1
+nemesség 1
+nemfizetések 1
+nemhogy 1
+nemkívánatos 1
+nemzet 1
+nemzete 1
+nemzetiség 1
+nemzetiségű 1
+neve 1
+nevelkedő 1
+nevem 1
+nevez 1
+nevezetesen 1
+nevezettek 1
+nevezik 1
+nevezték 1
+nevezési 1
+nevében 1
+nevéhez 1
+nevén 1
+nevéről 1
+nevét 1
+nevükhöz 1
+newspeak 1
+nisi 1
+no 1
+nominálisan 1
+normatívák 1
+norvégot 1
+novemberi 1
+novemberre 1
+novemberében 1
+numerus 1
+nyalogathatja 1
+nyelven 1
+nyelvtudományok 1
+nyer 1
+nyeregben 1
+nyereséges 1
+nyers 1
+nyersanyag 1
+nyersanyagért 1
+nyerte 1
+nyertek 1
+nyerőautomatánál 1
+nyerősorozattal 1
+nyilatkozat 1
+nyilatkozata 1
+nyilatkozatokat 1
+nyilatkozatát 1
+nyilatkozni 1
+nyilatkozott 1
+nyilatkozta 1
+nyilatkozva 1
+nyilvános 1
+nyilvánosan 1
+nyilvánosságban 1
+nyilvánvaló 1
+nyit 1
+nyitotta 1
+nyitották 1
+nyitva 1
+nyolcadikok 1
+nyolcas 1
+nyolcszáz 1
+nyomai 1
+nyomatékot 1
+nyomdokain 1
+nyomorúságra 1
+nyomot 1
+nyomott 1
+nyomozás 1
+nyomozást 1
+nyomtatott 1
+nyomában 1
+nyomásra 1
+nyomására 1
+nyugatnémet 1
+nyugdíj-biztosítási 1
+nyugdíjasok 1
+nyugdíjkorhatárt 1
+nyugovóra 1
+nyugtalanít 1
+nyári 1
+nyáron 1
+nyújtandó 1
+nyújtanunk 1
+nyújthatnak 1
+nyújtják 1
+nyújtsanak 1
+nyújtására 1
+nyújtó 1
+náci 1
+négy- 1
+négyes 1
+négyessel 1
+négyet 1
+négyszáz 1
+négyszögesítésével 1
+négytagú 1
+négyzetkilométer 1
+négyzetméter 1
+négyzetét 1
+négyéves 1
+néktek 1
+nélküle 1
+nélküliek 1
+nélkülözhetetlen 1
+nélkülöző 1
+némely 1
+németeknek 1
+németeknél 1
+némileg 1
+népei 1
+népek 1
+népekhez 1
+népességet 1
+népességgel 1
+népszerűbb 1
+népszerűsége 1
+népszokás 1
+népszámlálás 1
+névértékénél 1
+nézegette 1
+nézem 1
+nézetazonosság 1
+nézeteltérés 1
+nézettségi 1
+nézettségének 1
+nézhetnek 1
+nézlek 1
+nézniük 1
+nézték 1
+nézőket 1
+nézőnek 1
+növekedett 1
+növekedjen 1
+növekednek 1
+növekedni 1
+növekednének 1
+növekedésben 1
+növelhetik 1
+növeli 1
+növelné 1
+növelte 1
+növeléséről 1
+női 1
+nők 1
+nőkkel 1
+nőknek 1
+nőknél 1
+nőt 1
+odavezényeltek 1
+okai 1
+okokból 1
+okokkal 1
+okolta 1
+okolták 1
+okoz 1
+okozhasson 1
+okozhat 1
+okozna 1
+okoznak 1
+okoztak 1
+okozó 1
+okozói 1
+okra 1
+oktatás 1
+októberi 1
+olajat 1
+olajbányászati 1
+olajcégek 1
+olajmező 1
+olajmilliárdos 1
+olajtartályokra 1
+olajvezetékben 1
+olajvállalat 1
+olajáron 1
+olaszokkal 1
+olaszokra 1
+olcsó 1
+oldalas 1
+oldalirányban 1
+oldalról 1
+oldalsó 1
+oldalára 1
+oldaláról 1
+olimpiai 1
+olvastam 1
+olvasók 1
+ominózus 1
+opciót 1
+operaházi 1
+operaszínpadon 1
+operatívan 1
+operaénekes 1
+operettet 1
+operában 1
+operája 1
+operákat 1
+operálandó 1
+operálja 1
+operálták 1
+optimistábbak 1
+optimizmus 1
+opusz 1
+orahovaci 1
+oratóriumszólista 1
+ordas 1
+ordibáltak 1
+orosz-csecsen 1
+oroszokkal 1
+oroszt 1
+orra 1
+országaiban 1
+országainkat 1
+országban 1
+országból 1
+országhatárokon 1
+országnak 1
+országokat 1
+országot 1
+orvosból 1
+orvoscsoport 1
+orvosnak 1
+orvosunk 1
+oslói 1
+osszanak 1
+ostromát 1
+oszlatja 1
+osztani 1
+osztatlan 1
+osztja 1
+osztott 1
+osztották 1
+osztoznak 1
+osztálya 1
+osztályban 1
+osztályhoz 1
+osztályokon 1
+osztályozókat 1
+osztályra 1
+osztályt 1
+osztályának 1
+osztásával 1
+ottani 1
+otthoni 1
+otthoniaknak 1
+otthonmaradásra 1
+otthonokban 1
+otthont 1
+otthontalanná 1
+otthonteremtés 1
+otthonuk 1
+otthonukból 1
+pajzsként 1
+pakurára 1
+panaszkodnak 1
+panaszkodott 1
+panaszáradat 1
+papírok 1
+papíron 1
+parancsnok 1
+parancsnokai 1
+parancsol 1
+parkolhassanak 1
+parkolóba 1
+parkolóban 1
+parkolóhely 1
+parkolókkal 1
+partizán 1
+partizán-módit 1
+partizánháború 1
+partnerével 1
+partvidékén 1
+pasas 1
+passzolni 1
+patthelyzet 1
+pedagógusként 1
+pedagógust 1
+pehelysúly 1
+perben 1
+percekre 1
+percet 1
+pergethetik 1
+perverzeknek 1
+perújrafelvétel-kezdeményezőnek 1
+perújrafelvételhez 1
+perújrafelvételt 1
+pesszimista 1
+pesszimisták 1
+piacgazdaság 1
+piacok 1
+piacokért 1
+piacot 1
+piacvezető 1
+pihenő-melegedő 1
+pikantéria 1
+pilisi 1
+pilisszántóiak 1
+pillanatban 1
+pillantásokat 1
+pirogránit 1
+piszok 1
+poeticaként 1
+polgárai 1
+polgármester-választást 1
+polgárok 1
+polgároknak 1
+polgárság 1
+politikusokkal 1
+politikusoknak 1
+politikába 1
+politikájukat 1
+politikától 1
+pompával 1
+pont 1
+pontjain 1
+pontjairól 1
+pontjait 1
+pontként 1
+ponttal 1
+pontátlaga 1
+populárisabb 1
+porcelánból 1
+port 1
+posztkommunista 1
+posztokat 1
+poszton 1
+posztra 1
+potenciális 1
+pozícióharc 1
+pozícióit 1
+pragmatikus 1
+praxis 1
+premierjét 1
+primitív 1
+privatizáció 1
+privatizációjában 1
+privatizációjának 1
+privatizációjáról 1
+privatizációs 1
+privatizációval 1
+privatizálása 1
+privatizálásából 1
+privatizáló 1
+problémája 1
+problémáját 1
+problémákkal 1
+problémám 1
+problémás 1
+produkciók 1
+produkciókban 1
+produkcióm 1
+produkcióra 1
+professzor 1
+profiként 1
+profitéhes 1
+prognosztizálják 1
+programban 1
+programja 1
+programjába 1
+programokból 1
+programról 1
+projekció 1
+protezsált 1
+provokációnak 1
+próbálnak 1
+próbálok 1
+próbának 1
+pszichiáter 1
+pszichiáternek 1
+pszichés 1
+publikált 1
+publikálásához 1
+puccsot 1
+puha 1
+pukkadni 1
+puszta 1
+pusztáról 1
+pusztította 1
+pusztító 1
+pálfordulás 1
+pályafutásának 1
+pályakezdésének 1
+pályaudvari 1
+pályaudvarig 1
+pályája 1
+pályáján 1
+pályát 1
+pályázatokra 1
+páncélszekrényének 1
+páncéltermeiben 1
+párbeszédet 1
+párhuzamosan 1
+párosmérkőzést 1
+párosul 1
+párosult 1
+pártját 1
+pártok 1
+pártokat 1
+pártokra 1
+párttagok 1
+pártállásból 1
+pécsi 1
+példaképnek 1
+példányainak 1
+pénteki 1
+péntekre 1
+pénzben 1
+pénzbírsággal 1
+pénzből 1
+pénze 1
+pénzintézetek 1
+pénzkérdés 1
+pénzmennyiség 1
+pénznyelő 1
+pénzre 1
+pénztárost 1
+pénzéből 1
+pénzén 1
+pénzért 1
+pénzügyminiszteri 1
+pénzügyminisztert 1
+péti 1
+pótalkatrész 1
+pótlékban 1
+pótlékra 1
+pótolhatnak 1
+pótolja 1
+pótolva 1
+püspök 1
+püspököknek 1
+rabbi-szobrocska 1
+rabszolgamunkát 1
+rabul 1
+radikális 1
+ragadtak 1
+ragaszkodik 1
+rajzai 1
+rajzfilmek 1
+rajzfilmen 1
+rajzolódik 1
+raktár 1
+rakódott 1
+rangját 1
+rangok 1
+rangsorban 1
+rapszodikus 1
+ratifikálása 1
+reagált 1
+reakció 1
+reakciókat 1
+realista 1
+rebesgették 1
+recessziót 1
+reflektorait 1
+reformintézkedésektől 1
+reformja 1
+reformokat 1
+reformoknak 1
+reformot 1
+regionális 1
+regisztráció 1
+regisztrálják 1
+regisztráltak 1
+regresszió 1
+regénybeli 1
+regényhőse 1
+regényének 1
+rejlő 1
+rejtőzködő 1
+rekedt 1
+rekedtek 1
+relaxációs 1
+remek 1
+remekmű 1
+remélhetőleg 1
+remélik 1
+remélt 1
+reményei 1
+reménykednek 1
+reményét 1
+rendben 1
+rendelet 1
+rendeljenek 1
+rendeljék 1
+rendelkezései 1
+rendeltek 1
+rendeltetési 1
+rendelték 1
+rendelőket 1
+rendes 1
+rendez 1
+rendezetlen 1
+rendezetlensége 1
+rendezett 1
+rendezik 1
+rendezvénysorozat 1
+rendezési 1
+rendezésére 1
+rendezéséről 1
+rendezésű 1
+rendező 1
+rendezővel 1
+rendfenntartók 1
+rendként 1
+rendkívül 1
+rendszerbe 1
+rendszerből 1
+rendszeres 1
+rendszerhez 1
+rendszernek 1
+rendszerspecifikus 1
+rendszert 1
+rendszerű 1
+rendőr-főkapitányság 1
+rendőri 1
+rendőrjárőrre 1
+rendőrre 1
+rendőrsége 1
+rendőrséget 1
+rendőrségre 1
+rendűek 1
+rendűre 1
+repülni 1
+repült 1
+repülők 1
+repülőrajtot 1
+repülőtéren 1
+restanciája 1
+restitúció 1
+restitúciós 1
+rezet 1
+rezidenciája 1
+rezsim 1
+reálgazdaság 1
+reálgazdaságtól 1
+reálkeresetekhez 1
+reálérték-növekedést 1
+reálértékben 1
+reálértéken 1
+riasztják 1
+riasztó 1
+rideg 1
+riportere 1
+riportjait 1
+riportot 1
+ritka 1
+ritkaságok 1
+ritkán 1
+ritmusos 1
+ritmusú 1
+rivalizálásukat 1
+robbantásos 1
+rokona 1
+rokonai 1
+rokonszenvének 1
+rolót 1
+romantika 1
+romantikus 1
+romjain 1
+romlik 1
+romlott 1
+romlottak 1
+romlását 1
+romák 1
+romákat 1
+romániai 1
+rontotta 1
+rosszfiúk 1
+rosszullétek 1
+rt-nél 1
+rubellel 1
+rubelre 1
+rugalmas 1
+rutinos 1
+ráadás 1
+rábeszélni 1
+rábeszélés 1
+rácsokat 1
+rádióban 1
+rádiófelvételeink 1
+rádiókritika 1
+rádióval 1
+ráfizetést 1
+rájöjjön 1
+rákövetkező 1
+rálőttek 1
+rámutatnak 1
+rámutatott 1
+rászorultságuk 1
+rászorulók 1
+ráta 1
+rátermett 1
+rávegye 1
+rázott 1
+rázta 1
+régión 1
+részben 1
+részegységek 1
+részei 1
+részein 1
+részeivé 1
+részeként 1
+részesedése 1
+részesül 1
+részesülőkre 1
+részint 1
+részleg 1
+részlegétől 1
+részleteiről 1
+részletek 1
+részmunkaidőnek 1
+résztulajdonosa 1
+résztvevői 1
+részvény 1
+részvénycsomag 1
+részvényeinek 1
+részvényeit 1
+részvényeseit 1
+részvénypakettel 1
+részvétel 1
+részvételi 1
+részvételre 1
+részvételét 1
+részében 1
+részéről 1
+részével 1
+réteg 1
+rétegelt 1
+rétegelést 1
+ró 1
+róla 1
+rólam 1
+rögnek 1
+rögzítették 1
+rögzítő 1
+röviden 1
+rövidesen 1
+rövidre 1
+rúgó 1
+sajnos 1
+sajnálom 1
+sajtó 1
+sajtóbemutatót 1
+sajtónak 1
+sajtóosztálya 1
+sajtótájékoztatón 1
+sajtóértesülések 1
+sajátosságok 1
+sakk-sekk-bástya 1
+sakkasztalhoz 1
+sakkcsapat 1
+sakkolimpián 1
+sakkéletbe 1
+salamoni 1
+sarat 1
+sarkallhatja 1
+sarkon 1
+sebeit 1
+sebeket 1
+sebességgel 1
+sebességváltón 1
+sebességével 1
+sebesülteket 1
+segélyakciókhoz 1
+segélyezés 1
+segélyhívó 1
+segélynyújtó 1
+segélynyújtóknak 1
+segít 1
+segített 1
+segítette 1
+segítheti 1
+segítik 1
+segítsenek 1
+segítség 1
+segítségével 1
+segítségéért 1
+segítésében 1
+segítőkészségét 1
+semmibe 1
+semmiféle 1
+semmilyent 1
+semminemű 1
+semmisíteni 1
+semmit 1
+semmitmondásra 1
+sertésszállító 1
+siet 1
+sietségre 1
+siettették 1
+sikere 1
+sikeredett 1
+sikernek 1
+sikerrel 1
+sikerétől 1
+sikerű 1
+siklani 1
+siófoki 1
+skopjei 1
+sofőr 1
+sofőrjei 1
+sofőrjével 1
+sokadszor 1
+sokakat 1
+sokaknak 1
+sokba 1
+soknemzetiségű 1
+sokszor 1
+sokszorosan 1
+sokszorosított 1
+sora 1
+sorjázásában 1
+sorolt 1
+soron 1
+soros 1
+sorozatban 1
+sorozatgyártását 1
+sorozatok 1
+sorrendbe 1
+sorsa 1
+sorsot 1
+sorszámozott 1
+sort 1
+sorállást 1
+spirituális 1
+sportbizottságának 1
+sporthetilap 1
+sportújságíró-társadalom 1
+stabilitást 1
+stabilizációs 1
+stabilizálódik 1
+stagnáltak 1
+sterilizálatlan 1
+stimmel 1
+stratégia 1
+stratégiájának 1
+struktúrájának 1
+stábja 1
+stábnak 1
+státusokat 1
+státusát 1
+stílusérzékkel 1
+stúdiójában 1
+stúdiómunkát 1
+summa 1
+svéd 1
+svédé 1
+szabadabbá 1
+szabaddá 1
+szabadgondolkodó 1
+szabadrúgásánál 1
+szabadsághiányos 1
+szabadultak 1
+szabja 1
+szabolcsi 1
+szabotálta 1
+szabotálásával 1
+szabta 1
+szabály 1
+szabályaihoz 1
+szabályok 1
+szabályozza 1
+szabályozása 1
+szabálytalanságaiban 1
+szabálytalanságok 1
+szak- 1
+szakadár 1
+szakadék 1
+szakadékokat 1
+szakasza 1
+szakasznak 1
+szakaszt 1
+szakember 1
+szakembereik 1
+szakembereket 1
+szakszervezet 1
+szaktárca 1
+szakértő 1
+szakértője 1
+szaladt 1
+szanálásának 1
+szaporodik 1
+szaporodtak 1
+szavainak 1
+szavatolni 1
+szavatolása 1
+szavazat 1
+szavazatszerző 1
+szavazattöbbséggel 1
+szavazatából 1
+szavazatával 1
+szavaztak 1
+szavazás 1
+szavazóhelyiségeket 1
+szavazóik 1
+szavukat 1
+szavát 1
+szaúdi 1
+szedett 1
+szektáról 1
+szelekkel 1
+szelid 1
+szelleme 1
+szellemiségét 1
+szem 1
+szembenállás 1
+szembenállássá 1
+szembenéznie 1
+szembeszállni 1
+szeme 1
+szemem 1
+szemes 1
+szemináriumokat 1
+szemináriumra 1
+szemleírója 1
+szemlélő 1
+szempontok 1
+szemében 1
+személy 1
+személyautó 1
+személyautók 1
+személye 1
+személyek 1
+személyesen 1
+személygépkocsik 1
+személyijövedelemadó-kulcsot 1
+személyiség 1
+személyiségi 1
+személyiségéről 1
+személyszállító 1
+szemüvegszár 1
+szentesített 1
+szentgyörgyi 1
+szenvedte 1
+szenvedéllyel 1
+szenzáció 1
+szenzációja 1
+szeparatisták 1
+szerbül 1
+szerelvényeket 1
+szerelőipari 1
+szerencsének 1
+szerencsések 1
+szerencsétlenül 1
+szerep 1
+szerepe 1
+szerepeit 1
+szerepeket 1
+szerepekre 1
+szerepelt 1
+szerepeltem 1
+szerephez 1
+szereplést 1
+szereplőjeként 1
+szereplők 1
+szeretet 1
+szeretne 1
+szeretnének 1
+szerették 1
+szeretője 1
+szerezni 1
+szereztek 1
+szerezzen 1
+szerezzenek 1
+szerintem 1
+szerintük 1
+szerkezete 1
+szerkezeti 1
+szerkezetátalakítással 1
+szerkezetű 1
+szert 1
+szervek 1
+szervezet 1
+szervezeteire 1
+szervezetében 1
+szervezetének 1
+szervezte 1
+szerveztek 1
+szervezték 1
+szervezése 1
+szervezői 1
+szervhez 1
+szervokormányt 1
+szerzeményei 1
+szerzeményekből 1
+szerző 1
+szerződtethetnek 1
+szerződések 1
+szerzők 1
+szezonban 1
+szférából 1
+szilveszter 1
+szimpatikus 1
+szimpatizálnak 1
+szimpátiával 1
+szingapúri 1
+szinkron 1
+szintéren 1
+szja 1
+szlovákiai 1
+szlovákok 1
+szlovéneknél 1
+szláv 1
+szoborról 1
+szobát 1
+szocdemek 1
+szocialista 1
+szocializmus 1
+szociáldemokratának 1
+szokatlan 1
+szokás 1
+szokások 1
+szolgálat 1
+szolgálatot 1
+szolgálattal 1
+szolgálhatja 1
+szolgált 1
+szolgáltam 1
+szolgáltat 1
+szolgáltathat 1
+szolgáltatási 1
+szolgáltatásokat 1
+szolidaritás 1
+szolidaritási 1
+szombaton 1
+szomszéd 1
+szomszédaiknál 1
+szomszédok 1
+szorgalmaz 1
+szorgalmazták 1
+szorgalmazza 1
+szorongatva 1
+szorongást 1
+szorosabb 1
+szorul 1
+szorítani 1
+szovjeteknek 1
+szponzorának 1
+sztori 1
+sztrájkhullámra 1
+sztár 1
+sztárcsapatával 1
+szublimálás 1
+szuggesztivitással 1
+szuggesztiós 1
+szuperkém 1
+szurkolnak 1
+szurkoltam 1
+szábor 1
+száguldott 1
+szálak 1
+szállnak 1
+szállodaszobájában 1
+szállodában 1
+szállodák 1
+szállodákat 1
+szállt 1
+szállásolják 1
+szállítják 1
+szállítmány 1
+szállítmánynak 1
+szállítmányok 1
+szállítója 1
+számairól 1
+számban 1
+számlatartozása 1
+számolhat 1
+számolni 1
+számolt 1
+számot 1
+számozott 1
+számtalanszor 1
+számítaniuk 1
+számíthatna 1
+számíthattak 1
+számítottak 1
+számításai 1
+számításokat 1
+számítógépbe 1
+számítógépek 1
+szándékainak 1
+szándékos 1
+szándékosan 1
+szándékot 1
+szándékoznak 1
+szándékú 1
+száraz 1
+származik 1
+származása 1
+származási 1
+század 1
+században 1
+századból 1
+századforduló 1
+százalékról 1
+százalékával 1
+százméterenként 1
+szédüljön 1
+széke 1
+székelő 1
+székesfehérvári 1
+székhelyen 1
+székében 1
+szél 1
+széles 1
+szélesebb 1
+szélesítését 1
+szélsebesen 1
+szélsőségesen 1
+szélén 1
+szénhidrogének 1
+szépek 1
+szépet 1
+szépnek 1
+szépsége 1
+szépségük 1
+szétaprózott 1
+szétaprózva 1
+szétlőtt 1
+szétosztott 1
+szétszórt 1
+szétválasztása 1
+szín- 1
+színeiben 1
+színfalak 1
+színfoltot 1
+színhelyén 1
+színház 1
+színiirodalom 1
+színikritikusokból 1
+színművében 1
+színművészeti 1
+szívritmust 1
+szívtipró 1
+szívébe 1
+szívében 1
+szóba 1
+szóban 1
+szóhasználattal 1
+szól 1
+szólaltathatok 1
+szólhatnak 1
+szólítják 1
+szólított 1
+szórakoztató 1
+szótár 1
+szótára 1
+szótárt 1
+szótárának 1
+szótárával 1
+szökött 1
+szökő 1
+szörfözései-forgásai 1
+szövegek 1
+szöveget 1
+szövetkezeti 1
+szövetségen 1
+szövetségest 1
+szükségem 1
+szükségesnél 1
+szükségessége 1
+szükségünk 1
+szüleire 1
+születik 1
+születnek 1
+születésnapi 1
+születésének 1
+születésű 1
+szülők 1
+szünet 1
+szünetelnének 1
+szünetet 1
+szüntesse 1
+szüntetik 1
+szűk 1
+szűkebb 1
+szűknek 1
+szűkössége 1
+szűkült 1
+szűnt 1
+szűz 1
+sárga 1
+sárkányrepülőn 1
+sávossá 1
+sértetlenül 1
+sérthet 1
+sérülése 1
+sérülésekkel 1
+sérüléssel 1
+sérülésveszélyes 1
+síelőket 1
+síkos 1
+sínek 1
+síoktatók 1
+sípálya 1
+síremlékét 1
+sírokon 1
+síron 1
+sítalpakon 1
+sótartó 1
+sötétségbe 1
+sújtó 1
+súlyhatárát 1
+súlyosbította 1
+súlyosságának 1
+súlyát 1
+süllyedt 1
+sürgetett 1
+sürgette 1
+sütőipar 1
+sűrű 1
+ta 1
+tabunak 1
+tagadják 1
+taggal 1
+tagjai 1
+tagjaitól 1
+tagjaként 1
+tagköztársaság 1
+tagország 1
+tagozatként 1
+tagállamaiban 1
+tagú 1
+takar 1
+takarékoskodni 1
+takarókat 1
+taksálják 1
+taksálták 1
+taktikázni 1
+talaj 1
+talpon 1
+találattal 1
+találatát 1
+találgatta 1
+találhat 1
+találhatóak 1
+találhatók 1
+találjon 1
+találják 1
+találkozhatott 1
+találkozunk 1
+találkozó 1
+találkozóján 1
+találkozóját 1
+találkozón 1
+találkozót 1
+találni 1
+találta 1
+találtam 1
+tanakodni 1
+tantermek 1
+tanulmány 1
+tanulmányait 1
+tanulmányozzák 1
+tanulni 1
+tanulnia 1
+tanulságosak 1
+tanult 1
+tanuló 1
+tanyát 1
+tanácsa 1
+tanácsadást 1
+tanácsadó 1
+tanácsadókkal 1
+tanácsadót 1
+tanácskozása 1
+tanácsolt 1
+tanácsot 1
+tanárként 1
+tanárok 1
+tanítana 1
+tanított 1
+tanítványa 1
+tanítványainak 1
+tanítás 1
+tanítási 1
+tanúsága 1
+tapad 1
+tapasztalat 1
+tapasztalatok 1
+tapasztalatokat 1
+tapasztalható 1
+tapasztaltam 1
+tapsolhattunk 1
+tartalmazza 1
+tartalmazó 1
+tartalommal 1
+tartandó 1
+tartanák 1
+tartottak 1
+tartozik 1
+tartoznak 1
+tartozásának 1
+tartozó 1
+tartása 1
+tartásán 1
+tartására 1
+tartókat 1
+tartósan 1
+tavalyelőtt 1
+tavalyhoz 1
+tavalyihoz 1
+tavalyinál 1
+tavaszán 1
+taxisblokád 1
+tb- 1
+technikai 1
+technikailag 1
+technikának 1
+technológiáért 1
+tee-t 1
+teendői 1
+tegnapi 1
+teherautónyi 1
+teherbe 1
+tehergépkocsik 1
+tehetetlen 1
+tehetett 1
+tehetnek 1
+tehetségesebben 1
+tehette 1
+tej- 1
+tejiparban 1
+tekercset 1
+tekintetben 1
+tekintete 1
+tekintett 1
+tekinthetnek 1
+tekinthetők 1
+tekintve 1
+telefonhálózatokat 1
+telefonvonal-hiányt 1
+telepedhetnek 1
+telephelyeiket 1
+településeire 1
+településen 1
+településnek 1
+települését 1
+telet 1
+televíziózásban 1
+telhetett 1
+teljesítménye 1
+teljesítményén 1
+teljesítményét 1
+teljesítményű 1
+teljesítő 1
+teljhatalmú 1
+tellett 1
+telt 1
+telített 1
+telítését 1
+tematikus 1
+temetni 1
+temettek 1
+temetőkben 1
+tempójú 1
+tendencia 1
+tendenciaváltozás 1
+tendenciát 1
+tengelyszélességben 1
+tennék 1
+tenyerükből 1
+tereli 1
+terelték 1
+teremben 1
+teremnek 1
+teremteni 1
+terepet 1
+terepjáró-gépkocsik 1
+terheik 1
+terhek 1
+terheket 1
+terhelik 1
+terhelnék 1
+terhességük 1
+terjed 1
+terjeszkedni 1
+terjesztett 1
+terjeszti 1
+termelt 1
+termelésben 1
+termeléskiesés 1
+termelő 1
+termében 1
+terméke 1
+termékeket 1
+terményt 1
+természet 1
+természetesnek 1
+természeténél 1
+terroristaközpontok 1
+terrorizmussal 1
+tervbe 1
+tervből 1
+terve 1
+terveik 1
+terveivel 1
+tervez 1
+tervezet 1
+tervezete 1
+tervezetet 1
+tervezetének 1
+tervezi 1
+tervezik 1
+terveznek 1
+tervezze 1
+tervszerűségét 1
+terítik 1
+területekről 1
+területet 1
+területfejlesztésre 1
+területének 1
+területű 1
+testbe 1
+testvére 1
+testületben 1
+testőre 1
+testőrei 1
+tesznek 1
+tetemes 1
+tetszeni 1
+tetszett 1
+tetsző 1
+tettek 1
+tettét 1
+tetézve 1
+tető 1
+tevékenykedik 1
+tevékenységi 1
+tevékenységüket 1
+tevő 1
+textiláruk 1
+thai 1
+tilt 1
+tiltakoznak 1
+tiltakozott 1
+tiltakoztak 1
+tiltakozást 1
+tiszabecsin 1
+tisztelegtek 1
+tisztelettel 1
+tisztelte 1
+tisztes 1
+tisztességesek 1
+tisztességesekre 1
+tisztességtelenek 1
+tisztességtelenekre 1
+tisztogató 1
+tisztségeitől 1
+tisztségviselőit 1
+tisztségviselők 1
+tisztségviselőként 1
+tisztségéből 1
+tisztázatlan 1
+tisztázni 1
+tisztéről 1
+tisztét 1
+titkokhoz 1
+titkosszolgálat 1
+titkosszolgálati 1
+titkosszolgálatok 1
+titoisták 1
+tizeddel 1
+tizedére 1
+tizenkilencedik 1
+tizenkét 1
+tobzódik 1
+tokiói 1
+tolakszik 1
+tolerancia 1
+tologatjuk 1
+tologatás 1
+tombol 1
+tonnáját 1
+tonnára 1
+torlaszokat 1
+torlódtak 1
+torlódás 1
+torna 1
+tornára 1
+torzultak 1
+totalitárius 1
+továbbadott 1
+továbbjutás 1
+továbbtanulás 1
+továbbításához 1
+toxikológiai 1
+tradicionális 1
+tragédiáknak 1
+traktoron 1
+transzcendens 1
+transzparens 1
+transzportban 1
+tranzitforgalomban 1
+trolibusz 1
+tucat 1
+tucatot 1
+tudat 1
+tudata 1
+tudhatott 1
+tudhatta 1
+tudható 1
+tudna 1
+tudom 1
+tudományos 1
+tudtam 1
+tudtuk 1
+tudták 1
+tudásukat 1
+tudású 1
+tudó 1
+tudós 1
+tudósa 1
+tulajdon 1
+tulajdonképpen 1
+tulajdonosai 1
+tulajdonosi 1
+tulajdonosként 1
+tulajdonostársakat 1
+tulajdonostársát 1
+tulajdonából 1
+tulajdonít 1
+tulajdonította 1
+turizmus 1
+tutte 1
+tábla 1
+táblát 1
+táborában 1
+tádzsik 1
+tájékoztatása 1
+tájékoztatást 1
+tájékoztatóból 1
+tájékoztatón 1
+tájékozódhatnak 1
+támadják 1
+támadt 1
+támadták 1
+támadás 1
+támadásait 1
+támadásokban 1
+támadásokkal 1
+támadásokra 1
+támasztott 1
+támaszát 1
+támogatni 1
+támogatnák 1
+támogattak 1
+támogatták 1
+támogatásokat 1
+támogatásra 1
+támogatásáról 1
+támogatását 1
+támogatásával 1
+tán 1
+táncok 1
+tánczenének 1
+tárcsáz 1
+tárcától 1
+tárgy 1
+tárgyalná 1
+tárgyalta 1
+tárgyalás 1
+tárgyalásokon 1
+tárgyalásának 1
+tárgyat 1
+tárlaton 1
+társa 1
+társadalmi 1
+társadalom 1
+társadalombiztosítási 1
+társai 1
+társainak 1
+társasággá 1
+társaságot 1
+társaságában 1
+társtulajdonosa 1
+társulat 1
+társulni 1
+társának 1
+tátong 1
+távirati 1
+távirászlány 1
+távközlés 1
+távlatokat 1
+távol 1
+távoztak 1
+távozása 1
+távozásban 1
+távozásra 1
+távozást 1
+távozásuk 1
+távozó 1
+távozók 1
+távra 1
+távú 1
+téged 1
+téli 1
+témái 1
+témák 1
+tények 1
+tényezőkért 1
+tényét 1
+térbe 1
+térdükig 1
+térnek 1
+térszintjénél 1
+térségbeli 1
+térségek 1
+térséget 1
+térségünkben 1
+tért 1
+tét 1
+tételeket 1
+téve 1
+tévébemondó 1
+téziseikben 1
+tízen 1
+tízezren 1
+tízkor 1
+tízmillióval 1
+tóra 1
+tóratekercs 1
+többfordulós 1
+többletforrást 1
+többnemzetiségű 1
+többségre 1
+többségén 1
+többségük 1
+többé 1
+többért 1
+tökéletes 1
+tölteni 1
+töltheti 1
+tölti 1
+töltik 1
+töltötte 1
+tömegesen 1
+tömegmegmozdulás 1
+tönkremennek 1
+törekedett 1
+törekednek 1
+törekszik 1
+töretlenül 1
+törlesztés 1
+törlesztésre 1
+törmelék 1
+történelemben 1
+történelme 1
+történetbe 1
+történetet 1
+történeti 1
+történetén 1
+történtek 1
+történése 1
+történések 1
+törvénnyel 1
+törvénycsomagnak 1
+törvényi 1
+törvényjavaslat 1
+törvénykönyve 1
+törvénynek 1
+törzsközönségünk 1
+törzstőkével 1
+törékeny 1
+törést 1
+töröltek 1
+törött 1
+túladtak 1
+túldimenzionálásától 1
+túlmutató 1
+túlterhelheti 1
+túlterheltsége 1
+túltermelési 1
+túlteszi 1
+túlzott 1
+túlzottaknak 1
+túlzottan 1
+túlzással 1
+túlélőt 1
+tüntetést 1
+tüntető 1
+türelmetlenül 1
+türk 1
+türkök 1
+tüzek 1
+tüzérségi 1
+tőke 1
+tőkeemelésben 1
+tőkeemelések 1
+tőkeemelésről 1
+tőkeemeléssel 1
+tőkekoncentráció 1
+tőkepiacok 1
+tőketartalékba 1
+tőketöbblet 1
+tőketömegek 1
+tőketörlesztésre 1
+tőkéjének 1
+tőkéjű 1
+tőkénél 1
+tőkésíti 1
+tőkével 1
+tőle 1
+tőzsdei 1
+tőzsdéinek 1
+tű 1
+tűnt 1
+tűnő 1
+tűz 1
+tűzesetek 1
+tűzkárok 1
+tűznék 1
+tűzoltókat 1
+tűzön-vízen 1
+u 1
+udvarán 1
+ugyanarra 1
+ugyanolyan 1
+ugyanott 1
+ukrán 1
+ukránok 1
+unatkozik 1
+universitasra 1
+univerzum 1
+unióhoz 1
+urakat 1
+uralkodik 1
+uralmát 1
+urusz-martani 1
+urát 1
+utalják 1
+utalt 1
+utasaikat 1
+utasfülkében 1
+utasokat 1
+utasította 1
+utasításra 1
+utasítást 1
+utazni 1
+utazom 1
+utazott 1
+utazzon 1
+utazással 1
+utazást 1
+utazó 1
+utca 1
+utcaihoz 1
+utcaival 1
+utcaié 1
+utcákon 1
+utcán 1
+utolsósorban 1
+utánpótlás 1
+utánpótlást 1
+utóbb 1
+utóbbiak 1
+utóbbiakat 1
+utóbbiakkal 1
+utóbbira 1
+utódaként 1
+utódra 1
+utódállama 1
+utódállamaiban 1
+utódának 1
+utópiája 1
+vacsora 1
+vacsorára 1
+vagon 1
+vagyonhoz 1
+vagyonmegosztás 1
+vagyonrendezés 1
+vagyonvédelmi 1
+vagyonú 1
+valahol 1
+valakinek 1
+valamelyik 1
+valamiféle 1
+valamilyen 1
+valamirevaló 1
+valamiért 1
+vall 1
+valljuk 1
+vallott 1
+vallási 1
+valutabevételei 1
+valutákban 1
+valójában 1
+valószínűnek 1
+valóságos 1
+valóságra 1
+varsói 1
+varázslóját 1
+vasdarabbá 1
+vasutat 1
+vasúttal 1
+vasútvonalakon 1
+vasútvonalon 1
+vb-címmérkőzésére 1
+vegyes 1
+vegyesvállalata 1
+vegyipari 1
+vehet 1
+veheti 1
+velem 1
+velünk 1
+vendégek 1
+vendégeket 1
+vendégforgalom 1
+vendégjátékán 1
+vendégszereplés 1
+venné 1
+vereséget 1
+vereségért 1
+veretlen 1
+vergődnek 1
+verseinek 1
+versengenek 1
+versengés 1
+versengésbe 1
+versenyben 1
+versenyen 1
+versenyeztetés 1
+versenygazdaság 1
+versenyképesség 1
+versenyképességért 1
+versenytársaik 1
+versenytársaikkal 1
+versenytársuk 1
+vert 1
+verzió 1
+verziót 1
+vesebeteget 1
+vesszen 1
+vesszük 1
+vesz 1
+veszem 1
+veszendőbe 1
+veszhet 1
+vesztegeltek 1
+veszteglő 1
+vesztes 1
+vesztese 1
+vesztesei 1
+veszteséggel 1
+vesztett 1
+vesztettem 1
+veszély 1
+veszélyezteti 1
+veszélyforrásai 1
+veszélyforrássá 1
+veszélyére 1
+veszített 1
+vetnek 1
+vetni 1
+vette 1
+vettem 1
+vetélkedik 1
+vetélkedés 1
+vetélytársa 1
+vevői 1
+vevőt 1
+vezessenek 1
+vezet 1
+vezetett 1
+vezethető 1
+vezeti 1
+vezetni 1
+vezettek 1
+vezetékes 1
+vezetékre 1
+vezetés 1
+vezetéshez 1
+vezetésében 1
+vezetésű 1
+vezetőiből 1
+vezetőinek 1
+vezetőire 1
+vezetőjét 1
+vezetőségi 1
+vezényletével 1
+vezérevezős 1
+vezérezredes 1
+vezérigazgató 1
+vezérigazgatónak 1
+vezérét 1
+vezérőrnagy 1
+viaszkópiák 1
+videotékára 1
+vidék- 1
+vidéken 1
+vidékfejlesztés 1
+vidékről 1
+villamosenergetikai 1
+villamosmérnököket 1
+villamosok 1
+villamossal 1
+villanymozdony 1
+villanyvezetékek 1
+villanyáramot 1
+világ- 1
+világa 1
+világbajnok-jelölti 1
+világbajnoki 1
+világbajnokjelöltje 1
+világban 1
+világcég 1
+világgazdaság 1
+világháborús 1
+világhírű 1
+világmagyarázatként 1
+világos 1
+világosan 1
+világpiac 1
+világszerte 1
+világszervezet 1
+világviszonylatban 1
+vinni 1
+viselkedjenek 1
+viselkednek 1
+viselkedésén 1
+viselkedésüket 1
+viselt 1
+viselő 1
+visszaadja 1
+visszaesését 1
+visszaesésével 1
+visszajelzést 1
+visszajuttatását 1
+visszalépjenek 1
+visszaszerzi 1
+visszaszolgáltatásának 1
+visszatelepülése 1
+visszatérni 1
+visszatért 1
+visszatérésük 1
+visszautalták 1
+visszavonva 1
+visszavásárlása 1
+visszavásárlási 1
+visszaállítása 1
+visszaélve 1
+visszaéléseket 1
+visz 1
+viszonozva 1
+viszonya 1
+viszonyban 1
+viszonylag 1
+viszonyokhoz 1
+viszonyszáma 1
+viszonyt 1
+viszonyában 1
+viszonyítási 1
+viszálykodtak 1
+viszályokat 1
+vita 1
+vitasorozat 1
+vitatható 1
+vitatják 1
+vitatkozni 1
+vitatta 1
+vitt 1
+vittek 1
+vitték 1
+vitájába 1
+vitáját 1
+vitákat 1
+vitáktól 1
+vitán 1
+vitára 1
+vivő 1
+vizes 1
+vizitje 1
+vizsgálat 1
+vizsgálatban 1
+vizsgálta 1
+vizsgálódik 1
+voksok 1
+voksolás 1
+voksukat 1
+voltam 1
+volumene 1
+volumenét 1
+vonakodva 1
+vonja 1
+vonnak 1
+vonni 1
+vonnák 1
+vontatták 1
+vonul 1
+vonulhattak 1
+vonzó 1
+vonzóak 1
+vonzódás 1
+vonása 1
+vonást 1
+vád 1
+vádak 1
+vádlottak 1
+vádolható 1
+vádolják 1
+vádolta 1
+vádolták 1
+vágták 1
+vágynak 1
+vágású 1
+vágóhidak 1
+válaszom 1
+választani 1
+választhatnak 1
+választja 1
+választmányi 1
+választottam 1
+választás 1
+választást 1
+választóival 1
+választókat 1
+válhat 1
+vállal 1
+vállalat 1
+vállalata 1
+vállalatbirodalmának 1
+vállalati 1
+vállalatokkal 1
+vállalatot 1
+vállalatát 1
+vállalhatok 1
+vállalható 1
+vállalkozásba 1
+vállalkozásnak 1
+vállalkozást 1
+vállalkozó 1
+vállalkozójának 1
+vállalnia 1
+vállalt 1
+vállalta 1
+vállalva 1
+válniuk 1
+válogatottbeli 1
+válogatottjában 1
+válsága 1
+válságban 1
+válsággal 1
+válságából 1
+váltani 1
+változata 1
+változatlanul 1
+változik 1
+változott 1
+változtatnak 1
+változtatás 1
+változtatások 1
+változás 1
+változások 1
+változást 1
+váltson 1
+váltók 1
+vályogház 1
+vámjának 1
+vámtarifákkal 1
+várakozása 1
+várakozásra 1
+várakozó 1
+várbéli 1
+várják 1
+városa 1
+városatyák 1
+városok 1
+városokban 1
+városvezetés 1
+városvezető 1
+vásár 1
+vásárlásaik 1
+vásárlók 1
+vásárlókra 1
+vásárol 1
+vásárolni 1
+védendő 1
+védjegyek 1
+védés 1
+védőintézkedésekkel 1
+védőnek 1
+végbe 1
+végelszámolással 1
+végeredmény 1
+véget 1
+végig 1
+végigaludta 1
+végighúzódik 1
+végigég 1
+véginél 1
+végrehajtási 1
+végrehajtásához 1
+végtelenné 1
+végzi 1
+végzők 1
+vélelmét 1
+vélemények 1
+véleményének 1
+véleményét 1
+vélt 1
+vér 1
+vérmérgezést 1
+vészhelyzetből 1
+vételi 1
+vételre 1
+vételár 1
+vírussal 1
+vívja 1
+vívott 1
+vörös 1
+vörösváriak 1
+whiskyt 1
+zagyva 1
+zajlanak 1
+zajló 1
+zajos 1
+zavargásokat 1
+zene 1
+zeneakadémistát 1
+zenei 1
+zeneszerző 1
+zeneszerzőzseniket 1
+zenék 1
+zenéket 1
+zenének 1
+zenére 1
+ziccerben 1
+zokszó 1
+zongoraszvitemet 1
+zord 1
+zsoldos 1
+zsolnai 1
+zsúfoltságot 1
+zárkóznak 1
+zárlat 1
+zárni 1
+zártak 1
+zártkörű 1
+zárult 1
+zárása 1
+zárójelbe 1
+zászlaját 1
+zászló 1
+zömmel 1
+zömében 1
+zürichi 1
+ÁPTF 1
+ÁPTF-nek 1
+Ákos 1
+Államokban 1
+Államoknak 1
+Állták 1
+Állásbörze 1
+Általában 1
+Árgus 1
+Áron 1
+Árpád 1
+Árverést 1
+Ásványolaj 1
+Átmeneti 1
+Ázsiában 1
+Élet 1
+Élvezettel 1
+Élő-pontszámaikat 1
+Élő-pontszámú 1
+Ének-Zene 1
+Építő 1
+Építőipari 1
+Érdemes 1
+Érthetné 1
+Értéktőzsdén 1
+Észak-Kaukázus 1
+Észak-Kaukázusban 1
+Északnyugat-Magyarországon 1
+Éta 1
+Éva 1
+Ön 1
+Önkéntes 1
+Önkéntesek 1
+Ördögökkel 1
+Öregasszony 1
+Örökség 1
+Örülök 1
+Ösztönösen 1
+Ötödik 1
+Újabb 1
+Újlaki 1
+Újsolt 1
+Úristen 1
+áfa-tartozásai 1
+ága 1
+ágak 1
+ágazat 1
+ágazaton 1
+ágazatra 1
+ágon 1
+áldozat 1
+áldozata 1
+áldozatainak 1
+áldozatként 1
+áldozatnak 1
+áldozatok 1
+áldozatot 1
+államalkotó 1
+államfőt 1
+államháztartás 1
+államok 1
+állampolgári 1
+állampolgárok 1
+államra 1
+államtitkokat 1
+államtitkár-helyettesi 1
+államtitkárát 1
+államának 1
+állandósulnia 1
+állapot 1
+állapotban 1
+állapotok 1
+állapotot 1
+állapotát 1
+állapítsa 1
+állatok 1
+állatokkal 1
+állatábrázolás 1
+állhat 1
+állhatnak 1
+álljanak 1
+álltak 1
+állták 1
+állása 1
+állásajánlatok 1
+állásbörze 1
+álláskeresés 1
+álláskeresésnek 1
+álláspontja 1
+álláspontok 1
+állásra 1
+állást 1
+állásából 1
+állít 1
+állíthassa 1
+állíthatom 1
+állítsanak 1
+állításokat 1
+állítását 1
+álmainak 1
+álmatlanságban 1
+általam 1
+ápolnak 1
+ápolása 1
+ápoló 1
+áprilisban 1
+áprilisi 1
+áprilisában 1
+áradata 1
+árai 1
+árakat 1
+áralku 1
+áram 1
+áramot 1
+árbevétele 1
+árbevételük 1
+áremelkedés 1
+árfolyamok 1
+árfolyamváltozások 1
+árindex 1
+áringadozásai 1
+árján 1
+árkokba 1
+árkokból 1
+árnyakat 1
+árnyékgazdaságnak 1
+árnyékában 1
+árnyékát 1
+árnál 1
+árnövekedés 1
+árról 1
+árstruktúráját 1
+árszintjét 1
+ártámogatási 1
+árverés 1
+árverési 1
+árverésre 1
+árváltozásainak 1
+ássuk 1
+ásványkincsekben 1
+átalakul 1
+átalakult 1
+átalakulásokra 1
+átalakítani 1
+átalakítása 1
+átalakítások 1
+átalakítását 1
+átbocsátóképességgel 1
+átengedésével 1
+átesnie 1
+átformálódjon 1
+átfújt 1
+áthárítani 1
+átigazolási 1
+átkelőhelyén 1
+átkos 1
+átköltöztetését 1
+átlagemberek 1
+átlaggal 1
+átlagnak 1
+átlagosnál 1
+átlagához 1
+átlátható 1
+átláthatóság 1
+átlépni 1
+átlépői 1
+átmegy 1
+átmenetileg 1
+átnyújtsa 1
+átrepülése 1
+átszervezési 1
+átszervezéssel 1
+átszervezéséhez 1
+átszállást 1
+áttért 1
+áttérést 1
+áttételesen 1
+áttört 1
+átutazó 1
+átvette 1
+átvilágítás 1
+átvilágítási 1
+átéléssel 1
+átívelő 1
+átütemezésére 1
+átütemezéséről 1
+ébrednie 1
+ébredve 1
+édes- 1
+édesanyám 1
+édesapja 1
+égetően 1
+égtáj 1
+éjjel 1
+éjszaka 1
+éjszakai 1
+éjszakát 1
+élelem- 1
+élelmiszer-fogyasztás 1
+élelmiszerek 1
+élelmiszergyártóknak 1
+élelmiszerárak 1
+élemiszeriparban 1
+élesen 1
+életem 1
+életerőnk 1
+életet 1
+életfontosságúnak 1
+életmódjára 1
+élettartam 1
+életveszély 1
+életébe 1
+életévét 1
+éli 1
+élménnyel 1
+élményét 1
+élte 1
+éltető 1
+éltáblás 1
+élve 1
+élvezetes 1
+élvezik 1
+élvezni 1
+élvezte 1
+éléről 1
+élünk 1
+élőknek 1
+énekei 1
+énekelni 1
+énekelsz 1
+énekelt 1
+énekes 1
+énekesek 1
+énekli 1
+éneklés 1
+épp 1
+építenek 1
+építenék 1
+építette 1
+építkezés 1
+építsen 1
+építtetett 1
+építészt 1
+építésével 1
+építő 1
+építőipari 1
+építőművészeti 1
+épül 1
+épület 1
+épületfenntartással 1
+épületébe 1
+épületében 1
+épületének 1
+épületét 1
+épülő 1
+érckőzet 1
+érdek 1
+érdekből 1
+érdekeinek 1
+érdekeit 1
+érdekelt 1
+érdekelte 1
+érdekeltek 1
+érdekeltségeken 1
+érdekeltségét 1
+érdekesebb 1
+érdeklő 1
+érdeklődnek 1
+érdeklődőket 1
+éremért 1
+érezhető 1
+érezném 1
+éreztek 1
+érezteti 1
+érhet 1
+érhető 1
+érint 1
+érintene 1
+érintenek 1
+érintheti 1
+érinti 1
+érintkezési 1
+érjen 1
+érkezne 1
+érkező 1
+érni 1
+érnie 1
+értelmes 1
+értelmetlenebbé 1
+értelmetlenségig 1
+értelmezhető 1
+értelmezési 1
+értelmű 1
+értenie 1
+értesült 1
+értesülései 1
+értesüléseink 1
+értesülések 1
+értetődően 1
+érthetetlenül 1
+érthetően 1
+érthetőséghez 1
+érti 1
+értik 1
+értékeinek 1
+értékelték 1
+értéken 1
+értékesítik 1
+értékesítése 1
+értékesítésével 1
+értéket 1
+értéknek 1
+értékpapír-kereskedő 1
+értékpapírok 1
+értéktőzsdén 1
+értékállóságát 1
+érv 1
+érveiket 1
+érvénybe 1
+érvényesnek 1
+érvényt 1
+érzelmek 1
+érzelmeket 1
+érzem 1
+érzi 1
+érzékelhető 1
+érzékelteti 1
+érzékem 1
+érzékenyen 1
+érzését 1
+érző 1
+érésétől 1
+érő 1
+észak-koszovói 1
+északi 1
+északi-tengeri 1
+északkelet-boszniai 1
+észrevesz 1
+észrevette 1
+észrevették 1
+étkezési 1
+étteremben 1
+évekig 1
+évenkénti 1
+évesek 1
+évesen 1
+évet 1
+évezredben 1
+évforduló 1
+évfordulója 1
+évfordulójára 1
+évfordulóját 1
+évfordulót 1
+évihez 1
+évjáratban 1
+évkönyv 1
+évről 1
+évszázados 1
+évtized 1
+évtizedben 1
+évében 1
+ígéreteinek 1
+ígéretet 1
+írjon 1
+írnának 1
+írok 1
+írott 1
+írtak 1
+írás 1
+írásban 1
+író 1
+író-rendező 1
+íróasztalfióknak 1
+ítélete 1
+ítéletidő 1
+ítélhetnék 1
+ópiumtermelés 1
+órakor 1
+óriáscég 1
+óriások 1
+óriásvállalat 1
+órák 1
+órákban 1
+órákon 1
+órákra 1
+órán 1
+óráról 1
+óva 1
+óvatosak 1
+óvatosan 1
+ölelte 1
+ölti 1
+önfelfedezési 1
+öniróniáját 1
+önkormányzati 1
+önkormányzatok 1
+önkormányzatokat 1
+önkormányzatoknak 1
+önkormányzatoknál 1
+önkorrekcióra 1
+önkényes 1
+önnel 1
+önről 1
+önállótlanul 1
+ördöggel 1
+örmények 1
+örvendő 1
+öröksége 1
+örökérvényű 1
+örökös 1
+örökösödésellenes 1
+örültem 1
+összeadjuk 1
+összecsapásnak 1
+összecsapások 1
+összefoglaló 1
+összefogás 1
+összeget 1
+összegyűlt 1
+összegért 1
+összegű 1
+összehívott 1
+összekapcsolásában 1
+összekuszálódott 1
+összeköttetésben 1
+összekötésekor 1
+összekötését 1
+összekötő 1
+összekötőként 1
+összességében 1
+összeszedni 1
+összeszámlálásakor 1
+összetartozás 1
+összetétele 1
+összetörte 1
+összevetve 1
+összevonni 1
+összevonás 1
+összevonásokra 1
+összeállítás 1
+összeállítást 1
+összeállításukban 1
+összeállításában 1
+összeállítású 1
+összpontosítottak 1
+össztartozása 1
+ötmillió 1
+ötven 1
+ötvenszer 1
+ötvenéves 1
+ötödik 1
+övezet 1
+övezett 1
+úgyhogy 1
+újabbakkal 1
+újból 1
+újdonság 1
+újdonságot 1
+újdonsült 1
+újjászületve 1
+újjáválasztott 1
+újjáépítés 1
+újjáépítési 1
+újraindult 1
+újraválasztják 1
+újraöntik 1
+újraöntésével 1
+újság 1
+újságok 1
+újságírója 1
+újságírókat 1
+újságíróknak 1
+újvidéki 1
+úr 1
+úrként 1
+úszva 1
+útdíj 1
+úthálózat 1
+úthálózatot 1
+úti 1
+útja 1
+útmunkások 1
+útmutatás 1
+útnak 1
+útszakasz 1
+útvesztőkből 1
+üdvözölte 1
+üdítőital-gyártás 1
+üggyel 1
+üggyel-bajjal 1
+ügye 1
+ügyek 1
+ügyekben 1
+ügyeletet 1
+ügynöknévsorok 1
+ügyvezető 1
+ügyvivőként 1
+ügyvédje 1
+ügyébe 1
+ügyészség 1
+üldögélnek 1
+üldözés 1
+üldözői 1
+ülnek 1
+ültem 1
+ülése 1
+ülésein 1
+ülésének 1
+ülök 1
+ünnep 1
+ünnepekkel 1
+ünnepekre 1
+ünnepel 1
+ünnepelhet 1
+ünnepelhette 1
+ünnepelte 1
+ünnepséget 1
+üres 1
+ürüggyel 1
+ürügynek 1
+ütemben 1
+üteme 1
+ütemét 1
+ütik 1
+ütközetek 1
+ütközik 1
+ütősök 1
+üveg 1
+üzemanyag 1
+üzemanyag-kínálat 1
+üzemanyag-árak 1
+üzemanyaghiány 1
+üzemanyagok 1
+üzemanyagárakra 1
+üzembe 1
+üzemei 1
+üzemeltetők 1
+üzemi 1
+üzeneteit 1
+üzenetnek 1
+üzletrészét 1
+üzlettel 1
+Őket 1
+Őszintén 1
+őreként 1
+őrizd 1
+őrizetlenül 1
+őrizni 1
+őrködő 1
+őrzik 1
+őrület 1
+ősrégi 1
+őszön 1
+űr 1
diff --git a/research/syntaxnet/dragnn/python/trainer_lib.py b/research/syntaxnet/dragnn/python/trainer_lib.py
index 57451f85..f53cb894 100644
--- a/research/syntaxnet/dragnn/python/trainer_lib.py
+++ b/research/syntaxnet/dragnn/python/trainer_lib.py
@@ -152,8 +152,9 @@ def run_training(sess, trainers, annotator, evaluator, pretrain_steps,
       for label, metric in summaries.iteritems():
         write_summary(summary_writer, label, metric, actual_step + step)
       eval_metric = summaries['eval_metric']
+      tf.logging.info('Current eval metric: %.2f', eval_metric)
       if best_eval_metric < eval_metric:
-        tf.logging.info('Updating best eval to %.2f%%, saving checkpoint.',
+        tf.logging.info('Updating best eval to %.2f, saving checkpoint.',
                         eval_metric)
         best_eval_metric = eval_metric
         saver.save(sess, checkpoint_filename)
diff --git a/research/syntaxnet/dragnn/python/transformer_units.py b/research/syntaxnet/dragnn/python/transformer_units.py
new file mode 100644
index 00000000..4e7ddb1a
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/transformer_units.py
@@ -0,0 +1,584 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Network units implementing the Transformer network (Vaswani et al. 2017).
+
+Heavily adapted from the tensor2tensor implementation of the Transformer,
+described in detail here: https://arxiv.org/abs/1706.03762.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import numpy as np
+import tensorflow as tf
+
+from dragnn.python import network_units
+
+
+def add_timing_signal_1d(x, min_timescale=1.0, max_timescale=1.0e4):
+  """Adds a bunch of sinusoids of different frequencies to a Tensor.
+
+  Each channel of the input Tensor is incremented by a sinusoid of a different
+  frequency and phase.
+
+  This allows attention to learn to use absolute and relative positions.
+  Timing signals should be added to some precursors of both the query and the
+  memory inputs to attention.
+
+  The use of relative position is possible because sin(x+y) and cos(x+y) can be
+  expressed in terms of y, sin(x) and cos(x).
+
+  In particular, we use a geometric sequence of timescales starting with
+  min_timescale and ending with max_timescale.  The number of different
+  timescales is equal to channels / 2. For each timescale, we
+  generate the two sinusoidal signals sin(timestep/timescale) and
+  cos(timestep/timescale).  All of these sinusoids are concatenated in
+  the channels dimension.
+
+  Args:
+    x: a Tensor with shape [batch, length, channels]
+    min_timescale: a float
+    max_timescale: a float
+
+  Returns:
+    a Tensor the same shape as x.
+  """
+  length = tf.shape(x)[1]
+  channels = tf.shape(x)[2]
+  pos = tf.to_float(tf.range(length))
+  num_timescales = channels // 2
+  log_timescale_increment = (
+      np.log(float(max_timescale) / float(min_timescale)) /
+      (tf.to_float(num_timescales) - 1))
+  inv_timescales = min_timescale * tf.exp(
+      tf.to_float(tf.range(num_timescales)) * -log_timescale_increment)
+  scaled_time = tf.expand_dims(pos, 1) * tf.expand_dims(inv_timescales, 0)
+  signal = tf.concat([tf.sin(scaled_time), tf.cos(scaled_time)], axis=1)
+  signal = tf.pad(signal, [[0, 0], [0, tf.mod(channels, 2)]])
+  signal = tf.reshape(signal, [1, length, channels])
+  return x + signal
+
+
+def split_last_dimension(x, n):
+  """Partitions x so that the last dimension becomes two dimensions.
+
+  The first of these two dimensions is n.
+
+  Args:
+    x: a Tensor with shape [..., m]
+    n: an integer.
+
+  Returns:
+    a Tensor with shape [..., n, m/n]
+  """
+  old_shape = x.get_shape().dims
+  last = old_shape[-1]
+  new_shape = old_shape[:-1] + [n] + [last // n if last else None]
+  ret = tf.reshape(x, tf.concat([tf.shape(x)[:-1], [n, -1]], 0))
+  ret.set_shape(new_shape)
+  return ret
+
+
+def combine_last_two_dimensions(x):
+  """Reshape x so that the last two dimensions become one.
+
+  Args:
+    x: a Tensor with shape [..., a, b]
+
+  Returns:
+    a Tensor with shape [..., ab]
+  """
+  old_shape = x.get_shape().dims
+  a, b = old_shape[-2:]
+  new_shape = old_shape[:-2] + [a * b if a and b else None]
+  ret = tf.reshape(x, tf.concat([tf.shape(x)[:-2], [-1]], 0))
+  ret.set_shape(new_shape)
+  return ret
+
+
+def split_heads(x, num_heads):
+  """Splits channels (dimension 3) into multiple heads (becomes dimension 1).
+
+  Args:
+    x: a Tensor with shape [batch, length, channels]
+    num_heads: an integer
+
+  Returns:
+    a Tensor with shape [batch, num_heads, length, channels / num_heads]
+  """
+  return tf.transpose(split_last_dimension(x, num_heads), [0, 2, 1, 3])
+
+
+def combine_heads(x):
+  """Performs the inverse of split_heads.
+
+  Args:
+    x: a Tensor with shape [batch, num_heads, length, channels / num_heads]
+
+  Returns:
+    a Tensor with shape [batch, length, channels]
+  """
+  return combine_last_two_dimensions(tf.transpose(x, [0, 2, 1, 3]))
+
+
+def compute_padding_mask(lengths):
+  """Computes an additive mask for padding.
+
+  Given the non-padded sequence lengths for the batch, computes a mask that will
+  send padding attention to 0 when added to logits before applying a softmax.
+
+  Args:
+    lengths: a Tensor containing the sequence length of each batch element
+
+  Returns:
+    A Tensor of shape [batch_size, 1, 1, max_len] with zeros in non-padding
+    entries and -1e9 in padding entries.
+  """
+  lengths = tf.reshape(lengths, [-1])
+  mask = tf.sequence_mask(lengths)
+
+  # This will be used as an additive mask, so we want the inverse of the mask
+  # produced by tf.sequence_mask.
+  inv_mask = tf.to_float(tf.logical_not(mask))
+
+  mem_padding = inv_mask * -1e9
+  return tf.expand_dims(tf.expand_dims(mem_padding, 1), 1)
+
+
+def dot_product_attention(queries, keys, values, dropout_keep_rate, bias=None):
+  """Computes dot-product attention.
+
+  Args:
+    queries: a Tensor with shape [batch, heads, seq_len, depth_keys]
+    keys: a Tensor with shape [batch, heads, seq_len, depth_keys]
+    values: a Tensor with shape [batch, heads, seq_len, depth_values]
+    dropout_keep_rate: dropout proportion of units to keep
+    bias: A bias to add before applying the softmax, or None. This can be used
+          for masking padding in the batch.
+
+  Returns:
+    A Tensor with shape [batch, heads, seq_len, depth_values].
+  """
+  # [batch, num_heads, seq_len, seq_len]
+  logits = tf.matmul(queries, keys, transpose_b=True)
+  if bias is not None:
+    logits += bias
+
+  attn_weights = tf.nn.softmax(logits)
+
+  # Dropping out the attention links for each of the heads
+  attn_weights = network_units.maybe_apply_dropout(attn_weights,
+                                                   dropout_keep_rate,
+                                                   False)
+  return tf.matmul(attn_weights, values)
+
+
+def residual(old_input, new_input, dropout_keep_rate, layer_norm):
+  """Residual layer combining old_input and new_input.
+
+  Computes old_input + dropout(new_input) if layer_norm is None; otherwise:
+  layer_norm(old_input + dropout(new_input)).
+
+  Args:
+    old_input: old float32 Tensor input to residual layer
+    new_input: new float32 Tensor input to residual layer
+    dropout_keep_rate: dropout proportion of units to keep
+    layer_norm: network_units.LayerNorm to apply to residual output, or None
+
+  Returns:
+    float32 Tensor output of residual layer.
+  """
+  res_sum = old_input + network_units.maybe_apply_dropout(new_input,
+                                                          dropout_keep_rate,
+                                                          False)
+  return layer_norm.normalize(res_sum) if layer_norm else res_sum
+
+
+def mlp(component, input_tensor, dropout_keep_rate, depth):
+  """Feed the input through an MLP.
+
+  Each layer except the last is followed by a ReLU activation and dropout.
+
+  Args:
+    component: the DRAGNN Component containing parameters for the MLP
+    input_tensor: the float32 Tensor input to the MLP.
+    dropout_keep_rate: dropout proportion of units to keep
+    depth: depth of the MLP.
+
+  Returns:
+    the float32 output Tensor
+  """
+  for i in range(depth):
+    ff_weights = component.get_variable('ff_weights_%d' % i)
+    input_tensor = tf.nn.conv2d(input_tensor,
+                                ff_weights,
+                                [1, 1, 1, 1],
+                                padding='SAME')
+    # Apply ReLU and dropout to all but the last layer
+    if i < depth - 1:
+      input_tensor = tf.nn.relu(input_tensor)
+      input_tensor = network_units.maybe_apply_dropout(input_tensor,
+                                                       dropout_keep_rate,
+                                                       False)
+  return input_tensor
+
+
+class TransformerEncoderNetwork(network_units.NetworkUnitInterface):
+  """Implementation of the Transformer network encoder."""
+
+  def __init__(self, component):
+    """Initializes parameters for this Transformer unit.
+
+    Args:
+      component: parent ComponentBuilderBase object.
+
+    Parameters used to construct the network:
+      num_layers: number of transformer layers (attention + MLP)
+      hidden_size: size of hidden layers in MLPs
+      filter_size: filter width for each attention head
+      num_heads: number of attention heads
+      residual_dropout: dropout keep rate for residual layers
+      attention_dropout: dropout keep rate for attention weights
+      mlp_dropout: dropout keep rate for mlp layers
+      initialization: initialization scheme to use for model parameters
+      bias_init: initial value for bias parameters
+      scale_attention: whether to scale attention parameters by filter_size^-0.5
+      layer_norm_residuals: whether to perform layer normalization on residual
+        layers
+      timing_signal: whether to add a position-wise timing signal to the input
+      kernel: kernel width in middle MLP layers
+      mlp_layers: number of MLP layers. Must be >= 2.
+
+    Raises:
+      ValueError: if mlp_layers < 2.
+
+    The input depth of the first layer is inferred from the total concatenated
+    size of the input features, minus 1 to account for the sequence lengths.
+
+    Hyperparameters used:
+      dropout_rate: The probability that an input is not dropped. This is the
+          default when the |dropout_keep_prob| parameter is unset.
+    """
+
+    super(TransformerEncoderNetwork, self).__init__(component)
+    default_dropout_rate = component.master.hyperparams.dropout_rate
+    self._attrs = network_units.get_attrs_with_defaults(
+        component.spec.network_unit.parameters, defaults={
+            'num_layers': 4,
+            'hidden_size': 256,
+            'filter_size': 64,
+            'num_heads': 8,
+            'residual_drop': default_dropout_rate,
+            'attention_drop': default_dropout_rate,
+            'mlp_drop': default_dropout_rate,
+            'initialization': 'xavier',
+            'bias_init': 0.001,
+            'scale_attention': True,
+            'layer_norm_residuals': True,
+            'timing_signal': True,
+            'kernel': 1,
+            'mlp_layers': 2})
+
+    self._num_layers = self._attrs['num_layers']
+    self._hidden_size = self._attrs['hidden_size']
+    self._filter_size = self._attrs['filter_size']
+    self._num_heads = self._attrs['num_heads']
+    self._residual_dropout = self._attrs['residual_drop']
+    self._attention_dropout = self._attrs['attention_drop']
+    self._mlp_dropout = self._attrs['mlp_drop']
+    self._initialization = self._attrs['initialization']
+    self._bias_init = self._attrs['bias_init']
+    self._scale_attn = self._attrs['scale_attention']
+    self._layer_norm_res = self._attrs['layer_norm_residuals']
+    self._timing_signal = self._attrs['timing_signal']
+    self._kernel = self._attrs['kernel']
+    self._mlp_depth = self._attrs['mlp_layers']
+
+    if self._mlp_depth < 2:
+      raise ValueError('TransformerEncoderNetwork needs mlp_layers >= 2')
+
+    self._combined_filters = self._num_heads * self._filter_size
+
+    self._weights = []
+    self._biases = []
+    self._layer_norms = {}
+
+    # Hacky: one dimension comes from the lengths input; subtract it.
+    self._concatenated_input_dim -= 1
+
+    # Initial projection of inputs, this is mainly to project input down to the
+    # right size for residual layers
+    proj_shape = [1, 1, self._concatenated_input_dim, self._combined_filters]
+    self._weights.append(
+        network_units.add_var_initialized('init_proj', proj_shape,
+                                          self._initialization))
+    self._biases.append(tf.get_variable('init_bias',
+                                        self._combined_filters,
+                                        initializer=tf.constant_initializer(
+                                            self._bias_init),
+                                        dtype=tf.float32))
+
+    for i in range(self._num_layers):
+      with tf.variable_scope('transform_%d' % i):
+        # Attention weights: 3 * self.combined_filters = (q, k, v)
+        # We assume that q, k and v all have the same dimension
+        attn_shape = [1, 1, self._combined_filters, 3 * self._combined_filters]
+        self._weights.append(
+            network_units.add_var_initialized('attn_weights',
+                                              attn_shape,
+                                              self._initialization))
+
+        # Attention final projection weights
+        proj_shape = [1, 1, self._combined_filters, self._combined_filters]
+        self._weights.append(
+            network_units.add_var_initialized('proj_weights',
+                                              proj_shape,
+                                              self._initialization))
+
+        # MLP weights
+        with tf.variable_scope('mlp'):
+          ff_shape = [1, 1, self._combined_filters, self._hidden_size]
+          self._weights.append(
+              network_units.add_var_initialized('ff_weights_0',
+                                                ff_shape,
+                                                self._initialization))
+          ff_shape = [1, self._kernel, self._hidden_size, self._hidden_size]
+          for j in range(1, self._mlp_depth - 1):
+            self._weights.append(
+                network_units.add_var_initialized('ff_weights_%d' % j,
+                                                  ff_shape,
+                                                  self._initialization))
+          ff_shape = [1, 1, self._hidden_size, self._combined_filters]
+          self._weights.append(
+              network_units.add_var_initialized('ff_weights_%d' %
+                                                (self._mlp_depth - 1),
+                                                ff_shape,
+                                                self._initialization))
+
+        # Layer normalization for residual layers
+        if self._layer_norm_res:
+          attn_layer_norm = network_units.LayerNorm(component,
+                                                    'attn_layer_norm_%d' % i,
+                                                    self._combined_filters,
+                                                    tf.float32)
+          self._layer_norms['attn_layer_norm_%d' % i] = attn_layer_norm
+
+          ff_layer_norm = network_units.LayerNorm(component,
+                                                  'ff_layer_norm_%d' % i,
+                                                  self._combined_filters,
+                                                  tf.float32)
+          self._layer_norms['ff_layer_norm_%d' % i] = ff_layer_norm
+
+          # Layer norm parameters are not added to self._weights,
+          # which means that they are not l2 regularized
+          self._params.extend(attn_layer_norm.params + ff_layer_norm.params)
+
+    self._params.extend(self._weights)
+    self._params.extend(self._biases)
+    self._regularized_weights.extend(self._weights)
+    self._layers.append(
+        network_units.Layer(component, name='transformer_output',
+                            dim=self._combined_filters))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor
+    if stride is None:
+      raise RuntimeError("TransformerEncoderNetwork needs 'stride' and must be "
+                         "called in the bulk feature extractor component.")
+
+    lengths = network_units.lookup_named_tensor('lengths', linked_embeddings)
+    lengths_s = tf.to_int32(tf.squeeze(lengths.tensor, [1]))
+    num_steps = tf.reduce_max(lengths_s)
+
+    in_tensor = network_units.lookup_named_tensor('features', linked_embeddings)
+    input_tensor = tf.reshape(in_tensor.tensor, [stride, num_steps, -1])
+
+    if self._timing_signal:
+      input_tensor = add_timing_signal_1d(input_tensor)
+
+    # Adds a dimension for conv2d
+    input_tensor = tf.expand_dims(input_tensor, 1)
+
+    # For masking padding in attention
+    mask = compute_padding_mask(lengths_s)
+
+    conv = tf.nn.conv2d(input_tensor,
+                        self._component.get_variable('init_proj'),
+                        [1, 1, 1, 1], padding='SAME')
+    conv = tf.nn.bias_add(conv, self._component.get_variable('init_bias'))
+
+    for i in range(self._num_layers):
+      with tf.variable_scope('transform_%d' % i, reuse=True):
+        attn_weights = self._component.get_variable('attn_weights')
+        attn_combined = tf.nn.conv2d(conv,
+                                     attn_weights,
+                                     [1, 1, 1, 1],
+                                     padding='SAME')
+        attn_combined = tf.squeeze(attn_combined, 1)
+
+        # Splits combined projection into queries, keys, and values
+        queries, keys, values = tf.split(attn_combined,
+                                         [self._combined_filters]*3,
+                                         axis=2)
+
+        # Splits each of queries, keys, values into attention heads
+        queries = split_heads(queries, self._num_heads)
+        keys = split_heads(keys, self._num_heads)
+        values = split_heads(values, self._num_heads)
+        if self._scale_attn:
+          queries *= self._filter_size**-0.5
+
+        # Performs dot product attention and concatenates the resulting heads
+        attended = dot_product_attention(queries, keys, values,
+                                         self._attention_dropout, mask)
+        attended = combine_heads(attended)
+
+        # Projects combined heads
+        attended = tf.expand_dims(attended, 1)
+        proj = tf.nn.conv2d(attended,
+                            self._component.get_variable('proj_weights'),
+                            [1, 1, 1, 1],
+                            padding='SAME')
+
+        # Residual connection between input and attended input
+        attn_layer_norm_params = None
+        if self._layer_norm_res:
+          attn_layer_norm_params = self._layer_norms['attn_layer_norm_%d' % i]
+        proj_res = residual(conv, proj, self._residual_dropout,
+                            attn_layer_norm_params)
+
+        # Feed forward
+        with tf.variable_scope('mlp'):
+          ff = mlp(self._component, proj_res, self._mlp_dropout,
+                   self._mlp_depth)
+
+        # Residual connection between attended input and feed forward layers
+        ff_layer_norm_params = None
+        if self._layer_norm_res:
+          ff_layer_norm_params = self._layer_norms['ff_layer_norm_%d' % i]
+        conv = residual(proj_res, ff, self._residual_dropout,
+                        ff_layer_norm_params)
+
+    return [tf.reshape(conv, [-1, self._combined_filters],
+                       name='reshape_activations')]
+
+
+class PairwiseBilinearLabelNetwork(network_units.NetworkUnitInterface):
+  r"""Network unit that computes pairwise bilinear label scores.
+
+  Given source and target representations for each token, this network unit
+  computes bilinear scores for each label for each of the N^2 combinations of
+  source and target tokens, rather than for only N already-computed
+  source/target pairs (as is performed by the biaffine_units). The output is
+  suitable as input to e.g. the heads_labels transition system.
+  Specifically, a weights tensor W called `bilinear' is used to compute bilinear
+  scores B for input tensors S and T:
+
+    B_{bnml} = \sum_{i,j} S_{bni} W_{ilj} T{bmj}
+
+  for batches b, steps n and m and labels l.
+
+  Parameters:
+    num_labels: The number of dependency labels, L.
+
+  Features:
+    sources: [B * N, S] matrix of batched activations for source tokens.
+    targets: [B * N, T] matrix of batched activations for target tokens.
+
+  Layers:
+    bilinear_scores: [B * N, N * L] matrix where vector b*N*N*L+t contains
+                     per-label scores for all N possible arcs from token t in
+                     batch b.
+  """
+
+  def __init__(self, component):
+    super(PairwiseBilinearLabelNetwork, self).__init__(component)
+    parameters = component.spec.network_unit.parameters
+
+    self._num_labels = int(parameters['num_labels'])
+
+    self._source_dim = self._linked_feature_dims['sources']
+    self._target_dim = self._linked_feature_dims['targets']
+
+    self._weights = []
+    self._weights.append(
+        network_units.add_var_initialized('bilinear',
+                                          [self._source_dim,
+                                           self._num_labels,
+                                           self._target_dim],
+                                          'xavier'))
+
+    self._params.extend(self._weights)
+    self._regularized_weights.extend(self._weights)
+    self._layers.append(network_units.Layer(component,
+                                            name='bilinear_scores',
+                                            dim=self._num_labels))
+
+  def create(self,
+             fixed_embeddings,
+             linked_embeddings,
+             context_tensor_arrays,
+             attention_tensor,
+             during_training,
+             stride=None):
+    """Requires |stride|; otherwise see base class."""
+    del context_tensor_arrays, attention_tensor
+    if stride is None:
+      raise RuntimeError("PairwiseBilinearLabelNetwork needs 'stride' and must "
+                         "be called in a bulk component.")
+
+    sources = network_units.lookup_named_tensor('sources', linked_embeddings)
+    sources_tensor = tf.reshape(sources.tensor, [stride, -1, self._source_dim])
+
+    targets = network_units.lookup_named_tensor('targets', linked_embeddings)
+    targets_tensor = tf.reshape(targets.tensor, [stride, -1, self._target_dim])
+
+    # Dimensions: source_dim x num_labels x target_dim
+    bilinear_params = self._component.get_variable('bilinear')
+
+    # Ensures that num_steps is the same for both inputs
+    num_steps = tf.shape(sources_tensor)[1]
+    with tf.control_dependencies([tf.assert_equal(num_steps,
+                                                  tf.shape(targets_tensor)[1],
+                                                  name='num_steps_mismatch')]):
+      # Dimensions:
+      # (batch_size*num_steps x source_dim) *
+      #   (source_dim x num_labels*target_dim)
+      #     = (batch_size*num_steps x num_labels*target_dim)
+      lin = tf.matmul(tf.reshape(sources_tensor, [-1, self._source_dim]),
+                      tf.reshape(bilinear_params, [self._source_dim, -1]))
+
+      # (batch_size x num_steps*num_labels x target_dim) *
+      #   (batch_size x num_steps x target_dim)^T
+      #     = (batch_size x num_steps*num_labels x num_steps)
+      bilin = tf.matmul(
+          tf.reshape(lin, [-1, num_steps*self._num_labels, self._target_dim]),
+          targets_tensor, transpose_b=True)
+
+    # (batch_size x num_steps*num_labels x num_steps) ->
+    #   (batch_size x num_steps x num_steps*num_labels)
+    scores = tf.transpose(bilin, [0, 2, 1])
+
+    return [tf.reshape(scores, [-1, num_steps*self._num_labels],
+                       name='reshape_activations')]
diff --git a/research/syntaxnet/dragnn/python/transformer_units_test.py b/research/syntaxnet/dragnn/python/transformer_units_test.py
new file mode 100644
index 00000000..8c80eb92
--- /dev/null
+++ b/research/syntaxnet/dragnn/python/transformer_units_test.py
@@ -0,0 +1,90 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Tests for dragnn.python.transformer_units."""
+
+
+import numpy as np
+import tensorflow as tf
+
+from tensorflow.python.framework import test_util
+from tensorflow.python.platform import googletest
+
+from dragnn.python import transformer_units
+
+
+class TransformerTest(test_util.TensorFlowTestCase):
+
+  def testComputePadding(self):
+    with tf.Graph().as_default(), self.test_session() as session:
+      lengths = [5, 1, 2, 0]
+      expected = [[[[0, 0, 0, 0, 0]]],
+                  [[[0, -1e9, -1e9, -1e9, -1e9]]],
+                  [[[0, 0, -1e9, -1e9, -1e9]]],
+                  [[[-1e9, -1e9, -1e9, -1e9, -1e9]]]]
+      tensor = transformer_units.compute_padding_mask(lengths)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+      self.assertAllEqual(actual, expected)
+
+  def testDotProductAttention(self):
+    with tf.Graph().as_default(), self.test_session() as session:
+      padding = [[[[0, 0, 0, 0, 0]]],
+                 [[[0, -1e9, -1e9, -1e9, -1e9]]]]
+      # batch x heads x length x d
+      np.random.seed(4)
+      q = np.random.random((2, 2, 5, 2)).astype(np.float32)
+      k = np.random.random((2, 2, 5, 2)).astype(np.float32)
+      v = np.random.random((2, 2, 5, 2)).astype(np.float32)
+
+      # Should have shape: 2x2x5x5. Computed as follows:
+      # r = np.einsum('hijk,hilk->hijl', q, k) + padding_bias
+      # r = r - np.expand_dims(np.max(r, axis=-1), -1)
+      # r = np.exp(r)
+      # ax_sum = np.expand_dims(np.sum(r, axis=-1), -1)
+      # r = r / ax_sum
+      # for i in range(2):
+      #   for j in range(2):
+      #     np.dot(r[i,j], v[i,j])
+      expected = [[[[0.46580601, 0.64643575],
+                    [0.46182397, 0.64578158],
+                    [0.46866544, 0.64562998],
+                    [0.47930001, 0.64838011],
+                    [0.45466267, 0.64061598]],
+                   [[0.50887558, 0.39900422],
+                    [0.51721343, 0.39245871],
+                    [0.50348963, 0.40090425],
+                    [0.49889359, 0.4035989],
+                    [0.50523872, 0.39916877]]],
+                  [[[0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222],
+                    [0.26092216, 0.41247222]],
+                   [[0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009],
+                    [0.34745133, 0.05888009]]]]
+
+      tensor = transformer_units.dot_product_attention(q, k, v, 1.0, padding)
+      session.run(tf.global_variables_initializer())
+      actual = session.run(tensor)
+
+      self.assertAllClose(actual, expected, 1e-6, 1e-6)
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/dragnn/python/visualization.py b/research/syntaxnet/dragnn/python/visualization.py
index f39c80bb..76ac144c 100644
--- a/research/syntaxnet/dragnn/python/visualization.py
+++ b/research/syntaxnet/dragnn/python/visualization.py
@@ -12,7 +12,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-
 """Helper library for visualizations.
 
 TODO(googleuser): Find a more reliable way to serve stuff from IPython
@@ -64,6 +63,17 @@ def parse_trace_json(trace):
     JSON str, as expected by visualization tools.
   """
   as_proto = trace_pb2.MasterTrace.FromString(trace)
+
+  # Sanitize non-UTF8 captions. One case where this occurs is for byte LSTMs,
+  # which may be processing a sub-sequence of a UTF-8 multi-byte sequence.
+  for component_trace in as_proto.component_trace:
+    for step_trace in component_trace.step_trace:
+      if isinstance(step_trace.caption, str):
+        try:
+          unicode(step_trace.caption, 'utf-8')
+        except UnicodeDecodeError:
+          step_trace.caption = repr(step_trace.caption)  # Safe encoding.
+
   as_json = json_format.MessageToJson(
       as_proto, preserving_proto_field_name=True)
   return as_json
diff --git a/research/syntaxnet/dragnn/python/wrapped_units.py b/research/syntaxnet/dragnn/python/wrapped_units.py
index 4843aa41..5e6347f6 100644
--- a/research/syntaxnet/dragnn/python/wrapped_units.py
+++ b/research/syntaxnet/dragnn/python/wrapped_units.py
@@ -27,6 +27,60 @@ from dragnn.python import network_units as dragnn
 from syntaxnet.util import check
 
 
+def capture_variables(function, scope_name):
+  """Captures and returns variables created by a function.
+
+  Runs |function| in a scope of name |scope_name| and returns the list of
+  variables created by |function|.
+
+  Args:
+    function: Function whose variables should be captured.  The function should
+        take one argument, its enclosing variable scope.
+    scope_name: Variable scope in which the |function| is evaluated.
+
+  Returns:
+    List of created variables.
+  """
+  # Use a dict to dedupe captured variables.
+  created_vars = {}
+
+  def _custom_getter(getter, *args, **kwargs):
+    """Calls the real getter and captures its result in |created_vars|."""
+    real_variable = getter(*args, **kwargs)
+    created_vars[real_variable.name] = real_variable
+    return real_variable
+
+  with tf.variable_scope(
+      scope_name, reuse=None, custom_getter=_custom_getter) as scope:
+    function(scope)
+  return created_vars.values()
+
+
+def apply_with_captured_variables(function, scope_name, component):
+  """Applies a function using previously-captured variables.
+
+  The counterpart to capture_variables(); invokes |function| in a scope of name
+  |scope_name|, extracting captured variables from the |component|.
+
+  Args:
+    function: Function to apply using captured variables.  The function should
+        take one argument, its enclosing variable scope.
+    scope_name: Variable scope in which the |function| is evaluated.  Must match
+        the scope passed to capture_variables().
+    component: Component from which to extract captured variables.
+
+  Returns:
+    Results of function application.
+  """
+  def _custom_getter(getter, *args, **kwargs):
+    """Retrieves the normal or moving-average variables."""
+    return component.get_variable(var_params=getter(*args, **kwargs))
+
+  with tf.variable_scope(
+      scope_name, reuse=True, custom_getter=_custom_getter) as scope:
+    return function(scope)
+
+
 class BaseLSTMNetwork(dragnn.NetworkUnitInterface):
   """Base class for wrapped LSTM networks.
 
@@ -179,43 +233,12 @@ class BaseLSTMNetwork(dragnn.NetworkUnitInterface):
     ]
 
   def _capture_variables_as_params(self, function):
-    """Captures variables created by a function in |self._params|.
-
-    Args:
-      function: Function whose variables should be captured.  The function
-          should take one argument, its enclosing variable scope.
-    """
-    created_vars = {}
-
-    def _custom_getter(getter, *args, **kwargs):
-      """Calls the real getter and captures its result in |created_vars|."""
-      real_variable = getter(*args, **kwargs)
-      created_vars[real_variable.name] = real_variable
-      return real_variable
-
-    with tf.variable_scope(
-        'cell', reuse=None, custom_getter=_custom_getter) as scope:
-      function(scope)
-    self._params.extend(created_vars.values())
+    """Captures variables created by a function in |self._params|."""
+    self._params.extend(capture_variables(function, 'cell'))
 
   def _apply_with_captured_variables(self, function):
-    """Applies a function using previously-captured variables.
-
-    Args:
-      function: Function to apply using captured variables.  The function
-          should take one argument, its enclosing variable scope.
-
-    Returns:
-      Results of function application.
-    """
-
-    def _custom_getter(getter, *args, **kwargs):
-      """Retrieves the normal or moving-average variables."""
-      return self._component.get_variable(var_params=getter(*args, **kwargs))
-
-    with tf.variable_scope(
-        'cell', reuse=True, custom_getter=_custom_getter) as scope:
-      return function(scope)
+    """Applies a function using previously-captured variables."""
+    return apply_with_captured_variables(function, 'cell', self._component)
 
 
 class LayerNormBasicLSTMNetwork(BaseLSTMNetwork):
diff --git a/research/syntaxnet/dragnn/tensorflow_ops.bzl b/research/syntaxnet/dragnn/tensorflow_ops.bzl
index 6d5ac9c3..473b7a59 100644
--- a/research/syntaxnet/dragnn/tensorflow_ops.bzl
+++ b/research/syntaxnet/dragnn/tensorflow_ops.bzl
@@ -331,7 +331,7 @@ def tf_cc_test(name, srcs, deps, linkstatic=0, tags=[], data=[], size="medium",
                  linkstatic=linkstatic,
                  tags=tags)
 
-# Part of the testing workflow requires a distinguishable name for the build
+# Part of the testing process requires a distinguishable name for the build
 # rules that involve a GPU, even if otherwise identical to the base rule.
 def tf_cc_test_gpu(name, srcs, deps, linkstatic=0, tags=[], data=[],
                    size="medium", suffix="", args=None):
@@ -534,13 +534,13 @@ def _py_wrap_cc_impl(ctx):
     fail("Exactly one SWIG source file label must be specified.", "srcs")
   module_name = ctx.attr.module_name
   src = ctx.files.srcs[0]
-  inputs = set([src])
+  inputs = depset([src])
   inputs += ctx.files.swig_includes
   for dep in ctx.attr.deps:
     inputs += dep.cc.transitive_headers
   inputs += ctx.files._swiglib
   inputs += ctx.files.toolchain_deps
-  swig_include_dirs = set(_get_repository_roots(ctx, inputs))
+  swig_include_dirs = depset(_get_repository_roots(ctx, inputs))
   swig_include_dirs += sorted([f.dirname for f in ctx.files._swiglib])
   args = ["-c++",
           "-python",
@@ -558,7 +558,7 @@ def _py_wrap_cc_impl(ctx):
              outputs=outputs,
              mnemonic="PythonSwig",
              progress_message="SWIGing " + src.path)
-  return struct(files=set(outputs))
+  return struct(files=depset(outputs))
 
 _py_wrap_cc = rule(
     attrs = {
@@ -627,7 +627,7 @@ def _get_repository_roots(ctx, files):
 
 # Bazel rule for collecting the header files that a target depends on.
 def _transitive_hdrs_impl(ctx):
-  outputs = set()
+  outputs = depset()
   for dep in ctx.attr.deps:
     outputs += dep.cc.transitive_headers
   return struct(files=outputs)
@@ -669,10 +669,10 @@ def tf_custom_op_library_additional_deps():
 # tf_collected_deps will be the union of the deps of the current target
 # and the tf_collected_deps of the dependencies of this target.
 def _collect_deps_aspect_impl(target, ctx):
-  alldeps = set()
+  alldeps = depset()
   if hasattr(ctx.rule.attr, "deps"):
     for dep in ctx.rule.attr.deps:
-      alldeps = alldeps | set([dep.label])
+      alldeps = alldeps | depset([dep.label])
       if hasattr(dep, "tf_collected_deps"):
         alldeps = alldeps | dep.tf_collected_deps
   return struct(tf_collected_deps=alldeps)
diff --git a/research/syntaxnet/dragnn/tools/BUILD b/research/syntaxnet/dragnn/tools/BUILD
index 84a35225..1a7f800a 100644
--- a/research/syntaxnet/dragnn/tools/BUILD
+++ b/research/syntaxnet/dragnn/tools/BUILD
@@ -5,6 +5,18 @@ filegroup(
     srcs = glob(["testdata/**"]),
 )
 
+py_binary(
+    name = "conll_checkpoint_converter",
+    srcs = ["conll_checkpoint_converter.py"],
+    deps = [
+        "//dragnn/protos:spec_py_pb2",
+        "//dragnn/python:dragnn_model_saver_lib",
+        "//dragnn/python:spec_builder",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+        "@org_tensorflow//tensorflow/core:protos_all_py",
+    ],
+)
+
 py_binary(
     name = "evaluator",
     srcs = ["evaluator.py"],
@@ -19,6 +31,21 @@ py_binary(
     ],
 )
 
+py_binary(
+    name = "legacy_parse_to_conll",
+    srcs = ["legacy_parse_to_conll.py"],
+    tags = [
+        "notap",
+        "optonly",
+    ],
+    deps = [
+        ":components",
+        "//dragnn/python:dragnn_ops",
+        "//dragnn/python:evaluation",
+        "//dragnn/python:spec_builder",
+    ],
+)
+
 py_binary(
     name = "segmenter-evaluator",
     srcs = ["segmenter-evaluator.py"],
@@ -35,8 +62,8 @@ py_binary(
 )
 
 py_binary(
-    name = "parse-to-conll",
-    srcs = ["parse-to-conll.py"],
+    name = "parse_to_conll",
+    srcs = ["parse_to_conll.py"],
     tags = [
         "notap",
         "optonly",
@@ -44,6 +71,7 @@ py_binary(
     deps = [
         ":components",
         "//dragnn/python:dragnn_ops",
+        "//dragnn/python:evaluation",
         "//dragnn/python:spec_builder",
     ],
 )
@@ -85,11 +113,9 @@ py_binary(
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/python:evaluation",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
         "//dragnn/python:spec_builder",
         "//dragnn/python:trainer_lib",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "@org_tensorflow//tensorflow:tensorflow_py",
         "@org_tensorflow//tensorflow/core:protos_all_py",
@@ -106,11 +132,9 @@ py_binary(
         "//dragnn/python:dragnn_ops",
         "//dragnn/python:evaluation",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
         "//dragnn/python:spec_builder",
         "//dragnn/python:trainer_lib",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "//syntaxnet:sentence_py_pb2",
         "//syntaxnet:task_spec_py_pb2",
@@ -168,9 +192,7 @@ py_library(
         "//dragnn/core:dragnn_ops",
         "//dragnn/protos:spec_py_pb2",
         "//dragnn/python:graph_builder",
-        "//dragnn/python:load_dragnn_cc_impl_py",
         "//dragnn/python:sentence_io",
-        "//syntaxnet:load_parser_ops_py",
         "//syntaxnet:parser_ops",
         "//syntaxnet:sentence_py_pb2",
         "@org_tensorflow//tensorflow:tensorflow_py",
diff --git a/research/syntaxnet/dragnn/tools/benchmarks/BUILD b/research/syntaxnet/dragnn/tools/benchmarks/BUILD
new file mode 100644
index 00000000..77eeebf4
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/benchmarks/BUILD
@@ -0,0 +1,11 @@
+cc_test(
+    name = "beam_benchmark",
+    srcs = ["beam_benchmark.cc"],
+    deps = [
+        "//dragnn/core:beam",
+        "//dragnn/core/interfaces:cloneable_transition_state",
+        "//dragnn/core/interfaces:transition_state",
+        "//dragnn/core/test:mock_transition_state",
+        "@org_tensorflow//tensorflow/core:test",
+    ],
+)
diff --git a/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc b/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc
new file mode 100644
index 00000000..9e677d2f
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/benchmarks/beam_benchmark.cc
@@ -0,0 +1,193 @@
+// Copyright 2017 Google Inc. All Rights Reserved.
+//
+// Licensed under the Apache License, Version 2.0 (the "License");
+// you may not use this file except in compliance with the License.
+// You may obtain a copy of the License at
+//
+//     http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing, software
+// distributed under the License is distributed on an "AS IS" BASIS,
+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// See the License for the specific language governing permissions and
+// limitations under the License.
+// =============================================================================
+
+#include "dragnn/core/beam.h"
+
+#include <limits>
+#include <random>
+
+#include "dragnn/core/interfaces/cloneable_transition_state.h"
+#include "dragnn/core/interfaces/transition_state.h"
+#include "dragnn/core/test/mock_transition_state.h"
+#include <gmock/gmock.h>
+#include "tensorflow/core/platform/test.h"
+#include "tensorflow/core/platform/test_benchmark.h"
+
+namespace syntaxnet {
+namespace dragnn {
+
+using testing::MockFunction;
+using testing::Ne;
+using testing::Return;
+using testing::_;
+
+namespace {
+
+// *****************************************************************************
+// Test-internal class definitions.
+// *****************************************************************************
+
+// Create a very basic transition state to test the beam. All it does is keep
+// track of its current beam index and score, as well as providing a field
+// for the transition function to write in what transition occurred.
+// Note that this class does not fulfill the entire TransitionState contract,
+// since it is only used in this particular test.
+class TestTransitionState
+    : public CloneableTransitionState<TestTransitionState> {
+ public:
+  TestTransitionState() : is_gold_(false) {}
+
+  void Init(const TransitionState &parent) override {}
+
+  std::unique_ptr<TestTransitionState> Clone() const override {
+    std::unique_ptr<TestTransitionState> ptr(new TestTransitionState());
+    return ptr;
+  }
+
+  int ParentBeamIndex() const override { return parent_beam_index_; }
+
+  // Gets the current beam index for this state.
+  int GetBeamIndex() const override { return beam_index_; }
+
+  // Sets the current beam index for this state.
+  void SetBeamIndex(int index) override { beam_index_ = index; }
+
+  // Gets the score associated with this transition state.
+  float GetScore() const override { return score_; }
+
+  // Sets the score associated with this transition state.
+  void SetScore(float score) override { score_ = score; }
+
+  // Gets the gold-ness of this state (whether it is on the oracle path)
+  bool IsGold() const override { return is_gold_; }
+
+  // Sets the gold-ness of this state.
+  void SetGold(bool is_gold) override { is_gold_ = is_gold; }
+
+  // Depicts this state as an HTML-language string.
+  string HTMLRepresentation() const override { return ""; }
+
+  int parent_beam_index_;
+
+  int beam_index_;
+
+  float score_;
+
+  int transition_action_;
+
+  bool is_gold_;
+};
+
+// This transition function annotates a TestTransitionState with the action that
+// was chosen for the transition.
+auto transition_function = [](TestTransitionState *state, int action) {
+  TestTransitionState *cast_state = dynamic_cast<TestTransitionState *>(state);
+  cast_state->transition_action_ = action;
+};
+
+// Creates oracle and permission functions that do nothing.
+auto null_oracle = [](TestTransitionState *) -> const vector<int> {
+  return {0};
+};
+auto null_permissions = [](TestTransitionState *, int) { return true; };
+auto null_finality = [](TestTransitionState *) { return false; };
+
+// Creates a unique_ptr with a test transition state in it and set its initial
+// score.
+std::unique_ptr<TestTransitionState> CreateState(float score) {
+  std::unique_ptr<TestTransitionState> state;
+  state.reset(new TestTransitionState());
+  state->SetScore(score);
+  return state;
+}
+
+}  // namespace
+
+// *****************************************************************************
+// Tests begin here.
+// *****************************************************************************
+// Helper function for creating random transition matrices of a particular size.
+std::vector<float> MakeRandomVector(int size) {
+  std::default_random_engine engine;
+  std::uniform_real_distribution<float> dist(0., 10.);
+  auto gen = std::bind(dist, engine);
+  std::vector<float> vec(size);
+  std::generate(vec.begin(), vec.end(), gen);
+  return vec;
+}
+
+// Benchmark Beam::FastAdvanceFromPrediction for a beam size of 1 and
+// a variety of transition system sizes.
+void BM_FastAdvance(int num_iters, int num_transitions) {
+  tensorflow::testing::StopTiming();
+
+  // Create a matrix of transitions.
+  constexpr int kMaxBeamSize = 1;
+  const int matrix_size = num_transitions * kMaxBeamSize;
+  const std::vector<float> matrix = MakeRandomVector(matrix_size);
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 4.0;
+  states.push_back(CreateState(kOldScore));
+
+  Beam<TestTransitionState> beam(kMaxBeamSize);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  beam.AdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  ASSERT_EQ(beam.beam().size(), kMaxBeamSize);
+
+  tensorflow::testing::StartTiming();
+  for (int i = 0; i < num_iters; ++i) {
+    beam.FastAdvanceFromPrediction(matrix.data(), num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), kMaxBeamSize);
+}
+BENCHMARK(BM_FastAdvance)->Range(2, 128);
+
+// Benchmark Beam::BeamAdvanceFromPrediction for a variety of beam
+// sizes and transition system sizes.
+void BM_BeamAdvance(int num_iters, int num_transitions, int max_beam_size) {
+  tensorflow::testing::StopTiming();
+
+  // Create a matrix of transitions.
+  const int matrix_size = num_transitions * max_beam_size;
+  const std::vector<float> matrix = MakeRandomVector(matrix_size);
+
+  // Create the beam and transition it.
+  std::vector<std::unique_ptr<TestTransitionState>> states;
+  constexpr float kOldScore = 4.0;
+  states.push_back(CreateState(kOldScore));
+
+  Beam<TestTransitionState> beam(max_beam_size);
+  beam.SetFunctions(null_permissions, null_finality, transition_function,
+                    null_oracle);
+  beam.Init(std::move(states));
+  while (beam.beam().size() < max_beam_size) {
+    beam.AdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), max_beam_size);
+
+  tensorflow::testing::StartTiming();
+  for (int i = 0; i < num_iters; ++i) {
+    beam.BeamAdvanceFromPrediction(matrix.data(), matrix_size, num_transitions);
+  }
+  ASSERT_EQ(beam.beam().size(), max_beam_size);
+}
+BENCHMARK(BM_BeamAdvance)->RangePair(2, 128, 1, 64);
+
+}  // namespace dragnn
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py b/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py
new file mode 100644
index 00000000..980dec2b
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/conll_checkpoint_converter.py
@@ -0,0 +1,103 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Conversion script for CoNLL checkpoints to DRAGNN SavedModel format.
+
+This script loads and finishes a CoNLL checkpoint, then exports it as a
+SavedModel. It expects that the CoNLL RNN cells have been updated using the
+RNN update script.
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+import os
+import tensorflow as tf
+
+from google.protobuf import text_format
+from dragnn.protos import spec_pb2
+from dragnn.python import dragnn_model_saver_lib as saver_lib
+from dragnn.python import spec_builder
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string('master_spec', None, 'Path to task context with '
+                    'inputs and parameters for feature extractors.')
+flags.DEFINE_string('params_path', None, 'Path to trained model parameters.')
+flags.DEFINE_string('export_path', '', 'Output path for exported servo model.')
+flags.DEFINE_string('resource_path', '',
+                    'Base directory for resources in the master spec.')
+flags.DEFINE_bool('export_moving_averages', True,
+                  'Whether to export the moving average parameters.')
+
+
+def export(master_spec_path, params_path, resource_path, export_path,
+           export_moving_averages):
+  """Restores a model and exports it in SavedModel form.
+
+  This method loads a graph specified by the spec at master_spec_path and the
+  params in params_path. It then saves the model in SavedModel format to the
+  location specified in export_path.
+
+  Args:
+    master_spec_path: Path to a proto-text master spec.
+    params_path: Path to the parameters file to export.
+    resource_path: Path to resources in the master spec.
+    export_path: Path to export the SavedModel to.
+    export_moving_averages: Whether to export the moving average parameters.
+  """
+  # Old CoNLL checkpoints did not need a known-word-map. Create a temporary if
+  # that file is missing.
+  if not tf.gfile.Exists(os.path.join(resource_path, 'known-word-map')):
+    with tf.gfile.FastGFile(os.path.join(resource_path, 'known-word-map'),
+                            'w') as out_file:
+      out_file.write('This file intentionally left blank.')
+
+  graph = tf.Graph()
+  master_spec = spec_pb2.MasterSpec()
+  with tf.gfile.FastGFile(master_spec_path) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  # This is a workaround for an issue where the segmenter master-spec had a
+  # spurious resource in it; this resource was not respected in the spec-builder
+  # and ended up crashing the saver (since it didn't really exist).
+  for component in master_spec.component:
+    del component.resource[:]
+
+  spec_builder.complete_master_spec(master_spec, None, resource_path)
+
+  # Remove '/' if it exists at the end of the export path, ensuring that
+  # path utils work correctly.
+  stripped_path = export_path.rstrip('/')
+  saver_lib.clean_output_paths(stripped_path)
+
+  short_to_original = saver_lib.shorten_resource_paths(master_spec)
+  saver_lib.export_master_spec(master_spec, graph)
+  saver_lib.export_to_graph(master_spec, params_path, stripped_path, graph,
+                            export_moving_averages)
+  saver_lib.export_assets(master_spec, short_to_original, stripped_path)
+
+
+def main(unused_argv):
+  # Run the exporter.
+  export(FLAGS.master_spec, FLAGS.params_path, FLAGS.resource_path,
+         FLAGS.export_path, FLAGS.export_moving_averages)
+  tf.logging.info('Export complete.')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/evaluator.py b/research/syntaxnet/dragnn/tools/evaluator.py
index 58d8fbcd..75da5191 100644
--- a/research/syntaxnet/dragnn/tools/evaluator.py
+++ b/research/syntaxnet/dragnn/tools/evaluator.py
@@ -16,7 +16,7 @@
 r"""Runs a DRAGNN model on a given set of CoNLL-formatted sentences.
 
 Sample invocation:
-  bazel run -c opt <...>:dragnn_eval -- \
+  bazel run -c opt <...>:evaluator -- \
     --master_spec="/path/to/master-spec" \
     --checkpoint_file="/path/to/model/name.checkpoint" \
     --input_file="/path/to/input/documents/test.connlu"
@@ -39,9 +39,6 @@ from dragnn.python import sentence_io
 from dragnn.python import spec_builder
 from syntaxnet import sentence_pb2
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py b/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py
new file mode 100644
index 00000000..899e9545
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/legacy_parse_to_conll.py
@@ -0,0 +1,243 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+r"""Runs a both a segmentation and parsing model on a CoNLL dataset.
+"""
+
+import re
+import time
+
+import tensorflow as tf
+
+from google.protobuf import text_format
+from tensorflow.python.client import timeline
+from tensorflow.python.platform import gfile
+
+from dragnn.protos import spec_pb2
+from dragnn.python import evaluation
+from dragnn.python import graph_builder
+from dragnn.python import sentence_io
+from dragnn.python import spec_builder
+from syntaxnet import sentence_pb2
+from syntaxnet.ops import gen_parser_ops
+from syntaxnet.util import check
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+
+flags.DEFINE_string('parser_master_spec', '',
+                    'Path to text file containing a DRAGNN master spec to run.')
+flags.DEFINE_string('parser_checkpoint_file', '',
+                    'Path to trained model checkpoint.')
+flags.DEFINE_string('parser_resource_dir', '',
+                    'Optional base directory for resources in the master spec.')
+flags.DEFINE_string('segmenter_master_spec', '',
+                    'Path to text file containing a DRAGNN master spec to run.')
+flags.DEFINE_string('segmenter_checkpoint_file', '',
+                    'Path to trained model checkpoint.')
+flags.DEFINE_string('segmenter_resource_dir', '',
+                    'Optional base directory for resources in the master spec.')
+flags.DEFINE_bool('complete_master_spec', True, 'Whether the master_specs '
+                  'needs the lexicon and other resources added to them.')
+flags.DEFINE_string('input_file', '',
+                    'File of CoNLL-formatted sentences to read from.')
+flags.DEFINE_string('output_file', '',
+                    'File path to write annotated sentences to.')
+flags.DEFINE_integer('max_batch_size', 2048, 'Maximum batch size to support.')
+flags.DEFINE_string('inference_beam_size', '', 'Comma separated list of '
+                    'component_name=beam_size pairs.')
+flags.DEFINE_string('locally_normalize', '', 'Comma separated list of '
+                    'component names to do local normalization on.')
+flags.DEFINE_integer('threads', 10, 'Number of threads used for intra- and '
+                     'inter-op parallelism.')
+flags.DEFINE_string('timeline_output_file', '', 'Path to save timeline to. '
+                    'If specified, the final iteration of the evaluation loop '
+                    'will capture and save a TensorFlow timeline.')
+flags.DEFINE_bool('use_gold_segmentation', False,
+                  'Whether or not to use gold segmentation.')
+flags.DEFINE_bool('text_format', False, '')
+
+
+def main(unused_argv):
+
+  # Parse the flags containing lists, using regular expressions.
+  # This matches and extracts key=value pairs.
+  component_beam_sizes = re.findall(r'([^=,]+)=(\d+)',
+                                    FLAGS.inference_beam_size)
+  # This matches strings separated by a comma. Does not return any empty
+  # strings.
+  components_to_locally_normalize = re.findall(r'[^,]+',
+                                               FLAGS.locally_normalize)
+
+  ## SEGMENTATION ##
+
+  if not FLAGS.use_gold_segmentation:
+
+    # Reads master spec.
+    master_spec = spec_pb2.MasterSpec()
+    with gfile.FastGFile(FLAGS.segmenter_master_spec) as fin:
+      text_format.Parse(fin.read(), master_spec)
+
+    if FLAGS.complete_master_spec:
+      spec_builder.complete_master_spec(
+          master_spec, None, FLAGS.segmenter_resource_dir)
+
+    # Graph building.
+    tf.logging.info('Building the graph')
+    g = tf.Graph()
+    with g.as_default(), tf.device('/device:CPU:0'):
+      hyperparam_config = spec_pb2.GridPoint()
+      hyperparam_config.use_moving_average = True
+      builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+      annotator = builder.add_annotation()
+      builder.add_saver()
+
+    tf.logging.info('Reading documents...')
+    if FLAGS.text_format:
+      char_corpus = sentence_io.FormatSentenceReader(
+          FLAGS.input_file, 'untokenized-text').corpus()
+    else:
+      input_corpus = sentence_io.ConllSentenceReader(FLAGS.input_file).corpus()
+      with tf.Session(graph=tf.Graph()) as tmp_session:
+        char_input = gen_parser_ops.char_token_generator(input_corpus)
+        char_corpus = tmp_session.run(char_input)
+      check.Eq(len(input_corpus), len(char_corpus))
+
+    session_config = tf.ConfigProto(
+        log_device_placement=False,
+        intra_op_parallelism_threads=FLAGS.threads,
+        inter_op_parallelism_threads=FLAGS.threads)
+
+    with tf.Session(graph=g, config=session_config) as sess:
+      tf.logging.info('Initializing variables...')
+      sess.run(tf.global_variables_initializer())
+      tf.logging.info('Loading from checkpoint...')
+      sess.run('save/restore_all',
+               {'save/Const:0': FLAGS.segmenter_checkpoint_file})
+
+      tf.logging.info('Processing sentences...')
+
+      processed = []
+      start_time = time.time()
+      run_metadata = tf.RunMetadata()
+      for start in range(0, len(char_corpus), FLAGS.max_batch_size):
+        end = min(start + FLAGS.max_batch_size, len(char_corpus))
+        feed_dict = {annotator['input_batch']: char_corpus[start:end]}
+        if FLAGS.timeline_output_file and end == len(char_corpus):
+          serialized_annotations = sess.run(
+              annotator['annotations'], feed_dict=feed_dict,
+              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+              run_metadata=run_metadata)
+          trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+          with open(FLAGS.timeline_output_file, 'w') as trace_file:
+            trace_file.write(trace.generate_chrome_trace_format())
+        else:
+          serialized_annotations = sess.run(
+              annotator['annotations'], feed_dict=feed_dict)
+        processed.extend(serialized_annotations)
+
+      tf.logging.info('Processed %d documents in %.2f seconds.',
+                      len(char_corpus), time.time() - start_time)
+
+    input_corpus = processed
+  else:
+    input_corpus = sentence_io.ConllSentenceReader(FLAGS.input_file).corpus()
+
+  ## PARSING
+
+  # Reads master spec.
+  master_spec = spec_pb2.MasterSpec()
+  with gfile.FastGFile(FLAGS.parser_master_spec) as fin:
+    text_format.Parse(fin.read(), master_spec)
+
+  if FLAGS.complete_master_spec:
+    spec_builder.complete_master_spec(
+        master_spec, None, FLAGS.parser_resource_dir)
+
+  # Graph building.
+  tf.logging.info('Building the graph')
+  g = tf.Graph()
+  with g.as_default(), tf.device('/device:CPU:0'):
+    hyperparam_config = spec_pb2.GridPoint()
+    hyperparam_config.use_moving_average = True
+    builder = graph_builder.MasterBuilder(master_spec, hyperparam_config)
+    annotator = builder.add_annotation()
+    builder.add_saver()
+
+  tf.logging.info('Reading documents...')
+
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=FLAGS.threads,
+      inter_op_parallelism_threads=FLAGS.threads)
+
+  with tf.Session(graph=g, config=session_config) as sess:
+    tf.logging.info('Initializing variables...')
+    sess.run(tf.global_variables_initializer())
+
+    tf.logging.info('Loading from checkpoint...')
+    sess.run('save/restore_all', {'save/Const:0': FLAGS.parser_checkpoint_file})
+
+    tf.logging.info('Processing sentences...')
+
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    for start in range(0, len(input_corpus), FLAGS.max_batch_size):
+      end = min(start + FLAGS.max_batch_size, len(input_corpus))
+      feed_dict = {annotator['input_batch']: input_corpus[start:end]}
+      for comp, beam_size in component_beam_sizes:
+        feed_dict['%s/InferenceBeamSize:0' % comp] = beam_size
+      for comp in components_to_locally_normalize:
+        feed_dict['%s/LocallyNormalize:0' % comp] = True
+      if FLAGS.timeline_output_file and end == len(input_corpus):
+        serialized_annotations = sess.run(
+            annotator['annotations'], feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(FLAGS.timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(
+            annotator['annotations'], feed_dict=feed_dict)
+      processed.extend(serialized_annotations)
+
+    tf.logging.info('Processed %d documents in %.2f seconds.',
+                    len(input_corpus), time.time() - start_time)
+    _, uas, las = evaluation.calculate_parse_metrics(input_corpus, processed)
+    tf.logging.info('UAS: %.2f', uas)
+    tf.logging.info('LAS: %.2f', las)
+
+    if FLAGS.output_file:
+      with gfile.GFile(FLAGS.output_file, 'w') as f:
+        f.write('## tf:{}\n'.format(FLAGS.text_format))
+        f.write('## gs:{}\n'.format(FLAGS.use_gold_segmentation))
+        for serialized_sentence in processed:
+          sentence = sentence_pb2.Sentence()
+          sentence.ParseFromString(serialized_sentence)
+          f.write('# text = {}\n'.format(sentence.text.encode('utf-8')))
+          for i, token in enumerate(sentence.token):
+            head = token.head + 1
+            f.write('%s\t%s\t_\t_\t_\t_\t%d\t%s\t_\t_\n'%(
+                i + 1,
+                token.word.encode('utf-8'), head,
+                token.label.encode('utf-8')))
+          f.write('\n')
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/model_trainer.py b/research/syntaxnet/dragnn/tools/model_trainer.py
index 724122a0..da8d6fb7 100755
--- a/research/syntaxnet/dragnn/tools/model_trainer.py
+++ b/research/syntaxnet/dragnn/tools/model_trainer.py
@@ -55,9 +55,6 @@ from dragnn.python import trainer_lib
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/oss_setup.py b/research/syntaxnet/dragnn/tools/oss_setup.py
index ea7c57c7..fa749b82 100644
--- a/research/syntaxnet/dragnn/tools/oss_setup.py
+++ b/research/syntaxnet/dragnn/tools/oss_setup.py
@@ -56,7 +56,7 @@ setuptools.setup(
     version='0.2',
     description='SyntaxNet: Neural Models of Syntax',
     long_description='',
-    url='https://github.com/tensorflow/models/tree/master/research/syntaxnet',
+    url='https://github.com/tensorflow/models/tree/master/syntaxnet',
     author='Google Inc.',
     author_email='opensource@google.com',
 
diff --git a/research/syntaxnet/dragnn/tools/parse-to-conll.py b/research/syntaxnet/dragnn/tools/parse-to-conll.py
index c4cfdd87..11f4a3b1 100644
--- a/research/syntaxnet/dragnn/tools/parse-to-conll.py
+++ b/research/syntaxnet/dragnn/tools/parse-to-conll.py
@@ -33,9 +33,6 @@ from syntaxnet import sentence_pb2
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/parse_to_conll.py b/research/syntaxnet/dragnn/tools/parse_to_conll.py
new file mode 100644
index 00000000..76268b7d
--- /dev/null
+++ b/research/syntaxnet/dragnn/tools/parse_to_conll.py
@@ -0,0 +1,283 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+r"""Runs a both a segmentation and parsing model on a CoNLL dataset.
+"""
+
+import re
+import time
+import tensorflow as tf
+
+from tensorflow.python.client import timeline
+from tensorflow.python.platform import gfile
+
+# The following line is necessary to load custom ops into the library.
+from dragnn.python import dragnn_ops
+
+from dragnn.python import evaluation
+from dragnn.python import sentence_io
+from syntaxnet import sentence_pb2
+
+# The following line is necessary to load custom ops into the library.
+from syntaxnet import syntaxnet_ops
+
+from syntaxnet.ops import gen_parser_ops
+from syntaxnet.util import check
+
+flags = tf.app.flags
+FLAGS = flags.FLAGS
+
+flags.DEFINE_string(
+    'segmenter_saved_model', None,
+    'Path to segmenter saved model. If not provided, gold segmentation is used.'
+)
+flags.DEFINE_string('parser_saved_model', None, 'Path to parser saved model.')
+
+flags.DEFINE_string('input_file', '',
+                    'File of CoNLL-formatted sentences to read from.')
+flags.DEFINE_string('output_file', '',
+                    'File path to write annotated sentences to.')
+flags.DEFINE_bool('text_format', False, '')
+
+flags.DEFINE_integer('max_batch_size', 2048, 'Maximum batch size to support.')
+flags.DEFINE_string('inference_beam_size', '', 'Comma separated list of '
+                    'component_name=beam_size pairs.')
+flags.DEFINE_string('locally_normalize', '', 'Comma separated list of '
+                    'component names to do local normalization on.')
+
+flags.DEFINE_integer('threads', 10, 'Number of threads used for intra- and '
+                     'inter-op parallelism.')
+flags.DEFINE_string('timeline_output_file', '', 'Path to save timeline to. '
+                    'If specified, the final iteration of the evaluation loop '
+                    'will capture and save a TensorFlow timeline.')
+
+
+def get_segmenter_corpus(input_data_path, use_text_format):
+  """Reads in a character corpus for segmenting."""
+  # Read in the documents.
+  tf.logging.info('Reading documents...')
+  if use_text_format:
+    char_corpus = sentence_io.FormatSentenceReader(input_data_path,
+                                                   'untokenized-text').corpus()
+  else:
+    input_corpus = sentence_io.ConllSentenceReader(input_data_path).corpus()
+    with tf.Session(graph=tf.Graph()) as tmp_session:
+      char_input = gen_parser_ops.char_token_generator(input_corpus)
+      char_corpus = tmp_session.run(char_input)
+    check.Eq(len(input_corpus), len(char_corpus))
+
+  return char_corpus
+
+
+def run_segmenter(input_data, segmenter_model, session_config, max_batch_size,
+                  timeline_output_file=None):
+  """Runs the provided segmenter model on the provided character corpus.
+
+  Args:
+    input_data: Character input corpus to segment.
+    segmenter_model: Path to a SavedModel file containing the segmenter graph.
+    session_config: A session configuration object.
+    max_batch_size: The maximum batch size to use.
+    timeline_output_file: Filepath for timeline export. Does not export if None.
+
+  Returns:
+    A list of segmented sentences suitable for parsing.
+  """
+  # Create the session and graph, and load the SavedModel.
+  g = tf.Graph()
+  with tf.Session(graph=g, config=session_config) as sess:
+    tf.logging.info('Initializing segmentation model...')
+    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                               segmenter_model)
+
+    # Use the graph to segment the sentences.
+    tf.logging.info('Segmenting sentences...')
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    for start in range(0, len(input_data), max_batch_size):
+      # Prepare the inputs.
+      end = min(start + max_batch_size, len(input_data))
+      feed_dict = {
+          'annotation/ComputeSession/InputBatch:0': input_data[start:end]
+      }
+      output_node = 'annotation/annotations:0'
+
+      # Process.
+      tf.logging.info('Processing examples %d to %d' % (start, end))
+      if timeline_output_file and end == len(input_data):
+        serialized_annotations = sess.run(
+            output_node,
+            feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(output_node, feed_dict=feed_dict)
+
+      # Save the outputs.
+      processed.extend(serialized_annotations)
+
+  # Report statistics.
+  tf.logging.info('Segmented %d documents in %.2f seconds.',
+                  len(input_data), time.time() - start_time)
+
+  # Once all sentences are segmented, the processed data can be used in the
+  # parsers.
+  return processed
+
+
+def run_parser(input_data, parser_model, session_config, beam_sizes,
+               locally_normalized_components, max_batch_size,
+               timeline_output_file):
+  """Runs the provided segmenter model on the provided character corpus.
+
+  Args:
+    input_data: Input corpus to parse.
+    parser_model: Path to a SavedModel file containing the parser graph.
+    session_config: A session configuration object.
+    beam_sizes: A dict of component names : beam sizes (optional).
+    locally_normalized_components: A list of components to normalize (optional).
+    max_batch_size: The maximum batch size to use.
+    timeline_output_file: Filepath for timeline export. Does not export if None.
+
+  Returns:
+    A list of parsed sentences.
+  """
+  parser_graph = tf.Graph()
+  with tf.Session(graph=parser_graph, config=session_config) as sess:
+    tf.logging.info('Initializing parser model...')
+    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING],
+                               parser_model)
+
+    tf.logging.info('Parsing sentences...')
+
+    processed = []
+    start_time = time.time()
+    run_metadata = tf.RunMetadata()
+    tf.logging.info('Corpus length is %d' % len(input_data))
+    for start in range(0, len(input_data), max_batch_size):
+      # Set up the input and output.
+      end = min(start + max_batch_size, len(input_data))
+      feed_dict = {
+          'annotation/ComputeSession/InputBatch:0': input_data[start:end]
+      }
+      for comp, beam_size in beam_sizes:
+        feed_dict['%s/InferenceBeamSize:0' % comp] = beam_size
+      for comp in locally_normalized_components:
+        feed_dict['%s/LocallyNormalize:0' % comp] = True
+      output_node = 'annotation/annotations:0'
+
+      # Process.
+      tf.logging.info('Processing examples %d to %d' % (start, end))
+      if timeline_output_file and end == len(input_data):
+        serialized_annotations = sess.run(
+            output_node,
+            feed_dict=feed_dict,
+            options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
+            run_metadata=run_metadata)
+        trace = timeline.Timeline(step_stats=run_metadata.step_stats)
+        with open(timeline_output_file, 'w') as trace_file:
+          trace_file.write(trace.generate_chrome_trace_format())
+      else:
+        serialized_annotations = sess.run(output_node, feed_dict=feed_dict)
+
+      processed.extend(serialized_annotations)
+
+    tf.logging.info('Processed %d documents in %.2f seconds.',
+                    len(input_data), time.time() - start_time)
+    _, uas, las = evaluation.calculate_parse_metrics(input_data, processed)
+    tf.logging.info('UAS: %.2f', uas)
+    tf.logging.info('LAS: %.2f', las)
+
+  return processed
+
+
+def print_output(output_file, use_text_format, use_gold_segmentation, output):
+  """Writes a set of sentences in CoNLL format.
+
+  Args:
+    output_file: The file to write to.
+    use_text_format: Whether this computation used text-format input.
+    use_gold_segmentation: Whether this computation used gold segmentation.
+    output: A list of sentences to write to the output file.
+  """
+  with gfile.GFile(output_file, 'w') as f:
+    f.write('## tf:{}\n'.format(use_text_format))
+    f.write('## gs:{}\n'.format(use_gold_segmentation))
+    for serialized_sentence in output:
+      sentence = sentence_pb2.Sentence()
+      sentence.ParseFromString(serialized_sentence)
+      f.write('# text = {}\n'.format(sentence.text.encode('utf-8')))
+      for i, token in enumerate(sentence.token):
+        head = token.head + 1
+        f.write('%s\t%s\t_\t_\t_\t_\t%d\t%s\t_\t_\n' %
+                (i + 1, token.word.encode('utf-8'), head,
+                 token.label.encode('utf-8')))
+      f.write('\n')
+
+
+def main(unused_argv):
+  # Validate that we have a parser saved model passed to this script.
+  if FLAGS.parser_saved_model is None:
+    tf.logging.fatal('A parser saved model must be provided.')
+
+  # Parse the flags containint lists, using regular expressions.
+  # This matches and extracts key=value pairs.
+  component_beam_sizes = re.findall(r'([^=,]+)=(\d+)',
+                                    FLAGS.inference_beam_size)
+  tf.logging.info('Found beam size dict %s' % component_beam_sizes)
+
+  # This matches strings separated by a comma. Does not return any empty
+  # strings.
+  components_to_locally_normalize = re.findall(r'[^,]+',
+                                               FLAGS.locally_normalize)
+  tf.logging.info(
+      'Found local normalization dict %s' % components_to_locally_normalize)
+
+  # Create a session config with the requested number of threads.
+  session_config = tf.ConfigProto(
+      log_device_placement=False,
+      intra_op_parallelism_threads=FLAGS.threads,
+      inter_op_parallelism_threads=FLAGS.threads)
+
+  # Get the segmented input data for the parser, either by running the
+  # segmenter ourselves or by simply reading it from the CoNLL file.
+  if FLAGS.segmenter_saved_model is None:
+    # If no segmenter was provided, we must use the data from the CONLL file.
+    input_file = FLAGS.input_file
+    parser_input = sentence_io.ConllSentenceReader(input_file).corpus()
+    use_gold_segmentation = True
+  else:
+    # If the segmenter was provided, use it.
+    segmenter_input = get_segmenter_corpus(FLAGS.input_file, FLAGS.text_format)
+    parser_input = run_segmenter(segmenter_input, FLAGS.segmenter_saved_model,
+                                 session_config, FLAGS.max_batch_size,
+                                 FLAGS.timeline_output_file)
+    use_gold_segmentation = False
+
+  # Now that we have parser input data, parse.
+  processed = run_parser(parser_input, FLAGS.parser_saved_model, session_config,
+                         component_beam_sizes, components_to_locally_normalize,
+                         FLAGS.max_batch_size, FLAGS.timeline_output_file)
+
+  if FLAGS.output_file:
+    print_output(FLAGS.output_file, FLAGS.text_format, use_gold_segmentation,
+                 processed)
+
+
+if __name__ == '__main__':
+  tf.app.run()
diff --git a/research/syntaxnet/dragnn/tools/parser_trainer.py b/research/syntaxnet/dragnn/tools/parser_trainer.py
index 0c0c009f..1ab37b63 100644
--- a/research/syntaxnet/dragnn/tools/parser_trainer.py
+++ b/research/syntaxnet/dragnn/tools/parser_trainer.py
@@ -40,9 +40,6 @@ from dragnn.python import sentence_io
 from dragnn.python import spec_builder
 from dragnn.python import trainer_lib
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/segmenter-evaluator.py b/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
index ce0558a9..3256017c 100644
--- a/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
+++ b/research/syntaxnet/dragnn/tools/segmenter-evaluator.py
@@ -42,9 +42,6 @@ from syntaxnet import sentence_pb2
 from syntaxnet.ops import gen_parser_ops
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/segmenter_trainer.py b/research/syntaxnet/dragnn/tools/segmenter_trainer.py
index 7c1e6dd0..d227da15 100644
--- a/research/syntaxnet/dragnn/tools/segmenter_trainer.py
+++ b/research/syntaxnet/dragnn/tools/segmenter_trainer.py
@@ -42,9 +42,6 @@ from dragnn.python import lexicon
 from dragnn.python import spec_builder
 from dragnn.python import trainer_lib
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/tools/trainer.py b/research/syntaxnet/dragnn/tools/trainer.py
index ba59b615..3952d62e 100644
--- a/research/syntaxnet/dragnn/tools/trainer.py
+++ b/research/syntaxnet/dragnn/tools/trainer.py
@@ -45,9 +45,6 @@ from dragnn.python import trainer_lib
 
 from syntaxnet.util import check
 
-import dragnn.python.load_dragnn_cc_impl
-import syntaxnet.load_parser_ops
-
 flags = tf.app.flags
 FLAGS = flags.FLAGS
 
diff --git a/research/syntaxnet/dragnn/viz/node_info.tsx b/research/syntaxnet/dragnn/viz/node_info.tsx
new file mode 100644
index 00000000..0185caea
--- /dev/null
+++ b/research/syntaxnet/dragnn/viz/node_info.tsx
@@ -0,0 +1,212 @@
+
+/**
+ * Template for node info.
+ */
+goog.module('nlp.saft.opensource.dragnn.viz.node_info');
+import preact from 'preact';
+import _ from 'lodash';
+
+const normalCell = {
+  'border': 0,
+  'border-collapse': 'separate',
+  'padding': '2px',
+};
+
+/**
+ * Style definitions which are directly injected (see README.md comments).
+ */
+const style = {
+  featuresTable: {
+    'background-color': 'rgba(255, 255, 255, 0.9)',
+    'border': '1px solid #dddddd',
+    'border-spacing': '2px',
+    'border-collapse': 'separate',
+    'font-family': 'roboto, helvectica, arial, sans-serif',
+    // Sometimes state strings (`stateHtml`) get long, and because this is an
+    // absolutely-positioned box, we need to make them wrap around.
+    'max-width': '600px',
+    'position': 'absolute',
+  },
+
+  heading: {
+    'background-color': '#ebf5fb',
+    'font-weight': 'bold',
+    'text-align': 'center',
+    ...normalCell
+  },
+
+  normalCell: normalCell,
+
+  featureGroup: (componentColor) => ({
+    'background-color': componentColor,
+    'font-weight': 'bold',
+    ...normalCell
+  }),
+
+  normalRow: {
+    'border': 0,
+    'border-collapse': 'separate',
+  },
+};
+
+/**
+ * Creates table rows that negate IPython/Jupyter notebook styling.
+ *
+ * @param {?XML|?Array<XML>} children Child nodes. (Recall Preact handles
+ *     null/undefined gracefully).
+ * @param {!Object} props Any additional properties.
+ * @return {!XML} React-y element, representing a table row.
+ */
+const Row = ({children, ...props}) => (
+  <tr style={style.normalRow} {...props}>{children}</tr>);
+
+/**
+ * Creates table cells that negate IPython/Jupyter notebook styling.
+ *
+ * @param {?XML|?Array<XML>} children Child nodes. (Recall Preact handles
+ *     null/undefined gracefully).
+ * @param {!Object} props Any additional properties.
+ * @return {!XML} React-y element, representing a table cell.
+ */
+const Cell = ({children, ...props}) => (
+  <td style={style.normalCell} {...props}>{children}</td>);
+
+/**
+ * Construct a table "multi-row" with a shared "header" cell.
+ *
+ * In ASCII-art,
+ *
+ * ------------------------------
+ *        | row1
+ * header | row2
+ *        | row3
+ * ------------------------------
+ *
+ * @param {string} headerText Text for the header cell
+ * @param {string} headerColor Color of the header cell
+ * @param {!Array<XML>} rowsCells Row cells (<td> React-y elements).
+ * @return {!Array<XML>} Array of React-y elements.
+ */
+const featureGroup = (headerText, headerColor, rowsCells) => {
+  const headerCell = (
+    <td rowspan={rowsCells.length} style={style.featureGroup(headerColor)}>
+      {headerText}
+    </td>
+  );
+  return _.map(rowsCells, (cells, i) => {
+    return <Row>{i == 0 ? headerCell : null}{cells}</Row>;
+  });
+};
+
+/**
+ * Mini helper to intersperse line breaks with a list of elements.
+ *
+ * This just replicates previous behavior and looks OK; we could also try spans
+ * with `display: 'block'` or such.
+ *
+ * @param {!Array<XML>} elements React-y elements.
+ * @return {!Array<XML>} React-y elements with line breaks.
+ */
+const intersperseLineBreaks = (elements) => _.tail(_.flatten(_.map(
+  elements, (v) => [<br />, v]
+)));
+
+export default class NodeInfo extends preact.Component {
+  /**
+   * Obligatory Preact render() function.
+   *
+   * It might be worthwhile converting some of the intermediate variables into
+   * stateless functional components, like Cell and Row.
+   *
+   * @param {?Object} selected Cytoscape node selected (null if no selection).
+   * @param {?Object} mousePosition Mouse position, if a node is selected.
+   * @return {!XML} Preact components to render.
+   */
+  render({selected, mousePosition}) {
+    const visible = selected != null;
+    const stateHtml = visible && selected.data('stateInfo');
+
+    // Generates elements for fixed features.
+    const fixedFeatures = visible ? selected.data('fixedFeatures') : [];
+    const fixedFeatureElements = _.map(fixedFeatures, (feature) => {
+      if (feature.value_trace.length == 0) {
+        // Preact will just prune this out.
+        return null;
+      } else {
+        const rowsCells = _.map(feature.value_trace, (value) => {
+          // Recall `value_name` is a list of strings (representing feature
+          // values), but this is OK because strings are valid react elements.
+          const valueCells = intersperseLineBreaks(value.value_name);
+          return [<Cell>{value.feature_name}</Cell>, <Cell>{valueCells}</Cell>];
+        });
+        return featureGroup(feature.name, '#cccccc', _.map(rowsCells));
+      }
+    });
+
+    /**
+     * Generates linked feature info from an edge.
+     *
+     * @param {!Object} edge Cytoscape JS Element representing a linked feature.
+     * @return {[XML,XML]} Linked feature information, as table elements.
+     */
+    const linkedFeatureInfoFromEdge = (edge) => {
+      return [
+        <Cell>{edge.data('featureName')}</Cell>,
+        <Cell>
+          value {edge.data('featureValue')} from
+          step {edge.source().data('stepIdx')}
+        </Cell>
+      ];
+    };
+
+    const linkedFeatureElements = _.flatten(
+      _.map(this.edgeStatesByComponent(), (edges, componentName) => {
+        // Because edges are generated by `incomers`, it is guaranteed to be
+        // non-empty.
+        const color = _.head(edges).source().parent().data('componentColor');
+        const rowsCells = _.map(edges, linkedFeatureInfoFromEdge);
+        return featureGroup(componentName, color, rowsCells);
+      }));
+
+    let positionOrHiddenStyle;
+    if (visible) {
+      positionOrHiddenStyle = {
+        left: mousePosition.x + 20,
+        top: mousePosition.y + 10,
+      };
+    } else {
+      positionOrHiddenStyle = {display: 'none'};
+    }
+
+    return (
+      <table style={_.defaults(positionOrHiddenStyle, style.featuresTable)}>
+        <Row>
+          <td colspan="3" style={style.heading}>State</td>
+        </Row>
+        <Row>
+          <Cell colspan="3">{stateHtml}</Cell>
+        </Row>
+        <Row>
+          <td colspan="3" style={style.heading}>Features</td>
+        </Row>
+        {fixedFeatureElements}
+        {linkedFeatureElements}
+      </table>
+    );
+  }
+
+  /**
+   * Gets a list of incoming edges, grouped by their component name.
+   *
+   * @return {!Object<string, !Array<!Object>>} Map from component name to list
+   *     of edges.
+   */
+  edgeStatesByComponent() {
+    if (this.props.selected == null) {
+      return [];
+    }
+    const incoming = this.props.selected.incomers();  // edges and nodes
+    return _.groupBy(incoming.edges(), (edge) => edge.source().parent().id());
+  }
+}
+
diff --git a/research/syntaxnet/g3doc/METADATA b/research/syntaxnet/g3doc/METADATA
deleted file mode 100644
index fbb76fcd..00000000
--- a/research/syntaxnet/g3doc/METADATA
+++ /dev/null
@@ -1,13 +0,0 @@
-# Format: google3/devtools/metadata/metadata.proto (go/google3metadata)
-name: "syntaxnet"
-# Use "base" template
-g3doc {
-    headerfooter {
-      path_regexp: ".*\\.md$"
-      name: "base"
-    }
-    navbar_file : "/company/teams/saft/navbar.md"
-    logo : "/company/teams/saft/images/logo.png"
-    favicon : "/company/teams/saft/images/saft-favicon.png"
-}
-teams_product_id: 7805219680
diff --git a/research/syntaxnet/g3doc/dragnn_ops.md b/research/syntaxnet/g3doc/dragnn_ops.md
index 9c92ab52..2355cee6 100644
--- a/research/syntaxnet/g3doc/dragnn_ops.md
+++ b/research/syntaxnet/g3doc/dragnn_ops.md
@@ -3,7 +3,7 @@
 ### Module `dragnn_ops`
 
 Defined in
-[`tensorflow/dragnn/python/dragnn_ops.py`](https://github.com/tensorflow/models/blob/master/research/syntaxnet/dragnn/python/dragnn_ops.py).
+[`tensorflow/dragnn/python/dragnn_ops.py`](https://github.com/tensorflow/models/blob/master/syntaxnet/dragnn/python/dragnn_ops.py).
 
 Groups the DRAGNN TensorFlow ops in one module.
 
diff --git a/research/syntaxnet/g3doc/dragnn_ops/google3.md b/research/syntaxnet/g3doc/dragnn_ops/google3.md
deleted file mode 100644
index 95a0abbc..00000000
--- a/research/syntaxnet/g3doc/dragnn_ops/google3.md
+++ /dev/null
@@ -1,9 +0,0 @@
-# Module: dragnn_ops.google3
-
-### Module `dragnn_ops.google3`
-
-This is the root of the google3 tree.
-
-Code in here is built by the Google3 build system.
-
-## Members
diff --git a/research/syntaxnet/g3doc/syntaxnet-tutorial.md b/research/syntaxnet/g3doc/syntaxnet-tutorial.md
index 4794e93b..56f66bdd 100644
--- a/research/syntaxnet/g3doc/syntaxnet-tutorial.md
+++ b/research/syntaxnet/g3doc/syntaxnet-tutorial.md
@@ -87,7 +87,8 @@ Note that `stack` here means "words we have already tagged." Thus, this feature
 spec uses three types of features: words, suffixes, and prefixes. The features
 are grouped into blocks that share an embedding matrix, concatenated together,
 and fed into a chain of hidden layers. This structure is based upon the model
-proposed by [Chen and Manning (2014)](http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf).
+proposed by [Chen and Manning (2014)]
+(http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf).
 
 We show this layout in the schematic below: the state of the system (a stack and
 a buffer, visualized below for both the POS and the dependency parsing task) is
diff --git a/research/syntaxnet/syntaxnet/BUILD b/research/syntaxnet/syntaxnet/BUILD
index aafd1695..9f60f42c 100644
--- a/research/syntaxnet/syntaxnet/BUILD
+++ b/research/syntaxnet/syntaxnet/BUILD
@@ -331,6 +331,8 @@ cc_library(
         "binary_segment_state.cc",
         "binary_segment_transitions.cc",
         "char_shift_transitions.cc",
+        "head_label_transitions.cc",
+        "head_label_transitions.h",
         "head_transitions.cc",
         "head_transitions.h",
         "label_transitions.cc",
@@ -353,6 +355,7 @@ cc_library(
     deps = [
         ":base",
         ":feature_extractor",
+        ":generic_features",
         ":morphology_label_set",
         ":registry",
         ":segmenter_utils",
@@ -399,6 +402,16 @@ cc_library(
     ],
 )
 
+cc_library(
+    name = "generic_features",
+    srcs = ["generic_features.cc"],
+    hdrs = ["generic_features.h"],
+    deps = [
+        ":feature_extractor",
+        ":registry",
+    ],
+)
+
 cc_library(
     name = "sentence_batch",
     srcs = ["sentence_batch.cc"],
@@ -510,6 +523,7 @@ filegroup(
     srcs = [
         "testdata/context.pbtxt",
         "testdata/document",
+        "testdata/hello.txt",
         "testdata/mini-training-set",
     ],
 )
@@ -572,6 +586,17 @@ cc_test(
     ],
 )
 
+cc_test(
+    name = "generic_features_test",
+    srcs = ["generic_features_test.cc"],
+    deps = [
+        ":generic_features",
+        ":registry",
+        ":task_context",
+        ":test_main",
+    ],
+)
+
 cc_test(
     name = "sentence_features_test",
     size = "medium",
@@ -712,6 +737,20 @@ cc_test(
     ],
 )
 
+cc_test(
+    name = "head_label_transitions_test",
+    size = "small",
+    srcs = ["head_label_transitions_test.cc"],
+    deps = [
+        ":base",
+        ":parser_transitions",
+        ":sentence_proto",
+        ":task_context",
+        ":term_frequency_map",
+        ":test_main",
+    ],
+)
+
 cc_test(
     name = "parser_features_test",
     size = "small",
@@ -750,8 +789,8 @@ py_library(
     name = "syntaxnet_ops",
     srcs = ["syntaxnet_ops.py"],
     deps = [
-        ":parser_ops",
         ":load_parser_ops_py",
+        ":parser_ops",
     ],
 )
 
diff --git a/research/syntaxnet/syntaxnet/arc_standard_transitions.cc b/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
index 24b94dbf..8feebe1a 100644
--- a/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
+++ b/research/syntaxnet/syntaxnet/arc_standard_transitions.cc
@@ -269,7 +269,9 @@ class ArcStandardTransitionSystem : public ParserTransitionSystem {
   void PerformRightArc(ParserState *state, int label) const {
     DCHECK(IsAllowedRightArc(*state));
     int s0 = state->Pop();
-    state->AddArc(s0, state->Top(), label);
+    int s1 = state->Pop();
+    state->AddArc(s0, s1, label);
+    state->Push(s1);
   }
 
   // We are in a deterministic state when we either reached the end of the input
diff --git a/research/syntaxnet/syntaxnet/base.h b/research/syntaxnet/syntaxnet/base.h
index d77c6b9b..a60bce3b 100644
--- a/research/syntaxnet/syntaxnet/base.h
+++ b/research/syntaxnet/syntaxnet/base.h
@@ -21,6 +21,7 @@ limitations under the License.
 #include <unordered_map>
 #include <unordered_set>
 #include <vector>
+
 #include "tensorflow/core/lib/core/status.h"
 #include "tensorflow/core/lib/strings/strcat.h"
 #include "tensorflow/core/lib/strings/stringprintf.h"
@@ -30,11 +31,14 @@ limitations under the License.
 
 
 
+using tensorflow::int8;
+using tensorflow::int16;
 using tensorflow::int32;
 using tensorflow::int64;
+using tensorflow::uint8;
+using tensorflow::uint16;
 using tensorflow::uint64;
 using tensorflow::uint32;
-using tensorflow::uint32;
 using tensorflow::protobuf::TextFormat;
 using tensorflow::mutex_lock;
 using tensorflow::mutex;
@@ -48,6 +52,7 @@ typedef signed int char32;
 using tensorflow::StringPiece;
 using std::string;
 
+
   // namespace syntaxnet
 
 #endif  // SYNTAXNET_BASE_H_
diff --git a/research/syntaxnet/syntaxnet/binary_segment_transitions.cc b/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
index 5fa44958..6fddfced 100644
--- a/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
+++ b/research/syntaxnet/syntaxnet/binary_segment_transitions.cc
@@ -28,8 +28,7 @@ namespace syntaxnet {
 //  -MERGE: adds the token at state.input to its prevous word, and also advances
 //          state.input.
 //
-// Also see nlp/saft/components/segmentation/transition/binary-segment-state.h
-// for examples on handling spaces.
+// Also see binary_segment_state.h for examples on handling spaces.
 class BinarySegmentTransitionSystem : public ParserTransitionSystem {
  public:
   BinarySegmentTransitionSystem() {}
diff --git a/research/syntaxnet/syntaxnet/char_properties.cc b/research/syntaxnet/syntaxnet/char_properties.cc
index 8ac9f87d..cd514616 100644
--- a/research/syntaxnet/syntaxnet/char_properties.cc
+++ b/research/syntaxnet/syntaxnet/char_properties.cc
@@ -203,8 +203,8 @@ void CharProperty::AddAsciiPredicate(AsciiPredicate *pred) {
 
 void CharProperty::AddCharProperty(const char *propname) {
   const CharProperty *prop = CharProperty::Lookup(propname);
-  CHECK(prop != NULL) << ": unknown char property \"" << propname
-                      << "\" in " << name_;
+  CHECK(prop != nullptr) << ": unknown char property \"" << propname << "\" in "
+                         << name_;
   int c = -1;
   while ((c = prop->NextElementAfter(c)) >= 0) {
     AddChar(c);
@@ -268,10 +268,10 @@ const CharProperty *CharProperty::Lookup(const char *subclass) {
   // the CharProperty it provides.
   std::unique_ptr<CharPropertyWrapper> wrapper(
       CharPropertyWrapper::Create(subclass));
-  if (wrapper.get() == NULL) {
+  if (wrapper == nullptr) {
     LOG(ERROR) << "CharPropertyWrapper not found for subclass: "
                << "\"" << subclass << "\"";
-    return NULL;
+    return nullptr;
   }
   return wrapper->GetCharProperty();
 }
diff --git a/research/syntaxnet/syntaxnet/char_properties.h b/research/syntaxnet/syntaxnet/char_properties.h
index cfb007f7..9980922a 100644
--- a/research/syntaxnet/syntaxnet/char_properties.h
+++ b/research/syntaxnet/syntaxnet/char_properties.h
@@ -357,6 +357,8 @@ DECLARE_CHAR_PROPERTY(directional_formatting_code);
 // just those listed in our code. See the definitions in char_properties.cc.
 DECLARE_CHAR_PROPERTY(punctuation_or_symbol);
 
+DECLARE_SYNTAXNET_CLASS_REGISTRY("char property wrapper", CharPropertyWrapper);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_CHAR_PROPERTIES_H_
diff --git a/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc b/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
index 65beb516..b5b874ed 100644
--- a/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
+++ b/research/syntaxnet/syntaxnet/char_shift_transitions_test.cc
@@ -118,6 +118,7 @@ class CharShiftTransitionTest : public ::testing::Test {
  protected:
   string MultiFeatureString(const FeatureVector &result) {
     std::vector<string> values;
+    values.reserve(result.size());
     for (int i = 0; i < result.size(); ++i) {
       values.push_back(result.type(i)->GetFeatureValueName(result.value(i)));
     }
diff --git a/research/syntaxnet/syntaxnet/document_format.h b/research/syntaxnet/syntaxnet/document_format.h
index 85d44cf5..115a6377 100644
--- a/research/syntaxnet/syntaxnet/document_format.h
+++ b/research/syntaxnet/syntaxnet/document_format.h
@@ -60,6 +60,9 @@ class DocumentFormat : public RegisterableClass<DocumentFormat> {
 #define REGISTER_SYNTAXNET_DOCUMENT_FORMAT(type, component) \
   REGISTER_SYNTAXNET_CLASS_COMPONENT(DocumentFormat, type, component)
 
+// Component registry for document formatters.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("document format", DocumentFormat);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_DOCUMENT_FORMAT_H__
diff --git a/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc b/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
index c753bda3..4d79ec42 100644
--- a/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
+++ b/research/syntaxnet/syntaxnet/embedding_feature_extractor.cc
@@ -94,7 +94,7 @@ GenericEmbeddingFeatureExtractor::ConvertExample(
     for (int j = 0; j < feature_vectors[i].size(); ++j) {
       const FeatureType &feature_type = *feature_vectors[i].type(j);
       const FeatureValue value = feature_vectors[i].value(j);
-      const bool is_continuous = feature_type.name().find("continuous") == 0;
+      const bool is_continuous = feature_type.is_continuous();
       const int64 id = is_continuous ? FloatFeatureValue(value).id : value;
       const int base = feature_type.base();
       if (id >= 0) {
diff --git a/research/syntaxnet/syntaxnet/feature_extractor.h b/research/syntaxnet/syntaxnet/feature_extractor.h
index 28a26da6..17f15a71 100644
--- a/research/syntaxnet/syntaxnet/feature_extractor.h
+++ b/research/syntaxnet/syntaxnet/feature_extractor.h
@@ -80,6 +80,42 @@ class FeatureVector {
   // Returns the number of elements in the feature vector.
   int size() const { return features_.size(); }
 
+  // Truncates the feature vector.  Requires that new_size <= size().
+  void Truncate(int new_size) {
+    DCHECK_GE(new_size, 0);
+    DCHECK_LE(new_size, size());
+    features_.resize(new_size);
+  }
+
+  // Returns string representation of feature vector.
+  string ToString() const {
+    string str;
+
+    str.append("[");
+    for (int i = 0; i < size(); ++i) {
+      if (i > 0) str.append(",");
+      if (!type(i)->name().empty()) {
+        // Get the name and erase any quotation characters.
+        string name_str = type(i)->name();
+        auto it = name_str.begin();
+        while (it != name_str.end()) {
+          if (*it == '"') {
+            it = name_str.erase(it);
+          } else {
+            ++it;
+          }
+        }
+        str.append(name_str);
+        str.append("=");
+      }
+      str.append(type(i)->GetFeatureValueName(value(i)));
+    }
+
+    str.append("]");
+
+    return str;
+  }
+
   // Reserves space in the underlying feature vector.
   void reserve(int n) { features_.reserve(n); }
 
diff --git a/research/syntaxnet/syntaxnet/feature_types.h b/research/syntaxnet/syntaxnet/feature_types.h
index 3912ef13..4d419037 100644
--- a/research/syntaxnet/syntaxnet/feature_types.h
+++ b/research/syntaxnet/syntaxnet/feature_types.h
@@ -40,9 +40,14 @@ class FeatureType {
  public:
   // Initializes a feature type.
   explicit FeatureType(const string &name)
-      : name_(name), base_(0) {}
+      : name_(name),
+        base_(0),
+        is_continuous_(name.find("continuous") != string::npos) {
+    // TODO(googleuser): Switch to explicitly setting is_continuous.
+    VLOG(2) << "Feature: " << name << ":" << is_continuous_;
+  }
 
-  virtual ~FeatureType() {}
+  virtual ~FeatureType() = default;
 
   // Converts a feature value to a name.
   virtual string GetFeatureValueName(FeatureValue value) const = 0;
@@ -56,12 +61,21 @@ class FeatureType {
   Predicate base() const { return base_; }
   void set_base(Predicate base) { base_ = base; }
 
+  // True if the underlying feature is continuous.
+  bool is_continuous() const { return is_continuous_; }
+
+  // Sets whenther the underlying feature should be represented as continuous.
+  void set_is_continuous(bool is_continuous) { is_continuous_ = is_continuous; }
+
  private:
   // Feature type name.
   string name_;
 
   // "Base" feature value: i.e. a "slot" in a global ordering of features.
   Predicate base_;
+
+  // True if this feature is continuous.
+  bool is_continuous_;
 };
 
 // Templated generic resource based feature type. This feature type delegates
@@ -73,7 +87,7 @@ class FeatureType {
 // successfully for values ONLY in the range [0, Resource->NumValues()) Any
 // feature value not in the extra value map and not in the above range of
 // Resource will result in a ERROR and return of "<INVALID>".
-template<class Resource>
+template <class Resource>
 class ResourceBasedFeatureType : public FeatureType {
  public:
   // Creates a new type with given name, resource object, and a mapping of
@@ -85,8 +99,8 @@ class ResourceBasedFeatureType : public FeatureType {
       : FeatureType(name), resource_(resource), values_(values) {
     max_value_ = resource->NumValues() - 1;
     for (const auto &pair : values) {
-      CHECK_GE(pair.first, resource->NumValues()) << "Invalid extra value: "
-               << pair.first << "," << pair.second;
+      CHECK_GE(pair.first, resource->NumValues())
+          << "Invalid extra value: " << pair.first << "," << pair.second;
       max_value_ = pair.first > max_value_ ? pair.first : max_value_;
     }
   }
@@ -152,8 +166,7 @@ class EnumFeatureType : public FeatureType {
   string GetFeatureValueName(FeatureValue value) const override {
     auto it = value_names_.find(value);
     if (it == value_names_.end()) {
-      LOG(ERROR)
-          << "Invalid feature value " << value << " for " << name();
+      LOG(ERROR) << "Invalid feature value " << value << " for " << name();
       return "<INVALID>";
     }
     return it->second;
diff --git a/research/syntaxnet/syntaxnet/generic_features.cc b/research/syntaxnet/syntaxnet/generic_features.cc
new file mode 100644
index 00000000..5dd6bcc2
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features.cc
@@ -0,0 +1,103 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/generic_features.h"
+
+#include <limits>
+#include <string>
+
+#include "syntaxnet/base.h"
+
+using tensorflow::strings::StrAppend;
+using tensorflow::strings::StrCat;
+namespace syntaxnet {
+
+GenericFeatureTypes::TupleFeatureTypeBase::TupleFeatureTypeBase(
+    const string &prefix, const std::vector<FeatureType *> &sub_types)
+    : FeatureType(CreateTypeName(prefix, sub_types)),
+      types_(sub_types.begin(), sub_types.end()) {
+  CHECK(!types_.empty());
+}
+
+string GenericFeatureTypes::TupleFeatureTypeBase::GetFeatureValueName(
+    FeatureValue value) const {
+  if (value < 0 || value >= size_) return "<INVALID>";
+  string name = "(";
+  for (uint32 i = 0; i < types_.size(); ++i) {
+    const FeatureType *sub_type = types_[i];
+    const FeatureValue sub_size = sub_type->GetDomainSize();
+    const FeatureValue sub_value = value % sub_size;
+    const string sub_name = sub_type->GetFeatureValueName(sub_value);
+    const string delimiter = i + 1 < types_.size() ? "," : ")";
+    StrAppend(&name, sub_name, delimiter);
+    value /= sub_size;
+  }
+  return name;
+}
+
+FeatureValue GenericFeatureTypes::TupleFeatureTypeBase::GetDomainSize() const {
+  return size_;
+}
+
+void GenericFeatureTypes::TupleFeatureTypeBase::InitDomainSizes(
+    vector<FeatureValue> *sizes) {
+  CHECK_EQ(sizes->size(), types_.size());
+
+  // Populate sub-sizes.
+  for (uint32 i = 0; i < types_.size(); ++i) {
+    sizes->at(i) = types_[i]->GetDomainSize();
+  }
+
+  // Compute the cardinality of the tuple.
+  size_ = 1;
+  double real_size = 1.0;  // for overflow detection
+  for (const FeatureValue sub_size : *sizes) {
+    size_ *= sub_size;
+    real_size *= static_cast<double>(sub_size);
+  }
+
+  // Check for overflow.
+  if (real_size > std::numeric_limits<FeatureValue>::max()) {
+    string message;
+    for (uint32 i = 0; i < types_.size(); ++i) {
+      StrAppend(&message, "\n  ", types_[i]->name(), ")=", sizes->at(i));
+    }
+    LOG(FATAL) << "Feature space overflow in feature " << name() << message;
+  }
+}
+
+string GenericFeatureTypes::TupleFeatureTypeBase::CreateTypeName(
+    const string &prefix, const std::vector<FeatureType *> &sub_types) {
+  string prefix_to_strip = prefix.empty() ? "" : StrCat(prefix, ".");
+  string name = StrCat(prefix, " {");
+  for (const FeatureType *type : sub_types) {
+    string stripped_name = type->name();
+    if (stripped_name.find_first_of(prefix_to_strip) == 0) {
+      stripped_name = stripped_name.substr(prefix_to_strip.length());
+    }
+    StrAppend(&name, " ", stripped_name);
+  }
+  StrAppend(&name, " }");
+  return name;
+}
+
+GenericFeatureTypes::DynamicTupleFeatureType::DynamicTupleFeatureType(
+    const string &prefix, const std::vector<FeatureType *> &sub_types)
+    : TupleFeatureTypeBase(prefix, sub_types), sizes_(sub_types.size()) {
+  CHECK_GE(sizes_.size(), 2);
+  InitDomainSizes(&sizes_);
+}
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/generic_features.h b/research/syntaxnet/syntaxnet/generic_features.h
new file mode 100644
index 00000000..ad441d1a
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features.h
@@ -0,0 +1,856 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+// Generic feature functions. These feature functions are independent of the
+// feature function template types.
+//
+// The generic features should be instantiated and registered using the
+// REGISTER_SYNTAXNET_GENERIC_FEATURES() macro:
+//
+// typedef GenericFeatures<Foo, int> GenericFooFeatures;
+// REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericFooFeatures);
+//
+
+#ifndef SYNTAXNET_GENERIC_FEATURES_H_
+#define SYNTAXNET_GENERIC_FEATURES_H_
+
+#include <string>
+#include <utility>
+#include <vector>
+
+#include "syntaxnet/base.h"
+#include "syntaxnet/feature_extractor.h"
+
+namespace syntaxnet {
+
+class TaskContext;
+class WorkspaceSet;
+
+// A class encapsulating all generic feature types.
+class GenericFeatureTypes {
+ public:
+  // Base class for tuple feature types.
+  class TupleFeatureTypeBase : public FeatureType {
+   public:
+    // Creates a tuple whose elements are defined by the sub-types.  This does
+    // not take ownership of the sub-types, which must remain live while this
+    // is in use.
+    TupleFeatureTypeBase(const string &prefix,
+                         const std::vector<FeatureType *> &sub_types);
+
+    // Returns a string representation of the tuple value.
+    string GetFeatureValueName(FeatureValue value) const override;
+
+    // Returns the domain size of this feature.
+    FeatureValue GetDomainSize() const override;
+
+   protected:
+    // Sets the feature domain sizes and computes the total domain size of the
+    // tuple.  Derived classes should call this method from their constructor.
+    void InitDomainSizes(vector<FeatureValue> *sizes);
+
+   private:
+    // Returns a string name for a type using the prefix and sub-types.
+    static string CreateTypeName(const string &prefix,
+                                 const std::vector<FeatureType *> &sub_types);
+
+    // The types of the sub-features.  Not owned.
+    const std::vector<const FeatureType *> types_;
+
+    // The domain size of the tuple.
+    FeatureValue size_ = 0;
+  };
+
+  // Feature type for tuples of fixed size.
+  template <int kNumElements>
+  class StaticTupleFeatureType : public TupleFeatureTypeBase {
+   public:
+    static_assert(kNumElements >= 2, "At least two elements required");
+
+    // Creates a fixed-size tuple of sub-types.  This does not take ownership
+    // of the sub-types, which must remain live while this is in use.
+    StaticTupleFeatureType(const string &prefix,
+                           const std::vector<FeatureType *> &sub_types)
+        : TupleFeatureTypeBase(prefix, sub_types) {
+      CHECK_EQ(sub_types.size(), kNumElements);
+      sizes_.resize(kNumElements);
+      InitDomainSizes(&sizes_);
+    }
+
+    // Returns the conjoined tuple value for a list of sub-values.  The range
+    // values[0,kNumElements) must be valid and non-absent.
+    FeatureValue Conjoin(const FeatureValue *values) const {
+      DCHECK_GE(values[kNumElements - 1], 0);
+      DCHECK_LT(values[kNumElements - 1], sizes_[kNumElements - 1]);
+      DCHECK_NE(values[kNumElements - 1], GenericFeatureFunction::kNone);
+      FeatureValue conjoined = values[kNumElements - 1];
+      for (int i = kNumElements - 2; i >= 0; --i) {
+        DCHECK_GE(values[i], 0);
+        DCHECK_LT(values[i], sizes_[i]);
+        DCHECK_NE(values[i], GenericFeatureFunction::kNone);
+        conjoined = values[i] + conjoined * sizes_[i];
+      }
+      return conjoined;
+    }
+
+   private:
+    // The domain sizes of the sub-types.
+    vector<FeatureValue> sizes_;
+  };
+
+  // Feature type for tuples of dynamic size.
+  class DynamicTupleFeatureType : public TupleFeatureTypeBase {
+   public:
+    // Creates a tuple of sub-types.  This does not take ownership of the
+    // sub-types, which must remain live while this is in use.
+    DynamicTupleFeatureType(const string &prefix,
+                            const std::vector<FeatureType *> &sub_types);
+
+    // Returns the conjoined tuple value for a list of sub-values, which must
+    // be the same size as the number of elements and non-absent.
+    FeatureValue Conjoin(const std::vector<FeatureValue> &values) const {
+      DCHECK_EQ(values.size(), sizes_.size());
+      DCHECK_GE(values.back(), 0);
+      DCHECK_LT(values.back(), sizes_.back());
+      DCHECK_NE(values.back(), GenericFeatureFunction::kNone);
+      FeatureValue conjoined = values.back();
+      for (int i = static_cast<int>(sizes_.size()) - 2; i >= 0; --i) {
+        DCHECK_GE(values[i], 0);
+        DCHECK_LT(values[i], sizes_[i]);
+        DCHECK_NE(values[i], GenericFeatureFunction::kNone);
+        conjoined = values[i] + conjoined * sizes_[i];
+      }
+      return conjoined;
+    }
+
+   private:
+    // The domain sizes of the sub-types.
+    std::vector<FeatureValue> sizes_;
+  };
+
+  // A wrapper which simply delegates to the sub-type.  This does not take
+  // ownership of the sub-type, which must remain live while this is in use.
+  class WrappedFeatureType : public FeatureType {
+   public:
+    explicit WrappedFeatureType(FeatureType *sub_type)
+        : FeatureType(sub_type->name()), sub_type_(sub_type) {}
+
+    string GetFeatureValueName(FeatureValue value) const override {
+      return sub_type_->GetFeatureValueName(value);
+    }
+
+    FeatureValue GetDomainSize() const override {
+      return sub_type_->GetDomainSize();
+    }
+
+   private:
+    FeatureType *sub_type_;
+  };
+};
+
+// A class encapsulating all generic feature functions.
+template <class OBJ, class... ARGS>
+class GenericFeatures {
+ public:
+  // Base class for feature functions.
+  typedef FeatureFunction<OBJ, ARGS...> Base;
+
+  // Base class for nested feature functions: these still have their own feature
+  // type, so make sure not to pass to the nested ones.
+  class MetaBase : public MetaFeatureFunction<OBJ, ARGS...> {
+   public:
+    // Don't use the nested logic for feature types by default.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      GenericFeatureFunction::GetFeatureTypes(types);
+    }
+  };
+
+  // Feature function that adds a bias value to the feature vector.
+  class Bias : public Base {
+    enum BiasFeatureValue { ON };
+
+   public:
+    // Initializes the feature.
+    void Init(TaskContext *context) override {
+      this->set_feature_type(
+          new EnumFeatureType(this->name(), {{BiasFeatureValue::ON, "ON"}}));
+    }
+
+    // Returns the bias value.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      return 0;
+    }
+  };
+
+  // Feature function that returns a constant value.
+  class Constant : public Base {
+   public:
+    // Initializes the feature.
+    void Init(TaskContext *context) override {
+      value_ = this->GetIntParameter("value", 0);
+      this->set_feature_type(new NumericFeatureType(this->name(), value_ + 1));
+    }
+
+    // Returns the constant's value.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      return value_;
+    }
+
+   private:
+    int value_ = 0;
+  };
+
+  // A feature function that tests equality between two nested features.  This
+  // can be used, for example, to check morphological agreement.
+  class Equals : public MetaBase {
+    enum EqualsFeatureValue { DIFFERENT, EQUAL };
+
+   public:
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      const auto &nested = this->nested();
+      CHECK_EQ(nested.size(), 2)
+          << "The 'equals' feature requires two nested features.";
+      this->set_feature_type(new EnumFeatureType(
+          this->name(), {{EqualsFeatureValue::DIFFERENT, "DIFFERENT"},
+                         {EqualsFeatureValue::EQUAL, "EQUAL"}}));
+    }
+
+    // Returns the equality value, or kNone if either value is absent.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      const FeatureValue a =
+          nested[0]->Compute(workspaces, object, args..., fv);
+      if (a == Base::kNone) return Base::kNone;
+      const FeatureValue b =
+          nested[1]->Compute(workspaces, object, args..., fv);
+      if (b == Base::kNone) return Base::kNone;
+      return a == b ? 1 : 0;
+    }
+  };
+
+  // Abstract base class for features that compare a nested feature's value
+  // to a target value (specified via the 'value' parameter).
+  //
+  // Subclasses must implement InitTypes() and ComputeValue().
+  class CompareValue : public MetaBase {
+   public:
+    // Initialize the type information.
+    virtual void InitTypes() = 0;
+
+    // Compute the feature value given the nested feature value and the target
+    // value (i.e., what was passed as the 'value' parameter).
+    virtual FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                                      FeatureValue target_value) const = 0;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      string value_str = this->GetParameter("value");
+      CHECK_GT(value_str.size(), 0)
+          << "The '" << this->FunctionName()
+          << "' feature requires a 'value' parameter.";
+
+      const auto &nested = this->nested();
+      CHECK_EQ(nested.size(), 1) << "The '" << this->FunctionName()
+                                 << "' feature requires one nested feature.";
+
+      // Only allow nested features with exactly one feature type.
+      FeatureType *nested_feature_type =
+          CHECK_NOTNULL(nested.front()->GetFeatureType());
+
+      for (int i = 0; i < nested_feature_type->GetDomainSize(); ++i) {
+        if (nested_feature_type->GetFeatureValueName(i) == value_str) {
+          value_ = i;
+          break;
+        }
+      }
+
+      CHECK_NE(value_, -1) << "Unknown feature value specified: " << value_str
+                           << ".";
+
+      InitTypes();
+    }
+
+    // Extracts the nested feature value, and delegates computation of the
+    // final feature value to ComputeValue().
+    // Returns kNone if the nested feature value is absent.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      FeatureValue feature_value =
+          nested.front()->Compute(workspaces, object, args..., fv);
+      if (feature_value == Base::kNone) return Base::kNone;
+      return ComputeValue(feature_value, value_);
+    }
+
+   private:
+    // The value to compare the feature against.
+    int value_ = -1;
+  };
+
+  // A feature function that fires if and only if the nested feature has the
+  // given value.
+  class Filter : public CompareValue {
+    enum FilterFeatureValue { ON };
+
+   public:
+    void InitTypes() override {
+      this->set_feature_type(
+          new EnumFeatureType(this->name(), {{FilterFeatureValue::ON, "ON"}}));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value ? 0 : Base::kNone;
+    }
+  };
+
+  // A feature function that tests equality between a feature and a value.
+  class Is : public CompareValue {
+    enum IsFeatureValue { FALSE, TRUE };
+
+   public:
+    void InitTypes() override {
+      this->set_feature_type(new EnumFeatureType(
+          this->name(),
+          {{IsFeatureValue::FALSE, "FALSE"}, {IsFeatureValue::TRUE, "TRUE"}}));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value;
+    }
+  };
+
+  // A feature function that forwards the nested feature value, unless it equals
+  // the target value (in which case, the feature doesn't fire).
+  class Ignore : public CompareValue {
+   public:
+    void InitTypes() override {
+      this->set_feature_type(new GenericFeatureTypes::WrappedFeatureType(
+          this->nested().front()->GetFeatureType()));
+    }
+
+    FeatureValue ComputeValue(FeatureValue nested_feature_value,
+                              FeatureValue target_value) const override {
+      return nested_feature_value == target_value
+                 ? GenericFeatureFunction::kNone
+                 : nested_feature_value;
+    }
+  };
+
+  // Abstract base class for features that reduce several binary values to a
+  // to a single binary value.
+  //
+  // Subclasses must implement Compute().
+  class BinaryReduce : public MetaBase {
+    enum BinaryReduceFeatureValue { FALSE, TRUE };
+
+   public:
+    // Initializes the feature.
+    // Checks that all the nested features are binary, and sets the output
+    // feature type to binary.
+    void InitNested(TaskContext *context) override {
+      for (const Base *function : this->nested()) {
+        FeatureType *nested_type = CHECK_NOTNULL(function->GetFeatureType());
+        CHECK_EQ(nested_type->GetDomainSize(), 2)
+            << this->name() << " requires nested binary feature types only.";
+      }
+      this->set_feature_type(new EnumFeatureType(
+          this->name(), {{BinaryReduceFeatureValue::FALSE, "FALSE"},
+                         {BinaryReduceFeatureValue::TRUE, "TRUE"}}));
+    }
+  };
+
+  // A feature function that takes any number of binary nested features, and
+  // returns whether they all evaluate to 1.
+  class All : public BinaryReduce {
+   public:
+    // Returns whether all nested feature values are 1, or kNone if any of them
+    // are unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        if (value == 0) return 0;
+      }
+      return 1;
+    }
+  };
+
+  // A feature function that takes any number of binary nested features, and
+  // returns whether any of them evaluate to 1.
+  class Any : public BinaryReduce {
+   public:
+    // Returns whether any nested feature values are 1, or kNone if any of them
+    // are unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        if (value == 1) return 1;
+      }
+      return 0;
+    }
+  };
+
+  // A feature function that computes a fixed-size tuple.
+  template <int kNumElements>
+  class StaticTuple : public MetaBase {
+   public:
+    // The associated fixed-size tuple type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<kNumElements> Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Returns the tuple value, or kNone if any sub-value is unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      const auto &nested = this->nested();
+      FeatureValue values[kNumElements];
+      for (int i = 0; i < kNumElements; ++i) {
+        const FeatureValue value =
+            nested[i]->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        values[i] = value;
+      }
+      return static_cast<Type *>(this->feature_type())->Conjoin(values);
+    }
+  };
+
+  // Convenience aliases for common fixed-size tuples.
+  typedef StaticTuple<2> Pair;
+  typedef StaticTuple<3> Triple;
+  typedef StaticTuple<4> Quad;
+  typedef StaticTuple<5> Quint;
+
+  // A feature function that computes a dynamically-sized tuple.
+  class Tuple : public MetaBase {
+   public:
+    // The associated tuple type.
+    typedef GenericFeatureTypes::DynamicTupleFeatureType Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Returns the tuple value, or kNone if any sub-value is unavailable.
+    FeatureValue Compute(const WorkspaceSet &workspaces, const OBJ &object,
+                         ARGS... args, const FeatureVector *fv) const override {
+      std::vector<FeatureValue> values;
+      for (const Base *function : this->nested()) {
+        const FeatureValue value =
+            function->Compute(workspaces, object, args..., fv);
+        if (value == Base::kNone) return Base::kNone;
+        values.push_back(value);
+      }
+      return static_cast<Type *>(this->feature_type())->Conjoin(values);
+    }
+  };
+
+  // A feature function that creates all pairs of the features extracted by the
+  // nested feature functions. All the nested feature functions must return
+  // single valued features.
+  //
+  // Parameters:
+  // bool unary (false):
+  //   If true, then unary features are also emitted.
+  class Pairs : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~Pairs() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      unary_ = this->GetParameter("unary") == "true";
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'pairs' feature requires at least two sub-features.";
+
+      // Get the types of all nested features.
+      types_.clear();
+      for (const Base *function : nested) {
+        types_.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types for all features.
+      pairs_.resize(NumPairs(nested.size()));
+      for (int right = 1; right < nested.size(); ++right) {
+        for (int left = 0; left < right; ++left) {
+          pairs_[PairIndex(left, right)] =
+              new Type(this->SubPrefix(), {types_[left], types_[right]});
+        }
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      if (unary_) types->insert(types->end(), types_.begin(), types_.end());
+      types->insert(types->end(), pairs_.begin(), pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+
+      // Collect all active feature sub-values.
+      std::vector<FeatureValue> values(nested.size());
+      std::vector<int> active_indices;
+      active_indices.reserve(nested.size());
+      for (int i = 0; i < nested.size(); ++i) {
+        values[i] = nested[i]->Compute(workspaces, object, args..., result);
+        if (values[i] != Base::kNone) active_indices.push_back(i);
+      }
+
+      // Optionally generate unary features.
+      if (unary_) {
+        for (int index : active_indices) {
+          result->add(types_[index], values[index]);
+        }
+      }
+
+      // Generate all feature pairs.
+      FeatureValue pair_values[2];
+      for (int right = 1; right < active_indices.size(); ++right) {
+        int right_index = active_indices[right];
+        pair_values[1] = values[right_index];
+        for (int left = 0; left < right; ++left) {
+          int left_index = active_indices[left];
+          pair_values[0] = values[left_index];
+          Type *type = pairs_[PairIndex(left_index, right_index)];
+          result->add(type, type->Conjoin(pair_values));
+        }
+      }
+    }
+
+   private:
+    // Returns the number of pairs (i,j) where 0 <= i < j < size.
+    static int NumPairs(int size) {
+      DCHECK_GE(size, 0);
+      return (size * (size - 1)) / 2;
+    }
+
+    // Returns the index for a pair (left,right) where left < right.  The
+    // indices are suitable for densely linearizing pairs into an array.
+    static int PairIndex(int left, int right) {
+      DCHECK_LE(0, left);
+      DCHECK_LT(left, right);
+      return left + NumPairs(right);
+    }
+
+    // Whether to also emit unary features.
+    bool unary_ = false;
+
+    // Feature types for all nested features.  Not owned.
+    std::vector<FeatureType *> types_;
+
+    // Feature types for all pairs.  Indexed according to PairIndex().  Owned.
+    std::vector<Type *> pairs_;
+  };
+
+  // Feature function for conjoining the first sub-feature with each of the
+  // rest of the sub-features.
+  //
+  // Parameters:
+  // bool unary (false):
+  //   If true, then unary features are also emitted.
+  class Conjoin : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~Conjoin() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      unary_ = this->GetParameter("unary") == "true";
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'conjoin' feature requires at least two sub-features.";
+
+      // Get the types of the rest of the nested features.
+      types_.clear();
+      for (const Base *function : nested) {
+        types_.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types.
+      pairs_.assign(1, nullptr);
+      for (int i = 1; i < types_.size(); ++i) {
+        pairs_.push_back(new Type(this->SubPrefix(), {types_[0], types_[i]}));
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      if (unary_) types->insert(types->end(), types_.begin() + 1, types_.end());
+      types->insert(types->end(), pairs_.begin() + 1, pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      FeatureValue values[2];
+      values[0] = nested[0]->Compute(workspaces, object, args..., result);
+
+      // Stop early if the first feature is absent.
+      if (values[0] == Base::kNone) {
+        if (unary_) {
+          for (int i = 1; i < nested.size(); ++i) {
+            values[1] = nested[i]->Compute(workspaces, object, args..., result);
+            if (values[1] == Base::kNone) continue;
+            result->add(types_[i], values[1]);
+          }
+        }
+        return;
+      }
+
+      // Otherwise, the first feature exists; conjoin it with the rest.
+      for (int i = 1; i < nested.size(); ++i) {
+        values[1] = nested[i]->Compute(workspaces, object, args..., result);
+        if (values[1] == Base::kNone) continue;
+        if (unary_) result->add(types_[i], values[1]);
+        result->add(pairs_[i], pairs_[i]->Conjoin(values));
+      }
+    }
+
+   private:
+    // Whether to also emit unary features.
+    bool unary_ = false;
+
+    // Feature types for all nested features.  Not owned.
+    std::vector<FeatureType *> types_;
+
+    // Feature types for all pairs.  The first element is null, in order to
+    // align this list with types_.  Owned.
+    std::vector<Type *> pairs_;
+  };
+
+  // Feature function for creating pairs of multi-valued features.  By default,
+  // the feature computes the Cartesian product of the extracted sub-features,
+  // but a parallel product can be specified via the options.
+  //
+  // Parameters:
+  // bool parallel (false):
+  //   If true, output features for parallel pairs, like a dot product.  The
+  //   two sub-features must produce identical numbers of features.
+  class MultiPair : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      parallel_ = this->GetParameter("parallel") == "true";
+      std::vector<FeatureType *> sub_types;
+      for (const Base *function : this->nested()) {
+        sub_types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+      this->set_feature_type(new Type(this->SubPrefix(), sub_types));
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      const int orig_size = result->size();
+
+      // Extract features from left half.  Values are extracted directly into
+      // the result so that optimized variable references are handled properly.
+      nested[0]->Evaluate(workspaces, object, args..., result);
+      if (orig_size == result->size()) return;  // no left features
+      std::vector<FeatureValue> left;
+      for (int i = orig_size; i < result->size(); ++i) {
+        left.push_back(result->value(i));
+      }
+      result->Truncate(orig_size);
+
+      // Extract features from right half.
+      nested[1]->Evaluate(workspaces, object, args..., result);
+      if (orig_size == result->size()) return;  // no right features
+      std::vector<FeatureValue> right;
+      for (int i = orig_size; i < result->size(); ++i) {
+        right.push_back(result->value(i));
+      }
+      result->Truncate(orig_size);
+
+      // Compute the pair values.
+      FeatureValue values[2];
+      Type *type = static_cast<Type *>(this->feature_type());
+      if (parallel_) {
+        // Produce parallel pairs.
+        CHECK_EQ(left.size(), right.size());
+        for (int i = 0; i < left.size(); ++i) {
+          values[0] = left[i];
+          values[1] = right[i];
+          result->add(type, type->Conjoin(values));
+        }
+      } else {
+        // Produce all pairs.
+        for (const FeatureValue left_value : left) {
+          values[0] = left_value;
+          for (const FeatureValue right_value : right) {
+            values[1] = right_value;
+            result->add(type, type->Conjoin(values));
+          }
+        }
+      }
+    }
+
+   private:
+    // Whether to do a parallel product instead of a Cartesian product.
+    bool parallel_ = false;
+  };
+
+  // Feature function for conjoining the first multi-valued sub-feature with
+  // each of the rest of the multi-valued sub-features.
+  class MultiConjoin : public MetaBase {
+   public:
+    // The pair feature type.
+    typedef GenericFeatureTypes::StaticTupleFeatureType<2> Type;
+
+    // Discards the pair types.
+    ~MultiConjoin() override {
+      for (Type *type : pairs_) delete type;
+    }
+
+    // Initializes the feature.
+    void InitNested(TaskContext *context) override {
+      const auto &nested = this->nested();
+      CHECK_GE(nested.size(), 2)
+          << "The 'multiconjoin' feature requires at least two sub-features.";
+
+      // Get the types of the rest of the nested features.
+      std::vector<FeatureType *> types;
+      types.reserve(nested.size());
+      for (const Base *function : nested) {
+        types.push_back(CHECK_NOTNULL(function->GetFeatureType()));
+      }
+
+      // Initialize the pair types.
+      pairs_.clear();
+      for (int i = 1; i < types.size(); ++i) {
+        pairs_.push_back(new Type(this->SubPrefix(), {types[0], types[i]}));
+      }
+    }
+
+    // Produces all feature types.
+    void GetFeatureTypes(std::vector<FeatureType *> *types) const override {
+      types->insert(types->end(), pairs_.begin(), pairs_.end());
+    }
+
+    // Evaluates the feature.
+    void Evaluate(const WorkspaceSet &workspaces, const OBJ &object,
+                  ARGS... args, FeatureVector *result) const override {
+      const auto &nested = this->nested();
+      const int orig_size = result->size();
+
+      // Gather the lists of sub-values for each nested feature.  Sub-values
+      // are extracted directly into the result so that optimized variable
+      // references are handled properly.
+      std::vector<std::vector<FeatureValue> > sub_values(nested.size());
+      for (int i = 0; i < nested.size(); ++i) {
+        nested[i]->Evaluate(workspaces, object, args..., result);
+        if (orig_size == result->size()) {
+          if (i == 0) {
+            return;  // no first values; nothing will be extracted
+          } else {
+            continue;  // no non-first values; skip to next feature
+          }
+        }
+        std::vector<FeatureValue> &values = sub_values[i];
+        for (int j = orig_size; j < result->size(); ++j) {
+          values.push_back(result->value(j));
+        }
+        result->Truncate(orig_size);
+      }
+
+      // Produce conjoined features.
+      const std::vector<FeatureValue> &first_values = sub_values[0];
+      FeatureValue values[2];
+      for (int i = 1; i < sub_values.size(); ++i) {
+        const std::vector<FeatureValue> &other_values = sub_values[i];
+        if (other_values.empty()) continue;
+        Type *type = pairs_[i - 1];
+        for (const FeatureValue first_value : first_values) {
+          values[0] = first_value;
+          for (const FeatureValue other_value : other_values) {
+            values[1] = other_value;
+            result->add(type, type->Conjoin(values));
+          }
+        }
+      }
+    }
+
+   private:
+    // Feature types for all pairs.  Owned.
+    std::vector<Type *> pairs_;
+  };
+};
+
+#define REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, name, type) \
+  typedef generics::type __##type##generics;                     \
+  REGISTER_SYNTAXNET_FEATURE_FUNCTION(generics::Base, name, __##type##generics)
+
+#define REGISTER_SYNTAXNET_GENERIC_FEATURES(generics)                   \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "bias", Bias);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "constant", Constant);   \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "equals", Equals);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "filter", Filter);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "is", Is);               \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "all", All);             \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "any", Any);             \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "pair", Pair);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "triple", Triple);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "quad", Quad);           \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "quint", Quint);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "tuple", Tuple);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "pairs", Pairs);         \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "conjoin", Conjoin);     \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "multipair", MultiPair); \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "ignore", Ignore);       \
+  REGISTER_SYNTAXNET_GENERIC_FEATURE(generics, "multiconjoin", MultiConjoin)
+
+}  // namespace syntaxnet
+
+#endif  // SYNTAXNET_GENERIC_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/generic_features_test.cc b/research/syntaxnet/syntaxnet/generic_features_test.cc
new file mode 100644
index 00000000..01a68963
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/generic_features_test.cc
@@ -0,0 +1,387 @@
+/* Copyright 2016 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/generic_features.h"
+
+#include <map>
+#include <memory>
+#include <string>
+#include <vector>
+
+#include "syntaxnet/registry.h"
+#include "syntaxnet/task_context.h"
+#include <gmock/gmock.h>
+
+namespace syntaxnet {
+
+// Test feature extractor.
+class TestFeatureExtractor : public FeatureExtractor<std::vector<int>, int> {};
+
+// Registration macro.
+#define REGISTER_TEST_FEATURE_FUNCTION(name, component)                     \
+  REGISTER_SYNTAXNET_FEATURE_FUNCTION(TestFeatureExtractor::Function, name, \
+                                      component)
+
+// The registry must be declared in the global namespace.
+REGISTER_SYNTAXNET_CLASS_REGISTRY("syntaxnet test feature function",
+                                  syntaxnet::TestFeatureExtractor::Function);
+
+typedef GenericFeatures<std::vector<int>, int> GenericTestFeatures;
+REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericTestFeatures);
+
+class TestVectorFeatureFunction : public TestFeatureExtractor::Function {
+ public:
+  // Initializes the feature.
+  void Init(TaskContext *context) override {
+    int arg = argument();
+    while (arg > 0) {
+      offsets_.push_back(arg % 10);
+      arg /= 10;
+    }
+    std::reverse(offsets_.begin(), offsets_.end());
+    if (offsets_.empty()) offsets_.push_back(0);
+    set_feature_type(new NumericFeatureType(name(), 10));
+  }
+
+  // Evaluates the feature.
+  void Evaluate(const WorkspaceSet &workspace, const std::vector<int> &object,
+                int focus, FeatureVector *features) const override {
+    for (const uint32 offset : offsets_) {
+      const uint32 index = focus + offset;
+      if (index >= object.size()) continue;
+      features->add(feature_type(), object[index]);
+    }
+  }
+
+  // Returns the first extracted feature, if available.
+  FeatureValue Compute(const WorkspaceSet &workspace,
+                       const std::vector<int> &object, int focus,
+                       const FeatureVector *fv) const override {
+    CHECK_EQ(1, offsets_.size());
+    FeatureVector features;
+    Evaluate(workspace, object, focus, &features);
+    return features.size() == 0 ? kNone : features.value(0);
+  }
+
+ private:
+  // A list of offsets extracted from the feature's argument.
+  std::vector<uint32> offsets_;
+};
+
+REGISTER_TEST_FEATURE_FUNCTION("f", TestVectorFeatureFunction);
+
+class TestParityFeatureFunction : public TestFeatureExtractor::Function {
+ public:
+  // Initializes the feature.
+  void Init(TaskContext *context) override {
+    // "even" corresponds to feature value 0, "odd" to 1.
+    enum ParityFeatureValue { EVEN, ODD };
+    set_feature_type(
+        new EnumFeatureType(name(), {{EVEN, "even"}, {ODD, "odd"}}));
+
+    // Check the "offset" parameter.
+    for (const auto &param : this->descriptor()->parameter()) {
+      if (param.name() == "offset") {
+        offset_ = std::stoi(param.value());
+        CHECK(&offset_);
+      }
+    }
+  }
+
+  // Evaluates the feature.
+  void Evaluate(const WorkspaceSet &workspace, const std::vector<int> &object,
+                int focus, FeatureVector *features) const override {
+    uint32 offset_focus = focus += offset_;
+    if (offset_focus < object.size()) {
+      features->add(feature_type(), object[offset_focus] & 1);
+    }
+  }
+
+  // Returns the first extracted feature, if available.
+  FeatureValue Compute(const WorkspaceSet &workspace,
+                       const std::vector<int> &object, int focus,
+                       const FeatureVector *fv) const override {
+    FeatureVector features;
+    Evaluate(workspace, object, focus, &features);
+    return features.size() == 0 ? kNone : features.value(0);
+  }
+
+ private:
+  int offset_ = 0;
+};
+
+REGISTER_TEST_FEATURE_FUNCTION("parity", TestParityFeatureFunction);
+
+// Testing rig.
+class GenericFeaturesTest : public ::testing::Test {
+ public:
+  // Deallocates test state.
+  void TearDown() override {
+    object_.reset();
+    extractor_.reset();
+    context_.reset();
+  }
+
+  // Initializes the test.
+  void Init(const string &spec, const std::vector<int> &object) {
+    context_.reset(new TaskContext());
+    extractor_.reset(new TestFeatureExtractor());
+    extractor_->Parse(spec);
+    extractor_->Setup(context_.get());
+    extractor_->Init(context_.get());
+    object_.reset(new std::vector<int>(object));
+  }
+
+  // Tests extraction on the current object.
+  void TestExtract(int focus, const string &feature_string) const {
+    FeatureVector features;
+    WorkspaceSet workspace;
+    extractor_->Preprocess(&workspace, object_.get());
+    extractor_->ExtractFeatures(workspace, *object_, focus, &features);
+    EXPECT_EQ(feature_string, features.ToString());
+  }
+
+ private:
+  // The task context for tests.
+  std::unique_ptr<TaskContext> context_;
+
+  // Feature extractor for tests.
+  std::unique_ptr<TestFeatureExtractor> extractor_;
+
+  // Object for tests.
+  std::unique_ptr<std::vector<int> > object_;
+};
+
+TEST_F(GenericFeaturesTest, Singleton) {
+  Init("f", {5, 3, 2, 4, 6});
+  TestExtract(0, "[f=5]");
+  TestExtract(1, "[f=3]");
+  TestExtract(4, "[f=6]");
+  TestExtract(5, "[]");
+}
+
+TEST_F(GenericFeaturesTest, TwoFeatures) {
+  Init("f(0) f(1)", {5, 3, 2, 4, 6});
+  TestExtract(0, "[f=5,f(1)=3]");
+}
+
+TEST_F(GenericFeaturesTest, Bias) {
+  Init("bias", {0, 1});
+  TestExtract(0, "[bias=ON]");
+}
+
+TEST_F(GenericFeaturesTest, Constant) {
+  Init("constant(value=2)", {0, 1});
+
+  TestExtract(0, "[constant(value=2)=2]");
+}
+
+TEST_F(GenericFeaturesTest, Equals) {
+  Init("equals { f(0) f(1) }", {0, 1, 0});
+  TestExtract(0, "[equals { f f(1) }=DIFFERENT]");
+  Init("equals { f(0) f(2) }", {0, 1, 0});
+  TestExtract(0, "[equals { f f(2) }=EQUAL]");
+}
+
+TEST_F(GenericFeaturesTest, Filter) {
+  Init("filter(value=5).f", {3, 5});
+  TestExtract(0, "[]");
+  TestExtract(1, "[filter(value=5).f=ON]");
+
+  // Check that we are actually parsing feature value names.
+  Init("filter(value=odd).parity", {3, 4});
+  TestExtract(0, "[filter(value=odd).parity=ON]");
+  TestExtract(1, "[]");
+  Init("filter(value=even).parity", {3, 4});
+  TestExtract(0, "[]");
+  TestExtract(1, "[filter(value=even).parity=ON]");
+}
+
+TEST_F(GenericFeaturesTest, Is) {
+  Init("is(value=5).f", {3, 5});
+  TestExtract(0, "[is(value=5).f=FALSE]");
+  TestExtract(1, "[is(value=5).f=TRUE]");
+
+  // Check that we are actually parsing feature value names.
+  Init("is(value=odd).parity", {3, 4});
+  TestExtract(0, "[is(value=odd).parity=TRUE]");
+  TestExtract(1, "[is(value=odd).parity=FALSE]");
+  Init("is(value=even).parity", {3, 4});
+  TestExtract(0, "[is(value=even).parity=FALSE]");
+  TestExtract(1, "[is(value=even).parity=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Ignore) {
+  Init("ignore(value=5).f", {3, 5});
+  TestExtract(0, "[ignore(value=5).f=3]");
+  TestExtract(1, "[]");
+
+  // Check that we are actually parsing feature value names.
+  Init("ignore(value=odd).parity", {3, 4});
+  TestExtract(0, "[]");
+  TestExtract(1, "[ignore(value=odd).parity=even]");
+  Init("ignore(value=even).parity", {3, 4});
+  TestExtract(0, "[ignore(value=even).parity=odd]");
+  TestExtract(1, "[]");
+}
+
+TEST_F(GenericFeaturesTest, All) {
+  Init("all { parity parity(offset=1) }", {2, 2});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {2, 3});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {3, 2});
+  TestExtract(0, "[all { parity parity(offset=1) }=FALSE]");
+
+  Init("all { parity parity(offset=1) }", {3, 3});
+  TestExtract(0, "[all { parity parity(offset=1) }=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Any) {
+  Init("any { parity parity(offset=1) }", {2, 2});
+  TestExtract(0, "[any { parity parity(offset=1) }=FALSE]");
+
+  Init("any { parity parity(offset=1) }", {2, 3});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+
+  Init("any { parity parity(offset=1) }", {3, 2});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+
+  Init("any { parity parity(offset=1) }", {3, 3});
+  TestExtract(0, "[any { parity parity(offset=1) }=TRUE]");
+}
+
+TEST_F(GenericFeaturesTest, Pair) {
+  Init("pair { f(0) f(1) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[pair { f f(1) }=(5,3)]");
+}
+
+TEST_F(GenericFeaturesTest, NestedPair) {
+  Init("pair { pair { f(0) f(1) } pair { f(2) f(3) } }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[pair { pair { f f(1) } pair { f(2) f(3) } }=((5,3),(2,4))]");
+}
+
+TEST_F(GenericFeaturesTest, Triple) {
+  Init("triple { f(0) f(1) f(2) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[triple { f f(1) f(2) }=(5,3,2)]");
+}
+
+TEST_F(GenericFeaturesTest, Quad) {
+  Init("quad { f(0) f(1) f(2) f(3) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[quad { f f(1) f(2) f(3) }=(5,3,2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, Quint) {
+  Init("quint { f(0) f(1) f(2) f(3) f(4) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[quint { f f(1) f(2) f(3) f(4) }=(5,3,2,4,6)]");
+}
+
+TEST_F(GenericFeaturesTest, Tuple) {
+  Init("tuple { f(0) f(1) f(2) f(3) f(4) }", {5, 3, 2, 4, 6});
+  TestExtract(0, "[tuple { f f(1) f(2) f(3) f(4) }=(5,3,2,4,6)]");
+}
+
+TEST_F(GenericFeaturesTest, Pairs) {
+  Init("pairs { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[pairs { f f(1) }=(0,1)"
+              ",pairs { f f(2) }=(0,2)"
+              ",pairs { f(1) f(2) }=(1,2)"
+              ",pairs { f f(3) }=(0,3)"
+              ",pairs { f(1) f(3) }=(1,3)"
+              ",pairs { f(2) f(3) }=(2,3)]");
+}
+
+TEST_F(GenericFeaturesTest, PairsWithUnary) {
+  Init("pairs(unary=true) { f(0) f(1) f(2) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[pairs(unary=true).f=0"
+              ",pairs(unary=true).f(1)=1"
+              ",pairs(unary=true).f(2)=2"
+              ",pairs(unary=true) { f f(1) }=(0,1)"
+              ",pairs(unary=true) { f f(2) }=(0,2)"
+              ",pairs(unary=true) { f(1) f(2) }=(1,2)]");
+}
+
+TEST_F(GenericFeaturesTest, Conjoin) {
+  Init("conjoin { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[conjoin { f f(1) }=(0,1)"
+              ",conjoin { f f(2) }=(0,2)"
+              ",conjoin { f f(3) }=(0,3)]");
+}
+
+TEST_F(GenericFeaturesTest, ConjoinWithUnary) {
+  Init("conjoin(unary=true) { f(0) f(1) f(2) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[conjoin(unary=true).f(1)=1"
+              ",conjoin(unary=true) { f f(1) }=(0,1)"
+              ",conjoin(unary=true).f(2)=2"
+              ",conjoin(unary=true) { f f(2) }=(0,2)"
+              ",conjoin(unary=true).f(3)=3"
+              ",conjoin(unary=true) { f f(3) }=(0,3)]");
+}
+
+TEST_F(GenericFeaturesTest, SingletonMultiValue) {
+  Init("f(12)", {0, 1, 2, 3, 4});
+  TestExtract(0, "[f(12)=1,f(12)=2]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairOneSided) {
+  Init("multipair { f(12) f(3) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair { f(12) f(3) }=(1,3)"
+              ",multipair { f(12) f(3) }=(2,3)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairTwoSided) {
+  Init("multipair { f(12) f(34) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair { f(12) f(34) }=(1,3)"
+              ",multipair { f(12) f(34) }=(1,4)"
+              ",multipair { f(12) f(34) }=(2,3)"
+              ",multipair { f(12) f(34) }=(2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiPairParallel) {
+  Init("multipair(parallel=true) { f(12) f(34) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multipair(parallel=true) { f(12) f(34) }=(1,3)"
+              ",multipair(parallel=true) { f(12) f(34) }=(2,4)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiConjoinFirstOnly) {
+  Init("multiconjoin { f(12) f(3) f(0) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multiconjoin { f(12) f(3) }=(1,3)"
+              ",multiconjoin { f(12) f(3) }=(2,3)"
+              ",multiconjoin { f(12) f }=(1,0)"
+              ",multiconjoin { f(12) f }=(2,0)]");
+}
+
+TEST_F(GenericFeaturesTest, MultiConjoinFirstAndRest) {
+  Init("multiconjoin { f(12) f(34) f(0) }", {0, 1, 2, 3, 4});
+  TestExtract(0,
+              "[multiconjoin { f(12) f(34) }=(1,3)"
+              ",multiconjoin { f(12) f(34) }=(1,4)"
+              ",multiconjoin { f(12) f(34) }=(2,3)"
+              ",multiconjoin { f(12) f(34) }=(2,4)"
+              ",multiconjoin { f(12) f }=(1,0)"
+              ",multiconjoin { f(12) f }=(2,0)]");
+}
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/graph_builder.py b/research/syntaxnet/syntaxnet/graph_builder.py
index 595d796e..58e41017 100644
--- a/research/syntaxnet/syntaxnet/graph_builder.py
+++ b/research/syntaxnet/syntaxnet/graph_builder.py
@@ -485,6 +485,7 @@ class GreedyParser(object):
           vectors=embeddings_path,
           task_context=task_context,
           embedding_init=self._embedding_init,
+          cache_vectors_locally=False,
           seed=seed1,
           seed2=seed2)
 
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions.cc b/research/syntaxnet/syntaxnet/head_label_transitions.cc
new file mode 100644
index 00000000..a5bce36d
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions.cc
@@ -0,0 +1,148 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include "syntaxnet/head_label_transitions.h"
+
+#include "syntaxnet/base.h"
+
+using tensorflow::strings::StrAppend;
+using tensorflow::strings::StrCat;
+
+namespace syntaxnet {
+
+// Parser transition state for head & label transitions.
+class HeadLabelTransitionSystem::State : public ParserTransitionState {
+ public:
+  // Returns a copy of this state.
+  State *Clone() const override { return new State(*this); }
+
+  // Does nothing; no need for additional initialization.
+  void Init(ParserState *state) override {}
+
+  // Copies the selected heads to the |sentence|.
+  void AddParseToDocument(const ParserState &state, bool rewrite_root_labels,
+                          Sentence *sentence) const override {
+    for (int i = 0; i < state.NumTokens(); ++i) {
+      Token *token = sentence->mutable_token(i);
+      token->set_head(state.Head(i));
+      token->set_label(state.LabelAsString(state.Label(i)));
+      if (rewrite_root_labels && state.Head(i) == -1) {
+        token->set_label(state.LabelAsString(state.RootLabel()));
+      }
+    }
+  }
+
+  // Returns true if the head and gold head match.
+  bool IsTokenCorrect(const ParserState &state, int index) const override {
+    return state.GoldHead(index) == state.Head(index);
+  }
+
+  // Returns a string representation of the |state|.
+  string ToString(const ParserState &state) const override {
+    string str = "[";
+    for (int i = 0; i < state.NumTokens(); ++i) {
+      StrAppend(&str, i == 0 ? "" : " ", state.Head(i));
+    }
+    StrAppend(&str, "]");
+    return str;
+  }
+};
+
+ParserAction HeadLabelTransitionSystem::GetDefaultAction(
+    const ParserState &state) const {
+  const int default_head = state.Next();
+  const int default_label = state.RootLabel();
+  return EncodeActionWithState(default_head, default_label, state);
+}
+
+ParserAction HeadLabelTransitionSystem::GetNextGoldAction(
+    const ParserState &state) const {
+  if (state.EndOfInput()) {
+    LOG(ERROR) << "Oracle called on invalid state: " << state.ToString();
+    return 0;
+  }
+  const int current = state.Next();
+  int head = state.GoldHead(current);
+  const int label = state.GoldLabel(current);
+
+  // In syntaxnet.Sentence, root arcs are token.head() == -1, whereas
+  // here, we use a self-loop to represent roots. So we need to convert here.
+  head = head == -1 ? current : head;
+  return EncodeActionWithState(head, label, state);
+}
+
+void HeadLabelTransitionSystem::PerformActionWithoutHistory(
+    ParserAction action, ParserState *state) const {
+  CHECK(IsAllowedAction(action, *state))
+      << "Illegal action " << action << " at state: " << state->ToString();
+
+  const int current = state->Next();
+  int head, label;
+  DecodeActionWithState(action, *state, &head, &label);
+
+  VLOG(2) << "Adding arc: " << label << " (" << current << " <- " << head
+          << ")";
+  state->AddArc(current, head == current ? -1 : head, label);
+  state->Advance();
+}
+
+bool HeadLabelTransitionSystem::IsAllowedAction(
+    ParserAction action, const ParserState &state) const {
+  if (state.EndOfInput()) return false;
+
+  // Unlike the labels transition system, we allow root tokens to receive
+  // non-root dependency labels and vice versa.
+  return action >= 0 && action < state.NumTokens() * state.NumLabels();
+}
+
+bool HeadLabelTransitionSystem::IsFinalState(const ParserState &state) const {
+  return state.EndOfInput();
+}
+
+string HeadLabelTransitionSystem::ActionAsString(
+    ParserAction action, const ParserState &state) const {
+  if (!IsAllowedAction(action, state)) return StrCat("INVALID:", action);
+
+  const auto &sentence = state.sentence();
+  const int current = state.Next();
+  int head, label;
+  DecodeActionWithState(action, state, &head, &label);
+  return StrCat(state.LabelAsString(label), "(",
+                sentence.token(current).word(), "<-",
+                head == current ? "ROOT" : sentence.token(head).word(), ")");
+}
+
+ParserTransitionState *HeadLabelTransitionSystem::NewTransitionState(
+    bool training_mode) const {
+  return new State();
+}
+
+void HeadLabelTransitionSystem::DecodeActionWithState(ParserAction action,
+                                                      const ParserState &state,
+                                                      ParserAction *base_action,
+                                                      int *label) const {
+  const int num_labels = state.NumLabels();
+  *base_action = action / num_labels;
+  *label = action % num_labels;
+}
+
+ParserAction HeadLabelTransitionSystem::EncodeActionWithState(
+    ParserAction base_action, int label, const ParserState &state) const {
+  return base_action * state.NumLabels() + label;
+}
+
+REGISTER_TRANSITION_SYSTEM("heads_labels", HeadLabelTransitionSystem);
+
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions.h b/research/syntaxnet/syntaxnet/head_label_transitions.h
new file mode 100644
index 00000000..d1d0dec1
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions.h
@@ -0,0 +1,96 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
+#define SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
+
+#include "syntaxnet/parser_state.h"
+#include "syntaxnet/parser_transitions.h"
+
+namespace syntaxnet {
+
+// Heads and labels transition system. Predicts the syntactic heads and labels
+// of a sentence directly.
+//
+// In this transition system actions encode heads and their labels, so the
+// space of actions is num_labels*N (for a sentence with N tokens.) A token
+// that points to itself is interpreted as a root. Unlike the heads transition
+// system followed by labels, we allow root arcs to receive non-root
+// dependency labels and vice versa since, unlike in the labels transition
+// system, it is unclear whether the arc or label prediction should take
+// precedence.
+//
+// Actions are interpreted as follows:
+//
+// For input pointer at position i:
+//   head  = A / num_labels
+//   label = A % num_labels
+//   if head == i  : Add a root arc to token i (with given label)
+//   if head != i  : Add an arc head -> i (with given label)
+//
+// Note that in syntaxnet.Sentence, root arcs are token.head() == -1, whereas
+// here, we use a self-loop to represent roots.
+class HeadLabelTransitionSystem : public ParserTransitionSystem {
+ public:
+  class State;  // defined in the .cc file
+
+  int NumActionTypes() const override { return 1; }
+  int NumActions(int num_labels) const override { return kDynamicNumActions; }
+
+  // The default action is to assign itself as root.
+  ParserAction GetDefaultAction(const ParserState &state) const override;
+
+  // Returns the next gold action for a given state according to the
+  // underlying annotated sentence.
+  ParserAction GetNextGoldAction(const ParserState &state) const override;
+
+  // Checks if the action is allowed in a given parser state.
+  bool IsAllowedAction(ParserAction action,
+                       const ParserState &state) const override;
+
+  // Performs the specified action on a given parser state, without adding the
+  // action to the state's history.
+  void PerformActionWithoutHistory(ParserAction action,
+                                   ParserState *state) const override;
+
+  // Returns true if the state is at the end of the input.
+  bool IsFinalState(const ParserState &state) const override;
+
+  // Returns a string representation of a parser action.
+  string ActionAsString(ParserAction action,
+                        const ParserState &state) const override;
+
+  // Returns a new transition state to be used to enhance the parser state.
+  ParserTransitionState *NewTransitionState(bool training_mode) const override;
+
+  // Returns false, since no states are deterministic.
+  bool IsDeterministicState(const ParserState &state) const override {
+    return false;
+  }
+
+ private:
+  // Given a ParseState, decodes an action into a base action and a label.
+  void DecodeActionWithState(ParserAction action, const ParserState &state,
+                             ParserAction *base_action, int *label) const;
+
+  // Given a ParseState, encodes a base action and a label into a single-valued
+  // function.
+  ParserAction EncodeActionWithState(ParserAction base_action, int label,
+                                     const ParserState &state) const;
+};
+
+}  // namespace syntaxnet
+
+#endif  // SYNTAXNET_HEAD_LABEL_TRANSITIONS_H_
diff --git a/research/syntaxnet/syntaxnet/head_label_transitions_test.cc b/research/syntaxnet/syntaxnet/head_label_transitions_test.cc
new file mode 100644
index 00000000..aebb0811
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/head_label_transitions_test.cc
@@ -0,0 +1,105 @@
+/* Copyright 2017 Google Inc. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#include <memory>
+
+#include "syntaxnet/base.h"
+#include "syntaxnet/parser_state.h"
+#include "syntaxnet/parser_transitions.h"
+#include "syntaxnet/sentence.pb.h"
+#include "syntaxnet/task_context.h"
+#include "syntaxnet/term_frequency_map.h"
+#include "tensorflow/core/platform/test.h"
+
+namespace syntaxnet {
+namespace {
+
+const char kSentence[] = R"(
+  text: 'I saw a man with a telescope.'
+  token { word: 'I' start: 0 end: 0 tag: 'PRP' category: 'PRON'
+          head: 1 label: 'nsubj' break_level: NO_BREAK }
+  token { word: 'saw' start: 2 end: 4 tag: 'VBD' category: 'VERB'
+          label: 'ROOT' break_level: SPACE_BREAK }
+  token { word: 'a' start: 6 end: 6 tag: 'DT' category: 'DET'
+          head: 3 label: 'det' break_level: SPACE_BREAK }
+  token { word: 'man' start: 8 end: 10 tag: 'NN' category: 'NOUN'
+          head: 1 label: 'dobj' break_level: SPACE_BREAK }
+  token { word: 'with' start: 12 end: 15 tag: 'IN' category: 'ADP'
+          head: 1 label: 'prep' break_level: SPACE_BREAK }
+  token { word: 'a' start: 17 end: 17 tag: 'DT' category: 'DET'
+          head: 6 label: 'det' break_level: SPACE_BREAK }
+  token { word: 'telescope' start: 19 end: 27 tag: 'NN' category: 'NOUN'
+          head: 4 label: 'pobj'  break_level: SPACE_BREAK }
+  token { word: '.' start: 28 end: 28 tag: '.' category: '.'
+          head: 1 label: 'p' break_level: NO_BREAK }
+)";
+
+class HeadLabelTransitionTest : public ::testing::Test {
+ public:
+  HeadLabelTransitionTest() {
+    transition_system_->Setup(&context_);
+    transition_system_->Init(&context_);
+    CHECK(TextFormat::ParseFromString(kSentence, &sentence_));
+    for (auto &token : sentence_.token()) label_map_.Increment(token.label());
+    state_.reset(new ParserState(
+        &sentence_, transition_system_->NewTransitionState(true), &label_map_));
+  }
+ protected:
+  TermFrequencyMap label_map_;
+  TaskContext context_;
+  std::unique_ptr<ParserTransitionSystem> transition_system_{
+      ParserTransitionSystem::Create("heads_labels")};
+  Sentence sentence_;
+  std::unique_ptr<ParserState> state_;
+};
+
+TEST_F(HeadLabelTransitionTest, TestPerformActionSelfRoot) {
+  const int current = state_->Next();
+  const int head = current;
+  const int label = state_->RootLabel();
+  const int action = head * state_->NumLabels() + label;
+  transition_system_->PerformActionWithoutHistory(action, state_.get());
+  EXPECT_EQ(state_->Head(current), -1);
+  EXPECT_EQ(state_->Label(current), label);
+}
+
+TEST_F(HeadLabelTransitionTest, TestPerformActionAssignRootOtherLabel) {
+  const int label = label_map_.LookupIndex("det", -1);
+  const int current = state_->Next();
+  const int head = current;
+  const int action = head * state_->NumLabels() + label;
+  transition_system_->PerformActionWithoutHistory(action, state_.get());
+  EXPECT_EQ(state_->Head(current), -1);
+  EXPECT_EQ(state_->Label(current), label);
+}
+
+TEST_F(HeadLabelTransitionTest, GoldParsesCorrectly) {
+  LOG(INFO) << "Initial parser state: " << state_->ToString();
+  while (!transition_system_->IsFinalState(*state_)) {
+    ParserAction action = transition_system_->GetNextGoldAction(*state_);
+    EXPECT_TRUE(transition_system_->IsAllowedAction(action, *state_));
+    LOG(INFO) << "Performing action " << action << ": "
+              << transition_system_->ActionAsString(action, *state_);
+    transition_system_->PerformActionWithoutHistory(action, state_.get());
+    LOG(INFO) << "Parser state: " << state_->ToString();
+  }
+  for (int i = 0; i < state_->NumTokens(); ++i) {
+    EXPECT_EQ(state_->GoldHead(i), state_->Head(i));
+    EXPECT_EQ(state_->GoldLabel(i), state_->Label(i));
+  }
+}
+
+}  // namespace
+}  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/head_transitions.h b/research/syntaxnet/syntaxnet/head_transitions.h
index fe4b1d85..4f36bbbb 100644
--- a/research/syntaxnet/syntaxnet/head_transitions.h
+++ b/research/syntaxnet/syntaxnet/head_transitions.h
@@ -30,17 +30,14 @@ namespace syntaxnet {
 //   Action A == i  : Add a root arc to token i.
 //   Action A != i  : Add an arc A -> i.
 //
-// Note that in nlp_saft.Document, root arcs are token.head() == -1, whereas
+// Note that in the Sentence proto, root arcs are token.head() == -1, whereas
 // here, we use a self-loop to represent roots.
 class HeadTransitionSystem : public ParserTransitionSystem {
  public:
   class State;  // defined in the .cc file
 
-  // Returns 1 for number of actions. This is because each action should be
-  // scored separately; e.g. instead of a fixed output set, we have a single
-  // scoring function.
   int NumActionTypes() const override { return 1; }
-  int NumActions(int num_labels) const override { return 1; }
+  int NumActions(int num_labels) const override { return kDynamicNumActions; }
 
   // Returns the default action, which is to assign itself as root.
   ParserAction GetDefaultAction(const ParserState &state) const override;
diff --git a/research/syntaxnet/syntaxnet/head_transitions_test.cc b/research/syntaxnet/syntaxnet/head_transitions_test.cc
index dcd95818..8cc0d995 100644
--- a/research/syntaxnet/syntaxnet/head_transitions_test.cc
+++ b/research/syntaxnet/syntaxnet/head_transitions_test.cc
@@ -68,7 +68,8 @@ class HeadTransitionSystemTest : public ::testing::Test {
 
 TEST_F(HeadTransitionSystemTest, Characteristics) {
   EXPECT_EQ(1, transition_system_->NumActionTypes());
-  EXPECT_EQ(1, transition_system_->NumActions(10));
+  EXPECT_EQ(ParserTransitionSystem::kDynamicNumActions,
+            transition_system_->NumActions(10));
 }
 
 TEST_F(HeadTransitionSystemTest, GoldParsesCorrectly) {
diff --git a/research/syntaxnet/syntaxnet/lexicon_builder.cc b/research/syntaxnet/syntaxnet/lexicon_builder.cc
index 29370d72..2536968e 100644
--- a/research/syntaxnet/syntaxnet/lexicon_builder.cc
+++ b/research/syntaxnet/syntaxnet/lexicon_builder.cc
@@ -26,6 +26,7 @@ limitations under the License.
 #include "syntaxnet/utils.h"
 #include "tensorflow/core/framework/op_kernel.h"
 #include "tensorflow/core/lib/core/status.h"
+#include "tensorflow/core/lib/strings/str_util.h"
 #include "tensorflow/core/platform/env.h"
 
 // A task that collects term statistics over a corpus and saves a set of
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt b/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
deleted file mode 100644
index 5660bb52..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
+++ /dev/null
@@ -1,64 +0,0 @@
-Parameter {
-  name: "brain_tokenizer_zh_embedding_dims"
-  value: "32;32"
-}
-Parameter {
-  name: "brain_tokenizer_zh_embedding_names"
-  value: "chars;words"
-}
-Parameter {
-  name: "brain_tokenizer_zh_features"
-  value: "input.char "
-         "input(1).char "
-         "input(2).char "
-         "input(3).char "
-         "input(-1).char "
-         "input(-2).char "
-         "input(-3).char "
-         "stack.char "
-         "stack.offset(1).char "
-         "stack.offset(-1).char "
-         "stack(1).char "
-         "stack(1).offset(1).char "
-         "stack(1).offset(-1).char "
-         "stack(2).char; "
-         "last-word(1,min-freq=2) "
-         "last-word(2,min-freq=2) "
-         "last-word(3,min-freq=2)"
-}
-Parameter {
-  name: "brain_tokenizer_zh_transition_system"
-  value: "binary-segment-transitions"
-}
-input {
-  name: "word-map"
-  Part {
-    file_pattern: "last-word-map"
-  }
-}
-input {
-  name: "char-map"
-  Part {
-    file_pattern: "char-map"
-  }
-}
-input {
-  name: "label-map"
-  Part {
-    file_pattern: "label-map"
-  }
-}
-input {
-  name: 'stdin-untoken'
-  record_format: 'untokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdout-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt b/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt
deleted file mode 100644
index 14f611d0..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/context.pbtxt
+++ /dev/null
@@ -1,362 +0,0 @@
-Parameter {
-  name: "brain_tokenizer_embedding_dims"
-  value: "16;16;16"
-}
-Parameter {
-  name: "brain_tokenizer_embedding_names"
-  value: "chars;digits;puncts"
-}
-Parameter {
-  name: "brain_tokenizer_features"
-  value:  "input.char "
-          "input(-1).char "
-          "input(1).char; "
-          "input.digit "
-          "input(-1).digit "
-          "input(1).digit; "
-          "input.punctuation-amount "
-          "input(-1).punctuation-amount "
-          "input(1).punctuation-amount "
-}
-Parameter {
-  name: "brain_tokenizer_transition_system"
-  value: "binary-segment-transitions"
-}
-Parameter {
-  name: "brain_morpher_embedding_dims"
-  value: "2;16;8;16;16;16;16;16;64"
-}
-Parameter {
-  name: "brain_morpher_embedding_names"
-  value: "capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words"
-}
-Parameter {
-  name: "brain_morpher_features"
-  value: "input.capitalization "
-         "input(1).capitalization "
-         "input(2).capitalization "
-         "input(3).capitalization "
-         "input(-1).capitalization "
-         "input(-2).capitalization "
-         "input(-3).capitalization "
-         "input(-4).capitalization; "
-         "input.token.char-ngram "
-         "input(1).token.char-ngram "
-         "input(2).token.char-ngram "
-         "input(3).token.char-ngram "
-         "input(-1).token.char-ngram "
-         "input(-2).token.char-ngram "
-         "input(-3).token.char-ngram "
-         "input(-4).token.char-ngram; "
-         "input.digit "
-         "input.hyphen "
-         "input.token.punctuation-amount "
-         "input.token.quote; "
-         "input.token.prefix(length=2) "
-         "input(1).token.prefix(length=2) "
-         "input(2).token.prefix(length=2) "
-         "input(3).token.prefix(length=2) "
-         "input(-1).token.prefix(length=2) "
-         "input(-2).token.prefix(length=2) "
-         "input(-3).token.prefix(length=2) "
-         "input(-4).token.prefix(length=2); "
-         "input.token.prefix(length=3) "
-         "input(1).token.prefix(length=3) "
-         "input(2).token.prefix(length=3) "
-         "input(3).token.prefix(length=3) "
-         "input(-1).token.prefix(length=3) "
-         "input(-2).token.prefix(length=3) "
-         "input(-3).token.prefix(length=3) "
-         "input(-4).token.prefix(length=3); "
-         "input.token.suffix(length=2) "
-         "input(1).token.suffix(length=2) "
-         "input(2).token.suffix(length=2) "
-         "input(3).token.suffix(length=2) "
-         "input(-1).token.suffix(length=2) "
-         "input(-2).token.suffix(length=2) "
-         "input(-3).token.suffix(length=2) "
-         "input(-4).token.suffix(length=2); "
-         "input.token.suffix(length=3) "
-         "input(1).token.suffix(length=3) "
-         "input(2).token.suffix(length=3) "
-         "input(3).token.suffix(length=3) "
-         "input(-1).token.suffix(length=3) "
-         "input(-2).token.suffix(length=3) "
-         "input(-3).token.suffix(length=3) "
-         "input(-4).token.suffix(length=3); "
-         "input(-1).pred-morph-tag "
-         "input(-2).pred-morph-tag "
-         "input(-3).pred-morph-tag "
-         "input(-4).pred-morph-tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "input(-1).token.word "
-         "input(-2).token.word "
-         "input(-3).token.word "
-         "input(-4).token.word"
-}
-Parameter {
-  name: "brain_morpher_transition_system"
-  value: "morpher"
-}
-Parameter {
-  name: "brain_tagger_embedding_dims"
-  value: "2;16;8;16;16;16;16;16;64"
-}
-Parameter {
-  name: "brain_tagger_embedding_names"
-  value: "capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words"
-}
-Parameter {
-  name: "brain_tagger_features"
-  value: "input.capitalization "
-         "input(1).capitalization "
-         "input(2).capitalization "
-         "input(3).capitalization "
-         "input(-1).capitalization "
-         "input(-2).capitalization "
-         "input(-3).capitalization "
-         "input(-4).capitalization; "
-         "input.token.char-ngram "
-         "input(1).token.char-ngram "
-         "input(2).token.char-ngram "
-         "input(3).token.char-ngram "
-         "input(-1).token.char-ngram "
-         "input(-2).token.char-ngram "
-         "input(-3).token.char-ngram "
-         "input(-4).token.char-ngram; "
-         "input.digit "
-         "input.hyphen "
-         "input.token.punctuation-amount "
-         "input.token.quote; "
-         "input.token.prefix(length=2) "
-         "input(1).token.prefix(length=2) "
-         "input(2).token.prefix(length=2) "
-         "input(3).token.prefix(length=2) "
-         "input(-1).token.prefix(length=2) "
-         "input(-2).token.prefix(length=2) "
-         "input(-3).token.prefix(length=2) "
-         "input(-4).token.prefix(length=2); "
-         "input.token.prefix(length=3) "
-         "input(1).token.prefix(length=3) "
-         "input(2).token.prefix(length=3) "
-         "input(3).token.prefix(length=3) "
-         "input(-1).token.prefix(length=3) "
-         "input(-2).token.prefix(length=3) "
-         "input(-3).token.prefix(length=3) "
-         "input(-4).token.prefix(length=3); "
-         "input.token.suffix(length=2) "
-         "input(1).token.suffix(length=2) "
-         "input(2).token.suffix(length=2) "
-         "input(3).token.suffix(length=2) "
-         "input(-1).token.suffix(length=2) "
-         "input(-2).token.suffix(length=2) "
-         "input(-3).token.suffix(length=2) "
-         "input(-4).token.suffix(length=2); "
-         "input.token.suffix(length=3) "
-         "input(1).token.suffix(length=3) "
-         "input(2).token.suffix(length=3) "
-         "input(3).token.suffix(length=3) "
-         "input(-1).token.suffix(length=3) "
-         "input(-2).token.suffix(length=3) "
-         "input(-3).token.suffix(length=3) "
-         "input(-4).token.suffix(length=3); "
-         "input(-1).pred-tag "
-         "input(-2).pred-tag "
-         "input(-3).pred-tag "
-         "input(-4).pred-tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "input(-1).token.word "
-         "input(-2).token.word "
-         "input(-3).token.word "
-         "input(-4).token.word"
-}
-Parameter {
-  name: "brain_tagger_transition_system"
-  value: "tagger"
-}
-Parameter {
-  name: "brain_parser_embedding_dims"
-  value: "32;32;32;64"
-}
-Parameter {
-  name: "brain_parser_embedding_names"
-  value: "labels;morphology;tags;words"
-}
-Parameter {
-  name: "brain_parser_features"
-  value: "stack.child(1).label "
-         "stack.child(1).sibling(-1).label "
-         "stack.child(-1).label "
-         "stack.child(-1).sibling(1).label "
-         "stack.child(2).label "
-         "stack.child(-2).label "
-         "stack(1).child(1).label "
-         "stack(1).child(1).sibling(-1).label "
-         "stack(1).child(-1).label "
-         "stack(1).child(-1).sibling(1).label "
-         "stack(1).child(2).label "
-         "stack(1).child(-2).label; "
-         "input.token.morphology-set "
-         "input(1).token.morphology-set "
-         "input(2).token.morphology-set "
-         "input(3).token.morphology-set "
-         "stack.token.morphology-set "
-         "stack.child(1).token.morphology-set "
-         "stack.child(1).sibling(-1).token.morphology-set "
-         "stack.child(-1).token.morphology-set "
-         "stack.child(-1).sibling(1).token.morphology-set "
-         "stack.child(2).token.morphology-set "
-         "stack.child(-2).token.morphology-set "
-         "stack(1).token.morphology-set "
-         "stack(1).child(1).token.morphology-set "
-         "stack(1).child(1).sibling(-1).token.morphology-set "
-         "stack(1).child(-1).token.morphology-set "
-         "stack(1).child(-1).sibling(1).token.morphology-set "
-         "stack(1).child(2).token.morphology-set "
-         "stack(1).child(-2).token.morphology-set "
-         "stack(2).token.morphology-set "
-         "stack(3).token.morphology-set; "
-         "input.token.tag "
-         "input(1).token.tag "
-         "input(2).token.tag "
-         "input(3).token.tag "
-         "stack.token.tag "
-         "stack.child(1).token.tag "
-         "stack.child(1).sibling(-1).token.tag "
-         "stack.child(-1).token.tag "
-         "stack.child(-1).sibling(1).token.tag "
-         "stack.child(2).token.tag "
-         "stack.child(-2).token.tag "
-         "stack(1).token.tag "
-         "stack(1).child(1).token.tag "
-         "stack(1).child(1).sibling(-1).token.tag "
-         "stack(1).child(-1).token.tag "
-         "stack(1).child(-1).sibling(1).token.tag "
-         "stack(1).child(2).token.tag "
-         "stack(1).child(-2).token.tag "
-         "stack(2).token.tag "
-         "stack(3).token.tag; "
-         "input.token.word "
-         "input(1).token.word "
-         "input(2).token.word "
-         "input(3).token.word "
-         "stack.token.word "
-         "stack.child(1).token.word "
-         "stack.child(1).sibling(-1).token.word "
-         "stack.child(-1).token.word "
-         "stack.child(-1).sibling(1).token.word "
-         "stack.child(2).token.word "
-         "stack.child(-2).token.word "
-         "stack(1).token.word "
-         "stack(1).child(1).token.word "
-         "stack(1).child(1).sibling(-1).token.word "
-         "stack(1).child(-1).token.word "
-         "stack(1).child(-1).sibling(1).token.word "
-         "stack(1).child(2).token.word "
-         "stack(1).child(-2).token.word "
-         "stack(2).token.word "
-         "stack(3).token.word "
-}
-Parameter {
-  name: "brain_parser_transition_system"
-  value: "arc-standard"
-}
-Parameter {
-  name: "join_category_to_pos"
-  value: "true"
-}
-input {
-  name: "word-map"
-  Part {
-    file_pattern: "word-map"
-  }
-}
-input {
-  name: "char-map"
-  Part {
-    file_pattern: "char-map"
-  }
-}
-input {
-  name: "tag-map"
-  Part {
-    file_pattern: "tag-map"
-  }
-}
-
-input {
-  name: "tag-to-category"
-  Part {
-    file_pattern: "tag-to-category"
-  }
-}
-input {
-  name: "label-map"
-  Part {
-    file_pattern: "label-map"
-  }
-}
-input {
-  name: "char-ngram-map"
-  Part {
-    file_pattern: "char-ngram-map"
-  }
-}
-input {
-  name: "prefix-table"
-  Part {
-    file_pattern: "prefix-table"
-  }
-}
-input {
-  name: "suffix-table"
-  Part {
-    file_pattern: "suffix-table"
-  }
-}
-input {
-  name: "morph-label-set"
-  Part {
-    file_pattern: "morph-label-set"
-  }
-}
-input {
-  name: "morphology-map"
-  Part {
-    file_pattern: "morphology-map"
-  }
-}
-input {
-  name: 'stdin'
-  record_format: 'tokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdin-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdin-untoken'
-  record_format: 'untokenized-text'
-  Part {
-    file_pattern: '-'
-  }
-}
-input {
-  name: 'stdout-conll'
-  record_format: 'conll-sentence'
-  Part {
-    file_pattern: '-'
-  }
-}
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh
deleted file mode 100755
index 2478d926..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/parse.sh
+++ /dev/null
@@ -1,68 +0,0 @@
-# A script that runs a morphological analyzer, a part-of-speech tagger and a
-# dependency parser on a text file, with one sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat sentences.txt |
-#    syntaxnet/models/parsey_universal/parse.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# To run on a conll formatted file, add the --conll command line argument:
-#  cat sentences.conll |
-#    syntaxnet/models/parsey_universal/parse.sh \
-#    --conll $MODEL_DIRECTORY > output.conll
-#
-# Models can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/<language>.zip
-# for the languages listed at
-#  https://github.com/tensorflow/models/blob/master/research/syntaxnet/universal.md
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context.pbtxt
-if [[ "$1" == "--conll" ]]; then
-  INPUT_FORMAT=stdin-conll
-  shift
-else
-  INPUT_FORMAT=stdin
-fi
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdout-conll \
-  --hidden_layer_sizes=64 \
-  --arg_prefix=brain_morpher \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/morpher-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr \
-  | \
-  $PARSER_EVAL \
-  --input=stdin-conll \
-  --output=stdout-conll \
-  --hidden_layer_sizes=64 \
-  --arg_prefix=brain_tagger \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tagger-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr \
-  | \
-  $PARSER_EVAL \
-  --input=stdin-conll \
-  --output=stdout-conll \
-  --hidden_layer_sizes=512,512 \
-  --arg_prefix=brain_parser \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/parser-params \
-  --slim_model \
-  --batch_size=1024 \
-  --alsologtostderr
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh
deleted file mode 100755
index 7c81e0fa..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize.sh
+++ /dev/null
@@ -1,31 +0,0 @@
-# A script that runs a tokenizer on a text file with one sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat untokenized-sentences.txt |
-#    syntaxnet/models/parsey_universal/tokenize.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# Models can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/<language>.zip
-# for the languages listed at
-#  https://github.com/tensorflow/models/blob/master/research/syntaxnet/universal.md
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context.pbtxt
-INPUT_FORMAT=stdin-untoken
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdin-untoken \
-  --hidden_layer_sizes=128,128 \
-  --arg_prefix=brain_tokenizer \
-  --graph_builder=greedy \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tokenizer-params \
-  --batch_size=32 \
-  --alsologtostderr \
-  --slim_model
diff --git a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh b/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh
deleted file mode 100755
index bc6cd431..00000000
--- a/research/syntaxnet/syntaxnet/models/parsey_universal/tokenize_zh.sh
+++ /dev/null
@@ -1,30 +0,0 @@
-# A script that runs a traditional Chinese tokenizer on a text file with one
-# sentence per line.
-#
-# Example usage:
-#  bazel build syntaxnet:parser_eval
-#  cat untokenized-sentences.txt |
-#    syntaxnet/models/parsey_universal/tokenize_zh.sh \
-#    $MODEL_DIRECTORY > output.conll
-#
-# The traditional Chinese model can be downloaded from
-#  http://download.tensorflow.org/models/parsey_universal/Chinese.zip
-#
-
-PARSER_EVAL=bazel-bin/syntaxnet/parser_eval
-CONTEXT=syntaxnet/models/parsey_universal/context-tokenize-zh.pbtxt
-INPUT_FORMAT=stdin-untoken
-MODEL_DIR=$1
-
-$PARSER_EVAL \
-  --input=$INPUT_FORMAT \
-  --output=stdin-untoken \
-  --hidden_layer_sizes=256,256 \
-  --arg_prefix=brain_tokenizer_zh \
-  --graph_builder=structured \
-  --task_context=$CONTEXT \
-  --resource_dir=$MODEL_DIR \
-  --model_path=$MODEL_DIR/tokenizer-params \
-  --batch_size=1024 \
-  --alsologtostderr \
-  --slim_model
diff --git a/research/syntaxnet/syntaxnet/morphology_label_set.h b/research/syntaxnet/syntaxnet/morphology_label_set.h
index eb309b5e..7d4601f8 100644
--- a/research/syntaxnet/syntaxnet/morphology_label_set.h
+++ b/research/syntaxnet/syntaxnet/morphology_label_set.h
@@ -43,8 +43,7 @@ class MorphologyLabelSet {
   int Add(const TokenMorphology &morph);
 
   // Look up an existing TokenMorphology. If it is not present, return -1.
-  // Note: This is slow, and should not be called outside of training workflow
-  // or init.
+  // Note: This is slow, and should not be called outside of training or init.
   int LookupExisting(const TokenMorphology &morph) const;
 
   // Return the TokenMorphology at position i. The input i should be in the
diff --git a/research/syntaxnet/syntaxnet/ops/parser_ops.cc b/research/syntaxnet/syntaxnet/ops/parser_ops.cc
index 9dddf04b..7695093e 100644
--- a/research/syntaxnet/syntaxnet/ops/parser_ops.cc
+++ b/research/syntaxnet/syntaxnet/ops/parser_ops.cc
@@ -258,7 +258,7 @@ REGISTER_OP("WordEmbeddingInitializer")
 Reads word embeddings from an sstable of dist_belief.TokenEmbedding protos for
 every word specified in a text vocabulary file.
 
-word_embeddings: a tensor containing word embeddings from the specified table.
+word_embeddings: a tensor containing word embeddings from the specified sstable.
 vectors: path to TF record file of word embedding vectors.
 task_context: file path at which to read the task context, for its "word-map"
   input.  Exactly one of `task_context` or `vocabulary` must be specified.
diff --git a/research/syntaxnet/syntaxnet/parser_features.cc b/research/syntaxnet/syntaxnet/parser_features.cc
index 35591bf3..4cda1bd2 100644
--- a/research/syntaxnet/syntaxnet/parser_features.cc
+++ b/research/syntaxnet/syntaxnet/parser_features.cc
@@ -17,8 +17,10 @@ limitations under the License.
 
 #include <string>
 
+#include "syntaxnet/generic_features.h"
 #include "syntaxnet/registry.h"
 #include "syntaxnet/sentence_features.h"
+#include "syntaxnet/whole_sentence_features.h"
 #include "syntaxnet/workspace.h"
 
 namespace syntaxnet {
@@ -347,4 +349,8 @@ class Constant : public ParserFeatureFunction {
 
 REGISTER_PARSER_FEATURE_FUNCTION("constant", Constant);
 
+// Register the generic parser features.
+typedef GenericFeatures<ParserState> GenericParserFeature;
+REGISTER_SYNTAXNET_GENERIC_FEATURES(GenericParserFeature);
+
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/parser_features.h b/research/syntaxnet/syntaxnet/parser_features.h
index 79176229..fed3ead4 100644
--- a/research/syntaxnet/syntaxnet/parser_features.h
+++ b/research/syntaxnet/syntaxnet/parser_features.h
@@ -146,6 +146,14 @@ class BasicParserSentenceFeatureFunction :
   }
 };
 
+// Registry for the parser feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("parser feature function",
+                                 ParserFeatureFunction);
+
+// Registry for the parser state + token index feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("parser+index feature function",
+                                 ParserIndexFeatureFunction);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_PARSER_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/parser_features_test.cc b/research/syntaxnet/syntaxnet/parser_features_test.cc
index 66a046c4..42fe8904 100644
--- a/research/syntaxnet/syntaxnet/parser_features_test.cc
+++ b/research/syntaxnet/syntaxnet/parser_features_test.cc
@@ -84,7 +84,6 @@ class ParserFeatureFunctionTest : public ::testing::Test {
   // Prepares a feature for computations.
   string ExtractFeature(const string &feature_name) {
     context_.mutable_spec()->mutable_input()->Clear();
-    context_.mutable_spec()->mutable_output()->Clear();
     feature_extractor_.reset(new ParserFeatureExtractor());
     feature_extractor_->Parse(feature_name);
     feature_extractor_->Setup(&context_);
@@ -152,4 +151,10 @@ TEST_F(ParserFeatureFunctionTest, GoldHeadFeatureFunction) {
   EXPECT_EQ("1", ExtractFeature("input(7).gold-head"));
 }
 
+TEST_F(ParserFeatureFunctionTest, PairFeatureFunction) {
+  EXPECT_EQ("(1,PRP)", ExtractFeature("pair { input.gold-head input.tag }"));
+  EXPECT_EQ("(1,PRP,ROOT)",
+            ExtractFeature("triple { input.gold-head input.tag input.label }"));
+}
+
 }  // namespace syntaxnet
diff --git a/research/syntaxnet/syntaxnet/parser_transitions.cc b/research/syntaxnet/syntaxnet/parser_transitions.cc
index 53bc16e0..e5607e0a 100644
--- a/research/syntaxnet/syntaxnet/parser_transitions.cc
+++ b/research/syntaxnet/syntaxnet/parser_transitions.cc
@@ -22,6 +22,8 @@ namespace syntaxnet {
 // Transition system registry.
 REGISTER_SYNTAXNET_CLASS_REGISTRY("transition system", ParserTransitionSystem);
 
+constexpr int ParserTransitionSystem::kDynamicNumActions;
+
 void ParserTransitionSystem::PerformAction(ParserAction action,
                                            ParserState *state) const {
   if (state->keep_history()) {
diff --git a/research/syntaxnet/syntaxnet/parser_transitions.h b/research/syntaxnet/syntaxnet/parser_transitions.h
index 7c545885..f1ab6d82 100644
--- a/research/syntaxnet/syntaxnet/parser_transitions.h
+++ b/research/syntaxnet/syntaxnet/parser_transitions.h
@@ -74,6 +74,9 @@ class ParserTransitionState {
 class ParserTransitionSystem
     : public RegisterableClass<ParserTransitionSystem> {
  public:
+  // Sentinel value that represents a dynamic action set.
+  static constexpr int kDynamicNumActions = -1;
+
   // Construction and cleanup.
   ParserTransitionSystem() {}
   virtual ~ParserTransitionSystem() {}
@@ -94,7 +97,8 @@ class ParserTransitionSystem
   // Returns the number of action types.
   virtual int NumActionTypes() const = 0;
 
-  // Returns the number of actions.
+  // Returns the number of actions, or |kDynamicNumActions| if the action set is
+  // dynamic (i.e., varies per instance).
   virtual int NumActions(int num_labels) const = 0;
 
   // Internally creates the set of outcomes (when transition systems support a
@@ -196,6 +200,9 @@ class ParserTransitionSystem
 #define REGISTER_TRANSITION_SYSTEM(type, component) \
   REGISTER_SYNTAXNET_CLASS_COMPONENT(ParserTransitionSystem, type, component)
 
+// Transition system registry.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("transition system", ParserTransitionSystem);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_PARSER_TRANSITIONS_H_
diff --git a/research/syntaxnet/syntaxnet/proto_io.h b/research/syntaxnet/syntaxnet/proto_io.h
index a3f0e8e2..b18378c5 100644
--- a/research/syntaxnet/syntaxnet/proto_io.h
+++ b/research/syntaxnet/syntaxnet/proto_io.h
@@ -66,6 +66,8 @@ class ProtoRecordReader {
       CHECK(proto->ParseFromString(buffer));
       return tensorflow::Status::OK();
     } else {
+      CHECK_EQ(status.code(), tensorflow::error::OUT_OF_RANGE)
+          << "Non-OK and non-out-of-range (EOF) status: " << status;
       return status;
     }
   }
diff --git a/research/syntaxnet/syntaxnet/reader_ops_test.py b/research/syntaxnet/syntaxnet/reader_ops_test.py
index d7fadaac..f95119e8 100644
--- a/research/syntaxnet/syntaxnet/reader_ops_test.py
+++ b/research/syntaxnet/syntaxnet/reader_ops_test.py
@@ -15,7 +15,6 @@
 
 """Tests for reader_ops."""
 
-# pylint: disable=no-name-in-module,unused-import,g-bad-import-order,maybe-no-member,no-member,g-importing-member
 
 import os.path
 import numpy as np
@@ -30,6 +29,7 @@ from syntaxnet import graph_builder
 from syntaxnet import sparse_pb2
 from syntaxnet.ops import gen_parser_ops
 
+
 FLAGS = tf.app.flags.FLAGS
 if not hasattr(FLAGS, 'test_srcdir'):
   FLAGS.test_srcdir = ''
diff --git a/research/syntaxnet/syntaxnet/registry.h b/research/syntaxnet/syntaxnet/registry.h
index 8ec033db..dd4c6655 100644
--- a/research/syntaxnet/syntaxnet/registry.h
+++ b/research/syntaxnet/syntaxnet/registry.h
@@ -229,6 +229,10 @@ class RegisterableInstance {
   classname::Registry RegisterableClass<classname>::registry_ = { \
       type, #classname, __FILE__, __LINE__, NULL}
 
+#define DECLARE_SYNTAXNET_CLASS_REGISTRY(type, classname) \
+  template <>                                             \
+  classname::Registry RegisterableClass<classname>::registry_;
+
 #define REGISTER_SYNTAXNET_INSTANCE_COMPONENT(base, type, component) \
   static base::Registry::Registrar __##component##__##registrar(     \
       base::registry(), type, #component, __FILE__, __LINE__, new component)
@@ -238,6 +242,10 @@ class RegisterableInstance {
   classname::Registry RegisterableInstance<classname>::registry_ = { \
       type, #classname, __FILE__, __LINE__, NULL}
 
+#define DECLARE_SYNTAXNET_INSTANCE_REGISTRY(type, classname) \
+  template <>                                                \
+  classname::Registry RegisterableInstance<classname>::registry_;
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_REGISTRY_H_
diff --git a/research/syntaxnet/syntaxnet/sentence_features.h b/research/syntaxnet/syntaxnet/sentence_features.h
index e7e2bf9c..c6985840 100644
--- a/research/syntaxnet/syntaxnet/sentence_features.h
+++ b/research/syntaxnet/syntaxnet/sentence_features.h
@@ -663,6 +663,10 @@ typedef FeatureExtractor<Sentence, int> SentenceExtractor;
 #define REGISTER_SENTENCE_IDX_FEATURE(name, type) \
   REGISTER_SYNTAXNET_FEATURE_FUNCTION(SentenceFeature, name, type)
 
+// Registry for the Sentence + token index feature functions.
+DECLARE_SYNTAXNET_CLASS_REGISTRY("sentence+index feature function",
+                                 SentenceFeature);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_SENTENCE_FEATURES_H_
diff --git a/research/syntaxnet/syntaxnet/sentence_features_test.cc b/research/syntaxnet/syntaxnet/sentence_features_test.cc
index 1945988d..3049e086 100644
--- a/research/syntaxnet/syntaxnet/sentence_features_test.cc
+++ b/research/syntaxnet/syntaxnet/sentence_features_test.cc
@@ -51,7 +51,6 @@ class SentenceFeaturesTest : public ::testing::Test {
   // anything in info_ field into the LexiFuse repository.
   virtual void PrepareFeature(const string &fml) {
     context_.mutable_spec()->mutable_input()->Clear();
-    context_.mutable_spec()->mutable_output()->Clear();
     extractor_.reset(new SentenceExtractor());
     extractor_->Parse(fml);
     extractor_->Setup(&context_);
@@ -78,6 +77,7 @@ class SentenceFeaturesTest : public ::testing::Test {
     FeatureVector result;
     extractor_->ExtractFeatures(workspaces_, sentence_, index,
                                 &result);
+    values.reserve(result.size());
     for (int i = 0; i < result.size(); ++i) {
       values.push_back(result.type(i)->GetFeatureValueName(result.value(i)));
     }
@@ -99,6 +99,7 @@ class SentenceFeaturesTest : public ::testing::Test {
   void CheckVectorWorkspace(const VectorIntWorkspace &workspace,
                             std::vector<int> target) {
     std::vector<int> src;
+    src.reserve(workspace.size());
     for (int i = 0; i < workspace.size(); ++i) {
       src.push_back(workspace.element(i));
     }
diff --git a/research/syntaxnet/syntaxnet/syntaxnet_ops.py b/research/syntaxnet/syntaxnet/syntaxnet_ops.py
index 1de0390c..6194e6f8 100644
--- a/research/syntaxnet/syntaxnet/syntaxnet_ops.py
+++ b/research/syntaxnet/syntaxnet/syntaxnet_ops.py
@@ -16,6 +16,6 @@
 """Imports the SyntaxNet ops and their C++ implementations."""
 
 
-from syntaxnet.ops.gen_parser_ops import *  # pylint: disable=wildcard-import
+from syntaxnet.ops.gen_parser_ops import *
 
 import syntaxnet.load_parser_ops
diff --git a/research/syntaxnet/syntaxnet/task_spec.proto b/research/syntaxnet/syntaxnet/task_spec.proto
index ecc9ab72..e690827e 100644
--- a/research/syntaxnet/syntaxnet/task_spec.proto
+++ b/research/syntaxnet/syntaxnet/task_spec.proto
@@ -35,39 +35,8 @@ message TaskInput {
   }
 }
 
-// Task output descriptor.
-message TaskOutput {
-  // Name of output resource.
-  required string name = 1;
-
-  // File format for output resource.
-  optional string file_format = 2;
-
-  // Record format for output resource.
-  optional string record_format = 3;
-
-  // Number of shards in output. If it is different from zero this output is
-  // sharded. If the number of shards is set to -1 this means that the output is
-  // sharded, but the number of shard is unknown. The files are then named
-  // 'base-*-of-*'.
-  optional int32 shards = 4 [default = 0];
-
-  // Base file name for output resource. If this is not set by the task
-  // component it is set to a default value by the workflow engine.
-  optional string file_base = 5;
-
-  // Optional extension added to the file name.
-  optional string file_extension = 6;
-}
-
 // A task specification is used for describing executing parameters.
 message TaskSpec {
-  // Name of task.
-  optional string task_name = 1;
-
-  // Workflow task type.
-  optional string task_type = 2;
-
   // Task parameters.
   repeated group Parameter = 3 {
     required string name = 4;
@@ -77,6 +46,6 @@ message TaskSpec {
   // Task inputs.
   repeated TaskInput input = 6;
 
-  // Task outputs.
-  repeated TaskOutput output = 7;
+  reserved 1, 2, 7;
+  reserved "task_name", "task_type", "output";
 }
diff --git a/research/syntaxnet/syntaxnet/term_frequency_map.cc b/research/syntaxnet/syntaxnet/term_frequency_map.cc
index 00891c19..f638ba43 100644
--- a/research/syntaxnet/syntaxnet/term_frequency_map.cc
+++ b/research/syntaxnet/syntaxnet/term_frequency_map.cc
@@ -68,7 +68,8 @@ void TermFrequencyMap::Load(const string &filename, int min_frequency,
   string line;
   TF_CHECK_OK(buffer.ReadLine(&line));
   int32 total = -1;
-  CHECK(utils::ParseInt32(line.c_str(), &total));
+  CHECK(utils::ParseInt32(line.c_str(), &total))
+      << "Unable to parse from " << filename;
   CHECK_GE(total, 0);
 
   // Read the mapping.
diff --git a/research/syntaxnet/syntaxnet/testdata/hello.txt b/research/syntaxnet/syntaxnet/testdata/hello.txt
new file mode 100644
index 00000000..3b18e512
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/testdata/hello.txt
@@ -0,0 +1 @@
+hello world
diff --git a/research/syntaxnet/syntaxnet/text_formats.cc b/research/syntaxnet/syntaxnet/text_formats.cc
index 93d1b785..0ea2cc75 100644
--- a/research/syntaxnet/syntaxnet/text_formats.cc
+++ b/research/syntaxnet/syntaxnet/text_formats.cc
@@ -157,7 +157,12 @@ class CoNLLSyntaxFormat : public DocumentFormat {
       const int start = text.size();
       const int end = start + word.size() - 1;
       text.append(word);
-      add_space_to_text = fields[9] != "SpaceAfter=No";
+
+      // Determine whether a space should be added to sentence text.
+      std::vector<string> sub_fields = utils::Split(fields[9], '|');
+      auto no_space = [](const string &str) { return str == "SpaceAfter=No"; };
+      add_space_to_text =
+          !std::any_of(sub_fields.begin(), sub_fields.end(), no_space);
 
       // Add token to sentence.
       Token *token = sentence->add_token();
@@ -329,28 +334,28 @@ REGISTER_SYNTAXNET_DOCUMENT_FORMAT("conll-sentence", CoNLLSyntaxFormat);
 //
 // Examples:
 // To create a training example for sentence with raw text:
-//   That's a good point.
+//   "That's a good point."
 // and the corresponding gold segmentation:
-//   That 's a good point .
+//   "That" "\'s" "a" "good" "point" "."
 // Then the correct input is:
-// That	NO_SPACE
-// 's	SPACE
-// a	SPACE
-// good	SPACE
-// point	NO_SPACE
-// .	NO_SPACE
+// "That\tNO_SPACE"
+// "'s\tSPACE"
+// "a\tSPACE"
+// "good\tSPACE"
+// "point\tNO_SPACE"
+// ".\tNO_SPACE"
 //
 // Yet another example:
 // To create a training example for sentence with raw text:
-//   这是一个测试
+//   "这是一个测试"
 // and the corresponding gold segmentation:
-//   这 是 一 个 测试
+//   "这" "是" "一" "个" "测试"
 // Then the correct input is:
-// 这	NO_SPACE
-// 是	NO_SPACE
-// 一	NO_SPACE
-// 个	NO_SPACE
-// 测试	NO_SPACE
+// "这\tNO_SPACE"
+// "是\tNO_SPACE"
+// "一\tNO_SPACE"
+// "个\tNO_SPACE"
+// "测试\tNO_SPACE"
 class SegmentationTrainingDataFormat : public CoNLLSyntaxFormat {
  public:
   // Converts to segmentation training data by breaking those word in the input
diff --git a/research/syntaxnet/syntaxnet/text_formats_test.py b/research/syntaxnet/syntaxnet/text_formats_test.py
index e9a45e16..4a408cd3 100644
--- a/research/syntaxnet/syntaxnet/text_formats_test.py
+++ b/research/syntaxnet/syntaxnet/text_formats_test.py
@@ -113,13 +113,13 @@ class TextFormatsTest(test_util.TensorFlowTestCase):
     # This test sentence includes a multiword token and an empty node,
     # both of which are to be ignored.
     test_sentence = """
-1-2	We've	_
-1	We	we	PRON	PRP	Case=Nom	3	nsubj	_	SpaceAfter=No
-2	've	have	AUX	VBP	Mood=Ind	3	aux	_	_
-3	moved	move	VERB	VBN	Tense=Past	0	root	_	_
-4	on	on	ADV	RB	_	3	advmod	_	SpaceAfter=No
-4.1	ignored	ignore	VERB	VBN	Tense=Past	0	_	_	_
-5	.	.	PUNCT	.	_	3	punct	_	_
+1-2\tWe've\t_
+1\tWe\twe\tPRON\tPRP\tCase=Nom\t3\tnsubj\t_\tSpaceAfter=No
+2\t've\thave\tAUX\tVBP\tMood=Ind\t3\taux\t_\t_
+3\tmoved\tmove\tVERB\tVBN\tTense=Past\t0\troot\t_\t_
+4\ton\ton\tADV\tRB\t_\t3\tadvmod\t_\tSpaceAfter=No|foobar=baz
+4.1\tignored\tignore\tVERB\tVBN\tTense=Past\t0\t_\t_\t_
+5\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_
 """
 
     # Prepare test sentence.
@@ -191,13 +191,13 @@ token {
       self.assertEqual(expected_ends, [t.end for t in sentence_doc.token])
 
   def testSegmentationTrainingData(self):
-    doc1_lines = ['测试	NO_SPACE\n', '的	NO_SPACE\n', '句子	NO_SPACE']
+    doc1_lines = ['测试\tNO_SPACE\n', '的\tNO_SPACE\n', '句子\tNO_SPACE']
     doc1_text = '测试的句子'
     doc1_tokens = ['测', '试', '的', '句', '子']
     doc1_break_levles = [1, 0, 1, 1, 0]
     doc2_lines = [
-        'That	NO_SPACE\n', '\'s	SPACE\n', 'a	SPACE\n', 'good	SPACE\n',
-        'point	NO_SPACE\n', '.	NO_SPACE'
+        'That\tNO_SPACE\n', '\'s\tSPACE\n', 'a\tSPACE\n', 'good\tSPACE\n',
+        'point\tNO_SPACE\n', '.\tNO_SPACE'
     ]
     doc2_text = 'That\'s a good point.'
     doc2_tokens = [
diff --git a/research/syntaxnet/syntaxnet/util/BUILD b/research/syntaxnet/syntaxnet/util/BUILD
index be58d249..39867e5f 100644
--- a/research/syntaxnet/syntaxnet/util/BUILD
+++ b/research/syntaxnet/syntaxnet/util/BUILD
@@ -16,6 +16,14 @@ py_library(
     srcs = ["check.py"],
 )
 
+py_library(
+    name = "resources",
+    srcs = ["resources.py"],
+    visibility = ["//visibility:public"],
+    deps = [
+    ],
+)
+
 py_library(
     name = "pyregistry_test_base",
     testonly = 1,
@@ -56,3 +64,15 @@ py_test(
         "@org_tensorflow//tensorflow/core:protos_all_py",
     ],
 )
+
+py_test(
+    name = "resources_test",
+    srcs = ["resources_test.py"],
+    data = [
+        "//syntaxnet:testdata/hello.txt",
+    ],
+    deps = [
+        ":resources",
+        "@org_tensorflow//tensorflow:tensorflow_py",
+    ],
+)
diff --git a/research/syntaxnet/syntaxnet/util/registry.py b/research/syntaxnet/syntaxnet/util/registry.py
index b413c02a..4dc87d9b 100644
--- a/research/syntaxnet/syntaxnet/util/registry.py
+++ b/research/syntaxnet/syntaxnet/util/registry.py
@@ -1,13 +1,28 @@
-"""A component registry, similar to nlp_saft::RegisteredClass<>.
-
-Like nlp_saft::RegisteredClass<>, one does not need to explicitly import the
-module containing each subclass.  It is sufficient to add subclasses as build
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""A component registry, similar to RegisterableClass<>.
+
+Like RegisterableClass<>, one does not need to explicitly import the module
+containing each subclass.  It is sufficient to add subclasses as build
 dependencies.
 
-Unlike nlp_saft::RegisteredClass<>, which allows subclasses to be registered
-under arbitrary names, subclasses must be looked up based on their type name.
-This restriction allows the registry to dynamically import the module containing
-the desired subclass.
+Unlike RegisterableClass<>, which allows subclasses to be registered under
+arbitrary names, subclasses must be looked up based on their type name.  This
+restriction allows the registry to dynamically import the module containing the
+desired subclass.
 
 Example usage:
 
@@ -82,7 +97,7 @@ def _GetClass(name):
 
   # Need at least "module.Class".
   if len(elements) < 2:
-    logging.debug('Malformed type: "%s"', name)
+    logging.info('Malformed type: "%s"', name)
     return None
   module_path = '.'.join(elements[:-1])
   class_name = elements[-1]
@@ -91,20 +106,19 @@ def _GetClass(name):
   try:
     __import__(module_path)
   except ImportError as e:
-    logging.debug('Unable to find module "%s": "%s"', module_path, e)
+    logging.info('Unable to find module "%s": "%s"', module_path, e)
     return None
   module = sys.modules[module_path]
 
   # Look up the class.
   if not hasattr(module, class_name):
-    logging.debug('Name "%s" not found in module: "%s"', class_name,
-                  module_path)
+    logging.info('Name "%s" not found in module: "%s"', class_name, module_path)
     return None
   class_obj = getattr(module, class_name)
 
   # Check that it is actually a class.
   if not inspect.isclass(class_obj):
-    logging.debug('Name does not refer to a class: "%s"', name)
+    logging.info('Name does not refer to a class: "%s"', name)
     return None
   return class_obj
 
@@ -125,8 +139,8 @@ def _Create(baseclass, subclass_name, *args, **kwargs):
   if subclass is None:
     return None  # _GetClass() already logged an error
   if not issubclass(subclass, baseclass):
-    logging.debug('Class "%s" is not a subclass of "%s"', subclass_name,
-                  baseclass.__name__)
+    logging.info('Class "%s" is not a subclass of "%s"', subclass_name,
+                 baseclass.__name__)
     return None
   return subclass(*args, **kwargs)
 
@@ -135,13 +149,13 @@ def _ResolveAndCreate(baseclass, path, subclass_name, *args, **kwargs):
   """Resolves the name of a subclass and creates an instance of it.
 
   The subclass is resolved with respect to a package path in an inside-out
-  manner.  For example, if |path| is 'google3.foo.bar' and |subclass_name| is
+  manner.  For example, if |path| is 'syntaxnet.foo.bar' and |subclass_name| is
   'baz.ClassName', then attempts are made to create instances of the following
   fully-qualified class names:
 
-    'google3.foo.bar.baz.ClassName'
-    'google3.foo.baz.ClassName'
-    'google3.baz.ClassName'
+    'syntaxnet.foo.bar.baz.ClassName'
+    'syntaxnet.foo.baz.ClassName'
+    'syntaxnet.baz.ClassName'
     'baz.ClassName'
 
   An instance corresponding to the first successful attempt is returned.
@@ -163,9 +177,12 @@ def _ResolveAndCreate(baseclass, path, subclass_name, *args, **kwargs):
   elements = path.split('.')
   while True:
     resolved_subclass_name = '.'.join(elements + [subclass_name])
+    logging.info('Attempting to instantiate "%s"', resolved_subclass_name)
     subclass = _Create(baseclass, resolved_subclass_name, *args, **kwargs)
-    if subclass: return subclass  # success
-    if not elements: break  # no more paths to try
+    if subclass:
+      return subclass  # success
+    if not elements:
+      break  # no more paths to try
     elements.pop()  # try resolving against the next-outer path
   raise ValueError(
       'Failed to create subclass "%s" of base class %s using path %s' %
diff --git a/research/syntaxnet/syntaxnet/util/registry_test.py b/research/syntaxnet/syntaxnet/util/registry_test.py
index 53d337e9..90ff0286 100644
--- a/research/syntaxnet/syntaxnet/util/registry_test.py
+++ b/research/syntaxnet/syntaxnet/util/registry_test.py
@@ -1,3 +1,18 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
 """Tests for registry system.
 
 This test uses two other modules:
@@ -104,9 +119,11 @@ class RegistryTest(googletest.TestCase):
   def testCannotResolveRelativeName(self):
     """Tests that Create fails if a relative path cannot be resolved."""
     for name in [
-        'nlp.saft.opensource.syntaxnet.util.registry_test_base.Impl',
-        'saft.bad.registry_test_impl.Impl', 'missing.registry_test_impl.Impl',
-        'registry_test_impl.Bad', 'Impl'
+        'bad.syntaxnet.util.registry_test_base.Impl',
+        'syntaxnet.bad.registry_test_impl.Impl',
+        'missing.registry_test_impl.Impl',
+        'registry_test_impl.Bad',
+        'Impl'
     ]:
       with self.assertRaisesRegexp(ValueError, 'Failed to create'):
         registry_test_base.Base.Create(name, 'hello world')
diff --git a/research/syntaxnet/syntaxnet/util/resources.py b/research/syntaxnet/syntaxnet/util/resources.py
new file mode 100644
index 00000000..cc1831a3
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/util/resources.py
@@ -0,0 +1,74 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Utils for loading resources (data files) from the SyntaxNet source tree.
+
+The resources must be data dependencies of the relevant py_*() build target.
+
+Example usage:
+
+from syntaxnet.util import resources
+
+data_blob = resources.GetSyntaxNetResource(
+    'syntaxnet/testdata/context.pbtxt')
+"""
+
+import os
+
+# Absolute path to the root directory holding syntaxnet.  Resource paths are
+# interpreted relative to this path.
+
+_ROOT_DIR = os.path.dirname(              # .../
+    os.path.dirname(                      # .../syntaxnet/
+        os.path.dirname(                  # .../syntaxnet/util/
+            os.path.abspath(__file__))))  # .../syntaxnet/util/resources.py
+
+
+def GetSyntaxNetResourceAsFile(path):
+  """Returns a resource as an opened read-only file.
+
+  Args:
+    path: Relative path to the resource, which must be a Bazel data dependency.
+
+  Returns:
+    Opened read-only file pointing to resource data.
+
+  Raises:
+    IOError: If the resource cannot be loaded.
+  """
+  path = os.path.join(_ROOT_DIR, path)
+  if os.path.isdir(path):
+    raise IOError('Resource "{}" is not a file'.format(path))
+  if not os.path.isfile(path):
+    raise IOError(
+        'Resource "{}" not found; is it a data dependency?'.format(path))
+  return open(path, 'rb')
+
+
+def GetSyntaxNetResource(path):
+  """Returns the content of a resource.
+
+  Args:
+    path: Relative path to the resource, which must be a Bazel data dependency.
+
+  Returns:
+    Raw content of the resource.
+
+  Raises:
+    IOError: If the resource cannot be loaded.
+  """
+  with GetSyntaxNetResourceAsFile(path) as resource_file:
+    return resource_file.read()
+
+
diff --git a/research/syntaxnet/syntaxnet/util/resources_test.py b/research/syntaxnet/syntaxnet/util/resources_test.py
new file mode 100644
index 00000000..d63ff26c
--- /dev/null
+++ b/research/syntaxnet/syntaxnet/util/resources_test.py
@@ -0,0 +1,44 @@
+# Copyright 2017 Google Inc. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Tests for resources."""
+
+from tensorflow.python.platform import googletest
+
+from syntaxnet.util import resources
+
+
+class ResourcesTest(googletest.TestCase):
+  """Testing rig."""
+
+  def testInvalidResource(self):
+    for path in [
+        'bad/path/to/no/file',
+        'syntaxnet/testdata',
+        'syntaxnet/testdata/context.pbtxt',
+    ]:
+      with self.assertRaises(IOError):
+        resources.GetSyntaxNetResource(path)
+      with self.assertRaises(IOError):
+        resources.GetSyntaxNetResourceAsFile(path)
+
+  def testValidResource(self):
+    path = 'syntaxnet/testdata/hello.txt'
+    self.assertEqual('hello world\n', resources.GetSyntaxNetResource(path))
+    with resources.GetSyntaxNetResourceAsFile(path) as resource_file:
+      self.assertEqual('hello world\n', resource_file.read())
+
+
+if __name__ == '__main__':
+  googletest.main()
diff --git a/research/syntaxnet/syntaxnet/whole_sentence_features.h b/research/syntaxnet/syntaxnet/whole_sentence_features.h
index 5a5829a1..e42cc556 100644
--- a/research/syntaxnet/syntaxnet/whole_sentence_features.h
+++ b/research/syntaxnet/syntaxnet/whole_sentence_features.h
@@ -16,11 +16,12 @@ limitations under the License.
 // Features for whole Sentence objects.  Contrast with SentenceFeature, which
 // operates on tokens within Sentences.
 
-#include "syntaxnet/feature_extractor.h"
-
 #ifndef SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
 #define SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
 
+#include "syntaxnet/feature_extractor.h"
+#include "syntaxnet/registry.h"
+
 namespace syntaxnet {
 
 // Type of feature functions whose focus is a whole sentence.
@@ -30,6 +31,9 @@ typedef FeatureFunction<Sentence> WholeSentenceFeatureFunction;
 #define REGISTER_WHOLE_SENTENCE_FEATURE_FUNCTION(name, type) \
   REGISTER_SYNTAXNET_FEATURE_FUNCTION(WholeSentenceFeatureFunction, name, type)
 
+DECLARE_SYNTAXNET_CLASS_REGISTRY("whole sentence feature function",
+                                 WholeSentenceFeatureFunction);
+
 }  // namespace syntaxnet
 
 #endif  // SYNTAXNET_WHOLE_SENTENCE_FEATURES_H_
diff --git a/research/syntaxnet/tensorflow b/research/syntaxnet/tensorflow
index 90267567..c52cdc03 160000
--- a/research/syntaxnet/tensorflow
+++ b/research/syntaxnet/tensorflow
@@ -1 +1 @@
-Subproject commit 9026756727e7c6782ab89c181c80b2117bf78c05
+Subproject commit c52cdc03a67ceae9ecc8c00025d3c60f54833e2d
diff --git a/research/syntaxnet/third_party/utf/LICENSE b/research/syntaxnet/third_party/utf/LICENSE
new file mode 100644
index 00000000..ad76cd52
--- /dev/null
+++ b/research/syntaxnet/third_party/utf/LICENSE
@@ -0,0 +1,13 @@
+/*
+ * The authors of this software are Rob Pike and Ken Thompson.
+ *              Copyright (c) 1998-2002 by Lucent Technologies.
+ * Permission to use, copy, modify, and distribute this software for any
+ * purpose without fee is hereby granted, provided that this entire notice
+ * is included in all copies of any software which is or includes a copy
+ * or modification of this software and in all copies of the supporting
+ * documentation for such software.
+ * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
+ * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR LUCENT TECHNOLOGIES MAKE ANY
+ * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
+ * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
+ */
diff --git a/research/syntaxnet/tools/bazel.rc b/research/syntaxnet/tools/bazel.rc
index 3bf93af5..d4732657 100644
--- a/research/syntaxnet/tools/bazel.rc
+++ b/research/syntaxnet/tools/bazel.rc
@@ -1,3 +1,5 @@
+import %workspace%/tensorflow/.tf_configure.bazelrc
+
 build:cuda --crosstool_top=@local_config_cuda//crosstool:toolchain
 build:cuda --define=using_cuda=true --define=using_cuda_nvcc=true
 build:win-cuda --define=using_cuda=true --define=using_cuda_nvcc=true
