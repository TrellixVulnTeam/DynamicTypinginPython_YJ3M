commit c5dbd487bb9278ba821f087874bdcf4e404f49bd
Author: josh11b <josh11b@users.noreply.github.com>
Date:   Wed Oct 24 19:54:06 2018 -0700

    Update distribution_utils.py

diff --git a/official/utils/misc/distribution_utils.py b/official/utils/misc/distribution_utils.py
index f6228efe..ef9fdd22 100644
--- a/official/utils/misc/distribution_utils.py
+++ b/official/utils/misc/distribution_utils.py
@@ -27,8 +27,9 @@ def get_distribution_strategy(num_gpus, all_reduce_alg=None):
   Args:
     num_gpus: Number of GPUs to run this model.
     all_reduce_alg: Specify which algorithm to use when performing all-reduce.
-      See tf.contrib.distribute.AllReduceCrossDeviceOps for available algorithms.
-      If None, DistributionStrategy will choose based on device topology.
+      See tf.contrib.distribute.AllReduceCrossDeviceOps for available
+      algorithms. If None, DistributionStrategy will choose based on device
+      topology.
 
   Returns:
     tf.contrib.distribute.DistibutionStrategy object.
