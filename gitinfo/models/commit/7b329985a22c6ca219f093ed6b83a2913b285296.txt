commit 7b329985a22c6ca219f093ed6b83a2913b285296
Author: Toby Boyd <tobyboyd@google.com>
Date:   Fri Jun 14 09:50:50 2019 -0700

    Resnet56 forced eager benchmark and no_dist_strat eager accuracy test. (#7017)
    
    * Add 1 gpu force_eager benchmark
    
    * Add accuracy for no dist strat eager
    
    * remvove return.

diff --git a/official/resnet/keras/keras_cifar_benchmark.py b/official/resnet/keras/keras_cifar_benchmark.py
index 6a5d2009..08e48000 100644
--- a/official/resnet/keras/keras_cifar_benchmark.py
+++ b/official/resnet/keras/keras_cifar_benchmark.py
@@ -13,7 +13,6 @@
 # limitations under the License.
 # ==============================================================================
 """Executes Keras benchmarks and accuracy tests."""
-
 from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
@@ -80,8 +79,21 @@ class Resnet56KerasAccuracy(keras_benchmark.KerasBenchmark):
     FLAGS.enable_eager = True
     self._run_and_report_benchmark()
 
+  def benchmark_1_gpu_no_dist_strat(self):
+    """Test keras based model with eager and no dist strat."""
+    self._setup()
+    FLAGS.num_gpus = 1
+    FLAGS.data_dir = self.data_dir
+    FLAGS.batch_size = 128
+    FLAGS.train_epochs = 182
+    FLAGS.model_dir = self._get_model_dir('benchmark_1_gpu_no_dist_strat')
+    FLAGS.dtype = 'fp32'
+    FLAGS.enable_eager = True
+    FLAGS.distribution_strategy = 'off'
+    self._run_and_report_benchmark()
+
   def benchmark_1_gpu_no_dist_strat_run_eagerly(self):
-    """Test keras based model with forced eager."""
+    """Test keras based model with forced eager and no dist_strat."""
     self._setup()
     FLAGS.num_gpus = 1
     FLAGS.data_dir = self.data_dir
@@ -204,6 +216,19 @@ class Resnet56KerasBenchmarkBase(keras_benchmark.KerasBenchmark):
     FLAGS.batch_size = 128
     self._run_and_report_benchmark()
 
+  def benchmark_1_gpu_no_dist_strat_run_eagerly(self):
+    """Test keras based model with forced eager."""
+    self._setup()
+    FLAGS.num_gpus = 1
+    FLAGS.batch_size = 128
+    FLAGS.model_dir = self._get_model_dir(
+        'benchmark_1_gpu_no_dist_strat_run_eagerly')
+    FLAGS.dtype = 'fp32'
+    FLAGS.enable_eager = True
+    FLAGS.run_eagerly = True
+    FLAGS.distribution_strategy = 'off'
+    self._run_and_report_benchmark()
+
   def benchmark_2_gpu(self):
     self._setup()
     FLAGS.num_gpus = 2
