commit 3024bde6cf048c208ad1131ff4cd82ec238c72ac
Author: Soroush Radpour <ssh.rdp@gmail.com>
Date:   Tue Mar 19 13:51:13 2019 -0700

    Add the option to run Keras resnet model on multiple workers. (#6368)

diff --git a/official/resnet/keras/keras_imagenet_main.py b/official/resnet/keras/keras_imagenet_main.py
index e233d82a..cbe5356d 100644
--- a/official/resnet/keras/keras_imagenet_main.py
+++ b/official/resnet/keras/keras_imagenet_main.py
@@ -144,7 +144,8 @@ def run(flags_obj):
 
   strategy = distribution_utils.get_distribution_strategy(
       distribution_strategy=flags_obj.distribution_strategy,
-      num_gpus=flags_obj.num_gpus)
+      num_gpus=flags_obj.num_gpus,
+      num_workers=distribution_utils.configure_cluster())
 
   strategy_scope = keras_common.get_strategy_scope(strategy)
 
diff --git a/official/utils/misc/distribution_utils.py b/official/utils/misc/distribution_utils.py
index 4327994e..f27ae721 100644
--- a/official/utils/misc/distribution_utils.py
+++ b/official/utils/misc/distribution_utils.py
@@ -229,6 +229,8 @@ def configure_cluster(worker_hosts=None, task_index=-1):
   tf_config = json.loads(os.environ.get('TF_CONFIG', '{}'))
   if tf_config:
     num_workers = len(tf_config['cluster']['worker'])
+    if tf_config['cluster'].get('chief', None):
+      num_workers += 1
   elif worker_hosts:
     workers = worker_hosts.split(',')
     num_workers = len(workers)
