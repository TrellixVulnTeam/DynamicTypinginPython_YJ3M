commit 66eb101896a1b7c1691c7416668776ea60ddb78f
Author: Neal Wu <neal@nealwu.com>
Date:   Fri Mar 24 21:02:35 2017 -0700

    Make textsum compatible with Python 3

diff --git a/textsum/batch_reader.py b/textsum/batch_reader.py
index ef7221a7..2b813ac2 100644
--- a/textsum/batch_reader.py
+++ b/textsum/batch_reader.py
@@ -16,12 +16,13 @@
 """Batch reader to seq2seq attention model, with bucketing support."""
 
 from collections import namedtuple
-import Queue
 from random import shuffle
 from threading import Thread
 import time
 
 import numpy as np
+from six.moves.queue import Queue
+from six.moves import xrange
 import tensorflow as tf
 
 import data
diff --git a/textsum/beam_search.py b/textsum/beam_search.py
index b5a583d9..446799ca 100644
--- a/textsum/beam_search.py
+++ b/textsum/beam_search.py
@@ -21,10 +21,11 @@ K*K results, and start over again until certain number of results are fully
 decoded.
 """
 
+from six.moves import xrange
 import tensorflow as tf
 
 FLAGS = tf.flags.FLAGS
-tf.flags.DEFINE_bool('normalize_by_length', True, 'Whether normalize')
+tf.flags.DEFINE_bool('normalize_by_length', True, 'Whether to normalize')
 
 
 class Hypothesis(object):
diff --git a/textsum/seq2seq_attention_decode.py b/textsum/seq2seq_attention_decode.py
index 85e2f992..54b56919 100644
--- a/textsum/seq2seq_attention_decode.py
+++ b/textsum/seq2seq_attention_decode.py
@@ -18,9 +18,10 @@
 import os
 import time
 
-import tensorflow as tf
 import beam_search
 import data
+from six.moves import xrange
+import tensorflow as tf
 
 FLAGS = tf.app.flags.FLAGS
 tf.app.flags.DEFINE_integer('max_decode_steps', 1000000,
diff --git a/textsum/seq2seq_attention_model.py b/textsum/seq2seq_attention_model.py
index 97a9ffd3..618d72fa 100644
--- a/textsum/seq2seq_attention_model.py
+++ b/textsum/seq2seq_attention_model.py
@@ -18,9 +18,9 @@
 from collections import namedtuple
 
 import numpy as np
-import tensorflow as tf
 import seq2seq_lib
-
+from six.moves import xrange
+import tensorflow as tf
 
 HParams = namedtuple('HParams',
                      'mode, min_lr, lr, batch_size, '
