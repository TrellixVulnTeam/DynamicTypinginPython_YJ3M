commit fbc5ba06a1eb6c75d1919bcdf4bd711d6962a5c5
Author: Zhichao Lu <lzc@google.com>
Date:   Fri Feb 2 11:44:21 2018 -0800

    Resolve commnets

diff --git a/research/object_detection/README.md b/research/object_detection/README.md
index d4a4adef..b0a8a78c 100644
--- a/research/object_detection/README.md
+++ b/research/object_detection/README.md
@@ -33,6 +33,7 @@ https://scholar.googleusercontent.com/scholar.bib?q=info:l291WsrB-hQJ:scholar.go
 * Chen Sun, github: [jesu9](https://github.com/jesu9)
 * Menglong Zhu, github: [dreamdragon](https://github.com/dreamdragon)
 * Alireza Fathi, github: [afathi3](https://github.com/afathi3)
+* Zhichao Lu, github: [pkulzc](https://github.com/pkulzc)
 
 
 ## Table of contents
diff --git a/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py b/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py
index a4e4eac8..f261cb8c 100644
--- a/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py
+++ b/research/object_detection/anchor_generators/multiscale_grid_anchor_generator.py
@@ -17,7 +17,7 @@
 Generates grid anchors on the fly corresponding to multiple CNN layers as
 described in:
 "Focal Loss for Dense Object Detection"
-T.-Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar
+T.-Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar (https://arxiv.org/abs/1708.02002)
 """
 
 from object_detection.anchor_generators import grid_anchor_generator
@@ -25,7 +25,7 @@ from object_detection.core import box_list_ops
 
 
 class MultiscaleGridAnchorGenerator(object):
-  """Generate a grid of anchors for multiple CNN layers."""
+  """Generate a grid of anchors for multiple CNN layers of different scale."""
 
   def __init__(self, min_level, max_level, anchor_scale, aspect_ratios,
                scales_per_octave):
diff --git a/research/object_detection/core/box_list_ops.py b/research/object_detection/core/box_list_ops.py
index 5bc3b7d0..f886d9fd 100644
--- a/research/object_detection/core/box_list_ops.py
+++ b/research/object_detection/core/box_list_ops.py
@@ -657,7 +657,7 @@ def filter_greater_than(boxlist, thresh, scope=None):
   This op keeps the collection of boxes whose corresponding scores are
   greater than the input threshold.
 
-  TODO: Change function name to FilterScoresGreaterThan
+  TODO: Change function name to filter_scores_greater_than
 
   Args:
     boxlist: BoxList holding N boxes.  Must contain a 'scores' field
diff --git a/research/object_detection/core/box_predictor.py b/research/object_detection/core/box_predictor.py
index 2d73cdcf..36059702 100644
--- a/research/object_detection/core/box_predictor.py
+++ b/research/object_detection/core/box_predictor.py
@@ -101,8 +101,7 @@ class BoxPredictor(object):
       with tf.variable_scope(scope):
         return self._predict(image_features, num_predictions_per_location,
                              **params)
-    else:
-      return self._predict(image_features, num_predictions_per_location,
+    return self._predict(image_features, num_predictions_per_location,
                            **params)
 
   # TODO: num_predictions_per_location could be moved to constructor.
diff --git a/research/object_detection/core/model.py b/research/object_detection/core/model.py
index 7cbaaa46..7182bbe4 100644
--- a/research/object_detection/core/model.py
+++ b/research/object_detection/core/model.py
@@ -40,7 +40,7 @@ Output classes are always integers in the range [0, num_classes).  Any mapping
 of these integers to semantic labels is to be handled outside of this class.
 
 Images are resized in the `preprocess` method. All of `preprocess`, `predict`,
-and `postprocess` should be stateless.
+and `postprocess` should be reentrant.
 
 The `preprocess` method runs `image_resizer_fn` that returns resized_images and
 `true_image_shapes`. Since `image_resizer_fn` can pad the images with zeros,
diff --git a/research/object_detection/dataset_tools/__init__.py b/research/object_detection/dataset_tools/__init__.py
index e69de29b..8b137891 100644
--- a/research/object_detection/dataset_tools/__init__.py
+++ b/research/object_detection/dataset_tools/__init__.py
@@ -0,0 +1 @@
+
diff --git a/research/object_detection/dataset_tools/oid_tfrecord_creation.py b/research/object_detection/dataset_tools/oid_tfrecord_creation.py
index 1bc41c0b..ccf6ec8e 100644
--- a/research/object_detection/dataset_tools/oid_tfrecord_creation.py
+++ b/research/object_detection/dataset_tools/oid_tfrecord_creation.py
@@ -102,7 +102,7 @@ def open_sharded_output_tfrecords(exit_stack, base_path, num_shards):
   """
   tf_record_output_filenames = [
       '{}-{:05d}-of-{:05d}'.format(base_path, idx, num_shards)
-      for idx in xrange(num_shards)
+      for idx in range(num_shards)
   ]
 
   tfrecords = [
diff --git a/research/object_detection/evaluator.py b/research/object_detection/evaluator.py
index 7d55d9f5..b2bd50ed 100644
--- a/research/object_detection/evaluator.py
+++ b/research/object_detection/evaluator.py
@@ -117,9 +117,8 @@ def get_evaluators(eval_config, categories):
   for eval_metric_fn_key in eval_metric_fn_keys:
     if eval_metric_fn_key not in EVAL_METRICS_CLASS_DICT:
       raise ValueError('Metric not found: {}'.format(eval_metric_fn_key))
-    else:
-      evaluators_list.append(
-          EVAL_METRICS_CLASS_DICT[eval_metric_fn_key](categories=categories))
+    evaluators_list.append(
+        EVAL_METRICS_CLASS_DICT[eval_metric_fn_key](categories=categories))
   return evaluators_list
 
 
diff --git a/research/object_detection/g3doc/using_your_own_dataset.md b/research/object_detection/g3doc/using_your_own_dataset.md
index a36698a2..c403930e 100644
--- a/research/object_detection/g3doc/using_your_own_dataset.md
+++ b/research/object_detection/g3doc/using_your_own_dataset.md
@@ -103,7 +103,7 @@ FLAGS = flags.FLAGS
 
 
 def create_tf_example(example):
-  # TODO: Populate the following variables from your example.
+  # TODO(user): Populate the following variables from your example.
   height = None # Image height
   width = None # Image width
   filename = None # Filename of the image. Empty if image is not from file
@@ -139,7 +139,7 @@ def create_tf_example(example):
 def main(_):
   writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
 
-  # TODO: Write code to read in your dataset to examples variable
+  # TODO(user): Write code to read in your dataset to examples variable
 
   for example in examples:
     tf_example = create_tf_example(example)
diff --git a/research/object_detection/meta_architectures/ssd_meta_arch.py b/research/object_detection/meta_architectures/ssd_meta_arch.py
index 7b5123c1..235db969 100644
--- a/research/object_detection/meta_architectures/ssd_meta_arch.py
+++ b/research/object_detection/meta_architectures/ssd_meta_arch.py
@@ -130,7 +130,7 @@ class SSDMetaArch(model.DetectionModel):
                add_summaries=True):
     """SSDMetaArch Constructor.
 
-    TODO(rathodv,jonathanhuang): group NMS parameters + score converter into
+    TODO: group NMS parameters + score converter into
     a class and loss parameters into a class and write config protos for
     postprocessing and losses.
 
diff --git a/research/object_detection/metrics/coco_evaluation.py b/research/object_detection/metrics/coco_evaluation.py
index c599b5bd..9d63ba3b 100644
--- a/research/object_detection/metrics/coco_evaluation.py
+++ b/research/object_detection/metrics/coco_evaluation.py
@@ -1,3 +1,17 @@
+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
 """Class for evaluating object detections with COCO metrics."""
 import numpy as np
 import tensorflow as tf
diff --git a/research/object_detection/metrics/coco_evaluation_test.py b/research/object_detection/metrics/coco_evaluation_test.py
index 30c61549..7a007d7b 100644
--- a/research/object_detection/metrics/coco_evaluation_test.py
+++ b/research/object_detection/metrics/coco_evaluation_test.py
@@ -1,3 +1,17 @@
+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
 """Tests for image.understanding.object_detection.metrics.coco_evaluation."""
 
 from __future__ import absolute_import
diff --git a/research/object_detection/metrics/coco_tools.py b/research/object_detection/metrics/coco_tools.py
index 4195b146..851b19f8 100644
--- a/research/object_detection/metrics/coco_tools.py
+++ b/research/object_detection/metrics/coco_tools.py
@@ -1,4 +1,18 @@
-"""Wrappers for third party pycocotools to be used within i/u/object_detection.
+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Wrappers for third party pycocotools to be used within object_detection.
 
 Note that nothing in this file is tensorflow related and thus cannot
 be called directly as a slim metric, for example.
diff --git a/research/object_detection/metrics/coco_tools_test.py b/research/object_detection/metrics/coco_tools_test.py
index 115b146d..c2d1b60c 100644
--- a/research/object_detection/metrics/coco_tools_test.py
+++ b/research/object_detection/metrics/coco_tools_test.py
@@ -1,3 +1,17 @@
+# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
 """Tests for google3.image.understanding.object_detection.metrics.coco_tools."""
 import json
 import os
