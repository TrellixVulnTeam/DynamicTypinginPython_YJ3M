commit bd0d5692a7b4879407202bee65214e02bed52e51
Author: Frank Chen <frankchn@google.com>
Date:   Mon Oct 21 14:56:25 2019 -0700

    Consolidate DistributeOptions.auto_shard into DistributeOptions.auto_shard_policy.
    
    PiperOrigin-RevId: 275930249

diff --git a/official/nlp/bert/input_pipeline.py b/official/nlp/bert/input_pipeline.py
index aee21dde..63e08727 100644
--- a/official/nlp/bert/input_pipeline.py
+++ b/official/nlp/bert/input_pipeline.py
@@ -51,7 +51,8 @@ def file_based_input_fn_builder(input_file, name_to_features):
     # same input file is sent to all workers.
     if isinstance(input_file, str) or len(input_file) == 1:
       options = tf.data.Options()
-      options.experimental_distribute.auto_shard = False
+      options.experimental_distribute.auto_shard_policy = (
+          tf.data.experimental.AutoShardPolicy.OFF)
       d = d.with_options(options)
     return d
 
diff --git a/official/nlp/xlnet/data_utils.py b/official/nlp/xlnet/data_utils.py
index f0f47b09..d86c66b0 100644
--- a/official/nlp/xlnet/data_utils.py
+++ b/official/nlp/xlnet/data_utils.py
@@ -119,7 +119,8 @@ def file_based_input_fn_builder(input_file, name_to_features, batch_size,
     # same input file is sent to all workers.
     if isinstance(input_file, str) or len(input_file) == 1:
       options = tf.data.Options()
-      options.experimental_distribute.auto_shard = False
+      options.experimental_distribute.auto_shard_policy = (
+          tf.data.experimental.AutoShardPolicy.OFF)
       d = d.with_options(options)
 
     d = d.prefetch(tf.data.experimental.AUTOTUNE)
