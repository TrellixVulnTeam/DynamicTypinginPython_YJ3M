commit 87252d5affbe6f00db7e458b7bc2ae16a527a9e2
Author: Derek Chow <derekjchow@gmail.com>
Date:   Thu Aug 3 14:03:46 2017 -0700

    Clean up slim/datasets.

diff --git a/slim/BUILD b/slim/BUILD
index 0a321278..1c0c5bf4 100644
--- a/slim/BUILD
+++ b/slim/BUILD
@@ -1,9 +1,7 @@
 # Description:
 #   Contains files for loading, training and evaluating TF-Slim-based models.
 
-package(default_visibility = [
-    "//visibility:public",
-])
+package(default_visibility = [":public"])
 
 licenses(["notice"])  # Apache 2.0
 
@@ -14,24 +12,36 @@ package_group(name = "internal")
 py_library(
     name = "dataset_utils",
     srcs = ["datasets/dataset_utils.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "download_and_convert_cifar10",
     srcs = ["datasets/download_and_convert_cifar10.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "download_and_convert_flowers",
     srcs = ["datasets/download_and_convert_flowers.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "download_and_convert_mnist",
     srcs = ["datasets/download_and_convert_mnist.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_binary(
@@ -47,25 +57,37 @@ py_binary(
 py_binary(
     name = "cifar10",
     srcs = ["datasets/cifar10.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_binary(
     name = "flowers",
     srcs = ["datasets/flowers.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_binary(
     name = "imagenet",
     srcs = ["datasets/imagenet.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_binary(
     name = "mnist",
     srcs = ["datasets/mnist.py"],
-    deps = [":dataset_utils"],
+    deps = [
+        ":dataset_utils",
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -82,33 +104,51 @@ py_library(
 py_library(
     name = "model_deploy",
     srcs = ["deployment/model_deploy.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_test(
     name = "model_deploy_test",
     srcs = ["deployment/model_deploy_test.py"],
     srcs_version = "PY2AND3",
-    deps = [":model_deploy"],
+    deps = [
+        ":model_deploy",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "cifarnet_preprocessing",
     srcs = ["preprocessing/cifarnet_preprocessing.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "inception_preprocessing",
     srcs = ["preprocessing/inception_preprocessing.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "lenet_preprocessing",
     srcs = ["preprocessing/lenet_preprocessing.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "vgg_preprocessing",
     srcs = ["preprocessing/vgg_preprocessing.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -119,6 +159,7 @@ py_library(
         ":inception_preprocessing",
         ":lenet_preprocessing",
         ":vgg_preprocessing",
+        "//tensorflow",
     ],
 )
 
@@ -150,12 +191,18 @@ py_test(
     size = "medium",
     srcs = ["nets/alexnet_test.py"],
     srcs_version = "PY2AND3",
-    deps = [":alexnet"],
+    deps = [
+        ":alexnet",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "cifarnet",
     srcs = ["nets/cifarnet.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -225,7 +272,10 @@ py_test(
     srcs = ["nets/inception_v1_test.py"],
     shard_count = 3,
     srcs_version = "PY2AND3",
-    deps = [":inception"],
+    deps = [
+        ":inception",
+        "//tensorflow",
+    ],
 )
 
 py_test(
@@ -234,7 +284,10 @@ py_test(
     srcs = ["nets/inception_v2_test.py"],
     shard_count = 3,
     srcs_version = "PY2AND3",
-    deps = [":inception"],
+    deps = [
+        ":inception",
+        "//tensorflow",
+    ],
 )
 
 py_test(
@@ -243,7 +296,10 @@ py_test(
     srcs = ["nets/inception_v3_test.py"],
     shard_count = 3,
     srcs_version = "PY2AND3",
-    deps = [":inception"],
+    deps = [
+        ":inception",
+        "//tensorflow",
+    ],
 )
 
 py_test(
@@ -252,7 +308,10 @@ py_test(
     srcs = ["nets/inception_v4_test.py"],
     shard_count = 3,
     srcs_version = "PY2AND3",
-    deps = [":inception"],
+    deps = [
+        ":inception",
+        "//tensorflow",
+    ],
 )
 
 py_test(
@@ -261,12 +320,18 @@ py_test(
     srcs = ["nets/inception_resnet_v2_test.py"],
     shard_count = 3,
     srcs_version = "PY2AND3",
-    deps = [":inception"],
+    deps = [
+        ":inception",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "lenet",
     srcs = ["nets/lenet.py"],
+    deps = [
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -283,6 +348,7 @@ py_test(
     srcs_version = "PY2AND3",
     deps = [
         ":mobilenet_v1",
+        "//tensorflow",
     ],
 )
 
@@ -297,7 +363,10 @@ py_test(
     size = "medium",
     srcs = ["nets/overfeat_test.py"],
     srcs_version = "PY2AND3",
-    deps = [":overfeat"],
+    deps = [
+        ":overfeat",
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -319,8 +388,12 @@ py_test(
     name = "resnet_v1_test",
     size = "medium",
     srcs = ["nets/resnet_v1_test.py"],
+    shard_count = 2,
     srcs_version = "PY2AND3",
-    deps = [":resnet_v1"],
+    deps = [
+        ":resnet_v1",
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -336,8 +409,12 @@ py_test(
     name = "resnet_v2_test",
     size = "medium",
     srcs = ["nets/resnet_v2_test.py"],
+    shard_count = 2,
     srcs_version = "PY2AND3",
-    deps = [":resnet_v2"],
+    deps = [
+        ":resnet_v2",
+        "//tensorflow",
+    ],
 )
 
 py_library(
@@ -351,21 +428,31 @@ py_test(
     size = "medium",
     srcs = ["nets/vgg_test.py"],
     srcs_version = "PY2AND3",
-    deps = [":vgg"],
+    deps = [
+        ":vgg",
+        "//tensorflow",
+    ],
 )
 
 py_library(
     name = "nets_factory",
     srcs = ["nets/nets_factory.py"],
-    deps = [":nets"],
+    deps = [
+        ":nets",
+        "//tensorflow",
+    ],
 )
 
 py_test(
     name = "nets_factory_test",
     size = "medium",
     srcs = ["nets/nets_factory_test.py"],
+    shard_count = 2,
     srcs_version = "PY2AND3",
-    deps = [":nets_factory"],
+    deps = [
+        ":nets_factory",
+        "//tensorflow",
+    ],
 )
 
 py_binary(
@@ -376,6 +463,7 @@ py_binary(
         ":model_deploy",
         ":nets_factory",
         ":preprocessing_factory",
+        "//tensorflow",
     ],
 )
 
@@ -387,6 +475,7 @@ py_binary(
         ":model_deploy",
         ":nets_factory",
         ":preprocessing_factory",
+        "//tensorflow",
     ],
 )
 
@@ -396,6 +485,7 @@ py_binary(
     deps = [
         ":dataset_factory",
         ":nets_factory",
+        "//tensorflow",
     ],
 )
 
@@ -410,5 +500,6 @@ py_test(
     deps = [
         ":export_inference_graph",
         ":nets_factory",
+        "//tensorflow",
     ],
 )
diff --git a/slim/datasets/dataset_utils.py b/slim/datasets/dataset_utils.py
index 6f7a1c20..fdaefca3 100644
--- a/slim/datasets/dataset_utils.py
+++ b/slim/datasets/dataset_utils.py
@@ -34,7 +34,7 @@ def int64_feature(values):
     values: A scalar or list of values.
 
   Returns:
-    a TF-Feature.
+    A TF-Feature.
   """
   if not isinstance(values, (tuple, list)):
     values = [values]
@@ -48,11 +48,25 @@ def bytes_feature(values):
     values: A string.
 
   Returns:
-    a TF-Feature.
+    A TF-Feature.
   """
   return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values]))
 
 
+def float_feature(values):
+  """Returns a TF-Feature of floats.
+
+  Args:
+    values: A scalar of list of values.
+
+  Returns:
+    A TF-Feature.
+  """
+  if not isinstance(values, (tuple, list)):
+    values = [values]
+  return tf.train.Feature(float_list=tf.train.FloatList(value=values))
+
+
 def image_to_tfexample(image_data, image_format, height, width, class_id):
   return tf.train.Example(features=tf.train.Features(feature={
       'image/encoded': bytes_feature(image_data),
diff --git a/slim/datasets/download_and_convert_cifar10.py b/slim/datasets/download_and_convert_cifar10.py
index 0e0abe3c..f23618e7 100644
--- a/slim/datasets/download_and_convert_cifar10.py
+++ b/slim/datasets/download_and_convert_cifar10.py
@@ -26,12 +26,12 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
-from six.moves import cPickle
 import os
 import sys
 import tarfile
 
 import numpy as np
+from six.moves import cPickle
 from six.moves import urllib
 import tensorflow as tf
 
diff --git a/slim/datasets/download_and_convert_flowers.py b/slim/datasets/download_and_convert_flowers.py
index 2c11ead4..93e5c414 100644
--- a/slim/datasets/download_and_convert_flowers.py
+++ b/slim/datasets/download_and_convert_flowers.py
@@ -209,4 +209,3 @@ def run(dataset_dir):
 
   _clean_up_temporary_files(dataset_dir)
   print('\nFinished converting the Flowers dataset!')
-
diff --git a/slim/download_and_convert_data.py b/slim/download_and_convert_data.py
index ac798df7..924a3a46 100644
--- a/slim/download_and_convert_data.py
+++ b/slim/download_and_convert_data.py
@@ -71,4 +71,3 @@ def main(_):
 
 if __name__ == '__main__':
   tf.app.run()
-
