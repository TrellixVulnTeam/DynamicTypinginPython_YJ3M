commit 0d105c323dfbfcf1ec9247d1a22b59e59f30fad2
Author: Josh Gordon <random-forests@users.noreply.github.com>
Date:   Tue Aug 28 14:15:07 2018 -0400

    Adding a note on fairness (#5197)

diff --git a/official/wide_deep/README.md b/official/wide_deep/README.md
index 7425c223..7296c589 100644
--- a/official/wide_deep/README.md
+++ b/official/wide_deep/README.md
@@ -6,6 +6,8 @@ Here, we use the [wide and deep model](https://research.googleblog.com/2016/06/w
 
 For the purposes of this example code, the Census Income Data Set was chosen to allow the model to train in a reasonable amount of time. You'll notice that the deep model performs almost as well as the wide and deep model on this dataset. The wide and deep model truly shines on larger data sets with high-cardinality features, where each feature has millions/billions of unique possible values (which is the specialty of the wide model).
 
+Finally, a key point. As a modeler and developer, think about how this dataset is used and the potential benefits and harm a model's predictions can cause. A model like this could reinforce societal biases and disparities. Is a feature relevant to the problem you want to solve, or will it introduce bias? For more information, read about [ML fairness](https://developers.google.com/machine-learning/fairness-overview/).
+
 ---
 
 The code sample in this directory uses the high level `tf.estimator.Estimator` API. This API is great for fast iteration and quickly adapting models to your own datasets without major code overhauls. It allows you to move from single-worker training to distributed training, and it makes it easy to export model binaries for prediction.
