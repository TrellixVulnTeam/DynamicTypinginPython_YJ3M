commit 85956b16fbb47c0c10008595f427b89277bc371c
Author: Jing Li <jingli@google.com>
Date:   Tue Aug 27 15:25:36 2019 -0700

    Update interleave hyperparameters
    
    PiperOrigin-RevId: 265780130

diff --git a/official/bert/input_pipeline.py b/official/bert/input_pipeline.py
index d1ed0390..aee21dde 100644
--- a/official/bert/input_pipeline.py
+++ b/official/bert/input_pipeline.py
@@ -94,8 +94,12 @@ def create_pretrain_dataset(file_paths,
   dataset = dataset.shuffle(len(file_paths))
 
   # In parallel, create tf record dataset for each train files.
+  # cycle_length = 8 means that up to 8 files will be read and deserialized in
+  # parallel. You may want to increase this number if you have a large number of
+  # CPU cores.
   dataset = dataset.interleave(
-      tf.data.TFRecordDataset, cycle_length=tf.data.experimental.AUTOTUNE)
+      tf.data.TFRecordDataset, cycle_length=8,
+      num_parallel_calls=tf.data.experimental.AUTOTUNE)
 
   decode_fn = lambda record: decode_record(record, name_to_features)
   dataset = dataset.map(
