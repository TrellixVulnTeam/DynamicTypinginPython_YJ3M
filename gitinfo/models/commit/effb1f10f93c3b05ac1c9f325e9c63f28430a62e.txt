commit effb1f10f93c3b05ac1c9f325e9c63f28430a62e
Author: Jaeyoun Kim <jaeyounkim@users.noreply.github.com>
Date:   Thu Apr 23 23:27:32 2020 -0700

    Update README.md
    
    Fixed typo

diff --git a/research/video_prediction/README.md b/research/video_prediction/README.md
index de3f9ef6..89ea9e28 100644
--- a/research/video_prediction/README.md
+++ b/research/video_prediction/README.md
@@ -7,7 +7,7 @@
 *A TensorFlow implementation of the models described in [Unsupervised Learning for Physical Interaction through Video Prediction (Finn et al., 2016)](https://arxiv.org/abs/1605.07157).*
 
 This video prediction model, which is optionally conditioned on actions,
-predictions future video by internally predicting how to transform the last
+predicts future video by internally predicting how to transform the last
 image (which may have been predicted) into the next image. As a result, it can
 reuse apperance information from previous frames and can better generalize to
 objects not seen in the training set. Some example predictions on novel objects
