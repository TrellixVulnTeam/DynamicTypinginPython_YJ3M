commit b61ccce140583f408d6ef283d00b50769c62cb2e
Author: Guo Yejun (郭叶军) <yejun.guo@intel.com>
Date:   Sat Mar 30 00:55:44 2019 +0800

    Update object detection notebook to use image_np_expanded (#6345)

diff --git a/research/object_detection/object_detection_tutorial.ipynb b/research/object_detection/object_detection_tutorial.ipynb
index f8dca2c7..0c8c087e 100644
--- a/research/object_detection/object_detection_tutorial.ipynb
+++ b/research/object_detection/object_detection_tutorial.ipynb
@@ -372,7 +372,7 @@
         "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
         "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
         "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
-        "            detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
+        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
         "        detection_masks_reframed = tf.cast(\n",
         "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
         "        # Follow the convention by adding back the batch dimension\n",
@@ -382,7 +382,7 @@
         "\n",
         "      # Run inference\n",
         "      output_dict = sess.run(tensor_dict,\n",
-        "                             feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
+        "                             feed_dict={image_tensor: image})\n",
         "\n",
         "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
         "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
@@ -418,7 +418,7 @@
         "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
         "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
         "  # Actual detection.\n",
-        "  output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
+        "  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
         "  # Visualization of the results of a detection.\n",
         "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
         "      image_np,\n",
