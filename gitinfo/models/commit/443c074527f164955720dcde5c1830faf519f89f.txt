commit 443c074527f164955720dcde5c1830faf519f89f
Author: Neal Wu <neal@nealwu.com>
Date:   Thu May 18 16:48:51 2017 -0700

    Convert control_flow_ops.with_dependencies to tf.control_dependencies

diff --git a/inception/inception/slim/ops_test.py b/inception/inception/slim/ops_test.py
index 0978e0ef..ab205deb 100644
--- a/inception/inception/slim/ops_test.py
+++ b/inception/inception/slim/ops_test.py
@@ -21,8 +21,6 @@ from __future__ import print_function
 import numpy as np
 import tensorflow as tf
 
-from tensorflow.python.ops import control_flow_ops
-
 from inception.slim import ops
 from inception.slim import scopes
 from inception.slim import variables
@@ -602,7 +600,8 @@ class BatchNormTest(tf.test.TestCase):
       update_ops = tf.get_collection(ops.UPDATE_OPS_COLLECTION)
       with tf.control_dependencies(update_ops):
         barrier = tf.no_op(name='gradient_barrier')
-        output = control_flow_ops.with_dependencies([barrier], output)
+        with tf.control_dependencies([barrier]):
+          output = output
       # Initialize all variables
       sess.run(tf.global_variables_initializer())
       moving_mean = variables.get_variables('BatchNorm/moving_mean')[0]
@@ -632,7 +631,8 @@ class BatchNormTest(tf.test.TestCase):
       update_ops = tf.get_collection(ops.UPDATE_OPS_COLLECTION)
       with tf.control_dependencies(update_ops):
         barrier = tf.no_op(name='gradient_barrier')
-        output = control_flow_ops.with_dependencies([barrier], output)
+        with tf.control_dependencies([barrier]):
+          output = output
       # Initialize all variables
       sess.run(tf.global_variables_initializer())
       moving_mean = variables.get_variables('BatchNorm/moving_mean')[0]
@@ -666,7 +666,8 @@ class BatchNormTest(tf.test.TestCase):
       update_ops = tf.get_collection(ops.UPDATE_OPS_COLLECTION)
       with tf.control_dependencies(update_ops):
         barrier = tf.no_op(name='gradient_barrier')
-        output = control_flow_ops.with_dependencies([barrier], output)
+        with tf.control_dependencies([barrier]):
+          output = output
       # Initialize all variables
       sess.run(tf.global_variables_initializer())
       moving_mean = variables.get_variables('BatchNorm/moving_mean')[0]
diff --git a/slim/deployment/model_deploy.py b/slim/deployment/model_deploy.py
index 8855f2ae..24dd5c34 100644
--- a/slim/deployment/model_deploy.py
+++ b/slim/deployment/model_deploy.py
@@ -378,8 +378,8 @@ def deploy(config,
         update_ops.append(grad_updates)
 
         update_op = tf.group(*update_ops)
-        train_op = control_flow_ops.with_dependencies([update_op], total_loss,
-                                                      name='train_op')
+        with tf.control_dependencies([update_op]):
+          train_op = total_loss
     else:
       clones_losses = []
       regularization_losses = tf.get_collection(
diff --git a/slim/preprocessing/vgg_preprocessing.py b/slim/preprocessing/vgg_preprocessing.py
index 1900cae2..c2c92f0a 100644
--- a/slim/preprocessing/vgg_preprocessing.py
+++ b/slim/preprocessing/vgg_preprocessing.py
@@ -34,8 +34,6 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from tensorflow.python.ops import control_flow_ops
-
 slim = tf.contrib.slim
 
 _R_MEAN = 123.68
@@ -71,9 +69,8 @@ def _crop(image, offset_height, offset_width, crop_height, crop_width):
   rank_assertion = tf.Assert(
       tf.equal(tf.rank(image), 3),
       ['Rank of image must be equal to 3.'])
-  cropped_shape = control_flow_ops.with_dependencies(
-      [rank_assertion],
-      tf.stack([crop_height, crop_width, original_shape[2]]))
+  with tf.control_dependencies([rank_assertion]):
+    cropped_shape = tf.stack([crop_height, crop_width, original_shape[2]])
 
   size_assertion = tf.Assert(
       tf.logical_and(
@@ -85,9 +82,8 @@ def _crop(image, offset_height, offset_width, crop_height, crop_width):
 
   # Use tf.slice instead of crop_to_bounding box as it accepts tensors to
   # define the crop size.
-  image = control_flow_ops.with_dependencies(
-      [size_assertion],
-      tf.slice(image, offsets, cropped_shape))
+  with tf.control_dependencies([size_assertion]):
+    image = tf.slice(image, offsets, cropped_shape)
   return tf.reshape(image, cropped_shape)
 
 
@@ -126,9 +122,8 @@ def _random_crop(image_list, crop_height, crop_width):
          image_list[i].name, 3, image_rank])
     rank_assertions.append(rank_assert)
 
-  image_shape = control_flow_ops.with_dependencies(
-      [rank_assertions[0]],
-      tf.shape(image_list[0]))
+  with tf.control_dependencies([rank_assertions[0]]):
+    image_shape = tf.shape(image_list[0])
   image_height = image_shape[0]
   image_width = image_shape[1]
   crop_size_assert = tf.Assert(
@@ -142,8 +137,8 @@ def _random_crop(image_list, crop_height, crop_width):
   for i in range(1, len(image_list)):
     image = image_list[i]
     asserts.append(rank_assertions[i])
-    shape = control_flow_ops.with_dependencies([rank_assertions[i]],
-                                               tf.shape(image))
+    with tf.control_dependencies([rank_assertions[i]]):
+      shape = tf.shape(image)
     height = shape[0]
     width = shape[1]
 
@@ -162,10 +157,10 @@ def _random_crop(image_list, crop_height, crop_width):
   # Use tf.random_uniform and not numpy.random.rand as doing the former would
   # generate random numbers at graph eval time, unlike the latter which
   # generates random numbers at graph definition time.
-  max_offset_height = control_flow_ops.with_dependencies(
-      asserts, tf.reshape(image_height - crop_height + 1, []))
-  max_offset_width = control_flow_ops.with_dependencies(
-      asserts, tf.reshape(image_width - crop_width + 1, []))
+  with tf.control_dependencies(asserts):
+    max_offset_height = tf.reshape(image_height - crop_height + 1, [])
+  with tf.control_dependencies(asserts):
+    max_offset_width = tf.reshape(image_width - crop_width + 1, [])
   offset_height = tf.random_uniform(
       [], maxval=max_offset_height, dtype=tf.int32)
   offset_width = tf.random_uniform(
diff --git a/slim/train_image_classifier.py b/slim/train_image_classifier.py
index 146f7002..5aa674f4 100755
--- a/slim/train_image_classifier.py
+++ b/slim/train_image_classifier.py
@@ -20,7 +20,6 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from tensorflow.python.ops import control_flow_ops
 from datasets import dataset_factory
 from deployment import model_deploy
 from nets import nets_factory
@@ -540,8 +539,8 @@ def main(_):
     update_ops.append(grad_updates)
 
     update_op = tf.group(*update_ops)
-    train_tensor = control_flow_ops.with_dependencies([update_op], total_loss,
-                                                      name='train_op')
+    with tf.control_dependencies([update_op]):
+      train_tensor = total_loss
 
     # Add the summaries from the first clone. These contain the summaries
     # created by model_fn and either optimize_clones() or _gather_clone_loss().
