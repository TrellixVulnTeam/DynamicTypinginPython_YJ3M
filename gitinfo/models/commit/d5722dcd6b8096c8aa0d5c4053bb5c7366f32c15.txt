commit d5722dcd6b8096c8aa0d5c4053bb5c7366f32c15
Author: Vinh Nguyen <vinh.nguyenx@gmail.com>
Date:   Wed Aug 21 12:55:58 2019 +0000

    minor fix to comments

diff --git a/official/transformer/v2/transformer_main.py b/official/transformer/v2/transformer_main.py
index 5b33ba94..19481f5b 100644
--- a/official/transformer/v2/transformer_main.py
+++ b/official/transformer/v2/transformer_main.py
@@ -380,7 +380,7 @@ class TransformerTask(object):
       # Note: when flags_obj.fp16_implementation == "graph_rewrite",
       # dtype as determined by flags_core.get_tf_dtype(flags_obj) would be 'float32'
       # which will ensure tf.keras.mixed_precision and tf.train.experimental.enable_mixed_precision_graph_rewrite
-      # does not double up.
+      # do not double up.
       opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)
     
     return opt
diff --git a/official/vision/image_classification/resnet_imagenet_main.py b/official/vision/image_classification/resnet_imagenet_main.py
index b4cf560c..c1c3c1db 100644
--- a/official/vision/image_classification/resnet_imagenet_main.py
+++ b/official/vision/image_classification/resnet_imagenet_main.py
@@ -188,7 +188,7 @@ def run(flags_obj):
       # Note: when flags_obj.fp16_implementation == "graph_rewrite", 
       # dtype as determined by flags_core.get_tf_dtype(flags_obj) would be 'float32'
       # which will ensure tf.keras.mixed_precision and tf.train.experimental.enable_mixed_precision_graph_rewrite
-      # does not double up.
+      # do not double up.
       optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(optimizer)
             
     if flags_obj.use_trivial_model:
