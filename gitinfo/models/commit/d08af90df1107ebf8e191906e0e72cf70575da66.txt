commit d08af90df1107ebf8e191906e0e72cf70575da66
Author: Scott Zhu <scottzhu@google.com>
Date:   Tue May 12 17:16:41 2020 -0700

    Restructure the Keras class hierarchy for Network, Model and Sequential.
    
    The intention of this change is to reduce the code complexity within Keras class, especially for Network, which currently contains logic for both subclass Model and functional Model.
    
    After this change, the subclass model and functional model become individual class and become self contained.
    
    1. Model is now the base class for subclass model. It doesn't contains network structure management, and the topology will be created within __init__ and __call__, which is for user to implement. It also contains compile/fit/eval/predict, which is the basic functionality for model training.
    
    2. Functional is created based on existing Network class. It extends the Model, which allows it leverage compile/fit/eval/predict. In addition, it also take input/output as init parameter and manage the network topology.
    
    3. Sequential model is now a subclass of Functional, since it will use Functional's method to manage it topology (layer stacking).
    
    Model(input, output) will create a Functional under the hood, and behave the same way as before.
    
    PiperOrigin-RevId: 311232972

diff --git a/official/nlp/modeling/networks/albert_transformer_encoder.py b/official/nlp/modeling/networks/albert_transformer_encoder.py
index 5a2b522f..b0b517a0 100644
--- a/official/nlp/modeling/networks/albert_transformer_encoder.py
+++ b/official/nlp/modeling/networks/albert_transformer_encoder.py
@@ -21,13 +21,12 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from tensorflow.python.keras.engine import network  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 from official.nlp.modeling import layers
 
 
 @tf.keras.utils.register_keras_serializable(package='Text')
-class AlbertTransformerEncoder(network.Network):
+class AlbertTransformerEncoder(tf.keras.Model):
   """ALBERT (https://arxiv.org/abs/1810.04805) text encoder network.
 
   This network implements the encoder described in the paper "ALBERT: A Lite
diff --git a/official/nlp/modeling/networks/classification.py b/official/nlp/modeling/networks/classification.py
index d3263e8d..96ed50c1 100644
--- a/official/nlp/modeling/networks/classification.py
+++ b/official/nlp/modeling/networks/classification.py
@@ -21,12 +21,9 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-# pylint: disable=g-direct-tensorflow-import
-from tensorflow.python.keras.engine import network
-
 
 @tf.keras.utils.register_keras_serializable(package='Text')
-class Classification(network.Network):
+class Classification(tf.keras.Model):
   """Classification network head for BERT modeling.
 
   This network implements a simple classifier head based on a dense layer.
diff --git a/official/nlp/modeling/networks/encoder_scaffold.py b/official/nlp/modeling/networks/encoder_scaffold.py
index fb982b72..e51d0e52 100644
--- a/official/nlp/modeling/networks/encoder_scaffold.py
+++ b/official/nlp/modeling/networks/encoder_scaffold.py
@@ -25,13 +25,12 @@ import inspect
 import gin
 import tensorflow as tf
 
-from tensorflow.python.keras.engine import network  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import layers
 
 
 @tf.keras.utils.register_keras_serializable(package='Text')
 @gin.configurable
-class EncoderScaffold(network.Network):
+class EncoderScaffold(tf.keras.Model):
   """Bi-directional Transformer-based encoder network scaffold.
 
   This network allows users to flexibly implement an encoder similar to the one
diff --git a/official/nlp/modeling/networks/masked_lm.py b/official/nlp/modeling/networks/masked_lm.py
index a6e2a910..19df018c 100644
--- a/official/nlp/modeling/networks/masked_lm.py
+++ b/official/nlp/modeling/networks/masked_lm.py
@@ -21,12 +21,11 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from tensorflow.python.keras.engine import network  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import tf_utils
 
 
 @tf.keras.utils.register_keras_serializable(package='Text')
-class MaskedLM(network.Network):
+class MaskedLM(tf.keras.Model):
   """Masked language model network head for BERT modeling.
 
   This network implements a masked language model based on the provided network.
diff --git a/official/nlp/modeling/networks/span_labeling.py b/official/nlp/modeling/networks/span_labeling.py
index e2fc400c..2d704c33 100644
--- a/official/nlp/modeling/networks/span_labeling.py
+++ b/official/nlp/modeling/networks/span_labeling.py
@@ -21,12 +21,9 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-# pylint: disable=g-direct-tensorflow-import
-from tensorflow.python.keras.engine import network
-
 
 @tf.keras.utils.register_keras_serializable(package='Text')
-class SpanLabeling(network.Network):
+class SpanLabeling(tf.keras.Model):
   """Span labeling network head for BERT modeling.
 
   This network implements a simple single-span labeler based on a dense layer.
diff --git a/official/nlp/modeling/networks/transformer_encoder.py b/official/nlp/modeling/networks/transformer_encoder.py
index e7ee32a9..3e4f0a6e 100644
--- a/official/nlp/modeling/networks/transformer_encoder.py
+++ b/official/nlp/modeling/networks/transformer_encoder.py
@@ -21,13 +21,12 @@ from __future__ import print_function
 
 import tensorflow as tf
 
-from tensorflow.python.keras.engine import network  # pylint: disable=g-direct-tensorflow-import
 from official.modeling import activations
 from official.nlp.modeling import layers
 
 
 @tf.keras.utils.register_keras_serializable(package='Text')
-class TransformerEncoder(network.Network):
+class TransformerEncoder(tf.keras.Model):
   """Bi-directional Transformer-based encoder network.
 
   This network implements a bi-directional Transformer-based encoder as
