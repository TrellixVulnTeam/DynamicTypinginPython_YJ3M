commit e302950da3bcd8c6bbdf4ac3897282decedb83e4
Author: lcchen <lcchen@google.com>
Date:   Wed Mar 14 17:22:56 2018 -0700

    update dataset examples

diff --git a/research/deeplab/g3doc/cityscapes.md b/research/deeplab/g3doc/cityscapes.md
index d729788a..43b3226e 100644
--- a/research/deeplab/g3doc/cityscapes.md
+++ b/research/deeplab/g3doc/cityscapes.md
@@ -42,6 +42,10 @@ A local training job using `xception_65` can be run with the following command:
 # From tensorflow/models/research/
 python deeplab/train.py \
     --logtostderr \
+<<<<<<< HEAD
+=======
+    --training_number_of_steps=90000 \
+>>>>>>> origin/master
     --train_split="train" \
     --model_variant="xception_65" \
     --atrous_rates=6 \
@@ -52,6 +56,11 @@ python deeplab/train.py \
     --train_crop_size=769 \
     --train_crop_size=769 \
     --train_batch_size=1 \
+<<<<<<< HEAD
+=======
+    --dataset="cityscapes" \
+    --train_split="train" \
+>>>>>>> origin/master
     --tf_initial_checkpoints=${PATH_TO_INITIAL_CHECKPOINT} \
     --train_logdir=${PATH_TO_TRAIN_DIR} \
     --dataset_dir=${PATH_TO_DATASET}
@@ -62,11 +71,22 @@ where ${PATH_TO_INITIAL_CHECKPOINT} is the path to the initial checkpoint
 directory in which training checkpoints and events will be written to, and
 ${PATH_TO_DATASET} is the directory in which the Cityscapes dataset resides.
 
+<<<<<<< HEAD
 Note that for {train,eval,vis}.py:
 
 1.  We use small batch size during training. The users could change it based on
     the available GPU memory and also set `fine_tune_batch_norm` to be False or
     True depending on the use case.
+=======
+**Note that for {train,eval,vis}.py**:
+
+1.  In order to reproduce our results, one needs to use large batch size (> 8),
+    and set fine_tune_batch_norm = True. Here, we simply use small batch size
+    during training for the purpose of demonstration. If the users have limited
+    GPU memory at hand, please fine-tune from our provided checkpoints whose
+    batch norm parameters have been trained, and use smaller learning rate with
+    fine_tune_batch_norm = False.
+>>>>>>> origin/master
 
 2.  The users should change atrous_rates from [6, 12, 18] to [12, 24, 36] if
     setting output_stride=8.
@@ -90,6 +110,11 @@ python deeplab/eval.py \
     --decoder_output_stride=4 \
     --eval_crop_size=1025 \
     --eval_crop_size=2049 \
+<<<<<<< HEAD
+=======
+    --dataset="cityscapes" \
+    --eval_split="val" \
+>>>>>>> origin/master
     --checkpoint_dir=${PATH_TO_CHECKPOINT} \
     --eval_logdir=${PATH_TO_EVAL_DIR} \
     --dataset_dir=${PATH_TO_DATASET}
@@ -116,6 +141,11 @@ python deeplab/vis.py \
     --decoder_output_stride=4 \
     --vis_crop_size=1025 \
     --vis_crop_size=2049 \
+<<<<<<< HEAD
+=======
+    --dataset="cityscapes" \
+    --vis_split="val" \
+>>>>>>> origin/master
     --colormap_type="cityscapes" \
     --checkpoint_dir=${PATH_TO_CHECKPOINT} \
     --vis_logdir=${PATH_TO_VIS_DIR} \
diff --git a/research/deeplab/g3doc/pascal.md b/research/deeplab/g3doc/pascal.md
index d0827d35..20a7b1ba 100644
--- a/research/deeplab/g3doc/pascal.md
+++ b/research/deeplab/g3doc/pascal.md
@@ -44,6 +44,10 @@ A local training job using `xception_65` can be run with the following command:
 # From tensorflow/models/research/
 python deeplab/train.py \
     --logtostderr \
+<<<<<<< HEAD
+=======
+    --training_number_of_steps=30000 \
+>>>>>>> origin/master
     --train_split="train" \
     --model_variant="xception_65" \
     --atrous_rates=6 \
@@ -54,6 +58,11 @@ python deeplab/train.py \
     --train_crop_size=513 \
     --train_crop_size=513 \
     --train_batch_size=1 \
+<<<<<<< HEAD
+=======
+    --dataset="pascal_voc_seg" \
+    --train_split="train" \
+>>>>>>> origin/master
     --tf_initial_checkpoints=${PATH_TO_INITIAL_CHECKPOINT} \
     --train_logdir=${PATH_TO_TRAIN_DIR} \
     --dataset_dir=${PATH_TO_DATASET}
@@ -65,11 +74,22 @@ directory in which training checkpoints and events will be written to, and
 ${PATH_TO_DATASET} is the directory in which the PASCAL VOC 2012 dataset
 resides.
 
+<<<<<<< HEAD
 Note that for {train,eval,vis}.py:
 
 1.  We use small batch size during training. The users could change it based on
     the available GPU memory and also set `fine_tune_batch_norm` to be False or
     True depending on the use case.
+=======
+**Note that for {train,eval,vis}.py:**
+
+1.  In order to reproduce our results, one needs to use large batch size (> 12),
+    and set fine_tune_batch_norm = True. Here, we simply use small batch size
+    during training for the purpose of demonstration. If the users have limited
+    GPU memory at hand, please fine-tune from our provided checkpoints whose
+    batch norm parameters have been trained, and use smaller learning rate with
+    fine_tune_batch_norm = False.
+>>>>>>> origin/master
 
 2.  The users should change atrous_rates from [6, 12, 18] to [12, 24, 36] if
     setting output_stride=8.
@@ -93,6 +113,11 @@ python deeplab/eval.py \
     --decoder_output_stride=4 \
     --eval_crop_size=513 \
     --eval_crop_size=513 \
+<<<<<<< HEAD
+=======
+    --dataset="pascal_voc_seg" \
+    --eval_split="val" \
+>>>>>>> origin/master
     --checkpoint_dir=${PATH_TO_CHECKPOINT} \
     --eval_logdir=${PATH_TO_EVAL_DIR} \
     --dataset_dir=${PATH_TO_DATASET}
@@ -119,6 +144,11 @@ python deeplab/vis.py \
     --decoder_output_stride=4 \
     --vis_crop_size=513 \
     --vis_crop_size=513 \
+<<<<<<< HEAD
+=======
+    --dataset="pascal_voc_seg" \
+    --vis_split="val" \
+>>>>>>> origin/master
     --checkpoint_dir=${PATH_TO_CHECKPOINT} \
     --vis_logdir=${PATH_TO_VIS_DIR} \
     --dataset_dir=${PATH_TO_DATASET}
