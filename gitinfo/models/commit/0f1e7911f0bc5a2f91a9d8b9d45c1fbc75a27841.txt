commit 0f1e7911f0bc5a2f91a9d8b9d45c1fbc75a27841
Author: 黄璞 <awsomekde@gmail.com>
Date:   Tue Jun 20 01:16:53 2017 +0800

    Make slim_walkthrough ipython notebook python3 compatible (#1612)
    
    * make slim_walkthrough ipython notebook python3 compatible
    
    * make slim_walkthrough ipython notebook python3 compatible

diff --git a/slim/slim_walkthrough.ipynb b/slim/slim_walkthrough.ipynb
index da868ef1..dff43e03 100644
--- a/slim/slim_walkthrough.ipynb
+++ b/slim/slim_walkthrough.ipynb
@@ -29,11 +29,14 @@
     "## Installation and setup\n",
     "<a id='Install'></a>\n",
     "\n",
-    "As of 8/28/16, the latest stable release of TF is r0.10, which does not contain the latest version of slim.\n",
-    "To obtain the latest version of TF-Slim, please install the most recent nightly build of TF\n",
-    "as explained [here](https://github.com/tensorflow/models/tree/master/slim#installing-latest-version-of-tf-slim).\n",
+    "Since the stable release of TF 1.0, the latest version of slim has been available as `tf.contrib.slim`.\n",
+    "To test that your installation is working, execute the following command; it should run without raising any errors.\n",
     "\n",
-    "To use TF-Slim for image classification (as we do in this notebook), you also have to install the TF-Slim image models library from [here](https://github.com/tensorflow/models/tree/master/slim). Let's suppose you install this into a directory called TF_MODELS. Then you should change directory to  TF_MODELS/slim **before** running this notebook, so that these files are in your python path.\n",
+    "```\n",
+    "python -c \"import tensorflow.contrib.slim as slim; eval = slim.evaluation.evaluate_once\"\n",
+    "```\n",
+    "\n",
+    "Although, to use TF-Slim for image classification (as we do in this notebook), you also have to install the TF-Slim image models library from [here](https://github.com/tensorflow/models/tree/master/slim). Let's suppose you install this into a directory called TF_MODELS. Then you should change directory to  TF_MODELS/slim **before** running this notebook, so that these files are in your python path.\n",
     "\n",
     "To check you've got these two steps to work, just execute the cell below. If it complains about unknown modules, restart the notebook after moving to the TF-Slim models directory.\n"
    ]
@@ -42,10 +45,14 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
+    "from __future__ import absolute_import\n",
+    "from __future__ import division\n",
+    "from __future__ import print_function\n",
+    "\n",
     "import matplotlib\n",
     "%matplotlib inline\n",
     "import matplotlib.pyplot as plt\n",
@@ -57,7 +64,7 @@
     "from datasets import dataset_utils\n",
     "\n",
     "# Main slim library\n",
-    "slim = tf.contrib.slim"
+    "from tensorflow.contrib import slim"
    ]
   },
   {
@@ -143,7 +150,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -156,15 +163,15 @@
     "    predictions, end_points = regression_model(inputs)\n",
     "\n",
     "    # Print name and shape of each tensor.\n",
-    "    print \"Layers\"\n",
+    "    print(\"Layers\")\n",
     "    for k, v in end_points.items():\n",
-    "        print 'name = {}, shape = {}'.format(v.name, v.get_shape())\n",
+    "        print('name = {}, shape = {}'.format(v.name, v.get_shape()))\n",
     "\n",
     "    # Print name and shape of parameter nodes  (values not yet initialized)\n",
-    "    print \"\\n\"\n",
-    "    print \"Parameters\"\n",
+    "    print(\"\\n\")\n",
+    "    print(\"Parameters\")\n",
     "    for v in slim.get_model_variables():\n",
-    "        print 'name = {}, shape = {}'.format(v.name, v.get_shape())\n"
+    "        print('name = {}, shape = {}'.format(v.name, v.get_shape()))\n"
    ]
   },
   {
@@ -180,7 +187,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -228,7 +235,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -280,7 +287,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -330,7 +337,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -367,7 +374,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -441,7 +448,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -468,14 +475,14 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
     "from datasets import flowers\n",
     "import tensorflow as tf\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "\n",
     "with tf.Graph().as_default(): \n",
     "    dataset = flowers.get_split('train', flowers_data_dir)\n",
@@ -485,7 +492,7 @@
     "    \n",
     "    with tf.Session() as sess:    \n",
     "        with slim.queues.QueueRunners(sess):\n",
-    "            for i in xrange(4):\n",
+    "            for i in range(4):\n",
     "                np_image, np_label = sess.run([image, label])\n",
     "                height, width, _ = np_image.shape\n",
     "                class_name = name = dataset.labels_to_names[np_label]\n",
@@ -547,7 +554,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -599,14 +606,14 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
     "from preprocessing import inception_preprocessing\n",
     "import tensorflow as tf\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "\n",
     "\n",
     "def load_batch(dataset, batch_size=32, height=299, width=299, is_training=False):\n",
@@ -651,7 +658,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -706,7 +713,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -771,7 +778,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -802,26 +809,30 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
     "import numpy as np\n",
     "import os\n",
     "import tensorflow as tf\n",
-    "import urllib2\n",
+    "\n",
+    "try:\n",
+    "    import urllib2\n",
+    "except ImportError:\n",
+    "    import urllib.request as urllib\n",
     "\n",
     "from datasets import imagenet\n",
     "from nets import inception\n",
     "from preprocessing import inception_preprocessing\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "\n",
     "image_size = inception.inception_v1.default_image_size\n",
     "\n",
     "with tf.Graph().as_default():\n",
     "    url = 'https://upload.wikimedia.org/wikipedia/commons/7/70/EnglishCockerSpaniel_simon.jpg'\n",
-    "    image_string = urllib2.urlopen(url).read()\n",
+    "    image_string = urllib.urlopen(url).read()\n",
     "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
     "    processed_image = inception_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n",
     "    processed_images  = tf.expand_dims(processed_image, 0)\n",
@@ -902,19 +913,23 @@
     "import numpy as np\n",
     "import os\n",
     "import tensorflow as tf\n",
-    "import urllib2\n",
+    "\n",
+    "try:\n",
+    "    import urllib2\n",
+    "except ImportError:\n",
+    "    import urllib.request as urllib\n",
     "\n",
     "from datasets import imagenet\n",
     "from nets import vgg\n",
     "from preprocessing import vgg_preprocessing\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "\n",
     "image_size = vgg.vgg_16.default_image_size\n",
     "\n",
     "with tf.Graph().as_default():\n",
     "    url = 'https://upload.wikimedia.org/wikipedia/commons/d/d9/First_Student_IC_school_bus_202076.jpg'\n",
-    "    image_string = urllib2.urlopen(url).read()\n",
+    "    image_string = urllib.urlopen(url).read()\n",
     "    image = tf.image.decode_jpeg(image_string, channels=3)\n",
     "    processed_image = vgg_preprocessing.preprocess_image(image, image_size, image_size, is_training=False)\n",
     "    processed_images  = tf.expand_dims(processed_image, 0)\n",
@@ -960,7 +975,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -972,7 +987,7 @@
     "from nets import inception\n",
     "from preprocessing import inception_preprocessing\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "image_size = inception.inception_v1.default_image_size\n",
     "\n",
     "\n",
@@ -1043,7 +1058,7 @@
    "cell_type": "code",
    "execution_count": null,
    "metadata": {
-    "collapsed": false
+    "collapsed": true
    },
    "outputs": [],
    "source": [
@@ -1052,7 +1067,7 @@
     "from datasets import flowers\n",
     "from nets import inception\n",
     "\n",
-    "slim = tf.contrib.slim\n",
+    "from tensorflow.contrib import slim\n",
     "\n",
     "image_size = inception.inception_v1.default_image_size\n",
     "batch_size = 3\n",
@@ -1080,7 +1095,7 @@
     "            init_fn(sess)\n",
     "            np_probabilities, np_images_raw, np_labels = sess.run([probabilities, images_raw, labels])\n",
     "    \n",
-    "            for i in xrange(batch_size): \n",
+    "            for i in range(batch_size): \n",
     "                image = np_images_raw[i, :, :, :]\n",
     "                true_label = np_labels[i]\n",
     "                predicted_label = np.argmax(np_probabilities[i, :])\n",
@@ -1093,27 +1108,36 @@
     "                plt.axis('off')\n",
     "                plt.show()"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [],
+   "source": []
   }
  ],
  "metadata": {
   "kernelspec": {
-   "display_name": "Python 2",
+   "display_name": "Python 3",
    "language": "python",
-   "name": "python2"
+   "name": "python3"
   },
   "language_info": {
    "codemirror_mode": {
     "name": "ipython",
-    "version": 2
+    "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
-   "pygments_lexer": "ipython2",
-   "version": "2.7.11"
+   "pygments_lexer": "ipython3",
+   "version": "3.6.1"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 0
+ "nbformat_minor": 1
 }
