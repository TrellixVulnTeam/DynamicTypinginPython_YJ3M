commit 4457c1a81c8e2b1f3fa50cc5362686cdab8e8bd9
Author: Hongkun Yu <hongkuny@google.com>
Date:   Mon Oct 28 10:08:32 2019 -0700

    remove use_remote_tpu as it is deprecated.
    
    PiperOrigin-RevId: 277087491

diff --git a/official/modeling/model_training_utils.py b/official/modeling/model_training_utils.py
index 52924c4b..fec46d3d 100644
--- a/official/modeling/model_training_utils.py
+++ b/official/modeling/model_training_utils.py
@@ -96,7 +96,6 @@ def run_customized_training_loop(
     eval_steps=None,
     metric_fn=None,
     init_checkpoint=None,
-    use_remote_tpu=False,
     custom_callbacks=None,
     run_eagerly=False):
   """Run BERT pretrain model training using low-level API.
@@ -130,7 +129,6 @@ def run_customized_training_loop(
         after every epoch.
       init_checkpoint: Optional checkpoint to load to `sub_model` returned by
         `model_fn`.
-      use_remote_tpu: Ignored, will be removed in the future.
       custom_callbacks: A list of Keras Callbacks objects to run during
         training. More specifically, `on_batch_begin()`, `on_batch_end()`,
         methods are invoked during training.
@@ -145,8 +143,6 @@ def run_customized_training_loop(
         attribute or when required parameters are set to none. (2) eval args are
         not specified correctly. (3) metric_fn must be a callable if specified.
   """
-  # TODO(bfontain): Remove use_remote_tpu once there are no models using it.
-  del use_remote_tpu
 
   if _sentinel is not None:
     raise ValueError('only call `run_customized_training_loop()` '
