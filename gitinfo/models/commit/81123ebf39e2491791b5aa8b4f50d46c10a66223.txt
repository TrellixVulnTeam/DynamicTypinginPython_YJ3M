commit 81123ebf39e2491791b5aa8b4f50d46c10a66223
Author: Toby Boyd <tobyboyd@google.com>
Date:   Thu Jul 11 14:35:01 2019 -0700

    Reduce transformer fp16 test to 12 iterations. (#7183)

diff --git a/official/transformer/v2/transformer_benchmark.py b/official/transformer/v2/transformer_benchmark.py
index 7c82998a..7995f4fa 100644
--- a/official/transformer/v2/transformer_benchmark.py
+++ b/official/transformer/v2/transformer_benchmark.py
@@ -322,7 +322,7 @@ class TransformerBigKerasAccuracy(TransformerBenchmark):
     FLAGS['bleu_ref'].value = self.bleu_ref
     FLAGS.param_set = 'big'
     FLAGS.batch_size = 3072*8
-    FLAGS.train_steps = 400000
+    FLAGS.train_steps = 20000 * 12
     FLAGS.steps_between_evals = 20000
     FLAGS.model_dir = self._get_model_dir('benchmark_8_gpu_fp16')
     self._run_and_report_benchmark(total_batch_size=FLAGS.batch_size,
