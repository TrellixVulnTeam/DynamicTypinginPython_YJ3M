commit 22c95c545365e02bf035b37426b036ad8709ba4f
Author: Junwei Pan <pandevirus@gmail.com>
Date:   Mon May 15 14:04:29 2017 -0700

    Fix Typo

diff --git a/inception/inception/inception_train.py b/inception/inception/inception_train.py
index 32c959df..e1c32713 100644
--- a/inception/inception/inception_train.py
+++ b/inception/inception/inception_train.py
@@ -12,7 +12,7 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 # ==============================================================================
-"""A library to train Inception using multiple GPU's with synchronous updates.
+"""A library to train Inception using multiple GPUs with synchronous updates.
 """
 from __future__ import absolute_import
 from __future__ import division
@@ -83,7 +83,7 @@ def _tower_loss(images, labels, num_classes, scope, reuse_variables=None):
   """Calculate the total loss on a single tower running the ImageNet model.
 
   We perform 'batch splitting'. This means that we cut up a batch across
-  multiple GPU's. For instance, if the batch size = 32 and num_gpus = 2,
+  multiple GPUs. For instance, if the batch size = 32 and num_gpus = 2,
   then each tower will operate on an batch of 16 images.
 
   Args:
diff --git a/tutorials/image/cifar10/cifar10_multi_gpu_train.py b/tutorials/image/cifar10/cifar10_multi_gpu_train.py
index 1c70ad39..16033eef 100644
--- a/tutorials/image/cifar10/cifar10_multi_gpu_train.py
+++ b/tutorials/image/cifar10/cifar10_multi_gpu_train.py
@@ -13,7 +13,7 @@
 # limitations under the License.
 # ==============================================================================
 
-"""A binary to train CIFAR-10 using multiple GPU's with synchronous updates.
+"""A binary to train CIFAR-10 using multiple GPUs with synchronous updates.
 
 Accuracy:
 cifar10_multi_gpu_train.py achieves ~86% accuracy after 100K steps (256
