commit 296d0d3fc8efd5f165c10a71a9e1235b5889bb90
Author: guptapriya <14104855+guptapriya@users.noreply.github.com>
Date:   Thu Jul 18 22:29:43 2019 -0700

    Unskip tests with 1.x

diff --git a/official/transformer/v2/transformer_main_test.py b/official/transformer/v2/transformer_main_test.py
index d3b50874..fa56b34d 100644
--- a/official/transformer/v2/transformer_main_test.py
+++ b/official/transformer/v2/transformer_main_test.py
@@ -79,25 +79,23 @@ class TransformerTaskTest(tf.test.TestCase):
   def _assert_exists(self, filepath):
     self.assertTrue(os.path.exists(filepath))
 
-  def test_train(self):
+  def test_train_no_dist_strat(self):
     t = tm.TransformerTask(FLAGS)
     t.train()
 
-  @unittest.skipUnless(keras_utils.is_v2_0(), 'TF 2.0 only test.')
   def test_train_static_batch(self):
+    FLAGS.distribution_strategy = 'one_device'
     FLAGS.static_batch = True
     t = tm.TransformerTask(FLAGS)
     t.train()
 
   @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  @unittest.skipUnless(keras_utils.is_v2_0(), 'TF 2.0 only test.')
   def test_train_1_gpu_with_dist_strat(self):
     FLAGS.distribution_strategy = 'one_device'
     t = tm.TransformerTask(FLAGS)
     t.train()
 
   @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  @unittest.skipUnless(keras_utils.is_v2_0(), 'TF 2.0 only test.')
   def test_train_2_gpu(self):
     if context.num_gpus() < 2:
       self.skipTest(
@@ -110,7 +108,6 @@ class TransformerTaskTest(tf.test.TestCase):
     t.train()
 
   @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  @unittest.skipUnless(keras_utils.is_v2_0(), 'TF 2.0 only test.')
   def test_train_2_gpu_fp16(self):
     if context.num_gpus() < 2:
       self.skipTest(
