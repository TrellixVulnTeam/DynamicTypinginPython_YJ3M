commit 6a3bcef8ee40aaf359cb7162f057b9543ce05822
Author: Hongkun Yu <hongkuny@google.com>
Date:   Fri Jan 24 23:35:49 2020 -0800

    Update transformer readme
    
    PiperOrigin-RevId: 291503470

diff --git a/official/transformer/README.md b/official/transformer/README.md
index f8bed8c7..93120d4e 100644
--- a/official/transformer/README.md
+++ b/official/transformer/README.md
@@ -135,9 +135,7 @@ tensorboard --logdir=$MODEL_DIR
     - --num_gpus=2+: Uses tf.distribute.MirroredStrategy to run synchronous
     distributed training across the GPUs.
 
-   #### Using TPUs
-
-   Note: This model will **not** work with TPUs on Colab.
+   #### Using Cloud TPUs
 
    You can train the Transformer model on Cloud TPUs using
    `tf.distribute.TPUStrategy`. If you are not familiar with Cloud TPUs, it is
