commit 1be8e32a8db756a019d7d1067ffc70eb08bcc6ce
Author: Mark Daoust <markdaoust@google.com>
Date:   Mon Jul 30 08:54:05 2018 -0700

    It turns out `input_shape` is needed by `summary`

diff --git a/samples/core/tutorials/keras/overfit_and_underfit.ipynb b/samples/core/tutorials/keras/overfit_and_underfit.ipynb
index 3841f1bf..991448df 100644
--- a/samples/core/tutorials/keras/overfit_and_underfit.ipynb
+++ b/samples/core/tutorials/keras/overfit_and_underfit.ipynb
@@ -294,7 +294,8 @@
       "cell_type": "code",
       "source": [
         "baseline_model = keras.Sequential([\n",
-        "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
+        "    # `input_shape` is only required here so that `.summary` works. \n"
+        "    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
         "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
         "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
         "])\n",
@@ -365,7 +366,7 @@
       "cell_type": "code",
       "source": [
         "smaller_model = keras.Sequential([\n",
-        "    keras.layers.Dense(4, activation=tf.nn.relu),\n",
+        "    keras.layers.Dense(4, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
         "    keras.layers.Dense(4, activation=tf.nn.relu),\n",
         "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
         "])\n",
@@ -438,7 +439,7 @@
       "cell_type": "code",
       "source": [
         "bigger_model = keras.models.Sequential([\n",
-        "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
+        "    keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
         "    keras.layers.Dense(512, activation=tf.nn.relu),\n",
         "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
         "])\n",
@@ -606,7 +607,7 @@
       "source": [
         "l2_model = keras.models.Sequential([\n",
         "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
-        "                       activation=tf.nn.relu),\n",
+        "                       activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
         "    keras.layers.Dense(16, kernel_regularizer=keras.regularizers.l2(0.001),\n",
         "                       activation=tf.nn.relu),\n",
         "    keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
@@ -697,7 +698,7 @@
       "cell_type": "code",
       "source": [
         "dpt_model = keras.models.Sequential([\n",
-        "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
+        "    keras.layers.Dense(16, activation=tf.nn.relu, input_shape=(NUM_WORDS,)),\n",
         "    keras.layers.Dropout(0.5),\n",
         "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
         "    keras.layers.Dropout(0.5),\n",
