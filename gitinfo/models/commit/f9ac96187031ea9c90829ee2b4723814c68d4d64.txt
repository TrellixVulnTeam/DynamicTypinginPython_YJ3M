commit f9ac96187031ea9c90829ee2b4723814c68d4d64
Author: Hongkun Yu <hongkuny@google.com>
Date:   Mon Jun 22 17:54:42 2020 -0700

    Remove this r1 folder from the master branch in June, 2020.
    
    PiperOrigin-RevId: 317772122

diff --git a/official/r1/README.md b/official/r1/README.md
deleted file mode 100644
index 72514177..00000000
--- a/official/r1/README.md
+++ /dev/null
@@ -1,23 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# Legacy Models
-
-The **r1** folder contains legacy model implementations developed
-using TensorFlow 1.x.
-
-**Note: We will remove this r1 folder from the master branch in June, 2020.**
-
-After removal, you will still be able to access legacy models
-in the previous releases.
-(e.g., [v2.1.0](https://github.com/tensorflow/models/releases/tag/v2.1.0))
-
-| Model | Description | Reference |
-| ----- | ----------- | --------- |
-| [Gradient Boosted Trees](boosted_trees) | A gradient boosted trees model to classify higgs boson process from HIGGS dataset | [Link](https://en.wikipedia.org/wiki/Gradient_boosting) |
-| [MNIST](mnist) | A basic model to classify digits from the MNIST dataset | [Link](http://yann.lecun.com/exdb/mnist/) |
-| [NCF](ncf) | NCF Estimator implementation | [arXiv:1708.05031](https://arxiv.org/abs/1708.05031) |
-| [ResNet](resnet) | A deep residual network for image recognition | [arXiv:1512.03385](https://arxiv.org/abs/1512.03385) |
-| [Transformer](transformer) | A transformer model to translate the WMT English to German dataset | [arXiv:1706.03762](https://arxiv.org/abs/1706.03762) |
-| [Wide & Deep Learning](wide_deep) | A model that combines a wide linear model and deep neural network for recommender systems | [arXiv:1606.07792](https://arxiv.org/abs/1606.07792) |
diff --git a/official/r1/__init__.py b/official/r1/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/boosted_trees/README.md b/official/r1/boosted_trees/README.md
deleted file mode 100644
index 56c40aa5..00000000
--- a/official/r1/boosted_trees/README.md
+++ /dev/null
@@ -1,117 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# Classifying Higgs boson processes in the HIGGS Data Set
-
-## Overview
-The [HIGGS Data Set](https://archive.ics.uci.edu/ml/datasets/HIGGS) contains 11 million samples with 28 features, and is for the classification problem to distinguish between a signal process which produces Higgs bosons and a background process which does not.
-
-We use Gradient Boosted Trees algorithm to distinguish the two classes.
-
----
-
-The code sample uses the high level `tf.estimator.Estimator` and `tf.data.Dataset`.  These APIs are great for fast iteration and quickly adapting models to your own datasets without major code overhauls.  It allows you to move from single-worker training to distributed training, and makes it easy to export model binaries for prediction.  Here, for further simplicity and faster execution, we use a utility function `tf.contrib.estimator.boosted_trees_classifier_train_in_memory`.  This utility function is especially effective when the input is provided as in-memory data sets like numpy arrays.
-
-An input function for the `Estimator` typically uses `tf.data.Dataset` API, which can handle various data control like streaming, batching, transform and shuffling. However `boosted_trees_classifier_train_in_memory()` utility function requires that the entire data is provided as a single batch (i.e. without using `batch()` API). Thus in this practice, simply `Dataset.from_tensors()` is used to convert numpy arrays into structured tensors, and `Dataset.zip()` is used to put features and label together.
-For further references of `Dataset`, [Read more here](https://www.tensorflow.org/guide/datasets).
-
-## Running the code
-First make sure you've [added the models folder to your Python path](/official/#running-the-models); otherwise you may encounter an error like `ImportError: No module named official.boosted_trees`.
-
-### Setup
-The [HIGGS Data Set](https://archive.ics.uci.edu/ml/datasets/HIGGS) that this sample uses for training is hosted by the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/). We have provided a script that downloads and cleans the necessary files.
-
-```
-python data_download.py
-```
-
-This will download a file and store the processed file under the directory designated by `--data_dir` (defaults to `/tmp/higgs_data/`). To change the target directory, set the `--data_dir` flag. The directory could be network storages that Tensorflow supports (like Google Cloud Storage, `gs://<bucket>/<path>/`).
-The file downloaded to the local temporary folder is about 2.8 GB, and the processed file is about 0.8 GB, so there should be enough storage to handle them.
-
-
-### Training
-
-This example uses about 3 GB of RAM during training.
-You can run the code locally as follows:
-
-```
-python train_higgs.py
-```
-
-The model is by default saved to `/tmp/higgs_model`, which can be changed using the `--model_dir` flag.
-Note that the model_dir is cleaned up before every time training starts.
-
-Model parameters can be adjusted by flags, like `--n_trees`, `--max_depth`, `--learning_rate` and so on.  Check out the code for details.
-
-The final accuracy will be around 74% and loss will be around 0.516 over the eval set, when trained with the default parameters.
-
-By default, the first 1 million examples among 11 millions are used for training, and the last 1 million examples are used for evaluation.
-The training/evaluation data can be selected as index ranges by flags `--train_start`, `--train_count`, `--eval_start`, `--eval_count`, etc.
-
-### TensorBoard
-
-Run TensorBoard to inspect the details about the graph and training progression.
-
-```
-tensorboard --logdir=/tmp/higgs_model  # set logdir as --model_dir set during training.
-```
-
-## Inference with SavedModel
-You can export the model into Tensorflow [SavedModel](https://www.tensorflow.org/guide/saved_model) format by using the argument `--export_dir`:
-
-```
-python train_higgs.py --export_dir /tmp/higgs_boosted_trees_saved_model
-```
-
-After the model finishes training, use [`saved_model_cli`](https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel) to inspect and execute the SavedModel.
-
-Try the following commands to inspect the SavedModel:
-
-**Replace `${TIMESTAMP}` with the folder produced (e.g. 1524249124)**
-```
-# List possible tag_sets. Only one metagraph is saved, so there will be one option.
-saved_model_cli show --dir /tmp/higgs_boosted_trees_saved_model/${TIMESTAMP}/
-
-# Show SignatureDefs for tag_set=serve. SignatureDefs define the outputs to show.
-saved_model_cli show --dir /tmp/higgs_boosted_trees_saved_model/${TIMESTAMP}/ \
-    --tag_set serve --all
-```
-
-### Inference
-Let's use the model to predict the income group of two examples.
-Note that this model exports SavedModel with the custom parsing module that accepts csv lines as features. (Each line is an example with 28 columns; be careful to not add a label column, unlike in the training data.)
-
-```
-saved_model_cli run --dir /tmp/boosted_trees_higgs_saved_model/${TIMESTAMP}/ \
-    --tag_set serve --signature_def="predict" \
-    --input_exprs='inputs=["0.869293,-0.635082,0.225690,0.327470,-0.689993,0.754202,-0.248573,-1.092064,0.0,1.374992,-0.653674,0.930349,1.107436,1.138904,-1.578198,-1.046985,0.0,0.657930,-0.010455,-0.045767,3.101961,1.353760,0.979563,0.978076,0.920005,0.721657,0.988751,0.876678", "1.595839,-0.607811,0.007075,1.818450,-0.111906,0.847550,-0.566437,1.581239,2.173076,0.755421,0.643110,1.426367,0.0,0.921661,-1.190432,-1.615589,0.0,0.651114,-0.654227,-1.274345,3.101961,0.823761,0.938191,0.971758,0.789176,0.430553,0.961357,0.957818"]'
-```
-
-This will print out the predicted classes and class probabilities. Something like:
-
-```
-Result for output key class_ids:
-[[1]
- [0]]
-Result for output key classes:
-[['1']
- ['0']]
-Result for output key logistic:
-[[0.6440273 ]
- [0.10902369]]
-Result for output key logits:
-[[ 0.59288704]
- [-2.1007526 ]]
-Result for output key probabilities:
-[[0.3559727 0.6440273]
- [0.8909763 0.1090237]]
-```
-
-Please note that "predict" signature_def gives out different (more detailed) results than "classification" or "serving_default".
-
-## Additional Links
-
-If you are interested in distributed training, take a look at [Distributed TensorFlow](https://www.tensorflow.org/deploy/distributed).
-
-You can also [train models on Cloud ML Engine](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction), which provides [hyperparameter tuning](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction#hyperparameter_tuning) to maximize your model's results and enables [deploying your model for prediction](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction#deploy_a_model_to_support_prediction).
diff --git a/official/r1/boosted_trees/__init__.py b/official/r1/boosted_trees/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/boosted_trees/data_download.py b/official/r1/boosted_trees/data_download.py
deleted file mode 100644
index 1b6fc050..00000000
--- a/official/r1/boosted_trees/data_download.py
+++ /dev/null
@@ -1,97 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Downloads the UCI HIGGS Dataset and prepares train data.
-
-The details on the dataset are in https://archive.ics.uci.edu/ml/datasets/HIGGS
-
-It takes a while as it needs to download 2.8 GB over the network, process, then
-store it into the specified location as a compressed numpy file.
-
-Usage:
-$ python data_download.py --data_dir=/tmp/higgs_data
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import gzip
-import os
-import tempfile
-
-# pylint: disable=g-bad-import-order
-import numpy as np
-import pandas as pd
-from six.moves import urllib
-from absl import app as absl_app
-from absl import flags
-import tensorflow as tf
-
-from official.utils.flags import core as flags_core
-
-URL_ROOT = "https://archive.ics.uci.edu/ml/machine-learning-databases/00280"
-INPUT_FILE = "HIGGS.csv.gz"
-NPZ_FILE = "HIGGS.csv.gz.npz"  # numpy compressed file to contain "data" array.
-
-
-def _download_higgs_data_and_save_npz(data_dir):
-  """Download higgs data and store as a numpy compressed file."""
-  input_url = URL_ROOT + "/" + INPUT_FILE
-  np_filename = os.path.join(data_dir, NPZ_FILE)
-  if tf.gfile.Exists(np_filename):
-    raise ValueError("data_dir already has the processed data file: {}".format(
-        np_filename))
-  if not tf.gfile.Exists(data_dir):
-    tf.gfile.MkDir(data_dir)
-  # 2.8 GB to download.
-  try:
-    tf.logging.info("Data downloading...")
-    temp_filename, _ = urllib.request.urlretrieve(input_url)
-    # Reading and parsing 11 million csv lines takes 2~3 minutes.
-    tf.logging.info("Data processing... taking multiple minutes...")
-    with gzip.open(temp_filename, "rb") as csv_file:
-      data = pd.read_csv(
-          csv_file,
-          dtype=np.float32,
-          names=["c%02d" % i for i in range(29)]  # label + 28 features.
-      ).as_matrix()
-  finally:
-    tf.gfile.Remove(temp_filename)
-
-  # Writing to temporary location then copy to the data_dir (0.8 GB).
-  f = tempfile.NamedTemporaryFile()
-  np.savez_compressed(f, data=data)
-  tf.gfile.Copy(f.name, np_filename)
-  tf.logging.info("Data saved to: {}".format(np_filename))
-
-
-def main(unused_argv):
-  if not tf.gfile.Exists(FLAGS.data_dir):
-    tf.gfile.MkDir(FLAGS.data_dir)
-  _download_higgs_data_and_save_npz(FLAGS.data_dir)
-
-
-def define_data_download_flags():
-  """Add flags specifying data download arguments."""
-  flags.DEFINE_string(
-      name="data_dir", default="/tmp/higgs_data",
-      help=flags_core.help_wrap(
-          "Directory to download higgs dataset and store training/eval data."))
-
-
-if __name__ == "__main__":
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_data_download_flags()
-  FLAGS = flags.FLAGS
-  absl_app.run(main)
diff --git a/official/r1/boosted_trees/train_higgs.py b/official/r1/boosted_trees/train_higgs.py
deleted file mode 100644
index 5f3f2547..00000000
--- a/official/r1/boosted_trees/train_higgs.py
+++ /dev/null
@@ -1,295 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-r"""A script that builds boosted trees over higgs data.
-
-If you haven't, please run data_download.py beforehand to prepare the data.
-
-For some more details on this example, please refer to README.md as well.
-
-Note that the model_dir is cleaned up before starting the training.
-
-Usage:
-$ python train_higgs.py --n_trees=100 --max_depth=6 --learning_rate=0.1 \
-    --model_dir=/tmp/higgs_model
-
-Note that BoostedTreesClassifier is available since Tensorflow 1.8.0.
-So you need to install recent enough version of Tensorflow to use this example.
-
-The training data is by default the first million examples out of 11M examples,
-and eval data is by default the last million examples.
-They are controlled by --train_start, --train_count, --eval_start, --eval_count.
-e.g. to train over the first 10 million examples instead of 1 million:
-$ python train_higgs.py --n_trees=100 --max_depth=6 --learning_rate=0.1 \
-    --model_dir=/tmp/higgs_model --train_count=10000000
-
-Training history and metrics can be inspected using tensorboard.
-Set --logdir as the --model_dir set by flag when training
-(or the default /tmp/higgs_model).
-$ tensorboard --logdir=/tmp/higgs_model
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-from absl import app as absl_app
-from absl import flags
-import numpy as np
-import tensorflow.compat.v1 as tf
-
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-from official.utils.flags._conventions import help_wrap
-
-NPZ_FILE = "HIGGS.csv.gz.npz"  # numpy compressed file containing "data" array
-
-
-def read_higgs_data(data_dir, train_start, train_count, eval_start, eval_count):
-  """Reads higgs data from csv and returns train and eval data.
-
-  Args:
-    data_dir: A string, the directory of higgs dataset.
-    train_start: An integer, the start index of train examples within the data.
-    train_count: An integer, the number of train examples within the data.
-    eval_start: An integer, the start index of eval examples within the data.
-    eval_count: An integer, the number of eval examples within the data.
-
-  Returns:
-    Numpy array of train data and eval data.
-  """
-  npz_filename = os.path.join(data_dir, NPZ_FILE)
-  try:
-    # gfile allows numpy to read data from network data sources as well.
-    with tf.gfile.Open(npz_filename, "rb") as npz_file:
-      with np.load(npz_file) as npz:
-        data = npz["data"]
-  except tf.errors.NotFoundError as e:
-    raise RuntimeError(
-        "Error loading data; use data_download.py to prepare the data.\n{}: {}"
-        .format(type(e).__name__, e))
-  return (data[train_start:train_start+train_count],
-          data[eval_start:eval_start+eval_count])
-
-
-# This showcases how to make input_fn when the input data is available in the
-# form of numpy arrays.
-def make_inputs_from_np_arrays(features_np, label_np):
-  """Makes and returns input_fn and feature_columns from numpy arrays.
-
-  The generated input_fn will return tf.data.Dataset of feature dictionary and a
-  label, and feature_columns will consist of the list of
-  tf.feature_column.BucketizedColumn.
-
-  Note, for in-memory training, tf.data.Dataset should contain the whole data
-  as a single tensor. Don't use batch.
-
-  Args:
-    features_np: A numpy ndarray (shape=[batch_size, num_features]) for
-        float32 features.
-    label_np: A numpy ndarray (shape=[batch_size, 1]) for labels.
-
-  Returns:
-    input_fn: A function returning a Dataset of feature dict and label.
-    feature_names: A list of feature names.
-    feature_column: A list of tf.feature_column.BucketizedColumn.
-  """
-  num_features = features_np.shape[1]
-  features_np_list = np.split(features_np, num_features, axis=1)
-  # 1-based feature names.
-  feature_names = ["feature_%02d" % (i + 1) for i in range(num_features)]
-
-  # Create source feature_columns and bucketized_columns.
-  def get_bucket_boundaries(feature):
-    """Returns bucket boundaries for feature by percentiles."""
-    return np.unique(np.percentile(feature, range(0, 100))).tolist()
-  source_columns = [
-      tf.feature_column.numeric_column(
-          feature_name, dtype=tf.float32,
-          # Although higgs data have no missing values, in general, default
-          # could be set as 0 or some reasonable value for missing values.
-          default_value=0.0)
-      for feature_name in feature_names
-  ]
-  bucketized_columns = [
-      tf.feature_column.bucketized_column(
-          source_columns[i],
-          boundaries=get_bucket_boundaries(features_np_list[i]))
-      for i in range(num_features)
-  ]
-
-  # Make an input_fn that extracts source features.
-  def input_fn():
-    """Returns features as a dictionary of numpy arrays, and a label."""
-    features = {
-        feature_name: tf.constant(features_np_list[i])
-        for i, feature_name in enumerate(feature_names)
-    }
-    return tf.data.Dataset.zip((tf.data.Dataset.from_tensors(features),
-                                tf.data.Dataset.from_tensors(label_np),))
-
-  return input_fn, feature_names, bucketized_columns
-
-
-def make_eval_inputs_from_np_arrays(features_np, label_np):
-  """Makes eval input as streaming batches."""
-  num_features = features_np.shape[1]
-  features_np_list = np.split(features_np, num_features, axis=1)
-  # 1-based feature names.
-  feature_names = ["feature_%02d" % (i + 1) for i in range(num_features)]
-
-  def input_fn():
-    features = {
-        feature_name: tf.constant(features_np_list[i])
-        for i, feature_name in enumerate(feature_names)
-    }
-    return tf.data.Dataset.zip((
-        tf.data.Dataset.from_tensor_slices(features),
-        tf.data.Dataset.from_tensor_slices(label_np),)).batch(1000)
-
-  return input_fn
-
-
-def _make_csv_serving_input_receiver_fn(column_names, column_defaults):
-  """Returns serving_input_receiver_fn for csv.
-
-  The input arguments are relevant to `tf.decode_csv()`.
-
-  Args:
-    column_names: a list of column names in the order within input csv.
-    column_defaults: a list of default values with the same size of
-        column_names. Each entity must be either a list of one scalar, or an
-        empty list to denote the corresponding column is required.
-        e.g. [[""], [2.5], []] indicates the third column is required while
-            the first column must be string and the second must be float/double.
-
-  Returns:
-    a serving_input_receiver_fn that handles csv for serving.
-  """
-  def serving_input_receiver_fn():
-    csv = tf.placeholder(dtype=tf.string, shape=[None], name="csv")
-    features = dict(zip(column_names, tf.decode_csv(csv, column_defaults)))
-    receiver_tensors = {"inputs": csv}
-    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)
-
-  return serving_input_receiver_fn
-
-
-def train_boosted_trees(flags_obj):
-  """Train boosted_trees estimator on HIGGS data.
-
-  Args:
-    flags_obj: An object containing parsed flag values.
-  """
-  # Clean up the model directory if present.
-  if tf.gfile.Exists(flags_obj.model_dir):
-    tf.gfile.DeleteRecursively(flags_obj.model_dir)
-  tf.logging.info("## Data loading...")
-  train_data, eval_data = read_higgs_data(
-      flags_obj.data_dir, flags_obj.train_start, flags_obj.train_count,
-      flags_obj.eval_start, flags_obj.eval_count)
-  tf.logging.info("## Data loaded; train: {}{}, eval: {}{}".format(
-      train_data.dtype, train_data.shape, eval_data.dtype, eval_data.shape))
-  # Data consists of one label column followed by 28 feature columns.
-  train_input_fn, feature_names, feature_columns = make_inputs_from_np_arrays(
-      features_np=train_data[:, 1:], label_np=train_data[:, 0:1])
-  eval_input_fn = make_eval_inputs_from_np_arrays(
-      features_np=eval_data[:, 1:], label_np=eval_data[:, 0:1])
-  tf.logging.info("## Features prepared. Training starts...")
-
-  # Create benchmark logger to log info about the training and metric values
-  run_params = {
-      "train_start": flags_obj.train_start,
-      "train_count": flags_obj.train_count,
-      "eval_start": flags_obj.eval_start,
-      "eval_count": flags_obj.eval_count,
-      "n_trees": flags_obj.n_trees,
-      "max_depth": flags_obj.max_depth,
-  }
-  benchmark_logger = logger.config_benchmark_logger(flags_obj)
-  benchmark_logger.log_run_info(
-      model_name="boosted_trees",
-      dataset_name="higgs",
-      run_params=run_params,
-      test_id=flags_obj.benchmark_test_id)
-
-  # Though BoostedTreesClassifier is under tf.estimator, faster in-memory
-  # training is yet provided as a contrib library.
-  from tensorflow.contrib import estimator as contrib_estimator  # pylint: disable=g-import-not-at-top
-  classifier = contrib_estimator.boosted_trees_classifier_train_in_memory(
-      train_input_fn,
-      feature_columns,
-      model_dir=flags_obj.model_dir or None,
-      n_trees=flags_obj.n_trees,
-      max_depth=flags_obj.max_depth,
-      learning_rate=flags_obj.learning_rate)
-
-  # Evaluation.
-  eval_results = classifier.evaluate(eval_input_fn)
-  # Benchmark the evaluation results
-  benchmark_logger.log_evaluation_result(eval_results)
-
-  # Exporting the savedmodel with csv parsing.
-  if flags_obj.export_dir is not None:
-    classifier.export_savedmodel(
-        flags_obj.export_dir,
-        _make_csv_serving_input_receiver_fn(
-            column_names=feature_names,
-            # columns are all floats.
-            column_defaults=[[0.0]] * len(feature_names)),
-        strip_default_attrs=True)
-
-
-def main(_):
-  train_boosted_trees(flags.FLAGS)
-
-
-def define_train_higgs_flags():
-  """Add tree related flags as well as training/eval configuration."""
-  flags_core.define_base(clean=False, stop_threshold=False, batch_size=False,
-                         num_gpu=False, export_dir=True)
-  flags_core.define_benchmark()
-  flags.adopt_module_key_flags(flags_core)
-
-  flags.DEFINE_integer(
-      name="train_start", default=0,
-      help=help_wrap("Start index of train examples within the data."))
-  flags.DEFINE_integer(
-      name="train_count", default=1000000,
-      help=help_wrap("Number of train examples within the data."))
-  flags.DEFINE_integer(
-      name="eval_start", default=10000000,
-      help=help_wrap("Start index of eval examples within the data."))
-  flags.DEFINE_integer(
-      name="eval_count", default=1000000,
-      help=help_wrap("Number of eval examples within the data."))
-
-  flags.DEFINE_integer(
-      "n_trees", default=100, help=help_wrap("Number of trees to build."))
-  flags.DEFINE_integer(
-      "max_depth", default=6, help=help_wrap("Maximum depths of each tree."))
-  flags.DEFINE_float(
-      "learning_rate", default=0.1,
-      help=help_wrap("The learning rate."))
-
-  flags_core.set_defaults(data_dir="/tmp/higgs_data",
-                          model_dir="/tmp/higgs_model")
-
-
-if __name__ == "__main__":
-  # Training progress and eval results are shown as logging.INFO; so enables it.
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_train_higgs_flags()
-  absl_app.run(main)
diff --git a/official/r1/mnist/README.md b/official/r1/mnist/README.md
deleted file mode 100644
index 55f35238..00000000
--- a/official/r1/mnist/README.md
+++ /dev/null
@@ -1,91 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# MNIST in TensorFlow
-
-This directory builds a convolutional neural net to classify the [MNIST
-dataset](http://yann.lecun.com/exdb/mnist/) using the
-[tf.data](https://www.tensorflow.org/api_docs/python/tf/data),
-[tf.estimator.Estimator](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator),
-and
-[tf.layers](https://www.tensorflow.org/api_docs/python/tf/layers)
-APIs.
-
-
-## Setup
-
-To begin, you'll simply need the latest version of TensorFlow installed.
-First make sure you've [added the models folder to your Python path]:
-
-```shell
-export PYTHONPATH="$PYTHONPATH:/path/to/models"
-```
-
-Otherwise you may encounter an error like `ImportError: No module named official.mnist`.
-
-Then to train the model, run the following:
-
-```
-python mnist.py
-```
-
-The model will begin training and will automatically evaluate itself on the
-validation data.
-
-Illustrative unit tests and benchmarks can be run with:
-
-```
-python mnist_test.py
-python mnist_test.py --benchmarks=.
-```
-
-## Exporting the model
-
-You can export the model into Tensorflow [SavedModel](https://www.tensorflow.org/guide/saved_model) format by using the argument `--export_dir`:
-
-```
-python mnist.py --export_dir /tmp/mnist_saved_model
-```
-
-The SavedModel will be saved in a timestamped directory under `/tmp/mnist_saved_model/` (e.g. `/tmp/mnist_saved_model/1513630966/`).
-
-**Getting predictions with SavedModel**
-Use [`saved_model_cli`](https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel) to inspect and execute the SavedModel.
-
-```
-saved_model_cli run --dir /tmp/mnist_saved_model/TIMESTAMP --tag_set serve --signature_def classify --inputs image=examples.npy
-```
-
-`examples.npy` contains the data from `example5.png` and `example3.png` in a numpy array, in that order. The array values are normalized to values between 0 and 1.
-
-The output should look similar to below:
-```
-Result for output key classes:
-[5 3]
-Result for output key probabilities:
-[[  1.53558474e-07   1.95694142e-13   1.31193523e-09   5.47467265e-03
-    5.85711526e-22   9.94520664e-01   3.48423509e-06   2.65365645e-17
-    9.78631419e-07   3.15522470e-08]
- [  1.22413359e-04   5.87615965e-08   1.72251271e-06   9.39960718e-01
-    3.30306928e-11   2.87386645e-02   2.82353517e-02   8.21146413e-18
-    2.52568233e-03   4.15460236e-04]]
-```
-
-## Experimental: Eager Execution
-
-[Eager execution](https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html)
-(an preview feature in TensorFlow 1.5) is an imperative interface to TensorFlow.
-The exact same model defined in `mnist.py` can be trained without creating a
-TensorFlow graph using:
-
-```
-python mnist_eager.py
-```
-
-## Experimental: TPU Acceleration
-
-`mnist.py` (and `mnist_eager.py`) demonstrate training a neural network to
-classify digits on CPUs and GPUs. `mnist_tpu.py` can be used to train the
-same model using TPUs for hardware acceleration. More information in
-the [tensorflow/tpu](https://github.com/tensorflow/tpu) repository.
diff --git a/official/r1/mnist/__init__.py b/official/r1/mnist/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/mnist/dataset.py b/official/r1/mnist/dataset.py
deleted file mode 100644
index 2bdd155d..00000000
--- a/official/r1/mnist/dataset.py
+++ /dev/null
@@ -1,117 +0,0 @@
-#  Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-#  Licensed under the Apache License, Version 2.0 (the "License");
-#  you may not use this file except in compliance with the License.
-#  You may obtain a copy of the License at
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS,
-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#  See the License for the specific language governing permissions and
-#  limitations under the License.
-"""tf.data.Dataset interface to the MNIST dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import gzip
-import os
-import shutil
-import tempfile
-
-import numpy as np
-from six.moves import urllib
-import tensorflow as tf
-
-
-def read32(bytestream):
-  """Read 4 bytes from bytestream as an unsigned 32-bit integer."""
-  dt = np.dtype(np.uint32).newbyteorder('>')
-  return np.frombuffer(bytestream.read(4), dtype=dt)[0]
-
-
-def check_image_file_header(filename):
-  """Validate that filename corresponds to images for the MNIST dataset."""
-  with tf.io.gfile.GFile(filename, 'rb') as f:
-    magic = read32(f)
-    read32(f)  # num_images, unused
-    rows = read32(f)
-    cols = read32(f)
-    if magic != 2051:
-      raise ValueError('Invalid magic number %d in MNIST file %s' % (magic,
-                                                                     f.name))
-    if rows != 28 or cols != 28:
-      raise ValueError(
-          'Invalid MNIST file %s: Expected 28x28 images, found %dx%d' %
-          (f.name, rows, cols))
-
-
-def check_labels_file_header(filename):
-  """Validate that filename corresponds to labels for the MNIST dataset."""
-  with tf.io.gfile.GFile(filename, 'rb') as f:
-    magic = read32(f)
-    read32(f)  # num_items, unused
-    if magic != 2049:
-      raise ValueError('Invalid magic number %d in MNIST file %s' % (magic,
-                                                                     f.name))
-
-
-def download(directory, filename):
-  """Download (and unzip) a file from the MNIST dataset if not already done."""
-  filepath = os.path.join(directory, filename)
-  if tf.io.gfile.exists(filepath):
-    return filepath
-  if not tf.io.gfile.exists(directory):
-    tf.io.gfile.makedirs(directory)
-  # CVDF mirror of http://yann.lecun.com/exdb/mnist/
-  url = 'https://storage.googleapis.com/cvdf-datasets/mnist/' + filename + '.gz'
-  _, zipped_filepath = tempfile.mkstemp(suffix='.gz')
-  print('Downloading %s to %s' % (url, zipped_filepath))
-  urllib.request.urlretrieve(url, zipped_filepath)
-  with gzip.open(zipped_filepath, 'rb') as f_in, \
-      tf.io.gfile.GFile(filepath, 'wb') as f_out:
-    shutil.copyfileobj(f_in, f_out)
-  os.remove(zipped_filepath)
-  return filepath
-
-
-def dataset(directory, images_file, labels_file):
-  """Download and parse MNIST dataset."""
-
-  images_file = download(directory, images_file)
-  labels_file = download(directory, labels_file)
-
-  check_image_file_header(images_file)
-  check_labels_file_header(labels_file)
-
-  def decode_image(image):
-    # Normalize from [0, 255] to [0.0, 1.0]
-    image = tf.io.decode_raw(image, tf.uint8)
-    image = tf.cast(image, tf.float32)
-    image = tf.reshape(image, [784])
-    return image / 255.0
-
-  def decode_label(label):
-    label = tf.io.decode_raw(label, tf.uint8)  # tf.string -> [tf.uint8]
-    label = tf.reshape(label, [])  # label is a scalar
-    return tf.cast(label, tf.int32)
-
-  images = tf.data.FixedLengthRecordDataset(
-      images_file, 28 * 28, header_bytes=16).map(decode_image)
-  labels = tf.data.FixedLengthRecordDataset(
-      labels_file, 1, header_bytes=8).map(decode_label)
-  return tf.data.Dataset.zip((images, labels))
-
-
-def train(directory):
-  """tf.data.Dataset object for MNIST training data."""
-  return dataset(directory, 'train-images-idx3-ubyte',
-                 'train-labels-idx1-ubyte')
-
-
-def test(directory):
-  """tf.data.Dataset object for MNIST test data."""
-  return dataset(directory, 't10k-images-idx3-ubyte', 't10k-labels-idx1-ubyte')
diff --git a/official/r1/mnist/example3.png b/official/r1/mnist/example3.png
deleted file mode 100644
index bb7f5b88..00000000
Binary files a/official/r1/mnist/example3.png and /dev/null differ
diff --git a/official/r1/mnist/example5.png b/official/r1/mnist/example5.png
deleted file mode 100644
index 68496bcc..00000000
Binary files a/official/r1/mnist/example5.png and /dev/null differ
diff --git a/official/r1/mnist/examples.npy b/official/r1/mnist/examples.npy
deleted file mode 100644
index 85d78b1b..00000000
Binary files a/official/r1/mnist/examples.npy and /dev/null differ
diff --git a/official/r1/mnist/mnist.py b/official/r1/mnist/mnist.py
deleted file mode 100644
index a93358d8..00000000
--- a/official/r1/mnist/mnist.py
+++ /dev/null
@@ -1,247 +0,0 @@
-#  Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-#  Licensed under the Apache License, Version 2.0 (the "License");
-#  you may not use this file except in compliance with the License.
-#  You may obtain a copy of the License at
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS,
-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#  See the License for the specific language governing permissions and
-#  limitations under the License.
-"""Convolutional Neural Network Estimator for MNIST, built with tf.layers."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-from absl import app as absl_app
-from absl import flags
-from absl import logging
-from six.moves import range
-import tensorflow.compat.v1 as tf
-
-from official.r1.mnist import dataset
-from official.r1.utils.logs import hooks_helper
-from official.utils.flags import core as flags_core
-from official.utils.misc import distribution_utils
-from official.utils.misc import model_helpers
-
-
-LEARNING_RATE = 1e-4
-
-
-def create_model(data_format):
-  """Model to recognize digits in the MNIST dataset.
-
-  Network structure is equivalent to:
-  https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/examples/tutorials/mnist/mnist_deep.py
-
-  But uses the tf.keras API.
-
-  Args:
-    data_format: Either 'channels_first' or 'channels_last'. 'channels_first' is
-      typically faster on GPUs while 'channels_last' is typically faster on
-      CPUs. See
-      https://www.tensorflow.org/performance/performance_guide#data_formats
-
-  Returns:
-    A tf.keras.Model.
-  """
-  if data_format == 'channels_first':
-    input_shape = [1, 28, 28]
-  else:
-    assert data_format == 'channels_last'
-    input_shape = [28, 28, 1]
-
-  l = tf.keras.layers
-  max_pool = l.MaxPooling2D(
-      (2, 2), (2, 2), padding='same', data_format=data_format)
-  # The model consists of a sequential chain of layers, so tf.keras.Sequential
-  # (a subclass of tf.keras.Model) makes for a compact description.
-  return tf.keras.Sequential(
-      [
-          l.Reshape(
-              target_shape=input_shape,
-              input_shape=(28 * 28,)),
-          l.Conv2D(
-              32,
-              5,
-              padding='same',
-              data_format=data_format,
-              activation=tf.nn.relu),
-          max_pool,
-          l.Conv2D(
-              64,
-              5,
-              padding='same',
-              data_format=data_format,
-              activation=tf.nn.relu),
-          max_pool,
-          l.Flatten(),
-          l.Dense(1024, activation=tf.nn.relu),
-          l.Dropout(0.4),
-          l.Dense(10)
-      ])
-
-
-def define_mnist_flags():
-  """Defines flags for mnist."""
-  flags_core.define_base(clean=True, train_epochs=True,
-                         epochs_between_evals=True, stop_threshold=True,
-                         num_gpu=True, hooks=True, export_dir=True,
-                         distribution_strategy=True)
-  flags_core.define_performance(inter_op=True, intra_op=True,
-                                num_parallel_calls=False,
-                                all_reduce_alg=True)
-  flags_core.define_image()
-  flags.adopt_module_key_flags(flags_core)
-  flags_core.set_defaults(data_dir='/tmp/mnist_data',
-                          model_dir='/tmp/mnist_model',
-                          batch_size=100,
-                          train_epochs=40)
-
-
-def model_fn(features, labels, mode, params):
-  """The model_fn argument for creating an Estimator."""
-  model = create_model(params['data_format'])
-  image = features
-  if isinstance(image, dict):
-    image = features['image']
-
-  if mode == tf.estimator.ModeKeys.PREDICT:
-    logits = model(image, training=False)
-    predictions = {
-        'classes': tf.argmax(logits, axis=1),
-        'probabilities': tf.nn.softmax(logits),
-    }
-    return tf.estimator.EstimatorSpec(
-        mode=tf.estimator.ModeKeys.PREDICT,
-        predictions=predictions,
-        export_outputs={
-            'classify': tf.estimator.export.PredictOutput(predictions)
-        })
-  if mode == tf.estimator.ModeKeys.TRAIN:
-    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=LEARNING_RATE)
-
-    logits = model(image, training=True)
-    loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(labels=labels,
-                                                            logits=logits)
-    accuracy = tf.compat.v1.metrics.accuracy(
-        labels=labels, predictions=tf.argmax(logits, axis=1))
-
-    # Name tensors to be logged with LoggingTensorHook.
-    tf.identity(LEARNING_RATE, 'learning_rate')
-    tf.identity(loss, 'cross_entropy')
-    tf.identity(accuracy[1], name='train_accuracy')
-
-    # Save accuracy scalar to Tensorboard output.
-    tf.summary.scalar('train_accuracy', accuracy[1])
-
-    return tf.estimator.EstimatorSpec(
-        mode=tf.estimator.ModeKeys.TRAIN,
-        loss=loss,
-        train_op=optimizer.minimize(
-            loss,
-            tf.compat.v1.train.get_or_create_global_step()))
-  if mode == tf.estimator.ModeKeys.EVAL:
-    logits = model(image, training=False)
-    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
-    return tf.estimator.EstimatorSpec(
-        mode=tf.estimator.ModeKeys.EVAL,
-        loss=loss,
-        eval_metric_ops={
-            'accuracy':
-                tf.metrics.accuracy(
-                    labels=labels, predictions=tf.argmax(logits, axis=1)),
-        })
-
-
-def run_mnist(flags_obj):
-  """Run MNIST training and eval loop.
-
-  Args:
-    flags_obj: An object containing parsed flag values.
-  """
-  model_helpers.apply_clean(flags_obj)
-  model_function = model_fn
-
-  session_config = tf.compat.v1.ConfigProto(
-      inter_op_parallelism_threads=flags_obj.inter_op_parallelism_threads,
-      intra_op_parallelism_threads=flags_obj.intra_op_parallelism_threads,
-      allow_soft_placement=True)
-
-  distribution_strategy = distribution_utils.get_distribution_strategy(
-      distribution_strategy=flags_obj.distribution_strategy,
-      num_gpus=flags_core.get_num_gpus(flags_obj),
-      all_reduce_alg=flags_obj.all_reduce_alg)
-
-  run_config = tf.estimator.RunConfig(
-      train_distribute=distribution_strategy, session_config=session_config)
-
-  data_format = flags_obj.data_format
-  if data_format is None:
-    data_format = ('channels_first' if tf.config.list_physical_devices('GPU')
-                   else 'channels_last')
-  mnist_classifier = tf.estimator.Estimator(
-      model_fn=model_function,
-      model_dir=flags_obj.model_dir,
-      config=run_config,
-      params={
-          'data_format': data_format,
-      })
-
-  # Set up training and evaluation input functions.
-  def train_input_fn():
-    """Prepare data for training."""
-
-    # When choosing shuffle buffer sizes, larger sizes result in better
-    # randomness, while smaller sizes use less memory. MNIST is a small
-    # enough dataset that we can easily shuffle the full epoch.
-    ds = dataset.train(flags_obj.data_dir)
-    ds = ds.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)
-
-    # Iterate through the dataset a set number (`epochs_between_evals`) of times
-    # during each training session.
-    ds = ds.repeat(flags_obj.epochs_between_evals)
-    return ds
-
-  def eval_input_fn():
-    return dataset.test(flags_obj.data_dir).batch(
-        flags_obj.batch_size).make_one_shot_iterator().get_next()
-
-  # Set up hook that outputs training logs every 100 steps.
-  train_hooks = hooks_helper.get_train_hooks(
-      flags_obj.hooks, model_dir=flags_obj.model_dir,
-      batch_size=flags_obj.batch_size)
-
-  # Train and evaluate model.
-  for _ in range(flags_obj.train_epochs // flags_obj.epochs_between_evals):
-    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)
-    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)
-    print('\nEvaluation results:\n\t%s\n' % eval_results)
-
-    if model_helpers.past_stop_threshold(flags_obj.stop_threshold,
-                                         eval_results['accuracy']):
-      break
-
-  # Export the model
-  if flags_obj.export_dir is not None:
-    image = tf.compat.v1.placeholder(tf.float32, [None, 28, 28])
-    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({
-        'image': image,
-    })
-    mnist_classifier.export_savedmodel(flags_obj.export_dir, input_fn,
-                                       strip_default_attrs=True)
-
-
-def main(_):
-  run_mnist(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  logging.set_verbosity(logging.INFO)
-  define_mnist_flags()
-  absl_app.run(main)
diff --git a/official/r1/mnist/mnist_eager.py b/official/r1/mnist/mnist_eager.py
deleted file mode 100644
index 36e2f7c3..00000000
--- a/official/r1/mnist/mnist_eager.py
+++ /dev/null
@@ -1,214 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""MNIST model training with TensorFlow eager execution.
-
-See:
-https://research.googleblog.com/2017/10/eager-execution-imperative-define-by.html
-
-This program demonstrates training of the convolutional neural network model
-defined in mnist.py with eager execution enabled.
-
-If you are not interested in eager execution, you should ignore this file.
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import time
-
-# pylint: disable=g-bad-import-order
-from absl import app as absl_app
-from absl import flags
-from six.moves import range
-from six.moves import zip
-import tensorflow as tf
-from tensorflow.python import eager as tfe
-# pylint: enable=g-bad-import-order
-
-from official.r1.mnist import dataset as mnist_dataset
-from official.r1.mnist import mnist
-from official.utils.flags import core as flags_core
-from official.utils.misc import model_helpers
-
-
-def loss(logits, labels):
-  return tf.reduce_mean(
-      tf.nn.sparse_softmax_cross_entropy_with_logits(
-          logits=logits, labels=labels))
-
-
-def compute_accuracy(logits, labels):
-  predictions = tf.argmax(logits, axis=1, output_type=tf.int64)
-  labels = tf.cast(labels, tf.int64)
-  batch_size = int(logits.shape[0])
-  return tf.reduce_sum(
-      tf.cast(tf.equal(predictions, labels), dtype=tf.float32)) / batch_size
-
-
-def train(model, optimizer, dataset, step_counter, log_interval=None):
-  """Trains model on `dataset` using `optimizer`."""
-  from tensorflow.contrib import summary as contrib_summary  # pylint: disable=g-import-not-at-top
-
-  start = time.time()
-  for (batch, (images, labels)) in enumerate(dataset):
-    with contrib_summary.record_summaries_every_n_global_steps(
-        10, global_step=step_counter):
-      # Record the operations used to compute the loss given the input,
-      # so that the gradient of the loss with respect to the variables
-      # can be computed.
-      with tf.GradientTape() as tape:
-        logits = model(images, training=True)
-        loss_value = loss(logits, labels)
-        contrib_summary.scalar('loss', loss_value)
-        contrib_summary.scalar('accuracy',
-                                    compute_accuracy(logits, labels))
-      grads = tape.gradient(loss_value, model.variables)
-      optimizer.apply_gradients(
-          list(zip(grads, model.variables)), global_step=step_counter)
-      if log_interval and batch % log_interval == 0:
-        rate = log_interval / (time.time() - start)
-        print('Step #%d\tLoss: %.6f (%d steps/sec)' % (batch, loss_value, rate))
-        start = time.time()
-
-
-def test(model, dataset):
-  """Perform an evaluation of `model` on the examples from `dataset`."""
-  from tensorflow.contrib import summary as contrib_summary  # pylint: disable=g-import-not-at-top
-  avg_loss = tf.keras.metrics.Mean('loss', dtype=tf.float32)
-  accuracy = tf.keras.metrics.Accuracy('accuracy', dtype=tf.float32)
-
-  for (images, labels) in dataset:
-    logits = model(images, training=False)
-    avg_loss.update_state(loss(logits, labels))
-    accuracy.update_state(
-        tf.argmax(logits, axis=1, output_type=tf.int64),
-        tf.cast(labels, tf.int64))
-  print('Test set: Average loss: %.4f, Accuracy: %4f%%\n' %
-        (avg_loss.result(), 100 * accuracy.result()))
-  with contrib_summary.always_record_summaries():
-    contrib_summary.scalar('loss', avg_loss.result())
-    contrib_summary.scalar('accuracy', accuracy.result())
-
-
-def run_mnist_eager(flags_obj):
-  """Run MNIST training and eval loop in eager mode.
-
-  Args:
-    flags_obj: An object containing parsed flag values.
-  """
-  tf.enable_eager_execution()
-  model_helpers.apply_clean(flags.FLAGS)
-
-  # Automatically determine device and data_format
-  (device, data_format) = ('/gpu:0', 'channels_first')
-  if flags_obj.no_gpu or not tf.test.is_gpu_available():
-    (device, data_format) = ('/cpu:0', 'channels_last')
-  # If data_format is defined in FLAGS, overwrite automatically set value.
-  if flags_obj.data_format is not None:
-    data_format = flags_obj.data_format
-  print('Using device %s, and data format %s.' % (device, data_format))
-
-  # Load the datasets
-  train_ds = mnist_dataset.train(flags_obj.data_dir).shuffle(60000).batch(
-      flags_obj.batch_size)
-  test_ds = mnist_dataset.test(flags_obj.data_dir).batch(
-      flags_obj.batch_size)
-
-  # Create the model and optimizer
-  model = mnist.create_model(data_format)
-  optimizer = tf.train.MomentumOptimizer(flags_obj.lr, flags_obj.momentum)
-
-  # Create file writers for writing TensorBoard summaries.
-  if flags_obj.output_dir:
-    # Create directories to which summaries will be written
-    # tensorboard --logdir=<output_dir>
-    # can then be used to see the recorded summaries.
-    train_dir = os.path.join(flags_obj.output_dir, 'train')
-    test_dir = os.path.join(flags_obj.output_dir, 'eval')
-    tf.gfile.MakeDirs(flags_obj.output_dir)
-  else:
-    train_dir = None
-    test_dir = None
-  summary_writer = tf.compat.v2.summary.create_file_writer(
-      train_dir, flush_millis=10000)
-  test_summary_writer = tf.compat.v2.summary.create_file_writer(
-      test_dir, flush_millis=10000, name='test')
-
-  # Create and restore checkpoint (if one exists on the path)
-  checkpoint_prefix = os.path.join(flags_obj.model_dir, 'ckpt')
-  step_counter = tf.train.get_or_create_global_step()
-  checkpoint = tf.train.Checkpoint(
-      model=model, optimizer=optimizer, step_counter=step_counter)
-  # Restore variables on creation if a checkpoint exists.
-  checkpoint.restore(tf.train.latest_checkpoint(flags_obj.model_dir))
-
-  # Train and evaluate for a set number of epochs.
-  with tf.device(device):
-    for _ in range(flags_obj.train_epochs):
-      start = time.time()
-      with summary_writer.as_default():
-        train(model, optimizer, train_ds, step_counter,
-              flags_obj.log_interval)
-      end = time.time()
-      print('\nTrain time for epoch #%d (%d total steps): %f' %
-            (checkpoint.save_counter.numpy() + 1,
-             step_counter.numpy(),
-             end - start))
-      with test_summary_writer.as_default():
-        test(model, test_ds)
-      checkpoint.save(checkpoint_prefix)
-
-
-def define_mnist_eager_flags():
-  """Defined flags and defaults for MNIST in eager mode."""
-  flags_core.define_base(clean=True, train_epochs=True, export_dir=True,
-                         distribution_strategy=True)
-  flags_core.define_image()
-  flags.adopt_module_key_flags(flags_core)
-
-  flags.DEFINE_integer(
-      name='log_interval', short_name='li', default=10,
-      help=flags_core.help_wrap('batches between logging training status'))
-
-  flags.DEFINE_string(
-      name='output_dir', short_name='od', default=None,
-      help=flags_core.help_wrap('Directory to write TensorBoard summaries'))
-
-  flags.DEFINE_float(name='learning_rate', short_name='lr', default=0.01,
-                     help=flags_core.help_wrap('Learning rate.'))
-
-  flags.DEFINE_float(name='momentum', short_name='m', default=0.5,
-                     help=flags_core.help_wrap('SGD momentum.'))
-
-  flags.DEFINE_bool(name='no_gpu', short_name='nogpu', default=False,
-                    help=flags_core.help_wrap(
-                        'disables GPU usage even if a GPU is available'))
-
-  flags_core.set_defaults(
-      data_dir='/tmp/tensorflow/mnist/input_data',
-      model_dir='/tmp/tensorflow/mnist/checkpoints/',
-      batch_size=100,
-      train_epochs=10,
-  )
-
-
-def main(_):
-  run_mnist_eager(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  define_mnist_eager_flags()
-  absl_app.run(main=main)
diff --git a/official/r1/mnist/mnist_test.py b/official/r1/mnist/mnist_test.py
deleted file mode 100644
index 87e05712..00000000
--- a/official/r1/mnist/mnist_test.py
+++ /dev/null
@@ -1,140 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import time
-
-import tensorflow.compat.v1 as tf  # pylint: disable=g-bad-import-order
-from absl import logging
-from official.r1.mnist import mnist
-
-BATCH_SIZE = 100
-
-
-def dummy_input_fn():
-  image = tf.random.uniform([BATCH_SIZE, 784])
-  labels = tf.random.uniform([BATCH_SIZE, 1], maxval=9, dtype=tf.int32)
-  return image, labels
-
-
-def make_estimator():
-  data_format = 'channels_last'
-  if tf.test.is_built_with_cuda():
-    data_format = 'channels_first'
-  return tf.estimator.Estimator(
-      model_fn=mnist.model_fn, params={
-          'data_format': data_format
-      })
-
-
-class Tests(tf.test.TestCase):
-  """Run tests for MNIST model.
-
-  MNIST uses contrib and will not work with TF 2.0.  All tests are disabled if
-  using TF 2.0.
-  """
-
-  def test_mnist(self):
-    classifier = make_estimator()
-    classifier.train(input_fn=dummy_input_fn, steps=2)
-    eval_results = classifier.evaluate(input_fn=dummy_input_fn, steps=1)
-
-    loss = eval_results['loss']
-    global_step = eval_results['global_step']
-    accuracy = eval_results['accuracy']
-    self.assertEqual(loss.shape, ())
-    self.assertEqual(2, global_step)
-    self.assertEqual(accuracy.shape, ())
-
-    input_fn = lambda: tf.random.uniform([3, 784])
-    predictions_generator = classifier.predict(input_fn)
-    for _ in range(3):
-      predictions = next(predictions_generator)
-      self.assertEqual(predictions['probabilities'].shape, (10,))
-      self.assertEqual(predictions['classes'].shape, ())
-
-  def mnist_model_fn_helper(self, mode, multi_gpu=False):
-    features, labels = dummy_input_fn()
-    image_count = features.shape[0]
-    spec = mnist.model_fn(features, labels, mode, {
-        'data_format': 'channels_last',
-        'multi_gpu': multi_gpu
-    })
-
-    if mode == tf.estimator.ModeKeys.PREDICT:
-      predictions = spec.predictions
-      self.assertAllEqual(predictions['probabilities'].shape, (image_count, 10))
-      self.assertEqual(predictions['probabilities'].dtype, tf.float32)
-      self.assertAllEqual(predictions['classes'].shape, (image_count,))
-      self.assertEqual(predictions['classes'].dtype, tf.int64)
-
-    if mode != tf.estimator.ModeKeys.PREDICT:
-      loss = spec.loss
-      self.assertAllEqual(loss.shape, ())
-      self.assertEqual(loss.dtype, tf.float32)
-
-    if mode == tf.estimator.ModeKeys.EVAL:
-      eval_metric_ops = spec.eval_metric_ops
-      self.assertAllEqual(eval_metric_ops['accuracy'][0].shape, ())
-      self.assertAllEqual(eval_metric_ops['accuracy'][1].shape, ())
-      self.assertEqual(eval_metric_ops['accuracy'][0].dtype, tf.float32)
-      self.assertEqual(eval_metric_ops['accuracy'][1].dtype, tf.float32)
-
-  def test_mnist_model_fn_train_mode(self):
-    self.mnist_model_fn_helper(tf.estimator.ModeKeys.TRAIN)
-
-  def test_mnist_model_fn_train_mode_multi_gpu(self):
-    self.mnist_model_fn_helper(tf.estimator.ModeKeys.TRAIN, multi_gpu=True)
-
-  def test_mnist_model_fn_eval_mode(self):
-    self.mnist_model_fn_helper(tf.estimator.ModeKeys.EVAL)
-
-  def test_mnist_model_fn_predict_mode(self):
-    self.mnist_model_fn_helper(tf.estimator.ModeKeys.PREDICT)
-
-
-class Benchmarks(tf.test.Benchmark):
-  """Simple speed benchmarking for MNIST."""
-
-  def benchmark_train_step_time(self):
-    classifier = make_estimator()
-    # Run one step to warmup any use of the GPU.
-    classifier.train(input_fn=dummy_input_fn, steps=1)
-
-    have_gpu = tf.test.is_gpu_available()
-    num_steps = 1000 if have_gpu else 100
-    name = 'train_step_time_%s' % ('gpu' if have_gpu else 'cpu')
-
-    start = time.time()
-    classifier.train(input_fn=dummy_input_fn, steps=num_steps)
-    end = time.time()
-
-    wall_time = (end - start) / num_steps
-    self.report_benchmark(
-        iters=num_steps,
-        wall_time=wall_time,
-        name=name,
-        extras={
-            'examples_per_sec': BATCH_SIZE / wall_time
-        })
-
-
-if __name__ == '__main__':
-  logging.set_verbosity(logging.ERROR)
-  tf.disable_v2_behavior()
-  tf.test.main()
diff --git a/official/r1/mnist/mnist_tpu.py b/official/r1/mnist/mnist_tpu.py
deleted file mode 100644
index 4ca62ef6..00000000
--- a/official/r1/mnist/mnist_tpu.py
+++ /dev/null
@@ -1,202 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""MNIST model training using TPUs.
-
-This program demonstrates training of the convolutional neural network model
-defined in mnist.py on Google Cloud TPUs (https://cloud.google.com/tpu/).
-
-If you are not interested in TPUs, you should ignore this file.
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import sys
-
-# pylint: disable=g-bad-import-order
-from absl import app as absl_app  # pylint: disable=unused-import
-import tensorflow.compat.v1 as tf
-# pylint: enable=g-bad-import-order
-
-# For open source environment, add grandparent directory for import
-sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(sys.path[0]))))
-
-from official.r1.mnist import dataset  # pylint: disable=wrong-import-position
-from official.r1.mnist import mnist  # pylint: disable=wrong-import-position
-
-# Cloud TPU Cluster Resolver flags
-tf.flags.DEFINE_string(
-    "tpu", default=None,
-    help="The Cloud TPU to use for training. This should be either the name "
-    "used when creating the Cloud TPU, or a grpc://ip.address.of.tpu:8470 "
-    "url.")
-tf.flags.DEFINE_string(
-    "tpu_zone", default=None,
-    help="[Optional] GCE zone where the Cloud TPU is located in. If not "
-    "specified, we will attempt to automatically detect the GCE project from "
-    "metadata.")
-tf.flags.DEFINE_string(
-    "gcp_project", default=None,
-    help="[Optional] Project name for the Cloud TPU-enabled project. If not "
-    "specified, we will attempt to automatically detect the GCE project from "
-    "metadata.")
-
-# Model specific parameters
-tf.flags.DEFINE_string("data_dir", "",
-                       "Path to directory containing the MNIST dataset")
-tf.flags.DEFINE_string("model_dir", None, "Estimator model_dir")
-tf.flags.DEFINE_integer("batch_size", 1024,
-                        "Mini-batch size for the training. Note that this "
-                        "is the global batch size and not the per-shard batch.")
-tf.flags.DEFINE_integer("train_steps", 1000, "Total number of training steps.")
-tf.flags.DEFINE_integer("eval_steps", 0,
-                        "Total number of evaluation steps. If `0`, evaluation "
-                        "after training is skipped.")
-tf.flags.DEFINE_float("learning_rate", 0.05, "Learning rate.")
-
-tf.flags.DEFINE_bool("use_tpu", True, "Use TPUs rather than plain CPUs")
-tf.flags.DEFINE_bool("enable_predict", True, "Do some predictions at the end")
-tf.flags.DEFINE_integer("iterations", 50,
-                        "Number of iterations per TPU training loop.")
-tf.flags.DEFINE_integer("num_shards", 8, "Number of shards (TPU chips).")
-
-FLAGS = tf.flags.FLAGS
-
-
-def metric_fn(labels, logits):
-  accuracy = tf.metrics.accuracy(
-      labels=labels, predictions=tf.argmax(logits, axis=1))
-  return {"accuracy": accuracy}
-
-
-def model_fn(features, labels, mode, params):
-  """model_fn constructs the ML model used to predict handwritten digits."""
-
-  del params
-  image = features
-  if isinstance(image, dict):
-    image = features["image"]
-
-  model = mnist.create_model("channels_last")
-
-  if mode == tf.estimator.ModeKeys.PREDICT:
-    logits = model(image, training=False)
-    predictions = {
-        'class_ids': tf.argmax(logits, axis=1),
-        'probabilities': tf.nn.softmax(logits),
-    }
-    return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=predictions)
-
-  logits = model(image, training=(mode == tf.estimator.ModeKeys.TRAIN))
-  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)
-
-  if mode == tf.estimator.ModeKeys.TRAIN:
-    learning_rate = tf.train.exponential_decay(
-        FLAGS.learning_rate,
-        tf.train.get_global_step(),
-        decay_steps=100000,
-        decay_rate=0.96)
-    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
-    if FLAGS.use_tpu:
-      optimizer = tf.tpu.CrossShardOptimizer(optimizer)
-    return tf.estimator.tpu.TPUEstimatorSpec(
-        mode=mode,
-        loss=loss,
-        train_op=optimizer.minimize(loss, tf.train.get_global_step()))
-
-  if mode == tf.estimator.ModeKeys.EVAL:
-    return tf.estimator.tpu.TPUEstimatorSpec(
-        mode=mode, loss=loss, eval_metrics=(metric_fn, [labels, logits]))
-
-
-def train_input_fn(params):
-  """train_input_fn defines the input pipeline used for training."""
-  batch_size = params["batch_size"]
-  data_dir = params["data_dir"]
-  # Retrieves the batch size for the current shard. The # of shards is
-  # computed according to the input pipeline deployment. See
-  # `tf.estimator.tpu.RunConfig` for details.
-  ds = dataset.train(data_dir).cache().repeat().shuffle(
-      buffer_size=50000).batch(batch_size, drop_remainder=True)
-  return ds
-
-
-def eval_input_fn(params):
-  batch_size = params["batch_size"]
-  data_dir = params["data_dir"]
-  ds = dataset.test(data_dir).batch(batch_size, drop_remainder=True)
-  return ds
-
-
-def predict_input_fn(params):
-  batch_size = params["batch_size"]
-  data_dir = params["data_dir"]
-  # Take out top 10 samples from test data to make the predictions.
-  ds = dataset.test(data_dir).take(10).batch(batch_size)
-  return ds
-
-
-def main(argv):
-  del argv  # Unused.
-  tf.logging.set_verbosity(tf.logging.INFO)
-
-  tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
-      FLAGS.tpu,
-      zone=FLAGS.tpu_zone,
-      project=FLAGS.gcp_project
-  )
-
-  run_config = tf.estimator.tpu.RunConfig(
-      cluster=tpu_cluster_resolver,
-      model_dir=FLAGS.model_dir,
-      session_config=tf.ConfigProto(
-          allow_soft_placement=True, log_device_placement=True),
-      tpu_config=tf.estimator.tpu.TPUConfig(FLAGS.iterations, FLAGS.num_shards),
-  )
-
-  estimator = tf.estimator.tpu.TPUEstimator(
-      model_fn=model_fn,
-      use_tpu=FLAGS.use_tpu,
-      train_batch_size=FLAGS.batch_size,
-      eval_batch_size=FLAGS.batch_size,
-      predict_batch_size=FLAGS.batch_size,
-      params={"data_dir": FLAGS.data_dir},
-      config=run_config)
-  # TPUEstimator.train *requires* a max_steps argument.
-  estimator.train(input_fn=train_input_fn, max_steps=FLAGS.train_steps)
-  # TPUEstimator.evaluate *requires* a steps argument.
-  # Note that the number of examples used during evaluation is
-  # --eval_steps * --batch_size.
-  # So if you change --batch_size then change --eval_steps too.
-  if FLAGS.eval_steps:
-    estimator.evaluate(input_fn=eval_input_fn, steps=FLAGS.eval_steps)
-
-  # Run prediction on top few samples of test data.
-  if FLAGS.enable_predict:
-    predictions = estimator.predict(input_fn=predict_input_fn)
-
-    for pred_dict in predictions:
-      template = ('Prediction is "{}" ({:.1f}%).')
-
-      class_id = pred_dict['class_ids']
-      probability = pred_dict['probabilities'][class_id]
-
-      print(template.format(class_id, 100 * probability))
-
-
-if __name__ == "__main__":
-  tf.disable_v2_behavior()
-  absl_app.run(main)
diff --git a/official/r1/ncf/README.md b/official/r1/ncf/README.md
deleted file mode 100644
index 8156d396..00000000
--- a/official/r1/ncf/README.md
+++ /dev/null
@@ -1,7 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# NCF Estimator implementation
-
-NCF framework to train and evaluate the NeuMF model
diff --git a/official/r1/ncf/ncf_estimator_main.py b/official/r1/ncf/ncf_estimator_main.py
deleted file mode 100644
index a40e7b77..00000000
--- a/official/r1/ncf/ncf_estimator_main.py
+++ /dev/null
@@ -1,187 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""NCF framework to train and evaluate the NeuMF model.
-
-The NeuMF model assembles both MF and MLP models under the NCF framework. Check
-`neumf_model.py` for more details about the models.
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import contextlib
-import heapq
-import json
-import math
-import multiprocessing
-import os
-import signal
-
-from absl import app as absl_app
-from absl import flags
-from absl import logging
-import numpy as np
-from six.moves import range
-import tensorflow as tf
-import typing
-
-from official.r1.utils.logs import hooks_helper
-from official.r1.utils.logs import logger
-from official.r1.utils.logs import mlperf_helper
-from official.recommendation import constants as rconst
-from official.recommendation import data_pipeline
-from official.recommendation import data_preprocessing
-from official.recommendation import movielens
-from official.recommendation import ncf_common
-from official.recommendation import neumf_model
-from official.utils.flags import core as flags_core
-from official.utils.misc import distribution_utils
-from official.utils.misc import model_helpers
-
-
-FLAGS = flags.FLAGS
-
-
-def construct_estimator(model_dir, params):
-  """Construct either an Estimator for NCF.
-
-  Args:
-    model_dir: The model directory for the estimator
-    params: The params dict for the estimator
-
-  Returns:
-    An Estimator.
-  """
-  distribution = ncf_common.get_v1_distribution_strategy(params)
-  run_config = tf.estimator.RunConfig(train_distribute=distribution,
-                                      eval_distribute=distribution)
-  model_fn = neumf_model.neumf_model_fn
-  estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir,
-                                     config=run_config, params=params)
-  return estimator
-
-
-def log_and_get_hooks(eval_batch_size):
-  """Convenience function for hook and logger creation."""
-  # Create hooks that log information about the training and metric values
-  train_hooks = hooks_helper.get_train_hooks(
-      FLAGS.hooks,
-      model_dir=FLAGS.model_dir,
-      batch_size=FLAGS.batch_size,  # for ExamplesPerSecondHook
-      tensors_to_log={"cross_entropy": "cross_entropy"}
-  )
-  run_params = {
-      "batch_size": FLAGS.batch_size,
-      "eval_batch_size": eval_batch_size,
-      "number_factors": FLAGS.num_factors,
-      "hr_threshold": FLAGS.hr_threshold,
-      "train_epochs": FLAGS.train_epochs,
-  }
-  benchmark_logger = logger.get_benchmark_logger()
-  benchmark_logger.log_run_info(
-      model_name="recommendation",
-      dataset_name=FLAGS.dataset,
-      run_params=run_params,
-      test_id=FLAGS.benchmark_test_id)
-
-  return benchmark_logger, train_hooks
-
-
-def main(_):
-  with logger.benchmark_context(FLAGS), \
-       mlperf_helper.LOGGER(FLAGS.output_ml_perf_compliance_logging):
-    mlperf_helper.set_ncf_root(os.path.split(os.path.abspath(__file__))[0])
-    run_ncf(FLAGS)
-
-
-def run_ncf(_):
-  """Run NCF training and eval loop."""
-  params = ncf_common.parse_flags(FLAGS)
-
-  num_users, num_items, num_train_steps, num_eval_steps, producer = (
-      ncf_common.get_inputs(params))
-
-  params["num_users"], params["num_items"] = num_users, num_items
-  producer.start()
-  model_helpers.apply_clean(flags.FLAGS)
-
-  estimator = construct_estimator(model_dir=FLAGS.model_dir, params=params)
-
-  benchmark_logger, train_hooks = log_and_get_hooks(params["eval_batch_size"])
-  total_training_cycle = FLAGS.train_epochs // FLAGS.epochs_between_evals
-
-  target_reached = False
-  mlperf_helper.ncf_print(key=mlperf_helper.TAGS.TRAIN_LOOP)
-  for cycle_index in range(total_training_cycle):
-    assert FLAGS.epochs_between_evals == 1 or not mlperf_helper.LOGGER.enabled
-    logging.info("Starting a training cycle: {}/{}".format(
-        cycle_index + 1, total_training_cycle))
-
-    mlperf_helper.ncf_print(key=mlperf_helper.TAGS.TRAIN_EPOCH,
-                            value=cycle_index)
-
-    train_input_fn = producer.make_input_fn(is_training=True)
-    estimator.train(input_fn=train_input_fn, hooks=train_hooks,
-                    steps=num_train_steps)
-
-    logging.info("Beginning evaluation.")
-    eval_input_fn = producer.make_input_fn(is_training=False)
-
-    mlperf_helper.ncf_print(key=mlperf_helper.TAGS.EVAL_START,
-                            value=cycle_index)
-    eval_results = estimator.evaluate(eval_input_fn, steps=num_eval_steps)
-    logging.info("Evaluation complete.")
-
-    hr = float(eval_results[rconst.HR_KEY])
-    ndcg = float(eval_results[rconst.NDCG_KEY])
-    loss = float(eval_results["loss"])
-
-    mlperf_helper.ncf_print(
-        key=mlperf_helper.TAGS.EVAL_TARGET,
-        value={"epoch": cycle_index, "value": FLAGS.hr_threshold})
-    mlperf_helper.ncf_print(key=mlperf_helper.TAGS.EVAL_ACCURACY,
-                            value={"epoch": cycle_index, "value": hr})
-    mlperf_helper.ncf_print(
-        key=mlperf_helper.TAGS.EVAL_HP_NUM_NEG,
-        value={"epoch": cycle_index, "value": rconst.NUM_EVAL_NEGATIVES})
-
-    mlperf_helper.ncf_print(key=mlperf_helper.TAGS.EVAL_STOP, value=cycle_index)
-
-    # Benchmark the evaluation results
-    benchmark_logger.log_evaluation_result(eval_results)
-    # Log the HR and NDCG results.
-    logging.info(
-        "Iteration {}: HR = {:.4f}, NDCG = {:.4f}, Loss = {:.4f}".format(
-            cycle_index + 1, hr, ndcg, loss))
-
-    # If some evaluation threshold is met
-    if model_helpers.past_stop_threshold(FLAGS.hr_threshold, hr):
-      target_reached = True
-      break
-
-  mlperf_helper.ncf_print(key=mlperf_helper.TAGS.RUN_STOP,
-                          value={"success": target_reached})
-  producer.stop_loop()
-  producer.join()
-
-  # Clear the session explicitly to avoid session delete error
-  tf.keras.backend.clear_session()
-  mlperf_helper.ncf_print(key=mlperf_helper.TAGS.RUN_FINAL)
-
-
-if __name__ == "__main__":
-  logging.set_verbosity(logging.INFO)
-  ncf_common.define_ncf_flags()
-  absl_app.run(main)
diff --git a/official/r1/resnet/README.md b/official/r1/resnet/README.md
deleted file mode 100644
index 7f70b501..00000000
--- a/official/r1/resnet/README.md
+++ /dev/null
@@ -1,156 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# ResNet in TensorFlow
-
-Deep residual networks, or ResNets for short, provided the breakthrough idea of
-identity mappings in order to enable training of very deep convolutional neural
-networks. This folder contains an implementation of ResNet for the ImageNet
-dataset written in TensorFlow.
-
-See the following papers for more background:
-
-[1] [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-[2] [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
-
-In code, v1 refers to the ResNet defined in [1] but where a stride 2 is used on
-the 3x3 conv rather than the first 1x1 in the bottleneck. This change results
-in higher and more stable accuracy with less epochs than the original v1 and has
-shown to scale to higher batch sizes with minimal degradation in accuracy.
-There is no originating paper. The first mention we are aware of was in the
-torch version of [ResNetv1](https://github.com/facebook/fb.resnet.torch). Most
-popular v1 implementations are this implementation which we call ResNetv1.5.
-
-In testing we found v1.5 requires ~12% more compute to train and has 6% reduced
-throughput for inference compared to ResNetv1. CIFAR-10 ResNet does not use the
-bottleneck and is thus the same for v1 as v1.5.
-
-v2 refers to [2]. The principle difference between the two versions is that v1
-applies batch normalization and activation after convolution, while v2 applies
-batch normalization, then activation, and finally convolution. A schematic
-comparison is presented in Figure 1 (left) of [2].
-
-Please proceed according to which dataset you would like to train/evaluate on:
-
-
-## CIFAR-10
-
-### Setup
-
-You need to have the latest version of TensorFlow installed.
-First, make sure [the models folder is in your Python path](/official/#running-the-models); otherwise you may encounter `ImportError: No module named official.resnet`.
-
-Then, download and extract the CIFAR-10 data from Alex's website, specifying the location with the `--data_dir` flag. Run the following:
-
-```bash
-python cifar10_download_and_extract.py --data_dir <DATA_DIR>
-```
-
-Then, to train the model:
-
-```bash
-python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR>
-```
-
-Use `--data_dir` to specify the location of the CIFAR-10 data used in the previous step. There are more flag options as described in `cifar10_main.py`.
-
-To export a `SavedModel` from the trained checkpoint:
-
-```bash
-python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR> --eval_only --export_dir <EXPORT_DIR>
-```
-
-Note: The `<EXPORT_DIR>` must be present. You might want to run `mkdir <EXPORT_DIR>` beforehand.
-
-The `SavedModel` can then be [loaded](https://www.tensorflow.org/guide/saved_model#loading_a_savedmodel_in_python) in order to use the ResNet for prediction.
-
-
-## ImageNet
-
-### Setup
-To begin, you will need to download the ImageNet dataset and convert it to
-TFRecord format. The following [script](https://github.com/tensorflow/tpu/blob/master/tools/datasets/imagenet_to_gcs.py)
-and [README](https://github.com/tensorflow/tpu/tree/master/tools/datasets#imagenet_to_gcspy)
-provide a few options.
-
-Once your dataset is ready, you can begin training the model as follows:
-
-```bash
-python imagenet_main.py --data_dir=/path/to/imagenet
-```
-
-The model will begin training and will automatically evaluate itself on the
-validation data roughly once per epoch.
-
-Note that there are a number of other options you can specify, including
-`--model_dir` to choose where to store the model and `--resnet_size` to choose
-the model size (options include ResNet-18 through ResNet-200). See
-[`resnet_run_loop.py`](resnet_run_loop.py) for the full list of options.
-
-
-## Compute Devices
-Training is accomplished using the DistributionStrategies API. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/README.md)
-
-The appropriate distribution strategy is chosen based on the `--num_gpus` flag.
-By default this flag is one if TensorFlow is compiled with CUDA, and zero
-otherwise.
-
-num_gpus:
-+ 0:  Use OneDeviceStrategy and train on CPU.
-+ 1:  Use OneDeviceStrategy and train on GPU.
-+ 2+: Use MirroredStrategy (data parallelism) to distribute a batch between devices.
-
-### Pre-trained model
-You can download pre-trained versions of ResNet-50. Reported accuracies are top-1 single-crop accuracy for the ImageNet validation set.
-Models are reported as both checkpoints produced by Estimator during training, and as SavedModels which are more portable. Checkpoints are fragile,
-and these are not guaranteed to work with future versions of the code. Both ResNet v1
-and ResNet v2 have been trained in both fp16 and fp32 precision. (Here v1 refers to "v1.5". See the note above.) Furthermore, SavedModels
-are generated to accept either tensor or JPG inputs, and with channels_first (NCHW) and channels_last (NHWC) convolutions. NCHW is generally
-better for GPUs, while NHWC is generally better for CPUs. See the TensorFlow [performance guide](https://www.tensorflow.org/performance/performance_guide#data_formats)
-for more details.
-
-ResNet-50 v2 (fp32, Accuracy 76.47%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp32_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v2 (fp16, Accuracy 76.56%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp16_20180928.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v1 (fp32, Accuracy 76.53%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp32_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v1 (fp16, Accuracy 76.18%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp16_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC_jpg.tar.gz)
-
-### Transfer Learning
-You can use a pretrained model to initialize a training process. In addition you are able to freeze all but the final fully connected layers to fine tune your model. Transfer Learning is useful when training on your own small datasets. For a brief look at transfer learning in the context of convolutional neural networks, we recommend reading these [short notes](http://cs231n.github.io/transfer-learning/).
-
-
-To fine tune a pretrained resnet you must make three changes to your training procedure:
-
-1) Build the exact same model as previously except we change the number of labels in the final classification layer.
-
-2) Restore all weights from the pre-trained resnet except for the final classification layer; this will get randomly initialized instead.
-
-3) Freeze earlier layers of the network
-
-We can perform these three operations by specifying two flags: ```--pretrained_model_checkpoint_path``` and ```--fine_tune```. The first flag is a string that points to the path of a pre-trained resnet model. If this flag is specified, it will load all but the final classification layer. A key thing to note: if both ```--pretrained_model_checkpoint_path``` and a non empty ```model_dir``` directory are passed, the tensorflow estimator will load only the ```model_dir```. For more on this please see [WarmStartSettings](https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/WarmStartSettings) and [Estimators](https://www.tensorflow.org/guide/estimators).
-
-The second flag ```--fine_tune``` is a boolean that indicates whether earlier layers of the network should be frozen. You may set this flag to false if you wish to continue training a pre-trained model from a checkpoint. If you set this flag to true, you can train a new classification layer from scratch.
diff --git a/official/r1/resnet/__init__.py b/official/r1/resnet/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/resnet/cifar10_download_and_extract.py b/official/r1/resnet/cifar10_download_and_extract.py
deleted file mode 100644
index a44d042e..00000000
--- a/official/r1/resnet/cifar10_download_and_extract.py
+++ /dev/null
@@ -1,63 +0,0 @@
-# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Downloads and extracts the binary version of the CIFAR-10 dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import argparse
-import os
-import sys
-import tarfile
-
-from six.moves import urllib
-import tensorflow as tf
-
-DATA_URL = 'https://www.cs.toronto.edu/~kriz/cifar-10-binary.tar.gz'
-
-parser = argparse.ArgumentParser()
-
-parser.add_argument(
-    '--data_dir', type=str, default='/tmp/cifar10_data',
-    help='Directory to download data and extract the tarball')
-
-
-def main(_):
-  """Download and extract the tarball from Alex's website."""
-  if not os.path.exists(FLAGS.data_dir):
-    os.makedirs(FLAGS.data_dir)
-
-  filename = DATA_URL.split('/')[-1]
-  filepath = os.path.join(FLAGS.data_dir, filename)
-
-  if not os.path.exists(filepath):
-    def _progress(count, block_size, total_size):
-      sys.stdout.write('\r>> Downloading %s %.1f%%' % (
-          filename, 100.0 * count * block_size / total_size))
-      sys.stdout.flush()
-
-    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
-    print()
-    statinfo = os.stat(filepath)
-    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')
-
-  tarfile.open(filepath, 'r:gz').extractall(FLAGS.data_dir)
-
-
-if __name__ == '__main__':
-  FLAGS, unparsed = parser.parse_known_args()
-  tf.compat.v1.app.run(argv=[sys.argv[0]] + unparsed)
diff --git a/official/r1/resnet/cifar10_main.py b/official/r1/resnet/cifar10_main.py
deleted file mode 100644
index e0983d82..00000000
--- a/official/r1/resnet/cifar10_main.py
+++ /dev/null
@@ -1,297 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Runs a ResNet model on the CIFAR-10 dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-from absl import app as absl_app
-from absl import flags
-from absl import logging
-from six.moves import range
-import tensorflow as tf
-
-from official.r1.resnet import resnet_model
-from official.r1.resnet import resnet_run_loop
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-
-HEIGHT = 32
-WIDTH = 32
-NUM_CHANNELS = 3
-_DEFAULT_IMAGE_BYTES = HEIGHT * WIDTH * NUM_CHANNELS
-# The record is the image plus a one-byte label
-_RECORD_BYTES = _DEFAULT_IMAGE_BYTES + 1
-NUM_CLASSES = 10
-_NUM_DATA_FILES = 5
-
-# TODO(tobyboyd): Change to best practice 45K(train)/5K(val)/10K(test) splits.
-NUM_IMAGES = {
-    'train': 50000,
-    'validation': 10000,
-}
-
-DATASET_NAME = 'CIFAR-10'
-
-
-###############################################################################
-# Data processing
-###############################################################################
-def get_filenames(is_training, data_dir):
-  """Returns a list of filenames."""
-  assert tf.io.gfile.exists(data_dir), (
-      'Run cifar10_download_and_extract.py first to download and extract the '
-      'CIFAR-10 data.')
-
-  if is_training:
-    return [
-        os.path.join(data_dir, 'data_batch_%d.bin' % i)
-        for i in range(1, _NUM_DATA_FILES + 1)
-    ]
-  else:
-    return [os.path.join(data_dir, 'test_batch.bin')]
-
-
-def parse_record(raw_record, is_training, dtype):
-  """Parse CIFAR-10 image and label from a raw record."""
-  # Convert bytes to a vector of uint8 that is record_bytes long.
-  record_vector = tf.io.decode_raw(raw_record, tf.uint8)
-
-  # The first byte represents the label, which we convert from uint8 to int32
-  # and then to one-hot.
-  label = tf.cast(record_vector[0], tf.int32)
-
-  # The remaining bytes after the label represent the image, which we reshape
-  # from [depth * height * width] to [depth, height, width].
-  depth_major = tf.reshape(record_vector[1:_RECORD_BYTES],
-                           [NUM_CHANNELS, HEIGHT, WIDTH])
-
-  # Convert from [depth, height, width] to [height, width, depth], and cast as
-  # float32.
-  image = tf.cast(tf.transpose(a=depth_major, perm=[1, 2, 0]), tf.float32)
-
-  image = preprocess_image(image, is_training)
-  image = tf.cast(image, dtype)
-
-  return image, label
-
-
-def preprocess_image(image, is_training):
-  """Preprocess a single image of layout [height, width, depth]."""
-  if is_training:
-    # Resize the image to add four extra pixels on each side.
-    image = tf.image.resize_with_crop_or_pad(
-        image, HEIGHT + 8, WIDTH + 8)
-
-    # Randomly crop a [HEIGHT, WIDTH] section of the image.
-    image = tf.image.random_crop(image, [HEIGHT, WIDTH, NUM_CHANNELS])
-
-    # Randomly flip the image horizontally.
-    image = tf.image.random_flip_left_right(image)
-
-  # Subtract off the mean and divide by the variance of the pixels.
-  image = tf.image.per_image_standardization(image)
-  return image
-
-
-def input_fn(is_training,
-             data_dir,
-             batch_size,
-             num_epochs=1,
-             dtype=tf.float32,
-             datasets_num_private_threads=None,
-             parse_record_fn=parse_record,
-             input_context=None,
-             drop_remainder=False):
-  """Input function which provides batches for train or eval.
-
-  Args:
-    is_training: A boolean denoting whether the input is for training.
-    data_dir: The directory containing the input data.
-    batch_size: The number of samples per batch.
-    num_epochs: The number of epochs to repeat the dataset.
-    dtype: Data type to use for images/features
-    datasets_num_private_threads: Number of private threads for tf.data.
-    parse_record_fn: Function to use for parsing the records.
-    input_context: A `tf.distribute.InputContext` object passed in by
-      `tf.distribute.Strategy`.
-    drop_remainder: A boolean indicates whether to drop the remainder of the
-      batches. If True, the batch dimension will be static.
-
-  Returns:
-    A dataset that can be used for iteration.
-  """
-  filenames = get_filenames(is_training, data_dir)
-  dataset = tf.data.FixedLengthRecordDataset(filenames, _RECORD_BYTES)
-
-  if input_context:
-    logging.info(
-        'Sharding the dataset: input_pipeline_id=%d num_input_pipelines=%d',
-        input_context.input_pipeline_id, input_context.num_input_pipelines)
-    dataset = dataset.shard(input_context.num_input_pipelines,
-                            input_context.input_pipeline_id)
-
-  return resnet_run_loop.process_record_dataset(
-      dataset=dataset,
-      is_training=is_training,
-      batch_size=batch_size,
-      shuffle_buffer=NUM_IMAGES['train'],
-      parse_record_fn=parse_record_fn,
-      num_epochs=num_epochs,
-      dtype=dtype,
-      datasets_num_private_threads=datasets_num_private_threads,
-      drop_remainder=drop_remainder
-  )
-
-
-def get_synth_input_fn(dtype):
-  return resnet_run_loop.get_synth_input_fn(
-      HEIGHT, WIDTH, NUM_CHANNELS, NUM_CLASSES, dtype=dtype)
-
-
-###############################################################################
-# Running the model
-###############################################################################
-class Cifar10Model(resnet_model.Model):
-  """Model class with appropriate defaults for CIFAR-10 data."""
-
-  def __init__(self, resnet_size, data_format=None, num_classes=NUM_CLASSES,
-               resnet_version=resnet_model.DEFAULT_VERSION,
-               dtype=resnet_model.DEFAULT_DTYPE):
-    """These are the parameters that work for CIFAR-10 data.
-
-    Args:
-      resnet_size: The number of convolutional layers needed in the model.
-      data_format: Either 'channels_first' or 'channels_last', specifying which
-        data format to use when setting up the model.
-      num_classes: The number of output classes needed from the model. This
-        enables users to extend the same model to their own datasets.
-      resnet_version: Integer representing which version of the ResNet network
-      to use. See README for details. Valid values: [1, 2]
-      dtype: The TensorFlow dtype to use for calculations.
-
-    Raises:
-      ValueError: if invalid resnet_size is chosen
-    """
-    if resnet_size % 6 != 2:
-      raise ValueError('resnet_size must be 6n + 2:', resnet_size)
-
-    num_blocks = (resnet_size - 2) // 6
-
-    super(Cifar10Model, self).__init__(
-        resnet_size=resnet_size,
-        bottleneck=False,
-        num_classes=num_classes,
-        num_filters=16,
-        kernel_size=3,
-        conv_stride=1,
-        first_pool_size=None,
-        first_pool_stride=None,
-        block_sizes=[num_blocks] * 3,
-        block_strides=[1, 2, 2],
-        resnet_version=resnet_version,
-        data_format=data_format,
-        dtype=dtype
-    )
-
-
-def cifar10_model_fn(features, labels, mode, params):
-  """Model function for CIFAR-10."""
-  features = tf.reshape(features, [-1, HEIGHT, WIDTH, NUM_CHANNELS])
-  # Learning rate schedule follows arXiv:1512.03385 for ResNet-56 and under.
-  learning_rate_fn = resnet_run_loop.learning_rate_with_decay(
-      batch_size=params['batch_size'] * params.get('num_workers', 1),
-      batch_denom=128, num_images=NUM_IMAGES['train'],
-      boundary_epochs=[91, 136, 182], decay_rates=[1, 0.1, 0.01, 0.001])
-
-  # Weight decay of 2e-4 diverges from 1e-4 decay used in the ResNet paper
-  # and seems more stable in testing. The difference was nominal for ResNet-56.
-  weight_decay = 2e-4
-
-  # Empirical testing showed that including batch_normalization variables
-  # in the calculation of regularized loss helped validation accuracy
-  # for the CIFAR-10 dataset, perhaps because the regularization prevents
-  # overfitting on the small data set. We therefore include all vars when
-  # regularizing and computing loss during training.
-  def loss_filter_fn(_):
-    return True
-
-  return resnet_run_loop.resnet_model_fn(
-      features=features,
-      labels=labels,
-      mode=mode,
-      model_class=Cifar10Model,
-      resnet_size=params['resnet_size'],
-      weight_decay=weight_decay,
-      learning_rate_fn=learning_rate_fn,
-      momentum=0.9,
-      data_format=params['data_format'],
-      resnet_version=params['resnet_version'],
-      loss_scale=params['loss_scale'],
-      loss_filter_fn=loss_filter_fn,
-      dtype=params['dtype'],
-      fine_tune=params['fine_tune']
-  )
-
-
-def define_cifar_flags():
-  resnet_run_loop.define_resnet_flags()
-  flags.adopt_module_key_flags(resnet_run_loop)
-  flags_core.set_defaults(data_dir='/tmp/cifar10_data/cifar-10-batches-bin',
-                          model_dir='/tmp/cifar10_model',
-                          resnet_size='56',
-                          train_epochs=182,
-                          epochs_between_evals=10,
-                          batch_size=128,
-                          image_bytes_as_serving_input=False)
-
-
-def run_cifar(flags_obj):
-  """Run ResNet CIFAR-10 training and eval loop.
-
-  Args:
-    flags_obj: An object containing parsed flag values.
-
-  Returns:
-    Dictionary of results. Including final accuracy.
-  """
-  if flags_obj.image_bytes_as_serving_input:
-    logging.fatal(
-        '--image_bytes_as_serving_input cannot be set to True for CIFAR. '
-        'This flag is only applicable to ImageNet.')
-    return
-
-  input_function = (flags_obj.use_synthetic_data and
-                    get_synth_input_fn(flags_core.get_tf_dtype(flags_obj)) or
-                    input_fn)
-  result = resnet_run_loop.resnet_main(
-      flags_obj, cifar10_model_fn, input_function, DATASET_NAME,
-      shape=[HEIGHT, WIDTH, NUM_CHANNELS])
-
-  return result
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    run_cifar(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  logging.set_verbosity(logging.INFO)
-  define_cifar_flags()
-  absl_app.run(main)
diff --git a/official/r1/resnet/cifar10_test.py b/official/r1/resnet/cifar10_test.py
deleted file mode 100644
index ba40eb2c..00000000
--- a/official/r1/resnet/cifar10_test.py
+++ /dev/null
@@ -1,183 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-from tempfile import mkstemp
-
-from absl import logging
-import numpy as np
-import tensorflow as tf
-
-from official.r1.resnet import cifar10_main
-from official.utils.testing import integration
-
-logging.set_verbosity(logging.ERROR)
-
-_BATCH_SIZE = 128
-_HEIGHT = 32
-_WIDTH = 32
-_NUM_CHANNELS = 3
-
-
-class BaseTest(tf.test.TestCase):
-  """Tests for the Cifar10 version of Resnet.
-  """
-
-  _num_validation_images = None
-
-  @classmethod
-  def setUpClass(cls):  # pylint: disable=invalid-name
-    super(BaseTest, cls).setUpClass()
-    tf.compat.v1.disable_eager_execution()
-    cifar10_main.define_cifar_flags()
-
-  def setUp(self):
-    super(BaseTest, self).setUp()
-    self._num_validation_images = cifar10_main.NUM_IMAGES['validation']
-    cifar10_main.NUM_IMAGES['validation'] = 4
-
-  def tearDown(self):
-    super(BaseTest, self).tearDown()
-    tf.io.gfile.rmtree(self.get_temp_dir())
-    cifar10_main.NUM_IMAGES['validation'] = self._num_validation_images
-
-  def test_dataset_input_fn(self):
-    fake_data = bytearray()
-    fake_data.append(7)
-    for i in range(_NUM_CHANNELS):
-      for _ in range(_HEIGHT * _WIDTH):
-        fake_data.append(i)
-
-    _, filename = mkstemp(dir=self.get_temp_dir())
-    data_file = open(filename, 'wb')
-    data_file.write(fake_data)
-    data_file.close()
-
-    fake_dataset = tf.data.FixedLengthRecordDataset(
-        filename, cifar10_main._RECORD_BYTES)  # pylint: disable=protected-access
-    fake_dataset = fake_dataset.map(
-        lambda val: cifar10_main.parse_record(val, False, tf.float32))
-    image, label = tf.compat.v1.data.make_one_shot_iterator(
-        fake_dataset).get_next()
-
-    self.assertAllEqual(label.shape, ())
-    self.assertAllEqual(image.shape, (_HEIGHT, _WIDTH, _NUM_CHANNELS))
-
-    with self.session() as sess:
-      image, label = sess.run([image, label])
-
-      self.assertEqual(label, 7)
-
-      for row in image:
-        for pixel in row:
-          self.assertAllClose(pixel, np.array([-1.225, 0., 1.225]), rtol=1e-3)
-
-  def cifar10_model_fn_helper(self, mode, resnet_version, dtype):
-    input_fn = cifar10_main.get_synth_input_fn(dtype)
-    dataset = input_fn(True, '', _BATCH_SIZE)
-    iterator = tf.compat.v1.data.make_initializable_iterator(dataset)
-    features, labels = iterator.get_next()
-    spec = cifar10_main.cifar10_model_fn(
-        features, labels, mode, {
-            'dtype': dtype,
-            'resnet_size': 32,
-            'data_format': 'channels_last',
-            'batch_size': _BATCH_SIZE,
-            'resnet_version': resnet_version,
-            'loss_scale': 128 if dtype == tf.float16 else 1,
-            'fine_tune': False,
-        })
-
-    predictions = spec.predictions
-    self.assertAllEqual(predictions['probabilities'].shape,
-                        (_BATCH_SIZE, 10))
-    self.assertEqual(predictions['probabilities'].dtype, tf.float32)
-    self.assertAllEqual(predictions['classes'].shape, (_BATCH_SIZE,))
-    self.assertEqual(predictions['classes'].dtype, tf.int64)
-
-    if mode != tf.estimator.ModeKeys.PREDICT:
-      loss = spec.loss
-      self.assertAllEqual(loss.shape, ())
-      self.assertEqual(loss.dtype, tf.float32)
-
-    if mode == tf.estimator.ModeKeys.EVAL:
-      eval_metric_ops = spec.eval_metric_ops
-      self.assertAllEqual(eval_metric_ops['accuracy'][0].shape, ())
-      self.assertAllEqual(eval_metric_ops['accuracy'][1].shape, ())
-      self.assertEqual(eval_metric_ops['accuracy'][0].dtype, tf.float32)
-      self.assertEqual(eval_metric_ops['accuracy'][1].dtype, tf.float32)
-
-  def test_cifar10_model_fn_train_mode_v1(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.TRAIN, resnet_version=1,
-                                 dtype=tf.float32)
-
-  def test_cifar10_model_fn_trainmode__v2(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.TRAIN, resnet_version=2,
-                                 dtype=tf.float32)
-
-  def test_cifar10_model_fn_eval_mode_v1(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.EVAL, resnet_version=1,
-                                 dtype=tf.float32)
-
-  def test_cifar10_model_fn_eval_mode_v2(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.EVAL, resnet_version=2,
-                                 dtype=tf.float32)
-
-  def test_cifar10_model_fn_predict_mode_v1(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.PREDICT,
-                                 resnet_version=1, dtype=tf.float32)
-
-  def test_cifar10_model_fn_predict_mode_v2(self):
-    self.cifar10_model_fn_helper(tf.estimator.ModeKeys.PREDICT,
-                                 resnet_version=2, dtype=tf.float32)
-
-  def _test_cifar10model_shape(self, resnet_version):
-    batch_size = 135
-    num_classes = 246
-
-    model = cifar10_main.Cifar10Model(32, data_format='channels_last',
-                                      num_classes=num_classes,
-                                      resnet_version=resnet_version)
-    fake_input = tf.random.uniform([batch_size, _HEIGHT, _WIDTH, _NUM_CHANNELS])
-    output = model(fake_input, training=True)
-
-    self.assertAllEqual(output.shape, (batch_size, num_classes))
-
-  def test_cifar10model_shape_v1(self):
-    self._test_cifar10model_shape(resnet_version=1)
-
-  def test_cifar10model_shape_v2(self):
-    self._test_cifar10model_shape(resnet_version=2)
-
-  def test_cifar10_end_to_end_synthetic_v1(self):
-    integration.run_synthetic(
-        main=cifar10_main.run_cifar, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '1', '-batch_size', '4',
-                     '--max_train_steps', '1']
-    )
-
-  def test_cifar10_end_to_end_synthetic_v2(self):
-    integration.run_synthetic(
-        main=cifar10_main.run_cifar, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '2', '-batch_size', '4',
-                     '--max_train_steps', '1']
-    )
-
-
-if __name__ == '__main__':
-  tf.test.main()
diff --git a/official/r1/resnet/estimator_benchmark.py b/official/r1/resnet/estimator_benchmark.py
deleted file mode 100644
index a1b9f79f..00000000
--- a/official/r1/resnet/estimator_benchmark.py
+++ /dev/null
@@ -1,500 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Executes Estimator benchmarks and accuracy tests."""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import time
-
-from absl import flags
-from absl import logging
-from absl.testing import flagsaver
-import tensorflow as tf
-
-from official.r1.resnet import cifar10_main as cifar_main
-from official.r1.resnet import imagenet_main
-from official.r1.utils.logs import hooks
-from official.utils.flags import core as flags_core
-
-IMAGENET_DATA_DIR_NAME = 'imagenet'
-CIFAR_DATA_DIR_NAME = 'cifar-10-batches-bin'
-FLAGS = flags.FLAGS
-
-
-class EstimatorBenchmark(tf.test.Benchmark):
-  """Base class to hold methods common to test classes in the module.
-
-     Code under test for Estimator models (ResNet50 and 56) report mostly the
-     same data and require the same FLAG setup.
-  """
-
-  local_flags = None
-
-  def __init__(self, output_dir=None, default_flags=None, flag_methods=None):
-    if not output_dir:
-      output_dir = '/tmp'
-    self.output_dir = output_dir
-    self.default_flags = default_flags or {}
-    self.flag_methods = flag_methods or {}
-
-  def _get_model_dir(self, folder_name):
-    """Returns directory to store info, e.g. saved model and event log."""
-    return os.path.join(self.output_dir, folder_name)
-
-  def _setup(self):
-    """Sets up and resets flags before each test."""
-    logging.set_verbosity(logging.INFO)
-    if EstimatorBenchmark.local_flags is None:
-      for flag_method in self.flag_methods:
-        flag_method()
-      # Loads flags to get defaults to then override. List cannot be empty.
-      flags.FLAGS(['foo'])
-      # Overrides flag values with defaults for the class of tests.
-      for k, v in self.default_flags.items():
-        setattr(FLAGS, k, v)
-      saved_flag_values = flagsaver.save_flag_values()
-      EstimatorBenchmark.local_flags = saved_flag_values
-    else:
-      flagsaver.restore_flag_values(EstimatorBenchmark.local_flags)
-
-  def _report_benchmark(self,
-                        stats,
-                        wall_time_sec,
-                        top_1_max=None,
-                        top_1_min=None):
-    """Report benchmark results by writing to local protobuf file.
-
-    Args:
-      stats: dict returned from estimator models with known entries.
-      wall_time_sec: the during of the benchmark execution in seconds
-      top_1_max: highest passing level for top_1 accuracy.
-      top_1_min: lowest passing level for top_1 accuracy.
-    """
-
-    examples_per_sec_hook = None
-    for hook in stats['train_hooks']:
-      if isinstance(hook, hooks.ExamplesPerSecondHook):
-        examples_per_sec_hook = hook
-        break
-
-    eval_results = stats['eval_results']
-    metrics = []
-    if 'accuracy' in eval_results:
-      metrics.append({'name': 'accuracy_top_1',
-                      'value': float(eval_results['accuracy']),
-                      'min_value': top_1_min,
-                      'max_value': top_1_max})
-    if 'accuracy_top_5' in eval_results:
-      metrics.append({'name': 'accuracy_top_5',
-                      'value': float(eval_results['accuracy_top_5'])})
-
-    if examples_per_sec_hook:
-      exp_per_second_list = examples_per_sec_hook.current_examples_per_sec_list
-      # ExamplesPerSecondHook skips the first 10 steps.
-      exp_per_sec = sum(exp_per_second_list) / (len(exp_per_second_list))
-      metrics.append({'name': 'exp_per_second',
-                      'value': exp_per_sec})
-    flags_str = flags_core.get_nondefault_flags_as_str()
-    self.report_benchmark(
-        iters=eval_results.get('global_step', None),
-        wall_time=wall_time_sec,
-        metrics=metrics,
-        extras={'flags': flags_str})
-
-
-class Resnet50EstimatorAccuracy(EstimatorBenchmark):
-  """Benchmark accuracy tests for ResNet50 w/ Estimator."""
-
-  def __init__(self, output_dir=None, root_data_dir=None, **kwargs):
-    """Benchmark accuracy tests for ResNet50 w/ Estimator.
-
-    Args:
-      output_dir: directory where to output e.g. log files
-      root_data_dir: directory under which to look for dataset
-      **kwargs: arbitrary named arguments. This is needed to make the
-                constructor forward compatible in case PerfZero provides more
-                named arguments before updating the constructor.
-    """
-    flag_methods = [imagenet_main.define_imagenet_flags]
-
-    self.data_dir = os.path.join(root_data_dir, IMAGENET_DATA_DIR_NAME)
-    super(Resnet50EstimatorAccuracy, self).__init__(
-        output_dir=output_dir, flag_methods=flag_methods)
-
-  def benchmark_graph_8_gpu(self):
-    """Test 8 GPUs graph mode."""
-    self._setup()
-    FLAGS.num_gpus = 8
-    FLAGS.data_dir = self.data_dir
-    FLAGS.batch_size = 128 * 8
-    FLAGS.train_epochs = 90
-    FLAGS.epochs_between_evals = 10
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_8_gpu')
-    FLAGS.dtype = 'fp32'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_8_gpu(self):
-    """Test FP16 8 GPUs graph mode."""
-    self._setup()
-    FLAGS.num_gpus = 8
-    FLAGS.data_dir = self.data_dir
-    FLAGS.batch_size = 256 * 8
-    FLAGS.train_epochs = 90
-    FLAGS.epochs_between_evals = 10
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_8_gpu')
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_graph_rewrite_8_gpu(self):
-    """Test FP16 graph rewrite 8 GPUs graph mode."""
-    self._setup()
-    FLAGS.num_gpus = 8
-    FLAGS.data_dir = self.data_dir
-    FLAGS.batch_size = 256 * 8
-    FLAGS.train_epochs = 90
-    FLAGS.epochs_between_evals = 10
-    FLAGS.model_dir = self._get_model_dir(
-        'benchmark_graph_fp16_graph_rewrite_8_gpu')
-    FLAGS.dtype = 'fp16'
-    FLAGS.fp16_implementation = 'graph_rewrite'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def _run_and_report_benchmark(self):
-    start_time_sec = time.time()
-    stats = imagenet_main.run_imagenet(flags.FLAGS)
-    wall_time_sec = time.time() - start_time_sec
-    self._report_benchmark(stats,
-                           wall_time_sec,
-                           top_1_min=0.762,
-                           top_1_max=0.766)
-
-
-class Resnet50EstimatorBenchmarkBase(EstimatorBenchmark):
-  """Base class for benchmarks for ResNet50 using Estimator."""
-  local_flags = None
-
-  def __init__(self, output_dir=None, default_flags=None):
-    flag_methods = [imagenet_main.define_imagenet_flags]
-
-    super(Resnet50EstimatorBenchmarkBase, self).__init__(
-        output_dir=output_dir,
-        default_flags=default_flags,
-        flag_methods=flag_methods)
-
-  def _run_and_report_benchmark(self):
-    start_time_sec = time.time()
-    stats = imagenet_main.run_imagenet(FLAGS)
-    wall_time_sec = time.time() - start_time_sec
-    print(stats)
-    # Remove values to skip triggering accuracy check.
-    stats['eval_results'].pop('accuracy', None)
-    stats['eval_results'].pop('accuracy_top_5', None)
-
-    self._report_benchmark(stats, wall_time_sec)
-
-
-class Resnet50EstimatorBenchmark(Resnet50EstimatorBenchmarkBase):
-  """Benchmarks for ResNet50 using Estimator with 1 worker."""
-
-  def __init__(self, output_dir=None, default_flags=None):
-    super(Resnet50EstimatorBenchmark, self).__init__(
-        output_dir=output_dir,
-        default_flags=default_flags)
-
-  def benchmark_graph_fp16_1_gpu(self):
-    """Benchmarks graph fp16 1 gpu."""
-    self._setup()
-
-    FLAGS.num_gpus = 1
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_1_gpu')
-    FLAGS.batch_size = 128
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_1_gpu_tweaked(self):
-    """Benchmarks graph fp16 1 gpu tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 1
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_1_gpu_tweaked')
-    FLAGS.batch_size = 256
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_graph_rewrite_1_gpu_tweaked(self):
-    """Benchmarks graph fp16 graph rewrite 1 gpu tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 1
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.model_dir = self._get_model_dir(
-        'benchmark_graph_fp16_graph_rewrite_1_gpu_tweaked')
-    FLAGS.batch_size = 256
-    FLAGS.dtype = 'fp16'
-    FLAGS.fp16_implementation = 'graph_rewrite'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_1_gpu(self):
-    """Benchmarks graph 1 gpu."""
-    self._setup()
-
-    FLAGS.num_gpus = 1
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_1_gpu')
-    FLAGS.batch_size = 128
-    FLAGS.dtype = 'fp32'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_8_gpu(self):
-    """Benchmarks graph 8 gpus."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_8_gpu')
-    FLAGS.batch_size = 128*8
-    FLAGS.dtype = 'fp32'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_8_gpu(self):
-    """Benchmarks graph fp16 8 gpus."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_8_gpu')
-    FLAGS.batch_size = 256*8
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_8_gpu_tweaked(self):
-    """Benchmarks graph fp16 8 gpus tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_8_gpu_tweaked')
-    FLAGS.batch_size = 256*8
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_graph_rewrite_8_gpu_tweaked(self):
-    """Benchmarks graph fp16 graph rewrite 8 gpus tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.model_dir = self._get_model_dir(
-        'benchmark_graph_fp16_graph_rewrite_8_gpu_tweaked')
-    FLAGS.batch_size = 256*8
-    FLAGS.dtype = 'fp16'
-    FLAGS.fp16_implementation = 'graph_rewrite'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-
-class Resnet50EstimatorBenchmarkSynth(Resnet50EstimatorBenchmark):
-  """Resnet50 synthetic benchmark tests."""
-
-  def __init__(self, output_dir=None, root_data_dir=None, **kwargs):
-    def_flags = {}
-    def_flags['use_synthetic_data'] = True
-    def_flags['max_train_steps'] = 110
-    def_flags['train_epochs'] = 1
-
-    super(Resnet50EstimatorBenchmarkSynth, self).__init__(
-        output_dir=output_dir, default_flags=def_flags)
-
-
-class Resnet50EstimatorBenchmarkReal(Resnet50EstimatorBenchmark):
-  """Resnet50 real data benchmark tests."""
-
-  def __init__(self, output_dir=None, root_data_dir=None, **kwargs):
-    def_flags = {}
-    def_flags['data_dir'] = os.path.join(root_data_dir, IMAGENET_DATA_DIR_NAME)
-    def_flags['max_train_steps'] = 110
-    def_flags['train_epochs'] = 1
-
-    super(Resnet50EstimatorBenchmarkReal, self).__init__(
-        output_dir=output_dir, default_flags=def_flags)
-
-
-class Resnet50MultiWorkerEstimatorBenchmark(Resnet50EstimatorBenchmarkBase):
-  """Benchmarks for ResNet50 using Estimator with multiple workers."""
-
-  def __init__(self, output_dir=None, default_flags=None):
-    super(Resnet50MultiWorkerEstimatorBenchmark, self).__init__(
-        output_dir=output_dir,
-        default_flags=default_flags)
-
-  def benchmark_graph_fp16_8_gpu_ring_tweaked(self):
-    """Benchmarks graph fp16 8 gpus with ring collective tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.distribution_strategy = 'multi_worker_mirrored'
-    FLAGS.all_reduce_alg = 'ring'
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.datasets_num_private_threads = 32
-    FLAGS.model_dir = self._get_model_dir(
-        folder_name='benchmark_graph_fp16_8_gpu_ring_tweaked')
-    FLAGS.batch_size = 256*8
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_8_gpu_nccl_tweaked(self):
-    """Benchmarks graph fp16 8 gpus with nccl collective tweaked."""
-    self._setup()
-
-    FLAGS.num_gpus = 8
-    FLAGS.distribution_strategy = 'multi_worker_mirrored'
-    FLAGS.all_reduce_alg = 'nccl'
-    FLAGS.tf_gpu_thread_mode = 'gpu_private'
-    FLAGS.intra_op_parallelism_threads = 1
-    FLAGS.datasets_num_private_threads = 32
-    FLAGS.model_dir = self._get_model_dir(
-        folder_name='benchmark_graph_fp16_8_gpu_nccl_tweaked')
-    FLAGS.batch_size = 256*8
-    FLAGS.dtype = 'fp16'
-    FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-
-class Resnet50MultiWorkerEstimatorBenchmarkSynth(
-    Resnet50MultiWorkerEstimatorBenchmark):
-  """ResNet50, multi-worker, Estimator, synthetic data."""
-
-  def __init__(self, output_dir=None, root_data_dir=None, **kwargs):
-    def_flags = {}
-    def_flags['use_synthetic_data'] = True
-    def_flags['max_train_steps'] = 110
-    def_flags['train_epochs'] = 1
-
-    super(Resnet50MultiWorkerEstimatorBenchmarkSynth, self).__init__(
-        output_dir=output_dir, default_flags=def_flags)
-
-
-class Resnet56EstimatorAccuracy(EstimatorBenchmark):
-  """Accuracy tests for Estimator ResNet56."""
-
-  local_flags = None
-
-  def __init__(self, output_dir=None, root_data_dir=None, **kwargs):
-    """A benchmark class.
-
-    Args:
-      output_dir: directory where to output e.g. log files
-      root_data_dir: directory under which to look for dataset
-      **kwargs: arbitrary named arguments. This is needed to make the
-                constructor forward compatible in case PerfZero provides more
-                named arguments before updating the constructor.
-    """
-    flag_methods = [cifar_main.define_cifar_flags]
-
-    self.data_dir = os.path.join(root_data_dir, CIFAR_DATA_DIR_NAME)
-    super(Resnet56EstimatorAccuracy, self).__init__(
-        output_dir=output_dir, flag_methods=flag_methods)
-
-  def benchmark_graph_1_gpu(self):
-    """Test layers model with Estimator and distribution strategies."""
-    self._setup()
-    flags.FLAGS.num_gpus = 1
-    flags.FLAGS.data_dir = self.data_dir
-    flags.FLAGS.batch_size = 128
-    flags.FLAGS.train_epochs = 182
-    flags.FLAGS.model_dir = self._get_model_dir('benchmark_graph_1_gpu')
-    flags.FLAGS.resnet_size = 56
-    flags.FLAGS.dtype = 'fp32'
-    flags.FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_1_gpu(self):
-    """Test layers FP16 model with Estimator and distribution strategies."""
-    self._setup()
-    flags.FLAGS.num_gpus = 1
-    flags.FLAGS.data_dir = self.data_dir
-    flags.FLAGS.batch_size = 128
-    flags.FLAGS.train_epochs = 182
-    flags.FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_1_gpu')
-    flags.FLAGS.resnet_size = 56
-    flags.FLAGS.dtype = 'fp16'
-    flags.FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_2_gpu(self):
-    """Test layers model with Estimator and dist_strat. 2 GPUs."""
-    self._setup()
-    flags.FLAGS.num_gpus = 2
-    flags.FLAGS.data_dir = self.data_dir
-    flags.FLAGS.batch_size = 128
-    flags.FLAGS.train_epochs = 182
-    flags.FLAGS.model_dir = self._get_model_dir('benchmark_graph_2_gpu')
-    flags.FLAGS.resnet_size = 56
-    flags.FLAGS.dtype = 'fp32'
-    flags.FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def benchmark_graph_fp16_2_gpu(self):
-    """Test layers FP16 model with Estimator and dist_strat. 2 GPUs."""
-    self._setup()
-    flags.FLAGS.num_gpus = 2
-    flags.FLAGS.data_dir = self.data_dir
-    flags.FLAGS.batch_size = 128
-    flags.FLAGS.train_epochs = 182
-    flags.FLAGS.model_dir = self._get_model_dir('benchmark_graph_fp16_2_gpu')
-    flags.FLAGS.resnet_size = 56
-    flags.FLAGS.dtype = 'fp16'
-    flags.FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def unit_test(self):
-    """A lightweight test that can finish quickly."""
-    self._setup()
-    flags.FLAGS.num_gpus = 1
-    flags.FLAGS.data_dir = self.data_dir
-    flags.FLAGS.batch_size = 128
-    flags.FLAGS.train_epochs = 1
-    flags.FLAGS.model_dir = self._get_model_dir('unit_test')
-    flags.FLAGS.resnet_size = 8
-    flags.FLAGS.dtype = 'fp32'
-    flags.FLAGS.hooks = ['ExamplesPerSecondHook']
-    self._run_and_report_benchmark()
-
-  def _run_and_report_benchmark(self):
-    """Executes benchmark and reports result."""
-    start_time_sec = time.time()
-    stats = cifar_main.run_cifar(flags.FLAGS)
-    wall_time_sec = time.time() - start_time_sec
-
-    self._report_benchmark(stats,
-                           wall_time_sec,
-                           top_1_min=0.926,
-                           top_1_max=0.938)
diff --git a/official/r1/resnet/imagenet_main.py b/official/r1/resnet/imagenet_main.py
deleted file mode 100644
index 37420d33..00000000
--- a/official/r1/resnet/imagenet_main.py
+++ /dev/null
@@ -1,393 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Runs a ResNet model on the ImageNet dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-from absl import app as absl_app
-from absl import flags
-from absl import logging
-from six.moves import range
-import tensorflow as tf
-
-from official.r1.resnet import imagenet_preprocessing
-from official.r1.resnet import resnet_model
-from official.r1.resnet import resnet_run_loop
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-
-DEFAULT_IMAGE_SIZE = 224
-NUM_CHANNELS = 3
-NUM_CLASSES = 1001
-
-NUM_IMAGES = {
-    'train': 1281167,
-    'validation': 50000,
-}
-
-_NUM_TRAIN_FILES = 1024
-_SHUFFLE_BUFFER = 10000
-
-DATASET_NAME = 'ImageNet'
-
-###############################################################################
-# Data processing
-###############################################################################
-def get_filenames(is_training, data_dir):
-  """Return filenames for dataset."""
-  if is_training:
-    return [
-        os.path.join(data_dir, 'train-%05d-of-01024' % i)
-        for i in range(_NUM_TRAIN_FILES)]
-  else:
-    return [
-        os.path.join(data_dir, 'validation-%05d-of-00128' % i)
-        for i in range(128)]
-
-
-def _parse_example_proto(example_serialized):
-  """Parses an Example proto containing a training example of an image.
-
-  The output of the build_image_data.py image preprocessing script is a dataset
-  containing serialized Example protocol buffers. Each Example proto contains
-  the following fields (values are included as examples):
-
-    image/height: 462
-    image/width: 581
-    image/colorspace: 'RGB'
-    image/channels: 3
-    image/class/label: 615
-    image/class/synset: 'n03623198'
-    image/class/text: 'knee pad'
-    image/object/bbox/xmin: 0.1
-    image/object/bbox/xmax: 0.9
-    image/object/bbox/ymin: 0.2
-    image/object/bbox/ymax: 0.6
-    image/object/bbox/label: 615
-    image/format: 'JPEG'
-    image/filename: 'ILSVRC2012_val_00041207.JPEG'
-    image/encoded: <JPEG encoded string>
-
-  Args:
-    example_serialized: scalar Tensor tf.string containing a serialized
-      Example protocol buffer.
-
-  Returns:
-    image_buffer: Tensor tf.string containing the contents of a JPEG file.
-    label: Tensor tf.int32 containing the label.
-    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
-      where each coordinate is [0, 1) and the coordinates are arranged as
-      [ymin, xmin, ymax, xmax].
-  """
-  # Dense features in Example proto.
-  feature_map = {
-      'image/encoded': tf.io.FixedLenFeature([], dtype=tf.string,
-                                             default_value=''),
-      'image/class/label': tf.io.FixedLenFeature([], dtype=tf.int64,
-                                                 default_value=-1),
-      'image/class/text': tf.io.FixedLenFeature([], dtype=tf.string,
-                                                default_value=''),
-  }
-  sparse_float32 = tf.io.VarLenFeature(dtype=tf.float32)
-  # Sparse features in Example proto.
-  feature_map.update(
-      {k: sparse_float32 for k in ['image/object/bbox/xmin',
-                                   'image/object/bbox/ymin',
-                                   'image/object/bbox/xmax',
-                                   'image/object/bbox/ymax']})
-
-  features = tf.io.parse_single_example(serialized=example_serialized,
-                                        features=feature_map)
-  label = tf.cast(features['image/class/label'], dtype=tf.int32)
-
-  xmin = tf.expand_dims(features['image/object/bbox/xmin'].values, 0)
-  ymin = tf.expand_dims(features['image/object/bbox/ymin'].values, 0)
-  xmax = tf.expand_dims(features['image/object/bbox/xmax'].values, 0)
-  ymax = tf.expand_dims(features['image/object/bbox/ymax'].values, 0)
-
-  # Note that we impose an ordering of (y, x) just to make life difficult.
-  bbox = tf.concat([ymin, xmin, ymax, xmax], 0)
-
-  # Force the variable number of bounding boxes into the shape
-  # [1, num_boxes, coords].
-  bbox = tf.expand_dims(bbox, 0)
-  bbox = tf.transpose(a=bbox, perm=[0, 2, 1])
-
-  return features['image/encoded'], label, bbox
-
-
-def parse_record(raw_record, is_training, dtype):
-  """Parses a record containing a training example of an image.
-
-  The input record is parsed into a label and image, and the image is passed
-  through preprocessing steps (cropping, flipping, and so on).
-
-  Args:
-    raw_record: scalar Tensor tf.string containing a serialized
-      Example protocol buffer.
-    is_training: A boolean denoting whether the input is for training.
-    dtype: data type to use for images/features.
-
-  Returns:
-    Tuple with processed image tensor and one-hot-encoded label tensor.
-  """
-  image_buffer, label, bbox = _parse_example_proto(raw_record)
-
-  image = imagenet_preprocessing.preprocess_image(
-      image_buffer=image_buffer,
-      bbox=bbox,
-      output_height=DEFAULT_IMAGE_SIZE,
-      output_width=DEFAULT_IMAGE_SIZE,
-      num_channels=NUM_CHANNELS,
-      is_training=is_training)
-  image = tf.cast(image, dtype)
-
-  return image, label
-
-
-def input_fn(is_training,
-             data_dir,
-             batch_size,
-             num_epochs=1,
-             dtype=tf.float32,
-             datasets_num_private_threads=None,
-             parse_record_fn=parse_record,
-             input_context=None,
-             drop_remainder=False,
-             tf_data_experimental_slack=False):
-  """Input function which provides batches for train or eval.
-
-  Args:
-    is_training: A boolean denoting whether the input is for training.
-    data_dir: The directory containing the input data.
-    batch_size: The number of samples per batch.
-    num_epochs: The number of epochs to repeat the dataset.
-    dtype: Data type to use for images/features
-    datasets_num_private_threads: Number of private threads for tf.data.
-    parse_record_fn: Function to use for parsing the records.
-    input_context: A `tf.distribute.InputContext` object passed in by
-      `tf.distribute.Strategy`.
-    drop_remainder: A boolean indicates whether to drop the remainder of the
-      batches. If True, the batch dimension will be static.
-    tf_data_experimental_slack: Whether to enable tf.data's
-      `experimental_slack` option.
-
-  Returns:
-    A dataset that can be used for iteration.
-  """
-  filenames = get_filenames(is_training, data_dir)
-  dataset = tf.data.Dataset.from_tensor_slices(filenames)
-
-  if input_context:
-    logging.info(
-        'Sharding the dataset: input_pipeline_id=%d num_input_pipelines=%d',
-        input_context.input_pipeline_id, input_context.num_input_pipelines)
-    dataset = dataset.shard(input_context.num_input_pipelines,
-                            input_context.input_pipeline_id)
-
-  if is_training:
-    # Shuffle the input files
-    dataset = dataset.shuffle(buffer_size=_NUM_TRAIN_FILES)
-
-  # Convert to individual records.
-  # cycle_length = 10 means that up to 10 files will be read and deserialized in
-  # parallel. You may want to increase this number if you have a large number of
-  # CPU cores.
-  dataset = dataset.interleave(
-      tf.data.TFRecordDataset,
-      cycle_length=10,
-      num_parallel_calls=tf.data.experimental.AUTOTUNE)
-
-  return resnet_run_loop.process_record_dataset(
-      dataset=dataset,
-      is_training=is_training,
-      batch_size=batch_size,
-      shuffle_buffer=_SHUFFLE_BUFFER,
-      parse_record_fn=parse_record_fn,
-      num_epochs=num_epochs,
-      dtype=dtype,
-      datasets_num_private_threads=datasets_num_private_threads,
-      drop_remainder=drop_remainder,
-      tf_data_experimental_slack=tf_data_experimental_slack,
-  )
-
-
-def get_synth_input_fn(dtype):
-  return resnet_run_loop.get_synth_input_fn(
-      DEFAULT_IMAGE_SIZE, DEFAULT_IMAGE_SIZE, NUM_CHANNELS, NUM_CLASSES,
-      dtype=dtype)
-
-
-###############################################################################
-# Running the model
-###############################################################################
-class ImagenetModel(resnet_model.Model):
-  """Model class with appropriate defaults for Imagenet data."""
-
-  def __init__(self, resnet_size, data_format=None, num_classes=NUM_CLASSES,
-               resnet_version=resnet_model.DEFAULT_VERSION,
-               dtype=resnet_model.DEFAULT_DTYPE):
-    """These are the parameters that work for Imagenet data.
-
-    Args:
-      resnet_size: The number of convolutional layers needed in the model.
-      data_format: Either 'channels_first' or 'channels_last', specifying which
-        data format to use when setting up the model.
-      num_classes: The number of output classes needed from the model. This
-        enables users to extend the same model to their own datasets.
-      resnet_version: Integer representing which version of the ResNet network
-        to use. See README for details. Valid values: [1, 2]
-      dtype: The TensorFlow dtype to use for calculations.
-    """
-
-    # For bigger models, we want to use "bottleneck" layers
-    if resnet_size < 50:
-      bottleneck = False
-    else:
-      bottleneck = True
-
-    super(ImagenetModel, self).__init__(
-        resnet_size=resnet_size,
-        bottleneck=bottleneck,
-        num_classes=num_classes,
-        num_filters=64,
-        kernel_size=7,
-        conv_stride=2,
-        first_pool_size=3,
-        first_pool_stride=2,
-        block_sizes=_get_block_sizes(resnet_size),
-        block_strides=[1, 2, 2, 2],
-        resnet_version=resnet_version,
-        data_format=data_format,
-        dtype=dtype
-    )
-
-
-def _get_block_sizes(resnet_size):
-  """Retrieve the size of each block_layer in the ResNet model.
-
-  The number of block layers used for the Resnet model varies according
-  to the size of the model. This helper grabs the layer set we want, throwing
-  an error if a non-standard size has been selected.
-
-  Args:
-    resnet_size: The number of convolutional layers needed in the model.
-
-  Returns:
-    A list of block sizes to use in building the model.
-
-  Raises:
-    KeyError: if invalid resnet_size is received.
-  """
-  choices = {
-      18: [2, 2, 2, 2],
-      34: [3, 4, 6, 3],
-      50: [3, 4, 6, 3],
-      101: [3, 4, 23, 3],
-      152: [3, 8, 36, 3],
-      200: [3, 24, 36, 3]
-  }
-
-  try:
-    return choices[resnet_size]
-  except KeyError:
-    err = ('Could not find layers for selected Resnet size.\n'
-           'Size received: {}; sizes allowed: {}.'.format(
-               resnet_size, list(choices.keys())))
-    raise ValueError(err)
-
-
-def imagenet_model_fn(features, labels, mode, params):
-  """Our model_fn for ResNet to be used with our Estimator."""
-
-  # Warmup and higher lr may not be valid for fine tuning with small batches
-  # and smaller numbers of training images.
-  if params['fine_tune']:
-    warmup = False
-    base_lr = .1
-  else:
-    warmup = True
-    base_lr = .128
-
-  learning_rate_fn = resnet_run_loop.learning_rate_with_decay(
-      batch_size=params['batch_size'] * params.get('num_workers', 1),
-      batch_denom=256, num_images=NUM_IMAGES['train'],
-      boundary_epochs=[30, 60, 80, 90], decay_rates=[1, 0.1, 0.01, 0.001, 1e-4],
-      warmup=warmup, base_lr=base_lr)
-
-  return resnet_run_loop.resnet_model_fn(
-      features=features,
-      labels=labels,
-      mode=mode,
-      model_class=ImagenetModel,
-      resnet_size=params['resnet_size'],
-      weight_decay=flags.FLAGS.weight_decay,
-      learning_rate_fn=learning_rate_fn,
-      momentum=0.9,
-      data_format=params['data_format'],
-      resnet_version=params['resnet_version'],
-      loss_scale=params['loss_scale'],
-      loss_filter_fn=None,
-      dtype=params['dtype'],
-      fine_tune=params['fine_tune'],
-      label_smoothing=flags.FLAGS.label_smoothing
-  )
-
-
-def define_imagenet_flags():
-  resnet_run_loop.define_resnet_flags(
-      resnet_size_choices=['18', '34', '50', '101', '152', '200'],
-      dynamic_loss_scale=True,
-      fp16_implementation=True)
-  flags.adopt_module_key_flags(resnet_run_loop)
-  flags_core.set_defaults(train_epochs=90)
-
-
-def run_imagenet(flags_obj):
-  """Run ResNet ImageNet training and eval loop.
-
-  Args:
-    flags_obj: An object containing parsed flag values.
-
-  Returns:
-    Dict of results of the run.  Contains the keys `eval_results` and
-      `train_hooks`. `eval_results` contains accuracy (top_1) and
-      accuracy_top_5. `train_hooks` is a list the instances of hooks used during
-      training.
-  """
-  input_function = (flags_obj.use_synthetic_data and
-                    get_synth_input_fn(flags_core.get_tf_dtype(flags_obj)) or
-                    input_fn)
-
-  result = resnet_run_loop.resnet_main(
-      flags_obj, imagenet_model_fn, input_function, DATASET_NAME,
-      shape=[DEFAULT_IMAGE_SIZE, DEFAULT_IMAGE_SIZE, NUM_CHANNELS])
-
-  return result
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    run_imagenet(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  logging.set_verbosity(logging.INFO)
-  define_imagenet_flags()
-  absl_app.run(main)
diff --git a/official/r1/resnet/imagenet_preprocessing.py b/official/r1/resnet/imagenet_preprocessing.py
deleted file mode 100644
index 891b58ab..00000000
--- a/official/r1/resnet/imagenet_preprocessing.py
+++ /dev/null
@@ -1,262 +0,0 @@
-# Copyright 2016 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Provides utilities to preprocess images.
-
-Training images are sampled using the provided bounding boxes, and subsequently
-cropped to the sampled bounding box. Images are additionally flipped randomly,
-then resized to the target output size (without aspect-ratio preservation).
-
-Images used during evaluation are resized (with aspect-ratio preservation) and
-centrally cropped.
-
-All images undergo mean color subtraction.
-
-Note that these steps are colloquially referred to as "ResNet preprocessing,"
-and they differ from "VGG preprocessing," which does not use bounding boxes
-and instead does an aspect-preserving resize followed by random crop during
-training. (These both differ from "Inception preprocessing," which introduces
-color distortion steps.)
-
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf
-
-_R_MEAN = 123.68
-_G_MEAN = 116.78
-_B_MEAN = 103.94
-_CHANNEL_MEANS = [_R_MEAN, _G_MEAN, _B_MEAN]
-
-# The lower bound for the smallest side of the image for aspect-preserving
-# resizing. For example, if an image is 500 x 1000, it will be resized to
-# _RESIZE_MIN x (_RESIZE_MIN * 2).
-_RESIZE_MIN = 256
-
-
-def _decode_crop_and_flip(image_buffer, bbox, num_channels):
-  """Crops the given image to a random part of the image, and randomly flips.
-
-  We use the fused decode_and_crop op, which performs better than the two ops
-  used separately in series, but note that this requires that the image be
-  passed in as an un-decoded string Tensor.
-
-  Args:
-    image_buffer: scalar string Tensor representing the raw JPEG image buffer.
-    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
-      where each coordinate is [0, 1) and the coordinates are arranged as
-      [ymin, xmin, ymax, xmax].
-    num_channels: Integer depth of the image buffer for decoding.
-
-  Returns:
-    3-D tensor with cropped image.
-
-  """
-  # A large fraction of image datasets contain a human-annotated bounding box
-  # delineating the region of the image containing the object of interest.  We
-  # choose to create a new bounding box for the object which is a randomly
-  # distorted version of the human-annotated bounding box that obeys an
-  # allowed range of aspect ratios, sizes and overlap with the human-annotated
-  # bounding box. If no box is supplied, then we assume the bounding box is
-  # the entire image.
-  sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(
-      tf.image.extract_jpeg_shape(image_buffer),
-      bounding_boxes=bbox,
-      min_object_covered=0.1,
-      aspect_ratio_range=[0.75, 1.33],
-      area_range=[0.05, 1.0],
-      max_attempts=100,
-      use_image_if_no_bounding_boxes=True)
-  bbox_begin, bbox_size, _ = sample_distorted_bounding_box
-
-  # Reassemble the bounding box in the format the crop op requires.
-  offset_y, offset_x, _ = tf.unstack(bbox_begin)
-  target_height, target_width, _ = tf.unstack(bbox_size)
-  crop_window = tf.stack([offset_y, offset_x, target_height, target_width])
-
-  # Use the fused decode and crop op here, which is faster than each in series.
-  cropped = tf.image.decode_and_crop_jpeg(
-      image_buffer, crop_window, channels=num_channels)
-
-  # Flip to add a little more random distortion in.
-  cropped = tf.image.random_flip_left_right(cropped)
-  return cropped
-
-
-def _central_crop(image, crop_height, crop_width):
-  """Performs central crops of the given image list.
-
-  Args:
-    image: a 3-D image tensor
-    crop_height: the height of the image following the crop.
-    crop_width: the width of the image following the crop.
-
-  Returns:
-    3-D tensor with cropped image.
-  """
-  shape = tf.shape(input=image)
-  height, width = shape[0], shape[1]
-
-  amount_to_be_cropped_h = (height - crop_height)
-  crop_top = amount_to_be_cropped_h // 2
-  amount_to_be_cropped_w = (width - crop_width)
-  crop_left = amount_to_be_cropped_w // 2
-  return tf.slice(
-      image, [crop_top, crop_left, 0], [crop_height, crop_width, -1])
-
-
-def _mean_image_subtraction(image, means, num_channels):
-  """Subtracts the given means from each image channel.
-
-  For example:
-    means = [123.68, 116.779, 103.939]
-    image = _mean_image_subtraction(image, means)
-
-  Note that the rank of `image` must be known.
-
-  Args:
-    image: a tensor of size [height, width, C].
-    means: a C-vector of values to subtract from each channel.
-    num_channels: number of color channels in the image that will be distorted.
-
-  Returns:
-    the centered image.
-
-  Raises:
-    ValueError: If the rank of `image` is unknown, if `image` has a rank other
-      than three or if the number of channels in `image` doesn't match the
-      number of values in `means`.
-  """
-  if image.get_shape().ndims != 3:
-    raise ValueError('Input must be of size [height, width, C>0]')
-
-  if len(means) != num_channels:
-    raise ValueError('len(means) must match the number of channels')
-
-  # We have a 1-D tensor of means; convert to 3-D.
-  # Note(b/130245863): we explicitly call `broadcast` instead of simply
-  # expanding dimensions for better performance.
-  means = tf.broadcast_to(means, tf.shape(image))
-
-  return image - means
-
-
-def _smallest_size_at_least(height, width, resize_min):
-  """Computes new shape with the smallest side equal to `smallest_side`.
-
-  Computes new shape with the smallest side equal to `smallest_side` while
-  preserving the original aspect ratio.
-
-  Args:
-    height: an int32 scalar tensor indicating the current height.
-    width: an int32 scalar tensor indicating the current width.
-    resize_min: A python integer or scalar `Tensor` indicating the size of
-      the smallest side after resize.
-
-  Returns:
-    new_height: an int32 scalar tensor indicating the new height.
-    new_width: an int32 scalar tensor indicating the new width.
-  """
-  resize_min = tf.cast(resize_min, tf.float32)
-
-  # Convert to floats to make subsequent calculations go smoothly.
-  height, width = tf.cast(height, tf.float32), tf.cast(width, tf.float32)
-
-  smaller_dim = tf.minimum(height, width)
-  scale_ratio = resize_min / smaller_dim
-
-  # Convert back to ints to make heights and widths that TF ops will accept.
-  new_height = tf.cast(height * scale_ratio, tf.int32)
-  new_width = tf.cast(width * scale_ratio, tf.int32)
-
-  return new_height, new_width
-
-
-def _aspect_preserving_resize(image, resize_min):
-  """Resize images preserving the original aspect ratio.
-
-  Args:
-    image: A 3-D image `Tensor`.
-    resize_min: A python integer or scalar `Tensor` indicating the size of
-      the smallest side after resize.
-
-  Returns:
-    resized_image: A 3-D tensor containing the resized image.
-  """
-  shape = tf.shape(input=image)
-  height, width = shape[0], shape[1]
-
-  new_height, new_width = _smallest_size_at_least(height, width, resize_min)
-
-  return _resize_image(image, new_height, new_width)
-
-
-def _resize_image(image, height, width):
-  """Simple wrapper around tf.resize_images.
-
-  This is primarily to make sure we use the same `ResizeMethod` and other
-  details each time.
-
-  Args:
-    image: A 3-D image `Tensor`.
-    height: The target height for the resized image.
-    width: The target width for the resized image.
-
-  Returns:
-    resized_image: A 3-D tensor containing the resized image. The first two
-      dimensions have the shape [height, width].
-  """
-  return tf.compat.v1.image.resize(
-      image, [height, width], method=tf.image.ResizeMethod.BILINEAR,
-      align_corners=False)
-
-
-def preprocess_image(image_buffer, bbox, output_height, output_width,
-                     num_channels, is_training=False):
-  """Preprocesses the given image.
-
-  Preprocessing includes decoding, cropping, and resizing for both training
-  and eval images. Training preprocessing, however, introduces some random
-  distortion of the image to improve accuracy.
-
-  Args:
-    image_buffer: scalar string Tensor representing the raw JPEG image buffer.
-    bbox: 3-D float Tensor of bounding boxes arranged [1, num_boxes, coords]
-      where each coordinate is [0, 1) and the coordinates are arranged as
-      [ymin, xmin, ymax, xmax].
-    output_height: The height of the image after preprocessing.
-    output_width: The width of the image after preprocessing.
-    num_channels: Integer depth of the image buffer for decoding.
-    is_training: `True` if we're preprocessing the image for training and
-      `False` otherwise.
-
-  Returns:
-    A preprocessed image.
-  """
-  if is_training:
-    # For training, we want to randomize some of the distortions.
-    image = _decode_crop_and_flip(image_buffer, bbox, num_channels)
-    image = _resize_image(image, output_height, output_width)
-  else:
-    # For validation, we want to decode, resize, then just crop the middle.
-    image = tf.image.decode_jpeg(image_buffer, channels=num_channels)
-    image = _aspect_preserving_resize(image, _RESIZE_MIN)
-    image = _central_crop(image, output_height, output_width)
-
-  image.set_shape([output_height, output_width, num_channels])
-
-  return _mean_image_subtraction(image, _CHANNEL_MEANS, num_channels)
diff --git a/official/r1/resnet/imagenet_test.py b/official/r1/resnet/imagenet_test.py
deleted file mode 100644
index c25cafb8..00000000
--- a/official/r1/resnet/imagenet_test.py
+++ /dev/null
@@ -1,325 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import unittest
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-from absl import logging
-
-from official.r1.resnet import imagenet_main
-from official.utils.testing import integration
-
-logging.set_verbosity(logging.ERROR)
-
-_BATCH_SIZE = 32
-_LABEL_CLASSES = 1001
-
-
-class BaseTest(tf.test.TestCase):
-
-  _num_validation_images = None
-
-  @classmethod
-  def setUpClass(cls):  # pylint: disable=invalid-name
-    super(BaseTest, cls).setUpClass()
-    imagenet_main.define_imagenet_flags()
-
-  def setUp(self):
-    super(BaseTest, self).setUp()
-    tf.compat.v1.disable_eager_execution()
-    self._num_validation_images = imagenet_main.NUM_IMAGES['validation']
-    imagenet_main.NUM_IMAGES['validation'] = 4
-
-  def tearDown(self):
-    super(BaseTest, self).tearDown()
-    tf.io.gfile.rmtree(self.get_temp_dir())
-    imagenet_main.NUM_IMAGES['validation'] = self._num_validation_images
-
-  def _tensor_shapes_helper(self, resnet_size, resnet_version, dtype, with_gpu):
-    """Checks the tensor shapes after each phase of the ResNet model."""
-    def reshape(shape):
-      """Returns the expected dimensions depending on if a GPU is being used."""
-
-      # If a GPU is used for the test, the shape is returned (already in NCHW
-      # form). When GPU is not used, the shape is converted to NHWC.
-      if with_gpu:
-        return shape
-      return shape[0], shape[2], shape[3], shape[1]
-
-    graph = tf.Graph()
-
-    with graph.as_default(), self.test_session(
-        graph=graph, use_gpu=with_gpu, force_gpu=with_gpu):
-      model = imagenet_main.ImagenetModel(
-          resnet_size=resnet_size,
-          data_format='channels_first' if with_gpu else 'channels_last',
-          resnet_version=resnet_version,
-          dtype=dtype
-      )
-      inputs = tf.random.uniform([1, 224, 224, 3])
-      output = model(inputs, training=True)
-
-      initial_conv = graph.get_tensor_by_name('resnet_model/initial_conv:0')
-      max_pool = graph.get_tensor_by_name('resnet_model/initial_max_pool:0')
-      block_layer1 = graph.get_tensor_by_name('resnet_model/block_layer1:0')
-      block_layer2 = graph.get_tensor_by_name('resnet_model/block_layer2:0')
-      block_layer3 = graph.get_tensor_by_name('resnet_model/block_layer3:0')
-      block_layer4 = graph.get_tensor_by_name('resnet_model/block_layer4:0')
-      reduce_mean = graph.get_tensor_by_name('resnet_model/final_reduce_mean:0')
-      dense = graph.get_tensor_by_name('resnet_model/final_dense:0')
-
-      self.assertAllEqual(initial_conv.shape, reshape((1, 64, 112, 112)))
-      self.assertAllEqual(max_pool.shape, reshape((1, 64, 56, 56)))
-
-      # The number of channels after each block depends on whether we're
-      # using the building_block or the bottleneck_block.
-      if resnet_size < 50:
-        self.assertAllEqual(block_layer1.shape, reshape((1, 64, 56, 56)))
-        self.assertAllEqual(block_layer2.shape, reshape((1, 128, 28, 28)))
-        self.assertAllEqual(block_layer3.shape, reshape((1, 256, 14, 14)))
-        self.assertAllEqual(block_layer4.shape, reshape((1, 512, 7, 7)))
-        self.assertAllEqual(reduce_mean.shape, reshape((1, 512, 1, 1)))
-      else:
-        self.assertAllEqual(block_layer1.shape, reshape((1, 256, 56, 56)))
-        self.assertAllEqual(block_layer2.shape, reshape((1, 512, 28, 28)))
-        self.assertAllEqual(block_layer3.shape, reshape((1, 1024, 14, 14)))
-        self.assertAllEqual(block_layer4.shape, reshape((1, 2048, 7, 7)))
-        self.assertAllEqual(reduce_mean.shape, reshape((1, 2048, 1, 1)))
-
-      self.assertAllEqual(dense.shape, (1, _LABEL_CLASSES))
-      self.assertAllEqual(output.shape, (1, _LABEL_CLASSES))
-
-  def tensor_shapes_helper(self, resnet_size, resnet_version, with_gpu=False):
-    self._tensor_shapes_helper(resnet_size=resnet_size,
-                               resnet_version=resnet_version,
-                               dtype=tf.float32, with_gpu=with_gpu)
-    self._tensor_shapes_helper(resnet_size=resnet_size,
-                               resnet_version=resnet_version,
-                               dtype=tf.float16, with_gpu=with_gpu)
-
-  def test_tensor_shapes_resnet_18_v1(self):
-    self.tensor_shapes_helper(18, resnet_version=1)
-
-  def test_tensor_shapes_resnet_18_v2(self):
-    self.tensor_shapes_helper(18, resnet_version=2)
-
-  def test_tensor_shapes_resnet_34_v1(self):
-    self.tensor_shapes_helper(34, resnet_version=1)
-
-  def test_tensor_shapes_resnet_34_v2(self):
-    self.tensor_shapes_helper(34, resnet_version=2)
-
-  def test_tensor_shapes_resnet_50_v1(self):
-    self.tensor_shapes_helper(50, resnet_version=1)
-
-  def test_tensor_shapes_resnet_50_v2(self):
-    self.tensor_shapes_helper(50, resnet_version=2)
-
-  def test_tensor_shapes_resnet_101_v1(self):
-    self.tensor_shapes_helper(101, resnet_version=1)
-
-  def test_tensor_shapes_resnet_101_v2(self):
-    self.tensor_shapes_helper(101, resnet_version=2)
-
-  def test_tensor_shapes_resnet_152_v1(self):
-    self.tensor_shapes_helper(152, resnet_version=1)
-
-  def test_tensor_shapes_resnet_152_v2(self):
-    self.tensor_shapes_helper(152, resnet_version=2)
-
-  def test_tensor_shapes_resnet_200_v1(self):
-    self.tensor_shapes_helper(200, resnet_version=1)
-
-  def test_tensor_shapes_resnet_200_v2(self):
-    self.tensor_shapes_helper(200, resnet_version=2)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_18_with_gpu_v1(self):
-    self.tensor_shapes_helper(18, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_18_with_gpu_v2(self):
-    self.tensor_shapes_helper(18, resnet_version=2, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_34_with_gpu_v1(self):
-    self.tensor_shapes_helper(34, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_34_with_gpu_v2(self):
-    self.tensor_shapes_helper(34, resnet_version=2, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_50_with_gpu_v1(self):
-    self.tensor_shapes_helper(50, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_50_with_gpu_v2(self):
-    self.tensor_shapes_helper(50, resnet_version=2, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_101_with_gpu_v1(self):
-    self.tensor_shapes_helper(101, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_101_with_gpu_v2(self):
-    self.tensor_shapes_helper(101, resnet_version=2, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_152_with_gpu_v1(self):
-    self.tensor_shapes_helper(152, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_152_with_gpu_v2(self):
-    self.tensor_shapes_helper(152, resnet_version=2, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_200_with_gpu_v1(self):
-    self.tensor_shapes_helper(200, resnet_version=1, with_gpu=True)
-
-  @unittest.skipUnless(tf.test.is_built_with_cuda(), 'requires GPU')
-  def test_tensor_shapes_resnet_200_with_gpu_v2(self):
-    self.tensor_shapes_helper(200, resnet_version=2, with_gpu=True)
-
-  def resnet_model_fn_helper(self, mode, resnet_version, dtype):
-    """Tests that the EstimatorSpec is given the appropriate arguments."""
-    tf.compat.v1.train.create_global_step()
-
-    input_fn = imagenet_main.get_synth_input_fn(dtype)
-    dataset = input_fn(True, '', _BATCH_SIZE)
-    iterator = tf.compat.v1.data.make_initializable_iterator(dataset)
-    features, labels = iterator.get_next()
-    spec = imagenet_main.imagenet_model_fn(
-        features, labels, mode, {
-            'dtype': dtype,
-            'resnet_size': 50,
-            'data_format': 'channels_last',
-            'batch_size': _BATCH_SIZE,
-            'resnet_version': resnet_version,
-            'loss_scale': 128 if dtype == tf.float16 else 1,
-            'fine_tune': False,
-        })
-
-    predictions = spec.predictions
-    self.assertAllEqual(predictions['probabilities'].shape,
-                        (_BATCH_SIZE, _LABEL_CLASSES))
-    self.assertEqual(predictions['probabilities'].dtype, tf.float32)
-    self.assertAllEqual(predictions['classes'].shape, (_BATCH_SIZE,))
-    self.assertEqual(predictions['classes'].dtype, tf.int64)
-
-    if mode != tf.estimator.ModeKeys.PREDICT:
-      loss = spec.loss
-      self.assertAllEqual(loss.shape, ())
-      self.assertEqual(loss.dtype, tf.float32)
-
-    if mode == tf.estimator.ModeKeys.EVAL:
-      eval_metric_ops = spec.eval_metric_ops
-      self.assertAllEqual(eval_metric_ops['accuracy'][0].shape, ())
-      self.assertAllEqual(eval_metric_ops['accuracy'][1].shape, ())
-      self.assertEqual(eval_metric_ops['accuracy'][0].dtype, tf.float32)
-      self.assertEqual(eval_metric_ops['accuracy'][1].dtype, tf.float32)
-
-  def test_resnet_model_fn_train_mode_v1(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.TRAIN, resnet_version=1,
-                                dtype=tf.float32)
-
-  def test_resnet_model_fn_train_mode_v2(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.TRAIN, resnet_version=2,
-                                dtype=tf.float32)
-
-  def test_resnet_model_fn_eval_mode_v1(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.EVAL, resnet_version=1,
-                                dtype=tf.float32)
-
-  def test_resnet_model_fn_eval_mode_v2(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.EVAL, resnet_version=2,
-                                dtype=tf.float32)
-
-  def test_resnet_model_fn_predict_mode_v1(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.PREDICT, resnet_version=1,
-                                dtype=tf.float32)
-
-  def test_resnet_model_fn_predict_mode_v2(self):
-    self.resnet_model_fn_helper(tf.estimator.ModeKeys.PREDICT, resnet_version=2,
-                                dtype=tf.float32)
-
-  def _test_imagenetmodel_shape(self, resnet_version):
-    batch_size = 135
-    num_classes = 246
-
-    model = imagenet_main.ImagenetModel(
-        50, data_format='channels_last', num_classes=num_classes,
-        resnet_version=resnet_version)
-
-    fake_input = tf.random.uniform([batch_size, 224, 224, 3])
-    output = model(fake_input, training=True)
-
-    self.assertAllEqual(output.shape, (batch_size, num_classes))
-
-  def test_imagenetmodel_shape_v1(self):
-    self._test_imagenetmodel_shape(resnet_version=1)
-
-  def test_imagenetmodel_shape_v2(self):
-    self._test_imagenetmodel_shape(resnet_version=2)
-
-  def test_imagenet_end_to_end_synthetic_v1(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '1', '-batch_size', '4',
-                     '--max_train_steps', '1']
-    )
-
-  def test_imagenet_end_to_end_synthetic_v2(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '2', '-batch_size', '4',
-                     '--max_train_steps', '1']
-    )
-
-  def test_imagenet_end_to_end_synthetic_v1_tiny(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '1', '-batch_size', '4',
-                     '-resnet_size', '18', '--max_train_steps', '1']
-    )
-
-  def test_imagenet_end_to_end_synthetic_v2_tiny(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '2', '-batch_size', '4',
-                     '-resnet_size', '18', '--max_train_steps', '1']
-    )
-
-  def test_imagenet_end_to_end_synthetic_v1_huge(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '1', '-batch_size', '4',
-                     '-resnet_size', '200', '--max_train_steps', '1']
-    )
-
-  def test_imagenet_end_to_end_synthetic_v2_huge(self):
-    integration.run_synthetic(
-        main=imagenet_main.run_imagenet, tmp_root=self.get_temp_dir(),
-        extra_flags=['-resnet_version', '2', '-batch_size', '4',
-                     '-resnet_size', '200', '--max_train_steps', '1']
-    )
-
-
-if __name__ == '__main__':
-  tf.test.main()
diff --git a/official/r1/resnet/resnet_model.py b/official/r1/resnet/resnet_model.py
deleted file mode 100644
index d6449df5..00000000
--- a/official/r1/resnet/resnet_model.py
+++ /dev/null
@@ -1,548 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Contains definitions for Residual Networks.
-
-Residual networks ('v1' ResNets) were originally proposed in:
-[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
-    Deep Residual Learning for Image Recognition. arXiv:1512.03385
-
-The full preactivation 'v2' ResNet variant was introduced by:
-[2] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun
-    Identity Mappings in Deep Residual Networks. arXiv: 1603.05027
-
-The key difference of the full preactivation 'v2' variant compared to the
-'v1' variant in [1] is the use of batch normalization before every weight layer
-rather than after.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf
-
-_BATCH_NORM_DECAY = 0.997
-_BATCH_NORM_EPSILON = 1e-5
-DEFAULT_VERSION = 2
-DEFAULT_DTYPE = tf.float32
-CASTABLE_TYPES = (tf.float16,)
-ALLOWED_TYPES = (DEFAULT_DTYPE,) + CASTABLE_TYPES
-
-
-################################################################################
-# Convenience functions for building the ResNet model.
-################################################################################
-def batch_norm(inputs, training, data_format):
-  """Performs a batch normalization using a standard set of parameters."""
-  # We set fused=True for a significant performance boost. See
-  # https://www.tensorflow.org/performance/performance_guide#common_fused_ops
-  return tf.compat.v1.layers.batch_normalization(
-      inputs=inputs, axis=1 if data_format == 'channels_first' else 3,
-      momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON, center=True,
-      scale=True, training=training, fused=True)
-
-
-def fixed_padding(inputs, kernel_size, data_format):
-  """Pads the input along the spatial dimensions independently of input size.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    kernel_size: The kernel to be used in the conv2d or max_pool2d operation.
-                 Should be a positive integer.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    A tensor with the same format as the input with the data either intact
-    (if kernel_size == 1) or padded (if kernel_size > 1).
-  """
-  pad_total = kernel_size - 1
-  pad_beg = pad_total // 2
-  pad_end = pad_total - pad_beg
-
-  if data_format == 'channels_first':
-    padded_inputs = tf.pad(tensor=inputs,
-                           paddings=[[0, 0], [0, 0], [pad_beg, pad_end],
-                                     [pad_beg, pad_end]])
-  else:
-    padded_inputs = tf.pad(tensor=inputs,
-                           paddings=[[0, 0], [pad_beg, pad_end],
-                                     [pad_beg, pad_end], [0, 0]])
-  return padded_inputs
-
-
-def conv2d_fixed_padding(inputs, filters, kernel_size, strides, data_format):
-  """Strided 2-D convolution with explicit padding."""
-  # The padding is consistent and is based only on `kernel_size`, not on the
-  # dimensions of `inputs` (as opposed to using `tf.layers.conv2d` alone).
-  if strides > 1:
-    inputs = fixed_padding(inputs, kernel_size, data_format)
-
-  return tf.compat.v1.layers.conv2d(
-      inputs=inputs, filters=filters, kernel_size=kernel_size, strides=strides,
-      padding=('SAME' if strides == 1 else 'VALID'), use_bias=False,
-      kernel_initializer=tf.compat.v1.variance_scaling_initializer(),
-      data_format=data_format)
-
-
-################################################################################
-# ResNet block definitions.
-################################################################################
-def _building_block_v1(inputs, filters, training, projection_shortcut, strides,
-                       data_format):
-  """A single block for ResNet v1, without a bottleneck.
-
-  Convolution then batch normalization then ReLU as described by:
-    Deep Residual Learning for Image Recognition
-    https://arxiv.org/pdf/1512.03385.pdf
-    by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    filters: The number of filters for the convolutions.
-    training: A Boolean for whether the model is in training or inference
-      mode. Needed for batch normalization.
-    projection_shortcut: The function to use for projection shortcuts
-      (typically a 1x1 convolution when downsampling the input).
-    strides: The block's stride. If greater than 1, this block will ultimately
-      downsample the input.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    The output tensor of the block; shape should match inputs.
-  """
-  shortcut = inputs
-
-  if projection_shortcut is not None:
-    shortcut = projection_shortcut(inputs)
-    shortcut = batch_norm(inputs=shortcut, training=training,
-                          data_format=data_format)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=strides,
-      data_format=data_format)
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=1,
-      data_format=data_format)
-  inputs = batch_norm(inputs, training, data_format)
-  inputs += shortcut
-  inputs = tf.nn.relu(inputs)
-
-  return inputs
-
-
-def _building_block_v2(inputs, filters, training, projection_shortcut, strides,
-                       data_format):
-  """A single block for ResNet v2, without a bottleneck.
-
-  Batch normalization then ReLu then convolution as described by:
-    Identity Mappings in Deep Residual Networks
-    https://arxiv.org/pdf/1603.05027.pdf
-    by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    filters: The number of filters for the convolutions.
-    training: A Boolean for whether the model is in training or inference
-      mode. Needed for batch normalization.
-    projection_shortcut: The function to use for projection shortcuts
-      (typically a 1x1 convolution when downsampling the input).
-    strides: The block's stride. If greater than 1, this block will ultimately
-      downsample the input.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    The output tensor of the block; shape should match inputs.
-  """
-  shortcut = inputs
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-
-  # The projection shortcut should come after the first batch norm and ReLU
-  # since it performs a 1x1 convolution.
-  if projection_shortcut is not None:
-    shortcut = projection_shortcut(inputs)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=strides,
-      data_format=data_format)
-
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=1,
-      data_format=data_format)
-
-  return inputs + shortcut
-
-
-def _bottleneck_block_v1(inputs, filters, training, projection_shortcut,
-                         strides, data_format):
-  """A single block for ResNet v1, with a bottleneck.
-
-  Similar to _building_block_v1(), except using the "bottleneck" blocks
-  described in:
-    Convolution then batch normalization then ReLU as described by:
-      Deep Residual Learning for Image Recognition
-      https://arxiv.org/pdf/1512.03385.pdf
-      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    filters: The number of filters for the convolutions.
-    training: A Boolean for whether the model is in training or inference
-      mode. Needed for batch normalization.
-    projection_shortcut: The function to use for projection shortcuts
-      (typically a 1x1 convolution when downsampling the input).
-    strides: The block's stride. If greater than 1, this block will ultimately
-      downsample the input.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    The output tensor of the block; shape should match inputs.
-  """
-  shortcut = inputs
-
-  if projection_shortcut is not None:
-    shortcut = projection_shortcut(inputs)
-    shortcut = batch_norm(inputs=shortcut, training=training,
-                          data_format=data_format)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=1, strides=1,
-      data_format=data_format)
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=strides,
-      data_format=data_format)
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,
-      data_format=data_format)
-  inputs = batch_norm(inputs, training, data_format)
-  inputs += shortcut
-  inputs = tf.nn.relu(inputs)
-
-  return inputs
-
-
-def _bottleneck_block_v2(inputs, filters, training, projection_shortcut,
-                         strides, data_format):
-  """A single block for ResNet v2, with a bottleneck.
-
-  Similar to _building_block_v2(), except using the "bottleneck" blocks
-  described in:
-    Convolution then batch normalization then ReLU as described by:
-      Deep Residual Learning for Image Recognition
-      https://arxiv.org/pdf/1512.03385.pdf
-      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-  Adapted to the ordering conventions of:
-    Batch normalization then ReLu then convolution as described by:
-      Identity Mappings in Deep Residual Networks
-      https://arxiv.org/pdf/1603.05027.pdf
-      by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    filters: The number of filters for the convolutions.
-    training: A Boolean for whether the model is in training or inference
-      mode. Needed for batch normalization.
-    projection_shortcut: The function to use for projection shortcuts
-      (typically a 1x1 convolution when downsampling the input).
-    strides: The block's stride. If greater than 1, this block will ultimately
-      downsample the input.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    The output tensor of the block; shape should match inputs.
-  """
-  shortcut = inputs
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-
-  # The projection shortcut should come after the first batch norm and ReLU
-  # since it performs a 1x1 convolution.
-  if projection_shortcut is not None:
-    shortcut = projection_shortcut(inputs)
-
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=1, strides=1,
-      data_format=data_format)
-
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=filters, kernel_size=3, strides=strides,
-      data_format=data_format)
-
-  inputs = batch_norm(inputs, training, data_format)
-  inputs = tf.nn.relu(inputs)
-  inputs = conv2d_fixed_padding(
-      inputs=inputs, filters=4 * filters, kernel_size=1, strides=1,
-      data_format=data_format)
-
-  return inputs + shortcut
-
-
-def block_layer(inputs, filters, bottleneck, block_fn, blocks, strides,
-                training, name, data_format):
-  """Creates one layer of blocks for the ResNet model.
-
-  Args:
-    inputs: A tensor of size [batch, channels, height_in, width_in] or
-      [batch, height_in, width_in, channels] depending on data_format.
-    filters: The number of filters for the first convolution of the layer.
-    bottleneck: Is the block created a bottleneck block.
-    block_fn: The block to use within the model, either `building_block` or
-      `bottleneck_block`.
-    blocks: The number of blocks contained in the layer.
-    strides: The stride to use for the first convolution of the layer. If
-      greater than 1, this layer will ultimately downsample the input.
-    training: Either True or False, whether we are currently training the
-      model. Needed for batch norm.
-    name: A string name for the tensor output of the block layer.
-    data_format: The input format ('channels_last' or 'channels_first').
-
-  Returns:
-    The output tensor of the block layer.
-  """
-
-  # Bottleneck blocks end with 4x the number of filters as they start with
-  filters_out = filters * 4 if bottleneck else filters
-
-  def projection_shortcut(inputs):
-    return conv2d_fixed_padding(
-        inputs=inputs, filters=filters_out, kernel_size=1, strides=strides,
-        data_format=data_format)
-
-  # Only the first block per block_layer uses projection_shortcut and strides
-  inputs = block_fn(inputs, filters, training, projection_shortcut, strides,
-                    data_format)
-
-  for _ in range(1, blocks):
-    inputs = block_fn(inputs, filters, training, None, 1, data_format)
-
-  return tf.identity(inputs, name)
-
-
-class Model(object):
-  """Base class for building the Resnet Model."""
-
-  def __init__(self, resnet_size, bottleneck, num_classes, num_filters,
-               kernel_size,
-               conv_stride, first_pool_size, first_pool_stride,
-               block_sizes, block_strides,
-               resnet_version=DEFAULT_VERSION, data_format=None,
-               dtype=DEFAULT_DTYPE):
-    """Creates a model for classifying an image.
-
-    Args:
-      resnet_size: A single integer for the size of the ResNet model.
-      bottleneck: Use regular blocks or bottleneck blocks.
-      num_classes: The number of classes used as labels.
-      num_filters: The number of filters to use for the first block layer
-        of the model. This number is then doubled for each subsequent block
-        layer.
-      kernel_size: The kernel size to use for convolution.
-      conv_stride: stride size for the initial convolutional layer
-      first_pool_size: Pool size to be used for the first pooling layer.
-        If none, the first pooling layer is skipped.
-      first_pool_stride: stride size for the first pooling layer. Not used
-        if first_pool_size is None.
-      block_sizes: A list containing n values, where n is the number of sets of
-        block layers desired. Each value should be the number of blocks in the
-        i-th set.
-      block_strides: List of integers representing the desired stride size for
-        each of the sets of block layers. Should be same length as block_sizes.
-      resnet_version: Integer representing which version of the ResNet network
-        to use. See README for details. Valid values: [1, 2]
-      data_format: Input format ('channels_last', 'channels_first', or None).
-        If set to None, the format is dependent on whether a GPU is available.
-      dtype: The TensorFlow dtype to use for calculations. If not specified
-        tf.float32 is used.
-
-    Raises:
-      ValueError: if invalid version is selected.
-    """
-    self.resnet_size = resnet_size
-
-    if not data_format:
-      data_format = ('channels_first' if tf.config.list_physical_devices('GPU')
-                     else 'channels_last')
-
-    self.resnet_version = resnet_version
-    if resnet_version not in (1, 2):
-      raise ValueError(
-          'Resnet version should be 1 or 2. See README for citations.')
-
-    self.bottleneck = bottleneck
-    if bottleneck:
-      if resnet_version == 1:
-        self.block_fn = _bottleneck_block_v1
-      else:
-        self.block_fn = _bottleneck_block_v2
-    else:
-      if resnet_version == 1:
-        self.block_fn = _building_block_v1
-      else:
-        self.block_fn = _building_block_v2
-
-    if dtype not in ALLOWED_TYPES:
-      raise ValueError('dtype must be one of: {}'.format(ALLOWED_TYPES))
-
-    self.data_format = data_format
-    self.num_classes = num_classes
-    self.num_filters = num_filters
-    self.kernel_size = kernel_size
-    self.conv_stride = conv_stride
-    self.first_pool_size = first_pool_size
-    self.first_pool_stride = first_pool_stride
-    self.block_sizes = block_sizes
-    self.block_strides = block_strides
-    self.dtype = dtype
-    self.pre_activation = resnet_version == 2
-
-  def _custom_dtype_getter(self, getter, name, shape=None, dtype=DEFAULT_DTYPE,
-                           *args, **kwargs):
-    """Creates variables in fp32, then casts to fp16 if necessary.
-
-    This function is a custom getter. A custom getter is a function with the
-    same signature as tf.get_variable, except it has an additional getter
-    parameter. Custom getters can be passed as the `custom_getter` parameter of
-    tf.variable_scope. Then, tf.get_variable will call the custom getter,
-    instead of directly getting a variable itself. This can be used to change
-    the types of variables that are retrieved with tf.get_variable.
-    The `getter` parameter is the underlying variable getter, that would have
-    been called if no custom getter was used. Custom getters typically get a
-    variable with `getter`, then modify it in some way.
-
-    This custom getter will create an fp32 variable. If a low precision
-    (e.g. float16) variable was requested it will then cast the variable to the
-    requested dtype. The reason we do not directly create variables in low
-    precision dtypes is that applying small gradients to such variables may
-    cause the variable not to change.
-
-    Args:
-      getter: The underlying variable getter, that has the same signature as
-        tf.get_variable and returns a variable.
-      name: The name of the variable to get.
-      shape: The shape of the variable to get.
-      dtype: The dtype of the variable to get. Note that if this is a low
-        precision dtype, the variable will be created as a tf.float32 variable,
-        then cast to the appropriate dtype
-      *args: Additional arguments to pass unmodified to getter.
-      **kwargs: Additional keyword arguments to pass unmodified to getter.
-
-    Returns:
-      A variable which is cast to fp16 if necessary.
-    """
-
-    if dtype in CASTABLE_TYPES:
-      var = getter(name, shape, tf.float32, *args, **kwargs)
-      return tf.cast(var, dtype=dtype, name=name + '_cast')
-    else:
-      return getter(name, shape, dtype, *args, **kwargs)
-
-  def _model_variable_scope(self):
-    """Returns a variable scope that the model should be created under.
-
-    If self.dtype is a castable type, model variable will be created in fp32
-    then cast to self.dtype before being used.
-
-    Returns:
-      A variable scope for the model.
-    """
-
-    return tf.compat.v1.variable_scope('resnet_model',
-                                       custom_getter=self._custom_dtype_getter)
-
-  def __call__(self, inputs, training):
-    """Add operations to classify a batch of input images.
-
-    Args:
-      inputs: A Tensor representing a batch of input images.
-      training: A boolean. Set to True to add operations required only when
-        training the classifier.
-
-    Returns:
-      A logits Tensor with shape [<batch_size>, self.num_classes].
-    """
-
-    with self._model_variable_scope():
-      if self.data_format == 'channels_first':
-        # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).
-        # This provides a large performance boost on GPU. See
-        # https://www.tensorflow.org/performance/performance_guide#data_formats
-        inputs = tf.transpose(a=inputs, perm=[0, 3, 1, 2])
-
-      inputs = conv2d_fixed_padding(
-          inputs=inputs, filters=self.num_filters, kernel_size=self.kernel_size,
-          strides=self.conv_stride, data_format=self.data_format)
-      inputs = tf.identity(inputs, 'initial_conv')
-
-      # We do not include batch normalization or activation functions in V2
-      # for the initial conv1 because the first ResNet unit will perform these
-      # for both the shortcut and non-shortcut paths as part of the first
-      # block's projection. Cf. Appendix of [2].
-      if self.resnet_version == 1:
-        inputs = batch_norm(inputs, training, self.data_format)
-        inputs = tf.nn.relu(inputs)
-
-      if self.first_pool_size:
-        inputs = tf.compat.v1.layers.max_pooling2d(
-            inputs=inputs, pool_size=self.first_pool_size,
-            strides=self.first_pool_stride, padding='SAME',
-            data_format=self.data_format)
-        inputs = tf.identity(inputs, 'initial_max_pool')
-
-      for i, num_blocks in enumerate(self.block_sizes):
-        num_filters = self.num_filters * (2**i)
-        inputs = block_layer(
-            inputs=inputs, filters=num_filters, bottleneck=self.bottleneck,
-            block_fn=self.block_fn, blocks=num_blocks,
-            strides=self.block_strides[i], training=training,
-            name='block_layer{}'.format(i + 1), data_format=self.data_format)
-
-      # Only apply the BN and ReLU for model that does pre_activation in each
-      # building/bottleneck block, eg resnet V2.
-      if self.pre_activation:
-        inputs = batch_norm(inputs, training, self.data_format)
-        inputs = tf.nn.relu(inputs)
-
-      # The current top layer has shape
-      # `batch_size x pool_size x pool_size x final_size`.
-      # ResNet does an Average Pooling layer over pool_size,
-      # but that is the same as doing a reduce_mean. We do a reduce_mean
-      # here because it performs better than AveragePooling2D.
-      axes = [2, 3] if self.data_format == 'channels_first' else [1, 2]
-      inputs = tf.reduce_mean(input_tensor=inputs, axis=axes, keepdims=True)
-      inputs = tf.identity(inputs, 'final_reduce_mean')
-
-      inputs = tf.squeeze(inputs, axes)
-      inputs = tf.compat.v1.layers.dense(inputs=inputs, units=self.num_classes)
-      inputs = tf.identity(inputs, 'final_dense')
-      return inputs
diff --git a/official/r1/resnet/resnet_run_loop.py b/official/r1/resnet/resnet_run_loop.py
deleted file mode 100644
index 5c90d855..00000000
--- a/official/r1/resnet/resnet_run_loop.py
+++ /dev/null
@@ -1,831 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Contains utility and supporting functions for ResNet.
-
-  This module contains ResNet code which does not directly build layers. This
-includes dataset management, hyperparameter and optimizer code, and argument
-parsing. Code for defining the ResNet layers can be found in resnet_model.py.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import functools
-import math
-import multiprocessing
-import os
-
-from absl import flags
-from absl import logging
-import tensorflow as tf
-
-from official.r1.resnet import imagenet_preprocessing
-from official.r1.resnet import resnet_model
-from official.r1.utils import export
-from official.r1.utils.logs import hooks_helper
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-from official.utils.misc import distribution_utils
-from official.utils.misc import model_helpers
-
-
-################################################################################
-# Functions for input processing.
-################################################################################
-def process_record_dataset(dataset,
-                           is_training,
-                           batch_size,
-                           shuffle_buffer,
-                           parse_record_fn,
-                           num_epochs=1,
-                           dtype=tf.float32,
-                           datasets_num_private_threads=None,
-                           drop_remainder=False,
-                           tf_data_experimental_slack=False):
-  """Given a Dataset with raw records, return an iterator over the records.
-
-  Args:
-    dataset: A Dataset representing raw records
-    is_training: A boolean denoting whether the input is for training.
-    batch_size: The number of samples per batch.
-    shuffle_buffer: The buffer size to use when shuffling records. A larger
-      value results in better randomness, but smaller values reduce startup
-      time and use less memory.
-    parse_record_fn: A function that takes a raw record and returns the
-      corresponding (image, label) pair.
-    num_epochs: The number of epochs to repeat the dataset.
-    dtype: Data type to use for images/features.
-    datasets_num_private_threads: Number of threads for a private
-      threadpool created for all datasets computation.
-    drop_remainder: A boolean indicates whether to drop the remainder of the
-      batches. If True, the batch dimension will be static.
-    tf_data_experimental_slack: Whether to enable tf.data's
-      `experimental_slack` option.
-
-  Returns:
-    Dataset of (image, label) pairs ready for iteration.
-  """
-  # Defines a specific size thread pool for tf.data operations.
-  if datasets_num_private_threads:
-    options = tf.data.Options()
-    options.experimental_threading.private_threadpool_size = (
-        datasets_num_private_threads)
-    dataset = dataset.with_options(options)
-    logging.info('datasets_num_private_threads: %s',
-                 datasets_num_private_threads)
-
-  # Disable intra-op parallelism to optimize for throughput instead of latency.
-  options = tf.data.Options()
-  options.experimental_threading.max_intra_op_parallelism = 1
-  dataset = dataset.with_options(options)
-
-  # Prefetches a batch at a time to smooth out the time taken to load input
-  # files for shuffling and processing.
-  dataset = dataset.prefetch(buffer_size=batch_size)
-  if is_training:
-    # Shuffles records before repeating to respect epoch boundaries.
-    dataset = dataset.shuffle(buffer_size=shuffle_buffer)
-
-  # Repeats the dataset for the number of epochs to train.
-  dataset = dataset.repeat(num_epochs)
-
-  # Parses the raw records into images and labels.
-  dataset = dataset.map(
-      lambda value: parse_record_fn(value, is_training, dtype),
-      num_parallel_calls=tf.data.experimental.AUTOTUNE)
-  dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)
-
-  # Operations between the final prefetch and the get_next call to the iterator
-  # will happen synchronously during run time. We prefetch here again to
-  # background all of the above processing work and keep it out of the
-  # critical training path. Setting buffer_size to tf.data.experimental.AUTOTUNE
-  # allows DistributionStrategies to adjust how many batches to fetch based
-  # on how many devices are present.
-  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
-
-  if tf_data_experimental_slack:
-    options = tf.data.Options()
-    options.experimental_slack = True
-    dataset = dataset.with_options(options)
-
-  return dataset
-
-
-def get_synth_input_fn(height, width, num_channels, num_classes,
-                       dtype=tf.float32):
-  """Returns an input function that returns a dataset with random data.
-
-  This input_fn returns a data set that iterates over a set of random data and
-  bypasses all preprocessing, e.g. jpeg decode and copy. The host to device
-  copy is still included. This used to find the upper throughput bound when
-  tunning the full input pipeline.
-
-  Args:
-    height: Integer height that will be used to create a fake image tensor.
-    width: Integer width that will be used to create a fake image tensor.
-    num_channels: Integer depth that will be used to create a fake image tensor.
-    num_classes: Number of classes that should be represented in the fake labels
-      tensor
-    dtype: Data type for features/images.
-
-  Returns:
-    An input_fn that can be used in place of a real one to return a dataset
-    that can be used for iteration.
-  """
-  # pylint: disable=unused-argument
-  def input_fn(is_training, data_dir, batch_size, *args, **kwargs):
-    """Returns dataset filled with random data."""
-    # Synthetic input should be within [0, 255].
-    inputs = tf.random.truncated_normal(
-        [batch_size] + [height, width, num_channels],
-        dtype=dtype,
-        mean=127,
-        stddev=60,
-        name='synthetic_inputs')
-
-    labels = tf.random.uniform(
-        [batch_size],
-        minval=0,
-        maxval=num_classes - 1,
-        dtype=tf.int32,
-        name='synthetic_labels')
-    data = tf.data.Dataset.from_tensors((inputs, labels)).repeat()
-    data = data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
-    return data
-
-  return input_fn
-
-
-def image_bytes_serving_input_fn(image_shape, dtype=tf.float32):
-  """Serving input fn for raw jpeg images."""
-
-  def _preprocess_image(image_bytes):
-    """Preprocess a single raw image."""
-    # Bounding box around the whole image.
-    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=dtype, shape=[1, 1, 4])
-    height, width, num_channels = image_shape
-    image = imagenet_preprocessing.preprocess_image(
-        image_bytes, bbox, height, width, num_channels, is_training=False)
-    return image
-
-  image_bytes_list = tf.compat.v1.placeholder(
-      shape=[None], dtype=tf.string, name='input_tensor')
-  images = tf.map_fn(
-      _preprocess_image, image_bytes_list, back_prop=False, dtype=dtype)
-  return tf.estimator.export.TensorServingInputReceiver(
-      images, {'image_bytes': image_bytes_list})
-
-
-def override_flags_and_set_envars_for_gpu_thread_pool(flags_obj):
-  """Override flags and set env_vars for performance.
-
-  These settings exist to test the difference between using stock settings
-  and manual tuning. It also shows some of the ENV_VARS that can be tweaked to
-  squeeze a few extra examples per second.  These settings are defaulted to the
-  current platform of interest, which changes over time.
-
-  On systems with small numbers of cpu cores, e.g. under 8 logical cores,
-  setting up a gpu thread pool with `tf_gpu_thread_mode=gpu_private` may perform
-  poorly.
-
-  Args:
-    flags_obj: Current flags, which will be adjusted possibly overriding
-    what has been set by the user on the command-line.
-  """
-  cpu_count = multiprocessing.cpu_count()
-  logging.info('Logical CPU cores: %s', cpu_count)
-
-  # Sets up thread pool for each GPU for op scheduling.
-  per_gpu_thread_count = 1
-  total_gpu_thread_count = per_gpu_thread_count * flags_obj.num_gpus
-  os.environ['TF_GPU_THREAD_MODE'] = flags_obj.tf_gpu_thread_mode
-  os.environ['TF_GPU_THREAD_COUNT'] = str(per_gpu_thread_count)
-  logging.info('TF_GPU_THREAD_COUNT: %s', os.environ['TF_GPU_THREAD_COUNT'])
-  logging.info('TF_GPU_THREAD_MODE: %s', os.environ['TF_GPU_THREAD_MODE'])
-
-  # Reduces general thread pool by number of threads used for GPU pool.
-  main_thread_count = cpu_count - total_gpu_thread_count
-  flags_obj.inter_op_parallelism_threads = main_thread_count
-
-  # Sets thread count for tf.data. Logical cores minus threads assign to the
-  # private GPU pool along with 2 thread per GPU for event monitoring and
-  # sending / receiving tensors.
-  num_monitoring_threads = 2 * flags_obj.num_gpus
-  flags_obj.datasets_num_private_threads = (cpu_count - total_gpu_thread_count
-                                            - num_monitoring_threads)
-
-
-################################################################################
-# Functions for running training/eval/validation loops for the model.
-################################################################################
-def learning_rate_with_decay(
-    batch_size, batch_denom, num_images, boundary_epochs, decay_rates,
-    base_lr=0.1, warmup=False):
-  """Get a learning rate that decays step-wise as training progresses.
-
-  Args:
-    batch_size: the number of examples processed in each training batch.
-    batch_denom: this value will be used to scale the base learning rate.
-      `0.1 * batch size` is divided by this number, such that when
-      batch_denom == batch_size, the initial learning rate will be 0.1.
-    num_images: total number of images that will be used for training.
-    boundary_epochs: list of ints representing the epochs at which we
-      decay the learning rate.
-    decay_rates: list of floats representing the decay rates to be used
-      for scaling the learning rate. It should have one more element
-      than `boundary_epochs`, and all elements should have the same type.
-    base_lr: Initial learning rate scaled based on batch_denom.
-    warmup: Run a 5 epoch warmup to the initial lr.
-  Returns:
-    Returns a function that takes a single argument - the number of batches
-    trained so far (global_step)- and returns the learning rate to be used
-    for training the next batch.
-  """
-  initial_learning_rate = base_lr * batch_size / batch_denom
-  batches_per_epoch = num_images / batch_size
-
-  # Reduce the learning rate at certain epochs.
-  # CIFAR-10: divide by 10 at epoch 100, 150, and 200
-  # ImageNet: divide by 10 at epoch 30, 60, 80, and 90
-  boundaries = [int(batches_per_epoch * epoch) for epoch in boundary_epochs]
-  vals = [initial_learning_rate * decay for decay in decay_rates]
-
-  def learning_rate_fn(global_step):
-    """Builds scaled learning rate function with 5 epoch warm up."""
-    lr = tf.compat.v1.train.piecewise_constant(global_step, boundaries, vals)
-    if warmup:
-      warmup_steps = int(batches_per_epoch * 5)
-      warmup_lr = (
-          initial_learning_rate * tf.cast(global_step, tf.float32) / tf.cast(
-              warmup_steps, tf.float32))
-      return tf.cond(pred=global_step < warmup_steps,
-                     true_fn=lambda: warmup_lr,
-                     false_fn=lambda: lr)
-    return lr
-
-  def poly_rate_fn(global_step):
-    """Handles linear scaling rule, gradual warmup, and LR decay.
-
-    The learning rate starts at 0, then it increases linearly per step.  After
-    FLAGS.poly_warmup_epochs, we reach the base learning rate (scaled to account
-    for batch size). The learning rate is then decayed using a polynomial rate
-    decay schedule with power 2.0.
-
-    Args:
-      global_step: the current global_step
-
-    Returns:
-      returns the current learning rate
-    """
-
-    # Learning rate schedule for LARS polynomial schedule
-    if flags.FLAGS.batch_size < 8192:
-      plr = 5.0
-      w_epochs = 5
-    elif flags.FLAGS.batch_size < 16384:
-      plr = 10.0
-      w_epochs = 5
-    elif flags.FLAGS.batch_size < 32768:
-      plr = 25.0
-      w_epochs = 5
-    else:
-      plr = 32.0
-      w_epochs = 14
-
-    w_steps = int(w_epochs * batches_per_epoch)
-    wrate = (plr * tf.cast(global_step, tf.float32) / tf.cast(
-        w_steps, tf.float32))
-
-    # TODO(pkanwar): use a flag to help calc num_epochs.
-    num_epochs = 90
-    train_steps = batches_per_epoch * num_epochs
-
-    min_step = tf.constant(1, dtype=tf.int64)
-    decay_steps = tf.maximum(min_step, tf.subtract(global_step, w_steps))
-    poly_rate = tf.train.polynomial_decay(
-        plr,
-        decay_steps,
-        train_steps - w_steps + 1,
-        power=2.0)
-    return tf.where(global_step <= w_steps, wrate, poly_rate)
-
-  # For LARS we have a new learning rate schedule
-  if flags.FLAGS.enable_lars:
-    return poly_rate_fn
-
-  return learning_rate_fn
-
-
-def per_replica_batch_size(batch_size, num_gpus):
-  """For multi-gpu, batch-size must be a multiple of the number of GPUs.
-
-
-  Note that distribution strategy handles this automatically when used with
-  Keras. For using with Estimator, we need to get per GPU batch.
-
-  Args:
-    batch_size: Global batch size to be divided among devices. This should be
-      equal to num_gpus times the single-GPU batch_size for multi-gpu training.
-    num_gpus: How many GPUs are used with DistributionStrategies.
-
-  Returns:
-    Batch size per device.
-
-  Raises:
-    ValueError: if batch_size is not divisible by number of devices
-  """
-  if num_gpus <= 1:
-    return batch_size
-
-  remainder = batch_size % num_gpus
-  if remainder:
-    err = ('When running with multiple GPUs, batch size '
-           'must be a multiple of the number of available GPUs. Found {} '
-           'GPUs with a batch size of {}; try --batch_size={} instead.'
-          ).format(num_gpus, batch_size, batch_size - remainder)
-    raise ValueError(err)
-  return int(batch_size / num_gpus)
-
-
-def resnet_model_fn(features, labels, mode, model_class,
-                    resnet_size, weight_decay, learning_rate_fn, momentum,
-                    data_format, resnet_version, loss_scale,
-                    loss_filter_fn=None, dtype=resnet_model.DEFAULT_DTYPE,
-                    fine_tune=False, label_smoothing=0.0):
-  """Shared functionality for different resnet model_fns.
-
-  Initializes the ResnetModel representing the model layers
-  and uses that model to build the necessary EstimatorSpecs for
-  the `mode` in question. For training, this means building losses,
-  the optimizer, and the train op that get passed into the EstimatorSpec.
-  For evaluation and prediction, the EstimatorSpec is returned without
-  a train op, but with the necessary parameters for the given mode.
-
-  Args:
-    features: tensor representing input images
-    labels: tensor representing class labels for all input images
-    mode: current estimator mode; should be one of
-      `tf.estimator.ModeKeys.TRAIN`, `EVALUATE`, `PREDICT`
-    model_class: a class representing a TensorFlow model that has a __call__
-      function. We assume here that this is a subclass of ResnetModel.
-    resnet_size: A single integer for the size of the ResNet model.
-    weight_decay: weight decay loss rate used to regularize learned variables.
-    learning_rate_fn: function that returns the current learning rate given
-      the current global_step
-    momentum: momentum term used for optimization
-    data_format: Input format ('channels_last', 'channels_first', or None).
-      If set to None, the format is dependent on whether a GPU is available.
-    resnet_version: Integer representing which version of the ResNet network to
-      use. See README for details. Valid values: [1, 2]
-    loss_scale: The factor to scale the loss for numerical stability. A detailed
-      summary is present in the arg parser help text.
-    loss_filter_fn: function that takes a string variable name and returns
-      True if the var should be included in loss calculation, and False
-      otherwise. If None, batch_normalization variables will be excluded
-      from the loss.
-    dtype: the TensorFlow dtype to use for calculations.
-    fine_tune: If True only train the dense layers(final layers).
-    label_smoothing: If greater than 0 then smooth the labels.
-
-  Returns:
-    EstimatorSpec parameterized according to the input params and the
-    current mode.
-  """
-
-  # Generate a summary node for the images
-  tf.compat.v1.summary.image('images', features, max_outputs=6)
-  # Checks that features/images have same data type being used for calculations.
-  assert features.dtype == dtype
-
-  model = model_class(resnet_size, data_format, resnet_version=resnet_version,
-                      dtype=dtype)
-
-  logits = model(features, mode == tf.estimator.ModeKeys.TRAIN)
-
-  # This acts as a no-op if the logits are already in fp32 (provided logits are
-  # not a SparseTensor). If dtype is is low precision, logits must be cast to
-  # fp32 for numerical stability.
-  logits = tf.cast(logits, tf.float32)
-
-  predictions = {
-      'classes': tf.argmax(input=logits, axis=1),
-      'probabilities': tf.nn.softmax(logits, name='softmax_tensor')
-  }
-
-  if mode == tf.estimator.ModeKeys.PREDICT:
-    # Return the predictions and the specification for serving a SavedModel
-    return tf.estimator.EstimatorSpec(
-        mode=mode,
-        predictions=predictions,
-        export_outputs={
-            'predict': tf.estimator.export.PredictOutput(predictions)
-        })
-
-  # Calculate loss, which includes softmax cross entropy and L2 regularization.
-  if label_smoothing != 0.0:
-    one_hot_labels = tf.one_hot(labels, 1001)
-    cross_entropy = tf.losses.softmax_cross_entropy(
-        logits=logits, onehot_labels=one_hot_labels,
-        label_smoothing=label_smoothing)
-  else:
-    cross_entropy = tf.compat.v1.losses.sparse_softmax_cross_entropy(
-        logits=logits, labels=labels)
-
-  # Create a tensor named cross_entropy for logging purposes.
-  tf.identity(cross_entropy, name='cross_entropy')
-  tf.compat.v1.summary.scalar('cross_entropy', cross_entropy)
-
-  # If no loss_filter_fn is passed, assume we want the default behavior,
-  # which is that batch_normalization variables are excluded from loss.
-  def exclude_batch_norm(name):
-    return 'batch_normalization' not in name
-  loss_filter_fn = loss_filter_fn or exclude_batch_norm
-
-  # Add weight decay to the loss.
-  l2_loss = weight_decay * tf.add_n(
-      # loss is computed using fp32 for numerical stability.
-      [
-          tf.nn.l2_loss(tf.cast(v, tf.float32))
-          for v in tf.compat.v1.trainable_variables()
-          if loss_filter_fn(v.name)
-      ])
-  tf.compat.v1.summary.scalar('l2_loss', l2_loss)
-  loss = cross_entropy + l2_loss
-
-  if mode == tf.estimator.ModeKeys.TRAIN:
-    global_step = tf.compat.v1.train.get_or_create_global_step()
-
-    learning_rate = learning_rate_fn(global_step)
-
-    # Create a tensor named learning_rate for logging purposes
-    tf.identity(learning_rate, name='learning_rate')
-    tf.compat.v1.summary.scalar('learning_rate', learning_rate)
-
-    if flags.FLAGS.enable_lars:
-      from tensorflow.contrib import opt as contrib_opt  # pylint: disable=g-import-not-at-top
-      optimizer = contrib_opt.LARSOptimizer(
-          learning_rate,
-          momentum=momentum,
-          weight_decay=weight_decay,
-          skip_list=['batch_normalization', 'bias'])
-    else:
-      optimizer = tf.compat.v1.train.MomentumOptimizer(
-          learning_rate=learning_rate,
-          momentum=momentum
-      )
-
-    fp16_implementation = getattr(flags.FLAGS, 'fp16_implementation', None)
-    if fp16_implementation == 'graph_rewrite':
-      optimizer = (
-          tf.compat.v1.train.experimental.enable_mixed_precision_graph_rewrite(
-              optimizer, loss_scale=loss_scale))
-
-    def _dense_grad_filter(gvs):
-      """Only apply gradient updates to the final layer.
-
-      This function is used for fine tuning.
-
-      Args:
-        gvs: list of tuples with gradients and variable info
-      Returns:
-        filtered gradients so that only the dense layer remains
-      """
-      return [(g, v) for g, v in gvs if 'dense' in v.name]
-
-    if loss_scale != 1 and fp16_implementation != 'graph_rewrite':
-      # When computing fp16 gradients, often intermediate tensor values are
-      # so small, they underflow to 0. To avoid this, we multiply the loss by
-      # loss_scale to make these tensor values loss_scale times bigger.
-      scaled_grad_vars = optimizer.compute_gradients(loss * loss_scale)
-
-      if fine_tune:
-        scaled_grad_vars = _dense_grad_filter(scaled_grad_vars)
-
-      # Once the gradient computation is complete we can scale the gradients
-      # back to the correct scale before passing them to the optimizer.
-      unscaled_grad_vars = [(grad / loss_scale, var)
-                            for grad, var in scaled_grad_vars]
-      minimize_op = optimizer.apply_gradients(unscaled_grad_vars, global_step)
-    else:
-      grad_vars = optimizer.compute_gradients(loss)
-      if fine_tune:
-        grad_vars = _dense_grad_filter(grad_vars)
-      minimize_op = optimizer.apply_gradients(grad_vars, global_step)
-
-    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)
-    train_op = tf.group(minimize_op, update_ops)
-  else:
-    train_op = None
-
-  accuracy = tf.compat.v1.metrics.accuracy(labels, predictions['classes'])
-  accuracy_top_5 = tf.compat.v1.metrics.mean(
-      tf.nn.in_top_k(predictions=logits, targets=labels, k=5, name='top_5_op'))
-  metrics = {'accuracy': accuracy,
-             'accuracy_top_5': accuracy_top_5}
-
-  # Create a tensor named train_accuracy for logging purposes
-  tf.identity(accuracy[1], name='train_accuracy')
-  tf.identity(accuracy_top_5[1], name='train_accuracy_top_5')
-  tf.compat.v1.summary.scalar('train_accuracy', accuracy[1])
-  tf.compat.v1.summary.scalar('train_accuracy_top_5', accuracy_top_5[1])
-
-  return tf.estimator.EstimatorSpec(
-      mode=mode,
-      predictions=predictions,
-      loss=loss,
-      train_op=train_op,
-      eval_metric_ops=metrics)
-
-
-def resnet_main(
-    flags_obj, model_function, input_function, dataset_name, shape=None):
-  """Shared main loop for ResNet Models.
-
-  Args:
-    flags_obj: An object containing parsed flags. See define_resnet_flags()
-      for details.
-    model_function: the function that instantiates the Model and builds the
-      ops for train/eval. This will be passed directly into the estimator.
-    input_function: the function that processes the dataset and returns a
-      dataset that the estimator can train on. This will be wrapped with
-      all the relevant flags for running and passed to estimator.
-    dataset_name: the name of the dataset for training and evaluation. This is
-      used for logging purpose.
-    shape: list of ints representing the shape of the images used for training.
-      This is only used if flags_obj.export_dir is passed.
-
-  Returns:
-     Dict of results of the run.  Contains the keys `eval_results` and
-    `train_hooks`. `eval_results` contains accuracy (top_1) and accuracy_top_5.
-    `train_hooks` is a list the instances of hooks used during training.
-  """
-
-  model_helpers.apply_clean(flags.FLAGS)
-
-  # Ensures flag override logic is only executed if explicitly triggered.
-  if flags_obj.tf_gpu_thread_mode:
-    override_flags_and_set_envars_for_gpu_thread_pool(flags_obj)
-
-  # Configures cluster spec for distribution strategy.
-  num_workers = distribution_utils.configure_cluster(flags_obj.worker_hosts,
-                                                     flags_obj.task_index)
-
-  # Creates session config. allow_soft_placement = True, is required for
-  # multi-GPU and is not harmful for other modes.
-  session_config = tf.compat.v1.ConfigProto(
-      inter_op_parallelism_threads=flags_obj.inter_op_parallelism_threads,
-      intra_op_parallelism_threads=flags_obj.intra_op_parallelism_threads,
-      allow_soft_placement=True)
-
-  distribution_strategy = distribution_utils.get_distribution_strategy(
-      distribution_strategy=flags_obj.distribution_strategy,
-      num_gpus=flags_core.get_num_gpus(flags_obj),
-      all_reduce_alg=flags_obj.all_reduce_alg,
-      num_packs=flags_obj.num_packs)
-
-  # Creates a `RunConfig` that checkpoints every 24 hours which essentially
-  # results in checkpoints determined only by `epochs_between_evals`.
-  run_config = tf.estimator.RunConfig(
-      train_distribute=distribution_strategy,
-      session_config=session_config,
-      save_checkpoints_secs=60*60*24,
-      save_checkpoints_steps=None)
-
-  # Initializes model with all but the dense layer from pretrained ResNet.
-  if flags_obj.pretrained_model_checkpoint_path is not None:
-    warm_start_settings = tf.estimator.WarmStartSettings(
-        flags_obj.pretrained_model_checkpoint_path,
-        vars_to_warm_start='^(?!.*dense)')
-  else:
-    warm_start_settings = None
-
-  classifier = tf.estimator.Estimator(
-      model_fn=model_function, model_dir=flags_obj.model_dir, config=run_config,
-      warm_start_from=warm_start_settings, params={
-          'resnet_size': int(flags_obj.resnet_size),
-          'data_format': flags_obj.data_format,
-          'batch_size': flags_obj.batch_size,
-          'resnet_version': int(flags_obj.resnet_version),
-          'loss_scale': flags_core.get_loss_scale(flags_obj,
-                                                  default_for_fp16=128),
-          'dtype': flags_core.get_tf_dtype(flags_obj),
-          'fine_tune': flags_obj.fine_tune,
-          'num_workers': num_workers,
-      })
-
-  run_params = {
-      'batch_size': flags_obj.batch_size,
-      'dtype': flags_core.get_tf_dtype(flags_obj),
-      'resnet_size': flags_obj.resnet_size,
-      'resnet_version': flags_obj.resnet_version,
-      'synthetic_data': flags_obj.use_synthetic_data,
-      'train_epochs': flags_obj.train_epochs,
-      'num_workers': num_workers,
-  }
-  if flags_obj.use_synthetic_data:
-    dataset_name = dataset_name + '-synthetic'
-
-  benchmark_logger = logger.get_benchmark_logger()
-  benchmark_logger.log_run_info('resnet', dataset_name, run_params,
-                                test_id=flags_obj.benchmark_test_id)
-
-  train_hooks = hooks_helper.get_train_hooks(
-      flags_obj.hooks,
-      model_dir=flags_obj.model_dir,
-      batch_size=flags_obj.batch_size)
-
-  def input_fn_train(num_epochs, input_context=None):
-    return input_function(
-        is_training=True,
-        data_dir=flags_obj.data_dir,
-        batch_size=per_replica_batch_size(
-            flags_obj.batch_size, flags_core.get_num_gpus(flags_obj)),
-        num_epochs=num_epochs,
-        dtype=flags_core.get_tf_dtype(flags_obj),
-        datasets_num_private_threads=flags_obj.datasets_num_private_threads,
-        input_context=input_context)
-
-  def input_fn_eval():
-    return input_function(
-        is_training=False,
-        data_dir=flags_obj.data_dir,
-        batch_size=per_replica_batch_size(
-            flags_obj.batch_size, flags_core.get_num_gpus(flags_obj)),
-        num_epochs=1,
-        dtype=flags_core.get_tf_dtype(flags_obj))
-
-  train_epochs = (0 if flags_obj.eval_only or not flags_obj.train_epochs else
-                  flags_obj.train_epochs)
-
-  use_train_and_evaluate = flags_obj.use_train_and_evaluate or num_workers > 1
-  if use_train_and_evaluate:
-    train_spec = tf.estimator.TrainSpec(
-        input_fn=lambda input_context=None: input_fn_train(
-            train_epochs, input_context=input_context),
-        hooks=train_hooks,
-        max_steps=flags_obj.max_train_steps)
-    eval_spec = tf.estimator.EvalSpec(input_fn=input_fn_eval)
-    logging.info('Starting to train and evaluate.')
-    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)
-    # tf.estimator.train_and_evalute doesn't return anything in multi-worker
-    # case.
-    eval_results = {}
-  else:
-    if train_epochs == 0:
-      # If --eval_only is set, perform a single loop with zero train epochs.
-      schedule, n_loops = [0], 1
-    else:
-      # Compute the number of times to loop while training. All but the last
-      # pass will train for `epochs_between_evals` epochs, while the last will
-      # train for the number needed to reach `training_epochs`. For instance if
-      #   train_epochs = 25 and epochs_between_evals = 10
-      # schedule will be set to [10, 10, 5]. That is to say, the loop will:
-      #   Train for 10 epochs and then evaluate.
-      #   Train for another 10 epochs and then evaluate.
-      #   Train for a final 5 epochs (to reach 25 epochs) and then evaluate.
-      n_loops = math.ceil(train_epochs / flags_obj.epochs_between_evals)
-      schedule = [flags_obj.epochs_between_evals for _ in range(int(n_loops))]
-      schedule[-1] = train_epochs - sum(schedule[:-1])  # over counting.
-
-    for cycle_index, num_train_epochs in enumerate(schedule):
-      logging.info('Starting cycle: %d/%d', cycle_index, int(n_loops))
-
-      if num_train_epochs:
-        # Since we are calling classifier.train immediately in each loop, the
-        # value of num_train_epochs in the lambda function will not be changed
-        # before it is used. So it is safe to ignore the pylint error here
-        # pylint: disable=cell-var-from-loop
-        classifier.train(
-            input_fn=lambda input_context=None: input_fn_train(
-                num_train_epochs, input_context=input_context),
-            hooks=train_hooks,
-            max_steps=flags_obj.max_train_steps)
-
-      # flags_obj.max_train_steps is generally associated with testing and
-      # profiling. As a result it is frequently called with synthetic data,
-      # which will iterate forever. Passing steps=flags_obj.max_train_steps
-      # allows the eval (which is generally unimportant in those circumstances)
-      # to terminate.  Note that eval will run for max_train_steps each loop,
-      # regardless of the global_step count.
-      logging.info('Starting to evaluate.')
-      eval_results = classifier.evaluate(input_fn=input_fn_eval,
-                                         steps=flags_obj.max_train_steps)
-
-      benchmark_logger.log_evaluation_result(eval_results)
-
-      if model_helpers.past_stop_threshold(
-          flags_obj.stop_threshold, eval_results['accuracy']):
-        break
-
-  if flags_obj.export_dir is not None:
-    # Exports a saved model for the given classifier.
-    export_dtype = flags_core.get_tf_dtype(flags_obj)
-    if flags_obj.image_bytes_as_serving_input:
-      input_receiver_fn = functools.partial(
-          image_bytes_serving_input_fn, shape, dtype=export_dtype)
-    else:
-      input_receiver_fn = export.build_tensor_serving_input_receiver_fn(
-          shape, batch_size=flags_obj.batch_size, dtype=export_dtype)
-    classifier.export_savedmodel(flags_obj.export_dir, input_receiver_fn,
-                                 strip_default_attrs=True)
-
-  stats = {}
-  stats['eval_results'] = eval_results
-  stats['train_hooks'] = train_hooks
-
-  return stats
-
-
-def define_resnet_flags(resnet_size_choices=None, dynamic_loss_scale=False,
-                        fp16_implementation=False):
-  """Add flags and validators for ResNet."""
-  flags_core.define_base(clean=True, train_epochs=True,
-                         epochs_between_evals=True, stop_threshold=True,
-                         num_gpu=True, hooks=True, export_dir=True,
-                         distribution_strategy=True)
-  flags_core.define_performance(num_parallel_calls=False,
-                                inter_op=True,
-                                intra_op=True,
-                                synthetic_data=True,
-                                dtype=True,
-                                all_reduce_alg=True,
-                                num_packs=True,
-                                tf_gpu_thread_mode=True,
-                                datasets_num_private_threads=True,
-                                dynamic_loss_scale=dynamic_loss_scale,
-                                fp16_implementation=fp16_implementation,
-                                loss_scale=True,
-                                tf_data_experimental_slack=True,
-                                max_train_steps=True)
-  flags_core.define_image()
-  flags_core.define_benchmark()
-  flags_core.define_distribution()
-  flags.adopt_module_key_flags(flags_core)
-
-  flags.DEFINE_enum(
-      name='resnet_version', short_name='rv', default='1',
-      enum_values=['1', '2'],
-      help=flags_core.help_wrap(
-          'Version of ResNet. (1 or 2) See README.md for details.'))
-  flags.DEFINE_bool(
-      name='fine_tune', short_name='ft', default=False,
-      help=flags_core.help_wrap(
-          'If True do not train any parameters except for the final layer.'))
-  flags.DEFINE_string(
-      name='pretrained_model_checkpoint_path', short_name='pmcp', default=None,
-      help=flags_core.help_wrap(
-          'If not None initialize all the network except the final layer with '
-          'these values'))
-  flags.DEFINE_boolean(
-      name='eval_only', default=False,
-      help=flags_core.help_wrap('Skip training and only perform evaluation on '
-                                'the latest checkpoint.'))
-  flags.DEFINE_boolean(
-      name='image_bytes_as_serving_input', default=False,
-      help=flags_core.help_wrap(
-          'If True exports savedmodel with serving signature that accepts '
-          'JPEG image bytes instead of a fixed size [HxWxC] tensor that '
-          'represents the image. The former is easier to use for serving at '
-          'the expense of image resize/cropping being done as part of model '
-          'inference. Note, this flag only applies to ImageNet and cannot '
-          'be used for CIFAR.'))
-  flags.DEFINE_boolean(
-      name='use_train_and_evaluate', default=False,
-      help=flags_core.help_wrap(
-          'If True, uses `tf.estimator.train_and_evaluate` for the training '
-          'and evaluation loop, instead of separate calls to `classifier.train '
-          'and `classifier.evaluate`, which is the default behavior.'))
-  flags.DEFINE_bool(
-      name='enable_lars', default=False,
-      help=flags_core.help_wrap(
-          'Enable LARS optimizer for large batch training.'))
-  flags.DEFINE_float(
-      name='label_smoothing', default=0.0,
-      help=flags_core.help_wrap(
-          'Label smoothing parameter used in the softmax_cross_entropy'))
-  flags.DEFINE_float(
-      name='weight_decay', default=1e-4,
-      help=flags_core.help_wrap(
-          'Weight decay coefficiant for l2 regularization.'))
-
-  choice_kwargs = dict(
-      name='resnet_size', short_name='rs', default='50',
-      help=flags_core.help_wrap('The size of the ResNet model to use.'))
-
-  if resnet_size_choices is None:
-    flags.DEFINE_string(**choice_kwargs)
-  else:
-    flags.DEFINE_enum(enum_values=resnet_size_choices, **choice_kwargs)
diff --git a/official/r1/transformer/README.md b/official/r1/transformer/README.md
deleted file mode 100644
index c680f8b3..00000000
--- a/official/r1/transformer/README.md
+++ /dev/null
@@ -1,380 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# Transformer Translation Model
-This is an implementation of the Transformer translation model as described in the [Attention is All You Need](https://arxiv.org/abs/1706.03762) paper. Based on the code provided by the authors: [Transformer code](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py) from [Tensor2Tensor](https://github.com/tensorflow/tensor2tensor). Also, check out the [tutorial](https://www.tensorflow.org/beta/tutorials/text/transformer) on Transformer in TF 2.0.
-
-**Please follow the [README](https://github.com/tensorflow/models/official/transformer/README.md), the new Keras-based TF 2 implementation, to walk through the new Transformer.**
-
-Transformer is a neural network architecture that solves sequence to sequence problems using attention mechanisms. Unlike traditional neural seq2seq models, Transformer does not involve recurrent connections. The attention mechanism learns dependencies between tokens in two sequences. Since attention weights apply to all tokens in the sequences, the Transformer model is able to easily capture long-distance dependencies.
-
-Transformer's overall structure follows the standard encoder-decoder pattern. The encoder uses self-attention to compute a representation of the input sequence. The decoder generates the output sequence one token at a time, taking the encoder output and previous decoder-outputted tokens as inputs.
-
-The model also applies embeddings on the input and output tokens, and adds a constant positional encoding. The positional encoding adds information about the position of each token.
-
-## Contents
-  * [Contents](#contents)
-  * [Walkthrough](#walkthrough)
-  * [Benchmarks](#benchmarks)
-    * [Training times](#training-times)
-    * [Evaluation results](#evaluation-results)
-  * [Detailed instructions](#detailed-instructions)
-    * [Environment preparation](#environment-preparation)
-    * [Download and preprocess datasets](#download-and-preprocess-datasets)
-    * [Model training and evaluation](#model-training-and-evaluation)
-    * [Translate using the model](#translate-using-the-model)
-    * [Compute official BLEU score](#compute-official-bleu-score)
-    * [TPU](#tpu)
-  * [Export trained model](#export-trained-model)
-    * [Example translation](#example-translation)
-  * [Implementation overview](#implementation-overview)
-    * [Model Definition](#model-definition)
-    * [Model Estimator](#model-estimator)
-    * [Other scripts](#other-scripts)
-    * [Test dataset](#test-dataset)
-  * [Term definitions](#term-definitions)
-
-## Walkthrough
-
-Below are the commands for running the Transformer model. See the
-[Detailed instructions](#detailed-instructions) for more details on running the
-model.
-
-```
-cd /path/to/models/official/transformer
-
-# Ensure that PYTHONPATH is correctly defined as described in
-# https://github.com/tensorflow/models/tree/master/official#requirements
-# export PYTHONPATH="$PYTHONPATH:/path/to/models"
-
-# Export variables
-PARAM_SET=big
-DATA_DIR=$HOME/transformer/data
-MODEL_DIR=$HOME/transformer/model_$PARAM_SET
-VOCAB_FILE=$DATA_DIR/vocab.ende.32768
-
-# Download training/evaluation/test datasets
-python data_download.py --data_dir=$DATA_DIR
-
-# Train the model for 10 epochs, and evaluate after every epoch.
-python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR \
-    --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET \
-    --bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de
-
-# Run during training in a separate process to get continuous updates,
-# or after training is complete.
-tensorboard --logdir=$MODEL_DIR
-
-# Translate some text using the trained model
-python translate.py --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE \
-    --param_set=$PARAM_SET --text="hello world"
-
-# Compute model's BLEU score using the newstest2014 dataset.
-python translate.py --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE \
-    --param_set=$PARAM_SET --file=$DATA_DIR/newstest2014.en --file_out=translation.en
-python compute_bleu.py --translation=translation.en --reference=$DATA_DIR/newstest2014.de
-```
-
-## Benchmarks
-### Training times
-
-Currently, both big and base parameter sets run on a single GPU. The measurements below
-are reported from running the model on a P100 GPU.
-
-Param Set | batches/sec | batches per epoch | time per epoch
---- | --- | --- | ---
-base | 4.8 | 83244 | 4 hr
-big | 1.1 | 41365 | 10 hr
-
-### Evaluation results
-Below are the case-insensitive BLEU scores after 10 epochs.
-
-Param Set | Score
---- | --- |
-base | 27.7
-big | 28.9
-
-
-## Detailed instructions
-
-
-0. ### Environment preparation
-
-   #### Add models repo to PYTHONPATH
-   Follow the instructions described in the [Requirements](https://github.com/tensorflow/models/tree/master/official#requirements) section to add the models folder to the python path.
-
-   #### Export variables (optional)
-
-   Export the following variables, or modify the values in each of the snippets below:
-   ```
-   PARAM_SET=big
-   DATA_DIR=$HOME/transformer/data
-   MODEL_DIR=$HOME/transformer/model_$PARAM_SET
-   VOCAB_FILE=$DATA_DIR/vocab.ende.32768
-   ```
-
-1. ### Download and preprocess datasets
-
-   [data_download.py](data_download.py) downloads and preprocesses the training and evaluation WMT datasets. After the data is downloaded and extracted, the training data is used to generate a vocabulary of subtokens. The evaluation and training strings are tokenized, and the resulting data is sharded, shuffled, and saved as TFRecords.
-
-   1.75GB of compressed data will be downloaded. In total, the raw files (compressed, extracted, and combined files) take up 8.4GB of disk space. The resulting TFRecord and vocabulary files are 722MB. The script takes around 40 minutes to run, with the bulk of the time spent downloading and ~15 minutes spent on preprocessing.
-
-   Command to run:
-   ```
-   python data_download.py --data_dir=$DATA_DIR
-   ```
-
-   Arguments:
-   * `--data_dir`: Path where the preprocessed TFRecord data, and vocab file will be saved.
-   * Use the `--help` or `-h` flag to get a full list of possible arguments.
-
-2. ### Model training and evaluation
-
-   [transformer_main.py](transformer_main.py) creates a Transformer model, and trains it using Tensorflow Estimator.
-
-   Command to run:
-   ```
-   python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR \
-       --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET
-   ```
-
-   Arguments:
-   * `--data_dir`: This should be set to the same directory given to the `data_download`'s `data_dir` argument.
-   * `--model_dir`: Directory to save Transformer model training checkpoints.
-   * `--vocab_file`: Path to subtoken vocabulary file. If data_download was used, you may find the file in `data_dir`.
-   * `--param_set`: Parameter set to use when creating and training the model. Options are `base` and `big` (default).
-   * Use the `--help` or `-h` flag to get a full list of possible arguments.
-
-   #### Customizing training schedule
-
-   By default, the model will train for 10 epochs, and evaluate after every epoch. The training schedule may be defined through the flags:
-   * Training with epochs (default):
-     * `--train_epochs`: The total number of complete passes to make through the dataset
-     * `--epochs_between_evals`: The number of epochs to train between evaluations.
-   * Training with steps:
-     * `--train_steps`: sets the total number of training steps to run.
-     * `--steps_between_evals`: Number of training steps to run between evaluations.
-
-   Only one of `train_epochs` or `train_steps` may be set. Since the default option is to evaluate the model after training for an epoch, it may take 4 or more hours between model evaluations. To get more frequent evaluations, use the flags `--train_steps=250000 --steps_between_evals=1000`.
-
-   Note: At the beginning of each training session, the training dataset is reloaded and shuffled. Stopping the training before completing an epoch may result in worse model quality, due to the chance that some examples may be seen more than others. Therefore, it is recommended to use epochs when the model quality is important.
-
-   #### Compute BLEU score during model evaluation
-
-   Use these flags to compute the BLEU when the model evaluates:
-   * `--bleu_source`: Path to file containing text to translate.
-   * `--bleu_ref`: Path to file containing the reference translation.
-   * `--stop_threshold`: Train until the BLEU score reaches this lower bound. This setting overrides the `--train_steps` and `--train_epochs` flags.
-
-   When running `transformer_main.py`, use the flags: `--bleu_source=$DATA_DIR/newstest2014.en --bleu_ref=$DATA_DIR/newstest2014.de`
-
-   #### Tensorboard
-   Training and evaluation metrics (loss, accuracy, approximate BLEU score, etc.) are logged, and can be displayed in the browser using Tensorboard.
-   ```
-   tensorboard --logdir=$MODEL_DIR
-   ```
-   The values are displayed at [localhost:6006](localhost:6006).
-
-3. ### Translate using the model
-   [translate.py](translate.py) contains the script to use the trained model to translate input text or file. Each line in the file is translated separately.
-
-   Command to run:
-   ```
-   python translate.py --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE \
-       --param_set=$PARAM_SET --text="hello world"
-   ```
-
-   Arguments for initializing the Subtokenizer and trained model:
-   * `--model_dir` and `--param_set`: These parameters are used to rebuild the trained model
-   * `--vocab_file`: Path to subtoken vocabulary file. If data_download was used, you may find the file in `data_dir`.
-
-   Arguments for specifying what to translate:
-   * `--text`: Text to translate
-   * `--file`: Path to file containing text to translate
-   * `--file_out`: If `--file` is set, then this file will store the input file's translations.
-
-   To translate the newstest2014 data, run:
-   ```
-   python translate.py --model_dir=$MODEL_DIR --vocab_file=$VOCAB_FILE \
-       --param_set=$PARAM_SET --file=$DATA_DIR/newstest2014.en --file_out=translation.en
-   ```
-
-   Translating the file takes around 15 minutes on a GTX1080, or 5 minutes on a P100.
-
-4. ### Compute official BLEU score
-   Use [compute_bleu.py](compute_bleu.py) to compute the BLEU by comparing generated translations to the reference translation.
-
-   Command to run:
-   ```
-   python compute_bleu.py --translation=translation.en --reference=$DATA_DIR/newstest2014.de
-   ```
-
-   Arguments:
-   * `--translation`: Path to file containing generated translations.
-   * `--reference`: Path to file containing reference translations.
-   * Use the `--help` or `-h` flag to get a full list of possible arguments.
-
-5. ### TPU
-   TPU support for this version of Transformer is experimental. Currently it is present for
-   demonstration purposes only, but will be optimized in the coming weeks.
-
-## Export trained model
-To export the model as a Tensorflow [SavedModel](https://www.tensorflow.org/guide/saved_model) format, use the argument `--export_dir` when running `transformer_main.py`. A folder will be created in the directory with the name as the timestamp (e.g. $EXPORT_DIR/1526427396).
-
-```
-EXPORT_DIR=$HOME/transformer/saved_model
-python transformer_main.py --data_dir=$DATA_DIR --model_dir=$MODEL_DIR \
-  --vocab_file=$VOCAB_FILE --param_set=$PARAM_SET --export_model=$EXPORT_DIR
-```
-
-To inspect the SavedModel, use saved_model_cli:
-```
-SAVED_MODEL_DIR=$EXPORT_DIR/{TIMESTAMP}  # replace {TIMESTAMP} with the name of the folder created
-saved_model_cli show --dir=$SAVED_MODEL_DIR  --all
-```
-
-### Example translation
-Let's translate **"hello world!"**, **"goodbye world."**, and **"Would you like some pie?"**.
-
-The SignatureDef for "translate" is:
-
-    signature_def['translate']:
-        The given SavedModel SignatureDef contains the following input(s):
-          inputs['input'] tensor_info:
-              dtype: DT_INT64
-              shape: (-1, -1)
-              name: Placeholder:0
-        The given SavedModel SignatureDef contains the following output(s):
-          outputs['outputs'] tensor_info:
-              dtype: DT_INT32
-              shape: (-1, -1)
-              name: model/Transformer/strided_slice_19:0
-          outputs['scores'] tensor_info:
-              dtype: DT_FLOAT
-              shape: (-1)
-              name: model/Transformer/strided_slice_20:0
-
-Follow the steps below to use the translate signature def:
-
-1. #### Encode the inputs to integer arrays.
-   This can be done using `utils.tokenizer.Subtokenizer`, and the vocab file in the SavedModel assets (`$SAVED_MODEL_DIR/assets.extra/vocab.txt`).
-
-   ```
-   from official.transformer.utils.tokenizer import Subtokenizer
-   s = Subtokenizer(PATH_TO_VOCAB_FILE)
-   print(s.encode("hello world!", add_eos=True))
-   ```
-
-   The encoded inputs are:
-   * `"hello world!" = [6170, 3731, 178, 207, 1]`
-   * `"goodbye world." = [15431, 13966, 36, 178, 3, 1]`
-   * `"Would you like some pie?" = [9092, 72, 155, 202, 19851, 102, 1]`
-
-2. #### Run `saved_model_cli` to obtain the predicted translations
-   The encoded inputs should be padded so that they are the same length. The padding token is `0`.
-   ```
-   ENCODED_INPUTS="[[26228, 145, 178, 1, 0, 0, 0], \
-                   [15431, 13966, 36, 178, 3, 1, 0], \
-                   [9092, 72, 155, 202, 19851, 102, 1]]"
-   ```
-
-   Now, use the `run` command with `saved_model_cli` to get the outputs.
-
-   ```
-   saved_model_cli run --dir=$SAVED_MODEL_DIR --tag_set=serve --signature_def=translate \
-     --input_expr="input=$ENCODED_INPUTS"
-   ```
-
-   The outputs will look similar to:
-   ```
-   Result for output key outputs:
-   [[18744   145   297     1     0     0     0     0     0     0     0     0
-         0     0]
-    [ 5450  4642    21    11   297     3     1     0     0     0     0     0
-         0     0]
-    [25940    22    66   103 21713    31   102     1     0     0     0     0
-         0     0]]
-   Result for output key scores:
-   [-1.5493642 -1.4032784 -3.252089 ]
-   ```
-
-3. #### Decode the outputs to strings.
-   Use the `Subtokenizer` and vocab file as described in step 1 to decode the output integer arrays.
-   ```
-   from official.transformer.utils.tokenizer import Subtokenizer
-   s = Subtokenizer(PATH_TO_VOCAB_FILE)
-   print(s.decode([18744, 145, 297, 1]))
-   ```
-   The decoded outputs from above are:
-   * `[18744, 145, 297, 1] = "Hallo Welt<EOS>"`
-   * `[5450, 4642, 21, 11, 297, 3, 1] = "Abschied von der Welt.<EOS>"`
-   * `[25940, 22, 66, 103, 21713, 31, 102, 1] = "Möchten Sie einen Kuchen?<EOS>"`
-
-## Implementation overview
-
-A brief look at each component in the code:
-
-### Model Definition
-The [model](model) subdirectory contains the implementation of the Transformer model. The following files define the Transformer model and its layers:
-* [transformer.py](model/transformer.py): Defines the transformer model and its encoder/decoder layer stacks.
-* [embedding_layer.py](model/embedding_layer.py): Contains the layer that calculates the embeddings. The embedding weights are also used to calculate the pre-softmax probabilities from the decoder output.
-* [attention_layer.py](model/attention_layer.py): Defines the multi-headed and self attention layers that are used in the encoder/decoder stacks.
-* [ffn_layer.py](model/ffn_layer.py): Defines the feedforward network that is used in the encoder/decoder stacks. The network is composed of 2 fully connected layers.
-
-Other files:
-* [beam_search.py](model/beam_search.py) contains the beam search implementation, which is used during model inference to find high scoring translations.
-* [model_params.py](model/model_params.py) contains the parameters used for the big and base models.
-* [model_utils.py](model/model_utils.py) defines some helper functions used in the model (calculating padding, bias, etc.).
-
-
-### Model Estimator
-[transformer_main.py](model/transformer.py) creates an `Estimator` to train and evaluate the model.
-
-Helper functions:
-* [utils/dataset.py](utils/dataset.py): contains functions for creating a `dataset` that is passed to the `Estimator`.
-* [utils/metrics.py](utils/metrics.py): defines metrics functions used by the `Estimator` to evaluate the
-
-### Other scripts
-
-Aside from the main file to train the Transformer model, we provide other scripts for using the model or downloading the data:
-
-#### Data download and preprocessing
-
-[data_download.py](data_download.py) downloads and extracts data, then uses `Subtokenizer` to tokenize strings into arrays of int IDs. The int arrays are converted to `tf.Examples` and saved in the `tf.RecordDataset` format.
-
- The data is downloaded from the Workshop of Machine Translation (WMT) [news translation task](http://www.statmt.org/wmt17/translation-task.html). The following datasets are used:
-
- * Europarl v7
- * Common Crawl corpus
- * News Commentary v12
-
- See the [download section](http://www.statmt.org/wmt17/translation-task.html#download) to explore the raw datasets. The parameters in this model are tuned to fit the English-German translation data, so the EN-DE texts are extracted from the downloaded compressed files.
-
-The text is transformed into arrays of integer IDs using the `Subtokenizer` defined in [`utils/tokenizer.py`](util/tokenizer.py). During initialization of the `Subtokenizer`, the raw training data is used to generate a vocabulary list containing common subtokens.
-
-The target vocabulary size of the WMT dataset is 32,768. The set of subtokens is found through binary search on the minimum number of times a subtoken appears in the data. The actual vocabulary size is 33,708, and is stored in a 324kB file.
-
-#### Translation
-Translation is defined in [translate.py](translate.py). First, `Subtokenizer` tokenizes the input. The vocabulary file is the same used to tokenize the training/eval files. Next, beam search is used to find the combination of tokens that maximizes the probability outputted by the model decoder. The tokens are then converted back to strings with `Subtokenizer`.
-
-#### BLEU computation
-[compute_bleu.py](compute_bleu.py): Implementation from [https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/bleu_hook.py](https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/utils/bleu_hook.py).
-
-### Test dataset
-The [newstest2014 files](https://storage.googleapis.com/tf-perf-public/official_transformer/test_data/newstest2014.tgz)
-are extracted from the [NMT Seq2Seq tutorial](https://google.github.io/seq2seq/nmt/#download-data).
-The raw text files are converted from the SGM format of the
-[WMT 2016](http://www.statmt.org/wmt16/translation-task.html) test sets. The
-newstest2014 files are put into the `$DATA_DIR` when executing
-`data_download.py`
-
-## Term definitions
-
-**Steps / Epochs**:
-* Step: unit for processing a single batch of data
-* Epoch: a complete run through the dataset
-
-Example: Consider a training a dataset with 100 examples that is divided into 20 batches with 5 examples per batch. A single training step trains the model on one batch. After 20 training steps, the model will have trained on every batch in the dataset, or one epoch.
-
-**Subtoken**: Words are referred to as tokens, and parts of words are referred to as 'subtokens'. For example, the word 'inclined' may be split into `['incline', 'd_']`. The '\_' indicates the end of the token. The subtoken vocabulary list is guaranteed to contain the alphabet (including numbers and special characters), so all words can be tokenized.
diff --git a/official/r1/transformer/__init__.py b/official/r1/transformer/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/transformer/attention_layer.py b/official/r1/transformer/attention_layer.py
deleted file mode 100644
index e3537939..00000000
--- a/official/r1/transformer/attention_layer.py
+++ /dev/null
@@ -1,148 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Implementation of multiheaded attention and self-attention layers."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow.compat.v1 as tf
-
-
-class Attention(tf.layers.Layer):
-  """Multi-headed attention layer."""
-
-  def __init__(self, hidden_size, num_heads, attention_dropout, train):
-    if hidden_size % num_heads != 0:
-      raise ValueError("Hidden size must be evenly divisible by the number of "
-                       "heads.")
-
-    super(Attention, self).__init__()
-    self.hidden_size = hidden_size
-    self.num_heads = num_heads
-    self.attention_dropout = attention_dropout
-    self.train = train
-
-    # Layers for linearly projecting the queries, keys, and values.
-    self.q_dense_layer = tf.layers.Dense(hidden_size, use_bias=False, name="q")
-    self.k_dense_layer = tf.layers.Dense(hidden_size, use_bias=False, name="k")
-    self.v_dense_layer = tf.layers.Dense(hidden_size, use_bias=False, name="v")
-
-    self.output_dense_layer = tf.layers.Dense(hidden_size, use_bias=False,
-                                              name="output_transform")
-
-  def split_heads(self, x):
-    """Split x into different heads, and transpose the resulting value.
-
-    The tensor is transposed to insure the inner dimensions hold the correct
-    values during the matrix multiplication.
-
-    Args:
-      x: A tensor with shape [batch_size, length, hidden_size]
-
-    Returns:
-      A tensor with shape [batch_size, num_heads, length, hidden_size/num_heads]
-    """
-    with tf.name_scope("split_heads"):
-      batch_size = tf.shape(x)[0]
-      length = tf.shape(x)[1]
-
-      # Calculate depth of last dimension after it has been split.
-      depth = (self.hidden_size // self.num_heads)
-
-      # Split the last dimension
-      x = tf.reshape(x, [batch_size, length, self.num_heads, depth])
-
-      # Transpose the result
-      return tf.transpose(x, [0, 2, 1, 3])
-
-  def combine_heads(self, x):
-    """Combine tensor that has been split.
-
-    Args:
-      x: A tensor [batch_size, num_heads, length, hidden_size/num_heads]
-
-    Returns:
-      A tensor with shape [batch_size, length, hidden_size]
-    """
-    with tf.name_scope("combine_heads"):
-      batch_size = tf.shape(x)[0]
-      length = tf.shape(x)[2]
-      x = tf.transpose(x, [0, 2, 1, 3])  # --> [batch, length, num_heads, depth]
-      return tf.reshape(x, [batch_size, length, self.hidden_size])
-
-  def call(self, x, y, bias, cache=None):
-    """Apply attention mechanism to x and y.
-
-    Args:
-      x: a tensor with shape [batch_size, length_x, hidden_size]
-      y: a tensor with shape [batch_size, length_y, hidden_size]
-      bias: attention bias that will be added to the result of the dot product.
-      cache: (Used during prediction) dictionary with tensors containing results
-        of previous attentions. The dictionary must have the items:
-            {"k": tensor with shape [batch_size, i, key_channels],
-             "v": tensor with shape [batch_size, i, value_channels]}
-        where i is the current decoded length.
-
-    Returns:
-      Attention layer output with shape [batch_size, length_x, hidden_size]
-    """
-    # Linearly project the query (q), key (k) and value (v) using different
-    # learned projections. This is in preparation of splitting them into
-    # multiple heads. Multi-head attention uses multiple queries, keys, and
-    # values rather than regular attention (which uses a single q, k, v).
-    q = self.q_dense_layer(x)
-    k = self.k_dense_layer(y)
-    v = self.v_dense_layer(y)
-
-    if cache is not None:
-      # Combine cached keys and values with new keys and values.
-      k = tf.concat([cache["k"], k], axis=1)
-      v = tf.concat([cache["v"], v], axis=1)
-
-      # Update cache
-      cache["k"] = k
-      cache["v"] = v
-
-    # Split q, k, v into heads.
-    q = self.split_heads(q)
-    k = self.split_heads(k)
-    v = self.split_heads(v)
-
-    # Scale q to prevent the dot product between q and k from growing too large.
-    depth = (self.hidden_size // self.num_heads)
-    q *= depth ** -0.5
-
-    # Calculate dot product attention
-    logits = tf.matmul(q, k, transpose_b=True)
-    logits += bias
-    weights = tf.nn.softmax(logits, name="attention_weights")
-    if self.train:
-      weights = tf.nn.dropout(weights, 1.0 - self.attention_dropout)
-    attention_output = tf.matmul(weights, v)
-
-    # Recombine heads --> [batch_size, length, hidden_size]
-    attention_output = self.combine_heads(attention_output)
-
-    # Run the combined outputs through another linear projection layer.
-    attention_output = self.output_dense_layer(attention_output)
-    return attention_output
-
-
-class SelfAttention(Attention):
-  """Multiheaded self-attention layer."""
-
-  def call(self, x, bias, cache=None):
-    return super(SelfAttention, self).call(x, x, bias, cache)
diff --git a/official/r1/transformer/dataset.py b/official/r1/transformer/dataset.py
deleted file mode 100644
index 47987745..00000000
--- a/official/r1/transformer/dataset.py
+++ /dev/null
@@ -1,284 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Input pipeline for the transformer model to read, filter, and batch examples.
-
-Two things to note in the pipeline:
-
-1. Batching scheme
-
-   The examples encoded in the TFRecord files contain data in the format:
-     {"inputs": [variable length array of integers],
-      "targets": [variable length array of integers]}
-   Where integers in the arrays refer to tokens in the English and German vocab
-   file (named `vocab.ende.32768`).
-
-   Prior to batching, elements in the dataset are grouped by length (max between
-   "inputs" and "targets" length). Each group is then batched such that:
-     group_batch_size * length <= batch_size.
-
-   Another way to view batch_size is the maximum number of tokens in each batch.
-
-   Once batched, each element in the dataset will have the shape:
-     {"inputs": [group_batch_size, padded_input_length],
-      "targets": [group_batch_size, padded_target_length]}
-   Lengths are padded to the longest "inputs" or "targets" sequence in the batch
-   (padded_input_length and padded_target_length can be different).
-
-   This batching scheme decreases the fraction of padding tokens per training
-   batch, thus improving the training speed significantly.
-
-2. Shuffling
-
-   While training, the dataset is shuffled in two places in the code. The first
-   is the list of training files. Second, while reading records using
-   `parallel_interleave`, the `sloppy` argument is used to generate randomness
-   in the order of the examples.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import math
-import os
-
-import tensorflow.compat.v1 as tf
-
-from official.utils.misc import model_helpers
-
-# Buffer size for reading records from a TFRecord file. Each training file is
-# 7.2 MB, so 8 MB allows an entire file to be kept in memory.
-_READ_RECORD_BUFFER = 8 * 1000 * 1000
-
-# Example grouping constants. Defines length boundaries for each group.
-# These values are the defaults used in Tensor2Tensor.
-_MIN_BOUNDARY = 8
-_BOUNDARY_SCALE = 1.1
-
-
-def _load_records(filename):
-  """Read file and return a dataset of tf.Examples."""
-  return tf.data.TFRecordDataset(filename, buffer_size=_READ_RECORD_BUFFER)
-
-
-def _parse_example(serialized_example):
-  """Return inputs and targets Tensors from a serialized tf.Example."""
-  data_fields = {
-      "inputs": tf.VarLenFeature(tf.int64),
-      "targets": tf.VarLenFeature(tf.int64)
-  }
-  parsed = tf.parse_single_example(serialized_example, data_fields)
-  inputs = tf.sparse_tensor_to_dense(parsed["inputs"])
-  targets = tf.sparse_tensor_to_dense(parsed["targets"])
-  return inputs, targets
-
-
-def _filter_max_length(example, max_length=256):
-  """Indicates whether the example's length is lower than the maximum length."""
-  return tf.logical_and(tf.size(example[0]) <= max_length,
-                        tf.size(example[1]) <= max_length)
-
-
-def _get_example_length(example):
-  """Returns the maximum length between the example inputs and targets."""
-  length = tf.maximum(tf.shape(example[0])[0], tf.shape(example[1])[0])
-  return length
-
-
-def _create_min_max_boundaries(
-    max_length, min_boundary=_MIN_BOUNDARY, boundary_scale=_BOUNDARY_SCALE):
-  """Create min and max boundary lists up to max_length.
-
-  For example, when max_length=24, min_boundary=4 and boundary_scale=2, the
-  returned values will be:
-    buckets_min = [0, 4, 8, 16, 24]
-    buckets_max = [4, 8, 16, 24, 25]
-
-  Args:
-    max_length: The maximum length of example in dataset.
-    min_boundary: Minimum length in boundary.
-    boundary_scale: Amount to scale consecutive boundaries in the list.
-
-  Returns:
-    min and max boundary lists
-
-  """
-  # Create bucket boundaries list by scaling the previous boundary or adding 1
-  # (to ensure increasing boundary sizes).
-  bucket_boundaries = []
-  x = min_boundary
-  while x < max_length:
-    bucket_boundaries.append(x)
-    x = max(x + 1, int(x * boundary_scale))
-
-  # Create min and max boundary lists from the initial list.
-  buckets_min = [0] + bucket_boundaries
-  buckets_max = bucket_boundaries + [max_length + 1]
-  return buckets_min, buckets_max
-
-
-def _batch_examples(dataset, batch_size, max_length):
-  """Group examples by similar lengths, and return batched dataset.
-
-  Each batch of similar-length examples are padded to the same length, and may
-  have different number of elements in each batch, such that:
-    group_batch_size * padded_length <= batch_size.
-
-  This decreases the number of padding tokens per batch, which improves the
-  training speed.
-
-  Args:
-    dataset: Dataset of unbatched examples.
-    batch_size: Max number of tokens per batch of examples.
-    max_length: Max number of tokens in an example input or target sequence.
-
-  Returns:
-    Dataset of batched examples with similar lengths.
-  """
-  # Get min and max boundary lists for each example. These are used to calculate
-  # the `bucket_id`, which is the index at which:
-  # buckets_min[bucket_id] <= len(example) < buckets_max[bucket_id]
-  # Note that using both min and max lists improves the performance.
-  buckets_min, buckets_max = _create_min_max_boundaries(max_length)
-
-  # Create list of batch sizes for each bucket_id, so that
-  # bucket_batch_size[bucket_id] * buckets_max[bucket_id] <= batch_size
-  bucket_batch_sizes = [batch_size // x for x in buckets_max]
-  # bucket_id will be a tensor, so convert this list to a tensor as well.
-  bucket_batch_sizes = tf.constant(bucket_batch_sizes, dtype=tf.int64)
-
-  def example_to_bucket_id(example_input, example_target):
-    """Return int64 bucket id for this example, calculated based on length."""
-    seq_length = _get_example_length((example_input, example_target))
-
-    # TODO: investigate whether removing code branching improves performance.
-    conditions_c = tf.logical_and(
-        tf.less_equal(buckets_min, seq_length),
-        tf.less(seq_length, buckets_max))
-    bucket_id = tf.reduce_min(tf.where(conditions_c))
-    return bucket_id
-
-  def window_size_fn(bucket_id):
-    """Return number of examples to be grouped when given a bucket id."""
-    return bucket_batch_sizes[bucket_id]
-
-  def batching_fn(bucket_id, grouped_dataset):
-    """Batch and add padding to a dataset of elements with similar lengths."""
-    bucket_batch_size = window_size_fn(bucket_id)
-
-    # Batch the dataset and add padding so that all input sequences in the
-    # examples have the same length, and all target sequences have the same
-    # lengths as well. Resulting lengths of inputs and targets can differ.
-    return grouped_dataset.padded_batch(bucket_batch_size, ([None], [None]))
-
-  return dataset.apply(tf.data.experimental.group_by_window(
-      key_func=example_to_bucket_id,
-      reduce_func=batching_fn,
-      window_size=None,
-      window_size_func=window_size_fn))
-
-
-def _read_and_batch_from_files(
-    file_pattern, batch_size, max_length, num_parallel_calls, shuffle, repeat,
-    static_batch=False):
-  """Create dataset where each item is a dict of "inputs" and "targets".
-
-  Args:
-    file_pattern: String used to match the input TFRecord files.
-    batch_size: Maximum number of tokens per batch of examples
-    max_length: Maximum number of tokens per example
-    num_parallel_calls: Number of cpu cores for parallel input processing.
-    shuffle: If true, randomizes order of elements.
-    repeat: Number of times to repeat the dataset. If None, the dataset is
-      repeated forever.
-    static_batch: Whether the batches in the dataset should have static shapes.
-      If True, the input is batched so that every batch has the
-      shape [batch_size // max_length, max_length]. If False, the input is
-      grouped by length, and batched so that batches may have different
-      shapes [N, M], where:
-        N * M <= batch_size
-        M <= max_length
-      In general, this setting should be False. Dynamic shapes allow the inputs
-      to be grouped so that the number of padding tokens is minimized, and helps
-      model training. In cases where the input shape must be static
-      (e.g. running on TPU), this setting should be set to True.
-
-  Returns:
-    tf.data.Dataset object containing examples loaded from the files.
-  """
-  dataset = tf.data.Dataset.list_files(file_pattern, shuffle=shuffle)
-
-  # Read files and interleave results. When training, the order of the examples
-  # will be non-deterministic.
-  dataset = dataset.apply(
-      tf.data.experimental.parallel_interleave(
-          _load_records, sloppy=shuffle, cycle_length=num_parallel_calls))
-
-  # Parse each tf.Example into a dictionary
-  # TODO: Look into prefetch_input_elements for performance optimization.
-  dataset = dataset.map(_parse_example,
-                        num_parallel_calls=num_parallel_calls)
-
-  # Remove examples where the input or target length exceeds the maximum length,
-  dataset = dataset.filter(lambda x, y: _filter_max_length((x, y), max_length))
-
-  if static_batch:
-    dataset = dataset.padded_batch(
-        batch_size // max_length, ([max_length], [max_length]),
-        drop_remainder=True)
-  else:
-    # Group and batch such that each batch has examples of similar length.
-    dataset = _batch_examples(dataset, batch_size, max_length)
-
-  dataset = dataset.repeat(repeat)
-
-  # Prefetch the next element to improve speed of input pipeline.
-  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
-  return dataset
-
-
-def _generate_synthetic_data(params):
-  """Create synthetic data based on the parameter batch size."""
-  batch = length = int(math.sqrt(params["batch_size"]))
-  return model_helpers.generate_synthetic_data(
-      input_shape=tf.TensorShape([batch, length]),
-      input_value=1,
-      input_dtype=tf.int32,
-      label_shape=tf.TensorShape([batch, length]),
-      label_value=1,
-      label_dtype=tf.int32,
-  )
-
-
-def train_input_fn(params):
-  """Load and return dataset of batched examples for use during training."""
-  file_pattern = os.path.join(params["data_dir"] or "", "*train*")
-  if params["use_synthetic_data"]:
-    return _generate_synthetic_data(params)
-  return _read_and_batch_from_files(
-      file_pattern, params["batch_size"], params["max_length"],
-      params["num_parallel_calls"], shuffle=True,
-      repeat=params["repeat_dataset"], static_batch=params["static_batch"])
-
-
-def eval_input_fn(params):
-  """Load and return dataset of batched examples for use during evaluation."""
-  file_pattern = os.path.join(params["data_dir"] or "", "*dev*")
-  if params["use_synthetic_data"]:
-    return _generate_synthetic_data(params)
-  return _read_and_batch_from_files(
-      file_pattern, params["batch_size"], params["max_length"],
-      params["num_parallel_calls"], shuffle=False, repeat=1,
-      static_batch=params["static_batch"])
diff --git a/official/r1/transformer/embedding_layer.py b/official/r1/transformer/embedding_layer.py
deleted file mode 100644
index 3ebedeaf..00000000
--- a/official/r1/transformer/embedding_layer.py
+++ /dev/null
@@ -1,108 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Implementation of embedding layer with shared weights."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow.compat.v1 as tf  # pylint: disable=g-bad-import-order
-
-from official.r1.utils import tpu as tpu_utils
-
-
-class EmbeddingSharedWeights(tf.layers.Layer):
-  """Calculates input embeddings and pre-softmax linear with shared weights."""
-
-  def __init__(self, vocab_size, hidden_size, method="gather"):
-    """Specify characteristic parameters of embedding layer.
-
-    Args:
-      vocab_size: Number of tokens in the embedding. (Typically ~32,000)
-      hidden_size: Dimensionality of the embedding. (Typically 512 or 1024)
-      method: Strategy for performing embedding lookup. "gather" uses tf.gather
-        which performs well on CPUs and GPUs, but very poorly on TPUs. "matmul"
-        one-hot encodes the indicies and formulates the embedding as a sparse
-        matrix multiplication. The matmul formulation is wasteful as it does
-        extra work, however matrix multiplication is very fast on TPUs which
-        makes "matmul" considerably faster than "gather" on TPUs.
-    """
-    super(EmbeddingSharedWeights, self).__init__()
-    self.vocab_size = vocab_size
-    self.hidden_size = hidden_size
-    if method not in ("gather", "matmul"):
-      raise ValueError("method {} must be 'gather' or 'matmul'".format(method))
-    self.method = method
-
-  def build(self, _):
-    with tf.variable_scope("embedding_and_softmax", reuse=tf.AUTO_REUSE):
-      # Create and initialize weights. The random normal initializer was chosen
-      # randomly, and works well.
-      self.shared_weights = tf.get_variable(
-          "weights", [self.vocab_size, self.hidden_size],
-          initializer=tf.random_normal_initializer(
-              0., self.hidden_size ** -0.5))
-
-    self.built = True
-
-  def call(self, x):
-    """Get token embeddings of x.
-
-    Args:
-      x: An int64 tensor with shape [batch_size, length]
-    Returns:
-      embeddings: float32 tensor with shape [batch_size, length, embedding_size]
-      padding: float32 tensor with shape [batch_size, length] indicating the
-        locations of the padding tokens in x.
-    """
-    with tf.name_scope("embedding"):
-      # Create binary mask of size [batch_size, length]
-      mask = tf.to_float(tf.not_equal(x, 0))
-
-      if self.method == "gather":
-        embeddings = tf.gather(self.shared_weights, x)
-        embeddings *= tf.expand_dims(mask, -1)
-      else:  # matmul
-        embeddings = tpu_utils.embedding_matmul(
-            embedding_table=self.shared_weights,
-            values=tf.cast(x, dtype=tf.int32),
-            mask=mask
-        )
-        # embedding_matmul already zeros out masked positions, so
-        # `embeddings *= tf.expand_dims(mask, -1)` is unnecessary.
-
-
-      # Scale embedding by the sqrt of the hidden size
-      embeddings *= self.hidden_size ** 0.5
-
-      return embeddings
-
-
-  def linear(self, x):
-    """Computes logits by running x through a linear layer.
-
-    Args:
-      x: A float32 tensor with shape [batch_size, length, hidden_size]
-    Returns:
-      float32 tensor with shape [batch_size, length, vocab_size].
-    """
-    with tf.name_scope("presoftmax_linear"):
-      batch_size = tf.shape(x)[0]
-      length = tf.shape(x)[1]
-
-      x = tf.reshape(x, [-1, self.hidden_size])
-      logits = tf.matmul(x, self.shared_weights, transpose_b=True)
-
-      return tf.reshape(logits, [batch_size, length, self.vocab_size])
diff --git a/official/r1/transformer/ffn_layer.py b/official/r1/transformer/ffn_layer.py
deleted file mode 100644
index fc475032..00000000
--- a/official/r1/transformer/ffn_layer.py
+++ /dev/null
@@ -1,89 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Implementation of fully connected network."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow.compat.v1 as tf
-
-
-class FeedFowardNetwork(tf.layers.Layer):
-  """Fully connected feedforward network."""
-
-  def __init__(self, hidden_size, filter_size, relu_dropout, train, allow_pad):
-    super(FeedFowardNetwork, self).__init__()
-    self.hidden_size = hidden_size
-    self.filter_size = filter_size
-    self.relu_dropout = relu_dropout
-    self.train = train
-    self.allow_pad = allow_pad
-
-    self.filter_dense_layer = tf.layers.Dense(
-        filter_size, use_bias=True, activation=tf.nn.relu, name="filter_layer")
-    self.output_dense_layer = tf.layers.Dense(
-        hidden_size, use_bias=True, name="output_layer")
-
-  def call(self, x, padding=None):
-    """Return outputs of the feedforward network.
-
-    Args:
-      x: tensor with shape [batch_size, length, hidden_size]
-      padding: (optional) If set, the padding values are temporarily removed
-        from x (provided self.allow_pad is set). The padding values are placed
-        back in the output tensor in the same locations.
-        shape [batch_size, length]
-
-    Returns:
-      Output of the feedforward network.
-      tensor with shape [batch_size, length, hidden_size]
-    """
-    padding = None if not self.allow_pad else padding
-
-    # Retrieve dynamically known shapes
-    batch_size = tf.shape(x)[0]
-    length = tf.shape(x)[1]
-
-    if padding is not None:
-      with tf.name_scope("remove_padding"):
-        # Flatten padding to [batch_size*length]
-        pad_mask = tf.reshape(padding, [-1])
-
-        nonpad_ids = tf.to_int32(tf.where(pad_mask < 1e-9))
-
-        # Reshape x to [batch_size*length, hidden_size] to remove padding
-        x = tf.reshape(x, [-1, self.hidden_size])
-        x = tf.gather_nd(x, indices=nonpad_ids)
-
-        # Reshape x from 2 dimensions to 3 dimensions.
-        x.set_shape([None, self.hidden_size])
-        x = tf.expand_dims(x, axis=0)
-
-    output = self.filter_dense_layer(x)
-    if self.train:
-      output = tf.nn.dropout(output, 1.0 - self.relu_dropout)
-    output = self.output_dense_layer(output)
-
-    if padding is not None:
-      with tf.name_scope("re_add_padding"):
-        output = tf.squeeze(output, axis=0)
-        output = tf.scatter_nd(
-            indices=nonpad_ids,
-            updates=output,
-            shape=[batch_size * length, self.hidden_size]
-        )
-        output = tf.reshape(output, [batch_size, length, self.hidden_size])
-    return output
diff --git a/official/r1/transformer/schedule.py b/official/r1/transformer/schedule.py
deleted file mode 100644
index 60aedffc..00000000
--- a/official/r1/transformer/schedule.py
+++ /dev/null
@@ -1,130 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Abstract training on a step or epoch basis."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import math
-
-import tensorflow.compat.v1 as tf
-
-
-_TRAIN, _EVAL = tf.estimator.ModeKeys.TRAIN, tf.estimator.ModeKeys.EVAL
-
-
-NUM_EXAMPLES = {
-    tf.estimator.ModeKeys.TRAIN: 4572160,
-    # # Examples that are too long are filtered out, thus the total is less
-    # # than the total number of lines.
-    # 2399123 +  # news-commentary-v12.de-en
-    # 1920209 +  # commoncrawl.de-en
-    # 270769,    # europarl-v7.de-en
-    tf.estimator.ModeKeys.EVAL: 3000,  # newstest2013
-}
-
-
-class Manager(object):
-  """Container for convenience functions to abstract step or epoch basis.
-  Transformer allows users to specify an epoch basis (generally recommended for
-  full training) or a number of steps basis (convenient since epochs are rather
-  large). TPUs furthermore require a step basis; however epochs are the norm in
-  the machine learning community and it is desirable to allow users to specify
-  epochs even when running with TPUS which requires behind the scenes
-  conversions.
-  This container simply groups what are largely mundane checks and conversions
-  rather than interspersing them throughout the run loop code.
-  """
-
-  def __init__(self, train_steps, steps_between_evals, train_epochs,
-               epochs_between_evals, default_train_epochs, batch_size,
-               max_length, use_tpu=False, num_tpu_shards=8):
-    if train_steps and train_epochs:
-      raise ValueError("Both train_steps or train_epochs were be defined.")
-
-    # Determine training schedule based on flags.
-    if train_steps:
-      self.train_eval_iterations = train_steps // steps_between_evals
-      self._single_iteration_train_steps = steps_between_evals
-      self._single_iteration_train_epochs = None
-    else:
-      train_epochs = train_epochs or default_train_epochs
-      self.train_eval_iterations = train_epochs // epochs_between_evals
-      self._single_iteration_train_steps = None
-      self._single_iteration_train_epochs = epochs_between_evals
-
-    self.max_length = max_length
-    self.batch_size = batch_size
-    self.use_tpu = use_tpu
-    self.num_tpu_shards = num_tpu_shards
-
-    if self.use_tpu:
-      assert (self.batch_size // self.max_length) % self.num_tpu_shards == 0
-
-  @property
-  def single_iteration_train_steps(self):
-    if self._single_iteration_train_steps or not self.use_tpu:
-      return self._single_iteration_train_steps
-
-    return self.epochs_to_steps(
-        num_epochs=self._single_iteration_train_epochs, mode=_TRAIN)
-
-  @property
-  def single_iteration_eval_steps(self):
-    if not self.use_tpu:
-      return None
-
-    return self.epochs_to_steps(num_epochs=1, mode=_EVAL)
-
-  @property
-  def train_increment_str(self):
-    if self._single_iteration_train_steps:
-      return "{} steps.".format(self._single_iteration_train_steps)
-
-    if not self.use_tpu:
-      return "{} epochs.".format(self._single_iteration_train_epochs)
-
-    return "~{} epochs. ({} steps)".format(
-        self._single_iteration_train_epochs,
-        self.single_iteration_train_steps)
-
-  @property
-  def repeat_dataset(self):
-    if (self._single_iteration_train_epochs is None and
-        self._single_iteration_train_steps > NUM_EXAMPLES[_TRAIN]):
-      return math.ceil(self._single_iteration_train_steps /
-                       NUM_EXAMPLES[_TRAIN])
-    return self._single_iteration_train_epochs
-
-  def epochs_to_steps(self, num_epochs, mode):
-    """Converts a number of epochs to a number of training steps.
-
-    TPU only: This function assumes that static_batch is True.
-
-      TPU can not tolerate an OutOfRange error from a dataset. As a result the
-    number of examples to be processed must be known ahead of time. TPUs also
-    do not allow partial batches, so this function rounds down.
-
-    Args:
-      num_epochs: An integer of the number of epochs to convert to steps.
-      mode: The estimator ModeKey of the computation
-
-    Returns:
-      An integer of the number of equivalent steps rounded down.
-    """
-    assert self.use_tpu, "epochs_to_steps should only be reached when using TPU"
-    total_num_tokens = NUM_EXAMPLES[mode] * self.max_length * num_epochs
-    return total_num_tokens // self.batch_size
diff --git a/official/r1/transformer/schedule_test.py b/official/r1/transformer/schedule_test.py
deleted file mode 100644
index 29b4d5fd..00000000
--- a/official/r1/transformer/schedule_test.py
+++ /dev/null
@@ -1,84 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Test Transformer's schedule manager."""
-
-import tensorflow.compat.v1 as tf
-
-from official.r1.transformer import schedule
-
-
-class ScheduleBaseTester(tf.test.TestCase):
-  def test_mutual_exclusivity(self):
-    with self.assertRaises(ValueError):
-      schedule.Manager(
-          train_steps=100, steps_between_evals=100, train_epochs=2,
-          epochs_between_evals=1, default_train_epochs=None, batch_size=2048,
-          max_length=256)
-
-  def test_step_basis(self):
-    manager = schedule.Manager(
-        train_steps=1000, steps_between_evals=100, train_epochs=None,
-        epochs_between_evals=None, default_train_epochs=None, batch_size=2048,
-        max_length=256)
-
-    self.assertEqual(manager.single_iteration_train_steps, 100)
-
-    # Evaluation uses the full set
-    self.assertIsNone(manager.single_iteration_eval_steps)
-
-    self.assertIsNone(manager.repeat_dataset)
-
-  def test_epoch_basis(self):
-    manager = schedule.Manager(
-        train_steps=None, steps_between_evals=None, train_epochs=10,
-        epochs_between_evals=2, default_train_epochs=None, batch_size=2048,
-        max_length=256)
-
-    # For non-TPU, estimator relies on dataset exhausion
-    self.assertIsNone(manager.single_iteration_train_steps)
-    self.assertIsNone(manager.single_iteration_eval_steps)
-
-    self.assertEqual(manager.repeat_dataset, 2)
-
-  def test_step_basis_tpu(self):
-    manager = schedule.Manager(
-        train_steps=1000, steps_between_evals=100, train_epochs=None,
-        epochs_between_evals=None, default_train_epochs=None, batch_size=2048,
-        max_length=256, use_tpu=True)
-
-    self.assertEqual(manager.single_iteration_train_steps, 100)
-    # num_eval_examples / (batch_size / max_length) == 3000 / (2048 / 256)
-    self.assertEqual(manager.single_iteration_eval_steps, 375)
-    self.assertIsNone(manager.repeat_dataset)
-
-  def test_epoch_basis_tpu(self):
-    manager = schedule.Manager(
-        train_steps=None, steps_between_evals=None, train_epochs=10,
-        epochs_between_evals=2, default_train_epochs=None, batch_size=2048,
-        max_length=256, use_tpu=True)
-
-    self.assertEqual(
-        manager.single_iteration_train_steps,
-        schedule.NUM_EXAMPLES[tf.estimator.ModeKeys.TRAIN] * 2 // (2048 / 256)
-    )
-
-    # num_eval_examples / (batch_size / max_length) == 3000 / (2048 / 256)
-    self.assertEqual(manager.single_iteration_eval_steps, 375)
-
-    self.assertEqual(manager.repeat_dataset, 2)
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/transformer/transformer.py b/official/r1/transformer/transformer.py
deleted file mode 100644
index 708c3dd9..00000000
--- a/official/r1/transformer/transformer.py
+++ /dev/null
@@ -1,417 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Defines the Transformer model, and its encoder and decoder stacks.
-
-Model paper: https://arxiv.org/pdf/1706.03762.pdf
-Transformer model code source: https://github.com/tensorflow/tensor2tensor
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow.compat.v1 as tf
-
-from official.nlp.transformer import beam_search_v1 as beam_search
-from official.nlp.transformer import model_utils
-from official.nlp.transformer.utils.tokenizer import EOS_ID
-from official.r1.transformer import attention_layer
-from official.r1.transformer import embedding_layer
-from official.r1.transformer import ffn_layer
-
-_NEG_INF = -1e9
-
-
-class Transformer(object):
-  """Transformer model for sequence to sequence data.
-
-  Implemented as described in: https://arxiv.org/pdf/1706.03762.pdf
-
-  The Transformer model consists of an encoder and decoder. The input is an int
-  sequence (or a batch of sequences). The encoder produces a continous
-  representation, and the decoder uses the encoder output to generate
-  probabilities for the output sequence.
-  """
-
-  def __init__(self, params, train):
-    """Initialize layers to build Transformer model.
-
-    Args:
-      params: hyperparameter object defining layer sizes, dropout values, etc.
-      train: boolean indicating whether the model is in training mode. Used to
-        determine if dropout layers should be added.
-    """
-    self.train = train
-    self.params = params
-
-    self.embedding_softmax_layer = embedding_layer.EmbeddingSharedWeights(
-        params["vocab_size"], params["hidden_size"],
-        method="matmul" if params["tpu"] else "gather")
-    self.encoder_stack = EncoderStack(params, train)
-    self.decoder_stack = DecoderStack(params, train)
-
-  def __call__(self, inputs, targets=None):
-    """Calculate target logits or inferred target sequences.
-
-    Args:
-      inputs: int tensor with shape [batch_size, input_length].
-      targets: None or int tensor with shape [batch_size, target_length].
-
-    Returns:
-      If targets is defined, then return logits for each word in the target
-      sequence. float tensor with shape [batch_size, target_length, vocab_size]
-      If target is none, then generate output sequence one token at a time.
-        returns a dictionary {
-          output: [batch_size, decoded length]
-          score: [batch_size, float]}
-    """
-    # Variance scaling is used here because it seems to work in many problems.
-    # Other reasonable initializers may also work just as well.
-    initializer = tf.variance_scaling_initializer(
-        self.params["initializer_gain"], mode="fan_avg", distribution="uniform")
-    with tf.variable_scope("Transformer", initializer=initializer):
-      # Calculate attention bias for encoder self-attention and decoder
-      # multi-headed attention layers.
-      attention_bias = model_utils.get_padding_bias(inputs)
-
-      # Run the inputs through the encoder layer to map the symbol
-      # representations to continuous representations.
-      encoder_outputs = self.encode(inputs, attention_bias)
-
-      # Generate output sequence if targets is None, or return logits if target
-      # sequence is known.
-      if targets is None:
-        return self.predict(encoder_outputs, attention_bias)
-      else:
-        logits = self.decode(targets, encoder_outputs, attention_bias)
-        return logits
-
-  def encode(self, inputs, attention_bias):
-    """Generate continuous representation for inputs.
-
-    Args:
-      inputs: int tensor with shape [batch_size, input_length].
-      attention_bias: float tensor with shape [batch_size, 1, 1, input_length]
-
-    Returns:
-      float tensor with shape [batch_size, input_length, hidden_size]
-    """
-    with tf.name_scope("encode"):
-      # Prepare inputs to the layer stack by adding positional encodings and
-      # applying dropout.
-      embedded_inputs = self.embedding_softmax_layer(inputs)
-      inputs_padding = model_utils.get_padding(inputs)
-
-      with tf.name_scope("add_pos_encoding"):
-        length = tf.shape(embedded_inputs)[1]
-        pos_encoding = model_utils.get_position_encoding(
-            length, self.params["hidden_size"])
-        encoder_inputs = embedded_inputs + pos_encoding
-
-      if self.train:
-        encoder_inputs = tf.nn.dropout(
-            encoder_inputs, 1 - self.params["layer_postprocess_dropout"])
-
-      return self.encoder_stack(encoder_inputs, attention_bias, inputs_padding)
-
-  def decode(self, targets, encoder_outputs, attention_bias):
-    """Generate logits for each value in the target sequence.
-
-    Args:
-      targets: target values for the output sequence.
-        int tensor with shape [batch_size, target_length]
-      encoder_outputs: continuous representation of input sequence.
-        float tensor with shape [batch_size, input_length, hidden_size]
-      attention_bias: float tensor with shape [batch_size, 1, 1, input_length]
-
-    Returns:
-      float32 tensor with shape [batch_size, target_length, vocab_size]
-    """
-    with tf.name_scope("decode"):
-      # Prepare inputs to decoder layers by shifting targets, adding positional
-      # encoding and applying dropout.
-      decoder_inputs = self.embedding_softmax_layer(targets)
-      with tf.name_scope("shift_targets"):
-        # Shift targets to the right, and remove the last element
-        decoder_inputs = tf.pad(
-            decoder_inputs, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]
-      with tf.name_scope("add_pos_encoding"):
-        length = tf.shape(decoder_inputs)[1]
-        decoder_inputs += model_utils.get_position_encoding(
-            length, self.params["hidden_size"])
-      if self.train:
-        decoder_inputs = tf.nn.dropout(
-            decoder_inputs, 1 - self.params["layer_postprocess_dropout"])
-
-      # Run values
-      decoder_self_attention_bias = model_utils.get_decoder_self_attention_bias(
-          length)
-      outputs = self.decoder_stack(
-          decoder_inputs, encoder_outputs, decoder_self_attention_bias,
-          attention_bias)
-      logits = self.embedding_softmax_layer.linear(outputs)
-      return logits
-
-  def _get_symbols_to_logits_fn(self, max_decode_length):
-    """Returns a decoding function that calculates logits of the next tokens."""
-
-    timing_signal = model_utils.get_position_encoding(
-        max_decode_length + 1, self.params["hidden_size"])
-    decoder_self_attention_bias = model_utils.get_decoder_self_attention_bias(
-        max_decode_length)
-
-    def symbols_to_logits_fn(ids, i, cache):
-      """Generate logits for next potential IDs.
-
-      Args:
-        ids: Current decoded sequences.
-          int tensor with shape [batch_size * beam_size, i + 1]
-        i: Loop index
-        cache: dictionary of values storing the encoder output, encoder-decoder
-          attention bias, and previous decoder attention values.
-
-      Returns:
-        Tuple of
-          (logits with shape [batch_size * beam_size, vocab_size],
-           updated cache values)
-      """
-      # Set decoder input to the last generated IDs
-      decoder_input = ids[:, -1:]
-
-      # Preprocess decoder input by getting embeddings and adding timing signal.
-      decoder_input = self.embedding_softmax_layer(decoder_input)
-      decoder_input += timing_signal[i:i + 1]
-
-      self_attention_bias = decoder_self_attention_bias[:, :, i:i + 1, :i + 1]
-      decoder_outputs = self.decoder_stack(
-          decoder_input, cache.get("encoder_outputs"), self_attention_bias,
-          cache.get("encoder_decoder_attention_bias"), cache)
-      logits = self.embedding_softmax_layer.linear(decoder_outputs)
-      logits = tf.squeeze(logits, axis=[1])
-      return logits, cache
-    return symbols_to_logits_fn
-
-  def predict(self, encoder_outputs, encoder_decoder_attention_bias):
-    """Return predicted sequence."""
-    batch_size = tf.shape(encoder_outputs)[0]
-    input_length = tf.shape(encoder_outputs)[1]
-    max_decode_length = input_length + self.params["extra_decode_length"]
-
-    symbols_to_logits_fn = self._get_symbols_to_logits_fn(max_decode_length)
-
-    # Create initial set of IDs that will be passed into symbols_to_logits_fn.
-    initial_ids = tf.zeros([batch_size], dtype=tf.int32)
-
-    # Create cache storing decoder attention values for each layer.
-    cache = {
-        "layer_%d" % layer: {
-            "k": tf.zeros([batch_size, 0, self.params["hidden_size"]]),
-            "v": tf.zeros([batch_size, 0, self.params["hidden_size"]]),
-        } for layer in range(self.params["num_hidden_layers"])}
-
-    # Add encoder output and attention bias to the cache.
-    cache["encoder_outputs"] = encoder_outputs
-    cache["encoder_decoder_attention_bias"] = encoder_decoder_attention_bias
-
-    # Use beam search to find the top beam_size sequences and scores.
-    decoded_ids, scores = beam_search.sequence_beam_search(
-        symbols_to_logits_fn=symbols_to_logits_fn,
-        initial_ids=initial_ids,
-        initial_cache=cache,
-        vocab_size=self.params["vocab_size"],
-        beam_size=self.params["beam_size"],
-        alpha=self.params["alpha"],
-        max_decode_length=max_decode_length,
-        eos_id=EOS_ID)
-
-    # Get the top sequence for each batch element
-    top_decoded_ids = decoded_ids[:, 0, 1:]
-    top_scores = scores[:, 0]
-
-    return {"outputs": top_decoded_ids, "scores": top_scores}
-
-
-class LayerNormalization(tf.layers.Layer):
-  """Applies layer normalization."""
-
-  def __init__(self, hidden_size):
-    super(LayerNormalization, self).__init__()
-    self.hidden_size = hidden_size
-
-  def build(self, _):
-    self.scale = tf.get_variable("layer_norm_scale", [self.hidden_size],
-                                 initializer=tf.ones_initializer())
-    self.bias = tf.get_variable("layer_norm_bias", [self.hidden_size],
-                                initializer=tf.zeros_initializer())
-    self.built = True
-
-  def call(self, x, epsilon=1e-6):
-    mean = tf.reduce_mean(x, axis=[-1], keepdims=True)
-    variance = tf.reduce_mean(tf.square(x - mean), axis=[-1], keepdims=True)
-    norm_x = (x - mean) * tf.rsqrt(variance + epsilon)
-    return norm_x * self.scale + self.bias
-
-
-class PrePostProcessingWrapper(object):
-  """Wrapper class that applies layer pre-processing and post-processing."""
-
-  def __init__(self, layer, params, train):
-    self.layer = layer
-    self.postprocess_dropout = params["layer_postprocess_dropout"]
-    self.train = train
-
-    # Create normalization layer
-    self.layer_norm = LayerNormalization(params["hidden_size"])
-
-  def __call__(self, x, *args, **kwargs):
-    # Preprocessing: apply layer normalization
-    y = self.layer_norm(x)
-
-    # Get layer output
-    y = self.layer(y, *args, **kwargs)
-
-    # Postprocessing: apply dropout and residual connection
-    if self.train:
-      y = tf.nn.dropout(y, 1 - self.postprocess_dropout)
-    return x + y
-
-
-class EncoderStack(tf.layers.Layer):
-  """Transformer encoder stack.
-
-  The encoder stack is made up of N identical layers. Each layer is composed
-  of the sublayers:
-    1. Self-attention layer
-    2. Feedforward network (which is 2 fully-connected layers)
-  """
-
-  def __init__(self, params, train):
-    super(EncoderStack, self).__init__()
-    self.layers = []
-    for _ in range(params["num_hidden_layers"]):
-      # Create sublayers for each layer.
-      self_attention_layer = attention_layer.SelfAttention(
-          params["hidden_size"], params["num_heads"],
-          params["attention_dropout"], train)
-      feed_forward_network = ffn_layer.FeedFowardNetwork(
-          params["hidden_size"], params["filter_size"],
-          params["relu_dropout"], train, params["allow_ffn_pad"])
-
-      self.layers.append([
-          PrePostProcessingWrapper(self_attention_layer, params, train),
-          PrePostProcessingWrapper(feed_forward_network, params, train)])
-
-    # Create final layer normalization layer.
-    self.output_normalization = LayerNormalization(params["hidden_size"])
-
-  def call(self, encoder_inputs, attention_bias, inputs_padding):
-    """Return the output of the encoder layer stacks.
-
-    Args:
-      encoder_inputs: tensor with shape [batch_size, input_length, hidden_size]
-      attention_bias: bias for the encoder self-attention layer.
-        [batch_size, 1, 1, input_length]
-      inputs_padding: P
-
-    Returns:
-      Output of encoder layer stack.
-      float32 tensor with shape [batch_size, input_length, hidden_size]
-    """
-    for n, layer in enumerate(self.layers):
-      # Run inputs through the sublayers.
-      self_attention_layer = layer[0]
-      feed_forward_network = layer[1]
-
-      with tf.variable_scope("layer_%d" % n):
-        with tf.variable_scope("self_attention"):
-          encoder_inputs = self_attention_layer(encoder_inputs, attention_bias)
-        with tf.variable_scope("ffn"):
-          encoder_inputs = feed_forward_network(encoder_inputs, inputs_padding)
-
-    return self.output_normalization(encoder_inputs)
-
-
-class DecoderStack(tf.layers.Layer):
-  """Transformer decoder stack.
-
-  Like the encoder stack, the decoder stack is made up of N identical layers.
-  Each layer is composed of the sublayers:
-    1. Self-attention layer
-    2. Multi-headed attention layer combining encoder outputs with results from
-       the previous self-attention layer.
-    3. Feedforward network (2 fully-connected layers)
-  """
-
-  def __init__(self, params, train):
-    super(DecoderStack, self).__init__()
-    self.layers = []
-    for _ in range(params["num_hidden_layers"]):
-      self_attention_layer = attention_layer.SelfAttention(
-          params["hidden_size"], params["num_heads"],
-          params["attention_dropout"], train)
-      enc_dec_attention_layer = attention_layer.Attention(
-          params["hidden_size"], params["num_heads"],
-          params["attention_dropout"], train)
-      feed_forward_network = ffn_layer.FeedFowardNetwork(
-          params["hidden_size"], params["filter_size"],
-          params["relu_dropout"], train, params["allow_ffn_pad"])
-
-      self.layers.append([
-          PrePostProcessingWrapper(self_attention_layer, params, train),
-          PrePostProcessingWrapper(enc_dec_attention_layer, params, train),
-          PrePostProcessingWrapper(feed_forward_network, params, train)])
-
-    self.output_normalization = LayerNormalization(params["hidden_size"])
-
-  def call(self, decoder_inputs, encoder_outputs, decoder_self_attention_bias,
-           attention_bias, cache=None):
-    """Return the output of the decoder layer stacks.
-
-    Args:
-      decoder_inputs: tensor with shape [batch_size, target_length, hidden_size]
-      encoder_outputs: tensor with shape [batch_size, input_length, hidden_size]
-      decoder_self_attention_bias: bias for decoder self-attention layer.
-        [1, 1, target_len, target_length]
-      attention_bias: bias for encoder-decoder attention layer.
-        [batch_size, 1, 1, input_length]
-      cache: (Used for fast decoding) A nested dictionary storing previous
-        decoder self-attention values. The items are:
-          {layer_n: {"k": tensor with shape [batch_size, i, key_channels],
-                     "v": tensor with shape [batch_size, i, value_channels]},
-           ...}
-
-    Returns:
-      Output of decoder layer stack.
-      float32 tensor with shape [batch_size, target_length, hidden_size]
-    """
-    for n, layer in enumerate(self.layers):
-      self_attention_layer = layer[0]
-      enc_dec_attention_layer = layer[1]
-      feed_forward_network = layer[2]
-
-      # Run inputs through the sublayers.
-      layer_name = "layer_%d" % n
-      layer_cache = cache[layer_name] if cache is not None else None
-      with tf.variable_scope(layer_name):
-        with tf.variable_scope("self_attention"):
-          decoder_inputs = self_attention_layer(
-              decoder_inputs, decoder_self_attention_bias, cache=layer_cache)
-        with tf.variable_scope("encdec_attention"):
-          decoder_inputs = enc_dec_attention_layer(
-              decoder_inputs, encoder_outputs, attention_bias)
-        with tf.variable_scope("ffn"):
-          decoder_inputs = feed_forward_network(decoder_inputs)
-
-    return self.output_normalization(decoder_inputs)
diff --git a/official/r1/transformer/transformer_main.py b/official/r1/transformer/transformer_main.py
deleted file mode 100644
index eb2c2f94..00000000
--- a/official/r1/transformer/transformer_main.py
+++ /dev/null
@@ -1,710 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Train and evaluate the Transformer model.
-
-See README for description of setting the training schedule and evaluating the
-BLEU score.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import tempfile
-
-# pylint: disable=g-bad-import-order
-from six.moves import xrange  # pylint: disable=redefined-builtin
-from absl import app as absl_app
-from absl import flags
-import tensorflow.compat.v1 as tf
-# pylint: enable=g-bad-import-order
-
-from official.nlp.transformer import model_params
-from official.r1.utils import export
-from official.r1.utils import tpu as tpu_util
-from official.r1.transformer import translate
-from official.r1.transformer import transformer
-from official.r1.transformer import dataset
-from official.r1.transformer import schedule
-from official.nlp.transformer import compute_bleu
-from official.nlp.transformer.utils import metrics
-from official.nlp.transformer.utils import tokenizer
-from official.utils.flags import core as flags_core
-from official.r1.utils.logs import hooks_helper
-from official.r1.utils.logs import logger
-from official.utils.misc import distribution_utils
-from official.utils.misc import model_helpers
-
-PARAMS_MAP = {
-    "tiny": model_params.TINY_PARAMS,
-    "base": model_params.BASE_PARAMS,
-    "big": model_params.BIG_PARAMS,
-}
-
-
-DEFAULT_TRAIN_EPOCHS = 10
-INF = 1000000000  # 1e9
-BLEU_DIR = "bleu"
-
-# Dictionary containing tensors that are logged by the logging hooks. Each item
-# maps a string to the tensor name.
-TENSORS_TO_LOG = {
-    "learning_rate": "model/get_train_op/learning_rate/learning_rate",
-    "cross_entropy_loss": "model/cross_entropy"}
-
-
-def model_fn(features, labels, mode, params):
-  """Defines how to train, evaluate and predict from the transformer model."""
-  with tf.variable_scope("model"):
-    inputs, targets = features, labels
-
-    # Create model and get output logits.
-    model = transformer.Transformer(params, mode == tf.estimator.ModeKeys.TRAIN)
-
-    logits = model(inputs, targets)
-
-    # When in prediction mode, the labels/targets is None. The model output
-    # is the prediction
-    if mode == tf.estimator.ModeKeys.PREDICT:
-      if params["use_tpu"]:
-        raise NotImplementedError("Prediction is not yet supported on TPUs.")
-      return tf.estimator.EstimatorSpec(
-          tf.estimator.ModeKeys.PREDICT,
-          predictions=logits,
-          export_outputs={
-              "translate": tf.estimator.export.PredictOutput(logits)
-          })
-
-    # Explicitly set the shape of the logits for XLA (TPU). This is needed
-    # because the logits are passed back to the host VM CPU for metric
-    # evaluation, and the shape of [?, ?, vocab_size] is too vague. However
-    # it is known from Transformer that the first two dimensions of logits
-    # are the dimensions of targets. Note that the ambiguous shape of logits is
-    # not a problem when computing xentropy, because padded_cross_entropy_loss
-    # resolves the shape on the TPU.
-    logits.set_shape(targets.shape.as_list() + logits.shape.as_list()[2:])
-
-    # Calculate model loss.
-    # xentropy contains the cross entropy loss of every nonpadding token in the
-    # targets.
-    xentropy, weights = metrics.padded_cross_entropy_loss(
-        logits, targets, params["label_smoothing"], params["vocab_size"])
-    loss = tf.reduce_sum(xentropy) / tf.reduce_sum(weights)
-
-    # Save loss as named tensor that will be logged with the logging hook.
-    tf.identity(loss, "cross_entropy")
-
-    if mode == tf.estimator.ModeKeys.EVAL:
-      if params["use_tpu"]:
-        # host call functions should only have tensors as arguments.
-        # This lambda pre-populates params so that metric_fn is
-        # TPUEstimator compliant.
-        metric_fn = lambda logits, labels: (
-            metrics.get_eval_metrics(logits, labels, params=params))
-        eval_metrics = (metric_fn, [logits, labels])
-        return tf.estimator.tpu.TPUEstimatorSpec(
-            mode=mode,
-            loss=loss,
-            predictions={"predictions": logits},
-            eval_metrics=eval_metrics)
-      return tf.estimator.EstimatorSpec(
-          mode=mode, loss=loss, predictions={"predictions": logits},
-          eval_metric_ops=metrics.get_eval_metrics(logits, labels, params))
-    else:
-      train_op, metric_dict = get_train_op_and_metrics(loss, params)
-
-      # Epochs can be quite long. This gives some intermediate information
-      # in TensorBoard.
-      metric_dict["minibatch_loss"] = loss
-      if params["use_tpu"]:
-        return tf.estimator.tpu.TPUEstimatorSpec(
-            mode=mode,
-            loss=loss,
-            train_op=train_op,
-            host_call=tpu_util.construct_scalar_host_call(
-                metric_dict=metric_dict,
-                model_dir=params["model_dir"],
-                prefix="training/"))
-      record_scalars(metric_dict)
-      return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)
-
-
-def record_scalars(metric_dict):
-  for key, value in metric_dict.items():
-    tf.summary.scalar(name=key, tensor=value)
-
-
-def get_learning_rate(learning_rate, hidden_size, learning_rate_warmup_steps):
-  """Calculate learning rate with linear warmup and rsqrt decay."""
-  with tf.name_scope("learning_rate"):
-    warmup_steps = tf.to_float(learning_rate_warmup_steps)
-    step = tf.to_float(tf.train.get_or_create_global_step())
-
-    learning_rate *= (hidden_size ** -0.5)
-    # Apply linear warmup
-    learning_rate *= tf.minimum(1.0, step / warmup_steps)
-    # Apply rsqrt decay
-    learning_rate *= tf.rsqrt(tf.maximum(step, warmup_steps))
-
-    # Create a named tensor that will be logged using the logging hook.
-    # The full name includes variable and names scope. In this case, the name
-    # is model/get_train_op/learning_rate/learning_rate
-    tf.identity(learning_rate, "learning_rate")
-
-    return learning_rate
-
-
-def get_train_op_and_metrics(loss, params):
-  """Generate training op and metrics to save in TensorBoard."""
-  with tf.variable_scope("get_train_op"):
-    learning_rate = get_learning_rate(
-        learning_rate=params["learning_rate"],
-        hidden_size=params["hidden_size"],
-        learning_rate_warmup_steps=params["learning_rate_warmup_steps"])
-
-    # Create optimizer. Use LazyAdamOptimizer from TF contrib, which is faster
-    # than the TF core Adam optimizer.
-    from tensorflow.contrib import opt as contrib_opt  # pylint: disable=g-import-not-at-top
-    optimizer = contrib_opt.LazyAdamOptimizer(
-        learning_rate,
-        beta1=params["optimizer_adam_beta1"],
-        beta2=params["optimizer_adam_beta2"],
-        epsilon=params["optimizer_adam_epsilon"])
-
-    if params["use_tpu"] and params["tpu"] != tpu_util.LOCAL:
-      optimizer = tf.compat.v1.tpu.CrossShardOptimizer(optimizer)
-
-    # Uses automatic mixed precision FP16 training if on GPU.
-    if params["dtype"] == "fp16":
-      optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(
-          optimizer)
-
-    # Calculate and apply gradients using LazyAdamOptimizer.
-    global_step = tf.train.get_global_step()
-    tvars = tf.trainable_variables()
-    gradients = optimizer.compute_gradients(
-        loss, tvars, colocate_gradients_with_ops=True)
-    minimize_op = optimizer.apply_gradients(
-        gradients, global_step=global_step, name="train")
-    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
-    train_op = tf.group(minimize_op, update_ops)
-
-    train_metrics = {"learning_rate": learning_rate}
-
-    if not params["use_tpu"]:
-      # gradient norm is not included as a summary when running on TPU, as
-      # it can cause instability between the TPU and the host controller.
-      gradient_norm = tf.global_norm(list(zip(*gradients))[0])
-      train_metrics["global_norm/gradient_norm"] = gradient_norm
-
-    return train_op, train_metrics
-
-
-def translate_and_compute_bleu(estimator, subtokenizer, bleu_source, bleu_ref):
-  """Translate file and report the cased and uncased bleu scores."""
-  # Create temporary file to store translation.
-  tmp = tempfile.NamedTemporaryFile(delete=False)
-  tmp_filename = tmp.name
-
-  translate.translate_file(
-      estimator, subtokenizer, bleu_source, output_file=tmp_filename,
-      print_all_translations=False)
-
-  # Compute uncased and cased bleu scores.
-  uncased_score = compute_bleu.bleu_wrapper(bleu_ref, tmp_filename, False)
-  cased_score = compute_bleu.bleu_wrapper(bleu_ref, tmp_filename, True)
-  os.remove(tmp_filename)
-  return uncased_score, cased_score
-
-
-def get_global_step(estimator):
-  """Return estimator's last checkpoint."""
-  return int(estimator.latest_checkpoint().split("-")[-1])
-
-
-def evaluate_and_log_bleu(estimator, bleu_source, bleu_ref, vocab_file):
-  """Calculate and record the BLEU score."""
-  subtokenizer = tokenizer.Subtokenizer(vocab_file)
-
-  uncased_score, cased_score = translate_and_compute_bleu(
-      estimator, subtokenizer, bleu_source, bleu_ref)
-
-  tf.logging.info("Bleu score (uncased): %f", uncased_score)
-  tf.logging.info("Bleu score (cased): %f", cased_score)
-  return uncased_score, cased_score
-
-
-def _validate_file(filepath):
-  """Make sure that file exists."""
-  if not tf.io.gfile.exists(filepath):
-    raise tf.errors.NotFoundError(None, None, "File %s not found." % filepath)
-
-
-def run_loop(
-    estimator, schedule_manager, train_hooks=None, benchmark_logger=None,
-    bleu_source=None, bleu_ref=None, bleu_threshold=None, vocab_file=None):
-  """Train and evaluate model, and optionally compute model's BLEU score.
-
-  **Step vs. Epoch vs. Iteration**
-
-  Steps and epochs are canonical terms used in TensorFlow and general machine
-  learning. They are used to describe running a single process (train/eval):
-    - Step refers to running the process through a single or batch of examples.
-    - Epoch refers to running the process through an entire dataset.
-
-  E.g. training a dataset with 100 examples. The dataset is
-  divided into 20 batches with 5 examples per batch. A single training step
-  trains the model on one batch. After 20 training steps, the model will have
-  trained on every batch in the dataset, or, in other words, one epoch.
-
-  Meanwhile, iteration is used in this implementation to describe running
-  multiple processes (training and eval).
-    - A single iteration:
-      1. trains the model for a specific number of steps or epochs.
-      2. evaluates the model.
-      3. (if source and ref files are provided) compute BLEU score.
-
-  This function runs through multiple train+eval+bleu iterations.
-
-  Args:
-    estimator: tf.Estimator containing model to train.
-    schedule_manager: A schedule.Manager object to guide the run loop.
-    train_hooks: List of hooks to pass to the estimator during training.
-    benchmark_logger: a BenchmarkLogger object that logs evaluation data
-    bleu_source: File containing text to be translated for BLEU calculation.
-    bleu_ref: File containing reference translations for BLEU calculation.
-    bleu_threshold: minimum BLEU score before training is stopped.
-    vocab_file: Path to vocab file that will be used to subtokenize bleu_source.
-
-  Returns:
-    Dict of results of the run.  Contains the keys `eval_results`,
-    `train_hooks`, `bleu_cased`, and `bleu_uncased`. `train_hooks` is a list the
-    instances of hooks used during training.
-
-  Raises:
-    ValueError: if both or none of single_iteration_train_steps and
-      single_iteration_train_epochs were defined.
-    NotFoundError: if the vocab file or bleu files don't exist.
-  """
-  if bleu_source:
-    _validate_file(bleu_source)
-  if bleu_ref:
-    _validate_file(bleu_ref)
-  if vocab_file:
-    _validate_file(vocab_file)
-
-  evaluate_bleu = bleu_source is not None and bleu_ref is not None
-  if evaluate_bleu and schedule_manager.use_tpu:
-    raise ValueError("BLEU score can not be computed when training with a TPU, "
-                     "as it requires estimator.predict which is not yet "
-                     "supported.")
-
-  # Print details of training schedule.
-  tf.logging.info("Training schedule:")
-  tf.logging.info(
-      "\t1. Train for {}".format(schedule_manager.train_increment_str))
-  tf.logging.info("\t2. Evaluate model.")
-  if evaluate_bleu:
-    tf.logging.info("\t3. Compute BLEU score.")
-    if bleu_threshold is not None:
-      tf.logging.info("Repeat above steps until the BLEU score reaches %f" %
-                      bleu_threshold)
-  if not evaluate_bleu or bleu_threshold is None:
-    tf.logging.info("Repeat above steps %d times." %
-                    schedule_manager.train_eval_iterations)
-
-  if evaluate_bleu:
-    # Create summary writer to log bleu score (values can be displayed in
-    # Tensorboard).
-    bleu_writer = tf.summary.FileWriter(
-        os.path.join(estimator.model_dir, BLEU_DIR))
-    if bleu_threshold is not None:
-      # Change loop stopping condition if bleu_threshold is defined.
-      schedule_manager.train_eval_iterations = INF
-
-  # Loop training/evaluation/bleu cycles
-  stats = {}
-  for i in xrange(schedule_manager.train_eval_iterations):
-    tf.logging.info("Starting iteration %d" % (i + 1))
-
-    # Train the model for single_iteration_train_steps or until the input fn
-    # runs out of examples (if single_iteration_train_steps is None).
-    estimator.train(
-        dataset.train_input_fn,
-        steps=schedule_manager.single_iteration_train_steps,
-        hooks=train_hooks)
-
-    eval_results = None
-    eval_results = estimator.evaluate(
-        input_fn=dataset.eval_input_fn,
-        steps=schedule_manager.single_iteration_eval_steps)
-
-    tf.logging.info("Evaluation results (iter %d/%d):" %
-                    (i + 1, schedule_manager.train_eval_iterations))
-    tf.logging.info(eval_results)
-    benchmark_logger.log_evaluation_result(eval_results)
-
-    # The results from estimator.evaluate() are measured on an approximate
-    # translation, which utilize the target golden values provided. The actual
-    # bleu score must be computed using the estimator.predict() path, which
-    # outputs translations that are not based on golden values. The translations
-    # are compared to reference file to get the actual bleu score.
-    if evaluate_bleu:
-      uncased_score, cased_score = evaluate_and_log_bleu(
-          estimator, bleu_source, bleu_ref, vocab_file)
-
-      stats["bleu_uncased"] = uncased_score
-      stats["bleu_cased"] = cased_score
-
-      # Write actual bleu scores using summary writer and benchmark logger
-      global_step = get_global_step(estimator)
-      summary = tf.Summary(value=[
-          tf.Summary.Value(tag="bleu/uncased", simple_value=uncased_score),
-          tf.Summary.Value(tag="bleu/cased", simple_value=cased_score),
-      ])
-      bleu_writer.add_summary(summary, global_step)
-      bleu_writer.flush()
-      benchmark_logger.log_metric(
-          "bleu_uncased", uncased_score, global_step=global_step)
-      benchmark_logger.log_metric(
-          "bleu_cased", cased_score, global_step=global_step)
-
-      # Stop training if bleu stopping threshold is met.
-      if model_helpers.past_stop_threshold(bleu_threshold, uncased_score):
-        bleu_writer.close()
-        break
-
-  stats["eval_results"] = eval_results
-  stats["train_hooks"] = train_hooks
-
-  return stats
-
-
-def define_transformer_flags():
-  """Add flags and flag validators for running transformer_main."""
-  # Add common flags (data_dir, model_dir, train_epochs, etc.).
-  flags.DEFINE_integer(
-      name="max_length", short_name="ml", default=None,
-      help=flags_core.help_wrap("Max length."))
-
-  flags_core.define_base(clean=True, train_epochs=True,
-                         epochs_between_evals=True, stop_threshold=True,
-                         num_gpu=True, hooks=True, export_dir=True,
-                         distribution_strategy=True)
-  flags_core.define_performance(
-      num_parallel_calls=True,
-      inter_op=False,
-      intra_op=False,
-      synthetic_data=True,
-      max_train_steps=False,
-      dtype=True,
-      all_reduce_alg=True
-  )
-  flags_core.define_benchmark()
-  flags_core.define_device(tpu=True)
-
-  # Set flags from the flags_core module as "key flags" so they're listed when
-  # the '-h' flag is used. Without this line, the flags defined above are
-  # only shown in the full `--helpful` help text.
-  flags.adopt_module_key_flags(flags_core)
-
-  # Add transformer-specific flags
-  flags.DEFINE_enum(
-      name="param_set", short_name="mp", default="big",
-      enum_values=PARAMS_MAP.keys(),
-      help=flags_core.help_wrap(
-          "Parameter set to use when creating and training the model. The "
-          "parameters define the input shape (batch size and max length), "
-          "model configuration (size of embedding, # of hidden layers, etc.), "
-          "and various other settings. The big parameter set increases the "
-          "default batch size, embedding/hidden size, and filter size. For a "
-          "complete list of parameters, please see model/model_params.py."))
-
-  flags.DEFINE_bool(
-      name="static_batch", default=False,
-      help=flags_core.help_wrap(
-          "Whether the batches in the dataset should have static shapes. In "
-          "general, this setting should be False. Dynamic shapes allow the "
-          "inputs to be grouped so that the number of padding tokens is "
-          "minimized, and helps model training. In cases where the input shape "
-          "must be static (e.g. running on TPU), this setting will be ignored "
-          "and static batching will always be used."))
-
-  # Flags for training with steps (may be used for debugging)
-  flags.DEFINE_integer(
-      name="train_steps", short_name="ts", default=None,
-      help=flags_core.help_wrap("The number of steps used to train."))
-  flags.DEFINE_integer(
-      name="steps_between_evals", short_name="sbe", default=1000,
-      help=flags_core.help_wrap(
-          "The Number of training steps to run between evaluations. This is "
-          "used if --train_steps is defined."))
-
-  # BLEU score computation
-  flags.DEFINE_string(
-      name="bleu_source", short_name="bls", default=None,
-      help=flags_core.help_wrap(
-          "Path to source file containing text translate when calculating the "
-          "official BLEU score. Both --bleu_source and --bleu_ref must be set. "
-          "Use the flag --stop_threshold to stop the script based on the "
-          "uncased BLEU score."))
-  flags.DEFINE_string(
-      name="bleu_ref", short_name="blr", default=None,
-      help=flags_core.help_wrap(
-          "Path to source file containing text translate when calculating the "
-          "official BLEU score. Both --bleu_source and --bleu_ref must be set. "
-          "Use the flag --stop_threshold to stop the script based on the "
-          "uncased BLEU score."))
-  flags.DEFINE_string(
-      name="vocab_file", short_name="vf", default=None,
-      help=flags_core.help_wrap(
-          "Path to subtoken vocabulary file. If data_download.py was used to "
-          "download and encode the training data, look in the data_dir to find "
-          "the vocab file."))
-
-  flags_core.set_defaults(data_dir="/tmp/translate_ende",
-                          model_dir="/tmp/transformer_model",
-                          batch_size=None,
-                          train_epochs=None)
-
-  @flags.multi_flags_validator(
-      ["train_epochs", "train_steps"],
-      message="Both --train_steps and --train_epochs were set. Only one may be "
-              "defined.")
-  def _check_train_limits(flag_dict):
-    return flag_dict["train_epochs"] is None or flag_dict["train_steps"] is None
-
-  @flags.multi_flags_validator(
-      ["bleu_source", "bleu_ref"],
-      message="Both or neither --bleu_source and --bleu_ref must be defined.")
-  def _check_bleu_files(flags_dict):
-    return (flags_dict["bleu_source"] is None) == (
-        flags_dict["bleu_ref"] is None)
-
-  @flags.multi_flags_validator(
-      ["bleu_source", "bleu_ref", "vocab_file"],
-      message="--vocab_file must be defined if --bleu_source and --bleu_ref "
-              "are defined.")
-  def _check_bleu_vocab_file(flags_dict):
-    if flags_dict["bleu_source"] and flags_dict["bleu_ref"]:
-      return flags_dict["vocab_file"] is not None
-    return True
-
-  @flags.multi_flags_validator(
-      ["export_dir", "vocab_file"],
-      message="--vocab_file must be defined if --export_dir is set.")
-  def _check_export_vocab_file(flags_dict):
-    if flags_dict["export_dir"]:
-      return flags_dict["vocab_file"] is not None
-    return True
-
-  flags_core.require_cloud_storage(["data_dir", "model_dir", "export_dir"])
-
-
-def construct_estimator(flags_obj, params, schedule_manager):
-  """Construct an estimator from either Estimator or TPUEstimator.
-
-  Args:
-    flags_obj: The FLAGS object parsed from command line.
-    params: A dict of run specific parameters.
-    schedule_manager: A schedule.Manager object containing the run schedule.
-
-  Returns:
-    An estimator object to be used for training and eval.
-  """
-  if not params["use_tpu"]:
-    distribution_strategy = distribution_utils.get_distribution_strategy(
-        distribution_strategy=flags_obj.distribution_strategy,
-        num_gpus=flags_core.get_num_gpus(flags_obj),
-        all_reduce_alg=flags_obj.all_reduce_alg)
-    return tf.estimator.Estimator(
-        model_fn=model_fn, model_dir=flags_obj.model_dir, params=params,
-        config=tf.estimator.RunConfig(train_distribute=distribution_strategy))
-
-  tpu_cluster_resolver = tf.compat.v1.cluster_resolver.TPUClusterResolver(
-      tpu=flags_obj.tpu,
-      zone=flags_obj.tpu_zone,
-      project=flags_obj.tpu_gcp_project
-  )
-
-  tpu_config = tf.estimator.tpu.TPUConfig(
-      iterations_per_loop=schedule_manager.single_iteration_train_steps,
-      num_shards=flags_obj.num_tpu_shards)
-
-  run_config = tf.estimator.tpu.RunConfig(
-      cluster=tpu_cluster_resolver,
-      model_dir=flags_obj.model_dir,
-      session_config=tf.ConfigProto(
-          allow_soft_placement=True, log_device_placement=True),
-      tpu_config=tpu_config)
-
-  return tf.estimator.tpu.TPUEstimator(
-      model_fn=model_fn,
-      use_tpu=params["use_tpu"] and flags_obj.tpu != tpu_util.LOCAL,
-      train_batch_size=schedule_manager.batch_size,
-      eval_batch_size=schedule_manager.batch_size,
-      params={
-          # TPUEstimator needs to populate batch_size itself due to sharding.
-          key: value for key, value in params.items() if key != "batch_size"
-      },
-      config=run_config)
-
-def per_replica_batch_size(batch_size, num_gpus):
-  """For multi-gpu, batch-size must be a multiple of the number of GPUs.
-
-
-  Note that distribution strategy handles this automatically when used with
-  Keras. For using with Estimator, we need to get per GPU batch.
-
-  Args:
-    batch_size: Global batch size to be divided among devices. This should be
-      equal to num_gpus times the single-GPU batch_size for multi-gpu training.
-    num_gpus: How many GPUs are used with DistributionStrategies.
-
-  Returns:
-    Batch size per device.
-
-  Raises:
-    ValueError: if batch_size is not divisible by number of devices
-  """
-  if num_gpus <= 1:
-    return batch_size
-
-  remainder = batch_size % num_gpus
-  if remainder:
-    err = ('When running with multiple GPUs, batch size '
-           'must be a multiple of the number of available GPUs. Found {} '
-           'GPUs with a batch size of {}; try --batch_size={} instead.'
-          ).format(num_gpus, batch_size, batch_size - remainder)
-    raise ValueError(err)
-  return int(batch_size / num_gpus)
-
-
-def run_transformer(flags_obj):
-  """Create tf.Estimator to train and evaluate transformer model.
-
-  Args:
-    flags_obj: Object containing parsed flag values.
-
-  Returns:
-    Dict of results of the run.  Contains the keys `eval_results`,
-    `train_hooks`, `bleu_cased`, and `bleu_uncased`. `train_hooks` is a list the
-    instances of hooks used during training.
-  """
-  num_gpus = flags_core.get_num_gpus(flags_obj)
-
-  # Add flag-defined parameters to params object
-  params = PARAMS_MAP[flags_obj.param_set]
-  if num_gpus > 1:
-    if flags_obj.param_set == "big":
-      params = model_params.BIG_MULTI_GPU_PARAMS
-    elif flags_obj.param_set == "base":
-      params = model_params.BASE_MULTI_GPU_PARAMS
-
-  params["data_dir"] = flags_obj.data_dir
-  params["model_dir"] = flags_obj.model_dir
-  params["num_parallel_calls"] = flags_obj.num_parallel_calls
-
-  params["tpu"] = flags_obj.tpu
-  params["use_tpu"] = bool(flags_obj.tpu)  # was a tpu specified.
-  params["static_batch"] = flags_obj.static_batch or params["use_tpu"]
-  params["allow_ffn_pad"] = not params["use_tpu"]
-
-  params["max_length"] = flags_obj.max_length or params["max_length"]
-
-  params["use_synthetic_data"] = flags_obj.use_synthetic_data
-
-  # Set batch size parameter, which depends on the availability of
-  # TPU and GPU, and distribution settings.
-  params["batch_size"] = (flags_obj.batch_size or (
-      params["default_batch_size_tpu"] if params["use_tpu"]
-      else params["default_batch_size"]))
-
-  total_batch_size = params["batch_size"]
-  if not params["use_tpu"]:
-    params["batch_size"] = per_replica_batch_size(params["batch_size"],
-                                                  num_gpus)
-
-  schedule_manager = schedule.Manager(
-      train_steps=flags_obj.train_steps,
-      steps_between_evals=flags_obj.steps_between_evals,
-      train_epochs=flags_obj.train_epochs,
-      epochs_between_evals=flags_obj.epochs_between_evals,
-      default_train_epochs=DEFAULT_TRAIN_EPOCHS,
-      batch_size=params["batch_size"],
-      max_length=params["max_length"],
-      use_tpu=params["use_tpu"],
-      num_tpu_shards=flags_obj.num_tpu_shards
-  )
-
-  params["repeat_dataset"] = schedule_manager.repeat_dataset
-
-  model_helpers.apply_clean(flags.FLAGS)
-
-  # Create hooks that log information about the training and metric values
-  train_hooks = hooks_helper.get_train_hooks(
-      flags_obj.hooks,
-      model_dir=flags_obj.model_dir,
-      tensors_to_log=TENSORS_TO_LOG,  # used for logging hooks
-      batch_size=total_batch_size,  # for ExamplesPerSecondHook
-      use_tpu=params["use_tpu"]  # Not all hooks can run with TPUs
-  )
-  benchmark_logger = logger.get_benchmark_logger()
-  benchmark_logger.log_run_info(
-      model_name="transformer",
-      dataset_name="wmt_translate_ende",
-      run_params=params,
-      test_id=flags_obj.benchmark_test_id)
-
-  # Train and evaluate transformer model
-  estimator = construct_estimator(flags_obj, params, schedule_manager)
-  stats = run_loop(
-      estimator=estimator,
-      # Training arguments
-      schedule_manager=schedule_manager,
-      train_hooks=train_hooks,
-      benchmark_logger=benchmark_logger,
-      # BLEU calculation arguments
-      bleu_source=flags_obj.bleu_source,
-      bleu_ref=flags_obj.bleu_ref,
-      bleu_threshold=flags_obj.stop_threshold,
-      vocab_file=flags_obj.vocab_file)
-
-  if flags_obj.export_dir and not params["use_tpu"]:
-    serving_input_fn = export.build_tensor_serving_input_receiver_fn(
-        shape=[None], dtype=tf.int64, batch_size=None)
-    # Export saved model, and save the vocab file as an extra asset. The vocab
-    # file is saved to allow consistent input encoding and output decoding.
-    # (See the "Export trained model" section in the README for an example of
-    # how to use the vocab file.)
-    # Since the model itself does not use the vocab file, this file is saved as
-    # an extra asset rather than a core asset.
-    estimator.export_savedmodel(
-        flags_obj.export_dir, serving_input_fn,
-        assets_extra={"vocab.txt": flags_obj.vocab_file},
-        strip_default_attrs=True)
-  return stats
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    run_transformer(flags.FLAGS)
-
-
-if __name__ == "__main__":
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_transformer_flags()
-  absl_app.run(main)
diff --git a/official/r1/transformer/translate.py b/official/r1/transformer/translate.py
deleted file mode 100644
index 9912ee3c..00000000
--- a/official/r1/transformer/translate.py
+++ /dev/null
@@ -1,237 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Translate text or files using trained transformer model."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-# pylint: disable=g-bad-import-order
-from absl import app as absl_app
-from absl import flags
-import tensorflow.compat.v1 as tf
-# pylint: enable=g-bad-import-order
-
-from official.nlp.transformer.utils import tokenizer
-from official.utils.flags import core as flags_core
-
-_DECODE_BATCH_SIZE = 32
-_EXTRA_DECODE_LENGTH = 100
-_BEAM_SIZE = 4
-_ALPHA = 0.6
-
-
-def _get_sorted_inputs(filename):
-  """Read and sort lines from the file sorted by decreasing length.
-
-  Args:
-    filename: String name of file to read inputs from.
-  Returns:
-    Sorted list of inputs, and dictionary mapping original index->sorted index
-    of each element.
-  """
-  with tf.io.gfile.GFile(filename) as f:
-    records = f.read().split("\n")
-    inputs = [record.strip() for record in records]
-    if not inputs[-1]:
-      inputs.pop()
-
-  input_lens = [(i, len(line.split())) for i, line in enumerate(inputs)]
-  sorted_input_lens = sorted(input_lens, key=lambda x: x[1], reverse=True)
-
-  sorted_inputs = [None] * len(sorted_input_lens)
-  sorted_keys = [0] * len(sorted_input_lens)
-  for i, (index, _) in enumerate(sorted_input_lens):
-    sorted_inputs[i] = inputs[index]
-    sorted_keys[index] = i
-
-  return sorted_inputs, sorted_keys
-
-
-def _encode_and_add_eos(line, subtokenizer):
-  """Encode line with subtokenizer, and add EOS id to the end."""
-  return subtokenizer.encode(line) + [tokenizer.EOS_ID]
-
-
-def _trim_and_decode(ids, subtokenizer):
-  """Trim EOS and PAD tokens from ids, and decode to return a string."""
-  try:
-    index = list(ids).index(tokenizer.EOS_ID)
-    return subtokenizer.decode(ids[:index])
-  except ValueError:  # No EOS found in sequence
-    return subtokenizer.decode(ids)
-
-
-def translate_file(
-    estimator, subtokenizer, input_file, output_file=None,
-    print_all_translations=True):
-  """Translate lines in file, and save to output file if specified.
-
-  Args:
-    estimator: tf.Estimator used to generate the translations.
-    subtokenizer: Subtokenizer object for encoding and decoding source and
-       translated lines.
-    input_file: file containing lines to translate
-    output_file: file that stores the generated translations.
-    print_all_translations: If true, all translations are printed to stdout.
-
-  Raises:
-    ValueError: if output file is invalid.
-  """
-  batch_size = _DECODE_BATCH_SIZE
-
-  # Read and sort inputs by length. Keep dictionary (original index-->new index
-  # in sorted list) to write translations in the original order.
-  sorted_inputs, sorted_keys = _get_sorted_inputs(input_file)
-  num_decode_batches = (len(sorted_inputs) - 1) // batch_size + 1
-
-  def input_generator():
-    """Yield encoded strings from sorted_inputs."""
-    for i, line in enumerate(sorted_inputs):
-      if i % batch_size == 0:
-        batch_num = (i // batch_size) + 1
-
-        tf.logging.info("Decoding batch %d out of %d." %
-                        (batch_num, num_decode_batches))
-      yield _encode_and_add_eos(line, subtokenizer)
-
-  def input_fn():
-    """Created batched dataset of encoded inputs."""
-    ds = tf.data.Dataset.from_generator(
-        input_generator, tf.int64, tf.TensorShape([None]))
-    ds = ds.padded_batch(batch_size, [None])
-    return ds
-
-  translations = []
-  for i, prediction in enumerate(estimator.predict(input_fn)):
-    translation = _trim_and_decode(prediction["outputs"], subtokenizer)
-    translations.append(translation)
-
-    if print_all_translations:
-      tf.logging.info("Translating:\n\tInput: %s\n\tOutput: %s" %
-                      (sorted_inputs[i], translation))
-
-  # Write translations in the order they appeared in the original file.
-  if output_file is not None:
-    if tf.io.gfile.isdir(output_file):
-      raise ValueError("File output is a directory, will not save outputs to "
-                       "file.")
-    tf.logging.info("Writing to file %s" % output_file)
-    with tf.io.gfile.GFile(output_file, "w") as f:
-      for i in sorted_keys:
-        f.write("%s\n" % translations[i])
-
-
-def translate_text(estimator, subtokenizer, txt):
-  """Translate a single string."""
-  encoded_txt = _encode_and_add_eos(txt, subtokenizer)
-
-  def input_fn():
-    ds = tf.data.Dataset.from_tensors(encoded_txt)
-    ds = ds.batch(_DECODE_BATCH_SIZE)
-    return ds
-
-  predictions = estimator.predict(input_fn)
-  translation = next(predictions)["outputs"]
-  translation = _trim_and_decode(translation, subtokenizer)
-  tf.logging.info("Translation of \"%s\": \"%s\"" % (txt, translation))
-
-
-def main(unused_argv):
-  from official.transformer import transformer_main
-
-  tf.logging.set_verbosity(tf.logging.INFO)
-
-  if FLAGS.text is None and FLAGS.file is None:
-    tf.logging.warn("Nothing to translate. Make sure to call this script using "
-                    "flags --text or --file.")
-    return
-
-  subtokenizer = tokenizer.Subtokenizer(FLAGS.vocab_file)
-
-  # Set up estimator and params
-  params = transformer_main.PARAMS_MAP[FLAGS.param_set]
-  params["beam_size"] = _BEAM_SIZE
-  params["alpha"] = _ALPHA
-  params["extra_decode_length"] = _EXTRA_DECODE_LENGTH
-  params["batch_size"] = _DECODE_BATCH_SIZE
-  estimator = tf.estimator.Estimator(
-      model_fn=transformer_main.model_fn, model_dir=FLAGS.model_dir,
-      params=params)
-
-  if FLAGS.text is not None:
-    tf.logging.info("Translating text: %s" % FLAGS.text)
-    translate_text(estimator, subtokenizer, FLAGS.text)
-
-  if FLAGS.file is not None:
-    input_file = os.path.abspath(FLAGS.file)
-    tf.logging.info("Translating file: %s" % input_file)
-    if not tf.gfile.Exists(FLAGS.file):
-      raise ValueError("File does not exist: %s" % input_file)
-
-    output_file = None
-    if FLAGS.file_out is not None:
-      output_file = os.path.abspath(FLAGS.file_out)
-      tf.logging.info("File output specified: %s" % output_file)
-
-    translate_file(estimator, subtokenizer, input_file, output_file)
-
-
-def define_translate_flags():
-  """Define flags used for translation script."""
-  # Model flags
-  flags.DEFINE_string(
-      name="model_dir", short_name="md", default="/tmp/transformer_model",
-      help=flags_core.help_wrap(
-          "Directory containing Transformer model checkpoints."))
-  flags.DEFINE_enum(
-      name="param_set", short_name="mp", default="big",
-      enum_values=["base", "big"],
-      help=flags_core.help_wrap(
-          "Parameter set to use when creating and training the model. The "
-          "parameters define the input shape (batch size and max length), "
-          "model configuration (size of embedding, # of hidden layers, etc.), "
-          "and various other settings. The big parameter set increases the "
-          "default batch size, embedding/hidden size, and filter size. For a "
-          "complete list of parameters, please see model/model_params.py."))
-  flags.DEFINE_string(
-      name="vocab_file", short_name="vf", default=None,
-      help=flags_core.help_wrap(
-          "Path to subtoken vocabulary file. If data_download.py was used to "
-          "download and encode the training data, look in the data_dir to find "
-          "the vocab file."))
-  flags.mark_flag_as_required("vocab_file")
-
-  flags.DEFINE_string(
-      name="text", default=None,
-      help=flags_core.help_wrap(
-          "Text to translate. Output will be printed to console."))
-  flags.DEFINE_string(
-      name="file", default=None,
-      help=flags_core.help_wrap(
-          "File containing text to translate. Translation will be printed to "
-          "console and, if --file_out is provided, saved to an output file."))
-  flags.DEFINE_string(
-      name="file_out", default=None,
-      help=flags_core.help_wrap(
-          "If --file flag is specified, save translation to this file."))
-
-
-if __name__ == "__main__":
-  define_translate_flags()
-  FLAGS = flags.FLAGS
-  absl_app.run(main)
diff --git a/official/r1/utils/__init__.py b/official/r1/utils/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/utils/data/__init__.py b/official/r1/utils/data/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/utils/data/file_io.py b/official/r1/utils/data/file_io.py
deleted file mode 100644
index b7776fc9..00000000
--- a/official/r1/utils/data/file_io.py
+++ /dev/null
@@ -1,207 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Convenience functions for managing dataset file buffers."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import atexit
-import multiprocessing
-import multiprocessing.dummy
-import os
-import tempfile
-import uuid
-
-from absl import logging
-import numpy as np
-import six
-import tensorflow as tf
-# pylint:disable=logging-format-interpolation
-
-
-class _GarbageCollector(object):
-  """Deletes temporary buffer files at exit.
-
-  Certain tasks (such as NCF Recommendation) require writing buffers to
-  temporary files. (Which may be local or distributed.) It is not generally safe
-  to delete these files during operation, but they should be cleaned up. This
-  class keeps track of temporary files created, and deletes them at exit.
-  """
-  def __init__(self):
-    self.temp_buffers = []
-
-  def register(self, filepath):
-    self.temp_buffers.append(filepath)
-
-  def purge(self):
-    try:
-      for i in self.temp_buffers:
-        if tf.io.gfile.exists(i):
-          tf.io.gfile.remove(i)
-          logging.info("Buffer file {} removed".format(i))
-    except Exception as e:
-      logging.error("Failed to cleanup buffer files: {}".format(e))
-
-
-_GARBAGE_COLLECTOR = _GarbageCollector()
-atexit.register(_GARBAGE_COLLECTOR.purge)
-
-_ROWS_PER_CORE = 50000
-
-
-def write_to_temp_buffer(dataframe, buffer_folder, columns):
-  if buffer_folder is None:
-    _, buffer_path = tempfile.mkstemp()
-  else:
-    tf.io.gfile.makedirs(buffer_folder)
-    buffer_path = os.path.join(buffer_folder, str(uuid.uuid4()))
-  _GARBAGE_COLLECTOR.register(buffer_path)
-
-  return write_to_buffer(dataframe, buffer_path, columns)
-
-
-def iter_shard_dataframe(df, rows_per_core=1000):
-  """Two way shard of a dataframe.
-
-  This function evenly shards a dataframe so that it can be mapped efficiently.
-  It yields a list of dataframes with length equal to the number of CPU cores,
-  with each dataframe having rows_per_core rows. (Except for the last batch
-  which may have fewer rows in the dataframes.) Passing vectorized inputs to
-  a pool is more effecient than iterating through a dataframe in serial and
-  passing a list of inputs to the pool.
-
-  Args:
-    df: Pandas dataframe to be sharded.
-    rows_per_core: Number of rows in each shard.
-
-  Returns:
-    A list of dataframe shards.
-  """
-  n = len(df)
-  num_cores = min([multiprocessing.cpu_count(), n])
-
-  num_blocks = int(np.ceil(n / num_cores / rows_per_core))
-  max_batch_size = num_cores * rows_per_core
-  for i in range(num_blocks):
-    min_index = i * max_batch_size
-    max_index = min([(i + 1) * max_batch_size, n])
-    df_shard = df[min_index:max_index]
-    n_shard = len(df_shard)
-    boundaries = np.linspace(0, n_shard, num_cores + 1, dtype=np.int64)
-    yield [df_shard[boundaries[j]:boundaries[j+1]] for j in range(num_cores)]
-
-
-def _shard_dict_to_examples(shard_dict):
-  """Converts a dict of arrays into a list of example bytes."""
-  n = [i for i in shard_dict.values()][0].shape[0]
-  feature_list = [{} for _ in range(n)]
-  for column, values in shard_dict.items():
-    if len(values.shape) == 1:
-      values = np.reshape(values, values.shape + (1,))
-
-    if values.dtype.kind == "i":
-      feature_map = lambda x: tf.train.Feature(
-          int64_list=tf.train.Int64List(value=x))
-    elif values.dtype.kind == "f":
-      feature_map = lambda x: tf.train.Feature(
-          float_list=tf.train.FloatList(value=x))
-    else:
-      raise ValueError("Invalid dtype")
-    for i in range(n):
-      feature_list[i][column] = feature_map(values[i])
-  examples = [
-      tf.train.Example(features=tf.train.Features(feature=example_features))
-      for example_features in feature_list
-  ]
-
-  return [e.SerializeToString() for e in examples]
-
-
-def _serialize_shards(df_shards, columns, pool, writer):
-  """Map sharded dataframes to bytes, and write them to a buffer.
-
-  Args:
-    df_shards: A list of pandas dataframes. (Should be of similar size)
-    columns: The dataframe columns to be serialized.
-    pool: A pool to serialize in parallel.
-    writer: A TFRecordWriter to write the serialized shards.
-  """
-  # Pandas does not store columns of arrays as nd arrays. stack remedies this.
-  map_inputs = [{c: np.stack(shard[c].values, axis=0) for c in columns}
-                for shard in df_shards]
-
-  # Failure within pools is very irksome. Thus, it is better to thoroughly check
-  # inputs in the main process.
-  for inp in map_inputs:
-    # Check that all fields have the same number of rows.
-    assert len(set([v.shape[0] for v in inp.values()])) == 1
-    for val in inp.values():
-      assert hasattr(val, "dtype")
-      assert hasattr(val.dtype, "kind")
-      assert val.dtype.kind in ("i", "f")
-      assert len(val.shape) in (1, 2)
-  shard_bytes = pool.map(_shard_dict_to_examples, map_inputs)
-  for s in shard_bytes:
-    for example in s:
-      writer.write(example)
-
-
-def write_to_buffer(dataframe, buffer_path, columns, expected_size=None):
-  """Write a dataframe to a binary file for a dataset to consume.
-
-  Args:
-    dataframe: The pandas dataframe to be serialized.
-    buffer_path: The path where the serialized results will be written.
-    columns: The dataframe columns to be serialized.
-    expected_size: The size in bytes of the serialized results. This is used to
-      lazily construct the buffer.
-
-  Returns:
-    The path of the buffer.
-  """
-  if (tf.io.gfile.exists(buffer_path) and
-      tf.io.gfile.stat(buffer_path).length > 0):
-    actual_size = tf.io.gfile.stat(buffer_path).length
-    if expected_size == actual_size:
-      return buffer_path
-    logging.warning(
-        "Existing buffer {} has size {}. Expected size {}. Deleting and "
-        "rebuilding buffer.".format(buffer_path, actual_size, expected_size))
-    tf.io.gfile.remove(buffer_path)
-
-  if dataframe is None:
-    raise ValueError(
-        "dataframe was None but a valid existing buffer was not found.")
-
-  tf.io.gfile.makedirs(os.path.split(buffer_path)[0])
-
-  logging.info("Constructing TFRecordDataset buffer: {}".format(buffer_path))
-
-  count = 0
-  pool = multiprocessing.dummy.Pool(multiprocessing.cpu_count())
-  try:
-    with tf.io.TFRecordWriter(buffer_path) as writer:
-      for df_shards in iter_shard_dataframe(df=dataframe,
-                                            rows_per_core=_ROWS_PER_CORE):
-        _serialize_shards(df_shards, columns, pool, writer)
-        count += sum([len(s) for s in df_shards])
-        logging.info("{}/{} examples written.".format(
-            str(count).ljust(8), len(dataframe)))
-  finally:
-    pool.terminate()
-
-  logging.info("Buffer write complete.")
-  return buffer_path
diff --git a/official/r1/utils/data/file_io_test.py b/official/r1/utils/data/file_io_test.py
deleted file mode 100644
index 529cb459..00000000
--- a/official/r1/utils/data/file_io_test.py
+++ /dev/null
@@ -1,197 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Tests for binary data file utilities."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import contextlib
-import multiprocessing
-
-# pylint: disable=wrong-import-order
-import numpy as np
-import pandas as pd
-import tensorflow as tf
-# pylint: enable=wrong-import-order
-
-from official.r1.utils.data import file_io
-
-
-_RAW_ROW = "raw_row"
-_DUMMY_COL = "column_0"
-_DUMMY_VEC_COL = "column_1"
-_DUMMY_VEC_LEN = 4
-
-_ROWS_PER_CORE = 4
-_TEST_CASES = [
-    # One batch of one
-    dict(row_count=1, cpu_count=1, expected=[
-        [[0]]
-    ]),
-
-    dict(row_count=10, cpu_count=1, expected=[
-        [[0, 1, 2, 3]], [[4, 5, 6, 7]], [[8, 9]]
-    ]),
-
-    dict(row_count=21, cpu_count=1, expected=[
-        [[0, 1, 2, 3]], [[4, 5, 6, 7]], [[8, 9, 10, 11]],
-        [[12, 13, 14, 15]], [[16, 17, 18, 19]], [[20]]
-    ]),
-
-    dict(row_count=1, cpu_count=4, expected=[
-        [[0]]
-    ]),
-
-    dict(row_count=10, cpu_count=4, expected=[
-        [[0, 1], [2, 3, 4], [5, 6], [7, 8, 9]]
-    ]),
-
-    dict(row_count=21, cpu_count=4, expected=[
-        [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]],
-        [[16], [17], [18], [19, 20]]
-    ]),
-
-    dict(row_count=10, cpu_count=8, expected=[
-        [[0], [1], [2], [3, 4], [5], [6], [7], [8, 9]]
-    ]),
-
-    dict(row_count=40, cpu_count=8, expected=[
-        [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15],
-         [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27],
-         [28, 29, 30, 31]],
-        [[32], [33], [34], [35], [36], [37], [38], [39]]
-    ]),
-]
-
-_FEATURE_MAP = {
-    _RAW_ROW: tf.io.FixedLenFeature([1], dtype=tf.int64),
-    _DUMMY_COL: tf.io.FixedLenFeature([1], dtype=tf.int64),
-    _DUMMY_VEC_COL: tf.io.FixedLenFeature([_DUMMY_VEC_LEN], dtype=tf.float32)
-}
-
-
-@contextlib.contextmanager
-def fixed_core_count(cpu_count):
-  """Override CPU count.
-
-  file_io.py uses the cpu_count function to scale to the size of the instance.
-  However, this is not desirable for testing because it can make the test flaky.
-  Instead, this context manager fixes the count for more robust testing.
-
-  Args:
-    cpu_count: How many cores multiprocessing claims to have.
-
-  Yields:
-    Nothing. (for context manager only)
-  """
-  old_count_fn = multiprocessing.cpu_count
-  multiprocessing.cpu_count = lambda: cpu_count
-  yield
-  multiprocessing.cpu_count = old_count_fn
-
-
-class BaseTest(tf.test.TestCase):
-
-  def setUp(self):
-    super(BaseTest, self).setUp()
-    tf.compat.v1.disable_eager_execution()
-
-  def _test_sharding(self, row_count, cpu_count, expected):
-    df = pd.DataFrame({_DUMMY_COL: list(range(row_count))})
-    with fixed_core_count(cpu_count):
-      shards = list(file_io.iter_shard_dataframe(df, _ROWS_PER_CORE))
-    result = [[j[_DUMMY_COL].tolist() for j in i] for i in shards]
-    self.assertAllEqual(expected, result)
-
-  def test_tiny_rows_low_core(self):
-    self._test_sharding(**_TEST_CASES[0])
-
-  def test_small_rows_low_core(self):
-    self._test_sharding(**_TEST_CASES[1])
-
-  def test_large_rows_low_core(self):
-    self._test_sharding(**_TEST_CASES[2])
-
-  def test_tiny_rows_medium_core(self):
-    self._test_sharding(**_TEST_CASES[3])
-
-  def test_small_rows_medium_core(self):
-    self._test_sharding(**_TEST_CASES[4])
-
-  def test_large_rows_medium_core(self):
-    self._test_sharding(**_TEST_CASES[5])
-
-  def test_small_rows_large_core(self):
-    self._test_sharding(**_TEST_CASES[6])
-
-  def test_large_rows_large_core(self):
-    self._test_sharding(**_TEST_CASES[7])
-
-  def _serialize_deserialize(self, num_cores=1, num_rows=20):
-    np.random.seed(1)
-    df = pd.DataFrame({
-        # Serialization order is only deterministic for num_cores=1. raw_row is
-        # used in validation after the deserialization.
-        _RAW_ROW: np.array(range(num_rows), dtype=np.int64),
-        _DUMMY_COL: np.random.randint(0, 35, size=(num_rows,)),
-        _DUMMY_VEC_COL: [
-            np.array([np.random.random() for _ in range(_DUMMY_VEC_LEN)])
-            for i in range(num_rows)  # pylint: disable=unused-variable
-        ]
-    })
-
-    with fixed_core_count(num_cores):
-      buffer_path = file_io.write_to_temp_buffer(
-          df, self.get_temp_dir(), [_RAW_ROW, _DUMMY_COL, _DUMMY_VEC_COL])
-
-    with self.session(graph=tf.Graph()) as sess:
-      dataset = tf.data.TFRecordDataset(buffer_path)
-      dataset = dataset.batch(1).map(
-          lambda x: tf.io.parse_example(serialized=x, features=_FEATURE_MAP))
-
-      data_iter = tf.compat.v1.data.make_one_shot_iterator(dataset)
-      seen_rows = set()
-      for i in range(num_rows+5):
-        row = data_iter.get_next()
-        try:
-          row_id, val_0, val_1 = sess.run(
-              [row[_RAW_ROW], row[_DUMMY_COL], row[_DUMMY_VEC_COL]])
-          row_id, val_0, val_1 = row_id[0][0], val_0[0][0], val_1[0]
-          assert row_id not in seen_rows
-          seen_rows.add(row_id)
-
-          self.assertEqual(val_0, df[_DUMMY_COL][row_id])
-          self.assertAllClose(val_1, df[_DUMMY_VEC_COL][row_id])
-
-          self.assertLess(i, num_rows, msg="Too many rows.")
-        except tf.errors.OutOfRangeError:
-          self.assertGreaterEqual(i, num_rows, msg="Too few rows.")
-
-    file_io._GARBAGE_COLLECTOR.purge()
-    assert not tf.io.gfile.exists(buffer_path)
-
-  def test_serialize_deserialize_0(self):
-    self._serialize_deserialize(num_cores=1)
-
-  def test_serialize_deserialize_1(self):
-    self._serialize_deserialize(num_cores=2)
-
-  def test_serialize_deserialize_2(self):
-    self._serialize_deserialize(num_cores=8)
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/utils/export.py b/official/r1/utils/export.py
deleted file mode 100644
index 8061c288..00000000
--- a/official/r1/utils/export.py
+++ /dev/null
@@ -1,49 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Convenience functions for exporting models as SavedModels or other types."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf
-
-
-def build_tensor_serving_input_receiver_fn(shape, dtype=tf.float32,
-                                           batch_size=1):
-  """Returns a input_receiver_fn that can be used during serving.
-
-  This expects examples to come through as float tensors, and simply
-  wraps them as TensorServingInputReceivers.
-
-  Arguably, this should live in tf.estimator.export. Testing here first.
-
-  Args:
-    shape: list representing target size of a single example.
-    dtype: the expected datatype for the input example
-    batch_size: number of input tensors that will be passed for prediction
-
-  Returns:
-    A function that itself returns a TensorServingInputReceiver.
-  """
-  def serving_input_receiver_fn():
-    # Prep a placeholder where the input example will be fed in
-    features = tf.compat.v1.placeholder(
-        dtype=dtype, shape=[batch_size] + shape, name='input_tensor')
-
-    return tf.estimator.export.TensorServingInputReceiver(
-        features=features, receiver_tensors=features)
-
-  return serving_input_receiver_fn
diff --git a/official/r1/utils/export_test.py b/official/r1/utils/export_test.py
deleted file mode 100644
index 3785edd4..00000000
--- a/official/r1/utils/export_test.py
+++ /dev/null
@@ -1,63 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Tests for exporting utils."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-
-from official.r1.utils import export
-
-
-class ExportUtilsTest(tf.test.TestCase):
-  """Tests for the ExportUtils."""
-
-  def test_build_tensor_serving_input_receiver_fn(self):
-    receiver_fn = export.build_tensor_serving_input_receiver_fn(shape=[4, 5])
-    with tf.Graph().as_default():
-      receiver = receiver_fn()
-      self.assertIsInstance(
-          receiver, tf.estimator.export.TensorServingInputReceiver)
-
-      self.assertIsInstance(receiver.features, tf.Tensor)
-      self.assertEqual(receiver.features.shape, tf.TensorShape([1, 4, 5]))
-      self.assertEqual(receiver.features.dtype, tf.float32)
-      self.assertIsInstance(receiver.receiver_tensors, dict)
-      # Note that Python 3 can no longer index .values() directly; cast to list.
-      self.assertEqual(list(receiver.receiver_tensors.values())[0].shape,
-                       tf.TensorShape([1, 4, 5]))
-
-  def test_build_tensor_serving_input_receiver_fn_batch_dtype(self):
-    receiver_fn = export.build_tensor_serving_input_receiver_fn(
-        shape=[4, 5], dtype=tf.int8, batch_size=10)
-
-    with tf.Graph().as_default():
-      receiver = receiver_fn()
-      self.assertIsInstance(
-          receiver, tf.estimator.export.TensorServingInputReceiver)
-
-      self.assertIsInstance(receiver.features, tf.Tensor)
-      self.assertEqual(receiver.features.shape, tf.TensorShape([10, 4, 5]))
-      self.assertEqual(receiver.features.dtype, tf.int8)
-      self.assertIsInstance(receiver.receiver_tensors, dict)
-      # Note that Python 3 can no longer index .values() directly; cast to list.
-      self.assertEqual(list(receiver.receiver_tensors.values())[0].shape,
-                       tf.TensorShape([10, 4, 5]))
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/utils/logs/__init__.py b/official/r1/utils/logs/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/utils/logs/cloud_lib.py b/official/r1/utils/logs/cloud_lib.py
deleted file mode 100644
index a2d9bd3d..00000000
--- a/official/r1/utils/logs/cloud_lib.py
+++ /dev/null
@@ -1,34 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Utilities that interact with cloud service.
-"""
-
-import requests
-
-GCP_METADATA_URL = "http://metadata/computeMetadata/v1/instance/hostname"
-GCP_METADATA_HEADER = {"Metadata-Flavor": "Google"}
-
-
-def on_gcp():
-  """Detect whether the current running environment is on GCP."""
-  try:
-    # Timeout in 5 seconds, in case the test environment has connectivity issue.
-    # There is not default timeout, which means it might block forever.
-    response = requests.get(
-        GCP_METADATA_URL, headers=GCP_METADATA_HEADER, timeout=5)
-    return response.status_code == 200
-  except requests.exceptions.RequestException:
-    return False
diff --git a/official/r1/utils/logs/cloud_lib_test.py b/official/r1/utils/logs/cloud_lib_test.py
deleted file mode 100644
index 15cdc3c6..00000000
--- a/official/r1/utils/logs/cloud_lib_test.py
+++ /dev/null
@@ -1,48 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Tests for cloud_lib."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import unittest
-
-import mock
-import requests
-
-from official.r1.utils.logs import cloud_lib
-
-
-class CloudLibTest(unittest.TestCase):
-
-  @mock.patch("requests.get")
-  def test_on_gcp(self, mock_requests_get):
-    mock_response = mock.MagicMock()
-    mock_requests_get.return_value = mock_response
-    mock_response.status_code = 200
-
-    self.assertEqual(cloud_lib.on_gcp(), True)
-
-  @mock.patch("requests.get")
-  def test_not_on_gcp(self, mock_requests_get):
-    mock_requests_get.side_effect = requests.exceptions.ConnectionError()
-
-    self.assertEqual(cloud_lib.on_gcp(), False)
-
-
-if __name__ == "__main__":
-  unittest.main()
diff --git a/official/r1/utils/logs/guidelines.md b/official/r1/utils/logs/guidelines.md
deleted file mode 100644
index 408c3cd5..00000000
--- a/official/r1/utils/logs/guidelines.md
+++ /dev/null
@@ -1,58 +0,0 @@
-# Logging in official models
-
-This library adds logging functions that print or save tensor values. Official models should define all common hooks
-(using hooks helper) and a benchmark logger.
-
-1. **Training Hooks**
-
-   Hooks are a TensorFlow concept that define specific actions at certain points of the execution. We use them to obtain and log
-   tensor values during training.
-
-   hooks_helper.py provides an easy way to create common hooks. The following hooks are currently defined:
-   * LoggingTensorHook: Logs tensor values
-   * ProfilerHook: Writes a timeline json that can be loaded into chrome://tracing.
-   * ExamplesPerSecondHook: Logs the number of examples processed per second.
-   * LoggingMetricHook: Similar to LoggingTensorHook, except that the tensors are logged in a format defined by our data
-     anaylsis pipeline.
-
-
-2. **Benchmarks**
-
-   The benchmark logger provides useful functions for logging environment information, and evaluation results.
-   The module also contains a context which is used to update the status of the run.
-
-Example usage:
-
-```
-from absl import app as absl_app
-
-from official.utils.logs import hooks_helper
-from official.utils.logs import logger
-
-def model_main(flags_obj):
-  estimator = ...
-
-  benchmark_logger = logger.get_benchmark_logger()
-  benchmark_logger.log_run_info(...)
-
-  train_hooks = hooks_helper.get_train_hooks(...)
-
-  for epoch in range(10):
-    estimator.train(..., hooks=train_hooks)
-    eval_results = estimator.evaluate(...)
-
-    # Log a dictionary of metrics
-    benchmark_logger.log_evaluation_result(eval_results)
-
-    # Log an individual metric
-    benchmark_logger.log_metric(...)
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    model_main(flags.FLAGS)
-
-if __name__ == "__main__":
-  # define flags
-  absl_app.run(main)
-```
diff --git a/official/r1/utils/logs/hooks.py b/official/r1/utils/logs/hooks.py
deleted file mode 100644
index c595eabb..00000000
--- a/official/r1/utils/logs/hooks.py
+++ /dev/null
@@ -1,130 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Hook that counts examples per second every N steps or seconds."""
-
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-
-from official.r1.utils.logs import logger
-
-
-class ExamplesPerSecondHook(tf.estimator.SessionRunHook):
-  """Hook to print out examples per second.
-
-  Total time is tracked and then divided by the total number of steps
-  to get the average step time and then batch_size is used to determine
-  the running average of examples per second. The examples per second for the
-  most recent interval is also logged.
-  """
-
-  def __init__(self,
-               batch_size,
-               every_n_steps=None,
-               every_n_secs=None,
-               warm_steps=0,
-               metric_logger=None):
-    """Initializer for ExamplesPerSecondHook.
-
-    Args:
-      batch_size: Total batch size across all workers used to calculate
-        examples/second from global time.
-      every_n_steps: Log stats every n steps.
-      every_n_secs: Log stats every n seconds. Exactly one of the
-        `every_n_steps` or `every_n_secs` should be set.
-      warm_steps: The number of steps to be skipped before logging and running
-        average calculation. warm_steps steps refers to global steps across all
-        workers, not on each worker
-      metric_logger: instance of `BenchmarkLogger`, the benchmark logger that
-          hook should use to write the log. If None, BaseBenchmarkLogger will
-          be used.
-
-    Raises:
-      ValueError: if neither `every_n_steps` or `every_n_secs` is set, or
-      both are set.
-    """
-
-    if (every_n_steps is None) == (every_n_secs is None):
-      raise ValueError("exactly one of every_n_steps"
-                       " and every_n_secs should be provided.")
-
-    self._logger = metric_logger or logger.BaseBenchmarkLogger()
-
-    self._timer = tf.estimator.SecondOrStepTimer(
-        every_steps=every_n_steps, every_secs=every_n_secs)
-
-    self._step_train_time = 0
-    self._total_steps = 0
-    self._batch_size = batch_size
-    self._warm_steps = warm_steps
-    # List of examples per second logged every_n_steps.
-    self.current_examples_per_sec_list = []
-
-  def begin(self):
-    """Called once before using the session to check global step."""
-    self._global_step_tensor = tf.compat.v1.train.get_global_step()
-    if self._global_step_tensor is None:
-      raise RuntimeError(
-          "Global step should be created to use StepCounterHook.")
-
-  def before_run(self, run_context):  # pylint: disable=unused-argument
-    """Called before each call to run().
-
-    Args:
-      run_context: A SessionRunContext object.
-
-    Returns:
-      A SessionRunArgs object or None if never triggered.
-    """
-    return tf.estimator.SessionRunArgs(self._global_step_tensor)
-
-  def after_run(self, run_context, run_values):  # pylint: disable=unused-argument
-    """Called after each call to run().
-
-    Args:
-      run_context: A SessionRunContext object.
-      run_values: A SessionRunValues object.
-    """
-    global_step = run_values.results
-
-    if self._timer.should_trigger_for_step(
-        global_step) and global_step > self._warm_steps:
-      elapsed_time, elapsed_steps = self._timer.update_last_triggered_step(
-          global_step)
-      if elapsed_time is not None:
-        self._step_train_time += elapsed_time
-        self._total_steps += elapsed_steps
-
-        # average examples per second is based on the total (accumulative)
-        # training steps and training time so far
-        average_examples_per_sec = self._batch_size * (
-            self._total_steps / self._step_train_time)
-        # current examples per second is based on the elapsed training steps
-        # and training time per batch
-        current_examples_per_sec = self._batch_size * (
-            elapsed_steps / elapsed_time)
-        # Logs entries to be read from hook during or after run.
-        self.current_examples_per_sec_list.append(current_examples_per_sec)
-        self._logger.log_metric(
-            "average_examples_per_sec", average_examples_per_sec,
-            global_step=global_step)
-
-        self._logger.log_metric(
-            "current_examples_per_sec", current_examples_per_sec,
-            global_step=global_step)
diff --git a/official/r1/utils/logs/hooks_helper.py b/official/r1/utils/logs/hooks_helper.py
deleted file mode 100644
index 1e823241..00000000
--- a/official/r1/utils/logs/hooks_helper.py
+++ /dev/null
@@ -1,173 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Hooks helper to return a list of TensorFlow hooks for training by name.
-
-More hooks can be added to this set. To add a new hook, 1) add the new hook to
-the registry in HOOKS, 2) add a corresponding function that parses out necessary
-parameters.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-from absl import logging
-
-from official.r1.utils.logs import hooks
-from official.r1.utils.logs import logger
-from official.r1.utils.logs import metric_hook
-
-_TENSORS_TO_LOG = dict((x, x) for x in ['learning_rate',
-                                        'cross_entropy',
-                                        'train_accuracy'])
-
-
-def get_train_hooks(name_list, use_tpu=False, **kwargs):
-  """Factory for getting a list of TensorFlow hooks for training by name.
-
-  Args:
-    name_list: a list of strings to name desired hook classes. Allowed:
-      LoggingTensorHook, ProfilerHook, ExamplesPerSecondHook, which are defined
-      as keys in HOOKS
-    use_tpu: Boolean of whether computation occurs on a TPU. This will disable
-      hooks altogether.
-    **kwargs: a dictionary of arguments to the hooks.
-
-  Returns:
-    list of instantiated hooks, ready to be used in a classifier.train call.
-
-  Raises:
-    ValueError: if an unrecognized name is passed.
-  """
-
-  if not name_list:
-    return []
-
-  if use_tpu:
-    logging.warning(
-        'hooks_helper received name_list `%s`, but a '
-        'TPU is specified. No hooks will be used.', name_list)
-    return []
-
-  train_hooks = []
-  for name in name_list:
-    hook_name = HOOKS.get(name.strip().lower())
-    if hook_name is None:
-      raise ValueError('Unrecognized training hook requested: {}'.format(name))
-    else:
-      train_hooks.append(hook_name(**kwargs))
-
-  return train_hooks
-
-
-def get_logging_tensor_hook(every_n_iter=100, tensors_to_log=None, **kwargs):  # pylint: disable=unused-argument
-  """Function to get LoggingTensorHook.
-
-  Args:
-    every_n_iter: `int`, print the values of `tensors` once every N local
-      steps taken on the current worker.
-    tensors_to_log: List of tensor names or dictionary mapping labels to tensor
-      names. If not set, log _TENSORS_TO_LOG by default.
-    **kwargs: a dictionary of arguments to LoggingTensorHook.
-
-  Returns:
-    Returns a LoggingTensorHook with a standard set of tensors that will be
-    printed to stdout.
-  """
-  if tensors_to_log is None:
-    tensors_to_log = _TENSORS_TO_LOG
-
-  return tf.estimator.LoggingTensorHook(
-      tensors=tensors_to_log,
-      every_n_iter=every_n_iter)
-
-
-def get_profiler_hook(model_dir, save_steps=1000, **kwargs):  # pylint: disable=unused-argument
-  """Function to get ProfilerHook.
-
-  Args:
-    model_dir: The directory to save the profile traces to.
-    save_steps: `int`, print profile traces every N steps.
-    **kwargs: a dictionary of arguments to ProfilerHook.
-
-  Returns:
-    Returns a ProfilerHook that writes out timelines that can be loaded into
-    profiling tools like chrome://tracing.
-  """
-  return tf.estimator.ProfilerHook(save_steps=save_steps, output_dir=model_dir)
-
-
-def get_examples_per_second_hook(every_n_steps=100,
-                                 batch_size=128,
-                                 warm_steps=5,
-                                 **kwargs):  # pylint: disable=unused-argument
-  """Function to get ExamplesPerSecondHook.
-
-  Args:
-    every_n_steps: `int`, print current and average examples per second every
-      N steps.
-    batch_size: `int`, total batch size used to calculate examples/second from
-      global time.
-    warm_steps: skip this number of steps before logging and running average.
-    **kwargs: a dictionary of arguments to ExamplesPerSecondHook.
-
-  Returns:
-    Returns a ProfilerHook that writes out timelines that can be loaded into
-    profiling tools like chrome://tracing.
-  """
-  return hooks.ExamplesPerSecondHook(
-      batch_size=batch_size, every_n_steps=every_n_steps,
-      warm_steps=warm_steps, metric_logger=logger.get_benchmark_logger())
-
-
-def get_logging_metric_hook(tensors_to_log=None,
-                            every_n_secs=600,
-                            **kwargs):  # pylint: disable=unused-argument
-  """Function to get LoggingMetricHook.
-
-  Args:
-    tensors_to_log: List of tensor names or dictionary mapping labels to tensor
-      names. If not set, log _TENSORS_TO_LOG by default.
-    every_n_secs: `int`, the frequency for logging the metric. Default to every
-      10 mins.
-    **kwargs: a dictionary of arguments.
-
-  Returns:
-    Returns a LoggingMetricHook that saves tensor values in a JSON format.
-  """
-  if tensors_to_log is None:
-    tensors_to_log = _TENSORS_TO_LOG
-  return metric_hook.LoggingMetricHook(
-      tensors=tensors_to_log,
-      metric_logger=logger.get_benchmark_logger(),
-      every_n_secs=every_n_secs)
-
-
-def get_step_counter_hook(**kwargs):
-  """Function to get StepCounterHook."""
-  del kwargs
-  return tf.estimator.StepCounterHook()
-
-
-# A dictionary to map one hook name and its corresponding function
-HOOKS = {
-    'loggingtensorhook': get_logging_tensor_hook,
-    'profilerhook': get_profiler_hook,
-    'examplespersecondhook': get_examples_per_second_hook,
-    'loggingmetrichook': get_logging_metric_hook,
-    'stepcounterhook': get_step_counter_hook
-}
diff --git a/official/r1/utils/logs/hooks_test.py b/official/r1/utils/logs/hooks_test.py
deleted file mode 100644
index 5ce4c5e5..00000000
--- a/official/r1/utils/logs/hooks_test.py
+++ /dev/null
@@ -1,159 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Tests for hooks."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import time
-
-from absl import logging
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-
-from official.r1.utils.logs import hooks
-from official.r1.utils.logs import mock_lib
-
-logging.set_verbosity(logging.DEBUG)
-
-
-class ExamplesPerSecondHookTest(tf.test.TestCase):
-  """Tests for the ExamplesPerSecondHook.
-
-  In the test, we explicitly run global_step tensor after train_op in order to
-  keep the global_step value and the train_op (which increase the glboal_step
-  by 1) consistent. This is to correct the discrepancies in reported global_step
-  value when running on GPUs.
-  """
-
-  def setUp(self):
-    """Mock out logging calls to verify if correct info is being monitored."""
-    self._logger = mock_lib.MockBenchmarkLogger()
-
-    self.graph = tf.Graph()
-    with self.graph.as_default():
-      tf.compat.v1.train.create_global_step()
-      self.train_op = tf.compat.v1.assign_add(
-          tf.compat.v1.train.get_global_step(), 1)
-      self.global_step = tf.compat.v1.train.get_global_step()
-
-  def test_raise_in_both_secs_and_steps(self):
-    with self.assertRaises(ValueError):
-      hooks.ExamplesPerSecondHook(
-          batch_size=256,
-          every_n_steps=10,
-          every_n_secs=20,
-          metric_logger=self._logger)
-
-  def test_raise_in_none_secs_and_steps(self):
-    with self.assertRaises(ValueError):
-      hooks.ExamplesPerSecondHook(
-          batch_size=256,
-          every_n_steps=None,
-          every_n_secs=None,
-          metric_logger=self._logger)
-
-  def _validate_log_every_n_steps(self, every_n_steps, warm_steps):
-    hook = hooks.ExamplesPerSecondHook(
-        batch_size=256,
-        every_n_steps=every_n_steps,
-        warm_steps=warm_steps,
-        metric_logger=self._logger)
-
-    with tf.compat.v1.train.MonitoredSession(
-        tf.compat.v1.train.ChiefSessionCreator(), [hook]) as mon_sess:
-      for _ in range(every_n_steps):
-        # Explicitly run global_step after train_op to get the accurate
-        # global_step value
-        mon_sess.run(self.train_op)
-        mon_sess.run(self.global_step)
-        # Nothing should be in the list yet
-        self.assertFalse(self._logger.logged_metric)
-
-      mon_sess.run(self.train_op)
-      global_step_val = mon_sess.run(self.global_step)
-
-      if global_step_val > warm_steps:
-        self._assert_metrics()
-      else:
-        # Nothing should be in the list yet
-        self.assertFalse(self._logger.logged_metric)
-
-      # Add additional run to verify proper reset when called multiple times.
-      prev_log_len = len(self._logger.logged_metric)
-      mon_sess.run(self.train_op)
-      global_step_val = mon_sess.run(self.global_step)
-
-      if every_n_steps == 1 and global_step_val > warm_steps:
-        # Each time, we log two additional metrics. Did exactly 2 get added?
-        self.assertEqual(len(self._logger.logged_metric), prev_log_len + 2)
-      else:
-        # No change in the size of the metric list.
-        self.assertEqual(len(self._logger.logged_metric), prev_log_len)
-
-  def test_examples_per_sec_every_1_steps(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_steps(1, 0)
-
-  def test_examples_per_sec_every_5_steps(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_steps(5, 0)
-
-  def test_examples_per_sec_every_1_steps_with_warm_steps(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_steps(1, 10)
-
-  def test_examples_per_sec_every_5_steps_with_warm_steps(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_steps(5, 10)
-
-  def _validate_log_every_n_secs(self, every_n_secs):
-    hook = hooks.ExamplesPerSecondHook(
-        batch_size=256,
-        every_n_steps=None,
-        every_n_secs=every_n_secs,
-        metric_logger=self._logger)
-
-    with tf.compat.v1.train.MonitoredSession(
-        tf.compat.v1.train.ChiefSessionCreator(), [hook]) as mon_sess:
-      # Explicitly run global_step after train_op to get the accurate
-      # global_step value
-      mon_sess.run(self.train_op)
-      mon_sess.run(self.global_step)
-      # Nothing should be in the list yet
-      self.assertFalse(self._logger.logged_metric)
-      time.sleep(every_n_secs)
-
-      mon_sess.run(self.train_op)
-      mon_sess.run(self.global_step)
-      self._assert_metrics()
-
-  def test_examples_per_sec_every_1_secs(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_secs(1)
-
-  def test_examples_per_sec_every_5_secs(self):
-    with self.graph.as_default():
-      self._validate_log_every_n_secs(5)
-
-  def _assert_metrics(self):
-    metrics = self._logger.logged_metric
-    self.assertEqual(metrics[-2]["name"], "average_examples_per_sec")
-    self.assertEqual(metrics[-1]["name"], "current_examples_per_sec")
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/utils/logs/logger.py b/official/r1/utils/logs/logger.py
deleted file mode 100644
index 587053e9..00000000
--- a/official/r1/utils/logs/logger.py
+++ /dev/null
@@ -1,305 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Logging utilities for benchmark.
-
-For collecting local environment metrics like CPU and memory, certain python
-packages need be installed. See README for details.
-"""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import contextlib
-import datetime
-import json
-import numbers
-import os
-import threading
-import uuid
-
-from absl import flags
-from absl import logging
-from six.moves import _thread as thread
-import tensorflow as tf
-from tensorflow.python.client import device_lib
-from official.r1.utils.logs import cloud_lib
-
-METRIC_LOG_FILE_NAME = "metric.log"
-BENCHMARK_RUN_LOG_FILE_NAME = "benchmark_run.log"
-_DATE_TIME_FORMAT_PATTERN = "%Y-%m-%dT%H:%M:%S.%fZ"
-GCP_TEST_ENV = "GCP"
-RUN_STATUS_SUCCESS = "success"
-RUN_STATUS_FAILURE = "failure"
-RUN_STATUS_RUNNING = "running"
-
-
-FLAGS = flags.FLAGS
-
-# Don't use it directly. Use get_benchmark_logger to access a logger.
-_benchmark_logger = None
-_logger_lock = threading.Lock()
-
-
-def config_benchmark_logger(flag_obj=None):
-  """Config the global benchmark logger."""
-  _logger_lock.acquire()
-  try:
-    global _benchmark_logger
-    if not flag_obj:
-      flag_obj = FLAGS
-
-    if (not hasattr(flag_obj, "benchmark_logger_type") or
-        flag_obj.benchmark_logger_type == "BaseBenchmarkLogger"):
-      _benchmark_logger = BaseBenchmarkLogger()
-    elif flag_obj.benchmark_logger_type == "BenchmarkFileLogger":
-      _benchmark_logger = BenchmarkFileLogger(flag_obj.benchmark_log_dir)
-    else:
-      raise ValueError("Unrecognized benchmark_logger_type: %s"
-                       % flag_obj.benchmark_logger_type)
-
-  finally:
-    _logger_lock.release()
-  return _benchmark_logger
-
-
-def get_benchmark_logger():
-  if not _benchmark_logger:
-    config_benchmark_logger()
-  return _benchmark_logger
-
-
-@contextlib.contextmanager
-def benchmark_context(flag_obj):
-  """Context of benchmark, which will update status of the run accordingly."""
-  benchmark_logger = config_benchmark_logger(flag_obj)
-  try:
-    yield
-    benchmark_logger.on_finish(RUN_STATUS_SUCCESS)
-  except Exception:  # pylint: disable=broad-except
-    # Catch all the exception, update the run status to be failure, and re-raise
-    benchmark_logger.on_finish(RUN_STATUS_FAILURE)
-    raise
-
-
-class BaseBenchmarkLogger(object):
-  """Class to log the benchmark information to STDOUT."""
-
-  def log_evaluation_result(self, eval_results):
-    """Log the evaluation result.
-
-    The evaluate result is a dictionary that contains metrics defined in
-    model_fn. It also contains a entry for global_step which contains the value
-    of the global step when evaluation was performed.
-
-    Args:
-      eval_results: dict, the result of evaluate.
-    """
-    if not isinstance(eval_results, dict):
-      logging.warning("eval_results should be dictionary for logging. Got %s",
-                      type(eval_results))
-      return
-    global_step = eval_results[tf.compat.v1.GraphKeys.GLOBAL_STEP]
-    for key in sorted(eval_results):
-      if key != tf.compat.v1.GraphKeys.GLOBAL_STEP:
-        self.log_metric(key, eval_results[key], global_step=global_step)
-
-  def log_metric(self, name, value, unit=None, global_step=None, extras=None):
-    """Log the benchmark metric information to local file.
-
-    Currently the logging is done in a synchronized way. This should be updated
-    to log asynchronously.
-
-    Args:
-      name: string, the name of the metric to log.
-      value: number, the value of the metric. The value will not be logged if it
-        is not a number type.
-      unit: string, the unit of the metric, E.g "image per second".
-      global_step: int, the global_step when the metric is logged.
-      extras: map of string:string, the extra information about the metric.
-    """
-    metric = _process_metric_to_json(name, value, unit, global_step, extras)
-    if metric:
-      logging.info("Benchmark metric: %s", metric)
-
-  def log_run_info(self, model_name, dataset_name, run_params, test_id=None):
-    logging.info(
-        "Benchmark run: %s",
-        _gather_run_info(model_name, dataset_name, run_params, test_id))
-
-  def on_finish(self, status):
-    pass
-
-
-class BenchmarkFileLogger(BaseBenchmarkLogger):
-  """Class to log the benchmark information to local disk."""
-
-  def __init__(self, logging_dir):
-    super(BenchmarkFileLogger, self).__init__()
-    self._logging_dir = logging_dir
-    if not tf.io.gfile.isdir(self._logging_dir):
-      tf.io.gfile.makedirs(self._logging_dir)
-    self._metric_file_handler = tf.io.gfile.GFile(
-        os.path.join(self._logging_dir, METRIC_LOG_FILE_NAME), "a")
-
-  def log_metric(self, name, value, unit=None, global_step=None, extras=None):
-    """Log the benchmark metric information to local file.
-
-    Currently the logging is done in a synchronized way. This should be updated
-    to log asynchronously.
-
-    Args:
-      name: string, the name of the metric to log.
-      value: number, the value of the metric. The value will not be logged if it
-        is not a number type.
-      unit: string, the unit of the metric, E.g "image per second".
-      global_step: int, the global_step when the metric is logged.
-      extras: map of string:string, the extra information about the metric.
-    """
-    metric = _process_metric_to_json(name, value, unit, global_step, extras)
-    if metric:
-      try:
-        json.dump(metric, self._metric_file_handler)
-        self._metric_file_handler.write("\n")
-        self._metric_file_handler.flush()
-      except (TypeError, ValueError) as e:
-        logging.warning(
-            "Failed to dump metric to log file: name %s, value %s, error %s",
-            name, value, e)
-
-  def log_run_info(self, model_name, dataset_name, run_params, test_id=None):
-    """Collect most of the TF runtime information for the local env.
-
-    The schema of the run info follows official/benchmark/datastore/schema.
-
-    Args:
-      model_name: string, the name of the model.
-      dataset_name: string, the name of dataset for training and evaluation.
-      run_params: dict, the dictionary of parameters for the run, it could
-        include hyperparameters or other params that are important for the run.
-      test_id: string, the unique name of the test run by the combination of key
-        parameters, eg batch size, num of GPU. It is hardware independent.
-    """
-    run_info = _gather_run_info(model_name, dataset_name, run_params, test_id)
-
-    with tf.io.gfile.GFile(os.path.join(
-        self._logging_dir, BENCHMARK_RUN_LOG_FILE_NAME), "w") as f:
-      try:
-        json.dump(run_info, f)
-        f.write("\n")
-      except (TypeError, ValueError) as e:
-        logging.warning("Failed to dump benchmark run info to log file: %s", e)
-
-  def on_finish(self, status):
-    self._metric_file_handler.flush()
-    self._metric_file_handler.close()
-
-
-def _gather_run_info(model_name, dataset_name, run_params, test_id):
-  """Collect the benchmark run information for the local environment."""
-  run_info = {
-      "model_name": model_name,
-      "dataset": {"name": dataset_name},
-      "machine_config": {},
-      "test_id": test_id,
-      "run_date": datetime.datetime.utcnow().strftime(
-          _DATE_TIME_FORMAT_PATTERN)}
-  _collect_tensorflow_info(run_info)
-  _collect_tensorflow_environment_variables(run_info)
-  _collect_run_params(run_info, run_params)
-  _collect_memory_info(run_info)
-  _collect_test_environment(run_info)
-  return run_info
-
-
-def _process_metric_to_json(
-    name, value, unit=None, global_step=None, extras=None):
-  """Validate the metric data and generate JSON for insert."""
-  if not isinstance(value, numbers.Number):
-    logging.warning("Metric value to log should be a number. Got %s",
-                    type(value))
-    return None
-
-  extras = _convert_to_json_dict(extras)
-  return {
-      "name": name,
-      "value": float(value),
-      "unit": unit,
-      "global_step": global_step,
-      "timestamp": datetime.datetime.utcnow().strftime(
-          _DATE_TIME_FORMAT_PATTERN),
-      "extras": extras}
-
-
-def _collect_tensorflow_info(run_info):
-  run_info["tensorflow_version"] = {
-      "version": tf.version.VERSION, "git_hash": tf.version.GIT_VERSION}
-
-
-def _collect_run_params(run_info, run_params):
-  """Log the parameter information for the benchmark run."""
-  def process_param(name, value):
-    type_check = {
-        str: {"name": name, "string_value": value},
-        int: {"name": name, "long_value": value},
-        bool: {"name": name, "bool_value": str(value)},
-        float: {"name": name, "float_value": value},
-    }
-    return type_check.get(type(value),
-                          {"name": name, "string_value": str(value)})
-  if run_params:
-    run_info["run_parameters"] = [
-        process_param(k, v) for k, v in sorted(run_params.items())]
-
-
-def _collect_tensorflow_environment_variables(run_info):
-  run_info["tensorflow_environment_variables"] = [
-      {"name": k, "value": v}
-      for k, v in sorted(os.environ.items()) if k.startswith("TF_")]
-
-
-def _collect_memory_info(run_info):
-  try:
-    # Note: psutil is not installed in the TensorFlow OSS tree.
-    # It is installable via pip.
-    import psutil   # pylint: disable=g-import-not-at-top
-    vmem = psutil.virtual_memory()
-    run_info["machine_config"]["memory_total"] = vmem.total
-    run_info["machine_config"]["memory_available"] = vmem.available
-  except ImportError:
-    logging.warn("'psutil' not imported. Memory info will not be logged.")
-
-
-def _collect_test_environment(run_info):
-  """Detect the local environment, eg GCE, AWS or DGX, etc."""
-  if cloud_lib.on_gcp():
-    run_info["test_environment"] = GCP_TEST_ENV
-  # TODO(scottzhu): Add more testing env detection for other platform
-
-
-def _parse_gpu_model(physical_device_desc):
-  # Assume all the GPU connected are same model
-  for kv in physical_device_desc.split(","):
-    k, _, v = kv.partition(":")
-    if k.strip() == "name":
-      return v.strip()
-  return None
-
-
-def _convert_to_json_dict(input_dict):
-  if input_dict:
-    return [{"name": k, "value": v} for k, v in sorted(input_dict.items())]
-  else:
-    return []
diff --git a/official/r1/utils/logs/logger_test.py b/official/r1/utils/logs/logger_test.py
deleted file mode 100644
index 96a8802d..00000000
--- a/official/r1/utils/logs/logger_test.py
+++ /dev/null
@@ -1,253 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Tests for benchmark logger."""
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import json
-import os
-import tempfile
-import time
-import unittest
-
-from absl import logging
-from absl.testing import flagsaver
-import tensorflow as tf
-
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-from official.utils.misc import keras_utils
-
-
-class BenchmarkLoggerTest(tf.test.TestCase):
-
-  @classmethod
-  def setUpClass(cls):  # pylint: disable=invalid-name
-    super(BenchmarkLoggerTest, cls).setUpClass()
-    flags_core.define_benchmark()
-
-  def test_get_default_benchmark_logger(self):
-    with flagsaver.flagsaver(benchmark_logger_type="foo"):
-      self.assertIsInstance(logger.get_benchmark_logger(),
-                            logger.BaseBenchmarkLogger)
-
-  def test_config_base_benchmark_logger(self):
-    with flagsaver.flagsaver(benchmark_logger_type="BaseBenchmarkLogger"):
-      logger.config_benchmark_logger()
-      self.assertIsInstance(logger.get_benchmark_logger(),
-                            logger.BaseBenchmarkLogger)
-
-  def test_config_benchmark_file_logger(self):
-    # Set the benchmark_log_dir first since the benchmark_logger_type will need
-    # the value to be set when it does the validation.
-    with flagsaver.flagsaver(benchmark_log_dir="/tmp"):
-      with flagsaver.flagsaver(benchmark_logger_type="BenchmarkFileLogger"):
-        logger.config_benchmark_logger()
-        self.assertIsInstance(logger.get_benchmark_logger(),
-                              logger.BenchmarkFileLogger)
-
-
-class BaseBenchmarkLoggerTest(tf.test.TestCase):
-
-  def setUp(self):
-    super(BaseBenchmarkLoggerTest, self).setUp()
-    self._actual_log = logging.info
-    self.logged_message = None
-
-    def mock_log(*args, **kwargs):
-      self.logged_message = args
-      self._actual_log(*args, **kwargs)
-
-    logging.info = mock_log
-
-  def tearDown(self):
-    super(BaseBenchmarkLoggerTest, self).tearDown()
-    logging.info = self._actual_log
-
-  def test_log_metric(self):
-    log = logger.BaseBenchmarkLogger()
-    log.log_metric("accuracy", 0.999, global_step=1e4, extras={"name": "value"})
-
-    expected_log_prefix = "Benchmark metric:"
-    self.assertRegexpMatches(str(self.logged_message), expected_log_prefix)
-
-
-class BenchmarkFileLoggerTest(tf.test.TestCase):
-
-  def setUp(self):
-    super(BenchmarkFileLoggerTest, self).setUp()
-    # Avoid pulling extra env vars from test environment which affects the test
-    # result, eg. Kokoro test has a TF_PKG env which affect the test case
-    # test_collect_tensorflow_environment_variables()
-    self.original_environ = dict(os.environ)
-    os.environ.clear()
-
-  def tearDown(self):
-    super(BenchmarkFileLoggerTest, self).tearDown()
-    tf.io.gfile.rmtree(self.get_temp_dir())
-    os.environ.clear()
-    os.environ.update(self.original_environ)
-
-  def test_create_logging_dir(self):
-    non_exist_temp_dir = os.path.join(self.get_temp_dir(), "unknown_dir")
-    self.assertFalse(tf.io.gfile.isdir(non_exist_temp_dir))
-
-    logger.BenchmarkFileLogger(non_exist_temp_dir)
-    self.assertTrue(tf.io.gfile.isdir(non_exist_temp_dir))
-
-  def test_log_metric(self):
-    log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    log = logger.BenchmarkFileLogger(log_dir)
-    log.log_metric("accuracy", 0.999, global_step=1e4, extras={"name": "value"})
-
-    metric_log = os.path.join(log_dir, "metric.log")
-    self.assertTrue(tf.io.gfile.exists(metric_log))
-    with tf.io.gfile.GFile(metric_log) as f:
-      metric = json.loads(f.readline())
-      self.assertEqual(metric["name"], "accuracy")
-      self.assertEqual(metric["value"], 0.999)
-      self.assertEqual(metric["unit"], None)
-      self.assertEqual(metric["global_step"], 1e4)
-      self.assertEqual(metric["extras"], [{"name": "name", "value": "value"}])
-
-  def test_log_multiple_metrics(self):
-    log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    log = logger.BenchmarkFileLogger(log_dir)
-    log.log_metric("accuracy", 0.999, global_step=1e4, extras={"name": "value"})
-    log.log_metric("loss", 0.02, global_step=1e4)
-
-    metric_log = os.path.join(log_dir, "metric.log")
-    self.assertTrue(tf.io.gfile.exists(metric_log))
-    with tf.io.gfile.GFile(metric_log) as f:
-      accuracy = json.loads(f.readline())
-      self.assertEqual(accuracy["name"], "accuracy")
-      self.assertEqual(accuracy["value"], 0.999)
-      self.assertEqual(accuracy["unit"], None)
-      self.assertEqual(accuracy["global_step"], 1e4)
-      self.assertEqual(accuracy["extras"], [{"name": "name", "value": "value"}])
-
-      loss = json.loads(f.readline())
-      self.assertEqual(loss["name"], "loss")
-      self.assertEqual(loss["value"], 0.02)
-      self.assertEqual(loss["unit"], None)
-      self.assertEqual(loss["global_step"], 1e4)
-      self.assertEqual(loss["extras"], [])
-
-  def test_log_non_number_value(self):
-    log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    log = logger.BenchmarkFileLogger(log_dir)
-    const = tf.constant(1)
-    log.log_metric("accuracy", const)
-
-    metric_log = os.path.join(log_dir, "metric.log")
-    self.assertFalse(tf.io.gfile.exists(metric_log))
-
-  def test_log_evaluation_result(self):
-    eval_result = {"loss": 0.46237424,
-                   "global_step": 207082,
-                   "accuracy": 0.9285}
-    log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    log = logger.BenchmarkFileLogger(log_dir)
-    log.log_evaluation_result(eval_result)
-
-    metric_log = os.path.join(log_dir, "metric.log")
-    self.assertTrue(tf.io.gfile.exists(metric_log))
-    with tf.io.gfile.GFile(metric_log) as f:
-      accuracy = json.loads(f.readline())
-      self.assertEqual(accuracy["name"], "accuracy")
-      self.assertEqual(accuracy["value"], 0.9285)
-      self.assertEqual(accuracy["unit"], None)
-      self.assertEqual(accuracy["global_step"], 207082)
-
-      loss = json.loads(f.readline())
-      self.assertEqual(loss["name"], "loss")
-      self.assertEqual(loss["value"], 0.46237424)
-      self.assertEqual(loss["unit"], None)
-      self.assertEqual(loss["global_step"], 207082)
-
-  def test_log_evaluation_result_with_invalid_type(self):
-    eval_result = "{'loss': 0.46237424, 'global_step': 207082}"
-    log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    log = logger.BenchmarkFileLogger(log_dir)
-    log.log_evaluation_result(eval_result)
-
-    metric_log = os.path.join(log_dir, "metric.log")
-    self.assertFalse(tf.io.gfile.exists(metric_log))
-
-  def test_collect_tensorflow_info(self):
-    run_info = {}
-    logger._collect_tensorflow_info(run_info)
-    self.assertNotEqual(run_info["tensorflow_version"], {})
-    self.assertEqual(run_info["tensorflow_version"]["version"],
-                     tf.version.VERSION)
-    self.assertEqual(run_info["tensorflow_version"]["git_hash"],
-                     tf.version.GIT_VERSION)
-
-  def test_collect_run_params(self):
-    run_info = {}
-    run_parameters = {
-        "batch_size": 32,
-        "synthetic_data": True,
-        "train_epochs": 100.00,
-        "dtype": "fp16",
-        "resnet_size": 50,
-        "random_tensor": tf.constant(2.0)
-    }
-    logger._collect_run_params(run_info, run_parameters)
-    self.assertEqual(len(run_info["run_parameters"]), 6)
-    self.assertEqual(run_info["run_parameters"][0],
-                     {"name": "batch_size", "long_value": 32})
-    self.assertEqual(run_info["run_parameters"][1],
-                     {"name": "dtype", "string_value": "fp16"})
-    v1_tensor = {"name": "random_tensor", "string_value":
-                     "Tensor(\"Const:0\", shape=(), dtype=float32)"}
-    v2_tensor = {"name": "random_tensor", "string_value":
-                     "tf.Tensor(2.0, shape=(), dtype=float32)"}
-    self.assertIn(run_info["run_parameters"][2], [v1_tensor, v2_tensor])
-
-
-    self.assertEqual(run_info["run_parameters"][3],
-                     {"name": "resnet_size", "long_value": 50})
-    self.assertEqual(run_info["run_parameters"][4],
-                     {"name": "synthetic_data", "bool_value": "True"})
-    self.assertEqual(run_info["run_parameters"][5],
-                     {"name": "train_epochs", "float_value": 100.00})
-
-  def test_collect_tensorflow_environment_variables(self):
-    os.environ["TF_ENABLE_WINOGRAD_NONFUSED"] = "1"
-    os.environ["TF_OTHER"] = "2"
-    os.environ["OTHER"] = "3"
-
-    run_info = {}
-    logger._collect_tensorflow_environment_variables(run_info)
-    self.assertIsNotNone(run_info["tensorflow_environment_variables"])
-    expected_tf_envs = [
-        {"name": "TF_ENABLE_WINOGRAD_NONFUSED", "value": "1"},
-        {"name": "TF_OTHER", "value": "2"},
-    ]
-    self.assertEqual(run_info["tensorflow_environment_variables"],
-                     expected_tf_envs)
-
-  def test_collect_memory_info(self):
-    run_info = {"machine_config": {}}
-    logger._collect_memory_info(run_info)
-    self.assertIsNotNone(run_info["machine_config"]["memory_total"])
-    self.assertIsNotNone(run_info["machine_config"]["memory_available"])
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/utils/logs/metric_hook.py b/official/r1/utils/logs/metric_hook.py
deleted file mode 100644
index f408e3e9..00000000
--- a/official/r1/utils/logs/metric_hook.py
+++ /dev/null
@@ -1,97 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Session hook for logging benchmark metric."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-
-
-class LoggingMetricHook(tf.estimator.LoggingTensorHook):
-  """Hook to log benchmark metric information.
-
-  This hook is very similar as tf.train.LoggingTensorHook, which logs given
-  tensors every N local steps, every N seconds, or at the end. The metric
-  information will be logged to given log_dir or via metric_logger in JSON
-  format, which can be consumed by data analysis pipeline later.
-
-  Note that if `at_end` is True, `tensors` should not include any tensor
-  whose evaluation produces a side effect such as consuming additional inputs.
-  """
-
-  def __init__(self, tensors, metric_logger=None,
-               every_n_iter=None, every_n_secs=None, at_end=False):
-    """Initializer for LoggingMetricHook.
-
-    Args:
-      tensors: `dict` that maps string-valued tags to tensors/tensor names,
-          or `iterable` of tensors/tensor names.
-      metric_logger: instance of `BenchmarkLogger`, the benchmark logger that
-          hook should use to write the log.
-      every_n_iter: `int`, print the values of `tensors` once every N local
-          steps taken on the current worker.
-      every_n_secs: `int` or `float`, print the values of `tensors` once every N
-          seconds. Exactly one of `every_n_iter` and `every_n_secs` should be
-          provided.
-      at_end: `bool` specifying whether to print the values of `tensors` at the
-          end of the run.
-
-    Raises:
-      ValueError:
-        1. `every_n_iter` is non-positive, or
-        2. Exactly one of every_n_iter and every_n_secs should be provided.
-        3. Exactly one of log_dir and metric_logger should be provided.
-    """
-    super(LoggingMetricHook, self).__init__(
-        tensors=tensors,
-        every_n_iter=every_n_iter,
-        every_n_secs=every_n_secs,
-        at_end=at_end)
-
-    if metric_logger is None:
-      raise ValueError("metric_logger should be provided.")
-    self._logger = metric_logger
-
-  def begin(self):
-    super(LoggingMetricHook, self).begin()
-    self._global_step_tensor = tf.compat.v1.train.get_global_step()
-    if self._global_step_tensor is None:
-      raise RuntimeError(
-          "Global step should be created to use LoggingMetricHook.")
-    if self._global_step_tensor.name not in self._current_tensors:
-      self._current_tensors[self._global_step_tensor.name] = (
-          self._global_step_tensor)
-
-  def after_run(self, unused_run_context, run_values):
-    # should_trigger is a internal state that populated at before_run, and it is
-    # using self_timer to determine whether it should trigger.
-    if self._should_trigger:
-      self._log_metric(run_values.results)
-
-    self._iter_count += 1
-
-  def end(self, session):
-    if self._log_at_end:
-      values = session.run(self._current_tensors)
-      self._log_metric(values)
-
-  def _log_metric(self, tensor_values):
-    self._timer.update_last_triggered_step(self._iter_count)
-    global_step = tensor_values[self._global_step_tensor.name]
-    # self._tag_order is populated during the init of LoggingTensorHook
-    for tag in self._tag_order:
-      self._logger.log_metric(tag, tensor_values[tag], global_step=global_step)
diff --git a/official/r1/utils/logs/metric_hook_test.py b/official/r1/utils/logs/metric_hook_test.py
deleted file mode 100644
index eba93014..00000000
--- a/official/r1/utils/logs/metric_hook_test.py
+++ /dev/null
@@ -1,217 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Tests for metric_hook."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import tempfile
-import time
-
-import tensorflow as tf  # pylint: disable=g-bad-import-order
-from tensorflow.python.training import monitored_session  # pylint: disable=g-bad-import-order
-
-from official.r1.utils.logs import metric_hook
-from official.r1.utils.logs import mock_lib
-
-
-class LoggingMetricHookTest(tf.test.TestCase):
-  """Tests for LoggingMetricHook."""
-
-  def setUp(self):
-    super(LoggingMetricHookTest, self).setUp()
-
-    self._log_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
-    self._logger = mock_lib.MockBenchmarkLogger()
-
-  def tearDown(self):
-    super(LoggingMetricHookTest, self).tearDown()
-    tf.io.gfile.rmtree(self.get_temp_dir())
-
-  def test_illegal_args(self):
-    with self.assertRaisesRegexp(ValueError, "nvalid every_n_iter"):
-      metric_hook.LoggingMetricHook(tensors=["t"], every_n_iter=0)
-    with self.assertRaisesRegexp(ValueError, "nvalid every_n_iter"):
-      metric_hook.LoggingMetricHook(tensors=["t"], every_n_iter=-10)
-    with self.assertRaisesRegexp(ValueError, "xactly one of"):
-      metric_hook.LoggingMetricHook(
-          tensors=["t"], every_n_iter=5, every_n_secs=5)
-    with self.assertRaisesRegexp(ValueError, "xactly one of"):
-      metric_hook.LoggingMetricHook(tensors=["t"])
-    with self.assertRaisesRegexp(ValueError, "metric_logger"):
-      metric_hook.LoggingMetricHook(tensors=["t"], every_n_iter=5)
-
-  def test_print_at_end_only(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      t = tf.constant(42.0, name="foo")
-      train_op = tf.constant(3)
-      hook = metric_hook.LoggingMetricHook(
-          tensors=[t.name], at_end=True, metric_logger=self._logger)
-      hook.begin()
-      mon_sess = monitored_session._HookedSession(sess, [hook])  # pylint: disable=protected-access
-      sess.run(tf.compat.v1.global_variables_initializer())
-
-      for _ in range(3):
-        mon_sess.run(train_op)
-        self.assertEqual(self._logger.logged_metric, [])
-
-      hook.end(sess)
-      self.assertEqual(len(self._logger.logged_metric), 1)
-      metric = self._logger.logged_metric[0]
-      self.assertRegexpMatches(metric["name"], "foo")
-      self.assertEqual(metric["value"], 42.0)
-      self.assertEqual(metric["unit"], None)
-      self.assertEqual(metric["global_step"], 0)
-
-  def test_global_step_not_found(self):
-    with tf.Graph().as_default():
-      t = tf.constant(42.0, name="foo")
-      hook = metric_hook.LoggingMetricHook(
-          tensors=[t.name], at_end=True, metric_logger=self._logger)
-
-      with self.assertRaisesRegexp(
-          RuntimeError, "should be created to use LoggingMetricHook."):
-        hook.begin()
-
-  def test_log_tensors(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      t1 = tf.constant(42.0, name="foo")
-      t2 = tf.constant(43.0, name="bar")
-      train_op = tf.constant(3)
-      hook = metric_hook.LoggingMetricHook(
-          tensors=[t1, t2], at_end=True, metric_logger=self._logger)
-      hook.begin()
-      mon_sess = monitored_session._HookedSession(sess, [hook])  # pylint: disable=protected-access
-      sess.run(tf.compat.v1.global_variables_initializer())
-
-      for _ in range(3):
-        mon_sess.run(train_op)
-        self.assertEqual(self._logger.logged_metric, [])
-
-      hook.end(sess)
-      self.assertEqual(len(self._logger.logged_metric), 2)
-      metric1 = self._logger.logged_metric[0]
-      self.assertRegexpMatches(str(metric1["name"]), "foo")
-      self.assertEqual(metric1["value"], 42.0)
-      self.assertEqual(metric1["unit"], None)
-      self.assertEqual(metric1["global_step"], 0)
-
-      metric2 = self._logger.logged_metric[1]
-      self.assertRegexpMatches(str(metric2["name"]), "bar")
-      self.assertEqual(metric2["value"], 43.0)
-      self.assertEqual(metric2["unit"], None)
-      self.assertEqual(metric2["global_step"], 0)
-
-  def _validate_print_every_n_steps(self, sess, at_end):
-    t = tf.constant(42.0, name="foo")
-
-    train_op = tf.constant(3)
-    hook = metric_hook.LoggingMetricHook(
-        tensors=[t.name], every_n_iter=10, at_end=at_end,
-        metric_logger=self._logger)
-    hook.begin()
-    mon_sess = monitored_session._HookedSession(sess, [hook])  # pylint: disable=protected-access
-    sess.run(tf.compat.v1.global_variables_initializer())
-    mon_sess.run(train_op)
-    self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-    for _ in range(3):
-      self._logger.logged_metric = []
-      for _ in range(9):
-        mon_sess.run(train_op)
-        # assertNotRegexpMatches is not supported by python 3.1 and later
-        self.assertEqual(str(self._logger.logged_metric).find(t.name), -1)
-      mon_sess.run(train_op)
-      self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-
-    # Add additional run to verify proper reset when called multiple times.
-    self._logger.logged_metric = []
-    mon_sess.run(train_op)
-    # assertNotRegexpMatches is not supported by python 3.1 and later
-    self.assertEqual(str(self._logger.logged_metric).find(t.name), -1)
-
-    self._logger.logged_metric = []
-    hook.end(sess)
-    if at_end:
-      self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-    else:
-      # assertNotRegexpMatches is not supported by python 3.1 and later
-      self.assertEqual(str(self._logger.logged_metric).find(t.name), -1)
-
-  def test_print_every_n_steps(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      self._validate_print_every_n_steps(sess, at_end=False)
-      # Verify proper reset.
-      self._validate_print_every_n_steps(sess, at_end=False)
-
-  def test_print_every_n_steps_and_end(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      self._validate_print_every_n_steps(sess, at_end=True)
-      # Verify proper reset.
-      self._validate_print_every_n_steps(sess, at_end=True)
-
-  def _validate_print_every_n_secs(self, sess, at_end):
-    t = tf.constant(42.0, name="foo")
-    train_op = tf.constant(3)
-
-    hook = metric_hook.LoggingMetricHook(
-        tensors=[t.name], every_n_secs=1.0, at_end=at_end,
-        metric_logger=self._logger)
-    hook.begin()
-    mon_sess = monitored_session._HookedSession(sess, [hook])  # pylint: disable=protected-access
-    sess.run(tf.compat.v1.global_variables_initializer())
-
-    mon_sess.run(train_op)
-    self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-
-    # assertNotRegexpMatches is not supported by python 3.1 and later
-    self._logger.logged_metric = []
-    mon_sess.run(train_op)
-    self.assertEqual(str(self._logger.logged_metric).find(t.name), -1)
-    time.sleep(1.0)
-
-    self._logger.logged_metric = []
-    mon_sess.run(train_op)
-    self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-
-    self._logger.logged_metric = []
-    hook.end(sess)
-    if at_end:
-      self.assertRegexpMatches(str(self._logger.logged_metric), t.name)
-    else:
-      # assertNotRegexpMatches is not supported by python 3.1 and later
-      self.assertEqual(str(self._logger.logged_metric).find(t.name), -1)
-
-  def test_print_every_n_secs(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      self._validate_print_every_n_secs(sess, at_end=False)
-      # Verify proper reset.
-      self._validate_print_every_n_secs(sess, at_end=False)
-
-  def test_print_every_n_secs_and_end(self):
-    with tf.Graph().as_default(), tf.compat.v1.Session() as sess:
-      tf.compat.v1.train.get_or_create_global_step()
-      self._validate_print_every_n_secs(sess, at_end=True)
-      # Verify proper reset.
-      self._validate_print_every_n_secs(sess, at_end=True)
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/utils/logs/mlperf_helper.py b/official/r1/utils/logs/mlperf_helper.py
deleted file mode 100644
index 3f9601b6..00000000
--- a/official/r1/utils/logs/mlperf_helper.py
+++ /dev/null
@@ -1,192 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Wrapper for the mlperf logging utils.
-
-MLPerf compliance logging is only desired under a limited set of circumstances.
-This module is intended to keep users from needing to consider logging (or
-install the module) unless they are performing mlperf runs.
-"""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-from collections import namedtuple
-import json
-import os
-import re
-import subprocess
-import sys
-from absl import logging
-import typing
-# pylint:disable=logging-format-interpolation
-
-
-_MIN_VERSION = (0, 0, 10)
-_STACK_OFFSET = 2
-
-SUDO = "sudo" if os.geteuid() else ""
-
-# This indirection is used in docker.
-DROP_CACHE_LOC = os.getenv("DROP_CACHE_LOC", "/proc/sys/vm/drop_caches")
-
-_NCF_PREFIX = "NCF_RAW_"
-
-# TODO(robieta): move line parsing to mlperf util
-_PREFIX = r"(?:{})?:::MLPv([0-9]+).([0-9]+).([0-9]+)".format(_NCF_PREFIX)
-_BENCHMARK = r"([a-zA-Z0-9_]+)"
-_TIMESTAMP = r"([0-9]+\.[0-9]+)"
-_CALLSITE = r"\((.+):([0-9]+)\)"
-_TAG = r"([a-zA-Z0-9_]+)"
-_VALUE = r"(.*)"
-
-ParsedLine = namedtuple("ParsedLine", ["version", "benchmark", "timestamp",
-                                       "callsite", "tag", "value"])
-
-LINE_PATTERN = re.compile(
-    "^{prefix} {benchmark} {timestamp} {callsite} {tag}(: |$){value}?$".format(
-        prefix=_PREFIX, benchmark=_BENCHMARK, timestamp=_TIMESTAMP,
-        callsite=_CALLSITE, tag=_TAG, value=_VALUE))
-
-
-def parse_line(line): # type: (str) -> typing.Optional[ParsedLine]
-  match = LINE_PATTERN.match(line.strip())
-  if not match:
-    return
-
-  major, minor, micro, benchmark, timestamp = match.groups()[:5]
-  call_file, call_line, tag, _, value = match.groups()[5:]
-
-  return ParsedLine(version=(int(major), int(minor), int(micro)),
-                    benchmark=benchmark, timestamp=timestamp,
-                    callsite=(call_file, call_line), tag=tag, value=value)
-
-
-def unparse_line(parsed_line): # type: (ParsedLine) -> str
-  version_str = "{}.{}.{}".format(*parsed_line.version)
-  callsite_str = "({}:{})".format(*parsed_line.callsite)
-  value_str = ": {}".format(parsed_line.value) if parsed_line.value else ""
-  return ":::MLPv{} {} {} {} {} {}".format(
-      version_str, parsed_line.benchmark, parsed_line.timestamp, callsite_str,
-      parsed_line.tag, value_str)
-
-
-def get_mlperf_log():
-  """Shielded import of mlperf_log module."""
-  try:
-    import mlperf_compliance
-
-    def test_mlperf_log_pip_version():
-      """Check that mlperf_compliance is up to date."""
-      import pkg_resources
-      version = pkg_resources.get_distribution("mlperf_compliance")
-      version = tuple(int(i) for i in version.version.split("."))
-      if version < _MIN_VERSION:
-        logging.warning("mlperf_compliance is version {}, must be >= {}".format(
-            ".".join([str(i) for i in version]),
-            ".".join([str(i) for i in _MIN_VERSION])))
-        raise ImportError
-      return mlperf_compliance.mlperf_log
-
-    mlperf_log = test_mlperf_log_pip_version()
-
-  except ImportError:
-    mlperf_log = None
-
-  return mlperf_log
-
-
-class Logger(object):
-  """MLPerf logger indirection class.
-
-  This logger only logs for MLPerf runs, and prevents various errors associated
-  with not having the mlperf_compliance package installed.
-  """
-  class Tags(object):
-    def __init__(self, mlperf_log):
-      self._enabled = False
-      self._mlperf_log = mlperf_log
-
-    def __getattr__(self, item):
-      if self._mlperf_log is None or not self._enabled:
-        return
-      return getattr(self._mlperf_log, item)
-
-  def __init__(self):
-    self._enabled = False
-    self._mlperf_log = get_mlperf_log()
-    self.tags = self.Tags(self._mlperf_log)
-
-  def __call__(self, enable=False):
-    if enable and self._mlperf_log is None:
-      raise ImportError("MLPerf logging was requested, but mlperf_compliance "
-                        "module could not be loaded.")
-
-    self._enabled = enable
-    self.tags._enabled = enable
-    return self
-
-  def __enter__(self):
-    pass
-
-  def __exit__(self, exc_type, exc_val, exc_tb):
-    self._enabled = False
-    self.tags._enabled = False
-
-  @property
-  def log_file(self):
-    if self._mlperf_log is None:
-      return
-    return self._mlperf_log.LOG_FILE
-
-  @property
-  def enabled(self):
-    return self._enabled
-
-  def ncf_print(self, key, value=None, stack_offset=_STACK_OFFSET,
-                deferred=False, extra_print=False, prefix=_NCF_PREFIX):
-    if self._mlperf_log is None or not self.enabled:
-      return
-    self._mlperf_log.ncf_print(key=key, value=value, stack_offset=stack_offset,
-                               deferred=deferred, extra_print=extra_print,
-                               prefix=prefix)
-
-  def set_ncf_root(self, path):
-    if self._mlperf_log is None:
-      return
-    self._mlperf_log.ROOT_DIR_NCF = path
-
-
-LOGGER = Logger()
-ncf_print, set_ncf_root = LOGGER.ncf_print, LOGGER.set_ncf_root
-TAGS = LOGGER.tags
-
-
-def clear_system_caches():
-  if not LOGGER.enabled:
-    return
-  ret_code = subprocess.call(
-      ["sync && echo 3 | {} tee {}".format(SUDO, DROP_CACHE_LOC)],
-      shell=True)
-
-  if ret_code:
-    raise ValueError("Failed to clear caches")
-
-
-if __name__ == "__main__":
-  logging.set_verbosity(logging.INFO)
-  with LOGGER(True):
-    ncf_print(key=TAGS.RUN_START)
diff --git a/official/r1/utils/logs/mock_lib.py b/official/r1/utils/logs/mock_lib.py
deleted file mode 100644
index ee4de3c4..00000000
--- a/official/r1/utils/logs/mock_lib.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-"""Mock objects and related functions for testing."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-
-class MockBenchmarkLogger(object):
-  """This is a mock logger that can be used in dependent tests."""
-
-  def __init__(self):
-    self.logged_metric = []
-
-  def log_metric(self, name, value, unit=None, global_step=None,
-                 extras=None):
-    self.logged_metric.append({
-        "name": name,
-        "value": float(value),
-        "unit": unit,
-        "global_step": global_step,
-        "extras": extras})
diff --git a/official/r1/utils/tpu.py b/official/r1/utils/tpu.py
deleted file mode 100644
index 737a7942..00000000
--- a/official/r1/utils/tpu.py
+++ /dev/null
@@ -1,116 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Functions specific to running TensorFlow on TPUs."""
-
-import tensorflow as tf
-
-
-# "local" is a magic word in the TPU cluster resolver; it informs the resolver
-# to use the local CPU as the compute device. This is useful for testing and
-# debugging; the code flow is ostensibly identical, but without the need to
-# actually have a TPU on the other end.
-LOCAL = "local"
-
-
-def construct_scalar_host_call(metric_dict, model_dir, prefix=""):
-  """Construct a host call to log scalars when training on TPU.
-
-  Args:
-    metric_dict: A dict of the tensors to be logged.
-    model_dir: The location to write the summary.
-    prefix: The prefix (if any) to prepend to the metric names.
-
-  Returns:
-    A tuple of (function, args_to_be_passed_to_said_function)
-  """
-  # type: (dict, str) -> (function, list)
-  metric_names = list(metric_dict.keys())
-
-  def host_call_fn(global_step, *args):
-    """Training host call. Creates scalar summaries for training metrics.
-
-    This function is executed on the CPU and should not directly reference
-    any Tensors in the rest of the `model_fn`. To pass Tensors from the
-    model to the `metric_fn`, provide as part of the `host_call`. See
-    https://www.tensorflow.org/api_docs/python/tf/contrib/tpu/TPUEstimatorSpec
-    for more information.
-
-    Arguments should match the list of `Tensor` objects passed as the second
-    element in the tuple passed to `host_call`.
-
-    Args:
-      global_step: `Tensor with shape `[batch]` for the global_step
-      *args: Remaining tensors to log.
-
-    Returns:
-      List of summary ops to run on the CPU host.
-    """
-    step = global_step[0]
-    with tf.compat.v1.summary.create_file_writer(
-        logdir=model_dir, filename_suffix=".host_call").as_default():
-      with tf.compat.v1.summary.always_record_summaries():
-        for i, name in enumerate(metric_names):
-          tf.compat.v1.summary.scalar(prefix + name, args[i][0], step=step)
-
-        return tf.compat.v1.summary.all_summary_ops()
-
-  # To log the current learning rate, and gradient norm for Tensorboard, the
-  # summary op needs to be run on the host CPU via host_call. host_call
-  # expects [batch_size, ...] Tensors, thus reshape to introduce a batch
-  # dimension. These Tensors are implicitly concatenated to
-  # [params['batch_size']].
-  global_step_tensor = tf.reshape(
-      tf.compat.v1.train.get_or_create_global_step(), [1])
-  other_tensors = [tf.reshape(metric_dict[key], [1]) for key in metric_names]
-
-  return host_call_fn, [global_step_tensor] + other_tensors
-
-
-def embedding_matmul(embedding_table, values, mask, name="embedding_matmul"):
-  """Performs embedding lookup via a matmul.
-
-  The matrix to be multiplied by the embedding table Tensor is constructed
-  via an implementation of scatter based on broadcasting embedding indices
-  and performing an equality comparison against a broadcasted
-  range(num_embedding_table_rows). All masked positions will produce an
-  embedding vector of zeros.
-
-  Args:
-    embedding_table: Tensor of embedding table.
-      Rank 2 (table_size x embedding dim)
-    values: Tensor of embedding indices. Rank 2 (batch x n_indices)
-    mask: Tensor of mask / weights. Rank 2 (batch x n_indices)
-    name: Optional name scope for created ops
-
-  Returns:
-    Rank 3 tensor of embedding vectors.
-  """
-
-  with tf.name_scope(name):
-    n_embeddings = embedding_table.get_shape().as_list()[0]
-    batch_size, padded_size = values.shape.as_list()
-
-    emb_idcs = tf.tile(
-        tf.reshape(values, (batch_size, padded_size, 1)), (1, 1, n_embeddings))
-    emb_weights = tf.tile(
-        tf.reshape(mask, (batch_size, padded_size, 1)), (1, 1, n_embeddings))
-    col_idcs = tf.tile(
-        tf.reshape(tf.range(n_embeddings), (1, 1, n_embeddings)),
-        (batch_size, padded_size, 1))
-    one_hot = tf.where(
-        tf.equal(emb_idcs, col_idcs), emb_weights,
-        tf.zeros((batch_size, padded_size, n_embeddings)))
-
-    return tf.tensordot(one_hot, embedding_table, 1)
diff --git a/official/r1/utils/tpu_test.py b/official/r1/utils/tpu_test.py
deleted file mode 100644
index ba5b868a..00000000
--- a/official/r1/utils/tpu_test.py
+++ /dev/null
@@ -1,108 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Test TPU optimized matmul embedding."""
-
-import numpy as np
-import tensorflow as tf
-
-from official.r1.utils import tpu as tpu_utils
-
-
-TEST_CASES = [
-    dict(embedding_dim=256, vocab_size=1000, sequence_length=64,
-         batch_size=32, seed=54131),
-    dict(embedding_dim=8, vocab_size=15, sequence_length=12,
-         batch_size=256, seed=536413),
-    dict(embedding_dim=2048, vocab_size=512, sequence_length=50,
-         batch_size=8, seed=35124)
-]
-
-
-class TPUBaseTester(tf.test.TestCase):
-  def construct_embedding_and_values(self, embedding_dim, vocab_size,
-                                     sequence_length, batch_size, seed):
-    np.random.seed(seed)
-
-    embeddings = np.random.random(size=(vocab_size, embedding_dim))
-    embedding_table = tf.convert_to_tensor(value=embeddings, dtype=tf.float32)
-
-    tokens = np.random.randint(low=1, high=vocab_size-1,
-                               size=(batch_size, sequence_length))
-    for i in range(batch_size):
-      tokens[i, np.random.randint(low=0, high=sequence_length-1):] = 0
-    values = tf.convert_to_tensor(value=tokens, dtype=tf.int32)
-    mask = tf.cast(tf.not_equal(values, 0), dtype=tf.float32)
-    return embedding_table, values, mask
-
-  def _test_embedding(self, embedding_dim, vocab_size,
-                      sequence_length, batch_size, seed):
-    """Test that matmul embedding matches embedding lookup (gather)."""
-
-    with self.test_session():
-      embedding_table, values, mask = self.construct_embedding_and_values(
-          embedding_dim=embedding_dim,
-          vocab_size=vocab_size,
-          sequence_length=sequence_length,
-          batch_size=batch_size,
-          seed=seed
-      )
-
-      embedding = (tf.nn.embedding_lookup(params=embedding_table, ids=values) *
-                   tf.expand_dims(mask, -1))
-
-      matmul_embedding = tpu_utils.embedding_matmul(
-          embedding_table=embedding_table, values=values, mask=mask)
-
-      self.assertAllClose(embedding, matmul_embedding)
-
-  def _test_masking(self, embedding_dim, vocab_size,
-                    sequence_length, batch_size, seed):
-    """Test that matmul embedding properly zeros masked positions."""
-    with self.test_session():
-      embedding_table, values, mask = self.construct_embedding_and_values(
-          embedding_dim=embedding_dim,
-          vocab_size=vocab_size,
-          sequence_length=sequence_length,
-          batch_size=batch_size,
-          seed=seed
-      )
-
-      matmul_embedding = tpu_utils.embedding_matmul(
-          embedding_table=embedding_table, values=values, mask=mask)
-
-      self.assertAllClose(matmul_embedding,
-                          matmul_embedding * tf.expand_dims(mask, -1))
-
-  def test_embedding_0(self):
-    self._test_embedding(**TEST_CASES[0])
-
-  def test_embedding_1(self):
-    self._test_embedding(**TEST_CASES[1])
-
-  def test_embedding_2(self):
-    self._test_embedding(**TEST_CASES[2])
-
-  def test_masking_0(self):
-    self._test_masking(**TEST_CASES[0])
-
-  def test_masking_1(self):
-    self._test_masking(**TEST_CASES[1])
-
-  def test_masking_2(self):
-    self._test_masking(**TEST_CASES[2])
-
-
-if __name__ == "__main__":
-  tf.test.main()
diff --git a/official/r1/wide_deep/README.md b/official/r1/wide_deep/README.md
deleted file mode 100644
index 6598d895..00000000
--- a/official/r1/wide_deep/README.md
+++ /dev/null
@@ -1,102 +0,0 @@
-![No Maintenance Intended](https://img.shields.io/badge/No%20Maintenance%20Intended-%E2%9C%95-red.svg)
-![TensorFlow Requirement: 1.x](https://img.shields.io/badge/TensorFlow%20Requirement-1.x-brightgreen)
-![TensorFlow 2 Not Supported](https://img.shields.io/badge/TensorFlow%202%20Not%20Supported-%E2%9C%95-red.svg)
-
-# Predicting Income with the Census Income Dataset
-
-The implementation is based on TensorFlow 1.x.
-
-## Overview
-The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) contains over 48,000 samples with attributes including age, occupation, education, and income (a binary label, either `>50K` or `<=50K`). The dataset is split into roughly 32,000 training and 16,000 testing samples.
-
-Here, we use the [wide and deep model](https://research.googleblog.com/2016/06/wide-deep-learning-better-together-with.html) to predict the income labels. The **wide model** is able to memorize interactions with data with a large number of features but not able to generalize these learned interactions on new data. The **deep model** generalizes well but is unable to learn exceptions within the data. The **wide and deep model** combines the two models and is able to generalize while learning exceptions.
-
-For the purposes of this example code, the Census Income Data Set was chosen to allow the model to train in a reasonable amount of time. You'll notice that the deep model performs almost as well as the wide and deep model on this dataset. The wide and deep model truly shines on larger data sets with high-cardinality features, where each feature has millions/billions of unique possible values (which is the specialty of the wide model).
-
-Finally, a key point. As a modeler and developer, think about how this dataset is used and the potential benefits and harm a model's predictions can cause. A model like this could reinforce societal biases and disparities. Is a feature relevant to the problem you want to solve, or will it introduce bias? For more information, read about [ML fairness](https://developers.google.com/machine-learning/fairness-overview/).
-
----
-
-The code sample in this directory uses the high level `tf.estimator.Estimator` API. This API is great for fast iteration and quickly adapting models to your own datasets without major code overhauls. It allows you to move from single-worker training to distributed training, and it makes it easy to export model binaries for prediction.
-
-The input function for the `Estimator` uses `tf.contrib.data.TextLineDataset`, which creates a `Dataset` object. The `Dataset` API makes it easy to apply transformations (map, batch, shuffle, etc.) to the data. [Read more here](https://www.tensorflow.org/guide/datasets).
-
-The `Estimator` and `Dataset` APIs are both highly encouraged for fast development and efficient training.
-
-## Running the code
-First make sure you've [added the models folder to your Python path](/official/#running-the-models); otherwise you may encounter an error like `ImportError: No module named official.wide_deep`.
-
-### Setup
-The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this sample uses for training is hosted by the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/). We have provided a script that downloads and cleans the necessary files.
-
-```
-python census_dataset.py
-```
-
-This will download the files to `/tmp/census_data`. To change the directory, set the `--data_dir` flag.
-
-### Training
-You can run the code locally as follows:
-
-```
-python census_main.py
-```
-
-The model is saved to `/tmp/census_model` by default, which can be changed using the `--model_dir` flag.
-
-To run the *wide* or *deep*-only models, set the `--model_type` flag to `wide` or `deep`. Other flags are configurable as well; see `census_main.py` for details.
-
-The final accuracy should be over 83% with any of the three model types.
-
-You can also experiment with `-inter` and `-intra` flag to explore inter/intra op parallelism for potential better performance as follows:
-
-```
-python census_main.py --inter=<int> --intra=<int>
-```
-Please note the above optional inter/intra op does not affect model accuracy. These are TensorFlow framework configurations that only affect execution time.
-For more details regarding the above inter/intra flags, please refer to [Optimizing_for_CPU](https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu) or [TensorFlow config.proto source code](https://github.com/tensorflow/tensorflow/blob/26b4dfa65d360f2793ad75083c797d57f8661b93/tensorflow/core/protobuf/config.proto#L165).
-
-### TensorBoard
-
-Run TensorBoard to inspect the details about the graph and training progression.
-
-```
-tensorboard --logdir=/tmp/census_model
-```
-
-## Inference with SavedModel
-You can export the model into Tensorflow [SavedModel](https://www.tensorflow.org/guide/saved_model) format by using the argument `--export_dir`:
-
-```
-python census_main.py --export_dir /tmp/wide_deep_saved_model
-```
-
-After the model finishes training, use [`saved_model_cli`](https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel) to inspect and execute the SavedModel.
-
-Try the following commands to inspect the SavedModel:
-
-**Replace `${TIMESTAMP}` with the folder produced (e.g. 1524249124)**
-```
-# List possible tag_sets. Only one metagraph is saved, so there will be one option.
-saved_model_cli show --dir /tmp/wide_deep_saved_model/${TIMESTAMP}/
-
-# Show SignatureDefs for tag_set=serve. SignatureDefs define the outputs to show.
-saved_model_cli show --dir /tmp/wide_deep_saved_model/${TIMESTAMP}/ \
-    --tag_set serve --all
-```
-
-### Inference
-Let's use the model to predict the income group of two examples:
-```
-saved_model_cli run --dir /tmp/wide_deep_saved_model/${TIMESTAMP}/ \
---tag_set serve --signature_def="predict" \
---input_examples='examples=[{"age":[46.], "education_num":[10.], "capital_gain":[7688.], "capital_loss":[0.], "hours_per_week":[38.]}, {"age":[24.], "education_num":[13.], "capital_gain":[0.], "capital_loss":[0.], "hours_per_week":[50.]}]'
-```
-
-This will print out the predicted classes and class probabilities. Class 0 is the <=50k group and 1 is the >50k group.
-
-## Additional Links
-
-If you are interested in distributed training, take a look at [Distributed TensorFlow](https://www.tensorflow.org/deploy/distributed).
-
-You can also [run this model on Cloud ML Engine](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction), which provides [hyperparameter tuning](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction#hyperparameter_tuning) to maximize your model's results and enables [deploying your model for prediction](https://cloud.google.com/ml-engine/docs/getting-started-training-prediction#deploy_a_model_to_support_prediction).
diff --git a/official/r1/wide_deep/__init__.py b/official/r1/wide_deep/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/official/r1/wide_deep/census_dataset.py b/official/r1/wide_deep/census_dataset.py
deleted file mode 100644
index f3a07ac6..00000000
--- a/official/r1/wide_deep/census_dataset.py
+++ /dev/null
@@ -1,205 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Download and clean the Census Income Dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import sys
-
-# pylint: disable=wrong-import-order
-from absl import app as absl_app
-from absl import flags
-from six.moves import urllib
-from six.moves import zip
-import tensorflow.compat.v1 as tf
-# pylint: enable=wrong-import-order
-
-from official.utils.flags import core as flags_core
-
-
-DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult'
-TRAINING_FILE = 'adult.data'
-TRAINING_URL = '%s/%s' % (DATA_URL, TRAINING_FILE)
-EVAL_FILE = 'adult.test'
-EVAL_URL = '%s/%s' % (DATA_URL, EVAL_FILE)
-
-
-_CSV_COLUMNS = [
-    'age', 'workclass', 'fnlwgt', 'education', 'education_num',
-    'marital_status', 'occupation', 'relationship', 'race', 'gender',
-    'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',
-    'income_bracket'
-]
-
-_CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],
-                        [0], [0], [0], [''], ['']]
-
-_HASH_BUCKET_SIZE = 1000
-
-_NUM_EXAMPLES = {
-    'train': 32561,
-    'validation': 16281,
-}
-
-
-def _download_and_clean_file(filename, url):
-  """Downloads data from url, and makes changes to match the CSV format."""
-  temp_file, _ = urllib.request.urlretrieve(url)
-  with tf.gfile.Open(temp_file, 'r') as temp_eval_file:
-    with tf.gfile.Open(filename, 'w') as eval_file:
-      for line in temp_eval_file:
-        line = line.strip()
-        line = line.replace(', ', ',')
-        if not line or ',' not in line:
-          continue
-        if line[-1] == '.':
-          line = line[:-1]
-        line += '\n'
-        eval_file.write(line)
-  tf.gfile.Remove(temp_file)
-
-
-def download(data_dir):
-  """Download census data if it is not already present."""
-  tf.gfile.MakeDirs(data_dir)
-
-  training_file_path = os.path.join(data_dir, TRAINING_FILE)
-  if not tf.gfile.Exists(training_file_path):
-    _download_and_clean_file(training_file_path, TRAINING_URL)
-
-  eval_file_path = os.path.join(data_dir, EVAL_FILE)
-  if not tf.gfile.Exists(eval_file_path):
-    _download_and_clean_file(eval_file_path, EVAL_URL)
-
-
-def build_model_columns():
-  """Builds a set of wide and deep feature columns."""
-  # Continuous variable columns
-  age = tf.feature_column.numeric_column('age')
-  education_num = tf.feature_column.numeric_column('education_num')
-  capital_gain = tf.feature_column.numeric_column('capital_gain')
-  capital_loss = tf.feature_column.numeric_column('capital_loss')
-  hours_per_week = tf.feature_column.numeric_column('hours_per_week')
-
-  education = tf.feature_column.categorical_column_with_vocabulary_list(
-      'education', [
-          'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',
-          'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',
-          '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])
-
-  marital_status = tf.feature_column.categorical_column_with_vocabulary_list(
-      'marital_status', [
-          'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',
-          'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])
-
-  relationship = tf.feature_column.categorical_column_with_vocabulary_list(
-      'relationship', [
-          'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',
-          'Other-relative'])
-
-  workclass = tf.feature_column.categorical_column_with_vocabulary_list(
-      'workclass', [
-          'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',
-          'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])
-
-  # To show an example of hashing:
-  occupation = tf.feature_column.categorical_column_with_hash_bucket(
-      'occupation', hash_bucket_size=_HASH_BUCKET_SIZE)
-
-  # Transformations.
-  age_buckets = tf.feature_column.bucketized_column(
-      age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
-
-  # Wide columns and deep columns.
-  base_columns = [
-      education, marital_status, relationship, workclass, occupation,
-      age_buckets,
-  ]
-
-  crossed_columns = [
-      tf.feature_column.crossed_column(
-          ['education', 'occupation'], hash_bucket_size=_HASH_BUCKET_SIZE),
-      tf.feature_column.crossed_column(
-          [age_buckets, 'education', 'occupation'],
-          hash_bucket_size=_HASH_BUCKET_SIZE),
-  ]
-
-  wide_columns = base_columns + crossed_columns
-
-  deep_columns = [
-      age,
-      education_num,
-      capital_gain,
-      capital_loss,
-      hours_per_week,
-      tf.feature_column.indicator_column(workclass),
-      tf.feature_column.indicator_column(education),
-      tf.feature_column.indicator_column(marital_status),
-      tf.feature_column.indicator_column(relationship),
-      # To show an example of embedding
-      tf.feature_column.embedding_column(occupation, dimension=8),
-  ]
-
-  return wide_columns, deep_columns
-
-
-def input_fn(data_file, num_epochs, shuffle, batch_size):
-  """Generate an input function for the Estimator."""
-  assert tf.gfile.Exists(data_file), (
-      '%s not found. Please make sure you have run census_dataset.py and '
-      'set the --data_dir argument to the correct path.' % data_file)
-
-  def parse_csv(value):
-    tf.logging.info('Parsing {}'.format(data_file))
-    columns = tf.decode_csv(value, record_defaults=_CSV_COLUMN_DEFAULTS)
-    features = dict(list(zip(_CSV_COLUMNS, columns)))
-    labels = features.pop('income_bracket')
-    classes = tf.equal(labels, '>50K')  # binary classification
-    return features, classes
-
-  # Extract lines from input files using the Dataset API.
-  dataset = tf.data.TextLineDataset(data_file)
-
-  if shuffle:
-    dataset = dataset.shuffle(buffer_size=_NUM_EXAMPLES['train'])
-
-  dataset = dataset.map(parse_csv, num_parallel_calls=5)
-
-  # We call repeat after shuffling, rather than before, to prevent separate
-  # epochs from blending together.
-  dataset = dataset.repeat(num_epochs)
-  dataset = dataset.batch(batch_size)
-  return dataset
-
-
-def define_data_download_flags():
-  """Add flags specifying data download arguments."""
-  flags.DEFINE_string(
-      name="data_dir", default="/tmp/census_data/",
-      help=flags_core.help_wrap(
-          "Directory to download and extract data."))
-
-
-def main(_):
-  download(flags.FLAGS.data_dir)
-
-
-if __name__ == '__main__':
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_data_download_flags()
-  absl_app.run(main)
diff --git a/official/r1/wide_deep/census_main.py b/official/r1/wide_deep/census_main.py
deleted file mode 100644
index 39a1610e..00000000
--- a/official/r1/wide_deep/census_main.py
+++ /dev/null
@@ -1,115 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Train DNN on census income dataset."""
-
-import os
-
-from absl import app as absl_app
-from absl import flags
-import tensorflow.compat.v1 as tf
-from official.r1.utils.logs import logger
-from official.r1.wide_deep import census_dataset
-from official.r1.wide_deep import wide_deep_run_loop
-from official.utils.flags import core as flags_core
-
-
-def define_census_flags():
-  wide_deep_run_loop.define_wide_deep_flags()
-  flags.adopt_module_key_flags(wide_deep_run_loop)
-  flags_core.set_defaults(data_dir='/tmp/census_data',
-                          model_dir='/tmp/census_model',
-                          train_epochs=40,
-                          epochs_between_evals=2,
-                          inter_op_parallelism_threads=0,
-                          intra_op_parallelism_threads=0,
-                          batch_size=40)
-
-
-def build_estimator(model_dir, model_type, model_column_fn, inter_op, intra_op):
-  """Build an estimator appropriate for the given model type."""
-  wide_columns, deep_columns = model_column_fn()
-  hidden_units = [100, 75, 50, 25]
-
-  # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which
-  # trains faster than GPU for this model.
-  run_config = tf.estimator.RunConfig().replace(
-      session_config=tf.ConfigProto(device_count={'GPU': 0},
-                                    inter_op_parallelism_threads=inter_op,
-                                    intra_op_parallelism_threads=intra_op))
-
-  if model_type == 'wide':
-    return tf.estimator.LinearClassifier(
-        model_dir=model_dir,
-        feature_columns=wide_columns,
-        config=run_config)
-  elif model_type == 'deep':
-    return tf.estimator.DNNClassifier(
-        model_dir=model_dir,
-        feature_columns=deep_columns,
-        hidden_units=hidden_units,
-        config=run_config)
-  else:
-    return tf.estimator.DNNLinearCombinedClassifier(
-        model_dir=model_dir,
-        linear_feature_columns=wide_columns,
-        dnn_feature_columns=deep_columns,
-        dnn_hidden_units=hidden_units,
-        config=run_config)
-
-
-def run_census(flags_obj):
-  """Construct all necessary functions and call run_loop.
-
-  Args:
-    flags_obj: Object containing user specified flags.
-  """
-  if flags_obj.download_if_missing:
-    census_dataset.download(flags_obj.data_dir)
-
-  train_file = os.path.join(flags_obj.data_dir, census_dataset.TRAINING_FILE)
-  test_file = os.path.join(flags_obj.data_dir, census_dataset.EVAL_FILE)
-
-  # Train and evaluate the model every `flags.epochs_between_evals` epochs.
-  def train_input_fn():
-    return census_dataset.input_fn(
-        train_file, flags_obj.epochs_between_evals, True, flags_obj.batch_size)
-
-  def eval_input_fn():
-    return census_dataset.input_fn(test_file, 1, False, flags_obj.batch_size)
-
-  tensors_to_log = {
-      'average_loss': '{loss_prefix}head/truediv',
-      'loss': '{loss_prefix}head/weighted_loss/Sum'
-  }
-
-  wide_deep_run_loop.run_loop(
-      name="Census Income", train_input_fn=train_input_fn,
-      eval_input_fn=eval_input_fn,
-      model_column_fn=census_dataset.build_model_columns,
-      build_estimator_fn=build_estimator,
-      flags_obj=flags_obj,
-      tensors_to_log=tensors_to_log,
-      early_stop=True)
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    run_census(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_census_flags()
-  absl_app.run(main)
diff --git a/official/r1/wide_deep/census_test.csv b/official/r1/wide_deep/census_test.csv
deleted file mode 100644
index 374397db..00000000
--- a/official/r1/wide_deep/census_test.csv
+++ /dev/null
@@ -1,30 +0,0 @@
-39,State-gov,77516,Bachelors,13,Never-married,Adm-clerical,Not-in-family,,,2174,0,40,,<=50K
-50,Self-emp-not-inc,83311,Bachelors,13,Married-civ-spouse,Exec-managerial,Husband,,,0,0,13,,<=50K
-38,Private,215646,HS-grad,9,Divorced,Handlers-cleaners,Not-in-family,,,0,0,40,,<=50K
-53,Private,234721,11th,7,Married-civ-spouse,Handlers-cleaners,Husband,,,0,0,40,,<=50K
-28,Private,338409,Bachelors,13,Married-civ-spouse,Prof-specialty,Wife,,,0,0,40,,<=50K
-37,Private,284582,Masters,14,Married-civ-spouse,Exec-managerial,Wife,,,0,0,40,,<=50K
-49,Private,160187,9th,5,Married-spouse-absent,Other-service,Not-in-family,,,0,0,16,,<=50K
-52,Self-emp-not-inc,209642,HS-grad,9,Married-civ-spouse,Exec-managerial,Husband,,,0,0,45,,>50K
-31,Private,45781,Masters,14,Never-married,Prof-specialty,Not-in-family,,,14084,0,50,,>50K
-42,Private,159449,Bachelors,13,Married-civ-spouse,Exec-managerial,Husband,,,5178,0,40,,>50K
-37,Private,280464,Some-college,10,Married-civ-spouse,Exec-managerial,Husband,,,0,0,80,,>50K
-30,State-gov,141297,Bachelors,13,Married-civ-spouse,Prof-specialty,Husband,,,0,0,40,,>50K
-23,Private,122272,Bachelors,13,Never-married,Adm-clerical,Own-child,,,0,0,30,,<=50K
-32,Private,205019,Assoc-acdm,12,Never-married,Sales,Not-in-family,,,0,0,50,,<=50K
-40,Private,121772,Assoc-voc,11,Married-civ-spouse,Craft-repair,Husband,,,0,0,40,,>50K
-34,Private,245487,7th-8th,4,Married-civ-spouse,Transport-moving,Husband,,,0,0,45,,<=50K
-25,Self-emp-not-inc,176756,HS-grad,9,Never-married,Farming-fishing,Own-child,,,0,0,35,,<=50K
-32,Private,186824,HS-grad,9,Never-married,Machine-op-inspct,Unmarried,,,0,0,40,,<=50K
-38,Private,28887,11th,7,Married-civ-spouse,Sales,Husband,,,0,0,50,,<=50K
-43,Self-emp-not-inc,292175,Masters,14,Divorced,Exec-managerial,Unmarried,,,0,0,45,,>50K
-40,Private,193524,Doctorate,16,Married-civ-spouse,Prof-specialty,Husband,,,0,0,60,,>50K
-56,Local-gov,216851,Bachelors,13,Married-civ-spouse,Tech-support,Husband,,,0,0,40,,>50K
-54,?,180211,Some-college,10,Married-civ-spouse,?,Husband,,,0,0,60,,>50K
-22,State-gov,311512,Some-college,10,Married-civ-spouse,Other-service,Husband,,,0,0,15,,<=50K
-31,Private,84154,Some-college,10,Married-civ-spouse,Sales,Husband,,,0,0,38,,>50K
-57,Federal-gov,337895,Bachelors,13,Married-civ-spouse,Prof-specialty,Husband,,,0,0,40,,>50K
-47,Private,51835,Prof-school,15,Married-civ-spouse,Prof-specialty,Wife,,,0,1902,60,,>50K
-50,Federal-gov,251585,Bachelors,13,Divorced,Exec-managerial,Not-in-family,,,0,0,55,,>50K
-25,Private,289980,HS-grad,9,Never-married,Handlers-cleaners,Not-in-family,,,0,0,35,,<=50K
-42,Private,116632,Doctorate,16,Married-civ-spouse,Prof-specialty,Husband,,,0,0,45,,>50K
diff --git a/official/r1/wide_deep/census_test.py b/official/r1/wide_deep/census_test.py
deleted file mode 100644
index 81165156..00000000
--- a/official/r1/wide_deep/census_test.py
+++ /dev/null
@@ -1,163 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-from absl import logging
-import tensorflow.compat.v1 as tf
-
-from official.r1.wide_deep import census_dataset
-from official.r1.wide_deep import census_main
-from official.utils.testing import integration
-
-logging.set_verbosity(logging.ERROR)
-
-TEST_INPUT = ('18,Self-emp-not-inc,987,Bachelors,12,Married-civ-spouse,abc,'
-              'Husband,zyx,wvu,34,56,78,tsr,<=50K')
-
-TEST_INPUT_VALUES = {
-    'age': 18,
-    'education_num': 12,
-    'capital_gain': 34,
-    'capital_loss': 56,
-    'hours_per_week': 78,
-    'education': 'Bachelors',
-    'marital_status': 'Married-civ-spouse',
-    'relationship': 'Husband',
-    'workclass': 'Self-emp-not-inc',
-    'occupation': 'abc',
-}
-
-TEST_CSV = os.path.join(os.path.dirname(__file__), 'census_test.csv')
-
-
-class BaseTest(tf.test.TestCase):
-  """Tests for Wide Deep model."""
-
-  @classmethod
-  def setUpClass(cls):  # pylint: disable=invalid-name
-    super(BaseTest, cls).setUpClass()
-    census_main.define_census_flags()
-
-  def setUp(self):
-    # Create temporary CSV file
-    self.temp_dir = self.get_temp_dir()
-    self.input_csv = os.path.join(self.temp_dir, 'test.csv')
-    with tf.io.gfile.GFile(self.input_csv, 'w') as temp_csv:
-      temp_csv.write(TEST_INPUT)
-
-    with tf.io.gfile.GFile(TEST_CSV, 'r') as temp_csv:
-      test_csv_contents = temp_csv.read()
-
-    # Used for end-to-end tests.
-    for fname in [census_dataset.TRAINING_FILE, census_dataset.EVAL_FILE]:
-      with tf.io.gfile.GFile(
-          os.path.join(self.temp_dir, fname), 'w') as test_csv:
-        test_csv.write(test_csv_contents)
-
-  def test_input_fn(self):
-    dataset = census_dataset.input_fn(self.input_csv, 1, False, 1)
-    features, labels = dataset.make_one_shot_iterator().get_next()
-
-    with self.test_session() as sess:
-      features, labels = sess.run((features, labels))
-
-      # Compare the two features dictionaries.
-      for key in TEST_INPUT_VALUES:
-        self.assertTrue(key in features)
-        self.assertEqual(len(features[key]), 1)
-        feature_value = features[key][0]
-
-        # Convert from bytes to string for Python 3.
-        if isinstance(feature_value, bytes):
-          feature_value = feature_value.decode()
-
-        self.assertEqual(TEST_INPUT_VALUES[key], feature_value)
-
-      self.assertFalse(labels)
-
-  def build_and_test_estimator(self, model_type):
-    """Ensure that model trains and minimizes loss."""
-    model = census_main.build_estimator(
-        self.temp_dir, model_type,
-        model_column_fn=census_dataset.build_model_columns,
-        inter_op=0, intra_op=0)
-
-    # Train for 1 step to initialize model and evaluate initial loss
-    def get_input_fn(num_epochs, shuffle, batch_size):
-      def input_fn():
-        return census_dataset.input_fn(
-            TEST_CSV, num_epochs=num_epochs, shuffle=shuffle,
-            batch_size=batch_size)
-      return input_fn
-
-    model.train(input_fn=get_input_fn(1, True, 1), steps=1)
-    initial_results = model.evaluate(input_fn=get_input_fn(1, False, 1))
-
-    # Train for 100 epochs at batch size 3 and evaluate final loss
-    model.train(input_fn=get_input_fn(100, True, 3))
-    final_results = model.evaluate(input_fn=get_input_fn(1, False, 1))
-
-    print('%s initial results:' % model_type, initial_results)
-    print('%s final results:' % model_type, final_results)
-
-    # Ensure loss has decreased, while accuracy and both AUCs have increased.
-    self.assertLess(final_results['loss'], initial_results['loss'])
-    self.assertGreater(final_results['auc'], initial_results['auc'])
-    self.assertGreater(final_results['auc_precision_recall'],
-                       initial_results['auc_precision_recall'])
-    self.assertGreater(final_results['accuracy'], initial_results['accuracy'])
-
-  def test_wide_deep_estimator_training(self):
-    self.build_and_test_estimator('wide_deep')
-
-  def test_end_to_end_wide(self):
-    integration.run_synthetic(
-        main=census_main.main, tmp_root=self.get_temp_dir(),
-        extra_flags=[
-            '--data_dir', self.get_temp_dir(),
-            '--model_type', 'wide',
-            '--download_if_missing=false'
-        ],
-        synth=False)
-
-  def test_end_to_end_deep(self):
-    integration.run_synthetic(
-        main=census_main.main, tmp_root=self.get_temp_dir(),
-        extra_flags=[
-            '--data_dir', self.get_temp_dir(),
-            '--model_type', 'deep',
-            '--download_if_missing=false'
-        ],
-        synth=False)
-
-  def test_end_to_end_wide_deep(self):
-    integration.run_synthetic(
-        main=census_main.main, tmp_root=self.get_temp_dir(),
-        extra_flags=[
-            '--data_dir', self.get_temp_dir(),
-            '--model_type', 'wide_deep',
-            '--download_if_missing=false'
-        ],
-        synth=False)
-
-
-if __name__ == '__main__':
-  tf.disable_eager_execution()
-  tf.test.main()
diff --git a/official/r1/wide_deep/movielens_dataset.py b/official/r1/wide_deep/movielens_dataset.py
deleted file mode 100644
index 676062cb..00000000
--- a/official/r1/wide_deep/movielens_dataset.py
+++ /dev/null
@@ -1,165 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Prepare MovieLens dataset for wide-deep."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import functools
-import os
-
-# pylint: disable=wrong-import-order
-from absl import app as absl_app
-from absl import flags
-import numpy as np
-import tensorflow.compat.v1 as tf
-# pylint: enable=wrong-import-order
-
-from official.recommendation import movielens
-from official.r1.utils.data import file_io
-from official.utils.flags import core as flags_core
-
-
-_BUFFER_SUBDIR = "wide_deep_buffer"
-_FEATURE_MAP = {
-    movielens.USER_COLUMN: tf.compat.v1.FixedLenFeature([1], dtype=tf.int64),
-    movielens.ITEM_COLUMN: tf.compat.v1.FixedLenFeature([1], dtype=tf.int64),
-    movielens.TIMESTAMP_COLUMN: tf.compat.v1.FixedLenFeature([1],
-                                                             dtype=tf.int64),
-    movielens.GENRE_COLUMN: tf.compat.v1.FixedLenFeature(
-        [movielens.N_GENRE], dtype=tf.int64),
-    movielens.RATING_COLUMN: tf.compat.v1.FixedLenFeature([1],
-                                                          dtype=tf.float32),
-}
-
-_BUFFER_SIZE = {
-    movielens.ML_1M: {"train": 107978119, "eval": 26994538},
-    movielens.ML_20M: {"train": 2175203810, "eval": 543802008}
-}
-
-_USER_EMBEDDING_DIM = 16
-_ITEM_EMBEDDING_DIM = 64
-
-def build_model_columns(dataset):
-  """Builds a set of wide and deep feature columns."""
-  user_id = tf.feature_column.categorical_column_with_vocabulary_list(
-      movielens.USER_COLUMN, range(1, movielens.NUM_USER_IDS[dataset]))
-  user_embedding = tf.feature_column.embedding_column(
-      user_id, _USER_EMBEDDING_DIM, max_norm=np.sqrt(_USER_EMBEDDING_DIM))
-
-  item_id = tf.feature_column.categorical_column_with_vocabulary_list(
-      movielens.ITEM_COLUMN, range(1, movielens.NUM_ITEM_IDS))
-  item_embedding = tf.feature_column.embedding_column(
-      item_id, _ITEM_EMBEDDING_DIM, max_norm=np.sqrt(_ITEM_EMBEDDING_DIM))
-
-  time = tf.feature_column.numeric_column(movielens.TIMESTAMP_COLUMN)
-  genres = tf.feature_column.numeric_column(
-      movielens.GENRE_COLUMN, shape=(movielens.N_GENRE,), dtype=tf.uint8)
-
-  deep_columns = [user_embedding, item_embedding, time, genres]
-  wide_columns = []
-
-  return wide_columns, deep_columns
-
-
-def _deserialize(examples_serialized):
-  features = tf.parse_example(examples_serialized, _FEATURE_MAP)
-  return features, features[movielens.RATING_COLUMN] / movielens.MAX_RATING
-
-
-def _buffer_path(data_dir, dataset, name):
-  return os.path.join(data_dir, _BUFFER_SUBDIR,
-                      "{}_{}_buffer".format(dataset, name))
-
-
-def _df_to_input_fn(df, name, dataset, data_dir, batch_size, repeat, shuffle):
-  """Serialize a dataframe and write it to a buffer file."""
-  buffer_path = _buffer_path(data_dir, dataset, name)
-  expected_size = _BUFFER_SIZE[dataset].get(name)
-
-  file_io.write_to_buffer(
-      dataframe=df, buffer_path=buffer_path,
-      columns=list(_FEATURE_MAP.keys()), expected_size=expected_size)
-
-  def input_fn():
-    dataset = tf.data.TFRecordDataset(buffer_path)
-    # batch comes before map because map can deserialize multiple examples.
-    dataset = dataset.batch(batch_size)
-    dataset = dataset.map(_deserialize, num_parallel_calls=16)
-    if shuffle:
-      dataset = dataset.shuffle(shuffle)
-
-    dataset = dataset.repeat(repeat)
-    return dataset.prefetch(1)
-
-  return input_fn
-
-
-def _check_buffers(data_dir, dataset):
-  train_path = os.path.join(data_dir, _BUFFER_SUBDIR,
-                            "{}_{}_buffer".format(dataset, "train"))
-  eval_path = os.path.join(data_dir, _BUFFER_SUBDIR,
-                           "{}_{}_buffer".format(dataset, "eval"))
-
-  if not tf.gfile.Exists(train_path) or not tf.gfile.Exists(eval_path):
-    return False
-
-  return all([
-      tf.gfile.Stat(_buffer_path(data_dir, dataset, "train")).length ==
-      _BUFFER_SIZE[dataset]["train"],
-      tf.gfile.Stat(_buffer_path(data_dir, dataset, "eval")).length ==
-      _BUFFER_SIZE[dataset]["eval"],
-  ])
-
-
-def construct_input_fns(dataset, data_dir, batch_size=16, repeat=1):
-  """Construct train and test input functions, as well as the column fn."""
-  if _check_buffers(data_dir, dataset):
-    train_df, eval_df = None, None
-  else:
-    df = movielens.csv_to_joint_dataframe(dataset=dataset, data_dir=data_dir)
-    df = movielens.integerize_genres(dataframe=df)
-    df = df.drop(columns=[movielens.TITLE_COLUMN])
-
-    train_df = df.sample(frac=0.8, random_state=0)
-    eval_df = df.drop(train_df.index)
-
-    train_df = train_df.reset_index(drop=True)
-    eval_df = eval_df.reset_index(drop=True)
-
-  train_input_fn = _df_to_input_fn(
-      df=train_df, name="train", dataset=dataset, data_dir=data_dir,
-      batch_size=batch_size, repeat=repeat,
-      shuffle=movielens.NUM_RATINGS[dataset])
-  eval_input_fn = _df_to_input_fn(
-      df=eval_df, name="eval", dataset=dataset, data_dir=data_dir,
-      batch_size=batch_size, repeat=repeat, shuffle=None)
-  model_column_fn = functools.partial(build_model_columns, dataset=dataset)
-
-  train_input_fn()
-  return train_input_fn, eval_input_fn, model_column_fn
-
-
-def main(_):
-  movielens.download(dataset=flags.FLAGS.dataset, data_dir=flags.FLAGS.data_dir)
-  construct_input_fns(flags.FLAGS.dataset, flags.FLAGS.data_dir)
-
-if __name__ == "__main__":
-  tf.logging.set_verbosity(tf.logging.INFO)
-  movielens.define_data_download_flags()
-  flags.adopt_module_key_flags(movielens)
-  flags_core.set_defaults(dataset="ml-1m")
-  absl_app.run(main)
diff --git a/official/r1/wide_deep/movielens_main.py b/official/r1/wide_deep/movielens_main.py
deleted file mode 100644
index 45f7453c..00000000
--- a/official/r1/wide_deep/movielens_main.py
+++ /dev/null
@@ -1,114 +0,0 @@
-# Copyright 2018 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Train DNN on Kaggle movie dataset."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-
-from absl import app as absl_app
-from absl import flags
-import tensorflow.compat.v1 as tf
-from official.r1.utils.logs import logger
-from official.r1.wide_deep import movielens_dataset
-from official.r1.wide_deep import wide_deep_run_loop
-from official.recommendation import movielens
-from official.utils.flags import core as flags_core
-
-
-def define_movie_flags():
-  """Define flags for movie dataset training."""
-  wide_deep_run_loop.define_wide_deep_flags()
-  flags.DEFINE_enum(
-      name="dataset", default=movielens.ML_1M,
-      enum_values=movielens.DATASETS, case_sensitive=False,
-      help=flags_core.help_wrap("Dataset to be trained and evaluated."))
-  flags.adopt_module_key_flags(wide_deep_run_loop)
-  flags_core.set_defaults(data_dir="/tmp/movielens-data/",
-                          model_dir='/tmp/movie_model',
-                          model_type="deep",
-                          train_epochs=50,
-                          epochs_between_evals=5,
-                          inter_op_parallelism_threads=0,
-                          intra_op_parallelism_threads=0,
-                          batch_size=256)
-
-  @flags.validator("stop_threshold",
-                   message="stop_threshold not supported for movielens model")
-  def _no_stop(stop_threshold):
-    return stop_threshold is None
-
-
-def build_estimator(model_dir, model_type, model_column_fn, inter_op, intra_op):
-  """Build an estimator appropriate for the given model type."""
-  if model_type != "deep":
-    raise NotImplementedError("movie dataset only supports `deep` model_type")
-  _, deep_columns = model_column_fn()
-  hidden_units = [256, 256, 256, 128]
-
-  run_config = tf.estimator.RunConfig().replace(
-      session_config=tf.ConfigProto(device_count={'GPU': 0},
-                                    inter_op_parallelism_threads=inter_op,
-                                    intra_op_parallelism_threads=intra_op))
-  return tf.estimator.DNNRegressor(
-      model_dir=model_dir,
-      feature_columns=deep_columns,
-      hidden_units=hidden_units,
-      optimizer=tf.compat.v1.train.AdamOptimizer(),
-      activation_fn=tf.nn.sigmoid,
-      dropout=0.3,
-      loss_reduction=tf.losses.Reduction.MEAN)
-
-
-def run_movie(flags_obj):
-  """Construct all necessary functions and call run_loop.
-
-  Args:
-    flags_obj: Object containing user specified flags.
-  """
-
-  if flags_obj.download_if_missing:
-    movielens.download(dataset=flags_obj.dataset, data_dir=flags_obj.data_dir)
-
-  train_input_fn, eval_input_fn, model_column_fn = \
-    movielens_dataset.construct_input_fns(
-        dataset=flags_obj.dataset, data_dir=flags_obj.data_dir,
-        batch_size=flags_obj.batch_size, repeat=flags_obj.epochs_between_evals)
-
-  tensors_to_log = {
-      'loss': '{loss_prefix}head/weighted_loss/value'
-  }
-
-  wide_deep_run_loop.run_loop(
-      name="MovieLens", train_input_fn=train_input_fn,
-      eval_input_fn=eval_input_fn,
-      model_column_fn=model_column_fn,
-      build_estimator_fn=build_estimator,
-      flags_obj=flags_obj,
-      tensors_to_log=tensors_to_log,
-      early_stop=False)
-
-
-def main(_):
-  with logger.benchmark_context(flags.FLAGS):
-    run_movie(flags.FLAGS)
-
-
-if __name__ == '__main__':
-  tf.logging.set_verbosity(tf.logging.INFO)
-  define_movie_flags()
-  absl_app.run(main)
diff --git a/official/r1/wide_deep/wide_deep_run_loop.py b/official/r1/wide_deep/wide_deep_run_loop.py
deleted file mode 100644
index d81bfc85..00000000
--- a/official/r1/wide_deep/wide_deep_run_loop.py
+++ /dev/null
@@ -1,133 +0,0 @@
-# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
-#
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-# ==============================================================================
-"""Core run logic for TensorFlow Wide & Deep Tutorial using tf.estimator API."""
-
-from __future__ import absolute_import
-from __future__ import division
-from __future__ import print_function
-
-import os
-import shutil
-
-from absl import app as absl_app
-from absl import flags
-import tensorflow.compat.v1 as tf
-
-from official.r1.utils.logs import hooks_helper
-from official.r1.utils.logs import logger
-from official.utils.flags import core as flags_core
-from official.utils.misc import model_helpers
-
-
-LOSS_PREFIX = {'wide': 'linear/', 'deep': 'dnn/'}
-
-
-def define_wide_deep_flags():
-  """Add supervised learning flags, as well as wide-deep model type."""
-  flags_core.define_base(clean=True, train_epochs=True,
-                         epochs_between_evals=True, stop_threshold=True,
-                         hooks=True, export_dir=True)
-  flags_core.define_benchmark()
-  flags_core.define_performance(
-      num_parallel_calls=False, inter_op=True, intra_op=True,
-      synthetic_data=False, max_train_steps=False, dtype=False,
-      all_reduce_alg=False)
-
-  flags.adopt_module_key_flags(flags_core)
-
-  flags.DEFINE_enum(
-      name="model_type", short_name="mt", default="wide_deep",
-      enum_values=['wide', 'deep', 'wide_deep'],
-      help="Select model topology.")
-  flags.DEFINE_boolean(
-      name="download_if_missing", default=True, help=flags_core.help_wrap(
-          "Download data to data_dir if it is not already present."))
-
-
-def export_model(model, model_type, export_dir, model_column_fn):
-  """Export to SavedModel format.
-
-  Args:
-    model: Estimator object
-    model_type: string indicating model type. "wide", "deep" or "wide_deep"
-    export_dir: directory to export the model.
-    model_column_fn: Function to generate model feature columns.
-  """
-  wide_columns, deep_columns = model_column_fn()
-  if model_type == 'wide':
-    columns = wide_columns
-  elif model_type == 'deep':
-    columns = deep_columns
-  else:
-    columns = wide_columns + deep_columns
-  feature_spec = tf.feature_column.make_parse_example_spec(columns)
-  example_input_fn = (
-      tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec))
-  model.export_savedmodel(export_dir, example_input_fn,
-                          strip_default_attrs=True)
-
-
-def run_loop(name, train_input_fn, eval_input_fn, model_column_fn,
-             build_estimator_fn, flags_obj, tensors_to_log, early_stop=False):
-  """Define training loop."""
-  model_helpers.apply_clean(flags.FLAGS)
-  model = build_estimator_fn(
-      model_dir=flags_obj.model_dir, model_type=flags_obj.model_type,
-      model_column_fn=model_column_fn,
-      inter_op=flags_obj.inter_op_parallelism_threads,
-      intra_op=flags_obj.intra_op_parallelism_threads)
-
-  run_params = {
-      'batch_size': flags_obj.batch_size,
-      'train_epochs': flags_obj.train_epochs,
-      'model_type': flags_obj.model_type,
-  }
-
-  benchmark_logger = logger.get_benchmark_logger()
-  benchmark_logger.log_run_info('wide_deep', name, run_params,
-                                test_id=flags_obj.benchmark_test_id)
-
-  loss_prefix = LOSS_PREFIX.get(flags_obj.model_type, '')
-  tensors_to_log = {k: v.format(loss_prefix=loss_prefix)
-                    for k, v in tensors_to_log.items()}
-  train_hooks = hooks_helper.get_train_hooks(
-      flags_obj.hooks, model_dir=flags_obj.model_dir,
-      batch_size=flags_obj.batch_size, tensors_to_log=tensors_to_log)
-
-  # Train and evaluate the model every `flags.epochs_between_evals` epochs.
-  for n in range(flags_obj.train_epochs // flags_obj.epochs_between_evals):
-    model.train(input_fn=train_input_fn, hooks=train_hooks)
-
-    results = model.evaluate(input_fn=eval_input_fn)
-
-    # Display evaluation metrics
-    tf.logging.info('Results at epoch %d / %d',
-                    (n + 1) * flags_obj.epochs_between_evals,
-                    flags_obj.train_epochs)
-    tf.logging.info('-' * 60)
-
-    for key in sorted(results):
-      tf.logging.info('%s: %s' % (key, results[key]))
-
-    benchmark_logger.log_evaluation_result(results)
-
-    if early_stop and model_helpers.past_stop_threshold(
-        flags_obj.stop_threshold, results['accuracy']):
-      break
-
-  # Export the model
-  if flags_obj.export_dir is not None:
-    export_model(model, flags_obj.model_type, flags_obj.export_dir,
-                 model_column_fn)
