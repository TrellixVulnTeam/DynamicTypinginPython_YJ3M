commit 4cd908efd2cebff7efee4ad8b4246fe431913b01
Author: Hongkun Yu <hongkuny@google.com>
Date:   Wed Jun 10 12:05:50 2020 -0700

    Fix typo.
    
    PiperOrigin-RevId: 315738983

diff --git a/official/nlp/modeling/layers/attention.py b/official/nlp/modeling/layers/attention.py
index 3db611f8..99692b28 100644
--- a/official/nlp/modeling/layers/attention.py
+++ b/official/nlp/modeling/layers/attention.py
@@ -145,7 +145,7 @@ class MultiHeadAttention(tf.keras.layers.Layer):
   >>> target = tf.keras.Input(shape=[8, 16])
   >>> source = tf.keras.Input(shape=[4, 16])
   >>> mask_tensor = tf.keras.Input(shape=[8, 4])
-  >>> output_tensor, weights = layer([input_tensor, input_tensor])
+  >>> output_tensor, weights = layer([target, source])
   >>> print(output_tensor.shape), print(weights.shape)
   (None, 8, 16)  (None, 2, 8, 4)
 
