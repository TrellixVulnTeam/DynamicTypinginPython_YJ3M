commit 0cde63327088b6fc27e832d65f8c48f3037f154f
Author: Ashley Williamson <11356993@students.lincoln.ac.uk>
Date:   Wed Jun 7 18:51:58 2017 +0100

    Implemented LRN for AlexNet tutorial
    
    A TODO was stated for adding LRN - Pending GPU support.
    LRN was implemented by tensorflow/tensorflow@35df3ed43edabbc4ad1b2439bbc7de8917026d6e
    
    Hyper-parameters taken from http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks

diff --git a/tutorials/image/alexnet/alexnet_benchmark.py b/tutorials/image/alexnet/alexnet_benchmark.py
index ed723055..04c394ad 100644
--- a/tutorials/image/alexnet/alexnet_benchmark.py
+++ b/tutorials/image/alexnet/alexnet_benchmark.py
@@ -73,11 +73,18 @@ def inference(images):
     print_activations(conv1)
     parameters += [kernel, biases]
 
-  # lrn1
-  # TODO(shlens, jiayq): Add a GPU version of local response normalization.
+
+  with tf.name_scope('lrn1') as scope:
+    lrn1 = tf.nn.local_response_normalization(
+      conv1,
+      alpha=1e-04,
+      beta=0.75,
+      depth_radius=5,
+      bias=2.0
+    )
 
   # pool1
-  pool1 = tf.nn.max_pool(conv1,
+  pool1 = tf.nn.max_pool(lrn1,
                          ksize=[1, 3, 3, 1],
                          strides=[1, 2, 2, 1],
                          padding='VALID',
@@ -96,8 +103,18 @@ def inference(images):
     parameters += [kernel, biases]
   print_activations(conv2)
 
+
+  with tf.name_scope('lrn2') as scope:
+    lrn2 = tf.nn.local_response_normalization(
+      conv2,
+      alpha=1e-04,
+      beta=0.75,
+      depth_radius=5,
+      bias=2.0
+    )
+
   # pool2
-  pool2 = tf.nn.max_pool(conv2,
+  pool2 = tf.nn.max_pool(lrn2,
                          ksize=[1, 3, 3, 1],
                          strides=[1, 2, 2, 1],
                          padding='VALID',
