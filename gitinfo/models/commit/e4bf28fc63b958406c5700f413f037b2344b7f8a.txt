commit e4bf28fc63b958406c5700f413f037b2344b7f8a
Author: guptapriya <priyag@google.com>
Date:   Wed Jun 5 23:07:35 2019 +0000

    fix lint errors

diff --git a/official/transformer/v2/transformer_main.py b/official/transformer/v2/transformer_main.py
index ba789010..30263d4a 100644
--- a/official/transformer/v2/transformer_main.py
+++ b/official/transformer/v2/transformer_main.py
@@ -99,10 +99,11 @@ class TransformerTask(object):
 
     print("Running transformer with num_gpus =", num_gpus)
     if self.distribution_strategy:
-      print("For training, using distribution strategy: ", self.distribution_strategy)
+      print("For training, using distribution strategy: ",
+            self.distribution_strategy)
     else:
       print("Not using any distribution strategy.")
-    
+
     self.params = params = misc.get_model_params(flags_obj.param_set, num_gpus)
 
     params["num_gpus"] = num_gpus
@@ -197,7 +198,7 @@ class TransformerTask(object):
     with tf.name_scope("model"):
       model = transformer.create_model(params, is_train)
       self._load_weights_if_possible(
-        model, tf.train.latest_checkpoint(self.flags_obj.model_dir))
+          model, tf.train.latest_checkpoint(self.flags_obj.model_dir))
       model.summary()
     subtokenizer = tokenizer.Subtokenizer(flags_obj.vocab_file)
 
