commit 0f12d4a4188fa7fe4e2fe943d1035eec64a630df
Author: Justine Tunney <jart@google.com>
Date:   Fri May 26 23:07:13 2017 -0700

    Fix Bazel incantations in docs
    
    Fixes tensorflow/tensorflow#10239

diff --git a/im2txt/README.md b/im2txt/README.md
index 510ee544..223cf91f 100644
--- a/im2txt/README.md
+++ b/im2txt/README.md
@@ -145,7 +145,8 @@ available space for storing the downloaded and processed data.
 MSCOCO_DIR="${HOME}/im2txt/data/mscoco"
 
 # Build the preprocessing script.
-bazel build im2txt/download_and_preprocess_mscoco
+cd tensorflow-models/im2txt
+bazel build //im2txt:download_and_preprocess_mscoco
 
 # Run the preprocessing script.
 bazel-bin/im2txt/download_and_preprocess_mscoco "${MSCOCO_DIR}"
@@ -211,7 +212,8 @@ INCEPTION_CHECKPOINT="${HOME}/im2txt/data/inception_v3.ckpt"
 MODEL_DIR="${HOME}/im2txt/model"
 
 # Build the model.
-bazel build -c opt im2txt/...
+cd tensorflow-models/im2txt
+bazel build -c opt //im2txt/...
 
 # Run the training script.
 bazel-bin/im2txt/train \
@@ -304,7 +306,8 @@ VOCAB_FILE="${HOME}/im2txt/data/mscoco/word_counts.txt"
 IMAGE_FILE="${HOME}/im2txt/data/mscoco/raw-data/val2014/COCO_val2014_000000224477.jpg"
 
 # Build the inference binary.
-bazel build -c opt im2txt/run_inference
+cd tensorflow-models/im2txt
+bazel build -c opt //im2txt:run_inference
 
 # Ignore GPU devices (only necessary if your GPU is currently memory
 # constrained, for example, by running the training script).
diff --git a/inception/README.md b/inception/README.md
index 44641530..f4731213 100644
--- a/inception/README.md
+++ b/inception/README.md
@@ -86,7 +86,8 @@ you will not need to interact with the script again.
 DATA_DIR=$HOME/imagenet-data
 
 # build the preprocessing script.
-bazel build inception/download_and_preprocess_imagenet
+cd tensorflow-models/inception
+bazel build //inception:download_and_preprocess_imagenet
 
 # run it
 bazel-bin/inception/download_and_preprocess_imagenet "${DATA_DIR}"
@@ -153,7 +154,8 @@ To train this model, you simply need to specify the following:
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/imagenet_train
+cd tensorflow-models/inception
+bazel build //inception:imagenet_train
 
 # run it
 bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=32 --train_dir=/tmp/imagenet_train --data_dir=/tmp/imagenet_data
@@ -189,7 +191,8 @@ GPU cards.
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/imagenet_train
+cd tensorflow-models/inception
+bazel build //inception:imagenet_train
 
 # run it
 bazel-bin/inception/imagenet_train --num_gpus=2 --batch_size=64 --train_dir=/tmp/imagenet_train
@@ -288,7 +291,8 @@ running. Several things to note here:
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/imagenet_distributed_train
+cd tensorflow-models/inception
+bazel build //inception:imagenet_distributed_train
 
 # To start worker 0, go to the worker0 host and run the following (Note that
 # task_id should be in the range [0, num_worker_tasks):
@@ -395,7 +399,8 @@ Briefly, one can evaluate the model by running:
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/imagenet_eval
+cd tensorflow-models/inception
+bazel build //inception:imagenet_eval
 
 # run it
 bazel-bin/inception/imagenet_eval --checkpoint_dir=/tmp/imagenet_train --eval_dir=/tmp/imagenet_eval
@@ -450,7 +455,8 @@ but feel free to edit accordingly.
 FLOWERS_DATA_DIR=/tmp/flowers-data/
 
 # build the preprocessing script.
-bazel build inception/download_and_preprocess_flowers
+cd tensorflow-models/inception
+bazel build //inception:download_and_preprocess_flowers
 
 # run it
 bazel-bin/inception/download_and_preprocess_flowers "${FLOWERS_DATA_DIR}"
@@ -530,7 +536,8 @@ the flowers data set with the following command.
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/flowers_train
+cd tensorflow-models/inception
+bazel build //inception:flowers_train
 
 # Path to the downloaded Inception-v3 model.
 MODEL_PATH="${INCEPTION_MODEL_DIR}/inception-v3/model.ckpt-157585"
@@ -566,7 +573,8 @@ fine-tuned model, you will need to run `flowers_eval`:
 ```shell
 # Build the model. Note that we need to make sure the TensorFlow is ready to
 # use before this as this command will not build TensorFlow.
-bazel build inception/flowers_eval
+cd tensorflow-models/inception
+bazel build //inception:flowers_eval
 
 # Directory where we saved the fine-tuned checkpoint and events files.
 TRAIN_DIR=/tmp/flowers_train/
@@ -654,7 +662,8 @@ To run `build_image_data.py`, you can run the following command line:
 OUTPUT_DIRECTORY=$HOME/my-custom-data/
 
 # build the preprocessing script.
-bazel build inception/build_image_data
+cd tensorflow-models/inception
+bazel build //inception:build_image_data
 
 # convert the data.
 bazel-bin/inception/build_image_data \
diff --git a/skip_thoughts/README.md b/skip_thoughts/README.md
index 68cc45e6..cdcffe7c 100644
--- a/skip_thoughts/README.md
+++ b/skip_thoughts/README.md
@@ -133,7 +133,8 @@ INPUT_FILES="${HOME}/skip_thoughts/bookcorpus/*.txt"
 DATA_DIR="${HOME}/skip_thoughts/data"
 
 # Build the preprocessing script.
-bazel build -c opt skip_thoughts/data/preprocess_dataset
+cd tensorflow-models/skip_thoughts
+bazel build -c opt //skip_thoughts/data:preprocess_dataset
 
 # Run the preprocessing script.
 bazel-bin/skip_thoughts/data/preprocess_dataset \
@@ -164,7 +165,8 @@ DATA_DIR="${HOME}/skip_thoughts/data"
 MODEL_DIR="${HOME}/skip_thoughts/model"
 
 # Build the model.
-bazel build -c opt skip_thoughts/...
+cd tensorflow-models/skip_thoughts
+bazel build -c opt //skip_thoughts/...
 
 # Run the training script.
 bazel-bin/skip_thoughts/train \
@@ -269,7 +271,8 @@ WORD2VEC_MODEL="${HOME}/skip_thoughts/googlenews/GoogleNews-vectors-negative300.
 EXP_VOCAB_DIR="${HOME}/skip_thoughts/exp_vocab"
 
 # Build the vocabulary expansion script.
-bazel build -c opt skip_thoughts/vocabulary_expansion
+cd tensorflow-models/skip_thoughts
+bazel build -c opt //skip_thoughts:vocabulary_expansion
 
 # Run the vocabulary expansion script.
 bazel-bin/skip_thoughts/vocabulary_expansion \
@@ -343,7 +346,8 @@ EMBEDDINGS_FILE="${HOME}/skip_thoughts/exp_vocab/embeddings.npy"
 EVAL_DATA_DIR="${HOME}/skip_thoughts/eval_data"
 
 # Build the evaluation script.
-bazel build -c opt skip_thoughts/evaluate
+cd tensorflow-models/skip_thoughts
+bazel build -c opt //skip_thoughts:evaluate
 
 # Run the evaluation script.
 bazel-bin/skip_thoughts/evaluate \
