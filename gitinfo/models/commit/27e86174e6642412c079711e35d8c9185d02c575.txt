commit 27e86174e6642412c079711e35d8c9185d02c575
Author: Toby Boyd <tobyboyd@google.com>
Date:   Mon Feb 11 00:56:11 2019 -0800

    Fix accuracy name (#6179)

diff --git a/official/resnet/estimator_cifar_benchmark.py b/official/resnet/estimator_cifar_benchmark.py
index bb296874..135abc98 100644
--- a/official/resnet/estimator_cifar_benchmark.py
+++ b/official/resnet/estimator_cifar_benchmark.py
@@ -19,8 +19,8 @@ from __future__ import division
 from __future__ import print_function
 
 import json
-import time
 import os
+import time
 
 from absl import flags
 from absl.testing import flagsaver
@@ -88,7 +88,7 @@ class EstimatorCifar10BenchmarkTests(tf.test.Benchmark):
     self._run_and_report_benchmark()
 
   def unit_test(self):
-    """A lightweigth test that can finish quickly"""
+    """A lightweight test that can finish quickly."""
     self._setup()
     flags.FLAGS.num_gpus = 1
     flags.FLAGS.data_dir = DATA_DIR
@@ -108,7 +108,7 @@ class EstimatorCifar10BenchmarkTests(tf.test.Benchmark):
         iters=stats['global_step'],
         wall_time=wall_time_sec,
         extras={
-            'accuracy':
+            'accuracy_top_1':
                 self._json_description(stats['accuracy'].item(), priority=0),
             'accuracy_top_5':
                 self._json_description(stats['accuracy_top_5'].item()),
@@ -119,7 +119,7 @@ class EstimatorCifar10BenchmarkTests(tf.test.Benchmark):
                         priority=None,
                         min_value=None,
                         max_value=None):
-    """Get a json-formatted string describing the attributes for a metric"""
+    """Get a json-formatted string describing the attributes for a metric."""
 
     attributes = {}
     attributes['value'] = value
diff --git a/official/resnet/keras/keras_benchmark.py b/official/resnet/keras/keras_benchmark.py
index 6b2d26e1..d6170c81 100644
--- a/official/resnet/keras/keras_benchmark.py
+++ b/official/resnet/keras/keras_benchmark.py
@@ -65,7 +65,7 @@ class KerasBenchmark(tf.test.Benchmark):
                         log_steps=None,
                         total_batch_size=None,
                         warmup=1):
-    """Report benchmark results by writing to local protobuf file
+    """Report benchmark results by writing to local protobuf file.
 
     Args:
       stats: dict returned from keras models with known entries.
@@ -79,7 +79,7 @@ class KerasBenchmark(tf.test.Benchmark):
 
     extras = {}
     if 'accuracy_top_1' in stats:
-      extras['accuracy'] = self._json_description(
+      extras['accuracy_top_1'] = self._json_description(
           stats['accuracy_top_1'],
           priority=0,
           min_value=top_1_min,
