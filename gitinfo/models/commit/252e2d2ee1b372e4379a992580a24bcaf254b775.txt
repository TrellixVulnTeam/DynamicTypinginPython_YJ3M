commit 252e2d2ee1b372e4379a992580a24bcaf254b775
Author: Chris Shallue <shallue@google.com>
Date:   Fri Sep 21 03:51:12 2018 -0700

    Update formatting.
    
    PiperOrigin-RevId: 213963765

diff --git a/research/astronet/astronet/astro_cnn_model/astro_cnn_model_test.py b/research/astronet/astronet/astro_cnn_model/astro_cnn_model_test.py
index 6424917d..a89ec26d 100644
--- a/research/astronet/astronet/astro_cnn_model/astro_cnn_model_test.py
+++ b/research/astronet/astronet/astro_cnn_model/astro_cnn_model_test.py
@@ -35,8 +35,7 @@ class AstroCNNModelTest(tf.test.TestCase):
 
     Args:
       shape: Numpy array or anything that can be converted to one.
-      tensor_or_array: tf.Tensor, tf.Variable, Numpy array or anything that can
-          be converted to one.
+      tensor_or_array: tf.Tensor, tf.Variable, or Numpy array.
     """
     if isinstance(tensor_or_array, (np.ndarray, np.generic)):
       self.assertAllEqual(shape, tensor_or_array.shape)
diff --git a/research/astronet/astronet/astro_fc_model/astro_fc_model_test.py b/research/astronet/astronet/astro_fc_model/astro_fc_model_test.py
index 459eb26d..de7ed23c 100644
--- a/research/astronet/astronet/astro_fc_model/astro_fc_model_test.py
+++ b/research/astronet/astronet/astro_fc_model/astro_fc_model_test.py
@@ -35,8 +35,7 @@ class AstroFCModelTest(tf.test.TestCase):
 
     Args:
       shape: Numpy array or anything that can be converted to one.
-      tensor_or_array: tf.Tensor, tf.Variable, Numpy array or anything that can
-          be converted to one.
+      tensor_or_array: tf.Tensor, tf.Variable, or Numpy array.
     """
     if isinstance(tensor_or_array, (np.ndarray, np.generic)):
       self.assertAllEqual(shape, tensor_or_array.shape)
diff --git a/research/astronet/astronet/astro_model/astro_model.py b/research/astronet/astronet/astro_model/astro_model.py
index 7af9adf3..d608cec1 100644
--- a/research/astronet/astronet/astro_model/astro_model.py
+++ b/research/astronet/astronet/astro_model/astro_model.py
@@ -73,17 +73,19 @@ class AstroModel(object):
   """A TensorFlow model for classifying astrophysical light curves."""
 
   def __init__(self, features, labels, hparams, mode):
-    """Basic setup. The actual TensorFlow graph is constructed in build().
+    """Basic setup.
+
+    The actual TensorFlow graph is constructed in build().
 
     Args:
       features: A dictionary containing "time_series_features" and
-          "aux_features", each of which is a dictionary of named input Tensors.
-          All features have dtype float32 and shape [batch_size, length].
+        "aux_features", each of which is a dictionary of named input Tensors.
+        All features have dtype float32 and shape [batch_size, length].
       labels: An int64 Tensor with shape [batch_size]. May be None if mode is
-          tf.estimator.ModeKeys.PREDICT.
+        tf.estimator.ModeKeys.PREDICT.
       hparams: A ConfigDict of hyperparameters for building the model.
       mode: A tf.estimator.ModeKeys to specify whether the graph should be built
-          for training, evaluation or prediction.
+        for training, evaluation or prediction.
 
     Raises:
       ValueError: If mode is invalid.
@@ -201,10 +203,9 @@ class AstroModel(object):
     if len(hidden_layers) == 1:
       pre_logits_concat = hidden_layers[0][1]
     else:
-      pre_logits_concat = tf.concat(
-          [layer[1] for layer in hidden_layers],
-          axis=1,
-          name="pre_logits_concat")
+      pre_logits_concat = tf.concat([layer[1] for layer in hidden_layers],
+                                    axis=1,
+                                    name="pre_logits_concat")
 
     net = pre_logits_concat
     with tf.variable_scope("pre_logits_hidden"):
diff --git a/research/astronet/astronet/astro_model/astro_model_test.py b/research/astronet/astronet/astro_model/astro_model_test.py
index 5c45a780..901c47e3 100644
--- a/research/astronet/astronet/astro_model/astro_model_test.py
+++ b/research/astronet/astronet/astro_model/astro_model_test.py
@@ -35,8 +35,7 @@ class AstroModelTest(tf.test.TestCase):
 
     Args:
       shape: Numpy array or anything that can be converted to one.
-      tensor_or_array: tf.Tensor, tf.Variable, Numpy array or anything that can
-          be converted to one.
+      tensor_or_array: tf.Tensor, tf.Variable, or Numpy array.
     """
     if isinstance(tensor_or_array, (np.ndarray, np.generic)):
       self.assertAllEqual(shape, tensor_or_array.shape)
diff --git a/research/astronet/astronet/data/generate_input_records.py b/research/astronet/astronet/data/generate_input_records.py
index 2dafd096..fc3d5bba 100644
--- a/research/astronet/astronet/data/generate_input_records.py
+++ b/research/astronet/astronet/data/generate_input_records.py
@@ -88,7 +88,6 @@ import tensorflow as tf
 
 from astronet.data import preprocess
 
-
 parser = argparse.ArgumentParser()
 
 _DR24_TCE_URL = ("https://exoplanetarchive.ipac.caltech.edu/cgi-bin/TblView/"
@@ -225,10 +224,10 @@ def main(argv):
     file_shards.append((train_tces[start:end], filename))
 
   # Validation and test sets each have a single shard.
-  file_shards.append((val_tces, os.path.join(FLAGS.output_dir,
-                                             "val-00000-of-00001")))
-  file_shards.append((test_tces, os.path.join(FLAGS.output_dir,
-                                              "test-00000-of-00001")))
+  file_shards.append((val_tces,
+                      os.path.join(FLAGS.output_dir, "val-00000-of-00001")))
+  file_shards.append((test_tces,
+                      os.path.join(FLAGS.output_dir, "test-00000-of-00001")))
   num_file_shards = len(file_shards)
 
   # Launch subprocesses for the file shards.
diff --git a/research/astronet/astronet/data/preprocess.py b/research/astronet/astronet/data/preprocess.py
index 45d9e6e4..e3f3e876 100644
--- a/research/astronet/astronet/data/preprocess.py
+++ b/research/astronet/astronet/data/preprocess.py
@@ -34,7 +34,7 @@ def read_light_curve(kepid, kepler_data_dir):
   Args:
     kepid: Kepler id of the target star.
     kepler_data_dir: Base directory containing Kepler data. See
-        kepler_io.kepler_filenames().
+      kepler_io.kepler_filenames().
 
   Returns:
     all_time: A list of numpy arrays; the time values of the raw light curve.
@@ -59,7 +59,7 @@ def process_light_curve(all_time, all_flux):
   Args:
     all_time: A list of numpy arrays; the time values of the raw light curve.
     all_flux: A list of numpy arrays corresponding to the time arrays in
-        all_time.
+      all_time.
 
   Returns:
     time: 1D NumPy array; the time values of the light curve.
@@ -192,7 +192,7 @@ def local_view(time,
     num_bins: The number of intervals to divide the time axis into.
     bin_width_factor: Width of the bins, as a fraction of duration.
     num_durations: The number of durations to consider on either side of 0 (the
-        event is assumed to be centered at 0).
+      event is assumed to be centered at 0).
 
   Returns:
     1D NumPy array of size num_bins containing the median flux values of
@@ -214,7 +214,7 @@ def generate_example_for_tce(time, flux, tce):
     time: 1D NumPy array; the time values of the light curve.
     flux: 1D NumPy array; the normalized flux values of the light curve.
     tce: Dict-like object containing at least 'tce_period', 'tce_duration', and
-        'tce_time0bk'. Additional items are included as features in the output.
+      'tce_time0bk'. Additional items are included as features in the output.
 
   Returns:
     A tf.train.Example containing features 'global_view', 'local_view', and all
diff --git a/research/astronet/astronet/models.py b/research/astronet/astronet/models.py
index 4a51ca6e..47e63437 100644
--- a/research/astronet/astronet/models.py
+++ b/research/astronet/astronet/models.py
@@ -57,7 +57,7 @@ def get_model_config(model_name, config_name):
   Args:
     model_name: Name of the model class.
     config_name: Name of a configuration-builder function from the model's
-        configurations module.
+      configurations module.
 
   Returns:
     model_class: The requested model class.
diff --git a/research/astronet/astronet/ops/dataset_ops.py b/research/astronet/astronet/ops/dataset_ops.py
index 710d0d00..62bcf52e 100644
--- a/research/astronet/astronet/ops/dataset_ops.py
+++ b/research/astronet/astronet/ops/dataset_ops.py
@@ -142,19 +142,19 @@ def build_dataset(file_pattern,
 
   Args:
     file_pattern: File pattern matching input TFRecord files, e.g.
-        "/tmp/train-?????-of-00100". May also be a comma-separated list of file
-        patterns.
+      "/tmp/train-?????-of-00100". May also be a comma-separated list of file
+      patterns.
     input_config: ConfigDict containing feature and label specifications.
     batch_size: The number of examples per batch.
     include_labels: Whether to read labels from the input files.
     reverse_time_series_prob: If > 0, the time series features will be randomly
-        reversed with this probability. Within a given example, either all time
-        series features will be reversed, or none will be reversed.
+      reversed with this probability. Within a given example, either all time
+      series features will be reversed, or none will be reversed.
     shuffle_filenames: Whether to shuffle the order of TFRecord files between
-        epochs.
+      epochs.
     shuffle_values_buffer: If > 0, shuffle examples using a buffer of this size.
     repeat: The number of times to repeat the dataset. If None or -1 the dataset
-        will repeat indefinitely.
+      will repeat indefinitely.
     use_tpu: Whether to build the dataset for TPU.
 
   Raises:
diff --git a/research/astronet/astronet/ops/input_ops.py b/research/astronet/astronet/ops/input_ops.py
index 03f2c425..aafc4473 100644
--- a/research/astronet/astronet/ops/input_ops.py
+++ b/research/astronet/astronet/ops/input_ops.py
@@ -27,11 +27,10 @@ def prepare_feed_dict(model, features, labels=None, is_training=None):
   Args:
     model: An instance of AstroModel.
     features: Dictionary containing "time_series_features" and "aux_features".
-        Each is a dictionary of named numpy arrays of shape
-        [batch_size, length].
+      Each is a dictionary of named numpy arrays of shape [batch_size, length].
     labels: (Optional). Numpy array of shape [batch_size].
     is_training: (Optional). Python boolean to feed to the model.is_training
-        Tensor (if None, no value is fed).
+      Tensor (if None, no value is fed).
 
   Returns:
     feed_dict: A dictionary of input Tensor to numpy array.
diff --git a/research/astronet/astronet/ops/input_ops_test.py b/research/astronet/astronet/ops/input_ops_test.py
index 3c8ba777..f511ac74 100644
--- a/research/astronet/astronet/ops/input_ops_test.py
+++ b/research/astronet/astronet/ops/input_ops_test.py
@@ -31,9 +31,9 @@ class InputOpsTest(tf.test.TestCase):
 
     Args:
       expected_shapes: Dictionary of expected Tensor shapes, as lists,
-          corresponding to the structure of 'features'.
+        corresponding to the structure of 'features'.
       features: Dictionary of feature placeholders of the format returned by
-          input_ops.build_feature_placeholders().
+        input_ops.build_feature_placeholders().
     """
     actual_shapes = {}
     for feature_type in features:
diff --git a/research/astronet/astronet/ops/testing.py b/research/astronet/astronet/ops/testing.py
index 682bf5fa..e362b381 100644
--- a/research/astronet/astronet/ops/testing.py
+++ b/research/astronet/astronet/ops/testing.py
@@ -47,15 +47,10 @@ def fake_features(feature_spec, batch_size):
     Dictionary containing "time_series_features" and "aux_features". Each is a
         dictionary of named numpy arrays of shape [batch_size, length].
   """
-  features = {}
-  features["time_series_features"] = {
-      name: np.random.random([batch_size, spec["length"]])
-      for name, spec in feature_spec.items() if spec["is_time_series"]
-  }
-  features["aux_features"] = {
-      name: np.random.random([batch_size, spec["length"]])
-      for name, spec in feature_spec.items() if not spec["is_time_series"]
-  }
+  features = {"time_series_features": {}, "aux_features": {}}
+  for name, spec in feature_spec.items():
+    ftype = "time_series_features" if spec["is_time_series"] else "aux_features"
+    features[ftype][name] = np.random.random([batch_size, spec["length"]])
   return features
 
 
diff --git a/research/astronet/astronet/ops/training.py b/research/astronet/astronet/ops/training.py
index f5c6b2f7..c02e01af 100644
--- a/research/astronet/astronet/ops/training.py
+++ b/research/astronet/astronet/ops/training.py
@@ -51,7 +51,7 @@ def create_optimizer(hparams, learning_rate, use_tpu=False):
     hparams: ConfigDict containing the optimizer configuration.
     learning_rate: A Python float or a scalar Tensor.
     use_tpu: If True, the returned optimizer is wrapped in a
-        CrossShardOptimizer.
+      CrossShardOptimizer.
 
   Returns:
     A TensorFlow optimizer.
diff --git a/research/astronet/astronet/util/config_util.py b/research/astronet/astronet/util/config_util.py
index c983a42a..aa6e2823 100644
--- a/research/astronet/astronet/util/config_util.py
+++ b/research/astronet/astronet/util/config_util.py
@@ -105,7 +105,7 @@ def unflatten(flat_config):
 
   Args:
     flat_config: A dictionary with strings as keys where nested configuration
-        parameters are represented with period-separated names.
+      parameters are represented with period-separated names.
 
   Returns:
     A dictionary nested according to the keys of the input dictionary.
diff --git a/research/astronet/astronet/util/estimator_util.py b/research/astronet/astronet/util/estimator_util.py
index 5b1ae135..a5f727bf 100644
--- a/research/astronet/astronet/util/estimator_util.py
+++ b/research/astronet/astronet/util/estimator_util.py
@@ -203,10 +203,10 @@ def create_estimator(model_class,
     hparams: ConfigDict of configuration parameters for building the model.
     run_config: Optional tf.estimator.RunConfig or tf.contrib.tpu.RunConfig.
     model_dir: Optional directory for saving the model. If not passed
-        explicitly, it must be specified in run_config.
+      explicitly, it must be specified in run_config.
     eval_batch_size: Optional batch size for evaluation on TPU. Only applicable
-        if run_config is a tf.contrib.tpu.RunConfig. Defaults to
-        hparams.batch_size.
+      if run_config is a tf.contrib.tpu.RunConfig. Defaults to
+      hparams.batch_size.
 
   Returns:
     An Estimator object if run_config is None or a tf.estimator.RunConfig, or a
diff --git a/research/astronet/astronet/util/example_util.py b/research/astronet/astronet/util/example_util.py
index cec48692..da71c50c 100644
--- a/research/astronet/astronet/util/example_util.py
+++ b/research/astronet/astronet/util/example_util.py
@@ -28,7 +28,7 @@ def get_feature(ex, name, kind=None, strict=True):
     ex: A tf.train.Example.
     name: Name of the feature to look up.
     kind: Optional: one of 'bytes_list', 'float_list', 'int64_list'. Inferred if
-        not specified.
+      not specified.
     strict: Whether to raise a KeyError if there is no such feature.
 
   Returns:
@@ -93,7 +93,7 @@ def set_feature(ex,
     name: Name of the feature to set.
     value: Feature value to set. Must be a sequence.
     kind: Optional: one of 'bytes_list', 'float_list', 'int64_list'. Inferred if
-        not specified.
+      not specified.
     allow_overwrite: Whether to overwrite the existing value of the feature.
     bytes_encoding: Codec for encoding strings when kind = 'bytes_list'.
 
diff --git a/research/astronet/light_curve_util/cc/python/median_filter_test.py b/research/astronet/light_curve_util/cc/python/median_filter_test.py
index 3a64de09..2ccd5d1d 100644
--- a/research/astronet/light_curve_util/cc/python/median_filter_test.py
+++ b/research/astronet/light_curve_util/cc/python/median_filter_test.py
@@ -44,5 +44,5 @@ class MedianFilterTest(absltest.TestCase):
     np.testing.assert_almost_equal(result, expected)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
   absltest.main()
diff --git a/research/astronet/light_curve_util/cc/python/phase_fold_test.py b/research/astronet/light_curve_util/cc/python/phase_fold_test.py
index 41f6566c..73a054da 100644
--- a/research/astronet/light_curve_util/cc/python/phase_fold_test.py
+++ b/research/astronet/light_curve_util/cc/python/phase_fold_test.py
@@ -66,5 +66,5 @@ class PhaseFoldAndSortLightCurveTest(absltest.TestCase):
     np.testing.assert_almost_equal(folded_flux, expected_flux)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
   absltest.main()
diff --git a/research/astronet/light_curve_util/cc/python/view_generator_test.py b/research/astronet/light_curve_util/cc/python/view_generator_test.py
index 00110fe8..5a3717d1 100644
--- a/research/astronet/light_curve_util/cc/python/view_generator_test.py
+++ b/research/astronet/light_curve_util/cc/python/view_generator_test.py
@@ -76,5 +76,5 @@ class ViewGeneratorTest(absltest.TestCase):
     np.testing.assert_almost_equal(result, expected)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
   absltest.main()
diff --git a/research/astronet/light_curve_util/kepler_io.py b/research/astronet/light_curve_util/kepler_io.py
index cc8fd9ae..a26c0eb2 100644
--- a/research/astronet/light_curve_util/kepler_io.py
+++ b/research/astronet/light_curve_util/kepler_io.py
@@ -105,15 +105,15 @@ def kepler_filenames(base_dir,
   Args:
     base_dir: Base directory containing Kepler data.
     kep_id: Id of the Kepler target star. May be an int or a possibly zero-
-        padded string.
+      padded string.
     long_cadence: Whether to read a long cadence (~29.4 min / measurement) light
-        curve as opposed to a short cadence (~1 min / measurement) light curve.
+      curve as opposed to a short cadence (~1 min / measurement) light curve.
     quarters: Optional list of integers in [0, 17]; the quarters of the Kepler
-        mission to return.
+      mission to return.
     injected_group: Optional string indicating injected light curves. One of
-        "inj1", "inj2", "inj3".
+      "inj1", "inj2", "inj3".
     check_existence: If True, only return filenames corresponding to files that
-        exist (not all stars have data for all quarters).
+      exist (not all stars have data for all quarters).
 
   Returns:
     A list of filenames.
diff --git a/research/astronet/light_curve_util/median_filter.py b/research/astronet/light_curve_util/median_filter.py
index 5f16ad48..e806479e 100644
--- a/research/astronet/light_curve_util/median_filter.py
+++ b/research/astronet/light_curve_util/median_filter.py
@@ -32,16 +32,16 @@ def median_filter(x, y, num_bins, bin_width=None, x_min=None, x_max=None):
 
   Args:
     x: 1D array of x-coordinates sorted in ascending order. Must have at least 2
-        elements, and all elements cannot be the same value.
+      elements, and all elements cannot be the same value.
     y: 1D array of y-coordinates with the same size as x.
     num_bins: The number of intervals to divide the x-axis into. Must be at
-        least 2.
+      least 2.
     bin_width: The width of each bin on the x-axis. Must be positive, and less
-        than x_max - x_min. Defaults to (x_max - x_min) / num_bins.
+      than x_max - x_min. Defaults to (x_max - x_min) / num_bins.
     x_min: The inclusive leftmost value to consider on the x-axis. Must be less
-        than or equal to the largest value of x. Defaults to min(x).
+      than or equal to the largest value of x. Defaults to min(x).
     x_max: The exclusive rightmost value to consider on the x-axis. Must be
-        greater than x_min. Defaults to max(x).
+      greater than x_min. Defaults to max(x).
 
   Returns:
     1D NumPy array of size num_bins containing the median y-values of uniformly
diff --git a/research/astronet/light_curve_util/median_filter_test.py b/research/astronet/light_curve_util/median_filter_test.py
index 72b5b15c..6104be99 100644
--- a/research/astronet/light_curve_util/median_filter_test.py
+++ b/research/astronet/light_curve_util/median_filter_test.py
@@ -124,5 +124,5 @@ class MedianFilterTest(absltest.TestCase):
     np.testing.assert_array_equal([7, 1, 5, 2, 3], result)
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
   absltest.main()
diff --git a/research/astronet/light_curve_util/periodic_event.py b/research/astronet/light_curve_util/periodic_event.py
index 4e795bea..c75ee4ee 100644
--- a/research/astronet/light_curve_util/periodic_event.py
+++ b/research/astronet/light_curve_util/periodic_event.py
@@ -62,7 +62,7 @@ class Event(object):
       other_event: An Event.
       period_rtol: Relative tolerance in matching the periods.
       t0_durations: Tolerance in matching the t0 values, in units of the other
-          Event's duration.
+        Event's duration.
 
     Returns:
       True if this Event is the same as other_event, within the given tolerance.
diff --git a/research/astronet/light_curve_util/util.py b/research/astronet/light_curve_util/util.py
index 84b3196a..123aeae9 100644
--- a/research/astronet/light_curve_util/util.py
+++ b/research/astronet/light_curve_util/util.py
@@ -51,9 +51,9 @@ def split(all_time, all_flux, gap_width=0.75):
 
   Args:
     all_time: Numpy array or sequence of numpy arrays; each is a sequence of
-        time values.
+      time values.
     all_flux: Numpy array or sequence of numpy arrays; each is a sequence of
-        flux values of the corresponding time array.
+      flux values of the corresponding time array.
     gap_width: Minimum gap size (in time units) for a split.
 
   Returns:
@@ -91,9 +91,9 @@ def remove_events(all_time,
 
   Args:
     all_time: Numpy array or sequence of numpy arrays; each is a sequence of
-        time values.
+      time values.
     all_flux: Numpy array or sequence of numpy arrays; each is a sequence of
-        flux values of the corresponding time array.
+      flux values of the corresponding time array.
     events: List of Event objects to remove.
     width_factor: Fractional multiplier of the duration of each event to remove.
     include_empty_segments: Whether to include empty segments in the output.
@@ -136,12 +136,12 @@ def interpolate_missing_time(time, cadence_no=None, fill_value="extrapolate"):
 
   Args:
     time: A numpy array of monotonically increasing values, with missing values
-        denoted by NaN or Inf.
+      denoted by NaN or Inf.
     cadence_no: Optional numpy array of cadence numbers corresponding to the
-        time values. If not provided, missing time values are assumed to be
-        evenly spaced between present time values.
+      time values. If not provided, missing time values are assumed to be evenly
+      spaced between present time values.
     fill_value: Specifies how missing time values should be treated at the
-        beginning and end of the array. See scipy.interpolate.interp1d.
+      beginning and end of the array. See scipy.interpolate.interp1d.
 
   Returns:
     A numpy array of the same length as the input time array, with NaN/Inf
@@ -177,17 +177,17 @@ def interpolate_masked_spline(all_time, all_masked_time, all_masked_spline):
   Args:
     all_time: List of numpy arrays; each is a sequence of time values.
     all_masked_time: List of numpy arrays; each is a sequence of time values
-        with some values missing (masked).
+      with some values missing (masked).
     all_masked_spline: List of numpy arrays; the masked spline values
-        corresponding to all_masked_time.
+      corresponding to all_masked_time.
 
   Returns:
     interp_spline: List of numpy arrays; each is the masked spline with missing
         points linearly interpolated.
   """
   interp_spline = []
-  for time, masked_time, masked_spline in zip(
-      all_time, all_masked_time, all_masked_spline):
+  for time, masked_time, masked_spline in zip(all_time, all_masked_time,
+                                              all_masked_spline):
     if masked_time.size:
       interp_spline.append(np.interp(time, masked_time, masked_spline))
     else:
diff --git a/research/astronet/third_party/kepler_spline/kepler_spline.py b/research/astronet/third_party/kepler_spline/kepler_spline.py
index 67a34712..afddf2c2 100644
--- a/research/astronet/third_party/kepler_spline/kepler_spline.py
+++ b/research/astronet/third_party/kepler_spline/kepler_spline.py
@@ -37,9 +37,9 @@ def kepler_spline(time, flux, bkspace=1.5, maxiter=5, outlier_cut=3):
     flux: Numpy array; the flux (brightness) values of the light curve.
     bkspace: Spline break point spacing in time units.
     maxiter: Maximum number of attempts to fit the spline after removing badly
-        fit points.
+      fit points.
     outlier_cut: The maximum number of standard deviations from the median
-        spline residual before a point is considered an outlier.
+      spline residual before a point is considered an outlier.
 
   Returns:
     spline: The values of the fitted spline corresponding to the input time
@@ -119,15 +119,15 @@ class SplineMetadata(object):
 
   Attributes:
     light_curve_mask: List of boolean numpy arrays indicating which points in
-        the light curve were used to fit the best-fit spline.
+      the light curve were used to fit the best-fit spline.
     bkspace: The break-point spacing used for the best-fit spline.
     bad_bkspaces: List of break-point spacing values that failed.
     likelihood_term: The likelihood term of the Bayesian Information Criterion;
-        -2*ln(L), where L is the likelihood of the data given the model.
-    penalty_term: The penalty term for the number of parameters in the
-        Bayesian Information Criterion.
+      -2*ln(L), where L is the likelihood of the data given the model.
+    penalty_term: The penalty term for the number of parameters in the Bayesian
+      Information Criterion.
     bic: The value of the Bayesian Information Criterion; equal to
-        likelihood_term + penalty_coeff * penalty_term.
+      likelihood_term + penalty_coeff * penalty_term.
   """
 
   def __init__(self):
@@ -163,14 +163,13 @@ def choose_kepler_spline(all_time,
     all_flux: List of 1D numpy arrays; the flux values of the light curve.
     bkspaces: List of break-point spacings to try.
     maxiter: Maximum number of attempts to fit each spline after removing badly
-        fit points.
+      fit points.
     penalty_coeff: Coefficient of the penalty term for using more parameters in
-        the Bayesian Information Criterion. Decreasing this value will allow
-        more parameters to be used (i.e. smaller break-point spacing), and
-        vice-versa.
+      the Bayesian Information Criterion. Decreasing this value will allow more
+      parameters to be used (i.e. smaller break-point spacing), and vice-versa.
     verbose: Whether to log individual spline errors. Note that if bkspaces
-        contains many values (particularly small ones) then this may cause
-        logging pollution if calling this function for many light curves.
+      contains many values (particularly small ones) then this may cause logging
+      pollution if calling this function for many light curves.
 
   Returns:
     spline: List of numpy arrays; values of the best-fit spline corresponding to
@@ -295,14 +294,13 @@ def fit_kepler_spline(all_time,
     bkspace_max: Maximum breakpoint spacing to try.
     bkspace_num: Number of breakpoint spacings to try.
     maxiter: Maximum number of attempts to fit each spline after removing badly
-        fit points.
+      fit points.
     penalty_coeff: Coefficient of the penalty term for using more parameters in
-        the Bayesian Information Criterion. Decreasing this value will allow
-        more parameters to be used (i.e. smaller break-point spacing), and
-        vice-versa.
+      the Bayesian Information Criterion. Decreasing this value will allow more
+      parameters to be used (i.e. smaller break-point spacing), and vice-versa.
     verbose: Whether to log individual spline errors. Note that if bkspaces
-        contains many values (particularly small ones) then this may cause
-        logging pollution if calling this function for many light curves.
+      contains many values (particularly small ones) then this may cause logging
+      pollution if calling this function for many light curves.
 
   Returns:
     spline: List of numpy arrays; values of the best-fit spline corresponding to
diff --git a/research/astronet/third_party/robust_mean/robust_mean.py b/research/astronet/third_party/robust_mean/robust_mean.py
index f6ef93d2..3a1e32a8 100644
--- a/research/astronet/third_party/robust_mean/robust_mean.py
+++ b/research/astronet/third_party/robust_mean/robust_mean.py
@@ -17,7 +17,7 @@ def robust_mean(y, cut):
   Args:
     y: 1D numpy array. Assumed to be normally distributed with outliers.
     cut: Points more than this number of standard deviations from the median are
-        ignored.
+      ignored.
 
   Returns:
     mean: A robust estimate of the mean of y.
