commit 2be9ba5b740e70dad6016470c9ee3e840eb395c6
Author: guptapriya <14104855+guptapriya@users.noreply.github.com>
Date:   Tue May 28 15:19:34 2019 -0700

    Turn dist strat off for 1 GPU benchmarks

diff --git a/official/transformer/v2/transformer_benchmark.py b/official/transformer/v2/transformer_benchmark.py
index a6cbf12d..e4a00210 100644
--- a/official/transformer/v2/transformer_benchmark.py
+++ b/official/transformer/v2/transformer_benchmark.py
@@ -133,6 +133,7 @@ class TransformerBaseKerasAccuracy(TransformerBenchmark):
     """
     self._setup()
     FLAGS.num_gpus = 1
+    FLAGS.distribution_strategy = off
     FLAGS.data_dir = self.train_data_dir
     FLAGS.vocab_file = self.vocab_file
     # Sets values directly to avoid validation check.
@@ -158,6 +159,7 @@ class TransformerBaseKerasAccuracy(TransformerBenchmark):
     """
     self._setup()
     FLAGS.num_gpus = 1
+    FLAGS.distribution_strategy = off
     FLAGS.data_dir = self.train_data_dir
     FLAGS.vocab_file = self.vocab_file
     # Sets values directly to avoid validation check.
@@ -315,6 +317,7 @@ class TransformerKerasBenchmark(TransformerBenchmark):
     """Benchmark 1 gpu."""
     self._setup()
     FLAGS.num_gpus = 1
+    FLAGS.distribution_strategy = off
     FLAGS.batch_size = self.batch_per_gpu
     FLAGS.model_dir = self._get_model_dir('benchmark_1_gpu')
     self._run_and_report_benchmark(total_batch_size=FLAGS.batch_size,
@@ -324,6 +327,7 @@ class TransformerKerasBenchmark(TransformerBenchmark):
     """Benchmark 1 gpu."""
     self._setup()
     FLAGS.num_gpus = 1
+    FLAGS.distribution_strategy = off
     FLAGS.batch_size = self.batch_per_gpu
     FLAGS.model_dir = self._get_model_dir('benchmark_1_gpu_static_batch')
     # TODO(guptapriya): Add max_length
