commit a85c40e36fad0ee3754c1046eb8968e50d22bbf8
Author: Reed Wanderman-Milne <reedwm@google.com>
Date:   Tue Sep 3 19:21:07 2019 -0700

    Unexpose some flags from models which do not use them.
    
    --clean, --train_epochs, and --epochs_between_evals have been unexposed from models which do not use them
    
    PiperOrigin-RevId: 267065651

diff --git a/official/mnist/mnist.py b/official/mnist/mnist.py
index dd6e260a..7af0f678 100644
--- a/official/mnist/mnist.py
+++ b/official/mnist/mnist.py
@@ -88,7 +88,8 @@ def create_model(data_format):
 
 
 def define_mnist_flags():
-  flags_core.define_base()
+  flags_core.define_base(clean=True, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_performance(inter_op=True, intra_op=True,
                                 num_parallel_calls=False,
                                 all_reduce_alg=True)
diff --git a/official/mnist/mnist_eager.py b/official/mnist/mnist_eager.py
index b46df343..6f554ecc 100644
--- a/official/mnist/mnist_eager.py
+++ b/official/mnist/mnist_eager.py
@@ -169,7 +169,7 @@ def run_mnist_eager(flags_obj):
 
 def define_mnist_eager_flags():
   """Defined flags and defaults for MNIST in eager mode."""
-  flags_core.define_base_eager()
+  flags_core.define_base_eager(clean=True, train_epochs=True)
   flags_core.define_image()
   flags.adopt_module_key_flags(flags_core)
 
diff --git a/official/r1/boosted_trees/train_higgs_test.py b/official/r1/boosted_trees/train_higgs_test.py
index 6a4317bf..4e77902d 100644
--- a/official/r1/boosted_trees/train_higgs_test.py
+++ b/official/r1/boosted_trees/train_higgs_test.py
@@ -133,7 +133,7 @@ class BaseTest(tf.test.TestCase):
             "--eval_start", "12",
             "--eval_count", "8",
         ],
-        synth=False)
+        synth=False, train_epochs=None, epochs_between_evals=None)
     self.assertTrue(tf.gfile.Exists(os.path.join(model_dir, "checkpoint")))
 
   @unittest.skipIf(keras_utils.is_v2_0(), "TF 1.0 only test.")
@@ -152,7 +152,7 @@ class BaseTest(tf.test.TestCase):
             "--eval_start", "12",
             "--eval_count", "8",
         ],
-        synth=False)
+        synth=False, train_epochs=None, epochs_between_evals=None)
     self.assertTrue(tf.gfile.Exists(os.path.join(model_dir, "checkpoint")))
     self.assertTrue(tf.gfile.Exists(os.path.join(export_dir)))
 
diff --git a/official/r1/resnet/resnet_run_loop.py b/official/r1/resnet/resnet_run_loop.py
index 480d95ad..91bce96d 100644
--- a/official/r1/resnet/resnet_run_loop.py
+++ b/official/r1/resnet/resnet_run_loop.py
@@ -723,7 +723,8 @@ def resnet_main(
 def define_resnet_flags(resnet_size_choices=None, dynamic_loss_scale=False,
                         fp16_implementation=False):
   """Add flags and validators for ResNet."""
-  flags_core.define_base()
+  flags_core.define_base(clean=True, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_performance(num_parallel_calls=False,
                                 inter_op=True,
                                 intra_op=True,
diff --git a/official/r1/wide_deep/wide_deep_run_loop.py b/official/r1/wide_deep/wide_deep_run_loop.py
index 7bc4c555..6bff3238 100644
--- a/official/r1/wide_deep/wide_deep_run_loop.py
+++ b/official/r1/wide_deep/wide_deep_run_loop.py
@@ -36,7 +36,8 @@ LOSS_PREFIX = {'wide': 'linear/', 'deep': 'dnn/'}
 
 def define_wide_deep_flags():
   """Add supervised learning flags, as well as wide-deep model type."""
-  flags_core.define_base()
+  flags_core.define_base(clean=True, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_benchmark()
   flags_core.define_performance(
       num_parallel_calls=False, inter_op=True, intra_op=True,
diff --git a/official/recommendation/ncf_common.py b/official/recommendation/ncf_common.py
index 3aac5ee2..bb13cfef 100644
--- a/official/recommendation/ncf_common.py
+++ b/official/recommendation/ncf_common.py
@@ -147,7 +147,9 @@ def get_v1_distribution_strategy(params):
 def define_ncf_flags():
   """Add flags for running ncf_main."""
   # Add common flags
-  flags_core.define_base(export_dir=False, run_eagerly=True)
+  flags_core.define_base(clean=True, train_epochs=True,
+                         epochs_between_evals=True, export_dir=False,
+                         run_eagerly=True)
   flags_core.define_performance(
       num_parallel_calls=False,
       inter_op=False,
diff --git a/official/transformer/transformer_main.py b/official/transformer/transformer_main.py
index 8894ae69..5f8e4013 100644
--- a/official/transformer/transformer_main.py
+++ b/official/transformer/transformer_main.py
@@ -394,7 +394,8 @@ def define_transformer_flags():
       name="max_length", short_name="ml", default=None,
       help=flags_core.help_wrap("Max length."))
 
-  flags_core.define_base()
+  flags_core.define_base(clean=True, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_performance(
       num_parallel_calls=True,
       inter_op=False,
diff --git a/official/transformer/v2/misc.py b/official/transformer/v2/misc.py
index 23a4f916..d82eabe2 100644
--- a/official/transformer/v2/misc.py
+++ b/official/transformer/v2/misc.py
@@ -60,7 +60,7 @@ def get_model_params(param_set, num_gpus):
 
 def define_transformer_flags():
   """Add flags and flag validators for running transformer_main."""
-  # Add common flags (data_dir, model_dir, train_epochs, etc.).
+  # Add common flags (data_dir, model_dir, etc.).
   flags_core.define_base()
   flags_core.define_performance(
       num_parallel_calls=True,
@@ -214,18 +214,9 @@ def define_transformer_flags():
 
   flags_core.set_defaults(data_dir='/tmp/translate_ende',
                           model_dir='/tmp/transformer_model',
-                          batch_size=None,
-                          train_epochs=10)
+                          batch_size=None)
 
   # pylint: disable=unused-variable
-  @flags.multi_flags_validator(
-      ['mode', 'train_epochs'],
-      message='--train_epochs must be defined in train mode')
-  def _check_train_limits(flag_dict):
-    if flag_dict['mode'] == 'train':
-      return flag_dict['train_epochs'] is not None
-    return True
-
   @flags.multi_flags_validator(
       ['bleu_source', 'bleu_ref'],
       message='Both or neither --bleu_source and --bleu_ref must be defined.')
diff --git a/official/utils/flags/_base.py b/official/utils/flags/_base.py
index c4fb7353..aabb0f4f 100644
--- a/official/utils/flags/_base.py
+++ b/official/utils/flags/_base.py
@@ -25,9 +25,9 @@ from official.utils.flags._conventions import help_wrap
 from official.utils.logs import hooks_helper
 
 
-def define_base(data_dir=True, model_dir=True, clean=True, train_epochs=True,
-                epochs_between_evals=True, stop_threshold=True, batch_size=True,
-                num_gpu=True, hooks=True, export_dir=True,
+def define_base(data_dir=True, model_dir=True, clean=False, train_epochs=False,
+                epochs_between_evals=False, stop_threshold=True,
+                batch_size=True, num_gpu=True, hooks=True, export_dir=True,
                 distribution_strategy=True, run_eagerly=False):
   """Register base flags.
 
diff --git a/official/utils/flags/core.py b/official/utils/flags/core.py
index 9ca85c6b..82986dee 100644
--- a/official/utils/flags/core.py
+++ b/official/utils/flags/core.py
@@ -72,8 +72,7 @@ def register_key_flags_in_core(f):
 define_base = register_key_flags_in_core(_base.define_base)
 # Remove options not relevant for Eager from define_base().
 define_base_eager = register_key_flags_in_core(functools.partial(
-    _base.define_base, epochs_between_evals=False, stop_threshold=False,
-    hooks=False))
+    _base.define_base, stop_threshold=False, hooks=False))
 define_benchmark = register_key_flags_in_core(_benchmark.define_benchmark)
 define_device = register_key_flags_in_core(_device.define_device)
 define_image = register_key_flags_in_core(_misc.define_image)
diff --git a/official/utils/flags/flags_test.py b/official/utils/flags/flags_test.py
index a2fe2499..78dc4a81 100644
--- a/official/utils/flags/flags_test.py
+++ b/official/utils/flags/flags_test.py
@@ -22,7 +22,8 @@ from official.utils.flags import core as flags_core  # pylint: disable=g-bad-imp
 
 
 def define_flags():
-  flags_core.define_base(num_gpu=False)
+  flags_core.define_base(clean=True, num_gpu=False, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_performance(
       num_parallel_calls=True, inter_op=True,  intra_op=True,
       dynamic_loss_scale=True, loss_scale=True, synthetic_data=True,
diff --git a/official/utils/testing/integration.py b/official/utils/testing/integration.py
index 2760b46a..f95c5cec 100644
--- a/official/utils/testing/integration.py
+++ b/official/utils/testing/integration.py
@@ -29,7 +29,8 @@ from absl import flags
 from official.utils.flags import core as flags_core
 
 
-def run_synthetic(main, tmp_root, extra_flags=None, synth=True):
+def run_synthetic(main, tmp_root, extra_flags=None, synth=True, train_epochs=1,
+                  epochs_between_evals=1):
   """Performs a minimal run of a model.
 
     This function is intended to test for syntax errors throughout a model. A
@@ -41,18 +42,25 @@ def run_synthetic(main, tmp_root, extra_flags=None, synth=True):
     tmp_root: Root path for the temp directory created by the test class.
     extra_flags: Additional flags passed by the caller of this function.
     synth: Use synthetic data.
+    train_epochs: Value of the --train_epochs flag.
+    epochs_between_evals: Value of the --epochs_between_evals flag.
   """
 
   extra_flags = [] if extra_flags is None else extra_flags
 
   model_dir = tempfile.mkdtemp(dir=tmp_root)
 
-  args = [sys.argv[0], "--model_dir", model_dir, "--train_epochs", "1",
-          "--epochs_between_evals", "1"] + extra_flags
+  args = [sys.argv[0], "--model_dir", model_dir] + extra_flags
 
   if synth:
     args.append("--use_synthetic_data")
 
+  if train_epochs is not None:
+    args.extend(["--train_epochs", str(train_epochs)])
+
+  if epochs_between_evals is not None:
+    args.extend(["--epochs_between_evals", str(epochs_between_evals)])
+
   try:
     flags_core.parse_flags(argv=args)
     main(flags.FLAGS)
diff --git a/official/vision/image_classification/common.py b/official/vision/image_classification/common.py
index e4b7a76a..9b9319e7 100644
--- a/official/vision/image_classification/common.py
+++ b/official/vision/image_classification/common.py
@@ -283,7 +283,8 @@ def build_stats(history, eval_output, callbacks):
 
 def define_keras_flags(dynamic_loss_scale=True):
   """Define flags for Keras models."""
-  flags_core.define_base(run_eagerly=True)
+  flags_core.define_base(clean=True, run_eagerly=True, train_epochs=True,
+                         epochs_between_evals=True)
   flags_core.define_performance(num_parallel_calls=False,
                                 synthetic_data=True,
                                 dtype=True,
