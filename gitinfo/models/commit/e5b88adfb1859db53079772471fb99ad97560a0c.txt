commit e5b88adfb1859db53079772471fb99ad97560a0c
Author: Mark Daoust <markdaoust@google.com>
Date:   Mon Jul 9 11:05:47 2018 -0700

    typo

diff --git a/samples/core/tutorials/eager/custom_training_walkthrough.ipynb b/samples/core/tutorials/eager/custom_training_walkthrough.ipynb
index 54a6433e..8de9c666 100644
--- a/samples/core/tutorials/eager/custom_training_walkthrough.ipynb
+++ b/samples/core/tutorials/eager/custom_training_walkthrough.ipynb
@@ -345,7 +345,7 @@
         "TensorFlow's [Dataset API](https://www.tensorflow.org/guide/datasets) handles many common cases for loading data into a model. This is a high-level API for reading data and transforming it into a form used for training. See the [Datasets Quick Start guide](https://www.tensorflow.org/get_started/datasets_quickstart) for more information.\n",
         "\n",
         "\n",
-        "Since the dataset is a CSV-formatted text file, use the the [make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) function to parse the data into a suitable format. Since this function generates data for training models, the default behavior is to shuffle the data (`shuffle=True, shuffle_buffer_size=10000`), and repeat the dataset forever (`num_epochs=None`). We also set the [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size) parameter."
+        "Since the dataset is a CSV-formatted text file, use the [make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) function to parse the data into a suitable format. Since this function generates data for training models, the default behavior is to shuffle the data (`shuffle=True, shuffle_buffer_size=10000`), and repeat the dataset forever (`num_epochs=None`). We also set the [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size) parameter."
       ]
     },
     {
