commit f6e4dfe995d28ea96dcc304ea548d675865e03f3
Author: Igor Ganichev <iga@google.com>
Date:   Tue Apr 10 21:42:32 2018 -0700

    Fix order of variable update and moving average update
    
    While the original code works fine in practice, it technically
    allows gradient application and moving average update to happen
    in any order. This causes the behavior to deviate from pure
    mathematical specifications.

diff --git a/tutorials/image/cifar10/cifar10.py b/tutorials/image/cifar10/cifar10.py
index 8fc63ffc..018e2f26 100644
--- a/tutorials/image/cifar10/cifar10.py
+++ b/tutorials/image/cifar10/cifar10.py
@@ -370,12 +370,10 @@ def train(total_loss, global_step):
   # Track the moving averages of all trainable variables.
   variable_averages = tf.train.ExponentialMovingAverage(
       MOVING_AVERAGE_DECAY, global_step)
-  variables_averages_op = variable_averages.apply(tf.trainable_variables())
+  with tf.control_dependencies([apply_gradient_op]):
+    variables_averages_op = variable_averages.apply(tf.trainable_variables())
 
-  with tf.control_dependencies([apply_gradient_op, variables_averages_op]):
-    train_op = tf.no_op(name='train')
-
-  return train_op
+  return variables_averages_op
 
 
 def maybe_download_and_extract():
