commit 477ed41e7e4e8a8443bc633846eb01e2182dc68a
Author: Jonathan Huang <jonathanhuang@google.com>
Date:   Tue Jun 20 16:14:33 2017 -0700

    Replace Oxford-IIT by Oxford-IIIT. (#1708)

diff --git a/object_detection/g3doc/preparing_inputs.md b/object_detection/g3doc/preparing_inputs.md
index a1f8f17e..77ba7f39 100644
--- a/object_detection/g3doc/preparing_inputs.md
+++ b/object_detection/g3doc/preparing_inputs.md
@@ -2,7 +2,7 @@
 
 Tensorflow Object Detection API reads data using the TFRecord file format. Two
 sample scripts (`create_pascal_tf_record.py` and `create_pet_tf_record.py`) are
-provided to convert from the PASCAL VOC dataset and Oxford-IIT Pet dataset to
+provided to convert from the PASCAL VOC dataset and Oxford-IIIT Pet dataset to
 TFRecords.
 
 ## Generating the PASCAL VOC TFRecord files.
@@ -26,9 +26,9 @@ pascal_val.record in the tensorflow/models/object_detection directory.
 The label map for the PASCAL VOC data set can be found at
 data/pascal_label_map.pbtxt.
 
-## Generation the Oxford-IIT Pet TFRecord files.
+## Generation the Oxford-IIIT Pet TFRecord files.
 
-The Oxford-IIT Pet data set can be downloaded from
+The Oxford-IIIT Pet data set can be downloaded from
 [their website](http://www.robots.ox.ac.uk/~vgg/data/pets/). Extract the tar
 file and run the `create_pet_tf_record` script to generate TFRecords.
 
diff --git a/object_detection/g3doc/running_locally.md b/object_detection/g3doc/running_locally.md
index 7143b6d8..dd53225b 100644
--- a/object_detection/g3doc/running_locally.md
+++ b/object_detection/g3doc/running_locally.md
@@ -10,7 +10,7 @@ dependencies, compiling the configuration protobufs and setting up the Python
 environment.
 2. A valid data set has been created. See [this page](preparing_inputs.md) for
 instructions on how to generate a dataset for the PASCAL VOC challenge or the
-Oxford-IIT Pet dataset.
+Oxford-IIIT Pet dataset.
 3. A Object Detection pipeline configuration has been written. See
 [this page](configuring_jobs.md) for details on how to write a pipeline configuration.
 
diff --git a/object_detection/g3doc/running_on_cloud.md b/object_detection/g3doc/running_on_cloud.md
index 0d74ac4e..b96725ea 100644
--- a/object_detection/g3doc/running_on_cloud.md
+++ b/object_detection/g3doc/running_on_cloud.md
@@ -11,7 +11,7 @@ See [the Cloud ML quick start guide](https://cloud.google.com/ml-engine/docs/qui
 in the [installation instructions](installation.md).
 3. The reader has a valid data set and stored it in a Google Cloud Storage
 bucket. See [this page](preparing_inputs.md) for instructions on how to generate
-a dataset for the PASCAL VOC challenge or the Oxford-IIT Pet dataset.
+a dataset for the PASCAL VOC challenge or the Oxford-IIIT Pet dataset.
 4. The reader has configured a valid Object Detection pipeline, and stored it
 in a Google Cloud Storage bucket. See [this page](configuring_jobs.md) for
 details on how to write a pipeline configuration.
diff --git a/object_detection/g3doc/running_pets.md b/object_detection/g3doc/running_pets.md
index 08fe34eb..eae858af 100644
--- a/object_detection/g3doc/running_pets.md
+++ b/object_detection/g3doc/running_pets.md
@@ -1,7 +1,7 @@
-# Quick Start: Distributed Training on the Oxford-IIT Pets Dataset on Google Cloud
+# Quick Start: Distributed Training on the Oxford-IIIT Pets Dataset on Google Cloud
 
 This page is a walkthrough for training an object detector using the Tensorflow
-Object Detection API. In this tutorial, we'll be training on the Oxford-IIT Pets
+Object Detection API. In this tutorial, we'll be training on the Oxford-IIIT Pets
 dataset to build a system to detect various breeds of cats and dogs. The output
 of the detector will look like the following:
 
@@ -43,11 +43,11 @@ Please run through the [installation instructions](installation.md) to install
 Tensorflow and all it dependencies. Ensure the Protobuf libraries are
 compiled and the library directories are added to `PYTHONPATH`.
 
-## Getting the Oxford-IIT Pets Dataset and Uploading it to Google Cloud Storage
+## Getting the Oxford-IIIT Pets Dataset and Uploading it to Google Cloud Storage
 
 In order to train a detector, we require a dataset of images, bounding boxes and
-classifications. For this demo, we'll use the Oxford-IIT Pets dataset. The raw
-dataset for Oxford-IIT Pets lives
+classifications. For this demo, we'll use the Oxford-IIIT Pets dataset. The raw
+dataset for Oxford-IIIT Pets lives
 [here](http://www.robots.ox.ac.uk/~vgg/data/pets/). You will need to download
 both the image dataset [`images.tar.gz`](http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz)
 and the groundtruth data [`annotations.tar.gz`](http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz)
@@ -65,7 +65,7 @@ the tarballs, your object_detection directory should appear as follows:
 
 The Tensorflow Object Detection API expects data to be in the TFRecord format,
 so we'll now run the _create_pet_tf_record_ script to convert from the raw
-Oxford-IIT Pet dataset into TFRecords. Run the following commands from the
+Oxford-IIIT Pet dataset into TFRecords. Run the following commands from the
 object_detection directory:
 
 ``` bash
diff --git a/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config b/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config
index a0913337..fc7e14e2 100644
--- a/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config
+++ b/object_detection/samples/configs/faster_rcnn_inception_resnet_v2_atrous_pets.config
@@ -1,5 +1,5 @@
 # Faster R-CNN with Inception Resnet v2, Atrous version;
-# Configured for Oxford-IIT Pets Dataset.
+# Configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/faster_rcnn_resnet101_pets.config b/object_detection/samples/configs/faster_rcnn_resnet101_pets.config
index b90304c2..cee6604a 100644
--- a/object_detection/samples/configs/faster_rcnn_resnet101_pets.config
+++ b/object_detection/samples/configs/faster_rcnn_resnet101_pets.config
@@ -1,4 +1,4 @@
-# Faster R-CNN with Resnet-101 (v1) configured for the Oxford-IIT Pet Dataset.
+# Faster R-CNN with Resnet-101 (v1) configured for the Oxford-IIIT Pet Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/faster_rcnn_resnet152_pets.config b/object_detection/samples/configs/faster_rcnn_resnet152_pets.config
index 128380b9..aae28489 100644
--- a/object_detection/samples/configs/faster_rcnn_resnet152_pets.config
+++ b/object_detection/samples/configs/faster_rcnn_resnet152_pets.config
@@ -1,4 +1,4 @@
-# Faster R-CNN with Resnet-152 (v1), configured for Oxford-IIT Pets Dataset.
+# Faster R-CNN with Resnet-152 (v1), configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/faster_rcnn_resnet50_pets.config b/object_detection/samples/configs/faster_rcnn_resnet50_pets.config
index 5e929301..110c1b4b 100644
--- a/object_detection/samples/configs/faster_rcnn_resnet50_pets.config
+++ b/object_detection/samples/configs/faster_rcnn_resnet50_pets.config
@@ -1,4 +1,4 @@
-# Faster R-CNN with Resnet-50 (v1), configured for Oxford-IIT Pets Dataset.
+# Faster R-CNN with Resnet-50 (v1), configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/rfcn_resnet101_pets.config b/object_detection/samples/configs/rfcn_resnet101_pets.config
index 2b9df17e..a2b88f9d 100644
--- a/object_detection/samples/configs/rfcn_resnet101_pets.config
+++ b/object_detection/samples/configs/rfcn_resnet101_pets.config
@@ -1,4 +1,4 @@
-# R-FCN with Resnet-101 (v1),  configured for Oxford-IIT Pets Dataset.
+# R-FCN with Resnet-101 (v1),  configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/ssd_inception_v2_pets.config b/object_detection/samples/configs/ssd_inception_v2_pets.config
index 49bdf7e0..b14fa480 100644
--- a/object_detection/samples/configs/ssd_inception_v2_pets.config
+++ b/object_detection/samples/configs/ssd_inception_v2_pets.config
@@ -1,4 +1,4 @@
-# SSD with Inception v2 configured for Oxford-IIT Pets Dataset.
+# SSD with Inception v2 configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
diff --git a/object_detection/samples/configs/ssd_mobilenet_v1_pets.config b/object_detection/samples/configs/ssd_mobilenet_v1_pets.config
index c8d83ddb..429075c6 100644
--- a/object_detection/samples/configs/ssd_mobilenet_v1_pets.config
+++ b/object_detection/samples/configs/ssd_mobilenet_v1_pets.config
@@ -1,4 +1,4 @@
-# SSD with Mobilenet v1, configured for Oxford-IIT Pets Dataset.
+# SSD with Mobilenet v1, configured for Oxford-IIIT Pets Dataset.
 # Users should configure the fine_tune_checkpoint field in the train config as
 # well as the label_map_path and input_path fields in the train_input_reader and
 # eval_input_reader. Search for "PATH_TO_BE_CONFIGURED" to find the fields that
