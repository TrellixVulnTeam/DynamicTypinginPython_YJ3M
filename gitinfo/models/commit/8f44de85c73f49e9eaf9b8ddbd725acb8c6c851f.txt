commit 8f44de85c73f49e9eaf9b8ddbd725acb8c6c851f
Author: guptapriya <priyag@google.com>
Date:   Tue Jun 11 20:49:23 2019 +0000

    Add more tests and benchmarks to cover no dist strat and ctl cases

diff --git a/official/recommendation/ncf_keras_benchmark.py b/official/recommendation/ncf_keras_benchmark.py
index 0ca009ab..9fef8d4c 100644
--- a/official/recommendation/ncf_keras_benchmark.py
+++ b/official/recommendation/ncf_keras_benchmark.py
@@ -121,6 +121,12 @@ class KerasNCFRealData(KerasNCFBenchmarkBase):
     self._setup()
     self._run_and_report_benchmark()
 
+  def benchmark_1_gpu_no_dist_strat_early_stop(self):
+    self._setup()
+    FLAGS.distribution_strategy = 'off'
+    FLAGS.early_stopping = True
+    self._run_and_report_benchmark()
+
   def benchmark_1_gpu_early_stop(self):
     self._setup()
     FLAGS.early_stopping = True
diff --git a/official/recommendation/ncf_test.py b/official/recommendation/ncf_test.py
index ded55653..a944433a 100644
--- a/official/recommendation/ncf_test.py
+++ b/official/recommendation/ncf_test.py
@@ -201,22 +201,29 @@ class NcfTest(tf.test.TestCase):
         extra_flags=self._BASE_END_TO_END_FLAGS + ['-ml_perf', 'True'])
 
   @mock.patch.object(rconst, "SYNTHETIC_BATCHES_PER_EPOCH", 100)
-  def test_end_to_end_keras(self):
+  def test_end_to_end_keras_no_dist_strat(self):
     integration.run_synthetic(
         ncf_keras_main.main, tmp_root=self.get_temp_dir(), max_train=None,
         extra_flags=self._BASE_END_TO_END_FLAGS +
         ['-distribution_strategy', 'off'])
 
   @mock.patch.object(rconst, "SYNTHETIC_BATCHES_PER_EPOCH", 100)
-  def test_end_to_end_keras_mlperf(self):
+  def test_end_to_end_keras_dist_strat(self):
     integration.run_synthetic(
         ncf_keras_main.main, tmp_root=self.get_temp_dir(), max_train=None,
-        extra_flags=self._BASE_END_TO_END_FLAGS +
-        ['-ml_perf', 'True',
-         '-distribution_strategy', 'off'])
+        extra_flags=self._BASE_END_TO_END_FLAGS + ['-num_gpus', '0'])
+
+  @mock.patch.object(rconst, "SYNTHETIC_BATCHES_PER_EPOCH", 100)
+  def test_end_to_end_keras_dist_strat_ctl(self):
+    flags = (self._BASE_END_TO_END_FLAGS +
+             ['-num_gpus', '0'] +
+             ['-keras_use_ctl', 'True'])
+    integration.run_synthetic(
+        ncf_keras_main.main, tmp_root=self.get_temp_dir(), max_train=None,
+        extra_flags=self._BASE_END_TO_END_FLAGS + ['-num_gpus', '0'])
 
   @mock.patch.object(rconst, "SYNTHETIC_BATCHES_PER_EPOCH", 100)
-  def test_end_to_end_keras_1_gpu(self):
+  def test_end_to_end_keras_1_gpu_dist_strat(self):
     if context.num_gpus() < 1:
       self.skipTest(
           "{} GPUs are not available for this test. {} GPUs are available".
