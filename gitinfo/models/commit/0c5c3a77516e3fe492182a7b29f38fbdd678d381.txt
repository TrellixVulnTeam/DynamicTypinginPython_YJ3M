commit 0c5c3a77516e3fe492182a7b29f38fbdd678d381
Author: shizhiw <34991981+shizhiw@users.noreply.github.com>
Date:   Fri Oct 12 20:57:59 2018 -0700

    Replace multiprocess pool with popen_helper.get_pool() in data_preprocessing. (#5512)
    
    * Use data_dir instead of flags.FLAGS.data_dir in data_preprocessing.py.
    
    * Use data_dir instead of flags.FLAGS.data_dir in data_preprocessing.py.
    
    * Replace multiprocess pool with popen_helper.get_pool() in data_preprocessing.

diff --git a/official/recommendation/data_preprocessing.py b/official/recommendation/data_preprocessing.py
index 84cbeaf6..d6819eec 100644
--- a/official/recommendation/data_preprocessing.py
+++ b/official/recommendation/data_preprocessing.py
@@ -333,8 +333,7 @@ def generate_train_eval_data(df, approx_num_shards, num_items, cache_paths,
   map_args = [(shards[i], i, num_items, cache_paths, process_seeds[i],
                match_mlperf)
               for i in range(approx_num_shards)]
-  with contextlib.closing(
-      multiprocessing.Pool(multiprocessing.cpu_count())) as pool:
+  with popen_helper.get_pool(multiprocessing.cpu_count()) as pool:
     test_shards = pool.map(_train_eval_map_fn, map_args)  # pylint: disable=no-member
 
   tf.logging.info("Merging test shards...")
