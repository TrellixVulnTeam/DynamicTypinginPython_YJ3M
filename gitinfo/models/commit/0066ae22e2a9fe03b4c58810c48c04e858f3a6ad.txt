commit 0066ae22e2a9fe03b4c58810c48c04e858f3a6ad
Author: Hongkun Yu <hongkuny@google.com>
Date:   Wed Mar 4 11:57:45 2020 -0800

    Creates a models folder to host all keras.Model end points.
    
    PiperOrigin-RevId: 298905114

diff --git a/official/nlp/bert/bert_models.py b/official/nlp/bert/bert_models.py
index 2a5d923d..8c8909d0 100644
--- a/official/nlp/bert/bert_models.py
+++ b/official/nlp/bert/bert_models.py
@@ -25,10 +25,8 @@ from official.modeling import tf_utils
 from official.nlp.albert import configs as albert_configs
 from official.nlp.bert import configs
 from official.nlp.modeling import losses
+from official.nlp.modeling import models
 from official.nlp.modeling import networks
-from official.nlp.modeling.networks import bert_classifier
-from official.nlp.modeling.networks import bert_pretrainer
-from official.nlp.modeling.networks import bert_span_labeler
 
 
 class BertPretrainLossAndMetricLayer(tf.keras.layers.Layer):
@@ -159,7 +157,7 @@ def pretrain_model(bert_config,
   if initializer is None:
     initializer = tf.keras.initializers.TruncatedNormal(
         stddev=bert_config.initializer_range)
-  pretrainer_model = bert_pretrainer.BertPretrainer(
+  pretrainer_model = models.BertPretrainer(
       network=transformer_encoder,
       num_classes=2,  # The next sentence prediction label has two classes.
       num_token_predictions=max_predictions_per_seq,
@@ -211,7 +209,7 @@ def squad_model(bert_config,
         stddev=bert_config.initializer_range)
   if not hub_module_url:
     bert_encoder = get_transformer_encoder(bert_config, max_seq_length)
-    return bert_span_labeler.BertSpanLabeler(
+    return models.BertSpanLabeler(
         network=bert_encoder, initializer=initializer), bert_encoder
 
   input_word_ids = tf.keras.layers.Input(
@@ -231,7 +229,7 @@ def squad_model(bert_config,
       },
       outputs=[sequence_output, pooled_output],
       name='core_model')
-  return bert_span_labeler.BertSpanLabeler(
+  return models.BertSpanLabeler(
       network=bert_encoder, initializer=initializer), bert_encoder
 
 
@@ -268,7 +266,7 @@ def classifier_model(bert_config,
 
   if not hub_module_url:
     bert_encoder = get_transformer_encoder(bert_config, max_seq_length)
-    return bert_classifier.BertClassifier(
+    return models.BertClassifier(
         bert_encoder,
         num_classes=num_labels,
         dropout_rate=bert_config.hidden_dropout_prob,
diff --git a/official/nlp/modeling/models/__init__.py b/official/nlp/modeling/models/__init__.py
new file mode 100644
index 00000000..dfcbc1d8
--- /dev/null
+++ b/official/nlp/modeling/models/__init__.py
@@ -0,0 +1,18 @@
+# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+"""Models package definition."""
+from official.nlp.modeling.models.bert_classifier import BertClassifier
+from official.nlp.modeling.models.bert_pretrainer import BertPretrainer
+from official.nlp.modeling.models.bert_span_labeler import BertSpanLabeler
diff --git a/official/nlp/modeling/networks/bert_classifier.py b/official/nlp/modeling/models/bert_classifier.py
similarity index 100%
rename from official/nlp/modeling/networks/bert_classifier.py
rename to official/nlp/modeling/models/bert_classifier.py
diff --git a/official/nlp/modeling/networks/bert_classifier_test.py b/official/nlp/modeling/models/bert_classifier_test.py
similarity index 98%
rename from official/nlp/modeling/networks/bert_classifier_test.py
rename to official/nlp/modeling/models/bert_classifier_test.py
index f3a880a8..085c2f78 100644
--- a/official/nlp/modeling/networks/bert_classifier_test.py
+++ b/official/nlp/modeling/models/bert_classifier_test.py
@@ -22,7 +22,7 @@ import tensorflow as tf
 
 from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
-from official.nlp.modeling.networks import bert_classifier
+from official.nlp.modeling.models import bert_classifier
 
 
 # This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
diff --git a/official/nlp/modeling/networks/bert_pretrainer.py b/official/nlp/modeling/models/bert_pretrainer.py
similarity index 100%
rename from official/nlp/modeling/networks/bert_pretrainer.py
rename to official/nlp/modeling/models/bert_pretrainer.py
diff --git a/official/nlp/modeling/networks/bert_pretrainer_test.py b/official/nlp/modeling/models/bert_pretrainer_test.py
similarity index 98%
rename from official/nlp/modeling/networks/bert_pretrainer_test.py
rename to official/nlp/modeling/models/bert_pretrainer_test.py
index f4f91f0d..587c2b07 100644
--- a/official/nlp/modeling/networks/bert_pretrainer_test.py
+++ b/official/nlp/modeling/models/bert_pretrainer_test.py
@@ -22,7 +22,7 @@ import tensorflow as tf
 
 from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
-from official.nlp.modeling.networks import bert_pretrainer
+from official.nlp.modeling.models import bert_pretrainer
 
 
 # This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
diff --git a/official/nlp/modeling/networks/bert_span_labeler.py b/official/nlp/modeling/models/bert_span_labeler.py
similarity index 100%
rename from official/nlp/modeling/networks/bert_span_labeler.py
rename to official/nlp/modeling/models/bert_span_labeler.py
diff --git a/official/nlp/modeling/networks/bert_span_labeler_test.py b/official/nlp/modeling/models/bert_span_labeler_test.py
similarity index 98%
rename from official/nlp/modeling/networks/bert_span_labeler_test.py
rename to official/nlp/modeling/models/bert_span_labeler_test.py
index c761a655..d05e91b5 100644
--- a/official/nlp/modeling/networks/bert_span_labeler_test.py
+++ b/official/nlp/modeling/models/bert_span_labeler_test.py
@@ -22,7 +22,7 @@ import tensorflow as tf
 
 from tensorflow.python.keras import keras_parameterized  # pylint: disable=g-direct-tensorflow-import
 from official.nlp.modeling import networks
-from official.nlp.modeling.networks import bert_span_labeler
+from official.nlp.modeling.models import bert_span_labeler
 
 
 # This decorator runs the test in V1, V2-Eager, and V2-Functional mode. It
