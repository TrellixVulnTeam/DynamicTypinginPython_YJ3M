commit 4a9987432932b44b09cac9325dc5f160e26e11fb
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Fri Apr 3 09:27:44 2020 -0700

    Update readme: Mask-RCNN
    
    PiperOrigin-RevId: 304631147

diff --git a/official/README-TPU.md b/official/README-TPU.md
index 17df3172..8a54f953 100644
--- a/official/README-TPU.md
+++ b/official/README-TPU.md
@@ -1,11 +1,11 @@
-# Offically Supported TensorFlow 2.1 Models on Cloud TPU
+# Offically Supported TensorFlow 2.1+ Models on Cloud TPU
 
 ## Natural Language Processing
 
 *   [bert](nlp/bert): A powerful pre-trained language representation model:
     BERT, which stands for Bidirectional Encoder Representations from
     Transformers.
-    [BERT FineTuning with Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/bert-2.x) provides step by step instructions on Cloud TPU training. You can look [Bert MNLI Tensorboard.dev metrics](https://tensorboard.dev/experiment/mIah5lppTASvrHqWrdr6NA) for MNLI fine tuning task.
+    [BERT FineTuning with Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/bert-2.x) provides step by step instructions on Cloud TPU training. You can look [Bert MNLI Tensorboard.dev metrics](https://tensorboard.dev/experiment/LijZ1IrERxKALQfr76gndA) for MNLI fine tuning task.
 *   [transformer](nlp/transformer): A transformer model to translate the WMT
     English to German dataset.
         [Training transformer on Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/transformer-2.x) for step by step instructions on Cloud TPU training.
@@ -18,6 +18,7 @@
     See [Tensorboard.dev training metrics](https://tensorboard.dev/experiment/KnaWjrq5TXGfv0NW5m7rpg/#scalars).
 *   [mnist](vision/image_classification): A basic model to classify digits
     from the MNIST dataset. See [Running MNIST on Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/mnist-2.x) tutorial and [Tensorboard.dev metrics](https://tensorboard.dev/experiment/mIah5lppTASvrHqWrdr6NA).
+*   [mask-rcnn](vision/detection): An object detection and instance segmentation model. See [Tensorboard.dev training metrics](https://tensorboard.dev/experiment/LH7k0fMsRwqUAcE09o9kPA).
 *   [resnet](vision/image_classification): A deep residual network that can
     be used to classify ImageNet's dataset of 1000 classes.
     See [Training ResNet on Cloud TPU](https://cloud.google.com/tpu/docs/tutorials/resnet-2.x) tutorial and [Tensorboard.dev metrics](https://tensorboard.dev/experiment/CxlDK8YMRrSpYEGtBRpOhg).
diff --git a/official/README.md b/official/README.md
index 6df3f0d4..778c71ad 100644
--- a/official/README.md
+++ b/official/README.md
@@ -29,6 +29,7 @@ with the same or improved speed and performance with each new TensorFlow build.
 | [MNIST](vision/image_classification) | A basic model to classify digits from the MNIST dataset | [Link](http://yann.lecun.com/exdb/mnist/) |
 | [ResNet](vision/image_classification) | A deep residual network for image recognition | [arXiv:1512.03385](https://arxiv.org/abs/1512.03385) |
 | [RetinaNet](vision/detection) | A fast and powerful object detector | [arXiv:1708.02002](https://arxiv.org/abs/1708.02002) |
+| [Mask-RCNN](vision/detection) | An object detection and instance segmentation model | [arXiv:1703.06870](https://arxiv.org/abs/1703.06870) |
 
 ### Other models
 
diff --git a/official/vision/detection/README.md b/official/vision/detection/README.md
index bed728de..bf06aae1 100644
--- a/official/vision/detection/README.md
+++ b/official/vision/detection/README.md
@@ -1,23 +1,22 @@
-# Object Detection Models on TensorFlow 2.0
+# Object Detection Models on TensorFlow 2
 
 **Note**: The repo is still under construction. More features and instructions
 will be added soon.
 
 ## Prerequsite
-To get started, make sure to use Tensorflow 2.1+ on Google Cloud. Also here are
-a few package you need to install to get started:
+To get started, download the code from TensorFlow models github repository or
+use the pre-installed Google Cloud VM.
 
 ```bash
-sudo apt-get install -y python-tk && \
-pip install Cython matplotlib opencv-python-headless pyyaml Pillow && \
-pip install 'git+https://github.com/cocodataset/cocoapi#egg=pycocotools&subdirectory=PythonAPI'
+git clone https://github.com/tensorflow/models.git
 ```
 
-Next, download the code from TensorFlow models github repository or use the
-pre-installed Google Cloud VM.
+Next, make sure to use Tensorflow 2.1+ on Google Cloud. Also here are
+a few package you need to install to get started:
 
 ```bash
-git clone https://github.com/tensorflow/models.git
+sudo apt-get install -y python-tk && \
+pip3 install -r ~/models/official/requirements.txt
 ```
 
 ## Train RetinaNet on TPU
@@ -30,7 +29,7 @@ RESNET_CHECKPOINT="<path to the pre-trained Resnet-50 checkpoint>"
 TRAIN_FILE_PATTERN="<path to the TFRecord training data>"
 EVAL_FILE_PATTERN="<path to the TFRecord validation data>"
 VAL_JSON_FILE="<path to the validation annotation JSON file>"
-python ~/models/official/vision/detection/main.py \
+python3 ~/models/official/vision/detection/main.py \
   --strategy_type=tpu \
   --tpu="${TPU_NAME?}" \
   --model_dir="${MODEL_DIR?}" \
@@ -60,7 +59,7 @@ following command.
 ```bash
 TPU_NAME="<your GCP TPU name>"
 MODEL_DIR="<path to the directory to store model files>"
-python ~/models/official/vision/detection/main.py \
+python3 ~/models/official/vision/detection/main.py \
   --strategy_type=tpu \
   --tpu="${TPU_NAME?}" \
   --model_dir="${MODEL_DIR?}" \
@@ -123,6 +122,116 @@ use_tpu: False
 "
 ```
 
+## Train Mask-RCNN on TPU
+### Train a vanilla ResNet-50 based Mask-RCNN.
+
+```bash
+TPU_NAME="<your GCP TPU name>"
+MODEL_DIR="<path to the directory to store model files>"
+RESNET_CHECKPOINT="<path to the pre-trained Resnet-50 checkpoint>"
+TRAIN_FILE_PATTERN="<path to the TFRecord training data>"
+EVAL_FILE_PATTERN="<path to the TFRecord validation data>"
+VAL_JSON_FILE="<path to the validation annotation JSON file>"
+python3 ~/models/official/vision/detection/main.py \
+  --strategy_type=tpu \
+  --tpu=${TPU_NAME} \
+  --model_dir=${MODEL_DIR} \
+  --mode=train \
+  --model=mask_rcnn \
+  --params_override="{train: { checkpoint: { path: ${RESNET_CHECKPOINT}, prefix: resnet50/ }, train_file_pattern: ${TRAIN_FILE_PATTERN} }, eval: { val_json_file: ${VAL_JSON_FILE}, eval_file_pattern: ${EVAL_FILE_PATTERN} } }"
+```
+
+### Train a custom Mask-RCNN using the config file.
+
+First, create a YAML config file, e.g. *my_maskrcnn.yaml*. This file specifies
+the parameters to be overridden, which should at least include the following
+fields.
+
+```YAML
+# my_maskrcnn.yaml
+train:
+  train_file_pattern: <path to the TFRecord training data>
+eval:
+  eval_file_pattern: <path to the TFRecord validation data>
+  val_json_file: <path to the validation annotation JSON file>
+```
+
+Once the YAML config file is created, you can launch the training using the
+following command.
+
+```bash
+TPU_NAME="<your GCP TPU name>"
+MODEL_DIR="<path to the directory to store model files>"
+python3 ~/models/official/vision/detection/main.py \
+  --strategy_type=tpu \
+  --tpu=${TPU_NAME} \
+  --model_dir=${MODEL_DIR} \
+  --mode=train \
+  --model=mask_rcnn \
+  --config_file="my_maskrcnn.yaml"
+```
+
+## Train Mask-RCNN on GPU
+
+Training on GPU is similar to that on TPU. The major change is the strategy type
+(use
+"[mirrored](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy)"
+for multiple GPU and
+"[one_device](https://www.tensorflow.org/api_docs/python/tf/distribute/OneDeviceStrategy)"
+for single GPU).
+
+Multi-GPUs example (assuming there are 8GPU connected to the host):
+
+```bash
+MODEL_DIR="<path to the directory to store model files>"
+python3 ~/models/official/vision/detection/main.py \
+  --strategy_type=mirrored \
+  --num_gpus=8 \
+  --model_dir=${MODEL_DIR} \
+  --mode=train \
+  --model=mask_rcnn \
+  --config_file="my_maskrcnn.yaml"
+```
+
+
+```bash
+MODEL_DIR="<path to the directory to store model files>"
+python3 ~/models/official/vision/detection/main.py \
+  --strategy_type=one_device \
+  --num_gpus=1 \
+  --model_dir=${MODEL_DIR} \
+  --mode=train \
+  --model=mask_rcnn \
+  --config_file="my_maskrcnn.yaml"
+```
+
+An example with inline configuration (YAML or JSON format):
+
+```
+python3 ~/models/official/vision/detection/main.py \
+  --model_dir=<model folder> \
+  --strategy_type=one_device \
+  --num_gpus=1 \
+  --mode=train \
+  --model=mask_rcnn \
+  --params_override="eval:
+ eval_file_pattern: <Eval TFRecord file pattern>
+ batch_size: 8
+ val_json_file: <COCO format groundtruth JSON file>
+predict:
+ predict_batch_size: 8
+architecture:
+ use_bfloat16: False
+maskrcnn_parser:
+ use_bfloat16: Flase
+train:
+ total_steps: 1000
+ batch_size: 8
+ train_file_pattern: <Eval TFRecord file pattern>
+use_tpu: False
+"
+```
+
 Note: The JSON groundtruth file is useful for [COCO dataset](http://cocodataset.org/#home) and can be
 downloaded from the [COCO website](http://cocodataset.org/#download). For custom dataset, it is unncessary because the groundtruth can be included in the TFRecord files.
 
