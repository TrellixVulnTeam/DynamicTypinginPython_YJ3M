commit f0d07563408e04bc870c2aec897dbd694566ab87
Author: Carlos Riquelme <rikel@google.com>
Date:   Mon Jul 23 13:25:11 2018 -0700

    Readme changes.

diff --git a/research/deep_contextual_bandits/README.md b/research/deep_contextual_bandits/README.md
index c5589d6e..36820ce3 100644
--- a/research/deep_contextual_bandits/README.md
+++ b/research/deep_contextual_bandits/README.md
@@ -41,7 +41,7 @@ the process if we use algorithm **A** is as follows:
 
 ```
 At time t = 1, ..., T:
-  1. Observe new context: X<sub>t</sub>
+  1. Observe new context: X_t
   2. Choose action: a_t = A.action(X_t)
   3. Observe reward: r_t
   4. Update internal state of the algorithm: A.update((X_t, a_t, r_t))
