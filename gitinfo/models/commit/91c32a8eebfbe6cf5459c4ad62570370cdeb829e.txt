commit 91c32a8eebfbe6cf5459c4ad62570370cdeb829e
Author: Mark Daoust <markdaoust@google.com>
Date:   Sun May 13 04:44:24 2018 -0700

    Fixes for eager.ipynb
    
    Set private_outputs (so output is not recorded on save).

diff --git a/samples/core/get_started/eager.ipynb b/samples/core/get_started/eager.ipynb
index ef1588f9..c51a36d1 100644
--- a/samples/core/get_started/eager.ipynb
+++ b/samples/core/get_started/eager.ipynb
@@ -5,12 +5,9 @@
     "colab": {
       "name": "eager.ipynb",
       "version": "0.3.2",
-      "views": {},
-      "default_view": {},
       "provenance": [],
-      "collapsed_sections": [
-        "rwxGnsA92emp"
-      ],
+      "private_outputs": true,
+      "collapsed_sections": [],
       "toc_visible": true
     },
     "kernelspec": {
@@ -35,13 +32,7 @@
       "metadata": {
         "id": "CPII1rGR2rF9",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        },
-        "cellView": "code"
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -139,12 +130,7 @@
       "metadata": {
         "id": "jBmKxLVy9Uhg",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -171,12 +157,7 @@
       "metadata": {
         "id": "g4Wzg69bnwK2",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -246,12 +227,7 @@
       "metadata": {
         "id": "J6c7uEU9rjRM",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -281,12 +257,7 @@
       "metadata": {
         "id": "FQvb_JYdrpPm",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -310,6 +281,31 @@
         "  * The first four fields are *[features](https://developers.google.com/machine-learning/glossary/#feature)*: these are characteristics of an example. Here, the fields hold float numbers representing flower measurements.\n",
         "  * The last column is the *[label](https://developers.google.com/machine-learning/glossary/#label)*: this is the value we want to predict. For this dataset, it's an integer value of 0, 1, or 2 that corresponds to a flower name.\n",
         "\n",
+        "Let's write that out in code:"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "9Edhevw7exl6",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
+        "feature_names = column_names[:-1]\n",
+        "label_name = column_names[-1]"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "CCtwLoJhhDNc",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
         "Each label is associated with string name (for example, \"setosa\"), but machine learning typically relies on numeric values. The label numbers are mapped to a named representation, such as:\n",
         "\n",
         "* `0`: Iris setosa\n",
@@ -319,6 +315,19 @@
         "For more information about features and labels, see the [ML Terminology section of the Machine Learning Crash Course](https://developers.google.com/machine-learning/crash-course/framing/ml-terminology)."
       ]
     },
+    {
+      "metadata": {
+        "id": "sVNlJlUOhkoX",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
     {
       "metadata": {
         "id": "dqPkQExM2Pwt",
@@ -326,75 +335,112 @@
       },
       "cell_type": "markdown",
       "source": [
-        "### Parse the dataset\n",
+        "### Create a `tf.data.Dataset`\n",
+        "\n",
+        "TensorFlow's [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) handles many common cases for feeding data into a model. This is a high-level API for reading data and transforming it into a form used for training. See the [Datasets Quick Start guide](https://www.tensorflow.org/get_started/datasets_quickstart) for more information.\n",
+        "\n",
         "\n",
-        "Since our dataset is a CSV-formatted text file, we'll parse the feature and label values into a format our Python model can use. Each line—or row—in the file is passed to the `parse_csv` function which grabs the first four feature fields and combines them into a single tensor. Then, the last field is parsed as the label. The function returns *both* the `features` and `label` tensors:"
+        "Since our dataset is a CSV-formatted text file, we'll use the the [`make_csv_dataset`](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) function to easily parse the data into a suitable format. This function is meant to generate fata for training models so the default behavior is to shuffle the data (`shuffle=True, shuffle_buffer_size=10000`), and repeat the dataset forever (`num_epochs=None`). Note the [batch size](https://developers.google.com/machine-learning/glossary/#batch_size) parameter."
       ]
     },
     {
       "metadata": {
-        "id": "2y4OgiIz2CVb",
+        "id": "WsxHnz1ebJ2S",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
-        "def parse_csv(line):\n",
-        "  example_defaults = [[0.], [0.], [0.], [0.], [0]]  # sets field types\n",
-        "  parsed_line = tf.decode_csv(line, example_defaults)\n",
-        "  # First 4 fields are features, combine into single tensor\n",
-        "  features = tf.reshape(parsed_line[:-1], shape=(4,))\n",
-        "  # Last field is the label\n",
-        "  label = tf.reshape(parsed_line[-1], shape=())\n",
-        "  return features, label"
+        "batch_size=32\n",
+        "train_dataset = tf.contrib.data.make_csv_dataset(\n",
+        "    train_dataset_fp, batch_size, \n",
+        "    column_names=column_names,\n",
+        "    label_name='species',\n",
+        "    num_epochs=1)"
       ],
       "execution_count": 0,
       "outputs": []
     },
     {
       "metadata": {
-        "id": "hBGYOBS7zfdQ",
+        "id": "gB_RSn62c-3G",
         "colab_type": "text"
       },
       "cell_type": "markdown",
       "source": [
-        "### Create the training tf.data.Dataset\n",
-        "\n",
-        "TensorFlow's [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) handles many common cases for feeding data into a model. This is a high-level API for reading data and transforming it into a form used for training. See the [Datasets Quick Start guide](https://www.tensorflow.org/get_started/datasets_quickstart) for more information.\n",
-        "\n",
-        "This program uses [tf.data.TextLineDataset](https://www.tensorflow.org/api_docs/python/tf/data/TextLineDataset) to load a CSV-formatted text file and is parsed with our `parse_csv` function. A [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) represents an input pipeline as a collection of elements and a series of transformations that act on those elements. Transformation methods are chained together or called sequentially—just make sure to keep a reference to the returned `Dataset` object.\n",
+        "This function returns a `tf.data.Dataset` of `(features, label)` pairs, where `features` is a `{'column_name': value}` dictionary.\n",
         "\n",
-        "Training works best if the examples are in random order. Use `tf.data.Dataset.shuffle` to randomize entries, setting  `buffer_size` to a value larger than the number of examples (120 in this case). To train the model faster, the dataset's *[batch size](https://developers.google.com/machine-learning/glossary/#batch_size)* is set to `32` examples to train at once."
+        "With eager execution enabled, these `Dataset` objects are iterable. Let's look at a batch of features:"
       ]
     },
     {
       "metadata": {
-        "id": "7YYQUa1Hz2pP",
+        "id": "me5Wn-9FcyyO",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
-        "train_dataset = tf.data.TextLineDataset(train_dataset_fp)\n",
-        "train_dataset = train_dataset.skip(1)             # skip the first header row\n",
-        "train_dataset = train_dataset.map(parse_csv)      # parse each row\n",
-        "train_dataset = train_dataset.shuffle(buffer_size=1000)  # randomize\n",
-        "train_dataset = train_dataset.batch(32)\n",
+        "features, labels = next(iter(train_dataset))\n",
+        "  \n",
+        "plt.scatter(features['petal_length'], features['petal_width'])\n",
+        "plt.xlabel(\"Petal Length\")\n",
+        "plt.ylabel(\"Petal Width\")\n"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "YlxpSyHlhT6M",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "To simplify the model building, let's repackage the features dictionary into an array with whape ``(batch_size,num_features)`.\n",
         "\n",
-        "# View a single example entry from a batch\n",
-        "features, label = iter(train_dataset).next()\n",
-        "print(\"example features:\", features[0])\n",
-        "print(\"example label:\", label[0])"
+        "To do this we'll write a simple function using the [`tf.stack`](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to pack the features into a single array. Then we'll use the [`tf.data.Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to apply this function to each `(features,label)` pair in the dataset. :\n"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "jm932WINcaGU",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "def pack_features_vector(features,labels):\n",
+        "  features = tf.stack([features[name] for name in feature_names],\n",
+        "                      axis=1)\n",
+        "  return features, labels\n",
+        "  \n",
+        "train_dataset = train_dataset.map(pack_features_vector)"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "NLy0Q1xCldVO",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "The features of this dataset arrays with shape `(batch_size, num_features)`. Let's look at the first 10 examples:"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "kex9ibEek6Tr",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "features,labels = next(iter(train_dataset))\n",
+        "  \n",
+        "features[:10]"
       ],
       "execution_count": 0,
       "outputs": []
@@ -440,21 +486,16 @@
       "source": [
         "### Create a model using Keras\n",
         "\n",
-        "The TensorFlow [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together. See the [Keras documentation](https://keras.io/) for details.\n",
+        "The TensorFlow [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together.\n",
         "\n",
-        "The [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer's `input_shape` parameter corresponds to the amount of features from the dataset, and is required."
+        "The [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer's `input_shape` parameter corresponds to the number of features from the dataset, and is required."
       ]
     },
     {
       "metadata": {
         "id": "2fZ6oL2ig3ZK",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -474,11 +515,62 @@
       },
       "cell_type": "markdown",
       "source": [
-        "The *[activation function](https://developers.google.com/machine-learning/crash-course/glossary#activation_function)* determines the output of a single neuron to the next layer. This is loosely based on how brain neurons are connected. There are many [available activations](https://www.tensorflow.org/api_docs/python/tf/keras/activations), but [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU) is common for hidden layers.\n",
+        "The *[activation function](https://developers.google.com/machine-learning/crash-course/glossary#activation_function)* determines the output shape of each node. These non-linearities are important as without them the model would be equivalent to a single layer. There are many [available activations](https://www.tensorflow.org/api_docs/python/tf/keras/activations), but [ReLU](https://developers.google.com/machine-learning/crash-course/glossary#ReLU) is common for hidden layers.\n",
         "\n",
         "The ideal number of hidden layers and neurons depends on the problem and the dataset. Like many aspects of machine learning, picking the best shape of the neural network requires a mixture of knowledge and experimentation. As a rule of thumb, increasing the number of hidden layers and neurons typically creates a more powerful model, which requires more data to train effectively."
       ]
     },
+    {
+      "metadata": {
+        "id": "2wFKnhWCpDSS",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "Let's have a quick look at what this model does to a batch of features:"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "xe6SQ5NrpB-I",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "prediction = model(features)\n",
+        "prediction[:5]"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "wxyXOhwVr5S3",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "For each example it returns a *[logit](https://developers.google.com/machine-learning/crash-course/glossary#logits)* score for each class. \n",
+        "\n",
+        "You can calculate the probability that the model assigns to each class using the [`tf.nn.softmax`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) function.\n",
+        "\n",
+        "The model hasn't been trained yet, so these aren't very good predictions."
+      ]
+    },
+    {
+      "metadata": {
+        "id": "-Jzm_GoErz8B",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "tf.nn.softmax(prediction[:5])"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
     {
       "metadata": {
         "id": "Vzq2E5J2QMtw",
@@ -504,45 +596,74 @@
         "\n",
         "Both training and evaluation stages need to calculate the model's *[loss](https://developers.google.com/machine-learning/crash-course/glossary#loss)*. This measures how off a model's predictions are from the desired label, in other words, how bad the model is performing. We want to minimize, or optimize, this value.\n",
         "\n",
-        "Our model will calculate its loss using the [tf.losses.sparse_softmax_cross_entropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy) function which takes the model's prediction and the desired label. The returned loss value is progressively larger as the prediction gets worse."
+        "Our model will calculate its loss using the [tf.losses.sparse_softmax_cross_entropy](https://www.tensorflow.org/api_docs/python/tf/losses/sparse_softmax_cross_entropy) function which takes the model's prediction and the desired label, and returns the average loss across the examples."
       ]
     },
     {
       "metadata": {
-        "id": "x57HcKWhKkei",
+        "id": "tMAT4DcMPwI-",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
         "def loss(model, x, y):\n",
         "  y_ = model(x)\n",
         "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
-        "\n",
-        "\n",
-        "def grad(model, inputs, targets):\n",
-        "  with tf.GradientTape() as tape:\n",
-        "    loss_value = loss(model, inputs, targets)\n",
-        "  return tape.gradient(loss_value, model.variables)"
+        "\n"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "xSFT90LsQRNV",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "Let's test out this function:"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "uDdxM3aeQQyx",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "loss(model, features, labels)"
       ],
       "execution_count": 0,
       "outputs": []
     },
     {
       "metadata": {
-        "id": "RtVOFpb21Krp",
+        "id": "3IcPqA24QM6B",
         "colab_type": "text"
       },
       "cell_type": "markdown",
       "source": [
-        "The `grad` function uses the `loss` function and the [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to record operations that compute the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model. For more examples of this, see the [eager execution guide](https://www.tensorflow.org/programmers_guide/eager)."
+        "To perform the optimization we will use the [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) context to calculate the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model. For more examples of this, see the [eager execution guide](https://www.tensorflow.org/programmers_guide/eager)."
       ]
     },
+    {
+      "metadata": {
+        "id": "x57HcKWhKkei",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "def grad(model, inputs, targets):\n",
+        "  with tf.GradientTape() as tape:\n",
+        "    loss_value = loss(model, inputs, targets)\n",
+        "  return tape.gradient(loss_value, model.trainable_variables)"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
     {
       "metadata": {
         "id": "lOxFimtlKruu",
@@ -552,7 +673,7 @@
       "source": [
         "### Create an optimizer\n",
         "\n",
-        "An *[optimizer](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)* applies the computed gradients to the model's variables to minimize the `loss` function. You can think of a curved surface (see Figure 3) and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascent—so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
+        "An *[optimizer](https://developers.google.com/machine-learning/crash-course/glossary#optimizer)* applies the computed gradients to the model's variables to minimize the `loss` function. You can think of the loss function as a curved surface (see Figure 3) and we want to find its lowest point by walking around. The gradients point in the direction of steepest ascent—so we'll travel the opposite way and move down the hill. By iteratively calculating the loss and gradient for each batch, we'll adjust the model during training. Gradually, the model will find the best combination of weights and bias to minimize loss. And the lower the loss, the better the model's predictions.\n",
         "\n",
         "<table>\n",
         "  <tr><td>\n",
@@ -567,20 +688,58 @@
         "TensorFlow has many [optimization algorithms](https://www.tensorflow.org/api_guides/python/train) available for training. This model uses the [tf.train.GradientDescentOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer) that implements the *[stochastic gradient descent](https://developers.google.com/machine-learning/crash-course/glossary#gradient_descent)* (SGD) algorithm. The `learning_rate` sets the step size to take for each iteration down the hill. This is a *hyperparameter* that you'll commonly adjust to achieve better results."
       ]
     },
+    {
+      "metadata": {
+        "id": "XkUd6UiZa_dF",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "Let's setup the optimizer, and the `global_step` counter:"
+      ]
+    },
     {
       "metadata": {
         "id": "8xxi2NNGKwG_",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "\n",
+        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
+        "global_step=tf.train.get_or_create_global_step()"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "pJVRZ0hP52ZB",
+        "colab_type": "text"
+      },
+      "cell_type": "markdown",
+      "source": [
+        "Now let's take a single optimization step:"
+      ]
+    },
+    {
+      "metadata": {
+        "id": "rxRNTFVe56RG",
+        "colab_type": "code",
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
-        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)"
+        "print(\"Step:        \", global_step.numpy())\n",
+        "print(\"Initial loss:\", loss(model, features, labels).numpy())\n",
+        "\n",
+        "grads = grad(model, features, labels)\n",
+        "optimizer.apply_gradients(zip(grads, model.variables), global_step)\n",
+        "\n",
+        "print()\n",
+        "print(\"Step:        \", global_step.numpy())\n",
+        "print(\"Loss:        \", loss(model, features, labels).numpy())"
       ],
       "execution_count": 0,
       "outputs": []
@@ -610,12 +769,7 @@
       "metadata": {
         "id": "AIgulGRUhpto",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -626,6 +780,7 @@
         "train_accuracy_results = []\n",
         "\n",
         "num_epochs = 201\n",
+        "global_step=tf.train.get_or_create_global_step()\n",
         "\n",
         "for epoch in range(num_epochs):\n",
         "  epoch_loss_avg = tfe.metrics.Mean()\n",
@@ -636,7 +791,7 @@
         "    # Optimize the model\n",
         "    grads = grad(model, x, y)\n",
         "    optimizer.apply_gradients(zip(grads, model.variables),\n",
-        "                              global_step=tf.train.get_or_create_global_step())\n",
+        "                              global_step)\n",
         "\n",
         "    # Track progress\n",
         "    epoch_loss_avg(loss(model, x, y))  # add current batch loss\n",
@@ -681,12 +836,7 @@
       "metadata": {
         "id": "agjvNd2iUGFn",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -766,25 +916,34 @@
       "metadata": {
         "id": "Ps3_9dJ3Lodk",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
         "test_url = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
         "\n",
         "test_fp = tf.keras.utils.get_file(fname=os.path.basename(test_url),\n",
-        "                                  origin=test_url)\n",
-        "\n",
-        "test_dataset = tf.data.TextLineDataset(test_fp)\n",
-        "test_dataset = test_dataset.skip(1)             # skip header row\n",
-        "test_dataset = test_dataset.map(parse_csv)      # parse each row with the function created earlier\n",
-        "test_dataset = test_dataset.shuffle(1000)       # randomize\n",
-        "test_dataset = test_dataset.batch(32)           # use the same batch size as the training set"
+        "                                  origin=test_url)"
+      ],
+      "execution_count": 0,
+      "outputs": []
+    },
+    {
+      "metadata": {
+        "id": "SRMWCu30bnxH",
+        "colab_type": "code",
+        "colab": {}
+      },
+      "cell_type": "code",
+      "source": [
+        "test_dataset = tf.contrib.data.make_csv_dataset(\n",
+        "    train_dataset_fp, batch_size, \n",
+        "    column_names=column_names,\n",
+        "    label_name='species',\n",
+        "    num_epochs=1,\n",
+        "    shuffle=False)\n",
+        "\n",
+        "test_dataset = test_dataset.map(pack_features_vector)"
       ],
       "execution_count": 0,
       "outputs": []
@@ -805,12 +964,7 @@
       "metadata": {
         "id": "Tw03-MK1cYId",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
@@ -847,17 +1001,10 @@
       "metadata": {
         "id": "kesTS5Lzv-M2",
         "colab_type": "code",
-        "colab": {
-          "autoexec": {
-            "startup": false,
-            "wait_interval": 0
-          }
-        }
+        "colab": {}
       },
       "cell_type": "code",
       "source": [
-        "class_ids = [\"Iris setosa\", \"Iris versicolor\", \"Iris virginica\"]\n",
-        "\n",
         "predict_dataset = tf.convert_to_tensor([\n",
         "    [5.1, 3.3, 1.7, 0.5,],\n",
         "    [5.9, 3.0, 4.2, 1.5,],\n",
@@ -868,7 +1015,7 @@
         "\n",
         "for i, logits in enumerate(predictions):\n",
         "  class_idx = tf.argmax(logits).numpy()\n",
-        "  name = class_ids[class_idx]\n",
+        "  name = class_names[class_idx]\n",
         "  print(\"Example {} prediction: {}\".format(i, name))"
       ],
       "execution_count": 0,
