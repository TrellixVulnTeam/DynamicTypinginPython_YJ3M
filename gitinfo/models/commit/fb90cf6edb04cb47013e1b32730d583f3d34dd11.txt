commit fb90cf6edb04cb47013e1b32730d583f3d34dd11
Author: Mark Daoust <markdaoust@google.com>
Date:   Mon May 14 15:10:45 2018 -0700

    remove code-quotes (broken in github viewer)

diff --git a/samples/core/get_started/eager.ipynb b/samples/core/get_started/eager.ipynb
index caba3931..0045998e 100644
--- a/samples/core/get_started/eager.ipynb
+++ b/samples/core/get_started/eager.ipynb
@@ -220,7 +220,7 @@
         "\n",
         "### Download the dataset\n",
         "\n",
-        "Download the training dataset file using the [`tf.keras.utils.get_file`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) function. This returns the file path of the downloaded file."
+        "Download the training dataset file using the [tf.keras.utils.get_file](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file) function. This returns the file path of the downloaded file."
       ]
     },
     {
@@ -340,7 +340,7 @@
         "TensorFlow's [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) handles many common cases for feeding data into a model. This is a high-level API for reading data and transforming it into a form used for training. See the [Datasets Quick Start guide](https://www.tensorflow.org/get_started/datasets_quickstart) for more information.\n",
         "\n",
         "\n",
-        "Since our dataset is a CSV-formatted text file, we'll use the the [`make_csv_dataset`](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) function to easily parse the data into a suitable format. This function is meant to generate data for training models so the default behavior is to shuffle the data (`shuffle=True, shuffle_buffer_size=10000`), and repeat the dataset forever (`num_epochs=None`). Also note the [`batch_size`](https://developers.google.com/machine-learning/glossary/#batch_size) parameter."
+        "Since our dataset is a CSV-formatted text file, we'll use the the [make_csv_dataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/make_csv_dataset) function to easily parse the data into a suitable format. This function is meant to generate data for training models so the default behavior is to shuffle the data (`shuffle=True, shuffle_buffer_size=10000`), and repeat the dataset forever (`num_epochs=None`). Also note the [batch_size](https://developers.google.com/machine-learning/glossary/#batch_size) parameter."
       ]
     },
     {
@@ -399,7 +399,8 @@
       "source": [
         "To simplify the model building, let's repackage the features dictionary into an array with shape ``(batch_size,num_features)`.\n",
         "\n",
-        "To do this we'll write a simple function using the [`tf.stack`](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to pack the features into a single array. Then we'll use the [`tf.data.Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to apply this function to each `(features,label)` pair in the dataset. :\n"
+        "To do this we'll write a simple function using the [tf.stack](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to pack the features into a single array. Then we'll use the [tf.data.Dataset.map](https://www.tensorflow.org/api_docs/python/tf/data/dataset/map) method to apply this function to each `(features,label)` pair in the dataset. :\n"
+
       ]
     },
     {
@@ -486,9 +487,9 @@
       "source": [
         "### Create a model using Keras\n",
         "\n",
-        "The TensorFlow [`tf.keras`](https://www.tensorflow.org/api_docs/python/tf/keras) API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together.\n",
+        "The TensorFlow [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) API is the preferred way to create models and layers. This makes it easy to build models and experiment while Keras handles the complexity of connecting everything together.\n",
         "\n",
-        "The [`tf.keras.Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer's `input_shape` parameter corresponds to the number of features from the dataset, and is required."
+        "The [tf.keras.Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) model is a linear stack of layers. Its constructor takes a list of layer instances, in this case, two [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layers with 10 nodes each, and an output layer with 3 nodes representing our label predictions. The first layer's `input_shape` parameter corresponds to the number of features from the dataset, and is required."
       ]
     },
     {
@@ -553,7 +554,7 @@
       "source": [
         "For each example it returns a *[logit](https://developers.google.com/machine-learning/crash-course/glossary#logits)* score for each class. \n",
         "\n",
-        "You can convert logits to probabilities for each class using the [`tf.nn.softmax`](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) function.\n",
+        "You can convert logits to probabilities for each class using the [tf.nn.softmax](https://www.tensorflow.org/api_docs/python/tf/nn/softmax) function.\n",
         "\n",
         "The model hasn't been trained yet, so these aren't very good predictions."
       ]
@@ -645,7 +646,7 @@
       },
       "cell_type": "markdown",
       "source": [
-        "To perform the optimization we will use the [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) context to calculate the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model. For more examples of this, see the [eager execution guide](https://www.tensorflow.org/programmers_guide/eager)."
+        "To perform the optimization we will use the [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) context to calculate the *[gradients](https://developers.google.com/machine-learning/crash-course/glossary#gradient)* used to optimize our model. For more examples of this, see the [eager execution guide](https://www.tensorflow.org/programmers_guide/eager)."
       ]
     },
     {
