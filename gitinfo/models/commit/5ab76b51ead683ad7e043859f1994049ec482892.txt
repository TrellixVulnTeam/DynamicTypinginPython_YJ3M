commit 5ab76b51ead683ad7e043859f1994049ec482892
Author: Saurabh Saxena <srbs@google.com>
Date:   Mon Apr 27 11:15:50 2020 -0700

    Internal change
    
    PiperOrigin-RevId: 308659564

diff --git a/official/nlp/data/classifier_data_lib.py b/official/nlp/data/classifier_data_lib.py
index 2a2ca58c..aa9ad438 100644
--- a/official/nlp/data/classifier_data_lib.py
+++ b/official/nlp/data/classifier_data_lib.py
@@ -250,6 +250,51 @@ class MrpcProcessor(DataProcessor):
     return examples
 
 
+class QqpProcessor(DataProcessor):
+  """Processor for the QQP data set (GLUE version)."""
+
+  def get_train_examples(self, data_dir):
+    """See base class."""
+    return self._create_examples(
+        self._read_tsv(os.path.join(data_dir, "train.tsv")), "train")
+
+  def get_dev_examples(self, data_dir):
+    """See base class."""
+    return self._create_examples(
+        self._read_tsv(os.path.join(data_dir, "dev.tsv")), "dev")
+
+  def get_test_examples(self, data_dir):
+    """See base class."""
+    return self._create_examples(
+        self._read_tsv(os.path.join(data_dir, "test.tsv")), "test")
+
+  def get_labels(self):
+    """See base class."""
+    return ["0", "1"]
+
+  @staticmethod
+  def get_processor_name():
+    """See base class."""
+    return "QQP"
+
+  def _create_examples(self, lines, set_type):
+    """Creates examples for the training and dev sets."""
+    examples = []
+    for (i, line) in enumerate(lines):
+      if i == 0:
+        continue
+      guid = "%s-%s" % (set_type, line[0])
+      try:
+        text_a = line[3]
+        text_b = line[4]
+        label = line[5]
+      except IndexError:
+        continue
+      examples.append(InputExample(guid=guid, text_a=text_a, text_b=text_b,
+                                   label=label))
+    return examples
+
+
 class ColaProcessor(DataProcessor):
   """Processor for the CoLA data set (GLUE version)."""
 
diff --git a/official/nlp/data/create_finetuning_data.py b/official/nlp/data/create_finetuning_data.py
index 92b8abe9..a83ee06e 100644
--- a/official/nlp/data/create_finetuning_data.py
+++ b/official/nlp/data/create_finetuning_data.py
@@ -46,7 +46,7 @@ flags.DEFINE_string(
     "for the task.")
 
 flags.DEFINE_enum("classification_task_name", "MNLI",
-                  ["COLA", "MNLI", "MRPC", "QNLI", "SST-2", "XNLI"],
+                  ["COLA", "MNLI", "MRPC", "QNLI", "QQP", "SST-2", "XNLI"],
                   "The name of the task to train BERT classifier.")
 
 # BERT Squad task specific flags.
@@ -143,6 +143,7 @@ def generate_classifier_dataset():
         "mnli": classifier_data_lib.MnliProcessor,
         "mrpc": classifier_data_lib.MrpcProcessor,
         "qnli": classifier_data_lib.QnliProcessor,
+        "qqp": classifier_data_lib.QqpProcessor,
         "sst-2": classifier_data_lib.SstProcessor,
         "xnli": classifier_data_lib.XnliProcessor,
     }
