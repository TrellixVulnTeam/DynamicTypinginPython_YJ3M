commit 48b60914481e59c233c83189ffb27deaeb681afe
Author: Vinh Nguyen <vinh.nguyenx@gmail.com>
Date:   Tue Aug 20 06:16:11 2019 +0000

    minor fix automatic mixed precision - resnet

diff --git a/official/vision/image_classification/resnet_imagenet_main.py b/official/vision/image_classification/resnet_imagenet_main.py
index 579204a4..b4cf560c 100644
--- a/official/vision/image_classification/resnet_imagenet_main.py
+++ b/official/vision/image_classification/resnet_imagenet_main.py
@@ -32,7 +32,6 @@ from official.vision.image_classification import common
 from official.vision.image_classification import imagenet_preprocessing
 from official.vision.image_classification import resnet_model
 from official.vision.image_classification import trivial_model
-import pdb
 
 LR_SCHEDULE = [    # (multiplier, epoch to start) tuples
     (1.0, 5), (0.1, 30), (0.01, 60), (0.001, 80)
@@ -185,11 +184,11 @@ def run(flags_obj):
       optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(
           optimizer, loss_scale=flags_core.get_loss_scale(flags_obj,
                                                           default_for_fp16=128))
-    pdb.set_trace()
     if flags_obj.fp16_implementation == "graph_rewrite":
-      # Note: when flags_obj["fp16_implementation"] == "graph_rewrite", 
+      # Note: when flags_obj.fp16_implementation == "graph_rewrite", 
       # dtype as determined by flags_core.get_tf_dtype(flags_obj) would be 'float32'
-      #
+      # which will ensure tf.keras.mixed_precision and tf.train.experimental.enable_mixed_precision_graph_rewrite
+      # does not double up.
       optimizer = tf.train.experimental.enable_mixed_precision_graph_rewrite(optimizer)
             
     if flags_obj.use_trivial_model:
