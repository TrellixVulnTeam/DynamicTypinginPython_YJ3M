commit 79d2ecb1026ac3057ab8206ea47a56dcac919ab4
Author: Neal Wu <neal@nealwu.com>
Date:   Mon Mar 20 15:16:59 2017 -0700

    Revert "fixed a bug in sampled_loss(), made compatible for 0.12.0"

diff --git a/tutorials/rnn/translate/seq2seq_model.py b/tutorials/rnn/translate/seq2seq_model.py
index 942ca026..89b27f5b 100644
--- a/tutorials/rnn/translate/seq2seq_model.py
+++ b/tutorials/rnn/translate/seq2seq_model.py
@@ -100,7 +100,7 @@ class Seq2SeqModel(object):
       b = tf.get_variable("proj_b", [self.target_vocab_size], dtype=dtype)
       output_projection = (w, b)
 
-      def sampled_loss(inputs, labels):
+      def sampled_loss(labels, inputs):
         labels = tf.reshape(labels, [-1, 1])
         # We need to compute the sampled_softmax_loss using 32bit floats to
         # avoid numerical instabilities.
