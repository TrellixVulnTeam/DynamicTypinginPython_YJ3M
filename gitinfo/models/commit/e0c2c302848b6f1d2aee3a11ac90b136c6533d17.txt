commit e0c2c302848b6f1d2aee3a11ac90b136c6533d17
Author: George Karpenkov <cheshire@google.com>
Date:   Wed Feb 26 08:24:41 2020 -0800

    Do not recreate tf.function on different calls to the same layer
    
    PiperOrigin-RevId: 297366158

diff --git a/official/nlp/modeling/layers/transformer.py b/official/nlp/modeling/layers/transformer.py
index 77f43545..5328d43c 100644
--- a/official/nlp/modeling/layers/transformer.py
+++ b/official/nlp/modeling/layers/transformer.py
@@ -195,11 +195,13 @@ class Transformer(tf.keras.layers.Layer):
 
   def call(self, inputs):
     # TODO(b/150147476, b/150024785): Fix tf.function in TF1 crash.
-    call_impl = self.call_impl
-    if not hasattr(tf.compat.v1, "executing_eagerly_outside_functions"
-                  ) or tf.compat.v1.executing_eagerly_outside_functions():
-      call_impl = tf.function(experimental_compile=True)(call_impl)
-    return call_impl(inputs)
+    if not hasattr(self, "_call_impl"):
+      self._call_impl = self.call_impl
+      if not hasattr(tf.compat.v1, "executing_eagerly_outside_functions"
+                    ) or tf.compat.v1.executing_eagerly_outside_functions():
+        self._call_impl = tf.function(experimental_compile=True)(
+            self._call_impl)
+    return self._call_impl(inputs)
 
   def call_impl(self, inputs):
     if isinstance(inputs, (list, tuple)) and len(inputs) == 2:
