commit e289c8c7e2666a3a0d09cd233a4780e216660246
Author: A. Unique TensorFlower <gardener@tensorflow.org>
Date:   Mon Apr 20 09:39:50 2020 -0700

    Internal change
    
    PiperOrigin-RevId: 307416709

diff --git a/official/nlp/bert/input_pipeline.py b/official/nlp/bert/input_pipeline.py
index 16bf824f..53694b82 100644
--- a/official/nlp/bert/input_pipeline.py
+++ b/official/nlp/bert/input_pipeline.py
@@ -156,7 +156,6 @@ def create_classifier_dataset(file_path,
       'input_mask': tf.io.FixedLenFeature([seq_length], tf.int64),
       'segment_ids': tf.io.FixedLenFeature([seq_length], tf.int64),
       'label_ids': tf.io.FixedLenFeature([], tf.int64),
-      'is_real_example': tf.io.FixedLenFeature([], tf.int64),
   }
   dataset = single_file_dataset(file_path, name_to_features)
 
diff --git a/official/nlp/bert/run_classifier.py b/official/nlp/bert/run_classifier.py
index 78855043..af34cc04 100644
--- a/official/nlp/bert/run_classifier.py
+++ b/official/nlp/bert/run_classifier.py
@@ -86,7 +86,7 @@ def get_dataset_fn(input_file_pattern, max_seq_length, global_batch_size,
     batch_size = ctx.get_per_replica_batch_size(
         global_batch_size) if ctx else global_batch_size
     dataset = input_pipeline.create_classifier_dataset(
-        input_file_pattern,
+        tf.io.gfile.glob(input_file_pattern),
         max_seq_length,
         batch_size,
         is_training=is_training,
