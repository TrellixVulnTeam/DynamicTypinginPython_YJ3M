commit 22b84f749489a94b484e3c1545ad9de0d8ad3e36
Author: Hongkun Yu <hongkuny@google.com>
Date:   Thu Nov 21 17:50:39 2019 -0800

    Transformer Nits: reshape -> set_shape
    
    PiperOrigin-RevId: 281872406

diff --git a/official/transformer/v2/transformer.py b/official/transformer/v2/transformer.py
index cc81f1a7..9c8b9b9b 100644
--- a/official/transformer/v2/transformer.py
+++ b/official/transformer/v2/transformer.py
@@ -121,6 +121,7 @@ class Transformer(tf.keras.Model):
     if len(inputs) == 2:
       inputs, targets = inputs[0], inputs[1]
     else:
+      # Decoding path.
       inputs, targets = inputs[0], None
       if self.params["padded_decode"]:
         if not self.params["num_replicas"]:
@@ -128,8 +129,9 @@ class Transformer(tf.keras.Model):
               "Padded decoding on CPU/GPUs is not supported.")
         decode_batch_size = int(self.params["decode_batch_size"] /
                                 self.params["num_replicas"])
-        inputs = tf.reshape(
-            inputs, [decode_batch_size, self.params["decode_max_length"]])
+        inputs.set_shape([
+            decode_batch_size, self.params["decode_max_length"]
+        ])
 
     # Variance scaling is used here because it seems to work in many problems.
     # Other reasonable initializers may also work just as well.
