commit 9d42f79762ecf516a9dda324a01a48c7d50018aa
Author: Taylor Robie <taylorrobie@google.com>
Date:   Fri Dec 21 13:43:38 2018 -0800

    remove 'deterministic'

diff --git a/official/recommendation/data_preprocessing.py b/official/recommendation/data_preprocessing.py
index 489920fa..190fcf85 100644
--- a/official/recommendation/data_preprocessing.py
+++ b/official/recommendation/data_preprocessing.py
@@ -197,15 +197,14 @@ def _filter_index_sort(raw_rating_path, cache_path, match_mlperf):
   return data, valid_cache
 
 
-def instantiate_pipeline(dataset, data_dir, deterministic, params):
-  # type: (str, str, bool, dict) -> (NCFDataset, typing.Callable)
+def instantiate_pipeline(dataset, data_dir, params):
+  # type: (str, str, dict) -> (NCFDataset, typing.Callable)
   """Load and digest data CSV into a usable form.
 
   Args:
     dataset: The name of the dataset to be used.
     data_dir: The root directory of the dataset.
-    deterministic: Try to enforce repeatable behavior, even at the cost of
-      performance.
+    params: dict of parameters for the run.
   """
   tf.logging.info("Beginning data preprocessing.")
 
@@ -225,9 +224,6 @@ def instantiate_pipeline(dataset, data_dir, deterministic, params):
     raise ValueError("Expected to find {} items, but found {}".format(
         num_items, len(item_map)))
 
-  if deterministic:
-    raise NotImplementedError("Fixed seed behavior has not been implemented.")
-
   producer = data_pipeline.MaterializedDataConstructor(
       maximum_number_epochs=params["train_epochs"],
       num_users=num_users,
diff --git a/official/recommendation/ncf_main.py b/official/recommendation/ncf_main.py
index 4eed3141..c986892c 100644
--- a/official/recommendation/ncf_main.py
+++ b/official/recommendation/ncf_main.py
@@ -195,6 +195,8 @@ def run_ncf(_):
 
   if FLAGS.seed is not None:
     np.random.seed(FLAGS.seed)
+    tf.logging.warning("Values may still vary from run to run due to thread "
+                       "execution ordering.")
 
   params = parse_flags(FLAGS)
   total_training_cycle = FLAGS.train_epochs // FLAGS.epochs_between_evals
@@ -207,8 +209,7 @@ def run_ncf(_):
     num_eval_steps = rconst.SYNTHETIC_BATCHES_PER_EPOCH
   else:
     num_users, num_items, producer = data_preprocessing.instantiate_pipeline(
-        dataset=FLAGS.dataset, data_dir=FLAGS.data_dir,
-        deterministic=FLAGS.seed is not None, params=params)
+        dataset=FLAGS.dataset, data_dir=FLAGS.data_dir, params=params)
 
     num_train_steps = (producer.train_batches_per_epoch //
                        params["batches_per_step"])
