commit 89ec947fdca50740e3eab6b51ade8f4c9cdebc7e
Author: Mark Daoust <markdaoust@google.com>
Date:   Tue Dec 19 07:46:08 2017 -0800

    Don't put an activation on the logit layer

diff --git a/samples/outreach/blogs/Blog_Custom_Estimators.py b/samples/outreach/blogs/Blog_Custom_Estimators.py
index 7a5407a6..8f3b36b1 100644
--- a/samples/outreach/blogs/Blog_Custom_Estimators.py
+++ b/samples/outreach/blogs/Blog_Custom_Estimators.py
@@ -109,18 +109,15 @@ def my_model_fn(
     # We implement it as a fully-connected layer (tf.layers.dense)
     # Has 10 neurons, and uses ReLU as the activation function
     # Takes input_layer as input
-    # h1 = tf.layers.dense(input_layer, 10, activation=tf.nn.relu)
     h1 = tf.layers.Dense(10, activation=tf.nn.relu)(input_layer)
 
     # Definition of hidden layer: h2 (this is the logits layer)
     # Similar to h1, but takes h1 as input
-    # h2 = tf.layers.dense(h1, 10, activation=tf.nn.relu)
     h2 = tf.layers.Dense(10, activation=tf.nn.relu)(h1)
 
     # Output 'logits' layer is three number = probability distribution
     # between Iris Sentosa, Versicolor, and Viginica
-    # logits = tf.layers.dense(h2, 3)
-    logits = tf.layers.Dense(3, activation=tf.nn.relu)(h2)
+    logits = tf.layers.Dense(3)(h2)
 
     # class_ids will be the model prediction for the class (Iris flower type)
     # The output node with the highest value is our prediction
