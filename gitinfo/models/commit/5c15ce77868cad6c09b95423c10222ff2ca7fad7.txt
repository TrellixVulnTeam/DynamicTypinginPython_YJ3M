commit 5c15ce77868cad6c09b95423c10222ff2ca7fad7
Author: Hongkun Yu <hongkuny@google.com>
Date:   Tue Nov 19 16:47:35 2019 -0800

    Fix a mistake in previous change
    
    PiperOrigin-RevId: 281409019

diff --git a/official/nlp/bert/run_pretraining.py b/official/nlp/bert/run_pretraining.py
index ef30502d..b54bf34e 100644
--- a/official/nlp/bert/run_pretraining.py
+++ b/official/nlp/bert/run_pretraining.py
@@ -59,12 +59,10 @@ def get_pretrain_dataset_fn(input_file_pattern, seq_length,
   """Returns input dataset from input file string."""
   def _dataset_fn(ctx=None):
     """Returns tf.data.Dataset for distributed BERT pretraining."""
-    input_files = []
-    for input_pattern in input_file_pattern.split(','):
-      input_files.extend(tf.io.gfile.glob(input_pattern))
+    input_patterns = input_file_pattern.split(',')
     batch_size = ctx.get_per_replica_batch_size(global_batch_size)
     train_dataset = input_pipeline.create_pretrain_dataset(
-        input_files,
+        input_patterns,
         seq_length,
         max_predictions_per_seq,
         batch_size,
