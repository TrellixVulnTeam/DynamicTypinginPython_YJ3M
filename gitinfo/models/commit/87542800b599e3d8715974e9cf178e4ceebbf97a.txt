commit 87542800b599e3d8715974e9cf178e4ceebbf97a
Author: Haoyu Zhang <haoyuzhang@google.com>
Date:   Thu Aug 1 15:50:17 2019 -0700

    Move the official ResNet (estimator version) under `official/r1` (#7355)
    
    * Restructure resnet estimator code to under official/r1
    
    * Continue moving resnet code...
    
    * Improved README.md

diff --git a/official/r1/resnet/README.md b/official/r1/resnet/README.md
new file mode 100644
index 00000000..890f42fd
--- /dev/null
+++ b/official/r1/resnet/README.md
@@ -0,0 +1,152 @@
+# ResNet in TensorFlow
+
+Deep residual networks, or ResNets for short, provided the breakthrough idea of
+identity mappings in order to enable training of very deep convolutional neural
+networks. This folder contains an implementation of ResNet for the ImageNet
+dataset written in TensorFlow.
+
+See the following papers for more background:
+
+[1] [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
+
+[2] [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
+
+In code, v1 refers to the ResNet defined in [1] but where a stride 2 is used on
+the 3x3 conv rather than the first 1x1 in the bottleneck. This change results
+in higher and more stable accuracy with less epochs than the original v1 and has
+shown to scale to higher batch sizes with minimal degradation in accuracy.
+There is no originating paper. The first mention we are aware of was in the
+torch version of [ResNetv1](https://github.com/facebook/fb.resnet.torch). Most
+popular v1 implementations are this implementation which we call ResNetv1.5.
+
+In testing we found v1.5 requires ~12% more compute to train and has 6% reduced
+throughput for inference compared to ResNetv1. CIFAR-10 ResNet does not use the
+bottleneck and is thus the same for v1 as v1.5.
+
+v2 refers to [2]. The principle difference between the two versions is that v1
+applies batch normalization and activation after convolution, while v2 applies
+batch normalization, then activation, and finally convolution. A schematic
+comparison is presented in Figure 1 (left) of [2].
+
+Please proceed according to which dataset you would like to train/evaluate on:
+
+
+## CIFAR-10
+
+### Setup
+
+You need to have the latest version of TensorFlow installed.
+First, make sure [the models folder is in your Python path](/official/#running-the-models); otherwise you may encounter `ImportError: No module named official.resnet`.
+
+Then, download and extract the CIFAR-10 data from Alex's website, specifying the location with the `--data_dir` flag. Run the following:
+
+```bash
+python cifar10_download_and_extract.py --data_dir <DATA_DIR>
+```
+
+Then, to train the model:
+
+```bash
+python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR>
+```
+
+Use `--data_dir` to specify the location of the CIFAR-10 data used in the previous step. There are more flag options as described in `cifar10_main.py`.
+
+To export a `SavedModel` from the trained checkpoint:
+
+```bash
+python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR> --eval_only --export_dir <EXPORT_DIR>
+```
+
+Note: The `<EXPORT_DIR>` must be present. You might want to run `mkdir <EXPORT_DIR>` beforehand.
+
+The `SavedModel` can then be [loaded](https://www.tensorflow.org/guide/saved_model#loading_a_savedmodel_in_python) in order to use the ResNet for prediction.
+
+
+## ImageNet
+
+### Setup
+To begin, you will need to download the ImageNet dataset and convert it to
+TFRecord format. The following [script](https://github.com/tensorflow/tpu/blob/master/tools/datasets/imagenet_to_gcs.py)
+and [README](https://github.com/tensorflow/tpu/tree/master/tools/datasets#imagenet_to_gcspy)
+provide a few options.
+
+Once your dataset is ready, you can begin training the model as follows:
+
+```bash
+python imagenet_main.py --data_dir=/path/to/imagenet
+```
+
+The model will begin training and will automatically evaluate itself on the
+validation data roughly once per epoch.
+
+Note that there are a number of other options you can specify, including
+`--model_dir` to choose where to store the model and `--resnet_size` to choose
+the model size (options include ResNet-18 through ResNet-200). See
+[`resnet_run_loop.py`](resnet_run_loop.py) for the full list of options.
+
+
+## Compute Devices
+Training is accomplished using the DistributionStrategies API. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/README.md)
+
+The appropriate distribution strategy is chosen based on the `--num_gpus` flag.
+By default this flag is one if TensorFlow is compiled with CUDA, and zero
+otherwise.
+
+num_gpus:
++ 0:  Use OneDeviceStrategy and train on CPU.
++ 1:  Use OneDeviceStrategy and train on GPU.
++ 2+: Use MirroredStrategy (data parallelism) to distribute a batch between devices.
+
+### Pre-trained model
+You can download pre-trained versions of ResNet-50. Reported accuracies are top-1 single-crop accuracy for the ImageNet validation set.
+Models are reported as both checkpoints produced by Estimator during training, and as SavedModels which are more portable. Checkpoints are fragile,
+and these are not guaranteed to work with future versions of the code. Both ResNet v1
+and ResNet v2 have been trained in both fp16 and fp32 precision. (Here v1 refers to "v1.5". See the note above.) Furthermore, SavedModels
+are generated to accept either tensor or JPG inputs, and with channels_first (NCHW) and channels_last (NHWC) convolutions. NCHW is generally
+better for GPUs, while NHWC is generally better for CPUs. See the TensorFlow [performance guide](https://www.tensorflow.org/performance/performance_guide#data_formats)
+for more details.
+
+ResNet-50 v2 (fp32, Accuracy 76.47%):
+* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp32_20181001.tar.gz)
+* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW.tar.gz),
+[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW_jpg.tar.gz),
+[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC.tar.gz),
+[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz)
+
+ResNet-50 v2 (fp16, Accuracy 76.56%):
+* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp16_20180928.tar.gz)
+* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW.tar.gz),
+[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW_jpg.tar.gz),
+[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC.tar.gz),
+[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC_jpg.tar.gz)
+
+ResNet-50 v1 (fp32, Accuracy 76.53%):
+* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp32_20181001.tar.gz)
+* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW.tar.gz),
+[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz),
+[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC.tar.gz),
+[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC_jpg.tar.gz)
+
+ResNet-50 v1 (fp16, Accuracy 76.18%):
+* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp16_20181001.tar.gz)
+* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW.tar.gz),
+[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW_jpg.tar.gz),
+[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC.tar.gz),
+[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC_jpg.tar.gz)
+
+### Transfer Learning
+You can use a pretrained model to initialize a training process. In addition you are able to freeze all but the final fully connected layers to fine tune your model. Transfer Learning is useful when training on your own small datasets. For a brief look at transfer learning in the context of convolutional neural networks, we recommend reading these [short notes](http://cs231n.github.io/transfer-learning/).
+
+
+To fine tune a pretrained resnet you must make three changes to your training procedure:
+
+1) Build the exact same model as previously except we change the number of labels in the final classification layer.
+
+2) Restore all weights from the pre-trained resnet except for the final classification layer; this will get randomly initialized instead.
+
+3) Freeze earlier layers of the network
+
+We can perform these three operations by specifying two flags: ```--pretrained_model_checkpoint_path``` and ```--fine_tune```. The first flag is a string that points to the path of a pre-trained resnet model. If this flag is specified, it will load all but the final classification layer. A key thing to note: if both ```--pretrained_model_checkpoint_path``` and a non empty ```model_dir``` directory are passed, the tensorflow estimator will load only the ```model_dir```. For more on this please see [WarmStartSettings](https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/WarmStartSettings) and [Estimators](https://www.tensorflow.org/guide/estimators).
+
+The second flag ```--fine_tune``` is a boolean that indicates whether earlier layers of the network should be frozen. You may set this flag to false if you wish to continue training a pre-trained model from a checkpoint. If you set this flag to true, you can train a new classification layer from scratch.
diff --git a/official/r1/resnet/__init__.py b/official/r1/resnet/__init__.py
new file mode 100644
index 00000000..e69de29b
diff --git a/official/resnet/cifar10_download_and_extract.py b/official/r1/resnet/cifar10_download_and_extract.py
similarity index 100%
rename from official/resnet/cifar10_download_and_extract.py
rename to official/r1/resnet/cifar10_download_and_extract.py
diff --git a/official/resnet/cifar10_main.py b/official/r1/resnet/cifar10_main.py
similarity index 99%
rename from official/resnet/cifar10_main.py
rename to official/r1/resnet/cifar10_main.py
index 5bac3e4b..76629fa5 100644
--- a/official/resnet/cifar10_main.py
+++ b/official/r1/resnet/cifar10_main.py
@@ -24,8 +24,8 @@ from absl import app as absl_app
 from absl import flags
 import tensorflow as tf  # pylint: disable=g-bad-import-order
 
-from official.resnet import resnet_model
-from official.resnet import resnet_run_loop
+from official.r1.resnet import resnet_model
+from official.r1.resnet import resnet_run_loop
 from official.utils.flags import core as flags_core
 from official.utils.logs import logger
 
diff --git a/official/resnet/cifar10_test.py b/official/r1/resnet/cifar10_test.py
similarity index 99%
rename from official/resnet/cifar10_test.py
rename to official/r1/resnet/cifar10_test.py
index aaf83782..cb1eef18 100644
--- a/official/resnet/cifar10_test.py
+++ b/official/r1/resnet/cifar10_test.py
@@ -22,7 +22,7 @@ from tempfile import mkstemp
 import numpy as np
 import tensorflow as tf  # pylint: disable=g-bad-import-order
 
-from official.resnet import cifar10_main
+from official.r1.resnet import cifar10_main
 from official.utils.misc import keras_utils
 from official.utils.testing import integration
 
diff --git a/official/resnet/estimator_benchmark.py b/official/r1/resnet/estimator_benchmark.py
similarity index 99%
rename from official/resnet/estimator_benchmark.py
rename to official/r1/resnet/estimator_benchmark.py
index 42a11a78..c0e4cdb1 100644
--- a/official/resnet/estimator_benchmark.py
+++ b/official/r1/resnet/estimator_benchmark.py
@@ -24,8 +24,8 @@ from absl import flags
 from absl.testing import flagsaver
 import tensorflow as tf  # pylint: disable=g-bad-import-order
 
-from official.resnet import cifar10_main as cifar_main
-from official.resnet import imagenet_main
+from official.r1.resnet import cifar10_main as cifar_main
+from official.r1.resnet import imagenet_main
 from official.utils.flags import core as flags_core
 from official.utils.logs import hooks
 
diff --git a/official/resnet/imagenet_main.py b/official/r1/resnet/imagenet_main.py
similarity index 98%
rename from official/resnet/imagenet_main.py
rename to official/r1/resnet/imagenet_main.py
index 18f4b1a0..bbff51dc 100644
--- a/official/resnet/imagenet_main.py
+++ b/official/r1/resnet/imagenet_main.py
@@ -22,13 +22,13 @@ import os
 
 from absl import app as absl_app
 from absl import flags
-import tensorflow as tf  # pylint: disable=g-bad-import-order
+import tensorflow as tf
 
+from official.r1.resnet import imagenet_preprocessing
+from official.r1.resnet import resnet_model
+from official.r1.resnet import resnet_run_loop
 from official.utils.flags import core as flags_core
 from official.utils.logs import logger
-from official.resnet import imagenet_preprocessing
-from official.resnet import resnet_model
-from official.resnet import resnet_run_loop
 
 DEFAULT_IMAGE_SIZE = 224
 NUM_CHANNELS = 3
diff --git a/official/resnet/imagenet_preprocessing.py b/official/r1/resnet/imagenet_preprocessing.py
similarity index 100%
rename from official/resnet/imagenet_preprocessing.py
rename to official/r1/resnet/imagenet_preprocessing.py
diff --git a/official/resnet/imagenet_test.py b/official/r1/resnet/imagenet_test.py
similarity index 99%
rename from official/resnet/imagenet_test.py
rename to official/r1/resnet/imagenet_test.py
index 7526dbf0..bff79727 100644
--- a/official/resnet/imagenet_test.py
+++ b/official/r1/resnet/imagenet_test.py
@@ -21,7 +21,7 @@ import unittest
 
 import tensorflow as tf  # pylint: disable=g-bad-import-order
 
-from official.resnet import imagenet_main
+from official.r1.resnet import imagenet_main
 from official.utils.misc import keras_utils
 from official.utils.testing import integration
 
diff --git a/official/resnet/layer_test.py b/official/r1/resnet/layer_test.py
similarity index 98%
rename from official/resnet/layer_test.py
rename to official/r1/resnet/layer_test.py
index 5afa7fcd..13907c78 100644
--- a/official/resnet/layer_test.py
+++ b/official/r1/resnet/layer_test.py
@@ -33,9 +33,9 @@ from __future__ import print_function
 
 import sys
 import unittest
+import tensorflow as tf
 
-import tensorflow as tf   # pylint: disable=g-bad-import-order
-from official.resnet import resnet_model
+from official.r1.resnet import resnet_model
 from official.utils.misc import keras_utils
 from official.utils.testing import reference_data
 
diff --git a/official/resnet/resnet_model.py b/official/r1/resnet/resnet_model.py
similarity index 100%
rename from official/resnet/resnet_model.py
rename to official/r1/resnet/resnet_model.py
diff --git a/official/resnet/resnet_run_loop.py b/official/r1/resnet/resnet_run_loop.py
similarity index 99%
rename from official/resnet/resnet_run_loop.py
rename to official/r1/resnet/resnet_run_loop.py
index 432ca39c..713d5958 100644
--- a/official/resnet/resnet_run_loop.py
+++ b/official/r1/resnet/resnet_run_loop.py
@@ -28,17 +28,15 @@ import math
 import multiprocessing
 import os
 
-
-# pylint: disable=g-bad-import-order
 from absl import flags
 import tensorflow as tf
 
-from official.resnet import resnet_model
-from official.utils.flags import core as flags_core
+from official.r1.resnet import imagenet_preprocessing
+from official.r1.resnet import resnet_model
 from official.utils.export import export
+from official.utils.flags import core as flags_core
 from official.utils.logs import hooks_helper
 from official.utils.logs import logger
-from official.resnet import imagenet_preprocessing
 from official.utils.misc import distribution_utils
 from official.utils.misc import model_helpers
 
diff --git a/official/resnet/README.md b/official/resnet/README.md
index 890f42fd..3fe9645e 100644
--- a/official/resnet/README.md
+++ b/official/resnet/README.md
@@ -1,152 +1,7 @@
 # ResNet in TensorFlow
 
-Deep residual networks, or ResNets for short, provided the breakthrough idea of
-identity mappings in order to enable training of very deep convolutional neural
-networks. This folder contains an implementation of ResNet for the ImageNet
-dataset written in TensorFlow.
-
-See the following papers for more background:
-
-[1] [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Dec 2015.
-
-[2] [Identity Mappings in Deep Residual Networks](https://arxiv.org/pdf/1603.05027.pdf) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, Jul 2016.
-
-In code, v1 refers to the ResNet defined in [1] but where a stride 2 is used on
-the 3x3 conv rather than the first 1x1 in the bottleneck. This change results
-in higher and more stable accuracy with less epochs than the original v1 and has
-shown to scale to higher batch sizes with minimal degradation in accuracy.
-There is no originating paper. The first mention we are aware of was in the
-torch version of [ResNetv1](https://github.com/facebook/fb.resnet.torch). Most
-popular v1 implementations are this implementation which we call ResNetv1.5.
-
-In testing we found v1.5 requires ~12% more compute to train and has 6% reduced
-throughput for inference compared to ResNetv1. CIFAR-10 ResNet does not use the
-bottleneck and is thus the same for v1 as v1.5.
-
-v2 refers to [2]. The principle difference between the two versions is that v1
-applies batch normalization and activation after convolution, while v2 applies
-batch normalization, then activation, and finally convolution. A schematic
-comparison is presented in Figure 1 (left) of [2].
-
-Please proceed according to which dataset you would like to train/evaluate on:
-
-
-## CIFAR-10
-
-### Setup
-
-You need to have the latest version of TensorFlow installed.
-First, make sure [the models folder is in your Python path](/official/#running-the-models); otherwise you may encounter `ImportError: No module named official.resnet`.
-
-Then, download and extract the CIFAR-10 data from Alex's website, specifying the location with the `--data_dir` flag. Run the following:
-
-```bash
-python cifar10_download_and_extract.py --data_dir <DATA_DIR>
-```
-
-Then, to train the model:
-
-```bash
-python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR>
-```
-
-Use `--data_dir` to specify the location of the CIFAR-10 data used in the previous step. There are more flag options as described in `cifar10_main.py`.
-
-To export a `SavedModel` from the trained checkpoint:
-
-```bash
-python cifar10_main.py --data_dir <DATA_DIR>/cifar-10-batches-bin --model_dir <MODEL_DIR> --eval_only --export_dir <EXPORT_DIR>
-```
-
-Note: The `<EXPORT_DIR>` must be present. You might want to run `mkdir <EXPORT_DIR>` beforehand.
-
-The `SavedModel` can then be [loaded](https://www.tensorflow.org/guide/saved_model#loading_a_savedmodel_in_python) in order to use the ResNet for prediction.
-
-
-## ImageNet
-
-### Setup
-To begin, you will need to download the ImageNet dataset and convert it to
-TFRecord format. The following [script](https://github.com/tensorflow/tpu/blob/master/tools/datasets/imagenet_to_gcs.py)
-and [README](https://github.com/tensorflow/tpu/tree/master/tools/datasets#imagenet_to_gcspy)
-provide a few options.
-
-Once your dataset is ready, you can begin training the model as follows:
-
-```bash
-python imagenet_main.py --data_dir=/path/to/imagenet
-```
-
-The model will begin training and will automatically evaluate itself on the
-validation data roughly once per epoch.
-
-Note that there are a number of other options you can specify, including
-`--model_dir` to choose where to store the model and `--resnet_size` to choose
-the model size (options include ResNet-18 through ResNet-200). See
-[`resnet_run_loop.py`](resnet_run_loop.py) for the full list of options.
-
-
-## Compute Devices
-Training is accomplished using the DistributionStrategies API. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/README.md)
-
-The appropriate distribution strategy is chosen based on the `--num_gpus` flag.
-By default this flag is one if TensorFlow is compiled with CUDA, and zero
-otherwise.
-
-num_gpus:
-+ 0:  Use OneDeviceStrategy and train on CPU.
-+ 1:  Use OneDeviceStrategy and train on GPU.
-+ 2+: Use MirroredStrategy (data parallelism) to distribute a batch between devices.
-
-### Pre-trained model
-You can download pre-trained versions of ResNet-50. Reported accuracies are top-1 single-crop accuracy for the ImageNet validation set.
-Models are reported as both checkpoints produced by Estimator during training, and as SavedModels which are more portable. Checkpoints are fragile,
-and these are not guaranteed to work with future versions of the code. Both ResNet v1
-and ResNet v2 have been trained in both fp16 and fp32 precision. (Here v1 refers to "v1.5". See the note above.) Furthermore, SavedModels
-are generated to accept either tensor or JPG inputs, and with channels_first (NCHW) and channels_last (NHWC) convolutions. NCHW is generally
-better for GPUs, while NHWC is generally better for CPUs. See the TensorFlow [performance guide](https://www.tensorflow.org/performance/performance_guide#data_formats)
-for more details.
-
-ResNet-50 v2 (fp32, Accuracy 76.47%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp32_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp32_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v2 (fp16, Accuracy 76.56%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v2_fp16_20180928.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v2_fp16_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v1 (fp32, Accuracy 76.53%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp32_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC_jpg.tar.gz)
-
-ResNet-50 v1 (fp16, Accuracy 76.18%):
-* [Checkpoint](http://download.tensorflow.org/models/official/20181001_resnet/checkpoints/resnet_imagenet_v1_fp16_20181001.tar.gz)
-* SavedModel [(NCHW)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW.tar.gz),
-[(NCHW, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NCHW_jpg.tar.gz),
-[(NHWC)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC.tar.gz),
-[(NHWC, JPG)](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp16_savedmodel_NHWC_jpg.tar.gz)
-
-### Transfer Learning
-You can use a pretrained model to initialize a training process. In addition you are able to freeze all but the final fully connected layers to fine tune your model. Transfer Learning is useful when training on your own small datasets. For a brief look at transfer learning in the context of convolutional neural networks, we recommend reading these [short notes](http://cs231n.github.io/transfer-learning/).
-
-
-To fine tune a pretrained resnet you must make three changes to your training procedure:
-
-1) Build the exact same model as previously except we change the number of labels in the final classification layer.
-
-2) Restore all weights from the pre-trained resnet except for the final classification layer; this will get randomly initialized instead.
-
-3) Freeze earlier layers of the network
-
-We can perform these three operations by specifying two flags: ```--pretrained_model_checkpoint_path``` and ```--fine_tune```. The first flag is a string that points to the path of a pre-trained resnet model. If this flag is specified, it will load all but the final classification layer. A key thing to note: if both ```--pretrained_model_checkpoint_path``` and a non empty ```model_dir``` directory are passed, the tensorflow estimator will load only the ```model_dir```. For more on this please see [WarmStartSettings](https://www.tensorflow.org/versions/master/api_docs/python/tf/estimator/WarmStartSettings) and [Estimators](https://www.tensorflow.org/guide/estimators).
-
-The second flag ```--fine_tune``` is a boolean that indicates whether earlier layers of the network should be frozen. You may set this flag to false if you wish to continue training a pre-trained model from a checkpoint. If you set this flag to true, you can train a new classification layer from scratch.
+* For the Keras version of the ResNet model, see
+  [`official/resnet/keras`](keras).
+* For the Keras custom training loop version, see
+  [`official/resnet/ctl`](ctl).
+* For the Estimator version, see [`official/r1/resnet`](../r1/resnet).
\ No newline at end of file
diff --git a/official/resnet/__init__.py b/official/resnet/__init__.py
index e69de29b..79fa34f8 100644
--- a/official/resnet/__init__.py
+++ b/official/resnet/__init__.py
@@ -0,0 +1,38 @@
+# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+# ==============================================================================
+
+"""Bring in the shared ResNet modules into this module.
+
+The TensorFlow v1 official models are moved under official/r1/resnet. In order
+to be backward compatible with models that directly import v1 modules, we import
+the v1 ResNet modules under official.resnet.
+
+New TF models should not depend on modules directly under this path (which will
+soon be deprecated and removed).
+"""
+
+from __future__ import absolute_import
+from __future__ import division
+from __future__ import print_function
+
+from official.r1.resnet import cifar10_main
+from official.r1.resnet import imagenet_main
+from official.r1.resnet import imagenet_preprocessing
+from official.r1.resnet import resnet_model
+from official.r1.resnet import resnet_run_loop
+
+del absolute_import
+del division
+del print_function
