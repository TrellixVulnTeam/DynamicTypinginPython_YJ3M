commit e1ac09e1fc9a6fb3ca3c36c5da6cb4539420a0f9
Author: Steven Hickson <me@stevenhickson.com>
Date:   Fri Jan 12 12:44:58 2018 -0500

    Updated cifar10_input.py to put the data augmentation into a name_scope named data_augmentation so the tensorboard graph is easier to read and more meaningful

diff --git a/tutorials/image/cifar10/cifar10_input.py b/tutorials/image/cifar10/cifar10_input.py
index 323f2f11..356a0347 100644
--- a/tutorials/image/cifar10/cifar10_input.py
+++ b/tutorials/image/cifar10/cifar10_input.py
@@ -157,44 +157,45 @@ def distorted_inputs(data_dir, batch_size):
   # Create a queue that produces the filenames to read.
   filename_queue = tf.train.string_input_producer(filenames)
 
-  # Read examples from files in the filename queue.
-  read_input = read_cifar10(filename_queue)
-  reshaped_image = tf.cast(read_input.uint8image, tf.float32)
-
-  height = IMAGE_SIZE
-  width = IMAGE_SIZE
-
-  # Image processing for training the network. Note the many random
-  # distortions applied to the image.
-
-  # Randomly crop a [height, width] section of the image.
-  distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
-
-  # Randomly flip the image horizontally.
-  distorted_image = tf.image.random_flip_left_right(distorted_image)
-
-  # Because these operations are not commutative, consider randomizing
-  # the order their operation.
-  # NOTE: since per_image_standardization zeros the mean and makes
-  # the stddev unit, this likely has no effect see tensorflow#1458.
-  distorted_image = tf.image.random_brightness(distorted_image,
-                                               max_delta=63)
-  distorted_image = tf.image.random_contrast(distorted_image,
-                                             lower=0.2, upper=1.8)
-
-  # Subtract off the mean and divide by the variance of the pixels.
-  float_image = tf.image.per_image_standardization(distorted_image)
-
-  # Set the shapes of tensors.
-  float_image.set_shape([height, width, 3])
-  read_input.label.set_shape([1])
-
-  # Ensure that the random shuffling has good mixing properties.
-  min_fraction_of_examples_in_queue = 0.4
-  min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *
-                           min_fraction_of_examples_in_queue)
-  print ('Filling queue with %d CIFAR images before starting to train. '
-         'This will take a few minutes.' % min_queue_examples)
+  with tf.name_scope('data_augmentation'):
+    # Read examples from files in the filename queue.
+    read_input = read_cifar10(filename_queue)
+    reshaped_image = tf.cast(read_input.uint8image, tf.float32)
+
+    height = IMAGE_SIZE
+    width = IMAGE_SIZE
+
+    # Image processing for training the network. Note the many random
+    # distortions applied to the image.
+
+    # Randomly crop a [height, width] section of the image.
+    distorted_image = tf.random_crop(reshaped_image, [height, width, 3])
+
+    # Randomly flip the image horizontally.
+    distorted_image = tf.image.random_flip_left_right(distorted_image)
+
+    # Because these operations are not commutative, consider randomizing
+    # the order their operation.
+    # NOTE: since per_image_standardization zeros the mean and makes
+    # the stddev unit, this likely has no effect see tensorflow#1458.
+    distorted_image = tf.image.random_brightness(distorted_image,
+                                                 max_delta=63)
+    distorted_image = tf.image.random_contrast(distorted_image,
+                                               lower=0.2, upper=1.8)
+
+    # Subtract off the mean and divide by the variance of the pixels.
+    float_image = tf.image.per_image_standardization(distorted_image)
+
+    # Set the shapes of tensors.
+    float_image.set_shape([height, width, 3])
+    read_input.label.set_shape([1])
+
+    # Ensure that the random shuffling has good mixing properties.
+    min_fraction_of_examples_in_queue = 0.4
+    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *
+                             min_fraction_of_examples_in_queue)
+    print ('Filling queue with %d CIFAR images before starting to train. '
+           'This will take a few minutes.' % min_queue_examples)
 
   # Generate a batch of images and labels by building up a queue of examples.
   return _generate_image_and_label_batch(float_image, read_input.label,
@@ -226,32 +227,33 @@ def inputs(eval_data, data_dir, batch_size):
     if not tf.gfile.Exists(f):
       raise ValueError('Failed to find file: ' + f)
 
-  # Create a queue that produces the filenames to read.
-  filename_queue = tf.train.string_input_producer(filenames)
+  with tf.name_scope('input'):
+    # Create a queue that produces the filenames to read.
+    filename_queue = tf.train.string_input_producer(filenames)
 
-  # Read examples from files in the filename queue.
-  read_input = read_cifar10(filename_queue)
-  reshaped_image = tf.cast(read_input.uint8image, tf.float32)
+    # Read examples from files in the filename queue.
+    read_input = read_cifar10(filename_queue)
+    reshaped_image = tf.cast(read_input.uint8image, tf.float32)
 
-  height = IMAGE_SIZE
-  width = IMAGE_SIZE
+    height = IMAGE_SIZE
+    width = IMAGE_SIZE
 
-  # Image processing for evaluation.
-  # Crop the central [height, width] of the image.
-  resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,
-                                                         height, width)
+    # Image processing for evaluation.
+    # Crop the central [height, width] of the image.
+    resized_image = tf.image.resize_image_with_crop_or_pad(reshaped_image,
+                                                           height, width)
 
-  # Subtract off the mean and divide by the variance of the pixels.
-  float_image = tf.image.per_image_standardization(resized_image)
+    # Subtract off the mean and divide by the variance of the pixels.
+    float_image = tf.image.per_image_standardization(resized_image)
 
-  # Set the shapes of tensors.
-  float_image.set_shape([height, width, 3])
-  read_input.label.set_shape([1])
+    # Set the shapes of tensors.
+    float_image.set_shape([height, width, 3])
+    read_input.label.set_shape([1])
 
-  # Ensure that the random shuffling has good mixing properties.
-  min_fraction_of_examples_in_queue = 0.4
-  min_queue_examples = int(num_examples_per_epoch *
-                           min_fraction_of_examples_in_queue)
+    # Ensure that the random shuffling has good mixing properties.
+    min_fraction_of_examples_in_queue = 0.4
+    min_queue_examples = int(num_examples_per_epoch *
+                             min_fraction_of_examples_in_queue)
 
   # Generate a batch of images and labels by building up a queue of examples.
   return _generate_image_and_label_batch(float_image, read_input.label,
