commit e0dade52dc470e8696556760516b65a5864e1f6d
Author: vivek rathod <rathodv@google.com>
Date:   Wed Jun 24 14:18:02 2020 -0700

    Merged commit includes the following changes: (#8728)
    
    318106429  by derekjchow:
    
        Add Dockerfiles for TF-OD API.
    
        1.15 and 2.2 supported currently.
    
    --
    318083650  by rathodv:
    
        Internal Change.
    
    --
    317893148  by Zhichao Lu:
    
        Fix mapping from proto fields to parameters of the data augmentation functions for horizontal flip, vertical flip and 90 degree rotations.
    
    --
    317753117  by Zhichao Lu:
    
        Adds keras hyperparam option to force use_bias to True, even when using batch norm.
    
    --
    317613986  by Zhichao Lu:
    
        Improves Keypoints support for data augmentation by means of 90 degree rotation adding an option to permute keypoints.
    
        Unify the interfaces among flip and rotation ops for data augmentation by exposing additional properties to the user.
    
    --
    317136881  by Zhichao Lu:
    
        Clarifying documentation
    
    --
    317097141  by Zhichao Lu:
    
        Adding Context R-CNN Release to TFODAPI ReadMe
    
    --
    316999744  by Zhichao Lu:
    
        Add import tensorflow.compat.v2 as tf2 in the model_lib to
        ensure tf1 compatibility.
    
    --
    316964482  by Zhichao Lu:
    
        adding a note about a config change needed for exporting detection features
    
    --
    316944293  by Zhichao Lu:
    
        Adding install instructions for apache beam
    
    --
    316917592  by lzc:
    
        Internal change.
    
    --
    
    PiperOrigin-RevId: 318106429
    
    Co-authored-by: Zhichao Lu <lzc@google.com>

diff --git a/research/object_detection/builders/hyperparams_builder.py b/research/object_detection/builders/hyperparams_builder.py
index f34e1112..90aef43a 100644
--- a/research/object_detection/builders/hyperparams_builder.py
+++ b/research/object_detection/builders/hyperparams_builder.py
@@ -64,6 +64,7 @@ class KerasLayerHyperparams(object):
       self._batch_norm_params = _build_keras_batch_norm_params(
           hyperparams_config.batch_norm)
 
+    self._force_use_bias = hyperparams_config.force_use_bias
     self._activation_fn = _build_activation_fn(hyperparams_config.activation)
     # TODO(kaftan): Unclear if these kwargs apply to separable & depthwise conv
     # (Those might use depthwise_* instead of kernel_*)
@@ -80,6 +81,13 @@ class KerasLayerHyperparams(object):
   def use_batch_norm(self):
     return self._batch_norm_params is not None
 
+  def force_use_bias(self):
+    return self._force_use_bias
+
+  def use_bias(self):
+    return (self._force_use_bias or not
+            (self.use_batch_norm() and self.batch_norm_params()['center']))
+
   def batch_norm_params(self, **overrides):
     """Returns a dict containing batchnorm layer construction hyperparameters.
 
@@ -168,10 +176,7 @@ class KerasLayerHyperparams(object):
     new_params['activation'] = None
     if include_activation:
       new_params['activation'] = self._activation_fn
-    if self.use_batch_norm() and self.batch_norm_params()['center']:
-      new_params['use_bias'] = False
-    else:
-      new_params['use_bias'] = True
+    new_params['use_bias'] = self.use_bias()
     new_params.update(**overrides)
     return new_params
 
@@ -210,6 +215,10 @@ def build(hyperparams_config, is_training):
     raise ValueError('hyperparams_config not of type '
                      'hyperparams_pb.Hyperparams.')
 
+  if hyperparams_config.force_use_bias:
+    raise ValueError('Hyperparams force_use_bias only supported by '
+                     'KerasLayerHyperparams.')
+
   normalizer_fn = None
   batch_norm_params = None
   if hyperparams_config.HasField('batch_norm'):
diff --git a/research/object_detection/builders/hyperparams_builder_test.py b/research/object_detection/builders/hyperparams_builder_test.py
index 2c6fcd5a..e48ac23b 100644
--- a/research/object_detection/builders/hyperparams_builder_test.py
+++ b/research/object_detection/builders/hyperparams_builder_test.py
@@ -667,6 +667,67 @@ class KerasHyperparamsBuilderTest(tf.test.TestCase):
     self.assertIsInstance(identity_layer,
                           tf.keras.layers.Lambda)
 
+  def test_do_not_use_bias_if_batch_norm_center_keras(self):
+    conv_hyperparams_text_proto = """
+      regularizer {
+        l2_regularizer {
+        }
+      }
+      initializer {
+        truncated_normal_initializer {
+        }
+      }
+      batch_norm {
+        decay: 0.7
+        center: true
+        scale: true
+        epsilon: 0.03
+        train: true
+      }
+    """
+    conv_hyperparams_proto = hyperparams_pb2.Hyperparams()
+    text_format.Merge(conv_hyperparams_text_proto, conv_hyperparams_proto)
+    keras_config = hyperparams_builder.KerasLayerHyperparams(
+        conv_hyperparams_proto)
+
+    self.assertTrue(keras_config.use_batch_norm())
+    batch_norm_params = keras_config.batch_norm_params()
+    self.assertTrue(batch_norm_params['center'])
+    self.assertTrue(batch_norm_params['scale'])
+    hyperparams = keras_config.params()
+    self.assertFalse(hyperparams['use_bias'])
+
+  def test_force_use_bias_if_batch_norm_center_keras(self):
+    conv_hyperparams_text_proto = """
+      regularizer {
+        l2_regularizer {
+        }
+      }
+      initializer {
+        truncated_normal_initializer {
+        }
+      }
+      batch_norm {
+        decay: 0.7
+        center: true
+        scale: true
+        epsilon: 0.03
+        train: true
+      }
+      force_use_bias: true
+    """
+    conv_hyperparams_proto = hyperparams_pb2.Hyperparams()
+    text_format.Merge(conv_hyperparams_text_proto, conv_hyperparams_proto)
+    keras_config = hyperparams_builder.KerasLayerHyperparams(
+        conv_hyperparams_proto)
+
+    self.assertTrue(keras_config.use_batch_norm())
+    batch_norm_params = keras_config.batch_norm_params()
+    self.assertTrue(batch_norm_params['center'])
+    self.assertTrue(batch_norm_params['scale'])
+    hyperparams = keras_config.params()
+    self.assertTrue(hyperparams['use_bias'])
+
   def test_use_none_activation_keras(self):
     conv_hyperparams_text_proto = """
       regularizer {
diff --git a/research/object_detection/builders/preprocessor_builder.py b/research/object_detection/builders/preprocessor_builder.py
index aa6a6bc9..fe59039b 100644
--- a/research/object_detection/builders/preprocessor_builder.py
+++ b/research/object_detection/builders/preprocessor_builder.py
@@ -151,6 +151,7 @@ def build(preprocessor_step_config):
             {
                 'keypoint_flip_permutation': tuple(
                     config.keypoint_flip_permutation) or None,
+                'probability': config.probability or None,
             })
 
   if step_type == 'random_vertical_flip':
@@ -159,10 +160,17 @@ def build(preprocessor_step_config):
             {
                 'keypoint_flip_permutation': tuple(
                     config.keypoint_flip_permutation) or None,
+                'probability': config.probability or None,
             })
 
   if step_type == 'random_rotation90':
-    return (preprocessor.random_rotation90, {})
+    config = preprocessor_step_config.random_rotation90
+    return (preprocessor.random_rotation90,
+            {
+                'keypoint_rot_permutation': tuple(
+                    config.keypoint_rot_permutation) or None,
+                'probability': config.probability or None,
+            })
 
   if step_type == 'random_crop_image':
     config = preprocessor_step_config.random_crop_image
diff --git a/research/object_detection/builders/preprocessor_builder_test.py b/research/object_detection/builders/preprocessor_builder_test.py
index 4c283238..9e90344d 100644
--- a/research/object_detection/builders/preprocessor_builder_test.py
+++ b/research/object_detection/builders/preprocessor_builder_test.py
@@ -65,13 +65,15 @@ class PreprocessorBuilderTest(tf.test.TestCase):
       keypoint_flip_permutation: 3
       keypoint_flip_permutation: 5
       keypoint_flip_permutation: 4
+      probability: 0.5
     }
     """
     preprocessor_proto = preprocessor_pb2.PreprocessingStep()
     text_format.Merge(preprocessor_text_proto, preprocessor_proto)
     function, args = preprocessor_builder.build(preprocessor_proto)
     self.assertEqual(function, preprocessor.random_horizontal_flip)
-    self.assertEqual(args, {'keypoint_flip_permutation': (1, 0, 2, 3, 5, 4)})
+    self.assertEqual(args, {'keypoint_flip_permutation': (1, 0, 2, 3, 5, 4),
+                            'probability': 0.5})
 
   def test_build_random_vertical_flip(self):
     preprocessor_text_proto = """
@@ -82,23 +84,32 @@ class PreprocessorBuilderTest(tf.test.TestCase):
       keypoint_flip_permutation: 3
       keypoint_flip_permutation: 5
       keypoint_flip_permutation: 4
+      probability: 0.5
     }
     """
     preprocessor_proto = preprocessor_pb2.PreprocessingStep()
     text_format.Merge(preprocessor_text_proto, preprocessor_proto)
     function, args = preprocessor_builder.build(preprocessor_proto)
     self.assertEqual(function, preprocessor.random_vertical_flip)
-    self.assertEqual(args, {'keypoint_flip_permutation': (1, 0, 2, 3, 5, 4)})
+    self.assertEqual(args, {'keypoint_flip_permutation': (1, 0, 2, 3, 5, 4),
+                            'probability': 0.5})
 
   def test_build_random_rotation90(self):
     preprocessor_text_proto = """
-    random_rotation90 {}
+    random_rotation90 {
+      keypoint_rot_permutation: 3
+      keypoint_rot_permutation: 0
+      keypoint_rot_permutation: 1
+      keypoint_rot_permutation: 2
+      probability: 0.5
+    }
     """
     preprocessor_proto = preprocessor_pb2.PreprocessingStep()
     text_format.Merge(preprocessor_text_proto, preprocessor_proto)
     function, args = preprocessor_builder.build(preprocessor_proto)
     self.assertEqual(function, preprocessor.random_rotation90)
-    self.assertEqual(args, {})
+    self.assertEqual(args, {'keypoint_rot_permutation': (3, 0, 1, 2),
+                            'probability': 0.5})
 
   def test_build_random_pixel_value_scale(self):
     preprocessor_text_proto = """
diff --git a/research/object_detection/core/keypoint_ops.py b/research/object_detection/core/keypoint_ops.py
index e321783d..1b0c4ccf 100644
--- a/research/object_detection/core/keypoint_ops.py
+++ b/research/object_detection/core/keypoint_ops.py
@@ -217,7 +217,7 @@ def to_absolute_coordinates(keypoints, height, width,
     return scale(keypoints, height, width)
 
 
-def flip_horizontal(keypoints, flip_point, flip_permutation, scope=None):
+def flip_horizontal(keypoints, flip_point, flip_permutation=None, scope=None):
   """Flips the keypoints horizontally around the flip_point.
 
   This operation flips the x coordinate for each keypoint around the flip_point
@@ -227,13 +227,14 @@ def flip_horizontal(keypoints, flip_point, flip_permutation, scope=None):
     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
     flip_point:  (float) scalar tensor representing the x coordinate to flip the
       keypoints around.
-    flip_permutation: rank 1 int32 tensor containing the keypoint flip
-      permutation. This specifies the mapping from original keypoint indices
-      to the flipped keypoint indices. This is used primarily for keypoints
-      that are not reflection invariant. E.g. Suppose there are 3 keypoints
-      representing ['head', 'right_eye', 'left_eye'], then a logical choice for
-      flip_permutation might be [0, 2, 1] since we want to swap the 'left_eye'
-      and 'right_eye' after a horizontal flip.
+    flip_permutation: integer list or rank 1 int32 tensor containing the
+      keypoint flip permutation. This specifies the mapping from original
+      keypoint indices to the flipped keypoint indices. This is used primarily
+      for keypoints that are not reflection invariant. E.g. Suppose there are 3
+      keypoints representing ['head', 'right_eye', 'left_eye'], then a logical
+      choice for flip_permutation might be [0, 2, 1] since we want to swap the
+      'left_eye' and 'right_eye' after a horizontal flip.
+      Default to None or empty list to keep the original order after flip.
     scope: name scope.
 
   Returns:
@@ -241,7 +242,8 @@ def flip_horizontal(keypoints, flip_point, flip_permutation, scope=None):
   """
   with tf.name_scope(scope, 'FlipHorizontal'):
     keypoints = tf.transpose(keypoints, [1, 0, 2])
-    keypoints = tf.gather(keypoints, flip_permutation)
+    if flip_permutation:
+      keypoints = tf.gather(keypoints, flip_permutation)
     v, u = tf.split(value=keypoints, num_or_size_splits=2, axis=2)
     u = flip_point * 2.0 - u
     new_keypoints = tf.concat([v, u], 2)
@@ -249,7 +251,7 @@ def flip_horizontal(keypoints, flip_point, flip_permutation, scope=None):
     return new_keypoints
 
 
-def flip_vertical(keypoints, flip_point, flip_permutation, scope=None):
+def flip_vertical(keypoints, flip_point, flip_permutation=None, scope=None):
   """Flips the keypoints vertically around the flip_point.
 
   This operation flips the y coordinate for each keypoint around the flip_point
@@ -259,13 +261,14 @@ def flip_vertical(keypoints, flip_point, flip_permutation, scope=None):
     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
     flip_point:  (float) scalar tensor representing the y coordinate to flip the
       keypoints around.
-    flip_permutation: rank 1 int32 tensor containing the keypoint flip
-      permutation. This specifies the mapping from original keypoint indices
-      to the flipped keypoint indices. This is used primarily for keypoints
-      that are not reflection invariant. E.g. Suppose there are 3 keypoints
-      representing ['head', 'right_eye', 'left_eye'], then a logical choice for
-      flip_permutation might be [0, 2, 1] since we want to swap the 'left_eye'
-      and 'right_eye' after a horizontal flip.
+    flip_permutation: integer list or rank 1 int32 tensor containing the
+      keypoint flip permutation. This specifies the mapping from original
+      keypoint indices to the flipped keypoint indices. This is used primarily
+      for keypoints that are not reflection invariant. E.g. Suppose there are 3
+      keypoints representing ['head', 'right_eye', 'left_eye'], then a logical
+      choice for flip_permutation might be [0, 2, 1] since we want to swap the
+      'left_eye' and 'right_eye' after a horizontal flip.
+      Default to None or empty list to keep the original order after flip.
     scope: name scope.
 
   Returns:
@@ -273,7 +276,8 @@ def flip_vertical(keypoints, flip_point, flip_permutation, scope=None):
   """
   with tf.name_scope(scope, 'FlipVertical'):
     keypoints = tf.transpose(keypoints, [1, 0, 2])
-    keypoints = tf.gather(keypoints, flip_permutation)
+    if flip_permutation:
+      keypoints = tf.gather(keypoints, flip_permutation)
     v, u = tf.split(value=keypoints, num_or_size_splits=2, axis=2)
     v = flip_point * 2.0 - v
     new_keypoints = tf.concat([v, u], 2)
@@ -281,18 +285,24 @@ def flip_vertical(keypoints, flip_point, flip_permutation, scope=None):
     return new_keypoints
 
 
-def rot90(keypoints, scope=None):
+def rot90(keypoints, rotation_permutation=None, scope=None):
   """Rotates the keypoints counter-clockwise by 90 degrees.
 
   Args:
     keypoints: a tensor of shape [num_instances, num_keypoints, 2]
+    rotation_permutation:  integer list or rank 1 int32 tensor containing the
+      keypoint flip permutation. This specifies the mapping from original
+      keypoint indices to the rotated keypoint indices. This is used primarily
+      for keypoints that are not rotation invariant.
+      Default to None or empty list to keep the original order after rotation.
     scope: name scope.
-
   Returns:
     new_keypoints: a tensor of shape [num_instances, num_keypoints, 2]
   """
   with tf.name_scope(scope, 'Rot90'):
     keypoints = tf.transpose(keypoints, [1, 0, 2])
+    if rotation_permutation:
+      keypoints = tf.gather(keypoints, rotation_permutation)
     v, u = tf.split(value=keypoints[:, :, ::-1], num_or_size_splits=2, axis=2)
     v = 1.0 - v
     new_keypoints = tf.concat([v, u], 2)
diff --git a/research/object_detection/core/keypoint_ops_test.py b/research/object_detection/core/keypoint_ops_test.py
index 695e8fa1..bbdcf019 100644
--- a/research/object_detection/core/keypoint_ops_test.py
+++ b/research/object_detection/core/keypoint_ops_test.py
@@ -180,6 +180,21 @@ class KeypointOpsTest(test_case.TestCase):
           [[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]],
           [[0.4, 0.4], [0.5, 0.5], [0.6, 0.6]]
       ])
+      expected_keypoints = tf.constant([
+          [[0.1, 0.9], [0.2, 0.8], [0.3, 0.7]],
+          [[0.4, 0.6], [0.5, 0.5], [0.6, 0.4]],
+      ])
+      output = keypoint_ops.flip_horizontal(keypoints, 0.5)
+      return output, expected_keypoints
+
+    output, expected_keypoints = self.execute(graph_fn, [])
+    self.assertAllClose(output, expected_keypoints)
+
+  def test_flip_horizontal_permutation(self):
+
+    def graph_fn():
+      keypoints = tf.constant([[[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]],
+                               [[0.4, 0.4], [0.5, 0.5], [0.6, 0.6]]])
       flip_permutation = [0, 2, 1]
 
       expected_keypoints = tf.constant([
@@ -197,6 +212,22 @@ class KeypointOpsTest(test_case.TestCase):
           [[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]],
           [[0.4, 0.4], [0.5, 0.5], [0.6, 0.6]]
       ])
+
+      expected_keypoints = tf.constant([
+          [[0.9, 0.1], [0.8, 0.2], [0.7, 0.3]],
+          [[0.6, 0.4], [0.5, 0.5], [0.4, 0.6]],
+      ])
+      output = keypoint_ops.flip_vertical(keypoints, 0.5)
+      return output, expected_keypoints
+
+    output, expected_keypoints = self.execute(graph_fn, [])
+    self.assertAllClose(output, expected_keypoints)
+
+  def test_flip_vertical_permutation(self):
+
+    def graph_fn():
+      keypoints = tf.constant([[[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]],
+                               [[0.4, 0.4], [0.5, 0.5], [0.6, 0.6]]])
       flip_permutation = [0, 2, 1]
 
       expected_keypoints = tf.constant([
@@ -223,6 +254,23 @@ class KeypointOpsTest(test_case.TestCase):
     output, expected_keypoints = self.execute(graph_fn, [])
     self.assertAllClose(output, expected_keypoints)
 
+  def test_rot90_permutation(self):
+
+    def graph_fn():
+      keypoints = tf.constant([[[0.1, 0.1], [0.2, 0.2], [0.3, 0.3]],
+                               [[0.4, 0.6], [0.5, 0.6], [0.6, 0.7]]])
+      rot_permutation = [0, 2, 1]
+      expected_keypoints = tf.constant([
+          [[0.9, 0.1], [0.7, 0.3], [0.8, 0.2]],
+          [[0.4, 0.4], [0.3, 0.6], [0.4, 0.5]],
+      ])
+      output = keypoint_ops.rot90(keypoints,
+                                  rotation_permutation=rot_permutation)
+      return output, expected_keypoints
+
+    output, expected_keypoints = self.execute(graph_fn, [])
+    self.assertAllClose(output, expected_keypoints)
+
   def test_keypoint_weights_from_visibilities(self):
     def graph_fn():
       keypoint_visibilities = tf.constant([
diff --git a/research/object_detection/core/preprocessor.py b/research/object_detection/core/preprocessor.py
index 8b8fdff5..a1e7ed02 100644
--- a/research/object_detection/core/preprocessor.py
+++ b/research/object_detection/core/preprocessor.py
@@ -569,12 +569,11 @@ def random_horizontal_flip(image,
                            keypoints=None,
                            keypoint_visibilities=None,
                            keypoint_flip_permutation=None,
+                           probability=0.5,
                            seed=None,
                            preprocess_vars_cache=None):
   """Randomly flips the image and detections horizontally.
 
-  The probability of flipping the image is 50%.
-
   Args:
     image: rank 3 float32 tensor with shape [height, width, channels].
     boxes: (optional) rank 2 float32 tensor with shape [N, 4]
@@ -592,6 +591,7 @@ def random_horizontal_flip(image,
                            [num_instances, num_keypoints].
     keypoint_flip_permutation: rank 1 int32 tensor containing the keypoint flip
                                permutation.
+    probability: the probability of performing this augmentation.
     seed: random seed
     preprocess_vars_cache: PreprocessorCache object that records previously
                            performed augmentations. Updated in-place. If this
@@ -636,7 +636,7 @@ def random_horizontal_flip(image,
         generator_func,
         preprocessor_cache.PreprocessorCache.HORIZONTAL_FLIP,
         preprocess_vars_cache)
-    do_a_flip_random = tf.greater(do_a_flip_random, 0.5)
+    do_a_flip_random = tf.less(do_a_flip_random, probability)
 
     # flip image
     image = tf.cond(do_a_flip_random, lambda: _flip_image(image), lambda: image)
@@ -682,6 +682,7 @@ def random_vertical_flip(image,
                          masks=None,
                          keypoints=None,
                          keypoint_flip_permutation=None,
+                         probability=0.5,
                          seed=None,
                          preprocess_vars_cache=None):
   """Randomly flips the image and detections vertically.
@@ -703,6 +704,7 @@ def random_vertical_flip(image,
                normalized coordinates.
     keypoint_flip_permutation: rank 1 int32 tensor containing the keypoint flip
                                permutation.
+    probability: the probability of performing this augmentation.
     seed: random seed
     preprocess_vars_cache: PreprocessorCache object that records previously
                            performed augmentations. Updated in-place. If this
@@ -743,7 +745,7 @@ def random_vertical_flip(image,
     do_a_flip_random = _get_or_create_preprocess_rand_vars(
         generator_func, preprocessor_cache.PreprocessorCache.VERTICAL_FLIP,
         preprocess_vars_cache)
-    do_a_flip_random = tf.greater(do_a_flip_random, 0.5)
+    do_a_flip_random = tf.less(do_a_flip_random, probability)
 
     # flip image
     image = tf.cond(do_a_flip_random, lambda: _flip_image(image), lambda: image)
@@ -777,6 +779,8 @@ def random_rotation90(image,
                       boxes=None,
                       masks=None,
                       keypoints=None,
+                      keypoint_rot_permutation=None,
+                      probability=0.5,
                       seed=None,
                       preprocess_vars_cache=None):
   """Randomly rotates the image and detections 90 degrees counter-clockwise.
@@ -799,6 +803,9 @@ def random_rotation90(image,
     keypoints: (optional) rank 3 float32 tensor with shape
                [num_instances, num_keypoints, 2]. The keypoints are in y-x
                normalized coordinates.
+    keypoint_rot_permutation: rank 1 int32 tensor containing the keypoint flip
+                              permutation.
+    probability: the probability of performing this augmentation.
     seed: random seed
     preprocess_vars_cache: PreprocessorCache object that records previously
                            performed augmentations. Updated in-place. If this
@@ -833,7 +840,7 @@ def random_rotation90(image,
     do_a_rot90_random = _get_or_create_preprocess_rand_vars(
         generator_func, preprocessor_cache.PreprocessorCache.ROTATION90,
         preprocess_vars_cache)
-    do_a_rot90_random = tf.greater(do_a_rot90_random, 0.5)
+    do_a_rot90_random = tf.less(do_a_rot90_random, probability)
 
     # flip image
     image = tf.cond(do_a_rot90_random, lambda: _rot90_image(image),
@@ -856,7 +863,7 @@ def random_rotation90(image,
     if keypoints is not None:
       keypoints = tf.cond(
           do_a_rot90_random,
-          lambda: keypoint_ops.rot90(keypoints),
+          lambda: keypoint_ops.rot90(keypoints, keypoint_rot_permutation),
           lambda: keypoints)
       result.append(keypoints)
 
diff --git a/research/object_detection/core/preprocessor_test.py b/research/object_detection/core/preprocessor_test.py
index fdb56c90..5ebfe9ee 100644
--- a/research/object_detection/core/preprocessor_test.py
+++ b/research/object_detection/core/preprocessor_test.py
@@ -120,7 +120,10 @@ class PreprocessorTest(test_case.TestCase, parameterized.TestCase):
     return tf.constant(keypoints, dtype=tf.float32)
 
   def createKeypointFlipPermutation(self):
-    return np.array([0, 2, 1], dtype=np.int32)
+    return [0, 2, 1]
+
+  def createKeypointRotPermutation(self):
+    return [0, 2, 1]
 
   def createTestLabels(self):
     labels = tf.constant([1, 2], dtype=tf.int32)
@@ -912,19 +915,22 @@ class PreprocessorTest(test_case.TestCase, parameterized.TestCase):
                                 test_keypoints=True)
 
   def testRunRandomRotation90WithMaskAndKeypoints(self):
-    preprocess_options = [(preprocessor.random_rotation90, {})]
     image_height = 3
     image_width = 3
     images = tf.random_uniform([1, image_height, image_width, 3])
     boxes = self.createTestBoxes()
     masks = self.createTestMasks()
     keypoints, _ = self.createTestKeypoints()
+    keypoint_rot_permutation = self.createKeypointRotPermutation()
     tensor_dict = {
         fields.InputDataFields.image: images,
         fields.InputDataFields.groundtruth_boxes: boxes,
         fields.InputDataFields.groundtruth_instance_masks: masks,
         fields.InputDataFields.groundtruth_keypoints: keypoints
     }
+    preprocess_options = [(preprocessor.random_rotation90, {
+        'keypoint_rot_permutation': keypoint_rot_permutation
+    })]
     preprocessor_arg_map = preprocessor.get_default_func_arg_map(
         include_instance_masks=True, include_keypoints=True)
     tensor_dict = preprocessor.preprocess(
diff --git a/research/object_detection/dockerfiles/1.15/Dockerfile b/research/object_detection/dockerfiles/1.15/Dockerfile
new file mode 100644
index 00000000..76c0c1f0
--- /dev/null
+++ b/research/object_detection/dockerfiles/1.15/Dockerfile
@@ -0,0 +1,44 @@
+FROM tensorflow/tensorflow:1.15.2-gpu-py3
+
+ARG DEBIAN_FRONTEND=noninteractive
+
+# Install apt dependencies
+RUN apt-get update && apt-get install -y \
+    git \
+    gpg-agent \
+    python3-cairocffi \
+    protobuf-compiler \
+    python3-pil \
+    python3-lxml \
+    python3-tk \
+    wget
+
+# Install gcloud and gsutil commands
+# https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu
+RUN export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)" && \
+    echo "deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
+    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
+    apt-get update -y && apt-get install google-cloud-sdk -y
+
+# Add new user to avoid running as root
+RUN useradd -ms /bin/bash tensorflow
+USER tensorflow
+WORKDIR /home/tensorflow
+
+# Install pip dependencies
+RUN pip3 install --user absl-py
+RUN pip3 install --user contextlib2
+RUN pip3 install --user Cython
+RUN pip3 install --user jupyter
+RUN pip3 install --user matplotlib
+RUN pip3 install --user pycocotools
+RUN pip3 install --user tf-slim
+
+# Copy this version of of the model garden into the image
+COPY --chown=tensorflow . /home/tensorflow/models
+
+# Compile protobuf configs
+RUN (cd /home/tensorflow/models/research/ && protoc object_detection/protos/*.proto --python_out=.)
+
+ENV PYTHONPATH $PYTHONPATH:/home/tensorflow/models/research/:/home/tensorflow/models/research/slim
+ENV TF_CPP_MIN_LOG_LEVEL 3
diff --git a/research/object_detection/dockerfiles/1.15/README.md b/research/object_detection/dockerfiles/1.15/README.md
new file mode 100644
index 00000000..5e3e6d05
--- /dev/null
+++ b/research/object_detection/dockerfiles/1.15/README.md
@@ -0,0 +1,11 @@
+# Tensorflow Object Detection on Docker
+
+These instructions are experimental.
+
+## Building and running:
+
+```bash
+# From the root of the git repository
+docker build -f research/object_detection/dockerfiles/1.15/Dockerfile -t od .
+docker run -it od
+```
diff --git a/research/object_detection/dockerfiles/2.2/Dockerfile b/research/object_detection/dockerfiles/2.2/Dockerfile
new file mode 100644
index 00000000..c3d5e2e8
--- /dev/null
+++ b/research/object_detection/dockerfiles/2.2/Dockerfile
@@ -0,0 +1,44 @@
+FROM tensorflow/tensorflow:2.2.0-gpu
+
+ARG DEBIAN_FRONTEND=noninteractive
+
+# Install apt dependencies
+RUN apt-get update && apt-get install -y \
+    git \
+    gpg-agent \
+    python3-cairocffi \
+    protobuf-compiler \
+    python3-pil \
+    python3-lxml \
+    python3-tk \
+    wget
+
+# Install gcloud and gsutil commands
+# https://cloud.google.com/sdk/docs/quickstart-debian-ubuntu
+RUN export CLOUD_SDK_REPO="cloud-sdk-$(lsb_release -c -s)" && \
+    echo "deb http://packages.cloud.google.com/apt $CLOUD_SDK_REPO main" | tee -a /etc/apt/sources.list.d/google-cloud-sdk.list && \
+    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add - && \
+    apt-get update -y && apt-get install google-cloud-sdk -y
+
+# Add new user to avoid running as root
+RUN useradd -ms /bin/bash tensorflow
+USER tensorflow
+WORKDIR /home/tensorflow
+
+# Install pip dependencies
+RUN pip3 install --user absl-py
+RUN pip3 install --user contextlib2
+RUN pip3 install --user Cython
+RUN pip3 install --user jupyter
+RUN pip3 install --user matplotlib
+RUN pip3 install --user pycocotools
+RUN pip3 install --user tf-slim
+
+# Copy this version of of the model garden into the image
+COPY --chown=tensorflow . /home/tensorflow/models
+
+# Compile protobuf configs
+RUN (cd /home/tensorflow/models/research/ && protoc object_detection/protos/*.proto --python_out=.)
+
+ENV PYTHONPATH $PYTHONPATH:/home/tensorflow/models/research/:/home/tensorflow/models/research/slim
+ENV TF_CPP_MIN_LOG_LEVEL 3
diff --git a/research/object_detection/dockerfiles/2.2/README.md b/research/object_detection/dockerfiles/2.2/README.md
new file mode 100644
index 00000000..58b58db8
--- /dev/null
+++ b/research/object_detection/dockerfiles/2.2/README.md
@@ -0,0 +1,11 @@
+# Tensorflow Object Detection on Docker
+
+These instructions are experimental.
+
+## Building and running:
+
+```bash
+# From the root of the git repository
+docker build -f research/object_detection/dockerfiles/2.2/Dockerfile -t od .
+docker run -it od
+```
diff --git a/research/object_detection/model_lib_tf2_test.py b/research/object_detection/model_lib_tf2_test.py
index 8c6d9617..4e9b5a82 100644
--- a/research/object_detection/model_lib_tf2_test.py
+++ b/research/object_detection/model_lib_tf2_test.py
@@ -24,9 +24,9 @@ import unittest
 import numpy as np
 import six
 import tensorflow.compat.v1 as tf
+import tensorflow.compat.v2 as tf2
 
 from object_detection import inputs
-from object_detection import model_hparams
 from object_detection import model_lib_v2
 from object_detection.builders import model_builder
 from object_detection.core import model
@@ -82,24 +82,25 @@ class ModelLibTest(tf.test.TestCase):
 
   def test_train_loop_then_eval_loop(self):
     """Tests that Estimator and input function are constructed correctly."""
-    hparams = model_hparams.create_hparams(
-        hparams_overrides='load_pretrained=false')
+    model_dir = tf.test.get_temp_dir()
     pipeline_config_path = get_pipeline_config_path(MODEL_NAME_FOR_TEST)
+    new_pipeline_config_path = os.path.join(model_dir, 'new_pipeline.config')
+    config_util.clear_fine_tune_checkpoint(pipeline_config_path,
+                                           new_pipeline_config_path)
     config_kwarg_overrides = _get_config_kwarg_overrides()
-    model_dir = tf.test.get_temp_dir()
 
     train_steps = 2
-    model_lib_v2.train_loop(
-        hparams,
-        pipeline_config_path,
-        model_dir=model_dir,
-        train_steps=train_steps,
-        checkpoint_every_n=1,
-        **config_kwarg_overrides)
+    strategy = tf2.distribute.OneDeviceStrategy(device='/cpu:0')
+    with strategy.scope():
+      model_lib_v2.train_loop(
+          new_pipeline_config_path,
+          model_dir=model_dir,
+          train_steps=train_steps,
+          checkpoint_every_n=1,
+          **config_kwarg_overrides)
 
     model_lib_v2.eval_continuously(
-        hparams,
-        pipeline_config_path,
+        new_pipeline_config_path,
         model_dir=model_dir,
         checkpoint_dir=model_dir,
         train_steps=train_steps,
@@ -148,21 +149,24 @@ class ModelCheckpointTest(tf.test.TestCase):
   def test_checkpoint_max_to_keep(self):
     """Test that only the most recent checkpoints are kept."""
 
+    strategy = tf2.distribute.OneDeviceStrategy(device='/cpu:0')
     with mock.patch.object(
         model_builder, 'build', autospec=True) as mock_builder:
-      mock_builder.return_value = SimpleModel()
-
-      hparams = model_hparams.create_hparams(
-          hparams_overrides='load_pretrained=false')
+      with strategy.scope():
+        mock_builder.return_value = SimpleModel()
+      model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
       pipeline_config_path = get_pipeline_config_path(MODEL_NAME_FOR_TEST)
+      new_pipeline_config_path = os.path.join(model_dir, 'new_pipeline.config')
+      config_util.clear_fine_tune_checkpoint(pipeline_config_path,
+                                             new_pipeline_config_path)
       config_kwarg_overrides = _get_config_kwarg_overrides()
-      model_dir = tempfile.mkdtemp(dir=self.get_temp_dir())
 
-      model_lib_v2.train_loop(
-          hparams, pipeline_config_path, model_dir=model_dir,
-          train_steps=20, checkpoint_every_n=2, checkpoint_max_to_keep=3,
-          **config_kwarg_overrides
-      )
+      with strategy.scope():
+        model_lib_v2.train_loop(
+            new_pipeline_config_path, model_dir=model_dir,
+            train_steps=20, checkpoint_every_n=2, checkpoint_max_to_keep=3,
+            **config_kwarg_overrides
+        )
       ckpt_files = tf.io.gfile.glob(os.path.join(model_dir, 'ckpt-*.index'))
       self.assertEqual(len(ckpt_files), 3,
                        '{} not of length 3.'.format(ckpt_files))
@@ -221,3 +225,5 @@ class CheckpointV2Test(tf.test.TestCase):
           unpad_groundtruth_tensors=True)
 
 
+if __name__ == '__main__':
+  tf.test.main()
diff --git a/research/object_detection/model_lib_v2.py b/research/object_detection/model_lib_v2.py
index 29eb5a29..6a764d17 100644
--- a/research/object_detection/model_lib_v2.py
+++ b/research/object_detection/model_lib_v2.py
@@ -392,14 +392,12 @@ def clean_temporary_directories(strategy, filepath):
 
 
 def train_loop(
-    hparams,
     pipeline_config_path,
     model_dir,
     config_override=None,
     train_steps=None,
     use_tpu=False,
     save_final_config=False,
-    export_to_tpu=None,
     checkpoint_every_n=1000,
     checkpoint_max_to_keep=7,
     **kwargs):
@@ -417,7 +415,6 @@ def train_loop(
     8. Logs the training metrics as TensorBoard summaries.
 
   Args:
-    hparams: A `HParams`.
     pipeline_config_path: A path to a pipeline config file.
     model_dir:
       The directory to save checkpoints and summaries to.
@@ -428,10 +425,6 @@ def train_loop(
     use_tpu: Boolean, whether training and evaluation should run on TPU.
     save_final_config: Whether to save final config (obtained after applying
       overrides) to `model_dir`.
-    export_to_tpu: When use_tpu and export_to_tpu are true,
-      `export_savedmodel()` exports a metagraph for serving on TPU besides the
-      one on CPU. If export_to_tpu is not provided, we will look for it in
-      hparams too.
     checkpoint_every_n:
       Checkpoint every n training steps.
     checkpoint_max_to_keep:
@@ -453,7 +446,7 @@ def train_loop(
       'use_bfloat16': configs['train_config'].use_bfloat16 and use_tpu
   })
   configs = merge_external_params_with_configs(
-      configs, hparams, kwargs_dict=kwargs)
+      configs, None, kwargs_dict=kwargs)
   model_config = configs['model']
   train_config = configs['train_config']
   train_input_config = configs['train_input_config']
@@ -468,33 +461,12 @@ def train_loop(
   if train_steps is None and train_config.num_steps != 0:
     train_steps = train_config.num_steps
 
-  # Read export_to_tpu from hparams if not passed.
-  if export_to_tpu is None:
-    export_to_tpu = hparams.get('export_to_tpu', False)
-  tf.logging.info(
-      'train_loop: use_tpu %s, export_to_tpu %s', use_tpu,
-      export_to_tpu)
-
   if kwargs['use_bfloat16']:
     tf.compat.v2.keras.mixed_precision.experimental.set_policy('mixed_bfloat16')
 
-  # Parse the checkpoint fine tuning configs
-  if hparams.load_pretrained:
-    fine_tune_checkpoint_path = train_config.fine_tune_checkpoint
-  else:
-    fine_tune_checkpoint_path = None
   load_all_detection_checkpoint_vars = (
       train_config.load_all_detection_checkpoint_vars)
-  # TODO(kaftan) (or anyone else): move this piece of config munging to
-  ## utils/config_util.py
-  if not train_config.fine_tune_checkpoint_type:
-    # train_config.from_detection_checkpoint field is deprecated. For
-    # backward compatibility, set train_config.fine_tune_checkpoint_type
-    # based on train_config.from_detection_checkpoint.
-    if train_config.from_detection_checkpoint:
-      train_config.fine_tune_checkpoint_type = 'detection'
-    else:
-      train_config.fine_tune_checkpoint_type = 'classification'
+  config_util.update_fine_tune_checkpoint_type(train_config)
   fine_tune_checkpoint_type = train_config.fine_tune_checkpoint_type
   fine_tune_checkpoint_version = train_config.fine_tune_checkpoint_version
 
@@ -556,8 +528,9 @@ def train_loop(
       with tf.compat.v2.summary.record_if(
           lambda: global_step % num_steps_per_iteration == 0):
         # Load a fine-tuning checkpoint.
-        if fine_tune_checkpoint_path:
-          load_fine_tune_checkpoint(detection_model, fine_tune_checkpoint_path,
+        if train_config.fine_tune_checkpoint:
+          load_fine_tune_checkpoint(detection_model,
+                                    train_config.fine_tune_checkpoint,
                                     fine_tune_checkpoint_type,
                                     fine_tune_checkpoint_version,
                                     load_all_detection_checkpoint_vars,
@@ -841,7 +814,6 @@ def eager_eval_loop(
 
 
 def eval_continuously(
-    hparams,
     pipeline_config_path,
     config_override=None,
     train_steps=None,
@@ -850,7 +822,6 @@ def eval_continuously(
     use_tpu=False,
     override_eval_num_epochs=True,
     postprocess_on_cpu=False,
-    export_to_tpu=None,
     model_dir=None,
     checkpoint_dir=None,
     wait_interval=180,
@@ -863,7 +834,6 @@ def eval_continuously(
   on the evaluation data.
 
   Args:
-    hparams: A `HParams`.
     pipeline_config_path: A path to a pipeline config file.
     config_override: A pipeline_pb2.TrainEvalPipelineConfig text proto to
       override the config from `pipeline_config_path`.
@@ -879,10 +849,6 @@ def eval_continuously(
       eval_input.
     postprocess_on_cpu: When use_tpu and postprocess_on_cpu are true,
       postprocess is scheduled on the host cpu.
-    export_to_tpu: When use_tpu and export_to_tpu are true,
-      `export_savedmodel()` exports a metagraph for serving on TPU besides the
-      one on CPU. If export_to_tpu is not provided, we will look for it in
-      hparams too.
     model_dir: Directory to output resulting evaluation summaries to.
     checkpoint_dir: Directory that contains the training checkpoints.
     wait_interval: The mimmum number of seconds to wait before checking for a
@@ -910,7 +876,7 @@ def eval_continuously(
     tf.logging.warning(
         'Forced number of epochs for all eval validations to be 1.')
   configs = merge_external_params_with_configs(
-      configs, hparams, kwargs_dict=kwargs)
+      configs, None, kwargs_dict=kwargs)
   model_config = configs['model']
   train_input_config = configs['train_input_config']
   eval_config = configs['eval_config']
@@ -942,12 +908,6 @@ def eval_continuously(
         model=detection_model)
     eval_inputs.append((eval_input_config.name, next_eval_input))
 
-  # Read export_to_tpu from hparams if not passed.
-  if export_to_tpu is None:
-    export_to_tpu = hparams.get('export_to_tpu', False)
-  tf.logging.info('eval_continuously: use_tpu %s, export_to_tpu %s',
-                  use_tpu, export_to_tpu)
-
   global_step = tf.compat.v2.Variable(
       0, trainable=False, dtype=tf.compat.v2.dtypes.int64)
 
diff --git a/research/object_detection/model_main_tf2.py b/research/object_detection/model_main_tf2.py
index f6832ba8..e20a8bc2 100644
--- a/research/object_detection/model_main_tf2.py
+++ b/research/object_detection/model_main_tf2.py
@@ -37,7 +37,6 @@ python model_main_tf2.py -- \
 """
 from absl import flags
 import tensorflow.compat.v2 as tf
-from object_detection import model_hparams
 from object_detection import model_lib_v2
 
 flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '
@@ -51,10 +50,6 @@ flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '
                      'one of every n train input examples for evaluation, '
                      'where n is provided. This is only used if '
                      '`eval_training_data` is True.')
-flags.DEFINE_string(
-    'hparams_overrides', None, 'Hyperparameter overrides, '
-    'represented as a string containing comma-separated '
-    'hparam_name=value pairs.')
 flags.DEFINE_string(
     'model_dir', None, 'Path to output model directory '
                        'where event and checkpoint files will be written.')
@@ -80,7 +75,6 @@ def main(unused_argv):
 
   if FLAGS.checkpoint_dir:
     model_lib_v2.eval_continuously(
-        hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),
         pipeline_config_path=FLAGS.pipeline_config_path,
         model_dir=FLAGS.model_dir,
         train_steps=FLAGS.num_train_steps,
@@ -102,11 +96,10 @@ def main(unused_argv):
 
     with strategy.scope():
       model_lib_v2.train_loop(
-          hparams=model_hparams.create_hparams(FLAGS.hparams_overrides),
           pipeline_config_path=FLAGS.pipeline_config_path,
           model_dir=FLAGS.model_dir,
           train_steps=FLAGS.num_train_steps,
           use_tpu=FLAGS.use_tpu)
 
 if __name__ == '__main__':
-  tf.app.run()
+  tf.compat.v1.app.run()
diff --git a/research/object_detection/protos/hyperparams.proto b/research/object_detection/protos/hyperparams.proto
index 2b105387..e2fee247 100644
--- a/research/object_detection/protos/hyperparams.proto
+++ b/research/object_detection/protos/hyperparams.proto
@@ -52,6 +52,12 @@ message Hyperparams {
   // Whether depthwise convolutions should be regularized. If this parameter is
   // NOT set then the conv hyperparams will default to the parent scope.
   optional bool regularize_depthwise = 6 [default = false];
+
+  // By default, use_bias is set to False if batch_norm is not None and
+  // batch_norm.center is True. When force_use_bias is set to True, this
+  // behavior will be overridden, and use_bias will be set to True, regardless
+  // of batch norm parameters. Note, this only applies to KerasLayerHyperparams.
+  optional bool force_use_bias = 8 [default = false];
 }
 
 // Proto with one-of field for regularizers.
diff --git a/research/object_detection/protos/preprocessor.proto b/research/object_detection/protos/preprocessor.proto
index aa83939f..3201df2b 100644
--- a/research/object_detection/protos/preprocessor.proto
+++ b/research/object_detection/protos/preprocessor.proto
@@ -57,7 +57,8 @@ message NormalizeImage {
   optional float target_maxval = 4 [default=1];
 }
 
-// Randomly horizontally flips the image and detections 50% of the time.
+// Randomly horizontally flips the image and detections with the specified
+// probability, default to 50% of the time.
 message RandomHorizontalFlip {
   // Specifies a mapping from the original keypoint indices to horizontally
   // flipped indices. This is used in the event that keypoints are specified,
@@ -71,10 +72,15 @@ message RandomHorizontalFlip {
   // keypoint_flip_permutation: 3
   // keypoint_flip_permutation: 5
   // keypoint_flip_permutation: 4
+  // If nothing is specified the order of keypoint will be mantained.
   repeated int32 keypoint_flip_permutation = 1;
+
+  // The probability of running this augmentation for each image.
+  optional float probability = 2 [default=0.5];
 }
 
-// Randomly vertically flips the image and detections 50% of the time.
+// Randomly vertically flips the image and detections with the specified
+// probability, default to 50% of the time.
 message RandomVerticalFlip {
   // Specifies a mapping from the original keypoint indices to vertically
   // flipped indices. This is used in the event that keypoints are specified,
@@ -89,11 +95,23 @@ message RandomVerticalFlip {
   // keypoint_flip_permutation: 5
   // keypoint_flip_permutation: 4
   repeated int32 keypoint_flip_permutation = 1;
+
+  // The probability of running this augmentation for each image.
+  optional float probability = 2 [default=0.5];
 }
 
 // Randomly rotates the image and detections by 90 degrees counter-clockwise
-// 50% of the time.
-message RandomRotation90 {}
+// with the specified probability, default to 50% of the time.
+message RandomRotation90 {
+  // Specifies a mapping from the original keypoint indices to 90 degree counter
+  // clockwise indices. This is used in the event that keypoints are specified,
+  // in which case when the image is rotated the keypoints might need to be
+  // permuted.
+  repeated int32 keypoint_rot_permutation = 1;
+
+  // The probability of running this augmentation for each image.
+  optional float probability = 2 [default=0.5];
+}
 
 // Randomly scales the values of all pixels in the image by some constant value
 // between [minval, maxval], then clip the value to a range between [0, 1.0].
@@ -457,7 +475,6 @@ message SSDRandomCropPadFixedAspectRatio {
 // Converts class logits to softmax optionally scaling the values by temperature
 // first.
 message ConvertClassLogitsToSoftmax {
-
   // Scale to use on logits before applying softmax.
   optional float temperature = 1 [default=1.0];
 }
@@ -472,12 +489,10 @@ message RandomSelfConcatImage {
 
 // Apply an Autoaugment policy to the image and bounding boxes.
 message AutoAugmentImage {
-
   // What AutoAugment policy to apply to the Image
   optional string policy_name = 1 [default="v0"];
 }
 
-
 // Randomly drops ground truth boxes for a label with some probability.
 message DropLabelProbabilistically {
   // The label that should be dropped. This corresponds to one of the entries
@@ -487,7 +502,6 @@ message DropLabelProbabilistically {
   optional float drop_probability = 2 [default = 1.0];
 }
 
-
 //Remap a set of labels to a new label.
 message RemapLabels {
    // Labels to be remapped.
diff --git a/research/object_detection/utils/config_util.py b/research/object_detection/utils/config_util.py
index 71185a5a..8dd405df 100644
--- a/research/object_detection/utils/config_util.py
+++ b/research/object_detection/utils/config_util.py
@@ -142,6 +142,34 @@ def get_configs_from_pipeline_file(pipeline_config_path, config_override=None):
   return create_configs_from_pipeline_proto(pipeline_config)
 
 
+def clear_fine_tune_checkpoint(pipeline_config_path,
+                               new_pipeline_config_path):
+  """Clears fine_tune_checkpoint and writes a new pipeline config file."""
+  configs = get_configs_from_pipeline_file(pipeline_config_path)
+  configs["train_config"].fine_tune_checkpoint = ""
+  pipeline_proto = create_pipeline_proto_from_configs(configs)
+  with tf.gfile.Open(new_pipeline_config_path, "wb") as f:
+    f.write(text_format.MessageToString(pipeline_proto))
+
+
+def update_fine_tune_checkpoint_type(train_config):
+  """Set `fine_tune_checkpoint_type` using `from_detection_checkpoint`.
+
+  `train_config.from_detection_checkpoint` field is deprecated. For backward
+  compatibility, this function sets `train_config.fine_tune_checkpoint_type`
+  based on `train_config.from_detection_checkpoint`.
+
+  Args:
+    train_config: train_pb2.TrainConfig proto object.
+
+  """
+  if not train_config.fine_tune_checkpoint_type:
+    if train_config.from_detection_checkpoint:
+      train_config.fine_tune_checkpoint_type = "detection"
+    else:
+      train_config.fine_tune_checkpoint_type = "classification"
+
+
 def create_configs_from_pipeline_proto(pipeline_config):
   """Creates a configs dictionary from pipeline_pb2.TrainEvalPipelineConfig.
 
