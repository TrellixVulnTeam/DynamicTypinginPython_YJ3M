commit 013910f86ea9881cd2715f8ac01ddd265b097d05
Author: Carlos Riquelme <rikel@google.com>
Date:   Mon Jul 23 13:24:47 2018 -0700

    Readme changes.

diff --git a/research/deep_contextual_bandits/README.md b/research/deep_contextual_bandits/README.md
index 36820ce3..c5589d6e 100644
--- a/research/deep_contextual_bandits/README.md
+++ b/research/deep_contextual_bandits/README.md
@@ -41,7 +41,7 @@ the process if we use algorithm **A** is as follows:
 
 ```
 At time t = 1, ..., T:
-  1. Observe new context: X_t
+  1. Observe new context: X<sub>t</sub>
   2. Choose action: a_t = A.action(X_t)
   3. Observe reward: r_t
   4. Update internal state of the algorithm: A.update((X_t, a_t, r_t))
