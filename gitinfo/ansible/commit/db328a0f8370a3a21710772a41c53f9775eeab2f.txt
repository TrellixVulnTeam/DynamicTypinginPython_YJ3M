commit db328a0f8370a3a21710772a41c53f9775eeab2f
Author: ukaj <kupczyk@so1.net>
Date:   Fri Mar 24 21:05:19 2017 +0100

    [cloud] Add support for running s3 module in check mode (#22188)

diff --git a/lib/ansible/modules/cloud/amazon/s3.py b/lib/ansible/modules/cloud/amazon/s3.py
index fb9655da64..8f2eaa4226 100644
--- a/lib/ansible/modules/cloud/amazon/s3.py
+++ b/lib/ansible/modules/cloud/amazon/s3.py
@@ -318,6 +318,8 @@ def bucket_check(module, s3, bucket, validate=True):
     return bool(result)
 
 def create_bucket(module, s3, bucket, location=None):
+    if module.check_mode:
+        module.exit_json(msg="PUT operation skipped - running in check mode", changed=True)
     if location is None:
         location = Location.DEFAULT
     try:
@@ -345,6 +347,8 @@ def list_keys(module, bucket_object, prefix, marker, max_keys):
     module.exit_json(msg="LIST operation complete", s3_keys=keys)
 
 def delete_bucket(module, s3, bucket):
+    if module.check_mode:
+        module.exit_json(msg="DELETE operation skipped - running in check mode", changed=True)
     try:
         bucket = s3.lookup(bucket)
         bucket_contents = bucket.list()
@@ -355,6 +359,8 @@ def delete_bucket(module, s3, bucket):
         module.fail_json(msg= str(e))
 
 def delete_key(module, s3, bucket, obj, validate=True):
+    if module.check_mode:
+        module.exit_json(msg="DELETE operation skipped - running in check mode", changed=True)
     try:
         bucket = s3.lookup(bucket, validate=validate)
         bucket.delete_key(obj)
@@ -363,6 +369,8 @@ def delete_key(module, s3, bucket, obj, validate=True):
         module.fail_json(msg= str(e))
 
 def create_dirkey(module, s3, bucket, obj, validate=True):
+    if module.check_mode:
+        module.exit_json(msg="PUT operation skipped - running in check mode", changed=True)
     try:
         bucket = s3.lookup(bucket, validate=validate)
         key = bucket.new_key(obj)
@@ -379,6 +387,8 @@ def path_check(path):
 
 
 def upload_s3file(module, s3, bucket, obj, src, expiry, metadata, encrypt, headers, validate=True):
+    if module.check_mode:
+        module.exit_json(msg="PUT operation skipped - running in check mode", changed=True)
     try:
         bucket = s3.lookup(bucket, validate=validate)
         key = bucket.new_key(obj)
@@ -395,6 +405,8 @@ def upload_s3file(module, s3, bucket, obj, src, expiry, metadata, encrypt, heade
         module.fail_json(msg= str(e))
 
 def download_s3file(module, s3, bucket, obj, dest, retries, version=None, validate=True):
+    if module.check_mode:
+        module.exit_json(msg="GET operation skipped - running in check mode", changed=True)
     # retries is the number of loops; range/xrange needs to be one
     # more to get that count of loops.
     bucket = s3.lookup(bucket, validate=validate)
@@ -413,6 +425,8 @@ def download_s3file(module, s3, bucket, obj, dest, retries, version=None, valida
             pass
 
 def download_s3str(module, s3, bucket, obj, version=None, validate=True):
+    if module.check_mode:
+        module.exit_json(msg="GET operation skipped - running in check mode", changed=True)
     try:
         bucket = s3.lookup(bucket, validate=validate)
         key = bucket.get_key(obj, version_id=version)
@@ -472,7 +486,10 @@ def main():
         ignore_nonexistent_bucket       = dict(default=False, type='bool')
         ),
     )
-    module = AnsibleModule(argument_spec=argument_spec)
+    module = AnsibleModule(
+        argument_spec=argument_spec,
+        supports_check_mode=True,
+    )
 
     if not HAS_BOTO:
         module.fail_json(msg='boto required for this module')
