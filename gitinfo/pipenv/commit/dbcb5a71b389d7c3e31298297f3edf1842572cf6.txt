commit dbcb5a71b389d7c3e31298297f3edf1842572cf6
Author: Dan Ryan <dan@danryan.co>
Date:   Wed Jul 18 00:16:17 2018 -0400

    Add cached property to vendored deps
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/pipenv/vendor/cached-property.LICENSE b/pipenv/vendor/cached-property.LICENSE
new file mode 100644
index 00000000..a181761c
--- /dev/null
+++ b/pipenv/vendor/cached-property.LICENSE
@@ -0,0 +1,12 @@
+Copyright (c) 2015, Daniel Greenfeld
+All rights reserved.
+
+Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
+
+* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
+
+* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
+
+* Neither the name of cached-property nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
+
+THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/pipenv/vendor/cached_property.py b/pipenv/vendor/cached_property.py
new file mode 100644
index 00000000..a06be97a
--- /dev/null
+++ b/pipenv/vendor/cached_property.py
@@ -0,0 +1,152 @@
+# -*- coding: utf-8 -*-
+
+__author__ = "Daniel Greenfeld"
+__email__ = "pydanny@gmail.com"
+__version__ = "1.4.3"
+__license__ = "BSD"
+
+from time import time
+import threading
+
+try:
+    import asyncio
+except (ImportError, SyntaxError):
+    asyncio = None
+
+
+class cached_property(object):
+    """
+    A property that is only computed once per instance and then replaces itself
+    with an ordinary attribute. Deleting the attribute resets the property.
+    Source: https://github.com/bottlepy/bottle/commit/fa7733e075da0d790d809aa3d2f53071897e6f76
+    """  # noqa
+
+    def __init__(self, func):
+        self.__doc__ = getattr(func, "__doc__")
+        self.func = func
+
+    def __get__(self, obj, cls):
+        if obj is None:
+            return self
+
+        if asyncio and asyncio.iscoroutinefunction(self.func):
+            return self._wrap_in_coroutine(obj)
+
+        value = obj.__dict__[self.func.__name__] = self.func(obj)
+        return value
+
+    def _wrap_in_coroutine(self, obj):
+
+        @asyncio.coroutine
+        def wrapper():
+            future = asyncio.ensure_future(self.func(obj))
+            obj.__dict__[self.func.__name__] = future
+            return future
+
+        return wrapper()
+
+
+class threaded_cached_property(object):
+    """
+    A cached_property version for use in environments where multiple threads
+    might concurrently try to access the property.
+    """
+
+    def __init__(self, func):
+        self.__doc__ = getattr(func, "__doc__")
+        self.func = func
+        self.lock = threading.RLock()
+
+    def __get__(self, obj, cls):
+        if obj is None:
+            return self
+
+        obj_dict = obj.__dict__
+        name = self.func.__name__
+        with self.lock:
+            try:
+                # check if the value was computed before the lock was acquired
+                return obj_dict[name]
+
+            except KeyError:
+                # if not, do the calculation and release the lock
+                return obj_dict.setdefault(name, self.func(obj))
+
+
+class cached_property_with_ttl(object):
+    """
+    A property that is only computed once per instance and then replaces itself
+    with an ordinary attribute. Setting the ttl to a number expresses how long
+    the property will last before being timed out.
+    """
+
+    def __init__(self, ttl=None):
+        if callable(ttl):
+            func = ttl
+            ttl = None
+        else:
+            func = None
+        self.ttl = ttl
+        self._prepare_func(func)
+
+    def __call__(self, func):
+        self._prepare_func(func)
+        return self
+
+    def __get__(self, obj, cls):
+        if obj is None:
+            return self
+
+        now = time()
+        obj_dict = obj.__dict__
+        name = self.__name__
+        try:
+            value, last_updated = obj_dict[name]
+        except KeyError:
+            pass
+        else:
+            ttl_expired = self.ttl and self.ttl < now - last_updated
+            if not ttl_expired:
+                return value
+
+        value = self.func(obj)
+        obj_dict[name] = (value, now)
+        return value
+
+    def __delete__(self, obj):
+        obj.__dict__.pop(self.__name__, None)
+
+    def __set__(self, obj, value):
+        obj.__dict__[self.__name__] = (value, time())
+
+    def _prepare_func(self, func):
+        self.func = func
+        if func:
+            self.__doc__ = func.__doc__
+            self.__name__ = func.__name__
+            self.__module__ = func.__module__
+
+
+# Aliases to make cached_property_with_ttl easier to use
+cached_property_ttl = cached_property_with_ttl
+timed_cached_property = cached_property_with_ttl
+
+
+class threaded_cached_property_with_ttl(cached_property_with_ttl):
+    """
+    A cached_property version for use in environments where multiple threads
+    might concurrently try to access the property.
+    """
+
+    def __init__(self, ttl=None):
+        super(threaded_cached_property_with_ttl, self).__init__(ttl)
+        self.lock = threading.RLock()
+
+    def __get__(self, obj, cls):
+        with self.lock:
+            return super(threaded_cached_property_with_ttl, self).__get__(obj, cls)
+
+
+# Alias to make threaded_cached_property_with_ttl easier to use
+threaded_cached_property_ttl = threaded_cached_property_with_ttl
+timed_threaded_cached_property = threaded_cached_property_with_ttl
diff --git a/pipenv/vendor/vendor.txt b/pipenv/vendor/vendor.txt
index 961ad016..e2c3165c 100644
--- a/pipenv/vendor/vendor.txt
+++ b/pipenv/vendor/vendor.txt
@@ -39,3 +39,4 @@ six==1.11.0
 semver==2.8.0
 shutilwhich==1.1.0
 toml==0.9.4
+cached-property==1.4.3
diff --git a/tasks/vendoring/__init__.py b/tasks/vendoring/__init__.py
index 9b8a2c82..a93360ce 100644
--- a/tasks/vendoring/__init__.py
+++ b/tasks/vendoring/__init__.py
@@ -280,19 +280,47 @@ def write_backport_imports(ctx, vendor_dir):
     backport_init.write_text('\n'.join(init_py_lines) + '\n')
 
 
-def vendor(ctx, vendor_dir, rewrite=True):
-    log('Reinstalling vendored libraries')
-    is_patched = vendor_dir.name == 'patched'
-    requirements_file = vendor_dir.name
+def _ensure_package_in_requirements(ctx, requirements_file, package):
+    requirement = None
+    log('using requirements file: %s' % requirements_file)
+    req_file_lines = [l for l in requirements_file.read_text().splitlines()]
+    if package:
+        match = [r for r in req_file_lines if r.strip().lower().startswith(package)]
+        matched_req = None
+        if match:
+            for m in match:
+                specifiers = [m.index(s) for s in ['>', '<', '=', '~'] if s in m]
+                if m.lower() == package or (specifiers and m[:min(specifiers)].lower() == package):
+                    matched_req = "{0}".format(m)
+                    requirement = matched_req
+                    log("Matched req: %r" % matched_req)
+        if not matched_req:
+            req_file_lines.append("{0}".format(package))
+            log("Writing requirements file: %s" % requirements_file)
+            requirements_file.write_text('\n'.join(req_file_lines))
+            requirement = "{0}".format(package)
+    return requirement
+
+
+
+def install(ctx, vendor_dir, package=None):
+    requirements_file = vendor_dir / "{0}.txt".format(vendor_dir.name)
+    requirement = "-r {0}".format(requirements_file.as_posix())
+    log('Using requirements file: %s' % requirement)
+    if package:
+        requirement = _ensure_package_in_requirements(ctx, requirements_file, package)
     # We use --no-deps because we want to ensure that all of our dependencies
     # are added to vendor.txt, this includes all dependencies recursively up
     # the chain.
     ctx.run(
-        'pip install -t {0} -r {0}/{1}.txt --no-compile --no-deps'.format(
-            str(vendor_dir),
-            requirements_file,
+        'pip install -t {0} --no-compile --no-deps {1}'.format(
+            vendor_dir.as_posix(),
+            requirement,
         )
     )
+
+
+def post_install_cleanup(ctx, vendor_dir):
     remove_all(vendor_dir.glob('*.dist-info'))
     remove_all(vendor_dir.glob('*.egg-info'))
 
@@ -300,6 +328,13 @@ def vendor(ctx, vendor_dir, rewrite=True):
     drop_dir(vendor_dir / 'bin')
     drop_dir(vendor_dir / 'tests')
 
+
+def vendor(ctx, vendor_dir, package=None, rewrite=True):
+    log('Reinstalling vendored libraries')
+    is_patched = vendor_dir.name == 'patched'
+    install(ctx, vendor_dir, package=package)
+    log('Running post-install cleanup...')
+    post_install_cleanup(ctx, vendor_dir)
     # Detect the vendored packages/modules
     vendored_libs = detect_vendored_libs(_get_vendor_dir(ctx))
     patched_libs = detect_vendored_libs(_get_patched_dir(ctx))
@@ -320,25 +355,26 @@ def vendor(ctx, vendor_dir, rewrite=True):
     log('Renaming specified libs...')
     for item in vendor_dir.iterdir():
         if item.is_dir():
-            if rewrite:
+            if rewrite and not package or (package and item.name.lower() in package):
                 log('Rewriting imports for %s...' % item)
                 rewrite_imports(item, vendored_libs, vendor_dir)
             rename_if_needed(ctx, vendor_dir, item)
         elif item.name not in FILE_WHITE_LIST:
-            if rewrite:
+            if rewrite and not package or (package and item.stem.lower() in package):
                 rewrite_file_imports(item, vendored_libs, vendor_dir)
     write_backport_imports(ctx, vendor_dir)
-    log('Applying post-patches...')
-    patches = patch_dir.glob('*.patch' if not is_patched else '_post*.patch')
-    for patch in patches:
-        apply_patch(ctx, patch)
-    if is_patched:
-        piptools_vendor = vendor_dir / 'piptools' / '_vendored'
-        if piptools_vendor.exists():
-            drop_dir(piptools_vendor)
-        msgpack = vendor_dir / 'notpip' / '_vendor' / 'msgpack'
-        if msgpack.exists():
-            remove_all(msgpack.glob('*.so'))
+    if not package:
+        log('Applying post-patches...')
+        patches = patch_dir.glob('*.patch' if not is_patched else '_post*.patch')
+        for patch in patches:
+            apply_patch(ctx, patch)
+        if is_patched:
+            piptools_vendor = vendor_dir / 'piptools' / '_vendored'
+            if piptools_vendor.exists():
+                drop_dir(piptools_vendor)
+            msgpack = vendor_dir / 'notpip' / '_vendor' / 'msgpack'
+            if msgpack.exists():
+                remove_all(msgpack.glob('*.so'))
 
 
 @invoke.task
@@ -371,16 +407,19 @@ def rewrite_all_imports(ctx):
 
 
 @invoke.task
-def download_licenses(ctx, vendor_dir, requirements_file='vendor.txt'):
+def download_licenses(ctx, vendor_dir=None, requirements_file='vendor.txt', package=None):
     log('Downloading licenses')
     if not vendor_dir:
         vendor_dir = _get_vendor_dir(ctx)
+    requirements_file = vendor_dir / requirements_file
+    requirement = "-r {0}".format(requirements_file.as_posix())
+    if package:
+        requirement = _ensure_package_in_requirements(ctx, requirements_file, package)
     tmp_dir = vendor_dir / '__tmp__'
     ctx.run(
-        'pip download -r {0}/{1} --no-binary :all: --no-deps -d {2}'.format(
-            str(vendor_dir),
-            requirements_file,
-            str(tmp_dir),
+        'pip download --no-binary :all: --no-deps -d {0} {1}'.format(
+            tmp_dir.as_posix(),
+            requirement,
         )
     )
     for sdist in tmp_dir.iterdir():
@@ -503,10 +542,15 @@ def generate_patch(ctx, package_path, patch_description, base='HEAD'):
 
 
 @invoke.task(name=TASK_NAME)
-def main(ctx):
+def main(ctx, package=None):
     vendor_dir = _get_vendor_dir(ctx)
     patched_dir = _get_patched_dir(ctx)
     log('Using vendor dir: %s' % vendor_dir)
+    if package:
+        vendor(ctx, vendor_dir, package=package)
+        download_licenses(ctx, vendor_dir, package=package)
+        log("Vendored %s" % package)
+        return
     clean_vendor(ctx, vendor_dir)
     clean_vendor(ctx, patched_dir)
     vendor(ctx, vendor_dir)
