commit 2b90c89d1f518a543f775cb811ee8b5565ee1366
Author: Dan Ryan <dan@danryan.co>
Date:   Sun Nov 11 16:30:42 2018 -0500

    Revendor requirementslib
    
    - Implement improvements and bugfixes in codebase
    - Remote archives will now resolve properly
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/pipenv/__init__.py b/pipenv/__init__.py
index f8a1a8b3..ba4dd9c3 100644
--- a/pipenv/__init__.py
+++ b/pipenv/__init__.py
@@ -10,7 +10,7 @@ import warnings
 
 from .__version__ import __version__
 
-PIPENV_ROOT = os.path.dirname(os.path.realpath(__file__))
+PIPENV_ROOT = os.path.abspath(os.path.dirname(os.path.realpath(__file__)))
 PIPENV_VENDOR = os.sep.join([PIPENV_ROOT, "vendor"])
 PIPENV_PATCHED = os.sep.join([PIPENV_ROOT, "patched"])
 # Inject vendored directory into system path.
@@ -27,11 +27,13 @@ warnings.filterwarnings("ignore", category=UserWarning)
 if sys.version_info >= (3, 1) and sys.version_info <= (3, 6):
     if sys.stdout.isatty() and sys.stderr.isatty():
         import io
+        import atexit
         sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf8')
+        atexit.register(sys.stdout.close)
         sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf8')
+        atexit.register(sys.stdout.close)
 
 os.environ["PIP_DISABLE_PIP_VERSION_CHECK"] = fs_str("1")
-os.environ["PIP_SHIMS_BASE_MODULE"] = fs_str("pipenv.patched.notpip")
 
 # Hack to make things work better.
 try:
diff --git a/pipenv/_compat.py b/pipenv/_compat.py
index 6e5ae6a7..fb2c0147 100644
--- a/pipenv/_compat.py
+++ b/pipenv/_compat.py
@@ -382,7 +382,7 @@ def decode_output(output):
     except (AttributeError, UnicodeDecodeError, UnicodeEncodeError):
         if six.PY2:
             output = unicode.translate(vistir.misc.to_text(output),
-                                            UNICODE_TO_ASCII_TRANSLATION_MAP)
+                                       UNICODE_TO_ASCII_TRANSLATION_MAP)
         else:
             output = output.translate(UNICODE_TO_ASCII_TRANSLATION_MAP)
         output = output.encode(DEFAULT_ENCODING, "replace")
diff --git a/pipenv/core.py b/pipenv/core.py
index f9b8eaee..3cbd1645 100644
--- a/pipenv/core.py
+++ b/pipenv/core.py
@@ -40,8 +40,8 @@ from .utils import (
     clean_resolved_dep,
     parse_indexes,
     escape_cmd,
-    fix_venv_site,
     create_spinner,
+    get_canonical_names
 )
 from . import environments, pep508checker, progress
 from .environments import (
@@ -1296,7 +1296,7 @@ def pip_install(
     pypi_mirror=None,
     trusted_hosts=None
 ):
-    from notpip._internal import logger as piplogger
+    from pipenv.patched.notpip._internal import logger as piplogger
     from .utils import Mapping
     from .vendor.urllib3.util import parse_url
 
@@ -1746,11 +1746,11 @@ def do_install(
     if requirements or package_args or project.pipfile_exists:
         skip_requirements = True
     # Don't attempt to install develop and default packages if Pipfile is missing
-    if not project.pipfile_exists and not (packages or dev) and not code:
-        if not (skip_lock or deploy):
-            raise exceptions.PipfileNotFound(project.pipfile_location)
-        elif (skip_lock or deploy) and not project.lockfile_exists:
-            raise exceptions.LockfileNotFound(project.lockfile_location)
+    if not project.pipfile_exists and not (package_args or dev) and not code:
+        if not (ignore_pipfile or deploy):
+            raise exceptions.PipfileNotFound(project.path_to("Pipfile"))
+        elif ((skip_lock and deploy) or ignore_pipfile) and not project.lockfile_exists:
+            raise exceptions.LockfileNotFound(project.path_to("Pipfile.lock"))
     concurrent = not sequential
     # Ensure that virtualenv is available.
     ensure_project(
@@ -2092,7 +2092,6 @@ def do_uninstall(
             )
         )
         package_names = develop
-    fix_venv_site(project.env_paths["lib"])
     # Remove known "bad packages" from the list.
     bad_pkgs = set([canonicalize_name(pkg) for pkg in BAD_PACKAGES])
     for bad_package in BAD_PACKAGES:
diff --git a/pipenv/project.py b/pipenv/project.py
index 26b4cf0c..d4713b89 100644
--- a/pipenv/project.py
+++ b/pipenv/project.py
@@ -804,7 +804,7 @@ class Project(object):
             .lstrip("\n")
             .split("\n")
         )
-        sources = [DEFAULT_SOURCE]
+        sources = [DEFAULT_SOURCE,]
         for i, index in enumerate(indexes):
             if not index:
                 continue
@@ -831,55 +831,68 @@ class Project(object):
         version = python_version(required_python) or PIPENV_DEFAULT_PYTHON_VERSION
         if version and len(version) >= 3:
             data[u"requires"] = {"python_version": version[: len("2.7")]}
-        self.write_toml(data, "Pipfile")
+        self.write_toml(data)
 
     def get_or_create_lockfile(self):
-        from requirementslib.models.lockfile import Lockfile as Req_Lockfile
+        from pipenv.vendor.requirementslib.models.lockfile import Lockfile as Req_Lockfile
         lockfile = None
-        try:
-            lockfile = Req_Lockfile.load(self.lockfile_location)
-        except OSError:
-            lockfile = Req_Lockfile(self.lockfile_content)
-            return lockfile
+        if self.lockfile_exists:
+            try:
+                lockfile = Req_Lockfile.load(self.lockfile_location)
+            except OSError:
+                lockfile = Req_Lockfile.from_data(self.lockfile_location, self.lockfile_content)
         else:
-            if lockfile._lockfile is not None:
-                return lockfile
-            if self.lockfile_exists and self.lockfile_content:
-                from .vendor.plette.lockfiles import Lockfile
-                lockfile_dict = self.lockfile_content.copy()
-                sources = lockfile_dict["_meta"].get("sources", [])
-                if not sources:
-                    sources = self.pipfile_sources
-                elif not isinstance(sources, list):
-                    sources = [sources,]
-                lockfile_dict["_meta"]["sources"] = [
-                    {
-                        "name": s["name"],
-                        "url": s["url"],
-                        "verify_ssl": (
-                            s["verify_ssl"] if isinstance(s["verify_ssl"], bool) else (
-                                True if s["verify_ssl"].lower() == "true" else False
-                            )
+            lockfile = Req_Lockfile.from_data(path=self.lockfile_location, data=self._lockfile, meta_from_project=False)
+        if lockfile._lockfile is not None:
+            return lockfile
+        if self.lockfile_exists and self.lockfile_content:
+            lockfile_dict = self.lockfile_content.copy()
+            sources = lockfile_dict.get("_meta", {}).get("sources", [])
+            if not sources:
+                sources = self.pipfile_sources
+            elif not isinstance(sources, list):
+                sources = [sources,]
+            lockfile_dict["_meta"]["sources"] = [
+                {
+                    "name": s["name"],
+                    "url": s["url"],
+                    "verify_ssl": (
+                        s["verify_ssl"] if isinstance(s["verify_ssl"], bool) else (
+                            True if s["verify_ssl"].lower() == "true" else False
                         )
-                    } for s in sources
-                ]
-                _created_lockfile = Lockfile(lockfile_dict)
-                lockfile._lockfile = lockfile.projectfile.model = _created_lockfile
-                return lockfile
-            elif self.pipfile_exists:
-                from .vendor.plette.lockfiles import Lockfile, PIPFILE_SPEC_CURRENT
-                lockfile_dict = {
-                    "_meta": {
-                        "hash": {"sha256": self.calculate_pipfile_hash()},
-                        "pipfile-spec": PIPFILE_SPEC_CURRENT,
-                        "sources": self.pipfile_sources,
-                        "requires": self.parsed_pipfile.get("requires", {})
-                    },
-                    "default": self._lockfile["default"].copy(),
-                    "develop": self._lockfile["develop"].copy()
-                }
-                lockfile._lockfile = Lockfile(lockfile_dict)
-                return lockfile
+                    )
+                } for s in sources
+            ]
+            _created_lockfile = Req_Lockfile.from_data(
+                path=self.lockfile_location, data=lockfile_dict, meta_from_project=False
+            )
+            lockfile._lockfile = lockfile.projectfile.model = _created_lockfile
+            return lockfile
+        elif self.pipfile_exists:
+            lockfile_dict = {
+                "default": self._lockfile["default"].copy(),
+                "develop": self._lockfile["develop"].copy()
+            }
+            lockfile_dict.update({"_meta": self.get_lockfile_meta()})
+            _created_lockfile = Req_Lockfile.from_data(
+                path=self.lockfile_location, data=lockfile_dict, meta_from_project=False
+            )
+            lockfile._lockfile = _created_lockfile
+            return lockfile
+
+    def get_lockfile_meta(self):
+        from .vendor.plette.lockfiles import PIPFILE_SPEC_CURRENT
+        sources = self.lockfile_content.get("_meta", {}).get("sources", [])
+        if not sources:
+            sources = self.pipfile_sources
+        elif not isinstance(sources, list):
+            sources = [sources,]
+        return {
+            "hash": {"sha256": self.calculate_pipfile_hash()},
+            "pipfile-spec": PIPFILE_SPEC_CURRENT,
+            "sources": sources,
+            "requires": self.parsed_pipfile.get("requires", {})
+        }
 
     def write_toml(self, data, path=None):
         """Writes the given data structure out as TOML."""
@@ -943,7 +956,7 @@ class Project(object):
     @property
     def sources(self):
         if self.lockfile_exists and hasattr(self.lockfile_content, "keys"):
-            meta_ = self.lockfile_content["_meta"]
+            meta_ = self.lockfile_content.get("_meta", {})
             sources_ = meta_.get("sources")
             if sources_:
                 return sources_
diff --git a/pipenv/utils.py b/pipenv/utils.py
index c9feeafd..3a9ef307 100644
--- a/pipenv/utils.py
+++ b/pipenv/utils.py
@@ -18,7 +18,8 @@ from first import first
 from vistir.misc import fs_str
 
 six.add_move(six.MovedAttribute("Mapping", "collections", "collections.abc"))
-from six.moves import Mapping
+six.add_move(six.MovedAttribute("Sequence", "collections", "collections.abc"))
+from six.moves import Mapping, Sequence
 
 from vistir.compat import ResourceWarning
 
@@ -1035,6 +1036,17 @@ def path_to_url(path):
     return Path(normalize_drive(os.path.abspath(path))).as_uri()
 
 
+def get_canonical_names(packages):
+    """Canonicalize a list of packages and return a set of canonical names"""
+    from .vendor.packaging.utils import canonicalize_name
+
+    if not isinstance(packages, Sequence):
+        if not isinstance(packages, six.string_types):
+            return packages
+        packages = [packages,]
+    return set([canonicalize_name(pkg) for pkg in packages if pkg])
+
+
 def walk_up(bottom):
     """Mimic os.walk, but walk 'up' instead of down the directory tree.
     From: https://gist.github.com/zdavkeos/1098474
diff --git a/pipenv/vendor/requirementslib/__init__.py b/pipenv/vendor/requirementslib/__init__.py
index edbab5bc..881e9ac9 100644
--- a/pipenv/vendor/requirementslib/__init__.py
+++ b/pipenv/vendor/requirementslib/__init__.py
@@ -2,6 +2,10 @@
 __version__ = '1.2.6'
 
 import logging
+import warnings
+
+warnings.filterwarnings("ignore", category=ResourceWarning)
+
 
 logger = logging.getLogger(__name__)
 logger.addHandler(logging.NullHandler())
diff --git a/pipenv/vendor/requirementslib/exceptions.py b/pipenv/vendor/requirementslib/exceptions.py
index de8bf8ef..1a73f98e 100644
--- a/pipenv/vendor/requirementslib/exceptions.py
+++ b/pipenv/vendor/requirementslib/exceptions.py
@@ -1,7 +1,12 @@
 # -*- coding: utf-8 -*-
 from __future__ import absolute_import
 import errno
+import os
 import six
+import sys
+
+
+from vistir.compat import FileNotFoundError
 
 
 if six.PY2:
@@ -15,3 +20,73 @@ else:
 
 class RequirementError(Exception):
     pass
+
+
+class MissingParameter(Exception):
+    def __init__(self, param):
+        super(Exception, self).__init__()
+        print("Missing parameter: %s" % param, file=sys.stderr, flush=True)
+
+
+class FileCorruptException(OSError):
+    def __init__(self, path, *args, **kwargs):
+        path = path
+        backup_path = kwargs.pop("backup_path", None)
+        if not backup_path and args:
+            args = reversed(args)
+            backup_path = args.pop()
+            if not isinstance(backup_path, six.string_types) or not os.path.exists(os.path.abspath(os.path.dirname(backup_path))):
+                args.append(backup_path)
+                backup_path = None
+            if args:
+                args = reversed(args)
+        self.path = path
+        self.backup_path = backup_path
+        self.show(self.path, self.backup_path)
+        super(OSError, self).__init__(path, *args, **kwargs)
+
+    @classmethod
+    def show(cls, path, backup_path=None):
+        print("ERROR: Failed to load file at %s" % path, file=sys.stderr, flush=True)
+        if backup_path:
+            msg = "it will be backed up to %s and removed" % backup_path
+        else:
+            msg = "it will be removed and replaced."
+        print("The file is corrupt, %s" % msg, file=sys.stderr, flush=True)
+
+
+class LockfileCorruptException(FileCorruptException):
+
+    @classmethod
+    def show(cls, path, backup_path=None):
+        print("ERROR: Failed to load lockfile at %s" % path, file=sys.stderr, flush=True)
+        if backup_path:
+            msg = "it will be backed up to %s and removed" % backup_path
+        else:
+            msg = "it will be removed and replaced on the next lock."
+        print("Your lockfile is corrupt, %s" % msg, file=sys.stderr, flush=True)
+
+
+class PipfileCorruptException(FileCorruptException):
+
+    @classmethod
+    def show(cls, path, backup_path=None):
+        print("ERROR: Failed to load Pipfile at %s" % path, file=sys.stderr, flush=True)
+        if backup_path:
+            msg = "it will be backed up to %s and removed" % backup_path
+        else:
+            msg = "it will be removed and replaced on the next lock."
+        print("Your Pipfile is corrupt, %s" % msg, file=sys.stderr, flush=True)
+
+
+class PipfileNotFound(FileNotFoundError):
+    def __init__(self, path, *args, **kwargs):
+        self.errno = errno.ENOENT
+        self.path = path
+        self.show(path)
+        super(PipfileNotFound, self).__init__(*args, **kwargs)
+
+    @classmethod
+    def show(cls, path):
+        print("ERROR: The file could not be found: %s" % path, file=sys.stderr, flush=True)
+        print("Aborting...", file=sys.stderr, flush=True)
diff --git a/pipenv/vendor/requirementslib/models/lockfile.py b/pipenv/vendor/requirementslib/models/lockfile.py
index 3e482813..6f61f57e 100644
--- a/pipenv/vendor/requirementslib/models/lockfile.py
+++ b/pipenv/vendor/requirementslib/models/lockfile.py
@@ -9,12 +9,13 @@ import itertools
 import plette.lockfiles
 import six
 
-from vistir.compat import Path, FileNotFoundError
+from vistir.compat import Path, FileNotFoundError, JSONDecodeError
 
 from .project import ProjectFile
 from .requirements import Requirement
 
 from .utils import optional_instance_of
+from ..exceptions import LockfileCorruptException, PipfileNotFound, MissingParameter
 from ..utils import is_vcs, is_editable, merge_items
 
 DEFAULT_NEWLINES = u"\n"
@@ -134,7 +135,17 @@ class Lockfile(object):
         return pf
 
     @classmethod
-    def load_projectfile(cls, path, create=True):
+    def lockfile_from_pipfile(cls, pipfile_path):
+        from .pipfile import Pipfile
+        if os.path.isfile(pipfile_path):
+            if not os.path.isabs(pipfile_path):
+                pipfile_path = os.path.abspath(pipfile_path)
+            pipfile = Pipfile.load(os.path.dirname(pipfile_path))
+            return plette.lockfiles.Lockfile.with_meta_from(pipfile._pipfile)
+        raise PipfileNotFound(pipfile_path)
+
+    @classmethod
+    def load_projectfile(cls, path, create=True, data=None):
         """Given a path, load or create the necessary lockfile.
 
         :param str path: Path to the project root or lockfile
@@ -155,8 +166,48 @@ class Lockfile(object):
         elif not lockfile_path.exists() and not create:
             raise FileNotFoundError("Lockfile does not exist: %s" % lockfile_path.as_posix())
         projectfile = cls.read_projectfile(lockfile_path.as_posix())
+        if not lockfile_path.exists():
+            if not data:
+                lf = cls.lockfile_from_pipfile(project_path.joinpath("Pipfile"))
+            else:
+                lf = plette.lockfiles.Lockfile(data)
+            projectfile.model = lf
         return projectfile
 
+    @classmethod
+    def from_data(cls, path, data, meta_from_project=True):
+        """Create a new lockfile instance from a dictionary.
+
+        :param str path: Path to the project root.
+        :param dict data: Data to load into the lockfile.
+        :param bool meta_from_project: Attempt to populate the meta section from the
+            project root, default True.
+        """
+
+        if path is None:
+            raise MissingParameter("path")
+        if data is None:
+            raise MissingParameter("data")
+        if not isinstance(data, dict):
+            raise TypeError("Expecting a dictionary for parameter 'data'")
+        path = os.path.abspath(str(path))
+        if os.path.isdir(path):
+            project_path = path
+        elif not os.path.isdir(path) and os.path.isdir(os.path.dirname(path)):
+            project_path = os.path.dirname(path)
+        pipfile_path = os.path.join(project_path, "Pipfile")
+        lockfile_path = os.path.join(project_path, "Pipfile.lock")
+        if meta_from_project:
+            lockfile = cls.lockfile_from_pipfile(pipfile_path)
+            lockfile.update(data)
+        else:
+            lockfile = plette.lockfiles.Lockfile(data)
+        projectfile = ProjectFile(line_ending=DEFAULT_NEWLINES, location=lockfile_path, model=lockfile)
+        return cls(
+            projectfile=projectfile, lockfile=lockfile,
+            newlines=projectfile.line_ending, path=Path(projectfile.location)
+        )
+
     @classmethod
     def load(cls, path, create=True):
         """Create a new lockfile instance.
@@ -170,7 +221,18 @@ class Lockfile(object):
         :rtype: :class:`~requirementslib.models.lockfile.Lockfile`
         """
 
-        projectfile = cls.load_projectfile(path, create=create)
+        try:
+            projectfile = cls.load_projectfile(path, create=create)
+        except JSONDecodeError as e:
+            path = os.path.abspath(path)
+            if not os.path.isdir(path):
+                path = os.path.dirname(path)
+            path = Path(os.path.join(path, "Pipfile.lock"))
+            formatted_path = path.as_posix()
+            backup_path = "%.bak" % formatted_path
+            LockfileCorruptException.show(formatted_path, backup_path=backup_path)
+            path.rename(backup_path)
+            cls.load(formatted_path, create=True)
         lockfile_path = Path(projectfile.location)
         creation_args = {
             "projectfile": projectfile,
diff --git a/pipenv/vendor/requirementslib/models/pipfile.py b/pipenv/vendor/requirementslib/models/pipfile.py
index 58d54055..dbb024be 100644
--- a/pipenv/vendor/requirementslib/models/pipfile.py
+++ b/pipenv/vendor/requirementslib/models/pipfile.py
@@ -23,13 +23,26 @@ is_path = optional_instance_of(Path)
 is_projectfile = optional_instance_of(ProjectFile)
 
 
+def reorder_source_keys(data):
+    for i, entry in enumerate(data["source"]):
+        table = tomlkit.table()
+        table["name"] = entry["name"]
+        table["url"] = entry["url"]
+        table["verify_ssl"] = entry["verify_ssl"]
+        data["source"][i] = table
+    return data
+
+
 class PipfileLoader(plette.pipfiles.Pipfile):
     @classmethod
     def validate(cls, data):
         for key, klass in plette.pipfiles.PIPFILE_SECTIONS.items():
             if key not in data or key == "source":
                 continue
-            klass.validate(data[key])
+            try:
+                klass.validate(data[key])
+            except Exception:
+                pass
 
     @classmethod
     def load(cls, f, encoding=None):
@@ -37,19 +50,26 @@ class PipfileLoader(plette.pipfiles.Pipfile):
         if encoding is not None:
             content = content.decode(encoding)
         _data = tomlkit.loads(content)
+        _data["source"] = _data.get("source", []) + _data.get("sources", [])
+        _data = reorder_source_keys(_data)
         if "source" not in _data:
-            if "sources" in _data:
-                _data["source"] = _data["sources"]
-                content = tomlkit.dumps(_data)
-            else:
-                # HACK: There is no good way to prepend a section to an existing
-                # TOML document, but there's no good way to copy non-structural
-                # content from one TOML document to another either. Modify the
-                # TOML content directly, and load the new in-memory document.
-                sep = "" if content.startswith("\n") else "\n"
-                content = plette.pipfiles.DEFAULT_SOURCE_TOML + sep + content
+            # HACK: There is no good way to prepend a section to an existing
+            # TOML document, but there's no good way to copy non-structural
+            # content from one TOML document to another either. Modify the
+            # TOML content directly, and load the new in-memory document.
+            sep = "" if content.startswith("\n") else "\n"
+            content = plette.pipfiles.DEFAULT_SOURCE_TOML + sep + content
         data = tomlkit.loads(content)
-        return cls(data)
+        data = reorder_source_keys(data)
+        instance = cls(data)
+        new_data = reorder_source_keys(instance._data)
+        instance._data = new_data
+        return instance
+
+    def __getattribute__(self, key):
+        if key == "source":
+            return self._data[key]
+        return super(PipfileLoader, self).__getattribute__(key)
 
 
 @attr.s(slots=True)
diff --git a/pipenv/vendor/requirementslib/models/requirements.py b/pipenv/vendor/requirementslib/models/requirements.py
index a36e5ba4..51411429 100644
--- a/pipenv/vendor/requirementslib/models/requirements.py
+++ b/pipenv/vendor/requirementslib/models/requirements.py
@@ -36,6 +36,7 @@ from ..utils import (
     add_ssh_scheme_to_git_uri,
     strip_ssh_from_git_uri,
 )
+from .setup_info import SetupInfo
 from .utils import (
     HASH_STRING,
     build_vcs_link,
@@ -46,7 +47,6 @@ from .utils import (
     init_requirement,
     is_pinned_requirement,
     make_install_requirement,
-    optional_instance_of,
     parse_extras,
     specs_to_string,
     split_markers_from_line,
@@ -56,6 +56,7 @@ from .utils import (
     validate_vcs,
     normalize_name,
     create_link,
+    get_pyproject
 )
 
 
@@ -148,13 +149,19 @@ class FileRequirement(object):
     uri = attr.ib()
     #: Link object representing the package to clone
     link = attr.ib()
+    #: PyProject Requirements
+    pyproject_requires = attr.ib(default=attr.Factory(list))
+    #: PyProject Build System
+    pyproject_backend = attr.ib(default=None)
+    #: PyProject Path
+    pyproject_path = attr.ib(default=None)
     _has_hashed_name = attr.ib(default=False)
     #: Package name
     name = attr.ib()
     #: A :class:`~pkg_resources.Requirement` isntance
     req = attr.ib()
-    #: Whether this is a direct url requirement
-    is_direct = attr.ib(default=False)
+    #: Setup metadata e.g. dependencies
+    setup_info = attr.ib(default=None)
 
     @classmethod
     def get_link_from_line(cls, line):
@@ -258,107 +265,110 @@ class FileRequirement(object):
 
         return LinkInfo(vcs_type, prefer, relpath, path, uri, link)
 
-    def __attrs_post_init__(self):
-        if self.req and getattr(self.req, "url"):
-            self.uri = self.req.url
+    @property
+    def setup_py_dir(self):
+        if self.setup_path:
+            return os.path.dirname(os.path.abspath(self.setup_path))
+
+    @property
+    def dependencies(self):
+        build_deps = []
+        setup_deps = []
+        deps = {}
+        if self.setup_info:
+            setup_info = self.setup_info.as_dict()
+            deps.update(setup_info.get("requires", {}))
+            setup_deps.extend(setup_info.get("setup_requires", []))
+            build_deps.extend(setup_info.get("build_requires", []))
+        if self.pyproject_requires:
+            build_deps.extend(self.pyproject_requires)
+        return deps, setup_deps, build_deps
 
     @uri.default
     def get_uri(self):
         if self.path and not self.uri:
             self._uri_scheme = "path"
-            self.uri = pip_shims.shims.path_to_url(os.path.abspath(self.path))
+            return pip_shims.shims.path_to_url(os.path.abspath(self.path))
         elif self.req and getattr(self.req, "url"):
-            self.uri = self.req.url
+            return self.req.url
 
     @name.default
     def get_name(self):
         loc = self.path or self.uri
-        if loc:
-            self._uri_scheme = "path" if self.path else "uri"
+        if loc and not self._uri_scheme:
+            self._uri_scheme = "path" if self.path else "file"
         name = None
-        if getattr(self, "req", None) and getattr(self.req, "name"):
-            return self.req.name
-        if self.link and self.link.egg_fragment:
+        if getattr(self, "req", None) and getattr(self.req, "name") and self.req.name is not None:
+            if self.is_direct_url:
+                return self.req.name
+        if self.link and self.link.egg_fragment and not self._has_hashed_name:
             return self.link.egg_fragment
         elif self.link and self.link.is_wheel:
             from pip_shims import Wheel
-
+            self._has_hashed_name = False
             return Wheel(self.link.filename).name
-        if (
-            self._uri_scheme != "uri"
-            and self.path
-            and self.setup_path
-            and self.setup_path.exists()
-        ):
-            from setuptools.dist import distutils
-
-            old_curdir = os.path.abspath(os.getcwd())
-            try:
-                os.chdir(str(self.setup_path.parent))
-                dist = distutils.core.run_setup(self.setup_path.as_posix())
-                name = dist.get_name()
-            except (FileNotFoundError, IOError) as e:
-                dist = None
-            except Exception as e:
-                from pip_shims.shims import make_abstract_dist
-
-                try:
-                    if not isinstance(Path, self.path):
-                        _path = Path(self.path)
-                    else:
-                        _path = self.path
-                    if self.editable:
-                        _ireq = pip_shims.shims.install_req_from_editable(_path.as_uri())
-                    else:
-                        _ireq = pip_shims.shims.install_req_from_line(_path.as_posix())
-                    dist = make_abstract_dist(_ireq).get_dist()
-                    name = dist.project_name
-                except (TypeError, ValueError, AttributeError) as e:
-                    dist = None
-            finally:
-                os.chdir(old_curdir)
+        elif self.link and ((self.link.scheme == "file" or self.editable) or (
+            self.path and self.setup_path and os.path.isfile(str(self.setup_path))
+        )):
+            if self.editable:
+                line = pip_shims.shims.path_to_url(self.setup_py_dir)
+                _ireq = pip_shims.shims.install_req_from_editable(line)
+            else:
+                _ireq = pip_shims.shims.install_req_from_line(Path(self.setup_py_dir).as_posix())
+            from .setup_info import SetupInfo
+            subdir = getattr(self, "subdirectory", None)
+            setupinfo = SetupInfo.from_ireq(_ireq, subdir=subdir)
+            if setupinfo:
+                self.setup_info = setupinfo
+                setupinfo_dict = setupinfo.as_dict()
+                setup_name = setupinfo_dict.get("name", None)
+                if setup_name:
+                    name = setup_name
+                    self._has_hashed_name = False
+                version = setupinfo_dict.get("version")
+                if version and not self.version:
+                    self.version = version
+                build_requires = setupinfo_dict.get("build_requires")
+                build_backend = setupinfo_dict.get("build_backend")
+                if build_requires and not self.pyproject_requires:
+                    self.pyproject_requires = build_requires
+                if build_backend and not self.pyproject_backend:
+                    self.pyproject_backend = build_backend
         hashed_loc = hashlib.sha256(loc.encode("utf-8")).hexdigest()
         hashed_name = hashed_loc[-7:]
-        if not name or name == "UNKNOWN":
+        if not name or name.lower() == "unknown":
             self._has_hashed_name = True
             name = hashed_name
-        if self.link and not self._has_hashed_name:
+        else:
+            self._has_hashed_name = False
+        name_in_link = getattr(self.link, "egg_fragment", "") if self.link else ""
+        if not self._has_hashed_name and name_in_link != name:
             self.link = create_link("{0}#egg={1}".format(self.link.url, name))
         return name
 
     @link.default
     def get_link(self):
         target = "{0}".format(self.uri)
-        if hasattr(self, "name"):
+        if hasattr(self, "name") and not self._has_hashed_name:
             target = "{0}#egg={1}".format(target, self.name)
         link = create_link(target)
         return link
 
     @req.default
     def get_requirement(self):
-        if self.link.is_artifact and not self.editable:
-            if self._uri_scheme == "uri":
-                if self.name:
-                    req_str = "{0} @ {1}".format(self.name, self.link.url_without_fragment)
-                else:
-                    req_str = "{0}".format(self.link.url_without_fragment)
-                req = init_requirement(req_str)
-                req.line = req_str
-            else:
-                req = init_requirement(normalize_name(self.name))
-        else:
-            req = init_requirement(normalize_name(self.name))
-            req.editable = False
-            req.line = self.link.url_without_fragment
-            if self.path and self.link and self.link.scheme.startswith("file"):
-                req.local_file = True
-                req.path = self.path
+        req = init_requirement(normalize_name(self.name))
+        req.editable = False
+        req.line = self.link.url_without_fragment
+        if self.path and self.link and self.link.scheme.startswith("file"):
+            req.local_file = True
+            req.path = self.path
+            if self.editable:
                 req.url = None
-                self._uri_scheme = "file"
             else:
-                req.local_file = False
-                req.path = None
-        if not getattr(req, "url", None):
+                req.url = self.link.url_without_fragment
+        else:
+            req.local_file = False
+            req.path = None
             req.url = self.link.url_without_fragment
         if self.editable:
             req.editable = True
@@ -389,6 +399,99 @@ class FileRequirement(object):
             return path.as_posix()
         return
 
+    @classmethod
+    def create(
+        cls, path=None, uri=None, editable=False, extras=None, link=None, vcs_type=None,
+        name=None, req=None, line=None, uri_scheme=None, setup_path=None, relpath=None
+    ):
+        import pip_shims.shims
+        if relpath and not path:
+            path = relpath
+        if not path and uri and link.scheme == "file":
+            path = os.path.abspath(pip_shims.shims.url_to_path(unquote(uri)))
+            try:
+                path = get_converted_relative_path(path)
+            except ValueError:  # Vistir raises a ValueError if it can't make a relpath
+                path = path
+        if line and not (uri_scheme and uri and link):
+            vcs_type, uri_scheme, relpath, path, uri, link = cls.get_link_from_line(line)
+        if not uri_scheme:
+            uri_scheme = "path" if path else "file"
+        if path and not uri:
+            uri = unquote(pip_shims.shims.path_to_url(os.path.abspath(path)))
+        if not link:
+            link = create_link(uri)
+        if not uri:
+            uri = unquote(link.url_without_fragment)
+        if not extras:
+            extras = []
+        pyproject_path = None
+        if path is not None:
+            pyproject_requires = get_pyproject(os.path.abspath(path))
+        pyproject_backend = None
+        pyproject_requires = None
+        if pyproject_requires is not None:
+            pyproject_requires, pyproject_backend = pyproject_requires
+        if path:
+            pyproject_path = Path(path).joinpath("pyproject.toml")
+            if not pyproject_path.exists():
+                pyproject_path = None
+        if not setup_path and path is not None:
+            setup_path = Path(path).joinpath("setup.py")
+        if setup_path and isinstance(setup_path, Path):
+            setup_path = setup_path.as_posix()
+        creation_kwargs = {
+            "editable": editable,
+            "extras": extras,
+            "pyproject_path": pyproject_path,
+            "setup_path": setup_path if setup_path else None,
+            "uri_scheme": uri_scheme,
+            "link": link,
+            "uri": uri,
+            "pyproject_requires": pyproject_requires,
+            "pyproject_backend": pyproject_backend
+        }
+        if vcs_type:
+            creation_kwargs["vcs_type"] = vcs_type
+        _line = None
+        if not name:
+            import pip_shims.shims
+            _line = unquote(link.url_without_fragment) if link.url else uri
+            if editable:
+                ireq = pip_shims.shims.install_req_from_editable(_line)
+            else:
+                _line = path if (uri_scheme and uri_scheme == "path") else _line
+                ireq = pip_shims.shims.install_req_from_line(_line)
+            setup_info = SetupInfo.from_ireq(ireq)
+            setupinfo_dict = setup_info.as_dict()
+            setup_name = setupinfo_dict.get("name", None)
+            if setup_name:
+                name = setup_name
+                build_requires = setupinfo_dict.get("build_requires", [])
+                build_backend = setupinfo_dict.get("build_backend", [])
+                if not creation_kwargs.get("pyproject_requires") and build_requires:
+                    creation_kwargs["pyproject_requires"] = build_requires
+                if not creation_kwargs.get("pyproject_backend") and build_backend:
+                    creation_kwargs["pyproject_backend"] = build_backend
+            creation_kwargs["setup_info"] = setup_info
+        if path or relpath:
+            creation_kwargs["path"] = relpath if relpath else path
+        if req:
+            creation_kwargs["req"] = req
+        if creation_kwargs.get("req") and line and not getattr(creation_kwargs["req"], "line", None):
+            creation_kwargs["req"].line = line
+        if name:
+            creation_kwargs["name"] = name
+        cls_inst = cls(**creation_kwargs)
+        if not _line:
+            if editable and uri_scheme == "path":
+                _line = relpath if relpath else path
+            else:
+                _line = unquote(cls_inst.link.url_without_fragment) or cls_inst.uri
+                _line = "{0}#egg={1}".format(line, cls_inst.name) if not cls_inst._has_hashed_name else _line
+        cls_inst.req.line = line if line else _line
+        return cls_inst
+
     @classmethod
     def from_line(cls, line):
         line = line.strip('"').strip("'")
@@ -410,7 +513,6 @@ class FileRequirement(object):
                 name = getattr(req, "name", None)
                 line = getattr(req, "url", None)
         vcs_type, prefer, relpath, path, uri, link = cls.get_link_from_line(line)
-        setup_path = Path(path) / "setup.py" if path else None
         arg_dict = {
             "path": relpath if relpath else path,
             "uri": unquote(link.url_without_fragment),
@@ -418,6 +520,7 @@ class FileRequirement(object):
             "editable": editable,
             "setup_path": setup_path,
             "uri_scheme": prefer,
+            "line": line
         }
         if link and link.is_wheel:
             from pip_shims import Wheel
@@ -427,10 +530,7 @@ class FileRequirement(object):
             arg_dict["name"] = name
         elif link.egg_fragment:
             arg_dict["name"] = link.egg_fragment
-        if req:
-            arg_dict["req"] = req
-        created = cls(**arg_dict)
-        return created
+        return cls.create(**arg_dict)
 
     @classmethod
     def from_pipfile(cls, name, pipfile):
@@ -466,9 +566,6 @@ class FileRequirement(object):
         if not uri:
             uri = pip_shims.shims.path_to_url(path)
         link = create_link(uri)
-        req = None
-        if link.is_artifact and not link.is_wheel and not link.scheme.startswith("file"):
-            req = init_requirement("{0}@{1}".format(name, uri))
         arg_dict = {
             "name": name,
             "path": path,
@@ -477,13 +574,14 @@ class FileRequirement(object):
             "link": link,
             "uri_scheme": uri_scheme,
         }
-        if req:
-            arg_dict["req"] = req
-        return cls(**arg_dict)
+        if link.scheme != "file" and not pipfile.get("editable", False):
+            arg_dict["line"] = "{0}@ {1}".format(name, link.url_without_fragment)
+        return cls.create(**arg_dict)
 
     @property
     def line_part(self):
         if self._uri_scheme and self._uri_scheme == "path":
+            # We may need any one of these for passing to pip
             seed = self.path or unquote(self.link.url_without_fragment) or self.uri
         elif (self._uri_scheme and self._uri_scheme == "file") or (
             (self.link.is_artifact or self.link.is_wheel) and self.link.url
@@ -491,16 +589,16 @@ class FileRequirement(object):
             seed = unquote(self.link.url_without_fragment) or self.uri
         # add egg fragments to remote artifacts (valid urls only)
         if not self._has_hashed_name and self.is_remote_artifact:
-            if not self.link.is_wheel and self.link.is_artifact:
-                seed = "{0}@{1}".format(self.name, seed)
-            else:
-                seed += "#egg={0}".format(self.name)
+            seed += "#egg={0}".format(self.name)
         editable = "-e " if self.editable else ""
         return "{0}{1}".format(editable, seed)
 
     @property
     def pipfile_part(self):
-        excludes = ["_base_line", "_has_hashed_name", "setup_path"]
+        excludes = [
+            "_base_line", "_has_hashed_name", "setup_path", "pyproject_path",
+            "pyproject_requires", "pyproject_backend", "setup_info"
+        ]
         filter_func = lambda k, v: bool(v) is True and k.name not in excludes
         pipfile_dict = attr.asdict(self, filter=filter_func).copy()
         name = pipfile_dict.pop("name")
@@ -687,10 +785,19 @@ class VCSRequirement(FileRequirement):
         )
         if not self.is_local:
             vcsrepo.obtain()
+        pyproject_info = None
         if self.subdirectory:
             self.setup_path = os.path.join(checkout_dir, self.subdirectory, "setup.py")
+            self.pyproject_path = os.path.join(checkout_dir, self.subdirectory, "pyproject.toml")
+            pyproject_info = get_pyproject(os.path.join(checkout_dir, self.subdirectory))
         else:
             self.setup_path = os.path.join(checkout_dir, "setup.py")
+            self.pyproject_path = os.path.join(checkout_dir, "pyproject.toml")
+            pyproject_info = get_pyproject(checkout_dir)
+        if pyproject_info is not None:
+            pyproject_requires, pyproject_backend = pyproject_info
+            self.pyproject_requires = pyproject_requires
+            self.pyproject_backend = pyproject_backend
         return vcsrepo
 
     def get_commit_hash(self):
@@ -846,7 +953,10 @@ class VCSRequirement(FileRequirement):
 
     @property
     def pipfile_part(self):
-        excludes = ["_repo", "_base_line", "setup_path", "_has_hashed_name"]
+        excludes = [
+            "_repo", "_base_line", "setup_path", "_has_hashed_name", "pyproject_path",
+            "pyproject_requires", "pyproject_backend", "setup_info"
+        ]
         filter_func = lambda k, v: bool(v) is True and k.name not in excludes
         pipfile_dict = attr.asdict(self, filter=filter_func).copy()
         if "vcs" in pipfile_dict:
@@ -952,7 +1062,6 @@ class Requirement(object):
         line = line.split(" ", 1)[1] if editable else line
         line, markers = split_markers_from_line(line)
         line, extras = pip_shims.shims._strip_extras(line)
-        specifiers = ""
         if extras:
             extras = parse_extras(extras)
         line = line.strip('"').strip("'").strip()
@@ -984,7 +1093,6 @@ class Requirement(object):
                 spec_idx = min((line.index(match) for match in spec_matches))
                 name = line[:spec_idx]
                 version = line[spec_idx:]
-                specifiers = version
             if not extras:
                 name, extras = pip_shims.shims._strip_extras(name)
                 if extras:
@@ -995,7 +1103,7 @@ class Requirement(object):
         req_markers = None
         if markers:
             req_markers = PackagingRequirement("fakepkg; {0}".format(markers))
-        r.req.marker = getattr(req_markers, "marker", None)
+        r.req.marker = getattr(req_markers, "marker", None) if req_markers else None
         r.req.local_file = getattr(r.req, "local_file", False)
         name = getattr(r.req, "name", None)
         if not name:
@@ -1021,7 +1129,15 @@ class Requirement(object):
             args["extras"] = sorted(dedup([extra.lower() for extra in r.extras]))
         if hashes:
             args["hashes"] = hashes
-        return cls(**args)
+        cls_inst = cls(**args)
+        if not cls_inst.is_named and (not cls_inst.editable or cls_inst.req._has_hashed_name):
+            old_name = cls_inst.req.req.name or cls_inst.req.name
+            info_dict = cls_inst.run_requires()
+            calced_name = info_dict.get("name", old_name)
+            if old_name != calced_name:
+                cls_inst.req.req.line.replace(old_name, calced_name)
+            cls_inst.name = cls_inst.req.name = calced_name
+        return cls_inst
 
     @classmethod
     def from_ireq(cls, ireq):
@@ -1074,6 +1190,22 @@ class Requirement(object):
         cls_inst = cls(**args)
         if cls_inst.is_named:
             cls_inst.req.req.line = cls_inst.as_line()
+        old_name = cls_inst.req.req.name or cls_inst.req.name
+        if not cls_inst.is_named and not cls_inst.editable and not name:
+            if cls_inst.is_vcs:
+                import pip_shims.shims
+                ireq = pip_shims.shims.install_req_from_req(cls_inst.as_line(include_hashes=False))
+                info = SetupInfo.from_ireq(ireq)
+                if info is not None:
+                    info_dict = info.as_dict()
+                    cls_inst.req.setup_info = info
+                else:
+                    info_dict = {}
+            else:
+                info_dict = cls_inst.run_requires()
+            found_name = info_dict.get("name", old_name)
+            if old_name != found_name:
+                cls_inst.req.req.line.replace(old_name, found_name)
         return cls_inst
 
     def as_line(
@@ -1159,6 +1291,10 @@ class Requirement(object):
     def constraint_line(self):
         return self.as_line()
 
+    @property
+    def is_direct_url(self):
+        return self.is_file_or_url and self.req.is_direct_url
+
     def as_pipfile(self):
         good_keys = (
             "hashes",
@@ -1294,6 +1430,26 @@ class Requirement(object):
             finder = get_finder(sources=sources)
         return find_all_matches(finder, self.as_ireq())
 
+    def run_requires(self, sources=None, finder=None):
+        if self.req and self.req.setup_info is not None:
+            info_dict = self.req.setup_info.as_dict()
+        else:
+            from .setup_info import SetupInfo
+            if not finder:
+                from .dependencies import get_finder
+                finder = get_finder(sources=sources)
+            info = SetupInfo.from_requirement(self, finder=finder)
+            if info is None:
+                return {}
+            info_dict = info.get_info()
+            if self.req and not self.req.setup_info:
+                self.req.setup_info = info
+        if self.req._has_hashed_name and info_dict.get("name"):
+            self.req.name = self.name = info_dict["name"]
+            if self.req.req.name != info_dict["name"]:
+                self.req.req.name = info_dict["name"]
+        return info_dict
+
     def merge_markers(self, markers):
         if not isinstance(markers, Marker):
             markers = Marker(markers)
diff --git a/pipenv/vendor/requirementslib/models/setup_info.py b/pipenv/vendor/requirementslib/models/setup_info.py
new file mode 100644
index 00000000..319dd6bd
--- /dev/null
+++ b/pipenv/vendor/requirementslib/models/setup_info.py
@@ -0,0 +1,378 @@
+# -*- coding=utf-8 -*-
+import configparser
+import contextlib
+import os
+
+import attr
+import packaging.version
+import packaging.specifiers
+import packaging.utils
+
+try:
+    from setuptools.dist import distutils
+except ImportError:
+    import distutils
+
+from appdirs import user_cache_dir
+from six.moves.urllib.parse import unquote
+from vistir.compat import Path
+from vistir.contextmanagers import cd
+from vistir.path import create_tracked_tempdir, ensure_mkdir_p, mkdir_p
+
+from .utils import init_requirement, get_pyproject
+
+try:
+    from os import scandir
+except ImportError:
+    from scandir import scandir
+
+
+CACHE_DIR = os.environ.get("PIPENV_CACHE_DIR", user_cache_dir("pipenv"))
+
+
+@contextlib.contextmanager
+def _suppress_distutils_logs():
+    """Hack to hide noise generated by `setup.py develop`.
+
+    There isn't a good way to suppress them now, so let's monky-patch.
+    See https://bugs.python.org/issue25392.
+    """
+
+    f = distutils.log.Log._log
+
+    def _log(log, level, msg, args):
+        if level >= distutils.log.ERROR:
+            f(log, level, msg, args)
+
+    distutils.log.Log._log = _log
+    yield
+    distutils.log.Log._log = f
+
+
+@ensure_mkdir_p(mode=0o775)
+def _get_src_dir():
+    src = os.environ.get("PIP_SRC")
+    if src:
+        return src
+    virtual_env = os.environ.get("VIRTUAL_ENV")
+    if virtual_env:
+        return os.path.join(virtual_env, "src")
+    return os.path.join(os.getcwd(), "src")  # Match pip's behavior.
+
+
+def _prepare_wheel_building_kwargs(ireq):
+    download_dir = os.path.join(CACHE_DIR, "pkgs")
+    mkdir_p(download_dir)
+
+    wheel_download_dir = os.path.join(CACHE_DIR, "wheels")
+    mkdir_p(wheel_download_dir)
+
+    if ireq.source_dir is not None:
+        src_dir = ireq.source_dir
+    elif ireq.editable:
+        src_dir = _get_src_dir()
+    else:
+        src_dir = create_tracked_tempdir(prefix="reqlib-src")
+
+    # This logic matches pip's behavior, although I don't fully understand the
+    # intention. I guess the idea is to build editables in-place, otherwise out
+    # of the source tree?
+    if ireq.editable:
+        build_dir = src_dir
+    else:
+        build_dir = create_tracked_tempdir(prefix="reqlib-build")
+
+    return {
+        "build_dir": build_dir,
+        "src_dir": src_dir,
+        "download_dir": download_dir,
+        "wheel_download_dir": wheel_download_dir,
+    }
+
+
+def iter_egginfos(path, pkg_name=None):
+    for entry in scandir(path):
+        if entry.is_dir():
+            if not entry.name.endswith("egg-info"):
+                for dir_entry in iter_egginfos(entry.path, pkg_name=pkg_name):
+                    yield dir_entry
+            elif pkg_name is None or entry.name.startswith(pkg_name):
+                yield entry
+
+
+def find_egginfo(target, pkg_name=None):
+    egg_dirs = (egg_dir for egg_dir in iter_egginfos(target, pkg_name=pkg_name))
+    if pkg_name:
+        return next(iter(egg_dirs), None)
+    else:
+        for egg_dir in egg_dirs:
+            yield egg_dir
+
+
+def get_metadata(path, pkg_name=None):
+    if pkg_name:
+        pkg_name = packaging.utils.canonicalize_name(pkg_name)
+    egg_dir = next(iter(find_egginfo(path, pkg_name=pkg_name)), None)
+    if egg_dir is not None:
+        import pkg_resources
+
+        egg_dir = os.path.abspath(egg_dir)
+        base_dir = os.path.dirname(egg_dir)
+        path_metadata = pkg_resources.PathMetadata(base_dir, egg_dir)
+        dist = next(
+            iter(pkg_resources.distributions_from_metadata(path_metadata.egg_info)),
+            None,
+        )
+        if dist:
+            requires = dist.requires()
+            dep_map = dist._build_dep_map()
+            deps = []
+            for k in dep_map.keys():
+                if k is None:
+                    deps.extend(dep_map.get(k))
+                    continue
+                else:
+                    _deps = dep_map.get(k)
+                    k = k.replace(":", "; ")
+                    _deps = [
+                        pkg_resources.Requirement.parse("{0}{1}".format(str(req), k))
+                        for req in _deps
+                    ]
+                    deps.extend(_deps)
+            return {
+                "name": dist.project_name,
+                "version": dist.version,
+                "requires": requires,
+            }
+
+
+@attr.s(slots=True)
+class SetupInfo(object):
+    name = attr.ib(type=str, default=None)
+    base_dir = attr.ib(type=Path, default=None)
+    version = attr.ib(type=packaging.version.Version, default=None)
+    extras = attr.ib(type=list, default=attr.Factory(list))
+    requires = attr.ib(type=dict, default=attr.Factory(dict))
+    build_requires = attr.ib(type=list, default=attr.Factory(list))
+    build_backend = attr.ib(type=list, default=attr.Factory(list))
+    setup_requires = attr.ib(type=dict, default=attr.Factory(list))
+    python_requires = attr.ib(type=packaging.specifiers.SpecifierSet, default=None)
+    extras = attr.ib(type=dict, default=attr.Factory(dict))
+    setup_cfg = attr.ib(type=Path, default=None)
+    setup_py = attr.ib(type=Path, default=None)
+    pyproject = attr.ib(type=Path, default=None)
+    ireq = attr.ib(default=None)
+    extra_kwargs = attr.ib(default=attr.Factory(dict), type=dict)
+
+    def parse_setup_cfg(self):
+        if self.setup_cfg is not None and self.setup_cfg.exists():
+            default_opts = {
+                "metadata": {"name": "", "version": ""},
+                "options": {
+                    "install_requires": "",
+                    "python_requires": "",
+                    "build_requires": "",
+                    "setup_requires": "",
+                    "extras": "",
+                },
+            }
+            parser = configparser.ConfigParser(default_opts)
+            parser.read(self.setup_cfg.as_posix())
+            if parser.has_option("metadata", "name"):
+                name = parser.get("metadata", "name")
+                if not self.name and name is not None:
+                    self.name = name
+            if parser.has_option("metadata", "version"):
+                version = parser.get("metadata", "version")
+                if not self.version and version is not None:
+                    self.version = version
+            if parser.has_option("options", "install_requires"):
+                self.requires.update(
+                    {
+                        dep.strip(): init_requirement(dep.strip())
+                        for dep in parser.get("options", "install_requires").split("\n")
+                        if dep
+                    }
+                )
+            if parser.has_option("options", "python_requires"):
+                python_requires = parser.get("options", "python_requires")
+                if python_requires and not self.python_requires:
+                    self.python_requires = python_requires
+            if parser.has_option("options", "extras_require"):
+                self.extras.update(
+                    {
+                        section: [
+                            dep.strip()
+                            for dep in parser.get(
+                                "options.extras_require", section
+                            ).split("\n")
+                            if dep
+                        ]
+                        for section in parser.options("options.extras_require")
+                    }
+                )
+
+    def run_setup(self):
+        if self.setup_py is not None and self.setup_py.exists():
+            with cd(self.setup_py.parent), _suppress_distutils_logs():
+                from setuptools.dist import distutils
+
+                dist = distutils.core.run_setup(
+                    self.setup_py.as_posix(), ["egg_info", "--egg-base", self.base_dir]
+                )
+                name = dist.get_name()
+                if name:
+                    self.name = name
+                if dist.python_requires and not self.python_requires:
+                    self.python_requires = packaging.specifiers.SpecifierSet(
+                        dist.python_requires
+                    )
+                if dist.extras_require and not self.extras:
+                    self.extras = dist.extras_require
+                install_requires = dist.get_requires()
+                if not install_requires:
+                    install_requires = dist.install_requires
+                if install_requires and not self.requires:
+                    requirements = [init_requirement(req) for req in install_requires]
+                    self.requires.update({req.key: req for req in requirements})
+                if dist.setup_requires and not self.setup_requires:
+                    self.setup_requires = dist.setup_requires
+                if not self.version:
+                    self.version = dist.get_version()
+
+    def get_egg_metadata(self):
+        if self.setup_py is not None and self.setup_py.exists():
+            metadata = get_metadata(self.setup_py.parent.as_posix(), pkg_name=self.name)
+            if metadata:
+                if not self.name:
+                    self.name = metadata.get("name", self.name)
+                if not self.version:
+                    self.version = metadata.get("version", self.version)
+                self.requires.update(
+                    {req.key: req for req in metadata.get("requires", {})}
+                )
+
+    def run_pyproject(self):
+        if self.pyproject and self.pyproject.exists():
+            result = get_pyproject(self.pyproject.parent)
+            if result is not None:
+                requires, backend = result
+                if backend:
+                    self.build_backend = backend
+                if requires and not self.build_requires:
+                    self.build_requires = requires
+
+    def get_info(self):
+        if self.setup_cfg and self.setup_cfg.exists():
+            self.parse_setup_cfg()
+        if self.setup_py and self.setup_py.exists():
+            if not self.requires or not self.name:
+                try:
+                    self.run_setup()
+                except Exception as e:
+                    self.get_egg_metadata()
+                if not self.requires or not self.name:
+                    self.get_egg_metadata()
+
+        if self.pyproject and self.pyproject.exists():
+            self.run_pyproject()
+        return self.as_dict()
+
+    def as_dict(self):
+        prop_dict = {
+            "name": self.name,
+            "version": self.version,
+            "base_dir": self.base_dir,
+            "ireq": self.ireq,
+            "build_backend": self.build_backend,
+            "build_requires": self.build_requires,
+            "requires": self.requires,
+            "setup_requires": self.setup_requires,
+            "python_requires": self.python_requires,
+            "extras": self.extras,
+            "extra_kwargs": self.extra_kwargs,
+            "setup_cfg": self.setup_cfg,
+            "setup_py": self.setup_py,
+            "pyproject": self.pyproject,
+        }
+        return {k: v for k, v in prop_dict.items() if v}
+
+    @classmethod
+    def from_requirement(cls, requirement, finder=None):
+        ireq = requirement.as_ireq()
+        subdir = getattr(requirement.req, "subdirectory", None)
+        return cls.from_ireq(ireq, subdir=subdir, finder=finder)
+
+    @classmethod
+    def from_ireq(cls, ireq, subdir=None, finder=None):
+        import pip_shims.shims
+
+        if ireq.link.is_wheel:
+            return
+        if not finder:
+            from .dependencies import get_finder
+
+            finder = get_finder()
+        kwargs = _prepare_wheel_building_kwargs(ireq)
+        ireq.populate_link(finder, False, False)
+        ireq.ensure_has_source_dir(kwargs["build_dir"])
+        if not (
+            ireq.editable
+            and pip_shims.shims.is_file_url(ireq.link)
+            and not ireq.link.is_artifact
+        ):
+            if ireq.is_wheel:
+                only_download = True
+                download_dir = kwargs["wheel_download_dir"]
+            else:
+                only_download = False
+                download_dir = kwargs["download_dir"]
+        ireq_src_dir = None
+        if ireq.link.scheme == "file":
+            path = pip_shims.shims.url_to_path(unquote(ireq.link.url_without_fragment))
+            if pip_shims.shims.is_installable_dir(path):
+                ireq_src_dir = path
+        if not ireq.editable or not (pip_shims.is_file_url(ireq.link) and ireq_src_dir):
+            pip_shims.shims.unpack_url(
+                ireq.link,
+                ireq.source_dir,
+                download_dir,
+                only_download=only_download,
+                session=finder.session,
+                hashes=ireq.hashes(False),
+                progress_bar="off",
+            )
+        if ireq.editable:
+            created = cls.create(
+                ireq.source_dir, subdirectory=subdir, ireq=ireq, kwargs=kwargs
+            )
+        else:
+            build_dir = ireq.build_location(kwargs["build_dir"])
+            ireq._temp_build_dir.path = kwargs["build_dir"]
+            created = cls.create(
+                build_dir, subdirectory=subdir, ireq=ireq, kwargs=kwargs
+            )
+        created.get_info()
+        return created
+
+    @classmethod
+    def create(cls, base_dir, subdirectory=None, ireq=None, kwargs=None):
+        if not base_dir or base_dir is None:
+            return
+
+        creation_kwargs = {"extra_kwargs": kwargs}
+        if not isinstance(base_dir, Path):
+            base_dir = Path(base_dir)
+        creation_kwargs["base_dir"] = base_dir.as_posix()
+        pyproject = base_dir.joinpath("pyproject.toml")
+
+        if subdirectory is not None:
+            base_dir = base_dir.joinpath(subdirectory)
+        setup_py = base_dir.joinpath("setup.py")
+        setup_cfg = base_dir.joinpath("setup.cfg")
+        creation_kwargs["pyproject"] = pyproject
+        creation_kwargs["setup_py"] = setup_py
+        creation_kwargs["setup_cfg"] = setup_cfg
+        if ireq:
+            creation_kwargs["ireq"] = ireq
+        return cls(**creation_kwargs)
diff --git a/pipenv/vendor/requirementslib/models/utils.py b/pipenv/vendor/requirementslib/models/utils.py
index aa7ffd68..2b47ee9b 100644
--- a/pipenv/vendor/requirementslib/models/utils.py
+++ b/pipenv/vendor/requirementslib/models/utils.py
@@ -1,6 +1,7 @@
 # -*- coding: utf-8 -*-
 from __future__ import absolute_import
 
+import io
 import os
 import sys
 
@@ -9,6 +10,7 @@ from itertools import chain, groupby
 from operator import attrgetter
 
 import six
+import tomlkit
 
 from attr import validators
 from first import first
@@ -17,7 +19,7 @@ from packaging.specifiers import InvalidSpecifier, Specifier, SpecifierSet
 from vistir.misc import dedup
 
 
-from ..utils import SCHEME_LIST, VCS_LIST, is_star, strip_ssh_from_git_uri, add_ssh_scheme_to_git_uri
+from ..utils import SCHEME_LIST, VCS_LIST, is_star, add_ssh_scheme_to_git_uri
 
 
 HASH_STRING = " --hash={0}"
@@ -93,6 +95,7 @@ def build_vcs_link(vcs, uri, name=None, ref=None, subdirectory=None, extras=None
         if extras:
             extras = extras_to_string(extras)
             uri = "{0}{1}".format(uri, extras)
+    # if subdirectory:
     if subdirectory:
         uri = "{0}&subdirectory={1}".format(uri, subdirectory)
     return create_link(uri)
@@ -112,6 +115,42 @@ def get_version(pipfile_entry):
     return ""
 
 
+def get_pyproject(path):
+    from vistir.compat import Path
+    if not path:
+        return
+    if not isinstance(path, Path):
+        path = Path(path)
+    if not path.is_dir():
+        path = path.parent
+    pp_toml = path.joinpath("pyproject.toml")
+    setup_py = path.joinpath("setup.py")
+    if not pp_toml.exists():
+        if setup_py.exists():
+            return None
+    else:
+        pyproject_data = {}
+        with io.open(pp_toml.as_posix(), encoding="utf-8") as fh:
+            pyproject_data = tomlkit.loads(fh.read())
+        build_system = pyproject_data.get("build-system", None)
+        if build_system is None:
+            if setup_py.exists():
+                requires = ["setuptools", "wheel"]
+                backend = "setuptools.build_meta"
+            else:
+                requires = ["setuptools>=38.2.5", "wheel"]
+                backend = "setuptools.build_meta"
+            build_system = {
+                "requires": requires,
+                "build-backend": backend
+            }
+            pyproject_data["build_system"] = build_system
+        else:
+            requires = build_system.get("requires")
+            backend = build_system.get("build-backend")
+        return (requires, backend)
+
+
 def split_markers_from_line(line):
     """Split markers from a dependency"""
     if not any(line.startswith(uri_prefix) for uri_prefix in SCHEME_LIST):
diff --git a/pipenv/vendor/requirementslib/models/vcs.py b/pipenv/vendor/requirementslib/models/vcs.py
index dd8cc3a4..6a15db3f 100644
--- a/pipenv/vendor/requirementslib/models/vcs.py
+++ b/pipenv/vendor/requirementslib/models/vcs.py
@@ -4,7 +4,6 @@ import os
 import pip_shims
 
 
-
 @attr.s
 class VCSRepository(object):
     url = attr.ib()
@@ -32,7 +31,7 @@ class VCSRepository(object):
 
     def obtain(self):
         if (os.path.exists(self.checkout_directory) and not
-                    self.repo_instance.is_repository_directory(self.checkout_directory)):
+                self.repo_instance.is_repository_directory(self.checkout_directory)):
             self.repo_instance.unpack(self.checkout_directory)
         elif not os.path.exists(self.checkout_directory):
             self.repo_instance.obtain(self.checkout_directory)
diff --git a/tests/integration/conftest.py b/tests/integration/conftest.py
index 0ab0ab22..6ed95b3e 100644
--- a/tests/integration/conftest.py
+++ b/tests/integration/conftest.py
@@ -56,8 +56,17 @@ def check_github_ssh():
     return res
 
 
+def check_for_mercurial():
+    c = delegator.run("hg --help")
+    if c.return_code != 0:
+        return False
+    else:
+        return True
+
+
 TESTS_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
 PYPI_VENDOR_DIR = os.path.join(TESTS_ROOT, 'pypi')
+WE_HAVE_HG = check_for_mercurial()
 prepare_pypi_packages(PYPI_VENDOR_DIR)
 
 
@@ -66,6 +75,8 @@ def pytest_runtest_setup(item):
         pytest.skip('requires internet')
     if item.get_marker('needs_github_ssh') is not None and not WE_HAVE_GITHUB_SSH_KEYS:
         pytest.skip('requires github ssh')
+    if item.get_marker('needs_hg') is not None and not WE_HAVE_HG:
+        pytest.skip('requires mercurial')
 
 
 @pytest.fixture
@@ -100,6 +111,8 @@ def isolate(pathlib_tmpdir):
     os.environ["GIT_AUTHOR_EMAIL"] = fs_str("pipenv@pipenv.org")
     mkdir_p(os.path.join(home_dir, ".virtualenvs"))
     os.environ["WORKON_HOME"] = fs_str(os.path.join(home_dir, ".virtualenvs"))
+    global WE_HAVE_GITHUB_SSH_KEYS
+    WE_HAVE_GITHUB_SSH_KEYS = check_github_ssh()
 
 
 WE_HAVE_INTERNET = check_internet()
diff --git a/tests/integration/test_uninstall.py b/tests/integration/test_uninstall.py
index e19a1400..5f493cac 100644
--- a/tests/integration/test_uninstall.py
+++ b/tests/integration/test_uninstall.py
@@ -84,7 +84,7 @@ def test_uninstall_all_local_files(PipenvInstance, testsroot):
     # Not sure where travis/appveyor run tests from
     source_path = os.path.abspath(os.path.join(testsroot, "test_artifacts", file_name))
 
-    with PipenvInstance() as p:
+    with PipenvInstance(chdir=True) as p:
         shutil.copy(source_path, os.path.join(p.path, file_name))
         os.mkdir(os.path.join(p.path, "requests"))
         c = p.pipenv("install {}".format(file_name))
@@ -92,7 +92,9 @@ def test_uninstall_all_local_files(PipenvInstance, testsroot):
         c = p.pipenv("uninstall --all")
         assert c.return_code == 0
         assert "requests" in c.out
-        assert "requests" not in p.pipfile["packages"]
+        # Uninstall --all is not supposed to remove things from the pipfile
+        # Note that it didn't before, but that instead local filenames showed as hashes
+        assert "requests" in p.pipfile["packages"]
 
 
 @pytest.mark.run
