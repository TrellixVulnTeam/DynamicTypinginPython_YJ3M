commit dec7be54d716d078390232c5ac5a78991ca3e0b1
Author: Dan Ryan <dan@danryan.co>
Date:   Sun Nov 11 16:39:23 2018 -0500

    Introduce `pipenv.environments.Environment`
    
    - Specific construct for isolationg operations
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/pipenv/core.py b/pipenv/core.py
index 3cbd1645..021b0f3c 100644
--- a/pipenv/core.py
+++ b/pipenv/core.py
@@ -915,7 +915,15 @@ def do_create_virtualenv(python=None, site_packages=False, pypi_mirror=None):
     project_file_name = os.path.join(project.virtualenv_location, ".project")
     with open(project_file_name, "w") as f:
         f.write(vistir.misc.fs_str(project.project_directory))
-    fix_venv_site(project.env_paths["lib"])
+    from .environment import Environment
+    sources = project.pipfile_sources
+    project._environment = Environment(
+        prefix=project.get_location_for_virtualenv(),
+        is_venv=True,
+        sources=sources,
+        pipfile=project.parsed_pipfile
+    )
+    project._environment.add_dist("pipenv")
     # Say where the virtualenv is.
     do_where(virtualenv=True, bare=False)
 
@@ -1129,7 +1137,7 @@ def do_purge(bare=False, downloads=False, allow_global=False):
 
     # Remove comments from the output, if any.
     installed = set([
-        pep423_name(pkg.project_name) for pkg in project.get_installed_packages()
+        pep423_name(pkg.project_name) for pkg in project.environment.get_installed_packages()
     ])
     bad_pkgs = set([pep423_name(pkg) for pkg in BAD_PACKAGES])
     # Remove setuptools, pip, etc from targets for removal
@@ -1662,7 +1670,7 @@ def do_outdated(pypi_mirror=None):
     packages = {}
     package_info = namedtuple("PackageInfo", ["name", "installed", "available"])
 
-    installed_packages = project.get_installed_packages()
+    installed_packages = project.environment.get_installed_packages()
     outdated_packages = {
         canonicalize_name(pkg.project_name): package_info
         (pkg.project_name, pkg.parsed_version, pkg.latest_version)
@@ -1916,7 +1924,14 @@ def do_install(
 
         # make a tuple of (display_name, entry)
         pkg_list = packages + ["-e {0}".format(pkg) for pkg in editable_packages]
-
+        if not system and not project.virtualenv_exists:
+            with create_spinner("Creating virtualenv...") as sp:
+                try:
+                    do_create_virtualenv(pypi_mirror=pypi_mirror)
+                except KeyboardInterrupt:
+                    cleanup_virtualenv(bare=(not environments.is_verbose()))
+                    sys.exit(1)
+                sp.write_err("Ok...")
         for pkg_line in pkg_list:
             click.echo(
                 crayons.normal(
@@ -1925,8 +1940,7 @@ def do_install(
                 )
             )
             # pip install:
-            with vistir.contextmanagers.temp_environ(), \
-                    create_spinner("Installing...") as sp:
+            with vistir.contextmanagers.temp_environ(), create_spinner("Installing...") as sp:
                 os.environ["PIP_USER"] = vistir.compat.fs_str("0")
                 try:
                     pkg_requirement = Requirement.from_line(pkg_line)
@@ -2055,30 +2069,17 @@ def do_uninstall(
     package_map = {
         canonicalize_name(p): p for p in packages if p
     }
-    installed_package_names = set([
-        canonicalize_name(pkg.project_name) for pkg in project.get_installed_packages()
-    ])
+    installed_package_names = project.installed_package_names
     # Intelligently detect if --dev should be used or not.
     lockfile_packages = set()
     if project.lockfile_exists:
-        develop = set(
-            [canonicalize_name(k) for k in project.lockfile_content["develop"].keys()]
-        )
-        default = set(
-            [canonicalize_name(k) for k in project.lockfile_content["default"].keys()]
-        )
-        lockfile_packages |= develop | default
+        project_pkg_names = project.lockfile_package_names
     else:
-        develop = set(
-            [canonicalize_name(k) for k in project.dev_packages.keys()]
-        )
-        default = set(
-            [canonicalize_name(k) for k in project.packages.keys()]
-        )
+        project_pkg_names = project.pipfile_package_names
     pipfile_remove = True
     # Uninstall [dev-packages], if --dev was provided.
     if all_dev:
-        if "dev-packages" not in project.parsed_pipfile and not develop:
+        if "dev-packages" not in project.parsed_pipfile and not project_pkg_names["dev"]:
             click.echo(
                 crayons.normal(
                     "No {0} to uninstall.".format(crayons.red("[dev-packages]")),
@@ -2091,28 +2092,33 @@ def do_uninstall(
                 fix_utf8("Un-installing {0}…".format(crayons.red("[dev-packages]"))), bold=True
             )
         )
-        package_names = develop
+        package_names = project_pkg_names["dev"]
+
     # Remove known "bad packages" from the list.
-    bad_pkgs = set([canonicalize_name(pkg) for pkg in BAD_PACKAGES])
-    for bad_package in BAD_PACKAGES:
-        normalized_bad_pkg = canonicalize_name(bad_package)
-        if normalized_bad_pkg in package_map:
-            if environments.is_verbose():
-                click.echo("Ignoring {0}.".format(bad_package), err=True)
-            pkg_name_index = package_names.index(package_map[normalized_bad_pkg])
-            del package_names[pkg_name_index]
-    used_packages = develop | default & installed_package_names
+    bad_pkgs = get_canonical_names(BAD_PACKAGES)
+    ignored_packages = bad_pkgs & set(list(package_map.keys()))
+    for ignored_pkg in ignored_packages:
+        if environments.is_verbose():
+            click.echo("Ignoring {0}.".format(ignored_pkg), err=True)
+        pkg_name_index = package_names.index(package_map[ignored_pkg])
+        del package_names[pkg_name_index]
+
+    used_packages = project_pkg_names["combined"] & installed_package_names
     failure = False
     packages_to_remove = set()
     if all:
-        package_names = develop | default
         click.echo(
-            crayons.normal(fix_utf8("Un-installing all packages from virtualenv…"), bold=True)
+            crayons.normal(
+                fix_utf8("Un-installing all {0} and {1}…".format(
+                    crayons.red("[dev-packages]"),
+                    crayons.red("[packages]"),
+                )), bold=True
+            )
         )
-        do_purge(allow_global=system)
-        return
+        do_purge(bare=False, allow_global=system)
+        sys.exit(0)
     if all_dev:
-        package_names = develop
+        package_names = project_pkg_names["dev"]
     else:
         package_names = set([pkg_name for pkg_name in package_names])
     selected_pkg_map = {
@@ -2120,7 +2126,7 @@ def do_uninstall(
     }
     packages_to_remove = [
         p for normalized, p in selected_pkg_map.items()
-        if (normalized in used_packages and normalized not in bad_pkgs)
+        if normalized in (used_packages - bad_pkgs)
     ]
     for normalized, package_name in selected_pkg_map.items():
         click.echo(
@@ -2130,15 +2136,16 @@ def do_uninstall(
         )
         # Uninstall the package.
         if package_name in packages_to_remove:
-            cmd = "{0} uninstall {1} -y".format(
-                escape_grouped_arguments(which_pip(allow_global=system)), package_name,
-            )
-            if environments.is_verbose():
-                click.echo("$ {0}".format(cmd))
-            c = delegator.run(cmd)
-            click.echo(crayons.blue(c.out))
-            if c.return_code != 0:
-                failure = True
+            with project.environment.activated():
+                cmd = "{0} uninstall {1} -y".format(
+                    escape_grouped_arguments(which_pip(allow_global=system)), package_name,
+                )
+                if environments.is_verbose():
+                    click.echo("$ {0}".format(cmd))
+                c = delegator.run(cmd)
+                click.echo(crayons.blue(c.out))
+                if c.return_code != 0:
+                    failure = True
         if not failure and pipfile_remove:
             in_packages = project.get_package_name_in_pipfile(package_name, dev=False)
             in_dev_packages = project.get_package_name_in_pipfile(
@@ -2646,9 +2653,9 @@ def do_clean(ctx, three=None, python=None, dry_run=False, bare=False, pypi_mirro
     ensure_lockfile(pypi_mirror=pypi_mirror)
     # Make sure that the virtualenv's site packages are configured correctly
     # otherwise we may end up removing from the global site packages directory
-    fix_venv_site(project.env_paths["lib"])
     installed_package_names = [
-        canonicalize_name(pkg.project_name) for pkg in project.get_installed_packages()
+        canonicalize_name(pkg.project_name) for pkg
+        in project.environment.get_installed_packages()
     ]
     # Remove known "bad packages" from the list.
     for bad_package in BAD_PACKAGES:
diff --git a/pipenv/environment.py b/pipenv/environment.py
new file mode 100644
index 00000000..db0e22aa
--- /dev/null
+++ b/pipenv/environment.py
@@ -0,0 +1,618 @@
+# -*- coding=utf-8 -*-
+
+import contextlib
+import importlib
+import json
+import os
+import sys
+import operator
+import pkg_resources
+import six
+
+from distutils.sysconfig import get_python_lib
+from sysconfig import get_paths
+
+from cached_property import cached_property
+
+import vistir
+import pipenv
+
+BASE_WORKING_SET = pkg_resources.WorkingSet(sys.path)
+
+
+class Environment(object):
+    def __init__(self, prefix=None, is_venv=False, base_working_set=None, pipfile=None, sources=None):
+        super(Environment, self).__init__()
+        self._modules = {'pkg_resources': pkg_resources, 'pipenv': pipenv}
+        self.base_working_set = base_working_set if base_working_set else BASE_WORKING_SET
+        self.is_venv = not os.path.samefile(os.path.abspath(prefix), sys.prefix)
+        if not sources:
+            sources = []
+        self.sources = sources
+        self.extra_dists = []
+        prefix = prefix if prefix else sys.prefix
+        self.prefix = vistir.compat.Path(prefix)
+
+    def safe_import(self, name):
+        """Helper utility for reimporting previously imported modules while inside the env"""
+        module = None
+        if name not in self._modules:
+            self._modules[name] = importlib.import_module(name)
+        module = self._modules[name]
+        if not module:
+            dist = next(iter(
+                dist for dist in self.base_working_set if dist.project_name == name
+            ), None)
+            if dist:
+                dist.activate()
+            module = importlib.import_module(name)
+        if name in sys.modules:
+            try:
+                six.moves.reload_module(module)
+                six.moves.reload_module(sys.modules[name])
+            except TypeError:
+                del sys.modules[name]
+                sys.modules[name] = self._modules[name]
+        return module
+
+    @classmethod
+    def resolve_dist(cls, dist, working_set):
+        """Given a local distribution and a working set, returns all dependencies from the set.
+
+        :param dist: A single distribution to find the dependencies of
+        :type dist: :class:`pkg_resources.Distribution`
+        :param working_set: A working set to search for all packages
+        :type working_set: :class:`pkg_resources.WorkingSet`
+        :return: A set of distributions which the package depends on, including the package
+        :rtype: set(:class:`pkg_resources.Distribution`)
+        """
+
+        deps = set()
+        deps.add(dist)
+        try:
+            reqs = dist.requires()
+        except AttributeError:
+            return deps
+        for req in reqs:
+            dist = working_set.find(req)
+            deps |= cls.resolve_dist(dist, working_set)
+        return deps
+
+    def add_dist(self, dist_name):
+        dist = pkg_resources.get_distribution(pkg_resources.Requirement(dist_name))
+        extras = self.resolve_dist(dist, self.base_working_set)
+        if extras:
+            self.extra_dists.extend(extras)
+
+    @cached_property
+    def python_version(self):
+        with self.activated():
+            from sysconfig import get_python_version
+            py_version = get_python_version()
+            return py_version
+
+    @property
+    def python_info(self):
+        include_dir = self.prefix / "include"
+        python_path = next(iter(list(include_dir.iterdir())), None)
+        if python_path and python_path.name.startswith("python"):
+            python_version = python_path.name.replace("python", "")
+            py_version_short, abiflags = python_version[:3], python_version[3:]
+            return {"py_version_short": py_version_short, "abiflags": abiflags}
+        return {}
+
+    @cached_property
+    def base_paths(self):
+        """
+        Returns the context appropriate paths for the environment.
+
+        :return: A dictionary of environment specific paths to be used for installation operations
+        :rtype: dict
+
+        .. note:: The implementation of this is borrowed from a combination of pip and
+           virtualenv and is likely to change at some point in the future.
+
+        >>> from pipenv.core import project
+        >>> from pipenv.environment import Environment
+        >>> env = Environment(prefix=project.virtualenv_location, is_venv=True, sources=project.sources)
+        >>> import pprint
+        >>> pprint.pprint(env.base_paths)
+        {'PATH': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/bin::/bin:/usr/bin',
+        'PYTHONPATH': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/lib/python3.7/site-packages',
+        'data': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW',
+        'include': '/home/hawk/.pyenv/versions/3.7.1/include/python3.7m',
+        'libdir': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/lib/python3.7/site-packages',
+        'platinclude': '/home/hawk/.pyenv/versions/3.7.1/include/python3.7m',
+        'platlib': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/lib/python3.7/site-packages',
+        'platstdlib': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/lib/python3.7',
+        'prefix': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW',
+        'purelib': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/lib/python3.7/site-packages',
+        'scripts': '/home/hawk/.virtualenvs/pipenv-MfOPs1lW/bin',
+        'stdlib': '/home/hawk/.pyenv/versions/3.7.1/lib/python3.7'}
+        """
+
+        prefix = self.prefix.as_posix()
+        install_scheme = 'nt' if (os.name == 'nt') else 'posix_prefix'
+        paths = get_paths(install_scheme, vars={
+            'base': prefix,
+            'platbase': prefix,
+        })
+        paths["PATH"] = paths["scripts"] + os.pathsep + os.defpath
+        if "prefix" not in paths:
+            paths["prefix"] = prefix
+        purelib = get_python_lib(plat_specific=0, prefix=prefix)
+        platlib = get_python_lib(plat_specific=1, prefix=prefix)
+        if purelib == platlib:
+            lib_dirs = purelib
+        else:
+            lib_dirs = purelib + os.pathsep + platlib
+        paths["libdir"] = purelib
+        paths["purelib"] = purelib
+        paths["platlib"] = platlib
+        paths['PYTHONPATH'] = lib_dirs
+        paths["libdirs"] = lib_dirs
+        return paths
+
+    @cached_property
+    def script_basedir(self):
+        """Path to the environment scripts dir"""
+        script_dir = self.base_paths["scripts"]
+        return script_dir
+
+    @property
+    def python(self):
+        """Path to the environment python"""
+        py = vistir.compat.Path(self.base_paths["scripts"]).joinpath("python").as_posix()
+        if not py:
+            return vistir.compat.Path(sys.executable).as_posix()
+        return py
+
+    @cached_property
+    def sys_path(self):
+        """The system path inside the environment
+
+        :return: The :data:`sys.path` from the environment
+        :rtype: list
+        """
+
+        current_executable = vistir.compat.Path(sys.executable).as_posix()
+        if not self.python or self.python == current_executable:
+            return sys.path
+        elif any([sys.prefix == self.prefix, not self.is_venv]):
+            return sys.path
+        cmd_args = [self.python, "-c", "import json, sys; print(json.dumps(sys.path))"]
+        path, _ = vistir.misc.run(cmd_args, return_object=False, nospin=True, block=True, combine_stderr=False)
+        path = json.loads(path.strip())
+        return path
+
+    @cached_property
+    def system_paths(self):
+        paths = {}
+        paths = get_paths()
+        return paths
+
+    @cached_property
+    def sys_prefix(self):
+        """The prefix run inside the context of the environment
+
+        :return: The python prefix inside the environment
+        :rtype: :data:`sys.prefix`
+        """
+
+        command = [self.python, "-c" "import sys; print(sys.prefix)"]
+        c = vistir.misc.run(command, return_object=True, block=True, nospin=True)
+        sys_prefix = vistir.compat.Path(vistir.misc.to_text(c.out).strip()).as_posix()
+        return sys_prefix
+
+    @cached_property
+    def paths(self):
+        paths = {}
+        with vistir.contextmanagers.temp_environ(), vistir.contextmanagers.temp_path():
+            os.environ["PYTHONIOENCODING"] = vistir.compat.fs_str("utf-8")
+            os.environ["PYTHONDONTWRITEBYTECODE"] = vistir.compat.fs_str("1")
+            paths = self.base_paths
+            os.environ["PATH"] = paths["PATH"]
+            os.environ["PYTHONPATH"] = paths["PYTHONPATH"]
+            if "headers" not in paths:
+                paths["headers"] = paths["include"]
+        return paths
+
+    @property
+    def scripts_dir(self):
+        return self.paths["scripts"]
+
+    @property
+    def libdir(self):
+        purelib = self.paths.get("purelib", None)
+        if purelib and os.path.exists(purelib):
+            return "purelib", purelib
+        return "platlib", self.paths["platlib"]
+
+    def get_distributions(self):
+        """Retrives the distributions installed on the library path of the environment
+
+        :return: A set of distributions found on the library path
+        :rtype: iterator
+        """
+
+        pkg_resources = self.safe_import("pkg_resources")
+        return pkg_resources.find_distributions(self.paths["PYTHONPATH"])
+
+    def find_egg(self, egg_dist):
+        import site
+        site_packages = get_python_lib()
+        search_filename = "{0}.egg-link".format(egg_dist.project_name)
+        try:
+            user_site = site.getusersitepackages()
+        except AttributeError:
+            user_site = site.USER_SITE
+        search_locations = [site_packages, user_site]
+        for site_directory in search_locations:
+            egg = os.path.join(site_directory, search_filename)
+            if os.path.isfile(egg):
+                return egg
+
+    def locate_dist(self, dist):
+        location = self.find_egg(dist)
+        if not location:
+            return dist.location
+
+    def dist_is_in_project(self, dist):
+        from .project import _normalized
+        prefix = _normalized(self.base_paths["prefix"])
+        location = self.locate_dist(dist)
+        if not location:
+            return False
+        return _normalized(location).startswith(prefix)
+
+    def get_installed_packages(self):
+        workingset = self.get_working_set()
+        packages = [pkg for pkg in workingset if self.dist_is_in_project(pkg)]
+        return packages
+
+    def get_finder(self):
+        from .vendor.pip_shims import Command, cmdoptions, index_group, PackageFinder
+        from .environments import PIPENV_CACHE_DIR
+        index_urls = [source.get("url") for source in self.sources]
+
+        class PipCommand(Command):
+            name = "PipCommand"
+
+        pip_command = PipCommand()
+        index_opts = cmdoptions.make_option_group(
+            index_group, pip_command.parser
+        )
+        cmd_opts = pip_command.cmd_opts
+        pip_command.parser.insert_option_group(0, index_opts)
+        pip_command.parser.insert_option_group(0, cmd_opts)
+        pip_args = self._modules["pipenv"].utils.prepare_pip_source_args(self.sources, [])
+        pip_options, _ = pip_command.parser.parse_args(pip_args)
+        pip_options.cache_dir = PIPENV_CACHE_DIR
+        pip_options.pre = self.pipfile.get("pre", False)
+        with pip_command._build_session(pip_options) as session:
+            finder = PackageFinder(
+                find_links=pip_options.find_links,
+                index_urls=index_urls, allow_all_prereleases=pip_options.pre,
+                trusted_hosts=pip_options.trusted_hosts,
+                process_dependency_links=pip_options.process_dependency_links,
+                session=session
+            )
+            yield finder
+
+    def get_package_info(self):
+        dependency_links = []
+        packages = self.get_installed_packages()
+        # This code is borrowed from pip's current implementation
+        for dist in packages:
+            if dist.has_metadata('dependency_links.txt'):
+                dependency_links.extend(dist.get_metadata_lines('dependency_links.txt'))
+
+        with self.get_finder() as finder:
+            finder.add_dependency_links(dependency_links)
+
+            for dist in packages:
+                typ = 'unknown'
+                all_candidates = finder.find_all_candidates(dist.key)
+                if not finder.pip_options.pre:
+                    # Remove prereleases
+                    all_candidates = [
+                        candidate for candidate in all_candidates
+                        if not candidate.version.is_prerelease
+                    ]
+
+                if not all_candidates:
+                    continue
+                best_candidate = max(all_candidates, key=finder._candidate_sort_key)
+                remote_version = best_candidate.version
+                if best_candidate.location.is_wheel:
+                    typ = 'wheel'
+                else:
+                    typ = 'sdist'
+                # This is dirty but makes the rest of the code much cleaner
+                dist.latest_version = remote_version
+                dist.latest_filetype = typ
+                yield dist
+
+    def get_outdated_packages(self):
+        return [
+            pkg for pkg in self.get_package_info()
+            if pkg.latest_version._version > pkg.parsed_version._version
+        ]
+
+    def get_package_requirements(self):
+        from .vendor.pipdeptree import flatten, sorted_tree, build_dist_index, construct_tree
+        dist_index = build_dist_index(self.get_installed_packages())
+        tree = sorted_tree(construct_tree(dist_index))
+        branch_keys = set(r.key for r in flatten(tree.values()))
+        nodes = [p for p in tree.keys() if p.key not in branch_keys]
+        key_tree = dict((k.key, v) for k, v in tree.items())
+        get_children = lambda n: key_tree.get(n.key, [])
+
+        def aux(node, parent=None, chain=None):
+            if chain is None:
+                chain = [node.project_name]
+
+            d = node.as_dict()
+            if parent:
+                d['required_version'] = node.version_spec if node.version_spec else 'Any'
+            else:
+                d['required_version'] = d['installed_version']
+
+            d['dependencies'] = [
+                aux(c, parent=node, chain=chain+[c.project_name])
+                for c in get_children(node)
+                if c.project_name not in chain
+            ]
+
+            return d
+        return [aux(p) for p in nodes]
+
+    def get_working_set(self):
+        """Retrieve the working set of installed packages for the environment.
+
+        :return: The working set for the environment
+        :rtype: :class:`pkg_resources.WorkingSet`
+        """
+
+        working_set = pkg_resources.WorkingSet(self.sys_path)
+        return working_set
+
+    def is_installed(self, pkgname):
+        """Given a package name, returns whether it is installed in the environment
+
+        :param str pkgname: The name of a package
+        :return: Whether the supplied package is installed in the environment
+        :rtype: bool
+        """
+
+        return any(d for d in self.get_distributions() if d.project_name == pkgname)
+
+    def run(self, cmd, cwd=os.curdir):
+        """Run a command with :class:`~subprocess.Popen` in the context of the environment
+
+        :param cmd: A command to run in the environment
+        :type cmd: str or list
+        :param str cwd: The working directory in which to execute the command, defaults to :data:`os.curdir`
+        :return: A finished command object
+        :rtype: :class:`~subprocess.Popen`
+        """
+
+        c = None
+        with self.activated():
+            script = vistir.cmdparse.Script.parse(cmd)
+            c = vistir.misc.run(script._parts, return_object=True, nospin=True, cwd=cwd)
+        return c
+
+    def run_py(self, cmd, cwd=os.curdir):
+        """Run a python command in the enviornment context.
+
+        :param cmd: A command to run in the environment - runs with `python -c`
+        :type cmd: str or list
+        :param str cwd: The working directory in which to execute the command, defaults to :data:`os.curdir`
+        :return: A finished command object
+        :rtype: :class:`~subprocess.Popen`
+        """
+
+        c = None
+        if isinstance(cmd, six.string_types):
+            script = vistir.cmdparse.Script.parse("{0} -c {1}".format(self.python, cmd))
+        else:
+            script = vistir.cmdparse.Script.parse([self.python, "-c"] + list(cmd))
+        with self.activated():
+            c = vistir.misc.run(script._parts, return_object=True, nospin=True, cwd=cwd)
+        return c
+
+    def run_activate_this(self):
+        """Runs the environment's inline activation script"""
+        if self.is_venv:
+            activate_this = os.path.join(self.scripts_dir, "activate_this.py")
+            if not os.path.isfile(activate_this):
+                raise OSError("No such file: {0!s}".format(activate_this))
+            with open(activate_this, "r") as f:
+                code = compile(f.read(), activate_this, "exec")
+                exec(code, dict(__file__=activate_this))
+
+    @contextlib.contextmanager
+    def activated(self, include_extras=True, extra_dists=None):
+        """Helper context manager to activate the environment.
+
+        This context manager will set the following variables for the duration
+        of its activation:
+
+            * sys.prefix
+            * sys.path
+            * os.environ["VIRTUAL_ENV"]
+            * os.environ["PATH"]
+
+        In addition, it will make any distributions passed into `extra_dists` available
+        on `sys.path` while inside the context manager, as well as making `passa` itself
+        available.
+
+        The environment's `prefix` as well as `scripts_dir` properties are both prepended
+        to `os.environ["PATH"]` to ensure that calls to `~Environment.run()` use the
+        environment's path preferentially.
+        """
+
+        if not extra_dists:
+            extra_dists = []
+        original_path = sys.path
+        original_prefix = sys.prefix
+        parent_path = vistir.compat.Path(__file__).absolute().parent
+        vendor_dir = parent_path.joinpath("vendor").as_posix()
+        patched_dir = parent_path.joinpath("patched").as_posix()
+        parent_path = parent_path.as_posix()
+        prefix = self.prefix.as_posix()
+        with vistir.contextmanagers.temp_environ(), vistir.contextmanagers.temp_path():
+            os.environ["PATH"] = os.pathsep.join([
+                vistir.compat.fs_str(self.scripts_dir),
+                vistir.compat.fs_str(self.prefix.as_posix()),
+                os.environ.get("PATH", "")
+            ])
+            os.environ["PYTHONIOENCODING"] = vistir.compat.fs_str("utf-8")
+            os.environ["PYTHONDONTWRITEBYTECODE"] = vistir.compat.fs_str("1")
+            os.environ["PATH"] = self.base_paths["PATH"]
+            os.environ["PYTHONPATH"] = self.base_paths["PYTHONPATH"]
+            if self.is_venv:
+                os.environ["VIRTUAL_ENV"] = vistir.compat.fs_str(prefix)
+            sys.path = self.sys_path
+            sys.prefix = self.sys_prefix
+            site = self.safe_import("site")
+            site.addsitedir(self.base_paths["purelib"])
+            if include_extras:
+                site.addsitedir(parent_path)
+                sys.path.extend([parent_path, patched_dir, vendor_dir])
+                extra_dists = list(self.extra_dists) + extra_dists
+                for extra_dist in extra_dists:
+                    if extra_dist not in self.get_working_set():
+                        extra_dist.activate(self.sys_path)
+            try:
+                yield
+            finally:
+                sys.path = original_path
+                sys.prefix = original_prefix
+                six.moves.reload_module(pkg_resources)
+
+    @cached_property
+    def finders(self):
+        from pipenv.vendor.pythonfinder import Finder
+        finders = [
+            Finder(path=self.base_paths["scripts"], global_search=gs, system=False)
+            for gs in (False, True)
+        ]
+        return finders
+
+    @property
+    def finder(self):
+        return next(iter(self.finders), None)
+
+    def which(self, search, as_path=True):
+        find = operator.methodcaller("which", search)
+        result = next(iter(filter(None, (find(finder) for finder in self.finders))), None)
+        if not result:
+            result = self._which(search)
+        else:
+            if as_path:
+                result = str(result.path)
+        return result
+
+    def get_install_args(self, editable=False, setup_path=None):
+        install_arg = "install" if not editable else "develop"
+        install_keys = ["headers", "purelib", "platlib", "scripts", "data"]
+        install_args = [
+            self.environment.python, "-u", "-c", SETUPTOOLS_SHIM % setup_path,
+            install_arg, "--single-version-externally-managed", "--no-deps",
+            "--prefix={0}".format(self.base_paths["prefix"]), "--no-warn-script-location"
+        ]
+        for key in install_keys:
+            install_args.append(
+                "--install-{0}={1}".format(key, self.base_paths[key])
+            )
+        return install_args
+
+    def install(self, requirements):
+        if not isinstance(requirements, (tuple, list)):
+            requirements = [requirements,]
+        with self.get_finder() as finder:
+            args = []
+            for format_control in ('no_binary', 'only_binary'):
+                formats = getattr(finder.format_control, format_control)
+                args.extend(('--' + format_control.replace('_', '-'),
+                            ','.join(sorted(formats or {':none:'}))))
+            if finder.index_urls:
+                args.extend(['-i', finder.index_urls[0]])
+                for extra_index in finder.index_urls[1:]:
+                    args.extend(['--extra-index-url', extra_index])
+            else:
+                args.append('--no-index')
+            for link in finder.find_links:
+                args.extend(['--find-links', link])
+            for _, host, _ in finder.secure_origins:
+                args.extend(['--trusted-host', host])
+            if finder.allow_all_prereleases:
+                args.append('--pre')
+            if finder.process_dependency_links:
+                args.append('--process-dependency-links')
+            args.append('--')
+            args.extend(requirements)
+            out, _ = vistir.misc.run(args, return_object=False, nospin=True, block=True,
+                                     combine_stderr=False)
+
+    @contextlib.contextmanager
+    def uninstall(self, pkgname, *args, **kwargs):
+        """A context manager which allows uninstallation of packages from the environment
+
+        :param str pkgname: The name of a package to uninstall
+
+        >>> env = Environment("/path/to/env/root")
+        >>> with env.uninstall("pytz", auto_confirm=True, verbose=False) as uninstaller:
+                cleaned = uninstaller.paths
+        >>> if cleaned:
+                print("uninstalled packages: %s" % cleaned)
+        """
+
+        auto_confirm = kwargs.pop("auto_confirm", True)
+        verbose = kwargs.pop("verbose", False)
+        with self.activated():
+            monkey_patch = next(iter(
+                dist for dist in self.base_working_set
+                if dist.project_name == "recursive-monkey-patch"
+            ), None)
+            if monkey_patch:
+                monkey_patch.activate()
+            pip_shims = self.safe_import("pip_shims")
+            pathset_base = pip_shims.UninstallPathSet
+            import recursive_monkey_patch
+            recursive_monkey_patch.monkey_patch(
+                PatchedUninstaller, pathset_base
+            )
+            dist = next(
+                iter(filter(lambda d: d.project_name == pkgname, self.get_working_set())),
+                None
+            )
+            pathset = pathset_base.from_dist(dist)
+            if pathset is not None:
+                pathset.remove(auto_confirm=auto_confirm, verbose=verbose)
+            try:
+                yield pathset
+            except Exception as e:
+                if pathset is not None:
+                    pathset.rollback()
+            else:
+                if pathset is not None:
+                    pathset.commit()
+            if pathset is None:
+                return
+
+
+class PatchedUninstaller(object):
+    def _permitted(self, path):
+        return True
+
+
+SETUPTOOLS_SHIM = (
+    "import setuptools, tokenize;__file__=%r;"
+    "f=getattr(tokenize, 'open', open)(__file__);"
+    "code=f.read().replace('\\r\\n', '\\n');"
+    "f.close();"
+    "exec(compile(code, __file__, 'exec'))"
+)
diff --git a/pipenv/project.py b/pipenv/project.py
index d4713b89..d3b56be6 100644
--- a/pipenv/project.py
+++ b/pipenv/project.py
@@ -19,6 +19,7 @@ import vistir
 import toml
 import tomlkit
 
+from .environment import Environment
 from .cmdparse import Script
 from .utils import (
     pep423_name,
@@ -35,7 +36,7 @@ from .utils import (
     get_workon_home,
     is_virtual_environment,
     looks_like_dir,
-    sys_version
+    get_canonical_names
 )
 from .environments import (
     PIPENV_MAX_DEPTH,
@@ -45,7 +46,6 @@ from .environments import (
     PIPENV_TEST_INDEX,
     PIPENV_PYTHON,
     PIPENV_DEFAULT_PYTHON_VERSION,
-    PIPENV_CACHE_DIR
 )
 
 
@@ -154,6 +154,7 @@ class Project(object):
         self._lockfile_newlines = DEFAULT_NEWLINES
         self._requirements_location = None
         self._original_dir = os.path.abspath(os.curdir)
+        self._environment = None
         self._which = which
         self._build_system = {
             "requires": ["setuptools", "wheel"]
@@ -316,105 +317,48 @@ class Project(object):
         import pkg_resources
         return pkg_resources.WorkingSet(sys_path)
 
-    def find_egg(self, egg_dist):
-        import site
-        from distutils import sysconfig as distutils_sysconfig
-        site_packages = distutils_sysconfig.get_python_lib()
-        search_filename = "{0}.egg-link".format(egg_dist.project_name)
-        try:
-            user_site = site.getusersitepackages()
-        except AttributeError:
-            user_site = site.USER_SITE
-        search_locations = [site_packages, user_site]
-        for site_directory in search_locations:
-            egg = os.path.join(site_directory, search_filename)
-            if os.path.isfile(egg):
-                return egg
-
-    def locate_dist(self, dist):
-        location = self.find_egg(dist)
-        if not location:
-            return dist.location
-
-    def dist_is_in_project(self, dist):
-        prefix = _normalized(self.env_paths["prefix"])
-        location = self.locate_dist(dist)
-        if not location:
-            return False
-        return _normalized(location).startswith(prefix)
-
-    def get_installed_packages(self):
-        workingset = self.working_set
-        if self.virtualenv_exists:
-            packages = [pkg for pkg in workingset if self.dist_is_in_project(pkg)]
-        else:
-            packages = [pkg for pkg in packages]
-        return packages
+    @property
+    def installed_packages(self):
+        return self.environment.get_installed_packages()
 
-    def get_package_info(self):
-        from .utils import prepare_pip_source_args
-        from .vendor.pip_shims import Command, cmdoptions, index_group, PackageFinder
-        index_urls = [source.get("url") for source in self.sources]
+    @property
+    def installed_package_names(self):
+        return get_canonical_names([pkg.key for pkg in self.installed_packages])
 
-        class PipCommand(Command):
-            name = "PipCommand"
+    @property
+    def lockfile_package_names(self):
+        dev_keys = get_canonical_names(self.lockfile_content["develop"].keys())
+        default_keys = get_canonical_names(self.lockfile_content["default"].keys())
+        return {
+            "dev": dev_keys,
+            "default": default_keys,
+            "combined": dev_keys | default_keys
+        }
 
-        dependency_links = []
-        packages = self.get_installed_packages()
-        # This code is borrowed from pip's current implementation
-        for dist in packages:
-            if dist.has_metadata('dependency_links.txt'):
-                dependency_links.extend(dist.get_metadata_lines('dependency_links.txt'))
+    @property
+    def pipfile_package_names(self):
+        dev_keys = get_canonical_names(self.dev_packages.keys())
+        default_keys = get_canonical_names(self.packages.keys())
+        return {
+            "dev": dev_keys,
+            "default": default_keys,
+            "combined": dev_keys | default_keys
+        }
 
-        pip_command = PipCommand()
-        index_opts = cmdoptions.make_option_group(
-            index_group, pip_command.parser
-        )
-        cmd_opts = pip_command.cmd_opts
-        pip_command.parser.insert_option_group(0, index_opts)
-        pip_command.parser.insert_option_group(0, cmd_opts)
-        pip_args = prepare_pip_source_args(self.sources, [])
-        pip_options, _ = pip_command.parser.parse_args(pip_args)
-        pip_options.cache_dir = PIPENV_CACHE_DIR
-        pip_options.pre = self.settings.get("pre", False)
-        with pip_command._build_session(pip_options) as session:
-            finder = PackageFinder(
-                find_links=pip_options.find_links,
-                index_urls=index_urls, allow_all_prereleases=pip_options.pre,
-                trusted_hosts=pip_options.trusted_hosts,
-                process_dependency_links=pip_options.process_dependency_links,
-                session=session
+    @property
+    def environment(self):
+        if not self._environment:
+            prefix = self.get_location_for_virtualenv()
+            is_venv = prefix == sys.prefix
+            sources = self.sources.copy() if self.sources else [DEFAULT_SOURCE,]
+            self._environment = Environment(
+                prefix=prefix, is_venv=is_venv, sources=sources, pipfile=self.parsed_pipfile
             )
-            finder.add_dependency_links(dependency_links)
-
-            for dist in packages:
-                typ = 'unknown'
-                all_candidates = finder.find_all_candidates(dist.key)
-                if not pip_options.pre:
-                    # Remove prereleases
-                    all_candidates = [
-                        candidate for candidate in all_candidates
-                        if not candidate.version.is_prerelease
-                    ]
-
-                if not all_candidates:
-                    continue
-                best_candidate = max(all_candidates, key=finder._candidate_sort_key)
-                remote_version = best_candidate.version
-                if best_candidate.location.is_wheel:
-                    typ = 'wheel'
-                else:
-                    typ = 'sdist'
-                # This is dirty but makes the rest of the code much cleaner
-                dist.latest_version = remote_version
-                dist.latest_filetype = typ
-                yield dist
+            self._environment.add_dist("pipenv")
+        return self._environment
 
     def get_outdated_packages(self):
-        return [
-            pkg for pkg in self.get_package_info()
-            if pkg.latest_version._version > pkg.parsed_version._version
-        ]
+        return self.environment.get_outdated_packages()
 
     @classmethod
     def _sanitize(cls, name):
@@ -588,7 +532,6 @@ class Project(object):
         :return: A new toml hierarchical document
         """
 
-
         def gen_table(inline=False):
             if inline:
                 return tomlkit.inline_table()
@@ -1159,49 +1102,6 @@ class Project(object):
         # Return whether or not values have been changed.
         return changed_values
 
-    @property
-    def py_version(self):
-        py_path = self.which("python")
-        version = python_version(py_path)
-        return version
-
-    @property
-    def _pyversion(self):
-        include_dir = vistir.compat.Path(self.virtualenv_location) / "include"
-        python_path = next((x for x in include_dir.iterdir() if x.name.startswith("python")), None)
-        if python_path:
-            py_version = python_path.name.replace("python", "")
-            py_version_short, abiflags = py_version[:3], py_version[3:]
-            return {"py_version_short": py_version_short, "abiflags": abiflags}
-        return {}
-
-    @property
-    def env_paths(self):
-        location = self.virtualenv_location if self.virtualenv_location else sys.prefix
-        prefix = vistir.compat.Path(location)
-        import importlib
-        py_version = tuple([int(v) for v in self.py_version.split(".")])
-        py_version_short = ".".join([str(v) for v in py_version[:2]])
-        running_version = ".".join([str(v) for v in sys.version_info[:2]])
-        try:
-            _virtualenv = importlib.import_module("virtualenv")
-        except (ImportError, AttributeError):
-            with vistir.contextmanagers.temp_path():
-                sys.path = vistir.misc.load_path(self.which("python"))
-                six.moves.reload_module(importlib)
-                _virtualenv = importlib.import_module("virtualenv")
-        with sys_version(py_version):
-            home, lib, inc, bin_ = _virtualenv.path_locations(prefix.absolute().as_posix())
-        paths = {
-            "lib": lib.replace(running_version, py_version_short),
-            "include": inc.replace(running_version, py_version_short),
-            "scripts": bin_,
-            "purelib": lib.replace(running_version, py_version_short),
-            "prefix": home,
-            "base": home
-        }
-        return paths
-
     @cached_property
     def finders(self):
         from .vendor.pythonfinder import Finder
