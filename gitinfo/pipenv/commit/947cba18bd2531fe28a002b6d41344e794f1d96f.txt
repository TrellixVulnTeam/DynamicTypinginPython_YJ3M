commit 947cba18bd2531fe28a002b6d41344e794f1d96f
Author: Dan Ryan <dan@danryan.co>
Date:   Mon Aug 13 18:30:05 2018 -0400

    Vendor new libraries: vistir and pip_shims
    
    - Vendors new libraries for maintainability
    - Separates responsibiltiies and adds coverage
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/news/2639.vendor b/news/2639.vendor
new file mode 100644
index 00000000..777350aa
--- /dev/null
+++ b/news/2639.vendor
@@ -0,0 +1 @@
+Vendored new libraries ``vistir`` and ``pip-shims``.
diff --git a/pipenv/vendor/pip_shims/__init__.py b/pipenv/vendor/pip_shims/__init__.py
new file mode 100644
index 00000000..5f6ba2c4
--- /dev/null
+++ b/pipenv/vendor/pip_shims/__init__.py
@@ -0,0 +1,75 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import
+
+__version__ = "0.1.0"
+
+__all__ = [
+    "__version__",
+    "_strip_extras",
+    "cmdoptions",
+    "Command",
+    "ConfigOptionParser",
+    "DistributionNotFound",
+    "FAVORITE_HASH",
+    "FormatControl",
+    "get_installed_distributions",
+    "index_group",
+    "InstallRequirement",
+    "is_archive_file",
+    "is_file_url",
+    "is_installable_dir",
+    "Link",
+    "make_abstract_dist",
+    "make_option_group",
+    "PackageFinder",
+    "parse_requirements",
+    "parse_version",
+    "path_to_url",
+    "pip_version",
+    "PipError",
+    "RequirementPreparer",
+    "RequirementSet",
+    "RequirementTracker",
+    "Resolver",
+    "SafeFileCache",
+    "url_to_path",
+    "USER_CACHE_DIR",
+    "VcsSupport",
+    "Wheel",
+    "WheelCache",
+]
+
+from .shims import (
+    _strip_extras,
+    cmdoptions,
+    Command,
+    ConfigOptionParser,
+    DistributionNotFound,
+    FAVORITE_HASH,
+    FormatControl,
+    get_installed_distributions,
+    index_group,
+    InstallRequirement,
+    is_archive_file,
+    is_file_url,
+    is_installable_dir,
+    Link,
+    make_abstract_dist,
+    make_option_group,
+    PackageFinder,
+    parse_requirements,
+    parse_version,
+    path_to_url,
+    pip_version,
+    PipError,
+    RequirementPreparer,
+    RequirementSet,
+    RequirementTracker,
+    Resolver,
+    SafeFileCache,
+    url_to_path,
+    USER_CACHE_DIR,
+    VcsSupport,
+    Wheel,
+    WheelCache,
+)
diff --git a/pipenv/vendor/pip_shims/shims.py b/pipenv/vendor/pip_shims/shims.py
new file mode 100644
index 00000000..159b2223
--- /dev/null
+++ b/pipenv/vendor/pip_shims/shims.py
@@ -0,0 +1,207 @@
+# -*- coding=utf-8 -*-
+from collections import namedtuple
+from contextlib import contextmanager
+from .utils import _parse, get_package, STRING_TYPES
+import importlib
+import os
+from pip import __version__ as pip_version
+import sys
+
+
+has_modutil = False
+if sys.version_info[:2] >= (3, 7):
+    try:
+        import modutil
+    except ImportError:
+        has_modutil = False
+    else:
+        has_modutil = True
+
+
+BASE_IMPORT_PATH = os.environ.get("PIP_SHIMS_BASE_MODULE", "pip")
+path_info = namedtuple("PathInfo", "path start_version end_version")
+parsed_pip_version = _parse(pip_version)
+
+
+def is_valid(path_info_tuple):
+    if (
+        path_info_tuple.start_version >= parsed_pip_version
+        and path_info_tuple.end_version <= parsed_pip_version
+    ):
+        return 1
+    return 0
+
+
+def do_import(module_paths, base_path=BASE_IMPORT_PATH):
+    if not isinstance(module_paths, list):
+        module_paths = [module_paths]
+    prefix_order = [pth.format(base_path) for pth in ["{0}._internal", "{0}"]]
+    if _parse(pip_version) < _parse("10.0.0"):
+        prefix_order = reversed(prefix_order)
+    paths = sorted(module_paths, key=is_valid, reverse=True)
+    search_order = [
+        "{0}.{1}".format(p, pth.path)
+        for p in prefix_order
+        for pth in paths
+        if pth is not None
+    ]
+    imported = None
+    if has_modutil:
+        pkgs = [get_package(pkg) for pkg in search_order]
+        imports = [
+            modutil.lazy_import(__name__, {to_import}) for to_import, pkg in pkgs
+        ]
+        imp_getattrs = [imp_getattr for mod, imp_getattr in imports]
+        chained = modutil.chained___getattr__(__name__, *imp_getattrs)
+        imported = None
+        for to_import, pkg in pkgs:
+            _, _, module_name = to_import.rpartition(".")
+            try:
+                imported = chained(module_name)
+            except (modutil.ModuleAttributeError, ImportError):
+                continue
+            else:
+                if not imported:
+                    continue
+                return getattr(imported, pkg)
+        if not imported:
+            return
+        return imported
+    for to_import in search_order:
+        to_import, package = get_package(to_import)
+        try:
+            imported = importlib.import_module(to_import)
+        except ImportError:
+            continue
+        else:
+            return getattr(imported, package)
+    return imported
+
+
+parse_version = do_import(
+    [path_info("index.parse_version", _parse("7.0.0"), _parse("9999"))]
+)
+_strip_extras = do_import(
+    [path_info("req.req_install._strip_extras", _parse("7.0.0"), _parse("9999"))]
+)
+cmdoptions = do_import(
+    [
+        path_info("cli.cmdoptions", _parse("18.1"), _parse("9999")),
+        path_info("cmdoptions", _parse("7.0.0"), _parse("18.0")),
+    ]
+)
+Command = do_import(
+    [
+        path_info("cli.base_command.Command", _parse("18.1"), _parse("9999")),
+        path_info("basecommand.Command", _parse("7.0.0"), _parse("18.0")),
+    ]
+)
+ConfigOptionParser = do_import(
+    [
+        path_info("cli.parser.ConfigOptionParser", _parse("18.1"), _parse("9999")),
+        path_info("baseparser.ConfigOptionParser", _parse("7.0.0"), _parse("18.0")),
+    ]
+)
+DistributionNotFound = do_import(
+    [path_info("exceptions.DistributionNotFound", _parse("7.0.0"), _parse("9999"))]
+)
+FAVORITE_HASH = do_import(
+    [path_info("utils.hashes.FAVORITE_HASH", _parse("7.0.0"), _parse("9999"))]
+)
+FormatControl = do_import(
+    [path_info("index.FormatControl", _parse("7.0.0"), _parse("9999"))]
+)
+get_installed_distributions = do_import(
+    [
+        path_info(
+            "utils.misc.get_installed_distributions", _parse("10.0.0"), _parse("9999")
+        ),
+        path_info(
+            "utils.get_installed_distributions", _parse("7.0.0"), _parse("9.0.3")
+        ),
+    ]
+)
+index_group = do_import(
+    [
+        path_info("cli.cmdoptions.index_group", _parse("18.1"), _parse("9999")),
+        path_info("cmdoptions.index_group", _parse("7.0.0"), _parse("18.0")),
+    ]
+)
+InstallRequirement = do_import(
+    [path_info("req.req_install.InstallRequirement", _parse("7.0.0"), _parse("9999"))]
+)
+is_archive_file = do_import(
+    [path_info("download.is_archive_file", _parse("7.0.0"), _parse("9999"))]
+)
+is_file_url = do_import(
+    [path_info("download.is_file_url", _parse("7.0.0"), _parse("9999"))]
+)
+is_installable_dir = do_import(
+    [
+        path_info("utils.misc.is_installable_dir", _parse("10.0.0"), _parse("9999")),
+        path_info("utils.is_installable_dir", _parse("7.0.0"), _parse("9.0.3")),
+    ]
+)
+Link = do_import([path_info("index.Link", _parse("7.0.0"), _parse("9999"))])
+make_abstract_dist = do_import(
+    [
+        path_info(
+            "operations.prepare.make_abstract_dist", _parse("10.0.0"), _parse("9999")
+        ),
+        path_info("req.req_set.make_abstract_dist", _parse("7.0.0"), _parse("9.0.3")),
+    ]
+)
+make_option_group = do_import(
+    [
+        path_info("cli.cmdoptions.make_option_group", _parse("18.1"), _parse("9999")),
+        path_info("cmdoptions.make_option_group", _parse("7.0.0"), _parse("18.0")),
+    ]
+)
+PackageFinder = do_import(
+    [path_info("index.PackageFinder", _parse("7.0.0"), _parse("9999"))]
+)
+parse_requirements = do_import(
+    [path_info("req.req_file.parse_requirements", _parse("7.0.0"), _parse("9999"))]
+)
+parse_version = do_import(
+    [path_info("index.parse_version", _parse("7.0.0"), _parse("9999"))]
+)
+path_to_url = do_import(
+    [path_info("download.path_to_url", _parse("7.0.0"), _parse("9999"))]
+)
+PipError = do_import(
+    [path_info("exceptions.PipError", _parse("7.0.0"), _parse("9999"))]
+)
+RequirementPreparer = do_import(
+    [
+        path_info(
+            "operations.prepare.RequirementPreparer", _parse("7.0.0"), _parse("9999")
+        )
+    ]
+)
+RequirementSet = do_import(
+    [path_info("req.req_set.RequirementSet", _parse("7.0.0"), _parse("9999"))]
+)
+RequirementTracker = do_import(
+    [path_info("req.req_tracker.RequirementTracker", _parse("7.0.0"), _parse("9999"))]
+)
+Resolver = do_import([path_info("resolve.Resolver", _parse("7.0.0"), _parse("9999"))])
+SafeFileCache = do_import(
+    [path_info("download.SafeFileCache", _parse("7.0.0"), _parse("9999"))]
+)
+url_to_path = do_import(
+    [path_info("download.url_to_path", _parse("7.0.0"), _parse("9999"))]
+)
+USER_CACHE_DIR = do_import(
+    [path_info("locations.USER_CACHE_DIR", _parse("7.0.0"), _parse("9999"))]
+)
+VcsSupport = do_import([path_info("vcs.VcsSupport", _parse("7.0.0"), _parse("9999"))])
+Wheel = do_import([path_info("wheel.Wheel", _parse("7.0.0"), _parse("9999"))])
+WheelCache = do_import([path_info("cache.WheelCache", _parse("7.0.0"), _parse("9999"))])
+
+
+if not RequirementTracker:
+
+    @contextmanager
+    def RequirementTracker():
+        yield
diff --git a/pipenv/vendor/pip_shims/utils.py b/pipenv/vendor/pip_shims/utils.py
new file mode 100644
index 00000000..a8389bbe
--- /dev/null
+++ b/pipenv/vendor/pip_shims/utils.py
@@ -0,0 +1,35 @@
+# -*- coding=utf-8 -*-
+from functools import wraps
+import sys
+
+STRING_TYPES = (str,)
+if sys.version_info < (3, 0):
+    STRING_TYPES = STRING_TYPES + (unicode,)
+
+
+def memoize(obj):
+    cache = obj.cache = {}
+
+    @wraps(obj)
+    def memoizer(*args, **kwargs):
+        key = str(args) + str(kwargs)
+        if key not in cache:
+            cache[key] = obj(*args, **kwargs)
+        return cache[key]
+    return memoizer
+
+
+@memoize
+def _parse(version):
+    if isinstance(version, STRING_TYPES):
+        return tuple(version.split("."))
+    return version
+
+
+def get_package(module, subimport=None):
+    package = None
+    if subimport:
+        package = subimport
+    else:
+        module, _, package = module.rpartition(".")
+    return module, package
diff --git a/pipenv/vendor/vendor.txt b/pipenv/vendor/vendor.txt
index 47253dd3..dd6df701 100644
--- a/pipenv/vendor/vendor.txt
+++ b/pipenv/vendor/vendor.txt
@@ -40,3 +40,5 @@ semver==2.8.0
 shutilwhich==1.1.0
 toml==0.9.4
 cached-property==1.4.3
+vistir==0.1.0
+pip-shims==0.1.0
diff --git a/pipenv/vendor/vistir/__init__.py b/pipenv/vendor/vistir/__init__.py
new file mode 100644
index 00000000..c7f776d5
--- /dev/null
+++ b/pipenv/vendor/vistir/__init__.py
@@ -0,0 +1,34 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+from .compat import NamedTemporaryFile, TemporaryDirectory, partialmethod
+from .contextmanagers import (
+    atomic_open_for_write,
+    cd,
+    open_file,
+    temp_environ,
+    temp_path,
+)
+from .misc import load_path, partialclass, run, shell_escape
+from .path import mkdir_p, rmtree
+
+
+__version__ = '0.1.0'
+
+
+__all__ = [
+    "shell_escape",
+    "load_path",
+    "run",
+    "partialclass",
+    "temp_environ",
+    "temp_path",
+    "cd",
+    "atomic_open_for_write",
+    "open_file",
+    "rmtree",
+    "mkdir_p",
+    "TemporaryDirectory",
+    "NamedTemporaryFile",
+    "partialmethod",
+]
diff --git a/pipenv/vendor/vistir/backports/__init__.py b/pipenv/vendor/vistir/backports/__init__.py
new file mode 100644
index 00000000..0bdac1ea
--- /dev/null
+++ b/pipenv/vendor/vistir/backports/__init__.py
@@ -0,0 +1,11 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+from .functools import partialmethod
+from .tempfile import NamedTemporaryFile
+
+
+__all__ = [
+    "NamedTemporaryFile",
+    "partialmethod"
+]
diff --git a/pipenv/vendor/vistir/backports/functools.py b/pipenv/vendor/vistir/backports/functools.py
new file mode 100644
index 00000000..8060d183
--- /dev/null
+++ b/pipenv/vendor/vistir/backports/functools.py
@@ -0,0 +1,84 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+from functools import partial
+
+
+__all__ = ["partialmethod",]
+
+
+class partialmethod(object):
+    """Method descriptor with partial application of the given arguments
+    and keywords.
+    Supports wrapping existing descriptors and handles non-descriptor
+    callables as instance methods.
+    """
+
+    def __init__(self, func, *args, **keywords):
+        if not callable(func) and not hasattr(func, "__get__"):
+            raise TypeError("{!r} is not callable or a descriptor"
+                                .format(func))
+
+        # func could be a descriptor like classmethod which isn't callable,
+        # so we can't inherit from partial (it verifies func is callable)
+        if isinstance(func, partialmethod):
+            # flattening is mandatory in order to place cls/self before all
+            # other arguments
+            # it's also more efficient since only one function will be called
+            self.func = func.func
+            self.args = func.args + args
+            self.keywords = func.keywords.copy()
+            self.keywords.update(keywords)
+        else:
+            self.func = func
+            self.args = args
+            self.keywords = keywords
+
+    def __repr__(self):
+        args = ", ".join(map(repr, self.args))
+        keywords = ", ".join("{}={!r}".format(k, v)
+                                for k, v in self.keywords.items())
+        format_string = "{module}.{cls}({func}, {args}, {keywords})"
+        return format_string.format(module=self.__class__.__module__,
+                                    cls=self.__class__.__qualname__,
+                                    func=self.func,
+                                    args=args,
+                                    keywords=keywords)
+
+    def _make_unbound_method(self):
+        def _method(*args, **keywords):
+            call_keywords = self.keywords.copy()
+            call_keywords.update(keywords)
+            if len(args) > 1:
+                cls_or_self, rest = args[0], tuple(args[1:],)
+            else:
+                cls_or_self = args[0]
+                rest = tuple()
+            call_args = (cls_or_self,) + self.args + tuple(rest)
+            return self.func(*call_args, **call_keywords)
+        _method.__isabstractmethod__ = self.__isabstractmethod__
+        _method._partialmethod = self
+        return _method
+
+    def __get__(self, obj, cls):
+        get = getattr(self.func, "__get__", None)
+        result = None
+        if get is not None:
+            new_func = get(obj, cls)
+            if new_func is not self.func:
+                # Assume __get__ returning something new indicates the
+                # creation of an appropriate callable
+                result = partial(new_func, *self.args, **self.keywords)
+                try:
+                    result.__self__ = new_func.__self__
+                except AttributeError:
+                    pass
+        if result is None:
+            # If the underlying descriptor didn't do anything, treat this
+            # like an instance method
+            result = self._make_unbound_method().__get__(obj, cls)
+        return result
+
+    @property
+    def __isabstractmethod__(self):
+        return getattr(self.func, "__isabstractmethod__", False)
diff --git a/pipenv/vendor/vistir/backports/tempfile.py b/pipenv/vendor/vistir/backports/tempfile.py
new file mode 100644
index 00000000..483a479a
--- /dev/null
+++ b/pipenv/vendor/vistir/backports/tempfile.py
@@ -0,0 +1,211 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import functools
+import io
+import os
+import sys
+
+from tempfile import _bin_openflags, _mkstemp_inner, gettempdir
+
+import six
+
+try:
+    from weakref import finalize
+except ImportError:
+    from backports.weakref import finalize
+
+
+__all__ = ["finalize", "NamedTemporaryFile"]
+
+
+try:
+    from tempfile import _infer_return_type
+except ImportError:
+
+    def _infer_return_type(*args):
+        _types = set()
+        for arg in args:
+            if isinstance(type(arg), six.string_types):
+                _types.add(str)
+            elif isinstance(type(arg), bytes):
+                _types.add(bytes)
+            elif arg:
+                _types.add(type(arg))
+        return _types.pop()
+
+
+def _sanitize_params(prefix, suffix, dir):
+    """Common parameter processing for most APIs in this module."""
+    output_type = _infer_return_type(prefix, suffix, dir)
+    if suffix is None:
+        suffix = output_type()
+    if prefix is None:
+        if output_type is str:
+            prefix = "tmp"
+        else:
+            prefix = os.fsencode("tmp")
+    if dir is None:
+        if output_type is str:
+            dir = gettempdir()
+        else:
+            dir = os.fsencode(gettempdir())
+    return prefix, suffix, dir, output_type
+
+
+class _TemporaryFileCloser:
+    """A separate object allowing proper closing of a temporary file's
+    underlying file object, without adding a __del__ method to the
+    temporary file."""
+
+    file = None  # Set here since __del__ checks it
+    close_called = False
+
+    def __init__(self, file, name, delete=True):
+        self.file = file
+        self.name = name
+        self.delete = delete
+
+    # NT provides delete-on-close as a primitive, so we don't need
+    # the wrapper to do anything special.  We still use it so that
+    # file.name is useful (i.e. not "(fdopen)") with NamedTemporaryFile.
+    if os.name != "nt":
+
+        # Cache the unlinker so we don't get spurious errors at
+        # shutdown when the module-level "os" is None'd out.  Note
+        # that this must be referenced as self.unlink, because the
+        # name TemporaryFileWrapper may also get None'd out before
+        # __del__ is called.
+
+        def close(self, unlink=os.unlink):
+            if not self.close_called and self.file is not None:
+                self.close_called = True
+                try:
+                    self.file.close()
+                finally:
+                    if self.delete:
+                        unlink(self.name)
+
+        # Need to ensure the file is deleted on __del__
+
+        def __del__(self):
+            self.close()
+
+    else:
+
+        def close(self):
+            if not self.close_called:
+                self.close_called = True
+                self.file.close()
+
+
+class _TemporaryFileWrapper:
+    """Temporary file wrapper
+    This class provides a wrapper around files opened for
+    temporary use.  In particular, it seeks to automatically
+    remove the file when it is no longer needed.
+    """
+
+    def __init__(self, file, name, delete=True):
+        self.file = file
+        self.name = name
+        self.delete = delete
+        self._closer = _TemporaryFileCloser(file, name, delete)
+
+    def __getattr__(self, name):
+        # Attribute lookups are delegated to the underlying file
+        # and cached for non-numeric results
+        # (i.e. methods are cached, closed and friends are not)
+        file = self.__dict__["file"]
+        a = getattr(file, name)
+        if hasattr(a, "__call__"):
+            func = a
+
+            @functools.wraps(func)
+            def func_wrapper(*args, **kwargs):
+                return func(*args, **kwargs)
+
+            # Avoid closing the file as long as the wrapper is alive,
+            # see issue #18879.
+            func_wrapper._closer = self._closer
+            a = func_wrapper
+        if not isinstance(a, int):
+            setattr(self, name, a)
+        return a
+
+    # The underlying __enter__ method returns the wrong object
+    # (self.file) so override it to return the wrapper
+
+    def __enter__(self):
+        self.file.__enter__()
+        return self
+
+    # Need to trap __exit__ as well to ensure the file gets
+    # deleted when used in a with statement
+
+    def __exit__(self, exc, value, tb):
+        result = self.file.__exit__(exc, value, tb)
+        self.close()
+        return result
+
+    def close(self):
+        """
+        Close the temporary file, possibly deleting it.
+        """
+        self._closer.close()
+
+    # iter() doesn't use __getattr__ to find the __iter__ method
+
+    def __iter__(self):
+        # Don't return iter(self.file), but yield from it to avoid closing
+        # file as long as it's being used as iterator (see issue #23700).  We
+        # can't use 'yield from' here because iter(file) returns the file
+        # object itself, which has a close method, and thus the file would get
+        # closed when the generator is finalized, due to PEP380 semantics.
+        for line in self.file:
+            yield line
+
+
+def NamedTemporaryFile(
+    mode="w+b",
+    buffering=-1,
+    encoding=None,
+    newline=None,
+    suffix=None,
+    prefix=None,
+    dir=None,
+    delete=True,
+):
+    """Create and return a temporary file.
+    Arguments:
+    'prefix', 'suffix', 'dir' -- as for mkstemp.
+    'mode' -- the mode argument to io.open (default "w+b").
+    'buffering' -- the buffer size argument to io.open (default -1).
+    'encoding' -- the encoding argument to io.open (default None)
+    'newline' -- the newline argument to io.open (default None)
+    'delete' -- whether the file is deleted on close (default True).
+    The file is created as mkstemp() would do it.
+    Returns an object with a file-like interface; the name of the file
+    is accessible as its 'name' attribute.  The file will be automatically
+    deleted when it is closed unless the 'delete' argument is set to False.
+    """
+    prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)
+    flags = _bin_openflags
+    # Setting O_TEMPORARY in the flags causes the OS to delete
+    # the file when it is closed.  This is only supported by Windows.
+    if os.name == "nt" and delete:
+        flags |= os.O_TEMPORARY
+    if sys.version_info < (3, 5):
+        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags)
+    else:
+        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
+    try:
+        file = io.open(
+            fd, mode, buffering=buffering, newline=newline, encoding=encoding
+        )
+        return _TemporaryFileWrapper(file, name, delete)
+
+    except BaseException:
+        os.unlink(name)
+        os.close(fd)
+        raise
diff --git a/pipenv/vendor/vistir/cmdparse.py b/pipenv/vendor/vistir/cmdparse.py
new file mode 100644
index 00000000..07326c93
--- /dev/null
+++ b/pipenv/vendor/vistir/cmdparse.py
@@ -0,0 +1,78 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import re
+import shlex
+
+import six
+
+
+__all__ = ["ScriptEmptyError", "Script"]
+
+
+class ScriptEmptyError(ValueError):
+    pass
+
+
+class Script(object):
+    """Parse a script line (in Pipfile's [scripts] section).
+
+    This always works in POSIX mode, even on Windows.
+    """
+
+    def __init__(self, command, args=None):
+        self._parts = [command]
+        if args:
+            self._parts.extend(args)
+
+    @classmethod
+    def parse(cls, value):
+        if isinstance(value, six.string_types):
+            value = shlex.split(value)
+        if not value:
+            raise ScriptEmptyError(value)
+        return cls(value[0], value[1:])
+
+    def __repr__(self):
+        return "Script({0!r})".format(self._parts)
+
+    @property
+    def command(self):
+        return self._parts[0]
+
+    @property
+    def args(self):
+        return self._parts[1:]
+
+    def extend(self, extra_args):
+        self._parts.extend(extra_args)
+
+    def cmdify(self):
+        """Encode into a cmd-executable string.
+
+        This re-implements CreateProcess's quoting logic to turn a list of
+        arguments into one single string for the shell to interpret.
+
+        * All double quotes are escaped with a backslash.
+        * Existing backslashes before a quote are doubled, so they are all
+          escaped properly.
+        * Backslashes elsewhere are left as-is; cmd will interpret them
+          literally.
+
+        The result is then quoted into a pair of double quotes to be grouped.
+
+        An argument is intentionally not quoted if it does not contain
+        whitespaces. This is done to be compatible with Windows built-in
+        commands that don't work well with quotes, e.g. everything with `echo`,
+        and DOS-style (forward slash) switches.
+
+        The intended use of this function is to pre-process an argument list
+        before passing it into ``subprocess.Popen(..., shell=True)``.
+
+        See also: https://docs.python.org/3/library/subprocess.html#converting-argument-sequence
+        """
+        return " ".join(
+            arg if not next(re.finditer(r'\s', arg), None)
+            else '"{0}"'.format(re.sub(r'(\\*)"', r'\1\1\\"', arg))
+            for arg in self._parts
+        )
diff --git a/pipenv/vendor/vistir/compat.py b/pipenv/vendor/vistir/compat.py
new file mode 100644
index 00000000..454cc3c8
--- /dev/null
+++ b/pipenv/vendor/vistir/compat.py
@@ -0,0 +1,136 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import os
+import sys
+
+import six
+import warnings
+from tempfile import mkdtemp
+
+
+__all__ = [
+    "Path",
+    "get_terminal_size",
+    "finalize",
+    "partialmethod",
+    "JSONDecodeError",
+    "ResourceWarning",
+    "FileNotFoundError",
+    "fs_str",
+    "TemporaryDirectory",
+    "NamedTemporaryFile",
+]
+
+if sys.version_info >= (3, 5):
+    from pathlib import Path
+
+else:
+    from pathlib2 import Path
+
+if sys.version_info < (3, 3):
+    from backports.shutil_get_terminal_size import get_terminal_size
+    from .backports.tempfile import NamedTemporaryFile
+else:
+    from tempfile import NamedTemporaryFile
+    from shutil import get_terminal_size
+
+try:
+    from weakref import finalize
+except ImportError:
+    from backports.weakref import finalize
+
+try:
+    from functools import partialmethod
+except Exception:
+    from .backports.functools import partialmethod
+
+try:
+    from json import JSONDecodeError
+except ImportError:  # Old Pythons.
+    JSONDecodeError = ValueError
+
+if six.PY2:
+
+    class ResourceWarning(Warning):
+        pass
+
+    class FileNotFoundError(IOError):
+        pass
+
+else:
+    from builtins import ResourceWarning, FileNotFoundError
+
+    class ResourceWarning(ResourceWarning):
+        pass
+
+    class FileNotFoundError(FileNotFoundError):
+        pass
+
+
+class TemporaryDirectory(object):
+    """Create and return a temporary directory.  This has the same
+    behavior as mkdtemp but can be used as a context manager.  For
+    example:
+
+        with TemporaryDirectory() as tmpdir:
+            ...
+
+    Upon exiting the context, the directory and everything contained
+    in it are removed.
+    """
+
+    def __init__(self, suffix="", prefix=None, dir=None):
+        if "RAM_DISK" in os.environ:
+            import uuid
+
+            name = uuid.uuid4().hex
+            dir_name = os.path.join(os.environ["RAM_DISK"].strip(), name)
+            os.mkdir(dir_name)
+            self.name = dir_name
+        else:
+            suffix = suffix if suffix else ""
+            if not prefix:
+                self.name = mkdtemp(suffix=suffix, dir=dir)
+            else:
+                self.name = mkdtemp(suffix, prefix, dir)
+        self._finalizer = finalize(
+            self,
+            self._cleanup,
+            self.name,
+            warn_message="Implicitly cleaning up {!r}".format(self),
+        )
+
+    @classmethod
+    def _cleanup(cls, name, warn_message):
+        from .path import rmtree
+        rmtree(name)
+        warnings.warn(warn_message, ResourceWarning)
+
+    def __repr__(self):
+        return "<{} {!r}>".format(self.__class__.__name__, self.name)
+
+    def __enter__(self):
+        return self
+
+    def __exit__(self, exc, value, tb):
+        self.cleanup()
+
+    def cleanup(self):
+        from .path import rmtree
+        if self._finalizer.detach():
+            rmtree(self.name)
+
+
+def fs_str(string):
+    """Encodes a string into the proper filesystem encoding
+
+    Borrowed from pip-tools
+    """
+    if isinstance(string, str):
+        return string
+    assert not isinstance(string, bytes)
+    return string.encode(_fs_encoding)
+
+
+_fs_encoding = sys.getfilesystemencoding() or sys.getdefaultencoding()
diff --git a/pipenv/vendor/vistir/contextmanagers.py b/pipenv/vendor/vistir/contextmanagers.py
new file mode 100644
index 00000000..80f1f897
--- /dev/null
+++ b/pipenv/vendor/vistir/contextmanagers.py
@@ -0,0 +1,208 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import os
+import stat
+import sys
+
+from contextlib import contextmanager
+
+import six
+
+from .compat import NamedTemporaryFile, Path
+from .path import is_file_url, is_valid_url, path_to_url, url_to_path
+
+
+__all__ = ["temp_environ", "temp_path", "cd", "atomic_open_for_write", "open_file"]
+
+
+# Borrowed from Pew.
+# See https://github.com/berdario/pew/blob/master/pew/_utils.py#L82
+@contextmanager
+def temp_environ():
+    """Allow the ability to set os.environ temporarily"""
+    environ = dict(os.environ)
+    try:
+        yield
+    finally:
+        os.environ.clear()
+        os.environ.update(environ)
+
+
+@contextmanager
+def temp_path():
+    """A context manager which allows the ability to set sys.path temporarily
+
+    >>> path_from_virtualenv = load_path("/path/to/venv/bin/python")
+    >>> print(sys.path)
+    ['/home/user/.pyenv/versions/3.7.0/bin', '/home/user/.pyenv/versions/3.7.0/lib/python37.zip', '/home/user/.pyenv/versions/3.7.0/lib/python3.7', '/home/user/.pyenv/versions/3.7.0/lib/python3.7/lib-dynload', '/home/user/.pyenv/versions/3.7.0/lib/python3.7/site-packages']
+    >>> with temp_path():
+            sys.path = path_from_virtualenv
+            # Running in the context of the path above
+            run(["pip", "install", "stuff"])
+    >>> print(sys.path)
+    ['/home/user/.pyenv/versions/3.7.0/bin', '/home/user/.pyenv/versions/3.7.0/lib/python37.zip', '/home/user/.pyenv/versions/3.7.0/lib/python3.7', '/home/user/.pyenv/versions/3.7.0/lib/python3.7/lib-dynload', '/home/user/.pyenv/versions/3.7.0/lib/python3.7/site-packages']
+
+    """
+    path = [p for p in sys.path]
+    try:
+        yield
+    finally:
+        sys.path = [p for p in path]
+
+
+@contextmanager
+def cd(path):
+    """Context manager to temporarily change working directories
+
+    :param str path: The directory to move into
+
+    >>> print(os.path.abspath(os.curdir))
+    '/home/user/code/myrepo'
+    >>> with cd("/home/user/code/otherdir/subdir"):
+            print("Changed directory: %s" % os.path.abspath(os.curdir))
+    Changed directory: /home/user/code/otherdir/subdir
+    >>> print(os.path.abspath(os.curdir))
+    '/home/user/code/myrepo'
+    """
+    if not path:
+        return
+    prev_cwd = Path.cwd().as_posix()
+    if isinstance(path, Path):
+        path = path.as_posix()
+    os.chdir(str(path))
+    try:
+        yield
+    finally:
+        os.chdir(prev_cwd)
+
+
+@contextmanager
+def atomic_open_for_write(target, binary=False, newline=None, encoding=None):
+    """Atomically open `target` for writing.
+
+    This is based on Lektor's `atomic_open()` utility, but simplified a lot
+    to handle only writing, and skip many multi-process/thread edge cases
+    handled by Werkzeug.
+
+    :param str target: Target filename to write
+    :param bool binary: Whether to open in binary mode, default False
+    :param str newline: The newline character to use when writing, determined from system if not supplied
+    :param str encoding: The encoding to use when writing, defaults to system encoding
+
+    How this works:
+
+    * Create a temp file (in the same directory of the actual target), and
+      yield for surrounding code to write to it.
+    * If some thing goes wrong, try to remove the temp file. The actual target
+      is not touched whatsoever.
+    * If everything goes well, close the temp file, and replace the actual
+      target with this new file.
+
+    .. code:: python
+
+        >>> fn = "test_file.txt"
+        >>> def read_test_file(filename=fn):
+                with open(filename, 'r') as fh:
+                    print(fh.read().strip())
+
+        >>> with open(fn, "w") as fh:
+                fh.write("this is some test text")
+        >>> read_test_file()
+        this is some test text
+
+        >>> def raise_exception_while_writing(filename):
+                with open(filename, "w") as fh:
+                    fh.write("writing some new text")
+                    raise RuntimeError("Uh oh, hope your file didn't get overwritten")
+
+        >>> raise_exception_while_writing(fn)
+        Traceback (most recent call last):
+            ...
+        RuntimeError: Uh oh, hope your file didn't get overwritten
+        >>> read_test_file()
+        writing some new text
+
+        # Now try with vistir
+        >>> def raise_exception_while_writing(filename):
+                with vistir.contextmanagers.atomic_open_for_write(filename) as fh:
+                    fh.write("Overwriting all the text from before with even newer text")
+                    raise RuntimeError("But did it get overwritten now?")
+
+        >>> raise_exception_while_writing(fn)
+            Traceback (most recent call last):
+                ...
+            RuntimeError: But did it get overwritten now?
+
+        >>> read_test_file()
+            writing some new text
+    """
+
+    mode = "w+b" if binary else "w"
+    f = NamedTemporaryFile(
+        dir=os.path.dirname(target),
+        prefix=".__atomic-write",
+        mode=mode,
+        encoding=encoding,
+        newline=newline,
+        delete=False,
+    )
+    # set permissions to 0644
+    os.chmod(f.name, stat.S_IWUSR | stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)
+    try:
+        yield f
+    except BaseException:
+        f.close()
+        try:
+            os.remove(f.name)
+        except OSError:
+            pass
+        raise
+    else:
+        f.close()
+        try:
+            os.remove(target)  # This is needed on Windows.
+        except OSError:
+            pass
+        os.rename(f.name, target)  # No os.replace() on Python 2.
+
+
+@contextmanager
+def open_file(link, session=None):
+    """
+    Open local or remote file for reading.
+
+    :type link: pip._internal.index.Link or str
+    :type session: requests.Session
+    :raises ValueError: If link points to a local directory.
+    :return: a context manager to the opened file-like object
+    """
+    if not isinstance(link, six.string_types):
+        try:
+            link = link.url_without_fragment
+        except AttributeError:
+            raise ValueError("Cannot parse url from unkown type: {0!r}".format(link))
+
+    if not is_valid_url(link) and os.path.exists(link):
+        link = path_to_url(link)
+
+    if is_file_url(link):
+        # Local URL
+        local_path = url_to_path(link)
+        if os.path.isdir(local_path):
+            raise ValueError("Cannot open directory for read: {}".format(link))
+        else:
+            with open(local_path, "rb") as local_file:
+                yield local_file
+    else:
+        # Remote URL
+        headers = {"Accept-Encoding": "identity"}
+        if not session:
+            from requests import Session
+
+            session = Session()
+        response = session.get(link, headers=headers, stream=True)
+        try:
+            yield response.raw
+        finally:
+            response.close()
diff --git a/pipenv/vendor/vistir/misc.py b/pipenv/vendor/vistir/misc.py
new file mode 100644
index 00000000..5d7855aa
--- /dev/null
+++ b/pipenv/vendor/vistir/misc.py
@@ -0,0 +1,134 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import json
+import locale
+import os
+import subprocess
+import sys
+
+from collections import OrderedDict
+
+from .cmdparse import Script
+from .compat import Path, partialmethod
+
+
+__all__ = [
+    "shell_escape", "unnest", "dedup", "run", "load_path", "partialclass"
+]
+
+
+def shell_escape(cmd):
+    """Escape strings for use in :func:`~subprocess.Popen` and :func:`run`.
+
+    This is a passthrough method for instantiating a :class:`~vistir.cmdparse.Script`
+    object which can be used to escape commands to output as a single string.
+    """
+    cmd = Script.parse(cmd)
+    return cmd.cmdify()
+
+
+def unnest(elem):
+    """Flatten an arbitrarily nested iterable
+
+    :param elem: An iterable to flatten
+    :type elem: :class:`~collections.Iterable`
+
+    >>> nested_iterable = (1234, (3456, 4398345, (234234)), (2396, (23895750, 9283798, 29384, (289375983275, 293759, 2347, (2098, 7987, 27599)))))
+    >>> list(vistir.misc.unnest(nested_iterable))
+    [1234, 3456, 4398345, 234234, 2396, 23895750, 9283798, 29384, 289375983275, 293759, 2347, 2098, 7987, 27599]
+    """
+
+    if _is_iterable(elem):
+        for item in elem:
+            if _is_iterable(item):
+                for sub_item in unnest(item):
+                    yield sub_item
+            else:
+                yield item
+    else:
+        raise ValueError("Expecting an iterable, got %r" % elem)
+
+
+def _is_iterable(elem):
+    if getattr(elem, "__iter__", False):
+        return True
+    return False
+
+
+def dedup(iterable):
+    """Deduplicate an iterable object like iter(set(iterable)) but
+    order-reserved.
+    """
+    return iter(OrderedDict.fromkeys(iterable))
+
+
+def run(cmd):
+    """Use `subprocess.Popen` to get the output of a command and decode it.
+
+    :param list cmd: A list representing the command you want to run.
+    :returns: A 2-tuple of (output, error)
+    """
+    encoding = locale.getdefaultlocale()[1] or "utf-8"
+    c = subprocess.Popen(
+        cmd, env=os.environ.copy(), stdout=subprocess.PIPE, stderr=subprocess.PIPE
+    )
+    out, err = c.communicate()
+    return out.decode(encoding).strip(), err.decode(encoding).strip()
+
+
+def load_path(python):
+    """Load the :mod:`sys.path` from the given python executable's environment as json
+
+    :param str python: Path to a valid python executable
+    :return: A python representation of the `sys.path` value of the given python executable.
+    :rtype: list
+
+    >>> load_path("/home/user/.virtualenvs/requirementslib-5MhGuG3C/bin/python")
+    ['', '/home/user/.virtualenvs/requirementslib-5MhGuG3C/lib/python37.zip', '/home/user/.virtualenvs/requirementslib-5MhGuG3C/lib/python3.7', '/home/user/.virtualenvs/requirementslib-5MhGuG3C/lib/python3.7/lib-dynload', '/home/user/.pyenv/versions/3.7.0/lib/python3.7', '/home/user/.virtualenvs/requirementslib-5MhGuG3C/lib/python3.7/site-packages', '/home/user/git/requirementslib/src']
+    """
+
+    python = Path(python).as_posix()
+    out, err = run([python, "-c", "import json, sys; print(json.dumps(sys.path))"])
+    if out:
+        return json.loads(out)
+    else:
+        return []
+
+
+def partialclass(cls, *args, **kwargs):
+    """Returns a partially instantiated class
+
+    :return: A partial class instance
+    :rtype: cls
+
+    >>> source = partialclass(Source, url="https://pypi.org/simple")
+    >>> source
+    <class '__main__.Source'>
+    >>> source(name="pypi")
+    >>> source.__dict__
+    mappingproxy({'__module__': '__main__', '__dict__': <attribute '__dict__' of 'Source' objects>, '__weakref__': <attribute '__weakref__' of 'Source' objects>, '__doc__': None, '__init__': functools.partialmethod(<function Source.__init__ at 0x7f23af429bf8>, , url='https://pypi.org/simple')})
+    >>> new_source = source(name="pypi")
+    >>> new_source
+    <__main__.Source object at 0x7f23af189b38>
+    >>> new_source.__dict__
+    {'url': 'https://pypi.org/simple', 'verify_ssl': True, 'name': 'pypi'}
+    """
+
+    name_attrs = [n for n in (getattr(cls, name, str(cls)) for name in ("__name__", "__qualname__")) if n is not None]
+    name_attrs = name_attrs[0]
+    type_ = type(
+        name_attrs,
+        (cls,),
+        {
+            "__init__": partialmethod(cls.__init__, *args, **kwargs),
+        }
+    )
+    # Swiped from attrs.make_class
+    try:
+        type_.__module__ = sys._getframe(1).f_globals.get(
+            "__name__", "__main__",
+        )
+    except (AttributeError, ValueError):
+        pass
+    return type_
diff --git a/pipenv/vendor/vistir/path.py b/pipenv/vendor/vistir/path.py
new file mode 100644
index 00000000..85790244
--- /dev/null
+++ b/pipenv/vendor/vistir/path.py
@@ -0,0 +1,333 @@
+# -*- coding=utf-8 -*-
+from __future__ import absolute_import, unicode_literals
+
+import errno
+import os
+import posixpath
+import shutil
+import stat
+import warnings
+
+import six
+
+from six.moves.urllib import request as urllib_request
+from six.moves import urllib_parse
+
+from .compat import Path, _fs_encoding
+
+
+__all__ = [
+    "check_for_unc_path",
+    "get_converted_relative_path",
+    "handle_remove_readonly",
+    "is_file_url",
+    "is_readonly_path",
+    "is_valid_url",
+    "mkdir_p",
+    "path_to_url",
+    "rmtree",
+    "safe_expandvars",
+    "set_write_bit",
+    "url_to_path",
+    "walk_up",
+]
+
+
+def _decode_path(path):
+    if not isinstance(path, six.text_type):
+        try:
+            return path.decode(_fs_encoding, 'ignore')
+        except (UnicodeError, LookupError):
+            return path.decode('utf-8', 'ignore')
+    return path
+
+
+def _encode_path(path):
+    """Transform the provided path to a text encoding."""
+    if not isinstance(path, six.string_types + (six.binary_type,)):
+        try:
+            path = getattr(path, "__fspath__")
+        except AttributeError:
+            try:
+                path = getattr(path, "as_posix")
+            except AttributeError:
+                raise RuntimeError("Failed encoding path, unknown object type: %r" % path)
+            else:
+                path()
+        else:
+            path = path()
+    path = Path(_decode_path(path))
+    return _decode_path(path.as_posix())
+
+
+def normalize_drive(path):
+    """Normalize drive in path so they stay consistent.
+
+    This currently only affects local drives on Windows, which can be
+    identified with either upper or lower cased drive names. The case is
+    always converted to uppercase because it seems to be preferred.
+    """
+    if os.name != "nt" or not isinstance(path, six.string_types):
+        return path
+
+    drive, tail = os.path.splitdrive(path)
+    # Only match (lower cased) local drives (e.g. 'c:'), not UNC mounts.
+    if drive.islower() and len(drive) == 2 and drive[1] == ":":
+        return "{}{}".format(drive.upper(), tail)
+
+    return path
+
+
+def path_to_url(path):
+    """Convert the supplied local path to a file uri.
+
+    :param str path: A string pointing to or representing a local path
+    :return: A `file://` uri for the same location
+    :rtype: str
+
+    >>> path_to_url("/home/user/code/myrepo/myfile.zip")
+    'file:///home/user/code/myrepo/myfile.zip'
+    """
+
+    if not path:
+        return path
+    path = _encode_path(path)
+    return Path(normalize_drive(os.path.abspath(path))).as_uri()
+
+
+def url_to_path(url):
+    """Convert a valid file url to a local filesystem path
+
+    Follows logic taken from pip's equivalent function
+    """
+    assert is_file_url(url), "Only file: urls can be converted to local paths"
+    _, netloc, path, _, _ = urllib_parse.urlsplit(url)
+    # Netlocs are UNC paths
+    if netloc:
+        netloc = "\\\\" + netloc
+
+    path = urllib_request.url2pathname(netloc + path)
+    return path
+
+
+def is_valid_url(url):
+    """Checks if a given string is an url"""
+    if not url:
+        return url
+    pieces = urllib_parse.urlparse(url)
+    return all([pieces.scheme, pieces.netloc])
+
+
+def is_file_url(url):
+    """Returns true if the given url is a file url"""
+    if not url:
+        return False
+    if not isinstance(url, six.string_types):
+        try:
+            url = getattr(url, "url")
+        except AttributeError:
+            raise ValueError("Cannot parse url from unknown type: {0!r}".format(url))
+    return urllib_parse.urlparse(url.lower()).scheme == "file"
+
+
+def is_readonly_path(fn):
+    """Check if a provided path exists and is readonly.
+
+    Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`
+    """
+    fn = _encode_path(fn)
+    if os.path.exists(fn):
+        return bool(os.stat(fn).st_mode & stat.S_IREAD) and not os.access(fn, os.W_OK)
+    return False
+
+
+def mkdir_p(newdir):
+    """Recursively creates the target directory and all of its parents if they do not
+    already exist.  Fails silently if they do.
+
+    :param str newdir: The directory path to ensure
+    :raises: OSError if a file is encountered along the way
+    """
+    # http://code.activestate.com/recipes/82465-a-friendly-mkdir/
+    if os.path.exists(newdir):
+        if not os.path.isdir(newdir):
+            raise OSError(
+                "a file with the same name as the desired dir, '{0}', already exists.".format(
+                    newdir
+                )
+            )
+        pass
+    else:
+        head, tail = os.path.split(newdir)
+        if head and not os.path.isdir(head):
+            mkdir_p(head)
+        if tail and not os.path.isdir(newdir):
+            os.mkdir(newdir)
+
+
+def set_write_bit(fn):
+    """Set read-write permissions for the current user on the target path.  Fail silently
+    if the path doesn't exist.
+
+    :param str fn: The target filename or path
+    """
+
+    fn = _encode_path(fn)
+    if isinstance(fn, six.string_types) and not os.path.exists(fn):
+        return
+    os.chmod(fn, stat.S_IWRITE | stat.S_IWUSR | stat.S_IRUSR)
+
+
+def rmtree(directory, ignore_errors=False):
+    """Stand-in for :func:`~shutil.rmtree` with additional error-handling.
+
+    This version of `rmtree` handles read-only paths, especially in the case of index
+    files written by certain source control systems.
+
+    :param str directory: The target directory to remove
+    :param bool ignore_errors: Whether to ignore errors, defaults to False
+
+    .. note::
+
+       Setting `ignore_errors=True` may cause this to silently fail to delete the path
+    """
+
+    directory = _encode_path(directory)
+    shutil.rmtree(
+        directory, ignore_errors=ignore_errors, onerror=handle_remove_readonly
+    )
+
+
+def handle_remove_readonly(func, path, exc):
+    """Error handler for shutil.rmtree.
+
+    Windows source repo folders are read-only by default, so this error handler
+    attempts to set them as writeable and then proceed with deletion.
+
+    :param function func: The caller function
+    :param str path: The target path for removal
+    :param Exception exc: The raised exception
+
+    This function will call check :func:`is_readonly_path` before attempting to call
+    :func:`set_write_bit` on the target path and try again.
+    """
+    # Check for read-only attribute
+    from .compat import ResourceWarning
+    default_warning_message = (
+        "Unable to remove file due to permissions restriction: {!r}"
+    )
+    # split the initial exception out into its type, exception, and traceback
+    exc_type, exc_exception, exc_tb = exc
+    if is_readonly_path(path):
+        # Apply write permission and call original function
+        set_write_bit(path)
+        try:
+            func(path)
+        except (OSError, IOError) as e:
+            if e.errno in [errno.EACCES, errno.EPERM]:
+                warnings.warn(default_warning_message.format(path), ResourceWarning)
+                return
+
+    if exc_exception.errno in [errno.EACCES, errno.EPERM]:
+        warnings.warn(default_warning_message.format(path), ResourceWarning)
+        return
+
+    raise
+
+
+def walk_up(bottom):
+    """Mimic os.walk, but walk 'up' instead of down the directory tree.
+    From: https://gist.github.com/zdavkeos/1098474
+    """
+    bottom = os.path.realpath(bottom)
+    # Get files in current dir.
+    try:
+        names = os.listdir(bottom)
+    except Exception:
+        return
+
+    dirs, nondirs = [], []
+    for name in names:
+        if os.path.isdir(os.path.join(bottom, name)):
+            dirs.append(name)
+        else:
+            nondirs.append(name)
+    yield bottom, dirs, nondirs
+
+    new_path = os.path.realpath(os.path.join(bottom, ".."))
+    # See if we are at the top.
+    if new_path == bottom:
+        return
+
+    for x in walk_up(new_path):
+        yield x
+
+
+def check_for_unc_path(path):
+    """ Checks to see if a pathlib `Path` object is a unc path or not"""
+    if (
+        os.name == "nt"
+        and len(path.drive) > 2
+        and not path.drive[0].isalpha()
+        and path.drive[1] != ":"
+    ):
+        return True
+    else:
+        return False
+
+
+def get_converted_relative_path(path, relative_to=os.curdir):
+    """Convert `path` to be relative.
+
+    Given a vague relative path, return the path relative to the given
+    location.
+
+    :param str path: The location of a target path
+    :param str relative_to: The starting path to build against, optional
+    :returns: A relative posix-style path with a leading `./`
+
+    This performs additional conversion to ensure the result is of POSIX form,
+    and starts with `./`, or is precisely `.`.
+
+    >>> os.chdir('/home/user/code/myrepo/myfolder')
+    >>> vistir.path.get_converted_relative_path('/home/user/code/file.zip')
+    './../../file.zip'
+    >>> vistir.path.get_converted_relative_path('/home/user/code/myrepo/myfolder/mysubfolder')
+    './mysubfolder'
+    >>> vistir.path.get_converted_relative_path('/home/user/code/myrepo/myfolder')
+    '.'
+    """
+
+    path = _encode_path(path)
+    relative_to = _encode_path(relative_to)
+    start_path = Path(relative_to)
+    try:
+        start = start_path.resolve()
+    except OSError:
+        start = start_path.absolute()
+
+    # check if there is a drive letter or mount point
+    # if it is a mountpoint use the original absolute path
+    # instead of the unc path
+    if check_for_unc_path(start):
+        start = start_path.absolute()
+
+    path = start.joinpath(path).relative_to(start)
+
+    # check and see if the path that was passed into the function is a UNC path
+    # and raise value error if it is not.
+    if check_for_unc_path(path):
+        raise ValueError("The path argument does not currently accept UNC paths")
+
+    relpath_s = _encode_path(posixpath.normpath(path.as_posix()))
+    if not (relpath_s == "." or relpath_s.startswith("./")):
+        relpath_s = posixpath.join(".", relpath_s)
+    return relpath_s
+
+
+def safe_expandvars(value):
+    """Call os.path.expandvars if value is a string, otherwise do nothing.
+    """
+    if isinstance(value, six.string_types):
+        return os.path.expandvars(value)
+    return value
