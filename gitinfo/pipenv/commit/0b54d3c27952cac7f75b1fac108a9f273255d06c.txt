commit 0b54d3c27952cac7f75b1fac108a9f273255d06c
Author: Dan Ryan <dan@danryan.co>
Date:   Sat Aug 25 14:12:16 2018 -0400

    Vendor plette
    
    Signed-off-by: Dan Ryan <dan@danryan.co>

diff --git a/pipenv/vendor/plette/LICENSE b/pipenv/vendor/plette/LICENSE
new file mode 100644
index 00000000..b9077766
--- /dev/null
+++ b/pipenv/vendor/plette/LICENSE
@@ -0,0 +1,13 @@
+Copyright (c) 2018, Tzu-ping Chung <uranusjr@gmail.com>
+
+Permission to use, copy, modify, and distribute this software for any
+purpose with or without fee is hereby granted, provided that the above
+copyright notice and this permission notice appear in all copies.
+
+THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
+WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
+ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
+WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
+ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
+OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
diff --git a/pipenv/vendor/plette/__init__.py b/pipenv/vendor/plette/__init__.py
new file mode 100644
index 00000000..c99c1bc1
--- /dev/null
+++ b/pipenv/vendor/plette/__init__.py
@@ -0,0 +1,9 @@
+__all__ = [
+    "__version__",
+    "Lockfile", "Pipfile",
+]
+
+__version__ = '0.1.1'
+
+from .lockfiles import Lockfile
+from .pipfiles import Pipfile
diff --git a/pipenv/vendor/plette/lockfiles.py b/pipenv/vendor/plette/lockfiles.py
new file mode 100644
index 00000000..fe97a521
--- /dev/null
+++ b/pipenv/vendor/plette/lockfiles.py
@@ -0,0 +1,151 @@
+from __future__ import unicode_literals
+
+import json
+
+import six
+
+from .models import DataView, Meta, PackageCollection
+
+
+class _LockFileEncoder(json.JSONEncoder):
+    """A specilized JSON encoder to convert loaded data into a lock file.
+
+    This adds a few characteristics to the encoder:
+
+    * The JSON is always prettified with indents and spaces.
+    * The output is always UTF-8-encoded text, never binary, even on Python 2.
+    """
+    def __init__(self):
+        super(_LockFileEncoder, self).__init__(
+            indent=4, separators=(",", ": "), sort_keys=True,
+        )
+
+    def encode(self, obj):
+        content = super(_LockFileEncoder, self).encode(obj)
+        if not isinstance(content, six.text_type):
+            content = content.decode("utf-8")
+        content += "\n"
+        return content
+
+    def iterencode(self, obj):
+        for chunk in super(_LockFileEncoder, self).iterencode(obj):
+            if not isinstance(chunk, six.text_type):
+                chunk = chunk.decode("utf-8")
+            yield chunk
+        yield "\n"
+
+
+LOCKFILE_SECTIONS = {
+    "_meta": Meta,
+    "default": PackageCollection,
+    "develop": PackageCollection,
+}
+
+PIPFILE_SPEC_CURRENT = 6
+
+
+class Lockfile(DataView):
+    """Representation of a Pipfile.lock.
+    """
+    __SCHEMA__ = {
+        "_meta": {"type": "dict", "required": True},
+        "default": {"type": "dict", "required": True},
+        "develop": {"type": "dict", "required": True},
+    }
+
+    @classmethod
+    def validate(cls, data):
+        super(Lockfile, cls).validate(data)
+        for key, klass in LOCKFILE_SECTIONS.items():
+            klass.validate(data[key])
+
+    @classmethod
+    def load(cls, f, encoding=None):
+        if encoding is None:
+            data = json.load(f)
+        else:
+            data = json.loads(f.read().decode(encoding))
+        return cls(data)
+
+    @classmethod
+    def with_meta_from(cls, pipfile):
+        data = {
+            "_meta": {
+                "hash": pipfile.get_hash()._data,
+                "pipfile-spec": PIPFILE_SPEC_CURRENT,
+                "requires": pipfile._data.get("requires", {}).copy(),
+                "sources": pipfile.sources._data.copy(),
+            },
+            "default": {},
+            "develop": {},
+        }
+        return cls(data)
+
+    def __getitem__(self, key):
+        value = self._data[key]
+        try:
+            return LOCKFILE_SECTIONS[key](value)
+        except KeyError:
+            return value
+
+    def __setitem__(self, key, value):
+        if isinstance(value, DataView):
+            self._data[key] = value._data
+        else:
+            self._data[key] = value
+
+    def is_up_to_date(self, pipfile):
+        return self.meta.hash == pipfile.get_hash()
+
+    def dump(self, f, encoding=None):
+        encoder = _LockFileEncoder()
+        if encoding is None:
+            for chunk in encoder.iterencode(self._data):
+                f.write(chunk)
+        else:
+            content = encoder.encode(self._data)
+            f.write(content.encode(encoding))
+
+    @property
+    def meta(self):
+        try:
+            return self["_meta"]
+        except KeyError:
+            raise AttributeError("meta")
+
+    @meta.setter
+    def meta(self, value):
+        self["_meta"] = value
+
+    @property
+    def _meta(self):
+        try:
+            return self["_meta"]
+        except KeyError:
+            raise AttributeError("meta")
+
+    @_meta.setter
+    def _meta(self, value):
+        self["_meta"] = value
+
+    @property
+    def default(self):
+        try:
+            return self["default"]
+        except KeyError:
+            raise AttributeError("default")
+
+    @default.setter
+    def default(self, value):
+        self["default"] = value
+
+    @property
+    def develop(self):
+        try:
+            return self["develop"]
+        except KeyError:
+            raise AttributeError("develop")
+
+    @develop.setter
+    def develop(self, value):
+        self["develop"] = value
diff --git a/pipenv/vendor/plette/models/__init__.py b/pipenv/vendor/plette/models/__init__.py
new file mode 100644
index 00000000..42b8c49f
--- /dev/null
+++ b/pipenv/vendor/plette/models/__init__.py
@@ -0,0 +1,20 @@
+__all__ = [
+    "DataView", "DataViewCollection", "DataViewMapping", "DataViewSequence",
+    "validate", "ValidationError",
+    "Hash", "Package", "Requires", "Source", "Script",
+    "Meta", "PackageCollection", "ScriptCollection", "SourceCollection",
+]
+
+from .base import (
+    DataView, DataViewCollection, DataViewMapping, DataViewSequence,
+    validate, ValidationError,
+)
+
+from .hashes import Hash
+from .packages import Package
+from .scripts import Script
+from .sources import Source
+
+from .sections import (
+    Meta, Requires, PackageCollection, ScriptCollection, SourceCollection,
+)
diff --git a/pipenv/vendor/plette/models/base.py b/pipenv/vendor/plette/models/base.py
new file mode 100644
index 00000000..e8bbd4fa
--- /dev/null
+++ b/pipenv/vendor/plette/models/base.py
@@ -0,0 +1,132 @@
+try:
+    import cerberus
+except ImportError:
+    cerberus = None
+
+
+class ValidationError(ValueError):
+    def __init__(self, value, validator):
+        super(ValidationError, self).__init__(value)
+        self.validator = validator
+
+
+VALIDATORS = {}
+
+
+def validate(cls, data):
+    if not cerberus:    # Skip validation if Cerberus is not available.
+        return
+    schema = cls.__SCHEMA__
+    key = id(schema)
+    try:
+        v = VALIDATORS[key]
+    except KeyError:
+        v = VALIDATORS[key] = cerberus.Validator(schema, allow_unknown=True)
+    if v.validate(data, normalize=False):
+        return
+    raise ValidationError(data, v)
+
+
+class DataView(object):
+    """A "view" to a data.
+
+    Validates the input mapping on creation. A subclass is expected to
+    provide a `__SCHEMA__` class attribute specifying a validator schema,
+    or a concrete Cerberus validator object.
+    """
+    def __init__(self, data):
+        self.validate(data)
+        self._data = data
+
+    def __repr__(self):
+        return "{0}({1!r})".format(type(self).__name__, self._data)
+
+    def __eq__(self, other):
+        if not isinstance(other, type(self)):
+            raise TypeError("cannot compare {0!r} with {1!r}".format(
+                type(self).__name__, type(other).__name__,
+            ))
+        return self._data == other._data
+
+    def __getitem__(self, key):
+        return self._data[key]
+
+    def __setitem__(self, key, value):
+        self._data[key] = value
+
+    def get(self, key, default=None):
+        try:
+            return self[key]
+        except KeyError:
+            return default
+
+    @classmethod
+    def validate(cls, data):
+        return validate(cls, data)
+
+
+class DataViewCollection(DataView):
+    """A collection of dataview.
+
+    Subclasses are expected to assign a class attribute `item_class` to specify
+    how items should be coerced when accessed. The item class should conform to
+    the `DataView` protocol.
+
+    You should not instantiate an instance from this class, but from one of its
+    subclasses instead.
+    """
+    item_class = None
+
+    def __repr__(self):
+        return "{0}({1!r})".format(type(self).__name__, self._data)
+
+    def __len__(self):
+        return len(self._data)
+
+    def __getitem__(self, key):
+        return self.item_class(self._data[key])
+
+    def __setitem__(self, key, value):
+        if isinstance(value, self.item_class):
+            value = value._data
+        self._data[key] = value
+
+    def __delitem__(self, key):
+        del self._data[key]
+
+
+class DataViewMapping(DataViewCollection):
+    """A mapping of dataview.
+
+    The keys are primitive values, while values are instances of `item_class`.
+    """
+    @classmethod
+    def validate(cls, data):
+        for d in data.values():
+            cls.item_class.validate(d)
+
+    def __iter__(self):
+        return iter(self._data)
+
+    def keys(self):
+        return self._data.keys()
+
+    def values(self):
+        return [self[k] for k in self._data]
+
+    def items(self):
+        return [(k, self[k]) for k in self._data]
+
+
+class DataViewSequence(DataViewCollection):
+    """A sequence of dataview.
+
+    Each entry is an instance of `item_class`.
+    """
+    @classmethod
+    def validate(cls, data):
+        for d in data:
+            cls.item_class.validate(d)
+
+    def __iter__(self):
+        return (self.item_class(d) for d in self._data)
diff --git a/pipenv/vendor/plette/models/hashes.py b/pipenv/vendor/plette/models/hashes.py
new file mode 100644
index 00000000..d35d312e
--- /dev/null
+++ b/pipenv/vendor/plette/models/hashes.py
@@ -0,0 +1,51 @@
+from .base import DataView
+
+
+class Hash(DataView):
+    """A hash.
+    """
+    __SCHEMA__ = {
+        "__hash__": {
+            "type": "list", "minlength": 1, "maxlength": 1,
+            "schema": {
+                "type": "list", "minlength": 2, "maxlength": 2,
+                "schema": {"type": "string"},
+            },
+        },
+    }
+
+    @classmethod
+    def validate(cls, data):
+        super(Hash, cls).validate({"__hash__": list(data.items())})
+
+    @classmethod
+    def from_hash(cls, ins):
+        """Interpolation to the hash result of `hashlib`.
+        """
+        return cls({ins.name: ins.hexdigest()})
+
+    @classmethod
+    def from_line(cls, value):
+        try:
+            name, value = value.split(":", 1)
+        except ValueError:
+            name = "sha256"
+        return cls({name: value})
+
+    def __eq__(self, other):
+        if not isinstance(other, Hash):
+            raise TypeError("cannot compare Hash with {0!r}".format(
+                type(other).__name__,
+            ))
+        return self._data == other._data
+
+    @property
+    def name(self):
+        return next(iter(self._data.keys()))
+
+    @property
+    def value(self):
+        return next(iter(self._data.values()))
+
+    def as_line(self):
+        return "{0[0]}:{0[1]}".format(next(iter(self._data.items())))
diff --git a/pipenv/vendor/plette/models/packages.py b/pipenv/vendor/plette/models/packages.py
new file mode 100644
index 00000000..5bb36215
--- /dev/null
+++ b/pipenv/vendor/plette/models/packages.py
@@ -0,0 +1,45 @@
+import six
+
+from .base import DataView
+
+
+class Package(DataView):
+    """A package requirement specified in a Pipfile.
+
+    This is the base class of variants appearing in either `[packages]` or
+    `[dev-packages]` sections of a Pipfile.
+    """
+    # The extra layer is intentional. Cerberus does not allow top-level keys
+    # to have oneof_schema (at least I can't do it), so we wrap this in a
+    # top-level key. The Requirement model class implements extra hacks to
+    # make this work.
+    __SCHEMA__ = {
+        "__package__": {
+            "oneof_type": ["string", "dict"],
+        },
+    }
+
+    @classmethod
+    def validate(cls, data):
+        # HACK: Make this validatable for Cerberus. See comments in validation
+        # side for more information.
+        return super(Package, cls).validate({"__package__": data})
+
+    def __getattr__(self, key):
+        if isinstance(self._data, six.string_types):
+            if key == "version":
+                return self._data
+            raise AttributeError(key)
+        try:
+            return self._data[key]
+        except KeyError:
+            pass
+        raise AttributeError(key)
+
+    def __setattr__(self, key, value):
+        if key == "_data":
+            super(Package, self).__setattr__(key, value)
+        elif key == "version" and isinstance(self._data, six.string_types):
+            self._data = value
+        else:
+            self._data[key] = value
diff --git a/pipenv/vendor/plette/models/scripts.py b/pipenv/vendor/plette/models/scripts.py
new file mode 100644
index 00000000..7f34d816
--- /dev/null
+++ b/pipenv/vendor/plette/models/scripts.py
@@ -0,0 +1,79 @@
+import re
+import shlex
+
+import six
+
+from .base import DataView
+
+
+class Script(DataView):
+    """Parse a script line (in Pipfile's [scripts] section).
+
+    This always works in POSIX mode, even on Windows.
+    """
+    # This extra layer is intentional. Cerberus does not allow validation of
+    # non-mapping inputs, so we wrap this in a top-level key. The Script model
+    # class implements extra hacks to make this work.
+    __SCHEMA__ = {
+        "__script__": {
+            "oneof_type": ["string", "list"], "required": True, "empty": False,
+            "schema": {"type": "string"},
+        },
+    }
+
+    def __init__(self, data):
+        super(Script, self).__init__(data)
+        if isinstance(data, six.string_types):
+            data = shlex.split(data)
+        self._parts = [data[0]]
+        self._parts.extend(data[1:])
+
+    @classmethod
+    def validate(cls, data):
+        # HACK: Make this validatable for Cerberus. See comments in validation
+        # side for more information.
+        return super(Script, cls).validate({"__script__": data})
+
+    def __repr__(self):
+        return "Script({0!r})".format(self._parts)
+
+    @property
+    def command(self):
+        return self._parts[0]
+
+    @property
+    def args(self):
+        return self._parts[1:]
+
+    def cmdify(self, extra_args=None):
+        """Encode into a cmd-executable string.
+
+        This re-implements CreateProcess's quoting logic to turn a list of
+        arguments into one single string for the shell to interpret.
+
+        * All double quotes are escaped with a backslash.
+        * Existing backslashes before a quote are doubled, so they are all
+          escaped properly.
+        * Backslashes elsewhere are left as-is; cmd will interpret them
+          literally.
+
+        The result is then quoted into a pair of double quotes to be grouped.
+
+        An argument is intentionally not quoted if it does not contain
+        whitespaces. This is done to be compatible with Windows built-in
+        commands that don't work well with quotes, e.g. everything with `echo`,
+        and DOS-style (forward slash) switches.
+
+        The intended use of this function is to pre-process an argument list
+        before passing it into ``subprocess.Popen(..., shell=True)``.
+
+        See also: https://docs.python.org/3/library/subprocess.html
+        """
+        parts = list(self._parts)
+        if extra_args:
+            parts.extend(extra_args)
+        return " ".join(
+            arg if not next(re.finditer(r'\s', arg), None)
+            else '"{0}"'.format(re.sub(r'(\\*)"', r'\1\1\\"', arg))
+            for arg in parts
+        )
diff --git a/pipenv/vendor/plette/models/sections.py b/pipenv/vendor/plette/models/sections.py
new file mode 100644
index 00000000..893ab549
--- /dev/null
+++ b/pipenv/vendor/plette/models/sections.py
@@ -0,0 +1,123 @@
+from .base import DataView, DataViewMapping, DataViewSequence
+from .hashes import Hash
+from .packages import Package
+from .scripts import Script
+from .sources import Source
+
+
+class PackageCollection(DataViewMapping):
+    item_class = Package
+
+
+class ScriptCollection(DataViewMapping):
+    item_class = Script
+
+
+class SourceCollection(DataViewSequence):
+    item_class = Source
+
+
+class Requires(DataView):
+    """Representation of the `[requires]` section in a Pipfile.
+    """
+    __SCHEMA__ = {
+        "python_version": {
+            "type": "string",
+            "excludes": ["python_full_version"],
+        },
+        "python_full_version": {
+            "type": "string",
+            "excludes": ["python_version"],
+        },
+    }
+
+    @property
+    def python_version(self):
+        try:
+            return self._data["python_version"]
+        except KeyError:
+            raise AttributeError("python_version")
+
+    @property
+    def python_full_version(self):
+        try:
+            return self._data["python_full_version"]
+        except KeyError:
+            raise AttributeError("python_full_version")
+
+
+META_SECTIONS = {
+    "hash": Hash,
+    "requires": Requires,
+    "sources": SourceCollection,
+}
+
+
+class Meta(DataView):
+    """Representation of the `_meta` section in a Pipfile.lock.
+    """
+    __SCHEMA__ = {
+        "hash": {"type": "dict", "required": True},
+        "pipfile-spec": {"type": "integer", "required": True, "min": 0},
+        "requires": {"type": "dict", "required": True},
+        "sources": {"type": "list", "required": True},
+    }
+
+    @classmethod
+    def validate(cls, data):
+        super(Meta, cls).validate(data)
+        for key, klass in META_SECTIONS.items():
+            klass.validate(data[key])
+
+    def __getitem__(self, key):
+        value = super(Meta, self).__getitem__(key)
+        try:
+            return META_SECTIONS[key](value)
+        except KeyError:
+            return value
+
+    def __setitem__(self, key, value):
+        if isinstance(value, DataView):
+            self._data[key] = value._data
+        else:
+            self._data[key] = value
+
+    @property
+    def hash_(self):
+        return self["hash"]
+
+    @hash_.setter
+    def hash_(self, value):
+        self["hash"] = value
+
+    @property
+    def hash(self):
+        return self["hash"]
+
+    @hash.setter
+    def hash(self, value):
+        self["hash"] = value
+
+    @property
+    def pipfile_spec(self):
+        return self["pipfile-spec"]
+
+    @pipfile_spec.setter
+    def pipfile_spec(self, value):
+        self["pipfile-spec"] = value
+
+    @property
+    def requires(self):
+        return self["requires"]
+
+    @requires.setter
+    def requires(self, value):
+        self["requires"] = value
+
+    @property
+    def sources(self):
+        return self["sources"]
+
+    @sources.setter
+    def sources(self, value):
+        self["sources"] = value
diff --git a/pipenv/vendor/plette/models/sources.py b/pipenv/vendor/plette/models/sources.py
new file mode 100644
index 00000000..dc2529a0
--- /dev/null
+++ b/pipenv/vendor/plette/models/sources.py
@@ -0,0 +1,45 @@
+import os
+
+from .base import DataView
+
+
+class Source(DataView):
+    """Information on a "simple" Python package index.
+
+    This could be PyPI, or a self-hosted index server, etc. The server
+    specified by the `url` attribute is expected to provide the "simple"
+    package API.
+    """
+    __SCHEMA__ = {
+        "name": {"type": "string", "required": True},
+        "url": {"type": "string", "required": True},
+        "verify_ssl": {"type": "boolean", "required": True},
+    }
+
+    @property
+    def name(self):
+        return self._data["name"]
+
+    @name.setter
+    def name(self, value):
+        self._data["name"] = value
+
+    @property
+    def url(self):
+        return self._data["url"]
+
+    @url.setter
+    def url(self, value):
+        self._data["url"] = value
+
+    @property
+    def verify_ssl(self):
+        return self._data["verify_ssl"]
+
+    @verify_ssl.setter
+    def verify_ssl(self, value):
+        self._data["verify_ssl"] = value
+
+    @property
+    def url_expanded(self):
+        return os.path.expandvars(self._data["url"])
diff --git a/pipenv/vendor/plette/pipfiles.py b/pipenv/vendor/plette/pipfiles.py
new file mode 100644
index 00000000..95f413de
--- /dev/null
+++ b/pipenv/vendor/plette/pipfiles.py
@@ -0,0 +1,161 @@
+from __future__ import unicode_literals
+
+import hashlib
+import json
+
+import six
+import tomlkit
+
+from .models import (
+    DataView, Hash, Requires,
+    PackageCollection, ScriptCollection, SourceCollection,
+)
+
+
+PIPFILE_SECTIONS = {
+    "source": SourceCollection,
+    "packages": PackageCollection,
+    "dev-packages": PackageCollection,
+    "requires": Requires,
+    "scripts": ScriptCollection,
+}
+
+DEFAULT_SOURCE_TOML = """\
+[[source]]
+name = "pypi"
+url = "https://pypi.org/simple"
+verify_ssl = true
+"""
+
+
+class Pipfile(DataView):
+    """Representation of a Pipfile.
+    """
+    __SCHEMA__ = {}
+
+    @classmethod
+    def validate(cls, data):
+        # HACK: DO NOT CALL `super().validate()` here!!
+        # Cerberus seems to break TOML Kit's inline table preservation if it
+        # is not at the top-level. Fortunately the spec doesn't have nested
+        # non-inlined tables, so we're OK as long as validation is only
+        # performed at section-level. validation is performed.
+        for key, klass in PIPFILE_SECTIONS.items():
+            if key not in data:
+                continue
+            klass.validate(data[key])
+
+    @classmethod
+    def load(cls, f, encoding=None):
+        content = f.read()
+        if encoding is not None:
+            content = content.decode(encoding)
+        data = tomlkit.loads(content)
+        if "source" not in data:
+            # HACK: There is no good way to prepend a section to an existing
+            # TOML document, but there's no good way to copy non-structural
+            # content from one TOML document to another either. Modify the
+            # TOML content directly, and load the new in-memory document.
+            sep = "" if content.startswith("\n") else "\n"
+            content = DEFAULT_SOURCE_TOML + sep + content
+        data = tomlkit.loads(content)
+        return cls(data)
+
+    def __getitem__(self, key):
+        value = self._data[key]
+        try:
+            return PIPFILE_SECTIONS[key](value)
+        except KeyError:
+            return value
+
+    def __setitem__(self, key, value):
+        if isinstance(value, DataView):
+            self._data[key] = value._data
+        else:
+            self._data[key] = value
+
+    def get_hash(self):
+        data = {
+            "_meta": {
+                "sources": self._data["source"],
+                "requires": self._data.get("requires", {}),
+            },
+            "default": self._data.get("packages", {}),
+            "develop": self._data.get("dev-packages", {}),
+        }
+        content = json.dumps(data, sort_keys=True, separators=(",", ":"))
+        if isinstance(content, six.text_type):
+            content = content.encode("utf-8")
+        return Hash.from_hash(hashlib.sha256(content))
+
+    def dump(self, f, encoding=None):
+        content = tomlkit.dumps(self._data)
+        if encoding is not None:
+            content = content.encode(encoding)
+        f.write(content)
+
+    @property
+    def sources(self):
+        try:
+            return self["source"]
+        except KeyError:
+            raise AttributeError("sources")
+
+    @sources.setter
+    def sources(self, value):
+        self["source"] = value
+
+    @property
+    def source(self):
+        try:
+            return self["source"]
+        except KeyError:
+            raise AttributeError("source")
+
+    @source.setter
+    def source(self, value):
+        self["source"] = value
+
+    @property
+    def packages(self):
+        try:
+            return self["packages"]
+        except KeyError:
+            raise AttributeError("packages")
+
+    @packages.setter
+    def packages(self, value):
+        self["packages"] = value
+
+    @property
+    def dev_packages(self):
+        try:
+            return self["dev-packages"]
+        except KeyError:
+            raise AttributeError("dev-packages")
+
+    @dev_packages.setter
+    def dev_packages(self, value):
+        self["dev-packages"] = value
+
+    @property
+    def requires(self):
+        try:
+            return self["requires"]
+        except KeyError:
+            raise AttributeError("requires")
+
+    @requires.setter
+    def requires(self, value):
+        self["requires"] = value
+
+    @property
+    def scripts(self):
+        try:
+            return self["scripts"]
+        except KeyError:
+            raise AttributeError("scripts")
+
+    @scripts.setter
+    def scripts(self, value):
+        self["scripts"] = value
