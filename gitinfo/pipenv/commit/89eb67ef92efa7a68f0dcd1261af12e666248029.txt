commit 89eb67ef92efa7a68f0dcd1261af12e666248029
Author: Dan Ryan <dan.ryan@canonical.com>
Date:   Mon Apr 27 16:58:11 2020 -0400

    Rerun vendoring and remove extra files
    
    Signed-off-by: Dan Ryan <dan.ryan@canonical.com>

diff --git a/pipenv/patched/notpip/_internal/collector.py b/pipenv/patched/notpip/_internal/collector.py
deleted file mode 100644
index 1469cb7c..00000000
--- a/pipenv/patched/notpip/_internal/collector.py
+++ /dev/null
@@ -1,548 +0,0 @@
-"""
-The main purpose of this module is to expose LinkCollector.collect_links().
-"""
-
-# The following comment should be removed at some point in the future.
-# mypy: disallow-untyped-defs=False
-
-import cgi
-import itertools
-import logging
-import mimetypes
-import os
-from collections import OrderedDict
-
-from pipenv.patched.notpip._vendor import html5lib, requests
-from pipenv.patched.notpip._vendor.distlib.compat import unescape
-from pipenv.patched.notpip._vendor.requests.exceptions import HTTPError, RetryError, SSLError
-from pipenv.patched.notpip._vendor.six.moves.urllib import parse as urllib_parse
-from pipenv.patched.notpip._vendor.six.moves.urllib import request as urllib_request
-
-from pipenv.patched.notpip._internal.models.link import Link
-from pipenv.patched.notpip._internal.utils.filetypes import ARCHIVE_EXTENSIONS
-from pipenv.patched.notpip._internal.utils.misc import redact_auth_from_url
-from pipenv.patched.notpip._internal.utils.typing import MYPY_CHECK_RUNNING
-from pipenv.patched.notpip._internal.utils.urls import path_to_url, url_to_path
-from pipenv.patched.notpip._internal.vcs import is_url, vcs
-
-if MYPY_CHECK_RUNNING:
-    from typing import (
-        Callable, Dict, Iterable, List, MutableMapping, Optional, Sequence,
-        Tuple, Union,
-    )
-    import xml.etree.ElementTree
-
-    from pipenv.patched.notpip._vendor.requests import Response
-
-    from pipenv.patched.notpip._internal.models.search_scope import SearchScope
-    from pipenv.patched.notpip._internal.network.session import PipSession
-
-    HTMLElement = xml.etree.ElementTree.Element
-    ResponseHeaders = MutableMapping[str, str]
-
-
-logger = logging.getLogger(__name__)
-
-
-def _match_vcs_scheme(url):
-    # type: (str) -> Optional[str]
-    """Look for VCS schemes in the URL.
-
-    Returns the matched VCS scheme, or None if there's no match.
-    """
-    for scheme in vcs.schemes:
-        if url.lower().startswith(scheme) and url[len(scheme)] in '+:':
-            return scheme
-    return None
-
-
-def _is_url_like_archive(url):
-    # type: (str) -> bool
-    """Return whether the URL looks like an archive.
-    """
-    filename = Link(url).filename
-    for bad_ext in ARCHIVE_EXTENSIONS:
-        if filename.endswith(bad_ext):
-            return True
-    return False
-
-
-class _NotHTML(Exception):
-    def __init__(self, content_type, request_desc):
-        # type: (str, str) -> None
-        super(_NotHTML, self).__init__(content_type, request_desc)
-        self.content_type = content_type
-        self.request_desc = request_desc
-
-
-def _ensure_html_header(response):
-    # type: (Response) -> None
-    """Check the Content-Type header to ensure the response contains HTML.
-
-    Raises `_NotHTML` if the content type is not text/html.
-    """
-    content_type = response.headers.get("Content-Type", "")
-    if not content_type.lower().startswith("text/html"):
-        raise _NotHTML(content_type, response.request.method)
-
-
-class _NotHTTP(Exception):
-    pass
-
-
-def _ensure_html_response(url, session):
-    # type: (str, PipSession) -> None
-    """Send a HEAD request to the URL, and ensure the response contains HTML.
-
-    Raises `_NotHTTP` if the URL is not available for a HEAD request, or
-    `_NotHTML` if the content type is not text/html.
-    """
-    scheme, netloc, path, query, fragment = urllib_parse.urlsplit(url)
-    if scheme not in {'http', 'https'}:
-        raise _NotHTTP()
-
-    resp = session.head(url, allow_redirects=True)
-    resp.raise_for_status()
-
-    _ensure_html_header(resp)
-
-
-def _get_html_response(url, session):
-    # type: (str, PipSession) -> Response
-    """Access an HTML page with GET, and return the response.
-
-    This consists of three parts:
-
-    1. If the URL looks suspiciously like an archive, send a HEAD first to
-       check the Content-Type is HTML, to avoid downloading a large file.
-       Raise `_NotHTTP` if the content type cannot be determined, or
-       `_NotHTML` if it is not HTML.
-    2. Actually perform the request. Raise HTTP exceptions on network failures.
-    3. Check the Content-Type header to make sure we got HTML, and raise
-       `_NotHTML` otherwise.
-    """
-    if _is_url_like_archive(url):
-        _ensure_html_response(url, session=session)
-
-    logger.debug('Getting page %s', redact_auth_from_url(url))
-
-    resp = session.get(
-        url,
-        headers={
-            "Accept": "text/html",
-            # We don't want to blindly returned cached data for
-            # /simple/, because authors generally expecting that
-            # twine upload && pip install will function, but if
-            # they've done a pip install in the last ~10 minutes
-            # it won't. Thus by setting this to zero we will not
-            # blindly use any cached data, however the benefit of
-            # using max-age=0 instead of no-cache, is that we will
-            # still support conditional requests, so we will still
-            # minimize traffic sent in cases where the page hasn't
-            # changed at all, we will just always incur the round
-            # trip for the conditional GET now instead of only
-            # once per 10 minutes.
-            # For more information, please see pypa/pip#5670.
-            "Cache-Control": "max-age=0",
-        },
-    )
-    resp.raise_for_status()
-
-    # The check for archives above only works if the url ends with
-    # something that looks like an archive. However that is not a
-    # requirement of an url. Unless we issue a HEAD request on every
-    # url we cannot know ahead of time for sure if something is HTML
-    # or not. However we can check after we've downloaded it.
-    _ensure_html_header(resp)
-
-    return resp
-
-
-def _get_encoding_from_headers(headers):
-    # type: (ResponseHeaders) -> Optional[str]
-    """Determine if we have any encoding information in our headers.
-    """
-    if headers and "Content-Type" in headers:
-        content_type, params = cgi.parse_header(headers["Content-Type"])
-        if "charset" in params:
-            return params['charset']
-    return None
-
-
-def _determine_base_url(document, page_url):
-    # type: (HTMLElement, str) -> str
-    """Determine the HTML document's base URL.
-
-    This looks for a ``<base>`` tag in the HTML document. If present, its href
-    attribute denotes the base URL of anchor tags in the document. If there is
-    no such tag (or if it does not have a valid href attribute), the HTML
-    file's URL is used as the base URL.
-
-    :param document: An HTML document representation. The current
-        implementation expects the result of ``html5lib.parse()``.
-    :param page_url: The URL of the HTML document.
-    """
-    for base in document.findall(".//base"):
-        href = base.get("href")
-        if href is not None:
-            return href
-    return page_url
-
-
-def _clean_link(url):
-    # type: (str) -> str
-    """Makes sure a link is fully encoded.  That is, if a ' ' shows up in
-    the link, it will be rewritten to %20 (while not over-quoting
-    % or other characters)."""
-    # Split the URL into parts according to the general structure
-    # `scheme://netloc/path;parameters?query#fragment`. Note that the
-    # `netloc` can be empty and the URI will then refer to a local
-    # filesystem path.
-    result = urllib_parse.urlparse(url)
-    # In both cases below we unquote prior to quoting to make sure
-    # nothing is double quoted.
-    if result.netloc == "":
-        # On Windows the path part might contain a drive letter which
-        # should not be quoted. On Linux where drive letters do not
-        # exist, the colon should be quoted. We rely on urllib.request
-        # to do the right thing here.
-        path = urllib_request.pathname2url(
-            urllib_request.url2pathname(result.path))
-    else:
-        # In addition to the `/` character we protect `@` so that
-        # revision strings in VCS URLs are properly parsed.
-        path = urllib_parse.quote(urllib_parse.unquote(result.path), safe="/@")
-    return urllib_parse.urlunparse(result._replace(path=path))
-
-
-def _create_link_from_element(
-    anchor,    # type: HTMLElement
-    page_url,  # type: str
-    base_url,  # type: str
-):
-    # type: (...) -> Optional[Link]
-    """
-    Convert an anchor element in a simple repository page to a Link.
-    """
-    href = anchor.get("href")
-    if not href:
-        return None
-
-    url = _clean_link(urllib_parse.urljoin(base_url, href))
-    pyrequire = anchor.get('data-requires-python')
-    pyrequire = unescape(pyrequire) if pyrequire else None
-
-    yanked_reason = anchor.get('data-yanked')
-    if yanked_reason:
-        # This is a unicode string in Python 2 (and 3).
-        yanked_reason = unescape(yanked_reason)
-
-    link = Link(
-        url,
-        comes_from=page_url,
-        requires_python=pyrequire,
-        yanked_reason=yanked_reason,
-    )
-
-    return link
-
-
-def parse_links(page):
-    # type: (HTMLPage) -> Iterable[Link]
-    """
-    Parse an HTML document, and yield its anchor elements as Link objects.
-    """
-    document = html5lib.parse(
-        page.content,
-        transport_encoding=page.encoding,
-        namespaceHTMLElements=False,
-    )
-
-    url = page.url
-    base_url = _determine_base_url(document, url)
-    for anchor in document.findall(".//a"):
-        link = _create_link_from_element(
-            anchor,
-            page_url=url,
-            base_url=base_url,
-        )
-        if link is None:
-            continue
-        yield link
-
-
-class HTMLPage(object):
-    """Represents one page, along with its URL"""
-
-    def __init__(
-        self,
-        content,   # type: bytes
-        encoding,  # type: Optional[str]
-        url,       # type: str
-    ):
-        # type: (...) -> None
-        """
-        :param encoding: the encoding to decode the given content.
-        :param url: the URL from which the HTML was downloaded.
-        """
-        self.content = content
-        self.encoding = encoding
-        self.url = url
-
-    def __str__(self):
-        return redact_auth_from_url(self.url)
-
-
-def _handle_get_page_fail(
-    link,  # type: Link
-    reason,  # type: Union[str, Exception]
-    meth=None  # type: Optional[Callable[..., None]]
-):
-    # type: (...) -> None
-    if meth is None:
-        meth = logger.debug
-    meth("Could not fetch URL %s: %s - skipping", link, reason)
-
-
-def _make_html_page(response):
-    # type: (Response) -> HTMLPage
-    encoding = _get_encoding_from_headers(response.headers)
-    return HTMLPage(response.content, encoding=encoding, url=response.url)
-
-
-def _get_html_page(link, session=None):
-    # type: (Link, Optional[PipSession]) -> Optional[HTMLPage]
-    if session is None:
-        raise TypeError(
-            "_get_html_page() missing 1 required keyword argument: 'session'"
-        )
-
-    url = link.url.split('#', 1)[0]
-
-    # Check for VCS schemes that do not support lookup as web pages.
-    vcs_scheme = _match_vcs_scheme(url)
-    if vcs_scheme:
-        logger.debug('Cannot look at %s URL %s', vcs_scheme, link)
-        return None
-
-    # Tack index.html onto file:// URLs that point to directories
-    scheme, _, path, _, _, _ = urllib_parse.urlparse(url)
-    if (scheme == 'file' and os.path.isdir(urllib_request.url2pathname(path))):
-        # add trailing slash if not present so urljoin doesn't trim
-        # final segment
-        if not url.endswith('/'):
-            url += '/'
-        url = urllib_parse.urljoin(url, 'index.html')
-        logger.debug(' file: URL is directory, getting %s', url)
-
-    try:
-        resp = _get_html_response(url, session=session)
-    except _NotHTTP:
-        logger.debug(
-            'Skipping page %s because it looks like an archive, and cannot '
-            'be checked by HEAD.', link,
-        )
-    except _NotHTML as exc:
-        logger.debug(
-            'Skipping page %s because the %s request got Content-Type: %s',
-            link, exc.request_desc, exc.content_type,
-        )
-    except HTTPError as exc:
-        _handle_get_page_fail(link, exc)
-    except RetryError as exc:
-        _handle_get_page_fail(link, exc)
-    except SSLError as exc:
-        reason = "There was a problem confirming the ssl certificate: "
-        reason += str(exc)
-        _handle_get_page_fail(link, reason, meth=logger.info)
-    except requests.ConnectionError as exc:
-        _handle_get_page_fail(link, "connection error: %s" % exc)
-    except requests.Timeout:
-        _handle_get_page_fail(link, "timed out")
-    else:
-        return _make_html_page(resp)
-    return None
-
-
-def _remove_duplicate_links(links):
-    # type: (Iterable[Link]) -> List[Link]
-    """
-    Return a list of links, with duplicates removed and ordering preserved.
-    """
-    # We preserve the ordering when removing duplicates because we can.
-    return list(OrderedDict.fromkeys(links))
-
-
-def group_locations(locations, expand_dir=False):
-    # type: (Sequence[str], bool) -> Tuple[List[str], List[str]]
-    """
-    Divide a list of locations into two groups: "files" (archives) and "urls."
-
-    :return: A pair of lists (files, urls).
-    """
-    files = []
-    urls = []
-
-    # puts the url for the given file path into the appropriate list
-    def sort_path(path):
-        url = path_to_url(path)
-        if mimetypes.guess_type(url, strict=False)[0] == 'text/html':
-            urls.append(url)
-        else:
-            files.append(url)
-
-    for url in locations:
-
-        is_local_path = os.path.exists(url)
-        is_file_url = url.startswith('file:')
-
-        if is_local_path or is_file_url:
-            if is_local_path:
-                path = url
-            else:
-                path = url_to_path(url)
-            if os.path.isdir(path):
-                if expand_dir:
-                    path = os.path.realpath(path)
-                    for item in os.listdir(path):
-                        sort_path(os.path.join(path, item))
-                elif is_file_url:
-                    urls.append(url)
-                else:
-                    logger.warning(
-                        "Path '{0}' is ignored: "
-                        "it is a directory.".format(path),
-                    )
-            elif os.path.isfile(path):
-                sort_path(path)
-            else:
-                logger.warning(
-                    "Url '%s' is ignored: it is neither a file "
-                    "nor a directory.", url,
-                )
-        elif is_url(url):
-            # Only add url with clear scheme
-            urls.append(url)
-        else:
-            logger.warning(
-                "Url '%s' is ignored. It is either a non-existing "
-                "path or lacks a specific scheme.", url,
-            )
-
-    return files, urls
-
-
-class CollectedLinks(object):
-
-    """
-    Encapsulates all the Link objects collected by a call to
-    LinkCollector.collect_links(), stored separately as--
-
-    (1) links from the configured file locations,
-    (2) links from the configured find_links, and
-    (3) a dict mapping HTML page url to links from that page.
-    """
-
-    def __init__(
-        self,
-        files,       # type: List[Link]
-        find_links,  # type: List[Link]
-        pages,       # type: Dict[str, List[Link]]
-    ):
-        # type: (...) -> None
-        """
-        :param files: Links from file locations.
-        :param find_links: Links from find_links.
-        :param pages: A dict mapping HTML page url to links from that page.
-        """
-        self.files = files
-        self.find_links = find_links
-        self.pages = pages
-
-
-class LinkCollector(object):
-
-    """
-    Responsible for collecting Link objects from all configured locations,
-    making network requests as needed.
-
-    The class's main method is its collect_links() method.
-    """
-
-    def __init__(
-        self,
-        session,       # type: PipSession
-        search_scope,  # type: SearchScope
-    ):
-        # type: (...) -> None
-        self.search_scope = search_scope
-        self.session = session
-
-    @property
-    def find_links(self):
-        # type: () -> List[str]
-        return self.search_scope.find_links
-
-    def _get_pages(self, locations):
-        # type: (Iterable[Link]) -> Iterable[HTMLPage]
-        """
-        Yields (page, page_url) from the given locations, skipping
-        locations that have errors.
-        """
-        for location in locations:
-            page = _get_html_page(location, session=self.session)
-            if page is None:
-                continue
-
-            yield page
-
-    def collect_links(self, project_name):
-        # type: (str) -> CollectedLinks
-        """Find all available links for the given project name.
-
-        :return: All the Link objects (unfiltered), as a CollectedLinks object.
-        """
-        search_scope = self.search_scope
-        index_locations = search_scope.get_index_urls_locations(project_name)
-        index_file_loc, index_url_loc = group_locations(index_locations)
-        fl_file_loc, fl_url_loc = group_locations(
-            self.find_links, expand_dir=True,
-        )
-
-        file_links = [
-            Link(url) for url in itertools.chain(index_file_loc, fl_file_loc)
-        ]
-
-        # We trust every directly linked archive in find_links
-        find_link_links = [Link(url, '-f') for url in self.find_links]
-
-        # We trust every url that the user has given us whether it was given
-        # via --index-url or --find-links.
-        # We want to filter out anything that does not have a secure origin.
-        url_locations = [
-            link for link in itertools.chain(
-                (Link(url) for url in index_url_loc),
-                (Link(url) for url in fl_url_loc),
-            )
-            if self.session.is_secure_origin(link)
-        ]
-
-        url_locations = _remove_duplicate_links(url_locations)
-        lines = [
-            '{} location(s) to search for versions of {}:'.format(
-                len(url_locations), project_name,
-            ),
-        ]
-        for link in url_locations:
-            lines.append('* {}'.format(link))
-        logger.debug('\n'.join(lines))
-
-        pages_links = {}
-        for page in self._get_pages(url_locations):
-            pages_links[page.url] = list(parse_links(page))
-
-        return CollectedLinks(
-            files=file_links,
-            find_links=find_link_links,
-            pages=pages_links,
-        )
diff --git a/pipenv/patched/notpip/_internal/distributions/source/__init__.py b/pipenv/patched/notpip/_internal/distributions/source/__init__.py
deleted file mode 100644
index e69de29b..00000000
diff --git a/pipenv/patched/notpip/_internal/distributions/source/legacy.py b/pipenv/patched/notpip/_internal/distributions/source/legacy.py
deleted file mode 100644
index 0e700d2a..00000000
--- a/pipenv/patched/notpip/_internal/distributions/source/legacy.py
+++ /dev/null
@@ -1,98 +0,0 @@
-# The following comment should be removed at some point in the future.
-# mypy: disallow-untyped-defs=False
-
-import logging
-
-from pipenv.patched.notpip._internal.build_env import BuildEnvironment
-from pipenv.patched.notpip._internal.distributions.base import AbstractDistribution
-from pipenv.patched.notpip._internal.exceptions import InstallationError
-from pipenv.patched.notpip._internal.utils.subprocess import runner_with_spinner_message
-
-logger = logging.getLogger(__name__)
-
-
-class SourceDistribution(AbstractDistribution):
-    """Represents a source distribution.
-
-    The preparation step for these needs metadata for the packages to be
-    generated, either using PEP 517 or using the legacy `setup.py egg_info`.
-
-    NOTE from @pradyunsg (14 June 2019)
-    I expect SourceDistribution class will need to be split into
-    `legacy_source` (setup.py based) and `source` (PEP 517 based) when we start
-    bringing logic for preparation out of InstallRequirement into this class.
-    """
-
-    def get_pkg_resources_distribution(self):
-        return self.req.get_dist()
-
-    def prepare_distribution_metadata(self, finder, build_isolation):
-        # Prepare for building. We need to:
-        #   1. Load pyproject.toml (if it exists)
-        #   2. Set up the build environment
-
-        self.req.load_pyproject_toml()
-        should_isolate = self.req.use_pep517 and build_isolation
-        if should_isolate:
-            self._setup_isolation(finder)
-
-        self.req.prepare_metadata()
-        self.req.assert_source_matches_version()
-
-    def _setup_isolation(self, finder):
-        def _raise_conflicts(conflicting_with, conflicting_reqs):
-            format_string = (
-                "Some build dependencies for {requirement} "
-                "conflict with {conflicting_with}: {description}."
-            )
-            error_message = format_string.format(
-                requirement=self.req,
-                conflicting_with=conflicting_with,
-                description=', '.join(
-                    '%s is incompatible with %s' % (installed, wanted)
-                    for installed, wanted in sorted(conflicting)
-                )
-            )
-            raise InstallationError(error_message)
-
-        # Isolate in a BuildEnvironment and install the build-time
-        # requirements.
-        self.req.build_env = BuildEnvironment()
-        self.req.build_env.install_requirements(
-            finder, self.req.pyproject_requires, 'overlay',
-            "Installing build dependencies"
-        )
-        conflicting, missing = self.req.build_env.check_requirements(
-            self.req.requirements_to_check
-        )
-        if conflicting:
-            _raise_conflicts("PEP 517/518 supported requirements",
-                             conflicting)
-        if missing:
-            logger.warning(
-                "Missing build requirements in pyproject.toml for %s.",
-                self.req,
-            )
-            logger.warning(
-                "The project does not specify a build backend, and "
-                "pip cannot fall back to setuptools without %s.",
-                " and ".join(map(repr, sorted(missing)))
-            )
-        # Install any extra build dependencies that the backend requests.
-        # This must be done in a second pass, as the pyproject.toml
-        # dependencies must be installed before we can call the backend.
-        with self.req.build_env:
-            runner = runner_with_spinner_message(
-                "Getting requirements to build wheel"
-            )
-            backend = self.req.pep517_backend
-            with backend.subprocess_runner(runner):
-                reqs = backend.get_requires_for_build_wheel()
-
-        conflicting, missing = self.req.build_env.check_requirements(reqs)
-        if conflicting:
-            _raise_conflicts("the backend dependencies", conflicting)
-        self.req.build_env.install_requirements(
-            finder, missing, 'normal',
-            "Installing backend dependencies"
-        )
diff --git a/pipenv/patched/notpip/_internal/download.py b/pipenv/patched/notpip/_internal/download.py
deleted file mode 100644
index b8d12e17..00000000
--- a/pipenv/patched/notpip/_internal/download.py
+++ /dev/null
@@ -1,578 +0,0 @@
-# The following comment should be removed at some point in the future.
-# mypy: disallow-untyped-defs=False
-
-from __future__ import absolute_import
-
-import cgi
-import logging
-import mimetypes
-import os
-import re
-import shutil
-import sys
-
-from pipenv.patched.notpip._vendor import requests
-from pipenv.patched.notpip._vendor.requests.models import CONTENT_CHUNK_SIZE, Response
-from pipenv.patched.notpip._vendor.six import PY2
-from pipenv.patched.notpip._vendor.six.moves.urllib import parse as urllib_parse
-
-from pipenv.patched.notpip._internal.exceptions import HashMismatch, InstallationError
-from pipenv.patched.notpip._internal.models.index import PyPI
-from pipenv.patched.notpip._internal.network.session import PipSession
-from pipenv.patched.notpip._internal.utils.encoding import auto_decode
-from pipenv.patched.notpip._internal.utils.filesystem import copy2_fixed
-from pipenv.patched.notpip._internal.utils.misc import (
-    ask_path_exists,
-    backup_dir,
-    consume,
-    display_path,
-    format_size,
-    hide_url,
-    path_to_display,
-    rmtree,
-    splitext,
-)
-from pipenv.patched.notpip._internal.utils.temp_dir import TempDirectory
-from pipenv.patched.notpip._internal.utils.typing import MYPY_CHECK_RUNNING
-from pipenv.patched.notpip._internal.utils.ui import DownloadProgressProvider
-from pipenv.patched.notpip._internal.utils.unpacking import unpack_file
-from pipenv.patched.notpip._internal.utils.urls import get_url_scheme
-from pipenv.patched.notpip._internal.vcs import vcs
-
-if MYPY_CHECK_RUNNING:
-    from typing import (
-        IO, Callable, List, Optional, Text, Tuple,
-    )
-
-    from mypy_extensions import TypedDict
-
-    from pipenv.patched.notpip._internal.models.link import Link
-    from pipenv.patched.notpip._internal.utils.hashes import Hashes
-    from pipenv.patched.notpip._internal.vcs.versioncontrol import VersionControl
-
-    if PY2:
-        CopytreeKwargs = TypedDict(
-            'CopytreeKwargs',
-            {
-                'ignore': Callable[[str, List[str]], List[str]],
-                'symlinks': bool,
-            },
-            total=False,
-        )
-    else:
-        CopytreeKwargs = TypedDict(
-            'CopytreeKwargs',
-            {
-                'copy_function': Callable[[str, str], None],
-                'ignore': Callable[[str, List[str]], List[str]],
-                'ignore_dangling_symlinks': bool,
-                'symlinks': bool,
-            },
-            total=False,
-        )
-
-
-__all__ = ['get_file_content',
-           'unpack_vcs_link',
-           'unpack_file_url',
-           'unpack_http_url', 'unpack_url',
-           'parse_content_disposition', 'sanitize_content_filename']
-
-
-logger = logging.getLogger(__name__)
-
-
-def get_file_content(url, comes_from=None, session=None):
-    # type: (str, Optional[str], Optional[PipSession]) -> Tuple[str, Text]
-    """Gets the content of a file; it may be a filename, file: URL, or
-    http: URL.  Returns (location, content).  Content is unicode.
-
-    :param url:         File path or url.
-    :param comes_from:  Origin description of requirements.
-    :param session:     Instance of pip.download.PipSession.
-    """
-    if session is None:
-        raise TypeError(
-            "get_file_content() missing 1 required keyword argument: 'session'"
-        )
-
-    scheme = get_url_scheme(url)
-
-    if scheme in ['http', 'https']:
-        # FIXME: catch some errors
-        resp = session.get(url)
-        resp.raise_for_status()
-        return resp.url, resp.text
-
-    elif scheme == 'file':
-        if comes_from and comes_from.startswith('http'):
-            raise InstallationError(
-                'Requirements file %s references URL %s, which is local'
-                % (comes_from, url))
-
-        path = url.split(':', 1)[1]
-        path = path.replace('\\', '/')
-        match = _url_slash_drive_re.match(path)
-        if match:
-            path = match.group(1) + ':' + path.split('|', 1)[1]
-        path = urllib_parse.unquote(path)
-        if path.startswith('/'):
-            path = '/' + path.lstrip('/')
-        url = path
-
-    try:
-        with open(url, 'rb') as f:
-            content = auto_decode(f.read())
-    except IOError as exc:
-        raise InstallationError(
-            'Could not open requirements file: %s' % str(exc)
-        )
-    return url, content
-
-
-_url_slash_drive_re = re.compile(r'/*([a-z])\|', re.I)
-
-
-def unpack_vcs_link(link, location):
-    # type: (Link, str) -> None
-    vcs_backend = _get_used_vcs_backend(link)
-    assert vcs_backend is not None
-    vcs_backend.unpack(location, url=hide_url(link.url))
-
-
-def _get_used_vcs_backend(link):
-    # type: (Link) -> Optional[VersionControl]
-    """
-    Return a VersionControl object or None.
-    """
-    for vcs_backend in vcs.backends:
-        if link.scheme in vcs_backend.schemes:
-            return vcs_backend
-    return None
-
-
-def _progress_indicator(iterable, *args, **kwargs):
-    return iterable
-
-
-def _download_url(
-    resp,  # type: Response
-    link,  # type: Link
-    content_file,  # type: IO
-    hashes,  # type: Optional[Hashes]
-    progress_bar  # type: str
-):
-    # type: (...) -> None
-    try:
-        total_length = int(resp.headers['content-length'])
-    except (ValueError, KeyError, TypeError):
-        total_length = 0
-
-    cached_resp = getattr(resp, "from_cache", False)
-    if logger.getEffectiveLevel() > logging.INFO:
-        show_progress = False
-    elif cached_resp:
-        show_progress = False
-    elif total_length > (40 * 1000):
-        show_progress = True
-    elif not total_length:
-        show_progress = True
-    else:
-        show_progress = False
-
-    show_url = link.show_url
-
-    def resp_read(chunk_size):
-        try:
-            # Special case for urllib3.
-            for chunk in resp.raw.stream(
-                    chunk_size,
-                    # We use decode_content=False here because we don't
-                    # want urllib3 to mess with the raw bytes we get
-                    # from the server. If we decompress inside of
-                    # urllib3 then we cannot verify the checksum
-                    # because the checksum will be of the compressed
-                    # file. This breakage will only occur if the
-                    # server adds a Content-Encoding header, which
-                    # depends on how the server was configured:
-                    # - Some servers will notice that the file isn't a
-                    #   compressible file and will leave the file alone
-                    #   and with an empty Content-Encoding
-                    # - Some servers will notice that the file is
-                    #   already compressed and will leave the file
-                    #   alone and will add a Content-Encoding: gzip
-                    #   header
-                    # - Some servers won't notice anything at all and
-                    #   will take a file that's already been compressed
-                    #   and compress it again and set the
-                    #   Content-Encoding: gzip header
-                    #
-                    # By setting this not to decode automatically we
-                    # hope to eliminate problems with the second case.
-                    decode_content=False):
-                yield chunk
-        except AttributeError:
-            # Standard file-like object.
-            while True:
-                chunk = resp.raw.read(chunk_size)
-                if not chunk:
-                    break
-                yield chunk
-
-    def written_chunks(chunks):
-        for chunk in chunks:
-            content_file.write(chunk)
-            yield chunk
-
-    progress_indicator = _progress_indicator
-
-    if link.netloc == PyPI.netloc:
-        url = show_url
-    else:
-        url = link.url_without_fragment
-
-    if show_progress:  # We don't show progress on cached responses
-        progress_indicator = DownloadProgressProvider(progress_bar,
-                                                      max=total_length)
-        if total_length:
-            logger.info("Downloading %s (%s)", url, format_size(total_length))
-        else:
-            logger.info("Downloading %s", url)
-    elif cached_resp:
-        logger.info("Using cached %s", url)
-    else:
-        logger.info("Downloading %s", url)
-
-    downloaded_chunks = written_chunks(
-        progress_indicator(
-            resp_read(CONTENT_CHUNK_SIZE),
-            CONTENT_CHUNK_SIZE
-        )
-    )
-    if hashes:
-        hashes.check_against_chunks(downloaded_chunks)
-    else:
-        consume(downloaded_chunks)
-
-
-def _copy_file(filename, location, link):
-    copy = True
-    download_location = os.path.join(location, link.filename)
-    if os.path.exists(download_location):
-        response = ask_path_exists(
-            'The file %s exists. (i)gnore, (w)ipe, (b)ackup, (a)abort' %
-            display_path(download_location), ('i', 'w', 'b', 'a'))
-        if response == 'i':
-            copy = False
-        elif response == 'w':
-            logger.warning('Deleting %s', display_path(download_location))
-            os.remove(download_location)
-        elif response == 'b':
-            dest_file = backup_dir(download_location)
-            logger.warning(
-                'Backing up %s to %s',
-                display_path(download_location),
-                display_path(dest_file),
-            )
-            shutil.move(download_location, dest_file)
-        elif response == 'a':
-            sys.exit(-1)
-    if copy:
-        shutil.copy(filename, download_location)
-        logger.info('Saved %s', display_path(download_location))
-
-
-def unpack_http_url(
-    link,  # type: Link
-    location,  # type: str
-    download_dir=None,  # type: Optional[str]
-    session=None,  # type: Optional[PipSession]
-    hashes=None,  # type: Optional[Hashes]
-    progress_bar="on"  # type: str
-):
-    # type: (...) -> None
-    if session is None:
-        raise TypeError(
-            "unpack_http_url() missing 1 required keyword argument: 'session'"
-        )
-
-    with TempDirectory(kind="unpack") as temp_dir:
-        # If a download dir is specified, is the file already downloaded there?
-        already_downloaded_path = None
-        if download_dir:
-            already_downloaded_path = _check_download_dir(link,
-                                                          download_dir,
-                                                          hashes)
-
-        if already_downloaded_path:
-            from_path = already_downloaded_path
-            content_type = mimetypes.guess_type(from_path)[0]
-        else:
-            # let's download to a tmp dir
-            from_path, content_type = _download_http_url(link,
-                                                         session,
-                                                         temp_dir.path,
-                                                         hashes,
-                                                         progress_bar)
-
-        # unpack the archive to the build dir location. even when only
-        # downloading archives, they have to be unpacked to parse dependencies
-        unpack_file(from_path, location, content_type)
-
-        # a download dir is specified; let's copy the archive there
-        if download_dir and not already_downloaded_path:
-            _copy_file(from_path, download_dir, link)
-
-        if not already_downloaded_path:
-            os.unlink(from_path)
-
-
-def _copy2_ignoring_special_files(src, dest):
-    # type: (str, str) -> None
-    """Copying special files is not supported, but as a convenience to users
-    we skip errors copying them. This supports tools that may create e.g.
-    socket files in the project source directory.
-    """
-    try:
-        copy2_fixed(src, dest)
-    except shutil.SpecialFileError as e:
-        # SpecialFileError may be raised due to either the source or
-        # destination. If the destination was the cause then we would actually
-        # care, but since the destination directory is deleted prior to
-        # copy we ignore all of them assuming it is caused by the source.
-        logger.warning(
-            "Ignoring special file error '%s' encountered copying %s to %s.",
-            str(e),
-            path_to_display(src),
-            path_to_display(dest),
-        )
-
-
-def _copy_source_tree(source, target):
-    # type: (str, str) -> None
-    def ignore(d, names):
-        # Pulling in those directories can potentially be very slow,
-        # exclude the following directories if they appear in the top
-        # level dir (and only it).
-        # See discussion at https://github.com/pypa/pip/pull/6770
-        return ['.tox', '.nox'] if d == source else []
-
-    kwargs = dict(ignore=ignore, symlinks=True)  # type: CopytreeKwargs
-
-    if not PY2:
-        # Python 2 does not support copy_function, so we only ignore
-        # errors on special file copy in Python 3.
-        kwargs['copy_function'] = _copy2_ignoring_special_files
-
-    shutil.copytree(source, target, **kwargs)
-
-
-def unpack_file_url(
-    link,  # type: Link
-    location,  # type: str
-    download_dir=None,  # type: Optional[str]
-    hashes=None  # type: Optional[Hashes]
-):
-    # type: (...) -> None
-    """Unpack link into location.
-
-    If download_dir is provided and link points to a file, make a copy
-    of the link file inside download_dir.
-    """
-    link_path = link.file_path
-    # If it's a url to a local directory
-    if link.is_existing_dir():
-        if os.path.isdir(location):
-            rmtree(location)
-        _copy_source_tree(link_path, location)
-        if download_dir:
-            logger.info('Link is a directory, ignoring download_dir')
-        return
-
-    # If --require-hashes is off, `hashes` is either empty, the
-    # link's embedded hash, or MissingHashes; it is required to
-    # match. If --require-hashes is on, we are satisfied by any
-    # hash in `hashes` matching: a URL-based or an option-based
-    # one; no internet-sourced hash will be in `hashes`.
-    if hashes:
-        hashes.check_against_path(link_path)
-
-    # If a download dir is specified, is the file already there and valid?
-    already_downloaded_path = None
-    if download_dir:
-        already_downloaded_path = _check_download_dir(link,
-                                                      download_dir,
-                                                      hashes)
-
-    if already_downloaded_path:
-        from_path = already_downloaded_path
-    else:
-        from_path = link_path
-
-    content_type = mimetypes.guess_type(from_path)[0]
-
-    # unpack the archive to the build dir location. even when only downloading
-    # archives, they have to be unpacked to parse dependencies
-    unpack_file(from_path, location, content_type)
-
-    # a download dir is specified and not already downloaded
-    if download_dir and not already_downloaded_path:
-        _copy_file(from_path, download_dir, link)
-
-
-def unpack_url(
-    link,  # type: Link
-    location,  # type: str
-    download_dir=None,  # type: Optional[str]
-    session=None,  # type: Optional[PipSession]
-    hashes=None,  # type: Optional[Hashes]
-    progress_bar="on"  # type: str
-):
-    # type: (...) -> None
-    """Unpack link.
-       If link is a VCS link:
-         if only_download, export into download_dir and ignore location
-          else unpack into location
-       for other types of link:
-         - unpack into location
-         - if download_dir, copy the file into download_dir
-         - if only_download, mark location for deletion
-
-    :param hashes: A Hashes object, one of whose embedded hashes must match,
-        or HashMismatch will be raised. If the Hashes is empty, no matches are
-        required, and unhashable types of requirements (like VCS ones, which
-        would ordinarily raise HashUnsupported) are allowed.
-    """
-    # non-editable vcs urls
-    if link.is_vcs:
-        unpack_vcs_link(link, location)
-
-    # file urls
-    elif link.is_file:
-        unpack_file_url(link, location, download_dir, hashes=hashes)
-
-    # http urls
-    else:
-        if session is None:
-            session = PipSession()
-
-        unpack_http_url(
-            link,
-            location,
-            download_dir,
-            session,
-            hashes=hashes,
-            progress_bar=progress_bar
-        )
-
-
-def sanitize_content_filename(filename):
-    # type: (str) -> str
-    """
-    Sanitize the "filename" value from a Content-Disposition header.
-    """
-    return os.path.basename(filename)
-
-
-def parse_content_disposition(content_disposition, default_filename):
-    # type: (str, str) -> str
-    """
-    Parse the "filename" value from a Content-Disposition header, and
-    return the default filename if the result is empty.
-    """
-    _type, params = cgi.parse_header(content_disposition)
-    filename = params.get('filename')
-    if filename:
-        # We need to sanitize the filename to prevent directory traversal
-        # in case the filename contains ".." path parts.
-        filename = sanitize_content_filename(filename)
-    return filename or default_filename
-
-
-def _download_http_url(
-    link,  # type: Link
-    session,  # type: PipSession
-    temp_dir,  # type: str
-    hashes,  # type: Optional[Hashes]
-    progress_bar  # type: str
-):
-    # type: (...) -> Tuple[str, str]
-    """Download link url into temp_dir using provided session"""
-    target_url = link.url.split('#', 1)[0]
-    try:
-        resp = session.get(
-            target_url,
-            # We use Accept-Encoding: identity here because requests
-            # defaults to accepting compressed responses. This breaks in
-            # a variety of ways depending on how the server is configured.
-            # - Some servers will notice that the file isn't a compressible
-            #   file and will leave the file alone and with an empty
-            #   Content-Encoding
-            # - Some servers will notice that the file is already
-            #   compressed and will leave the file alone and will add a
-            #   Content-Encoding: gzip header
-            # - Some servers won't notice anything at all and will take
-            #   a file that's already been compressed and compress it again
-            #   and set the Content-Encoding: gzip header
-            # By setting this to request only the identity encoding We're
-            # hoping to eliminate the third case. Hopefully there does not
-            # exist a server which when given a file will notice it is
-            # already compressed and that you're not asking for a
-            # compressed file and will then decompress it before sending
-            # because if that's the case I don't think it'll ever be
-            # possible to make this work.
-            headers={"Accept-Encoding": "identity"},
-            stream=True,
-        )
-        resp.raise_for_status()
-    except requests.HTTPError as exc:
-        logger.critical(
-            "HTTP error %s while getting %s", exc.response.status_code, link,
-        )
-        raise
-
-    content_type = resp.headers.get('content-type', '')
-    filename = link.filename  # fallback
-    # Have a look at the Content-Disposition header for a better guess
-    content_disposition = resp.headers.get('content-disposition')
-    if content_disposition:
-        filename = parse_content_disposition(content_disposition, filename)
-    ext = splitext(filename)[1]  # type: Optional[str]
-    if not ext:
-        ext = mimetypes.guess_extension(content_type)
-        if ext:
-            filename += ext
-    if not ext and link.url != resp.url:
-        ext = os.path.splitext(resp.url)[1]
-        if ext:
-            filename += ext
-    file_path = os.path.join(temp_dir, filename)
-    with open(file_path, 'wb') as content_file:
-        _download_url(resp, link, content_file, hashes, progress_bar)
-    return file_path, content_type
-
-
-def _check_download_dir(link, download_dir, hashes):
-    # type: (Link, str, Optional[Hashes]) -> Optional[str]
-    """ Check download_dir for previously downloaded file with correct hash
-        If a correct file is found return its path else None
-    """
-    download_path = os.path.join(download_dir, link.filename)
-
-    if not os.path.exists(download_path):
-        return None
-
-    # If already downloaded, does its hash match?
-    logger.info('File was already downloaded %s', download_path)
-    if hashes:
-        try:
-            hashes.check_against_path(download_path)
-        except HashMismatch:
-            logger.warning(
-                'Previously-downloaded file %s has bad hash. '
-                'Re-downloading.',
-                download_path
-            )
-            os.unlink(download_path)
-            return None
-    return download_path
diff --git a/pipenv/patched/notpip/_internal/index.py b/pipenv/patched/notpip/_internal/index.py
deleted file mode 100644
index 0f212115..00000000
--- a/pipenv/patched/notpip/_internal/index.py
+++ /dev/null
@@ -1,1028 +0,0 @@
-"""Routines related to PyPI, indexes"""
-
-# The following comment should be removed at some point in the future.
-# mypy: strict-optional=False
-# mypy: disallow-untyped-defs=False
-
-from __future__ import absolute_import
-
-import logging
-import re
-
-from pipenv.patched.notpip._vendor.packaging import specifiers
-from pipenv.patched.notpip._vendor.packaging.utils import canonicalize_name
-from pipenv.patched.notpip._vendor.packaging.version import parse as parse_version
-
-from pipenv.patched.notpip._internal.exceptions import (
-    BestVersionAlreadyInstalled,
-    DistributionNotFound,
-    InvalidWheelFilename,
-    UnsupportedWheel,
-)
-from pipenv.patched.notpip._internal.models.candidate import InstallationCandidate
-from pipenv.patched.notpip._internal.models.format_control import FormatControl
-from pipenv.patched.notpip._internal.models.link import Link
-from pipenv.patched.notpip._internal.models.selection_prefs import SelectionPreferences
-from pipenv.patched.notpip._internal.models.target_python import TargetPython
-from pipenv.patched.notpip._internal.utils.filetypes import WHEEL_EXTENSION
-from pipenv.patched.notpip._internal.utils.logging import indent_log
-from pipenv.patched.notpip._internal.utils.misc import build_netloc
-from pipenv.patched.notpip._internal.utils.packaging import check_requires_python
-from pipenv.patched.notpip._internal.utils.typing import MYPY_CHECK_RUNNING
-from pipenv.patched.notpip._internal.utils.unpacking import SUPPORTED_EXTENSIONS
-from pipenv.patched.notpip._internal.utils.urls import url_to_path
-from pipenv.patched.notpip._internal.wheel import Wheel
-
-if MYPY_CHECK_RUNNING:
-    from typing import (
-        FrozenSet, Iterable, List, Optional, Set, Text, Tuple, Union,
-    )
-    from pipenv.patched.notpip._vendor.packaging.version import _BaseVersion
-    from pipenv.patched.notpip._internal.collector import LinkCollector
-    from pipenv.patched.notpip._internal.models.search_scope import SearchScope
-    from pipenv.patched.notpip._internal.req import InstallRequirement
-    from pipenv.patched.notpip._internal.pep425tags import Pep425Tag
-    from pipenv.patched.notpip._internal.utils.hashes import Hashes
-
-    BuildTag = Union[Tuple[()], Tuple[int, str]]
-    CandidateSortingKey = (
-        Tuple[int, int, int, _BaseVersion, BuildTag, Optional[int]]
-    )
-
-
-__all__ = ['FormatControl', 'BestCandidateResult', 'PackageFinder']
-
-
-logger = logging.getLogger(__name__)
-
-
-def _check_link_requires_python(
-    link,  # type: Link
-    version_info,  # type: Tuple[int, int, int]
-    ignore_requires_python=False,  # type: bool
-):
-    # type: (...) -> bool
-    """
-    Return whether the given Python version is compatible with a link's
-    "Requires-Python" value.
-
-    :param version_info: A 3-tuple of ints representing the Python
-        major-minor-micro version to check.
-    :param ignore_requires_python: Whether to ignore the "Requires-Python"
-        value if the given Python version isn't compatible.
-    """
-    try:
-        is_compatible = check_requires_python(
-            link.requires_python, version_info=version_info,
-        )
-    except specifiers.InvalidSpecifier:
-        logger.debug(
-            "Ignoring invalid Requires-Python (%r) for link: %s",
-            link.requires_python, link,
-        )
-    else:
-        if not is_compatible:
-            version = '.'.join(map(str, version_info))
-            if not ignore_requires_python:
-                logger.debug(
-                    'Link requires a different Python (%s not in: %r): %s',
-                    version, link.requires_python, link,
-                )
-                return False
-
-            logger.debug(
-                'Ignoring failed Requires-Python check (%s not in: %r) '
-                'for link: %s',
-                version, link.requires_python, link,
-            )
-
-    return True
-
-
-class LinkEvaluator(object):
-
-    """
-    Responsible for evaluating links for a particular project.
-    """
-
-    _py_version_re = re.compile(r'-py([123]\.?[0-9]?)$')
-
-    # Don't include an allow_yanked default value to make sure each call
-    # site considers whether yanked releases are allowed. This also causes
-    # that decision to be made explicit in the calling code, which helps
-    # people when reading the code.
-    def __init__(
-        self,
-        project_name,    # type: str
-        canonical_name,  # type: str
-        formats,         # type: FrozenSet
-        target_python,   # type: TargetPython
-        allow_yanked,    # type: bool
-        ignore_requires_python=None,  # type: Optional[bool]
-        ignore_compatibility=None,  # type: Optional[bool]
-    ):
-        # type: (...) -> None
-        """
-        :param project_name: The user supplied package name.
-        :param canonical_name: The canonical package name.
-        :param formats: The formats allowed for this package. Should be a set
-            with 'binary' or 'source' or both in it.
-        :param target_python: The target Python interpreter to use when
-            evaluating link compatibility. This is used, for example, to
-            check wheel compatibility, as well as when checking the Python
-            version, e.g. the Python version embedded in a link filename
-            (or egg fragment) and against an HTML link's optional PEP 503
-            "data-requires-python" attribute.
-        :param allow_yanked: Whether files marked as yanked (in the sense
-            of PEP 592) are permitted to be candidates for install.
-        :param ignore_requires_python: Whether to ignore incompatible
-            PEP 503 "data-requires-python" values in HTML links. Defaults
-            to False.
-        :param Optional[bool] ignore_compatibility: Whether to ignore
-            compatibility of python versions and allow all versions of packages.
-        """
-        if ignore_requires_python is None:
-            ignore_requires_python = False
-        if ignore_compatibility is None:
-            ignore_compatibility = True
-
-        self._allow_yanked = allow_yanked
-        self._canonical_name = canonical_name
-        self._ignore_requires_python = ignore_requires_python
-        self._formats = formats
-        self._target_python = target_python
-        self._ignore_compatibility = ignore_compatibility
-
-        self.project_name = project_name
-
-    def evaluate_link(self, link):
-        # type: (Link) -> Tuple[bool, Optional[Text]]
-        """
-        Determine whether a link is a candidate for installation.
-
-        :return: A tuple (is_candidate, result), where `result` is (1) a
-            version string if `is_candidate` is True, and (2) if
-            `is_candidate` is False, an optional string to log the reason
-            the link fails to qualify.
-        """
-        version = None
-        if link.is_yanked and not self._allow_yanked:
-            reason = link.yanked_reason or '<none given>'
-            # Mark this as a unicode string to prevent "UnicodeEncodeError:
-            # 'ascii' codec can't encode character" in Python 2 when
-            # the reason contains non-ascii characters.
-            return (False, u'yanked for reason: {}'.format(reason))
-
-        if link.egg_fragment:
-            egg_info = link.egg_fragment
-            ext = link.ext
-        else:
-            egg_info, ext = link.splitext()
-            if not ext:
-                return (False, 'not a file')
-            if ext not in SUPPORTED_EXTENSIONS:
-                return (False, 'unsupported archive format: %s' % ext)
-            if "binary" not in self._formats and ext == WHEEL_EXTENSION and not self._ignore_compatibility:
-                reason = 'No binaries permitted for %s' % self.project_name
-                return (False, reason)
-            if "macosx10" in link.path and ext == '.zip' and not self._ignore_compatibility:
-                return (False, 'macosx10 one')
-            if ext == WHEEL_EXTENSION:
-                try:
-                    wheel = Wheel(link.filename)
-                except InvalidWheelFilename:
-                    return (False, 'invalid wheel filename')
-                if canonicalize_name(wheel.name) != self._canonical_name:
-                    reason = 'wrong project name (not %s)' % self.project_name
-                    return (False, reason)
-
-                supported_tags = self._target_python.get_tags()
-                if not wheel.supported(supported_tags) and not self._ignore_compatibility:
-                    # Include the wheel's tags in the reason string to
-                    # simplify troubleshooting compatibility issues.
-                    file_tags = wheel.get_formatted_file_tags()
-                    reason = (
-                        "none of the wheel's tags match: {}".format(
-                            ', '.join(file_tags)
-                        )
-                    )
-                    return (False, reason)
-
-                version = wheel.version
-
-        # This should be up by the self.ok_binary check, but see issue 2700.
-        if "source" not in self._formats and ext != WHEEL_EXTENSION:
-            return (False, 'No sources permitted for %s' % self.project_name)
-
-        if not version:
-            version = _extract_version_from_fragment(
-                egg_info, self._canonical_name,
-            )
-        if not version:
-            return (
-                False, 'Missing project version for %s' % self.project_name,
-            )
-
-        match = self._py_version_re.search(version)
-        if match:
-            version = version[:match.start()]
-            py_version = match.group(1)
-            if py_version != self._target_python.py_version:
-                return (False, 'Python version is incorrect')
-
-        supports_python = _check_link_requires_python(
-            link, version_info=self._target_python.py_version_info,
-            ignore_requires_python=self._ignore_requires_python,
-        )
-        if not supports_python and not self._ignore_compatibility:
-            # Return None for the reason text to suppress calling
-            # _log_skipped_link().
-            return (False, None)
-
-        logger.debug('Found link %s, version: %s', link, version)
-
-        return (True, version)
-
-
-def filter_unallowed_hashes(
-    candidates,    # type: List[InstallationCandidate]
-    hashes,        # type: Hashes
-    project_name,  # type: str
-):
-    # type: (...) -> List[InstallationCandidate]
-    """
-    Filter out candidates whose hashes aren't allowed, and return a new
-    list of candidates.
-
-    If at least one candidate has an allowed hash, then all candidates with
-    either an allowed hash or no hash specified are returned.  Otherwise,
-    the given candidates are returned.
-
-    Including the candidates with no hash specified when there is a match
-    allows a warning to be logged if there is a more preferred candidate
-    with no hash specified.  Returning all candidates in the case of no
-    matches lets pip report the hash of the candidate that would otherwise
-    have been installed (e.g. permitting the user to more easily update
-    their requirements file with the desired hash).
-    """
-    if not hashes:
-        logger.debug(
-            'Given no hashes to check %s links for project %r: '
-            'discarding no candidates',
-            len(candidates),
-            project_name,
-        )
-        # Make sure we're not returning back the given value.
-        return list(candidates)
-
-    matches_or_no_digest = []
-    # Collect the non-matches for logging purposes.
-    non_matches = []
-    match_count = 0
-    for candidate in candidates:
-        link = candidate.link
-        if not link.has_hash:
-            pass
-        elif link.is_hash_allowed(hashes=hashes):
-            match_count += 1
-        else:
-            non_matches.append(candidate)
-            continue
-
-        matches_or_no_digest.append(candidate)
-
-    if match_count:
-        filtered = matches_or_no_digest
-    else:
-        # Make sure we're not returning back the given value.
-        filtered = list(candidates)
-
-    if len(filtered) == len(candidates):
-        discard_message = 'discarding no candidates'
-    else:
-        discard_message = 'discarding {} non-matches:\n  {}'.format(
-            len(non_matches),
-            '\n  '.join(str(candidate.link) for candidate in non_matches)
-        )
-
-    logger.debug(
-        'Checked %s links for project %r against %s hashes '
-        '(%s matches, %s no digest): %s',
-        len(candidates),
-        project_name,
-        hashes.digest_count,
-        match_count,
-        len(matches_or_no_digest) - match_count,
-        discard_message
-    )
-
-    return filtered
-
-
-class CandidatePreferences(object):
-
-    """
-    Encapsulates some of the preferences for filtering and sorting
-    InstallationCandidate objects.
-    """
-
-    def __init__(
-        self,
-        prefer_binary=False,  # type: bool
-        allow_all_prereleases=False,  # type: bool
-    ):
-        # type: (...) -> None
-        """
-        :param allow_all_prereleases: Whether to allow all pre-releases.
-        """
-        self.allow_all_prereleases = allow_all_prereleases
-        self.prefer_binary = prefer_binary
-
-
-class BestCandidateResult(object):
-    """A collection of candidates, returned by `PackageFinder.find_best_candidate`.
-
-    This class is only intended to be instantiated by CandidateEvaluator's
-    `compute_best_candidate()` method.
-    """
-
-    def __init__(
-        self,
-        candidates,             # type: List[InstallationCandidate]
-        applicable_candidates,  # type: List[InstallationCandidate]
-        best_candidate,         # type: Optional[InstallationCandidate]
-    ):
-        # type: (...) -> None
-        """
-        :param candidates: A sequence of all available candidates found.
-        :param applicable_candidates: The applicable candidates.
-        :param best_candidate: The most preferred candidate found, or None
-            if no applicable candidates were found.
-        """
-        assert set(applicable_candidates) <= set(candidates)
-
-        if best_candidate is None:
-            assert not applicable_candidates
-        else:
-            assert best_candidate in applicable_candidates
-
-        self._applicable_candidates = applicable_candidates
-        self._candidates = candidates
-
-        self.best_candidate = best_candidate
-
-    def iter_all(self):
-        # type: () -> Iterable[InstallationCandidate]
-        """Iterate through all candidates.
-        """
-        return iter(self._candidates)
-
-    def iter_applicable(self):
-        # type: () -> Iterable[InstallationCandidate]
-        """Iterate through the applicable candidates.
-        """
-        return iter(self._applicable_candidates)
-
-
-class CandidateEvaluator(object):
-
-    """
-    Responsible for filtering and sorting candidates for installation based
-    on what tags are valid.
-    """
-
-    @classmethod
-    def create(
-        cls,
-        project_name,         # type: str
-        target_python=None,   # type: Optional[TargetPython]
-        prefer_binary=False,  # type: bool
-        allow_all_prereleases=False,  # type: bool
-        specifier=None,       # type: Optional[specifiers.BaseSpecifier]
-        hashes=None,          # type: Optional[Hashes]
-    ):
-        # type: (...) -> CandidateEvaluator
-        """Create a CandidateEvaluator object.
-
-        :param target_python: The target Python interpreter to use when
-            checking compatibility. If None (the default), a TargetPython
-            object will be constructed from the running Python.
-        :param specifier: An optional object implementing `filter`
-            (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
-            versions.
-        :param hashes: An optional collection of allowed hashes.
-        """
-        if target_python is None:
-            target_python = TargetPython()
-        if specifier is None:
-            specifier = specifiers.SpecifierSet()
-
-        supported_tags = target_python.get_tags()
-
-        return cls(
-            project_name=project_name,
-            supported_tags=supported_tags,
-            specifier=specifier,
-            prefer_binary=prefer_binary,
-            allow_all_prereleases=allow_all_prereleases,
-            hashes=hashes,
-        )
-
-    def __init__(
-        self,
-        project_name,         # type: str
-        supported_tags,       # type: List[Pep425Tag]
-        specifier,            # type: specifiers.BaseSpecifier
-        prefer_binary=False,  # type: bool
-        allow_all_prereleases=False,  # type: bool
-        hashes=None,                  # type: Optional[Hashes]
-    ):
-        # type: (...) -> None
-        """
-        :param supported_tags: The PEP 425 tags supported by the target
-            Python in order of preference (most preferred first).
-        """
-        self._allow_all_prereleases = allow_all_prereleases
-        self._hashes = hashes
-        self._prefer_binary = prefer_binary
-        self._project_name = project_name
-        self._specifier = specifier
-        self._supported_tags = supported_tags
-
-    def get_applicable_candidates(
-        self,
-        candidates,  # type: List[InstallationCandidate]
-    ):
-        # type: (...) -> List[InstallationCandidate]
-        """
-        Return the applicable candidates from a list of candidates.
-        """
-        # Using None infers from the specifier instead.
-        allow_prereleases = self._allow_all_prereleases or None
-        specifier = self._specifier
-        versions = {
-            str(v) for v in specifier.filter(
-                # We turn the version object into a str here because otherwise
-                # when we're debundled but setuptools isn't, Python will see
-                # packaging.version.Version and
-                # pkg_resources._vendor.packaging.version.Version as different
-                # types. This way we'll use a str as a common data interchange
-                # format. If we stop using the pkg_resources provided specifier
-                # and start using our own, we can drop the cast to str().
-                (str(c.version) for c in candidates),
-                prereleases=allow_prereleases,
-            )
-        }
-
-        # Again, converting version to str to deal with debundling.
-        applicable_candidates = [
-            c for c in candidates if str(c.version) in versions
-        ]
-
-        return filter_unallowed_hashes(
-            candidates=applicable_candidates,
-            hashes=self._hashes,
-            project_name=self._project_name,
-        )
-
-    def _sort_key(self, candidate, ignore_compatibility=True):
-        # type: (InstallationCandidate, bool) -> CandidateSortingKey
-        """
-        Function to pass as the `key` argument to a call to sorted() to sort
-        InstallationCandidates by preference.
-
-        Returns a tuple such that tuples sorting as greater using Python's
-        default comparison operator are more preferred.
-
-        The preference is as follows:
-
-        First and foremost, candidates with allowed (matching) hashes are
-        always preferred over candidates without matching hashes. This is
-        because e.g. if the only candidate with an allowed hash is yanked,
-        we still want to use that candidate.
-
-        Second, excepting hash considerations, candidates that have been
-        yanked (in the sense of PEP 592) are always less preferred than
-        candidates that haven't been yanked. Then:
-
-        If not finding wheels, they are sorted by version only.
-        If finding wheels, then the sort order is by version, then:
-          1. existing installs
-          2. wheels ordered via Wheel.support_index_min(self._supported_tags)
-          3. source archives
-        If prefer_binary was set, then all wheels are sorted above sources.
-
-        Note: it was considered to embed this logic into the Link
-              comparison operators, but then different sdist links
-              with the same version, would have to be considered equal
-        """
-        valid_tags = self._supported_tags
-        support_num = len(valid_tags)
-        build_tag = ()  # type: BuildTag
-        binary_preference = 0
-        link = candidate.link
-        if link.is_wheel:
-            # can raise InvalidWheelFilename
-            wheel = Wheel(link.filename)
-            if not wheel.supported(valid_tags) and not ignore_compatibility:
-                raise UnsupportedWheel(
-                    "%s is not a supported wheel for this platform. It "
-                    "can't be sorted." % wheel.filename
-                )
-            if self._prefer_binary:
-                binary_preference = 1
-            tags = self.valid_tags if not ignore_compatibility else None
-            try:
-                pri = -(wheel.support_index_min(tags=tags))
-            except TypeError:
-                pri = -(support_num)
-            if wheel.build_tag is not None:
-                match = re.match(r'^(\d+)(.*)$', wheel.build_tag)
-                build_tag_groups = match.groups()
-                build_tag = (int(build_tag_groups[0]), build_tag_groups[1])
-        else:  # sdist
-            pri = -(support_num)
-        has_allowed_hash = int(link.is_hash_allowed(self._hashes))
-        yank_value = -1 * int(link.is_yanked)  # -1 for yanked.
-        return (
-            has_allowed_hash, yank_value, binary_preference, candidate.version,
-            build_tag, pri,
-        )
-
-    def sort_best_candidate(
-        self,
-        candidates,    # type: List[InstallationCandidate]
-    ):
-        # type: (...) -> Optional[InstallationCandidate]
-        """
-        Return the best candidate per the instance's sort order, or None if
-        no candidate is acceptable.
-        """
-        if not candidates:
-            return None
-
-        best_candidate = max(candidates, key=self._sort_key)
-
-        # Log a warning per PEP 592 if necessary before returning.
-        link = best_candidate.link
-        if link.is_yanked:
-            reason = link.yanked_reason or '<none given>'
-            msg = (
-                # Mark this as a unicode string to prevent
-                # "UnicodeEncodeError: 'ascii' codec can't encode character"
-                # in Python 2 when the reason contains non-ascii characters.
-                u'The candidate selected for download or install is a '
-                'yanked version: {candidate}\n'
-                'Reason for being yanked: {reason}'
-            ).format(candidate=best_candidate, reason=reason)
-            logger.warning(msg)
-
-        return best_candidate
-
-    def compute_best_candidate(
-        self,
-        candidates,      # type: List[InstallationCandidate]
-    ):
-        # type: (...) -> BestCandidateResult
-        """
-        Compute and return a `BestCandidateResult` instance.
-        """
-        applicable_candidates = self.get_applicable_candidates(candidates)
-
-        best_candidate = self.sort_best_candidate(applicable_candidates)
-
-        return BestCandidateResult(
-            candidates,
-            applicable_candidates=applicable_candidates,
-            best_candidate=best_candidate,
-        )
-
-
-class PackageFinder(object):
-    """This finds packages.
-
-    This is meant to match easy_install's technique for looking for
-    packages, by reading pages and looking for appropriate links.
-    """
-
-    def __init__(
-        self,
-        link_collector,       # type: LinkCollector
-        target_python,        # type: TargetPython
-        allow_yanked,         # type: bool
-        format_control=None,  # type: Optional[FormatControl]
-        candidate_prefs=None,         # type: CandidatePreferences
-        ignore_requires_python=None,  # type: Optional[bool]
-        ignore_compatibility=None,  # type: Optional[bool]
-    ):
-        # type: (...) -> None
-        """
-        This constructor is primarily meant to be used by the create() class
-        method and from tests.
-
-        :param format_control: A FormatControl object, used to control
-            the selection of source packages / binary packages when consulting
-            the index and links.
-        :param candidate_prefs: Options to use when creating a
-            CandidateEvaluator object.
-        """
-        if candidate_prefs is None:
-            candidate_prefs = CandidatePreferences()
-        if ignore_compatibility is None:
-            ignore_compatibility = False
-
-        format_control = format_control or FormatControl(set(), set())
-
-        self._allow_yanked = allow_yanked
-        self._candidate_prefs = candidate_prefs
-        self._ignore_requires_python = ignore_requires_python
-        self._link_collector = link_collector
-        self._target_python = target_python
-        self._ignore_compatibility = ignore_compatibility
-
-        self.format_control = format_control
-
-        # These are boring links that have already been logged somehow.
-        self._logged_links = set()  # type: Set[Link]
-
-        # Kenneth's Hack
-        self.extra = None
-
-    # Don't include an allow_yanked default value to make sure each call
-    # site considers whether yanked releases are allowed. This also causes
-    # that decision to be made explicit in the calling code, which helps
-    # people when reading the code.
-    @classmethod
-    def create(
-        cls,
-        link_collector,      # type: LinkCollector
-        selection_prefs,     # type: SelectionPreferences
-        target_python=None,  # type: Optional[TargetPython]
-    ):
-        # type: (...) -> PackageFinder
-        """Create a PackageFinder.
-
-        :param selection_prefs: The candidate selection preferences, as a
-            SelectionPreferences object.
-        :param target_python: The target Python interpreter to use when
-            checking compatibility. If None (the default), a TargetPython
-            object will be constructed from the running Python.
-        """
-        if target_python is None:
-            target_python = TargetPython()
-
-        candidate_prefs = CandidatePreferences(
-            prefer_binary=selection_prefs.prefer_binary,
-            allow_all_prereleases=selection_prefs.allow_all_prereleases,
-        )
-
-        return cls(
-            candidate_prefs=candidate_prefs,
-            link_collector=link_collector,
-            target_python=target_python,
-            allow_yanked=selection_prefs.allow_yanked,
-            format_control=selection_prefs.format_control,
-            ignore_requires_python=selection_prefs.ignore_requires_python,
-        )
-
-    @staticmethod
-    def get_extras_links(links):
-        requires = []
-        extras = {}
-
-        current_list = requires
-
-        for link in links:
-            if not link:
-                current_list = requires
-            if link.startswith('['):
-                current_list = []
-                extras[link[1:-1]] = current_list
-            else:
-                current_list.append(link)
-        return extras
-
-    @property
-    def search_scope(self):
-        # type: () -> SearchScope
-        return self._link_collector.search_scope
-
-    @search_scope.setter
-    def search_scope(self, search_scope):
-        # type: (SearchScope) -> None
-        self._link_collector.search_scope = search_scope
-
-    @property
-    def find_links(self):
-        # type: () -> List[str]
-        return self._link_collector.find_links
-
-    @property
-    def index_urls(self):
-        # type: () -> List[str]
-        return self.search_scope.index_urls
-
-    @property
-    def trusted_hosts(self):
-        # type: () -> Iterable[str]
-        for host_port in self._link_collector.session.pip_trusted_origins:
-            yield build_netloc(*host_port)
-
-    @property
-    def allow_all_prereleases(self):
-        # type: () -> bool
-        return self._candidate_prefs.allow_all_prereleases
-
-    def set_allow_all_prereleases(self):
-        # type: () -> None
-        self._candidate_prefs.allow_all_prereleases = True
-
-    def make_link_evaluator(self, project_name):
-        # type: (str) -> LinkEvaluator
-        canonical_name = canonicalize_name(project_name)
-        formats = self.format_control.get_allowed_formats(canonical_name)
-
-        return LinkEvaluator(
-            project_name=project_name,
-            canonical_name=canonical_name,
-            formats=formats,
-            target_python=self._target_python,
-            allow_yanked=self._allow_yanked,
-            ignore_requires_python=self._ignore_requires_python,
-            ignore_compatibility=self._ignore_compatibility
-        )
-
-    def _sort_links(self, links):
-        # type: (Iterable[Link]) -> List[Link]
-        """
-        Returns elements of links in order, non-egg links first, egg links
-        second, while eliminating duplicates
-        """
-        eggs, no_eggs = [], []
-        seen = set()  # type: Set[Link]
-        for link in links:
-            if link not in seen:
-                seen.add(link)
-                if link.egg_fragment:
-                    eggs.append(link)
-                else:
-                    no_eggs.append(link)
-        return no_eggs + eggs
-
-    def _log_skipped_link(self, link, reason):
-        # type: (Link, Text) -> None
-        if link not in self._logged_links:
-            # Mark this as a unicode string to prevent "UnicodeEncodeError:
-            # 'ascii' codec can't encode character" in Python 2 when
-            # the reason contains non-ascii characters.
-            #   Also, put the link at the end so the reason is more visible
-            # and because the link string is usually very long.
-            logger.debug(u'Skipping link: %s: %s', reason, link)
-            self._logged_links.add(link)
-
-    def get_install_candidate(self, link_evaluator, link):
-        # type: (LinkEvaluator, Link) -> Optional[InstallationCandidate]
-        """
-        If the link is a candidate for install, convert it to an
-        InstallationCandidate and return it. Otherwise, return None.
-        """
-        is_candidate, result = link_evaluator.evaluate_link(link)
-        if not is_candidate:
-            if result:
-                self._log_skipped_link(link, reason=result)
-            return None
-
-        return InstallationCandidate(
-            project=link_evaluator.project_name,
-            link=link,
-            # Convert the Text result to str since InstallationCandidate
-            # accepts str.
-            version=str(result),
-            requires_python=getattr(link, "requires_python", None)
-        )
-
-    def evaluate_links(self, link_evaluator, links):
-        # type: (LinkEvaluator, Iterable[Link]) -> List[InstallationCandidate]
-        """
-        Convert links that are candidates to InstallationCandidate objects.
-        """
-        candidates = []
-        for link in self._sort_links(links):
-            candidate = self.get_install_candidate(link_evaluator, link)
-            if candidate is not None:
-                candidates.append(candidate)
-
-        return candidates
-
-    def find_all_candidates(self, project_name):
-        # type: (str) -> List[InstallationCandidate]
-        """Find all available InstallationCandidate for project_name
-
-        This checks index_urls and find_links.
-        All versions found are returned as an InstallationCandidate list.
-
-        See LinkEvaluator.evaluate_link() for details on which files
-        are accepted.
-        """
-        collected_links = self._link_collector.collect_links(project_name)
-
-        link_evaluator = self.make_link_evaluator(project_name)
-
-        find_links_versions = self.evaluate_links(
-            link_evaluator,
-            links=collected_links.find_links,
-        )
-
-        page_versions = []
-        for page_url, page_links in collected_links.pages.items():
-            logger.debug('Analyzing links from page %s', page_url)
-            with indent_log():
-                new_versions = self.evaluate_links(
-                    link_evaluator,
-                    links=page_links,
-                )
-                page_versions.extend(new_versions)
-
-        file_versions = self.evaluate_links(
-            link_evaluator,
-            links=collected_links.files,
-        )
-        if file_versions:
-            file_versions.sort(reverse=True)
-            logger.debug(
-                'Local files found: %s',
-                ', '.join([
-                    url_to_path(candidate.link.url)
-                    for candidate in file_versions
-                ])
-            )
-
-        # This is an intentional priority ordering
-        return file_versions + find_links_versions + page_versions
-
-    def make_candidate_evaluator(
-        self,
-        project_name,    # type: str
-        specifier=None,  # type: Optional[specifiers.BaseSpecifier]
-        hashes=None,     # type: Optional[Hashes]
-    ):
-        # type: (...) -> CandidateEvaluator
-        """Create a CandidateEvaluator object to use.
-        """
-        candidate_prefs = self._candidate_prefs
-        return CandidateEvaluator.create(
-            project_name=project_name,
-            target_python=self._target_python,
-            prefer_binary=candidate_prefs.prefer_binary,
-            allow_all_prereleases=candidate_prefs.allow_all_prereleases,
-            specifier=specifier,
-            hashes=hashes,
-        )
-
-    def find_best_candidate(
-        self,
-        project_name,       # type: str
-        specifier=None,     # type: Optional[specifiers.BaseSpecifier]
-        hashes=None,        # type: Optional[Hashes]
-    ):
-        # type: (...) -> BestCandidateResult
-        """Find matches for the given project and specifier.
-
-        :param specifier: An optional object implementing `filter`
-            (e.g. `packaging.specifiers.SpecifierSet`) to filter applicable
-            versions.
-
-        :return: A `BestCandidateResult` instance.
-        """
-        candidates = self.find_all_candidates(project_name)
-        candidate_evaluator = self.make_candidate_evaluator(
-            project_name=project_name,
-            specifier=specifier,
-            hashes=hashes,
-        )
-        return candidate_evaluator.compute_best_candidate(candidates)
-
-    def find_requirement(self, req, upgrade):
-        # type: (InstallRequirement, bool) -> Optional[Link]
-        """Try to find a Link matching req
-
-        Expects req, an InstallRequirement and upgrade, a boolean
-        Returns a Link if found,
-        Raises DistributionNotFound or BestVersionAlreadyInstalled otherwise
-        """
-        hashes = req.hashes(trust_internet=False)
-        best_candidate_result = self.find_best_candidate(
-            req.name, specifier=req.specifier, hashes=hashes,
-        )
-        best_candidate = best_candidate_result.best_candidate
-
-        installed_version = None    # type: Optional[_BaseVersion]
-        if req.satisfied_by is not None:
-            installed_version = parse_version(req.satisfied_by.version)
-
-        def _format_versions(cand_iter):
-            # This repeated parse_version and str() conversion is needed to
-            # handle different vendoring sources from pipenv.patched.notpip and pkg_resources.
-            # If we stop using the pkg_resources provided specifier and start
-            # using our own, we can drop the cast to str().
-            return ", ".join(sorted(
-                {str(c.version) for c in cand_iter},
-                key=parse_version,
-            )) or "none"
-
-        if installed_version is None and best_candidate is None:
-            logger.critical(
-                'Could not find a version that satisfies the requirement %s '
-                '(from versions: %s)',
-                req,
-                _format_versions(best_candidate_result.iter_all()),
-            )
-
-            raise DistributionNotFound(
-                'No matching distribution found for %s' % req
-            )
-
-        best_installed = False
-        if installed_version and (
-                best_candidate is None or
-                best_candidate.version <= installed_version):
-            best_installed = True
-
-        if not upgrade and installed_version is not None:
-            if best_installed:
-                logger.debug(
-                    'Existing installed version (%s) is most up-to-date and '
-                    'satisfies requirement',
-                    installed_version,
-                )
-            else:
-                logger.debug(
-                    'Existing installed version (%s) satisfies requirement '
-                    '(most up-to-date version is %s)',
-                    installed_version,
-                    best_candidate.version,
-                )
-            return None
-
-        if best_installed:
-            # We have an existing version, and its the best version
-            logger.debug(
-                'Installed version (%s) is most up-to-date (past versions: '
-                '%s)',
-                installed_version,
-                _format_versions(best_candidate_result.iter_applicable()),
-            )
-            raise BestVersionAlreadyInstalled
-
-        logger.debug(
-            'Using version %s (newest of versions: %s)',
-            best_candidate.version,
-            _format_versions(best_candidate_result.iter_applicable()),
-        )
-        return best_candidate.link
-
-
-def _find_name_version_sep(fragment, canonical_name):
-    # type: (str, str) -> int
-    """Find the separator's index based on the package's canonical name.
-
-    :param fragment: A <package>+<version> filename "fragment" (stem) or
-        egg fragment.
-    :param canonical_name: The package's canonical name.
-
-    This function is needed since the canonicalized name does not necessarily
-    have the same length as the egg info's name part. An example::
-
-    >>> fragment = 'foo__bar-1.0'
-    >>> canonical_name = 'foo-bar'
-    >>> _find_name_version_sep(fragment, canonical_name)
-    8
-    """
-    # Project name and version must be separated by one single dash. Find all
-    # occurrences of dashes; if the string in front of it matches the canonical
-    # name, this is the one separating the name and version parts.
-    for i, c in enumerate(fragment):
-        if c != "-":
-            continue
-        if canonicalize_name(fragment[:i]) == canonical_name:
-            return i
-    raise ValueError("{} does not match {}".format(fragment, canonical_name))
-
-
-def _extract_version_from_fragment(fragment, canonical_name):
-    # type: (str, str) -> Optional[str]
-    """Parse the version string from a <package>+<version> filename
-    "fragment" (stem) or egg fragment.
-
-    :param fragment: The string to parse. E.g. foo-2.1
-    :param canonical_name: The canonicalized name of the package this
-        belongs to.
-    """
-    try:
-        version_start = _find_name_version_sep(fragment, canonical_name) + 1
-    except ValueError:
-        return None
-    version = fragment[version_start:]
-    if not version:
-        return None
-    return version
diff --git a/pipenv/patched/notpip/_internal/operations/generate_metadata.py b/pipenv/patched/notpip/_internal/operations/generate_metadata.py
deleted file mode 100644
index dd30f553..00000000
--- a/pipenv/patched/notpip/_internal/operations/generate_metadata.py
+++ /dev/null
@@ -1,136 +0,0 @@
-"""Metadata generation logic for source distributions.
-"""
-
-import logging
-import os
-
-from pipenv.patched.notpip._internal.exceptions import InstallationError
-from pipenv.patched.notpip._internal.utils.misc import ensure_dir
-from pipenv.patched.notpip._internal.utils.setuptools_build import make_setuptools_shim_args
-from pipenv.patched.notpip._internal.utils.subprocess import call_subprocess
-from pipenv.patched.notpip._internal.utils.typing import MYPY_CHECK_RUNNING
-from pipenv.patched.notpip._internal.vcs import vcs
-
-if MYPY_CHECK_RUNNING:
-    from typing import Callable, List
-    from pipenv.patched.notpip._internal.req.req_install import InstallRequirement
-
-logger = logging.getLogger(__name__)
-
-
-def get_metadata_generator(install_req):
-    # type: (InstallRequirement) -> Callable[[InstallRequirement], str]
-    """Return a callable metadata generator for this InstallRequirement.
-
-    A metadata generator takes an InstallRequirement (install_req) as an input,
-    generates metadata via the appropriate process for that install_req and
-    returns the generated metadata directory.
-    """
-    if not install_req.use_pep517:
-        return _generate_metadata_legacy
-
-    return _generate_metadata
-
-
-def _find_egg_info(source_directory, is_editable):
-    # type: (str, bool) -> str
-    """Find an .egg-info in `source_directory`, based on `is_editable`.
-    """
-
-    def looks_like_virtual_env(path):
-        # type: (str) -> bool
-        return (
-            os.path.lexists(os.path.join(path, 'bin', 'python')) or
-            os.path.exists(os.path.join(path, 'Scripts', 'Python.exe'))
-        )
-
-    def locate_editable_egg_info(base):
-        # type: (str) -> List[str]
-        candidates = []  # type: List[str]
-        for root, dirs, files in os.walk(base):
-            for dir_ in vcs.dirnames:
-                if dir_ in dirs:
-                    dirs.remove(dir_)
-            # Iterate over a copy of ``dirs``, since mutating
-            # a list while iterating over it can cause trouble.
-            # (See https://github.com/pypa/pip/pull/462.)
-            for dir_ in list(dirs):
-                if looks_like_virtual_env(os.path.join(root, dir_)):
-                    dirs.remove(dir_)
-                # Also don't search through tests
-                elif dir_ == 'test' or dir_ == 'tests':
-                    dirs.remove(dir_)
-            candidates.extend(os.path.join(root, dir_) for dir_ in dirs)
-        return [f for f in candidates if f.endswith('.egg-info')]
-
-    def depth_of_directory(dir_):
-        # type: (str) -> int
-        return (
-            dir_.count(os.path.sep) +
-            (os.path.altsep and dir_.count(os.path.altsep) or 0)
-        )
-
-    base = source_directory
-    if is_editable:
-        filenames = locate_editable_egg_info(base)
-    else:
-        base = os.path.join(base, 'pip-egg-info')
-        filenames = os.listdir(base)
-
-    if not filenames:
-        raise InstallationError(
-            "Files/directories not found in %s" % base
-        )
-
-    # If we have more than one match, we pick the toplevel one.  This
-    # can easily be the case if there is a dist folder which contains
-    # an extracted tarball for testing purposes.
-    if len(filenames) > 1:
-        filenames.sort(key=depth_of_directory)
-
-    return os.path.join(base, filenames[0])
-
-
-def _generate_metadata_legacy(install_req):
-    # type: (InstallRequirement) -> str
-    req_details_str = install_req.name or "from {}".format(install_req.link)
-    logger.debug(
-        'Running setup.py (path:%s) egg_info for package %s',
-        install_req.setup_py_path, req_details_str,
-    )
-
-    # Compose arguments for subprocess call
-    base_cmd = make_setuptools_shim_args(install_req.setup_py_path)
-    if install_req.isolated:
-        base_cmd += ["--no-user-cfg"]
-
-    # For non-editable installs, don't put the .egg-info files at the root,
-    # to avoid confusion due to the source code being considered an installed
-    # egg.
-    egg_base_option = []  # type: List[str]
-    if not install_req.editable:
-        egg_info_dir = os.path.join(
-            install_req.unpacked_source_directory, 'pip-egg-info',
-        )
-        egg_base_option = ['--egg-base', egg_info_dir]
-
-        # setuptools complains if the target directory does not exist.
-        ensure_dir(egg_info_dir)
-
-    with install_req.build_env:
-        call_subprocess(
-            base_cmd + ["egg_info"] + egg_base_option,
-            cwd=install_req.unpacked_source_directory,
-            command_desc='python setup.py egg_info',
-        )
-
-    # Return the .egg-info directory.
-    return _find_egg_info(
-        install_req.unpacked_source_directory,
-        install_req.editable,
-    )
-
-
-def _generate_metadata(install_req):
-    # type: (InstallRequirement) -> str
-    return install_req.prepare_pep517_metadata()
diff --git a/pipenv/patched/notpip/_internal/wheel.py b/pipenv/patched/notpip/_internal/wheel.py
deleted file mode 100644
index d4c155b4..00000000
--- a/pipenv/patched/notpip/_internal/wheel.py
+++ /dev/null
@@ -1,1181 +0,0 @@
-"""
-Support for installing and building the "wheel" binary package format.
-"""
-
-# The following comment should be removed at some point in the future.
-# mypy: strict-optional=False
-# mypy: disallow-untyped-defs=False
-
-from __future__ import absolute_import
-
-import collections
-import compileall
-import csv
-import hashlib
-import logging
-import os.path
-import re
-import shutil
-import stat
-import sys
-import warnings
-from base64 import urlsafe_b64encode
-from email.parser import Parser
-
-from pipenv.patched.notpip._vendor import pkg_resources
-from pipenv.patched.notpip._vendor.distlib.scripts import ScriptMaker
-from pipenv.patched.notpip._vendor.distlib.util import get_export_entry
-from pipenv.patched.notpip._vendor.packaging.utils import canonicalize_name
-from pipenv.patched.notpip._vendor.six import StringIO
-
-from pipenv.patched.notpip._internal import pep425tags
-from pipenv.patched.notpip._internal.exceptions import (
-    InstallationError,
-    InvalidWheelFilename,
-    UnsupportedWheel,
-)
-from pipenv.patched.notpip._internal.locations import distutils_scheme, get_major_minor_version
-from pipenv.patched.notpip._internal.models.link import Link
-from pipenv.patched.notpip._internal.utils.logging import indent_log
-from pipenv.patched.notpip._internal.utils.marker_files import has_delete_marker_file
-from pipenv.patched.notpip._internal.utils.misc import captured_stdout, ensure_dir, read_chunks
-from pipenv.patched.notpip._internal.utils.setuptools_build import make_setuptools_shim_args
-from pipenv.patched.notpip._internal.utils.subprocess import (
-    LOG_DIVIDER,
-    call_subprocess,
-    format_command_args,
-    runner_with_spinner_message,
-)
-from pipenv.patched.notpip._internal.utils.temp_dir import TempDirectory
-from pipenv.patched.notpip._internal.utils.typing import MYPY_CHECK_RUNNING
-from pipenv.patched.notpip._internal.utils.ui import open_spinner
-from pipenv.patched.notpip._internal.utils.unpacking import unpack_file
-from pipenv.patched.notpip._internal.utils.urls import path_to_url
-
-if MYPY_CHECK_RUNNING:
-    from typing import (
-        Dict, List, Optional, Sequence, Mapping, Tuple, IO, Text, Any,
-        Iterable, Callable, Set,
-    )
-    from pipenv.patched.notpip._vendor.packaging.requirements import Requirement
-    from pipenv.patched.notpip._internal.req.req_install import InstallRequirement
-    from pipenv.patched.notpip._internal.operations.prepare import (
-        RequirementPreparer
-    )
-    from pipenv.patched.notpip._internal.cache import WheelCache
-    from pipenv.patched.notpip._internal.pep425tags import Pep425Tag
-
-    InstalledCSVRow = Tuple[str, ...]
-
-    BinaryAllowedPredicate = Callable[[InstallRequirement], bool]
-
-
-VERSION_COMPATIBLE = (1, 0)
-
-
-logger = logging.getLogger(__name__)
-
-
-def normpath(src, p):
-    return os.path.relpath(src, p).replace(os.path.sep, '/')
-
-
-def hash_file(path, blocksize=1 << 20):
-    # type: (str, int) -> Tuple[Any, int]
-    """Return (hash, length) for path using hashlib.sha256()"""
-    h = hashlib.sha256()
-    length = 0
-    with open(path, 'rb') as f:
-        for block in read_chunks(f, size=blocksize):
-            length += len(block)
-            h.update(block)
-    return (h, length)  # type: ignore
-
-
-def rehash(path, blocksize=1 << 20):
-    # type: (str, int) -> Tuple[str, str]
-    """Return (encoded_digest, length) for path using hashlib.sha256()"""
-    h, length = hash_file(path, blocksize)
-    digest = 'sha256=' + urlsafe_b64encode(
-        h.digest()
-    ).decode('latin1').rstrip('=')
-    # unicode/str python2 issues
-    return (digest, str(length))  # type: ignore
-
-
-def open_for_csv(name, mode):
-    # type: (str, Text) -> IO
-    if sys.version_info[0] < 3:
-        nl = {}  # type: Dict[str, Any]
-        bin = 'b'
-    else:
-        nl = {'newline': ''}  # type: Dict[str, Any]
-        bin = ''
-    return open(name, mode + bin, **nl)
-
-
-def replace_python_tag(wheelname, new_tag):
-    # type: (str, str) -> str
-    """Replace the Python tag in a wheel file name with a new value.
-    """
-    parts = wheelname.split('-')
-    parts[-3] = new_tag
-    return '-'.join(parts)
-
-
-def fix_script(path):
-    # type: (str) -> Optional[bool]
-    """Replace #!python with #!/path/to/python
-    Return True if file was changed."""
-    # XXX RECORD hashes will need to be updated
-    if os.path.isfile(path):
-        with open(path, 'rb') as script:
-            firstline = script.readline()
-            if not firstline.startswith(b'#!python'):
-                return False
-            exename = sys.executable.encode(sys.getfilesystemencoding())
-            firstline = b'#!' + exename + os.linesep.encode("ascii")
-            rest = script.read()
-        with open(path, 'wb') as script:
-            script.write(firstline)
-            script.write(rest)
-        return True
-    return None
-
-
-dist_info_re = re.compile(r"""^(?P<namever>(?P<name>.+?)(-(?P<ver>.+?))?)
-                                \.dist-info$""", re.VERBOSE)
-
-
-def root_is_purelib(name, wheeldir):
-    # type: (str, str) -> bool
-    """
-    Return True if the extracted wheel in wheeldir should go into purelib.
-    """
-    name_folded = name.replace("-", "_")
-    for item in os.listdir(wheeldir):
-        match = dist_info_re.match(item)
-        if match and match.group('name') == name_folded:
-            with open(os.path.join(wheeldir, item, 'WHEEL')) as wheel:
-                for line in wheel:
-                    line = line.lower().rstrip()
-                    if line == "root-is-purelib: true":
-                        return True
-    return False
-
-
-def get_entrypoints(filename):
-    # type: (str) -> Tuple[Dict[str, str], Dict[str, str]]
-    if not os.path.exists(filename):
-        return {}, {}
-
-    # This is done because you can pass a string to entry_points wrappers which
-    # means that they may or may not be valid INI files. The attempt here is to
-    # strip leading and trailing whitespace in order to make them valid INI
-    # files.
-    with open(filename) as fp:
-        data = StringIO()
-        for line in fp:
-            data.write(line.strip())
-            data.write("\n")
-        data.seek(0)
-
-    # get the entry points and then the script names
-    entry_points = pkg_resources.EntryPoint.parse_map(data)
-    console = entry_points.get('console_scripts', {})
-    gui = entry_points.get('gui_scripts', {})
-
-    def _split_ep(s):
-        """get the string representation of EntryPoint, remove space and split
-        on '='"""
-        return str(s).replace(" ", "").split("=")
-
-    # convert the EntryPoint objects into strings with module:function
-    console = dict(_split_ep(v) for v in console.values())
-    gui = dict(_split_ep(v) for v in gui.values())
-    return console, gui
-
-
-def message_about_scripts_not_on_PATH(scripts):
-    # type: (Sequence[str]) -> Optional[str]
-    """Determine if any scripts are not on PATH and format a warning.
-
-    Returns a warning message if one or more scripts are not on PATH,
-    otherwise None.
-    """
-    if not scripts:
-        return None
-
-    # Group scripts by the path they were installed in
-    grouped_by_dir = collections.defaultdict(set)  # type: Dict[str, Set[str]]
-    for destfile in scripts:
-        parent_dir = os.path.dirname(destfile)
-        script_name = os.path.basename(destfile)
-        grouped_by_dir[parent_dir].add(script_name)
-
-    # We don't want to warn for directories that are on PATH.
-    not_warn_dirs = [
-        os.path.normcase(i).rstrip(os.sep) for i in
-        os.environ.get("PATH", "").split(os.pathsep)
-    ]
-    # If an executable sits with sys.executable, we don't warn for it.
-    #     This covers the case of venv invocations without activating the venv.
-    not_warn_dirs.append(os.path.normcase(os.path.dirname(sys.executable)))
-    warn_for = {
-        parent_dir: scripts for parent_dir, scripts in grouped_by_dir.items()
-        if os.path.normcase(parent_dir) not in not_warn_dirs
-    }  # type: Dict[str, Set[str]]
-    if not warn_for:
-        return None
-
-    # Format a message
-    msg_lines = []
-    for parent_dir, dir_scripts in warn_for.items():
-        sorted_scripts = sorted(dir_scripts)  # type: List[str]
-        if len(sorted_scripts) == 1:
-            start_text = "script {} is".format(sorted_scripts[0])
-        else:
-            start_text = "scripts {} are".format(
-                ", ".join(sorted_scripts[:-1]) + " and " + sorted_scripts[-1]
-            )
-
-        msg_lines.append(
-            "The {} installed in '{}' which is not on PATH."
-            .format(start_text, parent_dir)
-        )
-
-    last_line_fmt = (
-        "Consider adding {} to PATH or, if you prefer "
-        "to suppress this warning, use --no-warn-script-location."
-    )
-    if len(msg_lines) == 1:
-        msg_lines.append(last_line_fmt.format("this directory"))
-    else:
-        msg_lines.append(last_line_fmt.format("these directories"))
-
-    # Returns the formatted multiline message
-    return "\n".join(msg_lines)
-
-
-def sorted_outrows(outrows):
-    # type: (Iterable[InstalledCSVRow]) -> List[InstalledCSVRow]
-    """
-    Return the given rows of a RECORD file in sorted order.
-
-    Each row is a 3-tuple (path, hash, size) and corresponds to a record of
-    a RECORD file (see PEP 376 and PEP 427 for details).  For the rows
-    passed to this function, the size can be an integer as an int or string,
-    or the empty string.
-    """
-    # Normally, there should only be one row per path, in which case the
-    # second and third elements don't come into play when sorting.
-    # However, in cases in the wild where a path might happen to occur twice,
-    # we don't want the sort operation to trigger an error (but still want
-    # determinism).  Since the third element can be an int or string, we
-    # coerce each element to a string to avoid a TypeError in this case.
-    # For additional background, see--
-    # https://github.com/pypa/pip/issues/5868
-    return sorted(outrows, key=lambda row: tuple(str(x) for x in row))
-
-
-def get_csv_rows_for_installed(
-    old_csv_rows,  # type: Iterable[List[str]]
-    installed,  # type: Dict[str, str]
-    changed,  # type: set
-    generated,  # type: List[str]
-    lib_dir,  # type: str
-):
-    # type: (...) -> List[InstalledCSVRow]
-    """
-    :param installed: A map from archive RECORD path to installation RECORD
-        path.
-    """
-    installed_rows = []  # type: List[InstalledCSVRow]
-    for row in old_csv_rows:
-        if len(row) > 3:
-            logger.warning(
-                'RECORD line has more than three elements: {}'.format(row)
-            )
-        # Make a copy because we are mutating the row.
-        row = list(row)
-        old_path = row[0]
-        new_path = installed.pop(old_path, old_path)
-        row[0] = new_path
-        if new_path in changed:
-            digest, length = rehash(new_path)
-            row[1] = digest
-            row[2] = length
-        installed_rows.append(tuple(row))
-    for f in generated:
-        digest, length = rehash(f)
-        installed_rows.append((normpath(f, lib_dir), digest, str(length)))
-    for f in installed:
-        installed_rows.append((installed[f], '', ''))
-    return installed_rows
-
-
-class MissingCallableSuffix(Exception):
-    pass
-
-
-def _raise_for_invalid_entrypoint(specification):
-    entry = get_export_entry(specification)
-    if entry is not None and entry.suffix is None:
-        raise MissingCallableSuffix(str(entry))
-
-
-class PipScriptMaker(ScriptMaker):
-    def make(self, specification, options=None):
-        _raise_for_invalid_entrypoint(specification)
-        return super(PipScriptMaker, self).make(specification, options)
-
-
-def move_wheel_files(
-    name,  # type: str
-    req,  # type: Requirement
-    wheeldir,  # type: str
-    user=False,  # type: bool
-    home=None,  # type: Optional[str]
-    root=None,  # type: Optional[str]
-    pycompile=True,  # type: bool
-    scheme=None,  # type: Optional[Mapping[str, str]]
-    isolated=False,  # type: bool
-    prefix=None,  # type: Optional[str]
-    warn_script_location=True  # type: bool
-):
-    # type: (...) -> None
-    """Install a wheel"""
-    # TODO: Investigate and break this up.
-    # TODO: Look into moving this into a dedicated class for representing an
-    #       installation.
-
-    if not scheme:
-        scheme = distutils_scheme(
-            name, user=user, home=home, root=root, isolated=isolated,
-            prefix=prefix,
-        )
-
-    if root_is_purelib(name, wheeldir):
-        lib_dir = scheme['purelib']
-    else:
-        lib_dir = scheme['platlib']
-
-    info_dir = []  # type: List[str]
-    data_dirs = []
-    source = wheeldir.rstrip(os.path.sep) + os.path.sep
-
-    # Record details of the files moved
-    #   installed = files copied from the wheel to the destination
-    #   changed = files changed while installing (scripts #! line typically)
-    #   generated = files newly generated during the install (script wrappers)
-    installed = {}  # type: Dict[str, str]
-    changed = set()
-    generated = []  # type: List[str]
-
-    # Compile all of the pyc files that we're going to be installing
-    if pycompile:
-        with captured_stdout() as stdout:
-            with warnings.catch_warnings():
-                warnings.filterwarnings('ignore')
-                compileall.compile_dir(source, force=True, quiet=True)
-        logger.debug(stdout.getvalue())
-
-    def record_installed(srcfile, destfile, modified=False):
-        """Map archive RECORD paths to installation RECORD paths."""
-        oldpath = normpath(srcfile, wheeldir)
-        newpath = normpath(destfile, lib_dir)
-        installed[oldpath] = newpath
-        if modified:
-            changed.add(destfile)
-
-    def clobber(source, dest, is_base, fixer=None, filter=None):
-        ensure_dir(dest)  # common for the 'include' path
-
-        for dir, subdirs, files in os.walk(source):
-            basedir = dir[len(source):].lstrip(os.path.sep)
-            destdir = os.path.join(dest, basedir)
-            if is_base and basedir.split(os.path.sep, 1)[0].endswith('.data'):
-                continue
-            for s in subdirs:
-                destsubdir = os.path.join(dest, basedir, s)
-                if is_base and basedir == '' and destsubdir.endswith('.data'):
-                    data_dirs.append(s)
-                    continue
-                elif (is_base and
-                        s.endswith('.dist-info') and
-                        canonicalize_name(s).startswith(
-                            canonicalize_name(req.name))):
-                    assert not info_dir, ('Multiple .dist-info directories: ' +
-                                          destsubdir + ', ' +
-                                          ', '.join(info_dir))
-                    info_dir.append(destsubdir)
-            for f in files:
-                # Skip unwanted files
-                if filter and filter(f):
-                    continue
-                srcfile = os.path.join(dir, f)
-                destfile = os.path.join(dest, basedir, f)
-                # directory creation is lazy and after the file filtering above
-                # to ensure we don't install empty dirs; empty dirs can't be
-                # uninstalled.
-                ensure_dir(destdir)
-
-                # copyfile (called below) truncates the destination if it
-                # exists and then writes the new contents. This is fine in most
-                # cases, but can cause a segfault if pip has loaded a shared
-                # object (e.g. from pyopenssl through its vendored urllib3)
-                # Since the shared object is mmap'd an attempt to call a
-                # symbol in it will then cause a segfault. Unlinking the file
-                # allows writing of new contents while allowing the process to
-                # continue to use the old copy.
-                if os.path.exists(destfile):
-                    os.unlink(destfile)
-
-                # We use copyfile (not move, copy, or copy2) to be extra sure
-                # that we are not moving directories over (copyfile fails for
-                # directories) as well as to ensure that we are not copying
-                # over any metadata because we want more control over what
-                # metadata we actually copy over.
-                shutil.copyfile(srcfile, destfile)
-
-                # Copy over the metadata for the file, currently this only
-                # includes the atime and mtime.
-                st = os.stat(srcfile)
-                if hasattr(os, "utime"):
-                    os.utime(destfile, (st.st_atime, st.st_mtime))
-
-                # If our file is executable, then make our destination file
-                # executable.
-                if os.access(srcfile, os.X_OK):
-                    st = os.stat(srcfile)
-                    permissions = (
-                        st.st_mode | stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH
-                    )
-                    os.chmod(destfile, permissions)
-
-                changed = False
-                if fixer:
-                    changed = fixer(destfile)
-                record_installed(srcfile, destfile, changed)
-
-    clobber(source, lib_dir, True)
-
-    assert info_dir, "%s .dist-info directory not found" % req
-
-    # Get the defined entry points
-    ep_file = os.path.join(info_dir[0], 'entry_points.txt')
-    console, gui = get_entrypoints(ep_file)
-
-    def is_entrypoint_wrapper(name):
-        # EP, EP.exe and EP-script.py are scripts generated for
-        # entry point EP by setuptools
-        if name.lower().endswith('.exe'):
-            matchname = name[:-4]
-        elif name.lower().endswith('-script.py'):
-            matchname = name[:-10]
-        elif name.lower().endswith(".pya"):
-            matchname = name[:-4]
-        else:
-            matchname = name
-        # Ignore setuptools-generated scripts
-        return (matchname in console or matchname in gui)
-
-    for datadir in data_dirs:
-        fixer = None
-        filter = None
-        for subdir in os.listdir(os.path.join(wheeldir, datadir)):
-            fixer = None
-            if subdir == 'scripts':
-                fixer = fix_script
-                filter = is_entrypoint_wrapper
-            source = os.path.join(wheeldir, datadir, subdir)
-            dest = scheme[subdir]
-            clobber(source, dest, False, fixer=fixer, filter=filter)
-
-    maker = PipScriptMaker(None, scheme['scripts'])
-
-    # Ensure old scripts are overwritten.
-    # See https://github.com/pypa/pip/issues/1800
-    maker.clobber = True
-
-    # Ensure we don't generate any variants for scripts because this is almost
-    # never what somebody wants.
-    # See https://bitbucket.org/pypa/distlib/issue/35/
-    maker.variants = {''}
-
-    # This is required because otherwise distlib creates scripts that are not
-    # executable.
-    # See https://bitbucket.org/pypa/distlib/issue/32/
-    maker.set_mode = True
-
-    scripts_to_generate = []
-
-    # Special case pip and setuptools to generate versioned wrappers
-    #
-    # The issue is that some projects (specifically, pip and setuptools) use
-    # code in setup.py to create "versioned" entry points - pip2.7 on Python
-    # 2.7, pip3.3 on Python 3.3, etc. But these entry points are baked into
-    # the wheel metadata at build time, and so if the wheel is installed with
-    # a *different* version of Python the entry points will be wrong. The
-    # correct fix for this is to enhance the metadata to be able to describe
-    # such versioned entry points, but that won't happen till Metadata 2.0 is
-    # available.
-    # In the meantime, projects using versioned entry points will either have
-    # incorrect versioned entry points, or they will not be able to distribute
-    # "universal" wheels (i.e., they will need a wheel per Python version).
-    #
-    # Because setuptools and pip are bundled with _ensurepip and virtualenv,
-    # we need to use universal wheels. So, as a stopgap until Metadata 2.0, we
-    # override the versioned entry points in the wheel and generate the
-    # correct ones. This code is purely a short-term measure until Metadata 2.0
-    # is available.
-    #
-    # To add the level of hack in this section of code, in order to support
-    # ensurepip this code will look for an ``ENSUREPIP_OPTIONS`` environment
-    # variable which will control which version scripts get installed.
-    #
-    # ENSUREPIP_OPTIONS=altinstall
-    #   - Only pipX.Y and easy_install-X.Y will be generated and installed
-    # ENSUREPIP_OPTIONS=install
-    #   - pipX.Y, pipX, easy_install-X.Y will be generated and installed. Note
-    #     that this option is technically if ENSUREPIP_OPTIONS is set and is
-    #     not altinstall
-    # DEFAULT
-    #   - The default behavior is to install pip, pipX, pipX.Y, easy_install
-    #     and easy_install-X.Y.
-    pip_script = console.pop('pip', None)
-    if pip_script:
-        if "ENSUREPIP_OPTIONS" not in os.environ:
-            scripts_to_generate.append('pip = ' + pip_script)
-
-        if os.environ.get("ENSUREPIP_OPTIONS", "") != "altinstall":
-            scripts_to_generate.append(
-                'pip%s = %s' % (sys.version_info[0], pip_script)
-            )
-
-        scripts_to_generate.append(
-            'pip%s = %s' % (get_major_minor_version(), pip_script)
-        )
-        # Delete any other versioned pip entry points
-        pip_ep = [k for k in console if re.match(r'pip(\d(\.\d)?)?$', k)]
-        for k in pip_ep:
-            del console[k]
-    easy_install_script = console.pop('easy_install', None)
-    if easy_install_script:
-        if "ENSUREPIP_OPTIONS" not in os.environ:
-            scripts_to_generate.append(
-                'easy_install = ' + easy_install_script
-            )
-
-        scripts_to_generate.append(
-            'easy_install-%s = %s' % (
-                get_major_minor_version(), easy_install_script
-            )
-        )
-        # Delete any other versioned easy_install entry points
-        easy_install_ep = [
-            k for k in console if re.match(r'easy_install(-\d\.\d)?$', k)
-        ]
-        for k in easy_install_ep:
-            del console[k]
-
-    # Generate the console and GUI entry points specified in the wheel
-    scripts_to_generate.extend(
-        '%s = %s' % kv for kv in console.items()
-    )
-
-    gui_scripts_to_generate = [
-        '%s = %s' % kv for kv in gui.items()
-    ]
-
-    generated_console_scripts = []  # type: List[str]
-
-    try:
-        generated_console_scripts = maker.make_multiple(scripts_to_generate)
-        generated.extend(generated_console_scripts)
-
-        generated.extend(
-            maker.make_multiple(gui_scripts_to_generate, {'gui': True})
-        )
-    except MissingCallableSuffix as e:
-        entry = e.args[0]
-        raise InstallationError(
-            "Invalid script entry point: {} for req: {} - A callable "
-            "suffix is required. Cf https://packaging.python.org/en/"
-            "latest/distributing.html#console-scripts for more "
-            "information.".format(entry, req)
-        )
-
-    if warn_script_location:
-        msg = message_about_scripts_not_on_PATH(generated_console_scripts)
-        if msg is not None:
-            logger.warning(msg)
-
-    # Record pip as the installer
-    installer = os.path.join(info_dir[0], 'INSTALLER')
-    temp_installer = os.path.join(info_dir[0], 'INSTALLER.pip')
-    with open(temp_installer, 'wb') as installer_file:
-        installer_file.write(b'pip\n')
-    shutil.move(temp_installer, installer)
-    generated.append(installer)
-
-    # Record details of all files installed
-    record = os.path.join(info_dir[0], 'RECORD')
-    temp_record = os.path.join(info_dir[0], 'RECORD.pip')
-    with open_for_csv(record, 'r') as record_in:
-        with open_for_csv(temp_record, 'w+') as record_out:
-            reader = csv.reader(record_in)
-            outrows = get_csv_rows_for_installed(
-                reader, installed=installed, changed=changed,
-                generated=generated, lib_dir=lib_dir,
-            )
-            writer = csv.writer(record_out)
-            # Sort to simplify testing.
-            for row in sorted_outrows(outrows):
-                writer.writerow(row)
-    shutil.move(temp_record, record)
-
-
-def wheel_version(source_dir):
-    # type: (Optional[str]) -> Optional[Tuple[int, ...]]
-    """
-    Return the Wheel-Version of an extracted wheel, if possible.
-
-    Otherwise, return None if we couldn't parse / extract it.
-    """
-    try:
-        dist = [d for d in pkg_resources.find_on_path(None, source_dir)][0]
-
-        wheel_data = dist.get_metadata('WHEEL')
-        wheel_data = Parser().parsestr(wheel_data)
-
-        version = wheel_data['Wheel-Version'].strip()
-        version = tuple(map(int, version.split('.')))
-        return version
-    except Exception:
-        return None
-
-
-def check_compatibility(version, name):
-    # type: (Optional[Tuple[int, ...]], str) -> None
-    """
-    Raises errors or warns if called with an incompatible Wheel-Version.
-
-    Pip should refuse to install a Wheel-Version that's a major series
-    ahead of what it's compatible with (e.g 2.0 > 1.1); and warn when
-    installing a version only minor version ahead (e.g 1.2 > 1.1).
-
-    version: a 2-tuple representing a Wheel-Version (Major, Minor)
-    name: name of wheel or package to raise exception about
-
-    :raises UnsupportedWheel: when an incompatible Wheel-Version is given
-    """
-    if not version:
-        raise UnsupportedWheel(
-            "%s is in an unsupported or invalid wheel" % name
-        )
-    if version[0] > VERSION_COMPATIBLE[0]:
-        raise UnsupportedWheel(
-            "%s's Wheel-Version (%s) is not compatible with this version "
-            "of pip" % (name, '.'.join(map(str, version)))
-        )
-    elif version > VERSION_COMPATIBLE:
-        logger.warning(
-            'Installing from a newer Wheel-Version (%s)',
-            '.'.join(map(str, version)),
-        )
-
-
-def format_tag(file_tag):
-    # type: (Tuple[str, ...]) -> str
-    """
-    Format three tags in the form "<python_tag>-<abi_tag>-<platform_tag>".
-
-    :param file_tag: A 3-tuple of tags (python_tag, abi_tag, platform_tag).
-    """
-    return '-'.join(file_tag)
-
-
-class Wheel(object):
-    """A wheel file"""
-
-    # TODO: Maybe move the class into the models sub-package
-    # TODO: Maybe move the install code into this class
-
-    wheel_file_re = re.compile(
-        r"""^(?P<namever>(?P<name>.+?)-(?P<ver>.*?))
-        ((-(?P<build>\d[^-]*?))?-(?P<pyver>.+?)-(?P<abi>.+?)-(?P<plat>.+?)
-        \.whl|\.dist-info)$""",
-        re.VERBOSE
-    )
-
-    def __init__(self, filename):
-        # type: (str) -> None
-        """
-        :raises InvalidWheelFilename: when the filename is invalid for a wheel
-        """
-        wheel_info = self.wheel_file_re.match(filename)
-        if not wheel_info:
-            raise InvalidWheelFilename(
-                "%s is not a valid wheel filename." % filename
-            )
-        self.filename = filename
-        self.name = wheel_info.group('name').replace('_', '-')
-        # we'll assume "_" means "-" due to wheel naming scheme
-        # (https://github.com/pypa/pip/issues/1150)
-        self.version = wheel_info.group('ver').replace('_', '-')
-        self.build_tag = wheel_info.group('build')
-        self.pyversions = wheel_info.group('pyver').split('.')
-        self.abis = wheel_info.group('abi').split('.')
-        self.plats = wheel_info.group('plat').split('.')
-
-        # All the tag combinations from this file
-        self.file_tags = {
-            (x, y, z) for x in self.pyversions
-            for y in self.abis for z in self.plats
-        }
-
-    def get_formatted_file_tags(self):
-        # type: () -> List[str]
-        """
-        Return the wheel's tags as a sorted list of strings.
-        """
-        return sorted(format_tag(tag) for tag in self.file_tags)
-
-    def support_index_min(self, tags):
-        # type: (List[Pep425Tag]) -> int
-        """
-        Return the lowest index that one of the wheel's file_tag combinations
-        achieves in the given list of supported tags.
-
-        For example, if there are 8 supported tags and one of the file tags
-        is first in the list, then return 0.
-
-        :param tags: the PEP 425 tags to check the wheel against, in order
-            with most preferred first.
-
-        :raises ValueError: If none of the wheel's file tags match one of
-            the supported tags.
-        """
-        return min(tags.index(tag) for tag in self.file_tags if tag in tags)
-
-    def supported(self, tags):
-        # type: (List[Pep425Tag]) -> bool
-        """
-        Return whether the wheel is compatible with one of the given tags.
-
-        :param tags: the PEP 425 tags to check the wheel against.
-        """
-        return not self.file_tags.isdisjoint(tags)
-
-
-def _contains_egg_info(
-        s, _egg_info_re=re.compile(r'([a-z0-9_.]+)-([a-z0-9_.!+-]+)', re.I)):
-    """Determine whether the string looks like an egg_info.
-
-    :param s: The string to parse. E.g. foo-2.1
-    """
-    return bool(_egg_info_re.search(s))
-
-
-def should_use_ephemeral_cache(
-    req,  # type: InstallRequirement
-    should_unpack,  # type: bool
-    cache_available,  # type: bool
-    check_binary_allowed,  # type: BinaryAllowedPredicate
-):
-    # type: (...) -> Optional[bool]
-    """
-    Return whether to build an InstallRequirement object using the
-    ephemeral cache.
-
-    :param cache_available: whether a cache directory is available for the
-        should_unpack=True case.
-
-    :return: True or False to build the requirement with ephem_cache=True
-        or False, respectively; or None not to build the requirement.
-    """
-    if req.constraint:
-        # never build requirements that are merely constraints
-        return None
-    if req.is_wheel:
-        if not should_unpack:
-            logger.info(
-                'Skipping %s, due to already being wheel.', req.name,
-            )
-        return None
-    if not should_unpack:
-        # i.e. pip wheel, not pip install;
-        # return False, knowing that the caller will never cache
-        # in this case anyway, so this return merely means "build it".
-        # TODO improve this behavior
-        return False
-
-    if req.editable or not req.source_dir:
-        return None
-
-    if not check_binary_allowed(req):
-        logger.info(
-            "Skipping wheel build for %s, due to binaries "
-            "being disabled for it.", req.name,
-        )
-        return None
-
-    if req.link and req.link.is_vcs:
-        # VCS checkout. Build wheel just for this run.
-        return True
-
-    link = req.link
-    base, ext = link.splitext()
-    if cache_available and _contains_egg_info(base):
-        return False
-
-    # Otherwise, build the wheel just for this run using the ephemeral
-    # cache since we are either in the case of e.g. a local directory, or
-    # no cache directory is available to use.
-    return True
-
-
-def format_command_result(
-    command_args,  # type: List[str]
-    command_output,  # type: str
-):
-    # type: (...) -> str
-    """
-    Format command information for logging.
-    """
-    command_desc = format_command_args(command_args)
-    text = 'Command arguments: {}\n'.format(command_desc)
-
-    if not command_output:
-        text += 'Command output: None'
-    elif logger.getEffectiveLevel() > logging.DEBUG:
-        text += 'Command output: [use --verbose to show]'
-    else:
-        if not command_output.endswith('\n'):
-            command_output += '\n'
-        text += 'Command output:\n{}{}'.format(command_output, LOG_DIVIDER)
-
-    return text
-
-
-def get_legacy_build_wheel_path(
-    names,  # type: List[str]
-    temp_dir,  # type: str
-    req,  # type: InstallRequirement
-    command_args,  # type: List[str]
-    command_output,  # type: str
-):
-    # type: (...) -> Optional[str]
-    """
-    Return the path to the wheel in the temporary build directory.
-    """
-    # Sort for determinism.
-    names = sorted(names)
-    if not names:
-        msg = (
-            'Legacy build of wheel for {!r} created no files.\n'
-        ).format(req.name)
-        msg += format_command_result(command_args, command_output)
-        logger.warning(msg)
-        return None
-
-    if len(names) > 1:
-        msg = (
-            'Legacy build of wheel for {!r} created more than one file.\n'
-            'Filenames (choosing first): {}\n'
-        ).format(req.name, names)
-        msg += format_command_result(command_args, command_output)
-        logger.warning(msg)
-
-    return os.path.join(temp_dir, names[0])
-
-
-def _always_true(_):
-    return True
-
-
-class WheelBuilder(object):
-    """Build wheels from a RequirementSet."""
-
-    def __init__(
-        self,
-        preparer,  # type: RequirementPreparer
-        wheel_cache,  # type: WheelCache
-        build_options=None,  # type: Optional[List[str]]
-        global_options=None,  # type: Optional[List[str]]
-        check_binary_allowed=None,  # type: Optional[BinaryAllowedPredicate]
-        no_clean=False  # type: bool
-    ):
-        # type: (...) -> None
-        if check_binary_allowed is None:
-            # Binaries allowed by default.
-            check_binary_allowed = _always_true
-
-        self.preparer = preparer
-        self.wheel_cache = wheel_cache
-
-        self._wheel_dir = preparer.wheel_download_dir
-
-        self.build_options = build_options or []
-        self.global_options = global_options or []
-        self.check_binary_allowed = check_binary_allowed
-        self.no_clean = no_clean
-
-    def _build_one(self, req, output_dir, python_tag=None):
-        """Build one wheel.
-
-        :return: The filename of the built wheel, or None if the build failed.
-        """
-        # Install build deps into temporary directory (PEP 518)
-        with req.build_env:
-            return self._build_one_inside_env(req, output_dir,
-                                              python_tag=python_tag)
-
-    def _build_one_inside_env(self, req, output_dir, python_tag=None):
-        with TempDirectory(kind="wheel") as temp_dir:
-            if req.use_pep517:
-                builder = self._build_one_pep517
-            else:
-                builder = self._build_one_legacy
-            wheel_path = builder(req, temp_dir.path, python_tag=python_tag)
-            if wheel_path is not None:
-                wheel_name = os.path.basename(wheel_path)
-                dest_path = os.path.join(output_dir, wheel_name)
-                try:
-                    wheel_hash, length = hash_file(wheel_path)
-                    shutil.move(wheel_path, dest_path)
-                    logger.info('Created wheel for %s: '
-                                'filename=%s size=%d sha256=%s',
-                                req.name, wheel_name, length,
-                                wheel_hash.hexdigest())
-                    logger.info('Stored in directory: %s', output_dir)
-                    return dest_path
-                except Exception:
-                    pass
-            # Ignore return, we can't do anything else useful.
-            self._clean_one(req)
-            return None
-
-    def _base_setup_args(self, req):
-        # NOTE: Eventually, we'd want to also -S to the flags here, when we're
-        # isolating. Currently, it breaks Python in virtualenvs, because it
-        # relies on site.py to find parts of the standard library outside the
-        # virtualenv.
-        return make_setuptools_shim_args(
-            req.setup_py_path,
-            global_options=self.global_options,
-            unbuffered_output=True
-        )
-
-    def _build_one_pep517(self, req, tempd, python_tag=None):
-        """Build one InstallRequirement using the PEP 517 build process.
-
-        Returns path to wheel if successfully built. Otherwise, returns None.
-        """
-        assert req.metadata_directory is not None
-        if self.build_options:
-            # PEP 517 does not support --build-options
-            logger.error('Cannot build wheel for %s using PEP 517 when '
-                         '--build-options is present' % (req.name,))
-            return None
-        try:
-            logger.debug('Destination directory: %s', tempd)
-
-            runner = runner_with_spinner_message(
-                'Building wheel for {} (PEP 517)'.format(req.name)
-            )
-            backend = req.pep517_backend
-            with backend.subprocess_runner(runner):
-                wheel_name = backend.build_wheel(
-                    tempd,
-                    metadata_directory=req.metadata_directory,
-                )
-            if python_tag:
-                # General PEP 517 backends don't necessarily support
-                # a "--python-tag" option, so we rename the wheel
-                # file directly.
-                new_name = replace_python_tag(wheel_name, python_tag)
-                os.rename(
-                    os.path.join(tempd, wheel_name),
-                    os.path.join(tempd, new_name)
-                )
-                # Reassign to simplify the return at the end of function
-                wheel_name = new_name
-        except Exception:
-            logger.error('Failed building wheel for %s', req.name)
-            return None
-        return os.path.join(tempd, wheel_name)
-
-    def _build_one_legacy(self, req, tempd, python_tag=None):
-        """Build one InstallRequirement using the "legacy" build process.
-
-        Returns path to wheel if successfully built. Otherwise, returns None.
-        """
-        base_args = self._base_setup_args(req)
-
-        spin_message = 'Building wheel for %s (setup.py)' % (req.name,)
-        with open_spinner(spin_message) as spinner:
-            logger.debug('Destination directory: %s', tempd)
-            wheel_args = base_args + ['bdist_wheel', '-d', tempd] \
-                + self.build_options
-
-            if python_tag is not None:
-                wheel_args += ["--python-tag", python_tag]
-
-            try:
-                output = call_subprocess(
-                    wheel_args,
-                    cwd=req.unpacked_source_directory,
-                    spinner=spinner,
-                )
-            except Exception:
-                spinner.finish("error")
-                logger.error('Failed building wheel for %s', req.name)
-                return None
-
-            names = os.listdir(tempd)
-            wheel_path = get_legacy_build_wheel_path(
-                names=names,
-                temp_dir=tempd,
-                req=req,
-                command_args=wheel_args,
-                command_output=output,
-            )
-            return wheel_path
-
-    def _clean_one(self, req):
-        base_args = self._base_setup_args(req)
-
-        logger.info('Running setup.py clean for %s', req.name)
-        clean_args = base_args + ['clean', '--all']
-        try:
-            call_subprocess(clean_args, cwd=req.source_dir)
-            return True
-        except Exception:
-            logger.error('Failed cleaning build dir for %s', req.name)
-            return False
-
-    def build(
-        self,
-        requirements,  # type: Iterable[InstallRequirement]
-        should_unpack=False  # type: bool
-    ):
-        # type: (...) -> List[InstallRequirement]
-        """Build wheels.
-
-        :param should_unpack: If True, after building the wheel, unpack it
-            and replace the sdist with the unpacked version in preparation
-            for installation.
-        :return: True if all the wheels built correctly.
-        """
-        # pip install uses should_unpack=True.
-        # pip install never provides a _wheel_dir.
-        # pip wheel uses should_unpack=False.
-        # pip wheel always provides a _wheel_dir (via the preparer).
-        assert (
-            (should_unpack and not self._wheel_dir) or
-            (not should_unpack and self._wheel_dir)
-        )
-
-        buildset = []
-        cache_available = bool(self.wheel_cache.cache_dir)
-
-        for req in requirements:
-            ephem_cache = should_use_ephemeral_cache(
-                req,
-                should_unpack=should_unpack,
-                cache_available=cache_available,
-                check_binary_allowed=self.check_binary_allowed,
-            )
-            if ephem_cache is None:
-                continue
-
-            # Determine where the wheel should go.
-            if should_unpack:
-                if ephem_cache:
-                    output_dir = self.wheel_cache.get_ephem_path_for_link(
-                        req.link
-                    )
-                else:
-                    output_dir = self.wheel_cache.get_path_for_link(req.link)
-            else:
-                output_dir = self._wheel_dir
-
-            buildset.append((req, output_dir))
-
-        if not buildset:
-            return []
-
-        # TODO by @pradyunsg
-        # Should break up this method into 2 separate methods.
-
-        # Build the wheels.
-        logger.info(
-            'Building wheels for collected packages: %s',
-            ', '.join([req.name for (req, _) in buildset]),
-        )
-
-        python_tag = None
-        if should_unpack:
-            python_tag = pep425tags.implementation_tag
-
-        with indent_log():
-            build_success, build_failure = [], []
-            for req, output_dir in buildset:
-                try:
-                    ensure_dir(output_dir)
-                except OSError as e:
-                    logger.warning(
-                        "Building wheel for %s failed: %s",
-                        req.name, e,
-                    )
-                    build_failure.append(req)
-                    continue
-
-                wheel_file = self._build_one(
-                    req, output_dir,
-                    python_tag=python_tag,
-                )
-                if wheel_file:
-                    build_success.append(req)
-                    if should_unpack:
-                        # XXX: This is mildly duplicative with prepare_files,
-                        # but not close enough to pull out to a single common
-                        # method.
-                        # The code below assumes temporary source dirs -
-                        # prevent it doing bad things.
-                        if (
-                            req.source_dir and
-                            not has_delete_marker_file(req.source_dir)
-                        ):
-                            raise AssertionError(
-                                "bad source dir - missing marker")
-                        # Delete the source we built the wheel from
-                        req.remove_temporary_source()
-                        # set the build directory again - name is known from
-                        # the work prepare_files did.
-                        req.source_dir = req.ensure_build_location(
-                            self.preparer.build_dir
-                        )
-                        # Update the link for this.
-                        req.link = Link(path_to_url(wheel_file))
-                        assert req.link.is_wheel
-                        # extract the wheel into the dir
-                        unpack_file(req.link.file_path, req.source_dir)
-                else:
-                    build_failure.append(req)
-
-        # notify success/failure
-        if build_success:
-            logger.info(
-                'Successfully built %s',
-                ' '.join([req.name for req in build_success]),
-            )
-        if build_failure:
-            logger.info(
-                'Failed to build %s',
-                ' '.join([req.name for req in build_failure]),
-            )
-        # Return a list of requirements that failed to build
-        return build_failure
diff --git a/pipenv/patched/notpip/_vendor/README.rst b/pipenv/patched/notpip/_vendor/README.rst
deleted file mode 100644
index 38c306aa..00000000
--- a/pipenv/patched/notpip/_vendor/README.rst
+++ /dev/null
@@ -1,151 +0,0 @@
-Vendoring Policy
-================
-
-* Vendored libraries **MUST** not be modified except as required to
-  successfully vendor them.
-
-* Vendored libraries **MUST** be released copies of libraries available on
-  PyPI.
-
-* Vendored libraries **MUST** be accompanied with LICENSE files.
-
-* The versions of libraries vendored in pip **MUST** be reflected in
-  ``pip/_vendor/vendor.txt``.
-
-* Vendored libraries **MUST** function without any build steps such as ``2to3`` or
-  compilation of C code, practically this limits to single source 2.x/3.x and
-  pure Python.
-
-* Any modifications made to libraries **MUST** be noted in
-  ``pip/_vendor/README.rst`` and their corresponding patches **MUST** be
-  included ``tools/automation/vendoring/patches``.
-
-* Vendored libraries should have corresponding ``vendored()`` entries in
-  ``pip/_vendor/__init__.py``.
-
-Rationale
----------
-
-Historically pip has not had any dependencies except for ``setuptools`` itself,
-choosing instead to implement any functionality it needed to prevent needing
-a dependency. However, starting with pip 1.5, we began to replace code that was
-implemented inside of pip with reusable libraries from PyPI. This brought the
-typical benefits of reusing libraries instead of reinventing the wheel like
-higher quality and more battle tested code, centralization of bug fixes
-(particularly security sensitive ones), and better/more features for less work.
-
-However, there are several issues with having dependencies in the traditional
-way (via ``install_requires``) for pip. These issues are:
-
-* **Fragility.** When pip depends on another library to function then if for
-  whatever reason that library either isn't installed or an incompatible
-  version is installed then pip ceases to function. This is of course true for
-  all Python applications, however for every application *except* for pip the
-  way you fix it is by re-running pip. Obviously, when pip can't run, you can't
-  use pip to fix pip, so you're left having to manually resolve dependencies and
-  installing them by hand.
-
-* **Making other libraries uninstallable.** One of pip's current dependencies is
-  the ``requests`` library, for which pip requires a fairly recent version to run.
-  If pip depended on ``requests`` in the traditional manner, then we'd either
-  have to maintain compatibility with every ``requests`` version that has ever
-  existed (and ever will), OR allow pip to render certain versions of ``requests``
-  uninstallable. (The second issue, although technically true for any Python
-  application, is magnified by pip's ubiquity; pip is installed by default in
-  Python, in ``pyvenv``, and in ``virtualenv``.)
-
-* **Security.** This might seem puzzling at first glance, since vendoring
-  has a tendency to complicate updating dependencies for security updates,
-  and that holds true for pip. However, given the *other* reasons for avoiding
-  dependencies, the alternative is for pip to reinvent the wheel itself.
-  This is what pip did historically. It forced pip to re-implement its own
-  HTTPS verification routines as a workaround for the Python standard library's
-  lack of SSL validation, which resulted in similar bugs in the validation routine
-  in ``requests`` and ``urllib3``, except that they had to be discovered and
-  fixed independently. Even though we're vendoring, reusing libraries keeps pip
-  more secure by relying on the great work of our dependencies, *and* allowing for
-  faster, easier security fixes by simply pulling in newer versions of dependencies.
-
-* **Bootstrapping.** Currently most popular methods of installing pip rely
-  on pip's self-contained nature to install pip itself. These tools work by bundling
-  a copy of pip, adding it to ``sys.path``, and then executing that copy of pip.
-  This is done instead of implementing a "mini installer" (to reduce duplication);
-  pip already knows how to install a Python package, and is far more battle-tested
-  than any "mini installer" could ever possibly be.
-
-Many downstream redistributors have policies against this kind of bundling, and
-instead opt to patch the software they distribute to debundle it and make it
-rely on the global versions of the software that they already have packaged
-(which may have its own patches applied to it). We (the pip team) would prefer
-it if pip was *not* debundled in this manner due to the above reasons and
-instead we would prefer it if pip would be left intact as it is now. The one
-exception to this, is it is acceptable to remove the
-``pip/_vendor/requests/cacert.pem`` file provided you ensure that the
-``ssl.get_default_verify_paths().cafile`` API returns the correct CA bundle for
-your system. This will ensure that pip will use your system provided CA bundle
-instead of the copy bundled with pip.
-
-In the longer term, if someone has a *portable* solution to the above problems,
-other than the bundling method we currently use, that doesn't add additional
-problems that are unreasonable then we would be happy to consider, and possibly
-switch to said method. This solution must function correctly across all of the
-situation that we expect pip to be used and not mandate some external mechanism
-such as OS packages.
-
-
-Modifications
--------------
-
-* ``setuptools`` is completely stripped to only keep ``pkg_resources``
-* ``pkg_resources`` has been modified to import its dependencies from ``pip._vendor``
-* ``packaging`` has been modified to import its dependencies from ``pip._vendor``
-* ``html5lib`` has been modified to import six from ``pip._vendor`` and
-  to prefer importing from ``collections.abc`` instead of ``collections``.
-* ``CacheControl`` has been modified to import its dependencies from ``pip._vendor``
-* ``requests`` has been modified to import its other dependencies from ``pip._vendor``
-  and to *not* load ``simplejson`` (all platforms) and ``pyopenssl`` (Windows).
-
-
-Automatic Vendoring
--------------------
-
-Vendoring is automated via the ``vendoring`` tool from the content of
-``pip/_vendor/vendor.txt`` and the different patches in
-``tools/automation/vendoring/patches``.
-Launch it via ``vendoring sync . -v`` (requires ``vendoring>=0.2.2``).
-
-
-Debundling
-----------
-
-As mentioned in the rationale, we, the pip team, would prefer it if pip was not
-debundled (other than optionally ``pip/_vendor/requests/cacert.pem``) and that
-pip was left intact. However, if you insist on doing so, we have a
-semi-supported method (that we don't test in our CI) and requires a bit of
-extra work on your end in order to solve the problems described above.
-
-1. Delete everything in ``pip/_vendor/`` **except** for
-   ``pip/_vendor/__init__.py``.
-
-2. Generate wheels for each of pip's dependencies (and any of their
-   dependencies) using your patched copies of these libraries. These must be
-   placed somewhere on the filesystem that pip can access (``pip/_vendor`` is
-   the default assumption).
-
-3. Modify ``pip/_vendor/__init__.py`` so that the ``DEBUNDLED`` variable is
-   ``True``.
-
-4. Upon installation, the ``INSTALLER`` file in pip's own ``dist-info``
-   directory should be set to something other than ``pip``, so that pip
-   can detect that it wasn't installed using itself.
-
-5. *(optional)* If you've placed the wheels in a location other than
-   ``pip/_vendor/``, then modify ``pip/_vendor/__init__.py`` so that the
-   ``WHEEL_DIR`` variable points to the location you've placed them.
-
-6. *(optional)* Update the ``pip_self_version_check`` logic to use the
-   appropriate logic for determining the latest available version of pip and
-   prompt the user with the correct upgrade message.
-
-Note that partial debundling is **NOT** supported. You need to prepare wheels
-for all dependencies for successful debundling.
diff --git a/pipenv/patched/notpip/_vendor/cachecontrol.pyi b/pipenv/patched/notpip/_vendor/cachecontrol.pyi
deleted file mode 100644
index 636a66ba..00000000
--- a/pipenv/patched/notpip/_vendor/cachecontrol.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from cachecontrol import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/certifi.pyi b/pipenv/patched/notpip/_vendor/certifi.pyi
deleted file mode 100644
index e5c4d3d2..00000000
--- a/pipenv/patched/notpip/_vendor/certifi.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from certifi import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/chardet.pyi b/pipenv/patched/notpip/_vendor/chardet.pyi
deleted file mode 100644
index 29e87e33..00000000
--- a/pipenv/patched/notpip/_vendor/chardet.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from chardet import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/colorama.pyi b/pipenv/patched/notpip/_vendor/colorama.pyi
deleted file mode 100644
index 60a6c254..00000000
--- a/pipenv/patched/notpip/_vendor/colorama.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from colorama import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/distlib.pyi b/pipenv/patched/notpip/_vendor/distlib.pyi
deleted file mode 100644
index ea94b159..00000000
--- a/pipenv/patched/notpip/_vendor/distlib.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from distlib import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/distro.pyi b/pipenv/patched/notpip/_vendor/distro.pyi
deleted file mode 100644
index c7ea94b3..00000000
--- a/pipenv/patched/notpip/_vendor/distro.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from distro import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/html5lib.pyi b/pipenv/patched/notpip/_vendor/html5lib.pyi
deleted file mode 100644
index 9bc9af95..00000000
--- a/pipenv/patched/notpip/_vendor/html5lib.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from html5lib import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/idna.pyi b/pipenv/patched/notpip/_vendor/idna.pyi
deleted file mode 100644
index 7410d72f..00000000
--- a/pipenv/patched/notpip/_vendor/idna.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from idna import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/ipaddress.pyi b/pipenv/patched/notpip/_vendor/ipaddress.pyi
deleted file mode 100644
index eef994d9..00000000
--- a/pipenv/patched/notpip/_vendor/ipaddress.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from ipaddress import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/msgpack.pyi b/pipenv/patched/notpip/_vendor/msgpack.pyi
deleted file mode 100644
index 4e69b886..00000000
--- a/pipenv/patched/notpip/_vendor/msgpack.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from msgpack import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/packaging.pyi b/pipenv/patched/notpip/_vendor/packaging.pyi
deleted file mode 100644
index 3458a3d6..00000000
--- a/pipenv/patched/notpip/_vendor/packaging.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from packaging import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/packaging/LICENSE.APACHE b/pipenv/patched/notpip/_vendor/packaging/LICENSE.APACHE
index f433b1a5..4947287f 100644
--- a/pipenv/patched/notpip/_vendor/packaging/LICENSE.APACHE
+++ b/pipenv/patched/notpip/_vendor/packaging/LICENSE.APACHE
@@ -174,4 +174,4 @@
       incurred by, or claims asserted against, such Contributor by reason
       of your accepting any such warranty or additional liability.
 
-   END OF TERMS AND CONDITIONS
+   END OF TERMS AND CONDITIONS
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/packaging/py.typed b/pipenv/patched/notpip/_vendor/packaging/py.typed
deleted file mode 100644
index e69de29b..00000000
diff --git a/pipenv/patched/notpip/_vendor/pep517.pyi b/pipenv/patched/notpip/_vendor/pep517.pyi
deleted file mode 100644
index d1ce8102..00000000
--- a/pipenv/patched/notpip/_vendor/pep517.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from pep517 import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/pkg_resources.pyi b/pipenv/patched/notpip/_vendor/pkg_resources.pyi
deleted file mode 100644
index 47703031..00000000
--- a/pipenv/patched/notpip/_vendor/pkg_resources.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from pkg_resources import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/progress.pyi b/pipenv/patched/notpip/_vendor/progress.pyi
deleted file mode 100644
index c92de832..00000000
--- a/pipenv/patched/notpip/_vendor/progress.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from progress import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/pyparsing.pyi b/pipenv/patched/notpip/_vendor/pyparsing.pyi
deleted file mode 100644
index 8e9de6b0..00000000
--- a/pipenv/patched/notpip/_vendor/pyparsing.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from pyparsing import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/pytoml.pyi b/pipenv/patched/notpip/_vendor/pytoml.pyi
deleted file mode 100644
index 5566ee89..00000000
--- a/pipenv/patched/notpip/_vendor/pytoml.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from pytoml import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/requests.pyi b/pipenv/patched/notpip/_vendor/requests.pyi
deleted file mode 100644
index 6d69cd6f..00000000
--- a/pipenv/patched/notpip/_vendor/requests.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from requests import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/retrying.pyi b/pipenv/patched/notpip/_vendor/retrying.pyi
deleted file mode 100644
index 90f20c6d..00000000
--- a/pipenv/patched/notpip/_vendor/retrying.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from retrying import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/six.LICENSE b/pipenv/patched/notpip/_vendor/six.LICENSE
index de663311..365d1074 100644
--- a/pipenv/patched/notpip/_vendor/six.LICENSE
+++ b/pipenv/patched/notpip/_vendor/six.LICENSE
@@ -1,4 +1,4 @@
-Copyright (c) 2010-2020 Benjamin Peterson
+Copyright (c) 2010-2018 Benjamin Peterson
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of
 this software and associated documentation files (the "Software"), to deal in
diff --git a/pipenv/patched/notpip/_vendor/six/__init__.pyi b/pipenv/patched/notpip/_vendor/six/__init__.pyi
deleted file mode 100644
index e5c0e242..00000000
--- a/pipenv/patched/notpip/_vendor/six/__init__.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from six import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/six/moves/__init__.pyi b/pipenv/patched/notpip/_vendor/six/moves/__init__.pyi
deleted file mode 100644
index 7a82f79d..00000000
--- a/pipenv/patched/notpip/_vendor/six/moves/__init__.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from six.moves import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/six/moves/configparser.pyi b/pipenv/patched/notpip/_vendor/six/moves/configparser.pyi
deleted file mode 100644
index f77b3f41..00000000
--- a/pipenv/patched/notpip/_vendor/six/moves/configparser.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from six.moves.configparser import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/urllib3.pyi b/pipenv/patched/notpip/_vendor/urllib3.pyi
deleted file mode 100644
index 7e8a2a70..00000000
--- a/pipenv/patched/notpip/_vendor/urllib3.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from urllib3 import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/_vendor/vendor.txt b/pipenv/patched/notpip/_vendor/vendor.txt
index cbc2830a..aadd3526 100644
--- a/pipenv/patched/notpip/_vendor/vendor.txt
+++ b/pipenv/patched/notpip/_vendor/vendor.txt
@@ -1,23 +1,23 @@
 appdirs==1.4.3
-CacheControl==0.12.6
-colorama==0.4.3
+CacheControl==0.12.5
+colorama==0.4.1
 contextlib2==0.6.0
-distlib==0.3.0
+distlib==0.2.9.post0
 distro==1.4.0
 html5lib==1.0.1
-ipaddress==1.0.23  # Only needed on 2.6 and 2.7
+ipaddress==1.0.22  # Only needed on 2.6 and 2.7
 msgpack==0.6.2
-packaging==20.1
+packaging==19.2
 pep517==0.7.0
 progress==1.5
-pyparsing==2.4.6
+pyparsing==2.4.2
 pytoml==0.1.21
 requests==2.22.0
-    certifi==2019.11.28
+    certifi==2019.9.11
     chardet==3.0.4
     idna==2.8
-    urllib3==1.25.7
+    urllib3==1.25.6
 retrying==1.3.3
-setuptools==44.0.0
-six==1.14.0
+setuptools==41.4.0
+six==1.12.0
 webencodings==0.5.1
diff --git a/pipenv/patched/notpip/_vendor/webencodings.pyi b/pipenv/patched/notpip/_vendor/webencodings.pyi
deleted file mode 100644
index a11db4d8..00000000
--- a/pipenv/patched/notpip/_vendor/webencodings.pyi
+++ /dev/null
@@ -1 +0,0 @@
-from webencodings import *
\ No newline at end of file
diff --git a/pipenv/patched/notpip/appdirs.LICENSE.txt b/pipenv/patched/notpip/appdirs.LICENSE.txt
deleted file mode 100644
index 107c6140..00000000
--- a/pipenv/patched/notpip/appdirs.LICENSE.txt
+++ /dev/null
@@ -1,23 +0,0 @@
-# This is the MIT license
-
-Copyright (c) 2010 ActiveState Software Inc.
-
-Permission is hereby granted, free of charge, to any person obtaining a
-copy of this software and associated documentation files (the
-"Software"), to deal in the Software without restriction, including
-without limitation the rights to use, copy, modify, merge, publish,
-distribute, sublicense, and/or sell copies of the Software, and to
-permit persons to whom the Software is furnished to do so, subject to
-the following conditions:
-
-The above copyright notice and this permission notice shall be included
-in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
-OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
-MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
-IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
-CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
-SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
-
diff --git a/pipenv/patched/notpip/contextlib2.LICENSE.txt b/pipenv/patched/notpip/contextlib2.LICENSE.txt
deleted file mode 100644
index 5de20277..00000000
--- a/pipenv/patched/notpip/contextlib2.LICENSE.txt
+++ /dev/null
@@ -1,122 +0,0 @@
-
-
-A. HISTORY OF THE SOFTWARE
-==========================
-
-contextlib2 is a derivative of the contextlib module distributed by the PSF
-as part of the Python standard library. According, it is itself redistributed
-under the PSF license (reproduced in full below). As the contextlib module
-was added only in Python 2.5, the licenses for earlier Python versions are
-not applicable and have not been included.
-
-Python was created in the early 1990s by Guido van Rossum at Stichting
-Mathematisch Centrum (CWI, see http://www.cwi.nl) in the Netherlands
-as a successor of a language called ABC.  Guido remains Python's
-principal author, although it includes many contributions from others.
-
-In 1995, Guido continued his work on Python at the Corporation for
-National Research Initiatives (CNRI, see http://www.cnri.reston.va.us)
-in Reston, Virginia where he released several versions of the
-software.
-
-In May 2000, Guido and the Python core development team moved to
-BeOpen.com to form the BeOpen PythonLabs team.  In October of the same
-year, the PythonLabs team moved to Digital Creations (now Zope
-Corporation, see http://www.zope.com).  In 2001, the Python Software
-Foundation (PSF, see http://www.python.org/psf/) was formed, a
-non-profit organization created specifically to own Python-related
-Intellectual Property.  Zope Corporation is a sponsoring member of
-the PSF.
-
-All Python releases are Open Source (see http://www.opensource.org for
-the Open Source Definition).  Historically, most, but not all, Python
-releases have also been GPL-compatible; the table below summarizes
-the various releases that included the contextlib module.
-
-    Release         Derived     Year        Owner       GPL-
-                    from                                compatible? (1)
-
-    2.5             2.4         2006        PSF         yes
-    2.5.1           2.5         2007        PSF         yes
-    2.5.2           2.5.1       2008        PSF         yes
-    2.5.3           2.5.2       2008        PSF         yes
-    2.6             2.5         2008        PSF         yes
-    2.6.1           2.6         2008        PSF         yes
-    2.6.2           2.6.1       2009        PSF         yes
-    2.6.3           2.6.2       2009        PSF         yes
-    2.6.4           2.6.3       2009        PSF         yes
-    2.6.5           2.6.4       2010        PSF         yes
-    3.0             2.6         2008        PSF         yes
-    3.0.1           3.0         2009        PSF         yes
-    3.1             3.0.1       2009        PSF         yes
-    3.1.1           3.1         2009        PSF         yes
-    3.1.2           3.1.1       2010        PSF         yes
-    3.1.3           3.1.2       2010        PSF         yes
-    3.1.4           3.1.3       2011        PSF         yes
-    3.2             3.1         2011        PSF         yes
-    3.2.1           3.2         2011        PSF         yes
-    3.2.2           3.2.1       2011        PSF         yes
-    3.3             3.2         2012        PSF         yes
-
-Footnotes:
-
-(1) GPL-compatible doesn't mean that we're distributing Python under
-    the GPL.  All Python licenses, unlike the GPL, let you distribute
-    a modified version without making your changes open source.  The
-    GPL-compatible licenses make it possible to combine Python with
-    other software that is released under the GPL; the others don't.
-
-Thanks to the many outside volunteers who have worked under Guido's
-direction to make these releases possible.
-
-
-B. TERMS AND CONDITIONS FOR ACCESSING OR OTHERWISE USING PYTHON
-===============================================================
-
-PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
---------------------------------------------
-
-1. This LICENSE AGREEMENT is between the Python Software Foundation
-("PSF"), and the Individual or Organization ("Licensee") accessing and
-otherwise using this software ("Python") in source or binary form and
-its associated documentation.
-
-2. Subject to the terms and conditions of this License Agreement, PSF hereby
-grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
-analyze, test, perform and/or display publicly, prepare derivative works,
-distribute, and otherwise use Python alone or in any derivative version,
-provided, however, that PSF's License Agreement and PSF's notice of copyright,
-i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
-2011 Python Software Foundation; All Rights Reserved" are retained in Python
-alone or in any derivative version prepared by Licensee.
-
-3. In the event Licensee prepares a derivative work that is based on
-or incorporates Python or any part thereof, and wants to make
-the derivative work available to others as provided herein, then
-Licensee hereby agrees to include in any such work a brief summary of
-the changes made to Python.
-
-4. PSF is making Python available to Licensee on an "AS IS"
-basis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
-IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND
-DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
-FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT
-INFRINGE ANY THIRD PARTY RIGHTS.
-
-5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
-FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
-A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,
-OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
-
-6. This License Agreement will automatically terminate upon a material
-breach of its terms and conditions.
-
-7. Nothing in this License Agreement shall be deemed to create any
-relationship of agency, partnership, or joint venture between PSF and
-Licensee.  This License Agreement does not grant permission to use PSF
-trademarks or trade name in a trademark sense to endorse or promote
-products or services of Licensee, or any third party.
-
-8. By copying, installing or otherwise using Python, Licensee
-agrees to be bound by the terms and conditions of this License
-Agreement.
diff --git a/pipenv/patched/notpip/distro.LICENSE b/pipenv/patched/notpip/distro.LICENSE
deleted file mode 100644
index e06d2081..00000000
--- a/pipenv/patched/notpip/distro.LICENSE
+++ /dev/null
@@ -1,202 +0,0 @@
-Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "{}"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright {yyyy} {name of copyright owner}
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
-
diff --git a/pipenv/patched/notpip/idna.LICENSE.rst b/pipenv/patched/notpip/idna.LICENSE.rst
deleted file mode 100644
index 3ee64fba..00000000
--- a/pipenv/patched/notpip/idna.LICENSE.rst
+++ /dev/null
@@ -1,80 +0,0 @@
-License
--------
-
-Copyright (c) 2013-2018, Kim Davies. All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are met:
-
-#. Redistributions of source code must retain the above copyright
-   notice, this list of conditions and the following disclaimer.
-
-#. Redistributions in binary form must reproduce the above
-   copyright notice, this list of conditions and the following
-   disclaimer in the documentation and/or other materials provided with
-   the distribution.
-
-#. Neither the name of the copyright holder nor the names of the 
-   contributors may be used to endorse or promote products derived 
-   from this software without specific prior written permission.
-
-#. THIS SOFTWARE IS PROVIDED BY THE CONTRIBUTORS "AS IS" AND ANY
-   EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
-   IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-   PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR 
-   CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, 
-   SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT 
-   LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-   DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-   THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-   (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE
-   USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH
-   DAMAGE.
-
-Portions of the codec implementation and unit tests are derived from the
-Python standard library, which carries the `Python Software Foundation
-License <https://docs.python.org/2/license.html>`_:
-
-   Copyright (c) 2001-2014 Python Software Foundation; All Rights Reserved
-
-Portions of the unit tests are derived from the Unicode standard, which 
-is subject to the Unicode, Inc. License Agreement:
-
-   Copyright (c) 1991-2014 Unicode, Inc. All rights reserved.
-   Distributed under the Terms of Use in 
-   <http://www.unicode.org/copyright.html>.
-
-   Permission is hereby granted, free of charge, to any person obtaining
-   a copy of the Unicode data files and any associated documentation
-   (the "Data Files") or Unicode software and any associated documentation
-   (the "Software") to deal in the Data Files or Software
-   without restriction, including without limitation the rights to use,
-   copy, modify, merge, publish, distribute, and/or sell copies of
-   the Data Files or Software, and to permit persons to whom the Data Files
-   or Software are furnished to do so, provided that
-   
-   (a) this copyright and permission notice appear with all copies 
-   of the Data Files or Software,
-
-   (b) this copyright and permission notice appear in associated 
-   documentation, and
-
-   (c) there is clear notice in each modified Data File or in the Software
-   as well as in the documentation associated with the Data File(s) or
-   Software that the data or software has been modified.
-
-   THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF
-   ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
-   WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
-   NONINFRINGEMENT OF THIRD PARTY RIGHTS.
-   IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED IN THIS
-   NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL
-   DAMAGES, OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE,
-   DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
-   TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
-   PERFORMANCE OF THE DATA FILES OR SOFTWARE.
-
-   Except as contained in this notice, the name of a copyright holder
-   shall not be used in advertising or otherwise to promote the sale,
-   use or other dealings in these Data Files or Software without prior
-   written authorization of the copyright holder.
diff --git a/pipenv/patched/notpip/ipaddress.LICENSE b/pipenv/patched/notpip/ipaddress.LICENSE
deleted file mode 100644
index 41bd16ba..00000000
--- a/pipenv/patched/notpip/ipaddress.LICENSE
+++ /dev/null
@@ -1,50 +0,0 @@
-This package is a modified version of cpython's ipaddress module.
-It is therefore distributed under the PSF license, as follows: 
-
-PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
---------------------------------------------
-
-1. This LICENSE AGREEMENT is between the Python Software Foundation
-("PSF"), and the Individual or Organization ("Licensee") accessing and
-otherwise using this software ("Python") in source or binary form and
-its associated documentation.
-
-2. Subject to the terms and conditions of this License Agreement, PSF hereby
-grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce,
-analyze, test, perform and/or display publicly, prepare derivative works,
-distribute, and otherwise use Python alone or in any derivative version,
-provided, however, that PSF's License Agreement and PSF's notice of copyright,
-i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
-2011, 2012, 2013, 2014 Python Software Foundation; All Rights Reserved" are
-retained in Python alone or in any derivative version prepared by Licensee.
-
-3. In the event Licensee prepares a derivative work that is based on
-or incorporates Python or any part thereof, and wants to make
-the derivative work available to others as provided herein, then
-Licensee hereby agrees to include in any such work a brief summary of
-the changes made to Python.
-
-4. PSF is making Python available to Licensee on an "AS IS"
-basis.  PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR
-IMPLIED.  BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND
-DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS
-FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT
-INFRINGE ANY THIRD PARTY RIGHTS.
-
-5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON
-FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS
-A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON,
-OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
-
-6. This License Agreement will automatically terminate upon a material
-breach of its terms and conditions.
-
-7. Nothing in this License Agreement shall be deemed to create any
-relationship of agency, partnership, or joint venture between PSF and
-Licensee.  This License Agreement does not grant permission to use PSF
-trademarks or trade name in a trademark sense to endorse or promote
-products or services of Licensee, or any third party.
-
-8. By copying, installing or otherwise using Python, Licensee
-agrees to be bound by the terms and conditions of this License
-Agreement.
diff --git a/pipenv/patched/notpip/msgpack.COPYING b/pipenv/patched/notpip/msgpack.COPYING
deleted file mode 100644
index f067af3a..00000000
--- a/pipenv/patched/notpip/msgpack.COPYING
+++ /dev/null
@@ -1,14 +0,0 @@
-Copyright (C) 2008-2011 INADA Naoki <songofacandy@gmail.com>
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
-
diff --git a/pipenv/patched/notpip/packaging.LICENSE.APACHE b/pipenv/patched/notpip/packaging.LICENSE.APACHE
deleted file mode 100644
index 4947287f..00000000
--- a/pipenv/patched/notpip/packaging.LICENSE.APACHE
+++ /dev/null
@@ -1,177 +0,0 @@
-
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
\ No newline at end of file
diff --git a/pipenv/patched/notpip/packaging.LICENSE.BSD b/pipenv/patched/notpip/packaging.LICENSE.BSD
deleted file mode 100644
index 42ce7b75..00000000
--- a/pipenv/patched/notpip/packaging.LICENSE.BSD
+++ /dev/null
@@ -1,23 +0,0 @@
-Copyright (c) Donald Stufft and individual contributors.
-All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are met:
-
-    1. Redistributions of source code must retain the above copyright notice,
-       this list of conditions and the following disclaimer.
-
-    2. Redistributions in binary form must reproduce the above copyright
-       notice, this list of conditions and the following disclaimer in the
-       documentation and/or other materials provided with the distribution.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
-FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
-DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
-SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
-CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
-OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/pipenv/patched/notpip/pyparsing.LICENSE b/pipenv/patched/notpip/pyparsing.LICENSE
deleted file mode 100644
index 1bf98523..00000000
--- a/pipenv/patched/notpip/pyparsing.LICENSE
+++ /dev/null
@@ -1,18 +0,0 @@
-Permission is hereby granted, free of charge, to any person obtaining
-a copy of this software and associated documentation files (the
-"Software"), to deal in the Software without restriction, including
-without limitation the rights to use, copy, modify, merge, publish,
-distribute, sublicense, and/or sell copies of the Software, and to
-permit persons to whom the Software is furnished to do so, subject to
-the following conditions:
-
-The above copyright notice and this permission notice shall be
-included in all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
-EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
-MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
-IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
-CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
-TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
-SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
diff --git a/pipenv/patched/notpip/retrying.LICENSE b/pipenv/patched/notpip/retrying.LICENSE
deleted file mode 100644
index 7a4a3ea2..00000000
--- a/pipenv/patched/notpip/retrying.LICENSE
+++ /dev/null
@@ -1,202 +0,0 @@
-
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
\ No newline at end of file
diff --git a/pipenv/patched/notpip/six.LICENSE b/pipenv/patched/notpip/six.LICENSE
deleted file mode 100644
index 365d1074..00000000
--- a/pipenv/patched/notpip/six.LICENSE
+++ /dev/null
@@ -1,18 +0,0 @@
-Copyright (c) 2010-2018 Benjamin Peterson
-
-Permission is hereby granted, free of charge, to any person obtaining a copy of
-this software and associated documentation files (the "Software"), to deal in
-the Software without restriction, including without limitation the rights to
-use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
-the Software, and to permit persons to whom the Software is furnished to do so,
-subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in all
-copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
-FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
-COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
-IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
-CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
diff --git a/pipenv/patched/notpip/webencodings.LICENSE b/pipenv/patched/notpip/webencodings.LICENSE
deleted file mode 100644
index 3d0d3e70..00000000
--- a/pipenv/patched/notpip/webencodings.LICENSE
+++ /dev/null
@@ -1,31 +0,0 @@
-Copyright (c) 2012 by Simon Sapin.
-
-Some rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are
-met:
-
-    * Redistributions of source code must retain the above copyright
-      notice, this list of conditions and the following disclaimer.
-
-    * Redistributions in binary form must reproduce the above
-      copyright notice, this list of conditions and the following
-      disclaimer in the documentation and/or other materials provided
-      with the distribution.
-
-    * The names of the contributors may not be used to endorse or
-      promote products derived from this software without specific
-      prior written permission.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
-"AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
-LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
-A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
-OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
-SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
-LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
-DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
-THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
-OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
diff --git a/pipenv/patched/piptools/scripts/compile.py b/pipenv/patched/piptools/scripts/compile.py
old mode 100755
new mode 100644
diff --git a/pipenv/patched/piptools/scripts/sync.py b/pipenv/patched/piptools/scripts/sync.py
old mode 100755
new mode 100644
diff --git a/pipenv/patched/piptools/utils.py b/pipenv/patched/piptools/utils.py
index aa93ec88..28ece192 100644
--- a/pipenv/patched/piptools/utils.py
+++ b/pipenv/patched/piptools/utils.py
@@ -141,13 +141,13 @@ def _requirement_to_str_lowercase_name(requirement):
     Formats a packaging.requirements.Requirement with a lowercase name.
 
     This is simply a copy of
-    https://github.com/pypa/packaging/blob/16.8/packaging/requirements.py#L109-L124
+    https://github.com/pypa/pipenv/patched/packaging/blob/pipenv/patched/16.8/packaging/requirements.py#L109-L124
     modified to lowercase the dependency name.
 
     Previously, we were invoking the original Requirement.__str__ method and
     lowercasing the entire result, which would lowercase the name, *and* other,
     important stuff that should not be lowercased (such as the marker). See
-    this issue for more information: https://github.com/pypa/pipenv/issues/2113.
+    this issue for more information: https://github.com/pypa/pipenv/patched/pipenv/issues/2113.
     """
     parts = [requirement.name.lower()]
 
diff --git a/pipenv/patched/safety.LICENSE b/pipenv/patched/safety/LICENSE
similarity index 99%
rename from pipenv/patched/safety.LICENSE
rename to pipenv/patched/safety/LICENSE
index c5fda558..55a1eb03 100644
--- a/pipenv/patched/safety.LICENSE
+++ b/pipenv/patched/safety/LICENSE
@@ -1,3 +1,4 @@
+
 MIT License
 
 Copyright (c) 2016, pyup.io
diff --git a/pipenv/vendor/pip_shims/__init__.py b/pipenv/vendor/pip_shims/__init__.py
index 3a0188c9..795c4872 100644
--- a/pipenv/vendor/pip_shims/__init__.py
+++ b/pipenv/vendor/pip_shims/__init__.py
@@ -1,4 +1,24 @@
 # -*- coding=utf-8 -*-
+"""
+This library is a set of compatibilty access shims to the ``pip`` internal API.
+It provides compatibility with pip versions 8.0 through the current release. The
+shims are provided using a lazy import strategy by hacking a module by overloading
+a class instance's ``getattr`` method. This library exists due to my constant
+writing of the same set of import shims.
+
+Submodules
+==========
+
+.. autosummary::
+    :toctree: _autosummary
+
+    pip_shims.models
+    pip_shims.compat
+    pip_shims.utils
+    pip_shims.shims
+    pip_shims.environment
+
+"""
 from __future__ import absolute_import
 
 import sys
diff --git a/pipenv/vendor/pip_shims/compat.py b/pipenv/vendor/pip_shims/compat.py
index 0c125321..d8f409e1 100644
--- a/pipenv/vendor/pip_shims/compat.py
+++ b/pipenv/vendor/pip_shims/compat.py
@@ -720,7 +720,7 @@ def shim_unpack(
     :type unpack_fn: Callable
     :param str download_dir: The directory to download the file to
     :param TShimmedFunc tempdir_manager_provider: A callable or shim referring to
-        `global_tempdir_manager` function from pip or a shimmed no-op context manager
+        `global_tempdir_manager` function from pipenv.patched.notpip or a shimmed no-op context manager
     :param Optional[:class:`~pip._internal.req.req_install.InstallRequirement`] ireq:
         an Install Requirement instance, defaults to None
     :param Optional[:class:`~pip._internal.models.link.Link`] link: A Link instance,
