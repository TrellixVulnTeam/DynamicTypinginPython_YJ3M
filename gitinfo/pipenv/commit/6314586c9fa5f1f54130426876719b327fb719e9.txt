commit 6314586c9fa5f1f54130426876719b327fb719e9
Author: Kenneth Reitz <me@kennethreitz.org>
Date:   Tue Jul 3 09:54:46 2018 -0400

    black

diff --git a/Makefile b/Makefile
index 51b267c5..2722bdb4 100644
--- a/Makefile
+++ b/Makefile
@@ -1,2 +1,4 @@
+format:
+	black pipenv/*.py
 test:
-	docker-compose up
\ No newline at end of file
+	docker-compose up
diff --git a/pipenv/__init__.py b/pipenv/__init__.py
index e62e6584..471dcb94 100644
--- a/pipenv/__init__.py
+++ b/pipenv/__init__.py
@@ -8,20 +8,20 @@ from .__version__ import __version__
 
 
 PIPENV_ROOT = os.path.dirname(os.path.realpath(__file__))
-PIPENV_VENDOR = os.sep.join([PIPENV_ROOT, 'vendor'])
-PIPENV_PATCHED = os.sep.join([PIPENV_ROOT, 'patched'])
+PIPENV_VENDOR = os.sep.join([PIPENV_ROOT, "vendor"])
+PIPENV_PATCHED = os.sep.join([PIPENV_ROOT, "patched"])
 # Inject vendored directory into system path.
 sys.path.insert(0, PIPENV_VENDOR)
 # Inject patched directory into system path.
 sys.path.insert(0, PIPENV_PATCHED)
 # Hack to make things work better.
 try:
-    if 'concurrency' in sys.modules:
-        del sys.modules['concurrency']
+    if "concurrency" in sys.modules:
+        del sys.modules["concurrency"]
 except Exception:
     pass
 from .cli import cli
 from . import resolver
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     cli()
diff --git a/pipenv/__main__.py b/pipenv/__main__.py
index d396c2a7..98dcca0c 100644
--- a/pipenv/__main__.py
+++ b/pipenv/__main__.py
@@ -1,4 +1,4 @@
 from .cli import cli
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     cli()
diff --git a/pipenv/__version__.py b/pipenv/__version__.py
index 54f90c83..8c8673ae 100644
--- a/pipenv/__version__.py
+++ b/pipenv/__version__.py
@@ -2,4 +2,4 @@
 #   //   ) ) / / //   ) ) //___) ) //   ) ) ||  / /
 #  //___/ / / / //___/ / //       //   / /  || / /
 # //       / / //       ((____   //   / /   ||/ /
-__version__ = '2018.7.1'
+__version__ = "2018.7.1"
diff --git a/pipenv/_compat.py b/pipenv/_compat.py
index 96026089..a805e68c 100644
--- a/pipenv/_compat.py
+++ b/pipenv/_compat.py
@@ -12,7 +12,7 @@ import six
 import sys
 import warnings
 from tempfile import _bin_openflags, gettempdir, _mkstemp_inner, mkdtemp
-from .utils import (logging, rmtree)
+from .utils import logging, rmtree
 
 try:
     from tempfile import _infer_return_type
@@ -29,6 +29,7 @@ except ImportError:
                 _types.add(type(arg))
         return _types.pop()
 
+
 if sys.version_info[:2] >= (3, 5):
     try:
         from pathlib import Path
@@ -51,7 +52,6 @@ except ImportError:
     except ImportError:
 
         class finalize(object):
-
             def __init__(self, *args, **kwargs):
                 logging.warn("weakref.finalize unavailable, not cleaning...")
 
@@ -66,9 +66,9 @@ if six.PY2:
 
 
 def pip_import(module_path, subimport=None, old_path=None):
-    internal = 'pip._internal.{0}'.format(module_path)
+    internal = "pip._internal.{0}".format(module_path)
     old_path = old_path or module_path
-    pip9 = 'pip.{0}'.format(old_path)
+    pip9 = "pip.{0}".format(old_path)
     try:
         _tmp = importlib.import_module(internal)
     except ImportError:
@@ -148,6 +148,7 @@ class _TemporaryFileCloser:
     """A separate object allowing proper closing of a temporary file's
     underlying file object, without adding a __del__ method to the
     temporary file."""
+
     file = None  # Set here since __del__ checks it
     close_called = False
 
@@ -291,7 +292,7 @@ def NamedTemporaryFile(
         (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)
     try:
         file = io.open(
-            fd, mode, buffering=buffering, newline=newline, encoding=encoding,
+            fd, mode, buffering=buffering, newline=newline, encoding=encoding
         )
         return _TemporaryFileWrapper(file, name, delete)
 
diff --git a/pipenv/cli.py b/pipenv/cli.py
index 86a28ccf..86eb9866 100644
--- a/pipenv/cli.py
+++ b/pipenv/cli.py
@@ -27,7 +27,7 @@ from .utils import is_valid_url
 
 # Enable shell completion.
 click_completion.init()
-CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])
+CONTEXT_SETTINGS = dict(help_option_names=["-h", "--help"])
 
 
 class PipenvGroup(Group):
@@ -57,14 +57,15 @@ class PipenvGroup(Group):
             is_eager=True,
             expose_value=False,
             callback=show_help,
-            help='Show this message and exit.',
+            help="Show this message and exit.",
         )
 
 
 def setup_verbose(ctx, param, value):
     if value:
         import logging
-        logging.getLogger('pip').setLevel(logging.INFO)
+
+        logging.getLogger("pip").setLevel(logging.INFO)
     return value
 
 
@@ -76,90 +77,66 @@ def validate_python_path(ctx, param, value):
     # we'll report absolute paths which do not exist:
     if isinstance(value, (str, bytes)):
         if os.path.isabs(value) and not os.path.isfile(value):
-            raise BadParameter('Expected Python at path %s does not exist' % value)
+            raise BadParameter("Expected Python at path %s does not exist" % value)
     return value
 
 
 def validate_pypi_mirror(ctx, param, value):
     if value and not is_valid_url(value):
-        raise BadParameter('Invalid PyPI mirror URL: %s' % value)
+        raise BadParameter("Invalid PyPI mirror URL: %s" % value)
     return value
 
 
-@group(
-    cls=PipenvGroup,
-    invoke_without_command=True,
-    context_settings=CONTEXT_SETTINGS,
-)
-@option(
-    '--where',
-    is_flag=True,
-    default=False,
-    help="Output project home information.",
-)
-@option(
-    '--venv',
-    is_flag=True,
-    default=False,
-    help="Output virtualenv information.",
-)
-@option(
-    '--py',
-    is_flag=True,
-    default=False,
-    help="Output Python interpreter information.",
-)
+@group(cls=PipenvGroup, invoke_without_command=True, context_settings=CONTEXT_SETTINGS)
+@option("--where", is_flag=True, default=False, help="Output project home information.")
+@option("--venv", is_flag=True, default=False, help="Output virtualenv information.")
 @option(
-    '--envs',
-    is_flag=True,
-    default=False,
-    help="Output Environment Variable options.",
+    "--py", is_flag=True, default=False, help="Output Python interpreter information."
 )
 @option(
-    '--rm', is_flag=True, default=False, help="Remove the virtualenv."
+    "--envs", is_flag=True, default=False, help="Output Environment Variable options."
 )
-@option('--bare', is_flag=True, default=False, help="Minimal output.")
+@option("--rm", is_flag=True, default=False, help="Remove the virtualenv.")
+@option("--bare", is_flag=True, default=False, help="Minimal output.")
 @option(
-    '--completion',
+    "--completion",
     is_flag=True,
     default=False,
     help="Output completion (to be eval'd).",
 )
-@option('--man', is_flag=True, default=False, help="Display manpage.")
+@option("--man", is_flag=True, default=False, help="Display manpage.")
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--site-packages',
+    "--site-packages",
     is_flag=True,
     default=False,
     help="Enable site-packages for the virtualenv.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
 @option(
-    '--support',
+    "--support",
     is_flag=True,
-    help="Output diagnostic information for use in Github issues."
-)
-@version_option(
-    prog_name=crayons.normal('pipenv', bold=True), version=__version__
+    help="Output diagnostic information for use in Github issues.",
 )
+@version_option(prog_name=crayons.normal("pipenv", bold=True), version=__version__)
 @pass_context
 def cli(
     ctx,
@@ -176,20 +153,21 @@ def cli(
     man=False,
     completion=False,
     pypi_mirror=None,
-    support=None
+    support=None,
 ):
     if completion:  # Handle this ASAP to make shell startup fast.
         from . import shells
+
         try:
             shell = shells.detect_info()[0]
         except shells.ShellDetectionFailure:
             echo(
-                'Fail to detect shell. Please provide the {0} environment '
-                'variable.'.format(crayons.normal('PIPENV_SHELL', bold=True)),
+                "Fail to detect shell. Please provide the {0} environment "
+                "variable.".format(crayons.normal("PIPENV_SHELL", bold=True)),
                 err=True,
             )
             sys.exit(1)
-        print(click_completion.get_code(shell=shell, prog_name='pipenv'))
+        print(click_completion.get_code(shell=shell, prog_name="pipenv"))
         sys.exit(0)
 
     from .core import (
@@ -201,27 +179,24 @@ def cli(
         spinner,
         cleanup_virtualenv,
         ensure_project,
-        format_help
+        format_help,
     )
+
     if man:
-        if system_which('man'):
-            path = os.sep.join([os.path.dirname(__file__), 'pipenv.1'])
-            os.execle(system_which('man'), 'man', path, os.environ)
+        if system_which("man"):
+            path = os.sep.join([os.path.dirname(__file__), "pipenv.1"])
+            os.execle(system_which("man"), "man", path, os.environ)
         else:
-            echo(
-                'man does not appear to be available on your system.', err=True
-            )
+            echo("man does not appear to be available on your system.", err=True)
     if envs:
-        echo(
-            'The following environment variables can be set, to do various things:\n'
-        )
+        echo("The following environment variables can be set, to do various things:\n")
         for key in environments.__dict__:
-            if key.startswith('PIPENV'):
-                echo('  - {0}'.format(crayons.normal(key, bold=True)))
+            if key.startswith("PIPENV"):
+                echo("  - {0}".format(crayons.normal(key, bold=True)))
         echo(
-            '\nYou can learn more at:\n   {0}'.format(
+            "\nYou can learn more at:\n   {0}".format(
                 crayons.green(
-                    'http://docs.pipenv.org/advanced/#configuration-with-environment-variables'
+                    "http://docs.pipenv.org/advanced/#configuration-with-environment-variables"
                 )
             )
         )
@@ -238,6 +213,7 @@ def cli(
         # --support was passed...
         elif support:
             from .help import get_pipenv_diagnostics
+
             get_pipenv_diagnostics()
             sys.exit(0)
         # --venv was passed...
@@ -245,9 +221,7 @@ def cli(
             # There is no virtualenv yet.
             if not project.virtualenv_exists:
                 echo(
-                    crayons.red(
-                        'No virtualenv has been created for this project yet!'
-                    ),
+                    crayons.red("No virtualenv has been created for this project yet!"),
                     err=True,
                 )
                 sys.exit(1)
@@ -260,8 +234,8 @@ def cli(
             if environments.PIPENV_USE_SYSTEM:
                 echo(
                     crayons.red(
-                        'You are attempting to remove a virtualenv that '
-                        'Pipenv did not create. Aborting.'
+                        "You are attempting to remove a virtualenv that "
+                        "Pipenv did not create. Aborting."
                     )
                 )
                 sys.exit(1)
@@ -269,8 +243,8 @@ def cli(
                 loc = project.virtualenv_location
                 echo(
                     crayons.normal(
-                        u'{0} ({1})...'.format(
-                            crayons.normal('Removing virtualenv', bold=True),
+                        u"{0} ({1})...".format(
+                            crayons.normal("Removing virtualenv", bold=True),
                             crayons.green(loc),
                         )
                     )
@@ -282,7 +256,7 @@ def cli(
             else:
                 echo(
                     crayons.red(
-                        'No virtualenv has been created for this project yet!',
+                        "No virtualenv has been created for this project yet!",
                         bold=True,
                     ),
                     err=True,
@@ -291,7 +265,11 @@ def cli(
     # --two / --three was passed...
     if (python or three is not None) or site_packages:
         ensure_project(
-            three=three, python=python, warn=True, site_packages=site_packages, pypi_mirror=pypi_mirror
+            three=three,
+            python=python,
+            warn=True,
+            site_packages=site_packages,
+            pypi_mirror=pypi_mirror,
         )
     # Check this again before exiting for empty ``pipenv`` command.
     elif ctx.invoked_subcommand is None:
@@ -303,91 +281,85 @@ def cli(
     short_help="Installs provided packages and adds them to Pipfile, or (if none is given), installs all packages.",
     context_settings=dict(ignore_unknown_options=True, allow_extra_args=True),
 )
-@argument('package_name', default=False)
-@argument('more_packages', nargs=-1)
+@argument("package_name", default=False)
+@argument("more_packages", nargs=-1)
 @option(
-    '--dev',
-    '-d',
+    "--dev",
+    "-d",
     is_flag=True,
     default=False,
     help="Install package(s) in [dev-packages].",
 )
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
+@option("--system", is_flag=True, default=False, help="System pip management.")
 @option(
-    '--system', is_flag=True, default=False, help="System pip management."
-)
-@option(
-    '--requirements',
-    '-r',
+    "--requirements",
+    "-r",
     nargs=1,
     default=False,
     help="Import a requirements.txt file.",
 )
+@option("--code", "-c", nargs=1, default=False, help="Import from codebase.")
 @option(
-    '--code', '-c', nargs=1, default=False, help="Import from codebase."
-)
-@option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
 @option(
-    '--ignore-pipfile',
+    "--ignore-pipfile",
     is_flag=True,
     default=False,
     help="Ignore Pipfile when installing, using the Pipfile.lock.",
 )
 @option(
-    '--sequential',
+    "--sequential",
     is_flag=True,
     default=False,
     help="Install dependencies one-at-a-time, instead of concurrently.",
 )
 @option(
-    '--skip-lock',
+    "--skip-lock",
     is_flag=True,
     default=False,
     help=u"Ignore locking mechanisms when installing—use the Pipfile, instead.",
 )
 @option(
-    '--deploy',
+    "--deploy",
     is_flag=True,
     default=False,
     help=u"Abort if the Pipfile.lock is out-of-date, or Python version is wrong.",
 )
+@option("--pre", is_flag=True, default=False, help=u"Allow pre-releases.")
 @option(
-    '--pre', is_flag=True, default=False, help=u"Allow pre-releases."
-)
-@option(
-    '--keep-outdated',
+    "--keep-outdated",
     is_flag=True,
     default=False,
     help=u"Keep out-dated dependencies from being updated in Pipfile.lock.",
 )
 @option(
-    '--selective-upgrade',
+    "--selective-upgrade",
     is_flag=True,
     default=False,
     help="Update specified packages.",
@@ -436,56 +408,52 @@ def install(
     )
 
 
-@command(
-    short_help="Un-installs a provided package and removes it from Pipfile."
-)
-@argument('package_name', default=False)
-@argument('more_packages', nargs=-1)
+@command(short_help="Un-installs a provided package and removes it from Pipfile.")
+@argument("package_name", default=False)
+@argument("more_packages", nargs=-1)
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
+@option("--system", is_flag=True, default=False, help="System pip management.")
 @option(
-    '--system', is_flag=True, default=False, help="System pip management."
-)
-@option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
-@option('--lock', is_flag=True, default=True, help="Lock afterwards.")
+@option("--lock", is_flag=True, default=True, help="Lock afterwards.")
 @option(
-    '--all-dev',
+    "--all-dev",
     is_flag=True,
     default=False,
     help="Un-install all package from [dev-packages].",
 )
 @option(
-    '--all',
+    "--all",
     is_flag=True,
     default=False,
     help="Purge all package(s) from virtualenv. Does not edit Pipfile.",
 )
 @option(
-    '--keep-outdated',
+    "--keep-outdated",
     is_flag=True,
     default=False,
     help=u"Keep out-dated dependencies from being updated in Pipfile.lock.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
@@ -523,55 +491,51 @@ def uninstall(
 
 @command(short_help="Generates Pipfile.lock.")
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
 @option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
 @option(
-    '--requirements',
-    '-r',
+    "--requirements",
+    "-r",
     is_flag=True,
     default=False,
     help="Generate output compatible with requirements.txt.",
 )
 @option(
-    '--dev',
-    '-d',
+    "--dev",
+    "-d",
     is_flag=True,
     default=False,
     help="Generate output compatible with requirements.txt for the development dependencies.",
 )
+@option("--clear", is_flag=True, default=False, help="Clear the dependency cache.")
+@option("--pre", is_flag=True, default=False, help=u"Allow pre-releases.")
 @option(
-    '--clear', is_flag=True, default=False, help="Clear the dependency cache."
-)
-@option(
-    '--pre', is_flag=True, default=False, help=u"Allow pre-releases."
-)
-@option(
-    '--keep-outdated',
+    "--keep-outdated",
     is_flag=True,
     default=False,
     help=u"Keep out-dated dependencies from being updated in Pipfile.lock.",
@@ -594,7 +558,11 @@ def lock(
     if requirements:
         do_init(dev=dev, requirements=requirements, pypi_mirror=pypi_mirror)
     do_lock(
-        verbose=verbose, clear=clear, pre=pre, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror
+        verbose=verbose,
+        clear=clear,
+        pre=pre,
+        keep_outdated=keep_outdated,
+        pypi_mirror=pypi_mirror,
     )
 
 
@@ -603,54 +571,58 @@ def lock(
     context_settings=dict(ignore_unknown_options=True, allow_extra_args=True),
 )
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--fancy',
+    "--fancy",
     is_flag=True,
     default=False,
     help="Run in shell in fancy mode (for elegantly configured shells).",
 )
 @option(
-    '--anyway',
+    "--anyway",
     is_flag=True,
     default=False,
     help="Always spawn a subshell, even if one is already spawned.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
-@argument('shell_args', nargs=-1)
+@argument("shell_args", nargs=-1)
 def shell(
-    three=None, python=False, fancy=False, shell_args=None, anyway=False, pypi_mirror=None
+    three=None,
+    python=False,
+    fancy=False,
+    shell_args=None,
+    anyway=False,
+    pypi_mirror=None,
 ):
     from .core import load_dot_env, do_shell
+
     # Prevent user from activating nested environments.
-    if 'PIPENV_ACTIVE' in os.environ:
+    if "PIPENV_ACTIVE" in os.environ:
         # If PIPENV_ACTIVE is set, VIRTUAL_ENV should always be set too.
-        venv_name = os.environ.get(
-            'VIRTUAL_ENV', 'UNKNOWN_VIRTUAL_ENVIRONMENT'
-        )
+        venv_name = os.environ.get("VIRTUAL_ENV", "UNKNOWN_VIRTUAL_ENVIRONMENT")
         if not anyway:
             echo(
-                '{0} {1} {2}\nNo action taken to avoid nested environments.'.format(
-                    crayons.normal('Shell for'),
+                "{0} {1} {2}\nNo action taken to avoid nested environments.".format(
+                    crayons.normal("Shell for"),
                     crayons.green(venv_name, bold=True),
-                    crayons.normal('already activated.', bold=True),
+                    crayons.normal("already activated.", bold=True),
                 ),
                 err=True,
             )
@@ -658,10 +630,14 @@ def shell(
     # Load .env file.
     load_dot_env()
     # Use fancy mode for Windows.
-    if os.name == 'nt':
+    if os.name == "nt":
         fancy = True
     do_shell(
-        three=three, python=python, fancy=fancy, shell_args=shell_args, pypi_mirror=pypi_mirror
+        three=three,
+        python=python,
+        fancy=fancy,
+        shell_args=shell_args,
+        pypi_mirror=pypi_mirror,
     )
 
 
@@ -674,23 +650,23 @@ def shell(
         allow_extra_args=True,
     ),
 )
-@argument('command')
-@argument('args', nargs=-1)
+@argument("command")
+@argument("args", nargs=-1)
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
@@ -698,7 +674,10 @@ def shell(
 )
 def run(command, args, three=None, python=False, pypi_mirror=None):
     from .core import do_run
-    do_run(command=command, args=args, three=three, python=python, pypi_mirror=pypi_mirror)
+
+    do_run(
+        command=command, args=args, three=three, python=python, pypi_mirror=pypi_mirror
+    )
 
 
 @command(
@@ -706,41 +685,39 @@ def run(command, args, three=None, python=False, pypi_mirror=None):
     context_settings=dict(ignore_unknown_options=True, allow_extra_args=True),
 )
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
+@option("--system", is_flag=True, default=False, help="Use system Python.")
 @option(
-    '--system', is_flag=True, default=False, help="Use system Python."
-)
-@option(
-    '--unused',
+    "--unused",
     nargs=1,
     default=False,
     help="Given a code path, show potentially unused dependencies.",
 )
 @option(
-    '--ignore',
-    '-i',
+    "--ignore",
+    "-i",
     multiple=True,
-    help="Ignore specified vulnerability during safety checks."
+    help="Ignore specified vulnerability during safety checks.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
-@argument('args', nargs=-1)
+@argument("args", nargs=-1)
 def check(
     three=None,
     python=False,
@@ -752,6 +729,7 @@ def check(
     pypi_mirror=None,
 ):
     from .core import do_check
+
     do_check(
         three=three,
         python=python,
@@ -759,79 +737,67 @@ def check(
         unused=unused,
         ignore=ignore,
         args=args,
-        pypi_mirror=pypi_mirror
+        pypi_mirror=pypi_mirror,
     )
 
 
 @command(short_help="Runs lock, then sync.")
-@argument('more_packages', nargs=-1)
+@argument("more_packages", nargs=-1)
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
 @option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
 @option(
-    '--dev',
-    '-d',
+    "--dev",
+    "-d",
     is_flag=True,
     default=False,
     help="Install package(s) in [dev-packages].",
 )
+@option("--clear", is_flag=True, default=False, help="Clear the dependency cache.")
+@option("--bare", is_flag=True, default=False, help="Minimal output.")
+@option("--pre", is_flag=True, default=False, help=u"Allow pre-releases.")
 @option(
-    '--clear', is_flag=True, default=False, help="Clear the dependency cache."
-)
-@option('--bare', is_flag=True, default=False, help="Minimal output.")
-@option(
-    '--pre', is_flag=True, default=False, help=u"Allow pre-releases."
-)
-@option(
-    '--keep-outdated',
+    "--keep-outdated",
     is_flag=True,
     default=False,
     help=u"Keep out-dated dependencies from being updated in Pipfile.lock.",
 )
 @option(
-    '--sequential',
+    "--sequential",
     is_flag=True,
     default=False,
     help="Install dependencies one-at-a-time, instead of concurrently.",
 )
 @option(
-    '--outdated',
-    is_flag=True,
-    default=False,
-    help=u"List out-of-date dependencies.",
-)
-@option(
-    '--dry-run',
-    is_flag=True,
-    default=None,
-    help=u"List out-of-date dependencies.",
+    "--outdated", is_flag=True, default=False, help=u"List out-of-date dependencies."
 )
-@argument('package', default=False)
+@option("--dry-run", is_flag=True, default=None, help=u"List out-of-date dependencies.")
+@argument("package", default=False)
 @pass_context
 def update(
     ctx,
@@ -868,28 +834,32 @@ def update(
         do_outdated(pypi_mirror=pypi_mirror)
     if not package:
         echo(
-            '{0} {1} {2} {3}{4}'.format(
-                crayons.white('Running', bold=True),
-                crayons.red('$ pipenv lock', bold=True),
-                crayons.white('then', bold=True),
-                crayons.red('$ pipenv sync', bold=True),
-                crayons.white('.', bold=True),
+            "{0} {1} {2} {3}{4}".format(
+                crayons.white("Running", bold=True),
+                crayons.red("$ pipenv lock", bold=True),
+                crayons.white("then", bold=True),
+                crayons.red("$ pipenv sync", bold=True),
+                crayons.white(".", bold=True),
             )
         )
     else:
-        for package in ([package] + list(more_packages) or []):
+        for package in [package] + list(more_packages) or []:
             if package not in project.all_packages:
                 echo(
-                    '{0}: {1} was not found in your Pipfile! Aborting.'
-                    ''.format(
-                        crayons.red('Warning', bold=True),
+                    "{0}: {1} was not found in your Pipfile! Aborting."
+                    "".format(
+                        crayons.red("Warning", bold=True),
                         crayons.green(package, bold=True),
                     ),
                     err=True,
                 )
                 sys.exit(1)
     do_lock(
-        verbose=verbose, clear=clear, pre=pre, keep_outdated=keep_outdated, pypi_mirror=pypi_mirror
+        verbose=verbose,
+        clear=clear,
+        pre=pre,
+        keep_outdated=keep_outdated,
+        pypi_mirror=pypi_mirror,
     )
     do_sync(
         ctx=ctx,
@@ -907,15 +877,11 @@ def update(
     )
 
 
-@command(
-    short_help=u"Displays currently-installed dependency graph information."
-)
-@option('--bare', is_flag=True, default=False, help="Minimal output.")
-@option('--json', is_flag=True, default=False, help="Output JSON.")
-@option('--json-tree', is_flag=True, default=False, help="Output JSON in nested tree.")
-@option(
-    '--reverse', is_flag=True, default=False, help="Reversed dependency graph."
-)
+@command(short_help=u"Displays currently-installed dependency graph information.")
+@option("--bare", is_flag=True, default=False, help="Minimal output.")
+@option("--json", is_flag=True, default=False, help="Output JSON.")
+@option("--json-tree", is_flag=True, default=False, help="Output JSON in nested tree.")
+@option("--reverse", is_flag=True, default=False, help="Reversed dependency graph.")
 def graph(bare=False, json=False, json_tree=False, reverse=False):
     from .core import do_graph
 
@@ -924,94 +890,88 @@ def graph(bare=False, json=False, json_tree=False, reverse=False):
 
 @command(short_help="View a given module in your editor.", name="open")
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
-@argument('module', nargs=1)
+@argument("module", nargs=1)
 def run_open(module, three=None, python=None, pypi_mirror=None):
     from .core import which, ensure_project
 
     # Ensure that virtualenv is available.
     ensure_project(three=three, python=python, validate=False, pypi_mirror=pypi_mirror)
     c = delegator.run(
-        '{0} -c "import {1}; print({1}.__file__);"'.format(
-            which('python'), module
-        )
+        '{0} -c "import {1}; print({1}.__file__);"'.format(which("python"), module)
     )
     try:
         assert c.return_code == 0
     except AssertionError:
-        echo(crayons.red('Module not found!'))
+        echo(crayons.red("Module not found!"))
         sys.exit(1)
-    if '__init__.py' in c.out:
-        p = os.path.dirname(c.out.strip().rstrip('cdo'))
+    if "__init__.py" in c.out:
+        p = os.path.dirname(c.out.strip().rstrip("cdo"))
     else:
-        p = c.out.strip().rstrip('cdo')
-    echo(
-        crayons.normal('Opening {0!r} in your EDITOR.'.format(p), bold=True)
-    )
+        p = c.out.strip().rstrip("cdo")
+    echo(crayons.normal("Opening {0!r} in your EDITOR.".format(p), bold=True))
     edit(filename=p)
     sys.exit(0)
 
 
 @command(short_help="Installs all packages specified in Pipfile.lock.")
 @option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
 @option(
-    '--dev',
-    '-d',
+    "--dev",
+    "-d",
     is_flag=True,
     default=False,
     help="Additionally install package(s) in [dev-packages].",
 )
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
 @option(
-    '--pypi-mirror',
+    "--pypi-mirror",
     default=environments.PIPENV_PYPI_MIRROR,
     nargs=1,
     callback=validate_pypi_mirror,
     help="Specify a PyPI mirror.",
 )
-@option('--bare', is_flag=True, default=False, help="Minimal output.")
-@option(
-    '--clear', is_flag=True, default=False, help="Clear the dependency cache."
-)
+@option("--bare", is_flag=True, default=False, help="Minimal output.")
+@option("--clear", is_flag=True, default=False, help="Clear the dependency cache.")
 @option(
-    '--sequential',
+    "--sequential",
     is_flag=True,
     default=False,
     help="Install dependencies one-at-a-time, instead of concurrently.",
@@ -1050,51 +1010,36 @@ def sync(
     )
 
 
-@command(
-    short_help="Uninstalls all packages not specified in Pipfile.lock."
-)
+@command(short_help="Uninstalls all packages not specified in Pipfile.lock.")
 @option(
-    '--verbose',
-    '-v',
+    "--verbose",
+    "-v",
     is_flag=True,
     default=False,
     help="Verbose mode.",
     callback=setup_verbose,
 )
 @option(
-    '--three/--two',
+    "--three/--two",
     is_flag=True,
     default=None,
     help="Use Python 3/2 when creating virtualenv.",
 )
 @option(
-    '--python',
+    "--python",
     default=False,
     nargs=1,
     callback=validate_python_path,
     help="Specify which version of Python virtualenv should use.",
 )
-@option(
-    '--dry-run',
-    is_flag=True,
-    default=False,
-    help="Just output unneeded packages.",
-)
+@option("--dry-run", is_flag=True, default=False, help="Just output unneeded packages.")
 @pass_context
 def clean(
-    ctx,
-    three=None,
-    python=None,
-    dry_run=False,
-    bare=False,
-    user=False,
-    verbose=False,
+    ctx, three=None, python=None, dry_run=False, bare=False, user=False, verbose=False
 ):
     from .core import do_clean
 
-    do_clean(
-        ctx=ctx, three=three, python=python, dry_run=dry_run, verbose=verbose
-    )
+    do_clean(ctx=ctx, three=three, python=python, dry_run=dry_run, verbose=verbose)
 
 
 # Install click commands.
@@ -1110,7 +1055,7 @@ cli.add_command(run)
 cli.add_command(update)
 cli.add_command(run_open)
 # Only invoke the "did you mean" when an argument wasn't passed (it breaks those).
-if '-' not in ''.join(sys.argv) and len(sys.argv) > 1:
+if "-" not in "".join(sys.argv) and len(sys.argv) > 1:
     cli = DYMCommandCollection(sources=[cli])
-if __name__ == '__main__':
+if __name__ == "__main__":
     cli()
diff --git a/pipenv/cmdparse.py b/pipenv/cmdparse.py
index 0c2eebad..aa3442b8 100644
--- a/pipenv/cmdparse.py
+++ b/pipenv/cmdparse.py
@@ -13,6 +13,7 @@ class Script(object):
 
     This always works in POSIX mode, even on Windows.
     """
+
     def __init__(self, command, args=None):
         self._parts = [command]
         if args:
@@ -27,7 +28,7 @@ class Script(object):
         return cls(value[0], value[1:])
 
     def __repr__(self):
-        return 'Script({0!r})'.format(self._parts)
+        return "Script({0!r})".format(self._parts)
 
     @property
     def command(self):
@@ -59,7 +60,6 @@ class Script(object):
 
         See also: https://docs.python.org/3/library/subprocess.html#converting-argument-sequence
         """
-        return ' '.join(
-            '"{0}"'.format(re.sub(r'(\\*)"', r'\1\1\\"', arg))
-            for arg in self._parts
+        return " ".join(
+            '"{0}"'.format(re.sub(r'(\\*)"', r'\1\1\\"', arg)) for arg in self._parts
         )
diff --git a/pipenv/environments.py b/pipenv/environments.py
index 3ab5eefc..ba041e9b 100644
--- a/pipenv/environments.py
+++ b/pipenv/environments.py
@@ -2,81 +2,79 @@ import os
 import sys
 from appdirs import user_cache_dir
 
-os.environ['PYTHONDONTWRITEBYTECODE'] = '1'
+os.environ["PYTHONDONTWRITEBYTECODE"] = "1"
 
 # Prevent invalid shebangs with Homebrew-installed Python:
 # https://bugs.python.org/issue22490
-os.environ.pop('__PYVENV_LAUNCHER__', None)
+os.environ.pop("__PYVENV_LAUNCHER__", None)
 # Shell compatibility mode, for mis-configured shells.
-PIPENV_SHELL_FANCY = bool(os.environ.get('PIPENV_SHELL_FANCY'))
+PIPENV_SHELL_FANCY = bool(os.environ.get("PIPENV_SHELL_FANCY"))
 # Support for both Python 2 and Python 3 at the same time.
-PIPENV_PYTHON = os.environ.get('PIPENV_PYTHON')
+PIPENV_PYTHON = os.environ.get("PIPENV_PYTHON")
 # Create the virtualenv in the project, instead of with pew.
-PIPENV_VENV_IN_PROJECT = bool(
-    os.environ.get('PIPENV_VENV_IN_PROJECT')
-)
+PIPENV_VENV_IN_PROJECT = bool(os.environ.get("PIPENV_VENV_IN_PROJECT"))
 # Overwrite all index funcitonality.
-PIPENV_TEST_INDEX = os.environ.get('PIPENV_TEST_INDEX')
+PIPENV_TEST_INDEX = os.environ.get("PIPENV_TEST_INDEX")
 # No color mode, for unfun people.
-PIPENV_COLORBLIND = bool(os.environ.get('PIPENV_COLORBLIND'))
+PIPENV_COLORBLIND = bool(os.environ.get("PIPENV_COLORBLIND"))
 # Disable spinner for better test and deploy logs (for the unworthy).
-PIPENV_NOSPIN = bool(os.environ.get('PIPENV_NOSPIN'))
+PIPENV_NOSPIN = bool(os.environ.get("PIPENV_NOSPIN"))
 # Tells Pipenv how many rounds of resolving to do for Pip-Tools.
-PIPENV_MAX_ROUNDS = int(os.environ.get('PIPENV_MAX_ROUNDS', '16'))
+PIPENV_MAX_ROUNDS = int(os.environ.get("PIPENV_MAX_ROUNDS", "16"))
 # Specify how many retries Pipenv should attempt for network requests.
-default_retries = '1' if 'CI' in os.environ else '0'
-PIPENV_MAX_RETRIES = int(os.environ.get('PIPENV_MAX_RETRIES', default_retries))
+default_retries = "1" if "CI" in os.environ else "0"
+PIPENV_MAX_RETRIES = int(os.environ.get("PIPENV_MAX_RETRIES", default_retries))
 # Specify a custom Pipfile location.
-PIPENV_PIPFILE = os.environ.get('PIPENV_PIPFILE')
+PIPENV_PIPFILE = os.environ.get("PIPENV_PIPFILE")
 # Tells Pipenv which Python to default to, when none is provided.
-PIPENV_DEFAULT_PYTHON_VERSION = os.environ.get('PIPENV_DEFAULT_PYTHON_VERSION')
+PIPENV_DEFAULT_PYTHON_VERSION = os.environ.get("PIPENV_DEFAULT_PYTHON_VERSION")
 # Tells Pipenv to not load .env files.
-PIPENV_DONT_LOAD_ENV = bool(os.environ.get('PIPENV_DONT_LOAD_ENV'))
+PIPENV_DONT_LOAD_ENV = bool(os.environ.get("PIPENV_DONT_LOAD_ENV"))
 # Tell Pipenv to default to yes at all prompts.
-PIPENV_YES = bool(os.environ.get('PIPENV_YES'))
+PIPENV_YES = bool(os.environ.get("PIPENV_YES"))
 # Tells Pipenv how many subprocesses to use when installing.
-PIPENV_MAX_SUBPROCESS = int(os.environ.get('PIPENV_MAX_SUBPROCESS', '16'))
+PIPENV_MAX_SUBPROCESS = int(os.environ.get("PIPENV_MAX_SUBPROCESS", "16"))
 # User-configurable max-depth for Pipfile searching.
 # Note: +1 because of a temporary bug in Pipenv.
-PIPENV_MAX_DEPTH = int(os.environ.get('PIPENV_MAX_DEPTH', '3')) + 1
+PIPENV_MAX_DEPTH = int(os.environ.get("PIPENV_MAX_DEPTH", "3")) + 1
 # Tell Pipenv not to inherit parent directories (for development, mostly).
-PIPENV_NO_INHERIT = 'PIPENV_NO_INHERIT' in os.environ
+PIPENV_NO_INHERIT = "PIPENV_NO_INHERIT" in os.environ
 if PIPENV_NO_INHERIT:
     PIPENV_MAX_DEPTH = 2
 # Tells Pipenv to use the virtualenv-provided pip instead.
 PIPENV_VIRTUALENV = None
 PIPENV_USE_SYSTEM = False
-if 'PIPENV_ACTIVE' not in os.environ:
-    if 'PIPENV_IGNORE_VIRTUALENVS' not in os.environ:
-        PIPENV_VIRTUALENV = os.environ.get('VIRTUAL_ENV')
-        PIPENV_USE_SYSTEM = bool(os.environ.get('VIRTUAL_ENV'))
+if "PIPENV_ACTIVE" not in os.environ:
+    if "PIPENV_IGNORE_VIRTUALENVS" not in os.environ:
+        PIPENV_VIRTUALENV = os.environ.get("VIRTUAL_ENV")
+        PIPENV_USE_SYSTEM = bool(os.environ.get("VIRTUAL_ENV"))
 # Tells Pipenv to use hashing mode.
 PIPENV_USE_HASHES = True
 # Tells Pipenv to skip case-checking (slow internet connections).
 PIPENV_SKIP_VALIDATION = True
 # Tells Pipenv where to load .env from.
-PIPENV_DOTENV_LOCATION = os.environ.get('PIPENV_DOTENV_LOCATION')
+PIPENV_DOTENV_LOCATION = os.environ.get("PIPENV_DOTENV_LOCATION")
 # Disable spinner on Windows.
-if os.name == 'nt':
+if os.name == "nt":
     PIPENV_NOSPIN = True
 # Disable the spinner on Travis-Ci (and friends).
-if 'CI' in os.environ:
+if "CI" in os.environ:
     PIPENV_NOSPIN = True
-PIPENV_HIDE_EMOJIS = bool(os.environ.get('PIPENV_HIDE_EMOJIS'))
-if os.name == 'nt':
+PIPENV_HIDE_EMOJIS = bool(os.environ.get("PIPENV_HIDE_EMOJIS"))
+if os.name == "nt":
     PIPENV_HIDE_EMOJIS = True
 # Tells Pipenv how long to wait for virtualenvs to be created in seconds.
-PIPENV_TIMEOUT = int(os.environ.get('PIPENV_TIMEOUT', 120))
+PIPENV_TIMEOUT = int(os.environ.get("PIPENV_TIMEOUT", 120))
 PIPENV_INSTALL_TIMEOUT = 60 * 15
-PIPENV_DONT_USE_PYENV = os.environ.get('PIPENV_DONT_USE_PYENV')
-PYENV_ROOT = os.environ.get('PYENV_ROOT', os.path.expanduser('~/.pyenv'))
-PYENV_INSTALLED = (
-    bool(os.environ.get('PYENV_SHELL')) or bool(os.environ.get('PYENV_ROOT'))
+PIPENV_DONT_USE_PYENV = os.environ.get("PIPENV_DONT_USE_PYENV")
+PYENV_ROOT = os.environ.get("PYENV_ROOT", os.path.expanduser("~/.pyenv"))
+PYENV_INSTALLED = bool(os.environ.get("PYENV_SHELL")) or bool(
+    os.environ.get("PYENV_ROOT")
 )
 SESSION_IS_INTERACTIVE = bool(os.isatty(sys.stdout.fileno()))
-PIPENV_SHELL_EXPLICIT = os.environ.get('PIPENV_SHELL')
-PIPENV_SHELL = os.environ.get('SHELL') or os.environ.get('PYENV_SHELL')
-PIPENV_EMULATOR = os.environ.get('PIPENV_EMULATOR')
-PIPENV_CACHE_DIR = os.environ.get('PIPENV_CACHE_DIR', user_cache_dir('pipenv'))
+PIPENV_SHELL_EXPLICIT = os.environ.get("PIPENV_SHELL")
+PIPENV_SHELL = os.environ.get("SHELL") or os.environ.get("PYENV_SHELL")
+PIPENV_EMULATOR = os.environ.get("PIPENV_EMULATOR")
+PIPENV_CACHE_DIR = os.environ.get("PIPENV_CACHE_DIR", user_cache_dir("pipenv"))
 # Tells pipenv to override PyPI index urls with a mirror.
-PIPENV_PYPI_MIRROR = os.environ.get('PIPENV_PYPI_MIRROR')
+PIPENV_PYPI_MIRROR = os.environ.get("PIPENV_PYPI_MIRROR")
diff --git a/pipenv/help.py b/pipenv/help.py
index 4f853266..32ffa7c0 100644
--- a/pipenv/help.py
+++ b/pipenv/help.py
@@ -13,85 +13,80 @@ def print_utf(line):
     try:
         print(line)
     except UnicodeEncodeError:
-        print(line.encode('utf-8'))
+        print(line.encode("utf-8"))
 
 
 def get_pipenv_diagnostics():
-    print('<details><summary>$ pipenv --support</summary>')
-    print('')
-    print('Pipenv version: `{0!r}`'.format(__version__))
-    print('')
-    print('Pipenv location: `{0!r}`'.format(os.path.dirname(pipenv.__file__)))
-    print('')
-    print('Python location: `{0!r}`'.format(sys.executable))
-    print('')
-    print('Other Python installations in `PATH`:')
-    print('')
-    for python_v in ('2.5', '2.6', '2.7', '3.4', '3.5', '3.6', '3.7'):
+    print("<details><summary>$ pipenv --support</summary>")
+    print("")
+    print("Pipenv version: `{0!r}`".format(__version__))
+    print("")
+    print("Pipenv location: `{0!r}`".format(os.path.dirname(pipenv.__file__)))
+    print("")
+    print("Python location: `{0!r}`".format(sys.executable))
+    print("")
+    print("Other Python installations in `PATH`:")
+    print("")
+    for python_v in ("2.5", "2.6", "2.7", "3.4", "3.5", "3.6", "3.7"):
         found = find_python_in_path(python_v)
         if found:
-            print('  - `{0}`: `{1}`'.format(python_v, found))
-        found = system_which('python{0}'.format(python_v), mult=True)
+            print("  - `{0}`: `{1}`".format(python_v, found))
+        found = system_which("python{0}".format(python_v), mult=True)
         if found:
             for f in found:
-                print('  - `{0}`: `{1}`'.format(python_v, f))
-    print('')
-    for p in ('python', 'python2', 'python3', 'py'):
+                print("  - `{0}`: `{1}`".format(python_v, f))
+    print("")
+    for p in ("python", "python2", "python3", "py"):
         found = system_which(p, mult=True)
         for f in found:
-            print('  - `{0}`: `{1}`'.format(python_version(f), f))
-    print('')
-    print('PEP 508 Information:')
-    print('')
-    print('```')
+            print("  - `{0}`: `{1}`".format(python_version(f), f))
+    print("")
+    print("PEP 508 Information:")
+    print("")
+    print("```")
     pprint(lookup)
-    print('```')
-    print('')
-    print('System environment variables:')
-    print('')
+    print("```")
+    print("")
+    print("System environment variables:")
+    print("")
     for key in os.environ:
-        print('  - `{0}`'.format(key))
-    print('')
-    print_utf(u'Pipenv–specific environment variables:')
-    print('')
+        print("  - `{0}`".format(key))
+    print("")
+    print_utf(u"Pipenv–specific environment variables:")
+    print("")
     for key in os.environ:
-        if key.startswith('PIPENV'):
-            print(' - `{0}`: `{1}`'.format(key, os.environ[key]))
-    print('')
-    print_utf(u'Debug–specific environment variables:')
-    print('')
-    for key in ('PATH', 'SHELL', 'EDITOR', 'LANG', 'PWD', 'VIRTUAL_ENV'):
+        if key.startswith("PIPENV"):
+            print(" - `{0}`: `{1}`".format(key, os.environ[key]))
+    print("")
+    print_utf(u"Debug–specific environment variables:")
+    print("")
+    for key in ("PATH", "SHELL", "EDITOR", "LANG", "PWD", "VIRTUAL_ENV"):
         if key in os.environ:
-            print('  - `{0}`: `{1}`'.format(key, os.environ[key]))
-    print('')
-    print('')
-    print('---------------------------')
-    print('')
+            print("  - `{0}`: `{1}`".format(key, os.environ[key]))
+    print("")
+    print("")
+    print("---------------------------")
+    print("")
     if project.pipfile_exists:
-        print_utf(
-            u'Contents of `Pipfile` ({0!r}):'.format(project.pipfile_location)
-        )
-        print('')
-        print('```toml')
-        with open(project.pipfile_location, 'r') as f:
+        print_utf(u"Contents of `Pipfile` ({0!r}):".format(project.pipfile_location))
+        print("")
+        print("```toml")
+        with open(project.pipfile_location, "r") as f:
             print(f.read())
-        print('```')
-        print('')
+        print("```")
+        print("")
     if project.lockfile_exists:
-        print('')
+        print("")
         print_utf(
-            u'Contents of `Pipfile.lock` ({0!r}):'.format(
-                project.lockfile_location
-            )
+            u"Contents of `Pipfile.lock` ({0!r}):".format(project.lockfile_location)
         )
-        print('')
-        print('```json')
-        with open(project.lockfile_location, 'r') as f:
+        print("")
+        print("```json")
+        with open(project.lockfile_location, "r") as f:
             print(f.read())
-        print('```')
-    print('</details>')
+        print("```")
+    print("</details>")
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     get_pipenv_diagnostics()
-
diff --git a/pipenv/pep508checker.py b/pipenv/pep508checker.py
index 1bcf4226..724be7cc 100644
--- a/pipenv/pep508checker.py
+++ b/pipenv/pep508checker.py
@@ -6,35 +6,35 @@ import json
 
 
 def format_full_version(info):
-    version = '{0.major}.{0.minor}.{0.micro}'.format(info)
+    version = "{0.major}.{0.minor}.{0.micro}".format(info)
     kind = info.releaselevel
-    if kind != 'final':
+    if kind != "final":
         version += kind[0] + str(info.serial)
     return version
 
 
 # Support for 508's implementation_version.
-if hasattr(sys, 'implementation'):
+if hasattr(sys, "implementation"):
     implementation_version = format_full_version(sys.implementation.version)
 else:
-    implementation_version = '0'
+    implementation_version = "0"
 # Default to cpython for 2.7.
-if hasattr(sys, 'implementation'):
+if hasattr(sys, "implementation"):
     implementation_name = sys.implementation.name
 else:
-    implementation_name = 'cpython'
+    implementation_name = "cpython"
 lookup = {
-    'os_name': os.name,
-    'sys_platform': sys.platform,
-    'platform_machine': platform.machine(),
-    'platform_python_implementation': platform.python_implementation(),
-    'platform_release': platform.release(),
-    'platform_system': platform.system(),
-    'platform_version': platform.version(),
-    'python_version': platform.python_version()[:3],
-    'python_full_version': platform.python_version(),
-    'implementation_name': implementation_name,
-    'implementation_version': implementation_version,
+    "os_name": os.name,
+    "sys_platform": sys.platform,
+    "platform_machine": platform.machine(),
+    "platform_python_implementation": platform.python_implementation(),
+    "platform_release": platform.release(),
+    "platform_system": platform.system(),
+    "platform_version": platform.version(),
+    "python_version": platform.python_version()[:3],
+    "python_full_version": platform.python_version(),
+    "implementation_name": implementation_name,
+    "implementation_version": implementation_version,
 }
-if __name__ == '__main__':
+if __name__ == "__main__":
     print(json.dumps(lookup))
diff --git a/pipenv/progress.py b/pipenv/progress.py
index 256bec9d..4cea195c 100644
--- a/pipenv/progress.py
+++ b/pipenv/progress.py
@@ -13,39 +13,39 @@ import os
 import sys
 import time
 import crayons
-from .environments import (PIPENV_COLORBLIND, PIPENV_HIDE_EMOJIS)
+from .environments import PIPENV_COLORBLIND, PIPENV_HIDE_EMOJIS
 
 STREAM = sys.stderr
-MILL_TEMPLATE = '%s %s %i/%i\r'
-DOTS_CHAR = '.'
-if os.name != 'nt':
+MILL_TEMPLATE = "%s %s %i/%i\r"
+DOTS_CHAR = "."
+if os.name != "nt":
     if PIPENV_HIDE_EMOJIS:
         if PIPENV_COLORBLIND:
-            BAR_FILLED_CHAR = '='
-            BAR_EMPTY_CHAR = '-'
+            BAR_FILLED_CHAR = "="
+            BAR_EMPTY_CHAR = "-"
         else:
-            BAR_FILLED_CHAR = str(crayons.green('=', bold=True))
-            BAR_EMPTY_CHAR = str(crayons.black('-'))
+            BAR_FILLED_CHAR = str(crayons.green("=", bold=True))
+            BAR_EMPTY_CHAR = str(crayons.black("-"))
     else:
         if PIPENV_COLORBLIND:
-            BAR_FILLED_CHAR = '▉'
-            BAR_EMPTY_CHAR = ' '
+            BAR_FILLED_CHAR = "▉"
+            BAR_EMPTY_CHAR = " "
         else:
-            BAR_FILLED_CHAR = str(crayons.green('▉', bold=True))
-            BAR_EMPTY_CHAR = str(crayons.black('▉'))
+            BAR_FILLED_CHAR = str(crayons.green("▉", bold=True))
+            BAR_EMPTY_CHAR = str(crayons.black("▉"))
 
 else:
-    BAR_FILLED_CHAR = '='
-    BAR_EMPTY_CHAR = '-'
+    BAR_FILLED_CHAR = "="
+    BAR_EMPTY_CHAR = "-"
 
-if (sys.version_info[0] >= 3) and (os.name != 'nt'):
-    BAR_TEMPLATE = u'  %s%s%s %i/%i — {0}\r'.format(crayons.black('%s'))
+if (sys.version_info[0] >= 3) and (os.name != "nt"):
+    BAR_TEMPLATE = u"  %s%s%s %i/%i — {0}\r".format(crayons.black("%s"))
 else:
-    if os.name == 'nt':
-        BAR_TEMPLATE = '  %s%s%s %i/%i - %s\r'
+    if os.name == "nt":
+        BAR_TEMPLATE = "  %s%s%s %i/%i - %s\r"
     else:
-        BAR_TEMPLATE = '  %s%s%s %i/%i — %s\r'
-MILL_CHARS = ['|', '/', '-', '\\']
+        BAR_TEMPLATE = "  %s%s%s %i/%i — %s\r"
+MILL_CHARS = ["|", "/", "-", "\\"]
 # How long to wait before recalculating the ETA
 ETA_INTERVAL = 1
 # How many intervals (excluding the current one) to calculate the simple moving
@@ -54,7 +54,6 @@ ETA_SMA_WINDOW = 9
 
 
 class Bar(object):
-
     def __enter__(self):
         return self
 
@@ -64,7 +63,7 @@ class Bar(object):
 
     def __init__(
         self,
-        label='',
+        label="",
         width=32,
         hide=None,
         empty_char=BAR_EMPTY_CHAR,
@@ -91,7 +90,7 @@ class Bar(object):
         self.etadelta = time.time()
         self.etadisp = self.format_time(self.eta)
         self.last_progress = 0
-        if (self.expected_size):
+        if self.expected_size:
             self.show(0)
 
     def show(self, progress, count=None):
@@ -104,21 +103,22 @@ class Bar(object):
         if (time.time() - self.etadelta) > ETA_INTERVAL:
             self.etadelta = time.time()
             self.ittimes = self.ittimes[-ETA_SMA_WINDOW:] + [
-                - (self.start - time.time()) / (progress + 1)
+                -(self.start - time.time()) / (progress + 1)
             ]
-            self.eta = sum(self.ittimes) / float(len(self.ittimes)) * (
-                self.expected_size - progress
+            self.eta = (
+                sum(self.ittimes)
+                / float(len(self.ittimes))
+                * (self.expected_size - progress)
             )
             self.etadisp = self.format_time(self.eta)
         x = int(self.width * progress / self.expected_size)
         if not self.hide:
-            if (
-                (progress % self.every) == 0 or  # True every "every" updates
-                (progress == self.expected_size)
+            if (progress % self.every) == 0 or (  # True every "every" updates
+                progress == self.expected_size
             ):  # And when we're done
                 STREAM.write(
-                    BAR_TEMPLATE %
-                    (
+                    BAR_TEMPLATE
+                    % (
                         self.label,
                         self.filled_char * x,
                         self.empty_char * (self.width - x),
@@ -135,8 +135,8 @@ class Bar(object):
         if not self.hide:
             # Print completed bar with elapsed time
             STREAM.write(
-                BAR_TEMPLATE %
-                (
+                BAR_TEMPLATE
+                % (
                     self.label,
                     self.filled_char * self.width,
                     self.empty_char * 0,
@@ -145,16 +145,16 @@ class Bar(object):
                     elapsed_disp,
                 )
             )
-            STREAM.write('\n')
+            STREAM.write("\n")
             STREAM.flush()
 
     def format_time(self, seconds):
-        return time.strftime('%H:%M:%S', time.gmtime(seconds))
+        return time.strftime("%H:%M:%S", time.gmtime(seconds))
 
 
 def bar(
     it,
-    label='',
+    label="",
     width=32,
     hide=None,
     empty_char=BAR_EMPTY_CHAR,
@@ -179,7 +179,7 @@ def bar(
             bar.show(i + 1)
 
 
-def dots(it, label='', hide=None, every=1):
+def dots(it, label="", hide=None, every=1):
     """Progress iterator. Prints a dot for each item being iterated"""
     count = 0
     if not hide:
@@ -192,29 +192,26 @@ def dots(it, label='', hide=None, every=1):
         count += 1
         yield item
 
-    STREAM.write('\n')
+    STREAM.write("\n")
     STREAM.flush()
 
 
-def mill(it, label='', hide=None, expected_size=None, every=1):
+def mill(it, label="", hide=None, expected_size=None, every=1):
     """Progress iterator. Prints a mill while iterating over the items."""
 
     def _mill_char(_i):
         if _i >= count:
-            return ' '
+            return " "
 
         else:
             return MILL_CHARS[(_i // every) % len(MILL_CHARS)]
 
     def _show(_i):
         if not hide:
-            if (
-                (_i % every) == 0 or
-                (_i == count)  # True every "every" updates
-            ):  # And when we're done
-                STREAM.write(
-                    MILL_TEMPLATE % (label, _mill_char(_i), _i, count)
-                )
+            if (_i % every) == 0 or (
+                _i == count
+            ):  # True every "every" updates  # And when we're done
+                STREAM.write(MILL_TEMPLATE % (label, _mill_char(_i), _i, count))
                 STREAM.flush()
 
     count = len(it) if expected_size is None else expected_size
@@ -225,5 +222,5 @@ def mill(it, label='', hide=None, expected_size=None, every=1):
 
         _show(i + 1)
     if not hide:
-        STREAM.write('\n')
+        STREAM.write("\n")
         STREAM.flush()
diff --git a/pipenv/project.py b/pipenv/project.py
index a0841ce4..59ba0619 100644
--- a/pipenv/project.py
+++ b/pipenv/project.py
@@ -59,7 +59,7 @@ def _normalized(p):
         return normalize_drive(str(loc))
 
 
-DEFAULT_NEWLINES = u'\n'
+DEFAULT_NEWLINES = u"\n"
 
 
 def preferred_newlines(f):
@@ -71,7 +71,7 @@ def preferred_newlines(f):
 
 if PIPENV_PIPFILE:
     if not os.path.isfile(PIPENV_PIPFILE):
-        raise RuntimeError('Given PIPENV_PIPFILE is not found!')
+        raise RuntimeError("Given PIPENV_PIPFILE is not found!")
 
     else:
         PIPENV_PIPFILE = _normalized(PIPENV_PIPFILE)
@@ -82,15 +82,15 @@ _pipfile_cache = {}
 
 if PIPENV_TEST_INDEX:
     DEFAULT_SOURCE = {
-        u'url': PIPENV_TEST_INDEX,
-        u'verify_ssl': True,
-        u'name': u'custom',
+        u"url": PIPENV_TEST_INDEX,
+        u"verify_ssl": True,
+        u"name": u"custom",
     }
 else:
     DEFAULT_SOURCE = {
-        u'url': u'https://pypi.org/simple',
-        u'verify_ssl': True,
-        u'name': u'pypi',
+        u"url": u"https://pypi.org/simple",
+        u"verify_ssl": True,
+        u"name": u"pypi",
     }
 
 pipfile.api.DEFAULT_SOURCE = DEFAULT_SOURCE
@@ -117,7 +117,7 @@ class Project(object):
         self.which = which
         self.python_version = python_version
         # Hack to skip this during pipenv run, or -r.
-        if ('run' not in sys.argv) and chdir:
+        if ("run" not in sys.argv) and chdir:
             try:
                 os.chdir(self.project_directory)
             except (TypeError, AttributeError):
@@ -136,29 +136,29 @@ class Project(object):
         # TODO: Separate the logic for showing packages from the filters for supplying pip-tools
         for k, v in self.parsed_pipfile.get(package_section, {}).items():
             # Skip editable VCS deps.
-            if hasattr(v, 'keys'):
+            if hasattr(v, "keys"):
                 # When a vcs url is gven without editable it only appears as a key
                 # Eliminate any vcs, path, or url entries which are not editable
                 # Since pip-tools can't do deep resolution on them, even setuptools-installable ones
                 if (
-                    is_vcs(v) or
-                    is_vcs(k) or
-                    (is_installable_file(k) or is_installable_file(v)) or
-                    any(
+                    is_vcs(v)
+                    or is_vcs(k)
+                    or (is_installable_file(k) or is_installable_file(v))
+                    or any(
                         (
-                            prefix in v and
-                            (
-                                os.path.isfile(v[prefix]) or
-                                is_valid_url(v[prefix])
-                            )
+                            prefix in v
+                            and (os.path.isfile(v[prefix]) or is_valid_url(v[prefix]))
                         )
-                        for prefix in ['path', 'file']
+                        for prefix in ["path", "file"]
                     )
                 ):
                     # If they are editable, do resolve them
-                    if 'editable' not in v:
+                    if "editable" not in v:
                         # allow wheels to be passed through
-                        if not (hasattr(v, 'keys') and v.get('path', v.get('file', '')).endswith('.whl')):
+                        if not (
+                            hasattr(v, "keys")
+                            and v.get("path", v.get("file", "")).endswith(".whl")
+                        ):
                             continue
                         ps.update({k: v})
 
@@ -171,10 +171,12 @@ class Project(object):
                 # So we can safely exclude things that need to be editable in order to be resolved
                 # First exclude anything that is a vcs entry either in the key or value
                 if not (
-                    any(is_vcs(i) for i in [k, v]) or
+                    any(is_vcs(i) for i in [k, v])
+                    or
                     # Then exclude any installable files that are not directories
                     # Because pip-tools can resolve setup.py for example
-                    any(is_installable_file(i) for i in [k, v]) or
+                    any(is_installable_file(i) for i in [k, v])
+                    or
                     # Then exclude any URLs because they need to be editable also
                     # Things that are excluded can only be 'shallow resolved'
                     any(is_valid_url(i) for i in [k, v])
@@ -195,22 +197,18 @@ class Project(object):
     @property
     def required_python_version(self):
         if self.pipfile_exists:
-            required = self.parsed_pipfile.get('requires', {}).get(
-                'python_full_version'
+            required = self.parsed_pipfile.get("requires", {}).get(
+                "python_full_version"
             )
             if not required:
-                required = self.parsed_pipfile.get('requires', {}).get(
-                    'python_version'
-                )
+                required = self.parsed_pipfile.get("requires", {}).get("python_version")
             if required != "*":
                 return required
 
     @property
     def project_directory(self):
         if self.pipfile_location is not None:
-            return os.path.abspath(
-                os.path.join(self.pipfile_location, os.pardir)
-            )
+            return os.path.abspath(os.path.join(self.pipfile_location, os.pardir))
 
         else:
             return None
@@ -221,21 +219,19 @@ class Project(object):
 
     def is_venv_in_project(self):
         return PIPENV_VENV_IN_PROJECT or (
-            self.project_directory and
-            os.path.exists(os.path.join(self.project_directory, '.venv'))
+            self.project_directory
+            and os.path.exists(os.path.join(self.project_directory, ".venv"))
         )
 
     @property
     def virtualenv_exists(self):
         # TODO: Decouple project from existence of Pipfile.
         if self.pipfile_exists and os.path.exists(self.virtualenv_location):
-            if os.name == 'nt':
-                extra = ['Scripts', 'activate.bat']
+            if os.name == "nt":
+                extra = ["Scripts", "activate.bat"]
             else:
-                extra = ['bin', 'activate']
-            return os.path.isfile(
-                os.sep.join([self.virtualenv_location] + extra)
-            )
+                extra = ["bin", "activate"]
+            return os.path.isfile(os.sep.join([self.virtualenv_location] + extra))
 
         return False
 
@@ -243,8 +239,8 @@ class Project(object):
     def _get_virtualenv_location(cls, name):
         venv = get_workon_home() / name
         if not venv.exists():
-            return ''
-        return '{0}'.format(venv)
+            return ""
+        return "{0}".format(venv)
 
     @classmethod
     def _sanitize(cls, name):
@@ -260,13 +256,14 @@ class Project(object):
         #   https://www.gnu.org/software/bash/manual/html_node/Double-Quotes.html
         #   http://www.tldp.org/LDP/abs/html/special-chars.html#FIELDREF
         #   https://github.com/torvalds/linux/blob/2bfe01ef/include/uapi/linux/binfmts.h#L18
-        return re.sub(r'[ $`!*@"\\\r\n\t]', '_', name)[0:42]
+        return re.sub(r'[ $`!*@"\\\r\n\t]', "_", name)[0:42]
 
     def _get_virtualenv_hash(self, name):
         """Get the name of the virtualenv adjusted for windows if needed
 
         Returns (name, encoded_hash)
         """
+
         def get_name(name, location):
             name = self._sanitize(name)
             hash = hashlib.sha256(location.encode()).digest()[:6]
@@ -274,20 +271,23 @@ class Project(object):
             return name, encoded_hash[:8]
 
         clean_name, encoded_hash = get_name(name, self.pipfile_location)
-        venv_name = '{0}-{1}'.format(clean_name, encoded_hash)
+        venv_name = "{0}-{1}".format(clean_name, encoded_hash)
 
         # This should work most of the time, for non-WIndows, in-project venv,
         # or "proper" path casing (on Windows).
-        if (os.name != 'nt' or
-                self.is_venv_in_project() or
-                self._get_virtualenv_location(venv_name)):
+        if (
+            os.name != "nt"
+            or self.is_venv_in_project()
+            or self._get_virtualenv_location(venv_name)
+        ):
             return clean_name, encoded_hash
 
         # Check for different capitalization of the same project.
         from .patched.pew.pew import lsenvs
+
         for env in lsenvs():
             try:
-                env_name, hash_ = env.rsplit('-', 1)
+                env_name, hash_ = env.rsplit("-", 1)
             except ValueError:
                 continue
             if len(hash_) != 8 or env_name.lower() != name.lower():
@@ -300,10 +300,10 @@ class Project(object):
     @property
     def virtualenv_name(self):
         sanitized, encoded_hash = self._get_virtualenv_hash(self.name)
-        suffix = '-{0}'.format(PIPENV_PYTHON) if PIPENV_PYTHON else ''
+        suffix = "-{0}".format(PIPENV_PYTHON) if PIPENV_PYTHON else ""
         # If the pipfile was located at '/home/user/MY_PROJECT/Pipfile',
         # the name of its virtualenv will be 'my-project-wyUfYPqE'
-        return sanitized + '-' + encoded_hash + suffix
+        return sanitized + "-" + encoded_hash + suffix
 
     @property
     def virtualenv_location(self):
@@ -320,22 +320,20 @@ class Project(object):
             loc = self._get_virtualenv_location(self.virtualenv_name)
         # The user wants the virtualenv in the project.
         else:
-            loc = os.sep.join(
-                self.pipfile_location.split(os.sep)[:-1] + ['.venv']
-            )
+            loc = os.sep.join(self.pipfile_location.split(os.sep)[:-1] + [".venv"])
         self._virtualenv_location = loc
         return loc
 
     @property
     def virtualenv_src_location(self):
-        loc = os.sep.join([self.virtualenv_location, 'src'])
+        loc = os.sep.join([self.virtualenv_location, "src"])
         mkdir_p(loc)
         return loc
 
     @property
     def download_location(self):
         if self._download_location is None:
-            loc = os.sep.join([self.virtualenv_location, 'downloads'])
+            loc = os.sep.join([self.virtualenv_location, "downloads"])
             self._download_location = loc
         # Create the directory, if it doesn't exist.
         mkdir_p(self._download_location)
@@ -345,8 +343,7 @@ class Project(object):
     def proper_names_db_path(self):
         if self._proper_names_db_path is None:
             self._proper_names_db_path = Path(
-                self.virtualenv_location,
-                'pipenv-proper-names.txt',
+                self.virtualenv_location, "pipenv-proper-names.txt"
             )
         self._proper_names_db_path.touch()  # Ensure the file exists.
         return self._proper_names_db_path
@@ -358,8 +355,8 @@ class Project(object):
 
     def register_proper_name(self, name):
         """Registers a proper name to the database."""
-        with self.proper_names_db_path.open('a') as f:
-            f.write(u'{0}\n'.format(name))
+        with self.proper_names_db_path.open("a") as f:
+            f.write(u"{0}\n".format(name))
 
     @property
     def pipfile_location(self):
@@ -417,17 +414,15 @@ class Project(object):
 
     def _parse_pipfile(self, contents):
         # If any outline tables are present...
-        if ('[packages.' in contents) or ('[dev-packages.' in contents):
+        if ("[packages." in contents) or ("[dev-packages." in contents):
             data = toml.loads(contents)
             # Convert all outline tables to inline tables.
-            for section in ('packages', 'dev-packages'):
+            for section in ("packages", "dev-packages"):
                 for package in data.get(section, {}):
                     # Convert things to inline tables — fancy :)
-                    if hasattr(data[section][package], 'keys'):
+                    if hasattr(data[section][package], "keys"):
                         _data = data[section][package]
-                        data[section][package] = toml._get_empty_inline_table(
-                            dict
-                        )
+                        data[section][package] = toml._get_empty_inline_table(dict)
                         data[section][package].update(_data)
             # We lose comments here, but it's for the best.)
             try:
@@ -447,17 +442,17 @@ class Project(object):
     @property
     def settings(self):
         """A dictionary of the settings added to the Pipfile."""
-        return self.parsed_pipfile.get('pipenv', {})
+        return self.parsed_pipfile.get("pipenv", {})
 
     def has_script(self, name):
         try:
-            return name in self.parsed_pipfile['scripts']
+            return name in self.parsed_pipfile["scripts"]
         except KeyError:
             return False
 
     def build_script(self, name, extra_args=None):
         try:
-            script = Script.parse(self.parsed_pipfile['scripts'][name])
+            script = Script.parse(self.parsed_pipfile["scripts"][name])
         except KeyError:
             script = Script(name)
         if extra_args:
@@ -473,7 +468,7 @@ class Project(object):
                 changed = True
         if changed:
             p = self.parsed_pipfile
-            p['pipenv'] = settings
+            p["pipenv"] = settings
             # Write the changes to disk.
             self.write_toml(p)
 
@@ -482,7 +477,7 @@ class Project(object):
         """Pipfile.lock divided by PyPI and external dependencies."""
         pfile = pipfile.load(self.pipfile_location, inject_env=False)
         lockfile = json.loads(pfile.lock())
-        for section in ('default', 'develop'):
+        for section in ("default", "develop"):
             lock_section = lockfile.get(section, {})
             for key in list(lock_section.keys()):
                 norm_key = pep423_name(key)
@@ -491,7 +486,7 @@ class Project(object):
 
     @property
     def lockfile_location(self):
-        return '{0}.lock'.format(self.pipfile_location)
+        return "{0}.lock".format(self.pipfile_location)
 
     @property
     def lockfile_exists(self):
@@ -502,7 +497,7 @@ class Project(object):
         return self.load_lockfile()
 
     def _get_editable_packages(self, dev=False):
-        section = 'dev-packages' if dev else 'packages'
+        section = "dev-packages" if dev else "packages"
         packages = {
             k: v
             for k, v in self.parsed_pipfile.get(section, {}).items()
@@ -511,7 +506,7 @@ class Project(object):
         return packages
 
     def _get_vcs_packages(self, dev=False):
-        section = 'dev-packages' if dev else 'packages'
+        section = "dev-packages" if dev else "packages"
         packages = {
             k: v
             for k, v in self.parsed_pipfile.get(section, {}).items()
@@ -540,24 +535,24 @@ class Project(object):
     @property
     def all_packages(self):
         """Returns a list of all packages."""
-        p = dict(self.parsed_pipfile.get('dev-packages', {}))
-        p.update(self.parsed_pipfile.get('packages', {}))
+        p = dict(self.parsed_pipfile.get("dev-packages", {}))
+        p.update(self.parsed_pipfile.get("packages", {}))
         return p
 
     @property
     def packages(self):
         """Returns a list of packages, for pip-tools to consume."""
-        return self._build_package_list('packages')
+        return self._build_package_list("packages")
 
     @property
     def dev_packages(self):
         """Returns a list of dev-packages, for pip-tools to consume."""
-        return self._build_package_list('dev-packages')
+        return self._build_package_list("dev-packages")
 
     def touch_pipfile(self):
         """Simply touches the Pipfile, for later use."""
-        with open('Pipfile', 'a'):
-            os.utime('Pipfile', None)
+        with open("Pipfile", "a"):
+            os.utime("Pipfile", None)
 
     @property
     def pipfile_is_empty(self):
@@ -573,44 +568,43 @@ class Project(object):
         """Creates the Pipfile, filled with juicy defaults."""
         from .patched.notpip._internal import ConfigOptionParser
         from .patched.notpip._internal.cmdoptions import make_option_group, index_group
+
         config_parser = ConfigOptionParser(name=self.name)
         config_parser.add_option_group(make_option_group(index_group, config_parser))
         install = config_parser.option_groups[0]
-        indexes = ' '.join(install.get_option('--extra-index-url').default).lstrip('\n').split('\n')
+        indexes = (
+            " ".join(install.get_option("--extra-index-url").default)
+            .lstrip("\n")
+            .split("\n")
+        )
         sources = [DEFAULT_SOURCE]
         for i, index in enumerate(indexes):
             if not index:
                 continue
 
-            source_name = 'pip_index_{}'.format(i)
-            verify_ssl = index.startswith('https')
+            source_name = "pip_index_{}".format(i)
+            verify_ssl = index.startswith("https")
             sources.append(
-                {
-                    u'url': index,
-                    u'verify_ssl': verify_ssl,
-                    u'name': source_name,
-                }
+                {u"url": index, u"verify_ssl": verify_ssl, u"name": source_name}
             )
 
         data = {
-            u'source': sources,
+            u"source": sources,
             # Default packages.
-            u'packages': {},
-            u'dev-packages': {},
+            u"packages": {},
+            u"dev-packages": {},
         }
         # Default requires.
         required_python = python
         if not python:
             if self.virtualenv_location:
-                required_python = self.which('python', self.virtualenv_location)
+                required_python = self.which("python", self.virtualenv_location)
             else:
-                required_python = self.which('python')
+                required_python = self.which("python")
         version = python_version(required_python) or PIPENV_DEFAULT_PYTHON_VERSION
         if version and len(version) >= 3:
-            data[u'requires'] = {
-                'python_version': version[: len('2.7')]
-            }
-        self.write_toml(data, 'Pipfile')
+            data[u"requires"] = {"python_version": version[: len("2.7")]}
+        self.write_toml(data, "Pipfile")
 
     def write_toml(self, data, path=None):
         """Writes the given data structure out as TOML."""
@@ -619,14 +613,12 @@ class Project(object):
         try:
             formatted_data = contoml.dumps(data).rstrip()
         except Exception:
-            for section in ('packages', 'dev-packages'):
+            for section in ("packages", "dev-packages"):
                 for package in data.get(section, {}):
                     # Convert things to inline tables — fancy :)
-                    if hasattr(data[section][package], 'keys'):
+                    if hasattr(data[section][package], "keys"):
                         _data = data[section][package]
-                        data[section][package] = toml._get_empty_inline_table(
-                            dict
-                        )
+                        data[section][package] = toml._get_empty_inline_table(dict)
                         data[section][package].update(_data)
             formatted_data = toml.dumps(data).rstrip()
 
@@ -635,7 +627,7 @@ class Project(object):
         else:
             newlines = DEFAULT_NEWLINES
         formatted_data = cleanup_toml(formatted_data)
-        with io.open(path, 'w', newline=newlines) as f:
+        with io.open(path, "w", newline=newlines) as f:
             f.write(formatted_data)
         # pipfile is mutated!
         self.clear_pipfile_cache()
@@ -644,31 +636,31 @@ class Project(object):
         """Write out the lockfile.
         """
         newlines = self._lockfile_newlines
-        s = simplejson.dumps(   # Send Unicode in to guarentee Unicode out.
-            content, indent=4, separators=(u',', u': '), sort_keys=True,
+        s = simplejson.dumps(  # Send Unicode in to guarentee Unicode out.
+            content, indent=4, separators=(u",", u": "), sort_keys=True
         )
         with atomic_open_for_write(self.lockfile_location, newline=newlines) as f:
             f.write(s)
-            if not s.endswith(u'\n'):
-                f.write(u'\n')  # Write newline at end of document. GH #319.
+            if not s.endswith(u"\n"):
+                f.write(u"\n")  # Write newline at end of document. GH #319.
 
     @property
     def pipfile_sources(self):
-        if 'source' not in self.parsed_pipfile:
+        if "source" not in self.parsed_pipfile:
             return [DEFAULT_SOURCE]
         # We need to make copies of the source info so we don't
         # accidentally modify the cache. See #2100 where values are
         # written after the os.path.expandvars() call.
         return [
             {k: safe_expandvars(v) for k, v in source.items()}
-            for source in self.parsed_pipfile['source']
+            for source in self.parsed_pipfile["source"]
         ]
 
     @property
     def sources(self):
-        if self.lockfile_exists and hasattr(self.lockfile_content, 'keys'):
-            meta_ = self.lockfile_content['_meta']
-            sources_ = meta_.get('sources')
+        if self.lockfile_exists and hasattr(self.lockfile_content, "keys"):
+            meta_ = self.lockfile_content["_meta"]
+            sources_ = meta_.get("sources")
             if sources_:
                 return sources_
 
@@ -693,9 +685,9 @@ class Project(object):
         def find_source(sources, name=None, url=None):
             source = None
             if name:
-                source = [s for s in sources if s.get('name') == name]
+                source = [s for s in sources if s.get("name") == name]
             elif url:
-                source = [s for s in sources if url.startswith(s.get('url'))]
+                source = [s for s in sources if url.startswith(s.get("url"))]
             if source:
                 return first(source)
 
@@ -709,7 +701,7 @@ class Project(object):
 
     def get_package_name_in_pipfile(self, package_name, dev=False):
         """Get the equivalent package name in pipfile"""
-        key = 'dev-packages' if dev else 'packages'
+        key = "dev-packages" if dev else "packages"
         section = self.parsed_pipfile.get(key, {})
         package_name = pep423_name(package_name)
         for name in section.keys():
@@ -720,7 +712,7 @@ class Project(object):
     def remove_package_from_pipfile(self, package_name, dev=False):
         # Read and append Pipfile.
         name = self.get_package_name_in_pipfile(package_name, dev)
-        key = 'dev-packages' if dev else 'packages'
+        key = "dev-packages" if dev else "packages"
         p = self.parsed_pipfile
         if name:
             del p[key][name]
@@ -728,12 +720,13 @@ class Project(object):
 
     def add_package_to_pipfile(self, package_name, dev=False):
         from .vendor.requirementslib import Requirement
+
         # Read and append Pipfile.
         p = self.parsed_pipfile
         # Don't re-capitalize file URLs or VCSs.
         package = Requirement.from_line(package_name.strip())
         _, converted = package.pipfile_entry
-        key = 'dev-packages' if dev else 'packages'
+        key = "dev-packages" if dev else "packages"
         # Set empty group if it doesn't exist yet.
         if key not in p:
             p[key] = {}
@@ -750,12 +743,12 @@ class Project(object):
         """Adds a given index to the Pipfile."""
         # Read and append Pipfile.
         p = self.parsed_pipfile
-        source = {'url': index, 'verify_ssl': True}
+        source = {"url": index, "verify_ssl": True}
         # Add the package to the group.
-        if 'source' not in p:
-            p['source'] = [source]
+        if "source" not in p:
+            p["source"] = [source]
         else:
-            p['source'].append(source)
+            p["source"].append(source)
         # Write Pipfile.
         self.write_toml(p)
 
@@ -768,13 +761,15 @@ class Project(object):
             j = json.load(lock)
             self._lockfile_newlines = preferred_newlines(lock)
         # lockfile is just a string
-        if not j or not hasattr(j, 'keys'):
+        if not j or not hasattr(j, "keys"):
             return j
 
         if expand_env_vars:
             # Expand environment variables in Pipfile.lock at runtime.
-            for i, source in enumerate(j['_meta']['sources'][:]):
-                j['_meta']['sources'][i]['url'] = os.path.expandvars(j['_meta']['sources'][i]['url'])
+            for i, source in enumerate(j["_meta"]["sources"][:]):
+                j["_meta"]["sources"][i]["url"] = os.path.expandvars(
+                    j["_meta"]["sources"][i]["url"]
+                )
 
         return j
 
@@ -783,10 +778,10 @@ class Project(object):
             return
 
         lockfile = self.load_lockfile(expand_env_vars=False)
-        if '_meta' in lockfile and hasattr(lockfile, 'keys'):
-            return lockfile['_meta'].get('hash', {}).get('sha256')
+        if "_meta" in lockfile and hasattr(lockfile, "keys"):
+            return lockfile["_meta"].get("hash", {}).get("sha256")
         # Lockfile exists but has no hash at all
-        return ''
+        return ""
 
     def calculate_pipfile_hash(self):
         # Update the lockfile if it is out-of-date.
@@ -796,8 +791,8 @@ class Project(object):
     def ensure_proper_casing(self):
         """Ensures proper casing of Pipfile packages"""
         pfile = self.parsed_pipfile
-        casing_changed = self.proper_case_section(pfile.get('packages', {}))
-        casing_changed |= self.proper_case_section(pfile.get('dev-packages', {}))
+        casing_changed = self.proper_case_section(pfile.get("packages", {}))
+        casing_changed |= self.proper_case_section(pfile.get("dev-packages", {}))
         return casing_changed
 
     def proper_case_section(self, section):
@@ -806,9 +801,7 @@ class Project(object):
         """
         # Casing for section.
         changed_values = False
-        unknown_names = [
-            k for k in section.keys() if k not in set(self.proper_names)
-        ]
+        unknown_names = [k for k in section.keys() if k not in set(self.proper_names)]
         # Replace each package with proper casing.
         for dep in unknown_names:
             try:
diff --git a/pipenv/resolver.py b/pipenv/resolver.py
index 9f06caa3..72db9429 100644
--- a/pipenv/resolver.py
+++ b/pipenv/resolver.py
@@ -3,12 +3,12 @@ import sys
 import json
 import logging
 
-os.environ['PIP_PYTHON_PATH'] = sys.executable
+os.environ["PIP_PYTHON_PATH"] = sys.executable
 
 
 def _patch_path():
     pipenv_libdir = os.path.dirname(os.path.abspath(__file__))
-    for _dir in ('vendor', 'patched'):
+    for _dir in ("vendor", "patched"):
         sys.path.insert(0, os.path.join(pipenv_libdir, _dir))
     site_packages_dir = os.path.dirname(pipenv_libdir)
     if site_packages_dir not in sys.path:
@@ -20,36 +20,41 @@ def which(*args, **kwargs):
 
 
 def main():
-    is_verbose = '--verbose' in ' '.join(sys.argv)
-    do_pre = '--pre' in ' '.join(sys.argv)
-    do_clear = '--clear' in ' '.join(sys.argv)
-    is_debug = '--debug' in ' '.join(sys.argv)
-    system = '--system' in ' '.join(sys.argv)
+    is_verbose = "--verbose" in " ".join(sys.argv)
+    do_pre = "--pre" in " ".join(sys.argv)
+    do_clear = "--clear" in " ".join(sys.argv)
+    is_debug = "--debug" in " ".join(sys.argv)
+    system = "--system" in " ".join(sys.argv)
     new_sys_argv = []
     for v in sys.argv:
-        if v.startswith('--'):
+        if v.startswith("--"):
             continue
 
         else:
             new_sys_argv.append(v)
     sys.argv = new_sys_argv
 
-    os.environ['PIP_PYTHON_VERSION'] = '.'.join([str(s) for s in sys.version_info[:3]])
-    os.environ['PIP_PYTHON_PATH'] = sys.executable
+    os.environ["PIP_PYTHON_VERSION"] = ".".join([str(s) for s in sys.version_info[:3]])
+    os.environ["PIP_PYTHON_PATH"] = sys.executable
     if is_verbose:
-        logging.getLogger('notpip').setLevel(logging.INFO)
+        logging.getLogger("notpip").setLevel(logging.INFO)
     if is_debug:
         # Shit's getting real at this point.
-        logging.getLogger('notpip').setLevel(logging.DEBUG)
-    if 'PIPENV_PACKAGES' in os.environ:
-        packages = os.environ['PIPENV_PACKAGES'].strip().split('\n')
+        logging.getLogger("notpip").setLevel(logging.DEBUG)
+    if "PIPENV_PACKAGES" in os.environ:
+        packages = os.environ["PIPENV_PACKAGES"].strip().split("\n")
     else:
         packages = sys.argv[1:]
         for i, package in enumerate(packages):
-            if package.startswith('--'):
+            if package.startswith("--"):
                 del packages[i]
     from pipenv.utils import create_mirror_source, resolve_deps, replace_pypi_sources
-    pypi_mirror_source = create_mirror_source(os.environ['PIPENV_PYPI_MIRROR']) if 'PIPENV_PYPI_MIRROR' in os.environ else None
+
+    pypi_mirror_source = (
+        create_mirror_source(os.environ["PIPENV_PYPI_MIRROR"])
+        if "PIPENV_PYPI_MIRROR" in os.environ
+        else None
+    )
 
     def resolve(packages, pre, project, sources, verbose, clear, system):
         return resolve_deps(
@@ -64,8 +69,13 @@ def main():
         )
 
     from pipenv.core import project
-    sources = replace_pypi_sources(project.pipfile_sources, pypi_mirror_source) if pypi_mirror_source else project.pipfile_sources
-    print('using sources: %s' % sources)
+
+    sources = (
+        replace_pypi_sources(project.pipfile_sources, pypi_mirror_source)
+        if pypi_mirror_source
+        else project.pipfile_sources
+    )
+    print("using sources: %s" % sources)
     results = resolve(
         packages,
         pre=do_pre,
@@ -75,13 +85,13 @@ def main():
         clear=do_clear,
         system=system,
     )
-    print('RESULTS:')
+    print("RESULTS:")
     if results:
         print(json.dumps(results))
     else:
         print(json.dumps([]))
 
 
-if __name__ == '__main__':
+if __name__ == "__main__":
     _patch_path()
     main()
diff --git a/pipenv/shells.py b/pipenv/shells.py
index 87692b25..655c56cc 100644
--- a/pipenv/shells.py
+++ b/pipenv/shells.py
@@ -37,26 +37,26 @@ def _get_activate_script(venv):
     """
     # Suffix and source command for other shells.
     # Support for fish shell.
-    if PIPENV_SHELL and 'fish' in PIPENV_SHELL:
-        suffix = '.fish'
-        command = 'source'
+    if PIPENV_SHELL and "fish" in PIPENV_SHELL:
+        suffix = ".fish"
+        command = "source"
     # Support for csh shell.
-    elif PIPENV_SHELL and 'csh' in PIPENV_SHELL:
-        suffix = '.csh'
-        command = 'source'
+    elif PIPENV_SHELL and "csh" in PIPENV_SHELL:
+        suffix = ".csh"
+        command = "source"
     else:
-        suffix = ''
-        command = '.'
+        suffix = ""
+        command = "."
     # Escape any spaces located within the virtualenv path to allow
     # for proper activation.
-    venv_location = str(venv).replace(' ', r'\ ')
+    venv_location = str(venv).replace(" ", r"\ ")
     # The leading space can make history cleaner in some shells.
-    return ' {2} {0}/bin/activate{1}'.format(venv_location, suffix, command)
+    return " {2} {0}/bin/activate{1}".format(venv_location, suffix, command)
 
 
 def _handover(cmd, args):
     args = [cmd] + args
-    if os.name != 'nt':
+    if os.name != "nt":
         os.execvp(cmd, args)
     else:
         proc = subprocess.run(args, shell=True, universal_newlines=True)
@@ -64,7 +64,6 @@ def _handover(cmd, args):
 
 
 class Shell(object):
-
     def __init__(self, cmd):
         self.cmd = cmd
         self.args = []
@@ -72,10 +71,10 @@ class Shell(object):
     @contextlib.contextmanager
     def inject_path(self, venv):
         with temp_environ():
-            os.environ['PATH'] = '{0}{1}{2}'.format(
+            os.environ["PATH"] = "{0}{1}{2}".format(
                 os.pathsep.join(str(p.parent) for p in _iter_python(venv)),
                 os.pathsep,
-                os.environ['PATH'],
+                os.environ["PATH"],
             )
             yield
 
@@ -83,15 +82,11 @@ class Shell(object):
         # FIXME: This isn't necessarily the correct prompt. We should read the
         # actual prompt by peeking into the activation script.
         name = os.path.basename(venv)
-        os.environ['VIRTUAL_ENV'] = str(venv)
-        if 'PROMPT' in os.environ:
-            os.environ['PROMPT'] = '({0}) {1}'.format(
-                name, os.environ['PROMPT'],
-            )
-        if 'PS1' in os.environ:
-            os.environ['PS1'] = '({0}) {1}'.format(
-                name, os.environ['PS1'],
-            )
+        os.environ["VIRTUAL_ENV"] = str(venv)
+        if "PROMPT" in os.environ:
+            os.environ["PROMPT"] = "({0}) {1}".format(name, os.environ["PROMPT"])
+        if "PS1" in os.environ:
+            os.environ["PS1"] = "({0}) {1}".format(name, os.environ["PS1"])
         with self.inject_path(venv):
             os.chdir(cwd)
             _handover(self.cmd, self.args + list(args))
@@ -103,12 +98,10 @@ class Shell(object):
         # dimensions of pexpect.
         dims = get_terminal_size()
         with temp_environ():
-            c = pexpect.spawn(
-                self.cmd, ['-i'], dimensions=(dims.lines, dims.columns),
-            )
+            c = pexpect.spawn(self.cmd, ["-i"], dimensions=(dims.lines, dims.columns))
         c.sendline(_get_activate_script(venv))
         if args:
-            c.sendline(' '.join(args))
+            c.sendline(" ".join(args))
 
         # Handler for terminal resizing events
         # Must be defined here to have the shell process in its context, since
@@ -125,10 +118,7 @@ class Shell(object):
         sys.exit(c.exitstatus)
 
 
-POSSIBLE_ENV_PYTHON = [
-    Path('bin', 'python'),
-    Path('Scripts', 'python.exe'),
-]
+POSSIBLE_ENV_PYTHON = [Path("bin", "python"), Path("Scripts", "python.exe")]
 
 
 def _iter_python(venv):
@@ -144,46 +134,52 @@ class Bash(Shell):
     @contextlib.contextmanager
     def inject_path(self, venv):
         from ._compat import NamedTemporaryFile
-        bashrc_path = Path.home().joinpath('.bashrc')
-        with NamedTemporaryFile('w+') as rcfile:
+
+        bashrc_path = Path.home().joinpath(".bashrc")
+        with NamedTemporaryFile("w+") as rcfile:
             if bashrc_path.is_file():
                 base_rc_src = 'source "{0}"\n'.format(bashrc_path.as_posix())
                 rcfile.write(base_rc_src)
 
-            export_path = 'export PATH="{0}:$PATH"\n'.format(':'.join(
-                python.parent.as_posix()
-                for python in _iter_python(venv)
-            ))
+            export_path = 'export PATH="{0}:$PATH"\n'.format(
+                ":".join(python.parent.as_posix() for python in _iter_python(venv))
+            )
             rcfile.write(export_path)
             rcfile.flush()
-            self.args.extend(['--rcfile', rcfile.name])
+            self.args.extend(["--rcfile", rcfile.name])
             yield
 
 
 class CmderEmulatedShell(Shell):
     def fork(self, venv, cwd, args):
         if cwd:
-            os.environ['CMDER_START'] = cwd
+            os.environ["CMDER_START"] = cwd
         super(CmderEmulatedShell, self).fork(venv, cwd, args)
 
 
 class CmderCommandPrompt(CmderEmulatedShell):
     def fork(self, venv, cwd, args):
-        rc = os.path.expandvars('%CMDER_ROOT%\\vendor\\init.bat')
+        rc = os.path.expandvars("%CMDER_ROOT%\\vendor\\init.bat")
         if os.path.exists(rc):
-            self.args.extend(['/k', rc])
+            self.args.extend(["/k", rc])
         super(CmderCommandPrompt, self).fork(venv, cwd, args)
 
 
 class CmderPowershell(Shell):
     def fork(self, venv, cwd, args):
-        rc = os.path.expandvars('%CMDER_ROOT%\\vendor\\profile.ps1')
+        rc = os.path.expandvars("%CMDER_ROOT%\\vendor\\profile.ps1")
         if os.path.exists(rc):
-            self.args.extend([
-                '-ExecutionPolicy', 'Bypass', '-NoLogo', '-NoProfile',
-                '-NoExit', '-Command',
-                "Invoke-Expression '. ''{0}'''".format(rc),
-            ])
+            self.args.extend(
+                [
+                    "-ExecutionPolicy",
+                    "Bypass",
+                    "-NoLogo",
+                    "-NoProfile",
+                    "-NoExit",
+                    "-Command",
+                    "Invoke-Expression '. ''{0}'''".format(rc),
+                ]
+            )
         super(CmderPowershell, self).fork(venv, cwd, args)
 
 
@@ -192,24 +188,20 @@ class CmderPowershell(Shell):
 SHELL_LOOKUP = collections.defaultdict(
     lambda: collections.defaultdict(lambda: Shell),
     {
-        'bash': collections.defaultdict(lambda: Bash),
-        'cmd': collections.defaultdict(lambda: Shell, {
-            'cmder': CmderCommandPrompt,
-        }),
-        'powershell': collections.defaultdict(lambda: Shell, {
-            'cmder': CmderPowershell,
-        }),
-        'pwsh': collections.defaultdict(lambda: Shell, {
-            'cmder': CmderPowershell,
-        }),
+        "bash": collections.defaultdict(lambda: Bash),
+        "cmd": collections.defaultdict(lambda: Shell, {"cmder": CmderCommandPrompt}),
+        "powershell": collections.defaultdict(
+            lambda: Shell, {"cmder": CmderPowershell}
+        ),
+        "pwsh": collections.defaultdict(lambda: Shell, {"cmder": CmderPowershell}),
     },
 )
 
 
 def _detect_emulator():
-    if os.environ.get('CMDER_ROOT'):
-        return 'cmder'
-    return ''
+    if os.environ.get("CMDER_ROOT"):
+        return "cmder"
+    return ""
 
 
 def choose_shell():
diff --git a/pipenv/utils.py b/pipenv/utils.py
index 60c12cbd..a490df7a 100644
--- a/pipenv/utils.py
+++ b/pipenv/utils.py
@@ -14,19 +14,22 @@ import warnings
 
 from click import echo as click_echo
 from first import first
+
 try:
     from weakref import finalize
 except ImportError:
     try:
         from .vendor.backports.weakref import finalize
     except ImportError:
+
         class finalize(object):
             def __init__(self, *args, **kwargs):
-                logging.warn('weakref.finalize unavailable, not cleaning...')
+                logging.warn("weakref.finalize unavailable, not cleaning...")
 
             def detach(self):
                 return False
 
+
 logging.basicConfig(level=logging.ERROR)
 
 from time import time
@@ -39,11 +42,7 @@ except ImportError:
 from distutils.spawn import find_executable
 from contextlib import contextmanager
 from .pep508checker import lookup
-from .environments import (
-    PIPENV_MAX_ROUNDS,
-    PIPENV_CACHE_DIR,
-    PIPENV_MAX_RETRIES,
-)
+from .environments import PIPENV_MAX_ROUNDS, PIPENV_CACHE_DIR, PIPENV_MAX_RETRIES
 
 try:
     from collections.abc import Mapping
@@ -58,8 +57,8 @@ if six.PY2:
 
 specifiers = [k for k in lookup.keys()]
 # List of version control systems we support.
-VCS_LIST = ('git', 'svn', 'hg', 'bzr')
-SCHEME_LIST = ('http://', 'https://', 'ftp://', 'ftps://', 'file://')
+VCS_LIST = ("git", "svn", "hg", "bzr")
+SCHEME_LIST = ("http://", "https://", "ftp://", "ftps://", "file://")
 requests_session = None
 
 
@@ -69,32 +68,33 @@ def _get_requests_session():
     if requests_session is not None:
         return requests_session
     import requests
+
     requests_session = requests.Session()
     adapter = requests.adapters.HTTPAdapter(max_retries=PIPENV_MAX_RETRIES)
-    requests_session.mount('https://pypi.org/pypi', adapter)
+    requests_session.mount("https://pypi.org/pypi", adapter)
     return requests_session
 
 
 def cleanup_toml(tml):
-    toml = tml.split('\n')
+    toml = tml.split("\n")
     new_toml = []
     # Remove all empty lines from TOML.
     for line in toml:
         if line.strip():
             new_toml.append(line)
-    toml = '\n'.join(new_toml)
+    toml = "\n".join(new_toml)
     new_toml = []
     # Add newlines between TOML sections.
-    for i, line in enumerate(toml.split('\n')):
+    for i, line in enumerate(toml.split("\n")):
         # Skip the first line.
-        if line.startswith('['):
+        if line.startswith("["):
             if i > 0:
                 # Insert a newline before the heading.
-                new_toml.append('')
+                new_toml.append("")
         new_toml.append(line)
     # adding new line at the end of the TOML file
-    new_toml.append('')
-    toml = '\n'.join(new_toml)
+    new_toml.append("")
+    toml = "\n".join(new_toml)
     return toml
 
 
@@ -106,8 +106,9 @@ def parse_python_version(output):
 
     Note: The micro part would be `'0'` if it's missing from the input string.
     """
-    version_line = output.split('\n', 1)[0]
-    version_pattern = re.compile(r'''
+    version_line = output.split("\n", 1)[0]
+    version_pattern = re.compile(
+        r"""
         ^                   # Beginning of line.
         Python              # Literally "Python".
         \s                  # Space.
@@ -120,26 +121,29 @@ def parse_python_version(output):
         )?                  # Micro is optional because pypa/pipenv#1893.
         .*                  # Trailing garbage.
         $                   # End of line.
-    ''', re.VERBOSE)
+    """,
+        re.VERBOSE,
+    )
 
     match = version_pattern.match(version_line)
     if not match:
         return None
-    return match.groupdict(default='0')
+    return match.groupdict(default="0")
 
 
 def python_version(path_to_python):
     import delegator
+
     if not path_to_python:
         return None
     try:
-        c = delegator.run([path_to_python, '--version'], block=False)
+        c = delegator.run([path_to_python, "--version"], block=False)
     except Exception:
         return None
     c.block()
     version = parse_python_version(c.out.strip() or c.err.strip())
     try:
-        version = u'{major}.{minor}.{micro}'.format(**version)
+        version = u"{major}.{minor}.{micro}".format(**version)
     except TypeError:
         return None
     return version
@@ -154,14 +158,14 @@ def escape_grouped_arguments(s):
         return None
 
     # Additional escaping for windows paths
-    if os.name == 'nt':
+    if os.name == "nt":
         s = "{}".format(s.replace("\\", "\\\\"))
     return '"' + s.replace("'", "'\\''") + '"'
 
 
 def clean_pkg_version(version):
     """Uses pip to prepare a package version string, from our internal version."""
-    return six.u(pep440_version(str(version).replace('==', '')))
+    return six.u(pep440_version(str(version).replace("==", "")))
 
 
 class HackedPythonVersion(object):
@@ -174,14 +178,14 @@ class HackedPythonVersion(object):
     def __enter__(self):
         # Only inject when the value is valid
         if self.python_version:
-            os.environ['PIP_PYTHON_VERSION'] = str(self.python_version)
+            os.environ["PIP_PYTHON_VERSION"] = str(self.python_version)
         if self.python_path:
-            os.environ['PIP_PYTHON_PATH'] = str(self.python_path)
+            os.environ["PIP_PYTHON_PATH"] = str(self.python_path)
 
     def __exit__(self, *args):
         # Restore original Python version information.
         try:
-            del os.environ['PIP_PYTHON_VERSION']
+            del os.environ["PIP_PYTHON_VERSION"]
         except KeyError:
             pass
 
@@ -191,32 +195,34 @@ def prepare_pip_source_args(sources, pip_args=None):
         pip_args = []
     if sources:
         # Add the source to notpip.
-        pip_args.extend(['-i', sources[0]['url']])
+        pip_args.extend(["-i", sources[0]["url"]])
         # Trust the host if it's not verified.
-        if not sources[0].get('verify_ssl', True):
+        if not sources[0].get("verify_ssl", True):
             pip_args.extend(
-                [
-                    '--trusted-host',
-                    urlparse(sources[0]['url']).netloc.split(':')[0],
-                ]
+                ["--trusted-host", urlparse(sources[0]["url"]).netloc.split(":")[0]]
             )
         # Add additional sources as extra indexes.
         if len(sources) > 1:
             for source in sources[1:]:
-                pip_args.extend(['--extra-index-url', source['url']])
+                pip_args.extend(["--extra-index-url", source["url"]])
                 # Trust the host if it's not verified.
-                if not source.get('verify_ssl', True):
+                if not source.get("verify_ssl", True):
                     pip_args.extend(
-                        [
-                            '--trusted-host',
-                            urlparse(source['url']).hostname,
-                        ]
+                        ["--trusted-host", urlparse(source["url"]).hostname]
                     )
     return pip_args
 
 
 def actually_resolve_deps(
-    deps, index_lookup, markers_lookup, project, sources, verbose, clear, pre, req_dir=None
+    deps,
+    index_lookup,
+    markers_lookup,
+    project,
+    sources,
+    verbose,
+    clear,
+    pre,
+    req_dir=None,
 ):
     from .vendor.packaging.markers import default_environment
     from .patched.notpip._internal import basecommand
@@ -234,25 +240,26 @@ def actually_resolve_deps(
 
     class PipCommand(basecommand.Command):
         """Needed for pip-tools."""
-        name = 'PipCommand'
+
+        name = "PipCommand"
 
     constraints = []
     cleanup_req_dir = False
     if not req_dir:
-        req_dir = TemporaryDirectory(suffix='-requirements', prefix='pipenv-')
+        req_dir = TemporaryDirectory(suffix="-requirements", prefix="pipenv-")
         cleanup_req_dir = True
     for dep in deps:
         if not dep:
             continue
         url = None
-        if ' -i ' in dep:
-            dep, url = dep.split(' -i ')
+        if " -i " in dep:
+            dep, url = dep.split(" -i ")
         req = Requirement.from_line(dep)
 
         # extra_constraints = []
 
         if url:
-            index_lookup[req.name] = project.get_source(url=url).get('name')
+            index_lookup[req.name] = project.get_source(url=url).get("name")
         # strip the marker and re-add it later after resolution
         # but we will need a fallback in case resolution fails
         # eg pypiwin32
@@ -266,27 +273,35 @@ def actually_resolve_deps(
     if sources:
         pip_args = prepare_pip_source_args(sources, pip_args)
     if verbose:
-        print('Using pip: {0}'.format(' '.join(pip_args)))
-    with NamedTemporaryFile(mode='w', prefix='pipenv-', suffix='-constraints.txt', dir=req_dir.name, delete=False) as f:
+        print("Using pip: {0}".format(" ".join(pip_args)))
+    with NamedTemporaryFile(
+        mode="w",
+        prefix="pipenv-",
+        suffix="-constraints.txt",
+        dir=req_dir.name,
+        delete=False,
+    ) as f:
         if sources:
-            requirementstxt_sources = ' '.join(pip_args) if pip_args else ''
-            requirementstxt_sources = requirementstxt_sources.replace(' --', '\n--')
-            f.write(u'{0}\n'.format(requirementstxt_sources))
-        f.write(u'\n'.join([_constraint for _constraint in constraints]))
+            requirementstxt_sources = " ".join(pip_args) if pip_args else ""
+            requirementstxt_sources = requirementstxt_sources.replace(" --", "\n--")
+            f.write(u"{0}\n".format(requirementstxt_sources))
+        f.write(u"\n".join([_constraint for _constraint in constraints]))
         constraints_file = f.name
     pip_options, _ = pip_command.parser.parse_args(pip_args)
     pip_options.cache_dir = PIPENV_CACHE_DIR
     session = pip_command._build_session(pip_options)
-    pypi = PyPIRepository(
-        pip_options=pip_options, use_json=False, session=session
+    pypi = PyPIRepository(pip_options=pip_options, use_json=False, session=session)
+    constraints = parse_requirements(
+        constraints_file, finder=pypi.finder, session=pypi.session, options=pip_options
     )
-    constraints = parse_requirements(constraints_file, finder=pypi.finder, session=pypi.session, options=pip_options)
     constraints = [c for c in constraints]
     if verbose:
         logging.log.verbose = True
         piptools_logging.log.verbose = True
     resolved_tree = set()
-    resolver = Resolver(constraints=constraints, repository=pypi, clear_caches=clear, prereleases=pre)
+    resolver = Resolver(
+        constraints=constraints, repository=pypi, clear_caches=clear, prereleases=pre
+    )
     # pre-resolve instead of iterating to avoid asking pypi for hashes of editable packages
     hashes = None
     try:
@@ -295,24 +310,24 @@ def actually_resolve_deps(
         resolved_tree.update(results)
     except (NoCandidateFound, DistributionNotFound, HTTPError) as e:
         click_echo(
-            '{0}: Your dependencies could not be resolved. You likely have a '
-            'mismatch in your sub-dependencies.\n  '
-            'You can use {1} to bypass this mechanism, then run {2} to inspect '
-            'the situation.\n  '
-            'Hint: try {3} if it is a pre-release dependency.'
-            ''.format(
-                crayons.red('Warning', bold=True),
-                crayons.red('$ pipenv install --skip-lock'),
-                crayons.red('$ pipenv graph'),
-                crayons.red('$ pipenv lock --pre'),
+            "{0}: Your dependencies could not be resolved. You likely have a "
+            "mismatch in your sub-dependencies.\n  "
+            "You can use {1} to bypass this mechanism, then run {2} to inspect "
+            "the situation.\n  "
+            "Hint: try {3} if it is a pre-release dependency."
+            "".format(
+                crayons.red("Warning", bold=True),
+                crayons.red("$ pipenv install --skip-lock"),
+                crayons.red("$ pipenv graph"),
+                crayons.red("$ pipenv lock --pre"),
             ),
             err=True,
         )
         click_echo(crayons.blue(str(e)), err=True)
-        if 'no version found at all' in str(e):
+        if "no version found at all" in str(e):
             click_echo(
                 crayons.blue(
-                    'Please check your version specifier and version number. See PEP440 for more information.'
+                    "Please check your version specifier and version number. See PEP440 for more information."
                 )
             )
         if cleanup_req_dir:
@@ -324,26 +339,34 @@ def actually_resolve_deps(
 
 
 def venv_resolve_deps(
-    deps, which, project, pre=False, verbose=False, clear=False, allow_global=False, pypi_mirror=None
+    deps,
+    which,
+    project,
+    pre=False,
+    verbose=False,
+    clear=False,
+    allow_global=False,
+    pypi_mirror=None,
 ):
     from .vendor import delegator
     from . import resolver
     import json
+
     if not deps:
         return []
-    resolver = escape_grouped_arguments(resolver.__file__.rstrip('co'))
-    cmd = '{0} {1} {2} {3} {4} {5}'.format(
-        escape_grouped_arguments(which('python', allow_global=allow_global)),
+    resolver = escape_grouped_arguments(resolver.__file__.rstrip("co"))
+    cmd = "{0} {1} {2} {3} {4} {5}".format(
+        escape_grouped_arguments(which("python", allow_global=allow_global)),
         resolver,
-        '--pre' if pre else '',
-        '--verbose' if verbose else '',
-        '--clear' if clear else '',
-        '--system' if allow_global else '',
+        "--pre" if pre else "",
+        "--verbose" if verbose else "",
+        "--clear" if clear else "",
+        "--system" if allow_global else "",
     )
     with temp_environ():
-        os.environ['PIPENV_PACKAGES'] = '\n'.join(deps)
+        os.environ["PIPENV_PACKAGES"] = "\n".join(deps)
         if pypi_mirror:
-            os.environ['PIPENV_PYPI_MIRROR'] = str(pypi_mirror)
+            os.environ["PIPENV_PYPI_MIRROR"] = str(pypi_mirror)
         c = delegator.run(cmd, block=True)
     try:
         assert c.return_code == 0
@@ -352,15 +375,15 @@ def venv_resolve_deps(
             click_echo(c.out, err=True)
             click_echo(c.err, err=True)
         else:
-            click_echo(c.err[int(len(c.err) / 2) - 1:], err=True)
+            click_echo(c.err[int(len(c.err) / 2) - 1 :], err=True)
         sys.exit(c.return_code)
     if verbose:
-        click_echo(c.out.split('RESULTS:')[0], err=True)
+        click_echo(c.out.split("RESULTS:")[0], err=True)
     try:
-        return json.loads(c.out.split('RESULTS:')[1].strip())
+        return json.loads(c.out.split("RESULTS:")[1].strip())
 
     except IndexError:
-        raise RuntimeError('There was a problem with locking.')
+        raise RuntimeError("There was a problem with locking.")
 
 
 def resolve_deps(
@@ -372,22 +395,23 @@ def resolve_deps(
     python=False,
     clear=False,
     pre=False,
-    allow_global=False
+    allow_global=False,
 ):
     """Given a list of dependencies, return a resolved list of dependencies,
     using pip-tools -- and their hashes, using the warehouse API / pip.
     """
     from .patched.notpip._vendor.requests.exceptions import ConnectionError
     from ._compat import TemporaryDirectory
+
     index_lookup = {}
     markers_lookup = {}
-    python_path = which('python', allow_global=allow_global)
+    python_path = which("python", allow_global=allow_global)
     backup_python_path = sys.executable
     results = []
     if not deps:
         return results
     # First (proper) attempt:
-    req_dir = TemporaryDirectory(prefix='pipenv-', suffix='-requirements')
+    req_dir = TemporaryDirectory(prefix="pipenv-", suffix="-requirements")
     with HackedPythonVersion(python_version=python, python_path=python_path):
         try:
             resolved_tree, hashes, markers_lookup, resolver = actually_resolve_deps(
@@ -399,7 +423,7 @@ def resolve_deps(
                 verbose,
                 clear,
                 pre,
-                req_dir=req_dir
+                req_dir=req_dir,
             )
         except RuntimeError:
             # Don't exit here, like usual.
@@ -407,7 +431,7 @@ def resolve_deps(
     # Second (last-resort) attempt:
     if resolved_tree is None:
         with HackedPythonVersion(
-            python_version='.'.join([str(s) for s in sys.version_info[:3]]),
+            python_version=".".join([str(s) for s in sys.version_info[:3]]),
             python_path=backup_python_path,
         ):
             try:
@@ -422,7 +446,7 @@ def resolve_deps(
                     verbose,
                     clear,
                     pre,
-                    req_dir=req_dir
+                    req_dir=req_dir,
                 )
             except RuntimeError:
                 req_dir.cleanup()
@@ -433,38 +457,38 @@ def resolve_deps(
             version = clean_pkg_version(result.specifier)
             index = index_lookup.get(result.name)
             if not markers_lookup.get(result.name):
-                markers = str(
-                    result.markers
-                ) if result.markers and 'extra' not in str(
-                    result.markers
-                ) else None
+                markers = (
+                    str(result.markers)
+                    if result.markers and "extra" not in str(result.markers)
+                    else None
+                )
             else:
                 markers = markers_lookup.get(result.name)
             collected_hashes = []
             if result in hashes:
                 collected_hashes = list(hashes.get(result))
-            elif any('python.org' in source['url'] or 'pypi.org' in source['url']
-                   for source in sources):
-                pkg_url = 'https://pypi.org/pypi/{0}/json'.format(name)
+            elif any(
+                "python.org" in source["url"] or "pypi.org" in source["url"]
+                for source in sources
+            ):
+                pkg_url = "https://pypi.org/pypi/{0}/json".format(name)
                 session = _get_requests_session()
                 try:
                     # Grab the hashes from the new warehouse API.
                     r = session.get(pkg_url, timeout=10)
-                    api_releases = r.json()['releases']
+                    api_releases = r.json()["releases"]
                     cleaned_releases = {}
                     for api_version, api_info in api_releases.items():
                         api_version = clean_pkg_version(api_version)
                         cleaned_releases[api_version] = api_info
                     for release in cleaned_releases[version]:
-                        collected_hashes.append(release['digests']['sha256'])
-                    collected_hashes = [
-                        'sha256:' + s for s in collected_hashes
-                    ]
+                        collected_hashes.append(release["digests"]["sha256"])
+                    collected_hashes = ["sha256:" + s for s in collected_hashes]
                 except (ValueError, KeyError, ConnectionError):
                     if verbose:
                         click_echo(
-                            '{0}: Error generating hash for {1}'.format(
-                                crayons.red('Warning', bold=True), name
+                            "{0}: Error generating hash for {1}".format(
+                                crayons.red("Warning", bold=True), name
                             )
                         )
             # # Collect un-collectable hashes (should work with devpi).
@@ -476,11 +500,11 @@ def resolve_deps(
             #     if verbose:
             #         print('Error generating hash for {}'.format(name))
             collected_hashes = sorted(set(collected_hashes))
-            d = {'name': name, 'version': version, 'hashes': collected_hashes}
+            d = {"name": name, "version": version, "hashes": collected_hashes}
             if index:
-                d.update({'index': index})
+                d.update({"index": index})
             if markers:
-                d.update({'markers': markers.replace('"', "'")})
+                d.update({"markers": markers.replace('"', "'")})
             results.append(d)
     req_dir.cleanup()
     return results
@@ -489,38 +513,37 @@ def resolve_deps(
 def multi_split(s, split):
     """Splits on multiple given separators."""
     for r in split:
-        s = s.replace(r, '|')
-    return [i for i in s.split('|') if len(i) > 0]
+        s = s.replace(r, "|")
+    return [i for i in s.split("|") if len(i) > 0]
 
 
 def is_star(val):
-    return isinstance(val, six.string_types) and val == '*'
+    return isinstance(val, six.string_types) and val == "*"
 
 
 def is_pinned(val):
     if isinstance(val, Mapping):
-        val = val.get('version')
-    return isinstance(val, six.string_types) and val.startswith('==')
+        val = val.get("version")
+    return isinstance(val, six.string_types) and val.startswith("==")
 
 
 def convert_deps_to_pip(deps, project=None, r=True, include_index=False):
     """"Converts a Pipfile-formatted dependency to a pip-formatted one."""
     from ._compat import NamedTemporaryFile
     from .vendor.requirementslib import Requirement
+
     dependencies = []
     for dep_name, dep in deps.items():
-        indexes = project.sources if hasattr(project, 'sources') else None
+        indexes = project.sources if hasattr(project, "sources") else None
         new_dep = Requirement.from_pipfile(dep_name, dep)
-        req = new_dep.as_line(
-            sources=indexes if include_index else None
-        ).strip()
+        req = new_dep.as_line(sources=indexes if include_index else None).strip()
         dependencies.append(req)
     if not r:
         return dependencies
 
     # Write requirements.txt to tmp directory.
-    f = NamedTemporaryFile(suffix='-requirements.txt', delete=False)
-    f.write('\n'.join(dependencies).encode('utf-8'))
+    f = NamedTemporaryFile(suffix="-requirements.txt", delete=False)
+    f.write("\n".join(dependencies).encode("utf-8"))
     f.close()
     return f.name
 
@@ -555,9 +578,9 @@ def is_required_version(version, specified_version):
     """
     # Certain packages may be defined with multiple values.
     if isinstance(specified_version, dict):
-        specified_version = specified_version.get('version', '')
-    if specified_version.startswith('=='):
-        return version.strip() == specified_version.split('==')[1].strip()
+        specified_version = specified_version.get("version", "")
+    if specified_version.startswith("=="):
+        return version.strip() == specified_version.split("==")[1].strip()
 
     return True
 
@@ -565,7 +588,7 @@ def is_required_version(version, specified_version):
 def strip_ssh_from_git_uri(uri):
     """Return git+ssh:// formatted URI to git+git@ format"""
     if isinstance(uri, six.string_types):
-        uri = uri.replace('git+ssh://', 'git+')
+        uri = uri.replace("git+ssh://", "git+")
     return uri
 
 
@@ -573,15 +596,15 @@ def clean_git_uri(uri):
     """Cleans VCS uris from pip format"""
     if isinstance(uri, six.string_types):
         # Add scheme for parsing purposes, this is also what pip does
-        if uri.startswith('git+') and '://' not in uri:
-            uri = uri.replace('git+', 'git+ssh://')
+        if uri.startswith("git+") and "://" not in uri:
+            uri = uri.replace("git+", "git+ssh://")
     return uri
 
 
 def is_editable(pipfile_entry):
-    if hasattr(pipfile_entry, 'get'):
-        return pipfile_entry.get('editable', False) and any(
-            pipfile_entry.get(key) for key in ('file', 'path') + VCS_LIST
+    if hasattr(pipfile_entry, "get"):
+        return pipfile_entry.get("editable", False) and any(
+            pipfile_entry.get(key) for key in ("file", "path") + VCS_LIST
         )
     return False
 
@@ -590,14 +613,12 @@ def is_vcs(pipfile_entry):
     from .vendor import requirements
 
     """Determine if dictionary entry from Pipfile is for a vcs dependency."""
-    if hasattr(pipfile_entry, 'keys'):
+    if hasattr(pipfile_entry, "keys"):
         return any(key for key in pipfile_entry.keys() if key in VCS_LIST)
 
     elif isinstance(pipfile_entry, six.string_types):
         return bool(
-            requirements.requirement.VCS_REGEX.match(
-                clean_git_uri(pipfile_entry)
-            )
+            requirements.requirement.VCS_REGEX.match(clean_git_uri(pipfile_entry))
         )
 
     return False
@@ -610,16 +631,16 @@ def is_installable_file(path):
     from .patched.notpip._internal.download import is_archive_file
     from ._compat import Path
 
-    if hasattr(path, 'keys') and any(
-        key for key in path.keys() if key in ['file', 'path']
+    if hasattr(path, "keys") and any(
+        key for key in path.keys() if key in ["file", "path"]
     ):
-        path = urlparse(path['file']).path if 'file' in path else path['path']
-    if not isinstance(path, six.string_types) or path == '*':
+        path = urlparse(path["file"]).path if "file" in path else path["path"]
+    if not isinstance(path, six.string_types) or path == "*":
         return False
 
     # If the string starts with a valid specifier operator, test if it is a valid
     # specifier set before making a path object (to avoid breaking windows)
-    if any(path.startswith(spec) for spec in '!=<>~'):
+    if any(path.startswith(spec) for spec in "!=<>~"):
         try:
             specifiers.SpecifierSet(path)
         # If this is not a valid specifier, just move on and try it as a path
@@ -632,7 +653,7 @@ def is_installable_file(path):
         return False
 
     lookup_path = Path(path)
-    absolute_path = '{0}'.format(lookup_path.absolute())
+    absolute_path = "{0}".format(lookup_path.absolute())
     if lookup_path.is_dir() and is_installable_dir(absolute_path):
         return True
 
@@ -644,8 +665,8 @@ def is_installable_file(path):
 
 def is_file(package):
     """Determine if a package name is for a File dependency."""
-    if hasattr(package, 'keys'):
-        return any(key for key in package.keys() if key in ['file', 'path'])
+    if hasattr(package, "keys"):
+        return any(key for key in package.keys() if key in ["file", "path"])
 
     if os.path.exists(str(package)):
         return True
@@ -669,7 +690,7 @@ def pep423_name(name):
     """Normalize package name to PEP 423 style standard."""
     name = name.lower()
     if any(i not in name for i in (VCS_LIST + SCHEME_LIST)):
-        return name.replace('_', '-')
+        return name.replace("_", "-")
 
     else:
         return name
@@ -679,19 +700,15 @@ def proper_case(package_name):
     """Properly case project name from pypi.org."""
     # Hit the simple API.
     r = _get_requests_session().get(
-        'https://pypi.org/pypi/{0}/json'.format(package_name),
-        timeout=0.3,
-        stream=True,
+        "https://pypi.org/pypi/{0}/json".format(package_name), timeout=0.3, stream=True
     )
     if not r.ok:
         raise IOError(
-            'Unable to find package {0} in PyPI repository.'.format(
-                package_name
-            )
+            "Unable to find package {0} in PyPI repository.".format(package_name)
         )
 
-    r = parse.parse('https://pypi.org/pypi/{name}/json', r.url)
-    good_name = r['name']
+    r = parse.parse("https://pypi.org/pypi/{name}/json", r.url)
+    good_name = r["name"]
     return good_name
 
 
@@ -722,8 +739,8 @@ def split_section(input_file, section_suffix, test_function):
         }
     }
     """
-    pipfile_sections = ('packages', 'dev-packages')
-    lockfile_sections = ('default', 'develop')
+    pipfile_sections = ("packages", "dev-packages")
+    lockfile_sections = ("default", "develop")
     if any(section in input_file for section in pipfile_sections):
         sections = pipfile_sections
     elif any(section in input_file for section in lockfile_sections):
@@ -738,15 +755,15 @@ def split_section(input_file, section_suffix, test_function):
         for k in list(entries.keys()):
             if test_function(entries.get(k)):
                 split_dict[k] = entries.pop(k)
-        input_file['-'.join([section, section_suffix])] = split_dict
+        input_file["-".join([section, section_suffix])] = split_dict
     return input_file
 
 
 def split_file(file_dict):
     """Split VCS and editable dependencies out from file."""
     sections = {
-        'vcs': is_vcs,
-        'editable': lambda x: hasattr(x, 'keys') and x.get('editable'),
+        "vcs": is_vcs,
+        "editable": lambda x: hasattr(x, "keys") and x.get("editable"),
     }
     for k, func in sections.items():
         file_dict = split_section(file_dict, k, func)
@@ -777,24 +794,27 @@ def merge_deps(
     requirements_deps = []
     for section in list(file_dict.keys()):
         # Turn develop-vcs into ['develop', 'vcs']
-        section_name, suffix = section.rsplit(
-            '-', 1
-        ) if '-' in section and not section == 'dev-packages' else (
-            section, None
+        section_name, suffix = (
+            section.rsplit("-", 1)
+            if "-" in section and not section == "dev-packages"
+            else (section, None)
         )
         if not file_dict[section] or section_name not in (
-            'dev-packages', 'packages', 'default', 'develop'
+            "dev-packages",
+            "packages",
+            "default",
+            "develop",
         ):
             continue
 
-        is_dev = section_name in ('dev-packages', 'develop')
+        is_dev = section_name in ("dev-packages", "develop")
         if is_dev and not dev:
             continue
 
         if ignore_hashes:
             for k, v in file_dict[section]:
-                if 'hash' in v:
-                    del v['hash']
+                if "hash" in v:
+                    del v["hash"]
         # Block and ignore hashes for all suffixed sections (vcs/editable)
         no_hashes = True if suffix else ignore_hashes
         block = True if suffix else blocking
@@ -810,10 +830,10 @@ def merge_deps(
 
 def recase_file(file_dict):
     """Recase file before writing to output."""
-    if 'packages' in file_dict or 'dev-packages' in file_dict:
-        sections = ('packages', 'dev-packages')
-    elif 'default' in file_dict or 'develop' in file_dict:
-        sections = ('default', 'develop')
+    if "packages" in file_dict or "dev-packages" in file_dict:
+        sections = ("packages", "dev-packages")
+    elif "default" in file_dict or "develop" in file_dict:
+        sections = ("default", "develop")
     for section in sections:
         file_section = file_dict.get(section, {})
         # Try to properly case each key if we can.
@@ -840,7 +860,7 @@ def find_windows_executable(bin_path, exe_name):
         return requested_path
 
     try:
-        pathext = os.environ['PATHEXT']
+        pathext = os.environ["PATHEXT"]
     except KeyError:
         pass
     else:
@@ -854,6 +874,7 @@ def find_windows_executable(bin_path, exe_name):
 
 def path_to_url(path):
     from ._compat import Path
+
     return Path(normalize_drive(os.path.abspath(path))).as_uri()
 
 
@@ -876,7 +897,7 @@ def walk_up(bottom):
             nondirs.append(name)
     yield bottom, dirs, nondirs
 
-    new_path = os.path.realpath(os.path.join(bottom, '..'))
+    new_path = os.path.realpath(os.path.join(bottom, ".."))
     # See if we are at the top.
     if new_path == bottom:
         return
@@ -891,12 +912,12 @@ def find_requirements(max_depth=3):
     for c, d, f in walk_up(os.getcwd()):
         i += 1
         if i < max_depth:
-            if 'requirements.txt':
-                r = os.path.join(c, 'requirements.txt')
+            if "requirements.txt":
+                r = os.path.join(c, "requirements.txt")
                 if os.path.isfile(r):
                     return r
 
-    raise RuntimeError('No requirements.txt found!')
+    raise RuntimeError("No requirements.txt found!")
 
 
 # Borrowed from pew to avoid importing pew which imports psutil
@@ -920,31 +941,37 @@ def is_valid_url(url):
 
 
 def is_pypi_url(url):
-    return bool(re.match(r'^http[s]?:\/\/pypi(?:\.python)?\.org\/simple[\/]?$', url))
+    return bool(re.match(r"^http[s]?:\/\/pypi(?:\.python)?\.org\/simple[\/]?$", url))
 
 
 def replace_pypi_sources(sources, pypi_replacement_source):
-    return [pypi_replacement_source] + [source for source in sources if not is_pypi_url(source['url'])]
+    return [pypi_replacement_source] + [
+        source for source in sources if not is_pypi_url(source["url"])
+    ]
 
 
 def create_mirror_source(url):
-    return {'url': url, 'verify_ssl': url.startswith('https://'), 'name': urlparse(url).hostname}
+    return {
+        "url": url,
+        "verify_ssl": url.startswith("https://"),
+        "name": urlparse(url).hostname,
+    }
 
 
 def download_file(url, filename):
     """Downloads file from url to a path with filename"""
     r = _get_requests_session().get(url, stream=True)
     if not r.ok:
-        raise IOError('Unable to download file')
+        raise IOError("Unable to download file")
 
-    with open(filename, 'wb') as f:
+    with open(filename, "wb") as f:
         f.write(r.content)
 
 
 def need_update_check():
     """Determines whether we need to check for updates."""
     mkdir_p(PIPENV_CACHE_DIR)
-    p = os.sep.join((PIPENV_CACHE_DIR, '.pipenv_update_check'))
+    p = os.sep.join((PIPENV_CACHE_DIR, ".pipenv_update_check"))
     if not os.path.exists(p):
         return True
 
@@ -959,12 +986,12 @@ def need_update_check():
 def touch_update_stamp():
     """Touches PIPENV_CACHE_DIR/.pipenv_update_check"""
     mkdir_p(PIPENV_CACHE_DIR)
-    p = os.sep.join((PIPENV_CACHE_DIR, '.pipenv_update_check'))
+    p = os.sep.join((PIPENV_CACHE_DIR, ".pipenv_update_check"))
     try:
         os.utime(p, None)
     except OSError:
-        with open(p, 'w') as fh:
-            fh.write('')
+        with open(p, "w") as fh:
+            fh.write("")
 
 
 def normalize_drive(path):
@@ -976,13 +1003,13 @@ def normalize_drive(path):
 
     See: <https://github.com/pypa/pipenv/issues/1218>
     """
-    if os.name != 'nt' or not isinstance(path, six.string_types):
+    if os.name != "nt" or not isinstance(path, six.string_types):
         return path
 
     drive, tail = os.path.splitdrive(path)
     # Only match (lower cased) local drives (e.g. 'c:'), not UNC mounts.
-    if drive.islower() and len(drive) == 2 and drive[1] == ':':
-        return '{}{}'.format(drive.upper(), tail)
+    if drive.islower() and len(drive) == 2 and drive[1] == ":":
+        return "{}{}".format(drive.upper(), tail)
 
     return path
 
@@ -993,9 +1020,7 @@ def is_readonly_path(fn):
     Permissions check is `bool(path.stat & stat.S_IREAD)` or `not os.access(path, os.W_OK)`
     """
     if os.path.exists(fn):
-        return (os.stat(fn).st_mode & stat.S_IREAD) or not os.access(
-            fn, os.W_OK
-        )
+        return (os.stat(fn).st_mode & stat.S_IREAD) or not os.access(fn, os.W_OK)
 
     return False
 
@@ -1019,7 +1044,9 @@ def handle_remove_readonly(func, path, exc):
     Windows source repo folders are read-only by default, so this error handler
     attempts to set them as writeable and then proceed with deletion."""
     # Check for read-only attribute
-    default_warning_message = 'Unable to remove file due to permissions restriction: {!r}'
+    default_warning_message = (
+        "Unable to remove file due to permissions restriction: {!r}"
+    )
     # split the initial exception out into its type, exception, and traceback
     exc_type, exc_exception, exc_tb = exc
     if is_readonly_path(path):
@@ -1029,9 +1056,7 @@ def handle_remove_readonly(func, path, exc):
             func(path)
         except (OSError, IOError) as e:
             if e.errno in [errno.EACCES, errno.EPERM]:
-                warnings.warn(
-                    default_warning_message.format(path), ResourceWarning
-                )
+                warnings.warn(default_warning_message.format(path), ResourceWarning)
                 return
 
     if exc_exception.errno in [errno.EACCES, errno.EPERM]:
@@ -1050,19 +1075,20 @@ def split_argument(req, short=None, long_=None, num=-1):
     """
     index_entries = []
     import re
+
     if long_:
-        index_entries.append('--{0}'.format(long_))
+        index_entries.append("--{0}".format(long_))
     if short:
-        index_entries.append('-{0}'.format(short))
-    match_string = '|'.join(index_entries)
-    matches = re.findall('(?<=\s)({0})([\s=])(\S+)'.format(match_string), req)
+        index_entries.append("-{0}".format(short))
+    match_string = "|".join(index_entries)
+    matches = re.findall("(?<=\s)({0})([\s=])(\S+)".format(match_string), req)
     remove_strings = []
     match_values = []
     for match in matches:
         match_values.append(match[-1])
-        remove_strings.append(''.join(match))
+        remove_strings.append("".join(match))
     for string_to_remove in remove_strings:
-        req = req.replace(' {0}'.format(string_to_remove), '')
+        req = req.replace(" {0}".format(string_to_remove), "")
     if not match_values:
         return req, None
     if num == 1:
@@ -1091,10 +1117,10 @@ def atomic_open_for_write(target, binary=False, newline=None, encoding=None):
     """
     from ._compat import NamedTemporaryFile
 
-    mode = 'w+b' if binary else 'w'
+    mode = "w+b" if binary else "w"
     f = NamedTemporaryFile(
         dir=os.path.dirname(target),
-        prefix='.__atomic-write',
+        prefix=".__atomic-write",
         mode=mode,
         encoding=encoding,
         newline=newline,
@@ -1114,7 +1140,7 @@ def atomic_open_for_write(target, binary=False, newline=None, encoding=None):
     else:
         f.close()
         try:
-            os.remove(target)   # This is needed on Windows.
+            os.remove(target)  # This is needed on Windows.
         except OSError:
             pass
         os.rename(f.name, target)  # No os.replace() on Python 2.
@@ -1129,8 +1155,8 @@ def safe_expandvars(value):
 
 
 def extract_uri_from_vcs_dep(dep):
-    valid_keys = VCS_LIST + ('uri', 'file')
-    if hasattr(dep, 'keys'):
+    valid_keys = VCS_LIST + ("uri", "file")
+    if hasattr(dep, "keys"):
         return first(dep[k] for k in valid_keys if k in dep) or None
     return None
 
@@ -1144,7 +1170,9 @@ def obtain_vcs_req(vcs_obj, src_dir, name, rev=None):
     target_rev = vcs_obj.make_rev_options(rev)
     if not os.path.exists(target_dir):
         vcs_obj.obtain(target_dir)
-    if not vcs_obj.is_commit_id_equal(target_dir, rev) and not vcs_obj.is_commit_id_equal(target_dir, target_rev):
+    if not vcs_obj.is_commit_id_equal(
+        target_dir, rev
+    ) and not vcs_obj.is_commit_id_equal(target_dir, target_rev):
         vcs_obj.update(target_dir, target_rev)
     return vcs_obj.get_revision(target_dir)
 
@@ -1172,7 +1200,7 @@ def get_vcs_deps(
     except AttributeError:
         return [], []
     if not os.environ.get("PIP_SRC") and not project.virtualenv_location:
-        _src_dir = TemporaryDirectory(prefix='pipenv-', suffix='-src')
+        _src_dir = TemporaryDirectory(prefix="pipenv-", suffix="-src")
         src_dir = Path(_src_dir.name)
     else:
         src_dir = Path(
@@ -1208,37 +1236,38 @@ def translate_markers(pipfile_entry):
     :returns: A normalized dictionary with cleaned marker entries
     """
     if not isinstance(pipfile_entry, Mapping):
-        raise TypeError('Entry is not a pipfile formatted mapping.')
+        raise TypeError("Entry is not a pipfile formatted mapping.")
     from notpip._vendor.distlib.markers import DEFAULT_CONTEXT as marker_context
-    allowed_marker_keys = ['markers'] + [k for k in marker_context.keys()]
-    provided_keys = list(pipfile_entry.keys()) if hasattr(pipfile_entry, 'keys') else []
+
+    allowed_marker_keys = ["markers"] + [k for k in marker_context.keys()]
+    provided_keys = list(pipfile_entry.keys()) if hasattr(pipfile_entry, "keys") else []
     pipfile_marker = next((k for k in provided_keys if k in allowed_marker_keys), None)
     new_pipfile = dict(pipfile_entry).copy()
     if pipfile_marker:
         entry = "{0}".format(pipfile_entry[pipfile_marker])
-        if pipfile_marker != 'markers':
+        if pipfile_marker != "markers":
             entry = "{0} {1}".format(pipfile_marker, entry)
             new_pipfile.pop(pipfile_marker)
-        new_pipfile['markers'] = entry
+        new_pipfile["markers"] = entry
     return new_pipfile
 
 
 def clean_resolved_dep(dep, is_top_level=False, pipfile_entry=None):
-    name = pep423_name(dep['name'])
+    name = pep423_name(dep["name"])
     # We use this to determine if there are any markers on top level packages
     # So we can make sure those win out during resolution if the packages reoccur
-    dep_keys = [k for k in getattr(pipfile_entry, 'keys', list)()] if is_top_level else []
-    lockfile = {
-        'version': '=={0}'.format(dep['version']),
-    }
-    for key in ['hashes', 'index', 'extras']:
+    dep_keys = (
+        [k for k in getattr(pipfile_entry, "keys", list)()] if is_top_level else []
+    )
+    lockfile = {"version": "=={0}".format(dep["version"])}
+    for key in ["hashes", "index", "extras"]:
         if key in dep:
             lockfile[key] = dep[key]
     # In case we lock a uri or a file when the user supplied a path
     # remove the uri or file keys from the entry and keep the path
-    if pipfile_entry and any(k in pipfile_entry for k in ['file', 'path']):
-        fs_key = next((k for k in ['path', 'file'] if k in pipfile_entry), None)
-        lockfile_key = next((k for k in ['uri', 'file', 'path'] if k in lockfile), None)
+    if pipfile_entry and any(k in pipfile_entry for k in ["file", "path"]):
+        fs_key = next((k for k in ["path", "file"] if k in pipfile_entry), None)
+        lockfile_key = next((k for k in ["uri", "file", "path"] if k in lockfile), None)
         if fs_key != lockfile_key:
             try:
                 del lockfile[lockfile_key]
@@ -1249,11 +1278,11 @@ def clean_resolved_dep(dep, is_top_level=False, pipfile_entry=None):
 
     # If a package is **PRESENT** in the pipfile but has no markers, make sure we
     # **NEVER** include markers in the lockfile
-    if 'markers' in dep:
+    if "markers" in dep:
         # First, handle the case where there is no top level dependency in the pipfile
         if not is_top_level:
             try:
-                lockfile['markers'] = translate_markers(dep)['markers']
+                lockfile["markers"] = translate_markers(dep)["markers"]
             except TypeError:
                 pass
         # otherwise make sure we are prioritizing whatever the pipfile says about the markers
@@ -1261,7 +1290,7 @@ def clean_resolved_dep(dep, is_top_level=False, pipfile_entry=None):
         else:
             try:
                 pipfile_entry = translate_markers(pipfile_entry)
-                lockfile['markers'] = pipfile_entry.get('markers')
+                lockfile["markers"] = pipfile_entry.get("markers")
             except TypeError:
                 pass
     return {name: lockfile}
@@ -1284,13 +1313,13 @@ _fs_encoding = sys.getfilesystemencoding() or sys.getdefaultencoding()
 # Duplicated from Pew to avoid importing it (performance considerations).
 def get_workon_home():
     from ._compat import Path
-    workon_home = os.environ.get('WORKON_HOME')
+
+    workon_home = os.environ.get("WORKON_HOME")
     if not workon_home:
-        if os.name == 'nt':
-            workon_home = '~/.virtualenvs'
+        if os.name == "nt":
+            workon_home = "~/.virtualenvs"
         else:
             workon_home = os.path.join(
-                os.environ.get('XDG_DATA_HOME', '~/.local/share'),
-                'virtualenvs',
+                os.environ.get("XDG_DATA_HOME", "~/.local/share"), "virtualenvs"
             )
     return Path(os.path.expandvars(workon_home)).expanduser()
