commit 1af4bc9fa2f53eb43cb8890f7477f1db6db7ea92
Author: Ognjen <ognjen_j@yahoo.com>
Date:   Wed Mar 14 02:56:45 2018 +0100

    Converted LowMem model to the new structure (#292)
    
    * converted lowmem to the new structure
    
    * removed old lowmem

diff --git a/plugins/Model_LowMem/AutoEncoder.py b/plugins/Model_LowMem/AutoEncoder.py
new file mode 100644
index 0000000..db009e0
--- /dev/null
+++ b/plugins/Model_LowMem/AutoEncoder.py
@@ -0,0 +1,36 @@
+# AutoEncoder base classes
+
+encoderH5 = 'encoder.h5'
+decoder_AH5 = 'decoder_A.h5'
+decoder_BH5 = 'decoder_B.h5'
+
+class AutoEncoder:
+    def __init__(self, model_dir, gpus):
+        self.model_dir = model_dir
+        self.gpus = gpus
+
+        self.encoder = self.Encoder()
+        self.decoder_A = self.Decoder()
+        self.decoder_B = self.Decoder()
+
+        self.initModel()
+
+    def load(self, swapped):
+        (face_A,face_B) = (decoder_AH5, decoder_BH5) if not swapped else (decoder_BH5, decoder_AH5)
+
+        try:
+            self.encoder.load_weights(str(self.model_dir / encoderH5))
+            self.decoder_A.load_weights(str(self.model_dir / face_A))
+            self.decoder_B.load_weights(str(self.model_dir / face_B))
+            print('loaded model weights')
+            return True
+        except Exception as e:
+            print('Failed loading existing training data.')
+            print(e)
+            return False
+
+    def save_weights(self):
+        self.encoder.save_weights(str(self.model_dir / encoderH5))
+        self.decoder_A.save_weights(str(self.model_dir / decoder_AH5))
+        self.decoder_B.save_weights(str(self.model_dir / decoder_BH5))
+        print('saved model weights')
diff --git a/plugins/Model_LowMem.py b/plugins/Model_LowMem/Model.py
similarity index 93%
rename from plugins/Model_LowMem.py
rename to plugins/Model_LowMem/Model.py
index 6cb2cf9..506e6e9 100644
--- a/plugins/Model_LowMem.py
+++ b/plugins/Model_LowMem/Model.py
@@ -1,71 +1,70 @@
-# Based on the original https://www.reddit.com/r/deepfakes/ code sample + contribs
-
-from keras.models import Model as KerasModel
-from keras.layers import Input, Dense, Flatten, Reshape
-from keras.layers.advanced_activations import LeakyReLU
-from keras.layers.convolutional import Conv2D
-from keras.optimizers import Adam
-
-from .Model_Original import AutoEncoder, Trainer
-from lib.PixelShuffler import PixelShuffler
-
-from keras.utils import multi_gpu_model
-
-IMAGE_SHAPE = (64, 64, 3)
-ENCODER_DIM = 512
-
-class Model(AutoEncoder):
-    def initModel(self):
-        optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)
-        x = Input(shape=IMAGE_SHAPE)
-
-        self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
-        self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
-
-        if self.gpus > 1:
-            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
-            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)
-
-        self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')
-        self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')
-
-    def converter(self, swap):
-        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A
-        return lambda img: autoencoder.predict(img)
-
-    def conv(self, filters):
-        def block(x):
-            x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)
-            x = LeakyReLU(0.1)(x)
-            return x
-        return block
-
-    def upscale(self, filters):
-        def block(x):
-            x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)
-            x = LeakyReLU(0.1)(x)
-            x = PixelShuffler()(x)
-            return x
-        return block
-
-    def Encoder(self):
-        input_ = Input(shape=IMAGE_SHAPE)
-        x = input_
-        x = self.conv(128)(x)
-        x = self.conv(256)(x)
-        x = self.conv(512)(x)
-        #x = self.conv(1024)(x)
-        x = Dense(ENCODER_DIM)(Flatten()(x))
-        x = Dense(4 * 4 * 1024)(x)
-        x = Reshape((4, 4, 1024))(x)
-        x = self.upscale(512)(x)
-        return KerasModel(input_, x)
-
-    def Decoder(self):
-        input_ = Input(shape=(8, 8, 512))
-        x = input_
-        x = self.upscale(256)(x)
-        x = self.upscale(128)(x)
-        x = self.upscale(64)(x)
-        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)
-        return KerasModel(input_, x)
+# Based on the original https://www.reddit.com/r/deepfakes/ code sample + contribs
+
+from keras.models import Model as KerasModel
+from keras.layers import Input, Dense, Flatten, Reshape
+from keras.layers.advanced_activations import LeakyReLU
+from keras.layers.convolutional import Conv2D
+from keras.optimizers import Adam
+
+from .AutoEncoder import AutoEncoder
+from lib.PixelShuffler import PixelShuffler
+
+from keras.utils import multi_gpu_model
+
+IMAGE_SHAPE = (64, 64, 3)
+ENCODER_DIM = 512
+
+class Model(AutoEncoder):
+    def initModel(self):
+        optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)
+        x = Input(shape=IMAGE_SHAPE)
+
+        self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
+        self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
+
+        if self.gpus > 1:
+            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
+            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)
+
+        self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')
+        self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')
+
+    def converter(self, swap):
+        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A
+        return lambda img: autoencoder.predict(img)
+
+    def conv(self, filters):
+        def block(x):
+            x = Conv2D(filters, kernel_size=5, strides=2, padding='same')(x)
+            x = LeakyReLU(0.1)(x)
+            return x
+        return block
+
+    def upscale(self, filters):
+        def block(x):
+            x = Conv2D(filters * 4, kernel_size=3, padding='same')(x)
+            x = LeakyReLU(0.1)(x)
+            x = PixelShuffler()(x)
+            return x
+        return block
+
+    def Encoder(self):
+        input_ = Input(shape=IMAGE_SHAPE)
+        x = input_
+        x = self.conv(128)(x)
+        x = self.conv(256)(x)
+        x = self.conv(512)(x)
+        x = Dense(ENCODER_DIM)(Flatten()(x))
+        x = Dense(4 * 4 * 1024)(x)
+        x = Reshape((4, 4, 1024))(x)
+        x = self.upscale(512)(x)
+        return KerasModel(input_, x)
+
+    def Decoder(self):
+        input_ = Input(shape=(8, 8, 512))
+        x = input_
+        x = self.upscale(256)(x)
+        x = self.upscale(128)(x)
+        x = self.upscale(64)(x)
+        x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)
+        return KerasModel(input_, x)
diff --git a/plugins/Model_LowMem/Trainer.py b/plugins/Model_LowMem/Trainer.py
new file mode 100644
index 0000000..4f55b39
--- /dev/null
+++ b/plugins/Model_LowMem/Trainer.py
@@ -0,0 +1,56 @@
+
+import time
+import numpy
+from lib.training_data import TrainingDataGenerator, stack_images
+
+class Trainer():
+    random_transform_args = {
+        'rotation_range': 10,
+        'zoom_range': 0.05,
+        'shift_range': 0.05,
+        'random_flip': 0.4,
+    }
+
+    def __init__(self, model, fn_A, fn_B, batch_size, *args):
+        self.batch_size = batch_size
+        self.model = model
+
+        generator = TrainingDataGenerator(self.random_transform_args, 160)
+        self.images_A = generator.minibatchAB(fn_A, self.batch_size)
+        self.images_B = generator.minibatchAB(fn_B, self.batch_size)
+
+    def train_one_step(self, iter, viewer):
+        epoch, warped_A, target_A = next(self.images_A)
+        epoch, warped_B, target_B = next(self.images_B)
+
+        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
+        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
+        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B),
+            end='\r')
+
+        if viewer is not None:
+            viewer(self.show_sample(target_A[0:14], target_B[0:14]), "training")
+
+    def show_sample(self, test_A, test_B):
+        figure_A = numpy.stack([
+            test_A,
+            self.model.autoencoder_A.predict(test_A),
+            self.model.autoencoder_B.predict(test_A),
+        ], axis=1)
+        figure_B = numpy.stack([
+            test_B,
+            self.model.autoencoder_B.predict(test_B),
+            self.model.autoencoder_A.predict(test_B),
+        ], axis=1)
+
+        if test_A.shape[0] % 2 == 1:
+            figure_A = numpy.concatenate ([figure_A, numpy.expand_dims(figure_A[0],0) ])
+            figure_B = numpy.concatenate ([figure_B, numpy.expand_dims(figure_B[0],0) ])
+
+        figure = numpy.concatenate([figure_A, figure_B], axis=0)
+        w = 4
+        h = int( figure.shape[0] / w)
+        figure = figure.reshape((w, h) + figure.shape[1:])
+        figure = stack_images(figure)
+
+        return numpy.clip(figure * 255, 0, 255).astype('uint8')
diff --git a/plugins/Model_LowMem/__init__.py b/plugins/Model_LowMem/__init__.py
new file mode 100644
index 0000000..82d540f
--- /dev/null
+++ b/plugins/Model_LowMem/__init__.py
@@ -0,0 +1,8 @@
+# -*- coding: utf-8 -*-
+
+__author__ = """Based on https://reddit.com/u/deepfakes/"""
+__version__ = '0.1.0'
+
+from .Model import Model
+from .Trainer import Trainer
+from .AutoEncoder import AutoEncoder
\ No newline at end of file
