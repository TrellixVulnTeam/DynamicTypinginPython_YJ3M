commit 4a68b3f023ac3675c340231b0da103027860d3f7
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sun Jun 7 17:06:00 2020 +0000

    Move custom dlight blocks to nn_blocks

diff --git a/lib/model/nn_blocks.py b/lib/model/nn_blocks.py
index 180d064..91a66af 100644
--- a/lib/model/nn_blocks.py
+++ b/lib/model/nn_blocks.py
@@ -3,7 +3,7 @@
 
 import logging
 
-from keras.layers import Add, SeparableConv2D
+from keras.layers import Add, Concatenate, SeparableConv2D, UpSampling2D
 from keras.layers.advanced_activations import LeakyReLU
 from keras.layers.convolutional import Conv2D
 from keras.layers.core import Activation
@@ -308,6 +308,87 @@ class NNBlocks():
         var_x = PixelShuffler(name="{}_pixelshuffler".format(name), size=scale_factor)(var_x)
         return var_x
 
+    # <<< DLight Model Blocks >>> #
+    def upscale2x(self, input_tensor, filters,
+                  kernel_size=3, padding="same", interpolation="bilinear", res_block_follows=False,
+                  sr_ratio=0.5, scale_factor=2, fast=False, **kwargs):
+        """ Custom hybrid upscale layer for sub-pixel up-scaling.
+
+        Most of up-scaling is approximating lighting gradients which can be accurately achieved
+        using linear fitting. This layer attempts to improve memory consumption by splitting
+        with bilinear and convolutional layers so that the sub-pixel update will get details
+        whilst the bilinear filter will get lighting.
+
+        Adds reflection padding if it has been selected by the user, and other post-processing
+        if requested by the plugin.
+
+        Parameters
+        ----------
+        input_tensor: tensor
+            The input tensor to the layer
+        filters: int
+            The dimensionality of the output space (i.e. the number of output filters in the
+            convolution)
+        kernel_size: int, optional
+            An integer or tuple/list of 2 integers, specifying the height and width of the 2D
+            convolution window. Can be a single integer to specify the same value for all spatial
+            dimensions. Default: 3
+        padding: ["valid", "same"], optional
+            The padding to use. Default: `"same"`
+        interpolation: ["nearest", "bilinear"], optional
+            Interpolation to use for up-sampling. Default: `"bilinear"`
+        res_block_follows: bool, optional
+            If a residual block will follow this layer, then this should be set to `True` to add
+            a leaky ReLu after the convolutional layer. Default: ``False``
+        scale_factor: int, optional
+            The amount to upscale the image. Default: `2`
+        sr_ratio: float, optional
+            The proportion of super resolution (pixel shuffler) filters to use. Non-fast mode only.
+            Default: `0.5`
+        kwargs: dict
+            Any additional Keras standard layer keyword arguments
+        fast: bool, optional
+            Use a faster up-scaling method that may appear more rugged. Default: ``False``
+
+        Returns
+        -------
+        tensor
+            The output tensor from the Upscale layer
+        """
+        name = self._get_name("upscale2x_{}".format("fast" if fast else "hyb"))
+        var_x = input_tensor
+        if not fast:
+            sr_filters = int(filters * sr_ratio)
+            filters = filters - sr_filters
+            var_x_sr = self.upscale(var_x, filters,
+                                    kernel_size=kernel_size,
+                                    padding=padding,
+                                    scale_factor=scale_factor,
+                                    res_block_follows=res_block_follows,
+                                    **kwargs)
+
+        if fast or (not fast and filters > 0):
+            var_x2 = self.conv2d(var_x, filters,
+                                 kernel_size=3,
+                                 padding=padding,
+                                 name="{}_conv2d".format(name),
+                                 **kwargs)
+            var_x2 = UpSampling2D(size=(scale_factor, scale_factor),
+                                  interpolation=interpolation,
+                                  name="{}_upsampling2D".format(name))(var_x2)
+            if fast:
+                var_x1 = self.upscale(var_x, filters,
+                                      kernel_size=kernel_size,
+                                      padding=padding,
+                                      scale_factor=scale_factor,
+                                      res_block_follows=res_block_follows, **kwargs)
+                var_x = Add()([var_x2, var_x1])
+            else:
+                var_x = Concatenate(name="{}_concatenate".format(name))([var_x_sr, var_x2])
+        else:
+            var_x = var_x_sr
+        return var_x
+
     # <<< DFaker Model Blocks >>> #
     def res_block(self, input_tensor, filters, kernel_size=3, padding="same", **kwargs):
         """ Residual block.
diff --git a/plugins/train/__init__.py b/plugins/train/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/plugins/train/model/dlight.py b/plugins/train/model/dlight.py
index 8e1e677..3b9fc9b 100644
--- a/plugins/train/model/dlight.py
+++ b/plugins/train/model/dlight.py
@@ -3,17 +3,13 @@
     By AnDenix, 2018-2019
     Based on the dfaker model: https://github.com/dfaker
 
-    Acknowledgements:
-    kvrooman for numrious insights and invaluable aid
+    Acknowledgments:
+    kvrooman for numerous insights and invaluable aid
     DeepHomage for lots of testing
     """
 
-import sys
-import types
-
-from keras.initializers import RandomNormal
-from keras.layers import Add, Dense, Flatten, Input, Reshape, AveragePooling2D, LeakyReLU
-from keras.layers.convolutional import UpSampling2D, Conv2DTranspose
+from keras.layers import Dense, Flatten, Input, Reshape, AveragePooling2D, LeakyReLU
+from keras.layers import UpSampling2D
 from keras.layers.core import Dropout
 from keras.layers.merge import Concatenate
 from keras.layers.normalization import BatchNormalization
@@ -25,52 +21,6 @@ from ._base import logger
 from .original import Model as OriginalModel
 
 
-# [P] TODO Move upscale2x_hyb to nnblocks.py (after testing)
-# <<< DeLight Model Blocks >>> #
-def upscale2x_hyb(self, inp, filters, kernel_size=3, padding='same',
-                  sr_ratio=0.5, scale_factor=2, interpolation='bilinear',
-                  res_block_follows=False, **kwargs):
-    """Hybrid Upscale Layer"""
-    name = self._get_name("upscale2x_hyb")
-    var_x = inp
-
-    sr_filters = int(filters * sr_ratio)
-    upscale_filters = filters - sr_filters
-
-    var_x_sr = self.upscale(var_x, upscale_filters, kernel_size=kernel_size,
-                            padding=padding, scale_factor=scale_factor,
-                            res_block_follows=res_block_follows, **kwargs)
-    if upscale_filters > 0:
-        var_x_us = self.conv2d(var_x, upscale_filters,  kernel_size=3, padding=padding,
-                               name="{}_conv2d".format(name), **kwargs)
-        var_x_us = UpSampling2D(size=(scale_factor, scale_factor), interpolation=interpolation,
-                                name="{}_upsampling2D".format(name))(var_x_us)
-        var_x = Concatenate(name="{}_concatenate".format(name))([var_x_sr, var_x_us])
-    else:
-        var_x = var_x_sr
-
-    return var_x
-
-
-def upscale2x_fast(self, inp, filters, kernel_size=3, padding='same',
-                   sr_ratio=0.5, scale_factor=2, interpolation='bilinear',
-                   res_block_follows=False, **kwargs):
-    """Fast Upscale Layer"""
-    name = self._get_name("upscale2x_fast")
-    var_x = inp
-
-    var_x2 = self.conv2d(var_x, filters,  kernel_size=3, padding=padding,
-                         name="{}_conv2d".format(name), **kwargs)
-    var_x2 = UpSampling2D(size=(scale_factor, scale_factor), interpolation=interpolation,
-                          name="{}_upsampling2D".format(name))(var_x2)
-
-    var_x1 = self.upscale(var_x, filters, kernel_size=kernel_size,
-                          padding=padding, scale_factor=scale_factor,
-                          res_block_follows=res_block_follows, **kwargs)
-    var_x = Add()([var_x2, var_x1])
-    return var_x
-
-
 class Model(OriginalModel):
     """ DeLight Autoencoder Model """
 
@@ -82,42 +32,33 @@ class Model(OriginalModel):
         kwargs["encoder_dim"] = -1
         self.dense_output = None
         self.detail_level = None
+        self.features = None
+        self.encoder_filters = None
+        self.encoder_dim = None
+        self.details = None
+        self.upscale_ratio = None
         super().__init__(*args, **kwargs)
 
         logger.debug("Initialized %s", self.__class__.__name__)
 
     def _detail_level_setup(self):
         logger.debug('self.config[output_size]: %d', self.config["output_size"])
-
-        self.features = {
-            'lowmem': 0,
-            'fair':  1,
-            'best':  2,
-            }[self.config["features"]]
+        self.features = dict(lowmem=0, fair=1, best=2)[self.config["features"]]
         logger.debug('self.features: %d', self.features)
-
         self.encoder_filters = 64 if self.features > 0 else 48
         logger.debug('self.encoder_filters: %d', self.encoder_filters)
         bonum_fortunam = 128
-        self.encoder_dim = {
-            0: 512 + bonum_fortunam,
-            1: 1024 + bonum_fortunam,
-            2: 1536 + bonum_fortunam,
-            }[self.features]
+        self.encoder_dim = {0: 512 + bonum_fortunam,
+                            1: 1024 + bonum_fortunam,
+                            2: 1536 + bonum_fortunam}[self.features]
         logger.debug('self.encoder_dim: %d', self.encoder_dim)
-
-        self.details = {
-            'fast': 0,
-            'good':  1,
-            }[self.config["details"]]
+        self.details = dict(fast=0, good=1)[self.config["details"]]
         logger.debug('self.details: %d', self.details)
 
         try:
-            self.upscale_ratio = {
-                128: 2,
-                256: 4,
-                384: 6
-                }[self.config["output_size"]]
+            self.upscale_ratio = {128: 2,
+                                  256: 4,
+                                  384: 6}[self.config["output_size"]]
         except KeyError:
             logger.error("Config error: output_size must be one of: 128, 256, or 384.")
             raise FaceswapError("Config error: output_size must be one of: 128, 256, or 384.")
@@ -126,9 +67,6 @@ class Model(OriginalModel):
 
     def build(self):
         self._detail_level_setup()
-        # monkey patch-in nn_blocks
-        self.blocks.upscale2x_hyb = types.MethodType(upscale2x_hyb, self.blocks)
-        self.blocks.upscale2x_fast = types.MethodType(upscale2x_fast, self.blocks)
         super().build()
 
     def add_networks(self):
@@ -141,11 +79,12 @@ class Model(OriginalModel):
         self.add_network("encoder", None, self.encoder())
         logger.debug("Added networks")
 
-    def compile_predictors(self, **kwargs):
+    def compile_predictors(self, **kwargs):  # pylint: disable=arguments-differ
         self.set_networks_trainable()
         super().compile_predictors(**kwargs)
 
     def set_networks_trainable(self):
+        """ Set the network state to trainable """
         train_encoder = True
         train_decoder_a = True
         train_decoder_b = True
@@ -210,10 +149,10 @@ class Model(OriginalModel):
         var_xy = UpSampling2D(self.upscale_ratio, interpolation='bilinear')(var_xy)
 
         var_x = var_xy
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_a_complexity)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_a_complexity // 2)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_a_complexity // 4)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_a_complexity // 8)
+        var_x = self.blocks.upscale2x(var_x, decoder_a_complexity, fast=False)
+        var_x = self.blocks.upscale2x(var_x, decoder_a_complexity // 2, fast=False)
+        var_x = self.blocks.upscale2x(var_x, decoder_a_complexity // 4, fast=False)
+        var_x = self.blocks.upscale2x(var_x, decoder_a_complexity // 8, fast=False)
 
         var_x = self.blocks.conv2d(var_x, 3, kernel_size=5, padding="same",
                                    activation="sigmoid", name="face_out")
@@ -222,10 +161,10 @@ class Model(OriginalModel):
 
         if self.config.get("learn_mask", False):
             var_y = var_xy  # mask decoder
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 2)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 4)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 8)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 2, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 4, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 8, fast=False)
 
             var_y = self.blocks.conv2d(var_y, 1, kernel_size=5, padding="same",
                                        activation="sigmoid", name="mask_out")
@@ -246,10 +185,10 @@ class Model(OriginalModel):
         var_xy = self.blocks.upscale(var_xy, 512, scale_factor=self.upscale_ratio)
         var_x = var_xy
 
-        var_x = self.blocks.upscale2x_fast(var_x, decoder_b_complexity)
-        var_x = self.blocks.upscale2x_fast(var_x, decoder_b_complexity // 2)
-        var_x = self.blocks.upscale2x_fast(var_x, decoder_b_complexity // 4)
-        var_x = self.blocks.upscale2x_fast(var_x, decoder_b_complexity // 8)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity, fast=True)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 2, fast=True)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 4, fast=True)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 8, fast=True)
 
         var_x = self.blocks.conv2d(var_x, 3, kernel_size=5, padding="same",
                                    activation="sigmoid", name="face_out")
@@ -259,10 +198,10 @@ class Model(OriginalModel):
         if self.config.get("learn_mask", False):
             var_y = var_xy  # mask decoder
 
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 2)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 4)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 8)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 2, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 4, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 8, fast=False)
 
             var_y = self.blocks.conv2d(var_y, 1, kernel_size=5, padding="same",
                                        activation="sigmoid", name="mask_out")
@@ -280,23 +219,23 @@ class Model(OriginalModel):
 
         var_xy = input_
 
-        var_xy = self.blocks.upscale2x_hyb(var_xy, 512, scale_factor=self.upscale_ratio)
+        var_xy = self.blocks.upscale2x(var_xy, 512, scale_factor=self.upscale_ratio, fast=False)
 
         var_x = var_xy
 
         var_x = self.blocks.res_block(var_x, 512, use_bias=True)
         var_x = self.blocks.res_block(var_x, 512, use_bias=False)
         var_x = self.blocks.res_block(var_x, 512, use_bias=False)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_b_complexity)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity, fast=False)
         var_x = self.blocks.res_block(var_x, decoder_b_complexity, use_bias=True)
         var_x = self.blocks.res_block(var_x, decoder_b_complexity, use_bias=False)
         var_x = BatchNormalization()(var_x)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_b_complexity // 2)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 2, fast=False)
         var_x = self.blocks.res_block(var_x, decoder_b_complexity // 2, use_bias=True)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_b_complexity // 4)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 4, fast=False)
         var_x = self.blocks.res_block(var_x, decoder_b_complexity // 4, use_bias=False)
         var_x = BatchNormalization()(var_x)
-        var_x = self.blocks.upscale2x_hyb(var_x, decoder_b_complexity // 8)
+        var_x = self.blocks.upscale2x(var_x, decoder_b_complexity // 8, fast=False)
 
         var_x = self.blocks.conv2d(var_x, 3, kernel_size=5, padding="same",
                                    activation="sigmoid", name="face_out")
@@ -306,10 +245,10 @@ class Model(OriginalModel):
         if self.config.get("learn_mask", False):
             var_y = var_xy  # mask decoder
 
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 2)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 4)
-            var_y = self.blocks.upscale2x_hyb(var_y, mask_complexity // 8)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 2, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 4, fast=False)
+            var_y = self.blocks.upscale2x(var_y, mask_complexity // 8, fast=False)
 
             var_y = self.blocks.conv2d(var_y, 1, kernel_size=5, padding="same",
                                        activation="sigmoid", name="mask_out")
diff --git a/tests/lib/model/nn_blocks_test.py b/tests/lib/model/nn_blocks_test.py
index 9515a2d..ebe8256 100644
--- a/tests/lib/model/nn_blocks_test.py
+++ b/tests/lib/model/nn_blocks_test.py
@@ -72,3 +72,5 @@ def test_blocks(use_icnr_init, use_convaware_init, use_reflect_padding):
     block_test(cls_.conv_sep, input_shape=(2, 8, 8, 32), kwargs=dict(filters=64))
     block_test(cls_.upscale, input_shape=(2, 4, 4, 128), kwargs=dict(filters=64))
     block_test(cls_.res_block, input_shape=(2, 2, 2, 64), kwargs=dict(filters=64))
+    block_test(cls_.upscale2x, input_shape=(2, 4, 4, 128), kwargs=dict(filters=64, fast=False))
+    block_test(cls_.upscale2x, input_shape=(2, 4, 4, 128), kwargs=dict(filters=64, fast=True))
