commit 779006feca1ce1e77cb6d747ace1fa7b6bcfe966
Author: Artem Ivanov <37909402+andenixa@users.noreply.github.com>
Date:   Sat Aug 18 10:14:41 2018 +0300

    - added saving of current epoch number during save_weights (#468)

diff --git a/plugins/Model_Original/AutoEncoder.py b/plugins/Model_Original/AutoEncoder.py
index dd7eb00..3611910 100644
--- a/plugins/Model_Original/AutoEncoder.py
+++ b/plugins/Model_Original/AutoEncoder.py
@@ -1,10 +1,13 @@
 # AutoEncoder base classes
 
 from lib.utils import backup_file
+from lib import Serializer
+from json import JSONDecodeError
 
 hdf = {'encoderH5': 'encoder.h5',
        'decoder_AH5': 'decoder_A.h5',
-       'decoder_BH5': 'decoder_B.h5'}
+       'decoder_BH5': 'decoder_B.h5',
+       'state': 'state'}
 
 class AutoEncoder:
     def __init__(self, model_dir, gpus):
@@ -18,7 +21,20 @@ class AutoEncoder:
         self.initModel()
 
     def load(self, swapped):
-        (face_A,face_B) = (hdf['decoder_AH5'], hdf['decoder_BH5']) if not swapped else (hdf['decoder_BH5'], hdf['decoder_AH5'])
+        serializer = Serializer.get_serializer('json')
+        state_fn = ".".join([hdf['state'], serializer.ext]) 
+        try:
+            with open(str(self.model_dir / state_fn), 'rb') as fp:
+                state = serializer.unmarshal(fp.read().decode('utf-8'))
+                self._epoch_no = state['epoch_no']
+        except IOError as e:
+            print('Error loading training info:', e.strerror)
+            self._epoch_no = 0
+        except JSONDecodeError as e:
+            print('Error loading training info:', e.msg)
+            self._epoch_no = 0   
+        
+        (face_A,face_B) = (hdf['decoder_AH5'], hdf['decoder_BH5']) if not swapped else (hdf['decoder_BH5'], hdf['decoder_AH5'])                
 
         try:
             self.encoder.load_weights(str(self.model_dir / hdf['encoderH5']))
@@ -29,7 +45,7 @@ class AutoEncoder:
         except Exception as e:
             print('Failed loading existing training data.')
             print(e)
-            return False
+            return False                            
 
     def save_weights(self):
         model_dir = str(self.model_dir)
@@ -38,4 +54,24 @@ class AutoEncoder:
         self.encoder.save_weights(str(self.model_dir / hdf['encoderH5']))
         self.decoder_A.save_weights(str(self.model_dir / hdf['decoder_AH5']))
         self.decoder_B.save_weights(str(self.model_dir / hdf['decoder_BH5']))
+        
         print('saved model weights')
+        
+        serializer = Serializer.get_serializer('json')
+        state_fn = ".".join([hdf['state'], serializer.ext])
+        state_dir = str(self.model_dir / state_fn)                        
+        try:
+            with open(state_dir, 'wb') as fp:
+                state_json = serializer.marshal({
+                    'epoch_no' : self.epoch_no
+                     })
+                fp.write(state_json.encode('utf-8'))
+        except IOError as e:
+            print(e.strerror)                   
+
+    @property
+    def epoch_no(self):
+        "Get current training epoch number"
+        return self._epoch_no
+        
+        
diff --git a/plugins/Model_Original/Model.py b/plugins/Model_Original/Model.py
index d923afc..ce7648e 100644
--- a/plugins/Model_Original/Model.py
+++ b/plugins/Model_Original/Model.py
@@ -20,7 +20,7 @@ class Model(AutoEncoder):
         x = Input(shape=IMAGE_SHAPE)
 
         self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
-        self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
+        self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))        
 
         if self.gpus > 1:
             self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
diff --git a/plugins/Model_Original/Trainer.py b/plugins/Model_Original/Trainer.py
index d595ae8..17216b9 100644
--- a/plugins/Model_Original/Trainer.py
+++ b/plugins/Model_Original/Trainer.py
@@ -25,7 +25,10 @@ class Trainer():
 
         loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
         loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
-        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B),
+        
+        self.model._epoch_no += 1
+        
+        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), self.model.epoch_no, loss_A, loss_B),
             end='\r')
 
         if viewer is not None:
