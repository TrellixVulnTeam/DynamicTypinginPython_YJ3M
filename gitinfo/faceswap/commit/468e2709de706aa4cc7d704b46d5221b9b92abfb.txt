commit 468e2709de706aa4cc7d704b46d5221b9b92abfb
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Fri Oct 11 18:17:39 2019 +0000

    Mask plugin cleanup
    
    - PEP8 Fixes
    - Remove config for non NN Masks
    - Tidy up defaults helptext
    - cli.py fix typos
    - Remove unused imports and functions _base.py
    - Standardize input_size param
    - Enable and update documentation
    - Change references from `aligner` to `masker`
    - Change  input_size, output_size and coverage_ratio from kwargs to params
    - Move load_aligned to batch input iterator
    - Remove unnecessary self.input param
    - Add softmax layer append function to KSession
    - Remove references to KSession protected objects
    - Standardize plugin output into finalize method
    - Make masks full frame and add to lib.faces_detect
    - Add masks to alignments.json (temporary zipped base64 solution)

diff --git a/docs/full/plugins.extract.mask._base.rst b/docs/full/plugins.extract.mask._base.rst
new file mode 100644
index 0000000..ee9487e
--- /dev/null
+++ b/docs/full/plugins.extract.mask._base.rst
@@ -0,0 +1,7 @@
+plugins.extract.mask._base module
+======================================
+
+.. automodule:: plugins.extract.mask._base
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/docs/full/plugins.extract.mask.rst b/docs/full/plugins.extract.mask.rst
new file mode 100644
index 0000000..a748744
--- /dev/null
+++ b/docs/full/plugins.extract.mask.rst
@@ -0,0 +1,17 @@
+plugins.extract.mask package
+==============================
+
+Submodules
+----------
+
+.. toctree::
+
+   plugins.extract.mask._base
+
+Module contents
+---------------
+
+.. automodule:: plugins.extract.mask
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/docs/full/plugins.extract.rst b/docs/full/plugins.extract.rst
index 384a8c5..3061ac9 100644
--- a/docs/full/plugins.extract.rst
+++ b/docs/full/plugins.extract.rst
@@ -8,6 +8,7 @@ Subpackages
 
    plugins.extract.align
    plugins.extract.detect
+   plugins.extract.mask
 
 Submodules
 ----------
diff --git a/lib/cli.py b/lib/cli.py
index 06350a5..4b9b7d2 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -581,10 +581,10 @@ class ExtractArgs(ExtractConvertArgs):
                                       "channel that will not mask any portion of the image."
                                       "\nL|components: Mask designed to provide facial "
                                       "segmentation based on the positioning of landmark "
-                                      "locations. A convenx hull is constructed around the "
+                                      "locations. A convex hull is constructed around the "
                                       "exterior of the landmarks to create a mask."
                                       "\nL|extended: Mask designed to provide facial segmentation "
-                                      "based on the positioning of landmark locations. A convenx "
+                                      "based on the positioning of landmark locations. A convex "
                                       "hull is constructed around the exterior of the landmarks "
                                       "and the mask is extended upwards onto the forehead."
                                       "\nL|vgg-clear: Mask designed to provide smart segmentation "
diff --git a/lib/faces_detect.py b/lib/faces_detect.py
index 21bb53a..3361473 100644
--- a/lib/faces_detect.py
+++ b/lib/faces_detect.py
@@ -39,20 +39,26 @@ class DetectedFace():
     landmarks_xy: list
         The 68 point landmarks as discovered in :mod:`plugins.extract.align`. Should be a ``list``
         of 68 `(x, y)` ``tuples`` with each of the landmark co-ordinates.
+    mask: dict
+        The generated mask(s) for the face as generated in :mod:`plugins.extract.mask`. Must be a
+        dict of `{name (str): mask (numpy.ndarray)}
     """
     def __init__(self, image=None, x=None, w=None, y=None, h=None,
-                 landmarks_xy=None, filename=None):
+                 landmarks_xy=None, mask=None, filename=None):
         logger.trace("Initializing %s: (image: %s, x: %s, w: %s, y: %s, h:%s, "
                      "landmarks_xy: %s, filename: %s)",
                      self.__class__.__name__,
                      image.shape if image is not None and image.any() else image,
-                     x, w, y, h, landmarks_xy, filename)
+                     x, w, y, h, landmarks_xy,
+                     {k: v.shape for k, v in mask} if mask is not None else mask,
+                     filename)
         self.image = image
-        self.x = x
-        self.w = w
-        self.y = y
-        self.h = h
+        self.x = x  # pylint:disable=invalid-name
+        self.w = w  # pylint:disable=invalid-name
+        self.y = y  # pylint:disable=invalid-name
+        self.h = h  # pylint:disable=invalid-name
         self.landmarks_xy = landmarks_xy
+        self.mask = dict() if mask is None else mask
         self.filename = filename
         self.hash = None
         self.face = None
@@ -96,7 +102,7 @@ class DetectedFace():
         -------
         alignment: dict
             The alignment dict will be returned with the keys ``x``, ``w``, ``y``, ``h``,
-            ``landmarks_xy``, ``hash``.
+            ``landmarks_xy``, ``mask``, ``hash``.
         """
 
         alignment = dict()
@@ -106,6 +112,7 @@ class DetectedFace():
         alignment["h"] = self.h
         alignment["landmarks_xy"] = self.landmarks_xy
         alignment["hash"] = self.hash
+        alignment["mask"] = self.mask
         logger.trace("Returning: %s", alignment)
         return alignment
 
@@ -117,8 +124,11 @@ class DetectedFace():
         ----------
         alignment: dict
             A dictionary entry for a face from an alignments file containing the keys
-            ``x``, ``w``, ``y``, ``h``, ``landmarks_xy``. Optionally the key ``hash``
-            will be provided, but not all use cases will know the face hash at this time.
+            ``x``, ``w``, ``y``, ``h``, ``landmarks_xy``.
+            Optionally the key ``hash`` will be provided, but not all use cases will know the
+            face hash at this time.
+            Optionally the key ``mask`` will be provided, but legacy alignments will not have
+            this key.
         image: numpy.ndarray, optional
             If an image is passed in, then the ``image`` attribute will
             be set to the cropped face based on the passed in bounding box co-ordinates
@@ -133,6 +143,8 @@ class DetectedFace():
         self.landmarks_xy = alignment["landmarks_xy"]
         # Manual tool does not know the final hash so default to None
         self.hash = alignment.get("hash", None)
+        # Manual tool and legacy alignments will not have a mask
+        self.mask = alignment.get("mask", None)
         if image is not None and image.any():
             self.image = image
             self._image_to_face(image)
@@ -144,7 +156,7 @@ class DetectedFace():
         """ set self.image to be the cropped face from detected bounding box """
         logger.trace("Cropping face from image")
         self.face = image[self.top: self.bottom,
-                           self.left: self.right]
+                          self.left: self.right]
 
     # <<< Aligned Face methods and properties >>> #
     def load_aligned(self, image, size=256, coverage_ratio=1.0, dtype=None):
@@ -199,7 +211,8 @@ class DetectedFace():
                                                  for k, v in self.aligned.items()
                                                  if k != "face"})
 
-    def _padding_from_coverage(self, size, coverage_ratio):
+    @staticmethod
+    def _padding_from_coverage(size, coverage_ratio):
         """ Return the image padding for a face from coverage_ratio set against a
             pre-padded training image """
         padding = int((size * (coverage_ratio - 0.625)) / 2)
@@ -240,7 +253,7 @@ class DetectedFace():
         self.feed["face"] = face if dtype is None else face.astype(dtype)
 
         logger.trace("Loaded feed face. (face_shape: %s, matrix: %s)",
-                     self.feed_face.shape, self._feed_matrix)
+                     self.feed_face.shape, self.feed_matrix)
 
     def load_reference_face(self, image, size=64, coverage_ratio=0.625, dtype=None):
         """ Align a face in the correct dimensions for reference against the output from a model.
@@ -354,7 +367,7 @@ class DetectedFace():
         return landmarks
 
     @property
-    def _feed_matrix(self):
+    def feed_matrix(self):
         """ numpy.ndarray: The adjusted matrix face sized for feeding into a model. Only available
         after :func:`load_feed_face` has been called with an image, otherwise returns ``None`` """
         if not self.feed:
@@ -372,7 +385,7 @@ class DetectedFace():
         ``None``"""
         if not self.feed:
             return None
-        return get_matrix_scaling(self._feed_matrix)
+        return get_matrix_scaling(self.feed_matrix)
 
     @property
     def reference_face(self):
diff --git a/lib/model/session.py b/lib/model/session.py
index a9a825a..bff014e 100644
--- a/lib/model/session.py
+++ b/lib/model/session.py
@@ -4,6 +4,7 @@
 import logging
 
 import tensorflow as tf
+from keras.layers import Activation
 from keras.models import load_model as k_load_model, Model
 import numpy as np
 
@@ -165,3 +166,19 @@ class KSession():
             with self._session.as_default():  # pylint: disable=not-context-manager
                 with self._session.graph.as_default():
                     self._model.load_weights(self._model_path)
+
+    def append_softmax_activation(self, layer_index=-1):
+        """ Append a softmax activation layer to a model
+
+        Occasionally a softmax activation layer needs to be added to a model's output.
+        This is a convenience fuction to append this layer to the loaded model.
+
+        Parameters
+        ----------
+        layer_index: int, optional
+            The layer index of the model to select the output from to use as an input to the
+            softmax activation layer. Default: -1 (The final layer of the model)
+        """
+        logger.debug("Appending Softmax Activation to model: (layer_index: %s)", layer_index)
+        softmax = Activation("softmax", name="softmax")(self._model.layers[layer_index].output)
+        self._model = Model(inputs=self._model.input, outputs=[softmax])
diff --git a/plugins/extract/mask/_base.py b/plugins/extract/mask/_base.py
index 9539ab8..ee866fb 100644
--- a/plugins/extract/mask/_base.py
+++ b/plugins/extract/mask/_base.py
@@ -1,39 +1,35 @@
 #!/usr/bin/env python3
 """ Base class for Face Masker plugins
-    Plugins should inherit from this class
 
-    See the override methods for which methods are required.
+Plugins should inherit from this class
 
-    The plugin will receive a dict containing:
-    {"filename": <filename of source frame>,
-     "image": <source image>,
-     "detected_faces": <list of bounding box dicts from lib/plugins/extract/detect/_base>}
+See the override methods for which methods are required.
 
-    For each source item, the plugin must pass a dict to finalize containing:
-    {"filename": <filename of source frame>,
-     "image": <four channel source image>,
-     "detected_faces": <list of bounding box dicts from lib/plugins/extract/detect/_base>
-    """
+The plugin will receive a dict containing:
+
+>>> {"filename": <filename of source frame>,
+>>>  "image": <source image>,
+>>>  "detected_faces": <list of bounding box dicts from lib/plugins/extract/detect/_base>}
+
+For each source item, the plugin must pass a dict to finalize containing:
 
-import logging
-import os
-import traceback
+>>> {"filename": <filename of source frame>,
+>>>  "image": <four channel source image>,
+>>>  "detected_faces": <list of bounding box dicts from lib/plugins/extract/detect/_base>}
+"""
+
+import base64
+import zlib
 import cv2
 import numpy as np
-import keras
 
-from io import StringIO
-from lib.faces_detect import DetectedFace
-from lib.aligner import Extract
 from plugins.extract._base import Extractor, logger
 
-logger = logging.getLogger(__name__)  # pylint:disable=invalid-name
-
 
-class Masker(Extractor):
-    """ Aligner plugin _base Object
+class Masker(Extractor):  # pylint:disable=abstract-method
+    """ Masker plugin _base Object
 
-    All Aligner plugins must inherit from this class
+    All Masker plugins must inherit from this class
 
     Parameters
     ----------
@@ -42,14 +38,17 @@ class Masker(Extractor):
         https://github.com/deepfakes-models/faceswap-models for more information
     model_filename: str
         The name of the model file to be loaded
-    normalize_method: {`None`, 'clahe', 'hist', 'mean'}, optional
-        Normalize the images fed to the aligner. Default: ``None``
 
     Other Parameters
     ----------------
     configfile: str, optional
         Path to a custom configuration ``ini`` file. Default: Use system configfile
 
+    Attributes
+    ----------
+    blur_kernel, int
+        The size of the kernel for applying gaussian blur to the output of the mask
+
     See Also
     --------
     plugins.extract.align : Aligner plugins
@@ -58,18 +57,14 @@ class Masker(Extractor):
     plugins.extract.align._base : Aligner parent class for extraction plugins.
     """
 
-    def __init__(self, git_model_id=None, model_filename=None,
-                 configfile=None, input_size=256, output_size=256, coverage_ratio=1.):
-        logger.debug("Initializing %s: (configfile: %s, input_size: %s, "
-                     "output_size: %s, coverage_ratio: %s)",
-                     self.__class__.__name__, configfile, input_size, output_size, coverage_ratio)
+    def __init__(self, git_model_id=None, model_filename=None, configfile=None):
+        logger.debug("Initializing %s: (configfile: %s, )", self.__class__.__name__, configfile)
         super().__init__(git_model_id,
                          model_filename,
                          configfile=configfile)
-        self.input_size = input_size
-        self.output_size = output_size
-        self.coverage_ratio = coverage_ratio
-        self.extract = Extract()
+        self.input_size = 256  # Overide for model specific input_size
+        self.blur_kernel = 5  # Overide for model specific blur_kernel size
+        self.coverage_ratio = 1.0  # Overide for model specific coverage_ratio
 
         self._plugin_type = "mask"
         self._faces_per_filename = dict()  # Tracking for recompiling face batches
@@ -78,12 +73,12 @@ class Masker(Extractor):
         logger.debug("Initialized %s", self.__class__.__name__)
 
     def get_batch(self, queue):
-        """ Get items for inputting into the aligner from the queue in batches
+        """ Get items for inputting into the masker from the queue in batches
 
         Items are returned from the ``queue`` in batches of
         :attr:`~plugins.extract._base.Extractor.batchsize`
 
-        To ensure consistent batchsizes for aligner the items are split into separate items for
+        To ensure consistent batchsizes for masker the items are split into separate items for
         each :class:`lib.faces_detect.DetectedFace` object.
 
         Remember to put ``'EOF'`` to the out queue after processing
@@ -122,6 +117,10 @@ class Masker(Extractor):
                 self._queues["out"].put(item)
                 continue
             for f_idx, face in enumerate(item["detected_faces"]):
+                face.load_feed_face(face.image,
+                                    size=self.input_size,
+                                    coverage_ratio=1.0,
+                                    dtype="float32")
                 batch.setdefault("detected_faces", []).append(face)
                 batch.setdefault("filename", []).append(item["filename"])
                 batch.setdefault("image", []).append(item["image"])
@@ -160,11 +159,11 @@ class Masker(Extractor):
         return item
 
     def _predict(self, batch):
-        """ Just return the aligner's predict function """
+        """ Just return the masker's predict function """
         return self.predict(batch)
 
     def finalize(self, batch):
-        """ Finalize the output from Aligner
+        """ Finalize the output from Masker
 
         This should be called as the final task of each `plugin`.
 
@@ -181,7 +180,7 @@ class Masker(Extractor):
         ----------
         batch : dict
             The final ``dict`` from the `plugin` process. It must contain the `keys`:
-            ``detected_faces``, ``landmarks``, ``filename``, ``image``
+            ``detected_faces``, ``filename``, ``image``
 
         Yields
         ------
@@ -190,6 +189,26 @@ class Masker(Extractor):
             :class:`lib.faces_detect.DetectedFace` objects.
 
         """
+        if self.blur_kernel is not None:
+            predicted = np.array([cv2.GaussianBlur(mask, (self.blur_kernel, self.blur_kernel), 0)
+                                  for mask in batch["prediction"]])
+        else:
+            predicted = batch["prediction"]
+        predicted[predicted < 0.04] = 0.0
+        predicted[predicted > 0.96] = 1.0
+        # TODO Convert this and landmarks_xy to numpy arrays once serialization
+        # decision is made, Hacky temp fix as can't serialize numpy arrays in json
+        # and tolist is hugely slow and gobbles ram
+        for mask, face in zip(batch["prediction"], batch["detected_faces"]):
+            placeholder = np.zeros(face.image.shape[:2] + (1, ), dtype="float32")
+            placeholder = (cv2.warpAffine(
+                mask,
+                face.feed_matrix,
+                (face.image.shape[1], face.image.shape[0]),
+                placeholder,
+                flags=cv2.WARP_INVERSE_MAP | face.feed_interpolators[1],
+                borderMode=cv2.BORDER_TRANSPARENT) * 255.0).astype("uint8")
+            face.mask[self.name] = base64.b64encode(zlib.compress(placeholder)).decode()
         self._remove_invalid_keys(batch, ("detected_faces", "filename", "image"))
         logger.trace("Item out: %s", {key: val
                                       for key, val in batch.items()
@@ -220,39 +239,3 @@ class Masker(Extractor):
         resized = cv2.resize(image, (0, 0), fx=scale, fy=scale, interpolation=method)
         resized = resized if channels > 1 else resized[..., None]
         return resized
-
-    @staticmethod
-    def postprocessing(mask):
-        """ Post-processing of Nirkin style segmentation masks """
-        # Select_largest_segment
-        if pop_small_segments:
-            results = cv2.connectedComponentsWithStats(mask,  # pylint: disable=no-member
-                                                       4,
-                                                       cv2.CV_32S)  # pylint: disable=no-member
-            _, labels, stats, _ = results
-            segments_ranked_by_area = np.argsort(stats[:, -1])[::-1]
-            mask[labels != segments_ranked_by_area[0, 0]] = 0.
-
-        # Smooth contours
-        if smooth_contours:
-            iters = 2
-            kernel = cv2.getStructuringElement(cv2.MORPH_RECT,  # pylint: disable=no-member
-                                               (5, 5))
-            cv2.morphologyEx(mask, cv2.MORPH_OPEN,  # pylint: disable=no-member
-                             kernel, iterations=iters)
-            cv2.morphologyEx(mask, cv2.MORPH_CLOSE,  # pylint: disable=no-member
-                             kernel, iterations=iters)
-            cv2.morphologyEx(mask, cv2.MORPH_CLOSE,  # pylint: disable=no-member
-                             kernel, iterations=iters)
-            cv2.morphologyEx(mask, cv2.MORPH_OPEN,  # pylint: disable=no-member
-                             kernel, iterations=iters)
-
-        # Fill holes
-        if fill_holes:
-            not_holes = mask.copy()
-            not_holes = np.pad(not_holes, ((2, 2), (2, 2), (0, 0)), 'constant')
-            cv2.floodFill(not_holes, None, (0, 0), 255)  # pylint: disable=no-member
-            holes = cv2.bitwise_not(not_holes)[2:-2, 2:-2]  # pylint: disable=no-member
-            mask = cv2.bitwise_or(mask, holes)  # pylint: disable=no-member
-            mask = np.expand_dims(mask, axis=-1)
-        return mask
diff --git a/plugins/extract/mask/components.py b/plugins/extract/mask/components.py
index af225e0..a497e56 100644
--- a/plugins/extract/mask/components.py
+++ b/plugins/extract/mask/components.py
@@ -1,4 +1,5 @@
 #!/usr/bin/env python3
+""" Components Mask for faceswap.py """
 
 import cv2
 import numpy as np
@@ -11,44 +12,35 @@ class Mask(Masker):
         git_model_id = None
         model_filename = None
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
+        self.input_size = 256
+        self.blur_kernel = None
         self.name = "Components"
-        self.colorformat = "BGR"
-        self.vram = 0
-        self.vram_warnings = 0
-        self.vram_per_batch = 30
-        self.batchsize = self.config["batch-size"]
+        self.vram = 0  # Doesn't use GPU
+        self.vram_per_batch = 0
+        self.batchsize = 1
 
     def init_model(self):
         logger.debug("No mask model to initialize")
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        batch["feed"] = np.array([face.image for face in batch["detected_faces"]])
+        batch["feed"] = np.zeros((self.batchsize, self.input_size, self.input_size, 1),
+                                 dtype="float32")
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
-        masks = np.zeros(batch["feed"].shape[:-1] + (1,), dtype='uint8')
-        for mask, face in zip(masks, batch["detected_faces"]):
-            parts = self.parse_parts(np.array(face.landmarks_xy))
+        for mask, face in zip(batch["feed"], batch["detected_faces"]):
+            parts = self.parse_parts(np.array(face.feed_landmarks))
             for item in parts:
                 item = np.concatenate(item)
-                hull = cv2.convexHull(item).astype('int32')  # pylint: disable=no-member
-                cv2.fillConvexPoly(mask, hull, 255, lineType=cv2.LINE_AA)
-        batch["prediction"] = masks
+                hull = cv2.convexHull(item).astype("int32")  # pylint: disable=no-member
+                cv2.fillConvexPoly(mask, hull, 1.0, lineType=cv2.LINE_AA)
+        batch["prediction"] = batch["feed"]
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        generator = zip(batch["feed"], batch["detected_faces"], batch["prediction"])
-        for feed, face, prediction in generator:
-            face.image = np.concatenate((feed, prediction), axis=-1)
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
         return batch
 
     @staticmethod
diff --git a/plugins/extract/mask/components_defaults.py b/plugins/extract/mask/components_defaults.py
deleted file mode 100644
index 721ee94..0000000
--- a/plugins/extract/mask/components_defaults.py
+++ /dev/null
@@ -1,68 +0,0 @@
-#!/usr/bin/env python3
-"""
-    The default options for the faceswap VGG clear plugin.
-
-    Defaults files should be named <plugin_name>_defaults.py
-    Any items placed into this file will automatically get added to the relevant config .ini files
-    within the faceswap/config folder.
-
-    The following variables should be defined:
-        _HELPTEXT: A string describing what this plugin does
-        _DEFAULTS: A dictionary containing the options, defaults and meta information. The
-                   dictionary should be defined as:
-                       {<option_name>: {<metadata>}}
-
-                   <option_name> should always be lower text.
-                   <metadata> dictionary requirements are listed below.
-
-    The following keys are expected for the _DEFAULTS <metadata> dict:
-        datatype:  [required] A python type class. This limits the type of data that can be
-                   provided in the .ini file and ensures that the value is returned in the
-                   correct type to faceswap. Valid datatypes are: <class 'int'>, <class 'float'>,
-                   <class 'str'>, <class 'bool'>.
-        default:   [required] The default value for this option.
-        info:      [required] A string describing what this option does.
-        group:     [optional]. A group for grouping options together in the GUI. If not
-                   provided this will not group this option with any others.
-        choices:   [optional] If this option's datatype is of <class 'str'> then valid
-                   selections can be defined here. This validates the option and also enables
-                   a combobox / radio option in the GUI.
-        gui_radio: [optional] If <choices> are defined, this indicates that the GUI should use
-                   radio buttons rather than a combobox to display this option.
-        min_max:   [partial] For <class 'int'> and <class 'float'> datatypes this is required
-                   otherwise it is ignored. Should be a tuple of min and max accepted values.
-                   This is used for controlling the GUI slider range. Values are not enforced.
-        rounding:  [partial] For <class 'int'> and <class 'float'> datatypes this is
-                   required otherwise it is ignored. Used for the GUI slider. For floats, this
-                   is the number of decimal places to display. For ints this is the step size.
-        fixed:     [optional] [train only]. Training configurations are fixed when the model is
-                   created, and then reloaded from the state file. Marking an item as fixed=False
-                   indicates that this value can be changed for existing models, and will override
-                   the value saved in the state file with the updated value in config. If not
-                   provided this will default to True.
-"""
-
-
-_HELPTEXT = (
-    "Components options. Mask designed to provide facial segmentation based on the positioning of "
-    "landmark locations. A convenx hull is constructed around the exterior of the landmarks to "
-    "create a mask."
-    )
-
-
-_DEFAULTS = {
-    "batch-size": {
-        "default": 8,
-        "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
-                "but setting it too high can harm performance.\n"
-                "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
-        "datatype": int,
-        "rounding": 1,
-        "min_max": (1, 64),
-        "choices": [],
-        "gui_radio": False,
-        "fixed": True,
-    }
-}
diff --git a/plugins/extract/mask/extended.py b/plugins/extract/mask/extended.py
index 6e61733..bd84d2d 100644
--- a/plugins/extract/mask/extended.py
+++ b/plugins/extract/mask/extended.py
@@ -1,4 +1,5 @@
 #!/usr/bin/env python3
+""" Extended Mask for faceswap.py """
 
 import cv2
 import numpy as np
@@ -11,44 +12,35 @@ class Mask(Masker):
         git_model_id = None
         model_filename = None
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
+        self.input_size = 256
+        self.blur_kernel = None
         self.name = "Extended"
-        self.colorformat = "BGR"
-        self.vram = 0
-        self.vram_warnings = 0
-        self.vram_per_batch = 30
-        self.batchsize = self.config["batch-size"]
+        self.vram = 0  # Doesn't use GPU
+        self.vram_per_batch = 0
+        self.batchsize = 1
 
     def init_model(self):
         logger.debug("No mask model to initialize")
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        batch["feed"] = np.array([face.image for face in batch["detected_faces"]])
+        batch["feed"] = np.zeros((self.batchsize, self.input_size, self.input_size, 1),
+                                 dtype="float32")
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
-        masks = np.zeros(batch["feed"].shape[:-1] + (1,), dtype='uint8')
-        for mask, face in zip(masks, batch["detected_faces"]):
-            parts = self.parse_parts(np.array(face.landmarks_xy))
+        for mask, face in zip(batch["feed"], batch["detected_faces"]):
+            parts = self.parse_parts(np.array(face.feed_landmarks))
             for item in parts:
                 item = np.concatenate(item)
-                hull = cv2.convexHull(item).astype('int32')  # pylint: disable=no-member
-                cv2.fillConvexPoly(mask, hull, 255, lineType=cv2.LINE_AA)
-        batch["prediction"] = masks
+                hull = cv2.convexHull(item).astype("int32")  # pylint: disable=no-member
+                cv2.fillConvexPoly(mask, hull, 1.0, lineType=cv2.LINE_AA)
+        batch["prediction"] = batch["feed"]
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        generator = zip(batch["feed"], batch["detected_faces"], batch["prediction"])
-        for feed, face, prediction in generator:
-            face.image = np.concatenate((feed, prediction), axis=-1)
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
         return batch
 
     @staticmethod
diff --git a/plugins/extract/mask/extended_defaults.py b/plugins/extract/mask/extended_defaults.py
deleted file mode 100644
index f85996e..0000000
--- a/plugins/extract/mask/extended_defaults.py
+++ /dev/null
@@ -1,68 +0,0 @@
-#!/usr/bin/env python3
-"""
-    The default options for the faceswap extended mask plugin.
-
-    Defaults files should be named <plugin_name>_defaults.py
-    Any items placed into this file will automatically get added to the relevant config .ini files
-    within the faceswap/config folder.
-
-    The following variables should be defined:
-        _HELPTEXT: A string describing what this plugin does
-        _DEFAULTS: A dictionary containing the options, defaults and meta information. The
-                   dictionary should be defined as:
-                       {<option_name>: {<metadata>}}
-
-                   <option_name> should always be lower text.
-                   <metadata> dictionary requirements are listed below.
-
-    The following keys are expected for the _DEFAULTS <metadata> dict:
-        datatype:  [required] A python type class. This limits the type of data that can be
-                   provided in the .ini file and ensures that the value is returned in the
-                   correct type to faceswap. Valid datatypes are: <class 'int'>, <class 'float'>,
-                   <class 'str'>, <class 'bool'>.
-        default:   [required] The default value for this option.
-        info:      [required] A string describing what this option does.
-        group:     [optional]. A group for grouping options together in the GUI. If not
-                   provided this will not group this option with any others.
-        choices:   [optional] If this option's datatype is of <class 'str'> then valid
-                   selections can be defined here. This validates the option and also enables
-                   a combobox / radio option in the GUI.
-        gui_radio: [optional] If <choices> are defined, this indicates that the GUI should use
-                   radio buttons rather than a combobox to display this option.
-        min_max:   [partial] For <class 'int'> and <class 'float'> datatypes this is required
-                   otherwise it is ignored. Should be a tuple of min and max accepted values.
-                   This is used for controlling the GUI slider range. Values are not enforced.
-        rounding:  [partial] For <class 'int'> and <class 'float'> datatypes this is
-                   required otherwise it is ignored. Used for the GUI slider. For floats, this
-                   is the number of decimal places to display. For ints this is the step size.
-        fixed:     [optional] [train only]. Training configurations are fixed when the model is
-                   created, and then reloaded from the state file. Marking an item as fixed=False
-                   indicates that this value can be changed for existing models, and will override
-                   the value saved in the state file with the updated value in config. If not
-                   provided this will default to True.
-"""
-
-
-_HELPTEXT = (
-    "Extended options. Mask designed to provide facial segmentation based on the positioning of "
-    "landmark locations. A convenx hull is constructed around the landmarks and the mask is "
-    "extended upwards onto the forehead."
-    )
-
-
-_DEFAULTS = {
-    "batch-size": {
-        "default": 8,
-        "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
-                "but setting it too high can harm performance.\n"
-                "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
-        "datatype": int,
-        "rounding": 1,
-        "min_max": (1, 64),
-        "choices": [],
-        "gui_radio": False,
-        "fixed": True,
-    }
-}
diff --git a/plugins/extract/mask/none.py b/plugins/extract/mask/none.py
index 7ba4403..b2cc6a4 100644
--- a/plugins/extract/mask/none.py
+++ b/plugins/extract/mask/none.py
@@ -1,4 +1,5 @@
 #!/usr/bin/env python3
+""" Dummy empty Mask for faceswap.py """
 
 import numpy as np
 from ._base import Masker, logger
@@ -10,37 +11,27 @@ class Mask(Masker):
         git_model_id = None
         model_filename = None
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
-        self.name = "without a mask"
-        self.colorformat = "BGR"
+        self.input_size = 256
+        self.blur_kernel = None
+        self.name = "None"
         self.vram = 0
-        self.vram_warnings = 0
-        self.vram_per_batch = 30
-        self.batchsize = self.config["batch-size"]
+        self.vram_per_batch = 0
+        self.batchsize = 1
 
     def init_model(self):
         logger.debug("No mask model to initialize")
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        batch["feed"] = np.array([face.image for face in batch["detected_faces"]])
+        batch["feed"] = np.zeros((self.batchsize, self.input_size, self.input_size, 1),
+                                 dtype="float32")
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
-        batch["prediction"] = np.full(batch["feed"].shape[:-1] + (1,),
-                                      fill_value=255,
-                                      dtype='uint8')
+        batch["prediction"] = np.ones_like(batch["feed"], dtype="float32")
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        generator = zip(batch["feed"], batch["detected_faces"], batch["prediction"])
-        for feed, face, prediction in generator:
-            face.image = np.concatenate((feed, prediction), axis=-1)
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
         return batch
diff --git a/plugins/extract/mask/none_defaults.py b/plugins/extract/mask/none_defaults.py
deleted file mode 100644
index 8a97a6e..0000000
--- a/plugins/extract/mask/none_defaults.py
+++ /dev/null
@@ -1,67 +0,0 @@
-#!/usr/bin/env python3
-"""
-    The default options for the faceswap VGG clear plugin.
-
-    Defaults files should be named <plugin_name>_defaults.py
-    Any items placed into this file will automatically get added to the relevant config .ini files
-    within the faceswap/config folder.
-
-    The following variables should be defined:
-        _HELPTEXT: A string describing what this plugin does
-        _DEFAULTS: A dictionary containing the options, defaults and meta information. The
-                   dictionary should be defined as:
-                       {<option_name>: {<metadata>}}
-
-                   <option_name> should always be lower text.
-                   <metadata> dictionary requirements are listed below.
-
-    The following keys are expected for the _DEFAULTS <metadata> dict:
-        datatype:  [required] A python type class. This limits the type of data that can be
-                   provided in the .ini file and ensures that the value is returned in the
-                   correct type to faceswap. Valid datatypes are: <class 'int'>, <class 'float'>,
-                   <class 'str'>, <class 'bool'>.
-        default:   [required] The default value for this option.
-        info:      [required] A string describing what this option does.
-        group:     [optional]. A group for grouping options together in the GUI. If not
-                   provided this will not group this option with any others.
-        choices:   [optional] If this option's datatype is of <class 'str'> then valid
-                   selections can be defined here. This validates the option and also enables
-                   a combobox / radio option in the GUI.
-        gui_radio: [optional] If <choices> are defined, this indicates that the GUI should use
-                   radio buttons rather than a combobox to display this option.
-        min_max:   [partial] For <class 'int'> and <class 'float'> datatypes this is required
-                   otherwise it is ignored. Should be a tuple of min and max accepted values.
-                   This is used for controlling the GUI slider range. Values are not enforced.
-        rounding:  [partial] For <class 'int'> and <class 'float'> datatypes this is
-                   required otherwise it is ignored. Used for the GUI slider. For floats, this
-                   is the number of decimal places to display. For ints this is the step size.
-        fixed:     [optional] [train only]. Training configurations are fixed when the model is
-                   created, and then reloaded from the state file. Marking an item as fixed=False
-                   indicates that this value can be changed for existing models, and will override
-                   the value saved in the state file with the updated value in config. If not
-                   provided this will default to True.
-"""
-
-
-_HELPTEXT = (
-    "None options. An array of all ones is created to provide a 4th channel that will not mask "
-    "any portion of the image."
-    )
-
-
-_DEFAULTS = {
-    "batch-size": {
-        "default": 8,
-        "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
-                "but setting it too high can harm performance.\n"
-                "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
-        "datatype": int,
-        "rounding": 1,
-        "min_max": (1, 64),
-        "choices": [],
-        "gui_radio": False,
-        "fixed": True,
-    }
-}
diff --git a/plugins/extract/mask/unet_dfl.py b/plugins/extract/mask/unet_dfl.py
index 9e2151f..21ae57e 100644
--- a/plugins/extract/mask/unet_dfl.py
+++ b/plugins/extract/mask/unet_dfl.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
+""" UNET DFL face mask plugin """
 
-import cv2
-import keras
 import numpy as np
 from lib.model.session import KSession
 from ._base import Masker, logger
@@ -14,8 +13,8 @@ class Mask(Masker):
         model_filename = "DFL_256_sigmoid_v1.h5"
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
         self.name = "U-Net Mask Network(256)"
-        self.mask_in_size = 256
-        self.colorformat = "BGR"
+        self.input_size = 256
+        self.blur_kernel = 5
         self.vram = 3440
         self.vram_warnings = 1024  # TODO determine
         self.vram_per_batch = 64  # TODO determine
@@ -24,48 +23,22 @@ class Mask(Masker):
     def init_model(self):
         self.model = KSession(self.name, self.model_path, model_kwargs=dict())
         self.model.load_model()
-        self.input = np.zeros((self.batchsize, self.mask_in_size, self.mask_in_size, 3),
-                              dtype="float32")
-        self.model.predict(self.input)
+        placeholder = np.zeros((self.batchsize, self.input_size, self.input_size, 3),
+                               dtype="float32")
+        self.model.predict(placeholder)
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        for index, face in enumerate(batch["detected_faces"]):
-            face.load_aligned(face.image,
-                              size=self.mask_in_size,
-                              dtype='float32')
-            self.input[index] = face.aligned["face"][..., :3]
-        batch["feed"] = self.input / 255.
+        batch["feed"] = np.array([face.feed_face[..., :3]
+                                  for face in batch["detected_faces"]], dtype="float32") / 255.0
+        logger.trace("feed shape: %s", batch["feed"].shape)
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
-        predictions = self.model.predict(batch["feed"])
-        batch["prediction"] = predictions * 255.
+        batch["prediction"] = self.model.predict(batch["feed"])
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        for idx, (face, predicts) in enumerate(zip(batch["detected_faces"], batch["prediction"])):
-            generator = (cv2.GaussianBlur(mask, (7, 7), 0) for mask in predicts)
-            predicted = np.array(tuple(generator))
-            predicted[predicted < 10.] = 0.
-            predicted[predicted > 245.] = 255.
-
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            feed_face = face.feed["face"][..., :3]
-            feed_mask = self._resize(predicted, self.input_size).astype('uint8')
-            batch["detected_faces"][idx].feed["face"] = np.concatenate((feed_face,
-                                                                        feed_mask),
-                                                                       axis=-1)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
-            ref_face = face.reference["face"][..., :3]
-            ref_mask = self._resize(predicted, self.output_size).astype('uint8')
-            batch["detected_faces"][idx].reference["face"] = np.concatenate((ref_face,
-                                                                             ref_mask),
-                                                                            axis=-1)
         return batch
diff --git a/plugins/extract/mask/unet_dfl_defaults.py b/plugins/extract/mask/unet_dfl_defaults.py
index c153920..a00b170 100644
--- a/plugins/extract/mask/unet_dfl_defaults.py
+++ b/plugins/extract/mask/unet_dfl_defaults.py
@@ -44,7 +44,7 @@
 
 
 _HELPTEXT = (
-    "UNET_DFL options. Mask designed to provide smart segmentation of mostly frontal faces. "
+    "UNET_DFL options. Mask designed to provide smart segmentation of mostly frontal faces.\n"
     "The mask model has been trained by community members. Insert more commentary on testing "
     "here. Profile faces may result in sub-par performance."
     )
@@ -56,8 +56,7 @@ _DEFAULTS = {
         "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
                 "but setting it too high can harm performance.\n"
                 "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
+                "accomodate then this will automatically be lowered.",
         "datatype": int,
         "rounding": 1,
         "min_max": (1, 64),
diff --git a/plugins/extract/mask/vgg_clear.py b/plugins/extract/mask/vgg_clear.py
index 5ee02a8..c22171b 100644
--- a/plugins/extract/mask/vgg_clear.py
+++ b/plugins/extract/mask/vgg_clear.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
+""" VGG Clear face mask plugin """
 
-import cv2
-import keras
 import numpy as np
 from lib.model.session import KSession
 from ._base import Masker, logger
@@ -14,8 +13,8 @@ class Mask(Masker):
         model_filename = "Nirkin_300_softmax_v1.h5"
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
         self.name = "VGG Mask Network(300)"
-        self.mask_in_size = 300
-        self.colorformat = "BGR"
+        self.input_size = 300
+        self.blur_kernel = 7
         self.vram = 2000  # TODO determine
         self.vram_warnings = 1024  # TODO determine
         self.vram_per_batch = 64  # TODO determine
@@ -24,51 +23,25 @@ class Mask(Masker):
     def init_model(self):
         self.model = KSession(self.name, self.model_path, model_kwargs=dict())
         self.model.load_model()
-        o = keras.layers.core.Activation('softmax',
-                                         name='softmax')(self.model._model.layers[-1].output)
-        self.model._model = keras.models.Model(inputs=self.model._model.input, outputs=[o])
-        self.input = np.zeros((self.batchsize, self.mask_in_size, self.mask_in_size, 3),
-                              dtype="float32")
-        self.model.predict(self.input)
+        self.model.append_softmax_activation(layer_index=-1)
+        placeholder = np.zeros((self.batchsize, self.input_size, self.input_size, 3),
+                               dtype="float32")
+        self.model.predict(placeholder)
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        for index, face in enumerate(batch["detected_faces"]):
-            face.load_aligned(face.image,
-                              size=self.mask_in_size,
-                              dtype='float32')
-            self.input[index] = face.aligned["face"][..., :3]
-        batch["feed"] = self.input - np.mean(self.input, axis=(1, 2))[:, None, None, :]
+        input_ = np.array([face.feed_face[..., :3]
+                           for face in batch["detected_faces"]], dtype="float32")
+        batch["feed"] = input_ - np.mean(input_, axis=(1, 2))[:, None, None, :]
+        logger.trace("feed shape: %s", batch["feed"].shape)
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
         predictions = self.model.predict(batch["feed"])
-        batch["prediction"] = predictions[..., 1:2] * 255.
+        batch["prediction"] = predictions[..., -1]
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        for idx, (face, predicts) in enumerate(zip(batch["detected_faces"], batch["prediction"])):
-            generator = (cv2.GaussianBlur(mask, (7, 7), 0) for mask in predicts)
-            predicted = np.array(tuple(generator))
-            predicted[predicted < 10.] = 0.
-            predicted[predicted > 245.] = 255.
-
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            feed_face = face.feed["face"][..., :3]
-            feed_mask = self._resize(predicted, self.input_size).astype('uint8')
-            batch["detected_faces"][idx].feed["face"] = np.concatenate((feed_face,
-                                                                        feed_mask),
-                                                                       axis=-1)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
-            ref_face = face.reference["face"][..., :3]
-            ref_mask = self._resize(predicted, self.output_size).astype('uint8')
-            batch["detected_faces"][idx].reference["face"] = np.concatenate((ref_face,
-                                                                             ref_mask),
-                                                                            axis=-1)
         return batch
diff --git a/plugins/extract/mask/vgg_clear_defaults.py b/plugins/extract/mask/vgg_clear_defaults.py
index 5b12069..003a943 100644
--- a/plugins/extract/mask/vgg_clear_defaults.py
+++ b/plugins/extract/mask/vgg_clear_defaults.py
@@ -45,7 +45,7 @@
 
 _HELPTEXT = (
     "VGG_Clear options. Mask designed to provide smart segmentation of mostly frontal faces clear "
-    "of obstructions.  Profile faces and obstructions may result in sub-par performance."
+    "of obstructions.\nProfile faces and obstructions may result in sub-par performance."
     )
 
 
@@ -55,8 +55,7 @@ _DEFAULTS = {
         "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
                 "but setting it too high can harm performance.\n"
                 "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
+                "accomodate then this will automatically be lowered.",
         "datatype": int,
         "rounding": 1,
         "min_max": (1, 64),
diff --git a/plugins/extract/mask/vgg_obstructed.py b/plugins/extract/mask/vgg_obstructed.py
index 85ae018..e1faf44 100644
--- a/plugins/extract/mask/vgg_obstructed.py
+++ b/plugins/extract/mask/vgg_obstructed.py
@@ -1,7 +1,6 @@
 #!/usr/bin/env python3
+""" VGG Obstructed face mask plugin """
 
-import cv2
-import keras
 import numpy as np
 from lib.model.session import KSession
 from ._base import Masker, logger
@@ -14,8 +13,8 @@ class Mask(Masker):
         model_filename = "Nirkin_500_softmax_v1.h5"
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
         self.name = "VGG Mask Network(500)"
-        self.mask_in_size = 500
-        self.colorformat = "BGR"
+        self.input_size = 500
+        self.blur_kernel = 9
         self.vram = 3000  # TODO determine
         self.vram_warnings = 1024  # TODO determine
         self.vram_per_batch = 64  # TODO determine
@@ -24,51 +23,24 @@ class Mask(Masker):
     def init_model(self):
         self.model = KSession(self.name, self.model_path, model_kwargs=dict())
         self.model.load_model()
-        o = keras.layers.core.Activation('softmax',
-                                         name='softmax')(self.model._model.layers[-1].output)
-        self.model._model = keras.models.Model(inputs=self.model._model.input, outputs=[o])
-        self.input = np.zeros((self.batchsize, self.mask_in_size, self.mask_in_size, 3),
-                              dtype="float32")
-        self.model.predict(self.input)
+        self.model.append_softmax_activation(layer_index=-1)
+        placeholder = np.zeros((self.batchsize, self.input_size, self.input_size, 3),
+                               dtype="float32")
+        self.model.predict(placeholder)
 
     def process_input(self, batch):
         """ Compile the detected faces for prediction """
-        for index, face in enumerate(batch["detected_faces"]):
-            face.load_aligned(face.image,
-                              size=self.mask_in_size,
-                              dtype='float32')
-            self.input[index] = face.aligned["face"][..., :3]
-        batch["feed"] = self.input - np.mean(self.input, axis=(1, 2))[:, None, None, :]
+        input_ = [face.feed_face[..., :3] for face in batch["detected_faces"]]
+        batch["feed"] = input_ - np.mean(input_, axis=(1, 2))[:, None, None, :]
+        logger.trace("feed shape: %s", batch["feed"].shape)
         return batch
 
     def predict(self, batch):
         """ Run model to get predictions """
         predictions = self.model.predict(batch["feed"])
-        batch["prediction"] = predictions[..., 0:1] * -255. + 255.
+        batch["prediction"] = predictions[..., 0] * -1.0 + 1.0
         return batch
 
     def process_output(self, batch):
         """ Compile found faces for output """
-        for idx, (face, predicts) in enumerate(zip(batch["detected_faces"], batch["prediction"])):
-            generator = (cv2.GaussianBlur(mask, (7, 7), 0) for mask in predicts)
-            predicted = np.array(tuple(generator))
-            predicted[predicted < 10.] = 0.
-            predicted[predicted > 245.] = 255.
-
-            face.load_feed_face(face.image,
-                                size=self.input_size,
-                                coverage_ratio=self.coverage_ratio)
-            feed_face = face.feed["face"][..., :3]
-            feed_mask = self._resize(predicted, self.input_size).astype('uint8')
-            batch["detected_faces"][idx].feed["face"] = np.concatenate((feed_face,
-                                                                        feed_mask),
-                                                                       axis=-1)
-            face.load_reference_face(face.image,
-                                     size=self.output_size,
-                                     coverage_ratio=self.coverage_ratio)
-            ref_face = face.reference["face"][..., :3]
-            ref_mask = self._resize(predicted, self.output_size).astype('uint8')
-            batch["detected_faces"][idx].reference["face"] = np.concatenate((ref_face,
-                                                                             ref_mask),
-                                                                            axis=-1)
         return batch
diff --git a/plugins/extract/mask/vgg_obstructed_defaults.py b/plugins/extract/mask/vgg_obstructed_defaults.py
index d1ed3bf..89e42ce 100644
--- a/plugins/extract/mask/vgg_obstructed_defaults.py
+++ b/plugins/extract/mask/vgg_obstructed_defaults.py
@@ -44,9 +44,9 @@
 
 
 _HELPTEXT = (
-    "VGG_Obstructed options. Mask designed to provide smart segmentation of mostly frontal faces. "
-    "The mask model has been specifically trained to recognize some facial obstructions ( "
-    "hands and eyeglasses ). Profile faces may result in sub-par performance."
+    "VGG_Obstructed options. Mask designed to provide smart segmentation of mostly frontal "
+    "faces.\nThe mask model has been specifically trained to recognize some facial obstructions "
+    "(hands and eyeglasses). Profile faces may result in sub-par performance."
     )
 
 
@@ -56,8 +56,7 @@ _DEFAULTS = {
         "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
                 "but setting it too high can harm performance.\n"
                 "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
-                "accomodate then this will automatically be lowered."
-                "\n\tAMD users: A batchsize of 8 requires about xxxx GB vram.",
+                "accomodate then this will automatically be lowered.",
         "datatype": int,
         "rounding": 1,
         "min_max": (1, 64),
diff --git a/plugins/extract/pipeline.py b/plugins/extract/pipeline.py
index 14293af..4cc28c9 100644
--- a/plugins/extract/pipeline.py
+++ b/plugins/extract/pipeline.py
@@ -59,23 +59,18 @@ class Extractor():
     """
     def __init__(self, detector, aligner, masker, configfile=None,
                  multiprocess=False, rotate_images=None, min_size=20,
-                 normalize_method=None, input_size=256, output_size=256, coverage_ratio=1.):
+                 normalize_method=None):
         logger.debug("Initializing %s: (detector: %s, aligner: %s, masker: %s, "
                      "configfile: %s, multiprocess: %s, rotate_images: %s, min_size: %s, "
-                     "normalize_method: %s, input_size: %s, output_size: %s, coverage_ratio: %s)",
+                     "normalize_method: %s)",
                      self.__class__.__name__, detector, aligner, masker, configfile,
-                     multiprocess, rotate_images, min_size, normalize_method, input_size,
-                     output_size, coverage_ratio)
+                     multiprocess, rotate_images, min_size, normalize_method)
         self.phase = "detect"
         self._queue_size = 32
         self._vram_buffer = 320  # Leave a buffer for VRAM allocation
         self._detector = self._load_detector(detector, rotate_images, min_size, configfile)
         self._aligner = self._load_aligner(aligner, configfile, normalize_method)
-        self._masker = self._load_masker(masker,
-                                         configfile,
-                                         input_size,
-                                         output_size,
-                                         coverage_ratio)
+        self._masker = self._load_masker(masker, configfile)
         self._is_parallel = self._set_parallel_processing(multiprocess)
         self._set_extractor_batchsize()
         self._queues = self._add_queues()
@@ -336,14 +331,11 @@ class Extractor():
         return aligner
 
     @staticmethod
-    def _load_masker(masker, configfile, input_size, output_size, coverage_ratio):
+    def _load_masker(masker, configfile):
         """ Set global arguments and load masker plugin """
         masker_name = masker.replace("-", "_").lower()
         logger.debug("Loading Masker: '%s'", masker_name)
-        masker = PluginLoader.get_masker(masker_name)(configfile=configfile,
-                                                      input_size=input_size,
-                                                      output_size=output_size,
-                                                      coverage_ratio=coverage_ratio)
+        masker = PluginLoader.get_masker(masker_name)(configfile=configfile)
         return masker
 
     def _launch_detector(self):
@@ -374,15 +366,17 @@ class Extractor():
         logger.debug("Launched Masker")
 
     def _set_extractor_batchsize(self):
-        """ 
+        """
         Sets the batchsize of the requested plugins based on their vram and
         vram_per_batch_requirements if the the configured batchsize requires more
         vram than is available. Nvidia only.
         """
-        if (self._detector.vram == 0 and self._aligner.vram == 0 and self._masker.vram == 0
-            or get_backend() != "nvidia"):
-            logger.debug("Either detector and aligner have no VRAM requirements or not running "
-                         "on Nvidia. Not updating batchsize requirements.")
+        if get_backend() != "nvidia":
+            logger.debug("Backend is not Nvidia. Not updating batchsize requirements")
+            return
+        if self._detector.vram == 0 and self._aligner.vram == 0 and self._masker.vram == 0:
+            logger.debug("Either detector, aligner or masker have no VRAM requirements. Not "
+                         "updating batchsize requirements.")
             return
         stats = GPUStats().get_card_most_free()
         vram_free = int(stats["free"])
diff --git a/plugins/train/trainer/_base.py b/plugins/train/trainer/_base.py
index 170d476..1247d68 100644
--- a/plugins/train/trainer/_base.py
+++ b/plugins/train/trainer/_base.py
@@ -27,13 +27,14 @@ import time
 import cv2
 import numpy as np
 
+import tensorflow as tf
+from tensorflow.python import errors_impl as tf_errors  # pylint:disable=no-name-in-module
+
 from lib.alignments import Alignments
 from lib.faces_detect import DetectedFace
 from lib.training_data import TrainingDataGenerator
 from lib.utils import FaceswapError, get_folder, get_image_paths
 from plugins.train._config import Config
-from tensorflow.python import errors_impl as tf_errors  # pylint:disable=no-name-in-module
-import tensorflow as tf
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
@@ -342,7 +343,7 @@ class Batcher():
         batchsize = len(batch["samples"])
         images = batch["targets"][self.model.largest_face_index]
         masks = batch["masks"][0]
-        sample = self.compile_sample(batchsize, 
+        sample = self.compile_sample(batchsize,
                                      samples=batch["samples"],
                                      images=images,
                                      masks=masks)
