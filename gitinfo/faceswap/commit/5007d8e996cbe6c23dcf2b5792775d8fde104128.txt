commit 5007d8e996cbe6c23dcf2b5792775d8fde104128
Author: Clorr <Github@clorr.fr>
Date:   Sat Mar 10 10:38:50 2018 +0100

    Fixes (#267)

diff --git a/plugins/Extract_Align/Extract.py b/plugins/Extract_Align.py
similarity index 100%
rename from plugins/Extract_Align/Extract.py
rename to plugins/Extract_Align.py
diff --git a/plugins/Extract_Align/__init__.py b/plugins/Extract_Align/__init__.py
deleted file mode 100644
index cc3ec8c..0000000
--- a/plugins/Extract_Align/__init__.py
+++ /dev/null
@@ -1,6 +0,0 @@
-# -*- coding: utf-8 -*-
-
-__author__ = """Based on https://reddit.com/u/deepfakes/"""
-__version__ = '0.1.0'
-
-from .Extract import Extract
\ No newline at end of file
diff --git a/plugins/Model_Original/Trainer.py b/plugins/Model_Original/Trainer.py
index 5b1c918..d31ac91 100644
--- a/plugins/Model_Original/Trainer.py
+++ b/plugins/Model_Original/Trainer.py
@@ -1,50 +1,56 @@
-
-import time
-import numpy
-from lib.training_data import TrainingDataGenerator, stack_images
-
-class Trainer():
-    random_transform_args = {
-        'rotation_range': 10,
-        'zoom_range': 0.05,
-        'shift_range': 0.05,
-        'random_flip': 0.4,
-    }
-
-    def __init__(self, model, fn_A, fn_B, batch_size, *args):
-        self.batch_size = batch_size
-        self.model = model
-
-        generator = TrainingDataGenerator(self.random_transform_args, 160)
-        self.images_A = generator.minibatchAB(fn_A, self.batch_size)
-        self.images_B = generator.minibatchAB(fn_B, self.batch_size)
-
-    def train_one_step(self, iter, viewer):
-        epoch, warped_A, target_A = next(self.images_A)
-        epoch, warped_B, target_B = next(self.images_B)
-
-        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
-        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
-        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B),
-            end='\r')
-
-        if viewer is not None:
-            viewer(self.show_sample(target_A[0:14], target_B[0:14]), "training")
-
-    def show_sample(self, test_A, test_B):
-        figure_A = numpy.stack([
-            test_A,
-            self.model.autoencoder_A.predict(test_A),
-            self.model.autoencoder_B.predict(test_A),
-        ], axis=1)
-        figure_B = numpy.stack([
-            test_B,
-            self.model.autoencoder_B.predict(test_B),
-            self.model.autoencoder_A.predict(test_B),
-        ], axis=1)
-
-        figure = numpy.concatenate([figure_A, figure_B], axis=0)
-        figure = figure.reshape((4, 7) + figure.shape[1:])
-        figure = stack_images(figure)
-
-        return numpy.clip(figure * 255, 0, 255).astype('uint8')
+
+import time
+import numpy
+from lib.training_data import TrainingDataGenerator, stack_images
+
+class Trainer():
+    random_transform_args = {
+        'rotation_range': 10,
+        'zoom_range': 0.05,
+        'shift_range': 0.05,
+        'random_flip': 0.4,
+    }
+
+    def __init__(self, model, fn_A, fn_B, batch_size=64):
+        self.batch_size = batch_size
+        self.model = model
+
+        generator = TrainingDataGenerator(self.random_transform_args, 160)
+        self.images_A = generator.minibatchAB(fn_A, self.batch_size)
+        self.images_B = generator.minibatchAB(fn_B, self.batch_size)
+
+    def train_one_step(self, iter, viewer):
+        epoch, warped_A, target_A = next(self.images_A)
+        epoch, warped_B, target_B = next(self.images_B)
+
+        loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
+        loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
+        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B),
+            end='\r')
+
+        if viewer is not None:
+            viewer(self.show_sample(target_A[0:14], target_B[0:14]), "training")
+
+    def show_sample(self, test_A, test_B):
+        figure_A = numpy.stack([
+            test_A,
+            self.model.autoencoder_A.predict(test_A),
+            self.model.autoencoder_B.predict(test_A),
+        ], axis=1)
+        figure_B = numpy.stack([
+            test_B,
+            self.model.autoencoder_B.predict(test_B),
+            self.model.autoencoder_A.predict(test_B),
+        ], axis=1)
+
+        if test_A.shape[0] % 2 == 1:
+            figure_A = numpy.concatenate ([figure_A, numpy.expand_dims(figure_A[0],0) ])
+            figure_B = numpy.concatenate ([figure_B, numpy.expand_dims(figure_B[0],0) ])
+        
+        figure = numpy.concatenate([figure_A, figure_B], axis=0)
+        w = 4
+        h = int( figure.shape[0] / w)        
+        figure = figure.reshape((w, h) + figure.shape[1:])        
+        figure = stack_images(figure)
+        
+        return numpy.clip(figure * 255, 0, 255).astype('uint8')
diff --git a/scripts/train.py b/scripts/train.py
index 72ab106..411408e 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -132,22 +132,22 @@ class TrainingProcessor(object):
         thr.join() # waits until thread finishes
 
     def processThread(self):
-        if self.arguments.allow_growth:
-            self.set_tf_allow_growth()
+        try:
+            if self.arguments.allow_growth:
+                self.set_tf_allow_growth()
 
-        print('Loading data, this may take a while...')
-        # this is so that you can enter case insensitive values for trainer
-        trainer = self.arguments.trainer
-        trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
-        model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir))
-        model.load(swapped=False)
+            print('Loading data, this may take a while...')
+            # this is so that you can enter case insensitive values for trainer
+            trainer = self.arguments.trainer
+            trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
+            model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir))
+            model.load(swapped=False)
 
-        images_A = get_image_paths(self.arguments.input_A)
-        images_B = get_image_paths(self.arguments.input_B)
-        trainer = PluginLoader.get_trainer(trainer)
-        trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
+            images_A = get_image_paths(self.arguments.input_A)
+            images_B = get_image_paths(self.arguments.input_B)
+            trainer = PluginLoader.get_trainer(trainer)
+            trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
 
-        try:
             print('Starting. Press "Enter" to stop training and save model')
 
             for epoch in range(0, self.arguments.epochs):
