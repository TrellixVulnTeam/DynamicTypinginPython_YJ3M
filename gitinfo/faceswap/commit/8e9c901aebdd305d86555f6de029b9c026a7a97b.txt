commit 8e9c901aebdd305d86555f6de029b9c026a7a97b
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sat Jul 6 09:44:01 2019 +0000

    Bugfix: Extract - Remove BoundingBox object and replace with dict

diff --git a/lib/face_filter.py b/lib/face_filter.py
index 5ffae46..cd1226f 100644
--- a/lib/face_filter.py
+++ b/lib/face_filter.py
@@ -105,7 +105,7 @@ class FaceFilter():
             landmarks = face["landmarks"][0]
 
             detected_face = DetectedFace()
-            detected_face.from_bounding_box(bounding_box, image)
+            detected_face.from_bounding_box_dict(bounding_box, image)
             detected_face.landmarksXY = landmarks
             detected_face.load_aligned(image, size=224)
             face["face"] = detected_face.aligned_face
diff --git a/lib/faces_detect.py b/lib/faces_detect.py
index fe8f090..b6ffa81 100644
--- a/lib/faces_detect.py
+++ b/lib/faces_detect.py
@@ -38,28 +38,24 @@ class DetectedFace():
         """ Landmarks as XY """
         return self.landmarksXY
 
-    def to_bounding_box(self):
-        """ Return Bounding Box as BoundingBox """
-        left = self.x
-        top = self.y
-        right = self.x + self.w
-        bottom = self.y + self.h
-        retval = BoundingBox(left, top, right, bottom)
+    def to_bounding_box_dict(self):
+        """ Return Bounding Box as a bounding box dixt """
+        retval = dict(left=self.x, top=self.y, right=self.x + self.w, bottom=self.y + self.h)
         logger.trace("Returning: %s", retval)
         return retval
 
-    def from_bounding_box(self, bounding_box, image=None):
-        """ Set Bounding Box from a BoundingBox """
-        logger.trace("Creating from BoundingBox: %s", bounding_box)
-        if not isinstance(bounding_box, BoundingBox):
-            raise ValueError("Supplied Bounding Box is not a BoundingBox.")
-        self.x = bounding_box.left
-        self.w = bounding_box.width
-        self.y = bounding_box.top
-        self.h = bounding_box.height
+    def from_bounding_box_dict(self, bounding_box_dict, image=None):
+        """ Set Bounding Box from a bounding box dict """
+        logger.trace("Creating from bounding box dict: %s", bounding_box_dict)
+        if not isinstance(bounding_box_dict, dict):
+            raise ValueError("Supplied Bounding Box is not a dictionary.")
+        self.x = bounding_box_dict["left"]
+        self.w = bounding_box_dict["right"] - bounding_box_dict["left"]
+        self.y = bounding_box_dict["top"]
+        self.h = bounding_box_dict["bottom"] - bounding_box_dict["top"]
         if image is not None and image.any():
             self.image_to_face(image)
-        logger.trace("Created from BoundingBox: (x: %s, w: %s, y: %s. h: %s)",
+        logger.trace("Created from bounding box dict: (x: %s, w: %s, y: %s. h: %s)",
                      self.x, self.w, self.y, self.h)
 
     def image_to_face(self, image):
@@ -262,42 +258,3 @@ class DetectedFace():
     def reference_interpolators(self):
         """ Return the interpolators for an output face """
         return get_matrix_scaling(self.reference_matrix)
-
-
-class BoundingBox():
-    """ Bounding box class """
-    def __init__(self, left, top, right, bottom):
-        logger.trace("Initializing %s: (left: %s, top: %s, right: %s, bottom: %s)",
-                     self.__class__.__name__, left, top, right, bottom)
-        self._box = (left, top, right, bottom)
-        logger.trace("Initialized %s", self.__class__.__name__)
-
-    @property
-    def left(self):
-        """ Return left point as int """
-        return int(round(self._box[0]))
-
-    @property
-    def top(self):
-        """ Return top point as int """
-        return int(round(self._box[1]))
-
-    @property
-    def right(self):
-        """ Return right point as int """
-        return int(round(self._box[2]))
-
-    @property
-    def bottom(self):
-        """ Return bottom point as int """
-        return int(round(self._box[3]))
-
-    @property
-    def width(self):
-        """ Return width of bounding box """
-        return self.right - self.left
-
-    @property
-    def height(self):
-        """ Return height of bounding box """
-        return self.bottom - self.top
diff --git a/lib/utils.py b/lib/utils.py
index c63e88c..ac3a91d 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -18,7 +18,7 @@ import numpy as np
 import cv2
 
 
-from lib.faces_detect import BoundingBox, DetectedFace
+from lib.faces_detect import DetectedFace
 
 
 # Global variables
@@ -200,10 +200,12 @@ def rotate_landmarks(face, rotation_matrix):
     # pylint:disable=c-extension-no-member
     """ Rotate the landmarks and bounding box for faces
         found in rotated images.
-        Pass in a DetectedFace object, Alignments dict or BoundingBox"""
+        Pass in a DetectedFace object, Alignments dict or bounding box dict
+        (as defined in lib/plugins/extract/detect/_base.py) """
     logger = logging.getLogger(__name__)  # pylint:disable=invalid-name
     logger.trace("Rotating landmarks: (rotation_matrix: %s, type(face): %s",
                  rotation_matrix, type(face))
+    # Detected Face Object
     if isinstance(face, DetectedFace):
         bounding_box = [[face.x, face.y],
                         [face.x + face.w, face.y],
@@ -211,7 +213,8 @@ def rotate_landmarks(face, rotation_matrix):
                         [face.x, face.y + face.h]]
         landmarks = face.landmarksXY
 
-    elif isinstance(face, dict):
+    # Alignments Dict
+    elif isinstance(face, dict) and "x" in face:
         bounding_box = [[face.get("x", 0), face.get("y", 0)],
                         [face.get("x", 0) + face.get("w", 0),
                          face.get("y", 0)],
@@ -221,12 +224,14 @@ def rotate_landmarks(face, rotation_matrix):
                          face.get("y", 0) + face.get("h", 0)]]
         landmarks = face.get("landmarksXY", list())
 
-    elif isinstance(face, BoundingBox):
-        bounding_box = [[face.left, face.top],
-                        [face.right, face.top],
-                        [face.right, face.bottom],
-                        [face.left, face.bottom]]
+    # Bounding Box Dict
+    elif isinstance(face, dict) and "left" in face:
+        bounding_box = [[face["left"], face["top"]],
+                        [face["right"], face["top"]],
+                        [face["right"], face["bottom"]],
+                        [face["left"], face["bottom"]]]
         landmarks = list()
+
     else:
         raise ValueError("Unsupported face type")
 
@@ -250,28 +255,32 @@ def rotate_landmarks(face, rotation_matrix):
     pt_y = min([pnt[1] for pnt in rotated[0]])
     pt_x1 = max([pnt[0] for pnt in rotated[0]])
     pt_y1 = max([pnt[1] for pnt in rotated[0]])
+    width = pt_x1 - pt_x
+    height = pt_y1 - pt_y
 
     if isinstance(face, DetectedFace):
         face.x = int(pt_x)
         face.y = int(pt_y)
-        face.w = int(pt_x1 - pt_x)
-        face.h = int(pt_y1 - pt_y)
+        face.w = int(width)
+        face.h = int(height)
         face.r = 0
         if len(rotated) > 1:
             rotated_landmarks = [tuple(point) for point in rotated[1].tolist()]
             face.landmarksXY = rotated_landmarks
-    elif isinstance(face, dict):
+    elif isinstance(face, dict) and "x" in face:
         face["x"] = int(pt_x)
         face["y"] = int(pt_y)
-        face["w"] = int(pt_x1 - pt_x)
-        face["h"] = int(pt_y1 - pt_y)
+        face["w"] = int(width)
+        face["h"] = int(height)
         face["r"] = 0
         if len(rotated) > 1:
             rotated_landmarks = [tuple(point) for point in rotated[1].tolist()]
             face["landmarksXY"] = rotated_landmarks
     else:
-        rotated_landmarks = BoundingBox(pt_x, pt_y, pt_x1, pt_y1)
-        face = rotated_landmarks
+        face["left"] = int(pt_x)
+        face["top"] = int(pt_y)
+        face["right"] = int(pt_x1)
+        face["bottom"] = int(pt_y1)
 
     logger.trace("Rotated landmarks: %s", rotated_landmarks)
     return face
diff --git a/plugins/extract/align/_base.py b/plugins/extract/align/_base.py
index b20f353..3142cf5 100644
--- a/plugins/extract/align/_base.py
+++ b/plugins/extract/align/_base.py
@@ -8,12 +8,12 @@
     The plugin will receive a dict containing:
     {"filename": <filename of source frame>,
      "image": <source image>,
-     "detected_faces": <list of BoundingBoxes>}
+     "detected_faces": <list of bounding box dicts as defined in lib/plugins/extract/detect/_base>}
 
     For each source item, the plugin must pass a dict to finalize containing:
     {"filename": <filename of source frame>,
      "image": <source image>,
-     "detected_faces": <list of BoundingBoxes>, (Class defined in /lib/faces_detect)
+     "detected_faces": <list of bounding box dicts as defined in lib/plugins/extract/detect/_base>,
      "landmarks": <list of landmarks>}
     """
 
diff --git a/plugins/extract/align/cv2_dnn.py b/plugins/extract/align/cv2_dnn.py
index 9e5033e..22d2768 100644
--- a/plugins/extract/align/cv2_dnn.py
+++ b/plugins/extract/align/cv2_dnn.py
@@ -64,8 +64,13 @@ class Align(Aligner):
         """ Align the incoming image for prediction """
         logger.trace("Aligning image around center")
 
-        box = (detected_face.left, detected_face.top, detected_face.right, detected_face.bottom)
-        diff_height_width = detected_face.height - detected_face.width
+        box = (detected_face["left"],
+               detected_face["top"],
+               detected_face["right"],
+               detected_face["bottom"])
+        height = detected_face["bottom"] - detected_face["top"]
+        width = detected_face["right"] - detected_face["left"]
+        diff_height_width = height - width
         offset_y = int(abs(diff_height_width / 2))
         box_moved = self.move_box(box, [0, offset_y])
 
@@ -131,6 +136,7 @@ class Align(Aligner):
             top += abs(top)
 
         # Make sure box is always square.
+        print(right, left, bottom, top)
         assert ((right - left) == (bottom - top)), 'Box is not square.'
 
         return [left, top, right, bottom]
diff --git a/plugins/extract/align/fan.py b/plugins/extract/align/fan.py
index 3f32931..f9bc2a4 100644
--- a/plugins/extract/align/fan.py
+++ b/plugins/extract/align/fan.py
@@ -58,12 +58,15 @@ class Align(Aligner):
     def get_center_scale(self, detected_face):
         """ Get the center and set scale of bounding box """
         logger.trace("Calculating center and scale")
-        center = np.array([(detected_face.left + detected_face.right) / 2.0,
-                           (detected_face.top + detected_face.bottom) / 2.0])
+        center = np.array([(detected_face["left"] + detected_face["right"]) / 2.0,
+                           (detected_face["top"] + detected_face["bottom"]) / 2.0])
 
-        center[1] -= detected_face.height * 0.12
+        height = detected_face["bottom"] - detected_face["top"]
+        width = detected_face["right"] - detected_face["left"]
 
-        scale = (detected_face.width + detected_face.height) / self.reference_scale
+        center[1] -= height * 0.12
+
+        scale = (width + height) / self.reference_scale
 
         logger.trace("Calculated center and scale: %s, %s", center, scale)
         return center, scale
diff --git a/plugins/extract/align/fan_amd.py b/plugins/extract/align/fan_amd.py
index 25930b5..cc5bce3 100644
--- a/plugins/extract/align/fan_amd.py
+++ b/plugins/extract/align/fan_amd.py
@@ -51,12 +51,15 @@ class Align(Aligner):
     def get_center_scale(self, detected_face):
         """ Get the center and set scale of bounding box """
         logger.trace("Calculating center and scale")
-        center = np.array([(detected_face.left + detected_face.right) / 2.0,
-                           (detected_face.top + detected_face.bottom) / 2.0])
+        center = np.array([(detected_face["left"] + detected_face["right"]) / 2.0,
+                           (detected_face["top"] + detected_face["bottom"]) / 2.0])
 
-        center[1] -= detected_face.height * 0.12
+        height = detected_face["bottom"] - detected_face["top"]
+        width = detected_face["right"] - detected_face["left"]
 
-        scale = (detected_face.width + detected_face.height) / self.reference_scale
+        center[1] -= height * 0.12
+
+        scale = (width + height) / self.reference_scale
 
         logger.trace("Calculated center and scale: %s, %s", center, scale)
         return center, scale
@@ -244,7 +247,7 @@ class TorchBatchNorm2D(keras.engine.base_layer.Layer):
         return dict(list(base_config.items()) + list(config.items()))
 
 
-class FAN(object):
+class FAN():
     """
     Converted from pyTorch from
     https://github.com/1adrianb/face-alignment
@@ -264,5 +267,5 @@ class FAN(object):
 
     def predict(self, feed_item):
         """ Predict landmarks in session """
-        d = self.model.predict(feed_item)
-        return [d[-1].reshape((68, 64, 64))]
+        pred = self.model.predict(feed_item)
+        return [pred[-1].reshape((68, 64, 64))]
diff --git a/plugins/extract/detect/_base.py b/plugins/extract/detect/_base.py
index 7b2de45..e7bbb17 100755
--- a/plugins/extract/detect/_base.py
+++ b/plugins/extract/detect/_base.py
@@ -8,7 +8,9 @@
     For each source frame, the plugin must pass a dict to finalize containing:
     {"filename": <filename of source frame>,
      "image": <source image>,
-     "detected_faces": <list of BoundingBoxes>} (Class defined in /lib/faces_detect)
+     "detected_faces": <list of dicts containing bounding box points>}}
+
+    - Use the function self.to_bounding_box_dict(left, right, top, bottom) to define the dict
     """
 
 import logging
@@ -18,7 +20,6 @@ from io import StringIO
 
 import cv2
 
-from lib.faces_detect import BoundingBox
 from lib.gpu_stats import GPUStats
 from lib.utils import deprecation_warning, rotate_landmarks, GetModel
 from plugins.extract._config import Config
@@ -86,11 +87,6 @@ class Detector():
             Override for specific detector """
         logger.debug("initialize %s (PID: %s, args: %s, kwargs: %s)",
                      self.__class__.__name__, os.getpid(), args, kwargs)
-        # Sometimes BoundingBox doesn't get imported from the parent process
-        # Hacky fix to import it inside the process
-        global BoundingBox  # pylint:disable=global-statement,invalid-name
-        from lib.faces_detect import BoundingBox as bb  # pylint:disable=reimported
-        BoundingBox = bb
         self.init = kwargs.get("event", False)
         self.error = kwargs.get("error", False)
         self.queues["in"] = kwargs["in_queue"]
@@ -99,7 +95,7 @@ class Detector():
     def detect_faces(self, *args, **kwargs):
         """ Detect faces in rgb image
             Override for specific detector
-            Must return a list of BoundingBox's"""
+            Must return a list of bounding box dicts (See module docstring)"""
         try:
             if not self.init:
                 self.initialize(*args, **kwargs)
@@ -263,8 +259,8 @@ class Detector():
 
     @staticmethod
     def rotate_rect(bounding_box, rotation_matrix):
-        """ Rotate a BoundingBox based on the rotation_matrix"""
-        logger.trace("Rotating BoundingBox")
+        """ Rotate a bounding box dict based on the rotation_matrix"""
+        logger.trace("Rotating bounding box")
         bounding_box = rotate_landmarks(bounding_box, rotation_matrix)
         return bounding_box
 
@@ -342,11 +338,18 @@ class Detector():
         return int(vram["card_id"]), int(vram["free"]), int(vram["total"])
 
     @staticmethod
-    def set_predetected(width, height):
-        """ Set a BoundingBox for predetected faces """
+    def to_bounding_box_dict(left, top, right, bottom):
+        """ Return a dict for the bounding box """
+        return dict(left=int(round(left)),
+                    right=int(round(right)),
+                    top=int(round(top)),
+                    bottom=int(round(bottom)))
+
+    def set_predetected(self, width, height):
+        """ Set a bounding box dict for predetected faces """
         # Predetected_face is used for sort tool.
         # Landmarks should not be extracted again from predetected faces,
         # because face data is lost, resulting in a large variance
         # against extract from original image
         logger.debug("Setting predetected face")
-        return [BoundingBox(0, 0, width, height)]
+        return [self.to_bounding_box_dict(0, 0, width, height)]
diff --git a/plugins/extract/detect/cv2_dnn.py b/plugins/extract/detect/cv2_dnn.py
index ed65eea..0c39a7f 100755
--- a/plugins/extract/detect/cv2_dnn.py
+++ b/plugins/extract/detect/cv2_dnn.py
@@ -3,7 +3,7 @@
 
 import numpy as np
 
-from ._base import BoundingBox, cv2, Detector, logger
+from ._base import cv2, Detector, logger
 
 
 class Detect(Detector):
@@ -83,12 +83,12 @@ class Detect(Detector):
         logger.trace("Processing Output: (faces: %s, rotation_matrix: %s)",
                      faces, rotation_matrix)
 
-        faces = [BoundingBox(face[0], face[1], face[2], face[3]) for face in faces]
+        faces = [self.to_bounding_box_dict(face[0], face[1], face[2], face[3]) for face in faces]
         if isinstance(rotation_matrix, np.ndarray):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
-        detected = [BoundingBox(face.left / scale, face.top / scale,
-                                face.right / scale, face.bottom / scale)
+        detected = [self.to_bounding_box_dict(face["left"] / scale, face["top"] / scale,
+                                              face["right"] / scale, face["bottom"] / scale)
                     for face in faces]
 
         logger.trace("Processed Output: %s", detected)
diff --git a/plugins/extract/detect/manual.py b/plugins/extract/detect/manual.py
index d5c7441..08f2771 100644
--- a/plugins/extract/detect/manual.py
+++ b/plugins/extract/detect/manual.py
@@ -1,7 +1,7 @@
 #!/usr/bin/env python3
 """ Manual face detection plugin """
 
-from ._base import BoundingBox, Detector, logger
+from ._base import Detector, logger
 
 
 class Detect(Detector):
@@ -17,7 +17,7 @@ class Detect(Detector):
         logger.info("Initialized Manual Detector.")
 
     def detect_faces(self, *args, **kwargs):
-        """ Return the given bounding box in a BoundingBox """
+        """ Return the given bounding box in a bounding box dict """
         super().detect_faces(*args, **kwargs)
         while True:
             item = self.get_item()
@@ -25,7 +25,7 @@ class Detect(Detector):
                 break
             face = item["face"]
 
-            bounding_box = [BoundingBox(face[0], face[1], face[2], face[3])]
+            bounding_box = [self.to_bounding_box_dict(face[0], face[1], face[2], face[3])]
             item["detected_faces"] = bounding_box
             self.finalize(item)
 
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index f2cbf71..efa0e4a 100755
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -11,7 +11,7 @@ import cv2
 import numpy as np
 
 from lib.multithreading import MultiThread
-from ._base import BoundingBox, Detector, logger
+from ._base import Detector, logger
 
 
 # Must import tensorflow inside the spawned process
@@ -156,12 +156,12 @@ class Detect(Detector):
         logger.trace("Processing Output: (faces: %s, points: %s, rotation_matrix: %s)",
                      faces, points, rotation_matrix)
         faces = self.recalculate_bounding_box(faces, points)
-        faces = [BoundingBox(face[0], face[1], face[2], face[3]) for face in faces]
+        faces = [self.to_bounding_box_dict(face[0], face[1], face[2], face[3]) for face in faces]
         if isinstance(rotation_matrix, np.ndarray):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
-        detected = [BoundingBox(face.left / scale, face.top / scale,
-                                face.right / scale, face.bottom / scale)
+        detected = [self.to_bounding_box_dict(face["left"] / scale, face["top"] / scale,
+                                              face["right"] / scale, face["bottom"] / scale)
                     for face in faces]
         logger.trace("Processed Output: %s", detected)
         return detected
diff --git a/plugins/extract/detect/s3fd.py b/plugins/extract/detect/s3fd.py
index f451b15..0dbf5fd 100644
--- a/plugins/extract/detect/s3fd.py
+++ b/plugins/extract/detect/s3fd.py
@@ -11,7 +11,7 @@ from scipy.special import logsumexp
 import numpy as np
 
 from lib.multithreading import MultiThread
-from ._base import BoundingBox, Detector, logger
+from ._base import Detector, logger
 
 
 class Detect(Detector):
@@ -106,12 +106,12 @@ class Detect(Detector):
     def process_output(self, faces, rotation_matrix, scale):
         """ Compile found faces for output """
         logger.trace("Processing Output: (faces: %s, rotation_matrix: %s)", faces, rotation_matrix)
-        faces = [BoundingBox(face[0], face[1], face[2], face[3]) for face in faces]
+        faces = [self.to_bounding_box_dict(face[0], face[1], face[2], face[3]) for face in faces]
         if isinstance(rotation_matrix, np.ndarray):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
-        detected = [BoundingBox(face.left / scale, face.top / scale,
-                                face.right / scale, face.bottom / scale)
+        detected = [self.to_bounding_box_dict(face["left"] / scale, face["top"] / scale,
+                                              face["right"] / scale, face["bottom"] / scale)
                     for face in faces]
         logger.trace("Processed Output: %s", detected)
         return detected
diff --git a/scripts/convert.py b/scripts/convert.py
index fa28261..dc915e2 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -380,7 +380,7 @@ class DiskIO():
 
         for idx, face in enumerate(detected_faces):
             detected_face = DetectedFace()
-            detected_face.from_bounding_box(face)
+            detected_face.from_bounding_box_dict(face)
             detected_face.landmarksXY = landmarks[idx]
             final_faces.append(detected_face)
         return final_faces
diff --git a/scripts/extract.py b/scripts/extract.py
index ac76cec..0738819 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -228,7 +228,7 @@ class Extract():
         detected_faces = faces["detected_faces"]
         for idx, face in enumerate(detected_faces):
             detected_face = DetectedFace()
-            detected_face.from_bounding_box(face, image)
+            detected_face.from_bounding_box_dict(face, image)
             detected_face.landmarksXY = landmarks[idx]
             detected_face.load_aligned(image, size=size, align_eyes=align_eyes)
             final_faces.append({"file_location": self.output_dir / Path(filename).stem,
diff --git a/tools/sort.py b/tools/sort.py
index 59cf377..9b5d924 100644
--- a/tools/sort.py
+++ b/tools/sort.py
@@ -125,7 +125,7 @@ class Sort():
         """ Set the image to a dict for alignment """
         height, width = image.shape[:2]
         face = DetectedFace(x=0, w=width, y=0, h=height)
-        face = face.to_bounding_box()
+        face = face.to_bounding_box_dict()
         return {"image": image,
                 "detected_faces": [face]}
 
