commit cbba53ea67cb48d8886041ae594ca2dfda48a4c8
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Fri Apr 24 16:41:27 2020 +0100

    Core Updates (#1015)
    
    - Remove lib.utils.keras_backend_quiet and replace with get_backend() where relevant
    - Document lib.gpu_stats and lib.sys_info
    - Remove call to GPUStats.is_plaidml from convert and replace with get_backend()
    - lib.gui.menu - typofix

diff --git a/docs/full/lib/gpu_stats.rst b/docs/full/lib/gpu_stats.rst
new file mode 100755
index 0000000..6535ee2
--- /dev/null
+++ b/docs/full/lib/gpu_stats.rst
@@ -0,0 +1,7 @@
+gpu\_stats module
+=================
+
+.. automodule:: lib.gpu_stats
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/docs/full/lib/sysinfo.rst b/docs/full/lib/sysinfo.rst
new file mode 100755
index 0000000..409c310
--- /dev/null
+++ b/docs/full/lib/sysinfo.rst
@@ -0,0 +1,7 @@
+sysinfo module
+==============
+
+.. automodule:: lib.sysinfo
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/lib/gpu_stats.py b/lib/gpu_stats.py
index 5024d0e..72e64d8 100644
--- a/lib/gpu_stats.py
+++ b/lib/gpu_stats.py
@@ -1,13 +1,17 @@
 #!/usr/bin python3
-""" Information on available Nvidia GPUs """
+""" Collects and returns Information on available GPUs.
+
+The information returned from this module provides information for both Nvidia and AMD GPUs.
+However, the information available for Nvidia is far more thorough than what is available for
+AMD, where we need to plug into plaidML to pull stats. The quality of this data will vary
+depending on the OS' particular OpenCL implementation.
+"""
 
 import logging
 import os
 import platform
 
-from lib.utils import keras_backend_quiet
-
-K = keras_backend_quiet()
+from lib.utils import get_backend
 
 if platform.system() == 'Darwin':
     import pynvx  # pylint: disable=import-error
@@ -24,70 +28,128 @@ except ImportError:
 
 
 class GPUStats():
-    """ Holds information about system GPU(s) """
+    """ Holds information and statistics about the GPU(s) available on the currently
+    running system.
+
+    Parameters
+    ----------
+    log: bool, optional
+        Whether the class should output information to the logger. There may be occasions where the
+        logger has not yet been set up when this class is queried. Attempting to log in these
+        instances will raise an error. If GPU stats are being queried prior to the logger being
+        available then this parameter should be set to ``False``. Otherwise set to ``True``.
+        Default: ``True``
+    """
     def __init__(self, log=True):
-        self.logger = None
-        if log:
-            # Logger is held internally, as we don't want to log
-            # when obtaining system stats on crash
-            self.logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
-            self.logger.debug("Initializing %s", self.__class__.__name__)
-
-        self.plaid = None
-        self.initialized = False
-        self.device_count = 0
-        self.active_devices = list()
-        self.handles = list()
-        self.driver = None
-        self.devices = list()
-        self.vram = None
-
-        self.initialize(log)
-
-        self.driver = self.get_driver()
-        self.devices = self.get_devices()
-        self.vram = self.get_vram()
-        if not self.active_devices:
-            if self.logger:
-                self.logger.warning("No GPU detected. Switching to CPU mode")
+        # Logger is held internally, as we don't want to log when obtaining system stats on crash
+        self._logger = logging.getLogger(__name__) if log else None
+        self._log("debug", "Initializing {}".format(self.__class__.__name__))
+
+        self._plaid = None
+        self._initialized = False
+        self._device_count = 0
+        self._active_devices = list()
+        self._handles = list()
+        self._driver = None
+        self._devices = list()
+        self._vram = None
+
+        self._initialize(log)
+
+        self._driver = self._get_driver()
+        self._devices = self._get_devices()
+        self._vram = self._get_vram()
+        if not self._active_devices:
+            self._log("warning", "No GPU detected. Switching to CPU mode")
             return
 
-        self.shutdown()
-        if self.logger:
-            self.logger.debug("Initialized %s", self.__class__.__name__)
+        self._shutdown()
+        self._log("debug", "Initialized {}".format(self.__class__.__name__))
+
+    @property
+    def device_count(self):
+        """int: The number of GPU devices discovered on the system. """
+        return self._device_count
+
+    @property
+    def _is_plaidml(self):
+        """ bool: ``True`` if the backend is plaidML otherwise ``False``. """
+        return self._plaid is not None
 
     @property
-    def is_plaidml(self):
-        """ Return whether running on plaidML backend """
-        return self.plaid is not None
-
-    def initialize(self, log=False):
-        """ Initialize pynvml """
-        if not self.initialized:
-            if K.backend() == "plaidml.keras.backend":
-                loglevel = "INFO"
-                if self.logger:
-                    self.logger.debug("plaidML Detected. Using plaidMLStats")
-                    loglevel = self.logger.getEffectiveLevel()
-                self.plaid = plaidlib(loglevel=loglevel, log=log)
+    def sys_info(self):
+        """ dict: GPU Stats that are required for system information logging.
+
+        The dictionary contains the following data:
+
+            **vram** (`list`): the total amount of VRAM in Megabytes for each GPU as pertaining to
+            :attr:`_handles`
+
+            **driver** (`str`): The GPU driver version that is installed on the OS
+
+            **devices** (`list`): The device name of each GPU on the system as pertaining
+            to :attr:`_handles`
+
+            **devices_active** (`list`): The device name of each active GPU on the system as
+            pertaining to :attr:`_handles`
+        """
+        return dict(vram=self._vram,
+                    driver=self._driver,
+                    devices=self._devices,
+                    devices_active=self._active_devices)
+
+    def _log(self, level, message):
+        """ If the class has been initialized with :attr:`log` as `True` then log the message
+        otherwise skip logging.
+
+        Parameters
+        ----------
+        level: str
+            The log level to log at
+        message: str
+            The message to log
+        """
+        if self._logger is None:
+            return
+        logger = getattr(self._logger, level.lower())
+        logger(message)
+
+    def _initialize(self, log=False):
+        """ Initialize the library that will be returning stats for the system's GPU(s).
+        For Nvidia (on Linux and Windows) the library is `pynvml`. For Nvidia (on macOS) the
+        library is `pynvx`. For AMD `plaidML` is used.
+
+        Parameters
+        ----------
+        log: bool, optional
+            Whether the class should output information to the logger. There may be occasions where
+            the logger has not yet been set up when this class is queried. Attempting to log in
+            these instances will raise an error. If GPU stats are being queried prior to the
+            logger being available then this parameter should be set to ``False``. Otherwise set
+            to ``True``. Default: ``False``
+        """
+        if not self._initialized:
+            if get_backend() == "amd":
+                self._log("debug", "AMD Detected. Using plaidMLStats")
+                loglevel = "INFO" if self._logger is None else self._logger.getEffectiveLevel()
+                self._plaid = plaidlib(loglevel=loglevel, log=log)
             elif IS_MACOS:
-                if self.logger:
-                    self.logger.debug("macOS Detected. Using pynvx")
+                self._log("debug", "macOS Detected. Using pynvx")
                 try:
                     pynvx.cudaInit()
                 except RuntimeError:
-                    self.initialized = True
+                    self._initialized = True
                     return
             else:
                 try:
-                    if self.logger:
-                        self.logger.debug("OS is not macOS. Using pynvml")
+                    self._log("debug", "OS is not macOS. Trying pynvml")
                     pynvml.nvmlInit()
                 except (pynvml.NVMLError_LibraryNotFound,  # pylint: disable=no-member
                         pynvml.NVMLError_DriverNotLoaded,  # pylint: disable=no-member
                         pynvml.NVMLError_NoPermission) as err:  # pylint: disable=no-member
                     if plaidlib is not None:
-                        self.plaid = plaidlib(log=log)
+                        self._log("debug", "pynvml errored. Trying plaidML")
+                        self._plaid = plaidlib(log=log)
                     else:
                         msg = ("There was an error reading from the Nvidia Machine Learning "
                                "Library. Either you do not have an Nvidia GPU (in which case "
@@ -95,77 +157,83 @@ class GPUStats():
                                "incorrectly installed drivers. If this is the case, Please remove "
                                "and reinstall your Nvidia drivers before reporting."
                                "Original Error: {}".format(str(err)))
-                        if self.logger:
-                            self.logger.warning(msg)
-                        self.initialized = True
+                        self._log("warning", msg)
+                        self._initialized = True
                         return
                 except Exception as err:  # pylint: disable=broad-except
                     msg = ("An unhandled exception occured loading pynvml. "
                            "Original error: {}".format(str(err)))
-                    if self.logger:
-                        self.logger.error(msg)
+                    if self._logger:
+                        self._logger.error(msg)
                     else:
                         print(msg)
-                    self.initialized = True
+                    self._initialized = True
                     return
-            self.initialized = True
-            self.get_device_count()
-            self.get_active_devices()
-            self.get_handles()
-
-    def shutdown(self):
-        """ Shutdown pynvml """
-        if self.initialized:
-            self.handles = list()
-            if not IS_MACOS and not self.plaid:
+            self._initialized = True
+            self._get_device_count()
+            self._get_active_devices()
+            self._get_handles()
+
+    def _shutdown(self):
+        """ Shutdown pynvml if it was the library used for obtaining stats and set
+        :attr:`_initialized` back to ``False``. """
+        if self._initialized:
+            self._handles = list()
+            if not IS_MACOS and not self._is_plaidml:
                 pynvml.nvmlShutdown()
-            self.initialized = False
+            self._initialized = False
 
-    def get_device_count(self):
-        """ Return count of Nvidia devices """
-        if self.plaid is not None:
-            self.device_count = self.plaid.device_count
+    def _get_device_count(self):
+        """ Detect the number of GPUs attached to the system and allocate to
+        :attr:`_device_count`. """
+        if self._is_plaidml:
+            self._device_count = self._plaid.device_count
         elif IS_MACOS:
-            self.device_count = pynvx.cudaDeviceGetCount(ignore=True)
+            self._device_count = pynvx.cudaDeviceGetCount(ignore=True)
         else:
             try:
-                self.device_count = pynvml.nvmlDeviceGetCount()
+                self._device_count = pynvml.nvmlDeviceGetCount()
             except pynvml.NVMLError:
-                self.device_count = 0
-        if self.logger:
-            self.logger.debug("GPU Device count: %s", self.device_count)
-
-    def get_active_devices(self):
-        """ Return list of active Nvidia devices """
-        if self.plaid is not None:
-            self.active_devices = self.plaid.active_devices
+                self._device_count = 0
+        self._log("debug", "GPU Device count: {}".format(self._device_count))
+
+    def _get_active_devices(self):
+        """ Obtain the indices of active GPUs (those that have not been explicitly excluded by
+        CUDA_VISIBLE_DEVICES or plaidML) and allocate to :attr:`_active_devices`. """
+        if self._is_plaidml:
+            self._active_devices = self._plaid.active_devices
         else:
             devices = os.environ.get("CUDA_VISIBLE_DEVICES", None)
-            if self.device_count == 0:
-                self.active_devices = list()
+            if self._device_count == 0:
+                self._active_devices = list()
             elif devices is not None:
-                self.active_devices = [int(i) for i in devices.split(",") if devices]
+                self._active_devices = [int(i) for i in devices.split(",") if devices]
             else:
-                self.active_devices = list(range(self.device_count))
-            if self.logger:
-                self.logger.debug("Active GPU Devices: %s", self.active_devices)
-
-    def get_handles(self):
-        """ Return all listed Nvidia handles """
-        if self.plaid is not None:
-            self.handles = self.plaid.devices
+                self._active_devices = list(range(self._device_count))
+            self._log("debug", "Active GPU Devices: {}".format(self._active_devices))
+
+    def _get_handles(self):
+        """ Obtain the internal handle identifiers for the system GPUs and allocate to
+        :attr:`_handles`. """
+        if self._is_plaidml:
+            self._handles = self._plaid.devices
         elif IS_MACOS:
-            self.handles = pynvx.cudaDeviceGetHandles(ignore=True)
+            self._handles = pynvx.cudaDeviceGetHandles(ignore=True)
         else:
-            self.handles = [pynvml.nvmlDeviceGetHandleByIndex(i)
-                            for i in range(self.device_count)]
-        if self.logger:
-            self.logger.debug("GPU Handles found: %s", len(self.handles))
-
-    def get_driver(self):
-        """ Get the driver version """
-        if self.plaid is not None:
-            driver = self.plaid.drivers
+            self._handles = [pynvml.nvmlDeviceGetHandleByIndex(i)
+                             for i in range(self._device_count)]
+        self._log("debug", "GPU Handles found: {}".format(len(self._handles)))
+
+    def _get_driver(self):
+        """ Obtain and return the installed driver version for the system's GPUs.
+
+        Returns
+        -------
+        str
+            The currently installed GPU driver version
+        """
+        if self._is_plaidml:
+            driver = self._plaid.drivers
         elif IS_MACOS:
             driver = pynvx.cudaSystemGetDriverVersion(ignore=True)
         else:
@@ -173,100 +241,116 @@ class GPUStats():
                 driver = pynvml.nvmlSystemGetDriverVersion().decode("utf-8")
             except pynvml.NVMLError:
                 driver = "No Nvidia driver found"
-        if self.logger:
-            self.logger.debug("GPU Driver: %s", driver)
+        self._log("debug", "GPU Driver: {}".format(driver))
         return driver
 
-    def get_devices(self):
-        """ Return name of devices """
-        self.initialize()
-        if self.device_count == 0:
+    def _get_devices(self):
+        """ Obtain the name of the installed devices. The quality of this information depends on
+        the backend and OS being used, but it should be sufficient for identifying cards.
+
+        Returns
+        -------
+        list
+            List of device names for connected GPUs as corresponding to the values in
+            :attr:`_handles`
+        """
+        self._initialize()
+        if self._device_count == 0:
             names = list()
-        if self.plaid is not None:
-            names = self.plaid.names
+        if self._is_plaidml:
+            names = self._plaid.names
         elif IS_MACOS:
             names = [pynvx.cudaGetName(handle, ignore=True)
-                     for handle in self.handles]
+                     for handle in self._handles]
         else:
             names = [pynvml.nvmlDeviceGetName(handle).decode("utf-8")
-                     for handle in self.handles]
-        if self.logger:
-            self.logger.debug("GPU Devices: %s", names)
+                     for handle in self._handles]
+        self._log("debug", "GPU Devices: {}".format(names))
         return names
 
-    def get_vram(self):
-        """ Return total vram in megabytes per device """
-        self.initialize()
-        if self.device_count == 0:
+    def _get_vram(self):
+        """ Obtain the total VRAM in Megabytes for each connected GPU.
+
+        Returns
+        -------
+        list
+             List of floats containing the total amount of VRAM in Megabytes for each connected GPU
+             as corresponding to the values in :attr:`_handles
+        """
+        self._initialize()
+        if self._device_count == 0:
             vram = list()
-        elif self.plaid:
-            vram = self.plaid.vram
+        elif self._is_plaidml:
+            vram = self._plaid.vram
         elif IS_MACOS:
             vram = [pynvx.cudaGetMemTotal(handle, ignore=True) / (1024 * 1024)
-                    for handle in self.handles]
+                    for handle in self._handles]
         else:
             vram = [pynvml.nvmlDeviceGetMemoryInfo(handle).total /
                     (1024 * 1024)
-                    for handle in self.handles]
-        if self.logger:
-            self.logger.debug("GPU VRAM: %s", vram)
+                    for handle in self._handles]
+        self._log("debug", "GPU VRAM: {}".format(vram))
         return vram
 
-    def get_used(self):
-        """ Return the vram in use """
-        self.initialize()
-        if self.plaid:
-            # NB There is no useful way to get allocated VRAM on PlaidML.
-            # OpenCL loads and unloads VRAM as required, so this returns 0
-            # It's not particularly useful
-            vram = [0 for idx in range(self.device_count)]
+    def _get_free_vram(self):
+        """ Obtain the amount of VRAM that is available, in Megabytes, for each connected GPU.
 
-        elif IS_MACOS:
-            vram = [pynvx.cudaGetMemUsed(handle, ignore=True) / (1024 * 1024)
-                    for handle in self.handles]
-        else:
-            vram = [pynvml.nvmlDeviceGetMemoryInfo(handle).used / (1024 * 1024)
-                    for handle in self.handles]
-        self.shutdown()
+        Returns
+        -------
+        list
+             List of floats containing the amount of VRAM available, in Megabytes, for each
+             connected GPU as corresponding to the values in :attr:`_handles
 
-        if self.logger:
-            self.logger.verbose("GPU VRAM used: %s", vram)
-        return vram
+        Notes
+        -----
+        There is no useful way to get free VRAM on PlaidML. OpenCL loads and unloads VRAM as
+        required, so this returns the total memory available per card for AMD cards, which us
+        not particularly useful.
 
-    def get_free(self):
-        """ Return the vram available """
-        self.initialize()
-        if self.plaid:
-            # NB There is no useful way to get free VRAM on PlaidML.
-            # OpenCL loads and unloads VRAM as required, so this returns the total memory
-            # It's not particularly useful
-            vram = self.plaid.vram
+        """
+        self._initialize()
+        if self._is_plaidml:
+            vram = self._plaid.vram
         elif IS_MACOS:
             vram = [pynvx.cudaGetMemFree(handle, ignore=True) / (1024 * 1024)
-                    for handle in self.handles]
+                    for handle in self._handles]
         else:
             vram = [pynvml.nvmlDeviceGetMemoryInfo(handle).free / (1024 * 1024)
-                    for handle in self.handles]
-        self.shutdown()
-        if self.logger:
-            self.logger.debug("GPU VRAM free: %s", vram)
+                    for handle in self._handles]
+        self._shutdown()
+        self._log("debug", "GPU VRAM free: {}".format(vram))
         return vram
 
-    def get_card_most_free(self, supports_plaidml=True):
-        """ Return the card and available VRAM for active card with
-            most VRAM free """
-        if self.device_count == 0 or (self.is_plaidml and not supports_plaidml):
+    def get_card_most_free(self):
+        """ Obtain statistics for the GPU with the most available free VRAM.
+
+        Returns
+        -------
+        dict
+            The dictionary contains the following data:
+
+                **card_id** (`int`):  The index of the card as pertaining to :attr:`_handles`
+
+                **device** (`str`): The name of the device
+
+                **free** (`float`): The amount of available VRAM on the GPU
+
+                **total** (`float`): the total amount of VRAM on the GPU
+
+            If a GPU is not detected then the **card_id** is returned as ``-1`` and the amount
+            of free and total RAM available is fixed to 2048 Megabytes.
+        """
+        if self._device_count == 0:
             return {"card_id": -1,
-                    "device": "No Nvidia devices found",
+                    "device": "No GPU devices found",
                     "free": 2048,
                     "total": 2048}
-        free_vram = [self.get_free()[i] for i in self.active_devices]
+        free_vram = [self._get_free_vram()[i] for i in self._active_devices]
         vram_free = max(free_vram)
-        card_id = self.active_devices[free_vram.index(vram_free)]
+        card_id = self._active_devices[free_vram.index(vram_free)]
         retval = {"card_id": card_id,
-                  "device": self.devices[card_id],
+                  "device": self._devices[card_id],
                   "free": vram_free,
-                  "total": self.vram[card_id]}
-        if self.logger:
-            self.logger.debug("Active GPU Card with most free VRAM: %s", retval)
+                  "total": self._vram[card_id]}
+        self._log("debug", "Active GPU Card with most free VRAM: {}".format(retval))
         return retval
diff --git a/lib/gui/menu.py b/lib/gui/menu.py
index 7bbb687..61e336e 100644
--- a/lib/gui/menu.py
+++ b/lib/gui/menu.py
@@ -569,7 +569,7 @@ class TaskBar(ttk.Frame):  # pylint: disable=too-many-ancestors
         if btntype.startswith("reload"):
             hlp = "Reload {} from disk".format(task)
         if btntype == "new":
-            hlp = "Crate a new {}...".format(task)
+            hlp = "Create a new {}...".format(task)
         if btntype.startswith("clear"):
             hlp = "Reset {} to default".format(task)
         elif btntype.startswith("save") and "_" not in btntype:
diff --git a/lib/sysinfo.py b/lib/sysinfo.py
index bf3cb3c..8abe965 100644
--- a/lib/sysinfo.py
+++ b/lib/sysinfo.py
@@ -1,5 +1,5 @@
 #!/usr/bin python3
-""" Obtain information about the running system, environment and gpu """
+""" Obtain information about the running system, environment and GPU. """
 
 import json
 import locale
@@ -14,58 +14,52 @@ import psutil
 from lib.gpu_stats import GPUStats
 
 
-class SysInfo():
-    """ System and Python Information """
-    # pylint: disable=too-many-instance-attributes,too-many-public-methods
-
+class _SysInfo():
+    """ Obtain information about the System, Python and GPU """
     def __init__(self):
-        gpu_stats = GPUStats(log=False)
-        self.state_file = State().state_file
-        self.configs = Configs().configs
-        self.platform = platform.platform()
-        self.system = platform.system()
-        self.machine = platform.machine()
-        self.release = platform.release()
-        self.processor = platform.processor()
-        self.cpu_count = os.cpu_count()
-        self.py_implementation = platform.python_implementation()
-        self.py_version = platform.python_version()
-        self._cuda_path = self.get_cuda_path()
-        self.vram = gpu_stats.vram
-        self.gfx_driver = gpu_stats.driver
-        self.gfx_devices = gpu_stats.devices
-        self.gfx_devices_active = gpu_stats.active_devices
+        self._state_file = _State().state_file
+        self._configs = _Configs().configs
+        self._system = dict(platform=platform.platform(),
+                            system=platform.system(),
+                            machine=platform.machine(),
+                            release=platform.release(),
+                            processor=platform.processor(),
+                            cpu_count=os.cpu_count())
+        self._python = dict(implementation=platform.python_implementation(),
+                            version=platform.python_version())
+        self._gpu = GPUStats(log=False).sys_info
+        self._cuda_path = self._get_cuda_path()
 
     @property
-    def encoding(self):
-        """ Return system preferred encoding """
+    def _encoding(self):
+        """ str: The system preferred encoding """
         return locale.getpreferredencoding()
 
     @property
-    def is_conda(self):
-        """ Boolean for whether in a conda environment """
+    def _is_conda(self):
+        """ bool: `True` if running in a Conda environment otherwise ``False``. """
         return ("conda" in sys.version.lower() or
                 os.path.exists(os.path.join(sys.prefix, 'conda-meta')))
 
     @property
-    def is_linux(self):
-        """ Boolean for whether system is Linux """
-        return self.system.lower() == "linux"
+    def _is_linux(self):
+        """ bool: `True` if running on a Linux system otherwise ``False``. """
+        return self._system["system"].lower() == "linux"
 
     @property
-    def is_macos(self):
-        """ Boolean for whether system is macOS """
-        return self.system.lower() == "darwin"
+    def _is_macos(self):
+        """ bool: `True` if running on a macOS system otherwise ``False``. """
+        return self._system["system"].lower() == "darwin"
 
     @property
-    def is_windows(self):
-        """ Boolean for whether system is Windows """
-        return self.system.lower() == "windows"
+    def _is_windows(self):
+        """ bool: `True` if running on a Windows system otherwise ``False``. """
+        return self._system["system"].lower() == "windows"
 
     @property
-    def is_virtual_env(self):
-        """ Boolean for whether running in a virtual environment """
-        if not self.is_conda:
+    def _is_virtual_env(self):
+        """ bool: `True` if running inside a virtual environment otherwise ``False``. """
+        if not self._is_conda:
             retval = (hasattr(sys, "real_prefix") or
                       (hasattr(sys, "base_prefix") and sys.base_prefix != sys.prefix))
         else:
@@ -74,47 +68,42 @@ class SysInfo():
         return retval
 
     @property
-    def ram(self):
-        """ Return RAM stats """
-        return psutil.virtual_memory()
-
-    @property
-    def ram_free(self):
-        """ return free RAM """
-        return getattr(self.ram, "free")
+    def _ram_free(self):
+        """ int: The amount of free RAM in bytes. """
+        return psutil.virtual_memory().free
 
     @property
-    def ram_total(self):
-        """ return total RAM """
-        return getattr(self.ram, "total")
+    def _ram_total(self):
+        """ int: The amount of total RAM in bytes. """
+        return psutil.virtual_memory().total
 
     @property
-    def ram_available(self):
-        """ return available RAM """
-        return getattr(self.ram, "available")
+    def _ram_available(self):
+        """ int: The amount of available RAM in bytes. """
+        return psutil.virtual_memory().available
 
     @property
-    def ram_used(self):
-        """ return used RAM """
-        return getattr(self.ram, "used")
+    def _ram_used(self):
+        """ int: The amount of used RAM in bytes. """
+        return psutil.virtual_memory().used
 
     @property
-    def fs_command(self):
-        """ Return the executed faceswap command """
+    def _fs_command(self):
+        """ str: The command line command used to execute faceswap. """
         return " ".join(sys.argv)
 
     @property
-    def installed_pip(self):
-        """ Installed pip packages """
+    def _installed_pip(self):
+        """ str: The list of installed pip packages within Faceswap's scope. """
         pip = Popen("{} -m pip freeze".format(sys.executable),
                     shell=True, stdout=PIPE)
         installed = pip.communicate()[0].decode().splitlines()
         return "\n".join(installed)
 
     @property
-    def installed_conda(self):
-        """ Installed Conda packages """
-        if not self.is_conda:
+    def _installed_conda(self):
+        """ str: The list of installed Conda packages within Faceswap's scope. """
+        if not self._is_conda:
             return None
         conda = Popen("conda list", shell=True, stdout=PIPE, stderr=PIPE)
         stdout, stderr = conda.communicate()
@@ -124,9 +113,9 @@ class SysInfo():
         return "\n".join(installed)
 
     @property
-    def conda_version(self):
-        """ Get conda version """
-        if not self.is_conda:
+    def _conda_version(self):
+        """ str: The installed version of Conda, or `N/A` if Conda is not installed. """
+        if not self._is_conda:
             return "N/A"
         conda = Popen("conda --version", shell=True, stdout=PIPE, stderr=PIPE)
         stdout, stderr = conda.communicate()
@@ -136,8 +125,8 @@ class SysInfo():
         return "\n".join(version)
 
     @property
-    def git_branch(self):
-        """ Get the current git branch """
+    def _git_branch(self):
+        """ str: The git branch that is currently being used to execute Faceswap. """
         git = Popen("git status", shell=True, stdout=PIPE, stderr=PIPE)
         stdout, stderr = git.communicate()
         if stderr:
@@ -146,8 +135,8 @@ class SysInfo():
         return branch
 
     @property
-    def git_commits(self):
-        """ Get last 5 git commits """
+    def _git_commits(self):
+        """ str: The last 5 git commits for the currently running Faceswap. """
         git = Popen("git log --pretty=oneline --abbrev-commit -n 5",
                     shell=True, stdout=PIPE, stderr=PIPE)
         stdout, stderr = git.communicate()
@@ -157,41 +146,42 @@ class SysInfo():
         return ". ".join(commits)
 
     @property
-    def cuda_keys_windows(self):
-        """ Return the OS Environ CUDA Keys for Windows """
+    def _cuda_keys_windows(self):
+        """ list: The CUDA Path environment variables stored for Windows users. """
         return [key for key in os.environ.keys() if key.lower().startswith("cuda_path_v")]
 
     @property
-    def cuda_version(self):
-        """ Get the installed CUDA version """
+    def _cuda_version(self):
+        """ str: The installed CUDA version. """
+        # TODO Handle multiple CUDA installs
         chk = Popen("nvcc -V", shell=True, stdout=PIPE, stderr=PIPE)
         stdout, stderr = chk.communicate()
         if not stderr:
-            version = re.search(r".*release (?P<cuda>\d+\.\d+)", stdout.decode(self.encoding))
+            version = re.search(r".*release (?P<cuda>\d+\.\d+)", stdout.decode(self._encoding))
             version = version.groupdict().get("cuda", None)
             if version:
                 return version
         # Failed to load nvcc
-        if self.is_linux:
-            version = self.cuda_version_linux()
-        elif self.is_windows:
-            version = self.cuda_version_windows()
+        if self._is_linux:
+            version = self._cuda_version_linux()
+        elif self._is_windows:
+            version = self._cuda_version_windows()
         else:
             version = "Unsupported OS"
-            if self.is_conda:
+            if self._is_conda:
                 version += ". Check Conda packages for Conda Cuda"
         return version
 
     @property
-    def cudnn_version(self):
-        """ Get the installed cuDNN version """
-        if self.is_linux:
-            cudnn_checkfiles = self.cudnn_checkfiles_linux()
-        elif self.is_windows:
-            cudnn_checkfiles = self.cudnn_checkfiles_windows()
+    def _cudnn_version(self):
+        """ str: The installed cuDNN version. """
+        if self._is_linux:
+            cudnn_checkfiles = self._cudnn_checkfiles_linux()
+        elif self._is_windows:
+            cudnn_checkfiles = self._cudnn_checkfiles_windows()
         else:
             retval = "Unsupported OS"
-            if self.is_conda:
+            if self._is_conda:
                 retval += ". Check Conda packages for Conda cuDNN"
             return retval
 
@@ -203,7 +193,7 @@ class SysInfo():
 
         if not cudnn_checkfile:
             retval = "No global version found"
-            if self.is_conda:
+            if self._is_conda:
                 retval += ". Check Conda packages for Conda cuDNN"
             return retval
 
@@ -223,14 +213,19 @@ class SysInfo():
                     break
         if found != 3:
             retval = "No global version found"
-            if self.is_conda:
+            if self._is_conda:
                 retval += ". Check Conda packages for Conda cuDNN"
             return retval
         return "{}.{}.{}".format(major, minor, patchlevel)
 
     @staticmethod
-    def cudnn_checkfiles_linux():
-        """ Return the checkfile locations for linux """
+    def _cudnn_checkfiles_linux():
+        """ Obtain the location of the files to check for cuDNN location in Linux.
+
+        Returns
+        str:
+            The location of the header files for cuDNN
+        """
         chk = os.popen("ldconfig -p | grep -P \"libcudnn.so.\\d+\" | head -n 1").read()
         if "libcudnn.so." not in chk:
             return list()
@@ -242,30 +237,47 @@ class SysInfo():
                             os.path.join(cudnn_path, "cudnn.h")]
         return cudnn_checkfiles
 
-    def cudnn_checkfiles_windows(self):
-        """ Return the checkfile locations for windows """
+    def _cudnn_checkfiles_windows(self):
+        """ Obtain the location of the files to check for cuDNN location in Windows.
+
+        Returns
+        str:
+            The location of the header files for cuDNN
+        """
         # TODO A more reliable way of getting the windows location
-        if not self._cuda_path and not self.cuda_keys_windows:
+        if not self._cuda_path and not self._cuda_keys_windows:
             return list()
         if not self._cuda_path:
-            self._cuda_path = os.environ[self.cuda_keys_windows[0]]
+            self._cuda_path = os.environ[self._cuda_keys_windows[0]]
 
         cudnn_checkfile = os.path.join(self._cuda_path, "include", "cudnn.h")
         return [cudnn_checkfile]
 
-    def get_cuda_path(self):
-        """ Return the correct CUDA Path """
-        if self.is_linux:
-            path = self.cuda_path_linux()
-        elif self.is_windows:
-            path = self.cuda_path_windows()
+    def _get_cuda_path(self):
+        """ Obtain the path to Cuda install location.
+
+        Returns
+        -------
+        str
+            The path to the install location of Cuda on the system
+        """
+        if self._is_linux:
+            path = self._cuda_path_linux()
+        elif self._is_windows:
+            path = self._cuda_path_windows()
         else:
             path = None
         return path
 
     @staticmethod
-    def cuda_path_linux():
-        """ Get the path to Cuda on linux systems """
+    def _cuda_path_linux():
+        """ Obtain the path to Cuda install location on Linux.
+
+        Returns
+        -------
+        str
+            The path to the install location of Cuda on a Linux system
+        """
         ld_library_path = os.environ.get("LD_LIBRARY_PATH", None)
         chk = os.popen("ldconfig -p | grep -P \"libcudart.so.\\d+.\\d+\" | head -n 1").read()
         if ld_library_path and not chk:
@@ -280,13 +292,24 @@ class SysInfo():
         return chk[chk.find("=>") + 3:chk.find("targets") - 1]
 
     @staticmethod
-    def cuda_path_windows():
-        """ Get the path to Cuda on Windows systems """
+    def _cuda_path_windows():
+        """ Obtain the path to Cuda install location on Windows.
+
+        Returns
+        -------
+        str
+            The path to the install location of Cuda on a Windows system
+        """
         cuda_path = os.environ.get("CUDA_PATH", None)
         return cuda_path
 
-    def cuda_version_linux(self):
-        """ Get CUDA version for linux systems """
+    def _cuda_version_linux(self):
+        """ Obtain the installed version of Cuda on a Linux system.
+
+        Returns
+        -------
+        The installed CUDA version on a Linux system
+        """
         ld_library_path = os.environ.get("LD_LIBRARY_PATH", None)
         chk = os.popen("ldconfig -p | grep -P \"libcudart.so.\\d+.\\d+\" | head -n 1").read()
         if ld_library_path and not chk:
@@ -298,110 +321,166 @@ class SysInfo():
                     break
         if not chk:
             retval = "No global version found"
-            if self.is_conda:
+            if self._is_conda:
                 retval += ". Check Conda packages for Conda Cuda"
             return retval
         cudavers = chk.strip().replace("libcudart.so.", "")
         return cudavers[:cudavers.find(" ")]
 
-    def cuda_version_windows(self):
-        """ Get CUDA version for Windows systems """
-        cuda_keys = self.cuda_keys_windows
+    def _cuda_version_windows(self):
+        """ Obtain the installed version of Cuda on a Windows system.
+
+        Returns
+        -------
+        The installed CUDA version on a Windows system
+        """
+        cuda_keys = self._cuda_keys_windows
         if not cuda_keys:
             retval = "No global version found"
-            if self.is_conda:
+            if self._is_conda:
                 retval += ". Check Conda packages for Conda Cuda"
             return retval
         cudavers = [key.lower().replace("cuda_path_v", "").replace("_", ".") for key in cuda_keys]
         return " ".join(cudavers)
 
     def full_info(self):
-        """ Format system info human readable """
+        """ Obtain extensive system information stats, formatted into a human readable format.
+
+        Returns
+        -------
+        str
+            The system information for the currently running system, formatted for output to
+            console or a log file.
+        """
         retval = "\n============ System Information ============\n"
-        sys_info = {"os_platform": self.platform,
-                    "os_machine": self.machine,
-                    "os_release": self.release,
-                    "py_conda_version": self.conda_version,
-                    "py_implementation": self.py_implementation,
-                    "py_version": self.py_version,
-                    "py_command": self.fs_command,
-                    "py_virtual_env": self.is_virtual_env,
-                    "sys_cores": self.cpu_count,
-                    "sys_processor": self.processor,
-                    "sys_ram": self.format_ram(),
-                    "encoding": self.encoding,
-                    "git_branch": self.git_branch,
-                    "git_commits": self.git_commits,
-                    "gpu_cuda": self.cuda_version,
-                    "gpu_cudnn": self.cudnn_version,
-                    "gpu_driver": self.gfx_driver,
+        sys_info = {"os_platform": self._system["platform"],
+                    "os_machine": self._system["machine"],
+                    "os_release": self._system["release"],
+                    "py_conda_version": self._conda_version,
+                    "py_implementation": self._python["implementation"],
+                    "py_version": self._python["version"],
+                    "py_command": self._fs_command,
+                    "py_virtual_env": self._is_virtual_env,
+                    "sys_cores": self._system["cpu_count"],
+                    "sys_processor": self._system["processor"],
+                    "sys_ram": self._format_ram(),
+                    "encoding": self._encoding,
+                    "git_branch": self._git_branch,
+                    "git_commits": self._git_commits,
+                    "gpu_cuda": self._cuda_version,
+                    "gpu_cudnn": self._cudnn_version,
+                    "gpu_driver": self._gpu["driver"],
                     "gpu_devices": ", ".join(["GPU_{}: {}".format(idx, device)
-                                              for idx, device in enumerate(self.gfx_devices)]),
+                                              for idx, device in enumerate(self._gpu["devices"])]),
                     "gpu_vram": ", ".join(["GPU_{}: {}MB".format(idx, int(vram))
-                                           for idx, vram in enumerate(self.vram)]),
+                                           for idx, vram in enumerate(self._gpu["vram"])]),
                     "gpu_devices_active": ", ".join(["GPU_{}".format(idx)
-                                                     for idx in self.gfx_devices_active])}
+                                                     for idx in self._gpu["devices_active"]])}
         for key in sorted(sys_info.keys()):
             retval += ("{0: <20} {1}\n".format(key + ":", sys_info[key]))
         retval += "\n=============== Pip Packages ===============\n"
-        retval += self.installed_pip
-        if self.is_conda:
+        retval += self._installed_pip
+        if self._is_conda:
             retval += "\n\n============== Conda Packages ==============\n"
-            retval += self.installed_conda
-        retval += self.state_file
+            retval += self._installed_conda
+        retval += self._state_file
         retval += "\n\n================= Configs =================="
-        retval += self.configs
+        retval += self._configs
         return retval
 
-    def format_ram(self):
-        """ Format the RAM stats for human output """
+    def _format_ram(self):
+        """ Format the RAM stats into Megabytes to make it more readable.
+
+        Returns
+        -------
+        str
+            The total, available, used and free RAM displayed in Megabytes
+        """
         retval = list()
         for name in ("total", "available", "used", "free"):
-            value = getattr(self, "ram_{}".format(name))
+            value = getattr(self, "_ram_{}".format(name))
             value = int(value / (1024 * 1024))
             retval.append("{}: {}MB".format(name.capitalize(), value))
         return ", ".join(retval)
 
 
 def get_sysinfo():
-    """ Return sys info or error message if there is an error """
+    """ Obtain extensive system information stats, formatted into a human readable format.
+    If an error occurs obtaining the system information, then the error message is returned
+    instead.
+
+    Returns
+    -------
+    str
+        The system information for the currently running system, formatted for output to
+        console or a log file.
+    """
     try:
-        retval = SysInfo().full_info()
+        retval = _SysInfo().full_info()
     except Exception as err:  # pylint: disable=broad-except
         retval = "Exception occured trying to retrieve sysinfo: {}".format(err)
     return retval
 
 
-class Configs():
-    """ Parses the config files in /config and outputs the information """
+class _Configs():
+    """ Parses the config files in /faceswap/config and outputs the information stored within them
+    in a human readable format. """
 
     def __init__(self):
         self.config_dir = os.path.join(os.path.abspath(os.path.dirname(sys.argv[0])), "config")
-        self.configs = self.get_configs()
+        self.configs = self._get_configs()
+
+    def _get_configs(self):
+        """ Obtain the formatted configurations from the config folder.
 
-    def get_configs(self):
-        """ Return the configs from the config dir """
+        Returns
+        -------
+        str
+            The current configuration in the config files formatted in a human readable format
+        """
         config_files = [os.path.join(self.config_dir, cfile)
                         for cfile in os.listdir(self.config_dir)
                         if os.path.basename(cfile) == ".faceswap"
                         or os.path.splitext(cfile)[1] == ".ini"]
-        return self.parse_configs(config_files)
+        return self._parse_configs(config_files)
 
-    def parse_configs(self, config_files):
-        """ Parse the config files into the output format """
+    def _parse_configs(self, config_files):
+        """ Parse the given list of config files into a human readable format.
+
+        Parameters
+        ----------
+        config_files: list
+            A list of paths to the faceswap config files
+
+        Returns
+        -------
+        str
+            The current configuration in the config files formatted in a human readable format
+        """
         formatted = ""
         for cfile in config_files:
             fname = os.path.basename(cfile)
             ext = os.path.splitext(cfile)[1]
             formatted += "\n--------- {} ---------\n".format(fname)
             if ext == ".ini":
-                formatted += self.parse_ini(cfile)
+                formatted += self._parse_ini(cfile)
             elif fname == ".faceswap":
-                formatted += self.parse_json(cfile)
+                formatted += self._parse_json(cfile)
         return formatted
 
-    def parse_ini(self, config_file):
-        """ Parse an INI file converting it to a dict """
+    def _parse_ini(self, config_file):
+        """ Parse an ``.ini`` formatted config file into a human readable format.
+
+        Parameters
+        ----------
+        config_file: str
+            The path to the config.ini file
+
+        Returns
+        -------
+        str
+            The current configuration in the config file formatted in a human readable format
+        """
         formatted = ""
         with open(config_file, "r") as cfile:
             for line in cfile.readlines():
@@ -412,50 +491,88 @@ class Configs():
                 if len(item) == 1:
                     formatted += "\n{}\n".format(item[0].strip())
                 else:
-                    formatted += self.format_text(item[0], item[1])
+                    formatted += self._format_text(item[0], item[1])
         return formatted
 
-    def parse_json(self, config_file):
-        """ Parse a Json File converting it to a dict """
+    def _parse_json(self, config_file):
+        """ Parse an ``.json`` formatted config file into a python dictionary.
+
+        Parameters
+        ----------
+        config_file: str
+            The path to the config.json file
+
+        Returns
+        -------
+        dict
+            The current configuration in the config file formatted as a python dictionary
+        """
         formatted = ""
         with open(config_file, "r") as cfile:
             conf_dict = json.load(cfile)
             for key in sorted(conf_dict.keys()):
-                formatted += self.format_text(key, conf_dict[key])
+                formatted += self._format_text(key, conf_dict[key])
         return formatted
 
     @staticmethod
-    def format_text(key, val):
-        """Format the text for output """
-        return "{0: <25} {1}\n".format(key.strip() + ":", val.strip())
-
-
-class State():
-    """ State file for training command """
+    def _format_text(key, value):
+        """Format a key value pair into a consistently spaced string output for display.
+
+        Parameters
+        ----------
+        key: str
+            The label for this display item
+        value: str
+            The value for this display item
+
+        Returns
+        -------
+        str
+            The formatted key value pair for display
+        """
+        return "{0: <25} {1}\n".format(key.strip() + ":", value.strip())
+
+
+class _State():
+    """ Parses the state file in the current model directory, if the model is training, and
+    formats the content into a human readable format. """
     def __init__(self):
-        self.model_dir = self.get_arg("-m", "--model-dir")
-        self.trainer = self.get_arg("-t", "--trainer")
-        self.state_file = self.get_state_file()
+        self._model_dir = self._get_arg("-m", "--model-dir")
+        self._trainer = self._get_arg("-t", "--trainer")
+        self.state_file = self._get_state_file()
 
     @property
-    def is_training(self):
-        """ Return whether this has been called during training """
+    def _is_training(self):
+        """ bool: ``True`` if this function has been called during a training session
+        otherwise ``False``. """
         return len(sys.argv) > 1 and sys.argv[1].lower() == "train"
 
     @staticmethod
-    def get_arg(*args):
-        """ Return the value for a given option from sys.argv. Returns None if not found """
+    def _get_arg(*args):
+        """ Obtain the value for a given command line option from sys.argv.
+
+        Returns
+        -------
+        str or ``None``
+            The value of the given command line option, if it exists, otherwise ``None``
+        """
         cmd = sys.argv
         for opt in args:
             if opt in cmd:
                 return cmd[cmd.index(opt) + 1]
         return None
 
-    def get_state_file(self):
-        """ Return the state file in a string """
-        if not self.is_training or self.model_dir is None or self.trainer is None:
+    def _get_state_file(self):
+        """ Parses the model's state file and compiles the contents into a human readable string.
+
+        Returns
+        -------
+        str
+            The state file formatted into a human readable format
+        """
+        if not self._is_training or self._model_dir is None or self._trainer is None:
             return ""
-        fname = os.path.join(self.model_dir, "{}_state.json".format(self.trainer))
+        fname = os.path.join(self._model_dir, "{}_state.json".format(self._trainer))
         if not os.path.isfile(fname):
             return ""
 
diff --git a/lib/utils.py b/lib/utils.py
index f93da65..f65a054 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -149,12 +149,11 @@ def full_path_split(path):
         if parts[0] == path:   # sentinel for absolute paths
             allparts.insert(0, parts[0])
             break
-        elif parts[1] == path:  # sentinel for relative paths
+        if parts[1] == path:  # sentinel for relative paths
             allparts.insert(0, parts[1])
             break
-        else:
-            path = parts[0]
-            allparts.insert(0, parts[1])
+        path = parts[0]
+        allparts.insert(0, parts[1])
     logger.trace("path: %s, allparts: %s", path, allparts)
     return allparts
 
@@ -173,21 +172,6 @@ def backup_file(directory, filename):
         os.rename(origfile, backupfile)
 
 
-def keras_backend_quiet():
-    """ Suppresses the "Using x backend" message when importing backend from keras.
-
-    Make sure output is redirected back to stderr if there is an error. """
-    stderr = sys.stderr
-    sys.stderr = open(os.devnull, 'w')
-    try:
-        from keras import backend as K  # pylint:disable=import-outside-toplevel
-    except:
-        sys.stderr = stderr
-        raise
-    sys.stderr = stderr
-    return K
-
-
 def set_system_verbosity(loglevel):
     """ Set the verbosity level of tensorflow and suppresses
         future and deprecation warnings from any modules
@@ -200,7 +184,7 @@ def set_system_verbosity(loglevel):
         3 - filter out ERROR logs  """
 
     logger = logging.getLogger(__name__)  # pylint:disable=invalid-name
-    from lib.logger import get_loglevel
+    from lib.logger import get_loglevel  # pylint:disable=import-outside-toplevel
     numeric_level = get_loglevel(loglevel)
     loglevel = "2" if numeric_level > 15 else "0"
     logger.debug("System Verbosity level: %s", loglevel)
@@ -233,10 +217,10 @@ def safe_shutdown(got_error=False):
     """ Close queues, threads and processes in event of crash """
     logger = logging.getLogger(__name__)  # pylint:disable=invalid-name
     logger.debug("Safely shutting down")
-    from lib.queue_manager import queue_manager
+    from lib.queue_manager import queue_manager  # pylint:disable=import-outside-toplevel
     queue_manager.terminate_queues()
     logger.debug("Cleanup complete. Shutting down queue manager and exiting")
-    exit(1 if got_error else 0)
+    sys.exit(1 if got_error else 0)
 
 
 class FaceswapError(Exception):
@@ -370,7 +354,7 @@ class GetModel():
         os.remove(self._model_zip_path)
 
     def download_model(self):
-        """ Download model zip to cache dir """
+        """ Download model zip to cache folder """
         self.logger.info("Downloading model: '%s' from: %s", self._model_name, self._url_download)
         for attempt in range(self.retries):
             try:
@@ -395,7 +379,7 @@ class GetModel():
                     self.logger.info("Alternatively, you can manually download the model from: %s "
                                      "and unzip the contents to: %s",
                                      self._url_download, self.cache_dir)
-                    exit(1)
+                    sys.exit(1)
 
     def write_zipfile(self, response, downloaded_size):
         """ Write the model zip file to disk """
@@ -421,17 +405,17 @@ class GetModel():
             pbar.close()
 
     def unzip_model(self):
-        """ Unzip the model file to the cachedir """
+        """ Unzip the model file to the cache folder """
         self.logger.info("Extracting: '%s'", self._model_name)
         try:
             zip_file = zipfile.ZipFile(self._model_zip_path, "r")
             self.write_model(zip_file)
         except Exception as err:  # pylint:disable=broad-except
             self.logger.error("Unable to extract model file: %s", str(err))
-            exit(1)
+            sys.exit(1)
 
     def write_model(self, zip_file):
-        """ Extract files from zipfile and write, with progress bar """
+        """ Extract files from zip file and write, with progress bar """
         length = sum(f.file_size for f in zip_file.infolist())
         fnames = zip_file.namelist()
         self.logger.debug("Zipfile: Filenames: %s, Total Size: %s", fnames, length)
diff --git a/scripts/convert.py b/scripts/convert.py
index bdc28df..659c036 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -10,9 +10,9 @@ from time import sleep
 
 import cv2
 import numpy as np
+from tqdm import tqdm
 import tensorflow as tf
 from keras.backend.tensorflow_backend import set_session
-from tqdm import tqdm
 
 from scripts.fsmedia import Alignments, PostProcess, finalize
 from lib.serializer import get_serializer
@@ -22,7 +22,7 @@ from lib.gpu_stats import GPUStats
 from lib.image import read_image_hash, ImagesLoader
 from lib.multithreading import MultiThread, total_cpus
 from lib.queue_manager import queue_manager
-from lib.utils import FaceswapError, get_folder, get_image_paths
+from lib.utils import FaceswapError, get_backend, get_folder, get_image_paths
 from plugins.extract.pipeline import Extractor, ExtractMedia
 from plugins.plugin_loader import PluginLoader
 
@@ -830,7 +830,7 @@ class Predict():
         faces_seen = 0
         consecutive_no_faces = 0
         batch = list()
-        is_plaidml = GPUStats().is_plaidml
+        is_amd = get_backend() == "amd"
         while True:
             item = self._in_queue.get()
             if item != "EOF":
@@ -867,7 +867,7 @@ class Predict():
                 if faces_seen != 0:
                     feed_faces = self._compile_feed_faces(detected_batch)
                     batch_size = None
-                    if is_plaidml and feed_faces.shape[0] != self._batchsize:
+                    if is_amd and feed_faces.shape[0] != self._batchsize:
                         logger.verbose("Fallback to BS=1")
                         batch_size = 1
                     predicted = self._predict(feed_faces, batch_size)
