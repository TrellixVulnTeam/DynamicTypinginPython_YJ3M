commit 154729f4acfa5c85a50df6243940f39103664341
Author: deepfakes <deepfakes@clorr.fr>
Date:   Tue Dec 19 12:49:11 2017 +0100

    Creating lib folder

diff --git a/convert_photo.py b/convert_photo.py
index a95ed36..83b6354 100644
--- a/convert_photo.py
+++ b/convert_photo.py
@@ -2,14 +2,13 @@ import cv2
 import numpy
 from pathlib import Path
 
-from utils import get_image_paths
-from faces_detect import crop_faces
-from faces_process import convert_one_image
+from lib.utils import get_image_paths, get_folder
+from lib.faces_detect import crop_faces
+from lib.faces_process import convert_one_image
 
-images_SRC = get_image_paths( "original" )
+output_dir = get_folder( 'modified' )
 
-output_dir = Path( 'modified' )
-output_dir.mkdir( parents=True, exist_ok=True )
+images_SRC = get_image_paths( 'original' )
 
 for fn in images_SRC:
     image = cv2.imread(fn)
diff --git a/convert_trump_cage.py b/convert_trump_cage.py
new file mode 100644
index 0000000..fdd9813
--- /dev/null
+++ b/convert_trump_cage.py
@@ -0,0 +1,17 @@
+import cv2
+import numpy
+from pathlib import Path
+
+from lib.utils import get_image_paths, get_folder
+from lib.faces_process import convert_one_image
+
+output_dir = get_folder( 'output' )
+
+images_A = get_image_paths( 'data/trump' )
+images_B = get_image_paths( 'data/cage' )
+
+for fn in images_A:
+    image = cv2.imread(fn)
+    new_image = convert_one_image( image )
+    output_file = output_dir / Path(fn).name
+    cv2.imwrite( str(output_file), new_image )
\ No newline at end of file
diff --git a/extract.py b/extract.py
index cc0f9df..4b991bf 100644
--- a/extract.py
+++ b/extract.py
@@ -2,13 +2,12 @@ import cv2
 import numpy
 from pathlib import Path
 
-from utils import get_image_paths
-from faces_detect import crop_faces
+from lib.utils import get_image_paths, get_folder
+from lib.faces_detect import crop_faces
 
-images_SRC = get_image_paths( "src" )
+output_dir = get_folder( 'extract' )
 
-output_dir = Path( 'extract' )
-output_dir.mkdir( parents=True, exist_ok=True )
+images_SRC = get_image_paths( 'src' )
 
 for fn in images_SRC:
     image = cv2.imread(fn)
diff --git a/lib/__init__.py b/lib/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/faces_detect.py b/lib/faces_detect.py
similarity index 100%
rename from faces_detect.py
rename to lib/faces_detect.py
diff --git a/faces_process.py b/lib/faces_process.py
similarity index 100%
rename from faces_process.py
rename to lib/faces_process.py
diff --git a/image_augmentation.py b/lib/image_augmentation.py
old mode 100755
new mode 100644
similarity index 100%
rename from image_augmentation.py
rename to lib/image_augmentation.py
diff --git a/model.py b/lib/model.py
old mode 100755
new mode 100644
similarity index 100%
rename from model.py
rename to lib/model.py
diff --git a/pixel_shuffler.py b/lib/pixel_shuffler.py
old mode 100755
new mode 100644
similarity index 100%
rename from pixel_shuffler.py
rename to lib/pixel_shuffler.py
diff --git a/training_data.py b/lib/training_data.py
old mode 100755
new mode 100644
similarity index 100%
rename from training_data.py
rename to lib/training_data.py
diff --git a/umeyama.py b/lib/umeyama.py
old mode 100755
new mode 100644
similarity index 100%
rename from umeyama.py
rename to lib/umeyama.py
diff --git a/utils.py b/lib/utils.py
old mode 100755
new mode 100644
similarity index 100%
rename from utils.py
rename to lib/utils.py
diff --git a/script.py b/script.py
deleted file mode 100644
index 3fb3310..0000000
--- a/script.py
+++ /dev/null
@@ -1,19 +0,0 @@
-import cv2
-import numpy
-from pathlib import Path
-
-from utils import get_image_paths
-
-from faces_process import convert_one_image
-
-images_A = get_image_paths( "data/trump" )
-images_B = get_image_paths( "data/cage" )
-
-output_dir = Path( 'output' )
-output_dir.mkdir( parents=True, exist_ok=True )
-
-for fn in images_A:
-    image = cv2.imread(fn)
-    new_image = convert_one_image( image )
-    output_file = output_dir / Path(fn).name
-    cv2.imwrite( str(output_file), new_image )
\ No newline at end of file
diff --git a/train.py b/train.py
index eecdf7d..b5d2e58 100755
--- a/train.py
+++ b/train.py
@@ -1,49 +1,27 @@
 import cv2
 import numpy
 
-from utils import get_image_paths, load_images, stack_images
-from training_data import get_training_data
+from lib.utils import get_image_paths, load_images, stack_images
+from lib.training_data import get_training_data
 
-from model import autoencoder_A
-from model import autoencoder_B
-from model import encoder, decoder_A, decoder_B
+from lib.model import autoencoder_A
+from lib.model import autoencoder_B
+from lib.model import encoder, decoder_A, decoder_B
 
 try:
-    encoder  .load_weights( "models/encoder.h5"   )
-    decoder_A.load_weights( "models/decoder_A.h5" )
-    decoder_B.load_weights( "models/decoder_B.h5" )
+    encoder  .load_weights( 'models/encoder.h5'   )
+    decoder_A.load_weights( 'models/decoder_A.h5' )
+    decoder_B.load_weights( 'models/decoder_B.h5' )
 except:
     pass
 
 def save_model_weights():
-    encoder  .save_weights( "models/encoder.h5"   )
-    decoder_A.save_weights( "models/decoder_A.h5" )
-    decoder_B.save_weights( "models/decoder_B.h5" )
-    print( "save model weights" )
-
-images_A = get_image_paths( "data/trump" )
-images_B = get_image_paths( "data/cage"  )
-images_A = load_images( images_A ) / 255.0
-images_B = load_images( images_B ) / 255.0
-
-images_A += images_B.mean( axis=(0,1,2) ) - images_A.mean( axis=(0,1,2) )
-
-print( "press 'q' to stop training and save model" )
-
-for epoch in range(1000000):
-    batch_size = 64
-    warped_A, target_A = get_training_data( images_A, batch_size )
-    warped_B, target_B = get_training_data( images_B, batch_size )
-
-    loss_A = autoencoder_A.train_on_batch( warped_A, target_A )
-    loss_B = autoencoder_B.train_on_batch( warped_B, target_B )
-    print( loss_A, loss_B )
-
-    if epoch % 100 == 0:
-        save_model_weights()
-        test_A = target_A[0:14]
-        test_B = target_B[0:14]
+    encoder  .save_weights( 'models/encoder.h5'   )
+    decoder_A.save_weights( 'models/decoder_A.h5' )
+    decoder_B.save_weights( 'models/decoder_B.h5' )
+    print( 'save model weights' )
 
+def show_sample( test_A, test_B ):
     figure_A = numpy.stack([
         test_A,
         autoencoder_A.predict( test_A ),
@@ -61,7 +39,33 @@ for epoch in range(1000000):
 
     figure = numpy.clip( figure * 255, 0, 255 ).astype('uint8')
 
-    cv2.imshow( "", figure )
+    cv2.imshow( '', figure )
+    # If run from Docker, imshow won't work. Use:
+    # cv2.imwrite( '_sample.jpg', figure )
+
+images_A = get_image_paths( 'data/trump' )
+images_B = get_image_paths( 'data/cage'  )
+images_A = load_images( images_A ) / 255.0
+images_B = load_images( images_B ) / 255.0
+
+images_A += images_B.mean( axis=(0,1,2) ) - images_A.mean( axis=(0,1,2) )
+
+print( 'press "q" to stop training and save model' )
+
+BATCH_SIZE = 64
+
+for epoch in range(1000000):
+    warped_A, target_A = get_training_data( images_A, BATCH_SIZE )
+    warped_B, target_B = get_training_data( images_B, BATCH_SIZE )
+
+    loss_A = autoencoder_A.train_on_batch( warped_A, target_A )
+    loss_B = autoencoder_B.train_on_batch( warped_B, target_B )
+    print( loss_A, loss_B )
+
+    if epoch % 100 == 0:
+        save_model_weights()
+        show_sample(target_A[0:14], target_B[0:14])
+
     key = cv2.waitKey(1)
     if key == ord('q'):
         save_model_weights()
