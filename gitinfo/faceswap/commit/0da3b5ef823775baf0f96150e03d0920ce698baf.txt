commit 0da3b5ef823775baf0f96150e03d0920ce698baf
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sat Jun 8 11:52:17 2019 +0100

    Color Augmentation method (#752)
    
    * Color Augmentation: Implement testing code
    
    * Tweak Contrast and Lighting augmentation amounts
    
    * Prevent color augmentation from entering timelapse
    
    * Remove all augmentations from preview images

diff --git a/lib/cli.py b/lib/cli.py
index 9347df7..769f411 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -951,6 +951,17 @@ class TrainArgs(FaceSwapArgs):
                                       "horizontally. Sometimes it is desirable for this not to "
                                       "occur. Generally this should be left off except for "
                                       "during 'fit training'."})
+        argument_list.append({"opts": ("-ac", "--augment-color"),
+                              "action": "store_true",
+                              "dest": "augment_color",
+                              "default": False,
+                              "help": "Perform color augmentation on training images. This has "
+                                      "a 50%% chance of performing Contrast Limited Adaptive "
+                                      "Histogram Equilization on the image. Then it randomly "
+                                      "shifts the color balance +/- 8%% and the lighting +/- 30%% "
+                                      "on each face fed to the model. Should help make the model "
+                                      "less susceptible to color differences between the A and B "
+                                      "set, but may increase training time."})
         argument_list.append({"opts": ("-tia", "--timelapse-input-A"),
                               "action": DirFullPaths,
                               "dest": "timelapse_input_a",
diff --git a/lib/training_data.py b/lib/training_data.py
index 40f96db..1f4c005 100644
--- a/lib/training_data.py
+++ b/lib/training_data.py
@@ -4,7 +4,7 @@
 import logging
 
 from hashlib import sha1
-from random import shuffle, choice
+from random import random, shuffle, choice
 
 import cv2
 import numpy as np
@@ -50,12 +50,15 @@ class TrainingDataGenerator():
         logger.debug("Mask class: %s", mask_class)
         return mask_class
 
-    def minibatch_ab(self, images, batchsize, side, do_shuffle=True, is_timelapse=False):
+    def minibatch_ab(self, images, batchsize, side,
+                     do_shuffle=True, is_preview=False, is_timelapse=False):
         """ Keep a queue filled to 8x Batch Size """
         logger.debug("Queue batches: (image_count: %s, batchsize: %s, side: '%s', do_shuffle: %s, "
-                     "is_timelapse: %s)", len(images), batchsize, side, do_shuffle, is_timelapse)
+                     "is_preview, %s, is_timelapse: %s)", len(images), batchsize, side, do_shuffle,
+                     is_preview, is_timelapse)
         self.batchsize = batchsize
-        queue_in, queue_out = self.make_queues(side, is_timelapse)
+        is_display = is_preview or is_timelapse
+        queue_in, queue_out = self.make_queues(side, is_preview, is_timelapse)
         training_size = self.training_opts.get("training_size", 256)
         batch_shape = list((
             (batchsize, training_size, training_size, 3),  # sample images
@@ -69,25 +72,31 @@ class TrainingDataGenerator():
             shapes=batch_shape,
             in_queue=queue_in,
             out_queue=queue_out,
-            args=(images, side, is_timelapse, do_shuffle, batchsize))
+            args=(images, side, is_display, do_shuffle, batchsize))
         load_process.start()
-        logger.debug("Batching to queue: (side: '%s', is_timelapse: %s)", side, is_timelapse)
-        return self.minibatch(side, is_timelapse, load_process)
+        logger.debug("Batching to queue: (side: '%s', is_display: %s)", side, is_display)
+        return self.minibatch(side, is_display, load_process)
 
     @staticmethod
-    def make_queues(side, is_timelapse):
+    def make_queues(side, is_preview, is_timelapse):
         """ Create the buffer token queues for Fixed Producer Dispatcher """
-        q_name = "timelapse_{}".format(side) if is_timelapse else "train_{}".format(side)
+        q_name = "_{}".format(side)
+        if is_preview:
+            q_name = "{}{}".format("preview", q_name)
+        elif is_timelapse:
+            q_name = "{}{}".format("timelapse", q_name)
+        else:
+            q_name = "{}{}".format("train", q_name)
         q_names = ["{}_{}".format(q_name, direction) for direction in ("in", "out")]
         logger.debug(q_names)
         queues = [queue_manager.get_queue(queue) for queue in q_names]
         return queues
 
-    def load_batches(self, mem_gen, images, side, is_timelapse,
+    def load_batches(self, mem_gen, images, side, is_display,
                      do_shuffle=True, batchsize=0):
         """ Load the warped images and target images to queue """
-        logger.debug("Loading batch: (image_count: %s, side: '%s', is_timelapse: %s, "
-                     "do_shuffle: %s)", len(images), side, is_timelapse, do_shuffle)
+        logger.debug("Loading batch: (image_count: %s, side: '%s', is_display: %s, "
+                     "do_shuffle: %s)", len(images), side, is_display, do_shuffle)
         self.validate_samples(images)
         # Intialize this for each subprocess
         self._nearest_landmarks = dict()
@@ -103,18 +112,18 @@ class TrainingDataGenerator():
         epoch = 0
         for memory_wrapper in mem_gen:
             memory = memory_wrapper.get()
-            logger.trace("Putting to batch queue: (side: '%s', is_timelapse: %s)",
-                         side, is_timelapse)
+            logger.trace("Putting to batch queue: (side: '%s', is_display: %s)",
+                         side, is_display)
             for i, img_path in enumerate(img_iter):
-                imgs = self.process_face(img_path, side, is_timelapse)
+                imgs = self.process_face(img_path, side, is_display)
                 for j, img in enumerate(imgs):
                     memory[j][i][:] = img
                 epoch += 1
                 if i == batchsize - 1:
                     break
             memory_wrapper.ready()
-        logger.debug("Finished batching: (epoch: %s, side: '%s', is_timelapse: %s)",
-                     epoch, side, is_timelapse)
+        logger.debug("Finished batching: (epoch: %s, side: '%s', is_display: %s)",
+                     epoch, side, is_display)
 
     def validate_samples(self, data):
         """ Check the total number of images against batchsize and return
@@ -126,35 +135,37 @@ class TrainingDataGenerator():
         assert length >= self.batchsize, msg
 
     @staticmethod
-    def minibatch(side, is_timelapse, load_process):
+    def minibatch(side, is_display, load_process):
         """ A generator function that yields epoch, batchsize of warped_img
             and batchsize of target_img from the load queue """
-        logger.debug("Launching minibatch generator for queue (side: '%s', is_timelapse: %s)",
-                     side, is_timelapse)
+        logger.debug("Launching minibatch generator for queue (side: '%s', is_display: %s)",
+                     side, is_display)
         for batch_wrapper in load_process:
             with batch_wrapper as batch:
                 logger.trace("Yielding batch: (size: %s, item shapes: %s, side:  '%s', "
-                             "is_timelapse: %s)",
-                             len(batch), [item.shape for item in batch], side, is_timelapse)
+                             "is_display: %s)",
+                             len(batch), [item.shape for item in batch], side, is_display)
                 yield batch
         load_process.stop()
-        logger.debug("Finished minibatch generator for queue: (side: '%s', is_timelapse: %s)",
-                     side, is_timelapse)
+        logger.debug("Finished minibatch generator for queue: (side: '%s', is_display: %s)",
+                     side, is_display)
         load_process.join()
 
-    def process_face(self, filename, side, is_timelapse):
+    def process_face(self, filename, side, is_display):
         """ Load an image and perform transformation and warping """
-        logger.trace("Process face: (filename: '%s', side: '%s', is_timelapse: %s)",
-                     filename, side, is_timelapse)
+        logger.trace("Process face: (filename: '%s', side: '%s', is_display: %s)",
+                     filename, side, is_display)
         image = cv2_read_img(filename, raise_error=True)
         if self.mask_class or self.training_opts["warp_to_landmarks"]:
             src_pts = self.get_landmarks(filename, image, side)
         if self.mask_class:
             image = self.mask_class(src_pts, image, channels=4).mask
 
-        image = self.processing.color_adjust(image)
+        image = self.processing.color_adjust(image,
+                                             self.training_opts["augment_color"],
+                                             is_display)
 
-        if not is_timelapse:
+        if not is_display:
             image = self.processing.random_transform(image)
             if not self.training_opts["no_flip"]:
                 image = self.processing.do_random_flip(image)
@@ -223,12 +234,54 @@ class ImageManipulation():
         self.scale = 5  # Normal random variable scale
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    @staticmethod
-    def color_adjust(img):
+    def color_adjust(self, img, augment_color, is_display):
         """ Color adjust RGB image """
         logger.trace("Color adjusting image")
+        if not is_display and augment_color:
+            logger.trace("Augmenting color")
+            face, _ = self.separate_mask(img)
+            face = face.astype("uint8")
+            face = self.random_clahe(face)
+            face = self.random_lab(face)
+            img[:, :, :3] = face
         return img.astype('float32') / 255.0
 
+    @staticmethod
+    def random_clahe(image):
+        """ Randomly perform Contrast Limited Adaptive Histogram Equilization """
+        base_contrast = image.shape[0] // 128
+        contrast_random = random()
+        if contrast_random <= 0.5:
+            contrast_adjustment = int((contrast_random * 10.0) * (base_contrast / 2))
+            grid_size = base_contrast + contrast_adjustment
+            logger.trace("Adjusting Contrast. Grid Size: %s", grid_size)
+
+            clahe = cv2.createCLAHE(clipLimit=2.0,  # pylint: disable=no-member
+                                    tileGridSize=(grid_size, grid_size))
+            for chan in range(3):
+                image[:, :, chan] = clahe.apply(image[:, :, chan])
+        return image
+
+    @staticmethod
+    def random_lab(image):
+        """ Perform random color/lightness adjustment in LAB colorspace """
+        randoms = [(random() * 0.6) - 0.3,  # L adjust +/- 30%
+                   (random() * 0.16) - 0.08,  # A adjust +/- 8%
+                   (random() * 0.16) - 0.08]  # B adjust +/- 8%
+
+        logger.trace("Random LAB adjustments: %s", randoms)
+        image = cv2.cvtColor(  # pylint:disable=no-member
+            image, cv2.COLOR_BGR2LAB).astype("float32") / 255.0  # pylint:disable=no-member
+
+        for idx, adjustment in enumerate(randoms):
+            if adjustment >= 0:
+                image[:, :, idx] = ((1 - image[:, :, idx]) * adjustment) + image[:, :, idx]
+            else:
+                image[:, :, idx] = image[:, :, idx] * (1 + adjustment)
+        image = cv2.cvtColor((image * 255.0).astype("uint8"),  # pylint:disable=no-member
+                             cv2.COLOR_LAB2BGR)  # pylint:disable=no-member
+        return image
+
     @staticmethod
     def separate_mask(image):
         """ Return the image and the mask from a 4 channel image """
@@ -257,12 +310,12 @@ class ImageManipulation():
         tnx = np.random.uniform(-self.shift_range, self.shift_range) * width
         tny = np.random.uniform(-self.shift_range, self.shift_range) * height
 
-        mat = cv2.getRotationMatrix2D(  # pylint: disable=no-member
+        mat = cv2.getRotationMatrix2D(  # pylint:disable=no-member
             (width // 2, height // 2), rotation, scale)
         mat[:, 2] += (tnx, tny)
-        result = cv2.warpAffine(  # pylint: disable=no-member
+        result = cv2.warpAffine(  # pylint:disable=no-member
             image, mat, (width, height),
-            borderMode=cv2.BORDER_REPLICATE)  # pylint: disable=no-member
+            borderMode=cv2.BORDER_REPLICATE)  # pylint:disable=no-member
 
         logger.trace("Randomly transformed image")
         return result
@@ -301,16 +354,16 @@ class ImageManipulation():
 
         for i, map_ in enumerate([mapx, mapy]):
             map_ = map_ + np.random.normal(size=(5, 5), scale=self.scale)
-            interp[i] = cv2.resize(map_, (pad, pad))[slices, slices]  # pylint: disable=no-member
+            interp[i] = cv2.resize(map_, (pad, pad))[slices, slices]  # pylint:disable=no-member
 
-        warped_image = cv2.remap(  # pylint: disable=no-member
-            image, interp[0], interp[1], cv2.INTER_LINEAR)  # pylint: disable=no-member
+        warped_image = cv2.remap(  # pylint:disable=no-member
+            image, interp[0], interp[1], cv2.INTER_LINEAR)  # pylint:disable=no-member
         logger.trace("Warped image shape: %s", warped_image.shape)
 
         src_points = np.stack([mapx.ravel(), mapy.ravel()], axis=-1)
         dst_points = np.mgrid[dst_slice, dst_slice]
         mat = umeyama(src_points, True, dst_points.T.reshape(-1, 2))[0:2]
-        target_image = cv2.warpAffine(  # pylint: disable=no-member
+        target_image = cv2.warpAffine(  # pylint:disable=no-member
             image, mat, (self.output_size, self.output_size))
         logger.trace("Target image shape: %s", target_image.shape)
 
@@ -344,7 +397,7 @@ class ImageManipulation():
                        np.random.normal(size=dst_points.shape, scale=2.0))
         destination = destination.astype('uint8')
 
-        face_core = cv2.convexHull(np.concatenate(  # pylint: disable=no-member
+        face_core = cv2.convexHull(np.concatenate(  # pylint:disable=no-member
             [source[17:], destination[17:]], axis=0).astype(int))
 
         source = [(pty, ptx) for ptx, pty in source] + edge_anchors
@@ -355,7 +408,7 @@ class ImageManipulation():
             for idx, (pty, ptx) in enumerate(fpl):
                 if idx > 17:
                     break
-                elif cv2.pointPolygonTest(face_core,  # pylint: disable=no-member
+                elif cv2.pointPolygonTest(face_core,  # pylint:disable=no-member
                                           (pty, ptx),
                                           False) >= 0:
                     indicies_to_remove.add(idx)
@@ -370,23 +423,23 @@ class ImageManipulation():
         map_x_32 = map_x.astype('float32')
         map_y_32 = map_y.astype('float32')
 
-        warped_image = cv2.remap(image,  # pylint: disable=no-member
+        warped_image = cv2.remap(image,  # pylint:disable=no-member
                                  map_x_32,
                                  map_y_32,
-                                 cv2.INTER_LINEAR,  # pylint: disable=no-member
-                                 cv2.BORDER_TRANSPARENT)  # pylint: disable=no-member
+                                 cv2.INTER_LINEAR,  # pylint:disable=no-member
+                                 cv2.BORDER_TRANSPARENT)  # pylint:disable=no-member
         target_image = image
 
         # TODO Make sure this replacement is correct
         slices = slice(size // 2 - coverage // 2, size // 2 + coverage // 2)
 #        slices = slice(size // 32, size - size // 32)  # 8px on a 256px image
-        warped_image = cv2.resize(  # pylint: disable=no-member
+        warped_image = cv2.resize(  # pylint:disable=no-member
             warped_image[slices, slices, :], (self.input_size, self.input_size),
-            cv2.INTER_AREA)  # pylint: disable=no-member
+            cv2.INTER_AREA)  # pylint:disable=no-member
         logger.trace("Warped image shape: %s", warped_image.shape)
-        target_image = cv2.resize(  # pylint: disable=no-member
+        target_image = cv2.resize(  # pylint:disable=no-member
             target_image[slices, slices, :], (self.output_size, self.output_size),
-            cv2.INTER_AREA)  # pylint: disable=no-member
+            cv2.INTER_AREA)  # pylint:disable=no-member
         logger.trace("Target image shape: %s", target_image.shape)
 
         warped_image, warped_mask = self.separate_mask(warped_image)
diff --git a/plugins/train/model/_base.py b/plugins/train/model/_base.py
index f85a374..11f2570 100644
--- a/plugins/train/model/_base.py
+++ b/plugins/train/model/_base.py
@@ -37,6 +37,7 @@ class ModelBase():
                  gpus,
                  no_logs=False,
                  warp_to_landmarks=False,
+                 augment_color=False,
                  no_flip=False,
                  training_image_size=256,
                  alignments_paths=None,
@@ -48,12 +49,12 @@ class ModelBase():
                  memory_saving_gradients=False,
                  predict=False):
         logger.debug("Initializing ModelBase (%s): (model_dir: '%s', gpus: %s, no_logs: %s"
-                     "training_image_size, %s, alignments_paths: %s, preview_scale: %s, "
-                     "input_shape: %s, encoder_dim: %s, trainer: %s, pingpong: %s, "
-                     "memory_saving_gradients: %s, predict: %s)",
-                     self.__class__.__name__, model_dir, gpus, no_logs, training_image_size,
-                     alignments_paths, preview_scale, input_shape, encoder_dim, trainer,
-                     pingpong, memory_saving_gradients, predict)
+                     "warp_to_landmarks: %s, augment_color: %s, no_flip: %s, training_image_size, "
+                     "%s, alignments_paths: %s, preview_scale: %s, input_shape: %s, encoder_dim: "
+                     "%s, trainer: %s, pingpong: %s, memory_saving_gradients: %s, predict: %s)",
+                     self.__class__.__name__, model_dir, gpus, no_logs, warp_to_landmarks,
+                     augment_color, no_flip, training_image_size, alignments_paths, preview_scale,
+                     input_shape, encoder_dim, trainer, pingpong, memory_saving_gradients, predict)
 
         self.predict = predict
         self.model_dir = model_dir
@@ -85,6 +86,7 @@ class ModelBase():
         self.training_opts = {"alignments": alignments_paths,
                               "preview_scaling": preview_scale / 100,
                               "warp_to_landmarks": warp_to_landmarks,
+                              "augment_color": augment_color,
                               "no_flip": no_flip,
                               "pingpong": pingpong}
 
@@ -415,7 +417,7 @@ class ModelBase():
         logger.info("saved models")
         if snapshot_iteration:
             self.snapshot_models()
-    
+
     def snapshot_models(self):
         """ Take a snapshot of the model at current state and back up """
         logger.info("Saving snapshot")
diff --git a/plugins/train/trainer/_base.py b/plugins/train/trainer/_base.py
index c51c18c..7fcbdc1 100644
--- a/plugins/train/trainer/_base.py
+++ b/plugins/train/trainer/_base.py
@@ -15,6 +15,7 @@
                             Set to None for not used
         no_logs:            Disable tensorboard logging
         warp_to_landmarks:  Use random_warp_landmarks instead of random_warp
+        augment_color:      Perform random shifting of RGB colors +/- 15%
         no_flip:            Don't perform a random flip on the image
         pingpong:           Train each side seperately per save iteration rather than together
 """
@@ -144,8 +145,8 @@ class TrainerBase():
     def train_one_step(self, viewer, timelapse_kwargs):
         """ Train a batch """
         logger.trace("Training one step: (iteration: %s)", self.model.iterations)
-        do_preview = False if viewer is None else True
-        do_timelapse = False if timelapse_kwargs is None else True
+        do_preview = viewer is not None
+        do_timelapse = timelapse_kwargs is not None
         loss = dict()
         for side, batcher in self.batchers.items():
             if self.pingpong.active and side != self.pingpong.side:
@@ -212,11 +213,13 @@ class Batcher():
         self.model = model
         self.use_mask = use_mask
         self.side = side
+        self.images = images
         self.target = None
         self.samples = None
         self.mask = None
 
         self.feed = self.load_generator().minibatch_ab(images, batch_size, self.side)
+        self.preview_feed = None
         self.timelapse_feed = None
 
     def load_generator(self):
@@ -240,11 +243,10 @@ class Batcher():
         """ Return the next batch from the generator
             Items should come out as: (warped, target [, mask]) """
         batch = next(self.feed)
-        self.samples = batch[0] if do_preview else None
         batch = batch[1:]   # Remove full size samples from batch
         if self.use_mask:
             batch = self.compile_mask(batch)
-        self.target = batch[1] if do_preview else None
+        self.generate_preview(do_preview)
         return batch
 
     def compile_mask(self, batch):
@@ -257,6 +259,33 @@ class Batcher():
             retval.append([image, mask])
         return retval
 
+    def generate_preview(self, do_preview):
+        """ Generate the preview if a preview iteration """
+        if not do_preview:
+            self.samples = None
+            self.target = None
+            return
+        logger.debug("Generating preview")
+        if self.preview_feed is None:
+            self.set_preview_feed()
+        batch = next(self.preview_feed)
+        self.samples = batch[0]
+        batch = batch[1:]   # Remove full size samples from batch
+        if self.use_mask:
+            batch = self.compile_mask(batch)
+        self.target = batch[1]
+
+    def set_preview_feed(self):
+        """ Set the preview dictionary """
+        logger.debug("Setting preview feed: (side: '%s')", self.side)
+        batchsize = self.model.training_opts.get("preview_images", 14)
+        self.preview_feed = self.load_generator().minibatch_ab(self.images,
+                                                               batchsize,
+                                                               self.side,
+                                                               do_shuffle=True,
+                                                               is_preview=True)
+        logger.debug("Set preview feed. Batchsize: %s", batchsize)
+
     def compile_sample(self, batch_size, samples=None, images=None):
         """ Training samples to display in the viewer """
         num_images = self.model.training_opts.get("preview_images", 14)
diff --git a/scripts/train.py b/scripts/train.py
index 875450b..6ff1d61 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -157,6 +157,7 @@ class Train():
             self.args.gpus,
             no_logs=self.args.no_logs,
             warp_to_landmarks=self.args.warp_to_landmarks,
+            augment_color=self.args.augment_color,
             no_flip=self.args.no_flip,
             training_image_size=self.image_size,
             alignments_paths=self.alignments_paths,
