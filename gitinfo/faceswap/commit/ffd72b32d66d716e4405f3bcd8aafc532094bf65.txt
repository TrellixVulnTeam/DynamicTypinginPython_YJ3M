commit ffd72b32d66d716e4405f3bcd8aafc532094bf65
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Tue May 7 00:18:08 2019 +0000

    Remove all saved models from repo
    
    All models now download when required
    Model downloader can handle multiple files in model

diff --git a/.gitignore b/.gitignore
index 078aaf2..8522401 100644
--- a/.gitignore
+++ b/.gitignore
@@ -1,17 +1,11 @@
 *
 !setup.cfg
-!*.caffemodel
-!*.dat
-!*.h5
 !*.ico
 !*.inf
 !*.keep
 !*.md
-!*.npy
 !*.nsi
-!*.pb
 !*.png
-!*.prototxt
 !*.py
 !*.txt
 !.cache
diff --git a/lib/utils.py b/lib/utils.py
index 218a97d..91662e5 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -225,10 +225,29 @@ class GetModel():
     """ Check for models in their cache path
         If available, return the path, if not available, get, unzip and install model
 
-        model_name: The name of the model to be loaded
-        cache_dir: the model cache folder folder of the current plugin calling this class """
+        model_filename: The name of the model to be loaded (see notes below)
+        cache_dir:      The model cache folder of the current plugin calling this class
+                        IE: The folder that holds the model to be loaded.
+
+        NB: Models must have a certain naming convention:
+            IE: <model_name>_v<version_number>.<extension>
+            EG: s3fd_v1.pb
+
+            Multiple models can exist within the model_filename. They should be passed as a list
+            and follow the same naming convention as above. Any differences in filename should
+            occur AFTER the version number.
+            IE: [<model_name>_v<version_number><differentiating_information>.<extension>]
+            EG: [mtcnn_det_v1.1.py, mtcnn_det_v1.2.py, mtcnn_det_v1.3.py]
+                [resnet_ssd_v1.caffemodel, resnet_ssd_v1.prototext]
+
+            Models to be handled by this class must be added to the _model_id property
+            with their appropriate github identier mapped.
+            See https://github.com/deepfakes-models/faceswap-models for more information
+        """
 
     def __init__(self, model_filename, cache_dir):
+        if not isinstance(model_filename, list):
+            model_filename = [model_filename]
         self.model_filename = model_filename
         self.cache_dir = cache_dir
         self.url_base = "https://github.com/deepfakes-models/faceswap-models/releases/download"
@@ -244,6 +263,9 @@ class GetModel():
             # EXTRACT (SECTION 1)
             "face-alignment-network_2d4": 0,
             "cnn-facial-landmark": 1,
+            "mtcnn_det": 2,
+            "s3fd": 3,
+            "resnet_ssd": 4,
             # TRAIN (SECTION 2)
             # CONVERT (SECTION 3)
             }
@@ -251,29 +273,31 @@ class GetModel():
 
     @property
     def _model_full_name(self):
-        """ Return the model version from the filename """
-        retval = os.path.splitext(self.model_filename)[0]
+        """ Return the model full name from the filename(s) """
+        common_prefix = os.path.commonprefix(self.model_filename)
+        retval = os.path.splitext(common_prefix)[0]
         logger.trace(retval)
         return retval
 
     @property
     def _model_name(self):
-        """ Return the model version from the filename """
+        """ Return the model name from the model full name """
         retval = self._model_full_name[:self._model_full_name.rfind("_")]
         logger.trace(retval)
         return retval
 
     @property
     def _model_version(self):
-        """ Return the model version from the filename """
+        """ Return the model version from the model full name """
         retval = int(self._model_full_name[self._model_full_name.rfind("_") + 2:])
         logger.trace(retval)
         return retval
 
     @property
     def _model_path(self):
-        """ Return the model path in the cache folder """
-        retval = os.path.join(self.cache_dir, self.model_filename)
+        """ Return the model path(s) in the cache folder """
+        retval = [os.path.join(self.cache_dir, fname) for fname in self.model_filename]
+        retval = retval[0] if len(retval) == 1 else retval
         logger.trace(retval)
         return retval
 
@@ -286,7 +310,11 @@ class GetModel():
 
     @property
     def _model_exists(self):
-        retval = os.path.exists(self._model_path)
+        """ Check model(s) exist """
+        if isinstance(self._model_path, list):
+            retval = all(os.path.exists(pth) for pth in self._model_path)
+        else:
+            retval = os.path.exists(self._model_path)
         logger.trace(retval)
         return retval
 
@@ -343,6 +371,8 @@ class GetModel():
                 else:
                     logger.error("Failed to download model. Exiting. (Error: '%s', URL: '%s')",
                                  str(err), self._url_download)
+                    logger.info("You can manually download the model from: %s and unzip the "
+                                "contents to: %s", self._url_download, self.cache_dir)
                     exit(1)
 
     def write_zipfile(self, response):
diff --git a/plugins/extract/align/_base.py b/plugins/extract/align/_base.py
index 9dad4b1..30c90d0 100644
--- a/plugins/extract/align/_base.py
+++ b/plugins/extract/align/_base.py
@@ -84,6 +84,9 @@ class Aligner():
     @staticmethod
     def get_model(model_filename):
         """ Check if model is available, if not, download and unzip it """
+        if model_filename is None:
+            logger.debug("No model_filename specified. Returning None")
+            return None
         cache_path = os.path.join(os.path.dirname(__file__), ".cache")
         model = GetModel(model_filename, cache_path)
         return model.model_path
diff --git a/plugins/extract/detect/.cache/.keep b/plugins/extract/detect/.cache/.keep
new file mode 100644
index 0000000..e69de29
diff --git a/plugins/extract/detect/.cache/deploy.prototxt b/plugins/extract/detect/.cache/deploy.prototxt
deleted file mode 100644
index e9b7db0..0000000
--- a/plugins/extract/detect/.cache/deploy.prototxt
+++ /dev/null
@@ -1,1789 +0,0 @@
-input: "data"
-input_shape {
-  dim: 1
-  dim: 3
-  dim: 300
-  dim: 300
-}
-
-layer {
-  name: "data_bn"
-  type: "BatchNorm"
-  bottom: "data"
-  top: "data_bn"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "data_scale"
-  type: "Scale"
-  bottom: "data_bn"
-  top: "data_bn"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "conv1_h"
-  type: "Convolution"
-  bottom: "data_bn"
-  top: "conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 32
-    pad: 3
-    kernel_size: 7
-    stride: 2
-    weight_filler {
-      type: "msra"
-      variance_norm: FAN_OUT
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "conv1_bn_h"
-  type: "BatchNorm"
-  bottom: "conv1_h"
-  top: "conv1_h"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "conv1_scale_h"
-  type: "Scale"
-  bottom: "conv1_h"
-  top: "conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "conv1_relu"
-  type: "ReLU"
-  bottom: "conv1_h"
-  top: "conv1_h"
-}
-layer {
-  name: "conv1_pool"
-  type: "Pooling"
-  bottom: "conv1_h"
-  top: "conv1_pool"
-  pooling_param {
-    kernel_size: 3
-    stride: 2
-  }
-}
-layer {
-  name: "layer_64_1_conv1_h"
-  type: "Convolution"
-  bottom: "conv1_pool"
-  top: "layer_64_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 32
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_64_1_bn2_h"
-  type: "BatchNorm"
-  bottom: "layer_64_1_conv1_h"
-  top: "layer_64_1_conv1_h"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_64_1_scale2_h"
-  type: "Scale"
-  bottom: "layer_64_1_conv1_h"
-  top: "layer_64_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_64_1_relu2"
-  type: "ReLU"
-  bottom: "layer_64_1_conv1_h"
-  top: "layer_64_1_conv1_h"
-}
-layer {
-  name: "layer_64_1_conv2_h"
-  type: "Convolution"
-  bottom: "layer_64_1_conv1_h"
-  top: "layer_64_1_conv2_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 32
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_64_1_sum"
-  type: "Eltwise"
-  bottom: "layer_64_1_conv2_h"
-  bottom: "conv1_pool"
-  top: "layer_64_1_sum"
-}
-layer {
-  name: "layer_128_1_bn1_h"
-  type: "BatchNorm"
-  bottom: "layer_64_1_sum"
-  top: "layer_128_1_bn1_h"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_128_1_scale1_h"
-  type: "Scale"
-  bottom: "layer_128_1_bn1_h"
-  top: "layer_128_1_bn1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_128_1_relu1"
-  type: "ReLU"
-  bottom: "layer_128_1_bn1_h"
-  top: "layer_128_1_bn1_h"
-}
-layer {
-  name: "layer_128_1_conv1_h"
-  type: "Convolution"
-  bottom: "layer_128_1_bn1_h"
-  top: "layer_128_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 128
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_128_1_bn2"
-  type: "BatchNorm"
-  bottom: "layer_128_1_conv1_h"
-  top: "layer_128_1_conv1_h"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_128_1_scale2"
-  type: "Scale"
-  bottom: "layer_128_1_conv1_h"
-  top: "layer_128_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_128_1_relu2"
-  type: "ReLU"
-  bottom: "layer_128_1_conv1_h"
-  top: "layer_128_1_conv1_h"
-}
-layer {
-  name: "layer_128_1_conv2"
-  type: "Convolution"
-  bottom: "layer_128_1_conv1_h"
-  top: "layer_128_1_conv2"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 128
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_128_1_conv_expand_h"
-  type: "Convolution"
-  bottom: "layer_128_1_bn1_h"
-  top: "layer_128_1_conv_expand_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 128
-    bias_term: false
-    pad: 0
-    kernel_size: 1
-    stride: 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_128_1_sum"
-  type: "Eltwise"
-  bottom: "layer_128_1_conv2"
-  bottom: "layer_128_1_conv_expand_h"
-  top: "layer_128_1_sum"
-}
-layer {
-  name: "layer_256_1_bn1"
-  type: "BatchNorm"
-  bottom: "layer_128_1_sum"
-  top: "layer_256_1_bn1"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_256_1_scale1"
-  type: "Scale"
-  bottom: "layer_256_1_bn1"
-  top: "layer_256_1_bn1"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_256_1_relu1"
-  type: "ReLU"
-  bottom: "layer_256_1_bn1"
-  top: "layer_256_1_bn1"
-}
-layer {
-  name: "layer_256_1_conv1"
-  type: "Convolution"
-  bottom: "layer_256_1_bn1"
-  top: "layer_256_1_conv1"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 256
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_256_1_bn2"
-  type: "BatchNorm"
-  bottom: "layer_256_1_conv1"
-  top: "layer_256_1_conv1"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_256_1_scale2"
-  type: "Scale"
-  bottom: "layer_256_1_conv1"
-  top: "layer_256_1_conv1"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_256_1_relu2"
-  type: "ReLU"
-  bottom: "layer_256_1_conv1"
-  top: "layer_256_1_conv1"
-}
-layer {
-  name: "layer_256_1_conv2"
-  type: "Convolution"
-  bottom: "layer_256_1_conv1"
-  top: "layer_256_1_conv2"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 256
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_256_1_conv_expand"
-  type: "Convolution"
-  bottom: "layer_256_1_bn1"
-  top: "layer_256_1_conv_expand"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 256
-    bias_term: false
-    pad: 0
-    kernel_size: 1
-    stride: 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_256_1_sum"
-  type: "Eltwise"
-  bottom: "layer_256_1_conv2"
-  bottom: "layer_256_1_conv_expand"
-  top: "layer_256_1_sum"
-}
-layer {
-  name: "layer_512_1_bn1"
-  type: "BatchNorm"
-  bottom: "layer_256_1_sum"
-  top: "layer_512_1_bn1"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_512_1_scale1"
-  type: "Scale"
-  bottom: "layer_512_1_bn1"
-  top: "layer_512_1_bn1"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_512_1_relu1"
-  type: "ReLU"
-  bottom: "layer_512_1_bn1"
-  top: "layer_512_1_bn1"
-}
-layer {
-  name: "layer_512_1_conv1_h"
-  type: "Convolution"
-  bottom: "layer_512_1_bn1"
-  top: "layer_512_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 128
-    bias_term: false
-    pad: 1
-    kernel_size: 3
-    stride: 1 # 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_512_1_bn2_h"
-  type: "BatchNorm"
-  bottom: "layer_512_1_conv1_h"
-  top: "layer_512_1_conv1_h"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "layer_512_1_scale2_h"
-  type: "Scale"
-  bottom: "layer_512_1_conv1_h"
-  top: "layer_512_1_conv1_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "layer_512_1_relu2"
-  type: "ReLU"
-  bottom: "layer_512_1_conv1_h"
-  top: "layer_512_1_conv1_h"
-}
-layer {
-  name: "layer_512_1_conv2_h"
-  type: "Convolution"
-  bottom: "layer_512_1_conv1_h"
-  top: "layer_512_1_conv2_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 256
-    bias_term: false
-    pad: 2 # 1
-    kernel_size: 3
-    stride: 1
-    dilation: 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_512_1_conv_expand_h"
-  type: "Convolution"
-  bottom: "layer_512_1_bn1"
-  top: "layer_512_1_conv_expand_h"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  convolution_param {
-    num_output: 256
-    bias_term: false
-    pad: 0
-    kernel_size: 1
-    stride: 1 # 2
-    weight_filler {
-      type: "msra"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0.0
-    }
-  }
-}
-layer {
-  name: "layer_512_1_sum"
-  type: "Eltwise"
-  bottom: "layer_512_1_conv2_h"
-  bottom: "layer_512_1_conv_expand_h"
-  top: "layer_512_1_sum"
-}
-layer {
-  name: "last_bn_h"
-  type: "BatchNorm"
-  bottom: "layer_512_1_sum"
-  top: "layer_512_1_sum"
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-  param {
-    lr_mult: 0.0
-  }
-}
-layer {
-  name: "last_scale_h"
-  type: "Scale"
-  bottom: "layer_512_1_sum"
-  top: "layer_512_1_sum"
-  param {
-    lr_mult: 1.0
-    decay_mult: 1.0
-  }
-  param {
-    lr_mult: 2.0
-    decay_mult: 1.0
-  }
-  scale_param {
-    bias_term: true
-  }
-}
-layer {
-  name: "last_relu"
-  type: "ReLU"
-  bottom: "layer_512_1_sum"
-  top: "fc7"
-}
-
-layer {
-  name: "conv6_1_h"
-  type: "Convolution"
-  bottom: "fc7"
-  top: "conv6_1_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 128
-    pad: 0
-    kernel_size: 1
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv6_1_relu"
-  type: "ReLU"
-  bottom: "conv6_1_h"
-  top: "conv6_1_h"
-}
-layer {
-  name: "conv6_2_h"
-  type: "Convolution"
-  bottom: "conv6_1_h"
-  top: "conv6_2_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 256
-    pad: 1
-    kernel_size: 3
-    stride: 2
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv6_2_relu"
-  type: "ReLU"
-  bottom: "conv6_2_h"
-  top: "conv6_2_h"
-}
-layer {
-  name: "conv7_1_h"
-  type: "Convolution"
-  bottom: "conv6_2_h"
-  top: "conv7_1_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 64
-    pad: 0
-    kernel_size: 1
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv7_1_relu"
-  type: "ReLU"
-  bottom: "conv7_1_h"
-  top: "conv7_1_h"
-}
-layer {
-  name: "conv7_2_h"
-  type: "Convolution"
-  bottom: "conv7_1_h"
-  top: "conv7_2_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 128
-    pad: 1
-    kernel_size: 3
-    stride: 2
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv7_2_relu"
-  type: "ReLU"
-  bottom: "conv7_2_h"
-  top: "conv7_2_h"
-}
-layer {
-  name: "conv8_1_h"
-  type: "Convolution"
-  bottom: "conv7_2_h"
-  top: "conv8_1_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 64
-    pad: 0
-    kernel_size: 1
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv8_1_relu"
-  type: "ReLU"
-  bottom: "conv8_1_h"
-  top: "conv8_1_h"
-}
-layer {
-  name: "conv8_2_h"
-  type: "Convolution"
-  bottom: "conv8_1_h"
-  top: "conv8_2_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 128
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv8_2_relu"
-  type: "ReLU"
-  bottom: "conv8_2_h"
-  top: "conv8_2_h"
-}
-layer {
-  name: "conv9_1_h"
-  type: "Convolution"
-  bottom: "conv8_2_h"
-  top: "conv9_1_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 64
-    pad: 0
-    kernel_size: 1
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv9_1_relu"
-  type: "ReLU"
-  bottom: "conv9_1_h"
-  top: "conv9_1_h"
-}
-layer {
-  name: "conv9_2_h"
-  type: "Convolution"
-  bottom: "conv9_1_h"
-  top: "conv9_2_h"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 128
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv9_2_relu"
-  type: "ReLU"
-  bottom: "conv9_2_h"
-  top: "conv9_2_h"
-}
-layer {
-  name: "conv4_3_norm"
-  type: "Normalize"
-  bottom: "layer_256_1_bn1"
-  top: "conv4_3_norm"
-  norm_param {
-    across_spatial: false
-    scale_filler {
-      type: "constant"
-      value: 20
-    }
-    channel_shared: false
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_loc"
-  type: "Convolution"
-  bottom: "conv4_3_norm"
-  top: "conv4_3_norm_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 16
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_loc_perm"
-  type: "Permute"
-  bottom: "conv4_3_norm_mbox_loc"
-  top: "conv4_3_norm_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "conv4_3_norm_mbox_loc_perm"
-  top: "conv4_3_norm_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_conf"
-  type: "Convolution"
-  bottom: "conv4_3_norm"
-  top: "conv4_3_norm_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 8 # 84
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_conf_perm"
-  type: "Permute"
-  bottom: "conv4_3_norm_mbox_conf"
-  top: "conv4_3_norm_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "conv4_3_norm_mbox_conf_perm"
-  top: "conv4_3_norm_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv4_3_norm_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "conv4_3_norm"
-  bottom: "data"
-  top: "conv4_3_norm_mbox_priorbox"
-  prior_box_param {
-    min_size: 30.0
-    max_size: 60.0
-    aspect_ratio: 2
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 8
-    offset: 0.5
-  }
-}
-layer {
-  name: "fc7_mbox_loc"
-  type: "Convolution"
-  bottom: "fc7"
-  top: "fc7_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 24
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "fc7_mbox_loc_perm"
-  type: "Permute"
-  bottom: "fc7_mbox_loc"
-  top: "fc7_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "fc7_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "fc7_mbox_loc_perm"
-  top: "fc7_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "fc7_mbox_conf"
-  type: "Convolution"
-  bottom: "fc7"
-  top: "fc7_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 12 # 126
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "fc7_mbox_conf_perm"
-  type: "Permute"
-  bottom: "fc7_mbox_conf"
-  top: "fc7_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "fc7_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "fc7_mbox_conf_perm"
-  top: "fc7_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "fc7_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "fc7"
-  bottom: "data"
-  top: "fc7_mbox_priorbox"
-  prior_box_param {
-    min_size: 60.0
-    max_size: 111.0
-    aspect_ratio: 2
-    aspect_ratio: 3
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 16
-    offset: 0.5
-  }
-}
-layer {
-  name: "conv6_2_mbox_loc"
-  type: "Convolution"
-  bottom: "conv6_2_h"
-  top: "conv6_2_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 24
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv6_2_mbox_loc_perm"
-  type: "Permute"
-  bottom: "conv6_2_mbox_loc"
-  top: "conv6_2_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv6_2_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "conv6_2_mbox_loc_perm"
-  top: "conv6_2_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv6_2_mbox_conf"
-  type: "Convolution"
-  bottom: "conv6_2_h"
-  top: "conv6_2_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 12 # 126
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv6_2_mbox_conf_perm"
-  type: "Permute"
-  bottom: "conv6_2_mbox_conf"
-  top: "conv6_2_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv6_2_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "conv6_2_mbox_conf_perm"
-  top: "conv6_2_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv6_2_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "conv6_2_h"
-  bottom: "data"
-  top: "conv6_2_mbox_priorbox"
-  prior_box_param {
-    min_size: 111.0
-    max_size: 162.0
-    aspect_ratio: 2
-    aspect_ratio: 3
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 32
-    offset: 0.5
-  }
-}
-layer {
-  name: "conv7_2_mbox_loc"
-  type: "Convolution"
-  bottom: "conv7_2_h"
-  top: "conv7_2_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 24
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv7_2_mbox_loc_perm"
-  type: "Permute"
-  bottom: "conv7_2_mbox_loc"
-  top: "conv7_2_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv7_2_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "conv7_2_mbox_loc_perm"
-  top: "conv7_2_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv7_2_mbox_conf"
-  type: "Convolution"
-  bottom: "conv7_2_h"
-  top: "conv7_2_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 12 # 126
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv7_2_mbox_conf_perm"
-  type: "Permute"
-  bottom: "conv7_2_mbox_conf"
-  top: "conv7_2_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv7_2_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "conv7_2_mbox_conf_perm"
-  top: "conv7_2_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv7_2_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "conv7_2_h"
-  bottom: "data"
-  top: "conv7_2_mbox_priorbox"
-  prior_box_param {
-    min_size: 162.0
-    max_size: 213.0
-    aspect_ratio: 2
-    aspect_ratio: 3
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 64
-    offset: 0.5
-  }
-}
-layer {
-  name: "conv8_2_mbox_loc"
-  type: "Convolution"
-  bottom: "conv8_2_h"
-  top: "conv8_2_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 16
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv8_2_mbox_loc_perm"
-  type: "Permute"
-  bottom: "conv8_2_mbox_loc"
-  top: "conv8_2_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv8_2_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "conv8_2_mbox_loc_perm"
-  top: "conv8_2_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv8_2_mbox_conf"
-  type: "Convolution"
-  bottom: "conv8_2_h"
-  top: "conv8_2_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 8 # 84
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv8_2_mbox_conf_perm"
-  type: "Permute"
-  bottom: "conv8_2_mbox_conf"
-  top: "conv8_2_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv8_2_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "conv8_2_mbox_conf_perm"
-  top: "conv8_2_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv8_2_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "conv8_2_h"
-  bottom: "data"
-  top: "conv8_2_mbox_priorbox"
-  prior_box_param {
-    min_size: 213.0
-    max_size: 264.0
-    aspect_ratio: 2
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 100
-    offset: 0.5
-  }
-}
-layer {
-  name: "conv9_2_mbox_loc"
-  type: "Convolution"
-  bottom: "conv9_2_h"
-  top: "conv9_2_mbox_loc"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 16
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv9_2_mbox_loc_perm"
-  type: "Permute"
-  bottom: "conv9_2_mbox_loc"
-  top: "conv9_2_mbox_loc_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv9_2_mbox_loc_flat"
-  type: "Flatten"
-  bottom: "conv9_2_mbox_loc_perm"
-  top: "conv9_2_mbox_loc_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv9_2_mbox_conf"
-  type: "Convolution"
-  bottom: "conv9_2_h"
-  top: "conv9_2_mbox_conf"
-  param {
-    lr_mult: 1
-    decay_mult: 1
-  }
-  param {
-    lr_mult: 2
-    decay_mult: 0
-  }
-  convolution_param {
-    num_output: 8 # 84
-    pad: 1
-    kernel_size: 3
-    stride: 1
-    weight_filler {
-      type: "xavier"
-    }
-    bias_filler {
-      type: "constant"
-      value: 0
-    }
-  }
-}
-layer {
-  name: "conv9_2_mbox_conf_perm"
-  type: "Permute"
-  bottom: "conv9_2_mbox_conf"
-  top: "conv9_2_mbox_conf_perm"
-  permute_param {
-    order: 0
-    order: 2
-    order: 3
-    order: 1
-  }
-}
-layer {
-  name: "conv9_2_mbox_conf_flat"
-  type: "Flatten"
-  bottom: "conv9_2_mbox_conf_perm"
-  top: "conv9_2_mbox_conf_flat"
-  flatten_param {
-    axis: 1
-  }
-}
-layer {
-  name: "conv9_2_mbox_priorbox"
-  type: "PriorBox"
-  bottom: "conv9_2_h"
-  bottom: "data"
-  top: "conv9_2_mbox_priorbox"
-  prior_box_param {
-    min_size: 264.0
-    max_size: 315.0
-    aspect_ratio: 2
-    flip: true
-    clip: false
-    variance: 0.1
-    variance: 0.1
-    variance: 0.2
-    variance: 0.2
-    step: 300
-    offset: 0.5
-  }
-}
-layer {
-  name: "mbox_loc"
-  type: "Concat"
-  bottom: "conv4_3_norm_mbox_loc_flat"
-  bottom: "fc7_mbox_loc_flat"
-  bottom: "conv6_2_mbox_loc_flat"
-  bottom: "conv7_2_mbox_loc_flat"
-  bottom: "conv8_2_mbox_loc_flat"
-  bottom: "conv9_2_mbox_loc_flat"
-  top: "mbox_loc"
-  concat_param {
-    axis: 1
-  }
-}
-layer {
-  name: "mbox_conf"
-  type: "Concat"
-  bottom: "conv4_3_norm_mbox_conf_flat"
-  bottom: "fc7_mbox_conf_flat"
-  bottom: "conv6_2_mbox_conf_flat"
-  bottom: "conv7_2_mbox_conf_flat"
-  bottom: "conv8_2_mbox_conf_flat"
-  bottom: "conv9_2_mbox_conf_flat"
-  top: "mbox_conf"
-  concat_param {
-    axis: 1
-  }
-}
-layer {
-  name: "mbox_priorbox"
-  type: "Concat"
-  bottom: "conv4_3_norm_mbox_priorbox"
-  bottom: "fc7_mbox_priorbox"
-  bottom: "conv6_2_mbox_priorbox"
-  bottom: "conv7_2_mbox_priorbox"
-  bottom: "conv8_2_mbox_priorbox"
-  bottom: "conv9_2_mbox_priorbox"
-  top: "mbox_priorbox"
-  concat_param {
-    axis: 2
-  }
-}
-
-layer {
-  name: "mbox_conf_reshape"
-  type: "Reshape"
-  bottom: "mbox_conf"
-  top: "mbox_conf_reshape"
-  reshape_param {
-    shape {
-      dim: 0
-      dim: -1
-      dim: 2
-    }
-  }
-}
-layer {
-  name: "mbox_conf_softmax"
-  type: "Softmax"
-  bottom: "mbox_conf_reshape"
-  top: "mbox_conf_softmax"
-  softmax_param {
-    axis: 2
-  }
-}
-layer {
-  name: "mbox_conf_flatten"
-  type: "Flatten"
-  bottom: "mbox_conf_softmax"
-  top: "mbox_conf_flatten"
-  flatten_param {
-    axis: 1
-  }
-}
-
-layer {
-  name: "detection_out"
-  type: "DetectionOutput"
-  bottom: "mbox_loc"
-  bottom: "mbox_conf_flatten"
-  bottom: "mbox_priorbox"
-  top: "detection_out"
-  include {
-    phase: TEST
-  }
-  detection_output_param {
-    num_classes: 2
-    share_location: true
-    background_label_id: 0
-    nms_param {
-      nms_threshold: 0.3
-      top_k: 400
-    }
-    code_type: CENTER_SIZE
-    keep_top_k: 200
-    confidence_threshold: 0.01
-  }
-}
diff --git a/plugins/extract/detect/.cache/det1.npy b/plugins/extract/detect/.cache/det1.npy
deleted file mode 100755
index 7c05a2c..0000000
Binary files a/plugins/extract/detect/.cache/det1.npy and /dev/null differ
diff --git a/plugins/extract/detect/.cache/det2.npy b/plugins/extract/detect/.cache/det2.npy
deleted file mode 100755
index 85d5bf0..0000000
Binary files a/plugins/extract/detect/.cache/det2.npy and /dev/null differ
diff --git a/plugins/extract/detect/.cache/det3.npy b/plugins/extract/detect/.cache/det3.npy
deleted file mode 100755
index 90d5ba9..0000000
Binary files a/plugins/extract/detect/.cache/det3.npy and /dev/null differ
diff --git a/plugins/extract/detect/.cache/res10_300x300_ssd_iter_140000_fp16.caffemodel b/plugins/extract/detect/.cache/res10_300x300_ssd_iter_140000_fp16.caffemodel
deleted file mode 100644
index 0e9cd4a..0000000
Binary files a/plugins/extract/detect/.cache/res10_300x300_ssd_iter_140000_fp16.caffemodel and /dev/null differ
diff --git a/plugins/extract/detect/.cache/s3fd.pb b/plugins/extract/detect/.cache/s3fd.pb
deleted file mode 100755
index d498a53..0000000
Binary files a/plugins/extract/detect/.cache/s3fd.pb and /dev/null differ
diff --git a/plugins/extract/detect/_base.py b/plugins/extract/detect/_base.py
index 057b9c5..397348a 100755
--- a/plugins/extract/detect/_base.py
+++ b/plugins/extract/detect/_base.py
@@ -20,7 +20,7 @@ import cv2
 import dlib
 
 from lib.gpu_stats import GPUStats
-from lib.utils import rotate_landmarks
+from lib.utils import rotate_landmarks, GetModel
 from plugins.extract._config import Config
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
@@ -33,12 +33,11 @@ def get_config(plugin_name):
 
 class Detector():
     """ Detector object """
-    def __init__(self, loglevel, rotation=None, min_size=0):
-        logger.debug("Initializing %s: (rotation: %s, min_size: %s)",
-                     self.__class__.__name__, rotation, min_size)
+    def __init__(self, loglevel, model_filename=None, rotation=None, min_size=0):
+        logger.debug("Initializing %s: (model_filename: %s, rotation: %s, min_size: %s)",
+                     self.__class__.__name__, model_filename, rotation, min_size)
         self.config = get_config(".".join(self.__module__.split(".")[-2:]))
         self.loglevel = loglevel
-        self.cachepath = os.path.join(os.path.dirname(__file__), ".cache")
         self.rotation = self.get_rotation_angles(rotation)
         self.min_size = min_size
         self.parent_is_pool = False
@@ -50,7 +49,7 @@ class Detector():
         self.queues = {"in": None, "out": None}
 
         #  Path to model if required
-        self.model_path = self.set_model_path()
+        self.model_path = self.get_model(model_filename)
 
         # Target image size for passing images through the detector
         # Set to tuple of dimensions (x, y) or int of pixel count
@@ -69,13 +68,6 @@ class Detector():
         logger.debug("Initialized _base %s", self.__class__.__name__)
 
     # <<< OVERRIDE METHODS >>> #
-    # These methods must be overriden when creating a plugin
-    @staticmethod
-    def set_model_path():
-        """ path to data file/models
-            override for specific detector """
-        raise NotImplementedError()
-
     def initialize(self, *args, **kwargs):
         """ Inititalize the detector
             Tasks to be run before any detection is performed.
@@ -99,6 +91,17 @@ class Detector():
             exit(1)
         logger.debug("Detecting Faces (args: %s, kwargs: %s)", args, kwargs)
 
+    # <<< GET MODEL >>> #
+    @staticmethod
+    def get_model(model_filename):
+        """ Check if model is available, if not, download and unzip it """
+        if model_filename is None:
+            logger.debug("No model_filename specified. Returning None")
+            return None
+        cache_path = os.path.join(os.path.dirname(__file__), ".cache")
+        model = GetModel(model_filename, cache_path)
+        return model.model_path
+
     # <<< DETECTION WRAPPER >>> #
     def run(self, *args, **kwargs):
         """ Parent detect process.
diff --git a/plugins/extract/detect/cv2_dnn.py b/plugins/extract/detect/cv2_dnn.py
index 49d1356..8b282a8 100755
--- a/plugins/extract/detect/cv2_dnn.py
+++ b/plugins/extract/detect/cv2_dnn.py
@@ -1,6 +1,5 @@
 #!/usr/bin/env python3
 """ OpenCV DNN Face detection plugin """
-import os
 from time import sleep
 
 import numpy as np
@@ -11,23 +10,14 @@ from ._base import cv2, Detector, dlib, logger
 class Detect(Detector):
     """ CV2 DNN detector for face recognition """
     def __init__(self, **kwargs):
-        super().__init__(**kwargs)
+        model_filename = ["resnet_ssd_v1.caffemodel", "resnet_ssd_v1.prototxt"]
+        super().__init__(model_filename=model_filename, **kwargs)
         self.parent_is_pool = True
         self.target = (300, 300)  # Doesn't use VRAM
         self.vram = 0
-        self.config_file = os.path.join(self.cachepath, "deploy.prototxt")
         self.detector = None
         self.confidence = self.config["confidence"] / 100
 
-    def set_model_path(self):
-        """ CV2 DNN model file """
-        model_path = os.path.join(self.cachepath, "res10_300x300_ssd_iter_140000_fp16.caffemodel")
-        if not os.path.exists(model_path):
-            raise Exception("Error: Unable to find {}, reinstall "
-                            "the lib!".format(model_path))
-        logger.debug("Loading model: '%s'", model_path)
-        return model_path
-
     def initialize(self, *args, **kwargs):
         """ Calculate batch size """
         super().initialize(*args, **kwargs)
@@ -39,8 +29,8 @@ class Detect(Detector):
     def detect_faces(self, *args, **kwargs):
         """ Detect faces in grayscale image """
         super().detect_faces(*args, **kwargs)
-        detector = cv2.dnn.readNetFromCaffe(self.config_file,  # pylint: disable=no-member
-                                            self.model_path)
+        detector = cv2.dnn.readNetFromCaffe(self.model_path[1],  # pylint: disable=no-member
+                                            self.model_path[0])
         detector.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)  # pylint: disable=no-member
         while True:
             item = self.get_item()
diff --git a/plugins/extract/detect/manual.py b/plugins/extract/detect/manual.py
index 5b890f8..703d011 100644
--- a/plugins/extract/detect/manual.py
+++ b/plugins/extract/detect/manual.py
@@ -9,10 +9,6 @@ class Detect(Detector):
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
 
-    def set_model_path(self):
-        """ No model required for Manual Detector """
-        return None
-
     def initialize(self, *args, **kwargs):
         """ Create the mtcnn detector """
         super().initialize(*args, **kwargs)
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index e1d005b..1126005 100755
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -29,7 +29,8 @@ def import_tensorflow():
 class Detect(Detector):
     """ MTCNN detector for face recognition """
     def __init__(self, **kwargs):
-        super().__init__(**kwargs)
+        model_filename = ["mtcnn_det_v1.1.npy", "mtcnn_det_v1.2.npy", "mtcnn_det_v1.3.npy"]
+        super().__init__(model_filename=model_filename, **kwargs)
         self.kwargs = self.validate_kwargs()
         self.name = "mtcnn"
         self.target = 2073600  # Uses approx 1.30 GB of VRAM
@@ -60,16 +61,6 @@ class Detect(Detector):
         logger.debug("Using mtcnn kwargs: %s", kwargs)
         return kwargs
 
-    def set_model_path(self):
-        """ Load the mtcnn models """
-        for model in ("det1.npy", "det2.npy", "det3.npy"):
-            model_path = os.path.join(self.cachepath, model)
-            if not os.path.exists(model_path):
-                raise Exception("Error: Unable to find {}, reinstall "
-                                "the lib!".format(model_path))
-            logger.debug("Loading model: '%s'", model_path)
-        return self.cachepath
-
     def initialize(self, *args, **kwargs):
         """ Create the mtcnn detector """
         try:
@@ -513,15 +504,15 @@ def create_mtcnn(sess, model_path):
     with tf.variable_scope('pnet'):
         data = tf.placeholder(tf.float32, (None, None, None, 3), 'input')
         pnet = PNet({'data': data})
-        pnet.load(os.path.join(model_path, 'det1.npy'), sess)
+        pnet.load(model_path[0], sess)
     with tf.variable_scope('rnet'):
         data = tf.placeholder(tf.float32, (None, 24, 24, 3), 'input')
         rnet = RNet({'data': data})
-        rnet.load(os.path.join(model_path, 'det2.npy'), sess)
+        rnet.load(model_path[1], sess)
     with tf.variable_scope('onet'):
         data = tf.placeholder(tf.float32, (None, 48, 48, 3), 'input')
         onet = ONet({'data': data})
-        onet.load(os.path.join(model_path, 'det3.npy'), sess)
+        onet.load(model_path[2], sess)
 
     pnet_fun = lambda img: sess.run(('pnet/conv4-2/BiasAdd:0', # noqa
                                      'pnet/prob1:0'),
diff --git a/plugins/extract/detect/s3fd.py b/plugins/extract/detect/s3fd.py
index c8e5c58..2df7311 100644
--- a/plugins/extract/detect/s3fd.py
+++ b/plugins/extract/detect/s3fd.py
@@ -6,7 +6,6 @@ Adapted from S3FD Port in FAN:
 https://github.com/1adrianb/face-alignment
 """
 
-import os
 from scipy.special import logsumexp
 
 import numpy as np
@@ -18,22 +17,14 @@ from ._base import Detector, dlib, logger
 class Detect(Detector):
     """ S3FD detector for face recognition """
     def __init__(self, **kwargs):
-        super().__init__(**kwargs)
+        model_filename = "s3fd_v1.pb"
+        super().__init__(model_filename=model_filename, **kwargs)
         self.name = "s3fd"
         self.target = (640, 640)  # Uses approx 4 GB of VRAM
         self.vram = 4096
         self.min_vram = 1024  # Will run at this with warnings
         self.model = None
 
-    def set_model_path(self):
-        """ Load the s3fd model """
-        model_path = os.path.join(self.cachepath, "s3fd.pb")
-        if not os.path.exists(model_path):
-            raise Exception("Error: Unable to find {}, reinstall "
-                            "the lib!".format(model_path))
-        logger.debug("Loading model: '%s'", model_path)
-        return model_path
-
     def initialize(self, *args, **kwargs):
         """ Create the s3fd detector """
         try:
