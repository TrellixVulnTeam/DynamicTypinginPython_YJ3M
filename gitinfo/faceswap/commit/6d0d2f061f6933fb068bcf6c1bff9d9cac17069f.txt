commit 6d0d2f061f6933fb068bcf6c1bff9d9cac17069f
Author: Tim van den Essen <tim3345@live.nl>
Date:   Thu Oct 25 18:46:24 2018 +0200

    Add timelapse functionality (#512)
    
    * add new cli options
    
    * add timelapse script
    
    * add batch size on image generation
    
    * fix circular dependency
    
    * add attribute check
    
    * refactor to 3 parameters
    
    * fix some typos
    
    * do not shuffle the set
    
    * default to models folder when no timelapse output supplied
    
    * almost forgot this

diff --git a/lib/cli.py b/lib/cli.py
index 6cb9af5..26bb2c9 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -672,6 +672,36 @@ class TrainArgs(FaceSwapArgs):
                               "dest": "redirect_gui",
                               "default": False,
                               "help": argparse.SUPPRESS})
+        argument_list.append({"opts": ("-tia", "--timelapse-input-A"),
+                              "action": DirFullPaths,
+                              "dest": "timelapse_input_A",
+                              "default": None,
+                              "help": "For if you want a timelapse: "
+                                      "The input folder for the timelapse. "
+                                      "This folder should contain faces of A "
+                                      "which will be converted for the "
+                                      "timelapse. You must supply a "
+                                      "--timelapse-output and a "
+                                      "--timelapse-input-B parameter."})
+        argument_list.append({"opts": ("-tib", "--timelapse-input-B"),
+                              "action": DirFullPaths,
+                              "dest": "timelapse_input_B",
+                              "default": None,
+                              "help": "For if you want a timelapse: "
+                                      "The input folder for the timelapse. "
+                                      "This folder should contain faces of B "
+                                      "which will be converted for the "
+                                      "timelapse. You must supply a "
+                                      "--timelapse-output and a "
+                                      "--timelapse-input-A parameter."})
+        argument_list.append({"opts": ("-to", "--timelapse-output"),
+                              "action": DirFullPaths,
+                              "dest": "timelapse_output",
+                              "default": None,
+                              "help": "The output folder for the timelapse. "
+                                      "If the input folders are supplied but "
+                                      "no output folder, it will default to "
+                                      "your model folder /timelapse/"})
         return argument_list
 
 
diff --git a/lib/training_data.py b/lib/training_data.py
index a45eb58..59a6f25 100644
--- a/lib/training_data.py
+++ b/lib/training_data.py
@@ -2,8 +2,8 @@ import cv2
 import numpy
 from random import shuffle
 
-from .utils import BackgroundGenerator
-from .umeyama import umeyama
+import lib.utils
+from lib.umeyama import umeyama
 
 class TrainingDataGenerator():
     def __init__(self, random_transform_args, coverage, scale=5, zoom=1): #TODO thos default should stay in the warp function
@@ -12,21 +12,23 @@ class TrainingDataGenerator():
         self.scale = scale
         self.zoom = zoom
 
-    def minibatchAB(self, images, batchsize):
-        batch = BackgroundGenerator(self.minibatch(images, batchsize), 1)
+    def minibatchAB(self, images, batchsize, doShuffle=True):
+        batch = lib.utils.BackgroundGenerator(self.minibatch(images, batchsize, doShuffle), 1)
         for ep1, warped_img, target_img in batch.iterator():
             yield ep1, warped_img, target_img
 
     # A generator function that yields epoch, batchsize of warped_img and batchsize of target_img
-    def minibatch(self, data, batchsize):
+    def minibatch(self, data, batchsize, doShuffle=True):
         length = len(data)
         assert length >= batchsize, "Number of images is lower than batch-size (Note that too few images may lead to bad training). # images: {}, batch-size: {}".format(length, batchsize)
         epoch = i = 0
-        shuffle(data)
+        if doShuffle:
+            shuffle(data)
         while True:
             size = batchsize
             if i+size > length:
-                shuffle(data)
+                if doShuffle:
+                    shuffle(data)
                 i = 0
                 epoch+=1
             rtn = numpy.float32([self.read_image(img) for img in data[i:i+size]])
diff --git a/lib/utils.py b/lib/utils.py
index 64a1be9..c04be48 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -12,6 +12,9 @@ from pathlib import Path
 import cv2
 import numpy as np
 
+import lib.training_data
+from time import time
+
 
 # Global variables
 _image_extensions = ['.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff']
@@ -160,3 +163,68 @@ class BackgroundGenerator(threading.Thread):
             if next_item is None:
                 break
             yield next_item
+
+class Timelapse:
+    @classmethod
+    def CreateTimelapse(test, input_dir_A, input_dir_B, output_dir, trainer):
+        #self.input_dir = input
+        #self.output_dir = output
+        #self.trainer = trainer
+
+        if input_dir_A is None and input_dir_B is None and output_dir is None:
+            return None
+
+        if input_dir_A is None or input_dir_B is None:
+            raise Exception("To enable the timelapse, you have to supply all the parameters "
+                            "(--timelapse-input-A and --timelapse-input-B).")
+
+        if output_dir is None:
+            output_dir = get_folder(os.path.join(trainer.model.model_dir, "timelapse"))
+
+        return Timelapse(input_dir_A, input_dir_B, output_dir, trainer)
+
+    def __init__(self, input_dir_A, input_dir_B, output, trainer):
+        self.output_dir = output
+        self.trainer = trainer
+
+        if not os.path.isdir(self.output_dir):
+            print('Error: {} does not exist'.format(self.output_dir))
+            exit(1)
+
+        self.files_A = self.read_input_images(input_dir_A)
+        self.files_B = self.read_input_images(input_dir_B)
+
+        bs = min(len(self.files_A), len(self.files_B)) 
+
+        self.images_A = self.get_image_data(self.files_A, bs)
+        self.images_B = self.get_image_data(self.files_B, bs)
+
+    def read_input_images(self, input_dir):
+        if not os.path.isdir(input_dir):
+            print('Error: {} does not exist'.format(input_dir))
+            exit(1)
+
+        if not os.listdir(input_dir):
+            print('Error: {} contains no images'.format(input_dir))
+            exit(1)
+
+        return get_image_paths(input_dir)
+
+    def get_image_data(self, input_images, batch_size):
+        random_transform_args = {
+            'rotation_range': 0,
+            'zoom_range': 0,
+            'shift_range': 0,
+            'random_flip': 0
+        }
+
+        zoom = self.trainer.model.IMAGE_SHAPE[0] // 64 if hasattr(self.trainer.model, 'IMAGE_SHAPE') else 1
+
+        generator = lib.training_data.TrainingDataGenerator(random_transform_args, 160, zoom)
+        batch = generator.minibatchAB(input_images, batch_size, doShuffle=False)
+
+        return next(batch)[2]
+
+    def work(self):
+        image = self.trainer.show_sample(self.images_A, self.images_B)
+        cv2.imwrite(os.path.join(self.output_dir, str(int(time())) + ".png"), image)
\ No newline at end of file
diff --git a/scripts/train.py b/scripts/train.py
index c44de33..7942b57 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -9,7 +9,7 @@ import cv2
 import tensorflow as tf
 from keras.backend.tensorflow_backend import set_session
 
-from lib.utils import get_folder, get_image_paths, set_system_verbosity
+from lib.utils import get_folder, get_image_paths, set_system_verbosity, Timelapse
 from plugins.PluginLoader import PluginLoader
 
 
@@ -26,6 +26,7 @@ class Train(object):
         # this is so that you can enter case insensitive values for trainer
         trainer_name = self.args.trainer
         self.trainer_name = "LowMem" if trainer_name.lower() == "lowmem" else trainer_name
+        self.timelapse = None
 
     def process(self):
         """ Call the training process object """
@@ -86,6 +87,11 @@ class Train(object):
             model = self.load_model()
             trainer = self.load_trainer(model)
 
+            self.timelapse = Timelapse.CreateTimelapse(self.args.timelapse_input_A,
+                                                       self.args.timelapse_input_B,
+                                                       self.args.timelapse_output,
+                                                       trainer)
+
             self.run_training_cycle(model, trainer)
         except KeyboardInterrupt:
             try:
@@ -121,6 +127,8 @@ class Train(object):
         for iteration in range(0, self.args.iterations):
             save_iteration = iteration % self.args.save_interval == 0
             viewer = self.show if save_iteration or self.save_now else None
+            if save_iteration and self.timelapse is not None:
+                self.timelapse.work()
             trainer.train_one_step(iteration, viewer)
             if self.stop:
                 break
