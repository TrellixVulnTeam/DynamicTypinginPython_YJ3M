commit b49c352e8f06667d42ffed5b630b890fd1c03184
Author: kvrooman <vrooman.kyle@gmail.com>
Date:   Wed Nov 13 06:17:59 2019 -0600

    # pylint:disable=no-member cleanup (#927)
    
    # pylint:disable=no-member cleanup

diff --git a/lib/model/session.py b/lib/model/session.py
index 6ddb3f6..35586ad 100644
--- a/lib/model/session.py
+++ b/lib/model/session.py
@@ -111,7 +111,7 @@ class KSession():
         self.graph = tf.Graph()
         config = tf.ConfigProto()
         if allow_growth and get_backend() == "nvidia":
-            config.gpu_options.allow_growth = True  # pylint:disable=no-member
+            config.gpu_options.allow_growth = True
         try:
             session = tf.Session(graph=tf.Graph(), config=config)
         except tf_error.InternalError as err:
diff --git a/lib/vgg_face.py b/lib/vgg_face.py
index ed92fc8..be917db 100644
--- a/lib/vgg_face.py
+++ b/lib/vgg_face.py
@@ -40,7 +40,7 @@ class VGGFace():
         root_path = os.path.abspath(os.path.dirname(sys.argv[0]))
         cache_path = os.path.join(root_path, "plugins", "extract", "recognition", ".cache")
         model = GetModel(model_filename, cache_path, git_model_id).model_path
-        model = cv2.dnn.readNetFromCaffe(model[1], model[0])  # pylint: disable=no-member
+        model = cv2.dnn.readNetFromCaffe(model[1], model[0])
         model.setPreferableTarget(self.get_backend(backend))
         return model
 
@@ -50,14 +50,14 @@ class VGGFace():
         if backend == "OPENCL":
             logger.info("Using OpenCL backend. If the process runs, you can safely ignore any of "
                         "the failure messages.")
-        retval = getattr(cv2.dnn, "DNN_TARGET_{}".format(backend))  # pylint: disable=no-member
+        retval = getattr(cv2.dnn, "DNN_TARGET_{}".format(backend))
         return retval
 
     def predict(self, face):
         """ Return encodings for given image from vgg_face """
         if face.shape[0] != self.input_size:
             face = self.resize_face(face)
-        blob = cv2.dnn.blobFromImage(face[..., :3],  # pylint: disable=no-member
+        blob = cv2.dnn.blobFromImage(face[..., :3],
                                      1.0,
                                      (self.input_size, self.input_size),
                                      self.average_img,
@@ -69,14 +69,9 @@ class VGGFace():
 
     def resize_face(self, face):
         """ Resize incoming face to model_input_size """
-        if face.shape[0] < self.input_size:
-            interpolation = cv2.INTER_CUBIC  # pylint:disable=no-member
-        else:
-            interpolation = cv2.INTER_AREA  # pylint:disable=no-member
-
-        face = cv2.resize(face,  # pylint:disable=no-member
-                          dsize=(self.input_size, self.input_size),
-                          interpolation=interpolation)
+        sizes = (self.input_size, self.input_size)
+        interpolation = cv2.INTER_CUBIC if face.shape[0] < self.input_size else cv2.INTER_AREA
+        face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
         return face
 
     @staticmethod
diff --git a/lib/vgg_face2_keras.py b/lib/vgg_face2_keras.py
index d66cf99..0f65e3e 100644
--- a/lib/vgg_face2_keras.py
+++ b/lib/vgg_face2_keras.py
@@ -69,14 +69,9 @@ class VGGFace2():
 
     def resize_face(self, face):
         """ Resize incoming face to model_input_size """
-        if face.shape[0] < self.input_size:
-            interpolation = cv2.INTER_CUBIC  # pylint:disable=no-member
-        else:
-            interpolation = cv2.INTER_AREA  # pylint:disable=no-member
-
-        face = cv2.resize(face,  # pylint:disable=no-member
-                          dsize=(self.input_size, self.input_size),
-                          interpolation=interpolation)
+        sizes = (self.input_size, self.input_size)
+        interpolation = cv2.INTER_CUBIC if face.shape[0] < self.input_size else cv2.INTER_AREA
+        face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
         return face
 
     @staticmethod
diff --git a/plugins/extract/align/cv2_dnn.py b/plugins/extract/align/cv2_dnn.py
index a28321b..c9308c1 100644
--- a/plugins/extract/align/cv2_dnn.py
+++ b/plugins/extract/align/cv2_dnn.py
@@ -59,6 +59,7 @@ class Align(Aligner):
     def align_image(self, detected_faces):
         """ Align the incoming image for prediction """
         logger.trace("Aligning image around center")
+        sizes = (self.input_size, self.input_size)
         rois = []
         faces = []
         for face in detected_faces:
@@ -76,14 +77,8 @@ class Align(Aligner):
             image = self.pad_image(roi, face.image)
             face = image[roi[1]: roi[3], roi[0]: roi[2]]
 
-            if face.shape[0] < self.input_size:
-                interpolation = cv2.INTER_CUBIC  # pylint:disable=no-member
-            else:
-                interpolation = cv2.INTER_AREA  # pylint:disable=no-member
-
-            face = cv2.resize(face,  # pylint:disable=no-member
-                              dsize=(int(self.input_size), int(self.input_size)),
-                              interpolation=interpolation)
+            interpolation = cv2.INTER_CUBIC if face.shape[0] < self.input_size else cv2.INTER_AREA
+            face = cv2.resize(face, dsize=sizes, interpolation=interpolation)
             faces.append(face)
             rois.append(roi)
         return faces, rois
@@ -127,11 +122,13 @@ class Align(Aligner):
 
         # Shift the box if any points fall below zero
         if left < 0:
-            right += abs(left)
-            left += abs(left)
+            shift_right = abs(left)
+            right += shift_right
+            left += shift_right
         if top < 0:
-            bottom += abs(top)
-            top += abs(top)
+            shift_down = abs(top)
+            bottom += shift_down
+            top += shift_down
 
         # Make sure box is always square.
         assert ((right - left) == (bottom - top)), 'Box is not square.'
@@ -147,12 +144,12 @@ class Align(Aligner):
         pad_r = box[2] - width if box[2] > width else 0
         pad_b = box[3] - height if box[3] > height else 0
         logger.trace("Padding: (l: %s, t: %s, r: %s, b: %s)", pad_l, pad_t, pad_r, pad_b)
-        retval = cv2.copyMakeBorder(image.copy(),  # pylint: disable=no-member
+        retval = cv2.copyMakeBorder(image.copy(),
                                     pad_t,
                                     pad_b,
                                     pad_l,
                                     pad_r,
-                                    cv2.BORDER_CONSTANT,  # pylint: disable=no-member
+                                    cv2.BORDER_CONSTANT,
                                     value=(0, 0, 0))
         logger.trace("Padded shape: %s", retval.shape)
         return retval
@@ -173,8 +170,7 @@ class Align(Aligner):
     def get_pts_from_predict(batch):
         """ Get points from predictor """
         for prediction, roi in zip(batch["prediction"], batch["roi"]):
-            points = np.array(prediction).flatten()
-            points = np.reshape(points, (-1, 2))
+            points = np.reshape(prediction, (-1, 2))
             points *= (roi[2] - roi[0])
             points[:, 0] += roi[0]
             points[:, 1] += roi[1]
diff --git a/plugins/extract/detect/_base.py b/plugins/extract/detect/_base.py
index b68a885..0a2fb72 100644
--- a/plugins/extract/detect/_base.py
+++ b/plugins/extract/detect/_base.py
@@ -254,13 +254,13 @@ class Detector(Extractor):
     @staticmethod
     def _scale_image(image, image_size, scale):
         """ Scale the image and optional pad to given size """
-        interpln = cv2.INTER_CUBIC if scale > 1.0 else cv2.INTER_AREA  # pylint:disable=no-member
+        interpln = cv2.INTER_CUBIC if scale > 1.0 else cv2.INTER_AREA
         if scale != 1.0:
             dims = (int(image_size[1] * scale), int(image_size[0] * scale))
             logger.trace("Resizing detection image from %s to %s. Scale=%s",
                          "x".join(str(i) for i in reversed(image_size)),
                          "x".join(str(i) for i in dims), scale)
-            image = cv2.resize(image, dims, interpolation=interpln)  # pylint:disable=no-member
+            image = cv2.resize(image, dims, interpolation=interpln)
         logger.trace("Resized image shape: %s", image.shape)
         return image
 
@@ -272,12 +272,12 @@ class Detector(Extractor):
             pad_r = (self.input_size - width) - pad_l
             pad_t = (self.input_size - height) // 2
             pad_b = (self.input_size - height) - pad_t
-            image = cv2.copyMakeBorder(image,  # pylint:disable=no-member
+            image = cv2.copyMakeBorder(image,
                                        pad_t,
                                        pad_b,
                                        pad_l,
                                        pad_r,
-                                       cv2.BORDER_CONSTANT)  # pylint:disable=no-member
+                                       cv2.BORDER_CONSTANT)
         logger.trace("Padded image shape: %s", image.shape)
         return image
 
@@ -416,14 +416,11 @@ class Detector(Extractor):
 
         height, width = image.shape[:2]
         image_center = (width/2, height/2)
-        rotation_matrix = cv2.getRotationMatrix2D(  # pylint: disable=no-member
-            image_center, -1.*angle, 1.)
+        rotation_matrix = cv2.getRotationMatrix2D(image_center, -1.*angle, 1.)
         rotation_matrix[0, 2] += self.input_size / 2 - image_center[0]
         rotation_matrix[1, 2] += self.input_size / 2 - image_center[1]
         logger.trace("Rotated image: (rotation_matrix: %s", rotation_matrix)
-        image = cv2.warpAffine(image,  # pylint: disable=no-member
-                               rotation_matrix,
-                               (self.input_size, self.input_size))
+        image = cv2.warpAffine(image, rotation_matrix, (self.input_size, self.input_size))
         if channels_first:
             image = np.moveaxis(image, 2, 0)
 
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index 230d6ca..e60340c 100644
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -247,8 +247,7 @@ class MTCNN():
             rwidth, rheight = int(width * scale), int(height * scale)
             batch = np.empty((batch_items, rheight, rwidth, 3), dtype="float32")
             for idx in range(batch_items):
-                batch[idx, ...] = cv2.resize(images[idx, ...],  # pylint:disable=no-member
-                                             (rwidth, rheight))
+                batch[idx, ...] = cv2.resize(images[idx, ...], (rwidth, rheight))
             output = self.pnet.predict(batch)
             cls_prob = output[0][..., 1]
             roi = output[1]
@@ -281,7 +280,7 @@ class MTCNN():
             predict_24_batch = []
             for rect in rectangles:
                 crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
-                scale_img = cv2.resize(crop_img, (24, 24))  # pylint:disable=no-member
+                scale_img = cv2.resize(crop_img, (24, 24))
                 predict_24_batch.append(scale_img)
                 crop_number += 1
             predict_24_batch = np.array(predict_24_batch)
@@ -308,7 +307,7 @@ class MTCNN():
             predict_batch = []
             for rect in rectangles:
                 crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
-                scale_img = cv2.resize(crop_img, (48, 48))  # pylint:disable=no-member
+                scale_img = cv2.resize(crop_img, (48, 48))
                 predict_batch.append(scale_img)
                 crop_number += 1
             predict_batch = np.array(predict_batch)
diff --git a/tools/preview.py b/tools/preview.py
index 87595c0..5c33d0f 100644
--- a/tools/preview.py
+++ b/tools/preview.py
@@ -408,7 +408,7 @@ class FacesDisplay():
         self.build_faces_image()
         img = np.vstack((self.faces_source, self.faces_dest))
         size = self.get_scale_size(img)
-        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # pylint:disable=no-member
+        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
         img = Image.fromarray(img)
         img = img.resize(size, Image.ANTIALIAS)
         self.tk_image = ImageTk.PhotoImage(img)
@@ -488,9 +488,9 @@ class FacesDisplay():
         """ Create header text for output image """
         font_scale = self.size / 640
         height = self.size // 8
-        font = cv2.FONT_HERSHEY_SIMPLEX  # pylint: disable=no-member
+        font = cv2.FONT_HERSHEY_SIMPLEX
         # Get size of placed text for positioning
-        text_sizes = [cv2.getTextSize(self.faces["filenames"][idx],  # pylint: disable=no-member
+        text_sizes = [cv2.getTextSize(self.faces["filenames"][idx],
                                       font,
                                       font_scale,
                                       1)[0]
@@ -503,24 +503,20 @@ class FacesDisplay():
                      self.faces["filenames"], text_sizes, text_x, text_y)
         header_box = np.ones((height, self.size * self.total_columns, 3), np.uint8) * 255
         for idx, text in enumerate(self.faces["filenames"]):
-            cv2.putText(header_box,  # pylint: disable=no-member
+            cv2.putText(header_box,
                         text,
                         (text_x[idx], text_y),
                         font,
                         font_scale,
                         (0, 0, 0),
                         1,
-                        lineType=cv2.LINE_AA)  # pylint: disable=no-member
+                        lineType=cv2.LINE_AA)
         logger.debug("header_box.shape: %s", header_box.shape)
         return header_box
 
     def draw_rect(self, image):
         """ draw border """
-        cv2.rectangle(image,    # pylint:disable=no-member
-                      (0, 0),
-                      (self.size - 1, self.size - 1),
-                      (255, 255, 255),
-                      1)
+        cv2.rectangle(image, (0, 0), (self.size - 1, self.size - 1), (255, 255, 255), 1)
         image = np.clip(image, 0.0, 255.0)
         return image.astype("uint8")
 
