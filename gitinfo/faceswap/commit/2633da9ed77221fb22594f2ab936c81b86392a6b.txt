commit 2633da9ed77221fb22594f2ab936c81b86392a6b
Author: Gareth Dunstone <gdunstone@users.noreply.github.com>
Date:   Fri Feb 2 03:11:26 2018 +1100

    frame-range changes (#92)
    
    * extended arguments for convert re https://github.com/deepfakes/faceswap/issues/85
    
    * forgot to change helptext for extended arguments.
    
    * Added -fr --frame-range argument to convert
    
    accepts a list of frame ranges like `-fr 40-50 90-100`
    
    still writes out frames that havent been converted.
    
    * added --discard-frames argument
    
    --discard-frames discards frames not included in --frame-range instead
    of writing them out unchanged.
    
    * Made training message slightly clearer
    
    * Revert "Made training message slightly clearer"
    
    This reverts commit 25a9744aea444a67a4825ec86d06357b31a43c9d.
    
    * Training status now '\r's rather than newlines.
    Maybe its good, maybe its bad.
    I like it.
    
    * fixing https://github.com/deepfakes/faceswap/pull/90#issuecomment-362309166

diff --git a/lib/ModelAE.py b/lib/ModelAE.py
index 8f2febb..2dd6f90 100644
--- a/lib/ModelAE.py
+++ b/lib/ModelAE.py
@@ -52,7 +52,8 @@ class TrainerAE():
 
         loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
         loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
-        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B))
+        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B),
+            end='\r')
 
         if viewer is not None:
             viewer(self.show_sample(target_A[0:14], target_B[0:14]), "training")
diff --git a/scripts/convert.py b/scripts/convert.py
index 6c0333f..a9af640 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -89,13 +89,13 @@ class ConvertImage(DirectoryProcessor):
                             help="Average color adjust. (Adjust converter only)")
 
         return parser
-
+    
     def process(self):
         # Original model goes with Adjust or Masked converter
         # does the LowMem one work with only one?
         model_name = "Original" # TODO Pass as argument
         conv_name = self.arguments.converter
-
+        
         model = PluginLoader.get_model(model_name)(self.arguments.model_dir)
         if not model.load(self.arguments.swap_model):
             print('Model Not Found! A valid model must be provided to continue!')
@@ -128,25 +128,23 @@ class ConvertImage(DirectoryProcessor):
         for item in batch.iterator():
             self.convert(converter, item)
 
+
+    def check_skip(self, filename):
+        idx = int(self.imageidxre.findall(filename)[0])
+        return not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
+
     def convert(self, converter, item):
         try:
             (filename, image, faces) = item
-            skip = False
-            try:
-                if self.frame_ranges is not None:
-                    # grab the index with last number regex
-                    idx = int(self.imageidxre.findall(filename)[0])
-                    # only skip if the current index is not between any of the frame ranges.
-                    skip = not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
-            except:
-                # if we error, dont skip
-                skip = False
+
+            skip = self.check_skip(filename)
 
             if not skip: # process as normal
                 for idx, face in faces:
                     image = converter.patch_image(image, face)
 
             output_file = self.output_dir / Path(filename).name
+
             if self.arguments.discard_frames and skip:
                 return
             cv2.imwrite(str(output_file), image)
