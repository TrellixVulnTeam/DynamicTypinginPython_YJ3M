commit 5741160bb776ad191a9a7c1b0bfc9ba06683b0cf
Author: iperov <lepersorium@gmail.com>
Date:   Sat Mar 24 20:06:53 2018 +0400

    sorttool - fixes, and added --sort-by face-yaw (#312)

diff --git a/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py b/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py
index 4546ba7..9691c21 100644
--- a/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py
+++ b/lib/FaceLandmarksExtractor/FaceLandmarksExtractor.py
@@ -135,23 +135,27 @@ def initialize(detector, scale_to=2048):
         is_initialized = True
 
 #scale_to=2048 with dlib upsamples=0 for 3GB VRAM Windows 10 users        
-def extract(input_image, detector, verbose, all_faces=True, scale_to=2048):
+def extract(input_image, detector, verbose, all_faces=True, input_is_predetected_face=False, scale_to=2048):
     initialize(detector, scale_to)
     global dlib_detectors
     global keras_model
     
     (h, w, ch) = input_image.shape
 
-    input_scale = scale_to / (w if w > h else h)
-    input_image = cv2.resize (input_image, ( int(w*input_scale), int(h*input_scale) ), interpolation=cv2.INTER_LINEAR)
-    input_image_bgr = input_image[:,:,::-1].copy() #cv2 and numpy inputs differs in rgb-bgr order, this affects chance of dlib face detection
-    input_images = [input_image, input_image_bgr]
- 
     detected_faces = []
-    for current_detector, input_image in ((current_detector, input_image) for current_detector in dlib_detectors for input_image in input_images):
-        detected_faces = current_detector(input_image, 0)
-        if len(detected_faces) != 0:
-            break
+    
+    if input_is_predetected_face:
+        input_scale = 1.0
+        detected_faces = [ dlib.rectangle(0, 0, w, h) ]
+    else:
+        input_scale = scale_to / (w if w > h else h)
+        input_image = cv2.resize (input_image, ( int(w*input_scale), int(h*input_scale) ), interpolation=cv2.INTER_LINEAR)
+        input_image_bgr = input_image[:,:,::-1].copy() #cv2 and numpy inputs differs in rgb-bgr order, this affects chance of dlib face detection
+        input_images = [input_image, input_image_bgr]
+        for current_detector, input_image in ((current_detector, input_image) for current_detector in dlib_detectors for input_image in input_images):
+            detected_faces = current_detector(input_image, 0)
+            if len(detected_faces) != 0:
+                break           
 
     landmarks = []
     if len(detected_faces) > 0:        
diff --git a/tools/sort.py b/tools/sort.py
index 7c20f48..2024baa 100644
--- a/tools/sort.py
+++ b/tools/sort.py
@@ -126,7 +126,7 @@ class SortProcessor(object):
         parser.add_argument('-s', '--sort-by',
                             type=str,
                             choices=("blur", "face", "face-cnn",
-                                     "face-cnn-dissim", "face-dissim", "hist",
+                                     "face-cnn-dissim", "face-dissim", "face-yaw", "hist",
                                      "hist-dissim"),
                             dest='sort_method',
                             default="hist",
@@ -292,7 +292,7 @@ class SortProcessor(object):
 
         img_list = []
         for x in tqdm( self.find_images(input_dir), desc="Loading", file=sys.stdout):
-            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True)
+            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True, input_is_predetected_face=True)
             img_list.append( [x, np.array(d[0][1]) if len(d) > 0 else np.zeros ( (68,2) ) ] )
 
         img_list_len = len(img_list)
@@ -321,7 +321,7 @@ class SortProcessor(object):
 
         img_list = []
         for x in tqdm( self.find_images(input_dir), desc="Loading", file=sys.stdout):
-            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True)
+            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True, input_is_predetected_face=True)
             img_list.append( [x, np.array(d[0][1]) if len(d) > 0 else np.zeros ( (68,2) ), 0 ] )
 
         img_list_len = len(img_list)
@@ -340,7 +340,30 @@ class SortProcessor(object):
         img_list = sorted(img_list, key=operator.itemgetter(2), reverse=True)
 
         return img_list
+        
+    def sort_face_yaw(self):
+        def calc_landmarks_face_pitch(fl): #unused
+            t = ( (fl[6][1]-fl[8][1]) + (fl[10][1]-fl[8][1]) ) / 2.0   
+            b = fl[8][1]
+            return b-t
+        def calc_landmarks_face_yaw(fl):
+            l = ( (fl[27][0]-fl[0][0]) + (fl[28][0]-fl[1][0]) + (fl[29][0]-fl[2][0]) ) / 3.0   
+            r = ( (fl[16][0]-fl[27][0]) + (fl[15][0]-fl[28][0]) + (fl[14][0]-fl[29][0]) ) / 3.0
+            return r-l
+            
+        from lib import FaceLandmarksExtractor
+        input_dir = self.arguments.input_dir
+    
+        img_list = []
+        for x in tqdm( self.find_images(input_dir), desc="Loading", file=sys.stdout):
+            d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True, input_is_predetected_face=True)
+            img_list.append( [x, calc_landmarks_face_yaw(np.array(d[0][1])) ] )
 
+        print ("Sorting...")
+        img_list = sorted(img_list, key=operator.itemgetter(1), reverse=True)
+        
+        return img_list
+        
     def sort_hist(self):
         input_dir = self.arguments.input_dir
 
@@ -621,7 +644,7 @@ class SortProcessor(object):
             from lib import FaceLandmarksExtractor
             temp_list = []
             for x in tqdm(self.find_images(input_dir), desc="Reloading", file=sys.stdout):
-                d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True)
+                d = FaceLandmarksExtractor.extract(cv2.imread(x), 'cnn', True, input_is_predetected_face=True)
                 temp_list.append([x, np.array(d[0][1]) if len(d) > 0 else np.zeros((68, 2))])
         elif group_method == 'group_hist':
             temp_list = [[x, cv2.calcHist([cv2.imread(x)], [0], None, [256], [0, 256])] for x in tqdm(self.find_images(input_dir), desc="Reloading", file=sys.stdout)]
