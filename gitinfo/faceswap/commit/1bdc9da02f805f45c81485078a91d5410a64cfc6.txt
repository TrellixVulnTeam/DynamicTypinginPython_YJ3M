commit 1bdc9da02f805f45c81485078a91d5410a64cfc6
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sun Dec 29 23:13:25 2019 +0000

    Smart Masks to Convert (#957)
    
    - scripts.convert - Use Smart Masks for Convert
        * Make on-the-fly conversion an explicit option
    
    - Move BlurMask to lib.faces_detect
    
    - tools.preview - Fix for smart masks
        * Subclass from tk.Tk
        * Options to lib.gui.control_helper
        *variable cleanup
    
    - lib.logger - Demote more tensorflow deprecation messages
    
    - Documentation:
        * lib.faces_detect.BlurMask
        * plugins.convert.mask
        * lib.convert
        * scripts.convert
        * scripts.fsmedia
        * tools.preview

diff --git a/docs/full/lib.convert.rst b/docs/full/lib.convert.rst
new file mode 100644
index 0000000..b5f5c90
--- /dev/null
+++ b/docs/full/lib.convert.rst
@@ -0,0 +1,7 @@
+lib.convert module
+==================
+
+.. automodule:: lib.convert
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/docs/full/lib.gui.rst b/docs/full/lib.gui.rst
index e8d44f6..565b830 100644
--- a/docs/full/lib.gui.rst
+++ b/docs/full/lib.gui.rst
@@ -1,9 +1,6 @@
 lib.gui package
 ===============
 
-Submodules
-----------
-
 .. toctree::
 
    lib.gui.custom_widgets
diff --git a/docs/full/lib.image.rst b/docs/full/lib.image.rst
index 36ba2e5..a9f0e86 100644
--- a/docs/full/lib.image.rst
+++ b/docs/full/lib.image.rst
@@ -1,5 +1,5 @@
 lib.image module
-========================
+================
 
 .. automodule:: lib.image
    :members:
diff --git a/docs/full/lib.model.rst b/docs/full/lib.model.rst
index b75d7a9..c2c18da 100644
--- a/docs/full/lib.model.rst
+++ b/docs/full/lib.model.rst
@@ -1,17 +1,6 @@
 lib.model package
 =================
 
-Submodules
-----------
-
 .. toctree::
 
    lib.model.session
-
-Module contents
----------------
-
-.. automodule:: lib.model
-   :members:
-   :undoc-members:
-   :show-inheritance:
diff --git a/docs/full/lib.rst b/docs/full/lib.rst
index ce60321..a23f652 100644
--- a/docs/full/lib.rst
+++ b/docs/full/lib.rst
@@ -1,23 +1,20 @@
 lib package
 ===========
 
-Subpackages
------------
-
 .. toctree::
 
+   lib.convert
    lib.faces_detect
-   lib.gui
    lib.image
-   lib.model
    lib.serializer
    lib.training_data
    lib.vgg_face2_keras
 
-Module contents
----------------
 
-.. automodule:: lib
-   :members:
-   :undoc-members:
-   :show-inheritance:
+Subpackages
+-----------
+
+.. toctree::
+
+   lib.gui
+   lib.model
diff --git a/docs/full/plugins.convert.mask.rst b/docs/full/plugins.convert.mask.rst
new file mode 100644
index 0000000..b6bc41d
--- /dev/null
+++ b/docs/full/plugins.convert.mask.rst
@@ -0,0 +1,27 @@
+plugins.convert.mask package
+============================
+
+plugins.convert.mask._base module
+---------------------------------
+
+.. automodule:: plugins.convert.mask._base
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
+plugins.convert.mask.box_blend module
+-------------------------------------
+
+.. automodule:: plugins.convert.mask.box_blend
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
+plugins.convert.mask.mask_blend module
+--------------------------------------
+
+.. automodule:: plugins.convert.mask.mask_blend
+   :members:
+   :undoc-members:
+   :show-inheritance:
+
diff --git a/docs/full/plugins.convert.rst b/docs/full/plugins.convert.rst
new file mode 100644
index 0000000..bfdb120
--- /dev/null
+++ b/docs/full/plugins.convert.rst
@@ -0,0 +1,9 @@
+plugins.convert package
+=======================
+
+Subpackages
+-----------
+
+.. toctree::
+
+   plugins.convert.mask
diff --git a/docs/full/plugins.extract._base.rst b/docs/full/plugins.extract._base.rst
index 242ab98..131a5dd 100644
--- a/docs/full/plugins.extract._base.rst
+++ b/docs/full/plugins.extract._base.rst
@@ -1,5 +1,5 @@
 plugins.extract._base module
-===============================
+============================
 
 .. automodule:: plugins.extract._base
    :members:
diff --git a/docs/full/plugins.extract.rst b/docs/full/plugins.extract.rst
index 8c4ea2e..d150f9f 100644
--- a/docs/full/plugins.extract.rst
+++ b/docs/full/plugins.extract.rst
@@ -1,19 +1,10 @@
 plugins.extract package
 =======================
 
-Subpackages
------------
-
 .. toctree::
 
+   plugins.extract._base
    plugins.extract.align._base
    plugins.extract.detect._base
    plugins.extract.mask._base
-
-Submodules
-----------
-
-.. toctree::
-
-   plugins.extract._base
    plugins.extract.pipeline
diff --git a/docs/full/plugins.rst b/docs/full/plugins.rst
index bfaecff..d07e762 100644
--- a/docs/full/plugins.rst
+++ b/docs/full/plugins.rst
@@ -1,6 +1,10 @@
 plugins package
 ===============
 
+.. toctree::
+
+   plugins.plugin_loader
+
 Subpackages
 -----------
 
@@ -9,3 +13,4 @@ Subpackages
    plugins.extract
    plugins.plugin_loader
    plugins.train
+   plugins.convert
diff --git a/docs/full/plugins.train.rst b/docs/full/plugins.train.rst
index 17a8166..5be6a76 100644
--- a/docs/full/plugins.train.rst
+++ b/docs/full/plugins.train.rst
@@ -1,9 +1,6 @@
 plugins.train package
 =====================
 
-Subpackages
------------
-
 .. toctree::
 
    plugins.train.trainer._base
diff --git a/docs/full/scripts.extract.rst b/docs/full/scripts.extract.rst
deleted file mode 100644
index 742f40b..0000000
--- a/docs/full/scripts.extract.rst
+++ /dev/null
@@ -1,7 +0,0 @@
-scripts.extract
-===============
-
-.. automodule:: scripts.extract
-   :members:
-   :undoc-members:
-   :show-inheritance:
diff --git a/docs/full/scripts.rst b/docs/full/scripts.rst
index ebf3c04..0c4c68c 100644
--- a/docs/full/scripts.rst
+++ b/docs/full/scripts.rst
@@ -1,18 +1,30 @@
 scripts package
 ===============
 
-Subpackages
------------
-
-.. toctree::
+scripts.extract module
+----------------------
+.. automodule:: scripts.extract
+   :members:
+   :undoc-members:
+   :show-inheritance:
 
-   scripts.extract
-   scripts.train
+scripts.train module
+--------------------
+.. automodule:: scripts.train
+   :members:
+   :undoc-members:
+   :show-inheritance:
 
-Module contents
----------------
+scripts.convert module
+----------------------
+.. automodule:: scripts.convert
+   :members:
+   :undoc-members:
+   :show-inheritance:
 
-.. automodule:: scripts
+scripts.fsmedia module
+----------------------
+.. automodule:: scripts.fsmedia
    :members:
    :undoc-members:
    :show-inheritance:
diff --git a/docs/full/scripts.train.rst b/docs/full/scripts.train.rst
deleted file mode 100644
index 111f2b3..0000000
--- a/docs/full/scripts.train.rst
+++ /dev/null
@@ -1,7 +0,0 @@
-scripts.train
-=============
-
-.. automodule:: scripts.train
-   :members:
-   :undoc-members:
-   :show-inheritance:
diff --git a/docs/full/tools.mask.rst b/docs/full/tools.mask.rst
deleted file mode 100644
index 5a5d3e0..0000000
--- a/docs/full/tools.mask.rst
+++ /dev/null
@@ -1,7 +0,0 @@
-tools.mask module
-======================================
-
-.. automodule:: tools.mask
-   :members:
-   :undoc-members:
-   :show-inheritance:
diff --git a/docs/full/tools.rst b/docs/full/tools.rst
index 45b22b5..d6a3a58 100644
--- a/docs/full/tools.rst
+++ b/docs/full/tools.rst
@@ -1,17 +1,18 @@
 tools package
 =============
 
-Subpackages
------------
+tools.mask module
+-----------------
 
-.. toctree::
-
-   tools.mask
+.. automodule:: tools.mask
+   :members:
+   :undoc-members:
+   :show-inheritance:
 
-Module contents
----------------
+tools.preview module
+--------------------
 
-.. automodule:: tools
+.. automodule:: tools.preview
    :members:
    :undoc-members:
    :show-inheritance:
diff --git a/lib/alignments.py b/lib/alignments.py
index 3f985b9..1557c39 100644
--- a/lib/alignments.py
+++ b/lib/alignments.py
@@ -160,6 +160,43 @@ class Alignments():
         logger.trace("'%s': %s", frame, retval)
         return retval
 
+    def mask_is_valid(self, mask_type):
+        """ Ensure the given ``mask_type`` is valid for this alignments file.
+
+        Every face in the alignments file must have the given mask type to successfully
+        pass the test.
+
+        Parameters
+        ----------
+        mask_type: str
+            The mask type to check against the current alignments
+
+        Returns
+        -------
+        bool:
+            ``True`` if all faces in the current alignments possess the given ``mask_type``
+            otherwise ``False``
+        """
+        retval = any([(face.get("mask", None) is not None and
+                       face["mask"].get(mask_type, None) is not None)
+                      for faces in self.data.values()
+                      for face in faces])
+        logger.debug(retval)
+        return retval
+
+    @property
+    def mask_summary(self):
+        """ Dict: The mask types and the number of faces which have each type that exist with in
+        the loaded alignments """
+        masks = dict()
+        for faces in self.data.values():
+            for face in faces:
+                if face.get("mask", None) is None:
+                    masks["none"] = masks.get("none", 0) + 1
+                for key in face.get("mask", dict):
+                    masks[key] = masks.get(key, 0) + 1
+        return masks
+
     # << DATA >> #
 
     def get_faces_in_frame(self, frame):
diff --git a/lib/cli.py b/lib/cli.py
index d4d448a..6573f73 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -14,7 +14,6 @@ import textwrap
 from importlib import import_module
 
 from lib.logger import crash_log, log_setup
-from lib.model.masks import get_available_masks, get_default_mask
 from lib.utils import FaceswapError, get_backend, safe_shutdown, set_system_verbosity
 from plugins.plugin_loader import PluginLoader
 
@@ -576,9 +575,7 @@ class ExtractArgs(ExtractConvertArgs):
             "choices": PluginLoader.get_available_extractors("mask", add_none=True),
             "default": "extended",
             "group": "Plugins",
-            "help": "R|Masker to use. NB - masks generated here can be used for training, and "
-                    "converting with the 'predicted' mask. Availability of all masks specified "
-                    "here for convert is coming soon."
+            "help": "R|Masker to use."
                     "\nL|none: Don't use a mask."
                     "\nL|components: Mask designed to provide facial segmentation based on the "
                     "positioning of landmark locations. A convex hull is constructed around the "
@@ -808,23 +805,32 @@ class ConvertArgs(ExtractConvertArgs):
         argument_list.append({
             "opts": ("-M", "--mask-type"),
             "action": Radio,
-            "type": str.lower,
             "dest": "mask_type",
-            "choices": get_available_masks() + ["predicted"],
-            "group": "plugins",
-            "default": "predicted",
-            "help": "R|Mask to use to replace faces. Blending of the masks can be adjusted in "
-                    "'/config/convert.ini' or 'Settings > Configure Convert Plugins':"
-                    "\nL|components: An improved face hull mask using a facehull of 8 facial "
-                    "parts."
-                    "\nL|dfl_full: An improved face hull mask using a facehull of 3 facial parts."
-                    "\nL|extended: Based on components mask. Extends the eyebrow points to "
-                    "further up the forehead. May perform badly on difficult angles."
-                    "\nL|facehull: Face cutout based on landmarks."
-                    "\nL|predicted: The predicted mask generated from the model. If the model was "
-                    "not trained with a mask then this will fallback to "
-                    "'{}'".format(get_default_mask()) +
-                    "\nL|none: Don't use a mask."})
+            "type": str.lower,
+            "choices": PluginLoader.get_available_extractors("mask",
+                                                             add_none=True) + ["predicted"],
+            "default": "extended",
+            "group": "Plugins",
+            "help": "R|Masker to use. NB: The mask you require must exist within the alignments "
+                    "file. You can add additional masks with the Mask Tool."
+                    "\nL|none: Don't use a mask."
+                    "\nL|components: Mask designed to provide facial segmentation based on the "
+                    "positioning of landmark locations. A convex hull is constructed around the "
+                    "exterior of the landmarks to create a mask."
+                    "\nL|extended: Mask designed to provide facial segmentation based on the "
+                    "positioning of landmark locations. A convex hull is constructed around the "
+                    "exterior of the landmarks and the mask is extended upwards onto the forehead."
+                    "\nL|vgg-clear: Mask designed to provide smart segmentation of mostly frontal "
+                    "faces clear of obstructions. Profile faces and obstructions may result in "
+                    "sub-par performance."
+                    "\nL|vgg-obstructed: Mask designed to provide smart segmentation of mostly "
+                    "frontal faces. The mask model has been specifically trained to recognize "
+                    "some facial obstructions (hands and eyeglasses). Profile faces may result in "
+                    "sub-par performance."
+                    "\nL|unet-dfl: Mask designed to provide smart segmentation of mostly frontal "
+                    "faces. The mask model has been trained by community members and will need "
+                    "testing for further description. Profile faces may result in sub-par "
+                    "performance."})
         argument_list.append({
             "opts": ("-sc", "--scaling"),
             "action": Radio,
@@ -967,6 +973,17 @@ class ConvertArgs(ExtractConvertArgs):
             "backend": "nvidia",
             "help": "Sets allow_growth option of Tensorflow to spare memory on some "
                     "configurations."})
+        argument_list.append({
+            "opts": ("-otf", "--on-the-fly"),
+            "action": "store_true",
+            "dest": "on_the_fly",
+            "group": "settings",
+            "default": False,
+            "help": "Enable On-The-Fly Conversion. NOT recommended. You should generate a clean "
+                    "alignments file for your destination video. However, if you wish you can "
+                    "generate the alignments on-the-fly by enabling this option. This will use "
+                    "an inferior extraction pipeline and will lead to substandard results. If an "
+                    "alignments file is found, this option will be ignored."})
         argument_list.append({
             "opts": ("-k", "--keep-unchanged"),
             "action": "store_true",
diff --git a/lib/convert.py b/lib/convert.py
index d292966..157fa53 100644
--- a/lib/convert.py
+++ b/lib/convert.py
@@ -1,7 +1,5 @@
 #!/usr/bin/env python3
-""" Converter for faceswap.py
-    Based on: https://gist.github.com/anonymous/d3815aba83a8f79779451262599b0955
-    found on https://www.reddit.com/r/deepfakes/ """
+""" Converter for Faceswap """
 
 import logging
 
@@ -14,69 +12,132 @@ logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
 class Converter():
-    """ Swap a source face with a target """
-    def __init__(self, output_dir, output_size, output_has_mask,
-                 draw_transparent, pre_encode, arguments, configfile=None):
-        logger.debug("Initializing %s: (output_dir: '%s', output_size: %s,  output_has_mask: %s, "
-                     "draw_transparent: %s, pre_encode: %s, arguments: %s, configfile: %s)",
-                     self.__class__.__name__, output_dir, output_size, output_has_mask,
-                     draw_transparent, pre_encode, arguments, configfile)
-        self.output_dir = output_dir
-        self.draw_transparent = draw_transparent
-        self.writer_pre_encode = pre_encode
-        self.scale = arguments.output_scale / 100
-        self.output_size = output_size
-        self.output_has_mask = output_has_mask
-        self.args = arguments
-        self.configfile = configfile
-        self.adjustments = dict(box=None, mask=None, color=None, seamless=None, scaling=None)
-        self.load_plugins()
+    """ The converter is responsible for swapping the original face(s) in a frame with the output
+    of a trained Faceswap model.
+
+    Parameters
+    ----------
+    output_size: int
+        The size of the face, in pixels, that is output from the Faceswap model
+    coverage_ratio: float
+        The ratio of the training image that was used for training the Faceswap model
+    draw_transparent: bool
+        Whether the final output should be drawn onto a transparent layer rather than the original
+        frame. Only available with certain writer plugins.
+    pre_encode: python function
+        Some writer plugins support the pre-encoding of images prior to saving out. As patching is
+        done in multiple threads, but writing is done in a single thread, it can speed up the
+        process to do any pre-encoding as part of the converter process.
+    arguments: :class:`argparse.Namespace`
+        The arguments that were passed to the convert process as generated from Faceswap's command
+        line arguments
+    configfile: str, optional
+        Optional location of custom configuration ``ini`` file. If ``None`` then use the default
+        config location. Default: ``None``
+    """
+    def __init__(self, output_size, coverage_ratio, draw_transparent, pre_encode,
+                 arguments, configfile=None):
+        logger.debug("Initializing %s: (output_size: %s,  coverage_ratio: %s, draw_transparent: "
+                     "%s, pre_encode: %s, arguments: %s, configfile: %s)", self.__class__.__name__,
+                     output_size, coverage_ratio, draw_transparent, pre_encode, arguments,
+                     configfile)
+        self._output_size = output_size
+        self._coverage_ratio = coverage_ratio
+        self._draw_transparent = draw_transparent
+        self._writer_pre_encode = pre_encode
+        self._args = arguments
+        self._configfile = configfile
+
+        self._scale = arguments.output_scale / 100
+        self._adjustments = dict(box=None, mask=None, color=None, seamless=None, scaling=None)
+
+        self._load_plugins()
         logger.debug("Initialized %s", self.__class__.__name__)
 
+    @property
+    def cli_arguments(self):
+        """:class:`argparse.Namespace`: The command line arguments passed to the convert
+        process """
+        return self._args
+
     def reinitialize(self, config):
-        """ reinitialize converter """
+        """ Reinitialize this :class:`Converter`.
+
+        Called as part of the :mod:`~tools.preview` tool. Resets all adjustments then loads the
+        plugins as specified in the given config.
+
+        Parameters
+        ----------
+        config: :class:`lib.config.FaceswapConfig`
+            Pre-loaded :class:`lib.config.FaceswapConfig`. used over any configuration on disk.
+        """
         logger.debug("Reinitializing converter")
-        self.adjustments = dict(box=None, mask=None, color=None, seamless=None, scaling=None)
-        self.load_plugins(config=config, disable_logging=True)
+        self._adjustments = dict(box=None, mask=None, color=None, seamless=None, scaling=None)
+        self._load_plugins(config=config, disable_logging=True)
         logger.debug("Reinitialized converter")
 
-    def load_plugins(self, config=None, disable_logging=False):
-        """ Load the requested adjustment plugins """
+    def _load_plugins(self, config=None, disable_logging=False):
+        """ Load the requested adjustment plugins.
+
+        Loads the :mod:`plugins.converter` plugins that have been requested for this conversion
+        session.
+
+        Parameters
+        ----------
+        config: :class:`lib.config.FaceswapConfig`, optional
+            Optional pre-loaded :class:`lib.config.FaceswapConfig`. If passed, then this will be
+            used over any configuration on disk. If ``None`` then it is ignored. Default: ``None``
+        disable_logging: bool, optional
+            Plugin loader outputs logging info every time a plugin is loaded. Set to ``True`` to
+            suppress these messages otherwise ``False``. Default: ``False``
+        """
         logger.debug("Loading plugins. config: %s", config)
-        self.adjustments["box"] = PluginLoader.get_converter(
+        self._adjustments["box"] = PluginLoader.get_converter(
             "mask",
             "box_blend",
-            disable_logging=disable_logging)("none",
-                                             self.output_size,
-                                             configfile=self.configfile,
+            disable_logging=disable_logging)(self._output_size,
+                                             configfile=self._configfile,
                                              config=config)
 
-        self.adjustments["mask"] = PluginLoader.get_converter(
+        self._adjustments["mask"] = PluginLoader.get_converter(
             "mask",
             "mask_blend",
-            disable_logging=disable_logging)(self.args.mask_type,
-                                             self.output_size,
-                                             self.output_has_mask,
-                                             configfile=self.configfile,
+            disable_logging=disable_logging)(self._args.mask_type,
+                                             self._output_size,
+                                             self._coverage_ratio,
+                                             configfile=self._configfile,
                                              config=config)
 
-        if self.args.color_adjustment != "none" and self.args.color_adjustment is not None:
-            self.adjustments["color"] = PluginLoader.get_converter(
+        if self._args.color_adjustment != "none" and self._args.color_adjustment is not None:
+            self._adjustments["color"] = PluginLoader.get_converter(
                 "color",
-                self.args.color_adjustment,
-                disable_logging=disable_logging)(configfile=self.configfile, config=config)
+                self._args.color_adjustment,
+                disable_logging=disable_logging)(configfile=self._configfile, config=config)
 
-        if self.args.scaling != "none" and self.args.scaling is not None:
-            self.adjustments["scaling"] = PluginLoader.get_converter(
+        if self._args.scaling != "none" and self._args.scaling is not None:
+            self._adjustments["scaling"] = PluginLoader.get_converter(
                 "scaling",
-                self.args.scaling,
-                disable_logging=disable_logging)(configfile=self.configfile, config=config)
-        logger.debug("Loaded plugins: %s", self.adjustments)
-
-    def process(self, in_queue, out_queue, completion_queue=None):
-        """ Process items from the queue """
-        logger.debug("Starting convert process. (in_queue: %s, out_queue: %s, completion_queue: "
-                     "%s)", in_queue, out_queue, completion_queue)
+                self._args.scaling,
+                disable_logging=disable_logging)(configfile=self._configfile, config=config)
+        logger.debug("Loaded plugins: %s", self._adjustments)
+
+    def process(self, in_queue, out_queue):
+        """ Main convert process.
+
+        Takes items from the in queue, runs the relevant adjustments, patches faces to final frame
+        and outputs patched frame to the out queue.
+
+        Parameters
+        ----------
+        in_queue: :class:`queue.Queue`
+            The output from :class:`scripts.convert.Predictor`. Contains detected faces from the
+            Faceswap model as well as the frame to be patched.
+        out_queue: :class:`queue.Queue`
+            The queue to place patched frames into for writing by one of Faceswap's
+            :mod:`plugins.convert.writer` plugins.
+        """
+        logger.debug("Starting convert process. (in_queue: %s, out_queue: %s)",
+                     in_queue, out_queue)
         while True:
             items = in_queue.get()
             if items == "EOF":
@@ -92,7 +153,7 @@ class Converter():
             for item in items:
                 logger.trace("Patch queue got: '%s'", item["filename"])
                 try:
-                    image = self.patch_image(item)
+                    image = self._patch_image(item)
                 except Exception as err:  # pylint: disable=broad-except
                     # Log error and output original frame
                     logger.error("Failed to convert image: '%s'. Reason: %s",
@@ -104,30 +165,59 @@ class Converter():
                 logger.trace("Out queue put: %s", item["filename"])
                 out_queue.put((item["filename"], image))
         logger.debug("Completed convert process")
-        # Signal that this process has finished
-        if completion_queue is not None:
-            completion_queue.put(1)
 
-    def patch_image(self, predicted):
-        """ Patch the image """
+    def _patch_image(self, predicted):
+        """ Patch a swapped face onto a frame.
+
+        Run selected adjustments and swap the faces in a frame.
+
+        Parameters
+        ----------
+        predicted: dict
+            The output from :class:`scripts.convert.Predictor`.
+
+        Returns
+        -------
+        :class: `numpy.ndarray` or pre-encoded image output
+            The final frame ready for writing by a :mod:`plugins.convert.writer` plugin.
+            Frame is either an array, or the pre-encoded output from the writer's pre-encode
+            function (if it has one)
+
+        """
         logger.trace("Patching image: '%s'", predicted["filename"])
         frame_size = (predicted["image"].shape[1], predicted["image"].shape[0])
-        new_image, background = self.get_new_image(predicted, frame_size)
-        patched_face = self.post_warp_adjustments(background, new_image)
-        patched_face = self.scale_image(patched_face)
+        new_image, background = self._get_new_image(predicted, frame_size)
+        patched_face = self._post_warp_adjustments(background, new_image)
+        patched_face = self._scale_image(patched_face)
         patched_face *= 255.0
-        patched_face = np.rint(
-            patched_face,
-            out=np.empty(patched_face.shape, dtype="uint8"),
-            casting='unsafe'
-        )
-        if self.writer_pre_encode is not None:
-            patched_face = self.writer_pre_encode(patched_face)
+        patched_face = np.rint(patched_face,
+                               out=np.empty(patched_face.shape, dtype="uint8"),
+                               casting='unsafe')
+        if self._writer_pre_encode is not None:
+            patched_face = self._writer_pre_encode(patched_face)
         logger.trace("Patched image: '%s'", predicted["filename"])
         return patched_face
 
-    def get_new_image(self, predicted, frame_size):
-        """ Get the new face from the predictor and apply box manipulations """
+    def _get_new_image(self, predicted, frame_size):
+        """ Get the new face from the predictor and apply pre-warp manipulations.
+
+        Applies any requested adjustments to the raw output of the Faceswap model
+        before transforming the image into the target frame.
+
+        Parameters
+        ----------
+        predicted: dict
+            The output from :class:`scripts.convert.Predictor`.
+        frame_size: tuple
+            The (`width`, `height`) of the final frame in pixels
+
+        Returns
+        -------
+        placeholder:  :class: `numpy.ndarray`
+            The original frame with the swapped faces patched onto it
+        background:  :class: `numpy.ndarray`
+            The original frame
+        """
         logger.trace("Getting: (filename: '%s', faces: %s)",
                      predicted["filename"], len(predicted["swapped_faces"]))
 
@@ -139,19 +229,17 @@ class Converter():
                                            predicted["detected_faces"]):
             predicted_mask = new_face[:, :, -1] if new_face.shape[2] == 4 else None
             new_face = new_face[:, :, :3]
-            src_face = detected_face.reference_face[..., :3] / 255.0
             interpolator = detected_face.reference_interpolators[1]
 
-            new_face = self.pre_warp_adjustments(src_face, new_face, detected_face, predicted_mask)
+            new_face = self._pre_warp_adjustments(new_face, detected_face, predicted_mask)
 
             # Warp face with the mask
-            cv2.warpAffine(  # pylint: disable=no-member
-                new_face,
-                detected_face.reference_matrix,
-                frame_size,
-                placeholder,
-                flags=cv2.WARP_INVERSE_MAP | interpolator,  # pylint: disable=no-member
-                borderMode=cv2.BORDER_TRANSPARENT)  # pylint: disable=no-member
+            cv2.warpAffine(new_face,
+                           detected_face.reference_matrix,
+                           frame_size,
+                           placeholder,
+                           flags=cv2.WARP_INVERSE_MAP | interpolator,
+                           borderMode=cv2.BORDER_TRANSPARENT)
 
         np.clip(placeholder, 0.0, 1.0, out=placeholder)
         logger.trace("Got filename: '%s'. (placeholders: %s)",
@@ -159,43 +247,97 @@ class Converter():
 
         return placeholder, background
 
-    def pre_warp_adjustments(self, old_face, new_face, detected_face, predicted_mask):
-        """ Run the pre-warp adjustments """
-        logger.trace("old_face shape: %s, new_face shape: %s, predicted_mask shape: %s",
-                     old_face.shape, new_face.shape,
+    def _pre_warp_adjustments(self, new_face, detected_face, predicted_mask):
+        """ Run any requested adjustments that can be performed on the raw output from the Faceswap
+        model.
+
+        Any adjustments that can be performed before warping the face into the final frame are
+        performed here.
+
+        Parameters
+        ----------
+        new_face: :class:`numpy.ndarray`
+            The swapped face received from the faceswap model.
+        detected_face: :class:`~lib.faces_detect.DetectedFace`
+            The detected_face object as defined in :class:`scripts.convert.Predictor`
+        predicted_mask: :class:`numpy.ndarray` or ``None``
+            The predicted mask output from the Faceswap model. ``None`` if the model
+            did not learn a mask
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The face output from the Faceswap Model with any requested pre-warp adjustments
+            performed.
+        """
+        logger.trace("new_face shape: %s, predicted_mask shape: %s", new_face.shape,
                      predicted_mask.shape if predicted_mask is not None else None)
-        new_face = self.adjustments["box"].run(new_face)
-        new_face, raw_mask = self.get_image_mask(new_face, detected_face, predicted_mask)
-        if self.adjustments["color"] is not None:
-            new_face = self.adjustments["color"].run(old_face, new_face, raw_mask)
-        if self.adjustments["seamless"] is not None:
-            new_face = self.adjustments["seamless"].run(old_face, new_face, raw_mask)
+        old_face = detected_face.reference_face[..., :3] / 255.0
+        new_face = self._adjustments["box"].run(new_face)
+        new_face, raw_mask = self._get_image_mask(new_face, detected_face, predicted_mask)
+        if self._adjustments["color"] is not None:
+            new_face = self._adjustments["color"].run(old_face, new_face, raw_mask)
+        if self._adjustments["seamless"] is not None:
+            new_face = self._adjustments["seamless"].run(old_face, new_face, raw_mask)
         logger.trace("returning: new_face shape %s", new_face.shape)
         return new_face
 
-    def get_image_mask(self, new_face, detected_face, predicted_mask):
-        """ Get the image mask """
+    def _get_image_mask(self, new_face, detected_face, predicted_mask):
+        """ Return any selected image mask and intersect with any box mask.
+
+        Places the requested mask into the new face's Alpha channel, intersecting with any box
+        mask that has already been applied.
+
+        Parameters
+        ----------
+        new_face: :class:`numpy.ndarray`
+            The swapped face received from the faceswap model, with any box mask applied
+        detected_face: :class:`~lib.faces_detect.DetectedFace`
+            The detected_face object as defined in :class:`scripts.convert.Predictor`
+        predicted_mask: :class:`numpy.ndarray` or ``None``
+            The predicted mask output from the Faceswap model. ``None`` if the model
+            did not learn a mask
+
+        Returns
+        :class:`numpy.ndarray`
+            The swapped face with the requested mask added to the Alpha channel
+        """
         logger.trace("Getting mask. Image shape: %s", new_face.shape)
-        mask, raw_mask = self.adjustments["mask"].run(detected_face, predicted_mask)
+        mask, raw_mask = self._adjustments["mask"].run(detected_face, predicted_mask)
         if new_face.shape[2] == 4:
             logger.trace("Combining mask with alpha channel box mask")
             new_face[:, :, -1] = np.minimum(new_face[:, :, -1], mask.squeeze())
         else:
             logger.trace("Adding mask to alpha channel")
             new_face = np.concatenate((new_face, mask), -1)
-        np.clip(new_face, 0.0, 1.0, out=new_face)
         logger.trace("Got mask. Image shape: %s", new_face.shape)
         return new_face, raw_mask
 
-    def post_warp_adjustments(self, background, new_image):
-        """ Apply fixes to the image after warping """
-        if self.adjustments["scaling"] is not None:
-            new_image = self.adjustments["scaling"].run(new_image)
+    def _post_warp_adjustments(self, background, new_image):
+        """ Perform any requested adjustments to the swapped faces after they have been transformed
+        into the final frame.
+
+        Parameters
+        ----------
+        background: :class:`numpy.ndarray`
+            The original frame
+        new_image: :class:`numpy.ndarray`
+            A blank frame of original frame size with the faces warped onto it
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The final merged and swapped frame with any requested post-warp adjustments applied
+        """
+        if self._adjustments["scaling"] is not None:
+            new_image = self._adjustments["scaling"].run(new_image)
 
-        if self.draw_transparent:
+        if self._draw_transparent:
             frame = new_image
         else:
-            foreground, mask = np.split(new_image, (3, ), axis=-1)
+            foreground, mask = np.split(new_image,  # pylint:disable=unbalanced-tuple-unpacking
+                                        (3, ),
+                                        axis=-1)
             foreground *= mask
             background *= (1.0 - mask)
             background += foreground
@@ -203,15 +345,29 @@ class Converter():
         np.clip(frame, 0.0, 1.0, out=frame)
         return frame
 
-    def scale_image(self, frame):
-        """ Scale the image if requested """
-        if self.scale == 1:
+    def _scale_image(self, frame):
+        """ Scale the final image if requested.
+
+        If output scale has been requested in command line arguments, scale the output
+        otherwise return the final frame.
+
+        Parameters
+        ----------
+        frame: :class:`numpy.ndarray`
+            The final frame with faces swapped
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The final frame scaled by the requested scaling factor
+        """
+        if self._scale == 1:
             return frame
         logger.trace("source frame: %s", frame.shape)
-        interp = cv2.INTER_CUBIC if self.scale > 1 else cv2.INTER_AREA  # pylint: disable=no-member
-        dims = (round((frame.shape[1] / 2 * self.scale) * 2),
-                round((frame.shape[0] / 2 * self.scale) * 2))
-        frame = cv2.resize(frame, dims, interpolation=interp)  # pylint: disable=no-member
+        interp = cv2.INTER_CUBIC if self._scale > 1 else cv2.INTER_AREA
+        dims = (round((frame.shape[1] / 2 * self._scale) * 2),
+                round((frame.shape[0] / 2 * self._scale) * 2))
+        frame = cv2.resize(frame, dims, interpolation=interp)
         logger.trace("resized frame: %s", frame.shape)
         np.clip(frame, 0.0, 1.0, out=frame)
         return frame
diff --git a/lib/faces_detect.py b/lib/faces_detect.py
index e138b1a..ec068c2 100644
--- a/lib/faces_detect.py
+++ b/lib/faces_detect.py
@@ -519,6 +519,7 @@ class Mask():
         self._affine_matrix = None
         self._interpolator = None
 
+        self._blur = dict()
         self._blur_kernel = 0
         self._threshold = 0.0
 
@@ -528,13 +529,16 @@ class Mask():
         and threshold amount applied."""
         dims = (self.stored_size, self.stored_size, 1)
         mask = np.frombuffer(decompress(self._mask), dtype="uint8").reshape(dims)
-        if self._threshold != 0.0 or self._blur_kernel != 0:
+        if self._threshold != 0.0 or self._blur["kernel"] != 0:
             mask = mask.copy()
         if self._threshold != 0.0:
             mask[mask < self._threshold] = 0.0
             mask[mask > 255.0 - self._threshold] = 255.0
-        if self._blur_kernel != 0:
-            mask = cv2.GaussianBlur(mask, (self._blur_kernel, self._blur_kernel), 0)[..., None]
+        if self._blur["kernel"] != 0:
+            mask = BlurMask(self._blur["type"],
+                            mask,
+                            self._blur["kernel"],
+                            passes=self._blur["passes"]).blurred
         logger.trace("mask shape: %s", mask.shape)
         return mask
 
@@ -588,7 +592,8 @@ class Mask():
                            interpolation=cv2.INTER_AREA) * 255.0).astype("uint8")
         self._mask = compress(mask)
 
-    def set_blur_kernel_and_threshold(self, blur_kernel=0, threshold=0):
+    def set_blur_and_threshold(self,
+                               blur_kernel=0, blur_type="gaussian", blur_passes=1, threshold=0):
         """ Set the internal blur kernel and threshold amount for returned masks
 
         Parameters
@@ -597,15 +602,20 @@ class Mask():
             The kernel size, in pixels to apply gaussian blurring to the mask. Set to 0 for no
             blurring. Should be odd, if an even number is passed in (outside of 0) then it is
             rounded up to the next odd number. Default: 0
+        blur_type: ["gaussian", "normalized"], optional
+            The blur type to use. ``gaussian`` or ``normalized`` box filter. Default: ``gaussian``
+        blur_passes: int, optional
+            The number of passed to perform when blurring. Default: 1
         threshold: int, optional
             The threshold amount to minimize/maximize mask values to 0 and 100. Percentage value.
             Default: 0
         """
         logger.trace("blur_kernel: %s, threshold: %s", blur_kernel, threshold)
-        if blur_kernel == 0 or blur_kernel % 2 == 1:
-            self._blur_kernel = blur_kernel
-        else:
-            self._blur_kernel = blur_kernel + 1
+        if blur_type is not None:
+            blur_kernel += 0 if blur_kernel == 0 or blur_kernel % 2 == 1 else 1
+            self._blur["kernel"] = blur_kernel
+            self._blur["type"] = blur_type
+            self._blur["passes"] = blur_passes
         self._threshold = (threshold / 100.0) * 255.0
 
     def _adjust_affine_matrix(self, mask_size, affine_matrix):
@@ -676,3 +686,145 @@ class Mask():
         retval = "_{}".format(dict_key) if dict_key != "stored_size" else dict_key
         logger.trace("dict_key: %s, attribute_name: %s", dict_key, retval)
         return retval
+
+
+class BlurMask():
+    """ Factory class to return the correct blur object for requested blur type.
+
+    Works for square images only. Currently supports Gaussian and Normalized Box Filters.
+
+    Parameters
+    ----------
+    blur_type: ["gaussian", "normalized"]
+        The type of blur to use
+    mask: :class:`numpy.ndarray`
+        The mask to apply the blur to
+    kernel: int or float
+        Either the kernel size (in pixels) or the size of the kernel as a ratio of mask size
+    is_ratio: bool, optional
+        Whether the given :attr:`kernel` parameter is a ratio or not. If ``True`` then the
+        actual kernel size will be calculated from the given ratio and the mask size. If
+        ``False`` then the kernel size will be set directly from the :attr:`kernel` parameter.
+        Default: ``False``
+    passes: int, optional
+        The number of passes to perform when blurring. Default: ``1``
+
+    Example
+    -------
+    >>> print(mask.shape)
+    (128, 128, 1)
+    >>> new_mask = BlurMask("gaussian", mask, 3, is_ratio=False, passes=1).blurred
+    >>> print(new_mask.shape)
+    (128, 128, 1)
+    """
+    def __init__(self, blur_type, mask, kernel, is_ratio=False, passes=1):
+        logger.trace("Initializing %s: (blur_type: '%s', mask_shape: %s, kernel: %s, "
+                     "is_ratio: %s, passes: %s)", self.__class__.__name__, blur_type, mask.shape,
+                     kernel, is_ratio, passes)
+        self._blur_type = blur_type.lower()
+        self._mask = mask
+        self._passes = passes
+        kernel_size = self._get_kernel_size(kernel, is_ratio)
+        self._kernel_size = self._get_kernel_tuple(kernel_size)
+        logger.trace("Initialized %s", self.__class__.__name__)
+
+    @property
+    def blurred(self):
+        """ :class:`numpy.ndarray`: The final mask with blurring applied. """
+        func = self._func_mapping[self._blur_type]
+        kwargs = self._get_kwargs()
+        blurred = self._mask
+        for i in range(self._passes):
+            ksize = int(kwargs["ksize"][0])
+            logger.trace("Pass: %s, kernel_size: %s", i + 1, (ksize, ksize))
+            blurred = func(blurred, **kwargs)
+            ksize = int(round(ksize * self._multipass_factor))
+            kwargs["ksize"] = self._get_kernel_tuple(ksize)
+        blurred = blurred[..., None]
+        logger.trace("Returning blurred mask. Shape: %s", blurred.shape)
+        return blurred
+
+    @property
+    def _multipass_factor(self):
+        """ For multiple passes the kernel must be scaled down. This value is
+            different for box filter and gaussian """
+        factor = dict(gaussian=0.8, normalized=0.5)
+        return factor[self._blur_type]
+
+    @property
+    def _sigma(self):
+        """ int: The Sigma for Gaussian Blur. Returns 0 to force calculation from kernel size. """
+        return 0
+
+    @property
+    def _func_mapping(self):
+        """ dict: :attr:`_blur_type` mapped to cv2 Function name. """
+        return dict(gaussian=cv2.GaussianBlur,  # pylint: disable = no-member
+                    normalized=cv2.blur)  # pylint: disable = no-member
+
+    @property
+    def _kwarg_requirements(self):
+        """ dict: :attr:`_blur_type` mapped to cv2 Function required keyword arguments. """
+        return dict(gaussian=["ksize", "sigmaX"],
+                    normalized=["ksize"])
+
+    @property
+    def _kwarg_mapping(self):
+        """ dict: cv2 function keyword arguments mapped to their parameters. """
+        return dict(ksize=self._kernel_size,
+                    sigmaX=self._sigma)
+
+    def _get_kernel_size(self, kernel, is_ratio):
+        """ Set the kernel size to absolute value.
+
+        If :attr:`is_ratio` is ``True`` then the kernel size is calculated from the given ratio and
+        the :attr:`_mask` size, otherwise the given kernel size is just returned.
+
+        Parameters
+        ----------
+        kernel: int or float
+            Either the kernel size (in pixels) or the size of the kernel as a ratio of mask size
+        is_ratio: bool, optional
+            Whether the given :attr:`kernel` parameter is a ratio or not. If ``True`` then the
+            actual kernel size will be calculated from the given ratio and the mask size. If
+            ``False`` then the kernel size will be set directly from the :attr:`kernel` parameter.
+
+        Returns
+        -------
+        int
+            The size (in pixels) of the blur kernel
+        """
+        if not is_ratio:
+            return kernel
+
+        mask_diameter = np.sqrt(np.sum(self._mask))
+        radius = round(max(1., mask_diameter * kernel / 100.))
+        kernel_size = int(radius * 2 + 1)
+        logger.trace("kernel_size: %s", kernel_size)
+        return kernel_size
+
+    @staticmethod
+    def _get_kernel_tuple(kernel_size):
+        """ Make sure kernel_size is odd and return it as a tuple.
+
+        Parameters
+        ----------
+        kernel_size: int
+            The size in pixels of the blur kernel
+
+        Returns
+        -------
+        tuple
+            The kernel size as a tuple of ('int', 'int')
+        """
+        kernel_size += 1 if kernel_size % 2 == 0 else 0
+        retval = (kernel_size, kernel_size)
+        logger.trace(retval)
+        return retval
+
+    def _get_kwargs(self):
+        """ dict: the valid keyword arguments for the requested :attr:`_blur_type` """
+        retval = {kword: self._kwarg_mapping[kword]
+                  for kword in self._kwarg_requirements[self._blur_type]}
+        logger.trace("BlurMask kwargs: %s", retval)
+        return retval
diff --git a/lib/gui/control_helper.py b/lib/gui/control_helper.py
index 8d1a7d2..f7ad70d 100644
--- a/lib/gui/control_helper.py
+++ b/lib/gui/control_helper.py
@@ -161,7 +161,7 @@ class ControlPanelOption():
 
     @property
     def value(self):
-        """ Return either selected value or default """
+        """ Return either initial value or default """
         val = self._options["initial_value"]
         val = self.default if val is None else val
         return val
@@ -227,6 +227,17 @@ class ControlPanelOption():
         """ Set the tk_var to a new value """
         self.tk_var.set(value)
 
+    def set_initial_value(self, value):
+        """ Set the initial_value to the given value
+
+        Parameters
+        ----------
+        value: varies
+            The value to set the initial value attribute to
+        """
+        logger.debug("Setting inital value for %s to %s", self.name, value)
+        self._options["initial_value"] = value
+
     def get_control(self):
         """ Set the correct control type based on the datatype or for this option """
         if self.choices and self.is_radio:
diff --git a/lib/logger.py b/lib/logger.py
index b567f3c..21e3ef2 100644
--- a/lib/logger.py
+++ b/lib/logger.py
@@ -69,7 +69,7 @@ class FaceswapFormatter(logging.Formatter):
     def rewrite_tf_deprecation(record):
         """ Change TF deprecation messages from WARNING to DEBUG """
         if record.levelno == 30 and (record.funcName == "_tfmw_add_deprecation_warning" or
-                                     record.module == "deprecation"):
+                                     record.module in("deprecation", "deprecation_wrapper")):
             record.levelno = 10
             record.levelname = "DEBUG"
         return record
diff --git a/lib/model/masks.py b/lib/model/masks.py
deleted file mode 100644
index d3693b4..0000000
--- a/lib/model/masks.py
+++ /dev/null
@@ -1,177 +0,0 @@
-#!/usr/bin/env python3
-""" Masks functions for faceswap.py """
-
-import inspect
-import logging
-import sys
-
-import cv2
-import numpy as np
-
-logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
-
-
-def get_available_masks():
-    """ Return a list of the available masks for cli """
-    masks = sorted([name for name, obj in inspect.getmembers(sys.modules[__name__])
-                    if inspect.isclass(obj) and name != "Mask"])
-    masks.append("none")
-    logger.debug(masks)
-    return masks
-
-
-def get_default_mask():
-    """ Set the default mask for cli """
-    masks = get_available_masks()
-    default = "dfl_full"
-    default = default if default in masks else masks[0]
-    logger.debug(default)
-    return default
-
-
-class Mask():
-    """ Parent class for masks
-
-        the output mask will be <mask_type>.mask
-        channels: 1, 3 or 4:
-                    1 - Returns a single channel mask
-                    3 - Returns a 3 channel mask
-                    4 - Returns the original image with the mask in the alpha channel """
-
-    def __init__(self, landmarks, face, channels=4):
-        logger.trace("Initializing %s: (face_shape: %s, channels: %s, landmarks: %s)",
-                     self.__class__.__name__, face.shape, channels, landmarks)
-        self.landmarks = np.rint(landmarks).astype("int32")
-        self.face = face
-        self.dtype = face.dtype
-        self.threshold = 255 if self.dtype == "uint8" else 255.0
-        self.channels = channels
-
-        mask = self.build_mask()
-        self.mask = self.merge_mask(mask)
-        logger.trace("Initialized %s", self.__class__.__name__)
-
-    def build_mask(self):
-        """ Override to build the mask """
-        raise NotImplementedError
-
-    def merge_mask(self, mask):
-        """ Return the mask in requested shape """
-        logger.trace("mask_shape: %s", mask.shape)
-        assert self.channels in (1, 3, 4), "Channels should be 1, 3 or 4"
-        assert mask.shape[2] == 1 and mask.ndim == 3, "Input mask be 3 dimensions with 1 channel"
-
-        if self.channels == 3:
-            retval = np.tile(mask, 3)
-        elif self.channels == 4:
-            retval = np.concatenate((self.face, mask), -1)
-        else:
-            retval = mask
-
-        logger.trace("Final mask shape: %s", retval.shape)
-        return retval
-
-
-class dfl_full(Mask):  # pylint: disable=invalid-name
-    """ DFL facial mask """
-    def build_mask(self):
-        mask = np.zeros(self.face.shape[0:2] + (1, ), dtype=self.dtype)
-
-        nose_ridge = (self.landmarks[27:31], self.landmarks[33:34])
-        jaw = (self.landmarks[0:17],
-               self.landmarks[48:68],
-               self.landmarks[0:1],
-               self.landmarks[8:9],
-               self.landmarks[16:17])
-        eyes = (self.landmarks[17:27],
-                self.landmarks[0:1],
-                self.landmarks[27:28],
-                self.landmarks[16:17],
-                self.landmarks[33:34])
-        parts = [jaw, nose_ridge, eyes]
-
-        for item in parts:
-            merged = np.concatenate(item)
-            cv2.fillConvexPoly(mask, cv2.convexHull(merged), self.threshold)
-        return mask
-
-
-class components(Mask):  # pylint: disable=invalid-name
-    """ Component model mask """
-    def build_mask(self):
-        mask = np.zeros(self.face.shape[0:2] + (1, ), dtype=self.dtype)
-
-        r_jaw = (self.landmarks[0:9], self.landmarks[17:18])
-        l_jaw = (self.landmarks[8:17], self.landmarks[26:27])
-        r_cheek = (self.landmarks[17:20], self.landmarks[8:9])
-        l_cheek = (self.landmarks[24:27], self.landmarks[8:9])
-        nose_ridge = (self.landmarks[19:25], self.landmarks[8:9],)
-        r_eye = (self.landmarks[17:22],
-                 self.landmarks[27:28],
-                 self.landmarks[31:36],
-                 self.landmarks[8:9])
-        l_eye = (self.landmarks[22:27],
-                 self.landmarks[27:28],
-                 self.landmarks[31:36],
-                 self.landmarks[8:9])
-        nose = (self.landmarks[27:31], self.landmarks[31:36])
-        parts = [r_jaw, l_jaw, r_cheek, l_cheek, nose_ridge, r_eye, l_eye, nose]
-
-        for item in parts:
-            merged = np.concatenate(item)
-            cv2.fillConvexPoly(mask, cv2.convexHull(merged), self.threshold)
-        return mask
-
-
-class extended(Mask):  # pylint: disable=invalid-name
-    """ Extended mask
-        Based on components mask. Attempts to extend the eyebrow points up the forehead
-    """
-    def build_mask(self):
-        mask = np.zeros(self.face.shape[0:2] + (1, ), dtype=self.dtype)
-
-        landmarks = self.landmarks.copy()
-        # mid points between the side of face and eye point
-        ml_pnt = (landmarks[36] + landmarks[0]) // 2
-        mr_pnt = (landmarks[16] + landmarks[45]) // 2
-
-        # mid points between the mid points and eye
-        ql_pnt = (landmarks[36] + ml_pnt) // 2
-        qr_pnt = (landmarks[45] + mr_pnt) // 2
-
-        # Top of the eye arrays
-        bot_l = np.array((ql_pnt, landmarks[36], landmarks[37], landmarks[38], landmarks[39]))
-        bot_r = np.array((landmarks[42], landmarks[43], landmarks[44], landmarks[45], qr_pnt))
-
-        # Eyebrow arrays
-        top_l = landmarks[17:22]
-        top_r = landmarks[22:27]
-
-        # Adjust eyebrow arrays
-        landmarks[17:22] = top_l + ((top_l - bot_l) // 2)
-        landmarks[22:27] = top_r + ((top_r - bot_r) // 2)
-
-        r_jaw = (landmarks[0:9], landmarks[17:18])
-        l_jaw = (landmarks[8:17], landmarks[26:27])
-        r_cheek = (landmarks[17:20], landmarks[8:9])
-        l_cheek = (landmarks[24:27], landmarks[8:9])
-        nose_ridge = (landmarks[19:25], landmarks[8:9],)
-        r_eye = (landmarks[17:22], landmarks[27:28], landmarks[31:36], landmarks[8:9])
-        l_eye = (landmarks[22:27], landmarks[27:28], landmarks[31:36], landmarks[8:9])
-        nose = (landmarks[27:31], landmarks[31:36])
-        parts = [r_jaw, l_jaw, r_cheek, l_cheek, nose_ridge, r_eye, l_eye, nose]
-
-        for item in parts:
-            merged = np.concatenate(item)
-            cv2.fillConvexPoly(mask, cv2.convexHull(merged), self.threshold)
-        return mask
-
-
-class facehull(Mask):  # pylint: disable=invalid-name
-    """ Basic face hull mask """
-    def build_mask(self):
-        mask = np.zeros(self.face.shape[0:2] + (1, ), dtype=self.dtype)
-        hull = cv2.convexHull(
-            np.array(self.landmarks).reshape((-1, 2)))
-        cv2.fillConvexPoly(mask, hull, self.threshold, lineType=cv2.LINE_AA)
-        return mask
diff --git a/plugins/convert/mask/_base.py b/plugins/convert/mask/_base.py
index 88d38f4..0008dd3 100644
--- a/plugins/convert/mask/_base.py
+++ b/plugins/convert/mask/_base.py
@@ -1,42 +1,105 @@
 #!/usr/bin/env python3
-""" Parent class for mask adjustments for faceswap.py converter """
+""" Base class for Faceswap :mod:`~plugins.convert.mask` Plugins """
 
 import logging
 
-import cv2
 import numpy as np
 
-from lib.model import masks as model_masks
 from plugins.convert._config import Config
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
-def get_config(plugin_name, configfile=None):
-    """ Return the config for the requested model """
+def _get_config(plugin_name, configfile=None):
+    """ Return the :attr:`lib.config.FaceswapConfig.config_dict` for the requested plugin.
+
+    Parameters
+    ----------
+    plugin_name: str
+        The name of the plugin to retrieve the config for
+    configfile: str, optional
+        Optional location of custom configuration ``ini`` file. If ``None`` then use the default
+        config location. Default: ``None``
+
+    Returns
+    -------
+    dict
+        The configuration in dictionary form for the given plugin_name from
+         :attr:`lib.config.FaceswapConfig.config_dict`
+    """
     return Config(plugin_name, configfile=configfile).config_dict
 
 
 class Adjustment():
-    """ Parent class for adjustments """
-    def __init__(self, mask_type, output_size, predicted_available, configfile=None, config=None):
+    """ Parent class for Mask Adjustment Plugins.
+
+    All mask plugins must inherit from this class.
+
+    Parameters
+    ----------
+    mask_type: str
+        The type of mask that this plugin is being used for
+    output_size: int
+        The size, in pixels, of the output from the Faceswap model.
+    configfile: str, Optional
+        Optional location of custom configuration ``ini`` file. If ``None`` then use the default
+        config location. Default: ``None``
+    config: :class:`lib.config.FaceswapConfig`, Optional
+        Optional pre-loaded :class:`lib.config.FaceswapConfig`. If passed, then this will be used
+        over any configuration on disk. If ``None`` then it is ignored. Default: ``None``
+
+
+    Attributes
+    ----------
+    config: dict
+        The configuration dictionary for this plugin.
+    mask_type: str
+        The type of mask that this plugin is being used for.
+    """
+    def __init__(self, mask_type, output_size, configfile=None, config=None):
         logger.debug("Initializing %s: (arguments: '%s', output_size: %s, "
-                     "predicted_available: %s, configfile: %s, config: %s)",
-                     self.__class__.__name__, mask_type, output_size, predicted_available,
-                     configfile, config)
-        self.config = self.set_config(configfile, config)
+                     "configfile: %s, config: %s)", self.__class__.__name__, mask_type,
+                     output_size, configfile, config)
+        self.config = self._set_config(configfile, config)
         logger.debug("config: %s", self.config)
-        self.mask_type = self.get_mask_type(mask_type, predicted_available)
-        self.dummy = np.zeros((output_size, output_size, 3), dtype='float32')
-
-        self.skip = self.config.get("type", None) is None
+        self.mask_type = mask_type
+        self._dummy = np.zeros((output_size, output_size, 3), dtype='float32')
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def set_config(self, configfile, config):
-        """ Set the config to either global config or passed in config """
+    @property
+    def dummy(self):
+        """:class:`numpy.ndarray`: A dummy mask of all zeros of the shape:
+        (:attr:`output_size`, :attr:`output_size`, `3`)
+        """
+        return self._dummy
+
+    @property
+    def skip(self):
+        """bool: ``True`` if the blur type config attribute is ``None`` otherwise ``False`` """
+        return self.config.get("type", None) is None
+
+    def _set_config(self, configfile, config):
+        """ Set the correct configuration for the plugin based on whether a config file
+        or pre-loaded config has been passed in.
+
+        Parameters
+        ----------
+        configfile: str
+            Location of custom configuration ``ini`` file. If ``None`` then use the
+            default config location
+        config: :class:`lib.config.FaceswapConfig`
+            Pre-loaded :class:`lib.config.FaceswapConfig`. If passed, then this will be
+            used over any configuration on disk. If ``None`` then it is ignored.
+
+        Returns
+        -------
+        dict
+            The configuration in dictionary form for the given from
+            :attr:`lib.config.FaceswapConfig.config_dict`
+        """
         section = ".".join(self.__module__.split(".")[-2:])
         if config is None:
-            retval = get_config(section, configfile=configfile)
+            retval = _get_config(section, configfile=configfile)
         else:
             config.section = section
             retval = config.config_dict
@@ -44,20 +107,13 @@ class Adjustment():
         logger.debug("Config: %s", retval)
         return retval
 
-    @staticmethod
-    def get_mask_type(mask_type, predicted_available):
-        """ Return the requested mask type. Return default mask if
-            predicted requested but not available """
-        logger.debug("Requested mask_type: %s", mask_type)
-        if mask_type == "predicted" and not predicted_available:
-            mask_type = model_masks.get_default_mask()
-            logger.warning("Predicted selected, but the model was not trained with a mask. "
-                           "Switching to '%s'", mask_type)
-        logger.debug("Returning mask_type: %s", mask_type)
-        return mask_type
-
     def process(self, *args, **kwargs):
-        """ Override for specific color adjustment process """
+        """ Override for specific mask adjustment plugin processes.
+
+        Input parameters will vary from plugin to plugin.
+
+        Should return a :class:`numpy.ndarray` mask with the plugin's actions applied
+        """
         raise NotImplementedError
 
     def run(self, *args, **kwargs):
@@ -66,95 +122,3 @@ class Adjustment():
                      self.__module__, args, kwargs)
         retval = self.process(*args, **kwargs)
         return retval
-
-
-class BlurMask():
-    """ Factory class to return the correct blur object for requested blur
-        Works for square images only.
-        Currently supports Gaussian and Normalized Box Filters
-    """
-    def __init__(self, blur_type, mask, kernel_ratio, passes=1):
-        """ image_size = height or width of original image
-            mask = the mask to apply the blurring to
-            kernel_ratio = kernel ratio as percentage of mask size
-            diameter = True calculates approx diameter of mask for kernel, False
-            passes = the number of passes to perform the blur """
-        logger.trace("Initializing %s: (blur_type: '%s', mask_shape: %s, kernel_ratio: %s, "
-                     "passes: %s)", self.__class__.__name__, blur_type, mask.shape, kernel_ratio,
-                     passes)
-        self.blur_type = blur_type.lower()
-        self.mask = mask
-        self.passes = passes
-        kernel_size = self.get_kernel_size(kernel_ratio)
-        self.kernel_size = self.get_kernel_tuple(kernel_size)
-        logger.trace("Initialized %s", self.__class__.__name__)
-
-    @property
-    def blurred(self):
-        """ The final blurred mask """
-        func = self.func_mapping[self.blur_type]
-        kwargs = self.get_kwargs()
-        blurred = self.mask
-        for i in range(self.passes):
-            ksize = int(kwargs["ksize"][0])
-            logger.trace("Pass: %s, kernel_size: %s", i + 1, (ksize, ksize))
-            blurred = func(blurred, **kwargs)
-            ksize = int(round(ksize * self.multipass_factor))
-            kwargs["ksize"] = self.get_kernel_tuple(ksize)
-        logger.trace("Returning blurred mask. Shape: %s", blurred.shape)
-        return blurred
-
-    @property
-    def multipass_factor(self):
-        """ Multipass Factor
-            For multiple passes the kernel must be scaled down. This value is
-            different for box filter and gaussian """
-        factor = dict(gaussian=0.8, normalized=0.5)
-        return factor[self.blur_type]
-
-    @property
-    def sigma(self):
-        """ Sigma for Gaussian Blur
-            Returns zero so it is calculated from kernel size """
-        return 0
-
-    @property
-    def func_mapping(self):
-        """ Return a dict of function name to cv2 function """
-        return dict(gaussian=cv2.GaussianBlur,  # pylint: disable = no-member
-                    normalized=cv2.blur)  # pylint: disable = no-member
-
-    @property
-    def kwarg_requirements(self):
-        """ Return a dict of function name to a list of required kwargs """
-        return dict(gaussian=["ksize", "sigmaX"],
-                    normalized=["ksize"])
-
-    @property
-    def kwarg_mapping(self):
-        """ Return a dict of kwarg names to config item names """
-        return dict(ksize=self.kernel_size,
-                    sigmaX=self.sigma)
-
-    def get_kernel_size(self, radius_ratio):
-        """ Set the kernel size to absolute """
-        mask_diameter = np.sqrt(np.sum(self.mask))
-        radius = round(max(1., mask_diameter * radius_ratio / 100.))
-        kernel_size = int(radius * 2 + 1)
-        logger.trace("kernel_size: %s", kernel_size)
-        return kernel_size
-
-    @staticmethod
-    def get_kernel_tuple(kernel_size):
-        """ Make sure kernel_size is odd and return it as a tupe """
-        kernel_size += 1 if kernel_size % 2 == 0 else 0
-        retval = (kernel_size, kernel_size)
-        logger.trace(retval)
-        return retval
-
-    def get_kwargs(self):
-        """ return valid kwargs for the requested blur """
-        retval = {kword: self.kwarg_mapping[kword]
-                  for kword in self.kwarg_requirements[self.blur_type]}
-        logger.trace("BlurMask kwargs: %s", retval)
-        return retval
diff --git a/plugins/convert/mask/box_blend.py b/plugins/convert/mask/box_blend.py
index c1d34f7..a7dd4fb 100644
--- a/plugins/convert/mask/box_blend.py
+++ b/plugins/convert/mask/box_blend.py
@@ -1,26 +1,42 @@
 #!/usr/bin/env python3
-""" Adjustments for the swap box for faceswap.py converter """
+""" Plugin to blend the edges of the face box that comes out of the Faceswap Model into the final
+frame. """
 
 import numpy as np
 
-from ._base import Adjustment, BlurMask, logger
+from lib.faces_detect import BlurMask
+from ._base import Adjustment, logger
 
 
 class Mask(Adjustment):
-    """ Manipulations that occur on the swap box
-        Actions performed here occur prior to warping the face back to the background frame
-
-        For actions that occur identically for each frame (e.g. blend_box), constants can
-        be placed into self.func_constants to be compiled at launch, then referenced for
-        each face. """
-    def __init__(self, mask_type, output_size, predicted_available=False, **kwargs):
-        super().__init__(mask_type, output_size, predicted_available, **kwargs)
-        self.mask = self.get_mask() if not self.skip else None
-
-    def get_mask(self):
-        """ The box for every face will be identical, so set the mask just once
-            As gaussian blur technically blurs both sides of the mask, reduce the mask ratio by
-            half to give a more expected box """
+    """ Manipulations to perform on the edges of the box that is received from the Faceswap model.
+
+    As the size of the box coming out of the model is identical for every face, the mask to be
+    applied is just calculated once (at launch).
+
+    Parameters
+    ----------
+    output_size: int
+        The size of the output from the Faceswap model.
+    **kwargs: dict, optional
+        See the parent :class:`~plugins.convert.mask._base` for additional keyword arguments.
+    """
+    def __init__(self, output_size, **kwargs):
+        super().__init__("none", output_size, **kwargs)
+        self.mask = self._get_mask() if not self.skip else None
+
+    def _get_mask(self):
+        """ Create a mask to be used at the edges of the face box.
+
+        The box for every face will be identical, so the mask is set just once on initialization.
+        As gaussian blur technically blurs both sides of the mask, the mask ratio is reduced by
+        half to give a more expected box.
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The mask to be used at the edges of the box output from the Faceswap model
+        """
         logger.debug("Building box mask")
         mask_ratio = self.config["distance"] / 200
         facesize = self.dummy.shape[0]
@@ -31,18 +47,31 @@ class Mask(Adjustment):
         mask = BlurMask(self.config["type"],
                         mask,
                         self.config["radius"],
-                        self.config["passes"]).blurred
+                        is_ratio=True,
+                        passes=self.config["passes"]).blurred
         logger.debug("Built box mask. Shape: %s", mask.shape)
         return mask
 
-    def process(self, new_face):
-        """ The blend box function. Adds the created mask to the alpha channel """
+    def process(self, new_face):  # pylint:disable=arguments-differ
+        """ Apply the box mask to the swapped face.
+
+        Parameters
+        ----------
+        new_face: :class:`numpy.ndarray`
+            The swapped face that has been output from the Faceswap model
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The input face is returned with the box mask added to the alpha channel if a blur type
+            has been specified in the plugin configuration. If this configuration is set to
+            ``None`` then the input face is returned with no mask applied.
+        """
         if self.skip:
             logger.trace("Skipping blend box")
             return new_face
 
         logger.trace("Blending box")
-        mask = np.expand_dims(self.mask, axis=-1)
-        new_face = np.clip(np.concatenate((new_face, mask), axis=-1), 0.0, 1.0)
+        new_face = np.concatenate((new_face, self.mask), axis=-1)
         logger.trace("Blended box")
         return new_face
diff --git a/plugins/convert/mask/mask_blend.py b/plugins/convert/mask/mask_blend.py
index e626a10..a09d4b6 100644
--- a/plugins/convert/mask/mask_blend.py
+++ b/plugins/convert/mask/mask_blend.py
@@ -1,75 +1,160 @@
 #!/usr/bin/env python3
-""" Adjustments for the mask for faceswap.py converter """
+""" Plugin to blend the edges of the face between the swap and the original face. """
 
 import cv2
 import numpy as np
 
-from lib.model import masks as model_masks
-from ._base import Adjustment, BlurMask, logger
+from ._base import Adjustment, logger
 
 
 class Mask(Adjustment):
-    """ Return the requested mask """
-    def __init__(self, mask_type, output_size, predicted_available, **kwargs):
-        super().__init__(mask_type, output_size, predicted_available, **kwargs)
-        self.do_erode = self.config.get("erosion", 0) != 0
-        self.do_blend = self.config.get("type", None) is not None
-
-    def process(self, detected_face, predicted_mask=None):
-        """ Return mask and perform processing """
-        mask = self.get_mask(detected_face, predicted_mask)
+    """ Manipulations to perform to the mask that is to be applied to the output of the Faceswap
+    model.
+
+    Parameters
+    ----------
+    mask_type: str
+        The mask type to use for this plugin
+    output_size: int
+        The size of the output from the Faceswap model.
+    coverage_ratio: float
+        The coverage ratio that the Faceswap model was trained at.
+    **kwargs: dict, optional
+        See the parent :class:`~plugins.convert.mask._base` for additional keyword arguments.
+    """
+    def __init__(self, mask_type, output_size, coverage_ratio, **kwargs):
+        super().__init__(mask_type, output_size, **kwargs)
+        self._do_erode = self.config.get("erosion", 0) != 0
+        self._coverage_ratio = coverage_ratio
+
+    def process(self, detected_face, predicted_mask=None):  # pylint:disable=arguments-differ
+        """ Obtain the requested mask type and perform any defined mask manipulations.
+
+        Parameters
+        ----------
+        detected_face: :class:`lib.faces_detect.DetectedFace`
+            The DetectedFace object as returned from :class:`scripts.convert.Predictor`.
+        predicted_mask: :class:`numpy.ndarray`, optional
+            The predicted mask as output from the Faceswap Model, if the model was trained
+            with a mask, otherwise ``None``. Default: ``None``.
+
+        Returns
+        -------
+        mask: :class:`numpy.ndarray`
+            The mask with all requested manipulations applied
+        raw_mask: :class:`numpy.ndarray`
+            The mask with no erosion/dilation applied
+        """
+        mask = self._get_mask(detected_face, predicted_mask)
         raw_mask = mask.copy()
-        if not self.skip and self.do_erode:
-            mask = self.erode(mask)
-        if not self.skip and self.do_blend:
-            mask = self.blend(mask)
+        if not self.skip and self._do_erode:
+            mask = self._erode(mask)
         raw_mask = np.expand_dims(raw_mask, axis=-1) if raw_mask.ndim != 3 else raw_mask
         mask = np.expand_dims(mask, axis=-1) if mask.ndim != 3 else mask
         logger.trace("mask shape: %s, raw_mask shape: %s", mask.shape, raw_mask.shape)
-        return mask, raw_mask
+        return mask.astype("float32") / 255.0, raw_mask.astype("float32") / 255.0
+
+    def _get_mask(self, detected_face, predicted_mask):
+        """ Return the requested mask with any requested blurring applied.
 
-    def get_mask(self, detected_face, predicted_mask):
-        """ Return the mask from lib/model/masks and intersect with box """
+        Parameters
+        ----------
+        detected_face: :class:`lib.faces_detect.DetectedFace`
+            The DetectedFace object as returned from :class:`scripts.convert.Predictor`.
+        predicted_mask: :class:`numpy.ndarray`
+            The predicted mask as output from the Faceswap Model if the model was trained
+            with a mask, otherwise ``None``
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The mask sized to Faceswap model output with any requested blurring applied.
+        """
         if self.mask_type == "none":
             # Return a dummy mask if not using a mask
             mask = np.ones_like(self.dummy[:, :, 1])
         elif self.mask_type == "predicted":
             mask = predicted_mask
         else:
-            landmarks = detected_face.reference_landmarks
-            mask = getattr(model_masks, self.mask_type)(landmarks, self.dummy, channels=1).mask
-        np.nan_to_num(mask, copy=False)
-        np.clip(mask, 0.0, 1.0, out=mask)
+            mask = detected_face.mask[self.mask_type]
+            mask.set_blur_and_threshold(blur_kernel=self.config["kernel_size"],
+                                        blur_type=self.config["type"],
+                                        blur_passes=self.config["passes"],
+                                        threshold=self.config["threshold"])
+            mask = self._crop_to_coverage(mask.mask)
+
+            mask_size = mask.shape[0]
+            face_size = self.dummy.shape[0]
+            if mask_size != face_size:
+                interp = cv2.INTER_CUBIC if mask_size < face_size else cv2.INTER_AREA
+                mask = cv2.resize(mask,
+                                  self.dummy.shape[:2],
+                                  interpolation=interp)[..., None]
+        logger.trace(mask.shape)
+        return mask
+
+    def _crop_to_coverage(self, mask):
+        """ Crop the mask to the correct dimensions based on coverage ratio.
+
+        Parameters
+        ----------
+        mask: :class:`numpy.ndarray`
+            The original mask to be cropped
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The cropped mask
+        """
+        if self._coverage_ratio == 1.0:
+            return mask
+        mask_size = mask.shape[0]
+        padding = round((mask_size * (1 - self._coverage_ratio)) / 2)
+        mask_slice = slice(padding, mask_size - padding)
+        mask = mask[mask_slice, mask_slice, :]
+        logger.trace("mask_size: %s, coverage: %s, padding: %s, final shape: %s",
+                     mask_size, self._coverage_ratio, padding, mask.shape)
         return mask
 
     # MASK MANIPULATIONS
-    def erode(self, mask):
-        """ Erode/dilate mask if requested """
-        kernel = self.get_erosion_kernel(mask)
+    def _erode(self, mask):
+        """ Erode or dilate mask the mask based on configuration options.
+
+        Parameters
+        ----------
+        mask: :class:`numpy.ndarray`
+            The mask to be eroded or dilated
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The mask with erosion/dilation applied
+        """
+        kernel = self._get_erosion_kernel(mask)
         if self.config["erosion"] > 0:
             logger.trace("Eroding mask")
-            mask = cv2.erode(mask, kernel, iterations=1)  # pylint: disable=no-member
+            mask = cv2.erode(mask, kernel, iterations=1)
         else:
             logger.trace("Dilating mask")
-            mask = cv2.dilate(mask, kernel, iterations=1)  # pylint: disable=no-member
+            mask = cv2.dilate(mask, kernel, iterations=1)
         return mask
 
-    def get_erosion_kernel(self, mask):
-        """ Get the erosion kernel """
+    def _get_erosion_kernel(self, mask):
+        """ Get the erosion kernel.
+
+        Parameters
+        ----------
+        mask: :class:`numpy.ndarray`
+            The mask to be eroded or dilated
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The erosion kernel to be used for erosion/dilation
+        """
         erosion_ratio = self.config["erosion"] / 100
         mask_radius = np.sqrt(np.sum(mask)) / 2
         kernel_size = max(1, int(abs(erosion_ratio * mask_radius)))
-        erosion_kernel = cv2.getStructuringElement(  # pylint: disable=no-member
-            cv2.MORPH_ELLIPSE,  # pylint: disable=no-member
-            (kernel_size, kernel_size))
+        erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
         logger.trace("erosion_kernel shape: %s", erosion_kernel.shape)
         return erosion_kernel
-
-    def blend(self, mask):
-        """ Blur mask if requested """
-        logger.trace("Blending mask")
-        mask = BlurMask(self.config["type"],
-                        mask,
-                        self.config["radius"],
-                        self.config["passes"]).blurred
-        return mask
diff --git a/plugins/convert/mask/mask_blend_defaults.py b/plugins/convert/mask/mask_blend_defaults.py
index deb2a4b..618060e 100755
--- a/plugins/convert/mask/mask_blend_defaults.py
+++ b/plugins/convert/mask/mask_blend_defaults.py
@@ -59,15 +59,15 @@ _DEFAULTS = {
         "gui_radio": True,
         "fixed": True,
     },
-    "radius": {
-        "default": 3.0,
-        "info": "Radius dictates how much blending should occur.\nThis figure is set as a "
-                "percentage of the mask diameter to give the radius in pixels. Eg: for a mask "
-                "with diameter 200px, a percentage of 6% would give a final radius of 3px.\n"
-                "Higher percentage means more blending.",
-        "datatype": float,
+    "kernel_size": {
+        "default": 3,
+        "info": "The kernel size dictates how much blending should occur.\n"
+                "The size is the diameter of the kernel in pixels (calculated from a 128px mask). "
+                " This value should be odd, if an even number is passed in then it will be "
+                "rounded to the next odd number. Higher sizes means more blending.",
+        "datatype": int,
         "rounding": 1,
-        "min_max": (0.1, 25.0),
+        "min_max": (1, 9),
         "choices": [],
         "gui_radio": False,
         "group": "settings",
@@ -87,6 +87,18 @@ _DEFAULTS = {
         "group": "settings",
         "fixed": True,
     },
+    "threshold": {
+        "default": 4,
+        "info": "Sets pixels that are near white to white and near black to black. Set to 0 for "
+                "off.",
+        "datatype": int,
+        "rounding": 1,
+        "min_max": (0, 50),
+        "choices": [],
+        "gui_radio": False,
+        "group": "settings",
+        "fixed": True,
+    },
     "erosion": {
         "default": 0.0,
         "info": "Erosion kernel size as a percentage of the mask radius area.\nPositive "
diff --git a/plugins/train/trainer/_base.py b/plugins/train/trainer/_base.py
index 60b65c3..5a61edb 100644
--- a/plugins/train/trainer/_base.py
+++ b/plugins/train/trainer/_base.py
@@ -1118,8 +1118,8 @@ class TrainingAlignments():
         masks = dict()
         for fhash, face in detected_faces.items():
             mask = face.mask[self._training_opts["mask_type"]]
-            mask.set_blur_kernel_and_threshold(blur_kernel=self._training_opts["mask_blur_kernel"],
-                                               threshold=self._training_opts["mask_threshold"])
+            mask.set_blur_and_threshold(blur_kernel=self._training_opts["mask_blur_kernel"],
+                                        threshold=self._training_opts["mask_threshold"])
             for filename in self._hash_to_filenames(side, fhash):
                 masks[filename] = mask
         return masks
diff --git a/scripts/convert.py b/scripts/convert.py
index 3affd74..b9cbdff 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -1,5 +1,5 @@
 #!/usr/bin python3
-""" The script to run the convert process of faceswap """
+""" Main entry point to the convert process of FaceSwap """
 
 import logging
 import re
@@ -8,13 +8,13 @@ import sys
 from threading import Event
 from time import sleep
 
-from cv2 import imwrite  # pylint:disable=no-name-in-module
+import cv2
 import numpy as np
 import tensorflow as tf
 from keras.backend.tensorflow_backend import set_session
 from tqdm import tqdm
 
-from scripts.fsmedia import Alignments, Images, PostProcess, Utils
+from scripts.fsmedia import Alignments, Images, PostProcess, finalize
 from lib.serializer import get_serializer
 from lib.convert import Converter
 from lib.faces_detect import DetectedFace
@@ -29,37 +29,54 @@ from plugins.plugin_loader import PluginLoader
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
-class Convert():
-    """ The convert process. """
+class Convert():  # pylint:disable=too-few-public-methods
+    """ The Faceswap Face Conversion Process.
+
+    The conversion process is responsible for swapping the faces on source frames with the output
+    from a trained model.
+
+    It leverages a series of user selected post-processing plugins, executed from
+    :class:`lib.convert.Converter`.
+
+    The convert process is self contained and should not be referenced by any other scripts, so it
+    contains no public properties.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The arguments to be passed to the convert process as generated from Faceswap's command
+        line arguments
+    """
     def __init__(self, arguments):
         logger.debug("Initializing %s: (args: %s)", self.__class__.__name__, arguments)
-        self.args = arguments
-
-        self.patch_threads = None
-        self.images = Images(self.args)
-        self.validate()
-        self.alignments = Alignments(self.args, False, self.images.is_video)
-        self.opts = OptionalActions(self.args, self.images.input_images, self.alignments)
-
-        self.add_queues()
-        self.disk_io = DiskIO(self.alignments, self.images, arguments)
-        self.predictor = Predict(self.disk_io.load_queue, self.queue_size, arguments)
-
-        configfile = self.args.configfile if hasattr(self.args, "configfile") else None
-        self.converter = Converter(get_folder(self.args.output_dir),
-                                   self.predictor.output_size,
-                                   self.predictor.has_predicted_mask,
-                                   self.disk_io.draw_transparent,
-                                   self.disk_io.pre_encode,
-                                   arguments,
-                                   configfile=configfile)
+        self._args = arguments
+
+        self._patch_threads = None
+        self._images = Images(self._args)
+        self._alignments = Alignments(self._args, False, self._images.is_video)
+
+        self._opts = OptionalActions(self._args, self._images.input_images, self._alignments)
+
+        self._add_queues()
+        self._disk_io = DiskIO(self._alignments, self._images, arguments)
+        self._predictor = Predict(self._disk_io.load_queue, self._queue_size, arguments)
+        self._validate()
+        get_folder(self._args.output_dir)
+
+        configfile = self._args.configfile if hasattr(self._args, "configfile") else None
+        self._converter = Converter(self._predictor.output_size,
+                                    self._predictor.coverage_ratio,
+                                    self._disk_io.draw_transparent,
+                                    self._disk_io.pre_encode,
+                                    arguments,
+                                    configfile=configfile)
 
         logger.debug("Initialized %s", self.__class__.__name__)
 
     @property
-    def queue_size(self):
-        """ Set 16 for single process otherwise 32 """
-        if self.args.singleprocess:
+    def _queue_size(self):
+        """ int: Size of the converter queues. 16 for single process otherwise 32 """
+        if self._args.singleprocess:
             retval = 16
         else:
             retval = 32
@@ -67,47 +84,83 @@ class Convert():
         return retval
 
     @property
-    def pool_processes(self):
-        """ return the maximum number of pooled processes to use """
-        if self.args.singleprocess:
+    def _pool_processes(self):
+        """ int: The number of threads to run in parallel. Based on user options and number of
+        available processors. """
+        if self._args.singleprocess:
             retval = 1
-        elif self.args.jobs > 0:
-            retval = min(self.args.jobs, total_cpus(), self.images.images_found)
+        elif self._args.jobs > 0:
+            retval = min(self._args.jobs, total_cpus(), self._images.images_found)
         else:
-            retval = min(total_cpus(), self.images.images_found)
+            retval = min(total_cpus(), self._images.images_found)
         retval = 1 if retval == 0 else retval
         logger.debug(retval)
         return retval
 
-    def validate(self):
-        """ Make the output folder if it doesn't exist and check that video flag is
-            a valid choice """
-        if (self.args.writer == "ffmpeg" and
-                not self.images.is_video and
-                self.args.reference_video is None):
+    def _validate(self):
+        """ Validate the Command Line Options.
+
+        Ensure that certain cli selections are valid and won't result in an error. Checks:
+            * If frames have been passed in with video output, ensure user supplies reference
+            video.
+            * If a mask-type is selected, ensure it exists in the alignments file.
+            * If a predicted mask-type is selected, ensure model has been trained with a mask
+            otherwise attempt to select first available masks, otherwise raise error.
+
+        Raises
+        ------
+        FaceswapError
+            If an invalid selection has been found.
+
+        """
+        if (self._args.writer == "ffmpeg" and
+                not self._images.is_video and
+                self._args.reference_video is None):
             raise FaceswapError("Output as video selected, but using frames as input. You must "
                                 "provide a reference video ('-ref', '--reference-video').")
-        output_dir = get_folder(self.args.output_dir)
-        logger.info("Output Directory: %s", output_dir)
-
-    def add_queues(self):
-        """ Add the queues for convert """
-        logger.debug("Adding queues. Queue size: %s", self.queue_size)
+        if (self._args.mask_type not in ("none", "predicted") and
+                not self._alignments.mask_is_valid(self._args.mask_type)):
+            msg = ("You have selected the Mask Type `{}` but at least one face does not have this "
+                   "mask stored in the Alignments File.\nYou should generate the required masks "
+                   "with the Mask Tool or set the Mask Type option to an existing Mask Type.\nA "
+                   "summary of existing masks is as follows:\nTotal faces: {}, Masks: "
+                   "{}".format(self._args.mask_type, self._alignments.faces_count,
+                               self._alignments.mask_summary))
+            raise FaceswapError(msg)
+        if self._args.mask_type == "predicted" and not self._predictor.has_predicted_mask:
+            available_masks = [k for k, v in self._alignments.mask_summary.items()
+                               if k != "none" and v == self._alignments.faces_count]
+            if not available_masks:
+                msg = ("Predicted Mask selected, but the model was not trained with a mask and no "
+                       "masks are stored in the Alignments File.\nYou should generate the "
+                       "required masks with the Mask Tool or set the Mask Type to `none`.")
+                raise FaceswapError(msg)
+            mask_type = available_masks[0]
+            logger.warning("Predicted Mask selected, but the model was not trained with a "
+                           "mask. Selecting first available mask: '%s'", mask_type)
+            self._args.mask_type = mask_type
+
+    def _add_queues(self):
+        """ Add the queues for in, patch and out. """
+        logger.debug("Adding queues. Queue size: %s", self._queue_size)
         for qname in ("convert_in", "convert_out", "patch"):
-            queue_manager.add_queue(qname, self.queue_size)
+            queue_manager.add_queue(qname, self._queue_size)
 
     def process(self):
-        """ Process the conversion """
+        """ The entry point for triggering the Conversion Process.
+
+        Should only be called from  :class:`lib.cli.ScriptExecutor`
+        """
         logger.debug("Starting Conversion")
         # queue_manager.debug_monitor(5)
         try:
-            self.convert_images()
-            self.disk_io.save_thread.join()
+            self._convert_images()
+            self._disk_io.save_thread.join()
             queue_manager.terminate_queues()
 
-            Utils.finalize(self.images.images_found,
-                           self.predictor.faces_count,
-                           self.predictor.verify_output)
+            finalize(self._images.images_found,
+                     self._predictor.faces_count,
+                     self._predictor.verify_output)
             logger.debug("Completed Conversion")
         except MemoryError as err:
             msg = ("Faceswap ran out of RAM running convert. Conversion is very system RAM "
@@ -117,119 +170,171 @@ class Convert():
                    "'singleprocess' flag (-sp) or lowering the number of parallel jobs (-j).")
             raise FaceswapError(msg) from err
 
-    def convert_images(self):
-        """ Convert the images """
+    def _convert_images(self):
+        """ Start the multi-threaded patching process, monitor all threads for errors and join on
+        completion. """
         logger.debug("Converting images")
         save_queue = queue_manager.get_queue("convert_out")
         patch_queue = queue_manager.get_queue("patch")
-        self.patch_threads = MultiThread(self.converter.process, patch_queue, save_queue,
-                                         thread_count=self.pool_processes, name="patch")
+        self._patch_threads = MultiThread(self._converter.process, patch_queue, save_queue,
+                                          thread_count=self._pool_processes, name="patch")
 
-        self.patch_threads.start()
+        self._patch_threads.start()
         while True:
-            self.check_thread_error()
-            if self.disk_io.completion_event.is_set():
+            self._check_thread_error()
+            if self._disk_io.completion_event.is_set():
                 logger.debug("DiskIO completion event set. Joining Pool")
                 break
-            if self.patch_threads.completed():
+            if self._patch_threads.completed():
                 logger.debug("All patch threads completed")
                 break
             sleep(1)
-        self.patch_threads.join()
+        self._patch_threads.join()
 
         logger.debug("Putting EOF")
         save_queue.put("EOF")
         logger.debug("Converted images")
 
-    def check_thread_error(self):
-        """ Check and raise thread errors """
-        for thread in (self.predictor.thread,
-                       self.disk_io.load_thread,
-                       self.disk_io.save_thread,
-                       self.patch_threads):
+    def _check_thread_error(self):
+        """ Monitor all running threads for errors, and raise accordingly. """
+        for thread in (self._predictor.thread,
+                       self._disk_io.load_thread,
+                       self._disk_io.save_thread,
+                       self._patch_threads):
             thread.check_and_raise_error()
 
 
 class DiskIO():
-    """ Background threads to:
-            Load images from disk and get the detected faces
-            Save images back to disk """
+    """ Disk Input/Output for the converter process.
+
+    Background threads to:
+        * Load images from disk and get the detected faces
+        * Save images back to disk
+
+    Parameters
+    ----------
+    alignments: :class:`lib.alignmnents.Alignments`
+        The alignments for the input video
+    images: :class:`scripts.fsmedia.Images`
+        The input images
+    arguments: :class:`argparse.Namespace`
+        The arguments that were passed to the convert process as generated from Faceswap's command
+        line arguments
+    """
+
     def __init__(self, alignments, images, arguments):
         logger.debug("Initializing %s: (alignments: %s, images: %s, arguments: %s)",
                      self.__class__.__name__, alignments, images, arguments)
-        self.alignments = alignments
-        self.images = images
-        self.args = arguments
-        self.pre_process = PostProcess(arguments)
-        self.completion_event = Event()
+        self._alignments = alignments
+        self._images = images
+        self._args = arguments
+        self._pre_process = PostProcess(arguments)
+        self._completion_event = Event()
 
         # For frame skipping
-        self.imageidxre = re.compile(r"(\d+)(?!.*\d\.)(?=\.\w+$)")
-        self.frame_ranges = self.get_frame_ranges()
-        self.writer = self.get_writer()
+        self._imageidxre = re.compile(r"(\d+)(?!.*\d\.)(?=\.\w+$)")
+        self._frame_ranges = self._get_frame_ranges()
+        self._writer = self._get_writer()
 
         # Extractor for on the fly detection
-        self.extractor = self.load_extractor()
+        self._extractor = self._load_extractor()
 
-        self.load_queue = None
-        self.save_queue = None
-        self.load_thread = None
-        self.save_thread = None
-        self.init_threads()
+        self._queues = dict(load=None, save=None)
+        self._threads = dict(oad=None, save=None)
+        self._init_threads()
         logger.debug("Initialized %s", self.__class__.__name__)
 
+    @property
+    def completion_event(self):
+        """ :class:`event.Event`: Event is set when the DiskIO Save task is complete """
+        return self._completion_event
+
     @property
     def draw_transparent(self):
-        """ Draw transparent is an image writer only parameter.
-            Return the value here for easy access for predictor """
-        return self.writer.config.get("draw_transparent", False)
+        """ bool: ``True`` if the selected writer's Draw_transparent configuration item is set
+        otherwise ``False`` """
+        return self._writer.config.get("draw_transparent", False)
 
     @property
     def pre_encode(self):
-        """ Return the writer's pre-encoder """
+        """ python function: Selected writer's pre-encode function, if it has one,
+        otherwise ``None`` """
         dummy = np.zeros((20, 20, 3), dtype="uint8")
-        test = self.writer.pre_encode(dummy)
-        retval = None if test is None else self.writer.pre_encode
+        test = self._writer.pre_encode(dummy)
+        retval = None if test is None else self._writer.pre_encode
         logger.debug("Writer pre_encode function: %s", retval)
         return retval
 
     @property
-    def total_count(self):
-        """ Return the total number of frames to be converted """
-        if self.frame_ranges and not self.args.keep_unchanged:
-            retval = sum([fr[1] - fr[0] + 1 for fr in self.frame_ranges])
+    def save_thread(self):
+        """ :class:`lib.multithreading.MultiThread`: The thread that is running the image writing
+        operation. """
+        return self._threads["save"]
+
+    @property
+    def load_thread(self):
+        """ :class:`lib.multithreading.MultiThread`: The thread that is running the image loading
+        operation. """
+        return self._threads["load"]
+
+    @property
+    def load_queue(self):
+        """ :class:`queue.Queue()`: The queue that images and detected faces are loaded into. """
+        return self._queues["load"]
+
+    @property
+    def _total_count(self):
+        """ int: The total number of frames to be converted """
+        if self._frame_ranges and not self._args.keep_unchanged:
+            retval = sum([fr[1] - fr[0] + 1 for fr in self._frame_ranges])
         else:
-            retval = self.images.images_found
+            retval = self._images.images_found
         logger.debug(retval)
         return retval
 
     # Initialization
-    def get_writer(self):
-        """ Return the writer plugin """
-        args = [self.args.output_dir]
-        if self.args.writer in ("ffmpeg", "gif"):
-            args.extend([self.total_count, self.frame_ranges])
-        if self.args.writer == "ffmpeg":
-            if self.images.is_video:
-                args.append(self.args.input_dir)
+    def _get_writer(self):
+        """ Load the selected writer plugin.
+
+        Returns
+        -------
+        :mod:`plugins.convert.writer` plugin
+            The requested writer plugin
+        """
+        args = [self._args.output_dir]
+        if self._args.writer in ("ffmpeg", "gif"):
+            args.extend([self._total_count, self._frame_ranges])
+        if self._args.writer == "ffmpeg":
+            if self._images.is_video:
+                args.append(self._args.input_dir)
             else:
-                args.append(self.args.reference_video)
+                args.append(self._args.reference_video)
         logger.debug("Writer args: %s", args)
-        configfile = self.args.configfile if hasattr(self.args, "configfile") else None
-        return PluginLoader.get_converter("writer", self.args.writer)(*args, configfile=configfile)
-
-    def get_frame_ranges(self):
-        """ split out the frame ranges and parse out 'min' and 'max' values """
-        if not self.args.frame_ranges:
+        configfile = self._args.configfile if hasattr(self._args, "configfile") else None
+        return PluginLoader.get_converter("writer", self._args.writer)(*args,
+                                                                       configfile=configfile)
+
+    def _get_frame_ranges(self):
+        """ Obtain the frame ranges that are to be converted.
+
+        If frame ranges have been specified, then split the command line formatted arguments into
+        ranges that can be used.
+
+        Returns
+        list or ``None``
+            A list of  frames to be processed, or ``None`` if the command line argument was not
+            used
+        """
+        if not self._args.frame_ranges:
             logger.debug("No frame range set")
             return None
 
         minframe, maxframe = None, None
-        if self.images.is_video:
-            minframe, maxframe = 1, self.images.images_found
+        if self._images.is_video:
+            minframe, maxframe = 1, self._images.images_found
         else:
-            indices = [int(self.imageidxre.findall(os.path.basename(filename))[0])
-                       for filename in self.images.input_images]
+            indices = [int(self._imageidxre.findall(os.path.basename(filename))[0])
+                       for filename in self._images.input_images]
             if indices:
                 minframe, maxframe = min(indices), max(indices)
         logger.debug("minframe: %s, maxframe: %s", minframe, maxframe)
@@ -239,7 +344,7 @@ class DiskIO():
                                 "from filenames")
 
         retval = list()
-        for rng in self.args.frame_ranges:
+        for rng in self._args.frame_ranges:
             if "-" not in rng:
                 raise FaceswapError("Frame Ranges not specified in the correct format")
             start, end = rng.split("-")
@@ -247,16 +352,35 @@ class DiskIO():
         logger.debug("frame ranges: %s", retval)
         return retval
 
-    def load_extractor(self):
-        """ Set on the fly extraction """
-        if self.alignments.have_alignments_file:
+    def _load_extractor(self):
+        """ Load the CV2-DNN Face Extractor Chain.
+
+        For On-The-Fly conversion we use a CPU based extractor to avoid stacking the GPU.
+        Results are poor.
+
+        Returns
+        -------
+        :class:`plugins.extract.Pipeline.Extractor`
+            The face extraction chain to be used for on-the-fly conversion
+        """
+        if not self._alignments.have_alignments_file and not self._args.on_the_fly:
+            logger.error("No alignments file found. Please provide an alignments file for your "
+                         "destination video (recommended) or enable on-the-fly conversion (not "
+                         "recommended).")
+            sys.exit(1)
+        if self._alignments.have_alignments_file:
+            if self._args.on_the_fly:
+                logger.info("On-The-Fly conversion selected, but an alignments file was found. "
+                            "Using pre-existing alignments file: '%s'", self._alignments.file)
+            else:
+                logger.debug("Alignments file found: '%s'", self._alignments.file)
             return None
 
         logger.debug("Loading extractor")
-        logger.warning("No Alignments file found. Extracting on the fly.")
-        logger.warning("NB: This will use the inferior cv2-dnn for extraction "
-                       "and  landmarks. It is recommended to perfom Extract first for "
-                       "superior results")
+        logger.warning("On-The-Fly conversion selected. This will use the inferior cv2-dnn for "
+                       "extraction and will produce poor results.")
+        logger.warning("It is recommended to generate an alignments file for your destination "
+                       "video with Extract first for superior results.")
         extractor = Extractor(detector="cv2-dnn",
                               aligner="cv2-dnn",
                               masker="none",
@@ -267,16 +391,25 @@ class DiskIO():
         logger.debug("Loaded extractor")
         return extractor
 
-    def init_threads(self):
-        """ Initialize queues and threads """
+    def _init_threads(self):
+        """ Initialize queues and threads.
+
+        Creates the load and save queues and the load and save threads. Starts the threads.
+        """
         logger.debug("Initializing DiskIO Threads")
         for task in ("load", "save"):
-            self.add_queue(task)
-            self.start_thread(task)
+            self._add_queue(task)
+            self._start_thread(task)
         logger.debug("Initialized DiskIO Threads")
 
-    def add_queue(self, task):
-        """ Add the queue to queue_manager and set queue attribute """
+    def _add_queue(self, task):
+        """ Add the queue to queue_manager and to :attr:`self._queues` for the given task.
+
+        Parameters
+        ----------
+        task: {"load", "save"}
+            The task that the queue is to be added for
+        """
         logger.debug("Adding queue for task: '%s'", task)
         if task == "load":
             q_name = "convert_in"
@@ -284,83 +417,135 @@ class DiskIO():
             q_name = "convert_out"
         else:
             q_name = task
-        setattr(self,
-                "{}_queue".format(task),
-                queue_manager.get_queue(q_name))
+        self._queues[task] = queue_manager.get_queue(q_name)
         logger.debug("Added queue for task: '%s'", task)
 
-    def start_thread(self, task):
-        """ Start the DiskIO thread """
+    def _start_thread(self, task):
+        """ Create the thread for the given task, add it it :attr:`self._threads` and start it.
+
+        Parameters
+        ----------
+        task: {"load", "save"}
+            The task that the thread is to be created for
+        """
         logger.debug("Starting thread: '%s'", task)
-        args = self.completion_event if task == "save" else None
-        func = getattr(self, task)
+        args = self._completion_event if task == "save" else None
+        func = getattr(self, "_{}".format(task))
         io_thread = MultiThread(func, args, thread_count=1)
         io_thread.start()
-        setattr(self, "{}_thread".format(task), io_thread)
+        self._threads[task] = io_thread
         logger.debug("Started thread: '%s'", task)
 
     # Loading tasks
-    def load(self, *args):  # pylint: disable=unused-argument
-        """ Load the images with detected_faces"""
+    def _load(self, *args):  # pylint: disable=unused-argument
+        """ Load frames from disk.
+
+        In a background thread:
+            * Loads frames from disk.
+            * Discards or passes through cli selected skipped frames
+            * Pairs the frame with its :class:`~lib.faces_detect.DetectedFace` objects
+            * Performs any pre-processing actions
+            * Puts the frame and detected faces to the load queue
+        """
         logger.debug("Load Images: Start")
         idx = 0
-        for filename, image in self.images.load():
+        for filename, image in self._images.load():
             idx += 1
-            if self.load_queue.shutdown.is_set():
+            if self._queues["load"].shutdown.is_set():
                 logger.debug("Load Queue: Stop signal received. Terminating")
                 break
             if image is None or (not image.any() and image.ndim not in (2, 3)):
                 # All black frames will return not numpy.any() so check dims too
                 logger.warning("Unable to open image. Skipping: '%s'", filename)
                 continue
-            if self.check_skipframe(filename):
-                if self.args.keep_unchanged:
+            if self._check_skipframe(filename):
+                if self._args.keep_unchanged:
                     logger.trace("Saving unchanged frame: %s", filename)
-                    out_file = os.path.join(self.args.output_dir, os.path.basename(filename))
-                    self.save_queue.put((out_file, image))
+                    out_file = os.path.join(self._args.output_dir, os.path.basename(filename))
+                    self._queues["save"].put((out_file, image))
                 else:
                     logger.trace("Discarding frame: '%s'", filename)
                 continue
 
-            detected_faces = self.get_detected_faces(filename, image)
+            detected_faces = self._get_detected_faces(filename, image)
             item = dict(filename=filename, image=image, detected_faces=detected_faces)
-            self.pre_process.do_actions(item)
-            self.load_queue.put(item)
+            self._pre_process.do_actions(item)
+            self._queues["load"].put(item)
 
         logger.debug("Putting EOF")
-        self.load_queue.put("EOF")
+        self._queues["load"].put("EOF")
         logger.debug("Load Images: Complete")
 
-    def check_skipframe(self, filename):
-        """ Check whether frame is to be skipped """
-        if not self.frame_ranges:
+    def _check_skipframe(self, filename):
+        """ Check whether a frame is to be skipped.
+
+        Parameters
+        ----------
+        filename: str
+            The filename of the frame to check
+
+        Returns
+        -------
+        bool
+            ``True`` if the frame is to be skipped otherwise ``False``
+        """
+        if not self._frame_ranges:
             return None
-        indices = self.imageidxre.findall(filename)
+        indices = self._imageidxre.findall(filename)
         if not indices:
             logger.warning("Could not determine frame number. Frame will be converted: '%s'",
                            filename)
             return False
         idx = int(indices[0]) if indices else None
-        skipframe = not any(map(lambda b: b[0] <= idx <= b[1], self.frame_ranges))
+        skipframe = not any(map(lambda b: b[0] <= idx <= b[1], self._frame_ranges))
         logger.trace("idx: %s, skipframe: %s", idx, skipframe)
         return skipframe
 
-    def get_detected_faces(self, filename, image):
-        """ Return detected faces from alignments or detector """
+    def _get_detected_faces(self, filename, image):
+        """ Return the detected faces for the given image.
+
+        If we have an alignments file, then the detected faces are created from that file. If
+        we're running On-The-Fly then they will be extracted from the extractor.
+
+        Parameters
+        ----------
+        filename: str
+            The filename to return the detected faces for
+        image: :class:`numpy.ndarray`
+            The frame that the detected faces exist in
+
+        Returns
+        -------
+        list
+            List of :class:`lib.faces_detect.DetectedFace` objects
+        """
         logger.trace("Getting faces for: '%s'", filename)
-        if not self.extractor:
-            detected_faces = self.alignments_faces(os.path.basename(filename), image)
+        if not self._extractor:
+            detected_faces = self._alignments_faces(os.path.basename(filename), image)
         else:
-            detected_faces = self.detect_faces(filename, image)
+            detected_faces = self._detect_faces(filename, image)
         logger.trace("Got %s faces for: '%s'", len(detected_faces), filename)
         return detected_faces
 
-    def alignments_faces(self, frame, image):
-        """ Get the face from alignments file """
-        if not self.check_alignments(frame):
+    def _alignments_faces(self, frame_name, image):
+        """ Return detected faces from an alignments file.
+
+        Parameters
+        ----------
+        frame_name: str
+            The name of the frame to return the detected faces for
+        image: :class:`numpy.ndarray`
+            The frame that the detected faces exist in
+
+        Returns
+        -------
+        list
+            List of :class:`lib.faces_detect.DetectedFace` objects
+        """
+        if not self._check_alignments(frame_name):
             return list()
 
-        faces = self.alignments.get_faces_in_frame(frame)
+        faces = self._alignments.get_faces_in_frame(frame_name)
         detected_faces = list()
 
         for rawface in faces:
@@ -369,34 +554,71 @@ class DiskIO():
             detected_faces.append(face)
         return detected_faces
 
-    def check_alignments(self, frame):
-        """ If we have no alignments for this image, skip it """
-        have_alignments = self.alignments.frame_exists(frame)
+    def _check_alignments(self, frame_name):
+        """ Ensure that we have alignments for the current frame.
+
+        If we have no alignments for this image, skip it and output a message.
+
+        Parameters
+        ----------
+        frame_name: str
+            The name of the frame to check that we have alignments for
+
+        Returns
+        -------
+        bool
+            ``True`` if we have alignments for this face, otherwise ``False``
+        """
+        have_alignments = self._alignments.frame_exists(frame_name)
         if not have_alignments:
             tqdm.write("No alignment found for {}, "
-                       "skipping".format(frame))
+                       "skipping".format(frame_name))
         return have_alignments
 
-    def detect_faces(self, filename, image):
-        """ Extract the face from a frame (If alignments file not found) """
-        self.extractor.input_queue.put(ExtractMedia(filename, image))
-        faces = next(self.extractor.detected_faces())
+    def _detect_faces(self, filename, image):
+        """ Extract the face from a frame for On-The-Fly conversion.
+
+        Pulls detected faces out of the Extraction pipeline.
+
+        Parameters
+        ----------
+        filename: str
+            The filename to return the detected faces for
+        image: :class:`numpy.ndarray`
+            The frame that the detected faces exist in
+
+        Returns
+        -------
+        list
+            List of :class:`lib.faces_detect.DetectedFace` objects
+         """
+        self._extractor.input_queue.put(ExtractMedia(filename, image))
+        faces = next(self._extractor.detected_faces())
 
         final_faces = [face for face in faces.detected_faces]
         return final_faces
 
     # Saving tasks
-    def save(self, completion_event):
-        """ Save the converted images """
+    def _save(self, completion_event):
+        """ Save the converted images.
+
+        Puts the selected writer into a background thread and feeds it from the output of the
+        patch queue.
+
+        Parameters
+        ----------
+        completion_event: :class:`event.Event`
+            An even that this process triggers when it has finished saving
+        """
         logger.debug("Save Images: Start")
-        write_preview = self.args.redirect_gui and self.writer.is_stream
-        preview_image = os.path.join(self.writer.output_folder, ".gui_preview.jpg")
+        write_preview = self._args.redirect_gui and self._writer.is_stream
+        preview_image = os.path.join(self._writer.output_folder, ".gui_preview.jpg")
         logger.debug("Write preview for gui: %s", write_preview)
-        for idx in tqdm(range(self.total_count), desc="Converting", file=sys.stdout):
-            if self.save_queue.shutdown.is_set():
+        for idx in tqdm(range(self._total_count), desc="Converting", file=sys.stdout):
+            if self._queues["save"].shutdown.is_set():
                 logger.debug("Save Queue: Stop signal received. Terminating")
                 break
-            item = self.save_queue.get()
+            item = self._queues["save"].get()
             if item == "EOF":
                 logger.debug("EOF Received")
                 break
@@ -404,68 +626,111 @@ class DiskIO():
             # Write out preview image for the GUI every 10 frames if writing to stream
             if write_preview and idx % 10 == 0 and not os.path.exists(preview_image):
                 logger.debug("Writing GUI Preview image: '%s'", preview_image)
-                imwrite(preview_image, image)
-            self.writer.write(filename, image)
-        self.writer.close()
+                cv2.imwrite(preview_image, image)
+            self._writer.write(filename, image)
+        self._writer.close()
         completion_event.set()
         logger.debug("Save Faces: Complete")
 
 
 class Predict():
-    """ Predict faces from incoming queue """
+    """ Obtains the output from the Faceswap model.
+
+    Parameters
+    ----------
+    in_queue: :class:`queue.Queue`
+        The queue that contains images and detected faces for feeding the model
+    queue_size: int
+        The maximum size of the input queue
+    arguments: :class:`argparse.Namespace`
+        The arguments that were passed to the convert process as generated from Faceswap's command
+        line arguments
+    """
     def __init__(self, in_queue, queue_size, arguments):
         logger.debug("Initializing %s: (args: %s, queue_size: %s, in_queue: %s)",
                      self.__class__.__name__, arguments, queue_size, in_queue)
-        self.batchsize = self.get_batchsize(queue_size)
-        self.args = arguments
-        self.in_queue = in_queue
-        self.out_queue = queue_manager.get_queue("patch")
-        self.serializer = get_serializer("json")
-        self.faces_count = 0
-        self.verify_output = False
+        self._batchsize = self._get_batchsize(queue_size)
+        self._args = arguments
+        self._in_queue = in_queue
+        self._out_queue = queue_manager.get_queue("patch")
+        self._serializer = get_serializer("json")
+        self._faces_count = 0
+        self._verify_output = False
 
         if arguments.allow_growth:
-            self.set_tf_allow_growth()
+            self._set_tf_allow_growth()
+
+        self._model = self._load_model()
+        self._output_indices = {"face": self._model.largest_face_index,
+                                "mask": self._model.largest_mask_index}
+        self._predictor = self._model.converter(self._args.swap_model)
+        self._thread = self._launch_predictor()
+        logger.debug("Initialized %s: (out_queue: %s)", self.__class__.__name__, self._out_queue)
 
-        self.model = self.load_model()
-        self.output_indices = {"face": self.model.largest_face_index,
-                               "mask": self.model.largest_mask_index}
-        self.predictor = self.model.converter(self.args.swap_model)
-        self.queues = dict()
+    @property
+    def thread(self):
+        """ :class:`~lib.multithreading.MultiThread`: The thread that is running the prediction
+        function from the Faceswap model. """
+        return self._thread
+
+    @property
+    def in_queue(self):
+        """ :class:`queue.Queue`: The input queue to the predictor. """
+        return self._in_queue
+
+    @property
+    def out_queue(self):
+        """ :class:`queue.Queue`: The output queue from the predictor. """
+        return self._out_queue
+
+    @property
+    def faces_count(self):
+        """ int: The total number of faces seen by the Predictor. """
+        return self._faces_count
 
-        self.thread = MultiThread(self.predict_faces, thread_count=1)
-        self.thread.start()
-        logger.debug("Initialized %s: (out_queue: %s)", self.__class__.__name__, self.out_queue)
+    @property
+    def verify_output(self):
+        """ bool: ``True`` if multiple faces have been found in frames, otherwise ``False``. """
+        return self._verify_output
 
     @property
     def coverage_ratio(self):
-        """ Return coverage ratio from training options """
-        return self.model.training_opts["coverage_ratio"]
+        """ float: The coverage ratio that the model was trained at. """
+        return self._model.training_opts["coverage_ratio"]
 
     @property
-    def input_size(self):
-        """ Return the model input size """
-        return self.model.input_shape[0]
+    def has_predicted_mask(self):
+        """ bool: ``True`` if the model was trained to learn a mask, otherwise ``False``. """
+        return bool(self._model.state.config.get("learn_mask", False))
 
     @property
     def output_size(self):
-        """ Return the model output size """
-        return self.model.output_shape[0]
+        """ int: The size in pixels of the Faceswap model output. """
+        return self._model.output_shape[0]
 
     @property
-    def input_mask(self):
-        """ Return the input mask """
-        mask = np.zeros((1, ) + self.model.state.mask_shapes[0], dtype="float32")
-        return mask
+    def _input_size(self):
+        """ int: The size in pixels of the Faceswap model input. """
+        return self._model.input_shape[0]
 
     @property
-    def has_predicted_mask(self):
-        """ Return whether this model has a predicted mask """
-        return bool(self.model.state.config.get("learn_mask", False))
+    def _input_mask(self):
+        """ :class:`numpy.ndarray`: A dummy mask for inputting to the model. """
+        mask = np.zeros((1, ) + self._model.state.mask_shapes[0], dtype="float32")
+        return mask
 
     @staticmethod
-    def get_batchsize(queue_size):
-        """ Get the batchsize """
+    def _get_batchsize(queue_size):
+        """ Get the batch size for feeding the model.
+
+        Sets the batch size to 1 if inference is being run on CPU, otherwise the minimum of the
+        :attr:`self._queue_size` and 16.
+
+        Returns
+        -------
+        int
+            The batch size that the model is to be fed at.
+        """
         logger.debug("Getting batchsize")
         is_cpu = GPUStats().device_count == 0
         batchsize = 1 if is_cpu else 16
@@ -475,10 +740,12 @@ class Predict():
         return batchsize
 
     @staticmethod
-    def set_tf_allow_growth():
-        """ Allow TensorFlow to manage VRAM growth """
+    def _set_tf_allow_growth():
+        """ Enables the TensorFlow configuration option "allow_growth".
+
+        TODO Move this temporary fix somewhere more appropriate
+        """
         # pylint: disable=no-member
-        # TODO Move this temporary fix somewhere more appropriate
         logger.debug("Setting Tensorflow 'allow_growth' option")
         config = tf.ConfigProto()
         config.gpu_options.allow_growth = True
@@ -486,23 +753,44 @@ class Predict():
         set_session(tf.Session(config=config))
         logger.debug("Set Tensorflow 'allow_growth' option")
 
-    def load_model(self):
-        """ Load the model requested for conversion """
+    def _load_model(self):
+        """ Load the Faceswap model.
+
+        Returns
+        -------
+        :mod:`plugins.train.model` plugin
+            The trained model in the specified model folder
+        """
         logger.debug("Loading Model")
-        model_dir = get_folder(self.args.model_dir, make_folder=False)
+        model_dir = get_folder(self._args.model_dir, make_folder=False)
         if not model_dir:
-            raise FaceswapError("{} does not exist.".format(self.args.model_dir))
-        trainer = self.get_trainer(model_dir)
-        gpus = 1 if not hasattr(self.args, "gpus") else self.args.gpus
+            raise FaceswapError("{} does not exist.".format(self._args.model_dir))
+        trainer = self._get_model_name(model_dir)
+        gpus = 1 if not hasattr(self._args, "gpus") else self._args.gpus
         model = PluginLoader.get_model(trainer)(model_dir, gpus, predict=True)
         logger.debug("Loaded Model")
         return model
 
-    def get_trainer(self, model_dir):
-        """ Return the trainer name if provided, or read from state file """
-        if hasattr(self.args, "trainer") and self.args.trainer:
-            logger.debug("Trainer name provided: '%s'", self.args.trainer)
-            return self.args.trainer
+    def _get_model_name(self, model_dir):
+        """ Return the name of the Faceswap model used.
+
+        If a "trainer" option has been selected in the command line arguments, use that value,
+        otherwise retrieve the name of the model from the model's state file.
+
+        Parameters
+        ----------
+        model_dir: str
+            The folder that contains the trained Faceswap model
+
+        Returns
+        -------
+        str
+            The name of the Faceswap model being used.
+
+        """
+        if hasattr(self._args, "trainer") and self._args.trainer:
+            logger.debug("Trainer name provided: '%s'", self._args.trainer)
+            return self._args.trainer
 
         statefile = [fname for fname in os.listdir(str(model_dir))
                      if fname.endswith("_state.json")]
@@ -512,7 +800,7 @@ class Predict():
                                 "option.".format(len(statefile)))
         statefile = os.path.join(str(model_dir), statefile[0])
 
-        state = self.serializer.load(statefile)
+        state = self._serializer.load(statefile)
         trainer = state.get("name", None)
 
         if not trainer:
@@ -521,26 +809,44 @@ class Predict():
         logger.debug("Trainer from state file: '%s'", trainer)
         return trainer
 
-    def predict_faces(self):
-        """ Get detected faces from images """
+    def _launch_predictor(self):
+        """ Launch the prediction process in a background thread.
+
+        Starts the prediction thread and returns the thread.
+
+        Returns
+        -------
+        :class:`~lib.multithreading.MultiThread`
+            The started Faceswap model prediction thread.
+        """
+        thread = MultiThread(self._predict_faces, thread_count=1)
+        thread.start()
+        return thread
+
+    def _predict_faces(self):
+        """ Run Prediction on the Faceswap model in a background thread.
+
+        Reads from the :attr:`self._in_queue`, prepares images for prediction
+        then puts the predictions back to the :attr:`self.out_queue`
+        """
         faces_seen = 0
         consecutive_no_faces = 0
         batch = list()
         is_plaidml = GPUStats().is_plaidml
         while True:
-            item = self.in_queue.get()
+            item = self._in_queue.get()
             if item != "EOF":
                 logger.trace("Got from queue: '%s'", item["filename"])
                 faces_count = len(item["detected_faces"])
 
                 # Safety measure. If a large stream of frames appear that do not have faces,
                 # these will stack up into RAM. Keep a count of consecutive frames with no faces.
-                # If self.batchsize number of frames appear, force the current batch through
+                # If self._batchsize number of frames appear, force the current batch through
                 # to clear RAM.
                 consecutive_no_faces = consecutive_no_faces + 1 if faces_count == 0 else 0
-                self.faces_count += faces_count
+                self._faces_count += faces_count
                 if faces_count > 1:
-                    self.verify_output = True
+                    self._verify_output = True
                     logger.verbose("Found more than one face in an image! '%s'",
                                    os.path.basename(item["filename"]))
 
@@ -549,8 +855,8 @@ class Predict():
                 faces_seen += faces_count
                 batch.append(item)
 
-            if item != "EOF" and (faces_seen < self.batchsize and
-                                  consecutive_no_faces < self.batchsize):
+            if item != "EOF" and (faces_seen < self._batchsize and
+                                  consecutive_no_faces < self._batchsize):
                 logger.trace("Continuing. Current batchsize: %s, consecutive_no_faces: %s",
                              faces_seen, consecutive_no_faces)
                 continue
@@ -561,16 +867,16 @@ class Predict():
                 detected_batch = [detected_face for item in batch
                                   for detected_face in item["detected_faces"]]
                 if faces_seen != 0:
-                    feed_faces = self.compile_feed_faces(detected_batch)
+                    feed_faces = self._compile_feed_faces(detected_batch)
                     batch_size = None
-                    if is_plaidml and feed_faces.shape[0] != self.batchsize:
+                    if is_plaidml and feed_faces.shape[0] != self._batchsize:
                         logger.verbose("Fallback to BS=1")
                         batch_size = 1
-                    predicted = self.predict(feed_faces, batch_size)
+                    predicted = self._predict(feed_faces, batch_size)
                 else:
                     predicted = list()
 
-                self.queue_out_frames(batch, predicted)
+                self._queue_out_frames(batch, predicted)
 
             consecutive_no_faces = 0
             faces_seen = 0
@@ -579,18 +885,28 @@ class Predict():
                 logger.debug("EOF Received")
                 break
         logger.debug("Putting EOF")
-        self.out_queue.put("EOF")
+        self._out_queue.put("EOF")
         logger.debug("Load queue complete")
 
     def load_aligned(self, item):
-        """ Load the feed faces and reference output faces """
+        """ Load the model's feed faces and the reference output faces.
+
+        For each detected face in the incoming item, load the feed face and reference face
+        images, correctly sized for input and output respectively.
+
+        Parameters
+        ----------
+        item: dict
+            The incoming image and list of :class:`~lib.faces_detect.DetectedFace` objects
+
+        """
         logger.trace("Loading aligned faces: '%s'", item["filename"])
         for detected_face in item["detected_faces"]:
             detected_face.load_feed_face(item["image"],
-                                         size=self.input_size,
+                                         size=self._input_size,
                                          coverage_ratio=self.coverage_ratio,
                                          dtype="float32")
-            if self.input_size == self.output_size:
+            if self._input_size == self.output_size:
                 detected_face.reference = detected_face.feed
             else:
                 detected_face.load_reference_face(item["image"],
@@ -600,27 +916,52 @@ class Predict():
         logger.trace("Loaded aligned faces: '%s'", item["filename"])
 
     @staticmethod
-    def compile_feed_faces(detected_faces):
-        """ Compile the faces for feeding into the predictor """
+    def _compile_feed_faces(detected_faces):
+        """ Compile a batch of faces for feeding into the Predictor.
+
+        Parameters
+        ----------
+        detected_faces: list
+            List of `~lib.faces_detect.DetectedFace` objects
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            A batch of faces ready for feeding into the Faceswap model.
+        """
         logger.trace("Compiling feed face. Batchsize: %s", len(detected_faces))
         feed_faces = np.stack([detected_face.feed_face[..., :3]
                                for detected_face in detected_faces]) / 255.0
         logger.trace("Compiled Feed faces. Shape: %s", feed_faces.shape)
         return feed_faces
 
-    def predict(self, feed_faces, batch_size=None):
-        """ Perform inference on the feed """
+    def _predict(self, feed_faces, batch_size=None):
+        """ Run the Faceswap models' prediction function.
+
+        Parameters
+        ----------
+        feed_faces: :class:`numpy.ndarray`
+            The batch to be fed into the model
+        batch_size: int, optional
+            Used for plaidml only. Indicates to the model what batch size is being processed.
+            Default: ``None``
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The swapped faces for the given batch
+        """
         logger.trace("Predicting: Batchsize: %s", len(feed_faces))
         feed = [feed_faces]
-        if self.model.feed_mask:
-            feed.append(np.repeat(self.input_mask, feed_faces.shape[0], axis=0))
+        if self._model.feed_mask:
+            feed.append(np.repeat(self._input_mask, feed_faces.shape[0], axis=0))
         logger.trace("Input shape(s): %s", [item.shape for item in feed])
 
-        predicted = self.predictor(feed, batch_size=batch_size)
+        predicted = self._predictor(feed, batch_size=batch_size)
         predicted = predicted if isinstance(predicted, list) else [predicted]
         logger.trace("Output shape(s): %s", [predict.shape for predict in predicted])
 
-        predicted = self.filter_multi_out(predicted)
+        predicted = self._filter_multi_out(predicted)
 
         # Compile masks into alpha channel or keep raw faces
         predicted = np.concatenate(predicted, axis=-1) if len(predicted) == 2 else predicted[0]
@@ -629,19 +970,44 @@ class Predict():
         logger.trace("Final shape: %s", predicted.shape)
         return predicted
 
-    def filter_multi_out(self, predicted):
-        """ Filter the predicted output to the final output """
+    def _filter_multi_out(self, predicted):
+        """ Filter the model output to just the required image.
+
+        Some models have multi-scale outputs, so just make sure we take the largest
+        output.
+
+        Parameters
+        ----------
+        predicted: :class:`numpy.ndarray`
+            The predictions retrieved from the Faceswap model.
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The predictions with any superfluous outputs removed.
+        """
         if not predicted:
             return predicted
-        face = predicted[self.output_indices["face"]]
-        mask_idx = self.output_indices["mask"]
+        face = predicted[self._output_indices["face"]]
+        mask_idx = self._output_indices["mask"]
         mask = predicted[mask_idx] if mask_idx is not None else None
         predicted = [face, mask] if mask is not None else [face]
         logger.trace("Filtered output shape(s): %s", [predict.shape for predict in predicted])
         return predicted
 
-    def queue_out_frames(self, batch, swapped_faces):
-        """ Compile the batch back to original frames and put to out_queue """
+    def _queue_out_frames(self, batch, swapped_faces):
+        """ Compile the batch back to original frames and put to the Out Queue.
+
+        For batching, faces are split away from their frames. This compiles all detected faces
+        back to their parent frame before putting each frame to the out queue in batches.
+
+        Parameters
+        ----------
+        batch: dict
+            The batch that was used as the input for the model predict function
+        swapped_faces: :class:`numpy.ndarray`
+            The predictions returned from the model's predict function
+        """
         logger.trace("Queueing out batch. Batchsize: %s", len(batch))
         pointer = 0
         for item in batch:
@@ -655,40 +1021,59 @@ class Predict():
                          item["filename"], len(item["detected_faces"]),
                          item["swapped_faces"].shape[0])
             pointer += num_faces
-        self.out_queue.put(batch)
+        self._out_queue.put(batch)
         logger.trace("Queued out batch. Batchsize: %s", len(batch))
 
 
-class OptionalActions():
-    """ Process the optional actions for convert """
+class OptionalActions():  # pylint:disable=too-few-public-methods
+    """ Process specific optional actions for Convert.
+
+    Currently only handles skip faces. This class should probably be (re)moved.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The arguments that were passed to the convert process as generated from Faceswap's command
+        line arguments
+    input_images: list
+        List of input image files
+    alignments: :class:`lib.alignments.Alignments`
+        The alignments file for this conversion
+    """
 
-    def __init__(self, args, input_images, alignments):
+    def __init__(self, arguments, input_images, alignments):
         logger.debug("Initializing %s", self.__class__.__name__)
-        self.args = args
-        self.input_images = input_images
-        self.alignments = alignments
+        self._args = arguments
+        self._input_images = input_images
+        self._alignments = alignments
 
-        self.remove_skipped_faces()
+        self._remove_skipped_faces()
         logger.debug("Initialized %s", self.__class__.__name__)
 
     # SKIP FACES #
-    def remove_skipped_faces(self):
-        """ Remove deleted faces from the loaded alignments """
+    def _remove_skipped_faces(self):
+        """ If the user has specified an input aligned directory, remove any non-matching faces
+        from the alignments file. """
         logger.debug("Filtering Faces")
-        face_hashes = self.get_face_hashes()
+        face_hashes = self._get_face_hashes()
         if not face_hashes:
             logger.debug("No face hashes. Not skipping any faces")
             return
-        pre_face_count = self.alignments.faces_count
-        self.alignments.filter_hashes(face_hashes, filter_out=False)
-        logger.info("Faces filtered out: %s", pre_face_count - self.alignments.faces_count)
-
-    def get_face_hashes(self):
-        """ Check for the existence of an aligned directory for identifying
-            which faces in the target frames should be swapped.
-            If it exists, obtain the hashes of the faces in the folder """
+        pre_face_count = self._alignments.faces_count
+        self._alignments.filter_hashes(face_hashes, filter_out=False)
+        logger.info("Faces filtered out: %s", pre_face_count - self._alignments.faces_count)
+
+    def _get_face_hashes(self):
+        """ Check for the existence of an aligned directory for identifying which faces in the
+        target frames should be swapped.
+
+        Returns
+        -------
+        list
+            A list of face hashes that exist in the given input aligned directory.
+        """
         face_hashes = list()
-        input_aligned_dir = self.args.input_aligned_dir
+        input_aligned_dir = self._args.input_aligned_dir
 
         if input_aligned_dir is None:
             logger.verbose("Aligned directory not specified. All faces listed in the "
@@ -704,7 +1089,7 @@ class OptionalActions():
             logger.debug("Face Hashes: %s", (len(face_hashes)))
             if not face_hashes:
                 raise FaceswapError("Aligned directory is empty, no faces will be converted!")
-            if len(face_hashes) <= len(self.input_images) / 3:
+            if len(face_hashes) <= len(self._input_images) / 3:
                 logger.warning("Aligned directory contains far fewer images than the input "
                                "directory, are you sure this is the right folder?")
         return face_hashes
diff --git a/scripts/extract.py b/scripts/extract.py
index ce2a049..f7490f8 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -11,13 +11,13 @@ from lib.image import encode_image_with_hash, ImagesLoader, ImagesSaver
 from lib.multithreading import MultiThread
 from lib.utils import get_folder
 from plugins.extract.pipeline import Extractor, ExtractMedia
-from scripts.fsmedia import Alignments, PostProcess, Utils
+from scripts.fsmedia import Alignments, PostProcess, finalize
 
 tqdm.monitor_interval = 0  # workaround for TqdmSynchronisationWarning
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
-class Extract():
+class Extract():  # pylint:disable=too-few-public-methods
     """ The Faceswap Face Extraction Process.
 
     The extraction process is responsible for detecting faces in a series of images/video, aligning
@@ -115,9 +115,9 @@ class Extract():
         for thread in self._threads:
             thread.join()
         self._alignments.save()
-        Utils.finalize(self._images.process_count + self._existing_count,
-                       self._alignments.faces_count,
-                       self._verify_output)
+        finalize(self._images.process_count + self._existing_count,
+                 self._alignments.faces_count,
+                 self._verify_output)
 
     def _threaded_redirector(self, task, io_args=None):
         """ Redirect image input/output tasks to relevant queues in background thread
diff --git a/scripts/fsmedia.py b/scripts/fsmedia.py
index 27da35d..eb28633 100644
--- a/scripts/fsmedia.py
+++ b/scripts/fsmedia.py
@@ -1,12 +1,14 @@
 #!/usr/bin/env python3
-""" Holds the classes for the 3 main Faceswap 'media' objects for
-    input (extract) and output (convert) tasks. Those being:
-            Images
-            Faces
-            Alignments"""
+""" Helper functions for :mod:`~scripts.extract` and :mod:`~scripts.convert`.
+
+Holds the classes for the 2 main Faceswap 'media' objects: Images and Alignments.
+
+Holds optional pre/post processing functions for convert and extract.
+"""
 
 import logging
 import os
+import sys
 from pathlib import Path
 
 import cv2
@@ -20,68 +22,112 @@ from lib.utils import (camel_case_split, get_image_paths, _video_extensions)
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
-class Utils():
-    """ Holds utility functions that are required by more than one media
-        object """
-
-    @staticmethod
-    def finalize(images_found, num_faces_detected, verify_output):
-        """ Finalize the image processing """
+def finalize(images_found, num_faces_detected, verify_output):
+    """ Output summary statistics at the end of the extract or convert processes.
+
+    Parameters
+    ----------
+    images_found: int
+        The number of images/frames that were processed
+    num_faces_detected: int
+        The number of faces that have been detected
+    verify_output: bool
+        ``True`` if multiple faces were detected in frames otherwise ``False``.
+     """
+    logger.info("-------------------------")
+    logger.info("Images found:        %s", images_found)
+    logger.info("Faces detected:      %s", num_faces_detected)
+    logger.info("-------------------------")
+
+    if verify_output:
+        logger.info("Note:")
+        logger.info("Multiple faces were detected in one or more pictures.")
+        logger.info("Double check your results.")
         logger.info("-------------------------")
-        logger.info("Images found:        %s", images_found)
-        logger.info("Faces detected:      %s", num_faces_detected)
-        logger.info("-------------------------")
-
-        if verify_output:
-            logger.info("Note:")
-            logger.info("Multiple faces were detected in one or more pictures.")
-            logger.info("Double check your results.")
-            logger.info("-------------------------")
 
-        logger.info("Process Succesfully Completed. Shutting Down...")
+    logger.info("Process Succesfully Completed. Shutting Down...")
 
 
 class Alignments(AlignmentsBase):
-    """ Override main alignments class for extract """
+    """ Override :class:`lib.alignments.Alignments` to add custom loading based on command
+    line arguments.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The command line arguments that were passed to Faceswap
+    is_extract: bool
+        ``True`` if the process calling this class is extraction otherwise ``False``
+    input_is_video: bool, optional
+        ``True`` if the input to the process is a video, ``False`` if it is a folder of images.
+        Default: False
+    """
     def __init__(self, arguments, is_extract, input_is_video=False):
         logger.debug("Initializing %s: (is_extract: %s, input_is_video: %s)",
                      self.__class__.__name__, is_extract, input_is_video)
-        self.args = arguments
-        self.is_extract = is_extract
-        folder, filename = self.set_folder_filename(input_is_video)
-        super().__init__(folder,
-                         filename=filename)
+        self._args = arguments
+        self._is_extract = is_extract
+        folder, filename = self._set_folder_filename(input_is_video)
+        super().__init__(folder, filename=filename)
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def set_folder_filename(self, input_is_video):
-        """ Return the folder for the alignments file"""
-        if self.args.alignments_path:
-            logger.debug("Alignments File provided: '%s'", self.args.alignments_path)
-            folder, filename = os.path.split(str(self.args.alignments_path))
+    def _set_folder_filename(self, input_is_video):
+        """ Return the folder and the filename for the alignments file.
+
+        If the input is a video, the alignments file will be stored in the same folder
+        as the video, with filename `<videoname>_alignments`.
+
+        If the input is a folder of images, the alignments file will be stored in folder with
+        the images and just be called 'alignments'
+
+        Parameters
+        ----------
+        input_is_video: bool, optional
+            ``True`` if the input to the process is a video, ``False`` if it is a folder of images.
+
+        Returns
+        -------
+        folder: str
+            The folder where the alignments file will be stored
+        filename: str
+            The filename of the alignments file
+        """
+        if self._args.alignments_path:
+            logger.debug("Alignments File provided: '%s'", self._args.alignments_path)
+            folder, filename = os.path.split(str(self._args.alignments_path))
         elif input_is_video:
-            logger.debug("Alignments from Video File: '%s'", self.args.input_dir)
-            folder, filename = os.path.split(self.args.input_dir)
+            logger.debug("Alignments from Video File: '%s'", self._args.input_dir)
+            folder, filename = os.path.split(self._args.input_dir)
             filename = "{}_alignments".format(os.path.splitext(filename)[0])
         else:
-            logger.debug("Alignments from Input Folder: '%s'", self.args.input_dir)
-            folder = str(self.args.input_dir)
+            logger.debug("Alignments from Input Folder: '%s'", self._args.input_dir)
+            folder = str(self._args.input_dir)
             filename = "alignments"
         logger.debug("Setting Alignments: (folder: '%s' filename: '%s')", folder, filename)
         return folder, filename
 
     def load(self):
-        """ Override  parent loader to handle skip existing on extract """
+        """ Override the parent :func:`~lib.alignments.Alignments.load` to handle skip existing
+        frames and faces on extract.
+
+        If skip existing has been selected, existing alignments are loaded and returned to the
+        calling script.
+
+        Returns
+        -------
+        dict
+            Any alignments that have already been extracted if skip existing has been selected
+            otherwise an empty dictionary
+        """
         data = dict()
-        if not self.is_extract:
+        if not self._is_extract:
             if not self.have_alignments_file:
                 return data
             data = super().load()
             return data
 
-        skip_existing = bool(hasattr(self.args, 'skip_existing')
-                             and self.args.skip_existing)
-        skip_faces = bool(hasattr(self.args, 'skip_faces')
-                          and self.args.skip_faces)
+        skip_existing = hasattr(self._args, 'skip_existing') and self._args.skip_existing
+        skip_faces = hasattr(self._args, 'skip_faces') and self._args.skip_faces
 
         if not skip_existing and not skip_faces:
             logger.debug("No skipping selected. Returning empty dictionary")
@@ -106,66 +152,131 @@ class Alignments(AlignmentsBase):
 
 
 class Images():
-    """ Holds the full frames/images """
+    """ Handles the loading of frames from a folder of images or a video file for extract
+    and convert processes.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The command line arguments that were passed to Faceswap
+    """
     def __init__(self, arguments):
         logger.debug("Initializing %s", self.__class__.__name__)
-        self.args = arguments
-        self.is_video = self.check_input_folder()
-        self.input_images = self.get_input_images()
-        self.images_found = self.count_images()
+        self._args = arguments
+        self._is_video = self._check_input_folder()
+        self._input_images = self._get_input_images()
+        self._images_found = self._count_images()
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def count_images(self):
-        """ Number of images or frames """
-        if self.is_video:
-            retval = int(count_frames(self.args.input_dir, fast=True))
+    @property
+    def is_video(self):
+        """bool: ``True`` if the input is a video file otherwise ``False``. """
+        return self._is_video
+
+    @property
+    def input_images(self):
+        """str or list: Path to the video file if the input is a video otherwise list of
+        image paths. """
+        return self._input_images
+
+    @property
+    def images_found(self):
+        """int: The number of frames that exist in the video file, or the folder of images. """
+        return self._images_found
+
+    def _count_images(self):
+        """ Get the number of Frames from a video file or folder of images.
+
+        Returns
+        -------
+        int
+            The number of frames in the image source
+        """
+        if self._is_video:
+            retval = int(count_frames(self._args.input_dir, fast=True))
         else:
-            retval = len(self.input_images)
+            retval = len(self._input_images)
         return retval
 
-    def check_input_folder(self):
-        """ Check whether the input is a folder or video """
-        if not os.path.exists(self.args.input_dir):
-            logger.error("Input location %s not found.", self.args.input_dir)
-            exit(1)
-        if (os.path.isfile(self.args.input_dir) and
-                os.path.splitext(self.args.input_dir)[1].lower() in _video_extensions):
-            logger.info("Input Video: %s", self.args.input_dir)
+    def _check_input_folder(self):
+        """ Check whether the input is a folder or video.
+
+        Returns
+        -------
+        bool
+            ``True`` if the input is a video otherwise ``False``
+        """
+        if not os.path.exists(self._args.input_dir):
+            logger.error("Input location %s not found.", self._args.input_dir)
+            sys.exit(1)
+        if (os.path.isfile(self._args.input_dir) and
+                os.path.splitext(self._args.input_dir)[1].lower() in _video_extensions):
+            logger.info("Input Video: %s", self._args.input_dir)
             retval = True
         else:
-            logger.info("Input Directory: %s", self.args.input_dir)
+            logger.info("Input Directory: %s", self._args.input_dir)
             retval = False
         return retval
 
-    def get_input_images(self):
-        """ Return the list of images or video file that is to be processed """
-        if self.is_video:
-            input_images = self.args.input_dir
+    def _get_input_images(self):
+        """ Return the list of images or path to video file that is to be processed.
+
+        Returns
+        -------
+        str or list
+            Path to the video file if the input is a video otherwise list of image paths.
+        """
+        if self._is_video:
+            input_images = self._args.input_dir
         else:
-            input_images = get_image_paths(self.args.input_dir)
+            input_images = get_image_paths(self._args.input_dir)
 
         return input_images
 
     def load(self):
-        """ Load an image and yield it with it's filename """
-        iterator = self.load_video_frames if self.is_video else self.load_disk_frames
+        """ Generator to load frames from a folder of images or from a video file.
+
+        Yields
+        ------
+        filename: str
+            The filename of the current frame
+        image: :class:`numpy.ndarray`
+            A single frame
+        """
+        iterator = self._load_video_frames if self._is_video else self._load_disk_frames
         for filename, image in iterator():
             yield filename, image
 
-    def load_disk_frames(self):
-        """ Load frames from disk """
+    def _load_disk_frames(self):
+        """ Generator to load frames from a folder of images.
+
+        Yields
+        ------
+        filename: str
+            The filename of the current frame
+        image: :class:`numpy.ndarray`
+            A single frame
+        """
         logger.debug("Input is separate Frames. Loading images")
-        for filename in self.input_images:
+        for filename in self._input_images:
             image = read_image(filename, raise_error=False)
             if image is None:
                 continue
             yield filename, image
 
-    def load_video_frames(self):
-        """ Return frames from a video file """
+    def _load_video_frames(self):
+        """ Generator to load frames from a video file.
+
+        Yields
+        ------
+        filename: str
+            The filename of the current frame
+        image: :class:`numpy.ndarray`
+            A single frame
+        """
         logger.debug("Input is video. Capturing frames")
-        vidname = os.path.splitext(os.path.basename(self.args.input_dir))[0]
-        reader = imageio.get_reader(self.args.input_dir, "ffmpeg")
+        vidname = os.path.splitext(os.path.basename(self._args.input_dir))[0]
+        reader = imageio.get_reader(self._args.input_dir, "ffmpeg")
         for i, frame in enumerate(reader):
             # Convert to BGR for cv2 compatibility
             frame = frame[:, :, ::-1]
@@ -175,40 +286,78 @@ class Images():
         reader.close()
 
     def load_one_image(self, filename):
-        """ load requested image """
+        """ Obtain a single image for the given filename.
+
+        Parameters
+        ----------
+        filename: str
+            The filename to return the image for
+
+        Returns
+        ------
+        :class:`numpy.ndarray`
+            The image for the requested filename,
+
+        """
         logger.trace("Loading image: '%s'", filename)
-        if self.is_video:
+        if self._is_video:
             if filename.isdigit():
                 frame_no = filename
             else:
                 frame_no = os.path.splitext(filename)[0][filename.rfind("_") + 1:]
                 logger.trace("Extracted frame_no %s from filename '%s'", frame_no, filename)
-            retval = self.load_one_video_frame(int(frame_no))
+            retval = self._load_one_video_frame(int(frame_no))
         else:
             retval = read_image(filename, raise_error=True)
         return retval
 
-    def load_one_video_frame(self, frame_no):
-        """ Load a single frame from a video file """
+    def _load_one_video_frame(self, frame_no):
+        """ Obtain a single frame from a video file.
+
+        Parameters
+        ----------
+        frame_no: int
+            The frame index for the required frame
+
+        Returns
+        ------
+        :class:`numpy.ndarray`
+            The image for the requested frame index,
+        """
         logger.trace("Loading video frame: %s", frame_no)
-        reader = imageio.get_reader(self.args.input_dir, "ffmpeg")
+        reader = imageio.get_reader(self._args.input_dir, "ffmpeg")
         reader.set_image_index(frame_no - 1)
         frame = reader.get_next_data()[:, :, ::-1]
         reader.close()
         return frame
 
 
-class PostProcess():
-    """ Optional post processing tasks """
+class PostProcess():  # pylint:disable=too-few-public-methods
+    """ Optional pre/post processing tasks for convert and extract.
+
+    Builds a pipeline of actions that have optionally been requested to be performed
+    in this session.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The command line arguments that were passed to Faceswap
+    """
     def __init__(self, arguments):
         logger.debug("Initializing %s", self.__class__.__name__)
-        self.args = arguments
-        self.actions = self.set_actions()
+        self._args = arguments
+        self._actions = self._set_actions()
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def set_actions(self):
-        """ Compile the actions to be performed into a list """
-        postprocess_items = self.get_items()
+    def _set_actions(self):
+        """ Compile the requested actions to be performed into a list
+
+        Returns
+        -------
+        list
+            The list of :class:`PostProcessAction` to be performed
+        """
+        postprocess_items = self._get_items()
         actions = list()
         for action, options in postprocess_items.items():
             options = dict() if options is None else options
@@ -227,35 +376,45 @@ class PostProcess():
 
         return actions
 
-    def get_items(self):
-        """ Set the post processing actions """
+    def _get_items(self):
+        """ Check the passed in command line arguments for requested actions,
+
+        For any requested actions, add the item to the actions list along with
+        any relevant arguments and keyword arguments.
+
+        Returns
+        -------
+        dict
+            The name of the action to be performed as the key. Any action specific
+            arguments and keyword arguments as the value.
+        """
         postprocess_items = dict()
         # Debug Landmarks
-        if (hasattr(self.args, 'debug_landmarks') and self.args.debug_landmarks):
+        if (hasattr(self._args, 'debug_landmarks') and self._args.debug_landmarks):
             postprocess_items["DebugLandmarks"] = None
 
         # Face Filter post processing
-        if ((hasattr(self.args, "filter") and self.args.filter is not None) or
-                (hasattr(self.args, "nfilter") and
-                 self.args.nfilter is not None)):
+        if ((hasattr(self._args, "filter") and self._args.filter is not None) or
+                (hasattr(self._args, "nfilter") and
+                 self._args.nfilter is not None)):
 
-            if hasattr(self.args, "detector"):
-                detector = self.args.detector.replace("-", "_").lower()
+            if hasattr(self._args, "detector"):
+                detector = self._args.detector.replace("-", "_").lower()
             else:
                 detector = "cv2_dnn"
-            if hasattr(self.args, "aligner"):
-                aligner = self.args.aligner.replace("-", "_").lower()
+            if hasattr(self._args, "aligner"):
+                aligner = self._args.aligner.replace("-", "_").lower()
             else:
                 aligner = "cv2_dnn"
 
             face_filter = dict(detector=detector,
                                aligner=aligner,
-                               multiprocess=not self.args.singleprocess)
+                               multiprocess=not self._args.singleprocess)
             filter_lists = dict()
-            if hasattr(self.args, "ref_threshold"):
-                face_filter["ref_threshold"] = self.args.ref_threshold
+            if hasattr(self._args, "ref_threshold"):
+                face_filter["ref_threshold"] = self._args.ref_threshold
             for filter_type in ('filter', 'nfilter'):
-                filter_args = getattr(self.args, filter_type, None)
+                filter_args = getattr(self._args, filter_type, None)
                 filter_args = None if not filter_args else filter_args
                 filter_lists[filter_type] = filter_args
             face_filter["filter_lists"] = filter_lists
@@ -265,32 +424,79 @@ class PostProcess():
         return postprocess_items
 
     def do_actions(self, extract_media):
-        """ Perform the requested post-processing actions """
-        for action in self.actions:
+        """ Perform the requested optional post-processing actions on the given image.
+
+        Parameters
+        ----------
+        extract_media: :class:`~plugins.extract.pipeline.ExtractMedia`
+            The :class:`~plugins.extract.pipeline.ExtractMedia` object to perform the
+            action on.
+
+        Returns
+        -------
+        :class:`~plugins.extract.pipeline.ExtractMedia`
+            The original :class:`~plugins.extract.pipeline.ExtractMedia` with any actions applied
+        """
+        for action in self._actions:
             logger.debug("Performing postprocess action: '%s'", action.__class__.__name__)
             action.process(extract_media)
 
 
 class PostProcessAction():  # pylint: disable=too-few-public-methods
-    """ Parent class for Post Processing Actions. Usable in Extract or Convert or both
-        depending on context """
+    """ Parent class for Post Processing Actions.
+
+    Usable in Extract or Convert or both depending on context. Any post-processing actions should
+    inherit from this class.
+
+    Parameters
+    -----------
+    args: tuple
+        Varies for specific post process action
+    kwargs: dict
+        Varies for specific post process action
+    """
     def __init__(self, *args, **kwargs):
         logger.debug("Initializing %s: (args: %s, kwargs: %s)",
                      self.__class__.__name__, args, kwargs)
-        self.valid = True  # Set to False if invalid parameters passed in to disable
+        self._valid = True  # Set to False if invalid parameters passed in to disable
         logger.debug("Initialized base class %s", self.__class__.__name__)
 
+    @property
+    def valid(self):
+        """bool: ``True`` if the action if the parameters passed in for this action are valid,
+        otherwise ``False`` """
+        return self._valid
+
     def process(self, extract_media):
-        """ Override for specific post processing action """
+        """ Override for specific post processing action
+
+        Parameters
+        ----------
+        extract_media: :class:`~plugins.extract.pipeline.ExtractMedia`
+            The :class:`~plugins.extract.pipeline.ExtractMedia` object to perform the
+            action on.
+        """
         raise NotImplementedError
 
 
 class DebugLandmarks(PostProcessAction):  # pylint: disable=too-few-public-methods
-    """ Draw debug landmarks on face
-        Extract Only """
+    """ Draw debug landmarks on face output. Extract Only """
 
     def process(self, extract_media):
-        """ Draw landmarks on image """
+        """ Draw landmarks on a face.
+
+        Parameters
+        ----------
+        extract_media: :class:`~plugins.extract.pipeline.ExtractMedia`
+            The :class:`~plugins.extract.pipeline.ExtractMedia` object that contains the faces to
+            draw the landmarks on to
+
+        Returns
+        -------
+        :class:`~plugins.extract.pipeline.ExtractMedia`
+            The original :class:`~plugins.extract.pipeline.ExtractMedia` with landmarks drawn
+            onto the face
+        """
         frame = os.path.splitext(os.path.basename(extract_media.filename))[0]
         for idx, face in enumerate(extract_media.detected_faces):
             logger.trace("Drawing Landmarks. Frame: '%s'. Face: %s", frame, idx)
@@ -300,23 +506,59 @@ class DebugLandmarks(PostProcessAction):  # pylint: disable=too-few-public-metho
 
 
 class FaceFilter(PostProcessAction):
-    """ Filter in or out faces based on input image(s)
-        Extract or Convert """
+    """ Filter in or out faces based on input image(s). Extract or Convert
+
+    Parameters
+    -----------
+    args: tuple
+        Unused
+    kwargs: dict
+        Keyword arguments for face filter:
+
+        * **detector** (`str`) - The detector to use
+
+        * **aligner** (`str`) - The aligner to use
+
+        * **multiprocess** (`bool`) - Whether to run the extraction pipeline in single process \
+        mode or not
+
+        * **ref_threshold** (`float`) - The reference threshold for a positive match
+
+        * **filter_lists** (`dict`) - The filter and nfilter image paths
+    """
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
         logger.info("Extracting and aligning face for Face Filter...")
-        self.filter = self.load_face_filter(**kwargs)
+        self._filter = self._load_face_filter(**kwargs)
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def load_face_filter(self, filter_lists, ref_threshold, aligner, detector,
-                         multiprocess):
-        """ Load faces to filter out of images """
+    def _load_face_filter(self, filter_lists, ref_threshold, aligner, detector, multiprocess):
+        """ Set up and load the :class:`~lib.face_filter.FaceFilter`.
+
+        Parameters
+        ----------
+        filter_lists: dict
+            The filter and nfilter image paths
+        ref_threshold: float
+            The reference threshold for a positive match
+        aligner: str
+            The aligner to use
+        detector: str
+            The detector to use
+        multiprocess: bool
+            Whether to run the extraction pipeline in single process mode or not
+
+        Returns
+        -------
+        :class:`~lib.face_filter.FaceFilter`
+            The face filter
+        """
         if not any(val for val in filter_lists.values()):
             return None
 
         facefilter = None
-        filter_files = [self.set_face_filter(f_type, filter_lists[f_type])
+        filter_files = [self._set_face_filter(f_type, filter_lists[f_type])
                         for f_type in ("filter", "nfilter")]
 
         if any(filters for filters in filter_files):
@@ -332,8 +574,21 @@ class FaceFilter(PostProcessAction):
         return facefilter
 
     @staticmethod
-    def set_face_filter(f_type, f_args):
-        """ Set the required filters """
+    def _set_face_filter(f_type, f_args):
+        """ Check filter files exist and add the filter file paths to a list.
+
+        Parameters
+        ----------
+        f_type: {"filter", "nfilter"}
+            The type of filter to create this list for
+        f_args: str or list
+            The filter image(s) to use
+
+        Returns
+        -------
+        list
+            The confirmed existing paths to filter files to use
+        """
         if not f_args:
             return list()
 
@@ -347,14 +602,27 @@ class FaceFilter(PostProcessAction):
         return filter_files
 
     def process(self, extract_media):
-        """ Filter in/out wanted/unwanted faces """
-        if not self.filter:
+        """ Filters in or out any wanted or unwanted faces based on command line arguments.
+
+        Parameters
+        ----------
+        extract_media: :class:`~plugins.extract.pipeline.ExtractMedia`
+            The :class:`~plugins.extract.pipeline.ExtractMedia` object to perform the
+            face filtering on.
+
+        Returns
+        -------
+        :class:`~plugins.extract.pipeline.ExtractMedia`
+            The original :class:`~plugins.extract.pipeline.ExtractMedia` with any requested filters
+            applied
+        """
+        if not self._filter:
             return
         ret_faces = list()
         for idx, detect_face in enumerate(extract_media.detected_faces):
             check_item = detect_face["face"] if isinstance(detect_face, dict) else detect_face
             check_item.load_aligned(extract_media.image)
-            if not self.filter.check(check_item):
+            if not self._filter.check(check_item):
                 logger.verbose("Skipping not recognized face: (Frame: %s Face %s)",
                                extract_media.filename, idx)
                 continue
diff --git a/tools/mask.py b/tools/mask.py
index b276a67..b866cb4 100644
--- a/tools/mask.py
+++ b/tools/mask.py
@@ -21,7 +21,7 @@ logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 class Mask():
     """ This tool is part of the Faceswap Tools suite and should be called from
-    ``python tools.py mask``.
+    ``python tools.py mask`` command.
 
     Faceswap Masks tool. Generate masks from existing alignments files, and output masks
     for preview.
@@ -375,7 +375,7 @@ class Mask():
               - The masked face
         """
         mask = detected_face.mask[self._mask_type]
-        mask.set_blur_kernel_and_threshold(**self._output_opts)
+        mask.set_blur_and_threshold(**self._output_opts)
         if not self._output_full_frame or self._input_is_faces:
             if self._input_is_faces:
                 face = detected_face.image
diff --git a/tools/preview.py b/tools/preview.py
index 2c25ba7..7040732 100644
--- a/tools/preview.py
+++ b/tools/preview.py
@@ -1,5 +1,5 @@
 #!/usr/bin/env python3
-""" Tool to preview swaps and tweak the config prior to running a convert """
+""" Tool to preview swaps and tweak configuration prior to running a convert """
 
 import logging
 import random
@@ -16,13 +16,11 @@ from PIL import Image, ImageTk
 
 from lib.aligner import Extract as AlignerExtract
 from lib.cli import ConvertArgs
-from lib.gui.custom_widgets import ContextMenu
 from lib.gui.utils import get_images, initialize_config, initialize_images
 from lib.gui.custom_widgets import Tooltip
-from lib.gui.control_helper import set_slider_rounding
+from lib.gui.control_helper import ControlPanel, ControlPanelOption
 from lib.convert import Converter
 from lib.faces_detect import DetectedFace
-from lib.model.masks import get_available_masks
 from lib.multithreading import MultiThread
 from lib.utils import FaceswapError
 from lib.queue_manager import queue_manager
@@ -35,159 +33,236 @@ from plugins.convert._config import Config
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
-class Preview():
-    """ Loads up 5 semi-random face swaps and displays them, cropped, in place in the final frame.
-        Allows user to live tweak settings, before saving the final config to
-        ./config/convert.ini """
+class Preview(tk.Tk):  # pylint:disable=too-few-public-methods
+    """ This tool is part of the Faceswap Tools suite and should be called from
+    ``python tools.py preview`` command.
+
+    Loads up 5 semi-random face swaps and displays them, cropped, in place in the final frame.
+    Allows user to live tweak settings, before saving the final config to
+    :file:`./config/convert.ini`
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The :mod:`argparse` arguments as passed in from :mod:`tools.py`
+    """
 
     def __init__(self, arguments):
         logger.debug("Initializing %s: (arguments: '%s'", self.__class__.__name__, arguments)
-        self.config_tools = ConfigTools()
-        self.lock = Lock()
-        self.trigger_patch = Event()
-
-        self.root = tk.Tk()
-        self.scaling = self.get_scaling()
+        super().__init__()
+        self._config_tools = ConfigTools()
+        self._lock = Lock()
+        self._scaling = self._get_scaling()
 
-        self.tk_vars = dict(refresh=tk.BooleanVar(), busy=tk.BooleanVar())
-        for val in self.tk_vars.values():
+        self._tk_vars = dict(refresh=tk.BooleanVar(), busy=tk.BooleanVar())
+        for val in self._tk_vars.values():
             val.set(False)
-        self.display = FacesDisplay(256, 64, self.tk_vars)
-        self.samples = Samples(arguments, 5, self.display, self.lock, self.trigger_patch)
-        self.patch = Patch(arguments,
-                           self.samples,
-                           self.display,
-                           self.lock,
-                           self.trigger_patch,
-                           self.config_tools,
-                           self.tk_vars)
-
-        self.initialize_tkinter()
-        self.image_canvas = None
-        self.opts_book = None
-        self.cli_frame = None  # cli frame holds cli options
+        self._display = FacesDisplay(256, 64, self._tk_vars)
+
+        trigger_patch = Event()
+        self._samples = Samples(arguments, 5, self._display, self._lock, trigger_patch)
+        self._patch = Patch(arguments,
+                            self._samples,
+                            self._display,
+                            self._lock,
+                            trigger_patch,
+                            self._config_tools,
+                            self._tk_vars)
+
+        self._initialize_tkinter()
+        self._image_canvas = None
+        self._opts_book = None
+        self._cli_frame = None  # cli frame holds cli options
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def initialize_tkinter(self):
-        """ Initialize tkinter for standalone or GUI """
+    def _initialize_tkinter(self):
+        """ Initialize a standalone tkinter instance. """
         logger.debug("Initializing tkinter")
-        initialize_config(self.root, None, None, None)
+        initialize_config(self, None, None, None)
         initialize_images()
-        self.set_geometry()
-        self.root.title("Faceswap.py - Convert Settings")
-        self.root.tk.call(
+        self._set_geometry()
+        self.title("Faceswap.py - Convert Settings")
+        self.tk.call(
             "wm",
             "iconphoto",
-            self.root._w, get_images().icons["favicon"])  # pylint:disable=protected-access
+            self._w, get_images().icons["favicon"])  # pylint:disable=protected-access
         logger.debug("Initialized tkinter")
 
-    def get_scaling(self):
-        """ Get dpi and update scaling for the display """
-        dpi = self.root.winfo_fpixels("1i")
+    def _get_scaling(self):
+        """ Get dpi and update scaling for the display.
+
+        Returns
+        -------
+        float: The scaling factor for display
+        """
+        dpi = self.winfo_fpixels("1i")
         scaling = dpi / 72.0
         logger.debug("dpi: %s, scaling: %s'", dpi, scaling)
         return scaling
 
-    def set_geometry(self):
-        """ Set GUI geometry """
-        self.root.tk.call("tk", "scaling", self.scaling)
-        width = int(940 * self.scaling)
-        height = int(600 * self.scaling)
+    def _set_geometry(self):
+        """ Set the GUI window geometry. """
+        self.tk.call("tk", "scaling", self._scaling)
+        width = int(940 * self._scaling)
+        height = int(600 * self._scaling)
         logger.debug("Geometry: %sx%s", width, height)
-        self.root.geometry("{}x{}+80+80".format(str(width), str(height)))
+        self.geometry("{}x{}+80+80".format(str(width), str(height)))
 
     def process(self):
-        """ The preview process """
-        self.build_ui()
-        self.root.mainloop()
+        """ The entry point for the Preview tool from :file:`lib.tools.cli`.
+
+        Launch the tkinter preview Window and run main loop.
+        """
+        self._build_ui()
+        self.mainloop()
 
-    def refresh(self, *args):
-        """ Refresh the display """
+    def _refresh(self, *args):
+        """ Load new faces to display in preview.
+
+        Parameters
+        ----------
+        *args: tuple
+            Unused, but required for tkinter callback.
+        """
         logger.trace("Refreshing swapped faces. args: %s", args)
-        self.tk_vars["busy"].set(True)
-        self.config_tools.update_config()
-        with self.lock:
-            self.patch.converter_arguments = self.cli_frame.convert_args
-            self.patch.current_config = self.config_tools.config
-        self.patch.trigger.set()
+        self._tk_vars["busy"].set(True)
+        self._config_tools.update_config()
+        with self._lock:
+            self._patch.converter_arguments = self._cli_frame.convert_args
+            self._patch.current_config = self._config_tools.config
+        self._patch.trigger.set()
         logger.trace("Refreshed swapped faces")
 
-    def build_ui(self):
-        """ Build the UI elements for displaying preview and options """
-        container = tk.PanedWindow(self.root,
+    def _build_ui(self):
+        """ Build the elements for displaying preview images and options panels. """
+        container = tk.PanedWindow(self,
                                    sashrelief=tk.RIDGE,
                                    sashwidth=4,
                                    sashpad=8,
                                    orient=tk.VERTICAL)
         container.pack(fill=tk.BOTH, expand=True)
-        container.preview_display = self.display
-        self.image_canvas = ImagesCanvas(container, self.tk_vars)
-        container.add(self.image_canvas, height=400 * self.scaling)
+        container.preview_display = self._display
+        self._image_canvas = ImagesCanvas(container, self._tk_vars)
+        container.add(self._image_canvas, height=400 * self._scaling)
 
         options_frame = ttk.Frame(container)
-        self.cli_frame = ActionFrame(options_frame,
-                                     self.patch.converter.args.color_adjustment.replace("-", "_"),
-                                     self.patch.converter.args.mask_type.replace("-", "_"),
-                                     self.patch.converter.args.scaling.replace("-", "_"),
-                                     self.config_tools,
-                                     self.refresh,
-                                     self.samples.generate,
-                                     self.tk_vars)
-        self.opts_book = OptionsBook(options_frame, self.config_tools, self.refresh, self.scaling)
+        self._cli_frame = ActionFrame(
+            options_frame,
+            list(self._samples.alignments.mask_summary.keys()),
+            self._samples.predictor.has_predicted_mask,
+            self._patch.converter.cli_arguments.color_adjustment.replace("-", "_"),
+            self._patch.converter.cli_arguments.mask_type.replace("-", "_"),
+            self._patch.converter.cli_arguments.scaling.replace("-", "_"),
+            self._config_tools,
+            self._refresh,
+            self._samples.generate,
+            self._tk_vars)
+        self._opts_book = OptionsBook(options_frame,
+                                      self._config_tools,
+                                      self._refresh,
+                                      self._scaling)
         container.add(options_frame)
 
 
 class Samples():
-    """ Holds 5 random test faces """
+    """ The display samples.
+
+    Obtains and holds :attr:`sample_size` semi random test faces for displaying in the
+    preview GUI.
+
+    The file list is split into evenly sized groups of :attr:`sample_size`. When a display set is
+    generated, a random image from each of the groups is selected to provide an array of images
+    across the length of the video.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The :mod:`argparse` arguments as passed in from :mod:`tools.py`
+    sample_size: int
+        The number of samples to take from the input video/images
+    display: :class:`FacesDisplay`
+        The display section of the Preview GUI.
+    lock: :class:`threading.Lock`
+        A threading lock to prevent multiple GUI updates at the same time.
+    trigger_patch:  :class:`threading.Event`
+        An event to indicate that a converter patch should be run
+    """
 
     def __init__(self, arguments, sample_size, display, lock, trigger_patch):
         logger.debug("Initializing %s: (arguments: '%s', sample_size: %s, display: %s, lock: %s, "
                      "trigger_patch: %s)", self.__class__.__name__, arguments, sample_size,
                      display, lock, trigger_patch)
-        self.sample_size = sample_size
-        self.display = display
-        self.lock = lock
-        self.trigger_patch = trigger_patch
-        self.input_images = list()
-        self.predicted_images = list()
-
-        self.images = Images(arguments)
-        self.alignments = Alignments(arguments,
-                                     is_extract=False,
-                                     input_is_video=self.images.is_video)
-        if not self.alignments.have_alignments_file:
-            logger.error("Alignments file not found at: '%s'", self.alignments.file)
+        self._sample_size = sample_size
+        self._display = display
+        self._lock = lock
+        self._trigger_patch = trigger_patch
+        self._input_images = list()
+        self._predicted_images = list()
+
+        self._images = Images(arguments)
+        self._alignments = Alignments(arguments,
+                                      is_extract=False,
+                                      input_is_video=self._images.is_video)
+        if not self._alignments.have_alignments_file:
+            logger.error("Alignments file not found at: '%s'", self._alignments.file)
             exit(1)
-        self.filelist = self.get_filelist()
-        self.indices = self.get_indices()
+        self._filelist = self._get_filelist()
+        self._indices = self._get_indices()
 
-        self.predictor = Predict(queue_manager.get_queue("preview_predict_in"),
-                                 sample_size,
-                                 arguments)
+        self._predictor = Predict(queue_manager.get_queue("preview_predict_in"),
+                                  sample_size,
+                                  arguments)
         self.generate()
 
         logger.debug("Initialized %s", self.__class__.__name__)
 
     @property
-    def random_choice(self):
-        """ Return for random indices from the indices group """
-        retval = [random.choice(indices) for indices in self.indices]
+    def sample_size(self):
+        """ int: The number of samples to take from the input video/images """
+        return self._sample_size
+
+    @property
+    def predicted_images(self):
+        """ list: The predicted faces output from the Faceswap model """
+        return self._predicted_images
+
+    @property
+    def alignments(self):
+        """ :class:`~lib.alignments.Alignments`: The alignments for the preview faces """
+        return self._alignments
+
+    @property
+    def predictor(self):
+        """ :class:`~scripts.convert.Predict`: The Predictor for the Faceswap model """
+        return self._predictor
+
+    @property
+    def _random_choice(self):
+        """ list: Random indices from the :attr:`_indices` group """
+        retval = [random.choice(indices) for indices in self._indices]
         logger.debug(retval)
         return retval
 
-    def get_filelist(self):
-        """ Return a list of files, filtering out those frames which do not contain faces """
+    def _get_filelist(self):
+        """ Get a list of files for the input, filtering out those frames which do
+        not contain faces.
+
+        Returns
+        -------
+        list
+            A list of filenames of frames that contain faces.
+        """
         logger.debug("Filtering file list to frames with faces")
-        if self.images.is_video:
-            filelist = ["{}_{:06d}.png".format(os.path.splitext(self.images.input_images)[0],
+        if self._images.is_video:
+            filelist = ["{}_{:06d}.png".format(os.path.splitext(self._images.input_images)[0],
                                                frame_no)
-                        for frame_no in range(1, self.images.images_found + 1)]
+                        for frame_no in range(1, self._images.images_found + 1)]
         else:
-            filelist = self.images.input_images
+            filelist = self._images.input_images
 
         retval = [filename for filename in filelist
-                  if self.alignments.frame_has_faces(os.path.basename(filename))]
-        logger.debug("Filtered out frames: %s", self.images.images_found - len(retval))
+                  if self._alignments.frame_has_faces(os.path.basename(filename))]
+        logger.debug("Filtered out frames: %s", self._images.images_found - len(retval))
         try:
             assert retval
         except AssertionError as err:
@@ -197,18 +272,26 @@ class Samples():
             raise FaceswapError(msg) from err
         return retval
 
-    def get_indices(self):
-        """ Returns a list of 'self.sample_size' evenly sized partition indices
-            pertaining to the filtered file list """
+    def _get_indices(self):
+        """ Get indices for each sample group.
+
+        Obtain :attr:`self.sample_size` evenly sized groups of indices
+        pertaining to the filtered :attr:`self._file_list`
+
+        Returns
+        -------
+        list
+            list of indices relating to the filtered file list, split into groups
+        """
         # Remove start and end values to get a list divisible by self.sample_size
-        no_files = len(self.filelist)
-        crop = no_files % self.sample_size
+        no_files = len(self._filelist)
+        crop = no_files % self._sample_size
         top_tail = list(range(no_files))[
             crop // 2:no_files - (crop - (crop // 2))]
         # Partition the indices
         size = len(top_tail)
-        retval = [top_tail[start:start + size // self.sample_size]
-                  for start in range(0, size, size // self.sample_size)]
+        retval = [top_tail[start:start + size // self._sample_size]
+                  for start in range(0, size, size // self._sample_size)]
         logger.debug("Indices pools: %s", ["{}: (start: {}, end: {}, size: {})".format(idx,
                                                                                        min(pool),
                                                                                        max(pool),
@@ -217,87 +300,152 @@ class Samples():
         return retval
 
     def generate(self):
-        """ Generate a random test set """
-        self.load_frames()
-        self.predict()
-        self.trigger_patch.set()
-
-    def load_frames(self):
-        """ Load a sample of random frames """
-        self.input_images = list()
-        for selection in self.random_choice:
-            filename = os.path.basename(self.filelist[selection])
-            image = self.images.load_one_image(self.filelist[selection])
+        """ Generate a sample set.
+
+        Selects :attr:`sample_size` random faces. Runs them through prediction to obtain the
+        swap, then trigger the patch event to run the faces through patching.
+        """
+        self._load_frames()
+        self._predict()
+        self._trigger_patch.set()
+
+    def _load_frames(self):
+        """ Load a sample of random frames.
+
+        * Picks a random face from each indices group.
+
+        * Takes the first face from the image (if there) are multiple faces. Adds the images to \
+            :attr:`self._input_images`.
+
+        * Sets :attr:`_display.source` to the input images and flags that the display should \
+            be updated
+        """
+        self._input_images = list()
+        for selection in self._random_choice:
+            filename = os.path.basename(self._filelist[selection])
+            image = self._images.load_one_image(self._filelist[selection])
             # Get first face only
-            face = self.alignments.get_faces_in_frame(filename)[0]
+            face = self._alignments.get_faces_in_frame(filename)[0]
             detected_face = DetectedFace()
             detected_face.from_alignment(face, image=image)
-            self.input_images.append({"filename": filename,
-                                      "image": image,
-                                      "detected_faces": [detected_face]})
-        self.display.source = self.input_images
-        self.display.update_source = True
-        logger.debug("Selected frames: %s", [frame["filename"] for frame in self.input_images])
-
-    def predict(self):
-        """ Predict from the loaded frames """
-        with self.lock:
-            self.predicted_images = list()
-            for frame in self.input_images:
-                self.predictor.in_queue.put(frame)
+            self._input_images.append({"filename": filename,
+                                       "image": image,
+                                       "detected_faces": [detected_face]})
+        self._display.source = self._input_images
+        self._display.update_source = True
+        logger.debug("Selected frames: %s", [frame["filename"] for frame in self._input_images])
+
+    def _predict(self):
+        """ Predict from the loaded frames.
+
+        With a threading lock (to prevent stacking), run the selected faces through the Faceswap
+        model predict function and add the output to :attr:`predicted`
+        """
+        with self._lock:
+            self._predicted_images = list()
+            for frame in self._input_images:
+                self._predictor.in_queue.put(frame)
             idx = 0
-            while idx < self.sample_size:
-                logger.debug("Predicting face %s of %s", idx + 1, self.sample_size)
-                items = self.predictor.out_queue.get()
+            while idx < self._sample_size:
+                logger.debug("Predicting face %s of %s", idx + 1, self._sample_size)
+                items = self._predictor.out_queue.get()
                 if items == "EOF":
                     logger.debug("Received EOF")
                     break
                 for item in items:
-                    self.predicted_images.append(item)
-                    logger.debug("Predicted face %s of %s", idx + 1, self.sample_size)
+                    self._predicted_images.append(item)
+                    logger.debug("Predicted face %s of %s", idx + 1, self._sample_size)
                     idx += 1
         logger.debug("Predicted faces")
 
 
 class Patch():
-    """ The patch pipeline
-        To be run within it's own thread """
+    """ The Patch pipeline
+
+    Runs in it's own thread. Takes the output from the Faceswap model predictor and runs the faces
+    through the convert pipeline using the currently selected options.
+
+    Parameters
+    ----------
+    arguments: :class:`argparse.Namespace`
+        The :mod:`argparse` arguments as passed in from :mod:`tools.py`
+    samples: :class:`Samples`
+        The Samples for display.
+    display: :class:`FacesDisplay`
+        The display section of the Preview GUI.
+    lock: :class:`threading.Lock`
+        A threading lock to prevent multiple GUI updates at the same time.
+    trigger:  :class:`threading.Event`
+        An event to indicate that a converter patch should be run
+    config_tools: :class:`ConfigTools`
+        Tools for loading and saving configuration files
+    tk_vars: dict
+        Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+
+    Attributes
+    ----------
+    converter_arguments: dict
+        The currently selected converter command line arguments for the patch queue
+    current_config::class:`lib.config.FaceswapConfig`
+        The currently set configuration for the patch queue
+    """
     def __init__(self, arguments, samples, display, lock, trigger, config_tools, tk_vars):
         logger.debug("Initializing %s: (arguments: '%s', samples: %s: display: %s, lock: %s,"
                      " trigger: %s, config_tools: %s, tk_vars %s)", self.__class__.__name__,
                      arguments, samples, display, lock, trigger, config_tools, tk_vars)
-        self.samples = samples
-        self.queue_patch_in = queue_manager.get_queue("preview_patch_in")
-        self.display = display
-        self.lock = lock
-        self.trigger = trigger
+        self._samples = samples
+        self._queue_patch_in = queue_manager.get_queue("preview_patch_in")
+        self._display = display
+        self._lock = lock
+        self._trigger = trigger
         self.current_config = config_tools.config
         self.converter_arguments = None  # Updated converter arguments dict
 
         configfile = arguments.configfile if hasattr(arguments, "configfile") else None
-        self.converter = Converter(output_dir=None,
-                                   output_size=self.samples.predictor.output_size,
-                                   output_has_mask=self.samples.predictor.has_predicted_mask,
-                                   draw_transparent=False,
-                                   pre_encode=None,
-                                   configfile=configfile,
-                                   arguments=self.generate_converter_arguments(arguments))
-
-        self.shutdown = Event()
-
-        self.thread = MultiThread(self.process,
-                                  self.trigger,
-                                  self.shutdown,
-                                  self.queue_patch_in,
-                                  self.samples,
-                                  tk_vars,
-                                  thread_count=1,
-                                  name="patch_thread")
-        self.thread.start()
+        self._converter = Converter(output_size=self._samples.predictor.output_size,
+                                    coverage_ratio=self._samples.predictor.coverage_ratio,
+                                    draw_transparent=False,
+                                    pre_encode=None,
+                                    arguments=self._generate_converter_arguments(arguments),
+                                    configfile=configfile)
+        self._shutdown = Event()
+
+        self._thread = MultiThread(self._process,
+                                   self._trigger,
+                                   self._shutdown,
+                                   self._queue_patch_in,
+                                   self._samples,
+                                   tk_vars,
+                                   thread_count=1,
+                                   name="patch_thread")
+        self._thread.start()
+
+    @property
+    def trigger(self):
+        """ :class:`threading.Event`: The trigger to indicate that a patching run should
+        commence. """
+        return self._trigger
+
+    @property
+    def converter(self):
+        """ :class:`lib.convert.Converter`: The converter to use for patching the images. """
+        return self._converter
 
     @staticmethod
-    def generate_converter_arguments(arguments):
-        """ Get the default converter arguments """
+    def _generate_converter_arguments(arguments):
+        """ Add the default converter arguments to the initial arguments.
+
+        Parameters
+        ----------
+        arguments: :class:`argparse.Namespace`
+            The :mod:`argparse` arguments as passed in from :mod:`tools.py`
+
+        Returns
+        ----------
+        arguments: :class:`argparse.Namespace`
+            The :mod:`argparse` arguments as passed in with converter default
+            arguments added
+        """
         converter_arguments = ConvertArgs(None, "convert").get_optional_arguments()
         for item in converter_arguments:
             value = item.get("default", None)
@@ -313,8 +461,25 @@ class Patch():
         logger.debug(arguments)
         return arguments
 
-    def process(self, trigger_event, shutdown_event, patch_queue_in, samples, tk_vars):
-        """ Wait for event trigger and run when process when set """
+    def _process(self, trigger_event, shutdown_event, patch_queue_in, samples, tk_vars):
+        """ The face patching process.
+
+        Runs in a thread, and waits for an event to be set. Once triggered, runs a patching
+        cycle and sets the :class:`Display` destination images.
+
+        Parameters
+        ----------
+        trigger_event: :class:`threading.Event`
+            Set by parent process when a patching run should be executed
+        shutdown_event :class:`threading.Event`
+            Set by parent process if a shutdown has been requested
+        patch_queue_in: :class:`queue.Queue`
+            The input queue for the patching process
+        samples: :class:`Samples`
+            The Samples for display.
+        tk_vars: dict
+            Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+        """
         patch_queue_out = queue_manager.get_queue("preview_patch_out")
         while True:
             trigger = trigger_event.wait(1)
@@ -327,30 +492,38 @@ class Patch():
             trigger_event.clear()
             tk_vars["busy"].set(True)
             queue_manager.flush_queue("preview_patch_in")
-            self.feed_swapped_faces(patch_queue_in, samples)
-            with self.lock:
-                self.update_converter_arguments()
-                self.converter.reinitialize(config=self.current_config)
-            swapped = self.patch_faces(patch_queue_in, patch_queue_out, samples.sample_size)
-            with self.lock:
-                self.display.destination = swapped
+            self._feed_swapped_faces(patch_queue_in, samples)
+            with self._lock:
+                self._update_converter_arguments()
+                self._converter.reinitialize(config=self.current_config)
+            swapped = self._patch_faces(patch_queue_in, patch_queue_out, samples.sample_size)
+            with self._lock:
+                self._display.destination = swapped
             tk_vars["refresh"].set(True)
             tk_vars["busy"].set(False)
 
-    def update_converter_arguments(self):
-        """ Update the converter arguments """
+    def _update_converter_arguments(self):
+        """ Update the converter arguments to the currently selected values. """
         logger.debug("Updating Converter cli arguments")
         if self.converter_arguments is None:
             logger.debug("No arguments to update")
             return
         for key, val in self.converter_arguments.items():
             logger.debug("Updating %s to %s", key, val)
-            setattr(self.converter.args, key, val)
+            setattr(self._converter.cli_arguments, key, val)
         logger.debug("Updated Converter cli arguments")
 
     @staticmethod
-    def feed_swapped_faces(patch_queue_in, samples):
-        """ Feed swapped faces to the converter and trigger a run """
+    def _feed_swapped_faces(patch_queue_in, samples):
+        """ Feed swapped faces to the converter's in-queue.
+
+        Parameters
+        ----------
+        patch_queue_in: :class:`queue.Queue`
+            The input queue for the patching process
+        samples: :class:`Samples`
+            The Samples for display.
+        """
         logger.trace("feeding swapped faces to converter")
         for item in samples.predicted_images:
             patch_queue_in.put(item)
@@ -358,10 +531,25 @@ class Patch():
         logger.trace("Putting EOF to converter")
         patch_queue_in.put("EOF")
 
-    def patch_faces(self, queue_in, queue_out, sample_size):
-        """ Patch faces """
+    def _patch_faces(self, queue_in, queue_out, sample_size):
+        """ Patch faces.
+
+        Run the convert process on the swapped faces and return the patched faces.
+
+        patch_queue_in: :class:`queue.Queue`
+            The input queue for the patching process
+        queue_out: :class:`queue.Queue`
+            The output queue from the patching process
+        sample_size: int
+            The number of samples to be displayed
+
+        Returns
+        -------
+        list
+            The swapped faces patched with the selected convert settings
+        """
         logger.trace("Patching faces")
-        self.converter.process(queue_in, queue_out)
+        self._converter.process(queue_in, queue_out)
         swapped = list()
         idx = 0
         while idx < sample_size:
@@ -375,14 +563,40 @@ class Patch():
 
 
 class FacesDisplay():
-    """ Compiled faces into a single image """
+    """ Compiles the 2 rows of sample faces (original and swapped) into a single image
+
+    Parameters
+    ----------
+    size: int
+        The size of each individual face sample in pixels
+    padding: int
+        The amount of extra padding to apply to the outside of the face
+    tk_vars: dict
+        Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+
+    Attributes
+    ----------
+    update_source: bool
+        Flag to indicate that the source images for the preview have been updated, so the preview
+        should be recompiled.
+    source: list
+        The list of :class:`numpy.ndarray` source preview images for top row of display
+    destination: list
+        The list of :class:`numpy.ndarray` swapped and patched preview images for bottom row of
+        display
+    """
     def __init__(self, size, padding, tk_vars):
         logger.trace("Initializing %s: (size: %s, padding: %s, tk_vars: %s)",
                      self.__class__.__name__, size, padding, tk_vars)
-        self.size = size
-        self.display_dims = (1, 1)
-        self.tk_vars = tk_vars
-        self.padding = padding
+        self._size = size
+        self._display_dims = (1, 1)
+        self._tk_vars = tk_vars
+        self._padding = padding
+
+        self._faces = dict()
+        self._faces_source = None
+        self._faces_dest = None
+        self._tk_image = None
 
         # Set from Samples
         self.update_source = False
@@ -390,118 +604,152 @@ class FacesDisplay():
         # Set from Patch
         self.destination = list()  # Swapped + patched images
 
-        self.faces = dict()
-        self.faces_source = None
-        self.faces_dest = None
-        self.tk_image = None
         logger.trace("Initialized %s", self.__class__.__name__)
 
     @property
-    def total_columns(self):
+    def tk_image(self):
+        """ :class:`PIL.ImageTk.PhotoImage`: The compiled preview display in tkinter display
+        format """
+        return self._tk_image
+
+    @property
+    def _total_columns(self):
         """ Return the total number of images that are being displayed """
         return len(self.source)
 
+    def set_display_dimensions(self, dimensions):
+        """ Adjust the size of the frame that will hold the preview samples.
+
+        Parameters
+        ----------
+        dimensions: tuple
+            The (`width`, `height`) of the frame that holds the preview
+        """
+        self._display_dims = dimensions
+
     def update_tk_image(self):
-        """ Return compiled images images in TK PIL format resized for frame """
+        """ Build the full preview images and compile :attr:`tk_image` for display. """
         logger.trace("Updating tk image")
-        self.build_faces_image()
-        img = np.vstack((self.faces_source, self.faces_dest))
-        size = self.get_scale_size(img)
+        self._build_faces_image()
+        img = np.vstack((self._faces_source, self._faces_dest))
+        size = self._get_scale_size(img)
         img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
         img = Image.fromarray(img)
         img = img.resize(size, Image.ANTIALIAS)
-        self.tk_image = ImageTk.PhotoImage(img)
-        self.tk_vars["refresh"].set(False)
+        self._tk_image = ImageTk.PhotoImage(img)
+        self._tk_vars["refresh"].set(False)
         logger.trace("Updated tk image")
 
-    def get_scale_size(self, image):
-        """ Return the scale and size for passed in display image """
-        frameratio = float(self.display_dims[0]) / float(self.display_dims[1])
+    def _get_scale_size(self, image):
+        """ Get the size that the full preview image should be resized to fit in the
+        display window.
+
+        Parameters
+        ----------
+        image: :class:`numpy.ndarray`
+            The full sized compiled preview image
+
+        Returns
+        -------
+        tuple
+            The (`width`, `height`) that the display image should be sized to fit in the display
+            window
+        """
+        frameratio = float(self._display_dims[0]) / float(self._display_dims[1])
         imgratio = float(image.shape[1]) / float(image.shape[0])
 
         if frameratio <= imgratio:
-            scale = self.display_dims[0] / float(image.shape[1])
-            size = (self.display_dims[0], max(1, int(image.shape[0] * scale)))
+            scale = self._display_dims[0] / float(image.shape[1])
+            size = (self._display_dims[0], max(1, int(image.shape[0] * scale)))
         else:
-            scale = self.display_dims[1] / float(image.shape[0])
-            size = (max(1, int(image.shape[1] * scale)), self.display_dims[1])
+            scale = self._display_dims[1] / float(image.shape[0])
+            size = (max(1, int(image.shape[1] * scale)), self._display_dims[1])
         logger.trace("scale: %s, size: %s", scale, size)
         return size
 
-    def build_faces_image(self):
-        """ Display associated faces """
+    def _build_faces_image(self):
+        """ Compile the source and destination rows of the preview image. """
         logger.trace("Building Faces Image")
         update_all = self.update_source
-        self.faces_from_frames()
+        self._faces_from_frames()
         if update_all:
-            header = self.header_text()
-            source = np.hstack([self.draw_rect(face) for face in self.faces["src"]])
-            self.faces_source = np.vstack((header, source))
-        self.faces_dest = np.hstack([self.draw_rect(face) for face in self.faces["dst"]])
+            header = self._header_text()
+            source = np.hstack([self._draw_rect(face) for face in self._faces["src"]])
+            self._faces_source = np.vstack((header, source))
+        self._faces_dest = np.hstack([self._draw_rect(face) for face in self._faces["dst"]])
         logger.debug("source row shape: %s, swapped row shape: %s",
-                     self.faces_dest.shape, self.faces_source.shape)
+                     self._faces_dest.shape, self._faces_source.shape)
 
-    def faces_from_frames(self):
-        """ Compile faces from the original images and return a row for each of source and dest """
+    def _faces_from_frames(self):
+        """ Extract the preview faces from the source frames and apply the requisite padding. """
         logger.debug("Extracting faces from frames: Number images: %s", len(self.source))
         if self.update_source:
-            self.crop_source_faces()
-        self.crop_destination_faces()
-        logger.debug("Extracted faces from frames: %s", {k: len(v) for k, v in self.faces.items()})
-
-    def crop_source_faces(self):
-        """ Update the main faces dict with new source faces and matrices """
+            self._crop_source_faces()
+        self._crop_destination_faces()
+        logger.debug("Extracted faces from frames: %s",
+                     {k: len(v) for k, v in self._faces.items()})
+
+    def _crop_source_faces(self):
+        """ Extract the source faces from the source frames, along with their filenames and the
+        transformation matrix used to extract the faces. """
         logger.debug("Updating source faces")
-        self.faces = dict()
+        self._faces = dict()
         for image in self.source:
             detected_face = image["detected_faces"][0]
             src_img = image["image"]
-            detected_face.load_aligned(src_img, self.size)
+            detected_face.load_aligned(src_img, self._size)
             matrix = detected_face.aligned["matrix"]
-            self.faces.setdefault("filenames",
-                                  list()).append(os.path.splitext(image["filename"])[0])
-            self.faces.setdefault("matrix", list()).append(matrix)
-            self.faces.setdefault("src", list()).append(AlignerExtract().transform(
+            self._faces.setdefault("filenames",
+                                   list()).append(os.path.splitext(image["filename"])[0])
+            self._faces.setdefault("matrix", list()).append(matrix)
+            self._faces.setdefault("src", list()).append(AlignerExtract().transform(
                 src_img,
                 matrix,
-                self.size,
-                self.padding))
+                self._size,
+                self._padding))
         self.update_source = False
         logger.debug("Updated source faces")
 
-    def crop_destination_faces(self):
-        """ Update the main faces dict with new destination faces based on source matrices """
+    def _crop_destination_faces(self):
+        """ Extract the swapped faces from the swapped frames using the source face destination
+        matrices. """
         logger.debug("Updating destination faces")
-        self.faces["dst"] = list()
+        self._faces["dst"] = list()
         destination = self.destination if self.destination else [np.ones_like(src["image"])
                                                                  for src in self.source]
         for idx, image in enumerate(destination):
-            self.faces["dst"].append(AlignerExtract().transform(
+            self._faces["dst"].append(AlignerExtract().transform(
                 image,
-                self.faces["matrix"][idx],
-                self.size,
-                self.padding))
+                self._faces["matrix"][idx],
+                self._size,
+                self._padding))
         logger.debug("Updated destination faces")
 
-    def header_text(self):
-        """ Create header text for output image """
-        font_scale = self.size / 640
-        height = self.size // 8
+    def _header_text(self):
+        """ Create the header text displaying the frame name for each preview column.
+
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The header row of the preview image containing the frame names for each column
+        """
+        font_scale = self._size / 640
+        height = self._size // 8
         font = cv2.FONT_HERSHEY_SIMPLEX
         # Get size of placed text for positioning
-        text_sizes = [cv2.getTextSize(self.faces["filenames"][idx],
+        text_sizes = [cv2.getTextSize(self._faces["filenames"][idx],
                                       font,
                                       font_scale,
                                       1)[0]
-                      for idx in range(self.total_columns)]
-        # Get X and Y co-ords for each text item
+                      for idx in range(self._total_columns)]
+        # Get X and Y co-ordinates for each text item
         text_y = int((height + text_sizes[0][1]) / 2)
-        text_x = [int((self.size - text_sizes[idx][0]) / 2) + self.size * idx
-                  for idx in range(self.total_columns)]
+        text_x = [int((self._size - text_sizes[idx][0]) / 2) + self._size * idx
+                  for idx in range(self._total_columns)]
         logger.debug("filenames: %s, text_sizes: %s, text_x: %s, text_y: %s",
-                     self.faces["filenames"], text_sizes, text_x, text_y)
-        header_box = np.ones((height, self.size * self.total_columns, 3), np.uint8) * 255
-        for idx, text in enumerate(self.faces["filenames"]):
+                     self._faces["filenames"], text_sizes, text_x, text_y)
+        header_box = np.ones((height, self._size * self._total_columns, 3), np.uint8) * 255
+        for idx, text in enumerate(self._faces["filenames"]):
             cv2.putText(header_box,
                         text,
                         (text_x[idx], text_y),
@@ -513,87 +761,147 @@ class FacesDisplay():
         logger.debug("header_box.shape: %s", header_box.shape)
         return header_box
 
-    def draw_rect(self, image):
-        """ draw border """
-        cv2.rectangle(image, (0, 0), (self.size - 1, self.size - 1), (255, 255, 255), 1)
+    def _draw_rect(self, image):
+        """ Place a white border around a given image.
+
+        Parameters
+        ----------
+        image: :class:`numpy.ndarray`
+            The image to place a border on to
+        Returns
+        -------
+        :class:`numpy.ndarray`
+            The given image with a border drawn around the outside
+        """
+        cv2.rectangle(image, (0, 0), (self._size - 1, self._size - 1), (255, 255, 255), 1)
         image = np.clip(image, 0.0, 255.0)
         return image.astype("uint8")
 
 
 class ConfigTools():
-    """ Saving and resetting config values and stores selected variables """
+    """ Tools for loading, saving, setting and retrieving configuration file values.
+
+    Attributes
+    ----------
+    tk_vars: dict
+        Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+    """
     def __init__(self):
-        self.config = Config(None)
-        self.config_dicts = self.get_config_dicts()  # Holds currently saved config
+        self._config = Config(None)
         self.tk_vars = dict()
+        self._config_dicts = self._get_config_dicts()  # Holds currently saved config
+
+    @property
+    def config(self):
+        """ :class:`plugins.convert._config.Config` The convert configuration """
+        return self._config
+
+    @property
+    def config_dicts(self):
+        """ dict: The convert configuration options in dictionary form."""
+        return self._config_dicts
 
     @property
     def sections(self):
-        """ Return the sorted unique section names from the configs """
-        return sorted(set(plugin.split(".")[0] for plugin in self.config.config.sections()
+        """ list: The sorted section names that exist within the convert Configuration options. """
+        return sorted(set(plugin.split(".")[0] for plugin in self._config.config.sections()
                           if plugin.split(".")[0] != "writer"))
 
     @property
     def plugins_dict(self):
-        """ Return dict of sections with sorted list of containing plugins """
-        return {section: sorted([plugin.split(".")[1] for plugin in self.config.config.sections()
+        """ dict: Dictionary of configuration option sections as key with a list of containing
+        plugins as the value """
+        return {section: sorted([plugin.split(".")[1] for plugin in self._config.config.sections()
                                  if plugin.split(".")[0] == section])
                 for section in self.sections}
 
     def update_config(self):
-        """ Update config with selected values """
+        """ Update :attr:`config` with the currently selected values from the GUI. """
         for section, items in self.tk_vars.items():
             for item, value in items.items():
                 try:
                     new_value = str(value.get())
                 except tk.TclError as err:
                     # When manually filling in text fields, blank values will
-                    # raise an error on numeric datatypes so return 0
+                    # raise an error on numeric data types so return 0
                     logger.debug("Error getting value. Defaulting to 0. Error: %s", str(err))
                     new_value = str(0)
-                old_value = self.config.config[section][item]
+                old_value = self._config.config[section][item]
                 if new_value != old_value:
                     logger.trace("Updating config: %s, %s from %s to %s",
                                  section, item, old_value, new_value)
-                    self.config.config[section][item] = new_value
-
-    def get_config_dicts(self):
-        """ Hold a custom config dict for the config """
+                    self._config.config[section][item] = new_value
+
+    def _get_config_dicts(self):
+        """ Obtain a custom configuration dictionary for convert configuration items in use
+        by the preview tool formatted for control helper.
+
+        Returns
+        -------
+        dict
+            Each configuration section as keys, with the values as a dict of option:
+            :class:`lib.gui.control_helper.ControlOption` pairs. """
+        logger.debug("Formatting Config for GUI")
         config_dicts = dict()
-        for section in self.config.config.sections():
-            if section == "writer":
+        for section in self._config.config.sections():
+            if section.startswith("writer."):
                 continue
-            default_dict = self.config.defaults[section]
-            for key in default_dict.keys():
+            for key, val in self._config.defaults[section].items():
                 if key == "helptext":
+                    config_dicts.setdefault(section, dict())[key] = val
                     continue
-                default_dict[key]["value"] = self.config.get(section, key)
-            config_dicts[section] = default_dict
+                cp_option = ControlPanelOption(title=key,
+                                               dtype=val["type"],
+                                               group=val["group"],
+                                               default=val["default"],
+                                               initial_value=self._config.get(section, key),
+                                               choices=val["choices"],
+                                               is_radio=val["gui_radio"],
+                                               rounding=val["rounding"],
+                                               min_max=val["min_max"],
+                                               helptext=val["helptext"])
+                self.tk_vars.setdefault(section, dict())[key] = cp_option.tk_var
+                config_dicts.setdefault(section, dict())[key] = cp_option
+        logger.debug("Formatted Config for GUI: %s", config_dicts)
         return config_dicts
 
-    def reset_config_saved(self, section=None):
-        """ Reset config to saved values """
+    def reset_config_to_saved(self, section=None):
+        """ Reset the GUI parameters to their saved values within the configuration file.
+
+        Parameters
+        ----------
+        section: str, optional
+            The configuration section to reset the values for, If ``None`` provided then all
+            sections are reset. Default: ``None``
+        """
         logger.debug("Resetting to saved config: %s", section)
         sections = [section] if section is not None else list(self.tk_vars.keys())
         for config_section in sections:
-            for item, options in self.config_dicts[config_section].items():
+            for item, options in self._config_dicts[config_section].items():
                 if item == "helptext":
                     continue
-                val = options["value"]
+                val = options.value
                 if val != self.tk_vars[config_section][item].get():
                     self.tk_vars[config_section][item].set(val)
                     logger.debug("Setting %s - %s to saved value %s", config_section, item, val)
         logger.debug("Reset to saved config: %s", section)
 
-    def reset_config_default(self, section=None):
-        """ Reset config to default values """
+    def reset_config_to_default(self, section=None):
+        """ Reset the GUI parameters to their default configuration values.
+
+        Parameters
+        ----------
+        section: str, optional
+            The configuration section to reset the values for, If ``None`` provided then all
+            sections are reset. Default: ``None``
+        """
         logger.debug("Resetting to default: %s", section)
         sections = [section] if section is not None else list(self.tk_vars.keys())
         for config_section in sections:
-            for item, options in self.config.defaults[config_section].items():
+            for item, options in self._config_dicts[config_section].items():
                 if item == "helptext":
                     continue
-                default = options["default"]
+                default = options.default
                 if default != self.tk_vars[config_section][item].get():
                     self.tk_vars[config_section][item].set(default)
                     logger.debug("Setting %s - %s to default value %s",
@@ -601,205 +909,388 @@ class ConfigTools():
         logger.debug("Reset to default: %s", section)
 
     def save_config(self, section=None):
-        """ Save config """
+        """ Save the configuration ``.ini`` file with the currently stored values.
+
+        Parameters
+        ----------
+        section: str, optional
+            The configuration section to save, If ``None`` provided then all sections are saved.
+            Default: ``None``
+        """
         logger.debug("Saving %s config", section)
         new_config = ConfigParser(allow_no_value=True)
-        for config_section, items in self.config_dicts.items():
+        for config_section, items in self._config_dicts.items():
             logger.debug("Adding section: '%s')", config_section)
-            self.config.insert_config_section(config_section, items["helptext"], config=new_config)
+            self._config.insert_config_section(config_section,
+                                               items["helptext"],
+                                               config=new_config)
             for item, options in items.items():
                 if item == "helptext":
                     continue
                 if ((section is not None and config_section != section)
                         or config_section not in self.tk_vars):
-                    new_opt = options["value"]  # Keep saved item for other sections
+                    new_opt = options.value  # Keep saved item for other sections
                     logger.debug("Retaining option: (item: '%s', value: '%s')", item, new_opt)
                 else:
                     new_opt = self.tk_vars[config_section][item].get()
                     logger.debug("Setting option: (item: '%s', value: '%s')", item, new_opt)
-                helptext = options["helptext"]
-                helptext = self.config.format_help(helptext, is_section=False)
+                    # Set config_dicts value to new saved value
+                    options.set_initial_value(new_opt)
+                helptext = self._config.format_help(options.helptext, is_section=False)
                 new_config.set(config_section, helptext)
                 new_config.set(config_section, item, str(new_opt))
-        self.config.config = new_config
-        self.config.save_config()
-        print("Saved config: '{}'".format(self.config.configfile))
-        # Update config dict to newly saved
-        self.config_dicts = self.get_config_dicts()
-        logger.debug("Saved config")
+        self._config.config = new_config
+        self._config.save_config()
+        logger.info("Saved config: '%s'", self._config.configfile)
 
 
 class ImagesCanvas(ttk.Frame):  # pylint:disable=too-many-ancestors
-    """ Canvas to hold the images """
+    """ tkinter Canvas that holds the preview images.
+
+    Parameters
+    ----------
+    parent: tkinter object
+        The parent tkinter object that holds the canvas
+    tk_vars: dict
+        Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+    """
     def __init__(self, parent, tk_vars):
         logger.debug("Initializing %s: (parent: %s,  tk_vars: %s)",
                      self.__class__.__name__, parent, tk_vars)
         super().__init__(parent)
         self.pack(expand=True, fill=tk.BOTH, padx=2, pady=2)
 
-        self.refresh_display_trigger = tk_vars["refresh"]
-        self.refresh_display_trigger.trace("w", self.refresh_display_callback)
-        self.display = parent.preview_display
-        self.canvas = tk.Canvas(self, bd=0, highlightthickness=0)
-        self.canvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
-        self.displaycanvas = self.canvas.create_image(0, 0,
-                                                      image=self.display.tk_image,
-                                                      anchor=tk.NW)
-        self.bind("<Configure>", self.resize)
+        self._refresh_display_trigger = tk_vars["refresh"]
+        self._refresh_display_trigger.trace("w", self._refresh_display_callback)
+        self._display = parent.preview_display
+        self._canvas = tk.Canvas(self, bd=0, highlightthickness=0)
+        self._canvas.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
+        self._displaycanvas = self._canvas.create_image(0, 0,
+                                                        image=self._display.tk_image,
+                                                        anchor=tk.NW)
+        self.bind("<Configure>", self._resize)
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def refresh_display_callback(self, *args):
+    def _refresh_display_callback(self, *args):
         """ Add a trace to refresh display on callback """
-        if not self.refresh_display_trigger.get():
+        if not self._refresh_display_trigger.get():
             return
         logger.trace("Refresh display trigger received: %s", args)
-        self.reload()
+        self._reload()
 
-    def resize(self, event):
-        """  Resize the image to fit the frame, maintaining aspect ratio """
+    def _resize(self, event):
+        """ Resize the image to fit the frame, maintaining aspect ratio """
         logger.trace("Resizing preview image")
         framesize = (event.width, event.height)
-        self.display.display_dims = framesize
-        self.reload()
+        self._display.set_display_dimensions(framesize)
+        self._reload()
 
-    def reload(self):
+    def _reload(self):
         """ Reload the preview image """
         logger.trace("Reloading preview image")
-        self.display.update_tk_image()
-        self.canvas.itemconfig(self.displaycanvas, image=self.display.tk_image)
+        self._display.update_tk_image()
+        self._canvas.itemconfig(self._displaycanvas, image=self._display.tk_image)
 
 
 class ActionFrame(ttk.Frame):  # pylint: disable=too-many-ancestors
-    """ Frame that holds the left hand side options panel """
-    def __init__(self, parent, selected_color, selected_mask_type, selected_scaling,
-                 config_tools, patch_callback, refresh_callback, tk_vars):
-        logger.debug("Initializing %s: (selected_color: %s, selected_mask_type: %s, "
-                     "selected_scaling: %s, config_tools, patch_callback: %s, "
-                     "refresh_callback: %s, tk_vars: %s)", self.__class__.__name__, selected_color,
+    """ Frame that holds the left hand side options panel containing the command line options.
+
+    Parameters
+    ----------
+    parent: tkinter object
+        The parent tkinter object that holds the Action Frame
+    available_masks: list
+        The available masks that exist within the alignments file
+    has_predicted_mask: bool
+        Whether the model was trained with a mask
+    selected_color: str
+        The selected color adjustment type
+    selected_mask_type: str
+        The selected mask type
+    selected_scaling: str
+        The selected scaling type
+    config_tools: :class:`ConfigTools`
+        Tools for loading and saving configuration files
+    patch_callback: python function
+        The function to execute when a patch callback is received
+    refresh_callback: python function
+        The function to execute when a refresh callback is received
+    tk_vars: dict
+        Global tkinter variables. `Refresh` and `Busy` :class:`tkinter.BooleanVar`
+    """
+    def __init__(self, parent, available_masks, has_predicted_mask, selected_color,
+                 selected_mask_type, selected_scaling, config_tools, patch_callback,
+                 refresh_callback, tk_vars):
+        logger.debug("Initializing %s: (available_masks: %s, has_predicted_mask: %s, "
+                     "selected_color: %s, selected_mask_type: %s, selected_scaling: %s, "
+                     "patch_callback: %s, refresh_callback: %s, tk_vars: %s)",
+                     self.__class__.__name__, available_masks, has_predicted_mask, selected_color,
                      selected_mask_type, selected_scaling, patch_callback, refresh_callback,
                      tk_vars)
-        self.config_tools = config_tools
+        self._config_tools = config_tools
 
         super().__init__(parent)
         self.pack(side=tk.LEFT, anchor=tk.N, fill=tk.Y)
-        self.options = ["color", "mask_type", "scaling"]
-        self.busy_tkvar = tk_vars["busy"]
-        self.tk_vars = dict()
+        self._options = ["color", "mask_type", "scaling"]
+        self._busy_tkvar = tk_vars["busy"]
+        self._tk_vars = dict()
 
         d_locals = locals()
-        defaults = {opt: self.format_to_display(d_locals["selected_{}".format(opt)])
-                    for opt in self.options}
-        self.busy_indicator = self.build_frame(defaults, refresh_callback, patch_callback)
+        defaults = {opt: self._format_to_display(d_locals["selected_{}".format(opt)])
+                    for opt in self._options}
+        self._busy_indicator = self._build_frame(defaults,
+                                                 refresh_callback,
+                                                 patch_callback,
+                                                 available_masks,
+                                                 has_predicted_mask)
 
     @property
     def convert_args(self):
-        """ Return a dict of cli arguments for converter based on selected options """
+        """ dict: Currently selected Command line arguments from the :class:`ActionFrame`. """
         return {opt if opt != "color" else "color_adjustment":
-                self.format_from_display(self.tk_vars[opt].get())
-                for opt in self.options}
+                self._format_from_display(self._tk_vars[opt].get())
+                for opt in self._options}
 
     @staticmethod
-    def format_from_display(var):
-        """ Format a variable from display version """
+    def _format_from_display(var):
+        """ Format a variable from the display version to the command line action version.
+
+        Parameters
+        ----------
+        var: str
+            The variable name to format
+
+        Returns
+        -------
+        str
+            The formatted variable name
+        """
         return var.replace(" ", "_").lower()
 
     @staticmethod
-    def format_to_display(var):
-        """ Format a variable from display version """
+    def _format_to_display(var):
+        """ Format a variable from the command line action version to the display version.
+        Parameters
+        ----------
+        var: str
+            The variable name to format
+
+        Returns
+        -------
+        str
+            The formatted variable name
+        """
         return var.replace("_", " ").replace("-", " ").title()
 
-    def build_frame(self, defaults, refresh_callback, patch_callback):
-        """ Build the action frame """
+    def _build_frame(self, defaults, refresh_callback, patch_callback,
+                     available_masks, has_predicted_mask):
+        """ Build the :class:`ActionFrame`.
+
+        Parameters
+        ----------
+        defaults: dict
+            The default command line options
+        patch_callback: python function
+            The function to execute when a patch callback is received
+        refresh_callback: python function
+            The function to execute when a refresh callback is received
+        available_masks: list
+            The available masks that exist within the alignments file
+        has_predicted_mask: bool
+            Whether the model was trained with a mask
+
+        Returns
+        -------
+        ttk.Progressbar
+            A Progress bar to indicate that the Preview tool is busy
+        """
         logger.debug("Building Action frame")
-        top_frame = ttk.Frame(self)
-        top_frame.pack(side=tk.TOP, fill=tk.BOTH, anchor=tk.N, expand=True)
+
         bottom_frame = ttk.Frame(self)
         bottom_frame.pack(side=tk.BOTTOM, fill=tk.X, anchor=tk.S)
+        top_frame = ttk.Frame(self)
+        top_frame.pack(side=tk.TOP, fill=tk.BOTH, anchor=tk.N, expand=True)
 
-        self.add_comboboxes(top_frame, defaults)
-        busy_indicator = self.add_busy_indicator(top_frame)
-        self.add_refresh_button(top_frame, refresh_callback)
-        self.add_patch_callback(patch_callback)
-        self.add_actions(bottom_frame)
+        self._add_cli_choices(top_frame, defaults, available_masks, has_predicted_mask)
+
+        busy_indicator = self._add_busy_indicator(bottom_frame)
+        self._add_refresh_button(bottom_frame, refresh_callback)
+        self._add_patch_callback(patch_callback)
+        self._add_actions(bottom_frame)
         logger.debug("Built Action frame")
         return busy_indicator
 
-    def add_comboboxes(self, parent, defaults):
-        """ Add the comboboxes to the Action Frame """
-        for opt in self.options:
+    def _add_cli_choices(self, parent, defaults, available_masks, has_predicted_mask):
+        """ Create :class:`lib.gui.control_helper.ControlPanel` object for the command
+        line options.
+
+        parent: :class:`ttk.Frame`
+            The frame to hold the command line choices
+        defaults: dict
+            The default command line options
+        available_masks: list
+            The available masks that exist within the alignments file
+        has_predicted_mask: bool
+            Whether the model was trained with a mask
+        """
+        cp_options = self._get_control_panel_options(defaults, available_masks, has_predicted_mask)
+        panel_kwargs = dict(blank_nones=False, label_width=10)
+        ControlPanel(parent, cp_options, header_text=None, **panel_kwargs)
+
+    def _get_control_panel_options(self, defaults, available_masks, has_predicted_mask):
+        """ Create :class:`lib.gui.control_helper.ControlPanelOption` objects for the command
+        line options.
+
+        defaults: dict
+            The default command line options
+        available_masks: list
+            The available masks that exist within the alignments file
+        has_predicted_mask: bool
+            Whether the model was trained with a mask
+
+        Returns
+        -------
+        list
+            The list of `lib.gui.control_helper.ControlPanelOption` objects for the Action Frame
+        """
+        cp_options = []
+        for opt in self._options:
             if opt == "mask_type":
-                choices = get_available_masks() + ["predicted"]
+                choices = self._create_mask_choices(defaults, available_masks, has_predicted_mask)
             else:
                 choices = PluginLoader.get_available_convert_plugins(opt, True)
-            choices = [self.format_to_display(choice) for choice in choices]
-            ctl = ControlBuilder(parent,
-                                 opt,
-                                 str,
-                                 defaults[opt],
-                                 choices=choices,
-                                 is_radio=False,
-                                 label_width=10,
-                                 control_width=12)
-            self.tk_vars[opt] = ctl.tk_var
+            cp_option = ControlPanelOption(title=opt,
+                                           dtype=str,
+                                           default=defaults[opt],
+                                           initial_value=defaults[opt],
+                                           choices=choices,
+                                           is_radio=False)
+            self._tk_vars[opt] = cp_option.tk_var
+            cp_options.append(cp_option)
+        return cp_options
+
+    @staticmethod
+    def _create_mask_choices(defaults, available_masks, has_predicted_mask):
+        """ Set the mask choices and default mask based on available masks.
+
+        Parameters
+        ----------
+        defaults: dict
+            The default command line options
+        available_masks: list
+            The available masks that exist within the alignments file
+        has_predicted_mask: bool
+            Whether the model was trained with a mask
+
+        Returns
+        -------
+        list
+            The masks that are available to use from the alignments file
+        """
+        logger.debug("Initial mask choices: %s", available_masks)
+        if has_predicted_mask:
+            available_masks += ["predicted"]
+        if "none" not in available_masks:
+            available_masks += ["none"]
+        if defaults["mask_type"] not in available_masks:
+            logger.debug("Setting default mask to first available: %s", available_masks[0])
+            defaults["mask_type"] = available_masks[0]
+        logger.debug("Final mask choices: %s", available_masks)
+        return available_masks
 
     @staticmethod
-    def add_refresh_button(parent, refresh_callback):
-        """ Add button to refresh the images """
+    def _add_refresh_button(parent, refresh_callback):
+        """ Add a button to refresh the images.
+
+        Parameters
+        ----------
+        refresh_callback: python function
+            The function to execute when the refresh button is pressed
+        """
         btn = ttk.Button(parent, text="Update Samples", command=refresh_callback)
-        btn.pack(padx=5, pady=5, side=tk.BOTTOM, fill=tk.X, anchor=tk.S)
+        btn.pack(padx=5, pady=5, side=tk.TOP, fill=tk.X, anchor=tk.N)
+
+    def _add_patch_callback(self, patch_callback):
+        """ Add callback to re-patch images on action option change.
 
-    def add_patch_callback(self, patch_callback):
-        """ Add callback to repatch images on action option change """
-        for tk_var in self.tk_vars.values():
+        Parameters
+        ----------
+        patch_callback: python function
+            The function to execute when the images require patching
+        """
+        for tk_var in self._tk_vars.values():
             tk_var.trace("w", patch_callback)
 
-    def add_busy_indicator(self, parent):
-        """ Place progress bar into bottom bar to indicate when processing """
+    def _add_busy_indicator(self, parent):
+        """ Place progress bar into bottom bar to indicate when processing.
+
+        Parameters
+        ----------
+        parent: tkinter object
+            The tkinter object that holds the busy indicator
+
+        Returns
+        -------
+        ttk.Progressbar
+            A Progress bar to indicate that the Preview tool is busy
+        """
         logger.debug("Placing busy indicator")
         pbar = ttk.Progressbar(parent, mode="indeterminate")
-        pbar.pack(side=tk.BOTTOM, padx=5, pady=5, fill=tk.X)
+        pbar.pack(side=tk.LEFT)
         pbar.pack_forget()
-        self.busy_tkvar.trace("w", self.busy_indicator_trace)
+        self._busy_tkvar.trace("w", self._busy_indicator_trace)
         return pbar
 
-    def busy_indicator_trace(self, *args):
-        """ Show or hide busy indicator """
+    def _busy_indicator_trace(self, *args):
+        """ Show or hide busy indicator based on whether the preview is updating.
+
+        Parameters
+        ----------
+        args: unused
+            Required for tkinter event, but unused
+        """
         logger.trace("Busy indicator trace: %s", args)
-        if self.busy_tkvar.get():
-            self.start_busy_indicator()
+        if self._busy_tkvar.get():
+            self._start_busy_indicator()
         else:
-            self.stop_busy_indicator()
+            self._stop_busy_indicator()
 
-    def stop_busy_indicator(self):
+    def _stop_busy_indicator(self):
         """ Stop and hide progress bar """
         logger.debug("Stopping busy indicator")
-        self.busy_indicator.stop()
-        self.busy_indicator.pack_forget()
+        self._busy_indicator.stop()
+        self._busy_indicator.pack_forget()
 
-    def start_busy_indicator(self):
+    def _start_busy_indicator(self):
         """ Start and display progress bar """
         logger.debug("Starting busy indicator")
-        self.busy_indicator.pack(side=tk.BOTTOM, padx=5, pady=5, fill=tk.X)
-        self.busy_indicator.start()
+        self._busy_indicator.pack(side=tk.LEFT, padx=5, pady=(5, 10), fill=tk.X, expand=True)
+        self._busy_indicator.start()
+
+    def _add_actions(self, parent):
+        """ Add Action Buttons to the :class:`ActionFrame`
 
-    def add_actions(self, parent):
-        """ Add Action Buttons """
+        Parameters
+        ----------
+        parent: tkinter object
+            The tkinter object that holds the action buttons
+        """
         logger.debug("Adding util buttons")
         frame = ttk.Frame(parent)
-        frame.pack(padx=5, pady=(5, 10), side=tk.BOTTOM, fill=tk.X, anchor=tk.E)
+        frame.pack(padx=5, pady=(5, 10), side=tk.RIGHT, fill=tk.X, anchor=tk.E)
 
         for utl in ("save", "clear", "reload"):
             logger.debug("Adding button: '%s'", utl)
             img = get_images().icons[utl]
             if utl == "save":
                 text = "Save full config"
-                action = self.config_tools.save_config
+                action = self._config_tools.save_config
             elif utl == "clear":
                 text = "Reset full config to default values"
-                action = self.config_tools.reset_config_default
+                action = self._config_tools.reset_config_to_default
             elif utl == "reload":
                 text = "Reset full config to saved values"
-                action = self.config_tools.reset_config_saved
+                action = self._config_tools.reset_config_to_saved
 
             btnutl = ttk.Button(frame,
                                 image=img,
@@ -810,141 +1301,137 @@ class ActionFrame(ttk.Frame):  # pylint: disable=too-many-ancestors
 
 
 class OptionsBook(ttk.Notebook):  # pylint:disable=too-many-ancestors
-    """ Convert settings Options Frame """
+    """ The notebook that holds the Convert configuration options.
+
+    Parameters
+    ----------
+    parent: tkinter object
+        The parent tkinter object that holds the Options book
+    config_tools: :class:`ConfigTools`
+        Tools for loading and saving configuration files
+    patch_callback: python function
+        The function to execute when a patch callback is received
+    scaling: float
+        The scaling factor for display
+
+    Attributes
+    ----------
+    config_tools: :class:`ConfigTools`
+        Tools for loading and saving configuration files
+    """
     def __init__(self, parent, config_tools, patch_callback, scaling):
         logger.debug("Initializing %s: (parent: %s, config: %s, scaling: %s)",
                      self.__class__.__name__, parent, config_tools, scaling)
         super().__init__(parent)
         self.pack(side=tk.RIGHT, anchor=tk.N, fill=tk.BOTH, expand=True)
         self.config_tools = config_tools
-        self.scaling = scaling
+        self._scaling = scaling
 
-        self.tabs = dict()
-        self.build_tabs()
-        self.build_sub_tabs()
-        self.add_patch_callback(patch_callback)
+        self._tabs = dict()
+        self._build_tabs()
+        self._build_sub_tabs()
+        self._add_patch_callback(patch_callback)
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def build_tabs(self):
-        """ Build the tabs for the relevant section """
+    def _build_tabs(self):
+        """ Build the notebook tabs for the each configuration section. """
         logger.debug("Build Tabs")
         for section in self.config_tools.sections:
             tab = ttk.Notebook(self)
-            self.tabs[section] = {"tab": tab}
+            self._tabs[section] = {"tab": tab}
             self.add(tab, text=section.replace("_", " ").title())
 
-    def build_sub_tabs(self):
-        """ Build the sub tabs for the relevant plugin """
+    def _build_sub_tabs(self):
+        """ Build the notebook sub tabs for each convert section's plugin. """
         for section, plugins in self.config_tools.plugins_dict.items():
             for plugin in plugins:
                 config_key = ".".join((section, plugin))
                 config_dict = self.config_tools.config_dicts[config_key]
-                tab = ConfigFrame(self,
-                                  config_key,
-                                  config_dict)
-                self.tabs[section][plugin] = tab
-                self.tabs[section]["tab"].add(tab, text=plugin.replace("_", " ").title())
-
-    def add_patch_callback(self, patch_callback):
-        """ Add callback to repatch images on config option change """
+                tab = ConfigFrame(self, config_key, config_dict)
+                self._tabs[section][plugin] = tab
+                self._tabs[section]["tab"].add(tab, text=plugin.replace("_", " ").title())
+
+    def _add_patch_callback(self, patch_callback):
+        """ Add callback to re-patch images on configuration option change.
+
+        Parameters
+        ----------
+        patch_callback: python function
+            The function to execute when the images require patching
+        """
         for plugins in self.config_tools.tk_vars.values():
             for tk_var in plugins.values():
                 tk_var.trace("w", patch_callback)
 
 
 class ConfigFrame(ttk.Frame):  # pylint: disable=too-many-ancestors
-    """ Config Frame - Holds the Options for config """
+    """ Holds the configuration options for a convert plugin inside the :class:`OptionsBook`.
+
+    Parameters
+    ----------
+    parent: tkinter object
+        The tkinter object that will hold this configuration frame
+    config_key: str
+        The section/plugin key for these configuration options
+    options: dict
+        The options for this section/plugin
+    """
 
     def __init__(self, parent, config_key, options):
         logger.debug("Initializing %s", self.__class__.__name__)
         super().__init__(parent)
         self.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
 
-        self.options = options
-        self.static_dims = [0, 0]
-
-        self.canvas_frame = ttk.Frame(self)
-        self.canvas_frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
-
-        self.canvas = tk.Canvas(self.canvas_frame, bd=0, highlightthickness=0)
-        self.canvas.pack(side=tk.LEFT, fill=tk.Y)
-
-        self.optsframe = ttk.Frame(self.canvas)
-        self.optscanvas = self.canvas.create_window((0, 0), window=self.optsframe, anchor=tk.NW)
-
-        self.scrollbar = self.add_scrollbar()
+        self._options = options
 
-        self.frame_separator = self.add_frame_separator()
-        self.action_frame = ttk.Frame(self)
-        self.action_frame.pack(padx=5, pady=5, side=tk.BOTTOM, fill=tk.X, anchor=tk.E)
-
-        self.build_frame(parent, config_key)
-
-        self.bind("<Configure>", self.resize_frame)
+        self._action_frame = ttk.Frame(self)
+        self._action_frame.pack(padx=0, pady=(0, 5), side=tk.BOTTOM, fill=tk.X, anchor=tk.E)
+        self._add_frame_separator()
 
+        self._build_frame(parent, config_key)
         logger.debug("Initialized %s", self.__class__.__name__)
 
-    def build_frame(self, parent, config_key):
-        """ Build the options frame for this command """
-        logger.debug("Add Config Frame")
+    def _build_frame(self, parent, config_key):
+        """ Build the options frame for this command
 
-        for key, val in self.options.items():
-            if key == "helptext":
-                continue
-            value = val.get("value", val["default"])
-            ctl = ControlBuilder(self.optsframe,
-                                 key,
-                                 val["type"],
-                                 value,
-                                 selected_value=None,
-                                 choices=val["choices"],
-                                 is_radio=val["gui_radio"],
-                                 rounding=val["rounding"],
-                                 min_max=val["min_max"],
-                                 helptext=val["helptext"],
-                                 radio_columns=4)
-            parent.config_tools.tk_vars.setdefault(config_key, dict())[key] = ctl.tk_var
-        self.add_frame_separator()
-        self.add_actions(parent, config_key)
+        Parameters
+        ----------
+        parent: tkinter object
+            The tkinter object that will hold this configuration frame
+        config_key: str
+            The section/plugin key for these configuration options
+        """
+        logger.debug("Add Config Frame")
+        panel_kwargs = dict(columns=2, option_columns=2, blank_nones=False)
+        frame = ttk.Frame(self)
+        frame.pack(side=tk.TOP, fill=tk.BOTH, expand=True)
+        cp_options = [opt for key, opt in self._options.items() if key != "helptext"]
+        ControlPanel(frame, cp_options, header_text=None, **panel_kwargs)
+        self._add_actions(parent, config_key)
         logger.debug("Added Config Frame")
 
-    def add_scrollbar(self):
-        """ Add a scrollbar to the options frame """
-        logger.debug("Add Config Scrollbar")
-        scrollbar = ttk.Scrollbar(self.canvas_frame, command=self.canvas.yview)
-        scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
-        self.canvas.config(yscrollcommand=scrollbar.set)
-        self.optsframe.bind("<Configure>", self.update_scrollbar)
-        logger.debug("Added Config Scrollbar")
-        return scrollbar
-
-    def update_scrollbar(self, event):  # pylint: disable=unused-argument
-        """ Update the options frame scrollbar """
-        self.canvas.configure(scrollregion=self.canvas.bbox("all"))
-
-    def resize_frame(self, event):
-        """ Resize the options frame to fit the canvas """
-        logger.debug("Resize Config Frame")
-        canvas_width = event.width - self.scrollbar.winfo_reqwidth()
-        canvas_height = event.height - (self.action_frame.winfo_reqheight() +
-                                        self.frame_separator.winfo_reqheight() + 16)
-        self.canvas.configure(width=canvas_width, height=canvas_height)
-        self.canvas.itemconfig(self.optscanvas, width=canvas_width, height=canvas_height)
-        logger.debug("Resized Config Frame")
-
-    def add_frame_separator(self):
-        """ Add a separator between top and bottom frames """
+    def _add_frame_separator(self):
+        """ Add a separator between top and bottom frames. """
         logger.debug("Add frame seperator")
-        sep = ttk.Frame(self, height=2, relief=tk.RIDGE)
-        sep.pack(fill=tk.X, pady=(5, 0), side=tk.TOP)
+        sep = ttk.Frame(self._action_frame, height=2, relief=tk.RIDGE)
+        sep.pack(fill=tk.X, pady=5, side=tk.TOP)
         logger.debug("Added frame seperator")
-        return sep
 
-    def add_actions(self, parent, config_key):
-        """ Add Action Buttons """
+    def _add_actions(self, parent, config_key):
+        """ Add Action Buttons.
+
+        Parameters
+        ----------
+        parent: tkinter object
+            The tkinter object that will hold this configuration frame
+        config_key: str
+            The section/plugin key for these configuration options
+        """
         logger.debug("Adding util buttons")
 
         title = config_key.split(".")[1].replace("_", " ").title()
+        btn_frame = ttk.Frame(self._action_frame)
+        btn_frame.pack(padx=5, side=tk.BOTTOM, fill=tk.X)
         for utl in ("save", "clear", "reload"):
             logger.debug("Adding button: '%s'", utl)
             img = get_images().icons[utl]
@@ -953,225 +1440,14 @@ class ConfigFrame(ttk.Frame):  # pylint: disable=too-many-ancestors
                 action = parent.config_tools.save_config
             elif utl == "clear":
                 text = "Reset {} config to default values".format(title)
-                action = parent.config_tools.reset_config_default
+                action = parent.config_tools.reset_config_to_default
             elif utl == "reload":
                 text = "Reset {} config to saved values".format(title)
-                action = parent.config_tools.reset_config_saved
+                action = parent.config_tools.reset_config_to_saved
 
-            btnutl = ttk.Button(self.action_frame,
+            btnutl = ttk.Button(btn_frame,
                                 image=img,
                                 command=lambda cmd=action: cmd(config_key))
             btnutl.pack(padx=2, side=tk.RIGHT)
             Tooltip(btnutl, text=text, wraplength=200)
         logger.debug("Added util buttons")
-
-
-class ControlBuilder():
-    """
-    Builds and returns a frame containing a tkinter control with label
-
-    Currently only setup for config items
-
-    Parameters
-    ----------
-    parent: tkinter object
-        Parent tkinter object
-    title: str
-        Title of the control. Will be used for label text
-    dtype: datatype object
-        Datatype of the control
-    default: str
-        Default value for the control
-    selected_value: str, optional
-        Selected value for the control. If None, default will be used
-    choices: list or tuple, object
-        Used for combo boxes and radio control option setting
-    is_radio: bool, optional
-        Specifies to use a Radio control instead of combobox if choices are passed
-    rounding: int or float, optional
-        For slider controls. Sets the stepping
-    min_max: int or float, optional
-        For slider controls. Sets the min and max values
-    helptext: str, optional
-        Sets the tooltip text
-    radio_columns: int, optional
-        Sets the number of columns to use for grouping radio buttons
-    label_width: int, optional
-        Sets the width of the control label. Defaults to 20
-    control_width: int, optional
-        Sets the width of the control. Default is to auto expand
-    """
-    def __init__(self, parent, title, dtype, default,
-                 selected_value=None, choices=None, is_radio=False, rounding=None,
-                 min_max=None, helptext=None, radio_columns=3, label_width=20, control_width=None):
-        logger.debug("Initializing %s: (parent: %s, title: %s, dtype: %s, default: %s, "
-                     "selected_value: %s, choices: %s, is_radio: %s, rounding: %s, min_max: %s, "
-                     "helptext: %s, radio_columns: %s, label_width: %s, control_width: %s)",
-                     self.__class__.__name__, parent, title, dtype, default, selected_value,
-                     choices, is_radio, rounding, min_max, helptext, radio_columns, label_width,
-                     control_width)
-
-        self.title = title
-        self.default = default
-
-        self.frame = self.control_frame(parent, helptext)
-        self.control = self.set_control(dtype, choices, is_radio)
-        self.tk_var = self.set_tk_var(dtype, selected_value)
-
-        self.build_control(choices,
-                           dtype,
-                           rounding,
-                           min_max,
-                           radio_columns,
-                           label_width,
-                           control_width)
-        logger.debug("Initialized: %s", self.__class__.__name__)
-
-    # Frame, control type and varable
-    def control_frame(self, parent, helptext):
-        """ Frame to hold control and it's label """
-        logger.debug("Build control frame")
-        frame = ttk.Frame(parent)
-        frame.pack(side=tk.TOP, fill=tk.X)
-        if helptext is not None:
-            helptext = self.format_helptext(helptext)
-            Tooltip(frame, text=helptext, wraplength=720)
-        logger.debug("Built control frame")
-        return frame
-
-    def format_helptext(self, helptext):
-        """ Format the help text for tooltips """
-        logger.debug("Format control help: '%s'", self.title)
-        helptext = helptext.replace("\n\t", "\n  - ").replace("%%", "%")
-        helptext = self.title + " - " + helptext
-        logger.debug("Formatted control help: (title: '%s', help: '%s'", self.title, helptext)
-        return helptext
-
-    def set_control(self, dtype, choices, is_radio):
-        """ Set the correct control type based on the datatype or for this option """
-        if choices and is_radio:
-            control = ttk.Radiobutton
-        elif choices:
-            control = ttk.Combobox
-        elif dtype == bool:
-            control = ttk.Checkbutton
-        elif dtype in (int, float):
-            control = ttk.Scale
-        else:
-            control = ttk.Entry
-        logger.debug("Setting control '%s' to %s", self.title, control)
-        return control
-
-    def set_tk_var(self, dtype, selected_value):
-        """ Correct variable type for control """
-        logger.debug("Setting tk variable: (title: '%s', dtype: %s, selected_value: %s)",
-                     self.title, dtype, selected_value)
-        if dtype == bool:
-            var = tk.BooleanVar
-        elif dtype == int:
-            var = tk.IntVar
-        elif dtype == float:
-            var = tk.DoubleVar
-        else:
-            var = tk.StringVar
-        var = var(self.frame)
-        val = self.default if selected_value is None else selected_value
-        var.set(val)
-        logger.debug("Set tk variable: (title: '%s', type: %s, value: '%s')",
-                     self.title, type(var), val)
-        return var
-
-    # Build the full control
-    def build_control(self, choices, dtype, rounding, min_max, radio_columns,
-                      label_width, control_width):
-        """ Build the correct control type for the option passed through """
-        logger.debug("Build confog option control")
-        self.build_control_label(label_width)
-        self.build_one_control(choices, dtype, rounding, min_max, radio_columns, control_width)
-        logger.debug("Built option control")
-
-    def build_control_label(self, label_width):
-        """ Label for control """
-        logger.debug("Build control label: (title: '%s', label_width: %s)",
-                     self.title, label_width)
-        title = self.title.replace("_", " ").title()
-        lbl = ttk.Label(self.frame, text=title, width=label_width, anchor=tk.W)
-        lbl.pack(padx=5, pady=5, side=tk.LEFT, anchor=tk.N)
-        logger.debug("Built control label: '%s'", self.title)
-
-    def build_one_control(self, choices, dtype, rounding, min_max, radio_columns, control_width):
-        """ Build and place the option controls """
-        logger.debug("Build control: (title: '%s', control: %s, choices: %s, dtype: %s, "
-                     "rounding: %s, min_max: %s: radio_columns: %s, control_width: %s)",
-                     self.title, self.control, choices, dtype, rounding, min_max, radio_columns,
-                     control_width)
-        if self.control == ttk.Scale:
-            ctl = self.slider_control(dtype, rounding, min_max)
-        elif self.control == ttk.Radiobutton:
-            ctl = self.radio_control(choices, radio_columns)
-        else:
-            ctl = self.control_to_optionsframe(choices)
-        self.set_control_width(ctl, control_width)
-        ctl.pack(padx=5, pady=5, fill=tk.X, expand=True)
-        logger.debug("Built control: '%s'", self.title)
-
-    @staticmethod
-    def set_control_width(ctl, control_width):
-        """ Set the control width if required """
-        if control_width is not None:
-            ctl.config(width=control_width)
-
-    def radio_control(self, choices, columns):
-        """ Create a group of radio buttons """
-        logger.debug("Adding radio group: %s", self.title)
-        ctl = ttk.Frame(self.frame)
-        frames = list()
-        for _ in range(columns):
-            frame = ttk.Frame(ctl)
-            frame.pack(padx=5, pady=5, fill=tk.X, expand=True, side=tk.LEFT, anchor=tk.N)
-            frames.append(frame)
-
-        for idx, choice in enumerate(choices):
-            frame_id = idx % columns
-            radio = ttk.Radiobutton(frames[frame_id],
-                                    text=choice.title(),
-                                    value=choice,
-                                    variable=self.tk_var)
-            radio.pack(anchor=tk.W)
-            logger.debug("Adding radio option %s to column %s", choice, frame_id)
-        logger.debug("Added radio group: '%s'", self.title)
-        return ctl
-
-    def slider_control(self, dtype, rounding, min_max):
-        """ A slider control with corresponding Entry box """
-        logger.debug("Add slider control to Options Frame: (title: '%s', dtype: %s, rounding: %s, "
-                     "min_max: %s)", self.title, dtype, rounding, min_max)
-        tbox = ttk.Entry(self.frame, width=8, textvariable=self.tk_var, justify=tk.RIGHT)
-        tbox.pack(padx=(0, 5), side=tk.RIGHT)
-        ctl = self.control(
-            self.frame,
-            variable=self.tk_var,
-            command=lambda val, var=self.tk_var, dt=dtype, rn=rounding, mm=min_max:
-            set_slider_rounding(val, var, dt, rn, mm))
-        rc_menu = ContextMenu(tbox)
-        rc_menu.cm_bind()
-        ctl["from_"] = min_max[0]
-        ctl["to"] = min_max[1]
-        logger.debug("Added slider control to Options Frame: %s", self.title)
-        return ctl
-
-    def control_to_optionsframe(self, choices):
-        """ Standard non-check buttons sit in the main options frame """
-        logger.debug("Add control to Options Frame: (title: '%s', control: %s, choices: %s)",
-                     self.title, self.control, choices)
-        if self.control == ttk.Checkbutton:
-            ctl = self.control(self.frame, variable=self.tk_var, text=None)
-        else:
-            ctl = self.control(self.frame, textvariable=self.tk_var)
-            rc_menu = ContextMenu(ctl)
-            rc_menu.cm_bind()
-        if choices:
-            logger.debug("Adding combo choices: %s", choices)
-            ctl["values"] = [choice for choice in choices]
-        logger.debug("Added control to Options Frame: %s", self.title)
-        return ctl
