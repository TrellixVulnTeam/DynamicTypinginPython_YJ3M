commit 73ff840fbd68bc7737490217997a4e9e39fb7691
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Wed Nov 13 19:16:25 2019 +0000

    scripts.extract - code optimizations
    
    Limit queue sizes to reduce RAM usage
    Rename lib.image.BackgroundIO to ImageIO
    Create separate ImagesLoader and ImagesSaver classes
    Load/Save images from centralized lib.image.ImageIO
    scripts.extract documentation

diff --git a/docs/full/modules.rst b/docs/full/modules.rst
index 09bbbac..0d40e86 100644
--- a/docs/full/modules.rst
+++ b/docs/full/modules.rst
@@ -6,4 +6,5 @@ faceswap
 
    lib
    plugins
+   scripts
    tools
diff --git a/docs/full/scripts.extract.rst b/docs/full/scripts.extract.rst
new file mode 100644
index 0000000..6caa7b5
--- /dev/null
+++ b/docs/full/scripts.extract.rst
@@ -0,0 +1,7 @@
+scripts.extract
+=======================
+
+.. automodule:: scripts.extract
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/docs/full/scripts.rst b/docs/full/scripts.rst
new file mode 100644
index 0000000..baa53d1
--- /dev/null
+++ b/docs/full/scripts.rst
@@ -0,0 +1,17 @@
+scripts package
+===============
+
+Subpackages
+-----------
+
+.. toctree::
+
+   scripts.extract
+
+Module contents
+---------------
+
+.. automodule:: scripts
+   :members:
+   :undoc-members:
+   :show-inheritance:
diff --git a/lib/image.py b/lib/image.py
index b02add0..122552d 100644
--- a/lib/image.py
+++ b/lib/image.py
@@ -338,143 +338,257 @@ def count_frames(filename, fast=False):
     return frames
 
 
-class BackgroundIO():
+class ImageIO():
     """ Perform disk IO for images or videos in a background thread.
 
-    Loads images or videos from a given location in a background thread.
-    Saves images to the given location in a background thread.
-    Images/Videos will be loaded or saved in deterministic order.
+    This is the parent thread for :class:`ImagesLoader` and :class:`ImagesSaver` and should not
+    be called directly.
 
     Parameters
     ----------
-    path: str
+    path: str or list
         The path to load or save images to/from. For loading this can be a folder which contains
-        images or a video file. For saving this must be an existing folder.
-    task: {'load', 'save'}
-        The task to be performed. ``'load'`` to load images/video frames, ``'save'`` to save
-        images.
-    load_with_hash: bool, optional
-        When loading images, set to ``True`` to return the sha1 hash of the image along with the
-        image. Default: ``False``.
+        images, video file or a list of image files. For saving this must be an existing folder.
+    queue_size: int
+        The amount of images to hold in the internal buffer.
+    args: tuple, optional
+        The arguments to be passed to the loader or saver thread. Default: ``None``
+
+    See Also
+    --------
+    lib.image.ImagesLoader : Background Image Loader inheriting from this class.
+    lib.image.ImagesSaver : Background Image Saver inheriting from this class.
+    """
+
+    def __init__(self, path, queue_size, args=None):
+        logger.debug("Initializing %s: (path: %s, queue_size: %s, args: %s)",
+                     self.__class__.__name__, path, queue_size, args)
+
+        self._args = tuple() if args is None else args
+
+        self._location = path
+        self._check_location_exists()
+
+        self._queue = queue_manager.get_queue(name=self.__class__.__name__, maxsize=queue_size)
+        self._thread = None
+
+    @property
+    def location(self):
+        """ str: The folder or video that was passed in as the :attr:`path` parameter. """
+        return self._location
+
+    def _check_location_exists(self):
+        """ Check whether the input location exists.
+
+        Raises
+        ------
+        FaceswapError
+            If the given location does not exist
+        """
+        if isinstance(self.location, str) and not os.path.exists(self.location):
+            raise FaceswapError("The location '{}' does not exist".format(self.location))
+        if isinstance(self.location, (list, tuple)) and not all(os.path.exists(location)
+                                                                for location in self.location):
+            raise FaceswapError("Not all locations in the input list exist")
+
+    def _set_thread(self):
+        """ Set the load/save thread """
+        if self._thread is not None:
+            return
+        self._thread = MultiThread(self._process,
+                                   self._queue,
+                                   name=self.__class__.__name__,
+                                   thread_count=1)
+        logger.trace(self._thread)
+        self._thread.start()
+
+    def _process(self, queue):
+        """ Image IO process to be run in a thread. Override for loader/saver process.
+
+        Parameters
+        ----------
+        queue: queue.Queue()
+            The ImageIO Queue
+        """
+        raise NotImplementedError
+
+    def close(self):
+        """ Closes down and joins the internal threads """
+        logger.debug("Received Close")
+        self._thread.join()
+        logger.debug("Closed")
+
+
+class ImagesLoader(ImageIO):
+    """ Perform image loading from a folder of images or a video.
+
+    Images will be loaded and returned in the order that they appear in the folder, or in the video
+    to ensure deterministic ordering. Loading occurs in a background thread, caching 8 images at a
+    time so that other processes do not need to wait on disk reads.
+
+    See also :class:`ImageIO` for additional attributes.
+
+    Parameters
+    ----------
+    path: str or list
+        The path to load images from. This can be a folder which contains images a video file or a
+        list of image files.
     queue_size: int, optional
-        The amount of images to hold in the internal buffer. Default: 16.
+        The amount of images to hold in the internal buffer. Default: 8.
+    load_with_hash: bool, optional
+        Set to ``True`` to return the sha1 hash of the image along with the image.
+        Default: ``False``.
+    fast_count: bool, optional
+        When loading from video, the video needs to be parsed frame by frame to get an accurate
+        count. This can be done quite quickly without guaranteed accuracy, or slower with
+        guaranteed accuracy. Set to ``True`` to count quickly, or ``False`` to count slower
+        but accurately. Default: ``True``.
+    skip_list: list, optional
+        Optional list of frame/image indices to not load. Any indices provided here will be skipped
+        when reading images from the given location. Default: ``None``
 
     Examples
     --------
     Loading from a video file:
 
-    >>> loader = BackgroundIO('/path/to/video.mp4', 'load')
+    >>> loader = ImagesLoader('/path/to/video.mp4')
     >>> for filename, image in loader.load():
     >>>     <do processing>
 
     Loading faces with their sha1 hash:
 
-    >>> loader = BackgroundIO('/path/to/faces/folder', 'load', load_with_hash=True)
+    >>> loader = ImagesLoader('/path/to/faces/folder', load_with_hash=True)
     >>> for filename, image, sha1_hash in loader.load():
     >>>     <do processing>
+    """
 
-    Saving out images:
+    def __init__(self, path, queue_size=8, load_with_hash=False, fast_count=True, skip_list=None):
+        logger.debug("Initializing %s: (path: %s, queue_size: %s, load_with_hash: %s, "
+                     "fast_count: %s)", self.__class__.__name__, path, queue_size,
+                     load_with_hash, fast_count)
 
-    >>> saver = BackgroundIO('/path/to/save/folder', 'save')
-    >>> for filename, image in <image_iterator>:
-    >>>     saver.save(filename, image)
-    >>> saver.close()
-    """
+        args = (load_with_hash, )
+        super().__init__(path, queue_size=queue_size, args=args)
+        self._skip_list = set() if skip_list is None else set(skip_list)
 
-    def __init__(self, path, task, load_with_hash=False, queue_size=16):
-        logger.debug("Initializing %s: (path: %s, task: %s, load_with_hash: %s, queue_size: %s)",
-                     self.__class__.__name__, path, task, load_with_hash, queue_size)
-        self._location = path
+        self._is_video = self._check_for_video()
 
-        self._task = task.lower()
-        self._is_video = self._check_input()
-        self._input = self.location if self._is_video else get_image_paths(self.location)
-        self._count = count_frames(self._input) if self._is_video else len(self._input)
-        self._queue = queue_manager.get_queue(name="{}_{}".format(self.__class__.__name__,
-                                                                  self._task),
-                                              maxsize=queue_size)
-        self._thread = self._set_thread(io_args=(load_with_hash, ))
-        self._thread.start()
+        self._count = None
+        self._file_list = None
+        self._get_count_and_filelist(fast_count)
 
     @property
     def count(self):
-        """ int: The number of images or video frames to be processed """
+        """ int: The number of images or video frames in the source location. This count includes
+        any files that will ultimately be skipped if a :attr:`skip_list` has been provided. See
+        also: :attr:`process_count`"""
         return self._count
 
     @property
-    def location(self):
-        """ str: The folder or video that was passed in as the :attr:`path` parameter. """
-        return self._location
+    def process_count(self):
+        """ int: The number of images or video frames to be processed (IE the total count less
+        items that are to be skipped from the :attr:`skip_list`)"""
+        return self._count - len(self._skip_list)
+
+    @property
+    def is_video(self):
+        """ bool: ``True`` if the input is a video, ``False`` if it is not """
+        return self._is_video
+
+    @property
+    def file_list(self):
+        """ list: A full list of files in the source location. This includes any files that will
+        ultimately be skipped if a :attr:`skip_list` has been provided. If the input is a video
+        then this is a list of dummy filenames as corresponding to an alignments file """
+        return self._file_list
 
-    def _check_input(self):
-        """ Check whether the input path is valid and return if it is a video.
+    def add_skip_list(self, skip_list):
+        """ Add a skip list to this :class:`ImagesLoader`
+
+        Parameters
+        ----------
+        skip_list: list
+            A list of indices corresponding to the frame indices that should be skipped
+        """
+        logger.debug(skip_list)
+        self._skip_list = set(skip_list)
+
+    def _check_for_video(self):
+        """ Check whether the input is a video
 
         Returns
         -------
         bool: 'True' if input is a video 'False' if it is a folder.
-        """
-        if not os.path.exists(self.location):
-            raise FaceswapError("The location '{}' does not exist".format(self.location))
 
-        if self._task == "save" and not os.path.isdir(self.location):
-            raise FaceswapError("The output location '{}' is not a folder".format(self.location))
+        Raises
+        ------
+        FaceswapError
+            If the given location is a file and does not have a valid video extension.
 
-        is_video = (self._task == "load" and
-                    os.path.isfile(self.location) and
-                    os.path.splitext(self.location)[1].lower() in _video_extensions)
-        if is_video:
-            logger.debug("Input is video")
+        """
+        if os.path.isdir(self.location):
+            retval = False
+        elif os.path.splitext(self.location)[1].lower() in _video_extensions:
+            retval = True
         else:
-            logger.debug("Input is folder")
-        return is_video
+            raise FaceswapError("The input file '{}' is not a valid video".format(self.location))
+        logger.debug("Input '%s' is_video: %s", self.location, retval)
+        return retval
+
+    def _get_count_and_filelist(self, fast_count):
+        """ Set the count of images to be processed and set the file list
 
-    def _set_thread(self, io_args=None):
-        """ Set the load/save thread
+            If the input is a video, a dummy file list is created for checking against an
+            alignments file, otherwise it will be a list of full filenames.
 
         Parameters
         ----------
-        io_args: tuple, optional
-            The arguments to be passed to the load or save thread. Default: `None`.
-
-        Returns
-        -------
-        :class:`lib.multithreading.MultiThread`: Thread containing the load/save function.
+        fast_count: bool
+            When loading from video, the video needs to be parsed frame by frame to get an accurate
+            count. This can be done quite quickly without guaranteed accuracy, or slower with
+            guaranteed accuracy. Set to ``True`` to count quickly, or ``False`` to count slower
+            but accurately.
         """
-        io_args = (self._queue) if io_args is None else (self._queue, *io_args)
-        retval = MultiThread(getattr(self, "_{}".format(self._task)), *io_args, thread_count=1)
-        logger.trace(retval)
-        return retval
+        if self._is_video:
+            self._count = int(count_frames(self.location, fast=fast_count))
+            self._file_list = [self._dummy_video_framename(i + 1) for i in range(self.count)]
+        else:
+            if isinstance(self.location, (list, tuple)):
+                self._file_list = self.location
+            else:
+                self._file_list = get_image_paths(self.location)
+            self._count = len(self.file_list)
 
-    # LOADING #
-    def _load(self, *args):
+        logger.debug("count: %s", self.count)
+        logger.trace("filelist: %s", self.file_list)
+
+    def _process(self, queue):
         """ The load thread.
 
         Loads from a folder of images or from a video and puts to a queue
 
         Parameters
         ----------
-        args: tuple
-            The arguments to be passed to the load iterator
+        queue: queue.Queue()
+            The ImageIO Queue
         """
-        queue = args[0]
-        io_args = args[1:]
-        iterator = self._load_video if self._is_video else self._load_images
+        iterator = self._from_video if self._is_video else self._from_folder
         logger.debug("Load iterator: %s", iterator)
-        for retval in iterator(*io_args):
+        for retval in iterator():
+            filename, image = retval[:2]
+            if image is None or (not image.any() and image.ndim not in (2, 3)):
+                # All black frames will return not np.any() so check dims too
+                logger.warning("Unable to open image. Skipping: '%s'", filename)
+                continue
             logger.trace("Putting to queue: %s", [v.shape if isinstance(v, np.ndarray) else v
                                                   for v in retval])
             queue.put(retval)
         logger.trace("Putting EOF")
         queue.put("EOF")
 
-    def _load_video(self, *args):  # pylint:disable=unused-argument
+    def _from_video(self):
         """ Generator for loading frames from a video
 
-        Parameters
-        ----------
-        args: tuple
-            Unused
-
         Yields
         ------
         filename: str
@@ -482,24 +596,35 @@ class BackgroundIO():
         image: numpy.ndarray
             The loaded video frame.
         """
-        logger.debug("Loading frames from video: '%s'", self._input)
-        vidname = os.path.splitext(os.path.basename(self._input))[0]
-        reader = imageio.get_reader(self._input, "ffmpeg")
-        for i, frame in enumerate(reader):
+        logger.debug("Loading frames from video: '%s'", self.location)
+        reader = imageio.get_reader(self.location, "ffmpeg")
+        for idx, frame in enumerate(reader):
+            if idx in self._skip_list:
+                logger.trace("Skipping frame %s due to skip list")
+                continue
             # Convert to BGR for cv2 compatibility
             frame = frame[:, :, ::-1]
-            filename = "{}_{:06d}.png".format(vidname, i + 1)
+            filename = self._dummy_video_framename(idx + 1)
             logger.trace("Loading video frame: '%s'", filename)
             yield filename, frame
         reader.close()
 
-    def _load_images(self, with_hash):
-        """ Generator for loading images from a folder
+    def _dummy_video_framename(self, frame_no):
+        """ Return a dummy filename for video files
 
         Parameters
         ----------
-        with_hash: bool
-            If ``True`` adds the sha1 hash to the output tuple as the final item.
+        frame_no: int
+            The frame number for the video frame
+
+        Returns
+        -------
+        str: A dummied filename for a video frame """
+        vidname = os.path.splitext(os.path.basename(self.location))[0]
+        return "{}_{:06d}.png".format(vidname, frame_no + 1)
+
+    def _from_folder(self):
+        """ Generator for loading images from a folder
 
         Yields
         ------
@@ -508,12 +633,16 @@ class BackgroundIO():
         image: numpy.ndarray
             The loaded image.
         sha1_hash: str, optional
-            The sha1 hash of the loaded image. Only yielded if :class:`BackgroundIO` was
+            The sha1 hash of the loaded image. Only yielded if :class:`ImageIO` was
             initialized with :attr:`load_with_hash` set to ``True`` and the :attr:`location`
             is a folder of images.
         """
-        logger.debug("Loading images from folder: '%s'", self._input)
-        for filename in self._input:
+        with_hash = self._args[0]
+        logger.debug("Loading images from folder: '%s'. with_hash: %s", self.location, with_hash)
+        for idx, filename in enumerate(self.file_list):
+            if idx in self._skip_list:
+                logger.trace("Skipping frame %s due to skip list")
+                continue
             image_read = read_image(filename, raise_error=False, with_hash=with_hash)
             if with_hash:
                 retval = filename, *image_read
@@ -527,7 +656,7 @@ class BackgroundIO():
     def load(self):
         """ Generator for loading images from the given :attr:`location`
 
-        If :class:`BackgroundIO` was initialized with :attr:`load_with_hash` set to ``True`` then
+        If :class:`ImageIO` was initialized with :attr:`load_with_hash` set to ``True`` then
         the sha1 hash of the image is added as the final item in the output `tuple`.
 
         Yields
@@ -537,10 +666,11 @@ class BackgroundIO():
         image: numpy.ndarray
             The loaded image.
         sha1_hash: str, optional
-            The sha1 hash of the loaded image. Only yielded if :class:`BackgroundIO` was
+            The sha1 hash of the loaded image. Only yielded if :class:`ImageIO` was
             initialized with :attr:`load_with_hash` set to ``True`` and the :attr:`location`
             is a folder of images.
         """
+        self._set_thread()
         while True:
             self._thread.check_and_raise_error()
             try:
@@ -555,25 +685,93 @@ class BackgroundIO():
             yield retval
         self._thread.join()
 
-    # SAVING #
-    @staticmethod
-    def _save(*args):
+
+class ImagesSaver(ImageIO):
+    """ Perform image saving to a destination folder.
+
+    Images are saved in a background ThreadPoolExecutor to allow for concurrent saving.
+    See also :class:`ImageIO` for additional attributes.
+
+    Parameters
+    ----------
+    path: str
+        The folder to save images to. This must be an existing folder.
+    queue_size: int, optional
+        The amount of images to hold in the internal buffer. Default: 8.
+    as_bytes: bool, optional
+        ``True`` if the image is already encoded to bytes, ``False`` if the image is a
+        :class:`numpy.ndarray`. Default: ``False``.
+
+    Examples
+    --------
+
+    >>> saver = ImagesSaver('/path/to/save/folder')
+    >>> for filename, image in <image_iterator>:
+    >>>     saver.save(filename, image)
+    >>> saver.close()
+    """
+
+    def __init__(self, path, queue_size=8, as_bytes=False):
+        logger.debug("Initializing %s: (path: %s, load_with_hash: %s, as_bytes: %s)",
+                     self.__class__.__name__, path, queue_size, as_bytes)
+
+        super().__init__(path, queue_size=queue_size)
+        self._as_bytes = as_bytes
+
+    def _check_location_exists(self):
+        """ Check whether the output location exists and is a folder
+
+        Raises
+        ------
+        FaceswapError
+            If the given location does not exist or the location is not a folder
+        """
+        if not isinstance(self.location, str):
+            raise FaceswapError("The output location must be a string not a "
+                                "{}".format(type(self.location)))
+        super()._check_location_exists()
+        if not os.path.isdir(self.location):
+            raise FaceswapError("The output location '{}' is not a folder".format(self.location))
+
+    def _process(self, queue):
         """ Saves images from the save queue to the given :attr:`location` inside a thread.
 
         Parameters
         ----------
-        args: tuple
-            The save arguments
+        queue: queue.Queue()
+            The ImageIO Queue
         """
-        queue = args[0]
+        executor = futures.ThreadPoolExecutor(thread_name_prefix=self.__class__.__name__)
         while True:
             item = queue.get()
             if item == "EOF":
                 logger.debug("EOF received")
                 break
-            filename, image = item
-            logger.trace("Saving image: '%s'", filename)
-            cv2.imwrite(filename, image)
+            logger.trace("Submitting: '%s'", item[0])
+            executor.submit(self._save, *item)
+        executor.shutdown()
+
+    def _save(self, filename, image):
+        """ Save a single image inside a ThreadPoolExecutor
+
+        Parameters
+        ----------
+        filename: str
+            The filename of the image to be saved. Can include or exclude the folder location.
+        image: numpy.ndarray
+            The image to be saved
+        """
+        if not os.path.commonprefix([self.location, filename]):
+            filename = os.path.join(self.location, filename)
+        try:
+            if self._as_bytes:
+                with open(filename, "wb") as out_file:
+                    out_file.write(image)
+            else:
+                cv2.imwrite(filename, image)
+            logger.trace("Saved image: '%s'", filename)
+        except Exception as err:  # pylint: disable=broad-except
+            logger.error("Failed to save image '%s'. Original Error: %s", filename, err)
 
     def save(self, filename, image):
         """ Save the given image in the background thread
@@ -587,18 +785,13 @@ class BackgroundIO():
         image: numpy.ndarray
             The image to be saved
         """
+        self._set_thread()
         logger.trace("Putting to save queue: '%s'", filename)
         self._queue.put((filename, image))
 
     def close(self):
-        """ Closes down and joins the internal threads
-
-        Must be called after a :func:`save` operation to ensure all items are saved before the
-        parent process exits.
-        """
-        logger.debug("Received Close")
-        if self._task == "save":
-            logger.debug("Putting EOF to save queue")
-            self._queue.put("EOF")
-        self._thread.join()
-        logger.debug("Closed")
+        """ Signal to the Save Threads that they should be closed and cleanly shutdown
+        the saver """
+        logger.debug("Putting EOF to save queue")
+        self._queue.put("EOF")
+        super().close()
diff --git a/plugins/extract/_base.py b/plugins/extract/_base.py
index 86d4bcc..7e37a93 100644
--- a/plugins/extract/_base.py
+++ b/plugins/extract/_base.py
@@ -120,7 +120,7 @@ class Extractor():
         self.vram_per_batch = None
 
         # << THE FOLLOWING ARE SET IN self.initialize METHOD >> #
-        self.queue_size = 32
+        self.queue_size = 1
         """ int: Queue size for all internal queues. Set in :func:`initialize()` """
 
         self.model = None
diff --git a/plugins/extract/pipeline.py b/plugins/extract/pipeline.py
index 5ba84de..dedb5ec 100644
--- a/plugins/extract/pipeline.py
+++ b/plugins/extract/pipeline.py
@@ -70,7 +70,9 @@ class Extractor():
                      multiprocess, rotate_images, min_size, normalize_method, image_is_aligned)
         self._flow = self._set_flow(detector, aligner, masker)
         self.phase = self._flow[0]
-        self._queue_size = 32
+        # We only ever need 1 item in each queue. This is 2 items cached (1 in queue 1 waiting
+        # for queue) at each point. Adding more just stacks RAM with no speed benefit.
+        self._queue_size = 1
         self._vram_buffer = 256  # Leave a buffer for VRAM allocation
         self._detect = self._load_detect(detector, rotate_images, min_size, configfile)
         self._align = self._load_align(aligner, configfile, normalize_method)
@@ -328,10 +330,6 @@ class Extractor():
         tasks.append("extract_{}_out".format(self._final_phase))
         for task in tasks:
             # Limit queue size to avoid stacking ram
-            self._queue_size = 32
-            if task == "extract_{}_in".format(self._flow[0]) or (not self._is_parallel
-                                                                 and not task.endswith("_out")):
-                self._queue_size = 64
             queue_manager.add_queue(task, maxsize=self._queue_size)
             queues[task] = queue_manager.get_queue(task)
         logger.debug("Queues: %s", queues)
diff --git a/scripts/extract.py b/scripts/extract.py
index 8979b1d..b5c6be7 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -1,128 +1,179 @@
 #!/usr/bin python3
-""" The script to run the extract process of faceswap """
+""" Main entry point to the extract process of FaceSwap """
 
 import logging
 import os
 import sys
-from pathlib import Path
 
 from tqdm import tqdm
 
-from lib.image import encode_image_with_hash
+from lib.image import encode_image_with_hash, ImagesLoader, ImagesSaver
 from lib.multithreading import MultiThread
-from lib.queue_manager import queue_manager
 from lib.utils import get_folder
 from plugins.extract.pipeline import Extractor
-from scripts.fsmedia import Alignments, Images, PostProcess, Utils
+from scripts.fsmedia import Alignments, PostProcess, Utils
 
 tqdm.monitor_interval = 0  # workaround for TqdmSynchronisationWarning
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
 class Extract():
-    """ The extract process. """
+    """ The Faceswap Face Extraction Process.
+
+    The extraction process is responsible for detecting faces in a series of images/video, aligning
+    these faces and then generating a mask.
+
+    It leverages a series of user selected plugins, chained together using
+    :mod:`plugins.extract.pipeline`.
+
+    The extract process is self contained and should not be referenced by any other scripts, so it
+    contains no public properties.
+
+    Parameters
+    ----------
+    arguments: argparse.Namespace
+        The arguments to be passed to the extraction process as generated from Faceswap's command
+        line arguments
+    """
     def __init__(self, arguments):
         logger.debug("Initializing %s: (args: %s", self.__class__.__name__, arguments)
-        self.args = arguments
-        Utils.set_verbosity(self.args.loglevel)
-        self.output_dir = get_folder(self.args.output_dir)
-        logger.info("Output Directory: %s", self.args.output_dir)
-        self.images = Images(self.args)
-        self.alignments = Alignments(self.args, True, self.images.is_video)
-        self.post_process = PostProcess(arguments)
-        configfile = self.args.configfile if hasattr(self.args, "configfile") else None
-        normalization = None if self.args.normalization == "none" else self.args.normalization
-        self.extractor = Extractor(self.args.detector,
-                                   self.args.aligner,
-                                   self.args.masker,
-                                   configfile=configfile,
-                                   multiprocess=not self.args.singleprocess,
-                                   rotate_images=self.args.rotate_images,
-                                   min_size=self.args.min_size,
-                                   normalize_method=normalization)
-        self.save_queue = queue_manager.get_queue("extract_save")
-        self.threads = list()
-        self.verify_output = False
-        self.save_interval = None
-        if hasattr(self.args, "save_interval"):
-            self.save_interval = self.args.save_interval
+        self._args = arguments
+        Utils.set_verbosity(self._args.loglevel)
+
+        self._output_dir = str(get_folder(self._args.output_dir))
+
+        logger.info("Output Directory: %s", self._args.output_dir)
+        self._images = ImagesLoader(self._args.input_dir, load_with_hash=False, fast_count=True)
+        self._alignments = Alignments(self._args, True, self._images.is_video)
+
+        self._existing_count = 0
+        self._set_skip_list()
+
+        self._post_process = PostProcess(arguments)
+        configfile = self._args.configfile if hasattr(self._args, "configfile") else None
+        normalization = None if self._args.normalization == "none" else self._args.normalization
+        self._extractor = Extractor(self._args.detector,
+                                    self._args.aligner,
+                                    self._args.masker,
+                                    configfile=configfile,
+                                    multiprocess=not self._args.singleprocess,
+                                    rotate_images=self._args.rotate_images,
+                                    min_size=self._args.min_size,
+                                    normalize_method=normalization)
+        self._threads = list()
+        self._verify_output = False
         logger.debug("Initialized %s", self.__class__.__name__)
 
     @property
-    def skip_num(self):
-        """ Number of frames to skip if extract_every_n is passed """
-        return self.args.extract_every_n if hasattr(self.args, "extract_every_n") else 1
+    def _save_interval(self):
+        """ int: The number of frames to be processed between each saving of the alignments file if
+        it has been provided, otherwise ``None`` """
+        if hasattr(self._args, "save_interval"):
+            return self._args.save_interval
+        return None
+
+    @property
+    def _skip_num(self):
+        """ int: Number of frames to skip if extract_every_n has been provided """
+        return self._args.extract_every_n if hasattr(self._args, "extract_every_n") else 1
+
+    def _set_skip_list(self):
+        """ Add the skip list to the image loader
+
+        Checks against `extract_every_n` and the existence of alignments data (can exist if
+        `skip_existing` or `skip_existing_faces` has been provided) and compiles a list of frame
+        indices that should not be processed, providing these to :class:`lib.image.ImagesLoader`.
+        """
+        if self._skip_num == 1 and not self._alignments.data:
+            logger.debug("No frames to be skipped")
+            return
+        skip_list = []
+        for idx, filename in enumerate(self._images.file_list):
+            if idx % self._skip_num != 0:
+                logger.trace("Adding image '%s' to skip list due to extract_every_n = %s",
+                             filename, self._skip_num)
+                skip_list.append(idx)
+            # Items may be in the alignments file if skip-existing[-faces] is selected
+            elif os.path.basename(filename) in self._alignments.data:
+                self._existing_count += 1
+                logger.trace("Removing image: '%s' due to previously existing", filename)
+                skip_list.append(idx)
+        if self._existing_count != 0:
+            logger.info("Skipping %s frames due to skip_existing/skip_existing_faces.",
+                        self._existing_count)
+        logger.debug("Adding skip list: %s", skip_list)
+        self._images.add_skip_list(skip_list)
 
     def process(self):
-        """ Perform the extraction process """
+        """ The entry point for triggering the Extraction Process.
+
+        Should only be called from  :class:`lib.cli.ScriptExecutor`
+        """
         logger.info('Starting, this may take a while...')
+        # from lib.queue_manager import queue_manager
         # queue_manager.debug_monitor(3)
-        self.threaded_io("load")
-        self.threaded_io("save")
-        self.run_extraction()
-        for thread in self.threads:
+        self._threaded_redirector("load")
+        self._run_extraction()
+        for thread in self._threads:
             thread.join()
-        self.alignments.save()
-        Utils.finalize(self.images.images_found // self.skip_num,
-                       self.alignments.faces_count,
-                       self.verify_output)
+        self._alignments.save()
+        Utils.finalize(self._images.process_count + self._existing_count,
+                       self._alignments.faces_count,
+                       self._verify_output)
 
-    def threaded_io(self, task, io_args=None):
-        """ Perform I/O task in a background thread """
+    def _threaded_redirector(self, task, io_args=None):
+        """ Redirect image input/output tasks to relevant queues in background thread
+
+        Parameters
+        ----------
+        task: str
+            The name of the task to be put into a background thread
+        io_args: tuple, optional
+            Any arguments that need to be provided to the background function
+        """
         logger.debug("Threading task: (Task: '%s')", task)
         io_args = tuple() if io_args is None else (io_args, )
-        if task == "load":
-            func = self.load_images
-        elif task == "save":
-            func = self.save_faces
-        elif task == "reload":
-            func = self.reload_images
+        func = getattr(self, "_{}".format(task))
         io_thread = MultiThread(func, *io_args, thread_count=1)
         io_thread.start()
-        self.threads.append(io_thread)
+        self._threads.append(io_thread)
+
+    def _load(self):
+        """ Load the images
 
-    def load_images(self):
-        """ Load the images """
+        Loads images from :class:`lib.image.ImagesLoader`, formats them into a dict compatible
+        with :class:`plugins.extract.Pipeline.Extractor` and passes them into the extraction queue.
+        """
         logger.debug("Load Images: Start")
-        load_queue = self.extractor.input_queue
-        idx = 0
-        for filename, image in self.images.load():
-            idx += 1
+        load_queue = self._extractor.input_queue
+        for filename, image in self._images.load():
             if load_queue.shutdown.is_set():
                 logger.debug("Load Queue: Stop signal received. Terminating")
                 break
-            if idx % self.skip_num != 0:
-                logger.trace("Skipping image '%s' due to extract_every_n = %s",
-                             filename, self.skip_num)
-                continue
-            if image is None or (not image.any() and image.ndim not in ((2, 3))):
-                # All black frames will return not np.any() so check dims too
-                logger.warning("Unable to open image. Skipping: '%s'", filename)
-                continue
-            imagename = os.path.basename(filename)
-            if imagename in self.alignments.data.keys():
-                logger.trace("Skipping image: '%s'", filename)
-                continue
             item = {"filename": filename,
                     "image": image[..., :3]}
             load_queue.put(item)
         load_queue.put("EOF")
         logger.debug("Load Images: Complete")
 
-    def reload_images(self, detected_faces):
-        """ Reload the images and pair to detected face """
+    def _reload(self, detected_faces):
+        """ Reload the images and pair to detected face
+
+        When the extraction pipeline is running in serial mode, images are reloaded from disk,
+        paired with their extraction data and passed back into the extraction queue
+
+        Parameters
+        ----------
+        detected_faces: dict
+            Dictionary of detected_faces with the filename as its key and a list of
+            :class:`lib.faces_detect.DetectedFace` as the values for pairing with reloaded images.
+        """
         logger.debug("Reload Images: Start. Detected Faces Count: %s", len(detected_faces))
-        load_queue = self.extractor.input_queue
-        idx = 0
-        for filename, image in self.images.load():
-            idx += 1
+        load_queue = self._extractor.input_queue
+        for filename, image in self._images.load():
             if load_queue.shutdown.is_set():
                 logger.debug("Reload Queue: Stop signal received. Terminating")
                 break
-            if idx % self.skip_num != 0:
-                logger.trace("Skipping image '%s' due to extract_every_n = %s",
-                             filename, self.skip_num)
-                continue
             logger.trace("Reloading image: '%s'", filename)
             detect_item = detected_faces.pop(filename, None)
             if not detect_item:
@@ -133,130 +184,101 @@ class Extract():
         load_queue.put("EOF")
         logger.debug("Reload Images: Complete")
 
-    def save_faces(self):
-        """ Save the generated faces """
-        logger.debug("Save Faces: Start")
-        while True:
-            if self.save_queue.shutdown.is_set():
-                logger.debug("Save Queue: Stop signal received. Terminating")
-                break
-            item = self.save_queue.get()
-            logger.trace(item)
-            if item == "EOF":
-                break
-            filename, face = item
-
-            logger.trace("Saving face: '%s'", filename)
-            try:
-                with open(filename, "wb") as out_file:
-                    out_file.write(face)
-            except Exception as err:  # pylint: disable=broad-except
-                logger.error("Failed to save image '%s'. Original Error: %s", filename, err)
-                continue
-        logger.debug("Save Faces: Complete")
-
-    def process_item_count(self):
-        """ Return the number of items to be processedd """
-        processed = sum(os.path.basename(frame) in self.alignments.data.keys()
-                        for frame in self.images.input_images)
-        logger.debug("Items already processed: %s", processed)
-
-        if processed != 0 and self.args.skip_existing:
-            logger.info("Skipping previously extracted frames: %s", processed)
-        if processed != 0 and self.args.skip_faces:
-            logger.info("Skipping frames with detected faces: %s", processed)
-
-        to_process = (self.images.images_found - processed) // self.skip_num
-        logger.debug("Items to be Processed: %s", to_process)
-        if to_process == 0:
-            logger.error("No frames to process. Exiting")
-            queue_manager.terminate_queues()
-            exit(0)
-        return to_process
-
-    def run_extraction(self):
-        """ Run Face Detection """
-        to_process = self.process_item_count()
-        size = self.args.size if hasattr(self.args, "size") else 256
+    def _run_extraction(self):
+        """ The main Faceswap Extraction process
+
+        Receives items from :class:`plugins.extract.Pipeline.Extractor` and either saves out the
+        faces and data (if on the final pass) or reprocesses data through the pipeline for serial
+        processing.
+        """
+        size = self._args.size if hasattr(self._args, "size") else 256
+        saver = ImagesSaver(self._output_dir, as_bytes=True)
         exception = False
 
-        for phase in range(self.extractor.passes):
+        for phase in range(self._extractor.passes):
             if exception:
                 break
-            is_final = self.extractor.final_pass
+            is_final = self._extractor.final_pass
             detected_faces = dict()
-            self.extractor.launch()
-            self.check_thread_error()
+            self._extractor.launch()
+            self._check_thread_error()
             desc = "Running pass {} of {}: {}".format(phase + 1,
-                                                      self.extractor.passes,
-                                                      self.extractor.phase.title())
-            status_bar = tqdm(self.extractor.detected_faces(),
-                              total=to_process,
+                                                      self._extractor.passes,
+                                                      self._extractor.phase.title())
+            status_bar = tqdm(self._extractor.detected_faces(),
+                              total=self._images.process_count,
                               file=sys.stdout,
                               desc=desc)
             for idx, faces in enumerate(status_bar):
-                self.check_thread_error()
+                self._check_thread_error()
                 exception = faces.get("exception", False)
                 if exception:
                     break
-                filename = faces["filename"]
 
-                if self.extractor.final_pass:
-                    self.output_processing(faces, size, filename)
-                    self.output_faces(filename, faces)
-                    if self.save_interval and (idx + 1) % self.save_interval == 0:
-                        self.alignments.save()
+                if self._extractor.final_pass:
+                    self._output_processing(faces, size)
+                    self._output_faces(saver, faces)
+                    if self._save_interval and (idx + 1) % self._save_interval == 0:
+                        self._alignments.save()
                 else:
                     del faces["image"]
-                    detected_faces[filename] = faces
                 status_bar.update(1)
 
-            if is_final:
-                logger.debug("Putting EOF to save")
-                self.save_queue.put("EOF")
-            else:
+            if not is_final:
                 logger.debug("Reloading images")
-                self.threaded_io("reload", detected_faces)
+                self._threaded_redirector("reload", detected_faces)
+        saver.close()
 
-    def check_thread_error(self):
-        """ Check and raise thread errors """
-        for thread in self.threads:
+    def _check_thread_error(self):
+        """ Check if any errors have occurred in the running threads and their errors """
+        for thread in self._threads:
             thread.check_and_raise_error()
 
-    def output_processing(self, faces, size, filename):
-        """ Prepare faces for output """
-        self.align_face(faces, size, filename)
-        self.post_process.do_actions(faces)
+    def _output_processing(self, faces, size):
+        """ Prepare faces for output
+
+        Loads the aligned face, perform any processing actions and verify the output.
+
+        Parameters:
+        faces: dict
+            Dictionary output from :class:`plugins.extract.Pipeline.Extractor`
+        size: int
+            The size that the aligned face should be created at
+        """
+        for face in faces["detected_faces"]:
+            face.load_aligned(faces["image"], size=size)
+
+        self._post_process.do_actions(faces)
 
         faces_count = len(faces["detected_faces"])
         if faces_count == 0:
-            logger.verbose("No faces were detected in image: %s", os.path.basename(filename))
+            logger.verbose("No faces were detected in image: %s",
+                           os.path.basename(faces["filename"]))
 
-        if not self.verify_output and faces_count > 1:
-            self.verify_output = True
+        if not self._verify_output and faces_count > 1:
+            self._verify_output = True
 
-    def align_face(self, faces, size, filename):
-        """ Align the detected face and add the destination file path """
-        final_faces = list()
-        image = faces["image"]
-        detected_faces = faces["detected_faces"]
-        for face in detected_faces:
-            face.load_aligned(image, size=size)
-            final_faces.append({"file_location": self.output_dir / Path(filename).stem,
-                                "face": face})
-        faces["detected_faces"] = final_faces
-
-    def output_faces(self, filename, faces):
-        """ Output faces to save thread """
+    def _output_faces(self, saver, faces):
+        """ Output faces to save thread
+
+        Set the face filename based on the frame name and put the face to the
+        :class:`lib.image.ImagesSaver` save queue and add the face information to the alignments
+        data.
+
+        Parameters
+        ----------
+        saver: lib.images.ImagesSaver
+            The background saver for saving the image
+        faces: dict
+            The output dictionary from :class:`plugins.extract.Pipeline.Extractor`
+        """
+        logger.debug("Save Faces: Start")
         final_faces = list()
-        for idx, detected_face in enumerate(faces["detected_faces"]):
-            output_file = detected_face["file_location"]
-            extension = Path(filename).suffix
-            out_filename = "{}_{}{}".format(str(output_file), str(idx), extension)
-
-            face = detected_face["face"]
-            resized_face = face.aligned_face
-            face.hash, img = encode_image_with_hash(resized_face, extension)
-            self.save_queue.put((out_filename, img))
+        filename, extension = os.path.splitext(os.path.basename(faces["filename"]))
+        for idx, face in enumerate(faces["detected_faces"]):
+            output_filename = "{}_{}{}".format(filename, str(idx), extension)
+            face.hash, image = encode_image_with_hash(face.aligned_face, extension)
+
+            saver.save(output_filename, image)
             final_faces.append(face.to_alignment())
-        self.alignments.data[os.path.basename(filename)] = final_faces
+        self._alignments.data[os.path.basename(faces["filename"])] = final_faces
diff --git a/tools/mask.py b/tools/mask.py
index c77e272..46c2184 100644
--- a/tools/mask.py
+++ b/tools/mask.py
@@ -9,7 +9,7 @@ from tqdm import tqdm
 
 from lib.alignments import Alignments
 from lib.faces_detect import DetectedFace
-from lib.image import BackgroundIO
+from lib.image import ImagesLoader, ImagesSaver
 
 from lib.multithreading import MultiThread
 from lib.utils import set_system_verbosity, get_folder
@@ -45,10 +45,7 @@ class Mask():
 
         self._check_input(arguments.input)
         self._saver = self._set_saver(arguments)
-        self._loader = BackgroundIO(arguments.input,
-                                    "load",
-                                    load_with_hash=self._input_is_faces,
-                                    queue_size=16)
+        self._loader = ImagesLoader(arguments.input, load_with_hash=self._input_is_faces)
         self._alignments = Alignments(os.path.dirname(arguments.alignments),
                                       filename=os.path.basename(arguments.alignments))
 
@@ -84,9 +81,9 @@ class Mask():
 
         Returns
         -------
-        ``None`` or :class:`lib.image.BackgroundIO`:
-            If output is requested, returns a :class:`lib.image.BackgroundIO` in saver mode
-            otherwise returns ``None``
+        ``None`` or :class:`lib.image.ImagesSaver`:
+            If output is requested, returns a :class:`lib.image.ImagesSaver` otherwise
+            returns ``None``
         """
         if not hasattr(arguments, "output") or arguments.output is None or not arguments.output:
             if self._update_type == "output":
@@ -96,7 +93,7 @@ class Mask():
             return None
         output_dir = str(get_folder(arguments.output, make_folder=True))
         logger.info("Saving preview masks to: '%s'", output_dir)
-        saver = BackgroundIO(output_dir, "save", queue_size=16)
+        saver = ImagesSaver(output_dir)
         logger.debug(saver)
         return saver
 
@@ -330,7 +327,7 @@ class Mask():
                            self._mask_type, frame, idx)
             return
         image = self._create_image(detected_face)
-        logger.trace("filename: '%s', image_shape: %s", image.shape)
+        logger.trace("filename: '%s', image_shape: %s", filename, image.shape)
         self._saver.save(filename, image)
 
     def _create_image(self, detected_face):
