commit 7904b3210163b68c686a2df9f3550370b681a522
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon May 6 17:15:14 2019 +0000

    Remove Dlib Aligner
    
    Remove Dlib Aligner
    Add CV2-DNN Aligner replacement for dlib
    Remove aligner models from repo
    Add download function to pull models from remote location
    Minor FAN fixups

diff --git a/lib/cli.py b/lib/cli.py
index 7319673..a925af2 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -505,8 +505,9 @@ class ExtractArgs(ExtractConvertArgs):
             "choices": PluginLoader.get_available_extractors("align"),
             "default": "fan",
             "help": "R|Aligner to use."
-                    "\nL|'dlib': Dlib Pose Predictor. Faster, less "
-                    "resource intensive, but less accurate."
+                    "\nL|'cv2-dnn': A cpu only CNN based landmark detector. Faster, less "
+                    "resource intensive, but less accurate. Only use this if not using a gpu "
+                    " and time is important."
                     "\nL|'fan': Face Alignment Network. Best aligner. "
                     "GPU heavy, slow when not running on GPU"})
         argument_list.append({"opts": ("-r", "--rotate-images"),
diff --git a/lib/utils.py b/lib/utils.py
index 97ad380..218a97d 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -3,7 +3,10 @@
 
 import logging
 import os
+import urllib
 import warnings
+import zipfile
+from socket import timeout as socket_timeout, error as socket_error
 
 from hashlib import sha1
 from pathlib import Path
@@ -11,9 +14,10 @@ from re import finditer
 
 import cv2
 import numpy as np
-
 import dlib
 
+from tqdm import tqdm
+
 from lib.faces_detect import DetectedFace
 from lib.logger import get_loglevel
 
@@ -215,3 +219,173 @@ def safe_shutdown():
     while not queue_manager._log_queue.empty():  # pylint: disable=protected-access
         continue
     queue_manager.manager.shutdown()
+
+
+class GetModel():
+    """ Check for models in their cache path
+        If available, return the path, if not available, get, unzip and install model
+
+        model_name: The name of the model to be loaded
+        cache_dir: the model cache folder folder of the current plugin calling this class """
+
+    def __init__(self, model_filename, cache_dir):
+        self.model_filename = model_filename
+        self.cache_dir = cache_dir
+        self.url_base = "https://github.com/deepfakes-models/faceswap-models/releases/download"
+        self.chunk_size = 1024  # Chunk size for downloading and unzipping
+
+        self.get()
+        self.model_path = self._model_path
+
+    @property
+    def _model_id(self):
+        """ Return a mapping of model names to model ids as stored in github """
+        ids = {
+            # EXTRACT (SECTION 1)
+            "face-alignment-network_2d4": 0,
+            "cnn-facial-landmark": 1,
+            # TRAIN (SECTION 2)
+            # CONVERT (SECTION 3)
+            }
+        return ids[self._model_name]
+
+    @property
+    def _model_full_name(self):
+        """ Return the model version from the filename """
+        retval = os.path.splitext(self.model_filename)[0]
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _model_name(self):
+        """ Return the model version from the filename """
+        retval = self._model_full_name[:self._model_full_name.rfind("_")]
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _model_version(self):
+        """ Return the model version from the filename """
+        retval = int(self._model_full_name[self._model_full_name.rfind("_") + 2:])
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _model_path(self):
+        """ Return the model path in the cache folder """
+        retval = os.path.join(self.cache_dir, self.model_filename)
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _model_zip_path(self):
+        """ Full path to downloaded zip file """
+        retval = os.path.join(self.cache_dir, "{}.zip".format(self._model_full_name))
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _model_exists(self):
+        retval = os.path.exists(self._model_path)
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _plugin_section(self):
+        """ Get the plugin section from the config_dir """
+        path = os.path.normpath(self.cache_dir)
+        split = path.split(os.sep)
+        retval = split[split.index("plugins") + 1]
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _url_section(self):
+        """ Return the section ID in github for this plugin type """
+        sections = dict(extract=1, train=2, convert=3)
+        retval = sections[self._plugin_section]
+        logger.trace(retval)
+        return retval
+
+    @property
+    def _url_download(self):
+        """ Base URL for models """
+        tag = "v{}.{}.{}".format(self._url_section, self._model_id, self._model_version)
+        retval = "{}/{}/{}.zip".format(self.url_base, tag, self._model_full_name)
+        logger.trace("Download url: %s", retval)
+        return retval
+
+    def get(self):
+        """ Check the model exists, if not, download and unzip into location """
+        if self._model_exists:
+            logger.debug("Model exists: %s", self._model_path)
+            return
+        self.download_model()
+        self.unzip_model()
+        os.remove(self._model_zip_path)
+
+    def download_model(self):
+        """ Download model zip to cache dir """
+        logger.info("Downloading model: '%s'", self._model_name)
+        attempts = 3
+        for attempt in range(attempts):
+            try:
+                response = urllib.request.urlopen(self._url_download, timeout=10)
+                logger.debug("header info: {%s}", response.info())
+                logger.debug("Return Code: %s", response.getcode())
+                self.write_zipfile(response)
+                break
+            except (socket_error, socket_timeout,
+                    urllib.error.HTTPError, urllib.error.URLError) as err:
+                if attempt + 1 < attempts:
+                    logger.warning("Error downloading model (%s). Retrying %s of %s...",
+                                   str(err), attempt + 2, attempts)
+                else:
+                    logger.error("Failed to download model. Exiting. (Error: '%s', URL: '%s')",
+                                 str(err), self._url_download)
+                    exit(1)
+
+    def write_zipfile(self, response):
+        """ Write the model zip file to disk """
+        length = int(response.getheader("content-length"))
+        with open(self._model_zip_path, "wb") as out_file:
+            pbar = tqdm(desc="Downloading",
+                        unit="B",
+                        total=length,
+                        unit_scale=True,
+                        unit_divisor=1024)
+            while True:
+                buffer = response.read(self.chunk_size)
+                if not buffer:
+                    break
+                pbar.update(len(buffer))
+                out_file.write(buffer)
+
+    def unzip_model(self):
+        """ Unzip the model file to the cachedir """
+        logger.info("Extracting: '%s'", self._model_name)
+        try:
+            zip_file = zipfile.ZipFile(self._model_zip_path, "r")
+            self.write_model(zip_file)
+        except Exception as err:  # pylint:disable=broad-except
+            logger.error("Unable to extract model file: %s", str(err))
+            exit(1)
+
+    def write_model(self, zip_file):
+        """ Extract files from zipfile and write, with progress bar """
+        length = sum(f.file_size for f in zip_file.infolist())
+        fnames = zip_file.namelist()
+        logger.debug("Zipfile: Filenames: %s, Total Size: %s", fnames, length)
+        pbar = tqdm(desc="Extracting", unit="B", total=length, unit_scale=True, unit_divisor=1024)
+        for fname in fnames:
+            out_fname = os.path.join(self.cache_dir, fname)
+            logger.debug("Extracting from: '%s' to '%s'", self._model_zip_path, out_fname)
+            zipped = zip_file.open(fname)
+            with open(out_fname, "wb") as out_file:
+                while True:
+                    buffer = zipped.read(self.chunk_size)
+                    if not buffer:
+                        break
+                    pbar.update(len(buffer))
+                    out_file.write(buffer)
+        zip_file.close()
diff --git a/plugins/extract/align/.cache/.keep b/plugins/extract/align/.cache/.keep
new file mode 100644
index 0000000..e69de29
diff --git a/plugins/extract/align/.cache/2DFAN-4.pb b/plugins/extract/align/.cache/2DFAN-4.pb
deleted file mode 100755
index 6e52218..0000000
Binary files a/plugins/extract/align/.cache/2DFAN-4.pb and /dev/null differ
diff --git a/plugins/extract/align/_base.py b/plugins/extract/align/_base.py
index baf13a1..9dad4b1 100644
--- a/plugins/extract/align/_base.py
+++ b/plugins/extract/align/_base.py
@@ -23,18 +23,23 @@ import traceback
 
 from io import StringIO
 
+import cv2
+
 from lib.aligner import Extract
 from lib.gpu_stats import GPUStats
+from lib.utils import GetModel
 
-logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
+logger = logging.getLogger(__name__)  # pylint:disable=invalid-name
 
 
 class Aligner():
     """ Landmarks Aligner Object """
-    def __init__(self, loglevel):
-        logger.debug("Initializing %s", self.__class__.__name__)
+    def __init__(self, loglevel, model_filename=None, colorspace="BGR", input_size=256):
+        logger.debug("Initializing %s: (model_filename: '%s', colorspace: '%s'. input_size: %s)",
+                     self.__class__.__name__, model_filename, colorspace, input_size)
         self.loglevel = loglevel
-        self.cachepath = os.path.join(os.path.dirname(__file__), ".cache")
+        self.colorspace = colorspace.upper()
+        self.input_size = input_size
         self.extract = Extract()
         self.init = None
         self.error = None
@@ -43,8 +48,8 @@ class Aligner():
         # See lib.queue_manager.QueueManager for getting queues
         self.queues = {"in": None, "out": None}
 
-        #  Path to model if required
-        self.model_path = self.set_model_path()
+        #  Get model if required
+        self.model_path = self.get_model(model_filename)
 
         # Approximate VRAM required for aligner. Used to calculate
         # how many parallel processes / batches can be run.
@@ -54,12 +59,6 @@ class Aligner():
 
     # <<< OVERRIDE METHODS >>> #
     # These methods must be overriden when creating a plugin
-    @staticmethod
-    def set_model_path():
-        """ path to data file/models
-            override for specific detector """
-        raise NotImplementedError()
-
     def initialize(self, *args, **kwargs):
         """ Inititalize the aligner
             Tasks to be run before any alignments are performed.
@@ -71,15 +70,25 @@ class Aligner():
         self.queues["in"] = kwargs["in_queue"]
         self.queues["out"] = kwargs["out_queue"]
 
-    def align(self, *args, **kwargs):
-        """ Process landmarks
-            Override for specific detector
-            Must return a list of dlib rects"""
-        if not self.init:
-            self.initialize(*args, **kwargs)
-        logger.debug("Launching Align: (args: %s kwargs: %s)", args, kwargs)
+    def align_image(self, detected_face, image):
+        """ Align the incoming image for feeding into aligner
+            Override for aligner specific processing """
+        raise NotImplementedError
+
+    def predict_landmarks(self, feed_dict):
+        """ Predict the 68 point landmarks
+            Override for aligner specific landmark prediction """
+        raise NotImplementedError
+
+    # <<< GET MODEL >>> #
+    @staticmethod
+    def get_model(model_filename):
+        """ Check if model is available, if not, download and unzip it """
+        cache_path = os.path.join(os.path.dirname(__file__), ".cache")
+        model = GetModel(model_filename, cache_path)
+        return model.model_path
 
-    # <<< DETECTION WRAPPER >>> #
+    # <<< ALIGNMENT WRAPPER >>> #
     def run(self, *args, **kwargs):
         """ Parent align process.
             This should always be called as the entry point so exceptions
@@ -87,7 +96,7 @@ class Aligner():
             Do not override """
         try:
             self.align(*args, **kwargs)
-        except Exception:  # pylint: disable=broad-except
+        except Exception:  # pylint:disable=broad-except
             logger.error("Caught exception in child process: %s", os.getpid())
             # Display traceback if in initialization stage
             if not self.init.is_set():
@@ -98,6 +107,56 @@ class Aligner():
             self.queues["out"].put(exception)
             exit(1)
 
+    def align(self, *args, **kwargs):
+        """ Process landmarks """
+        if not self.init:
+            self.initialize(*args, **kwargs)
+        logger.debug("Launching Align: (args: %s kwargs: %s)", args, kwargs)
+
+        for item in self.get_item():
+            if item == "EOF":
+                self.finalize(item)
+                break
+            image = self.convert_color(item["image"])
+
+            logger.trace("Aligning faces")
+            try:
+                item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
+                logger.trace("Aligned faces: %s", item["landmarks"])
+            except ValueError as err:
+                logger.warning("Image '%s' could not be processed. This may be due to corrupted "
+                               "data: %s", item["filename"], str(err))
+                item["detected_faces"] = list()
+                item["landmarks"] = list()
+                # UNCOMMENT THIS CODE BLOCK TO PRINT TRACEBACK ERRORS
+                # import sys
+                # exc_info = sys.exc_info()
+                # traceback.print_exception(*exc_info)
+            self.finalize(item)
+        logger.debug("Completed Align")
+
+    def convert_color(self, image):
+        """ Convert the image to the correct colorspace """
+        logger.trace("Converting image to colorspace: %s", self.colorspace)
+        if self.colorspace == "RGB":
+            cvt_image = image[:, :, ::-1].copy()
+        elif self.colorspace == "GRAY":
+            cvt_image = cv2.cvtColor(image.copy(), cv2.COLOR_BGR2GRAY)  # pylint:disable=no-member
+        else:
+            cvt_image = image.copy()
+        return cvt_image
+
+    def process_landmarks(self, image, detected_faces):
+        """ Align image and process landmarks """
+        logger.trace("Processing landmarks")
+        retval = list()
+        for detected_face in detected_faces:
+            feed_dict = self.align_image(detected_face, image)
+            landmarks = self.predict_landmarks(feed_dict)
+            retval.append(landmarks)
+        logger.trace("Processed landmarks: %s", retval)
+        return retval
+
     # <<< FINALIZE METHODS>>> #
     def finalize(self, output):
         """ This should be called as the final task of each plugin
diff --git a/plugins/extract/align/cv2_dnn.py b/plugins/extract/align/cv2_dnn.py
new file mode 100644
index 0000000..4361352
--- /dev/null
+++ b/plugins/extract/align/cv2_dnn.py
@@ -0,0 +1,165 @@
+#!/usr/bin/env python3
+""" CV2 DNN landmarks extractor for faceswap.py
+Adapted from: https://github.com/yinguobing/cnn-facial-landmark
+MIT License
+
+Copyright (c) 2017 Yin Guobing
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+"""
+
+import cv2
+import numpy as np
+
+from ._base import Aligner, logger
+
+
+class Align(Aligner):
+    """ Perform transformation to align and get landmarks """
+    def __init__(self, **kwargs):
+        model_filename = "cnn-facial-landmark_v1.pb"
+        super().__init__(model_filename=model_filename, colorspace="RGB", input_size=128, **kwargs)
+        self.vram = 0  # Doesn't use GPU
+        self.model = None
+
+    def initialize(self, *args, **kwargs):
+        """ Initialization tasks to run prior to alignments """
+        try:
+            super().initialize(*args, **kwargs)
+            logger.info("Initializing cv2 DNN Aligner...")
+            logger.debug("cv2 DNN initialize: (args: %s kwargs: %s)", args, kwargs)
+            logger.verbose("Using CPU for alignment")
+
+            self.model = cv2.dnn.readNetFromTensorflow(  # pylint: disable=no-member
+                self.model_path)
+            self.model.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)  # pylint: disable=no-member
+            self.init.set()
+            logger.info("Initialized cv2 DNN Aligner.")
+        except Exception as err:
+            self.error.set()
+            raise err
+
+    def align_image(self, detected_face, image):
+        """ Align the incoming image for prediction """
+        logger.trace("Aligning image around center")
+
+        box = (detected_face.left(), detected_face.top(),
+               detected_face.right(), detected_face.bottom())
+        diff_height_width = (box[3] - box[1]) - (box[2] - box[0])
+        offset_y = int(abs(diff_height_width / 2))
+        box_moved = self.move_box(box, [0, offset_y])
+
+        # Make box square.
+        roi = self.get_square_box(box_moved)
+        # Pad the image if face is outside of boundaries
+        image = self.pad_image(roi, image)
+        face = image[roi[1]: roi[3], roi[0]: roi[2]]
+
+        if face.shape[0] < self.input_size:
+            interpolation = cv2.INTER_CUBIC  # pylint:disable=no-member
+        else:
+            interpolation = cv2.INTER_AREA  # pylint:disable=no-member
+
+        face = cv2.resize(face,  # pylint:disable=no-member
+                          dsize=(int(self.input_size), int(self.input_size)),
+                          interpolation=interpolation)
+        return dict(image=face, roi=roi)
+
+    @staticmethod
+    def move_box(box, offset):
+        """Move the box to direction specified by vector offset"""
+        left = box[0] + offset[0]
+        top = box[1] + offset[1]
+        right = box[2] + offset[0]
+        bottom = box[3] + offset[1]
+        return [left, top, right, bottom]
+
+    @staticmethod
+    def get_square_box(box):
+        """Get a square box out of the given box, by expanding it."""
+        left = box[0]
+        top = box[1]
+        right = box[2]
+        bottom = box[3]
+
+        box_width = right - left
+        box_height = bottom - top
+
+        # Check if box is already a square. If not, make it a square.
+        diff = box_height - box_width
+        delta = int(abs(diff) / 2)
+
+        if diff == 0:                   # Already a square.
+            return box
+        if diff > 0:                    # Height > width, a slim box.
+            left -= delta
+            right += delta
+            if diff % 2 == 1:
+                right += 1
+        else:                           # Width > height, a short box.
+            top -= delta
+            bottom += delta
+            if diff % 2 == 1:
+                bottom += 1
+
+        # Make sure box is always square.
+        assert ((right - left) == (bottom - top)), 'Box is not square.'
+
+        return [left, top, right, bottom]
+
+    @staticmethod
+    def pad_image(box, image):
+        """Pad image if facebox falls outside of boundaries """
+        width, height = image.shape[:2]
+        pad_l = 1 - box[0] if box[0] < 0 else 0
+        pad_t = 1 - box[1] if box[1] < 0 else 0
+        pad_r = box[2] - width if box[2] > width else 0
+        pad_b = box[3] - height if box[3] > height else 0
+        logger.trace("Padding: (l: %s, t: %s, r: %s, b: %s)", pad_l, pad_t, pad_r, pad_b)
+        retval = cv2.copyMakeBorder(image.copy(),  # pylint: disable=no-member
+                                    pad_t,
+                                    pad_b,
+                                    pad_l,
+                                    pad_r,
+                                    cv2.BORDER_CONSTANT,  # pylint: disable=no-member
+                                    value=(0, 0, 0))
+        logger.trace("Padded shape: %s", retval.shape)
+        return retval
+
+    def predict_landmarks(self, feed_dict):
+        """ Predict the 68 point landmarks """
+        logger.trace("Predicting Landmarks")
+        image = np.expand_dims(np.transpose(feed_dict["image"], (2, 0, 1)), 0).astype("float32")
+        self.model.setInput(image)
+        prediction = self.model.forward()
+        pts_img = self.get_pts_from_predict(prediction, feed_dict["roi"])
+        return pts_img
+
+    @staticmethod
+    def get_pts_from_predict(prediction, roi):
+        """ Get points from predictor """
+        logger.trace("Obtain points from prediction")
+        points = np.array(prediction).flatten()
+        points = np.reshape(points, (-1, 2))
+        points *= (roi[2] - roi[0])
+        points[:, 0] += roi[0]
+        points[:, 1] += roi[1]
+        retval = np.rint(points).astype("uint").tolist()
+        logger.trace("Predicted Landmarks: %s", retval)
+        return retval
diff --git a/plugins/extract/align/dlib.py b/plugins/extract/align/dlib.py
deleted file mode 100644
index 3fd97e2..0000000
--- a/plugins/extract/align/dlib.py
+++ /dev/null
@@ -1,60 +0,0 @@
-#!/usr/bin/env python3
-""" DLib landmarks extractor for faceswap.py """
-import face_recognition_models
-import dlib
-
-from ._base import Aligner, logger
-
-
-class Align(Aligner):
-    """ Perform transformation to align and get landmarks """
-    def __init__(self, **kwargs):
-        super().__init__(**kwargs)
-        self.vram = 0  # Doesn't use GPU
-        self.model = None
-
-    def set_model_path(self):
-        """ Model path handled by face_recognition_models """
-        model_path = face_recognition_models.pose_predictor_model_location()
-        logger.debug("Loading model: '%s'", model_path)
-        return model_path
-
-    def initialize(self, *args, **kwargs):
-        """ Initialization tasks to run prior to alignments """
-        try:
-            super().initialize(*args, **kwargs)
-            logger.info("Initializing Dlib Pose Predictor...")
-            logger.debug("dlib initialize: (args: %s kwargs: %s)", args, kwargs)
-            self.model = dlib.shape_predictor(self.model_path)  # pylint: disable=c-extension-no-member
-            self.init.set()
-            logger.info("Initialized Dlib Pose Predictor.")
-        except Exception as err:
-            self.error.set()
-            raise err
-
-    def align(self, *args, **kwargs):
-        """ Perform alignments on detected faces """
-        super().align(*args, **kwargs)
-        for item in self.get_item():
-            if item == "EOF":
-                self.finalize(item)
-                break
-            image = item["image"][:, :, ::-1].copy()
-
-            logger.trace("Algning faces")
-            item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
-            logger.trace("Algned faces: %s", item["landmarks"])
-
-            self.finalize(item)
-        logger.debug("Completed Align")
-
-    def process_landmarks(self, image, detected_faces):
-        """ Align image and process landmarks """
-        logger.trace("Processing Landmarks")
-        retval = list()
-        for detected_face in detected_faces:
-            pts = self.model(image, detected_face).parts()
-            landmarks = [(point.x, point.y) for point in pts]
-            retval.append(landmarks)
-        logger.trace("Processed Landmarks: %s", retval)
-        return retval
diff --git a/plugins/extract/align/fan.py b/plugins/extract/align/fan.py
index 56c3183..9d1077a 100644
--- a/plugins/extract/align/fan.py
+++ b/plugins/extract/align/fan.py
@@ -3,7 +3,6 @@
     Code adapted and modified from:
     https://github.com/1adrianb/face-alignment
 """
-import os
 import cv2
 import numpy as np
 
@@ -13,20 +12,11 @@ from ._base import Aligner, logger
 class Align(Aligner):
     """ Perform transformation to align and get landmarks """
     def __init__(self, **kwargs):
-        super().__init__(**kwargs)
+        model_filename = "face-alignment-network_2d4_v1.pb"
+        super().__init__(model_filename=model_filename, colorspace="RGB", input_size=256, **kwargs)
         self.vram = 2240
-        self.reference_scale = 195.0
         self.model = None
-        self.test = None
-
-    def set_model_path(self):
-        """ Load the mtcnn models """
-        model_path = os.path.join(self.cachepath, "2DFAN-4.pb")
-        if not os.path.exists(model_path):
-            raise Exception("Error: Unable to find {}, reinstall "
-                            "the lib!".format(model_path))
-        logger.debug("Loading model: '%s'", model_path)
-        return model_path
+        self.reference_scale = 195
 
     def initialize(self, *args, **kwargs):
         """ Initialization tasks to run prior to alignments """
@@ -51,38 +41,14 @@ class Align(Aligner):
             self.error.set()
             raise err
 
-    def align(self, *args, **kwargs):
-        """ Perform alignments on detected faces """
-        super().align(*args, **kwargs)
-        for item in self.get_item():
-            if item == "EOF":
-                self.finalize(item)
-                break
-            image = item["image"][:, :, ::-1].copy()
-
-            logger.trace("Aligning faces")
-            try:
-                item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
-                logger.trace("Aligned faces: %s", item["landmarks"])
-            except ValueError as err:
-                logger.warning("Image '%s' could not be processed. This may be due to corrupted "
-                               "data: %s", item["filename"], str(err))
-                item["detected_faces"] = list()
-                item["landmarks"] = list()
-            self.finalize(item)
-        logger.debug("Completed Align")
-
-    def process_landmarks(self, image, detected_faces):
-        """ Align image and process landmarks """
-        logger.trace("Processing landmarks")
-        retval = list()
-        for detected_face in detected_faces:
-            center, scale = self.get_center_scale(detected_face)
-            aligned_image = self.align_image(image, center, scale)
-            landmarks = self.predict_landmarks(aligned_image, center, scale)
-            retval.append(landmarks)
-        logger.trace("Processed landmarks: %s", retval)
-        return retval
+    # DETECTED FACE BOUNDING BOX PROCESSING
+    def align_image(self, detected_face, image):
+        """ Get center and scale, crop and align image around center """
+        logger.trace("Aligning image around center")
+        center, scale = self.get_center_scale(detected_face)
+        image = self.crop(image, center, scale)
+        logger.trace("Aligned image around center")
+        return dict(image=image, center=center, scale=scale)
 
     def get_center_scale(self, detected_face):
         """ Get the center and set scale of bounding box """
@@ -103,61 +69,25 @@ class Align(Aligner):
         logger.trace("Calculated center and scale: %s, %s", center, scale)
         return center, scale
 
-    def align_image(self, image, center, scale):
-        """ Crop and align image around center """
-        logger.trace("Aligning image around center")
-        image = self.crop(
-            image,
-            center,
-            scale).transpose((2, 0, 1)).astype(np.float32) / 255.0
-        logger.trace("Aligned image around center")
-        return np.expand_dims(image, 0)
-
-    def predict_landmarks(self, image, center, scale):
-        """ Predict the 68 point landmarks """
-        logger.trace("Predicting Landmarks")
-        prediction = self.model.predict(image)[-1]
-        pts_img = self.get_pts_from_predict(prediction, center, scale)
-        retval = [(int(pt[0]), int(pt[1])) for pt in pts_img]
-        logger.trace("Predicted Landmarks: %s", retval)
-        return retval
-
-    @staticmethod
-    def transform(point, center, scale, resolution):
-        """ Transform Image """
-        logger.trace("Transforming Points")
-        pnt = np.array([point[0], point[1], 1.0])
-        hscl = 200.0 * scale
-        eye = np.eye(3)
-        eye[0, 0] = resolution / hscl
-        eye[1, 1] = resolution / hscl
-        eye[0, 2] = resolution * (-center[0] / hscl + 0.5)
-        eye[1, 2] = resolution * (-center[1] / hscl + 0.5)
-        eye = np.linalg.inv(eye)
-        retval = np.matmul(eye, pnt)[0:2]
-        logger.trace("Transformed Points: %s", retval)
-        return retval
-
-    def crop(self, image, center, scale, resolution=256.0):  # pylint: disable=too-many-locals
+    def crop(self, image, center, scale):  # pylint:disable=too-many-locals
         """ Crop image around the center point """
         logger.trace("Cropping image")
-        v_ul = self.transform([1, 1], center, scale, resolution).astype(np.int)
-        v_br = self.transform([resolution, resolution],
+        is_color = image.ndim > 2
+        v_ul = self.transform([1, 1], center, scale, self.input_size).astype(np.int)
+        v_br = self.transform([self.input_size, self.input_size],
                               center,
                               scale,
-                              resolution).astype(np.int)
-        if image.ndim > 2:
+                              self.input_size).astype(np.int)
+        if is_color:
             new_dim = np.array([v_br[1] - v_ul[1],
                                 v_br[0] - v_ul[0],
                                 image.shape[2]],
                                dtype=np.int32)
-            self.test = new_dim
             new_img = np.zeros(new_dim, dtype=np.uint8)
         else:
             new_dim = np.array([v_br[1] - v_ul[1],
                                 v_br[0] - v_ul[0]],
                                dtype=np.int)
-            self.test = new_dim
             new_img = np.zeros(new_dim, dtype=np.uint8)
         height = image.shape[0]
         width = image.shape[1]
@@ -170,43 +100,80 @@ class Align(Aligner):
                          dtype=np.int32)
         old_y = np.array([max(1, v_ul[1] + 1), min(v_br[1], height)],
                          dtype=np.int32)
-        new_img[new_y[0] - 1:new_y[1],
-                new_x[0] - 1:new_x[1]] = image[old_y[0] - 1:old_y[1],
-                                               old_x[0] - 1:old_x[1], :]
-        # pylint: disable=no-member
-        new_img = cv2.resize(new_img,
-                             dsize=(int(resolution), int(resolution)),
-                             interpolation=cv2.INTER_LINEAR)
+        if is_color:
+            new_img[new_y[0] - 1:new_y[1],
+                    new_x[0] - 1:new_x[1]] = image[old_y[0] - 1:old_y[1],
+                                                   old_x[0] - 1:old_x[1], :]
+        else:
+            new_img[new_y[0] - 1:new_y[1],
+                    new_x[0] - 1:new_x[1]] = image[old_y[0] - 1:old_y[1],
+                                                   old_x[0] - 1:old_x[1]]
+
+        if new_img.shape[0] < self.input_size:
+            interpolation = cv2.INTER_CUBIC  # pylint:disable=no-member
+        else:
+            interpolation = cv2.INTER_AREA  # pylint:disable=no-member
+
+        new_img = cv2.resize(new_img,  # pylint:disable=no-member
+                             dsize=(int(self.input_size), int(self.input_size)),
+                             interpolation=interpolation)
         logger.trace("Cropped image")
         return new_img
 
-    def get_pts_from_predict(self, var_a, center, scale):
+    @staticmethod
+    def transform(point, center, scale, resolution):
+        """ Transform Image """
+        logger.trace("Transforming Points")
+        pnt = np.array([point[0], point[1], 1.0])
+        hscl = 200.0 * scale
+        eye = np.eye(3)
+        eye[0, 0] = resolution / hscl
+        eye[1, 1] = resolution / hscl
+        eye[0, 2] = resolution * (-center[0] / hscl + 0.5)
+        eye[1, 2] = resolution * (-center[1] / hscl + 0.5)
+        eye = np.linalg.inv(eye)
+        retval = np.matmul(eye, pnt)[0:2]
+        logger.trace("Transformed Points: %s", retval)
+        return retval
+
+    def predict_landmarks(self, feed_dict):
+        """ Predict the 68 point landmarks """
+        logger.trace("Predicting Landmarks")
+        image = np.expand_dims(
+            feed_dict["image"].transpose((2, 0, 1)).astype(np.float32) / 255.0, 0)
+        prediction = self.model.predict(image)[-1]
+        pts_img = self.get_pts_from_predict(prediction, feed_dict["center"], feed_dict["scale"])
+        retval = [(int(pt[0]), int(pt[1])) for pt in pts_img]
+        logger.trace("Predicted Landmarks: %s", retval)
+        return retval
+
+    def get_pts_from_predict(self, prediction, center, scale):
         """ Get points from predictor """
         logger.trace("Obtain points from prediction")
-        var_b = var_a.reshape((var_a.shape[0],
-                               var_a.shape[1] * var_a.shape[2]))
-        var_c = var_b.argmax(1).reshape((var_a.shape[0],
+        var_b = prediction.reshape((prediction.shape[0],
+                                    prediction.shape[1] * prediction.shape[2]))
+        var_c = var_b.argmax(1).reshape((prediction.shape[0],
                                          1)).repeat(2,
                                                     axis=1).astype(np.float)
-        var_c[:, 0] %= var_a.shape[2]
+        var_c[:, 0] %= prediction.shape[2]
         var_c[:, 1] = np.apply_along_axis(
-            lambda x: np.floor(x / var_a.shape[2]),
+            lambda x: np.floor(x / prediction.shape[2]),
             0,
             var_c[:, 1])
 
-        for i in range(var_a.shape[0]):
+        for i in range(prediction.shape[0]):
             pt_x, pt_y = int(var_c[i, 0]), int(var_c[i, 1])
             if pt_x > 0 and pt_x < 63 and pt_y > 0 and pt_y < 63:
-                diff = np.array([var_a[i, pt_y, pt_x+1]
-                                 - var_a[i, pt_y, pt_x-1],
-                                 var_a[i, pt_y+1, pt_x]
-                                 - var_a[i, pt_y-1, pt_x]])
+                diff = np.array([prediction[i, pt_y, pt_x+1]
+                                 - prediction[i, pt_y, pt_x-1],
+                                 prediction[i, pt_y+1, pt_x]
+                                 - prediction[i, pt_y-1, pt_x]])
 
                 var_c[i] += np.sign(diff)*0.25
 
         var_c += 0.5
-        retval = [self.transform(var_c[i], center, scale, var_a.shape[2])
-                  for i in range(var_a.shape[0])]
+        retval = [self.transform(var_c[i], center, scale, prediction.shape[2])
+                  for i in range(prediction.shape[0])]
         logger.trace("Obtained points from prediction: %s", retval)
 
         return retval
diff --git a/plugins/extract/detect/cv2_dnn.py b/plugins/extract/detect/cv2_dnn.py
index e067232..49d1356 100755
--- a/plugins/extract/detect/cv2_dnn.py
+++ b/plugins/extract/detect/cv2_dnn.py
@@ -31,10 +31,10 @@ class Detect(Detector):
     def initialize(self, *args, **kwargs):
         """ Calculate batch size """
         super().initialize(*args, **kwargs)
-        logger.info("Initializing CV2-DNN Detector...")
+        logger.info("Initializing cv2 DNN Detector...")
         logger.verbose("Using CPU for detection")
         self.init = True
-        logger.info("Initialized CV2-DNN Detector...")
+        logger.info("Initialized cv2 DNN Detector.")
 
     def detect_faces(self, *args, **kwargs):
         """ Detect faces in grayscale image """
