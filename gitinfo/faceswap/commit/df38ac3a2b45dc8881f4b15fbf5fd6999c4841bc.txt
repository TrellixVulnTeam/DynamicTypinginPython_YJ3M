commit df38ac3a2b45dc8881f4b15fbf5fd6999c4841bc
Author: Gareth Dunstone <freedom.2.the.leetle.people@gmail.com>
Date:   Thu Feb 1 21:50:29 2018 +1100

    added batch-size cli argumet.
    neatened up train.py and added LowMem trainer option.
    Added save_now/show key to preview.

diff --git a/lib/ModelAE.py b/lib/ModelAE.py
index 2f19e29..8f2febb 100644
--- a/lib/ModelAE.py
+++ b/lib/ModelAE.py
@@ -40,12 +40,11 @@ class ModelAE:
         print('saved model weights')
 
 class TrainerAE():
-    BATCH_SIZE = 64
-
-    def __init__(self, model, fn_A, fn_B):
+    def __init__(self, model, fn_A, fn_B, batch_size=64):
+        self.batch_size = batch_size
         self.model = model
-        self.images_A = minibatchAB(fn_A, self.BATCH_SIZE)
-        self.images_B = minibatchAB(fn_B, self.BATCH_SIZE)
+        self.images_A = minibatchAB(fn_A, self.batch_size)
+        self.images_B = minibatchAB(fn_B, self.batch_size)
 
     def train_one_step(self, iter, viewer):
         epoch, warped_A, target_A = next(self.images_A)
@@ -53,7 +52,7 @@ class TrainerAE():
 
         loss_A = self.model.autoencoder_A.train_on_batch(warped_A, target_A)
         loss_B = self.model.autoencoder_B.train_on_batch(warped_B, target_B)
-        print("[%s] [#%d] loss_A: %f, loss_B: %f"  % (time.strftime("%H:%M:%S"), iter, loss_A, loss_B))
+        print("[{0}] [#{1:05d}] loss_A: {2:.5f}, loss_B: {3:.5f}".format(time.strftime("%H:%M:%S"), iter, loss_A, loss_B))
 
         if viewer is not None:
             viewer(self.show_sample(target_A[0:14], target_B[0:14]), "training")
diff --git a/scripts/train.py b/scripts/train.py
index 4466da4..0c7bc8c 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -68,6 +68,14 @@ class TrainingProcessor(object):
                             dest="write_image",
                             default=False,
                             help="Writes the training result to a file even on preview mode.")
+        parser.add_argument('-t', '--trainer',
+                            type=str, choices=("Original","LowMem"),
+                            default="Original",
+                            help="Select which trainer to use, LowMem for cards < 2gb.")
+        parser.add_argument('-bs', '--batch-size',
+                            type=int,
+                            default=64,
+                            help="Batch size, as a power of 2 (64, 128, 256, etc)")
         parser = self.add_optional_arguments(parser)
         parser.set_defaults(func=self.process_arguments)
 
@@ -78,6 +86,7 @@ class TrainingProcessor(object):
     def process(self):
         import threading
         self.stop = False
+        self.save_now = False
 
         thr = threading.Thread(target=self.processThread, args=(), kwargs={})
         thr.start()
@@ -85,29 +94,36 @@ class TrainingProcessor(object):
         if self.arguments.preview:
             print('Using live preview')
             while True:
-                for name, image in self.preview_buffer.items():
-                    cv2.imshow(name, image)
-
-                key = cv2.waitKey(1000)
-                if key == ord('\n') or key == ord('\r'):
+                try:
+                    for name, image in self.preview_buffer.items():
+                        cv2.imshow(name, image)
+
+                    key = cv2.waitKey(1000)
+                    if key == ord('\n') or key == ord('\r'):
+                        break
+                    if key == ord('s'):
+                        self.save_now = True
+                except KeyboardInterrupt:
                     break
         else:
             input() # TODO how to catch a specific key instead of Enter?
+            # there isnt a good multiplatform solution: https://stackoverflow.com/questions/3523174/raw-input-in-python-without-pressing-enter
 
         print("Exit requested! The trainer will complete its current cycle, save the models and quit (it can take up a couple of seconds depending on your training speed). If you want to kill it now, press Ctrl + c")
         self.stop = True
         thr.join() # waits until thread finishes
-    
+
     def processThread(self):
-        variant = "Original" # TODO Pass as argument
-        
         print('Loading data, this may take a while...')
-        model = PluginLoader.get_model(variant)(self.arguments.model_dir)
+        model = PluginLoader.get_model(self.arguments.trainer)(self.arguments.model_dir)
         model.load(swapped=False)
 
         images_A = get_image_paths(self.arguments.input_A)
         images_B = get_image_paths(self.arguments.input_B)
-        trainer = PluginLoader.get_trainer(variant)(model, images_A, images_B)
+        trainer = PluginLoader.get_trainer(self.arguments.trainer)(model,
+                                                                   images_A,
+                                                                   images_B,
+                                                                   batch_size=self.arguments.batch_size)
 
         try:
             print('Starting. Press "Enter" to stop training and save model')
@@ -116,7 +132,7 @@ class TrainingProcessor(object):
 
                 save_iteration = epoch % self.arguments.save_interval == 0
 
-                trainer.train_one_step(epoch, self.show if save_iteration else None)
+                trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
 
                 if save_iteration:
                     model.save_weights()
@@ -125,6 +141,10 @@ class TrainingProcessor(object):
                     model.save_weights()
                     exit()
 
+                if self.save_now:
+                    model.save_weights()
+                    self.save_now = False
+
         except KeyboardInterrupt:
             try:
                 model.save_weights()
