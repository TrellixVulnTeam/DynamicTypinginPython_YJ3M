commit 31c51e8eb2a5674b00a6f4efe2fe7d7f456f679d
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Aug 12 22:34:32 2019 +0100

    DFL SAE

diff --git a/plugins/train/model/dfl_sae.py b/plugins/train/model/dfl_sae.py
new file mode 100644
index 0000000..e79822c
--- /dev/null
+++ b/plugins/train/model/dfl_sae.py
@@ -0,0 +1,188 @@
+#!/usr/bin/env python3
+""" DeepFakesLab SAE Model
+    Based on https://github.com/iperov/DeepFaceLab
+"""
+
+import numpy as np
+
+from keras.layers import Concatenate, Dense, Flatten, Input, Reshape
+from keras.models import Model as KerasModel
+
+from ._base import ModelBase, logger
+
+
+class Model(ModelBase):
+    """ Low Memory version of Original Faceswap Model """
+    def __init__(self, *args, **kwargs):
+        logger.debug("Initializing %s: (args: %s, kwargs: %s",
+                     self.__class__.__name__, args, kwargs)
+
+        self.configfile = kwargs.get("configfile", None)
+        kwargs["input_shape"] = (self.config["input_size"], self.config["input_size"], 3)
+
+        super().__init__(*args, **kwargs)
+        logger.debug("Initialized %s", self.__class__.__name__)
+
+    @property
+    def architecture(self):
+        """ Return the architecture used from config """
+        return self.config["architecture"].lower()
+
+    @property
+    def use_mask(self):
+        """ Return True if a mask has been set else false """
+        return self.config.get("mask_type", None) is not None
+
+    @property
+    def ae_dims(self):
+        """ Set the Autoencoder Dimensions or set to default """
+        retval = self.config["autoencoder_dims"]
+        if retval == 0:
+            retval = 256 if self.architecture == "liae" else 512
+        return retval
+
+    @property
+    def multiscale_count(self):
+        """ Return 3 if multiscale decoder is set else 1 """
+        retval = 3 if self.config["multiscale_decoder"] else 1
+        return retval
+
+    def add_networks(self):
+        """ Add the DFL SAE Networks """
+        logger.debug("Adding networks")
+        # Encoder
+        self.add_network("encoder", None, getattr(self, "encoder_{}".format(self.architecture))())
+
+        # Intermediate
+        if self.architecture == "liae":
+            self.add_network("intermediate", "b", self.inter_liae())
+            self.add_network("intermediate", None, self.inter_liae())
+
+        # Decoder
+        decoder_sides = [None] if self.architecture == "liae" else ["a", "b"]
+        for side in decoder_sides:
+            self.add_network("decoder", side, self.decoder(), is_output=True)
+        logger.debug("Added networks")
+
+    def build_autoencoders(self, inputs):
+        """ Initialize DFL SAE model """
+        logger.debug("Initializing model")
+        getattr(self, "build_{}_autoencoder".format(self.architecture))(inputs)
+        logger.debug("Initialized model")
+
+    def build_liae_autoencoder(self, inputs):
+        """ Build the LIAE Autoencoder """
+        for side in ("a", "b"):
+            encoder = self.networks["encoder"].network(inputs[0])
+            if side == "a":
+                intermediate = Concatenate()([self.networks["intermediate"].network(encoder),
+                                              self.networks["intermediate"].network(encoder)])
+            else:
+                intermediate = Concatenate()([self.networks["intermediate_b"].network(encoder),
+                                              self.networks["intermediate"].network(encoder)])
+            output = self.networks["decoder"].network(intermediate)
+            autoencoder = KerasModel(inputs, output)
+            self.add_predictor(side, autoencoder)
+
+    def build_df_autoencoder(self, inputs):
+        """ Build the DF Autoencoder """
+        for side in ("a", "b"):
+            logger.debug("Adding Autoencoder. Side: %s", side)
+            decoder = self.networks["decoder_{}".format(side)].network
+            output = decoder(self.networks["encoder"].network(inputs[0]))
+            autoencoder = KerasModel(inputs, output)
+            self.add_predictor(side, autoencoder)
+
+    def encoder_df(self):
+        """ DFL SAE DF Encoder Network"""
+        input_ = Input(shape=self.input_shape)
+        dims = self.input_shape[-1] * self.config["encoder_dims"]
+        lowest_dense_res = self.input_shape[0] // 16
+        var_x = input_
+        var_x = self.blocks.conv(var_x, dims)
+        var_x = self.blocks.conv(var_x, dims * 2)
+        var_x = self.blocks.conv(var_x, dims * 4)
+        var_x = self.blocks.conv(var_x, dims * 8)
+        var_x = Dense(self.ae_dims)(Flatten()(var_x))
+        var_x = Dense(lowest_dense_res * lowest_dense_res * self.ae_dims)(var_x)
+        var_x = Reshape((lowest_dense_res, lowest_dense_res, self.ae_dims))(var_x)
+        var_x = self.blocks.upscale(var_x, self.ae_dims)
+        return KerasModel(input_, var_x)
+
+    def encoder_liae(self):
+        """ DFL SAE LIAE Encoder Network """
+        input_ = Input(shape=self.input_shape)
+        dims = self.input_shape[-1] * self.config["encoder_dims"]
+        var_x = input_
+        var_x = self.blocks.conv(var_x, dims)
+        var_x = self.blocks.conv(var_x, dims * 2)
+        var_x = self.blocks.conv(var_x, dims * 4)
+        var_x = self.blocks.conv(var_x, dims * 8)
+        var_x = Flatten()(var_x)
+        return KerasModel(input_, var_x)
+
+    def inter_liae(self):
+        """ DFL SAE LIAE Intermediate Network """
+        input_ = Input(shape=self.networks["encoder"].output_shapes[0][1:])
+        lowest_dense_res = self.input_shape[0] // 16
+        var_x = input_
+        var_x = Dense(self.ae_dims)(var_x)
+        var_x = Dense(lowest_dense_res * lowest_dense_res * self.ae_dims * 2)(var_x)
+        var_x = Reshape((lowest_dense_res, lowest_dense_res, self.ae_dims * 2))(var_x)
+        var_x = self.blocks.upscale(var_x, self.ae_dims * 2)
+        return KerasModel(input_, var_x)
+
+    def decoder(self):
+        """ DFL SAE Decoder Network"""
+        if self.architecture == "liae":
+            input_shape = np.array(self.networks["intermediate"].output_shapes[0][1:]) * (1, 1, 2)
+        else:
+            input_shape = self.networks["encoder"].output_shapes[0][1:]
+        input_ = Input(shape=input_shape)
+        outputs = list()
+
+        dims = self.input_shape[-1] * self.config["decoder_dims"]
+        var_x = input_
+
+        var_x1 = self.blocks.upscale(var_x, dims * 8, res_block_follows=True)
+        var_x1 = self.blocks.res_block(var_x1, dims * 8)
+        var_x1 = self.blocks.res_block(var_x1, dims * 8)
+        if self.multiscale_count >= 3:
+            outputs.append(self.blocks.conv2d(var_x1, 3,
+                                              kernel_size=5,
+                                              padding="same",
+                                              activation="sigmoid",
+                                              name="face_out_32"))
+
+        var_x2 = self.blocks.upscale(var_x1, dims * 4, res_block_follows=True)
+        var_x2 = self.blocks.res_block(var_x2, dims * 4)
+        var_x2 = self.blocks.res_block(var_x2, dims * 4)
+        if self.multiscale_count >= 2:
+            outputs.append(self.blocks.conv2d(var_x2, 3,
+                                              kernel_size=5,
+                                              padding="same",
+                                              activation="sigmoid",
+                                              name="face_out_64"))
+
+        var_x3 = self.blocks.upscale(var_x2, dims * 2, res_block_follows=True)
+        var_x3 = self.blocks.res_block(var_x3, dims * 2)
+        var_x3 = self.blocks.res_block(var_x3, dims * 2)
+
+        outputs.append(self.blocks.conv2d(var_x3, 3,
+                                          kernel_size=5,
+                                          padding="same",
+                                          activation="sigmoid",
+                                          name="face_out_128"))
+
+        if self.use_mask:
+            var_y = input_
+            var_y = self.blocks.upscale(var_y, self.config["decoder_dims"] * 8)
+            var_y = self.blocks.upscale(var_y, self.config["decoder_dims"] * 4)
+            var_y = self.blocks.upscale(var_y, self.config["decoder_dims"] * 2)
+            var_y = self.blocks.conv2d(var_y, 1,
+                                       kernel_size=5,
+                                       padding="same",
+                                       activation="sigmoid",
+                                       name="mask_out")
+            outputs.append(var_y)
+        return KerasModel(input_, outputs=outputs)
diff --git a/plugins/train/model/dfaker_defaults.py b/plugins/train/model/dfl_sae_defaults.py
similarity index 51%
rename from plugins/train/model/dfaker_defaults.py
rename to plugins/train/model/dfl_sae_defaults.py
index 19285e6..3eacc79 100644
--- a/plugins/train/model/dfaker_defaults.py
+++ b/plugins/train/model/dfl_sae_defaults.py
@@ -1,16 +1,20 @@
 #!/usr/bin/env python3
 """
-    The default options for the faceswap Dfaker Model plugin.
+    The default options for the faceswap Dfl_H128 Model plugin.
+
     Defaults files should be named <plugin_name>_defaults.py
     Any items placed into this file will automatically get added to the relevant config .ini files
     within the faceswap/config folder.
+
     The following variables should be defined:
         _HELPTEXT: A string describing what this plugin does
         _DEFAULTS: A dictionary containing the options, defaults and meta information. The
                    dictionary should be defined as:
                        {<option_name>: {<metadata>}}
+
                    <option_name> should always be lower text.
                    <metadata> dictionary requirements are listed below.
+
     The following keys are expected for the _DEFAULTS <metadata> dict:
         datatype:  [required] A python type class. This limits the type of data that can be
                    provided in the .ini file and ensures that the value is returned in the
@@ -37,7 +41,70 @@
 """
 
 
-_HELPTEXT = "Dfaker Model (Adapted from https://github.com/dfaker/df)"
+_HELPTEXT = "DFL SAE Model (Adapted from https://github.com/iperov/DeepFaceLab)"
 
 
-_DEFAULTS = {}
+_DEFAULTS = {
+    "architecture": {
+        "default": "df",
+        "info": "Model architecture:"
+                "\n\t'df': Keeps the faces more natural."
+                "\n\t'liae': Can help fix overly different face shapes.",
+        "datatype": str,
+        "choices": ["df", "liae"],
+        "gui_radio": True,
+        "fixed": True,
+    },
+    "input_size": {
+        "default": 128,
+        "info": "Resolution (in pixels) of the input image to train on.\n"
+                "BE AWARE Larger resolution will dramatically increase VRAM requirements.\n"
+                "\nMust be divisible by 16.",
+        "datatype": int,
+        "rounding": 16,
+        "min_max": (64, 256),
+        "fixed": True,
+    },
+    "autoencoder_dims": {
+        "default": 0,
+        "info": "Face information is stored in AutoEncoder dimensions. If there are not enough "
+                "dimensions then certain facial features may not be recognized."
+                "\nHigher number of dimensions are better, but require more VRAM."
+                "\nSet to 0 to use the architecture defaults (256 for liae, 512 for df).",
+        "datatype": int,
+        "rounding": 32,
+        "min_max": (0, 1024),
+        "fixed": True,
+    },
+    "encoder_dims": {
+        "default": 42,
+        "info": "Encoder dimensions per channel. Higher number of encoder dimensions will help "
+                "the model to recognize more facial features, but will require more VRAM.",
+        "datatype": int,
+        "rounding": 1,
+        "min_max": (21, 85),
+        "fixed": True,
+    },
+    "decoder_dims": {
+        "default": 21,
+        "info": "Decoder dimensions per channel. Higher number of decoder dimensions will help "
+                "the model to improve details, but will require more VRAM.",
+        "datatype": int,
+        "rounding": 1,
+        "min_max": (10, 85),
+        "fixed": True,
+    },
+    "multiscale_decoder": {
+        "default": False,
+        "info": "Multiscale decoder can help to obtain better details.",
+        "datatype": bool,
+        "fixed": True,
+    },
+    "clipnorm": {
+        "default": True,
+        "info": "Controls gradient clipping of the optimizer. Can prevent model corruption at "
+                "the expense of VRAM.",
+        "datatype": bool,
+        "fixed": False,
+    },
+}
diff --git a/plugins/train/model/iae_defaults.py b/plugins/train/model/iae_defaults.py
deleted file mode 100644
index 5bb7d83..0000000
--- a/plugins/train/model/iae_defaults.py
+++ /dev/null
@@ -1,46 +0,0 @@
-#!/usr/bin/env python3
-"""
-    The default options for the faceswap Iae Model plugin.
-    Defaults files should be named <plugin_name>_defaults.py
-    Any items placed into this file will automatically get added to the relevant config .ini files
-    within the faceswap/config folder.
-    The following variables should be defined:
-        _HELPTEXT: A string describing what this plugin does
-        _DEFAULTS: A dictionary containing the options, defaults and meta information. The
-                   dictionary should be defined as:
-                       {<option_name>: {<metadata>}}
-                   <option_name> should always be lower text.
-                   <metadata> dictionary requirements are listed below.
-    The following keys are expected for the _DEFAULTS <metadata> dict:
-        datatype:  [required] A python type class. This limits the type of data that can be
-                   provided in the .ini file and ensures that the value is returned in the
-                   correct type to faceswap. Valid datatypes are: <class 'int'>, <class 'float'>,
-                   <class 'str'>, <class 'bool'>.
-        default:   [required] The default value for this option.
-        info:      [required] A string describing what this option does.
-        choices:   [optional] If this option's datatype is of <class 'str'> then valid
-                   selections can be defined here. This validates the option and also enables
-                   a combobox / radio option in the GUI.
-        gui_radio: [optional] If <choices> are defined, this indicates that the GUI should use
-                   radio buttons rather than a combobox to display this option.
-        min_max:   [partial] For <class 'int'> and <class 'float'> datatypes this is required
-                   otherwise it is ignored. Should be a tuple of min and max accepted values.
-                   This is used for controlling the GUI slider range. Values are not enforced.
-        rounding:  [partial] For <class 'int'> and <class 'float'> datatypes this is
-                   required otherwise it is ignored. Used for the GUI slider. For floats, this
-                   is the number of decimal places to display. For ints this is the step size.
-        fixed:     [optional] [train only]. Training configurations are fixed when the model is
-                   created, and then reloaded from the state file. Marking an item as fixed=False
-                   indicates that this value can be changed for existing models, and will override
-                   the value saved in the state file with the updated value in config. If not
-                   provided this will default to True.
-"""
-
-
-_HELPTEXT = (
-    "Intermediate Auto Encoder. Based on Original Model, uses intermediate layers to try to "
-    "better get details"
-)
-
-
-_DEFAULTS = {}
diff --git a/plugins/train/model/lightweight_defaults.py b/plugins/train/model/lightweight_defaults.py
deleted file mode 100644
index dadf270..0000000
--- a/plugins/train/model/lightweight_defaults.py
+++ /dev/null
@@ -1,47 +0,0 @@
-#!/usr/bin/env python3
-"""
-    The default options for the faceswap Lightweight Model plugin.
-    Defaults files should be named <plugin_name>_defaults.py
-    Any items placed into this file will automatically get added to the relevant config .ini files
-    within the faceswap/config folder.
-    The following variables should be defined:
-        _HELPTEXT: A string describing what this plugin does
-        _DEFAULTS: A dictionary containing the options, defaults and meta information. The
-                   dictionary should be defined as:
-                       {<option_name>: {<metadata>}}
-                   <option_name> should always be lower text.
-                   <metadata> dictionary requirements are listed below.
-    The following keys are expected for the _DEFAULTS <metadata> dict:
-        datatype:  [required] A python type class. This limits the type of data that can be
-                   provided in the .ini file and ensures that the value is returned in the
-                   correct type to faceswap. Valid datatypes are: <class 'int'>, <class 'float'>,
-                   <class 'str'>, <class 'bool'>.
-        default:   [required] The default value for this option.
-        info:      [required] A string describing what this option does.
-        choices:   [optional] If this option's datatype is of <class 'str'> then valid
-                   selections can be defined here. This validates the option and also enables
-                   a combobox / radio option in the GUI.
-        gui_radio: [optional] If <choices> are defined, this indicates that the GUI should use
-                   radio buttons rather than a combobox to display this option.
-        min_max:   [partial] For <class 'int'> and <class 'float'> datatypes this is required
-                   otherwise it is ignored. Should be a tuple of min and max accepted values.
-                   This is used for controlling the GUI slider range. Values are not enforced.
-        rounding:  [partial] For <class 'int'> and <class 'float'> datatypes this is
-                   required otherwise it is ignored. Used for the GUI slider. For floats, this
-                   is the number of decimal places to display. For ints this is the step size.
-        fixed:     [optional] [train only]. Training configurations are fixed when the model is
-                   created, and then reloaded from the state file. Marking an item as fixed=False
-                   indicates that this value can be changed for existing models, and will override
-                   the value saved in the state file with the updated value in config. If not
-                   provided this will default to True.
-"""
-
-
-_HELPTEXT = (
-    "A lightweight version of the Original Faceswap Model, designed to run on lower end GPUs "
-    "(~2GB).\nDon't expect great results, but it allows users with lower end cards to play with "
-    "the software.\n"
-)
-
-
-_DEFAULTS = {}
