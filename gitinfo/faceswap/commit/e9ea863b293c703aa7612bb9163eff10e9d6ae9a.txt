commit e9ea863b293c703aa7612bb9163eff10e9d6ae9a
Author: Lorjuo <julien.seitz@gmail.com>
Date:   Sun Jan 6 18:44:05 2019 +0100

    detection bugfixes: (#577)
    
    -scale in detector has been used as a member variable and shared between multiple threads. however scale heavily depends on the concrete image. if thread change occurs between calculation of scale, actual detection and postprocessing, then random behaviour and exceptions might happen. especially in the case of input images with varying sizes this might cause negative effects
    
    -wrong scale factor calculation:
    scale factor was calculated as: scale = target / source
    whereas target and source are variables for the total number of pixels in the image (= width * height)
    However, later on it was applied on the individual dimensions/components as width/height independantly:
    e.g.: dims = (int(width * scale), int(height * scale))
    or: int(face.left() / scale),
    
    therefore scaling factor often was too small and detection for very big input images was performed on very small intermediate images
    Therefore calculation has been changed to:
    scale = sqrt(target / source)

diff --git a/plugins/extract/align/fan.py b/plugins/extract/align/fan.py
index 5c54c1e..e46ca3e 100644
--- a/plugins/extract/align/fan.py
+++ b/plugins/extract/align/fan.py
@@ -60,10 +60,10 @@ class Align(Aligner):
                 break
             image = item["image"][:, :, ::-1].copy()
 
-            logger.trace("Algning faces")
+            logger.trace("Aligning faces")
             try:
                 item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
-                logger.trace("Algned faces: %s", item["landmarks"])
+                logger.trace("Aligned faces: %s", item["landmarks"])
             except ValueError as err:
                 logger.warning("Image '%s' could not be processed. This may be due to corrupted "
                                "data: %s", item["filename"], str(err))
diff --git a/plugins/extract/detect/_base.py b/plugins/extract/detect/_base.py
index efbf665..2b13aac 100644
--- a/plugins/extract/detect/_base.py
+++ b/plugins/extract/detect/_base.py
@@ -18,6 +18,7 @@ from io import StringIO
 
 import cv2
 import dlib
+from math import sqrt
 
 from lib.gpu_stats import GPUStats
 from lib.utils import rotate_landmarks
@@ -39,9 +40,6 @@ class Detector():
         # See lib.queue_manager.QueueManager for getting queues
         self.queues = {"in": None, "out": None}
 
-        # Scaling factor for image. Plugin dependent
-        self.scale = 1.0
-
         #  Path to model if required
         self.model_path = self.set_model_path()
 
@@ -125,8 +123,8 @@ class Detector():
     # <<< DETECTION IMAGE COMPILATION METHODS >>> #
     def compile_detection_image(self, image, is_square, scale_up):
         """ Compile the detection image """
-        self.set_scale(image, is_square=is_square, scale_up=scale_up)
-        return self.set_detect_image(image)
+        scale = self.set_scale(image, is_square=is_square, scale_up=scale_up)
+        return [self.set_detect_image(image, scale), scale]
 
     def set_scale(self, image, is_square=False, scale_up=False):
         """ Set the scale factor for incoming image """
@@ -144,23 +142,25 @@ class Detector():
             target = self.target
 
         if scale_up or target < source:
-            self.scale = target / source
+            scale = sqrt(target / source)
         else:
-            self.scale = 1.0
-        logger.trace("Detector scale: %s", self.scale)
+            scale = 1.0
+        logger.trace("Detector scale: %s", scale)
+        
+        return scale
 
-    def set_detect_image(self, input_image):
+    def set_detect_image(self, input_image, scale):
         """ Convert the image to RGB and scale """
         # pylint: disable=no-member
         image = input_image[:, :, ::-1].copy()
-        if self.scale == 1.0:
+        if scale == 1.0:
             return image
 
         height, width = image.shape[:2]
-        interpln = cv2.INTER_LINEAR if self.scale > 1.0 else cv2.INTER_AREA
-        dims = (int(width * self.scale), int(height * self.scale))
+        interpln = cv2.INTER_LINEAR if scale > 1.0 else cv2.INTER_AREA
+        dims = (int(width * scale), int(height * scale))
 
-        if self.scale < 1.0:
+        if scale < 1.0:
             logger.verbose("Resizing image from %sx%s to %s.",
                            width, height, "x".join(str(i) for i in dims))
 
diff --git a/plugins/extract/detect/dlib_cnn.py b/plugins/extract/detect/dlib_cnn.py
index 38ec22d..69bb5c3 100644
--- a/plugins/extract/detect/dlib_cnn.py
+++ b/plugins/extract/detect/dlib_cnn.py
@@ -72,12 +72,13 @@ class Detect(Detector):
             for item in batch:
                 filenames.append(item["filename"])
                 images.append(item["image"])
-            detect_images = self.compile_detection_images(images)
+            [detect_images, scales] = self.compile_detection_images(images)
             batch_detected = self.detect_batch(detect_images)
             processed = self.process_output(batch_detected,
                                             indexes=None,
                                             rotation_matrix=None,
-                                            output=None)
+                                            output=None,
+                                            scales=scales)
             if not all(faces for faces in processed) and self.rotation != [0]:
                 processed = self.process_rotations(detect_images, processed)
             for idx, faces in enumerate(processed):
@@ -100,11 +101,13 @@ class Detect(Detector):
         """ Compile the detection images into batches """
         logger.trace("Compiling Detection Images: %s", len(images))
         detect_images = list()
+        scales = list()
         for image in images:
-            self.set_scale(image, is_square=True, scale_up=True)
-            detect_images.append(self.set_detect_image(image))
+            scale = self.set_scale(image, is_square=True, scale_up=True)
+            detect_images.append(self.set_detect_image(image, scale))
+            scales.append(scale)
         logger.trace("Compiled Detection Images")
-        return detect_images
+        return [detect_images, scales]
 
     def detect_batch(self, detect_images, disable_message=False):
         """ Pass the batch through detector for consistently sized images
@@ -131,13 +134,14 @@ class Detect(Detector):
         return len(dims) == 1
 
     def process_output(self, batch_detected,
-                       indexes=None, rotation_matrix=None, output=None):
+                       indexes=None, rotation_matrix=None, output=None, scales=None):
         """ Process the output images """
         logger.trace("Processing Output: (batch_detected: %s, indexes: %s, rotation_matrix: %s, "
                      "output: %s", batch_detected, indexes, rotation_matrix, output)
         output = output if output else list()
         for idx, faces in enumerate(batch_detected):
             detected_faces = list()
+            scale = scales[idx]
 
             if isinstance(rotation_matrix, np.ndarray):
                 faces = [self.rotate_rect(face.rect, rotation_matrix)
@@ -146,10 +150,10 @@ class Detect(Detector):
             for face in faces:
                 face = self.convert_to_dlib_rectangle(face)
                 face = dlib.rectangle(  # pylint: disable=c-extension-no-member
-                    int(face.left() / self.scale),
-                    int(face.top() / self.scale),
-                    int(face.right() / self.scale),
-                    int(face.bottom() / self.scale))
+                    int(face.left() / scale),
+                    int(face.top() / scale),
+                    int(face.right() / scale),
+                    int(face.bottom() / scale))
                 detected_faces.append(face)
             if indexes:
                 target = indexes[idx]
diff --git a/plugins/extract/detect/dlib_hog.py b/plugins/extract/detect/dlib_hog.py
index cf07e9d..2f91d0d 100644
--- a/plugins/extract/detect/dlib_hog.py
+++ b/plugins/extract/detect/dlib_hog.py
@@ -37,7 +37,7 @@ class Detect(Detector):
             if item == "EOF":
                 break
             logger.trace("Detecting faces: %s", item["filename"])
-            detect_image = self.compile_detection_image(item["image"], True, True)
+            [detect_image, scale] = self.compile_detection_image(item["image"], True, True)
 
             for angle in self.rotation:
                 current_image, rotmat = self.rotate_image(detect_image, angle)
@@ -52,7 +52,7 @@ class Detect(Detector):
                 if faces:
                     break
 
-            detected_faces = self.process_output(faces, rotmat)
+            detected_faces = self.process_output(faces, rotmat, scale)
             item["detected_faces"] = detected_faces
             self.finalize(item)
 
@@ -61,7 +61,7 @@ class Detect(Detector):
             self.queues["out"].put("EOF")
         logger.debug("Detecting Faces Complete")
 
-    def process_output(self, faces, rotation_matrix):
+    def process_output(self, faces, rotation_matrix, scale):
         """ Compile found faces for output """
         logger.trace("Processing Output: (faces: %s, rotation_matrix: %s)",
                      faces, rotation_matrix)
@@ -69,8 +69,8 @@ class Detect(Detector):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
         detected = [dlib.rectangle(  # pylint: disable=c-extension-no-member
-            int(face.left() / self.scale), int(face.top() / self.scale),
-            int(face.right() / self.scale), int(face.bottom() / self.scale))
+            int(face.left() / scale), int(face.top() / scale),
+            int(face.right() / scale), int(face.bottom() / scale))
                     for face in faces]
         logger.trace("Processed Output: %s", detected)
         return detected
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index ae01135..bf28a64 100644
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -136,7 +136,7 @@ class Detect(Detector):
             if item == "EOF":
                 break
             logger.trace("Detecting faces: '%s'", item["filename"])
-            detect_image = self.compile_detection_image(item["image"], False, False)
+            [detect_image, scale] = self.compile_detection_image(item["image"], False, False)
 
             for angle in self.rotation:
                 current_image, rotmat = self.rotate_image(detect_image, angle)
@@ -146,13 +146,13 @@ class Detect(Detector):
                 if faces.any():
                     break
 
-            detected_faces = self.process_output(faces, points, rotmat)
+            detected_faces = self.process_output(faces, points, rotmat, scale)
             item["detected_faces"] = detected_faces
             self.finalize(item)
 
         logger.debug("Thread Completed Detect")
 
-    def process_output(self, faces, points, rotation_matrix):
+    def process_output(self, faces, points, rotation_matrix, scale):
         """ Compile found faces for output """
         logger.trace("Processing Output: (faces: %s, points: %s, rotation_matrix: %s)",
                      faces, points, rotation_matrix)
@@ -164,10 +164,10 @@ class Detect(Detector):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
         detected = [dlib.rectangle(  # pylint: disable=c-extension-no-member
-            int(face.left() / self.scale),
-            int(face.top() / self.scale),
-            int(face.right() / self.scale),
-            int(face.bottom() / self.scale))
+            int(face.left() / scale),
+            int(face.top() / scale),
+            int(face.right() / scale),
+            int(face.bottom() / scale))
                     for face in faces]
         logger.trace("Processed Output: %s", detected)
         return detected
