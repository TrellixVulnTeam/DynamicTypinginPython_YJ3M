commit 86947eca37350cad2708a3f1fa8eabe2d64c9ed1
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sat Mar 9 13:19:23 2019 +0000

    Allow s3fd to run at less than optimal vram availability

diff --git a/plugins/extract/detect/s3fd.py b/plugins/extract/detect/s3fd.py
index 154df4e..a525196 100644
--- a/plugins/extract/detect/s3fd.py
+++ b/plugins/extract/detect/s3fd.py
@@ -22,6 +22,7 @@ class Detect(Detector):
         self.name = "s3fd"
         self.target = (640, 640)  # Uses approx 4 GB of VRAM
         self.vram = 4096
+        self.min_vram = 1024  # Will run at this with warnings
         self.model = None
 
     def set_model_path(self):
@@ -43,6 +44,7 @@ class Detect(Detector):
                 tf_ratio = 1.0
             else:
                 tf_ratio = self.vram / vram_total
+
             logger.verbose("Reserving %s%% of total VRAM per s3fd thread",
                            round(tf_ratio * 100, 2))
 
@@ -57,8 +59,13 @@ class Detect(Detector):
                 alloc = vram_free
             logger.debug("Allocated for Tensorflow: %sMB", alloc)
 
-            self.batch_size = int(alloc / self.vram)
-
+            if self.min_vram < alloc < self.vram:
+                self.batch_size = 1
+                logger.warning("You are running s3fd with %sMB VRAM. The model is optimized for "
+                               "%sMB VRAM. Detection should still run but you may get "
+                               "warnings/errors", int(alloc), self.vram)
+            else:
+                self.batch_size = int(alloc / self.vram)
             if self.batch_size < 1:
                 raise ValueError("Insufficient VRAM available to continue "
                                  "({}MB)".format(int(alloc)))
