commit f68d444aa521db053375af1d4d5e80bab98bbf04
Author: Clorr <colin@clorr.fr>
Date:   Sun Dec 17 20:34:56 2017 +0100

    Adding an utility to process a regular image
    
    Processes a regular image and not only an input restricted to the face

diff --git a/convert_photo.py b/convert_photo.py
new file mode 100644
index 0000000..a95ed36
--- /dev/null
+++ b/convert_photo.py
@@ -0,0 +1,21 @@
+import cv2
+import numpy
+from pathlib import Path
+
+from utils import get_image_paths
+from faces_detect import crop_faces
+from faces_process import convert_one_image
+
+images_SRC = get_image_paths( "original" )
+
+output_dir = Path( 'modified' )
+output_dir.mkdir( parents=True, exist_ok=True )
+
+for fn in images_SRC:
+    image = cv2.imread(fn)
+    for ((x,w),(y,h),face) in crop_faces( image ):
+        new_face = convert_one_image( cv2.resize(face, (256,256)) )
+        image[slice(y,y+h),slice(x,x+w)] = cv2.resize(new_face, (w,h))
+    
+    output_file = output_dir / Path(fn).name
+    cv2.imwrite( str(output_file) , image )
diff --git a/extract.py b/extract.py
index 8cbf743..cc0f9df 100644
--- a/extract.py
+++ b/extract.py
@@ -3,27 +3,16 @@ import numpy
 from pathlib import Path
 
 from utils import get_image_paths
+from faces_detect import crop_faces
 
 images_SRC = get_image_paths( "src" )
 
-# Give right path to the xml file or put it directly in current folder
-face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
-
-def crop_faces( image ):
-    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
-
-    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
-    for (x,y,w,h) in faces:
-        crop_img = image[y: y + h, x: x + w]
-        final = cv2.resize(crop_img, (255,255))
-        yield final
-
 output_dir = Path( 'extract' )
-#output_dir.mkdir( parents=True, exist_ok=True )
+output_dir.mkdir( parents=True, exist_ok=True )
 
 for fn in images_SRC:
     image = cv2.imread(fn)
-#Add : cv.EqualizeHist(image, image) ?
-    for (idx, img) in enumerate(crop_faces( image )):
+    for (idx, (p1,p2,img)) in enumerate(crop_faces( image )):
+        final = cv2.resize(img, (256,256))
         output_file = output_dir / Path(fn).stem
-        cv2.imwrite( str(output_file) + str(idx) + Path(fn).suffix, img )
+        cv2.imwrite( str(output_file) + str(idx) + Path(fn).suffix, final )
diff --git a/faces_detect.py b/faces_detect.py
new file mode 100644
index 0000000..f66d43e
--- /dev/null
+++ b/faces_detect.py
@@ -0,0 +1,15 @@
+import cv2
+import numpy
+
+# Give right path to the xml file or put it directly in current folder
+face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
+
+def crop_faces( image ):
+#Add : cv.EqualizeHist(image, image) ?
+    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
+
+    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
+
+    for (x,y,w,h) in faces:
+        yield ((x,w), (y,h), image[y: y + h, x: x + w])
+
diff --git a/faces_process.py b/faces_process.py
new file mode 100644
index 0000000..59c02a0
--- /dev/null
+++ b/faces_process.py
@@ -0,0 +1,25 @@
+import cv2
+import numpy
+
+from model import autoencoder_A
+from model import autoencoder_B
+from model import encoder, decoder_A, decoder_B
+
+encoder  .load_weights( "models/encoder.h5"   )
+decoder_A.load_weights( "models/decoder_A.h5" )
+decoder_B.load_weights( "models/decoder_B.h5" )
+
+autoencoder = autoencoder_B
+
+def convert_one_image( image ):
+    assert image.shape == (256,256,3)
+    crop = slice(48,208)
+    face = image[crop,crop]
+    face = cv2.resize( face, (64,64) )
+    face = numpy.expand_dims( face, 0 )
+    new_face = autoencoder.predict( face / 255.0 )[0]
+    new_face = numpy.clip( new_face * 255, 0, 255 ).astype( image.dtype )
+    new_face = cv2.resize( new_face, (160,160) )
+    new_image = image.copy()
+    new_image[crop,crop] = new_face
+    return new_image
diff --git a/script.py b/script.py
index 6abd79e..3fb3310 100644
--- a/script.py
+++ b/script.py
@@ -4,35 +4,16 @@ from pathlib import Path
 
 from utils import get_image_paths
 
-from model import autoencoder_A
-from model import autoencoder_B
-from model import encoder, decoder_A, decoder_B
-
-encoder  .load_weights( "models/encoder.h5"   )
-decoder_A.load_weights( "models/decoder_A.h5" )
-decoder_B.load_weights( "models/decoder_B.h5" )
+from faces_process import convert_one_image
 
 images_A = get_image_paths( "data/trump" )
 images_B = get_image_paths( "data/cage" )
 
-def convert_one_image( autoencoder, image ):
-    assert image.shape == (256,256,3)
-    crop = slice(48,208)
-    face = image[crop,crop]
-    face = cv2.resize( face, (64,64) )
-    face = numpy.expand_dims( face, 0 )
-    new_face = autoencoder.predict( face / 255.0 )[0]
-    new_face = numpy.clip( new_face * 255, 0, 255 ).astype( image.dtype )
-    new_face = cv2.resize( new_face, (160,160) )
-    new_image = image.copy()
-    new_image[crop,crop] = new_face
-    return new_image
-
 output_dir = Path( 'output' )
 output_dir.mkdir( parents=True, exist_ok=True )
 
 for fn in images_A:
     image = cv2.imread(fn)
-    new_image = convert_one_image( autoencoder_B, image )
+    new_image = convert_one_image( image )
     output_file = output_dir / Path(fn).name
     cv2.imwrite( str(output_file), new_image )
\ No newline at end of file
