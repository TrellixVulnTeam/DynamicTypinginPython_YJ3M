commit 807f3db0654b5c33e0b73e6755a01f294ad0521a
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Feb 25 02:17:55 2019 +0000

    Fix typos

diff --git a/lib/model/nn_blocks.py b/lib/model/nn_blocks.py
index b97545d..9a64a34 100644
--- a/lib/model/nn_blocks.py
+++ b/lib/model/nn_blocks.py
@@ -25,7 +25,7 @@ logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 class NNBlocks():
     """ Blocks to use for creating models """
     def __init__(self, use_subpixel=False, use_icnr_init=False, use_reflect_padding=False):
-        logger.debug("Initializing %s: (use_subpixel: %s, use_icnr_init: %s, use_reflect_padding: %s",
+        logger.debug("Initializing %s: (use_subpixel: %s, use_icnr_init: %s, use_reflect_padding: %s)",
                      self.__class__.__name__, use_subpixel, use_icnr_init, use_reflect_padding)
         self.use_subpixel = use_subpixel
         self.use_icnr_init = use_icnr_init
@@ -42,7 +42,7 @@ class NNBlocks():
     def conv(self, inp, filters, kernel_size=5, strides=2, padding='same', use_instance_norm=False, res_block_follows=False, **kwargs):
         """ Convolution Layer"""
         logger.debug("inp: %s, filters: %s, kernel_size: %s, strides: %s, use_instance_norm: %s, "
-                     "kwargs: %s", inp, filters, kernel_size, strides, use_instance_norm, kwargs)
+                     "kwargs: %s)", inp, filters, kernel_size, strides, use_instance_norm, kwargs)
         kwargs = self.update_kwargs(kwargs)
         if self.use_reflect_padding:
             inp = ReflectionPadding2D(stride=strides, kernel_size=kernel_size)(inp)
@@ -60,7 +60,7 @@ class NNBlocks():
 
     def upscale(self, inp, filters, kernel_size=3, padding= 'same', use_instance_norm=False, res_block_follows=False, **kwargs):
         """ Upscale Layer """
-        logger.debug("inp: %s, filters: %s, kernel_size: %s, use_instance_norm: %s, kwargs: %s",
+        logger.debug("inp: %s, filters: %s, kernel_size: %s, use_instance_norm: %s, kwargs: %s)",
                      inp, filters, kernel_size, use_instance_norm, kwargs)
         kwargs = self.update_kwargs(kwargs)
         if self.use_reflect_padding:
@@ -85,7 +85,7 @@ class NNBlocks():
     # <<< DFaker Model Blocks >>> #
     def res_block(self, inp, filters, kernel_size=3, padding= 'same', **kwargs):
         """ Residual block """
-        logger.debug("inp: %s, filters: %s, kernel_size: %s, kwargs: %s",
+        logger.debug("inp: %s, filters: %s, kernel_size: %s, kwargs: %s)",
                      inp, filters, kernel_size, kwargs)
         kwargs = self.update_kwargs(kwargs)
         var_x = LeakyReLU(alpha=0.2)(inp)
@@ -112,7 +112,7 @@ class NNBlocks():
     # <<< Unbalanced Model Blocks >>> #
     def conv_sep(self, inp, filters, kernel_size=5, strides=2, **kwargs):
         """ Seperable Convolution Layer """
-        logger.debug("inp: %s, filters: %s, kernel_size: %s, strides: %s, kwargs: %s",
+        logger.debug("inp: %s, filters: %s, kernel_size: %s, strides: %s, kwargs: %s)",
                      inp, filters, kernel_size, strides, kwargs)
         kwargs = self.update_kwargs(kwargs)
         var_x = SeparableConv2D(filters,
diff --git a/plugins/train/model/iae.py b/plugins/train/model/iae.py
index 2ab622c..667cbe3 100644
--- a/plugins/train/model/iae.py
+++ b/plugins/train/model/iae.py
@@ -31,7 +31,7 @@ class Model(ModelBase):
         """ Initialize IAE model """
         logger.debug("Initializing model")
         inputs = [Input(shape=self.input_shape, name="face")]
-        if self.config.get("mask_type", "none") != "none":
+        if self.config.get("mask_type", None):
             mask_shape = (self.input_shape[:2] + (1, ))
             inputs.append(Input(shape=mask_shape, name="mask"))
 
@@ -52,7 +52,7 @@ class Model(ModelBase):
         input_ = Input(shape=self.input_shape)
         var_x = input_
         var_x = self.blocks.conv(var_x, 128)
-        var_x = self.blocks.conv(var_x, 266)
+        var_x = self.blocks.conv(var_x, 256)
         var_x = self.blocks.conv(var_x, 512)
         var_x = self.blocks.conv(var_x, 1024)
         var_x = Flatten()(var_x)
