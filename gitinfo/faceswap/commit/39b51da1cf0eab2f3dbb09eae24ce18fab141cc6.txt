commit 39b51da1cf0eab2f3dbb09eae24ce18fab141cc6
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Tue Aug 13 18:22:54 2019 +0100

    Clarification of helptext in cli.py

diff --git a/lib/cli.py b/lib/cli.py
index a7e4ad5..0dd256c 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -477,39 +477,44 @@ class ExtractConvertArgs(FaceSwapArgs):
                               "filetypes": "alignments",
                               "type": str,
                               "dest": "alignments_path",
-                              "help": "Optional path to an alignments file."})
-        argument_list.append({"opts": ("-l", "--ref_threshold"),
-                              "action": Slider,
-                              "min_max": (0.01, 0.99),
-                              "rounding": 2,
-                              "type": float,
-                              "dest": "ref_threshold",
-                              "default": 0.4,
-                              "help": "Threshold for positive face recognition. For use with "
-                                      "nfilter or filter. Lower values are stricter. NB: Using "
-                                      "face filter will significantly decrease extraction speed."})
+                              "help": "Optional path to an alignments file. Leave blank if the "
+                                      "alignments file is at the default location."})
         argument_list.append({"opts": ("-n", "--nfilter"),
                               "action": FilesFullPaths,
                               "filetypes": "image",
                               "dest": "nfilter",
                               "nargs": "+",
                               "default": None,
-                              "help": "Reference image for the persons you do not want to "
-                                      "process. Should be a front portrait with a single person "
-                                      "in the image. Multiple images can be added space "
-                                      "separated. NB: Using face filter will significantly "
-                                      "decrease extraction speed."})
+                              "help": "Optionally filter out people who you do not wish to "
+                                      "process by passing in an image of that person. Should be a "
+                                      "front portrait with a single person in the image. Multiple "
+                                      "images can be added space separated. NB: Using face filter "
+                                      "will significantly decrease extraction speed and its "
+                                      "accuracy cannot be guaranteed."})
         argument_list.append({"opts": ("-f", "--filter"),
                               "action": FilesFullPaths,
                               "filetypes": "image",
                               "dest": "filter",
                               "nargs": "+",
                               "default": None,
-                              "help": "Reference images for the person you want to process. "
-                                      "Should be a front portrait with a single person in the "
-                                      "image. Multiple images can be added space separated. NB: "
-                                      "Using face filter will significantly decrease extraction "
-                                      "speed."})
+                              "help": "Optionally select people you wish to process by passing in "
+                                      "an image of that person. Should be a front portrait with a "
+                                      "single person in the image. Multiple images can be added "
+                                      "space separated. NB: Using face filter will significantly "
+                                      "decrease extraction speed and its accuracy cannot be "
+                                      "guaranteed."})
+        argument_list.append({"opts": ("-l", "--ref_threshold"),
+                              "action": Slider,
+                              "min_max": (0.01, 0.99),
+                              "rounding": 2,
+                              "type": float,
+                              "dest": "ref_threshold",
+                              "default": 0.4,
+                              "help": "For use with the optional nfilter/filter files. Threshold "
+                                      "for positive face recognition. Lower values are stricter. "
+                                      "NB: Using face filter will significantly decrease "
+                                      "extraction speed and its accuracy cannot be "
+                                      "guaranteed."})
         return argument_list
 
 
@@ -528,16 +533,15 @@ class ExtractArgs(ExtractConvertArgs):
                               "dest": "serializer",
                               "default": "json",
                               "choices": ("json", "pickle", "yaml"),
-                              "help": "Serializer for alignments file. If "
-                                      "yaml is chosen and not available, then "
-                                      "json will be used as the default "
+                              "help": "Serializer for alignments file. If yaml is chosen and not "
+                                      "available, then json will be used as the default "
                                       "fallback."})
         argument_list.append({
             "opts": ("-D", "--detector"),
             "action": Radio,
             "type": str.lower,
             "choices":  PluginLoader.get_available_extractors("detect"),
-            "default": "mtcnn",
+            "default": "s3fd",
             "help": "R|Detector to use. NB: Unless stated, all aligners will run on CPU for AMD "
                     "GPUs. Some of these have configurable settings in "
                     "'/config/extract.ini' or 'Edit > Configure Extract Plugins':"
@@ -572,7 +576,8 @@ class ExtractArgs(ExtractConvertArgs):
                               "help": "R|Performing normalization can help the aligner better "
                                       "align faces with difficult lighting conditions at an "
                                       "extraction speed cost. Different methods will yield "
-                                      "different results on different sets."
+                                      "different results on different sets. NB: This does not "
+                                      "impact the output face, just the input to the aligner."
                                       "\nL|'none': Don't perform normalization on the face."
                                       "\nL|'clahe': Perform Contrast Limited Adaptive Histogram "
                                       "Equalization on the face."
@@ -582,13 +587,11 @@ class ExtractArgs(ExtractConvertArgs):
                               "type": str,
                               "dest": "rotate_images",
                               "default": None,
-                              "help": "If a face isn't found, rotate the "
-                                      "images to try to find a face. Can find "
-                                      "more faces at the cost of extraction "
-                                      "speed. Pass in a single number to use "
-                                      "increments of that size up to 360, or "
-                                      "pass in a list of numbers to enumerate "
-                                      "exactly what angles to check"})
+                              "help": "If a face isn't found, rotate the images to try to find a "
+                                      "face. Can find more faces at the cost of extraction speed. "
+                                      "Pass in a single number to use increments of that size up "
+                                      "to 360, or pass in a list of numbers to enumerate exactly "
+                                      "what angles to check"})
         argument_list.append({"opts": ("-bt", "--blur-threshold"),
                               "type": float,
                               "action": Slider,
@@ -644,29 +647,25 @@ class ExtractArgs(ExtractConvertArgs):
                               "action": "store_true",
                               "dest": "skip_existing",
                               "default": False,
-                              "help": "Skips frames that have already been "
-                                      "extracted and exist in the alignments "
-                                      "file"})
+                              "help": "Skips frames that have already been extracted and exist in "
+                                      "the alignments file"})
         argument_list.append({"opts": ("-sf", "--skip-existing-faces"),
                               "action": "store_true",
                               "dest": "skip_faces",
                               "default": False,
-                              "help": "Skip frames that already have "
-                                      "detected faces in the alignments "
-                                      "file"})
+                              "help": "Skip frames that already have detected faces in the "
+                                      "alignments file"})
         argument_list.append({"opts": ("-dl", "--debug-landmarks"),
                               "action": "store_true",
                               "dest": "debug_landmarks",
                               "default": False,
-                              "help": "Draw landmarks on the ouput faces for "
-                                      "debug"})
+                              "help": "Draw landmarks on the ouput faces for debugging purposes."})
         argument_list.append({"opts": ("-ae", "--align-eyes"),
                               "action": "store_true",
                               "dest": "align_eyes",
                               "default": False,
-                              "help": "Perform extra alignment to ensure "
-                                      "left/right eyes are  at the same "
-                                      "height"})
+                              "help": "Perform extra alignment to ensure left/right eyes are at "
+                                      "the same height"})
         argument_list.append({"opts": ("-si", "--save-interval"),
                               "dest": "save_interval",
                               "type": int,
@@ -675,10 +674,12 @@ class ExtractArgs(ExtractConvertArgs):
                               "rounding": 10,
                               "default": 0,
                               "help": "Automatically save the alignments file after a set amount "
-                                      "of frames. Will only save at the end of extracting by "
-                                      "default. WARNING: Don't interrupt the script when writing "
-                                      "the file because it might get corrupted. Set to 0 to turn "
-                                      "off"})
+                                      "of frames. By default the alignments file is only saved at "
+                                      "the end of the extraction process. NB: If extracting in 2 "
+                                      "passes then the alignments file will only start to be "
+                                      "saved out during the second pass. WARNING: Don't interrupt "
+                                      "the script when writing the file because it might get "
+                                      "corrupted. Set to 0 to turn off"})
         return argument_list
 
 
@@ -696,28 +697,8 @@ class ConvertArgs(ExtractConvertArgs):
                               "action": DirFullPaths,
                               "dest": "model_dir",
                               "required": True,
-                              "help": "Model directory. A directory containing the trained model "
-                                      "you wish to process."})
-        argument_list.append({"opts": ("-a", "--input-aligned-dir"),
-                              "action": DirFullPaths,
-                              "dest": "input_aligned_dir",
-                              "default": None,
-                              "help": "Input \"aligned directory\". A "
-                                      "directory that should contain the "
-                                      "aligned faces extracted from the input "
-                                      "files. If you delete faces from this "
-                                      "folder, they'll be skipped during "
-                                      "conversion. If no aligned dir is "
-                                      "specified, all faces will be "
-                                      "converted"})
-        argument_list.append({"opts": ("-ref", "--reference-video"),
-                              "action": FileFullPaths,
-                              "dest": "reference_video",
-                              "filetypes": "video",
-                              "type": str,
-                              "help": "Only required if converting from images to video. Provide "
-                                      "The original video that the source frames were extracted "
-                                      "from (for extracting the fps and audio)."})
+                              "help": "Model directory. The directory containing the trained "
+                                      "model you wish to use for conversion."})
         argument_list.append({
             "opts": ("-c", "--color-adjustment"),
             "action": Radio,
@@ -821,14 +802,35 @@ class ConvertArgs(ExtractConvertArgs):
                               "rounding": 1,
                               "default": 1,
                               "help": "Number of GPUs to use for conversion"})
+        argument_list.append({"opts": ("-a", "--input-aligned-dir"),
+                              "action": DirFullPaths,
+                              "dest": "input_aligned_dir",
+                              "default": None,
+                              "help": "If you have not cleansed your alignments file, then you "
+                                      "can filter out faces by defining a folder here that "
+                                      "contains the faces extracted from your input files/video. "
+                                      "If this folder is defined, then only faces that exist "
+                                      "within your alignments file and also exist within the "
+                                      "specified folder will be converted. Leaving this blank "
+                                      "will convert all faces that exist within the alignments "
+                                      "file."})
+        argument_list.append({"opts": ("-ref", "--reference-video"),
+                              "action": FileFullPaths,
+                              "dest": "reference_video",
+                              "filetypes": "video",
+                              "type": str,
+                              "help": "Only required if converting from images to video. Provide "
+                                      "The original video that the source frames were extracted "
+                                      "from (for extracting the fps and audio)."})
         argument_list.append({"opts": ("-fr", "--frame-ranges"),
                               "nargs": "+",
                               "type": str,
-                              "help": "frame ranges to apply transfer to e.g. For frames 10 to 50 "
-                                      "and 90 to 100 use --frame-ranges 10-50 90-100. Files "
-                                      "must have the frame-number as the last number in the name! "
-                                      "Frames falling outside of the selected range will be "
-                                      "discarded unless '-k' (--keep-unchanged) is selected."})
+                              "help": "Frame ranges to apply transfer to e.g. For frames 10 to 50 "
+                                      "and 90 to 100 use --frame-ranges 10-50 90-100. Frames "
+                                      "falling outside of the selected range will be discarded "
+                                      "unless '-k' (--keep-unchanged) is selected. NB: If you are "
+                                      "converting from images, then the filenames must end with "
+                                      "the frame-number!"})
         argument_list.append({"opts": ("-k", "--keep-unchanged"),
                               "action": "store_true",
                               "dest": "keep_unchanged",
@@ -839,8 +841,8 @@ class ConvertArgs(ExtractConvertArgs):
                               "action": "store_true",
                               "dest": "swap_model",
                               "default": False,
-                              "help": "Swap the model. Instead of A -> B, "
-                                      "swap B -> A"})
+                              "help": "Swap the model. Instead converting from of A -> B, "
+                                      "converts B -> A"})
         argument_list.append({"opts": ("-sp", "--singleprocess"),
                               "action": "store_true",
                               "default": False,
@@ -869,7 +871,8 @@ class TrainArgs(FaceSwapArgs):
                               "dest": "input_a",
                               "required": True,
                               "help": "Input directory. A directory containing training images "
-                                      "for face A."})
+                                      "for face A. This is the original face, i.e. the face that "
+                                      "you want to remove and replace with face B."})
         argument_list.append({"opts": ("-ala", "--alignments-A"),
                               "action": FileFullPaths,
                               "filetypes": 'alignments',
@@ -884,19 +887,19 @@ class TrainArgs(FaceSwapArgs):
                               "action": DirFullPaths,
                               "dest": "timelapse_input_a",
                               "default": None,
-                              "help": "For if you want a timelapse: "
-                                      "The input folder for the timelapse. "
-                                      "This folder should contain faces of A "
-                                      "which will be converted for the "
-                                      "timelapse. You must supply a "
-                                      "--timelapse-output and a "
-                                      "--timelapse-input-B parameter."})
+                              "help": "Optional for creating a timelapse. Timelapse will save an "
+                                      "image of your selected faces into the timelapse-output "
+                                      "folder at every save iteration. This should be the "
+                                      "input folder of 'A' faces that you would like to use for "
+                                      "creating the timelapse. You must also supply a "
+                                      "--timelapse-output and a --timelapse-input-B parameter."})
         argument_list.append({"opts": ("-B", "--input-B"),
                               "action": DirFullPaths,
                               "dest": "input_b",
                               "required": True,
                               "help": "Input directory. A directory containing training images "
-                                      "for face B."})
+                                      "for face B. This is the swap face, i.e. the face that "
+                                      "you want to place onto the head of person A."})
         argument_list.append({"opts": ("-alb", "--alignments-B"),
                               "action": FileFullPaths,
                               "filetypes": 'alignments',
@@ -911,13 +914,31 @@ class TrainArgs(FaceSwapArgs):
                               "action": DirFullPaths,
                               "dest": "timelapse_input_b",
                               "default": None,
-                              "help": "For if you want a timelapse: "
-                                      "The input folder for the timelapse. "
-                                      "This folder should contain faces of B "
-                                      "which will be converted for the "
-                                      "timelapse. You must supply a "
-                                      "--timelapse-output and a "
-                                      "--timelapse-input-A parameter."})
+                              "help": "Optional for creating a timelapse. Timelapse will save an "
+                                      "image of your selected faces into the timelapse-output "
+                                      "folder at every save iteration. This should be the "
+                                      "input folder of 'B' faces that you would like to use for "
+                                      "creating the timelapse. You must also supply a "
+                                      "--timelapse-output and a --timelapse-input-A parameter."})
+        argument_list.append({"opts": ("-to", "--timelapse-output"),
+                              "action": DirFullPaths,
+                              "dest": "timelapse_output",
+                              "default": None,
+                              "help": "Optional for creating a timelapse. Timelapse will save an "
+                                      "image of your selected faces into the timelapse-output "
+                                      "folder at every save iteration. If the input folders are "
+                                      "supplied but no output folder, it will default to your "
+                                      "model folder /timelapse/"})
+        argument_list.append({"opts": ("-m", "--model-dir"),
+                              "action": DirFullPaths,
+                              "dest": "model_dir",
+                              "required": True,
+                              "help": "Model directory. This is where the training data will be "
+                                      "stored. You should always specify a new folder for new "
+                                      "models. If starting a new model, select either an empty "
+                                      "folder, or a folder which does not exist (which will be "
+                                      "created). If continuing to train an existing model, "
+                                      "specify the location of the existing model."})
         argument_list.append({"opts": ("-t", "--trainer"),
                               "action": Radio,
                               "type": str.lower,
@@ -929,6 +950,7 @@ class TrainArgs(FaceSwapArgs):
                                       "\nL|dfaker: 64px in/128px out model from dfaker. "
                                       "Enable 'warp-to-landmarks' for full dfaker method."
                                       "\nL|dfl-h128. 128px in/out model from deepfacelab"
+                                      "\nL|dfl-sae. Adaptable model from deepfacelab"
                                       "\nL|iae: A model that uses intermediate layers to try to "
                                       "get better details"
                                       "\nL|lightweight: A lightweight model for low-end cards. "
@@ -944,20 +966,6 @@ class TrainArgs(FaceSwapArgs):
                                       "\nL|villain: 128px in/out model from villainguy. Very "
                                       "resource hungry (11GB for batchsize 16). Good for "
                                       "details, but more susceptible to color differences."})
-        argument_list.append({"opts": ("-to", "--timelapse-output"),
-                              "action": DirFullPaths,
-                              "dest": "timelapse_output",
-                              "default": None,
-                              "help": "The output folder for the timelapse. "
-                                      "If the input folders are supplied but "
-                                      "no output folder, it will default to "
-                                      "your model folder /timelapse/"})
-        argument_list.append({"opts": ("-m", "--model-dir"),
-                              "action": DirFullPaths,
-                              "dest": "model_dir",
-                              "required": True,
-                              "help": "Model directory. This is where the training data will be "
-                                      "stored."})
         argument_list.append({"opts": ("-s", "--save-interval"),
                               "type": int,
                               "action": Slider,
@@ -965,7 +973,7 @@ class TrainArgs(FaceSwapArgs):
                               "rounding": 10,
                               "dest": "save_interval",
                               "default": 100,
-                              "help": "Sets the number of iterations before saving the model"})
+                              "help": "Sets the number of iterations between each model save."})
         argument_list.append({"opts": ("-ss", "--snapshot-interval"),
                               "type": int,
                               "action": Slider,
@@ -983,14 +991,21 @@ class TrainArgs(FaceSwapArgs):
                               "rounding": 2,
                               "dest": "batch_size",
                               "default": 64,
-                              "help": "Batch size, as a power of 2 (64, 128, 256, etc)"})
+                              "help": "Batch size. This is the number of images processed through "
+                                      "the model for each iteration. Larger batches require more "
+                                      "GPU RAM."})
         argument_list.append({"opts": ("-it", "--iterations"),
                               "type": int,
                               "action": Slider,
                               "min_max": (0, 5000000),
                               "rounding": 20000,
                               "default": 1000000,
-                              "help": "Length of training in iterations."})
+                              "help": "Length of training in iterations. This is only really used "
+                                      "for automation. There is no 'correct' number of iterations "
+                                      "a model should be trained for. You should stop training "
+                                      "when you are happy with the previews. However, if you want "
+                                      "the model to stop automatically at a set number of "
+                                      "iterations, you can set that value here."})
         argument_list.append({"opts": ("-g", "--gpus"),
                               "type": int,
                               "action": Slider,
@@ -1021,8 +1036,8 @@ class TrainArgs(FaceSwapArgs):
                               "action": "store_true",
                               "dest": "allow_growth",
                               "default": False,
-                              "help": "Sets allow_growth option of Tensorflow "
-                                      "to spare memory on some configs"})
+                              "help": "Sets allow_growth option of Tensorflow to spare memory "
+                                      "on some configurations."})
         argument_list.append({"opts": ("-nl", "--no-logs"),
                               "action": "store_true",
                               "dest": "no_logs",
@@ -1047,7 +1062,7 @@ class TrainArgs(FaceSwapArgs):
                               "help": "[Nvidia only] To save VRAM some optimizer gradient "
                                       "calculations can be performed on the CPU rather than the "
                                       "GPU. This allows you to increase batchsize at a training "
-                                      "speed cost."})
+                                      "speed/system RAM cost."})
         argument_list.append({"opts": ("-pp", "--ping-pong"),
                               "action": "store_true",
                               "dest": "pingpong",
