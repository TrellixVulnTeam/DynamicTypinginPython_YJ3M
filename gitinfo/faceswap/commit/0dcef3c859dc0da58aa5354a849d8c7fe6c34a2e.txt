commit 0dcef3c859dc0da58aa5354a849d8c7fe6c34a2e
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Sun Nov 3 23:04:16 2019 +0000

    scripts.convert - add allow growth option

diff --git a/lib/cli.py b/lib/cli.py
index 94e71aa..a102044 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -963,6 +963,15 @@ class ConvertArgs(ExtractConvertArgs):
             "group": "settings",
             "help": "[LEGACY] This only needs to be selected if a legacy model is being loaded or "
                     "if there are multiple models in the model folder"})
+        argument_list.append({
+            "opts": ("-ag", "--allow-growth"),
+            "action": "store_true",
+            "dest": "allow_growth",
+            "group": "settings",
+            "default": False,
+            "backend": "nvidia",
+            "help": "Sets allow_growth option of Tensorflow to spare memory on some "
+                    "configurations."})
         argument_list.append({
             "opts": ("-k", "--keep-unchanged"),
             "action": "store_true",
diff --git a/scripts/convert.py b/scripts/convert.py
index 06be4f8..e05f974 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -10,6 +10,8 @@ from time import sleep
 
 from cv2 import imwrite  # pylint:disable=no-name-in-module
 import numpy as np
+import tensorflow as tf
+from keras.backend.tensorflow_backend import set_session
 from tqdm import tqdm
 
 from scripts.fsmedia import Alignments, Images, PostProcess, Utils
@@ -424,6 +426,10 @@ class Predict():
         self.serializer = get_serializer("json")
         self.faces_count = 0
         self.verify_output = False
+
+        if arguments.allow_growth:
+            self.set_tf_allow_growth()
+
         self.model = self.load_model()
         self.output_indices = {"face": self.model.largest_face_index,
                                "mask": self.model.largest_mask_index}
@@ -471,6 +477,18 @@ class Predict():
         logger.debug("Got batchsize: %s", batchsize)
         return batchsize
 
+    @staticmethod
+    def set_tf_allow_growth():
+        """ Allow TensorFlow to manage VRAM growth """
+        # pylint: disable=no-member
+        # TODO Move this temporary fix somewhere more appropriate
+        logger.debug("Setting Tensorflow 'allow_growth' option")
+        config = tf.ConfigProto()
+        config.gpu_options.allow_growth = True
+        config.gpu_options.visible_device_list = "0"
+        set_session(tf.Session(config=config))
+        logger.debug("Set Tensorflow 'allow_growth' option")
+
     def load_model(self):
         """ Load the model requested for conversion """
         logger.debug("Loading Model")
