commit 285fbf1fdb2d85cc20c5ca7c5076245caf6c0625
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Mar 4 10:34:00 2019 +0000

    linting, logging and fixups

diff --git a/lib/multithreading.py b/lib/multithreading.py
index 2f53963..264cb8b 100644
--- a/lib/multithreading.py
+++ b/lib/multithreading.py
@@ -4,63 +4,79 @@
 import logging
 import multiprocessing as mp
 from multiprocessing.sharedctypes import RawArray
+from ctypes import c_float
+
 import queue as Queue
 import sys
 import threading
 import numpy as np
-from ctypes import c_float
 from lib.logger import LOG_QUEUE, set_root_logger
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 _launched_processes = set()  # pylint: disable=invalid-name
 
 
-
 class ConsumerBuffer():
+    """ Memory buffer for consuming """
     def __init__(self, dispatcher, index, data):
+        logger.debug("Initializing %s: (dispatcher: '%s', index: %s, data: %s)",
+                     self.__class__.__name__, dispatcher, index, data)
         self._data = data
         self._id = index
         self._dispatcher = dispatcher
+        logger.debug("Initialized %s", self.__class__.__name__)
 
     def get(self):
+        """ Return Data """
         return self._data
 
     def free(self):
+        """ Return Free """
         self._dispatcher.free(self._id)
 
     def __enter__(self):
+        """ On Enter """
         return self.get()
 
     def __exit__(self, *args):
+        """ On Exit """
         self.free()
 
 
 class WorkerBuffer():
+    """ Memory buffer for working """
     def __init__(self, index, data, stop_event, queue):
+        logger.debug("Initializing %s: (index: '%s', data: %s, stop_event: %s, queue: %s)",
+                     self.__class__.__name__, index, data, stop_event, queue)
         self._id = index
         self._data = data
         self._stop_event = stop_event
         self._queue = queue
+        logger.debug("Initialized %s", self.__class__.__name__)
 
     def get(self):
+        """ Return Data """
         return self._data
 
     def ready(self):
+        """ Worker Ready """
         if self._stop_event.is_set():
             return
         self._queue.put(self._id)
 
     def __enter__(self):
+        """ On Enter """
         return self.get()
 
     def __exit__(self, *args):
+        """ On Exit """
         self.ready()
 
 
 class FixedProducerDispatcher():
     """
-    Runs the given target_function in N subprocesses
-    and provides fixed size shared memory to the target_function.
+    Runs the given method in N subprocesses
+    and provides fixed size shared memory to the method.
     This class is designed for endless running worker processes
     filling the provided memory with data,
     like preparing trainingsdata for neural network training.
@@ -89,15 +105,17 @@ class FixedProducerDispatcher():
     EVENT = mp.Event
     QUEUE = mp.Queue
 
-    def __init__(self, target_function, shapes, args=tuple(),
-                 kwargs={}, ctype=c_float, workers=1,
-                 buffers=None, log_queue=None, log_level=logging.DEBUG):
+    def __init__(self, method, shapes,
+                 args=tuple(), kwargs={}, ctype=c_float, workers=1, buffers=None):
+        logger.debug("Initializing %s: (method: '%s', shapes: %s, args: %s, kwargs: %s, "
+                     "ctype: %s, workers: %s, buffers: %s)", self.__class__.__name__, method,
+                     shapes, args, kwargs, ctype, workers, buffers)
         if buffers is None:
             buffers = workers * 2
         else:
             assert buffers >= 2 and buffers > workers
-        self.name = "%s_FixedProducerDispatcher" % str(target_function)
-        self._target_func = target_function
+        self.name = "%s_FixedProducerDispatcher" % str(method)
+        self._target_func = method
         self._shapes = shapes
         self._stop_event = self.EVENT()
         self._buffer_tokens = self.QUEUE()
@@ -106,23 +124,25 @@ class FixedProducerDispatcher():
         self._result_tokens = self.QUEUE()
         worker_data, self.data = self._create_data(shapes, ctype, buffers)
         proc_args = {
-            'data' : worker_data,
-            'stop_event' : self._stop_event,
-            'target' : self._target_func,
+            'data': worker_data,
+            'stop_event': self._stop_event,
+            'target': self._target_func,
             'buffer_tokens': self._buffer_tokens,
             'result_tokens': self._result_tokens,
             'dtype': np.dtype(ctype),
             'shapes': shapes,
-            'log_queue': log_queue,
-            'log_level': log_level,
+            'log_queue': LOG_QUEUE,
+            'log_level': logger.getEffectiveLevel(),
             'args': args,
             'kwargs': kwargs
         }
         self._worker = tuple(self._create_worker(proc_args) for _ in range(workers))
         self._open_worker = len(self._worker)
+        logger.debug("Initialized %s", self.__class__.__name__)
 
     @staticmethod
     def _np_from_shared(shared, shapes, dtype):
+        """ Numpy array from shared memory """
         arrs = []
         offset = 0
         np_data = np.frombuffer(shared, dtype=dtype)
@@ -133,6 +153,7 @@ class FixedProducerDispatcher():
         return arrs
 
     def _create_data(self, shapes, ctype, buffers):
+        """ Create data """
         buffer_size = int(sum(np.prod(x) for x in shapes))
         dtype = np.dtype(ctype)
         data = tuple(RawArray(ctype, buffer_size) for _ in range(buffers))
@@ -140,9 +161,11 @@ class FixedProducerDispatcher():
         return data, np_data
 
     def _create_worker(self, kwargs):
+        """ Create Worker """
         return mp.Process(target=self._runner, kwargs=kwargs)
 
     def free(self, index):
+        """ Free memory """
         if self._stop_event.is_set():
             return
         if isinstance(index, ConsumerBuffer):
@@ -150,9 +173,11 @@ class FixedProducerDispatcher():
         self._buffer_tokens.put(index)
 
     def __iter__(self):
+        """ Iterator """
         return self
 
     def __next__(self):
+        """ Next item """
         return self.next()
 
     def next(self, block=True, timeout=None):
@@ -161,8 +186,8 @@ class FixedProducerDispatcher():
         Will raise StopIteration if no more elements are available OR any worker is finished.
         Will raise queue.Empty when block is False and no element is available.
 
-        The returned data is safe until ConsumerBuffer.free() is called or the with context is left.
-        If you plan to hold on to it after that make a copy.
+        The returned data is safe until ConsumerBuffer.free() is called or the
+        with context is left. If you plan to hold on to it after that make a copy.
 
         This method is thread safe.
         """
@@ -177,17 +202,20 @@ class FixedProducerDispatcher():
         return ConsumerBuffer(self, i, self.data[i])
 
     def start(self):
+        """ Start Workers """
         for process in self._worker:
             process.start()
         _launched_processes.add(self)
 
     def is_alive(self):
+        """ Check workers are alive """
         for worker in self._worker:
             if worker.is_alive():
                 return True
         return False
 
     def join(self):
+        """ Join Workers """
         self.stop()
         while self._open_worker:
             if self._result_tokens.get() is None:
@@ -198,16 +226,18 @@ class FixedProducerDispatcher():
                 self._buffer_tokens.get(block=False, timeout=0.01)
             except Queue.Empty:
                 break
-        self._buffer_tokens.close()
+        self._result_tokens.close()
         for worker in self._worker:
             worker.join()
 
     def stop(self):
+        """ Stop Workers """
         self._stop_event.set()
         for _ in range(self._open_worker):
             self._buffer_tokens.put(None)
 
     def is_shutdown(self):
+        """ Check if stop event is set """
         return self._stop_event.is_set()
 
     @classmethod
@@ -215,17 +245,20 @@ class FixedProducerDispatcher():
                 buffer_tokens=None, result_tokens=None, dtype=None,
                 shapes=None, log_queue=None, log_level=None,
                 args=None, kwargs=None):
+        """ Shared Memory Object runner """
         # Fork inherits the queue handler, so skip registration with "fork"
         if log_queue and log_level is not None and mp.get_start_method() != "fork":
             set_root_logger(log_level, queue=log_queue)
         logger.debug("FixedProducerDispatcher worker for %s started", str(target))
         np_data = [cls._np_from_shared(d, shapes, dtype) for d in data]
+
         def get_free_slot():
             while not stop_event.is_set():
                 i = buffer_tokens.get()
                 if stop_event.is_set() or i is None:
                     break
                 yield WorkerBuffer(i, np_data[i], stop_event, result_tokens)
+
         args = tuple((get_free_slot(),)) + tuple(args)
         try:
             target(*args, **kwargs)
diff --git a/lib/training_data.py b/lib/training_data.py
index 014e745..df3de85 100644
--- a/lib/training_data.py
+++ b/lib/training_data.py
@@ -11,8 +11,7 @@ import numpy as np
 from scipy.interpolate import griddata
 
 from lib.model import masks
-from lib.multithreading import MultiThread, FixedProducerDispatcher
-from lib.queue_manager import queue_manager
+from lib.multithreading import FixedProducerDispatcher
 from lib.umeyama import umeyama
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
@@ -53,43 +52,42 @@ class TrainingDataGenerator():
         logger.debug("Queue batches: (image_count: %s, batchsize: %s, side: '%s', do_shuffle: %s, "
                      "is_timelapse: %s)", len(images), batchsize, side, do_shuffle, is_timelapse)
         self.batchsize = batchsize
+        training_size = self.training_opts.get("training_size", 256)
         batch_shape = list((
-            (batchsize,256,256,3), # sample images. We assume (256,256,3) for now
+            (batchsize, training_size, training_size, 3),  # sample images
             (batchsize, self.model_input_size, self.model_input_size, 3),
-            (batchsize, self.model_output_size, self.model_output_size, 3),
-        ))
+            (batchsize, self.model_output_size, self.model_output_size, 3)))
         if self.mask_function:
-            batch_shape.append((self.batchsize, self.model_output_size, self.model_output_size, 1))
+            batch_shape.append((self.batchsize, self.model_input_size, self.model_input_size, 1))
 
-        q_name = "timelapse_{}".format(side) if is_timelapse else "train_{}".format(side)
-        load_thread = FixedProducerDispatcher(
+        load_process = FixedProducerDispatcher(
             self.load_batches,
             batch_shape,
-            args=(images, q_name, side, is_timelapse, do_shuffle, batchsize),
-            log_queue=queue_manager._log_queue,
-            log_level=logger.getEffectiveLevel(),
-        )
-        load_thread.start()
-        logger.debug("Batching to queue: (side: '%s', queue: '%s')", side, q_name)
-        return self.minibatch(q_name, load_thread)
-
-    def load_batches(self, mem_gen, images, q_name, side, is_timelapse, do_shuffle=True, batchsize=0):
+            args=(images, side, is_timelapse, do_shuffle, batchsize))
+        load_process.start()
+        logger.debug("Batching to queue: (side: '%s', is_timelapse: %s)", side, is_timelapse)
+        return self.minibatch(side, is_timelapse, load_process)
+
+    def load_batches(self, mem_gen, images, side, is_timelapse,
+                     do_shuffle=True, batchsize=0):
         """ Load the warped images and target images to queue """
-        logger.debug("Loading batch: (image_count: %s, q_name: '%s', side: '%s', "
-                     "is_timelapse: %s, do_shuffle: %s)",
-                     len(images), q_name, side, is_timelapse, do_shuffle)
+        logger.debug("Loading batch: (image_count: %s, side: '%s', is_timelapse: %s, "
+                     "do_shuffle: %s)", len(images), side, is_timelapse, do_shuffle)
         self.validate_samples(images)
+
         def _img_iter(imgs):
             while True:
                 if do_shuffle:
                     shuffle(imgs)
                 for img in imgs:
                     yield img
+
         img_iter = _img_iter(images)
         epoch = 0
         for memory_wrapper in mem_gen:
             memory = memory_wrapper.get()
-            logger.debug("Putting to batch queue: (q_name: '%s', side: '%s')", q_name, side)
+            logger.debug("Putting to batch queue: (side: '%s', is_timelapse: %s)",
+                         side, is_timelapse)
             for i, img_path in enumerate(img_iter):
                 imgs = self.process_face(img_path, side, is_timelapse)
                 for j, img in enumerate(imgs):
@@ -98,8 +96,8 @@ class TrainingDataGenerator():
                 if i == batchsize - 1:
                     break
             memory_wrapper.ready()
-        logger.debug("Finished batching: (epoch: %s, q_name: '%s', side: '%s')",
-                     epoch, q_name, side)
+        logger.debug("Finished batching: (epoch: %s, side: '%s', is_timelapse: %s)",
+                     epoch, side, is_timelapse)
 
     def validate_samples(self, data):
         """ Check the total number of images against batchsize and return
@@ -110,18 +108,22 @@ class TrainingDataGenerator():
                "batch-size: {}".format(length, self.batchsize))
         assert length >= self.batchsize, msg
 
-    def minibatch(self, q_name, load_thread):
+    @staticmethod
+    def minibatch(side, is_timelapse, load_process):
         """ A generator function that yields epoch, batchsize of warped_img
             and batchsize of target_img from the load queue """
-        logger.debug("Launching minibatch generator for queue: '%s'", q_name)
-        for batch_wrapper in load_thread:
+        logger.debug("Launching minibatch generator for queue (side: '%s', is_timelapse: %s)",
+                     side, is_timelapse)
+        for batch_wrapper in load_process:
             with batch_wrapper as batch:
-                logger.trace("Yielding batch: (size: %s, item shapes: %s, queue:  '%s'",
-                             len(batch), [item.shape for item in batch], q_name)
+                logger.trace("Yielding batch: (size: %s, item shapes: %s, side:  '%s', "
+                             "is_timelapse: %s)",
+                             len(batch), [item.shape for item in batch], side, is_timelapse)
                 yield batch
-        load_thread.stop()
-        logger.debug("Finished minibatch generator for queue: '%s'", q_name)
-        load_thread.join()
+        load_process.stop()
+        logger.debug("Finished minibatch generator for queue: (side: '%s', is_timelapse: %s)",
+                     side, is_timelapse)
+        load_process.join()
 
     def process_face(self, filename, side, is_timelapse):
         """ Load an image and perform transformation and warping """
