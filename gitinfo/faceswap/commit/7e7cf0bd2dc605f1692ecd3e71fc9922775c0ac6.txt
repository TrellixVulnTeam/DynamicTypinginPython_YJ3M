commit 7e7cf0bd2dc605f1692ecd3e71fc9922775c0ac6
Author: Gareth Dunstone <gdunstone@users.noreply.github.com>
Date:   Thu Feb 1 23:19:03 2018 +1100

    extended arguments for convert.py (#89)
    
    * extended arguments for convert re https://github.com/deepfakes/faceswap/issues/85
    
    * helptext for extended arguments.
    
    * changed default mask type to facehullandrect

diff --git a/plugins/Convert_Adjust.py b/plugins/Convert_Adjust.py
index 42dd7e8..0760715 100644
--- a/plugins/Convert_Adjust.py
+++ b/plugins/Convert_Adjust.py
@@ -6,11 +6,11 @@ import numpy
 import os
 
 class Convert(object):
-    def __init__(self, encoder):
+    def __init__(self, encoder, smooth_mask=True, avg_color_adjust=True, **kwargs):
         self.encoder = encoder
-         
-        self.use_smooth_mask=True
-        self.use_avg_color_adjust=True
+        
+        self.use_smooth_mask = smooth_mask
+        self.use_avg_color_adjust = avg_color_adjust
 
     def patch_image( self, original, face_detected ):
         #assert image.shape == (256, 256, 3)
diff --git a/plugins/Convert_Masked.py b/plugins/Convert_Masked.py
index f575f17..8e0c1d9 100644
--- a/plugins/Convert_Masked.py
+++ b/plugins/Convert_Masked.py
@@ -6,18 +6,16 @@ import numpy
 from lib.aligner import get_align_mat
 
 class Convert():
-    def __init__(self, encoder):
+    def __init__(self, encoder, blur_size=2, seamless_clone=False, mask_type="facehullandrect", erosion_kernel_size=None, **kwargs):
         self.encoder = encoder
 
-        # if args.erosionKernelSize > 0:
-        #     self.erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(args.erosionKernelSize,args.erosionKernelSize))
-        # else:
-        #     self.erosion_kernel = None
-
         self.erosion_kernel = None
-        self.blurSize = 2
-        self.seamlessClone = False
-        self.maskType = 'Rect' # Choose in 'FaceHullAndRect','FaceHull','Rect'
+        if erosion_kernel_size is not None:
+            self.erosion_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(erosion_kernel_size,erosion_kernel_size))
+
+        self.blur_size = blur_size
+        self.seamless_clone = seamless_clone
+        self.mask_type = mask_type.lower() # Choose in 'FaceHullAndRect','FaceHull','Rect'
 
     def patch_image( self, image, face_detected ):
         size = 64
@@ -38,7 +36,7 @@ class Convert():
         cv2.warpAffine( new_face, mat, image_size, new_image, cv2.WARP_INVERSE_MAP, cv2.BORDER_TRANSPARENT )
 
         outImage = None
-        if self.seamlessClone:
+        if self.seamless_clone:
             masky,maskx = cv2.transform( numpy.array([ size/2,size/2 ]).reshape(1,1,2) ,cv2.invertAffineTransform(mat) ).reshape(2).astype(int)
             outimage = cv2.seamlessClone(new_image.astype(numpy.uint8),base_image.astype(numpy.uint8),(image_mask*255).astype(numpy.uint8),(masky,maskx) , cv2.NORMAL_CLONE )
         else:
@@ -58,18 +56,18 @@ class Convert():
     def get_image_mask(self, image, new_face, face_detected, mat, image_size):
 
         face_mask = numpy.zeros(image.shape,dtype=float)
-        if 'Rect' in self.maskType:
-            face_src = numpy.ones(new_face.shape,dtype=float) 
+        if 'rect' in self.mask_type:
+            face_src = numpy.ones(new_face.shape,dtype=float)
             cv2.warpAffine( face_src, mat, image_size, face_mask, cv2.WARP_INVERSE_MAP, cv2.BORDER_TRANSPARENT )
 
         hull_mask = numpy.zeros(image.shape,dtype=float)
-        if 'Hull' in self.maskType:
+        if 'hull' in self.mask_type:
             hull = cv2.convexHull( numpy.array( face_detected.landmarksAsXY() ).reshape((-1,2)).astype(int) ).flatten().reshape( (-1,2) )
             cv2.fillConvexPoly( hull_mask,hull,(1,1,1) )
 
-        if self.maskType == 'Rect':
+        if self.mask_type == 'rect':
             image_mask = face_mask
-        elif self.maskType == 'FaceHull':
+        elif self.mask_type == 'faceHull':
             image_mask = hull_mask
         else:
             image_mask = ((face_mask*hull_mask))
@@ -78,7 +76,7 @@ class Convert():
         if self.erosion_kernel is not None:
             image_mask = cv2.erode(image_mask,self.erosion_kernel,iterations = 1)
 
-        if self.blurSize!=0:
-            image_mask = cv2.blur(image_mask,(self.blurSize,self.blurSize))
+        if self.blur_size!=0:
+            image_mask = cv2.blur(image_mask,(self.blur_size,self.blur_size))
 
         return image_mask
diff --git a/scripts/convert.py b/scripts/convert.py
index 8276b9d..76b0fce 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -25,33 +25,83 @@ class ConvertImage(DirectoryProcessor):
                             default="models",
                             help="Model directory. A directory containing the trained model \
                     you wish to process. Defaults to 'models'")
+
         parser.add_argument('-s', '--swap-model',
                             action="store_true",
                             dest="swap_model",
                             default=False,
                             help="Swap the model. Instead of A -> B, swap B -> A.")
+
+        parser.add_argument('-c', '--converter',
+                            type=str,
+                            choices=("Masked", "Adjust"), # case sensitive because this is used to load a plugin.
+                            default="Masked",
+                            help="Converter to use.")
+
+        parser.add_argument('-b', '--blur-size',
+                            type=int,
+                            default=2,
+                            help="Blur size. (Masked converter only)")
+
+        parser.add_argument('-S', '--seamless',
+                            action="store_true",
+                            dest="seamless_clone",
+                            default=False,
+                            help="Seamless mode. (Masked converter only)")
+
+        parser.add_argument('-M', '--mask-type',
+                            type=str.lower, #lowercase this, because its just a string later on.
+                            dest="mask_type",
+                            choices=["rect", "facehull", "facehullandrect"],
+                            default="facehullandrect",
+                            help="Mask to use to replace faces. (Masked converter only)")
+
+        parser.add_argument('-e', '--erosion-kernel-size',
+                            dest="erosion_kernel_size",
+                            type=int,
+                            default=None,
+                            help="Erosion kernel size. (Masked converter only)")
+
+        parser.add_argument('-sm', '--smooth-mask',
+                            action="store_true",
+                            dest="smooth_mask",
+                            default=True,
+                            help="Smooth mask (Adjust converter only)")
+
+        parser.add_argument('-aca', '--avg-color-adjust',
+                            action="store_true",
+                            dest="avg_color_adjust",
+                            default=True,
+                            help="Average color adjust. (Adjust converter only)")
+
         return parser
 
     def process(self):
         # Original model goes with Adjust or Masked converter
+        # does the LowMem one work with only one?
         model_name = "Original" # TODO Pass as argument
-        conv_name = "Masked" # TODO Pass as argument
+        conv_name = self.arguments.converter
 
         model = PluginLoader.get_model(model_name)(self.arguments.model_dir)
         if not model.load(self.arguments.swap_model):
             print('Model Not Found! A valid model must be provided to continue!')
             exit(1)
-
-        converter = PluginLoader.get_converter(conv_name)(model.converter(False))
+        converter = PluginLoader.get_converter(conv_name)(model.converter(False),
+            blur_size=self.arguments.blur_size,
+            seamless_clone=self.arguments.seamless_clone,
+            mask_type=self.arguments.mask_type,
+            erosion_kernel_size=self.arguments.erosion_kernel_size,
+            smooth_mask=self.arguments.smooth_mask,
+            avg_color_adjust=self.arguments.avg_color_adjust
+        )
 
         batch = BackgroundGenerator(self.prepare_images(), 1)
         for item in batch.iterator():
             self.convert(converter, item)
-        
+
     def convert(self, converter, item):
         try:
             (filename, image, faces) = item
-            print('Processing %s' % (filename))
             for idx, face in faces:
                 image = converter.patch_image(image, face)
 
@@ -62,6 +112,5 @@ class ConvertImage(DirectoryProcessor):
 
     def prepare_images(self):
         for filename in self.read_directory():
-            print('Preparing %s' % (filename))
             image = cv2.imread(filename)
             yield filename, image, self.get_faces(image)
diff --git a/scripts/train.py b/scripts/train.py
index 0c7bc8c..113eca7 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -69,7 +69,8 @@ class TrainingProcessor(object):
                             default=False,
                             help="Writes the training result to a file even on preview mode.")
         parser.add_argument('-t', '--trainer',
-                            type=str, choices=("Original","LowMem"),
+                            type=str,
+                            choices=("Original", "LowMem"),
                             default="Original",
                             help="Select which trainer to use, LowMem for cards < 2gb.")
         parser.add_argument('-bs', '--batch-size',
@@ -115,12 +116,15 @@ class TrainingProcessor(object):
 
     def processThread(self):
         print('Loading data, this may take a while...')
-        model = PluginLoader.get_model(self.arguments.trainer)(self.arguments.model_dir)
+        # this is so that you can enter case insensitive values for trainer
+        trainer = self.arguments.trainer
+        trainer = trainer if trainer != "Lowmem" else "LowMem"
+        model = PluginLoader.get_model(trainer)(self.arguments.model_dir)
         model.load(swapped=False)
 
         images_A = get_image_paths(self.arguments.input_A)
         images_B = get_image_paths(self.arguments.input_B)
-        trainer = PluginLoader.get_trainer(self.arguments.trainer)(model,
+        trainer = PluginLoader.get_trainer(trainer)(model,
                                                                    images_A,
                                                                    images_B,
                                                                    batch_size=self.arguments.batch_size)
