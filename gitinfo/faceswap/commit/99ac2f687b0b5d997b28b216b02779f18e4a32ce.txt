commit 99ac2f687b0b5d997b28b216b02779f18e4a32ce
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Wed Apr 10 11:42:42 2019 +0100

    Allow 'unfixed' parameters for model config

diff --git a/lib/config.py b/lib/config.py
index fa4d9af..6a26a90 100644
--- a/lib/config.py
+++ b/lib/config.py
@@ -61,6 +61,20 @@ class FaceswapConfig():
                 conf[key] = self.get(sect, key)
         return conf
 
+    @property
+    def changeable_items(self):
+        """ Training only.
+            Return a dict of config items with their set values for items
+            that can be altered after the model has been created """
+        retval = dict()
+        for sect in ("global", self.section):
+            for key, val in self.defaults[sect].items():
+                if key == "helptext" or val["fixed"]:
+                    continue
+                retval[key] = self.get(sect, key)
+        logger.debug("Alterable for existing models: %s", retval)
+        return retval
+
     def get(self, section, option):
         """ Return a config item in it's correct format """
         logger.debug("Getting config item: (section: '%s', option: '%s')", section, option)
@@ -96,8 +110,8 @@ class FaceswapConfig():
         self.defaults[title] = OrderedDict()
         self.defaults[title]["helptext"] = info
 
-    def add_item(self, section=None, title=None, datatype=str,
-                 default=None, info=None, rounding=None, min_max=None, choices=None):
+    def add_item(self, section=None, title=None, datatype=str, default=None, info=None,
+                 rounding=None, min_max=None, choices=None, fixed=True):
         """ Add a default item to a config section
 
             For int or float values, rounding and min_max must be set
@@ -108,10 +122,16 @@ class FaceswapConfig():
             For str values choices can be set to validate input and create a combo box
             in the GUI
 
+            The 'fixed' parameter is only for training configs. Training configurations
+            are set when the model is created, and then reloaded from the state file.
+            Marking an item as fixed=False indicates that this value can be changed for
+            existing models, and will overide the value saved in the state file with the
+            updated value in config.
+
         """
         logger.debug("Add item: (section: '%s', title: '%s', datatype: '%s', default: '%s', "
-                     "info: '%s', rounding: '%s', min_max: %s, choices: %s)",
-                     section, title, datatype, default, info, rounding, min_max, choices)
+                     "info: '%s', rounding: '%s', min_max: %s, choices: %s, fixed: %s)",
+                     section, title, datatype, default, info, rounding, min_max, choices, fixed)
 
         choices = list() if not choices else choices
 
@@ -128,12 +148,33 @@ class FaceswapConfig():
             raise ValueError("'rounding' and 'min_max' must be set for numerical options")
         if not isinstance(choices, (list, tuple)):
             raise ValueError("'choices' must be a list or tuple")
+
+        info = self.expand_helptext(info, choices, default, datatype, min_max, fixed)
         self.defaults[section][title] = {"default": default,
                                          "helptext": info,
                                          "type": datatype,
                                          "rounding": rounding,
                                          "min_max": min_max,
-                                         "choices": choices}
+                                         "choices": choices,
+                                         "fixed": fixed}
+
+    @staticmethod
+    def expand_helptext(helptext, choices, default, datatype, min_max, fixed):
+        """ Add extra helptext info from parameters """
+        if not fixed:
+            helptext += "\nThis option can be updated for existing models."
+        if choices:
+            helptext += "\nChoose from: {}".format(choices)
+        elif datatype == bool:
+            helptext += "\nChoose from: True, False"
+        elif datatype == int:
+            cmin, cmax = min_max
+            helptext += "\nSelect an integer between {} and {}".format(cmin, cmax)
+        elif datatype == float:
+            cmin, cmax = min_max
+            helptext += "\nSelect a decimal number between {} and {}".format(cmin, cmax)
+        helptext += "\n[Default: {}]".format(default)
+        return helptext
 
     def check_exists(self):
         """ Check that a config file exists """
@@ -176,29 +217,11 @@ class FaceswapConfig():
                      "config: '%s')", section, item, default, option["helptext"], config)
         config = self.config if config is None else config
         helptext = option["helptext"]
-        helptext += self.set_helptext_choices(option)
-        helptext += "\n[Default: {}]".format(default)
         helptext = self.format_help(helptext, is_section=False)
         config.set(section, helptext)
         config.set(section, item, str(default))
         logger.debug("Inserted item: '%s'", item)
 
-    @staticmethod
-    def set_helptext_choices(option):
-        """ Set the helptext choices """
-        choices = ""
-        if option["choices"]:
-            choices = "\nChoose from: {}".format(option["choices"])
-        elif option["type"] == bool:
-            choices = "\nChoose from: True, False"
-        elif option["type"] == int:
-            cmin, cmax = option["min_max"]
-            choices = "\nSelect an integer between {} and {}".format(cmin, cmax)
-        elif option["type"] == float:
-            cmin, cmax = option["min_max"]
-            choices = "\nSelect a decimal number between {} and {}".format(cmin, cmax)
-        return choices
-
     @staticmethod
     def format_help(helptext, is_section=False):
         """ Format comments for default ini file """
diff --git a/plugins/train/_config.py b/plugins/train/_config.py
index 260cf05..965fa0e 100644
--- a/plugins/train/_config.py
+++ b/plugins/train/_config.py
@@ -19,7 +19,8 @@ COVERAGE_INFO = ("How much of the extracted image to train on. Generally the mod
                  "\n\t75.0%% spans from temple to temple."
                  "\n\t87.5%% spans from ear to ear."
                  "\n\t100.0%% is a mugshot.")
-ADDITIONAL_INFO = "\nNB: Values changed here will only take effect when creating a new model."
+ADDITIONAL_INFO = ("\nNB: Unless specifically stated, values changed here will only take effect "
+                   "when creating a new model.")
 
 
 class Config(FaceswapConfig):
@@ -46,7 +47,11 @@ class Config(FaceswapConfig):
                  "model you are training has a distinct line appearing around the edge of the "
                  "swap area.")
         self.add_item(
-            section=section, title="penalized_mask_loss", datatype=bool, default=True,
+            section=section, title="dssim_loss", datatype=bool, default=True, fixed=False,
+            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
+                 "May increase overall quality.")
+        self.add_item(
+            section=section, title="penalized_mask_loss", datatype=bool, default=True, fixed=False,
             info="If using a mask, This penalizes the loss for the masked area, to give higher "
                  "priority to the face area. \nShould increase overall quality and speed up "
                  "training. This should probably be left at True")
@@ -56,10 +61,6 @@ class Config(FaceswapConfig):
         self.add_section(title=section,
                          info="Dfaker Model (Adapted from https://github.com/dfaker/df)" +
                          ADDITIONAL_INFO)
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=True,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="dfaker",
             choices=MASK_TYPES, info=MASK_INFO)
@@ -88,10 +89,6 @@ class Config(FaceswapConfig):
         self.add_section(title=section,
                          info="Intermediate Auto Encoder. Based on Original Model, uses "
                               "intermediate layers to try to better get details" + ADDITIONAL_INFO)
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=False,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="none",
             choices=MASK_TYPES, info=MASK_INFO)
@@ -106,10 +103,6 @@ class Config(FaceswapConfig):
                               "run on lower end GPUs (~2GB).\nDon't expect great results, but it "
                               "allows users with lower end cards to play with the "
                               "software." + ADDITIONAL_INFO)
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=False,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="none",
             choices=MASK_TYPES, info=MASK_INFO)
@@ -125,10 +118,6 @@ class Config(FaceswapConfig):
             section=section, title="lowmem", datatype=bool, default=False,
             info="Lower memory mode. Set to 'True' if having issues with VRAM useage.\nNB: Models "
                  "with a changed lowmem mode are not compatible with each other.")
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=False,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="none",
             choices=MASK_TYPES, info=MASK_INFO)
@@ -147,10 +136,6 @@ class Config(FaceswapConfig):
             info="Lower memory mode. Set to 'True' if having issues with VRAM useage.\nNB: Models "
                  "with a changed lowmem mode are not compatible with each other. NB: lowmem will "
                  "override cutom nodes and complexity settings.")
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=False,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="clipnorm", datatype=bool, default=True,
             info="Controls gradient clipping of the optimizer. Can prevent model corruption at "
@@ -199,10 +184,6 @@ class Config(FaceswapConfig):
             section=section, title="lowmem", datatype=bool, default=False,
             info="Lower memory mode. Set to 'True' if having issues with VRAM useage.\nNB: Models "
                  "with a changed lowmem mode are not compatible with each other.")
-        self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=False,
-            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
-                 "May increase overall quality.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="none",
             choices=["none", "dfaker", "dfl_full"],
diff --git a/plugins/train/model/_base.py b/plugins/train/model/_base.py
index a3dae69..a392679 100644
--- a/plugins/train/model/_base.py
+++ b/plugins/train/model/_base.py
@@ -64,7 +64,12 @@ class ModelBase():
         self.encoder_dim = encoder_dim
         self.trainer = trainer
 
-        self.state = State(self.model_dir, self.name, no_logs, pingpong, training_image_size)
+        self.state = State(self.model_dir,
+                           self.name,
+                           self.config_changeable_items,
+                           no_logs,
+                           pingpong,
+                           training_image_size)
         self.is_legacy = False
         self.rename_legacy()
         self.load_state_info()
@@ -86,16 +91,29 @@ class ModelBase():
         self.set_training_data()
         logger.debug("Initialized ModelBase (%s)", self.__class__.__name__)
 
+    @property
+    def config_section(self):
+        """ The section name for loading config """
+        retval = ".".join(self.__module__.split(".")[-2:])
+        logger.debug(retval)
+        return retval
+
     @property
     def config(self):
         """ Return config dict for current plugin """
         global _CONFIG  # pylint: disable=global-statement
         if not _CONFIG:
-            model_name = ".".join(self.__module__.split(".")[-2:])
+            model_name = self.config_section
             logger.debug("Loading config for: %s", model_name)
             _CONFIG = Config(model_name).config_dict
         return _CONFIG
 
+    @property
+    def config_changeable_items(self):
+        """ Return the dict of config items that can be updated after the model
+            has been created """
+        return Config(self.config_section).changeable_items
+
     @property
     def name(self):
         """ Set the model name based on the subclass """
@@ -489,7 +507,7 @@ class ModelBase():
             self.encoder_dim = 512
             self.state.config["lowmem"] = True
 
-        self.state.replace_config()
+        self.state.replace_config(self.config_changeable_items)
         self.state.save()
 
 
@@ -578,10 +596,12 @@ class NNMeta():
 
 class State():
     """ Class to hold the model's current state and autoencoder structure """
-    def __init__(self, model_dir, model_name, no_logs, pingpong, training_image_size):
-        logger.debug("Initializing %s: (model_dir: '%s', model_name: '%s', no_logs: %s, "
-                     "pingpong: %s, training_image_size: '%s'", self.__class__.__name__, model_dir,
-                     model_name, no_logs, pingpong, training_image_size)
+    def __init__(self, model_dir, model_name, config_changeable_items,
+                 no_logs, pingpong, training_image_size):
+        logger.debug("Initializing %s: (model_dir: '%s', model_name: '%s', "
+                     "config_changeable_items: '%s', no_logs: %s, pingpong: %s, "
+                     "training_image_size: '%s'", self.__class__.__name__, model_dir, model_name,
+                     config_changeable_items, no_logs, pingpong, training_image_size)
         self.serializer = Serializer.get_serializer("json")
         filename = "{}_state.{}".format(model_name, self.serializer.ext)
         self.filename = str(model_dir / filename)
@@ -593,7 +613,7 @@ class State():
         self.lowest_avg_loss = dict()
         self.inputs = dict()
         self.config = dict()
-        self.load()
+        self.load(config_changeable_items)
         self.session_id = self.new_session_id()
         self.create_new_session(no_logs, pingpong)
         logger.debug("Initialized %s:", self.__class__.__name__)
@@ -652,7 +672,7 @@ class State():
         self.iterations += 1
         self.sessions[self.session_id]["iterations"] += 1
 
-    def load(self):
+    def load(self, config_changeable_items):
         """ Load state file """
         logger.debug("Loading State")
         try:
@@ -666,7 +686,7 @@ class State():
                 self.inputs = state.get("inputs", dict())
                 self.config = state.get("config", dict())
                 logger.debug("Loaded state: %s", state)
-                self.replace_config()
+                self.replace_config(config_changeable_items)
         except IOError as err:
             logger.warning("No existing state file found. Generating.")
             logger.debug("IOError: %s", str(err))
@@ -703,15 +723,30 @@ class State():
         if os.path.exists(origfile):
             os.rename(origfile, backupfile)
 
-    def replace_config(self):
-        """ Replace the loaded config with the one contained within the state file """
+    def replace_config(self, config_changeable_items):
+        """ Replace the loaded config with the one contained within the state file
+            Check for any fixed=False parameters changes and log info changes
+        """
         global _CONFIG  # pylint: disable=global-statement
         # Add any new items to state config for legacy purposes
         for key, val in _CONFIG.items():
             if key not in self.config.keys():
                 logger.info("Adding new config item to state file: '%s': '%s'", key, val)
                 self.config[key] = val
+        self.update_changed_config_items(config_changeable_items)
         logger.debug("Replacing config. Old config: %s", _CONFIG)
         _CONFIG = self.config
         logger.debug("Replaced config. New config: %s", _CONFIG)
         logger.info("Using configuration saved in state file")
+
+    def update_changed_config_items(self, config_changeable_items):
+        """ Update any parameters which are not fixed and have been changed """
+        if not config_changeable_items:
+            logger.debug("No changeable parameters have been updated")
+            return
+        for key, val in config_changeable_items.items():
+            old_val = self.config[key]
+            if old_val == val:
+                continue
+            self.config[key] = val
+            logger.info("Config item: '%s' has been updated from '%s' to '%s'", key, old_val, val)
