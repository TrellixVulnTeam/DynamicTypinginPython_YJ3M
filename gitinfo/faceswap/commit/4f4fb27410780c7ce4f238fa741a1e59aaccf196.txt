commit 4f4fb27410780c7ce4f238fa741a1e59aaccf196
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Wed Nov 21 17:58:41 2018 +0000

    extractor fixes

diff --git a/.gitignore b/.gitignore
index 987de29..9f1a273 100644
--- a/.gitignore
+++ b/.gitignore
@@ -25,4 +25,5 @@
 !tools
 !tools/lib*
 
+*.pyc
 __pycache__/
diff --git a/lib/multithreading.py b/lib/multithreading.py
index be4331f..e32b23c 100644
--- a/lib/multithreading.py
+++ b/lib/multithreading.py
@@ -12,6 +12,7 @@ class PoolProcess():
         self.verbose = verbose
         self.method = method
         self.procs = self.set_procs(processes)
+        self.pool = None
 
     def set_procs(self, processes):
         """ Set the number of processes to use """
@@ -24,9 +25,14 @@ class PoolProcess():
 
     def in_process(self, *args, **kwargs):
         """ Run the processing pool """
-        pool = mp.Pool(processes=self.procs)
+        self.pool = mp.Pool(processes=self.procs)
         for _ in range(self.procs):
-            pool.apply_async(self.method, args=args, kwds=kwargs)
+            self.pool.apply_async(self.method, args=args, kwds=kwargs)
+
+    def join(self):
+        """ Join the process """
+        self.pool.close()
+        self.pool.join()
 
 
 class SpawnProcess():
diff --git a/plugins/extract/align/_base.py b/plugins/extract/align/_base.py
index 6ef18a0..22bd400 100644
--- a/plugins/extract/align/_base.py
+++ b/plugins/extract/align/_base.py
@@ -13,7 +13,8 @@
     For each source item, the plugin must pass a dict to finalize containing:
     {"filename": <filename of source frame>,
      "image": <source image>,
-     "detected_faces": <list of tuples containing (dlibRectangle, Landmarks)>}
+     "detected_faces": <list of dlibRectangles>,
+     "landmarks": <list of landmarks>}
     """
 
 import os
diff --git a/plugins/extract/align/dlib.py b/plugins/extract/align/dlib.py
index 0ba2538..af5a460 100644
--- a/plugins/extract/align/dlib.py
+++ b/plugins/extract/align/dlib.py
@@ -37,7 +37,7 @@ class Align(Aligner):
                 self.queues["out"].put(item)
                 break
             image = item["image"][:, :, ::-1].copy()
-            item["detected_faces"] = self.process_landmarks(image, item["detected_faces"])
+            item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
             self.finalize(item)
         self.finalize("EOF")
 
@@ -47,5 +47,5 @@ class Align(Aligner):
         for detected_face in detected_faces:
             pts = self.model(image, detected_face).parts()
             landmarks = [(point.x, point.y) for point in pts]
-            retval.append((detected_face, landmarks))
+            retval.append(landmarks)
         return retval
diff --git a/plugins/extract/align/fan.py b/plugins/extract/align/fan.py
index e63c2cb..afdd0d4 100644
--- a/plugins/extract/align/fan.py
+++ b/plugins/extract/align/fan.py
@@ -59,6 +59,10 @@ class Align(Aligner):
         super().align(*args, **kwargs)
         try:
             while True:
+                # NB: There appears to be a bug somewhere that re-inserts the first item (after
+                # detecting landmarks) back into the in queue. This happens consistently when -mp
+                # is not set, only appears to happen for the first item and always places it in
+                # the same place. It doesn't effect output, but should be squashed.
                 item = self.queues["in"].get()
                 if item == "EOF":
                     break
@@ -66,7 +70,7 @@ class Align(Aligner):
                     self.queues["out"].put(item)
                     break
                 image = item["image"][:, :, ::-1].copy()
-                item["detected_faces"] = self.process_landmarks(image, item["detected_faces"])
+                item["landmarks"] = self.process_landmarks(image, item["detected_faces"])
                 self.finalize(item)
             self.finalize("EOF")
         except:
@@ -81,7 +85,7 @@ class Align(Aligner):
             center, scale = self.get_center_scale(detected_face)
             aligned_image = self.align_image(image, center, scale)
             landmarks = self.predict_landmarks(aligned_image, center, scale)
-            retval.append((detected_face, landmarks))
+            retval.append(landmarks)
         return retval
 
     def get_center_scale(self, detected_face):
diff --git a/plugins/extract/detect/dlib_cnn.py b/plugins/extract/detect/dlib_cnn.py
index 39451e0..7b98422 100644
--- a/plugins/extract/detect/dlib_cnn.py
+++ b/plugins/extract/detect/dlib_cnn.py
@@ -12,7 +12,7 @@ class Detect(Detector):
     """ Dlib detector for face recognition """
     def __init__(self, **kwargs):
         super().__init__(**kwargs)
-        self.target = (1920, 1920)  # Uses approx 1805MB of VRAM
+        self.target = (1792, 1792)  # Uses approx 1805MB of VRAM
         self.vram = 1600  # Lower as batch size of 2 gives wiggle room
         self.detector = None
 
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index 6e720e1..3d7d6c8 100644
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -62,9 +62,9 @@ class Detect(Detector):
         self.kwargs = kwargs["mtcnn_kwargs"]
 
         mtcnn_graph = tf.Graph()
-        with mtcnn_graph.as_default():
+        with mtcnn_graph.as_default():  # pylint: disable=not-context-manager
             sess = tf.Session()
-            with sess.as_default():
+            with sess.as_default():  # pylint: disable=not-context-manager
                 pnet, rnet, onet = create_mtcnn(sess, self.model_path)
 
             if any("gpu" in str(device).lower()
@@ -101,7 +101,8 @@ class Detect(Detector):
         workers = MultiThread(thread_count=self.batch_size)
         workers.in_thread(target=self.detect_thread)
         workers.join_threads()
-        self.queues["out"].put("EOF")
+        sentinel = self.queues["in"].get()
+        self.queues["out"].put(sentinel)
 
     def detect_thread(self):
         """ Detect faces in rgb image """
@@ -138,16 +139,17 @@ class Detect(Detector):
     def process_output(self, faces, points, rotation_matrix):
         """ Compile found faces for output """
         faces = self.recalculate_bounding_box(faces, points)
-        faces = [dlib.rectangle(int(face[0]), int(face[1]),
-                                int(face[2]), int(face[3]))
+        faces = [dlib.rectangle(  # pylint: disable=c-extension-no-member
+            int(face[0]), int(face[1]), int(face[2]), int(face[3]))
                  for face in faces]
         if isinstance(rotation_matrix, np.ndarray):
             faces = [self.rotate_rect(face, rotation_matrix)
                      for face in faces]
-        detected = [dlib.rectangle(int(face.left() / self.scale),
-                                   int(face.top() / self.scale),
-                                   int(face.right() / self.scale),
-                                   int(face.bottom() / self.scale))
+        detected = [dlib.rectangle(  # pylint: disable=c-extension-no-member
+            int(face.left() / self.scale),
+            int(face.top() / self.scale),
+            int(face.right() / self.scale),
+            int(face.bottom() / self.scale))
                     for face in faces]
         return detected
 
@@ -217,21 +219,21 @@ class Detect(Detector):
 # SOFTWARE.
 
 
-def layer(op):
+def layer(operator):
     """Decorator for composable network layers."""
 
     def layer_decorated(self, *args, **kwargs):
         # Automatically set a name if not provided.
-        name = kwargs.setdefault('name', self.get_unique_name(op.__name__))
+        name = kwargs.setdefault('name', self.get_unique_name(operator.__name__))
         # Figure out the layer inputs.
-        if len(self.terminals) == 0:
+        if len(self.terminals) == 0:  # pylint: disable=len-as-condition
             raise RuntimeError('No input variables found for layer %s.' % name)
         elif len(self.terminals) == 1:
             layer_input = self.terminals[0]
         else:
             layer_input = list(self.terminals)
         # Perform the operation and get the output.
-        layer_output = op(self, layer_input, *args, **kwargs)
+        layer_output = operator(self, layer_input, *args, **kwargs)
         # Add to layer LUT.
         self.layers[name] = layer_output
         # This output is now the input for the next layer.
@@ -242,7 +244,8 @@ def layer(op):
     return layer_decorated
 
 
-class Network(object):
+class Network():
+    """ Tensorflow Network """
     def __init__(self, inputs, trainable=True):
         # The input nodes for this network
         self.inputs = inputs
@@ -259,7 +262,8 @@ class Network(object):
         """Construct the network. """
         raise NotImplementedError('Must be implemented by the subclass.')
 
-    def load(self, model_path, session, ignore_missing=False):
+    @staticmethod
+    def load(model_path, session, ignore_missing=False):
         """Load network weights.
         model_path: The path to the numpy-serialized network weights
         session: The current TensorFlow session
@@ -283,7 +287,7 @@ class Network(object):
         """Set the input(s) for the next operation by replacing the terminal nodes.
         The arguments can be either layer names or the actual layers.
         """
-        assert len(args) != 0
+        assert len(args) != 0  # pylint: disable=len-as-condition
         self.terminals = []
         for fed_layer in args:
             if isinstance(fed_layer, string_types):
@@ -309,12 +313,13 @@ class Network(object):
         """Creates a new TensorFlow variable."""
         return tf.get_variable(name, shape, trainable=self.trainable)
 
-    def validate_padding(self, padding):
+    @staticmethod
+    def validate_padding(padding):
         """Verifies that the padding is one of the supported ones."""
         assert padding in ('SAME', 'VALID')
 
     @layer
-    def conv(self,
+    def conv(self,  # pylint: disable=too-many-arguments
              inp,
              k_h,
              k_w,
@@ -326,6 +331,9 @@ class Network(object):
              padding='SAME',
              group=1,
              biased=True):
+        """ Conv Layer """
+        # pylint: disable=too-many-locals
+
         # Verify that the padding is acceptable
         self.validate_padding(padding)
         # Get the number of channels in the input
@@ -334,8 +342,7 @@ class Network(object):
         assert c_i % group == 0
         assert c_o % group == 0
         # Convolution for a given input and kernel
-        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1],
-                                             padding=padding)
+        convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding) # noqa
         with tf.variable_scope(name) as scope:
             kernel = self.make_var('weights',
                                    shape=[k_h, k_w, c_i // group, c_o])
@@ -353,6 +360,7 @@ class Network(object):
 
     @layer
     def prelu(self, inp, name):
+        """ Prelu Layer """
         with tf.variable_scope(name):
             i = int(inp.get_shape()[-1])
             alpha = self.make_var('alpha', shape=(i,))
@@ -360,7 +368,9 @@ class Network(object):
         return output
 
     @layer
-    def max_pool(self, inp, k_h, k_w, s_h, s_w, name, padding='SAME'):
+    def max_pool(self, inp, k_h, k_w,  # pylint: disable=too-many-arguments
+                 s_h, s_w, name, padding='SAME'):
+        """ Max Pool Layer """
         self.validate_padding(padding)
         return tf.nn.max_pool(inp,
                               ksize=[1, k_h, k_w, 1],
@@ -369,29 +379,31 @@ class Network(object):
                               name=name)
 
     @layer
-    def fc(self, inp, num_out, name, relu=True):
+    def fc(self, inp, num_out, name, relu=True):  # pylint: disable=invalid-name
+        """ FC Layer """
         with tf.variable_scope(name):
             input_shape = inp.get_shape()
             if input_shape.ndims == 4:
                 # The input is spatial. Vectorize it first.
                 dim = 1
-                for d in input_shape[1:].as_list():
-                    dim *= int(d)
+                for this_dim in input_shape[1:].as_list():
+                    dim *= int(this_dim)
                 feed_in = tf.reshape(inp, [-1, dim])
             else:
                 feed_in, dim = (inp, input_shape[-1].value)
             weights = self.make_var('weights', shape=[dim, num_out])
             biases = self.make_var('biases', [num_out])
-            op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b
-            fc = op(feed_in, weights, biases, name=name)
+            operator = tf.nn.relu_layer if relu else tf.nn.xw_plus_b
+            fc = operator(feed_in, weights, biases, name=name)  # pylint: disable=invalid-name
             return fc
 
-    # Multi dimensional softmax,
-    # refer to https://github.com/tensorflow/tensorflow/issues/210
-    # compute softmax along the dimension of target
-    # the native softmax only supports batch_size x dimension
     @layer
-    def softmax(self, target, axis, name=None):
+    def softmax(self, target, axis, name=None):  # pylint: disable=no-self-use
+        """ Multi dimensional softmax,
+            refer to https://github.com/tensorflow/tensorflow/issues/210
+            compute softmax along the dimension of target
+            the native softmax only supports batch_size x dimension """
+
         max_axis = tf.reduce_max(target, axis, keepdims=True)
         target_exp = tf.exp(target-max_axis)
         normalize = tf.reduce_sum(target_exp, axis, keepdims=True)
@@ -400,6 +412,7 @@ class Network(object):
 
 
 class PNet(Network):
+    """ Tensorflow PNet """
     def setup(self):
         (self.feed('data')  # pylint: disable=no-value-for-parameter, no-member
          .conv(3, 3, 10, 1, 1, padding='VALID', relu=False, name='conv1')
@@ -417,6 +430,7 @@ class PNet(Network):
 
 
 class RNet(Network):
+    """ Tensorflow RNet """
     def setup(self):
         (self.feed('data')  # pylint: disable=no-value-for-parameter, no-member
          .conv(3, 3, 28, 1, 1, padding='VALID', relu=False, name='conv1')
@@ -437,6 +451,7 @@ class RNet(Network):
 
 
 class ONet(Network):
+    """ Tensorflow ONet """
     def setup(self):
         (self.feed('data')  # pylint: disable=no-value-for-parameter, no-member
          .conv(3, 3, 32, 1, 1, padding='VALID', relu=False, name='conv1')
@@ -480,20 +495,21 @@ def create_mtcnn(sess, model_path):
         onet = ONet({'data': data})
         onet.load(os.path.join(model_path, 'det3.npy'), sess)
 
-    pnet_fun = lambda img: sess.run(('pnet/conv4-2/BiasAdd:0',
+    pnet_fun = lambda img: sess.run(('pnet/conv4-2/BiasAdd:0', # noqa
                                      'pnet/prob1:0'),
                                     feed_dict={'pnet/input:0': img})
-    rnet_fun = lambda img: sess.run(('rnet/conv5-2/conv5-2:0',
+    rnet_fun = lambda img: sess.run(('rnet/conv5-2/conv5-2:0', # noqa
                                      'rnet/prob1:0'),
                                     feed_dict={'rnet/input:0': img})
-    onet_fun = lambda img: sess.run(('onet/conv6-2/conv6-2:0',
+    onet_fun = lambda img: sess.run(('onet/conv6-2/conv6-2:0', # noqa
                                      'onet/conv6-3/conv6-3:0',
                                      'onet/prob1:0'),
                                     feed_dict={'onet/input:0': img})
     return pnet_fun, rnet_fun, onet_fun
 
 
-def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
+def detect_face(img, minsize, pnet, rnet,  # pylint: disable=too-many-arguments
+                onet, threshold, factor):
     """Detects faces in an image, and returns bounding boxes and points for them.
     img: input image
     minsize: minimum faces' size
@@ -502,19 +518,20 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
     factor: the factor used to create a scaling pyramid of face sizes to
             detect in the image.
     """
+    # pylint: disable=too-many-locals,too-many-statements,too-many-branches
     factor_count = 0
     total_boxes = np.empty((0, 9))
     points = np.empty(0)
-    h = img.shape[0]
-    w = img.shape[1]
-    minl = np.amin([h, w])
-    m = 12.0/minsize
-    minl = minl*m
+    height = img.shape[0]
+    width = img.shape[1]
+    minl = np.amin([height, width])
+    var_m = 12.0 / minsize
+    minl = minl * var_m
     # create scale pyramid
     scales = []
     while minl >= 12:
-        scales += [m*np.power(factor, factor_count)]
-        minl = minl*factor
+        scales += [var_m * np.power(factor, factor_count)]
+        minl = minl * factor
         factor_count += 1
 
     # # # # # # # # # # # # #
@@ -522,19 +539,19 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
     # # # # # # # # # # # # #
 
     for scale in scales:
-        hs = int(np.ceil(h*scale))
-        ws = int(np.ceil(w*scale))
-        im_data = imresample(img, (hs, ws))
-        im_data = (im_data-127.5)*0.0078125
+        height_scale = int(np.ceil(height * scale))
+        width_scale = int(np.ceil(width * scale))
+        im_data = imresample(img, (height_scale, width_scale))
+        im_data = (im_data - 127.5) * 0.0078125
         img_x = np.expand_dims(im_data, 0)
         img_y = np.transpose(img_x, (0, 2, 1, 3))
         out = pnet(img_y)
         out0 = np.transpose(out[0], (0, 2, 1, 3))
         out1 = np.transpose(out[1], (0, 2, 1, 3))
 
-        boxes, _ = generateBoundingBox(out1[0, :, :, 1].copy(),
-                                       out0[0, :, :, :].copy(),
-                                       scale, threshold[0])
+        boxes, _ = generate_bounding_box(out1[0, :, :, 1].copy(),
+                                         out0[0, :, :, :].copy(),
+                                         scale, threshold[0])
 
         # inter-scale nms
         pick = nms(boxes.copy(), 0.5, 'Union')
@@ -548,16 +565,15 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
         total_boxes = total_boxes[pick, :]
         regw = total_boxes[:, 2]-total_boxes[:, 0]
         regh = total_boxes[:, 3]-total_boxes[:, 1]
-        qq1 = total_boxes[:, 0]+total_boxes[:, 5]*regw
-        qq2 = total_boxes[:, 1]+total_boxes[:, 6]*regh
-        qq3 = total_boxes[:, 2]+total_boxes[:, 7]*regw
-        qq4 = total_boxes[:, 3]+total_boxes[:, 8]*regh
-        total_boxes = np.transpose(np.vstack([qq1, qq2, qq3, qq4,
-                                              total_boxes[:, 4]]))
+        qq_1 = total_boxes[:, 0]+total_boxes[:, 5] * regw
+        qq_2 = total_boxes[:, 1]+total_boxes[:, 6] * regh
+        qq_3 = total_boxes[:, 2]+total_boxes[:, 7] * regw
+        qq_4 = total_boxes[:, 3]+total_boxes[:, 8] * regh
+        total_boxes = np.transpose(np.vstack([qq_1, qq_2, qq_3, qq_4, total_boxes[:, 4]]))
         total_boxes = rerec(total_boxes.copy())
         total_boxes[:, 0:4] = np.fix(total_boxes[:, 0:4]).astype(np.int32)
-        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(),
-                                                         w, h)
+        d_y, ed_y, d_x, ed_x, var_y, e_y, var_x, e_x, tmpw, tmph = pad(total_boxes.copy(),
+                                                                       width, height)
 
     numbox = total_boxes.shape[0]
 
@@ -569,10 +585,9 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
         tempimg = np.zeros((24, 24, 3, numbox))
         for k in range(0, numbox):
             tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))
-            tmp[dy[k]-1:edy[k], dx[k]-1:edx[k], :] = img[y[k]-1:ey[k],
-                                                         x[k]-1:ex[k], :]
-            if (tmp.shape[0] > 0 and tmp.shape[1] > 0 or
-                    tmp.shape[0] == 0 and tmp.shape[1] == 0):
+            tmp[d_y[k] - 1:ed_y[k], d_x[k] - 1:ed_x[k], :] = img[var_y[k] - 1:e_y[k],
+                                                                 var_x[k]-1:e_x[k], :]
+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:
                 tempimg[:, :, :, k] = imresample(tmp, (24, 24))
             else:
                 return np.empty()
@@ -585,11 +600,11 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
         ipass = np.where(score > threshold[1])
         total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(),
                                  np.expand_dims(score[ipass].copy(), 1)])
-        mv = out0[:, ipass[0]]
+        m_v = out0[:, ipass[0]]
         if total_boxes.shape[0] > 0:
             pick = nms(total_boxes, 0.7, 'Union')
             total_boxes = total_boxes[pick, :]
-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv[:, pick]))
+            total_boxes = bbreg(total_boxes.copy(), np.transpose(m_v[:, pick]))
             total_boxes = rerec(total_boxes.copy())
 
     numbox = total_boxes.shape[0]
@@ -602,15 +617,14 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
     if numbox > 0:
         # third stage
         total_boxes = np.fix(total_boxes).astype(np.int32)
-        dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph = pad(total_boxes.copy(),
-                                                         w, h)
+        d_y, ed_y, d_x, ed_x, var_y, e_y, var_x, e_x, tmpw, tmph = pad(total_boxes.copy(),
+                                                                       width, height)
         tempimg = np.zeros((48, 48, 3, numbox))
         for k in range(0, numbox):
             tmp = np.zeros((int(tmph[k]), int(tmpw[k]), 3))
-            tmp[dy[k]-1:edy[k], dx[k]-1:edx[k], :] = img[y[k]-1:ey[k],
-                                                         x[k]-1:ex[k], :]
-            if (tmp.shape[0] > 0 and tmp.shape[1] > 0 or
-                    tmp.shape[0] == 0 and tmp.shape[1] == 0):
+            tmp[d_y[k] - 1:ed_y[k], d_x[k] - 1:ed_x[k], :] = img[var_y[k] - 1:e_y[k],
+                                                                 var_x[k] - 1:e_x[k], :]
+            if tmp.shape[0] > 0 and tmp.shape[1] > 0 or tmp.shape[0] == 0 and tmp.shape[1] == 0:
                 tempimg[:, :, :, k] = imresample(tmp, (48, 48))
             else:
                 return np.empty()
@@ -626,16 +640,16 @@ def detect_face(img, minsize, pnet, rnet, onet, threshold, factor):
         points = points[:, ipass[0]]
         total_boxes = np.hstack([total_boxes[ipass[0], 0:4].copy(),
                                  np.expand_dims(score[ipass].copy(), 1)])
-        mv = out0[:, ipass[0]]
-
-        w = total_boxes[:, 2]-total_boxes[:, 0]+1
-        h = total_boxes[:, 3]-total_boxes[:, 1]+1
-        points[0:5, :] = (np.tile(w, (5, 1))*points[0:5, :] +
-                          np.tile(total_boxes[:, 0], (5, 1))-1)
-        points[5:10, :] = (np.tile(h, (5, 1))*points[5:10, :] +
-                           np.tile(total_boxes[:, 1], (5, 1))-1)
+        m_v = out0[:, ipass[0]]
+
+        width = total_boxes[:, 2] - total_boxes[:, 0] + 1
+        height = total_boxes[:, 3] - total_boxes[:, 1] + 1
+        points[0:5, :] = (np.tile(width, (5, 1)) * points[0:5, :] +
+                          np.tile(total_boxes[:, 0], (5, 1)) - 1)
+        points[5:10, :] = (np.tile(height, (5, 1)) * points[5:10, :] +
+                           np.tile(total_boxes[:, 1], (5, 1)) - 1)
         if total_boxes.shape[0] > 0:
-            total_boxes = bbreg(total_boxes.copy(), np.transpose(mv))
+            total_boxes = bbreg(total_boxes.copy(), np.transpose(m_v))
             pick = nms(total_boxes.copy(), 0.7, 'Min')
             total_boxes = total_boxes[pick, :]
             points = points[:, pick]
@@ -649,128 +663,132 @@ def bbreg(boundingbox, reg):
     if reg.shape[1] == 1:
         reg = np.reshape(reg, (reg.shape[2], reg.shape[3]))
 
-    w = boundingbox[:, 2]-boundingbox[:, 0]+1
-    h = boundingbox[:, 3]-boundingbox[:, 1]+1
-    b1 = boundingbox[:, 0]+reg[:, 0]*w
-    b2 = boundingbox[:, 1]+reg[:, 1]*h
-    b3 = boundingbox[:, 2]+reg[:, 2]*w
-    b4 = boundingbox[:, 3]+reg[:, 3]*h
-    boundingbox[:, 0:4] = np.transpose(np.vstack([b1, b2, b3, b4]))
+    width = boundingbox[:, 2] - boundingbox[:, 0] + 1
+    height = boundingbox[:, 3] - boundingbox[:, 1] + 1
+    b_1 = boundingbox[:, 0] + reg[:, 0] * width
+    b_2 = boundingbox[:, 1] + reg[:, 1] * height
+    b_3 = boundingbox[:, 2] + reg[:, 2] * width
+    b_4 = boundingbox[:, 3] + reg[:, 3] * height
+    boundingbox[:, 0:4] = np.transpose(np.vstack([b_1, b_2, b_3, b_4]))
     return boundingbox
 
 
-def generateBoundingBox(imap, reg, scale, t):
+def generate_bounding_box(imap, reg, scale, threshold):
     """Use heatmap to generate bounding boxes"""
+    # pylint: disable=too-many-locals
     stride = 2
     cellsize = 12
 
     imap = np.transpose(imap)
-    dx1 = np.transpose(reg[:, :, 0])
-    dy1 = np.transpose(reg[:, :, 1])
-    dx2 = np.transpose(reg[:, :, 2])
-    dy2 = np.transpose(reg[:, :, 3])
-    y, x = np.where(imap >= t)
-    if y.shape[0] == 1:
-        dx1 = np.flipud(dx1)
-        dy1 = np.flipud(dy1)
-        dx2 = np.flipud(dx2)
-        dy2 = np.flipud(dy2)
-    score = imap[(y, x)]
-    reg = np.transpose(np.vstack([dx1[(y, x)], dy1[(y, x)],
-                                  dx2[(y, x)], dy2[(y, x)]]))
+    d_x1 = np.transpose(reg[:, :, 0])
+    d_y1 = np.transpose(reg[:, :, 1])
+    d_x2 = np.transpose(reg[:, :, 2])
+    d_y2 = np.transpose(reg[:, :, 3])
+    dim_y, dim_x = np.where(imap >= threshold)
+    if dim_y.shape[0] == 1:
+        d_x1 = np.flipud(d_x1)
+        d_y1 = np.flipud(d_y1)
+        d_x2 = np.flipud(d_x2)
+        d_y2 = np.flipud(d_y2)
+    score = imap[(dim_y, dim_x)]
+    reg = np.transpose(np.vstack([d_x1[(dim_y, dim_x)], d_y1[(dim_y, dim_x)],
+                                  d_x2[(dim_y, dim_x)], d_y2[(dim_y, dim_x)]]))
     if reg.size == 0:
         reg = np.empty((0, 3))
-    bb = np.transpose(np.vstack([y, x]))
-    q1 = np.fix((stride*bb+1)/scale)
-    q2 = np.fix((stride*bb+cellsize-1+1)/scale)
-    boundingbox = np.hstack([q1, q2, np.expand_dims(score, 1), reg])
+    bbox = np.transpose(np.vstack([dim_y, dim_x]))
+    q_1 = np.fix((stride * bbox + 1) / scale)
+    q_2 = np.fix((stride * bbox + cellsize - 1 + 1) / scale)
+    boundingbox = np.hstack([q_1, q_2, np.expand_dims(score, 1), reg])
     return boundingbox, reg
 
 
 # function pick = nms(boxes,threshold,type)
 def nms(boxes, threshold, method):
+    """ Non_Max Suppression """
+    # pylint: disable=too-many-locals
     if boxes.size == 0:
         return np.empty((0, 3))
-    x1 = boxes[:, 0]
-    y1 = boxes[:, 1]
-    x2 = boxes[:, 2]
-    y2 = boxes[:, 3]
-    s = boxes[:, 4]
-    area = (x2-x1+1) * (y2-y1+1)
-    I = np.argsort(s)
-    pick = np.zeros_like(s, dtype=np.int16)
+    x_1 = boxes[:, 0]
+    y_1 = boxes[:, 1]
+    x_2 = boxes[:, 2]
+    y_2 = boxes[:, 3]
+    var_s = boxes[:, 4]
+    area = (x_2 - x_1 + 1) * (y_2 - y_1 + 1)
+    s_sort = np.argsort(var_s)
+    pick = np.zeros_like(var_s, dtype=np.int16)
     counter = 0
-    while I.size > 0:
-        i = I[-1]
+    while s_sort.size > 0:
+        i = s_sort[-1]
         pick[counter] = i
         counter += 1
-        idx = I[0:-1]
-        xx1 = np.maximum(x1[i], x1[idx])
-        yy1 = np.maximum(y1[i], y1[idx])
-        xx2 = np.minimum(x2[i], x2[idx])
-        yy2 = np.minimum(y2[i], y2[idx])
-        w = np.maximum(0.0, xx2-xx1+1)
-        h = np.maximum(0.0, yy2-yy1+1)
-        inter = w * h
+        idx = s_sort[0:-1]
+        xx_1 = np.maximum(x_1[i], x_1[idx])
+        yy_1 = np.maximum(y_1[i], y_1[idx])
+        xx_2 = np.minimum(x_2[i], x_2[idx])
+        yy_2 = np.minimum(y_2[i], y_2[idx])
+        width = np.maximum(0.0, xx_2-xx_1+1)
+        height = np.maximum(0.0, yy_2-yy_1+1)
+        inter = width * height
         if method == 'Min':
-            o = inter / np.minimum(area[i], area[idx])
+            var_o = inter / np.minimum(area[i], area[idx])
         else:
-            o = inter / (area[i] + area[idx] - inter)
-        I = I[np.where(o <= threshold)]
+            var_o = inter / (area[i] + area[idx] - inter)
+        s_sort = s_sort[np.where(var_o <= threshold)]
     pick = pick[0:counter]
     return pick
 
 
-# function [dy edy dx edx y ey x ex tmpw tmph] = pad(total_boxes,w,h)
-def pad(total_boxes, w, h):
+# function [d_y ed_y d_x ed_x y e_y x e_x tmp_width tmp_height] = pad(total_boxes,width,height)
+def pad(total_boxes, width, height):
     """Compute the padding coordinates (pad the bounding boxes to square)"""
-    tmpw = (total_boxes[:, 2]-total_boxes[:, 0]+1).astype(np.int32)
-    tmph = (total_boxes[:, 3]-total_boxes[:, 1]+1).astype(np.int32)
+    tmp_width = (total_boxes[:, 2] - total_boxes[:, 0] + 1).astype(np.int32)
+    tmp_height = (total_boxes[:, 3] - total_boxes[:, 1] + 1).astype(np.int32)
     numbox = total_boxes.shape[0]
 
-    dx = np.ones((numbox), dtype=np.int32)
-    dy = np.ones((numbox), dtype=np.int32)
-    edx = tmpw.copy().astype(np.int32)
-    edy = tmph.copy().astype(np.int32)
+    d_x = np.ones((numbox), dtype=np.int32)
+    d_y = np.ones((numbox), dtype=np.int32)
+    ed_x = tmp_width.copy().astype(np.int32)
+    ed_y = tmp_height.copy().astype(np.int32)
 
-    x = total_boxes[:, 0].copy().astype(np.int32)
-    y = total_boxes[:, 1].copy().astype(np.int32)
-    ex = total_boxes[:, 2].copy().astype(np.int32)
-    ey = total_boxes[:, 3].copy().astype(np.int32)
+    dim_x = total_boxes[:, 0].copy().astype(np.int32)
+    dim_y = total_boxes[:, 1].copy().astype(np.int32)
+    e_x = total_boxes[:, 2].copy().astype(np.int32)
+    e_y = total_boxes[:, 3].copy().astype(np.int32)
 
-    tmp = np.where(ex > w)
-    edx.flat[tmp] = np.expand_dims(-ex[tmp]+w+tmpw[tmp], 1)
-    ex[tmp] = w
+    tmp = np.where(e_x > width)
+    ed_x.flat[tmp] = np.expand_dims(-e_x[tmp] + width + tmp_width[tmp], 1)
+    e_x[tmp] = width
 
-    tmp = np.where(ey > h)
-    edy.flat[tmp] = np.expand_dims(-ey[tmp]+h+tmph[tmp], 1)
-    ey[tmp] = h
+    tmp = np.where(e_y > height)
+    ed_y.flat[tmp] = np.expand_dims(-e_y[tmp] + height + tmp_height[tmp], 1)
+    e_y[tmp] = height
 
-    tmp = np.where(x < 1)
-    dx.flat[tmp] = np.expand_dims(2-x[tmp], 1)
-    x[tmp] = 1
+    tmp = np.where(dim_x < 1)
+    d_x.flat[tmp] = np.expand_dims(2 - dim_x[tmp], 1)
+    dim_x[tmp] = 1
 
-    tmp = np.where(y < 1)
-    dy.flat[tmp] = np.expand_dims(2-y[tmp], 1)
-    y[tmp] = 1
+    tmp = np.where(dim_y < 1)
+    d_y.flat[tmp] = np.expand_dims(2 - dim_y[tmp], 1)
+    dim_y[tmp] = 1
 
-    return dy, edy, dx, edx, y, ey, x, ex, tmpw, tmph
+    return d_y, ed_y, d_x, ed_x, dim_y, e_y, dim_x, e_x, tmp_width, tmp_height
 
 
-# function [bboxA] = rerec(bboxA)
-def rerec(bboxA):
-    """Convert bboxA to square."""
-    h = bboxA[:, 3]-bboxA[:, 1]
-    w = bboxA[:, 2]-bboxA[:, 0]
-    l = np.maximum(w, h)
-    bboxA[:, 0] = bboxA[:, 0]+w*0.5-l*0.5
-    bboxA[:, 1] = bboxA[:, 1]+h*0.5-l*0.5
-    bboxA[:, 2:4] = bboxA[:, 0:2] + np.transpose(np.tile(l, (2, 1)))
-    return bboxA
+# function [bbox_a] = rerec(bbox_a)
+def rerec(bbox_a):
+    """Convert bbox_a to square."""
+    height = bbox_a[:, 3]-bbox_a[:, 1]
+    width = bbox_a[:, 2]-bbox_a[:, 0]
+    length = np.maximum(width, height)
+    bbox_a[:, 0] = bbox_a[:, 0] + width * 0.5 - length * 0.5
+    bbox_a[:, 1] = bbox_a[:, 1] + height * 0.5 - length * 0.5
+    bbox_a[:, 2:4] = bbox_a[:, 0:2] + np.transpose(np.tile(length, (2, 1)))
+    return bbox_a
 
 
 def imresample(img, size):
     """ Resample image """
+    # pylint: disable=no-member
     im_data = cv2.resize(img, (size[1], size[0]),
                          interpolation=cv2.INTER_AREA)  # @UndefinedVariable
     return im_data
diff --git a/scripts/extract.py b/scripts/extract.py
index e1eecf5..9abc5a4 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -50,6 +50,8 @@ class Extract():
         Utils.finalize(self.images.images_found,
                        self.alignments.faces_count,
                        self.verify_output)
+        self.plugins.process_detect.join()
+        self.plugins.process_align.join()
 
     def threaded_io(self, task, io_args=None):
         """ Load images in a background thread """
@@ -106,6 +108,9 @@ class Extract():
         """ Run Face Detection """
         to_process = self.process_item_count()
         frame_no = 0
+        size = self.args.size if hasattr(self.args, "size") else 256
+        align_eyes = self.args.align_eyes if hasattr(self.args, "align_eyes") else False
+
         if self.plugins.is_parallel:
             self.plugins.launch_aligner()
             self.plugins.launch_detector()
@@ -122,9 +127,9 @@ class Extract():
             if exception:
                 exit(1)
             filename = faces["filename"]
-
             faces["output_file"] = self.output_dir / Path(filename).stem
 
+            self.align_face(faces, align_eyes, size)
             self.post_process.do_actions(faces)
 
             faces_count = len(faces["detected_faces"])
@@ -182,43 +187,42 @@ class Extract():
 
         self.threaded_io("reload", detected_faces)
 
+    @staticmethod
+    def align_face(faces, align_eyes, size, padding=48):
+        """ Align the detected face """
+        final_faces = list()
+        image = faces["image"]
+        landmarks = faces["landmarks"]
+        detected_faces = faces["detected_faces"]
+        for idx, face in enumerate(detected_faces):
+            detected_face = DetectedFace()
+            detected_face.from_dlib_rect(face)
+            detected_face.landmarksXY = landmarks[idx]
+            detected_face.frame_dims = image.shape[:2]
+            detected_face.load_aligned(image,
+                                       size=size,
+                                       padding=padding,
+                                       align_eyes=align_eyes)
+            final_faces.append(detected_face)
+        faces["detected_faces"] = final_faces
+
     def process_faces(self, filename, faces):
         """ Perform processing on found faces """
-        size = self.args.size if hasattr(self.args, "size") else 256
-        align_eyes = self.args.align_eyes if hasattr(self.args, "align_eyes") else False
-
         final_faces = list()
         save_queue = queue_manager.get_queue("save")
-
         filename = faces["filename"]
-        image = faces["image"]
         output_file = faces["output_file"]
 
         for idx, face in enumerate(faces["detected_faces"]):
-            detected_face = self.align_face(image, face, align_eyes, size)
-
             if self.export_face:
                 save_queue.put((filename,
                                 output_file,
-                                detected_face.aligned_face,
+                                face.aligned_face,
                                 idx))
 
-            final_faces.append(detected_face.to_alignment())
+            final_faces.append(face.to_alignment())
         self.alignments.data[os.path.basename(filename)] = final_faces
 
-    @staticmethod
-    def align_face(image, face, align_eyes, size, padding=48):
-        """ Align the detected face """
-        detected_face = DetectedFace()
-        detected_face.from_dlib_rect(face[0])
-        detected_face.landmarksXY = face[1]
-        detected_face.frame_dims = image.shape[:2]
-        detected_face.load_aligned(image,
-                                   size=size,
-                                   padding=padding,
-                                   align_eyes=align_eyes)
-        return detected_face
-
 
 class Plugins():
     """ Detector and Aligner Plugins and queues """
@@ -228,6 +232,8 @@ class Plugins():
         self.aligner = self.load_aligner()
         self.is_parallel = self.set_parallel_processing()
 
+        self.process_detect = None
+        self.process_align = None
         self.add_queues()
 
     def set_parallel_processing(self):
@@ -297,10 +303,10 @@ class Plugins():
         kwargs = {"in_queue": queue_manager.get_queue("detect"),
                   "out_queue": out_queue}
 
-        align_process = SpawnProcess()
-        event = align_process.event
+        self.process_align = SpawnProcess()
+        event = self.process_align.event
 
-        align_process.in_process(self.aligner.align, **kwargs)
+        self.process_align.in_process(self.aligner.align, **kwargs)
 
         # Wait for Aligner to take it's VRAM
         # The first ever load of the model for FAN has reportedly taken
@@ -336,15 +342,15 @@ class Plugins():
             kwargs["mtcnn_kwargs"] = mtcnn_kwargs
 
         if self.detector.parent_is_pool:
-            detect_process = PoolProcess(self.detector.detect_faces)
+            self.process_detect = PoolProcess(self.detector.detect_faces)
         else:
-            detect_process = SpawnProcess()
+            self.process_detect = SpawnProcess()
 
         event = None
-        if hasattr(detect_process, "event"):
-            event = detect_process.event
+        if hasattr(self.process_detect, "event"):
+            event = self.process_detect.event
 
-        detect_process.in_process(self.detector.detect_faces, **kwargs)
+        self.process_detect.in_process(self.detector.detect_faces, **kwargs)
 
         if not event:
             return
diff --git a/tools/lib_alignments/jobs_manual.py b/tools/lib_alignments/jobs_manual.py
index cb78427..7c86101 100644
--- a/tools/lib_alignments/jobs_manual.py
+++ b/tools/lib_alignments/jobs_manual.py
@@ -890,8 +890,8 @@ class MouseHandler():
         landmarks = queue_manager.get_queue("out").get()
         if landmarks == "EOF":
             exit(0)
-        alignment = self.extracted_to_alignment(landmarks["detected_faces"][0])
-        print(alignment)
+        alignment = self.extracted_to_alignment((landmarks["detected_faces"][0],
+                                                 landmarks["landmarks"][0]))
         frame = self.media["frame_id"]
 
         if self.interface.get_selected_face_id() is None:
