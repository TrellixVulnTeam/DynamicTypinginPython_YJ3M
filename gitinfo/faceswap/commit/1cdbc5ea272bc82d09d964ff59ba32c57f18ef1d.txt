commit 1cdbc5ea272bc82d09d964ff59ba32c57f18ef1d
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Wed Sep 18 23:37:22 2019 +0000

    Update cli for MTCNN

diff --git a/lib/cli.py b/lib/cli.py
index 6c9dff1..3706e45 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -554,8 +554,8 @@ class ExtractArgs(ExtractConvertArgs):
                     "\nL|cv2-dnn: A CPU only extractor, is the least reliable, but uses least "
                     "resources and runs fast on CPU. Use this if not using a GPU and time is "
                     "important."
-                    "\nL|mtcnn: Fast on GPU, slow on CPU. Uses fewer resources than other GPU "
-                    "detectors but can often return more false positives."
+                    "\nL|mtcnn: Fast on CPU, Faster on GPU. Uses far fewer resources than other "
+                    "GPU detectors but can often return more false positives."
                     "\nL|s3fd: Fast on GPU, slow on CPU. Can detect more faces and "
                     "fewer false positives than other GPU detectors, but is a lot more resource "
                     "intensive."})
diff --git a/plugins/extract/pipeline.py b/plugins/extract/pipeline.py
index 7e22292..bc31147 100644
--- a/plugins/extract/pipeline.py
+++ b/plugins/extract/pipeline.py
@@ -342,7 +342,7 @@ class Extractor():
             vram than is available. Nvidia only. """
         if (self._detector.vram == 0 and self._aligner.vram == 0) or get_backend() != "nvidia":
             logger.debug("Either detector and aligner have no VRAM requirements or not running "
-                         "on Nvidia. Not updating batchsize requirements/")
+                         "on Nvidia. Not updating batchsize requirements.")
             return
         stats = GPUStats().get_card_most_free()
         vram_free = int(stats["free"])
