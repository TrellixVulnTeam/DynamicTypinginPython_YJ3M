commit 2e9abd7c09c15955bffa57fe249de0b6ee06f8ea
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Apr 23 11:44:52 2018 +0100

    Model backup bugfix (#371)
    
    * model backup bugfix - original model
    
    * Model backup bugfix - remaining models

diff --git a/lib/utils.py b/lib/utils.py
index f555990..dac971f 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -1,6 +1,6 @@
 import cv2
 import sys
-from os.path import basename, exists
+from os.path import basename, exists, join
 
 from pathlib import Path
 from scandir import scandir
@@ -32,6 +32,14 @@ def get_image_paths(directory, exclude=[], debug=False):
 
     return dir_contents
 
+def backup_file(directory, filename):
+    """ Backup a given file by appending .bk to the end """
+    origfile = join(directory, filename)
+    backupfile = origfile + '.bk'
+    if exists(backupfile):
+        os.remove(backupfile)
+    os.rename(origfile, backupfile)
+
 # From: https://stackoverflow.com/questions/22041699/rotate-an-image-without-cropping-in-opencv-in-c
 def rotate_image(image, angle, rotated_width=None, rotated_height=None):
     height, width = image.shape[:2]
diff --git a/plugins/Model_GAN/Model.py b/plugins/Model_GAN/Model.py
index f73d117..0f90ed1 100644
--- a/plugins/Model_GAN/Model.py
+++ b/plugins/Model_GAN/Model.py
@@ -1,7 +1,5 @@
 # Based on the https://github.com/shaoanlu/faceswap-GAN repo (master/temp/faceswap_GAN_keras.ipynb)
 
-import os
-import shutil
 from keras.models import Model
 from keras.layers import *
 from keras.layers.advanced_activations import LeakyReLU
@@ -12,13 +10,14 @@ from keras.optimizers import Adam
 
 from lib.PixelShuffler import PixelShuffler
 from .instance_normalization import InstanceNormalization
+from lib.utils import backup_file
 
 from keras.utils import multi_gpu_model
 
-netGAH5 = 'netGA_GAN.h5'
-netGBH5 = 'netGB_GAN.h5'
-netDAH5 = 'netDA_GAN.h5'
-netDBH5 = 'netDB_GAN.h5'
+hdf = {'netGAH5': 'netGA_GAN.h5',
+       'netGBH5': 'netGB_GAN.h5',
+       'netDAH5': 'netDA_GAN.h5',
+       'netDBH5': 'netDB_GAN.h5'}
 
 def __conv_init(a):
     print("conv_init", a)
@@ -122,8 +121,8 @@ class GANModel():
         self.netGB_sm = netGB
 
         try:
-            netGA.load_weights(str(self.model_dir / netGAH5))
-            netGB.load_weights(str(self.model_dir / netGBH5))
+            netGA.load_weights(str(self.model_dir / hdf['netGAH5']))
+            netGB.load_weights(str(self.model_dir / hdf['netGBH5']))
             print ("Generator models loaded.")
         except:
             print ("Generator weights files not found.")
@@ -154,8 +153,8 @@ class GANModel():
         netDA = Discriminator(self.nc_D_inp)
         netDB = Discriminator(self.nc_D_inp)
         try:
-            netDA.load_weights(str(self.model_dir / netDAH5))
-            netDB.load_weights(str(self.model_dir / netDBH5))
+            netDA.load_weights(str(self.model_dir / hdf['netDAH5']))
+            netDB.load_weights(str(self.model_dir / hdf['netDBH5']))
             print ("Discriminator models loaded.")
         except:
             print ("Discriminator weights files not found.")
@@ -170,16 +169,14 @@ class GANModel():
 
     def save_weights(self):
         model_dir = str(self.model_dir)
-        if os.path.isdir(model_dir + "_bk"):
-            shutil.rmtree(model_dir + "_bk")
-        shutil.move(model_dir,  model_dir + "_bk")
-        os.mkdir(model_dir)
+        for model in hdf.values():
+            backup_file(model_dir, model)
         if self.gpus > 1:
-            self.netGA_sm.save_weights(str(self.model_dir / netGAH5))
-            self.netGB_sm.save_weights(str(self.model_dir / netGBH5))
+            self.netGA_sm.save_weights(str(self.model_dir / hdf['netGAH5']))
+            self.netGB_sm.save_weights(str(self.model_dir / hdf['netGBH5']))
         else:
-            self.netGA.save_weights(str(self.model_dir / netGAH5))
-            self.netGB.save_weights(str(self.model_dir / netGBH5))
-        self.netDA.save_weights(str(self.model_dir / netDAH5))
-        self.netDB.save_weights(str(self.model_dir / netDBH5))
+            self.netGA.save_weights(str(self.model_dir / hdf['netGAH5']))
+            self.netGB.save_weights(str(self.model_dir / hdf['netGBH5']))
+        self.netDA.save_weights(str(self.model_dir / hdf['netDAH5']))
+        self.netDB.save_weights(str(self.model_dir / hdf['netDBH5']))
         print ("Models saved.")
diff --git a/plugins/Model_GAN128/Model.py b/plugins/Model_GAN128/Model.py
index 7cf150f..fffa74f 100644
--- a/plugins/Model_GAN128/Model.py
+++ b/plugins/Model_GAN128/Model.py
@@ -1,8 +1,6 @@
 # Based on the https://github.com/shaoanlu/faceswap-GAN repo
 # source : https://github.com/shaoanlu/faceswap-GAN/blob/master/FaceSwap_GAN_v2_sz128_train.ipynbtemp/faceswap_GAN_keras.ipynb
 
-import os
-import shutil
 from keras.models import Model
 from keras.layers import *
 from keras.layers.advanced_activations import LeakyReLU
@@ -13,13 +11,14 @@ from keras.optimizers import Adam
 
 from lib.PixelShuffler import PixelShuffler
 from .instance_normalization import InstanceNormalization
+from lib.utils import backup_file
 
 from keras.utils import multi_gpu_model
 
-netGAH5 = 'netGA_GAN128.h5'
-netGBH5 = 'netGB_GAN128.h5'
-netDAH5 = 'netDA_GAN128.h5'
-netDBH5 = 'netDB_GAN128.h5'
+hdf = {'netGAH5':'netGA_GAN128.h5',
+       'netGBH5': 'netGB_GAN128.h5',
+       'netDAH5': 'netDA_GAN128.h5',
+       'netDBH5': 'netDB_GAN128.h5'}
 
 def __conv_init(a):
     print("conv_init", a)
@@ -136,8 +135,8 @@ class GANModel():
         self.netGB_sm = netGB
 
         try:
-            netGA.load_weights(str(self.model_dir / netGAH5))
-            netGB.load_weights(str(self.model_dir / netGBH5))
+            netGA.load_weights(str(self.model_dir / hdf['netGAH5']))
+            netGB.load_weights(str(self.model_dir / hdf['netGBH5']))
             print ("Generator models loaded.")
         except:
             print ("Generator weights files not found.")
@@ -172,8 +171,8 @@ class GANModel():
         netDB = Discriminator(self.nc_D_inp)
 
         try:
-            netDA.load_weights(str(self.model_dir / netDAH5))
-            netDB.load_weights(str(self.model_dir / netDBH5))
+            netDA.load_weights(str(self.model_dir / hdf['netDAH5']))
+            netDB.load_weights(str(self.model_dir / hdf['netDBH5']))
             print ("Discriminator models loaded.")
         except:
             print ("Discriminator weights files not found.")
@@ -188,16 +187,14 @@ class GANModel():
 
     def save_weights(self):
         model_dir = str(self.model_dir)
-        if os.path.isdir(model_dir + "_bk"):
-            shutil.rmtree(model_dir + "_bk")
-        shutil.move(model_dir,  model_dir + "_bk")
-        os.mkdir(model_dir)
+        for model in hdf.values():
+            backup_file(model_dir, model)
         if self.gpus > 1:
-            self.netGA_sm.save_weights(str(self.model_dir / netGAH5))
-            self.netGB_sm.save_weights(str(self.model_dir / netGBH5))
+            self.netGA_sm.save_weights(str(self.model_dir / hdf['netGAH5']))
+            self.netGB_sm.save_weights(str(self.model_dir / hdf['netGBH5']))
         else:
-            self.netGA.save_weights(str(self.model_dir / netGAH5))
-            self.netGB.save_weights(str(self.model_dir / netGBH5))
-        self.netDA.save_weights(str(self.model_dir / netDAH5))
-        self.netDB.save_weights(str(self.model_dir / netDBH5))
+            self.netGA.save_weights(str(self.model_dir / hdf['netGAH5']))
+            self.netGB.save_weights(str(self.model_dir / hdf['netGBH5']))
+        self.netDA.save_weights(str(self.model_dir / hdf['netDAH5']))
+        self.netDB.save_weights(str(self.model_dir / hdf['netDBH5']))
         print ("Models saved.")
diff --git a/plugins/Model_IAE/AutoEncoder.py b/plugins/Model_IAE/AutoEncoder.py
index dd7eee9..dce65fe 100644
--- a/plugins/Model_IAE/AutoEncoder.py
+++ b/plugins/Model_IAE/AutoEncoder.py
@@ -1,12 +1,12 @@
 # Improved-AutoEncoder base classes
 
-import os, shutil
+from lib.utils import backup_file
 
-encoderH5 = 'IAE_encoder.h5'
-decoderH5 = 'IAE_decoder.h5'
-inter_AH5 = 'IAE_inter_A.h5'
-inter_BH5 = 'IAE_inter_B.h5'
-inter_bothH5 = 'IAE_inter_both.h5'
+hdf = {'encoderH5': 'IAE_encoder.h5',
+       'decoderH5': 'IAE_decoder.h5',
+       'inter_AH5': 'IAE_inter_A.h5',
+       'inter_BH5': 'IAE_inter_B.h5',
+       'inter_bothH5': 'IAE_inter_both.h5'}
 
 
 class AutoEncoder:
@@ -23,12 +23,12 @@ class AutoEncoder:
         self.initModel()
 
     def load(self, swapped):
-        (face_A,face_B) = (inter_AH5, inter_BH5) if not swapped else (inter_BH5, inter_AH5)
+        (face_A,face_B) = (hdf['inter_AH5'], hdf['inter_BH5']) if not swapped else (hdf['inter_BH5'], hdf['inter_AH5'])
 
         try:
-            self.encoder.load_weights(str(self.model_dir / encoderH5))
-            self.decoder.load_weights(str(self.model_dir / decoderH5))
-            self.inter_both.load_weights(str(self.model_dir / inter_bothH5))
+            self.encoder.load_weights(str(self.model_dir / hdf['encoderH5']))
+            self.decoder.load_weights(str(self.model_dir / hdf['decoderH5']))
+            self.inter_both.load_weights(str(self.model_dir / hdf['inter_bothH5']))
             self.inter_A.load_weights(str(self.model_dir / face_A))
             self.inter_B.load_weights(str(self.model_dir / face_B))
             print('loaded model weights')
@@ -40,13 +40,11 @@ class AutoEncoder:
 
     def save_weights(self):
         model_dir = str(self.model_dir)
-        if os.path.isdir(model_dir + "_bk"):
-            shutil.rmtree(model_dir + "_bk")
-        shutil.move(model_dir,  model_dir + "_bk")
-        os.mkdir(model_dir)
-        self.encoder.save_weights(str(self.model_dir / encoderH5))
-        self.decoder.save_weights(str(self.model_dir / decoderH5))
-        self.inter_both.save_weights(str(self.model_dir / inter_bothH5))
-        self.inter_A.save_weights(str(self.model_dir / inter_AH5))
-        self.inter_B.save_weights(str(self.model_dir / inter_BH5))
+        for model in hdf.values():
+            backup_file(model_dir, model)
+        self.encoder.save_weights(str(self.model_dir / hdf['encoderH5']))
+        self.decoder.save_weights(str(self.model_dir / hdf['decoderH5']))
+        self.inter_both.save_weights(str(self.model_dir / hdf['inter_bothH5']))
+        self.inter_A.save_weights(str(self.model_dir / hdf['inter_AH5']))
+        self.inter_B.save_weights(str(self.model_dir / hdf['inter_BH5']))
         print('saved model weights')
diff --git a/plugins/Model_LowMem/AutoEncoder.py b/plugins/Model_LowMem/AutoEncoder.py
index 5c457f7..2fb148d 100644
--- a/plugins/Model_LowMem/AutoEncoder.py
+++ b/plugins/Model_LowMem/AutoEncoder.py
@@ -1,10 +1,10 @@
 # AutoEncoder base classes
 
-import os, shutil
+from lib.utils import backup_file
 
-encoderH5 = 'lowmem_encoder.h5'
-decoder_AH5 = 'lowmem_decoder_A.h5'
-decoder_BH5 = 'lowmem_decoder_B.h5'
+hdf = {'encoderH5': 'lowmem_encoder.h5',
+       'decoder_AH5': 'lowmem_decoder_A.h5',
+       'decoder_BH5': 'lowmem_decoder_B.h5'}
 
 #Part of Filename migration, should be remopved some reasonable time after first added
 import os.path
@@ -25,21 +25,21 @@ class AutoEncoder:
         self.initModel()
 
     def load(self, swapped):
-        (face_A,face_B) = (decoder_AH5, decoder_BH5) if not swapped else (decoder_BH5, decoder_AH5)
+        (face_A,face_B) = (hdf['decoder_AH5'], hdf['decoder_BH5']) if not swapped else (hdf['decoder_BH5'], hdf['decoder_AH5'])
 
         try:
             #Part of Filename migration, should be remopved some reasonable time after first added
             if os.path.isfile(str(self.model_dir / old_encoderH5)):
                 print('Migrating to new filenames: ', end='')
-                if os.path.isfile(str(self.model_dir / encoderH5)) is not True:
-                    os.rename(str(self.model_dir / old_decoder_AH5), str(self.model_dir / decoder_AH5))
-                    os.rename(str(self.model_dir / old_decoder_BH5), str(self.model_dir / decoder_BH5))
-                    os.rename(str(self.model_dir / old_encoderH5), str(self.model_dir / encoderH5))
+                if os.path.isfile(str(self.model_dir / hdf['encoderH5'])) is not True:
+                    os.rename(str(self.model_dir / old_decoder_AH5), str(self.model_dir / hdf['decoder_AH5']))
+                    os.rename(str(self.model_dir / old_decoder_BH5), str(self.model_dir / hdf['decoder_BH5']))
+                    os.rename(str(self.model_dir / old_encoderH5), str(self.model_dir / hdf['encoderH5']))
                     print('Complete')
                 else:
                     print('Failed due to existing files in folder.  Loading already migrated files')
             #End filename migration
-            self.encoder.load_weights(str(self.model_dir / encoderH5))
+            self.encoder.load_weights(str(self.model_dir / hdf['encoderH5']))
             self.decoder_A.load_weights(str(self.model_dir / face_A))
             self.decoder_B.load_weights(str(self.model_dir / face_B))
             print('loaded model weights')
@@ -51,11 +51,9 @@ class AutoEncoder:
 
     def save_weights(self):
         model_dir = str(self.model_dir)
-        if os.path.isdir(model_dir + "_bk"):
-            shutil.rmtree(model_dir + "_bk")
-        shutil.move(model_dir,  model_dir + "_bk")
-        os.mkdir(model_dir)
-        self.encoder.save_weights(str(self.model_dir / encoderH5))
-        self.decoder_A.save_weights(str(self.model_dir / decoder_AH5))
-        self.decoder_B.save_weights(str(self.model_dir / decoder_BH5))
+        for model in hdf.values():
+            backup_file(model_dir, model)
+        self.encoder.save_weights(str(self.model_dir / hdf['encoderH5']))
+        self.decoder_A.save_weights(str(self.model_dir / hdf['decoder_AH5']))
+        self.decoder_B.save_weights(str(self.model_dir / hdf['decoder_BH5']))
         print('saved model weights')
diff --git a/plugins/Model_Original/AutoEncoder.py b/plugins/Model_Original/AutoEncoder.py
index 8c3ffdd..dd7eb00 100644
--- a/plugins/Model_Original/AutoEncoder.py
+++ b/plugins/Model_Original/AutoEncoder.py
@@ -1,10 +1,10 @@
 # AutoEncoder base classes
 
-import os, shutil
+from lib.utils import backup_file
 
-encoderH5 = 'encoder.h5'
-decoder_AH5 = 'decoder_A.h5'
-decoder_BH5 = 'decoder_B.h5'
+hdf = {'encoderH5': 'encoder.h5',
+       'decoder_AH5': 'decoder_A.h5',
+       'decoder_BH5': 'decoder_B.h5'}
 
 class AutoEncoder:
     def __init__(self, model_dir, gpus):
@@ -18,10 +18,10 @@ class AutoEncoder:
         self.initModel()
 
     def load(self, swapped):
-        (face_A,face_B) = (decoder_AH5, decoder_BH5) if not swapped else (decoder_BH5, decoder_AH5)
+        (face_A,face_B) = (hdf['decoder_AH5'], hdf['decoder_BH5']) if not swapped else (hdf['decoder_BH5'], hdf['decoder_AH5'])
 
         try:
-            self.encoder.load_weights(str(self.model_dir / encoderH5))
+            self.encoder.load_weights(str(self.model_dir / hdf['encoderH5']))
             self.decoder_A.load_weights(str(self.model_dir / face_A))
             self.decoder_B.load_weights(str(self.model_dir / face_B))
             print('loaded model weights')
@@ -33,11 +33,9 @@ class AutoEncoder:
 
     def save_weights(self):
         model_dir = str(self.model_dir)
-        if os.path.isdir(model_dir + "_bk"):
-            shutil.rmtree(model_dir + "_bk")
-        shutil.move(model_dir,  model_dir + "_bk")
-        os.mkdir(model_dir)
-        self.encoder.save_weights(str(self.model_dir / encoderH5))
-        self.decoder_A.save_weights(str(self.model_dir / decoder_AH5))
-        self.decoder_B.save_weights(str(self.model_dir / decoder_BH5))
+        for model in hdf.values():
+            backup_file(model_dir, model)
+        self.encoder.save_weights(str(self.model_dir / hdf['encoderH5']))
+        self.decoder_A.save_weights(str(self.model_dir / hdf['decoder_AH5']))
+        self.decoder_B.save_weights(str(self.model_dir / hdf['decoder_BH5']))
         print('saved model weights')
