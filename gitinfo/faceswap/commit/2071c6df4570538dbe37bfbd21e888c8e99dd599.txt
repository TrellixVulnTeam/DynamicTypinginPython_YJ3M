commit 2071c6df4570538dbe37bfbd21e888c8e99dd599
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Jun 3 01:43:35 2019 +0000

    Add save snapshot backup option for training

diff --git a/lib/cli.py b/lib/cli.py
index b4df373..9347df7 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -851,6 +851,16 @@ class TrainArgs(FaceSwapArgs):
                               "dest": "save_interval",
                               "default": 100,
                               "help": "Sets the number of iterations before saving the model"})
+        argument_list.append({"opts": ("-ss", "--snapshot-interval"),
+                              "type": int,
+                              "action": Slider,
+                              "min_max": (0, 100000),
+                              "rounding": 5000,
+                              "dest": "snapshot_interval",
+                              "default": 25000,
+                              "help": "Sets the number of iterations before saving a backup "
+                                      "snapshot of the model in it's current state. Set to 0 for "
+                                      "off."})
         argument_list.append({"opts": ("-bs", "--batch-size"),
                               "type": int,
                               "action": Slider,
diff --git a/plugins/train/model/_base.py b/plugins/train/model/_base.py
index e08c9fa..a51ff13 100644
--- a/plugins/train/model/_base.py
+++ b/plugins/train/model/_base.py
@@ -10,6 +10,7 @@ import sys
 import time
 
 from json import JSONDecodeError
+from shutil import copyfile, copytree
 
 import keras
 from keras import losses
@@ -22,6 +23,7 @@ from lib import Serializer
 from lib.model.losses import DSSIMObjective, PenalizedLoss
 from lib.model.nn_blocks import NNBlocks
 from lib.multithreading import MultiThread
+from lib.utils import get_folder
 from plugins.train._config import Config
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
@@ -391,16 +393,20 @@ class ModelBase():
             logger.info("Loaded model from disk: '%s'", self.model_dir)
         return is_loaded
 
-    def save_models(self):
+    def save_models(self, snapshot_iteration):
         """ Backup and save the models """
         logger.debug("Backing up and saving models")
         should_backup = self.get_save_averages()
         save_threads = list()
         for network in self.networks.values():
             name = "save_{}".format(network.name)
-            save_threads.append(MultiThread(network.save, name=name, should_backup=should_backup))
+            save_threads.append(MultiThread(network.save,
+                                            name=name,
+                                            should_backup=should_backup))
         save_threads.append(MultiThread(self.state.save,
-                                        name="save_state", should_backup=should_backup))
+                                        name="save_state",
+                                        should_backup=should_backup,
+                                        snapshot=snapshot_iteration))
         for thread in save_threads:
             thread.start()
         for thread in save_threads:
@@ -408,7 +414,6 @@ class ModelBase():
                 logger.error(thread.errors[0])
             thread.join()
         # Put in a line break to avoid jumbled console
-        print("\n")
         logger.info("saved models")
 
     def get_save_averages(self):
@@ -697,7 +702,7 @@ class State():
         except JSONDecodeError as err:
             logger.debug("JSONDecodeError: %s:", str(err))
 
-    def save(self, should_backup=False):
+    def save(self, should_backup=False, snapshot=False):
         """ Save iteration number to state file """
         logger.debug("Saving State")
         if should_backup:
@@ -716,6 +721,8 @@ class State():
         except IOError as err:
             logger.error("Unable to save model state: %s", str(err.strerror))
         logger.debug("Saved State")
+        if snapshot:
+            self.snapshot_model()
 
     def backup(self):
         """ Backup state file """
@@ -727,6 +734,21 @@ class State():
         if os.path.exists(origfile):
             os.rename(origfile, backupfile)
 
+    def snapshot_model(self):
+        """ Take a snapshot of the model at current state and back up """
+        logger.info("Saving snapshot")
+        src = os.path.dirname(self.filename)
+        dst = get_folder("{}_{}".format(src, self.iterations))
+        for filename in os.listdir(src):
+            if filename.endswith(".bk"):
+                continue
+            srcfile = os.path.join(src, filename)
+            dstfile = os.path.join(dst, filename)
+            copyfunc = copytree if os.path.isdir(srcfile) else copyfile
+            logger.debug("Saving snapshot: '%s' > '%s'", srcfile, dstfile)
+            copyfunc(srcfile, dstfile)
+        logger.info("Saved snapshot")
+
     def replace_config(self, config_changeable_items):
         """ Replace the loaded config with the one contained within the state file
             Check for any fixed=False parameters changes and log info changes
diff --git a/scripts/train.py b/scripts/train.py
index 9bf9fdb..ff5d9bf 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -140,7 +140,7 @@ class Train():
         except KeyboardInterrupt:
             try:
                 logger.debug("Keyboard Interrupt Caught. Saving Weights and exiting")
-                model.save_models()
+                model.save_models(False)
                 trainer.clear_tensorboard()
             except KeyboardInterrupt:
                 logger.info("Saving model weights has been cancelled!")
@@ -208,6 +208,10 @@ class Train():
 
         for iteration in range(0, self.args.iterations):
             logger.trace("Training iteration: %s", iteration)
+            snapshot_interval = self.args.save_interval * self.args.snapshot_interval
+            snapshot_iteration = bool(snapshot_interval != 0 and
+                                      iteration >= snapshot_interval and
+                                      iteration % snapshot_interval == 0)
             save_iteration = iteration % self.args.save_interval == 0
             viewer = display_func if save_iteration or self.save_now else None
             timelapse = self.timelapse if save_iteration else None
@@ -215,19 +219,19 @@ class Train():
             if self.stop:
                 logger.debug("Stop received. Terminating")
                 break
-            elif save_iteration:
+            if save_iteration:
                 logger.trace("Save Iteration: (iteration: %s", iteration)
                 if self.args.pingpong:
-                    model.save_models()
+                    model.save_models(snapshot_iteration)
                     trainer.pingpong.switch()
                 else:
-                    model.save_models()
+                    model.save_models(snapshot_iteration)
             elif self.save_now:
                 logger.trace("Save Requested: (iteration: %s", iteration)
-                model.save_models()
+                model.save_models(False)
                 self.save_now = False
         logger.debug("Training cycle complete")
-        model.save_models()
+        model.save_models(False)
         trainer.clear_tensorboard()
         self.stop = True
 
