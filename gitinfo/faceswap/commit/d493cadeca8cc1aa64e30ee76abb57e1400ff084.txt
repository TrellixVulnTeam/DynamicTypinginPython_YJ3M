commit d493cadeca8cc1aa64e30ee76abb57e1400ff084
Author: Hidde Jansen <Ganonmaster@users.noreply.github.com>
Date:   Wed Dec 27 12:47:52 2017 +0100

    Allow users to swap the A/B models (#29)
    
    * Allow users to swap the conversion models.

diff --git a/lib/faces_process.py b/lib/faces_process.py
index e951cae..a5577ae 100644
--- a/lib/faces_process.py
+++ b/lib/faces_process.py
@@ -8,11 +8,14 @@ from .model import autoencoder_B
 from .model import encoder, decoder_A, decoder_B
 
 
-def convert_one_image(image, model_dir="models"):
+def convert_one_image(image, model_dir="models", swap_model=False, use_aligner=False):
+
+    face_A = '/decoder_A.h5' if not swap_model else '/decoder_B.h5'
+    face_B = '/decoder_B.h5' if not swap_model else '/decoder_A.h5'
 
     encoder.load_weights(model_dir + "/encoder.h5")
-    decoder_A.load_weights(model_dir + "/decoder_A.h5")
-    decoder_B.load_weights(model_dir + "/decoder_B.h5")
+    decoder_A.load_weights(model_dir + face_A)
+    decoder_B.load_weights(model_dir + face_B)
 
     autoencoder = autoencoder_B
 
@@ -23,7 +26,8 @@ def convert_one_image(image, model_dir="models"):
               "Landmark file can be found in http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2"
               "\nUnzip it in the contrib/ folder.".format(shapePredictor))
         return
-    aligner = Aligner(shapePredictor, humanFaceDetector)
+    if use_aligner:
+        aligner = Aligner(shapePredictor, humanFaceDetector)
 
     assert image.shape == (256, 256, 3)
     crop = slice(48, 208)
@@ -33,13 +37,11 @@ def convert_one_image(image, model_dir="models"):
     new_face = autoencoder.predict(face / 255.0)[0]
     new_face = numpy.clip(new_face * 255, 0, 255).astype(image.dtype)
     new_face = cv2.resize(new_face, (160, 160))
-    return superpose(image, new_face, crop)
     # Aligner is not ready to use yet
-    # result = aligner.align(image.copy(), new_face)
-    # if result is None:
-    #     return superpose(image, new_face, crop)
-    # else:
-    #     return result
+    if use_aligner:
+        return aligner.align(image.copy(), new_face)
+    else:
+        return superpose(image, new_face, crop)
 
 
 def superpose(image, new_face, crop):
diff --git a/scripts/convert.py b/scripts/convert.py
index ce50439..5570dcb 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -23,6 +23,11 @@ class ConvertImage(DirectoryProcessor):
                             default="models",
                             help="Model directory. A directory containing the trained model \
                     you wish to process. Defaults to 'models'")
+        parser.add_argument('-s', '--swap-model',
+                            action="store_true",
+                            dest="swap_model",
+                            default=False,
+                            help="Swap the model. Instead of A -> B, swap B -> A.")
         return parser
 
     def process_image(self, filename):
@@ -33,7 +38,7 @@ class ConvertImage(DirectoryProcessor):
                     print('- Found more than one face!')
                     self.verify_output = True
 
-                new_face = convert_one_image(cv2.resize(face.image, (256, 256)), self.arguments.model_dir)
+                new_face = convert_one_image(cv2.resize(face.image, (256, 256)), self.arguments.model_dir, self.arguments.swap_model)
                 image[slice(face.y, face.y + face.h), slice(face.x, face.x + face.w)] = cv2.resize(new_face, (face.w, face.h))
                 self.faces_detected = self.faces_detected + 1
             output_file = self.output_dir / Path(filename).name
