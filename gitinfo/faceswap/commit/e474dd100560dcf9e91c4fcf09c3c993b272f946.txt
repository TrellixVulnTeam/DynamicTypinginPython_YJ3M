commit e474dd100560dcf9e91c4fcf09c3c993b272f946
Author: Artem Ivanov <37909402+andenixa@users.noreply.github.com>
Date:   Sun Apr 14 22:28:56 2019 +0300

    Pegasus model plug-in rc1 (#701)
    
    * added new RealFace training model (codenamed: Pegasus)
    
    * minor re-factoring (doesn't break compatibility)
    
    * fixed tf error for input/output sizes with ratios other than 1:2
    
    * linting
    
    * Minor formatting/grammar ammends
    
    * Make loss a fixed config item. Make learning rate an unfixed item
    
    * Check input and output sizes

diff --git a/plugins/train/_config.py b/plugins/train/_config.py
index 965fa0e..b54bf20 100644
--- a/plugins/train/_config.py
+++ b/plugins/train/_config.py
@@ -25,7 +25,7 @@ ADDITIONAL_INFO = ("\nNB: Unless specifically stated, values changed here will o
 
 class Config(FaceswapConfig):
     """ Config File for Models """
-
+    # pylint: disable=too-many-statements
     def set_defaults(self):
         """ Set the default values for config """
         logger.debug("Setting defaults")
@@ -47,11 +47,11 @@ class Config(FaceswapConfig):
                  "model you are training has a distinct line appearing around the edge of the "
                  "swap area.")
         self.add_item(
-            section=section, title="dssim_loss", datatype=bool, default=True, fixed=False,
+            section=section, title="dssim_loss", datatype=bool, default=True,
             info="Use DSSIM for Loss rather than Mean Absolute Error\n"
                  "May increase overall quality.")
         self.add_item(
-            section=section, title="penalized_mask_loss", datatype=bool, default=True, fixed=False,
+            section=section, title="penalized_mask_loss", datatype=bool, default=True,
             info="If using a mask, This penalizes the loss for the masked area, to give higher "
                  "priority to the face area. \nShould increase overall quality and speed up "
                  "training. This should probably be left at True")
@@ -174,6 +174,62 @@ class Config(FaceswapConfig):
             section=section, title="coverage", datatype=float, default=62.5, rounding=1,
             min_max=(62.5, 100.0), info=COVERAGE_INFO)
 
+        # << PEGASUS MODEL OPTIONS >> #
+        section = "model.realface"
+        self.add_section(title=section,
+                         info="An extra detailed variant of Original model.\n"
+                              "Incorporates ideas from Bryanlyon and inspiration from the Villain "
+                              "model.\n"
+                              "Requires about 6GB-8GB of VRAM (batchsize 8-16)." + ADDITIONAL_INFO)
+        self.add_item(
+            section=section, title="dssim_loss", datatype=bool, default=True,
+            info="Use DSSIM for Loss rather than Mean Absolute Error\n"
+                 "May increase overall quality.")
+        self.add_item(
+            section=section, title="mask_type", datatype=str, default="components",
+            choices=MASK_TYPES, info=MASK_INFO)
+        self.add_item(
+            section=section, title="coverage", datatype=float, default=62.5, rounding=1,
+            min_max=(62.5, 100.0),
+            info="{}\nThe model is essentially created for 60-80% coverage as it follows "
+                 "Original paradigm.\nYou may try higher values but good results are not "
+                 "guaranteed.".format(COVERAGE_INFO))
+        self.add_item(
+            section=section, title="input_size", datatype=int, default=64,
+            rounding=16, min_max=(64, 128),
+            info="Resolution (in pixels) of the input image to train on.\n"
+                 "BE AWARE Larger resolution will dramatically increase"
+                 "VRAM requirements.\n"
+                 "Higher resolutions may increase prediction accuracy, but does not effect the "
+                 "resulting output size.\n"
+                 "Must be between 64 and 128 and be divisible by 16.")
+        self.add_item(
+            section=section, title="output_size", datatype=int, default=128,
+            rounding=16, min_max=(64, 256),
+            info="Output image resolution (in pixels).\n"
+                 "Be aware that larger resolution will increase VRAM requirements.\n"
+                 "NB: Must be between 64 and 256 and be divisible by 16.")
+        self.add_item(
+            section=section, title="dense_nodes", datatype=int, default=1536, rounding=64,
+            min_max=(768, 2048),
+            info="Number of nodes for decoder. Might affect your model's ability to learn in "
+                 "general.\n"
+                 "Note that: Lower values will affect the ability to predict details.")
+        self.add_item(
+            section=section, title="complexity_encoder", datatype=int, default=128,
+            min_max=(96, 160), rounding=4,
+            info="Encoder Convolution Layer Complexity. sensible ranges: "
+                 "128 to 150")
+        self.add_item(
+            section=section, title="complexity_decoder", datatype=int, default=512,
+            rounding=4, min_max=(512, 544),
+            info="Decoder Complexity.")
+        self.add_item(
+            section=section, title="learning_rate", datatype=float, default=5e-5,
+            min_max=(5e-6, 1e-4), rounding=6, fixed=False,
+            info="Learning rate - how fast your network will learn.\n"
+                 "Note that: Higher values might result in RSoD failure.")
+
         # << VILLAIN MODEL OPTIONS >> #
         section = "model.villain"
         self.add_section(title=section,
@@ -186,8 +242,7 @@ class Config(FaceswapConfig):
                  "with a changed lowmem mode are not compatible with each other.")
         self.add_item(
             section=section, title="mask_type", datatype=str, default="none",
-            choices=["none", "dfaker", "dfl_full"],
-            info="The mask to be used for training. Select none to not use a mask")
+            choices=MASK_TYPES, info=MASK_INFO)
         self.add_item(
             section=section, title="coverage", datatype=float, default=62.5, rounding=1,
             min_max=(62.5, 100.0), info=COVERAGE_INFO)
diff --git a/plugins/train/model/realface.py b/plugins/train/model/realface.py
new file mode 100644
index 0000000..f499955
--- /dev/null
+++ b/plugins/train/model/realface.py
@@ -0,0 +1,188 @@
+#!/usr/bin/env python3
+""" RealFaceRC1, codenamed 'Pegasus'
+    Based on the original https://www.reddit.com/r/deepfakes/
+    code sample + contribs
+    Major thanks goes to BryanLyon as it vastly powered by his ideas and insights.
+    Without him it would not be possible to come up with the model.
+    Additional thanks: Birb - source of inspiration, great Encoder ideas
+                       Kvrooman - additional couseling on autoencoders and practical advices
+    """
+
+from keras.initializers import RandomNormal
+from keras.layers import Conv2D, Dense, Flatten, Input, Reshape
+from keras.models import Model as KerasModel
+
+from ._base import ModelBase, logger
+
+
+class Model(ModelBase):
+    """ RealFace(tm) Faceswap Model """
+    def __init__(self, *args, **kwargs):
+        logger.debug("Initializing %s: (args: %s, kwargs: %s",
+                     self.__class__.__name__, args, kwargs)
+
+        self.check_input_output()
+        self.dense_width, self.upscalers_no = self.get_dense_width_upscalers_numbers()
+        kwargs["input_shape"] = (self.config["input_size"], self.config["input_size"], 3)
+        self.kernel_initializer = RandomNormal(0, 0.02)
+
+        super().__init__(*args, **kwargs)
+        logger.debug("Initialized %s", self.__class__.__name__)
+
+    @property
+    def downscalers_no(self):
+        """ Number of downscalers. Don't change! """
+        return 4
+
+    @property
+    def _downscale_ratio(self):
+        """ Downscale Ratio """
+        return 2**self.downscalers_no
+
+    @property
+    def dense_filters(self):
+        """ Dense Filters. Don't change! """
+        return (int(1024 - (self.dense_width - 4) * 64) // 16) * 16
+
+    def check_input_output(self):
+        """ Confirm valid input and output sized have been provided """
+        if not 64 <= self.config["input_size"] <=128 or self.config["input_size"] % 16 != 0:
+            logger.error("Config error: input_size must be between 64 and 128 and be divisible by "
+                         "16.")
+            exit(1)
+        if not 64 <= self.config["output_size"] <=256 or self.config["output_size"] % 16 != 0:
+            logger.error("Config error: output_size must be between 64 and 256 and be divisible by "
+                         "16.")
+            exit(1)
+        logger.debug("Input and output sizes are valid")
+
+    def get_dense_width_upscalers_numbers(self):
+        """ Return the dense width and number of upscalers """
+        output_size = self.config['output_size']
+        sides = [(output_size // 2**n, n) for n in [4, 5] if (output_size // 2**n) < 10]
+        closest = min([x * self._downscale_ratio for x, _ in sides],
+                      key=lambda x: abs(x - self.config['input_size']))
+        dense_width, upscalers_no = [(s, n) for s, n in sides
+                                     if s * self._downscale_ratio == closest][0]
+        logger.debug("dense_width: %s, upscalers_no: %s", dense_width, upscalers_no)
+        return dense_width, upscalers_no
+
+    def add_networks(self):
+        """ Add the original model weights """
+        logger.debug("Adding networks")
+        self.add_network("decoder", "a", self.decoder_a())
+        self.add_network("decoder", "b", self.decoder_b())
+        self.add_network("encoder", None, self.encoder())
+        logger.debug("Added networks")
+
+    def build_autoencoders(self):
+        """ Initialize original model """
+        logger.debug("Initializing model")
+        inputs = [Input(shape=self.input_shape, name="face")]
+        if self.config.get("mask_type", None):
+            mask_shape = self.config["output_size"], self.config["output_size"], 1
+            inputs.append(Input(shape=mask_shape, name="mask"))
+
+        for side in "a", "b":
+            logger.debug("Adding Autoencoder. Side: %s", side)
+            decoder = self.networks["decoder_{}".format(side)].network
+            output = decoder(self.networks["encoder"].network(inputs[0]))
+            autoencoder = KerasModel(inputs, output)
+            self.add_predictor(side, autoencoder)
+        logger.debug("Initialized model")
+
+    def encoder(self):
+        """ RealFace Encoder Network """
+        input_ = Input(shape=self.input_shape)
+        var_x = input_
+
+        encoder_complexity = self.config['complexity_encoder']
+
+        for idx in range(self.downscalers_no - 1):
+            var_x = self.blocks.conv(var_x, encoder_complexity * 2**idx)
+            var_x = self.blocks.res_block(var_x, encoder_complexity * 2**idx, use_bias=True)
+            var_x = self.blocks.res_block(var_x, encoder_complexity * 2**idx, use_bias=True)
+
+        var_x = self.blocks.conv(var_x, encoder_complexity * 2**(idx + 1))
+
+        return KerasModel(input_, var_x)
+
+    def decoder_b(self):
+        """ RealFace Decoder Network """
+        input_width = self.config['input_size'] // self._downscale_ratio
+        input_ = Input(shape=(input_width, input_width, 1024))
+
+        var_xy = input_
+
+        var_xy = Dense(self.config['dense_nodes'])(Flatten()(var_xy))
+        var_xy = Dense(self.dense_width * self.dense_width * self.dense_filters)(var_xy)
+        var_xy = Reshape((self.dense_width, self.dense_width, self.dense_filters))(var_xy)
+        var_xy = self.blocks.upscale(var_xy, self.dense_filters)
+
+        var_x = var_xy
+        var_x = self.blocks.res_block(var_x, self.dense_filters, use_bias=False)
+
+        decoder_b_complexity = self.config['complexity_decoder']
+        for idx in range(self.upscalers_no - 2):
+            var_x = self.blocks.upscale(var_x, decoder_b_complexity // 2**idx)
+            var_x = self.blocks.res_block(var_x, decoder_b_complexity // 2**idx, use_bias=False)
+            var_x = self.blocks.res_block(var_x, decoder_b_complexity // 2**idx, use_bias=True)
+        var_x = self.blocks.upscale(var_x, decoder_b_complexity // 2**(idx + 1))
+
+        var_x = Conv2D(3, kernel_size=5, padding="same", activation="sigmoid")(var_x)
+
+        outputs = [var_x]
+
+        if self.config.get("mask_type", None) is not None:
+            var_y = var_xy
+            mask_b_complexity = 384
+            for idx in range(self.upscalers_no-2):
+                var_y = self.blocks.upscale(var_y, mask_b_complexity // 2**idx)
+            var_y = self.blocks.upscale(var_y, mask_b_complexity // 2**(idx + 1))
+
+            var_y = Conv2D(1, kernel_size=5, padding='same', activation='sigmoid')(var_y)
+
+            outputs += [var_y]
+
+        return KerasModel(input_, outputs=outputs)
+
+    def decoder_a(self):
+        """ RealFace Decoder (A) Network """
+        input_width = self.config['input_size'] // self._downscale_ratio
+        input_ = Input(shape=(input_width, input_width, 1024))
+
+        var_xy = input_
+
+        dense_nodes = int(self.config['dense_nodes']/1.5)
+        dense_filters = int(self.dense_filters/1.5)
+
+        var_xy = Dense(dense_nodes)(Flatten()(var_xy))
+        var_xy = Dense(self.dense_width * self.dense_width * dense_filters)(var_xy)
+        var_xy = Reshape((self.dense_width, self.dense_width, dense_filters))(var_xy)
+
+        var_xy = self.blocks.upscale(var_xy, dense_filters)
+
+        var_x = var_xy
+        var_x = self.blocks.res_block(var_x, dense_filters, use_bias=False)
+
+        decoder_a_complexity = int(self.config['complexity_decoder'] / 1.5)
+        for idx in range(self.upscalers_no-2):
+            var_x = self.blocks.upscale(var_x, decoder_a_complexity // 2**idx)
+        var_x = self.blocks.upscale(var_x, decoder_a_complexity // 2**(idx + 1))
+
+        var_x = Conv2D(3, kernel_size=5, padding="same", activation="sigmoid")(var_x)
+
+        outputs = [var_x]
+
+        if self.config.get("mask_type", None) is not None:
+            var_y = var_xy
+            mask_a_complexity = 384
+            for idx in range(self.upscalers_no-2):
+                var_y = self.blocks.upscale(var_y, mask_a_complexity // 2**idx)
+            var_y = self.blocks.upscale(var_y, mask_a_complexity // 2**(idx + 1))
+
+            var_y = Conv2D(1, kernel_size=5, padding='same', activation='sigmoid')(var_y)
+
+            outputs += [var_y]
+
+        return KerasModel(input_, outputs=outputs)
