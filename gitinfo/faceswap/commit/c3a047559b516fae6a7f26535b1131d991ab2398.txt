commit c3a047559b516fae6a7f26535b1131d991ab2398
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Mon Apr 23 14:57:08 2018 +0100

    cli/scripts Refactor (#367)
    
    * Refactor for PEP 8 and split process function
    
    * Remove backwards compatibility for skip frames
    
    * Split optional functions into own class. Make functions more modular
    
    * Conform scripts folder to PEP 8
    
    * train.py - Fix write image bug. Make more modular
    
    * extract.py - Make more modular, Put optional actions into own class
    
    * cli.py - start PEP 8
    
    * cli,py - Pep 8. Refactor and make modular. Bugfixes
    
    * 1st round refactor. Completely untested and probably broken.
    
    * convert.py: Extract alignments from frames if they don't exist
    
    * BugFix: SkipExisting broken since face name refactor
    
    * Extract.py tested
    
    * Minor formatting
    
    * convert.py + train.py amended not tested
    
    * train.py - Semi-fix for hang on reaching target iteration. Now quits on preview mode
    Make tensorflow / system warning less verbose
    
    * 2nd pass refactor. Semi tested
    
    bugfixes
    
    * Remove obsolete code. imread/write to Utils
    
    * rename inout.py to fsmedia.py
    
    * Final bugfixes

diff --git a/faceswap.py b/faceswap.py
index f6df460..0519928 100755
--- a/faceswap.py
+++ b/faceswap.py
@@ -1,33 +1,32 @@
 #!/usr/bin/env python3
+""" The master faceswap.py script """
 import sys
+
+import lib.cli as cli
+
 if  sys.version_info[0] < 3:
     raise Exception("This program requires at least python3.2")
 if sys.version_info[0] == 3 and sys.version_info[1] < 2:
     raise Exception("This program requires at least python3.2")
 
-from lib.cli import FullHelpArgumentParser
-
-from scripts.extract import ExtractTrainingData
-from scripts.train import TrainingProcessor
-from scripts.convert import ConvertImage
-from scripts.gui import TKGui
 
 def bad_args(args):
-    parser.print_help()
+    """ Print help on bad arguments """
+    PARSER.print_help()
     exit(0)
 
 if __name__ == "__main__":
-    parser = FullHelpArgumentParser()
-    subparser = parser.add_subparsers()
-    extract = ExtractTrainingData(
-        subparser, "extract", "Extract the faces from a pictures.")
-    train = TrainingProcessor(
-        subparser, "train", "This command trains the model for the two faces A and B.")
-    convert = ConvertImage(
-        subparser, "convert", "Convert a source image to a new one with the face swapped.")
-    guiparsers = {'extract': extract, 'train': train, 'convert': convert}
-    gui = TKGui(
-        subparser, guiparsers, "gui", "Launch the Faceswap Graphical User Interface.")
-    parser.set_defaults(func=bad_args)
-    arguments = parser.parse_args()
-    arguments.func(arguments)
+    PARSER = cli.FullHelpArgumentParser()
+    SUBPARSER = PARSER.add_subparsers()
+    EXTRACT = cli.ExtractArgs(
+        SUBPARSER, "extract", "Extract the faces from pictures")
+    TRAIN = cli.TrainArgs(
+        SUBPARSER, "train", "This command trains the model for the two faces A and B")
+    CONVERT = cli.ConvertArgs(
+        SUBPARSER, "convert", "Convert a source image to a new one with the face swapped")
+    GUIPARSERS = {'extract': EXTRACT, 'train': TRAIN, 'convert': CONVERT}
+    GUI = cli.GuiArgs(
+        SUBPARSER, "gui", "Launch the Faceswap Graphical User Interface", GUIPARSERS)
+    PARSER.set_defaults(func=bad_args)
+    ARGUMENTS = PARSER.parse_args()
+    ARGUMENTS.func(ARGUMENTS)
diff --git a/lib/cli.py b/lib/cli.py
index 7a36a08..bdea9d4 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -1,311 +1,423 @@
+#!/usr/bin python3
+""" Command Line Arguments """
+
 import argparse
 import os
 import sys
-import time
-
-from pathlib import Path
-from lib.utils import get_image_paths, get_folder, rotate_image
-from lib import Serializer
 
-# DLIB is a GPU Memory hog, so the following modules should only be imported when required
-detect_faces = None
-DetectedFace = None
-FaceFilter = None
-
-def import_faces_detect():
-    ''' Import the faces_detect module only when it is required '''
-    global detect_faces
-    global DetectedFace
-    if detect_faces is None or DetectedFace is None:
-        import lib.faces_detect 
-        detect_faces = lib.faces_detect.detect_faces
-        DetectedFace = lib.faces_detect.DetectedFace
+from plugins.PluginLoader import PluginLoader
+
+class ScriptExecutor(object):
+    """ Loads the relevant script modules and executes the script.
+        This class is initialised in each of the argparsers for the relevant command,
+        then execute script is called within their set_default function """
+
+    def __init__(self, command, subparsers=None):
+        self.command = command.lower()
+        self.subparsers = subparsers
+
+    def import_script(self):
+        """ Only import a script's modules when running that script."""
+        if self.command == 'extract':
+            from scripts.extract import Extract as script
+        elif self.command == 'train':
+            from scripts.train import Train as script
+        elif self.command == 'convert':
+            from scripts.convert import Convert as script
+        elif self.command == 'gui':
+            from scripts.gui import Gui as script
+        else:
+            script = None
+        return script
 
-def import_FaceFilter():
-    ''' Import the FaceFilter module only when it is required '''
-    global FaceFilter
-    if FaceFilter is None:
-        import lib.FaceFilter
-        FaceFilter = lib.FaceFilter.FaceFilter
+    def execute_script(self, arguments):
+        """ Run the script for called command """
+        script = self.import_script()
+        args = (arguments, ) if self.command != 'gui' else (arguments, self.subparsers)
+        process = script(*args)
+        process.process()
 
 class FullPaths(argparse.Action):
     """Expand user- and relative-paths"""
-
     def __call__(self, parser, namespace, values, option_string=None):
         setattr(namespace, self.dest, os.path.abspath(
             os.path.expanduser(values)))
 
 class FullHelpArgumentParser(argparse.ArgumentParser):
-    """
-    Identical to the built-in argument parser, but on error
-    it prints full help message instead of just usage information
-    """
+    """ Identical to the built-in argument parser, but on error it
+        prints full help message instead of just usage information """
     def error(self, message):
         self.print_help(sys.stderr)
-        args = {'prog': self.prog, 'message': message}
-        self.exit(2, '%(prog)s: error: %(message)s\n' % args)
-
-class DirectoryProcessor(object):
-    '''
-    Abstract class that processes a directory of images
-    and writes output to the specified folder
-    '''
-    arguments = None
-    parser = None
-
-    input_dir = None
-    output_dir = None
-
-    images_found = 0
-    num_faces_detected = 0
-    faces_detected = dict()
-    verify_output = False
-    rotation_angles = None
-
-    def __init__(self, subparser, command, description='default'):
+        args = {"prog": self.prog, "message": message}
+        self.exit(2, "%(prog)s: error: %(message)s\n" % args)
+
+class FaceSwapArgs(object):
+    """ Faceswap argument parser functions that are universal
+        to all commands. Should be the parent function of all
+        subsequent argparsers """
+    def __init__(self, subparser, command, description="default", subparsers=None):
         self.argument_list = self.get_argument_list()
         self.optional_arguments = self.get_optional_arguments()
-        self.create_parser(subparser, command, description)
-        self.parse_arguments(description, subparser, command)
+        self.parser = self.create_parser(subparser, command, description)
+
+        self.add_arguments()
+
+        script = ScriptExecutor(command, subparsers)
+        self.parser.set_defaults(func=script.execute_script)
 
     @staticmethod
     def get_argument_list():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
+        """ Put the arguments in a list so that they are accessible from both argparse and gui
+            overide for command specific arguments """
         argument_list = []
-        argument_list.append({ "opts": ('-i', '--input-dir'),
-                               "action": FullPaths,
-                               "dest": "input_dir",
-                               "default": "input",
-                               "help": "Input directory. A directory containing the files \
-                                you wish to process. Defaults to 'input'"})
-        argument_list.append({ "opts": ('-o', '--output-dir'),
-                               "action": FullPaths,
-                               "dest": "output_dir",
-                               "default": "output",
-                               "help": "Output directory. This is where the converted files will \
-                                be stored. Defaults to 'output'"})
-        argument_list.append({ "opts": ('--serializer', ),
-                               "type": str.lower,
-                               "dest": "serializer",
-                               "choices": ("yaml", "json", "pickle"),
-                               "help": "serializer for alignments file"})
-        argument_list.append({ "opts": ('--alignments', ),
-                               "type": str,
-                               "dest": "alignments_path",
-                               "help": "optional path to alignments file."})
-        argument_list.append({ "opts": ('-v', '--verbose'),
-                               "action": "store_true",
-                               "dest": "verbose",
-                               "default": False,
-                               "help": "Show verbose output"})
         return argument_list
 
     @staticmethod
     def get_optional_arguments():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
-        # Override this for custom arguments
+        """ Put the arguments in a list so that they are accessible from both argparse and gui
+            This is used for when there are sub-children (e.g. convert and extract)
+            Override this for custom arguments """
         argument_list = []
         return argument_list
 
-    def process_arguments(self, arguments):
-        self.arguments = arguments
-        print("Input Directory: {}".format(self.arguments.input_dir))
-        print("Output Directory: {}".format(self.arguments.output_dir))
-        print("Filter: {}".format(self.arguments.filter))
-        self.serializer = None
-        if self.arguments.serializer is None and self.arguments.alignments_path is not None:
-            ext = os.path.splitext(self.arguments.alignments_path)[-1]
-            self.serializer = Serializer.get_serializer_fromext(ext)
-            print(self.serializer, self.arguments.alignments_path)
-        else:
-            self.serializer = Serializer.get_serializer(self.arguments.serializer or "json")
-        print("Using {} serializer".format(self.serializer.ext))
-
-        try:
-            if self.arguments.rotate_images is not None and self.arguments.rotate_images != "off":
-                if self.arguments.rotate_images == "on":
-                    self.rotation_angles = range(90, 360, 90)
-                else:
-                    rotation_angles = [int(angle) for angle in self.arguments.rotate_images.split(",")]
-                    if len(rotation_angles) == 1:
-                        rotation_step_size = rotation_angles[0]
-                        self.rotation_angles = range(rotation_step_size, 360, rotation_step_size)
-                    elif len(rotation_angles) > 1:
-                        self.rotation_angles = rotation_angles
-        except AttributeError:
-            pass
-
-        print('Starting, this may take a while...')
-
-        try:
-            if self.arguments.skip_existing:
-                self.already_processed = get_image_paths(self.arguments.output_dir)
-        except AttributeError:
-            pass
-    
-        self.output_dir = get_folder(self.arguments.output_dir)
-
-        try:
-            try:
-                if self.arguments.skip_existing:
-                    self.input_dir = get_image_paths(self.arguments.input_dir, self.already_processed)
-                    print('Excluding %s files' % len(self.already_processed))
-                else:
-                    self.input_dir = get_image_paths(self.arguments.input_dir)
-            except AttributeError:
-                self.input_dir = get_image_paths(self.arguments.input_dir)
-        except:
-            print('Input directory not found. Please ensure it exists.')
-            exit(1)
-
-        self.filter = self.load_filter()
-        self.process()
-        self.finalize()
-
-    def read_alignments(self):
-
-        fn = os.path.join(str(self.arguments.input_dir),"alignments.{}".format(self.serializer.ext))
-        if self.arguments.alignments_path is not None:
-            fn = self.arguments.alignments_path
-
-        try:
-            print("Reading alignments from: {}".format(fn))
-            with open(fn, self.serializer.roptions) as f:
-                self.faces_detected = self.serializer.unmarshal(f.read())
-        except Exception as e:
-            print("{} not read!".format(fn))
-            print(str(e))
-            self.faces_detected = dict()
-
-    def write_alignments(self):
-
-        fn = os.path.join(str(self.arguments.input_dir), "alignments.{}".format(self.serializer.ext))
-        if self.arguments.alignments_path is not None:
-            fn = self.arguments.alignments_path
-        print("Alignments filepath: %s" % fn)
-        
-        if self.arguments.skip_existing:
-            if os.path.exists(fn):
-                with open(fn, self.serializer.roptions) as inf:
-                    data = self.serializer.unmarshal(inf.read())
-                    for k, v in data.items():
-                        self.faces_detected[k] = v
-            else:
-                print('Existing alignments file "%s" not found.' % fn)
-        try:
-            print("Writing alignments to: {}".format(fn))
-            with open(fn, self.serializer.woptions) as fh:
-                fh.write(self.serializer.marshal(self.faces_detected))
-        except Exception as e:
-            print("{} not written!".format(fn))
-            print(str(e))
-            self.faces_detected = dict()
-
-    def read_directory(self):
-        self.images_found = len(self.input_dir)
-        return self.input_dir
-
-    def have_face(self, filename):
-        return os.path.basename(filename) in self.faces_detected
-
-    def have_alignments(self):
-        fn = os.path.join(str(self.arguments.input_dir), "alignments.{}".format(self.serializer.ext))
-        return os.path.exists(fn)
+    @staticmethod
+    def create_parser(subparser, command, description):
+        """ Create the parser for the selected command """
+        parser = subparser.add_parser(
+            command,
+            help=description,
+            description=description,
+            epilog="Questions and feedback: \
+            https://github.com/deepfakes/faceswap-playground")
+        return parser
 
-    def get_faces_alignments(self, filename, image):
-        import_faces_detect()
-        faces_count = 0
-        faces = self.faces_detected[os.path.basename(filename)]
-        for rawface in faces:
-            face = DetectedFace(**rawface)
-            # Rotate the image if necessary
-            if face.r != 0: image = rotate_image(image, face.r)
-            face.image = image[face.y : face.y + face.h, face.x : face.x + face.w]
-            if self.filter is not None and not self.filter.check(face):
-                if self.arguments.verbose:
-                    print('Skipping not recognized face!')
-                continue
+    def add_arguments(self):
+        """ Parse the arguments passed in from argparse """
+        for option in self.argument_list + self.optional_arguments:
+            args = option["opts"]
+            kwargs = {key: option[key] for key in option.keys() if key != "opts"}
+            self.parser.add_argument(*args, **kwargs)
 
-            yield faces_count, face
-            self.num_faces_detected += 1
-            faces_count += 1
-        if faces_count > 1 and self.arguments.verbose:
-            print('Note: Found more than one face in an image! File: %s' % filename)
-            self.verify_output = True
 
-    def get_faces(self, image, rotation=0):
-        import_faces_detect()
-        faces_count = 0
-        faces = detect_faces(image, self.arguments.detector, self.arguments.verbose, rotation)
-        
-        for face in faces:
-            if self.filter is not None and not self.filter.check(face):
-                if self.arguments.verbose:
-                    print('Skipping not recognized face!')
-                continue
-            yield faces_count, face
+class ExtractConvertArgs(FaceSwapArgs):
+    """ This class is used as a parent class to capture arguments that
+        will be used in both the extract and convert process.
 
-            self.num_faces_detected += 1
-            faces_count += 1
+        Arguments that can be used in both of these processes should be
+        placed here, but no further processing should be done. This class
+        just captures arguments """
 
-        if faces_count > 1 and self.arguments.verbose:
-            self.verify_output = True
+    @staticmethod
+    def get_argument_list():
+        """ Put the arguments in a list so that they are accessible from both argparse and gui """
+        argument_list = []
+        argument_list.append({"opts": ("-i", "--input-dir"),
+                              "action": FullPaths,
+                              "dest": "input_dir",
+                              "default": "input",
+                              "help": "Input directory. A directory containing the files "
+                                      "you wish to process. Defaults to 'input'"})
+        argument_list.append({"opts": ("-o", "--output-dir"),
+                              "action": FullPaths,
+                              "dest": "output_dir",
+                              "default": "output",
+                              "help": "Output directory. This is where the converted files will "
+                                      "be stored. Defaults to 'output'"})
+        argument_list.append({"opts": ("--alignments", ),
+                              "type": str,
+                              "dest": "alignments_path",
+                              "help": "optional path to alignments file"})
+        argument_list.append({"opts": ("--serializer", ),
+                              "type": str.lower,
+                              "dest": "serializer",
+                              "choices": ("yaml", "json", "pickle"),
+                              "help": "serializer for alignments file"})
+        argument_list.append({"opts": ("-D", "--detector"),
+                              "type": str,
+                              # case sensitive because this is used to load a plugin.
+                              "choices": ("hog", "cnn"),
+                              "default": "hog",
+                              "help": "Detector to use. 'cnn' detects many more angles but "
+                                      "will be much more resource intensive and may fail "
+                                      "on large files"})
+        argument_list.append({"opts": ("-l", "--ref_threshold"),
+                              "type": float,
+                              "dest": "ref_threshold",
+                              "default": 0.6,
+                              "help": "Threshold for positive face recognition"})
+        argument_list.append({"opts": ("-n", "--nfilter"),
+                              "type": str,
+                              "dest": "nfilter",
+                              "nargs": "+",
+                              "default": None,
+                              "help": "Reference image for the persons you do not want to "
+                                      "process. Should be a front portrait. Multiple images"
+                                      "can be added space separated"})
+        argument_list.append({"opts": ("-f", "--filter"),
+                              "type": str,
+                              "dest": "filter",
+                              "nargs": "+",
+                              "default": None,
+                              "help": "Reference images for the person you want to process. "
+                                      "Should be a front portrait. Multiple images"
+                                      "can be added space separated"})
+        argument_list.append({"opts": ("-v", "--verbose"),
+                              "action": "store_true",
+                              "dest": "verbose",
+                              "default": False,
+                              "help": "Show verbose output"})
+        return argument_list
 
-    def load_filter(self):
-        nfilter_files = self.arguments.nfilter
-        if not isinstance(self.arguments.nfilter, list):
-            nfilter_files = [self.arguments.nfilter]
-        nfilter_files = list(filter(lambda fn: Path(fn).exists(), nfilter_files))
+class ExtractArgs(ExtractConvertArgs):
+    """ Class to parse the command line arguments for extraction.
+        Inherits base options from ExtractConvertArgs where arguments
+        that are used for both extract and convert should be placed """
 
-        filter_files = self.arguments.filter
-        if not isinstance(self.arguments.filter, list):
-            filter_files = [self.arguments.filter]
-        filter_files = list(filter(lambda fn: Path(fn).exists(), filter_files))
-        
-        if filter_files:
-            import_FaceFilter()
-            print('Loading reference images for filtering: %s' % filter_files)
-            return FaceFilter(filter_files, nfilter_files, self.arguments.ref_threshold)
+    @staticmethod
+    def get_optional_arguments():
+        """ Put the arguments in a list so that they are accessible from both argparse and gui """
+        argument_list = []
+        argument_list.append({"opts": ("-r", "--rotate-images"),
+                              "type": str,
+                              "dest": "rotate_images",
+                              "default": None,
+                              "help": "If a face isn't found, rotate the images to try to "
+                                      "find a face. Can find more faces at the cost of extraction "
+                                      "speed. Pass in a single number to use increments of that "
+                                      "size up to 360, or pass in a list of numbers to enumerate "
+                                      "exactly what angles to check"})
+        argument_list.append({"opts": ("-bt", "--blur-threshold"),
+                              "type": int,
+                              "dest": "blur_thresh",
+                              "default": None,
+                              "help": "Automatically discard images blurrier than the specified "
+                                      "threshold. Discarded images are moved into a \"blurry\" "
+                                      "sub-folder. Lower values allow more blur"})
+        argument_list.append({"opts": ("-j", "--processes"),
+                              "type": int,
+                              "default": 1,
+                              "help": "Number of CPU processes to use. WARNING: ONLY USE THIS "
+                                      " IF YOU ARE NOT EXTRACTING ON A GPU. Anything above 1 "
+                                      " process on a GPU will run out of memory and will crash"})
+        argument_list.append({"opts": ("-s", "--skip-existing"),
+                              "action": "store_true",
+                              "dest": "skip_existing",
+                              "default": False,
+                              "help": "Skips frames that have already been extracted"})
+        argument_list.append({"opts": ("-dl", "--debug-landmarks"),
+                              "action": "store_true",
+                              "dest": "debug_landmarks",
+                              "default": False,
+                              "help": "Draw landmarks on the ouput faces for debug"})
+        argument_list.append({"opts": ("-ae", "--align-eyes"),
+                              "action": "store_true",
+                              "dest": "align_eyes",
+                              "default": False,
+                              "help": "Perform extra alignment to ensure left/right eyes "
+                                      "are  at the same height"})
+        return argument_list
 
-    # for now, we limit this class responsability to the read of files. images and faces are processed outside this class
-    def process(self):
-        # implement your image processing!
-        raise NotImplementedError()
+class ConvertArgs(ExtractConvertArgs):
+    """ Class to parse the command line arguments for conversion.
+        Inherits base options from ExtractConvertArgs where arguments
+        that are used for both extract and convert should be placed """
 
-    def parse_arguments(self, description, subparser, command):
-        for option in self.argument_list:
-            args = option['opts']
-            kwargs = {key: option[key] for key in option.keys() if key != 'opts'}
-            self.parser.add_argument(*args, **kwargs)
-        
-        self.parser = self.add_optional_arguments(self.parser)
-        self.parser.set_defaults(func=self.process_arguments)
+    @staticmethod
+    def get_optional_arguments():
+        """ Put the arguments in a list so that they are accessible from both argparse and gui """
+        argument_list = []
+        argument_list.append({"opts": ("-m", "--model-dir"),
+                              "action": FullPaths,
+                              "dest": "model_dir",
+                              "default": "models",
+                              "help": "Model directory. A directory containing the trained model "
+                                      "you wish to process. Defaults to 'models'"})
+        argument_list.append({"opts": ("-a", "--input-aligned-dir"),
+                              "action": FullPaths,
+                              "dest": "input_aligned_dir",
+                              "default": None,
+                              "help": "Input \"aligned directory\". A directory that should "
+                                      "contain the aligned faces extracted from the input files. "
+                                      "If you delete faces from this folder, they'll be skipped "
+                                      "during conversion. If no aligned dir is specified, all "
+                                      "faces will be converted"})
+        argument_list.append({"opts": ("-t", "--trainer"),
+                              "type": str,
+                              # case sensitive because this is used to load a plug-in.
+                              "choices": PluginLoader.get_available_models(),
+                              "default": PluginLoader.get_default_model(),
+                              "help": "Select the trainer that was used to create the model"})
+        argument_list.append({"opts": ("-c", "--converter"),
+                              "type": str,
+                              # case sensitive because this is used to load a plugin.
+                              "choices": ("Masked", "Adjust"),
+                              "default": "Masked",
+                              "help": "Converter to use"})
+        argument_list.append({"opts": ("-b", "--blur-size"),
+                              "type": int,
+                              "default": 2,
+                              "help": "Blur size. (Masked converter only)"})
+        argument_list.append({"opts": ("-e", "--erosion-kernel-size"),
+                              "dest": "erosion_kernel_size",
+                              "type": int,
+                              "default": None,
+                              "help": "Erosion kernel size. Positive values apply erosion "
+                                      "which reduces the edge of the swapped face. Negative "
+                                      "values apply dilation which allows the swapped face "
+                                      "to cover more space. (Masked converter only)"})
+        argument_list.append({"opts": ("-M", "--mask-type"),
+                              #lowercase this, because its just a string later on.
+                              "type": str.lower,
+                              "dest": "mask_type",
+                              "choices": ["rect", "facehull", "facehullandrect"],
+                              "default": "facehullandrect",
+                              "help": "Mask to use to replace faces. (Masked converter only)"})
+        argument_list.append({"opts": ("-sh", "--sharpen"),
+                              "type": str.lower,
+                              "dest": "sharpen_image",
+                              "choices": ["bsharpen", "gsharpen"],
+                              "default": None,
+                              "help": "Use Sharpen Image.bsharpen for Box Blur, gsharpen for "
+                                      "Gaussian Blur (Masked converter only)"})
+        argument_list.append({"opts": ("-g", "--gpus"),
+                              "type": int,
+                              "default": 1,
+                              "help": "Number of GPUs to use for conversion"})
+        argument_list.append({"opts": ("-fr", "--frame-ranges"),
+                              "nargs": "+",
+                              "type": str,
+                              "help": "frame ranges to apply transfer to e.g. For frames 10 to "
+                                      "50 and 90 to 100 use --frame-ranges 10-50 90-100. Files "
+                                      "must have the frame-number as the last number in the "
+                                      "name!"})
+        argument_list.append({"opts": ("-d", "--discard-frames"),
+                              "action": "store_true",
+                              "dest": "discard_frames",
+                              "default": False,
+                              "help": "When used with --frame-ranges discards frames that are "
+                                      "not processed instead of writing them out unchanged"})
+        argument_list.append({"opts": ("-s", "--swap-model"),
+                              "action": "store_true",
+                              "dest": "swap_model",
+                              "default": False,
+                              "help": "Swap the model. Instead of A -> B, swap B -> A"})
+        argument_list.append({"opts": ("-S", "--seamless"),
+                              "action": "store_true",
+                              "dest": "seamless_clone",
+                              "default": False,
+                              "help": "Use cv2's seamless clone. (Masked converter only)"})
+        argument_list.append({"opts": ("-mh", "--match-histgoram"),
+                              "action": "store_true",
+                              "dest": "match_histogram",
+                              "default": False,
+                              "help": "Use histogram matching. (Masked converter only)"})
+        argument_list.append({"opts": ("-sm", "--smooth-mask"),
+                              "action": "store_true",
+                              "dest": "smooth_mask",
+                              "default": True,
+                              "help": "Smooth mask (Adjust converter only)"})
+        argument_list.append({"opts": ("-aca", "--avg-color-adjust"),
+                              "action": "store_true",
+                              "dest": "avg_color_adjust",
+                              "default": True,
+                              "help": "Average color adjust. (Adjust converter only)"})
+        return argument_list
 
-    def create_parser(self, subparser, command, description):
-        parser = subparser.add_parser(
-            command,
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground"
-        )
-        return parser
+class TrainArgs(FaceSwapArgs):
+    """ Class to parse the command line arguments for training """
 
-    def add_optional_arguments(self, parser):
-        for option in self.optional_arguments:
-            args = option['opts']
-            kwargs = {key: option[key] for key in option.keys() if key != 'opts'}
-            parser.add_argument(*args, **kwargs)
-        return parser
+    @staticmethod
+    def get_argument_list():
+        """ Put the arguments in a list so that they are accessible from both argparse and gui """
+        argument_list = []
+        argument_list.append({"opts": ("-A", "--input-A"),
+                              "action": FullPaths,
+                              "dest": "input_A",
+                              "default": "input_A",
+                              "help": "Input directory. A directory containing training images "
+                                      "for face A. Defaults to 'input'"})
+        argument_list.append({"opts": ("-B", "--input-B"),
+                              "action": FullPaths,
+                              "dest": "input_B",
+                              "default": "input_B",
+                              "help": "Input directory. A directory containing training images "
+                                      "for face B Defaults to 'input'"})
+        argument_list.append({"opts": ("-m", "--model-dir"),
+                              "action": FullPaths,
+                              "dest": "model_dir",
+                              "default": "models",
+                              "help": "Model directory. This is where the training data will "
+                                      "be stored. Defaults to 'model'"})
+        argument_list.append({"opts": ("-s", "--save-interval"),
+                              "type": int,
+                              "dest": "save_interval",
+                              "default": 100,
+                              "help": "Sets the number of iterations before saving the model"})
+        argument_list.append({"opts": ("-t", "--trainer"),
+                              "type": str,
+                              "choices": PluginLoader.get_available_models(),
+                              "default": PluginLoader.get_default_model(),
+                              "help": "Select which trainer to use, Use LowMem for cards with "
+                                      " less than 2GB of VRAM"})
+        argument_list.append({"opts": ("-bs", "--batch-size"),
+                              "type": int,
+                              "default": 64,
+                              "help": "Batch size, as a power of 2 (64, 128, 256, etc)"})
+        argument_list.append({"opts": ("-ep", "--epochs"),
+                              "type": int,
+                              "default": 1000000,
+                              "help": "Length of training in epochs"})
+        argument_list.append({"opts": ("-g", "--gpus"),
+                              "type": int,
+                              "default": 1,
+                              "help": "Number of GPUs to use for training"})
+        argument_list.append({"opts": ("-p", "--preview"),
+                              "action": "store_true",
+                              "dest": "preview",
+                              "default": False,
+                              "help": "Show preview output. If not specified, write progress "
+                                      "to file"})
+        argument_list.append({"opts": ("-w", "--write-image"),
+                              "action": "store_true",
+                              "dest": "write_image",
+                              "default": False,
+                              "help": "Writes the training result to a file even on "
+                                      "preview mode"})
+        argument_list.append({"opts": ("-pl", "--use-perceptual-loss"),
+                              "action": "store_true",
+                              "dest": "perceptual_loss",
+                              "default": False,
+                              "help": "Use perceptual loss while training"})
+        argument_list.append({"opts": ("-ag", "--allow-growth"),
+                              "action": "store_true",
+                              "dest": "allow_growth",
+                              "default": False,
+                              "help": "Sets allow_growth option of Tensorflow to spare memory "
+                                      "on some configs"})
+        argument_list.append({"opts": ("-v", "--verbose"),
+                              "action": "store_true",
+                              "dest": "verbose",
+                              "default": False,
+                              "help": "Show verbose output"})
+        # This is a hidden argument to indicate that the GUI is being used,
+        # so the preview window should be redirected Accordingly
+        argument_list.append({"opts": ("-gui", "--gui"),
+                              "action": "store_true",
+                              "dest": "redirect_gui",
+                              "default": False,
+                              "help": argparse.SUPPRESS})
+        return argument_list
 
-    def finalize(self):
-        print('-------------------------')
-        print('Images found:        {}'.format(self.images_found))
-        print('Faces detected:      {}'.format(self.num_faces_detected))
-        print('-------------------------')
+class GuiArgs(FaceSwapArgs):
+    """ Class to parse the command line arguments for training """
 
-        if self.verify_output:
-            print('Note:')
-            print('Multiple faces were detected in one or more pictures.')
-            print('Double check your results.')
-            print('-------------------------')
-        print('Done!')
+    @staticmethod
+    def get_argument_list():
+        """ Put the arguments in a list so that they are accessible from both argparse and gui """
+        argument_list = []
+        argument_list.append({"opts": ("-d", "--debug"),
+                              "action": "store_true",
+                              "dest": "debug",
+                              "default": False,
+                              "help": "Output to Shell console instead of GUI console"})
+        return argument_list
diff --git a/lib/utils.py b/lib/utils.py
index 2bbfda5..09f71ac 100644
--- a/lib/utils.py
+++ b/lib/utils.py
@@ -1,34 +1,38 @@
-import cv2
-import sys
-from os.path import basename, exists, join
+#!/usr/bin python3
+""" Utilities available across all scripts """
 
-from pathlib import Path
-from scandir import scandir
 import os
+from os.path import basename, exists, join
+import queue as Queue
+import threading
+import warnings
 
-image_extensions = [".jpg", ".jpeg", ".png", ".tif", ".tiff"]
+from pathlib import Path
 
 def get_folder(path):
+    """ Return a path to a folder, creating it if it doesn't exist """
     output_dir = Path(path)
     output_dir.mkdir(parents=True, exist_ok=True)
     return output_dir
 
-def get_image_paths(directory, exclude=[], debug=False):
-    exclude_names = [basename(Path(x).stem[:-1] + Path(x).suffix) for x in exclude]
-    dir_contents = []
+def get_image_paths(directory, exclude=list(), debug=False):
+    """ Return a list of images that reside in a folder """
+    image_extensions = [".jpg", ".jpeg", ".png", ".tif", ".tiff"]
+    exclude_names = [basename(Path(x).stem[:-2] + Path(x).suffix) for x in exclude]
+    dir_contents = list()
 
     if not exists(directory):
-        directory = get_folder(directory).path
+        directory = get_folder(directory)
 
     dir_scanned = sorted(os.scandir(directory), key=lambda x: x.name)
-    for x in dir_scanned:
-        if any([x.name.lower().endswith(ext) for ext in image_extensions]):
-            if x.name in exclude_names:
+    for chkfile in dir_scanned:
+        if any([chkfile.name.lower().endswith(ext) for ext in image_extensions]):
+            if chkfile.name in exclude_names:
                 if debug:
-                    print("Already processed %s" % x.name)
+                    print("Already processed %s" % chkfile.name)
                 continue
             else:
-                dir_contents.append(x.path)
+                dir_contents.append(chkfile.path)
 
     return dir_contents
 
@@ -41,26 +45,26 @@ def backup_file(directory, filename):
     if exists(origfile):
         os.rename(origfile, backupfile)
 
-# From: https://stackoverflow.com/questions/22041699/rotate-an-image-without-cropping-in-opencv-in-c
-def rotate_image(image, angle, rotated_width=None, rotated_height=None):
-    height, width = image.shape[:2]
-    image_center = (width/2, height/2)
-    rotation_matrix = cv2.getRotationMatrix2D(image_center, -1.*angle, 1.)
-    if rotated_width is None or rotated_height is None:
-        abs_cos = abs(rotation_matrix[0, 0])
-        abs_sin = abs(rotation_matrix[0, 1])
-        if rotated_width is None:
-            rotated_width = int(height*abs_sin + width*abs_cos)
-        if rotated_height is None:
-            rotated_height = int(height*abs_cos + width*abs_sin)
-    rotation_matrix[0, 2] += rotated_width/2 - image_center[0]
-    rotation_matrix[1, 2] += rotated_height/2 - image_center[1]
-    return cv2.warpAffine(image, rotation_matrix, (rotated_width, rotated_height))
+def set_system_verbosity(loglevel):
+    """ Set the verbosity level of tensorflow and suppresses
+        future and deprecation warnings from any modules
+        From:
+        https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information
+        Can be set to:
+        0 - all logs shown
+        1 - filter out INFO logs
+        2 - filter out WARNING logs
+        3 - filter out ERROR logs  """
+    # TODO suppress tensorflow deprecation warnings """
+
+    os.environ['TF_CPP_MIN_LOG_LEVEL'] = loglevel
+    if loglevel != '0':
+        for warncat in (FutureWarning, DeprecationWarning):
+            warnings.simplefilter(action='ignore', category=warncat)
 
-# From: https://stackoverflow.com/questions/7323664/python-generator-pre-fetch
-import threading
-import queue as Queue
 class BackgroundGenerator(threading.Thread):
+    """ Run a queue in the background. From:
+        https://stackoverflow.com/questions/7323664/python-generator-pre-fetch """
     def __init__(self, generator, prefetch=1): #See below why prefetch count is flawed
         threading.Thread.__init__(self)
         self.queue = Queue.Queue(prefetch)
@@ -69,13 +73,15 @@ class BackgroundGenerator(threading.Thread):
         self.start()
 
     def run(self):
-        # Put until queue size is reached. Note: put blocks only if put is called while queue has already reached max size
-        # => this makes 2 prefetched items! One in the queue, one waiting for insertion!
+        """ Put until queue size is reached.
+            Note: put blocks only if put is called while queue has already reached max size
+            => this makes 2 prefetched items! One in the queue, one waiting for insertion! """
         for item in self.generator:
             self.queue.put(item)
         self.queue.put(None)
 
     def iterator(self):
+        """ Iterate items out of the queue """
         while True:
             next_item = self.queue.get()
             if next_item is None:
diff --git a/scripts/convert.py b/scripts/convert.py
index ac85fc3..5ec0b40 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -1,251 +1,206 @@
-import cv2
+#!/usr/bin python3
+""" The script to run the convert process of faceswap """
+
 import re
 import os
-
 from pathlib import Path
+
 from tqdm import tqdm
 
-from lib.cli import DirectoryProcessor, FullPaths
-from lib.utils import BackgroundGenerator, get_folder, get_image_paths, rotate_image
+from scripts.fsmedia import Alignments, Images, Faces, Utils
+from scripts.extract import Extract
+from lib.utils import BackgroundGenerator, get_folder, get_image_paths
 
 from plugins.PluginLoader import PluginLoader
 
-class ConvertImage(DirectoryProcessor):
-    filename = ''
-    def create_parser(self, subparser, command, description):
-        self.optional_arguments = self.get_optional_arguments()
-        self.parser = subparser.add_parser(
-            command,
-            help="Convert a source image to a new one with the face swapped.",
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground"
-        )
-
-    @staticmethod
-    def get_optional_arguments():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
-        argument_list = []
-        argument_list.append({ "opts": ('-m', '--model-dir'),
-                               "action": FullPaths,
-                               "dest": "model_dir",
-                               "default": "models",
-                               "help": "Model directory. A directory containing the trained model \
-                               you wish to process. Defaults to 'models'"})
-        argument_list.append({ "opts": ('-a', '--input-aligned-dir'),
-                               "action": FullPaths,
-                               "dest": "input_aligned_dir",
-                               "default": None,
-                               "help": "Input \"aligned directory\". A directory that should contain the \
-                               aligned faces extracted from the input files. If you delete faces from \
-                               this folder, they'll be skipped during conversion. If no aligned dir is \
-                               specified, all faces will be converted."})
-        argument_list.append({ "opts": ('-t', '--trainer'),
-                               "type": str,
-                               "choices": PluginLoader.get_available_models(), # case sensitive because this is used to load a plug-in.
-                               "default": PluginLoader.get_default_model(),
-                               "help": "Select the trainer that was used to create the model."})
-        argument_list.append({ "opts": ('-s', '--swap-model'),
-                               "action": "store_true",
-                               "dest": "swap_model",
-                               "default": False,
-                               "help": "Swap the model. Instead of A -> B, swap B -> A."})
-        argument_list.append({ "opts": ('-c', '--converter'),
-                               "type": str,
-                               "choices": ("Masked", "Adjust"), # case sensitive because this is used to load a plugin.
-                               "default": "Masked",
-                               "help": "Converter to use."})
-        argument_list.append({ "opts": ('-D', '--detector'),
-                               "type": str,
-                               "choices": ("hog", "cnn"), # case sensitive because this is used to load a plugin.
-                               "default": "hog",
-                               "help": "Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files."})
-        argument_list.append({ "opts": ('-fr', '--frame-ranges'),
-                               "nargs": "+",
-                               "type": str,
-                               "help": "frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 use --frame-ranges 10-50 90-100. \
-                               Files must have the frame-number as the last number in the name!"})
-        argument_list.append({ "opts": ('-d', '--discard-frames'),
-                               "action": "store_true",
-                               "dest": "discard_frames",
-                               "default": False,
-                               "help": "When used with --frame-ranges discards frames that are not processed instead of writing them out unchanged."})
-        argument_list.append({ "opts": ('-l', '--ref_threshold'),
-                               "type": float,
-                               "dest": "ref_threshold",
-                               "default": 0.6,
-                               "help": "Threshold for positive face recognition"})
-        argument_list.append({ "opts": ('-n', '--nfilter'),
-                               "type": str,
-                               "dest": "nfilter",
-                               "nargs": '+',
-                               "default": "nfilter.jpg",
-                               "help": "Reference image for the persons you do not want to process. Should be a front portrait"})
-        argument_list.append({ "opts": ('-f', '--filter'),
-                               "type": str,
-                               "dest": "filter",
-                               "nargs": "+",
-                               "default": "filter.jpg",
-                               "help": "Reference images for the person you want to process. Should be a front portrait"})
-        argument_list.append({ "opts": ('-b', '--blur-size'),
-                               "type": int,
-                               "default": 2,
-                               "help": "Blur size. (Masked converter only)"})
-        argument_list.append({ "opts": ('-S', '--seamless'),
-                               "action": "store_true",
-                               "dest": "seamless_clone",
-                               "default": False,
-                               "help": "Use cv2's seamless clone. (Masked converter only)"})
-        argument_list.append({ "opts": ('-M', '--mask-type'),
-                               "type": str.lower, #lowercase this, because its just a string later on.
-                               "dest": "mask_type",
-                               "choices": ["rect", "facehull", "facehullandrect"],
-                               "default": "facehullandrect",
-                               "help": "Mask to use to replace faces. (Masked converter only)"})
-        argument_list.append({ "opts": ('-e', '--erosion-kernel-size'),
-                               "dest": "erosion_kernel_size",
-                               "type": int,
-                               "default": None,
-                               "help": "Erosion kernel size. (Masked converter only). Positive values apply erosion which reduces the edge of the swapped face. Negative values apply dilation which allows the swapped face to cover more space."})
-        argument_list.append({ "opts": ('-mh', '--match-histgoram'),
-                               "action": "store_true",
-                               "dest": "match_histogram",
-                               "default": False,
-                               "help": "Use histogram matching. (Masked converter only)"})
-        argument_list.append({ "opts": ('-sh', ),
-                               "type": str.lower,
-                               "dest": "sharpen_image",
-                               "choices": ["bsharpen", "gsharpen"],
-                               "default": None,
-                               "help": "Use Sharpen Image - bsharpen = Box Blur, gsharpen = Gaussian Blur (Masked converter only)"})
-        argument_list.append({ "opts": ('-sm', '--smooth-mask'),
-                               "action": "store_true",
-                               "dest": "smooth_mask",
-                               "default": True,
-                               "help": "Smooth mask (Adjust converter only)"})
-        argument_list.append({ "opts": ('-aca', '--avg-color-adjust'),
-                               "action": "store_true",
-                               "dest": "avg_color_adjust",
-                               "default": True,
-                               "help": "Average color adjust. (Adjust converter only)"})
-        argument_list.append({ "opts": ('-g', '--gpus'),
-                               "type": int,
-                               "default": 1,
-                               "help": "Number of GPUs to use for conversion"})
-        return argument_list
+class Convert(object):
+    """ The convert process. """
+    def __init__(self, arguments):
+        self.args = arguments
+        self.output_dir = get_folder(self.args.output_dir)
 
-    def process(self):
-        # Original & LowMem models go with Adjust or Masked converter
-        # Note: GAN prediction outputs a mask + an image, while other predicts only an image
-        model_name = self.arguments.trainer
-        conv_name = self.arguments.converter
-        self.input_aligned_dir = None
-
-        model = PluginLoader.get_model(model_name)(get_folder(self.arguments.model_dir), self.arguments.gpus)
-        if not model.load(self.arguments.swap_model):
-            print('Model Not Found! A valid model must be provided to continue!')
-            exit(1)
+        self.images = Images(self.args)
+        self.faces = Faces(self.args)
+        self.alignments = Alignments(self.args)
 
-        input_aligned_dir = Path(self.arguments.input_dir)/Path('aligned')
-        if self.arguments.input_aligned_dir is not None:
-            input_aligned_dir = self.arguments.input_aligned_dir
-        try:
-            self.input_aligned_dir = [Path(path) for path in get_image_paths(input_aligned_dir)]
-            if len(self.input_aligned_dir) == 0:
-                print('Aligned directory is empty, no faces will be converted!')
-            elif len(self.input_aligned_dir) <= len(self.input_dir)/3:
-                print('Aligned directory contains an amount of images much less than the input, are you sure this is the right directory?')
-        except:
-            print('Aligned directory not found. All faces listed in the alignments file will be converted.')
-
-        converter = PluginLoader.get_converter(conv_name)(model.converter(False),
-            trainer=self.arguments.trainer,
-            blur_size=self.arguments.blur_size,
-            seamless_clone=self.arguments.seamless_clone,
-            sharpen_image=self.arguments.sharpen_image,
-            mask_type=self.arguments.mask_type,
-            erosion_kernel_size=self.arguments.erosion_kernel_size,
-            match_histogram=self.arguments.match_histogram,
-            smooth_mask=self.arguments.smooth_mask,
-            avg_color_adjust=self.arguments.avg_color_adjust
-        )
+        self.opts = OptionalActions(self.args, self.images.input_images)
 
-        batch = BackgroundGenerator(self.prepare_images(), 1)
+    def process(self):
+        """ Original & LowMem models go with Adjust or Masked converter
+            Note: GAN prediction outputs a mask + an image, while other predicts only an image """
+        Utils.set_verbosity(self.args.verbose)
 
-        # frame ranges stuff...
-        self.frame_ranges = None
+        if not self.alignments.have_alignments():
+            self.generate_alignments()
 
-        # split out the frame ranges and parse out "min" and "max" values
-        minmax = {
-            "min": 0, # never any frames less than 0
-            "max": float("inf")
-        }
+        self.faces.faces_detected = self.alignments.read_alignments()
 
-        if self.arguments.frame_ranges:
-            self.frame_ranges = [tuple(map(lambda q: minmax[q] if q in minmax.keys() else int(q), v.split("-"))) for v in self.arguments.frame_ranges]
+        model = self.load_model()
+        converter = self.load_converter(model)
 
-        # last number regex. I know regex is hacky, but its reliablyhacky(tm).
-        self.imageidxre = re.compile(r'(\d+)(?!.*\d)')
+        batch = BackgroundGenerator(self.prepare_images(), 1)
 
         for item in batch.iterator():
             self.convert(converter, item)
 
-    def check_skipframe(self, filename):
-        try:
-            idx = int(self.imageidxre.findall(filename)[0])
-            return not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
-        except:
-            return False
+        Utils.finalize(self.images.images_found,
+                       self.faces.num_faces_detected,
+                       self.faces.verify_output)
 
-    def check_skipface(self, filename, face_idx):
-        aligned_face_name = '{}_{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
-        aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(aligned_face_name)
-        # TODO: Remove this temporary fix for backwards compatibility of filenames
-        bk_compat_aligned_face_name = '{}{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
-        bk_compat_aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(bk_compat_aligned_face_name)
-        return aligned_face_file not in self.input_aligned_dir and bk_compat_aligned_face_file not in self.input_aligned_dir
+    def generate_alignments(self):
+        """ Generate an alignments file if one does not already
+        exist. Does not save extracted faces """
+        print('Alignments file not found. Generating at default values...')
+        extract = Extract(self.args)
+        extract.export_face = False
+        extract.process()
 
-    def convert(self, converter, item):
-        try:
-            (filename, image, faces) = item
+    def load_model(self):
+        """ Load the model requested for conversion """
+        model_name = self.args.trainer
+        model_dir = get_folder(self.args.model_dir)
+        num_gpus = self.args.gpus
 
-            skip = self.check_skipframe(filename)
-            if self.arguments.discard_frames and skip:
-                return
+        model = PluginLoader.get_model(model_name)(model_dir, num_gpus)
 
-            if not skip: # process frame as normal
-                for idx, face in faces:
-                    if self.input_aligned_dir is not None and self.check_skipface(filename, idx):
-                        print ('face {} for frame {} was deleted, skipping'.format(idx, os.path.basename(filename)))
-                        continue
-                    # Check for image rotations and rotate before mapping face
-                    if face.r != 0:
-                        height, width = image.shape[:2]
-                        image = rotate_image(image, face.r)
-                        image = converter.patch_image(image, face, 64 if "128" not in self.arguments.trainer else 128)
-                        # TODO: This switch between 64 and 128 is a hack for now. We should have a separate cli option for size
-                        image = rotate_image(image, face.r * -1, rotated_width=width, rotated_height=height)
-                    else:
-                        image = converter.patch_image(image, face, 64 if "128" not in self.arguments.trainer else 128)
-                        # TODO: This switch between 64 and 128 is a hack for now. We should have a separate cli option for size
-
-            output_file = get_folder(self.output_dir) / Path(filename).name
-            cv2.imwrite(str(output_file), image)
-        except Exception as e:
-            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
+        if not model.load(self.args.swap_model):
+            print("Model Not Found! A valid model must be provided to continue!")
+            exit(1)
+
+        return model
+
+    def load_converter(self, model):
+        """ Load the requested converter for conversion """
+        args = self.args
+        conv = args.converter
+
+        converter = PluginLoader.get_converter(conv)(model.converter(False),
+                                                     trainer=args.trainer,
+                                                     blur_size=args.blur_size,
+                                                     seamless_clone=args.seamless_clone,
+                                                     sharpen_image=args.sharpen_image,
+                                                     mask_type=args.mask_type,
+                                                     erosion_kernel_size=args.erosion_kernel_size,
+                                                     match_histogram=args.match_histogram,
+                                                     smooth_mask=args.smooth_mask,
+                                                     avg_color_adjust=args.avg_color_adjust)
+        return converter
 
     def prepare_images(self):
-        self.read_alignments()
-        is_have_alignments = self.have_alignments()
-        for filename in tqdm(self.read_directory()):
-            image = cv2.imread(filename)
-
-            if is_have_alignments:
-                if self.have_face(filename):
-                    faces = self.get_faces_alignments(filename, image)
-                else:
-                    tqdm.write ('no alignment found for {}, skipping'.format(os.path.basename(filename)))
-                    continue
-            else:
-                faces = self.get_faces(image)
+        """ Prepare the images for conversion """
+        filename = ""
+        for filename in tqdm(self.images.input_images):
+            if not self.check_alignments(filename):
+                continue
+            image = Utils.cv2_read_write('read', filename)
+            faces = self.faces.get_faces_alignments(filename, image)
+            if not faces:
+                continue
+
             yield filename, image, faces
+
+    def check_alignments(self, filename):
+        """ If we have no alignments for this image, skip it """
+        have_alignments = self.faces.have_face(filename)
+        if not have_alignments:
+            tqdm.write("No alignment found for {}, skipping".format(os.path.basename(filename)))
+        return have_alignments
+
+    def convert(self, converter, item):
+        """ Apply the conversion transferring faces onto frames """
+        try:
+            filename, image, faces = item
+            skip = self.opts.check_skipframe(filename)
+
+            if not skip:
+                for idx, face in faces:
+                    image = self.convert_one_face(converter, (filename, image, idx, face))
+            if skip != "discard":
+                filename = str(self.output_dir / Path(filename).name)
+                Utils.cv2_read_write('write', filename, image)
+        except Exception as err:
+            print("Failed to convert image: {}. Reason: {}".format(filename, err))
+
+    def convert_one_face(self, converter, imagevars):
+        """ Perform the conversion on the given frame for a single face """
+        filename, image, idx, face = imagevars
+
+        if self.opts.check_skipface(filename, idx):
+            return image
+
+        image = self.images.rotate_image(image, face.r)
+        # TODO: This switch between 64 and 128 is a hack for now.
+        # We should have a separate cli option for size
+        image = converter.patch_image(image,
+                                      face,
+                                      64 if "128" not in self.args.trainer else 128)
+        image = self.images.rotate_image(image, face.r, reverse=True)
+        return image
+
+class OptionalActions(object):
+    """ Process the optional actions for convert """
+
+    def __init__(self, args, input_images):
+        self.args = args
+        self.input_images = input_images
+
+        self.faces_to_swap = self.get_aligned_directory()
+
+        self.frame_ranges = self.get_frame_ranges()
+        self.imageidxre = re.compile(r"(\d+)(?!.*\d)")
+
+    ### SKIP FACES ###
+    def get_aligned_directory(self):
+        """ Check for the existence of an aligned directory for identifying
+            which faces in the target frames should be swapped """
+        faces_to_swap = None
+        input_aligned_dir = self.args.input_aligned_dir
+
+        if input_aligned_dir is None:
+            print("Aligned directory not specified. All faces listed in the alignments file "
+                  "will be converted")
+        elif not os.path.isdir(input_aligned_dir):
+            print("Aligned directory not found. All faces listed in the alignments file "
+                  "will be converted")
+        else:
+            faces_to_swap = [Path(path) for path in get_image_paths(input_aligned_dir)]
+            if not faces_to_swap:
+                print("Aligned directory is empty, no faces will be converted!")
+            elif len(faces_to_swap) <= len(self.input_images) / 3:
+                print("Aligned directory contains an amount of images much less than the input, \
+                        are you sure this is the right directory?")
+        return faces_to_swap
+
+    ### SKIP FRAME RANGES ###
+    def get_frame_ranges(self):
+        """ split out the frame ranges and parse out 'min' and 'max' values """
+        if not self.args.frame_ranges:
+            return None
+
+        minmax = {"min": 0, # never any frames less than 0
+                  "max": float("inf")}
+        rng = [tuple(map(lambda q: minmax[q] if q in minmax.keys() else int(q), v.split("-")))
+               for v in self.args.frame_ranges]
+        return rng
+
+    def check_skipframe(self, filename):
+        """ Check whether frame is to be skipped """
+        if not self.frame_ranges:
+            return None
+        idx = int(self.imageidxre.findall(filename)[0])
+        skipframe = not any(map(lambda b: b[0] <= idx <= b[1], self.frame_ranges))
+        if skipframe and self.args.discard_frames:
+            skipframe = "discard"
+        return skipframe
+
+    def check_skipface(self, filename, face_idx):
+        """ Check whether face is to be skipped """
+        if self.faces_to_swap is None:
+            return False
+        face_name = "{}_{}{}".format(Path(filename).stem, face_idx, Path(filename).suffix)
+        face_file = Path(self.args.input_aligned_dir) / Path(face_name)
+        skip_face = face_file not in self.faces_to_swap
+        if skip_face:
+            print("face {} for frame {} was deleted, skipping".format(
+                face_idx, os.path.basename(filename)))
+        return skip_face
diff --git a/scripts/extract.py b/scripts/extract.py
index f44b9f9..b69879c 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -1,175 +1,110 @@
-import cv2
+#!/usr/bin python3
+""" The script to run the extract process of faceswap """
 
+import os
 from pathlib import Path
+
 from tqdm import tqdm
-import os
-import numpy as np
 
-from lib.cli import DirectoryProcessor, rotate_image
-from lib.utils import get_folder
 from lib.multithreading import pool_process
-from lib.detect_blur import is_blurry
-from plugins.PluginLoader import PluginLoader
-
-class ExtractTrainingData(DirectoryProcessor):
-    def create_parser(self, subparser, command, description):
-        self.optional_arguments = self.get_optional_arguments()
-        self.parser = subparser.add_parser(
-            command,
-            help="Extract the faces from a pictures.",
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground"
-            )
-
-    @staticmethod
-    def get_optional_arguments():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
-        argument_list = []
-        argument_list.append({ "opts": ('-D', '--detector'),
-                               "type": str,
-                               "choices": ("hog", "cnn", "all"), # case sensitive because this is used to load a plugin.
-                               "default": "hog",
-                               "help": "Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files."})
-        argument_list.append({ "opts": ('-l', '--ref_threshold'),
-                               "type": float,
-                               "dest": "ref_threshold",
-                               "default": 0.6,
-                               "help": "Threshold for positive face recognition"})
-        argument_list.append({ "opts": ('-n', '--nfilter'),
-                               "type": str,
-                               "dest": "nfilter",
-                               "nargs": '+',
-                               "default": "nfilter.jpg",
-                               "help": "Reference image for the persons you do not want to process. Should be a front portrait"})
-        argument_list.append({ "opts": ('-f', '--filter'),
-                               "type": str,
-                               "dest": "filter",
-                               "nargs": '+',
-                               "default": "filter.jpg",
-                               "help": "Reference image for the person you want to process. Should be a front portrait"})
-        argument_list.append({ "opts": ('-j', '--processes'),
-                               "type": int,
-                               "default": 1,
-                               "help": "Number of processes to use."})
-        argument_list.append({ "opts": ('-s', '--skip-existing'),
-                               "action": 'store_true',
-                               "dest": 'skip_existing',
-                               "default": False,
-                               "help": "Skips frames already extracted."})
-        argument_list.append({ "opts": ('-dl', '--debug-landmarks'),
-                               "action": "store_true",
-                               "dest": "debug_landmarks",
-                               "default": False,
-                               "help": "Draw landmarks for debug."})
-        argument_list.append({ "opts": ('-r', '--rotate-images'),
-                               "type": str,
-                               "dest": "rotate_images",
-                               "default": None,
-                               "help": "If a face isn't found, rotate the images to try to find a face. Can find more faces at the "
-                                 "cost of extraction speed.  Pass in a single number to use increments of that size up to 360, "
-                                 "or pass in a list of numbers to enumerate exactly what angles to check."})
-        argument_list.append({ "opts": ('-ae', '--align-eyes'),
-                               "action": "store_true",
-                               "dest": "align_eyes",
-                               "default": False,
-                               "help": "Perform extra alignment to ensure left/right eyes lie at the same height"})
-        argument_list.append({ "opts": ('-bt', '--blur-threshold'),
-                               "type": int,
-                               "dest": "blur_thresh",
-                               "default": None,
-                               "help": "Automatically discard images blurrier than the specified threshold. Discarded images are moved into a \"blurry\" sub-folder. Lower values allow more blur"})
-        return argument_list
+from scripts.fsmedia import Alignments, Faces, Images, Utils
+
+class Extract(object):
+    """ The extract process. """
+
+    def __init__(self, arguments):
+        self.args = arguments
+
+        self.images = Images(self.args)
+        self.faces = Faces(self.args)
+        self.alignments = Alignments(self.args)
+
+        self.output_dir = self.faces.output_dir
+
+        self.export_face = True
 
     def process(self):
-        extractor_name = "Align" # TODO Pass as argument
-        self.extractor = PluginLoader.get_extractor(extractor_name)()
-        processes = self.arguments.processes
-        try:
-            if processes != 1:
-                files = list(self.read_directory())
-                for filename, faces in tqdm(pool_process(self.processFiles, files, processes=processes), total = len(files)):
-                    self.num_faces_detected += 1
-                    self.faces_detected[os.path.basename(filename)] = faces
-            else:
-                for filename in tqdm(self.read_directory()):
-                    try:
-                        image = cv2.imread(filename)
-                        self.faces_detected[os.path.basename(filename)] = self.handleImage(image, filename)
-                    except Exception as e:
-                        if self.arguments.verbose:
-                            print('Failed to extract from image: {}. Reason: {}'.format(filename, e))
-                        pass
-        finally:
-            self.write_alignments()
-
-    def processFiles(self, filename):
+        """ Perform the extraction process """
+        print('Starting, this may take a while...')
+        Utils.set_verbosity(self.args.verbose)
+
+        if hasattr(self.args, 'processes') and self.args.processes > 1:
+            self.extract_multi_process()
+        else:
+            self.extract_single_process()
+
+        self.alignments.write_alignments(self.faces.faces_detected)
+
+        images, faces = Utils.finalize(self.images.images_found,
+                                       self.faces.num_faces_detected,
+                                       self.faces.verify_output)
+        self.images.images_found = images
+        self.faces.num_faces_detected = faces
+
+    def extract_single_process(self):
+        """ Run extraction in a single process """
+        for filename in tqdm(self.images.input_images):
+            filename, faces = self.process_single_image(filename)
+            self.faces.faces_detected[os.path.basename(filename)] = faces
+
+    def extract_multi_process(self):
+        """ Run the extraction on the correct number of processes """
+        for filename, faces in tqdm(pool_process(self.process_single_image,
+                                                 self.images.input_images,
+                                                 processes=self.args.processes),
+                                    total=self.images.images_found):
+            self.faces.num_faces_detected += 1
+            self.faces.faces_detected[os.path.basename(filename)] = faces
+
+    def process_single_image(self, filename):
+        """ Detect faces in an image. Rotate the image the specified amount
+            until at least one face is found, or until image rotations are
+            depleted.
+            Once at least one face has been detected, pass to process_single_face
+            to process the individual faces """
+        retval = filename, list()
         try:
-            image = cv2.imread(filename)
-            return filename, self.handleImage(image, filename)
-        except Exception as e:
-            if self.arguments.verbose:
-                print('Failed to extract from image: {}. Reason: {}'.format(filename, e))
-            pass
-        return filename, []
-
-    def getRotatedImageFaces(self, image, angle):
-        rotated_image = rotate_image(image, angle)
-        faces = self.get_faces(rotated_image, rotation=angle)
-        rotated_faces = [(idx, face) for idx, face in faces]
-        return rotated_faces, rotated_image
-
-    def imageRotator(self, image):
-        ''' rotates the image through rotation_angles to try to find a face '''
-        for angle in self.rotation_angles:
-            rotated_faces, rotated_image = self.getRotatedImageFaces(image, angle)
-            if len(rotated_faces) > 0:
-                if self.arguments.verbose:
-                    print('found face(s) by rotating image {} degrees'.format(angle))
-                break
-        return rotated_faces, rotated_image
-
-    def handleImage(self, image, filename):
-        faces = self.get_faces(image)
-        process_faces = [(idx, face) for idx, face in faces]
-
-        # Run image rotator if requested and no faces found
-        if self.rotation_angles is not None and len(process_faces) == 0:
-            process_faces, image = self.imageRotator(image)
-
-        rvals = []
-        for idx, face in process_faces:
-            # Draws landmarks for debug
-            if self.arguments.debug_landmarks:
-                for (x, y) in face.landmarksAsXY():
-                    cv2.circle(image, (x, y), 2, (0, 0, 255), -1)
-
-            resized_image, t_mat = self.extractor.extract(image, face, 256, self.arguments.align_eyes)
-            output_file = get_folder(self.output_dir) / Path(filename).stem
-
-            # Detect blurry images
-            if self.arguments.blur_thresh is not None:
-                aligned_landmarks = self.extractor.transform_points(face.landmarksAsXY(), t_mat, 256, 48)
-                feature_mask = self.extractor.get_feature_mask(aligned_landmarks / 256, 256, 48)
-                feature_mask = cv2.blur(feature_mask, (10, 10))
-                isolated_face = cv2.multiply(feature_mask, resized_image.astype(float)).astype(np.uint8)
-                blurry, focus_measure = is_blurry(isolated_face, self.arguments.blur_thresh)
-                # print("{} focus measure: {}".format(Path(filename).stem, focus_measure))
-                # cv2.imshow("Isolated Face", isolated_face)
-                # cv2.waitKey(0)
-                # cv2.destroyAllWindows()
-                if blurry:
-                    print("{}'s focus measure of {} was below the blur threshold, moving to \"blurry\"".format(Path(filename).stem, focus_measure))
-                    output_file = get_folder(Path(self.output_dir) / Path("blurry")) / Path(filename).stem
-
-            cv2.imwrite('{}_{}{}'.format(str(output_file), str(idx), Path(filename).suffix), resized_image)
-            f = {
-                "r": face.r,
+            image = Utils.cv2_read_write('read', filename)
+
+            for angle in self.images.rotation_angles:
+                image = Utils.rotate_image_by_angle(image, angle)
+                faces = self.faces.get_faces(image, angle)
+                process_faces = [(idx, face) for idx, face in faces]
+                if process_faces and angle != 0 and self.args.verbose:
+                    print("found face(s) by rotating image {} degrees".format(angle))
+                if process_faces:
+                    break
+
+            final_faces = [self.process_single_face(idx, face, filename, image)
+                           for idx, face in process_faces]
+
+            retval = filename, final_faces
+        except Exception as err:
+            if self.args.verbose:
+                print("Failed to extract from image: {}. Reason: {}".format(filename, err))
+        return retval
+
+    def process_single_face(self, idx, face, filename, image):
+        """ Perform processing on found faces """
+        output_file = self.output_dir / Path(filename).stem if self.export_face else None
+
+        self.faces.draw_landmarks_on_face(face, image)
+
+        resized_face, t_mat = self.faces.extractor.extract(image,
+                                                           face,
+                                                           256,
+                                                           self.faces.align_eyes)
+
+        blurry_file = self.faces.detect_blurry_faces(face, t_mat, resized_face, filename)
+        output_file = blurry_file if blurry_file else output_file
+
+        if self.export_face:
+            filename = "{}_{}{}".format(str(output_file), str(idx), Path(filename).suffix)
+            Utils.cv2_read_write('write', filename, resized_face)
+
+        return {"r": face.r,
                 "x": face.x,
                 "w": face.w,
                 "y": face.y,
                 "h": face.h,
-                "landmarksXY": face.landmarksAsXY()
-            }
-            rvals.append(f)
-        return rvals
+                "landmarksXY": face.landmarksAsXY()}
diff --git a/scripts/fsmedia.py b/scripts/fsmedia.py
new file mode 100644
index 0000000..f15d4d7
--- /dev/null
+++ b/scripts/fsmedia.py
@@ -0,0 +1,338 @@
+#!/usr/bin python3
+""" Holds the classes for the 3 main Faceswap 'media' objects for input (extract)
+    and output (convert) tasks. Those being:
+            Images
+            Faces
+            Alignments"""
+
+import os
+from pathlib import Path
+
+import cv2
+import numpy as np
+
+from lib.detect_blur import is_blurry
+from lib import Serializer
+from lib.faces_detect import detect_faces, DetectedFace
+from lib.FaceFilter import FaceFilter
+from lib.utils import get_folder, get_image_paths, set_system_verbosity
+from plugins.PluginLoader import PluginLoader
+
+class Utils(object):
+    """ Holds utility functions that are required by more than one media
+        object """
+
+    @staticmethod
+    def set_verbosity(verbose):
+        """ Set the system output verbosity """
+        lvl = '0' if verbose else '2'
+        set_system_verbosity(lvl)
+
+    @staticmethod
+    def rotate_image_by_angle(image, angle, rotated_width=None, rotated_height=None):
+        """ Rotate an image by a given angle. From:
+            https://stackoverflow.com/questions/22041699
+            This is required by both Faces and Images so placed here for now """
+        height, width = image.shape[:2]
+        image_center = (width/2, height/2)
+        rotation_matrix = cv2.getRotationMatrix2D(image_center, -1.*angle, 1.)
+        if rotated_width is None or rotated_height is None:
+            abs_cos = abs(rotation_matrix[0, 0])
+            abs_sin = abs(rotation_matrix[0, 1])
+            if rotated_width is None:
+                rotated_width = int(height*abs_sin + width*abs_cos)
+            if rotated_height is None:
+                rotated_height = int(height*abs_cos + width*abs_sin)
+        rotation_matrix[0, 2] += rotated_width/2 - image_center[0]
+        rotation_matrix[1, 2] += rotated_height/2 - image_center[1]
+        return cv2.warpAffine(image, rotation_matrix, (rotated_width, rotated_height))
+
+    @staticmethod
+    def cv2_read_write(action, filename, image=None):
+        """ Read or write an image using cv2 """
+        if action == 'read':
+            image = cv2.imread(filename)
+        if action == 'write':
+            cv2.imwrite(filename, image)
+        return image
+
+    @staticmethod
+    def finalize(images_found, num_faces_detected, verify_output):
+        """ Finalize the image processing """
+        print("-------------------------")
+        print("Images found:        {}".format(images_found))
+        print("Faces detected:      {}".format(num_faces_detected))
+        print("-------------------------")
+
+        if verify_output:
+            print("Note:")
+            print("Multiple faces were detected in one or more pictures.")
+            print("Double check your results.")
+            print("-------------------------")
+
+        images_found = 0
+        num_faces_detected = 0
+        print("Done!")
+        return images_found, num_faces_detected
+
+class Images(object):
+    """ Holds the full frames/images """
+    def __init__(self, arguments):
+        self.args = arguments
+        self.rotation_angles = self.get_rotation_angles()
+        self.already_processed = self.get_already_processed()
+        self.input_images = self.get_input_images()
+        self.images_found = len(self.input_images)
+
+        self.rotation_width = 0
+        self.rotation_height = 0
+
+    def get_rotation_angles(self):
+        """ Set the rotation angles. Includes backwards compatibility for the 'on'
+            and 'off' options:
+                - 'on' - increment 90 degrees
+                - 'off' - disable
+                - 0 is prepended to the list, as whatever happens, we want to scan the image
+                  in it's upright state """
+        rotation_angles = [0]
+
+        if (not hasattr(self.args, 'rotate_images')
+                or not self.args.rotate_images
+                or self.args.rotate_images == "off"):
+            return rotation_angles
+
+        if self.args.rotate_images == "on":
+            rotation_angles.extend(range(90, 360, 90))
+        else:
+            passed_angles = [int(angle)
+                             for angle in self.args.rotate_images.split(",")]
+            if len(passed_angles) == 1:
+                rotation_step_size = passed_angles[0]
+                rotation_angles.extend(range(rotation_step_size, 360, rotation_step_size))
+            elif len(rotation_angles) > 1:
+                rotation_angles.extend(rotation_angles)
+
+        return rotation_angles
+
+    def get_already_processed(self):
+        """ Return the images that already exist in the output directory """
+        print("Output Directory: {}".format(self.args.output_dir))
+
+        if not hasattr(self.args, 'skip_existing') or not self.args.skip_existing:
+            return None
+
+        return get_image_paths(self.args.output_dir)
+
+    def get_input_images(self):
+        """ Return the list of images that are to be processed """
+        if not os.path.exists(self.args.input_dir):
+            print("Input directory {} not found.".format(self.args.input_dir))
+            exit(1)
+
+        print("Input Directory: {}".format(self.args.input_dir))
+
+        if hasattr(self.args, 'skip_existing') and self.args.skip_existing:
+            input_images = get_image_paths(self.args.input_dir, self.already_processed)
+            print("Excluding %s files" % len(self.already_processed))
+        else:
+            input_images = get_image_paths(self.args.input_dir)
+
+        return input_images
+
+    def rotate_image(self, image, rotation, reverse=False):
+        """ Rotate the image forwards or backwards """
+        if rotation != 0:
+            if not reverse:
+                self.rotation_height, self.rotation_width = image.shape[:2]
+                image = Utils.rotate_image_by_angle(image, rotation)
+            else:
+                image = Utils.rotate_image_by_angle(image,
+                                                    rotation * -1,
+                                                    rotated_width=self.rotation_width,
+                                                    rotated_height=self.rotation_height)
+        return image
+
+class Faces(object):
+    """ Holds the faces """
+    def __init__(self, arguments):
+        self.args = arguments
+        self.extractor = self.load_extractor()
+        self.filter = self.load_face_filter()
+        self.align_eyes = self.args.align_eyes if hasattr(self.args, 'align_eyes') else False
+        self.output_dir = get_folder(self.args.output_dir)
+
+        self.faces_detected = dict()
+        self.num_faces_detected = 0
+        self.verify_output = False
+
+    @staticmethod
+    def load_extractor():
+        """ Load the requested extractor for extraction """
+        # TODO Pass as argument
+        extractor_name = "Align"
+        extractor = PluginLoader.get_extractor(extractor_name)()
+
+        return extractor
+
+    def load_face_filter(self):
+        """ Load faces to filter out of images """
+        facefilter = None
+        filter_files = [self.set_face_filter(filter_type)
+                        for filter_type in ('filter', 'nfilter')]
+
+        if any(filters for filters in filter_files):
+            facefilter = FaceFilter(filter_files[0], filter_files[1], self.args.ref_threshold)
+        return facefilter
+
+    def set_face_filter(self, filter_list):
+        """ Set the required filters """
+        filter_files = list()
+        filter_args = getattr(self.args, filter_list)
+        if filter_args:
+            print("{}: {}".format(filter_list.title(), filter_args))
+            filter_files = filter_args
+            if not isinstance(filter_args, list):
+                filter_files = [filter_args]
+            filter_files = list(filter(lambda fnc: Path(fnc).exists(), filter_files))
+        return filter_files
+
+    def have_face(self, filename):
+        """ return path of images that have faces """
+        return os.path.basename(filename) in self.faces_detected
+
+    def get_faces(self, image, rotation=0):
+        """ Extract the faces from an image """
+        faces_count = 0
+        faces = detect_faces(image, self.args.detector, self.args.verbose, rotation)
+
+        for face in faces:
+            if self.filter and not self.filter.check(face):
+                if self.args.verbose:
+                    print("Skipping not recognized face!")
+                continue
+            yield faces_count, face
+
+            self.num_faces_detected += 1
+            faces_count += 1
+
+        if faces_count > 1 and self.args.verbose:
+            self.verify_output = True
+
+    def get_faces_alignments(self, filename, image):
+        """ Retrieve the face alignments from an image """
+        faces_count = 0
+        faces = self.faces_detected[os.path.basename(filename)]
+        for rawface in faces:
+            face = DetectedFace(**rawface)
+            # Rotate the image if necessary
+            if face.r != 0:
+                image = Utils.rotate_image_by_angle(image, face.r)
+            face.image = image[face.y : face.y + face.h, face.x : face.x + face.w]
+            if self.filter and not self.filter.check(face):
+                if self.args.verbose:
+                    print("Skipping not recognized face!")
+                continue
+
+            yield faces_count, face
+            self.num_faces_detected += 1
+            faces_count += 1
+        if faces_count > 1 and self.args.verbose:
+            print("Note: Found more than one face in an image! File: %s" % filename)
+            self.verify_output = True
+
+    def draw_landmarks_on_face(self, face, image):
+        """ Draw debug landmarks on extracted face """
+        if not hasattr(self.args, 'debug_landmarks') or not self.args.debug_landmarks:
+            return
+
+        for (pos_x, pos_y) in face.landmarksAsXY():
+            cv2.circle(image, (pos_x, pos_y), 2, (0, 0, 255), -1)
+
+    def detect_blurry_faces(self, face, t_mat, resized_image, filename):
+        """ Detect and move blurry face """
+        if not hasattr(self.args, 'blur_thresh') or not self.args.blur_thresh:
+            return None
+
+        blurry_file = None
+        aligned_landmarks = self.extractor.transform_points(face.landmarksAsXY(), t_mat, 256, 48)
+        feature_mask = self.extractor.get_feature_mask(aligned_landmarks / 256, 256, 48)
+        feature_mask = cv2.blur(feature_mask, (10, 10))
+        isolated_face = cv2.multiply(feature_mask, resized_image.astype(float)).astype(np.uint8)
+        blurry, focus_measure = is_blurry(isolated_face, self.args.blur_thresh)
+
+        if blurry:
+            print("{}'s focus measure of {} was below the blur threshold, "
+                  "moving to \"blurry\"".format(Path(filename).stem, focus_measure))
+            blurry_file = get_folder(Path(self.output_dir) / Path("blurry")) / \
+                Path(filename).stem
+        return blurry_file
+
+class Alignments(object):
+    """ Holds processes pertaining to the alignments file """
+    def __init__(self, arguments):
+        self.args = arguments
+        self.serializer = self.get_serializer()
+
+    def get_serializer(self):
+        """ Set the serializer to be used for loading and saving alignments """
+        if not self.args.serializer and self.args.alignments_path:
+            ext = os.path.splitext(self.args.alignments_path)[-1]
+            serializer = Serializer.get_serializer_fromext(ext)
+            print("Alignments Output: {}".format(self.args.alignments_path))
+        else:
+            serializer = Serializer.get_serializer(self.args.serializer or "json")
+        print("Using {} serializer".format(serializer.ext))
+        return serializer
+
+    def get_alignments_path(self):
+        """ Return the path to alignments file """
+        if self.args.alignments_path:
+            alignfile = self.args.alignments_path
+        else:
+            alignfile = os.path.join(str(self.args.input_dir),
+                                     "alignments.{}".format(self.serializer.ext))
+        print("Alignments filepath: %s" % alignfile)
+        return alignfile
+
+    def read_alignments(self):
+        """ Read the serialized alignments file """
+        alignfile = self.get_alignments_path()
+        try:
+            with open(alignfile, self.serializer.roptions) as align:
+                faces_detected = self.serializer.unmarshal(align.read())
+        except Exception as err:
+            print("{} not read!".format(alignfile))
+            print(str(err))
+            faces_detected = dict()
+        return faces_detected
+
+    def write_alignments(self, faces_detected):
+        """ Write the serialized alignments file """
+        alignfile = self.get_alignments_path()
+
+        if hasattr(self.args, 'skip_existing') and self.args.skip_existing:
+            faces_detected = self.load_skip_alignments(alignfile, faces_detected)
+
+        try:
+            print("Writing alignments to: {}".format(alignfile))
+            with open(alignfile, self.serializer.woptions) as align:
+                align.write(self.serializer.marshal(faces_detected))
+        except Exception as err:
+            print("{} not written!".format(alignfile))
+            print(str(err))
+
+    def load_skip_alignments(self, alignfile, faces_detected):
+        """ Load existing alignments if skipping existing images """
+        if self.have_alignments():
+            existing_alignments = self.read_alignments()
+            for key, val in existing_alignments.items():
+                if val:
+                    faces_detected[key] = val
+        else:
+            print("Existing alignments file '%s' not found." % alignfile)
+        return faces_detected
+
+    def have_alignments(self):
+        """ Check if an alignments file exists """
+        alignfile = self.get_alignments_path()
+        return os.path.exists(alignfile)
diff --git a/scripts/gui.py b/scripts/gui.py
index 92ca065..6a93b73 100644
--- a/scripts/gui.py
+++ b/scripts/gui.py
@@ -2,8 +2,8 @@
 """ The optional GUI for faceswap """
 
 import os
-import signal
 import re
+import signal
 import subprocess
 from subprocess import PIPE, Popen, TimeoutExpired
 import sys
@@ -13,17 +13,20 @@ from math import ceil, floor
 from threading import Thread
 from time import time
 
-import numpy
 import matplotlib
-matplotlib.use('TkAgg')
 import matplotlib.animation as animation
 from matplotlib import pyplot as plt
 from matplotlib import style
 from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
 
+import numpy
+
 from lib.cli import FullPaths
 from lib.Serializer import JSONSerializer
 
+matplotlib.use('TkAgg')
+
+
 PATHSCRIPT = os.path.realpath(os.path.dirname(sys.argv[0]))
 
 # An error will be thrown when importing tkinter for users without tkinter
@@ -1088,55 +1091,51 @@ class FaceswapControl(object):
         self.utils.guitext['status'].set(status)
 
 
-class TKGui(object):
-    """ Main GUI Control """
-
-    def __init__(self, subparser, subparsers, command, description='default'):
+class Gui(object):
+    """ The GUI process. """
+    def __init__(self, arguments, subparsers):
         # Don't try to load the GUI if there is no display or there are
         # problems importing tkinter
-        cmd = sys.argv
-        if not self.check_display(cmd) or not self.check_tkinter_available(cmd):
+        if not self.check_display() or not self.check_tkinter_available():
             return
 
-        self.arguments = None
+        cmd = sys.argv
+
+        self.args = arguments
         self.opts = self.extract_options(subparsers)
         self.utils = Utils(self.opts, calling_file=cmd[0])
         self.root = FaceswapGui(self.utils, calling_file=cmd[0])
-        self.parse_arguments(description, subparser, command)
 
     @staticmethod
-    def check_display(command):
+    def check_display():
         """ Check whether there is a display to output the GUI. If running on
             Windows then assume not running in headless mode """
         if not os.environ.get('DISPLAY', None) and os.name != 'nt':
-            if 'gui' in command:
-                print('Could not detect a display. The GUI has been disabled.')
-                if os.name == 'posix':
-                    print('macOS users need to install XQuartz. '
-                          'See https://support.apple.com/en-gb/HT201341')
+            if os.name == 'posix':
+                print('macOS users need to install XQuartz. '
+                      'See https://support.apple.com/en-gb/HT201341')
             return False
         return True
 
     @staticmethod
-    def check_tkinter_available(command):
+    def check_tkinter_available():
         """ Check whether TkInter is installed on user's machine """
         tkinter_vars = [tk, ttk, filedialog, messagebox, TclError]
         if any(var is None for var in tkinter_vars):
-            if "gui" in command:
-                print(
-                    "It looks like TkInter isn't installed for your OS, so "
-                    "the GUI has been "
-                    "disabled. To enable the GUI please install the TkInter "
-                    "application.\n"
-                    "You can try:\n"
-                    "  Windows/macOS:      Install ActiveTcl Community "
-                    "Edition from "
-                    "www.activestate.com\n"
-                    "  Ubuntu/Mint/Debian: sudo apt install python3-tk\n"
-                    "  Arch:               sudo pacman -S tk\n"
-                    "  CentOS/Redhat:      sudo yum install tkinter\n"
-                    "  Fedora:             sudo dnf install python3-tkinter\n",
-                    file=sys.stderr)
+            print(
+                "It looks like TkInter isn't installed for your OS, so "
+                "the GUI has been "
+                "disabled. To enable the GUI please install the TkInter "
+                "application.\n"
+                "You can try:\n"
+                "  Windows/macOS:      Install ActiveTcl Community "
+                "Edition from "
+                "www.activestate.com\n"
+                "  Ubuntu/Mint/Debian: sudo apt install python3-tk\n"
+                "  Arch:               sudo pacman -S tk\n"
+                "  CentOS/Redhat:      sudo yum install tkinter\n"
+                "  Fedora:             sudo dnf install python3-tkinter\n",
+                file=sys.stderr)
             return False
         return True
 
@@ -1177,25 +1176,8 @@ class TKGui(object):
             ctl = ttk.Checkbutton
         return ctl, sysbrowser
 
-    def parse_arguments(self, description, subparser, command):
-        """ Parse the command line arguments for the GUI """
-        parser = subparser.add_parser(
-            command,
-            help="This Launches a GUI for Faceswap.",
-            description=description,
-            epilog="Questions and feedback: \
-                    https://github.com/deepfakes/faceswap-playground")
-
-        parser.add_argument('-d', '--debug',
-                            action='store_true',
-                            dest='debug',
-                            default=False,
-                            help='Output to Shell console instead of GUI console')
-        parser.set_defaults(func=self.process)
-
-    def process(self, arguments):
+    def process(self):
         """ Builds the GUI """
-        self.arguments = arguments
-        self.utils.debugconsole = self.arguments.debug
+        self.utils.debugconsole = self.args.debug
         self.root.build_gui()
         self.root.gui.mainloop()
diff --git a/scripts/train.py b/scripts/train.py
index 77ce464..96be29f 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -1,251 +1,198 @@
-import cv2
-import numpy
-import time
+#!/usr/bin python3
+""" The script to run the training process of faceswap """
 
-import threading 
-from lib.utils import get_image_paths, get_folder
-from lib.cli import FullPaths, argparse, os, sys
-from plugins.PluginLoader import PluginLoader
+import os
+import sys
+import threading
 
-tf = None
-set_session = None
-def import_tensorflow_keras():
-    ''' Import the TensorFlow and keras set_session modules only when they are required '''
-    global tf
-    global set_session
-    if tf is None or set_session is None:
-        import tensorflow
-        import keras.backend.tensorflow_backend
-        tf = tensorflow
-        set_session = keras.backend.tensorflow_backend.set_session
-
-class TrainingProcessor(object):
-    arguments = None
-
-    def __init__(self, subparser, command, description='default'):
-        self.argument_list = self.get_argument_list()
-        self.optional_arguments = self.get_optional_arguments()
-        self.parse_arguments(description, subparser, command)
-        self.lock = threading.Lock()
+import cv2
+import tensorflow as tf
+from keras.backend.tensorflow_backend import set_session
 
-    def process_arguments(self, arguments):
-        self.arguments = arguments
-        print("Model A Directory: {}".format(self.arguments.input_A))
-        print("Model B Directory: {}".format(self.arguments.input_B))
-        print("Training data directory: {}".format(self.arguments.model_dir))
+from lib.utils import get_folder, get_image_paths, set_system_verbosity
+from plugins.PluginLoader import PluginLoader
 
-        self.process()
-    
-    @staticmethod
-    def get_argument_list():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
-        argument_list = []
-        argument_list.append({ "opts": ("-A", "--input-A"),
-                               "action": FullPaths,
-                               "dest": "input_A",
-                               "default": "input_A",
-                               "help": "Input directory. A directory containing training images for face A.\
-                               Defaults to 'input'"})
-        argument_list.append({ "opts": ("-B", "--input-B"),
-                               "action": FullPaths,
-                               "dest": "input_B",
-                               "default": "input_B",
-                               "help": "Input directory. A directory containing training images for face B.\
-                               Defaults to 'input'"})
-        argument_list.append({ "opts": ("-m", "--model-dir"),
-                               "action": FullPaths,
-                               "dest": "model_dir",
-                               "default": "models",
-                               "help": "Model directory. This is where the training data will \
-                               be stored. Defaults to 'model'"})
-        argument_list.append({ "opts": ("-p", "--preview"),
-                               "action": "store_true",
-                               "dest": "preview",
-                               "default": False,
-                               "help": "Show preview output. If not specified, write progress \
-                               to file."})
-        argument_list.append({ "opts": ("-v", "--verbose"),
-                               "action": "store_true",
-                               "dest": "verbose",
-                               "default": False,
-                               "help": "Show verbose output"})
-        argument_list.append({ "opts": ("-s", "--save-interval"),
-                               "type": int,
-                               "dest": "save_interval",
-                               "default": 100,
-                               "help": "Sets the number of iterations before saving the model."})
-        argument_list.append({ "opts": ("-w", "--write-image"),
-                               "action": "store_true",
-                               "dest": "write_image",
-                               "default": False,
-                               "help": "Writes the training result to a file even on preview mode."})
-        argument_list.append({ "opts": ("-t", "--trainer"),
-                               "type": str,
-                               "choices": PluginLoader.get_available_models(),
-                               "default": PluginLoader.get_default_model(),
-                               "help": "Select which trainer to use, LowMem for cards < 2gb."})
-        argument_list.append({ "opts": ("-pl", "--use-perceptual-loss"),
-                               "action": "store_true",
-                               "dest": "perceptual_loss",
-                               "default": False,
-                               "help": "Use perceptual loss while training"})
-        argument_list.append({ "opts": ("-bs", "--batch-size"),
-                               "type": int,
-                               "default": 64,
-                               "help": "Batch size, as a power of 2 (64, 128, 256, etc)"})
-        argument_list.append({ "opts": ("-ag", "--allow-growth"),
-                               "action": "store_true",
-                               "dest": "allow_growth",
-                               "default": False,
-                               "help": "Sets allow_growth option of Tensorflow to spare memory on some configs"})
-        argument_list.append({ "opts": ("-ep", "--epochs"),
-                               "type": int,
-                               "default": 1000000,
-                               "help": "Length of training in epochs."})
-        argument_list.append({ "opts": ("-g", "--gpus"),
-                               "type": int,
-                               "default": 1,
-                               "help": "Number of GPUs to use for training"})
-        # This is a hidden argument to indicate that the GUI is being used, so the preview window
-        # should be redirected Accordingly
-        argument_list.append({ "opts": ("-gui", "--gui"),
-                               "action": "store_true",
-                               "dest": "redirect_gui",
-                               "default": False,
-                               "help": argparse.SUPPRESS})
-        return argument_list
 
-    @staticmethod
-    def get_optional_arguments():
-        ''' Put the arguments in a list so that they are accessible from both argparse and gui '''
-        # Override this for custom arguments
-        argument_list = []
-        return argument_list
-
-    def parse_arguments(self, description, subparser, command):
-        parser = subparser.add_parser(
-            command,
-            help="This command trains the model for the two faces A and B.",
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground")
-
-        for option in self.argument_list:
-            args = option['opts']
-            kwargs = {key: option[key] for key in option.keys() if key != 'opts'}
-            parser.add_argument(*args, **kwargs)
-
-        parser = self.add_optional_arguments(parser)
-        parser.set_defaults(func=self.process_arguments)
-
-    def add_optional_arguments(self, parser):
-        for option in self.optional_arguments:
-            args = option['opts']
-            kwargs = {key: option[key] for key in option.keys() if key != 'opts'}
-            parser.add_argument(*args, **kwargs)
-        return parser
+class Train(object):
+    """ The training process.  """
+    def __init__(self, arguments):
+        self.args = arguments
+        self.images = self.get_images()
 
-    def process(self):
         self.stop = False
         self.save_now = False
+        self.preview_buffer = dict()
+        self.lock = threading.Lock()
 
-        thr = threading.Thread(target=self.processThread, args=(), kwargs={})
-        thr.start()
-
-        if self.arguments.preview:
-            print('Using live preview')
-            while True:
-                try:
-                    with self.lock:
-                        for name, image in self.preview_buffer.items():
-                            cv2.imshow(name, image)
-
-                    key = cv2.waitKey(1000)
-                    if key == ord('\n') or key == ord('\r'):
-                        break
-                    if key == ord('s'):
-                        self.save_now = True
-                except KeyboardInterrupt:
-                    break
-        else:
-            try:
-                input() # TODO how to catch a specific key instead of Enter?
-                # there isnt a good multiplatform solution: https://stackoverflow.com/questions/3523174/raw-input-in-python-without-pressing-enter
-            except KeyboardInterrupt:
-                pass
+        # this is so that you can enter case insensitive values for trainer
+        trainer_name = self.args.trainer
+        self.trainer_name = "LowMem" if trainer_name.lower() == "lowmem" else trainer_name
 
-        print("Exit requested! The trainer will complete its current cycle, save the models and quit (it can take up a couple of seconds depending on your training speed). If you want to kill it now, press Ctrl + c")
-        self.stop = True
-        thr.join() # waits until thread finishes
+    def process(self):
+        """ Call the training process object """
+        print("Training data directory: {}".format(self.args.model_dir))
 
-    def processThread(self):
-        try:
-            if self.arguments.allow_growth:
-                self.set_tf_allow_growth()
+        lvl = '0' if self.args.verbose else '2'
+        set_system_verbosity(lvl)
 
-            print('Loading data, this may take a while...')
-            # this is so that you can enter case insensitive values for trainer
-            trainer = self.arguments.trainer
-            trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
-            model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
-            model.load(swapped=False)
+        thread = self.start_thread()
 
-            images_A = get_image_paths(self.arguments.input_A)
-            images_B = get_image_paths(self.arguments.input_B)
-            trainer = PluginLoader.get_trainer(trainer)
-            trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
+        if self.args.preview:
+            self.monitor_preview()
+        else:
+            self.monitor_console()
+
+        self.end_thread(thread)
+
+    def get_images(self):
+        """ Check the image dirs exist, contain images and return the image objects """
+        images = []
+        for image_dir in [self.args.input_A, self.args.input_B]:
+            if not os.path.isdir(image_dir):
+                print('Error: {} does not exist'.format(image_dir))
+                exit(1)
+
+            if not os.listdir(image_dir):
+                print('Error: {} contains no images'.format(image_dir))
+                exit(1)
+
+            images.append(get_image_paths(image_dir))
+        print("Model A Directory: {}".format(self.args.input_A))
+        print("Model B Directory: {}".format(self.args.input_B))
+        return images
+
+    def start_thread(self):
+        """ Put the training process in a thread so we can keep control """
+        thread = threading.Thread(target=self.process_thread)
+        thread.start()
+        return thread
+
+    def end_thread(self, thread):
+        """ On termination output message and join thread back to main """
+        print("Exit requested! The trainer will complete its current cycle, save "
+              "the models and quit (it can take up a couple of seconds depending "
+              "on your training speed). If you want to kill it now, press Ctrl + c")
+        self.stop = True
+        thread.join()
+        sys.stdout.flush()
 
-            print('Starting. Press "Enter" to stop training and save model')
+    def process_thread(self):
+        """ The training process to be run inside a thread """
+        try:
+            print("Loading data, this may take a while...")
 
-            for epoch in range(0, self.arguments.epochs):
+            if self.args.allow_growth:
+                self.set_tf_allow_growth()
 
-                save_iteration = epoch % self.arguments.save_interval == 0
+            model = self.load_model()
+            trainer = self.load_trainer(model)
 
-                trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
+            self.run_training_cycle(model, trainer)
+        except KeyboardInterrupt:
+            try:
+                model.save_weights()
+            except KeyboardInterrupt:
+                print("Saving model weights has been cancelled!")
+            exit(0)
+        except Exception as err:
+            raise err
+
+    def load_model(self):
+        """ Load the model requested for training """
+        model_dir = get_folder(self.args.model_dir)
+        model = PluginLoader.get_model(self.trainer_name)(model_dir, self.args.gpus)
+
+        model.load(swapped=False)
+        return model
+
+    def load_trainer(self, model):
+        """ Load the trainer requested for traning """
+        images_a, images_b = self.images
+
+        trainer = PluginLoader.get_trainer(self.trainer_name)
+        trainer = trainer(model,
+                          images_a,
+                          images_b,
+                          self.args.batch_size,
+                          self.args.perceptual_loss)
+        return trainer
+
+    def run_training_cycle(self, model, trainer):
+        """ Perform the training cycle """
+        for epoch in range(0, self.args.epochs):
+            save_iteration = epoch % self.args.save_interval == 0
+            viewer = self.show if save_iteration or self.save_now else None
+            trainer.train_one_step(epoch, viewer)
+            if self.stop:
+                break
+            elif save_iteration:
+                model.save_weights()
+            elif self.save_now:
+                model.save_weights()
+                self.save_now = False
+        model.save_weights()
+        self.stop = True
 
-                if save_iteration:
-                    model.save_weights()
+    def monitor_preview(self):
+        """ Generate the preview window and wait for keyboard input """
+        print("Using live preview.\n"
+              "Press 'ENTER' on the preview window to save and quit.\n"
+              "Press 'S' on the preview window to save model weights immediately")
+        while True:
+            try:
+                with self.lock:
+                    for name, image in self.preview_buffer.items():
+                        cv2.imshow(name, image)
 
+                key = cv2.waitKey(1000)
+                if key == ord("\n") or key == ord("\r"):
+                    break
+                if key == ord("s"):
+                    self.save_now = True
                 if self.stop:
                     break
+            except KeyboardInterrupt:
+                break
 
-                if self.save_now:
-                    model.save_weights()
-                    self.save_now = False
-                    
-            model.save_weights()
-            exit(0)
+    @staticmethod
+    def monitor_console():
+        """ Monitor the console for any input followed by enter or ctrl+c """
+        # TODO: how to catch a specific key instead of Enter?
+        # there isnt a good multiplatform solution:
+        # https://stackoverflow.com/questions/3523174
+        # TODO: Find a way to interrupt input() if the target iterations are reached.
+        # At the moment, setting a target iteration and using the -p flag is the only guaranteed
+        # way to exit the training loop on hitting target iterations. """
+        print("Starting. Press 'ENTER' to stop training and save model")
+        try:
+            input()
         except KeyboardInterrupt:
-            try:
-                model.save_weights()
-            except KeyboardInterrupt:
-                print('Saving model weights has been cancelled!')
-            exit(0)
-        except Exception as e:
-            raise e
-            exit(1)
+            pass
 
-    def set_tf_allow_growth(self):
-        import_tensorflow_keras()
+    @staticmethod
+    def set_tf_allow_growth():
+        """ Allow TensorFlow to manage VRAM growth """
         config = tf.ConfigProto()
         config.gpu_options.allow_growth = True
-        config.gpu_options.visible_device_list="0"
+        config.gpu_options.visible_device_list = "0"
         set_session(tf.Session(config=config))
 
-    preview_buffer = {}
-
-    def show(self, image, name=''):
+    def show(self, image, name=""):
+        """ Generate the preview and write preview file output """
         try:
-            if self.arguments.redirect_gui:
-                scriptpath = os.path.realpath(os.path.dirname(sys.argv[0]))
-                img = '.gui_preview.png'
+            scriptpath = os.path.realpath(os.path.dirname(sys.argv[0]))
+            if self.args.write_image:
+                img = "_sample_{}.jpg".format(name)
+                imgfile = os.path.join(scriptpath, img)
+                cv2.imwrite(imgfile, image)
+
+            if self.args.redirect_gui:
+                img = ".gui_preview.png"
                 imgfile = os.path.join(scriptpath, img)
                 cv2.imwrite(imgfile, image)
-            elif self.arguments.preview:
+            elif self.args.preview:
                 with self.lock:
                     self.preview_buffer[name] = image
-            elif self.arguments.write_image:
-                cv2.imwrite('_sample_{}.jpg'.format(name), image)
-        except Exception as e:
+        except Exception as err:
             print("could not preview sample")
-            raise e
+            raise err
