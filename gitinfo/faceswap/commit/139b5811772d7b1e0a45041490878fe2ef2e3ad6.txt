commit 139b5811772d7b1e0a45041490878fe2ef2e3ad6
Author: kvrooman <vrooman.kyle@gmail.com>
Date:   Tue Sep 24 05:16:03 2019 -0500

    Align eyes deprecation (#851)
    
    * align eyes removal
    
    * add align_eyes tool

diff --git a/lib/align_eyes.py b/lib/align_eyes.py
deleted file mode 100644
index dc8a1ef..0000000
--- a/lib/align_eyes.py
+++ /dev/null
@@ -1,71 +0,0 @@
-# Code borrowed from https://github.com/jrosebr1/imutils/blob/d5cb29d02cf178c399210d5a139a821dfb0ae136/imutils/face_utils/helpers.py
-"""
-The MIT License (MIT)
-
-Copyright (c) 2015-2016 Adrian Rosebrock, http://www.pyimagesearch.com
-
-Permission is hereby granted, free of charge, to any person obtaining a copy
-of this software and associated documentation files (the "Software"), to deal
-in the Software without restriction, including without limitation the rights
-to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
-copies of the Software, and to permit persons to whom the Software is
-furnished to do so, subject to the following conditions:
-
-The above copyright notice and this permission notice shall be included in
-all copies or substantial portions of the Software.
-
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
-IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
-FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
-AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
-LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
-OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
-THE SOFTWARE.
-"""
-
-from collections import OrderedDict
-import numpy as np
-import cv2
-
-# define a dictionary that maps the indexes of the facial
-# landmarks to specific face regions
-FACIAL_LANDMARKS_IDXS = OrderedDict([
-    ("mouth", (48, 68)),
-    ("right_eyebrow", (17, 22)),
-    ("left_eyebrow", (22, 27)),
-    ("right_eye", (36, 42)),
-    ("left_eye", (42, 48)),
-    ("nose", (27, 36)),
-    ("jaw", (0, 17)),
-    ("chin", (8, 11))
-])
-
-# Returns a rotation matrix that when applied to the 68 input facial landmarks
-# results in landmarks with eyes aligned horizontally
-def align_eyes(landmarks, size):
-    desiredLeftEye = (0.35, 0.35) # (y, x) value
-    desiredFaceWidth = desiredFaceHeight = size
-
-    # extract the left and right eye (x, y)-coordinates
-    (lStart, lEnd) = FACIAL_LANDMARKS_IDXS["left_eye"]
-    (rStart, rEnd) = FACIAL_LANDMARKS_IDXS["right_eye"]
-    leftEyePts = landmarks[lStart:lEnd]
-    rightEyePts = landmarks[rStart:rEnd]
-
-    # compute the center of mass for each eye
-    leftEyeCenter = leftEyePts.mean(axis=0).astype("int")
-    rightEyeCenter = rightEyePts.mean(axis=0).astype("int")
-
-    # compute the angle between the eye centroids
-    dY = rightEyeCenter[0,1] - leftEyeCenter[0,1]
-    dX = rightEyeCenter[0,0] - leftEyeCenter[0,0]
-    angle = np.degrees(np.arctan2(dY, dX)) - 180
-
-    # compute center (x, y)-coordinates (i.e., the median point)
-    # between the two eyes in the input image
-    eyesCenter = ((leftEyeCenter[0,0] + rightEyeCenter[0,0]) // 2, (leftEyeCenter[0,1] + rightEyeCenter[0,1]) // 2)
-
-    # grab the rotation matrix for rotating and scaling the face
-    M = cv2.getRotationMatrix2D(eyesCenter, angle, 1.0)
-
-    return M
diff --git a/lib/aligner.py b/lib/aligner.py
index 4018661..2e00b9f 100644
--- a/lib/aligner.py
+++ b/lib/aligner.py
@@ -7,7 +7,6 @@ import cv2
 import numpy as np
 
 from lib.umeyama import umeyama
-from lib.align_eyes import align_eyes as func_align_eyes, FACIAL_LANDMARKS_IDXS
 
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
@@ -16,11 +15,11 @@ class Extract():
     """ Based on the original https://www.reddit.com/r/deepfakes/
         code sample + contribs """
 
-    def extract(self, image, face, size, align_eyes):
+    def extract(self, image, face, size):
         """ Extract a face from an image """
-        logger.trace("size: %s. align_eyes: %s", size, align_eyes)
+        logger.trace("size: %s", size)
         padding = int(size * 0.1875)
-        alignment = get_align_mat(face, size, align_eyes)
+        alignment = get_align_mat(face)
         extracted = self.transform(image, alignment, size, padding)
         logger.trace("Returning face and alignment matrix: (alignment_matrix: %s)", alignment)
         return extracted, alignment
@@ -39,85 +38,73 @@ class Extract():
         logger.trace("matrix: %s, size: %s. padding: %s", mat, size, padding)
         matrix = self.transform_matrix(mat, size, padding)
         interpolators = get_matrix_scaling(matrix)
-        return cv2.warpAffine(  # pylint: disable=no-member
-            image, matrix, (size, size), flags=interpolators[0])
+        retval = cv2.warpAffine(image,  # pylint: disable=no-member
+                                matrix, (size, size), flags=interpolators[0])
+        return retval
 
     def transform_points(self, points, mat, size, padding=0):
         """ Transform points along matrix """
         logger.trace("points: %s, matrix: %s, size: %s. padding: %s", points, mat, size, padding)
         matrix = self.transform_matrix(mat, size, padding)
         points = np.expand_dims(points, axis=1)
-        points = cv2.transform(  # pylint: disable=no-member
-            points, matrix, points.shape)
+        points = cv2.transform(points,  # pylint: disable=no-member
+                               matrix, points.shape)
         retval = np.squeeze(points)
         logger.trace("Returning: %s", retval)
         return retval
 
     def get_original_roi(self, mat, size, padding=0):
-        """ Return the square aligned box location on the original
-            image """
+        """ Return the square aligned box location on the original image """
         logger.trace("matrix: %s, size: %s. padding: %s", mat, size, padding)
         matrix = self.transform_matrix(mat, size, padding)
-        points = np.array([[0, 0],
-                           [0, size - 1],
-                           [size - 1, size - 1],
-                           [size - 1, 0]], np.int32)
+        points = np.array([[0, 0], [0, size - 1], [size - 1, size - 1], [size - 1, 0]], np.int32)
         points = points.reshape((-1, 1, 2))
         matrix = cv2.invertAffineTransform(matrix)  # pylint: disable=no-member
         logger.trace("Returning: (points: %s, matrix: %s", points, matrix)
         return cv2.transform(points, matrix)  # pylint: disable=no-member
 
     @staticmethod
-    def get_feature_mask(aligned_landmarks_68, size,
-                         padding=0, dilation=30):
+    def get_feature_mask(aligned_landmarks_68, size, padding=0, dilation=30):
         """ Return the face feature mask """
-        # pylint: disable=no-member
         logger.trace("aligned_landmarks_68: %s, size: %s, padding: %s, dilation: %s",
                      aligned_landmarks_68, size, padding, dilation)
         scale = size - 2 * padding
         translation = padding
-        pad_mat = np.matrix([[scale, 0.0, translation],
-                             [0.0, scale, translation]])
+        pad_mat = np.matrix([[scale, 0.0, translation], [0.0, scale, translation]])
         aligned_landmarks_68 = np.expand_dims(aligned_landmarks_68, axis=1)
-        aligned_landmarks_68 = cv2.transform(aligned_landmarks_68,
+        aligned_landmarks_68 = cv2.transform(aligned_landmarks_68,  # pylint: disable=no-member
                                              pad_mat,
                                              aligned_landmarks_68.shape)
         aligned_landmarks_68 = np.squeeze(aligned_landmarks_68)
-
-        (l_start, l_end) = FACIAL_LANDMARKS_IDXS["left_eye"]
-        (r_start, r_end) = FACIAL_LANDMARKS_IDXS["right_eye"]
-        (m_start, m_end) = FACIAL_LANDMARKS_IDXS["mouth"]
-        (n_start, n_end) = FACIAL_LANDMARKS_IDXS["nose"]
-        (lb_start, lb_end) = FACIAL_LANDMARKS_IDXS["left_eyebrow"]
-        (rb_start, rb_end) = FACIAL_LANDMARKS_IDXS["right_eyebrow"]
-        (c_start, c_end) = FACIAL_LANDMARKS_IDXS["chin"]
-
-        l_eye_points = aligned_landmarks_68[l_start:l_end].tolist()
-        l_brow_points = aligned_landmarks_68[lb_start:lb_end].tolist()
-        r_eye_points = aligned_landmarks_68[r_start:r_end].tolist()
-        r_brow_points = aligned_landmarks_68[rb_start:rb_end].tolist()
-        nose_points = aligned_landmarks_68[n_start:n_end].tolist()
-        chin_points = aligned_landmarks_68[c_start:c_end].tolist()
-        mouth_points = aligned_landmarks_68[m_start:m_end].tolist()
-        l_eye_points = l_eye_points + l_brow_points
-        r_eye_points = r_eye_points + r_brow_points
-        mouth_points = mouth_points + nose_points + chin_points
-
-        l_eye_hull = cv2.convexHull(np.array(l_eye_points).reshape(
-            (-1, 2)).astype(int)).flatten().reshape((-1, 2))
-        r_eye_hull = cv2.convexHull(np.array(r_eye_points).reshape(
-            (-1, 2)).astype(int)).flatten().reshape((-1, 2))
-        mouth_hull = cv2.convexHull(np.array(mouth_points).reshape(
-            (-1, 2)).astype(int)).flatten().reshape((-1, 2))
+        l_eye_points = aligned_landmarks_68[42:48].tolist()
+        l_brow_points = aligned_landmarks_68[22:27].tolist()
+        r_eye_points = aligned_landmarks_68[36:42].tolist()
+        r_brow_points = aligned_landmarks_68[17:22].tolist()
+        nose_points = aligned_landmarks_68[27:36].tolist()
+        chin_points = aligned_landmarks_68[8:11].tolist()
+        mouth_points = aligned_landmarks_68[48:68].tolist()
+        # TODO remove excessive reshapes and flattens
+
+        l_eye = np.array(l_eye_points + l_brow_points).reshape((-1, 2)).astype(int).flatten()
+        r_eye = np.array(r_eye_points + r_brow_points).reshape((-1, 2)).astype(int).flatten()
+        mouth = np.array(mouth_points + nose_points + chin_points)
+        mouth = mouth.reshape((-1, 2)).astype(int).flatten()
+        l_eye_hull = cv2.convexHull(l_eye.reshape((-1, 2)))  # pylint: disable=no-member
+        r_eye_hull = cv2.convexHull(r_eye.reshape((-1, 2)))  # pylint: disable=no-member
+        mouth_hull = cv2.convexHull(mouth.reshape((-1, 2)))  # pylint: disable=no-member
 
         mask = np.zeros((size, size, 3), dtype=float)
-        cv2.fillConvexPoly(mask, l_eye_hull, (1, 1, 1))
-        cv2.fillConvexPoly(mask, r_eye_hull, (1, 1, 1))
-        cv2.fillConvexPoly(mask, mouth_hull, (1, 1, 1))
+        cv2.fillConvexPoly(mask,  # pylint: disable=no-member
+                           l_eye_hull, (1, 1, 1))
+        cv2.fillConvexPoly(mask,  # pylint: disable=no-member
+                           r_eye_hull, (1, 1, 1))
+        cv2.fillConvexPoly(mask,  # pylint: disable=no-member
+                           mouth_hull, (1, 1, 1))
 
         if dilation > 0:
             kernel = np.ones((dilation, dilation), np.uint8)
-            mask = cv2.dilate(mask, kernel, iterations=1)
+            mask = cv2.dilate(mask,  # pylint: disable=no-member
+                              kernel, iterations=1)
 
         logger.trace("Returning: %s", mask)
         return mask
@@ -128,53 +115,15 @@ def get_matrix_scaling(mat):
     x_scale = np.sqrt(mat[0, 0] * mat[0, 0] + mat[0, 1] * mat[0, 1])
     y_scale = (mat[0, 0] * mat[1, 1] - mat[0, 1] * mat[1, 0]) / x_scale
     avg_scale = (x_scale + y_scale) * 0.5
-    if avg_scale >= 1.0:
-        interpolators = cv2.INTER_CUBIC, cv2.INTER_AREA   # pylint: disable=no-member
+    if avg_scale >= 1.:
+        interpolators = cv2.INTER_CUBIC, cv2.INTER_AREA  # pylint: disable=no-member
     else:
         interpolators = cv2.INTER_AREA, cv2.INTER_CUBIC  # pylint: disable=no-member
     logger.trace("interpolator: %s, inverse interpolator: %s", interpolators[0], interpolators[1])
     return interpolators
 
 
-def get_align_mat(face, size, should_align_eyes):
+def get_align_mat(face):
     """ Return the alignment Matrix """
-    logger.trace("size: %s, should_align_eyes: %s", size, should_align_eyes)
     mat_umeyama = umeyama(np.array(face.landmarks_xy[17:]), True)[0:2]
-
-    if should_align_eyes is False:
-        return mat_umeyama
-
-    mat_umeyama = mat_umeyama * size
-
-    # Convert to matrix
-    landmarks = np.matrix(face.landmarks_xy)
-
-    # cv2 expects points to be in the form
-    # np.array([ [[x1, y1]], [[x2, y2]], ... ]), we'll expand the dim
-    landmarks = np.expand_dims(landmarks, axis=1)
-
-    # Align the landmarks using umeyama
-    umeyama_landmarks = cv2.transform(  # pylint: disable=no-member
-        landmarks,
-        mat_umeyama,
-        landmarks.shape)
-
-    # Determine a rotation matrix to align eyes horizontally
-    mat_align_eyes = func_align_eyes(umeyama_landmarks, size)
-
-    # Extend the 2x3 transform matrices to 3x3 so we can multiply them
-    # and combine them as one
-    mat_umeyama = np.matrix(mat_umeyama)
-    mat_umeyama.resize((3, 3))
-    mat_align_eyes = np.matrix(mat_align_eyes)
-    mat_align_eyes.resize((3, 3))
-    mat_umeyama[2] = mat_align_eyes[2] = [0, 0, 1]
-
-    # Combine the umeyama transform with the extra rotation matrix
-    transform_mat = mat_align_eyes * mat_umeyama
-
-    # Remove the extra row added, shape needs to be 2x3
-    transform_mat = np.delete(transform_mat, 2, 0)
-    transform_mat = transform_mat / size
-    logger.trace("Returning: %s", transform_mat)
-    return transform_mat
+    return mat_umeyama
diff --git a/lib/cli.py b/lib/cli.py
index 3706e45..9264e60 100644
--- a/lib/cli.py
+++ b/lib/cli.py
@@ -704,13 +704,6 @@ class ExtractArgs(ExtractConvertArgs):
                               "group": "output",
                               "default": False,
                               "help": "Draw landmarks on the ouput faces for debugging purposes."})
-        argument_list.append({"opts": ("-ae", "--align-eyes"),
-                              "action": "store_true",
-                              "dest": "align_eyes",
-                              "group": "output",
-                              "default": False,
-                              "help": "Perform extra alignment to ensure left/right eyes are at "
-                                      "the same height"})
         argument_list.append({"opts": ("-sp", "--singleprocess"),
                               "action": "store_true",
                               "default": False,
diff --git a/lib/faces_detect.py b/lib/faces_detect.py
index a4a4b58..b712988 100644
--- a/lib/faces_detect.py
+++ b/lib/faces_detect.py
@@ -141,7 +141,7 @@ class DetectedFace():
                            self.left: self.right]
 
     # <<< Aligned Face methods and properties >>> #
-    def load_aligned(self, image, size=256, align_eyes=False, dtype=None):
+    def load_aligned(self, image, size=256, dtype=None):
         """ Align a face from a given image.
 
         Aligning a face is a relatively expensive task and is not required for all uses of
@@ -175,13 +175,11 @@ class DetectedFace():
             # Don't reload an already aligned face
             logger.trace("Skipping alignment calculation for already aligned face")
         else:
-            logger.trace("Loading aligned face: (size: %s, align_eyes: %s, dtype: %s)",
-                         size, align_eyes, dtype)
+            logger.trace("Loading aligned face: (size: %s, dtype: %s)", size, dtype)
             padding = int(size * self._extract_ratio) // 2
             self.aligned["size"] = size
             self.aligned["padding"] = padding
-            self.aligned["align_eyes"] = align_eyes
-            self.aligned["matrix"] = get_align_mat(self, size, align_eyes)
+            self.aligned["matrix"] = get_align_mat(self)
             self.aligned["face"] = None
         if image is not None and self.aligned["face"] is None:
             logger.trace("Getting aligned face")
@@ -229,13 +227,10 @@ class DetectedFace():
 
         self.feed["size"] = size
         self.feed["padding"] = self._padding_from_coverage(size, coverage_ratio)
-        self.feed["matrix"] = get_align_mat(self, size, should_align_eyes=False)
+        self.feed["matrix"] = get_align_mat(self)
 
-        face = np.clip(AlignerExtract().transform(image,
-                                                  self.feed["matrix"],
-                                                  size,
-                                                  self.feed["padding"])[:, :, :3] / 255.0,
-                       0.0, 1.0)
+        face = AlignerExtract().transform(image, self.feed["matrix"], size, self.feed["padding"])
+        face = np.clip(face[:, :, :3] / 255., 0., 1.)
         self.feed["face"] = face if dtype is None else face.astype(dtype)
 
         logger.trace("Loaded feed face. (face_shape: %s, matrix: %s)",
@@ -268,13 +263,13 @@ class DetectedFace():
 
         self.reference["size"] = size
         self.reference["padding"] = self._padding_from_coverage(size, coverage_ratio)
-        self.reference["matrix"] = get_align_mat(self, size, should_align_eyes=False)
+        self.reference["matrix"] = get_align_mat(self)
 
-        face = np.clip(AlignerExtract().transform(image,
-                                                  self.reference["matrix"],
-                                                  size,
-                                                  self.reference["padding"])[:, :, :3] / 255.0,
-                       0.0, 1.0)
+        face = AlignerExtract().transform(image,
+                                          self.reference["matrix"],
+                                          size,
+                                          self.reference["padding"])
+        face = np.clip(face[:, :, :3] / 255., 0., 1.)
         self.reference["face"] = face if dtype is None else face.astype(dtype)
 
         logger.trace("Loaded reference face. (face_shape: %s, matrix: %s)",
diff --git a/plugins/train/trainer/_base.py b/plugins/train/trainer/_base.py
index 519eb60..65825a0 100644
--- a/plugins/train/trainer/_base.py
+++ b/plugins/train/trainer/_base.py
@@ -700,6 +700,6 @@ class Landmarks():
             for face in faces:
                 detected_face = DetectedFace()
                 detected_face.from_alignment(face)
-                detected_face.load_aligned(None, size=self.size, align_eyes=False)
+                detected_face.load_aligned(None, size=self.size)
                 landmarks[detected_face.hash] = detected_face.aligned_landmarks
         return landmarks
diff --git a/scripts/extract.py b/scripts/extract.py
index 28abb33..fabf9cd 100644
--- a/scripts/extract.py
+++ b/scripts/extract.py
@@ -190,13 +190,14 @@ class Extract():
             detected_faces = dict()
             self.extractor.launch()
             self.check_thread_error()
-            for idx, faces in enumerate(tqdm(self.extractor.detected_faces(),
-                                             total=to_process,
-                                             file=sys.stdout,
-                                             desc="Running pass {} of {}: {}".format(
-                                                 phase + 1,
-                                                 self.extractor.passes,
-                                                 self.extractor.phase.title()))):
+            desc = "Running pass {} of {}: {}".format(phase + 1,
+                                                      self.extractor.passes,
+                                                      self.extractor.phase.title())
+            status_bar = tqdm(self.extractor.detected_faces(),
+                              total=to_process,
+                              file=sys.stdout,
+                              desc=desc)
+            for idx, faces in enumerate(status_bar):
                 self.check_thread_error()
                 exception = faces.get("exception", False)
                 if exception:
@@ -204,13 +205,14 @@ class Extract():
                 filename = faces["filename"]
 
                 if self.extractor.final_pass:
-                    self.output_processing(faces, align_eyes, size, filename)
+                    self.output_processing(faces, size, filename)
                     self.output_faces(filename, faces)
                     if self.save_interval and (idx + 1) % self.save_interval == 0:
                         self.alignments.save()
                 else:
                     del faces["image"]
                     detected_faces[filename] = faces
+                status_bar.update(1)
 
             if is_final:
                 logger.debug("Putting EOF to save")
@@ -224,26 +226,25 @@ class Extract():
         for thread in self.threads:
             thread.check_and_raise_error()
 
-    def output_processing(self, faces, align_eyes, size, filename):
+    def output_processing(self, faces, size, filename):
         """ Prepare faces for output """
-        self.align_face(faces, align_eyes, size, filename)
+        self.align_face(faces, size, filename)
         self.post_process.do_actions(faces)
 
         faces_count = len(faces["detected_faces"])
         if faces_count == 0:
-            logger.verbose("No faces were detected in image: %s",
-                           os.path.basename(filename))
+            logger.verbose("No faces were detected in image: %s", os.path.basename(filename))
 
         if not self.verify_output and faces_count > 1:
             self.verify_output = True
 
-    def align_face(self, faces, align_eyes, size, filename):
+    def align_face(self, faces, size, filename):
         """ Align the detected face and add the destination file path """
         final_faces = list()
         image = faces["image"]
         detected_faces = faces["detected_faces"]
         for face in detected_faces:
-            face.load_aligned(image, size=size, align_eyes=align_eyes)
+            face.load_aligned(image, size=size)
             final_faces.append({"file_location": self.output_dir / Path(filename).stem,
                                 "face": face})
         faces["detected_faces"] = final_faces
diff --git a/tools/cli.py b/tools/cli.py
index f780e1d..3ff1fdc 100644
--- a/tools/cli.py
+++ b/tools/cli.py
@@ -40,16 +40,16 @@ class AlignmentsArgs(FaceSwapArgs):
                     "NB: All actions require an alignments file (-a) to be passed in."
                     "\nL|'draw': Draw landmarks on frames in the selected folder/video. A "
                     "subfolder will be created within the frames folder to hold the output." +
-                    frames_dir + align_eyes +
+                    frames_dir +
                     "\nL|'extract': Re-extract faces from the source frames/video based on "
                     "alignment data. This is a lot quicker than re-detecting faces. Can pass in "
                     "the '-een' (--extract-every-n) parameter to only extract every nth frame." +
                     frames_and_faces_dir + align_eyes +
-                    "\nL|'extract-large' - Extract all faces that have not been upscaled. Useful "
+                    "\nL|'extract-large': - Extract all faces that have not been upscaled. Useful "
                     "for excluding low-res images from a training set.. Can pass in the '-een' "
                     "(--extract-every-n) parameter to only extract every nth frame." +
                     frames_and_faces_dir + align_eyes +
-                    "\nL|'manual': Manually view and edit landmarks." + frames_dir + align_eyes +
+                    "\nL|'manual': Manually view and edit landmarks." + frames_dir +
                     "\nL|'merge': Merge multiple alignment files into one. Specify a space "
                     "separated list of alignments files with the -a flag. Optionally specify a "
                     "faces (-fc) folder to filter the final alignments file to only those faces "
@@ -158,9 +158,8 @@ class AlignmentsArgs(FaceSwapArgs):
                               "group": "extract",
                               "default": False,
                               "help": "Perform extra alignment to ensure "
-                                      "left/right eyes are  at the same "
-                                      "height. (Draw, Extract and manual "
-                                      "only)"})
+                                      "left/right eyes are at the same "
+                                      "height. (Extract only)"})
         argument_list.append({"opts": ("-dm", "--disable-monitor"),
                               "action": "store_true",
                               "group": "manual tool",
diff --git a/tools/lib_alignments/annotate.py b/tools/lib_alignments/annotate.py
index 6c27b4d..2ad6112 100644
--- a/tools/lib_alignments/annotate.py
+++ b/tools/lib_alignments/annotate.py
@@ -6,8 +6,6 @@ import logging
 import cv2
 import numpy as np
 
-from lib.align_eyes import FACIAL_LANDMARKS_IDXS
-
 logger = logging.getLogger(__name__)  # pylint: disable=invalid-name
 
 
@@ -32,7 +30,7 @@ class Annotate():
         """ Change image to black at correct dimensions """
         logger.trace("Drawing black image")
         height, width = self.image.shape[:2]
-        self.image = np.zeros((height, width, 3), np.uint8)
+        self.image = np.zeros((height, width, 3), dtype="uint8")
 
     def draw_bounding_box(self, color_id=1, thickness=1):
         """ Draw the bounding box around faces """
@@ -43,10 +41,7 @@ class Annotate():
             logger.trace("Drawing bounding box: (top_left: %s, bottom_right: %s, color: %s, "
                          "thickness: %s)", top_left, bottom_right, color, thickness)
             cv2.rectangle(self.image,  # pylint: disable=no-member
-                          top_left,
-                          bottom_right,
-                          color,
-                          thickness)
+                          top_left, bottom_right, color, thickness)
 
     def draw_extract_box(self, color_id=2, thickness=1):
         """ Draw the extracted face box """
@@ -65,6 +60,7 @@ class Annotate():
                         color,
                         thickness)
             cv2.polylines(self.image, [roi], True, color, thickness)  # pylint: disable=no-member
+                          
 
     def draw_landmarks(self, color_id=3, radius=1):
         """ Draw the facial landmarks """
@@ -75,14 +71,19 @@ class Annotate():
                          landmarks, color, radius)
             for (pos_x, pos_y) in landmarks:
                 cv2.circle(self.image,  # pylint: disable=no-member
-                           (pos_x, pos_y),
-                           radius,
-                           color,
-                           -1)
+                           (pos_x, pos_y), radius, color, -1)
 
     def draw_landmarks_mesh(self, color_id=4, thickness=1):
         """ Draw the facial landmarks """
         color = self.colors[color_id]
+        FACIAL_LANDMARKS_IDXS = OrderedDict([("mouth", (48, 68)),
+                                             ("right_eyebrow", (17, 22)),
+                                             ("left_eyebrow", (22, 27)),
+                                             ("right_eye", (36, 42)),
+                                             ("left_eye", (42, 48)),
+                                             ("nose", (27, 36)),
+                                             ("jaw", (0, 17)),
+                                             ("chin", (8, 11))])
         for alignment in self.alignments:
             landmarks = alignment["landmarks_xy"]
             logger.trace("Drawing Landmarks Mesh: (landmarks: %s, color: %s, thickness: %s)",
@@ -91,10 +92,7 @@ class Annotate():
                 points = np.array([landmarks[val[0]:val[1]]], np.int32)
                 fill_poly = bool(key in ("right_eye", "left_eye", "mouth"))
                 cv2.polylines(self.image,  # pylint: disable=no-member
-                              points,
-                              fill_poly,
-                              color,
-                              thickness)
+                              points, fill_poly, color, thickness)
 
     def draw_grey_out_faces(self, live_face):
         """ Grey out all faces except target """
@@ -106,9 +104,6 @@ class Annotate():
             if idx != int(live_face):
                 logger.trace("Greying out face: (idx: %s, roi: %s)", idx, roi)
                 cv2.fillPoly(overlay, roi, (0, 0, 0))  # pylint: disable=no-member
+                             
         cv2.addWeighted(overlay,  # pylint: disable=no-member
-                        alpha,
-                        self.image,
-                        1 - alpha,
-                        0,
-                        self.image)
+                        alpha, self.image, 1. - alpha, 0., self.image)
diff --git a/tools/lib_alignments/jobs.py b/tools/lib_alignments/jobs.py
index 55b6925..80178e9 100644
--- a/tools/lib_alignments/jobs.py
+++ b/tools/lib_alignments/jobs.py
@@ -287,8 +287,7 @@ class Draw():
         legacy.process()
 
         logger.info("[DRAW LANDMARKS]")  # Tidy up cli output
-        self.extracted_faces = ExtractedFaces(self.frames, self.alignments, size=256,
-                                              align_eyes=self.arguments.align_eyes)
+        self.extracted_faces = ExtractedFaces(self.frames, self.alignments, size=256)
         frames_drawn = 0
         for frame in tqdm(self.frames.file_list_sorted, desc="Drawing landmarks"):
             frame_name = frame["frame_fullname"]
@@ -329,7 +328,9 @@ class Extract():
         self.type = arguments.job.replace("extract-", "")
         self.faces_dir = arguments.faces_dir
         self.frames = Frames(arguments.frames_dir)
-        self.extracted_faces = ExtractedFaces(self.frames, self.alignments, size=arguments.size,
+        self.extracted_faces = ExtractedFaces(self.frames,
+                                              self.alignments,
+                                              size=arguments.size,
                                               align_eyes=arguments.align_eyes)
         logger.debug("Initialized %s", self.__class__.__name__)
 
diff --git a/tools/lib_alignments/jobs_manual.py b/tools/lib_alignments/jobs_manual.py
index f5d2810..53408a6 100644
--- a/tools/lib_alignments/jobs_manual.py
+++ b/tools/lib_alignments/jobs_manual.py
@@ -445,7 +445,6 @@ class Manual():
                      self.__class__.__name__, alignments, arguments)
         self.arguments = arguments
         self.alignments = alignments
-        self.align_eyes = arguments.align_eyes
         self.frames = Frames(arguments.frames_dir)
         self.extracted_faces = None
         self.interface = None
@@ -460,8 +459,7 @@ class Manual():
         legacy.process()
 
         logger.info("[MANUAL PROCESSING]")  # Tidy up cli output
-        self.extracted_faces = ExtractedFaces(self.frames, self.alignments, size=256,
-                                              align_eyes=self.align_eyes)
+        self.extracted_faces = ExtractedFaces(self.frames, self.alignments, size=256)
         self.interface = Interface(self.alignments, self.frames)
         self.help = Help(self.interface)
         self.mouse_handler = MouseHandler(self.interface, self.arguments.loglevel)
diff --git a/tools/lib_alignments/media.py b/tools/lib_alignments/media.py
index 05050dd..6dd867c 100644
--- a/tools/lib_alignments/media.py
+++ b/tools/lib_alignments/media.py
@@ -4,12 +4,14 @@
 
 import logging
 import os
+import cv2
+import numpy as np
 from tqdm import tqdm
 
-import cv2
 # TODO imageio single frame seek seems slow. Look into this
 # import imageio
 
+from lib.aligner import Extract as AlignerExtract
 from lib.alignments import Alignments
 from lib.faces_detect import DetectedFace
 from lib.utils import (_image_extensions, _video_extensions, count_frames_and_secs, cv2_read_img,
@@ -192,6 +194,7 @@ class MediaLoader():
     def save_image(output_folder, filename, image):
         """ Save an image """
         output_file = os.path.join(output_folder, filename)
+        output_file = os.path.splitext(output_file)[0]+'.png'
         logger.trace("Saving image: '%s'", output_file)
         cv2.imwrite(output_file, image)  # pylint: disable=no-member
 
@@ -291,14 +294,12 @@ class ExtractedFaces():
     """ Holds the extracted faces and matrix for
         alignments """
     def __init__(self, frames, alignments, size=256, align_eyes=False):
-        logger.trace("Initializing %s: (size: %s, align_eyes: %s)",
-                     self.__class__.__name__, size, align_eyes)
+        logger.trace("Initializing %s: size: %s", self.__class__.__name__, size)
         self.size = size
         self.padding = int(size * 0.1875)
-        self.align_eyes = align_eyes
+        self.align_eyes_bool = align_eyes
         self.alignments = alignments
         self.frames = frames
-
         self.current_frame = None
         self.faces = list()
         logger.trace("Initialized %s", self.__class__.__name__)
@@ -314,8 +315,7 @@ class ExtractedFaces():
             self.faces = list()
             return
         image = self.frames.load_image(frame)
-        self.faces = [self.extract_one_face(alignment, image.copy())
-                      for alignment in alignments]
+        self.faces = [self.extract_one_face(alignment, image.copy()) for alignment in alignments]
         self.current_frame = frame
 
     def extract_one_face(self, alignment, image):
@@ -324,7 +324,8 @@ class ExtractedFaces():
                      self.current_frame, alignment)
         face = DetectedFace()
         face.from_alignment(alignment, image=image)
-        face.load_aligned(image, size=self.size, align_eyes=self.align_eyes)
+        face.load_aligned(image, size=self.size)
+        face = self.align_eyes(face, image) if self.align_eyes_bool else face
         return face
 
     def get_faces_in_frame(self, frame, update=False):
@@ -362,3 +363,28 @@ class ExtractedFaces():
         with open(filename, "wb") as out_file:
             out_file.write(img)
         return f_hash
+
+    def align_eyes(self, face, image):
+        """ Re-extract a face with the pupils forced to be absolutely horizontally aligned """
+        umeyama_landmarks = face.aligned_landmarks
+        leftEyeCenter = umeyama_landmarks[42:48].mean(axis=0)
+        rightEyeCenter = umeyama_landmarks[36:42].mean(axis=0)
+        eyesCenter = umeyama_landmarks[36:48].mean(axis=0)
+        dY = rightEyeCenter[1] - leftEyeCenter[1]
+        dX = rightEyeCenter[0] - leftEyeCenter[0]
+        theta = np.pi - np.arctan2(dY, dX)
+        rot_cos = np.cos(theta)
+        rot_sin = np.sin(theta)
+        rotation_matrix = np.array([[rot_cos, -rot_sin, 0.],
+                                    [rot_sin, rot_cos, 0.],
+                                    [0., 0., 1.]])
+
+        mat_umeyama = np.concatenate((face.aligned["matrix"], np.array([[0., 0., 1.]])), axis=0)
+        corrected_mat = np.dot(rotation_matrix, mat_umeyama)
+        face.aligned["matrix"] = corrected_mat[:2]
+        face.aligned["face"] = AlignerExtract().transform(image,
+                                                          face.aligned["matrix"],
+                                                          face.aligned["size"],
+                                                          int(face.aligned["size"] * 0.375) // 2)
+        logger.trace("Adjusted matrix: %s", face.aligned["matrix"])
+        return face
diff --git a/tools/preview.py b/tools/preview.py
index 2d11e63..87595c0 100644
--- a/tools/preview.py
+++ b/tools/preview.py
@@ -457,7 +457,7 @@ class FacesDisplay():
         for image in self.source:
             detected_face = image["detected_faces"][0]
             src_img = image["image"]
-            detected_face.load_aligned(src_img, self.size, align_eyes=False)
+            detected_face.load_aligned(src_img, self.size)
             matrix = detected_face.aligned["matrix"]
             self.faces.setdefault("filenames",
                                   list()).append(os.path.splitext(image["filename"])[0])
