commit 6bb4df43091ea7c2672eb1d86042197e919de9cd
Author: Othniel Cundangan <othniel.cundangan@gmail.com>
Date:   Fri Mar 9 21:04:32 2018 -0500

    Fix line endings (#266)
    
    * Remove files with line-ending issues
    
    * Add back files with line-ending issues

diff --git a/scripts/convert.py b/scripts/convert.py
index ad67e6c..e06f4db 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -1,235 +1,235 @@
-import cv2
-import re
-import os
-
-from pathlib import Path
-from tqdm import tqdm
-
-from lib.cli import DirectoryProcessor, FullPaths
-from lib.utils import BackgroundGenerator, get_folder, get_image_paths
-
-from plugins.PluginLoader import PluginLoader
-
-class ConvertImage(DirectoryProcessor):
-    filename = ''
-    def create_parser(self, subparser, command, description):
-        self.parser = subparser.add_parser(
-            command,
-            help="Convert a source image to a new one with the face swapped.",
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground"
-        )
-
-    def add_optional_arguments(self, parser):
-        parser.add_argument('-m', '--model-dir',
-                            action=FullPaths,
-                            dest="model_dir",
-                            default="models",
-                            help="Model directory. A directory containing the trained model \
-                            you wish to process. Defaults to 'models'")
-
-        parser.add_argument('-a', '--input-aligned-dir',
-                            action=FullPaths,
-                            dest="input_aligned_dir",
-                            default=None,
-                            help="Input \"aligned directory\". A directory that should contain the \
-                            aligned faces extracted from the input files. If you delete faces from \
-                            this folder, they'll be skipped during conversion. If no aligned dir is \
-                            specified, all faces will be converted.")
-
-        parser.add_argument('-t', '--trainer',
-                            type=str,
-                            choices=("Original", "LowMem", "GAN", "GAN128"), # case sensitive because this is used to load a plug-in.
-                            default="Original",
-                            help="Select the trainer that was used to create the model.")
-
-        parser.add_argument('-s', '--swap-model',
-                            action="store_true",
-                            dest="swap_model",
-                            default=False,
-                            help="Swap the model. Instead of A -> B, swap B -> A.")
-
-        parser.add_argument('-c', '--converter',
-                            type=str,
-                            choices=("Masked", "Adjust"), # case sensitive because this is used to load a plugin.
-                            default="Masked",
-                            help="Converter to use.")
-
-        parser.add_argument('-D', '--detector',
-                            type=str,
-                            choices=("hog", "cnn"), # case sensitive because this is used to load a plugin.
-                            default="hog",
-                            help="Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files.")
-
-        parser.add_argument('-fr', '--frame-ranges',
-                            nargs="+",
-                            type=str,
-                            help="frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 use --frame-ranges 10-50 90-100. \
-                            Files must have the frame-number as the last number in the name!"
-                            )
-
-        parser.add_argument('-d', '--discard-frames',
-                            action="store_true",
-                            dest="discard_frames",
-                            default=False,
-                            help="When used with --frame-ranges discards frames that are not processed instead of writing them out unchanged."
-                            )
-
-        parser.add_argument('-f', '--filter',
-                            type=str,
-                            dest="filter",
-                            default="filter.jpg",
-                            help="Reference image for the person you want to process. Should be a front portrait"
-                            )
-
-        parser.add_argument('-b', '--blur-size',
-                            type=int,
-                            default=2,
-                            help="Blur size. (Masked converter only)")
-
-
-        parser.add_argument('-S', '--seamless',
-                            action="store_true",
-                            dest="seamless_clone",
-                            default=False,
-                            help="Use cv2's seamless clone. (Masked converter only)")
-
-        parser.add_argument('-M', '--mask-type',
-                            type=str.lower, #lowercase this, because its just a string later on.
-                            dest="mask_type",
-                            choices=["rect", "facehull", "facehullandrect"],
-                            default="facehullandrect",
-                            help="Mask to use to replace faces. (Masked converter only)")
-
-        parser.add_argument('-e', '--erosion-kernel-size',
-                            dest="erosion_kernel_size",
-                            type=int,
-                            default=None,
-                            help="Erosion kernel size. (Masked converter only). Positive values apply erosion which reduces the edge of the swapped face. Negative values apply dilation which allows the swapped face to cover more space.")
-
-        parser.add_argument('-mh', '--match-histgoram',
-                            action="store_true",
-                            dest="match_histogram",
-                            default=False,
-                            help="Use histogram matching. (Masked converter only)")
-
-        parser.add_argument('-sm', '--smooth-mask',
-                            action="store_true",
-                            dest="smooth_mask",
-                            default=True,
-                            help="Smooth mask (Adjust converter only)")
-
-        parser.add_argument('-aca', '--avg-color-adjust',
-                            action="store_true",
-                            dest="avg_color_adjust",
-                            default=True,
-                            help="Average color adjust. (Adjust converter only)")
-        return parser
-
-    def process(self):
-        # Original & LowMem models go with Adjust or Masked converter
-        # Note: GAN prediction outputs a mask + an image, while other predicts only an image
-        model_name = self.arguments.trainer
-        conv_name = self.arguments.converter
-        self.input_aligned_dir = None
-
-        model = PluginLoader.get_model(model_name)(get_folder(self.arguments.model_dir))
-        if not model.load(self.arguments.swap_model):
-            print('Model Not Found! A valid model must be provided to continue!')
-            exit(1)
-
-        input_aligned_dir = Path(self.arguments.input_dir)/Path('aligned')
-        if self.arguments.input_aligned_dir is not None:
-            input_aligned_dir = self.arguments.input_aligned_dir
-        try:
-            self.input_aligned_dir = [Path(path) for path in get_image_paths(input_aligned_dir)]
-            if len(self.input_aligned_dir) == 0:
-                print('Aligned directory is empty, no faces will be converted!')
-            elif len(self.input_aligned_dir) <= len(self.input_dir)/3:
-                print('Aligned directory contains an amount of images much less than the input, are you sure this is the right directory?')
-        except:
-            print('Aligned directory not found. All faces listed in the alignments file will be converted.')
-
-        converter = PluginLoader.get_converter(conv_name)(model.converter(False),
-            trainer=self.arguments.trainer,
-            blur_size=self.arguments.blur_size,
-            seamless_clone=self.arguments.seamless_clone,
-            mask_type=self.arguments.mask_type,
-            erosion_kernel_size=self.arguments.erosion_kernel_size,
-            match_histogram=self.arguments.match_histogram,
-            smooth_mask=self.arguments.smooth_mask,
-            avg_color_adjust=self.arguments.avg_color_adjust
-        )
-
-        batch = BackgroundGenerator(self.prepare_images(), 1)
-
-        # frame ranges stuff...
-        self.frame_ranges = None
-
-        # split out the frame ranges and parse out "min" and "max" values
-        minmax = {
-            "min": 0, # never any frames less than 0
-            "max": float("inf")
-        }
-
-        if self.arguments.frame_ranges:
-            self.frame_ranges = [tuple(map(lambda q: minmax[q] if q in minmax.keys() else int(q), v.split("-"))) for v in self.arguments.frame_ranges]
-
-        # last number regex. I know regex is hacky, but its reliablyhacky(tm).
-        self.imageidxre = re.compile(r'(\d+)(?!.*\d)')
-
-        for item in batch.iterator():
-            self.convert(converter, item)
-
-    def check_skipframe(self, filename):
-        try:
-            idx = int(self.imageidxre.findall(filename)[0])
-            return not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
-        except:
-            return False
-
-    def check_skipface(self, filename, face_idx):
-        aligned_face_name = '{}_{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
-        aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(aligned_face_name)
-        # TODO: Remove this temporary fix for backwards compatibility of filenames
-        bk_compat_aligned_face_name = '{}{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
-        bk_compat_aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(bk_compat_aligned_face_name)
-        return aligned_face_file not in self.input_aligned_dir and bk_compat_aligned_face_file not in self.input_aligned_dir
-
-    def convert(self, converter, item):
-        try:
-            (filename, image, faces) = item
-
-            skip = self.check_skipframe(filename)
-            if self.arguments.discard_frames and skip:
-                return
-
-            if not skip: # process frame as normal
-                for idx, face in faces:
-                    if self.input_aligned_dir is not None and self.check_skipface(filename, idx):
-                        print ('face {} for frame {} was deleted, skipping'.format(idx, os.path.basename(filename)))
-                        continue
-                    image = converter.patch_image(image, face, 64 if "128" not in self.arguments.trainer else 128)
-                    # TODO: This switch between 64 and 128 is a hack for now. We should have a separate cli option for size
-
-            output_file = get_folder(self.output_dir) / Path(filename).name
-            cv2.imwrite(str(output_file), image)
-        except Exception as e:
-            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
-
-    def prepare_images(self):
-        self.read_alignments()
-        is_have_alignments = self.have_alignments()
-        for filename in tqdm(self.read_directory()):
-            image = cv2.imread(filename)
-
-            if is_have_alignments:
-                if self.have_face(filename):
-                    faces = self.get_faces_alignments(filename, image)
-                else:
-                    print ('no alignment found for {}, skipping'.format(os.path.basename(filename)))
-                    continue
-            else:
-                faces = self.get_faces(image)
-            yield filename, image, faces
+import cv2
+import re
+import os
+
+from pathlib import Path
+from tqdm import tqdm
+
+from lib.cli import DirectoryProcessor, FullPaths
+from lib.utils import BackgroundGenerator, get_folder, get_image_paths
+
+from plugins.PluginLoader import PluginLoader
+
+class ConvertImage(DirectoryProcessor):
+    filename = ''
+    def create_parser(self, subparser, command, description):
+        self.parser = subparser.add_parser(
+            command,
+            help="Convert a source image to a new one with the face swapped.",
+            description=description,
+            epilog="Questions and feedback: \
+            https://github.com/deepfakes/faceswap-playground"
+        )
+
+    def add_optional_arguments(self, parser):
+        parser.add_argument('-m', '--model-dir',
+                            action=FullPaths,
+                            dest="model_dir",
+                            default="models",
+                            help="Model directory. A directory containing the trained model \
+                            you wish to process. Defaults to 'models'")
+
+        parser.add_argument('-a', '--input-aligned-dir',
+                            action=FullPaths,
+                            dest="input_aligned_dir",
+                            default=None,
+                            help="Input \"aligned directory\". A directory that should contain the \
+                            aligned faces extracted from the input files. If you delete faces from \
+                            this folder, they'll be skipped during conversion. If no aligned dir is \
+                            specified, all faces will be converted.")
+
+        parser.add_argument('-t', '--trainer',
+                            type=str,
+                            choices=("Original", "LowMem", "GAN", "GAN128"), # case sensitive because this is used to load a plug-in.
+                            default="Original",
+                            help="Select the trainer that was used to create the model.")
+
+        parser.add_argument('-s', '--swap-model',
+                            action="store_true",
+                            dest="swap_model",
+                            default=False,
+                            help="Swap the model. Instead of A -> B, swap B -> A.")
+
+        parser.add_argument('-c', '--converter',
+                            type=str,
+                            choices=("Masked", "Adjust"), # case sensitive because this is used to load a plugin.
+                            default="Masked",
+                            help="Converter to use.")
+
+        parser.add_argument('-D', '--detector',
+                            type=str,
+                            choices=("hog", "cnn"), # case sensitive because this is used to load a plugin.
+                            default="hog",
+                            help="Detector to use. 'cnn' detects much more angles but will be much more resource intensive and may fail on large files.")
+
+        parser.add_argument('-fr', '--frame-ranges',
+                            nargs="+",
+                            type=str,
+                            help="frame ranges to apply transfer to e.g. For frames 10 to 50 and 90 to 100 use --frame-ranges 10-50 90-100. \
+                            Files must have the frame-number as the last number in the name!"
+                            )
+
+        parser.add_argument('-d', '--discard-frames',
+                            action="store_true",
+                            dest="discard_frames",
+                            default=False,
+                            help="When used with --frame-ranges discards frames that are not processed instead of writing them out unchanged."
+                            )
+
+        parser.add_argument('-f', '--filter',
+                            type=str,
+                            dest="filter",
+                            default="filter.jpg",
+                            help="Reference image for the person you want to process. Should be a front portrait"
+                            )
+
+        parser.add_argument('-b', '--blur-size',
+                            type=int,
+                            default=2,
+                            help="Blur size. (Masked converter only)")
+
+
+        parser.add_argument('-S', '--seamless',
+                            action="store_true",
+                            dest="seamless_clone",
+                            default=False,
+                            help="Use cv2's seamless clone. (Masked converter only)")
+
+        parser.add_argument('-M', '--mask-type',
+                            type=str.lower, #lowercase this, because its just a string later on.
+                            dest="mask_type",
+                            choices=["rect", "facehull", "facehullandrect"],
+                            default="facehullandrect",
+                            help="Mask to use to replace faces. (Masked converter only)")
+
+        parser.add_argument('-e', '--erosion-kernel-size',
+                            dest="erosion_kernel_size",
+                            type=int,
+                            default=None,
+                            help="Erosion kernel size. (Masked converter only). Positive values apply erosion which reduces the edge of the swapped face. Negative values apply dilation which allows the swapped face to cover more space.")
+
+        parser.add_argument('-mh', '--match-histgoram',
+                            action="store_true",
+                            dest="match_histogram",
+                            default=False,
+                            help="Use histogram matching. (Masked converter only)")
+
+        parser.add_argument('-sm', '--smooth-mask',
+                            action="store_true",
+                            dest="smooth_mask",
+                            default=True,
+                            help="Smooth mask (Adjust converter only)")
+
+        parser.add_argument('-aca', '--avg-color-adjust',
+                            action="store_true",
+                            dest="avg_color_adjust",
+                            default=True,
+                            help="Average color adjust. (Adjust converter only)")
+        return parser
+
+    def process(self):
+        # Original & LowMem models go with Adjust or Masked converter
+        # Note: GAN prediction outputs a mask + an image, while other predicts only an image
+        model_name = self.arguments.trainer
+        conv_name = self.arguments.converter
+        self.input_aligned_dir = None
+
+        model = PluginLoader.get_model(model_name)(get_folder(self.arguments.model_dir))
+        if not model.load(self.arguments.swap_model):
+            print('Model Not Found! A valid model must be provided to continue!')
+            exit(1)
+
+        input_aligned_dir = Path(self.arguments.input_dir)/Path('aligned')
+        if self.arguments.input_aligned_dir is not None:
+            input_aligned_dir = self.arguments.input_aligned_dir
+        try:
+            self.input_aligned_dir = [Path(path) for path in get_image_paths(input_aligned_dir)]
+            if len(self.input_aligned_dir) == 0:
+                print('Aligned directory is empty, no faces will be converted!')
+            elif len(self.input_aligned_dir) <= len(self.input_dir)/3:
+                print('Aligned directory contains an amount of images much less than the input, are you sure this is the right directory?')
+        except:
+            print('Aligned directory not found. All faces listed in the alignments file will be converted.')
+
+        converter = PluginLoader.get_converter(conv_name)(model.converter(False),
+            trainer=self.arguments.trainer,
+            blur_size=self.arguments.blur_size,
+            seamless_clone=self.arguments.seamless_clone,
+            mask_type=self.arguments.mask_type,
+            erosion_kernel_size=self.arguments.erosion_kernel_size,
+            match_histogram=self.arguments.match_histogram,
+            smooth_mask=self.arguments.smooth_mask,
+            avg_color_adjust=self.arguments.avg_color_adjust
+        )
+
+        batch = BackgroundGenerator(self.prepare_images(), 1)
+
+        # frame ranges stuff...
+        self.frame_ranges = None
+
+        # split out the frame ranges and parse out "min" and "max" values
+        minmax = {
+            "min": 0, # never any frames less than 0
+            "max": float("inf")
+        }
+
+        if self.arguments.frame_ranges:
+            self.frame_ranges = [tuple(map(lambda q: minmax[q] if q in minmax.keys() else int(q), v.split("-"))) for v in self.arguments.frame_ranges]
+
+        # last number regex. I know regex is hacky, but its reliablyhacky(tm).
+        self.imageidxre = re.compile(r'(\d+)(?!.*\d)')
+
+        for item in batch.iterator():
+            self.convert(converter, item)
+
+    def check_skipframe(self, filename):
+        try:
+            idx = int(self.imageidxre.findall(filename)[0])
+            return not any(map(lambda b: b[0]<=idx<=b[1], self.frame_ranges))
+        except:
+            return False
+
+    def check_skipface(self, filename, face_idx):
+        aligned_face_name = '{}_{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
+        aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(aligned_face_name)
+        # TODO: Remove this temporary fix for backwards compatibility of filenames
+        bk_compat_aligned_face_name = '{}{}{}'.format(Path(filename).stem, face_idx, Path(filename).suffix)
+        bk_compat_aligned_face_file = Path(self.arguments.input_aligned_dir) / Path(bk_compat_aligned_face_name)
+        return aligned_face_file not in self.input_aligned_dir and bk_compat_aligned_face_file not in self.input_aligned_dir
+
+    def convert(self, converter, item):
+        try:
+            (filename, image, faces) = item
+
+            skip = self.check_skipframe(filename)
+            if self.arguments.discard_frames and skip:
+                return
+
+            if not skip: # process frame as normal
+                for idx, face in faces:
+                    if self.input_aligned_dir is not None and self.check_skipface(filename, idx):
+                        print ('face {} for frame {} was deleted, skipping'.format(idx, os.path.basename(filename)))
+                        continue
+                    image = converter.patch_image(image, face, 64 if "128" not in self.arguments.trainer else 128)
+                    # TODO: This switch between 64 and 128 is a hack for now. We should have a separate cli option for size
+
+            output_file = get_folder(self.output_dir) / Path(filename).name
+            cv2.imwrite(str(output_file), image)
+        except Exception as e:
+            print('Failed to convert image: {}. Reason: {}'.format(filename, e))
+
+    def prepare_images(self):
+        self.read_alignments()
+        is_have_alignments = self.have_alignments()
+        for filename in tqdm(self.read_directory()):
+            image = cv2.imread(filename)
+
+            if is_have_alignments:
+                if self.have_face(filename):
+                    faces = self.get_faces_alignments(filename, image)
+                else:
+                    print ('no alignment found for {}, skipping'.format(os.path.basename(filename)))
+                    continue
+            else:
+                faces = self.get_faces(image)
+            yield filename, image, faces
diff --git a/scripts/train.py b/scripts/train.py
index e8b1e57..72ab106 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -1,199 +1,199 @@
-import cv2
-import numpy
-import time
-
-from threading import Lock
-from lib.utils import get_image_paths, get_folder
-from lib.cli import FullPaths
-from plugins.PluginLoader import PluginLoader
-
-class TrainingProcessor(object):
-    arguments = None
-
-    def __init__(self, subparser, command, description='default'):
-        self.parse_arguments(description, subparser, command)
-        self.lock = Lock()
-
-    def process_arguments(self, arguments):
-        self.arguments = arguments
-        print("Model A Directory: {}".format(self.arguments.input_A))
-        print("Model B Directory: {}".format(self.arguments.input_B))
-        print("Training data directory: {}".format(self.arguments.model_dir))
-
-        self.process()
-
-    def parse_arguments(self, description, subparser, command):
-        parser = subparser.add_parser(
-            command,
-            help="This command trains the model for the two faces A and B.",
-            description=description,
-            epilog="Questions and feedback: \
-            https://github.com/deepfakes/faceswap-playground"
-        )
-
-        parser.add_argument('-A', '--input-A',
-                            action=FullPaths,
-                            dest="input_A",
-                            default="input_A",
-                            help="Input directory. A directory containing training images for face A.\
-                             Defaults to 'input'")
-        parser.add_argument('-B', '--input-B',
-                            action=FullPaths,
-                            dest="input_B",
-                            default="input_B",
-                            help="Input directory. A directory containing training images for face B.\
-                             Defaults to 'input'")
-        parser.add_argument('-m', '--model-dir',
-                            action=FullPaths,
-                            dest="model_dir",
-                            default="models",
-                            help="Model directory. This is where the training data will \
-                                be stored. Defaults to 'model'")
-        parser.add_argument('-p', '--preview',
-                            action="store_true",
-                            dest="preview",
-                            default=False,
-                            help="Show preview output. If not specified, write progress \
-                            to file.")
-        parser.add_argument('-v', '--verbose',
-                            action="store_true",
-                            dest="verbose",
-                            default=False,
-                            help="Show verbose output")
-        parser.add_argument('-s', '--save-interval',
-                            type=int,
-                            dest="save_interval",
-                            default=100,
-                            help="Sets the number of iterations before saving the model.")
-        parser.add_argument('-w', '--write-image',
-                            action="store_true",
-                            dest="write_image",
-                            default=False,
-                            help="Writes the training result to a file even on preview mode.")
-        parser.add_argument('-t', '--trainer',
-                            type=str,
-                            choices=("Original", "LowMem", "GAN", "GAN128"),
-                            default="Original",
-                            help="Select which trainer to use, LowMem for cards < 2gb.")
-        parser.add_argument('-pl', '--use-perceptual-loss',
-                            action="store_true",
-                            dest="perceptual_loss",
-                            default=False,
-                            help="Use perceptual loss while training")
-        parser.add_argument('-bs', '--batch-size',
-                            type=int,
-                            default=64,
-                            help="Batch size, as a power of 2 (64, 128, 256, etc)")
-        parser.add_argument('-ag', '--allow-growth',
-                            action="store_true",
-                            dest="allow_growth",
-                            default=False,
-                            help="Sets allow_growth option of Tensorflow to spare memory on some configs")
-        parser.add_argument('-ep', '--epochs',
-                            type=int,
-                            default=1000000,
-                            help="Length of training in epochs.")
-        parser = self.add_optional_arguments(parser)
-        parser.set_defaults(func=self.process_arguments)
-
-    def add_optional_arguments(self, parser):
-        # Override this for custom arguments
-        return parser
-
-    def process(self):
-        import threading
-        self.stop = False
-        self.save_now = False
-
-        thr = threading.Thread(target=self.processThread, args=(), kwargs={})
-        thr.start()
-
-        if self.arguments.preview:
-            print('Using live preview')
-            while True:
-                try:
-                    with self.lock:
-                        for name, image in self.preview_buffer.items():
-                            cv2.imshow(name, image)
-
-                    key = cv2.waitKey(1000)
-                    if key == ord('\n') or key == ord('\r'):
-                        break
-                    if key == ord('s'):
-                        self.save_now = True
-                except KeyboardInterrupt:
-                    break
-        else:
-            input() # TODO how to catch a specific key instead of Enter?
-            # there isnt a good multiplatform solution: https://stackoverflow.com/questions/3523174/raw-input-in-python-without-pressing-enter
-
-        print("Exit requested! The trainer will complete its current cycle, save the models and quit (it can take up a couple of seconds depending on your training speed). If you want to kill it now, press Ctrl + c")
-        self.stop = True
-        thr.join() # waits until thread finishes
-
-    def processThread(self):
-        if self.arguments.allow_growth:
-            self.set_tf_allow_growth()
-
-        print('Loading data, this may take a while...')
-        # this is so that you can enter case insensitive values for trainer
-        trainer = self.arguments.trainer
-        trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
-        model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir))
-        model.load(swapped=False)
-
-        images_A = get_image_paths(self.arguments.input_A)
-        images_B = get_image_paths(self.arguments.input_B)
-        trainer = PluginLoader.get_trainer(trainer)
-        trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
-
-        try:
-            print('Starting. Press "Enter" to stop training and save model')
-
-            for epoch in range(0, self.arguments.epochs):
-
-                save_iteration = epoch % self.arguments.save_interval == 0
-
-                trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
-
-                if save_iteration:
-                    model.save_weights()
-
-                if self.stop:
-                    model.save_weights()
-                    exit()
-
-                if self.save_now:
-                    model.save_weights()
-                    self.save_now = False
-
-        except KeyboardInterrupt:
-            try:
-                model.save_weights()
-            except KeyboardInterrupt:
-                print('Saving model weights has been cancelled!')
-            exit(0)
-        except Exception as e:
-            print(e)
-            exit(1)
-
-    def set_tf_allow_growth(self):
-        import tensorflow as tf
-        from keras.backend.tensorflow_backend import set_session
-        config = tf.ConfigProto()
-        config.gpu_options.allow_growth = True
-        config.gpu_options.visible_device_list="0"
-        set_session(tf.Session(config=config))
-
-    preview_buffer = {}
-
-    def show(self, image, name=''):
-        try:
-            if self.arguments.preview:
-                with self.lock:
-                    self.preview_buffer[name] = image
-            elif self.arguments.write_image:
-                cv2.imwrite('_sample_{}.jpg'.format(name), image)
-        except Exception as e:
-            print("could not preview sample")
-            print(e)
+import cv2
+import numpy
+import time
+
+from threading import Lock
+from lib.utils import get_image_paths, get_folder
+from lib.cli import FullPaths
+from plugins.PluginLoader import PluginLoader
+
+class TrainingProcessor(object):
+    arguments = None
+
+    def __init__(self, subparser, command, description='default'):
+        self.parse_arguments(description, subparser, command)
+        self.lock = Lock()
+
+    def process_arguments(self, arguments):
+        self.arguments = arguments
+        print("Model A Directory: {}".format(self.arguments.input_A))
+        print("Model B Directory: {}".format(self.arguments.input_B))
+        print("Training data directory: {}".format(self.arguments.model_dir))
+
+        self.process()
+
+    def parse_arguments(self, description, subparser, command):
+        parser = subparser.add_parser(
+            command,
+            help="This command trains the model for the two faces A and B.",
+            description=description,
+            epilog="Questions and feedback: \
+            https://github.com/deepfakes/faceswap-playground"
+        )
+
+        parser.add_argument('-A', '--input-A',
+                            action=FullPaths,
+                            dest="input_A",
+                            default="input_A",
+                            help="Input directory. A directory containing training images for face A.\
+                             Defaults to 'input'")
+        parser.add_argument('-B', '--input-B',
+                            action=FullPaths,
+                            dest="input_B",
+                            default="input_B",
+                            help="Input directory. A directory containing training images for face B.\
+                             Defaults to 'input'")
+        parser.add_argument('-m', '--model-dir',
+                            action=FullPaths,
+                            dest="model_dir",
+                            default="models",
+                            help="Model directory. This is where the training data will \
+                                be stored. Defaults to 'model'")
+        parser.add_argument('-p', '--preview',
+                            action="store_true",
+                            dest="preview",
+                            default=False,
+                            help="Show preview output. If not specified, write progress \
+                            to file.")
+        parser.add_argument('-v', '--verbose',
+                            action="store_true",
+                            dest="verbose",
+                            default=False,
+                            help="Show verbose output")
+        parser.add_argument('-s', '--save-interval',
+                            type=int,
+                            dest="save_interval",
+                            default=100,
+                            help="Sets the number of iterations before saving the model.")
+        parser.add_argument('-w', '--write-image',
+                            action="store_true",
+                            dest="write_image",
+                            default=False,
+                            help="Writes the training result to a file even on preview mode.")
+        parser.add_argument('-t', '--trainer',
+                            type=str,
+                            choices=("Original", "LowMem", "GAN", "GAN128"),
+                            default="Original",
+                            help="Select which trainer to use, LowMem for cards < 2gb.")
+        parser.add_argument('-pl', '--use-perceptual-loss',
+                            action="store_true",
+                            dest="perceptual_loss",
+                            default=False,
+                            help="Use perceptual loss while training")
+        parser.add_argument('-bs', '--batch-size',
+                            type=int,
+                            default=64,
+                            help="Batch size, as a power of 2 (64, 128, 256, etc)")
+        parser.add_argument('-ag', '--allow-growth',
+                            action="store_true",
+                            dest="allow_growth",
+                            default=False,
+                            help="Sets allow_growth option of Tensorflow to spare memory on some configs")
+        parser.add_argument('-ep', '--epochs',
+                            type=int,
+                            default=1000000,
+                            help="Length of training in epochs.")
+        parser = self.add_optional_arguments(parser)
+        parser.set_defaults(func=self.process_arguments)
+
+    def add_optional_arguments(self, parser):
+        # Override this for custom arguments
+        return parser
+
+    def process(self):
+        import threading
+        self.stop = False
+        self.save_now = False
+
+        thr = threading.Thread(target=self.processThread, args=(), kwargs={})
+        thr.start()
+
+        if self.arguments.preview:
+            print('Using live preview')
+            while True:
+                try:
+                    with self.lock:
+                        for name, image in self.preview_buffer.items():
+                            cv2.imshow(name, image)
+
+                    key = cv2.waitKey(1000)
+                    if key == ord('\n') or key == ord('\r'):
+                        break
+                    if key == ord('s'):
+                        self.save_now = True
+                except KeyboardInterrupt:
+                    break
+        else:
+            input() # TODO how to catch a specific key instead of Enter?
+            # there isnt a good multiplatform solution: https://stackoverflow.com/questions/3523174/raw-input-in-python-without-pressing-enter
+
+        print("Exit requested! The trainer will complete its current cycle, save the models and quit (it can take up a couple of seconds depending on your training speed). If you want to kill it now, press Ctrl + c")
+        self.stop = True
+        thr.join() # waits until thread finishes
+
+    def processThread(self):
+        if self.arguments.allow_growth:
+            self.set_tf_allow_growth()
+
+        print('Loading data, this may take a while...')
+        # this is so that you can enter case insensitive values for trainer
+        trainer = self.arguments.trainer
+        trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
+        model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir))
+        model.load(swapped=False)
+
+        images_A = get_image_paths(self.arguments.input_A)
+        images_B = get_image_paths(self.arguments.input_B)
+        trainer = PluginLoader.get_trainer(trainer)
+        trainer = trainer(model, images_A, images_B, self.arguments.batch_size, self.arguments.perceptual_loss)
+
+        try:
+            print('Starting. Press "Enter" to stop training and save model')
+
+            for epoch in range(0, self.arguments.epochs):
+
+                save_iteration = epoch % self.arguments.save_interval == 0
+
+                trainer.train_one_step(epoch, self.show if (save_iteration or self.save_now) else None)
+
+                if save_iteration:
+                    model.save_weights()
+
+                if self.stop:
+                    model.save_weights()
+                    exit()
+
+                if self.save_now:
+                    model.save_weights()
+                    self.save_now = False
+
+        except KeyboardInterrupt:
+            try:
+                model.save_weights()
+            except KeyboardInterrupt:
+                print('Saving model weights has been cancelled!')
+            exit(0)
+        except Exception as e:
+            print(e)
+            exit(1)
+
+    def set_tf_allow_growth(self):
+        import tensorflow as tf
+        from keras.backend.tensorflow_backend import set_session
+        config = tf.ConfigProto()
+        config.gpu_options.allow_growth = True
+        config.gpu_options.visible_device_list="0"
+        set_session(tf.Session(config=config))
+
+    preview_buffer = {}
+
+    def show(self, image, name=''):
+        try:
+            if self.arguments.preview:
+                with self.lock:
+                    self.preview_buffer[name] = image
+            elif self.arguments.write_image:
+                cv2.imwrite('_sample_{}.jpg'.format(name), image)
+        except Exception as e:
+            print("could not preview sample")
+            print(e)
