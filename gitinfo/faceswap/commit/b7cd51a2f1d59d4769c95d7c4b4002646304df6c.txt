commit b7cd51a2f1d59d4769c95d7c4b4002646304df6c
Author: kilroythethird <44308116+kilroythethird@users.noreply.github.com>
Date:   Thu Sep 19 00:09:00 2019 +0200

    Optimized mtcnn a bit + added batching (#874)

diff --git a/lib/model/session.py b/lib/model/session.py
index 6fa2be7..fd86cbf 100644
--- a/lib/model/session.py
+++ b/lib/model/session.py
@@ -5,6 +5,7 @@ import logging
 
 import tensorflow as tf
 from keras.models import load_model as k_load_model, Model
+import numpy as np
 
 from lib.utils import get_backend
 
@@ -39,7 +40,39 @@ class KSession():
         self._model = None
         logger.trace("Initialized: %s", self.__class__.__name__,)
 
-    def predict(self, feed):
+    def _amd_predict_with_optimized_batchsizes(self, feed, batch_size):
+        """ Minimizes the amount of kernels to be compiled when using
+        the ``Amd`` backend with varying batchsizes while trying to keep
+        the batchsize as high as possible.
+
+        Parameters
+        ----------
+        feed: numpy.ndarray or list
+            The feed to be provided to the model as input. This should be a ``numpy.ndarray``
+            for single inputs or a ``list`` of ``numpy.ndarrays`` for multiple inputs.
+        batch_size: int
+            The upper batchsize to use.
+        """
+        if isinstance(feed, np.ndarray):
+            feed = [feed]
+        items = feed[0].shape[0]
+        done_items = 0
+        results = list()
+        while done_items < items:
+            if batch_size < 4:  # Not much difference in BS < 4
+                batch_size = 1
+            batch_items = ((items - done_items) // batch_size) * batch_size
+            if batch_items:
+                pred_data = [x[done_items:done_items + batch_items] for x in feed]
+                pred = self._model.predict(pred_data, batch_size=batch_size)
+                done_items += batch_items
+                results.append(pred)
+            batch_size //= 2
+        if isinstance(results[0], np.ndarray):
+            return np.concatenate(results)
+        return [np.concatenate(x) for x in zip(*results)]
+
+    def predict(self, feed, batch_size=None):
         """ Get predictions from the model in the correct session.
 
         This method is a wrapper for :func:`keras.predict()` function.
@@ -51,11 +84,13 @@ class KSession():
             for single inputs or a ``list`` of ``numpy.ndarrays`` for multiple inputs.
         """
         if self._session is None:
-            return self._model.predict(feed)
+            if batch_size is None:
+                return self._model.predict(feed)
+            return self._amd_predict_with_optimized_batchsizes(feed, batch_size)
 
         with self._session.as_default():  # pylint: disable=not-context-manager
             with self._session.graph.as_default():
-                return self._model.predict(feed)
+                return self._model.predict(feed, batch_size=batch_size)
 
     def _set_session(self):
         """ Sets the session and graph.
diff --git a/plugins/extract/_base.py b/plugins/extract/_base.py
index 8274801..f4ed5a6 100644
--- a/plugins/extract/_base.py
+++ b/plugins/extract/_base.py
@@ -322,7 +322,7 @@ class Extractor():
                      self.__class__.__name__, args, kwargs)
         p_type = "Detector" if self._plugin_type == "detect" else "Aligner"
         logger.info("Initializing %s %s...", self.name, p_type)
-        self.queue_size = kwargs["queue_size"]
+        self.queue_size = 1
         self._add_queues(kwargs["in_queue"], kwargs["out_queue"], ["predict", "post"])
         self._compile_threads()
         self.init_model()
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index 47d036f..3be1067 100755
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -11,7 +11,6 @@ import numpy as np
 from lib.model.session import KSession
 from ._base import Detector, logger
 
-
 class Detect(Detector):
     """ MTCNN detector for face recognition """
     def __init__(self, **kwargs):
@@ -19,11 +18,11 @@ class Detect(Detector):
         model_filename = ["mtcnn_det_v2.1.h5", "mtcnn_det_v2.2.h5", "mtcnn_det_v2.3.h5"]
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
         self.name = "MTCNN"
-        self.input_size = 1440
+        self.input_size = 640
         self.vram = 1408
         self.vram_warnings = 512  # Will run at this with warnings
         self.vram_per_batch = 1  # TODO implement batch support
-        self.batchsize = 1  # TODO implement batch support
+        self.batchsize = self.config["batch-size"]
         self.kwargs = self.validate_kwargs()
 
     def validate_kwargs(self):
@@ -65,7 +64,7 @@ class Detect(Detector):
         prediction, points = self.model.detect_faces(batch["feed"])
         logger.trace("filename: %s, prediction: %s, mtcnn_points: %s",
                      batch["filename"], prediction, points)
-        batch["prediction"], batch["mtcnn_points"] = [prediction], [points]
+        batch["prediction"], batch["mtcnn_points"] = prediction, points
         return batch
 
     def process_output(self, batch):
@@ -210,99 +209,119 @@ class MTCNN():
         self.pnet = PNet(model_path[0])
         self.rnet = RNet(model_path[1])
         self.onet = ONet(model_path[2])
+        self._pnet_scales = None
         logger.debug("Initialized: %s", self.__class__.__name__)
 
     def detect_faces(self, batch):
         """Detects faces in an image, and returns bounding boxes and points for them.
         batch: input batch
         """
-        total_boxes = np.empty((0, 9))
-        points = np.empty(0)
-        # TODO Implement batch support
-        image = batch[0]
-        origin_h, origin_w = image.shape[:2]
-        rectangles = self.detect_pnet(image, origin_h, origin_w)
-        if not rectangles:
-            return total_boxes, points
-        rectangles = self.detect_rnet(image, rectangles, origin_h, origin_w)
-        if not rectangles:
-            return total_boxes, points
-        rectangles = self.detect_onet(image, rectangles, origin_h, origin_w)
-        if rectangles:
-            total_boxes = np.array([result[:5] for result in rectangles])
-            points = np.array([result[5:] for result in rectangles]).T
-        return total_boxes, points
-
-    def detect_pnet(self, image, height, width):
+        origin_h, origin_w = batch.shape[1:3]
+        rectangles = self.detect_pnet(batch, origin_h, origin_w)
+        rectangles = self.detect_rnet(batch, rectangles, origin_h, origin_w)
+        rectangles = self.detect_onet(batch, rectangles, origin_h, origin_w)
+        ret_boxes = list()
+        ret_points = list()
+        for rects in rectangles:
+            if rects:
+                total_boxes = np.array([result[:5] for result in rects])
+                points = np.array([result[5:] for result in rects]).T
+            else:
+                total_boxes = np.empty((0, 9))
+                points = np.empty(0)
+            ret_boxes.append(total_boxes)
+            ret_points.append(points)
+        return ret_boxes, ret_points
+
+    def detect_pnet(self, images, height, width):
         # pylint: disable=too-many-locals
         """ first stage - fast proposal network (pnet) to obtain face candidates """
-        scales = calculate_scales(height, width, self.minsize, self.factor)
-        rectangles = []
-        for scale in scales:
-            scale_img = cv2.resize(image,  # pylint:disable=no-member
-                                   (int(width * scale), int(height * scale)))
-            input_ = scale_img.reshape(1, *scale_img.shape)
-            output = self.pnet.predict(input_)
-            # .transpose(0, 2, 1, 3) should be added, but this seems wrong.
-            # first 0 select cls score, second 0 = batchnum, alway=0. 1 one hot repr
-            cls_prob = output[0][0][:, :, 1]
-            roi = output[1][0]
-            out_h, out_w = cls_prob.shape
+        if self._pnet_scales is None:
+            self._pnet_scales = calculate_scales(height, width, self.minsize, self.factor)
+        rectangles = [[] for _ in range(images.shape[0])]
+        batch_items = images.shape[0]
+        for scale in self._pnet_scales:
+            rwidth, rheight = int(width * scale), int(height * scale)
+            batch = np.empty((batch_items, rheight, rwidth, 3), dtype="float32")
+            for b in range(batch_items):
+                batch[b, ...] = cv2.resize(images[b, ...], (rwidth, rheight))
+            output = self.pnet.predict(batch)
+            cls_prob = output[0][..., 1]
+            roi = output[1]
+            out_h, out_w = cls_prob.shape[1:3]
             out_side = max(out_h, out_w)
-            cls_prob = np.swapaxes(cls_prob, 0, 1)
-            roi = np.swapaxes(roi, 0, 2)
-            rectangle = detect_face_12net(cls_prob,
-                                          roi,
-                                          out_side,
-                                          1 / scale,
-                                          width,
-                                          height,
-                                          self.threshold[0])
-            rectangles.extend(rectangle)
-        return nms(rectangles, 0.7, 'iou')
-
-    def detect_rnet(self, image, rectangles, height, width):
+            cls_prob = np.swapaxes(cls_prob, 1, 2)
+            roi = np.swapaxes(roi, 1, 3)
+            for b in range(batch_items):
+                # first index 0 = cls score, 1 = one hot repr
+                rectangle = detect_face_12net(cls_prob[b, ...],
+                                              roi[b, ...],
+                                              out_side,
+                                              1 / scale,
+                                              width,
+                                              height,
+                                              self.threshold[0])
+                rectangles[b].extend(rectangle)
+        return [nms(x, 0.7, 'iou') for x in rectangles]
+
+    def detect_rnet(self, images, rectangle_batch, height, width):
         """ second stage - refinement of face candidates with rnet """
-        crop_number = 0
-        predict_24_batch = []
-        for rect in rectangles:
-            crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
-            scale_img = cv2.resize(crop_img, (24, 24))  # pylint:disable=no-member
-            predict_24_batch.append(scale_img)
-            crop_number += 1
-
-        predict_24_batch = np.array(predict_24_batch)
-        output = self.rnet.predict(predict_24_batch)
-
-        cls_prob = output[0]  # first 0 is to select cls, second batch number, always =0
-        cls_prob = np.array(cls_prob)
-        roi_prob = output[1]  # first 0 is to select roi, second batch number, always =0
-        roi_prob = np.array(roi_prob)
-        return filter_face_24net(cls_prob, roi_prob, rectangles, width, height, self.threshold[1])
-
-    def detect_onet(self, image, rectangles, height, width):
+        ret = []
+        # TODO: batching
+        for b, rectangles in enumerate(rectangle_batch):
+            if not rectangles:
+                ret.append(list())
+                continue
+            image = images[b]
+            crop_number = 0
+            predict_24_batch = []
+            for rect in rectangles:
+                crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
+                scale_img = cv2.resize(crop_img, (24, 24))  # pylint:disable=no-member
+                predict_24_batch.append(scale_img)
+                crop_number += 1
+            predict_24_batch = np.array(predict_24_batch)
+            output = self.rnet.predict(predict_24_batch, batch_size=128)
+            cls_prob = output[0]
+            cls_prob = np.array(cls_prob)
+            roi_prob = output[1]
+            roi_prob = np.array(roi_prob)
+            ret.append(filter_face_24net(
+                cls_prob, roi_prob, rectangles, width, height, self.threshold[1]
+            ))
+        return ret
+
+    def detect_onet(self, images, rectangle_batch, height, width):
         """ third stage - further refinement and facial landmarks positions with onet """
-        crop_number = 0
-        predict_batch = []
-        for rect in rectangles:
-            crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
-            scale_img = cv2.resize(crop_img, (48, 48))  # pylint:disable=no-member
-            predict_batch.append(scale_img)
-            crop_number += 1
-
-        predict_batch = np.array(predict_batch)
-
-        output = self.onet.predict(predict_batch)
-        cls_prob = output[0]
-        roi_prob = output[1]
-        pts_prob = output[2]  # index
-        return filter_face_48net(cls_prob,
-                                 roi_prob,
-                                 pts_prob,
-                                 rectangles,
-                                 width,
-                                 height,
-                                 self.threshold[2])
+        ret = list()
+        # TODO: batching
+        for b, rectangles in enumerate(rectangle_batch):
+            if not rectangles:
+                ret.append(list())
+                continue
+            image = images[b]
+            crop_number = 0
+            predict_batch = []
+            for rect in rectangles:
+                crop_img = image[int(rect[1]):int(rect[3]), int(rect[0]):int(rect[2])]
+                scale_img = cv2.resize(crop_img, (48, 48))  # pylint:disable=no-member
+                predict_batch.append(scale_img)
+                crop_number += 1
+            predict_batch = np.array(predict_batch)
+            output = self.onet.predict(predict_batch, batch_size=128)
+            cls_prob = output[0]
+            roi_prob = output[1]
+            pts_prob = output[2]  # index
+            ret.append(filter_face_48net(
+                cls_prob,
+                roi_prob,
+                pts_prob,
+                rectangles,
+                width,
+                height,
+                self.threshold[2]
+            ))
+        return ret
 
 
 def detect_face_12net(cls_prob, roi, out_side, scale, width, height, threshold):
diff --git a/plugins/extract/detect/mtcnn_defaults.py b/plugins/extract/detect/mtcnn_defaults.py
index e50778d..f2d28bc 100755
--- a/plugins/extract/detect/mtcnn_defaults.py
+++ b/plugins/extract/detect/mtcnn_defaults.py
@@ -106,4 +106,17 @@ _DEFAULTS = {
         "gui_radio": False,
         "fixed": True,
     },
+    "batch-size": {
+        "default": 8,
+        "info": "The batch size to use. To a point, higher batch sizes equal better performance, "
+                "but setting it too high can harm performance.\n"
+                "\n\tNvidia users: If the batchsize is set higher than the your GPU can "
+                "accomodate then this will automatically be lowered.",
+        "datatype": int,
+        "rounding": 1,
+        "min_max": (1, 64),
+        "choices": [],
+        "gui_radio": False,
+        "fixed": True,
+    }
 }
diff --git a/plugins/extract/pipeline.py b/plugins/extract/pipeline.py
index 632ed4d..45a50f1 100644
--- a/plugins/extract/pipeline.py
+++ b/plugins/extract/pipeline.py
@@ -323,8 +323,7 @@ class Extractor():
         """ Launch the face aligner """
         logger.debug("Launching Aligner")
         kwargs = dict(in_queue=self._queues["extract_align_in"],
-                      out_queue=self._queues["extract_align_out"],
-                      queue_size=self._queue_size)
+                      out_queue=self._queues["extract_align_out"])
         self._aligner.initialize(**kwargs)
         self._aligner.start()
         logger.debug("Launched Aligner")
@@ -333,8 +332,7 @@ class Extractor():
         """ Launch the face detector """
         logger.debug("Launching Detector")
         kwargs = dict(in_queue=self._queues["extract_detect_in"],
-                      out_queue=self._queues["extract_align_in"],
-                      queue_size=self._queue_size)
+                      out_queue=self._queues["extract_align_in"])
         self._detector.initialize(**kwargs)
         self._detector.start()
         logger.debug("Launched Detector")
