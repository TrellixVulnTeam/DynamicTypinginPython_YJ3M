commit f6cb3941ad688a77f1c7e72b053a3429345167e4
Author: bryanlyon <bryanlyon@mail.weber.edu>
Date:   Sun Mar 11 10:03:33 2018 -0700

    Add Multi-GPU support (#272)
    
    * Add Improved AutoEncoder model.
    
    * Refactoring Model_IAE to match the new model folder structure
    
    * Add Model_IAE in plugins
    
    * Add Multi-GPU support
    
    I added multi-GPU support to the new model layout.  Currently, Original is not tested (due to OOM on my 2x 4gb 970s).  LowMem is not tested with the current commit due to it not being available since the new pluginloader misses it.

diff --git a/plugins/Model_GAN/Model.py b/plugins/Model_GAN/Model.py
index cd5d626..33a121c 100644
--- a/plugins/Model_GAN/Model.py
+++ b/plugins/Model_GAN/Model.py
@@ -11,6 +11,8 @@ from keras.optimizers import Adam
 from lib.PixelShuffler import PixelShuffler
 from .instance_normalization import InstanceNormalization
 
+from keras.utils import multi_gpu_model
+
 netGAH5 = 'netGA_GAN.h5'
 netGBH5 = 'netGB_GAN.h5'
 netDAH5 = 'netDA_GAN.h5'
@@ -19,7 +21,7 @@ netDBH5 = 'netDB_GAN.h5'
 def __conv_init(a):
     print("conv_init", a)
     k = RandomNormal(0, 0.02)(a) # for convolution kernel
-    k.conv_weight = True    
+    k.conv_weight = True
     return k
 
 #def batchnorm():
@@ -32,15 +34,16 @@ conv_init = RandomNormal(0, 0.02)
 gamma_init = RandomNormal(1., 0.02) # for batch normalization
 
 class GANModel():
-    img_size = 64 
+    img_size = 64
     channels = 3
     img_shape = (img_size, img_size, channels)
     encoded_dim = 1024
     nc_in = 3 # number of input channels of generators
     nc_D_inp = 6 # number of input channels of discriminators
 
-    def __init__(self, model_dir):
+    def __init__(self, model_dir, gpus):
         self.model_dir = model_dir
+        self.gpus = gpus
 
         optimizer = Adam(1e-4, 0.5)
 
@@ -84,7 +87,7 @@ class GANModel():
             x = Conv2D(64, kernel_size=5, kernel_initializer=conv_init, use_bias=False, padding="same")(inp)
             x = conv_block(x,128)
             x = conv_block(x,256)
-            x = conv_block(x,512) 
+            x = conv_block(x,512)
             x = conv_block(x,1024)
             x = Dense(1024)(Flatten()(x))
             x = Dense(4*4*1024)(x)
@@ -100,18 +103,23 @@ class GANModel():
             x = upscale_ps(64)(x)
             x = res_block(x, 64)
             x = res_block(x, 64)
-            #x = Conv2D(4, kernel_size=5, padding='same')(x)   
+            #x = Conv2D(4, kernel_size=5, padding='same')(x)
             alpha = Conv2D(1, kernel_size=5, padding='same', activation="sigmoid")(x)
             rgb = Conv2D(3, kernel_size=5, padding='same', activation="tanh")(x)
             out = concatenate([alpha, rgb])
             return Model(input_, out )
-        
+
         encoder = Encoder()
         decoder_A = Decoder_ps()
-        decoder_B = Decoder_ps()    
+        decoder_B = Decoder_ps()
         x = Input(shape=self.img_shape)
         netGA = Model(x, decoder_A(encoder(x)))
-        netGB = Model(x, decoder_B(encoder(x)))           
+        netGB = Model(x, decoder_B(encoder(x)))
+
+        if self.gpus > 1:
+            netGA = multi_gpu_model( netGA , self.gpus)
+            netGB = multi_gpu_model( netGB , self.gpus)
+
         try:
             netGA.load_weights(str(self.model_dir / netGAH5))
             netGB.load_weights(str(self.model_dir / netGBH5))
@@ -134,11 +142,11 @@ class GANModel():
             x = conv_block_d(inp, 64, False)
             x = conv_block_d(x, 128, False)
             x = conv_block_d(x, 256, False)
-            out = Conv2D(1, kernel_size=4, kernel_initializer=conv_init, use_bias=False, padding="same", activation="sigmoid")(x)   
+            out = Conv2D(1, kernel_size=4, kernel_initializer=conv_init, use_bias=False, padding="same", activation="sigmoid")(x)
             return Model(inputs=[inp], outputs=out)
-        
+
         netDA = Discriminator(self.nc_D_inp)
-        netDB = Discriminator(self.nc_D_inp)        
+        netDB = Discriminator(self.nc_D_inp)
         try:
             netDA.load_weights(str(self.model_dir / netDAH5))
             netDB.load_weights(str(self.model_dir / netDBH5))
@@ -146,14 +154,14 @@ class GANModel():
         except:
             print ("Discriminator weights files not found.")
             pass
-        return netDA, netDB    
-    
+        return netDA, netDB
+
     def load(self, swapped):
         if swapped:
             print("swapping not supported on GAN")
             # TODO load is done in __init__ => look how to swap if possible
         return True
-    
+
     def save_weights(self):
         self.netGA.save_weights(str(self.model_dir / netGAH5))
         self.netGB.save_weights(str(self.model_dir / netGBH5))
diff --git a/plugins/Model_IAE/AutoEncoder.py b/plugins/Model_IAE/AutoEncoder.py
index ff22ede..87fdc34 100644
--- a/plugins/Model_IAE/AutoEncoder.py
+++ b/plugins/Model_IAE/AutoEncoder.py
@@ -9,8 +9,9 @@ inter_bothH5 = 'IAE_inter_both.h5'
 
 
 class AutoEncoder:
-    def __init__(self, model_dir):
+    def __init__(self, model_dir, gpus):
         self.model_dir = model_dir
+        self.gpus = gpus
 
         self.encoder = self.Encoder()
         self.decoder = self.Decoder()
@@ -43,4 +44,3 @@ class AutoEncoder:
         self.inter_A.save_weights(str(self.model_dir / inter_AH5))
         self.inter_B.save_weights(str(self.model_dir / inter_BH5))
         print('saved model weights')
-
diff --git a/plugins/Model_IAE/Model.py b/plugins/Model_IAE/Model.py
index 84b014c..65f51de 100644
--- a/plugins/Model_IAE/Model.py
+++ b/plugins/Model_IAE/Model.py
@@ -9,10 +9,11 @@ from keras.optimizers import Adam
 from .AutoEncoder import AutoEncoder
 from lib.PixelShuffler import PixelShuffler
 
+from keras.utils import multi_gpu_model
+
 IMAGE_SHAPE = (64, 64, 3)
 ENCODER_DIM = 1024
 
-
 class Model(AutoEncoder):
     def initModel(self):
         optimizer = Adam(lr=5e-5, beta_1=0.5, beta_2=0.999)
@@ -21,6 +22,10 @@ class Model(AutoEncoder):
         self.autoencoder_A = KerasModel(x, self.decoder(Concatenate()([self.inter_A(self.encoder(x)), self.inter_both(self.encoder(x))])))
         self.autoencoder_B = KerasModel(x, self.decoder(Concatenate()([self.inter_B(self.encoder(x)), self.inter_both(self.encoder(x))])))
 
+        if self.gpus > 1:
+            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
+            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)
+
         self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')
         self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')
 
diff --git a/plugins/Model_LowMem.py b/plugins/Model_LowMem.py
index 08571e6..6cb2cf9 100644
--- a/plugins/Model_LowMem.py
+++ b/plugins/Model_LowMem.py
@@ -9,6 +9,8 @@ from keras.optimizers import Adam
 from .Model_Original import AutoEncoder, Trainer
 from lib.PixelShuffler import PixelShuffler
 
+from keras.utils import multi_gpu_model
+
 IMAGE_SHAPE = (64, 64, 3)
 ENCODER_DIM = 512
 
@@ -20,11 +22,15 @@ class Model(AutoEncoder):
         self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
         self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
 
+        if self.gpus > 1:
+            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
+            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)
+
         self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')
         self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')
 
     def converter(self, swap):
-        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A 
+        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A
         return lambda img: autoencoder.predict(img)
 
     def conv(self, filters):
diff --git a/plugins/Model_Original/AutoEncoder.py b/plugins/Model_Original/AutoEncoder.py
index e506c0e..eee517a 100644
--- a/plugins/Model_Original/AutoEncoder.py
+++ b/plugins/Model_Original/AutoEncoder.py
@@ -5,8 +5,9 @@ decoder_AH5 = 'decoder_A.h5'
 decoder_BH5 = 'decoder_B.h5'
 
 class AutoEncoder:
-    def __init__(self, model_dir):
+    def __init__(self, model_dir, gpus):
         self.model_dir = model_dir
+        self.gpus = gpus
 
         self.encoder = self.Encoder()
         self.decoder_A = self.Decoder()
diff --git a/plugins/Model_Original/Model.py b/plugins/Model_Original/Model.py
index 9f559d1..d923afc 100644
--- a/plugins/Model_Original/Model.py
+++ b/plugins/Model_Original/Model.py
@@ -9,6 +9,8 @@ from keras.optimizers import Adam
 from .AutoEncoder import AutoEncoder
 from lib.PixelShuffler import PixelShuffler
 
+from keras.utils import multi_gpu_model
+
 IMAGE_SHAPE = (64, 64, 3)
 ENCODER_DIM = 1024
 
@@ -20,11 +22,15 @@ class Model(AutoEncoder):
         self.autoencoder_A = KerasModel(x, self.decoder_A(self.encoder(x)))
         self.autoencoder_B = KerasModel(x, self.decoder_B(self.encoder(x)))
 
+        if self.gpus > 1:
+            self.autoencoder_A = multi_gpu_model( self.autoencoder_A , self.gpus)
+            self.autoencoder_B = multi_gpu_model( self.autoencoder_B , self.gpus)
+
         self.autoencoder_A.compile(optimizer=optimizer, loss='mean_absolute_error')
         self.autoencoder_B.compile(optimizer=optimizer, loss='mean_absolute_error')
 
     def converter(self, swap):
-        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A 
+        autoencoder = self.autoencoder_B if not swap else self.autoencoder_A
         return lambda img: autoencoder.predict(img)
 
     def conv(self, filters):
@@ -62,4 +68,4 @@ class Model(AutoEncoder):
         x = self.upscale(128)(x)
         x = self.upscale(64)(x)
         x = Conv2D(3, kernel_size=5, padding='same', activation='sigmoid')(x)
-        return KerasModel(input_, x)
\ No newline at end of file
+        return KerasModel(input_, x)
diff --git a/plugins/Model_Original/Trainer.py b/plugins/Model_Original/Trainer.py
index 0672307..d595ae8 100644
--- a/plugins/Model_Original/Trainer.py
+++ b/plugins/Model_Original/Trainer.py
@@ -46,11 +46,11 @@ class Trainer():
         if test_A.shape[0] % 2 == 1:
             figure_A = numpy.concatenate ([figure_A, numpy.expand_dims(figure_A[0],0) ])
             figure_B = numpy.concatenate ([figure_B, numpy.expand_dims(figure_B[0],0) ])
-        
+
         figure = numpy.concatenate([figure_A, figure_B], axis=0)
         w = 4
-        h = int( figure.shape[0] / w)        
-        figure = figure.reshape((w, h) + figure.shape[1:])        
+        h = int( figure.shape[0] / w)
+        figure = figure.reshape((w, h) + figure.shape[1:])
         figure = stack_images(figure)
-        
+
         return numpy.clip(figure * 255, 0, 255).astype('uint8')
diff --git a/scripts/convert.py b/scripts/convert.py
index 809dd06..39f4a2d 100644
--- a/scripts/convert.py
+++ b/scripts/convert.py
@@ -141,6 +141,12 @@ class ConvertImage(DirectoryProcessor):
                             dest="avg_color_adjust",
                             default=True,
                             help="Average color adjust. (Adjust converter only)")
+
+        parser.add_argument('-g', '--gpus',
+                            type=int,
+                            default=1,
+                            help="Number of GPUs to use for conversion")
+
         return parser
 
     def process(self):
@@ -150,7 +156,7 @@ class ConvertImage(DirectoryProcessor):
         conv_name = self.arguments.converter
         self.input_aligned_dir = None
 
-        model = PluginLoader.get_model(model_name)(get_folder(self.arguments.model_dir))
+        model = PluginLoader.get_model(model_name)(get_folder(self.arguments.model_dir), self.arguments.gpus)
         if not model.load(self.arguments.swap_model):
             print('Model Not Found! A valid model must be provided to continue!')
             exit(1)
diff --git a/scripts/train.py b/scripts/train.py
index 12f6503..a966368 100644
--- a/scripts/train.py
+++ b/scripts/train.py
@@ -93,6 +93,10 @@ class TrainingProcessor(object):
                             type=int,
                             default=1000000,
                             help="Length of training in epochs.")
+        parser.add_argument('-g', '--gpus',
+                            type=int,
+                            default=1,
+                            help="Number of GPUs to use for training")
         parser = self.add_optional_arguments(parser)
         parser.set_defaults(func=self.process_arguments)
 
@@ -140,7 +144,7 @@ class TrainingProcessor(object):
             # this is so that you can enter case insensitive values for trainer
             trainer = self.arguments.trainer
             trainer = "LowMem" if trainer.lower() == "lowmem" else trainer
-            model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir))
+            model = PluginLoader.get_model(trainer)(get_folder(self.arguments.model_dir), self.arguments.gpus)
             model.load(swapped=False)
 
             images_A = get_image_paths(self.arguments.input_A)
