commit feb5f75201eb3477f2f2d4b7196a4683936407f1
Author: torzdf <36920800+torzdf@users.noreply.github.com>
Date:   Wed Sep 18 22:30:49 2019 +0000

    set mtcnn Nvidia defaults

diff --git a/lib/model/session.py b/lib/model/session.py
index fd86cbf..3db05a0 100644
--- a/lib/model/session.py
+++ b/lib/model/session.py
@@ -18,8 +18,8 @@ class KSession():
     This class acts as a wrapper for various :class:`keras.Model()` functions, ensuring that
     actions performed on a model are handled consistently within the correct graph.
 
-    Currently this only does anything for Nvidia users, making sure a unique graph and session is
-    provided for the given model.
+    This is an early implementation of this class, and should be expanded out over time
+    with relevant `AMD`, `CPU` and `NVIDIA` backend methods.
 
     Parameters
     ----------
@@ -40,6 +40,26 @@ class KSession():
         self._model = None
         logger.trace("Initialized: %s", self.__class__.__name__,)
 
+    def predict(self, feed, batch_size=None):
+        """ Get predictions from the model in the correct session.
+
+        This method is a wrapper for :func:`keras.predict()` function.
+
+        Parameters
+        ----------
+        feed: numpy.ndarray or list
+            The feed to be provided to the model as input. This should be a ``numpy.ndarray``
+            for single inputs or a ``list`` of ``numpy.ndarrays`` for multiple inputs.
+        """
+        if self._session is None:
+            if batch_size is None:
+                return self._model.predict(feed)
+            return self._amd_predict_with_optimized_batchsizes(feed, batch_size)
+
+        with self._session.as_default():  # pylint: disable=not-context-manager
+            with self._session.graph.as_default():
+                return self._model.predict(feed, batch_size=batch_size)
+
     def _amd_predict_with_optimized_batchsizes(self, feed, batch_size):
         """ Minimizes the amount of kernels to be compiled when using
         the ``Amd`` backend with varying batchsizes while trying to keep
@@ -72,26 +92,6 @@ class KSession():
             return np.concatenate(results)
         return [np.concatenate(x) for x in zip(*results)]
 
-    def predict(self, feed, batch_size=None):
-        """ Get predictions from the model in the correct session.
-
-        This method is a wrapper for :func:`keras.predict()` function.
-
-        Parameters
-        ----------
-        feed: numpy.ndarray or list
-            The feed to be provided to the model as input. This should be a ``numpy.ndarray``
-            for single inputs or a ``list`` of ``numpy.ndarrays`` for multiple inputs.
-        """
-        if self._session is None:
-            if batch_size is None:
-                return self._model.predict(feed)
-            return self._amd_predict_with_optimized_batchsizes(feed, batch_size)
-
-        with self._session.as_default():  # pylint: disable=not-context-manager
-            with self._session.graph.as_default():
-                return self._model.predict(feed, batch_size=batch_size)
-
     def _set_session(self):
         """ Sets the session and graph.
 
diff --git a/plugins/extract/detect/mtcnn.py b/plugins/extract/detect/mtcnn.py
index 3be1067..d1901f7 100755
--- a/plugins/extract/detect/mtcnn.py
+++ b/plugins/extract/detect/mtcnn.py
@@ -11,6 +11,7 @@ import numpy as np
 from lib.model.session import KSession
 from ._base import Detector, logger
 
+
 class Detect(Detector):
     """ MTCNN detector for face recognition """
     def __init__(self, **kwargs):
@@ -19,9 +20,9 @@ class Detect(Detector):
         super().__init__(git_model_id=git_model_id, model_filename=model_filename, **kwargs)
         self.name = "MTCNN"
         self.input_size = 640
-        self.vram = 1408
-        self.vram_warnings = 512  # Will run at this with warnings
-        self.vram_per_batch = 1  # TODO implement batch support
+        self.vram = 320
+        self.vram_warnings = 64  # Will run at this with warnings
+        self.vram_per_batch = 32
         self.batchsize = self.config["batch-size"]
         self.kwargs = self.validate_kwargs()
 
@@ -190,7 +191,7 @@ class ONet(KSession):
 
 class MTCNN():
     """ MTCNN Detector for face alignment """
-    # TODO Batching
+    # TODO Batching for rnet and onet
 
     def __init__(self, model_path, minsize, threshold, factor):
         """
@@ -243,8 +244,9 @@ class MTCNN():
         for scale in self._pnet_scales:
             rwidth, rheight = int(width * scale), int(height * scale)
             batch = np.empty((batch_items, rheight, rwidth, 3), dtype="float32")
-            for b in range(batch_items):
-                batch[b, ...] = cv2.resize(images[b, ...], (rwidth, rheight))
+            for idx in range(batch_items):
+                batch[idx, ...] = cv2.resize(images[idx, ...],  # pylint:disable=no-member
+                                             (rwidth, rheight))
             output = self.pnet.predict(batch)
             cls_prob = output[0][..., 1]
             roi = output[1]
@@ -252,27 +254,27 @@ class MTCNN():
             out_side = max(out_h, out_w)
             cls_prob = np.swapaxes(cls_prob, 1, 2)
             roi = np.swapaxes(roi, 1, 3)
-            for b in range(batch_items):
+            for idx in range(batch_items):
                 # first index 0 = cls score, 1 = one hot repr
-                rectangle = detect_face_12net(cls_prob[b, ...],
-                                              roi[b, ...],
+                rectangle = detect_face_12net(cls_prob[idx, ...],
+                                              roi[idx, ...],
                                               out_side,
                                               1 / scale,
                                               width,
                                               height,
                                               self.threshold[0])
-                rectangles[b].extend(rectangle)
+                rectangles[idx].extend(rectangle)
         return [nms(x, 0.7, 'iou') for x in rectangles]
 
     def detect_rnet(self, images, rectangle_batch, height, width):
         """ second stage - refinement of face candidates with rnet """
         ret = []
         # TODO: batching
-        for b, rectangles in enumerate(rectangle_batch):
+        for idx, rectangles in enumerate(rectangle_batch):
             if not rectangles:
                 ret.append(list())
                 continue
-            image = images[b]
+            image = images[idx]
             crop_number = 0
             predict_24_batch = []
             for rect in rectangles:
@@ -295,11 +297,11 @@ class MTCNN():
         """ third stage - further refinement and facial landmarks positions with onet """
         ret = list()
         # TODO: batching
-        for b, rectangles in enumerate(rectangle_batch):
+        for idx, rectangles in enumerate(rectangle_batch):
             if not rectangles:
                 ret.append(list())
                 continue
-            image = images[b]
+            image = images[idx]
             crop_number = 0
             predict_batch = []
             for rect in rectangles:
