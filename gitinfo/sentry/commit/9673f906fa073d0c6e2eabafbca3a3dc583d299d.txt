commit 9673f906fa073d0c6e2eabafbca3a3dc583d299d
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Mon Sep 30 13:48:12 2019 -0700

    ref: Remove v2 tagstore (#14841)

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 65d17e9673..c9b3419db0 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -1055,10 +1055,7 @@ SENTRY_NODESTORE_OPTIONS = {}
 
 # Tag storage backend
 _SENTRY_TAGSTORE_DEFAULT_MULTI_OPTIONS = {
-    "backends": [
-        ("sentry.tagstore.legacy.LegacyTagStorage", {}),
-        ("sentry.tagstore.v2.V2TagStorage", {}),
-    ],
+    "backends": [("sentry.tagstore.legacy.LegacyTagStorage", {})],
     "runner": "ImmediateRunner",
 }
 SENTRY_TAGSTORE = os.environ.get("SENTRY_TAGSTORE", "sentry.tagstore.legacy.LegacyTagStorage")
diff --git a/src/sentry/tagstore/models.py b/src/sentry/tagstore/models.py
index 3a617a8a0b..22c4d23b41 100644
--- a/src/sentry/tagstore/models.py
+++ b/src/sentry/tagstore/models.py
@@ -1,50 +1,3 @@
 from __future__ import absolute_import
 
-from django.conf import settings
-from django.core.exceptions import ImproperlyConfigured
-
-backends = []
-
-if settings.SENTRY_TAGSTORE == "sentry.utils.services.ServiceDelegator":
-    backends = [
-        backend["path"] for backend in settings.SENTRY_TAGSTORE_OPTIONS.get("backends", {}).values()
-    ]
-elif settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.multi"):
-    backends = [backend[0] for backend in settings.SENTRY_TAGSTORE_OPTIONS.get("backends", [])]
-else:
-    backends = [settings.SENTRY_TAGSTORE]
-
-if not len(backends) > 0:
-    raise ImproperlyConfigured("One or more tagstore backend(s) must be specified")
-
-prefix_map = {
-    # backend path prefix: path to the `models` parent model used
-    "sentry.tagstore.legacy": "sentry.tagstore.legacy",
-    "sentry.tagstore.v2": "sentry.tagstore.v2",
-    "sentry.tagstore.snuba": "sentry.tagstore.v2",
-}
-
-for i, backend in enumerate(backends):
-    for prefix, path in prefix_map.items():
-        if backend.startswith(prefix):
-            models = __import__(path, globals(), locals(), ["models"], level=0).models
-            if i == 0:
-                # If this is the first iteration of the loop, we need to
-                # emulate ``from x import *`` by copying the module contents
-                # into the local (module) scope. This follows the same rules as
-                # the import statement itself, as defined in the refrence docs:
-                # https://docs.python.org/2.7/reference/simple_stmts.html#import
-                if getattr(models, "__all__", None) is not None:
-
-                    def predicate(name):
-                        return name in models.__all__
-
-                else:
-
-                    def predicate(name):
-                        return not name.startswith("_")
-
-                locals().update({k: v for k, v in vars(models).items() if predicate(k)})
-            break
-    else:
-        raise ImproperlyConfigured("Found unknown tagstore backend '%s'" % backend)
+from sentry.tagstore.legacy.models import *  # NOQA
diff --git a/src/sentry/tagstore/v2/__init__.py b/src/sentry/tagstore/v2/__init__.py
deleted file mode 100644
index 7aa2c293a7..0000000000
--- a/src/sentry/tagstore/v2/__init__.py
+++ /dev/null
@@ -1,3 +0,0 @@
-from __future__ import absolute_import
-
-from .backend import V2TagStorage  # NOQA
diff --git a/src/sentry/tagstore/v2/backend.py b/src/sentry/tagstore/v2/backend.py
deleted file mode 100644
index d19c072402..0000000000
--- a/src/sentry/tagstore/v2/backend.py
+++ /dev/null
@@ -1,1018 +0,0 @@
-from __future__ import absolute_import
-
-import collections
-import six
-
-import logging
-from collections import defaultdict
-from datetime import timedelta
-from django.db import connections, router, IntegrityError, transaction
-from django.db.models import F, Q, Sum
-from django.utils import timezone
-from operator import or_
-from six.moves import reduce
-
-from sentry import buffer
-from sentry.tagstore import TagKeyStatus
-from sentry.tagstore.base import TagStorage, TOP_VALUES_DEFAULT_LIMIT
-from sentry.utils import db
-
-from . import models
-from sentry.tagstore.types import TagKey, TagValue, GroupTagKey, GroupTagValue
-from sentry.tasks.post_process import index_event_tags
-
-
-logger = logging.getLogger("sentry.tagstore.v2")
-
-transformers = {
-    models.TagKey: lambda instance: TagKey(
-        key=instance.key, values_seen=instance.values_seen, status=instance.status
-    ),
-    models.TagValue: lambda instance: TagValue(
-        key=instance.key,
-        value=instance.value,
-        times_seen=instance.times_seen,
-        first_seen=instance.first_seen,
-        last_seen=instance.last_seen,
-    ),
-    models.GroupTagKey: lambda instance: GroupTagKey(
-        group_id=instance.group_id, key=instance.key, values_seen=instance.values_seen
-    ),
-    models.GroupTagValue: lambda instance: GroupTagValue(
-        group_id=instance.group_id,
-        key=instance.key,
-        value=instance.value,
-        times_seen=instance.times_seen,
-        first_seen=instance.first_seen,
-        last_seen=instance.last_seen,
-    ),
-}
-
-AGGREGATE_ENVIRONMENT_ID = 0
-
-
-class V2TagStorage(TagStorage):
-    """\
-    The v2 tagstore backend stores and respects ``environment_id``.
-
-    An ``environment_id`` value of ``None`` is used to keep track of the aggregate value across
-    all environments.
-    """
-
-    def setup(self):
-        self.setup_deletions()
-
-        self.setup_cleanup()
-
-        self.setup_merge(
-            grouptagkey_model=models.GroupTagKey, grouptagvalue_model=models.GroupTagValue
-        )
-
-        self.setup_receivers()
-
-    def setup_cleanup(self):
-        from sentry.runner.commands import cleanup
-
-        cleanup.EXTRA_BULK_QUERY_DELETES += [
-            (models.GroupTagValue, "last_seen", None),
-            (models.TagValue, "last_seen", None),
-            (models.EventTag, "date_added", "date_added", 50000),
-        ]
-
-    def setup_deletions(self):
-        from sentry.deletions import default_manager as deletion_manager
-        from sentry.deletions.defaults import BulkModelDeletionTask, ModelDeletionTask
-        from sentry.deletions.base import ModelRelation
-        from sentry.models import Event, Group, Project
-
-        deletion_manager.add_bulk_dependencies(
-            Event,
-            [
-                lambda instance_list: ModelRelation(
-                    models.EventTag,
-                    {
-                        "event_id__in": [i.id for i in instance_list],
-                        "project_id": instance_list[0].project_id,
-                    },
-                    ModelDeletionTask,
-                )
-            ],
-        )
-
-        deletion_manager.register(models.TagValue, BulkModelDeletionTask)
-        deletion_manager.register(models.GroupTagKey, BulkModelDeletionTask)
-        deletion_manager.register(models.GroupTagValue, BulkModelDeletionTask)
-        deletion_manager.register(models.EventTag, BulkModelDeletionTask)
-
-        deletion_manager.add_dependencies(
-            Group,
-            [
-                lambda instance: ModelRelation(
-                    models.EventTag,
-                    query={"group_id": instance.id, "project_id": instance.project_id},
-                    partition_key={"project_id": instance.project_id},
-                ),
-                lambda instance: ModelRelation(
-                    models.GroupTagKey,
-                    query={"group_id": instance.id, "project_id": instance.project_id},
-                    partition_key={"project_id": instance.project_id},
-                ),
-                lambda instance: ModelRelation(
-                    models.GroupTagValue,
-                    query={"group_id": instance.id, "project_id": instance.project_id},
-                    partition_key={"project_id": instance.project_id},
-                ),
-            ],
-        )
-
-        deletion_manager.add_dependencies(
-            Project,
-            [
-                lambda instance: ModelRelation(models.TagKey, query={"project_id": instance.id}),
-                lambda instance: ModelRelation(
-                    models.TagValue,
-                    query={"project_id": instance.id},
-                    partition_key={"project_id": instance.id},
-                ),
-                lambda instance: ModelRelation(
-                    models.GroupTagKey,
-                    query={"project_id": instance.id},
-                    partition_key={"project_id": instance.id},
-                ),
-                lambda instance: ModelRelation(
-                    models.GroupTagValue,
-                    query={"project_id": instance.id},
-                    partition_key={"project_id": instance.id},
-                ),
-            ],
-        )
-
-        # NOTE: EventTag is handled by cleanup
-
-        class TagKeyDeletionTask(ModelDeletionTask):
-            def get_child_relations(self, instance):
-                # in bulk
-                model_list = (models.GroupTagValue, models.GroupTagKey, models.TagValue)
-
-                # required to deal with custom SQL queries and the ORM
-                # in `bulk_delete_objects`
-                key_id_field_name = "key_id" if (db.is_postgres()) else "_key_id"
-
-                relations = [
-                    ModelRelation(
-                        m,
-                        query={"project_id": instance.project_id, key_id_field_name: instance.id},
-                        partition_key={"project_id": instance.project_id},
-                    )
-                    for m in model_list
-                ]
-                return relations
-
-            def mark_deletion_in_progress(self, instance_list):
-                for instance in instance_list:
-                    if instance.status != TagKeyStatus.DELETION_IN_PROGRESS:
-                        models.TagKey.objects.filter(
-                            id=instance.id, project_id=instance.project_id
-                        ).update(status=TagKeyStatus.DELETION_IN_PROGRESS)
-
-        deletion_manager.register(models.TagKey, TagKeyDeletionTask)
-
-    def setup_receivers(self):
-        from django.db.models.signals import post_save
-
-        def record_project_tag_count(instance, created, **kwargs):
-            if not created:
-                return
-
-            buffer.incr(
-                models.TagKey,
-                columns={"values_seen": 1},
-                filters={"id": instance._key_id, "project_id": instance.project_id},
-            )
-
-        def record_group_tag_count(instance, created, **kwargs):
-            if not created:
-                return
-
-            buffer.incr(
-                models.GroupTagKey,
-                columns={"values_seen": 1},
-                filters={
-                    "project_id": instance.project_id,
-                    "group_id": instance.group_id,
-                    "_key_id": instance._key_id,
-                },
-            )
-
-        post_save.connect(record_project_tag_count, sender=models.TagValue, weak=False)
-        post_save.connect(record_group_tag_count, sender=models.GroupTagValue, weak=False)
-
-    def create_tag_key(self, project_id, environment_id, key, **kwargs):
-        environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-        return models.TagKey.objects.create(
-            project_id=project_id, environment_id=environment_id, key=key, **kwargs
-        )
-
-    def get_or_create_tag_keys_bulk(self, project_id, environment_id, keys):
-        assert environment_id is not None
-
-        return models.TagKey.get_or_create_bulk(
-            project_id=project_id, environment_id=environment_id, keys=keys
-        )
-
-    def get_or_create_tag_values_bulk(self, project_id, tags):
-        return models.TagValue.get_or_create_bulk(project_id=project_id, tags=tags)
-
-    def get_or_create_tag_key(self, project_id, environment_id, key, **kwargs):
-        assert environment_id is not None
-
-        return models.TagKey.get_or_create(
-            project_id=project_id, environment_id=environment_id, key=key, **kwargs
-        )
-
-    def create_tag_value(self, project_id, environment_id, key, value, **kwargs):
-        environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-        tag_key_kwargs = kwargs.copy()
-        for k in ["times_seen", "first_seen", "last_seen"]:
-            tag_key_kwargs.pop(k, None)
-
-        tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **tag_key_kwargs)
-
-        tv = models.TagValue.objects.create(
-            project_id=project_id, _key_id=tag_key.id, value=value, **kwargs
-        )
-
-        tv.key = key
-        return tv
-
-    def get_or_create_tag_value(
-        self, project_id, environment_id, key, value, key_id=None, **kwargs
-    ):
-        assert environment_id is not None
-
-        if key_id is None:
-            tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **kwargs)
-            key_id = tag_key.id
-
-        tv, created = models.TagValue.get_or_create(
-            project_id=project_id, _key_id=key_id, value=value, **kwargs
-        )
-
-        tv.key = key
-        return (tv, created)
-
-    def create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
-        environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-        tag_key_kwargs = kwargs.copy()
-        tag_key_kwargs.pop("values_seen", None)
-
-        tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **tag_key_kwargs)
-
-        gtk = models.GroupTagKey.objects.create(
-            project_id=project_id, group_id=group_id, _key_id=tag_key.id, **kwargs
-        )
-
-        gtk.key = key
-        return gtk
-
-    def get_or_create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
-        assert environment_id is not None
-
-        tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **kwargs)
-
-        gtk, created = models.GroupTagKey.objects.get_or_create(
-            project_id=project_id, group_id=group_id, _key_id=tag_key.id, **kwargs
-        )
-
-        gtk.key = key
-        return (gtk, created)
-
-    def create_group_tag_value(self, project_id, group_id, environment_id, key, value, **kwargs):
-        environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-        other_kwargs = kwargs.copy()
-        for k in ["times_seen", "first_seen", "last_seen"]:
-            other_kwargs.pop(k, None)
-
-        tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **other_kwargs)
-
-        tag_value, _ = self.get_or_create_tag_value(
-            project_id, environment_id, key, value, key_id=tag_key.id, **other_kwargs
-        )
-
-        gtv = models.GroupTagValue.objects.create(
-            project_id=project_id,
-            group_id=group_id,
-            _key_id=tag_key.id,
-            _value_id=tag_value.id,
-            **kwargs
-        )
-
-        gtv.key = key
-        gtv.value = value
-        return gtv
-
-    def get_or_create_group_tag_value(
-        self, project_id, group_id, environment_id, key, value, **kwargs
-    ):
-        assert environment_id is not None
-
-        if "defaults" in kwargs:
-            # while backfilling v2 it is possible that a user performs an unmerge
-            # (which contains default values in kwargs) AND where the TagKey actually
-            # doesn't exist in the v2 database yet, so the defaults are used in create
-            # and explode because the fields don't actually exist in TagKey
-            # this is solved here as a one-off because it's very seldomly used and in
-            # the hot path for basically everything to do with tags
-            kcopy = kwargs.copy()
-            kcopy.pop("defaults")
-            tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **kcopy)
-
-            tag_value, _ = self.get_or_create_tag_value(
-                project_id, environment_id, key, value, key_id=tag_key.id, **kcopy
-            )
-
-        else:
-            tag_key, _ = self.get_or_create_tag_key(project_id, environment_id, key, **kwargs)
-
-            tag_value, _ = self.get_or_create_tag_value(
-                project_id, environment_id, key, value, key_id=tag_key.id, **kwargs
-            )
-
-        gtv, created = models.GroupTagValue.objects.get_or_create(
-            project_id=project_id,
-            group_id=group_id,
-            _key_id=tag_key.id,
-            _value_id=tag_value.id,
-            **kwargs
-        )
-
-        gtv.key = key
-        gtv.value = value
-        return (gtv, created)
-
-    def create_event_tags(
-        self, project_id, group_id, environment_id, event_id, tags, date_added=None
-    ):
-        assert environment_id is not None
-
-        if date_added is None:
-            date_added = timezone.now()
-
-        tagkeys = self.get_or_create_tag_keys_bulk(project_id, environment_id, [t[0] for t in tags])
-        tagvalues = self.get_or_create_tag_values_bulk(
-            project_id, [(tagkeys[t[0]], t[1]) for t in tags]
-        )
-        tag_ids = [(tk.id, tv.id) for (tk, _), tv in tagvalues.items()]
-
-        try:
-            # don't let a duplicate break the outer transaction
-            with transaction.atomic():
-                # Tags are bulk inserted because this is an all-or-nothing situation.
-                # Either the whole transaction works, or it doesn't. There's no value
-                # in a partial success where we'd need to replay half of the rows.
-                models.EventTag.objects.bulk_create(
-                    [
-                        models.EventTag(
-                            project_id=project_id,
-                            group_id=group_id,
-                            event_id=event_id,
-                            key_id=key_id,
-                            value_id=value_id,
-                            date_added=date_added,
-                        )
-                        for key_id, value_id in tag_ids
-                    ]
-                )
-        except IntegrityError:
-            logger.error(
-                "tagstore.create_event_tags.integrity_error",
-                extra={"project_id": project_id, "group_id": group_id, "event_id": event_id},
-                exc_info=True,
-            )
-
-    def get_tag_key(self, project_id, environment_id, key, status=TagKeyStatus.VISIBLE):
-        from sentry.tagstore.exceptions import TagKeyNotFound
-
-        qs = models.TagKey.objects.filter(project_id=project_id, key=key)
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        if status is not None:
-            qs = qs.filter(status=status)
-
-        try:
-            instance = qs.get()
-        except models.TagKey.DoesNotExist:
-            raise TagKeyNotFound
-
-        return transformers[models.TagKey](instance)
-
-    def get_tag_keys(
-        self, project_id, environment_id, status=TagKeyStatus.VISIBLE, include_values_seen=False
-    ):
-        qs = models.TagKey.objects.filter(project_id=project_id)
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        if status is not None:
-            qs = qs.filter(status=status)
-
-        return set(map(transformers[models.TagKey], qs))
-
-    def get_tag_value(self, project_id, environment_id, key, value):
-        from sentry.tagstore.exceptions import TagValueNotFound
-
-        qs = models.TagValue.objects.select_related("_key").filter(
-            project_id=project_id, _key__project_id=project_id, _key__key=key, value=value
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        try:
-            instance = qs.get()
-        except models.TagValue.DoesNotExist:
-            raise TagValueNotFound
-
-        return transformers[models.TagValue](instance)
-
-    def get_tag_values(self, project_id, environment_id, key):
-        qs = models.TagValue.objects.select_related("_key").filter(
-            project_id=project_id, _key__project_id=project_id, _key__key=key
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        return set(map(transformers[models.TagValue], qs))
-
-    def get_group_tag_key(self, project_id, group_id, environment_id, key):
-        from sentry.tagstore.exceptions import GroupTagKeyNotFound
-
-        qs = models.GroupTagKey.objects.select_related("_key").filter(
-            project_id=project_id, group_id=group_id, _key__project_id=project_id, _key__key=key
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        try:
-            instance = qs.get()
-        except models.GroupTagKey.DoesNotExist:
-            raise GroupTagKeyNotFound
-
-        return transformers[models.GroupTagKey](instance)
-
-    def get_group_tag_keys(self, project_id, group_id, environment_ids, limit=None, keys=None):
-        # only the snuba backend supports multi env
-        if environment_ids and len(environment_ids) > 1:
-            raise NotImplementedError
-
-        environment_id = environment_ids[0] if environment_ids else None
-
-        qs = models.GroupTagKey.objects.select_related("_key").filter(
-            project_id=project_id, group_id=group_id, _key__project_id=project_id
-        )
-        if keys is not None:
-            qs = qs.filter(_key__key__in=keys)
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        if limit is not None:
-            qs = qs[:limit]
-
-        return set(map(transformers[models.GroupTagKey], qs))
-
-    def get_group_tag_value(self, project_id, group_id, environment_id, key, value):
-        from sentry.tagstore.exceptions import GroupTagValueNotFound
-
-        value = self.get_group_list_tag_value(
-            [project_id], [group_id], [environment_id], key, value
-        ).get(group_id)
-
-        if value is None:
-            raise GroupTagValueNotFound
-
-        return value
-
-    def get_group_tag_values(self, project_id, group_id, environment_id, key):
-        qs = models.GroupTagValue.objects.select_related("_key", "_value").filter(
-            project_id=project_id,
-            group_id=group_id,
-            _key__project_id=project_id,
-            _key__key=key,
-            _value__project_id=project_id,
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        return list(map(transformers[models.GroupTagValue], qs))
-
-    def get_group_list_tag_value(self, project_ids, group_id_list, environment_ids, key, value):
-        # only the snuba backend supports multi project/env
-        if len(project_ids) > 1 or environment_ids and len(environment_ids) > 1:
-            raise NotImplementedError
-
-        qs = models.GroupTagValue.objects.select_related("_key", "_value").filter(
-            project_id=project_ids[0],
-            group_id__in=group_id_list,
-            _key__project_id=project_ids[0],
-            _key__key=key,
-            _value__project_id=project_ids[0],
-            _value__value=value,
-        )
-
-        qs = self._add_environment_filter(qs, environment_ids[0])
-        t = transformers[models.GroupTagValue]
-        return {result.group_id: t(result) for result in qs}
-
-    def delete_tag_key(self, project_id, key):
-        from sentry.tagstore.tasks import delete_tag_key as delete_tag_key_task
-
-        tagkeys_qs = models.TagKey.objects.filter(project_id=project_id, key=key)
-
-        deleted = []
-        for tagkey in tagkeys_qs:
-            updated = models.TagKey.objects.filter(
-                id=tagkey.id, project_id=project_id, status=TagKeyStatus.VISIBLE
-            ).update(status=TagKeyStatus.PENDING_DELETION)
-
-            if updated:
-                delete_tag_key_task.delay(object_id=tagkey.id, model=models.TagKey)
-                deleted.append(tagkey)
-
-        return deleted
-
-    def delete_all_group_tag_keys(self, project_id, group_id):
-        using = router.db_for_read(models.GroupTagKey)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_grouptagkey
-            WHERE project_id = %s
-              AND group_id = %s
-        """,
-            [project_id, group_id],
-        )
-
-    def delete_all_group_tag_values(self, project_id, group_id):
-        using = router.db_for_read(models.GroupTagValue)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_grouptagvalue
-            WHERE project_id = %s
-              AND group_id = %s
-        """,
-            [project_id, group_id],
-        )
-
-    def incr_tag_value_times_seen(
-        self, project_id, environment_id, key, value, extra=None, count=1
-    ):
-        for env in [environment_id, AGGREGATE_ENVIRONMENT_ID]:
-            tagkey, _ = self.get_or_create_tag_key(project_id, env, key)
-
-            buffer.incr(
-                models.TagValue,
-                columns={"times_seen": count},
-                filters={"project_id": project_id, "_key_id": tagkey.id, "value": value},
-                extra=extra,
-            )
-
-    def incr_group_tag_value_times_seen(
-        self, project_id, group_id, environment_id, key, value, extra=None, count=1
-    ):
-        for env in [environment_id, AGGREGATE_ENVIRONMENT_ID]:
-            tagkey, _ = self.get_or_create_tag_key(project_id, env, key)
-            tagvalue, _ = self.get_or_create_tag_value(
-                project_id, env, key, value, key_id=tagkey.id
-            )
-
-            buffer.incr(
-                models.GroupTagValue,
-                columns={"times_seen": count},
-                filters={
-                    "project_id": project_id,
-                    "group_id": group_id,
-                    "_key_id": tagkey.id,
-                    "_value_id": tagvalue.id,
-                },
-                extra=extra,
-            )
-
-    def get_group_event_filter(self, project_id, group_id, environment_ids, tags, start, end):
-        # NOTE: `environment_id=None` needs to be filtered differently in this method.
-        # EventTag never has NULL `environment_id` fields (individual Events always have an environment),
-        # and so `environment_id=None` needs to query EventTag for *all* environments (except, ironically
-        # the aggregate environment).
-        if environment_ids:
-            # only the snuba backend supports multi env
-            if len(environment_ids) > 1:
-                raise NotImplementedError
-            environment_id = environment_ids[0]
-        else:
-            environment_id = None
-
-        if environment_id is None:
-            # filter for all 'real' environments
-            exclude = {"_key__environment_id": AGGREGATE_ENVIRONMENT_ID}
-            env_filter = {}
-        else:
-            exclude = {}
-            env_filter = {"_key__environment_id": environment_id}
-
-        tagvalue_qs = models.TagValue.objects.filter(
-            reduce(
-                or_,
-                (
-                    Q(_key__key=k, _key__status=TagKeyStatus.VISIBLE, value=v)
-                    for k, v in six.iteritems(tags)
-                ),
-            ),
-            project_id=project_id,
-            _key__project_id=project_id,
-            **env_filter
-        )
-
-        if exclude:
-            tagvalue_qs = tagvalue_qs.exclude(**exclude)
-
-        tagvalue_qs = tagvalue_qs.values_list("_key_id", "id", "_key__key", "value")
-
-        tagvalues = defaultdict(list)
-        for key_id, value_id, key, value in tagvalue_qs:
-            tagvalues[(key, value)].append((key_id, value_id))
-        tagvalues = dict(tagvalues)
-
-        try:
-            # ensure all key/value pairs were found
-            tag_lookups = [tagvalues[(k, v)] for k, v in six.iteritems(tags)]
-            # [[(key0, value0), (key1, value1)], ...]
-        except KeyError:
-            # one or more tags were invalid, thus the result should be an empty
-            # set
-            return None
-
-        # Django doesnt support union, so we limit results and try to find
-        # reasonable matches
-
-        date_filters = Q()
-        if start:
-            date_filters &= Q(date_added__gte=start)
-        if end:
-            date_filters &= Q(date_added__lte=end)
-
-        # get initial matches to start the filter
-        kv_pairs = tag_lookups.pop()
-        matches = list(
-            models.EventTag.objects.filter(
-                reduce(or_, (Q(key_id=k, value_id=v) for k, v in kv_pairs)),
-                date_filters,
-                project_id=project_id,
-                group_id=group_id,
-            ).values_list("event_id", flat=True)[:1000]
-        )
-
-        # for each remaining tag, find matches contained in our
-        # existing set, pruning it down each iteration
-        for kv_pairs in tag_lookups:
-            matches = list(
-                models.EventTag.objects.filter(
-                    reduce(or_, (Q(key_id=k, value_id=v) for k, v in kv_pairs)),
-                    date_filters,
-                    project_id=project_id,
-                    group_id=group_id,
-                    event_id__in=matches,
-                ).values_list("event_id", flat=True)[:1000]
-            )
-            if not matches:
-                return None
-
-        return {"id__in": set(matches)}
-
-    def get_groups_user_counts(self, project_ids, group_ids, environment_ids, start=None, end=None):
-        # only the snuba backend supports multi project/env
-        if len(project_ids) > 1 or environment_ids and len(environment_ids) > 1:
-            raise NotImplementedError
-
-        qs = models.GroupTagKey.objects.filter(
-            project_id=project_ids[0],
-            group_id__in=group_ids,
-            _key__project_id=project_ids[0],
-            _key__key="sentry:user",
-        )
-
-        qs = self._add_environment_filter(qs, environment_ids and environment_ids[0])
-
-        return defaultdict(int, qs.values_list("group_id", "values_seen"))
-
-    def get_group_tag_value_count(self, project_id, group_id, environment_id, key):
-        if db.is_postgres():
-            environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-            # This doesnt guarantee percentage is accurate, but it does ensure
-            # that the query has a maximum cost
-            using = router.db_for_read(models.GroupTagValue)
-            cursor = connections[using].cursor()
-            cursor.execute(
-                """
-                SELECT SUM(t)
-                FROM (
-                    SELECT tagstore_grouptagvalue.times_seen as t
-                    FROM tagstore_grouptagvalue
-                    INNER JOIN tagstore_tagkey
-                    ON (tagstore_grouptagvalue.key_id = tagstore_tagkey.id)
-                    WHERE tagstore_grouptagvalue.group_id = %s
-                    AND tagstore_tagkey.project_id = %s
-                    AND tagstore_grouptagvalue.project_id = %s
-                    AND tagstore_tagkey.environment_id = %s
-                    AND tagstore_tagkey.key = %s
-                    ORDER BY last_seen DESC
-                    LIMIT 10000
-                ) as a
-                """,
-                [group_id, project_id, project_id, environment_id, key],
-            )
-            return cursor.fetchone()[0] or 0
-
-        cutoff = timezone.now() - timedelta(days=7)
-        qs = models.GroupTagValue.objects.filter(
-            project_id=project_id,
-            group_id=group_id,
-            _key__project_id=project_id,
-            _key__key=key,
-            last_seen__gte=cutoff,
-        )
-        qs = self._add_environment_filter(qs, environment_id)
-        return qs.aggregate(t=Sum("times_seen"))["t"]
-
-    def get_top_group_tag_values(
-        self, project_id, group_id, environment_id, key, limit=TOP_VALUES_DEFAULT_LIMIT
-    ):
-        if db.is_postgres():
-            environment_id = AGGREGATE_ENVIRONMENT_ID if environment_id is None else environment_id
-
-            # This doesnt guarantee percentage is accurate, but it does ensure
-            # that the query has a maximum cost
-            return list(
-                map(
-                    transformers[models.GroupTagValue],
-                    models.GroupTagValue.objects.raw(
-                        """
-                        SELECT *
-                        FROM (
-                            SELECT tagstore_grouptagvalue.*
-                            FROM tagstore_grouptagvalue
-                            INNER JOIN tagstore_tagkey
-                            ON (tagstore_grouptagvalue.key_id = tagstore_tagkey.id)
-                            WHERE tagstore_grouptagvalue.group_id = %%s
-                            AND tagstore_tagkey.project_id = %%s
-                            AND tagstore_grouptagvalue.project_id = %%s
-                            AND tagstore_tagkey.environment_id = %%s
-                            AND tagstore_tagkey.key = %%s
-                            ORDER BY last_seen DESC
-                            LIMIT 10000
-                        ) as a
-                        ORDER BY times_seen DESC
-                        LIMIT %d
-                        """
-                        % limit,
-                        [group_id, project_id, project_id, environment_id, key],
-                    ),
-                )
-            )
-
-        cutoff = timezone.now() - timedelta(days=7)
-        qs = models.GroupTagValue.objects.select_related("_key", "_value").filter(
-            project_id=project_id,
-            group_id=group_id,
-            _key__project_id=project_id,
-            _key__key=key,
-            _value__project_id=project_id,
-            last_seen__gte=cutoff,
-        )
-        qs = self._add_environment_filter(qs, environment_id)
-        return list(map(transformers[models.GroupTagValue], qs.order_by("-times_seen")[:limit]))
-
-    def get_first_release(self, project_id, group_id):
-        try:
-            first_release = (
-                models.GroupTagValue.objects.select_related("_value")
-                .filter(
-                    project_id=project_id,
-                    group_id=group_id,
-                    _key__project_id=project_id,
-                    _key__key__in=("sentry:release", "release"),
-                    _value__project_id=project_id,
-                )
-                .order_by("first_seen")[0]
-            )
-        except IndexError:
-            return None
-        else:
-            return first_release.value
-
-    def get_last_release(self, project_id, group_id):
-        try:
-            last_release = (
-                models.GroupTagValue.objects.select_related("_value")
-                .filter(
-                    project_id=project_id,
-                    group_id=group_id,
-                    _key__project_id=project_id,
-                    _key__key__in=("sentry:release", "release"),
-                    _value__project_id=project_id,
-                )
-                .order_by("-last_seen")[0]
-            )
-        except IndexError:
-            return None
-
-        return last_release.value
-
-    def get_release_tags(self, project_ids, environment_id, versions):
-        qs = (
-            models.TagValue.objects.select_related("_key")
-            .filter(
-                project_id__in=project_ids,
-                _key__project_id__in=project_ids,
-                _key__key="sentry:release",
-                value__in=versions,
-            )
-            .extra(
-                where=[
-                    # Force the join also through the shard
-                    "tagstore_tagvalue.project_id = tagstore_tagkey.project_id"
-                ]
-            )
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        return set(map(transformers[models.TagValue], qs))
-
-    def get_group_ids_for_users(self, project_ids, event_users, limit=100):
-        return set(
-            models.GroupTagValue.objects.filter(
-                project_id__in=project_ids,
-                _key__project_id__in=project_ids,
-                _key__environment_id=AGGREGATE_ENVIRONMENT_ID,
-                _key__key="sentry:user",
-                _value___key=F("_key"),
-                _value__value__in=[eu.tag_value for eu in event_users],
-            )
-            .extra(
-                where=[
-                    # Force the join also through the shard
-                    "tagstore_grouptagvalue.project_id = tagstore_tagkey.project_id",
-                    "tagstore_grouptagvalue.project_id = tagstore_tagvalue.project_id",
-                ]
-            )
-            .order_by("-last_seen")
-            .values_list("group_id", flat=True)[:limit]
-        )
-
-    def get_group_tag_values_for_users(self, event_users, limit=100):
-        tag_filters = [
-            Q(_value__value=eu.tag_value, _value__project_id=eu.project_id) for eu in event_users
-        ]
-
-        project_ids = {eu.project_id for eu in event_users}
-
-        return list(
-            map(
-                transformers[models.GroupTagValue],
-                models.GroupTagValue.objects.select_related("_value")
-                .filter(
-                    reduce(or_, tag_filters),
-                    project_id__in=project_ids,
-                    _key__project_id__in=project_ids,
-                    _key__environment_id=AGGREGATE_ENVIRONMENT_ID,
-                    _key__key="sentry:user",
-                    _value__project_id__in=project_ids,
-                )
-                .extra(
-                    where=[
-                        # Force the join also through the shard
-                        "tagstore_grouptagvalue.project_id = tagstore_tagkey.project_id",
-                        "tagstore_grouptagvalue.project_id = tagstore_tagvalue.project_id",
-                    ]
-                )
-                .order_by("-last_seen")[:limit],
-            )
-        )
-
-    def update_group_tag_key_values_seen(self, project_id, group_ids):
-        gtk_qs = models.GroupTagKey.objects.filter(project_id=project_id, group_id__in=group_ids)
-
-        for instance in gtk_qs:
-            models.GroupTagKey.objects.filter(id=instance.id, project_id=project_id).update(
-                values_seen=models.GroupTagValue.objects.filter(
-                    project_id=instance.project_id,
-                    group_id=instance.group_id,
-                    _key_id=instance._key_id,
-                ).count()
-            )
-
-    def get_tag_value_paginator(
-        self, project_id, environment_id, key, query=None, order_by="-last_seen"
-    ):
-        from sentry.api.paginator import DateTimePaginator
-
-        qs = models.TagValue.objects.select_related("_key").filter(
-            project_id=project_id, _key__project_id=project_id, _key__key=key
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        if query:
-            qs = qs.filter(value__contains=query)
-
-        return DateTimePaginator(
-            queryset=qs,
-            order_by=order_by,
-            on_results=lambda results: map(transformers[models.TagValue], results),
-        )
-
-    def get_group_tag_value_iter(self, project_id, group_id, environment_id, key, callbacks=()):
-        from sentry.utils.query import RangeQuerySetWrapper
-
-        qs = self.get_group_tag_value_qs(project_id, group_id, environment_id, key)
-
-        return RangeQuerySetWrapper(queryset=qs, callbacks=callbacks)
-
-    def get_group_tag_value_paginator(
-        self, project_id, group_id, environment_id, key, order_by="-id"
-    ):
-        from sentry.api.paginator import DateTimePaginator, Paginator
-
-        qs = self.get_group_tag_value_qs(project_id, group_id, environment_id, key)
-
-        if order_by in ("-last_seen", "-first_seen"):
-            paginator_cls = DateTimePaginator
-        elif order_by == "-id":
-            paginator_cls = Paginator
-        else:
-            raise ValueError("Unsupported order_by: %s" % order_by)
-
-        return paginator_cls(
-            queryset=qs,
-            order_by=order_by,
-            on_results=lambda results: map(transformers[models.GroupTagValue], results),
-        )
-
-    def get_group_tag_value_qs(self, project_id, group_id, environment_id, key, value=None):
-        qs = models.GroupTagValue.objects.select_related("_key", "_value").filter(
-            project_id=project_id,
-            _key__project_id=project_id,
-            _key__key=key,
-            _value__project_id=project_id,
-        )
-
-        if isinstance(group_id, collections.Iterable):
-            qs = qs.filter(group_id__in=group_id)
-        else:
-            qs = qs.filter(group_id=group_id)
-
-        if value is not None:
-            qs = qs.filter(_value__project_id=project_id, _value__value=value)
-
-        qs = self._add_environment_filter(qs, environment_id)
-        return qs
-
-    def update_group_for_events(self, project_id, event_ids, destination_id):
-        return models.EventTag.objects.filter(project_id=project_id, event_id__in=event_ids).update(
-            group_id=destination_id
-        )
-
-    def _add_environment_filter(self, queryset, environment_id):
-        """\
-        Filter a queryset by the provided `environment_id`, handling
-        whether a JOIN is required or not depending on the model.
-        """
-        if environment_id is None:
-            environment_id = AGGREGATE_ENVIRONMENT_ID
-
-        if queryset.model == models.TagKey:
-            return queryset.filter(environment_id=environment_id)
-        elif queryset.model in (models.EventTag,):
-            return queryset.filter(key__environment_id=environment_id)
-        elif queryset.model in (models.TagValue, models.GroupTagKey, models.GroupTagValue):
-            return queryset.filter(_key__environment_id=environment_id)
-        else:
-            raise ValueError("queryset of unsupported model '%s' provided" % queryset.model)
-
-    def delay_index_event_tags(
-        self, organization_id, project_id, group_id, environment_id, event_id, tags, date_added
-    ):
-        index_event_tags.delay(
-            organization_id=organization_id,
-            project_id=project_id,
-            group_id=group_id,
-            environment_id=environment_id,
-            event_id=event_id,
-            tags=tags,
-            date_added=date_added,
-        )
diff --git a/src/sentry/tagstore/v2/models/__init__.py b/src/sentry/tagstore/v2/models/__init__.py
deleted file mode 100644
index 1422fb52ef..0000000000
--- a/src/sentry/tagstore/v2/models/__init__.py
+++ /dev/null
@@ -1,5 +0,0 @@
-from __future__ import absolute_import
-
-from sentry.utils.imports import import_submodules
-
-import_submodules(globals(), __name__, __path__)
diff --git a/src/sentry/tagstore/v2/models/eventtag.py b/src/sentry/tagstore/v2/models/eventtag.py
deleted file mode 100644
index 110d1d279f..0000000000
--- a/src/sentry/tagstore/v2/models/eventtag.py
+++ /dev/null
@@ -1,36 +0,0 @@
-from __future__ import absolute_import
-
-from django.db import models, router, connections
-from django.utils import timezone
-
-from sentry.db.models import Model, BoundedBigIntegerField, FlexibleForeignKey, sane_repr
-
-
-class EventTag(Model):
-    __core__ = False
-
-    project_id = BoundedBigIntegerField()
-    group_id = BoundedBigIntegerField()
-    event_id = BoundedBigIntegerField()
-    key = FlexibleForeignKey("tagstore.TagKey", db_column="key_id")
-    value = FlexibleForeignKey("tagstore.TagValue", db_column="value_id")
-    date_added = models.DateTimeField(default=timezone.now, db_index=True)
-
-    class Meta:
-        app_label = "tagstore"
-        unique_together = (("project_id", "event_id", "key", "value"),)
-        index_together = (("project_id", "key", "value"), ("group_id", "key", "value"))
-
-    __repr__ = sane_repr("event_id", "key_id", "value_id")
-
-    def delete(self):
-        using = router.db_for_read(EventTag)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_eventtag
-            WHERE project_id = %s
-              AND id = %s
-        """,
-            [self.project_id, self.id],
-        )
diff --git a/src/sentry/tagstore/v2/models/grouptagkey.py b/src/sentry/tagstore/v2/models/grouptagkey.py
deleted file mode 100644
index 1410b59e8d..0000000000
--- a/src/sentry/tagstore/v2/models/grouptagkey.py
+++ /dev/null
@@ -1,89 +0,0 @@
-from __future__ import absolute_import
-
-from django.db import router, transaction, DataError, connections
-
-from sentry.db.models import (
-    Model,
-    BoundedPositiveIntegerField,
-    BoundedBigIntegerField,
-    FlexibleForeignKey,
-    sane_repr,
-)
-from sentry.tagstore.query import TagStoreManager
-
-
-class GroupTagKey(Model):
-    """
-    Stores a unique tag key name for a group.
-
-    An example key might be "url" or "server_name".
-    """
-
-    __core__ = False
-
-    project_id = BoundedBigIntegerField(db_index=True)
-    group_id = BoundedBigIntegerField(db_index=True)
-    _key = FlexibleForeignKey("tagstore.TagKey", db_column="key_id")
-    values_seen = BoundedPositiveIntegerField(default=0)
-
-    objects = TagStoreManager()
-
-    class Meta:
-        app_label = "tagstore"
-        unique_together = (("project_id", "group_id", "_key"),)
-
-    __repr__ = sane_repr("project_id", "group_id", "_key_id")
-
-    def delete(self):
-        using = router.db_for_read(GroupTagKey)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_grouptagkey
-            WHERE project_id = %s
-              AND id = %s
-        """,
-            [self.project_id, self.id],
-        )
-
-    @property
-    def key(self):
-        if hasattr(self, "_set_key"):
-            return self._set_key
-
-        if hasattr(self, "__key_cache"):
-            return self._key.key
-
-        # fallback
-        from sentry.tagstore.v2.models import TagKey
-
-        tk = (
-            TagKey.objects.filter(project_id=self.project_id, id=self._key_id)
-            .values_list("key", flat=True)
-            .get()
-        )
-
-        # cache for future calls
-        self.key = tk
-
-        return tk
-
-    @key.setter
-    def key(self, key):
-        self._set_key = key
-
-    def merge_counts(self, new_group):
-        from sentry.tagstore.v2.models import GroupTagValue
-
-        try:
-            with transaction.atomic(using=router.db_for_write(GroupTagKey)):
-                GroupTagKey.objects.filter(
-                    group_id=new_group.id, project_id=new_group.project_id, _key_id=self._key_id
-                ).update(
-                    values_seen=GroupTagValue.objects.filter(
-                        group_id=new_group.id, project_id=new_group.project_id, _key_id=self._key_id
-                    ).count()
-                )
-        except DataError:
-            # it's possible to hit an out of range value for counters
-            pass
diff --git a/src/sentry/tagstore/v2/models/grouptagvalue.py b/src/sentry/tagstore/v2/models/grouptagvalue.py
deleted file mode 100644
index 888dafdd18..0000000000
--- a/src/sentry/tagstore/v2/models/grouptagvalue.py
+++ /dev/null
@@ -1,165 +0,0 @@
-from __future__ import absolute_import
-
-import six
-
-from django.db import models, router, transaction, DataError, connections
-from django.utils import timezone
-
-from sentry.api.serializers import Serializer, register
-from sentry.db.models import (
-    Model,
-    BoundedPositiveIntegerField,
-    BoundedBigIntegerField,
-    FlexibleForeignKey,
-    sane_repr,
-)
-from sentry.tagstore.query import TagStoreManager
-
-
-class GroupTagValue(Model):
-    """
-    Stores the total number of messages seen by a group matching
-    the given filter.
-    """
-
-    __core__ = False
-
-    project_id = BoundedBigIntegerField(db_index=True)
-    group_id = BoundedBigIntegerField(db_index=True)
-    times_seen = BoundedPositiveIntegerField(default=0)
-    _key = FlexibleForeignKey("tagstore.TagKey", db_column="key_id")
-    _value = FlexibleForeignKey("tagstore.TagValue", db_column="value_id")
-    last_seen = models.DateTimeField(default=timezone.now, db_index=True, null=True)
-    first_seen = models.DateTimeField(default=timezone.now, db_index=True, null=True)
-
-    objects = TagStoreManager()
-
-    class Meta:
-        app_label = "tagstore"
-        unique_together = (("project_id", "group_id", "_key", "_value"),)
-        index_together = (("project_id", "_key", "_value", "last_seen"),)
-
-    __repr__ = sane_repr("project_id", "group_id", "_key_id", "_value_id")
-
-    def delete(self):
-        using = router.db_for_read(GroupTagValue)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_grouptagvalue
-            WHERE project_id = %s
-              AND id = %s
-        """,
-            [self.project_id, self.id],
-        )
-
-    @property
-    def key(self):
-        if hasattr(self, "_set_key"):
-            return self._set_key
-
-        if hasattr(self, "__key_cache"):
-            return self._key.key
-
-        # fallback
-        from sentry.tagstore.v2.models import TagKey
-
-        try:
-            tk = (
-                TagKey.objects.filter(project_id=self.project_id, id=self._key_id)
-                .values_list("key", flat=True)
-                .get()
-            )
-        except TagKey.DoesNotExist:
-            # Data got inconsistent, I must delete myself.
-            self.delete()
-            return None
-
-        # cache for future calls
-        self.key = tk
-
-        return tk
-
-    @key.setter
-    def key(self, key):
-        self._set_key = key
-
-    @property
-    def value(self):
-        if hasattr(self, "_set_value"):
-            return self._set_value
-
-        if hasattr(self, "__value_cache"):
-            return self._value.value
-
-        # fallback
-        from sentry.tagstore.v2.models import TagValue
-
-        try:
-            tv = (
-                TagValue.objects.filter(project_id=self.project_id, id=self._value_id)
-                .values_list("value", flat=True)
-                .get()
-            )
-        except TagValue.DoesNotExist:
-            # Data got inconsistent, I must delete myself.
-            self.delete()
-            return ""
-
-        # cache for future calls
-        self.value = tv
-
-        return tv
-
-    @value.setter
-    def value(self, value):
-        self._set_value = value
-
-    def save(self, *args, **kwargs):
-        if not self.first_seen:
-            self.first_seen = self.last_seen
-        super(GroupTagValue, self).save(*args, **kwargs)
-
-    def merge_counts(self, new_group):
-        try:
-            with transaction.atomic(using=router.db_for_write(GroupTagValue)):
-                new_obj, _ = GroupTagValue.objects.get_or_create(
-                    group_id=new_group.id,
-                    project_id=new_group.project_id,
-                    _key_id=self._key_id,
-                    _value_id=self._value_id,
-                )
-
-                GroupTagValue.objects.filter(id=new_obj.id, project_id=new_group.project_id).update(
-                    first_seen=min(new_obj.first_seen, self.first_seen),
-                    last_seen=max(new_obj.last_seen, self.last_seen),
-                    times_seen=new_obj.times_seen + self.times_seen,
-                )
-        except DataError:
-            # it's possible to hit an out of range value for counters
-            pass
-
-
-@register(GroupTagValue)
-class GroupTagValueSerializer(Serializer):
-    def get_attrs(self, item_list, user):
-        from sentry import tagstore
-
-        result = {}
-        for item in item_list:
-            result[item] = {"name": tagstore.get_tag_value_label(item.key, item.value)}
-
-        return result
-
-    def serialize(self, obj, attrs, user):
-        from sentry import tagstore
-
-        return {
-            "id": six.text_type(obj.id),
-            "name": attrs["name"],
-            "key": tagstore.get_standardized_key(obj.key),
-            "value": obj.value,
-            "count": obj.times_seen,
-            "lastSeen": obj.last_seen,
-            "firstSeen": obj.first_seen,
-        }
diff --git a/src/sentry/tagstore/v2/models/tagkey.py b/src/sentry/tagstore/v2/models/tagkey.py
deleted file mode 100644
index 9aac9d1fff..0000000000
--- a/src/sentry/tagstore/v2/models/tagkey.py
+++ /dev/null
@@ -1,156 +0,0 @@
-from __future__ import absolute_import, print_function
-
-from django.db import models, router, connections, transaction, IntegrityError
-from django.utils.translation import ugettext_lazy as _
-
-from sentry.tagstore import TagKeyStatus
-from sentry.tagstore.query import TagStoreManager
-from sentry.constants import MAX_TAG_KEY_LENGTH
-from sentry.db.models import Model, BoundedPositiveIntegerField, BoundedBigIntegerField, sane_repr
-from sentry.utils.cache import cache
-from sentry.utils.hashlib import md5_text
-
-
-class TagKey(Model):
-    """
-    Stores references to available filters keys.
-    """
-
-    __core__ = False
-
-    project_id = BoundedBigIntegerField(db_index=True)
-    environment_id = BoundedBigIntegerField()
-    key = models.CharField(max_length=MAX_TAG_KEY_LENGTH)
-    values_seen = BoundedPositiveIntegerField(default=0)
-    status = BoundedPositiveIntegerField(
-        choices=(
-            (TagKeyStatus.VISIBLE, _("Visible")),
-            (TagKeyStatus.PENDING_DELETION, _("Pending Deletion")),
-            (TagKeyStatus.DELETION_IN_PROGRESS, _("Deletion in Progress")),
-        ),
-        default=TagKeyStatus.VISIBLE,
-    )
-
-    objects = TagStoreManager()
-
-    class Meta:
-        app_label = "tagstore"
-        unique_together = (("project_id", "environment_id", "key"),)
-
-    __repr__ = sane_repr("project_id", "environment_id", "key")
-
-    def delete(self):
-        using = router.db_for_read(TagKey)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_tagkey
-            WHERE project_id = %s
-              AND id = %s
-        """,
-            [self.project_id, self.id],
-        )
-
-    def get_label(self):
-        from sentry import tagstore
-
-        return tagstore.get_tag_key_label(self.key)
-
-    def get_audit_log_data(self):
-        return {"key": self.key}
-
-    @classmethod
-    def get_cache_key(cls, project_id, environment_id, key):
-        return "tagkey:1:%s:%s:%s" % (project_id, environment_id, md5_text(key).hexdigest())
-
-    @classmethod
-    def get_or_create(cls, project_id, environment_id, key, **kwargs):
-        cache_key = cls.get_cache_key(project_id, environment_id, key)
-
-        rv = cache.get(cache_key)
-        created = False
-        if rv is None:
-            rv, created = cls.objects.get_or_create(
-                project_id=project_id, environment_id=environment_id, key=key, **kwargs
-            )
-            cache.set(cache_key, rv, 3600)
-
-        return rv, created
-
-    @classmethod
-    def get_or_create_bulk(cls, project_id, environment_id, keys):
-        # Attempt to create a bunch of models in one big batch with as few
-        # queries and cache calls as possible.
-        # In best case, this is all done in 1 cache get.
-        # In ideal case, we'll do 3 queries total instead of N.
-        # Absolute worst case, we still just do O(n) queries, but this should be rare.
-        key_to_model = {key: None for key in keys}
-        remaining_keys = set(keys)
-
-        # First attempt to hit from cache, which in theory is the hot case
-        cache_key_to_key = {cls.get_cache_key(project_id, environment_id, key): key for key in keys}
-        cache_key_to_models = cache.get_many(cache_key_to_key.keys())
-        for model in cache_key_to_models.values():
-            key_to_model[model.key] = model
-            remaining_keys.remove(model.key)
-
-        if not remaining_keys:
-            # 100% cache hit on all items, good work team
-            return key_to_model
-
-        # If we have some misses, we want to first check if
-        # all of the misses actually exist in the database
-        # already in one bulk query.
-        to_cache = {}
-        for model in cls.objects.filter(
-            project_id=project_id, environment_id=environment_id, key__in=remaining_keys
-        ):
-            key_to_model[model.key] = to_cache[
-                cls.get_cache_key(project_id, environment_id, model.key)
-            ] = model
-            remaining_keys.remove(model.key)
-
-        # If we have found them all, cache all these misses
-        # and return all the hits.
-        if not remaining_keys:
-            cache.set_many(to_cache, 3600)
-            return key_to_model
-
-        # At this point, we need to create all of our keys, since they
-        # don't exist in cache or the database.
-
-        # First attempt to create them all in one bulk query
-        try:
-            with transaction.atomic():
-                cls.objects.bulk_create(
-                    [
-                        cls(project_id=project_id, environment_id=environment_id, key=key)
-                        for key in remaining_keys
-                    ]
-                )
-        except IntegrityError:
-            pass
-        else:
-            # If we succeed, the shitty part is we need one
-            # more query to get back the actual rows with their ids.
-            for model in cls.objects.filter(
-                project_id=project_id, environment_id=environment_id, key__in=remaining_keys
-            ):
-                key_to_model[model.key] = to_cache[
-                    cls.get_cache_key(project_id, environment_id, model.key)
-                ] = model
-                remaining_keys.remove(model.key)
-
-            cache.set_many(to_cache, 3600)
-
-            # Not clear if this could actually happen, but if it does,
-            # guard ourselves against returning bad data.
-            if not remaining_keys:
-                return key_to_model
-
-        # Fall back to just doing it manually
-        # This case will only ever happen in a race condition.
-        for key in remaining_keys:
-            key_to_model[key] = cls.get_or_create(project_id, environment_id, key)[0]
-
-        return key_to_model
diff --git a/src/sentry/tagstore/v2/models/tagvalue.py b/src/sentry/tagstore/v2/models/tagvalue.py
deleted file mode 100644
index b28ae52262..0000000000
--- a/src/sentry/tagstore/v2/models/tagvalue.py
+++ /dev/null
@@ -1,169 +0,0 @@
-from __future__ import absolute_import, print_function
-
-import six
-
-from django.db import models, router, connections
-from django.utils import timezone
-
-from sentry.api.serializers import Serializer, register
-from sentry.constants import MAX_TAG_VALUE_LENGTH
-from sentry.db.models import (
-    Model,
-    BoundedPositiveIntegerField,
-    BoundedBigIntegerField,
-    GzippedDictField,
-    FlexibleForeignKey,
-    sane_repr,
-)
-from sentry.search.utils import convert_user_tag_to_query
-from sentry.tagstore.query import TagStoreManager
-from sentry.utils.cache import cache
-from sentry.utils.hashlib import md5_text
-
-
-class TagValue(Model):
-    """
-    Stores references to available filters.
-    """
-
-    __core__ = False
-
-    project_id = BoundedBigIntegerField(db_index=True)
-    _key = FlexibleForeignKey("tagstore.TagKey", db_column="key_id")
-    value = models.CharField(max_length=MAX_TAG_VALUE_LENGTH)
-    data = GzippedDictField(blank=True, null=True)
-    times_seen = BoundedPositiveIntegerField(default=0)
-    last_seen = models.DateTimeField(default=timezone.now, db_index=True, null=True)
-    first_seen = models.DateTimeField(default=timezone.now, db_index=True, null=True)
-
-    objects = TagStoreManager()
-
-    class Meta:
-        app_label = "tagstore"
-        unique_together = (("project_id", "_key", "value"),)
-        index_together = (("project_id", "_key", "last_seen"),)
-
-    __repr__ = sane_repr("project_id", "_key_id", "value")
-
-    def delete(self):
-        using = router.db_for_read(TagValue)
-        cursor = connections[using].cursor()
-        cursor.execute(
-            """
-            DELETE FROM tagstore_tagvalue
-            WHERE project_id = %s
-              AND id = %s
-        """,
-            [self.project_id, self.id],
-        )
-
-    @property
-    def key(self):
-        if hasattr(self, "_set_key"):
-            return self._set_key
-
-        if hasattr(self, "__key_cache"):
-            return self._key.key
-
-        # fallback
-        from sentry.tagstore.v2.models import TagKey
-
-        tk = (
-            TagKey.objects.filter(project_id=self.project_id, id=self._key_id)
-            .values_list("key", flat=True)
-            .get()
-        )
-
-        # cache for future calls
-        self.key = tk
-
-        return tk
-
-    @key.setter
-    def key(self, key):
-        self._set_key = key
-
-    def get_label(self):
-        from sentry import tagstore
-
-        return tagstore.get_tag_value_label(self.key, self.value)
-
-    @classmethod
-    def get_cache_key(cls, project_id, _key_id, value):
-        return "tagvalue:1:%s:%s:%s" % (project_id, _key_id, md5_text(value).hexdigest())
-
-    @classmethod
-    def get_or_create(cls, project_id, _key_id, value, **kwargs):
-        cache_key = cls.get_cache_key(project_id, _key_id, value)
-
-        rv = cache.get(cache_key)
-        created = False
-        if rv is None:
-            rv, created = cls.objects.get_or_create(
-                project_id=project_id, _key_id=_key_id, value=value, **kwargs
-            )
-            cache.set(cache_key, rv, 3600)
-
-        return rv, created
-
-    @classmethod
-    def get_or_create_bulk(cls, project_id, tags):
-        # Attempt to create a bunch of models in one big batch with as few
-        # queries and cache calls as possible.
-        # In best case, this is all done in 1 cache get.
-        # If we miss cache hit here, we have to fall back to old behavior.
-        key_to_model = {tag: None for tag in tags}
-        tags_by_key_id = {tag[0].id: tag for tag in tags}
-        remaining_keys = set(tags)
-
-        # First attempt to hit from cache, which in theory is the hot case
-        cache_key_to_key = {cls.get_cache_key(project_id, tk.id, v): (tk, v) for tk, v in tags}
-        cache_key_to_models = cache.get_many(cache_key_to_key.keys())
-        for model in cache_key_to_models.values():
-            key_to_model[tags_by_key_id[model._key_id]] = model
-            remaining_keys.remove(tags_by_key_id[model._key_id])
-
-        if not remaining_keys:
-            # 100% cache hit on all items, good work team
-            return key_to_model
-
-        # Fall back to just doing it manually
-        # Further optimizations start to become not so great.
-        # For some reason, when trying to do a bulk SELECT with all of the
-        # key value pairs in big OR ends up using the wrong index and ultimating
-        # generating a significantly less efficient query. The only alternative is to
-        # splice this up a bit and do all of the SELECTs, then do a bulk INSERT for remaining
-        for key in remaining_keys:
-            key_to_model[key] = cls.get_or_create(project_id, key[0].id, key[1])[0]
-
-        return key_to_model
-
-
-@register(TagValue)
-class TagValueSerializer(Serializer):
-    def get_attrs(self, item_list, user):
-        from sentry import tagstore
-
-        result = {}
-        for item in item_list:
-            result[item] = {"name": tagstore.get_tag_value_label(item.key, item.value)}
-        return result
-
-    def serialize(self, obj, attrs, user):
-        from sentry import tagstore
-
-        key = tagstore.get_standardized_key(obj.key)
-        serialized = {
-            "id": six.text_type(obj.id),
-            "key": key,
-            "name": attrs["name"],
-            "value": obj.value,
-            "count": obj.times_seen,
-            "lastSeen": obj.last_seen,
-            "firstSeen": obj.first_seen,
-        }
-
-        query = convert_user_tag_to_query(key, obj.value)
-        if query:
-            serialized["query"] = query
-        return serialized
diff --git a/tests/sentry/lang/java/test_plugin.py b/tests/sentry/lang/java/test_plugin.py
index a0da74f8ba..fd9d81beee 100644
--- a/tests/sentry/lang/java/test_plugin.py
+++ b/tests/sentry/lang/java/test_plugin.py
@@ -1,10 +1,8 @@
 from __future__ import absolute_import
 
 import zipfile
-import pytest
 from six import BytesIO
 
-from django.conf import settings
 from django.core.urlresolvers import reverse
 from django.core.files.uploadedfile import SimpleUploadedFile
 
@@ -25,10 +23,6 @@ PROGUARD_BUG_SOURCE = b"x"
 
 
 class BasicResolvingIntegrationTest(TestCase):
-    @pytest.mark.skipif(
-        settings.SENTRY_TAGSTORE == "sentry.tagstore.v2.V2TagStorage",
-        reason="Queries are completly different when using tagstore",
-    )
     def test_basic_resolving(self):
         url = reverse(
             "sentry-api-0-dsym-files",
diff --git a/tests/sentry/lang/javascript/test_plugin.py b/tests/sentry/lang/javascript/test_plugin.py
index 27a0f3ee07..d8d3a12db1 100644
--- a/tests/sentry/lang/javascript/test_plugin.py
+++ b/tests/sentry/lang/javascript/test_plugin.py
@@ -2,13 +2,10 @@
 
 from __future__ import absolute_import
 
-import pytest
 import os.path
 import responses
 from mock import patch
 
-from django.conf import settings
-
 from sentry import eventstore
 from sentry.models import File, Release, ReleaseFile
 from sentry.testutils import TestCase, SnubaTestCase
@@ -41,10 +38,6 @@ class JavascriptIntegrationTest(TestCase, SnubaTestCase):
     def get_event(self):
         return eventstore.get_events(filter_keys={"project_id": [self.project.id]})[0]
 
-    @pytest.mark.skipif(
-        settings.SENTRY_TAGSTORE == "sentry.tagstore.v2.V2TagStorage",
-        reason="Queries are completly different when using tagstore",
-    )
     def test_adds_contexts_without_device(self):
         data = {
             "timestamp": self.min_ago,
diff --git a/tests/sentry/tagstore/v2/__init__.py b/tests/sentry/tagstore/v2/__init__.py
deleted file mode 100644
index c3961685ab..0000000000
--- a/tests/sentry/tagstore/v2/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from __future__ import absolute_import
diff --git a/tests/sentry/tagstore/v2/test_backend.py b/tests/sentry/tagstore/v2/test_backend.py
deleted file mode 100644
index 785cf844dc..0000000000
--- a/tests/sentry/tagstore/v2/test_backend.py
+++ /dev/null
@@ -1,629 +0,0 @@
-from __future__ import absolute_import
-
-import pytest
-
-from datetime import datetime, timedelta
-from django.utils import timezone
-
-from sentry.testutils import TestCase
-from sentry.tagstore import TagKeyStatus
-from sentry.tagstore.v2 import models
-from sentry.tagstore.v2.backend import V2TagStorage, transformers
-from sentry.tagstore.exceptions import (
-    TagKeyNotFound,
-    TagValueNotFound,
-    GroupTagKeyNotFound,
-    GroupTagValueNotFound,
-)
-
-
-class TagStorage(TestCase):
-    def setUp(self):
-        self.ts = V2TagStorage()
-
-        self.proj1 = self.create_project()
-        self.proj1group1 = self.create_group(self.proj1)
-        self.proj1group2 = self.create_group(self.proj1)
-        self.proj1env1 = self.create_environment(project=self.proj1)
-        self.proj1env2 = self.create_environment(project=self.proj1)
-        self.proj1group1event1 = self.create_event(project=self.proj1, group=self.proj1group1)
-        self.proj1group1event2 = self.create_event(project=self.proj1, group=self.proj1group1)
-        self.proj1group1event3 = self.create_event(project=self.proj1, group=self.proj1group1)
-
-        self.proj2 = self.create_project()
-        self.proj2group1 = self.create_group(self.proj2)
-        self.proj2env1 = self.create_environment(project=self.proj2)
-
-        self.key1 = "key1"
-        self.value1 = "value1"
-
-    def test_create_tag_key(self):
-        with pytest.raises(TagKeyNotFound):
-            self.ts.get_tag_key(
-                project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-            )
-
-        assert (
-            self.ts.get_tag_keys(project_id=self.proj1.id, environment_id=self.proj1env1.id)
-            == set()
-        )
-
-        tk = self.ts.create_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-
-        assert self.ts.get_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        ) == transformers[models.TagKey](tk)
-
-        assert self.ts.get_tag_keys(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id
-        ) == set([transformers[models.TagKey](tk)])
-
-        assert models.TagKey.objects.all().count() == 1
-
-    def test_get_or_create_tag_key(self):
-        tk1, _ = self.ts.get_or_create_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-
-        tk2, _ = self.ts.get_or_create_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-
-        assert tk1.id == tk2.id
-        assert (
-            models.TagKey.objects.filter(
-                project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-            ).count()
-            == 1
-        )
-        assert models.TagKey.objects.all().count() == 1
-
-    def test_create_tag_value(self):
-        with pytest.raises(TagValueNotFound):
-            self.ts.get_tag_value(
-                project_id=self.proj1.id,
-                environment_id=self.proj1env1.id,
-                key=self.key1,
-                value=self.value1,
-            )
-
-        assert (
-            self.ts.get_tag_values(
-                project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-            )
-            == set()
-        )
-
-        tv = self.ts.create_tag_value(
-            project_id=self.proj1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        assert self.ts.get_tag_value(
-            project_id=self.proj1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        ) == transformers[models.TagValue](tv)
-
-        assert self.ts.get_tag_values(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        ) == set([transformers[models.TagValue](tv)])
-
-        assert models.TagKey.objects.all().count() == 1
-        assert models.TagValue.objects.all().count() == 1
-
-    def test_get_or_create_tag_value(self):
-        tv1, _ = self.ts.get_or_create_tag_value(
-            project_id=self.proj1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        tv2, _ = self.ts.get_or_create_tag_value(
-            project_id=self.proj1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        assert tv1.id == tv2.id
-
-        tk = models.TagKey.objects.get(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-
-        assert models.TagKey.objects.all().count() == 1
-
-        assert (
-            models.TagValue.objects.filter(
-                project_id=self.proj1.id,
-                _key__environment_id=self.proj1env1.id,
-                _key_id=tk.id,
-                value=self.value1,
-            ).count()
-            == 1
-        )
-        assert models.TagValue.objects.all().count() == 1
-
-    def test_create_group_tag_key(self):
-        with pytest.raises(GroupTagKeyNotFound):
-            self.ts.get_group_tag_key(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                environment_id=self.proj1env1.id,
-                key=self.key1,
-            )
-
-        assert (
-            self.ts.get_group_tag_keys(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                environment_ids=[self.proj1env1.id],
-            )
-            == set()
-        )
-
-        gtk = self.ts.create_group_tag_key(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        )
-
-        self.ts.get_group_tag_keys(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_ids=[self.proj1env1.id],
-        ) == [transformers[models.GroupTagKey](gtk)]
-
-        models.TagKey.objects.get(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-        assert models.TagKey.objects.all().count() == 1
-
-        assert self.ts.get_group_tag_key(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        ) == transformers[models.GroupTagKey](gtk)
-
-        assert models.GroupTagKey.objects.all().count() == 1
-
-    def test_get_or_create_group_tag_key(self):
-        gtk1, _ = self.ts.get_or_create_group_tag_key(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        )
-
-        gtk2, _ = self.ts.get_or_create_group_tag_key(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        )
-
-        assert gtk1.id == gtk2.id
-
-        tk = models.TagKey.objects.get(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-        assert models.TagKey.objects.all().count() == 1
-
-        assert (
-            models.GroupTagKey.objects.filter(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                _key__environment_id=self.proj1env1.id,
-                _key_id=tk.id,
-            ).count()
-            == 1
-        )
-        assert models.GroupTagKey.objects.all().count() == 1
-
-    def test_create_group_tag_value(self):
-        with pytest.raises(GroupTagValueNotFound):
-            self.ts.get_group_tag_value(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                environment_id=self.proj1env1.id,
-                key=self.key1,
-                value=self.value1,
-            )
-
-        assert (
-            self.ts.get_group_tag_values(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                environment_id=self.proj1env1.id,
-                key=self.key1,
-            )
-            == []
-        )
-
-        gtv = self.ts.create_group_tag_value(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        assert self.ts.get_group_tag_value(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        ) == transformers[models.GroupTagValue](gtv)
-
-        assert self.ts.get_group_tag_values(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        ) == [transformers[models.GroupTagValue](gtv)]
-
-        assert models.TagKey.objects.all().count() == 1
-        assert models.TagValue.objects.all().count() == 1
-        assert models.GroupTagValue.objects.all().count() == 1
-
-    def test_get_or_create_group_tag_value(self):
-        gtv1, _ = self.ts.get_or_create_group_tag_value(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        gtv2, _ = self.ts.get_or_create_group_tag_value(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        assert gtv1.id == gtv2.id
-
-        tk = models.TagKey.objects.get(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-        assert models.TagKey.objects.all().count() == 1
-
-        tv = models.TagValue.objects.get(
-            project_id=self.proj1.id,
-            _key__environment_id=self.proj1env1.id,
-            _key_id=tk.id,
-            value=self.value1,
-        )
-        assert models.TagValue.objects.all().count() == 1
-
-        assert (
-            models.GroupTagValue.objects.filter(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                _key__environment_id=self.proj1env1.id,
-                _key_id=tk.id,
-                _value_id=tv.id,
-            ).count()
-            == 1
-        )
-        assert models.GroupTagValue.objects.all().count() == 1
-
-    def test_create_event_tags(self):
-        v1, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k1", "v1")
-        v2, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k2", "v2")
-        v3, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k3", "v3")
-
-        tags = [(v1._key, v1), (v2._key, v2), (v3._key, v3)]
-        self.ts.create_event_tags(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            event_id=self.proj1group1event1.id,
-            tags=[(k.key, v.value) for k, v in tags],
-        )
-
-        assert models.EventTag.objects.count() == 3
-        for (k, v) in tags:
-            assert (
-                models.EventTag.objects.get(
-                    project_id=self.proj1.id,
-                    group_id=self.proj1group1.id,
-                    key__environment_id=self.proj1env1.id,
-                    event_id=self.proj1group1event1.id,
-                    key_id=k.id,
-                    value_id=v.id,
-                )
-                is not None
-            )
-            expected_qs = models.EventTag.objects.filter(
-                project_id=self.proj1.id,
-                key__project_id=self.proj1.id,
-                key__key=k.key,
-                value__project_id=self.proj1.id,
-                value__value=v.value,
-            )
-            expected_qs = self.ts._add_environment_filter(
-                expected_qs, self.proj1env1.id
-            ).values_list("group_id", flat=True)
-            assert set(expected_qs) == set([self.proj1group1.id])
-
-    def test_delete_tag_key(self):
-        tk1 = self.ts.create_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env1.id, key=self.key1
-        )
-
-        tk2 = self.ts.create_tag_key(
-            project_id=self.proj1.id, environment_id=self.proj1env2.id, key=self.key1
-        )
-
-        assert (
-            models.TagKey.objects.filter(
-                project_id=self.proj1.id, status=TagKeyStatus.VISIBLE
-            ).count()
-            == 2
-        )
-
-        assert tk1.status == TagKeyStatus.VISIBLE
-        assert tk2.status == TagKeyStatus.VISIBLE
-
-        deleted = self.ts.delete_tag_key(self.proj1.id, self.key1)
-        assert tk1 in deleted
-        assert tk2 in deleted
-
-        assert (
-            models.TagKey.objects.filter(
-                project_id=self.proj1.id, status=TagKeyStatus.VISIBLE
-            ).count()
-            == 0
-        )
-
-    def test_delete_all_group_tag_keys(self):
-        assert models.GroupTagKey.objects.count() == 0
-
-        self.ts.create_group_tag_key(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-        )
-
-        assert models.GroupTagKey.objects.count() == 1
-
-        self.ts.delete_all_group_tag_keys(self.proj1.id, self.proj1group1.id)
-
-        assert models.GroupTagKey.objects.count() == 0
-
-    def test_delete_all_group_tag_values(self):
-        assert models.GroupTagValue.objects.count() == 0
-
-        self.ts.create_group_tag_value(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            key=self.key1,
-            value=self.value1,
-        )
-
-        assert models.GroupTagValue.objects.count() == 1
-
-        self.ts.delete_all_group_tag_values(self.proj1.id, self.proj1group1.id)
-
-        assert models.GroupTagValue.objects.count() == 0
-
-    def test_get_group_event_filter(self):
-        tags = {"abc": "xyz", "foo": "bar", "baz": "quux"}
-
-        # 2 events with the same tags
-        for i, event in enumerate((self.proj1group1event1, self.proj1group1event2)):
-            self.ts.create_event_tags(
-                project_id=self.proj1.id,
-                group_id=self.proj1group1.id,
-                environment_id=self.proj1env1.id,
-                event_id=event.id,
-                tags=tags.items(),
-                date_added=timezone.now() - timedelta(hours=i),
-            )
-
-        different_tags = {"abc": "DIFFERENT", "foo": "bar", "baz": "quux"}
-
-        # 1 event with different tags
-        self.ts.create_event_tags(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            event_id=self.proj1group1event3.id,
-            tags=different_tags.items(),
-        )
-
-        assert self.ts.get_group_event_filter(
-            self.proj1.id, self.proj1group1.id, [self.proj1env1.id], tags, None, None
-        ) == {"id__in": set([self.proj1group1event1.id, self.proj1group1event2.id])}
-
-        assert self.ts.get_group_event_filter(
-            self.proj1.id,
-            self.proj1group1.id,
-            [self.proj1env1.id],
-            tags,
-            timezone.now() - timedelta(minutes=30),
-            None,
-        ) == {"id__in": set([self.proj1group1event1.id])}
-
-        assert self.ts.get_group_event_filter(
-            self.proj1.id,
-            self.proj1group1.id,
-            [self.proj1env1.id],
-            tags,
-            None,
-            timezone.now() - timedelta(minutes=30),
-        ) == {"id__in": set([self.proj1group1event2.id])}
-
-        with pytest.raises(NotImplementedError):
-            self.ts.get_group_event_filter(
-                self.proj1.id,
-                self.proj1group1.id,
-                [self.proj1env1.id, self.proj1env2.id],
-                tags,
-                None,
-                None,
-            )
-
-    def test_get_groups_user_counts(self):
-        k1, _ = self.ts.get_or_create_group_tag_key(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, "sentry:user"
-        )
-        k1.values_seen = 7
-        k1.save()
-
-        k2, _ = self.ts.get_or_create_group_tag_key(
-            self.proj1.id, self.proj1group2.id, self.proj1env1.id, "sentry:user"
-        )
-        k2.values_seen = 11
-        k2.save()
-
-        assert dict(
-            self.ts.get_groups_user_counts(
-                [self.proj1.id], [self.proj1group1.id, self.proj1group2.id], [self.proj1env1.id]
-            ).items()
-        ) == {self.proj1group1.id: 7, self.proj1group2.id: 11}
-
-    def test_get_group_tag_value_count(self):
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1, "value1"
-        )
-        v1.times_seen = 7
-        v1.save()
-
-        v2, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1, "value2"
-        )
-        v2.times_seen = 11
-        v2.save()
-
-        assert (
-            self.ts.get_group_tag_value_count(
-                self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1
-            )
-            == 18
-        )
-
-    def test_get_top_group_tag_values(self):
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1, "value1"
-        )
-        v1.times_seen = 7
-        v1.save()
-
-        v2, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1, "value2"
-        )
-        v2.times_seen = 11
-        v2.save()
-
-        resp = self.ts.get_top_group_tag_values(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, self.key1
-        )
-
-        assert resp[0].times_seen == 11
-        assert resp[0].key == self.key1
-        assert resp[0].group_id == self.proj1group1.id
-
-        assert resp[1].times_seen == 7
-        assert resp[1].key == self.key1
-        assert resp[1].group_id == self.proj1group1.id
-
-    def test_get_first_release(self):
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, "sentry:release", "1.0"
-        )
-        v1.first_seen = datetime(2000, 1, 1)
-        v1.save()
-
-        v2, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, "sentry:release", "2.0"
-        )
-        v2.first_seen = datetime(2000, 1, 2)
-        v2.save()
-
-        assert self.ts.get_first_release(self.proj1.id, self.proj1group1.id) == "1.0"
-
-    def test_get_last_release(self):
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, "sentry:release", "1.0"
-        )
-        v1.last_seen = datetime(2000, 1, 1)
-        v1.save()
-
-        v2, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, self.proj1env1.id, "sentry:release", "2.0"
-        )
-        v2.last_seen = datetime(2000, 1, 2)
-        v2.save()
-
-        assert self.ts.get_last_release(self.proj1.id, self.proj1group1.id) == "2.0"
-
-    def test_get_release_tags(self):
-        tv, _ = self.ts.get_or_create_tag_value(
-            self.proj1.id, self.proj1env1.id, "sentry:release", "1.0"
-        )
-
-        assert self.ts.get_release_tags([self.proj1.id], self.proj1env1.id, ["1.0"]) == set(
-            [transformers[models.TagValue](tv)]
-        )
-
-    def test_get_group_ids_for_users(self):
-        from sentry.models import EventUser
-
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, 0, "sentry:user", "email:user@sentry.io"
-        )
-
-        eu = EventUser(project_id=self.proj1.id, email="user@sentry.io")
-
-        assert self.ts.get_group_ids_for_users([self.proj1.id], [eu]) == set([self.proj1group1.id])
-
-    def test_get_group_tag_values_for_users(self):
-        from sentry.models import EventUser
-
-        v1, _ = self.ts.get_or_create_group_tag_value(
-            self.proj1.id, self.proj1group1.id, 0, "sentry:user", "email:user@sentry.io"
-        )
-
-        eu = EventUser(project_id=self.proj1.id, email="user@sentry.io")
-
-        assert self.ts.get_group_tag_values_for_users([eu]) == [
-            transformers[models.GroupTagValue](v1)
-        ]
-
-    def test_update_group_for_events(self):
-        v1, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k1", "v1")
-        v2, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k2", "v2")
-        v3, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, "k3", "v3")
-
-        tags = [(v1.key, v1.value), (v2.key, v2.value), (v3.key, v3.value)]
-        self.ts.create_event_tags(
-            project_id=self.proj1.id,
-            group_id=self.proj1group1.id,
-            environment_id=self.proj1env1.id,
-            event_id=self.proj1group1event1.id,
-            tags=tags,
-        )
-
-        assert models.EventTag.objects.filter(group_id=self.proj1group2.id).count() == 0
-
-        self.ts.update_group_for_events(
-            self.proj1.id, [self.proj1group1event1.id], self.proj1group2.id
-        )
-
-        assert models.EventTag.objects.filter(group_id=self.proj1group2.id).count() == 3
diff --git a/tests/sentry/tasks/test_unmerge.py b/tests/sentry/tasks/test_unmerge.py
index 472f2e6f2a..5a4f3941be 100644
--- a/tests/sentry/tasks/test_unmerge.py
+++ b/tests/sentry/tasks/test_unmerge.py
@@ -9,7 +9,6 @@ from collections import OrderedDict
 from datetime import datetime, timedelta
 
 import pytz
-from django.conf import settings
 from django.utils import timezone
 from mock import patch, Mock
 
@@ -291,46 +290,22 @@ class UnmergeTestCase(TestCase):
             ]
         ) == set([(u"color", 3), (u"environment", 1), (u"sentry:release", 1)])
 
-        if settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.v2"):
-            assert set(
-                [
-                    (
-                        gtv.key,
-                        gtv.value,
-                        gtv.times_seen,
-                        Environment.objects.get(pk=gtv._key.environment_id).name,
-                    )
-                    for gtv in GroupTagValue.objects.filter(
-                        project_id=source.project_id, group_id=source.id
-                    ).exclude(_key__environment_id=0)
-                ]
-            ) == set(
-                [
-                    ("color", "red", 6, "production"),
-                    ("sentry:release", "version", 16, "production"),
-                    ("color", "blue", 5, "production"),
-                    ("color", "green", 5, "production"),
-                    ("environment", "production", 16, "production"),
-                    ("color", "green", 1, ""),
-                ]
-            )
-        else:
-            assert set(
-                [
-                    (gtv.key, gtv.value, gtv.times_seen)
-                    for gtv in GroupTagValue.objects.filter(
-                        project_id=source.project_id, group_id=source.id
-                    )
-                ]
-            ) == set(
-                [
-                    (u"color", u"red", 6),
-                    (u"color", u"green", 6),
-                    (u"color", u"blue", 5),
-                    (u"environment", u"production", 16),
-                    (u"sentry:release", u"version", 16),
-                ]
-            )
+        assert set(
+            [
+                (gtv.key, gtv.value, gtv.times_seen)
+                for gtv in GroupTagValue.objects.filter(
+                    project_id=source.project_id, group_id=source.id
+                )
+            ]
+        ) == set(
+            [
+                (u"color", u"red", 6),
+                (u"color", u"green", 6),
+                (u"color", u"blue", 5),
+                (u"environment", u"production", 16),
+                (u"sentry:release", u"version", 16),
+            ]
+        )
 
         assert features.compare(source) == [
             (
@@ -406,16 +381,11 @@ class UnmergeTestCase(TestCase):
             ]
         ) == set([(u"color", 3), (u"environment", 1), (u"sentry:release", 1)])
 
-        if settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.v2"):
-            env_filter = {"_key__environment_id": production_environment.id}
-        else:
-            env_filter = {}
-
         assert set(
             [
                 (gtv.key, gtv.value, gtv.times_seen, gtv.first_seen, gtv.last_seen)
                 for gtv in GroupTagValue.objects.filter(
-                    project_id=source.project_id, group_id=source.id, **env_filter
+                    project_id=source.project_id, group_id=source.id
                 )
             ]
         ) == set(
@@ -453,40 +423,22 @@ class UnmergeTestCase(TestCase):
             ]
         ) == set([(u"color", 3), (u"environment", 1), (u"sentry:release", 1)])
 
-        if settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.v2"):
-            assert set(
-                [
-                    (gtv.key, gtv.value, gtv.times_seen, gtv.first_seen, gtv.last_seen)
-                    for gtv in GroupTagValue.objects.filter(
-                        project_id=destination.project_id, group_id=destination.id, **env_filter
-                    )
-                ]
-            ) == set(
-                [
-                    (u"color", u"red", 2, now + shift(12), now + shift(15)),
-                    (u"color", u"green", 2, now + shift(10), now + shift(13)),
-                    (u"color", u"blue", 2, now + shift(11), now + shift(14)),
-                    (u"environment", u"production", 6, now + shift(10), now + shift(15)),
-                    (u"sentry:release", u"version", 6, now + shift(10), now + shift(15)),
-                ]
-            )
-        else:
-            assert set(
-                [
-                    (gtv.key, gtv.value, gtv.times_seen, gtv.first_seen, gtv.last_seen)
-                    for gtv in GroupTagValue.objects.filter(
-                        project_id=destination.project_id, group_id=destination.id, **env_filter
-                    )
-                ]
-            ) == set(
-                [
-                    (u"color", u"red", 2, now + shift(12), now + shift(15)),
-                    (u"color", u"green", 3, now + shift(10), now + shift(16)),
-                    (u"color", u"blue", 2, now + shift(11), now + shift(14)),
-                    (u"environment", u"production", 6, now + shift(10), now + shift(15)),
-                    (u"sentry:release", u"version", 6, now + shift(10), now + shift(15)),
-                ]
-            )
+        assert set(
+            [
+                (gtv.key, gtv.value, gtv.times_seen, gtv.first_seen, gtv.last_seen)
+                for gtv in GroupTagValue.objects.filter(
+                    project_id=destination.project_id, group_id=destination.id
+                )
+            ]
+        ) == set(
+            [
+                (u"color", u"red", 2, now + shift(12), now + shift(15)),
+                (u"color", u"green", 3, now + shift(10), now + shift(16)),
+                (u"color", u"blue", 2, now + shift(11), now + shift(14)),
+                (u"environment", u"production", 6, now + shift(10), now + shift(15)),
+                (u"sentry:release", u"version", 6, now + shift(10), now + shift(15)),
+            ]
+        )
 
         rollup_duration = 3600
 
diff --git a/tests/snuba/search/test_backend.py b/tests/snuba/search/test_backend.py
index bb14d5fd97..75060bb7ee 100644
--- a/tests/snuba/search/test_backend.py
+++ b/tests/snuba/search/test_backend.py
@@ -745,7 +745,7 @@ class SnubaSearchTest(TestCase, SnubaTestCase):
         assert set(results) == set([self.group1, self.group2])
 
     @pytest.mark.xfail(
-        not settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.v2"),
+        settings.SENTRY_TAGSTORE.startswith("sentry.tagstore.legacy.LegacyTagStorage"),
         reason="unsupported on legacy backend due to insufficient index",
     )
     def test_date_filter_with_environment(self):
