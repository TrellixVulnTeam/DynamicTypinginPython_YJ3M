commit 1190e1a05b6d234dc124d7f5748ada7d7ae8a953
Author: Alex Hofsteede <alex@hofsteede.com>
Date:   Tue Jan 29 10:20:03 2019 -0800

    Provide values (or estimates) for X-hits (#11493)
    
    Provide a useful value for X-Hits when using snuba search.
    
    In the case where there are a low enough number of matches on either side of the django<>snuba join, we can usually do the complete join and get the exact total count for the search query. In cases where there are a ton of issues, we grab a small (200) random sample of the matching ids on the snuba side, and check the percentage of those that match on the snuba side. This gives us an estimate of the overall intersection size of the two sets, which we return as X-Hits.

diff --git a/src/sentry/api/paginator.py b/src/sentry/api/paginator.py
index 8d811c12ec..deb3770888 100644
--- a/src/sentry/api/paginator.py
+++ b/src/sentry/api/paginator.py
@@ -102,7 +102,7 @@ class BasePaginator(object):
     def value_from_cursor(self, cursor):
         raise NotImplementedError
 
-    def get_result(self, limit=100, cursor=None, count_hits=False):
+    def get_result(self, limit=100, cursor=None, count_hits=False, known_hits=None):
         # cursors are:
         #   (identifier(integer), row offset, is_prev)
         if cursor is None:
@@ -121,6 +121,8 @@ class BasePaginator(object):
         # the key is not unique
         if count_hits:
             hits = self.count_hits(MAX_HITS_LIMIT)
+        elif known_hits is not None:
+            hits = known_hits
         else:
             hits = None
 
@@ -293,7 +295,7 @@ class SequencePaginator(object):
         self.max_limit = max_limit
         self.on_results = on_results
 
-    def get_result(self, limit, cursor=None, count_hits=False):
+    def get_result(self, limit, cursor=None, count_hits=False, known_hits=None):
         limit = min(limit, self.max_limit)
 
         if cursor is None:
@@ -343,12 +345,19 @@ class SequencePaginator(object):
         if self.on_results:
             results = self.on_results(results)
 
+        if known_hits is not None:
+            hits = min(known_hits, MAX_HITS_LIMIT)
+        elif count_hits:
+            hits = min(len(self.scores), MAX_HITS_LIMIT)
+        else:
+            hits = None
+
         return CursorResult(
             results,
             prev=prev_cursor,
             next=next_cursor,
-            hits=min(len(self.scores), MAX_HITS_LIMIT) if count_hits else None,
-            max_hits=MAX_HITS_LIMIT if count_hits else None,
+            hits=hits,
+            max_hits=MAX_HITS_LIMIT if hits is not None else None,
         )
 
 
diff --git a/src/sentry/options/defaults.py b/src/sentry/options/defaults.py
index c6aa3b6593..8b44ec2281 100644
--- a/src/sentry/options/defaults.py
+++ b/src/sentry/options/defaults.py
@@ -145,6 +145,7 @@ register('snuba.search.max-pre-snuba-candidates', default=5000)
 register('snuba.search.chunk-growth-rate', default=1.5)
 register('snuba.search.max-chunk-size', default=2000)
 register('snuba.search.max-total-chunk-time-seconds', default=30.0)
+register('snuba.search.hits-sample-size', default=100)
 register('snuba.events-queries.enabled', type=Bool, default=False)
 
 # Kafka Publisher
diff --git a/src/sentry/search/snuba/backend.py b/src/sentry/search/snuba/backend.py
index 63e4f4da43..8a5ab0edbf 100644
--- a/src/sentry/search/snuba/backend.py
+++ b/src/sentry/search/snuba/backend.py
@@ -1,7 +1,6 @@
 from __future__ import absolute_import
 
-import six
-
+from hashlib import md5
 import logging
 import pytz
 import time
@@ -15,7 +14,6 @@ from sentry.event_manager import ALLOWED_FUTURE_DELTA
 from sentry.models import Release, Group, GroupEnvironment
 from sentry.search.django import backend as ds
 from sentry.utils import snuba, metrics
-from sentry.utils.cache import cache
 from sentry.utils.dates import to_timestamp
 
 
@@ -55,6 +53,8 @@ aggregation_defs = {
     'last_seen': ['toUInt64(max(timestamp)) * 1000', ''],
     # https://github.com/getsentry/sentry/blob/804c85100d0003cfdda91701911f21ed5f66f67c/src/sentry/event_manager.py#L241-L271
     'priority': ['(toUInt64(log(times_seen) * 600)) + last_seen', ''],
+    # Only makes sense with WITH TOTALS, returns 1 for an individual group.
+    'total': ['uniq', 'issue'],
 }
 
 
@@ -127,12 +127,6 @@ class ScalarCondition(Condition):
 
 
 class SnubaSearchBackend(ds.DjangoSearchBackend):
-    def _get_project_count_cache_key(self, project_id):
-        return 'snuba.search:project.group.count:%s' % project_id
-
-    def _get_project_id_from_key(self, key):
-        return int(key.split(':')[2])
-
     def _query(self, projects, retention_window_start, group_queryset, tags, environments,
                sort_by, limit, cursor, count_hits, paginator_options, **parameters):
 
@@ -212,7 +206,8 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                     ]):
                 group_queryset = group_queryset.order_by('-last_seen')
                 paginator = DateTimePaginator(group_queryset, '-last_seen', **paginator_options)
-                return paginator.get_result(limit, cursor, count_hits=False)
+                # When its a simple django-only search, we count_hits like normal
+                return paginator.get_result(limit, cursor, count_hits=count_hits)
 
         # TODO: Presumably we only want to search back to the project's max
         # retention date, which may be closer than 90 days in the past, but
@@ -250,82 +245,30 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
             # is invalid.
             return EMPTY_RESULT
 
-        # num_candidates is the number of Group IDs to send down to Snuba, if
-        # more Group ID candidates are found, a "bare" Snuba search is performed
-        # and the result groups are then post-filtered via queries to the Sentry DB
-        optimizer_enabled = options.get('snuba.search.pre-snuba-candidates-optimizer')
-        if optimizer_enabled:
-            missed_projects = []
-            keys = [self._get_project_count_cache_key(p.id) for p in projects]
-
-            counts_by_projects = {
-                self._get_project_id_from_key(key): count for key, count in cache.get_many(keys).items()
-            }
-
-            missed_projects = {p.id for p in projects} - set(counts_by_projects.keys())
-
-            if missed_projects:
-                missing_counts = snuba.query(
-                    start=max(
-                        filter(None, [
-                            retention_window_start,
-                            now - timedelta(days=90)
-                        ])
-                    ),
-                    end=now,
-                    groupby=['project_id'],
-                    filter_keys={
-                        'project_id': list(missed_projects),
-                    },
-                    aggregations=[['uniq', 'group_id', 'group_count']],
-                    referrer='search',
-                )
-
-                cache.set_many({
-                    self._get_project_count_cache_key(project_id): count
-                    for project_id, count in missing_counts.items()
-                }, options.get('snuba.search.project-group-count-cache-time'))
-
-                counts_by_projects.update(missing_counts)
-
-            min_candidates = options.get('snuba.search.min-pre-snuba-candidates')
-            max_candidates = options.get('snuba.search.max-pre-snuba-candidates')
-            candidates_percentage = options.get('snuba.search.pre-snuba-candidates-percentage')
-
-            num_candidates = max(
-                min_candidates,
-                min(
-                    max_candidates,
-                    sum(counts_by_projects.values()) * candidates_percentage
-                )
-            )
-        else:
-            num_candidates = options.get('snuba.search.min-pre-snuba-candidates')
-
-        # pre-filter query
-        candidate_ids = None
-        if num_candidates and limit <= num_candidates:
-            candidate_ids = list(
-                group_queryset.values_list('id', flat=True)[:num_candidates + 1]
-            )
-            metrics.timing('snuba.search.num_candidates', len(candidate_ids))
-
-            if not candidate_ids:
-                # no matches could possibly be found from this point on
-                metrics.incr('snuba.search.no_candidates', skip_internal=False)
-                return EMPTY_RESULT
-            elif len(candidate_ids) > num_candidates:
-                # If the pre-filter query didn't include anything to significantly
-                # filter down the number of results (from 'first_release', 'query',
-                # 'status', 'bookmarked_by', 'assigned_to', 'unassigned',
-                # 'subscribed_by', 'active_at_from', or 'active_at_to') then it
-                # might have surpassed the `num_candidates`. In this case,
-                # we *don't* want to pass candidates down to Snuba, and instead we
-                # want Snuba to do all the filtering/sorting it can and *then* apply
-                # this queryset to the results from Snuba, which we call
-                # post-filtering.
-                metrics.incr('snuba.search.too_many_candidates', skip_internal=False)
-                candidate_ids = None
+        # Here we check if all the django filters reduce the set of groups down
+        # to something that we can send down to Snuba in a `group_id IN (...)`
+        # clause.
+        max_candidates = options.get('snuba.search.max-pre-snuba-candidates')
+        candidate_ids = list(
+            group_queryset.values_list('id', flat=True)[:max_candidates + 1]
+        )
+        metrics.timing('snuba.search.num_candidates', len(candidate_ids))
+        if not candidate_ids:
+            # no matches could possibly be found from this point on
+            metrics.incr('snuba.search.no_candidates', skip_internal=False)
+            return EMPTY_RESULT
+        elif len(candidate_ids) > max_candidates:
+            # If the pre-filter query didn't include anything to significantly
+            # filter down the number of results (from 'first_release', 'query',
+            # 'status', 'bookmarked_by', 'assigned_to', 'unassigned',
+            # 'subscribed_by', 'active_at_from', or 'active_at_to') then it
+            # might have surpassed the `max_candidates`. In this case,
+            # we *don't* want to pass candidates down to Snuba, and instead we
+            # want Snuba to do all the filtering/sorting it can and *then* apply
+            # this queryset to the results from Snuba, which we call
+            # post-filtering.
+            metrics.incr('snuba.search.too_many_candidates', skip_internal=False)
+            candidate_ids = None
 
         sort_field = sort_strategies[sort_by]
         chunk_growth = options.get('snuba.search.chunk-growth-rate')
@@ -333,6 +276,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
         chunk_limit = limit
         offset = 0
         num_chunks = 0
+        hits = None
 
         paginator_results = EMPTY_RESULT
         result_groups = []
@@ -341,6 +285,51 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
         max_time = options.get('snuba.search.max-total-chunk-time-seconds')
         time_start = time.time()
 
+        if count_hits and candidate_ids is None:
+            # If we have no candidates, get a random sample of groups matching
+            # the snuba side of the query, and see how many of those pass the
+            # post-filter in postgres. This should give us an estimate of the
+            # total number of snuba matches that will be overall matches, which
+            # we can use to get an estimate for X-Hits. Note no cursor, so we
+            # are always estimating the total hits.
+
+            # The number of samples required to achieve a certain error bound
+            # with a certain confidence interval can be calculated from a
+            # rearrangement of the normal approximation (Wald) confidence
+            # interval formula:
+            #
+            # https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval
+            #
+            # Effectively if we want the estimate to be within +/- 10% of the
+            # real value with 95% confidence, we would need (1.96^2 * p*(1-p))
+            # / 0.1^2 samples. With a starting assumption of p=0.5 (this
+            # requires the most samples) we would need 96 samples to achieve
+            # +/-10% @ 95% confidence.
+
+            sample_size = options.get('snuba.search.hits-sample-size')
+            snuba_groups, snuba_total = snuba_search(
+                start=start,
+                end=end,
+                project_ids=[p.id for p in projects],
+                environment_ids=environments and [environment.id for environment in environments],
+                tags=tags,
+                sort_field=sort_field,
+                limit=sample_size,
+                offset=0,
+                get_sample=True,
+                **parameters
+            )
+            snuba_count = len(snuba_groups)
+            if snuba_count == 0:
+                return EMPTY_RESULT
+            else:
+                filtered_count = group_queryset.filter(
+                    id__in=[gid for gid, _ in snuba_groups]
+                ).count()
+
+                hit_ratio = filtered_count / float(snuba_count)
+                hits = int(hit_ratio * snuba_total)
+
         # Do smaller searches in chunks until we have enough results
         # to answer the query (or hit the end of possible results). We do
         # this because a common case for search is to return 100 groups
@@ -357,7 +346,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
             chunk_limit = max(chunk_limit, len(candidate_ids) if candidate_ids else 0)
 
             # {group_id: group_score, ...}
-            snuba_groups, more_results = snuba_search(
+            snuba_groups, total = snuba_search(
                 start=start,
                 end=end,
                 project_ids=[p.id for p in projects],
@@ -371,16 +360,22 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                 **parameters
             )
             metrics.timing('snuba.search.num_snuba_results', len(snuba_groups))
+            count = len(snuba_groups)
+            more_results = count >= limit and (offset + limit) < total
             offset += len(snuba_groups)
 
             if not snuba_groups:
                 break
 
             if candidate_ids:
-                # pre-filtered candidates were passed down to Snuba,
-                # so we're finished with filtering and these are the
-                # only results
+                # pre-filtered candidates were passed down to Snuba, so we're
+                # finished with filtering and these are the only results. Note
+                # that because we set the chunk size to at least the size of
+                # the candidate_ids, we know we got all of them (ie there are
+                # no more chunks after the first)
                 result_groups = snuba_groups
+                if count_hits:
+                    hits = len(snuba_groups)
             else:
                 # pre-filtered candidates were *not* passed down to Snuba,
                 # so we need to do post-filtering to verify Sentry DB predicates
@@ -401,11 +396,26 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                     result_group_ids.add(group_id)
                     result_groups.append((group_id, group_score))
 
+                if count_hits:
+                    if not more_results:
+                        # We know we have got all possible groups from snuba and filtered
+                        # them all down, so we have all hits.
+                        # TODO this probably doesn't work because we could be on page N
+                        # and not be including hits from previous pages.
+                        hits = len(result_groups)
+                    else:
+                        # We also could have underestimated hits from our sample and have
+                        # already seen more hits than the estimate, so make sure hits is
+                        # at least as big as what we have seen.
+                        hits = max(hits, len(result_groups))
+
+            # TODO do we actually have to rebuild this SequencePaginator every time
+            # or can we just make it after we've broken out of the loop?
             paginator_results = SequencePaginator(
                 [(score, id) for (id, score) in result_groups],
                 reverse=True,
                 **paginator_options
-            ).get_result(limit, cursor, count_hits=False)
+            ).get_result(limit, cursor, known_hits=hits)
 
             # break the query loop for one of three reasons:
             # * we started with Postgres candidates and so only do one Snuba query max
@@ -421,6 +431,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
         # because we're 'lying' to the SequencePaginator (it thinks it has the entire
         # result set in memory when it does not). For this reason we need to make some
         # best guesses as to whether the `prev` and `next` cursors have more results.
+
         if len(paginator_results.results) == limit and more_results:
             # Because we are going back and forth between DBs there is a small
             # chance that we will hand the SequencePaginator exactly `limit`
@@ -443,7 +454,8 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
 
 
 def snuba_search(start, end, project_ids, environment_ids, tags,
-                 sort_field, cursor, candidate_ids, limit, offset, **parameters):
+                 sort_field, cursor=None, candidate_ids=None, limit=None,
+                 offset=0, get_sample=False, **parameters):
     """
     This function doesn't strictly benefit from or require being pulled out of the main
     query method above, but the query method is already large and this function at least
@@ -451,7 +463,7 @@ def snuba_search(start, end, project_ids, environment_ids, tags,
 
     Returns a tuple of:
      * a sorted list of (group_id, group_score) tuples sorted descending by score,
-     * a boolean indicating whether there are more result groups to iterate over
+     * the count of total results (rows) available for this query.
     """
 
     from sentry.search.base import ANY
@@ -479,7 +491,7 @@ def snuba_search(start, end, project_ids, environment_ids, tags,
     }).build(parameters)
 
     conditions = []
-    for tag, val in six.iteritems(tags):
+    for tag, val in sorted(tags.items()):
         col = u'tags[{}]'.format(tag)
         if val == ANY:
             conditions.append((col, '!=', ''))
@@ -487,7 +499,7 @@ def snuba_search(start, end, project_ids, environment_ids, tags,
             conditions.append((col, '=', val))
 
     extra_aggregations = dependency_aggregations.get(sort_field, [])
-    required_aggregations = set([sort_field] + extra_aggregations)
+    required_aggregations = set([sort_field, 'total'] + extra_aggregations)
     for h in having:
         alias = h[0]
         required_aggregations.add(alias)
@@ -499,49 +511,46 @@ def snuba_search(start, end, project_ids, environment_ids, tags,
     if cursor is not None:
         having.append((sort_field, '>=' if cursor.is_prev else '<=', cursor.value))
 
-    # {group_id -> {<agg_alias> -> <agg_value>,
-    #               <agg_alias> -> <agg_value>,
-    #               ...},
-    #  ...}
-    # _OR_ if there's only one <agg_alias> in use
-    # {group_id -> <agg_value>,
-    #  ...}
-    snuba_results = snuba.query(
+    selected_columns = []
+    if get_sample:
+        # Get a random sample of matching groups. Because we use any(rand()),
+        # we are testing against a single random value per group, and so the
+        # sample is independent of the number of events in a group. Since we
+        # are sampling using `ORDER by random() LIMIT x`, we will always grab
+        # the full result set if there less than x total results.
+
+        query_hash = md5(repr(conditions)).hexdigest()[:8]
+        selected_columns.append(('cityHash64', ("'{}'".format(query_hash), 'issue'), 'sample'))
+        sort_field = 'sample'
+        orderby = [sort_field]
+        referrer = 'search_sample'
+    else:
+        # Get the top matching groups by score, i.e. the actual search results
+        # in the order that we want them.
+        orderby = ['-{}'.format(sort_field), 'issue']  # ensure stable sort within the same score
+        referrer = 'search'
+
+    snuba_results = snuba.raw_query(
         start=start,
         end=end,
+        selected_columns=selected_columns,
         groupby=['issue'],
         conditions=conditions,
         having=having,
         filter_keys=filters,
         aggregations=aggregations,
-        orderby=['-' + sort_field, 'issue'],  # ensure stable sort within the same score
-        referrer='search',
-        limit=limit + 1,
+        orderby=orderby,
+        referrer=referrer,
+        limit=limit,
         offset=offset,
+        totals=True,  # Needs to have totals_mode=after_having_exclusive so we get groups matching HAVING only
+        turbo=get_sample,  # Turn off FINAL when in sampling mode
+        sample=1,  # Don't use clickhouse sampling, even when in turbo mode.
     )
-    metrics.timing('snuba.search.num_result_groups', len(snuba_results.keys()))
-    more_results = len(snuba_results) == limit + 1
-
-    # {group_id -> score,
-    #  ...}
-    group_data = {}
-    for group_id, obj in snuba_results.items():
-        # NOTE: The Snuba utility code is trying to be helpful by collapsing
-        # results with only one aggregate down to the single value. It's a
-        # bit of a hack that we then immediately undo that work here, but
-        # many other callers get value out of that functionality. If we see
-        # this pattern again we should either add an option to opt-out of
-        # the 'help' here or remove it from the Snuba code altogether.
-        if len(required_aggregations) == 1:
-            group_data[group_id] = obj
-        else:
-            group_data[group_id] = obj[sort_field]
+    rows = snuba_results['data']
+    total = snuba_results['totals']['total']
 
-    return (
-        list(
-            sorted(
-                ((gid, score) for gid, score in group_data.items()),
-                key=lambda t: t[1], reverse=True
-            )
-        )[:limit], more_results
-    )
+    if not get_sample:
+        metrics.timing('snuba.search.num_result_groups', len(rows))
+
+    return [(row['issue'], row[sort_field]) for row in rows], total
diff --git a/src/sentry/tsdb/snuba.py b/src/sentry/tsdb/snuba.py
index 48820b47d0..f973d4bf83 100644
--- a/src/sentry/tsdb/snuba.py
+++ b/src/sentry/tsdb/snuba.py
@@ -78,9 +78,16 @@ class SnubaTSDB(BaseTSDB):
         end = to_datetime(series[-1] + rollup)
 
         if keys:
-            result = snuba.query(start, end, groupby, None, keys_map,
-                                 aggregations, rollup, referrer='tsdb',
-                                 is_grouprelease=(model == TSDBModel.frequent_releases_by_group))
+            result = snuba.query(
+                start, end,
+                groupby=groupby,
+                conditions=None,
+                filter_keys=keys_map,
+                aggregations=aggregations,
+                rollup=rollup,
+                referrer='tsdb',
+                is_grouprelease=(model == TSDBModel.frequent_releases_by_group)
+            )
         else:
             result = {}
 
diff --git a/src/sentry/utils/snuba.py b/src/sentry/utils/snuba.py
index 50b805c855..2cd447eef5 100644
--- a/src/sentry/utils/snuba.py
+++ b/src/sentry/utils/snuba.py
@@ -355,12 +355,15 @@ def transform_aliases_and_query(**kwargs):
 
 
 def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
-              aggregations=None, rollup=None, arrayjoin=None, limit=None, offset=None,
-              orderby=None, having=None, referrer=None, is_grouprelease=False,
-              selected_columns=None, totals=None, limitby=None, turbo=False):
+              aggregations=None, rollup=None, referrer=None,
+              is_grouprelease=False, **kwargs):
     """
     Sends a query to snuba.
 
+    `start` and `end`: The beginning and end of the query time window (required)
+
+    `groupby`: A list of column names to group by.
+
     `conditions`: A list of (column, operator, literal) conditions to be passed
     to the query. Conditions that we know will not have to be translated should
     be passed this way (eg tag[foo] = bar).
@@ -375,6 +378,9 @@ def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
 
     `aggregations` a list of (aggregation_function, column, alias) tuples to be
     passed to the query.
+
+    The rest of the args are passed directly into the query JSON unmodified.
+    See the snuba schema for details.
     """
 
     # convert to naive UTC datetimes, as Snuba only deals in UTC
@@ -384,10 +390,8 @@ def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
 
     groupby = groupby or []
     conditions = conditions or []
-    having = having or []
     aggregations = aggregations or []
     filter_keys = filter_keys or {}
-    selected_columns = selected_columns or []
 
     with timer('get_snuba_map'):
         forward, reverse = get_snuba_translators(filter_keys, is_grouprelease=is_grouprelease)
@@ -432,26 +436,18 @@ def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
     if start > end:
         raise QueryOutsideGroupActivityError
 
-    request = {k: v for k, v in six.iteritems({
+    kwargs.update({
         'from_date': start.isoformat(),
         'to_date': end.isoformat(),
-        'conditions': conditions,
-        'having': having,
         'groupby': groupby,
-        'totals': totals,
-        'project': project_ids,
+        'conditions': conditions,
         'aggregations': aggregations,
-        'granularity': rollup,
-        'arrayjoin': arrayjoin,
-        'limit': limit,
-        'offset': offset,
-        'limitby': limitby,
-        'orderby': orderby,
-        'selected_columns': selected_columns,
-        'turbo': turbo
-    }) if v is not None}
-
-    request.update(OVERRIDE_OPTIONS)
+        'project': project_ids,
+        'granularity': rollup,  # TODO name these things the same
+    })
+    kwargs = {k: v for k, v in six.iteritems(kwargs) if v is not None}
+
+    kwargs.update(OVERRIDE_OPTIONS)
 
     headers = {}
     if referrer:
@@ -460,7 +456,7 @@ def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
     try:
         with timer('snuba_query'):
             response = _snuba_pool.urlopen(
-                'POST', '/query', body=json.dumps(request), headers=headers)
+                'POST', '/query', body=json.dumps(kwargs), headers=headers)
     except urllib3.exceptions.HTTPError as err:
         raise SnubaError(err)
 
@@ -491,10 +487,8 @@ def raw_query(start, end, groupby=None, conditions=None, filter_keys=None,
     return body
 
 
-def query(start, end, groupby, conditions=None, filter_keys=None,
-          aggregations=None, rollup=None, arrayjoin=None, limit=None, offset=None,
-          orderby=None, having=None, referrer=None, is_grouprelease=False,
-          selected_columns=None, totals=None, limitby=None):
+def query(start, end, groupby, conditions=None, filter_keys=None, aggregations=None,
+          selected_columns=None, totals=None, **kwargs):
 
     aggregations = aggregations or [['count()', '', 'aggregate']]
     filter_keys = filter_keys or {}
@@ -503,9 +497,8 @@ def query(start, end, groupby, conditions=None, filter_keys=None,
     try:
         body = raw_query(
             start, end, groupby=groupby, conditions=conditions, filter_keys=filter_keys,
-            selected_columns=selected_columns, aggregations=aggregations, rollup=rollup,
-            arrayjoin=arrayjoin, limit=limit, offset=offset, orderby=orderby, having=having,
-            referrer=referrer, is_grouprelease=is_grouprelease, totals=totals, limitby=limitby
+            aggregations=aggregations, selected_columns=selected_columns, totals=totals,
+            **kwargs
         )
     except (QueryOutsideRetentionError, QueryOutsideGroupActivityError):
         if totals:
@@ -514,17 +507,19 @@ def query(start, end, groupby, conditions=None, filter_keys=None,
             return OrderedDict()
 
     # Validate and scrub response, and translate snuba keys back to IDs
-    aggregate_cols = [a[2] for a in aggregations]
-    expected_cols = set(groupby + aggregate_cols + selected_columns)
+    aggregate_names = [a[2] for a in aggregations]
+    selected_names = [c[2] if isinstance(c, (list, tuple)) else c for c in selected_columns]
+    expected_cols = set(groupby + aggregate_names + selected_names)
     got_cols = set(c['name'] for c in body['meta'])
 
-    assert expected_cols == got_cols
+    assert expected_cols == got_cols, 'expected {}, got {}'.format(expected_cols, got_cols)
 
     with timer('process_result'):
         if totals:
-            return nest_groups(body['data'], groupby, aggregate_cols), body['totals']
+            return nest_groups(body['data'], groupby, aggregate_names +
+                               selected_names), body['totals']
         else:
-            return nest_groups(body['data'], groupby, aggregate_cols)
+            return nest_groups(body['data'], groupby, aggregate_names + selected_names)
 
 
 def nest_groups(data, groups, aggregate_cols):
diff --git a/tests/snuba/search/test_backend.py b/tests/snuba/search/test_backend.py
index a99cbaf6ef..b46515ef5a 100644
--- a/tests/snuba/search/test_backend.py
+++ b/tests/snuba/search/test_backend.py
@@ -6,6 +6,7 @@ import pytest
 from datetime import datetime, timedelta
 from django.conf import settings
 from django.utils import timezone
+from hashlib import md5
 
 from sentry import options
 from sentry.models import (
@@ -472,7 +473,7 @@ class SnubaSearchTest(SnubaTestCase):
             count_hits=True,
         )
         assert list(results) == [self.group2]
-        assert results.hits is None  # NOQA
+        assert results.hits == 2
 
         results = self.backend.query(
             [self.project],
@@ -483,7 +484,7 @@ class SnubaSearchTest(SnubaTestCase):
             count_hits=True,
         )
         assert list(results) == [self.group1]
-        assert results.hits is None  # NOQA
+        assert results.hits == 1  # TODO this is actually wrong because of the cursor
 
         results = self.backend.query(
             [self.project],
@@ -494,7 +495,7 @@ class SnubaSearchTest(SnubaTestCase):
             count_hits=True,
         )
         assert list(results) == []
-        assert results.hits is None  # NOQA
+        assert results.hits == 1  # TODO this is actually wrong because of the cursor
 
     def test_age_filter(self):
         results = self.backend.query(
@@ -879,7 +880,7 @@ class SnubaSearchTest(SnubaTestCase):
             result = get_latest_release([self.project], [environment])
             assert result == new.version
 
-    @mock.patch('sentry.utils.snuba.query')
+    @mock.patch('sentry.utils.snuba.raw_query')
     def test_snuba_not_called_optimization(self, query_mock):
         assert self.backend.query([self.project], query='foo').results == [self.group1]
         assert not query_mock.called
@@ -889,9 +890,11 @@ class SnubaSearchTest(SnubaTestCase):
         ).results == []
         assert query_mock.called
 
-    @mock.patch('sentry.utils.snuba.query')
+    @mock.patch('sentry.utils.snuba.raw_query')
     def test_optimized_aggregates(self, query_mock):
-        query_mock.return_value = {}
+        # TODO this test is annoyingly fragile and breaks in hard-to-see ways
+        # any time anything about the snuba query changes
+        query_mock.return_value = {'data': [], 'totals': {'total': 0}}
 
         def Any(cls):
             class Any(object):
@@ -901,7 +904,7 @@ class SnubaSearchTest(SnubaTestCase):
 
         DEFAULT_LIMIT = 100
         chunk_growth = options.get('snuba.search.chunk-growth-rate')
-        limit = (DEFAULT_LIMIT * chunk_growth) + 1
+        limit = int(DEFAULT_LIMIT * chunk_growth)
 
         common_args = {
             'start': Any(datetime),
@@ -913,8 +916,12 @@ class SnubaSearchTest(SnubaTestCase):
             'referrer': 'search',
             'groupby': ['issue'],
             'conditions': [],
+            'selected_columns': [],
             'limit': limit,
             'offset': 0,
+            'totals': True,
+            'turbo': False,
+            'sample': 1,
         }
 
         self.backend.query([self.project], query='foo')
@@ -924,7 +931,10 @@ class SnubaSearchTest(SnubaTestCase):
                            last_seen_from=timezone.now())
         assert query_mock.call_args == mock.call(
             orderby=['-last_seen', 'issue'],
-            aggregations=[['toUInt64(max(timestamp)) * 1000', '', 'last_seen']],
+            aggregations=[
+                ['uniq', 'issue', 'total'],
+                ['toUInt64(max(timestamp)) * 1000', '', 'last_seen']
+            ],
             having=[('last_seen', '>=', Any(int))],
             **common_args
         )
@@ -935,6 +945,7 @@ class SnubaSearchTest(SnubaTestCase):
             aggregations=[
                 ['(toUInt64(log(times_seen) * 600)) + last_seen', '', 'priority'],
                 ['count()', '', 'times_seen'],
+                ['uniq', 'issue', 'total'],
                 ['toUInt64(max(timestamp)) * 1000', '', 'last_seen']
             ],
             having=[],
@@ -944,7 +955,10 @@ class SnubaSearchTest(SnubaTestCase):
         self.backend.query([self.project], query='foo', sort_by='freq', times_seen=5)
         assert query_mock.call_args == mock.call(
             orderby=['-times_seen', 'issue'],
-            aggregations=[['count()', '', 'times_seen']],
+            aggregations=[
+                ['count()', '', 'times_seen'],
+                ['uniq', 'issue', 'total'],
+            ],
             having=[('times_seen', '=', 5)],
             **common_args
         )
@@ -952,7 +966,10 @@ class SnubaSearchTest(SnubaTestCase):
         self.backend.query([self.project], query='foo', sort_by='new', age_from=timezone.now())
         assert query_mock.call_args == mock.call(
             orderby=['-first_seen', 'issue'],
-            aggregations=[['toUInt64(min(timestamp)) * 1000', '', 'first_seen']],
+            aggregations=[
+                ['toUInt64(min(timestamp)) * 1000', '', 'first_seen'],
+                ['uniq', 'issue', 'total'],
+            ],
             having=[('first_seen', '>=', Any(int))],
             **common_args
         )
@@ -998,3 +1015,78 @@ class SnubaSearchTest(SnubaTestCase):
         )
 
         assert set(results) == set([])
+
+    def test_hits_estimate(self):
+        # 400 Groups/Events
+        # Every 3rd one is Unresolved
+        # Evey 2nd one has tag match=1
+        for i in range(400):
+            group = self.create_group(
+                project=self.project,
+                checksum=md5('group {}'.format(i)).hexdigest(),
+                message='group {}'.format(i),
+                times_seen=5,
+                status=GroupStatus.UNRESOLVED if i % 3 == 0 else GroupStatus.RESOLVED,
+                last_seen=self.base_datetime,
+                first_seen=self.base_datetime - timedelta(days=31),
+            )
+            self.create_event(
+                event_id=md5('event {}'.format(i)).hexdigest(),
+                group=group,
+                datetime=self.base_datetime - timedelta(days=31),
+                message='group {} event'.format(i),
+                stacktrace={
+                    'frames': [{
+                        'module': 'module {}'.format(i)
+                    }]
+                },
+                tags={
+                    'match': '{}'.format(i % 2),
+                    'environment': 'production',
+                }
+            )
+
+        # Sample should estimate there are roughly 66 overall matching groups
+        # based on a random sample of 100 (or $sample_size) of the total 200
+        # snuba matches, of which 33% should pass the postgres filter.
+        with self.options({
+                # Too small to pass all django candidates down to snuba
+                'snuba.search.max-pre-snuba-candidates': 5,
+                'snuba.search.hits-sample-size': 50}):
+            first_results = self.backend.query(
+                [self.project],
+                status=GroupStatus.UNRESOLVED,
+                tags={'match': '1'},
+                limit=10,
+                count_hits=True,
+            )
+
+            # Deliberately do not assert that the value is within some margin
+            # of error, as this will fail tests at some rate corresponding to
+            # our confidence interval.
+            assert first_results.hits > 10
+
+            # When searching for the same tags, we should get the same set of
+            # hits as the sampling is based on the hash of the query.
+            second_results = self.backend.query(
+                [self.project],
+                status=GroupStatus.UNRESOLVED,
+                tags={'match': '1'},
+                limit=10,
+                count_hits=True,
+            )
+
+            assert first_results.results == second_results.results
+
+            # When using a different search, we should get a different sample
+            # but still should have some hits.
+            third_results = self.backend.query(
+                [self.project],
+                status=GroupStatus.UNRESOLVED,
+                tags={'match': '0'},
+                limit=10,
+                count_hits=True,
+            )
+
+            assert third_results.hits > 10
+            assert third_results.results != second_results.results
