commit f22d270126c8158880581e3eeb7ee457564a4229
Author: William Mak <william@wmak.io>
Date:   Fri Mar 27 17:12:52 2020 -0400

    feat(performance) - Adding key transactions to event stats
    
    - Yanking the key transaction query conditions out into its own function
    - Reusing the conditions for event stats
    - Adding the same param that forces conditions on a query for timeseries
      too.

diff --git a/src/sentry/api/bases/organization_events.py b/src/sentry/api/bases/organization_events.py
index 96ed44e2cc..277002baf5 100644
--- a/src/sentry/api/bases/organization_events.py
+++ b/src/sentry/api/bases/organization_events.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 
 import six
+from datetime import timedelta
 from rest_framework.exceptions import PermissionDenied
 from rest_framework.exceptions import ParseError
 
@@ -8,11 +9,24 @@ from rest_framework.exceptions import ParseError
 from sentry import features
 from sentry_relay.consts import SPAN_STATUS_CODE_TO_NAME
 from sentry.api.bases import OrganizationEndpoint, OrganizationEventsError
-from sentry.api.event_search import get_filter, InvalidSearchQuery, get_json_meta_type
+from sentry.api.event_search import (
+    get_filter,
+    InvalidSearchQuery,
+    get_json_meta_type,
+    get_function_alias,
+)
+from sentry.api.serializers.snuba import SnubaTSResultSerializer
 from sentry.models.project import Project
 from sentry.models.group import Group
 from sentry.snuba.discover import ReferenceEvent
-from sentry.utils.compat import map
+from sentry.utils.compat import map, zip
+from sentry.utils.dates import parse_stats_period
+
+
+# Maximum number of results we are willing to fetch.
+# Clients should adapt the interval width based on their
+# display width.
+MAX_POINTS = 4500
 
 
 class OrganizationEventsEndpointBase(OrganizationEndpoint):
@@ -131,6 +145,54 @@ class OrganizationEventsV2EndpointBase(OrganizationEventsEndpointBase):
 
         return results
 
+    def get_event_stats_data(self, request, organization, get_event_stats):
+        try:
+            columns = request.GET.getlist("yAxis", ["count()"])
+            query = request.GET.get("query")
+            params = self.get_filter_params(request, organization)
+            rollup = self.get_rollup(request, params)
+            # Backwards compatibility for incidents which uses the old
+            # column aliases as it straddles both versions of events/discover.
+            # We will need these aliases until discover2 flags are enabled for all
+            # users.
+            column_map = {
+                "user_count": "count_unique(user)",
+                "event_count": "count()",
+                "rpm()": "rpm(%d)" % rollup,
+                "rps()": "rps(%d)" % rollup,
+            }
+            query_columns = [column_map.get(column, column) for column in columns]
+            reference_event = self.reference_event(
+                request, organization, params.get("start"), params.get("end")
+            )
+
+            result = get_event_stats(query_columns, query, params, rollup, reference_event)
+        except InvalidSearchQuery as err:
+            raise ParseError(detail=six.text_type(err))
+        serializer = SnubaTSResultSerializer(organization, None, request.user)
+        if len(columns) > 1:
+            # Return with requested yAxis as the key
+            return {
+                column: serializer.serialize(result, get_function_alias(query_column))
+                for column, query_column in zip(columns, query_columns)
+            }
+        else:
+            return serializer.serialize(result)
+
+    def get_rollup(self, request, params):
+        interval = parse_stats_period(request.GET.get("interval", "1h"))
+        if interval is None:
+            interval = timedelta(hours=1)
+
+        date_range = params["end"] - params["start"]
+        if date_range.total_seconds() / interval.total_seconds() > MAX_POINTS:
+            raise InvalidSearchQuery(
+                "Your interval and date range would create too many results. "
+                "Use a larger interval, or a smaller date range."
+            )
+
+        return int(interval.total_seconds())
+
 
 class KeyTransactionBase(OrganizationEventsV2EndpointBase):
     def has_feature(self, request, organization):
diff --git a/src/sentry/api/endpoints/organization_events_stats.py b/src/sentry/api/endpoints/organization_events_stats.py
index 83f8026480..5def368286 100644
--- a/src/sentry/api/endpoints/organization_events_stats.py
+++ b/src/sentry/api/endpoints/organization_events_stats.py
@@ -2,83 +2,36 @@ from __future__ import absolute_import
 
 import six
 
-from datetime import timedelta
 from rest_framework.response import Response
 from rest_framework.exceptions import ParseError
 
 from sentry import features, eventstore
-from sentry.api.bases import OrganizationEventsEndpointBase, OrganizationEventsError, NoProjects
-from sentry.api.event_search import resolve_field_list, InvalidSearchQuery, get_function_alias
+from sentry.api.bases import OrganizationEventsV2EndpointBase, OrganizationEventsError, NoProjects
+from sentry.api.event_search import resolve_field_list, InvalidSearchQuery
 from sentry.api.serializers.snuba import SnubaTSResultSerializer
 from sentry.discover.utils import transform_aliases_and_query
 from sentry.snuba import discover
 from sentry.utils import snuba
-from sentry.utils.dates import parse_stats_period
-from sentry.utils.compat import zip
 
-# Maximum number of results we are willing to fetch.
-# Clients should adapt the interval width based on their
-# display width.
-MAX_POINTS = 4500
 
-
-class OrganizationEventsStatsEndpoint(OrganizationEventsEndpointBase):
+class OrganizationEventsStatsEndpoint(OrganizationEventsV2EndpointBase):
     def get(self, request, organization):
         if not features.has("organizations:discover-basic", organization, actor=request.user):
             return self.get_v1_results(request, organization)
 
-        try:
-            columns = request.GET.getlist("yAxis", ["count()"])
-            params = self.get_filter_params(request, organization)
-            rollup = self.get_rollup(request, params)
-            # Backwards compatibility for incidents which uses the old
-            # column aliases as it straddles both versions of events/discover.
-            # We will need these aliases until discover2 flags are enabled for all
-            # users.
-            column_map = {
-                "user_count": "count_unique(user)",
-                "event_count": "count()",
-                "rpm()": "rpm(%d)" % rollup,
-                "rps()": "rps(%d)" % rollup,
-            }
-            query_columns = [column_map.get(column, column) for column in columns]
-
-            result = discover.timeseries_query(
+        def get_event_stats(query_columns, query, params, rollup, reference_event):
+            return discover.timeseries_query(
                 selected_columns=query_columns,
-                query=request.GET.get("query"),
+                query=query,
                 params=params,
                 rollup=rollup,
-                reference_event=self.reference_event(
-                    request, organization, params.get("start"), params.get("end")
-                ),
+                reference_event=reference_event,
                 referrer="api.organization-event-stats",
             )
-        except InvalidSearchQuery as err:
-            raise ParseError(detail=six.text_type(err))
-        serializer = SnubaTSResultSerializer(organization, None, request.user)
-        if len(columns) > 1:
-            # Return with requested yAxis as the key
-            data = {
-                column: serializer.serialize(result, get_function_alias(query_column))
-                for column, query_column in zip(columns, query_columns)
-            }
-        else:
-            data = serializer.serialize(result)
-        return Response(data, status=200)
-
-    def get_rollup(self, request, params):
-        interval = parse_stats_period(request.GET.get("interval", "1h"))
-        if interval is None:
-            interval = timedelta(hours=1)
-
-        date_range = params["end"] - params["start"]
-        if date_range.total_seconds() / interval.total_seconds() > MAX_POINTS:
-            raise InvalidSearchQuery(
-                "Your interval and date range would create too many results. "
-                "Use a larger interval, or a smaller date range."
-            )
 
-        return int(interval.total_seconds())
+        return Response(
+            self.get_event_stats_data(request, organization, get_event_stats), status=200
+        )
 
     def get_v1_results(self, request, organization):
         try:
diff --git a/src/sentry/api/urls.py b/src/sentry/api/urls.py
index 2d368f3ee1..6c237c31ed 100644
--- a/src/sentry/api/urls.py
+++ b/src/sentry/api/urls.py
@@ -289,6 +289,7 @@ from sentry.discover.endpoints.discover_saved_queries import DiscoverSavedQuerie
 from sentry.discover.endpoints.discover_saved_query_detail import DiscoverSavedQueryDetailEndpoint
 from sentry.discover.endpoints.discover_key_transactions import (
     KeyTransactionEndpoint,
+    KeyTransactionStatsEndpoint,
     IsKeyTransactionEndpoint,
 )
 from sentry.incidents.endpoints.organization_alert_rule_available_action_index import (
@@ -668,6 +669,11 @@ urlpatterns = [
                     IsKeyTransactionEndpoint.as_view(),
                     name="sentry-api-0-organization-is-key-transactions",
                 ),
+                url(
+                    r"^(?P<organization_slug>[^\/]+)/key-transactions-stats/$",
+                    KeyTransactionStatsEndpoint.as_view(),
+                    name="sentry-api-0-organization-key-transactions-stats",
+                ),
                 # Dashboards
                 url(
                     r"^(?P<organization_slug>[^\/]+)/dashboards/$",
diff --git a/src/sentry/discover/endpoints/discover_key_transactions.py b/src/sentry/discover/endpoints/discover_key_transactions.py
index 4a7724d98c..64d2b639f0 100644
--- a/src/sentry/discover/endpoints/discover_key_transactions.py
+++ b/src/sentry/discover/endpoints/discover_key_transactions.py
@@ -8,7 +8,7 @@ from sentry.api.bases.organization import OrganizationPermission
 from sentry.api.exceptions import ResourceDoesNotExist
 from sentry.discover.models import KeyTransaction
 from sentry.discover.endpoints.serializers import KeyTransactionSerializer
-from sentry.snuba.discover import query
+from sentry.snuba.discover import key_transaction_query, key_transaction_timeseries_query
 
 
 class IsKeyTransactionEndpoint(KeyTransactionBase):
@@ -71,40 +71,8 @@ class KeyTransactionEndpoint(KeyTransactionBase):
         if not queryset.exists():
             raise ResourceDoesNotExist
 
-        results = query(
-            fields,
-            request.GET.get("query"),
-            params,
-            orderby=orderby,
-            referrer="discover.key_transactions",
-            # The snuba query for transactions is of the form
-            # (transaction="1" AND project=1) OR (transaction="2" and project=2) ...
-            # which the schema intentionally doesn't support so we cannot do an AND in OR
-            # so here the "and" operator is being instead to do an AND in OR query
-            conditions=[
-                [
-                    # First layer is Ands
-                    [
-                        # Second layer is Ors
-                        [
-                            "and",
-                            [
-                                [
-                                    "equals",
-                                    # Without the outer ' here, the transaction will be treated as another column
-                                    # instead of a string. This isn't an injection risk since snuba is smart enough to
-                                    # handle escaping for us.
-                                    ["transaction", u"'{}'".format(transaction.transaction)],
-                                ],
-                                ["equals", ["project_id", transaction.project.id]],
-                            ],
-                        ],
-                        "=",
-                        1,
-                    ]
-                    for transaction in queryset
-                ]
-            ],
+        results = key_transaction_query(
+            fields, request.GET.get("query"), params, orderby, "discover.key_transactions", queryset
         )
 
         return Response(
@@ -130,3 +98,30 @@ class KeyTransactionEndpoint(KeyTransactionBase):
         model.delete()
 
         return Response(status=204)
+
+
+class KeyTransactionStatsEndpoint(KeyTransactionBase):
+    permission_classes = (OrganizationPermission,)
+
+    def get(self, request, organization):
+        """ Get the Key Transactions for a user """
+        if not self.has_feature(request, organization):
+            return self.response(status=404)
+
+        queryset = KeyTransaction.objects.filter(organization=organization, owner=request.user)
+        if not queryset.exists():
+            raise ResourceDoesNotExist
+
+        def get_event_stats(query_columns, query, params, rollup, reference_event=None):
+            return key_transaction_timeseries_query(
+                selected_columns=query_columns,
+                query=query,
+                params=params,
+                rollup=rollup,
+                referrer="api.organization-event-stats.key-transactions",
+                queryset=queryset,
+            )
+
+        return Response(
+            self.get_event_stats_data(request, organization, get_event_stats), status=200
+        )
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index 2c4ee0d441..1c56f7dcc9 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -38,6 +38,7 @@ __all__ = (
     "InvalidSearchQuery",
     "create_reference_event_conditions",
     "query",
+    "key_transaction_query",
     "timeseries_query",
     "get_pagination_ids",
     "get_facets",
@@ -597,28 +598,51 @@ def query(
     return transform_results(result, translated_columns, snuba_filter)
 
 
-def timeseries_query(selected_columns, query, params, rollup, reference_event=None, referrer=None):
+def key_transaction_conditions(queryset):
     """
-    High-level API for doing arbitrary user timeseries queries against events.
+        The snuba query for transactions is of the form
+        (transaction="1" AND project=1) OR (transaction="2" and project=2) ...
+        which the schema intentionally doesn't support so we cannot do an AND in OR
+        so here the "and" operator is being instead to do an AND in OR query
+    """
+    return [
+        [
+            # First layer is Ands
+            [
+                # Second layer is Ors
+                [
+                    "and",
+                    [
+                        [
+                            "equals",
+                            # Without the outer ' here, the transaction will be treated as another column
+                            # instead of a string. This isn't an injection risk since snuba is smart enough to
+                            # handle escaping for us.
+                            ["transaction", u"'{}'".format(transaction.transaction)],
+                        ],
+                        ["equals", ["project_id", transaction.project.id]],
+                    ],
+                ],
+                "=",
+                1,
+            ]
+            for transaction in queryset
+        ]
+    ]
 
-    This function operates on the public event schema and
-    virtual fields/aggregate functions for selected columns and
-    conditions are supported through this function.
 
-    This function is intended to only get timeseries based
-    results and thus requires the `rollup` parameter.
+def key_transaction_query(selected_columns, user_query, params, orderby, referrer, queryset):
+    return query(
+        selected_columns,
+        user_query,
+        params,
+        orderby=orderby,
+        referrer=referrer,
+        conditions=key_transaction_conditions(queryset),
+    )
 
-    Returns a SnubaTSResult object that has been zerofilled in
-    case of gaps.
 
-    selected_columns (Sequence[str]) List of public aliases to fetch.
-    query (str) Filter query string to create conditions from.
-    params (Dict[str, str]) Filtering parameters with start, end, project_id, environment,
-    rollup (int) The bucket width in seconds
-    reference_event (ReferenceEvent) A reference event object. Used to generate additional
-                    conditions based on the provided reference.
-    referrer (str|None) A referrer string to help locate the origin of this query.
-    """
+def get_timeseries_snuba_filter(selected_columns, query, params, rollup, reference_event=None):
     # TODO(evanh): These can be removed once we migrate the frontend / saved queries
     # to use the new function values
     selected_columns, _ = transform_deprecated_functions_in_columns(selected_columns)
@@ -644,6 +668,70 @@ def timeseries_query(selected_columns, query, params, rollup, reference_event=No
     if len(snuba_filter.aggregations) == 1:
         snuba_filter.aggregations[0][2] = "count"
 
+    return snuba_filter
+
+
+def key_transaction_timeseries_query(selected_columns, query, params, rollup, referrer, queryset):
+    """ Given a queryset of KeyTransactions perform a timeseries query
+
+        This function is intended to match the `timeseries_query` function,
+        but exists to avoid including conditions as a parameter on that function.
+
+        selected_columns (Sequence[str]) List of public aliases to fetch.
+        query (str) Filter query string to create conditions from.
+        params (Dict[str, str]) Filtering parameters with start, end, project_id, environment,
+        rollup (int) The bucket width in seconds
+        referrer (str|None) A referrer string to help locate the origin of this query.
+        queryset (QuerySet) Filtered QuerySet of KeyTransactions
+    """
+    snuba_filter = get_timeseries_snuba_filter(selected_columns, query, params, rollup)
+    snuba_filter.conditions.extend(key_transaction_conditions(queryset))
+
+    result = raw_query(
+        aggregations=snuba_filter.aggregations,
+        conditions=snuba_filter.conditions,
+        filter_keys=snuba_filter.filter_keys,
+        start=snuba_filter.start,
+        end=snuba_filter.end,
+        rollup=rollup,
+        orderby="time",
+        groupby=["time"],
+        dataset=Dataset.Discover,
+        limit=10000,
+        referrer=referrer,
+    )
+    result = zerofill(result["data"], snuba_filter.start, snuba_filter.end, rollup, "time")
+
+    return SnubaTSResult({"data": result}, snuba_filter.start, snuba_filter.end, rollup)
+
+
+def timeseries_query(selected_columns, query, params, rollup, reference_event=None, referrer=None):
+    """
+    High-level API for doing arbitrary user timeseries queries against events.
+
+    This function operates on the public event schema and
+    virtual fields/aggregate functions for selected columns and
+    conditions are supported through this function.
+
+    This function is intended to only get timeseries based
+    results and thus requires the `rollup` parameter.
+
+    Returns a SnubaTSResult object that has been zerofilled in
+    case of gaps.
+
+    selected_columns (Sequence[str]) List of public aliases to fetch.
+    query (str) Filter query string to create conditions from.
+    params (Dict[str, str]) Filtering parameters with start, end, project_id, environment,
+    rollup (int) The bucket width in seconds
+    reference_event (ReferenceEvent) A reference event object. Used to generate additional
+                    conditions based on the provided reference.
+    referrer (str|None) A referrer string to help locate the origin of this query.
+    """
+
+    snuba_filter = get_timeseries_snuba_filter(
+        selected_columns, query, params, rollup, reference_event
+    )
+
     result = raw_query(
         aggregations=snuba_filter.aggregations,
         conditions=snuba_filter.conditions,
diff --git a/tests/snuba/api/endpoints/test_discover_key_transactions.py b/tests/snuba/api/endpoints/test_discover_key_transactions.py
index d008a56113..113e6f896c 100644
--- a/tests/snuba/api/endpoints/test_discover_key_transactions.py
+++ b/tests/snuba/api/endpoints/test_discover_key_transactions.py
@@ -2,17 +2,18 @@ from __future__ import absolute_import
 
 import pytz
 import six
+from datetime import timedelta
 
 from django.core.urlresolvers import reverse
 
 from sentry.utils.compat.mock import patch
 from sentry.discover.models import KeyTransaction, MAX_KEY_TRANSACTIONS
 from sentry.utils.samples import load_data
-from sentry.testutils import APITestCase
+from sentry.testutils import APITestCase, SnubaTestCase
 from sentry.testutils.helpers.datetime import iso_format, before_now
 
 
-class KeyTransactionTest(APITestCase):
+class KeyTransactionTest(APITestCase, SnubaTestCase):
     def setUp(self):
         super(KeyTransactionTest, self).setUp()
 
@@ -467,3 +468,128 @@ class KeyTransactionTest(APITestCase):
             )
 
         assert response.status_code == 403
+
+    @patch("django.utils.timezone.now")
+    def test_key_transaction_stats(self, mock_now):
+        mock_now.return_value = before_now().replace(tzinfo=pytz.utc)
+        data = load_data("transaction")
+        event_ids = ["d" * 32, "e" * 32, "f" * 32]
+        data.update(
+            {
+                "timestamp": iso_format(before_now(minutes=30)),
+                "start_timestamp": iso_format(before_now(minutes=31)),
+            }
+        )
+        for event_id in event_ids:
+            data["event_id"] = event_id
+            self.store_event(data=data, project_id=self.project.id)
+
+        KeyTransaction.objects.create(
+            owner=self.user,
+            organization=self.org,
+            transaction=data["transaction"],
+            project=self.project,
+        )
+
+        with self.feature("organizations:performance-view"):
+            url = reverse("sentry-api-0-organization-key-transactions-stats", args=[self.org.slug])
+            response = self.client.get(
+                url,
+                format="json",
+                data={
+                    "start": iso_format(before_now(hours=2)),
+                    "end": iso_format(before_now()),
+                    "interval": "1h",
+                    "yAxis": "count()",
+                    "project": [self.project.id],
+                },
+            )
+
+        assert response.status_code == 200, response.content
+        assert len(response.data["data"]) == 3
+        assert [{"count": 3}] in [attrs for time, attrs in response.data["data"]]
+
+    @patch("django.utils.timezone.now")
+    def test_key_transaction_with_query(self, mock_now):
+        mock_now.return_value = before_now().replace(tzinfo=pytz.utc)
+        prototype = {
+            "type": "transaction",
+            "transaction": "api.issue.delete",
+            "spans": [],
+            "contexts": {"trace": {"op": "foobar", "trace_id": "a" * 32, "span_id": "a" * 16}},
+            "tags": {"important": "yes"},
+            "timestamp": iso_format(before_now(minutes=30)),
+            "start_timestamp": iso_format(before_now(minutes=31)),
+        }
+        fixtures = (("d" * 32, "yes"), ("e" * 32, "no"), ("f" * 32, "yes"))
+        for fixture in fixtures:
+            data = prototype.copy()
+            data["event_id"] = fixture[0]
+            data["tags"]["important"] = fixture[1]
+            self.store_event(data=data, project_id=self.project.id)
+
+        KeyTransaction.objects.create(
+            owner=self.user,
+            organization=self.project.organization,
+            transaction=prototype["transaction"],
+            project=self.project,
+        )
+
+        with self.feature("organizations:performance-view"):
+            url = reverse("sentry-api-0-organization-key-transactions-stats", args=[self.org.slug])
+            response = self.client.get(
+                url,
+                format="json",
+                data={
+                    "end": iso_format(before_now()),
+                    "start": iso_format(before_now(hours=2)),
+                    "interval": "1h",
+                    "yAxis": "count()",
+                    "query": "tags[important]:yes",
+                    "project": [self.project.id],
+                },
+            )
+
+        assert response.status_code == 200, response.content
+        assert len(response.data["data"]) == 3
+        assert [{"count": 2}] in [attrs for time, attrs in response.data["data"]]
+
+    @patch("django.utils.timezone.now")
+    def test_key_transaction_stats_with_no_key_transactions(self, mock_now):
+        mock_now.return_value = before_now().replace(tzinfo=pytz.utc)
+        prototype = {
+            "type": "transaction",
+            "transaction": "api.issue.delete",
+            "spans": [],
+            "contexts": {"trace": {"op": "foobar", "trace_id": "a" * 32, "span_id": "a" * 16}},
+            "tags": {"important": "yes"},
+        }
+        fixtures = (
+            ("d" * 32, before_now(minutes=32), "yes"),
+            ("e" * 32, before_now(hours=1, minutes=2), "no"),
+            ("f" * 32, before_now(hours=1, minutes=35), "yes"),
+        )
+        for fixture in fixtures:
+            data = prototype.copy()
+            data["event_id"] = fixture[0]
+            data["timestamp"] = iso_format(fixture[1])
+            data["start_timestamp"] = iso_format(fixture[1] - timedelta(seconds=1))
+            data["tags"]["important"] = fixture[2]
+            self.store_event(data=data, project_id=self.project.id)
+
+        with self.feature("organizations:performance-view"):
+            url = reverse("sentry-api-0-organization-key-transactions-stats", args=[self.org.slug])
+            response = self.client.get(
+                url,
+                format="json",
+                data={
+                    "end": iso_format(before_now()),
+                    "start": iso_format(before_now(hours=2)),
+                    "interval": "30m",
+                    "yAxis": "count()",
+                    "query": "tags[important]: yes",
+                    "project": [self.project.id],
+                },
+            )
+
+        assert response.status_code == 404
diff --git a/tests/snuba/api/endpoints/test_organization_events_stats.py b/tests/snuba/api/endpoints/test_organization_events_stats.py
index 19008c50e8..aff445b3fe 100644
--- a/tests/snuba/api/endpoints/test_organization_events_stats.py
+++ b/tests/snuba/api/endpoints/test_organization_events_stats.py
@@ -1,8 +1,8 @@
 from __future__ import absolute_import
 
+import mock
 import six
 import uuid
-import mock
 
 from datetime import timedelta
 
@@ -17,6 +17,7 @@ class OrganizationEventsStatsEndpointTest(APITestCase, SnubaTestCase):
     def setUp(self):
         super(OrganizationEventsStatsEndpointTest, self).setUp()
         self.login_as(user=self.user)
+        self.authed_user = self.user
 
         self.day_ago = before_now(days=1).replace(hour=10, minute=0, second=0, microsecond=0)
 
