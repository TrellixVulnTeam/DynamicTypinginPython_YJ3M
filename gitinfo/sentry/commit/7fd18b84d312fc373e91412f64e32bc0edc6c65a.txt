commit 7fd18b84d312fc373e91412f64e32bc0edc6c65a
Author: ted kaemming <ted@kaemming.com>
Date:   Thu Aug 17 11:35:11 2017 -0700

    Ensure all usage of `unpack` in digest script have fixed upper bounds. (#5900)
    
    This ensures all usage of `unpack` in the digest Lua script have fixed upper bounds to [prevent exceeding the stack limit](https://github.com/antirez/redis/issues/678#issuecomment-15848571).
    
    1. This replaces the existing `unpack`-based argument parser with a cursor-based iterative argument parser.
    2. This ensures that all Redis commands that are passed a variable number of arguments with `unpack` are wrapped in a chunk iterator to ensure that they don't exceed a specific number of arguments.
    
    This fixes SENTRY-45E.

diff --git a/src/sentry/scripts/digests/digests.lua b/src/sentry/scripts/digests/digests.lua
index 19f552acd4..01010cfd86 100644
--- a/src/sentry/scripts/digests/digests.lua
+++ b/src/sentry/scripts/digests/digests.lua
@@ -1,3 +1,13 @@
+-- Utilities
+
+local noop = function ()
+    return
+end
+
+local function identity(...)
+    return ...
+end
+
 function table.extend(t, items, length)
     -- The table length can be provided if you know the length of the table
     -- beforehand to avoid a potentially expensive length operator call.
@@ -9,22 +19,85 @@ function table.extend(t, items, length)
     end
 end
 
-function table.slice(t, start, stop)
-    if stop == nil then
-        stop = #t
+local function chunked(size, iterator, state, ...)
+    local next = {iterator(state, ...)}
+    local chunk_count = 1
+
+    return function ()
+        local item_count = 0
+        if #next == 0 then
+            return nil
+        end
+
+        return chunk_count, function ()
+            if item_count == size or #next == 0 then
+                chunk_count = chunk_count + 1
+                return nil
+            end
+
+            local result = next
+            next = {iterator(state, result[1])}
+
+            item_count = item_count + 1
+            return item_count, unpack(result)
+        end
+    end
+end
+
+
+-- Argument Parsing
+
+local function argument_parser(callback)
+    if callback == nil then
+        callback = identity
     end
 
-    local result = {}
-    for i = start, stop do
-        result[i - start + 1] = t[i]
+    return function (cursor, arguments)
+        return cursor + 1, callback(arguments[cursor])
     end
-    return result
 end
 
-local noop = function ()
-    return
+local function object_argument_parser(schema, callback)
+    if callback == nil then
+        callback = identity
+    end
+
+    return function (cursor, arguments)
+        local result = {}
+        for i, specification in ipairs(schema) do
+            local key, parser = unpack(specification)
+            cursor, result[key] = parser(cursor, arguments)
+        end
+        return cursor, callback(result)
+    end
 end
 
+local function variadic_argument_parser(argument_parser)
+    return function (cursor, arguments)
+        local results = {}
+        local i = 1
+        while arguments[cursor] ~= nil do
+            cursor, results[i] = argument_parser(cursor, arguments)
+            i = i + 1
+        end
+        return cursor, results
+    end
+end
+
+local function multiple_argument_parser(...)
+    local parsers = {...}
+    return function (cursor, arguments)
+        local results = {}
+        for i, parser in ipairs(parsers) do
+            cursor, results[i] = parser(cursor, arguments)
+        end
+        return cursor, unpack(results)
+    end
+end
+
+
+-- Redis Helpers
+
 local function zrange_scored_iterator(result)
     local i = -1
     return function ()
@@ -44,21 +117,23 @@ local function zrange_move_slice(source, destination, threshold, callback)
         return
     end
 
-    local i = 0
-    local zadd_args = {}
-    local zrem_args = {}
-    for key, score in zrange_scored_iterator(keys) do
-        zrem_args[i + 1] = key
-        table.extend(zadd_args, {score, key}, i * 2)
-        i = i + 1
-        callback(key, score)
-    end
+    -- NOTE: The actual number of arguments is the chunk size * 2, since the
+    -- ZADD command takes two arguments per item.
+    for _, chunk_iterator in chunked(500, zrange_scored_iterator(keys)) do
+        local zadd_args = {}
+        local zrem_args = {}
+        for i, key, score in chunk_iterator do
+            table.extend(zadd_args, {score, key}, (i - 1) * 2)
+            zrem_args[i] = key
+            callback(key, score)
+        end
 
-    -- TODO: This should support modifiers, and maintenance ZADD should include
-    -- the "NX" modifier to avoid resetting schedules during a race conditions
-    -- between a digest task and the maintenance task.
-    redis.call('ZADD', destination, unpack(zadd_args))
-    redis.call('ZREM', source, unpack(zrem_args))
+        -- TODO: This should support modifiers, and maintenance ZADD should
+        -- include the "NX" modifier to avoid resetting schedules during a race
+        -- conditions between a digest task and the maintenance task.
+        redis.call('ZADD', destination, unpack(zadd_args))
+        redis.call('ZREM', source, unpack(zrem_args))
+    end
 end
 
 local function zset_trim(key, capacity, callback)
@@ -86,6 +161,9 @@ local function zset_trim(key, capacity, callback)
     return n
 end
 
+
+-- Timeline and Schedule Operations
+
 local function schedule(configuration, deadline)
     local response = {}
     local i = 0
@@ -181,10 +259,7 @@ local function add_record_to_timeline(configuration, timeline_id, record_id, val
 
     local ready = add_timeline_to_schedule(configuration, timeline_id, timestamp, delay_increment, delay_maximum)
 
-    -- TODO: Validating `timeline_capacity` and casting to number should happen upstream.
-    local timeline_capacity = tonumber(timeline_capacity)
-    -- TODO: Validating `truncation_chance` and casting to number should happen upstream.
-    if timeline_capacity > 0 and math.random() < tonumber(truncation_chance) then
+    if timeline_capacity > 0 and math.random() < truncation_chance then
         truncate_timeline(configuration, timeline_id, timeline_capacity)
     end
 
@@ -229,16 +304,19 @@ local function digest_timeline(configuration, timeline_id)
     return results
 end
 
-local function close_digest(configuration, timeline_id, delay_minimum, ...)
-    local record_ids = {...}
+local function close_digest(configuration, timeline_id, delay_minimum, record_ids)
     local timeline_key = configuration:get_timeline_key(timeline_id)
     local digest_key = configuration:get_timeline_digest_key(timeline_id)
 
-    if #record_ids > 0 then
-        redis.call('ZREM', digest_key, unpack(record_ids))
-        for _, record_id in ipairs(record_ids) do
-            redis.call('DEL', configuration:get_timeline_record_key(timeline_id, record_id))
+    for _, chunk_iterator in chunked(1000, ipairs(record_ids)) do
+        local record_id_chunk = {}
+        local record_key_chunk = {}
+        for i, _, record_id in chunk_iterator do
+            record_id_chunk[i] = record_id
+            record_key_chunk[i] = configuration:get_timeline_record_key(timeline_id, record_id)
         end
+        redis.call('ZREM', digest_key, unpack(record_id_chunk))
+        redis.call('DEL', unpack(record_key_chunk))
     end
 
     -- If this digest didn't contain any data (no record IDs) and there isn't
@@ -263,14 +341,14 @@ local function delete_timeline(configuration, timeline_id)
     redis.call('ZREM', configuration:get_schedule_waiting_key(), timeline_id)
 end
 
-local function parse_arguments(arguments)
-    -- TODO: These need validation!
-    local configuration = {
-        namespace = arguments[1],
-        ttl = tonumber(arguments[2]),
-        timestamp = tonumber(arguments[3]),
-    }
 
+-- Command Execution
+
+local configuration_argument_parser = object_argument_parser({
+    {"namespace", argument_parser()},
+    {"ttl", argument_parser(tonumber)},
+    {"timestamp", argument_parser(tonumber)},
+}, function (configuration)
     math.randomseed(configuration.timestamp)
 
     function configuration:get_schedule_waiting_key()
@@ -297,34 +375,79 @@ local function parse_arguments(arguments)
         return string.format('%s:t:%s:r:%s', self.namespace, timeline_id, record_id)
     end
 
-    return configuration, table.slice(arguments, 4)
-end
+    return configuration
+end)
 
 local commands = {
-    SCHEDULE = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return schedule(configuration, unpack(arguments))
+    SCHEDULE = function (cursor, arguments)
+        local cursor, configuration, deadline = multiple_argument_parser(
+            configuration_argument_parser,
+            argument_parser(tonumber)
+        )(cursor, arguments)
+        return schedule(configuration, deadline)
     end,
-    MAINTENANCE = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return maintenance(configuration, unpack(arguments))
+    MAINTENANCE = function (cursor, arguments)
+        local cursor, configuration, deadline = multiple_argument_parser(
+            configuration_argument_parser,
+            argument_parser(tonumber)
+        )(cursor, arguments)
+        return maintenance(configuration, deadline)
     end,
-    ADD = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return add_record_to_timeline(configuration, unpack(arguments))
+    ADD = function (cursor, arguments)
+        local cursor, configuration, arguments = multiple_argument_parser(
+            configuration_argument_parser,
+            object_argument_parser({
+                {"timeline_id", argument_parser()},
+                {"record_id", argument_parser()},
+                {"value", argument_parser()},
+                {"timestamp", argument_parser(tonumber)},
+                {"delay_increment", argument_parser(tonumber)},
+                {"delay_maximum", argument_parser(tonumber)},
+                {"timeline_capacity", argument_parser(tonumber)},
+                {"truncation_chance", argument_parser(tonumber)},
+            })
+        )(cursor, arguments)
+        return add_record_to_timeline(
+            configuration,
+            arguments.timeline_id,
+            arguments.record_id,
+            arguments.value,
+            arguments.timestamp,
+            arguments.delay_increment,
+            arguments.delay_maximum,
+            arguments.timeline_capacity,
+            arguments.truncation_chance
+        )
     end,
-    DELETE = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return delete_timeline(configuration, unpack(arguments))
+    DELETE = function (cursor, arguments)
+        local cursor, configuration, timeline_id = multiple_argument_parser(
+            configuration_argument_parser,
+            argument_parser()
+        )(cursor, arguments)
+        return delete_timeline(configuration, timeline_id)
     end,
-    DIGEST_OPEN = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return digest_timeline(configuration, unpack(arguments))
+    DIGEST_OPEN = function (cursor, arguments)
+        local cursor, configuration, timeline_id = multiple_argument_parser(
+            configuration_argument_parser,
+            argument_parser()
+        )(cursor, arguments)
+        return digest_timeline(configuration, timeline_id)
     end,
-    DIGEST_CLOSE = function (arguments)
-        local configuration, arguments = parse_arguments(arguments)
-        return close_digest(configuration, unpack(arguments))
+    DIGEST_CLOSE = function (cursor, arguments)
+        local cursor, configuration, timeline_id, delay_minimum, record_ids = multiple_argument_parser(
+            configuration_argument_parser,
+            argument_parser(),
+            argument_parser(tonumber),
+            variadic_argument_parser(argument_parser())
+        )(cursor, arguments)
+        return close_digest(configuration, timeline_id, delay_minimum, record_ids)
     end,
 }
 
-return commands[ARGV[1]](table.slice(ARGV, 2))
+local cursor, command = argument_parser(
+    function (argument)
+        return commands[argument]
+    end
+)(1, ARGV)
+
+return command(cursor, ARGV)
diff --git a/tests/sentry/digests/backends/test_redis.py b/tests/sentry/digests/backends/test_redis.py
index fb0f2c0072..2476dfb492 100644
--- a/tests/sentry/digests/backends/test_redis.py
+++ b/tests/sentry/digests/backends/test_redis.py
@@ -107,3 +107,14 @@ class RedisBackendTestCase(TestCase):
         # contents were merged back into the digest.
         with backend.digest('timeline', 0) as records:
             assert set(records) == set([record_2])
+
+    def test_large_digest(self):
+        backend = RedisBackend()
+
+        n = 8192
+        t = time.time()
+        for i in xrange(n):
+            backend.add('timeline', Record('record:{}'.format(i), '{}'.format(i), t))
+
+        with backend.digest('timeline', 0) as records:
+            assert len(set(records)) == n
