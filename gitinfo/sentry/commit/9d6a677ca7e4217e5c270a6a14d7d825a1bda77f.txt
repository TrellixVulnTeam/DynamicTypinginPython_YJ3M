commit 9d6a677ca7e4217e5c270a6a14d7d825a1bda77f
Author: Leander Rodrigues <leandergrodrigues@gmail.com>
Date:   Fri Feb 21 11:08:44 2020 -0800

    fix(async-csv): Fix deletion cascades for Files in ExportedData (#17179)
    
    Fix cascading deletions on ExportedData files when removing File objects

diff --git a/migrations_lockfile.txt b/migrations_lockfile.txt
index 475dc71b4b..ee03aebc2b 100644
--- a/migrations_lockfile.txt
+++ b/migrations_lockfile.txt
@@ -10,7 +10,7 @@ auth: 0008_alter_user_username_max_length
 contenttypes: 0002_remove_content_type_name
 jira_ac: 0001_initial
 nodestore: 0001_initial
-sentry: 0045_remove_incidentactivity_event_stats_snapshot
+sentry: 0046_auto_20200221_1735
 sessions: 0001_initial
 sites: 0002_alter_domain_unique
 social_auth: 0001_initial
diff --git a/src/sentry/migrations/0046_auto_20200221_1735.py b/src/sentry/migrations/0046_auto_20200221_1735.py
new file mode 100644
index 0000000000..694ee8312f
--- /dev/null
+++ b/src/sentry/migrations/0046_auto_20200221_1735.py
@@ -0,0 +1,45 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.11.28 on 2020-02-21 17:35
+from __future__ import unicode_literals
+
+from django.conf import settings
+from django.db import migrations
+import django.db.models.deletion
+import sentry.db.models.fields.foreignkey
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = False
+
+    # This flag is used to decide whether to run this migration in a transaction or not.
+    # By default we prefer to run in a transaction, but for migrations where you want
+    # to `CREATE INDEX CONCURRENTLY` this needs to be set to False. Typically you'll
+    # want to create an index concurrently when adding one to an existing table.
+    atomic = True
+
+
+    dependencies = [
+        ('sentry', '0045_remove_incidentactivity_event_stats_snapshot'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='exporteddata',
+            name='file',
+            field=sentry.db.models.fields.foreignkey.FlexibleForeignKey(db_constraint=False, null=True, on_delete=django.db.models.deletion.SET_NULL, to='sentry.File'),
+        ),
+        migrations.AlterField(
+            model_name='exporteddata',
+            name='user',
+            field=sentry.db.models.fields.foreignkey.FlexibleForeignKey(null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL),
+        ),
+    ]
diff --git a/src/sentry/models/exporteddata.py b/src/sentry/models/exporteddata.py
index 264acb49eb..23722e87f5 100644
--- a/src/sentry/models/exporteddata.py
+++ b/src/sentry/models/exporteddata.py
@@ -35,8 +35,10 @@ class ExportedData(Model):
     __core__ = False
 
     organization = FlexibleForeignKey("sentry.Organization")
-    user = FlexibleForeignKey(settings.AUTH_USER_MODEL)
-    file = FlexibleForeignKey("sentry.File", null=True, db_constraint=False)
+    user = FlexibleForeignKey(settings.AUTH_USER_MODEL, null=True, on_delete=models.SET_NULL)
+    file = FlexibleForeignKey(
+        "sentry.File", null=True, db_constraint=False, on_delete=models.SET_NULL
+    )
     date_added = models.DateTimeField(default=timezone.now)
     date_finished = models.DateTimeField(null=True)
     date_expired = models.DateTimeField(null=True, db_index=True)
diff --git a/src/sentry/runner/commands/cleanup.py b/src/sentry/runner/commands/cleanup.py
index 6934ca4049..6d90ec2022 100644
--- a/src/sentry/runner/commands/cleanup.py
+++ b/src/sentry/runner/commands/cleanup.py
@@ -235,7 +235,7 @@ def cleanup(days, project, concurrency, silent, model, router, timed):
     else:
         queryset = models.ExportedData.objects.filter(date_expired__lt=(timezone.now()))
         for item in queryset:
-            item.file.delete()
+            item.delete_file()
 
     project_id = None
     if project:
diff --git a/tests/sentry/models/test_exporteddata.py b/tests/sentry/models/test_exporteddata.py
index cfef3a0fe4..31164a2b00 100644
--- a/tests/sentry/models/test_exporteddata.py
+++ b/tests/sentry/models/test_exporteddata.py
@@ -4,6 +4,7 @@ import tempfile
 from datetime import timedelta
 
 from sentry.models import ExportedData, File
+from sentry.models.exporteddata import DEFAULT_EXPIRATION
 from sentry.testutils import TestCase
 
 
@@ -33,6 +34,9 @@ class DeleteExportedDataTest(TestCase):
         assert isinstance(self.data_export.file, File)
         self.data_export.delete_file()
         assert not File.objects.filter(id=self.file1.id).exists()
+        # The ExportedData should be unaffected
+        assert ExportedData.objects.filter(id=self.data_export.id).exists()
+        assert ExportedData.objects.get(id=self.data_export.id).file is None
 
     def test_delete(self):
         self.data_export.finalize_upload(file=self.file1)
@@ -44,7 +48,6 @@ class DeleteExportedDataTest(TestCase):
 
     def test_finalize_upload(self):
         TEST_STRING = "A bunch of test data..."
-        DEFAULT_EXPIRATION = timedelta(weeks=4)  # Matches src/sentry/models/exporteddata.py
         # With default expiration
         with tempfile.TemporaryFile() as tf:
             tf.write(TEST_STRING)
