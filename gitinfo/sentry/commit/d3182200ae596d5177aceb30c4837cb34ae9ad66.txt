commit d3182200ae596d5177aceb30c4837cb34ae9ad66
Author: Dan Fuller <dfuller@sentry.io>
Date:   Wed May 20 17:01:08 2020 -0700

    feat(alert_rules): Allow dataset to be passed to alert rule create/update endpoints (#18953)
    
    This allows us to specify dataset when creating or updating an alert rule. Since dataset is part of
    the primary key we use when talking to snuba, we also need to make sure that the old dataset is
    passed along to the update task when we update in snuba so that we can correctly identify it.

diff --git a/src/sentry/incidents/endpoints/serializers.py b/src/sentry/incidents/endpoints/serializers.py
index faddeca498..f040285c57 100644
--- a/src/sentry/incidents/endpoints/serializers.py
+++ b/src/sentry/incidents/endpoints/serializers.py
@@ -280,6 +280,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
     projects = serializers.ListField(child=ProjectField(), required=False)
     excluded_projects = serializers.ListField(child=ProjectField(), required=False)
     triggers = serializers.ListField(required=True)
+    dataset = serializers.CharField(required=False)
     query = serializers.CharField(required=True, allow_blank=True)
     time_window = serializers.IntegerField(
         required=True, min_value=1, max_value=int(timedelta(days=1).total_seconds() / 60)
@@ -292,6 +293,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
         model = AlertRule
         fields = [
             "name",
+            "dataset",
             "query",
             "time_window",
             "environment",
@@ -317,11 +319,20 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
                 % [item.value for item in QueryAggregations]
             )
 
+    def validate_dataset(self, dataset):
+        try:
+            return QueryDatasets(dataset)
+        except ValueError:
+            raise serializers.ValidationError(
+                "Invalid dataset, valid values are %s" % [item.value for item in QueryDatasets]
+            )
+
     def validate(self, data):
         """Performs validation on an alert rule's data
         This includes ensuring there is either 1 or 2 triggers, which each have actions, and have proper thresholds set.
         The critical trigger should both alert and resolve 'after' the warning trigger (whether that means > or < the value depends on threshold type).
         """
+        data.setdefault("dataset", QueryDatasets.EVENTS)
         if "aggregate" in data and "aggregation" in data:
             # `aggregate` takes precedence over `aggregation`, so just drop `aggregation`
             # if both are present.
@@ -337,8 +348,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
                 project_id = list(self.context["organization"].project_set.all()[:1])
             try:
                 snuba_filter = build_snuba_filter(
-                    # TODO: Stop hardcoding this once we support multiple datasets
-                    QueryDatasets.EVENTS,
+                    data["dataset"],
                     data["query"],
                     data["aggregate"],
                     data.get("environment"),
@@ -366,7 +376,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
                         conditions=snuba_filter.conditions,
                         filter_keys=snuba_filter.filter_keys,
                         having=snuba_filter.having,
-                        dataset=Dataset.Events,
+                        dataset=Dataset(data["dataset"].value),
                         limit=1,
                         referrer="alertruleserializer.test_query",
                     )
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index f4fa42ece8..7d83b77125 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -479,6 +479,7 @@ def create_alert_rule(
     environment=None,
     include_all_projects=False,
     excluded_projects=None,
+    dataset=QueryDatasets.EVENTS,
 ):
     """
     Creates an alert rule for an organization.
@@ -498,10 +499,10 @@ def create_alert_rule(
     from this organization
     :param excluded_projects: List of projects to exclude if we're using
     `include_all_projects`.
+    :param dataset: The dataset that this query will be executed on
 
     :return: The created `AlertRule`
     """
-    dataset = QueryDatasets.EVENTS
     resolution = DEFAULT_ALERT_RULE_RESOLUTION
     validate_alert_rule_query(query)
     if AlertRule.objects.filter(organization=organization, name=name).exists():
@@ -574,6 +575,7 @@ def snapshot_alert_rule(alert_rule):
 
 def update_alert_rule(
     alert_rule,
+    dataset=None,
     projects=None,
     name=None,
     query=None,
@@ -626,6 +628,8 @@ def update_alert_rule(
         updated_fields["threshold_period"] = threshold_period
     if include_all_projects is not None:
         updated_fields["include_all_projects"] = include_all_projects
+    if dataset is not None and dataset.value != alert_rule.snuba_query.dataset:
+        updated_query_fields["dataset"] = dataset
 
     with transaction.atomic():
         incidents = Incident.objects.filter(alert_rule=alert_rule).exists()
@@ -635,6 +639,7 @@ def update_alert_rule(
 
         if updated_query_fields or environment != alert_rule.snuba_query.environment:
             snuba_query = alert_rule.snuba_query
+            updated_query_fields.setdefault("dataset", QueryDatasets(snuba_query.dataset))
             updated_query_fields.setdefault("query", snuba_query.query)
             # XXX: We use the alert rule aggregation here since currently we're
             # expecting the enum value to be passed.
diff --git a/src/sentry/snuba/models.py b/src/sentry/snuba/models.py
index a27e8f6fdf..9db30fab70 100644
--- a/src/sentry/snuba/models.py
+++ b/src/sentry/snuba/models.py
@@ -23,6 +23,7 @@ query_aggregation_to_snuba = {
 
 class QueryDatasets(Enum):
     EVENTS = "events"
+    TRANSACTIONS = "transactions"
 
 
 class SnubaQuery(Model):
diff --git a/src/sentry/snuba/subscriptions.py b/src/sentry/snuba/subscriptions.py
index 03fb57fa21..390b26efc3 100644
--- a/src/sentry/snuba/subscriptions.py
+++ b/src/sentry/snuba/subscriptions.py
@@ -4,7 +4,7 @@ import logging
 
 from django.db import transaction
 
-from sentry.snuba.models import QueryAggregations, QuerySubscription, SnubaQuery
+from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription, SnubaQuery
 from sentry.snuba.tasks import (
     create_subscription_in_snuba,
     delete_subscription_from_snuba,
@@ -45,7 +45,9 @@ def create_snuba_query(dataset, query, aggregate, time_window, resolution, envir
     )
 
 
-def update_snuba_query(snuba_query, query, aggregate, time_window, resolution, environment):
+def update_snuba_query(
+    snuba_query, dataset, query, aggregate, time_window, resolution, environment
+):
     """
     Updates a SnubaQuery. Triggers updates to any related QuerySubscriptions.
 
@@ -59,16 +61,18 @@ def update_snuba_query(snuba_query, query, aggregate, time_window, resolution, e
     :param environment: An optional environment to filter by
     :return: A list of QuerySubscriptions
     """
+    old_dataset = QueryDatasets(snuba_query.dataset)
     with transaction.atomic():
         query_subscriptions = list(snuba_query.subscriptions.all())
         snuba_query.update(
+            dataset=dataset.value,
             query=query,
             aggregate=aggregate,
             time_window=int(time_window.total_seconds()),
             resolution=int(resolution.total_seconds()),
             environment=environment,
         )
-        bulk_update_snuba_subscriptions(query_subscriptions, snuba_query)
+        bulk_update_snuba_subscriptions(query_subscriptions, old_dataset)
 
 
 def bulk_create_snuba_subscriptions(projects, subscription_type, snuba_query):
@@ -111,7 +115,7 @@ def create_snuba_subscription(project, subscription_type, snuba_query):
     return subscription
 
 
-def bulk_update_snuba_subscriptions(subscriptions, snuba_query):
+def bulk_update_snuba_subscriptions(subscriptions, old_dataset):
     """
     Updates a list of query subscriptions.
 
@@ -122,26 +126,26 @@ def bulk_update_snuba_subscriptions(subscriptions, snuba_query):
     updated_subscriptions = []
     # TODO: Batch this up properly once we care about multi-project rules.
     for subscription in subscriptions:
-        updated_subscriptions.append(update_snuba_subscription(subscription, snuba_query))
+        updated_subscriptions.append(update_snuba_subscription(subscription, old_dataset))
     return subscriptions
 
 
-def update_snuba_subscription(subscription, snuba_query):
+def update_snuba_subscription(subscription, old_dataset):
     """
     Updates a subscription to a snuba query.
 
     :param query: An event search query that we can parse and convert into a
     set of Snuba conditions
-    :param snuba_query: A `SnubaQuery` instance to subscribe the project to.
-    :param aggregation: An aggregation to calculate over the time window. This will be
-    removed soon, once we're relying entirely on `snuba_query`.
+    :param old_dataset: The `QueryDataset` that this subscription was associated with
+    before the update.
     :return: The QuerySubscription representing the subscription
     """
     with transaction.atomic():
         subscription.update(status=QuerySubscription.Status.UPDATING.value)
 
         update_subscription_in_snuba.apply_async(
-            kwargs={"query_subscription_id": subscription.id}, countdown=5
+            kwargs={"query_subscription_id": subscription.id, "old_dataset": old_dataset.value},
+            countdown=5,
         )
 
     return subscription
diff --git a/src/sentry/snuba/tasks.py b/src/sentry/snuba/tasks.py
index 9f6a0122b0..323ac3e1d1 100644
--- a/src/sentry/snuba/tasks.py
+++ b/src/sentry/snuba/tasks.py
@@ -57,7 +57,7 @@ def create_subscription_in_snuba(query_subscription_id, **kwargs):
     default_retry_delay=5,
     max_retries=5,
 )
-def update_subscription_in_snuba(query_subscription_id, **kwargs):
+def update_subscription_in_snuba(query_subscription_id, old_dataset=None, **kwargs):
     """
     Task to update a corresponding subscription in Snuba from a `QuerySubscription` in
     Sentry. Updating in Snuba means deleting the existing subscription, then creating a
@@ -74,9 +74,8 @@ def update_subscription_in_snuba(query_subscription_id, **kwargs):
         return
 
     if subscription.subscription_id is not None:
-        _delete_from_snuba(
-            QueryDatasets(subscription.snuba_query.dataset), subscription.subscription_id
-        )
+        dataset = old_dataset if old_dataset is not None else subscription.snuba_query.dataset
+        _delete_from_snuba(QueryDatasets(dataset), subscription.subscription_id)
 
     subscription_id = _create_in_snuba(subscription)
     subscription.update(
diff --git a/tests/sentry/incidents/endpoints/test_serializers.py b/tests/sentry/incidents/endpoints/test_serializers.py
index 760cfd3c5e..8c7c6c124c 100644
--- a/tests/sentry/incidents/endpoints/test_serializers.py
+++ b/tests/sentry/incidents/endpoints/test_serializers.py
@@ -16,7 +16,7 @@ from sentry.incidents.endpoints.serializers import (
 from sentry.incidents.logic import create_alert_rule_trigger
 from sentry.incidents.models import AlertRule, AlertRuleThresholdType, AlertRuleTriggerAction
 from sentry.models import Integration, Environment
-from sentry.snuba.models import QueryAggregations
+from sentry.snuba.models import QueryAggregations, QueryDatasets
 from sentry.testutils import TestCase
 
 
@@ -26,6 +26,7 @@ class TestAlertRuleSerializer(TestCase):
         return {
             "name": "hello",
             "time_window": 10,
+            "dataset": QueryDatasets.EVENTS.value,
             "query": "level:error",
             "threshold_type": 0,
             "resolve_threshold": 1,
@@ -111,6 +112,12 @@ class TestAlertRuleSerializer(TestCase):
             {"timeWindow": 0}, {"timeWindow": ["Ensure this value is greater than or equal to 1."]}
         )
 
+    def test_dataset(self):
+        invalid_values = [
+            "Invalid dataset, valid values are %s" % [item.value for item in QueryDatasets]
+        ]
+        self.run_fail_validation_test({"dataset": "events_wrong"}, {"dataset": invalid_values})
+
     def test_aggregation(self):
         invalid_values = [
             "Invalid aggregation, valid values are %s" % [item.value for item in QueryAggregations]
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index 52a29ef4fc..c5e7e73a1d 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -715,7 +715,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
             10,
             1,
         )
-        update_alert_rule(alert_rule, [self.project])
+        update_alert_rule(alert_rule, projects=[self.project])
         assert self.alert_rule.snuba_query.subscriptions.get().project == self.project
 
     def test_new_updated_deleted_projects(self):
@@ -732,7 +732,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
         new_project = self.create_project(fire_project_created=True)
         updated_projects = [self.project, new_project]
         with self.tasks():
-            update_alert_rule(alert_rule, updated_projects, query=query_update)
+            update_alert_rule(alert_rule, projects=updated_projects, query=query_update)
         updated_subscriptions = alert_rule.snuba_query.subscriptions.all()
         assert set([sub.project for sub in updated_subscriptions]) == set(updated_projects)
         for sub in updated_subscriptions:
diff --git a/tests/sentry/snuba/test_subscriptions.py b/tests/sentry/snuba/test_subscriptions.py
index 1311ffd316..1f7aa0ae8b 100644
--- a/tests/sentry/snuba/test_subscriptions.py
+++ b/tests/sentry/snuba/test_subscriptions.py
@@ -100,20 +100,20 @@ class CreateSnubaSubscriptionTest(TestCase):
 
 class UpdateSnubaQueryTest(TestCase):
     def test(self):
-        dataset = QueryDatasets.EVENTS
         snuba_query = create_snuba_query(
-            dataset,
+            QueryDatasets.EVENTS,
             "hello",
             "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
             timedelta(minutes=2),
             self.environment,
         )
+        dataset = QueryDatasets.TRANSACTIONS
         query = "level:error"
         aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, None)
+        update_snuba_query(snuba_query, dataset, query, aggregate, time_window, resolution, None)
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
         assert snuba_query.aggregate == aggregate
@@ -122,9 +122,8 @@ class UpdateSnubaQueryTest(TestCase):
         assert snuba_query.environment is None
 
     def test_environment(self):
-        dataset = QueryDatasets.EVENTS
         snuba_query = create_snuba_query(
-            dataset,
+            QueryDatasets.EVENTS,
             "hello",
             "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
@@ -133,11 +132,12 @@ class UpdateSnubaQueryTest(TestCase):
         )
 
         new_env = self.create_environment()
+        dataset = QueryDatasets.TRANSACTIONS
         query = "level:error"
         aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, new_env)
+        update_snuba_query(snuba_query, dataset, query, aggregate, time_window, resolution, new_env)
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
         assert snuba_query.aggregate == aggregate
@@ -146,9 +146,8 @@ class UpdateSnubaQueryTest(TestCase):
         assert snuba_query.environment == new_env
 
     def test_subscriptions(self):
-        dataset = QueryDatasets.EVENTS
         snuba_query = create_snuba_query(
-            dataset,
+            QueryDatasets.EVENTS,
             "hello",
             "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
@@ -158,11 +157,12 @@ class UpdateSnubaQueryTest(TestCase):
         sub = create_snuba_subscription(self.project, "hi", snuba_query)
 
         new_env = self.create_environment()
+        dataset = QueryDatasets.TRANSACTIONS
         query = "level:error"
         aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, new_env)
+        update_snuba_query(snuba_query, dataset, query, aggregate, time_window, resolution, new_env)
         sub.refresh_from_db()
         assert sub.snuba_query == snuba_query
         assert sub.status == QuerySubscription.Status.UPDATING.value
@@ -170,9 +170,10 @@ class UpdateSnubaQueryTest(TestCase):
 
 class UpdateSnubaSubscriptionTest(TestCase):
     def test(self):
+        old_dataset = QueryDatasets.EVENTS
         with self.tasks():
             snuba_query = create_snuba_query(
-                QueryDatasets.EVENTS,
+                old_dataset,
                 "level:error",
                 "count()",
                 timedelta(minutes=10),
@@ -181,6 +182,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             )
             subscription = create_snuba_subscription(self.project, "something", snuba_query)
 
+        dataset = QueryDatasets.TRANSACTIONS
         query = "level:warning"
         aggregate = "count_unique(tags[sentry:user])"
         time_window = timedelta(minutes=20)
@@ -188,6 +190,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
         subscription = QuerySubscription.objects.get(id=subscription.id)
         subscription_id = subscription.subscription_id
         snuba_query.update(
+            dataset=dataset.value,
             query=query,
             time_window=int(time_window.total_seconds()),
             resolution=int(resolution.total_seconds()),
@@ -195,9 +198,10 @@ class UpdateSnubaSubscriptionTest(TestCase):
             aggregate=aggregate,
         )
         assert subscription_id is not None
-        update_snuba_subscription(subscription, snuba_query)
+        update_snuba_subscription(subscription, old_dataset)
         assert subscription.status == QuerySubscription.Status.UPDATING.value
         assert subscription.subscription_id == subscription_id
+        assert subscription.snuba_query.dataset == dataset.value
         assert subscription.snuba_query.query == query
         assert subscription.snuba_query.aggregate == aggregate
         assert subscription.snuba_query.time_window == int(time_window.total_seconds())
@@ -205,8 +209,9 @@ class UpdateSnubaSubscriptionTest(TestCase):
 
     def test_with_task(self):
         with self.tasks():
+            old_dataset = QueryDatasets.EVENTS
             snuba_query = create_snuba_query(
-                QueryDatasets.EVENTS,
+                old_dataset,
                 "level:error",
                 "count()",
                 timedelta(minutes=10),
@@ -215,6 +220,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             )
             subscription = create_snuba_subscription(self.project, "something", snuba_query)
 
+            dataset = QueryDatasets.TRANSACTIONS
             query = "level:warning"
             aggregate = "count_unique(tags[sentry:user])"
             time_window = timedelta(minutes=20)
@@ -223,13 +229,14 @@ class UpdateSnubaSubscriptionTest(TestCase):
             subscription_id = subscription.subscription_id
             assert subscription_id is not None
             snuba_query.update(
+                dataset=dataset.value,
                 query=query,
                 time_window=int(time_window.total_seconds()),
                 resolution=int(resolution.total_seconds()),
                 environment=self.environment,
                 aggregate=aggregate,
             )
-            update_snuba_subscription(subscription, snuba_query)
+            update_snuba_subscription(subscription, old_dataset)
             subscription = QuerySubscription.objects.get(id=subscription.id)
             assert subscription.status == QuerySubscription.Status.ACTIVE.value
             assert subscription.subscription_id is not None
