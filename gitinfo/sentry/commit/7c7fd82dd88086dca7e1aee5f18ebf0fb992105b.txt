commit 7c7fd82dd88086dca7e1aee5f18ebf0fb992105b
Author: Jan Michael Auer <jan.auer@sentry.io>
Date:   Thu Feb 27 17:50:40 2020 +0100

    feat(outcomes): Add data category and quantity (#17312)

diff --git a/src/sentry/constants.py b/src/sentry/constants.py
index 29526d56ab..91acf424eb 100644
--- a/src/sentry/constants.py
+++ b/src/sentry/constants.py
@@ -8,6 +8,7 @@ import logging
 import os.path
 import six
 from datetime import timedelta
+from enum import IntEnum, unique
 
 from collections import OrderedDict, namedtuple
 from django.conf import settings
@@ -484,3 +485,27 @@ DEFAULT_STORE_NORMALIZER_ARGS = dict(
 INTERNAL_INTEGRATION_TOKEN_COUNT_MAX = 20
 
 ALL_ACCESS_PROJECTS = {-1}
+
+
+@unique
+class DataCategory(IntEnum):
+    DEFAULT = 0
+    ERROR = 1
+    TRANSACTION = 2
+    SECURITY = 3
+    ATTACHMENT = 4
+    SESSION = 5
+    CRASH = 6
+
+    @classmethod
+    def from_event_type(cls, event_type):
+        if event_type == "error":
+            return DataCategory.ERROR
+        elif event_type == "transaction":
+            return DataCategory.TRANSACTION
+        elif event_type in ("csp", "hpkp", "expectct", "expectstaple"):
+            return DataCategory.SECURITY
+        return DataCategory.DEFAULT
+
+    def api_name(self):
+        return self.name.lower()
diff --git a/src/sentry/quotas/base.py b/src/sentry/quotas/base.py
index 296e524f24..b7dcfb2e4d 100644
--- a/src/sentry/quotas/base.py
+++ b/src/sentry/quotas/base.py
@@ -21,20 +21,6 @@ class QuotaScope(IntEnum):
         return self.name.lower()
 
 
-@unique
-class DataCategory(IntEnum):
-    DEFAULT = 0
-    ERROR = 1
-    TRANSACTION = 2
-    SECURITY = 3
-    ATTACHMENT = 4
-    SESSION = 5
-    CRASH = 6
-
-    def api_name(self):
-        return self.name.lower()
-
-
 class QuotaConfig(object):
     """
     Abstract configuration for a quota.
diff --git a/src/sentry/quotas/redis.py b/src/sentry/quotas/redis.py
index 635f302347..e3b2b356ed 100644
--- a/src/sentry/quotas/redis.py
+++ b/src/sentry/quotas/redis.py
@@ -5,14 +5,8 @@ import six
 
 from time import time
 
-from sentry.quotas.base import (
-    DataCategory,
-    NotRateLimited,
-    Quota,
-    QuotaConfig,
-    QuotaScope,
-    RateLimited,
-)
+from sentry.constants import DataCategory
+from sentry.quotas.base import NotRateLimited, Quota, QuotaConfig, QuotaScope, RateLimited
 from sentry.utils.redis import (
     get_dynamic_cluster_from_options,
     validate_dynamic_cluster,
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index b1e37fb967..fdf5d972d4 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -11,6 +11,7 @@ from django.conf import settings
 from sentry_relay.processing import StoreNormalizer
 
 from sentry import features, reprocessing
+from sentry.constants import DataCategory
 from sentry.relay.config import get_project_config
 from sentry.datascrubbing import scrub_data
 from sentry.constants import DEFAULT_STORE_NORMALIZER_ARGS
@@ -488,6 +489,8 @@ def _do_save_event(
             if data is not None:
                 metric_tags["event_type"] = event_type = data.get("type") or "none"
 
+    data_category = DataCategory.from_event_type(event_type)
+
     with metrics.global_tags(event_type=event_type):
         if data is not None:
             data = CanonicalKeyDict(data)
@@ -548,6 +551,7 @@ def _do_save_event(
                     None,
                     timestamp,
                     event_id,
+                    data_category,
                 )
 
         except HashDiscarded:
@@ -575,6 +579,7 @@ def _do_save_event(
                 reason,
                 timestamp,
                 event_id,
+                data_category,
             )
 
         finally:
diff --git a/src/sentry/utils/outcomes.py b/src/sentry/utils/outcomes.py
index e1ce53cc68..eccde39761 100644
--- a/src/sentry/utils/outcomes.py
+++ b/src/sentry/utils/outcomes.py
@@ -10,6 +10,7 @@ import six
 import time
 
 from sentry import tsdb, options
+from sentry.constants import DataCategory
 from sentry.utils import json, metrics
 from sentry.utils.data_filters import FILTER_STAT_KEYS_TO_VALUES
 from sentry.utils.dates import to_datetime
@@ -97,7 +98,17 @@ def tsdb_increments_from_outcome(org_id, project_id, key_id, outcome, reason):
             yield (FILTER_STAT_KEYS_TO_VALUES[reason], project_id)
 
 
-def track_outcome(org_id, project_id, key_id, outcome, reason=None, timestamp=None, event_id=None):
+def track_outcome(
+    org_id,
+    project_id,
+    key_id,
+    outcome,
+    reason=None,
+    timestamp=None,
+    event_id=None,
+    category=None,
+    quantity=None,
+):
     """
     This is a central point to track org/project counters per incoming event.
     NB: This should only ever be called once per incoming event, which means
@@ -112,11 +123,16 @@ def track_outcome(org_id, project_id, key_id, outcome, reason=None, timestamp=No
     if outcomes_publisher is None:
         outcomes_publisher = KafkaPublisher(settings.KAFKA_CLUSTERS[outcomes["cluster"]])
 
+    if quantity is None:
+        quantity = 1
+
     assert isinstance(org_id, six.integer_types)
     assert isinstance(project_id, six.integer_types)
     assert isinstance(key_id, (type(None), six.integer_types))
     assert isinstance(outcome, Outcome)
     assert isinstance(timestamp, (type(None), datetime))
+    assert isinstance(category, (type(None), DataCategory))
+    assert isinstance(quantity, int)
 
     timestamp = timestamp or to_datetime(time.time())
 
@@ -147,6 +163,8 @@ def track_outcome(org_id, project_id, key_id, outcome, reason=None, timestamp=No
                 "outcome": outcome.value,
                 "reason": reason,
                 "event_id": event_id,
+                "category": category,
+                "quantity": quantity,
             }
         ),
     )
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 3e240e33b4..db47b1e618 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -31,7 +31,7 @@ from sentry_relay import ProcessingErrorInvalidTransaction
 
 from sentry import features, options, quotas
 from sentry.attachments import CachedAttachment
-from sentry.constants import ObjectStatus
+from sentry.constants import DataCategory, ObjectStatus
 from sentry.coreapi import (
     Auth,
     APIError,
@@ -200,6 +200,7 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
     del event_manager
 
     event_id = data["event_id"]
+    data_category = DataCategory.from_event_type(data.get("type"))
 
     if should_filter:
         signals_in_consumer = decide_signals_in_consumer()
@@ -217,6 +218,7 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             Outcome.FILTERED,
             filter_reason,
             event_id=event_id,
+            category=data_category,
         )
         metrics.incr("events.blacklisted", tags={"reason": filter_reason}, skip_internal=False)
 
@@ -260,6 +262,7 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             Outcome.RATE_LIMITED,
             reason,
             event_id=event_id,
+            category=data_category,
         )
         metrics.incr("events.dropped", tags={"reason": reason or "unknown"}, skip_internal=False)
         if not signals_in_consumer:
@@ -282,6 +285,7 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             Outcome.INVALID,
             "duplicate",
             event_id=event_id,
+            category=data_category,
         )
         raise APIForbidden("An event with the same ID already exists (%s)" % (event_id,))
 
@@ -626,7 +630,12 @@ class StoreView(APIView):
             event_manager.normalize()
         except ProcessingErrorInvalidTransaction as e:
             track_outcome(
-                organization_id, project_id, key.id, Outcome.INVALID, "invalid_transaction"
+                organization_id,
+                project_id,
+                key.id,
+                Outcome.INVALID,
+                "invalid_transaction",
+                category=DataCategory.TRANSACTION,
             )
             raise APIError(six.text_type(e).split("\n", 1)[0])
 
@@ -643,6 +652,7 @@ class StoreView(APIView):
                 Outcome.INVALID,
                 "too_large",
                 event_id=dict_data.get("event_id"),
+                category=DataCategory.from_event_type(dict_data.get("type")),
             )
             raise APIForbidden("Event size exceeded 10MB after normalization.")
 
@@ -750,6 +760,9 @@ class MinidumpView(StoreView):
         request_files = request.FILES or {}
         content_type = request.META.get("CONTENT_TYPE")
 
+        # Track these submissions statically as ERROR. Relay infers properly.
+        data_category = DataCategory.ERROR
+
         if content_type in self.dump_types:
             minidump = io.BytesIO(request.body)
             minidump_name = "Minidump"
@@ -790,6 +803,7 @@ class MinidumpView(StoreView):
                 None,
                 Outcome.INVALID,
                 "missing_minidump_upload",
+                category=data_category,
             )
             raise APIError("Missing minidump upload")
 
@@ -830,6 +844,7 @@ class MinidumpView(StoreView):
                     None,
                     Outcome.INVALID,
                     "missing_minidump_upload",
+                    category=data_category,
                 )
                 raise APIError("Missing minidump upload")
 
@@ -841,6 +856,7 @@ class MinidumpView(StoreView):
                 None,
                 Outcome.INVALID,
                 "invalid_minidump",
+                category=data_category,
             )
             raise APIError("Uploaded file was not a minidump")
 
@@ -965,6 +981,9 @@ class UnrealView(StoreView):
         )
 
     def post(self, request, project, project_config, **kwargs):
+        # Track these submissions statically as ERROR. Relay infers properly.
+        data_category = DataCategory.ERROR
+
         attachments_enabled = features.has(
             "organizations:event-attachments", project.organization, actor=request.user
         )
@@ -986,6 +1005,7 @@ class UnrealView(StoreView):
                 None,
                 Outcome.INVALID,
                 "process_unreal",
+                category=data_category,
             )
             raise APIError(six.text_type(e).split("\n", 1)[0])
 
@@ -1122,6 +1142,9 @@ class SecurityReportView(StoreView):
         )
 
     def post(self, request, project, helper, key, project_config, **kwargs):
+        # This endpoint only accepts security reports.
+        data_category = DataCategory.SECURITY
+
         json_body = safely_load_json_string(request.body)
         report_type = self.security_report_type(json_body)
         if report_type is None:
@@ -1131,6 +1154,7 @@ class SecurityReportView(StoreView):
                 key.id,
                 Outcome.INVALID,
                 "security_report_type",
+                category=data_category,
             )
             raise APIError("Unrecognized security report type")
         interface = get_interface(report_type)
@@ -1144,6 +1168,7 @@ class SecurityReportView(StoreView):
                 key.id,
                 Outcome.INVALID,
                 "security_report",
+                category=data_category,
             )
             raise APIError("Invalid security report: %s" % str(e).splitlines()[0])
 
@@ -1156,6 +1181,7 @@ class SecurityReportView(StoreView):
                 key.id,
                 Outcome.INVALID,
                 FilterStatKeys.CORS,
+                category=data_category,
             )
             raise APIForbidden("Invalid origin")
 
diff --git a/tests/sentry/quotas/test_base.py b/tests/sentry/quotas/test_base.py
index 686d988644..e792a09711 100644
--- a/tests/sentry/quotas/test_base.py
+++ b/tests/sentry/quotas/test_base.py
@@ -2,8 +2,9 @@
 
 from __future__ import absolute_import
 
+from sentry.constants import DataCategory
 from sentry.models import OrganizationOption, ProjectKey
-from sentry.quotas.base import Quota, QuotaConfig, QuotaScope, DataCategory
+from sentry.quotas.base import Quota, QuotaConfig, QuotaScope
 from sentry.testutils import TestCase
 
 import pytest
