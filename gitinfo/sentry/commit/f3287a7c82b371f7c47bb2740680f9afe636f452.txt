commit f3287a7c82b371f7c47bb2740680f9afe636f452
Author: Chris Fuller <cfuller@sentry.io>
Date:   Wed Mar 4 09:18:43 2020 -0500

    fix(workflow): Incident details page graph incorrectly showing 0 results (#17416)
    
    * Including prewindow in TimeSeries start date

diff --git a/src/sentry/api/serializers/models/incident.py b/src/sentry/api/serializers/models/incident.py
index b539420201..775d0dc807 100644
--- a/src/sentry/api/serializers/models/incident.py
+++ b/src/sentry/api/serializers/models/incident.py
@@ -28,7 +28,7 @@ class IncidentSerializer(Serializer):
             incident_projects[incident_project.incident_id].append(incident_project.project.slug)
 
         results = {}
-        for incident, stats in zip(item_list, bulk_get_incident_stats(item_list)):
+        for incident, stats in zip(item_list, bulk_get_incident_stats(item_list, prewindow=True)):
             results[incident] = {
                 "projects": incident_projects.get(incident.id, []),
                 "event_stats": stats["event_stats"],
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index d47f1e44e9..ac97469de3 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -238,14 +238,15 @@ def delete_comment(activity):
     return activity.delete()
 
 
-def create_incident_snapshot(incident):
+def create_incident_snapshot(incident, prewindow=True):
     """
     Creates a snapshot of an incident. This includes the count of unique users
     and total events, plus a time series snapshot of the entire incident.
     """
     assert incident.status == IncidentStatus.CLOSED.value
+
     event_stats_snapshot = create_event_stat_snapshot(
-        incident, incident.date_started, incident.date_closed
+        incident, incident.date_started, incident.date_closed, prewindow
     )
     aggregates = get_incident_aggregates(incident)
     return IncidentSnapshot.objects.create(
@@ -256,10 +257,13 @@ def create_incident_snapshot(incident):
     )
 
 
-def create_event_stat_snapshot(incident, start, end):
+def create_event_stat_snapshot(incident, start, end, prewindow):
     """
     Creates an event stats snapshot for an incident in a given period of time.
     """
+    if prewindow:
+        start = start - calculate_incident_prewindow(start, end, incident)
+
     event_stats = get_incident_event_stats(incident, start, end)
     return TimeSeriesSnapshot.objects.create(
         start=start,
@@ -321,18 +325,18 @@ def calculate_incident_prewindow(start, end, incident=None):
     # Make the a bit earlier to show more relevant data from before the incident started:
     prewindow = (end - start) / 5
     if incident and incident.alert_rule is not None:
-        alert_rule_time_window = incident.alert_rule.time_window
+        alert_rule_time_window = timedelta(minutes=incident.alert_rule.time_window)
         prewindow = max(alert_rule_time_window, prewindow)
     return prewindow
 
 
-def get_incident_event_stats(incident, start=None, end=None, data_points=50):
+def get_incident_event_stats(incident, start=None, end=None, data_points=50, prewindow=False):
     """
     Gets event stats for an incident. If start/end are provided, uses that time
     period, otherwise uses the incident start/current_end.
     """
     query_params = bulk_build_incident_query_params(
-        [incident], start=start, end=end, prewindow=True
+        [incident], start=start, end=end, prewindow=prewindow
     )
     return bulk_get_incident_event_stats([incident], query_params, data_points=data_points)[0]
 
@@ -389,10 +393,12 @@ def bulk_get_incident_aggregates(query_params_list):
     return [result["data"][0] for result in results]
 
 
-def bulk_get_incident_stats(incidents):
+def bulk_get_incident_stats(incidents, prewindow=False):
     """
     Returns bulk stats for a list of incidents. This includes unique user count,
     total event count and event stats.
+    Note that even though this function accepts a prewindow parameter, it does not
+    affect the snapshots if they were created using a prewindow. Only the live fetched stats.
     """
     closed = [i for i in incidents if i.status == IncidentStatus.CLOSED.value]
     incident_stats = {}
@@ -409,7 +415,7 @@ def bulk_get_incident_stats(incidents):
 
     to_fetch = [i for i in incidents if i.id not in incident_stats]
     if to_fetch:
-        query_params_list = bulk_build_incident_query_params(to_fetch, prewindow=True)
+        query_params_list = bulk_build_incident_query_params(to_fetch, prewindow=prewindow)
         all_event_stats = bulk_get_incident_event_stats(to_fetch, query_params_list)
         all_aggregates = bulk_get_incident_aggregates(query_params_list)
         for incident, event_stats, aggregates in zip(to_fetch, all_event_stats, all_aggregates):
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index 6d11307040..53c85f75fd 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -264,6 +264,16 @@ class GetIncidentEventStatsTest(TestCase, BaseIncidentEventStatsTest):
         assert result.rollup == 15
         expected_start = start if start else incident.date_started
         expected_end = end if end else incident.current_end_date
+        assert result.start == expected_start
+        assert result.end == expected_end
+        assert [r["count"] for r in result.data["data"]] == expected_results
+
+        # A prewindow version of the same test:
+        result = get_incident_event_stats(incident, data_points=20, prewindow=True, **kwargs)
+        # Duration of 300s / 20 data points
+        assert result.rollup == 15
+        expected_start = start if start else incident.date_started
+        expected_end = end if end else incident.current_end_date
         expected_start = expected_start - calculate_incident_prewindow(
             expected_start, expected_end, incident
         )
@@ -282,6 +292,20 @@ class GetIncidentEventStatsTest(TestCase, BaseIncidentEventStatsTest):
 
 class BulkGetIncidentEventStatsTest(TestCase, BaseIncidentEventStatsTest):
     def run_test(self, incidents, expected_results_list, start=None, end=None):
+        query_params_list = bulk_build_incident_query_params(
+            incidents, start=start, end=end, prewindow=False
+        )
+        results = bulk_get_incident_event_stats(incidents, query_params_list, data_points=20)
+        for incident, result, expected_results in zip(incidents, results, expected_results_list):
+            # Duration of 300s / 20 data points
+            assert result.rollup == 15
+            expected_start = start if start else incident.date_started
+            expected_end = end if end else incident.current_end_date
+            assert result.start == expected_start
+            assert result.end == expected_end
+            assert [r["count"] for r in result.data["data"]] == expected_results
+
+        # A prewindow version of the same test:
         query_params_list = bulk_build_incident_query_params(
             incidents, start=start, end=end, prewindow=True
         )
@@ -399,12 +423,21 @@ class CreateEventStatTest(TestCase, BaseIncidentsTest):
             date_started=self.now - timedelta(minutes=5), query="", projects=[self.project]
         )
         snapshot = create_event_stat_snapshot(
-            incident, incident.date_started, incident.current_end_date
+            incident, incident.date_started, incident.current_end_date, False
         )
         assert snapshot.start == incident.date_started
         assert snapshot.end == incident.current_end_date
         assert [row[1] for row in snapshot.values] == [2, 1]
 
+        snapshot = create_event_stat_snapshot(
+            incident, incident.date_started, incident.current_end_date, True
+        )
+        assert snapshot.start == incident.date_started - calculate_incident_prewindow(
+            incident.date_started, incident.current_end_date, incident
+        )
+        assert snapshot.end == incident.current_end_date
+        assert [row[1] for row in snapshot.values] == [2, 1]
+
 
 @freeze_time()
 class CreateIncidentActivityTest(TestCase, BaseIncidentsTest):
@@ -522,7 +555,7 @@ class CreateIncidentSnapshotTest(TestCase, BaseIncidentsTest):
         incident.update(status=IncidentStatus.CLOSED.value)
         snapshot = create_incident_snapshot(incident)
         expected_snapshot = create_event_stat_snapshot(
-            incident, incident.date_started, incident.date_closed
+            incident, incident.date_started, incident.date_closed, prewindow=True
         )
 
         assert snapshot.event_stats_snapshot.start == expected_snapshot.start
@@ -558,17 +591,14 @@ class BulkGetIncidentStatusTest(TestCase, BaseIncidentsTest):
             date_started=timezone.now() - timedelta(days=30),
         )
         incidents = [closed_incident, open_incident]
-        changed = False
-        for incident, incident_stats in zip(incidents, bulk_get_incident_stats(incidents)):
-            event_stats = get_incident_event_stats(incident)
+        # Note: Closing an incident above uses a prewindow in the snapshot by default, so without prewindows this test fails.
+        for incident, incident_stats in zip(
+            incidents, bulk_get_incident_stats(incidents, prewindow=True)
+        ):
+            event_stats = get_incident_event_stats(incident, prewindow=True)
             assert incident_stats["event_stats"].data["data"] == event_stats.data["data"]
             expected_start = incident_stats["event_stats"].start
             expected_end = incident_stats["event_stats"].end
-            if not changed:
-                expected_start = expected_start - calculate_incident_prewindow(
-                    expected_start, expected_end, incident
-                )
-                changed = True
             assert event_stats.start == expected_start
             assert event_stats.end == expected_end
             assert incident_stats["event_stats"].rollup == event_stats.rollup
