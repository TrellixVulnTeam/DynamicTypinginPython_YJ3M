commit fb2b75f400b257648e2bb0d882066cc06720062e
Author: Ted Kaemming <ted@kaemming.com>
Date:   Wed Oct 7 18:11:37 2015 -0700

    Add in memory backend, add it to the test script.

diff --git a/example.py b/example.py
index c63ddf7944..093f66d765 100644
--- a/example.py
+++ b/example.py
@@ -8,30 +8,47 @@ import random
 import pprint
 from datetime import timedelta
 
+from django.conf import settings
 from django.utils import timezone
 
 from sentry.app import tsdb
+from sentry.tsdb.redis import RedisTSDB
+from sentry.tsdb.inmemory import InMemoryTSDB
 
-keys = range(10)
 
-tsdb.record_multi([
-    (tsdb.models.users_affected_by_event, k, [random.randint(0, 1e6) for _ in xrange(random.randint(1, 50))]) for k in keys
-])
+backends = [
+    InMemoryTSDB,
+    RedisTSDB,
+]
 
-start = timezone.now() - timedelta(seconds=60)
 
-totals = tsdb.get_distinct_counts_totals(
-    tsdb.models.users_affected_by_event,
-    keys,
-    start,
-)
+for backend in backends:
+    print 'Testing %r...\n' % (backend,)
 
-pprint.pprint(totals)
+    database = backend(rollups=settings.SENTRY_TSDB_ROLLUPS)
 
-series = tsdb.get_distinct_counts_series(
-    tsdb.models.users_affected_by_event,
-    keys,
-    start,
-)
+    keys = range(10)
 
-pprint.pprint(series)
+    database.record_multi([
+        (tsdb.models.users_affected_by_event, k, [random.randint(0, 1e6) for _ in xrange(random.randint(1, 50))]) for k in keys
+    ])
+
+    start = timezone.now() - timedelta(seconds=60)
+
+    totals = database.get_distinct_counts_totals(
+        tsdb.models.users_affected_by_event,
+        keys,
+        start,
+    )
+
+    pprint.pprint(totals)
+
+    series = database.get_distinct_counts_series(
+        tsdb.models.users_affected_by_event,
+        keys,
+        start,
+    )
+
+    pprint.pprint(series)
+
+    print '\n'
diff --git a/src/sentry/tsdb/base.py b/src/sentry/tsdb/base.py
index bd6ca1f561..2039f8bc7b 100644
--- a/src/sentry/tsdb/base.py
+++ b/src/sentry/tsdb/base.py
@@ -191,19 +191,23 @@ class BaseTSDB(object):
                     last_new_ts = new_ts
         return result
 
+    def record(self, model, key, values, timestamp=None):
+        raise NotImplementedError
+
     def record_multi(self, items, timestamp=None):
         """
         Record an occurence of an item in a distinct counter.
         """
-        raise NotImplementedError
+        for model, key, values in items:
+            self.record(model, key, values, timestamp)
 
-    def get_distinct_counts_series(self, model, keys, start, end, rollup=None):
+    def get_distinct_counts_series(self, model, keys, start, end=None, rollup=None):
         """
         Fetch counts of distinct items for each rollup interval within the range.
         """
         raise NotImplementedError
 
-    def get_distinct_counts_totals(self, model, keys, start, end, rollup=None):
+    def get_distinct_counts_totals(self, model, keys, start, end=None, rollup=None):
         """
         Count distinct items during a time range.
         """
diff --git a/src/sentry/tsdb/inmemory.py b/src/sentry/tsdb/inmemory.py
index 3f1a2de2e1..5e0855f6ee 100644
--- a/src/sentry/tsdb/inmemory.py
+++ b/src/sentry/tsdb/inmemory.py
@@ -59,6 +59,44 @@ class InMemoryTSDB(BaseTSDB):
             results_by_key[key] = sorted(points.items())
         return dict(results_by_key)
 
+    def record(self, model, key, values, timestamp):
+        if timestamp is None:
+            timestamp = timezone.now()
+
+        for rollup, max_values in self.rollups:
+            r = self.normalize_to_rollup(timestamp, rollup)
+            self.sets[model][key][r].update(values)
+
+    def get_distinct_counts_series(self, model, keys, start, end=None, rollup=None):
+        rollup, intervals = self.get_optimal_rollup_intervals(start, end, rollup)
+
+        results = {}
+        for key in keys:
+            source = self.sets[model][key]
+            series = results[key] = []
+            for interval in intervals:
+                r = self.normalize_ts_to_rollup(interval, rollup)
+                series.append((interval, len(source[r])))
+
+        return results
+
+    def get_distinct_counts_totals(self, model, keys, start, end=None, rollup=None):
+        rollup, intervals = self.get_optimal_rollup_intervals(start, end, rollup)
+
+        results = {}
+        for key in keys:
+            source = self.sets[model][key]
+            values = set()
+            for interval in intervals:
+                r = self.normalize_ts_to_rollup(interval, rollup)
+                values.update(source[r])
+            results[key] = len(values)
+
+        return results
+
     def flush(self):
         # model => key => timestamp = count
         self.data = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))
+
+        # self.sets[model][key][rollup] = set of elements
+        self.sets = defaultdict(lambda: defaultdict(lambda: defaultdict(set)))
diff --git a/src/sentry/tsdb/redis.py b/src/sentry/tsdb/redis.py
index 1832f0f86f..ce941e925e 100644
--- a/src/sentry/tsdb/redis.py
+++ b/src/sentry/tsdb/redis.py
@@ -175,6 +175,9 @@ class RedisTSDB(BaseTSDB):
             results_by_key[key] = sorted(points.items())
         return dict(results_by_key)
 
+    def record(self, model, key, values, timestamp=None):
+        self.record_multi((model, key, values), timestamp)
+
     def record_multi(self, items, timestamp=None):
         """
         Record an occurence of an item in a distinct counter.
