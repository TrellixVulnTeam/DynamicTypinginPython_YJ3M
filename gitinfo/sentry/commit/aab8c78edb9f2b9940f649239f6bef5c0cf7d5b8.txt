commit aab8c78edb9f2b9940f649239f6bef5c0cf7d5b8
Author: evanh <evanh@users.noreply.github.com>
Date:   Mon Feb 24 10:04:42 2020 -0500

    feat(discover) Allow filtering on functions in discover search (#17192)
    
    Allow people to do function filtering in their discover queries. This will have
    the same rules as the current aggregate aliases in that the user has to include
    the function in their column selections.

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 3b759a29a9..a63230e1a2 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -111,7 +111,7 @@ rel_time_filter      = search_key sep rel_date_format
 # exact time filter for dates
 specific_time_filter = search_key sep date_format
 # Numeric comparison filter
-numeric_filter       = (function_key / search_key) sep operator? numeric_value
+numeric_filter       = search_key sep operator? numeric_value
 # Aggregate numeric filter
 aggregate_filter        = aggregate_key sep operator? numeric_value
 aggregate_date_filter   = aggregate_key sep operator? (date_format / rel_date_format)
@@ -121,7 +121,7 @@ has_filter           = negation? "has" sep (search_key / search_value)
 is_filter            = negation? "is" sep search_value
 tag_filter           = negation? "tags[" search_key "]" sep search_value
 
-aggregate_key        = key space? open_paren space? key space? closed_paren
+aggregate_key        = key space? open_paren space? function_arg* space? closed_paren
 function_key         = key space? open_paren space? closed_paren
 search_key           = key / quoted_key
 search_value         = quoted_value / value
@@ -129,6 +129,7 @@ value                = ~r"[^()\s]*"
 numeric_value        = ~r"[0-9]+(?=\s|$)"
 quoted_value         = ~r"\"((?:[^\"]|(?<=\\)[\"])*)?\""s
 key                  = ~r"[a-zA-Z0-9_\.-]+"
+function_arg         = space? key? comma? space?
 # only allow colons in quoted keys
 quoted_key           = ~r"\"([a-zA-Z0-9_\.:-]+)\""
 
@@ -145,6 +146,7 @@ closed_paren         = ")"
 sep                  = ":"
 space                = " "
 negation             = "!"
+comma                = ","
 spaces               = ~r"\ *"
 """
 )
@@ -368,7 +370,6 @@ class SearchVisitor(NodeVisitor):
 
     def visit_numeric_filter(self, node, children):
         (search_key, _, operator, search_value) = children
-        search_key = search_key[0] if not isinstance(search_key, Node) else search_key
         operator = operator[0] if not isinstance(operator, Node) else "="
 
         if search_key.name in self.numeric_keys:
@@ -395,7 +396,7 @@ class SearchVisitor(NodeVisitor):
 
     def visit_aggregate_date_filter(self, node, children):
         (search_key, _, operator, search_value) = children
-
+        search_value = search_value[0]
         operator = operator[0] if not isinstance(operator, Node) else "="
         is_date_aggregate = any(key in search_key.name for key in self.date_keys)
 
@@ -529,20 +530,17 @@ class SearchVisitor(NodeVisitor):
         children = self.flatten(children)
         children = self.remove_optional_nodes(children)
         children = self.remove_space(children)
+        (function_name, open_paren, args, close_paren) = children
+        if isinstance(args, Node):
+            args = ""
+        elif isinstance(args, list):
+            args = "".join(args)
 
-        key = "".join(children)
+        key = "".join([function_name, open_paren, args, close_paren])
         return AggregateKey(self.key_mappings_lookup.get(key, key))
 
-    def visit_function_key(self, node, children):
-        children = self.flatten(children)
-        children = self.remove_optional_nodes(children)
-        children = self.remove_space(children)
-
-        key = "".join(children)
-        if key.strip("()") in FIELD_ALIASES:
-            key = key.strip("()")
-
-        return SearchKey(self.key_mappings_lookup.get(key, key))
+    def visit_function_arg(self, node, children):
+        return node.text
 
     def visit_search_value(self, node, children):
         return SearchValue(children[0])
@@ -611,7 +609,7 @@ def convert_search_boolean_to_snuba_query(search_boolean):
     return [operator, [left, right]]
 
 
-def convert_aggregate_filter_to_snuba_query(aggregate_filter, is_alias):
+def convert_aggregate_filter_to_snuba_query(aggregate_filter, is_alias, params=None):
     name = aggregate_filter.key.name
     value = aggregate_filter.value.value
 
@@ -624,7 +622,7 @@ def convert_aggregate_filter_to_snuba_query(aggregate_filter, is_alias):
     if aggregate_filter.operator in ("=", "!=") and aggregate_filter.value.value == "":
         return [["isNull", [name]], aggregate_filter.operator, 1]
 
-    _, agg_additions = resolve_field(name)
+    _, agg_additions = resolve_field(name, params)
     if len(agg_additions) > 0:
         name = agg_additions[0][-1]
 
@@ -802,7 +800,7 @@ def get_filter(query=None, params=None):
                 if converted_filter:
                     kwargs["conditions"].append(converted_filter)
         elif isinstance(term, AggregateFilter):
-            converted_filter = convert_aggregate_filter_to_snuba_query(term, False)
+            converted_filter = convert_aggregate_filter_to_snuba_query(term, False, params)
             if converted_filter:
                 kwargs["having"].append(converted_filter)
 
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index 3b5f54963e..b2ee86fd9f 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -324,7 +324,9 @@ def query(
     if use_aggregate_conditions:
         snuba_args["having"] = snuba_filter.having
 
-    snuba_args.update(resolve_field_list(selected_columns, snuba_args, params=params, auto_fields=auto_fields))
+    snuba_args.update(
+        resolve_field_list(selected_columns, snuba_args, params=params, auto_fields=auto_fields)
+    )
 
     if reference_event:
         ref_conditions = create_reference_event_conditions(reference_event)
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index ac413d7540..1bd1849445 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1117,6 +1117,18 @@ class GetSnubaQueryArgsTest(TestCase):
         assert "Invalid value" in six.text_type(err)
         assert "cancelled," in six.text_type(err)
 
+    def test_function_with_default_arguments(self):
+        result = get_filter("rpm():>100", {"start": before_now(minutes=5), "end": before_now()})
+        assert result.having == [["rpm_300", ">", 100]]
+
+    def test_function_with_alias(self):
+        result = get_filter("p95():>100")
+        assert result.having == [["p95", ">", 100]]
+
+    def test_function_arguments(self):
+        result = get_filter("percentile(transaction.duration, 0.75):>100")
+        assert result.having == [["percentile_transaction_duration_0_75", ">", 100]]
+
     @pytest.mark.xfail(reason="this breaks issue search so needs to be redone")
     def test_trace_id(self):
         result = get_filter("trace:{}".format("a0fa8803753e40fd8124b21eeb2986b5"))
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index ff5af85bcf..4338f71234 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -800,7 +800,7 @@ class QueryTransformTest(TestCase):
 
         discover.query(
             selected_columns=["transaction", "avg(transaction.duration)", "max(time)"],
-            query="http.method:GET max(time):>5",
+            query="http.method:GET max(time):>2019-12-01",
             params={"project_id": [self.project.id], "start": start_time, "end": end_time},
             use_aggregate_conditions=True,
         )
@@ -814,7 +814,7 @@ class QueryTransformTest(TestCase):
                 ["avg", "duration", "avg_transaction_duration"],
                 ["max", "time", "max_time"],
             ],
-            having=[["max_time", ">", 5]],
+            having=[["max_time", ">", 1575158400000]],
             end=end_time,
             start=start_time,
             orderby=None,
@@ -840,6 +840,41 @@ class QueryTransformTest(TestCase):
                 use_aggregate_conditions=True,
             )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_function_conditions(self, mock_query):
+        mock_query.return_value = {
+            "meta": [{"name": "transaction"}, {"name": "percentile_transaction_duration_0_75"}],
+            "data": [
+                {"transaction": "api.do_things", "percentile_transaction_duration_0_75": 1123}
+            ],
+        }
+        discover.query(
+            selected_columns=["transaction", "percentile(transaction.duration, 0.75)"],
+            query="percentile(transaction.duration, 0.75):>100",
+            params={"project_id": [self.project.id]},
+            auto_fields=True,
+            use_aggregate_conditions=True,
+        )
+        mock_query.assert_called_with(
+            selected_columns=["transaction"],
+            aggregations=[
+                ["quantile(0.75)(duration)", None, "percentile_transaction_duration_0_75"],
+                ["argMax", ["event_id", "timestamp"], "latest_event"],
+                ["argMax", ["project_id", "timestamp"], "projectid"],
+            ],
+            filter_keys={"project_id": [self.project.id]},
+            dataset=Dataset.Discover,
+            groupby=["transaction"],
+            conditions=[],
+            end=None,
+            start=None,
+            orderby=None,
+            having=[["percentile_transaction_duration_0_75", ">", 100]],
+            limit=50,
+            offset=None,
+            referrer=None,
+        )
+
 
 class TimeseriesQueryTest(SnubaTestCase, TestCase):
     def setUp(self):
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index 84c43968db..b16c9ee901 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -895,6 +895,38 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[1]["transaction"] == event2.transaction
         assert data[1]["percentile_transaction_duration_0_95"] == 3000
 
+    def test_percentile_function_as_condition(self):
+        self.login_as(user=self.user)
+        project = self.create_project()
+        data = load_data("transaction")
+        data["transaction"] = "/aggregates/1"
+        data["timestamp"] = iso_format(before_now(minutes=1))
+        data["start_timestamp"] = iso_format(before_now(minutes=1, seconds=5))
+        event1 = self.store_event(data, project_id=project.id)
+
+        data = load_data("transaction")
+        data["transaction"] = "/aggregates/2"
+        data["timestamp"] = iso_format(before_now(minutes=1))
+        data["start_timestamp"] = iso_format(before_now(minutes=1, seconds=3))
+        self.store_event(data, project_id=project.id)
+
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "field": ["transaction", "percentile(transaction.duration, 0.95)"],
+                    "query": "event.type:transaction percentile(transaction.duration, 0.95):>4000",
+                    "orderby": ["transaction"],
+                },
+            )
+
+        assert response.status_code == 200, response.content
+        assert len(response.data["data"]) == 1
+        data = response.data["data"]
+        assert data[0]["transaction"] == event1.transaction
+        assert data[0]["percentile_transaction_duration_0_95"] == 5000
+
     def test_rpm_function(self):
         self.login_as(user=self.user)
         project = self.create_project()
