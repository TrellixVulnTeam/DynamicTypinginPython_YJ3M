commit 6aa87ac6a162858ca21670feb96fda2980746b38
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Thu Oct 17 13:40:33 2019 +0200

    feat(db): Added a local override to force an in-memory cache for blocks of code (#15148)
    
    * feat(db): Added a local override to force an in-memory cache for blocks of code
    
    * ref: only support global local caches
    
    * fix: Fix tests

diff --git a/src/sentry/db/models/manager.py b/src/sentry/db/models/manager.py
index 864915557b..3b64b77fca 100644
--- a/src/sentry/db/models/manager.py
+++ b/src/sentry/db/models/manager.py
@@ -5,6 +5,8 @@ import six
 import threading
 import weakref
 
+from contextlib import contextmanager
+
 from django.conf import settings
 from django.db import router
 from django.db.models import Model
@@ -23,6 +25,11 @@ __all__ = ("BaseManager",)
 logger = logging.getLogger("sentry")
 
 
+_local_cache = threading.local()
+_local_cache_generation = 0
+_local_cache_enabled = False
+
+
 def __prep_value(model, key, value):
     if isinstance(value, Model):
         value = value.pk
@@ -74,6 +81,33 @@ class BaseManager(Manager):
         self.__local_cache = threading.local()
         super(BaseManager, self).__init__(*args, **kwargs)
 
+    @staticmethod
+    @contextmanager
+    def local_cache():
+        """Enables local caching for the entire process."""
+        global _local_cache_enabled, _local_cache_generation
+        if _local_cache_enabled:
+            raise RuntimeError("nested use of process global local cache")
+        _local_cache_enabled = True
+        try:
+            yield
+        finally:
+            _local_cache_enabled = False
+            _local_cache_generation += 1
+
+    def _get_local_cache(self):
+        if not _local_cache_enabled:
+            return
+
+        gen = _local_cache_generation
+        cache_gen = getattr(_local_cache, "generation", None)
+
+        if cache_gen != gen or not hasattr(_local_cache, "cache"):
+            _local_cache.cache = {}
+            _local_cache.generation = gen
+
+        return _local_cache.cache
+
     def _get_cache(self):
         if not hasattr(self.__local_cache, "value"):
             self.__local_cache.value = weakref.WeakKeyDictionary()
@@ -243,18 +277,28 @@ class BaseManager(Manager):
 
         if key in self.cache_fields or key == pk_name:
             cache_key = self.__get_lookup_cache_key(**{key: value})
+            local_cache = self._get_local_cache()
+            if local_cache is not None:
+                result = local_cache.get(cache_key)
+                if result is not None:
+                    return result
 
             retval = cache.get(cache_key, version=self.cache_version)
             if retval is None:
                 result = self.get(**kwargs)
                 # Ensure we're pushing it into the cache
                 self.__post_save(instance=result)
+                if local_cache is not None:
+                    local_cache[cache_key] = result
                 return result
 
             # If we didn't look up by pk we need to hit the reffed
             # key
             if key != pk_name:
-                return self.get_from_cache(**{pk_name: retval})
+                result = self.get_from_cache(**{pk_name: retval})
+                if local_cache is not None:
+                    local_cache[cache_key] = result
+                return result
 
             if not isinstance(retval, self.model):
                 if settings.DEBUG:
diff --git a/src/sentry/ingest/outcomes_consumer.py b/src/sentry/ingest/outcomes_consumer.py
index 7b8047d1f7..eb56a30c3b 100644
--- a/src/sentry/ingest/outcomes_consumer.py
+++ b/src/sentry/ingest/outcomes_consumer.py
@@ -30,6 +30,7 @@ from django.conf import settings
 from django.core.cache import cache
 
 from sentry.models.project import Project
+from sentry.db.models.manager import BaseManager
 from sentry.signals import event_filtered, event_dropped
 from sentry.utils.kafka import create_batching_kafka_consumer
 from sentry.utils import json, metrics
@@ -123,8 +124,9 @@ class OutcomesConsumerWorker(AbstractBatchWorker):
         return message.value()
 
     def flush_batch(self, batch):
-        for _ in self.pool.imap_unordered(_process_message_with_timer, batch, chunksize=100):
-            pass
+        with BaseManager.local_cache():
+            for _ in self.pool.imap_unordered(_process_message_with_timer, batch, chunksize=100):
+                pass
 
     def shutdown(self):
         pass
