commit fd1a9ad4ba3a70dea115c4f86c4355b82bf84a03
Author: Jan Michael Auer <jan.auer@sentry.io>
Date:   Wed Mar 11 13:11:26 2020 +0100

    ref(ingest): Remove mark_signal_sent from outcomes consumers (#17553)

diff --git a/src/sentry/buffer/redis.py b/src/sentry/buffer/redis.py
index 805f8fbc36..7963009f76 100644
--- a/src/sentry/buffer/redis.py
+++ b/src/sentry/buffer/redis.py
@@ -33,23 +33,22 @@ def batch_buffers_incr():
         assert _local_buffers is None
         _local_buffers = {}
 
-    try:
-        yield
-    finally:
+    yield
+
+    with _local_buffers_lock:
         from sentry.app import buffer
 
-        with _local_buffers_lock:
-            buffers_to_flush = _local_buffers
-            _local_buffers = None
-
-            for (filters, model), (columns, extra, signal_only) in buffers_to_flush.items():
-                buffer.incr(
-                    model=model,
-                    columns=columns,
-                    filters=dict(filters),
-                    extra=extra,
-                    signal_only=signal_only,
-                )
+        buffers_to_flush = _local_buffers
+        _local_buffers = None
+
+        for (filters, model), (columns, extra, signal_only) in buffers_to_flush.items():
+            buffer.incr(
+                model=model,
+                columns=columns,
+                filters=dict(filters),
+                extra=extra,
+                signal_only=signal_only,
+            )
 
 
 class PendingBuffer(object):
diff --git a/src/sentry/ingest/outcomes_consumer.py b/src/sentry/ingest/outcomes_consumer.py
index 8febfa3c2f..95d2d007b9 100644
--- a/src/sentry/ingest/outcomes_consumer.py
+++ b/src/sentry/ingest/outcomes_consumer.py
@@ -17,8 +17,6 @@ signals to getSentry for these outcomes.
 """
 from __future__ import absolute_import
 
-import six
-
 import time
 import atexit
 import logging
@@ -28,7 +26,6 @@ import multiprocessing as _multiprocessing
 from sentry.utils.batching_kafka_consumer import AbstractBatchWorker
 
 from django.conf import settings
-from django.core.cache import cache
 
 from sentry.constants import DataCategory
 from sentry.models.project import Project
@@ -48,29 +45,6 @@ def _get_signal_cache_key(project_id, event_id):
     return "signal:{}:{}".format(project_id, event_id)
 
 
-def mark_signal_sent(project_id, event_id):
-    """
-    Remembers that a signal was emitted.
-
-    Sets a boolean flag to remember (for one hour) that a signal for a
-    particular event id (in a project) was sent. This is used by the signals
-    forwarder to avoid double-emission.
-
-    :param project_id: :param event_id: :return:
-    """
-    assert isinstance(project_id, six.integer_types)
-    key = _get_signal_cache_key(project_id, event_id)
-    cache.set(key, True, 3600)
-
-
-def is_signal_sent(project_id, event_id):
-    """
-    Checks a signal was sent previously.
-    """
-    key = _get_signal_cache_key(project_id, event_id)
-    return cache.get(key, None) is not None
-
-
 def _process_signal(msg):
     project_id = int(msg.get("project_id") or 0)
     if project_id == 0:
@@ -87,10 +61,6 @@ def _process_signal(msg):
         metrics.incr("outcomes_consumer.skip_outcome", tags={"reason": "missing_event_id"})
         return
 
-    if is_signal_sent(project_id=project_id, event_id=event_id):
-        metrics.incr("outcomes_consumer.skip_outcome", tags={"reason": "is_signal_sent"})
-        return  # message already processed nothing left to do
-
     try:
         project = Project.objects.get_from_cache(id=project_id)
     except Project.DoesNotExist:
@@ -132,9 +102,6 @@ def _process_signal(msg):
             sender=OutcomesConsumerWorker,
         )
 
-    # remember that we sent the signal just in case the processor dies before
-    mark_signal_sent(project_id=project_id, event_id=event_id)
-
     timestamp = msg.get("timestamp")
     if timestamp is not None:
         delta = to_datetime(time.time()) - parse_timestamp(timestamp)
diff --git a/tests/sentry/ingest/test_outcomes_consumer.py b/tests/sentry/ingest/test_outcomes_consumer.py
index 1132426dd7..cc90bd1435 100644
--- a/tests/sentry/ingest/test_outcomes_consumer.py
+++ b/tests/sentry/ingest/test_outcomes_consumer.py
@@ -4,7 +4,7 @@ import logging
 import pytest
 import six
 
-from sentry.ingest.outcomes_consumer import get_outcomes_consumer, mark_signal_sent, is_signal_sent
+from sentry.ingest.outcomes_consumer import get_outcomes_consumer
 from sentry.signals import event_filtered, event_discarded, event_dropped, event_saved
 from sentry.testutils.factories import Factories
 from sentry.utils.outcomes import Outcome
@@ -125,34 +125,6 @@ def outcome_tester(requires_kafka, kafka_producer, kafka_admin, task_runner):
     return OutcomeTester(kafka_producer, kafka_admin, task_runner)
 
 
-@pytest.mark.django_db
-def test_outcome_consumer_ignores_outcomes_already_handled(outcome_tester):
-    # put a few outcome messages on the kafka topic and also mark them in the cache
-    for i in range(4):
-        event_id = _get_event_id(i)
-
-        if i < 2:
-            # pretend that we have already processed this outcome before
-            project_id = outcome_tester.project.id
-            mark_signal_sent(project_id=project_id, event_id=event_id)
-
-        outcome_tester.track_outcome(
-            event_id=event_id,
-            outcome=Outcome.FILTERED,
-            reason="some_reason",
-            remote_addr="127.33.44.{}".format(i),
-        )
-
-    project_id = outcome_tester.project.id
-    outcome_tester.run(lambda: not is_signal_sent(project_id, event_id))
-
-    # verify that no signal was called (since the events have been previously processed)
-    ips = [outcome["ip"] for outcome in outcome_tester.events_filtered]
-    assert ips == ["127.33.44.2", "127.33.44.3"]
-    assert not outcome_tester.events_dropped
-    assert not outcome_tester.events_saved
-
-
 @pytest.mark.django_db
 def test_outcome_consumer_ignores_invalid_outcomes(outcome_tester):
     # Add two FILTERED items so we know when the producer has reached the end
