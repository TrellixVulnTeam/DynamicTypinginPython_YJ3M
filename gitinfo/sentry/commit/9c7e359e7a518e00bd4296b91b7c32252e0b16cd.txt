commit 9c7e359e7a518e00bd4296b91b7c32252e0b16cd
Author: Dan Fuller <dfuller@sentry.io>
Date:   Wed May 13 14:34:11 2020 -0700

    refs(subscriptions): Start using fields from `snuba_query` to replace fields on the alert rule (#18751)
    
    This changes us to use fields on the `snuba_query` in more places. I'll do another pass at this
    after this pr and catch the rest that I missed. It's fine to read from these fields in either the
    snuba_query or alert_rule, since we're keeping the two in sync at the moment.

diff --git a/src/sentry/api/serializers/models/alert_rule.py b/src/sentry/api/serializers/models/alert_rule.py
index d84b13eb9c..7d5eebe9e0 100644
--- a/src/sentry/api/serializers/models/alert_rule.py
+++ b/src/sentry/api/serializers/models/alert_rule.py
@@ -7,6 +7,7 @@ import six
 from sentry.api.serializers import register, serialize, Serializer
 from sentry.incidents.models import AlertRule, AlertRuleExcludedProjects, AlertRuleTrigger
 from sentry.models import Rule
+from sentry.snuba.subscriptions import aggregate_to_query_aggregation
 from sentry.utils.compat import zip
 from sentry.utils.db import attach_foreignkey
 
@@ -30,6 +31,7 @@ class AlertRuleSerializer(Serializer):
 
     def serialize(self, obj, attrs, user):
         env = obj.snuba_query.environment
+        aggregation = aggregate_to_query_aggregation.get(obj.snuba_query.aggregate).value
         return {
             "id": six.text_type(obj.id),
             "name": obj.name,
@@ -40,8 +42,8 @@ class AlertRuleSerializer(Serializer):
             "aggregate": obj.snuba_query.aggregate,
             # These fields are deprecated. Once we've moved over to using aggregate
             # entirely we can remove
-            "aggregation": obj.aggregation,
-            "aggregations": [obj.aggregation],
+            "aggregation": aggregation,
+            "aggregations": [aggregation] if aggregation else [],
             # TODO: Start having the frontend expect seconds
             "timeWindow": obj.snuba_query.time_window / 60,
             "environment": env.name if env else None,
diff --git a/src/sentry/incidents/action_handlers.py b/src/sentry/incidents/action_handlers.py
index db79c47418..3e9ffe864e 100644
--- a/src/sentry/incidents/action_handlers.py
+++ b/src/sentry/incidents/action_handlers.py
@@ -14,6 +14,7 @@ from sentry.incidents.models import (
     IncidentStatus,
     INCIDENT_STATUS,
 )
+from sentry.snuba.subscriptions import aggregate_to_query_aggregation
 from sentry.utils.email import MessageBuilder
 from sentry.utils.http import absolute_uri
 
@@ -95,6 +96,7 @@ class EmailActionHandler(ActionHandler):
     def generate_email_context(self, status):
         trigger = self.action.alert_rule_trigger
         alert_rule = trigger.alert_rule
+        snuba_query = alert_rule.snuba_query
         is_active = status == TriggerStatus.ACTIVE
         is_threshold_type_above = trigger.threshold_type == AlertRuleThresholdType.ABOVE.value
 
@@ -102,10 +104,7 @@ class EmailActionHandler(ActionHandler):
         # if resolve threshold and threshold type is *BELOW* then show '>'
         # we can simplify this to be the below statement
         show_greater_than_string = is_active == is_threshold_type_above
-        environments = list(alert_rule.environment.all())
-        environment_string = (
-            ", ".join(sorted([env.name for env in environments])) if len(environments) else "All"
-        )
+        environment_string = snuba_query.environment.name if snuba_query.environment else "All"
 
         return {
             "link": absolute_uri(
@@ -129,10 +128,12 @@ class EmailActionHandler(ActionHandler):
             ),
             "incident_name": self.incident.title,
             "environment": environment_string,
-            "time_window": format_duration(alert_rule.time_window),
+            "time_window": format_duration(snuba_query.time_window / 60),
             "triggered_at": trigger.date_added,
-            "aggregate": self.query_aggregations_display[QueryAggregations(alert_rule.aggregation)],
-            "query": alert_rule.query,
+            "aggregate": self.query_aggregations_display[
+                aggregate_to_query_aggregation[alert_rule.snuba_query.aggregate]
+            ],
+            "query": snuba_query.query,
             "threshold": trigger.alert_threshold if is_active else trigger.resolve_threshold,
             # if alert threshold and threshold type is above then show '>'
             # if resolve threshold and threshold type is *BELOW* then show '>'
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index dad6060da2..519eb26da8 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -276,9 +276,11 @@ def create_pending_incident_snapshot(incident):
     if PendingIncidentSnapshot.objects.filter(incident=incident).exists():
         PendingIncidentSnapshot.objects.filter(incident=incident).delete()
 
-    time_window = incident.alert_rule.time_window if incident.alert_rule is not None else 1
+    time_window = (
+        incident.alert_rule.snuba_query.time_window if incident.alert_rule is not None else 60
+    )
     target_run_date = incident.current_end_date + min(
-        timedelta(minutes=time_window * 10), timedelta(days=10)
+        timedelta(seconds=time_window * 10), timedelta(days=10)
     )
     return PendingIncidentSnapshot.objects.create(
         incident=incident, target_run_date=target_run_date
@@ -373,14 +375,16 @@ def bulk_build_incident_query_params(incidents, start=None, end=None, windowed_s
 
 def calculate_incident_time_range(incident, start=None, end=None, windowed_stats=False):
     # TODO: When time_window is persisted, switch to using that instead of alert_rule.time_window.
-    time_window = incident.alert_rule.time_window if incident.alert_rule is not None else 1
-    time_window_delta = timedelta(minutes=time_window)
+    time_window = (
+        incident.alert_rule.snuba_query.time_window if incident.alert_rule is not None else 60
+    )
+    time_window_delta = timedelta(seconds=time_window)
     start = incident.date_started - time_window_delta if start is None else start
     end = incident.current_end_date + time_window_delta if end is None else end
     if windowed_stats:
         now = timezone.now()
-        end = start + timedelta(minutes=time_window * (WINDOWED_STATS_DATA_POINTS / 2))
-        start = start - timedelta(minutes=time_window * (WINDOWED_STATS_DATA_POINTS / 2))
+        end = start + timedelta(seconds=time_window * (WINDOWED_STATS_DATA_POINTS / 2))
+        start = start - timedelta(seconds=time_window * (WINDOWED_STATS_DATA_POINTS / 2))
         if end > now:
             end = now
 
@@ -390,11 +394,11 @@ def calculate_incident_time_range(incident, start=None, end=None, windowed_stats
             # To resolve that, we ensure that the end is never greater than the date
             # an incident ended + the smaller of time_window*10 or 10 days.
             latest_end_date = incident.current_end_date + min(
-                timedelta(minutes=time_window * 10), timedelta(days=10)
+                timedelta(seconds=time_window * 10), timedelta(days=10)
             )
             end = min(end, latest_end_date)
 
-            start = end - timedelta(minutes=time_window * WINDOWED_STATS_DATA_POINTS)
+            start = end - timedelta(seconds=time_window * WINDOWED_STATS_DATA_POINTS)
 
     return start, end
 
@@ -403,7 +407,7 @@ def calculate_incident_prewindow(start, end, incident=None):
     # Make the a bit earlier to show more relevant data from before the incident started:
     prewindow = (end - start) / 5
     if incident and incident.alert_rule is not None:
-        alert_rule_time_window = timedelta(minutes=incident.alert_rule.time_window)
+        alert_rule_time_window = timedelta(seconds=incident.alert_rule.snuba_query.time_window)
         prewindow = max(alert_rule_time_window, prewindow)
     return prewindow
 
@@ -431,10 +435,9 @@ def bulk_get_incident_event_stats(incidents, query_params_list):
             ],
             orderby="time",
             groupby=["time"],
-            rollup=incident.alert_rule.time_window * 60
+            rollup=incident.alert_rule.snuba_query.time_window
             if incident.alert_rule is not None
-            else 1
-            * 60,  # TODO: When time_window is persisted, switch to using that instead of alert_rule.time_window.
+            else 60,  # TODO: When time_window is persisted, switch to using that instead of alert_rule.time_window.
             limit=10000,
             **query_param
         )
@@ -649,26 +652,6 @@ def snapshot_alert_rule(alert_rule):
     )
 
 
-def convert_alert_rule_to_snuba_query(alert_rule):
-    """
-    Temporary method to convert existing alert rules to have a snuba query
-    """
-    if alert_rule.snuba_query:
-        return
-
-    with transaction.atomic():
-        snuba_query = create_snuba_query(
-            QueryDatasets(alert_rule.dataset),
-            alert_rule.query,
-            QueryAggregations(alert_rule.aggregation),
-            timedelta(minutes=alert_rule.time_window),
-            timedelta(minutes=alert_rule.resolution),
-            alert_rule.environment,
-        )
-        alert_rule.update(snuba_query=snuba_query)
-        alert_rule.query_subscriptions.all().update(snuba_query=snuba_query)
-
-
 def update_alert_rule(
     alert_rule,
     projects=None,
@@ -707,7 +690,6 @@ def update_alert_rule(
         and AlertRule.objects.filter(organization=alert_rule.organization, name=name).exists()
     ):
         raise AlertRuleNameAlreadyUsedError()
-    convert_alert_rule_to_snuba_query(alert_rule)
 
     updated_fields = {}
     updated_query_fields = {}
diff --git a/src/sentry/integrations/slack/utils.py b/src/sentry/integrations/slack/utils.py
index e88267372d..be20394bfb 100644
--- a/src/sentry/integrations/slack/utils.py
+++ b/src/sentry/integrations/slack/utils.py
@@ -297,7 +297,7 @@ def build_incident_attachment(incident):
         # TODO: If we're relying on this and expecting possible delays between a trigger fired and this function running,
         # then this could actually be incorrect if they changed the trigger's time window in this time period. Should we store it?
         start = incident_trigger.date_modified - timedelta(
-            minutes=alert_rule_trigger.alert_rule.time_window
+            seconds=alert_rule_trigger.alert_rule.snuba_query.time_window
         )
         end = incident_trigger.date_modified
     else:
@@ -321,11 +321,11 @@ def build_incident_attachment(incident):
         if alert_rule.aggregation == QueryAggregations.TOTAL.value
         else aggregates["unique_users"]
     )
-    time_window = alert_rule.time_window
+    time_window = alert_rule.snuba_query.time_window / 60
 
     text = "{} {} in the last {} minutes".format(agg_value, agg_text, time_window)
 
-    if alert_rule.query != "":
+    if alert_rule.snuba_query.query != "":
         text = text + "\nFilter: {}".format(alert_rule.query)
 
     ts = incident.date_started
@@ -446,6 +446,4 @@ def send_incident_alert_notification(action, incident):
     try:
         client.post("/chat.postMessage", data=payload, timeout=5)
     except ApiError as e:
-        logger.info(
-            "rule.fail.slack_post", extra={"error": six.text_type(e)},
-        )
+        logger.info("rule.fail.slack_post", extra={"error": six.text_type(e)})
diff --git a/src/sentry/snuba/query_subscription_consumer.py b/src/sentry/snuba/query_subscription_consumer.py
index 5e2fd323ac..62f51903ab 100644
--- a/src/sentry/snuba/query_subscription_consumer.py
+++ b/src/sentry/snuba/query_subscription_consumer.py
@@ -200,11 +200,11 @@ class QuerySubscriptionConsumer(object):
                     "timestamp": contents["timestamp"],
                     "query_subscription_id": contents["subscription_id"],
                     "project_id": subscription.project_id,
-                    "subscription_dataset": subscription.dataset,
-                    "subscription_query": subscription.query,
-                    "subscription_aggregation": subscription.aggregation,
-                    "subscription_time_window": subscription.time_window,
-                    "subscription_resolution": subscription.resolution,
+                    "subscription_dataset": subscription.snuba_query.dataset,
+                    "subscription_query": subscription.snuba_query.query,
+                    "subscription_aggregation": subscription.snuba_query.aggregate,
+                    "subscription_time_window": subscription.snuba_query.time_window,
+                    "subscription_resolution": subscription.snuba_query.resolution,
                     "offset": message.offset(),
                     "partition": message.partition(),
                     "value": message.value(),
diff --git a/src/sentry/snuba/subscriptions.py b/src/sentry/snuba/subscriptions.py
index 33b694b870..fd84ce5dc9 100644
--- a/src/sentry/snuba/subscriptions.py
+++ b/src/sentry/snuba/subscriptions.py
@@ -22,6 +22,9 @@ aggregation_function_translations = {
     QueryAggregations.TOTAL: "count()",
     QueryAggregations.UNIQUE_USERS: "count_unique(tags[sentry:user])",
 }
+aggregate_to_query_aggregation = {
+    val: key for key, val in aggregation_function_translations.items()
+}
 
 
 def translate_aggregation(aggregation):
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index 907c0b0d7e..30a80fcdf5 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -71,6 +71,7 @@ from sentry.incidents.models import (
     IncidentType,
 )
 from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
+from sentry.snuba.subscriptions import aggregation_function_translations
 from sentry.models.integration import Integration
 from sentry.testutils import TestCase, SnubaTestCase
 from sentry.testutils.helpers.datetime import iso_format, before_now
@@ -285,22 +286,22 @@ class BaseIncidentEventStatsTest(BaseIncidentsTest):
 
     def validate_result(self, incident, result, expected_results, start, end, windowed_stats):
         # Duration of 300s, but no alert rule
-        time_window = incident.alert_rule.time_window if incident.alert_rule else 1
-        assert result.rollup == time_window * 60
+        time_window = incident.alert_rule.snuba_query.time_window if incident.alert_rule else 60
+        assert result.rollup == time_window
         expected_start = start if start else incident.date_started - timedelta(minutes=1)
         expected_end = end if end else incident.current_end_date + timedelta(minutes=1)
 
         if windowed_stats:
             now = timezone.now()
             expected_end = expected_start + timedelta(
-                minutes=time_window * (WINDOWED_STATS_DATA_POINTS / 2)
+                seconds=time_window * (WINDOWED_STATS_DATA_POINTS / 2)
             )
             expected_start = expected_start - timedelta(
-                minutes=time_window * (WINDOWED_STATS_DATA_POINTS / 2)
+                seconds=time_window * (WINDOWED_STATS_DATA_POINTS / 2)
             )
             if expected_end > now:
                 expected_end = now
-                expected_start = now - timedelta(minutes=time_window * WINDOWED_STATS_DATA_POINTS)
+                expected_start = now - timedelta(seconds=time_window * WINDOWED_STATS_DATA_POINTS)
 
         assert result.start == expected_start
         assert result.end == expected_end
@@ -654,7 +655,7 @@ class CreateIncidentSnapshotTest(TestCase, BaseIncidentsTest):
         start, end = calculate_incident_time_range(incident, windowed_stats=True)
         assert end == incident.current_end_date + timedelta(days=10)
 
-        alert_rule.update(time_window=10)
+        alert_rule.snuba_query.update(time_window=600)
 
         start, end = calculate_incident_time_range(incident, windowed_stats=True)
         assert end == incident.current_end_date + timedelta(minutes=100)
@@ -725,10 +726,15 @@ class CreateAlertRuleTest(TestCase, BaseIncidentsTest):
         assert alert_rule.name == name
         assert alert_rule.status == AlertRuleStatus.PENDING.value
         assert alert_rule.query_subscriptions.all().count() == 1
+        assert alert_rule.snuba_query.dataset == QueryDatasets.EVENTS.value
         assert alert_rule.dataset == QueryDatasets.EVENTS.value
+        assert alert_rule.snuba_query.query == query
         assert alert_rule.query == query
+        assert alert_rule.snuba_query.aggregate == aggregation_function_translations[aggregation]
         assert alert_rule.aggregation == aggregation.value
+        assert alert_rule.snuba_query.time_window == time_window * 60
         assert alert_rule.time_window == time_window
+        assert alert_rule.snuba_query.resolution == DEFAULT_ALERT_RULE_RESOLUTION * 60
         assert alert_rule.resolution == DEFAULT_ALERT_RULE_RESOLUTION
         assert alert_rule.threshold_period == threshold_period
 
@@ -840,11 +846,23 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
         updated_subscriptions = self.alert_rule.query_subscriptions.all()
         assert set([sub.project for sub in updated_subscriptions]) == set(updated_projects)
         for subscription in updated_subscriptions:
+            assert subscription.snuba_query.query == query
             assert subscription.query == query
+            assert (
+                subscription.snuba_query.aggregate == aggregation_function_translations[aggregation]
+            )
             assert subscription.aggregation == aggregation.value
+            assert subscription.snuba_query.time_window == int(
+                timedelta(minutes=time_window).total_seconds()
+            )
             assert subscription.time_window == int(timedelta(minutes=time_window).total_seconds())
+        assert self.alert_rule.snuba_query.query == query
         assert self.alert_rule.query == query
+        assert (
+            self.alert_rule.snuba_query.aggregate == aggregation_function_translations[aggregation]
+        )
         assert self.alert_rule.aggregation == aggregation.value
+        assert self.alert_rule.snuba_query.time_window == time_window * 60
         assert self.alert_rule.time_window == time_window
         assert self.alert_rule.threshold_period == threshold_period
 
@@ -1013,9 +1031,16 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
 
             # Rule snapshot should have properties of the rule before it was updated.
             assert rule_snapshot.id != updated_rule.id
+            assert rule_snapshot.snuba_query_id != updated_rule.snuba_query_id
             assert rule_snapshot.name == updated_rule.name
+            assert rule_snapshot.snuba_query.query == "level:error"
             assert rule_snapshot.query == "level:error"
+            assert rule_snapshot.snuba_query.time_window == 600
             assert rule_snapshot.time_window == 10
+            assert (
+                rule_snapshot.snuba_query.aggregate
+                == aggregation_function_translations[QueryAggregations.TOTAL]
+            )
             assert rule_snapshot.aggregation == QueryAggregations.TOTAL.value
             assert rule_snapshot.threshold_period == 1
 
diff --git a/tests/sentry/snuba/test_query_subscription_consumer.py b/tests/sentry/snuba/test_query_subscription_consumer.py
index 87d819b0e8..8241cb63fa 100644
--- a/tests/sentry/snuba/test_query_subscription_consumer.py
+++ b/tests/sentry/snuba/test_query_subscription_consumer.py
@@ -3,6 +3,7 @@ from __future__ import absolute_import
 import json
 import unittest
 from copy import deepcopy
+from datetime import timedelta
 
 import mock
 import six
@@ -12,7 +13,7 @@ from django.conf import settings
 from exam import fixture, patcher
 
 from sentry.utils.compat.mock import Mock
-from sentry.snuba.models import QueryDatasets, QuerySubscription
+from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
 from sentry.snuba.query_subscription_consumer import (
     InvalidMessageError,
     InvalidSchemaError,
@@ -20,6 +21,7 @@ from sentry.snuba.query_subscription_consumer import (
     register_subscriber,
     subscriber_registry,
 )
+from sentry.snuba.subscriptions import create_snuba_query, create_snuba_subscription
 from sentry.testutils.cases import TestCase
 
 
@@ -100,16 +102,20 @@ class HandleMessageTest(BaseQuerySubscriptionTest, TestCase):
         registration_key = "registered_test"
         mock_callback = Mock()
         register_subscriber(registration_key)(mock_callback)
-        sub = QuerySubscription.objects.create(
-            project=self.project,
-            type=registration_key,
-            subscription_id="an_id",
-            dataset="something",
-            query="hello",
-            aggregation=0,
-            time_window=1,
-            resolution=1,
-        )
+        with self.tasks():
+            snuba_query = create_snuba_query(
+                QueryDatasets.EVENTS,
+                "hello",
+                QueryAggregations.TOTAL,
+                timedelta(minutes=10),
+                timedelta(minutes=1),
+                None,
+            )
+            sub = create_snuba_subscription(
+                self.project, registration_key, snuba_query, QueryAggregations.TOTAL
+            )
+        sub.refresh_from_db()
+
         data = self.valid_wrapper
         data["payload"]["subscription_id"] = sub.subscription_id
         self.consumer.handle_message(self.build_mock_message(data))
diff --git a/tests/sentry/snuba/test_subscriptions.py b/tests/sentry/snuba/test_subscriptions.py
index 87e5631666..f237194507 100644
--- a/tests/sentry/snuba/test_subscriptions.py
+++ b/tests/sentry/snuba/test_subscriptions.py
@@ -4,6 +4,7 @@ from datetime import timedelta
 
 from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
 from sentry.snuba.subscriptions import (
+    aggregation_function_translations,
     bulk_delete_snuba_subscriptions,
     create_snuba_query,
     create_snuba_subscription,
@@ -215,14 +216,19 @@ class UpdateSnubaSubscriptionTest(TestCase):
             time_window=int(time_window.total_seconds()),
             resolution=int(resolution.total_seconds()),
             environment=self.environment,
+            aggregate=aggregation_function_translations[aggregation],
         )
         assert subscription_id is not None
         update_snuba_subscription(subscription, snuba_query, aggregation)
         assert subscription.status == QuerySubscription.Status.UPDATING.value
         assert subscription.subscription_id == subscription_id
+        assert subscription.snuba_query.query == query
         assert subscription.query == query
+        assert subscription.snuba_query.aggregate == aggregation_function_translations[aggregation]
         assert subscription.aggregation == aggregation.value
+        assert subscription.snuba_query.time_window == int(time_window.total_seconds())
         assert subscription.time_window == int(time_window.total_seconds())
+        assert subscription.snuba_query.resolution == int(resolution.total_seconds())
         assert subscription.resolution == int(resolution.total_seconds())
 
     def test_with_task(self):
diff --git a/tests/snuba/snuba/test_query_subscription_consumer.py b/tests/snuba/snuba/test_query_subscription_consumer.py
index ac7cc25e63..fbf186936c 100644
--- a/tests/snuba/snuba/test_query_subscription_consumer.py
+++ b/tests/snuba/snuba/test_query_subscription_consumer.py
@@ -2,6 +2,7 @@ from __future__ import absolute_import
 
 import json
 from copy import deepcopy
+from datetime import timedelta
 from uuid import uuid4
 
 import pytz
@@ -12,12 +13,13 @@ from django.test.utils import override_settings
 from exam import fixture
 from sentry.utils.compat.mock import call, Mock
 
-from sentry.snuba.models import QuerySubscription
+from sentry.snuba.models import QueryAggregations, QueryDatasets
 from sentry.snuba.query_subscription_consumer import (
     QuerySubscriptionConsumer,
     register_subscriber,
     subscriber_registry,
 )
+from sentry.snuba.subscriptions import create_snuba_query, create_snuba_subscription
 from sentry.testutils.cases import SnubaTestCase, TestCase
 
 
@@ -82,6 +84,24 @@ class QuerySubscriptionConsumerTest(TestCase, SnubaTestCase):
     def registration_key(self):
         return "registered_keyboard_interrupt"
 
+    def create_subscription(self):
+        with self.tasks():
+            snuba_query = create_snuba_query(
+                QueryDatasets.EVENTS,
+                "hello",
+                QueryAggregations.TOTAL,
+                timedelta(minutes=1),
+                timedelta(minutes=1),
+                None,
+            )
+            sub = create_snuba_subscription(
+                self.project, self.registration_key, snuba_query, QueryAggregations.TOTAL
+            )
+            sub.subscription_id = self.subscription_id
+            sub.status = 0
+            sub.save()
+        return sub
+
     def test_old(self):
         cluster_name = settings.KAFKA_TOPICS[self.topic]["cluster"]
 
@@ -96,16 +116,7 @@ class QuerySubscriptionConsumerTest(TestCase, SnubaTestCase):
         mock_callback = Mock()
         mock_callback.side_effect = KeyboardInterrupt()
         register_subscriber(self.registration_key)(mock_callback)
-        sub = QuerySubscription.objects.create(
-            project=self.project,
-            type=self.registration_key,
-            subscription_id=self.subscription_id,
-            dataset="something",
-            query="hello",
-            aggregation=0,
-            time_window=1,
-            resolution=1,
-        )
+        sub = self.create_subscription()
         consumer = QuerySubscriptionConsumer("hi", topic=self.topic, commit_batch_size=1)
         consumer.run()
 
@@ -127,16 +138,7 @@ class QuerySubscriptionConsumerTest(TestCase, SnubaTestCase):
         mock_callback = Mock()
         mock_callback.side_effect = KeyboardInterrupt()
         register_subscriber(self.registration_key)(mock_callback)
-        sub = QuerySubscription.objects.create(
-            project=self.project,
-            type=self.registration_key,
-            subscription_id=self.subscription_id,
-            dataset="something",
-            query="hello",
-            aggregation=0,
-            time_window=1,
-            resolution=1,
-        )
+        sub = self.create_subscription()
         consumer = QuerySubscriptionConsumer("hi", topic=self.topic, commit_batch_size=1)
         consumer.run()
 
@@ -165,16 +167,7 @@ class QuerySubscriptionConsumerTest(TestCase, SnubaTestCase):
         mock.side_effect = mock_callback
 
         register_subscriber(self.registration_key)(mock)
-        sub = QuerySubscription.objects.create(
-            project=self.project,
-            type=self.registration_key,
-            subscription_id=self.subscription_id,
-            dataset="something",
-            query="hello",
-            aggregation=0,
-            time_window=1,
-            resolution=1,
-        )
+        sub = self.create_subscription()
         consumer = QuerySubscriptionConsumer("hi", topic=self.topic, commit_batch_size=100)
         consumer.run()
         valid_payload = self.valid_payload
