commit bab90e3272350de5c0934e163321b9a8ce9b64cd
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Wed Feb 1 23:26:42 2017 +0100

    Revert "Revert "Reprocessing Part 1: Multi-Processor Support (#4774)""
    
    This reverts commit 607606ce7a546e0bc7d04465f31fa05caaeba0f8.

diff --git a/CHANGES b/CHANGES
index e91f326b00..14db0e6acf 100644
--- a/CHANGES
+++ b/CHANGES
@@ -27,6 +27,7 @@ API Changes
 - Added avatar and avatarType to ``/organizations/{org}/`` endpoint.
 - Provide commit and author information associated with a given release
 - Provide repository information for commits
+- Added new internal processing interface that supports multiple processing steps per stacktrace (for instance JavaScript + native)
 
 Version 8.12
 ------------
diff --git a/src/sentry/interfaces/exception.py b/src/sentry/interfaces/exception.py
index 2713ac455e..595e330cd9 100644
--- a/src/sentry/interfaces/exception.py
+++ b/src/sentry/interfaces/exception.py
@@ -60,6 +60,7 @@ class SingleException(Interface):
                 data['raw_stacktrace'],
                 has_system_frames=has_system_frames,
                 slim_frames=slim_frames,
+                raw=True
             )
         else:
             raw_stacktrace = None
diff --git a/src/sentry/interfaces/stacktrace.py b/src/sentry/interfaces/stacktrace.py
index 9fb7c798ed..ba94b7b4b5 100644
--- a/src/sentry/interfaces/stacktrace.py
+++ b/src/sentry/interfaces/stacktrace.py
@@ -242,7 +242,7 @@ def handle_nan(value):
 
 class Frame(Interface):
     @classmethod
-    def to_python(cls, data):
+    def to_python(cls, data, raw=False):
         abs_path = data.get('abs_path')
         filename = data.get('filename')
         symbol = data.get('symbol')
@@ -264,25 +264,27 @@ class Frame(Interface):
             if v is not None and not isinstance(v, six.string_types):
                 raise InterfaceValidationError("Invalid value for '%s'" % name)
 
-        # absolute path takes priority over filename
-        # (in the end both will get set)
-        if not abs_path:
-            abs_path = filename
-            filename = None
-
-        if not filename and abs_path:
-            if is_url(abs_path):
-                urlparts = urlparse(abs_path)
-                if urlparts.path:
-                    filename = urlparts.path
+        # Some of this processing should only be done for non raw frames
+        if not raw:
+            # absolute path takes priority over filename
+            # (in the end both will get set)
+            if not abs_path:
+                abs_path = filename
+                filename = None
+
+            if not filename and abs_path:
+                if is_url(abs_path):
+                    urlparts = urlparse(abs_path)
+                    if urlparts.path:
+                        filename = urlparts.path
+                    else:
+                        filename = abs_path
                 else:
                     filename = abs_path
-            else:
-                filename = abs_path
 
-        if not (filename or function or module or package):
-            raise InterfaceValidationError("No 'filename' or 'function' or "
-                                           "'module' or 'package'")
+            if not (filename or function or module or package):
+                raise InterfaceValidationError("No 'filename' or 'function' or "
+                                               "'module' or 'package'")
 
         platform = data.get('platform')
         if platform not in VALID_PLATFORMS:
@@ -624,27 +626,28 @@ class Stacktrace(Interface):
         return iter(self.frames)
 
     @classmethod
-    def to_python(cls, data, has_system_frames=None, slim_frames=True):
+    def to_python(cls, data, has_system_frames=None, slim_frames=True,
+                  raw=False):
         if not data.get('frames'):
             raise InterfaceValidationError("No 'frames' present")
 
         if not isinstance(data['frames'], list):
             raise InterfaceValidationError("Invalid value for 'frames'")
 
-        if has_system_frames is None:
-            has_system_frames = cls.data_has_system_frames(data)
-
         frame_list = [
             # XXX(dcramer): handle PHP sending an empty array for a frame
-            Frame.to_python(f or {})
+            Frame.to_python(f or {}, raw=raw)
             for f in data['frames']
         ]
 
-        for frame in frame_list:
-            if not has_system_frames:
-                frame.in_app = False
-            elif frame.in_app is None:
-                frame.in_app = False
+        if not raw:
+            if has_system_frames is None:
+                has_system_frames = cls.data_has_system_frames(data)
+            for frame in frame_list:
+                if not has_system_frames:
+                    frame.in_app = False
+                elif frame.in_app is None:
+                    frame.in_app = False
 
         kwargs = {
             'frames': frame_list,
diff --git a/src/sentry/interfaces/threads.py b/src/sentry/interfaces/threads.py
index 77bfc61752..1083d1d433 100644
--- a/src/sentry/interfaces/threads.py
+++ b/src/sentry/interfaces/threads.py
@@ -7,12 +7,12 @@ from sentry.utils.safe import trim
 __all__ = ('Threads',)
 
 
-def get_stacktrace(value):
+def get_stacktrace(value, raw=False):
     # Special case: if the thread has no frames we set the
     # stacktrace to none.  Otherwise this will fail really
     # badly.
     if value and value.get('frames'):
-        return Stacktrace.to_python(value, slim_frames=True)
+        return Stacktrace.to_python(value, slim_frames=True, raw=raw)
 
 
 class Threads(Interface):
@@ -25,7 +25,8 @@ class Threads(Interface):
         for thread in data.get('values') or ():
             threads.append({
                 'stacktrace': get_stacktrace(thread.get('stacktrace')),
-                'raw_stacktrace': get_stacktrace(thread.get('raw_stacktrace')),
+                'raw_stacktrace': get_stacktrace(thread.get('raw_stacktrace'),
+                                                 raw=True),
                 'id': trim(thread.get('id'), 40),
                 'crashed': bool(thread.get('crashed')),
                 'current': bool(thread.get('current')),
diff --git a/src/sentry/lang/javascript/plugin.py b/src/sentry/lang/javascript/plugin.py
index 9b36217ed0..9a82e02fa7 100644
--- a/src/sentry/lang/javascript/plugin.py
+++ b/src/sentry/lang/javascript/plugin.py
@@ -1,36 +1,42 @@
 from __future__ import absolute_import, print_function
 
-from django.conf import settings
 from ua_parser.user_agent_parser import Parse
 
-from sentry.models import Project
 from sentry.plugins import Plugin2
-from sentry.utils import metrics
+from sentry.stacktraces import find_stacktraces_in_data
 
-from .processor import SourceProcessor
+from .processor import JavaScriptStacktraceProcessor
 from .errormapping import rewrite_exception
 
 
 def preprocess_event(data):
-    if settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT:
-        project = Project.objects.get_from_cache(
-            id=data['project'],
-        )
+    rewrite_exception(data)
+    fix_culprit(data)
+    inject_device_data(data)
+    generate_modules(data)
+    return data
 
-        allow_scraping = bool(project.get_option('sentry:scrape_javascript', True))
 
-        processor = SourceProcessor(
-            project=project,
-            allow_scraping=allow_scraping,
-        )
-        with metrics.timer('sourcemaps.process', instance=project.id):
-            processor.process(data)
+def generate_modules(data):
+    from sentry.lang.javascript.processor import generate_module
 
-    rewrite_exception(data)
+    for info in find_stacktraces_in_data(data):
+        for frame in info.stacktrace['frames']:
+            platform = frame.get('platform') or data['platform']
+            if platform != 'javascript' or frame.get('module'):
+                continue
+            abs_path = frame.get('abs_path')
+            if abs_path and abs_path.startswith(('http:', 'https:', 'webpack:')):
+                frame['module'] = generate_module(abs_path)
 
-    inject_device_data(data)
 
-    return data
+def fix_culprit(data):
+    exc = data.get('sentry.interfaces.Exception')
+    if not exc:
+        return
+
+    from sentry.event_manager import generate_culprit
+    data['culprit'] = generate_culprit(data)
 
 
 def parse_user_agent(data):
@@ -119,6 +125,13 @@ class JavascriptPlugin(Plugin2):
         return False
 
     def get_event_preprocessors(self, data, **kwargs):
+        # XXX: rewrite_exception we probably also want if the event
+        # platform is something else? unsure
         if data.get('platform') == 'javascript':
             return [preprocess_event]
         return []
+
+    def get_stacktrace_processors(self, data, stacktrace_infos,
+                                  platforms, **kwargs):
+        if 'javascript' in platforms:
+            return [JavaScriptStacktraceProcessor]
diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index f77ba84166..3117da1d5c 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -1,6 +1,6 @@
 from __future__ import absolute_import, print_function
 
-__all__ = ['SourceProcessor']
+__all__ = ['JavaScriptStacktraceProcessor']
 
 import codecs
 import logging
@@ -27,7 +27,6 @@ except ImportError:
         pass
 
 from sentry import http
-from sentry.constants import MAX_CULPRIT_LENGTH
 from sentry.exceptions import RestrictedIPAddress
 from sentry.interfaces.stacktrace import Stacktrace
 from sentry.models import EventError, Release, ReleaseFile
@@ -37,6 +36,7 @@ from sentry.utils.hashlib import md5_text
 from sentry.utils.http import is_valid_origin
 from sentry.utils.strings import truncatechars
 from sentry.utils import metrics
+from sentry.stacktraces import StacktraceProcessor
 
 from .cache import SourceCache, SourceMapCache
 
@@ -139,7 +139,7 @@ def trim_line(line, column=0):
 
 def get_source_context(source, lineno, colno, context=LINES_OF_CONTEXT):
     if not source:
-        return [], '', []
+        return None, None, None
 
     # lineno's in JS are 1-indexed
     # just in case. sometimes math is hard
@@ -164,7 +164,7 @@ def get_source_context(source, lineno, colno, context=LINES_OF_CONTEXT):
     except IndexError:
         post_context = []
 
-    return pre_context, context_line, post_context
+    return pre_context or None, context_line, post_context or None
 
 
 def discover_sourcemap(result):
@@ -573,7 +573,7 @@ def generate_module(src):
     return CLEAN_MODULE_RE.sub('', filename) or UNKNOWN_MODULE
 
 
-class SourceProcessor(object):
+class JavaScriptStacktraceProcessor(StacktraceProcessor):
     """
     Attempts to fetch source code for javascript frames.
 
@@ -586,14 +586,16 @@ class SourceProcessor(object):
 
     Mutates the input ``data`` with expanded context if available.
     """
-    def __init__(self, project, max_fetches=MAX_RESOURCE_FETCHES,
-                 allow_scraping=True):
-        self.allow_scraping = allow_scraping
-        self.max_fetches = max_fetches
+
+    def __init__(self, *args, **kwargs):
+        StacktraceProcessor.__init__(self, *args, **kwargs)
+        self.max_fetches = MAX_RESOURCE_FETCHES
+        self.allow_scraping = self.project.get_option(
+            'sentry:scrape_javascript', True)
         self.fetch_count = 0
         self.cache = SourceCache()
         self.sourcemaps = SourceMapCache()
-        self.project = project
+        self.release = None
 
     def get_stacktraces(self, data):
         try:
@@ -613,117 +615,36 @@ class SourceProcessor(object):
             for s in stacktraces
         ]
 
-    def get_valid_frames(self, stacktraces):
+    def get_valid_frames(self):
         # build list of frames that we can actually grab source for
         frames = []
-        for _, stacktrace in stacktraces:
+        for info in self.stacktrace_infos:
             frames.extend([
-                f for f in stacktrace.frames
-                if f.lineno is not None
+                f for f in info.stacktrace['frames']
+                if f.get('lineno') is not None
             ])
         return frames
 
-    def get_release(self, data):
-        if not data.get('release'):
-            return
-
-        return Release.get(
-            project=self.project,
-            version=data['release'],
-        )
-
-    def process(self, data):
-        stacktraces = self.get_stacktraces(data)
-        if not stacktraces:
-            logger.debug('No stacktrace for event %r', data['event_id'])
-            return
-
-        # TODO(dcramer): we need this to do more than just sourcemaps
-        frames = self.get_valid_frames(stacktraces)
+    def preprocess_related_data(self):
+        frames = self.get_valid_frames()
         if not frames:
-            logger.debug('Event %r has no frames with enough context to fetch remote source', data['event_id'])
-            return
-
-        data.setdefault('errors', [])
-        errors = data['errors']
-
-        release = self.get_release(data)
-        # all of these methods assume mutation on the original
-        # objects rather than re-creation
-        self.populate_source_cache(frames, release)
-        with metrics.timer('sourcemaps.expand_frames'):
-            expand_errors, sourcemap_applied = self.expand_frames(frames, release)
-        errors.extend(expand_errors or [])
-        self.ensure_module_names(frames)
-        self.fix_culprit(data, stacktraces)
-        self.update_stacktraces(stacktraces)
-        if sourcemap_applied:
-            self.add_raw_stacktraces(data, release)
-        return data
-
-    def fix_culprit(self, data, stacktraces):
-        # This is a bit weird, since the original culprit we get
-        # will be wrong, so we want to touch it up after we've processed
-        # a stack trace.
-
-        # In this case, we have a list of all stacktraces as a tuple
-        # (stacktrace as dict, stacktrace class)
-        # So we need to take the [1] index to get the Stacktrace class,
-        # then extract the culprit string from that.
-        data['culprit'] = truncatechars(
-            stacktraces[-1][1].get_culprit_string(),
-            MAX_CULPRIT_LENGTH,
-        )
+            logger.debug('Event %r has no frames with enough context to '
+                         'fetch remote source', self.data['event_id'])
+            return False
 
-    def update_stacktraces(self, stacktraces):
-        for raw, interface in stacktraces:
-            raw.update(interface.to_json())
+        if self.data.get('release'):
+            self.release = Release.get(
+                project=self.project,
+                version=self.data['release'],
+            )
+        self.populate_source_cache(frames)
+        return True
 
-    def add_raw_stacktraces(self, data, release):
-        try:
-            values = data['sentry.interfaces.Exception']['values']
-        except KeyError:
+    def process_frame(self, frame):
+        if not settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT or \
+           self.get_effective_platform(frame) != 'javascript':
             return
 
-        for exc in values:
-            if not exc.get('stacktrace'):
-                continue
-
-            raw_frames = []
-            for frame in exc['stacktrace']['frames']:
-                if 'data' not in frame or 'raw' not in frame['data']:
-                    continue
-
-                frame = frame['data']['raw']
-
-                if frame['lineno'] is not None:
-                    source = self.get_source(frame['abs_path'], release)
-                    if source is None:
-                        logger.debug('No source found for %s', frame['abs_path'])
-                        continue
-
-                    frame['pre_context'], frame['context_line'], frame['post_context'] = get_source_context(
-                        source=source, lineno=frame['lineno'], colno=frame['colno'] or 0)
-
-            for frame in exc['stacktrace']['frames']:
-                try:
-                    # TODO(dcramer): we should refactor this to avoid this
-                    # push/pop process
-                    raw_frames.append(frame['data'].pop('raw'))
-                except KeyError:
-                    raw_frames.append(frame.copy())
-
-            exc['raw_stacktrace'] = {'frames': raw_frames}
-
-    def ensure_module_names(self, frames):
-        # TODO(dcramer): this doesn't really fit well with generic URLs so we
-        # whitelist it to http/https
-        for frame in frames:
-            if not frame.module and frame.abs_path \
-               and frame.abs_path.startswith(('http:', 'https:', 'webpack:')):
-                frame.module = generate_module(frame.abs_path)
-
-    def expand_frames(self, frames, release):
         last_token = None
         token = None
 
@@ -732,146 +653,163 @@ class SourceProcessor(object):
         all_errors = []
         sourcemap_applied = False
 
-        for frame in frames:
-            errors = cache.get_errors(frame.abs_path)
-            if errors:
-                all_errors.extend(errors)
+        errors = cache.get_errors(frame['abs_path'])
+        if errors:
+            all_errors.extend(errors)
 
-            # can't fetch source if there's no filename present
-            if not frame.abs_path:
-                continue
+        # can't fetch source if there's no filename present
+        if not frame.get('abs_path'):
+            return
 
-            source = self.get_source(frame.abs_path, release)
-            if source is None:
-                logger.debug('No source found for %s', frame.abs_path)
-                continue
+        # This might fail but that's okay, we try with a different path a
+        # bit later down the road.
+        source = self.get_source(frame['abs_path'])
 
-            sourcemap_url, sourcemap_view = sourcemaps.get_link(frame.abs_path)
-            if sourcemap_view and frame.colno is None:
-                all_errors.append({
-                    'type': EventError.JS_NO_COLUMN,
-                    'url': expose_url(frame.abs_path),
-                })
-            elif sourcemap_view:
-                last_token = token
+        in_app = None
+        new_frame = dict(frame)
+        raw_frame = dict(frame)
 
-                if is_data_uri(sourcemap_url):
-                    sourcemap_label = frame.abs_path
-                else:
-                    sourcemap_label = sourcemap_url
+        sourcemap_url, sourcemap_view = sourcemaps.get_link(frame['abs_path'])
+        if sourcemap_view and frame.get('colno') is None:
+            all_errors.append({
+                'type': EventError.JS_NO_COLUMN,
+                'url': expose_url(frame['abs_path']),
+            })
+        elif sourcemap_view:
+            last_token = token
 
-                sourcemap_label = expose_url(sourcemap_label)
+            if is_data_uri(sourcemap_url):
+                sourcemap_label = frame['abs_path']
+            else:
+                sourcemap_label = sourcemap_url
 
-                try:
-                    # Errors are 1-indexed in the frames, so we need to -1 to get
-                    # zero-indexed value from tokens.
-                    assert frame.lineno > 0, "line numbers are 1-indexed"
-                    token = sourcemap_view.lookup_token(frame.lineno - 1, frame.colno)
-                except Exception:
-                    token = None
-                    all_errors.append({
-                        'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
-                        'column': frame.colno,
-                        'row': frame.lineno,
-                        'source': frame.abs_path,
-                        'sourcemap': sourcemap_label,
-                    })
+            sourcemap_label = expose_url(sourcemap_label)
 
-                # Store original data in annotation
-                # HACK(dcramer): we stuff things into raw which gets popped off
-                # later when adding the raw_stacktrace attribute.
-                raw_frame = frame.to_json()
-                frame.data = {
-                    'raw': raw_frame,
+            try:
+                # Errors are 1-indexed in the frames, so we need to -1 to get
+                # zero-indexed value from tokens.
+                assert frame['lineno'] > 0, "line numbers are 1-indexed"
+                token = sourcemap_view.lookup_token(
+                    frame['lineno'] - 1, frame['colno'])
+            except Exception:
+                token = None
+                all_errors.append({
+                    'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
+                    'column': frame['colno'],
+                    'row': frame['lineno'],
+                    'source': frame['abs_path'],
                     'sourcemap': sourcemap_label,
-                }
+                })
 
-                sourcemap_applied = True
+            # Store original data in annotation
+            new_frame['data'] = dict(frame.get('data') or {},
+                                     sourcemap=sourcemap_label)
 
-                if token is not None:
-                    abs_path = urljoin(sourcemap_url, token.src)
+            sourcemap_applied = True
 
-                    logger.debug('Mapping compressed source %r to mapping in %r', frame.abs_path, abs_path)
-                    source = self.get_source(abs_path, release)
+            if token is not None:
+                abs_path = urljoin(sourcemap_url, token.src)
 
-                if not source:
-                    errors = cache.get_errors(abs_path)
-                    if errors:
-                        all_errors.extend(errors)
-                    else:
-                        all_errors.append({
-                            'type': EventError.JS_MISSING_SOURCE,
-                            'url': expose_url(abs_path),
-                        })
-
-                if token is not None:
-                    # Token's return zero-indexed lineno's
-                    frame.lineno = token.src_line + 1
-                    frame.colno = token.src_col
-                    # The offending function is always the previous function in the stack
-                    # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
-                    if last_token:
-                        frame.function = last_token.name or frame.function
+                logger.debug('Mapping compressed source %r to mapping in %r',
+                             frame['abs_path'], abs_path)
+                source = self.get_source(abs_path)
+
+            if not source:
+                errors = cache.get_errors(abs_path)
+                if errors:
+                    all_errors.extend(errors)
+                else:
+                    all_errors.append({
+                        'type': EventError.JS_MISSING_SOURCE,
+                        'url': expose_url(abs_path),
+                    })
+
+            if token is not None:
+                # Token's return zero-indexed lineno's
+                new_frame['lineno'] = token.src_line + 1
+                new_frame['colno'] = token.src_col
+                # The offending function is always the previous function in the stack
+                # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
+                if last_token:
+                    new_frame['function'] = last_token.name or frame.get('function')
+                else:
+                    new_frame['function'] = token.name or frame.get('function')
+
+                filename = token.src
+                # special case webpack support
+                # abs_path will always be the full path with webpack:/// prefix.
+                # filename will be relative to that
+                if abs_path.startswith('webpack:'):
+                    filename = abs_path
+                    # webpack seems to use ~ to imply "relative to resolver root"
+                    # which is generally seen for third party deps
+                    # (i.e. node_modules)
+                    if '/~/' in filename:
+                        filename = '~/' + abs_path.split('/~/', 1)[-1]
                     else:
-                        frame.function = token.name or frame.function
-
-                    filename = token.src
-                    # special case webpack support
-                    # abs_path will always be the full path with webpack:/// prefix.
-                    # filename will be relative to that
-                    if abs_path.startswith('webpack:'):
-                        filename = abs_path
-                        # webpack seems to use ~ to imply "relative to resolver root"
-                        # which is generally seen for third party deps
-                        # (i.e. node_modules)
-                        if '/~/' in filename:
-                            filename = '~/' + abs_path.split('/~/', 1)[-1]
-                        else:
-                            filename = filename.split('webpack:///', 1)[-1]
-
-                        # As noted above, '~/' means they're coming from node_modules,
-                        # so these are not app dependencies
-                        if filename.startswith('~/'):
-                            frame.in_app = False
-                        # And conversely, local dependencies start with './'
-                        elif filename.startswith('./'):
-                            frame.in_app = True
-
-                        # Update 'raw' copy to have same in_app status
-                        raw_frame['in_app'] = frame.in_app
-
-                        # We want to explicitly generate a webpack module name
-                        frame.module = generate_module(filename)
-
-                    frame.abs_path = abs_path
-                    frame.filename = filename
-                    if not frame.module and abs_path.startswith(('http:', 'https:', 'webpack:')):
-                        frame.module = generate_module(abs_path)
-
-            elif sourcemap_url:
-                frame.data = {
-                    'sourcemap': expose_url(sourcemap_url),
-                }
-
-            # TODO: theoretically a minified source could point to another mapped, minified source
-            frame.pre_context, frame.context_line, frame.post_context = get_source_context(
-                source=source, lineno=frame.lineno, colno=frame.colno or 0)
-
-            if not frame.context_line and source:
-                all_errors.append({
-                    'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
-                    'column': frame.colno,
-                    'row': frame.lineno,
-                    'source': frame.abs_path,
-                })
-        return all_errors, sourcemap_applied
+                        filename = filename.split('webpack:///', 1)[-1]
+
+                    # As noted above, '~/' means they're coming from node_modules,
+                    # so these are not app dependencies
+                    if filename.startswith('~/'):
+                        in_app = False
+                    # And conversely, local dependencies start with './'
+                    elif filename.startswith('./'):
+                        in_app = True
+
+                    # We want to explicitly generate a webpack module name
+                    new_frame['module'] = generate_module(filename)
+
+                new_frame['abs_path'] = abs_path
+                new_frame['filename'] = filename
+                if not frame.get('module') and abs_path.startswith(
+                        ('http:', 'https:', 'webpack:')):
+                    new_frame['module'] = generate_module(abs_path)
+
+        elif sourcemap_url:
+            new_frame['data'] = dict(new_frame.get('data') or {},
+                                     sourcemap=expose_url(sourcemap_url))
+
+        # TODO: theoretically a minified source could point to
+        # another mapped, minified source
+        changed_frame = self.expand_frame(new_frame, source=source)
+
+        if not new_frame.get('context_line') and source:
+            all_errors.append({
+                'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
+                'column': new_frame['colno'],
+                'row': new_frame['lineno'],
+                'source': new_frame['abs_path'],
+            })
+
+        changed_raw = sourcemap_applied and self.expand_frame(raw_frame)
+        if sourcemap_applied or all_errors or changed_frame or \
+           changed_raw:
+            if in_app is not None:
+                new_frame['in_app'] = in_app
+                raw_frame['in_app'] = in_app
+            return [new_frame], [raw_frame] if changed_raw else None, all_errors
+
+    def expand_frame(self, frame, source=None):
+        if frame.get('lineno') is not None:
+            if source is None:
+                source = self.get_source(frame['abs_path'])
+                if source is None:
+                    logger.debug('No source found for %s', frame['abs_path'])
+                    return False
+
+            frame['pre_context'], frame['context_line'], frame['post_context'] \
+                = get_source_context(source=source, lineno=frame['lineno'],
+                                     colno=frame['colno'] or 0)
+            return True
+        return False
 
-    def get_source(self, filename, release):
+    def get_source(self, filename):
         if filename not in self.cache:
-            self.cache_source(filename, release)
+            self.cache_source(filename)
         return self.cache.get(filename)
 
-    def cache_source(self, filename, release):
+    def cache_source(self, filename):
         sourcemaps = self.sourcemaps
         cache = self.cache
 
@@ -886,7 +824,8 @@ class SourceProcessor(object):
         # TODO: respect cache-control/max-age headers to some extent
         logger.debug('Fetching remote source %r', filename)
         try:
-            result = fetch_file(filename, project=self.project, release=release,
+            result = fetch_file(filename, project=self.project,
+                                release=self.release,
                                 allow_scraping=self.allow_scraping)
         except BadSource as exc:
             cache.add_error(filename, exc.data)
@@ -899,7 +838,8 @@ class SourceProcessor(object):
         if not sourcemap_url:
             return
 
-        logger.debug('Found sourcemap %r for minified script %r', sourcemap_url[:256], result.url)
+        logger.debug('Found sourcemap %r for minified script %r',
+                     sourcemap_url[:256], result.url)
         sourcemaps.link(filename, sourcemap_url)
         if sourcemap_url in sourcemaps:
             return
@@ -909,7 +849,7 @@ class SourceProcessor(object):
             sourcemap_view = fetch_sourcemap(
                 sourcemap_url,
                 project=self.project,
-                release=release,
+                release=self.release,
                 allow_scraping=self.allow_scraping,
             )
         except BadSource as exc:
@@ -927,7 +867,7 @@ class SourceProcessor(object):
                     None,
                 )
 
-    def populate_source_cache(self, frames, release):
+    def populate_source_cache(self, frames):
         """
         Fetch all sources that we know are required (being referenced directly
         in frames).
@@ -935,18 +875,17 @@ class SourceProcessor(object):
         pending_file_list = set()
         for f in frames:
             # We can't even attempt to fetch source if abs_path is None
-            if f.abs_path is None:
+            if f.get('abs_path') is None:
                 continue
             # tbh not entirely sure how this happens, but raven-js allows this
             # to be caught. I think this comes from dev consoles and whatnot
             # where there is no page. This just bails early instead of exposing
             # a fetch error that may be confusing.
-            if f.abs_path == '<anonymous>':
+            if f['abs_path'] == '<anonymous>':
                 continue
-            pending_file_list.add(f.abs_path)
+            pending_file_list.add(f['abs_path'])
 
         for idx, filename in enumerate(pending_file_list):
             self.cache_source(
                 filename=filename,
-                release=release,
             )
diff --git a/src/sentry/lang/native/plugin.py b/src/sentry/lang/native/plugin.py
index 9287aa8794..da351d1cb4 100644
--- a/src/sentry/lang/native/plugin.py
+++ b/src/sentry/lang/native/plugin.py
@@ -2,7 +2,6 @@ from __future__ import absolute_import
 
 import os
 import re
-import sys
 import six
 import time
 import logging
@@ -13,11 +12,12 @@ from symsynd.demangle import demangle_symbol
 from sentry.models import Project, EventError
 from sentry.plugins import Plugin2
 from sentry.lang.native.symbolizer import Symbolizer, SymbolicationFailed
-from sentry.lang.native.utils import find_all_stacktraces, \
+from sentry.lang.native.utils import \
     find_apple_crash_report_referenced_images, get_sdk_from_event, \
     find_stacktrace_referenced_images, get_sdk_from_apple_system_info, \
     APPLE_SDK_MAPPING
 from sentry.utils.native import parse_addr
+from sentry.stacktraces import StacktraceProcessor
 
 
 logger = logging.getLogger(__name__)
@@ -73,6 +73,7 @@ def append_error(data, err):
 
 
 def process_posix_signal(data):
+    # XXX: kill me
     signal = data.get('signal', -1)
     signal_name = data.get('name')
     if signal_name is None:
@@ -86,6 +87,7 @@ def process_posix_signal(data):
 
 
 def exception_from_apple_error_or_diagnosis(error, diagnosis=None):
+    # XXX: kill me
     rv = {}
     error = error or {}
 
@@ -136,6 +138,7 @@ def exception_from_apple_error_or_diagnosis(error, diagnosis=None):
 
 
 def is_in_app(frame, app_uuid=None):
+    # XXX: kill me
     if app_uuid is not None:
         frame_uuid = frame.get('uuid')
         if frame_uuid == app_uuid:
@@ -150,6 +153,7 @@ def is_in_app(frame, app_uuid=None):
 
 
 def convert_stacktrace(frames, system=None, notable_addresses=None):
+    # XXX: kill me
     app_uuid = None
     if system:
         app_uuid = system.get('app_uuid')
@@ -339,119 +343,113 @@ def preprocess_apple_crash_event(data):
     return data
 
 
-def resolve_frame_symbols(data):
-    debug_meta = data['debug_meta']
-    debug_images = debug_meta['images']
-    sdk_info = get_sdk_from_event(data)
+class NativeStacktraceProcessor(StacktraceProcessor):
 
-    stacktraces = find_all_stacktraces(data)
-    if not stacktraces:
-        return
-
-    project = Project.objects.get_from_cache(
-        id=data['project'],
-    )
-
-    errors = []
-    referenced_images = find_stacktrace_referenced_images(
-        debug_images, [x[0] for x in stacktraces])
-    sym = Symbolizer(project, debug_images,
-                     referenced_images=referenced_images)
-
-    frame = None
-    idx = -1
-
-    def report_error(exc_type, exc_value, tb):
-        if exc_value.is_user_fixable or exc_value.is_sdk_failure:
-            errors.append({
-                'type': EventError.NATIVE_INTERNAL_FAILURE,
-                'frame': frame,
-                'error': u'frame #%d: %s' % (idx, exc_value)
-            })
-        if not exc_value.is_user_fixable:
-            logger.debug('Failed to symbolicate',
-                         exc_info=(exc_type, exc_value, tb))
-
-    with sym:
-        for stacktrace, container in stacktraces:
-            store_raw = False
-
-            new_frames = list(stacktrace['frames'])
-            for idx, frame in enumerate(stacktrace['frames']):
-                if 'image_addr' not in frame or \
-                   'instruction_addr' not in frame or \
-                   'symbol_addr' not in frame:
-                    continue
-                try:
-                    # Construct a raw frame that is used by the symbolizer
-                    # backend.
-                    raw_frame = {
-                        'object_name': frame.get('package'),
-                        'object_addr': frame['image_addr'],
-                        'instruction_addr': frame['instruction_addr'],
-                        'symbol_addr': frame['symbol_addr'],
-                    }
-                    new_frame = dict(frame)
-
-                    try:
-                        sfrm = sym.symbolize_frame(raw_frame, sdk_info)
-                    except SymbolicationFailed:
-                        report_error(*sys.exc_info())
-                    else:
-                        symbol = sfrm.get('symbol_name') or \
-                            new_frame.get('function') or '<unknown>'
-                        function = demangle_symbol(symbol, simplified=True)
-
-                        new_frame['function'] = function
-
-                        # If we demangled something, store the original in the
-                        # symbol portion of the frame
-                        if function != symbol:
-                            new_frame['symbol'] = symbol
-
-                        new_frame['abs_path'] = sfrm.get('filename') or None
-                        if new_frame['abs_path']:
-                            new_frame['filename'] = posixpath.basename(
-                                new_frame['abs_path'])
-                        if sfrm.get('line') is not None:
-                            new_frame['lineno'] = sfrm['line']
-                        else:
-                            new_frame['instruction_offset'] = \
-                                parse_addr(sfrm['instruction_addr']) - \
-                                parse_addr(sfrm['symbol_addr'])
-                        if sfrm.get('column') is not None:
-                            new_frame['colno'] = sfrm['column']
-                        new_frame['package'] = sfrm['object_name'] \
-                            or new_frame.get('package')
-                        new_frame['symbol_addr'] = '0x%x' % \
-                            parse_addr(sfrm['symbol_addr'])
-                        new_frame['instruction_addr'] = '0x%x' % parse_addr(
-                            sfrm['instruction_addr'])
-
-                    new_frame['in_app'] = sym.is_in_app(raw_frame)
-                    if new_frame != frame:
-                        new_frames[idx] = new_frame
-                        store_raw = True
-                except Exception:
-                    logger.exception('Failed to symbolicate')
-                    errors.append({
-                        'type': EventError.NATIVE_INTERNAL_FAILURE,
-                        'error': 'The symbolicator encountered an internal failure',
-                    })
-
-            # Remember the raw stacktrace.
-            if store_raw and container is not None:
-                container['raw_stacktrace'] = {
-                    'frames': stacktrace['frames'],
-                }
-
-            # Put the new frames in
-            stacktrace['frames'] = new_frames
-
-    if errors:
-        data.setdefault('errors', []).extend(errors)
+    def __init__(self, *args, **kwargs):
+        StacktraceProcessor.__init__(self, *args, **kwargs)
+        debug_meta = self.data.get('debug_meta')
+        if debug_meta:
+            self.available = True
+            self.debug_meta = debug_meta
+            self.sdk_info = get_sdk_from_event(self.data)
+        else:
+            self.available = False
+
+    def close(self):
+        StacktraceProcessor.close(self)
+        self.sym.close()
+
+    def preprocess_related_data(self):
+        if not self.available:
+            return False
+
+        is_debug_build = self.debug_meta.get('is_debug_build')
+        referenced_images = find_stacktrace_referenced_images(
+            self.debug_meta['images'], [
+                x.stacktrace for x in self.stacktrace_infos])
+        self.sym = Symbolizer(self.project, self.debug_meta['images'],
+                              referenced_images=referenced_images,
+                              is_debug_build=is_debug_build)
+
+        # The symbolizer gets a reference to the debug meta's images so
+        # when it resolves the missing vmaddrs it changes them in the data
+        # dict.
+        return self.sym.resolve_missing_vmaddrs()
+
+    def process_frame(self, frame):
+        # XXX: warn on missing availability?
+
+        # Only process frames here that are of supported platforms and
+        # have the mandatory requirements for
+        if not self.available or \
+           self.get_effective_platform(frame) != 'cocoa' or \
+           'image_addr' not in frame or \
+           'instruction_addr' not in frame or \
+           'symbol_addr' not in frame:
+            return None
+
+        errors = []
+
+        # Construct a raw frame that is used by the symbolizer
+        # backend.
+        sym_frame = {
+            'object_name': frame.get('package'),
+            'object_addr': frame['image_addr'],
+            'instruction_addr': frame['instruction_addr'],
+            'symbol_name': frame.get('function'),
+            'symbol_addr': frame['symbol_addr'],
+        }
+        new_frame = dict(frame)
+        raw_frame = dict(frame)
 
-    return data
+        try:
+            sfrm = self.sym.symbolize_frame(sym_frame, self.sdk_info)
+        except SymbolicationFailed as e:
+            if e.is_user_fixable or e.is_sdk_failure:
+                errors.append({
+                    'type': EventError.NATIVE_INTERNAL_FAILURE,
+                    'image_uuid': e.image_uuid,
+                    'image_path': e.image_path,
+                    'image_arch': e.image_arch,
+                    'message': e.message,
+                })
+            else:
+                logger.debug('Failed to symbolicate with native backend',
+                             exc_info=True)
+        else:
+            symbol = sfrm.get('symbol_name') or \
+                new_frame.get('function') or '<unknown>'
+            function = demangle_symbol(symbol, simplified=True)
+
+            new_frame['function'] = function
+
+            # If we demangled something, store the original in the
+            # symbol portion of the frame
+            if function != symbol:
+                new_frame['symbol'] = symbol
+
+            new_frame['abs_path'] = sfrm.get('filename') or None
+            if new_frame['abs_path']:
+                new_frame['filename'] = posixpath.basename(
+                    new_frame['abs_path'])
+            if sfrm.get('line') is not None:
+                new_frame['lineno'] = sfrm['line']
+            else:
+                new_frame['instruction_offset'] = \
+                    parse_addr(sfrm['instruction_addr']) - \
+                    parse_addr(sfrm['symbol_addr'])
+            if sfrm.get('column') is not None:
+                new_frame['colno'] = sfrm['column']
+            new_frame['package'] = sfrm['object_name'] \
+                or new_frame.get('package')
+            new_frame['symbol_addr'] = '0x%x' % \
+                parse_addr(sfrm['symbol_addr'])
+            new_frame['instruction_addr'] = '0x%x' % parse_addr(
+                sfrm['instruction_addr'])
+
+        in_app = self.sym.is_in_app(sym_frame)
+        new_frame['in_app'] = raw_frame['in_app'] = in_app
+        return [new_frame], [raw_frame], errors
 
 
 class NativePlugin(Plugin2):
@@ -461,6 +459,9 @@ class NativePlugin(Plugin2):
         rv = []
         if data.get('sentry.interfaces.AppleCrashReport'):
             rv.append(preprocess_apple_crash_event)
-        if data.get('debug_meta'):
-            rv.append(resolve_frame_symbols)
         return rv
+
+    def get_stacktrace_processors(self, data, stacktrace_infos,
+                                  platforms, **kwargs):
+        if 'cocoa' in platforms:
+            return [NativeStacktraceProcessor]
diff --git a/src/sentry/lang/native/symbolizer.py b/src/sentry/lang/native/symbolizer.py
index 07eeff5ca7..d2d005efc9 100644
--- a/src/sentry/lang/native/symbolizer.py
+++ b/src/sentry/lang/native/symbolizer.py
@@ -3,9 +3,9 @@ from __future__ import absolute_import
 import re
 import six
 
-from symsynd.driver import Driver, SymbolicationError
+from symsynd.driver import Driver, SymbolicationError, normalize_dsym_path
 from symsynd.report import ReportSymbolizer
-from symsynd.macho.arch import get_cpu_name
+from symsynd.macho.arch import get_cpu_name, get_macho_vmaddr
 
 from sentry.lang.native.dsymcache import dsymcache
 from sentry.utils.safe import trim
@@ -14,6 +14,11 @@ from sentry.models import DSymSymbol, EventError
 from sentry.constants import MAX_SYM
 
 
+USER_FIXABLE_ERRORS = (
+    EventError.NATIVE_MISSING_DSYM,
+    EventError.NATIVE_BAD_DSYM,
+    EventError.NATIVE_MISSING_SYMBOL,
+)
 APP_BUNDLE_PATHS = (
     '/var/containers/Bundle/Application/',
     '/private/var/containers/Bundle/Application/',
@@ -28,6 +33,12 @@ _known_app_bundled_frameworks_re = re.compile(r'''(?x)
 SIM_PATH = '/Developer/CoreSimulator/Devices/'
 SIM_APP_PATH = '/Containers/Bundle/Application/'
 
+KNOWN_GARBAGE_SYMBOLS = set([
+    '_mh_execute_header',
+    '<redacted>',
+    '<unknown>',
+])
+
 
 @implements_to_string
 class SymbolicationFailed(Exception):
@@ -38,16 +49,21 @@ class SymbolicationFailed(Exception):
         self.message = six.text_type(message)
         self.type = type
         if image is not None:
-            self.image_uuid = image['uuid']
+            self.image_uuid = image['uuid'].lower()
+            self.image_path = image['name']
             self.image_name = image['name'].rsplit('/', 1)[-1]
+            self.image_arch = get_cpu_name(image['cpu_type'],
+                                           image['cpu_subtype'])
         else:
             self.image_uuid = None
             self.image_name = None
+            self.image_path = None
+            self.image_arch = None
 
     @property
     def is_user_fixable(self):
         """These are errors that a user can fix themselves."""
-        return self.type in ('missing-dsym', 'bad-dsym')
+        return self.type in USER_FIXABLE_ERRORS
 
     @property
     def is_sdk_failure(self):
@@ -113,16 +129,40 @@ def make_symbolizer(project, binary_images, referenced_images=None):
 
 class Symbolizer(object):
 
-    def __init__(self, project, binary_images, referenced_images=None):
+    def __init__(self, project, binary_images, referenced_images=None,
+                 is_debug_build=None):
         self.symsynd_symbolizer = make_symbolizer(
             project, binary_images, referenced_images=referenced_images)
         self.images = dict((img['image_addr'], img) for img in binary_images)
-
-    def __enter__(self):
-        return self.symsynd_symbolizer.driver.__enter__()
-
-    def __exit__(self, *args):
-        return self.symsynd_symbolizer.driver.__exit__(*args)
+        self.is_debug_build = is_debug_build
+
+    def resolve_missing_vmaddrs(self):
+        """When called this changes the vmaddr on all contained images from
+        the information in the dsym files (if there is no vmaddr already).
+        This changes both the image data from the original event submission
+        in the debug meta as well as the image data that the symbolizer uses.
+        """
+        changed_any = False
+
+        loaded_images = self.symsynd_symbolizer.images
+        for image_addr, image in six.iteritems(self.images):
+            if image.get('image_vmaddr') or not image.get('image_addr'):
+                continue
+            image_info = loaded_images.get(image['image_addr'])
+            if not image_info:
+                continue
+            dsym_path = normalize_dsym_path(image_info['dsym_path'])
+            cpu_name = image_info['cpu_name']
+            image_vmaddr = get_macho_vmaddr(dsym_path, cpu_name)
+            if image_vmaddr:
+                image['image_vmaddr'] = image_vmaddr
+                image_info['image_vmaddr'] = image_vmaddr
+                changed_any = True
+
+        return changed_any
+
+    def close(self):
+        self.symsynd_symbolizer.driver.close()
 
     def _process_frame(self, frame, img):
         rv = trim_frame(frame)
@@ -148,15 +188,20 @@ class Symbolizer(object):
             return False
         return True
 
+    def _is_app_bundled_framework(self, frame, img):
+        fn = self._get_frame_package(frame, img)
+        return _known_app_bundled_frameworks_re.search(fn) is not None
+
     def _is_app_frame(self, frame, img):
         if not self._is_app_bundled_frame(frame, img):
             return False
-        fn = self._get_frame_package(frame, img)
-        # Ignore known frameworks
-        match = _known_app_bundled_frameworks_re.search(fn)
-        if match is not None:
+        return not self._is_app_bundled_framework(frame, img)
+
+    def _is_optional_app_bundled_framework(self, frame, img):
+        if not self._is_app_bundled_framework(frame, img):
             return False
-        return True
+        symbol_name = frame.get('symbol_name')
+        return symbol_name and symbol_name not in KNOWN_GARBAGE_SYMBOLS
 
     def _is_simulator_frame(self, frame, img):
         fn = self._get_frame_package(frame, img)
@@ -168,11 +213,12 @@ class Symbolizer(object):
 
     def symbolize_app_frame(self, frame, img):
         if frame['object_addr'] not in self.symsynd_symbolizer.images:
+            if self._is_optional_app_bundled_framework(frame, img):
+                type = EventError.NATIVE_MISSING_OPTIONALLY_BUNDLED_DSYM
+            else:
+                type = EventError.NATIVE_MISSING_DSYM
             raise SymbolicationFailed(
-                type='missing-dsym',
-                message=(
-                    'Frame references a missing dSYM file.'
-                ),
+                type=type,
                 image=img
             )
 
@@ -181,17 +227,14 @@ class Symbolizer(object):
                 frame, silent=False, demangle=False)
         except SymbolicationError as e:
             raise SymbolicationFailed(
-                type='bad-dsym',
-                message='Symbolication failed due to bad dsym: %s' % e,
+                type=EventError.NATIVE_BAD_DSYM,
+                message=six.text_type(e),
                 image=img
             )
 
         if new_frame is None:
             raise SymbolicationFailed(
-                type='missing-symbol',
-                message=(
-                    'Upon symbolication a frame could not be resolved.'
-                ),
+                type=EventError.NATIVE_MISSING_SYMBOL,
                 image=img
             )
 
@@ -203,18 +246,11 @@ class Symbolizer(object):
         if symbol is None:
             # Simulator frames cannot be symbolicated
             if self._is_simulator_frame(frame, img):
-                type = 'simulator-frame'
-                message = 'Cannot symbolicate simulator system frames.'
+                type = EventError.NATIVE_SIMULATOR_FRAME
             else:
-                type = 'missing-system-dsym'
-                message = (
-                    'Attempted to look up system in the system symbols but '
-                    'no symbol could be found.  This might happen with beta '
-                    'releases of SDKs.'
-                )
+                type = EventError.NATIVE_MISSING_SYSTEM_DSYM
             raise SymbolicationFailed(
                 type=type,
-                message=message,
                 image=img
             )
 
@@ -227,11 +263,7 @@ class Symbolizer(object):
         img = self.images.get(frame['object_addr'])
         if img is None:
             raise SymbolicationFailed(
-                type='unknown-image',
-                message=(
-                    'The stacktrace referred to an object at an address '
-                    'that was not registered in the debug meta information.'
-                )
+                type=EventError.NATIVE_UNKNOWN_IMAGE
             )
 
         # If we are dealing with a frame that is not bundled with the app
diff --git a/src/sentry/lang/native/utils.py b/src/sentry/lang/native/utils.py
index 4ae017fe93..8316927b94 100644
--- a/src/sentry/lang/native/utils.py
+++ b/src/sentry/lang/native/utils.py
@@ -57,17 +57,26 @@ def find_stacktrace_referenced_images(debug_images, stacktraces):
 
 def find_all_stacktraces(data):
     """Given a data dictionary from an event this returns all
-    relevant stacktraces in a list.
+    relevant stacktraces in a list.  If a frame contains a raw_stacktrace
+    property it's preferred over the processed one.
     """
     rv = []
 
+    def _probe_for_stacktrace(container):
+        raw = container.get('raw_stacktrace')
+        if raw is not None:
+            rv.append((raw, container))
+        else:
+            processed = container.get('stacktrace')
+            if processed is not None:
+                rv.append((processed, container))
+
     exc_container = data.get('sentry.interfaces.Exception')
     if exc_container:
         for exc in exc_container['values']:
-            stacktrace = exc.get('stacktrace')
-            if stacktrace:
-                rv.append((stacktrace, exc))
+            _probe_for_stacktrace(exc)
 
+    # The legacy stacktrace interface does not support raw stacktraces
     stacktrace = data.get('sentry.interfaces.Stacktrace')
     if stacktrace:
         rv.append((stacktrace, None))
@@ -75,9 +84,7 @@ def find_all_stacktraces(data):
     threads = data.get('threads')
     if threads:
         for thread in threads['values']:
-            stacktrace = thread.get('stacktrace')
-            if stacktrace:
-                rv.append((stacktrace, thread))
+            _probe_for_stacktrace(thread)
 
     return rv
 
diff --git a/src/sentry/models/eventerror.py b/src/sentry/models/eventerror.py
index a516fa85fa..5031bc163f 100644
--- a/src/sentry/models/eventerror.py
+++ b/src/sentry/models/eventerror.py
@@ -39,6 +39,13 @@ class EventError(object):
     NATIVE_NO_CRASHED_THREAD = 'native_no_crashed_thread'
     NATIVE_INTERNAL_FAILURE = 'native_internal_failure'
     NATIVE_NO_SYMSYND = 'native_no_symsynd'
+    NATIVE_BAD_DSYM = 'native_bad_dsym'
+    NATIVE_MISSING_OPTIONALLY_BUNDLED_DSYM = 'native_optionally_bundled_dsym'
+    NATIVE_MISSING_DSYM = 'native_missing_dsym'
+    NATIVE_MISSING_SYSTEM_DSYM = 'native_missing_system_dsym'
+    NATIVE_MISSING_SYMBOL = 'native_missing_symbol'
+    NATIVE_SIMULATOR_FRAME = 'native_simulator_frame'
+    NATIVE_UNKNOWN_IMAGE = 'native_unknown_image'
 
     _messages = {
         INVALID_DATA: u'Discarded invalid value for parameter \'{name}\'',
@@ -61,6 +68,13 @@ class EventError(object):
         NATIVE_NO_CRASHED_THREAD: u'No crashed thread found in crash report',
         NATIVE_INTERNAL_FAILURE: u'Internal failure when attempting to symbolicate: {error}',
         NATIVE_NO_SYMSYND: u'The symbolizer is not configured for this system.',
+        NATIVE_BAD_DSYM: u'The debug symbol file used was broken.',
+        NATIVE_MISSING_OPTIONALLY_BUNDLED_DSYM: u'An optional debug symbol file was missing.',
+        NATIVE_MISSING_DSYM: u'A required debug symbol file was missing.',
+        NATIVE_MISSING_SYSTEM_DSYM: u'A system debug symbol file was missing.',
+        NATIVE_MISSING_SYMBOL: u'Unable to resolve a symbol.',
+        NATIVE_SIMULATOR_FRAME: u'Encountered an unprocessable simulator frame.',
+        NATIVE_UNKNOWN_IMAGE: u'An binary image is referenced that is unknown.'
     }
 
     @classmethod
diff --git a/src/sentry/plugins/base/v2.py b/src/sentry/plugins/base/v2.py
index 219bd34b15..ae70dfe5aa 100644
--- a/src/sentry/plugins/base/v2.py
+++ b/src/sentry/plugins/base/v2.py
@@ -365,6 +365,24 @@ class IPlugin2(local, PluginConfigMixin):
         """
         return []
 
+    def get_stacktrace_processors(self, data, stacktrace_infos,
+                                  platforms, **kwargs):
+        """
+        This works similarly to `get_event_preprocessors` but returns a
+        function that is invoked for all encountered stacktraces in an
+        event.
+
+        Preprocessors should not be returned if there is nothing to
+        do with the event data.
+
+        :::
+
+            def get_stacktrace_processors(self, data, stacktrace_infos,
+                                          platforms, **kwargs):
+                if 'cocoa' in platforms:
+                    return [CocoaProcessor(data, stacktrace_infos)]
+        """
+
     def get_feature_hooks(self, **kwargs):
         """
         Return a list of callables to check for feature status.
diff --git a/src/sentry/search/base.py b/src/sentry/search/base.py
index ac930399d1..89ab8dc315 100644
--- a/src/sentry/search/base.py
+++ b/src/sentry/search/base.py
@@ -27,8 +27,8 @@ class SearchBackend(object):
     def query(self, project, query=None, status=None, tags=None,
               bookmarked_by=None, assigned_to=None, first_release=None,
               sort_by='date', age_from=None, age_to=None,
-              unassigned=None, date_from=None, date_to=None, cursor=None,
-              limit=100):
+              unassigned=None, date_from=None, date_to=None,
+              cursor=None, limit=100):
         """
         The return value should be a CursorResult.
 
diff --git a/src/sentry/search/django/backend.py b/src/sentry/search/django/backend.py
index 130e2fff7f..36bfebf1a7 100644
--- a/src/sentry/search/django/backend.py
+++ b/src/sentry/search/django/backend.py
@@ -81,6 +81,7 @@ class DjangoSearchBackend(SearchBackend):
         engine = get_db_engine('default')
 
         queryset = Group.objects.filter(project=project)
+
         if query:
             # TODO(dcramer): if we want to continue to support search on SQL
             # we should at least optimize this in Postgres so that it does
@@ -92,13 +93,12 @@ class DjangoSearchBackend(SearchBackend):
             )
 
         if status is None:
-            queryset = queryset.exclude(
-                status__in=(
-                    GroupStatus.PENDING_DELETION,
-                    GroupStatus.DELETION_IN_PROGRESS,
-                    GroupStatus.PENDING_MERGE,
-                )
+            status_in = (
+                GroupStatus.PENDING_DELETION,
+                GroupStatus.DELETION_IN_PROGRESS,
+                GroupStatus.PENDING_MERGE,
             )
+            queryset = queryset.exclude(status__in=status_in)
         else:
             queryset = queryset.filter(status=status)
 
diff --git a/src/sentry/stacktraces.py b/src/sentry/stacktraces.py
new file mode 100644
index 0000000000..44a1f3250e
--- /dev/null
+++ b/src/sentry/stacktraces.py
@@ -0,0 +1,217 @@
+from __future__ import absolute_import
+
+import logging
+
+from sentry.models import Project
+from sentry.utils import metrics
+from sentry.utils.safe import safe_execute
+from collections import namedtuple
+
+
+logger = logging.getLogger(__name__)
+
+
+StacktraceInfo = namedtuple('StacktraceInfo', [
+    'stacktrace', 'container', 'platforms'])
+
+
+class StacktraceProcessor(object):
+
+    def __init__(self, data, stacktrace_infos, project=None):
+        self.data = data
+        self.stacktrace_infos = stacktrace_infos
+        if project is None:
+            project = Project.objects.get_from_cache(id=data['project'])
+        self.project = project
+
+    def close(self):
+        pass
+
+    def preprocess_related_data(self):
+        return False
+
+    def get_effective_platform(self, frame):
+        return frame.get('platform') or self.data['platform']
+
+    def process_frame(self, frame):
+        pass
+
+
+def find_stacktraces_in_data(data):
+    """Finds all stracktraces in a given data blob and returns it
+    together with some meta information.
+    """
+    rv = []
+
+    def _report_stack(stacktrace, container):
+        platforms = set()
+        for frame in stacktrace.get('frames') or ():
+            platforms.add(frame.get('platform') or data['platform'])
+        rv.append(StacktraceInfo(
+            stacktrace=stacktrace,
+            container=container,
+            platforms=platforms
+        ))
+
+    exc_container = data.get('sentry.interfaces.Exception')
+    if exc_container:
+        for exc in exc_container['values']:
+            stacktrace = exc.get('stacktrace')
+            if stacktrace:
+                _report_stack(stacktrace, exc)
+
+    stacktrace = data.get('sentry.interfaces.Stacktrace')
+    if stacktrace:
+        _report_stack(stacktrace, None)
+
+    threads = data.get('threads')
+    if threads:
+        for thread in threads['values']:
+            stacktrace = thread.get('stacktrace')
+            if stacktrace:
+                _report_stack(stacktrace, thread)
+
+    return rv
+
+
+def should_process_for_stacktraces(data):
+    from sentry.plugins import plugins
+    infos = find_stacktraces_in_data(data)
+    platforms = set()
+    for info in infos:
+        platforms.update(info.platforms or ())
+    for plugin in plugins.all(version=2):
+        processors = safe_execute(plugin.get_stacktrace_processors,
+                                  data=data, stacktrace_infos=infos,
+                                  platforms=platforms,
+                                  _with_transaction=False)
+        if processors:
+            return True
+    return False
+
+
+def get_processors_for_stacktraces(data, infos):
+    from sentry.plugins import plugins
+
+    platforms = set()
+    for info in infos:
+        platforms.update(info.platforms or ())
+
+    processors = []
+    for plugin in plugins.all(version=2):
+        processors.extend(safe_execute(plugin.get_stacktrace_processors,
+                                       data=data, stacktrace_infos=infos,
+                                       platforms=platforms,
+                                       _with_transaction=False) or ())
+
+    if processors:
+        project = Project.objects.get_from_cache(id=data['project'])
+        processors = [x(data, infos, project) for x in processors]
+
+    return processors
+
+
+def process_single_stacktrace(stacktrace_info, processors):
+    # TODO: associate errors with the frames and processing issues
+    changed_raw = False
+    changed_processed = False
+    raw_frames = []
+    processed_frames = []
+    all_errors = []
+
+    for frame in stacktrace_info.stacktrace['frames']:
+        need_processed_frame = True
+        need_raw_frame = True
+        errors = None
+        for processor in processors:
+            try:
+                rv = processor.process_frame(frame)
+                if rv is None:
+                    continue
+            except Exception:
+                logger.exception('Failed to process frame')
+                continue
+
+            expand_processed, expand_raw, errors = rv or (None, None, None)
+            if expand_processed is not None:
+                processed_frames.extend(expand_processed)
+                changed_processed = True
+                need_processed_frame = False
+
+            if expand_raw is not None:
+                raw_frames.extend(expand_raw)
+                changed_raw = True
+                need_raw_frame = False
+
+            break
+
+        if need_processed_frame:
+            processed_frames.append(frame)
+        if need_raw_frame:
+            raw_frames.append(frame)
+        all_errors.extend(errors or ())
+
+    return (
+        dict(stacktrace_info.stacktrace,
+             frames=processed_frames) if changed_processed else None,
+        dict(stacktrace_info.stacktrace,
+             frames=raw_frames) if changed_raw else None,
+        all_errors,
+    )
+
+
+def get_metrics_key(stacktrace_infos):
+    platforms = set()
+    for info in stacktrace_infos:
+        platforms.update(info.platforms)
+
+    if len(platforms) == 1:
+        platform = next(iter(platforms))
+        if platform == 'javascript':
+            return 'sourcemaps.process'
+        if platform == 'cocoa':
+            return 'dsym.process'
+    return 'mixed.process'
+
+
+def process_stacktraces(data, make_processors=None):
+    infos = find_stacktraces_in_data(data)
+    if make_processors is None:
+        processors = get_processors_for_stacktraces(data, infos)
+    else:
+        processors = make_processors(data, infos)
+
+    # Early out if we have no processors.  We don't want to record a timer
+    # in that case.
+    if not processors:
+        return
+
+    changed = False
+
+    mkey = get_metrics_key(infos)
+
+    with metrics.timer(mkey, instance=data['project']):
+        for processor in processors:
+            if processor.preprocess_related_data():
+                changed = True
+
+        for stacktrace_info in infos:
+            new_stacktrace, raw_stacktrace, errors = process_single_stacktrace(
+                stacktrace_info, processors)
+            if new_stacktrace is not None:
+                stacktrace_info.stacktrace.clear()
+                stacktrace_info.stacktrace.update(new_stacktrace)
+                changed = True
+            if raw_stacktrace is not None and \
+               stacktrace_info.container is not None:
+                stacktrace_info.container['raw_stacktrace'] = raw_stacktrace
+                changed = True
+            if errors:
+                data.setdefault('errors', []).extend(errors)
+                changed = True
+
+        for processor in processors:
+            processor.close()
+
+    if changed:
+        return data
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index d6fe356c85..093e5b2f8e 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -17,10 +17,28 @@ from sentry.cache import default_cache
 from sentry.tasks.base import instrumented_task
 from sentry.utils import metrics
 from sentry.utils.safe import safe_execute
+from sentry.stacktraces import process_stacktraces, \
+    should_process_for_stacktraces
 
 error_logger = logging.getLogger('sentry.errors.events')
 
 
+def should_process(data):
+    """Quick check if processing is needed at all."""
+    from sentry.plugins import plugins
+
+    for plugin in plugins.all(version=2):
+        processors = safe_execute(plugin.get_event_preprocessors, data=data,
+                                  _with_transaction=False)
+        if processors:
+            return True
+
+    if should_process_for_stacktraces(data):
+        return True
+
+    return False
+
+
 @instrumented_task(
     name='sentry.tasks.store.preprocess_event',
     queue='events.preprocess_event',
@@ -28,8 +46,6 @@ error_logger = logging.getLogger('sentry.errors.events')
     soft_time_limit=60,
 )
 def preprocess_event(cache_key=None, data=None, start_time=None, **kwargs):
-    from sentry.plugins import plugins
-
     if cache_key:
         data = default_cache.get(cache_key)
 
@@ -43,16 +59,9 @@ def preprocess_event(cache_key=None, data=None, start_time=None, **kwargs):
         'project': project,
     })
 
-    # Iterate over all plugins looking for processors based on the input data
-    # plugins should yield a processor function only if it actually can operate
-    # on the input data, otherwise it should yield nothing
-    for plugin in plugins.all(version=2):
-        processors = safe_execute(plugin.get_event_preprocessors, data=data, _with_transaction=False)
-        for processor in (processors or ()):
-            # On the first processor found, we just defer to the process_event
-            # queue to handle the actual work.
-            process_event.delay(cache_key=cache_key, start_time=start_time)
-            return
+    if should_process(data):
+        process_event.delay(cache_key=cache_key, start_time=start_time)
+        return
 
     # If we get here, that means the event had no preprocessing needed to be done
     # so we can jump directly to save_event
@@ -81,11 +90,19 @@ def process_event(cache_key, start_time=None, **kwargs):
     Raven.tags_context({
         'project': project,
     })
+    has_changed = False
+
+    # Stacktrace based event processors.  These run before anything else.
+    new_data = process_stacktraces(data)
+    if new_data is not None:
+        has_changed = True
+        data = new_data
 
     # TODO(dcramer): ideally we would know if data changed by default
-    has_changed = False
+    # Default event processors.
     for plugin in plugins.all(version=2):
-        processors = safe_execute(plugin.get_event_preprocessors, data=data, _with_transaction=False)
+        processors = safe_execute(plugin.get_event_preprocessors,
+                                  data=data, _with_transaction=False)
         for processor in (processors or ()):
             result = safe_execute(processor, data)
             if result:
diff --git a/tests/sentry/lang/javascript/test_plugin.py b/tests/sentry/lang/javascript/test_plugin.py
index b68d156cc7..863c6d5490 100644
--- a/tests/sentry/lang/javascript/test_plugin.py
+++ b/tests/sentry/lang/javascript/test_plugin.py
@@ -164,7 +164,7 @@ class JavascriptIntegrationTest(TestCase):
         assert frame.post_context == ['o', ' ', 'w', 'o', 'r']
 
         frame = frame_list[1]
-        assert frame.pre_context is None
+        assert not frame.pre_context
         assert frame.context_line == 'h'
         assert frame.post_context == ['e', 'l', 'l', 'o', ' ']
 
@@ -287,7 +287,7 @@ class JavascriptIntegrationTest(TestCase):
 
         raw_frame_list = exception.values[0].raw_stacktrace.frames
         raw_frame = raw_frame_list[0]
-        assert raw_frame.pre_context == []
+        assert not raw_frame.pre_context
         assert raw_frame.context_line == 'function add(a,b){"use strict";return a+b}function multiply(a,b){"use strict";return a*b}function divide(a,b){"use strict";try{return multip {snip}'
         assert raw_frame.post_context == ['//@ sourceMappingURL=file.sourcemap.js']
         assert raw_frame.lineno == 1
@@ -419,7 +419,7 @@ class JavascriptIntegrationTest(TestCase):
 
         raw_frame_list = exception.values[0].raw_stacktrace.frames
         raw_frame = raw_frame_list[0]
-        assert raw_frame.pre_context == []
+        assert not raw_frame.pre_context
         assert raw_frame.context_line == 'function add(a,b){"use strict";return a+b}'
         assert raw_frame.post_context == [
             'function multiply(a,b){"use strict";return a*b}function divide(a,b){"use strict";try{return multiply(add(a,b),a,b)/c}catch(e){Raven.captureE {snip}',
@@ -650,9 +650,9 @@ class JavascriptIntegrationTest(TestCase):
         frame = frame_list[0]
 
         # no context information ...
-        assert frame.pre_context is None
-        assert frame.context_line is None
-        assert frame.post_context is None
+        assert not frame.pre_context
+        assert not frame.context_line
+        assert not frame.post_context
 
         # ... but line, column numbers are still correctly mapped
         assert frame.lineno == 3
diff --git a/tests/sentry/lang/javascript/test_processor.py b/tests/sentry/lang/javascript/test_processor.py
index 0ea1681c04..400b3741bf 100644
--- a/tests/sentry/lang/javascript/test_processor.py
+++ b/tests/sentry/lang/javascript/test_processor.py
@@ -10,10 +10,9 @@ from libsourcemap import Token
 from mock import patch
 from requests.exceptions import RequestException
 
-from sentry.interfaces.stacktrace import Stacktrace
 from sentry.lang.javascript.processor import (
     BadSource, discover_sourcemap, fetch_sourcemap, fetch_file, generate_module,
-    SourceProcessor, trim_line, UrlResult, fetch_release_file, CannotFetchSource,
+    trim_line, UrlResult, fetch_release_file, CannotFetchSource,
     UnparseableSourcemap,
 )
 from sentry.lang.javascript.errormapping import (
@@ -304,130 +303,72 @@ class TrimLineTest(TestCase):
         assert trim_line(self.long_line, column=9999) == '{snip} gn. It is, in effect, conditioned to prefer bad design, because that is what it lives with. The new becomes threatening, the old reassuring.'
 
 
-class SourceProcessorTest(TestCase):
-    def test_get_stacktraces_returns_stacktrace_interface(self):
-        data = {
-            'message': 'hello',
-            'platform': 'javascript',
-            'sentry.interfaces.Stacktrace': {
-                'frames': [
-                    {
-                        'abs_path': 'http://example.com/foo.js',
-                        'filename': 'foo.js',
-                        'lineno': 4,
-                        'colno': 0,
-                    },
-                    {
-                        'abs_path': 'http://example.com/foo.js',
-                        'filename': 'foo.js',
-                        'lineno': 1,
-                        'colno': 0,
-                    },
-                ],
-            },
-        }
-
-        processor = SourceProcessor(project=self.project)
-        result = processor.get_stacktraces(data)
-        assert len(result) == 1
-        assert type(result[0][1]) is Stacktrace
-
-    def test_get_stacktraces_returns_exception_interface(self):
-        data = {
-            'message': 'hello',
-            'platform': 'javascript',
-            'sentry.interfaces.Exception': {
-                'values': [{
-                    'type': 'Error',
-                    'stacktrace': {
-                        'frames': [
-                            {
-                                'abs_path': 'http://example.com/foo.js',
-                                'filename': 'foo.js',
-                                'lineno': 4,
-                                'colno': 0,
-                            },
-                            {
-                                'abs_path': 'http://example.com/foo.js',
-                                'filename': 'foo.js',
-                                'lineno': 1,
-                                'colno': 0,
-                            },
-                        ],
-                    },
-                }],
-            }
-        }
-
-        processor = SourceProcessor(project=self.project)
-        result = processor.get_stacktraces(data)
-        assert len(result) == 1
-        assert type(result[0][1]) is Stacktrace
-
-    def test_get_culprit_is_patched(self):
-        data = {
-            'message': 'hello',
-            'platform': 'javascript',
-            'sentry.interfaces.Exception': {
-                'values': [{
-                    'type': 'Error',
-                    'stacktrace': {
-                        'frames': [
-                            {
-                                'abs_path': 'http://example.com/foo.js',
-                                'filename': 'foo.js',
-                                'lineno': 4,
-                                'colno': 0,
-                                'function': 'thing',
-                            },
-                            {
-                                'abs_path': 'http://example.com/bar.js',
-                                'filename': 'bar.js',
-                                'lineno': 1,
-                                'colno': 0,
-                                'function': 'oops',
-                            },
-                        ],
-                    },
-                }],
-            }
+def test_get_culprit_is_patched():
+    from sentry.lang.javascript.plugin import fix_culprit, generate_modules
+
+    data = {
+        'message': 'hello',
+        'platform': 'javascript',
+        'sentry.interfaces.Exception': {
+            'values': [{
+                'type': 'Error',
+                'stacktrace': {
+                    'frames': [
+                        {
+                            'abs_path': 'http://example.com/foo.js',
+                            'filename': 'foo.js',
+                            'lineno': 4,
+                            'colno': 0,
+                            'function': 'thing',
+                        },
+                        {
+                            'abs_path': 'http://example.com/bar.js',
+                            'filename': 'bar.js',
+                            'lineno': 1,
+                            'colno': 0,
+                            'function': 'oops',
+                        },
+                    ],
+                },
+            }],
         }
-
-        processor = SourceProcessor(project=self.project)
-        result = processor.process(data)
-        assert result['culprit'] == 'bar in oops'
-
-    def test_ensure_module_names(self):
-        data = {
-            'message': 'hello',
-            'platform': 'javascript',
-            'sentry.interfaces.Exception': {
-                'values': [{
-                    'type': 'Error',
-                    'stacktrace': {
-                        'frames': [
-                            {
-                                'filename': 'foo.js',
-                                'lineno': 4,
-                                'colno': 0,
-                                'function': 'thing',
-                            },
-                            {
-                                'abs_path': 'http://example.com/foo/bar.js',
-                                'filename': 'bar.js',
-                                'lineno': 1,
-                                'colno': 0,
-                                'function': 'oops',
-                            },
-                        ],
-                    },
-                }],
-            }
+    }
+    generate_modules(data)
+    fix_culprit(data)
+    assert data['culprit'] == 'bar in oops'
+
+
+def test_ensure_module_names():
+    from sentry.lang.javascript.plugin import generate_modules
+    data = {
+        'message': 'hello',
+        'platform': 'javascript',
+        'sentry.interfaces.Exception': {
+            'values': [{
+                'type': 'Error',
+                'stacktrace': {
+                    'frames': [
+                        {
+                            'filename': 'foo.js',
+                            'lineno': 4,
+                            'colno': 0,
+                            'function': 'thing',
+                        },
+                        {
+                            'abs_path': 'http://example.com/foo/bar.js',
+                            'filename': 'bar.js',
+                            'lineno': 1,
+                            'colno': 0,
+                            'function': 'oops',
+                        },
+                    ],
+                },
+            }],
         }
-        processor = SourceProcessor(project=self.project)
-        result = processor.process(data)
-        exc = result['sentry.interfaces.Exception']['values'][0]
-        assert exc['stacktrace']['frames'][1]['module'] == 'foo/bar'
+    }
+    generate_modules(data)
+    exc = data['sentry.interfaces.Exception']['values'][0]
+    assert exc['stacktrace']['frames'][1]['module'] == 'foo/bar'
 
 
 class ErrorMappingTest(TestCase):
diff --git a/tests/sentry/lang/native/test_plugin.py b/tests/sentry/lang/native/test_plugin.py
index b9d7dc8e97..a21783485e 100644
--- a/tests/sentry/lang/native/test_plugin.py
+++ b/tests/sentry/lang/native/test_plugin.py
@@ -101,7 +101,7 @@ class BasicResolvingIntegrationTest(TestCase):
             "sentry.interfaces.Exception": {
                 "values": [
                     {
-                        "stacktrace": {
+                        'stacktrace': {
                             "frames": [
                                 {
                                     "function": "<redacted>",
@@ -174,7 +174,7 @@ class BasicResolvingIntegrationTest(TestCase):
                 "values": [
                     {
                         "id": 39,
-                        "stacktrace": {
+                        'stacktrace': {
                             "frames": [
                                 {
                                     "in_app": False,
diff --git a/tests/sentry/lang/native/test_processor.py b/tests/sentry/lang/native/test_processor.py
index 7d4b17a50f..a2318e7de6 100644
--- a/tests/sentry/lang/native/test_processor.py
+++ b/tests/sentry/lang/native/test_processor.py
@@ -3,7 +3,8 @@ from __future__ import absolute_import
 from mock import patch
 
 from sentry.testutils import TestCase
-from sentry.lang.native.plugin import resolve_frame_symbols
+from sentry.lang.native.plugin import NativeStacktraceProcessor
+from sentry.stacktraces import process_stacktraces
 
 
 OBJECT_NAME = (
@@ -164,7 +165,10 @@ class BasicResolvingFileTest(TestCase):
             }
         }
 
-        resolve_frame_symbols(event_data)
+        def make_processors(data, infos):
+            return [NativeStacktraceProcessor(data, infos)]
+        event_data = process_stacktraces(
+            event_data, make_processors=make_processors)
 
         bt = event_data['sentry.interfaces.Exception']['values'][0]['stacktrace']
         frames = bt['frames']
diff --git a/tests/sentry/tasks/test_store.py b/tests/sentry/tasks/test_store.py
index 6aed4e83e8..9d77344f84 100644
--- a/tests/sentry/tasks/test_store.py
+++ b/tests/sentry/tasks/test_store.py
@@ -13,12 +13,19 @@ class BasicPreprocessorPlugin(Plugin2):
             del data['extra']
             return data
 
+        def put_on_hold(data):
+            data['unprocessed'] = True
+            return data
+
         if data.get('platform') == 'mattlang':
             return [remove_extra, lambda x: None]
 
         if data.get('platform') == 'noop':
             return [lambda data: data]
 
+        if data.get('platform') == 'holdmeclose':
+            return [put_on_hold]
+
         return []
 
     def is_enabled(self, project=None):
@@ -113,3 +120,33 @@ class StoreTasksTest(PluginTestCase):
         mock_save_event.delay.assert_called_once_with(
             cache_key='e:1', data=None, start_time=1,
         )
+
+    @mock.patch('sentry.tasks.store.save_event')
+    @mock.patch('sentry.tasks.store.default_cache')
+    def test_process_event_unprocessed(self, mock_default_cache, mock_save_event):
+        project = self.create_project()
+
+        data = {
+            'project': project.id,
+            'platform': 'holdmeclose',
+            'message': 'test',
+            'extra': {'foo': 'bar'},
+        }
+
+        mock_default_cache.get.return_value = data
+
+        process_event(cache_key='e:1', start_time=1)
+
+        mock_default_cache.set.assert_called_once_with(
+            'e:1', {
+                'project': project.id,
+                'platform': 'holdmeclose',
+                'message': 'test',
+                'extra': {'foo': 'bar'},
+                'unprocessed': True,
+            }, 3600
+        )
+
+        mock_save_event.delay.assert_called_once_with(
+            cache_key='e:1', data=None, start_time=1,
+        )
diff --git a/tests/sentry/test_stacktraces.py b/tests/sentry/test_stacktraces.py
new file mode 100644
index 0000000000..33e625a8cf
--- /dev/null
+++ b/tests/sentry/test_stacktraces.py
@@ -0,0 +1,63 @@
+from __future__ import absolute_import
+
+from sentry.stacktraces import find_stacktraces_in_data
+
+
+def test_stacktraces_basics():
+    data = {
+        'message': 'hello',
+        'platform': 'javascript',
+        'sentry.interfaces.Stacktrace': {
+            'frames': [
+                {
+                    'abs_path': 'http://example.com/foo.js',
+                    'filename': 'foo.js',
+                    'lineno': 4,
+                    'colno': 0,
+                },
+                {
+                    'abs_path': 'http://example.com/foo.js',
+                    'filename': 'foo.js',
+                    'lineno': 1,
+                    'colno': 0,
+                },
+            ],
+        },
+    }
+
+    infos = find_stacktraces_in_data(data)
+    assert len(infos) == 1
+    assert len(infos[0].stacktrace['frames']) == 2
+    assert infos[0].platforms == set(['javascript'])
+
+
+def test_get_stacktraces_returns_exception_interface():
+    data = {
+        'message': 'hello',
+        'platform': 'javascript',
+        'sentry.interfaces.Exception': {
+            'values': [{
+                'type': 'Error',
+                'stacktrace': {
+                    'frames': [
+                        {
+                            'abs_path': 'http://example.com/foo.js',
+                            'filename': 'foo.js',
+                            'lineno': 4,
+                            'colno': 0,
+                        },
+                        {
+                            'abs_path': 'http://example.com/foo.js',
+                            'filename': 'foo.js',
+                            'lineno': 1,
+                            'colno': 0,
+                        },
+                    ],
+                },
+            }],
+        }
+    }
+
+    infos = find_stacktraces_in_data(data)
+    assert len(infos) == 1
+    assert len(infos[0].stacktrace['frames']) == 2
