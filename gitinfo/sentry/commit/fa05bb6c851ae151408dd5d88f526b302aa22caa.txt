commit fa05bb6c851ae151408dd5d88f526b302aa22caa
Author: Manu <manu@sentry.io>
Date:   Tue Aug 20 12:35:45 2019 -0700

    fix: Do chunking of prepare_project_series (#14442)
    
    * fix: Do chunking of prepare_project_series
    
    * CR: reuse code, use single underscore
    
    * list? We already have a list.

diff --git a/src/sentry/tasks/reports.py b/src/sentry/tasks/reports.py
index cf31fd43a4..6a30d6345d 100644
--- a/src/sentry/tasks/reports.py
+++ b/src/sentry/tasks/reports.py
@@ -160,30 +160,30 @@ def merge_series(target, other, function=operator.add):
     return results
 
 
+def _query_tsdb_chunked(func, issue_ids, start, stop, rollup):
+    combined = {}
+
+    for chunk in chunked(issue_ids, BATCH_SIZE):
+        combined.update(func(tsdb.models.group, chunk, start, stop, rollup=rollup))
+
+    return combined
+
+
 def prepare_project_series(start__stop, project, rollup=60 * 60 * 24):
     start, stop = start__stop
     resolution, series = tsdb.get_optimal_rollup_series(start, stop, rollup)
     assert resolution == rollup, "resolution does not match requested value"
     clean = functools.partial(clean_series, start, stop, rollup)
+    issue_ids = project.group_set.filter(
+        status=GroupStatus.RESOLVED, resolved_at__gte=start, resolved_at__lt=stop
+    ).values_list("id", flat=True)
+
+    tsdb_range = _query_tsdb_chunked(tsdb.get_range, issue_ids, start, stop, rollup)
+
     return merge_series(
         reduce(
             merge_series,
-            map(
-                clean,
-                tsdb.get_range(
-                    tsdb.models.group,
-                    list(
-                        project.group_set.filter(
-                            status=GroupStatus.RESOLVED,
-                            resolved_at__gte=start,
-                            resolved_at__lt=stop,
-                        ).values_list("id", flat=True)
-                    ),
-                    start,
-                    stop,
-                    rollup=rollup,
-                ).values(),
-            ),
+            map(clean, tsdb_range.values()),
             clean([(timestamp, 0) for timestamp in series]),
         ),
         clean(
@@ -215,15 +215,6 @@ def prepare_project_aggregates(ignore__stop, project):
     ]
 
 
-def get_event_counts(issue_ids, start, stop, rollup):
-    combined = {}
-
-    for chunk in chunked(issue_ids, BATCH_SIZE):
-        combined.update(tsdb.get_sums(tsdb.models.group, chunk, start, stop, rollup=rollup))
-
-    return combined
-
-
 def prepare_project_issue_summaries(interval, project):
     start, stop = interval
 
@@ -257,7 +248,9 @@ def prepare_project_issue_summaries(interval, project):
     )
 
     rollup = 60 * 60 * 24
-    event_counts = get_event_counts(new_issue_ids | reopened_issue_ids, start, stop, rollup)
+    event_counts = _query_tsdb_chunked(
+        tsdb.get_sums, new_issue_ids | reopened_issue_ids, start, stop, rollup
+    )
 
     new_issue_count = sum(event_counts[id] for id in new_issue_ids)
     reopened_issue_count = sum(event_counts[id] for id in reopened_issue_ids)
diff --git a/tests/sentry/tasks/test_reports.py b/tests/sentry/tasks/test_reports.py
index c4b887133a..207a754176 100644
--- a/tests/sentry/tasks/test_reports.py
+++ b/tests/sentry/tasks/test_reports.py
@@ -6,10 +6,12 @@ from datetime import datetime, timedelta
 import mock
 import pytest
 import pytz
+import copy
 from django.core import mail
+from django.utils import timezone
 
 from sentry.app import tsdb
-from sentry.models import Project, UserOption
+from sentry.models import Project, UserOption, GroupStatus
 from sentry.tasks.reports import (
     DISABLED_ORGANIZATIONS_USER_OPTION_KEY,
     Report,
@@ -30,9 +32,12 @@ from sentry.tasks.reports import (
     safe_add,
     user_subscribed_to_organization_reports,
     prepare_project_issue_summaries,
+    prepare_project_series,
 )
 from sentry.testutils.cases import TestCase, SnubaTestCase
-from sentry.utils.dates import to_datetime, to_timestamp
+from sentry.testutils.factories import DEFAULT_EVENT_DATA
+from sentry.utils.dates import to_datetime, to_timestamp, floor_to_utc_day
+
 from six.moves import xrange
 
 
@@ -259,13 +264,7 @@ class ReportTestCase(TestCase, SnubaTestCase):
         assert user_subscribed_to_organization_reports(user, organization) is False
 
     @mock.patch("sentry.tasks.reports.BATCH_SIZE", 1)
-    def test_paginates_and_reassumbles_result(self):
-        import copy
-        from datetime import timedelta
-        from django.utils import timezone
-
-        from sentry.testutils.factories import DEFAULT_EVENT_DATA
-
+    def test_paginates_project_issue_summaries_and_reassembles_result(self):
         self.login_as(user=self.user)
 
         now = timezone.now()
@@ -295,3 +294,53 @@ class ReportTestCase(TestCase, SnubaTestCase):
         )
 
         assert prepare_project_issue_summaries([two_min_ago, now], self.project) == [2, 0, 0]
+
+    @mock.patch("sentry.tasks.reports.BATCH_SIZE", 1)
+    def test_paginates_project_series_and_reassembles_result(self):
+        self.login_as(user=self.user)
+
+        now = timezone.now()
+        two_days_ago = now - timedelta(days=2)
+        three_days_ago = (now - timedelta(days=3)).isoformat()[:19]
+        seven_days_back = now - timedelta(days=7)
+
+        event1 = self.store_event(
+            data={
+                "event_id": "a" * 32,
+                "message": "message",
+                "timestamp": three_days_ago,
+                "stacktrace": copy.deepcopy(DEFAULT_EVENT_DATA["stacktrace"]),
+                "fingerprint": ["group-1"],
+            },
+            project_id=self.project.id,
+        )
+
+        event2 = self.store_event(
+            data={
+                "event_id": "b" * 32,
+                "message": "message",
+                "timestamp": three_days_ago,
+                "stacktrace": copy.deepcopy(DEFAULT_EVENT_DATA["stacktrace"]),
+                "fingerprint": ["group-2"],
+            },
+            project_id=self.project.id,
+        )
+
+        group1 = event1.group
+        group2 = event2.group
+
+        group1.status = GroupStatus.RESOLVED
+        group1.resolved_at = two_days_ago
+        group1.save()
+
+        group2.status = GroupStatus.RESOLVED
+        group2.resolved_at = two_days_ago
+        group2.save()
+
+        response = prepare_project_series(
+            [floor_to_utc_day(seven_days_back), floor_to_utc_day(now)], self.project
+        )
+
+        assert any(
+            map(lambda x: x[1] == (2, 0), response)
+        ), "must show two issues resolved in one rollup window"
