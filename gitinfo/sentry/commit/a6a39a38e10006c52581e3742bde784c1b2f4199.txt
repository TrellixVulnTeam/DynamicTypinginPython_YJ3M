commit a6a39a38e10006c52581e3742bde784c1b2f4199
Author: Matt Robenolt <matt@ydekproductions.com>
Date:   Mon Oct 10 09:05:09 2016 -0700

    tasks: split events queue into preprocess_event and save_event queues (#4291)
    
    This will allow us to allocate workers dedicated for saves vs
    preprocessing. Right now, tasks flow into and out of the same queue for
    these two phases. This results in confusion when consuming a backlog
    becasue as the rate of consuming increases, the rate on "events" also
    increases, making it hard to diagnose the actual health of catching up
    on a backlog without visibility into seeing how many jobs are in each
    phase.
    
    Also, for most events, non-{js,dsym}, preprocess_event is considerably
    faster compared to save_event. This has an effect on our end-to-end
    latency when we're near or at capacity since save_events aren't
    otherwise taking priority to preprocess_events. This change will allow
    us to allocate priorities and monitor more effectively the situation at
    hand.
    
    Lastly, there's a compatibility shim in place for end-users that may be
    doing `run worker -Q events` that will fan out and actually subscribe to
    all 3 (for now, will remove old 'events' in a follow up) to maintain
    current and expected behavior. Likely htis only affects us and helps
    during our transition.

diff --git a/CHANGES b/CHANGES
index 8a45cce10e..eac22903b4 100644
--- a/CHANGES
+++ b/CHANGES
@@ -2,6 +2,7 @@ Version 8.10 (Unreleased)
 -------------------------
 
 - Removed previously deprecated ``sentry celery`` command.
+- Split the ``events`` queue into ``events.{preprocess,save}_event``.
 
 Version 8.9
 -----------
diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index a0564fc3a9..5a2ecde47c 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -405,6 +405,8 @@ CELERY_QUEUES = [
     Queue('digests.scheduling', routing_key='digests.scheduling'),
     Queue('email', routing_key='email'),
     Queue('events', routing_key='events'),
+    Queue('events.preprocess_event', routing_key='events.preprocess_event'),
+    Queue('events.save_event', routing_key='events.save_event'),
     Queue('merge', routing_key='merge'),
     Queue('options', routing_key='options'),
     Queue('reports.deliver', routing_key='reports.deliver'),
diff --git a/src/sentry/runner/commands/run.py b/src/sentry/runner/commands/run.py
index ab7c93800e..e7ae8eb5ab 100644
--- a/src/sentry/runner/commands/run.py
+++ b/src/sentry/runner/commands/run.py
@@ -35,15 +35,25 @@ class AddressParamType(click.ParamType):
 Address = AddressParamType()
 
 
-class SetType(click.ParamType):
+class QueueSetType(click.ParamType):
     name = 'text'
 
     def convert(self, value, param, ctx):
         if value is None:
             return None
-        return frozenset(value.split(','))
+        # Providing a compatibility with splitting
+        # the `events` queue until multiple queues
+        # without the need to explicitly add them.
+        queues = set()
+        for queue in value.split(','):
+            queues.add(queue)
+            if queue == 'events':
+                queues.add('events.preprocess_event')
+                queues.add('events.save_event')
+        return frozenset(queues)
 
-Set = SetType()
+
+QueueSet = QueueSetType()
 
 
 @click.group()
@@ -109,11 +119,11 @@ def smtp(bind, upgrade, noinput):
 @click.option('--hostname', '-n', help=(
     'Set custom hostname, e.g. \'w1.%h\'. Expands: %h'
     '(hostname), %n (name) and %d, (domain).'))
-@click.option('--queues', '-Q', type=Set, help=(
+@click.option('--queues', '-Q', type=QueueSet, help=(
     'List of queues to enable for this worker, separated by '
     'comma. By default all configured queues are enabled. '
     'Example: -Q video,image'))
-@click.option('--exclude-queues', '-X', type=Set)
+@click.option('--exclude-queues', '-X', type=QueueSet)
 @click.option('--concurrency', '-c', default=cpu_count(), help=(
     'Number of child processes processing the queue. The '
     'default is the number of CPUs available on your '
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index 9510644b1b..397c2e38b1 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -23,7 +23,7 @@ error_logger = logging.getLogger('sentry.errors.events')
 
 @instrumented_task(
     name='sentry.tasks.store.preprocess_event',
-    queue='events',
+    queue='events.preprocess_event',
     time_limit=65,
     soft_time_limit=60,
 )
@@ -65,7 +65,7 @@ def preprocess_event(cache_key=None, data=None, start_time=None, **kwargs):
 
 @instrumented_task(
     name='sentry.tasks.store.save_event',
-    queue='events')
+    queue='events.save_event')
 def save_event(cache_key=None, data=None, start_time=None, **kwargs):
     """
     Saves an event to the database.
