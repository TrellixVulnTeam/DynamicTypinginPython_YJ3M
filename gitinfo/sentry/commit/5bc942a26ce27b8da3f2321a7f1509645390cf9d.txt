commit 5bc942a26ce27b8da3f2321a7f1509645390cf9d
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Thu Aug 16 00:10:10 2018 +0200

    feat(minidump): Optionally add minidumps as event attachments (#9388)
    
    Third time is the charm

diff --git a/src/sentry/api/endpoints/organization_details.py b/src/sentry/api/endpoints/organization_details.py
index 460eb9721d..1ab2d91e01 100644
--- a/src/sentry/api/endpoints/organization_details.py
+++ b/src/sentry/api/endpoints/organization_details.py
@@ -35,6 +35,7 @@ ORG_OPTIONS = (
     ('dataScrubberDefaults', 'sentry:require_scrub_defaults', bool),
     ('sensitiveFields', 'sentry:sensitive_fields', list),
     ('safeFields', 'sentry:safe_fields', list),
+    ('storeCrashReports', 'sentry:store_crash_reports', bool),
     ('scrubIPAddresses', 'sentry:require_scrub_ip_address', bool),
     ('scrapeJavaScript', 'sentry:scrape_javascript', bool),
 )
@@ -84,6 +85,7 @@ class OrganizationSerializer(serializers.Serializer):
     dataScrubberDefaults = serializers.BooleanField(required=False)
     sensitiveFields = ListField(child=serializers.CharField(), required=False)
     safeFields = ListField(child=serializers.CharField(), required=False)
+    storeCrashReports = serializers.BooleanField(required=False)
     scrubIPAddresses = serializers.BooleanField(required=False)
     scrapeJavaScript = serializers.BooleanField(required=False)
     isEarlyAdopter = serializers.BooleanField(required=False)
diff --git a/src/sentry/api/endpoints/project_details.py b/src/sentry/api/endpoints/project_details.py
index 57a770d67d..6f0f302f45 100644
--- a/src/sentry/api/endpoints/project_details.py
+++ b/src/sentry/api/endpoints/project_details.py
@@ -93,6 +93,7 @@ class ProjectAdminSerializer(ProjectMemberSerializer):
     dataScrubberDefaults = serializers.BooleanField(required=False)
     sensitiveFields = ListField(child=serializers.CharField(), required=False)
     safeFields = ListField(child=serializers.CharField(), required=False)
+    storeCrashReports = serializers.BooleanField(required=False)
     scrubIPAddresses = serializers.BooleanField(required=False)
     scrapeJavaScript = serializers.BooleanField(required=False)
     allowedDomains = ListField(child=OriginField(), required=False)
@@ -349,6 +350,9 @@ class ProjectDetailsEndpoint(ProjectEndpoint):
         if result.get('safeFields') is not None:
             if project.update_option('sentry:safe_fields', result['safeFields']):
                 changed_proj_settings['sentry:safe_fields'] = result['safeFields']
+        if result.get('storeCrashReports') is not None:
+            if project.update_option('sentry:store_crash_reports', result['storeCrashReports']):
+                changed_proj_settings['sentry:store_crash_reports'] = result['storeCrashReports']
         if 'defaultEnvironment' in result:
             if result['defaultEnvironment'] is None:
                 project.delete_option('sentry:default_environment')
@@ -401,6 +405,9 @@ class ProjectDetailsEndpoint(ProjectEndpoint):
                     'sentry:safe_fields',
                     [s.strip().lower() for s in options['sentry:safe_fields']]
                 )
+            if 'sentry:store_crash_reports' in options:
+                project.update_option('sentry:store_crash_reports', bool(
+                    options['sentry:store_crash_reports']))
             if 'sentry:sensitive_fields' in options:
                 project.update_option(
                     'sentry:sensitive_fields',
diff --git a/src/sentry/api/serializers/models/organization.py b/src/sentry/api/serializers/models/organization.py
index 7e68fac2af..61aa146680 100644
--- a/src/sentry/api/serializers/models/organization.py
+++ b/src/sentry/api/serializers/models/organization.py
@@ -186,6 +186,7 @@ class DetailedOrganizationSerializer(OrganizationSerializer):
             'dataScrubberDefaults': bool(obj.get_option('sentry:require_scrub_defaults', False)),
             'sensitiveFields': obj.get_option('sentry:sensitive_fields', None) or [],
             'safeFields': obj.get_option('sentry:safe_fields', None) or [],
+            'storeCrashReports': bool(obj.get_option('sentry:store_crash_reports', False)),
             'scrubIPAddresses': bool(obj.get_option('sentry:require_scrub_ip_address', False)),
             'scrapeJavaScript': bool(obj.get_option('sentry:scrape_javascript', True)),
         })
diff --git a/src/sentry/api/serializers/models/project.py b/src/sentry/api/serializers/models/project.py
index 8b3fb7730f..2bd5e14cc6 100644
--- a/src/sentry/api/serializers/models/project.py
+++ b/src/sentry/api/serializers/models/project.py
@@ -322,6 +322,7 @@ class DetailedProjectSerializer(ProjectWithTeamSerializer):
             'sentry:scrub_data',
             'sentry:scrub_defaults',
             'sentry:safe_fields',
+            'sentry:store_crash_reports',
             'sentry:sensitive_fields',
             'sentry:csp_ignored_sources_defaults',
             'sentry:csp_ignored_sources',
@@ -465,6 +466,7 @@ class DetailedProjectSerializer(ProjectWithTeamSerializer):
                 bool(attrs['options'].get('sentry:scrub_defaults', True)),
                 'safeFields':
                 attrs['options'].get('sentry:safe_fields', []),
+                'storeCrashReports': bool(attrs['options'].get('sentry:store_crash_reports', False)),
                 'sensitiveFields':
                 attrs['options'].get('sentry:sensitive_fields', []),
                 'subjectTemplate':
diff --git a/src/sentry/attachments/__init__.py b/src/sentry/attachments/__init__.py
new file mode 100644
index 0000000000..7e41b029b2
--- /dev/null
+++ b/src/sentry/attachments/__init__.py
@@ -0,0 +1,12 @@
+from __future__ import absolute_import
+
+__all__ = ['attachment_cache', 'CachedAttachment']
+
+from django.conf import settings
+
+from sentry.utils.imports import import_string
+
+from .base import CachedAttachment
+
+
+attachment_cache = import_string(settings.SENTRY_ATTACHMENTS)(**settings.SENTRY_ATTACHMENTS_OPTIONS)
diff --git a/src/sentry/attachments/base.py b/src/sentry/attachments/base.py
new file mode 100644
index 0000000000..26a62f5a38
--- /dev/null
+++ b/src/sentry/attachments/base.py
@@ -0,0 +1,91 @@
+"""
+sentry.attachments.base
+~~~~~~~~~~~~~~~~~
+
+:copyright: (c) 2010-2014 by the Sentry Team, see AUTHORS for more details.
+:license: BSD, see LICENSE for more details.
+"""
+
+from __future__ import absolute_import
+
+import zlib
+
+
+class CachedAttachment(object):
+    def __init__(self, name=None, content_type=None, type=None, data=None, load=None):
+        if data is None and load is None:
+            raise AttributeError('Missing attachment data')
+
+        self.name = name
+        self.content_type = content_type
+        self.type = type or 'event.attachment'
+
+        self._data = data
+        self._load = load
+
+    @classmethod
+    def from_upload(cls, file, **kwargs):
+        return CachedAttachment(
+            name=file.name,
+            content_type=file.content_type,
+            data=file.read(),
+            **kwargs
+        )
+
+    @property
+    def data(self):
+        if self._data is None and self._load is not None:
+            self._data = self._load()
+
+        return self._data
+
+    def meta(self):
+        return {
+            'name': self.name,
+            'content_type': self.content_type,
+            'type': self.type,
+        }
+
+
+class BaseAttachmentCache(object):
+    def __init__(self, inner, appendix=None):
+        if appendix is None:
+            appendix = 'a'
+        self.appendix = appendix
+        self.inner = inner
+
+    def make_key(self, key):
+        return '{}:{}'.format(key, self.appendix)
+
+    def set(self, key, attachments, timeout=None):
+        key = self.make_key(key)
+        for index, attachment in enumerate(attachments):
+            compressed = zlib.compress(attachment.data)
+            self.inner.set('{}:{}'.format(key, index), compressed, timeout, raw=True)
+
+        meta = [attachment.meta() for attachment in attachments]
+        self.inner.set(key, meta, timeout, raw=False)
+
+    def get(self, key):
+        key = self.make_key(key)
+        result = self.inner.get(key, raw=False)
+        if result is not None:
+            result = [
+                CachedAttachment(
+                    load=lambda index=index: zlib.decompress(
+                        self.inner.get('{}:{}'.format(key, index), raw=True)),
+                    **attachment
+                )
+                for index, attachment in enumerate(result)
+            ]
+        return result
+
+    def delete(self, key):
+        key = self.make_key(key)
+        attachments = self.inner.get(key, raw=False)
+        if attachments is None:
+            return
+
+        for index in range(0, len(attachments)):
+            self.inner.delete('{}:{}'.format(key, index))
+        self.inner.delete(key)
diff --git a/src/sentry/attachments/default.py b/src/sentry/attachments/default.py
new file mode 100644
index 0000000000..3e722ff61d
--- /dev/null
+++ b/src/sentry/attachments/default.py
@@ -0,0 +1,18 @@
+"""
+sentry.attachments.default
+~~~~~~~~~~~~~~~~~~
+
+:copyright: (c) 2010-2014 by the Sentry Team, see AUTHORS for more details.
+:license: BSD, see LICENSE for more details.
+"""
+
+from __future__ import absolute_import
+
+from sentry.cache import default_cache
+
+from .base import BaseAttachmentCache
+
+
+class DefaultAttachmentCache(BaseAttachmentCache):
+    def __init__(self, **options):
+        super(DefaultAttachmentCache, self).__init__(default_cache, **options)
diff --git a/src/sentry/attachments/redis.py b/src/sentry/attachments/redis.py
new file mode 100644
index 0000000000..9d9d4f9b3c
--- /dev/null
+++ b/src/sentry/attachments/redis.py
@@ -0,0 +1,45 @@
+"""
+sentry.attachments.redis
+~~~~~~~~~~~~~~~~~~~~~~~~
+
+:copyright: (c) 2010-2014 by the Sentry Team, see AUTHORS for more details.
+:license: BSD, see LICENSE for more details.
+"""
+
+from __future__ import absolute_import
+
+import logging
+
+from django.conf import settings
+
+from sentry.cache.redis import RedisClusterCache, RbCache
+from .base import BaseAttachmentCache
+
+logger = logging.getLogger(__name__)
+
+
+class RedisClusterAttachmentCache(BaseAttachmentCache):
+    def __init__(self, **options):
+        appendix = options.pop('appendix', None)
+        cluster_id = options.pop('cluster_id', None)
+        if cluster_id is None:
+            cluster_id = getattr(
+                settings,
+                'SENTRY_ATTACHMENTS_REDIS_CLUSTER',
+                'rc-short'
+            )
+        BaseAttachmentCache.__init__(self,
+                                     inner=RedisClusterCache(cluster_id, **options),
+                                     appendix=appendix)
+
+
+class RbAttachmentCache(BaseAttachmentCache):
+    def __init__(self, **options):
+        appendix = options.pop('appendix', None)
+        BaseAttachmentCache.__init__(self,
+                                     inner=RbCache(**options),
+                                     appendix=appendix)
+
+
+# Confusing legacy name for RediscClusterCache
+RedisAttachmentCache = RedisClusterAttachmentCache
diff --git a/src/sentry/cache/base.py b/src/sentry/cache/base.py
index e2d38ece33..babf532b55 100644
--- a/src/sentry/cache/base.py
+++ b/src/sentry/cache/base.py
@@ -28,11 +28,11 @@ class BaseCache(local):
             key,
         )
 
-    def set(self, key, value, timeout, version=None):
+    def set(self, key, value, timeout, version=None, raw=False):
         raise NotImplementedError
 
     def delete(self, key, version=None):
         raise NotImplementedError
 
-    def get(self, key, version=None):
+    def get(self, key, version=None, raw=False):
         raise NotImplementedError
diff --git a/src/sentry/cache/django.py b/src/sentry/cache/django.py
index e0d32ff8da..03182baba7 100644
--- a/src/sentry/cache/django.py
+++ b/src/sentry/cache/django.py
@@ -14,11 +14,11 @@ from .base import BaseCache
 
 
 class DjangoCache(BaseCache):
-    def set(self, key, value, timeout, version=None):
+    def set(self, key, value, timeout, version=None, raw=False):
         cache.set(key, value, timeout, version=version or self.version)
 
     def delete(self, key, version=None):
         cache.delete(key, version=version or self.version)
 
-    def get(self, key, version=None):
+    def get(self, key, version=None, raw=False):
         return cache.get(key, version=version or self.version)
diff --git a/src/sentry/cache/redis.py b/src/sentry/cache/redis.py
index 7ba7625de3..4623839204 100644
--- a/src/sentry/cache/redis.py
+++ b/src/sentry/cache/redis.py
@@ -9,7 +9,7 @@ sentry.cache.redis
 from __future__ import absolute_import
 
 from sentry.utils import json
-from sentry.utils.redis import get_cluster_from_options
+from sentry.utils.redis import get_cluster_from_options, redis_clusters
 
 from .base import BaseCache
 
@@ -18,19 +18,17 @@ class ValueTooLarge(Exception):
     pass
 
 
-class RedisCache(BaseCache):
+class CommonRedisCache(BaseCache):
     key_expire = 60 * 60  # 1 hour
     max_size = 50 * 1024 * 1024  # 50MB
 
-    def __init__(self, **options):
-        self.cluster, options = get_cluster_from_options('SENTRY_CACHE_OPTIONS', options)
-        self.client = self.cluster.get_routing_client()
-
-        super(RedisCache, self).__init__(**options)
+    def __init__(self, client, **options):
+        self.client = client
+        BaseCache.__init__(self, **options)
 
-    def set(self, key, value, timeout, version=None):
+    def set(self, key, value, timeout, version=None, raw=False):
         key = self.make_key(key, version=version)
-        v = json.dumps(value)
+        v = json.dumps(value) if not raw else value
         if len(v) > self.max_size:
             raise ValueTooLarge('Cache key too large: %r %r' % (key, len(v)))
         if timeout:
@@ -42,9 +40,29 @@ class RedisCache(BaseCache):
         key = self.make_key(key, version=version)
         self.client.delete(key)
 
-    def get(self, key, version=None):
+    def get(self, key, version=None, raw=False):
         key = self.make_key(key, version=version)
         result = self.client.get(key)
-        if result is not None:
+        if result is not None and not raw:
             result = json.loads(result)
         return result
+
+
+class RbCache(CommonRedisCache):
+
+    def __init__(self, **options):
+        cluster, options = get_cluster_from_options(
+            'SENTRY_CACHE_OPTIONS', options)
+        client = cluster.get_routing_client()
+        CommonRedisCache.__init__(self, client, **options)
+
+
+# Confusing legacy name for RbCache.  We don't actually have a pure redis cache
+RedisCache = RbCache
+
+
+class RedisClusterCache(CommonRedisCache):
+
+    def __init__(self, cluster_id, **options):
+        client = redis_clusters.get(cluster_id)
+        CommonRedisCache.__init__(self, client=client, **options)
diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 4185da1f1c..07764d55fe 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -924,6 +924,10 @@ SENTRY_BUFFER_OPTIONS = {}
 SENTRY_CACHE = None
 SENTRY_CACHE_OPTIONS = {}
 
+# Attachment blob cache backend
+SENTRY_ATTACHMENTS = 'sentry.attachments.default.DefaultAttachmentCache'
+SENTRY_ATTACHMENTS_OPTIONS = {}
+
 # The internal Django cache is still used in many places
 # TODO(dcramer): convert uses over to Sentry's backend
 CACHES = {
diff --git a/src/sentry/coreapi.py b/src/sentry/coreapi.py
index d2f20bc583..66f19a5c94 100644
--- a/src/sentry/coreapi.py
+++ b/src/sentry/coreapi.py
@@ -25,6 +25,7 @@ from six import BytesIO
 from time import time
 
 from sentry import filters
+from sentry.attachments import attachment_cache
 from sentry.cache import default_cache
 from sentry.interfaces.base import get_interface
 from sentry.event_manager import EventManager
@@ -348,14 +349,25 @@ class ClientApiHelper(object):
         if 'sdk' in data:
             data['sdk'].pop('client_ip', None)
 
-    def insert_data_to_database(self, data, start_time=None, from_reprocessing=False):
+    def insert_data_to_database(self, data, start_time=None,
+                                from_reprocessing=False, attachments=None):
         if start_time is None:
             start_time = time()
+
         # we might be passed some sublcasses of dict that fail dumping
         if isinstance(data, DOWNGRADE_DATA_TYPES):
             data = dict(data.items())
+
+        cache_timeout = 3600
         cache_key = 'e:{1}:{0}'.format(data['project'], data['event_id'])
-        default_cache.set(cache_key, data, timeout=3600)
+        default_cache.set(cache_key, data, cache_timeout)
+
+        # Attachments will be empty or None if the "event-attachments" feature
+        # is turned off. For native crash reports it will still contain the
+        # crash dump (e.g. minidump) so we can load it during processing.
+        if attachments is not None:
+            attachment_cache.set(cache_key, attachments, cache_timeout)
+
         task = from_reprocessing and \
             preprocess_event_from_reprocessing or preprocess_event
         task.delay(cache_key=cache_key, start_time=start_time,
diff --git a/src/sentry/static/sentry/app/data/forms/organizationGeneralSettings.jsx b/src/sentry/static/sentry/app/data/forms/organizationGeneralSettings.jsx
index 00d99037d7..7932faa4af 100644
--- a/src/sentry/static/sentry/app/data/forms/organizationGeneralSettings.jsx
+++ b/src/sentry/static/sentry/app/data/forms/organizationGeneralSettings.jsx
@@ -198,6 +198,15 @@ const formGroups = [
         label: t('Allow JavaScript source fetching'),
         help: t('Allow Sentry to scrape missing JavaScript source context when possible'),
       },
+      {
+        name: 'storeCrashReports',
+        type: 'boolean',
+        label: t('Store Native Crash Reports'),
+        help: t(
+          'Store native crash reports such as Minidumps for improved processing and download in issue details'
+        ),
+        visible: ({features}) => features.has('event-attachments'),
+      },
     ],
   },
 ];
diff --git a/src/sentry/static/sentry/app/data/forms/projectGeneralSettings.jsx b/src/sentry/static/sentry/app/data/forms/projectGeneralSettings.jsx
index 95d416a854..f4266f8854 100644
--- a/src/sentry/static/sentry/app/data/forms/projectGeneralSettings.jsx
+++ b/src/sentry/static/sentry/app/data/forms/projectGeneralSettings.jsx
@@ -174,6 +174,15 @@ export const fields = {
     getValue: val => extractMultilineFields(val),
     setValue: val => (val && typeof val.join === 'function' && val.join('\n')) || '',
   },
+  storeCrashReports: {
+    name: 'storeCrashReports',
+    type: 'boolean',
+    label: t('Store Native Crash Reports'),
+    help: t(
+      'Store native crash reports such as Minidumps for improved processing and download in issue details'
+    ),
+    visible: ({features}) => features.includes('event-attachments'),
+  },
 
   allowedDomains: {
     name: 'allowedDomains',
diff --git a/src/sentry/static/sentry/app/views/settings/projectGeneralSettings.jsx b/src/sentry/static/sentry/app/views/settings/projectGeneralSettings.jsx
index 95ffbce5bd..dabfdff880 100644
--- a/src/sentry/static/sentry/app/views/settings/projectGeneralSettings.jsx
+++ b/src/sentry/static/sentry/app/views/settings/projectGeneralSettings.jsx
@@ -268,12 +268,14 @@ class ProjectGeneralSettings extends AsyncView {
           <JsonForm
             {...jsonFormProps}
             title={t('Data Privacy')}
+            features={organization.features}
             fields={[
               fields.dataScrubber,
               fields.dataScrubberDefaults,
               fields.scrubIPAddresses,
               fields.sensitiveFields,
               fields.safeFields,
+              fields.storeCrashReports,
             ]}
           />
 
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index 7ae3f86e49..9554bf5670 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -10,12 +10,14 @@ from __future__ import absolute_import
 
 import logging
 from datetime import datetime
+import six
 
 from raven.contrib.django.models import client as Raven
 from time import time
 from django.utils import timezone
 
-from sentry import reprocessing
+from sentry import features, reprocessing
+from sentry.attachments import attachment_cache
 from sentry.cache import default_cache
 from sentry.tasks.base import instrumented_task
 from sentry.utils import metrics
@@ -24,7 +26,7 @@ from sentry.stacktraces import process_stacktraces, \
     should_process_for_stacktraces
 from sentry.utils.canonical import CanonicalKeyDict, CANONICAL_TYPES
 from sentry.utils.dates import to_datetime
-from sentry.models import ProjectOption, Activity, Project
+from sentry.models import EventAttachment, File, ProjectOption, Activity, Project
 
 error_logger = logging.getLogger('sentry.errors.events')
 info_logger = logging.getLogger('sentry.store')
@@ -32,6 +34,9 @@ info_logger = logging.getLogger('sentry.store')
 # Is reprocessing on or off by default?
 REPROCESSING_DEFAULT = False
 
+# Attachment file types that are considered a crash report (PII relevant)
+CRASH_REPORT_TYPES = ('event.minidump', )
+
 
 class RetryProcessing(Exception):
     pass
@@ -294,6 +299,35 @@ def create_failed_event(cache_key, project_id, issues, event_id, start_time=None
     return True
 
 
+def save_attachment(event, attachment):
+    """
+    Saves an event attachment to blob storage.
+    """
+
+    # If the attachment is a crash report (e.g. minidump), we need to honor the
+    # store_crash_reports setting. Otherwise, we assume that the client has
+    # already verified PII and just store the attachment.
+    if attachment.type in CRASH_REPORT_TYPES:
+        if not event.project.get_option('sentry:store_crash_reports') and \
+                not event.project.organization.get_option('sentry:store_crash_reports'):
+            return
+
+    file = File.objects.create(
+        name=attachment.name,
+        type=attachment.type,
+        headers={'Content-Type': attachment.content_type},
+    )
+    file.putfile(six.BytesIO(attachment.data))
+
+    EventAttachment.objects.create(
+        event_id=event.event_id,
+        group_id=event.group_id,
+        project_id=event.project_id,
+        name=attachment.name,
+        file=file,
+    )
+
+
 @instrumented_task(name='sentry.tasks.store.save_event', queue='events.save_event')
 def save_event(cache_key=None, data=None, start_time=None, event_id=None,
                project_id=None, **kwargs):
@@ -340,7 +374,15 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None,
 
     try:
         manager = EventManager(data)
-        manager.save(project_id)
+        event = manager.save(project_id)
+
+        # Always load attachments from the cache so we can later prune them.
+        # Only save them if the event-attachments feature is active, though.
+        if features.has('organizations:event-attachments', event.project.organization, actor=None):
+            attachments = attachment_cache.get(cache_key) or []
+            for attachment in attachments:
+                save_attachment(event, attachment)
+
     except HashDiscarded:
         increment_list = [
             (tsdb.models.project_total_received_discarded, project_id),
@@ -379,6 +421,8 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None,
     finally:
         if cache_key:
             default_cache.delete(cache_key)
+            attachment_cache.delete(cache_key)
+
         if start_time:
             metrics.timing(
                 'events.time-to-process',
diff --git a/src/sentry/testutils/cases.py b/src/sentry/testutils/cases.py
index 2459911a50..62248d6eef 100644
--- a/src/sentry/testutils/cases.py
+++ b/src/sentry/testutils/cases.py
@@ -239,6 +239,19 @@ class BaseTestCase(Fixtures, Exam):
                 **extra
             )
 
+    def _postMinidumpWithHeader(self, upload_file_minidump, data=None, key=None, **extra):
+        data = dict(data or {})
+        data['upload_file_minidump'] = upload_file_minidump
+        path = reverse('sentry-api-minidump', kwargs={'project_id': self.project.id})
+        path += '?sentry_key=%s' % self.projectkey.public_key
+        with self.tasks():
+            return self.client.post(
+                path,
+                data=data,
+                HTTP_USER_AGENT=DEFAULT_USER_AGENT,
+                **extra
+            )
+
     def _getWithReferer(self, data, key=None, referer='sentry.io', protocol='4'):
         if key is None:
             key = self.projectkey.public_key
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 398453aa04..280f1187b4 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -28,7 +28,8 @@ from querystring_parser import parser
 from raven.contrib.django.models import client as Raven
 from symbolic import ProcessMinidumpError
 
-from sentry import quotas, tsdb
+from sentry import features, quotas, tsdb
+from sentry.attachments import CachedAttachment
 from sentry.coreapi import (
     APIError, APIForbidden, APIRateLimited, ClientApiHelper, SecurityApiHelper, LazyData,
     MinidumpApiHelper,
@@ -328,7 +329,7 @@ class StoreView(APIView):
             response['X-Sentry-ID'] = response_or_event_id
         return response
 
-    def process(self, request, project, key, auth, helper, data, **kwargs):
+    def process(self, request, project, key, auth, helper, data, attachments=None, **kwargs):
         metrics.incr('events.total')
 
         if not data:
@@ -484,7 +485,7 @@ class StoreView(APIView):
             helper.ensure_does_not_have_ip(data)
 
         # mutates data (strips a lot of context if not queued)
-        helper.insert_data_to_database(data, start_time=start_time)
+        helper.insert_data_to_database(data, start_time=start_time, attachments=attachments)
 
         cache.set(cache_key, '', 60 * 5)
 
@@ -543,7 +544,7 @@ class MinidumpView(StoreView):
             request=request, project=project, auth=auth, helper=helper, key=key, **kwargs
         )
 
-    def post(self, request, **kwargs):
+    def post(self, request, project, **kwargs):
         # Minidump request payloads do not have the same structure as
         # usual events from other SDKs. Most notably, the event needs
         # to be transfered in the `sentry` form field. All other form
@@ -624,13 +625,34 @@ class MinidumpView(StoreView):
                 for chunk in minidump.chunks():
                     out.write(chunk)
 
+        # Always store the minidump in attachments so we can access it during
+        # processing, regardless of the event-attachments feature. This will
+        # allow us to stack walk again with CFI once symbols are loaded.
+        attachments = []
+        minidump.seek(0)
+        attachments.append(CachedAttachment.from_upload(minidump, type='event.minidump'))
+
+        # Append all other files as generic attachments. We can skip this if the
+        # feature is disabled since they won't be saved.
+        if features.has('organizations:event-attachments',
+                        project.organization, actor=request.user):
+            for name, file in six.iteritems(request.FILES):
+                if name != 'upload_file_minidump':
+                    attachments.append(CachedAttachment.from_upload(file))
+
         try:
             merge_minidump_event(data, minidump)
         except ProcessMinidumpError as e:
             logger.exception(e)
             raise APIError(e.message.split('\n', 1)[0])
 
-        response_or_event_id = self.process(request, data=data, **kwargs)
+        response_or_event_id = self.process(
+            request,
+            attachments=attachments,
+            data=data,
+            project=project,
+            **kwargs)
+
         if isinstance(response_or_event_id, HttpResponse):
             return response_or_event_id
 
diff --git a/tests/js/setup.js b/tests/js/setup.js
index 74cb7c5477..db979fd76a 100644
--- a/tests/js/setup.js
+++ b/tests/js/setup.js
@@ -825,6 +825,7 @@ window.TestStubs = {
       resolveAge: 48,
       sensitiveFields: ['creditcard', 'ssn'],
       safeFields: ['business-email', 'company'],
+      storeCrashReports: false,
       allowedDomains: ['example.com', 'https://example.com'],
       scrapeJavaScript: true,
       securityToken: 'security-token',
diff --git a/tests/js/spec/views/__snapshots__/projectAlertSettings.spec.jsx.snap b/tests/js/spec/views/__snapshots__/projectAlertSettings.spec.jsx.snap
index bbbd182d0f..1b8a404d03 100644
--- a/tests/js/spec/views/__snapshots__/projectAlertSettings.spec.jsx.snap
+++ b/tests/js/spec/views/__snapshots__/projectAlertSettings.spec.jsx.snap
@@ -185,6 +185,7 @@ exports[`ProjectAlertSettings render() renders 1`] = `
             "ssn",
           ],
           "slug": "project-slug",
+          "storeCrashReports": false,
           "subjectPrefix": "[my-org]",
           "subjectTemplate": "[$project] \${tag:level}: $title",
           "teams": Array [],
diff --git a/tests/js/spec/views/__snapshots__/projectOwnership.spec.jsx.snap b/tests/js/spec/views/__snapshots__/projectOwnership.spec.jsx.snap
index 4853655e2e..531d428996 100644
--- a/tests/js/spec/views/__snapshots__/projectOwnership.spec.jsx.snap
+++ b/tests/js/spec/views/__snapshots__/projectOwnership.spec.jsx.snap
@@ -128,6 +128,7 @@ exports[`ProjectTeamsSettings render() renders 1`] = `
                 "ssn",
               ],
               "slug": "project-slug",
+              "storeCrashReports": false,
               "subjectPrefix": "[my-org]",
               "subjectTemplate": "[$project] \${tag:level}: $title",
               "teams": Array [],
diff --git a/tests/js/spec/views/groupDetails/__snapshots__/actions.spec.jsx.snap b/tests/js/spec/views/groupDetails/__snapshots__/actions.spec.jsx.snap
index 5db5a55bec..b21f882a19 100644
--- a/tests/js/spec/views/groupDetails/__snapshots__/actions.spec.jsx.snap
+++ b/tests/js/spec/views/groupDetails/__snapshots__/actions.spec.jsx.snap
@@ -91,6 +91,7 @@ exports[`GroupActions render() renders correctly 1`] = `
           "ssn",
         ],
         "slug": "project",
+        "storeCrashReports": false,
         "subjectPrefix": "[my-org]",
         "subjectTemplate": "[$project] \${tag:level}: $title",
         "teams": Array [],
diff --git a/tests/sentry/api/endpoints/test_organization_details.py b/tests/sentry/api/endpoints/test_organization_details.py
index eff429a921..71c1788012 100644
--- a/tests/sentry/api/endpoints/test_organization_details.py
+++ b/tests/sentry/api/endpoints/test_organization_details.py
@@ -193,6 +193,7 @@ class OrganizationUpdateTest(APITestCase):
             'dataScrubberDefaults': True,
             'sensitiveFields': [u'password'],
             'safeFields': [u'email'],
+            'storeCrashReports': True,
             'scrubIPAddresses': True,
             'scrapeJavaScript': False,
             'defaultRole': 'owner',
@@ -225,6 +226,7 @@ class OrganizationUpdateTest(APITestCase):
         assert options.get('sentry:require_scrub_ip_address')
         assert options.get('sentry:sensitive_fields') == ['password']
         assert options.get('sentry:safe_fields') == ['email']
+        assert options.get('sentry:store_crash_reports') is True
         assert options.get('sentry:scrape_javascript') is False
 
         # log created
diff --git a/tests/sentry/api/endpoints/test_project_details.py b/tests/sentry/api/endpoints/test_project_details.py
index dc0d715351..e8280ea3e9 100644
--- a/tests/sentry/api/endpoints/test_project_details.py
+++ b/tests/sentry/api/endpoints/test_project_details.py
@@ -79,8 +79,10 @@ class ProjectDetailsTest(APITestCase):
         response = self.client.get(url)
         assert response.status_code == 302
         assert response.data['slug'] == 'foobar'
-        assert response.data['detail']['extra']['url'] == '/api/0/projects/%s/%s/' % (project.organization.slug, 'foobar')
-        assert response['Location'] == 'http://testserver/api/0/projects/%s/%s/' % (project.organization.slug, 'foobar')
+        assert response.data['detail']['extra']['url'] == '/api/0/projects/%s/%s/' % (
+            project.organization.slug, 'foobar')
+        assert response['Location'] == 'http://testserver/api/0/projects/%s/%s/' % (
+            project.organization.slug, 'foobar')
 
 
 class ProjectUpdateTest(APITestCase):
@@ -221,6 +223,7 @@ class ProjectUpdateTest(APITestCase):
             'sentry:scrub_defaults': False,
             'sentry:sensitive_fields': ['foo', 'bar'],
             'sentry:safe_fields': ['token'],
+            'sentry:store_crash_reports': False,
             'sentry:csp_ignored_sources_defaults': False,
             'sentry:csp_ignored_sources': 'foo\nbar',
             'filters:blacklisted_ips': '127.0.0.1\n198.51.100.0',
@@ -257,6 +260,9 @@ class ProjectUpdateTest(APITestCase):
             event=AuditLogEntryEvent.PROJECT_EDIT,
         ).exists()
         assert project.get_option('sentry:safe_fields', []) == options['sentry:safe_fields']
+        assert project.get_option(
+            'sentry:store_crash_reports',
+            False) == options['sentry:store_crash_reports']
         assert AuditLogEntry.objects.filter(
             organization=project.organization,
             event=AuditLogEntryEvent.PROJECT_EDIT,
@@ -473,6 +479,14 @@ class ProjectUpdateTest(APITestCase):
             'foobar.com', 'https://example.com']
         assert resp.data['safeFields'] == ['foobar.com', 'https://example.com']
 
+    def test_store_crash_reports(self):
+        resp = self.client.put(self.path, data={
+            'storeCrashReports': True,
+        })
+        assert resp.status_code == 200, resp.content
+        assert self.project.get_option('sentry:store_crash_reports') is True
+        assert resp.data['storeCrashReports'] is True
+
     def test_sensitive_fields(self):
         resp = self.client.put(self.path, data={
             'sensitiveFields': ['foobar.com', 'https://example.com'],
diff --git a/tests/sentry/attachments/__init__.py b/tests/sentry/attachments/__init__.py
new file mode 100644
index 0000000000..c3961685ab
--- /dev/null
+++ b/tests/sentry/attachments/__init__.py
@@ -0,0 +1 @@
+from __future__ import absolute_import
diff --git a/tests/sentry/attachments/test_redis.py b/tests/sentry/attachments/test_redis.py
new file mode 100644
index 0000000000..be54b9e9c9
--- /dev/null
+++ b/tests/sentry/attachments/test_redis.py
@@ -0,0 +1,67 @@
+# -*- coding: utf-8 -*-
+
+from __future__ import absolute_import
+
+import mock
+import zlib
+
+from sentry.cache.redis import RedisClusterCache, RbCache
+from sentry.testutils import TestCase
+from sentry.utils.imports import import_string
+
+
+class FakeClient(object):
+    def get(self, key):
+        if key == 'c:1:foo:a':
+            return '[{"name":"foo.txt","content_type":"text/plain"}]'
+        elif key == 'c:1:foo:a:0':
+            return zlib.compress(b'Hello World!')
+
+
+class RbCluster(object):
+    def get_routing_client(self):
+        return CLIENT
+
+
+CLIENT = FakeClient()
+RB_CLUSTER = RbCluster()
+
+
+class RedisClusterAttachmentTest(TestCase):
+
+    @mock.patch('sentry.utils.redis.redis_clusters.get', return_value=CLIENT)
+    def test_process_pending_one_batch(self, cluster_get):
+        attachment_cache = import_string('sentry.attachments.redis.RedisClusterAttachmentCache')()
+        cluster_get.assert_any_call('rc-short')
+        assert isinstance(attachment_cache.inner, RedisClusterCache)
+        assert attachment_cache.inner.client is CLIENT
+
+        rv = attachment_cache.get('foo')
+        assert len(rv) == 1
+        attachment = rv[0]
+        assert attachment.meta() == {
+            'type': 'event.attachment',
+            'name': 'foo.txt',
+            'content_type': 'text/plain'
+        }
+        assert attachment.data == b'Hello World!'
+
+
+class RbAttachmentTest(TestCase):
+
+    @mock.patch('sentry.cache.redis.get_cluster_from_options', return_value=(RB_CLUSTER, {}))
+    def test_process_pending_one_batch(self, cluster_get):
+        attachment_cache = import_string('sentry.attachments.redis.RbAttachmentCache')(hosts=[])
+        cluster_get.assert_any_call('SENTRY_CACHE_OPTIONS', {'hosts': []})
+        assert isinstance(attachment_cache.inner, RbCache)
+        assert attachment_cache.inner.client is CLIENT
+
+        rv = attachment_cache.get('foo')
+        assert len(rv) == 1
+        attachment = rv[0]
+        assert attachment.meta() == {
+            'type': 'event.attachment',
+            'name': 'foo.txt',
+            'content_type': 'text/plain'
+        }
+        assert attachment.data == b'Hello World!'
diff --git a/tests/sentry/lang/native/test_plugin.py b/tests/sentry/lang/native/test_plugin.py
index 5ff33bff62..72611ff81e 100644
--- a/tests/sentry/lang/native/test_plugin.py
+++ b/tests/sentry/lang/native/test_plugin.py
@@ -12,7 +12,7 @@ from django.core.files.uploadedfile import SimpleUploadedFile
 
 from sentry.testutils import TestCase
 from sentry.lang.native.symbolizer import Symbolizer
-from sentry.models import Event, File, ProjectDSymFile
+from sentry.models import Event, EventAttachment, File, ProjectDSymFile
 
 from symbolic import parse_addr, Object, SymbolicError
 
@@ -1492,3 +1492,111 @@ class ExceptionMechanismIntegrationTest(TestCase):
         assert mechanism.meta['mach_exception']['code'] == 0
         assert mechanism.meta['mach_exception']['subcode'] == 0
         assert mechanism.meta['mach_exception']['name'] == 'EXC_CRASH'
+
+
+class MinidumpIntegrationTest(TestCase):
+
+    def upload_symbols(self):
+        url = reverse(
+            'sentry-api-0-dsym-files',
+            kwargs={
+                'organization_slug': self.project.organization.slug,
+                'project_slug': self.project.slug,
+            }
+        )
+
+        self.login_as(user=self.user)
+
+        out = BytesIO()
+        f = zipfile.ZipFile(out, 'w')
+        f.write(os.path.join(os.path.dirname(__file__), 'fixtures', 'windows.sym'),
+                'crash.sym')
+        f.close()
+
+        response = self.client.post(
+            url, {
+                'file':
+                SimpleUploadedFile('symbols.zip', out.getvalue(), content_type='application/zip'),
+            },
+            format='multipart'
+        )
+        assert response.status_code == 201, response.content
+        assert len(response.data) == 1
+
+    def test_full_minidump(self):
+        self.project.update_option('sentry:store_crash_reports', True)
+        self.upload_symbols()
+
+        with self.feature('organizations:event-attachments'):
+            attachment = BytesIO(b'Hello World!')
+            attachment.name = 'hello.txt'
+            with open(os.path.join(os.path.dirname(__file__), 'fixtures', 'windows.dmp'), 'rb') as f:
+                resp = self._postMinidumpWithHeader(f, {
+                    'sentry[logger]': 'test-logger',
+                    'some_file': attachment,
+                })
+                assert resp.status_code == 200
+
+        event = Event.objects.get()
+
+        bt = event.interfaces['sentry.interfaces.Exception'].values[0].stacktrace
+        frames = bt.frames
+        main = frames[-1]
+        assert main.function == 'main'
+        assert main.abs_path == 'c:\\projects\\breakpad-tools\\windows\\crash\\main.cpp'
+        assert main.errors is None
+        assert main.instruction_addr == '0x2a2a3d'
+
+        attachments = sorted(
+            EventAttachment.objects.filter(
+                event_id=event.event_id),
+            key=lambda x: x.name)
+        hello, minidump = attachments
+
+        assert hello.name == 'hello.txt'
+        assert hello.file.type == 'event.attachment'
+        assert hello.file.checksum == '2ef7bde608ce5404e97d5f042f95f89f1c232871'
+
+        assert minidump.name == 'windows.dmp'
+        assert minidump.file.type == 'event.minidump'
+        assert minidump.file.checksum == '74bb01c850e8d65d3ffbc5bad5cabc4668fce247'
+
+    def test_attachments_only_minidumps(self):
+        self.project.update_option('sentry:store_crash_reports', False)
+        self.upload_symbols()
+
+        with self.feature('organizations:event-attachments'):
+            attachment = BytesIO(b'Hello World!')
+            attachment.name = 'hello.txt'
+            with open(os.path.join(os.path.dirname(__file__), 'fixtures', 'windows.dmp'), 'rb') as f:
+                resp = self._postMinidumpWithHeader(f, {
+                    'sentry[logger]': 'test-logger',
+                    'some_file': attachment,
+                })
+                assert resp.status_code == 200
+
+        event = Event.objects.get()
+
+        attachments = list(EventAttachment.objects.filter(event_id=event.event_id))
+        assert len(attachments) == 1
+        hello = attachments[0]
+
+        assert hello.name == 'hello.txt'
+        assert hello.file.type == 'event.attachment'
+        assert hello.file.checksum == '2ef7bde608ce5404e97d5f042f95f89f1c232871'
+
+    def test_disabled_attachments(self):
+        self.upload_symbols()
+
+        attachment = BytesIO(b'Hello World!')
+        attachment.name = 'hello.txt'
+        with open(os.path.join(os.path.dirname(__file__), 'fixtures', 'windows.dmp'), 'rb') as f:
+            resp = self._postMinidumpWithHeader(f, {
+                'sentry[logger]': 'test-logger',
+                'some_file': attachment,
+            })
+            assert resp.status_code == 200
+
+        event = Event.objects.get()
+        attachments = list(EventAttachment.objects.filter(event_id=event.event_id))
+        assert attachments == []
diff --git a/tests/sentry/models/test_organization.py b/tests/sentry/models/test_organization.py
index 12178e0f90..cfbdcfcffa 100644
--- a/tests/sentry/models/test_organization.py
+++ b/tests/sentry/models/test_organization.py
@@ -230,3 +230,14 @@ class OrganizationTest(TestCase):
             key='sentry:safe_fields')
         f.value = ['email']
         assert f.has_changed('value') is False
+
+        OrganizationOption.objects.create(
+            organization=org,
+            key='sentry:store_crash_reports',
+            value=False
+        )
+        p = OrganizationOption.objects.get(
+            organization=org,
+            key='sentry:store_crash_reports')
+        p.value = True
+        assert p.has_changed('value') is True
