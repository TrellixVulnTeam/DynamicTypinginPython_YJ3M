commit 00f5909b8594d6fa3292e561a3519525bf492bb0
Author: Markus Unterwaditzer <markus@unterwaditzer.net>
Date:   Fri May 10 18:09:55 2019 +0200

    ref: Clean up dead code related to Rust normalization (#13080)
    
    * fix: Remove rust_normalize tag
    
    * ref: Remove unused serve_normalize
    
    * ref: Remove duplicate code from process_event

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 21e7b3741b..e12983e0cf 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -410,21 +410,12 @@ class EventManager(object):
         self._data = data
 
     def normalize(self):
-        tags = {
-            'use_rust_normalize': True
-        }
-
-        with metrics.timer('events.store.normalize.duration', tags=tags):
+        with metrics.timer('events.store.normalize.duration'):
             self._normalize_impl()
 
-        data = self.get_data()
-
-        data['use_rust_normalize'] = True
-
         metrics.timing(
             'events.store.normalize.errors',
-            len(data.get("errors") or ()),
-            tags=tags,
+            len(self._data.get("errors") or ()),
         )
 
     def _normalize_impl(self):
diff --git a/src/sentry/management/commands/serve_normalize.py b/src/sentry/management/commands/serve_normalize.py
deleted file mode 100644
index 177ad31d99..0000000000
--- a/src/sentry/management/commands/serve_normalize.py
+++ /dev/null
@@ -1,257 +0,0 @@
-"""
-sentry.management.commands.serve_normalize
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-:copyright: (c) 2018 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
-from __future__ import absolute_import, print_function
-
-import SocketServer
-import base64
-import os
-import stat
-import sys
-import time
-import traceback
-import json
-import resource
-import multiprocessing
-
-from django.core.management.base import BaseCommand, CommandError, make_option
-from django.utils.encoding import force_str
-
-
-class ForkingUnixStreamServer(SocketServer.ForkingMixIn,
-                              SocketServer.UnixStreamServer):
-    pass
-
-
-def catch_errors(f):
-    def wrapper(*args, **kwargs):
-        error = None
-        try:
-            return f(*args, **kwargs)
-        except Exception as e:
-            error = force_str(e.message) + ' ' + force_str(traceback.format_exc())
-
-        try:
-            return encode({
-                'result': None,
-                'error': error,
-                'metrics': None
-            })
-        except (ValueError, TypeError) as e:
-            try:
-                # Encoding error, try to send the exception instead
-                return encode({
-                    'result': None,
-                    'error': force_str(e.message) + ' ' + force_str(traceback.format_exc()),
-                    'metrics': None,
-                    'encoding_error': True,
-                })
-            except Exception:
-                return b'{}'
-
-    return wrapper
-
-
-# Here's where the normalization itself happens
-def process_event(data, meta):
-    from sentry.event_manager import EventManager
-    from sentry.tasks.store import should_process
-
-    event_manager = EventManager(
-        data,
-        client_ip=meta.get('REMOTE_ADDR'),
-        user_agent=meta.get('HTTP_USER_AGENT'),
-        auth=None,
-        key=None,
-        content_encoding=meta.get('HTTP_CONTENT_ENCODING')
-    )
-    event_manager.normalize()
-
-    event = event_manager.get_data()
-    group_hash = None
-
-    if not should_process(event):
-        group_hash = event_manager._get_event_instance(project_id=1).get_hashes()
-    return {
-        "event": dict(event),
-        "group_hash": group_hash,
-    }
-
-
-def decode(message):
-    meta, data_encoded = json.loads(message)
-    data = base64.b64decode(data_encoded)
-    return data, meta
-
-
-def encode(data):
-    # Normalized data should be serializable
-    return json.dumps(data)
-
-
-@catch_errors
-def handle_data(data):
-    mc = MetricCollector()
-
-    metrics_before = mc.collect_metrics()
-    data, meta = decode(data)
-    rv = process_event(data, meta)
-    metrics_after = mc.collect_metrics()
-
-    return encode({
-        'result': rv,
-        'metrics': {'before': metrics_before, 'after': metrics_after},
-        'error': None
-    })
-
-
-def handle_data_piped(pipe, data):
-    pipe.send(handle_data(data))
-
-
-class MetricCollector(object):
-    def __init__(self):
-        self.is_linux = sys.platform.startswith('linux')
-        self.pid = os.getpid()
-
-    def collect_metrics(self):
-        metrics = {
-            'time': time.time(),
-        }
-
-        usage = resource.getrusage(resource.RUSAGE_SELF)
-        usage_dict = {attr: getattr(usage, attr) for attr in dir(usage) if attr.startswith('ru_')}
-        metrics.update(usage_dict)
-
-        if self.is_linux:
-            with open('/proc/{}/status'.format(self.pid)) as procfh:
-                metrics['proc'] = procfh.read()
-
-        return metrics
-
-
-class EventNormalizeHandler(SocketServer.BaseRequestHandler):
-    """
-    The request handler class for our server.
-
-    It is instantiated once per connection to the server, and must
-    override the handle() method to implement communication to the
-    client.
-    """
-
-    BUFFER_SIZE = 4096
-    SOCKET_TIMEOUT = 10.0
-
-    def handle(self):
-        self.server.socket.settimeout(self.SOCKET_TIMEOUT)
-
-        chunks = []
-
-        # Receive the data
-        while True:
-            rcvd = self.request.recv(self.BUFFER_SIZE)
-            if rcvd is None:
-                raise ValueError('Received None')
-
-            if not rcvd:
-                break
-            chunks.append(rcvd)
-
-        self.data = ''.join(chunks)
-
-        response = self.handle_data()
-        self.request.sendall(response)
-        self.request.close()
-
-    def handle_data(self):
-        @catch_errors
-        def inner():
-            # TODO: Remove this contraption once we no longer get segfaults
-            parent_conn, child_conn = multiprocessing.Pipe()
-            p = multiprocessing.Process(
-                target=handle_data_piped,
-                args=(child_conn, self.data,)
-            )
-            p.start()
-            p.join(1)
-            assert parent_conn.poll(), "Process crashed"
-            return parent_conn.recv()
-
-        return inner()
-
-
-class Command(BaseCommand):
-    help = 'Start a socket server for event normalization'
-
-    option_list = BaseCommand.option_list + (
-        make_option('--unix', dest='socket_file',
-                    help='Unix socket to bind to. Example: "/tmp/normalize.sock"'),
-        make_option('--net', dest='network_socket',
-                    help='Network socket to bind to. Example: "127.0.0.1:1234"'),
-        make_option('--threading', action='store_true', dest='threading',
-                    help='Start a threading server'),
-        make_option('--forking', action='store_true', dest='forking',
-                    help='Start a forking server'),
-    )
-
-    def _check_socket_path(self, socket_file):
-        if os.path.exists(socket_file):
-            file_mode = os.stat(socket_file).st_mode
-            if not stat.S_ISSOCK(file_mode):
-                raise CommandError('File already exists and is not a socket')
-
-        # Make sure the socket does not already exist
-        try:
-            os.unlink(socket_file)
-        except OSError:
-            if os.path.exists(socket_file):
-                raise
-
-    def handle(self, **options):
-        socket_file = options.get('socket_file')
-        network_socket = options.get('network_socket')
-        threading = options.get('threading')
-        forking = options.get('forking')
-        if threading and forking:
-            raise CommandError('Pick one: threading or forking.')
-        if socket_file and network_socket:
-            raise CommandError('Only one socket allowed at a time')
-
-        if threading:
-            server_type = 'threading'
-        elif forking:
-            server_type = 'forking'
-        else:
-            server_type = 'single-threaded'
-        self.stdout.write('Server type: %s\n' % (server_type,))
-
-        if socket_file:
-            self.socket_file = os.path.abspath(socket_file)
-            self._check_socket_path(socket_file)
-            self.stdout.write('Binding to unix socket: %s\n' % (socket_file,))
-            if threading:
-                server = SocketServer.ThreadingUnixStreamServer(socket_file, EventNormalizeHandler)
-                server.daemon_threads = True
-            elif forking:
-                server = ForkingUnixStreamServer(socket_file, EventNormalizeHandler)
-            else:
-                server = SocketServer.UnixStreamServer(socket_file, EventNormalizeHandler)
-        elif network_socket:
-            host, port = network_socket.split(':')
-            port = int(port)
-            self.stdout.write('Binding to network socket: %s:%s\n' % (host, port))
-            if threading:
-                server = SocketServer.ThreadingTCPServer((host, port), EventNormalizeHandler)
-                server.daemon_threads = True
-            elif forking:
-                server = SocketServer.ForkingTCPServer((host, port), EventNormalizeHandler)
-            else:
-                server = SocketServer.TCPServer((host, port), EventNormalizeHandler)
-        else:
-            raise CommandError('No connection option specified')
-
-        server.serve_forever()
diff --git a/src/sentry/tasks/post_process.py b/src/sentry/tasks/post_process.py
index 7fc24b238e..8ea163cc01 100644
--- a/src/sentry/tasks/post_process.py
+++ b/src/sentry/tasks/post_process.py
@@ -53,7 +53,6 @@ def _capture_stats(event, is_new):
     platform = platform.split('-', 1)[0].split('_', 1)[0]
     tags = {
         'platform': platform,
-        'use_rust_normalize': event.data.get('use_rust_normalize', 'unknown')
     }
 
     if is_new:
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 29e5f8d75f..a7d0b544c5 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -97,9 +97,14 @@ def api(func):
 def process_event(event_manager, project, key, remote_addr, helper, attachments):
     event_received.send_robust(ip=remote_addr, project=project, sender=process_event)
 
-    event_id = event_manager.get_data().get('event_id')
     start_time = time()
+
+    data = event_manager.get_data()
     should_filter, filter_reason = event_manager.should_filter()
+    del event_manager
+
+    event_id = data['event_id']
+
     if should_filter:
         track_outcome(
             project.organization_id,
@@ -160,11 +165,6 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments)
     org_options = OrganizationOption.objects.get_all_values(
         project.organization_id)
 
-    data = event_manager.get_data()
-    del event_manager
-
-    event_id = data['event_id']
-
     # TODO(dcramer): ideally we'd only validate this if the event_id was
     # supplied by the user
     cache_key = 'ev:%s:%s' % (project.id, event_id, )
diff --git a/tests/symbolicator/snapshots/SymbolicatorResolvingIntegrationTest/test_real_resolving_with_multiple_requests.pysnap b/tests/symbolicator/snapshots/SymbolicatorResolvingIntegrationTest/test_real_resolving_with_multiple_requests.pysnap
deleted file mode 100644
index bda4b1d551..0000000000
--- a/tests/symbolicator/snapshots/SymbolicatorResolvingIntegrationTest/test_real_resolving_with_multiple_requests.pysnap
+++ /dev/null
@@ -1,71 +0,0 @@
----
-created: '2019-04-02T14:12:19.938357Z'
-creator: sentry
-source: tests/symbolicator/test_native_plugin.py
----
-culprit: main
-debug_meta:
-  images:
-  - arch: x86_64
-    code_file: Foo.app/Contents/Foo
-    code_id: null
-    debug_file: null
-    debug_id: 502fc0a5-1ec1-3e47-9998-684fa139dca7
-    image_addr: '0x100000000'
-    image_size: 4096
-    image_vmaddr: '0x100000000'
-    type: macho
-  sdk_info:
-    sdk_name: macOS
-    version_major: 10
-    version_minor: 12
-    version_patchlevel: 4
-exception:
-  values:
-  - raw_stacktrace:
-      frames:
-      - function: unknown
-        in_app: false
-        instruction_addr: '0x100000fa0'
-        package: Foo.app/Contents/Foo
-    stacktrace:
-      frames:
-      - abs_path: /tmp/hello.c
-        filename: hello.c
-        function: main
-        in_app: false
-        instruction_addr: '0x100000fa0'
-        lineno: 1
-        package: Foo.app/Contents/Foo
-        symbol: main
-    type: Fail
-    value: fail
-fingerprint:
-- '{{ default }}'
-grouping_config:
-  id: legacy:2019-03-12
-hashes:
-- 6e2889ec15f82569f56fdba9ffc9b90b
-level: error
-location: hello.c
-logger: ''
-metadata:
-  filename: hello.c
-  function: main
-  type: Fail
-  value: fail
-platform: cocoa
-sdk:
-  name: _postWithHeader
-  version: 0.0.0
-tags:
-- - level
-  - error
-- - sentry:user
-  - ip:127.0.0.1
-title: 'Fail: fail'
-type: error
-use_rust_normalize: true
-user:
-  ip_address: 127.0.0.1
-version: '6'
