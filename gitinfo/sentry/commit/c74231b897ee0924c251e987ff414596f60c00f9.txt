commit c74231b897ee0924c251e987ff414596f60c00f9
Author: Matt Robenolt <matt@ydekproductions.com>
Date:   Wed Aug 1 14:46:07 2018 -0700

    feat(filestore): Instrument save/read metrics

diff --git a/src/sentry/filestore/gcs.py b/src/sentry/filestore/gcs.py
index 5ce6c4e2ff..401ec10787 100644
--- a/src/sentry/filestore/gcs.py
+++ b/src/sentry/filestore/gcs.py
@@ -17,6 +17,8 @@ from google.cloud.storage.blob import Blob
 from google.cloud.storage.bucket import Bucket
 from google.cloud.exceptions import NotFound
 
+from sentry.utils import metrics
+
 
 def clean_name(name):
     """
@@ -110,15 +112,16 @@ class GoogleCloudFile(File):
 
     def _get_file(self):
         if self._file is None:
-            self._file = SpooledTemporaryFile(
-                max_size=self._storage.max_memory_size,
-                suffix=".GSStorageFile",
-                dir=None,
-            )
-            if 'r' in self._mode:
-                self._is_dirty = False
-                self.blob.download_to_file(self._file)
-                self._file.seek(0)
+            with metrics.timer('filestore.read', instance='gcs'):
+                self._file = SpooledTemporaryFile(
+                    max_size=self._storage.max_memory_size,
+                    suffix=".GSStorageFile",
+                    dir=None,
+                )
+                if 'r' in self._mode:
+                    self._is_dirty = False
+                    self.blob.download_to_file(self._file)
+                    self._file.seek(0)
         return self._file
 
     def _set_file(self, value):
@@ -202,15 +205,16 @@ class GoogleCloudStorage(Storage):
         return GoogleCloudFile(name, mode, self)
 
     def _save(self, name, content):
-        cleaned_name = clean_name(name)
-        name = self._normalize_name(cleaned_name)
-
-        content.name = cleaned_name
-        encoded_name = self._encode_name(name)
-        file = GoogleCloudFile(encoded_name, 'w', self)
-        content.seek(0, os.SEEK_SET)
-        file.blob.upload_from_file(content, size=content.size,
-                                   content_type=file.mime_type)
+        with metrics.timer('filestore.save', instance='gcs'):
+            cleaned_name = clean_name(name)
+            name = self._normalize_name(cleaned_name)
+
+            content.name = cleaned_name
+            encoded_name = self._encode_name(name)
+            file = GoogleCloudFile(encoded_name, 'w', self)
+            content.seek(0, os.SEEK_SET)
+            file.blob.upload_from_file(content, size=content.size,
+                                       content_type=file.mime_type)
         return cleaned_name
 
     def delete(self, name):
diff --git a/src/sentry/filestore/s3.py b/src/sentry/filestore/s3.py
index 99c8826581..73b7833873 100644
--- a/src/sentry/filestore/s3.py
+++ b/src/sentry/filestore/s3.py
@@ -55,6 +55,8 @@ from boto3.session import Session
 from botocore.client import Config
 from botocore.exceptions import ClientError
 
+from sentry.utils import metrics
+
 _thread_local_connection = threading.local()
 
 
@@ -155,13 +157,14 @@ class S3Boto3StorageFile(File):
 
     def _get_file(self):
         if self._file is None:
-            self._file = BytesIO()
-            if 'r' in self._mode:
-                self._is_dirty = False
-                self._file.write(self.obj.get()['Body'].read())
-                self._file.seek(0)
-            if self._storage.gzip and self.obj.content_encoding == 'gzip':
-                self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)
+            with metrics.timer('filestore.read', instance='s3'):
+                self._file = BytesIO()
+                if 'r' in self._mode:
+                    self._is_dirty = False
+                    self._file.write(self.obj.get()['Body'].read())
+                    self._file.seek(0)
+                if self._storage.gzip and self.obj.content_encoding == 'gzip':
+                    self._file = GzipFile(mode=self._mode, fileobj=self._file, mtime=0.0)
         return self._file
 
     def _set_file(self, value):
@@ -485,28 +488,29 @@ class S3Boto3Storage(Storage):
         return f
 
     def _save(self, name, content):
-        cleaned_name = self._clean_name(name)
-        name = self._normalize_name(cleaned_name)
-        parameters = self.object_parameters.copy()
-        content_type = getattr(
-            content, 'content_type', mimetypes.guess_type(name)[0] or self.default_content_type
-        )
+        with metrics.timer('filestore.save', instance='s3'):
+            cleaned_name = self._clean_name(name)
+            name = self._normalize_name(cleaned_name)
+            parameters = self.object_parameters.copy()
+            content_type = getattr(
+                content, 'content_type', mimetypes.guess_type(name)[0] or self.default_content_type
+            )
 
-        # setting the content_type in the key object is not enough.
-        parameters.update({'ContentType': content_type})
+            # setting the content_type in the key object is not enough.
+            parameters.update({'ContentType': content_type})
 
-        if self.gzip and content_type in self.gzip_content_types:
-            content = self._compress_content(content)
-            parameters.update({'ContentEncoding': 'gzip'})
+            if self.gzip and content_type in self.gzip_content_types:
+                content = self._compress_content(content)
+                parameters.update({'ContentEncoding': 'gzip'})
 
-        encoded_name = self._encode_name(name)
-        obj = self.bucket.Object(encoded_name)
-        if self.preload_metadata:
-            self._entries[encoded_name] = obj
+            encoded_name = self._encode_name(name)
+            obj = self.bucket.Object(encoded_name)
+            if self.preload_metadata:
+                self._entries[encoded_name] = obj
 
-        self._save_content(obj, content, parameters=parameters)
-        # Note: In boto3, after a put, last_modified is automatically reloaded
-        # the next time it is accessed; no need to specifically reload it.
+            self._save_content(obj, content, parameters=parameters)
+            # Note: In boto3, after a put, last_modified is automatically reloaded
+            # the next time it is accessed; no need to specifically reload it.
         return cleaned_name
 
     def _save_content(self, obj, content, parameters):
