commit a23a5725849c57c2f757d2c09584c37179e59124
Author: ted kaemming <ted@kaemming.com>
Date:   Tue Feb 5 16:07:55 2019 -0800

    ref(store): Remove Kafka event publisher from `StoreView.process` (#11920)
    
    This removes the Kafka event publishing block from the `StoreView.process` method as well as the options used to configure it. This doesn't affect the `APIView._publish_to_kafka` method that has been used for normalization testing.
    
    It's possible we'll want to bring back Kafka publishing from this view later, but it'll happen at a different point in this process.

diff --git a/src/sentry/event_consumer.py b/src/sentry/event_consumer.py
deleted file mode 100644
index 67075cbe4d..0000000000
--- a/src/sentry/event_consumer.py
+++ /dev/null
@@ -1,40 +0,0 @@
-from __future__ import absolute_import, print_function
-
-from sentry.coreapi import Auth, ClientApiHelper
-from sentry.event_manager import EventManager
-from sentry.models import Project
-from sentry.web.api import process_event
-
-
-def process_event_from_kafka(message):
-    project = Project.objects.get_from_cache(pk=message['project_id'])
-
-    remote_addr = message['remote_addr']
-    helper = ClientApiHelper(
-        agent=message['agent'],
-        project_id=project.id,
-        ip_address=remote_addr,
-    )
-    helper.context.bind_project(project)
-
-    auth = Auth(message['auth'], message['auth'].pop('is_public'))
-    helper.context.bind_auth(auth)
-
-    key = helper.project_key_from_auth(auth)
-    data = message['data']
-    version = data['version']
-
-    event_manager = EventManager(
-        data,
-        project=project,
-        key=key,
-        auth=auth,
-        client_ip=remote_addr,
-        user_agent=helper.context.agent,
-        version=version,
-    )
-    event_manager._normalized = True
-    del data
-
-    return process_event(event_manager, project, key,
-                         remote_addr, helper, attachments=None)
diff --git a/src/sentry/options/defaults.py b/src/sentry/options/defaults.py
index 8b44ec2281..04dc8fcdb7 100644
--- a/src/sentry/options/defaults.py
+++ b/src/sentry/options/defaults.py
@@ -156,8 +156,6 @@ register('kafka-publisher.max-event-size', default=100000)
 register('eventstream.kafka.send-post_process-task', type=Bool, default=True)
 
 # Ingest refactor
-register('store.process-in-kafka', type=Bool, default=False)
-register('store.kafka-sample-rate', default=0.0)
 register('store.projects-normalize-in-rust-opt-in', type=Sequence, default=[])
 register('store.projects-normalize-in-rust-opt-out', type=Sequence, default=[])
 # positive value means stable opt-in in the range 0.0 to 1.0, negative value
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index c4041c0337..11293bad3c 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -549,50 +549,6 @@ class StoreView(APIView):
         self.pre_normalize(event_manager, helper)
         event_manager.normalize()
 
-        agent = request.META.get('HTTP_USER_AGENT')
-
-        # TODO: Some form of coordination between the Kafka consumer
-        # and this method (the 'relay') to decide whether a 429 should
-        # be returned here.
-
-        # Everything before this will eventually be done in the relay.
-        if (kafka_publisher is not None
-                and not attachments
-                and random.random() < options.get('store.kafka-sample-rate')):
-
-            process_in_kafka = options.get('store.process-in-kafka')
-
-            try:
-                kafka_publisher.publish(
-                    channel=getattr(settings, 'KAFKA_EVENTS_PUBLISHER_TOPIC', 'store-events'),
-                    # Relay will (eventually) need to produce a Kafka message
-                    # with this JSON format.
-                    value=json.dumps({
-                        'data': dict(event_manager.get_data()),
-                        'project_id': project.id,
-                        'auth': {
-                            'sentry_client': auth.client,
-                            'sentry_version': auth.version,
-                            'sentry_secret': auth.secret_key,
-                            'sentry_key': auth.public_key,
-                            'is_public': auth.is_public,
-                        },
-                        'remote_addr': remote_addr,
-                        'agent': agent,
-                        # Whether or not the Kafka consumer is in charge
-                        # of actually processing this event.
-                        'should_process': process_in_kafka,
-                    })
-                )
-            except Exception as e:
-                logger.exception("Cannot publish event to Kafka: {}".format(e.message))
-            else:
-                if process_in_kafka:
-                    # This event will be processed by the Kafka consumer, so we
-                    # shouldn't double process it here.
-                    return event_manager.get_data()['event_id']
-
-        # Everything after this will eventually be done in a Kafka consumer.
         return process_event(event_manager, project,
                              key, remote_addr, helper, attachments)
 
diff --git a/tests/sentry/test_event_consumer.py b/tests/sentry/test_event_consumer.py
deleted file mode 100644
index 87f4584c93..0000000000
--- a/tests/sentry/test_event_consumer.py
+++ /dev/null
@@ -1,34 +0,0 @@
-from __future__ import absolute_import, print_function
-
-import mock
-
-from sentry.event_consumer import process_event_from_kafka
-from sentry.signals import event_accepted
-from sentry.testutils import (assert_mock_called_once_with_partial, TestCase)
-from sentry.utils import json
-
-
-class EventConsumerTest(TestCase):
-    @mock.patch('sentry.web.api.kafka_publisher')
-    def test_event_consumer(self, mock_kafka_publisher):
-        with self.options({
-            'store.kafka-sample-rate': 1.0,
-            'store.process-in-kafka': True,
-            'kafka-publisher.raw-event-sample-rate': 0.0,
-        }):
-            mock_event_accepted = mock.Mock()
-            event_accepted.connect(mock_event_accepted)
-
-            resp = self._postWithHeader({'logentry': {'message': u'hello'}})
-            assert resp.status_code == 200, resp.content
-
-            publish_args, publish_kwargs = list(mock_kafka_publisher.publish.call_args)
-            kafka_message_value = publish_kwargs['value']
-            process_event_from_kafka(json.loads(kafka_message_value))
-
-            assert_mock_called_once_with_partial(
-                mock_event_accepted,
-                ip='127.0.0.1',
-                project=self.project,
-                signal=event_accepted,
-            )
