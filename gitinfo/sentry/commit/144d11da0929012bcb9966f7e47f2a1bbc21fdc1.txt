commit 144d11da0929012bcb9966f7e47f2a1bbc21fdc1
Author: Mark Story <mark@sentry.io>
Date:   Wed Jun 24 13:21:17 2020 -0400

    ref(discover) Remove automatic latest_event field (#19496)
    
    When getting aggregate results we now have a drilldown UX flow instead
    of opening a details view for the aggregate. This means that we no
    longer need the latest_event id and its corresponding project slug.
    Because these automatic aggregates are not free we shouldn't be
    including them when we don't need them.

diff --git a/src/sentry/api/endpoints/organization_events.py b/src/sentry/api/endpoints/organization_events.py
index 94c13da80c..ae6cad2325 100644
--- a/src/sentry/api/endpoints/organization_events.py
+++ b/src/sentry/api/endpoints/organization_events.py
@@ -73,16 +73,15 @@ class OrganizationEventsEndpoint(OrganizationEventsEndpointBase):
         )
 
     def handle_results(self, request, organization, project_ids, results):
-        projects = {
-            p["id"]: p["slug"]
-            for p in Project.objects.filter(organization=organization, id__in=project_ids).values(
-                "id", "slug"
-            )
-        }
-
         fields = request.GET.getlist("field")
 
         if "project.name" in fields:
+            projects = {
+                p["id"]: p["slug"]
+                for p in Project.objects.filter(
+                    organization=organization, id__in=project_ids
+                ).values("id", "slug")
+            }
             for result in results:
                 result["project.name"] = projects[result["project.id"]]
                 if "project.id" not in fields:
diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index b55eabce52..0a50c9e927 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -1451,8 +1451,6 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
     columns = []
     groupby = []
     project_key = ""
-    # Which column to map to project names
-    project_column = "project_id"
 
     # If project is requested, we need to map ids to their names since snuba only has ids
     if "project" in fields:
@@ -1480,22 +1478,11 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
     if not rollup and auto_fields:
         # Ensure fields we require to build a functioning interface
         # are present. We don't add fields when using a rollup as the additional fields
-        # would be aggregated away. When there are aggregations
-        # we use argMax to get the latest event/projectid so we can create links.
-        # The `projectid` output name is not a typo, using `project_id` triggers
-        # generates invalid queries.
+        # would be aggregated away.
         if not aggregations and "id" not in columns:
             columns.append("id")
         if not aggregations and "project.id" not in columns:
             columns.append("project.id")
-            project_column = "project_id"
-        if aggregations and "latest_event" not in map(lambda a: a[-1], aggregations):
-            _, aggregates = resolve_function("latest_event()")
-            aggregations.extend(aggregates)
-        if aggregations and "project.id" not in columns:
-            aggregations.append(["argMax", ["project.id", "timestamp"], "projectid"])
-            project_column = "projectid"
-        if project_key == "":
             project_key = PROJECT_NAME_ALIAS
 
     if project_key:
@@ -1511,7 +1498,7 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
         aggregations.append(
             [
                 u"transform({}, array({}), array({}), '')".format(
-                    project_column,
+                    "project_id",
                     # Need to use join like this so we don't get a list including Ls which confuses clickhouse
                     ",".join([six.text_type(project["id"]) for project in projects]),
                     # Can't just format a list since we'll get u"string" instead of a plain 'string'
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index 186584903e..88382086ac 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1391,7 +1391,7 @@ class ResolveFieldListTest(unittest.TestCase):
         result = resolve_field_list(fields, eventstore.Filter())
         assert result["selected_columns"] == ["event.type", "message", "id", "project.id"]
         assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"]
+            ["transform(project_id, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == ["event.type", "message", "id", "project.id"]
 
@@ -1424,8 +1424,6 @@ class ResolveFieldListTest(unittest.TestCase):
             ["quantile(0.75)", "transaction.duration", "percentile_transaction_duration_0_75"],
             ["quantile(0.95)", "transaction.duration", "percentile_transaction_duration_0_95"],
             ["quantile(0.99)", "transaction.duration", "percentile_transaction_duration_0_99"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1467,9 +1465,6 @@ class ResolveFieldListTest(unittest.TestCase):
             ["uniq", "user", "count_unique_user"],
             ["count", None, "count_id"],
             ["min", "timestamp", "min_timestamp"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1482,9 +1477,6 @@ class ResolveFieldListTest(unittest.TestCase):
             ["count", None, "count_id"],
             ["count", None, "count_user"],
             ["count", None, "count_transaction_duration"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1493,9 +1485,6 @@ class ResolveFieldListTest(unittest.TestCase):
         result = resolve_field_list(fields, eventstore.Filter())
         assert result["aggregations"] == [
             ["uniq", "user.id", "count_unique_user_id"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
 
     def test_aggregate_function_invalid_name(self):
@@ -1526,9 +1515,6 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["selected_columns"] == []
         assert result["aggregations"] == [
             ["quantile(0.75)", "transaction.duration", "percentile_transaction_duration_0_75"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1572,9 +1558,6 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["selected_columns"] == []
         assert result["aggregations"] == [
             ["divide(count(), divide(3600, 60))", None, "epm_3600"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1605,9 +1588,6 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["selected_columns"] == []
         assert result["aggregations"] == [
             ["divide(count(), divide(3600, 60))", None, "epm"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1618,9 +1598,6 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["selected_columns"] == []
         assert result["aggregations"] == [
             ["divide(count(), 3600)", None, "eps_3600"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1644,9 +1621,6 @@ class ResolveFieldListTest(unittest.TestCase):
         ]
         assert result["aggregations"] == [
             ["count", None, "count"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == ["histogram_transaction_duration_10_1000_0"]
 
@@ -1703,7 +1677,7 @@ class ResolveFieldListTest(unittest.TestCase):
         result = resolve_field_list(fields, eventstore.Filter(orderby="-message"))
         assert result["selected_columns"] == ["message", "id", "project.id"]
         assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"]
+            ["transform(project_id, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == ["message", "id", "project.id"]
 
@@ -1714,9 +1688,6 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["aggregations"] == [
             ["count", None, "count_id"],
             ["uniq", "user", "count_unique_user"],
-            ["argMax", ["id", "timestamp"], "latest_event"],
-            ["argMax", ["project.id", "timestamp"], "projectid"],
-            ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == []
 
@@ -1726,7 +1697,7 @@ class ResolveFieldListTest(unittest.TestCase):
         assert result["orderby"] == ["-issue.id"]
         assert result["selected_columns"] == ["issue.id", "id", "project.id"]
         assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"]
+            ["transform(project_id, array(), array(), '')", None, "project.name"],
         ]
         assert result["groupby"] == ["issue.id", "id", "project.id"]
 
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index 19238fdef1..181d8c492b 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -210,6 +210,7 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
         assert data[0]["project.id"] == self.project.id
         assert data[0]["user.email"] == "bruce@example.com"
         assert data[0]["release"] == "first-release"
+        assert data[0]["project.name"] == self.project.slug, "should include project name for links"
 
         assert len(result["meta"]) == 5
         assert result["meta"][0] == {"name": "user.email", "type": "Nullable(String)"}
@@ -227,8 +228,6 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
         )
         data = result["data"]
         assert len(data) == 1
-        assert data[0]["projectid"] == self.project.id
-        assert data[0]["latest_event"] == self.event.event_id
         assert data[0]["count_unique_user_email"] == 1
 
     def test_release_condition(self):
@@ -492,18 +491,7 @@ class QueryTransformTest(TestCase):
         )
         mock_query.assert_called_with(
             selected_columns=["transaction", "duration"],
-            aggregations=[
-                ["uniq", "duration", "count_unique_transaction_duration"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["uniq", "duration", "count_unique_transaction_duration"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             end=None,
@@ -534,15 +522,6 @@ class QueryTransformTest(TestCase):
             aggregations=[
                 ["quantile(0.95)", "duration", "p95"],
                 ["uniq", "transaction", "count_unique_transaction"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project.name",
-                ],
             ],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
@@ -574,15 +553,6 @@ class QueryTransformTest(TestCase):
             aggregations=[
                 ["quantile(0.95)", "duration", "p95"],
                 ["uniq", "transaction", "count_unique_transaction"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project.name",
-                ],
             ],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
@@ -611,18 +581,7 @@ class QueryTransformTest(TestCase):
         )
         mock_query.assert_called_with(
             selected_columns=["transaction"],
-            aggregations=[
-                ["failure_rate()", None, "failure_rate"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["failure_rate()", None, "failure_rate"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             groupby=["transaction"],
@@ -650,18 +609,7 @@ class QueryTransformTest(TestCase):
         )
         mock_query.assert_called_with(
             selected_columns=["transaction"],
-            aggregations=[
-                ["uniqIf(user, greater(duration, 1200))", None, "user_misery_300"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["uniqIf(user, greater(duration, 1200))", None, "user_misery_300"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             groupby=["transaction"],
@@ -691,18 +639,7 @@ class QueryTransformTest(TestCase):
         )
         mock_query.assert_called_with(
             selected_columns=["transaction"],
-            aggregations=[
-                ["quantile(0.75)", "duration", "percentile_transaction_duration_0_75"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), six.text_type(self.project.slug)
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["quantile(0.75)", "duration", "percentile_transaction_duration_0_75"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             groupby=["transaction"],
@@ -1208,18 +1145,7 @@ class QueryTransformTest(TestCase):
         )
         mock_query.assert_called_with(
             selected_columns=["transaction"],
-            aggregations=[
-                ["quantile(0.75)", "duration", "percentile_transaction_duration_0_75"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), six.text_type(self.project.slug)
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["quantile(0.75)", "duration", "percentile_transaction_duration_0_75"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             groupby=["transaction"],
@@ -1257,18 +1183,7 @@ class QueryTransformTest(TestCase):
                     "histogram_transaction_duration_10_1000_0",
                 ]
             ],
-            aggregations=[
-                ["count", None, "count"],
-                ["argMax", ["event_id", "timestamp"], "latest_event"],
-                ["argMax", ["project_id", "timestamp"], "projectid"],
-                [
-                    "transform(projectid, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), six.text_type(self.project.slug)
-                    ),
-                    None,
-                    "project.name",
-                ],
-            ],
+            aggregations=[["count", None, "count"]],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             groupby=["histogram_transaction_duration_10_1000_0"],
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index 027e50050e..80396c5626 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -217,6 +217,9 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[0]["id"] == "b" * 32
         assert data[0]["project.id"] == project.id
         assert data[0]["user.email"] == "foo@example.com"
+        assert "project.name" not in data[0], "project.id does not auto select name"
+        assert "project" not in data[0]
+
         meta = response.data["meta"]
         assert meta["id"] == "string"
         assert meta["user.email"] == "string"
@@ -551,47 +554,16 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         data = response.data["data"]
         assert data[0] == {
             "project.id": project.id,
-            "project.name": project.slug,
             "issue.id": event1.group_id,
             "count_id": 2,
-            "latest_event": event1.event_id,
         }
         assert data[1] == {
             "project.id": project.id,
-            "project.name": project.slug,
             "issue.id": event2.group_id,
             "count_id": 1,
-            "latest_event": event2.event_id,
-        }
-        meta = response.data["meta"]
-        assert meta["count_id"] == "integer"
-
-    def test_automatic_id_and_project(self):
-        self.login_as(user=self.user)
-        project = self.create_project()
-        self.store_event(
-            data={"event_id": "a" * 32, "timestamp": self.two_min_ago, "fingerprint": ["group_1"]},
-            project_id=project.id,
-        )
-        event = self.store_event(
-            data={"event_id": "b" * 32, "timestamp": self.min_ago, "fingerprint": ["group_1"]},
-            project_id=project.id,
-        )
-
-        with self.feature("organizations:discover-basic"):
-            response = self.client.get(self.url, format="json", data={"field": ["count(id)"]})
-
-        assert response.status_code == 200, response.content
-        assert len(response.data["data"]) == 1
-        data = response.data["data"]
-        assert data[0] == {
-            "project.name": project.slug,
-            "count_id": 2,
-            "latest_event": event.event_id,
         }
         meta = response.data["meta"]
         assert meta["count_id"] == "integer"
-        assert meta["latest_event"] == "string"
 
     def test_orderby(self):
         self.login_as(user=self.user)
@@ -739,8 +711,6 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[0]["issue.id"] == event1.group_id
         assert data[0]["count_id"] == 1
         assert data[0]["count_unique_user"] == 1
-        assert "latest_event" in data[0]
-        assert "project.name" in data[0]
         assert "projectid" not in data[0]
         assert "project.id" not in data[0]
         assert data[1]["issue.id"] == event2.group_id
@@ -794,8 +764,6 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[0]["issue.id"] == event1.group_id
         assert data[0]["count_id"] == 1
         assert data[0]["count_unique_user_email"] == 1
-        assert "latest_event" in data[0]
-        assert "project.name" in data[0]
         assert "projectid" not in data[0]
         assert "project.id" not in data[0]
         assert data[1]["issue.id"] == event2.group_id
@@ -1436,9 +1404,7 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert response.status_code == 200, response.content
         data = response.data["data"]
         assert len(data) == 1
-        assert data[0]["project.name"] == ""
         assert data[0]["count"] == 0
-        assert data[0]["latest_event"] == ""
 
     def test_reference_event(self):
         self.login_as(user=self.user)
@@ -1485,7 +1451,6 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert len(response.data["data"]) == 1
         data = response.data["data"]
         assert data[0]["transaction"] == "/example"
-        assert data[0]["latest_event"] == "b" * 32
 
     def test_stack_wildcard_condition(self):
         self.login_as(user=self.user)
