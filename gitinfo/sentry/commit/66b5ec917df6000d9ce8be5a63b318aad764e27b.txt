commit 66b5ec917df6000d9ce8be5a63b318aad764e27b
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Wed Feb 5 15:50:56 2020 -0800

    perf: Improve direct hit queries (#16483)
    
    The Group.filter_by_event_id query is currently one of the slowest in
    Sentry since it searches every accessible project for matching
    event IDs in Snuba. It will be faster to get these from nodestore first
    and just populate the group_id from Snuba.

diff --git a/src/sentry/eventstore/snuba/backend.py b/src/sentry/eventstore/snuba/backend.py
index 767fc606ea..8a622f5e33 100644
--- a/src/sentry/eventstore/snuba/backend.py
+++ b/src/sentry/eventstore/snuba/backend.py
@@ -3,7 +3,7 @@ from __future__ import absolute_import
 import six
 
 from copy import deepcopy
-from datetime import datetime, timedelta
+from datetime import timedelta
 import logging
 
 from sentry.eventstore.base import EventStorage
@@ -22,6 +22,8 @@ ASC_ORDERING = [TIMESTAMP, EVENT_ID]
 DEFAULT_LIMIT = 100
 DEFAULT_OFFSET = 0
 
+NODESTORE_LIMIT = 100
+
 logger = logging.getLogger(__name__)
 
 
@@ -97,6 +99,57 @@ class SnubaEventStorage(EventStorage):
         cols = self.__get_columns()
         orderby = orderby or DESC_ORDERING
 
+        # This is an optimization for the Group.filter_by_event_id query where we
+        # have a single event ID and want to check all accessible projects for a
+        # direct hit. In this case it's usually faster to go to nodestore first.
+        if (
+            filter.event_ids
+            and filter.project_ids
+            and len(filter.event_ids) * len(filter.project_ids) < min(limit, NODESTORE_LIMIT)
+            and offset == 0
+        ):
+            event_list = [
+                Event(project_id=project_id, event_id=event_id)
+                for event_id in filter.event_ids
+                for project_id in filter.project_ids
+            ]
+            self.bind_nodes(event_list)
+
+            nodestore_events = [event for event in event_list if len(event.data)]
+
+            if nodestore_events:
+                event_ids = {event.event_id for event in nodestore_events}
+                project_ids = {event.project_id for event in nodestore_events}
+                start = min(event.datetime for event in nodestore_events)
+                end = max(event.datetime for event in nodestore_events) + timedelta(seconds=1)
+
+                result = snuba.aliased_query(
+                    selected_columns=cols,
+                    start=start,
+                    end=end,
+                    conditions=filter.conditions,
+                    filter_keys={"project_id": project_ids, "event_id": event_ids},
+                    orderby=orderby,
+                    limit=len(nodestore_events),
+                    offset=DEFAULT_OFFSET,
+                    referrer=referrer,
+                    dataset=snuba.Dataset.Events,
+                )
+
+                if "error" not in result:
+                    events = [self.__make_event(evt) for evt in result["data"]]
+
+                    # Bind previously fetched node data
+                    nodestore_dict = {
+                        (e.event_id, e.project_id): e.data.data for e in nodestore_events
+                    }
+                    for event in events:
+                        node_data = nodestore_dict[(event.event_id, event.project_id)]
+                        event.data.bind_data(node_data)
+                    return events
+
+            return []
+
         result = snuba.aliased_query(
             selected_columns=cols,
             start=filter.start,
@@ -134,14 +187,12 @@ class SnubaEventStorage(EventStorage):
         if len(event.data) == 0:
             return None
 
-        event_time = datetime.fromtimestamp(event.data["timestamp"])
-
         # Load group_id from Snuba if not a transaction
         if event.get_event_type() != "transaction":
             result = snuba.raw_query(
                 selected_columns=["group_id"],
-                start=event_time,
-                end=event_time + timedelta(seconds=1),
+                start=event.datetime,
+                end=event.datetime + timedelta(seconds=1),
                 filter_keys={"project_id": [project_id], "event_id": [event_id]},
                 limit=1,
                 referrer="eventstore.get_event_by_id_nodestore",
diff --git a/src/sentry/models/group.py b/src/sentry/models/group.py
index c76e9fb900..8af83d6df1 100644
--- a/src/sentry/models/group.py
+++ b/src/sentry/models/group.py
@@ -218,7 +218,7 @@ class GroupManager(BaseManager):
             filter=eventstore.Filter(
                 event_ids=event_ids, project_ids=project_ids, conditions=conditions
             ),
-            limit=len(project_ids),
+            limit=max(len(project_ids), 100),
             referrer="Group.filter_by_event_id",
         )
 
diff --git a/tests/sentry/eventstore/snuba/test_backend.py b/tests/sentry/eventstore/snuba/test_backend.py
index 6d5af0200a..c0323898c9 100644
--- a/tests/sentry/eventstore/snuba/test_backend.py
+++ b/tests/sentry/eventstore/snuba/test_backend.py
@@ -85,6 +85,18 @@ class SnubaEventStorageTest(TestCase, SnubaTestCase):
         events = self.eventstore.get_events(filter=Filter(project_ids=[project.id]))
         assert events == []
 
+        # Test with a list of event IDs and project ID filters
+        events = self.eventstore.get_events(
+            filter=Filter(
+                project_ids=[self.project1.id, self.project2.id],
+                event_ids=["a" * 32, "b" * 32, "c" * 32, "x" * 32, "y" * 32, "z" * 32],
+            )
+        )
+        assert len(events) == 3
+        assert events[0].event_id == "c" * 32
+        assert events[1].event_id == "b" * 32
+        assert events[2].event_id == "a" * 32
+
     def test_get_event_by_id(self):
         # Get valid event
         event = self.eventstore.get_event_by_id(self.project1.id, "a" * 32)
