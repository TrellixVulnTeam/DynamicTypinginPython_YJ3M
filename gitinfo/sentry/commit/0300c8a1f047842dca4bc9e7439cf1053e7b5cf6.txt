commit 0300c8a1f047842dca4bc9e7439cf1053e7b5cf6
Author: David Cramer <dcramer@gmail.com>
Date:   Wed Jan 13 11:05:50 2016 -0800

    Task to re-split a merged group
    
    This will take a given issue, wipe all hashes against it, and ensure the attached events generate a new issue (or get attached to the correct issue). Upon completion it will remove the legacy issue.

diff --git a/src/sentry/tasks/merge.py b/src/sentry/tasks/merge.py
index 812229067d..b6c87ee608 100644
--- a/src/sentry/tasks/merge.py
+++ b/src/sentry/tasks/merge.py
@@ -13,6 +13,7 @@ from django.db import IntegrityError, router, transaction
 from django.db.models import F
 
 from sentry.tasks.base import instrumented_task, retry
+from sentry.tasks.deletion import delete_group
 
 logger = get_task_logger(__name__)
 
@@ -68,6 +69,72 @@ def merge_group(from_object_id=None, to_object_id=None, **kwargs):
     group.delete()
 
 
+@instrumented_task(name='sentry.tasks.merge.rehash_group_events', queue='cleanup',
+                   default_retry_delay=60 * 5, max_retries=None)
+@retry
+def rehash_group_events(group_id, **kwargs):
+    from sentry.models import Group, GroupHash
+
+    group = Group.objects.get(id=group_id)
+
+    # Clear out existing hashes to preempt new events being added
+    # This can cause the new groups to be created before we get to them, but
+    # its a tradeoff we're willing to take
+    GroupHash.objects.filter(group=group).delete()
+
+    has_more = _rehash_group_events(group)
+
+    if has_more:
+        rehash_group_events.delay(
+            group_id=group.id
+        )
+        return
+
+    delete_group.delay(group.id)
+
+
+def _rehash_group_events(group, limit=100):
+    from sentry.event_manager import (
+        EventManager, get_hashes_from_fingerprint, generate_culprit,
+        md5_from_hash
+    )
+    from sentry.models import Event
+
+    event_list = list(Event.objects.filter(group=group)[:limit])
+    Event.objects.bind_nodes(event_list, 'data')
+
+    for event in event_list:
+        fingerprint = event.data.get('fingerprint', ['{{ default }}'])
+        if fingerprint and not isinstance(fingerprint, (list, tuple)):
+            fingerprint = [fingerprint]
+        elif not fingerprint:
+            fingerprint = ['{{ default }}']
+
+        manager = EventManager({})
+
+        group_kwargs = {
+            'message': event.message,
+            'platform': event.platform,
+            'culprit': generate_culprit(event.data),
+            'logger': event.get_tag('logger') or group.logger,
+            'level': group.level,
+            'last_seen': event.datetime,
+            'first_seen': event.datetime,
+        }
+
+        # XXX(dcramer): doesnt support checksums as they're not stored
+        hashes = map(md5_from_hash, get_hashes_from_fingerprint(event, fingerprint))
+        for hash in hashes:
+            new_group, _, _, _ = manager._save_aggregate(
+                event=event,
+                hashes=hashes,
+                release=None,
+                **group_kwargs
+            )
+            event.update(group=new_group)
+    return bool(event_list)
+
+
 def merge_objects(models, group, new_group, limit=1000,
                   logger=None):
 
diff --git a/tests/sentry/tasks/test_merge.py b/tests/sentry/tasks/test_merge.py
index 525e682d7f..55a99e2ee0 100644
--- a/tests/sentry/tasks/test_merge.py
+++ b/tests/sentry/tasks/test_merge.py
@@ -1,6 +1,6 @@
 from __future__ import absolute_import
 
-from sentry.tasks.merge import merge_group
+from sentry.tasks.merge import merge_group, rehash_group_events
 from sentry.models import Event, Group
 from sentry.testutils import TestCase
 
@@ -30,3 +30,32 @@ class MergeGroupTest(TestCase):
         assert event2.group_id == group2.id
         Event.objects.bind_nodes([event2], 'data')
         assert event2.data == {'foo': 'baz'}
+
+
+class RehashGroupEventsTest(TestCase):
+    def test_simple(self):
+        project = self.create_project()
+        group = self.create_group(project)
+        event1 = self.create_event('a' * 32, message='foo', group=group, data={})
+        event2 = self.create_event('b' * 32, message='foo', group=group, data={})
+        event3 = self.create_event('c' * 32, message='bar', group=group, data={})
+
+        with self.tasks():
+            rehash_group_events(group.id)
+
+        assert not Group.objects.filter(id=group.id).exists()
+
+        # this previously would error with NodeIntegrityError due to the
+        # reference check being bound to a group
+        event1 = Event.objects.get(id=event1.id)
+        group1 = event1.group
+        assert sorted(Event.objects.filter(group=group1).values_list('id', flat=True)) == [
+            event1.id,
+            event2.id,
+        ]
+
+        event3 = Event.objects.get(id=event3.id)
+        group2 = event3.group
+        assert sorted(Event.objects.filter(group=group2).values_list('id', flat=True)) == [
+            event3.id,
+        ]
