commit 0ddb6e2e13051882eb433f87126491d0ec0cc94e
Author: Filippo Pacifici <fpacifici@sentry.io>
Date:   Tue Jul 9 10:31:36 2019 -0700

    feat(issueless events): Test eventstream work without groups (#13888)
    
    Adds a test for eventstream without issue.

diff --git a/tests/snuba/eventstream/test_eventstream.py b/tests/snuba/eventstream/test_eventstream.py
index 28c7404485..b5dd4a72d0 100644
--- a/tests/snuba/eventstream/test_eventstream.py
+++ b/tests/snuba/eventstream/test_eventstream.py
@@ -20,6 +20,37 @@ class SnubaEventStreamTest(TestCase, SnubaTestCase):
         self.kafka_eventstream = KafkaEventStream()
         self.kafka_eventstream.producer = Mock()
 
+    def __build_event(self, timestamp):
+        raw_event = {
+            'event_id': 'a' * 32,
+            'message': 'foo',
+            'timestamp': time.mktime(timestamp.timetuple()),
+            'level': logging.ERROR,
+            'logger': 'default',
+            'tags': [],
+        }
+        manager = EventManager(raw_event)
+        manager.normalize()
+        return manager.save(self.project.id)
+
+    def __produce_event(self, *insert_args, **insert_kwargs):
+        # pass arguments on to Kafka EventManager
+        self.kafka_eventstream.insert(*insert_args, **insert_kwargs)
+
+        produce_args, produce_kwargs = list(self.kafka_eventstream.producer.produce.call_args)
+        assert not produce_args
+        assert produce_kwargs['topic'] == 'events'
+        assert produce_kwargs['key'] == six.text_type(self.project.id)
+
+        version, type_, payload1, payload2 = json.loads(produce_kwargs['value'])
+        assert version == 2
+        assert type_ == 'insert'
+
+        # insert what would have been the Kafka payload directly
+        # into Snuba, expect an HTTP 200 and for the event to now exist
+        snuba_eventstream = SnubaEventStream()
+        snuba_eventstream._send(self.project.id, 'insert', (payload1, payload2))
+
     @patch('sentry.eventstream.insert')
     @patch('sentry.tagstore.delay_index_event_tags')
     def test(self, mock_delay_index_event_tags, mock_eventstream_insert):
@@ -35,18 +66,7 @@ class SnubaEventStreamTest(TestCase, SnubaTestCase):
 
         assert _get_event_count() == 0
 
-        raw_event = {
-            'event_id': 'a' * 32,
-            'message': 'foo',
-            'timestamp': time.mktime(now.timetuple()),
-            'level': logging.ERROR,
-            'logger': 'default',
-            'tags': [],
-        }
-
-        manager = EventManager(raw_event)
-        manager.normalize()
-        event = manager.save(self.project.id)
+        event = self.__build_event(now)
 
         # verify eventstream was called by EventManager
         insert_args, insert_kwargs = list(mock_eventstream_insert.call_args)
@@ -64,20 +84,38 @@ class SnubaEventStreamTest(TestCase, SnubaTestCase):
 
         assert mock_delay_index_event_tags.call_count == 1
 
-        # pass arguments on to Kafka EventManager
-        self.kafka_eventstream.insert(*insert_args, **insert_kwargs)
+        self.__produce_event(*insert_args, **insert_kwargs)
+        assert _get_event_count() == 1
 
-        produce_args, produce_kwargs = list(self.kafka_eventstream.producer.produce.call_args)
-        assert not produce_args
-        assert produce_kwargs['topic'] == 'events'
-        assert produce_kwargs['key'] == six.text_type(self.project.id)
+    @patch('sentry.eventstream.insert')
+    @patch('sentry.tagstore.delay_index_event_tags')
+    def test_issueless(self, mock_delay_index_event_tags, mock_eventstream_insert):
+        now = datetime.utcnow()
+        event = self.__build_event(now)
 
-        version, type_, payload1, payload2 = json.loads(produce_kwargs['value'])
-        assert version == 2
-        assert type_ == 'insert'
+        event.group_id = None
+        insert_args = ()
+        insert_kwargs = {
+            'event': event,
+            'group': None,
+            'is_new_group_environment': True,
+            'is_new': True,
+            'is_regression': False,
+            'is_sample': False,
+            'primary_hash': 'acbd18db4cc2f85cedef654fccc4a4d8',
+            'skip_consume': False
+        }
 
-        # insert what would have been the Kafka payload directly
-        # into Snuba, expect an HTTP 200 and for the event to now exist
-        snuba_eventstream = SnubaEventStream()
-        snuba_eventstream._send(self.project.id, 'insert', (payload1, payload2))
-        assert _get_event_count() == 1
+        self.__produce_event(*insert_args, **insert_kwargs)
+        result = snuba.raw_query(
+            start=now - timedelta(days=1),
+            end=now + timedelta(days=1),
+            selected_columns=['event_id', 'group_id'],
+            groupby=None,
+            filter_keys={
+                'project_id': [self.project.id],
+                'event_id': [event.event_id],
+            },
+        )
+        assert len(result['data']) == 1
+        assert result['data'][0]['group_id'] is None
