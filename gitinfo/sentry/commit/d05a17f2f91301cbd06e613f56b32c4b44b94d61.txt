commit d05a17f2f91301cbd06e613f56b32c4b44b94d61
Author: evanh <evanh@users.noreply.github.com>
Date:   Fri May 15 13:17:20 2020 -0400

    fix(discover) Handle ms timestamps in aggregate conditions (#18802)
    
    Fix the functionality for comparing date columns with +/- date ranges in
    discover to mirror the functionality in issue search. Also with aggregate
    conditions, the timestamp we were sending to snuba were in ms, but snuba expects
    them to be in seconds.

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index eabccaefb4..56a14748b8 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -100,7 +100,7 @@ boolean_term         = (paren_term / search_term) space? (boolean_operator space
 paren_term           = spaces open_paren space? (paren_term / boolean_term)+ space? closed_paren spaces
 search_term          = key_val_term / quoted_raw_search / raw_search
 key_val_term         = spaces (tag_filter / time_filter / rel_time_filter / specific_time_filter / duration_filter
-                       / numeric_filter / aggregate_filter / aggregate_date_filter / has_filter
+                       / numeric_filter / aggregate_filter / aggregate_date_filter / aggregate_rel_date_filter / has_filter
                        / is_filter / quoted_basic_filter / basic_filter)
                        spaces
 raw_search           = (!key_val_term ~r"\ *([^\ ^\n ()]+)\ *" )*
@@ -120,8 +120,9 @@ specific_time_filter = search_key sep (date_format / alt_date_format)
 # Numeric comparison filter
 numeric_filter       = search_key sep operator? numeric_value
 # Aggregate numeric filter
-aggregate_filter        = aggregate_key sep operator? (numeric_value / duration_format)
-aggregate_date_filter   = aggregate_key sep operator? (date_format / alt_date_format / rel_date_format)
+aggregate_filter          = aggregate_key sep operator? (numeric_value / duration_format)
+aggregate_date_filter     = aggregate_key sep operator? (date_format / alt_date_format)
+aggregate_rel_date_filter = aggregate_key sep operator? rel_date_format
 
 # has filter for not null type checks
 has_filter           = negation? "has" sep (search_key / search_value)
@@ -419,7 +420,6 @@ class SearchVisitor(NodeVisitor):
         search_value = search_value[0]
         operator = operator[0] if not isinstance(operator, Node) else "="
         is_date_aggregate = any(key in search_key.name for key in self.date_keys)
-
         if is_date_aggregate:
             try:
                 search_value = parse_datetime_string(search_value)
@@ -430,6 +430,28 @@ class SearchVisitor(NodeVisitor):
             search_value = operator + search_value if operator != "=" else search_value
             return AggregateFilter(search_key, "=", SearchValue(search_value))
 
+    def visit_aggregate_rel_date_filter(self, node, children):
+        (search_key, _, operator, search_value) = children
+        operator = operator[0] if not isinstance(operator, Node) else "="
+        is_date_aggregate = any(key in search_key.name for key in self.date_keys)
+        if is_date_aggregate:
+            try:
+                from_val, to_val = parse_datetime_range(search_value.text)
+            except InvalidQuery as exc:
+                raise InvalidSearchQuery(six.text_type(exc))
+
+            if from_val is not None:
+                operator = ">="
+                search_value = from_val[0]
+            else:
+                operator = "<="
+                search_value = to_val[0]
+
+            return AggregateFilter(search_key, operator, SearchValue(search_value))
+        else:
+            search_value = operator + search_value.text if operator != "=" else search_value
+            return AggregateFilter(search_key, "=", SearchValue(search_value))
+
     def visit_time_filter(self, node, children):
         (search_key, _, operator, search_value) = children
         search_value = search_value[0]
@@ -656,9 +678,7 @@ def convert_aggregate_filter_to_snuba_query(aggregate_filter, params):
     value = aggregate_filter.value.value
 
     value = (
-        int(to_timestamp(value)) * 1000
-        if isinstance(value, datetime) and name != "timestamp"
-        else value
+        int(to_timestamp(value)) if isinstance(value, datetime) and name != "timestamp" else value
     )
 
     if aggregate_filter.operator in ("=", "!=") and aggregate_filter.value.value == "":
diff --git a/src/sentry/search/utils.py b/src/sentry/search/utils.py
index 0a9001f542..366f1af3ea 100644
--- a/src/sentry/search/utils.py
+++ b/src/sentry/search/utils.py
@@ -121,7 +121,7 @@ def parse_datetime_string(value):
     except ValueError:
         pass
 
-    raise InvalidQuery(u"{} is not a valid datetime query".format(value))
+    raise InvalidQuery(u"{} is not a valid ISO8601 date query".format(value))
 
 
 def parse_datetime_comparison(value):
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index 775cff99b8..97a62cd176 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -648,6 +648,27 @@ class ParseSearchQueryTest(unittest.TestCase):
         with self.assertRaises(InvalidSearchQuery, regex="not a duration column"):
             parse_search_query("avg(stack.colno):>500s")
 
+    def test_aggregate_rel_time_filter(self):
+        now = timezone.now()
+        with freeze_time(now):
+            assert parse_search_query("last_seen():+7d") == [
+                SearchFilter(
+                    key=SearchKey(name="last_seen()"),
+                    operator="<=",
+                    value=SearchValue(raw_value=now - timedelta(days=7)),
+                )
+            ]
+            assert parse_search_query("last_seen():-2w") == [
+                SearchFilter(
+                    key=SearchKey(name="last_seen()"),
+                    operator=">=",
+                    value=SearchValue(raw_value=now - timedelta(days=14)),
+                )
+            ]
+            assert parse_search_query("random:-2w") == [
+                SearchFilter(key=SearchKey(name="random"), operator="=", value=SearchValue("-2w"))
+            ]
+
     def test_quotes_filtered_on_raw(self):
         # Enclose the full raw query? Strip it.
         assert parse_search_query('thinger:unknown "what is this?"') == [
@@ -1294,7 +1315,7 @@ class GetSnubaQueryArgsTest(TestCase):
 
     def test_function_with_date_arguments(self):
         result = get_filter("last_seen():2020-04-01T19:34:52+00:00")
-        assert result.having == [["last_seen", "=", 1585769692000]]
+        assert result.having == [["last_seen", "=", 1585769692]]
 
     @pytest.mark.xfail(reason="this breaks issue search so needs to be redone")
     def test_trace_id(self):
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index d987679848..219845ceb3 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -1128,7 +1128,7 @@ class QueryTransformTest(TestCase):
                 ["avg", "duration", "avg_transaction_duration"],
                 ["max", "time", "max_time"],
             ],
-            having=[["max_time", ">", 1575158400000]],
+            having=[["max_time", ">", 1575158400]],
             end=end_time,
             start=start_time,
             orderby=None,
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index b0b9e769b3..5c9ee71843 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -1959,7 +1959,7 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
 
             assert response.status_code == 200, response.content
             data = response.data["data"]
-            assert len(data) == 0
+            assert len(data) == 1
 
         with self.feature(
             {"organizations:discover-basic": True, "organizations:global-views": True}
@@ -2189,6 +2189,55 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[0]["issue"] == event1.group.qualified_short_id
         assert data[1]["issue"] == "unknown"
 
+    def test_last_seen_negative_duration(self):
+        self.login_as(user=self.user)
+
+        project = self.create_project()
+        self.store_event(
+            data={"event_id": "f" * 32, "timestamp": self.two_min_ago, "fingerprint": ["group_1"]},
+            project_id=project.id,
+        )
+
+        with self.feature(
+            {"organizations:discover-basic": True, "organizations:global-views": True}
+        ):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={"field": ["id", "last_seen()"], "query": "last_seen():-30d"},
+            )
+
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 1
+        assert data[0]["id"] == "f" * 32
+
+    def test_last_seen_aggregate_condition(self):
+        self.login_as(user=self.user)
+
+        project = self.create_project()
+        self.store_event(
+            data={"event_id": "f" * 32, "timestamp": self.two_min_ago, "fingerprint": ["group_1"]},
+            project_id=project.id,
+        )
+
+        with self.feature(
+            {"organizations:discover-basic": True, "organizations:global-views": True}
+        ):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "field": ["id", "last_seen()"],
+                    "query": "last_seen():>{}".format(iso_format(before_now(days=30))),
+                },
+            )
+
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 1
+        assert data[0]["id"] == "f" * 32
+
     def test_context_fields(self):
         self.login_as(user=self.user)
         project = self.create_project()
