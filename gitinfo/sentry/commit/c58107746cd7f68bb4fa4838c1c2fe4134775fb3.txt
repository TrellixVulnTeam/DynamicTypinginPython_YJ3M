commit c58107746cd7f68bb4fa4838c1c2fe4134775fb3
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Mon Nov 18 18:58:36 2019 +0000

    feat: Do not save event to Postgres (#15544)
    
    Since we fetch events exclusively from Snuba now, we no longer need to
    write events to Postgres.
    
    Saving can be (temporarily) restored for rollout by setting store.skip-pg-save
    to False.

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 67bac27dec..072cd0b385 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -15,7 +15,7 @@ from django.db.models import Func
 from django.utils import timezone
 from django.utils.encoding import force_text
 
-from sentry import buffer, eventtypes, eventstream, tsdb
+from sentry import buffer, eventtypes, eventstream, options, tsdb
 from sentry.constants import (
     DEFAULT_STORE_NORMALIZER_ARGS,
     LOG_LEVELS,
@@ -719,22 +719,27 @@ class EventManager(object):
                 group=group, environment=environment
             )
 
-        # save the event
-        try:
-            with transaction.atomic(using=router.db_for_write(Event)):
-                event.data.save()
-                event.save()
-        except IntegrityError:
-            logger.info(
-                "duplicate.found",
-                exc_info=True,
-                extra={
-                    "event_uuid": event_id,
-                    "project_id": project.id,
-                    "group_id": group.id if group else None,
-                    "model": Event.__name__,
-                },
-            )
+        # Write the event to Nodestore if "store.skip-pg-save" is True
+        # If False, write to both Postgres and Nodestore (this path is temporary
+        # and will be removed after rollout)
+        if options.get("store.skip-pg-save", False):
+            event.data.save()
+        else:
+            try:
+                with transaction.atomic(using=router.db_for_write(Event)):
+                    event.data.save()
+                    event.save()
+            except IntegrityError:
+                logger.info(
+                    "duplicate.found",
+                    exc_info=True,
+                    extra={
+                        "event_uuid": event_id,
+                        "project_id": project.id,
+                        "group_id": group.id if group else None,
+                        "model": Event.__name__,
+                    },
+                )
 
         if event_user:
             counters = [
diff --git a/src/sentry/testutils/factories.py b/src/sentry/testutils/factories.py
index 0cb91c85f9..74ec9e87d7 100644
--- a/src/sentry/testutils/factories.py
+++ b/src/sentry/testutils/factories.py
@@ -494,7 +494,6 @@ class Factories(object):
         event = Event(event_id=event_id, group=group, **kwargs)
         # emulate EventManager refs
         event.data.bind_ref(event)
-        event.save()
         event.data.save()
         return event
 
diff --git a/src/sentry/web/frontend/debug/mail.py b/src/sentry/web/frontend/debug/mail.py
index 9d86d3465b..f8372b9c31 100644
--- a/src/sentry/web/frontend/debug/mail.py
+++ b/src/sentry/web/frontend/debug/mail.py
@@ -13,7 +13,6 @@ from django.template.defaultfilters import slugify
 from django.utils import timezone
 from django.utils.safestring import mark_safe
 from django.views.generic import View
-from django.db import IntegrityError
 from loremipsum import Generator
 from random import Random
 
@@ -244,10 +243,6 @@ def alert(request):
     event = event_manager.save(project.id)
     # Prevent Percy screenshot from constantly changing
     event.datetime = datetime(2017, 9, 6, 0, 0)
-    try:
-        event.save()
-    except IntegrityError:
-        pass
     event_type = event_manager.get_event_type()
 
     group.message = event_manager.get_search_message()
diff --git a/tests/acceptance/test_issue_details_workflow.py b/tests/acceptance/test_issue_details_workflow.py
index 1b9a1acafb..293d07251b 100644
--- a/tests/acceptance/test_issue_details_workflow.py
+++ b/tests/acceptance/test_issue_details_workflow.py
@@ -27,7 +27,6 @@ class IssueDetailsWorkflowTest(AcceptanceTestCase, SnubaTestCase):
             data=event_data, project_id=self.project.id, assert_no_errors=False
         )
         event.datetime = datetime(2017, 9, 6, 0, 0)
-        event.save()
         event.group.update(
             first_seen=datetime(2015, 8, 13, 3, 8, 25, tzinfo=timezone.utc),
             last_seen=datetime(2016, 1, 13, 3, 8, 25, tzinfo=timezone.utc),
diff --git a/tests/sentry/db/test_parse_query.py b/tests/sentry/db/test_parse_query.py
index 8bc064f029..48988525e7 100644
--- a/tests/sentry/db/test_parse_query.py
+++ b/tests/sentry/db/test_parse_query.py
@@ -18,10 +18,6 @@ class ParseQuery(TestCase):
                     u"sql": u'SELECT "sentry_reprocessingreport"."id", "sentry_reprocessingreport"."project_id", "sentry_reprocessingreport"."event_id", "sentry_reprocessingreport"."datetime" FROM "sentry_reprocessingreport" WHERE ("sentry_reprocessingreport"."event_id" = \'1fba9e314001443b93285dc4411f1593\'  AND "sentry_reprocessingreport"."project_id" = 864 )',
                     u"time": u"0.001",
                 },
-                {
-                    u"sql": u'SELECT "sentry_message"."id", "sentry_message"."group_id", "sentry_message"."message_id", "sentry_message"."project_id", "sentry_message"."message", "sentry_message"."platform", "sentry_message"."datetime", "sentry_message"."time_spent", "sentry_message"."data" FROM "sentry_message" WHERE ("sentry_message"."message_id" = \'1fba9e314001443b93285dc4411f1593\'  AND "sentry_message"."project_id" = 864 )',
-                    u"time": u"0.001",
-                },
                 {u"sql": u'SAVEPOINT "s47890194282880_x50"', u"time": u"0.000"},
                 {
                     u"sql": u'INSERT INTO "sentry_eventuser" ("project_id", "hash", "ident", "email", "username", "name", "ip_address", "date_added") VALUES (864, \'f528764d624db129b32c21fbca0cb8d6\', NULL, NULL, NULL, NULL, \'127.0.0.1\', \'2018-05-22 09:12:12.357888+00:00\') RETURNING "sentry_eventuser"."id"',
@@ -69,10 +65,6 @@ class ParseQuery(TestCase):
                     u"time": u"0.000",
                 },
                 {u"sql": u'RELEASE SAVEPOINT "s47890194282880_x53"', u"time": u"0.000"},
-                {
-                    u"sql": u'INSERT INTO "sentry_message" ("group_id", "message_id", "project_id", "message", "platform", "datetime", "time_spent", "data") VALUES (662, \'1fba9e314001443b93285dc4411f1593\', 864, \'hello http://example.com\', \'javascript\', \'2018-05-22 09:12:12+00:00\', NULL, \'eJzTSCkw5ApWz8tPSY3PTFHnKjAC8kotM8sMPTNMglwKq0zdS3LKI4y1QxxtbYHSxlzFegCZxA8W\') RETURNING "sentry_message"."id"',
-                    u"time": u"0.000",
-                },
                 {u"sql": u'RELEASE SAVEPOINT "s47890194282880_x52"', u"time": u"0.000"},
                 {u"sql": u'SAVEPOINT "s47890194282880_x54"', u"time": u"0.000"},
                 {u"sql": u'RELEASE SAVEPOINT "s47890194282880_x54"', u"time": u"0.000"},
@@ -98,6 +90,5 @@ class ParseQuery(TestCase):
             "sentry_environmentproject": 1,
             "sentry_eventuser": 1,
             "sentry_groupedmessage": 1,
-            "sentry_message": 1,
             "sentry_userreport": 1,
         }
diff --git a/tests/sentry/deletions/test_event.py b/tests/sentry/deletions/test_event.py
deleted file mode 100644
index 1abc756291..0000000000
--- a/tests/sentry/deletions/test_event.py
+++ /dev/null
@@ -1,40 +0,0 @@
-from __future__ import absolute_import
-
-from sentry import nodestore
-from sentry.models import Event, EventAttachment, File, ScheduledDeletion, UserReport
-from sentry.tasks.deletion import run_deletion
-from sentry.testutils import TestCase
-
-
-class DeleteEventTest(TestCase):
-    def test_simple(self):
-        event_id = "a" * 32
-        project = self.create_project()
-        node_id = Event.generate_node_id(project.id, event_id)
-        group = self.create_group(project=project)
-        event = self.create_event(group=group, event_id=event_id)
-        EventAttachment.objects.create(
-            event_id=event.event_id,
-            project_id=event.project_id,
-            file=File.objects.create(name="hello.png", type="image/png"),
-            name="hello.png",
-        )
-        UserReport.objects.create(
-            event_id=event.event_id, project_id=event.project_id, name="Jane Bloggs"
-        )
-        assert nodestore.get(node_id) is not None
-        deletion = ScheduledDeletion.schedule(event, days=0)
-        deletion.update(in_progress=True)
-
-        with self.tasks():
-            run_deletion(deletion.id)
-
-        assert not Event.objects.filter(event_id=event.event_id).exists()
-        assert not EventAttachment.objects.filter(
-            event_id=event.event_id, project_id=project.id
-        ).exists()
-        assert not UserReport.objects.filter(
-            event_id=event.event_id, project_id=project.id
-        ).exists()
-
-        assert nodestore.get(node_id) is None
diff --git a/tests/sentry/deletions/test_group.py b/tests/sentry/deletions/test_group.py
index 73c24a4098..a9b8a2308f 100644
--- a/tests/sentry/deletions/test_group.py
+++ b/tests/sentry/deletions/test_group.py
@@ -1,7 +1,6 @@
 from __future__ import absolute_import
 
 import mock
-import os
 from uuid import uuid4
 
 from sentry.models import (
@@ -91,7 +90,6 @@ class DeleteGroupTest(TestCase, SnubaTestCase):
         with self.tasks():
             delete_groups(object_ids=[group.id])
 
-        assert not Event.objects.filter(event_id=self.event.event_id).exists()
         assert not UserReport.objects.filter(group_id=group.id).exists()
         assert not UserReport.objects.filter(event_id=self.event.event_id).exists()
         assert not EventAttachment.objects.filter(event_id=self.event.event_id).exists()
@@ -103,15 +101,13 @@ class DeleteGroupTest(TestCase, SnubaTestCase):
         assert not nodestore.get(self.node_id2)
         assert nodestore.get(self.node_id3), "Does not remove from second group"
 
+    @mock.patch("os.environ.get")
     @mock.patch("sentry.nodestore.delete_multi")
-    def test_cleanup(self, nodestore_delete_multi):
-        # Skip EventDataDeletionTask if _SENTRY_CLEANUP is set
-        os.environ["_SENTRY_CLEANUP"] = "1"
+    def test_cleanup(self, nodestore_delete_multi, os_environ):
+        os_environ.side_effect = lambda key: "1" if key == "_SENTRY_CLEANUP" else None
         group = self.event.group
 
         with self.tasks():
             delete_groups(object_ids=[group.id])
 
-        # Eventually this will be 0, nodestore deletions are currently still
-        # being triggered from event deletions
-        assert nodestore_delete_multi.call_count == 1
+        assert nodestore_delete_multi.call_count == 0
diff --git a/tests/sentry/deletions/test_project.py b/tests/sentry/deletions/test_project.py
index 90ce431b43..ac2ef41833 100644
--- a/tests/sentry/deletions/test_project.py
+++ b/tests/sentry/deletions/test_project.py
@@ -5,7 +5,6 @@ from sentry.models import (
     CommitAuthor,
     Environment,
     EnvironmentProject,
-    Event,
     EventAttachment,
     File,
     Group,
@@ -82,7 +81,6 @@ class DeleteProjectTest(TestCase):
         ).exists()
         assert Environment.objects.filter(id=env.id).exists()
         assert not Group.objects.filter(project_id=project.id).exists()
-        assert not Event.objects.filter(project_id=project.id).exists()
         assert not EventAttachment.objects.filter(project_id=project.id).exists()
         assert Release.objects.filter(id=release.id).exists()
         assert ReleaseCommit.objects.filter(release_id=release.id).exists()
diff --git a/tests/sentry/digests/test_notifications.py b/tests/sentry/digests/test_notifications.py
index 0ba1ecab34..76e876d5bd 100644
--- a/tests/sentry/digests/test_notifications.py
+++ b/tests/sentry/digests/test_notifications.py
@@ -32,7 +32,11 @@ class RewriteRecordTestCase(TestCase):
             project=self.event.project,
             groups={self.event.group.id: self.event.group},
             rules={self.rule.id: self.rule},
-        ) == Record(self.record.key, Notification(self.event, [self.rule]), self.record.timestamp)
+        ) == Record(
+            self.record.key,
+            Notification(self.record.value.event, [self.rule]),
+            self.record.timestamp,
+        )
 
     def test_without_group(self):
         # If the record can't be associated with a group, it should be returned as None.
@@ -44,13 +48,14 @@ class RewriteRecordTestCase(TestCase):
         )
 
     def test_filters_invalid_rules(self):
-        # If the record can't be associated with a group, it should be returned as None.
         assert rewrite_record(
             self.record,
             project=self.event.project,
             groups={self.event.group.id: self.event.group},
             rules={},
-        ) == Record(self.record.key, Notification(self.event, []), self.record.timestamp)
+        ) == Record(
+            self.record.key, Notification(self.record.value.event, []), self.record.timestamp
+        )
 
 
 class GroupRecordsTestCase(TestCase):
diff --git a/tests/sentry/digests/test_utilities.py b/tests/sentry/digests/test_utilities.py
index cc3d342d54..b0e280fbbc 100644
--- a/tests/sentry/digests/test_utilities.py
+++ b/tests/sentry/digests/test_utilities.py
@@ -67,7 +67,9 @@ class UtilitiesHelpersTestCase(TestCase, SnubaTestCase):
         )
 
         events.pop(0)  # remove event with same group
-        assert get_event_from_groups_in_digest(digest) == set(events)
+        assert set([e.event_id for e in get_event_from_groups_in_digest(digest)]) == set(
+            [e.event_id for e in events]
+        )
 
     def test_team_actors_to_user_ids(self):
         team1 = self.create_team()
@@ -234,7 +236,9 @@ class GetPersonalizedDigestsTestCase(TestCase, SnubaTestCase):
         result_user_ids = []
         for user_id, user_digest in get_personalized_digests(project.id, digest, user_ids):
             assert user_id in expected_result
-            assert expected_result[user_id] == get_event_from_groups_in_digest(user_digest)
+            assert set([e.event_id for e in get_event_from_groups_in_digest(user_digest)]) == set(
+                [e.event_id for e in expected_result[user_id]]
+            )
             result_user_ids.append(user_id)
 
         assert sorted(expected_result.keys()) == sorted(result_user_ids)
diff --git a/tests/sentry/event_manager/test_event_manager.py b/tests/sentry/event_manager/test_event_manager.py
index e7e55db6ba..74cc454f45 100644
--- a/tests/sentry/event_manager/test_event_manager.py
+++ b/tests/sentry/event_manager/test_event_manager.py
@@ -12,6 +12,7 @@ from datetime import datetime, timedelta
 from django.utils import timezone
 from time import time
 
+from sentry import nodestore
 from sentry.app import tsdb
 from sentry.constants import MAX_VERSION_LENGTH
 from sentry.event_manager import HashDiscarded, EventManager, EventUser
@@ -83,21 +84,24 @@ class EventManagerTest(TestCase):
         assert group.platform == "python"
         assert event.platform == "python"
 
-    def test_dupe_message_id(self):
+    @mock.patch("sentry.event_manager.eventstream.insert")
+    def test_dupe_message_id(self, eventstream_insert):
+        # Saves the latest event to nodestore and eventstream
+        project_id = 1
         event_id = "a" * 32
+        node_id = Event.generate_node_id(project_id, event_id)
 
-        manager = EventManager(make_event(event_id=event_id))
+        manager = EventManager(make_event(event_id=event_id, message="first"))
         manager.normalize()
-        manager.save(1)
-
-        assert Event.objects.count() == 1
+        manager.save(project_id)
+        assert nodestore.get(node_id)["logentry"]["formatted"] == "first"
 
-        # ensure that calling it again doesn't raise a db error
-        manager = EventManager(make_event(event_id=event_id))
+        manager = EventManager(make_event(event_id=event_id, message="second"))
         manager.normalize()
-        manager.save(1)
+        manager.save(project_id)
+        assert nodestore.get(node_id)["logentry"]["formatted"] == "second"
 
-        assert Event.objects.count() == 1
+        assert eventstream_insert.call_count == 2
 
     def test_updates_group(self):
         timestamp = time() - 300
@@ -741,7 +745,7 @@ class EventManagerTest(TestCase):
             manager = EventManager(
                 make_event(
                     **{
-                        "event_id": uuid.uuid1().hex,  # don't deduplicate
+                        "event_id": uuid.uuid1().hex,
                         "environment": "beta",
                         "release": release_version,
                     }
diff --git a/tests/sentry/lang/java/test_plugin.py b/tests/sentry/lang/java/test_plugin.py
index 4a98d7ab3e..6690ad40c7 100644
--- a/tests/sentry/lang/java/test_plugin.py
+++ b/tests/sentry/lang/java/test_plugin.py
@@ -97,7 +97,6 @@ class BasicResolvingIntegrationTest(TestCase):
                 "nodestore_node": 2,
                 "sentry_eventuser": 1,
                 "sentry_groupedmessage": 1,
-                "sentry_message": 1,
                 "sentry_userreport": 1,
             }
         ):
diff --git a/tests/sentry/lang/javascript/test_plugin.py b/tests/sentry/lang/javascript/test_plugin.py
index 60232c0242..0fe22aa648 100644
--- a/tests/sentry/lang/javascript/test_plugin.py
+++ b/tests/sentry/lang/javascript/test_plugin.py
@@ -63,7 +63,6 @@ class JavascriptIntegrationTest(TestCase, SnubaTestCase):
                 "nodestore_node": 2,
                 "sentry_eventuser": 1,
                 "sentry_groupedmessage": 1,
-                "sentry_message": 1,
                 "sentry_userreport": 1,
             },
             debug=True,
diff --git a/tests/sentry/models/tests.py b/tests/sentry/models/tests.py
index 7d4c27898b..95d21d382a 100644
--- a/tests/sentry/models/tests.py
+++ b/tests/sentry/models/tests.py
@@ -159,7 +159,6 @@ class EventNodeStoreTest(TestCase):
         group2 = self.create_group(project2)
         event = self.create_event(group=group2)
         event.data.bind_ref(invalid_event)
-        event.save()
         event.data.save()
 
         assert event.data.get_ref(event) != event.data.get_ref(invalid_event)
@@ -170,7 +169,6 @@ class EventNodeStoreTest(TestCase):
     def test_accepts_valid_ref(self):
         event = self.create_event()
         event.data.bind_ref(event)
-        event.save()
 
         Event.objects.bind_nodes([event], "data")
 
diff --git a/tests/sentry/rules/conditions/test_level_event.py b/tests/sentry/rules/conditions/test_level_event.py
index 6c50891bf8..530f4507c6 100644
--- a/tests/sentry/rules/conditions/test_level_event.py
+++ b/tests/sentry/rules/conditions/test_level_event.py
@@ -56,6 +56,7 @@ class LevelConditionTest(RuleTestCase):
     #
     # Specifically here to make sure the check is properly checking the event's level
     def test_differing_levels(self):
+
         eevent = self.create_event(tags={"level": "error"})
         wevent = self.create_event(tags={"level": "warning"})
 
diff --git a/tests/sentry/tasks/test_merge.py b/tests/sentry/tasks/test_merge.py
index 80ab0a7a53..e3682ac7f8 100644
--- a/tests/sentry/tasks/test_merge.py
+++ b/tests/sentry/tasks/test_merge.py
@@ -8,6 +8,7 @@ from sentry.similarity import _make_index_backend
 from sentry.testutils import TestCase
 from sentry.utils import redis
 from sentry.testutils.helpers.datetime import iso_format, before_now
+from sentry import eventstream, eventstore
 
 # Use the default redis client as a cluster client in the similarity index
 index = _make_index_backend(redis.clusters.get("default").get_local_client(0))
@@ -48,26 +49,41 @@ class MergeGroupTest(TestCase):
         ) == [1, 2]
 
     def test_merge_with_event_integrity(self):
-        project1 = self.create_project()
-        group1 = self.create_group(project1)
-        event1 = self.create_event("a" * 32, group=group1, data={"extra": {"foo": "bar"}})
-        project2 = self.create_project()
-        group2 = self.create_group(project2)
-        event2 = self.create_event("b" * 32, group=group2, data={"extra": {"foo": "baz"}})
+        project = self.create_project()
+        event1 = self.store_event(
+            data={
+                "event_id": "a" * 32,
+                "timestamp": iso_format(before_now(seconds=1)),
+                "fingerprint": ["group-1"],
+                "extra": {"foo": "bar"},
+            },
+            project_id=project.id,
+        )
+        group1 = event1.group
+        event2 = self.store_event(
+            data={
+                "event_id": "b" * 32,
+                "timestamp": iso_format(before_now(seconds=1)),
+                "fingerprint": ["group-2"],
+                "extra": {"foo": "baz"},
+            },
+            project_id=project.id,
+        )
+        group2 = event2.group
 
         with self.tasks():
+            eventstream_state = eventstream.start_merge(project.id, [group1.id], group2.id)
             merge_groups([group1.id], group2.id)
+            eventstream.end_merge(eventstream_state)
 
         assert not Group.objects.filter(id=group1.id).exists()
 
-        # this previously would error with NodeIntegrityError due to the
-        # reference check being bound to a group
-        event1 = Event.objects.get(id=event1.id)
+        event1 = eventstore.get_event_by_id(project.id, event1.event_id)
         assert event1.group_id == group2.id
         Event.objects.bind_nodes([event1], "data")
         assert event1.data["extra"]["foo"] == "bar"
 
-        event2 = Event.objects.get(id=event2.id)
+        event2 = eventstore.get_event_by_id(project.id, event2.event_id)
         assert event2.group_id == group2.id
         Event.objects.bind_nodes([event2], "data")
         assert event2.data["extra"]["foo"] == "baz"
