commit 8d5a7bbed5e073be4485046f53c80dd01dbc732e
Author: Dan Fuller <dfuller@sentry.io>
Date:   Tue Feb 26 13:25:55 2019 -0800

    refs(api): Default to using SnubaSearchBackend for search. Remove unused code from
    DjangoSearchBackend (SEN-181)
    
    Production is now in a world where we're entirely using Snuba for search. It's time to start relying
    on this in dev as well, so that we're getting the same results. Matt is working on
    https://github.com/getsentry/sentry/pull/12173, which will make it easy to run Snuba locally. So
    once that has been merged, we can merge this as well.
    
    Also removes unused `_query` code from `DjangoSearchBackend`, and cascades out to remove anything
    that is now unused due to that removal. I plan to just merge the django and snuba backends together,
    but this pr is already pretty big so holding off for now.

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index c22f987aa5..6f5afa72a3 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -1076,7 +1076,7 @@ SENTRY_TAGSTORE_OPTIONS = (
 )
 
 # Search backend
-SENTRY_SEARCH = os.environ.get('SENTRY_SEARCH', 'sentry.search.django.DjangoSearchBackend')
+SENTRY_SEARCH = os.environ.get('SENTRY_SEARCH', 'sentry.search.snuba.SnubaSearchBackend')
 SENTRY_SEARCH_OPTIONS = {}
 # SENTRY_SEARCH_OPTIONS = {
 #     'urls': ['http://localhost:9200/'],
@@ -1090,7 +1090,7 @@ SENTRY_TSDB_OPTIONS = {}
 SENTRY_NEWSLETTER = 'sentry.newsletter.base.Newsletter'
 SENTRY_NEWSLETTER_OPTIONS = {}
 
-SENTRY_EVENTSTREAM = 'sentry.eventstream.base.EventStream'
+SENTRY_EVENTSTREAM = 'sentry.eventstream.snuba.SnubaEventStream'
 SENTRY_EVENTSTREAM_OPTIONS = {}
 
 # rollups must be ordered from highest granularity to lowest
diff --git a/src/sentry/search/django/backend.py b/src/sentry/search/django/backend.py
index fe98e72dc0..5b0c0b51ae 100644
--- a/src/sentry/search/django/backend.py
+++ b/src/sentry/search/django/backend.py
@@ -11,80 +11,27 @@ from __future__ import absolute_import
 import functools
 from datetime import timedelta
 
-from django.db import router
 from django.db.models import Q
 from django.utils import timezone
 
-from sentry import quotas, tagstore
-from sentry.api.paginator import DateTimePaginator, Paginator, SequencePaginator
+from sentry import quotas
 from sentry.api.event_search import InvalidSearchQuery
-from sentry.search.base import SearchBackend
-from sentry.search.django.constants import (
-    SORT_CLAUSES, SQLITE_SORT_CLAUSES,
-)
-from sentry.utils.dates import to_timestamp
-from sentry.utils.db import get_db_engine, is_postgres
+from sentry.utils.db import is_postgres
 
 
 class QuerySetBuilder(object):
-    """\
-    Adds filters to a ``QuerySet`` from a ``parameters`` mapping.
-
-    ``Condition`` objects are registered by their parameter name and used to
-    update the ``QuerySet`` instance provided to the ``build`` method if they
-    are present in the ``parameters`` mapping.
-    """
-
-    def __init__(self, conditions):
-        self.conditions = conditions
-
-    def build(self, queryset, parameters):
-        for name, condition in self.conditions.items():
-            if name in parameters:
-                queryset = condition.apply(queryset, name, parameters)
-        return queryset
-
-
-# TODO: Once we've removed the existing `QuerySetBuilder`, rename this to
-# QuerySetBuilder
-class NewQuerySetBuilder(object):
-
     def __init__(self, conditions):
         self.conditions = conditions
 
-    def normalize_parameters(self, params):
-        """
-        Converts passed in parameters into a standard format. Allows us to
-        support old/new style parameter being passed in.
-        """
-        for key, value in params.items():
-            yield key, value, None
-
-    def build(self, queryset, parameters):
-        for name, value, search_filter in self.normalize_parameters(parameters):
+    def build(self, queryset, search_filters):
+        for search_filter in search_filters:
+            name = search_filter.key.name
             if name in self.conditions:
                 condition = self.conditions[name]
-                if isinstance(condition, ScalarCondition):
-                    # XXX: Gross temporary hack to support old style
-                    # `ScalarCondition`s
-                    # This type of `ScalarCondition` should only ever be called
-                    # with old style parameters
-                    queryset = condition.apply(queryset, name, parameters)
-                else:
-                    queryset = condition.apply(queryset, value, search_filter)
+                queryset = condition.apply(queryset, search_filter)
         return queryset
 
 
-class SearchFilterQuerySetBuilder(NewQuerySetBuilder):
-    def normalize_parameters(self, search_filters):
-        for search_filter in search_filters:
-            yield (
-                search_filter.key.name,
-                search_filter.value.raw_value,
-                search_filter,
-            )
-
-
 class Condition(object):
     """\
     Adds a single filter to a ``QuerySet`` object. Used with
@@ -95,35 +42,22 @@ class Condition(object):
         raise NotImplementedError
 
 
-class CallbackCondition(Condition):
-    def __init__(self, callback):
-        self.callback = callback
-
-    def apply(self, queryset, name, parameters):
-        return self.callback(queryset, parameters[name])
-
-
 class QCallbackCondition(Condition):
     def __init__(self, callback):
         self.callback = callback
 
-    def apply(self, queryset, value, search_filter=None):
+    def apply(self, queryset, search_filter):
+        value = search_filter.value.raw_value
         q = self.callback(value)
-        # TODO: Once we're entirely using search filters we can just pass them
-        # in and not have this check. This is to support the old style search
-        # terms.
-        if search_filter:
-            if search_filter.operator not in ('=', '!='):
-                raise InvalidSearchQuery(
-                    u'Operator {} not valid for search {}'.format(
-                        search_filter.operator,
-                        search_filter,
-                    ),
-                )
-            queryset_method = queryset.filter if search_filter.operator == '=' else queryset.exclude
-            queryset = queryset_method(q)
-        else:
-            queryset = queryset.filter(q)
+        if search_filter.operator not in ('=', '!='):
+            raise InvalidSearchQuery(
+                u'Operator {} not valid for search {}'.format(
+                    search_filter.operator,
+                    search_filter,
+                ),
+            )
+        queryset_method = queryset.filter if search_filter.operator == '=' else queryset.exclude
+        queryset = queryset_method(q)
         return queryset
 
 
@@ -135,9 +69,7 @@ OPERATOR_TO_DJANGO = {
 }
 
 
-# TODO: Rename this to ScalarCondition once we've removed the existing
-# `ScalarCondition`
-class SearchFilterScalarCondition(Condition):
+class ScalarCondition(Condition):
     """
     Adds a scalar filter to a ``QuerySet`` object. Only accepts `SearchFilter`
     instances
@@ -152,107 +84,14 @@ class SearchFilterScalarCondition(Condition):
             django_operator = '__{}'.format(django_operator)
         return django_operator
 
-    def apply(self, queryset, value, search_filter):
+    def apply(self, queryset, search_filter):
         django_operator = self._get_operator(search_filter)
 
         qs_method = queryset.exclude if search_filter.operator == '!=' else queryset.filter
 
-        return qs_method(**{'{}{}'.format(self.field, django_operator): value})
-
-
-class ScalarCondition(Condition):
-    """\
-    Adds a scalar filter (less than or greater than are supported) to a
-    ``QuerySet`` object. Whether or not the filter is inclusive is defined by
-    the '{parameter_name}_inclusive' parameter.
-    """
-
-    def __init__(self, field, operator, default_inclusivity=True):
-        assert operator in ['lt', 'gt']
-        self.field = field
-        self.operator = operator
-        self.default_inclusivity = default_inclusivity
-
-    def apply(self, queryset, name, parameters):
-        inclusive = parameters.get(
-            u'{}_inclusive'.format(name),
-            self.default_inclusivity,
+        return qs_method(
+            **{'{}{}'.format(self.field, django_operator): search_filter.value.raw_value}
         )
-        return queryset.filter(**{
-            u'{}__{}{}'.format(
-                self.field,
-                self.operator,
-                'e' if inclusive else ''
-            ): parameters[name]
-        })
-
-
-def get_sql_table(model):
-    return u'{}'.format(model._meta.db_table)
-
-
-def get_sql_column(model, field):
-    "Convert a model class and field name to it's (unquoted!) SQL column representation."
-    return u'{}.{}'.format(*[
-        get_sql_table(model),
-        model._meta.get_field_by_name(field)[0].column,
-    ])
-
-
-sort_strategies = {
-    # sort_by -> Tuple[
-    #   Paginator,
-    #   String: QuerySet order_by parameter
-    # ]
-    'priority': (Paginator, '-score'),
-    'date': (DateTimePaginator, '-last_seen'),
-    'new': (DateTimePaginator, '-first_seen'),
-    'freq': (Paginator, '-times_seen'),
-}
-
-
-def get_priority_sort_expression(model):
-    engine = get_db_engine(router.db_for_read(model))
-    table = get_sql_table(model)
-    if 'postgres' in engine:
-        return u'log({table}.times_seen) * 600 + {table}.last_seen::abstime::int'.format(table=table)
-    else:
-        # TODO: This should be improved on other databases where possible.
-        # (This doesn't work on some databases: SQLite for example doesn't
-        # have a built-in logarithm function.)
-        return u'{}.times_seen'.format(table)
-
-
-environment_sort_strategies = {
-    # sort_by -> Tuple[
-    #   Function[Model] returning String: SQL expression to generate sort value (of type T, used below),
-    #   Function[T] -> int: function for converting sort value to cursor value),
-    # ]
-    'priority': (
-        get_priority_sort_expression,
-        int,
-    ),
-    'date': (
-        lambda model: u'{}.last_seen'.format(get_sql_table(model)),
-        lambda score: int(to_timestamp(score) * 1000),
-    ),
-    'new': (
-        lambda model: u'{}.first_seen'.format(get_sql_table(model)),
-        lambda score: int(to_timestamp(score) * 1000),
-    ),
-    'freq': (
-        lambda model: u'{}.times_seen'.format(get_sql_table(model)),
-        int,
-    ),
-}
-
-
-def get_sort_clause(sort_by):
-    engine = get_db_engine('default')
-    if engine.startswith('sqlite'):
-        return SQLITE_SORT_CLAUSES[sort_by]
-    else:
-        return SORT_CLAUSES[sort_by]
 
 
 def assigned_to_filter(actor, projects):
@@ -352,7 +191,7 @@ class DjangoSearchBackend(SearchBackend):
                     ).values_list('group'),
                 ),
             ),
-            'active_at': SearchFilterScalarCondition('active_at'),
+            'active_at': ScalarCondition('active_at'),
         }
 
         message = [
@@ -372,7 +211,7 @@ class DjangoSearchBackend(SearchBackend):
                     ),
                 )
 
-        group_queryset = SearchFilterQuerySetBuilder(qs_builder_conditions).build(
+        group_queryset = QuerySetBuilder(qs_builder_conditions).build(
             group_queryset,
             search_filters,
         )
@@ -392,268 +231,15 @@ class DjangoSearchBackend(SearchBackend):
         # This is a punt because the SnubaSearchBackend (a subclass) shares so much that it
         # seemed better to handle all the shared initialization and then handoff to the
         # actual backend.
-        return self._query(projects, retention_window_start, group_queryset, tags,
-                           environments, sort_by, limit, cursor, count_hits,
-                           paginator_options, search_filters, **parameters)
-
-    def _query(self, projects, retention_window_start, group_queryset, tags, environments,
-               sort_by, limit, cursor, count_hits, paginator_options, search_filters,
-               **parameters):
-
-        from sentry.models import (Group, Event, GroupEnvironment, Release)
-
-        # this backend only supports search within one project/environment
-        if len(projects) != 1 or (environments is not None and len(environments) > 1):
-            raise NotImplementedError
-
-        project = projects[0]
-        environment = environments[0] if environments is not None else environments
-
-        if environment is not None:
-            # An explicit environment takes precedence over one defined
-            # in the tags data.
-            if 'environment' in tags:
-                tags.pop('environment')
-
-            event_queryset_builder = QuerySetBuilder({
-                'date_from': ScalarCondition('date_added', 'gt'),
-                'date_to': ScalarCondition('date_added', 'lt'),
-            })
-
-            if any(key in parameters for key in event_queryset_builder.conditions.keys()):
-                event_queryset = event_queryset_builder.build(
-                    tagstore.get_event_tag_qs(
-                        project_id=project.id,
-                        environment_id=environment.id,
-                        key='environment',
-                        value=environment.name,
-                    ),
-                    parameters,
-                )
-                if retention_window_start is not None:
-                    event_queryset = event_queryset.filter(date_added__gte=retention_window_start)
-
-                group_queryset = group_queryset.filter(
-                    id__in=list(event_queryset.distinct().values_list('group_id', flat=True)[:1000])
-                )
-
-            _, group_queryset_sort_clause = sort_strategies[sort_by]
-            group_queryset = QuerySetBuilder({
-                'first_release': CallbackCondition(
-                    lambda queryset, version: queryset.extra(
-                        where=[
-                            '{} = {}'.format(
-                                get_sql_column(GroupEnvironment, 'first_release'),
-                                get_sql_column(Release, 'id'),
-                            ),
-                            '{} = %s'.format(
-                                get_sql_column(Release, 'organization'),
-                            ),
-                            '{} = %s'.format(
-                                get_sql_column(Release, 'version'),
-                            ),
-                        ],
-                        params=[project.organization_id, version],
-                        tables=[Release._meta.db_table],
-                    ),
-                ),
-                'times_seen': CallbackCondition(
-                    # This condition represents the exact number of times that
-                    # an issue has been seen in an environment. Since an issue
-                    # can't be seen in an environment more times than the issue
-                    # was seen overall, we can safely exclude any groups that
-                    # don't have at least that many events.
-                    lambda queryset, times_seen: queryset.exclude(
-                        times_seen__lt=times_seen,
-                    ),
-                ),
-                'times_seen_lower': CallbackCondition(
-                    # This condition represents the lower threshold for the
-                    # number of times an issue has been seen in an environment.
-                    # Since an issue can't be seen in an environment more times
-                    # than the issue was seen overall, we can safely exclude
-                    # any groups that haven't met that threshold.
-                    lambda queryset, times_seen: queryset.exclude(
-                        times_seen__lt=times_seen,
-                    ),
-                ),
-                # The following conditions make a few assertions that are are
-                # correct in an abstract sense but may not accurately reflect
-                # the existing implementation (see GH-5289). These assumptions
-                # are that 1. The first seen time for a Group is the minimum
-                # value of the first seen time for all of it's GroupEnvironment
-                # relations; 2. The last seen time for a Group is the maximum
-                # value of the last seen time for all of it's GroupEnvironment
-                # relations; 3. The first seen time is always less than or
-                # equal to the last seen time.
-                'age_from': CallbackCondition(
-                    # This condition represents the lower threshold for "first
-                    # seen" time for an environment. Due to assertions #1 and
-                    # #3, we can exclude any groups where the "last seen" time
-                    # is prior to this timestamp.
-                    lambda queryset, first_seen: queryset.exclude(
-                        last_seen__lt=first_seen,
-                    ),
-                ),
-                'age_to': CallbackCondition(
-                    # This condition represents the upper threshold for "first
-                    # seen" time for an environment. Due to assertions #1, we
-                    # can exclude any values where the group first seen is
-                    # greater than that threshold.
-                    lambda queryset, first_seen: queryset.exclude(
-                        first_seen__gt=first_seen,
-                    ),
-                ),
-                'last_seen_from': CallbackCondition(
-                    # This condition represents the lower threshold for "last
-                    # seen" time for an environment. Due to assertion #2, we
-                    # can exclude any values where the group last seen value is
-                    # less than that threshold.
-                    lambda queryset, last_seen: queryset.exclude(
-                        last_seen__lt=last_seen,
-                    ),
-                ),
-                'last_seen_to': CallbackCondition(
-                    # This condition represents the upper threshold for "last
-                    # seen" time for an environment. Due to assertions #2 and
-                    # #3, we can exclude any values where the group first seen
-                    # value is greater than that threshold.
-                    lambda queryset, last_seen: queryset.exclude(
-                        first_seen__gt=last_seen,
-                    ),
-                ),
-            }).build(
-                group_queryset.extra(
-                    where=[
-                        '{} = {}'.format(
-                            get_sql_column(Group, 'id'),
-                            get_sql_column(GroupEnvironment, 'group'),
-                        ),
-                        '{} = %s'.format(
-                            get_sql_column(GroupEnvironment, 'environment'),
-                        ),
-                    ],
-                    params=[environment.id],
-                    tables=[GroupEnvironment._meta.db_table],
-                ),
-                parameters,
-            ).order_by(group_queryset_sort_clause)
-
-            get_sort_expression, sort_value_to_cursor_value = environment_sort_strategies[sort_by]
-
-            group_tag_value_queryset = tagstore.get_group_tag_value_qs(
-                project_id=project.id,
-                group_id=set(group_queryset.values_list('id', flat=True)[:10000]),
-                environment_id=environment.id,
-                key='environment',
-                value=environment.name,
-            )
-
-            if retention_window_start is not None:
-                group_tag_value_queryset = group_tag_value_queryset.filter(
-                    last_seen__gte=retention_window_start
-                )
-
-            candidates = dict(
-                QuerySetBuilder({
-                    'age_from': ScalarCondition('first_seen', 'gt'),
-                    'age_to': ScalarCondition('first_seen', 'lt'),
-                    'last_seen_from': ScalarCondition('last_seen', 'gt'),
-                    'last_seen_to': ScalarCondition('last_seen', 'lt'),
-                    'times_seen': CallbackCondition(
-                        lambda queryset, times_seen: queryset.filter(times_seen=times_seen),
-                    ),
-                    'times_seen_lower': ScalarCondition('times_seen', 'gt'),
-                    'times_seen_upper': ScalarCondition('times_seen', 'lt'),
-                }).build(
-                    group_tag_value_queryset,
-                    parameters,
-                ).extra(
-                    select={
-                        'sort_value': get_sort_expression(group_tag_value_queryset.model),
-                    },
-                ).values_list('group_id', 'sort_value')
-            )
-
-            if tags:
-                # TODO: `get_group_ids_for_search_filter` should be able to
-                # utilize the retention window start parameter for additional
-                # optimizations.
-                matches = tagstore.get_group_ids_for_search_filter(
-                    project_id=project.id,
-                    environment_id=environment.id,
-                    tags=tags,
-                    candidates=candidates.keys(),
-                    limit=len(candidates),
-                )
-                for key in set(candidates) - set(matches or []):
-                    del candidates[key]
-
-            result = SequencePaginator(
-                [(sort_value_to_cursor_value(score), id) for (id, score) in candidates.items()],
-                reverse=True,
-                **paginator_options
-            ).get_result(limit, cursor, count_hits=count_hits)
-
-            groups = Group.objects.in_bulk(result.results)
-            result.results = [groups[k] for k in result.results if k in groups]
-
-            return result
-        else:
-            event_queryset_builder = QuerySetBuilder({
-                'date_from': ScalarCondition('datetime', 'gt'),
-                'date_to': ScalarCondition('datetime', 'lt'),
-            })
-
-            if any(key in parameters for key in event_queryset_builder.conditions.keys()):
-                group_queryset = group_queryset.filter(
-                    id__in=list(
-                        event_queryset_builder.build(
-                            Event.objects.filter(project_id=project.id),
-                            parameters,
-                        ).distinct().values_list('group_id', flat=True)[:1000],
-                    )
-                )
-
-            group_queryset = QuerySetBuilder({
-                'first_release': CallbackCondition(
-                    lambda queryset, version: queryset.filter(
-                        first_release__organization_id=project.organization_id,
-                        first_release__version=version,
-                    ),
-                ),
-                'age_from': ScalarCondition('first_seen', 'gt'),
-                'age_to': ScalarCondition('first_seen', 'lt'),
-                'last_seen_from': ScalarCondition('last_seen', 'gt'),
-                'last_seen_to': ScalarCondition('last_seen', 'lt'),
-                'times_seen': CallbackCondition(
-                    lambda queryset, times_seen: queryset.filter(times_seen=times_seen),
-                ),
-                'times_seen_lower': ScalarCondition('times_seen', 'gt'),
-                'times_seen_upper': ScalarCondition('times_seen', 'lt'),
-            }).build(
-                group_queryset,
-                parameters,
-            ).extra(
-                select={
-                    'sort_value': get_sort_clause(sort_by),
-                },
-            )
-
-            if tags:
-                group_ids = tagstore.get_group_ids_for_search_filter(
-                    project_id=project.id,
-                    environment_id=None,
-                    tags=tags,
-                    candidates=None,
-                )
-
-                if group_ids:
-                    group_queryset = group_queryset.filter(id__in=group_ids)
-                else:
-                    group_queryset = group_queryset.none()
+        return self._query(
+            projects, retention_window_start, group_queryset, environments,
+            sort_by, limit, cursor, count_hits, paginator_options,
+            search_filters, **parameters
+        )
 
-            paginator_cls, sort_clause = sort_strategies[sort_by]
-            group_queryset = group_queryset.order_by(sort_clause)
-            paginator = paginator_cls(group_queryset, sort_clause, **paginator_options)
-            return paginator.get_result(limit, cursor, count_hits=count_hits)
+    def _query(
+        self, projects, retention_window_start, group_queryset, environments,
+        sort_by, limit, cursor, count_hits, paginator_options, search_filters,
+        **parameters
+    ):
+        raise NotImplementedError
diff --git a/src/sentry/search/django/constants.py b/src/sentry/search/django/constants.py
deleted file mode 100644
index 78df14f4a2..0000000000
--- a/src/sentry/search/django/constants.py
+++ /dev/null
@@ -1,26 +0,0 @@
-"""
-sentry.search.django.constants
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-:copyright: (c) 2010-2014 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
-
-from __future__ import absolute_import
-
-SORT_CLAUSES = {
-    'priority': 'sentry_groupedmessage.score',
-    'date': 'EXTRACT(EPOCH FROM sentry_groupedmessage.last_seen)::int',
-    'new': 'EXTRACT(EPOCH FROM sentry_groupedmessage.first_seen)::int',
-    'freq': 'sentry_groupedmessage.times_seen',
-}
-
-SQLITE_SORT_CLAUSES = SORT_CLAUSES.copy()
-SQLITE_SORT_CLAUSES.update(
-    {
-        'date':
-        "cast((julianday(sentry_groupedmessage.last_seen) - 2440587.5) * 86400.0 as INTEGER)",
-        'new':
-        "cast((julianday(sentry_groupedmessage.first_seen) - 2440587.5) * 86400.0 as INTEGER)",
-    }
-)
diff --git a/src/sentry/search/snuba/backend.py b/src/sentry/search/snuba/backend.py
index 2487973862..6d10b49a8d 100644
--- a/src/sentry/search/snuba/backend.py
+++ b/src/sentry/search/snuba/backend.py
@@ -71,15 +71,10 @@ def get_search_filter(search_filters, name, operator):
 
 
 class SnubaSearchBackend(ds.DjangoSearchBackend):
-    def _query(self, projects, retention_window_start, group_queryset, tags, environments,
+    def _query(self, projects, retention_window_start, group_queryset, environments,
                sort_by, limit, cursor, count_hits, paginator_options, search_filters,
                **parameters):
 
-        # TODO: Product decision: we currently search Group.message to handle
-        # the `query` parameter, because that's what we've always done. We could
-        # do that search against every event in Snuba instead, but results may
-        # differ.
-
         # TODO: It's possible `first_release` could be handled by Snuba.
         if environments is not None:
             group_queryset = group_queryset.filter(
@@ -87,7 +82,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                     environment.id for environment in environments
                 ],
             )
-            group_queryset = ds.SearchFilterQuerySetBuilder({
+            group_queryset = ds.QuerySetBuilder({
                 'first_release': ds.QCallbackCondition(
                     lambda version: Q(
                         groupenvironment__first_release__organization_id=projects[0].organization_id,
@@ -96,7 +91,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                 ),
             }).build(group_queryset, search_filters)
         else:
-            group_queryset = ds.SearchFilterQuerySetBuilder({
+            group_queryset = ds.QuerySetBuilder({
                 'first_release': ds.QCallbackCondition(
                     lambda version: Q(
                         first_release__organization_id=projects[0].organization_id,
diff --git a/src/sentry/tagstore/base.py b/src/sentry/tagstore/base.py
index 113b13608d..2130fe4d4b 100644
--- a/src/sentry/tagstore/base.py
+++ b/src/sentry/tagstore/base.py
@@ -57,7 +57,6 @@ class TagStorage(Service):
 
         'get_group_ids_for_users',
         'get_group_tag_values_for_users',
-        'get_group_ids_for_search_filter',
 
         'get_group_tag_keys_and_top_values',
 
@@ -67,7 +66,6 @@ class TagStorage(Service):
         'get_group_tag_value_iter',
 
         'get_group_tag_value_qs',
-        'get_event_tag_qs',
     ])
 
     __write_methods__ = frozenset([
@@ -350,12 +348,6 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def get_event_tag_qs(self, project_id, environment_id, key, value):
-        """
-        >>> get_event_tag_qs(1, 2, 'environment', 'prod')
-        """
-        raise NotImplementedError
-
     def get_groups_user_counts(self, project_ids, group_ids, environment_ids,
                                start=None, end=None):
         """
@@ -407,13 +399,6 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def get_group_ids_for_search_filter(
-            self, project_id, environment_id, tags, candidates=None, limit=1000):
-        """
-        >>> get_group_ids_for_search_filter(1, 2, [('key1', 'value1'), ('key2', 'value2')])
-        """
-        raise NotImplementedError
-
     def update_group_for_events(self, project_id, event_ids, destination_id):
         """
         >>> update_group_for_events(1, [2, 3], 4)
diff --git a/src/sentry/tagstore/legacy/backend.py b/src/sentry/tagstore/legacy/backend.py
index c512022900..da97873b63 100644
--- a/src/sentry/tagstore/legacy/backend.py
+++ b/src/sentry/tagstore/legacy/backend.py
@@ -638,49 +638,6 @@ class LegacyTagStorage(TagStorage):
             )
         )
 
-    def get_group_ids_for_search_filter(
-            self, project_id, environment_id, tags, candidates=None, limit=1000):
-
-        from sentry.search.base import ANY
-        # Django doesnt support union, so we limit results and try to find
-        # reasonable matches
-
-        # ANY matches should come last since they're the least specific and
-        # will provide the largest range of matches
-        tag_lookups = sorted(six.iteritems(tags), key=lambda k_v: k_v[1] == ANY)
-
-        # get initial matches to start the filter
-        matches = candidates or []
-
-        # for each remaining tag, find matches contained in our
-        # existing set, pruning it down each iteration
-        for k, v in tag_lookups:
-            if v != ANY:
-                base_qs = models.GroupTagValue.objects.filter(
-                    key=k,
-                    value=v,
-                    project_id=project_id,
-                )
-
-            else:
-                base_qs = models.GroupTagValue.objects.filter(
-                    key=k,
-                    project_id=project_id,
-                ).distinct()
-
-            if matches:
-                base_qs = base_qs.filter(group_id__in=matches)
-            else:
-                # restrict matches to only the most recently seen issues
-                base_qs = base_qs.order_by('-last_seen')
-
-            matches = list(base_qs.values_list('group_id', flat=True)[:limit])
-
-            if not matches:
-                return []
-
-        return set(matches)
-
     def update_group_tag_key_values_seen(self, project_id, group_ids):
         gtk_qs = models.GroupTagKey.objects.filter(
             project_id=project_id,
@@ -755,9 +712,6 @@ class LegacyTagStorage(TagStorage):
 
         return queryset
 
-    def get_event_tag_qs(self, project_id, environment_id, key, value):
-        raise NotImplementedError  # there is no index that can appopriate satisfy this query
-
     def update_group_for_events(self, project_id, event_ids, destination_id):
         return models.EventTag.objects.filter(
             project_id=project_id,
diff --git a/src/sentry/tagstore/snuba/backend.py b/src/sentry/tagstore/snuba/backend.py
index 622c4073f9..500388dd66 100644
--- a/src/sentry/tagstore/snuba/backend.py
+++ b/src/sentry/tagstore/snuba/backend.py
@@ -692,11 +692,6 @@ class SnubaTagStorage(TagStorage):
         # search backend.
         raise NotImplementedError
 
-    def get_event_tag_qs(self, project_id, environment_id, key, value):
-        # This method is not implemented because it is only used by the Django
-        # search backend.
-        raise NotImplementedError
-
     def get_group_event_filter(self, project_id, group_id, environment_ids, tags, start, end):
         default_start, default_end = self.get_time_range()
         start = max(start, default_start) if start else default_start
@@ -725,13 +720,6 @@ class SnubaTagStorage(TagStorage):
 
         return {'event_id__in': event_id_set}
 
-    def get_group_ids_for_search_filter(
-            self, project_id, environment_id, tags, candidates=None, limit=1000):
-        # This method is not implemented since the `group.id` column doesn't
-        # exist in Snuba. This logic is implemented in the search backend
-        # instead.
-        raise NotImplementedError
-
 
 class SnubaCompatibilityTagStorage(SnubaTagStorage):
     """
diff --git a/src/sentry/tagstore/v2/backend.py b/src/sentry/tagstore/v2/backend.py
index f53e4f294b..0a760f49e7 100644
--- a/src/sentry/tagstore/v2/backend.py
+++ b/src/sentry/tagstore/v2/backend.py
@@ -955,55 +955,6 @@ class V2TagStorage(TagStorage):
             )
         )
 
-    def get_group_ids_for_search_filter(
-            self, project_id, environment_id, tags, candidates=None, limit=1000):
-
-        from sentry.search.base import ANY
-        # Django doesnt support union, so we limit results and try to find
-        # reasonable matches
-
-        # ANY matches should come last since they're the least specific and
-        # will provide the largest range of matches
-        tag_lookups = sorted(six.iteritems(tags), key=lambda k_v: k_v[1] == ANY)
-
-        # get initial matches to start the filter
-        matches = candidates or []
-
-        # for each remaining tag, find matches contained in our
-        # existing set, pruning it down each iteration
-        for k, v in tag_lookups:
-            if v != ANY:
-                base_qs = models.GroupTagValue.objects.filter(
-                    project_id=project_id,
-                    _key__project_id=project_id,
-                    _key__key=k,
-                    _value__project_id=project_id,
-                    _value___key=F('_key'),
-                    _value__value=v,
-                )
-                base_qs = self._add_environment_filter(base_qs, environment_id)
-
-            else:
-                base_qs = models.GroupTagValue.objects.filter(
-                    project_id=project_id,
-                    _key__project_id=project_id,
-                    _key__key=k,
-                )
-                base_qs = self._add_environment_filter(base_qs, environment_id).distinct()
-
-            if matches:
-                base_qs = base_qs.filter(group_id__in=matches)
-            else:
-                # restrict matches to only the most recently seen issues
-                base_qs = base_qs.order_by('-last_seen')
-
-            matches = list(base_qs.values_list('group_id', flat=True)[:limit])
-
-            if not matches:
-                return []
-
-        return matches
-
     def update_group_tag_key_values_seen(self, project_id, group_ids):
         gtk_qs = models.GroupTagKey.objects.filter(
             project_id=project_id,
@@ -1090,19 +1041,6 @@ class V2TagStorage(TagStorage):
         qs = self._add_environment_filter(qs, environment_id)
         return qs
 
-    def get_event_tag_qs(self, project_id, environment_id, key, value):
-        qs = models.EventTag.objects.filter(
-            project_id=project_id,
-            key__project_id=project_id,
-            key__key=key,
-            value__project_id=project_id,
-            value__value=value,
-        )
-
-        qs = self._add_environment_filter(qs, environment_id)
-
-        return qs
-
     def update_group_for_events(self, project_id, event_ids, destination_id):
         return models.EventTag.objects.filter(
             project_id=project_id,
diff --git a/tests/sentry/search/django/__init__.py b/tests/sentry/search/django/__init__.py
deleted file mode 100644
index c3961685ab..0000000000
--- a/tests/sentry/search/django/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from __future__ import absolute_import
diff --git a/tests/sentry/search/django/tests.py b/tests/sentry/search/django/tests.py
deleted file mode 100644
index 7a8d2ba3f4..0000000000
--- a/tests/sentry/search/django/tests.py
+++ /dev/null
@@ -1,848 +0,0 @@
-# -*- coding: utf-8 -*-
-
-from __future__ import absolute_import
-
-from datetime import datetime, timedelta
-
-import pytest
-from django.conf import settings
-
-from sentry import tagstore
-from sentry.api.issue_search import (
-    convert_query_values,
-    parse_search_query,
-)
-from sentry.models import (
-    Environment, Event, Group, GroupAssignee, GroupBookmark, GroupEnvironment,
-    GroupStatus, GroupSubscription
-)
-from sentry.search.base import ANY
-from sentry.search.django.backend import DjangoSearchBackend
-from sentry.tagstore.v2.backend import AGGREGATE_ENVIRONMENT_ID
-from sentry.testutils import TestCase
-
-
-def date_to_query_format(date):
-    return date.strftime('%Y-%m-%dT%H:%M:%S')
-
-
-class DjangoSearchBackendTest(TestCase):
-
-    def create_backend(self):
-        return DjangoSearchBackend()
-
-    def setUp(self):
-        self.backend = self.create_backend()
-        now = datetime.now()
-
-        self.event1 = self.store_event(
-            data={
-                'fingerprint': ['put-me-in-group1'],
-                'event_id': 'a' * 32,
-                'message': 'foo',
-                'environment': 'production',
-                'tags': {
-                    'server': 'example.com',
-                },
-                'timestamp': (now - timedelta(days=10)).isoformat()[:19]
-            },
-            project_id=self.project.id
-        )
-
-        self.event3 = self.store_event(
-            data={
-                'fingerprint': ['put-me-in-group1'],
-                'event_id': 'c' * 32,
-                'message': 'foo',
-                'environment': 'production',
-                'tags': {
-                    'server': 'example.com',
-                },
-                'timestamp': (now - timedelta(days=2)).isoformat()[:19]
-            },
-            project_id=self.project.id
-        )
-
-        self.group1 = Group.objects.get(id=self.event3.group.id)
-        assert self.event1.group.id == self.group1.id
-
-        assert self.group1.first_seen == self.event1.datetime
-        assert self.group1.last_seen == self.event3.datetime
-
-        self.group1.status = GroupStatus.UNRESOLVED
-        self.group1.times_seen = 5
-        self.group1.save()
-
-        self.event2 = self.store_event(
-            data={
-                'fingerprint': ['put-me-in-group2'],
-                'event_id': 'b' * 32,
-                'message': 'bar',
-                'environment': 'staging',
-                'tags': {
-                    'server': 'example.com',
-                    'url': 'http://example.com',
-                },
-                'timestamp': (now - timedelta(days=9)).isoformat()[:19]
-            },
-            project_id=self.project.id
-        )
-
-        self.group2 = Group.objects.get(id=self.event2.group.id)
-        assert self.group2.first_seen == self.event2.datetime
-        assert self.group2.last_seen == self.event2.datetime
-        self.group2.status = GroupStatus.RESOLVED
-        self.group2.times_seen = 10
-        self.group2.save()
-
-        self.environments = {}
-
-        for event in Event.objects.filter(project_id=self.project.id):
-            self._setup_tags_for_event(event)
-
-        GroupBookmark.objects.create(
-            user=self.user,
-            group=self.group2,
-            project=self.group2.project,
-        )
-
-        GroupAssignee.objects.create(
-            user=self.user,
-            group=self.group2,
-            project=self.group2.project,
-        )
-
-        GroupSubscription.objects.create(
-            user=self.user,
-            group=self.group1,
-            project=self.group1.project,
-            is_active=True,
-        )
-
-        GroupSubscription.objects.create(
-            user=self.user,
-            group=self.group2,
-            project=self.group2.project,
-            is_active=False,
-        )
-
-    def _setup_tags_for_event(self, event):
-        tags = dict(event.data.get('tags') or ())
-
-        try:
-            environment = self.environments[event.data['environment']]
-        except KeyError:
-            environment = self.environments[event.data['environment']] = Environment.get_or_create(
-                event.project,
-                event.data['environment'],
-            )
-
-        GroupEnvironment.objects.get_or_create(
-            environment_id=environment.id,
-            group_id=event.group_id,
-        )
-
-        for key, value in tags.items():
-            for environment_id in [AGGREGATE_ENVIRONMENT_ID, environment.id]:
-                tag_value, created = tagstore.get_or_create_group_tag_value(
-                    project_id=event.project_id,
-                    group_id=event.group_id,
-                    environment_id=environment_id,
-                    key=key,
-                    value=value,
-                )
-
-                if created:  # XXX: Hack for tagstore compat
-                    tag_value.update(
-                        times_seen=1,
-                        first_seen=event.datetime,
-                        last_seen=event.datetime,
-                    )
-                else:
-                    updates = {
-                        'times_seen': tag_value.times_seen + 1,
-                    }
-
-                    if event.datetime < tag_value.first_seen:
-                        updates['first_seen'] = event.datetime
-
-                    if event.datetime > tag_value.last_seen:
-                        updates['last_seen'] = event.datetime
-
-                    if updates:
-                        tag_value.update(**updates)
-
-                tagstore.create_event_tags(
-                    project_id=event.project_id,
-                    group_id=event.group_id,
-                    environment_id=environment_id,
-                    event_id=event.id,
-                    tags=tags.items(),
-                    date_added=event.datetime,
-                )
-
-    def make_query(self, projects=None, search_filter_query=None, environments=None, **kwargs):
-        search_filters = []
-        if search_filter_query is not None:
-            search_filters = self.build_search_filter(search_filter_query, projects, environments)
-        return self.backend.query(
-            projects if projects is not None else [self.project],
-            search_filters=search_filters,
-            environments=environments,
-            **kwargs
-        )
-
-    def build_search_filter(self, query, projects=None, user=None, environments=None):
-        user = user if user is not None else self.user
-        projects = projects if projects is not None else [self.project]
-        return convert_query_values(parse_search_query(query), projects, user, environments)
-
-    def test_query(self):
-        results = self.make_query(search_filter_query='foo', query='foo')
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(search_filter_query='bar', query='bar')
-        assert set(results) == set([self.group2])
-
-    def test_query_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            search_filter_query='foo',
-            query='foo',
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            search_filter_query='bar',
-            query='bar',
-        )
-        assert set(results) == set([])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            search_filter_query='bar',
-            query='bar',
-        )
-        assert set(results) == set([self.group2])
-
-    def test_sort(self):
-        results = self.make_query(sort_by='date')
-        assert list(results) == [self.group1, self.group2]
-
-        results = self.make_query(sort_by='new')
-        assert list(results) == [self.group2, self.group1]
-
-        results = self.make_query(sort_by='freq')
-        assert list(results) == [self.group2, self.group1]
-
-        results = self.make_query(sort_by='priority')
-        assert list(results) == [self.group1, self.group2]
-
-    def test_sort_with_environment(self):
-        for dt in [
-                self.group1.first_seen + timedelta(days=1),
-                self.group1.first_seen + timedelta(days=2),
-                self.group1.last_seen + timedelta(days=1)]:
-            event = self.store_event(
-                data={
-                    'fingerprint': ['put-me-in-group2'],
-                    'message': 'foo',
-                    'environment': 'production',
-                    'tags': {
-                        'server': 'example.com',
-                    },
-                    'timestamp': dt.isoformat()[:19]
-                },
-                project_id=self.project.id
-            )
-            self._setup_tags_for_event(event)
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='date',
-        )
-        assert list(results) == [self.group2, self.group1]
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='new',
-        )
-        assert list(results) == [self.group2, self.group1]
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='freq',
-        )
-        assert list(results) == [self.group2, self.group1]
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='priority',
-        )
-        assert list(results) == [self.group2, self.group1]
-
-    def test_status(self):
-        results = self.make_query(
-            search_filter_query='is:unresolved',
-            status=GroupStatus.UNRESOLVED,
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            search_filter_query='is:resolved',
-            status=GroupStatus.RESOLVED,
-        )
-        assert set(results) == set([self.group2])
-
-    def test_status_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            search_filter_query='is:unresolved',
-            status=GroupStatus.UNRESOLVED,
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            search_filter_query='is:resolved',
-            status=GroupStatus.RESOLVED,
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            status=GroupStatus.RESOLVED,
-            search_filter_query='is:resolved',
-        )
-        assert set(results) == set([])
-
-    def test_tags(self):
-        results = self.make_query(
-            search_filter_query='environment:staging',
-            tags={'environment': 'staging'},
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            search_filter_query='environment:example.com',
-            tags={'environment': 'example.com'},
-        )
-        assert set(results) == set([])
-
-        results = self.make_query(
-            search_filter_query='has:environment',
-            tags={'environment': ANY},
-        )
-        assert set(results) == set([self.group2, self.group1])
-
-        results = self.make_query(
-            search_filter_query='environment:staging server:example.com',
-            tags={'environment': 'staging', 'server': 'example.com'},
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            search_filter_query='environment:staging has:server',
-            tags={'environment': 'staging', 'server': ANY},
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            search_filter_query='environment:staging server:bar.example.com',
-            tags={'environment': 'staging',
-                  'server': 'bar.example.com'})
-        assert set(results) == set([])
-
-    def test_environment_tag_not_matching_project(self):
-        project = self.create_project(name='other')
-        results = self.make_query(
-            [project],
-            environments=[self.environments['production']],
-            tags={'environment': 'production'},
-            search_filter_query='',
-            query='',
-        )
-        assert set(results) == set([])
-
-    def test_tags_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            tags={'server': 'example.com'})
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            tags={'server': 'example.com'})
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            tags={'server': ANY})
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            tags={
-                'environment': ANY,
-                'server': ANY,
-            })
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            tags={'url': 'http://example.com'})
-        assert set(results) == set([])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            tags={'url': 'http://example.com'})
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            tags={'server': 'bar.example.com'})
-        assert set(results) == set([])
-
-    def test_bookmarked_by(self):
-        results = self.make_query(
-            bookmarked_by=self.user,
-            search_filter_query='bookmarks:%s' % self.user.username,
-        )
-        assert set(results) == set([self.group2])
-
-    def test_bookmarked_by_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            bookmarked_by=self.user,
-            search_filter_query='bookmarks:%s' % self.user.username,
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            bookmarked_by=self.user,
-            search_filter_query='bookmarks:%s' % self.user.username,
-        )
-        assert set(results) == set([])
-
-    def test_project(self):
-        results = self.make_query([self.create_project(name='other')])
-        assert set(results) == set([])
-
-    def test_pagination(self):
-        results = self.make_query(limit=1, sort_by='date')
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(cursor=results.next, limit=1, sort_by='date')
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(cursor=results.next, limit=1, sort_by='date')
-        assert set(results) == set([])
-
-    def test_pagination_with_environment(self):
-        for dt in [
-                self.group1.first_seen + timedelta(days=1),
-                self.group1.first_seen + timedelta(days=2),
-                self.group1.last_seen + timedelta(days=1)]:
-            event = self.store_event(
-                data={
-                    'environment': 'production',
-                    'fingerprint': ['put-me-in-group2'],
-                    'message': 'bar',
-                    'timestamp': dt.isoformat()[:19]
-                },
-                project_id=self.project.id
-            )
-            self._setup_tags_for_event(event)
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='date',
-            limit=1,
-            count_hits=True,
-        )
-        assert list(results) == [self.group2]
-        assert results.hits == 2
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='date',
-            limit=1,
-            cursor=results.next,
-            count_hits=True,
-        )
-        assert list(results) == [self.group1]
-        assert results.hits == 2
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            sort_by='date',
-            limit=1,
-            cursor=results.next,
-            count_hits=True,
-        )
-        assert list(results) == []
-        assert results.hits == 2
-
-    def test_active_at_filter(self):
-        results = self.make_query(
-            active_at_from=self.group2.active_at,
-            active_at_inclusive=True,
-            search_filter_query='activeSince:>=%s' % date_to_query_format(self.group2.active_at),
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            active_at_to=self.group1.active_at + timedelta(minutes=1),
-            active_at_inclusive=True,
-            search_filter_query='activeSince:<=%s' % date_to_query_format(
-                self.group1.active_at + timedelta(minutes=1),
-            ),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            active_at_from=self.group1.active_at,
-            active_at_from_inclusive=True,
-            active_at_to=self.group1.active_at + timedelta(minutes=1),
-            active_at_to_inclusive=True,
-            search_filter_query='activeSince:>=%s activeSince:<=%s' % (
-                date_to_query_format(self.group1.active_at),
-                date_to_query_format(self.group1.active_at + timedelta(minutes=1)),
-            )
-        )
-        assert set(results) == set([self.group1])
-
-    def test_age_filter(self):
-        results = self.make_query(
-            age_from=self.group2.first_seen,
-            age_from_inclusive=True,
-            search_filter_query='firstSeen:>=%s' % date_to_query_format(self.group2.first_seen),
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            age_to=self.group1.first_seen + timedelta(minutes=1),
-            age_to_inclusive=True,
-            search_filter_query='firstSeen:<=%s' % date_to_query_format(
-                self.group1.first_seen + timedelta(minutes=1),
-            ),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            age_from=self.group1.first_seen,
-            age_from_inclusive=True,
-            age_to=self.group1.first_seen + timedelta(minutes=1),
-            age_to_inclusive=True,
-            search_filter_query='firstSeen:>=%s firstSeen:<=%s' % (
-                date_to_query_format(self.group1.first_seen),
-                date_to_query_format(self.group1.first_seen + timedelta(minutes=1)),
-            )
-        )
-        assert set(results) == set([self.group1])
-
-    def test_age_filter_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            age_from=self.group1.first_seen,
-            age_from_inclusive=True,
-            search_filter_query='firstSeen:>=%s' % date_to_query_format(self.group1.first_seen),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            age_to=self.group1.first_seen,
-            age_to_inclusive=True,
-            search_filter_query='firstSeen:<=%s' % date_to_query_format(self.group1.first_seen),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            age_from=self.group1.first_seen,
-            age_from_inclusive=False,
-            search_filter_query='firstSeen:>%s' % date_to_query_format(self.group1.first_seen),
-        )
-        assert set(results) == set([])
-
-        event = self.store_event(
-            data={
-                'fingerprint': ['put-me-in-group1'],
-                'message': 'foo',
-                'environment': 'development',
-                'tags': {
-                    'server': 'example.com',
-                },
-                'timestamp': (self.group1.first_seen + timedelta(days=1)).isoformat()[:19]
-            },
-            project_id=self.project.id
-        )
-
-        self._setup_tags_for_event(event)
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            age_from=self.group1.first_seen,
-            age_from_inclusive=False,
-            search_filter_query='firstSeen:>%s' % date_to_query_format(self.group1.first_seen),
-        )
-        assert set(results) == set([])
-
-        results = self.make_query(
-            environments=[self.environments['development']],
-            age_from=self.group1.first_seen,
-            age_from_inclusive=False,
-            search_filter_query='firstSeen:>%s' % date_to_query_format(self.group1.first_seen),
-        )
-        assert set(results) == set([self.group1])
-
-    def test_last_seen_filter(self):
-        results = self.make_query(
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=True,
-            search_filter_query='lastSeen:>=%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=True,
-            last_seen_to=self.group1.last_seen + timedelta(minutes=1),
-            last_seen_to_inclusive=True,
-            search_filter_query='lastSeen:>=%s lastSeen:<=%s' % (
-                date_to_query_format(self.group1.last_seen),
-                date_to_query_format(self.group1.last_seen + timedelta(minutes=1)),
-            )
-        )
-        assert set(results) == set([self.group1])
-
-    def test_last_seen_filter_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=True,
-            search_filter_query='lastSeen:>=%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            last_seen_to=self.group1.last_seen,
-            last_seen_to_inclusive=True,
-            search_filter_query='lastSeen:<=%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=False,
-            search_filter_query='lastSeen:>%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([])
-
-        event = self.store_event(
-            data={
-                'fingerprint': ['put-me-in-group1'],
-                'message': 'foo',
-                'environment': 'development',
-                'tags': {
-                    'server': 'example.com',
-                },
-                'timestamp': (self.group1.last_seen + timedelta(days=1)).isoformat()[:19]
-            },
-            project_id=self.project.id
-        )
-
-        self._setup_tags_for_event(event)
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=False,
-            search_filter_query='lastSeen:>%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([])
-
-        results = self.make_query(
-            environments=[self.environments['development']],
-            last_seen_from=self.group1.last_seen,
-            last_seen_from_inclusive=False,
-            search_filter_query='lastSeen:>%s' % date_to_query_format(self.group1.last_seen),
-        )
-        assert set(results) == set([self.group1])
-
-    def test_date_filter(self):
-        results = self.make_query(
-            date_from=self.event2.datetime,
-            search_filter_query='event.timestamp:>=%s' % date_to_query_format(self.event2.datetime),
-        )
-        assert set(results) == set([self.group1, self.group2])
-
-        results = self.make_query(
-            date_to=self.event1.datetime + timedelta(minutes=1),
-            search_filter_query='event.timestamp:<=%s' % date_to_query_format(
-                self.event1.datetime + timedelta(minutes=1),
-            ),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            date_from=self.event1.datetime,
-            date_to=self.event2.datetime + timedelta(minutes=1),
-            search_filter_query='event.timestamp:>=%s event.timestamp:<=%s' % (
-                date_to_query_format(self.event1.datetime),
-                date_to_query_format(self.event2.datetime + timedelta(minutes=1)),
-            )
-        )
-        assert set(results) == set([self.group1, self.group2])
-
-    @pytest.mark.xfail(
-        not settings.SENTRY_TAGSTORE.startswith('sentry.tagstore.v2'),
-        reason='unsupported on legacy backend due to insufficient index',
-    )
-    def test_date_filter_with_environment(self):
-        results = self.backend.query(
-            [self.project],
-            environments=[self.environments['production']],
-            date_from=self.event2.datetime,
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.backend.query(
-            [self.project],
-            environments=[self.environments['production']],
-            date_to=self.event1.datetime + timedelta(minutes=1),
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.backend.query(
-            [self.project],
-            environments=[self.environments['staging']],
-            date_from=self.event1.datetime,
-            date_to=self.event2.datetime + timedelta(minutes=1),
-        )
-        assert set(results) == set([self.group2])
-
-    def test_unassigned(self):
-        results = self.make_query(
-            unassigned=True,
-            search_filter_query='is:unassigned',
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            unassigned=False,
-            search_filter_query='is:assigned',
-        )
-        assert set(results) == set([self.group2])
-
-    def test_unassigned_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['production']],
-            unassigned=True,
-            search_filter_query='is:unassigned',
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            unassigned=False,
-            search_filter_query='is:assigned',
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            unassigned=False,
-            search_filter_query='is:assigned',
-        )
-        assert set(results) == set([])
-
-    def test_assigned_to(self):
-        results = self.make_query(
-            assigned_to=self.user,
-            search_filter_query='assigned:%s' % self.user.username,
-        )
-        assert set(results) == set([self.group2])
-
-        # test team assignee
-        ga = GroupAssignee.objects.get(
-            user=self.user,
-            group=self.group2,
-            project=self.group2.project,
-        )
-        ga.update(team=self.team, user=None)
-        assert GroupAssignee.objects.get(id=ga.id).user is None
-
-        results = self.make_query(
-            assigned_to=self.user,
-            search_filter_query='assigned:%s' % self.user.username,
-        )
-        assert set(results) == set([self.group2])
-
-        # test when there should be no results
-        other_user = self.create_user()
-        results = self.make_query(
-            assigned_to=other_user,
-            search_filter_query='assigned:%s' % other_user.username
-        )
-        assert set(results) == set([])
-
-        owner = self.create_user()
-        self.create_member(
-            organization=self.project.organization,
-            user=owner,
-            role='owner',
-            teams=[],
-        )
-
-        # test that owners don't see results for all teams
-        results = self.make_query(
-            assigned_to=owner,
-            search_filter_query='assigned:%s' % owner.username
-        )
-        assert set(results) == set([])
-
-    def test_assigned_to_with_environment(self):
-        results = self.make_query(
-            environments=[self.environments['staging']],
-            assigned_to=self.user,
-            search_filter_query='assigned:%s' % self.user.username
-        )
-        assert set(results) == set([self.group2])
-
-        results = self.make_query(
-            environments=[self.environments['production']],
-            assigned_to=self.user,
-            search_filter_query='assigned:%s' % self.user.username
-        )
-        assert set(results) == set([])
-
-    def test_subscribed_by(self):
-        results = self.make_query(
-            [self.group1.project],
-            subscribed_by=self.user,
-            search_filter_query='subscribed:%s' % self.user.username
-        )
-        assert set(results) == set([self.group1])
-
-    def test_subscribed_by_with_environment(self):
-        results = self.make_query(
-            [self.group1.project],
-            environments=[self.environments['production']],
-            subscribed_by=self.user,
-            search_filter_query='subscribed:%s' % self.user.username
-        )
-        assert set(results) == set([self.group1])
-
-        results = self.make_query(
-            [self.group1.project],
-            environments=[self.environments['staging']],
-            subscribed_by=self.user,
-            search_filter_query='subscribed:%s' % self.user.username
-        )
-        assert set(results) == set([])
diff --git a/tests/sentry/tagstore/v2/test_backend.py b/tests/sentry/tagstore/v2/test_backend.py
index f70da178bc..811cfef996 100644
--- a/tests/sentry/tagstore/v2/test_backend.py
+++ b/tests/sentry/tagstore/v2/test_backend.py
@@ -2,14 +2,12 @@ from __future__ import absolute_import
 
 import pytest
 
-from collections import OrderedDict
 from datetime import (
     datetime,
     timedelta,
 )
 from django.utils import timezone
 
-from sentry.search.base import ANY
 from sentry.testutils import TestCase
 from sentry.tagstore import TagKeyStatus
 from sentry.tagstore.v2 import models
@@ -348,14 +346,18 @@ class TagStorage(TestCase):
                 key_id=k.id,
                 value_id=v.id,
             ) is not None
-            assert set(
-                self.ts.get_event_tag_qs(
-                    self.proj1.id,
-                    self.proj1env1.id,
-                    k.key,
-                    v.value,
-                ).values_list('group_id', flat=True)
-            ) == set([self.proj1group1.id])
+            expected_qs = models.EventTag.objects.filter(
+                project_id=self.proj1.id,
+                key__project_id=self.proj1.id,
+                key__key=k.key,
+                value__project_id=self.proj1.id,
+                value__value=v.value,
+            )
+            expected_qs = self.ts._add_environment_filter(
+                expected_qs,
+                self.proj1env1.id,
+            ).values_list('group_id', flat=True)
+            assert set(expected_qs) == set([self.proj1group1.id])
 
     def test_delete_tag_key(self):
         tk1 = self.ts.create_tag_key(
@@ -667,52 +669,6 @@ class TagStorage(TestCase):
             transformers[models.GroupTagValue](v1)
         ]
 
-    def test_get_group_ids_for_search_filter(self):
-        tags = {
-            'foo': 'bar',
-            'baz': 'quux',
-        }
-
-        for k, v in tags.items():
-            v1, _ = self.ts.get_or_create_group_tag_value(
-                self.proj1.id,
-                self.proj1group1.id,
-                self.proj1env1.id,
-                k,
-                v)
-
-        assert self.ts.get_group_ids_for_search_filter(
-            self.proj1.id, self.proj1env1.id, tags) == [self.proj1group1.id]
-
-    def test_get_group_ids_for_search_filter_predicate_order(self):
-        """
-            Since each tag-matching filter returns limited results, and each
-            filter returns a subset of the previous filter's matches, we
-            attempt to match more selective predicates first.
-
-            This tests that we filter by a more selective "divides == even"
-            predicate before filtering by an ANY predicate and therefore return
-            all matching groups instead of the partial set that would be returned
-            if we had filtered and limited using the ANY predicate first.
-        """
-        for i in range(3):
-            self.ts.get_or_create_group_tag_value(
-                self.proj1.id, i, self.proj1env1.id,
-                'foo', 'bar'
-            )
-
-            self.ts.get_or_create_group_tag_value(
-                self.proj1.id, i, self.proj1env1.id,
-                'divides', 'even' if i % 2 == 0 else 'odd'
-            )
-
-        assert len(self.ts.get_group_ids_for_search_filter(
-            self.proj1.id,
-            self.proj1env1.id,
-            OrderedDict([('foo', ANY), ('divides', 'even')]),
-            limit=2
-        )) == 2
-
     def test_update_group_for_events(self):
         v1, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, 'k1', 'v1')
         v2, _ = self.ts.get_or_create_tag_value(self.proj1.id, self.proj1env1.id, 'k2', 'v2')
diff --git a/tests/snuba/api/endpoints/test_organization_group_index.py b/tests/snuba/api/endpoints/test_organization_group_index.py
index 7b37a3c3fd..3d04a11e9a 100644
--- a/tests/snuba/api/endpoints/test_organization_group_index.py
+++ b/tests/snuba/api/endpoints/test_organization_group_index.py
@@ -1243,7 +1243,7 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         assert response.data['statusDetails']['actor']['id'] == six.text_type(self.user.id)
 
     def test_snooze_user_count(self):
-        for i in range(100):
+        for i in range(10):
             event = self.store_event(
                 data={
                     'fingerprint': ['put-me-in-group-1'],
@@ -1262,15 +1262,15 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         response = self.get_valid_response(
             qs_params={'id': group.id},
             status='ignored',
-            ignoreUserCount=100,
+            ignoreUserCount=10,
         )
         snooze = GroupSnooze.objects.get(group=group)
         assert snooze.count is None
         assert snooze.until is None
-        assert snooze.user_count == 100
+        assert snooze.user_count == 10
         assert snooze.user_window is None
         assert snooze.window is None
-        assert snooze.state['users_seen'] == 100
+        assert snooze.state['users_seen'] == 10
 
         assert response.data['status'] == 'ignored'
         assert response.data['statusDetails']['ignoreCount'] == snooze.count
diff --git a/tests/sentry/api/endpoints/test_project_group_index.py b/tests/snuba/api/endpoints/test_project_group_index.py
similarity index 95%
rename from tests/sentry/api/endpoints/test_project_group_index.py
rename to tests/snuba/api/endpoints/test_project_group_index.py
index f4b74876b3..dabc814c4f 100644
--- a/tests/sentry/api/endpoints/test_project_group_index.py
+++ b/tests/snuba/api/endpoints/test_project_group_index.py
@@ -9,19 +9,22 @@ from django.utils import timezone
 from exam import fixture
 from mock import patch, Mock
 
-from sentry import tagstore
 from sentry.models import (
     Activity, ApiToken, EventMapping, Group, GroupAssignee, GroupBookmark, GroupHash,
     GroupLink, GroupResolution, GroupSeen, GroupShare, GroupSnooze, GroupStatus, GroupSubscription,
     GroupTombstone, ExternalIssue, Integration, Release, OrganizationIntegration, UserOption
 )
 from sentry.models.event import Event
-from sentry.testutils import APITestCase
+from sentry.testutils import APITestCase, SnubaTestCase
 from sentry.testutils.helpers import parse_link_header
 from six.moves.urllib.parse import quote
 
 
-class GroupListTest(APITestCase):
+class GroupListTest(APITestCase, SnubaTestCase):
+    def setUp(self):
+        super(GroupListTest, self).setUp()
+        self.min_ago = timezone.now() - timedelta(minutes=1)
+
     def _parse_links(self, header):
         # links come in {url: {...attrs}}, but we need {rel: {...attrs}}
         links = {}
@@ -72,14 +75,22 @@ class GroupListTest(APITestCase):
     def test_simple_pagination(self):
         now = timezone.now()
         group1 = self.create_group(
-            checksum='a' * 32,
-            last_seen=now - timedelta(seconds=1),
+            project=self.project,
+            last_seen=now - timedelta(seconds=2),
+        )
+        self.create_event(
+            group=group1,
+            datetime=now - timedelta(seconds=2),
         )
         group2 = self.create_group(
-            checksum='b' * 32,
-            last_seen=now,
+            project=self.project,
+            last_seen=now - timedelta(seconds=1),
+        )
+        self.create_event(
+            stacktrace=[['foo.py']],
+            group=group2,
+            datetime=now - timedelta(seconds=1),
         )
-
         self.login_as(user=self.user)
         response = self.client.get(
             u'{}?sort_by=date&limit=1'.format(self.path),
@@ -104,39 +115,6 @@ class GroupListTest(APITestCase):
         assert links['previous']['results'] == 'true'
         assert links['next']['results'] == 'false'
 
-        # TODO(dcramer): not working correctly
-        # print(links['previous']['cursor'])
-        # response = self.client.get(links['previous']['href'], format='json')
-        # assert response.status_code == 200
-        # assert len(response.data) == 1
-        # assert response.data[0]['id'] == six.text_type(group2.id)
-
-        # links = self._parse_links(response['Link'])
-
-        # assert links['previous']['results'] == 'false'
-        # assert links['next']['results'] == 'true'
-
-        # print(links['previous']['cursor'])
-        # response = self.client.get(links['previous']['href'], format='json')
-        # assert response.status_code == 200
-        # assert len(response.data) == 0
-
-        # group3 = self.create_group(
-        #     checksum='c' * 32,
-        #     last_seen=now + timedelta(seconds=1),
-        # )
-
-        # links = self._parse_links(response['Link'])
-
-        # assert links['previous']['results'] == 'false'
-        # assert links['next']['results'] == 'true'
-
-        # print(links['previous']['cursor'])
-        # response = self.client.get(links['previous']['href'], format='json')
-        # assert response.status_code == 200
-        # assert len(response.data) == 1
-        # assert response.data[0]['id'] == six.text_type(group3.id)
-
     def test_stats_period(self):
         # TODO(dcramer): this test really only checks if validation happens
         # on statsPeriod
@@ -321,20 +299,12 @@ class GroupListTest(APITestCase):
     def test_lookup_by_release(self):
         self.login_as(self.user)
         project = self.project
-        project2 = self.create_project(name='baz', organization=project.organization)
         release = Release.objects.create(organization=project.organization, version='12345')
         release.add_project(project)
-        release.add_project(project2)
-        group = self.create_group(checksum='a' * 32, project=project)
-        group2 = self.create_group(checksum='b' * 32, project=project2)
-        tagstore.create_group_tag_value(
-            project_id=project.id, group_id=group.id, environment_id=None,
-            key='sentry:release', value=release.version
-        )
-
-        tagstore.create_group_tag_value(
-            project_id=project2.id, group_id=group2.id, environment_id=None,
-            key='sentry:release', value=release.version
+        self.create_event(
+            group=self.group,
+            datetime=self.min_ago,
+            tags={'sentry:release': release.version},
         )
 
         url = '%s?query=%s' % (self.path, quote('release:"%s"' % release.version))
@@ -342,7 +312,7 @@ class GroupListTest(APITestCase):
         issues = json.loads(response.content)
         assert response.status_code == 200
         assert len(issues) == 1
-        assert int(issues[0]['id']) == group.id
+        assert int(issues[0]['id']) == self.group.id
 
     def test_pending_delete_pending_merge_excluded(self):
         self.create_group(
@@ -388,7 +358,11 @@ class GroupListTest(APITestCase):
         assert response.status_code == 200, response.content
 
 
-class GroupUpdateTest(APITestCase):
+class GroupUpdateTest(APITestCase, SnubaTestCase):
+    def setUp(self):
+        super(GroupUpdateTest, self).setUp()
+        self.min_ago = timezone.now() - timedelta(minutes=1)
+
     @fixture
     def path(self):
         return u'/api/0/projects/{}/{}/issues/'.format(
@@ -1324,17 +1298,19 @@ class GroupUpdateTest(APITestCase):
         assert response.data['statusDetails']['actor']['id'] == six.text_type(self.user.id)
 
     def test_snooze_user_count(self):
-        group = self.create_group(
-            checksum='a' * 32,
-            status=GroupStatus.RESOLVED,
-        )
-        tagstore.create_group_tag_key(
-            group.project_id,
-            group.id,
-            None,
-            'sentry:user',
-            values_seen=100,
-        )
+        for i in range(10):
+            event = self.store_event(
+                data={
+                    'fingerprint': ['put-me-in-group-1'],
+                    'user': {'id': six.binary_type(i)},
+                    'timestamp': (self.min_ago - timedelta(seconds=i)).isoformat()[:19]
+                },
+                project_id=self.project.id
+            )
+
+        group = Group.objects.get(id=event.group.id)
+        group.status = GroupStatus.RESOLVED
+        group.save()
 
         self.login_as(user=self.user)
 
@@ -1345,7 +1321,7 @@ class GroupUpdateTest(APITestCase):
         response = self.client.put(
             url, data={
                 'status': 'ignored',
-                'ignoreUserCount': 100,
+                'ignoreUserCount': 10,
             }, format='json'
         )
 
@@ -1354,10 +1330,10 @@ class GroupUpdateTest(APITestCase):
         snooze = GroupSnooze.objects.get(group=group)
         assert snooze.count is None
         assert snooze.until is None
-        assert snooze.user_count == 100
+        assert snooze.user_count == 10
         assert snooze.user_window is None
         assert snooze.window is None
-        assert snooze.state['users_seen'] == 100
+        assert snooze.state['users_seen'] == 10
 
         assert response.data['status'] == 'ignored'
         assert response.data['statusDetails']['ignoreCount'] == snooze.count
@@ -1764,7 +1740,7 @@ class GroupUpdateTest(APITestCase):
         assert tombstone.data == group1.data
 
 
-class GroupDeleteTest(APITestCase):
+class GroupDeleteTest(APITestCase, SnubaTestCase):
     @fixture
     def path(self):
         return u'/api/0/projects/{}/{}/issues/'.format(
