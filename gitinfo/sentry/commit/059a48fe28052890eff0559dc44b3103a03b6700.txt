commit 059a48fe28052890eff0559dc44b3103a03b6700
Author: Daniel Griesser <daniel.griesser.86@gmail.com>
Date:   Thu Feb 23 10:53:30 2017 +0100

    Rename of erros, Rename function in http to fetch_file

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 22bf6cca20..1172a5fff7 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -950,13 +950,13 @@ SENTRY_MAX_EXCEPTIONS = 25
 SENTRY_GRAVATAR_BASE_URL = 'https://secure.gravatar.com'
 
 # Timeout (in seconds) for fetching remote source files (e.g. JS)
-SENTRY_SOURCE_FETCH_TIMEOUT = 5
+SENTRY_FETCH_TIMEOUT = 5
 
 # Timeout (in seconds) for socket operations when fetching remote source files
-SENTRY_SOURCE_FETCH_SOCKET_TIMEOUT = 2
+SENTRY_FETCH_SOCKET_TIMEOUT = 2
 
 # Maximum content length for source files before we abort fetching
-SENTRY_SOURCE_FETCH_MAX_SIZE = 40 * 1024 * 1024
+SENTRY_FETCH_MAX_SIZE = 40 * 1024 * 1024
 
 # List of IP subnets which should not be accessible
 SENTRY_DISALLOWED_IPS = ()
diff --git a/src/sentry/http.py b/src/sentry/http.py
index 0fd85e886d..5866582c1a 100644
--- a/src/sentry/http.py
+++ b/src/sentry/http.py
@@ -74,8 +74,8 @@ class BadSource(Exception):
         self.data = data
 
 
-class CannotFetchSource(BadSource):
-    error_type = EventError.JS_GENERIC_FETCH_ERROR
+class CannotFetch(BadSource):
+    error_type = EventError.FETCH_GENERIC_ERROR
 
 
 def get_server_hostname():
@@ -227,7 +227,7 @@ def expose_url(url):
     return url
 
 
-def stream_download_binary(url, headers=None, cache_enabled=True):
+def fetch_file(url, headers=None, cache_enabled=True):
     """
     Pull down a URL, returning a UrlResult object.
 
@@ -242,7 +242,7 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
         domain_result = cache.get(domain_key)
         if domain_result:
             domain_result['url'] = url
-            raise CannotFetchSource(domain_result)
+            raise CannotFetch(domain_result)
 
     logger.debug('Fetching %r from the internet', url)
 
@@ -256,7 +256,7 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
                 allow_redirects=True,
                 verify=False,
                 headers=headers,
-                timeout=settings.SENTRY_SOURCE_FETCH_SOCKET_TIMEOUT,
+                timeout=settings.SENTRY_FETCH_SOCKET_TIMEOUT,
                 stream=True,
             )
 
@@ -264,7 +264,7 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
                 cl = int(response.headers['content-length'])
             except (LookupError, ValueError):
                 cl = 0
-            if cl > settings.SENTRY_SOURCE_FETCH_MAX_SIZE:
+            if cl > settings.SENTRY_FETCH_MAX_SIZE:
                 raise OverflowError()
 
             contents = []
@@ -274,11 +274,11 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
             # got a 200 OK
             if response.status_code == 200:
                 for chunk in response.iter_content(16 * 1024):
-                    if time.time() - start > settings.SENTRY_SOURCE_FETCH_TIMEOUT:
+                    if time.time() - start > settings.SENTRY_FETCH_TIMEOUT:
                         raise Timeout()
                     contents.append(chunk)
                     cl += len(chunk)
-                    if cl > settings.SENTRY_SOURCE_FETCH_MAX_SIZE:
+                    if cl > settings.SENTRY_FETCH_MAX_SIZE:
                         raise OverflowError()
 
         except Exception as exc:
@@ -295,20 +295,20 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
                 }
             elif isinstance(exc, Timeout):
                 error = {
-                    'type': EventError.JS_FETCH_TIMEOUT,
+                    'type': EventError.FETCH_TIMEOUT,
                     'url': expose_url(url),
-                    'timeout': settings.SENTRY_SOURCE_FETCH_TIMEOUT,
+                    'timeout': settings.SENTRY_FETCH_TIMEOUT,
                 }
             elif isinstance(exc, OverflowError):
                 error = {
-                    'type': EventError.JS_TOO_LARGE,
+                    'type': EventError.FETCH_TOO_LARGE,
                     'url': expose_url(url),
                     # We want size in megabytes to format nicely
-                    'max_size': float(settings.SENTRY_SOURCE_FETCH_MAX_SIZE) / 1024 / 1024,
+                    'max_size': float(settings.SENTRY_FETCH_MAX_SIZE) / 1024 / 1024,
                 }
             elif isinstance(exc, (RequestException, ZeroReturnError)):
                 error = {
-                    'type': EventError.JS_GENERIC_FETCH_ERROR,
+                    'type': EventError.FETCH_GENERIC_ERROR,
                     'value': six.text_type(type(exc)),
                     'url': expose_url(url),
                 }
@@ -323,7 +323,7 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
             if cache_enabled:
                 cache.set(domain_key, error or '', 300)
             logger.warning('source.disabled', extra=error)
-            raise CannotFetchSource(error)
+            raise CannotFetch(error)
 
         body = b''.join(contents)
         headers = {k.lower(): v for k, v in response.headers.items()}
@@ -342,7 +342,7 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
             'value': result[2],
             'url': expose_url(url),
         }
-        raise CannotFetchSource(error)
+        raise CannotFetch(error)
 
     # Make sure the file we're getting back is six.binary_type. The only
     # reason it'd not be binary would be from old cached blobs, so
@@ -357,6 +357,6 @@ def stream_download_binary(url, headers=None, cache_enabled=True):
                 'value': 'utf8',
                 'url': expose_url(url),
             }
-            raise CannotFetchSource(error)
+            raise CannotFetch(error)
 
     return UrlResult(url, result[0], result[1], response.status_code, result[3])
diff --git a/src/sentry/lang/javascript/errormapping.py b/src/sentry/lang/javascript/errormapping.py
index 16ebd5d9ba..266c2e0a36 100644
--- a/src/sentry/lang/javascript/errormapping.py
+++ b/src/sentry/lang/javascript/errormapping.py
@@ -56,7 +56,7 @@ class Processor(object):
             http_session = http.build_session()
             response = http_session.get(self.mapping_url,
                 allow_redirects=True,
-                timeout=settings.SENTRY_SOURCE_FETCH_TIMEOUT,
+                timeout=settings.SENTRY_FETCH_TIMEOUT,
             )
             # Make sure we only get a 2xx to prevent caching bad data
             response.raise_for_status()
diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index 4dadbfa83a..1bff6569ea 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -264,7 +264,7 @@ def fetch_file(url, project=None, release=None, allow_scraping=True):
     # If our url has been truncated, it'd be impossible to fetch
     # so we check for this early and bail
     if url[-3:] == '...':
-        raise http.CannotFetchSource({
+        raise http.CannotFetch({
             'type': EventError.JS_MISSING_SOURCE,
             'url': http.expose_url(url),
         })
@@ -284,7 +284,7 @@ def fetch_file(url, project=None, release=None, allow_scraping=True):
                 'type': EventError.JS_MISSING_SOURCE,
                 'url': http.expose_url(url),
             }
-            raise http.CannotFetchSource(error)
+            raise http.CannotFetch(error)
 
         logger.debug('Checking cache for url %r', url)
         result = cache.get(cache_key)
@@ -311,7 +311,7 @@ def fetch_file(url, project=None, release=None, allow_scraping=True):
                 headers[token_header] = token
 
         with metrics.timer('sourcemaps.fetch'):
-            result = http.stream_download_binary(url, headers)
+            result = http.fetch_file(url, headers)
             z_body = zlib.compress(result.body)
             cache.set(cache_key, (url, headers, z_body, result.status, result.encoding), 60)
 
@@ -328,7 +328,7 @@ def fetch_file(url, project=None, release=None, allow_scraping=True):
                 'type': EventError.JS_INVALID_CONTENT,
                 'url': url,
             }
-            raise http.CannotFetchSource(error)
+            raise http.CannotFetch(error)
 
     return result
 
@@ -366,7 +366,7 @@ def fetch_sourcemap(url, project=None, release=None, allow_scraping=True):
                 'value': 'utf8',
                 'url': http.expose_url(url),
             }
-            raise http.CannotFetchSource(error)
+            raise http.CannotFetch(error)
 
     try:
         return view_from_json(body)
diff --git a/src/sentry/models/eventerror.py b/src/sentry/models/eventerror.py
index 5031bc163f..8646b9a6a7 100644
--- a/src/sentry/models/eventerror.py
+++ b/src/sentry/models/eventerror.py
@@ -25,7 +25,8 @@ class EventError(object):
     SECURITY_VIOLATION = 'security_violation'
     RESTRICTED_IP = 'restricted_ip'
 
-    JS_GENERIC_FETCH_ERROR = 'js_generic_fetch_error'
+    JS_GENERIC_FETCH_ERROR = 'js_generic_fetch_error'  # deprecated in favor of FETCH_GENERIC_ERROR
+    FETCH_GENERIC_ERROR = 'fetch_generic_error'
     JS_INVALID_HTTP_CODE = 'js_invalid_http_code'
     JS_INVALID_CONTENT = 'js_invalid_content'
     JS_NO_COLUMN = 'js_no_column'
@@ -34,8 +35,10 @@ class EventError(object):
     JS_TOO_MANY_REMOTE_SOURCES = 'js_too_many_sources'
     JS_INVALID_SOURCE_ENCODING = 'js_invalid_source_encoding'
     JS_INVALID_SOURCEMAP_LOCATION = 'js_invalid_sourcemap_location'
-    JS_TOO_LARGE = 'js_too_large'
-    JS_FETCH_TIMEOUT = 'js_fetch_timeout'
+    JS_TOO_LARGE = 'js_too_large'  # deprecated in favor of FETCH_TOO_LARGE
+    FETCH_TOO_LARGE = 'fetch_too_large'
+    JS_FETCH_TIMEOUT = 'js_fetch_timeout'  # deprecated in favor of FETCH_TIMEOUT
+    FETCH_TIMEOUT = 'fetch_timeout'
     NATIVE_NO_CRASHED_THREAD = 'native_no_crashed_thread'
     NATIVE_INTERNAL_FAILURE = 'native_internal_failure'
     NATIVE_NO_SYMSYND = 'native_no_symsynd'
@@ -54,7 +57,8 @@ class EventError(object):
         UNKNOWN_ERROR: u'Unknown error',
         SECURITY_VIOLATION: u'Cannot fetch resource due to security violation on {url}',
         RESTRICTED_IP: u'Cannot fetch resource due to restricted IP address on {url}',
-        JS_GENERIC_FETCH_ERROR: u'Unable to fetch resource: {url}',
+        JS_GENERIC_FETCH_ERROR: u'Unable to fetch resource: {url}',  # deprecated in favor of FETCH_GENERIC_ERROR
+        FETCH_GENERIC_ERROR: u'Unable to fetch resource: {url}',
         JS_INVALID_HTTP_CODE: u'HTTP returned {value} response on {url}',
         JS_INVALID_CONTENT: u'Source file was not JavaScript: {url}',
         JS_NO_COLUMN: u'Cannot expand sourcemap due to no column information for {url}',
@@ -63,8 +67,10 @@ class EventError(object):
         JS_TOO_MANY_REMOTE_SOURCES: u'The maximum number of remote source requests was made',
         JS_INVALID_SOURCE_ENCODING: u'Source file was not \'{value}\' encoding: {url}',
         JS_INVALID_SOURCEMAP_LOCATION: u'Invalid location in sourcemap: ({column}, {row})',
-        JS_TOO_LARGE: u'Remote file too large: ({max_size:g}MB, {url})',
-        JS_FETCH_TIMEOUT: u'Remote file took too long to load: ({timeout}s, {url})',
+        JS_TOO_LARGE: u'Remote file too large: ({max_size:g}MB, {url})',  # deprecated in favor of FETCH_TOO_LARGE
+        FETCH_TOO_LARGE: u'Remote file too large: ({max_size:g}MB, {url})',
+        JS_FETCH_TIMEOUT: u'Remote file took too long to load: ({timeout}s, {url})',  # deprecated in favor of FETCH_TIMEOUT
+        FETCH_TIMEOUT: u'Remote file took too long to load: ({timeout}s, {url})',
         NATIVE_NO_CRASHED_THREAD: u'No crashed thread found in crash report',
         NATIVE_INTERNAL_FAILURE: u'Internal failure when attempting to symbolicate: {error}',
         NATIVE_NO_SYMSYND: u'The symbolizer is not configured for this system.',
diff --git a/tests/sentry/lang/javascript/test_processor.py b/tests/sentry/lang/javascript/test_processor.py
index 400b3741bf..7fd18eab49 100644
--- a/tests/sentry/lang/javascript/test_processor.py
+++ b/tests/sentry/lang/javascript/test_processor.py
@@ -12,7 +12,7 @@ from requests.exceptions import RequestException
 
 from sentry.lang.javascript.processor import (
     BadSource, discover_sourcemap, fetch_sourcemap, fetch_file, generate_module,
-    trim_line, UrlResult, fetch_release_file, CannotFetchSource,
+    trim_line, UrlResult, fetch_release_file, CannotFetch,
     UnparseableSourcemap,
 )
 from sentry.lang.javascript.errormapping import (
@@ -175,7 +175,7 @@ class FetchFileTest(TestCase):
     @responses.activate
     def test_truncated(self):
         url = truncatechars('http://example.com', 3)
-        with pytest.raises(CannotFetchSource) as exc:
+        with pytest.raises(CannotFetch) as exc:
             fetch_file(url)
 
         assert exc.value.data['type'] == EventError.JS_MISSING_SOURCE
@@ -277,7 +277,7 @@ class FetchSourcemapTest(TestCase):
         responses.add(responses.GET, 'http://example.com', body='{}',
                       content_type='application/json; charset=NOPE')
 
-        with pytest.raises(CannotFetchSource) as exc:
+        with pytest.raises(CannotFetch) as exc:
             fetch_sourcemap('http://example.com')
 
         assert exc.value.data['type'] == EventError.JS_INVALID_SOURCE_ENCODING
