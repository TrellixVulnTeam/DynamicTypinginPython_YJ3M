commit c35008055e7e31514363a9f3ce9e11e6d818551e
Author: evanh <evanh@users.noreply.github.com>
Date:   Wed Feb 19 16:26:51 2020 -0500

    feat(tracing) Add rpm() and rps() function support to event stats (#17113)
    
    feat(tracing) Add rpm() and rps() function support to event stats
    
    Add the ability to send rpm() and rps() functions to the event stats endpoint,
    and use the rollup parameter to correctly average counts.

diff --git a/src/sentry/api/endpoints/organization_events_stats.py b/src/sentry/api/endpoints/organization_events_stats.py
index 0bc98129fb..6d2f2f5617 100644
--- a/src/sentry/api/endpoints/organization_events_stats.py
+++ b/src/sentry/api/endpoints/organization_events_stats.py
@@ -23,6 +23,7 @@ class OrganizationEventsStatsEndpoint(OrganizationEventsEndpointBase):
 
         try:
             column = request.GET.get("yAxis", "count()")
+            rollup = self.get_rollup(request)
             # Backwards compatibility for incidents which uses the old
             # column aliases as it straddles both versions of events/discover.
             # We will need these aliases until discover2 flags are enabled for all
@@ -31,13 +32,17 @@ class OrganizationEventsStatsEndpoint(OrganizationEventsEndpointBase):
                 column = "count_unique(user)"
             elif column == "event_count":
                 column = "count()"
+            elif column == "rpm()":
+                column = "rpm(%d)" % rollup
+            elif column == "rps()":
+                column = "rps(%d)" % rollup
 
             params = self.get_filter_params(request, organization)
             result = discover.timeseries_query(
                 selected_columns=[column],
                 query=request.GET.get("query"),
                 params=params,
-                rollup=self.get_rollup(request),
+                rollup=rollup,
                 reference_event=self.reference_event(
                     request, organization, params.get("start"), params.get("end")
                 ),
diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index d56122429d..e205fe288e 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -922,7 +922,21 @@ FUNCTIONS = {
             },
         ],
         "transform": "quantile(%(percentile).2f)(%(column)s)",
-    }
+    },
+    "rps": {
+        "name": "rps",
+        "args": [
+            {"name": "interval", "type": NUMBER, "validator": lambda v: (v > 0, "must be positive integer")},
+        ],
+        "transform": "divide(count(), %(interval)d)",
+    },
+    "rpm": {
+        "name": "rpm",
+        "args": [
+            {"name": "interval", "type": NUMBER, "validator": lambda v: (v >= 60, "must be greater than 60 seconds")},
+        ],
+        "transform": "divide(count(), divide(%(interval)d, 60))",
+    },
 }
 
 
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index a311cc386c..dda07bf61f 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1317,6 +1317,40 @@ class ResolveFieldListTest(unittest.TestCase):
             in six.text_type(err)
         )
 
+    def test_rpm_function(self):
+        fields = ["rpm(3600)"]
+        result = resolve_field_list(fields, {})
+
+        assert result["selected_columns"] == []
+        assert result["aggregations"] == [
+            ["divide(count(), divide(3600, 60))", None, "rpm_3600"],
+            ["argMax", ["id", "timestamp"], "latest_event"],
+            ["argMax", ["project.id", "timestamp"], "projectid"],
+        ]
+        assert result["groupby"] == []
+
+        with pytest.raises(InvalidSearchQuery) as err:
+            fields = ["rpm(30)"]
+            result = resolve_field_list(fields, {})
+        assert "rpm(30): 30.0 argument invalid: must be greater than 60 seconds" in six.text_type(err)
+
+    def test_rps_function(self):
+        fields = ["rps(3600)"]
+        result = resolve_field_list(fields, {})
+
+        assert result["selected_columns"] == []
+        assert result["aggregations"] == [
+            ["divide(count(), 3600)", None, "rps_3600"],
+            ["argMax", ["id", "timestamp"], "latest_event"],
+            ["argMax", ["project.id", "timestamp"], "projectid"],
+        ]
+        assert result["groupby"] == []
+
+        with pytest.raises(InvalidSearchQuery) as err:
+            fields = ["rps(0)"]
+            result = resolve_field_list(fields, {})
+        assert "rps(0): 0.0 argument invalid: must be positive integer" in six.text_type(err)
+
     def test_rollup_with_unaggregated_fields(self):
         with pytest.raises(InvalidSearchQuery) as err:
             fields = ["message"]
diff --git a/tests/snuba/api/endpoints/test_organization_events_stats.py b/tests/snuba/api/endpoints/test_organization_events_stats.py
index b61a091a07..d7d228bc0a 100644
--- a/tests/snuba/api/endpoints/test_organization_events_stats.py
+++ b/tests/snuba/api/endpoints/test_organization_events_stats.py
@@ -1,5 +1,8 @@
 from __future__ import absolute_import
 
+import six
+import uuid
+
 from datetime import timedelta
 
 from django.core.urlresolvers import reverse
@@ -247,6 +250,155 @@ class OrganizationEventsStatsEndpointTest(APITestCase, SnubaTestCase):
             )
         assert response.status_code == 400, response.content
 
+    def test_throughput_rpm_hour_rollup(self):
+        project = self.create_project()
+        # Each of these denotes how many events to create in each hour
+        event_counts = [6, 0, 6, 3, 0, 3]
+        for hour, count in enumerate(event_counts):
+            for minute in range(count):
+                self.store_event(
+                    data={
+                        "event_id": six.binary_type(uuid.uuid1()),
+                        "message": "very bad",
+                        "timestamp": iso_format(
+                            self.day_ago + timedelta(hours=hour, minutes=minute)
+                        ),
+                        "fingerprint": ["group1"],
+                        "tags": {"sentry:user": self.user.email},
+                    },
+                    project_id=project.id,
+                )
+
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(hours=6)),
+                    "interval": "1h",
+                    "yAxis": "rpm()",
+                    "project": project.id,
+                },
+            )
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 8
+
+        rows = data[1:7]
+        for test in zip(event_counts, rows):
+            assert test[1][1][0]["count"] == test[0] / (3600.0 / 60.0)
+
+    def test_throughput_rpm_day_rollup(self):
+        project = self.create_project()
+        # Each of these denotes how many events to create in each minute
+        event_counts = [6, 0, 6, 3, 0, 3]
+        for hour, count in enumerate(event_counts):
+            for minute in range(count):
+                self.store_event(
+                    data={
+                        "event_id": six.binary_type(uuid.uuid1()),
+                        "message": "very bad",
+                        "timestamp": iso_format(
+                            self.day_ago + timedelta(hours=hour, minutes=minute)
+                        ),
+                        "fingerprint": ["group1"],
+                        "tags": {"sentry:user": self.user.email},
+                    },
+                    project_id=project.id,
+                )
+
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(hours=6)),
+                    "interval": "24h",
+                    "yAxis": "rpm()",
+                    "project": project.id,
+                },
+            )
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 2
+        assert data[1][1][0]["count"] == sum(event_counts) / (86400.0 / 60.0)
+
+    def test_throughput_rps_minute_rollup(self):
+        project = self.create_project()
+        # Each of these denotes how many events to create in each minute
+        event_counts = [6, 0, 6, 3, 0, 3]
+        for minute, count in enumerate(event_counts):
+            for second in range(count):
+                self.store_event(
+                    data={
+                        "event_id": six.binary_type(uuid.uuid1()),
+                        "message": "very bad",
+                        "timestamp": iso_format(self.day_ago + timedelta(minutes=minute, seconds=second)),
+                        "fingerprint": ["group1"],
+                        "tags": {"sentry:user": self.user.email},
+                    },
+                    project_id=project.id,
+                )
+
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(minutes=6)),
+                    "interval": "1m",
+                    "yAxis": "rps()",
+                    "project": project.id,
+                },
+            )
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 8
+
+        rows = data[1:7]
+        for test in zip(event_counts, rows):
+            assert test[1][1][0]["count"] == test[0] / 60.0
+
+    def test_throughput_rps_no_rollup(self):
+        project = self.create_project()
+        # Each of these denotes how many events to create in each minute
+        event_counts = [6, 0, 6, 3, 0, 3]
+        for minute, count in enumerate(event_counts):
+            for second in range(count):
+                self.store_event(
+                    data={
+                        "event_id": six.binary_type(uuid.uuid1()),
+                        "message": "very bad",
+                        "timestamp": iso_format(self.day_ago + timedelta(minutes=minute, seconds=second)),
+                        "fingerprint": ["group1"],
+                        "tags": {"sentry:user": self.user.email},
+                    },
+                    project_id=project.id,
+                )
+
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(minutes=1)),
+                    "interval": "1s",
+                    "yAxis": "rps()",
+                    "project": project.id,
+                },
+            )
+        assert response.status_code == 200, response.content
+        data = response.data["data"]
+        assert len(data) == 62
+
+        rows = data[1:7]
+        for row in rows:
+            assert row[1][0]["count"] == 1
+
     def test_with_field_and_reference_event_invalid(self):
         with self.feature("organizations:discover-basic"):
             response = self.client.get(
