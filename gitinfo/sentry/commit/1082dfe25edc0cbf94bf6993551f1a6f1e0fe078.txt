commit 1082dfe25edc0cbf94bf6993551f1a6f1e0fe078
Author: Leander Rodrigues <leandergrodrigues@gmail.com>
Date:   Wed Feb 12 14:35:28 2020 -0800

    feat(async-csv): Setup CSV export logic (#16711)
    
    Introduces CSV creation and file storage on ExportedData model

diff --git a/src/sentry/api/endpoints/data_export.py b/src/sentry/api/endpoints/data_export.py
index ca9ec3644a..b18b545257 100644
--- a/src/sentry/api/endpoints/data_export.py
+++ b/src/sentry/api/endpoints/data_export.py
@@ -10,7 +10,7 @@ from sentry.api.bases.organization import OrganizationEndpoint, OrganizationEven
 from sentry.api.serializers import serialize
 from sentry.constants import ExportQueryType
 from sentry.models import ExportedData
-from sentry.tasks.data_export import compile_data
+from sentry.tasks.data_export import assemble_download
 
 
 class ExportedDataSerializer(serializers.Serializer):
@@ -53,5 +53,5 @@ class DataExportEndpoint(OrganizationEndpoint):
             # This will handle invalid JSON requests
             return Response({"detail": six.text_type(e)}, status=400)
 
-        compile_data.delay(data_export=data_export)
+        assemble_download.delay(data_export=data_export)
         return Response(serialize(data_export, request.user), status=201)
diff --git a/src/sentry/api/endpoints/data_export_details.py b/src/sentry/api/endpoints/data_export_details.py
index 535793460c..c05300d002 100644
--- a/src/sentry/api/endpoints/data_export_details.py
+++ b/src/sentry/api/endpoints/data_export_details.py
@@ -11,6 +11,10 @@ from sentry.models import ExportedData
 class DataExportDetailsEndpoint(OrganizationEndpoint):
     permission_classes = (OrganizationEventPermission,)
 
+    def download(self, data_export):
+        # TODO(Leander): Implement safe downloads
+        return
+
     def get(self, request, organization, **kwargs):
         """
         Retrieve information about the temporary file record.
@@ -22,6 +26,8 @@ class DataExportDetailsEndpoint(OrganizationEndpoint):
 
         try:
             data_export = ExportedData.objects.get(id=kwargs["data_export_id"])
+            if request.GET.get("download") is not None:
+                return self.download(data_export)
             return Response(serialize(data_export, request.user))
         except ExportedData.DoesNotExist:
             return Response(status=404)
diff --git a/src/sentry/api/serializers/models/exporteddata.py b/src/sentry/api/serializers/models/exporteddata.py
index 66b30ed2ce..e7c1e26c94 100644
--- a/src/sentry/api/serializers/models/exporteddata.py
+++ b/src/sentry/api/serializers/models/exporteddata.py
@@ -8,8 +8,10 @@ from sentry.models import ExportedData, User
 class ExportedDataSerializer(Serializer):
     def get_attrs(self, item_list, user, **kwargs):
         attrs = {}
+        users = User.objects.filter(id__in=set([item.user_id for item in item_list]))
+        user_lookup = {user.id: user for user in users}
         for item in item_list:
-            user = User.objects.get(id=item.user_id)
+            user = user_lookup[item.user_id]
             serialized_user = serialize(user)
             attrs[item] = {
                 "user": {
diff --git a/src/sentry/constants.py b/src/sentry/constants.py
index 46bcc99af4..29526d56ab 100644
--- a/src/sentry/constants.py
+++ b/src/sentry/constants.py
@@ -436,11 +436,11 @@ class SentryAppInstallationStatus(object):
 
 
 class ExportQueryType(object):
-    DISCOVER_V1 = 0
+    DISCOVER_V2 = 0
     BILLING_REPORT = 1
     ISSUE_BY_TAG = 2
     # Add additional query types here...
-    DISCOVER_V1_STR = "DISCOVER_V1"
+    DISCOVER_V2_STR = "DISCOVER_V2"
     BILLING_REPORT_STR = "BILLING_REPORT"
     ISSUE_BY_TAG_STR = "ISSUE_BY_TAG"
     # Add their corresponding strings (sent from browser) here...
@@ -448,15 +448,15 @@ class ExportQueryType(object):
     @classmethod
     def as_choices(cls):
         return (
-            (cls.DISCOVER_V1, cls.DISCOVER_V1_STR),
+            (cls.DISCOVER_V2, cls.DISCOVER_V2_STR),
             (cls.BILLING_REPORT, cls.BILLING_REPORT_STR),
             (cls.ISSUE_BY_TAG, cls.ISSUE_BY_TAG_STR),
         )
 
     @classmethod
     def as_str(cls, status):
-        if status == cls.DISCOVER_V1:
-            return cls.DISCOVER_V1_STR
+        if status == cls.DISCOVER_V2:
+            return cls.DISCOVER_V2_STR
         elif status == cls.BILLING_REPORT:
             return cls.BILLING_REPORT_STR
         elif status == cls.ISSUE_BY_TAG:
diff --git a/src/sentry/models/exporteddata.py b/src/sentry/models/exporteddata.py
index 2e7dd7a734..029c5d1d26 100644
--- a/src/sentry/models/exporteddata.py
+++ b/src/sentry/models/exporteddata.py
@@ -2,7 +2,7 @@ from __future__ import absolute_import
 
 import six
 from enum import Enum
-
+from datetime import timedelta
 from django.conf import settings
 from django.db import models
 from django.utils import timezone
@@ -16,6 +16,9 @@ from sentry.db.models import (
     sane_repr,
 )
 
+# Arbitrary, subject to change
+DEFAULT_EXPIRATION = timedelta(weeks=4)
+
 
 class ExportStatus(six.binary_type, Enum):
     Early = "EARLY"  # The download is being prepared
@@ -49,8 +52,14 @@ class ExportedData(Model):
         else:
             return ExportStatus.Valid
 
+    def complete_upload(self, file, expiration=DEFAULT_EXPIRATION):
+        current_time = timezone.now()
+        expire_time = current_time + DEFAULT_EXPIRATION
+        self.update(file=file, date_finished=current_time, date_expired=expire_time)
+        # TODO(Leander): Implement email notification
+
     class Meta:
         app_label = "sentry"
         db_table = "sentry_exporteddata"
 
-    __repr__ = sane_repr("data_id")
+    __repr__ = sane_repr("query_type", "query_info")
diff --git a/src/sentry/static/sentry/app/views/dataExport/dataDownload.tsx b/src/sentry/static/sentry/app/views/dataExport/dataDownload.tsx
index 34e4b6f304..76463c5775 100644
--- a/src/sentry/static/sentry/app/views/dataExport/dataDownload.tsx
+++ b/src/sentry/static/sentry/app/views/dataExport/dataDownload.tsx
@@ -30,7 +30,6 @@ type Download = {
   dateCreated: string;
   dateFinished?: string;
   dateExpired?: string;
-  storageUrl?: string;
   query: {
     type: number;
     info: object;
@@ -55,7 +54,7 @@ class DataDownload extends AsyncView<Props, State> {
   }
 
   handleDownload(): void {
-    // TODO(Leander): Implement direct download from Google Cloud Storage
+    // TODO(Leander): Send request to download endpoint
   }
 
   renderExpired(): React.ReactNode {
diff --git a/src/sentry/tagstore/base.py b/src/sentry/tagstore/base.py
index f498c6d775..d11493ae0b 100644
--- a/src/sentry/tagstore/base.py
+++ b/src/sentry/tagstore/base.py
@@ -211,7 +211,9 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def get_group_tag_value_iter(self, project_id, group_id, environment_id, key, callbacks=()):
+    def get_group_tag_value_iter(
+        self, project_id, group_id, environment_id, key, callbacks=(), offset=0
+    ):
         """
         >>> get_group_tag_value_iter(1, 2, 3, 'environment')
         """
diff --git a/src/sentry/tagstore/snuba/backend.py b/src/sentry/tagstore/snuba/backend.py
index 472bc2b5b2..be9cdb1ef5 100644
--- a/src/sentry/tagstore/snuba/backend.py
+++ b/src/sentry/tagstore/snuba/backend.py
@@ -758,7 +758,9 @@ class SnubaTagStorage(TagStorage):
             reverse=desc,
         )
 
-    def get_group_tag_value_iter(self, project_id, group_id, environment_id, key, callbacks=()):
+    def get_group_tag_value_iter(
+        self, project_id, group_id, environment_id, key, callbacks=(), offset=0
+    ):
         filters = {
             "project_id": get_project_list(project_id),
             "tags_key": [key],
@@ -775,9 +777,9 @@ class SnubaTagStorage(TagStorage):
                 ["max", "timestamp", "last_seen"],
             ],
             orderby="-first_seen",  # Closest thing to pre-existing `-id` order
-            # TODO: This means they can't actually iterate all GroupTagValues.
             limit=1000,
             referrer="tagstore.get_group_tag_value_iter",
+            offset=offset,
         )
 
         group_tag_values = [
diff --git a/src/sentry/tasks/data_export.py b/src/sentry/tasks/data_export.py
index 159554e678..04f6d21622 100644
--- a/src/sentry/tasks/data_export.py
+++ b/src/sentry/tasks/data_export.py
@@ -1,8 +1,147 @@
 from __future__ import absolute_import
+
+import csv
+import tempfile
+
+from django.db import transaction
+
+from sentry import tagstore
+from sentry.constants import ExportQueryType
+from sentry.models import EventUser, File, Group, Project, get_group_with_redirect
 from sentry.tasks.base import instrumented_task
 
+SNUBA_MAX_RESULTS = 1000
+
+
+@instrumented_task(name="sentry.tasks.data_export.assemble_download", queue="data_export")
+def assemble_download(data_export):
+    # Create a temporary file
+    with tempfile.TemporaryFile() as tf:
+        # Process the query based on its type
+        if data_export.query_type == ExportQueryType.DISCOVER_V2:
+            process_discover_v2(data_export, tf)
+            return
+        elif data_export.query_type == ExportQueryType.BILLING_REPORT:
+            process_billing_report(data_export, tf)
+            return
+        elif data_export.query_type == ExportQueryType.ISSUE_BY_TAG:
+            file_name = process_issue_by_tag(data_export, tf)
+        # Create a new File object and attach it to the ExportedData
+        tf.seek(0)
+        with transaction.atomic():
+            file = File.objects.create(name=file_name, type="export.csv")
+            file.putfile(tf)
+            data_export.complete_upload(file=file)
+
+
+def process_discover_v2(data_export, file):
+    # TODO(Leander): Implement processing for Discover V2
+    return
+
+
+def process_billing_report(data_export, file):
+    # TODO(Leander): Implement processing for Billing Reports
+    return
+
+
+def process_issue_by_tag(data_export, file):
+    """
+    Convert the tag query to a CSV, writing it to the provided file.
+    Returns the suggested file name.
+    (Adapted from 'src/sentry/web/frontend/group_tag_export.py')
+    """
+    # Get the pertaining project
+    payload = data_export.query_info
+    project = Project.objects.get(id=payload["project_id"])
+
+    # Get the pertaining issue
+    group, _ = get_group_with_redirect(
+        payload["group_id"], queryset=Group.objects.filter(project=project)
+    )
 
-@instrumented_task(name="sentry.tasks.data_export.compile_data", queue="data_export")
-def compile_data(data_export):
-    # TODO(Leander): Implement logic to compile CSV data via provided ExportedData object
+    # Get the pertaining key
+    key = payload["key"]
+    lookup_key = u"sentry:{0}".format(key) if tagstore.is_reserved_key(key) else key
+
+    # If the key is the 'user' tag, attach the event user
+    def attach_eventuser(items):
+        users = EventUser.for_tags(group.project_id, [i.value for i in items])
+        for item in items:
+            item._eventuser = users.get(item.value)
+
+    # Create the fields/callback lists
+    if key == "user":
+        callbacks = [attach_eventuser]
+        fields = [
+            "value",
+            "id",
+            "email",
+            "username",
+            "ip_address",
+            "times_seen",
+            "last_seen",
+            "first_seen",
+        ]
+    else:
+        callbacks = []
+        fields = ["value", "times_seen", "last_seen", "first_seen"]
+
+    # Example file name: ISSUE_BY_TAG-project10-user__721.csv
+    file_details = u"{}-{}__{}".format(project.slug, key, data_export.id)
+    file_name = get_file_name(ExportQueryType.ISSUE_BY_TAG_STR, file_details)
+
+    # Iterate through all the GroupTagValues
+    writer = create_writer(file, fields)
+    iteration = 0
+    while True:
+        gtv_list = tagstore.get_group_tag_value_iter(
+            project_id=group.project_id,
+            group_id=group.id,
+            environment_id=None,
+            key=lookup_key,
+            callbacks=callbacks,
+            offset=SNUBA_MAX_RESULTS * iteration,
+        )
+        gtv_list_raw = [serialize_issue_by_tag(key, item) for item in gtv_list]
+        if len(gtv_list_raw) == 0:
+            break
+        writer.writerows(gtv_list_raw)
+        iteration += 1
+    return file_name
+
+
+def create_writer(file, fields):
+    writer = csv.DictWriter(file, fields)
+    writer.writeheader()
+    return writer
+
+
+def get_file_name(export_type, custom_string, extension="csv"):
+    file_name = u"{}-{}.{}".format(export_type, custom_string, extension)
+    return file_name
+
+
+def alert_error():
+    # TODO(Leander): Handle errors in these tasks.
     return
+
+
+################################
+#  Process-specific functions  #
+################################
+
+
+def serialize_issue_by_tag(key, item):
+    result = {
+        "value": item.value,
+        "times_seen": item.times_seen,
+        "last_seen": item.last_seen.strftime("%Y-%m-%dT%H:%M:%S.%fZ"),
+        "first_seen": item.first_seen.strftime("%Y-%m-%dT%H:%M:%S.%fZ"),
+    }
+    if key == "user":
+        euser = item._eventuser
+        result["id"] = euser.ident if euser else ""
+        result["email"] = euser.email if euser else ""
+        result["username"] = euser.username if euser else ""
+        result["ip_address"] = euser.ip_address if euser else ""
+    return result
diff --git a/tests/sentry/tasks/test_data_export.py b/tests/sentry/tasks/test_data_export.py
new file mode 100644
index 0000000000..596ccad47b
--- /dev/null
+++ b/tests/sentry/tasks/test_data_export.py
@@ -0,0 +1,70 @@
+from __future__ import absolute_import
+
+from sentry.models import ExportedData, File
+from sentry.tasks.data_export import assemble_download, get_file_name
+from sentry.testutils import TestCase, SnubaTestCase
+
+
+class AssembleDownloadTest(TestCase, SnubaTestCase):
+    def setUp(self):
+        super(AssembleDownloadTest, self).setUp()
+        self.user = self.create_user()
+        self.org = self.create_organization()
+        self.project = self.create_project()
+        self.event = self.store_event(
+            data={"tags": {"foo": "bar"}, "fingerprint": ["group-1"]}, project_id=self.project.id
+        )
+        self.store_event(
+            data={"tags": {"foo": "bar2"}, "fingerprint": ["group-1"]}, project_id=self.project.id
+        )
+        self.store_event(
+            data={"tags": {"foo": "bar2"}, "fingerprint": ["group-1"]}, project_id=self.project.id
+        )
+
+    def test_task_persistent_name(self):
+        assert assemble_download.name == "sentry.tasks.data_export.assemble_download"
+
+    def test_get_file_name(self):
+        file_name = get_file_name("TESTING", "proj1_user1_test", "ext")
+        assert file_name == "TESTING-proj1_user1_test.ext"
+        file_name = get_file_name("TESTING", "proj1_user1_test")
+        assert file_name == "TESTING-proj1_user1_test.csv"
+
+    def test_assemble_download_issue_by_tag(self):
+        de1 = ExportedData.objects.create(
+            user=self.user,
+            organization=self.org,
+            query_type=2,
+            query_info={
+                "project_id": self.project.id,
+                "group_id": self.event.group_id,
+                "key": "user",
+            },
+        )
+        with self.tasks():
+            assemble_download(de1)
+        assert de1.date_finished is not None
+        assert de1.date_expired is not None
+        assert de1.file is not None
+        f1 = de1.file
+        assert isinstance(f1, File)
+        raw1 = f1.getfile().read()
+        assert raw1 == "value,id,email,username,ip_address,times_seen,last_seen,first_seen\r\n"
+        de2 = ExportedData.objects.create(
+            user=self.user,
+            organization=self.org,
+            query_type=2,
+            query_info={
+                "project_id": self.project.id,
+                "group_id": self.event.group_id,
+                "key": "foo",
+            },
+        )
+        with self.tasks():
+            assemble_download(de2)
+        # Convert raw csv to list of line-strings
+        raw2 = de2.file.getfile().read().strip().split("\r\n")
+        assert len(raw2) == 3
+        assert raw2[0] == "value,times_seen,last_seen,first_seen"
+        assert raw2[1].startswith("bar,1,")
+        assert raw2[2].startswith("bar2,2,")
