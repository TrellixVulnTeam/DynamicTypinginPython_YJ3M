commit 3ae9f67e5159a9dfd96d0c51d1b1467c5fae5e75
Author: Jess MacQueen <macqueen@users.noreply.github.com>
Date:   Fri Jan 18 09:50:15 2019 -0800

    ref(api): Move discard and some deletion code from project index to mixin (#11578)

diff --git a/src/sentry/api/endpoints/project_group_index.py b/src/sentry/api/endpoints/project_group_index.py
index eeced64d46..82e2d57c9a 100644
--- a/src/sentry/api/endpoints/project_group_index.py
+++ b/src/sentry/api/endpoints/project_group_index.py
@@ -2,21 +2,20 @@ from __future__ import absolute_import, division, print_function
 
 from datetime import timedelta
 import functools
-import logging
 from uuid import uuid4
 
 import six
-from django.db import IntegrityError, transaction
+from django.db import transaction
 from django.utils import timezone
 from rest_framework.response import Response
 
-from sentry import analytics, eventstream, features, search
+from sentry import analytics, eventstream, search
 from sentry.api.base import DocSection, EnvironmentMixin
 from sentry.api.bases.project import ProjectEndpoint, ProjectEventPermission
 from sentry.api.fields import Actor
 from sentry.api.helpers.group_index import (
-    build_query_params_from_request, get_by_short_id, GroupValidator,
-    STATUS_CHOICES, ValidationError
+    build_query_params_from_request, delete_groups, get_by_short_id, GroupValidator,
+    handle_discard, STATUS_CHOICES, ValidationError
 )
 from sentry.api.serializers import serialize
 from sentry.api.serializers.models.actor import ActorSerializer
@@ -24,14 +23,13 @@ from sentry.api.serializers.models.group import (
     SUBSCRIPTION_REASON_MAP, StreamGroupSerializer)
 from sentry.db.models.query import create_or_update
 from sentry.models import (
-    Activity, Environment, Group, GroupAssignee, GroupBookmark, GroupLink, GroupHash, GroupResolution,
+    Activity, Environment, Group, GroupAssignee, GroupBookmark, GroupLink, GroupResolution,
     GroupSeen, GroupShare, GroupSnooze, GroupStatus, GroupSubscription, GroupSubscriptionReason,
-    GroupTombstone, Release, TOMBSTONE_FIELDS_FROM_GROUP, UserOption, User
+    Release, UserOption, User
 )
 from sentry.models.event import Event
 from sentry.receivers import DEFAULT_SAVED_SEARCHES
-from sentry.signals import advanced_search, issue_ignored, issue_resolved_in_release, issue_deleted, resolved_with_commit
-from sentry.tasks.deletion import delete_groups
+from sentry.signals import advanced_search, issue_ignored, issue_resolved_in_release, resolved_with_commit
 from sentry.tasks.integrations import kick_off_status_syncs
 from sentry.tasks.merge import merge_groups
 from sentry.utils import metrics
@@ -39,7 +37,6 @@ from sentry.utils.apidocs import attach_scenarios, scenario
 from sentry.utils.cursors import CursorResult
 from sentry.utils.functional import extract_lazy_object
 
-delete_logger = logging.getLogger('sentry.deletions.api')
 
 ERR_INVALID_STATS_PERIOD = "Invalid stats_period. Valid choices are '', '24h', and '14d'"
 SAVED_SEARCH_QUERIES = set([s['query'] for s in DEFAULT_SAVED_SEARCHES])
@@ -340,38 +337,7 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint, EnvironmentMixin):
 
         discard = result.get('discard')
         if discard:
-
-            if not features.has('projects:discard-groups', project, actor=request.user):
-                return Response({'detail': ['You do not have that feature enabled']}, status=400)
-
-            group_list = list(queryset)
-            groups_to_delete = []
-
-            for group in group_list:
-                with transaction.atomic():
-                    try:
-                        tombstone = GroupTombstone.objects.create(
-                            previous_group_id=group.id,
-                            actor_id=acting_user.id if acting_user else None,
-                            **{name: getattr(group, name) for name in TOMBSTONE_FIELDS_FROM_GROUP}
-                        )
-                    except IntegrityError:
-                        # in this case, a tombstone has already been created
-                        # for a group, so no hash updates are necessary
-                        pass
-                    else:
-                        groups_to_delete.append(group)
-
-                        GroupHash.objects.filter(
-                            group=group,
-                        ).update(
-                            group=None,
-                            group_tombstone_id=tombstone.id,
-                        )
-
-            self._delete_groups(request, project, groups_to_delete, delete_type='discard')
-
-            return Response(status=204)
+            return handle_discard(request, list(queryset), [project], acting_user)
 
         statusDetails = result.pop('statusDetails', result)
         status = result.get('status')
@@ -875,62 +841,6 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint, EnvironmentMixin):
         if not group_list:
             return Response(status=204)
 
-        self._delete_groups(request, project, group_list, delete_type='delete')
+        delete_groups(request, project, group_list, delete_type='delete')
 
         return Response(status=204)
-
-    def _delete_groups(self, request, project, group_list, delete_type):
-        if not group_list:
-            return
-
-        # deterministic sort for sanity, and for very large deletions we'll
-        # delete the "smaller" groups first
-        group_list.sort(key=lambda g: (g.times_seen, g.id))
-        group_ids = [g.id for g in group_list]
-
-        Group.objects.filter(
-            id__in=group_ids,
-        ).exclude(status__in=[
-            GroupStatus.PENDING_DELETION,
-            GroupStatus.DELETION_IN_PROGRESS,
-        ]).update(status=GroupStatus.PENDING_DELETION)
-
-        eventstream_state = eventstream.start_delete_groups(project.id, group_ids)
-        transaction_id = uuid4().hex
-
-        GroupHash.objects.filter(
-            project_id=project.id,
-            group__id__in=group_ids,
-        ).delete()
-
-        delete_groups.apply_async(
-            kwargs={
-                'object_ids': group_ids,
-                'transaction_id': transaction_id,
-                'eventstream_state': eventstream_state,
-            },
-            countdown=3600,
-        )
-
-        for group in group_list:
-            self.create_audit_entry(
-                request=request,
-                organization_id=project.organization_id,
-                target_object=group.id,
-                transaction_id=transaction_id,
-            )
-
-            delete_logger.info(
-                'object.delete.queued',
-                extra={
-                    'object_id': group.id,
-                    'transaction_id': transaction_id,
-                    'model': type(group).__name__,
-                }
-            )
-
-            issue_deleted.send_robust(
-                group=group,
-                user=request.user,
-                delete_type=delete_type,
-                sender=self.__class__)
diff --git a/src/sentry/api/helpers/group_index.py b/src/sentry/api/helpers/group_index.py
index 55fdb3f7c7..86b9730382 100644
--- a/src/sentry/api/helpers/group_index.py
+++ b/src/sentry/api/helpers/group_index.py
@@ -1,14 +1,32 @@
 from __future__ import absolute_import
 
+import logging
+
+from collections import defaultdict
+from uuid import uuid4
+
+from django.db import IntegrityError, transaction
+
 from rest_framework import serializers
+from rest_framework.response import Response
 
+from sentry import eventstream, features
+from sentry.api.base import audit_logger
 from sentry.api.fields import ActorField
 from sentry.constants import DEFAULT_SORT_OPTION
-from sentry.models import Commit, Group, GroupStatus, Release, Repository, Team, User
+from sentry.models import (
+    Commit, Group, GroupHash, GroupStatus, GroupTombstone,
+    Release, Repository, TOMBSTONE_FIELDS_FROM_GROUP, Team, User
+)
 from sentry.models.group import looks_like_short_id
 from sentry.search.utils import InvalidQuery, parse_query
+from sentry.signals import issue_deleted
+from sentry.tasks.deletion import delete_groups as delete_groups_task
+from sentry.utils.audit import create_audit_entry
 from sentry.utils.cursors import Cursor
 
+delete_logger = logging.getLogger('sentry.deletions.api')
+
 
 class ValidationError(Exception):
     pass
@@ -207,3 +225,97 @@ class GroupValidator(serializers.Serializer):
             raise serializers.ValidationError(
                 'Other attributes cannot be updated when discarding')
         return attrs
+
+
+def handle_discard(request, group_list, projects, user):
+    for project in projects:
+        if not features.has('projects:discard-groups', project, actor=user):
+            return Response({'detail': ['You do not have that feature enabled']}, status=400)
+
+    # grouped by project_id
+    groups_to_delete = defaultdict(list)
+
+    for group in group_list:
+        with transaction.atomic():
+            try:
+                tombstone = GroupTombstone.objects.create(
+                    previous_group_id=group.id,
+                    actor_id=user.id if user else None,
+                    **{name: getattr(group, name) for name in TOMBSTONE_FIELDS_FROM_GROUP}
+                )
+            except IntegrityError:
+                # in this case, a tombstone has already been created
+                # for a group, so no hash updates are necessary
+                pass
+            else:
+                groups_to_delete[group.project_id].append(group)
+
+                GroupHash.objects.filter(
+                    group=group,
+                ).update(
+                    group=None,
+                    group_tombstone_id=tombstone.id,
+                )
+
+    for project in projects:
+        delete_groups(request, project, groups_to_delete.get(project.id), delete_type='discard')
+
+    return Response(status=204)
+
+
+def delete_groups(request, project, group_list, delete_type):
+    if not group_list:
+        return
+
+    # deterministic sort for sanity, and for very large deletions we'll
+    # delete the "smaller" groups first
+    group_list.sort(key=lambda g: (g.times_seen, g.id))
+    group_ids = [g.id for g in group_list]
+
+    Group.objects.filter(
+        id__in=group_ids,
+    ).exclude(status__in=[
+        GroupStatus.PENDING_DELETION,
+        GroupStatus.DELETION_IN_PROGRESS,
+    ]).update(status=GroupStatus.PENDING_DELETION)
+
+    eventstream_state = eventstream.start_delete_groups(project.id, group_ids)
+    transaction_id = uuid4().hex
+
+    GroupHash.objects.filter(
+        project_id=project.id,
+        group__id__in=group_ids,
+    ).delete()
+
+    delete_groups_task.apply_async(
+        kwargs={
+            'object_ids': group_ids,
+            'transaction_id': transaction_id,
+            'eventstream_state': eventstream_state,
+        },
+        countdown=3600,
+    )
+
+    for group in group_list:
+        create_audit_entry(
+            request=request,
+            transaction_id=transaction_id,
+            logger=audit_logger,
+            organization_id=project.organization_id,
+            target_object=group.id,
+        )
+
+        delete_logger.info(
+            'object.delete.queued',
+            extra={
+                'object_id': group.id,
+                'transaction_id': transaction_id,
+                'model': type(group).__name__,
+            }
+        )
+
+        issue_deleted.send_robust(
+            group=group,
+            user=request.user,
+            delete_type=delete_type,
+            sender=delete_groups)
diff --git a/tests/sentry/api/endpoints/test_project_group_index.py b/tests/sentry/api/endpoints/test_project_group_index.py
index 6f3e26de7c..cee53929c1 100644
--- a/tests/sentry/api/endpoints/test_project_group_index.py
+++ b/tests/sentry/api/endpoints/test_project_group_index.py
@@ -1782,7 +1782,7 @@ class GroupDeleteTest(APITestCase):
             self.project.slug,
         )
 
-    @patch('sentry.api.endpoints.project_group_index.eventstream')
+    @patch('sentry.api.helpers.group_index.eventstream')
     @patch('sentry.eventstream')
     def test_delete_by_id(self, mock_eventstream_task, mock_eventstream_api):
         eventstream_state = object()
