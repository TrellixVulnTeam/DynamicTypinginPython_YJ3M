commit 3c24657507a85f837512d0ec151f79cb75f28380
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Mon Feb 6 12:28:54 2017 +0100

    Added expiration support to processing issues and raw events

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index f7e0b9936e..e49e17ce74 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -428,6 +428,7 @@ CELERY_IMPORTS = (
     'sentry.tasks.deletion',
     'sentry.tasks.digests',
     'sentry.tasks.dsymcache',
+    'sentry.tasks.reprocessing',
     'sentry.tasks.email',
     'sentry.tasks.merge',
     'sentry.tasks.options',
@@ -530,6 +531,13 @@ CELERYBEAT_SCHEDULE = {
             'expires': 300,
         },
     },
+    'clear-expired-raw-events': {
+        'task': 'sentry.tasks.clear_expired_raw_events',
+        'schedule': timedelta(minutes=15),
+        'options': {
+            'expires': 300,
+        },
+    },
     # Disabled for the time being:
     # 'clear-old-cached-dsyms': {
     #     'task': 'sentry.tasks.clear_old_cached_dsyms',
@@ -1048,6 +1056,9 @@ SENTRY_WATCHERS = (
 # Max file size for avatar photo uploads
 SENTRY_MAX_AVATAR_SIZE = 5000000
 
+# The maximum age of raw events before they are deleted
+SENTRY_RAW_EVENT_MAX_AGE = 60 * 60 * 24 * 10
+
 # statuspage.io support
 STATUS_PAGE_ID = None
 STATUS_PAGE_API_HOST = 'statuspage.io'
diff --git a/src/sentry/models/processingissue.py b/src/sentry/models/processingissue.py
index daf72efb9c..26ddbeb86c 100644
--- a/src/sentry/models/processingissue.py
+++ b/src/sentry/models/processingissue.py
@@ -10,9 +10,10 @@ from __future__ import absolute_import
 from hashlib import sha1
 from django.db import models
 from django.db.models.aggregates import Count
+from django.utils import timezone
 
 from sentry.db.models import (
-    BaseManager, Model, FlexibleForeignKey, GzippedDictField, RawEvent,
+    BaseManager, Model, FlexibleForeignKey, GzippedDictField,
     sane_repr
 )
 
@@ -48,6 +49,7 @@ class ProcessingIssueManager(BaseManager):
         a list of raw events that are now resolved and a bool that indicates
         if there are more.
         """
+        from sentry.models import RawEvent
         rv = list(RawEvent.objects
             .filter(project_id=project_id)
             .annotate(eventissue_count=Count('eventprocessingissue'))
@@ -72,6 +74,9 @@ class ProcessingIssueManager(BaseManager):
             type=type,
             data=data
         )
+        ProcessingIssue.objects \
+            .filter(pk=issue.id) \
+            .update(datetime=timezone.now())
         # In case the issue moved away from unresolved we want to make
         # sure it's back to unresolved
         EventProcessingIssue.objects.get_or_create(
@@ -87,6 +92,7 @@ class ProcessingIssue(Model):
     checksum = models.CharField(max_length=40, db_index=True)
     type = models.CharField(max_length=30)
     data = GzippedDictField()
+    datetime = models.DateTimeField(default=timezone.now)
 
     objects = ProcessingIssueManager()
 
diff --git a/src/sentry/reprocessing.py b/src/sentry/reprocessing.py
index 3ec8793ba8..2a2886668e 100644
--- a/src/sentry/reprocessing.py
+++ b/src/sentry/reprocessing.py
@@ -28,7 +28,8 @@ def resolve_processing_issue(project, scope, object=None, type=None):
     if object is None:
         object = '*'
     from sentry.models import ProcessingIssue
-    from sentry.tasks.store import reprocess_events
+    from sentry.tasks.reprocessing import reprocess_events
+    # XXX: consider moving to task?
     if ProcessingIssue.objects.resolve_processing_issue(
             project=project, scope=scope, object=object, type=type):
         reprocess_events.delay(project_id=project.id)
diff --git a/src/sentry/tasks/reprocessing.py b/src/sentry/tasks/reprocessing.py
new file mode 100644
index 0000000000..8d15f18baa
--- /dev/null
+++ b/src/sentry/tasks/reprocessing.py
@@ -0,0 +1,58 @@
+from __future__ import absolute_import, print_function
+
+import logging
+from datetime import timedelta
+
+from django.conf import settings
+from django.utils import timezone
+
+from sentry.tasks.base import instrumented_task
+from sentry.utils.locking import UnableToAcquireLock
+
+logger = logging.getLogger(__name__)
+
+
+@instrumented_task(
+    name='sentry.tasks.store.reprocess_events',
+    queue='events.reprocess_events')
+def reprocess_events(project_id, **kwargs):
+    from sentry.models import ProcessingIssue
+    from sentry.coreapi import ClientApiHelper
+    from sentry import app
+
+    lock_key = 'events:reprocess_events:%s' % project_id
+    have_more = False
+    lock = app.locks.get(lock_key, duration=60)
+    try:
+        with lock.acquire():
+            raw_events, have_more = ProcessingIssue.find_resolved(project_id)
+            if raw_events:
+                helper = ClientApiHelper()
+                for raw_event in raw_events:
+                    helper.insert_data_to_database(raw_event.data)
+                    raw_event.delete()
+    except UnableToAcquireLock as error:
+        logger.warning('reprocess_events.fail', extra={'error': error})
+
+    # There are more, kick us off again
+    if have_more:
+        reprocess_events.delay(project_id=project_id)
+
+
+@instrumented_task(name='sentry.tasks.clear_expired_raw_events',
+                   time_limit=15,
+                   soft_time_limit=10)
+def clear_expired_raw_events():
+    from sentry.models import RawEvent, ProcessingIssue
+
+    cutoff = timezone.now() - timedelta(settings.SENTRY_RAW_EVENT_MAX_AGE)
+    RawEvent.objects.filter(
+        datetime__lt=cutoff
+    ).delete()
+
+    # Processing issues get a bit of extra time before we delete them
+    cutoff = timezone.now() - timedelta(int(
+        settings.SENTRY_RAW_EVENT_MAX_AGE * 1.3))
+    ProcessingIssue.objects.filter(
+        datetime__lt=cutoff
+    ).delete()
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index b95563a645..b5ee983124 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -19,7 +19,6 @@ from sentry.cache import default_cache
 from sentry.tasks.base import instrumented_task
 from sentry.utils import metrics
 from sentry.utils.safe import safe_execute
-from sentry.utils.locking import UnableToAcquireLock
 from sentry.stacktraces import process_stacktraces, \
     should_process_for_stacktraces
 
@@ -200,30 +199,3 @@ def save_event(cache_key=None, data=None, start_time=None, **kwargs):
         if start_time:
             metrics.timing('events.time-to-process', time() - start_time,
                            instance=data['platform'])
-
-
-@instrumented_task(
-    name='sentry.tasks.store.reprocess_events',
-    queue='events.reprocess_events')
-def reprocess_events(project_id, **kwargs):
-    from sentry.models import ProcessingIssue
-    from sentry.coreapi import ClientApiHelper
-    helper = ClientApiHelper()
-
-    from sentry import app
-
-    lock_key = 'events:reprocess_events:%s' % project_id
-    have_more = False
-    lock = app.locks.get(lock_key, duration=60)
-    try:
-        with lock.acquire():
-            raw_events, have_more = ProcessingIssue.find_resolved(project_id)
-            for raw_event in raw_events:
-                helper.insert_data_to_database(raw_event.data)
-                raw_event.delete()
-    except UnableToAcquireLock as error:
-        error_logger.warning('reprocess_events.fail', extra={'error': error})
-
-    # There are more, kick us off again
-    if have_more:
-        reprocess_events.delay(project_id=project_id)
