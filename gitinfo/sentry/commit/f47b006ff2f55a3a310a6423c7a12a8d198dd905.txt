commit f47b006ff2f55a3a310a6423c7a12a8d198dd905
Author: Jess MacQueen <macqueen@users.noreply.github.com>
Date:   Wed Oct 10 14:21:31 2018 -0700

    feat(api): Add snuba event paginator and serializer (#10061)

diff --git a/src/sentry/api/base.py b/src/sentry/api/base.py
index 7473f7f015..a99fae0823 100644
--- a/src/sentry/api/base.py
+++ b/src/sentry/api/base.py
@@ -254,6 +254,8 @@ class Endpoint(APIView):
         # map results based on callback
         if on_results:
             results = on_results(cursor_result.results)
+        else:
+            results = cursor_result.results
 
         response = Response(results)
         self.add_cursor_headers(request, response, cursor_result)
diff --git a/src/sentry/api/paginator.py b/src/sentry/api/paginator.py
index 768bfe8c6b..75c46234a0 100644
--- a/src/sentry/api/paginator.py
+++ b/src/sentry/api/paginator.py
@@ -330,3 +330,43 @@ class SequencePaginator(object):
             hits=min(len(self.scores), MAX_HITS_LIMIT) if count_hits else None,
             max_hits=MAX_HITS_LIMIT if count_hits else None,
         )
+
+
+class GenericOffsetPaginator(object):
+    """
+    A paginator for getting pages of results for a query using the OFFSET/LIMIT
+    mechanism.
+
+    This class makes the assumption that the query provides a static,
+    totally-ordered view on the data, so that the next page of data can be
+    retrieved by incrementing OFFSET to the next multiple of LIMIT with no
+    overlaps or gaps from the previous page.
+
+    It is potentially less performant than a ranged query solution that might
+    not to have to look at as many rows.
+    """
+
+    def __init__(self, data_fn):
+        self.data_fn = data_fn
+
+    def get_result(self, limit, cursor=None):
+        assert limit > 0
+        offset = cursor.offset if cursor is not None else 0
+        # Request 1 more than limit so we can tell if there is another page
+        data = self.data_fn(offset=offset, limit=limit + 1)
+        has_more = (len(data) == limit + 1)
+        if has_more:
+            data.pop()
+
+        # Since we are not issuing ranged queries, our cursors always have
+        # `value=0` (ie. all rows have the same value), and so offset naturally
+        # becomes the absolute row offset from the beginning of the entire
+        # dataset, which is the same meaning as SQLs `OFFSET`.
+        return CursorResult(
+            data,
+            prev=Cursor(0, max(0, offset - limit), True, offset > 0),
+            next=Cursor(0, max(0, offset + limit), False, has_more)
+        )
+        # TODO use Cursor.value as the `end` argument to data_fn() so that
+        # subsequent pages returned using these cursors are using the same end
+        # date for queries, this should stop drift from new incoming events.
diff --git a/src/sentry/api/serializers/models/event.py b/src/sentry/api/serializers/models/event.py
index 1b291a78dc..634bec7ca4 100644
--- a/src/sentry/api/serializers/models/event.py
+++ b/src/sentry/api/serializers/models/event.py
@@ -221,3 +221,45 @@ class SharedEventSerializer(EventSerializer):
         result['entries'] = [e for e in result['entries']
                              if e['type'] != 'breadcrumbs']
         return result
+
+
+class SnubaEvent(object):
+    """
+        A simple wrapper class on a row (dict) returned from snuba representing
+        an event. Provides a class name to register a serializer against, and
+        Makes keys accessible as attributes.
+    """
+
+    # The list of columns that we should request from snuba to be able to fill
+    # out a proper event object.
+    selected_columns = [
+        'event_id',
+        'message',
+        'user_id',
+        'username',
+        'email',
+    ]
+
+    def __init__(self, kv):
+        assert set(kv.keys()) == set(self.selected_columns)
+        self.__dict__ = kv
+
+
+@register(SnubaEvent)
+class SnubaEventSerializer(Serializer):
+    """
+        A bare-bones version of EventSerializer which uses snuba event rows as
+        the source data but attempts to produce a compatible (subset) of the
+        serialization returned by EventSerializer.
+    """
+
+    def serialize(self, obj, attrs, user):
+        return {
+            'eventID': six.text_type(obj.event_id),
+            'message': obj.message,
+            'user': {
+                'id': obj.user_id,
+                'email': obj.email,
+                'username': obj.username,
+            }
+        }
diff --git a/tests/sentry/api/test_paginator.py b/tests/sentry/api/test_paginator.py
index 421880de3e..229ed62489 100644
--- a/tests/sentry/api/test_paginator.py
+++ b/tests/sentry/api/test_paginator.py
@@ -10,6 +10,7 @@ from sentry.api.paginator import (
     DateTimePaginator,
     OffsetPaginator,
     SequencePaginator,
+    GenericOffsetPaginator,
     reverse_bisect_left)
 from sentry.models import User
 from sentry.testutils import TestCase
@@ -401,3 +402,23 @@ class SequencePaginatorTestCase(SimpleTestCase):
         n = 10
         paginator = SequencePaginator([(i, i) for i in range(n)])
         assert paginator.get_result(5, count_hits=True).hits == n
+
+
+class GenericOffsetPaginatorTest(TestCase):
+    def test_simple(self):
+        def data_fn(offset=None, limit=None):
+            return [i for i in range(offset, limit)]
+
+        paginator = GenericOffsetPaginator(data_fn=data_fn)
+
+        result = paginator.get_result(5)
+
+        assert list(result) == [0, 1, 2, 3, 4]
+        assert result.prev == Cursor(0, 0, True, False)
+        assert result.next == Cursor(0, 5, False, True)
+
+        result2 = paginator.get_result(5, result.next)
+
+        assert list(result2) == [5]
+        assert result2.prev == Cursor(0, 0, True, True)
+        assert result2.next == Cursor(0, 10, False, False)
