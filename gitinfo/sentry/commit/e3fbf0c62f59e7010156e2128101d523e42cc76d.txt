commit e3fbf0c62f59e7010156e2128101d523e42cc76d
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Mon Jan 16 18:20:54 2017 +0100

    Switch javascript processing over to new system

diff --git a/src/sentry/lang/javascript/plugin.py b/src/sentry/lang/javascript/plugin.py
index 9b36217ed0..6b3ae2a4e0 100644
--- a/src/sentry/lang/javascript/plugin.py
+++ b/src/sentry/lang/javascript/plugin.py
@@ -1,38 +1,29 @@
 from __future__ import absolute_import, print_function
 
-from django.conf import settings
 from ua_parser.user_agent_parser import Parse
 
-from sentry.models import Project
 from sentry.plugins import Plugin2
-from sentry.utils import metrics
 
-from .processor import SourceProcessor
+from .processor import JavaScriptStacktraceProcessor
 from .errormapping import rewrite_exception
 
 
 def preprocess_event(data):
-    if settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT:
-        project = Project.objects.get_from_cache(
-            id=data['project'],
-        )
-
-        allow_scraping = bool(project.get_option('sentry:scrape_javascript', True))
-
-        processor = SourceProcessor(
-            project=project,
-            allow_scraping=allow_scraping,
-        )
-        with metrics.timer('sourcemaps.process', instance=project.id):
-            processor.process(data)
-
     rewrite_exception(data)
-
+    fix_culprit(data)
     inject_device_data(data)
-
     return data
 
 
+def fix_culprit(data):
+    exc = data.get('sentry.interfaces.Exception')
+    if not exc:
+        return
+
+    from sentry.event_manager import generate_culprit
+    data['culprit'] = generate_culprit(data)
+
+
 def parse_user_agent(data):
     http = data.get('sentry.interfaces.Http')
     if not http:
@@ -119,6 +110,13 @@ class JavascriptPlugin(Plugin2):
         return False
 
     def get_event_preprocessors(self, data, **kwargs):
+        # XXX: rewrite_exception we probably also want if the event
+        # platform is something else? unsure
         if data.get('platform') == 'javascript':
             return [preprocess_event]
         return []
+
+    def get_stacktrace_processors(self, data, stacktrace_infos,
+                                  platforms, **kwargs):
+        if 'javascript' in platforms:
+            return [JavaScriptStacktraceProcessor(data, stacktrace_infos)]
diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index f77ba84166..e7e6b2d6b0 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -1,6 +1,6 @@
 from __future__ import absolute_import, print_function
 
-__all__ = ['SourceProcessor']
+__all__ = ['JavaScriptStacktraceProcessor']
 
 import codecs
 import logging
@@ -27,7 +27,6 @@ except ImportError:
         pass
 
 from sentry import http
-from sentry.constants import MAX_CULPRIT_LENGTH
 from sentry.exceptions import RestrictedIPAddress
 from sentry.interfaces.stacktrace import Stacktrace
 from sentry.models import EventError, Release, ReleaseFile
@@ -37,6 +36,7 @@ from sentry.utils.hashlib import md5_text
 from sentry.utils.http import is_valid_origin
 from sentry.utils.strings import truncatechars
 from sentry.utils import metrics
+from sentry.stacktraces import StacktraceProcessor
 
 from .cache import SourceCache, SourceMapCache
 
@@ -573,7 +573,7 @@ def generate_module(src):
     return CLEAN_MODULE_RE.sub('', filename) or UNKNOWN_MODULE
 
 
-class SourceProcessor(object):
+class JavaScriptStacktraceProcessor(StacktraceProcessor):
     """
     Attempts to fetch source code for javascript frames.
 
@@ -586,14 +586,17 @@ class SourceProcessor(object):
 
     Mutates the input ``data`` with expanded context if available.
     """
-    def __init__(self, project, max_fetches=MAX_RESOURCE_FETCHES,
-                 allow_scraping=True):
-        self.allow_scraping = allow_scraping
-        self.max_fetches = max_fetches
+
+    def __init__(self, *args, **kwargs):
+        StacktraceProcessor.__init__(self, *args, **kwargs)
+        self.max_fetches = MAX_RESOURCE_FETCHES
+        self.allow_scraping = self.project.get_option(
+            'sentry:scrape_javascript', True)
         self.fetch_count = 0
         self.cache = SourceCache()
         self.sourcemaps = SourceMapCache()
-        self.project = project
+        self.release = None
+        self._fetched_related_data = False
 
     def get_stacktraces(self, data):
         try:
@@ -613,117 +616,41 @@ class SourceProcessor(object):
             for s in stacktraces
         ]
 
-    def get_valid_frames(self, stacktraces):
+    def get_valid_frames(self):
         # build list of frames that we can actually grab source for
         frames = []
-        for _, stacktrace in stacktraces:
+        for info in self.stacktrace_infos:
             frames.extend([
-                f for f in stacktrace.frames
+                f for f in info.stacktrace['frames']
                 if f.lineno is not None
             ])
         return frames
 
-    def get_release(self, data):
-        if not data.get('release'):
+    def fetch_related_data(self):
+        if self._fetched_related_data:
             return
 
-        return Release.get(
-            project=self.project,
-            version=data['release'],
-        )
-
-    def process(self, data):
-        stacktraces = self.get_stacktraces(data)
-        if not stacktraces:
-            logger.debug('No stacktrace for event %r', data['event_id'])
-            return
-
-        # TODO(dcramer): we need this to do more than just sourcemaps
-        frames = self.get_valid_frames(stacktraces)
+        frames = self.get_valid_frames()
         if not frames:
-            logger.debug('Event %r has no frames with enough context to fetch remote source', data['event_id'])
+            logger.debug('Event %r has no frames with enough context to '
+                         'fetch remote source', self.data['event_id'])
             return
 
-        data.setdefault('errors', [])
-        errors = data['errors']
-
-        release = self.get_release(data)
-        # all of these methods assume mutation on the original
-        # objects rather than re-creation
-        self.populate_source_cache(frames, release)
-        with metrics.timer('sourcemaps.expand_frames'):
-            expand_errors, sourcemap_applied = self.expand_frames(frames, release)
-        errors.extend(expand_errors or [])
-        self.ensure_module_names(frames)
-        self.fix_culprit(data, stacktraces)
-        self.update_stacktraces(stacktraces)
-        if sourcemap_applied:
-            self.add_raw_stacktraces(data, release)
-        return data
-
-    def fix_culprit(self, data, stacktraces):
-        # This is a bit weird, since the original culprit we get
-        # will be wrong, so we want to touch it up after we've processed
-        # a stack trace.
-
-        # In this case, we have a list of all stacktraces as a tuple
-        # (stacktrace as dict, stacktrace class)
-        # So we need to take the [1] index to get the Stacktrace class,
-        # then extract the culprit string from that.
-        data['culprit'] = truncatechars(
-            stacktraces[-1][1].get_culprit_string(),
-            MAX_CULPRIT_LENGTH,
-        )
+        if self.data.get('release'):
+            self.release = Release.get(
+                project=self.project,
+                version=self.data['release'],
+            )
+        self.populate_source_cache(frames)
+        self._fetched_related_data = True
 
-    def update_stacktraces(self, stacktraces):
-        for raw, interface in stacktraces:
-            raw.update(interface.to_json())
+    def process_frame(self, frame):
+        self.fetch_related_data()
 
-    def add_raw_stacktraces(self, data, release):
-        try:
-            values = data['sentry.interfaces.Exception']['values']
-        except KeyError:
+        if not settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT or \
+           self.get_effective_platform(frame) != 'javascript':
             return
 
-        for exc in values:
-            if not exc.get('stacktrace'):
-                continue
-
-            raw_frames = []
-            for frame in exc['stacktrace']['frames']:
-                if 'data' not in frame or 'raw' not in frame['data']:
-                    continue
-
-                frame = frame['data']['raw']
-
-                if frame['lineno'] is not None:
-                    source = self.get_source(frame['abs_path'], release)
-                    if source is None:
-                        logger.debug('No source found for %s', frame['abs_path'])
-                        continue
-
-                    frame['pre_context'], frame['context_line'], frame['post_context'] = get_source_context(
-                        source=source, lineno=frame['lineno'], colno=frame['colno'] or 0)
-
-            for frame in exc['stacktrace']['frames']:
-                try:
-                    # TODO(dcramer): we should refactor this to avoid this
-                    # push/pop process
-                    raw_frames.append(frame['data'].pop('raw'))
-                except KeyError:
-                    raw_frames.append(frame.copy())
-
-            exc['raw_stacktrace'] = {'frames': raw_frames}
-
-    def ensure_module_names(self, frames):
-        # TODO(dcramer): this doesn't really fit well with generic URLs so we
-        # whitelist it to http/https
-        for frame in frames:
-            if not frame.module and frame.abs_path \
-               and frame.abs_path.startswith(('http:', 'https:', 'webpack:')):
-                frame.module = generate_module(frame.abs_path)
-
-    def expand_frames(self, frames, release):
         last_token = None
         token = None
 
@@ -732,146 +659,170 @@ class SourceProcessor(object):
         all_errors = []
         sourcemap_applied = False
 
-        for frame in frames:
-            errors = cache.get_errors(frame.abs_path)
-            if errors:
-                all_errors.extend(errors)
+        errors = cache.get_errors(frame['abs_path'])
+        if errors:
+            all_errors.extend(errors)
 
-            # can't fetch source if there's no filename present
-            if not frame.abs_path:
-                continue
+        # can't fetch source if there's no filename present
+        if not frame.get('abs_path'):
+            return
 
-            source = self.get_source(frame.abs_path, release)
-            if source is None:
-                logger.debug('No source found for %s', frame.abs_path)
-                continue
+        # This might fail but that's okay, we try with a different path a
+        # bit later down the road.
+        source = self.get_source(frame['abs_path'])
+
+        in_app = None
+        new_frame = dict(frame)
+        sourcemap_url, sourcemap_view = sourcemaps.get_link(frame['abs_path'])
+        if sourcemap_view and frame.get('colno') is None:
+            all_errors.append({
+                'type': EventError.JS_NO_COLUMN,
+                'url': expose_url(frame['abs_path']),
+            })
+        elif sourcemap_view:
+            last_token = token
 
-            sourcemap_url, sourcemap_view = sourcemaps.get_link(frame.abs_path)
-            if sourcemap_view and frame.colno is None:
+            if is_data_uri(sourcemap_url):
+                sourcemap_label = frame['abs_path']
+            else:
+                sourcemap_label = sourcemap_url
+
+            sourcemap_label = expose_url(sourcemap_label)
+
+            try:
+                # Errors are 1-indexed in the frames, so we need to -1 to get
+                # zero-indexed value from tokens.
+                assert frame['lineno'] > 0, "line numbers are 1-indexed"
+                token = sourcemap_view.lookup_token(
+                    frame['lineno'] - 1, frame['colno'])
+            except Exception:
+                token = None
                 all_errors.append({
-                    'type': EventError.JS_NO_COLUMN,
-                    'url': expose_url(frame.abs_path),
+                    'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
+                    'column': frame['colno'],
+                    'row': frame['lineno'],
+                    'source': frame['abs_path'],
+                    'sourcemap': sourcemap_label,
                 })
-            elif sourcemap_view:
-                last_token = token
 
-                if is_data_uri(sourcemap_url):
-                    sourcemap_label = frame.abs_path
-                else:
-                    sourcemap_label = sourcemap_url
+            # Store original data in annotation
+            raw_frame = frame.to_json()
+            raw_frame = dict(frame)
+            new_frame['data'] = dict(frame.get('data') or {},
+                                     sourcemap=sourcemap_label)
 
-                sourcemap_label = expose_url(sourcemap_label)
+            sourcemap_applied = True
 
-                try:
-                    # Errors are 1-indexed in the frames, so we need to -1 to get
-                    # zero-indexed value from tokens.
-                    assert frame.lineno > 0, "line numbers are 1-indexed"
-                    token = sourcemap_view.lookup_token(frame.lineno - 1, frame.colno)
-                except Exception:
-                    token = None
+            if token is not None:
+                abs_path = urljoin(sourcemap_url, token.src)
+
+                logger.debug('Mapping compressed source %r to mapping in %r',
+                             frame['abs_path'], abs_path)
+                source = self.get_source(abs_path)
+
+            if not source:
+                errors = cache.get_errors(abs_path)
+                if errors:
+                    all_errors.extend(errors)
+                else:
                     all_errors.append({
-                        'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
-                        'column': frame.colno,
-                        'row': frame.lineno,
-                        'source': frame.abs_path,
-                        'sourcemap': sourcemap_label,
+                        'type': EventError.JS_MISSING_SOURCE,
+                        'url': expose_url(abs_path),
                     })
 
-                # Store original data in annotation
-                # HACK(dcramer): we stuff things into raw which gets popped off
-                # later when adding the raw_stacktrace attribute.
-                raw_frame = frame.to_json()
-                frame.data = {
-                    'raw': raw_frame,
-                    'sourcemap': sourcemap_label,
-                }
+            if token is not None:
+                # Token's return zero-indexed lineno's
+                new_frame['lineno'] = token.src_line + 1
+                new_frame['colno'] = token.src_col
+                # The offending function is always the previous function in the stack
+                # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
+                if last_token:
+                    new_frame['function'] = last_token.name or frame['function']
+                else:
+                    new_frame['function'] = token.name or frame['function']
+
+                filename = token.src
+                # special case webpack support
+                # abs_path will always be the full path with webpack:/// prefix.
+                # filename will be relative to that
+                if abs_path.startswith('webpack:'):
+                    filename = abs_path
+                    # webpack seems to use ~ to imply "relative to resolver root"
+                    # which is generally seen for third party deps
+                    # (i.e. node_modules)
+                    if '/~/' in filename:
+                        filename = '~/' + abs_path.split('/~/', 1)[-1]
+                    else:
+                        filename = filename.split('webpack:///', 1)[-1]
+
+                    # As noted above, '~/' means they're coming from node_modules,
+                    # so these are not app dependencies
+                    if filename.startswith('~/'):
+                        in_app = False
+                    # And conversely, local dependencies start with './'
+                    elif filename.startswith('./'):
+                        in_app = True
+
+                    # We want to explicitly generate a webpack module name
+                    new_frame['module'] = generate_module(filename)
+
+                new_frame['abs_path'] = abs_path
+                new_frame['filename'] = filename
+                if not frame.module and abs_path.startswith(('http:', 'https:', 'webpack:')):
+                    new_frame['module'] = generate_module(abs_path)
+
+        elif sourcemap_url:
+            new_frame['data']['sourcemap'] = expose_url(sourcemap_url)
+
+        # TODO: theoretically a minified source could point to another mapped, minified source
+        new_frame['pre_context'], new_frame['context_line'], \
+            new_frame['post_context'] = get_source_context(
+            source=source, lineno=frame['lineno'], colno=frame['colno'] or 0)
+
+        if not new_frame['context_line'] and source:
+            all_errors.append({
+                'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
+                'column': new_frame['colno'],
+                'row': new_frame['lineno'],
+                'source': new_frame['abs_path'],
+            })
 
-                sourcemap_applied = True
+        changed_module = False
+        if not new_frame['module'] and frame['abs_path'].startswith(
+                ('http:', 'https:', 'webpack:')):
+            new_frame['module'] = generate_module(frame['abs_path'])
+            changed_module = True
 
-                if token is not None:
-                    abs_path = urljoin(sourcemap_url, token.src)
+        if sourcemap_applied or changed_module:
+            if in_app is not None:
+                new_frame['in_app'] = in_app
+                raw_frame['in_app'] = in_app
+            self.process_raw_frame(raw_frame)
+            return [new_frame], [raw_frame], all_errors
 
-                    logger.debug('Mapping compressed source %r to mapping in %r', frame.abs_path, abs_path)
-                    source = self.get_source(abs_path, release)
+    def update_stacktraces(self, stacktraces):
+        for raw, interface in stacktraces:
+            raw.update(interface.to_json())
 
-                if not source:
-                    errors = cache.get_errors(abs_path)
-                    if errors:
-                        all_errors.extend(errors)
-                    else:
-                        all_errors.append({
-                            'type': EventError.JS_MISSING_SOURCE,
-                            'url': expose_url(abs_path),
-                        })
-
-                if token is not None:
-                    # Token's return zero-indexed lineno's
-                    frame.lineno = token.src_line + 1
-                    frame.colno = token.src_col
-                    # The offending function is always the previous function in the stack
-                    # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
-                    if last_token:
-                        frame.function = last_token.name or frame.function
-                    else:
-                        frame.function = token.name or frame.function
-
-                    filename = token.src
-                    # special case webpack support
-                    # abs_path will always be the full path with webpack:/// prefix.
-                    # filename will be relative to that
-                    if abs_path.startswith('webpack:'):
-                        filename = abs_path
-                        # webpack seems to use ~ to imply "relative to resolver root"
-                        # which is generally seen for third party deps
-                        # (i.e. node_modules)
-                        if '/~/' in filename:
-                            filename = '~/' + abs_path.split('/~/', 1)[-1]
-                        else:
-                            filename = filename.split('webpack:///', 1)[-1]
-
-                        # As noted above, '~/' means they're coming from node_modules,
-                        # so these are not app dependencies
-                        if filename.startswith('~/'):
-                            frame.in_app = False
-                        # And conversely, local dependencies start with './'
-                        elif filename.startswith('./'):
-                            frame.in_app = True
-
-                        # Update 'raw' copy to have same in_app status
-                        raw_frame['in_app'] = frame.in_app
-
-                        # We want to explicitly generate a webpack module name
-                        frame.module = generate_module(filename)
-
-                    frame.abs_path = abs_path
-                    frame.filename = filename
-                    if not frame.module and abs_path.startswith(('http:', 'https:', 'webpack:')):
-                        frame.module = generate_module(abs_path)
-
-            elif sourcemap_url:
-                frame.data = {
-                    'sourcemap': expose_url(sourcemap_url),
-                }
-
-            # TODO: theoretically a minified source could point to another mapped, minified source
-            frame.pre_context, frame.context_line, frame.post_context = get_source_context(
-                source=source, lineno=frame.lineno, colno=frame.colno or 0)
-
-            if not frame.context_line and source:
-                all_errors.append({
-                    'type': EventError.JS_INVALID_SOURCEMAP_LOCATION,
-                    'column': frame.colno,
-                    'row': frame.lineno,
-                    'source': frame.abs_path,
-                })
-        return all_errors, sourcemap_applied
+    def process_raw_frame(self, frame):
+        frame = frame['data']['raw']
+
+        if frame['lineno'] is not None:
+            source = self.get_source(frame['abs_path'])
+            if source is None:
+                logger.debug('No source found for %s', frame['abs_path'])
+                return
+
+            frame['pre_context'], frame['context_line'], frame['post_context'] \
+                = get_source_context(source=source, lineno=frame['lineno'],
+                                     colno=frame['colno'] or 0)
 
-    def get_source(self, filename, release):
+    def get_source(self, filename):
         if filename not in self.cache:
-            self.cache_source(filename, release)
+            self.cache_source(filename)
         return self.cache.get(filename)
 
-    def cache_source(self, filename, release):
+    def cache_source(self, filename):
         sourcemaps = self.sourcemaps
         cache = self.cache
 
@@ -886,7 +837,8 @@ class SourceProcessor(object):
         # TODO: respect cache-control/max-age headers to some extent
         logger.debug('Fetching remote source %r', filename)
         try:
-            result = fetch_file(filename, project=self.project, release=release,
+            result = fetch_file(filename, project=self.project,
+                                release=self.release,
                                 allow_scraping=self.allow_scraping)
         except BadSource as exc:
             cache.add_error(filename, exc.data)
@@ -909,7 +861,7 @@ class SourceProcessor(object):
             sourcemap_view = fetch_sourcemap(
                 sourcemap_url,
                 project=self.project,
-                release=release,
+                release=self.release,
                 allow_scraping=self.allow_scraping,
             )
         except BadSource as exc:
@@ -927,7 +879,7 @@ class SourceProcessor(object):
                     None,
                 )
 
-    def populate_source_cache(self, frames, release):
+    def populate_source_cache(self, frames):
         """
         Fetch all sources that we know are required (being referenced directly
         in frames).
@@ -948,5 +900,4 @@ class SourceProcessor(object):
         for idx, filename in enumerate(pending_file_list):
             self.cache_source(
                 filename=filename,
-                release=release,
             )
