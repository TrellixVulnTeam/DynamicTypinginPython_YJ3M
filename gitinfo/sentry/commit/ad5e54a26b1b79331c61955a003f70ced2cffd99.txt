commit ad5e54a26b1b79331c61955a003f70ced2cffd99
Author: Mark Story <mark@sentry.io>
Date:   Thu Apr 2 10:23:37 2020 -0400

    feat(perf-views) Enable latency drilldown (#17979)
    
    Our distributions and likely those of our customers are not anything
    approximating normal. Because they are heavily modal, or bi-modal we end
    up with results that are skewed heavily by outliers. While those
    outliers are important being able to drill down into the mode is also
    useful.
    
    Remove the active bar highlighting and instead allow users to zoom in on
    individual bars to generate new distributions between 0 and the new
    upper bound.
    
    While we want to make sure the API is well behaved we also don't want to
    let users get into a bad state, and aim to prevent them from requesting
    a data set that won't render.
    
    When the duration conditions create a window equal to or smaller than
    the number of bars in the graph we need to include the starting bucket
    so that we can zerofill correctly which requires expanding the internal
    representation of the histogram function.

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index c0a7dbff1e..6fb713082f 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -1102,16 +1102,23 @@ FUNCTIONS = {
         "transform": "divide(countIf(notEquals(transaction_status, 0)), count())",
         "result_type": "number",
     },
+    # The user facing signature for this function is histogram(<column>, <num_buckets>)
+    # Internally, snuba.discover.query() expands the user request into this value by
+    # calculating the bucket size and start_offset.
     "histogram": {
         "name": "histogram",
         "args": [
             DurationColumnNoLookup("column"),
             NumberRange("num_buckets", 1, 500),
-            NumberRange("bucket", 0, None),
+            NumberRange("bucket_size", 0, None),
+            NumberRange("start_offset", 0, None),
         ],
         "column": [
             "multiply",
-            [["floor", [["divide", [u"{column}", ArgValue("bucket")]]]], ArgValue("bucket")],
+            [
+                ["floor", [["divide", [u"{column}", ArgValue("bucket_size")]]]],
+                ArgValue("bucket_size"),
+            ],
             None,
         ],
         "result_type": "number",
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index 1c56f7dcc9..c02a2afdea 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -5,7 +5,7 @@ import six
 from collections import namedtuple
 from copy import deepcopy
 from datetime import timedelta
-from math import ceil
+from math import ceil, floor
 
 from sentry import options
 from sentry.api.event_search import (
@@ -171,7 +171,8 @@ def find_histogram_buckets(field, params, conditions):
             u"histogram(...) requires a bucket value between 1 and 500, not {}".format(columns[1])
         )
 
-    alias = u"max_{}".format(column)
+    max_alias = u"max_{}".format(column)
+    min_alias = u"min_{}".format(column)
 
     conditions = deepcopy(conditions) if conditions else []
     found = False
@@ -189,19 +190,23 @@ def find_histogram_buckets(field, params, conditions):
         end=params.get("end"),
         dataset=Dataset.Discover,
         conditions=translated_args.conditions,
-        aggregations=[["max", "duration", alias]],
+        aggregations=[["max", "duration", max_alias], ["min", "duration", min_alias]],
     )
     if len(results["data"]) != 1:
         # If there are no transactions, so no max duration, return one empty bucket
-        return "histogram({}, 1, 1)".format(column)
+        return "histogram({}, 1, 1, 0)".format(column)
 
-    bucket_max = results["data"][0][alias]
+    bucket_min = results["data"][0][min_alias]
+    bucket_max = results["data"][0][max_alias]
     if bucket_max == 0:
         raise InvalidSearchQuery(u"Cannot calculate histogram for {}".format(field))
+    bucket_size = ceil((bucket_max - bucket_min) / float(num_buckets))
 
-    bucket_number = ceil(bucket_max / float(num_buckets))
+    # Determine the first bucket that will show up in our results so that we can
+    # zerofill correctly.
+    offset = floor(bucket_min / bucket_size) * bucket_size
 
-    return "histogram({}, {:g}, {:g})".format(column, num_buckets, bucket_number)
+    return "histogram({}, {:g}, {:g}, {:g})".format(column, num_buckets, bucket_size, offset)
 
 
 def zerofill_histogram(results, column_meta, orderby, sentry_function_alias, snuba_function_alias):
@@ -209,7 +214,7 @@ def zerofill_histogram(results, column_meta, orderby, sentry_function_alias, snu
     if len(parts) < 2:
         raise Exception(u"{} is not a valid histogram alias".format(snuba_function_alias))
 
-    bucket_size, num_buckets = int(parts[-1]), int(parts[-2])
+    bucket_offset, bucket_size, num_buckets = int(parts[-1]), int(parts[-2]), int(parts[-3])
     if len(results) == num_buckets:
         return results
 
@@ -233,7 +238,7 @@ def zerofill_histogram(results, column_meta, orderby, sentry_function_alias, snu
                 break
 
     for i in range(num_buckets):
-        bucket = bucket_size * i
+        bucket = bucket_offset + (bucket_size * i)
         if bucket not in bucket_map:
             bucket_map[bucket] = build_new_bucket_row(bucket)
 
@@ -241,7 +246,7 @@ def zerofill_histogram(results, column_meta, orderby, sentry_function_alias, snu
     if is_sorted:
         i, diff, end = (0, 1, num_buckets) if not is_reversed else (num_buckets, -1, 0)
         while i <= end:
-            bucket = bucket_size * i
+            bucket = bucket_offset + (bucket_size * i)
             if bucket in bucket_map:
                 new_results.append(bucket_map[bucket])
             i += diff
diff --git a/src/sentry/static/sentry/app/components/charts/baseChart.jsx b/src/sentry/static/sentry/app/components/charts/baseChart.jsx
index 864b469cbc..e9e012fcf7 100644
--- a/src/sentry/static/sentry/app/components/charts/baseChart.jsx
+++ b/src/sentry/static/sentry/app/components/charts/baseChart.jsx
@@ -348,13 +348,12 @@ const ChartContainer = styled('div')`
   .tooltip-arrow {
     top: 100%;
     left: 50%;
-    border: solid transparent;
+    border: 0px solid transparent;
     content: ' ';
     height: 0;
     width: 0;
     position: absolute;
     pointer-events: none;
-    border-color: transparent;
     border-top-color: ${theme.gray5};
     border-width: 8px;
     margin-left: -8px;
diff --git a/src/sentry/static/sentry/app/views/performance/transactionSummary/latencyChart.tsx b/src/sentry/static/sentry/app/views/performance/transactionSummary/latencyChart.tsx
index a7e30d6a6e..f85671f857 100644
--- a/src/sentry/static/sentry/app/views/performance/transactionSummary/latencyChart.tsx
+++ b/src/sentry/static/sentry/app/views/performance/transactionSummary/latencyChart.tsx
@@ -26,6 +26,7 @@ import space from 'app/styles/space';
 import theme from 'app/utils/theme';
 import {getDuration} from 'app/utils/formatters';
 
+const NUM_BUCKETS = 15;
 const QUERY_KEYS = [
   'environment',
   'project',
@@ -50,6 +51,7 @@ type Props = AsyncComponent['props'] &
 
 type State = AsyncComponent['state'] & {
   chartData: {data: ApiResult[]} | null;
+  zoomError?: boolean;
 };
 
 /**
@@ -71,7 +73,7 @@ class LatencyHistogram extends AsyncComponent<Props, State> {
       id: '',
       name: '',
       version: 2,
-      fields: ['histogram(transaction.duration,15)', 'count()'],
+      fields: [`histogram(transaction.duration,${NUM_BUCKETS})`, 'count()'],
       orderby: 'histogram_transaction_duration_15',
       projects: project,
       range: statsPeriod,
@@ -101,24 +103,31 @@ class LatencyHistogram extends AsyncComponent<Props, State> {
     return !isEqual(pick(prevProps, QUERY_KEYS), pick(this.props, QUERY_KEYS));
   }
 
+  handleMouseOver = () => {
+    // Hide the zoom error tooltip on the next hover.
+    if (this.state.zoomError) {
+      this.setState({zoomError: false});
+    }
+  };
+
   handleClick = value => {
     const {chartData} = this.state;
     if (chartData === null) {
       return;
     }
     const {location} = this.props;
-
-    // Only bars that are 'active' will have itemStyle set.
-    // See transformData()
-    const isActive = value.data.hasOwnProperty('itemStyle');
     const valueIndex = value.dataIndex;
 
     // If the active bar is clicked again we need to remove the constraints.
-    const startDuration = isActive
-      ? undefined
-      : chartData.data[valueIndex].histogram_transaction_duration_15;
-    const endDuration =
-      typeof startDuration === 'number' ? startDuration + this.bucketWidth : undefined;
+    const startDuration = chartData.data[valueIndex].histogram_transaction_duration_15;
+    const endDuration = startDuration + this.bucketWidth;
+    // Re-render showing a zoom error above the current bar.
+    if ((endDuration - startDuration) / NUM_BUCKETS < 0.6) {
+      this.setState({
+        zoomError: true,
+      });
+      return;
+    }
 
     const target = {
       pathname: location.pathname,
@@ -159,11 +168,10 @@ class LatencyHistogram extends AsyncComponent<Props, State> {
   }
 
   renderBody() {
-    const {chartData} = this.state;
+    const {chartData, zoomError} = this.state;
     if (chartData === null) {
       return null;
     }
-    const {location} = this.props;
     const xAxis = {
       type: 'category',
       truncate: true,
@@ -176,15 +184,50 @@ class LatencyHistogram extends AsyncComponent<Props, State> {
       },
     };
 
+    // Use a custom tooltip formatter as we need to replace
+    // the tooltip content entirely when zooming is no longer available.
+    const tooltip = {
+      formatter(series) {
+        const seriesData = Array.isArray(series) ? series : [series];
+        let contents: string[] = [];
+        if (!zoomError) {
+          // Replicate the necessary logic from app/components/charts/components/tooltip.jsx
+          contents = seriesData.map(item => {
+            const label = item.seriesName;
+            const value = item.value[1].toLocaleString();
+            return [
+              '<div class="tooltip-series">',
+              `<div><span class="tooltip-label">${item.marker} <strong>${label}</strong></span> ${value}</div>`,
+              '</div>',
+            ].join('');
+          });
+          const seriesLabel = seriesData[0].value[0];
+          contents.push(`<div class="tooltip-date">${seriesLabel}</div>`);
+        } else {
+          contents = [
+            '<div class="tooltip-series tooltip-series-solo">',
+            t('You cannot zoom in any further'),
+            '</div>',
+          ];
+        }
+        contents.push('<div class="tooltip-arrow"></div>');
+        return contents.join('');
+      },
+    };
+
     return (
-      <BarChart
-        grid={{left: '24px', right: '24px', top: '32px', bottom: '16px'}}
-        xAxis={xAxis}
-        yAxis={{type: 'value'}}
-        series={transformData(chartData.data, location, this.bucketWidth)}
-        colors={['rgba(140, 79, 189, 0.3)']}
-        onClick={this.handleClick}
-      />
+      <React.Fragment>
+        <BarChart
+          grid={{left: '24px', right: '24px', top: '32px', bottom: '16px'}}
+          xAxis={xAxis}
+          yAxis={{type: 'value'}}
+          series={transformData(chartData.data, this.bucketWidth)}
+          tooltip={tooltip}
+          colors={['rgba(140, 79, 189, 0.3)']}
+          onClick={this.handleClick}
+          onMouseOver={this.handleMouseOver}
+        />
+      </React.Fragment>
     );
   }
 }
@@ -232,24 +275,14 @@ function LatencyChart({totalValues, ...props}: WrapperProps) {
 /**
  * Convert a discover response into a barchart compatible series
  */
-function transformData(data: ApiResult[], location: Location, bucketWidth: number) {
+function transformData(data: ApiResult[], bucketWidth: number) {
   const seriesData = data.map(item => {
     const bucket = item.histogram_transaction_duration_15;
-    const midPoint = Math.ceil(bucket + bucketWidth / 2);
-    const value: any = {
+    const midPoint = bucketWidth > 1 ? Math.ceil(bucket + bucketWidth / 2) : bucket;
+    return {
       value: item.count,
       name: getDuration(midPoint / 1000, 2, true),
     };
-    if (
-      location.query.startDuration &&
-      typeof location.query.startDuration === 'string'
-    ) {
-      const start = parseInt(location.query.startDuration, 10);
-      if (bucket >= start && bucket < start + bucketWidth) {
-        value.itemStyle = {color: theme.purpleLight};
-      }
-    }
-    return value;
   });
 
   return [
diff --git a/src/sentry/static/sentry/app/views/performance/transactionSummary/table.tsx b/src/sentry/static/sentry/app/views/performance/transactionSummary/table.tsx
index 50d6c087a0..c03d4e710e 100644
--- a/src/sentry/static/sentry/app/views/performance/transactionSummary/table.tsx
+++ b/src/sentry/static/sentry/app/views/performance/transactionSummary/table.tsx
@@ -21,7 +21,7 @@ import {
   generateEventSlug,
   eventDetailsRouteWithEventView,
 } from 'app/views/eventsV2/eventDetails/utils';
-import {tokenizeSearch, stringifyQueryObject} from 'app/utils/tokenizeSearch';
+import {tokenizeSearch} from 'app/utils/tokenizeSearch';
 
 import {
   TableGrid,
@@ -162,14 +162,9 @@ class SummaryContentTable extends React.Component<Props> {
     const {eventView, location, organization, totalValues} = this.props;
 
     let title = t('Slowest Requests');
-    let chartQuery = eventView.query;
-    if (location.query.startDuration || location.query.endDuration) {
-      // Remove duration conditions from the chart query as we want it
-      // to always reflect the full dataset.
-      const parsed = tokenizeSearch(chartQuery);
+    const parsed = tokenizeSearch(eventView.query);
+    if (parsed['transaction.duration']) {
       title = t('Requests %s and %s in duration', ...parsed['transaction.duration']);
-      delete parsed['transaction.duration'];
-      chartQuery = stringifyQueryObject(parsed);
     }
 
     return (
@@ -177,7 +172,7 @@ class SummaryContentTable extends React.Component<Props> {
         <LatencyChart
           organization={organization}
           location={location}
-          query={chartQuery}
+          query={eventView.query}
           project={eventView.project}
           environment={eventView.environment}
           start={eventView.start}
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index 167fe349f6..145f6bfd10 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1502,13 +1502,13 @@ class ResolveFieldListTest(unittest.TestCase):
         )
 
     def test_histogram_function(self):
-        fields = ["histogram(transaction.duration, 10, 1000)", "count()"]
+        fields = ["histogram(transaction.duration, 10, 1000, 0)", "count()"]
         result = resolve_field_list(fields, eventstore.Filter())
         assert result["selected_columns"] == [
             [
                 "multiply",
                 [["floor", [["divide", ["transaction.duration", 1000]]]], 1000],
-                "histogram_transaction_duration_10_1000",
+                "histogram_transaction_duration_10_1000_0",
             ]
         ]
         assert result["aggregations"] == [
@@ -1517,26 +1517,26 @@ class ResolveFieldListTest(unittest.TestCase):
             ["argMax", ["project.id", "timestamp"], "projectid"],
             ["transform(projectid, array(), array(), '')", None, "project.name"],
         ]
-        assert result["groupby"] == ["histogram_transaction_duration_10_1000"]
+        assert result["groupby"] == ["histogram_transaction_duration_10_1000_0"]
 
         with pytest.raises(InvalidSearchQuery) as err:
-            fields = ["histogram(stack.colno, 10, 1000)"]
+            fields = ["histogram(stack.colno, 10, 1000, 0)"]
             resolve_field_list(fields, eventstore.Filter())
         assert (
-            "histogram(stack.colno, 10, 1000): column argument invalid: stack.colno is not a duration column"
+            "histogram(stack.colno, 10, 1000, 0): column argument invalid: stack.colno is not a duration column"
             in six.text_type(err)
         )
 
         with pytest.raises(InvalidSearchQuery) as err:
             fields = ["histogram(transaction.duration, 10)"]
             resolve_field_list(fields, eventstore.Filter())
-        assert "histogram(transaction.duration, 10): expected 3 arguments" in six.text_type(err)
+        assert "histogram(transaction.duration, 10): expected 4 arguments" in six.text_type(err)
 
         with pytest.raises(InvalidSearchQuery) as err:
-            fields = ["histogram(transaction.duration, 1000, 1000)"]
+            fields = ["histogram(transaction.duration, 1000, 1000, 0)"]
             resolve_field_list(fields, eventstore.Filter())
         assert (
-            "histogram(transaction.duration, 1000, 1000): num_buckets argument invalid: 1000 must be less than 500"
+            "histogram(transaction.duration, 1000, 1000, 0): num_buckets argument invalid: 1000 must be less than 500"
             in six.text_type(err)
         )
 
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index f3f931f1df..f2cc7a0132 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -1114,10 +1114,10 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_translations(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
-                "data": [{"histogram_transaction_duration_10_1000": 1000, "count": 1123}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
+                "data": [{"histogram_transaction_duration_10_1000_0": 1000, "count": 1123}],
             },
         ]
         discover.query(
@@ -1132,7 +1132,7 @@ class QueryTransformTest(TestCase):
                 [
                     "multiply",
                     [["floor", [["divide", ["duration", 1000]]]], 1000],
-                    "histogram_transaction_duration_10_1000",
+                    "histogram_transaction_duration_10_1000_0",
                 ]
             ],
             aggregations=[
@@ -1149,7 +1149,7 @@ class QueryTransformTest(TestCase):
             ],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
-            groupby=["histogram_transaction_duration_10_1000"],
+            groupby=["histogram_transaction_duration_10_1000_0"],
             conditions=[],
             end=None,
             start=None,
@@ -1163,10 +1163,10 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_bad_histogram_translations(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
-                "data": [{"histogram_transaction_duration_10_1000": 1000, "count": 1123}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
+                "data": [{"histogram_transaction_duration_10_1000_0": 1000, "count": 1123}],
             },
         ]
         with pytest.raises(InvalidSearchQuery) as err:
@@ -1207,13 +1207,68 @@ class QueryTransformTest(TestCase):
             in six.text_type(err)
         )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_histogram_zerofill_narrow_range(self, mock_query):
+        mock_query.side_effect = [
+            {"data": [{"max_transaction.duration": 505, "min_transaction.duration": 490}]},
+            {
+                "meta": [{"name": "histogram_transaction_duration_15_1_490"}, {"name": "count"}],
+                "data": [
+                    {"histogram_transaction_duration_15_1_490": 490, "count": 1},
+                    {"histogram_transaction_duration_15_1_490": 492, "count": 2},
+                    {"histogram_transaction_duration_15_1_490": 500, "count": 4},
+                    {"histogram_transaction_duration_15_1_490": 501, "count": 3},
+                ],
+            },
+        ]
+        results = discover.query(
+            selected_columns=["histogram(transaction.duration, 15)", "count()"],
+            query="",
+            params={"project_id": [self.project.id]},
+            orderby="histogram_transaction_duration_15",
+            auto_fields=True,
+            use_aggregate_conditions=False,
+        )
+        expected = (1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 4, 3, 0, 0, 0, 0)
+        for result, exp in zip(results["data"], expected):
+            assert result["count"] == exp
+
+    @patch("sentry.snuba.discover.raw_query")
+    def test_histogram_zerofill_uneven_start_end(self, mock_query):
+        # the start end values don't align well with bucket boundaries.
+        mock_query.side_effect = [
+            {"data": [{"max_transaction.duration": 507, "min_transaction.duration": 392}]},
+            {
+                "meta": [{"name": "histogram_transaction_duration_10_12_384"}, {"name": "count"}],
+                "data": [
+                    {"histogram_transaction_duration_10_12_384": 396, "count": 1},
+                    {"histogram_transaction_duration_10_12_384": 420, "count": 2},
+                    {"histogram_transaction_duration_10_12_384": 456, "count": 4},
+                    {"histogram_transaction_duration_10_12_384": 492, "count": 3},
+                ],
+            },
+        ]
+        results = discover.query(
+            selected_columns=["histogram(transaction.duration, 10)", "count()"],
+            query="",
+            params={"project_id": [self.project.id]},
+            orderby="histogram_transaction_duration_10",
+            auto_fields=True,
+            use_aggregate_conditions=False,
+        )
+        data = results["data"]
+        assert len(data) == 10, data
+        expected = (0, 1, 0, 2, 0, 0, 4, 0, 0, 3)
+        for result, exp in zip(data, expected):
+            assert result["count"] == exp
+
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_zerofill_empty_results(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
-                "data": [{"histogram_transaction_duration_10_1000": 10000, "count": 1}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
+                "data": [{"histogram_transaction_duration_10_1000_0": 10000, "count": 1}],
             },
         ]
 
@@ -1233,11 +1288,11 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_zerofill_full_results(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
                 "data": [
-                    {"histogram_transaction_duration_10_1000": i * 1000, "count": i}
+                    {"histogram_transaction_duration_10_1000_0": i * 1000, "count": i}
                     for i in range(11)
                 ],
             },
@@ -1260,11 +1315,11 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_zerofill_missing_results_asc_sort(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
                 "data": [
-                    {"histogram_transaction_duration_10_1000": i * 1000, "count": i}
+                    {"histogram_transaction_duration_10_1000_0": i * 1000, "count": i}
                     for i in range(0, 11, 2)
                 ],
             },
@@ -1289,11 +1344,11 @@ class QueryTransformTest(TestCase):
         seed = range(0, 11, 2)
         seed.reverse()
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
                 "data": [
-                    {"histogram_transaction_duration_10_1000": i * 1000, "count": i} for i in seed
+                    {"histogram_transaction_duration_10_1000_0": i * 1000, "count": i} for i in seed
                 ],
             },
         ]
@@ -1316,11 +1371,11 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_zerofill_missing_results_no_sort(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 10000}]},
+            {"data": [{"max_transaction.duration": 10000, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_1000"}, {"name": "count"}],
+                "meta": [{"name": "histogram_transaction_duration_10_1000_0"}, {"name": "count"}],
                 "data": [
-                    {"histogram_transaction_duration_10_1000": i * 1000, "count": i}
+                    {"histogram_transaction_duration_10_1000_0": i * 1000, "count": i}
                     for i in range(0, 10, 2)
                 ],
             },
@@ -1347,11 +1402,11 @@ class QueryTransformTest(TestCase):
     @patch("sentry.snuba.discover.raw_query")
     def test_histogram_zerofill_on_weird_bucket(self, mock_query):
         mock_query.side_effect = [
-            {"data": [{"max_transaction.duration": 869}]},
+            {"data": [{"max_transaction.duration": 869, "min_transaction.duration": 0}]},
             {
-                "meta": [{"name": "histogram_transaction_duration_10_87"}, {"name": "count"}],
+                "meta": [{"name": "histogram_transaction_duration_10_87_0"}, {"name": "count"}],
                 "data": [
-                    {"histogram_transaction_duration_10_87": i * 87, "count": i}
+                    {"histogram_transaction_duration_10_87_0": i * 87, "count": i}
                     for i in range(1, 10, 2)
                 ],
             },
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index 0c1909cd87..67ef534332 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -4,6 +4,7 @@ import six
 import pytest
 import random
 from datetime import timedelta
+from math import ceil
 
 from django.core.urlresolvers import reverse
 
@@ -2202,15 +2203,18 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         project = self.create_project()
         start = before_now(minutes=2).replace(microsecond=0)
         latencies = [
-            (1, 999, 5),
-            (1000, 1999, 4),
-            (3000, 3999, 3),
-            (6000, 6999, 2),
+            (1, 500, 5),
+            (1000, 1500, 4),
+            (3000, 3500, 3),
+            (6000, 6500, 2),
             (10000, 10000, 1),  # just to make the math easy
         ]
+        values = []
         for bucket in latencies:
             for i in range(bucket[2]):
+                # Don't generate a wide range of variance as the buckets can mis-align.
                 milliseconds = random.randint(bucket[0], bucket[1])
+                values.append(milliseconds)
                 data = load_data("transaction")
                 data["transaction"] = "/error_rate/{}".format(milliseconds)
                 data["timestamp"] = iso_format(start)
@@ -2229,22 +2233,22 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
                     "sort": "histogram_transaction_duration_10",
                 },
             )
-
         assert response.status_code == 200, response.content
         data = response.data["data"]
         assert len(data) == 11
+        bucket_size = ceil((max(values) - min(values)) / 10.0)
         expected = [
             (0, 5),
-            (1000, 4),
-            (2000, 0),
-            (3000, 3),
-            (4000, 0),
-            (5000, 0),
-            (6000, 2),
-            (7000, 0),
-            (8000, 0),
-            (9000, 0),
-            (10000, 1),
+            (bucket_size, 4),
+            (bucket_size * 2, 0),
+            (bucket_size * 3, 3),
+            (bucket_size * 4, 0),
+            (bucket_size * 5, 0),
+            (bucket_size * 6, 2),
+            (bucket_size * 7, 0),
+            (bucket_size * 8, 0),
+            (bucket_size * 9, 0),
+            (bucket_size * 10, 1),
         ]
         for idx, datum in enumerate(data):
             assert datum["histogram_transaction_duration_10"] == expected[idx][0]
@@ -2255,15 +2259,17 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         project = self.create_project()
         start = before_now(minutes=2).replace(microsecond=0)
         latencies = [
-            (1, 999, 5),
-            (1000, 1999, 4),
-            (3000, 3999, 3),
-            (6000, 6999, 2),
+            (1, 500, 5),
+            (1000, 1500, 4),
+            (3000, 3500, 3),
+            (6000, 6500, 2),
             (10000, 10000, 1),  # just to make the math easy
         ]
+        values = []
         for bucket in latencies:
             for i in range(bucket[2]):
                 milliseconds = random.randint(bucket[0], bucket[1])
+                values.append(milliseconds)
                 data = load_data("transaction")
                 data["transaction"] = "/error_rate/sleepy_gary/{}".format(milliseconds)
                 data["timestamp"] = iso_format(start)
@@ -2294,18 +2300,19 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert response.status_code == 200, response.content
         data = response.data["data"]
         assert len(data) == 11
+        bucket_size = ceil((max(values) - min(values)) / 10.0)
         expected = [
             (0, 5),
-            (1000, 4),
-            (2000, 0),
-            (3000, 3),
-            (4000, 0),
-            (5000, 0),
-            (6000, 2),
-            (7000, 0),
-            (8000, 0),
-            (9000, 0),
-            (10000, 1),
+            (bucket_size, 4),
+            (bucket_size * 2, 0),
+            (bucket_size * 3, 3),
+            (bucket_size * 4, 0),
+            (bucket_size * 5, 0),
+            (bucket_size * 6, 2),
+            (bucket_size * 7, 0),
+            (bucket_size * 8, 0),
+            (bucket_size * 9, 0),
+            (bucket_size * 10, 1),
         ]
         for idx, datum in enumerate(data):
             assert datum["histogram_transaction_duration_10"] == expected[idx][0]
