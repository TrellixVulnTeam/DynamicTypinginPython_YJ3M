commit 98aba252024a0136701d23b96b9260eea8d10d09
Author: Anton Ovchinnikov <anton@tonyo.info>
Date:   Tue May 5 15:14:50 2020 +0200

    ref(processing): Remove old symbolication path (#18546)
    
    * ref(processing): Remove old symbolication path
    
    * Update tests

diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index eeb14fd956..b7f766b025 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -66,14 +66,7 @@ def should_process(data):
 
 
 def submit_process(
-    project,
-    from_reprocessing,
-    cache_key,
-    event_id,
-    start_time,
-    data,
-    data_has_changed=None,
-    new_process_behavior=None,
+    project, from_reprocessing, cache_key, event_id, start_time, data, data_has_changed=None,
 ):
     task = process_event_from_reprocessing if from_reprocessing else process_event
     task.delay(
@@ -81,7 +74,6 @@ def submit_process(
         start_time=start_time,
         event_id=event_id,
         data_has_changed=data_has_changed,
-        new_process_behavior=new_process_behavior,
     )
 
 
@@ -126,12 +118,7 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_task, pr
 
     from_reprocessing = process_task is process_event_from_reprocessing
 
-    new_process_behavior = bool(options.get("sentry:preprocess-use-new-behavior", False))
-    metrics.incr(
-        "tasks.store.preprocess_event.new_process_behavior", tags={"value": new_process_behavior}
-    )
-
-    if new_process_behavior and should_process_with_symbolicator(data):
+    if should_process_with_symbolicator(data):
         submit_symbolicate(
             project, from_reprocessing, cache_key, event_id, start_time, original_data
         )
@@ -146,7 +133,6 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_task, pr
             start_time,
             original_data,
             data_has_changed=False,
-            new_process_behavior=new_process_behavior,
         )
         return
 
@@ -271,7 +257,6 @@ def _do_symbolicate_event(cache_key, start_time, event_id, symbolicate_task, dat
         process_task=process_task,
         data=data,
         data_has_changed=has_changed,
-        new_process_behavior=True,
         from_symbolicate=True,
     )
 
@@ -370,7 +355,6 @@ def _do_process_event(
     process_task,
     data=None,
     data_has_changed=None,
-    new_process_behavior=None,
     from_symbolicate=False,
 ):
     from sentry.plugins.base import plugins
@@ -395,74 +379,25 @@ def _do_process_event(
     project = Project.objects.get_from_cache(id=project_id)
 
     has_changed = bool(data_has_changed)
-    new_process_behavior = bool(new_process_behavior)
-
-    metrics.incr(
-        "tasks.store.process_event.new_process_behavior", tags={"value": new_process_behavior}
-    )
 
     # Fetch the reprocessing revision
     reprocessing_rev = reprocessing.get_reprocessing_revision(project_id)
 
-    try:
-        if not new_process_behavior:
-            # Event enhancers.  These run before anything else.
-            for plugin in plugins.all(version=2):
-                with metrics.timer(
-                    "tasks.store.process_event.enhancers",
-                    tags={"plugin": plugin.slug, "from_symbolicate": from_symbolicate},
-                ):
-                    enhancers = safe_execute(plugin.get_event_enhancers, data=data)
-                    for enhancer in enhancers or ():
-                        enhanced = safe_execute(
-                            enhancer, data, _passthrough_errors=(RetrySymbolication,)
-                        )
-                        if enhanced:
-                            data = enhanced
-                            has_changed = True
-
-        # Stacktrace based event processors.
-        with metrics.timer(
-            "tasks.store.process_event.stacktraces", tags={"from_symbolicate": from_symbolicate}
-        ):
-            new_data = process_stacktraces(data)
-        if new_data is not None:
-            has_changed = True
-            data = new_data
-    except RetrySymbolication as e:
-        if start_time and (time() - start_time) > settings.SYMBOLICATOR_PROCESS_EVENT_WARN_TIMEOUT:
-            error_logger.warning(
-                "process.slow", extra={"project_id": project_id, "event_id": event_id}
-            )
-
-        if start_time and (time() - start_time) > settings.SYMBOLICATOR_PROCESS_EVENT_HARD_TIMEOUT:
-            # Do not drop event but actually continue with rest of pipeline
-            # (persisting unsymbolicated event)
-            error_logger.exception(
-                "process.failed.infinite_retry",
-                extra={"project_id": project_id, "event_id": event_id},
-            )
-        else:
-            retry_process_event.apply_async(
-                args=(),
-                kwargs={
-                    "process_task_name": process_task.__name__,
-                    "task_kwargs": {
-                        "cache_key": cache_key,
-                        "event_id": event_id,
-                        "start_time": start_time,
-                    },
-                },
-                countdown=e.retry_after,
-            )
-            return
+    # Stacktrace based event processors.
+    with metrics.timer(
+        "tasks.store.process_event.stacktraces", tags={"from_symbolicate": from_symbolicate}
+    ):
+        new_data = process_stacktraces(data)
+    if new_data is not None:
+        has_changed = True
+        data = new_data
 
     # Second round of datascrubbing after stacktrace and language-specific
     # processing. First round happened as part of ingest.
     #
     # *Right now* the only sensitive data that is added in stacktrace
     # processing are usernames in filepaths, so we run directly after
-    # stacktrace processors and `get_event_enhancers`.
+    # stacktrace processors.
     #
     # We do not yet want to deal with context data produced by plugins like
     # sessionstack or fullstory (which are in `get_event_preprocessors`), as
@@ -557,14 +492,7 @@ def _do_process_event(
     time_limit=65,
     soft_time_limit=60,
 )
-def process_event(
-    cache_key,
-    start_time=None,
-    event_id=None,
-    data_has_changed=None,
-    new_process_behavior=None,
-    **kwargs
-):
+def process_event(cache_key, start_time=None, event_id=None, data_has_changed=None, **kwargs):
     """
     Handles event processing (for those events that need it)
 
@@ -581,7 +509,6 @@ def process_event(
         event_id=event_id,
         process_task=process_event,
         data_has_changed=data_has_changed,
-        new_process_behavior=new_process_behavior,
     )
 
 
diff --git a/tests/sentry/tasks/test_store.py b/tests/sentry/tasks/test_store.py
index a40b56b408..96d4aff122 100644
--- a/tests/sentry/tasks/test_store.py
+++ b/tests/sentry/tasks/test_store.py
@@ -3,7 +3,6 @@ from __future__ import absolute_import
 import pytest
 
 from sentry.utils.compat import mock
-from sentry import options
 from time import time
 
 from sentry import quotas
@@ -121,7 +120,6 @@ def test_move_to_symbolicate_event(
         "extra": {"foo": "bar"},
     }
 
-    options.set("sentry:preprocess-use-new-behavior", True)
     preprocess_event(data=data)
 
     assert mock_symbolicate_event.delay.call_count == 1
@@ -129,28 +127,6 @@ def test_move_to_symbolicate_event(
     assert mock_save_event.delay.call_count == 0
 
 
-@pytest.mark.django_db
-def test_move_to_symbolicate_event_old(
-    default_project, mock_process_event, mock_save_event, mock_symbolicate_event, register_plugin
-):
-    # Temporarily test old behavior
-    register_plugin(BasicPreprocessorPlugin)
-    data = {
-        "project": default_project.id,
-        "platform": "native",
-        "logentry": {"formatted": "test"},
-        "event_id": EVENT_ID,
-        "extra": {"foo": "bar"},
-    }
-
-    options.set("sentry:preprocess-use-new-behavior", False)
-    preprocess_event(data=data)
-
-    assert mock_symbolicate_event.delay.call_count == 0
-    assert mock_process_event.delay.call_count == 1
-    assert mock_save_event.delay.call_count == 0
-
-
 @pytest.mark.django_db
 def test_symbolicate_event_call_process_inline(
     default_project,
@@ -192,7 +168,6 @@ def test_symbolicate_event_call_process_inline(
         process_task=mock_process_event,
         data=symbolicated_data,
         data_has_changed=True,
-        new_process_behavior=True,
         from_symbolicate=True,
     )
 
@@ -344,16 +319,8 @@ def test_scrubbing_after_processing(
 ):
     @register_plugin
     class TestPlugin(Plugin2):
-        def get_event_enhancers(self, data):
-            def more_extra(data):
-                data["extra"]["aaa"] = "remove me"
-                return data
-
-            return [more_extra]
-
         def get_event_preprocessors(self, data):
-            # Right now we do not scrub data from event preprocessors, only
-            # from event enhancers.
+            # Right now we do not scrub data from event preprocessors
             def more_extra(data):
                 data["extra"]["aaa2"] = "event preprocessor"
                 return data
@@ -378,13 +345,15 @@ def test_scrubbing_after_processing(
         "platform": "python",
         "logentry": {"formatted": "test"},
         "event_id": EVENT_ID,
-        "extra": {},
+        "extra": {"aaa": "remove me"},
     }
 
     mock_default_cache.get.return_value = data
 
     with Feature({"organizations:datascrubbers-v2": True}):
-        process_event(cache_key="e:1", start_time=1)
+        # We pass data_has_changed=True to pretend that we've added "extra" attribute
+        # to "data" shortly before (e.g. during symbolication).
+        process_event(cache_key="e:1", start_time=1, data_has_changed=True)
 
     ((_, (key, event, duration), _),) = mock_default_cache.set.mock_calls
     assert key == "e:1"
