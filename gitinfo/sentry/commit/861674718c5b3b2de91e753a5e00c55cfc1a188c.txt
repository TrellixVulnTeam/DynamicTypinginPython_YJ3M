commit 861674718c5b3b2de91e753a5e00c55cfc1a188c
Author: ted kaemming <ted@kaemming.com>
Date:   Wed Jul 26 14:04:09 2017 -0700

    Accept multiple signatures/events for similarity index record and classify operations. (#5778)

diff --git a/bin/load-mocks b/bin/load-mocks
index b04a835af7..ea7d7785e0 100755
--- a/bin/load-mocks
+++ b/bin/load-mocks
@@ -67,7 +67,7 @@ def make_sentence(words=None):
 
 def create_sample_event(*args, **kwargs):
     event = _create_sample_event(*args, **kwargs)
-    features.record(event)
+    features.record([event])
     return event
 
 
diff --git a/src/sentry/receivers/similarity.py b/src/sentry/receivers/similarity.py
index c8e1b5ebcd..68f7621346 100644
--- a/src/sentry/receivers/similarity.py
+++ b/src/sentry/receivers/similarity.py
@@ -10,4 +10,4 @@ def record(project, group, event, **kwargs):
     if not feature_flags.has('projects:similarity-indexing', project):
         return
 
-    similarity_features.record(event)
+    similarity_features.record([event])
diff --git a/src/sentry/scripts/similarity/index.lua b/src/sentry/scripts/similarity/index.lua
index 74386610c4..206e7273e8 100644
--- a/src/sentry/scripts/similarity/index.lua
+++ b/src/sentry/scripts/similarity/index.lua
@@ -288,46 +288,52 @@ end
 
 -- Signature Matching
 
-local function parse_signatures(configuration, arguments)
-    --[[
-    Parses signatures from an argument table, collecting signatures until the
-    end of the table is reached. Signatures are expected to be an index name,
-    followed by the number of items specified by the `configuration.bands`
-    value. Signatures are returned as a table with an `index` key (string) and
-    a `buckets` key (table of strings).
-    ]]--
-    local entries = table.ireduce(
-        arguments,
-        function (state, token)
-            if state.active == nil then
-                -- When there is no active entry, we need to initialize
-                -- a new one. The first token is the index identifier.
-                state.active = {index = token, buckets = {}}
-            else
-                -- If there is an active entry, we need to add the
-                -- current token to the feature list.
-                table.insert(state.active.buckets, token)
-
-                -- When we've seen the same number of buckets as there
-                -- are bands, we're done recording and need to mark the
-                -- current entry as completed, and reset the current
-                -- active entry.
-                if #state.active.buckets == configuration.bands then
-                    table.insert(state.completed, state.active)
-                    state.active = nil
-                end
-            end
-            return state
-        end,
-        {active = nil, completed = {}}
-    )
+local function parse_band(configuration, arguments, cursor)
+    local result = {}
+
+    local count = tonumber(arguments[cursor])
+    cursor = cursor + 1
+
+    for i = 1, count do
+        result[arguments[cursor]] = tonumber(arguments[cursor + 1])
+        cursor = cursor + 2
+    end
+
+    return result, cursor
+end
+
+local function parse_signature(configuration, arguments, cursor)
+    local result = {}
+
+    result.index = arguments[cursor]
+    cursor = cursor + 1
 
-    -- If there are any entries in progress when we are completed, that
-    -- means the input was in an incorrect format and we should error
-    -- before we record any bad data.
-    assert(entries.active == nil, 'unexpected end of input')
+    for i = 1, configuration.bands do
+        result[i], cursor = parse_band(
+            configuration,
+            arguments,
+            cursor
+        )
+    end
 
-    return entries.completed
+    return result, cursor
+end
+
+local function parse_signatures(configuration, arguments, cursor)
+    local result = {}
+
+    local count = tonumber(arguments[cursor])
+    cursor = cursor + 1
+
+    for i = 1, count  do
+        result[i], cursor = parse_signature(
+            configuration,
+            arguments,
+            cursor
+        )
+    end
+
+    return result, cursor
 end
 
 local function fetch_candidates(configuration, time_series, index, frequencies)
@@ -492,7 +498,8 @@ local commands = {
             local key = arguments[1]
             local signatures = parse_signatures(
                 configuration,
-                table.slice(arguments, 2)
+                arguments,
+                2
             )
 
             local time = math.floor(configuration.timestamp / configuration.interval)
@@ -504,32 +511,34 @@ local commands = {
 
             return table.imap(
                 signatures,
-                function (entry)
+                function (signature)
                     local results = {}
 
-                    for band, bucket in ipairs(entry.buckets) do
-                        local bucket_membership_key = get_bucket_membership_key(
-                            configuration,
-                            entry.index,
-                            time,
-                            band,
-                            bucket
-                        )
-                        redis.call('SADD', bucket_membership_key, key)
-                        redis.call('EXPIREAT', bucket_membership_key, expiration)
+                    for band, buckets in ipairs(signature) do
+                        for bucket, count in pairs(buckets) do
+                            local bucket_membership_key = get_bucket_membership_key(
+                                configuration,
+                                signature.index,
+                                time,
+                                band,
+                                bucket
+                            )
+                            redis.call('SADD', bucket_membership_key, key)
+                            redis.call('EXPIREAT', bucket_membership_key, expiration)
 
-                        local bucket_frequency_key = get_bucket_frequency_key(
-                            configuration,
-                            entry.index,
-                            time,
-                            band,
-                            key
-                        )
-                        table.insert(
-                            results,
-                            tonumber(redis.call('HINCRBY', bucket_frequency_key, bucket, 1))
-                        )
-                        redis.call('EXPIREAT', bucket_frequency_key, expiration)
+                            local bucket_frequency_key = get_bucket_frequency_key(
+                                configuration,
+                                signature.index,
+                                time,
+                                band,
+                                key
+                            )
+                            table.insert(
+                                results,
+                                tonumber(redis.call('HINCRBY', bucket_frequency_key, bucket, count))
+                            )
+                            redis.call('EXPIREAT', bucket_frequency_key, expiration)
+                        end
                     end
 
                     return results
@@ -541,7 +550,8 @@ local commands = {
         function (configuration, arguments)
             local signatures = parse_signatures(
                 configuration,
-                arguments
+                arguments,
+                1
             )
             local time_series = get_active_indices(
                 configuration.interval,
@@ -556,14 +566,7 @@ local commands = {
                         configuration,
                         time_series,
                         signature.index,
-                        table.imap(
-                            signature.buckets,
-                            function (band)
-                                local item = {}
-                                item[band] = 1
-                                return item
-                            end
-                        )
+                        signature
                     )
 
                     -- Sort the results in descending order (most similar first.)
diff --git a/src/sentry/similarity/features.py b/src/sentry/similarity/features.py
index 6047cbe998..c3ad77e6fe 100644
--- a/src/sentry/similarity/features.py
+++ b/src/sentry/similarity/features.py
@@ -56,8 +56,10 @@ class MessageFeature(object):
 
 
 class FeatureSet(object):
-    def __init__(self, index, encoder, aliases, features,
-                 expected_extraction_errors, expected_encoding_errors):
+    def __init__(
+        self, index, encoder, aliases, features, expected_extraction_errors,
+        expected_encoding_errors
+    ):
         self.index = index
         self.encoder = encoder
         self.aliases = aliases
@@ -79,12 +81,8 @@ class FeatureSet(object):
                 results[label] = strategy.extract(event)
             except Exception as error:
                 log = (
-                    logger.debug
-                    if isinstance(error, self.expected_extraction_errors) else
-                    functools.partial(
-                        logger.warning,
-                        exc_info=True
-                    )
+                    logger.debug if isinstance(error, self.expected_extraction_errors) else
+                    functools.partial(logger.warning, exc_info=True)
                 )
                 log(
                     'Could not extract features from %r for %r due to error: %r',
@@ -95,69 +93,96 @@ class FeatureSet(object):
                 )
         return results
 
-    def record(self, event):
+    def record(self, events):
+        if not events:
+            return []
+
+        scope = None
+        key = None
+
         items = []
-        for label, features in self.extract(event).items():
-            try:
-                features = map(self.encoder.dumps, features)
-            except Exception as error:
-                log = (
-                    logger.debug if isinstance(error, self.expected_encoding_errors) else
-                    functools.partial(logger.warning, exc_info=True)
-                )
-                log(
-                    'Could not encode features from %r for %r due to error: %r',
-                    event,
-                    label,
-                    error,
-                )
-            else:
-                if features:
-                    items.append((self.aliases[label], features, ))
+        for event in events:
+            for label, features in self.extract(event).items():
+                if scope is None:
+                    scope = self.__get_scope(event.project)
+                else:
+                    assert self.__get_scope(
+                        event.project
+                    ) == scope, 'all events must be associated with the same project'
+
+                if key is None:
+                    key = self.__get_key(event.group)
+                else:
+                    assert self.__get_key(
+                        event.group
+                    ) == key, 'all events must be associated with the same group'
+
+                try:
+                    features = map(self.encoder.dumps, features)
+                except Exception as error:
+                    log = (
+                        logger.debug if isinstance(error, self.expected_encoding_errors) else
+                        functools.partial(logger.warning, exc_info=True)
+                    )
+                    log(
+                        'Could not encode features from %r for %r due to error: %r',
+                        event,
+                        label,
+                        error,
+                    )
+                else:
+                    if features:
+                        items.append((self.aliases[label], features, ))
+
         return self.index.record(
-            self.__get_scope(event.project),
-            self.__get_key(event.group),
+            scope,
+            key,
             items,
             timestamp=to_timestamp(event.datetime),
         )
 
-    def classify(self, event):
+    def classify(self, events):
+        if not events:
+            return []
+
+        scope = None
+
         items = []
-        for label, features in self.extract(event).items():
-            try:
-                features = map(self.encoder.dumps, features)
-            except Exception as error:
-                log = (
-                    logger.debug
-                    if isinstance(error, self.expected_encoding_errors) else
-                    functools.partial(
-                        logger.warning,
-                        exc_info=True
+        for event in events:
+            for label, features in self.extract(event).items():
+                if scope is None:
+                    scope = self.__get_scope(event.project)
+                else:
+                    assert self.__get_scope(
+                        event.project
+                    ) == scope, 'all events must be associated with the same project'
+
+                try:
+                    features = map(self.encoder.dumps, features)
+                except Exception as error:
+                    log = (
+                        logger.debug if isinstance(error, self.expected_encoding_errors) else
+                        functools.partial(logger.warning, exc_info=True)
                     )
-                )
-                log(
-                    'Could not encode features from %r for %r due to error: %r',
-                    event,
-                    label,
-                    error,
-                )
-            else:
-                if features:
-                    items.append((
-                        self.aliases[label],
-                        features,
-                    ))
-        results = self.index.classify(
-            self.__get_scope(event.project),
-            items,
-            timestamp=to_timestamp(event.datetime),
-        )
+                    log(
+                        'Could not encode features from %r for %r due to error: %r',
+                        event,
+                        label,
+                        error,
+                    )
+                else:
+                    if features:
+                        items.append((self.aliases[label], features, ))
         return zip(
             map(
                 lambda (alias, characteristics): self.aliases.get_key(alias),
                 items,
             ),
-            results,
+            self.index.classify(
+                scope,
+                items,
+                timestamp=to_timestamp(event.datetime),
+            ),
         )
 
     def compare(self, group):
diff --git a/src/sentry/similarity/index.py b/src/sentry/similarity/index.py
index 693ca7bf77..c883d06b50 100644
--- a/src/sentry/similarity/index.py
+++ b/src/sentry/similarity/index.py
@@ -2,6 +2,7 @@ from __future__ import absolute_import
 
 import itertools
 import time
+from collections import Counter, defaultdict
 
 from sentry.utils.iterators import chunked
 from sentry.utils.redis import load_script
@@ -27,6 +28,38 @@ class MinHashIndex(object):
         self.interval = interval
         self.retention = retention
 
+    def __build_signatures(self, items):
+        data = defaultdict(
+            lambda: [Counter() for _ in xrange(self.bands)],
+        )
+
+        for idx, features in items:
+            bands = map(
+                ','.join, band(
+                    self.bands,
+                    map(
+                        '{}'.format,
+                        self.signature_builder(features),
+                    ),
+                )
+            )
+
+            for i, bucket in enumerate(bands):
+                data[idx][i][bucket] += 1
+
+        arguments = [len(data)]
+        for idx, bands in data.items():
+            arguments.append(idx)
+            for buckets in bands:
+                arguments.append(len(buckets))
+                for bucket, count in buckets.items():
+                    arguments.extend([
+                        bucket,
+                        count,
+                    ])
+
+        return arguments
+
     def classify(self, scope, items, timestamp=None):
         if timestamp is None:
             timestamp = int(time.time())
@@ -41,18 +74,11 @@ class MinHashIndex(object):
             scope,
         ]
 
-        for idx, features in items:
-            arguments.append(idx)
-            arguments.extend([
-                ','.join(map('{}'.format, b))
-                for b in
-                band(self.bands, self.signature_builder(features))
-            ])
+        arguments.extend(self.__build_signatures(items))
 
         return [
             [(item, float(score)) for item, score in result]
-            for result in
-            index(
+            for result in index(
                 self.cluster.get_local_client_for_key(scope),
                 [],
                 arguments,
@@ -103,14 +129,7 @@ class MinHashIndex(object):
             key,
         ]
 
-        for idx, features in items:
-            arguments.append(idx)
-            arguments.extend(
-                [
-                    ','.join(map('{}'.format, b))
-                    for b in band(self.bands, self.signature_builder(features))
-                ]
-            )
+        arguments.extend(self.__build_signatures(items))
 
         return index(
             self.cluster.get_local_client_for_key(scope),
diff --git a/src/sentry/tasks/unmerge.py b/src/sentry/tasks/unmerge.py
index 4dd50b747f..98ba11f33e 100644
--- a/src/sentry/tasks/unmerge.py
+++ b/src/sentry/tasks/unmerge.py
@@ -256,10 +256,12 @@ def truncate_denormalizations(group):
         tsdb.models.users_affected_by_group,
     ], [group.id])
 
-    tsdb.delete_frequencies([
-        tsdb.models.frequent_releases_by_group,
-        tsdb.models.frequent_environments_by_group,
-    ], [group.id])
+    tsdb.delete_frequencies(
+        [
+            tsdb.models.frequent_releases_by_group,
+            tsdb.models.frequent_environments_by_group,
+        ], [group.id]
+    )
 
     features.delete(group)
 
@@ -458,7 +460,7 @@ def repair_denormalizations(caches, project, events):
     repair_tsdb_data(caches, project, events)
 
     for event in events:
-        features.record(event)
+        features.record([event])
 
 
 def update_tag_value_counts(id_list):
diff --git a/tests/sentry/similarity/test_index.py b/tests/sentry/similarity/test_index.py
index 0d25ea48b3..eac73f3220 100644
--- a/tests/sentry/similarity/test_index.py
+++ b/tests/sentry/similarity/test_index.py
@@ -29,8 +29,10 @@ class MinHashIndexTestCase(TestCase):
         self.index.record('example', '1', [('index', 'hello world')])
         self.index.record('example', '2', [('index', 'hello world')])
         self.index.record('example', '3', [('index', 'jello world')])
-        self.index.record('example', '4', [('index', 'yellow world')])
-        self.index.record('example', '4', [('index', 'mellow world')])
+        self.index.record('example', '4', [
+            ('index', 'yellow world'),
+            ('index', 'mellow world'),
+        ])
         self.index.record('example', '5', [('index', 'pizza world')])
 
         results = self.index.compare('example', '1', ['index'])[0]
diff --git a/tests/sentry/tasks/test_unmerge.py b/tests/sentry/tasks/test_unmerge.py
index c8e93c7789..677e9f84ce 100644
--- a/tests/sentry/tasks/test_unmerge.py
+++ b/tests/sentry/tasks/test_unmerge.py
@@ -237,7 +237,7 @@ class UnmergeTestCase(TestCase):
                 comments='Quack',
             )
 
-            features.record(event)
+            features.record([event])
 
             return event
 
@@ -283,7 +283,9 @@ class UnmergeTestCase(TestCase):
         )
 
         assert features.compare(source) == [
-            (source.id, {'message:message:character-shingles': 1.0}),
+            (source.id, {
+                'message:message:character-shingles': 1.0
+            }),
         ]
 
         with self.tasks():
@@ -622,7 +624,10 @@ class UnmergeTestCase(TestCase):
 
         destination_similar_items = features.compare(destination)
         assert destination_similar_items[0] == (
-            destination.id, {'message:message:character-shingles': 1.0})
+            destination.id, {
+                'message:message:character-shingles': 1.0
+            }
+        )
         assert destination_similar_items[1][0] == source.id
         assert destination_similar_items[1][1].keys() == ['message:message:character-shingles']
         assert destination_similar_items[1][1]['message:message:character-shingles'] < 1.0
