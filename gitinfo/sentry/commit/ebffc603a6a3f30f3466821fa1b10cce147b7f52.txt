commit ebffc603a6a3f30f3466821fa1b10cce147b7f52
Author: David Cramer <dcramer@gmail.com>
Date:   Mon Aug 21 18:01:21 2017 -0700

    dev: autoformat south/social_auth codebases

diff --git a/src/social_auth/backends/asana.py b/src/social_auth/backends/asana.py
index f685031ae1..64716f5c28 100644
--- a/src/social_auth/backends/asana.py
+++ b/src/social_auth/backends/asana.py
@@ -87,6 +87,7 @@ class AsanaAuth(BaseOAuth2):
         response.raise_for_status()
         return response.json()
 
+
 # Backend definition
 BACKENDS = {
     'asana': AsanaAuth,
diff --git a/src/social_auth/backends/github.py b/src/social_auth/backends/github.py
index 898ef94381..b8ad6e6c31 100644
--- a/src/social_auth/backends/github.py
+++ b/src/social_auth/backends/github.py
@@ -128,6 +128,7 @@ class GithubAuth(BaseOAuth2):
                                      'organization')
         return data
 
+
 # Backend definition
 BACKENDS = {
     'github': GithubAuth,
diff --git a/src/social_auth/backends/slack.py b/src/social_auth/backends/slack.py
index a21591bb6a..90c6df4396 100644
--- a/src/social_auth/backends/slack.py
+++ b/src/social_auth/backends/slack.py
@@ -66,6 +66,7 @@ class SlackAuth(BaseOAuth2):
         response.raise_for_status()
         return response.json()
 
+
 # Backend definition
 BACKENDS = {
     'slack': SlackAuth,
diff --git a/src/south/creator/actions.py b/src/south/creator/actions.py
index 2ffc8ca19f..35b9a0141a 100644
--- a/src/south/creator/actions.py
+++ b/src/south/creator/actions.py
@@ -22,60 +22,61 @@ class Action(object):
     Generic base Action class. Contains utility methods for inserting into
     the forwards() and backwards() method lists.
     """
-    
+
     prepend_forwards = False
     prepend_backwards = False
-    
+
     def forwards_code(self):
         raise NotImplementedError
-    
+
     def backwards_code(self):
         raise NotImplementedError
-    
+
     def add_forwards(self, forwards):
         if self.prepend_forwards:
             forwards.insert(0, self.forwards_code())
         else:
             forwards.append(self.forwards_code())
-    
+
     def add_backwards(self, backwards):
         if self.prepend_backwards:
             backwards.insert(0, self.backwards_code())
         else:
             backwards.append(self.backwards_code())
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         raise NotImplementedError
-    
+
     @classmethod
     def triples_to_defs(cls, fields):
         # Turn the (class, args, kwargs) format into a string
         for field, triple in fields.items():
             fields[field] = cls.triple_to_def(triple)
         return fields
-    
+
     @classmethod
     def triple_to_def(cls, triple):
         "Turns a single triple into a definition."
         return "self.gf(%r)(%s)" % (
-            triple[0], # Field full path
-            ", ".join(triple[1] + ["%s=%s" % (kwd, val) for kwd, val in triple[2].items()]), # args and kwds
+            triple[0],  # Field full path
+            ", ".join(triple[1] + ["%s=%s" % (kwd, val)
+                                   for kwd, val in triple[2].items()]),  # args and kwds
         )
-    
-    
+
+
 class AddModel(Action):
     """
     Addition of a model. Takes the Model subclass that is being created.
     """
-    
+
     FORWARDS_TEMPLATE = '''
         # Adding model '%(model_name)s'
         db.create_table(%(table_name)r, (
             %(field_defs)s
         ))
         db.send_create_signal(%(app_label)r, [%(model_name)r])'''[1:] + "\n"
-    
+
     BACKWARDS_TEMPLATE = '''
         # Deleting model '%(model_name)s'
         db.delete_table(%(table_name)r)'''[1:] + "\n"
@@ -83,11 +84,11 @@ class AddModel(Action):
     def __init__(self, model, model_def):
         self.model = model
         self.model_def = model_def
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " + Added model %s.%s" % (
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
 
@@ -97,7 +98,7 @@ class AddModel(Action):
             "(%r, %s)" % (name, defn) for name, defn
             in self.triples_to_defs(self.model_def).items()
         ]) + ","
-        
+
         return self.FORWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
@@ -111,17 +112,17 @@ class AddModel(Action):
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
         }
-    
-    
+
+
 class DeleteModel(AddModel):
     """
     Deletion of a model. Takes the Model subclass that is being created.
     """
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " - Deleted model %s.%s" % (
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
 
@@ -143,7 +144,7 @@ class _NullIssuesField(object):
     IRREVERSIBLE_TEMPLATE = '''
         # User chose to not deal with backwards NULL issues for '%(model_name)s.%(field_name)s'
         raise RuntimeError("Cannot reverse this migration. '%(model_name)s.%(field_name)s' and its values cannot be restored.")
-        
+
         # The following code is provided here to aid in writing a correct migration'''
 
     def deal_with_not_null_no_default(self, field, field_def):
@@ -158,7 +159,8 @@ class _NullIssuesField(object):
         ))
         print(" ? Since you are %s, you MUST specify a default" % self.null_reason)
         print(" ? value to use for existing rows. Would you like to:")
-        print(" ?  1. Quit now"+("." if self.issue_with_backward_migration else ", and add a default to the field in models.py" ))
+        print(" ?  1. Quit now" +
+              ("." if self.issue_with_backward_migration else ", and add a default to the field in models.py"))
         print(" ?  2. Specify a one-off value to use for existing columns now")
         if self.issue_with_backward_migration:
             print(" ?  3. Disable the backwards migration by raising an exception; you can edit the migration to fix it later")
@@ -204,34 +206,34 @@ class _NullIssuesField(object):
             "field_name": field.name,
             "field_column": field.column,
         }
-    
-    
+
+
 class AddField(Action, _NullIssuesField):
     """
     Adds a field to a model. Takes a Model class and the field name.
     """
 
     null_reason = "adding this field"
-    
+
     FORWARDS_TEMPLATE = '''
         # Adding field '%(model_name)s.%(field_name)s'
         db.add_column(%(table_name)r, %(field_name)r,
                       %(field_def)s,
                       keep_default=False)'''[1:] + "\n"
-    
+
     BACKWARDS_TEMPLATE = '''
         # Deleting field '%(model_name)s.%(field_name)s'
         db.delete_column(%(table_name)r, %(field_column)r)'''[1:] + "\n"
-    
+
     def __init__(self, model, field, field_def):
         self.model = model
         self.field = field
         self.field_def = field_def
-        
+
         # See if they've made a NOT NULL column but also have no default (far too common)
         is_null = self.field.null
         default = (self.field.default is not None) and (self.field.default is not NOT_PROVIDED)
-        
+
         if not is_null and not default:
             self.deal_with_not_null_no_default(self.field, self.field_def)
 
@@ -242,9 +244,9 @@ class AddField(Action, _NullIssuesField):
             self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
-        
+
         return self.FORWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
@@ -260,8 +262,8 @@ class AddField(Action, _NullIssuesField):
             "field_name": self.field.name,
             "field_column": self.field.column,
         }
-    
-    
+
+
 class DeleteField(AddField):
     """
     Removes a field from a model. Takes a Model class and the field name.
@@ -274,10 +276,10 @@ class DeleteField(AddField):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " - Deleted field %s on %s.%s" % (
             self.field.name,
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
         return AddField.backwards_code(self)
 
@@ -294,15 +296,15 @@ class ChangeField(Action, _NullIssuesField):
     """
 
     null_reason = "making this field non-nullable"
-    
+
     FORWARDS_TEMPLATE = BACKWARDS_TEMPLATE = '''
         # Changing field '%(model_name)s.%(field_name)s'
         db.alter_column(%(table_name)r, %(field_column)r, %(field_def)s)'''
-    
+
     RENAME_TEMPLATE = '''
         # Renaming column for '%(model_name)s.%(field_name)s' to match new field type.
         db.rename_column(%(table_name)r, %(old_column)r, %(new_column)r)'''
-    
+
     def __init__(self, model, old_field, new_field, old_def, new_def):
         self.model = model
         self.old_field = old_field
@@ -311,27 +313,31 @@ class ChangeField(Action, _NullIssuesField):
         self.new_def = new_def
 
         # See if they've changed a not-null field to be null
-        new_default = (self.new_field.default is not None) and (self.new_field.default is not NOT_PROVIDED)
-        old_default = (self.old_field.default is not None) and (self.old_field.default is not NOT_PROVIDED)
+        new_default = (
+            self.new_field.default is not None) and (
+            self.new_field.default is not NOT_PROVIDED)
+        old_default = (
+            self.old_field.default is not None) and (
+            self.old_field.default is not NOT_PROVIDED)
         if self.old_field.null and not self.new_field.null and not new_default:
             self.deal_with_not_null_no_default(self.new_field, self.new_def)
         if not self.old_field.null and self.new_field.null and not old_default:
             self.null_reason = "making this field nullable"
             self.issue_with_backward_migration = True
             self.deal_with_not_null_no_default(self.old_field, self.old_def)
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " ~ Changed field %s on %s.%s" % (
             self.new_field.name,
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def _code(self, old_field, new_field, new_def):
-        
+
         output = ""
-        
+
         if self.old_field.column != self.new_field.column:
             output += self.RENAME_TEMPLATE % {
                 "model_name": self.model._meta.object_name,
@@ -340,7 +346,7 @@ class ChangeField(Action, _NullIssuesField):
                 "old_column": old_field.column,
                 "new_column": new_field.column,
             }
-        
+
         output += self.FORWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
@@ -348,7 +354,7 @@ class ChangeField(Action, _NullIssuesField):
             "field_column": new_field.column,
             "field_def": self.triple_to_def(new_def),
         }
-        
+
         return output
 
     def forwards_code(self):
@@ -366,36 +372,36 @@ class AddUnique(Action):
     """
     Adds a unique constraint to a model. Takes a Model class and the field names.
     """
-    
+
     FORWARDS_TEMPLATE = '''
         # Adding unique constraint on '%(model_name)s', fields %(field_names)s
         db.create_unique(%(table_name)r, %(fields)r)'''[1:] + "\n"
-    
+
     BACKWARDS_TEMPLATE = '''
         # Removing unique constraint on '%(model_name)s', fields %(field_names)s
         db.delete_unique(%(table_name)r, %(fields)r)'''[1:] + "\n"
-    
+
     prepend_backwards = True
-    
+
     def __init__(self, model, fields):
         self.model = model
         self.fields = fields
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " + Added unique constraint for %s on %s.%s" % (
             [x.name for x in self.fields],
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
-        
+
         return self.FORWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
-            "fields":  [field.column for field in self.fields],
-            "field_names":  [field.name for field in self.fields],
+            "fields": [field.column for field in self.fields],
+            "field_names": [field.name for field in self.fields],
         }
 
     def backwards_code(self):
@@ -403,7 +409,7 @@ class AddUnique(Action):
             "model_name": self.model._meta.object_name,
             "table_name": self.model._meta.db_table,
             "fields": [field.column for field in self.fields],
-            "field_names":  [field.name for field in self.fields],
+            "field_names": [field.name for field in self.fields],
         }
 
 
@@ -411,18 +417,18 @@ class DeleteUnique(AddUnique):
     """
     Removes a unique constraint from a model. Takes a Model class and the field names.
     """
-    
+
     prepend_forwards = True
     prepend_backwards = False
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " - Deleted unique constraint for %s on %s.%s" % (
             [x.name for x in self.fields],
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
         return AddUnique.backwards_code(self)
 
@@ -434,20 +440,20 @@ class AddIndex(AddUnique):
     """
     Adds an index to a model field[s]. Takes a Model class and the field names.
     """
-    
+
     FORWARDS_TEMPLATE = '''
         # Adding index on '%(model_name)s', fields %(field_names)s
         db.create_index(%(table_name)r, %(fields)r)'''[1:] + "\n"
-    
+
     BACKWARDS_TEMPLATE = '''
         # Removing index on '%(model_name)s', fields %(field_names)s
         db.delete_index(%(table_name)r, %(fields)r)'''[1:] + "\n"
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " + Added index for %s on %s.%s" % (
             [x.name for x in self.fields],
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
 
@@ -456,15 +462,15 @@ class DeleteIndex(AddIndex):
     """
     Deletes an index off a model field[s]. Takes a Model class and the field names.
     """
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " + Deleted index for %s on %s.%s" % (
             [x.name for x in self.fields],
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
         return AddIndex.backwards_code(self)
 
@@ -476,7 +482,7 @@ class AddM2M(Action):
     """
     Adds a unique constraint to a model. Takes a Model class and the field names.
     """
-    
+
     FORWARDS_TEMPLATE = '''
         # Adding M2M table for field %(field_name)s on '%(model_name)s'
         m2m_table_name = %(table_name)s
@@ -486,26 +492,26 @@ class AddM2M(Action):
             (%(right_field)r, models.ForeignKey(orm[%(right_model_key)r], null=False))
         ))
         db.create_unique(m2m_table_name, [%(left_column)r, %(right_column)r])'''[1:] + "\n"
-    
+
     BACKWARDS_TEMPLATE = '''
         # Removing M2M table for field %(field_name)s on '%(model_name)s'
         db.delete_table(%(table_name)s)'''[1:] + "\n"
-    
+
     def __init__(self, model, field):
         self.model = model
         self.field = field
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " + Added M2M table for %s on %s.%s" % (
             self.field.name,
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
 
     def table_name(self):
         # This is part of a workaround for the fact that Django uses
-        # different shortening for automatically generated m2m table names 
+        # different shortening for automatically generated m2m table names
         # (as opposed to any explicitly specified table name)
         f = self.field
         explicit = f.db_table
@@ -516,21 +522,21 @@ class AddM2M(Action):
             return 'db.shorten_name(%r)' % auto
 
     def forwards_code(self):
-        
+
         return self.FORWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "field_name": self.field.name,
             "table_name": self.table_name(),
-            "left_field": self.field.m2m_column_name()[:-3], # Remove the _id part
+            "left_field": self.field.m2m_column_name()[:-3],  # Remove the _id part
             "left_column": self.field.m2m_column_name(),
             "left_model_key": model_key(self.model),
-            "right_field": self.field.m2m_reverse_name()[:-3], # Remove the _id part
+            "right_field": self.field.m2m_reverse_name()[:-3],  # Remove the _id part
             "right_column": self.field.m2m_reverse_name(),
             "right_model_key": model_key(self.field.rel.to),
         }
 
     def backwards_code(self):
-        
+
         return self.BACKWARDS_TEMPLATE % {
             "model_name": self.model._meta.object_name,
             "field_name": self.field.name,
@@ -542,18 +548,17 @@ class DeleteM2M(AddM2M):
     """
     Adds a unique constraint to a model. Takes a Model class and the field names.
     """
-    
+
     def console_line(self):
         "Returns the string to print on the console, e.g. ' + Added field foo'"
         return " - Deleted M2M table for %s on %s.%s" % (
             self.field.name,
-            self.model._meta.app_label, 
+            self.model._meta.app_label,
             self.model._meta.object_name,
         )
-    
+
     def forwards_code(self):
         return AddM2M.backwards_code(self)
 
     def backwards_code(self):
         return AddM2M.forwards_code(self)
-    
diff --git a/src/south/creator/changes.py b/src/south/creator/changes.py
index 6cdbd19de0..1dea8e3545 100644
--- a/src/south/creator/changes.py
+++ b/src/south/creator/changes.py
@@ -13,13 +13,15 @@ from south.creator.freezer import remove_useless_attributes, freeze_apps, model_
 from south.utils import auto_through
 from south.utils.py3 import string_types
 
+
 class BaseChanges(object):
     """
     Base changes class.
     """
+
     def suggest_name(self):
         return ''
-    
+
     def split_model_def(self, model, model_def):
         """
         Given a model and its model def (a dict of field: triple), returns three
@@ -36,11 +38,11 @@ class BaseChanges(object):
             else:
                 real_fields[name] = triple
         return real_fields, meta, m2m_fields
-    
+
     def current_model_from_key(self, key):
         app_label, model_name = key.split(".")
         return models.get_model(app_label, model_name)
-    
+
     def current_field_from_key(self, key, fieldname):
         app_label, model_name = key.split(".")
         # Special, for the magical field from order_with_respect_to
@@ -59,18 +61,18 @@ class AutoChanges(BaseChanges):
     """
     Detects changes by 'diffing' two sets of frozen model definitions.
     """
-    
+
     # Field types we don't generate add/remove field changes for.
     IGNORED_FIELD_TYPES = [
         GenericRelation,
     ]
-    
+
     def __init__(self, migrations, old_defs, old_orm, new_defs):
         self.migrations = migrations
         self.old_defs = old_defs
         self.old_orm = old_orm
         self.new_defs = new_defs
-    
+
     def suggest_name(self):
         parts = ["auto"]
         for change_name, params in self.get_changes():
@@ -114,24 +116,25 @@ class AutoChanges(BaseChanges):
                     "_".join([x.name for x in params['fields']]),
                 ))
         return ("__".join(parts))[:70]
-    
+
     def get_changes(self):
         """
         Returns the difference between the old and new sets of models as a 5-tuple:
         added_models, deleted_models, added_fields, deleted_fields, changed_fields
         """
-        
+
         deleted_models = set()
-        
+
         # See if anything's vanished
         for key in self.old_defs:
             if key not in self.new_defs:
                 # We shouldn't delete it if it was managed=False
-                old_fields, old_meta, old_m2ms = self.split_model_def(self.old_orm[key], self.old_defs[key])
+                old_fields, old_meta, old_m2ms = self.split_model_def(
+                    self.old_orm[key], self.old_defs[key])
                 if old_meta.get("managed", "True") != "False":
                     # Alright, delete it.
                     yield ("DeleteModel", {
-                        "model": self.old_orm[key], 
+                        "model": self.old_orm[key],
                         "model_def": old_fields,
                     })
                     # Also make sure we delete any M2Ms it had.
@@ -141,7 +144,8 @@ class AutoChanges(BaseChanges):
                         if auto_through(field):
                             yield ("DeleteM2M", {"model": self.old_orm[key], "field": field})
                     # And any index/uniqueness constraints it had
-                    for attr, operation in (("unique_together", "DeleteUnique"), ("index_together", "DeleteIndex")):
+                    for attr, operation in (("unique_together", "DeleteUnique"),
+                                            ("index_together", "DeleteIndex")):
                         together = eval(old_meta.get(attr, "[]"))
                         if together:
                             # If it's only a single tuple, make it into the longer one
@@ -155,15 +159,16 @@ class AutoChanges(BaseChanges):
                                 })
                 # We always add it in here so we ignore it later
                 deleted_models.add(key)
-        
+
         # Or appeared
         for key in self.new_defs:
             if key not in self.old_defs:
                 # We shouldn't add it if it's managed=False
-                new_fields, new_meta, new_m2ms = self.split_model_def(self.current_model_from_key(key), self.new_defs[key])
+                new_fields, new_meta, new_m2ms = self.split_model_def(
+                    self.current_model_from_key(key), self.new_defs[key])
                 if new_meta.get("managed", "True") != "False":
                     yield ("AddModel", {
-                        "model": self.current_model_from_key(key), 
+                        "model": self.current_model_from_key(key),
                         "model_def": new_fields,
                     })
                     # Also make sure we add any M2Ms it has.
@@ -173,7 +178,8 @@ class AutoChanges(BaseChanges):
                         if auto_through(field):
                             yield ("AddM2M", {"model": self.current_model_from_key(key), "field": field})
                     # And any index/uniqueness constraints it has
-                    for attr, operation in (("unique_together", "AddUnique"), ("index_together", "AddIndex")):
+                    for attr, operation in (("unique_together", "AddUnique"),
+                                            ("index_together", "AddIndex")):
                         together = eval(new_meta.get(attr, "[]"))
                         if together:
                             # If it's only a single tuple, make it into the longer one
@@ -185,18 +191,20 @@ class AutoChanges(BaseChanges):
                                     "model": self.current_model_from_key(key),
                                     "fields": [self.current_model_from_key(key)._meta.get_field_by_name(x)[0] for x in fields],
                                 })
-        
+
         # Now, for every model that's stayed the same, check its fields.
         for key in self.old_defs:
             if key not in deleted_models:
-                
-                old_fields, old_meta, old_m2ms = self.split_model_def(self.old_orm[key], self.old_defs[key])
-                new_fields, new_meta, new_m2ms = self.split_model_def(self.current_model_from_key(key), self.new_defs[key])
-                
+
+                old_fields, old_meta, old_m2ms = self.split_model_def(
+                    self.old_orm[key], self.old_defs[key])
+                new_fields, new_meta, new_m2ms = self.split_model_def(
+                    self.current_model_from_key(key), self.new_defs[key])
+
                 # Do nothing for models which are now not managed.
                 if new_meta.get("managed", "True") == "False":
                     continue
-                
+
                 # Find fields that have vanished.
                 for fieldname in old_fields:
                     if fieldname not in new_fields:
@@ -213,7 +221,7 @@ class AutoChanges(BaseChanges):
                                 "field": field,
                                 "field_def": old_fields[fieldname],
                             })
-                
+
                 # And ones that have appeared
                 for fieldname in new_fields:
                     if fieldname not in old_fields:
@@ -230,7 +238,7 @@ class AutoChanges(BaseChanges):
                                 "field": field,
                                 "field_def": new_fields[fieldname],
                             })
-                
+
                 # Find M2Ms that have vanished
                 for fieldname in old_m2ms:
                     if fieldname not in new_m2ms:
@@ -238,7 +246,7 @@ class AutoChanges(BaseChanges):
                         field = self.old_orm[key + ":" + fieldname]
                         if auto_through(field):
                             yield ("DeleteM2M", {"model": self.old_orm[key], "field": field})
-                
+
                 # Find M2Ms that have appeared
                 for fieldname in new_m2ms:
                     if fieldname not in old_m2ms:
@@ -246,13 +254,13 @@ class AutoChanges(BaseChanges):
                         field = self.current_field_from_key(key, fieldname)
                         if auto_through(field):
                             yield ("AddM2M", {"model": self.current_model_from_key(key), "field": field})
-                
+
                 # For the ones that exist in both models, see if they were changed
                 for fieldname in set(old_fields).intersection(set(new_fields)):
                     # Non-index changes
                     if self.different_attributes(
-                     remove_useless_attributes(old_fields[fieldname], True, True),
-                     remove_useless_attributes(new_fields[fieldname], True, True)):
+                            remove_useless_attributes(old_fields[fieldname], True, True),
+                            remove_useless_attributes(new_fields[fieldname], True, True)):
                         yield ("ChangeField", {
                             "model": self.current_model_from_key(key),
                             "old_field": self.old_orm[key + ":" + fieldname],
@@ -288,7 +296,7 @@ class AutoChanges(BaseChanges):
                                 "model": self.old_orm[key],
                                 "fields": [old_field],
                             })
-                
+
                 # See if there's any M2Ms that have changed.
                 for fieldname in set(old_m2ms).intersection(set(new_m2ms)):
                     old_field = self.old_orm[key + ":" + fieldname]
@@ -299,9 +307,10 @@ class AutoChanges(BaseChanges):
                     # Have they _removed_ a through= ?
                     if not auto_through(old_field) and auto_through(new_field):
                         yield ("AddM2M", {"model": self.current_model_from_key(key), "field": new_field})
-                
-                ## See if the {index,unique}_togethers have changed
-                for attr, add_operation, del_operation in (("unique_together", "AddUnique", "DeleteUnique"), ("index_together", "AddIndex", "DeleteIndex")):
+
+                # See if the {index,unique}_togethers have changed
+                for attr, add_operation, del_operation in (
+                        ("unique_together", "AddUnique", "DeleteUnique"), ("index_together", "AddIndex", "DeleteIndex")):
                     # First, normalise them into lists of sets.
                     old_together = eval(old_meta.get(attr, "[]"))
                     new_together = eval(new_meta.get(attr, "[]"))
@@ -340,37 +349,37 @@ class AutoChanges(BaseChanges):
         and which knows django.db.models.fields.CharField = models.CharField.
         Has a whole load of tests in tests/autodetection.py.
         """
-        
+
         # If they're not triples, just do normal comparison
         if not cls.is_triple(old) or not cls.is_triple(new):
             return old != new
-        
+
         # Expand them out into parts
         old_field, old_pos, old_kwd = old
         new_field, new_pos, new_kwd = new
-        
+
         # Copy the positional and keyword arguments so we can compare them and pop off things
         old_pos, new_pos = old_pos[:], new_pos[:]
         old_kwd = dict(old_kwd.items())
         new_kwd = dict(new_kwd.items())
-        
+
         # Remove comparison of the existence of 'unique', that's done elsewhere.
         # TODO: Make this work for custom fields where unique= means something else?
         if "unique" in old_kwd:
             del old_kwd['unique']
         if "unique" in new_kwd:
             del new_kwd['unique']
-        
+
         # If the first bit is different, check it's not by dj.db.models...
         if old_field != new_field:
-            if old_field.startswith("models.") and (new_field.startswith("django.db.models") \
-             or new_field.startswith("django.contrib.gis")):
+            if old_field.startswith("models.") and (new_field.startswith("django.db.models")
+                                                    or new_field.startswith("django.contrib.gis")):
                 if old_field.split(".")[-1] != new_field.split(".")[-1]:
                     return True
                 else:
                     # Remove those fields from the final comparison
                     old_field = new_field = ""
-        
+
         # If there's a positional argument in the first, and a 'to' in the second,
         # see if they're actually comparable.
         if (old_pos and "to" in new_kwd) and ("orm" in new_kwd['to'] and "orm" not in old_pos[0]):
@@ -379,11 +388,11 @@ class AutoChanges(BaseChanges):
                 if old_pos[0] != new_kwd['to'].split("'")[1].split(".")[1]:
                     return True
             except IndexError:
-                pass # Fall back to next comparison
+                pass  # Fall back to next comparison
             # Remove those attrs from the final comparison
             old_pos = old_pos[1:]
             del new_kwd['to']
-        
+
         return old_field != new_field or old_pos != new_pos or old_kwd != new_kwd
 
 
@@ -391,13 +400,13 @@ class ManualChanges(BaseChanges):
     """
     Detects changes by reading the command line.
     """
-    
+
     def __init__(self, migrations, added_models, added_fields, added_indexes):
         self.migrations = migrations
         self.added_models = added_models
         self.added_fields = added_fields
         self.added_indexes = added_indexes
-    
+
     def suggest_name(self):
         bits = []
         for model_name in self.added_models:
@@ -407,14 +416,15 @@ class ManualChanges(BaseChanges):
         for index_name in self.added_indexes:
             bits.append('add_index_%s' % index_name)
         return '_'.join(bits).replace('.', '_')
-    
+
     def get_changes(self):
         # Get the model defs so we can use them for the yield later
         model_defs = freeze_apps([self.migrations.app_label()])
         # Make the model changes
         for model_name in self.added_models:
             model = models.get_model(self.migrations.app_label(), model_name)
-            real_fields, meta, m2m_fields = self.split_model_def(model, model_defs[model_key(model)])
+            real_fields, meta, m2m_fields = self.split_model_def(
+                model, model_defs[model_key(model)])
             yield ("AddModel", {
                 "model": model,
                 "model_def": real_fields,
@@ -426,7 +436,8 @@ class ManualChanges(BaseChanges):
             except (TypeError, ValueError):
                 raise ValueError("%r is not a valid field description." % field_desc)
             model = models.get_model(self.migrations.app_label(), model_name)
-            real_fields, meta, m2m_fields = self.split_model_def(model, model_defs[model_key(model)])
+            real_fields, meta, m2m_fields = self.split_model_def(
+                model, model_defs[model_key(model)])
             yield ("AddField", {
                 "model": model,
                 "field": model._meta.get_field_by_name(field_name)[0],
@@ -443,39 +454,43 @@ class ManualChanges(BaseChanges):
                 "model": model,
                 "fields": [model._meta.get_field_by_name(field_name)[0]],
             })
-    
-    
+
+
 class InitialChanges(BaseChanges):
     """
     Creates all models; handles --initial.
     """
+
     def suggest_name(self):
         return 'initial'
-    
+
     def __init__(self, migrations):
         self.migrations = migrations
-    
+
     def get_changes(self):
         # Get the frozen models for this app
         model_defs = freeze_apps([self.migrations.app_label()])
-        
+
         for model in models.get_models(models.get_app(self.migrations.app_label())):
-            
+
             # Don't do anything for unmanaged, abstract or proxy models
-            if model._meta.abstract or getattr(model._meta, "proxy", False) or not getattr(model._meta, "managed", True):
+            if model._meta.abstract or getattr(
+                    model._meta, "proxy", False) or not getattr(model._meta, "managed", True):
                 continue
-            
-            real_fields, meta, m2m_fields = self.split_model_def(model, model_defs[model_key(model)])
-            
+
+            real_fields, meta, m2m_fields = self.split_model_def(
+                model, model_defs[model_key(model)])
+
             # Firstly, add the main table and fields
             yield ("AddModel", {
                 "model": model,
                 "model_def": real_fields,
             })
-            
+
             # Then, add any indexing/uniqueness that's around
             if meta:
-                for attr, operation in (("unique_together", "AddUnique"), ("index_together", "AddIndex")):
+                for attr, operation in (("unique_together", "AddUnique"),
+                                        ("index_together", "AddIndex")):
                     together = eval(meta.get(attr, "[]"))
                     if together:
                         # If it's only a single tuple, make it into the longer one
@@ -487,7 +502,7 @@ class InitialChanges(BaseChanges):
                                 "model": model,
                                 "fields": [model._meta.get_field_by_name(x)[0] for x in fields],
                             })
-            
+
             # Finally, see if there's some M2M action
             for name, triple in m2m_fields.items():
                 field = model._meta.get_field_by_name(name)[0]
diff --git a/src/south/creator/freezer.py b/src/south/creator/freezer.py
index 0f98cea0d7..aaa410f6c1 100644
--- a/src/south/creator/freezer.py
+++ b/src/south/creator/freezer.py
@@ -14,6 +14,7 @@ from south.utils import get_attribute, auto_through
 from south import modelsinspector
 from south.utils.py3 import string_types
 
+
 def freeze_apps(apps):
     """
     Takes a list of app labels, and returns a string of their frozen form.
@@ -45,7 +46,8 @@ def freeze_apps(apps):
                 model_class = model_classes[key]
                 field_class = model_class._meta.get_field_by_name(field_name)[0]
                 print(" ! Cannot freeze field '%s.%s'" % (key, field_name))
-                print(" ! (this field has class %s.%s)" % (field_class.__class__.__module__, field_class.__class__.__name__))
+                print(" ! (this field has class %s.%s)" %
+                      (field_class.__class__.__module__, field_class.__class__.__name__))
     if missing_fields:
         print("")
         print(" ! South cannot introspect some fields; this is probably because they are custom")
@@ -53,18 +55,21 @@ def freeze_apps(apps):
         print(" ! models parser (it often broke things).")
         print(" ! To fix this, read http://south.aeracode.org/wiki/MyFieldsDontWork")
         sys.exit(1)
-    
+
     return model_defs
-    
+
+
 def freeze_apps_to_string(apps):
     return pprint_frozen_models(freeze_apps(apps))
-    
-### 
+
+###
+
 
 def model_key(model):
     "For a given model, return 'appname.modelname'."
     return "%s.%s" % (model._meta.app_label, model._meta.object_name.lower())
 
+
 def prep_for_freeze(model):
     """
     Takes a model and returns the ready-to-serialise dict (all you need
@@ -77,12 +82,13 @@ def prep_for_freeze(model):
     # See if there's a Meta
     fields['Meta'] = remove_useless_meta(modelsinspector.get_model_meta(model))
     # Add in our own special items to track the object name and managed
-    fields['Meta']['object_name'] = model._meta.object_name # Special: not eval'able.
+    fields['Meta']['object_name'] = model._meta.object_name  # Special: not eval'able.
     if not getattr(model._meta, "managed", True):
         fields['Meta']['managed'] = repr(model._meta.managed)
     return fields
 
-### Dependency resolvers
+# Dependency resolvers
+
 
 def model_dependencies(model, checked_models=None):
     """
@@ -114,6 +120,7 @@ def model_dependencies(model, checked_models=None):
             depends.add(dep)
     return depends
 
+
 def field_dependencies(field, checked_models=None):
     checked_models = checked_models or set()
     depends = set()
@@ -148,7 +155,8 @@ def field_dependencies(field, checked_models=None):
 
     return depends
 
-### Prettyprinters
+# Prettyprinters
+
 
 def pprint_frozen_models(models):
     return "{\n        %s\n    }" % ",\n        ".join([
@@ -156,18 +164,21 @@ def pprint_frozen_models(models):
         for name, fields in sorted(models.items())
     ])
 
+
 def pprint_fields(fields):
     return "{\n            %s\n        }" % ",\n            ".join([
         "%r: %r" % (name, defn)
         for name, defn in sorted(fields.items())
     ])
 
-### Output sanitisers
+# Output sanitisers
+
 
 USELESS_KEYWORDS = ["choices", "help_text", "verbose_name"]
-USELESS_DB_KEYWORDS = ["related_name", "default", "blank"] # Important for ORM, not for DB.
+USELESS_DB_KEYWORDS = ["related_name", "default", "blank"]  # Important for ORM, not for DB.
 INDEX_KEYWORDS = ["db_index"]
 
+
 def remove_useless_attributes(field, db=False, indexes=False):
     "Removes useless (for database) attributes from the field's defn."
     # Work out what to remove, and remove it.
@@ -182,7 +193,10 @@ def remove_useless_attributes(field, db=False, indexes=False):
                 del field[2][name]
     return field
 
+
 USELESS_META = ["verbose_name", "verbose_name_plural"]
+
+
 def remove_useless_meta(meta):
     "Removes useless (for database) attributes from the table's meta."
     if meta:
diff --git a/src/south/db/__init__.py b/src/south/db/__init__.py
index 7f837d8e9b..cec4572651 100644
--- a/src/south/db/__init__.py
+++ b/src/south/db/__init__.py
@@ -10,7 +10,7 @@ engine_modules = {
     'django.db.backends.postgresql_psycopg2': 'postgresql_psycopg2',
     'django.db.backends.sqlite3': 'sqlite3',
     'django.db.backends.mysql': 'mysql',
-    'mysql.connector.django': 'mysql', # MySQL Connector/Python
+    'mysql.connector.django': 'mysql',  # MySQL Connector/Python
 }
 
 # First, work out if we're multi-db or not, and which databases we have
@@ -30,9 +30,9 @@ for alias, engine in db_engines.items():
         # They've used a backend we don't support
         sys.stderr.write(
             (
-                "There is no South database module for your database backend '%s'. " + \
-                "Please either choose a supported database, check for " + \
-                "SOUTH_DATABASE_ADAPTER[S] settings, " + \
+                "There is no South database module for your database backend '%s'. " +
+                "Please either choose a supported database, check for " +
+                "SOUTH_DATABASE_ADAPTER[S] settings, " +
                 "or remove South from INSTALLED_APPS.\n"
             ) % (settings.DATABASES[alias]['ENGINE'],)
         )
@@ -48,9 +48,9 @@ except ImportError:
     # This error should only be triggered on 1.1 and below.
     sys.stderr.write(
         (
-            "There is no South database module '%s' for your database. " + \
-            "Please either choose a supported database, check for " + \
-            "SOUTH_DATABASE_ADAPTER[S] settings, " + \
+            "There is no South database module '%s' for your database. " +
+            "Please either choose a supported database, check for " +
+            "SOUTH_DATABASE_ADAPTER[S] settings, " +
             "or remove South from INSTALLED_APPS.\n"
         ) % (module_name,)
     )
diff --git a/src/south/db/generic.py b/src/south/db/generic.py
index 5c1935444d..a1a5feb72f 100644
--- a/src/south/db/generic.py
+++ b/src/south/db/generic.py
@@ -20,6 +20,7 @@ except ImportError:
         Decorator that creates converts a method with a single
         self argument into a property cached on the instance.
         """
+
         def __init__(self, func):
             self.func = func
 
@@ -36,6 +37,7 @@ def alias(attrname):
     Returns a function which calls 'attrname' - for function aliasing.
     We can't just use foo = bar, as this breaks subclassing.
     """
+
     def func(self, *args, **kwds):
         return getattr(self, attrname)(*args, **kwds)
     return func
@@ -95,7 +97,7 @@ class DatabaseOperations(object):
     rename_table_sql = "ALTER TABLE %s RENAME TO %s;"
     backend_name = None
     default_schema_name = "public"
-    
+
     # Features
     allows_combined_alters = True
     supports_foreign_keys = True
@@ -238,7 +240,7 @@ class DatabaseOperations(object):
             return self._get_setting('schema')
         except (KeyError, AttributeError):
             return self.default_schema_name
-    
+
     def _possibly_initialise(self):
         if not self._initialised:
             self.connection_init()
@@ -250,7 +252,7 @@ class DatabaseOperations(object):
         e.g. which storage engine (MySQL) or transaction serialisability level.
         """
         pass
-    
+
     def quote_name(self, name):
         """
         Uses the database backend to quote the given table/column name.
@@ -260,15 +262,15 @@ class DatabaseOperations(object):
     def _print_sql_error(self, e, sql, params=[]):
         print('FATAL ERROR - The following SQL query failed: %s' % sql, file=sys.stderr)
         print('The error was: %s' % e, file=sys.stderr)
-        
+
     def execute(self, sql, params=[], print_all_errors=True):
         """
         Executes the given SQL statement, with optional parameters.
         If the instance's debug attribute is True, prints out what it executes.
         """
-        
+
         self._possibly_initialise()
-        
+
         cursor = self._get_connection().cursor()
         if self.debug:
             print("   = %s" % sql, params)
@@ -287,10 +289,11 @@ class DatabaseOperations(object):
 
         try:
             return cursor.fetchall()
-        except:
+        except BaseException:
             return []
 
-    def execute_many(self, sql, regex=r"(?mx) ([^';]* (?:'[^']*'[^';]*)*)", comment_regex=r"(?mx) (?:^\s*$)|(?:--.*$)"):
+    def execute_many(
+            self, sql, regex=r"(?mx) ([^';]* (?:'[^']*'[^';]*)*)", comment_regex=r"(?mx) (?:^\s*$)|(?:--.*$)"):
         """
         Takes a SQL file and executes it as many separate statements.
         (Some backends, such as Postgres, don't work otherwise.)
@@ -298,7 +301,8 @@ class DatabaseOperations(object):
         # Be warned: This function is full of dark magic. Make sure you really
         # know regexes before trying to edit it.
         # First, strip comments
-        sql = "\n".join([x.strip().replace("%", "%%") for x in re.split(comment_regex, sql) if x.strip()])
+        sql = "\n".join([x.strip().replace("%", "%%")
+                         for x in re.split(comment_regex, sql) if x.strip()])
         # Now execute each statement
         for st in re.split(regex, sql)[1:][::2]:
             self.execute(st)
@@ -325,7 +329,7 @@ class DatabaseOperations(object):
         """
         self.deferred_sql = []
 
-    def clear_run_data(self, pending_creates = None):
+    def clear_run_data(self, pending_creates=None):
         """
         Resets variables to how they should be before a run. Used for dry runs.
         If you want, pass in an old panding_creates to reset to.
@@ -420,7 +424,12 @@ class DatabaseOperations(object):
             # Now, drop the default if we need to
             if field.default is not None:
                 field.default = NOT_PROVIDED
-                self.alter_column(table_name, name, field, explicit_name=False, ignore_constraints=True)
+                self.alter_column(
+                    table_name,
+                    name,
+                    field,
+                    explicit_name=False,
+                    ignore_constraints=True)
 
     def _db_type_for_alter_column(self, field):
         """
@@ -433,7 +442,7 @@ class DatabaseOperations(object):
             return field.db_type(connection=self._get_connection())
         except TypeError:
             return field.db_type()
-        
+
     def _alter_add_column_mods(self, field, name, params, sqls):
         """
         Subcommand of alter_column that modifies column definitions beyond
@@ -453,7 +462,9 @@ class DatabaseOperations(object):
     def _update_nulls_to_default(self, params, field):
         "Subcommand of alter_column that updates nulls to default value (overrideable)"
         default = field.get_db_prep_save(field.get_default(), connection=self._get_connection())
-        self.execute('UPDATE %(table_name)s SET %(column)s=%%s WHERE %(column)s IS NULL' % params, [default])
+        self.execute(
+            'UPDATE %(table_name)s SET %(column)s=%%s WHERE %(column)s IS NULL' %
+            params, [default])
 
     @invalidate_table_constraints
     def alter_column(self, table_name, name, field, explicit_name=True, ignore_constraints=False):
@@ -467,7 +478,7 @@ class DatabaseOperations(object):
         @param name: The name of the column to alter
         @param field: The new field definition to use
         """
-        
+
         if self.dry_run:
             if self.debug:
                 print('   - no dry run output for alter_column() due to dynamic DDL, sorry')
@@ -494,7 +505,7 @@ class DatabaseOperations(object):
                         'table': self.quote_name(table_name),
                         'constraint': self.quote_name(constraint),
                     })
-        
+
             # Drop all foreign key constraints
             try:
                 self.delete_foreign_key(table_name, name)
@@ -511,11 +522,11 @@ class DatabaseOperations(object):
 
         # SQLs is a list of (SQL, values) pairs.
         sqls = []
-        
+
         # Only alter the column if it has a type (Geometry ones sometimes don't)
         if params["type"] is not None:
             sqls.append((self.alter_string_set_type % params, []))
-        
+
         # Add any field- and backend- specific modifications
         self._alter_add_column_mods(field, name, params, sqls)
         # Next, nullity
@@ -542,7 +553,12 @@ class DatabaseOperations(object):
         if not field.null and field.has_default():
             # Final fixes
             self._update_nulls_to_default(params, field)
-            self.execute("ALTER TABLE %s %s;" % (self.quote_name(table_name), self.alter_string_drop_null % params), [])
+            self.execute(
+                "ALTER TABLE %s %s;" %
+                (self.quote_name(table_name),
+                 self.alter_string_drop_null %
+                 params),
+                [])
 
         if not ignore_constraints:
             # Add back FK constraints if needed
@@ -641,14 +657,17 @@ class DatabaseOperations(object):
 
         constraints = list(self._constraints_affecting_columns(table_name, columns))
         if not constraints:
-            raise ValueError("Cannot find a UNIQUE constraint on table %s, columns %r" % (table_name, columns))
+            raise ValueError(
+                "Cannot find a UNIQUE constraint on table %s, columns %r" %
+                (table_name, columns))
         for constraint in constraints:
             self.execute(self.delete_unique_sql % (
                 self.quote_name(table_name),
                 self.quote_name(constraint),
             ))
 
-    def column_sql(self, table_name, field_name, field, tablespace='', with_name=True, field_prepared=False):
+    def column_sql(self, table_name, field_name, field, tablespace='',
+                   with_name=True, field_prepared=False):
         """
         Creates the SQL snippet for a column. Used by add_column and add_table.
         """
@@ -668,15 +687,15 @@ class DatabaseOperations(object):
             sql = field.db_type(connection=self._get_connection())
         except TypeError:
             sql = field.db_type()
-        
+
         if sql:
-            
+
             # Some callers, like the sqlite stuff, just want the extended type.
             if with_name:
                 field_output = [self.quote_name(field.column), sql]
             else:
                 field_output = [sql]
-            
+
             field_output.append('%sNULL' % (not field.null and 'NOT ' or ''))
             if field.primary_key:
                 field_output.append('PRIMARY KEY')
@@ -685,11 +704,14 @@ class DatabaseOperations(object):
                 field_output.append('UNIQUE')
 
             tablespace = field.db_tablespace or tablespace
-            if tablespace and getattr(self._get_connection().features, "supports_tablespaces", False) and field.unique:
+            if tablespace and getattr(self._get_connection().features,
+                                      "supports_tablespaces", False) and field.unique:
                 # We must specify the index tablespace inline, because we
                 # won't be generating a CREATE INDEX statement for this field.
-                field_output.append(self._get_connection().ops.tablespace_sql(tablespace, inline=True))
-            
+                field_output.append(
+                    self._get_connection().ops.tablespace_sql(
+                        tablespace, inline=True))
+
             sql = ' '.join(field_output)
             sqlparams = ()
             # if the field is "NOT NULL" and a default value is provided, create the column with it
@@ -702,10 +724,11 @@ class DatabaseOperations(object):
                         # If the default is a callable, then call it!
                         if callable(default):
                             default = default()
-                            
+
                         default = field.get_db_prep_save(default, connection=self._get_connection())
                         default = self._default_value_workaround(default)
-                        # Now do some very cheap quoting. TODO: Redesign return values to avoid this.
+                        # Now do some very cheap quoting. TODO: Redesign return values to avoid
+                        # this.
                         if isinstance(default, string_types):
                             default = "'%s'" % default.replace("'", "''")
                         # Escape any % signs in the output (bug #317)
@@ -718,7 +741,7 @@ class DatabaseOperations(object):
                     if field.empty_strings_allowed and self._get_connection().features.interprets_empty_strings_as_nulls:
                         sql += " DEFAULT ''"
                     # Error here would be nice, but doesn't seem to play fair.
-                    #else:
+                    # else:
                     #    raise ValueError("Attempting to add a non null column that isn't character based without an explicit default value.")
 
             if field.rel and self.supports_foreign_keys:
@@ -735,7 +758,7 @@ class DatabaseOperations(object):
         if hasattr(field, 'post_create_sql'):
             for stmt in field.post_create_sql(no_style(), table_name):
                 self.add_deferred_sql(stmt)
-        
+
         # In 1.2 and above, you have to ask the DatabaseCreation stuff for it.
         # This also creates normal indexes in 1.1.
         if hasattr(self._get_connection().creation, "sql_indexes_for_field"):
@@ -743,7 +766,7 @@ class DatabaseOperations(object):
             model = self.mock_model("FakeModelForGISCreation", table_name)
             for stmt in self._get_connection().creation.sql_indexes_for_field(model, field, no_style()):
                 self.add_deferred_sql(stmt)
-        
+
         if sql:
             return sql % sqlparams
         else:
@@ -770,7 +793,8 @@ class DatabaseOperations(object):
         """
         Generates a full SQL statement to add a foreign key constraint
         """
-        constraint_name = '%s_refs_%s_%s' % (from_column_name, to_column_name, self._digest(from_table_name, to_table_name))
+        constraint_name = '%s_refs_%s_%s' % (
+            from_column_name, to_column_name, self._digest(from_table_name, to_table_name))
         return 'ALTER TABLE %s ADD CONSTRAINT %s FOREIGN KEY (%s) REFERENCES %s (%s)%s;' % (
             self.quote_name(from_table_name),
             self.quote_name(self.shorten_name(constraint_name)),
@@ -791,7 +815,9 @@ class DatabaseOperations(object):
             return  # We can't look at the DB to get the constraints
         constraints = self._find_foreign_constraints(table_name, column)
         if not constraints:
-            raise ValueError("Cannot find a FOREIGN KEY constraint on table %s, column %s" % (table_name, column))
+            raise ValueError(
+                "Cannot find a FOREIGN KEY constraint on table %s, column %s" %
+                (table_name, column))
         for constraint_name in constraints:
             self.execute(self.delete_foreign_key_sql % {
                 "table": self.quote_name(table_name),
@@ -802,7 +828,7 @@ class DatabaseOperations(object):
 
     def _find_foreign_constraints(self, table_name, column_name=None):
         constraints = self._constraints_affecting_columns(
-                            table_name, [column_name], "FOREIGN KEY")
+            table_name, [column_name], "FOREIGN KEY")
 
         primary_key_columns = self._find_primary_key_columns(table_name)
 
@@ -812,7 +838,7 @@ class DatabaseOperations(object):
         else:
             primary_key_columns.add(column_name)
             recursive_constraints = set(self._constraints_affecting_columns(
-                                table_name, primary_key_columns, "FOREIGN KEY"))
+                table_name, primary_key_columns, "FOREIGN KEY"))
             return list(recursive_constraints.union(constraints))
 
     def _digest(self, *args):
@@ -848,7 +874,16 @@ class DatabaseOperations(object):
         index_unique_name = '_%x' % abs(hash((table_name, ','.join(column_names))))
 
         # If the index name is too long, truncate it
-        index_name = ('%s_%s%s%s' % (table_name, column_names[0], index_unique_name, suffix)).replace('"', '').replace('.', '_')
+        index_name = (
+            '%s_%s%s%s' %
+            (table_name,
+             column_names[0],
+             index_unique_name,
+             suffix)).replace(
+            '"',
+            '').replace(
+            '.',
+            '_')
         if len(index_name) > self.max_index_name_length:
             part = ('_%s%s%s' % (column_names[0], index_unique_name, suffix))
             index_name = '%s%s' % (table_name[:(self.max_index_name_length - len(part))], part)
@@ -928,17 +963,19 @@ class DatabaseOperations(object):
             if self.debug:
                 print('   - no dry run output for delete_primary_key() due to dynamic DDL, sorry')
             return
-        
-        constraints = list(self._constraints_affecting_columns(table_name, None, type="PRIMARY KEY"))
+
+        constraints = list(
+            self._constraints_affecting_columns(
+                table_name, None, type="PRIMARY KEY"))
         if not constraints:
             raise ValueError("Cannot find a PRIMARY KEY constraint on table %s" % (table_name,))
-        
+
         for constraint in constraints:
             self.execute(self.delete_primary_key_sql % {
                 "table": self.quote_name(table_name),
                 "constraint": self.quote_name(constraint),
             })
-    
+
     drop_primary_key = alias('delete_primary_key')
 
     @invalidate_table_constraints
@@ -959,13 +996,13 @@ class DatabaseOperations(object):
         Find all columns of the primary key of the specified table
         """
         db_name = self._get_setting('NAME')
-        
+
         primary_key_columns = set()
         for col, constraints in self.lookup_constraint(db_name, table_name):
             for kind, cname in constraints:
                 if kind == 'PRIMARY KEY':
                     primary_key_columns.add(col.lower())
-                    
+
         return primary_key_columns
 
     def start_transaction(self):
@@ -1043,10 +1080,10 @@ class DatabaseOperations(object):
         over all models within the app sending the signal.  This is a
         patch we should push Django to make  For now, this should work.
         """
-        
+
         if self.debug:
             print(" - Sending post_syncdb signal for %s: %s" % (app_label, model_names))
-        
+
         app = models.get_app(app_label)
         if not app:
             return
@@ -1140,7 +1177,7 @@ class DatabaseOperations(object):
         if isinstance(field, (models.PositiveSmallIntegerField, models.PositiveIntegerField)):
             return super_result.split(" ", 1)[0]
         return super_result
-        
+
     def _alter_add_positive_check(self, klass, field, name, params, sqls):
         """
         A helper for subclasses overriding _alter_add_column_mods:
@@ -1151,8 +1188,8 @@ class DatabaseOperations(object):
         if isinstance(field, (models.PositiveSmallIntegerField, models.PositiveIntegerField)):
             uniq_hash = abs(hash(tuple(params.values())))
             d = dict(
-                     constraint = "CK_%s_PSTV_%s" % (name, hex(uniq_hash)[2:]),
-                     check = "%s >= 0" % self.quote_name(name))
+                constraint="CK_%s_PSTV_%s" % (name, hex(uniq_hash)[2:]),
+                check="%s >= 0" % self.quote_name(name))
             sqls.append((self.add_check_constraint_fragment % d, []))
 
 
diff --git a/src/south/db/mysql.py b/src/south/db/mysql.py
index 3e87464ae0..d726243124 100644
--- a/src/south/db/mysql.py
+++ b/src/south/db/mysql.py
@@ -12,6 +12,7 @@ def delete_column_constraints(func):
     Decorates column operation functions for MySQL.
     Deletes the constraints from the database and clears local cache.
     """
+
     def _column_rm(self, table_name, column_name, *args, **opts):
         # Delete foreign key constraints
         try:
@@ -34,6 +35,7 @@ def copy_column_constraints(func):
     Decorates column operation functions for MySQL.
     Determines existing constraints and copies them to a new column
     """
+
     def _column_cp(self, table_name, column_old, column_new, *args, **opts):
         # Copy foreign key constraint
         try:
@@ -56,7 +58,7 @@ def copy_column_constraints(func):
             reverse = self._lookup_reverse_constraint(table_name, column_old)
             for cname, rtable, rcolumn in reverse:
                 fk_sql = self.foreign_key_sql(
-                        rtable, rcolumn, table_name, column_new)
+                    rtable, rcolumn, table_name, column_new)
                 self.add_deferred_sql(fk_sql)
         except DryRunError:
             pass
@@ -70,6 +72,7 @@ def invalidate_table_constraints(func):
     effective.
     It further solves the issues of invalidating referred table constraints.
     """
+
     def _cache_clear(self, table, *args, **opts):
         db_name = self._get_setting('NAME')
         if db_name in self._constraint_cache:
@@ -112,7 +115,8 @@ class DatabaseOperations(generic.DatabaseOperations):
         self._reverse_cache = {}
         super(DatabaseOperations, self).__init__(db_alias)
         if self._has_setting('STORAGE_ENGINE') and self._get_setting('STORAGE_ENGINE'):
-            self.create_table_sql = self.create_table_sql + ' ENGINE=%s' % self._get_setting('STORAGE_ENGINE')
+            self.create_table_sql = self.create_table_sql + \
+                ' ENGINE=%s' % self._get_setting('STORAGE_ENGINE')
 
     def _is_valid_cache(self, db_name, table_name):
         cache = self._constraint_cache
@@ -161,19 +165,19 @@ class DatabaseOperations(generic.DatabaseOperations):
                 self._constraint_cache[db_name][table].setdefault(column, set())
                 if kind == 'FOREIGN KEY':
                     self._constraint_cache[db_name][table][column].add((kind,
-                        constraint))
+                                                                        constraint))
                     # Create constraint lookup, see constraint_references
                     self._constraint_references[db_name][(table,
-                        constraint)] = (ref_table, ref_column)
+                                                          constraint)] = (ref_table, ref_column)
                     # Create reverse table lookup, reverse_lookup
                     self._reverse_cache[db_name].setdefault(ref_table, {})
                     self._reverse_cache[db_name][ref_table].setdefault(ref_column,
-                            set())
+                                                                       set())
                     self._reverse_cache[db_name][ref_table][ref_column].add(
-                            (constraint, table, column))
+                        (constraint, table, column))
                 else:
                     self._constraint_cache[db_name][table][column].add((kind,
-                    constraint))
+                                                                        constraint))
 
     def connection_init(self):
         """
@@ -199,7 +203,10 @@ class DatabaseOperations(generic.DatabaseOperations):
         if old == new or self.dry_run:
             return []
 
-        rows = [x for x in self.execute('DESCRIBE %s' % (self.quote_name(table_name),)) if x[0] == old]
+        rows = [
+            x for x in self.execute(
+                'DESCRIBE %s' %
+                (self.quote_name(table_name),)) if x[0] == old]
 
         if not rows:
             raise ValueError("No column '%s' in '%s'." % (old, table_name))
@@ -229,7 +236,7 @@ class DatabaseOperations(generic.DatabaseOperations):
     @invalidate_table_constraints
     def rename_table(self, old_table_name, table_name):
         super(DatabaseOperations, self).rename_table(old_table_name,
-                table_name)
+                                                     table_name)
 
     @invalidate_table_constraints
     def delete_table(self, table_name):
diff --git a/src/south/db/postgresql_psycopg2.py b/src/south/db/postgresql_psycopg2.py
index d6c63c47a3..54243046b9 100644
--- a/src/south/db/postgresql_psycopg2.py
+++ b/src/south/db/postgresql_psycopg2.py
@@ -57,7 +57,8 @@ class DatabaseOperations(generic.DatabaseOperations):
             """,
             [old_table_name + '_id_seq']
         ):
-            generic.DatabaseOperations.rename_table(self, old_table_name + "_id_seq", table_name + "_id_seq")
+            generic.DatabaseOperations.rename_table(
+                self, old_table_name + "_id_seq", table_name + "_id_seq")
 
         # Rename primary key index, will not rename other indices on
         # the table that are used by django (e.g. foreign keys). Until
@@ -76,7 +77,8 @@ class DatabaseOperations(generic.DatabaseOperations):
             [table_name]
         )
         if old_table_name + "_pkey" in pkey_index_names:
-            generic.DatabaseOperations.rename_table(self, old_table_name + "_pkey", table_name + "_pkey")
+            generic.DatabaseOperations.rename_table(
+                self, old_table_name + "_pkey", table_name + "_pkey")
 
     def rename_index(self, old_index_name, index_name):
         "Rename an index individually"
diff --git a/src/south/db/sqlite3.py b/src/south/db/sqlite3.py
index c4014d3bd0..a5d129d87e 100644
--- a/src/south/db/sqlite3.py
+++ b/src/south/db/sqlite3.py
@@ -1,12 +1,12 @@
 from south.db import generic
 
-    
+
 class DatabaseOperations(generic.DatabaseOperations):
 
     """
     SQLite3 implementation of database operations.
     """
-    
+
     backend_name = "sqlite3"
 
     # SQLite ignores several constraints. I wish I could.
@@ -20,19 +20,21 @@ class DatabaseOperations(generic.DatabaseOperations):
         """
         # If it's not nullable, and has no default, raise an error (SQLite is picky)
         if (not field.null and
-           (not field.has_default() or field.get_default() is None) and
-           not field.empty_strings_allowed):
+            (not field.has_default() or field.get_default() is None) and
+                not field.empty_strings_allowed):
             raise ValueError("You cannot add a null=False column without a default value.")
         # Initialise the field.
         field.set_attributes_from_name(name)
         # We add columns by remaking the table; even though SQLite supports
         # adding columns, it doesn't support adding PRIMARY KEY or UNIQUE cols.
-        # We define fields with no default; a default will be used, though, to fill up the remade table
+        # We define fields with no default; a default will be used, though, to
+        # fill up the remade table
         field_default = None
         if not getattr(field, '_suppress_default', False):
             default = field.get_default()
             if default is not None:
-                field_default = "'%s'" % field.get_db_prep_save(default, connection=self._get_connection())
+                field_default = "'%s'" % field.get_db_prep_save(
+                    default, connection=self._get_connection())
         field._suppress_default = True
         self._remake_table(table_name, added={
             field.column: (self._column_sql_for_create(table_name, name, field, False), field_default)
@@ -49,7 +51,8 @@ class DatabaseOperations(generic.DatabaseOperations):
                  } for field in cursor.fetchall()]
 
     @generic.invalidate_table_constraints
-    def _remake_table(self, table_name, added={}, renames={}, deleted=[], altered={}, primary_key_override=None, uniques_deleted=[]):
+    def _remake_table(self, table_name, added={}, renames={}, deleted=[],
+                      altered={}, primary_key_override=None, uniques_deleted=[]):
         """
         Given a table and three sets of changes (renames, deletes, alters),
         recreates it with the modified schema.
@@ -66,7 +69,8 @@ class DatabaseOperations(generic.DatabaseOperations):
         indexes = self._get_connection().introspection.get_indexes(cursor, table_name)
         standalone_indexes = self._get_standalone_indexes(table_name)
         # Work out new column defs.
-        for column_info in self._get_full_table_description(self._get_connection(), cursor, table_name):
+        for column_info in self._get_full_table_description(
+                self._get_connection(), cursor, table_name):
             name = column_info['name']
             if name in deleted:
                 continue
@@ -75,12 +79,12 @@ class DatabaseOperations(generic.DatabaseOperations):
             # Add on primary key, not null or unique if needed.
             if (primary_key_override and primary_key_override == name) or \
                (not primary_key_override and name in indexes and
-                indexes[name]['primary_key']):
+                    indexes[name]['primary_key']):
                 type += " PRIMARY KEY"
             elif not column_info['null_ok']:
                 type += " NOT NULL"
             if (name in indexes and indexes[name]['unique'] and
-                name not in uniques_deleted):
+                    name not in uniques_deleted):
                 type += " UNIQUE"
             if column_info['dflt_value'] is not None:
                 type += " DEFAULT " + column_info['dflt_value']
@@ -93,21 +97,22 @@ class DatabaseOperations(generic.DatabaseOperations):
         for name, type in altered.items():
             if (primary_key_override and primary_key_override == name) or \
                (not primary_key_override and name in indexes and
-                indexes[name]['primary_key']):
+                    indexes[name]['primary_key']):
                 type += " PRIMARY KEY"
             if (name in indexes and indexes[name]['unique'] and
-                name not in uniques_deleted):
+                    name not in uniques_deleted):
                 type += " UNIQUE"
             definitions[name] = type
         # Add on the new columns
-        for name, (type,_) in added.items():
+        for name, (type, _) in added.items():
             if (primary_key_override and primary_key_override == name):
                 type += " PRIMARY KEY"
             definitions[name] = type
         # Alright, Make the table
         self.execute("CREATE TABLE %s (%s)" % (
             self.quote_name(temp_name),
-            ", ".join(["%s %s" % (self.quote_name(cname), ctype) for cname, ctype in definitions.items()]),
+            ", ".join(["%s %s" % (self.quote_name(cname), ctype)
+                       for cname, ctype in definitions.items()]),
         ))
         # Copy over the data
         self._copy_data(table_name, temp_name, renames, added)
@@ -117,15 +122,22 @@ class DatabaseOperations(generic.DatabaseOperations):
         # Recreate multi-valued indexes
         # We can't do that before since it's impossible to rename indexes
         # and index name scope is global
-        self._make_standalone_indexes(table_name, standalone_indexes, renames=renames, deleted=deleted, uniques_deleted=uniques_deleted)
-        self.deferred_sql = [] # prevent double indexing
+        self._make_standalone_indexes(
+            table_name,
+            standalone_indexes,
+            renames=renames,
+            deleted=deleted,
+            uniques_deleted=uniques_deleted)
+        self.deferred_sql = []  # prevent double indexing
 
     def _copy_data(self, src, dst, field_renames={}, added={}):
         "Used to copy data into a new table"
         # Make a list of all the fields to select
         cursor = self._get_connection().cursor()
-        src_fields = [column_info[0] for column_info in self._get_connection().introspection.get_table_description(cursor, src)]
-        dst_fields = [column_info[0] for column_info in self._get_connection().introspection.get_table_description(cursor, dst)]
+        src_fields = [column_info[0] for column_info in self._get_connection(
+        ).introspection.get_table_description(cursor, src)]
+        dst_fields = [column_info[0] for column_info in self._get_connection(
+        ).introspection.get_table_description(cursor, dst)]
         src_fields_new = []
         dst_fields_new = []
         for field in src_fields:
@@ -136,7 +148,7 @@ class DatabaseOperations(generic.DatabaseOperations):
             else:
                 continue
             src_fields_new.append(self.quote_name(field))
-        for field, (_,default) in added.items():
+        for field, (_, default) in added.items():
             if default is not None:
                 field = self.quote_name(field)
                 src_fields_new.append("%s as %s" % (default, field))
@@ -180,7 +192,8 @@ class DatabaseOperations(generic.DatabaseOperations):
             indexes.append((index, columns, unique))
         return indexes
 
-    def _make_standalone_indexes(self, table_name, indexes, deleted=[], renames={}, uniques_deleted=[]):
+    def _make_standalone_indexes(self, table_name, indexes, deleted=[],
+                                 renames={}, uniques_deleted=[]):
         for index_name, index, unique in indexes:
             columns = []
 
@@ -210,7 +223,7 @@ class DatabaseOperations(generic.DatabaseOperations):
         if sql:
             sql = sql.replace("PRIMARY KEY", "")
         return sql
-    
+
     def alter_column(self, table_name, name, field, explicit_name=True, ignore_constraints=False):
         """
         Changes a column's SQL definition.
@@ -224,7 +237,7 @@ class DatabaseOperations(generic.DatabaseOperations):
             params = {
                 "column": self.quote_name(name),
                 "table_name": self.quote_name(table_name)
-            }            
+            }
             self._update_nulls_to_default(params, field)
         # Remake the table correctly
         field._suppress_default = True
@@ -237,25 +250,25 @@ class DatabaseOperations(generic.DatabaseOperations):
         Deletes a column.
         """
         self._remake_table(table_name, deleted=[column_name])
-    
+
     def rename_column(self, table_name, old, new):
         """
         Renames a column from one name to another.
         """
         self._remake_table(table_name, renames={old: new})
-    
+
     def create_unique(self, table_name, columns):
         """
         Create an unique index on columns
         """
         self._create_unique(table_name, columns)
-    
+
     def delete_unique(self, table_name, columns):
         """
         Delete an unique index
         """
         self._remake_table(table_name, uniques_deleted=columns)
-    
+
     def create_primary_key(self, table_name, columns):
         if not isinstance(columns, (list, tuple)):
             columns = [columns]
@@ -266,7 +279,7 @@ class DatabaseOperations(generic.DatabaseOperations):
     def delete_primary_key(self, table_name):
         # By passing True in, we make sure we wipe all existing PKs.
         self._remake_table(table_name, primary_key_override=True)
-    
+
     # No cascades on deletes
     def delete_table(self, table_name, cascade=True):
         generic.DatabaseOperations.delete_table(self, table_name, False)
diff --git a/src/south/exceptions.py b/src/south/exceptions.py
index f2e772fe55..52b2ca73c6 100644
--- a/src/south/exceptions.py
+++ b/src/south/exceptions.py
@@ -2,12 +2,15 @@ from __future__ import print_function
 
 from traceback import format_exception, format_exc
 
+
 class SouthError(RuntimeError):
     pass
 
+
 class SouthWarning(RuntimeWarning):
     pass
 
+
 class BrokenMigration(SouthError):
     def __init__(self, migration, exc_info):
         self.migration = migration
@@ -17,7 +20,7 @@ class BrokenMigration(SouthError):
         else:
             try:
                 self.traceback = format_exc()
-            except AttributeError: # Python3 when there is no previous exception
+            except AttributeError:  # Python3 when there is no previous exception
                 self.traceback = None
 
     def __str__(self):
@@ -37,7 +40,7 @@ class InvalidMigrationModule(SouthError):
     def __init__(self, application, module):
         self.application = application
         self.module = module
-    
+
     def __str__(self):
         return ('The migration module specified for %(application)s, %(module)r, is invalid; the parent module does not exist.' % self.__dict__)
 
@@ -109,7 +112,9 @@ class DependsOnUnknownMigration(SouthError):
         self.depends_on = depends_on
 
     def __str__(self):
-        print("Migration '%(migration)s' depends on unknown migration '%(depends_on)s'." % self.__dict__)
+        print(
+            "Migration '%(migration)s' depends on unknown migration '%(depends_on)s'." %
+            self.__dict__)
 
 
 class DependsOnUnmigratedApplication(SouthError):
@@ -147,6 +152,7 @@ class ImpossibleORMUnfreeze(SouthError):
     """Raised if the ORM can't manage to unfreeze all the models in a linear fashion."""
     pass
 
+
 class ConstraintDropped(SouthWarning):
     def __init__(self, constraint, table, column=None):
         self.table = table
@@ -155,6 +161,6 @@ class ConstraintDropped(SouthWarning):
         else:
             self.column = ""
         self.constraint = constraint
-    
+
     def __str__(self):
-        return "Constraint %(constraint)s was dropped from %(table)s%(column)s -- was this intended?" % self.__dict__  
+        return "Constraint %(constraint)s was dropped from %(table)s%(column)s -- was this intended?" % self.__dict__
diff --git a/src/south/hacks/__init__.py b/src/south/hacks/__init__.py
index 8f28503ed6..63045889e5 100644
--- a/src/south/hacks/__init__.py
+++ b/src/south/hacks/__init__.py
@@ -7,4 +7,4 @@ This top file will automagically expose the correct Hacks class.
 # Currently, these work for 1.0 and 1.1.
 from south.hacks.django_1_0 import Hacks
 
-hacks = Hacks()
\ No newline at end of file
+hacks = Hacks()
diff --git a/src/south/hacks/django_1_0.py b/src/south/hacks/django_1_0.py
index e4a60c66a9..420e2b632d 100644
--- a/src/south/hacks/django_1_0.py
+++ b/src/south/hacks/django_1_0.py
@@ -12,41 +12,42 @@ from django.utils.datastructures import SortedDict
 
 from south.utils.py3 import string_types
 
+
 class SkipFlushCommand(FlushCommand):
     def handle_noargs(self, **options):
         # no-op to avoid calling flush
         return
 
+
 class Hacks:
-    
+
     def set_installed_apps(self, apps):
         """
         Sets Django's INSTALLED_APPS setting to be effectively the list passed in.
         """
-        
+
         # Make sure it's a list.
         apps = list(apps)
-        
+
         # Make sure it contains strings
         if apps:
-            assert isinstance(apps[0], string_types), "The argument to set_installed_apps must be a list of strings."
-        
+            assert isinstance(
+                apps[0], string_types), "The argument to set_installed_apps must be a list of strings."
+
         # Monkeypatch in!
         settings.INSTALLED_APPS, settings.OLD_INSTALLED_APPS = (
             apps,
             settings.INSTALLED_APPS,
         )
         self._redo_app_cache()
-    
-    
+
     def reset_installed_apps(self):
         """
         Undoes the effect of set_installed_apps.
         """
         settings.INSTALLED_APPS = settings.OLD_INSTALLED_APPS
         self._redo_app_cache()
-    
-    
+
     def _redo_app_cache(self):
         """
         Used to repopulate AppCache after fiddling with INSTALLED_APPS.
@@ -58,24 +59,21 @@ class Hacks:
         cache.app_models = SortedDict()
         cache.app_errors = {}
         cache._populate()
-    
-    
+
     def clear_app_cache(self):
         """
         Clears the contents of AppCache to a blank state, so new models
         from the ORM can be added.
         """
         self.old_app_models, cache.app_models = cache.app_models, {}
-    
-    
+
     def unclear_app_cache(self):
         """
         Reversed the effects of clear_app_cache.
         """
         cache.app_models = self.old_app_models
         cache._get_models_cache = {}
-    
-    
+
     def repopulate_app_cache(self):
         """
         Rebuilds AppCache with the real model definitions.
@@ -105,6 +103,5 @@ class Hacks:
                     # unpatch flush back to the original
                     management._commands['flush'] = original_flush_command
             return wrapper
-            
-        BaseDatabaseCreation.create_test_db = patch(BaseDatabaseCreation.create_test_db)
 
+        BaseDatabaseCreation.create_test_db = patch(BaseDatabaseCreation.create_test_db)
diff --git a/src/south/introspection_plugins/__init__.py b/src/south/introspection_plugins/__init__.py
index 38262b52fb..7699a49b75 100644
--- a/src/south/introspection_plugins/__init__.py
+++ b/src/south/introspection_plugins/__init__.py
@@ -8,4 +8,3 @@ import south.introspection_plugins.django_tagging
 import south.introspection_plugins.django_taggit
 import south.introspection_plugins.django_objectpermissions
 import south.introspection_plugins.annoying_autoonetoone
-
diff --git a/src/south/introspection_plugins/annoying_autoonetoone.py b/src/south/introspection_plugins/annoying_autoonetoone.py
index d61304f3be..7707bcd45f 100644
--- a/src/south/introspection_plugins/annoying_autoonetoone.py
+++ b/src/south/introspection_plugins/annoying_autoonetoone.py
@@ -7,5 +7,5 @@ if 'annoying' in settings.INSTALLED_APPS:
     except ImportError:
         pass
     else:
-        #django-annoying's AutoOneToOneField is essentially a OneToOneField.
+        # django-annoying's AutoOneToOneField is essentially a OneToOneField.
         add_introspection_rules([], ["^annoying\.fields\.AutoOneToOneField"])
diff --git a/src/south/introspection_plugins/django_audit_log.py b/src/south/introspection_plugins/django_audit_log.py
index b874428e6d..7699722e15 100644
--- a/src/south/introspection_plugins/django_audit_log.py
+++ b/src/south/introspection_plugins/django_audit_log.py
@@ -1,30 +1,30 @@
-"""                                                 
+"""
 South introspection rules for django-audit-log
-"""                                                 
-                                                    
+"""
+
 from django.contrib.auth.models import User
 from django.conf import settings
 from south.modelsinspector import add_introspection_rules
 
 if "audit_log" in settings.INSTALLED_APPS:
-    try:                                                
+    try:
         # Try and import the field so we can see if audit_log is available
         from audit_log.models import fields
 
         # Make sure the `to` and `null` parameters will be ignored
-        rules = [(                                     
-            (fields.LastUserField,),                   
-            [],                                        
-            {                                          
-                'to': ['rel.to', {'default': User}],   
-                'null': ['null', {'default': True}],   
-            },                                         
-        )]                                             
+        rules = [(
+            (fields.LastUserField,),
+            [],
+            {
+                'to': ['rel.to', {'default': User}],
+                'null': ['null', {'default': True}],
+            },
+        )]
 
         # Add the rules for the `LastUserField`
-        add_introspection_rules(                           
-            rules,                                         
-            ['^audit_log\.models\.fields\.LastUserField'], 
-        )                                                  
-    except ImportError:                                 
+        add_introspection_rules(
+            rules,
+            ['^audit_log\.models\.fields\.LastUserField'],
+        )
+    except ImportError:
         pass
diff --git a/src/south/introspection_plugins/django_objectpermissions.py b/src/south/introspection_plugins/django_objectpermissions.py
index 42b353b53a..77d09696dc 100644
--- a/src/south/introspection_plugins/django_objectpermissions.py
+++ b/src/south/introspection_plugins/django_objectpermissions.py
@@ -13,4 +13,3 @@ if 'objectpermissions' in settings.INSTALLED_APPS:
     else:
         add_ignored_fields(["^objectpermissions\.models\.UserPermissionRelation",
                             "^objectpermissions\.models\.GroupPermissionRelation"])
-
diff --git a/src/south/introspection_plugins/django_tagging.py b/src/south/introspection_plugins/django_tagging.py
index c02e5294de..0a741884d8 100644
--- a/src/south/introspection_plugins/django_tagging.py
+++ b/src/south/introspection_plugins/django_tagging.py
@@ -17,8 +17,7 @@ if "tagging" in settings.INSTALLED_APPS:
                 },
             ),
         ]
-        add_introspection_rules(rules, ["^tagging\.fields",])
+        add_introspection_rules(rules, ["^tagging\.fields", ])
 
 if "tagging_autocomplete" in settings.INSTALLED_APPS:
     add_introspection_rules([], ["^tagging_autocomplete\.models\.TagAutocompleteField"])
-
diff --git a/src/south/introspection_plugins/django_timezones.py b/src/south/introspection_plugins/django_timezones.py
index d4b573d89c..d257a17943 100644
--- a/src/south/introspection_plugins/django_timezones.py
+++ b/src/south/introspection_plugins/django_timezones.py
@@ -17,5 +17,4 @@ if "timezones" in settings.INSTALLED_APPS:
                 },
             ),
         ]
-        add_introspection_rules(rules, ["^timezones\.fields",])
-
+        add_introspection_rules(rules, ["^timezones\.fields", ])
diff --git a/src/south/introspection_plugins/geodjango.py b/src/south/introspection_plugins/geodjango.py
index bece1c9f56..585e44fc1d 100644
--- a/src/south/introspection_plugins/geodjango.py
+++ b/src/south/introspection_plugins/geodjango.py
@@ -12,7 +12,7 @@ has_gis = "django.contrib.gis" in settings.INSTALLED_APPS
 if has_gis:
     # Alright,import the field
     from django.contrib.gis.db.models.fields import GeometryField
-    
+
     # Make some introspection rules
     if django.VERSION[0] == 1 and django.VERSION[1] >= 1:
         # Django 1.1's gis module renamed these.
@@ -40,6 +40,6 @@ if has_gis:
                 },
             ),
         ]
-    
+
     # Install them
-    add_introspection_rules(rules, ["^django\.contrib\.gis"])
\ No newline at end of file
+    add_introspection_rules(rules, ["^django\.contrib\.gis"])
diff --git a/src/south/logger.py b/src/south/logger.py
index 2caae3a9f6..5d446d8735 100644
--- a/src/south/logger.py
+++ b/src/south/logger.py
@@ -3,15 +3,18 @@ import logging
 from django.conf import settings
 
 # Create a dummy handler to use for now.
+
+
 class NullHandler(logging.Handler):
     def emit(self, record):
         pass
 
+
 def get_logger():
     "Attach a file handler to the logger if there isn't one already."
     debug_on = getattr(settings, "SOUTH_LOGGING_ON", False)
     logging_file = getattr(settings, "SOUTH_LOGGING_FILE", False)
-    
+
     if debug_on:
         if logging_file:
             if len(_logger.handlers) < 2:
@@ -19,9 +22,10 @@ def get_logger():
                 _logger.setLevel(logging.DEBUG)
         else:
             raise IOError("SOUTH_LOGGING_ON is True. You also need a SOUTH_LOGGING_FILE setting.")
-    
+
     return _logger
 
+
 def close_logger():
     "Closes the logger handler for the file, so we can remove the file after a test."
     for handler in _logger.handlers:
@@ -29,10 +33,12 @@ def close_logger():
         if isinstance(handler, logging.FileHandler):
             handler.close()
 
+
 def init_logger():
     "Initialize the south logger"
     logger = logging.getLogger("south")
     logger.addHandler(NullHandler())
     return logger
 
+
 _logger = init_logger()
diff --git a/src/south/management/commands/__init__.py b/src/south/management/commands/__init__.py
index da218eb240..9edd3c07b4 100644
--- a/src/south/management/commands/__init__.py
+++ b/src/south/management/commands/__init__.py
@@ -12,6 +12,7 @@ import django.template.loaders.app_directories
 from south.hacks import hacks
 from south.management.commands.syncdb import Command as SyncCommand
 
+
 class MigrateAndSyncCommand(SyncCommand):
     """Used for situations where "syncdb" is called by test frameworks."""
 
@@ -22,6 +23,7 @@ class MigrateAndSyncCommand(SyncCommand):
             opt.default = True
             break
 
+
 def patch_for_test_db_setup():
     # Load the commands cache
     management.get_commands()
diff --git a/src/south/management/commands/convert_to_south.py b/src/south/management/commands/convert_to_south.py
index 658ed482fc..e942344966 100644
--- a/src/south/management/commands/convert_to_south.py
+++ b/src/south/management/commands/convert_to_south.py
@@ -18,31 +18,32 @@ from south.migration import Migrations
 from south.hacks import hacks
 from south.exceptions import NoMigrations
 
+
 class Command(BaseCommand):
-    
+
     option_list = BaseCommand.option_list
     if '--verbosity' not in [opt.get_opt_string() for opt in BaseCommand.option_list]:
         option_list += (
             make_option('--verbosity', action='store', dest='verbosity', default='1',
-                type='choice', choices=['0', '1', '2'],
-                help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
+                        type='choice', choices=['0', '1', '2'],
+                        help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
         )
     option_list += (
         make_option('--delete-ghost-migrations', action='store_true', dest='delete_ghosts', default=False,
-            help="Tells South to delete any 'ghost' migrations (ones in the database but not on disk)."),
+                    help="Tells South to delete any 'ghost' migrations (ones in the database but not on disk)."),
         make_option('--ignore-ghost-migrations', action='store_true', dest='ignore_ghosts', default=False,
-            help="Tells South to ignore any 'ghost' migrations (ones in the database but not on disk) and continue to apply new migrations."), 
+                    help="Tells South to ignore any 'ghost' migrations (ones in the database but not on disk) and continue to apply new migrations."),
     )
 
     help = "Quickly converts the named application to use South if it is currently using syncdb."
 
     def handle(self, app=None, *args, **options):
-        
+
         # Make sure we have an app
         if not app:
             print("Please specify an app to convert.")
             return
-        
+
         # See if the app exists
         app = app.split(".")[-1]
         try:
@@ -50,14 +51,14 @@ class Command(BaseCommand):
         except ImproperlyConfigured:
             print("There is no enabled application matching '%s'." % app)
             return
-        
+
         # Try to get its list of models
         model_list = models.get_models(app_module)
         if not model_list:
             print("This application has no models; this command is for applications that already have models syncdb'd.")
             print("Make some models, and then use ./manage.py schemamigration %s --initial instead." % app)
             return
-        
+
         # Ask South if it thinks it's already got migrations
         try:
             Migrations(app)
@@ -66,18 +67,18 @@ class Command(BaseCommand):
         else:
             print("This application is already managed by South.")
             return
-        
+
         # Finally! It seems we've got a candidate, so do the two-command trick
         verbosity = int(options.get('verbosity', 0))
         management.call_command("schemamigration", app, initial=True, verbosity=verbosity)
-        
+
         # Now, we need to re-clean and sanitise appcache
         hacks.clear_app_cache()
         hacks.repopulate_app_cache()
-        
+
         # And also clear our cached Migration classes
         Migrations._clear_cache()
-        
+
         # Now, migrate
         management.call_command(
             "migrate",
@@ -88,8 +89,12 @@ class Command(BaseCommand):
             ignore_ghosts=options.get("ignore_ghosts", False),
             delete_ghosts=options.get("delete_ghosts", False),
         )
-        
-        print() 
-        print("App '%s' converted. Note that South assumed the application's models matched the database" % app)
-        print("(i.e. you haven't changed it since last syncdb); if you have, you should delete the %s/migrations" % app)
+
+        print()
+        print(
+            "App '%s' converted. Note that South assumed the application's models matched the database" %
+            app)
+        print(
+            "(i.e. you haven't changed it since last syncdb); if you have, you should delete the %s/migrations" %
+            app)
         print("directory, revert models.py so it matches the database, and try again.")
diff --git a/src/south/management/commands/datamigration.py b/src/south/management/commands/datamigration.py
index 9fe239f5aa..2d7e4a1c38 100644
--- a/src/south/management/commands/datamigration.py
+++ b/src/south/management/commands/datamigration.py
@@ -23,12 +23,13 @@ from south.migration import Migrations
 from south.exceptions import NoMigrations
 from south.creator import freezer
 
+
 class Command(BaseCommand):
     option_list = BaseCommand.option_list + (
         make_option('--freeze', action='append', dest='freeze_list', type='string',
-            help='Freeze the specified app(s). Provide an app name with each; use the option multiple times for multiple apps'),
+                    help='Freeze the specified app(s). Provide an app name with each; use the option multiple times for multiple apps'),
         make_option('--stdout', action='store_true', dest='stdout', default=False,
-            help='Print the migration to stdout instead of writing it to a file.'),
+                    help='Print the migration to stdout instead of writing it to a file.'),
     )
     help = "Creates a new template data migration for the given app"
     usage_str = "Usage: ./manage.py datamigration appname migrationname [--stdout] [--freeze appname]"
@@ -72,7 +73,7 @@ class Command(BaseCommand):
 
         # So, what's in this file, then?
         file_contents = self.get_migration_template() % {
-            "frozen_models":  freezer.freeze_apps_to_string(apps_to_freeze),
+            "frozen_models": freezer.freeze_apps_to_string(apps_to_freeze),
             "complete_apps": apps_to_freeze and "complete_apps = [%s]" % (", ".join(map(repr, apps_to_freeze))) or ""
         }
 
@@ -94,7 +95,9 @@ class Command(BaseCommand):
         apps_to_freeze = []
         for to_freeze in freeze_list:
             if "." in to_freeze:
-                self.error("You cannot freeze %r; you must provide an app label, like 'auth' or 'books'." % to_freeze)
+                self.error(
+                    "You cannot freeze %r; you must provide an app label, like 'auth' or 'books'." %
+                    to_freeze)
             # Make sure it's a real app
             if not models.get_app(to_freeze):
                 self.error("You cannot freeze %r; it's not an installed app." % to_freeze)
diff --git a/src/south/management/commands/graphmigrations.py b/src/south/management/commands/graphmigrations.py
index 6ff1e479be..73ec81f5b8 100644
--- a/src/south/management/commands/graphmigrations.py
+++ b/src/south/management/commands/graphmigrations.py
@@ -13,22 +13,23 @@ from django.core.management.color import no_style
 
 from south.migration import Migrations, all_migrations
 
+
 class Command(BaseCommand):
 
     help = "Outputs a GraphViz dot file of all migration dependencies to stdout."
-    
+
     def handle(self, **options):
-        
+
         # Resolve dependencies
         Migrations.calculate_dependencies()
 
-        colors = [ 'crimson', 'darkgreen', 'darkgoldenrod', 'navy',
-                'brown', 'darkorange', 'aquamarine' , 'blueviolet' ]
+        colors = ['crimson', 'darkgreen', 'darkgoldenrod', 'navy',
+                  'brown', 'darkorange', 'aquamarine', 'blueviolet']
         color_index = 0
         wrapper = textwrap.TextWrapper(width=40)
-        
+
         print("digraph G {")
-        
+
         # Group each app in a subgraph
         for migrations in all_migrations():
             print("  subgraph %s {" % migrations.app_label())
@@ -38,9 +39,9 @@ class Command(BaseCommand):
                 label = "%s - %s" % (
                         migration.app_label(), migration.name())
                 label = re.sub(r"_+", " ", label)
-                label=  "\\n".join(wrapper.wrap(label))
+                label = "\\n".join(wrapper.wrap(label))
                 print('    "%s.%s" [label="%s"];' % (
-                        migration.app_label(), migration.name(), label))
+                    migration.app_label(), migration.name(), label))
             print("  }")
             color_index = (color_index + 1) % len(colors)
 
@@ -59,5 +60,5 @@ class Command(BaseCommand):
                         migration.app_label(), migration.name(),
                         attrs
                     ))
-            
+
         print("}");
diff --git a/src/south/management/commands/migrate.py b/src/south/management/commands/migrate.py
index 693dbb7b6a..1aca7375e3 100644
--- a/src/south/management/commands/migrate.py
+++ b/src/south/management/commands/migrate.py
@@ -4,7 +4,9 @@ Migrate management command.
 
 from __future__ import print_function
 
-import os.path, re, sys
+import os.path
+import re
+import sys
 from functools import reduce
 from optparse import make_option
 
@@ -17,45 +19,47 @@ from south.migration import Migrations
 from south.exceptions import NoMigrations
 from south.db import DEFAULT_DB_ALIAS
 
+
 class Command(BaseCommand):
     option_list = BaseCommand.option_list + (
         make_option('--all', action='store_true', dest='all_apps', default=False,
-            help='Run the specified migration for all apps.'),
+                    help='Run the specified migration for all apps.'),
         make_option('--list', action='store_true', dest='show_list', default=False,
-            help='List migrations noting those that have been applied'),
+                    help='List migrations noting those that have been applied'),
         make_option('--changes', action='store_true', dest='show_changes', default=False,
-            help='List changes for migrations'),
+                    help='List changes for migrations'),
         make_option('--skip', action='store_true', dest='skip', default=False,
-            help='Will skip over out-of-order missing migrations'),
+                    help='Will skip over out-of-order missing migrations'),
         make_option('--merge', action='store_true', dest='merge', default=False,
-            help='Will run out-of-order missing migrations as they are - no rollbacks.'),
+                    help='Will run out-of-order missing migrations as they are - no rollbacks.'),
         make_option('--no-initial-data', action='store_true', dest='no_initial_data', default=False,
-            help='Skips loading initial data if specified.'),
+                    help='Skips loading initial data if specified.'),
         make_option('--fake', action='store_true', dest='fake', default=False,
-            help="Pretends to do the migrations, but doesn't actually execute them."),
+                    help="Pretends to do the migrations, but doesn't actually execute them."),
         make_option('--db-dry-run', action='store_true', dest='db_dry_run', default=False,
-            help="Doesn't execute the SQL generated by the db methods, and doesn't store a record that the migration(s) occurred. Useful to test migrations before applying them."),
+                    help="Doesn't execute the SQL generated by the db methods, and doesn't store a record that the migration(s) occurred. Useful to test migrations before applying them."),
         make_option('--delete-ghost-migrations', action='store_true', dest='delete_ghosts', default=False,
-            help="Tells South to delete any 'ghost' migrations (ones in the database but not on disk)."),
+                    help="Tells South to delete any 'ghost' migrations (ones in the database but not on disk)."),
         make_option('--ignore-ghost-migrations', action='store_true', dest='ignore_ghosts', default=False,
-            help="Tells South to ignore any 'ghost' migrations (ones in the database but not on disk) and continue to apply new migrations."),
+                    help="Tells South to ignore any 'ghost' migrations (ones in the database but not on disk) and continue to apply new migrations."),
         make_option('--noinput', action='store_false', dest='interactive', default=True,
-            help='Tells Django to NOT prompt the user for input of any kind.'),
+                    help='Tells Django to NOT prompt the user for input of any kind.'),
         make_option('--database', action='store', dest='database',
-            default=DEFAULT_DB_ALIAS, help='Nominates a database to synchronize. '
-                'Defaults to the "default" database.'),
+                    default=DEFAULT_DB_ALIAS, help='Nominates a database to synchronize. '
+                    'Defaults to the "default" database.'),
     )
     if '--verbosity' not in [opt.get_opt_string() for opt in BaseCommand.option_list]:
         option_list += (
             make_option('--verbosity', action='store', dest='verbosity', default='1',
-            type='choice', choices=['0', '1', '2'],
-            help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
+                        type='choice', choices=['0', '1', '2'],
+                        help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
         )
     help = "Runs migrations for all apps."
     args = "[appname] [migrationname|zero] [--all] [--list] [--skip] [--merge] [--no-initial-data] [--fake] [--db-dry-run] [--database=dbalias]"
 
-    def handle(self, app=None, target=None, skip=False, merge=False, backwards=False, fake=False, db_dry_run=False, show_list=False, show_changes=False, database=DEFAULT_DB_ALIAS, delete_ghosts=False, ignore_ghosts=False, **options):
-        
+    def handle(self, app=None, target=None, skip=False, merge=False, backwards=False, fake=False, db_dry_run=False,
+               show_list=False, show_changes=False, database=DEFAULT_DB_ALIAS, delete_ghosts=False, ignore_ghosts=False, **options):
+
         # NOTE: THIS IS DUPLICATED FROM django.core.management.commands.syncdb
         # This code imports any module named 'management' in INSTALLED_APPS.
         # The 'management' module is the preferred way of listening to post_syncdb
@@ -69,7 +73,7 @@ class Command(BaseCommand):
                 if not msg.startswith('No module named') or 'management' not in msg:
                     raise
         # END DJANGO DUPE CODE
-        
+
         # if all_apps flag is set, shift app over to target
         if options.get('all_apps', False):
             target = app
@@ -85,45 +89,47 @@ class Command(BaseCommand):
                 return
         else:
             apps = list(migration.all_migrations())
-        
+
         # Do we need to show the list of migrations?
         if show_list and apps:
             list_migrations(apps, database, **options)
-            
+
         if show_changes and apps:
             show_migration_changes(apps)
-        
+
         if not (show_list or show_changes):
-            
+
             for app in apps:
                 result = migration.migrate_app(
                     app,
-                    target_name = target,
-                    fake = fake,
-                    db_dry_run = db_dry_run,
-                    verbosity = int(options.get('verbosity', 0)),
-                    interactive = options.get('interactive', True),
-                    load_initial_data = not options.get('no_initial_data', False),
-                    merge = merge,
-                    skip = skip,
-                    database = database,
-                    delete_ghosts = delete_ghosts,
-                    ignore_ghosts = ignore_ghosts,
+                    target_name=target,
+                    fake=fake,
+                    db_dry_run=db_dry_run,
+                    verbosity=int(options.get('verbosity', 0)),
+                    interactive=options.get('interactive', True),
+                    load_initial_data=not options.get('no_initial_data', False),
+                    merge=merge,
+                    skip=skip,
+                    database=database,
+                    delete_ghosts=delete_ghosts,
+                    ignore_ghosts=ignore_ghosts,
                 )
                 if result is False:
-                    sys.exit(1) # Migration failed, so the command fails.
+                    sys.exit(1)  # Migration failed, so the command fails.
 
 
-def list_migrations(apps, database = DEFAULT_DB_ALIAS, **options):
+def list_migrations(apps, database=DEFAULT_DB_ALIAS, **options):
     """
     Prints a list of all available migrations, and which ones are currently applied.
     Accepts a list of Migrations instances.
     """
     from south.models import MigrationHistory
-    applied_migrations = MigrationHistory.objects.filter(app_name__in=[app.app_label() for app in apps])
+    applied_migrations = MigrationHistory.objects.filter(
+        app_name__in=[app.app_label() for app in apps])
     if database != DEFAULT_DB_ALIAS:
         applied_migrations = applied_migrations.using(database)
-    applied_migrations_lookup = dict(('%s.%s' % (mi.app_name, mi.migration), mi) for mi in applied_migrations)
+    applied_migrations_lookup = dict(('%s.%s' % (mi.app_name, mi.migration), mi)
+                                     for mi in applied_migrations)
 
     print()
     for app in apps:
@@ -133,16 +139,21 @@ def list_migrations(apps, database = DEFAULT_DB_ALIAS, **options):
             full_name = migration.app_label() + "." + migration.name()
             if full_name in applied_migrations_lookup:
                 applied_migration = applied_migrations_lookup[full_name]
-                print(format_migration_list_item(migration.name(), applied=applied_migration.applied, **options))
+                print(
+                    format_migration_list_item(
+                        migration.name(),
+                        applied=applied_migration.applied,
+                        **options))
             else:
                 print(format_migration_list_item(migration.name(), applied=False, **options))
         print()
 
+
 def show_migration_changes(apps):
     """
     Prints a list of all available migrations, and which ones are currently applied.
     Accepts a list of Migrations instances.
-    
+
     Much simpler, less clear, and much less robust version:
         grep "ing " migrations/*.py
     """
@@ -153,6 +164,7 @@ def show_migration_changes(apps):
         # we use reduce to compare models in pairs, not to generate a value
         reduce(diff_migrations, migrations)
 
+
 def format_migration_list_item(name, applied=True, **options):
     if applied:
         if int(options.get('verbosity')) >= 2:
@@ -161,17 +173,18 @@ def format_migration_list_item(name, applied=True, **options):
             return '  (*) %s' % name
     else:
         return '  ( ) %s' % name
-                            
+
+
 def diff_migrations(migration1, migration2):
-    
+
     def model_name(models, model):
         return models[model].get('Meta', {}).get('object_name', model)
-        
+
     def field_name(models, model, field):
         return '%s.%s' % (model_name(models, model), field)
-        
+
     print("  " + migration2.name())
-    
+
     models1 = migration1.migration_class().models
     models2 = migration2.migration_class().models
 
@@ -179,16 +192,16 @@ def diff_migrations(migration1, migration2):
     for model in models2.keys():
         if not model in models1.keys():
             print('    added model %s' % model_name(models2, model))
- 
+
     # find removed models
     for model in models1.keys():
         if not model in models2.keys():
             print('    removed model %s' % model_name(models1, model))
-            
+
     # compare models
     for model in models1:
         if model in models2:
-        
+
             # find added fields
             for field in models2[model]:
                 if not field in models1[model]:
@@ -198,67 +211,67 @@ def diff_migrations(migration1, migration2):
             for field in models1[model]:
                 if not field in models2[model]:
                     print('    removed field %s' % field_name(models1, model, field))
-                
+
             # compare fields
             for field in models1[model]:
                 if field in models2[model]:
-                
+
                     name = field_name(models1, model, field)
-                
+
                     # compare field attributes
                     field_value1 = models1[model][field]
                     field_value2 = models2[model][field]
-                    
+
                     # if a field has become a class, or vice versa
                     if type(field_value1) != type(field_value2):
                         print('    type of %s changed from %s to %s' % (
                             name, field_value1, field_value2))
-                    
+
                     # if class
                     elif isinstance(field_value1, dict):
                         # print '    %s is a class' % name
                         pass
-                    
+
                     # else regular field
                     else:
-                    
+
                         type1, attr_list1, field_attrs1 = models1[model][field]
                         type2, attr_list2, field_attrs2 = models2[model][field]
-                        
+
                         if type1 != type2:
                             print('    %s type changed from %s to %s' % (
                                 name, type1, type2))
-    
+
                         if attr_list1 != []:
                             print('    %s list %s is not []' % (
                                 name, attr_list1))
                         if attr_list2 != []:
                             print('    %s list %s is not []' % (
-                                name, attr_list2))    
+                                name, attr_list2))
                         if attr_list1 != attr_list2:
                             print('    %s list changed from %s to %s' % (
-                                name, attr_list1, attr_list2))                
-                                        
+                                name, attr_list1, attr_list2))
+
                         # find added field attributes
                         for attr in field_attrs2:
                             if not attr in field_attrs1:
                                 print('    added %s attribute %s=%s' % (
                                     name, attr, field_attrs2[attr]))
-                                
+
                         # find removed field attributes
                         for attr in field_attrs1:
                             if not attr in field_attrs2:
                                 print('    removed attribute %s(%s=%s)' % (
                                     name, attr, field_attrs1[attr]))
-                            
+
                         # compare field attributes
                         for attr in field_attrs1:
                             if attr in field_attrs2:
-                            
+
                                 value1 = field_attrs1[attr]
                                 value2 = field_attrs2[attr]
                                 if value1 != value2:
                                     print('    %s attribute %s changed from %s to %s' % (
                                         name, attr, value1, value2))
-    
+
     return migration2
diff --git a/src/south/management/commands/migrationcheck.py b/src/south/management/commands/migrationcheck.py
index f498d0b312..2c3eb036c6 100644
--- a/src/south/management/commands/migrationcheck.py
+++ b/src/south/management/commands/migrationcheck.py
@@ -9,6 +9,7 @@ from south.migration import Migrations
 from south.exceptions import NoMigrations
 from south.hacks import hacks
 
+
 class Command(BaseCommand):
     help = "Runs migrations for each app in turn, detecting missing depends_on values."
     usage_str = "Usage: ./manage.py migrationcheck"
@@ -55,7 +56,7 @@ class Command(BaseCommand):
             raise CommandError("Missing depends_on found in %s app(s)." % failures)
         self.stderr.write("No missing depends_on found.\n")
 #
-#for each app:
+# for each app:
 #    start with blank db.
 #    syncdb only south (and contrib?)
 #
diff --git a/src/south/management/commands/schemamigration.py b/src/south/management/commands/schemamigration.py
index efd4266f3d..ed2f298ef1 100644
--- a/src/south/management/commands/schemamigration.py
+++ b/src/south/management/commands/schemamigration.py
@@ -29,28 +29,30 @@ from south.exceptions import NoMigrations
 from south.creator import changes, actions, freezer
 from south.management.commands.datamigration import Command as DataCommand
 
+
 class Command(DataCommand):
     option_list = DataCommand.option_list + (
         make_option('--add-model', action='append', dest='added_model_list', type='string',
-            help='Generate a Create Table migration for the specified model.  Add multiple models to this migration with subsequent --add-model parameters.'),
+                    help='Generate a Create Table migration for the specified model.  Add multiple models to this migration with subsequent --add-model parameters.'),
         make_option('--add-field', action='append', dest='added_field_list', type='string',
-            help='Generate an Add Column migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
+                    help='Generate an Add Column migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
         make_option('--add-index', action='append', dest='added_index_list', type='string',
-            help='Generate an Add Index migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
+                    help='Generate an Add Index migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
         make_option('--initial', action='store_true', dest='initial', default=False,
-            help='Generate the initial schema for the app.'),
+                    help='Generate the initial schema for the app.'),
         make_option('--auto', action='store_true', dest='auto', default=False,
-            help='Attempt to automatically detect differences from the last migration.'),
+                    help='Attempt to automatically detect differences from the last migration.'),
         make_option('--empty', action='store_true', dest='empty', default=False,
-            help='Make a blank migration.'),
+                    help='Make a blank migration.'),
         make_option('--update', action='store_true', dest='update', default=False,
                     help='Update the most recent migration instead of creating a new one. Rollback this migration if it is already applied.'),
     )
     help = "Creates a new template schema migration for the given app"
     usage_str = "Usage: ./manage.py schemamigration appname migrationname [--empty] [--initial] [--auto] [--add-model ModelName] [--add-field ModelName.field_name] [--stdout]"
-    
-    def handle(self, app=None, name="", added_model_list=None, added_field_list=None, freeze_list=None, initial=False, auto=False, stdout=False, added_index_list=None, verbosity=1, empty=False, update=False, **options):
-        
+
+    def handle(self, app=None, name="", added_model_list=None, added_field_list=None, freeze_list=None, initial=False,
+               auto=False, stdout=False, added_index_list=None, verbosity=1, empty=False, update=False, **options):
+
         # Any supposed lists that are None become empty lists
         added_model_list = added_model_list or []
         added_field_list = added_field_list or []
@@ -60,21 +62,21 @@ class Command(DataCommand):
         # --stdout means name = -
         if stdout:
             name = "-"
-	
+
         # Only allow valid names
         if re.search('[^_\w]', name) and name != "-":
             self.error("Migration names should contain only alphanumeric characters and underscores.")
-        
+
         # Make sure options are compatable
         if initial and (added_model_list or added_field_list or auto):
             self.error("You cannot use --initial and other options together\n" + self.usage_str)
-        
+
         if auto and (added_model_list or added_field_list or initial):
             self.error("You cannot use --auto and other options together\n" + self.usage_str)
-        
+
         if not app:
             self.error("You must provide an app to create a migration for.\n" + self.usage_str)
-	    
+
         # See if the app exists
         app = app.split(".")[-1]
         try:
@@ -82,10 +84,10 @@ class Command(DataCommand):
         except ImproperlyConfigured:
             print("There is no enabled application matching '%s'." % app)
             return
-	
+
         # Get the Migrations for this app (creating the migrations dir if needed)
         migrations = Migrations(app, force_creation=True, verbose_creation=int(verbosity) > 0)
-        
+
         # What actions do we need to do?
         if auto:
             # Get the old migration
@@ -95,7 +97,9 @@ class Command(DataCommand):
                 self.error("You cannot use --auto on an app with no migrations. Try --initial.")
             # Make sure it has stored models
             if migrations.app_label() not in getattr(last_migration.migration_class(), "complete_apps", []):
-                self.error("You cannot use automatic detection, since the previous migration does not have this whole app frozen.\nEither make migrations using '--freeze %s' or set 'SOUTH_AUTO_FREEZE_APP = True' in your settings.py." % migrations.app_label())
+                self.error(
+                    "You cannot use automatic detection, since the previous migration does not have this whole app frozen.\nEither make migrations using '--freeze %s' or set 'SOUTH_AUTO_FREEZE_APP = True' in your settings.py." %
+                    migrations.app_label())
             # Alright, construct two model dicts to run the differ on.
             old_defs = dict(
                 (k, v) for k, v in last_migration.migration_class().models.items()
@@ -106,16 +110,16 @@ class Command(DataCommand):
                 if k.split(".")[0] == migrations.app_label()
             )
             change_source = changes.AutoChanges(
-                migrations = migrations,
-                old_defs = old_defs,
-                old_orm = last_migration.orm(),
-                new_defs = new_defs,
+                migrations=migrations,
+                old_defs=old_defs,
+                old_orm=last_migration.orm(),
+                new_defs=new_defs,
             )
-        
+
         elif initial:
             # Do an initial migration
             change_source = changes.InitialChanges(migrations)
-        
+
         else:
             # Read the commands manually off of the arguments
             if (added_model_list or added_field_list or added_index_list):
@@ -128,13 +132,15 @@ class Command(DataCommand):
             elif empty:
                 change_source = None
             else:
-                print("You have not passed any of --initial, --auto, --empty, --add-model, --add-field or --add-index.", file=sys.stderr)
+                print(
+                    "You have not passed any of --initial, --auto, --empty, --add-model, --add-field or --add-index.",
+                    file=sys.stderr)
                 sys.exit(1)
 
         # Validate this so we can access the last migration without worrying
         if update and not migrations:
             self.error("You cannot use --update on an app with no migrations.")
-        
+
         # if not name, there's an error
         if not name:
             if change_source:
@@ -143,7 +149,7 @@ class Command(DataCommand):
                 name = re.sub(r'^\d{4}_', '', migrations[-1].name())
             if not name:
                 self.error("You must provide a name for this migration\n" + self.usage_str)
-        
+
         # Get the actions, and then insert them into the actions lists
         forwards_actions = []
         backwards_actions = []
@@ -159,19 +165,19 @@ class Command(DataCommand):
                     action.add_forwards(forwards_actions)
                     action.add_backwards(backwards_actions)
                     print(action.console_line(), file=sys.stderr)
-        
+
         # Nowt happen? That's not good for --auto.
         if auto and not forwards_actions:
             self.error("Nothing seems to have changed.")
-        
+
         # Work out which apps to freeze
         apps_to_freeze = self.calc_frozen_apps(migrations, freeze_list)
-        
+
         # So, what's in this file, then?
         file_contents = self.get_migration_template() % {
             "forwards": "\n".join(forwards_actions or ["        pass"]),
             "backwards": "\n".join(backwards_actions or ["        pass"]),
-            "frozen_models":  freezer.freeze_apps_to_string(apps_to_freeze),
+            "frozen_models": freezer.freeze_apps_to_string(apps_to_freeze),
             "complete_apps": apps_to_freeze and "complete_apps = [%s]" % (", ".join(map(repr, apps_to_freeze))) or ""
         }
 
@@ -179,11 +185,15 @@ class Command(DataCommand):
         # as something else can go wrong.
         if update:
             last_migration = migrations[-1]
-            if MigrationHistory.objects.filter(applied__isnull=False, app_name=app, migration=last_migration.name()):
-                print("Migration to be updated, %s, is already applied, rolling it back now..." % last_migration.name(), file=sys.stderr)
+            if MigrationHistory.objects.filter(
+                    applied__isnull=False, app_name=app, migration=last_migration.name()):
+                print(
+                    "Migration to be updated, %s, is already applied, rolling it back now..." %
+                    last_migration.name(), file=sys.stderr)
                 migrate_app(migrations, 'current-1', verbosity=verbosity)
             for ext in ('py', 'pyc'):
-                old_filename = "%s.%s" % (os.path.join(migrations.migrations_dir(), last_migration.filename), ext)
+                old_filename = "%s.%s" % (os.path.join(
+                    migrations.migrations_dir(), last_migration.filename), ext)
                 if os.path.isfile(old_filename):
                     os.unlink(old_filename)
             migrations.remove(last_migration)
@@ -201,9 +211,13 @@ class Command(DataCommand):
             fp.close()
             verb = 'Updated' if update else 'Created'
             if empty:
-                print("%s %s. You must now edit this migration and add the code for each direction." % (verb, new_filename), file=sys.stderr)
+                print(
+                    "%s %s. You must now edit this migration and add the code for each direction." %
+                    (verb, new_filename), file=sys.stderr)
             else:
-                print("%s %s. You can now apply this migration with: ./manage.py migrate %s" % (verb, new_filename, app), file=sys.stderr)
+                print(
+                    "%s %s. You can now apply this migration with: ./manage.py migrate %s" %
+                    (verb, new_filename, app), file=sys.stderr)
 
     def get_migration_template(self):
         return MIGRATION_TEMPLATE
diff --git a/src/south/management/commands/startmigration.py b/src/south/management/commands/startmigration.py
index e4fcf458c9..ceec06910a 100644
--- a/src/south/management/commands/startmigration.py
+++ b/src/south/management/commands/startmigration.py
@@ -9,25 +9,27 @@ from optparse import make_option
 from django.core.management.base import BaseCommand
 from django.core.management.color import no_style
 
+
 class Command(BaseCommand):
     option_list = BaseCommand.option_list + (
         make_option('--model', action='append', dest='added_model_list', type='string',
-            help='Generate a Create Table migration for the specified model.  Add multiple models to this migration with subsequent --add-model parameters.'),
+                    help='Generate a Create Table migration for the specified model.  Add multiple models to this migration with subsequent --add-model parameters.'),
         make_option('--add-field', action='append', dest='added_field_list', type='string',
-            help='Generate an Add Column migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
+                    help='Generate an Add Column migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
         make_option('--add-index', action='append', dest='added_index_list', type='string',
-            help='Generate an Add Index migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
+                    help='Generate an Add Index migration for the specified modelname.fieldname - you can use this multiple times to add more than one column.'),
         make_option('--initial', action='store_true', dest='initial', default=False,
-            help='Generate the initial schema for the app.'),
+                    help='Generate the initial schema for the app.'),
         make_option('--auto', action='store_true', dest='auto', default=False,
-            help='Attempt to automatically detect differences from the last migration.'),
+                    help='Attempt to automatically detect differences from the last migration.'),
         make_option('--freeze', action='append', dest='freeze_list', type='string',
-            help='Freeze the specified model(s). Pass in either an app name (to freeze the whole app) or a single model, as appname.modelname.'),
+                    help='Freeze the specified model(s). Pass in either an app name (to freeze the whole app) or a single model, as appname.modelname.'),
         make_option('--stdout', action='store_true', dest='stdout', default=False,
-            help='Print the migration to stdout instead of writing it to a file.'),
+                    help='Print the migration to stdout instead of writing it to a file.'),
     )
     help = "Deprecated command"
-    
-    def handle(self, app=None, name="", added_model_list=None, added_field_list=None, initial=False, freeze_list=None, auto=False, stdout=False, added_index_list=None, **options):
-        
+
+    def handle(self, app=None, name="", added_model_list=None, added_field_list=None, initial=False,
+               freeze_list=None, auto=False, stdout=False, added_index_list=None, **options):
+
         print("The 'startmigration' command is now deprecated; please use the new 'schemamigration' and 'datamigration' commands.")
diff --git a/src/south/management/commands/syncdb.py b/src/south/management/commands/syncdb.py
index 17fc22cbfc..d2262f9c36 100644
--- a/src/south/management/commands/syncdb.py
+++ b/src/south/management/commands/syncdb.py
@@ -7,7 +7,7 @@ from __future__ import print_function
 import sys
 from optparse import make_option
 
-from django.core.management.base import NoArgsCommand, BaseCommand 
+from django.core.management.base import NoArgsCommand, BaseCommand
 from django.core.management.color import no_style
 from django.utils.datastructures import SortedDict
 from django.core.management.commands import syncdb
@@ -20,33 +20,35 @@ from south.db import dbs
 from south import migration
 from south.exceptions import NoMigrations
 
+
 def get_app_label(app):
-    return '.'.join( app.__name__.split('.')[0:-1] )
+    return '.'.join(app.__name__.split('.')[0:-1])
+
 
 class Command(NoArgsCommand):
-    option_list = syncdb.Command.option_list + ( 
+    option_list = syncdb.Command.option_list + (
         make_option('--migrate', action='store_true', dest='migrate', default=False,
-            help='Tells South to also perform migrations after the sync. Default for during testing, and other internal calls.'),
+                    help='Tells South to also perform migrations after the sync. Default for during testing, and other internal calls.'),
         make_option('--all', action='store_true', dest='migrate_all', default=False,
-            help='Makes syncdb work on all apps, even migrated ones. Be careful!'),
+                    help='Makes syncdb work on all apps, even migrated ones. Be careful!'),
     )
     if '--verbosity' not in [opt.get_opt_string() for opt in syncdb.Command.option_list]:
         option_list += (
             make_option('--verbosity', action='store', dest='verbosity', default='1',
-            type='choice', choices=['0', '1', '2'],
-            help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
+                        type='choice', choices=['0', '1', '2'],
+                        help='Verbosity level; 0=minimal output, 1=normal output, 2=all output'),
         )
     help = "Create the database tables for all apps in INSTALLED_APPS whose tables haven't already been created, except those which use migrations."
 
     def handle_noargs(self, migrate_all=False, **options):
-        
+
         # Import the 'management' module within each installed app, to register
         # dispatcher events.
         # This is copied from Django, to fix bug #511.
         try:
             from django.utils.importlib import import_module
         except ImportError:
-            pass # TODO: Remove, only for Django1.0
+            pass  # TODO: Remove, only for Django1.0
         else:
             for app_name in settings.INSTALLED_APPS:
                 try:
@@ -55,7 +57,7 @@ class Command(NoArgsCommand):
                     msg = exc.args[0]
                     if not msg.startswith('No module named') or 'management' not in msg:
                         raise
-        
+
         # Work out what uses migrations and so doesn't need syncing
         apps_needing_sync = []
         apps_migrated = []
@@ -73,27 +75,27 @@ class Command(NoArgsCommand):
                     # This is a migrated app, leave it
                     apps_migrated.append(app_label)
         verbosity = int(options.get('verbosity', 0))
-        
+
         # Run syncdb on only the ones needed
         if verbosity:
             print("Syncing...")
-        
+
         old_installed, settings.INSTALLED_APPS = settings.INSTALLED_APPS, apps_needing_sync
         old_app_store, cache.app_store = cache.app_store, SortedDict([
             (k, v) for (k, v) in cache.app_store.items()
             if get_app_label(k) in apps_needing_sync
         ])
-        
+
         # This will allow the setting of the MySQL storage engine, for example.
-        for db in dbs.values(): 
-            db.connection_init() 
-        
+        for db in dbs.values():
+            db.connection_init()
+
         # OK, run the actual syncdb
         syncdb.Command().execute(**options)
-        
+
         settings.INSTALLED_APPS = old_installed
         cache.app_store = old_app_store
-        
+
         # Migrate if needed
         if options.get('migrate', True):
             if verbosity:
@@ -101,11 +103,11 @@ class Command(NoArgsCommand):
             # convert from store_true to store_false
             options['no_initial_data'] = not options.get('load_initial_data', True)
             management.call_command('migrate', **options)
-        
+
         # Be obvious about what we did
         if verbosity:
             print("\nSynced:\n > %s" % "\n > ".join(apps_needing_sync))
-        
+
         if options.get('migrate', True):
             if verbosity:
                 print("\nMigrated:\n - %s" % "\n - ".join(apps_migrated))
diff --git a/src/south/management/commands/test.py b/src/south/management/commands/test.py
index 990178637a..bc721bb15b 100644
--- a/src/south/management/commands/test.py
+++ b/src/south/management/commands/test.py
@@ -2,6 +2,7 @@ from django.core.management.commands import test
 
 from south.management.commands import patch_for_test_db_setup
 
+
 class Command(test.Command):
     def handle(self, *args, **kwargs):
         patch_for_test_db_setup()
diff --git a/src/south/management/commands/testserver.py b/src/south/management/commands/testserver.py
index 3c3c4b5ecc..5f2cc6efd0 100644
--- a/src/south/management/commands/testserver.py
+++ b/src/south/management/commands/testserver.py
@@ -2,6 +2,7 @@ from django.core.management.commands import testserver
 
 from south.management.commands import patch_for_test_db_setup
 
+
 class Command(testserver.Command):
     def handle(self, *args, **kwargs):
         patch_for_test_db_setup()
diff --git a/src/south/migration/__init__.py b/src/south/migration/__init__.py
index 1d91ddf83d..19afdbae55 100644
--- a/src/south/migration/__init__.py
+++ b/src/south/migration/__init__.py
@@ -24,9 +24,11 @@ from south.signals import pre_migrate, post_migrate
 def to_apply(forwards, done):
     return [m for m in forwards if m not in done]
 
+
 def to_unapply(backwards, done):
     return [m for m in backwards if m in done]
 
+
 def problems(pending, done):
     last = None
     if not pending:
@@ -38,6 +40,7 @@ def problems(pending, done):
         if last and migration not in done:
             yield last, migration
 
+
 def forwards_problems(pending, done, verbosity):
     """
     Takes the list of linearised pending migrations, and the set of done ones,
@@ -45,9 +48,11 @@ def forwards_problems(pending, done, verbosity):
     """
     return inner_problem_check(problems(reversed(pending), done), done, verbosity)
 
+
 def backwards_problems(pending, done, verbosity):
     return inner_problem_check(problems(pending, done), done, verbosity)
 
+
 def inner_problem_check(problems, done, verbosity):
     "Takes a set of possible problems and gets the actual issues out of it."
     result = []
@@ -72,6 +77,7 @@ def inner_problem_check(problems, done, verbosity):
                 to_check.extend(checking.dependencies)
     return result
 
+
 def check_migration_histories(histories, delete_ghosts=False, ignore_ghosts=False):
     "Checks that there's no 'ghost' migrations in the database."
     exists = SortedSet()
@@ -95,6 +101,7 @@ def check_migration_histories(histories, delete_ghosts=False, ignore_ghosts=Fals
             raise exceptions.GhostMigrations(ghosts)
     return exists
 
+
 def get_dependencies(target, migrations):
     forwards = list
     backwards = list
@@ -110,6 +117,7 @@ def get_dependencies(target, migrations):
             backwards = migration_before_here.backwards_plan
     return forwards, backwards
 
+
 def get_direction(target, applied, migrations, verbosity, interactive):
     # Get the forwards and reverse dependencies for this target
     forwards, backwards = get_dependencies(target, migrations)
@@ -138,6 +146,7 @@ def get_direction(target, applied, migrations, verbosity, interactive):
             direction = Backwards(verbosity=verbosity, interactive=interactive)
     return direction, problems, workplan
 
+
 def get_migrator(direction, db_dry_run, fake, load_initial_data):
     if not direction:
         return direction
@@ -149,42 +158,47 @@ def get_migrator(direction, db_dry_run, fake, load_initial_data):
         direction = LoadInitialDataMigrator(migrator=direction)
     return direction
 
+
 def get_unapplied_migrations(migrations, applied_migrations):
-    applied_migration_names = ['%s.%s' % (mi.app_name,mi.migration) for mi in applied_migrations]
+    applied_migration_names = ['%s.%s' % (mi.app_name, mi.migration) for mi in applied_migrations]
 
     for migration in migrations:
         is_applied = '%s.%s' % (migration.app_label(), migration.name()) in applied_migration_names
         if not is_applied:
             yield migration
 
-def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_run=False, yes=False, verbosity=0, load_initial_data=False, skip=False, database=DEFAULT_DB_ALIAS, delete_ghosts=False, ignore_ghosts=False, interactive=False):
+
+def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_run=False, yes=False, verbosity=0,
+                load_initial_data=False, skip=False, database=DEFAULT_DB_ALIAS, delete_ghosts=False, ignore_ghosts=False, interactive=False):
     app_label = migrations.app_label()
 
     verbosity = int(verbosity)
     # Fire off the pre-migrate signal
     pre_migrate.send(None, app=app_label, verbosity=verbosity, interactive=verbosity, db=database)
-    
+
     # If there aren't any, quit quizically
     if not migrations:
         print("? You have no migrations for the '%s' app. You might want some." % app_label)
         return
-    
+
     # Load the entire dependency graph
     Migrations.calculate_dependencies()
-    
+
     # Check there's no strange ones in the database
-    applied_all = MigrationHistory.objects.filter(applied__isnull=False).order_by('applied').using(database)
+    applied_all = MigrationHistory.objects.filter(
+        applied__isnull=False).order_by('applied').using(database)
     applied = applied_all.filter(app_name=app_label).using(database)
     south.db.db = south.db.dbs[database]
     Migrations.invalidate_all_modules()
-    
+
     south.db.db.debug = (verbosity > 1)
 
     if target_name == 'current-1':
         if applied.count() > 1:
             previous_migration = applied[applied.count() - 2]
             if verbosity:
-                print('previous_migration: %s (applied: %s)' % (previous_migration.migration, previous_migration.applied))
+                print('previous_migration: %s (applied: %s)' %
+                      (previous_migration.migration, previous_migration.applied))
             target_name = previous_migration.migration
         else:
             if verbosity:
@@ -196,9 +210,9 @@ def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_ru
             target_name = first_unapplied_migration.name()
         except StopIteration:
             target_name = None
-    
+
     applied_all = check_migration_histories(applied_all, delete_ghosts, ignore_ghosts)
-    
+
     # Guess the target_name
     target = migrations.guess_migration(target_name)
     if verbosity:
@@ -206,13 +220,13 @@ def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_ru
             print(" - Soft matched migration %s to %s." % (target_name,
                                                            target.name()))
         print("Running migrations for %s:" % app_label)
-    
+
     # Get the forwards and reverse dependencies for this target
     direction, problems, workplan = get_direction(target, applied_all, migrations,
                                                   verbosity, interactive)
     if problems and not (merge or skip):
         raise exceptions.InconsistentMigrationHistory(problems)
-    
+
     # Perform the migration
     migrator = get_migrator(direction, db_dry_run, fake, load_initial_data)
     if migrator:
@@ -220,7 +234,12 @@ def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_ru
         success = migrator.migrate_many(target, workplan, database)
         # Finally, fire off the post-migrate signal
         if success:
-            post_migrate.send(None, app=app_label, verbosity=verbosity, interactive=verbosity, db=database)
+            post_migrate.send(
+                None,
+                app=app_label,
+                verbosity=verbosity,
+                interactive=verbosity,
+                db=database)
     else:
         if verbosity:
             # Say there's nothing.
@@ -232,4 +251,9 @@ def migrate_app(migrations, target_name=None, merge=False, fake=False, db_dry_ru
             migrator = LoadInitialDataMigrator(migrator=Forwards(verbosity=verbosity))
             migrator.load_initial_data(target, db=database)
         # Send signal.
-        post_migrate.send(None, app=app_label, verbosity=verbosity, interactive=verbosity, db=database)
+        post_migrate.send(
+            None,
+            app=app_label,
+            verbosity=verbosity,
+            interactive=verbosity,
+            db=database)
diff --git a/src/south/migration/base.py b/src/south/migration/base.py
index 9241a4592b..8614c4891d 100644
--- a/src/south/migration/base.py
+++ b/src/south/migration/base.py
@@ -19,6 +19,7 @@ from south.utils import memoize, ask_for_it_by_name, datetime_utils
 from south.migration.utils import app_label_to_app_module
 from south.utils.py3 import string_types, with_metaclass
 
+
 def all_migrations(applications=None):
     """
     Returns all Migrations for all `applications` that are migrated.
@@ -45,24 +46,26 @@ def application_to_app_label(application):
 
 
 class MigrationsMetaclass(type):
-    
+
     """
     Metaclass which ensures there is only one instance of a Migrations for
     any given app.
     """
-    
+
     def __init__(self, name, bases, dict):
         super(MigrationsMetaclass, self).__init__(name, bases, dict)
         self.instances = {}
-    
+
     def __call__(self, application, **kwds):
-        
+
         app_label = application_to_app_label(application)
-        
+
         # If we don't already have an instance, make one
         if app_label not in self.instances:
-            self.instances[app_label] = super(MigrationsMetaclass, self).__call__(app_label_to_app_module(app_label), **kwds)
-        
+            self.instances[app_label] = super(
+                MigrationsMetaclass, self).__call__(
+                app_label_to_app_module(app_label), **kwds)
+
         return self.instances[app_label]
 
     def _clear_cache(self):
@@ -74,21 +77,25 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
     """
     Holds a list of Migration objects for a particular app.
     """
-    
+
     if getattr(settings, "SOUTH_USE_PYC", False):
-        MIGRATION_FILENAME = re.compile(r'(?!__init__)' # Don't match __init__.py
-                                        r'[0-9a-zA-Z_]*' # Don't match dotfiles, or names with dots/invalid chars in them
+        MIGRATION_FILENAME = re.compile(r'(?!__init__)'  # Don't match __init__.py
+                                        # Don't match dotfiles, or names with dots/invalid chars in
+                                        # them
+                                        r'[0-9a-zA-Z_]*'
                                         r'(\.pyc?)?$')     # Match .py or .pyc files, or module dirs
     else:
-        MIGRATION_FILENAME = re.compile(r'(?!__init__)' # Don't match __init__.py
-                                        r'[0-9a-zA-Z_]*' # Don't match dotfiles, or names with dots/invalid chars in them
+        MIGRATION_FILENAME = re.compile(r'(?!__init__)'  # Don't match __init__.py
+                                        # Don't match dotfiles, or names with dots/invalid chars in
+                                        # them
+                                        r'[0-9a-zA-Z_]*'
                                         r'(\.py)?$')       # Match only .py files, or module dirs
 
     def __init__(self, application, force_creation=False, verbose_creation=True):
         "Constructor. Takes the module of the app, NOT its models (like get_app returns)"
         self._cache = {}
         self.set_application(application, force_creation, verbose_creation)
-    
+
     def create_migrations_directory(self, verbose=True):
         "Given an application, ensures that the migrations directory is ready."
         migrations_dir = self.migrations_dir()
@@ -104,7 +111,7 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
             if verbose:
                 print("Creating __init__.py in '%s'..." % migrations_dir)
             open(init_path, "w").close()
-    
+
     def migrations_dir(self):
         """
         Returns the full path of the migrations directory.
@@ -121,8 +128,8 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
             except ImportError:
                 # The parent doesn't even exist, that's an issue.
                 raise exceptions.InvalidMigrationModule(
-                    application = self.application.__name__,
-                    module = module_path,
+                    application=self.application.__name__,
+                    module=module_path,
                 )
             else:
                 # Good guess.
@@ -130,7 +137,7 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
         else:
             # Get directory directly
             return os.path.dirname(module.__file__)
-    
+
     def migrations_module(self):
         "Returns the module name of the migrations module for this"
         app_label = application_to_app_label(self.application)
@@ -187,9 +194,9 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
                     continue
                 # If it's a module directory, only append if it contains __init__.py[c].
                 if os.path.isdir(full_path):
-                    if not (os.path.isfile(os.path.join(full_path, "__init__.py")) or \
-                      (getattr(settings, "SOUTH_USE_PYC", False) and \
-                      os.path.isfile(os.path.join(full_path, "__init__.pyc")))):
+                    if not (os.path.isfile(os.path.join(full_path, "__init__.py")) or
+                            (getattr(settings, "SOUTH_USE_PYC", False) and
+                             os.path.isfile(os.path.join(full_path, "__init__.pyc")))):
                         continue
                 filenames.append(f)
         filenames.sort()
@@ -223,7 +230,7 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
             return self[-1]
         else:
             return self._guess_migration(prefix=target_name)
-    
+
     def app_label(self):
         return self._application.__name__.split('.')[-1]
 
@@ -239,14 +246,14 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
             for migration in migrations:
                 migration.calculate_dependencies()
         cls._dependencies_done = True
-    
+
     @staticmethod
     def invalidate_all_modules():
         "Goes through all the migrations, and invalidates all cached modules."
         for migrations in all_migrations():
             for migration in migrations:
                 migration.invalidate_module()
-    
+
     def next_filename(self, name):
         "Returns the fully-formatted filename of what a new migration 'name' would be"
         highest_number = 0
@@ -264,11 +271,11 @@ class Migrations(with_metaclass(MigrationsMetaclass, list)):
 
 
 class Migration(object):
-    
+
     """
     Class which represents a particular migration file on-disk.
     """
-    
+
     def __init__(self, migrations, filename):
         """
         Returns the migration class implied by 'filename'.
@@ -345,7 +352,7 @@ class Migration(object):
             return None
         return self.migrations[index]
     next = memoize(next)
-    
+
     def _get_dependency_objects(self, attrname):
         """
         Given the name of an attribute (depends_on or needed_by), either yields
@@ -364,7 +371,7 @@ class Migration(object):
             if migration.is_before(self) == False:
                 raise exceptions.DependsOnHigherMigration(self, migration)
             yield migration
-    
+
     def calculate_dependencies(self):
         """
         Loads dependency info for this migration, and stores it in itself
@@ -383,7 +390,7 @@ class Migration(object):
         if previous:
             self.dependencies.add(previous)
             previous.dependents.add(self)
-    
+
     def invalidate_module(self):
         """
         Removes the cached version of this migration's module import, so we
diff --git a/src/south/migration/migrators.py b/src/south/migration/migrators.py
index ad064ead74..5fd782eff3 100644
--- a/src/south/migration/migrators.py
+++ b/src/south/migration/migrators.py
@@ -87,7 +87,7 @@ class Migrator(object):
                 # record us as having done this in the same transaction,
                 # since we're not in a dry run
                 self.record(migration, database)
-        except:
+        except BaseException:
             south.db.db.rollback_transaction()
             if not south.db.db.has_ddl_transactions:
                 print(self.run_migration_error(migration))
@@ -96,11 +96,10 @@ class Migrator(object):
         else:
             try:
                 south.db.db.commit_transaction()
-            except:
+            except BaseException:
                 print("Error during commit in migration: %s" % migration)
                 raise
 
-
     def run(self, migration, database):
         # Get the correct ORM.
         south.db.db.current_orm = self.orm(migration)
@@ -113,7 +112,6 @@ class Migrator(object):
                 dry_run.run_migration(migration, database)
         return self.run_migration(migration, database)
 
-
     def send_ran_migration(self, migration, database):
         ran_migration.send(None,
                            app=migration.app_label(),
@@ -174,7 +172,7 @@ class DryRunMigrator(MigratorWrapper):
             try:
                 migration_function()
                 south.db.db.execute_deferred_sql()
-            except:
+            except BaseException:
                 raise exceptions.FailedDryRun(migration, sys.exc_info())
         finally:
             south.db.db.rollback_transactions_dry_run()
@@ -227,7 +225,8 @@ class LoadInitialDataMigrator(MigratorWrapper):
         # Override Django's get_apps call temporarily to only load from the
         # current app
         old_get_apps = models.get_apps
-        new_get_apps = lambda: [models.get_app(target.app_label())]
+
+        def new_get_apps(): return [models.get_app(target.app_label())]
         models.get_apps = new_get_apps
         loaddata.get_apps = new_get_apps
         try:
@@ -238,17 +237,17 @@ class LoadInitialDataMigrator(MigratorWrapper):
 
     def post_1_6(self, target, db):
         import django.db.models.loading
-        ## build a new 'AppCache' object with just the app we care about.
+        # build a new 'AppCache' object with just the app we care about.
         old_cache = django.db.models.loading.cache
         new_cache = django.db.models.loading.AppCache()
         new_cache.get_apps = lambda: [new_cache.get_app(target.app_label())]
 
-        ## monkeypatch
+        # monkeypatch
         django.db.models.loading.cache = new_cache
         try:
             call_command('loaddata', 'initial_data', verbosity=self.verbosity, database=db)
         finally:
-            ## unmonkeypatch
+            # unmonkeypatch
             django.db.models.loading.cache = old_cache
 
     def migrate_many(self, target, migrations, database):
@@ -311,7 +310,7 @@ class Forwards(Migrator):
             try:
                 self.backwards(migration)()
                 return sys.stdout.getvalue()
-            except:
+            except BaseException:
                 raise
         finally:
             south.db.db.debug, south.db.db.dry_run = old_debug, old_dry_run
@@ -329,7 +328,7 @@ class Forwards(Migrator):
         try:
             for migration in migrations:
                 result = self.migrate(migration, database)
-                if result is False: # The migrations errored, but nicely.
+                if result is False:  # The migrations errored, but nicely.
                     return False
         finally:
             # Call any pending post_syncdb signals
@@ -376,6 +375,3 @@ class Backwards(Migrator):
         for migration in migrations:
             self.migrate(migration, database)
         return True
-
-
-
diff --git a/src/south/migration/utils.py b/src/south/migration/utils.py
index 68b91645ac..c27cf16801 100644
--- a/src/south/migration/utils.py
+++ b/src/south/migration/utils.py
@@ -64,8 +64,10 @@ def flatten(*stack):
         else:
             yield x
 
+
 dependency_cache = {}
 
+
 def _dfs(start, get_children, path):
     if (start, get_children) in dependency_cache:
         return dependency_cache[(start, get_children)]
@@ -76,7 +78,7 @@ def _dfs(start, get_children, path):
     path.append(start)
     results.append(start)
     children = sorted(get_children(start), key=lambda x: str(x))
-    
+
     # We need to apply all the migrations this one depends on
     for n in children:
         results = _dfs(n, get_children, path) + results
@@ -87,8 +89,10 @@ def _dfs(start, get_children, path):
     dependency_cache[(start, get_children)] = results
     return results
 
+
 def dfs(start, get_children):
     return _dfs(start, get_children, [])
 
+
 def depends(start, get_children):
     return dfs(start, get_children)
diff --git a/src/south/models.py b/src/south/models.py
index 70f40c99f0..99845d221d 100644
--- a/src/south/models.py
+++ b/src/south/models.py
@@ -5,7 +5,9 @@ from south.db import DEFAULT_DB_ALIAS
 # Placed here so it's guaranteed to be imported on Django start
 import django
 if django.VERSION[0] > 1 or (django.VERSION[0] == 1 and django.VERSION[1] > 6):
-    raise RuntimeError("South does not support Django 1.7 or higher. Please use native Django migrations.")
+    raise RuntimeError(
+        "South does not support Django 1.7 or higher. Please use native Django migrations.")
+
 
 class MigrationHistory(models.Model):
     app_name = models.CharField(max_length=255)
@@ -38,6 +40,6 @@ class MigrationHistory(models.Model):
 
     def get_migration(self):
         return self.get_migrations().migration(self.migration)
-    
+
     def __str__(self):
         return "<%s: %s>" % (self.app_name, self.migration)
diff --git a/src/south/modelsinspector.py b/src/south/modelsinspector.py
index 13e493d2dc..a2c5e6e820 100644
--- a/src/south/modelsinspector.py
+++ b/src/south/modelsinspector.py
@@ -47,13 +47,25 @@ def convert_on_delete_handler(value):
                     return "%s.SET_NULL" % (django_db_models_module)
                 # simple function we can perhaps cope with:
                 elif hasattr(closure_contents, '__call__'):
-                    raise ValueError("South does not support on_delete with SET(function) as values.")
+                    raise ValueError(
+                        "South does not support on_delete with SET(function) as values.")
                 else:
                     # Attempt to serialise the value
                     return "%s.SET(%s)" % (django_db_models_module, value_clean(closure_contents))
-        raise ValueError("%s was not recognized as a valid model deletion handler. Possible values: %s." % (value, ', '.join(f.__name__ for f in (models.CASCADE, models.PROTECT, models.SET, models.SET_NULL, models.SET_DEFAULT, models.DO_NOTHING))))
+        raise ValueError(
+            "%s was not recognized as a valid model deletion handler. Possible values: %s." %
+            (value,
+             ', '.join(
+                 f.__name__ for f in (
+                     models.CASCADE,
+                     models.PROTECT,
+                     models.SET,
+                     models.SET_NULL,
+                     models.SET_DEFAULT,
+                     models.DO_NOTHING))))
     else:
-        raise ValueError("on_delete argument encountered in Django version that does not support it")
+        raise ValueError(
+            "on_delete argument encountered in Django version that does not support it")
 
 # Gives information about how to introspect certain fields.
 # This is a list of triples; the first item is a list of fields it applies to,
@@ -66,14 +78,15 @@ def convert_on_delete_handler(value):
 # is an optional dict.
 #
 # The introspector uses the combination of all matching entries, in order.
-                                     
+
+
 introspection_details = [
     (
         (models.Field, ),
         [],
         {
             "null": ["null", {"default": False}],
-            "blank": ["blank", {"default": False, "ignore_if":"primary_key"}],
+            "blank": ["blank", {"default": False, "ignore_if": "primary_key"}],
             "primary_key": ["primary_key", {"default": False}],
             "max_length": ["max_length", {"default": None}],
             "unique": ["_unique", {"default": False}],
@@ -91,7 +104,14 @@ introspection_details = [
             ("to_field", ["rel.field_name", {"default_attr": "rel.to._meta.pk.name"}]),
             ("related_name", ["rel.related_name", {"default": None}]),
             ("db_index", ["db_index", {"default": True}]),
-            ("on_delete", ["rel.on_delete", {"default": getattr(models, "CASCADE", None), "is_django_function": True, "converter": convert_on_delete_handler, "ignore_missing": True}])
+            ("on_delete",
+             ["rel.on_delete",
+              {"default": getattr(models,
+                                  "CASCADE",
+                                  None),
+               "is_django_function": True,
+               "converter": convert_on_delete_handler,
+               "ignore_missing": True}])
         ])
     ),
     (
@@ -134,7 +154,7 @@ introspection_details = [
         [],
         {
             "default": ["default", {"default": NOT_PROVIDED, "converter": bool}],
-            "blank": ["blank", {"default": True, "ignore_if":"primary_key"}],
+            "blank": ["blank", {"default": True, "ignore_if": "primary_key"}],
         },
     ),
     (
@@ -196,7 +216,7 @@ def add_ignored_fields(patterns):
     "Allows you to add some ignore field patterns."
     assert isinstance(patterns, (list, tuple))
     ignored_fields.extend(patterns)
-    
+
 
 def can_ignore(field):
     """
@@ -262,7 +282,7 @@ def get_value(field, descriptor):
                 raise IsDefault
             else:
                 raise
-            
+
     # Lazy-eval functions get eval'd.
     if isinstance(value, Promise):
         value = text_type(value)
@@ -298,7 +318,8 @@ def value_clean(value, options={}):
     if isinstance(value, Promise):
         value = text_type(value)
     # Callables get called.
-    if not options.get('is_django_function', False) and callable(value) and not isinstance(value, ModelBase):
+    if not options.get('is_django_function', False) and callable(
+            value) and not isinstance(value, ModelBase):
         # Datetime.datetime.now is special, as we can access it from the eval
         # context (and because it changes all the time; people will file bugs otherwise).
         if value == datetime.datetime.now:
@@ -323,7 +344,8 @@ def value_clean(value, options={}):
     if isinstance(value, Model):
         if options.get("ignore_dynamics", False):
             raise IsDefault
-        return "orm['%s.%s'].objects.get(pk=%r)" % (value.__class__._meta.app_label, value.__class__._meta.object_name, value.pk)
+        return "orm['%s.%s'].objects.get(pk=%r)" % (
+            value.__class__._meta.app_label, value.__class__._meta.object_name, value.pk)
     # Make sure Decimal is converted down into a string
     if isinstance(value, decimal.Decimal):
         value = str(value)
@@ -380,22 +402,22 @@ def get_model_fields(model, m2m=False):
     """
     Given a model class, returns a dict of {field_name: field_triple} defs.
     """
-    
+
     field_defs = SortedDict()
     inherited_fields = {}
-    
+
     # Go through all bases (that are themselves models, but not Model)
     for base in model.__bases__:
         if hasattr(base, '_meta') and issubclass(base, models.Model):
             if not base._meta.abstract:
                 # Looks like we need their fields, Ma.
                 inherited_fields.update(get_model_fields(base))
-    
+
     # Now, go through all the fields and try to get their definition
     source = model._meta.local_fields[:]
     if m2m:
         source += model._meta.local_many_to_many
-    
+
     for field in source:
         # Can we ignore it completely?
         if can_ignore(field):
@@ -421,12 +443,12 @@ def get_model_fields(model, m2m=False):
             if NOISY:
                 print(" ( Nodefing field: %s" % field.name)
             field_defs[field.name] = None
-    
+
     # If they've used the horrific hack that is order_with_respect_to, deal with
     # it.
     if model._meta.order_with_respect_to:
         field_defs['_order'] = ("django.db.models.fields.IntegerField", [], {"default": "0"})
-    
+
     return field_defs
 
 
@@ -434,7 +456,7 @@ def get_model_meta(model):
     """
     Given a model class, will return the dict representing the Meta class.
     """
-    
+
     # Get the introspected attributes
     meta_def = {}
     for kwd, defn in meta_details.items():
@@ -442,7 +464,7 @@ def get_model_meta(model):
             meta_def[kwd] = get_value(model._meta, defn)
         except IsDefault:
             pass
-    
+
     # Also, add on any non-abstract model base classes.
     # This is called _ormbases as the _bases variable was previously used
     # for a list of full class paths to bases, so we can't conflict.
@@ -456,7 +478,7 @@ def get_model_meta(model):
                     base._meta.app_label,
                     base._meta.object_name,
                 ))
-    
+
     return meta_def
 
 
diff --git a/src/south/orm.py b/src/south/orm.py
index 8d46ee7194..705d37b199 100644
--- a/src/south/orm.py
+++ b/src/south/orm.py
@@ -19,16 +19,16 @@ from south.utils.py3 import string_types
 
 
 class ModelsLocals(object):
-    
+
     """
     Custom dictionary-like class to be locals();
     falls back to lowercase search for items that don't exist
     (because we store model names as lowercase).
     """
-    
+
     def __init__(self, data):
         self.data = data
-    
+
     def __getitem__(self, key):
         try:
             return self.data[key]
@@ -39,13 +39,14 @@ class ModelsLocals(object):
 # Stores already-created ORMs.
 _orm_cache = {}
 
+
 def FakeORM(*args):
     """
     Creates a Fake Django ORM.
     This is actually a memoised constructor; the real class is _FakeORM.
     """
     if not args in _orm_cache:
-        _orm_cache[args] = _FakeORM(*args)  
+        _orm_cache[args] = _FakeORM(*args)
     return _orm_cache[args]
 
 
@@ -55,11 +56,11 @@ class LazyFakeORM(object):
     for a Migration class. Assign the result of this to (for example)
     .orm, and as soon as .orm is accessed the ORM will be created.
     """
-    
+
     def __init__(self, *args):
         self._args = args
         self.orm = None
-    
+
     def __get__(self, obj, type=None):
         if not self.orm:
             self.orm = FakeORM(*self._args)
@@ -67,12 +68,12 @@ class LazyFakeORM(object):
 
 
 class _FakeORM(object):
-    
+
     """
     Simulates the Django ORM at some point in time,
     using a frozen definition on the Migration class.
     """
-    
+
     def __init__(self, cls, app):
         self.default_app = app
         self.cls = cls
@@ -82,10 +83,10 @@ class _FakeORM(object):
             self.models_source = cls.models
         except AttributeError:
             return
-        
+
         # Start a 'new' AppCache
         hacks.clear_app_cache()
-        
+
         # Now, make each model's data into a FakeModel
         # We first make entries for each model that are just its name
         # This allows us to have circular model dependency loops
@@ -99,16 +100,16 @@ class _FakeORM(object):
             except ValueError:
                 app_label = self.default_app
                 model_name = name
-            
+
             # If there's an object_name in the Meta, use it and remove it
             if "object_name" in data['Meta']:
                 model_name = data['Meta']['object_name']
                 del data['Meta']['object_name']
-            
+
             name = "%s.%s" % (app_label, model_name)
             self.models[name.lower()] = name
             model_names.append((name.lower(), app_label, model_name, data))
-        
+
         # Loop until model_names is entry, or hasn't shrunk in size since
         # last iteration.
         # The make_model method can ask to postpone a model; it's then pushed
@@ -129,30 +130,29 @@ class _FakeORM(object):
                     postponed_model_names.append((name, app_label, model_name, data))
             # Reset
             model_names = postponed_model_names
-        
+
         # And perform the second run to iron out any circular/backwards depends.
         self.retry_failed_fields()
-        
+
         # Force evaluation of relations on the models now
         for model in self.models.values():
             model._meta.get_all_field_names()
-        
+
         # Reset AppCache
         hacks.unclear_app_cache()
-    
-    
+
     def __iter__(self):
         return iter(self.models.values())
 
-    
     def __getattr__(self, key):
-        fullname = (self.default_app+"."+key).lower()
+        fullname = (self.default_app + "." + key).lower()
         try:
             return self.models[fullname]
         except KeyError:
-            raise AttributeError("The model '%s' from the app '%s' is not available in this migration. (Did you use orm.ModelName, not orm['app.ModelName']?)" % (key, self.default_app))
-    
-    
+            raise AttributeError(
+                "The model '%s' from the app '%s' is not available in this migration. (Did you use orm.ModelName, not orm['app.ModelName']?)" %
+                (key, self.default_app))
+
     def __getitem__(self, key):
         # Detect if they asked for a field on a model or not.
         if ":" in key:
@@ -169,17 +169,18 @@ class _FakeORM(object):
             except ValueError:
                 raise KeyError("The model '%s' is not in appname.modelname format." % key)
             else:
-                raise KeyError("The model '%s' from the app '%s' is not available in this migration." % (model, app))
+                raise KeyError(
+                    "The model '%s' from the app '%s' is not available in this migration." %
+                    (model, app))
         # If they asked for a field, get it.
         if fname:
             return model._meta.get_field_by_name(fname)[0]
         else:
             return model
-    
-    
+
     def eval_in_context(self, code, app, extra_imports={}):
         "Evaluates the given code in the context of the migration file."
-        
+
         # Drag in the migration module's locals (hopefully including models.py)
         # excluding all models from that (i.e. from modern models.py), to stop pollution
         fake_locals = dict(
@@ -191,29 +192,29 @@ class _FakeORM(object):
                 and hasattr(value, "_meta")
             )
         )
-        
+
         # We add our models into the locals for the eval
         fake_locals.update(dict([
             (name.split(".")[-1], model)
             for name, model in self.models.items()
         ]))
-        
+
         # Make sure the ones for this app override.
         fake_locals.update(dict([
             (name.split(".")[-1], model)
             for name, model in self.models.items()
             if name.split(".")[0] == app
         ]))
-        
+
         # Ourselves as orm, to allow non-fail cross-app referencing
         fake_locals['orm'] = self
-        
+
         # And a fake _ function
         fake_locals['_'] = lambda x: x
-        
+
         # Datetime; there should be no datetime direct accesses
         fake_locals['datetime'] = datetime_utils
-        
+
         # Now, go through the requested imports and import them.
         for name, value in extra_imports.items():
             # First, try getting it out of locals.
@@ -235,13 +236,12 @@ class _FakeORM(object):
                     raise ValueError("Cannot import the required field '%s'" % value)
                 else:
                     print("WARNING: Cannot import '%s'" % value)
-        
+
         # Use ModelsLocals to make lookups work right for CapitalisedModels
         fake_locals = ModelsLocals(fake_locals)
-        
+
         return eval(code, globals(), fake_locals)
-    
-    
+
     def make_meta(self, app, model, data, stub=False):
         "Makes a Meta class out of a dict of eval-able arguments."
         results = {'app_label': app}
@@ -259,12 +259,11 @@ class _FakeORM(object):
                 raise ValueError("Cannot successfully create meta field '%s' for model '%s.%s': %s." % (
                     key, app, model, e
                 ))
-        return type("Meta", tuple(), results) 
-    
-    
+        return type("Meta", tuple(), results)
+
     def make_model(self, app, name, data):
         "Makes a Model class out of the given app name, model name and pickled data."
-        
+
         # Extract any bases out of Meta
         if "_ormbases" in data['Meta']:
             # Make sure everything we depend on is done already; otherwise, wait.
@@ -283,14 +282,14 @@ class _FakeORM(object):
         # Ah, bog standard, then.
         else:
             bases = [models.Model]
-        
+
         # Turn the Meta dict into a basic class
         meta = self.make_meta(app, name, data['Meta'], data.get("_stub", False))
-        
+
         failed_fields = {}
         fields = {}
         stub = False
-        
+
         # Now, make some fields!
         for fname, params in data.items():
             # If it's the stub marker, ignore it.
@@ -300,7 +299,9 @@ class _FakeORM(object):
             elif fname == "Meta":
                 continue
             elif not params:
-                raise ValueError("Field '%s' on model '%s.%s' has no definition." % (fname, app, name))
+                raise ValueError(
+                    "Field '%s' on model '%s.%s' has no definition." %
+                    (fname, app, name))
             elif isinstance(params, string_types):
                 # It's a premade definition string! Let's hope it works...
                 code = params
@@ -317,8 +318,10 @@ class _FakeORM(object):
                     )
                     extra_imports = {"SouthFieldClass": params[0]}
                 else:
-                    raise ValueError("Field '%s' on model '%s.%s' has a weird definition length (should be 1 or 3 items)." % (fname, app, name))
-            
+                    raise ValueError(
+                        "Field '%s' on model '%s.%s' has a weird definition length (should be 1 or 3 items)." %
+                        (fname, app, name))
+
             try:
                 # Execute it in a probably-correct context.
                 field = self.eval_in_context(code, app, extra_imports)
@@ -328,7 +331,7 @@ class _FakeORM(object):
                 failed_fields[fname] = (code, extra_imports)
             else:
                 fields[fname] = field
-        
+
         # Find the app in the Django core, and get its module
         more_kwds = {}
         try:
@@ -338,18 +341,18 @@ class _FakeORM(object):
             # The app this belonged to has vanished, but thankfully we can still
             # make a mock model, so ignore the error.
             more_kwds['__module__'] = '_south_mock'
-        
+
         more_kwds['Meta'] = meta
-        
+
         # Make our model
         fields.update(more_kwds)
-        
+
         model = type(
             str(name),
             tuple(bases),
             fields,
         )
-        
+
         # If this is a stub model, change Objects to a whiny class
         if stub:
             model.objects = WhinyManager()
@@ -357,12 +360,12 @@ class _FakeORM(object):
             model.__init__ = whiny_method
         else:
             model.objects = NoDryRunManager(model.objects)
-        
+
         if failed_fields:
             model._failed_fields = failed_fields
-        
+
         return model
-    
+
     def retry_failed_fields(self):
         "Tries to re-evaluate the _failed_fields for each model."
         for modelkey, model in self.models.items():
@@ -383,7 +386,7 @@ class _FakeORM(object):
 
 class WhinyManager(object):
     "A fake manager that whines whenever you try to touch it. For stub models."
-    
+
     def __getattr__(self, key):
         raise AttributeError("You cannot use items from a stub model.")
 
@@ -393,13 +396,14 @@ class NoDryRunManager(object):
     A manager that always proxies through to the real manager,
     unless a dry run is in progress.
     """
-    
+
     def __init__(self, real):
         self.real = real
-    
+
     def __getattr__(self, name):
         if db.dry_run:
-            raise AttributeError("You are in a dry run, and cannot access the ORM.\nWrap ORM sections in 'if not db.dry_run:', or if the whole migration is only a data migration, set no_dry_run = True on the Migration class.")
+            raise AttributeError(
+                "You are in a dry run, and cannot access the ORM.\nWrap ORM sections in 'if not db.dry_run:', or if the whole migration is only a data migration, set no_dry_run = True on the Migration class.")
         return getattr(self.real, name)
 
 
diff --git a/src/south/signals.py b/src/south/signals.py
index 12a1362e7b..d58a48beee 100644
--- a/src/south/signals.py
+++ b/src/south/signals.py
@@ -12,13 +12,20 @@ pre_migrate = Signal(providing_args=["app", "verbosity", "interactive", "db"])
 post_migrate = Signal(providing_args=["app", "verbosity", "interactive", "db"])
 
 # Sent after each run of a particular migration in a direction
-ran_migration = Signal(providing_args=["app", "migration", "method", "verbosity", "interactive", "db"])
+ran_migration = Signal(
+    providing_args=[
+        "app",
+        "migration",
+        "method",
+        "verbosity",
+        "interactive",
+        "db"])
 
 # Compatibility code for django.contrib.auth
 # Is causing strange errors, removing for now (we might need to fix up orm first)
-#if 'django.contrib.auth' in settings.INSTALLED_APPS:
-    #def create_permissions_compat(app, **kwargs):
-        #from django.db.models import get_app
-        #from django.contrib.auth.management import create_permissions
-        #create_permissions(get_app(app), (), 0)
-    #post_migrate.connect(create_permissions_compat)
+# if 'django.contrib.auth' in settings.INSTALLED_APPS:
+# def create_permissions_compat(app, **kwargs):
+#from django.db.models import get_app
+#from django.contrib.auth.management import create_permissions
+#create_permissions(get_app(app), (), 0)
+# post_migrate.connect(create_permissions_compat)
diff --git a/src/south/utils/__init__.py b/src/south/utils/__init__.py
index 8d7297ea5d..bebce14295 100644
--- a/src/south/utils/__init__.py
+++ b/src/south/utils/__init__.py
@@ -7,7 +7,7 @@ def _ask_for_it_by_name(name):
     "Returns an object referenced by absolute path."
     bits = str(name).split(".")
 
-    ## what if there is no absolute reference?
+    # what if there is no absolute reference?
     if len(bits) > 1:
         modulename = ".".join(bits[:-1])
     else:
@@ -26,6 +26,8 @@ def ask_for_it_by_name(name):
     if name not in ask_for_it_by_name.cache:
         ask_for_it_by_name.cache[name] = _ask_for_it_by_name(name)
     return ask_for_it_by_name.cache[name]
+
+
 ask_for_it_by_name.cache = {}
 
 
@@ -38,6 +40,7 @@ def get_attribute(item, attribute):
         value = getattr(value, part)
     return value
 
+
 def auto_through(field):
     "Returns if the M2M class passed in has an autogenerated through table or not."
     return (
@@ -48,10 +51,12 @@ def auto_through(field):
         getattr(getattr(field.rel.through, "_meta", None), "auto_created", False)
     )
 
+
 def auto_model(model):
     "Returns if the given model was automatically generated."
     return getattr(model._meta, "auto_created", False)
 
+
 def memoize(function):
     "Standard memoization decorator."
     name = function.__name__
diff --git a/src/south/utils/py3.py b/src/south/utils/py3.py
index 7fc3484246..a81cbda4f4 100644
--- a/src/south/utils/py3.py
+++ b/src/south/utils/py3.py
@@ -32,6 +32,7 @@ def _add_doc(func, doc):
     """Add documentation to a function."""
     func.__doc__ = doc
 
+
 if PY3:
     def iteritems(d, **kw):
         return iter(d.items(**kw))
diff --git a/src/south/v2.py b/src/south/v2.py
index 22afed2923..b60283eac3 100644
--- a/src/south/v2.py
+++ b/src/south/v2.py
@@ -5,21 +5,25 @@ by what class they inherit from (if none, it's a v1).
 
 from south.utils import ask_for_it_by_name
 
+
 class BaseMigration(object):
-    
+
     def gf(self, field_name):
         "Gets a field by absolute reference."
         field = ask_for_it_by_name(field_name)
         field.model = FakeModel
         return field
 
+
 class SchemaMigration(BaseMigration):
     pass
 
+
 class DataMigration(BaseMigration):
     # Data migrations shouldn't be dry-run
     no_dry_run = True
 
+
 class FakeModel(object):
     "Fake model so error messages on fields don't explode"
     pass
