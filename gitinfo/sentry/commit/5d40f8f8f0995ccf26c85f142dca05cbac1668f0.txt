commit 5d40f8f8f0995ccf26c85f142dca05cbac1668f0
Author: Dan Fuller <dfuller@sentry.io>
Date:   Mon Feb 10 18:30:58 2020 -0800

    refs(Incidents): Remove date_started automatic detection code and cleanup around removing manual incident creation
    
    We no longer support manual incident creation, just removing some unused code around it.

diff --git a/migrations_lockfile.txt b/migrations_lockfile.txt
index 465c606385..a14992d8a1 100644
--- a/migrations_lockfile.txt
+++ b/migrations_lockfile.txt
@@ -10,7 +10,7 @@ auth: 0008_alter_user_username_max_length
 contenttypes: 0002_remove_content_type_name
 jira_ac: 0001_initial
 nodestore: 0001_initial
-sentry: 0042_auto_20200214_1607
+sentry: 0043_auto_20200218_1903
 sessions: 0001_initial
 sites: 0002_alter_domain_unique
 social_auth: 0001_initial
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index 736e6220d0..1edd74102d 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -5,9 +5,7 @@ from datetime import timedelta
 from rest_framework import serializers
 from uuid import uuid4
 
-import pytz
 import six
-from dateutil.parser import parse as parse_date
 from django.db import transaction
 from django.utils import timezone
 
@@ -32,10 +30,8 @@ from sentry.incidents.models import (
     IncidentSeen,
     IncidentStatus,
     IncidentSubscription,
-    IncidentType,
     TimeSeriesSnapshot,
 )
-from sentry.snuba.discover import zerofill
 from sentry.models import Integration, Project
 from sentry.snuba.discover import resolve_discover_aliases
 from sentry.snuba.models import QueryAggregations, QueryDatasets
@@ -45,7 +41,7 @@ from sentry.snuba.subscriptions import (
     bulk_update_snuba_subscriptions,
     query_aggregation_to_snuba,
 )
-from sentry.utils.snuba import bulk_raw_query, raw_query, SnubaQueryParams, SnubaTSResult
+from sentry.utils.snuba import bulk_raw_query, SnubaQueryParams, SnubaTSResult
 
 MAX_INITIAL_INCIDENT_PERIOD = timedelta(days=7)
 
@@ -64,7 +60,7 @@ def create_incident(
     title,
     query,
     aggregation,
-    date_started=None,
+    date_started,
     date_detected=None,
     # TODO: Probably remove detection_uuid?
     detection_uuid=None,
@@ -79,9 +75,6 @@ def create_incident(
             projects = []
         projects = list(set(projects + group_projects))
 
-    if date_started is None:
-        date_started = calculate_incident_start(query, projects, groups)
-
     if date_detected is None:
         date_detected = date_started
 
@@ -107,14 +100,12 @@ def create_incident(
                 [IncidentGroup(incident=incident, group=group) for group in groups]
             )
 
-        if type == IncidentType.CREATED:
-            activity_status = IncidentActivityType.CREATED
-        else:
-            activity_status = IncidentActivityType.DETECTED
-
         event_stats_snapshot = create_initial_event_stats_snapshot(incident)
         create_incident_activity(
-            incident, activity_status, event_stats_snapshot=event_stats_snapshot, user=user
+            incident,
+            IncidentActivityType.DETECTED,
+            event_stats_snapshot=event_stats_snapshot,
+            user=user,
         )
         analytics.record(
             "incident.created",
@@ -126,110 +117,6 @@ def create_incident(
     return incident
 
 
-INCIDENT_START_PERIOD = timedelta(days=14)
-INCIDENT_START_ROLLUP = timedelta(minutes=15)
-
-
-def calculate_incident_start(query, projects, groups):
-    """
-    Attempts to automatically calculate the date that an incident began at based
-    on the events related to the incident.
-    """
-    params = {}
-    if groups:
-        params["group_ids"] = [g.id for g in groups]
-        end = max(g.last_seen for g in groups) + timedelta(seconds=1)
-    else:
-        end = timezone.now()
-
-    params["start"] = end - INCIDENT_START_PERIOD
-    params["end"] = end
-
-    if projects:
-        params["project_id"] = [p.id for p in projects]
-
-    filter = get_filter(query, params)
-    rollup = int(INCIDENT_START_ROLLUP.total_seconds())
-
-    result = raw_query(
-        aggregations=[("count()", "", "count"), ("min", "timestamp", "first_seen")],
-        orderby="time",
-        groupby=["time"],
-        rollup=rollup,
-        referrer="incidents.calculate_incident_start",
-        limit=10000,
-        start=filter.start,
-        end=filter.end,
-        conditions=filter.conditions,
-        filter_keys=filter.filter_keys,
-    )["data"]
-    # TODO: Start could be the period before the first period we find
-    result = zerofill(result, params["start"], params["end"], rollup, "time")
-
-    # We want to linearly scale scores from 100% value at the most recent to
-    # 50% at the oldest. This gives a bias towards newer results.
-    negative_weight = (1.0 / len(result)) / 2
-    multiplier = 1.0
-    cur_spike_max_count = -1
-    cur_spike_start = None
-    cur_spike_end = None
-    max_height = 0
-    incident_start = None
-    cur_height = 0
-    prev_count = 0
-
-    def get_row_first_seen(row, default=None):
-        first_seen = default
-        if "first_seen" in row:
-            first_seen = parse_date(row["first_seen"]).replace(tzinfo=pytz.utc)
-        return first_seen
-
-    def calculate_start(spike_start, spike_end):
-        """
-        We arbitrarily choose a date about 1/3 into the incident period. We
-        could potentially improve this if we want by analyzing the period in
-        more detail and choosing a date that most closely fits with being 1/3
-        up the spike.
-        """
-        spike_length = spike_end - spike_start
-        return spike_start + (spike_length / 3)
-
-    for row in reversed(result):
-        cur_count = row.get("count", 0)
-        if cur_count < prev_count or cur_count > 0 and cur_count == prev_count:
-            cur_height = cur_spike_max_count - cur_count
-        elif cur_count > 0 or prev_count > 0 or cur_height > 0:
-            # Now we've got the height of the current spike, compare it to the
-            # current max. We decrease the value by `multiplier` so that we
-            # favour newer results
-            cur_height *= multiplier
-            if cur_height > max_height:
-                # If we detect that we have a new highest peak, then set a new
-                # incident start date
-                incident_start = calculate_start(cur_spike_start, cur_spike_end)
-                max_height = cur_height
-
-            cur_height = 0
-            cur_spike_max_count = cur_count
-            cur_spike_end = get_row_first_seen(row)
-
-        # We attempt to get the first_seen value from the row here. If the row
-        # doesn't have it (because it's a zerofilled row), then just use the
-        # previous value. This allows us to have the start of a spike always be
-        # a bucket that contains at least one element.
-        cur_spike_start = get_row_first_seen(row, cur_spike_start)
-        prev_count = cur_count
-        multiplier -= negative_weight
-
-    if (cur_height > max_height or not incident_start) and cur_spike_start:
-        incident_start = calculate_start(cur_spike_start, cur_spike_end)
-
-    if not incident_start:
-        incident_start = timezone.now()
-
-    return incident_start
-
-
 def update_incident_status(incident, status, user=None, comment=None):
     """
     Updates the status of an Incident and write an IncidentActivity row to log
diff --git a/src/sentry/incidents/models.py b/src/sentry/incidents/models.py
index b04916d1b2..4761c94a6a 100644
--- a/src/sentry/incidents/models.py
+++ b/src/sentry/incidents/models.py
@@ -82,7 +82,6 @@ class IncidentManager(BaseManager):
 
 class IncidentType(Enum):
     DETECTED = 0
-    CREATED = 1
     ALERT_TRIGGERED = 2
 
 
@@ -109,7 +108,7 @@ class Incident(Model):
     # Identifier used to match incoming events from the detection algorithm
     detection_uuid = UUIDField(null=True, db_index=True)
     status = models.PositiveSmallIntegerField(default=IncidentStatus.OPEN.value)
-    type = models.PositiveSmallIntegerField(default=IncidentType.CREATED.value)
+    type = models.PositiveSmallIntegerField()
     aggregation = models.PositiveSmallIntegerField(default=QueryAggregations.TOTAL.value)
     title = models.TextField()
     # Query used to fetch events related to an incident
@@ -178,7 +177,6 @@ class TimeSeriesSnapshot(Model):
 
 
 class IncidentActivityType(Enum):
-    CREATED = 0
     DETECTED = 1
     STATUS_CHANGE = 2
     COMMENT = 3
diff --git a/src/sentry/migrations/0043_auto_20200218_1903.py b/src/sentry/migrations/0043_auto_20200218_1903.py
new file mode 100644
index 0000000000..bafd5be79d
--- /dev/null
+++ b/src/sentry/migrations/0043_auto_20200218_1903.py
@@ -0,0 +1,37 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.11.28 on 2020-02-18 19:03
+from __future__ import unicode_literals
+
+from django.db import migrations, models
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = False
+
+    # This flag is used to decide whether to run this migration in a transaction or not.
+    # By default we prefer to run in a transaction, but for migrations where you want
+    # to `CREATE INDEX CONCURRENTLY` this needs to be set to False. Typically you'll
+    # want to create an index concurrently when adding one to an existing table.
+    atomic = True
+
+
+    dependencies = [
+        ('sentry', '0042_auto_20200214_1607'),
+    ]
+
+    operations = [
+        migrations.AlterField(
+            model_name='incident',
+            name='type',
+            field=models.PositiveSmallIntegerField(),
+        ),
+    ]
diff --git a/src/sentry/testutils/factories.py b/src/sentry/testutils/factories.py
index fe68a3ea33..82b7f8785d 100644
--- a/src/sentry/testutils/factories.py
+++ b/src/sentry/testutils/factories.py
@@ -29,10 +29,11 @@ from sentry.incidents.models import (
     AlertRuleThresholdType,
     AlertRuleTriggerAction,
     Incident,
+    IncidentActivity,
     IncidentGroup,
     IncidentProject,
     IncidentSeen,
-    IncidentActivity,
+    IncidentType,
 )
 from sentry.mediators import (
     sentry_apps,
@@ -763,6 +764,7 @@ class Factories(object):
             date_started=date_started or timezone.now(),
             date_detected=date_detected or timezone.now(),
             date_closed=date_closed or timezone.now(),
+            type=IncidentType.ALERT_TRIGGERED.value,
         )
         for project in projects:
             IncidentProject.objects.create(incident=incident, project=project)
diff --git a/tests/sentry/api/endpoints/test_organization_incident_activity_index.py b/tests/sentry/api/endpoints/test_organization_incident_activity_index.py
index 11a9d640e3..f0241cd1bd 100644
--- a/tests/sentry/api/endpoints/test_organization_incident_activity_index.py
+++ b/tests/sentry/api/endpoints/test_organization_incident_activity_index.py
@@ -50,7 +50,7 @@ class OrganizationIncidentActivityIndexTest(APITestCase):
         activities = [
             create_incident_activity(
                 incident=incident,
-                activity_type=IncidentActivityType.CREATED,
+                activity_type=IncidentActivityType.DETECTED,
                 user=self.user,
                 comment="hello",
                 event_stats_snapshot=snapshot,
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index c4ee499f53..45ba8579b5 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -25,7 +25,6 @@ from sentry.incidents.logic import (
     bulk_get_incident_aggregates,
     bulk_get_incident_event_stats,
     bulk_get_incident_stats,
-    calculate_incident_start,
     create_alert_rule,
     create_alert_rule_trigger,
     create_alert_rule_trigger_action,
@@ -45,7 +44,6 @@ from sentry.incidents.logic import (
     get_incident_event_stats,
     get_incident_subscribers,
     get_triggers_for_alert_rule,
-    INCIDENT_START_ROLLUP,
     ProjectsNotAssociatedWithAlertRuleError,
     subscribe_to_incident,
     update_alert_rule,
@@ -80,7 +78,7 @@ class CreateIncidentTest(TestCase):
     record_event = patcher("sentry.analytics.base.Analytics.record_event")
 
     def test_simple(self):
-        incident_type = IncidentType.CREATED
+        incident_type = IncidentType.ALERT_TRIGGERED
         title = "hello"
         query = "goodbye"
         aggregation = QueryAggregations.UNIQUE_USERS
@@ -110,7 +108,8 @@ class CreateIncidentTest(TestCase):
             alert_rule=alert_rule,
         )
         assert incident.identifier == 1
-        assert incident.status == incident_type.value
+        assert incident.status == IncidentStatus.OPEN.value
+        assert incident.type == incident_type.value
         assert incident.title == title
         assert incident.query == query
         assert incident.aggregation == aggregation.value
@@ -132,7 +131,7 @@ class CreateIncidentTest(TestCase):
         assert (
             IncidentActivity.objects.filter(
                 incident=incident,
-                type=IncidentActivityType.CREATED.value,
+                type=IncidentActivityType.DETECTED.value,
                 event_stats_snapshot__isnull=False,
             ).count()
             == 1
@@ -143,7 +142,7 @@ class CreateIncidentTest(TestCase):
         assert event.data == {
             "organization_id": six.text_type(self.organization.id),
             "incident_id": six.text_type(incident.id),
-            "incident_type": six.text_type(IncidentType.CREATED.value),
+            "incident_type": six.text_type(IncidentType.ALERT_TRIGGERED.value),
         }
 
 
@@ -190,7 +189,7 @@ class UpdateIncidentStatus(TestCase):
     def test_closed(self):
         incident = create_incident(
             self.organization,
-            IncidentType.CREATED,
+            IncidentType.ALERT_TRIGGERED,
             "Test",
             "",
             QueryAggregations.TOTAL,
@@ -444,10 +443,10 @@ class CreateIncidentActivityTest(TestCase, BaseIncidentsTest):
         event_stats_snapshot = create_initial_event_stats_snapshot(incident)
         self.record_event.reset_mock()
         activity = create_incident_activity(
-            incident, IncidentActivityType.CREATED, event_stats_snapshot=event_stats_snapshot
+            incident, IncidentActivityType.DETECTED, event_stats_snapshot=event_stats_snapshot
         )
         assert activity.incident == incident
-        assert activity.type == IncidentActivityType.CREATED.value
+        assert activity.type == IncidentActivityType.DETECTED.value
         assert activity.value is None
         assert activity.previous_value is None
 
@@ -583,7 +582,7 @@ class BulkGetIncidentStatusTest(TestCase, BaseIncidentsTest):
     def test(self):
         closed_incident = create_incident(
             self.organization,
-            IncidentType.CREATED,
+            IncidentType.ALERT_TRIGGERED,
             "Closed",
             "",
             QueryAggregations.TOTAL,
@@ -593,7 +592,7 @@ class BulkGetIncidentStatusTest(TestCase, BaseIncidentsTest):
         update_incident_status(closed_incident, IncidentStatus.CLOSED)
         open_incident = create_incident(
             self.organization,
-            IncidentType.CREATED,
+            IncidentType.ALERT_TRIGGERED,
             "Open",
             "",
             QueryAggregations.TOTAL,
@@ -872,67 +871,6 @@ class DeleteAlertRuleTest(TestCase, BaseIncidentsTest):
         assert Incident.objects.filter(id=incident.id, alert_rule_id__isnull=True).exists()
 
 
-@freeze_time()
-class CalculateIncidentStartTest(TestCase, BaseIncidentsTest):
-    def test_empty(self):
-        assert timezone.now() == calculate_incident_start("", [self.project], [])
-
-    def test_single_event(self):
-        start = self.now - timedelta(minutes=2)
-        event = self.create_event(start)
-        assert start == calculate_incident_start("", [self.project], [event.group])
-
-    def test_single_spike(self):
-        fingerprint = "hello"
-        start = self.now - (INCIDENT_START_ROLLUP * 2)
-        for _ in range(3):
-            event = self.create_event(start, fingerprint=fingerprint)
-
-        end = self.now - INCIDENT_START_ROLLUP
-        for _ in range(4):
-            event = self.create_event(end, fingerprint=fingerprint)
-        assert start + ((end - start) / 3) == calculate_incident_start(
-            "", [self.project], [event.group]
-        )
-
-    def test_multiple_same_size_spikes(self):
-        # The most recent spike should take precedence
-        fingerprint = "hello"
-        older_spike = self.now - (INCIDENT_START_ROLLUP * 3)
-        for _ in range(3):
-            event = self.create_event(older_spike, fingerprint=fingerprint)
-
-        newer_spike = self.now - INCIDENT_START_ROLLUP
-        for _ in range(3):
-            event = self.create_event(newer_spike, fingerprint=fingerprint)
-        assert newer_spike == calculate_incident_start("", [self.project], [event.group])
-
-    def test_multiple_spikes_large_older(self):
-        # The older spike should take precedence because it's much larger
-        fingerprint = "hello"
-        older_spike = self.now - (INCIDENT_START_ROLLUP * 2)
-        for _ in range(4):
-            event = self.create_event(older_spike, fingerprint=fingerprint)
-
-        newer_spike = self.now - INCIDENT_START_ROLLUP
-        for _ in range(2):
-            event = self.create_event(newer_spike, fingerprint=fingerprint)
-        assert older_spike == calculate_incident_start("", [self.project], [event.group])
-
-    def test_multiple_spikes_large_much_older(self):
-        # The most recent spike should take precedence because even though the
-        # older spike is larger, it's much older.
-        fingerprint = "hello"
-        older_spike = self.now - (INCIDENT_START_ROLLUP * 1000)
-        for _ in range(3):
-            event = self.create_event(older_spike, fingerprint=fingerprint)
-
-        newer_spike = self.now - INCIDENT_START_ROLLUP
-        for _ in range(2):
-            event = self.create_event(newer_spike, fingerprint=fingerprint)
-        assert newer_spike == calculate_incident_start("", [self.project], [event.group])
-
-
 class TestGetExcludedProjectsForAlertRule(TestCase):
     def test(self):
         excluded = [self.create_project(fire_project_created=True)]
diff --git a/tests/sentry/incidents/test_models.py b/tests/sentry/incidents/test_models.py
index cc72c16cb6..08a087f9c5 100644
--- a/tests/sentry/incidents/test_models.py
+++ b/tests/sentry/incidents/test_models.py
@@ -11,7 +11,7 @@ from freezegun import freeze_time
 from sentry.utils.compat.mock import Mock, patch
 
 from sentry.db.models.manager import BaseManager
-from sentry.incidents.models import AlertRuleTriggerAction, Incident, IncidentStatus
+from sentry.incidents.models import AlertRuleTriggerAction, Incident, IncidentStatus, IncidentType
 from sentry.testutils import TestCase
 
 
@@ -58,13 +58,17 @@ class IncidentCreationTest(TestCase):
     def test_simple(self):
         title = "hello"
         query = "goodbye"
-        incident = Incident.objects.create(self.organization, title=title, query=query)
+        incident = Incident.objects.create(
+            self.organization, title=title, query=query, type=IncidentType.ALERT_TRIGGERED.value
+        )
         assert incident.identifier == 1
         assert incident.title == title
         assert incident.query == query
 
         # Check identifier correctly increments
-        incident = Incident.objects.create(self.organization, title=title, query=query)
+        incident = Incident.objects.create(
+            self.organization, title=title, query=query, type=IncidentType.ALERT_TRIGGERED.value
+        )
         assert incident.identifier == 2
 
     def test_identifier_conflict(self):
@@ -83,6 +87,7 @@ class IncidentCreationTest(TestCase):
                         status=IncidentStatus.OPEN.value,
                         title="Conflicting Incident",
                         query="Uh oh",
+                        type=IncidentType.ALERT_TRIGGERED.value,
                     )
                 assert incident.identifier == kwargs["identifier"]
                 try:
@@ -99,7 +104,11 @@ class IncidentCreationTest(TestCase):
         self.organization
         with patch.object(BaseManager, "create", new=mock_base_create):
             incident = Incident.objects.create(
-                self.organization, status=IncidentStatus.OPEN.value, title="hi", query="bye"
+                self.organization,
+                status=IncidentStatus.OPEN.value,
+                title="hi",
+                query="bye",
+                type=IncidentType.ALERT_TRIGGERED.value,
             )
             # We should have 3 calls - one for initial create, one for conflict,
             # then the final one for the retry we get due to the conflict
diff --git a/tests/sentry/incidents/test_tasks.py b/tests/sentry/incidents/test_tasks.py
index a3096256a7..665ec4421e 100644
--- a/tests/sentry/incidents/test_tasks.py
+++ b/tests/sentry/incidents/test_tasks.py
@@ -63,11 +63,11 @@ class TestSendSubscriberNotifications(BaseIncidentActivityTest, TestCase):
         ).exists()
 
     def test_invalid_types(self):
-        for activity_type in (IncidentActivityType.CREATED, IncidentActivityType.DETECTED):
-            activity = create_incident_activity(self.incident, activity_type)
-            send_subscriber_notifications(activity.id)
-            self.send_async.assert_not_called()  # NOQA
-            self.send_async.reset_mock()
+        activity_type = IncidentActivityType.DETECTED
+        activity = create_incident_activity(self.incident, activity_type)
+        send_subscriber_notifications(activity.id)
+        self.send_async.assert_not_called()  # NOQA
+        self.send_async.reset_mock()
 
 
 class TestGenerateIncidentActivityEmail(BaseIncidentActivityTest, TestCase):
