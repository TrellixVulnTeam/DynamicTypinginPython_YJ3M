commit 37eb11f6b050fd019375002aed4cf1d8dff2b117
Author: Jess MacQueen <jessmacqueen@gmail.com>
Date:   Mon Dec 10 17:52:45 2018 -0800

    ref(metrics): Change metrics.incr default kwarg skip_internal to True

diff --git a/src/sentry/attachments/base.py b/src/sentry/attachments/base.py
index 24d476cff6..6c4c8f6c91 100644
--- a/src/sentry/attachments/base.py
+++ b/src/sentry/attachments/base.py
@@ -66,7 +66,7 @@ class BaseAttachmentCache(object):
             self.inner.set(u'{}:{}'.format(key, index), compressed, timeout, raw=True)
 
             metrics_tags = {'type': attachment.type}
-            metrics.incr('attachments.received', tags=metrics_tags)
+            metrics.incr('attachments.received', tags=metrics_tags, skip_internal=False)
             metrics.timing('attachments.blob-size.raw', len(attachment.data), tags=metrics_tags)
             metrics.timing('attachments.blob-size.compressed', len(compressed), tags=metrics_tags)
 
diff --git a/src/sentry/auth/helper.py b/src/sentry/auth/helper.py
index 332fb8437d..29a029b3e7 100644
--- a/src/sentry/auth/helper.py
+++ b/src/sentry/auth/helper.py
@@ -144,7 +144,7 @@ def handle_existing_identity(auth_provider, provider, organization,
         return HttpResponseRedirect(auth.get_login_redirect(request))
 
     state.clear()
-    metrics.incr('sso.login-success', tags={'provider': provider.key})
+    metrics.incr('sso.login-success', tags={'provider': provider.key}, skip_internal=False)
 
     return HttpResponseRedirect(auth.get_login_redirect(request))
 
@@ -831,7 +831,7 @@ class AuthHelper(object):
         metrics.incr('sso.error', tags={
             'provider': self.provider.key,
             'flow': self.state.flow
-        })
+        }, skip_internal=False)
 
         messages.add_message(
             self.request,
diff --git a/src/sentry/buffer/redis.py b/src/sentry/buffer/redis.py
index 4f26c910c1..841ec721b4 100644
--- a/src/sentry/buffer/redis.py
+++ b/src/sentry/buffer/redis.py
@@ -262,7 +262,7 @@ class RedisBuffer(Buffer):
         # prevent a stampede due to the way we use celery etas + duplicate
         # tasks
         if not client.set(lock_key, '1', nx=True, ex=10):
-            metrics.incr('buffer.revoked', tags={'reason': 'locked'})
+            metrics.incr('buffer.revoked', tags={'reason': 'locked'}, skip_internal=False)
             self.logger.debug('buffer.revoked.locked', extra={'redis_key': key})
             return
 
@@ -277,7 +277,7 @@ class RedisBuffer(Buffer):
             values = pipe.execute()[0]
 
             if not values:
-                metrics.incr('buffer.revoked', tags={'reason': 'empty'})
+                metrics.incr('buffer.revoked', tags={'reason': 'empty'}, skip_internal=False)
                 self.logger.debug('buffer.revoked.empty', extra={'redis_key': key})
                 return
 
diff --git a/src/sentry/integrations/slack/notify_action.py b/src/sentry/integrations/slack/notify_action.py
index 85ec481ac8..1602c4e573 100644
--- a/src/sentry/integrations/slack/notify_action.py
+++ b/src/sentry/integrations/slack/notify_action.py
@@ -123,7 +123,7 @@ class SlackNotifyServiceAction(EventAction):
 
         key = u'slack:{}:{}'.format(integration_id, channel)
 
-        metrics.incr('notifications.sent', instance='slack.notification')
+        metrics.incr('notifications.sent', instance='slack.notification', skip_internal=False)
         yield self.future(send_notification, key=key)
 
     def render_label(self):
diff --git a/src/sentry/logging/handlers.py b/src/sentry/logging/handlers.py
index ffc93c8f6d..0b1b1e745c 100644
--- a/src/sentry/logging/handlers.py
+++ b/src/sentry/logging/handlers.py
@@ -126,4 +126,4 @@ class MetricsLogHandler(logging.Handler):
         key = whitespace_re.sub("_", key)
         key = metrics_badchars_re.sub("", key)
         key = ".".join(key.split(".")[:3])
-        metrics.incr(key)
+        metrics.incr(key, skip_internal=False)
diff --git a/src/sentry/middleware/stats.py b/src/sentry/middleware/stats.py
index 723f74fef2..6e8284038e 100644
--- a/src/sentry/middleware/stats.py
+++ b/src/sentry/middleware/stats.py
@@ -11,12 +11,12 @@ from sentry.utils import metrics
 
 class ResponseCodeMiddleware(object):
     def process_response(self, request, response):
-        metrics.incr('response', instance=six.text_type(response.status_code))
+        metrics.incr('response', instance=six.text_type(response.status_code), skip_internal=False)
         return response
 
     def process_exception(self, request, exception):
         if not isinstance(exception, Http404):
-            metrics.incr('response', instance='500')
+            metrics.incr('response', instance='500', skip_internal=False)
 
 
 class RequestTimingMiddleware(object):
@@ -59,7 +59,8 @@ class RequestTimingMiddleware(object):
             tags={
                 'method': request.method,
                 'status_code': status_code,
-            }
+            },
+            skip_internal=False,
         )
 
         if not hasattr(request, '_start_time'):
diff --git a/src/sentry/models/debugfile.py b/src/sentry/models/debugfile.py
index 124d3c7c1e..8d4ac32a55 100644
--- a/src/sentry/models/debugfile.py
+++ b/src/sentry/models/debugfile.py
@@ -745,7 +745,7 @@ class DIFCache(object):
 
             metrics.incr('%s.failed' % cls.cache_name, tags={
                 'error': e.__class__.__name__,
-            })
+            }, skip_internal=False)
 
             return None, None, e.message
 
diff --git a/src/sentry/receivers/stats.py b/src/sentry/receivers/stats.py
index 4e0fbcab42..55a463ddef 100644
--- a/src/sentry/receivers/stats.py
+++ b/src/sentry/receivers/stats.py
@@ -17,7 +17,7 @@ def record_instance_creation(instance, created, **kwargs):
     if not created:
         return
 
-    metrics.incr('objects.created', instance=instance._meta.db_table)
+    metrics.incr('objects.created', instance=instance._meta.db_table, skip_internal=False)
 
 
 post_save.connect(
@@ -35,8 +35,9 @@ def record_task_signal(signal, name, **options):
     def handler(sender, **kwargs):
         if not isinstance(sender, six.string_types):
             sender = _get_task_name(sender)
+        options['skip_internal'] = options.get('skip_internal', False)
         metrics.incr(u'jobs.{0}'.format(name), instance=sender, **options)
-        metrics.incr(u'jobs.all.{0}'.format(name))
+        metrics.incr(u'jobs.all.{0}'.format(name), skip_internal=False)
 
     signal.connect(
         handler,
diff --git a/src/sentry/rules/actions/notify_event.py b/src/sentry/rules/actions/notify_event.py
index dde4c22917..4ff7f0a917 100644
--- a/src/sentry/rules/actions/notify_event.py
+++ b/src/sentry/rules/actions/notify_event.py
@@ -45,5 +45,5 @@ class NotifyEventAction(EventAction):
             ):
                 continue
 
-            metrics.incr('notifications.sent', instance=plugin.slug)
+            metrics.incr('notifications.sent', instance=plugin.slug, skip_internal=False)
             yield self.future(plugin.rule_notify)
diff --git a/src/sentry/rules/actions/notify_event_service.py b/src/sentry/rules/actions/notify_event_service.py
index d9949ed363..8def9cba8f 100644
--- a/src/sentry/rules/actions/notify_event_service.py
+++ b/src/sentry/rules/actions/notify_event_service.py
@@ -61,7 +61,7 @@ class NotifyEventServiceAction(EventAction):
 
         if app:
             kwargs = {'sentry_app': app}
-            metrics.incr('notifications.sent', instance=app.slug)
+            metrics.incr('notifications.sent', instance=app.slug, skip_internal=False)
             yield self.future(notify_sentry_app, **kwargs)
         else:
             plugin = plugins.get(service)
@@ -77,7 +77,7 @@ class NotifyEventServiceAction(EventAction):
                 self.logger.info('rule.fail.should_notify', extra=extra)
                 return
 
-            metrics.incr('notifications.sent', instance=plugin.slug)
+            metrics.incr('notifications.sent', instance=plugin.slug, skip_internal=False)
             yield self.future(plugin.rule_notify)
 
     def get_sentry_app_services(self):
diff --git a/src/sentry/search/snuba/backend.py b/src/sentry/search/snuba/backend.py
index 381b32b85f..63e4f4da43 100644
--- a/src/sentry/search/snuba/backend.py
+++ b/src/sentry/search/snuba/backend.py
@@ -312,7 +312,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
 
             if not candidate_ids:
                 # no matches could possibly be found from this point on
-                metrics.incr('snuba.search.no_candidates')
+                metrics.incr('snuba.search.no_candidates', skip_internal=False)
                 return EMPTY_RESULT
             elif len(candidate_ids) > num_candidates:
                 # If the pre-filter query didn't include anything to significantly
@@ -324,7 +324,7 @@ class SnubaSearchBackend(ds.DjangoSearchBackend):
                 # want Snuba to do all the filtering/sorting it can and *then* apply
                 # this queryset to the results from Snuba, which we call
                 # post-filtering.
-                metrics.incr('snuba.search.too_many_candidates')
+                metrics.incr('snuba.search.too_many_candidates', skip_internal=False)
                 candidate_ids = None
 
         sort_field = sort_strategies[sort_by]
diff --git a/src/sentry/tasks/check_auth.py b/src/sentry/tasks/check_auth.py
index 8fed73a0fd..ff24d1084d 100644
--- a/src/sentry/tasks/check_auth.py
+++ b/src/sentry/tasks/check_auth.py
@@ -86,13 +86,13 @@ def check_auth_identity(auth_identity_id, **kwargs):
                 six.text_type(exc),
                 exc_info=True,
             )
-            metrics.incr('auth.identities.invalidated')
+            metrics.incr('auth.identities.invalidated', skip_internal=False)
         is_linked = False
         is_valid = False
     except Exception as exc:
         # to ensure security we count any kind of error as an invalidation
         # event
-        metrics.incr('auth.identities.refresh_error')
+        metrics.incr('auth.identities.refresh_error', skip_internal=False)
         logger.exception(
             u'AuthIdentity(id=%s) returned an error during validation: %s',
             auth_identity_id,
diff --git a/src/sentry/tasks/post_process.py b/src/sentry/tasks/post_process.py
index 1ca25a0ba9..7b669bbef4 100644
--- a/src/sentry/tasks/post_process.py
+++ b/src/sentry/tasks/post_process.py
@@ -47,10 +47,10 @@ def _capture_stats(event, is_new):
     platform = platform.split('-', 1)[0].split('_', 1)[0]
 
     if is_new:
-        metrics.incr('events.unique')
+        metrics.incr('events.unique', skip_internal=False)
 
-    metrics.incr('events.processed')
-    metrics.incr(u'events.processed.{platform}'.format(platform=platform))
+    metrics.incr('events.processed', skip_internal=False)
+    metrics.incr(u'events.processed.{platform}'.format(platform=platform), skip_internal=False)
     metrics.timing('events.size.data', event.size, tags={'platform': platform})
 
 
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index e41e75e89b..4de2825261 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -64,7 +64,7 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_event):
         data = default_cache.get(cache_key)
 
     if data is None:
-        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'pre'})
+        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'pre'}, skip_internal=False)
         error_logger.error('preprocess.failed.empty', extra={'cache_key': cache_key})
         return
 
@@ -118,7 +118,12 @@ def _do_process_event(cache_key, start_time, event_id, process_task):
     data = default_cache.get(cache_key)
 
     if data is None:
-        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'process'})
+        metrics.incr(
+            'events.failed',
+            tags={
+                'reason': 'cache',
+                'stage': 'process'},
+            skip_internal=False)
         error_logger.error('process.failed.empty', extra={'cache_key': cache_key})
         return
 
@@ -282,7 +287,7 @@ def create_failed_event(cache_key, project_id, issues, event_id, start_time=None
     delete_raw_event(project_id, event_id)
     data = default_cache.get(cache_key)
     if data is None:
-        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'raw'})
+        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'raw'}, skip_internal=False)
         error_logger.error('process.failed_raw.empty', extra={'cache_key': cache_key})
         return True
 
@@ -375,7 +380,12 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None,
     # reprocessing reports correctly or they will screw up the UI.  So
     # to future proof this correctly we just handle this case here.
     if not data:
-        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'post'})
+        metrics.incr(
+            'events.failed',
+            tags={
+                'reason': 'cache',
+                'stage': 'post'},
+            skip_internal=False)
         return
 
     with configure_scope() as scope:
diff --git a/src/sentry/utils/committers.py b/src/sentry/utils/committers.py
index d63d125119..662763d006 100644
--- a/src/sentry/utils/committers.py
+++ b/src/sentry/utils/committers.py
@@ -217,5 +217,8 @@ def get_event_file_committers(project, event, frame_limit=25):
     )
 
     committers = _get_committers(annotated_frames, relevant_commits)
-    metrics.incr('feature.owners.has-committers', instance='hit' if committers else 'miss')
+    metrics.incr(
+        'feature.owners.has-committers',
+        instance='hit' if committers else 'miss',
+        skip_internal=False)
     return committers
diff --git a/src/sentry/utils/email.py b/src/sentry/utils/email.py
index 6f20f2f354..ed9dea7690 100644
--- a/src/sentry/utils/email.py
+++ b/src/sentry/utils/email.py
@@ -421,7 +421,7 @@ class MessageBuilder(object):
                 _with_transaction=False,
             )
             extra['message_id'] = message.extra_headers['Message-Id']
-            metrics.incr('email.queued', instance=self.type)
+            metrics.incr('email.queued', instance=self.type, skip_internal=False)
             if fmt == LoggingFormat.HUMAN:
                 extra['message_to'] = self.format_to(message.to),
                 log_mail_queued()
@@ -434,7 +434,7 @@ class MessageBuilder(object):
 def send_messages(messages, fail_silently=False):
     connection = get_connection(fail_silently=fail_silently)
     sent = connection.send_messages(messages)
-    metrics.incr('email.sent', len(messages))
+    metrics.incr('email.sent', len(messages), skip_internal=False)
     for message in messages:
         extra = {
             'message_id': message.extra_headers['Message-Id'],
diff --git a/src/sentry/utils/metrics.py b/src/sentry/utils/metrics.py
index d5a53f7a73..94ab99bf66 100644
--- a/src/sentry/utils/metrics.py
+++ b/src/sentry/utils/metrics.py
@@ -83,7 +83,7 @@ class InternalMetrics(object):
 internal = InternalMetrics()
 
 
-def incr(key, amount=1, instance=None, tags=None, skip_internal=False):
+def incr(key, amount=1, instance=None, tags=None, skip_internal=True):
     sample_rate = settings.SENTRY_METRICS_SAMPLE_RATE
     if not skip_internal and _should_sample():
         internal.incr(key, instance, tags, amount)
diff --git a/src/sentry/utils/sdk.py b/src/sentry/utils/sdk.py
index 1145328673..375e3ec6fa 100644
--- a/src/sentry/utils/sdk.py
+++ b/src/sentry/utils/sdk.py
@@ -70,7 +70,7 @@ def get_project_key():
 class SentryInternalFilter(logging.Filter):
     def filter(self, record):
         # TODO(mattrobenolt): handle an upstream Sentry
-        metrics.incr('internal.uncaptured.logs')
+        metrics.incr('internal.uncaptured.logs', skip_internal=False)
         return is_current_event_safe()
 
 
@@ -129,7 +129,7 @@ class InternalTransport(Transport):
                 return
 
             if not is_current_event_safe():
-                metrics.incr('internal.uncaptured.events')
+                metrics.incr('internal.uncaptured.events', skip_internal=False)
                 sdk_logger.warn('internal-error.unsafe-stacktrace')
                 return
 
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 50bfd4f96b..1834c1d5e1 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -122,7 +122,7 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments)
         )
 
         metrics.incr(
-            'events.blacklisted', tags={'reason': filter_reason}
+            'events.blacklisted', tags={'reason': filter_reason}, skip_internal=False
         )
         event_filtered.send_robust(
             ip=remote_addr,
@@ -160,7 +160,8 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments)
             'events.dropped',
             tags={
                 'reason': rate_limit.reason_code if rate_limit else 'unknown',
-            }
+            },
+            skip_internal=False,
         )
         event_dropped.send_robust(
             ip=remote_addr,
@@ -354,25 +355,27 @@ class APIView(BaseView):
 
         # TODO(dcramer): it'd be nice if we had an incr_multi method so
         # tsdb could optimize this
-        metrics.incr('client-api.all-versions.requests')
+        metrics.incr('client-api.all-versions.requests', skip_internal=False)
         metrics.incr('client-api.all-versions.responses.%s' %
-                     (response.status_code, ))
+                     (response.status_code, ), skip_internal=False)
         metrics.incr(
-            'client-api.all-versions.responses.%sxx' % (
-                six.text_type(response.status_code)[0], )
+            'client-api.all-versions.responses.%sxx' % (six.text_type(response.status_code)[0],),
+            skip_internal=False,
         )
 
         if helper.context.version:
-            metrics.incr('client-api.v%s.requests' %
-                         (helper.context.version, ))
             metrics.incr(
-                'client-api.v%s.responses.%s' % (
-                    helper.context.version, response.status_code)
+                'client-api.v%s.requests' % (helper.context.version, ),
+                skip_internal=False,
+            )
+            metrics.incr(
+                'client-api.v%s.responses.%s' % (helper.context.version, response.status_code),
+                skip_internal=False,
             )
             metrics.incr(
-                'client-api.v%s.responses.%sxx' %
-                (helper.context.version, six.text_type(
-                    response.status_code)[0])
+                'client-api.v%s.responses.%sxx' % (helper.context.version,
+                                                   six.text_type(response.status_code)[0]),
+                skip_internal=False,
             )
 
         if response.status_code != 200 and origin:
@@ -527,7 +530,7 @@ class StoreView(APIView):
         pass
 
     def process(self, request, project, key, auth, helper, data, attachments=None, **kwargs):
-        metrics.incr('events.total')
+        metrics.incr('events.total', skip_internal=False)
 
         if not data:
             raise APIError('No JSON data was found')
diff --git a/src/sentry/web/frontend/js_sdk_loader.py b/src/sentry/web/frontend/js_sdk_loader.py
index 128c329aad..5199602c83 100644
--- a/src/sentry/web/frontend/js_sdk_loader.py
+++ b/src/sentry/web/frontend/js_sdk_loader.py
@@ -62,7 +62,7 @@ class JavaScriptSdkLoader(BaseView):
         else:
             tmpl = 'sentry/js-sdk-loader.js.tmpl'
 
-        metrics.incr('js-sdk-loader.rendered', instance=instance)
+        metrics.incr('js-sdk-loader.rendered', instance=instance, skip_internal=False)
 
         response = render_to_response(tmpl, context, content_type="text/javascript")
 
diff --git a/tests/sentry/logging/test_handler.py b/tests/sentry/logging/test_handler.py
index 62e6d629c1..bcdc70bab6 100644
--- a/tests/sentry/logging/test_handler.py
+++ b/tests/sentry/logging/test_handler.py
@@ -66,7 +66,7 @@ def test_emit(record, out, handler, logger):
 def test_log_to_metric(metrics):
     logger = logging.getLogger('django.request')
     logger.warn("CSRF problem")
-    metrics.incr.assert_called_once_with('django.request.csrf_problem')
+    metrics.incr.assert_called_once_with('django.request.csrf_problem', skip_internal=False)
 
     metrics.reset_mock()
 
