commit 5922035c079c3c9d9d696e6f6c725b0bc68c4b52
Author: ted kaemming <ted@kaemming.com>
Date:   Wed Jul 19 13:43:28 2017 -0700

    Various improvements to similarity indexing. (#5719)
    
    - Feature extraction strategies now reference interface objects instead of the data payload.
    - Feature extraction strategies now only return a single result, rather than an iterator of results.
    - Serialization is now separate from feature extraction, which makes feature extraction easier to understand (and harder to mess up.) [NOTE: This is a breaking change!]
    - Added the `Encoder` class for encoding features before hashing. It supports all builtin types, as well as an implementation for `Frame`.
    - Factored signature building into a separate class from the index implementation.
    - Added some tests for things that could use them (encoder, signature builder) and should be relatively stable.
    - Added the ability to namespace the similarity index.

diff --git a/src/sentry/scripts/similarity/index.lua b/src/sentry/scripts/similarity/index.lua
index a5b4b30baa..7f9f00f746 100644
--- a/src/sentry/scripts/similarity/index.lua
+++ b/src/sentry/scripts/similarity/index.lua
@@ -199,6 +199,7 @@ end
 
 local configuration_parser = build_argument_parser({
     {"timestamp", parse_integer},
+    {"namespace", identity},
     {"bands", parse_integer},
     {"interval", parse_integer},
     {"retention", parse_integer},  -- how many previous intervals to store (does not include current interval)
@@ -218,11 +219,11 @@ end
 
 -- Key Generation
 
-local function get_bucket_frequency_key(scope, index, time, band, item)
+local function get_bucket_frequency_key(configuration, index, time, band, item)
     return string.format(
         '%s:%s:f:%s:%s:%s:%s',
-        'sim',
-        scope,
+        configuration.namespace,
+        configuration.scope,
         index,
         time,
         band,
@@ -230,11 +231,11 @@ local function get_bucket_frequency_key(scope, index, time, band, item)
     )
 end
 
-local function get_bucket_membership_key(scope, index, time, band, bucket)
+local function get_bucket_membership_key(configuration, index, time, band, bucket)
     return string.format(
         '%s:%s:m:%s:%s:%s:%s',
-        'sim',
-        scope,
+        configuration.namespace,
+        configuration.scope,
         index,
         time,
         band,
@@ -332,7 +333,7 @@ local commands = {
 
                     for band, bucket in ipairs(entry.buckets) do
                         local bucket_membership_key = get_bucket_membership_key(
-                            configuration.scope,
+                            configuration,
                             entry.index,
                             time,
                             band,
@@ -342,7 +343,7 @@ local commands = {
                         redis.call('EXPIREAT', bucket_membership_key, expiration)
 
                         local bucket_frequency_key = get_bucket_frequency_key(
-                            configuration.scope,
+                            configuration,
                             entry.index,
                             time,
                             band,
@@ -387,7 +388,7 @@ local commands = {
                                         redis.call(
                                             'HGETALL',
                                             get_bucket_frequency_key(
-                                                configuration.scope,
+                                                configuration,
                                                 index,
                                                 time,
                                                 band,
@@ -421,7 +422,7 @@ local commands = {
                             local members = redis.call(
                                 'SMEMBERS',
                                 get_bucket_membership_key(
-                                    configuration.scope,
+                                    configuration,
                                     index,
                                     time,
                                     band,
@@ -539,14 +540,14 @@ local commands = {
                 for band = 1, configuration.bands do
                     for _, time in ipairs(time_series) do
                         local source_bucket_frequency_key = get_bucket_frequency_key(
-                            configuration.scope,
+                            configuration,
                             source.index,
                             time,
                             band,
                             source.key
                         )
                         local destination_bucket_frequency_key = get_bucket_frequency_key(
-                            configuration.scope,
+                            configuration,
                             source.index,
                             time,
                             band,
@@ -571,7 +572,7 @@ local commands = {
                             -- set, and add the destination to the membership
                             -- set.
                             local bucket_membership_key = get_bucket_membership_key(
-                                configuration.scope,
+                                configuration,
                                 source.index,
                                 time,
                                 band,
@@ -620,7 +621,7 @@ local commands = {
                 for band = 1, configuration.bands do
                     for _, time in ipairs(time_series) do
                         local source_bucket_frequency_key = get_bucket_frequency_key(
-                            configuration.scope,
+                            configuration,
                             source.index,
                             time,
                             band,
@@ -636,7 +637,7 @@ local commands = {
                             redis.call(
                                 'SREM',
                                 get_bucket_membership_key(
-                                    configuration.scope,
+                                    configuration,
                                     source.index,
                                     time,
                                     band,
@@ -681,7 +682,7 @@ local commands = {
                             time
                         )
                         local destination_bucket_frequency_key = get_bucket_frequency_key(
-                            configuration.scope,
+                            configuration,
                             entry.index,
                             time,
                             band,
@@ -690,7 +691,7 @@ local commands = {
 
                         for bucket, count in pairs(buckets) do
                             local bucket_membership_key = get_bucket_membership_key(
-                                configuration.scope,
+                                configuration,
                                 entry.index,
                                 time,
                                 band,
@@ -762,7 +763,7 @@ local commands = {
                                                 redis.call(
                                                     'HGETALL',
                                                     get_bucket_frequency_key(
-                                                        configuration.scope,
+                                                        configuration,
                                                         source.index,
                                                         time,
                                                         band,
diff --git a/src/sentry/similarity/__init__.py b/src/sentry/similarity/__init__.py
index 49c51faaa0..03d9876d7d 100644
--- a/src/sentry/similarity/__init__.py
+++ b/src/sentry/similarity/__init__.py
@@ -1,22 +1,60 @@
 from __future__ import absolute_import
 
-from django.conf import settings
+import itertools
 
-from sentry.utils import redis
-from sentry.utils.datastructures import BidirectionalMapping
-from sentry.utils.iterators import shingle
+from django.conf import settings
 
+from sentry.interfaces.stacktrace import Frame
+from sentry.similarity.encoder import Encoder
 from sentry.similarity.index import MinHashIndex
 from sentry.similarity.features import (
-    FRAME_SEPARATOR,
     FeatureSet,
     ExceptionFeature,
     MessageFeature,
-    serialize_frame,
-    serialize_text_shingle,
     get_application_chunks,
-    get_exception_frames,
 )
+from sentry.similarity.signatures import MinHashSignatureBuilder
+from sentry.utils import redis
+from sentry.utils.datastructures import BidirectionalMapping
+from sentry.utils.iterators import shingle
+
+
+def text_shingle(n, value):
+    return itertools.imap(
+        u''.join,
+        shingle(n, value),
+    )
+
+
+class FrameEncodingError(ValueError):
+    pass
+
+
+def get_frame_attributes(frame):
+    attributes = {}
+
+    if frame.function in set(['<lambda>', None]):
+        if frame.context_line is None:
+            raise FrameEncodingError(
+                'Cannot create a signature for frame without a `context_line` value.')
+
+        attributes['signature'] = (
+            (frame.pre_context or [])[-5:] +
+            [frame.context_line] +
+            (frame.post_context or [])[:5]
+        )
+    else:
+        attributes['function'] = frame.function
+
+    for name in ('module', 'filename'):
+        value = getattr(frame, name)
+        if value:
+            attributes[name] = value
+            break
+    else:
+        raise FrameEncodingError('Cannot encode a frame without a `module` or `filename` value.')
+
+    return attributes
 
 
 features = FeatureSet(
@@ -28,12 +66,15 @@ features = FeatureSet(
                 'default',
             ),
         ),
-        0xFFFF,
+        'sim:1',
+        MinHashSignatureBuilder(16, 0xFFFF),
         8,
-        2,
         60 * 60 * 24 * 30,
         3,
     ),
+    Encoder({
+        Frame: get_frame_attributes,
+    }),
     BidirectionalMapping({
         'exception:message:character-shingles': 'a',
         'exception:stacktrace:application-chunks': 'b',
@@ -42,45 +83,28 @@ features = FeatureSet(
     }),
     {
         'exception:message:character-shingles': ExceptionFeature(
-            lambda exception: map(
-                serialize_text_shingle,
-                shingle(
-                    13,
-                    exception.get('value') or '',
-                ),
-            )
+            lambda exception: text_shingle(
+                13,
+                exception.value,
+            ),
         ),
         'exception:stacktrace:application-chunks': ExceptionFeature(
-            lambda exception: map(
-                lambda frames: FRAME_SEPARATOR.join(
-                    map(
-                        serialize_frame,
-                        frames,
-                    ),
-                ),
-                get_application_chunks(exception),
-            ),
+            lambda exception: get_application_chunks(exception),
         ),
         'exception:stacktrace:pairs': ExceptionFeature(
-            lambda exception: map(
-                FRAME_SEPARATOR.join,
-                shingle(
-                    2,
-                    map(
-                        serialize_frame,
-                        get_exception_frames(exception),
-                    ),
-                ),
+            lambda exception: shingle(
+                2,
+                exception.stacktrace.frames,
             ),
         ),
         'message:message:character-shingles': MessageFeature(
-            lambda message: map(
-                serialize_text_shingle,
-                shingle(
-                    13,
-                    message['message'],
-                ),
+            lambda message: text_shingle(
+                13,
+                message.message,
             ),
         ),
-    }
+    },
+    expected_encoding_errors=(
+        FrameEncodingError,
+    ),
 )
diff --git a/src/sentry/similarity/encoder.py b/src/sentry/similarity/encoder.py
new file mode 100644
index 0000000000..b5544d1c35
--- /dev/null
+++ b/src/sentry/similarity/encoder.py
@@ -0,0 +1,56 @@
+from __future__ import absolute_import
+
+from collections import (Mapping, Set, Sequence)
+
+import six
+
+
+class Encoder(object):
+    try:
+        number_types = (int, long, float)  # noqa
+    except NameError:
+        number_types = (int, float)
+
+    def __init__(self, types=None):
+        self.types = types if types is not None else {}
+
+    def dumps(self, value):
+        for cls, function in self.types.items():
+            if isinstance(value, cls):
+                value = function(value)
+
+        if isinstance(value, six.binary_type):
+            return value
+        elif isinstance(value, six.text_type):
+            return value.encode('utf8')
+        elif isinstance(value, self.number_types):
+            return six.text_type(value).encode('utf8')
+        elif isinstance(value, Set):
+            return '\x00'.join(
+                sorted(
+                    map(
+                        self.dumps,
+                        value,
+                    ),
+                )
+            )
+        elif isinstance(value, Sequence):
+            return '\x01'.join(
+                map(
+                    self.dumps,
+                    value,
+                ),
+            )
+        elif isinstance(value, Mapping):
+            return '\x02'.join(
+                sorted(
+                    '\x01'.join(
+                        map(
+                            self.dumps,
+                            item,
+                        )
+                    ) for item in value.items(),
+                ),
+            )
+        else:
+            raise TypeError('Unsupported type: {}'.format(type(value)))
diff --git a/src/sentry/similarity/features.py b/src/sentry/similarity/features.py
index ab67410a78..87f54f54e3 100644
--- a/src/sentry/similarity/features.py
+++ b/src/sentry/similarity/features.py
@@ -1,116 +1,13 @@
 from __future__ import absolute_import
 
+import functools
 import itertools
 import logging
-import operator
-import struct
-from collections import Sequence
-
-import mmh3
-import six
 
 from sentry.utils.dates import to_timestamp
 
-logger = logging.getLogger('sentry.similarity')
-
-
-FRAME_ITEM_SEPARATOR = b'\x00'
-FRAME_PAIR_SEPARATOR = b'\x01'
-FRAME_SEPARATOR = b'\x02'
 
-FRAME_FUNCTION_KEY = b'\x10'
-FRAME_MODULE_KEY = b'\x11'
-FRAME_FILENAME_KEY = b'\x12'
-FRAME_SIGNATURE_KEY = b'\x13'
-
-
-class InsufficientContext(Exception):
-    """\
-    Exception raised when a signature cannot be generated for a frame due to
-    insufficient context.
-    """
-
-
-def get_frame_signature(frame, lines=5):
-    """\
-    Creates a "signature" for a frame from the surrounding context lines,
-    reading up to ``lines`` values from each side.
-    """
-    try:
-        attributes = (frame.get('pre_context') or [])[-lines:] + \
-            [frame['context_line']] + \
-            (frame.get('post_context') or [])[:lines]
-    except KeyError as error:
-        six.raise_from(
-            InsufficientContext(),
-            error,
-        )
-
-    return struct.pack(
-        '>i',
-        mmh3.hash(
-            u'\n'.join(attributes).encode('utf8')
-        ),
-    )
-
-
-def serialize_frame(frame):
-    """\
-    Convert a frame value from a ``Stacktrace`` interface into a bytes object.
-    """
-    # TODO(tkaemming): This should likely result in an intermediate data
-    # structure that is easier to introspect than this one, and a separate
-    # serialization step before hashing.
-    # TODO(tkaemming): These frame values need platform-specific normalization.
-    # This probably should be done prior to this method being called...?
-    attributes = {}
-
-    function_name = frame.get('function')
-    if function_name in set(['<lambda>', None]):
-        attributes[FRAME_SIGNATURE_KEY] = get_frame_signature(frame)
-    else:
-        attributes[FRAME_FUNCTION_KEY] = function_name.encode('utf8')
-
-    scopes = (
-        (FRAME_MODULE_KEY, 'module'),
-        (FRAME_FILENAME_KEY, 'filename'),
-    )
-
-    for key, name in scopes:
-        value = frame.get(name)
-        if value:
-            attributes[key] = value.encode('utf8')
-            break
-
-    return FRAME_ITEM_SEPARATOR.join(
-        map(
-            FRAME_PAIR_SEPARATOR.join,
-            attributes.items(),
-        ),
-    )
-
-
-def get_exception_frames(exception):
-    """\
-    Extracts frames from an ``Exception`` interface, returning an empty
-    sequence if no frame value was provided or if the value is of an invalid or
-    unexpected type.
-    """
-    try:
-        frames = exception['stacktrace']['frames']
-    except (TypeError, KeyError):
-        logger.info(
-            'Could not extract frames from exception, returning empty sequence.',
-            exc_info=True)
-        frames = []
-    else:
-        if not isinstance(frames, Sequence):
-            logger.info(
-                'Expected frames to be a sequence but got %r, returning empty sequence instead.',
-                type(frames))
-            frames = []
-
-    return frames
+logger = logging.getLogger('sentry.similarity')
 
 
 def get_application_chunks(exception):
@@ -124,8 +21,8 @@ def get_application_chunks(exception):
         itertools.ifilter(
             lambda (in_app, frames): in_app,
             itertools.groupby(
-                get_exception_frames(exception),
-                key=lambda frame: frame.get('in_app', False),
+                exception.stacktrace.frames,
+                key=lambda frame: frame.in_app,
             )
         )
     )
@@ -136,29 +33,9 @@ class ExceptionFeature(object):
         self.function = function
 
     def extract(self, event):
-        try:
-            exceptions = event.data['sentry.interfaces.Exception']['values']
-        except KeyError as error:
-            logger.info(
-                'Could not extract characteristic(s) from %r due to error: %r',
-                event,
-                error,
-                exc_info=True)
-            return
-
-        for exception in exceptions:
-            try:
-                yield self.function(exception)
-            except InsufficientContext as error:
-                logger.debug(
-                    'Could not extract characteristic(s) from exception in %r due to expected error: %r',
-                    event,
-                    error)
-            except Exception as error:
-                logger.exception(
-                    'Could not extract characteristic(s) from exception in %r due to error: %r',
-                    event,
-                    error)
+        return self.function(
+            event.interfaces['sentry.interfaces.Exception'].values[0],
+        )
 
 
 class MessageFeature(object):
@@ -166,30 +43,18 @@ class MessageFeature(object):
         self.function = function
 
     def extract(self, event):
-        try:
-            message = event.data['sentry.interfaces.Message']
-        except KeyError as error:
-            logger.info(
-                'Could not extract characteristic(s) from %r due to error: %r',
-                event,
-                error,
-                exc_info=True)
-            return
-
-        try:
-            yield self.function(message)
-        except Exception as error:
-            logger.exception(
-                'Could not extract characteristic(s) from message of %r due to error: %r',
-                event,
-                error)
+        return self.function(
+            event.interfaces['sentry.interfaces.Message'],
+        )
 
 
 class FeatureSet(object):
-    def __init__(self, index, aliases, features):
+    def __init__(self, index, encoder, aliases, features, expected_encoding_errors):
         self.index = index
+        self.encoder = encoder
         self.aliases = aliases
         self.features = features
+        self.expected_encoding_errors = expected_encoding_errors
         assert set(self.aliases) == set(self.features)
 
     def __get_scope(self, group):
@@ -198,14 +63,46 @@ class FeatureSet(object):
     def __get_key(self, group):
         return '{}'.format(group.id)
 
+    def extract(self, event):
+        results = {}
+        for label, strategy in self.features.items():
+            try:
+                results[label] = strategy.extract(event)
+            except Exception as error:
+                logger.warning(
+                    'Could not extract features from %r for %r due to error: %r',
+                    event,
+                    label,
+                    error,
+                    exc_info=True,
+                )
+        return results
+
     def record(self, event):
         items = []
-        for label, feature in self.features.items():
-            for characteristics in feature.extract(event):
-                if characteristics:
+        for label, features in self.extract(event).items():
+            try:
+                features = map(self.encoder.dumps, features)
+            except Exception as error:
+                log = (
+                    logger.debug
+                    if isinstance(error, self.expected_encoding_errors) else
+                    functools.partial(
+                        logger.warning,
+                        exc_info=True
+                    )
+                )
+                log(
+                    'Could not encode features from %r for %r due to error: %r',
+                    event,
+                    label,
+                    error,
+                )
+            else:
+                if features:
                     items.append((
                         self.aliases[label],
-                        characteristics,
+                        features,
                     ))
         return self.index.record(
             self.__get_scope(event.group),
@@ -293,15 +190,3 @@ class FeatureSet(object):
             self.__get_scope(group),
             [(self.aliases[label], key) for label in self.features.keys()],
         )
-
-
-def serialize_text_shingle(value, separator=b''):
-    """\
-    Convert a sequence of Unicode strings into a bytes object.
-    """
-    return separator.join(
-        map(
-            operator.methodcaller('encode', 'utf8'),
-            value,
-        ),
-    )
diff --git a/src/sentry/similarity/index.py b/src/sentry/similarity/index.py
index b23780e37e..2efe5fcbf6 100644
--- a/src/sentry/similarity/index.py
+++ b/src/sentry/similarity/index.py
@@ -1,41 +1,28 @@
 from __future__ import absolute_import
 
-import itertools
 import time
 
-import mmh3
-
+from sentry.utils.iterators import chunked
 from sentry.utils.redis import load_script
 
+
 index = load_script('similarity/index.lua')
 
 
+def band(n, value):
+    assert len(value) % n == 0
+    return list(chunked(value, len(value) / n))
+
+
 class MinHashIndex(object):
-    def __init__(self, cluster, rows, bands, buckets, interval, retention):
+    def __init__(self, cluster, namespace, signature_builder, bands, interval, retention):
         self.cluster = cluster
-        self.rows = rows
-
-        sequence = itertools.count()
-        self.bands = [[next(sequence) for j in xrange(buckets)] for i in xrange(bands)]
-        self.buckets = buckets
+        self.namespace = namespace
+        self.signature_builder = signature_builder
+        self.bands = bands
         self.interval = interval
         self.retention = retention
 
-    def get_signature(self, value):
-        """Generate a signature for a value."""
-        return map(
-            lambda band: map(
-                lambda bucket: min(
-                    map(
-                        lambda item: mmh3.hash(item, bucket) % self.rows,
-                        value,
-                    ),
-                ),
-                band,
-            ),
-            self.bands,
-        )
-
     def query(self, scope, key, indices, timestamp=None):
         if timestamp is None:
             timestamp = int(time.time())
@@ -43,7 +30,8 @@ class MinHashIndex(object):
         arguments = [
             'QUERY',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
@@ -63,13 +51,17 @@ class MinHashIndex(object):
         ]
 
     def record(self, scope, key, items, timestamp=None):
+        if not items:
+            return  # nothing to do
+
         if timestamp is None:
             timestamp = int(time.time())
 
         arguments = [
             'RECORD',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
@@ -78,8 +70,11 @@ class MinHashIndex(object):
 
         for idx, features in items:
             arguments.append(idx)
-            arguments.extend([','.join(map('{}'.format, band))
-                              for band in self.get_signature(features)])
+            arguments.extend([
+                ','.join(map('{}'.format, b))
+                for b in
+                band(self.bands, self.signature_builder(features))
+            ])
 
         return index(
             self.cluster.get_local_client_for_key(scope),
@@ -94,7 +89,8 @@ class MinHashIndex(object):
         arguments = [
             'MERGE',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
@@ -117,7 +113,8 @@ class MinHashIndex(object):
         arguments = [
             'DELETE',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
@@ -139,7 +136,8 @@ class MinHashIndex(object):
         arguments = [
             'EXPORT',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
@@ -161,7 +159,8 @@ class MinHashIndex(object):
         arguments = [
             'IMPORT',
             timestamp,
-            len(self.bands),
+            self.namespace,
+            self.bands,
             self.interval,
             self.retention,
             scope,
diff --git a/src/sentry/similarity/signatures.py b/src/sentry/similarity/signatures.py
new file mode 100644
index 0000000000..b02690ffcf
--- /dev/null
+++ b/src/sentry/similarity/signatures.py
@@ -0,0 +1,23 @@
+from __future__ import absolute_import
+
+import mmh3
+
+
+class MinHashSignatureBuilder(object):
+    def __init__(self, columns, rows):
+        self.columns = columns
+        self.rows = rows
+
+    def __call__(self, features):
+        return map(
+            lambda column: min(
+                map(
+                    lambda feature: mmh3.hash(
+                        feature,
+                        column,
+                    ) % self.rows,
+                    features,
+                ),
+            ),
+            range(self.columns),
+        )
diff --git a/tests/sentry/similarity/test_encoder.py b/tests/sentry/similarity/test_encoder.py
new file mode 100644
index 0000000000..862292718e
--- /dev/null
+++ b/tests/sentry/similarity/test_encoder.py
@@ -0,0 +1,52 @@
+from __future__ import absolute_import
+
+import pytest
+import six
+
+from sentry.similarity.encoder import Encoder
+
+
+def test_builtin_types():
+    encoder = Encoder()
+    values = [
+        1,
+        1.1,
+        b'\x00\x01\x02',
+        u'\N{SNOWMAN}',
+        ('a', 'b', 'c'),
+        ['a', 'b', 'c'],
+        {'a': 1, 'b': 2, 'c': 3},
+        set(['a', 'b', 'c']),
+        frozenset(['a', 'b', 'c']),
+        [{'a': 1}, set('b'), ['c'], u'text'],
+    ]
+
+    try:
+        values.append(long(1))  # noqa
+    except NameError:
+        pass
+
+    for value in values:
+        encoded = encoder.dumps(value)
+        assert isinstance(encoded, six.binary_type)
+
+    with pytest.raises(TypeError):
+        encoder.dumps(object())
+
+
+def test_custom_types():
+    class Widget(object):
+        def __init__(self, color):
+            self.color = color
+
+    encoder = Encoder({
+        Widget: lambda i: {
+            'color': i.color,
+        },
+    })
+
+    assert encoder.dumps(
+        Widget('red'),
+    ) == encoder.dumps({
+        'color': 'red',
+    })
diff --git a/tests/sentry/similarity/test_features.py b/tests/sentry/similarity/test_features.py
deleted file mode 100644
index ab1a64c629..0000000000
--- a/tests/sentry/similarity/test_features.py
+++ /dev/null
@@ -1,167 +0,0 @@
-from __future__ import absolute_import
-
-import pytest
-
-from sentry.models import Event
-from sentry.similarity.features import (
-    ExceptionFeature, InsufficientContext, get_exception_frames,
-    get_frame_signature, serialize_frame
-)
-
-
-def test_get_exception_frames():
-    assert get_exception_frames({}) == []
-
-    assert get_exception_frames({
-        'stacktrace': None,
-    }) == []
-
-    assert get_exception_frames({
-        'stacktrace': {},
-    }) == []
-
-    assert get_exception_frames({
-        'stacktrace': {
-            'frames': None,
-        },
-    }) == []
-
-    assert get_exception_frames({
-        'stacktrace': {
-            'frames': 13,
-        },
-    }) == []
-
-
-def test_serialize_frame():
-    with pytest.raises(Exception):
-        serialize_frame({})
-
-    serialize_frame({
-        'function': u'\N{SNOWMAN}',
-    })
-
-    serialize_frame({
-        'module': u'\N{SNOWMAN WITHOUT SNOW}',
-        'function': u'\N{SNOWMAN}',
-    })
-
-    serialize_frame({
-        'filename': u'\N{BLACK SNOWMAN}',
-        'function': u'\N{SNOWMAN}',
-    })
-
-    context = {
-        'pre_context': ['foo'],
-        'context_line': 'bar',
-        'post_context': ['baz'],
-    }
-
-    assert serialize_frame(context) == \
-        serialize_frame(dict({'function': '<lambda>'}, **context)) == \
-        serialize_frame(dict({'function': None}, **context))
-
-    assert serialize_frame({
-        'pre_context': (['red'] * 10) + (['foo'] * 5),
-        'context_line': 'bar',
-        'post_context': (['foo'] * 5) + (['red'] * 10),
-    }) == serialize_frame({
-        'pre_context': (['blue'] * 10) + (['foo'] * 5),
-        'context_line': 'bar',
-        'post_context': (['foo'] * 5) + (['blue'] * 10),
-    })
-
-    with pytest.raises(Exception):
-        serialize_frame({
-            'pre_context': ['foo'],
-            'post_context': ['baz'],
-        })
-
-
-def test_get_frame_signature():
-    assert get_frame_signature({
-        'context_line': 'bar'
-    }) == get_frame_signature({
-        'pre_context': None,
-        'context_line': 'bar',
-        'post_context': None,
-    }) == get_frame_signature({
-        'pre_context': [],
-        'context_line': 'bar',
-        'post_context': [],
-    })
-
-    get_frame_signature({
-        'pre_context': ['foo'],
-        'context_line': 'bar',
-        'post_context': ['baz'],
-    })
-
-    get_frame_signature({
-        'pre_context': [u'\N{SNOWMAN WITHOUT SNOW}'],
-        'context_line': u'\N{SNOWMAN}',
-        'post_context': [u'\N{BLACK SNOWMAN}'],
-    })
-
-    with pytest.raises(InsufficientContext):
-        get_frame_signature({})
-
-    with pytest.raises(InsufficientContext):
-        get_frame_signature({
-            'pre_context': ['pre'],
-            'post_context': ['post'],
-        })
-
-
-def test_exception_feature():
-    good_frame = {
-        'function': 'name',
-        'module': 'module',
-    }
-
-    bad_frame = {}
-
-    assert serialize_frame(good_frame)
-    with pytest.raises(InsufficientContext):
-        serialize_frame(bad_frame)
-
-    feature = ExceptionFeature(
-        lambda exception: map(
-            serialize_frame,
-            get_exception_frames(exception),
-        ),
-    )
-
-    def build_event(frames):
-        return Event(
-            data={
-                'sentry.interfaces.Exception': {
-                    'values': [
-                        {
-                            'stacktrace': {
-                                'frames': frames,
-                            },
-                        },
-                    ],
-                },
-            },
-        )
-
-    assert list(
-        feature.extract(
-            build_event([
-                good_frame,
-            ]),
-        )
-    ) == [
-        [serialize_frame(good_frame)],
-    ]
-
-    assert list(
-        feature.extract(
-            build_event([
-                good_frame,
-                bad_frame,
-            ]),
-        )
-    ) == []
diff --git a/tests/sentry/similarity/test_index.py b/tests/sentry/similarity/test_index.py
index 0c3fd6baf1..578d2a2d7d 100644
--- a/tests/sentry/similarity/test_index.py
+++ b/tests/sentry/similarity/test_index.py
@@ -5,17 +5,21 @@ import time
 import msgpack
 
 from sentry.similarity.index import MinHashIndex
+from sentry.similarity.signatures import MinHashSignatureBuilder
 from sentry.testutils import TestCase
 from sentry.utils import redis
 
 
+signature_builder = MinHashSignatureBuilder(16, 0xFFFF)
+
+
 class MinHashIndexTestCase(TestCase):
     def test_index(self):
         index = MinHashIndex(
             redis.clusters.get('default'),
-            0xFFFF,
+            'sim',
+            signature_builder,
             8,
-            2,
             60 * 60,
             12,
         )
@@ -39,14 +43,22 @@ class MinHashIndexTestCase(TestCase):
             '1', '2', '4', '5'
         ]
 
+        assert MinHashIndex(
+            redis.clusters.get('default'),
+            'sim2',
+            signature_builder,
+            8,
+            60 * 60,
+            12,
+        ).query('example', '1', ['index']) == [[]]
+
     def test_export_import(self):
-        bands = 2
         retention = 12
         index = MinHashIndex(
             redis.clusters.get('default'),
-            0xFFFF,
-            bands,
-            2,
+            'sim',
+            signature_builder,
+            8,
             60 * 60,
             retention,
         )
@@ -58,7 +70,7 @@ class MinHashIndexTestCase(TestCase):
         assert len(result) == 1
 
         data = msgpack.unpackb(result[0])
-        assert len(data) == bands
+        assert len(data) == index.bands
 
         for band in data:
             assert len(band) == (retention + 1)
@@ -85,7 +97,7 @@ class MinHashIndexTestCase(TestCase):
         assert len(result) == 1
 
         data = msgpack.unpackb(result[0])
-        assert len(data) == bands
+        assert len(data) == index.bands
 
         for band in data:
             assert len(band) == (retention + 1)
diff --git a/tests/sentry/similarity/test_signatures.py b/tests/sentry/similarity/test_signatures.py
new file mode 100644
index 0000000000..f5753547a3
--- /dev/null
+++ b/tests/sentry/similarity/test_signatures.py
@@ -0,0 +1,40 @@
+from __future__ import absolute_import
+
+from collections import Counter
+from unittest import TestCase
+
+from sentry.similarity.signatures import MinHashSignatureBuilder
+
+
+class MinHashSignatureBuilderTestCase(TestCase):
+    def test_signatures(self):
+        n = 32
+        r = 0xFFFF
+        get_signature = MinHashSignatureBuilder(n, r)
+        get_signature(set(['foo', 'bar', 'baz'])) == get_signature(set(['foo', 'bar', 'baz']))
+
+        assert len(get_signature('hello world')) == n
+        for value in get_signature('hello world'):
+            assert 0 <= value < r
+
+        a = set('the quick grown box jumps over the hazy fog'.split())
+        b = set('the quick brown fox jumps over the lazy dog'.split())
+
+        results = Counter(
+            map(
+                lambda (l, r): l == r,
+                zip(
+                    get_signature(a),
+                    get_signature(b),
+                ),
+            ),
+        )
+
+        similarity = len(a & b) / float(len(a | b))
+        estimation = results[True] / float(sum(results.values()))
+
+        self.assertAlmostEqual(
+            similarity,
+            estimation,
+            delta=0.1,  # totally made up constant, seems reasonable
+        )
