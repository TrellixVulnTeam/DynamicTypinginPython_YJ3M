commit 45de133851a86f1bf59d6b92bab82db3204a1db5
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Thu Apr 13 12:23:36 2017 -0700

    Only count sourcemaps processed and do by actual sourcemaps touched (#5235)
    
    * Only count sourcemaps processed and do by actual sourcemaps touched
    
    * Added dsym counter back

diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index f90fc9ba82..93af166f98 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -443,6 +443,7 @@ class JavaScriptStacktraceProcessor(StacktraceProcessor):
         self.allow_scraping = self.project.get_option(
             'sentry:scrape_javascript', True)
         self.fetch_count = 0
+        self.sourcemaps_touched = set()
         self.cache = SourceCache()
         self.sourcemaps = SourceMapCache()
         self.release = None
@@ -524,6 +525,7 @@ class JavaScriptStacktraceProcessor(StacktraceProcessor):
         raw_frame = dict(frame)
 
         sourcemap_url, sourcemap_view = sourcemaps.get_link(frame['abs_path'])
+        self.sourcemaps_touched.add(sourcemap_url)
         if sourcemap_view and frame.get('colno') is None:
             all_errors.append({
                 'type': EventError.JS_NO_COLUMN,
@@ -751,3 +753,10 @@ class JavaScriptStacktraceProcessor(StacktraceProcessor):
             self.cache_source(
                 filename=filename,
             )
+
+    def close(self):
+        StacktraceProcessor.close(self)
+        if self.sourcemaps_touched:
+            metrics.incr('sourcemaps.processed',
+                         amount=len(self.sourcemaps_touched),
+                         instance=self.project.id)
diff --git a/src/sentry/lang/native/plugin.py b/src/sentry/lang/native/plugin.py
index 7d2c8569f0..cb01d2b72c 100644
--- a/src/sentry/lang/native/plugin.py
+++ b/src/sentry/lang/native/plugin.py
@@ -22,6 +22,7 @@ from sentry.lang.native.utils import \
     get_sdk_from_apple_system_info, cpu_name_from_data, APPLE_SDK_MAPPING, \
     rebase_addr, version_build_from_data
 from sentry.lang.native.systemsymbols import lookup_system_symbols
+from sentry.utils import metrics
 from sentry.stacktraces import StacktraceProcessor
 from sentry.reprocessing import report_processing_issue
 from sentry.constants import NATIVE_UNKNOWN_STRING
@@ -358,6 +359,7 @@ class NativeStacktraceProcessor(StacktraceProcessor):
         debug_meta = self.data.get('debug_meta')
         self.cpu_name = cpu_name_from_data(self.data)
         self.sym = None
+        self.dsyms_referenced = set()
         if debug_meta:
             self.available = True
             self.debug_meta = debug_meta
@@ -368,6 +370,10 @@ class NativeStacktraceProcessor(StacktraceProcessor):
 
     def close(self):
         StacktraceProcessor.close(self)
+        if self.dsyms_referenced:
+            metrics.incr('dsyms.processed',
+                         amount=len(self.dsyms_referenced),
+                         instance=self.project.id)
         if self.sym is not None:
             self.sym.close()
             self.sym = None
@@ -517,6 +523,9 @@ class NativeStacktraceProcessor(StacktraceProcessor):
             }
             in_app = self.sym.is_in_app(sym_input_frame)
             raw_frame['in_app'] = in_app
+            img_uuid = processable_frame.data['image_uuid']
+            if img_uuid is not None:
+                self.dsyms_referenced.add(img_uuid)
             try:
                 symbolicated_frames = self.sym.symbolize_frame(
                     sym_input_frame, self.sdk_info,
diff --git a/src/sentry/stacktraces.py b/src/sentry/stacktraces.py
index e91e75ff82..18ee7ffa90 100644
--- a/src/sentry/stacktraces.py
+++ b/src/sentry/stacktraces.py
@@ -6,7 +6,6 @@ import hashlib
 from collections import namedtuple
 
 from sentry.models import Project
-from sentry.utils import metrics
 from sentry.utils.safe import safe_execute
 from sentry.utils.cache import cache
 
@@ -280,20 +279,6 @@ def process_single_stacktrace(processing_task, stacktrace_info,
     )
 
 
-def get_metrics_key(stacktrace_infos):
-    platforms = set()
-    for info in stacktrace_infos:
-        platforms.update(info.platforms)
-
-    if len(platforms) == 1:
-        platform = next(iter(platforms))
-        if platform == 'javascript':
-            return 'sourcemaps.process'
-        if platform == 'cocoa':
-            return 'dsym.process'
-    return 'mixed.process'
-
-
 def lookup_frame_cache(keys):
     rv = {}
     for key in keys:
@@ -344,35 +329,33 @@ def process_stacktraces(data, make_processors=None):
 
     changed = False
 
-    mkey = get_metrics_key(infos)
-    with metrics.timer(mkey, instance=data['project']):
-        # Build a new processing task
-        processing_task = get_stacktrace_processing_task(infos, processors)
-
-        # Preprocess step
-        for processor in processing_task.iter_processors():
-            if processor.preprocess_step(processing_task):
-                changed = True
-
-        # Process all stacktraces
-        for stacktrace_info, processable_frames in processing_task.iter_processable_stacktraces():
-            new_frames, new_raw_frames, errors = process_single_stacktrace(
-                processing_task, stacktrace_info, processable_frames)
-            if new_frames is not None:
-                stacktrace_info.stacktrace['frames'] = new_frames
-                changed = True
-            if new_raw_frames is not None and \
-               stacktrace_info.container is not None:
-                stacktrace_info.container['raw_stacktrace'] = dict(
-                    stacktrace_info.stacktrace, frames=new_raw_frames)
-                changed = True
-            if errors:
-                data.setdefault('errors', []).extend(errors)
-                changed = True
-
-        # Close down everything
-        for processor in processors:
-            processor.close()
+    # Build a new processing task
+    processing_task = get_stacktrace_processing_task(infos, processors)
+
+    # Preprocess step
+    for processor in processing_task.iter_processors():
+        if processor.preprocess_step(processing_task):
+            changed = True
+
+    # Process all stacktraces
+    for stacktrace_info, processable_frames in processing_task.iter_processable_stacktraces():
+        new_frames, new_raw_frames, errors = process_single_stacktrace(
+            processing_task, stacktrace_info, processable_frames)
+        if new_frames is not None:
+            stacktrace_info.stacktrace['frames'] = new_frames
+            changed = True
+        if new_raw_frames is not None and \
+           stacktrace_info.container is not None:
+            stacktrace_info.container['raw_stacktrace'] = dict(
+                stacktrace_info.stacktrace, frames=new_raw_frames)
+            changed = True
+        if errors:
+            data.setdefault('errors', []).extend(errors)
+            changed = True
+
+    # Close down everything
+    for processor in processors:
+        processor.close()
 
     if changed:
         return data
