commit 4d6641a9f875e67a9492e29bc8f3e4a7c923d604
Author: josh <josh@jrl.ninja>
Date:   Thu Nov 14 16:28:45 2019 -0800

    py3(django): Switch to Django 1.9 (#15399)

diff --git a/.travis.yml b/.travis.yml
index b2d5e3e565..d95b294234 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -35,7 +35,7 @@ env:
     - SENTRY_SKIP_BACKEND_VALIDATION=1
     - MIGRATIONS_TEST_MIGRATE=0
     # Use this to override the django version in the requirements file.
-    - DJANGO_VERSION=">=1.8,<1.9"
+    - DJANGO_VERSION=">=1.9,<1.10"
     # node's version is pinned by .nvmrc and is autodetected by `nvm install`.
     - NODE_DIR="${HOME}/.nvm/versions/node/v$(< .nvmrc)"
     - NODE_OPTIONS=--max-old-space-size=4096
@@ -158,31 +158,11 @@ matrix:
       name: 'Acceptance'
       env: TEST_SUITE=acceptance USE_SNUBA=1
 
-    # allowed to fail
-    - <<: *postgres_default
-      name: 'Django 1.9 Backend [Postgres] (1/2)'
-      env: DJANGO_VERSION=">=1.9,<1.10" TEST_SUITE=postgres DB=postgres TOTAL_TEST_GROUPS=2 TEST_GROUP=0
-
-    # allowed to fail
-    - <<: *postgres_default
-      name: 'Django 1.9 Backend [Postgres] (2/2)'
-      env: DJANGO_VERSION=">=1.9,<1.10" TEST_SUITE=postgres DB=postgres TOTAL_TEST_GROUPS=2 TEST_GROUP=1
-
-    # allowed to fail
-    - <<: *acceptance_default
-      name: 'Django 1.9 Acceptance'
-      env: DJANGO_VERSION=">=1.9,<1.10" TEST_SUITE=acceptance USE_SNUBA=1
-
     # allowed to fail
     - <<: *acceptance_default
       name: 'Plugins'
       env: TEST_SUITE=plugins DB=postgres PERCY_TOKEN=${PLUGIN_PERCY_TOKEN}
 
-    # allowed to fail
-    - <<: *acceptance_default
-      name: 'Django 1.9 Plugins'
-      env: DJANGO_VERSION=">=1.9,<1.10" TEST_SUITE=plugins DB=postgres PERCY_TOKEN=${PLUGIN_PERCY_TOKEN}
-
     - python: 2.7
       name: 'Frontend'
       env: TEST_SUITE=js
@@ -265,11 +245,7 @@ matrix:
 
   allow_failures:
     - name: 'Storybook Deploy'
-    - name: 'Django 1.9 Backend [Postgres] (1/2)'
-    - name: 'Django 1.9 Backend [Postgres] (2/2)'
-    - name: 'Django 1.9 Acceptance'
     - name: 'Plugins'
-    - name: 'Django 1.9 Plugins'
 
 notifications:
   webhooks:
diff --git a/requirements-base.txt b/requirements-base.txt
index d986a31bef..20acea4d1a 100644
--- a/requirements-base.txt
+++ b/requirements-base.txt
@@ -14,7 +14,7 @@ cssutils==1.0.2
 django-crispy-forms==1.6.1
 django-picklefield>=0.3.0,<1.1.0
 django-sudo>=2.1.0,<3.0.0
-Django>=1.8,<1.9
+Django>=1.9,<1.10
 djangorestframework==3.4.7
 email-reply-parser>=0.2.0,<0.3.0
 enum34>=1.1.6,<1.2.0
diff --git a/src/sentry/api/endpoints/debug_files.py b/src/sentry/api/endpoints/debug_files.py
index 7a0a7b338b..adf050a164 100644
--- a/src/sentry/api/endpoints/debug_files.py
+++ b/src/sentry/api/endpoints/debug_files.py
@@ -7,6 +7,7 @@ import posixpath
 
 from django.db import transaction
 from django.db.models import Q
+from django.http import StreamingHttpResponse, HttpResponse, Http404
 from rest_framework.response import Response
 from symbolic import normalize_debug_id, SymbolicError
 
@@ -26,15 +27,6 @@ from sentry.tasks.assemble import (
 )
 from sentry.utils import json
 
-try:
-    from django.http import (
-        CompatibleStreamingHttpResponse as StreamingHttpResponse,
-        HttpResponse,
-        Http404,
-    )
-except ImportError:
-    from django.http import StreamingHttpResponse, HttpResponse, Http404
-
 
 logger = logging.getLogger("sentry.api")
 ERR_FILE_EXISTS = "A file matching this debug identifier already exists"
diff --git a/src/sentry/api/endpoints/event_apple_crash_report.py b/src/sentry/api/endpoints/event_apple_crash_report.py
index ef373ee1a8..0f0d796c6b 100644
--- a/src/sentry/api/endpoints/event_apple_crash_report.py
+++ b/src/sentry/api/endpoints/event_apple_crash_report.py
@@ -2,10 +2,7 @@ from __future__ import absolute_import
 
 import six
 
-try:
-    from django.http import HttpResponse, CompatibleStreamingHttpResponse as StreamingHttpResponse
-except ImportError:
-    from django.http import HttpResponse, StreamingHttpResponse
+from django.http import HttpResponse, StreamingHttpResponse
 
 from sentry import eventstore
 from sentry.api.bases.project import ProjectEndpoint
diff --git a/src/sentry/api/endpoints/event_attachment_details.py b/src/sentry/api/endpoints/event_attachment_details.py
index a3d2f1ca69..50d3fc6a84 100644
--- a/src/sentry/api/endpoints/event_attachment_details.py
+++ b/src/sentry/api/endpoints/event_attachment_details.py
@@ -3,10 +3,7 @@ from __future__ import absolute_import
 import posixpath
 import six
 
-try:
-    from django.http import CompatibleStreamingHttpResponse as StreamingHttpResponse
-except ImportError:
-    from django.http import StreamingHttpResponse
+from django.http import StreamingHttpResponse
 
 from sentry import eventstore, features, roles
 from sentry.api.bases.project import ProjectEndpoint, ProjectPermission
diff --git a/src/sentry/api/endpoints/organization_release_file_details.py b/src/sentry/api/endpoints/organization_release_file_details.py
index 839ad3bc86..8b05380152 100644
--- a/src/sentry/api/endpoints/organization_release_file_details.py
+++ b/src/sentry/api/endpoints/organization_release_file_details.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 import posixpath
 
+from django.http import StreamingHttpResponse
 from rest_framework import serializers
 from rest_framework.response import Response
 
@@ -10,11 +11,6 @@ from sentry.api.exceptions import ResourceDoesNotExist
 from sentry.api.serializers import serialize
 from sentry.models import Release, ReleaseFile
 
-try:
-    from django.http import CompatibleStreamingHttpResponse as StreamingHttpResponse
-except ImportError:
-    from django.http import StreamingHttpResponse
-
 
 class ReleaseFileSerializer(serializers.Serializer):
     name = serializers.CharField(max_length=200, required=True)
diff --git a/src/sentry/api/endpoints/project_release_file_details.py b/src/sentry/api/endpoints/project_release_file_details.py
index fb328cdad0..ac4b7f4499 100644
--- a/src/sentry/api/endpoints/project_release_file_details.py
+++ b/src/sentry/api/endpoints/project_release_file_details.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 import posixpath
 
+from django.http import StreamingHttpResponse
 from rest_framework import serializers
 from rest_framework.response import Response
 
@@ -11,11 +12,6 @@ from sentry.api.serializers import serialize
 from sentry.models import Release, ReleaseFile
 from sentry.utils.apidocs import scenario, attach_scenarios
 
-try:
-    from django.http import CompatibleStreamingHttpResponse as StreamingHttpResponse
-except ImportError:
-    from django.http import StreamingHttpResponse
-
 
 @scenario("RetrieveReleaseFile")
 def retrieve_file_scenario(runner):
diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 4bc1528ae0..0f9f441d8b 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -373,14 +373,10 @@ CSRF_COOKIE_NAME = "sc"
 
 # Auth configuration
 
-try:
-    from django.core.urlresolvers import reverse_lazy
-except ImportError:
-    LOGIN_REDIRECT_URL = "/login-redirect/"
-    LOGIN_URL = "/auth/login/"
-else:
-    LOGIN_REDIRECT_URL = reverse_lazy("sentry-login-redirect")
-    LOGIN_URL = reverse_lazy("sentry-login")
+from django.core.urlresolvers import reverse_lazy
+
+LOGIN_REDIRECT_URL = reverse_lazy("sentry-login-redirect")
+LOGIN_URL = reverse_lazy("sentry-login")
 
 AUTHENTICATION_BACKENDS = (
     "sentry.utils.auth.EmailAuthBackend",
diff --git a/src/sentry/conf/urls.py b/src/sentry/conf/urls.py
index 205b82474b..5088cf6820 100644
--- a/src/sentry/conf/urls.py
+++ b/src/sentry/conf/urls.py
@@ -10,12 +10,8 @@ These are additional urls used by the Sentry-provided web server
 from __future__ import absolute_import
 
 from django.conf import settings
+from django.conf.urls import patterns, url
 
-try:
-    from django.conf.urls import include, patterns, url
-except ImportError:
-    # django < 1.5 compat
-    from django.conf.urls.defaults import include, patterns, url  # NOQA
 
 from sentry.web.urls import urlpatterns as web_urlpatterns
 from sentry.web.frontend.csrf_failure import CsrfFailureView
diff --git a/src/sentry/db/models/fields/foreignkey.py b/src/sentry/db/models/fields/foreignkey.py
index 5f5bf6c861..3e411286b8 100644
--- a/src/sentry/db/models/fields/foreignkey.py
+++ b/src/sentry/db/models/fields/foreignkey.py
@@ -1,6 +1,5 @@
 from __future__ import absolute_import
 
-import django
 from django.db.models import ForeignKey
 
 __all__ = ("FlexibleForeignKey",)
@@ -9,10 +8,7 @@ __all__ = ("FlexibleForeignKey",)
 class FlexibleForeignKey(ForeignKey):
     def db_type(self, connection):
         # This is required to support BigAutoField (or anything similar)
-        if django.VERSION >= (1, 9):
-            rel_field = self.target_field
-        else:
-            rel_field = self.related_field
+        rel_field = self.target_field
         if hasattr(rel_field, "get_related_db_type"):
             return rel_field.get_related_db_type(connection)
         return super(FlexibleForeignKey, self).db_type(connection)
diff --git a/src/sentry/new_migrations/django_19_executor/__init__.py b/src/sentry/new_migrations/django_19_executor/__init__.py
deleted file mode 100644
index c3961685ab..0000000000
--- a/src/sentry/new_migrations/django_19_executor/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from __future__ import absolute_import
diff --git a/src/sentry/new_migrations/django_19_executor/django.py b/src/sentry/new_migrations/django_19_executor/django.py
deleted file mode 100644
index ae37728cd6..0000000000
--- a/src/sentry/new_migrations/django_19_executor/django.py
+++ /dev/null
@@ -1,328 +0,0 @@
-from __future__ import absolute_import, unicode_literals
-
-from django.apps.registry import apps as global_apps
-from django.db import migrations
-from django.db.migrations.loader import MigrationLoader
-from django.db.migrations.recorder import MigrationRecorder
-from django.db.migrations.state import ProjectState
-
-
-class InvalidMigrationPlan(ValueError):
-    """
-    Backported from Django 1.9.1, containing changes from:
-
-    https://github.com/django/django/commit/5aa55038ca9ac44b440b56d1fc4e79c876e51393
-    """
-
-    pass
-
-
-class Django19MigrationExecutor(object):
-    """
-    End-to-end migration execution - loads migrations, and runs them
-    up or down to a specified set of targets.
-
-    Backported from Django 1.9.1, containing changes from:
-
-    https://github.com/django/django/commit/5aa55038ca9ac44b440b56d1fc4e79c876e51393
-    https://github.com/django/django/commit/a80fb8ae24e77abf20047b9dfe867b4b53a8d648
-    """
-
-    def __init__(self, connection, progress_callback=None):
-        self.connection = connection
-        self.loader = MigrationLoader(self.connection)
-        self.recorder = MigrationRecorder(self.connection)
-        self.progress_callback = progress_callback
-
-    def migration_plan(self, targets, clean_start=False):
-        """
-        Given a set of targets, returns a list of (Migration instance, backwards?).
-        """
-        plan = []
-        if clean_start:
-            applied = set()
-        else:
-            applied = set(self.loader.applied_migrations)
-        for target in targets:
-            # If the target is (app_label, None), that means unmigrate everything
-            if target[1] is None:
-                for root in self.loader.graph.root_nodes():
-                    if root[0] == target[0]:
-                        for migration in self.loader.graph.backwards_plan(root):
-                            if migration in applied:
-                                plan.append((self.loader.graph.nodes[migration], True))
-                                applied.remove(migration)
-            # If the migration is already applied, do backwards mode,
-            # otherwise do forwards mode.
-            elif target in applied:
-                # Don't migrate backwards all the way to the target node (that
-                # may roll back dependencies in other apps that don't need to
-                # be rolled back); instead roll back through target's immediate
-                # child(ren) in the same app, and no further.
-                next_in_app = sorted(
-                    n for n in self.loader.graph.node_map[target].children if n[0] == target[0]
-                )
-                for node in next_in_app:
-                    for migration in self.loader.graph.backwards_plan(node):
-                        if migration in applied:
-                            plan.append((self.loader.graph.nodes[migration], True))
-                            applied.remove(migration)
-            else:
-                for migration in self.loader.graph.forwards_plan(target):
-                    if migration not in applied:
-                        plan.append((self.loader.graph.nodes[migration], False))
-                        applied.add(migration)
-        return plan
-
-    def migrate(self, targets, plan=None, fake=False, fake_initial=False):
-        """
-        Migrates the database up to the given targets.
-
-        Django first needs to create all project states before a migration is
-        (un)applied and in a second step run all the database operations.
-        """
-        if plan is None:
-            plan = self.migration_plan(targets)
-        # Create the forwards plan Django would follow on an empty database
-        full_plan = self.migration_plan(self.loader.graph.leaf_nodes(), clean_start=True)
-
-        all_forwards = all(not backwards for mig, backwards in plan)
-        all_backwards = all(backwards for mig, backwards in plan)
-
-        if not plan:
-            pass  # Nothing to do for an empty plan
-        elif all_forwards == all_backwards:
-            # This should only happen if there's a mixed plan
-            raise InvalidMigrationPlan(
-                "Migration plans with both forwards and backwards migrations "
-                "are not supported. Please split your migration process into "
-                "separate plans of only forwards OR backwards migrations.",
-                plan,
-            )
-        elif all_forwards:
-            self._migrate_all_forwards(plan, full_plan, fake=fake, fake_initial=fake_initial)
-        else:
-            # No need to check for `elif all_backwards` here, as that condition
-            # would always evaluate to true.
-            self._migrate_all_backwards(plan, full_plan, fake=fake)
-
-        self.check_replacements()
-
-    def _migrate_all_forwards(self, plan, full_plan, fake, fake_initial):
-        """
-        Take a list of 2-tuples of the form (migration instance, False) and
-        apply them in the order they occur in the full_plan.
-        """
-        migrations_to_run = {m[0] for m in plan}
-        state = ProjectState(real_apps=list(self.loader.unmigrated_apps))
-        for migration, _ in full_plan:
-            if not migrations_to_run:
-                # We remove every migration that we applied from this set so
-                # that we can bail out once the last migration has been applied
-                # and don't always run until the very end of the migration
-                # process.
-                break
-            if migration in migrations_to_run:
-                if "apps" not in state.__dict__:
-                    if self.progress_callback:
-                        self.progress_callback("render_start")
-                    state.apps  # Render all -- performance critical
-                    if self.progress_callback:
-                        self.progress_callback("render_success")
-                state = self.apply_migration(state, migration, fake=fake, fake_initial=fake_initial)
-                migrations_to_run.remove(migration)
-            else:
-                migration.mutate_state(state, preserve=False)
-
-    def _migrate_all_backwards(self, plan, full_plan, fake):
-        """
-        Take a list of 2-tuples of the form (migration instance, True) and
-        unapply them in reverse order they occur in the full_plan.
-
-        Since unapplying a migration requires the project state prior to that
-        migration, Django will compute the migration states before each of them
-        in a first run over the plan and then unapply them in a second run over
-        the plan.
-        """
-        migrations_to_run = {m[0] for m in plan}
-        # Holds all migration states prior to the migrations being unapplied
-        states = {}
-        state = ProjectState(real_apps=list(self.loader.unmigrated_apps))
-        if self.progress_callback:
-            self.progress_callback("render_start")
-        for migration, _ in full_plan:
-            if not migrations_to_run:
-                # We remove every migration that we applied from this set so
-                # that we can bail out once the last migration has been applied
-                # and don't always run until the very end of the migration
-                # process.
-                break
-            if migration in migrations_to_run:
-                if "apps" not in state.__dict__:
-                    state.apps  # Render all -- performance critical
-                # The state before this migration
-                states[migration] = state
-                # The old state keeps as-is, we continue with the new state
-                state = migration.mutate_state(state, preserve=True)
-                migrations_to_run.remove(migration)
-            else:
-                migration.mutate_state(state, preserve=False)
-        if self.progress_callback:
-            self.progress_callback("render_success")
-
-        for migration, _ in plan:
-            self.unapply_migration(states[migration], migration, fake=fake)
-
-    def collect_sql(self, plan):
-        """
-        Takes a migration plan and returns a list of collected SQL
-        statements that represent the best-efforts version of that plan.
-        """
-        statements = []
-        state = None
-        for migration, backwards in plan:
-            with self.connection.schema_editor(collect_sql=True) as schema_editor:
-                if state is None:
-                    state = self.loader.project_state(
-                        (migration.app_label, migration.name), at_end=False
-                    )
-                if not backwards:
-                    state = migration.apply(state, schema_editor, collect_sql=True)
-                else:
-                    state = migration.unapply(state, schema_editor, collect_sql=True)
-            statements.extend(schema_editor.collected_sql)
-        return statements
-
-    def apply_migration(self, state, migration, fake=False, fake_initial=False):
-        """
-        Runs a migration forwards.
-        """
-        if self.progress_callback:
-            self.progress_callback("apply_start", migration, fake)
-        if not fake:
-            if fake_initial:
-                # Test to see if this is an already-applied initial migration
-                applied, state = self.detect_soft_applied(state, migration)
-                if applied:
-                    fake = True
-            if not fake:
-                # Alright, do it normally
-                with self.connection.schema_editor() as schema_editor:
-                    state = migration.apply(state, schema_editor)
-        # For replacement migrations, record individual statuses
-        if migration.replaces:
-            for app_label, name in migration.replaces:
-                self.recorder.record_applied(app_label, name)
-        else:
-            self.recorder.record_applied(migration.app_label, migration.name)
-        # Report progress
-        if self.progress_callback:
-            self.progress_callback("apply_success", migration, fake)
-        return state
-
-    def unapply_migration(self, state, migration, fake=False):
-        """
-        Runs a migration backwards.
-        """
-        if self.progress_callback:
-            self.progress_callback("unapply_start", migration, fake)
-        if not fake:
-            with self.connection.schema_editor() as schema_editor:
-                state = migration.unapply(state, schema_editor)
-        # For replacement migrations, record individual statuses
-        if migration.replaces:
-            for app_label, name in migration.replaces:
-                self.recorder.record_unapplied(app_label, name)
-        else:
-            self.recorder.record_unapplied(migration.app_label, migration.name)
-        # Report progress
-        if self.progress_callback:
-            self.progress_callback("unapply_success", migration, fake)
-        return state
-
-    def check_replacements(self):
-        """
-        Mark replacement migrations applied if their replaced set all are.
-
-        We do this unconditionally on every migrate, rather than just when
-        migrations are applied or unapplied, so as to correctly handle the case
-        when a new squash migration is pushed to a deployment that already had
-        all its replaced migrations applied. In this case no new migration will
-        be applied, but we still want to correctly maintain the applied state
-        of the squash migration.
-        """
-        applied = self.recorder.applied_migrations()
-        for key, migration in self.loader.replacements.items():
-            all_applied = all(m in applied for m in migration.replaces)
-            if all_applied and key not in applied:
-                self.recorder.record_applied(*key)
-
-    def detect_soft_applied(self, project_state, migration):
-        """
-        Tests whether a migration has been implicitly applied - that the
-        tables or columns it would create exist. This is intended only for use
-        on initial migrations (as it only looks for CreateModel and AddField).
-        """
-        if migration.initial is None:
-            # Bail if the migration isn't the first one in its app
-            if any(app == migration.app_label for app, name in migration.dependencies):
-                return False, project_state
-        elif migration.initial is False:
-            # Bail if it's NOT an initial migration
-            return False, project_state
-
-        if project_state is None:
-            after_state = self.loader.project_state(
-                (migration.app_label, migration.name), at_end=True
-            )
-        else:
-            after_state = migration.mutate_state(project_state)
-        apps = after_state.apps
-        found_create_model_migration = False
-        found_add_field_migration = False
-        existing_table_names = self.connection.introspection.table_names(self.connection.cursor())
-        # Make sure all create model and add field operations are done
-        for operation in migration.operations:
-            if isinstance(operation, migrations.CreateModel):
-                model = apps.get_model(migration.app_label, operation.name)
-                if model._meta.swapped:
-                    # We have to fetch the model to test with from the
-                    # main app cache, as it's not a direct dependency.
-                    model = global_apps.get_model(model._meta.swapped)
-                if model._meta.proxy or not model._meta.managed:
-                    continue
-                if model._meta.db_table not in existing_table_names:
-                    return False, project_state
-                found_create_model_migration = True
-            elif isinstance(operation, migrations.AddField):
-                model = apps.get_model(migration.app_label, operation.model_name)
-                if model._meta.swapped:
-                    # We have to fetch the model to test with from the
-                    # main app cache, as it's not a direct dependency.
-                    model = global_apps.get_model(model._meta.swapped)
-                if model._meta.proxy or not model._meta.managed:
-                    continue
-
-                table = model._meta.db_table
-                field = model._meta.get_field(operation.name)
-
-                # Handle implicit many-to-many tables created by AddField.
-                if field.many_to_many:
-                    if field.remote_field.through._meta.db_table not in existing_table_names:
-                        return False, project_state
-                    else:
-                        found_add_field_migration = True
-                        continue
-
-                column_names = [
-                    column.name
-                    for column in self.connection.introspection.get_table_description(
-                        self.connection.cursor(), table
-                    )
-                ]
-                if field.column not in column_names:
-                    return False, project_state
-                found_add_field_migration = True
-        # If we get this far and we found at least one CreateModel or AddField migration,
-        # the migration is considered implicitly applied.
-        return (found_create_model_migration or found_add_field_migration), after_state
diff --git a/src/sentry/new_migrations/monkey/__init__.py b/src/sentry/new_migrations/monkey/__init__.py
index 0be02c5d1e..0942af9243 100644
--- a/src/sentry/new_migrations/monkey/__init__.py
+++ b/src/sentry/new_migrations/monkey/__init__.py
@@ -27,9 +27,7 @@ changes are backwards incompatible, change the monkeying to handle both versions
 if VERSION[:2] > LAST_VERIFIED_DJANGO_VERSION:
     raise Exception(CHECK_MESSAGE)
 
-# Monkeypatch Django 1.8 migration executor to use the much faster version
-# from Django 1.9.1. We'll continue to monkeypatch once we're on 1.9.1, just a smaller
-# set of functionality
+# monkeypatch Django's migration executor and template.
 executor.MigrationExecutor = SentryMigrationExecutor
 migration.Migration.initial = None
 writer.MIGRATION_TEMPLATE = SENTRY_MIGRATION_TEMPLATE
diff --git a/src/sentry/new_migrations/monkey/executor.py b/src/sentry/new_migrations/monkey/executor.py
index 05ab393274..4fae92763a 100644
--- a/src/sentry/new_migrations/monkey/executor.py
+++ b/src/sentry/new_migrations/monkey/executor.py
@@ -3,15 +3,12 @@ from __future__ import absolute_import
 import logging
 import os
 
-from sentry.new_migrations.django_19_executor.django import Django19MigrationExecutor
+from django.db.migrations.executor import MigrationExecutor
 
 logger = logging.getLogger(__name__)
 
 
-class SentryMigrationExecutor(Django19MigrationExecutor):
-    # TODO: Once we're on Django 1.9, just inherit from
-    # `django.db.migrations.executor.MigrationExecutor`
-
+class SentryMigrationExecutor(MigrationExecutor):
     def _check_fake(self, migration, fake):
         if (
             os.environ.get("MIGRATION_SKIP_DANGEROUS", "0") == "1"
diff --git a/src/sentry/new_migrations/monkey/writer.py b/src/sentry/new_migrations/monkey/writer.py
index bcfc8c13d2..d51c84d8ea 100644
--- a/src/sentry/new_migrations/monkey/writer.py
+++ b/src/sentry/new_migrations/monkey/writer.py
@@ -1,16 +1,14 @@
 from __future__ import absolute_import
 
-# This should be exactly the same as `django.db.migrations.writer.py.MIGRATION_TEMPLATE`,
-# except that we add
-# - `atomic = False`
-# - `is_dangerous = False`
-# to the class definition. Compare this template after each Django version bump to make
+# This should be exactly the same as MIGRATION_TEMPLATE in `django.db.migrations.writer.py`,
+# except that we add `is_dangerous = False` to the class definition.
+# Compare this template after each Django version bump to make
 # sure we're not missing any important changes.
 SENTRY_MIGRATION_TEMPLATE = """\
 # -*- coding: utf-8 -*-
+# Generated by Django %(version)s on %(timestamp)s
 from __future__ import unicode_literals
 
-from django.db import migrations, models
 %(imports)s
 
 class Migration(migrations.Migration):
@@ -28,7 +26,7 @@ class Migration(migrations.Migration):
     # - Adding columns to highly active tables, even ones that are NULL.
     is_dangerous = False
 
-%(replaces_str)s
+%(replaces_str)s%(initial_str)s
     dependencies = [
 %(dependencies)s\
     ]
diff --git a/src/sentry/runner/initializer.py b/src/sentry/runner/initializer.py
index 712699f1db..ef9131fb72 100644
--- a/src/sentry/runner/initializer.py
+++ b/src/sentry/runner/initializer.py
@@ -395,8 +395,8 @@ def validate_options(settings):
 
 
 def monkeypatch_django_migrations():
-    # This monkey patches the django 1.8 migration executor with a backported 1.9
-    # executor. This improves the speed that Django builds the migration state.
+    # This monkeypatches django's migration executor with our own, which
+    # adds some small but important customizations.
     import sentry.new_migrations.monkey  # NOQA
 
 
diff --git a/src/sentry/tagstore/query.py b/src/sentry/tagstore/query.py
index 04803f612a..3a23440384 100644
--- a/src/sentry/tagstore/query.py
+++ b/src/sentry/tagstore/query.py
@@ -3,12 +3,7 @@ from __future__ import absolute_import, print_function
 from django.db.models import sql
 from django.db.models.query import QuerySet
 from sentry.db.models import BaseManager
-
-try:
-    # Django 1.7+
-    from django.db.models.sql.constants import CURSOR
-except ImportError:
-    CURSOR = None
+from django.db.models.sql.constants import CURSOR
 
 
 class NoTransactionUpdateQuerySet(QuerySet):
diff --git a/src/sentry/utils/db.py b/src/sentry/utils/db.py
index 3fc8aacedf..287c8cab12 100644
--- a/src/sentry/utils/db.py
+++ b/src/sentry/utils/db.py
@@ -5,13 +5,7 @@ import six
 from django.conf import settings
 from django.db import connections, DEFAULT_DB_ALIAS
 
-# TODO: (Django 1.9) Remove once on Django 1.9+
-try:
-    from django.db.models.fields.related_descriptors import ReverseOneToOneDescriptor
-except ImportError:
-    from django.db.models.fields.related import (
-        SingleRelatedObjectDescriptor as ReverseOneToOneDescriptor,
-    )
+from django.db.models.fields.related_descriptors import ReverseOneToOneDescriptor
 
 
 def get_db_engine(alias="default"):
diff --git a/src/sentry/utils/pytest/sentry.py b/src/sentry/utils/pytest/sentry.py
index c939aa2555..e0547fc4b5 100644
--- a/src/sentry/utils/pytest/sentry.py
+++ b/src/sentry/utils/pytest/sentry.py
@@ -128,9 +128,9 @@ def pytest_configure(config):
     patcher.start()
 
     if not settings.MIGRATIONS_TEST_MIGRATE:
-        # TODO: In Django 1.9 the value can be set to `None` rather than a nonexistent
-        # module.
-        settings.MIGRATION_MODULES["sentry"] = "sentry.migrations_not_used_in_tests"
+        # Migrations for the "sentry" app take a long time to run, which makes test startup time slow in dev.
+        # This is a hack to force django to sync the database state from the models rather than use migrations.
+        settings.MIGRATION_MODULES["sentry"] = None
 
     from sentry.runner.initializer import (
         bind_cache_to_option_store,
diff --git a/tests/snuba/api/endpoints/test_organization_group_index.py b/tests/snuba/api/endpoints/test_organization_group_index.py
index 20bf012de6..a8a9b55e05 100644
--- a/tests/snuba/api/endpoints/test_organization_group_index.py
+++ b/tests/snuba/api/endpoints/test_organization_group_index.py
@@ -5,7 +5,6 @@ import six
 from datetime import timedelta
 from uuid import uuid4
 
-import django
 from django.core.urlresolvers import reverse
 from django.utils import timezone
 from mock import patch, Mock
@@ -1181,15 +1180,7 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         response = self.get_valid_response(
             qs_params={"id": [group1.id, group2.id]}, isPublic="false"
         )
-        if django.VERSION < (1, 9):
-            assert response.data == {"isPublic": False}
-        else:
-            # In Django < 1.9 `.delete()` returns nothing, even if it manages to delete
-            # rows. In 1.9+ it returns information about how many rows were deleted.
-            # We use `.delete()` in an if statement when setting `isPublic`, and it was
-            # always returning False due to this. Since this is fixed we now have this
-            # extra attribute.
-            assert response.data == {"isPublic": False, "shareId": None}
+        assert response.data == {"isPublic": False, "shareId": None}
 
         new_group1 = Group.objects.get(id=group1.id)
         assert not bool(new_group1.get_share_id())
diff --git a/tests/snuba/api/endpoints/test_project_group_index.py b/tests/snuba/api/endpoints/test_project_group_index.py
index 164254ca05..6762579edc 100644
--- a/tests/snuba/api/endpoints/test_project_group_index.py
+++ b/tests/snuba/api/endpoints/test_project_group_index.py
@@ -4,7 +4,6 @@ import json
 from datetime import timedelta
 from uuid import uuid4
 
-import django
 import six
 from django.utils import timezone
 from exam import fixture
@@ -1113,15 +1112,7 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         )
         response = self.client.put(url, data={"isPublic": "false"}, format="json")
         assert response.status_code == 200
-        if django.VERSION < (1, 9):
-            assert response.data == {"isPublic": False}
-        else:
-            # In Django < 1.9 `.delete()` returns nothing, even if it manages to delete
-            # rows. In 1.9+ it returns information about how many rows were deleted.
-            # We use `.delete()` in an if statement when setting `isPublic`, and it was
-            # always returning False due to this. Since this is fixed we now have this
-            # extra attribute.
-            assert response.data == {"isPublic": False, "shareId": None}
+        assert response.data == {"isPublic": False, "shareId": None}
 
         new_group1 = Group.objects.get(id=group1.id)
         assert not bool(new_group1.get_share_id())
