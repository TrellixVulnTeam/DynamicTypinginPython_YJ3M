commit 1be31397210eb749b2586868cb384b4138996942
Author: ted kaemming <ted@kaemming.com>
Date:   Fri Feb 10 11:36:47 2017 -0800

    Add `FeatureSet` used to record and query group similarity. (#4893)
    
    * Add BidirectionalMapping.
    * Add event processors.

diff --git a/src/sentry/similarity.py b/src/sentry/similarity.py
index a52b6718eb..5ac78376a0 100644
--- a/src/sentry/similarity.py
+++ b/src/sentry/similarity.py
@@ -1,10 +1,17 @@
 from __future__ import absolute_import
 
 import itertools
+import logging
 import math
+import operator
 import struct
 
 import mmh3
+from django.conf import settings
+
+from sentry.utils import redis
+from sentry.utils.datastructures import BidirectionalMapping
+from sentry.utils.iterators import shingle
 
 
 def scale_to_total(value):
@@ -32,7 +39,7 @@ def get_euclidian_distance(target, other):
 
 
 def get_manhattan_distance(target, other):
-    """
+    """\
     Calculate the N-dimensional Manhattan distance between two mappings.
 
     The mappings are used to represent sparse arrays -- if a key is not present
@@ -99,8 +106,8 @@ class MinHashIndex(object):
       what other keys may be similar to the lookup key (but not the degree of
       similarity.)
     """
-    BUCKET_MEMBERSHIP = '0'
-    BUCKET_FREQUENCY = '1'
+    BUCKET_MEMBERSHIP = b'\x00'
+    BUCKET_FREQUENCY = b'\x01'
 
     def __init__(self, cluster, rows, bands, buckets):
         self.namespace = b'sim'
@@ -111,6 +118,7 @@ class MinHashIndex(object):
         sequence = itertools.count()
         self.bands = [[next(sequence) for j in xrange(buckets)] for i in xrange(bands)]
 
+        self.__band_format = get_number_format(bands)
         self.__bucket_format = get_number_format(rows, buckets)
 
     def get_signature(self, value):
@@ -168,7 +176,13 @@ class MinHashIndex(object):
                 responses = {
                     key: map(
                         lambda band: client.zrange(
-                            b'{}:{}:{}:{}:{}'.format(self.namespace, scope, self.BUCKET_FREQUENCY, band, key),
+                            b'{}:{}:{}:{}:{}'.format(
+                                self.namespace,
+                                scope,
+                                self.BUCKET_FREQUENCY,
+                                self.__band_format.pack(band),
+                                key,
+                            ),
                             0,
                             -1,
                             desc=True,
@@ -202,7 +216,7 @@ class MinHashIndex(object):
                                 self.namespace,
                                 scope,
                                 self.BUCKET_MEMBERSHIP,
-                                band,
+                                self.__band_format.pack(band),
                                 self.__bucket_format.pack(*bucket),
                             )
                         ),
@@ -258,11 +272,23 @@ class MinHashIndex(object):
                 for band, buckets in enumerate(self.get_signature(characteristics)):
                     buckets = self.__bucket_format.pack(*buckets)
                     client.sadd(
-                        b'{}:{}:{}:{}:{}'.format(self.namespace, scope, self.BUCKET_MEMBERSHIP, band, buckets),
+                        b'{}:{}:{}:{}:{}'.format(
+                            self.namespace,
+                            scope,
+                            self.BUCKET_MEMBERSHIP,
+                            self.__band_format.pack(band),
+                            buckets,
+                        ),
                         key,
                     )
                     client.zincrby(
-                        b'{}:{}:{}:{}:{}'.format(self.namespace, scope, self.BUCKET_FREQUENCY, band, key),
+                        b'{}:{}:{}:{}:{}'.format(
+                            self.namespace,
+                            scope,
+                            self.BUCKET_FREQUENCY,
+                            self.__band_format.pack(band),
+                            key,
+                        ),
                         buckets,
                         1,
                     )
@@ -272,3 +298,220 @@ class MinHashIndex(object):
         return self.record_multi([
             (scope, key, characteristics),
         ])
+
+
+FRAME_ITEM_SEPARATOR = b'\x00'
+FRAME_PAIR_SEPARATOR = b'\x01'
+FRAME_SEPARATOR = b'\x02'
+
+FRAME_FUNCTION_KEY = b'\x10'
+FRAME_MODULE_KEY = b'\x11'
+FRAME_FILENAME_KEY = b'\x12'
+
+
+def serialize_frame(frame):
+    """\
+    Convert a frame value from a ``Stacktrace`` interface into a bytes object.
+    """
+    # TODO(tkaemming): This should likely result in an intermediate data
+    # structure that is easier to introspect than this one, and a separate
+    # serialization step before hashing.
+    # TODO(tkaemming): These frame values need platform-specific normalization.
+    # This probably should be done prior to this method being called...?
+    attributes = {
+        FRAME_FUNCTION_KEY: frame['function']
+    }
+
+    module = frame.get('module')
+    if module:
+        attributes[FRAME_MODULE_KEY] = module
+    else:
+        attributes[FRAME_FILENAME_KEY] = frame['filename']
+
+    return FRAME_ITEM_SEPARATOR.join(
+        map(
+            lambda item: FRAME_PAIR_SEPARATOR.join(
+                map(
+                    operator.methodcaller('encode', 'utf8'),
+                    item,
+                ),
+            ),
+            attributes.items(),
+        ),
+    )
+
+
+def get_application_chunks(exception):
+    """\
+    Filters out system and framework frames from a stacktrace in order to
+    better align similar logical application paths. This returns a sequence of
+    application code "chunks": blocks of contiguously called application code.
+    """
+    return map(
+        lambda (in_app, frames): list(frames),
+        itertools.ifilter(
+            lambda (in_app, frames): in_app,
+            itertools.groupby(
+                exception['stacktrace']['frames'],
+                key=lambda frame: frame.get('in_app', False),
+            )
+        )
+    )
+
+
+class ExceptionFeature(object):
+    def __init__(self, function):
+        self.function = function
+        self.logger = logging.getLogger(__name__)
+
+    def extract(self, event):
+        try:
+            exceptions = event.data['sentry.interfaces.Exception']['values']
+        except KeyError as error:
+            self.logger.info('Could not extract characteristic(s) from %r due error: %r', event, error, exc_info=True)
+            return
+
+        for exception in exceptions:
+            try:
+                yield self.function(exception)
+            except Exception as error:
+                self.logger.exception('Could not extract characteristic(s) from exception in %r due to error: %r', event, error)
+
+
+class MessageFeature(object):
+    def __init__(self, function):
+        self.function = function
+        self.logger = logging.getLogger(__name__)
+
+    def extract(self, event):
+        try:
+            message = event.data['sentry.interfaces.Message']
+        except KeyError as error:
+            self.logger.info('Could not extract characteristic(s) from %r due error: %r', event, error, exc_info=True)
+            return
+
+        try:
+            yield self.function(message)
+        except Exception as error:
+            self.logger.exception('Could not extract characteristic(s) from message of %r due to error: %r', event, error)
+
+
+class FeatureSet(object):
+    def __init__(self, index, aliases, features):
+        self.index = index
+        self.aliases = aliases
+        self.features = features
+        self.__number_format = get_number_format(0xFFFFFFFF)
+        assert set(self.aliases) == set(self.features)
+
+    def record(self, event):
+        items = []
+        for label, feature in self.features.items():
+            alias = self.aliases[label]
+            scope = ':'.join((
+                alias,
+                self.__number_format.pack(event.project_id),
+            ))
+            for characteristics in feature.extract(event):
+                if characteristics:
+                    items.append((
+                        scope,
+                        self.__number_format.pack(event.group_id),
+                        characteristics,
+                    ))
+        return self.index.record_multi(items)
+
+    def query(self, group):
+        results = {}
+        key = self.__number_format.pack(group.id)
+        for label in self.features.keys():
+            alias = self.aliases[label]
+            scope = ':'.join((
+                alias,
+                self.__number_format.pack(group.project_id)
+            ))
+            results[label] = map(
+                lambda (id, score): (
+                    self.__number_format.unpack(id)[0],
+                    score,
+                ),
+                self.index.query(scope, key)
+            )
+        return results
+
+
+def serialize_text_shingle(value, separator=b''):
+    """\
+    Convert a sequence of Unicode strings into a bytes object.
+    """
+    return separator.join(
+        map(
+            operator.methodcaller('encode', 'utf8'),
+            value,
+        ),
+    )
+
+
+features = FeatureSet(
+    MinHashIndex(
+        redis.clusters.get(
+            getattr(
+                settings,
+                'SENTRY_SIMILARITY_INDEX_REDIS_CLUSTER',
+                'default',
+            ),
+        ),
+        0xFFFF,
+        8,
+        2,
+    ),
+    BidirectionalMapping({
+        'exception:message:character-shingles': '\x00',
+        'exception:stacktrace:application-chunks': '\x01',
+        'exception:stacktrace:pairs': '\x02',
+        'message:message:character-shingles': '\x03',
+    }),
+    {
+        'exception:message:character-shingles': ExceptionFeature(
+            lambda exception: map(
+                serialize_text_shingle,
+                shingle(
+                    13,
+                    exception['value'],
+                ),
+            )
+        ),
+        'exception:stacktrace:application-chunks': ExceptionFeature(
+            lambda exception: map(
+                lambda frames: FRAME_SEPARATOR.join(
+                    map(
+                        serialize_frame,
+                        frames,
+                    ),
+                ),
+                get_application_chunks(exception),
+            ),
+        ),
+        'exception:stacktrace:pairs': ExceptionFeature(
+            lambda exception: map(
+                FRAME_SEPARATOR.join,
+                shingle(
+                    2,
+                    map(
+                        serialize_frame,
+                        exception['stacktrace']['frames'],
+                    ),
+                ),
+            ),
+        ),
+        'message:message:character-shingles': MessageFeature(
+            lambda message: map(
+                serialize_text_shingle,
+                shingle(
+                    13,
+                    message['message'],
+                ),
+            ),
+        ),
+    }
+)
diff --git a/src/sentry/utils/datastructures.py b/src/sentry/utils/datastructures.py
new file mode 100644
index 0000000000..1374ce1dc5
--- /dev/null
+++ b/src/sentry/utils/datastructures.py
@@ -0,0 +1,63 @@
+from __future__ import absolute_import
+
+from collections import Hashable, MutableMapping
+
+
+__unset__ = object()
+
+
+class BidirectionalMapping(MutableMapping):
+    """\
+    An associative data structure in which the ``(key, value)`` pairs form a
+    one-to-one correspondence in both directions.
+
+    For example, when ``(a, b)`` is added to the mapping, ``b`` can be found
+    when ``a`` is used as a key, and ``a`` can *also* be found when ``b`` is
+    provided to ``get_key``.
+    """
+    def __init__(self, data):
+        self.__data = data
+        self.__inverse = {v: k for k, v in self.__data.items()}
+        if len(self.__data) != len(self.__inverse):
+            raise ValueError('duplicate value provided')
+
+    def __getitem__(self, key):
+        return self.__data[key]
+
+    def __setitem__(self, key, value):
+        if not isinstance(key, Hashable):
+            raise TypeError('key must be hashable')
+
+        if not isinstance(value, Hashable):
+            raise TypeError('value must be hashable')
+
+        if value in self.__inverse:
+            raise ValueError('value already present')
+
+        previous = self.__data.pop(key, __unset__)
+        if previous is not __unset__:
+            assert self.__inverse.pop(previous) == key
+
+        self.__data[key] = value
+        self.__inverse[value] = key
+
+    def __delitem__(self, key):
+        del self.__inverse[self.__data.pop(key)]
+
+    def __iter__(self):
+        return iter(self.__data)
+
+    def __len__(self):
+        return len(self.__data)
+
+    def get_key(self, value, default=__unset__):
+        try:
+            return self.__inverse[value]
+        except KeyError:
+            if default is __unset__:
+                raise
+            else:
+                return default
+
+    def inverse(self):
+        return self.__inverse.copy()
diff --git a/tests/sentry/utils/test_datastructures.py b/tests/sentry/utils/test_datastructures.py
new file mode 100644
index 0000000000..81ec6b8b33
--- /dev/null
+++ b/tests/sentry/utils/test_datastructures.py
@@ -0,0 +1,40 @@
+from __future__ import absolute_import
+
+import pytest
+
+from sentry.utils.datastructures import BidirectionalMapping
+
+
+def test_bidirectional_mapping():
+    value = BidirectionalMapping({
+        'a': 1,
+        'b': 2,
+    })
+
+    assert value['a'] == 1
+    assert value['b'] == 2
+    assert value.get_key(1) == 'a'
+    assert value.get_key(2) == 'b'
+    assert value.inverse() == {
+        1: 'a',
+        2: 'b',
+    }
+
+    value['c'] = 3
+    assert value['c'] == 3
+    assert value.get_key(3) == 'c'
+
+    with pytest.raises(KeyError):
+        value['d']
+
+    with pytest.raises(KeyError):
+        value.get_key(4)
+
+    with pytest.raises(TypeError):
+        value['d'] = [1, 2, 3]  # not hashable
+
+    assert len(value) == len(value.inverse()) == 3
+
+    del value['c']
+
+    assert len(value) == len(value.inverse()) == 2
