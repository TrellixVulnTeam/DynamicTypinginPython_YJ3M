commit aa17dd354997cfec39e11fe86607b7edcc254547
Author: Jess MacQueen <jess@getsentry.com>
Date:   Mon Jul 10 18:02:29 2017 -0700

    ted feedback (except for model changes)

diff --git a/src/sentry/api/endpoints/project_group_index.py b/src/sentry/api/endpoints/project_group_index.py
index 03c07001c7..358e219644 100644
--- a/src/sentry/api/endpoints/project_group_index.py
+++ b/src/sentry/api/endpoints/project_group_index.py
@@ -42,6 +42,7 @@ delete_logger = logging.getLogger('sentry.deletions.api')
 
 ERR_INVALID_STATS_PERIOD = "Invalid stats_period. Valid choices are '', '24h', and '14d'"
 SAVED_SEARCH_QUERIES = set([s['query'] for s in DEFAULT_SAVED_SEARCHES])
+TOMBSTONE_FIELDS_FROM_GROUP = ('project_id', 'level', 'message', 'culprit')
 
 
 @scenario('BulkUpdateIssues')
@@ -169,11 +170,10 @@ class GroupValidator(serializers.Serializer):
 
     def validate(self, attrs):
         attrs = super(GroupValidator, self).validate(attrs)
-        if 'discard' in attrs:
-            if len(attrs) > 1:
-                raise serializers.ValidationError(
-                    'Other attributes cannot be updated when discarding'
-                )
+        if 'discard' in attrs and len(attrs) > 1:
+            raise serializers.ValidationError(
+                'Other attributes cannot be updated when discarding'
+            )
         return attrs
 
 
@@ -473,31 +473,37 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint):
 
         discard = result.get('discard')
         if discard:
+
             if not features.has('projects:custom-filters', project, actor=request.user):
                 return Response({'detail': ['You do not have that feature enabled']}, status=400)
+
             group_list = list(queryset)
+            groups_to_delete = []
+
             for group in group_list:
                 with transaction.atomic():
                     try:
                         tombstone = GroupTombstone.objects.create(
                             previous_group_id=group.id,
-                            project_id=group.project_id,
-                            level=group.level,
-                            message=group.message,
-                            culprit=group.culprit,
                             type=group.get_event_type(),
                             actor_id=acting_user.id if acting_user else None,
+                            **{name: getattr(group, name) for name in TOMBSTONE_FIELDS_FROM_GROUP}
                         )
                     except IntegrityError:
-                        continue
+                        # in this case, a tombstone has already been created
+                        # for a group, so no hash updates are necessary
+                        pass
+                    else:
+                        groups_to_delete.append(group)
 
-                GroupHash.objects.filter(
-                    group=group,
-                ).update(
-                    group=None,
-                    group_tombstone=tombstone,
-                )
-            self._delete_groups(request, project, group_list)
+                        GroupHash.objects.filter(
+                            group=group,
+                        ).update(
+                            group=None,
+                            group_tombstone=tombstone,
+                        )
+
+            self._delete_groups(request, project, groups_to_delete)
 
             return Response(status=204)
 
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index e5d2a4941a..7d3b21da54 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -190,7 +190,7 @@ def plugin_is_regression(group, event):
     return True
 
 
-class DiscardedHash(Exception):
+class HashDiscarded(Exception):
     pass
 
 
@@ -823,17 +823,13 @@ class EventManager(object):
         # attempt to find a matching hash
         all_hashes = self._find_hashes(project, hashes)
 
-        try:
-            existing_group_id, existing_tombstone_id = six.next(
-                (h.group_id, h.group_tombstone_id)
-                for h in all_hashes if h.group_id is not None or h.group_tombstone_id is not None
-            )
-        except StopIteration:
-            existing_group_id = None
-            existing_tombstone_id = None
-
-        if existing_tombstone_id is not None:
-            raise DiscardedHash('Matches discarded group %s' % existing_tombstone_id)
+        existing_group_id = None
+        for h in all_hashes:
+            if h.group_id is not None:
+                existing_group_id = h.group_id
+                break
+            if h.group_tombstone_id is not None:
+                raise HashDiscarded('Matches discarded group %s' % h.group_tombstone_id)
 
         # XXX(dcramer): this has the opportunity to create duplicate groups
         # it should be resolved by the hash merging function later but this
diff --git a/src/sentry/models/group.py b/src/sentry/models/group.py
index cd29752438..9c10226ac8 100644
--- a/src/sentry/models/group.py
+++ b/src/sentry/models/group.py
@@ -104,7 +104,7 @@ class GroupManager(BaseManager):
         )
 
     def from_kwargs(self, project, **kwargs):
-        from sentry.event_manager import DiscardedHash, EventManager
+        from sentry.event_manager import HashDiscarded, EventManager
 
         manager = EventManager(kwargs)
         manager.normalize()
@@ -112,7 +112,7 @@ class GroupManager(BaseManager):
             return manager.save(project)
 
         # TODO(jess): this method maybe isn't even used?
-        except DiscardedHash as exc:
+        except HashDiscarded as exc:
             logger.info('discarded.hash', extra={
                 'project_id': project.id,
                 'message': exc.message,
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index 0a55586cf7..95d9ab9fb7 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -270,7 +270,7 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None, **kwar
     """
     Saves an event to the database.
     """
-    from sentry.event_manager import DiscardedHash, EventManager
+    from sentry.event_manager import HashDiscarded, EventManager
 
     if cache_key:
         data = default_cache.get(cache_key)
@@ -293,7 +293,7 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None, **kwar
     try:
         manager = EventManager(data)
         manager.save(project)
-    except DiscardedHash as exc:
+    except HashDiscarded as exc:
         error_logger.info('discarded.hash', extra={
             'project_id': project.id,
             'message': exc.message,
