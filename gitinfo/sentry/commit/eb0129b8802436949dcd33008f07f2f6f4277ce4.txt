commit eb0129b8802436949dcd33008f07f2f6f4277ce4
Author: Dan Fuller <dfuller@sentry.io>
Date:   Thu Jul 11 18:42:24 2019 -0700

    Incidents: Attempt to detect start date of incident automatically (SEN-804)
    
    This attempts to determine the start date of an incident based on the events in the related groups.
    We try to find the largest spike, where a spike monotonically increases across each time bucket. We
    also downweight older spikes slightly, so that hopefully we pick the most relevant ones.

diff --git a/src/sentry/api/endpoints/organization_incident_index.py b/src/sentry/api/endpoints/organization_incident_index.py
index 70a7069980..d7ef686a6f 100644
--- a/src/sentry/api/endpoints/organization_incident_index.py
+++ b/src/sentry/api/endpoints/organization_incident_index.py
@@ -34,7 +34,7 @@ class IncidentSerializer(serializers.Serializer):
     )
     title = serializers.CharField(required=True)
     query = serializers.CharField(required=False, allow_blank=True, allow_null=True)
-    dateStarted = serializers.DateTimeField(required=True)
+    dateStarted = serializers.DateTimeField(required=False)
     dateDetected = serializers.DateTimeField(required=False, allow_null=True)
 
     def validate_projects(self, slugs):
@@ -113,8 +113,8 @@ class OrganizationIncidentIndexEndpoint(OrganizationEndpoint):
                 type=IncidentType.CREATED,
                 title=result['title'],
                 query=result.get('query', ''),
-                date_started=result['dateStarted'],
-                date_detected=result.get('dateDetected', result['dateStarted']),
+                date_started=result.get('dateStarted'),
+                date_detected=result.get('dateDetected'),
                 projects=result['projects'],
                 groups=groups,
                 user=request.user,
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index 5f8fb57ce8..b4356e3817 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -4,7 +4,9 @@ from collections import defaultdict
 from datetime import timedelta
 from uuid import uuid4
 
+import pytz
 import six
+from dateutil.parser import parse as parse_date
 from django.db import transaction
 from django.utils import timezone
 
@@ -34,8 +36,10 @@ from sentry.incidents import tasks
 from sentry.utils.committers import get_event_file_committers
 from sentry.utils.snuba import (
     bulk_raw_query,
+    raw_query,
     SnubaQueryParams,
     SnubaTSResult,
+    zerofill,
 )
 
 MAX_INITIAL_INCIDENT_PERIOD = timedelta(days=7)
@@ -54,22 +58,25 @@ def create_incident(
     type,
     title,
     query,
-    date_started,
+    date_started=None,
     date_detected=None,
     detection_uuid=None,
     projects=None,
     groups=None,
     user=None,
 ):
-    if date_detected is None:
-        date_detected = date_started
-
     if groups:
         group_projects = [g.project for g in groups]
         if projects is None:
             projects = []
         projects = list(set(projects + group_projects))
 
+    if date_started is None:
+        date_started = calculate_incident_start(query, projects, groups)
+
+    if date_detected is None:
+        date_detected = date_started
+
     with transaction.atomic():
         incident = Incident.objects.create(
             organization=organization,
@@ -113,6 +120,110 @@ def create_incident(
     return incident
 
 
+INCIDENT_START_PERIOD = timedelta(days=14)
+INCIDENT_START_ROLLUP = timedelta(minutes=15)
+
+
+def calculate_incident_start(query, projects, groups):
+    """
+    Attempts to automatically calculate the date that an incident began at based
+    on the events related to the incident.
+    """
+    params = {}
+    if groups:
+        params['issue.id'] = [g.id for g in groups]
+        end = max(g.last_seen for g in groups) + timedelta(seconds=1)
+    else:
+        end = timezone.now()
+
+    params['start'] = end - INCIDENT_START_PERIOD
+    params['end'] = end
+
+    if projects:
+        params['project_id'] = [p.id for p in projects]
+
+    query_args = get_snuba_query_args(query, params)
+    rollup = int(INCIDENT_START_ROLLUP.total_seconds())
+
+    result = raw_query(
+        aggregations=[
+            ('count()', '', 'count'),
+            ('min', 'timestamp', 'first_seen'),
+        ],
+        orderby='time',
+        groupby=['time'],
+        rollup=rollup,
+        referrer='incidents.calculate_incident_start',
+        limit=10000,
+        **query_args
+    )['data']
+    # TODO: Start could be the period before the first period we find
+    result = zerofill(result, params['start'], params['end'], rollup, 'time')
+
+    # We want to linearly scale scores from 100% value at the most recent to
+    # 50% at the oldest. This gives a bias towards newer results.
+    negative_weight = (1.0 / len(result)) / 2
+    multiplier = 1.0
+    cur_spike_max_count = -1
+    cur_spike_start = None
+    cur_spike_end = None
+    max_height = 0
+    incident_start = None
+    cur_height = 0
+    prev_count = 0
+
+    def get_row_first_seen(row, default=None):
+        first_seen = default
+        if 'first_seen' in row:
+            first_seen = parse_date(row['first_seen']).replace(tzinfo=pytz.utc)
+        return first_seen
+
+    def calculate_start(spike_start, spike_end):
+        """
+        We arbitrarily choose a date about 1/3 into the incident period. We
+        could potentially improve this if we want by analyzing the period in
+        more detail and choosing a date that most closely fits with being 1/3
+        up the spike.
+        """
+        spike_length = (spike_end - spike_start)
+        return spike_start + (spike_length / 3)
+
+    for row in reversed(result):
+        cur_count = row.get('count', 0)
+        if cur_count < prev_count or cur_count > 0 and cur_count == prev_count:
+            cur_height = cur_spike_max_count - cur_count
+        elif cur_count > 0 or prev_count > 0 or cur_height > 0:
+            # Now we've got the height of the current spike, compare it to the
+            # current max. We decrease the value by `multiplier` so that we
+            # favour newer results
+            cur_height *= multiplier
+            if cur_height > max_height:
+                # If we detect that we have a new highest peak, then set a new
+                # incident start date
+                incident_start = calculate_start(cur_spike_start, cur_spike_end)
+                max_height = cur_height
+
+            cur_height = 0
+            cur_spike_max_count = cur_count
+            cur_spike_end = get_row_first_seen(row)
+
+        # We attempt to get the first_seen value from the row here. If the row
+        # doesn't have it (because it's a zerofilled row), then just use the
+        # previous value. This allows us to have the start of a spike always be
+        # a bucket that contains at least one element.
+        cur_spike_start = get_row_first_seen(row, cur_spike_start)
+        prev_count = cur_count
+        multiplier -= negative_weight
+
+    if (cur_height > max_height or not incident_start) and cur_spike_start:
+        incident_start = calculate_start(cur_spike_start, cur_spike_end)
+
+    if not incident_start:
+        incident_start = timezone.now()
+
+    return incident_start
+
+
 def update_incident_status(incident, status, user=None, comment=None):
     """
     Updates the status of an Incident and write an IncidentActivity row to log
@@ -189,7 +300,7 @@ def create_initial_event_stats_snapshot(incident):
         MAX_INITIAL_INCIDENT_PERIOD,
     )
     end = incident.date_started + initial_period_length
-    start = end - (initial_period_length * 8)
+    start = end - (initial_period_length * 4)
     return create_event_stat_snapshot(incident, start, end)
 
 
diff --git a/src/sentry/static/sentry/app/actionCreators/incident.jsx b/src/sentry/static/sentry/app/actionCreators/incident.jsx
index 7ecfdeafec..f6b57d6b29 100644
--- a/src/sentry/static/sentry/app/actionCreators/incident.jsx
+++ b/src/sentry/static/sentry/app/actionCreators/incident.jsx
@@ -13,13 +13,7 @@ import {t} from 'app/locale';
  * @param {String} title Title of the incident
  * @param {String[]} groups List of group ids
  */
-export async function createIncident(
-  api,
-  organization,
-  title,
-  groups,
-  dateStarted = new Date()
-) {
+export async function createIncident(api, organization, title, groups) {
   addLoadingMessage(t('Creating new incident...'));
 
   try {
@@ -30,7 +24,6 @@ export async function createIncident(
         data: {
           title,
           groups,
-          dateStarted,
           query: '',
         },
       }
diff --git a/src/sentry/static/sentry/app/components/modals/createIncidentModal.jsx b/src/sentry/static/sentry/app/components/modals/createIncidentModal.jsx
index dfc96af098..bdc4d0331f 100644
--- a/src/sentry/static/sentry/app/components/modals/createIncidentModal.jsx
+++ b/src/sentry/static/sentry/app/components/modals/createIncidentModal.jsx
@@ -4,7 +4,6 @@ import React from 'react';
 
 import {createIncident} from 'app/actionCreators/incident';
 import {t} from 'app/locale';
-import DatePickerField from 'app/views/settings/components/forms/datePickerField';
 import Form from 'app/views/settings/components/forms/form';
 import SentryTypes from 'app/sentryTypes';
 import TextField from 'app/views/settings/components/forms/textField';
@@ -27,13 +26,7 @@ class CreateIncidentModal extends React.Component {
     setFormSavingState();
 
     try {
-      const incident = await createIncident(
-        api,
-        organization,
-        data.title,
-        issues,
-        data.dateStarted
-      );
+      const incident = await createIncident(api, organization, data.title, issues);
       onSuccess(incident);
     } catch (err) {
       onError(err);
@@ -85,15 +78,6 @@ class CreateIncidentModal extends React.Component {
               inline={false}
               flexibleControlStateSize
             />
-            <DatePickerField
-              name="dateStarted"
-              label={t('Date Started')}
-              help={t('This should be around when the incident first began.')}
-              required
-              stacked
-              inline={false}
-              flexibleControlStateSize
-            />
           </Form>
         </Body>
       </React.Fragment>
diff --git a/tests/js/spec/components/modals/createIncidentModal.spec.jsx b/tests/js/spec/components/modals/createIncidentModal.spec.jsx
index fc43380ecb..3f93ad63cd 100644
--- a/tests/js/spec/components/modals/createIncidentModal.spec.jsx
+++ b/tests/js/spec/components/modals/createIncidentModal.spec.jsx
@@ -48,7 +48,6 @@ describe('CreateIncidentModal', function() {
       '/organizations/org-slug/incidents/',
       expect.objectContaining({
         data: {
-          dateStarted: new Date(),
           groups: ['123', '456'],
           query: '',
           title: 'Oh no',
diff --git a/tests/js/spec/views/issueList/createIncident.spec.jsx b/tests/js/spec/views/issueList/createIncident.spec.jsx
index 0717a5362f..2a5c1a5f99 100644
--- a/tests/js/spec/views/issueList/createIncident.spec.jsx
+++ b/tests/js/spec/views/issueList/createIncident.spec.jsx
@@ -163,23 +163,13 @@ describe('IssueList --> Create Incident', function() {
       .find('input[name="title"]')
       .simulate('change', {target: {value: 'New Incident'}})
       .simulate('blur');
-    wrapper.find('DatePickerField[name="dateStarted"] input').simulate('click');
 
-    await tick();
-    wrapper.update();
-    expect(wrapper.find('Calendar')).toHaveLength(1);
-
-    wrapper
-      .find('Calendar DayCell')
-      .at(0)
-      .simulate('mouseUp');
     wrapper.find('Form').simulate('submit');
 
     expect(createIncident).toHaveBeenCalledWith(
       '/organizations/org-slug/incidents/',
       expect.objectContaining({
         data: {
-          dateStarted: new Date('2017-10-01T04:00:00.000Z'),
           groups: ['1', '2'],
           query: '',
           title: 'New Incident',
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index 881b37e9d0..0c6bd2048f 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -25,6 +25,7 @@ from sentry.incidents.logic import (
     bulk_get_incident_aggregates,
     bulk_get_incident_event_stats,
     bulk_get_incident_stats,
+    calculate_incident_start,
     create_alert_rule,
     create_event_stat_snapshot,
     create_incident,
@@ -38,6 +39,7 @@ from sentry.incidents.logic import (
     get_incident_subscribers,
     get_incident_suspect_commits,
     get_incident_suspects,
+    INCIDENT_START_ROLLUP,
     subscribe_to_incident,
     StatusAlreadyChangedError,
     update_alert_rule,
@@ -229,7 +231,7 @@ class BaseIncidentsTest(SnubaTestCase):
 
     @cached_property
     def now(self):
-        return timezone.now()
+        return timezone.now().replace(microsecond=0)
 
 
 class BaseIncidentEventStatsTest(BaseIncidentsTest):
@@ -555,29 +557,29 @@ class CreateIncidentActivityTest(TestCase, BaseIncidentsTest):
         }
 
 
-@freeze_time()
 class CreateInitialEventStatsSnapshotTest(TestCase, BaseIncidentsTest):
 
     def test_snapshot(self):
-        self.create_event(self.now - timedelta(minutes=2))
-        self.create_event(self.now - timedelta(minutes=2))
-        self.create_event(self.now - timedelta(minutes=1))
-        # Define events outside incident range. Should be included in the
-        # snapshot
-        self.create_event(self.now - timedelta(minutes=20))
-        self.create_event(self.now - timedelta(minutes=30))
-
-        # Too far out, should be excluded
-        self.create_event(self.now - timedelta(minutes=100))
-
-        incident = self.create_incident(
-            date_started=self.now - timedelta(minutes=5),
-            query='',
-            projects=[self.project]
-        )
-        event_stat_snapshot = create_initial_event_stats_snapshot(incident)
-        assert event_stat_snapshot.start == self.now - timedelta(minutes=40)
-        assert [row[1] for row in event_stat_snapshot.values] == [1, 1, 2, 1]
+        with freeze_time(self.now):
+            self.create_event(self.now - timedelta(minutes=2))
+            self.create_event(self.now - timedelta(minutes=2))
+            self.create_event(self.now - timedelta(minutes=1))
+            # Define events outside incident range. Should be included in the
+            # snapshot
+            self.create_event(self.now - timedelta(minutes=15))
+            self.create_event(self.now - timedelta(minutes=20))
+
+            # Too far out, should be excluded
+            self.create_event(self.now - timedelta(minutes=100))
+
+            incident = self.create_incident(
+                date_started=self.now - timedelta(minutes=5),
+                query='',
+                projects=[self.project]
+            )
+            event_stat_snapshot = create_initial_event_stats_snapshot(incident)
+            assert event_stat_snapshot.start == self.now - timedelta(minutes=20)
+            assert [row[1] for row in event_stat_snapshot.values] == [1, 1, 2, 1]
 
 
 class GetIncidentSuscribersTest(TestCase, BaseIncidentsTest):
@@ -960,3 +962,67 @@ class DeleteAlertRuleTest(TestCase, BaseIncidentsTest):
         assert not AlertRule.objects_with_deleted.filter(id=alert_rule_id).exists()
         incident = Incident.objects.get(id=incident.id)
         assert Incident.objects.filter(id=incident.id, alert_rule_id__isnull=True).exists()
+
+
+@freeze_time()
+class CalculateIncidentStartTest(TestCase, BaseIncidentsTest):
+
+    def test_empty(self):
+        assert timezone.now() == calculate_incident_start('', [self.project], [])
+
+    def test_single_event(self):
+        start = self.now - timedelta(minutes=2)
+        event = self.create_event(start)
+        assert start == calculate_incident_start('', [self.project], [event.group])
+
+    def test_single_spike(self):
+        fingerprint = 'hello'
+        start = self.now - (INCIDENT_START_ROLLUP * 2)
+        for _ in xrange(3):
+            event = self.create_event(start, fingerprint=fingerprint)
+
+        end = self.now - INCIDENT_START_ROLLUP
+        for _ in xrange(4):
+            event = self.create_event(end, fingerprint=fingerprint)
+        assert start + ((end - start) / 3) == calculate_incident_start(
+            '',
+            [self.project],
+            [event.group],
+        )
+
+    def test_multiple_same_size_spikes(self):
+        # The most recent spike should take precedence
+        fingerprint = 'hello'
+        older_spike = self.now - (INCIDENT_START_ROLLUP * 3)
+        for _ in xrange(3):
+            event = self.create_event(older_spike, fingerprint=fingerprint)
+
+        newer_spike = self.now - INCIDENT_START_ROLLUP
+        for _ in xrange(3):
+            event = self.create_event(newer_spike, fingerprint=fingerprint)
+        assert newer_spike == calculate_incident_start('', [self.project], [event.group])
+
+    def test_multiple_spikes_large_older(self):
+        # The older spike should take precedence because it's much larger
+        fingerprint = 'hello'
+        older_spike = self.now - (INCIDENT_START_ROLLUP * 2)
+        for _ in xrange(4):
+            event = self.create_event(older_spike, fingerprint=fingerprint)
+
+        newer_spike = self.now - INCIDENT_START_ROLLUP
+        for _ in xrange(2):
+            event = self.create_event(newer_spike, fingerprint=fingerprint)
+        assert older_spike == calculate_incident_start('', [self.project], [event.group])
+
+    def test_multiple_spikes_large_much_older(self):
+        # The most recent spike should take precedence because even though the
+        # older spike is larger, it's much older.
+        fingerprint = 'hello'
+        older_spike = self.now - (INCIDENT_START_ROLLUP * 1000)
+        for _ in xrange(3):
+            event = self.create_event(older_spike, fingerprint=fingerprint)
+
+        newer_spike = self.now - INCIDENT_START_ROLLUP
+        for _ in xrange(2):
+            event = self.create_event(newer_spike, fingerprint=fingerprint)
+        assert newer_spike == calculate_incident_start('', [self.project], [event.group])
