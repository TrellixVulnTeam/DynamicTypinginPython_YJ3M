commit 5d45a83e94f4cca2f46e52ca16c5cc081ab15ab6
Author: Mark Story <mark@sentry.io>
Date:   Mon Dec 9 10:27:34 2019 -0800

    feat(discover) Add timeseries method for high-level discover API (#15872)
    
    This implements the timeseries_query() method for the new high-level
    discover API. It currently does not work with transaction events as the
    underlying `time` alias does not yet work in snuba for transaction
    events.
    
    I chose to re-implement reference conditions as a named tuple as passing
    around a few semi-related parameters was a clunky part of the old
    implementation. I've also switched to the new discover alias resolution
    model which was one of the reasons that reference event condition was
    re-implemented instead of re-used.
    
    Only keep one copy of the reference condition code around, and use the
    new implementation in the existing endpoints. I've also bypassed
    eventstore to get an event dictionary and used raw_query instead as
    `snuba_data` is not intended as a public interface.

diff --git a/src/sentry/api/bases/organization_events.py b/src/sentry/api/bases/organization_events.py
index c6e4436154..e994f1547d 100644
--- a/src/sentry/api/bases/organization_events.py
+++ b/src/sentry/api/bases/organization_events.py
@@ -3,12 +3,8 @@ from __future__ import absolute_import
 from rest_framework.exceptions import PermissionDenied
 
 from sentry.api.bases import OrganizationEndpoint, OrganizationEventsError
-from sentry.api.event_search import (
-    get_filter,
-    resolve_field_list,
-    InvalidSearchQuery,
-    get_reference_event_conditions,
-)
+from sentry.api.event_search import get_filter, resolve_field_list, InvalidSearchQuery
+from sentry.snuba.discover import ReferenceEvent, create_reference_event_conditions
 from sentry.models.project import Project
 from sentry.snuba.dataset import Dataset
 from sentry.utils import snuba
@@ -54,10 +50,8 @@ class OrganizationEventsEndpointBase(OrganizationEndpoint):
 
         reference_event_id = request.GET.get("referenceEvent")
         if reference_event_id:
-            snuba_args["conditions"] = get_reference_event_conditions(
-                organization, snuba_args, reference_event_id
-            )
-
+            reference = ReferenceEvent(organization, reference_event_id, fields)
+            snuba_args["conditions"].extend(create_reference_event_conditions(reference))
         return snuba_args
 
     def get_snuba_query_args_legacy(self, request, organization):
diff --git a/src/sentry/api/endpoints/organization_event_details.py b/src/sentry/api/endpoints/organization_event_details.py
index 78989d35df..f2d089fbe1 100644
--- a/src/sentry/api/endpoints/organization_event_details.py
+++ b/src/sentry/api/endpoints/organization_event_details.py
@@ -3,9 +3,9 @@ from __future__ import absolute_import
 from rest_framework.response import Response
 
 from sentry.api.bases import OrganizationEventsEndpointBase, OrganizationEventsError, NoProjects
-from sentry.api.event_search import get_reference_event_conditions
 from sentry import eventstore, features
 from sentry.models.project import Project, ProjectStatus
+from sentry.snuba.discover import create_reference_event_conditions, ReferenceEvent
 from sentry.api.serializers import serialize
 
 
@@ -44,9 +44,10 @@ class OrganizationEventDetailsEndpoint(OrganizationEventsEndpointBase):
         # This ensure that if a field list/groupby conditions were provided
         # that we constrain related events to the query + current event values
         event_slug = u"{}:{}".format(project.slug, event_id)
-        snuba_args["conditions"].extend(
-            get_reference_event_conditions(organization, snuba_args, event_slug)
-        )
+        fields = request.query_params.getlist("field")
+        if fields:
+            reference = ReferenceEvent(organization, event_slug, fields)
+            snuba_args["conditions"].extend(create_reference_event_conditions(reference))
 
         data = serialize(event)
         data["nextEventID"] = self.next_event_id(snuba_args, event)
diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 2331ec2a17..98c919f357 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -13,7 +13,7 @@ from parsimonious.nodes import Node
 from parsimonious.grammar import Grammar, NodeVisitor
 
 from sentry import eventstore
-from sentry.models import Project, ProjectStatus
+from sentry.models import Project
 from sentry.search.utils import (
     parse_datetime_range,
     parse_datetime_string,
@@ -21,9 +21,8 @@ from sentry.search.utils import (
     InvalidQuery,
 )
 from sentry.snuba.dataset import Dataset
-from sentry.snuba.events import get_columns_from_aliases
 from sentry.utils.dates import to_timestamp
-from sentry.utils.snuba import DATASETS, get_snuba_column_name, get_json_type
+from sentry.utils.snuba import DATASETS, get_json_type
 
 WILDCARD_CHARS = re.compile(r"[\*]")
 
@@ -862,59 +861,4 @@ def resolve_field_list(fields, snuba_args, auto_fields=True):
     }
 
 
-def find_reference_event(organization, snuba_args, reference_event_slug, fields):
-    try:
-        project_slug, event_id = reference_event_slug.split(":")
-    except ValueError:
-        raise InvalidSearchQuery("Invalid reference event")
-    try:
-        project = Project.objects.get(
-            slug=project_slug, organization=organization, status=ProjectStatus.VISIBLE
-        )
-    except Project.DoesNotExist:
-        raise InvalidSearchQuery("Invalid reference event")
-    reference_event = eventstore.get_event_by_id(project.id, event_id, fields)
-    if not reference_event:
-        raise InvalidSearchQuery("Invalid reference event")
-
-    return reference_event.snuba_data
-
-
 TAG_KEY_RE = re.compile(r"^tags\[(.*)\]$")
-
-
-def get_reference_event_conditions(organization, snuba_args, event_slug):
-    """
-    Returns a list of additional conditions/filter_keys to
-    scope a query by the groupby fields using values from the reference event
-
-    This is a key part of pagination in the event details modal and
-    summary graph navigation.
-    """
-    groupby = snuba_args.get("groupby", [])
-    columns = get_columns_from_aliases(groupby)
-    field_names = [get_snuba_column_name(field) for field in groupby]
-
-    # Fetch the reference event ensuring the fields in the groupby
-    # clause are present.
-    event_data = find_reference_event(organization, snuba_args, event_slug, columns)
-
-    conditions = []
-    tags = {}
-    if "tags.key" in event_data and "tags.value" in event_data:
-        tags = dict(zip(event_data["tags.key"], event_data["tags.value"]))
-
-    for (i, field) in enumerate(groupby):
-        match = TAG_KEY_RE.match(field_names[i])
-        if match:
-            value = tags.get(match.group(1), None)
-        else:
-            value = event_data.get(field_names[i], None)
-            # If the value is a sequence use the first element as snuba
-            # doesn't support `=` or `IN` operations on fields like exception_frames.filename
-            if isinstance(value, (list, set)) and value:
-                value = value.pop()
-        if value:
-            conditions.append([field, "=", value])
-
-    return conditions
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index afe6ed9570..0ce8068ad4 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -2,17 +2,92 @@ from __future__ import absolute_import
 
 import six
 
+from collections import namedtuple
 from copy import deepcopy
-from sentry.api.event_search import get_filter, resolve_field_list
+
+from sentry.api.event_search import TAG_KEY_RE, get_filter, resolve_field_list, InvalidSearchQuery
+from sentry.models import Project, ProjectStatus
+from sentry.snuba.events import get_columns_from_aliases
 from sentry.utils.snuba import (
     Dataset,
+    SnubaTSResult,
     DISCOVER_COLUMN_MAP,
     QUOTED_LITERAL_RE,
     get_function_index,
     raw_query,
     transform_results,
+    zerofill,
 )
 
+ReferenceEvent = namedtuple("ReferenceEvent", ["organization", "slug", "fields"])
+
+
+def find_reference_event(reference_event):
+    try:
+        project_slug, event_id = reference_event.slug.split(":")
+    except ValueError:
+        raise InvalidSearchQuery("Invalid reference event")
+    try:
+        project = Project.objects.get(
+            slug=project_slug,
+            organization=reference_event.organization,
+            status=ProjectStatus.VISIBLE,
+        )
+    except Project.DoesNotExist:
+        raise InvalidSearchQuery("Invalid reference event")
+
+    column_names = [c.value.discover_name for c in get_columns_from_aliases(reference_event.fields)]
+    # We don't need to run a query if there are no columns
+    if not column_names:
+        return None
+
+    event = raw_query(
+        selected_columns=column_names,
+        filter_keys={"project_id": [project.id], "event_id": [event_id]},
+        dataset=Dataset.Discover,
+        limit=1,
+    )
+    if "error" in event or len(event["data"]) != 1:
+        raise InvalidSearchQuery("Invalid reference event")
+
+    return event["data"][0]
+
+
+def create_reference_event_conditions(reference_event):
+    """
+    Create a list of conditions based on a Reference object.
+
+    This is useful when you want to get results that match an exemplar
+    event. A use case of this is generating pagination links for, or getting
+    timeseries results of the records inside a single aggregated row.
+
+    reference_event (ReferenceEvent) The reference event to build conditions from.
+    """
+    conditions = []
+    tags = {}
+    event_data = find_reference_event(reference_event)
+    if event_data is None:
+        return conditions
+
+    if "tags.key" in event_data and "tags.value" in event_data:
+        tags = dict(zip(event_data["tags.key"], event_data["tags.value"]))
+
+    field_names = [resolve_column(col) for col in reference_event.fields]
+    for (i, field) in enumerate(reference_event.fields):
+        match = TAG_KEY_RE.match(field_names[i])
+        if match:
+            value = tags.get(match.group(1), None)
+        else:
+            value = event_data.get(field_names[i], None)
+            # If the value is a sequence use the first element as snuba
+            # doesn't support `=` or `IN` operations on fields like exception_frames.filename
+            if isinstance(value, (list, set)) and value:
+                value = value.pop()
+        if value:
+            conditions.append([field, "=", value])
+
+    return conditions
+
 
 def resolve_column(col):
     """
@@ -149,14 +224,15 @@ def query(selected_columns, query, params, orderby=None, referrer=None, auto_fie
     selected_columns (Sequence[str]) List of public aliases to fetch.
     query (str) Filter query string to create conditions from.
     params (Dict[str, str]) Filtering parameters with start, end, project_id, environment
-    orderby (str|Sequence[str]) The field to order results by.
-    referrer (str) A reference string to help locate where queries are coming from.
+    orderby (None|str|Sequence[str]) The field to order results by.
+    referrer (str|None) A referrer string to help locate the origin of this query.
     auto_fields (bool) Set to true to have project + eventid fields automatically added.
     """
     snuba_filter = get_filter(query, params)
 
     # TODO(mark) Refactor the need for this translation shim once all of
-    # discover is using this module
+    # discover is using this module. Remember to update all the functions
+    # in this module.
     snuba_args = {
         "start": snuba_filter.start,
         "end": snuba_filter.end,
@@ -185,7 +261,7 @@ def query(selected_columns, query, params, orderby=None, referrer=None, auto_fie
     return transform_results(result, translated_columns, snuba_args)
 
 
-def timeseries_query(selected_columns, query, params, rollup):
+def timeseries_query(selected_columns, query, params, rollup, reference_event=None, referrer=None):
     """
     High-level API for doing arbitrary user timeseries queries against events.
 
@@ -195,8 +271,55 @@ def timeseries_query(selected_columns, query, params, rollup):
 
     This function is intended to only get timeseries based
     results and thus requires the `rollup` parameter.
+
+    Returns a SnubaTSResult object that has been zerofilled in
+    case of gaps.
+
+    selected_columns (Sequence[str]) List of public aliases to fetch.
+    query (str) Filter query string to create conditions from.
+    params (Dict[str, str]) Filtering parameters with start, end, project_id, environment,
+    rollup (int) The bucket width in seconds
+    reference_event (ReferenceEvent) A reference event object. Used to generate additional
+                    conditions based on the provided reference.
+    referrer (str|None) A referrer string to help locate the origin of this query.
     """
-    raise NotImplementedError
+    snuba_filter = get_filter(query, params)
+    snuba_args = {
+        "start": snuba_filter.start,
+        "end": snuba_filter.end,
+        "conditions": snuba_filter.conditions,
+        "filter_keys": snuba_filter.filter_keys,
+    }
+    if not snuba_args["start"] and not snuba_args["end"]:
+        raise InvalidSearchQuery("Cannot get timeseries result without a start and end.")
+
+    snuba_args.update(resolve_field_list(selected_columns, snuba_args, auto_fields=False))
+    if reference_event:
+        ref_conditions = create_reference_event_conditions(reference_event)
+        if ref_conditions:
+            snuba_args["conditions"].extend(ref_conditions)
+
+    # Resolve the public aliases into the discover dataset names.
+    snuba_args, _ = resolve_discover_aliases(snuba_args)
+    if not snuba_args["aggregations"]:
+        raise InvalidSearchQuery("Cannot get timeseries result with no aggregation.")
+
+    result = raw_query(
+        aggregations=snuba_args.get("aggregations"),
+        conditions=snuba_args.get("conditions"),
+        filter_keys=snuba_args.get("filter_keys"),
+        start=snuba_args.get("start"),
+        end=snuba_args.get("end"),
+        rollup=rollup,
+        orderby="time",
+        groupby=["time"],
+        dataset=Dataset.Discover,
+        limit=10000,
+        referrer=referrer,
+    )
+    result = zerofill(result["data"], snuba_args["start"], snuba_args["end"], rollup, "time")
+
+    return SnubaTSResult(result, snuba_filter.start, snuba_filter.end, rollup)
 
 
 def get_pagination_ids(event, query, params):
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index c4b8d73e49..bdd4ec15d2 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -13,7 +13,6 @@ from sentry.api.event_search import (
     event_search_grammar,
     get_filter,
     resolve_field_list,
-    get_reference_event_conditions,
     parse_search_query,
     get_json_meta_type,
     InvalidSearchQuery,
@@ -23,9 +22,7 @@ from sentry.api.event_search import (
     SearchValue,
     SearchVisitor,
 )
-from sentry.utils.samples import load_data
-from sentry.testutils import TestCase, SnubaTestCase
-from sentry.testutils.helpers.datetime import before_now, iso_format
+from sentry.testutils.cases import TestCase
 
 
 def test_get_json_meta_type():
@@ -1210,181 +1207,3 @@ class ResolveFieldListTest(unittest.TestCase):
             ["argMax", ["project.id", "timestamp"], "projectid"],
         ]
         assert result["groupby"] == []
-
-
-class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
-    def setUp(self):
-        super(GetReferenceEventConditionsTest, self).setUp()
-
-        self.conditions = {"filter_keys": {"project_id": [self.project.id]}}
-
-    def test_bad_slug_format(self):
-        with pytest.raises(InvalidSearchQuery):
-            get_reference_event_conditions(self.organization, self.conditions, "lol")
-
-    def test_unknown_project(self):
-        event = self.store_event(
-            data={"message": "oh no!", "timestamp": iso_format(before_now(seconds=1))},
-            project_id=self.project.id,
-        )
-        self.conditions["filter_keys"]["project_id"] = [-1]
-        with pytest.raises(InvalidSearchQuery):
-            get_reference_event_conditions(
-                self.organization, self.conditions, "nope:{}".format(event.event_id)
-            )
-
-    def test_unknown_event(self):
-        with pytest.raises(InvalidSearchQuery):
-            slug = "{}:deadbeef".format(self.project.slug)
-            get_reference_event_conditions(self.organization, self.conditions, slug)
-
-    def test_no_fields(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "transaction": "/issues/{issue_id}",
-                "timestamp": iso_format(before_now(seconds=1)),
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = []
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert len(result) == 0
-
-    def test_basic_fields(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "transaction": "/issues/{issue_id}",
-                "timestamp": iso_format(before_now(seconds=1)),
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["message", "transaction", "unknown-field"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [
-            ["message", "=", "oh no! /issues/{issue_id}"],
-            ["transaction", "=", "/issues/{issue_id}"],
-        ]
-
-    def test_geo_field(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "transaction": "/issues/{issue_id}",
-                "user": {
-                    "id": 1,
-                    "geo": {"country_code": "US", "region": "CA", "city": "San Francisco"},
-                },
-                "timestamp": iso_format(before_now(seconds=1)),
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["geo.city", "geo.region", "geo.country_code"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [
-            ["geo.city", "=", "San Francisco"],
-            ["geo.region", "=", "CA"],
-            ["geo.country_code", "=", "US"],
-        ]
-
-    def test_sdk_field(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "transaction": "/issues/{issue_id}",
-                "sdk": {"name": "sentry-python", "version": "5.0.12"},
-                "timestamp": iso_format(before_now(seconds=1)),
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["sdk.version", "sdk.name"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [["sdk.version", "=", "5.0.12"], ["sdk.name", "=", "sentry-python"]]
-
-    def test_error_field(self):
-        data = load_data("php")
-        data["timestamp"] = iso_format(before_now(seconds=1))
-        event = self.store_event(data=data, project_id=self.project.id)
-        self.conditions["groupby"] = ["error.value", "error.type", "error.handled"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [
-            ["error.value", "=", "This is a test exception sent from the Raven CLI."],
-            ["error.type", "=", "Exception"],
-        ]
-
-    def test_stack_field(self):
-        data = load_data("php")
-        data["timestamp"] = iso_format(before_now(seconds=1))
-        event = self.store_event(data=data, project_id=self.project.id)
-        self.conditions["groupby"] = ["stack.filename", "stack.function"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [
-            ["stack.filename", "=", "/Users/example/Development/raven-php/bin/raven"],
-            ["stack.function", "=", "raven_cli_test"],
-        ]
-
-    def test_tag_value(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "timestamp": iso_format(before_now(seconds=1)),
-                "tags": {"customer_id": 1, "color": "red"},
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["nope", "color", "customer_id"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [["color", "=", "red"], ["customer_id", "=", "1"]]
-
-    def test_context_value(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "timestamp": iso_format(before_now(seconds=1)),
-                "contexts": {
-                    "os": {"version": "10.14.6", "type": "os", "name": "Mac OS X"},
-                    "browser": {"type": "browser", "name": "Firefox", "version": "69"},
-                    "gpu": {"type": "gpu", "name": "nvidia 8600", "vendor": "nvidia"},
-                },
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["gpu.name", "browser.name"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [["gpu.name", "=", "nvidia 8600"], ["browser.name", "=", "Firefox"]]
-
-    def test_issue_field(self):
-        event = self.store_event(
-            data={
-                "message": "oh no!",
-                "timestamp": iso_format(before_now(seconds=1)),
-                "contexts": {
-                    "os": {"version": "10.14.6", "type": "os", "name": "Mac OS X"},
-                    "browser": {"type": "browser", "name": "Firefox", "version": "69"},
-                    "gpu": {"type": "gpu", "name": "nvidia 8600", "vendor": "nvidia"},
-                },
-            },
-            project_id=self.project.id,
-        )
-        self.conditions["groupby"] = ["issue.id"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [["issue.id", "=", event.group_id]]
-
-    @pytest.mark.xfail(reason="This requires eventstore.get_event_by_id to work with transactions")
-    def test_transcation_field(self):
-        data = load_data("transaction")
-        event = self.store_event(data=data, project_id=self.project.id)
-        self.conditions["groupby"] = ["transaction.op", "transaction.duration"]
-        slug = "{}:{}".format(self.project.slug, event.event_id)
-        result = get_reference_event_conditions(self.organization, self.conditions, slug)
-        assert result == [["transaction.op", "=", "db"], ["transaction.duration", "=", 2]]
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index 383750d8e5..175ff00307 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -4,9 +4,13 @@ from sentry.api.event_search import InvalidSearchQuery
 from sentry.snuba import discover
 from sentry.testutils import TestCase, SnubaTestCase
 from sentry.testutils.helpers.datetime import iso_format, before_now
+from sentry.utils.samples import load_data
 from sentry.utils.snuba import Dataset
 
 from mock import patch
+from datetime import timedelta
+
+import six
 import pytest
 
 
@@ -55,7 +59,6 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
         data = result["data"]
         assert len(data) == 1
         assert data[0]["project.id"] == self.project.id
-        assert data[0]["latest_event"] == self.event.event_id
         assert data[0]["count_unique_user_email"] == 1
 
     def test_field_aliasing_in_conditions(self):
@@ -63,6 +66,7 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
             selected_columns=["project.id", "user.email"],
             query="user.email:bruce@example.com",
             params={"project_id": [self.project.id]},
+            auto_fields=True,
         )
         data = result["data"]
         assert len(data) == 1
@@ -438,8 +442,315 @@ class QueryTransformTest(TestCase):
         )
 
 
-class TimeseriesQueryTest(TestCase):
-    pass
+class TimeseriesQueryTest(SnubaTestCase, TestCase):
+    def setUp(self):
+        super(TimeseriesQueryTest, self).setUp()
+
+        self.day_ago = before_now(days=1).replace(hour=10, minute=0, second=0, microsecond=0)
+
+        self.store_event(
+            data={
+                "event_id": "a" * 32,
+                "message": "very bad",
+                "timestamp": iso_format(self.day_ago + timedelta(hours=1)),
+                "fingerprint": ["group1"],
+                "tags": {"important": "yes"},
+            },
+            project_id=self.project.id,
+        )
+        self.store_event(
+            data={
+                "event_id": "b" * 32,
+                "message": "oh my",
+                "timestamp": iso_format(self.day_ago + timedelta(hours=1, minutes=1)),
+                "fingerprint": ["group2"],
+                "tags": {"important": "no"},
+            },
+            project_id=self.project.id,
+        )
+        self.store_event(
+            data={
+                "event_id": "c" * 32,
+                "message": "very bad",
+                "timestamp": iso_format(self.day_ago + timedelta(hours=2, minutes=1)),
+                "fingerprint": ["group2"],
+                "tags": {"important": "yes"},
+            },
+            project_id=self.project.id,
+        )
+
+    def test_invalid_field_in_function(self):
+        with pytest.raises(InvalidSearchQuery):
+            discover.timeseries_query(
+                selected_columns=["min(transaction)"],
+                query="transaction:api.issue.delete",
+                params={"project_id": [self.project.id]},
+                rollup=1800,
+            )
+
+    def test_missing_start_and_end(self):
+        with pytest.raises(InvalidSearchQuery) as err:
+            discover.timeseries_query(
+                selected_columns=["count()"],
+                query="transaction:api.issue.delete",
+                params={"project_id": [self.project.id]},
+                rollup=1800,
+            )
+        assert "without a start and end" in six.text_type(err)
+
+    def test_no_aggregations(self):
+        with pytest.raises(InvalidSearchQuery) as err:
+            discover.timeseries_query(
+                selected_columns=["transaction", "title"],
+                query="transaction:api.issue.delete",
+                params={
+                    "start": self.day_ago,
+                    "end": self.day_ago + timedelta(hours=2),
+                    "project_id": [self.project.id],
+                },
+                rollup=1800,
+            )
+        assert "no aggregation" in six.text_type(err)
+
+    def test_field_alias(self):
+        result = discover.timeseries_query(
+            selected_columns=["p95"],
+            query="event.type:transaction transaction:api.issue.delete",
+            params={
+                "start": self.day_ago,
+                "end": self.day_ago + timedelta(hours=2),
+                "project_id": [self.project.id],
+            },
+            rollup=3600,
+        )
+        assert len(result.data) == 3
+
+    def test_aggregate_function(self):
+        result = discover.timeseries_query(
+            selected_columns=["count()"],
+            query="",
+            params={
+                "start": self.day_ago,
+                "end": self.day_ago + timedelta(hours=2),
+                "project_id": [self.project.id],
+            },
+            rollup=3600,
+        )
+        assert len(result.data) == 3
+        assert [2] == [val["count"] for val in result.data if "count" in val]
+
+    def test_zerofilling(self):
+        result = discover.timeseries_query(
+            selected_columns=["count()"],
+            query="",
+            params={
+                "start": self.day_ago,
+                "end": self.day_ago + timedelta(hours=3),
+                "project_id": [self.project.id],
+            },
+            rollup=3600,
+        )
+        assert len(result.data) == 4, "Should have empty results"
+        assert [2, 1] == [val["count"] for val in result.data if "count" in val], result.data
+
+    def test_reference_event(self):
+        ref = discover.ReferenceEvent(
+            self.organization,
+            "{}:{}".format(self.project.slug, "a" * 32),
+            ["message", "count()", "last_seen"],
+        )
+        result = discover.timeseries_query(
+            selected_columns=["count()"],
+            query="",
+            params={
+                "start": self.day_ago,
+                "end": self.day_ago + timedelta(hours=3),
+                "project_id": [self.project.id],
+            },
+            reference_event=ref,
+            rollup=3600,
+        )
+        assert len(result.data) == 4
+        assert [1, 1] == [val["count"] for val in result.data if "count" in val]
+
+
+class CreateReferenceEventConditionsTest(SnubaTestCase, TestCase):
+    def test_bad_slug_format(self):
+        ref = discover.ReferenceEvent(self.organization, "lol", [])
+        with pytest.raises(InvalidSearchQuery):
+            discover.create_reference_event_conditions(ref)
+
+    def test_unknown_project(self):
+        event = self.store_event(
+            data={"message": "oh no!", "timestamp": iso_format(before_now(seconds=1))},
+            project_id=self.project.id,
+        )
+        ref = discover.ReferenceEvent(self.organization, "nope:{}".format(event.event_id), [])
+        with pytest.raises(InvalidSearchQuery):
+            discover.create_reference_event_conditions(ref)
+
+    def test_unknown_event(self):
+        with pytest.raises(InvalidSearchQuery):
+            slug = "{}:deadbeef".format(self.project.slug)
+            ref = discover.ReferenceEvent(self.organization, slug, ["message"])
+            discover.create_reference_event_conditions(ref)
+
+    def test_unknown_event_and_no_fields(self):
+        slug = "{}:deadbeef".format(self.project.slug)
+        ref = discover.ReferenceEvent(self.organization, slug, [])
+        result = discover.create_reference_event_conditions(ref)
+        assert len(result) == 0
+
+    def test_no_fields(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "transaction": "/issues/{issue_id}",
+                "timestamp": iso_format(before_now(seconds=1)),
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, [])
+        result = discover.create_reference_event_conditions(ref)
+        assert len(result) == 0
+
+    def test_basic_fields(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "transaction": "/issues/{issue_id}",
+                "timestamp": iso_format(before_now(seconds=1)),
+            },
+            project_id=self.project.id,
+        )
+
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(
+            self.organization, slug, ["message", "transaction", "unknown-field"]
+        )
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [
+            ["message", "=", "oh no! /issues/{issue_id}"],
+            ["transaction", "=", "/issues/{issue_id}"],
+        ]
+
+    def test_geo_field(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "transaction": "/issues/{issue_id}",
+                "user": {
+                    "id": 1,
+                    "geo": {"country_code": "US", "region": "CA", "city": "San Francisco"},
+                },
+                "timestamp": iso_format(before_now(seconds=1)),
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(
+            self.organization, slug, ["geo.city", "geo.region", "geo.country_code"]
+        )
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [
+            ["geo.city", "=", "San Francisco"],
+            ["geo.region", "=", "CA"],
+            ["geo.country_code", "=", "US"],
+        ]
+
+    def test_sdk_field(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "transaction": "/issues/{issue_id}",
+                "sdk": {"name": "sentry-python", "version": "5.0.12"},
+                "timestamp": iso_format(before_now(seconds=1)),
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, ["sdk.version", "sdk.name"])
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [["sdk.version", "=", "5.0.12"], ["sdk.name", "=", "sentry-python"]]
+
+    def test_error_field(self):
+        data = load_data("php")
+        data["timestamp"] = iso_format(before_now(seconds=1))
+        event = self.store_event(data=data, project_id=self.project.id)
+
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(
+            self.organization, slug, ["error.value", "error.type", "error.handled"]
+        )
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [
+            ["error.value", "=", "This is a test exception sent from the Raven CLI."],
+            ["error.type", "=", "Exception"],
+        ]
+
+    def test_stack_field(self):
+        data = load_data("php")
+        data["timestamp"] = iso_format(before_now(seconds=1))
+        event = self.store_event(data=data, project_id=self.project.id)
+
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, ["stack.filename", "stack.function"])
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [
+            ["stack.filename", "=", "/Users/example/Development/raven-php/bin/raven"],
+            ["stack.function", "=", "raven_cli_test"],
+        ]
+
+    def test_tag_value(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "timestamp": iso_format(before_now(seconds=1)),
+                "tags": {"customer_id": 1, "color": "red"},
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, ["nope", "color", "customer_id"])
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [["color", "=", "red"], ["customer_id", "=", "1"]]
+
+    def test_context_value(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "timestamp": iso_format(before_now(seconds=1)),
+                "contexts": {
+                    "os": {"version": "10.14.6", "type": "os", "name": "Mac OS X"},
+                    "browser": {"type": "browser", "name": "Firefox", "version": "69"},
+                    "gpu": {"type": "gpu", "name": "nvidia 8600", "vendor": "nvidia"},
+                },
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, ["gpu.name", "browser.name"])
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [["gpu.name", "=", "nvidia 8600"], ["browser.name", "=", "Firefox"]]
+
+    def test_issue_field(self):
+        event = self.store_event(
+            data={
+                "message": "oh no!",
+                "timestamp": iso_format(before_now(seconds=1)),
+                "contexts": {
+                    "os": {"version": "10.14.6", "type": "os", "name": "Mac OS X"},
+                    "browser": {"type": "browser", "name": "Firefox", "version": "69"},
+                    "gpu": {"type": "gpu", "name": "nvidia 8600", "vendor": "nvidia"},
+                },
+            },
+            project_id=self.project.id,
+        )
+        slug = "{}:{}".format(self.project.slug, event.event_id)
+        ref = discover.ReferenceEvent(self.organization, slug, ["issue.id"])
+        result = discover.create_reference_event_conditions(ref)
+        assert result == [["issue.id", "=", event.group_id]]
 
 
 class GetPaginationIdsTest(TestCase):
