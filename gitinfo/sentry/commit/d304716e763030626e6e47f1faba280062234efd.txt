commit d304716e763030626e6e47f1faba280062234efd
Author: David Cramer <dcramer@gmail.com>
Date:   Sun Jan 29 12:58:00 2012 -0800

    Index culprit, dont tokenize search, and dont restrict token types

diff --git a/sentry/manager.py b/sentry/manager.py
index b58ed2abb6..0d2876d873 100644
--- a/sentry/manager.py
+++ b/sentry/manager.py
@@ -621,7 +621,8 @@ class SearchDocumentManager(models.Manager):
         return words
 
     def search(self, project, query, sort_by='score', offset=0, limit=100):
-        tokens = self._tokenize(query)
+        # tokens = self._tokenize(query)
+        tokens = [query]
 
         if sort_by == 'score':
             order_by = 'SUM(st.times_seen) / sd.total_events DESC'
@@ -638,8 +639,7 @@ class SearchDocumentManager(models.Manager):
             FROM sentry_searchdocument as sd
             INNER JOIN sentry_searchtoken as st
                 ON st.document_id = sd.id
-            WHERE st.field = 'text'
-                AND st.token IN (%s)
+            WHERE st.token IN (%s)
                 AND sd.project_id = %s
             GROUP BY sd.id, sd.group_id, sd.total_events, sd.date_changed, sd.date_added
             ORDER BY %s
@@ -677,7 +677,12 @@ class SearchDocumentManager(models.Manager):
             for k, v in interface.get_search_context(event).iteritems():
                 context[k].extend(v)
 
-        context['text'].extend([event.message, event.logger, event.server_name])
+        context['text'].extend([
+            event.message,
+            event.logger,
+            event.server_name,
+            event.culprit,
+        ])
 
         token_counts = defaultdict(lambda: defaultdict(int))
         for field, values in context.iteritems():
