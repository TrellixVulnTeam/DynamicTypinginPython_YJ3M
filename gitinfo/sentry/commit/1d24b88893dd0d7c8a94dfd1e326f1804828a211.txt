commit 1d24b88893dd0d7c8a94dfd1e326f1804828a211
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Fri Feb 10 19:46:22 2017 +0100

    Move reprocessing stuff into separate tasks with independent queues

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 2c37da9340..cd9b2ea6ab 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -447,7 +447,11 @@ CELERY_QUEUES = [
     Queue('digests.scheduling', routing_key='digests.scheduling'),
     Queue('email', routing_key='email'),
     Queue('events.preprocess_event', routing_key='events.preprocess_event'),
+    Queue('events.preprocess_event_from_reprocessing',
+          routing_key='events.preprocess_event_from_reprocessing'),
     Queue('events.process_event', routing_key='events.process_event'),
+    Queue('events.process_event_from_reprocessing',
+          routing_key='events.process_event_from_reprocessing'),
     Queue('events.reprocess_events', routing_key='events.reprocess_events'),
     Queue('events.save_event', routing_key='events.save_event'),
     Queue('merge', routing_key='merge'),
diff --git a/src/sentry/coreapi.py b/src/sentry/coreapi.py
index 9f4d387653..f02cac48ee 100644
--- a/src/sentry/coreapi.py
+++ b/src/sentry/coreapi.py
@@ -34,7 +34,8 @@ from sentry.interfaces.base import get_interface, InterfaceValidationError
 from sentry.interfaces.csp import Csp
 from sentry.event_manager import EventManager
 from sentry.models import EventError, ProjectKey, TagKey, TagValue
-from sentry.tasks.store import preprocess_event
+from sentry.tasks.store import preprocess_event, \
+    preprocess_event_from_reprocessing
 from sentry.utils import json
 from sentry.utils.auth import parse_auth_header
 from sentry.utils.csp import is_valid_csp_report
@@ -741,13 +742,15 @@ class ClientApiHelper(object):
         if not got_ip and set_if_missing:
             data.setdefault('sentry.interfaces.User', {})['ip_address'] = ip_address
 
-    def insert_data_to_database(self, data):
+    def insert_data_to_database(self, data, from_reprocessing=False):
         # we might be passed LazyData
         if isinstance(data, LazyData):
             data = dict(data.items())
         cache_key = 'e:{1}:{0}'.format(data['project'], data['event_id'])
         default_cache.set(cache_key, data, timeout=3600)
-        preprocess_event.delay(cache_key=cache_key, start_time=time(),
+        task = from_reprocessing and \
+            preprocess_event_from_reprocessing or preprocess_event
+        task.delay(cache_key=cache_key, start_time=time(),
             event_id=data['event_id'])
 
 
diff --git a/src/sentry/tasks/reprocessing.py b/src/sentry/tasks/reprocessing.py
index aa97f05520..dc9d49b6f5 100644
--- a/src/sentry/tasks/reprocessing.py
+++ b/src/sentry/tasks/reprocessing.py
@@ -31,7 +31,8 @@ def reprocess_events(project_id, **kwargs):
             if raw_events:
                 helper = ClientApiHelper()
                 for raw_event in raw_events:
-                    helper.insert_data_to_database(raw_event.data.data)
+                    helper.insert_data_to_database(raw_event.data.data,
+                                                   from_reprocessing=True)
                     create_reprocessing_report(project_id=project_id,
                         event_id=raw_event.event_id)
                     raw_event.delete()
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index bfd63cfc5e..8a89fc9758 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -41,13 +41,8 @@ def should_process(data):
     return False
 
 
-@instrumented_task(
-    name='sentry.tasks.store.preprocess_event',
-    queue='events.preprocess_event',
-    time_limit=65,
-    soft_time_limit=60,
-)
-def preprocess_event(cache_key=None, data=None, start_time=None, event_id=None, **kwargs):
+def _do_preprocess_event(cache_key, data, start_time, event_id,
+                         process_event):
     if cache_key:
         data = default_cache.get(cache_key)
 
@@ -76,12 +71,29 @@ def preprocess_event(cache_key=None, data=None, start_time=None, event_id=None,
 
 
 @instrumented_task(
-    name='sentry.tasks.store.process_event',
-    queue='events.process_event',
+    name='sentry.tasks.store.preprocess_event',
+    queue='events.preprocess_event',
     time_limit=65,
     soft_time_limit=60,
 )
-def process_event(cache_key, start_time=None, event_id=None, **kwargs):
+def preprocess_event(cache_key=None, data=None, start_time=None, event_id=None, **kwargs):
+    return _do_preprocess_event(cache_key, data, start_time, event_id,
+                                process_event)
+
+
+@instrumented_task(
+    name='sentry.tasks.store.preprocess_event_from_reprocessing',
+    queue='events.preprocess_event_from_reprocessing',
+    time_limit=65,
+    soft_time_limit=60,
+)
+def preprocess_event_from_reprocessing(cache_key=None, data=None,
+                                       start_time=None, event_id=None, **kwargs):
+    return _do_preprocess_event(cache_key, data, start_time, event_id,
+                                process_event_from_reprocessing)
+
+
+def _do_process_event(cache_key, start_time, event_id):
     from sentry.plugins import plugins
 
     data = default_cache.get(cache_key)
@@ -130,6 +142,26 @@ def process_event(cache_key, start_time=None, event_id=None, **kwargs):
         event_id=event_id)
 
 
+@instrumented_task(
+    name='sentry.tasks.store.process_event',
+    queue='events.process_event',
+    time_limit=65,
+    soft_time_limit=60,
+)
+def process_event(cache_key, start_time=None, event_id=None, **kwargs):
+    return _do_process_event(cache_key, start_time, event_id)
+
+
+@instrumented_task(
+    name='sentry.tasks.store.process_event_from_reprocessing',
+    queue='events.process_event_from_reprocessing',
+    time_limit=65,
+    soft_time_limit=60,
+)
+def process_event_from_reprocessing(cache_key, start_time=None, event_id=None, **kwargs):
+    return _do_process_event(cache_key, start_time, event_id)
+
+
 def delete_raw_event(project_id, event_id):
     if event_id is None:
         error_logger.error('process.failed_delete_raw_event',
