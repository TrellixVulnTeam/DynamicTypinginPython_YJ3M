commit 22ab512de0db4e79a57a5275fcd376133e3235c5
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Fri Jan 3 11:56:20 2020 -0800

    feat: Move event backfill script to a data migration (#16226)
    
    This migration exists for open source users upgrading from 9.x. If the
    user has recent events (in the last 14 days) in Postgres we can assume
    that they are upgrading from 9.x and backfill all of their Postgres
    events into the eventstream. If there are no recent events in Postgres,
    don't do anything.
    
    This migration replaces the backfill_eventstream script as this will
    stop working correctly once the Event model (which is now deprecated)
    is removed whereas the migration will continue to reference the
    historical model.

diff --git a/src/sentry/management/commands/backfill_eventstream.py b/src/sentry/management/commands/backfill_eventstream.py
index c328feaf85..17cc167a22 100644
--- a/src/sentry/management/commands/backfill_eventstream.py
+++ b/src/sentry/management/commands/backfill_eventstream.py
@@ -1,16 +1,8 @@
 from __future__ import absolute_import, print_function
 
-import sys
-
 import six
 
-from datetime import timedelta, datetime
-
-from django.core.management.base import BaseCommand, CommandError
-from django.utils.dateparse import parse_datetime
-
-from sentry import eventstore
-from sentry.models import Event, Project, Group
+from django.core.management.base import BaseCommand
 
 
 class Command(BaseCommand):
@@ -37,25 +29,6 @@ class Command(BaseCommand):
             "--no-input", action="store_true", dest="no_input", help="Do not ask questions."
         )
 
-    def get_events_by_timestamp(self, from_ts, to_ts):
-        from_date = parse_datetime(from_ts)
-        if not from_date:
-            raise CommandError("Cannot parse --from-ts")
-        to_date = parse_datetime(to_ts)
-        if not to_date:
-            raise CommandError("Cannot parse --to-ts")
-        return Event.objects.filter(datetime__gte=from_date, datetime__lte=to_date)
-
-    def get_events_by_last_days(self, last_days):
-        to_date = datetime.now()
-        from_date = to_date - timedelta(days=last_days)
-        return Event.objects.filter(datetime__gte=from_date, datetime__lte=to_date)
-
-    def get_events_by_id(self, from_id, to_id):
-        if from_id > to_id:
-            raise CommandError("Invalid ID range.")
-        return Event.objects.filter(id__gte=from_id, id__lte=to_id)
-
     def handle(
         self,
         from_ts=None,
@@ -66,57 +39,7 @@ class Command(BaseCommand):
         no_input=False,
         **options
     ):
-        def _attach_related(_events):
-            project_ids = set([event.project_id for event in _events])
-            projects = {p.id: p for p in Project.objects.filter(id__in=project_ids)}
-            group_ids = set([event.group_id for event in _events])
-            groups = {g.id: g for g in Group.objects.filter(id__in=group_ids)}
-            for event in _events:
-                event.project = projects[event.project_id]
-                event.group = groups[event.group_id]
-            eventstore.bind_nodes(_events, "data")
-
-        from sentry import eventstream
-        from sentry.utils.query import RangeQuerySetWrapper
-
-        filter_methods = bool(last_days) + bool(from_ts or to_ts) + bool(from_id or to_id)
-        if filter_methods > 1:
-            raise CommandError(
-                "You can either limit by primary key, or by timestamp, or last X days."
-            )
-        elif from_ts and to_ts:
-            events = self.get_events_by_timestamp(from_ts, to_ts)
-        elif last_days:
-            events = self.get_events_by_last_days(last_days)
-        elif from_id and to_id:
-            events = self.get_events_by_id(from_id, to_id)
-        else:
-            raise CommandError(
-                "Invalid arguments: either use --from/--to-id, or --from/--to-ts, or --last-days."
-            )
-
-        count = events.count()
-        self.stdout.write("Events to process: {}\n".format(count))
-
-        if count == 0:
-            self.stdout.write("Nothing to do.\n")
-            sys.exit(0)
-
-        if not no_input:
-            proceed = six.moves.input("Do you want to continue? [y/N] ")
-            if proceed.strip().lower() not in ["yes", "y"]:
-                raise CommandError("Aborted.")
-
-        for event in RangeQuerySetWrapper(events, step=100, callbacks=(_attach_related,)):
-            primary_hash = event.get_primary_hash()
-            eventstream.insert(
-                group=event.group,
-                event=event,
-                is_new=False,
-                is_regression=False,
-                is_new_group_environment=False,
-                primary_hash=primary_hash,
-                skip_consume=True,
-            )
-
-        self.stdout.write("Done.\n")
+        """
+        Remove this script once no longer referenced in https://github.com/getsentry/onpremise
+        """
+        pass
diff --git a/src/sentry/migrations/0024_auto_20191230_2052.py b/src/sentry/migrations/0024_auto_20191230_2052.py
new file mode 100644
index 0000000000..b9b818d534
--- /dev/null
+++ b/src/sentry/migrations/0024_auto_20191230_2052.py
@@ -0,0 +1,99 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.9.13 on 2019-12-30 20:52
+from __future__ import unicode_literals
+
+import os
+from datetime import timedelta, datetime
+
+from django.db import migrations
+
+from sentry import options
+
+
+def backfill_eventstream(apps, schema_editor):
+    """
+    Inserts Postgres events into the eventstream if there are recent events in Postgres.
+
+    This is for open source users migrating from 9.x who want to keep their events.
+    If there are no recent events in Postgres, skip the backfill.
+    """
+    from sentry import eventstore, eventstream
+    from sentry.utils.query import RangeQuerySetWrapper
+
+    Event = apps.get_model('sentry', 'Event')
+    Group = apps.get_model('sentry', 'Group')
+    Project = apps.get_model('sentry', 'Project')
+
+    # Kill switch to skip this migration
+    skip_backfill = os.environ.get("SENTRY_SKIP_EVENTS_BACKFILL_FOR_10", False)
+
+    # Use 90 day retention if the option has not been set or set to 0
+    DEFAULT_RETENTION = 90
+    retention_days = options.get("system.event-retention-days") or DEFAULT_RETENTION
+
+    def get_events(last_days):
+        to_date = datetime.now()
+        from_date = to_date - timedelta(days=last_days)
+        return Event.objects.filter(datetime__gte=from_date, datetime__lte=to_date)
+
+    def _attach_related(_events):
+        project_ids = {event.project_id for event in _events}
+        projects = {p.id: p for p in Project.objects.filter(id__in=project_ids)}
+        group_ids = {event.group_id for event in _events}
+        groups = {g.id: g for g in Group.objects.filter(id__in=group_ids)}
+        for event in _events:
+            event.project = projects[event.project_id]
+            event.group = groups[event.group_id]
+        eventstore.bind_nodes(_events, "data")
+
+    if skip_backfill:
+        print("Skipping backfill\n")
+        return
+
+    events = get_events(retention_days)
+    count = events.count()
+
+    if count == 0:
+        print("Nothing to do, skipping migration.\n")
+        return
+
+    print("Events to process: {}\n".format(count))
+
+    for event in RangeQuerySetWrapper(events, step=100, callbacks=(_attach_related,)):
+        primary_hash = event.get_primary_hash()
+        eventstream.insert(
+            group=event.group,
+            event=event,
+            is_new=False,
+            is_regression=False,
+            is_new_group_environment=False,
+            primary_hash=primary_hash,
+            skip_consume=True,
+        )
+
+    print("Done.\n")
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Adding indexes to large tables. These indexes should be created concurrently,
+    #   unfortunately we can't run migrations outside of a transaction until Django
+    #   1.10. So until then these should be run manually.
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = True
+
+
+    dependencies = [
+        ('sentry', '0023_hide_environment_none_20191126'),
+    ]
+
+    operations = [
+        migrations.RunPython(backfill_eventstream, reverse_code=migrations.RunPython.noop),
+    ]
