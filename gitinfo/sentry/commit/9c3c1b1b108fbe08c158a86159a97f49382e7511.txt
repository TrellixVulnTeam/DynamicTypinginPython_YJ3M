commit 9c3c1b1b108fbe08c158a86159a97f49382e7511
Author: Nathan Heskia <nathan.heskia@gmail.com>
Date:   Wed Feb 26 12:08:52 2020 -0800

    ref(event_saved): Send event_saved signal in outcomes_consumer (#17291)

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 64cf2b02b7..3244b76df1 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -40,6 +40,7 @@ from sentry.coreapi import (
     decode_data,
     safely_load_json_string,
 )
+from sentry.ingest.outcomes_consumer import mark_signal_sent
 from sentry.interfaces.base import get_interface
 from sentry.lang.native.utils import STORE_CRASH_REPORTS_ALL, convert_crashreport_count
 from sentry.models import (
@@ -785,6 +786,7 @@ def _materialize_metadata_many(jobs):
 @metrics.wraps("save_event.send_event_saved_signal_many")
 def _send_event_saved_signal_many(jobs, projects):
     for job in jobs:
+        mark_signal_sent(project_id=job["project_id"], event_id=job["event"].event_id)
         event_saved.send_robust(
             project=projects[job["project_id"]], event_size=job["event"].size, sender=EventManager
         )
diff --git a/src/sentry/ingest/outcomes_consumer.py b/src/sentry/ingest/outcomes_consumer.py
index 3ff8a23646..c1d8f0b49c 100644
--- a/src/sentry/ingest/outcomes_consumer.py
+++ b/src/sentry/ingest/outcomes_consumer.py
@@ -32,7 +32,7 @@ from django.core.cache import cache
 
 from sentry.models.project import Project
 from sentry.db.models.manager import BaseManager
-from sentry.signals import event_filtered, event_dropped
+from sentry.signals import event_saved, event_filtered, event_dropped
 from sentry.utils.kafka import create_batching_kafka_consumer
 from sentry.utils import json, metrics
 from sentry.utils.outcomes import Outcome
@@ -76,7 +76,7 @@ def _process_signal(msg):
         return  # no project. this is valid, so ignore silently.
 
     outcome = int(msg.get("outcome", -1))
-    if outcome not in (Outcome.FILTERED, Outcome.RATE_LIMITED):
+    if outcome not in (Outcome.FILTERED, Outcome.RATE_LIMITED, Outcome.ACCEPTED):
         metrics.incr("outcomes_consumer.skip_outcome", tags={"reason": "wrong_outcome_type"})
         return  # nothing to do here
 
@@ -99,7 +99,9 @@ def _process_signal(msg):
     reason = msg.get("reason")
     remote_addr = msg.get("remote_addr")
 
-    if outcome == Outcome.FILTERED:
+    if outcome == Outcome.ACCEPTED:
+        event_saved.send_robust(project=project, sender=OutcomesConsumerWorker)
+    elif outcome == Outcome.FILTERED:
         event_filtered.send_robust(ip=remote_addr, project=project, sender=OutcomesConsumerWorker)
     elif outcome == Outcome.RATE_LIMITED:
         event_dropped.send_robust(
diff --git a/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py b/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
index c2248b5976..6bfd228ee9 100644
--- a/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
+++ b/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
@@ -5,7 +5,7 @@ import pytest
 import six.moves
 
 from sentry.ingest.outcomes_consumer import get_outcomes_consumer, mark_signal_sent, is_signal_sent
-from sentry.signals import event_filtered, event_dropped
+from sentry.signals import event_filtered, event_dropped, event_saved
 from sentry.testutils.factories import Factories
 from sentry.utils.outcomes import Outcome
 from django.conf import settings
@@ -101,6 +101,7 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
+    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -108,8 +109,12 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -130,6 +135,7 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     # verify that no signal was called (since the events have been previously processed)
     assert event_filtered_sink == ["127.33.44.2", "127.33.44.3"]
     assert len(event_dropped_sink) == 0
+    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -156,6 +162,7 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
+    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -163,8 +170,12 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -180,6 +191,7 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     # verify that the appropriate filters were called
     assert event_filtered_sink == ["127.33.44.2", "127.33.44.3"]
     assert len(event_dropped_sink) == 0
+    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -207,6 +219,7 @@ def test_outcome_consumer_remembers_handled_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
+    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -214,8 +227,12 @@ def test_outcome_consumer_remembers_handled_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -232,16 +249,73 @@ def test_outcome_consumer_remembers_handled_outcomes(
     assert len(event_filtered_sink) == 1
     assert event_filtered_sink == ["127.33.44.1"]
     assert len(event_dropped_sink) == 0
+    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
-def test_outcome_consumer_handles_filtered_outcomes(
+def test_outcome_consumer_handles_accepted_outcomes(
     kafka_producer, task_runner, kafka_admin, requires_kafka
 ):
     producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
 
     group_id = "test-outcome-consumer-4"
 
+    # put a few outcome messages on the kafka topic
+    for i in six.moves.range(1, 3):
+        msg = _get_outcome(
+            event_id=i,
+            project_id=project_id,
+            outcome=Outcome.ACCEPTED,
+            reason="some_reason",
+            remote_addr="127.33.44.{}".format(i),
+        )
+
+        producer.produce(topic_name, msg)
+
+    # setup django signals for event_filtered and event_dropped
+    event_filtered_sink = []
+    event_dropped_sink = []
+    event_saved_sink = []
+
+    def event_filtered_receiver(**kwargs):
+        event_filtered_sink.append(kwargs.get("ip"))
+
+    def event_dropped_receiver(**kwargs):
+        event_dropped_sink.append("something")
+
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
+    event_filtered.connect(event_filtered_receiver)
+    event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
+
+    consumer = get_outcomes_consumer(
+        max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
+    )
+
+    # run the outcome consumer
+    with task_runner():
+        i = 0
+        while len(event_filtered_sink) < 2 and i < MAX_POLL_ITERATIONS:
+            consumer._run_once()
+            i += 1
+
+    # verify that the appropriate filters were called
+    assert len(event_saved_sink) == 2
+    assert set(event_saved_sink) == {"saved event"}
+    assert len(event_dropped_sink) == 0
+    assert len(event_filtered_sink) == 0
+
+
+@pytest.mark.django_db
+def test_outcome_consumer_handles_filtered_outcomes(
+    kafka_producer, task_runner, kafka_admin, requires_kafka
+):
+    producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
+
+    group_id = "test-outcome-consumer-5"
+
     # put a few outcome messages on the kafka topic
     for i in six.moves.range(1, 3):
         msg = _get_outcome(
@@ -257,6 +331,7 @@ def test_outcome_consumer_handles_filtered_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
+    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -264,8 +339,12 @@ def test_outcome_consumer_handles_filtered_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -280,8 +359,9 @@ def test_outcome_consumer_handles_filtered_outcomes(
 
     # verify that the appropriate filters were called
     assert len(event_filtered_sink) == 2
-    assert set(event_filtered_sink) == set(["127.33.44.1", "127.33.44.2"])
+    assert set(event_filtered_sink) == {"127.33.44.1", "127.33.44.2"}
     assert len(event_dropped_sink) == 0
+    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -290,7 +370,7 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
 ):
     producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
 
-    group_id = "test-outcome-consumer-5"
+    group_id = "test-outcome-consumer-6"
 
     # put a few outcome messages on the kafka topic
     for i in six.moves.range(1, 3):
@@ -307,6 +387,7 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
+    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append("something")
@@ -314,8 +395,12 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append((kwargs.get("ip"), kwargs.get("reason_code")))
 
+    def event_saved_receiver(**kwargs):
+        event_saved_sink.append("saved event")
+
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
+    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -331,6 +416,5 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     # verify that the appropriate filters were called
     assert len(event_filtered_sink) == 0
     assert len(event_dropped_sink) == 2
-    assert set(event_dropped_sink) == set(
-        [("127.33.44.1", "reason_1"), ("127.33.44.2", "reason_2")]
-    )
+    assert set(event_dropped_sink) == {("127.33.44.1", "reason_1"), ("127.33.44.2", "reason_2")}
+    assert len(event_saved_sink) == 0
