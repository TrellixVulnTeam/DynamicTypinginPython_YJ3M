commit 1f0a5ff5c7822517a814e71c5a118a57622a8e82
Author: William Mak <william@wmak.io>
Date:   Thu Mar 19 14:02:57 2020 -0400

    feature(search) - Allow aliases for durations (#17218)
    
    * feature(search) - Allow aliases for durations
    
    - This allows us to use ms, s, hr, day and week in our searches
    - These values were selected to match what we display on the frontend,
      which is why its different from our other durations `hr` instead of
      `h`

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 5836bb04b3..4a3e6502a0 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -9,7 +9,7 @@ import six
 from django.utils.functional import cached_property
 from parsimonious.expressions import Optional
 from parsimonious.exceptions import IncompleteParseError, ParseError
-from parsimonious.nodes import Node
+from parsimonious.nodes import Node, RegexNode
 from parsimonious.grammar import Grammar, NodeVisitor
 from sentry_relay.consts import SPAN_STATUS_NAME_TO_CODE
 
@@ -17,6 +17,7 @@ from sentry import eventstore
 from sentry.models import Project
 from sentry.models.group import Group
 from sentry.search.utils import (
+    parse_duration,
     parse_datetime_range,
     parse_datetime_string,
     parse_datetime_value,
@@ -97,7 +98,7 @@ search               = (boolean_term / paren_term / search_term)*
 boolean_term         = (paren_term / search_term) space? (boolean_operator space? (paren_term / search_term) space?)+
 paren_term           = space? open_paren space? (paren_term / boolean_term)+ space? closed_paren space?
 search_term          = key_val_term / quoted_raw_search / raw_search
-key_val_term         = space? (tag_filter / time_filter / rel_time_filter / specific_time_filter
+key_val_term         = space? (tag_filter / time_filter / rel_time_filter / specific_time_filter / duration_filter
                        / numeric_filter / aggregate_filter / aggregate_date_filter / has_filter
                        / is_filter / quoted_basic_filter / basic_filter)
                        space?
@@ -111,12 +112,14 @@ quoted_basic_filter  = negation? search_key sep quoted_value
 time_filter          = search_key sep? operator date_format
 # filter for relative dates
 rel_time_filter      = search_key sep rel_date_format
+# filter for durations
+duration_filter      = search_key sep operator? duration_format
 # exact time filter for dates
 specific_time_filter = search_key sep date_format
 # Numeric comparison filter
 numeric_filter       = search_key sep operator? numeric_value
 # Aggregate numeric filter
-aggregate_filter        = aggregate_key sep operator? numeric_value
+aggregate_filter        = aggregate_key sep operator? (numeric_value / duration_format)
 aggregate_date_filter   = aggregate_key sep operator? (date_format / rel_date_format)
 
 # has filter for not null type checks
@@ -138,6 +141,7 @@ quoted_key           = ~r"\"([a-zA-Z0-9_\.:-]+)\""
 
 date_format          = ~r"\d{4}-\d{2}-\d{2}(T\d{2}:\d{2}:\d{2}(\.\d{1,6})?)?Z?(?=\s|$)"
 rel_date_format      = ~r"[\+\-][0-9]+[wdhm](?=\s|$)"
+duration_format      = ~r"([0-9\.]+)(ms|s|min|m|hr|h|day|d|wk|w)(?=\s|$)"
 
 # NOTE: the order in which these operators are listed matters
 # because for example, if < comes before <= it will match that
@@ -235,6 +239,7 @@ class SearchVisitor(NodeVisitor):
     # A list of mappers that map source keys to a target name. Format is
     # <target_name>: [<list of source names>],
     key_mappings = {}
+    duration_keys = set(["transaction.duration"])
     numeric_keys = set(
         [
             "project_id",
@@ -386,12 +391,25 @@ class SearchVisitor(NodeVisitor):
     def visit_aggregate_filter(self, node, children):
         (search_key, _, operator, search_value) = children
         operator = operator[0] if not isinstance(operator, Node) else "="
+        search_value = search_value[0] if not isinstance(search_value, RegexNode) else search_value
 
         try:
-            search_value = SearchValue(float(search_value.text))
+            aggregate_value = None
+            if search_value.expr_name == "duration_format":
+                # Even if the search value matches duration format, only act as duration for certain columns
+                _, agg_additions = resolve_field(search_key.name, None)
+                if len(agg_additions) > 0:
+                    # Extract column and function name out so we can check if we should parse as duration
+                    if agg_additions[0][-2] in self.duration_keys:
+                        aggregate_value = parse_duration(*search_value.match.groups())
+
+            if aggregate_value is None:
+                aggregate_value = float(search_value.text)
         except ValueError:
             raise InvalidSearchQuery(u"Invalid aggregate query condition: {}".format(search_key))
-        return AggregateFilter(search_key, operator, search_value)
+        except InvalidQuery as exc:
+            raise InvalidSearchQuery(six.text_type(exc))
+        return AggregateFilter(search_key, operator, SearchValue(aggregate_value))
 
     def visit_aggregate_date_filter(self, node, children):
         (search_key, _, operator, search_value) = children
@@ -421,6 +439,20 @@ class SearchVisitor(NodeVisitor):
             search_value = operator + search_value if operator != "=" else search_value
             return self._handle_basic_filter(search_key, "=", SearchValue(search_value))
 
+    def visit_duration_filter(self, node, children):
+        (search_key, _, operator, search_value) = children
+
+        operator = operator[0] if not isinstance(operator, Node) else "="
+        if search_key.name in self.duration_keys:
+            try:
+                search_value = parse_duration(*search_value.match.groups())
+            except InvalidQuery as exc:
+                raise InvalidSearchQuery(six.text_type(exc))
+            return SearchFilter(search_key, operator, SearchValue(search_value))
+        else:
+            search_value = operator + search_value if operator != "=" else search_value
+            return self._handle_basic_filter(search_key, "=", SearchValue(search_value))
+
     def visit_rel_time_filter(self, node, children):
         (search_key, _, value) = children
         if search_key.name in self.date_keys:
diff --git a/src/sentry/search/utils.py b/src/sentry/search/utils.py
index 66f28b2d61..58808143ef 100644
--- a/src/sentry/search/utils.py
+++ b/src/sentry/search/utils.py
@@ -40,6 +40,34 @@ def parse_status_value(value):
     raise ValueError("Invalid status value")
 
 
+def parse_duration(value, interval):
+    try:
+        value = float(value)
+    except ValueError:
+        raise InvalidQuery(u"{} is not a valid duration value".format(value))
+
+    if interval == "ms":
+        delta = timedelta(milliseconds=value)
+    elif interval == "s":
+        delta = timedelta(seconds=value)
+    elif interval in ["min", "m"]:
+        delta = timedelta(minutes=value)
+    elif interval in ["hr", "h"]:
+        delta = timedelta(hours=value)
+    elif interval in ["day", "d"]:
+        delta = timedelta(days=value)
+    elif interval in ["wk", "w"]:
+        delta = timedelta(days=value * 7)
+    else:
+        raise InvalidQuery(
+            u"{} is not a valid duration type, must be ms, s, min, m, hr, h, day, d, wk or w".format(
+                interval
+            )
+        )
+
+    return delta.total_seconds() * 1000.0
+
+
 def parse_datetime_range(value):
     try:
         flag, count, interval = value[0], int(value[1:-1]), value[-1]
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index f59ce379cc..4b51945a44 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -11,6 +11,7 @@ from django.utils import timezone
 from freezegun import freeze_time
 
 from sentry.api.event_search import (
+    AggregateKey,
     event_search_grammar,
     get_filter,
     resolve_field_list,
@@ -555,6 +556,36 @@ class ParseSearchQueryTest(unittest.TestCase):
             with self.assertRaisesRegexp(InvalidSearchQuery, "Invalid format for numeric search"):
                 parse_search_query(invalid_query)
 
+    def test_duration_filter(self):
+        assert parse_search_query("transaction.duration:>500s") == [
+            SearchFilter(
+                key=SearchKey(name="transaction.duration"),
+                operator=">",
+                value=SearchValue(raw_value=500000.0),
+            )
+        ]
+
+    def test_aggregate_duration_filter(self):
+        assert parse_search_query("avg(transaction.duration):>500s") == [
+            SearchFilter(
+                key=AggregateKey(name="avg(transaction.duration)"),
+                operator=">",
+                value=SearchValue(raw_value=500000.0),
+            )
+        ]
+
+    def test_invalid_duration_filter(self):
+        with self.assertRaises(InvalidSearchQuery, expected_regex="not a valid duration value"):
+            parse_search_query("transaction.duration:>..500s")
+
+    def test_invalid_aggregate_duration_filter(self):
+        with self.assertRaises(InvalidSearchQuery, expected_regex="not a valid duration value"):
+            parse_search_query("avg(transaction.duration):>..500s")
+
+    def test_invalid_aggregate_column_with_duration_filter(self):
+        with self.assertRaises(InvalidSearchQuery, regex="not a duration column"):
+            parse_search_query("avg(stack.colno):>500s")
+
     def test_quotes_filtered_on_raw(self):
         # Enclose the full raw query? Strip it.
         assert parse_search_query('thinger:unknown "what is this?"') == [
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index ec99eb786e..5dcb820ee4 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -904,6 +904,50 @@ class QueryTransformTest(TestCase):
             referrer=None,
         )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_duration_aliases(self, mock_query):
+        mock_query.return_value = {
+            "meta": [{"name": "transaction"}, {"name": "duration"}],
+            "data": [{"transaction": "api.do_things", "duration": 200}],
+        }
+        start_time = before_now(minutes=10)
+        end_time = before_now(seconds=1)
+        test_cases = [
+            ("1ms", 1),
+            ("1.5s", 1500),
+            ("23.4m", 1000 * 60 * 23.4),
+            ("1.00min", 1000 * 60),
+            ("3.45hr", 1000 * 60 * 60 * 3.45),
+            ("1.23h", 1000 * 60 * 60 * 1.23),
+            ("3wk", 1000 * 60 * 60 * 24 * 7 * 3),
+            ("2.1w", 1000 * 60 * 60 * 24 * 7 * 2.1),
+        ]
+        for query_string, value in test_cases:
+            discover.query(
+                selected_columns=["transaction", "p95"],
+                query="http.method:GET p95:>{}".format(query_string),
+                params={"project_id": [self.project.id], "start": start_time, "end": end_time},
+                use_aggregate_conditions=True,
+            )
+
+            mock_query.assert_called_with(
+                selected_columns=["transaction"],
+                conditions=[["http_method", "=", "GET"]],
+                filter_keys={"project_id": [self.project.id]},
+                groupby=["transaction"],
+                dataset=Dataset.Discover,
+                aggregations=[
+                    ["quantile(0.95)", "duration", "percentile_transaction_duration_0_95"]
+                ],
+                having=[["percentile_transaction_duration_0_95", ">", value]],
+                end=end_time,
+                start=start_time,
+                orderby=None,
+                limit=50,
+                offset=None,
+                referrer=None,
+            )
+
     @patch("sentry.snuba.discover.raw_query")
     def test_alias_aggregate_conditions_with_brackets(self, mock_query):
         mock_query.return_value = {
@@ -969,6 +1013,47 @@ class QueryTransformTest(TestCase):
             referrer=None,
         )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_aggregate_duration_alias(self, mock_query):
+        mock_query.return_value = {
+            "meta": [{"name": "transaction"}, {"name": "duration"}],
+            "data": [{"transaction": "api.do_things", "duration": 200}],
+        }
+        start_time = before_now(minutes=10)
+        end_time = before_now(seconds=1)
+
+        test_cases = [
+            ("1ms", 1),
+            ("1.5s", 1500),
+            ("1.00min", 1000 * 60),
+            ("3.45hr", 1000 * 60 * 60 * 3.45),
+        ]
+        for query_string, value in test_cases:
+            discover.query(
+                selected_columns=["transaction", "avg(transaction.duration)", "max(time)"],
+                query="http.method:GET avg(transaction.duration):>{}".format(query_string),
+                params={"project_id": [self.project.id], "start": start_time, "end": end_time},
+                use_aggregate_conditions=True,
+            )
+            mock_query.assert_called_with(
+                selected_columns=["transaction"],
+                conditions=[["http_method", "=", "GET"]],
+                filter_keys={"project_id": [self.project.id]},
+                groupby=["transaction"],
+                dataset=Dataset.Discover,
+                aggregations=[
+                    ["avg", "duration", "avg_transaction_duration"],
+                    ["max", "time", "max_time"],
+                ],
+                having=[["avg_transaction_duration", ">", value]],
+                end=end_time,
+                start=start_time,
+                orderby=None,
+                limit=50,
+                offset=None,
+                referrer=None,
+            )
+
     @patch("sentry.snuba.discover.raw_query")
     def test_aggregate_condition_missing_selected_column(self, mock_query):
         mock_query.return_value = {
