commit fb5fa25d7996d4c9a59920c57dfca63f7c615e2a
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Fri Aug 16 13:51:28 2019 -0700

    Revert "feat: Reprocess event if a duplicate is found (#14375)" (#14425)
    
    This reverts commit a96e147fb5974afc100a9a58d9471d000255c65a.

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index cba300c879..747e74f01d 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -511,6 +511,29 @@ class EventManager(object):
             id=project.organization_id
         )
 
+        # Check to make sure we're not about to do a bunch of work that's
+        # already been done if we've processed an event with this ID. (This
+        # isn't a perfect solution -- this doesn't handle ``EventMapping`` and
+        # there's a race condition between here and when the event is actually
+        # saved, but it's an improvement. See GH-7677.)
+        try:
+            event = Event.objects.get(project_id=project.id, event_id=data["event_id"])
+        except Event.DoesNotExist:
+            pass
+        else:
+            # Make sure we cache on the project before returning
+            event._project_cache = project
+            logger.info(
+                "duplicate.found",
+                exc_info=True,
+                extra={
+                    "event_uuid": data["event_id"],
+                    "project_id": project.id,
+                    "model": Event.__name__,
+                },
+            )
+            return event
+
         # Pull out the culprit
         culprit = self.get_culprit()
 
@@ -758,10 +781,7 @@ class EventManager(object):
         if not is_sample:
             try:
                 with transaction.atomic(using=router.db_for_write(Event)):
-                    try:
-                        event = Event.objects.get(project_id=project.id, event_id=data["event_id"])
-                    except Event.DoesNotExist:
-                        event.save()
+                    event.save()
             except IntegrityError:
                 logger.info(
                     "duplicate.found",
