commit d61ccf8112e007076359a69c4a22c68a723482ca
Author: Mark Story <mark@sentry.io>
Date:   Mon Oct 28 11:50:22 2019 -0400

    ref(discover) Consolidate snuba alias resolution (#15179)
    
    Alias resolution will be deferred until much later in dataset_query().
    By deferring alias resolution we can have simpler and more contained
    abstractions around the customer facing event query datamodel.
    
    Add/improve integration tests around event details. We know that
    issue search is always for errors so don't use detection logic.

diff --git a/src/sentry/api/bases/organization_events.py b/src/sentry/api/bases/organization_events.py
index 4c5b644206..de96419981 100644
--- a/src/sentry/api/bases/organization_events.py
+++ b/src/sentry/api/bases/organization_events.py
@@ -95,7 +95,7 @@ class OrganizationEventsEndpointBase(OrganizationEndpoint):
 
         # 'legacy' endpoints cannot access transactions dataset.
         # as they often have assumptions about which columns are returned.
-        dataset = snuba.detect_dataset(snuba_args, aliased_conditions=True)
+        dataset = snuba.detect_dataset(snuba_args)
         if dataset != snuba.Dataset.Events:
             raise OrganizationEventsError(
                 "Invalid query. You cannot reference non-events data in this endpoint."
diff --git a/src/sentry/api/endpoints/group_events.py b/src/sentry/api/endpoints/group_events.py
index 97d77755cd..432d6a1b2e 100644
--- a/src/sentry/api/endpoints/group_events.py
+++ b/src/sentry/api/endpoints/group_events.py
@@ -87,6 +87,7 @@ class GroupEventsEndpoint(GroupEndpoint, EnvironmentMixin):
 
         full = request.GET.get("full", False)
         snuba_filter = get_filter(request.GET.get("query", None), params)
+        snuba_filter.conditions.append(["event.type", "!=", "transaction"])
 
         snuba_cols = None if full else eventstore.full_columns
 
diff --git a/src/sentry/api/endpoints/organization_eventid.py b/src/sentry/api/endpoints/organization_eventid.py
index 08bcb248d0..96fd6cb9e2 100644
--- a/src/sentry/api/endpoints/organization_eventid.py
+++ b/src/sentry/api/endpoints/organization_eventid.py
@@ -46,12 +46,12 @@ class EventIdLookupEndpoint(OrganizationEndpoint):
         )
 
         try:
-            event = eventstore.get_events(
-                filter=eventstore.Filter(
-                    project_ids=project_slugs_by_id.keys(), event_ids=[event_id]
-                ),
-                limit=1,
-            )[0]
+            snuba_filter = eventstore.Filter(
+                conditions=[["event.type", "!=", "transaction"]],
+                project_ids=project_slugs_by_id.keys(),
+                event_ids=[event_id],
+            )
+            event = eventstore.get_events(filter=snuba_filter, limit=1)[0]
         except IndexError:
             raise ResourceDoesNotExist()
         else:
diff --git a/src/sentry/api/endpoints/organization_events.py b/src/sentry/api/endpoints/organization_events.py
index 98f955acab..2fcec9dca6 100644
--- a/src/sentry/api/endpoints/organization_events.py
+++ b/src/sentry/api/endpoints/organization_events.py
@@ -111,7 +111,7 @@ class OrganizationEventsV2Endpoint(OrganizationEventsEndpointBase):
             )
 
         data_fn = partial(
-            lambda **kwargs: snuba.transform_aliases_and_query(skip_conditions=True, **kwargs),
+            lambda **kwargs: snuba.transform_aliases_and_query(**kwargs),
             referrer="api.organization-events-v2",
             **snuba_args
         )
diff --git a/src/sentry/api/endpoints/organization_events_distribution.py b/src/sentry/api/endpoints/organization_events_distribution.py
index f45cd01edc..9704b1fd58 100644
--- a/src/sentry/api/endpoints/organization_events_distribution.py
+++ b/src/sentry/api/endpoints/organization_events_distribution.py
@@ -45,7 +45,6 @@ class OrganizationEventsDistributionEndpoint(OrganizationEventsEndpointBase):
             conditions = snuba_args["conditions"] + additional_conditions
 
         top_values = transform_aliases_and_query(
-            skip_conditions=True,
             start=snuba_args["start"],
             end=snuba_args["end"],
             conditions=conditions,
diff --git a/src/sentry/api/endpoints/organization_events_meta.py b/src/sentry/api/endpoints/organization_events_meta.py
index 3eae70a25a..ebe43bf096 100644
--- a/src/sentry/api/endpoints/organization_events_meta.py
+++ b/src/sentry/api/endpoints/organization_events_meta.py
@@ -17,7 +17,6 @@ class OrganizationEventsMetaEndpoint(OrganizationEventsEndpointBase):
             return Response({"count": 0})
 
         data = snuba.transform_aliases_and_query(
-            skip_conditions=True,
             aggregations=[["count()", "", "count"]],
             referrer="api.organization-event-meta",
             **snuba_args
diff --git a/src/sentry/api/endpoints/organization_events_stats.py b/src/sentry/api/endpoints/organization_events_stats.py
index 65e70a8b02..f4550db333 100644
--- a/src/sentry/api/endpoints/organization_events_stats.py
+++ b/src/sentry/api/endpoints/organization_events_stats.py
@@ -35,7 +35,6 @@ class OrganizationEventsStatsEndpoint(OrganizationEventsEndpointBase):
         snuba_args = self.get_field(request, snuba_args)
 
         result = snuba.transform_aliases_and_query(
-            skip_conditions=True,
             aggregations=snuba_args.get("aggregations"),
             conditions=snuba_args.get("conditions"),
             filter_keys=snuba_args.get("filter_keys"),
diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 5bd0f6f87c..46ddc30e01 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -186,19 +186,6 @@ class SearchFilter(namedtuple("SearchFilter", "key operator value")):
 
 
 class SearchKey(namedtuple("SearchKey", "name")):
-    @property
-    def snuba_name(self):
-        snuba_name = SEARCH_MAP.get(self.name)
-        if snuba_name:
-            return snuba_name
-
-        # assume custom tag if not matched above, and add tags[xxx] wrapper if not present.
-        match = TAG_KEY_RE.match(self.name)
-        if match:
-            return self.name
-        else:
-            return "tags[%s]" % (self.name,)
-
     @cached_property
     def is_tag(self):
         return TAG_KEY_RE.match(self.name) or self.name not in SEARCH_MAP
@@ -544,12 +531,12 @@ def convert_endpoint_params(params):
 
 
 def convert_search_filter_to_snuba_query(search_filter):
-    snuba_name = search_filter.key.snuba_name
+    name = search_filter.key.name
     value = search_filter.value.value
 
-    if snuba_name in no_conversion:
+    if name in no_conversion:
         return
-    elif snuba_name == "environment":
+    elif name == "environment":
         # conditions added to env_conditions are OR'd
         env_conditions = []
 
@@ -565,7 +552,7 @@ def convert_search_filter_to_snuba_query(search_filter):
 
         return env_conditions
 
-    elif snuba_name == "message":
+    elif name == "message":
         if search_filter.value.is_wildcard():
             # XXX: We don't want the '^$' values at the beginning and end of
             # the regex since we want to find the pattern anywhere in the
@@ -583,7 +570,7 @@ def convert_search_filter_to_snuba_query(search_filter):
     else:
         value = (
             int(to_timestamp(value)) * 1000
-            if isinstance(value, datetime) and snuba_name != "timestamp"
+            if isinstance(value, datetime) and name != "timestamp"
             else value
         )
 
@@ -591,15 +578,15 @@ def convert_search_filter_to_snuba_query(search_filter):
         # To handle both cases, use `ifNull` to convert to an empty string and
         # compare so we need to check for empty values.
         if search_filter.key.is_tag:
-            snuba_name = ["ifNull", [snuba_name, "''"]]
+            name = ["ifNull", [name, "''"]]
 
         # Handle checks for existence
         if search_filter.operator in ("=", "!=") and search_filter.value.value == "":
             if search_filter.key.is_tag:
-                return [snuba_name, search_filter.operator, value]
+                return [name, search_filter.operator, value]
             else:
                 # If not a tag, we can just check that the column is null.
-                return [["isNull", [snuba_name]], search_filter.operator, 1]
+                return [["isNull", [name]], search_filter.operator, 1]
 
         is_null_condition = None
         if search_filter.operator == "!=" and not search_filter.key.is_tag:
@@ -609,12 +596,12 @@ def convert_search_filter_to_snuba_query(search_filter):
             # together with the inequality check.
             # We don't need to apply this for tags, since if they don't exist
             # they'll always be an empty string.
-            is_null_condition = [["isNull", [snuba_name]], "=", 1]
+            is_null_condition = [["isNull", [name]], "=", 1]
 
         if search_filter.value.is_wildcard():
-            condition = [["match", [snuba_name, "'(?i)%s'" % (value,)]], search_filter.operator, 1]
+            condition = [["match", [name, "'(?i)%s'" % (value,)]], search_filter.operator, 1]
         else:
-            condition = [snuba_name, search_filter.operator, value]
+            condition = [name, search_filter.operator, value]
 
         # We only want to return as a list if we have the check for null
         # present. Returning as a list causes these conditions to be ORed
@@ -657,21 +644,21 @@ def get_filter(query=None, params=None):
 
     for term in parsed_terms:
         if isinstance(term, SearchFilter):
-            snuba_name = term.key.snuba_name
+            name = term.key.name
             if term.key.name == PROJECT_KEY:
                 condition = ["project_id", "=", projects.get(term.value.value)]
                 kwargs["conditions"].append(condition)
-            elif snuba_name in ("start", "end"):
-                kwargs[snuba_name] = term.value.value
-            elif snuba_name in ("project_id", "issue"):
-                if snuba_name == "issue":
-                    snuba_name = "group_ids"
-                if snuba_name == "project_id":
-                    snuba_name = "project_ids"
+            elif name in ("start", "end"):
+                kwargs[name] = term.value.value
+            elif name in ("project_id", "issue.id"):
+                if name == "issue.id":
+                    name = "group_ids"
+                if name == "project_id":
+                    name = "project_ids"
                 value = term.value.value
                 if isinstance(value, int):
                     value = [value]
-                kwargs[snuba_name].extend(value)
+                kwargs[name].extend(value)
             else:
                 converted_filter = convert_search_filter_to_snuba_query(term)
                 kwargs["conditions"].append(converted_filter)
@@ -868,12 +855,12 @@ def get_reference_event_conditions(snuba_args, event_slug):
     if "tags.key" in event_data and "tags.value" in event_data:
         tags = dict(zip(event_data["tags.key"], event_data["tags.value"]))
 
-    for field in field_names:
-        match = TAG_KEY_RE.match(field)
+    for (i, field) in enumerate(groupby):
+        match = TAG_KEY_RE.match(field_names[i])
         if match:
             value = tags.get(match.group(1), None)
         else:
-            value = event_data.get(field, None)
+            value = event_data.get(field_names[i], None)
             # If the value is a sequence use the first element as snuba
             # doesn't support `=` or `IN` operations on fields like exception_frames.filename
             if isinstance(value, (list, set)) and value:
diff --git a/src/sentry/api/helpers/events.py b/src/sentry/api/helpers/events.py
index b5e3dd9792..00234f9be6 100644
--- a/src/sentry/api/helpers/events.py
+++ b/src/sentry/api/helpers/events.py
@@ -16,6 +16,7 @@ def get_direct_hit_response(request, query, snuba_params, referrer):
     event_id = normalize_event_id(query)
     if event_id:
         snuba_filter = get_filter(query=u"id:{}".format(event_id), params=snuba_params)
+        snuba_filter.conditions.append(["event.type", "!=", "transaction"])
 
         results = eventstore.get_events(referrer=referrer, filter=snuba_filter)
 
diff --git a/src/sentry/eventstore/snuba/backend.py b/src/sentry/eventstore/snuba/backend.py
index 868aa26f7f..38d5bce572 100644
--- a/src/sentry/eventstore/snuba/backend.py
+++ b/src/sentry/eventstore/snuba/backend.py
@@ -45,10 +45,9 @@ class SnubaEventStorage(EventStorage):
         Get events from Snuba.
         """
         assert filter, "You must provide a filter"
-
         cols = self.__get_columns(additional_columns)
 
-        result = snuba.raw_query(
+        result = snuba.dataset_query(
             selected_columns=cols,
             start=filter.start,
             end=filter.end,
@@ -160,9 +159,7 @@ class SnubaEventStorage(EventStorage):
             limit=1,
             referrer="eventstore.get_next_or_prev_event_id",
             orderby=orderby,
-            dataset=snuba.detect_dataset(
-                {"conditions": filter.conditions}, aliased_conditions=True
-            ),
+            dataset=snuba.detect_dataset({"conditions": filter.conditions}),
         )
 
         if "error" in result or len(result["data"]) == 0:
diff --git a/src/sentry/search/snuba/backend.py b/src/sentry/search/snuba/backend.py
index 218d35d941..1befaaf3c7 100644
--- a/src/sentry/search/snuba/backend.py
+++ b/src/sentry/search/snuba/backend.py
@@ -671,7 +671,8 @@ def snuba_search(
         orderby = ["-{}".format(sort_field), "issue"]  # ensure stable sort within the same score
         referrer = "search"
 
-    snuba_results = snuba.raw_query(
+    snuba_results = snuba.dataset_query(
+        dataset=snuba.Dataset.Events,
         start=start,
         end=end,
         selected_columns=selected_columns,
diff --git a/src/sentry/utils/snuba.py b/src/sentry/utils/snuba.py
index a6c30e433f..6cae5df4a2 100644
--- a/src/sentry/utils/snuba.py
+++ b/src/sentry/utils/snuba.py
@@ -68,9 +68,11 @@ class Dataset(Enum):
 DATASETS = {Dataset.Events: SENTRY_SNUBA_MAP, Dataset.Transactions: TRANSACTIONS_SENTRY_SNUBA_MAP}
 
 # Store the internal field names to save work later on.
+# Add `group_id` to the events dataset list as we don't want to publically
+# expose that field, but it is used by eventstore and other internals.
 DATASET_FIELDS = {
-    Dataset.Events: SENTRY_SNUBA_MAP.values(),
-    Dataset.Transactions: TRANSACTIONS_SENTRY_SNUBA_MAP.values(),
+    Dataset.Events: list(SENTRY_SNUBA_MAP.values()) + ["group_id"],
+    Dataset.Transactions: list(TRANSACTIONS_SENTRY_SNUBA_MAP.values()),
 }
 
 
@@ -242,7 +244,7 @@ def get_snuba_column_name(name, dataset=Dataset.Events):
     the column is assumed to be a tag. If name is falsy or name is a quoted literal
     (e.g. "'name'"), leave unchanged.
     """
-    no_conversion = set(["project_id", "start", "end"])
+    no_conversion = set(["issue", "project_id", "start", "end"])
 
     if name in no_conversion:
         return name
@@ -428,7 +430,7 @@ def valid_orderby(orderby, custom_fields=None, dataset=Dataset.Events):
     return True
 
 
-def transform_aliases_and_query(skip_conditions=False, **kwargs):
+def transform_aliases_and_query(**kwargs):
     """
     Convert aliases in selected_columns, groupby, aggregation, conditions,
     orderby and arrayjoin fields to their internal Snuba format and post the
@@ -450,7 +452,7 @@ def transform_aliases_and_query(skip_conditions=False, **kwargs):
     rollup = kwargs.get("rollup")
     orderby = kwargs.get("orderby")
     having = kwargs.get("having", [])
-    dataset = detect_dataset(kwargs, aliased_conditions=skip_conditions)
+    dataset = detect_dataset(kwargs)
 
     if selected_columns:
         for (idx, col) in enumerate(selected_columns):
@@ -483,22 +485,9 @@ def transform_aliases_and_query(skip_conditions=False, **kwargs):
         elif isinstance(aggregation[1], (set, tuple, list)):
             aggregation[1] = [get_snuba_column_name(col, dataset) for col in aggregation[1]]
 
-    if not skip_conditions:
-        for col in filter_keys.keys():
-            name = get_snuba_column_name(col, dataset)
-            filter_keys[name] = filter_keys.pop(col)
-
-    def handle_condition(cond):
-        if isinstance(cond, (list, tuple)) and len(cond):
-            if isinstance(cond[0], (list, tuple)):
-                cond[0] = handle_condition(cond[0])
-            elif len(cond) == 3:
-                # map column name
-                cond[0] = get_snuba_column_name(cond[0], dataset)
-            elif len(cond) == 2 and cond[0] == "has":
-                # first function argument is the column if function is "has"
-                cond[1][0] = get_snuba_column_name(cond[1][0], dataset)
-        return cond
+    for col in filter_keys.keys():
+        name = get_snuba_column_name(col, dataset)
+        filter_keys[name] = filter_keys.pop(col)
 
     if conditions:
         aliased_conditions = []
@@ -506,10 +495,8 @@ def transform_aliases_and_query(skip_conditions=False, **kwargs):
             field = condition[0]
             if not isinstance(field, (list, tuple)) and field in derived_columns:
                 having.append(condition)
-            elif skip_conditions:
-                aliased_conditions.append(condition)
             else:
-                aliased_conditions.append(handle_condition(condition))
+                aliased_conditions.append(condition)
         kwargs["conditions"] = aliased_conditions
 
     if having:
@@ -909,7 +896,7 @@ def constrain_column_to_dataset(col, dataset, value=None):
         return col
     # Special case for the type condition as we only want
     # to drop it when we are querying transactions.
-    if dataset == Dataset.Transactions and col == "type" and value == "transaction":
+    if dataset == Dataset.Transactions and col == "event.type" and value == "transaction":
         return None
     if not col or QUOTED_LITERAL_RE.match(col):
         return col
@@ -932,6 +919,11 @@ def constrain_condition_to_dataset(cond, dataset):
     """
     index = get_function_index(cond)
     if index is not None:
+        # IN conditions are detected as a function but aren't really.
+        if cond[index] == "IN":
+            cond[0] = constrain_column_to_dataset(cond[0], dataset)
+            return cond
+
         func_args = cond[index + 1]
         for (i, arg) in enumerate(func_args):
             # Nested function
@@ -941,6 +933,7 @@ def constrain_condition_to_dataset(cond, dataset):
                 func_args[i] = constrain_column_to_dataset(arg, dataset)
         cond[index + 1] = func_args
         return cond
+
     # No function name found
     if isinstance(cond, (list, tuple)) and len(cond):
         # Condition is [col, operator, value]
@@ -998,7 +991,7 @@ def dataset_query(
     derived_columns = []
     if selected_columns:
         for (i, col) in enumerate(selected_columns):
-            if isinstance(col, list):
+            if isinstance(col, (list, tuple)):
                 derived_columns.append(col[2])
             else:
                 selected_columns[i] = constrain_column_to_dataset(col, dataset)
@@ -1015,11 +1008,14 @@ def dataset_query(
         conditions = list(filter(None, conditions))
 
     if orderby:
+        # Don't mutate in case we have a default order passed.
+        updated_order = []
         for (i, order) in enumerate(orderby):
             order_field = order.lstrip("-")
             if order_field not in derived_columns:
                 order_field = constrain_column_to_dataset(order_field, dataset)
-            orderby[i] = u"{}{}".format("-" if order.startswith("-") else "", order_field)
+            updated_order.append(u"{}{}".format("-" if order.startswith("-") else "", order_field))
+        orderby = updated_order
 
     return raw_query(
         start=start,
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index 267c72f0de..893fcb0208 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -859,9 +859,9 @@ class GetSnubaQueryArgsTest(TestCase):
         )
 
         assert filter.conditions == [
-            ["email", "=", "foo@example.com"],
-            ["tags[sentry:release]", "=", "1.2.1"],
-            [["ifNull", ["tags[fruit]", "''"]], "=", "apple"],
+            ["user.email", "=", "foo@example.com"],
+            ["release", "=", "1.2.1"],
+            [["ifNull", ["fruit", "''"]], "=", "apple"],
             [["positionCaseInsensitive", ["message", "'hello'"]], "!=", 0],
         ]
         assert filter.start == datetime.datetime(2015, 5, 18, 10, 15, 1, tzinfo=timezone.utc)
@@ -874,7 +874,7 @@ class GetSnubaQueryArgsTest(TestCase):
     def test_negation(self):
         filter = get_filter("!user.email:foo@example.com")
         assert filter.conditions == [
-            [[["isNull", ["email"]], "=", 1], ["email", "!=", "foo@example.com"]]
+            [[["isNull", ["user.email"]], "=", 1], ["user.email", "!=", "foo@example.com"]]
         ]
         assert filter.filter_keys == {}
 
@@ -883,9 +883,7 @@ class GetSnubaQueryArgsTest(TestCase):
             [["ifNull", ["tags[fruit]", "''"]], "=", "apple"]
         ]
 
-        assert get_filter("fruit:apple").conditions == [
-            [["ifNull", ["tags[fruit]", "''"]], "=", "apple"]
-        ]
+        assert get_filter("fruit:apple").conditions == [[["ifNull", ["fruit", "''"]], "=", "apple"]]
 
         assert get_filter("tags[project_id]:123").conditions == [
             [["ifNull", ["tags[project_id]", "''"]], "=", "123"]
@@ -907,8 +905,8 @@ class GetSnubaQueryArgsTest(TestCase):
     def test_wildcard(self):
         filter = get_filter("release:3.1.* user.email:*@example.com")
         assert filter.conditions == [
-            [["match", ["tags[sentry:release]", "'(?i)^3\\.1\\..*$'"]], "=", 1],
-            [["match", ["email", "'(?i)^.*\\@example\\.com$'"]], "=", 1],
+            [["match", ["release", "'(?i)^3\\.1\\..*$'"]], "=", 1],
+            [["match", ["user.email", "'(?i)^.*\\@example\\.com$'"]], "=", 1],
         ]
         assert filter.filter_keys == {}
 
@@ -916,34 +914,30 @@ class GetSnubaQueryArgsTest(TestCase):
         filter = get_filter("!release:3.1.* user.email:*@example.com")
         assert filter.conditions == [
             [
-                [["isNull", ["tags[sentry:release]"]], "=", 1],
-                [["match", ["tags[sentry:release]", "'(?i)^3\\.1\\..*$'"]], "!=", 1],
+                [["isNull", ["release"]], "=", 1],
+                [["match", ["release", "'(?i)^3\\.1\\..*$'"]], "!=", 1],
             ],
-            [["match", ["email", "'(?i)^.*\\@example\\.com$'"]], "=", 1],
+            [["match", ["user.email", "'(?i)^.*\\@example\\.com$'"]], "=", 1],
         ]
         assert filter.filter_keys == {}
 
     def test_escaped_wildcard(self):
         assert get_filter("release:3.1.\\* user.email:\\*@example.com").conditions == [
-            [["match", ["tags[sentry:release]", "'(?i)^3\\.1\\.\\*$'"]], "=", 1],
-            [["match", ["email", "'(?i)^\*\\@example\\.com$'"]], "=", 1],
+            [["match", ["release", "'(?i)^3\\.1\\.\\*$'"]], "=", 1],
+            [["match", ["user.email", "'(?i)^\*\\@example\\.com$'"]], "=", 1],
         ]
         assert get_filter("release:\\\\\\*").conditions == [
-            [["match", ["tags[sentry:release]", "'(?i)^\\\\\\*$'"]], "=", 1]
+            [["match", ["release", "'(?i)^\\\\\\*$'"]], "=", 1]
         ]
         assert get_filter("release:\\\\*").conditions == [
-            [["match", ["tags[sentry:release]", "'(?i)^\\\\.*$'"]], "=", 1]
+            [["match", ["release", "'(?i)^\\\\.*$'"]], "=", 1]
         ]
 
     def test_has(self):
-        assert get_filter("has:release").conditions == [
-            [["isNull", ["tags[sentry:release]"]], "!=", 1]
-        ]
+        assert get_filter("has:release").conditions == [[["isNull", ["release"]], "!=", 1]]
 
     def test_not_has(self):
-        assert get_filter("!has:release").conditions == [
-            [["isNull", ["tags[sentry:release]"]], "=", 1]
-        ]
+        assert get_filter("!has:release").conditions == [[["isNull", ["release"]], "=", 1]]
 
     def test_message_negative(self):
         assert get_filter('!message:"post_process.process_error HTTPError 403"').conditions == [
@@ -973,7 +967,7 @@ class GetSnubaQueryArgsTest(TestCase):
         assert filter.group_ids == [1, 2, 3]
 
         filter = get_filter("issue.id:1 user.email:foo@example.com")
-        assert filter.conditions == [["email", "=", "foo@example.com"]]
+        assert filter.conditions == [["user.email", "=", "foo@example.com"]]
         assert filter.filter_keys == {"issue": [1]}
         assert filter.group_ids == [1]
 
@@ -1264,9 +1258,9 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
         assert result == [
-            ["geo_city", "=", "San Francisco"],
-            ["geo_region", "=", "CA"],
-            ["geo_country_code", "=", "US"],
+            ["geo.city", "=", "San Francisco"],
+            ["geo.region", "=", "CA"],
+            ["geo.country_code", "=", "US"],
         ]
 
     def test_sdk_field(self):
@@ -1282,7 +1276,7 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         self.conditions["groupby"] = ["sdk.version", "sdk.name"]
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
-        assert result == [["sdk_version", "=", "5.0.12"], ["sdk_name", "=", "sentry-python"]]
+        assert result == [["sdk.version", "=", "5.0.12"], ["sdk.name", "=", "sentry-python"]]
 
     def test_error_field(self):
         data = load_data("php")
@@ -1292,8 +1286,8 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
         assert result == [
-            ["exception_stacks.value", "=", "This is a test exception sent from the Raven CLI."],
-            ["exception_stacks.type", "=", "Exception"],
+            ["error.value", "=", "This is a test exception sent from the Raven CLI."],
+            ["error.type", "=", "Exception"],
         ]
 
     def test_stack_field(self):
@@ -1304,8 +1298,8 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
         assert result == [
-            ["exception_frames.filename", "=", "/Users/example/Development/raven-php/bin/raven"],
-            ["exception_frames.function", "=", "raven_cli_test"],
+            ["stack.filename", "=", "/Users/example/Development/raven-php/bin/raven"],
+            ["stack.function", "=", "raven_cli_test"],
         ]
 
     def test_tag_value(self):
@@ -1320,7 +1314,7 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         self.conditions["groupby"] = ["nope", "color", "customer_id"]
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
-        assert result == [["tags[color]", "=", "red"], ["tags[customer_id]", "=", "1"]]
+        assert result == [["color", "=", "red"], ["customer_id", "=", "1"]]
 
     def test_context_value(self):
         event = self.store_event(
@@ -1339,8 +1333,8 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
         assert result == [
-            ["tags[gpu.name]", "=", "nvidia 8600"],
-            ["tags[browser.name]", "=", "Firefox"],
+            ["gpu.name", "=", "nvidia 8600"],
+            ["browser.name", "=", "Firefox"],
         ]
 
     def test_issue_field(self):
@@ -1359,7 +1353,7 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         self.conditions["groupby"] = ["issue.id"]
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
-        assert result == [["issue", "=", event.group_id]]
+        assert result == [["issue.id", "=", event.group_id]]
 
     @pytest.mark.xfail(reason="This requires eventstore.get_event_by_id to work with transactions")
     def test_transcation_field(self):
@@ -1368,4 +1362,4 @@ class GetReferenceEventConditionsTest(SnubaTestCase, TestCase):
         self.conditions["groupby"] = ["transaction.op", "transaction.duration"]
         slug = "{}:{}".format(self.project.slug, event.event_id)
         result = get_reference_event_conditions(self.conditions, slug)
-        assert result == [["transaction_op", "=", "db"], ["duration", "=", 2]]
+        assert result == [["transaction.op", "=", "db"], ["transaction.duration", "=", 2]]
diff --git a/tests/sentry/utils/test_snuba.py b/tests/sentry/utils/test_snuba.py
index 6a7f68f04e..c8815726f3 100644
--- a/tests/sentry/utils/test_snuba.py
+++ b/tests/sentry/utils/test_snuba.py
@@ -419,10 +419,9 @@ class TransformAliasesAndQueryTransactionsTest(TestCase):
             "data": [{"transaction_name": "api.do_things"}],
         }
         transform_aliases_and_query(
-            skip_conditions=True,
             selected_columns=["transaction"],
             conditions=[
-                ["type", "=", "transaction"],
+                ["event.type", "=", "transaction"],
                 ["match", [["ifNull", ["tags[user_email]", ""]], "'(?i)^.*\@sentry\.io$'"]],
                 [["positionCaseInsensitive", ["message", "'recent-searches'"]], "!=", 0],
             ],
@@ -447,15 +446,14 @@ class TransformAliasesAndQueryTransactionsTest(TestCase):
         )
 
     @patch("sentry.utils.snuba.raw_query")
-    def test_condition_removal_skip_conditions(self, mock_query):
+    def test_condition_removal(self, mock_query):
         mock_query.return_value = {
             "meta": [{"name": "transaction_name"}, {"name": "duration"}],
             "data": [{"transaction_name": "api.do_things", "duration": 200}],
         }
         transform_aliases_and_query(
-            skip_conditions=True,
             selected_columns=["transaction", "transaction.duration"],
-            conditions=[["type", "=", "transaction"], ["duration", ">", 200]],
+            conditions=[["event.type", "=", "transaction"], ["duration", ">", 200]],
             groupby=["transaction.op"],
             filter_keys={"project_id": [self.project.id]},
         )
@@ -480,9 +478,12 @@ class TransformAliasesAndQueryTransactionsTest(TestCase):
             "data": [{"transaction_name": "api.do_things", "duration": 200}],
         }
         transform_aliases_and_query(
-            skip_conditions=True,
             selected_columns=["transaction", "transaction.duration"],
-            conditions=[["type", "=", "transaction"], ["type", "=", "csp"], ["duration", ">", 200]],
+            conditions=[
+                ["event.type", "=", "transaction"],
+                ["type", "=", "csp"],
+                ["duration", ">", 200],
+            ],
             groupby=["transaction.op"],
             filter_keys={"project_id": [self.project.id]},
         )
@@ -501,13 +502,12 @@ class TransformAliasesAndQueryTransactionsTest(TestCase):
         )
 
     @patch("sentry.utils.snuba.raw_query")
-    def test_condition_transform_skip_conditions(self, mock_query):
+    def test_condition_transform(self, mock_query):
         mock_query.return_value = {
             "meta": [{"name": "transaction_name"}, {"name": "duration"}],
             "data": [{"transaction_name": "api.do_things", "duration": 200}],
         }
         transform_aliases_and_query(
-            skip_conditions=True,
             selected_columns=["transaction", "transaction.duration"],
             conditions=[["http_method", "=", "GET"]],
             groupby=["transaction.op"],
@@ -534,16 +534,16 @@ class DetectDatasetTest(TestCase):
         assert detect_dataset(query) == Dataset.Events
 
     def test_event_type_condition(self):
-        query = {"conditions": [["type", "=", "transaction"]]}
+        query = {"conditions": [["event.type", "=", "transaction"]]}
         assert detect_dataset(query) == Dataset.Transactions
 
-        query = {"conditions": [["type", "=", "error"]]}
+        query = {"conditions": [["event.type", "=", "error"]]}
         assert detect_dataset(query) == Dataset.Events
 
-        query = {"conditions": [["type", "=", "transaction"]]}
+        query = {"conditions": [["event.type", "=", "transaction"]]}
         assert detect_dataset(query) == Dataset.Transactions
 
-        query = {"conditions": [["type", "=", "error"]]}
+        query = {"conditions": [["event.type", "=", "error"]]}
         assert detect_dataset(query) == Dataset.Events
 
         query = {"conditions": [["type", "!=", "transactions"]]}
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index cefa0a5ef2..30c6e19a71 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -5,6 +5,7 @@ from django.core.urlresolvers import reverse
 
 from sentry.testutils import APITestCase, SnubaTestCase
 from sentry.testutils.helpers.datetime import before_now, iso_format
+from sentry.utils.samples import load_data
 import pytest
 
 
@@ -549,3 +550,24 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         data = response.data["data"]
         assert data[0]["transaction"] == "/example"
         assert data[0]["latest_event"] == "b" * 32
+
+    def test_transaction_event_type(self):
+        self.login_as(user=self.user)
+
+        project = self.create_project()
+        data = load_data("transaction")
+        data["timestamp"] = iso_format(before_now(minutes=1, seconds=5))
+        data["start_timestamp"] = iso_format(before_now(minutes=1))
+        self.store_event(data=data, project_id=project.id)
+
+        with self.feature("organizations:events-v2"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "field": ["transaction", "transaction.duration"],
+                    "query": "event.type:transaction",
+                },
+            )
+        assert response.status_code == 200, response.content
+        assert len(response.data["data"]) == 1
diff --git a/tests/snuba/search/test_backend.py b/tests/snuba/search/test_backend.py
index 87034067fc..9b01864d8f 100644
--- a/tests/snuba/search/test_backend.py
+++ b/tests/snuba/search/test_backend.py
@@ -20,7 +20,7 @@ from sentry.models import (
 from sentry.search.snuba.backend import SnubaSearchBackend
 from sentry.testutils import SnubaTestCase, TestCase, xfail_if_not_postgres
 from sentry.testutils.helpers.datetime import iso_format
-from sentry.utils.snuba import SENTRY_SNUBA_MAP, SnubaError
+from sentry.utils.snuba import Dataset, SENTRY_SNUBA_MAP, SnubaError
 
 
 def date_to_query_format(date):
@@ -882,6 +882,8 @@ class SnubaSearchTest(TestCase, SnubaTestCase):
         limit = int(DEFAULT_LIMIT * chunk_growth)
 
         common_args = {
+            "arrayjoin": None,
+            "dataset": Dataset.Events,
             "start": Any(datetime),
             "end": Any(datetime),
             "filter_keys": {
@@ -982,7 +984,7 @@ class SnubaSearchTest(TestCase, SnubaTestCase):
     def test_hits_estimate(self):
         # 400 Groups/Events
         # Every 3rd one is Unresolved
-        # Evey 2nd one has tag match=1
+        # Every 2nd one has tag match=1
         for i in range(400):
             event = self.store_event(
                 data={
