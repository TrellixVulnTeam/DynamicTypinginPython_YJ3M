commit cdb57dd4b49a8f93093edf9598adefa81b52ee70
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Wed Oct 12 01:44:24 2016 +0200

    Added read timeout and max size support for sourcemaps

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 08b1edf3b6..fbc56bebb1 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -880,6 +880,12 @@ SENTRY_GRAVATAR_BASE_URL = 'https://secure.gravatar.com'
 # Timeout (in seconds) for fetching remote source files (e.g. JS)
 SENTRY_SOURCE_FETCH_TIMEOUT = 5
 
+# Timeout (in seconds) for socket operations when fetching remote source files
+SENTRY_SOURCE_FETCH_SOCKET_TIMEOUT = 2
+
+# Maximum content length for source files before we abort fetching
+SENTRY_SOURCE_FETCH_MAX_SIZE = 25 * 1024 * 1024
+
 # List of IP subnets which should not be accessible
 SENTRY_DISALLOWED_IPS = ()
 
diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index f9774f47df..94fe6bbcc1 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -6,14 +6,15 @@ import logging
 import re
 import base64
 import six
+import time
 import zlib
 
 from django.conf import settings
 from django.core.exceptions import SuspiciousOperation
-from django.utils.encoding import force_bytes, force_text
+from django.utils.encoding import force_text
 from collections import namedtuple
 from os.path import splitext
-from requests.exceptions import RequestException
+from requests.exceptions import RequestException, Timeout
 from six.moves.urllib.parse import urlparse, urljoin, urlsplit
 
 # In case SSL is unavailable (light builds) we can't import this here.
@@ -358,56 +359,80 @@ def fetch_file(url, project=None, release=None, allow_scraping=True):
 
         with metrics.timer('sourcemaps.fetch'):
             http_session = http.build_session()
+            response = None
             try:
-                response = http_session.get(
-                    url,
-                    allow_redirects=True,
-                    verify=False,
-                    headers=headers,
-                    timeout=settings.SENTRY_SOURCE_FETCH_TIMEOUT,
-                )
-            except Exception as exc:
-                logger.debug('Unable to fetch %r', url, exc_info=True)
-                if isinstance(exc, RestrictedIPAddress):
-                    error = {
-                        'type': EventError.RESTRICTED_IP,
-                        'url': expose_url(url),
-                    }
-                elif isinstance(exc, SuspiciousOperation):
-                    error = {
-                        'type': EventError.SECURITY_VIOLATION,
-                        'url': expose_url(url),
-                    }
-                elif isinstance(exc, (RequestException, ZeroReturnError)):
-                    error = {
-                        'type': EventError.JS_GENERIC_FETCH_ERROR,
-                        'value': six.text_type(type(exc)),
-                        'url': expose_url(url),
-                    }
-                else:
-                    logger.exception(six.text_type(exc))
-                    error = {
-                        'type': EventError.UNKNOWN_ERROR,
-                        'url': expose_url(url),
-                    }
-
-                # TODO(dcramer): we want to be less aggressive on disabling domains
-                cache.set(domain_key, error or '', 300)
-                logger.warning('Disabling sources to %s for %ss', domain, 300,
-                               exc_info=True)
-                raise CannotFetchSource(error)
-
-            # requests' attempts to use chardet internally when no encoding is found
-            # and we want to avoid that slow behavior
-            if not response.encoding:
-                response.encoding = 'utf-8'
-
-            body = response.text
-            z_body = zlib.compress(force_bytes(body))
-            headers = {k.lower(): v for k, v in response.headers.items()}
-
-            cache.set(cache_key, (headers, z_body, response.status_code), 60)
-            result = (headers, body, response.status_code)
+                try:
+                    now = time.time()
+                    response = http_session.get(
+                        url,
+                        allow_redirects=True,
+                        verify=False,
+                        headers=headers,
+                        timeout=settings.SENTRY_SOURCE_FETCH_SOCKET_TIMEOUT,
+                        stream=True,
+                    )
+
+                    try:
+                        cl = int(response.headers['content-length'])
+                    except (LookupError, ValueError):
+                        cl = 0
+                    if cl > settings.SENTRY_SOURCE_FETCH_MAX_SIZE:
+                        raise OverflowError()
+                    contents = []
+                    for chunk in response.iter_content():
+                        if time.time() - now > settings.SENTRY_SOURCE_FETCH_TIMEOUT:
+                            raise Timeout()
+                        contents.append(chunk)
+                except Exception as exc:
+                    logger.debug('Unable to fetch %r', url, exc_info=True)
+                    if isinstance(exc, RestrictedIPAddress):
+                        error = {
+                            'type': EventError.RESTRICTED_IP,
+                            'url': expose_url(url),
+                        }
+                    elif isinstance(exc, SuspiciousOperation):
+                        error = {
+                            'type': EventError.SECURITY_VIOLATION,
+                            'url': expose_url(url),
+                        }
+                    elif isinstance(exc, Timeout):
+                        error = {
+                            'type': EventError.JS_SOURCEMAP_TIMEOUT,
+                            'url': expose_url(url),
+                        }
+                    elif isinstance(exc, OverflowError):
+                        error = {
+                            'type': EventError.JS_SOURCEMAP_TOO_LARGE,
+                            'url': expose_url(url),
+                        }
+                    elif isinstance(exc, (RequestException, ZeroReturnError)):
+                        error = {
+                            'type': EventError.JS_GENERIC_FETCH_ERROR,
+                            'value': six.text_type(type(exc)),
+                            'url': expose_url(url),
+                        }
+                    else:
+                        logger.exception(six.text_type(exc))
+                        error = {
+                            'type': EventError.UNKNOWN_ERROR,
+                            'url': expose_url(url),
+                        }
+
+                    # TODO(dcramer): we want to be less aggressive on disabling domains
+                    cache.set(domain_key, error or '', 300)
+                    logger.warning('Disabling sources to %s for %ss', domain, 300,
+                                   exc_info=True)
+                    raise CannotFetchSource(error)
+
+                body = b''.join(contents)
+                z_body = zlib.compress(body)
+                headers = {k.lower(): v for k, v in response.headers.items()}
+
+                cache.set(cache_key, (headers, z_body, response.status_code), 60)
+                result = (headers, body, response.status_code)
+            finally:
+                if response is not None:
+                    response.close()
 
     if result[2] != 200:
         logger.debug('HTTP %s when fetching %r', result[2], url,
diff --git a/src/sentry/models/eventerror.py b/src/sentry/models/eventerror.py
index 2eb7242e72..b4dae739b2 100644
--- a/src/sentry/models/eventerror.py
+++ b/src/sentry/models/eventerror.py
@@ -20,6 +20,8 @@ class EventError(object):
     JS_TOO_MANY_REMOTE_SOURCES = 'js_too_many_sources'
     JS_INVALID_SOURCE_ENCODING = 'js_invalid_source_encoding'
     JS_INVALID_SOURCEMAP_LOCATION = 'js_invalid_sourcemap_location'
+    JS_SOURCEMAP_TOO_LARGE = 'js_sourcemap_too_large'
+    JS_SOURCEMAP_TIMEOUT = 'js_sourcemap_timeout'
     NATIVE_NO_CRASHED_THREAD = 'native_no_crashed_thread'
     NATIVE_INTERNAL_FAILURE = 'native_internal_failure'
     NATIVE_NO_SYMSYND = 'native_no_symsynd'
@@ -40,6 +42,8 @@ class EventError(object):
         JS_TOO_MANY_REMOTE_SOURCES: u'The maximum number of remote source requests was made',
         JS_INVALID_SOURCE_ENCODING: u'Source file was not \'{value}\' encoding: {url}',
         JS_INVALID_SOURCEMAP_LOCATION: u'Invalid location in sourcemap: ({column}, {row})',
+        JS_SOURCEMAP_TOO_LARGE: u'Sourcemap too large',
+        JS_SOURCEMAP_TIMEOUT: u'Sourcemap took too long to load',
         NATIVE_NO_CRASHED_THREAD: u'No crashed thread found in crash report',
         NATIVE_INTERNAL_FAILURE: u'Internal failure when attempting to symbolicate: {error}',
         NATIVE_NO_SYMSYND: u'The symbolizer is not configured for this system.',
