commit c4c7e1ee91f072108b758f758d4177db1667bdfd
Author: Markus Unterwaditzer <markus@unterwaditzer.net>
Date:   Fri Oct 11 10:57:45 2019 +0200

    ref(signals): Process event_filtered and event_dropped in outcomes consumer exclusively (#15031)

diff --git a/src/sentry/options/defaults.py b/src/sentry/options/defaults.py
index 5caf5d27c9..8e21937a8d 100644
--- a/src/sentry/options/defaults.py
+++ b/src/sentry/options/defaults.py
@@ -172,5 +172,7 @@ register("post-process.error-hook-sample-rate", default=0.0)  # unused
 # Transaction events
 # True => kill switch to disable ingestion of transaction events for internal project.
 register("transaction-events.force-disable-internal-project", default=False)
+
+# Moving signals and TSDB into outcomes consumer
 register("outcomes.signals-in-consumer-sample-rate", default=0.0)
 register("outcomes.tsdb-in-consumer-sample-rate", default=0.0)
diff --git a/src/sentry/utils/outcomes.py b/src/sentry/utils/outcomes.py
index d797ec6ccf..38f54ea684 100644
--- a/src/sentry/utils/outcomes.py
+++ b/src/sentry/utils/outcomes.py
@@ -1,12 +1,14 @@
 from __future__ import absolute_import
 
+import random
+
 from datetime import datetime
 from django.conf import settings
 from enum import IntEnum
 import six
 import time
 
-from sentry import tsdb
+from sentry import tsdb, options
 from sentry.utils import json, metrics
 from sentry.utils.data_filters import FILTER_STAT_KEYS_TO_VALUES
 from sentry.utils.dates import to_datetime
@@ -27,6 +29,11 @@ outcomes = settings.KAFKA_TOPICS[settings.KAFKA_OUTCOMES]
 outcomes_publisher = None
 
 
+def decide_signals_in_consumer():
+    rate = options.get("outcomes.signals-in-consumer-sample-rate")
+    return rate and rate > random.random()
+
+
 def track_outcome(org_id, project_id, key_id, outcome, reason=None, timestamp=None, event_id=None):
     """
     This is a central point to track org/project counters per incoming event.
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index df097387bf..4866689a33 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -68,7 +68,7 @@ from sentry.utils import json, metrics
 from sentry.utils.data_filters import FilterStatKeys
 from sentry.utils.data_scrubber import SensitiveDataFilter
 from sentry.utils.http import is_valid_origin, get_origins, is_same_domain, origin_from_request
-from sentry.utils.outcomes import Outcome, track_outcome
+from sentry.utils.outcomes import Outcome, track_outcome, decide_signals_in_consumer
 from sentry.utils.pubsub import QueuedPublisherService, KafkaPublisher
 from sentry.utils.safe import safe_execute
 from sentry.utils.sdk import configure_scope
@@ -201,10 +201,13 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
     event_id = data["event_id"]
 
     if should_filter:
-        # Mark that the event_filtered signal is sent. Do this before emitting
-        # the outcome to avoid a potential race between OutcomesConsumer and
-        # `event_filtered.send_robust` below.
-        mark_signal_sent(project_config.project_id, event_id)
+        signals_in_consumer = decide_signals_in_consumer()
+
+        if not signals_in_consumer:
+            # Mark that the event_filtered signal is sent. Do this before emitting
+            # the outcome to avoid a potential race between OutcomesConsumer and
+            # `event_filtered.send_robust` below.
+            mark_signal_sent(project_config.project_id, event_id)
 
         track_outcome(
             project_config.organization_id,
@@ -215,7 +218,10 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             event_id=event_id,
         )
         metrics.incr("events.blacklisted", tags={"reason": filter_reason}, skip_internal=False)
-        event_filtered.send_robust(ip=remote_addr, project=project, sender=process_event)
+
+        if not signals_in_consumer:
+            event_filtered.send_robust(ip=remote_addr, project=project, sender=process_event)
+
         raise APIForbidden("Event dropped due to filter: %s" % (filter_reason,))
 
     # TODO: improve this API (e.g. make RateLimit act on __ne__)
@@ -231,10 +237,13 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
         if rate_limit is None:
             api_logger.debug("Dropped event due to error with rate limiter")
 
-        # Mark that the event_dropped signal is sent. Do this before emitting
-        # the outcome to avoid a potential race between OutcomesConsumer and
-        # `event_dropped.send_robust` below.
-        mark_signal_sent(project_config.project_id, event_id)
+        signals_in_consumer = decide_signals_in_consumer()
+
+        if not signals_in_consumer:
+            # Mark that the event_dropped signal is sent. Do this before emitting
+            # the outcome to avoid a potential race between OutcomesConsumer and
+            # `event_dropped.send_robust` below.
+            mark_signal_sent(project_config.project_id, event_id)
 
         reason = rate_limit.reason_code if rate_limit else None
         track_outcome(
@@ -246,9 +255,11 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             event_id=event_id,
         )
         metrics.incr("events.dropped", tags={"reason": reason or "unknown"}, skip_internal=False)
-        event_dropped.send_robust(
-            ip=remote_addr, project=project, reason_code=reason, sender=process_event
-        )
+        if not signals_in_consumer:
+            event_dropped.send_robust(
+                ip=remote_addr, project=project, reason_code=reason, sender=process_event
+            )
+
         if rate_limit is not None:
             raise APIRateLimited(rate_limit.retry_after)
 
