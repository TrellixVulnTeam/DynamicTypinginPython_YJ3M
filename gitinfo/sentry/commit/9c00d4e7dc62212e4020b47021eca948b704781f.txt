commit 9c00d4e7dc62212e4020b47021eca948b704781f
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Fri Jan 12 23:07:11 2018 +0100

    fix(reprocessing): Clean up reprocessing reports correctly (#6968)

diff --git a/src/sentry/tasks/reprocessing.py b/src/sentry/tasks/reprocessing.py
index 3040c5278d..0102163330 100644
--- a/src/sentry/tasks/reprocessing.py
+++ b/src/sentry/tasks/reprocessing.py
@@ -31,6 +31,9 @@ def reprocess_events(project_id, **kwargs):
                 for raw_event in raw_events:
                     helper.insert_data_to_database(raw_event.data.data, from_reprocessing=True)
                     create_reprocessing_report(project_id=project_id, event_id=raw_event.event_id)
+                    # Here we only delete the raw event but leave the
+                    # reprocessing report alive.  When the queue
+                    # eventually kicks in this should clean up.
                     raw_event.delete()
     except UnableToAcquireLock as error:
         logger.warning('reprocess_events.fail', extra={'error': error})
@@ -47,12 +50,14 @@ def create_reprocessing_report(project_id, event_id):
 
 @instrumented_task(name='sentry.tasks.clear_expired_raw_events', time_limit=15, soft_time_limit=10)
 def clear_expired_raw_events():
-    from sentry.models import RawEvent, ProcessingIssue
+    from sentry.models import RawEvent, ProcessingIssue, ReprocessingReport
 
     cutoff = timezone.now() - \
         timedelta(days=settings.SENTRY_RAW_EVENT_MAX_AGE_DAYS)
 
+    # Clear old raw events and reprocessing reports
     RawEvent.objects.filter(datetime__lt=cutoff).delete()
+    ReprocessingReport.objects.filter(datetime__lt=cutoff).delete()
 
     # Processing issues get a bit of extra time before we delete them
     cutoff = timezone.now() - timedelta(days=int(settings.SENTRY_RAW_EVENT_MAX_AGE_DAYS * 1.3))
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index 57dca96b9e..90d7a16676 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -77,6 +77,7 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_event):
         data = None
     save_event.delay(
         cache_key=cache_key, data=data, start_time=start_time, event_id=event_id,
+        project_id=project
     )
 
 
@@ -164,6 +165,7 @@ def _do_process_event(cache_key, start_time, event_id, process_task):
 
     save_event.delay(
         cache_key=cache_key, data=None, start_time=start_time, event_id=event_id,
+        project_id=project
     )
 
 
@@ -285,7 +287,8 @@ def create_failed_event(cache_key, project_id, issues, event_id, start_time=None
 
 
 @instrumented_task(name='sentry.tasks.store.save_event', queue='events.save_event')
-def save_event(cache_key=None, data=None, start_time=None, event_id=None, **kwargs):
+def save_event(cache_key=None, data=None, start_time=None, event_id=None,
+               project_id=None, **kwargs):
     """
     Saves an event to the database.
     """
@@ -299,14 +302,27 @@ def save_event(cache_key=None, data=None, start_time=None, event_id=None, **kwar
     if event_id is None and data is not None:
         event_id = data['event_id']
 
-    if data is None:
-        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'post'})
-        return
-
-    project_id = data.pop('project')
+    # only when we come from reprocessing we get a project_id sent into
+    # the task.
+    if project_id is None:
+        project_id = data.pop('project')
 
     delete_raw_event(project_id, event_id, allow_hint_clear=True)
 
+    # This covers two cases: where data is None because we did not manage
+    # to fetch it from the default cache or the empty dictionary was
+    # stored in the default cache.  The former happens if the event
+    # expired while being on the queue, the second happens on reprocessing
+    # if the raw event was deleted concurrently while we held on to
+    # it.  This causes the node store to delete the data and we end up
+    # fetching an empty dict.  We could in theory not invoke `save_event`
+    # in those cases but it's important that we always clean up the
+    # reprocessing reports correctly or they will screw up the UI.  So
+    # to future proof this correctly we just handle this case here.
+    if not data:
+        metrics.incr('events.failed', tags={'reason': 'cache', 'stage': 'post'})
+        return
+
     Raven.tags_context({
         'project': project_id,
     })
diff --git a/tests/sentry/tasks/test_store.py b/tests/sentry/tasks/test_store.py
index c1a556acb6..83e740d2ac 100644
--- a/tests/sentry/tasks/test_store.py
+++ b/tests/sentry/tasks/test_store.py
@@ -109,6 +109,7 @@ class StoreTasksTest(PluginTestCase):
 
         mock_save_event.delay.assert_called_once_with(
             cache_key='e:1', data=None, start_time=1, event_id=None,
+            project_id=project.id
         )
 
     @mock.patch('sentry.tasks.store.save_event')
@@ -134,6 +135,7 @@ class StoreTasksTest(PluginTestCase):
 
         mock_save_event.delay.assert_called_once_with(
             cache_key='e:1', data=None, start_time=1, event_id=None,
+            project_id=project.id
         )
 
     @mock.patch('sentry.tasks.store.save_event')
@@ -168,6 +170,7 @@ class StoreTasksTest(PluginTestCase):
 
         mock_save_event.delay.assert_called_once_with(
             cache_key='e:1', data=None, start_time=1, event_id=None,
+            project_id=project.id
         )
 
     @mock.patch.object(tsdb, 'incr')
