commit 05ab4247573f384b29dc58f29388d61b15224c95
Author: Ted Kaemming <ted@kaemming.com>
Date:   Mon Sep 21 16:21:14 2015 -0700

    Package hygiene, work on configuration options.

diff --git a/src/sentry/timelines/backoff.py b/src/sentry/timelines/backoff.py
new file mode 100644
index 0000000000..3578354a4d
--- /dev/null
+++ b/src/sentry/timelines/backoff.py
@@ -0,0 +1,11 @@
+class BackoffStrategy(object):
+    def __call__(self, iteration):
+        raise NotImplementedError
+
+
+class IntervalBackoffStrategy(BackoffStrategy):
+    def __init__(self, interval=60):
+        self.interval = interval
+
+    def __call__(self, iteration):
+        return self.interval
diff --git a/src/sentry/timelines/base.py b/src/sentry/timelines/base.py
index 41e8d25da5..7ea5deb0cc 100644
--- a/src/sentry/timelines/base.py
+++ b/src/sentry/timelines/base.py
@@ -1,15 +1,32 @@
-class Backend(object):
-    pass
+import logging
+from collections import namedtuple
+
+from sentry.utils.imports import import_string
+
+
+logger = logging.getLogger('sentry.timelines')
+
 
+Record = namedtuple('Record', 'key value timestamp')
 
-class Backoff(object):
-    def __init__(self, function, maximum_steps=2):
-        self.function = function
-        self.maximum_steps = maximum_steps
 
-    def __call__(self, step):
-        return self.function(min(step, self.maximum_steps))
+def load(options):
+    return import_string(options['path'])(**options.get('options', {}))
+
+
+class Backend(object):
+    def __init__(self, **options):
+        self.codec = load(options.pop('codec', {'path': 'sentry.timelines.codecs.CompressedPickleCodec'}))
+        self.backoff = load(options.pop('backoff', {'path': 'sentry.timelines.backoff.IntervalBackoffStrategy'}))
+
+        self.capacity = options.pop('capacity', None)
+        if self.capacity is not None and self.capacity < 1:
+            raise ValueError('Timeline capacity must be at least 1 if used.')
 
-    @property
-    def maximum(self):
-        return self(self.maximum_steps)
+        if self.capacity:
+            self.trim_chance = options.pop('trim_chance', 1.0 / self.capacity)
+        else:
+            self.trim_chance = None
+            if 'trim_chance' in options:
+                logger.warning('No timeline capacity has been set, ignoring "trim_chance" option.')
+                del options['trim_chance']
diff --git a/src/sentry/timelines/codecs.py b/src/sentry/timelines/codecs.py
new file mode 100644
index 0000000000..e83841edd0
--- /dev/null
+++ b/src/sentry/timelines/codecs.py
@@ -0,0 +1,19 @@
+import zlib
+
+from sentry.utils.compat import pickle
+
+
+class Codec(object):
+    def encode(self, value):
+        raise NotImplementedError
+
+    def decode(self, value):
+        raise NotImplementedError
+
+
+class CompressedPickleCodec(Codec):
+    def encode(self, value):
+        return zlib.compress(pickle.dumps(value))
+
+    def decode(self, value):
+        return pickle.loads(zlib.decompress(value))
diff --git a/src/sentry/timelines/redis.py b/src/sentry/timelines/redis.py
index ee57429419..499f3ee2f3 100644
--- a/src/sentry/timelines/redis.py
+++ b/src/sentry/timelines/redis.py
@@ -5,8 +5,6 @@ import itertools
 import logging
 import random
 import time
-import zlib
-from collections import namedtuple
 from contextlib import contextmanager
 from datetime import datetime
 
@@ -19,18 +17,14 @@ from redis.exceptions import (
     WatchError,
 )
 
-from sentry.utils.compat import pickle
 
 from .base import (
     Backend,
-    Backoff,
+    Record,
 )
 
 
-logger = logging.getLogger(__name__)
-
-
-Record = namedtuple('Record', 'key value timestamp')
+logger = logging.getLogger('sentry.timelines')
 
 
 ADD_TO_SCHEDULE_SCRIPT = """\
@@ -59,6 +53,7 @@ if redis.call('ZSCORE', KEYS[2], ARGV[1]) == false then
 end
 """
 
+
 TRUNCATE_TIMELINE_SCRIPT = """\
 -- Trims a timeline to a maximum number of records.
 -- Returns the number of keys that were deleted.
@@ -74,6 +69,7 @@ end
 return table.getn(keys)
 """
 
+
 # XXX: Passing `None` as the first argument is a dirty hack to allow us to use
 # this more easily with the cluster
 add_to_schedule = Script(None, ADD_TO_SCHEDULE_SCRIPT)
@@ -84,14 +80,6 @@ def to_timestamp(value):
     return (value - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
 
 
-class CompressedPickleCodec(object):
-    def encode(self, value):
-        return zlib.compress(pickle.dumps(value))
-
-    def decode(self, value):
-        return pickle.loads(zlib.decompress(value))
-
-
 WAITING_STATE = 'w'
 READY_STATE = 'r'
 
@@ -120,20 +108,14 @@ def make_record_key(timeline_key, record):
 
 class RedisBackend(Backend):
     def __init__(self, **options):
-        if not options:
-            options = settings.SENTRY_REDIS_OPTIONS
-
-        self.cluster = Cluster(options['hosts'])
-        self.namespace = 'digests'
-
-        # TODO: Allow this to be configured (probably via a import path.)
-        self.codec = CompressedPickleCodec()
+        super(RedisBackend, self).__init__(**options)
 
-        self.backoff = Backoff(lambda step: (60 * 5) << step)
-        self.delivery_grace_seconds = 60 * 15
+        self.cluster = Cluster(**options.pop('cluster', settings.SENTRY_REDIS_OPTIONS))
+        self.namespace = options.pop('namespace', 'digests')
+        self.record_ttl = options.pop('record_ttl', 60 * 60)
 
-        self.capacity = 1000
-        self.trim_chance = 1.0 / self.capacity
+        if options:
+            logger.warning('Discarding invalid options: %r', options)
 
     def add(self, target, record):
         timeline_key = make_timeline_key(self.namespace, target)
@@ -146,11 +128,9 @@ class RedisBackend(Backend):
             pipeline.set(
                 record_key,
                 self.codec.encode(record.value),
-                ex=self.backoff.maximum + self.delivery_grace_seconds,
+                ex=self.record_ttl,
             )
 
-            # TODO: Does this need a timeout? This assumes that the iteration
-            # counter will be deleted when the timeline has no more records.
             pipeline.set(make_iteration_key(timeline_key), 0, nx=True)
 
             # TODO: Prefix the entry with the timestamp (lexicographically
@@ -167,7 +147,7 @@ class RedisBackend(Backend):
                 pipeline,
             )
 
-            should_truncate = random.random() <= self.trim_chance
+            should_truncate = random.random() < self.trim_chance
             if should_truncate:
                 truncate_timeline((timeline_key,), (self.capacity,), pipeline)
 
