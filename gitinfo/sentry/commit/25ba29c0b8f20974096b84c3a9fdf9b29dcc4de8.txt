commit 25ba29c0b8f20974096b84c3a9fdf9b29dcc4de8
Author: Brett Hoerner <brett@bretthoerner.com>
Date:   Tue Nov 27 13:31:23 2018 -0600

    ref: Disable GroupHashTombstone code (#10784)
    
    This model is no longer used now that we have `group_id` as a first
    class column in Snuba.
    
    Follow-on PR will remove the model and drop the table.

diff --git a/src/sentry/api/endpoints/group_details.py b/src/sentry/api/endpoints/group_details.py
index bb264b993b..d5b02863ae 100644
--- a/src/sentry/api/endpoints/group_details.py
+++ b/src/sentry/api/endpoints/group_details.py
@@ -19,7 +19,7 @@ from sentry.models import (
     Activity,
     Environment,
     Group,
-    GroupHashTombstone,
+    GroupHash,
     GroupRelease,
     GroupSeen,
     GroupStatus,
@@ -393,14 +393,13 @@ class GroupDetailsEndpoint(GroupEndpoint, EnvironmentMixin):
             project = group.project
 
             eventstream_state = eventstream.start_delete_groups(group.project_id, [group.id])
-
-            GroupHashTombstone.tombstone_groups(
-                project_id=project.id,
-                group_ids=[group.id],
-            )
-
             transaction_id = uuid4().hex
 
+            GroupHash.objects.filter(
+                project_id=group.project_id,
+                group__id=group.id,
+            ).delete()
+
             delete_groups.apply_async(
                 kwargs={
                     'object_ids': [group.id],
diff --git a/src/sentry/api/endpoints/project_group_index.py b/src/sentry/api/endpoints/project_group_index.py
index cb484f6f01..98b90165d9 100644
--- a/src/sentry/api/endpoints/project_group_index.py
+++ b/src/sentry/api/endpoints/project_group_index.py
@@ -24,7 +24,7 @@ from sentry.db.models.query import create_or_update
 from sentry.models import (
     Activity, Environment, Group, GroupAssignee, GroupBookmark, GroupHash, GroupResolution,
     GroupSeen, GroupShare, GroupSnooze, GroupStatus, GroupSubscription, GroupSubscriptionReason,
-    GroupHashTombstone, GroupTombstone, Release, TOMBSTONE_FIELDS_FROM_GROUP, UserOption, User, Team
+    GroupTombstone, Release, TOMBSTONE_FIELDS_FROM_GROUP, UserOption, User, Team
 )
 from sentry.models.event import Event
 from sentry.models.group import looks_like_short_id
@@ -979,13 +979,12 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint, EnvironmentMixin):
         ]).update(status=GroupStatus.PENDING_DELETION)
 
         eventstream_state = eventstream.start_delete_groups(project.id, group_ids)
+        transaction_id = uuid4().hex
 
-        GroupHashTombstone.tombstone_groups(
+        GroupHash.objects.filter(
             project_id=project.id,
-            group_ids=group_ids,
-        )
-
-        transaction_id = uuid4().hex
+            group__id__in=group_ids,
+        ).delete()
 
         delete_groups.apply_async(
             kwargs={
diff --git a/src/sentry/deletions/__init__.py b/src/sentry/deletions/__init__.py
index f6d7f33e3c..4a74b81640 100644
--- a/src/sentry/deletions/__init__.py
+++ b/src/sentry/deletions/__init__.py
@@ -53,7 +53,6 @@ def load_defaults():
     default_manager.register(models.GroupEmailThread, BulkModelDeletionTask)
     default_manager.register(models.GroupEnvironment, BulkModelDeletionTask)
     default_manager.register(models.GroupHash, BulkModelDeletionTask)
-    default_manager.register(models.GroupHashTombstone, BulkModelDeletionTask)
     default_manager.register(models.GroupLink, BulkModelDeletionTask)
     default_manager.register(models.GroupMeta, BulkModelDeletionTask)
     default_manager.register(models.GroupRedirect, BulkModelDeletionTask)
diff --git a/src/sentry/deletions/defaults/project.py b/src/sentry/deletions/defaults/project.py
index 128568a718..9c25f30ae8 100644
--- a/src/sentry/deletions/defaults/project.py
+++ b/src/sentry/deletions/defaults/project.py
@@ -16,9 +16,9 @@ class ProjectDeletionTask(ModelDeletionTask):
         model_list = (
             models.Activity, models.EnvironmentProject, models.EventAttachment, models.EventMapping,
             models.EventUser, models.GroupAssignee, models.GroupBookmark, models.GroupEmailThread,
-            models.GroupHash, models.GroupHashTombstone, models.GroupRelease, models.GroupRuleStatus,
-            models.GroupSeen, models.GroupShare, models.GroupSubscription, models.ProjectBookmark,
-            models.ProjectKey, models.ProjectTeam, models.PromptsActivity, models.SavedSearchUserDefault, models.SavedSearch,
+            models.GroupHash, models.GroupRelease, models.GroupRuleStatus, models.GroupSeen,
+            models.GroupShare, models.GroupSubscription, models.ProjectBookmark, models.ProjectKey,
+            models.ProjectTeam, models.PromptsActivity, models.SavedSearchUserDefault, models.SavedSearch,
             models.ServiceHook, models.UserReport, models.DiscoverSavedQueryProject,
         )
 
diff --git a/src/sentry/models/grouphashtombstone.py b/src/sentry/models/grouphashtombstone.py
index 6ffa44c440..d4a2b4aeed 100644
--- a/src/sentry/models/grouphashtombstone.py
+++ b/src/sentry/models/grouphashtombstone.py
@@ -2,10 +2,9 @@ from __future__ import absolute_import, print_function
 
 import logging
 
-from django.db import models, transaction, IntegrityError
+from django.db import models
 from django.utils import timezone
 
-from sentry.models import GroupHash
 from sentry.db.models import FlexibleForeignKey, Model
 
 
@@ -23,65 +22,3 @@ class GroupHashTombstone(Model):
         app_label = 'sentry'
         db_table = 'sentry_grouphashtombstone'
         unique_together = (('project', 'hash'), )
-
-    @classmethod
-    def tombstone_groups(cls, project_id, group_ids):
-        """\
-        This method adds (or updates) a `GroupHashTombstone` for each `GroupHash`
-        matching the provided groups by:
-
-        * Fetching the `GroupHash`es for the provided set of groups
-        * Updating the `deleted_at` on any existing `GroupHashTombstone`s
-        * Bulk creating any missing `GroupHashTombstone`s
-        * Bulk deleting the `GroupHash`es fetched at the beginning
-        """
-
-        group_hashes = list(
-            GroupHash.objects.filter(
-                project_id=project_id,
-                group__id__in=group_ids,
-            )
-        )
-
-        hashes = [gh.hash for gh in group_hashes]
-        existing_tombstones = list(
-            cls.objects.filter(
-                project_id=project_id,
-                hash__in=hashes,
-            )
-        )
-
-        hashes_to_create = set(hashes)
-        now = timezone.now()
-
-        if existing_tombstones:
-            cls.objects.filter(
-                id__in=[et.id for et in existing_tombstones],
-            ).update(
-                deleted_at=now,
-            )
-
-            hashes_to_create -= set([et.hash for et in existing_tombstones])
-
-        try:
-            with transaction.atomic():
-                cls.objects.bulk_create([
-                    cls(
-                        project_id=project_id,
-                        hash=h,
-                        deleted_at=now,
-                    )
-                    for h in hashes_to_create
-                ])
-        except IntegrityError:
-            logger.error(
-                'grouphashtombstone.tombstone_groups.integrity_error',
-                extra={
-                    'project_id': project_id,
-                    'group_ids': group_ids,
-                    'hashes': hashes_to_create,
-                },
-                exc_info=True
-            )
-
-        GroupHash.objects.filter(id__in=[gh.id for gh in group_hashes]).delete()
diff --git a/src/sentry/runner/commands/cleanup.py b/src/sentry/runner/commands/cleanup.py
index bebe7fd25b..ecfeefb378 100644
--- a/src/sentry/runner/commands/cleanup.py
+++ b/src/sentry/runner/commands/cleanup.py
@@ -78,7 +78,6 @@ def multiprocess_worker(task_queue):
                 models.Group,
                 models.GroupEmailThread,
                 models.GroupRuleStatus,
-                models.GroupHashTombstone,
                 # Handled by TTL
                 similarity.features,
             ] + [b[0] for b in EXTRA_BULK_QUERY_DELETES]
@@ -182,7 +181,6 @@ def cleanup(days, project, concurrency, silent, model, router, timed):
         (models.EventMapping, 'date_added', '-date_added'),
         (models.EventAttachment, 'date_added', None),
         (models.UserReport, 'date_added', None),
-        (models.GroupHashTombstone, 'deleted_at', None),
         (models.GroupEmailThread, 'date', None),
         (models.GroupRuleStatus, 'date_added', None),
     ] + EXTRA_BULK_QUERY_DELETES
diff --git a/tests/sentry/api/endpoints/test_group_details.py b/tests/sentry/api/endpoints/test_group_details.py
index 2a223c8c11..985fbe6f16 100644
--- a/tests/sentry/api/endpoints/test_group_details.py
+++ b/tests/sentry/api/endpoints/test_group_details.py
@@ -8,8 +8,9 @@ from django.utils import timezone
 
 from sentry import tagstore
 from sentry.models import (
-    Activity, Environment, Group, GroupHash, GroupHashTombstone, GroupAssignee, GroupBookmark,
-    GroupResolution, GroupSeen, GroupSnooze, GroupSubscription, GroupStatus, GroupTombstone, Release
+    Activity, Environment, Group, GroupHash, GroupAssignee, GroupBookmark,
+    GroupResolution, GroupSeen, GroupSnooze, GroupSubscription, GroupStatus,
+    GroupTombstone, Release
 )
 from sentry.testutils import APITestCase
 
@@ -495,17 +496,13 @@ class GroupDeleteTest(APITestCase):
 
         url = u'/api/0/issues/{}/'.format(group.id)
 
-        assert not GroupHashTombstone.objects.filter(hash=hash).exists()
-
         response = self.client.delete(url, format='json')
-
         assert response.status_code == 202, response.content
 
         # Deletion was deferred, so it should still exist
         assert Group.objects.get(id=group.id).status == GroupStatus.PENDING_DELETION
         # BUT the hash should be gone
         assert not GroupHash.objects.filter(group_id=group.id).exists()
-        assert GroupHashTombstone.objects.filter(hash=hash).exists()
 
         Group.objects.filter(id=group.id).update(status=GroupStatus.UNRESOLVED)
 
@@ -519,4 +516,3 @@ class GroupDeleteTest(APITestCase):
         # Now we killed everything with fire
         assert not Group.objects.filter(id=group.id).exists()
         assert not GroupHash.objects.filter(group_id=group.id).exists()
-        assert GroupHashTombstone.objects.filter(hash=hash).exists()
diff --git a/tests/sentry/api/endpoints/test_project_group_index.py b/tests/sentry/api/endpoints/test_project_group_index.py
index a31fbe2389..a3bd95785e 100644
--- a/tests/sentry/api/endpoints/test_project_group_index.py
+++ b/tests/sentry/api/endpoints/test_project_group_index.py
@@ -11,7 +11,7 @@ from mock import patch, Mock
 
 from sentry import tagstore
 from sentry.models import (
-    Activity, ApiToken, EventMapping, Group, GroupAssignee, GroupBookmark, GroupHash, GroupHashTombstone,
+    Activity, ApiToken, EventMapping, Group, GroupAssignee, GroupBookmark, GroupHash,
     GroupLink, GroupResolution, GroupSeen, GroupShare, GroupSnooze, GroupStatus, GroupSubscription,
     GroupTombstone, ExternalIssue, Integration, Release, UserOption, OrganizationIntegration
 )
@@ -1620,9 +1620,6 @@ class GroupDeleteTest(APITestCase):
             group4=group4,
         )
 
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set()
-
         response = self.client.delete(url, format='json')
 
         mock_eventstream_api.start_delete_groups.assert_called_once_with(
@@ -1642,9 +1639,6 @@ class GroupDeleteTest(APITestCase):
         assert Group.objects.get(id=group4.id).status != GroupStatus.PENDING_DELETION
         assert GroupHash.objects.filter(group_id=group4.id).exists()
 
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set([hashes[0], hashes[1]])
-
         Group.objects.filter(id__in=(group1.id, group2.id)).update(status=GroupStatus.UNRESOLVED)
 
         with self.tasks():
@@ -1666,9 +1660,6 @@ class GroupDeleteTest(APITestCase):
         assert Group.objects.filter(id=group4.id).exists()
         assert GroupHash.objects.filter(group_id=group4.id).exists()
 
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set([hashes[0], hashes[1]])
-
     def test_bulk_delete(self):
         groups = []
         for i in range(10, 41):
@@ -1690,9 +1681,6 @@ class GroupDeleteTest(APITestCase):
 
         self.login_as(user=self.user)
 
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set()
-
         # if query is '' it defaults to is:unresolved
         url = self.path + '?query='
         response = self.client.delete(url, format='json')
@@ -1703,9 +1691,6 @@ class GroupDeleteTest(APITestCase):
             assert Group.objects.get(id=group.id).status == GroupStatus.PENDING_DELETION
             assert not GroupHash.objects.filter(group_id=group.id).exists()
 
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set(hashes)
-
         Group.objects.filter(
             id__in=[
                 group.id for group in groups]).update(
@@ -1719,6 +1704,3 @@ class GroupDeleteTest(APITestCase):
         for group in groups:
             assert not Group.objects.filter(id=group.id).exists()
             assert not GroupHash.objects.filter(group_id=group.id).exists()
-
-        assert set(GroupHashTombstone.objects.filter(hash__in=hashes).values_list('hash', flat=True)) == \
-            set(hashes)
diff --git a/tests/sentry/models/test_grouphashtombstone.py b/tests/sentry/models/test_grouphashtombstone.py
deleted file mode 100644
index 4b15b156b6..0000000000
--- a/tests/sentry/models/test_grouphashtombstone.py
+++ /dev/null
@@ -1,58 +0,0 @@
-from __future__ import absolute_import
-
-import mock
-from datetime import datetime
-
-from django.utils import timezone
-
-from sentry.models import GroupHash, GroupHashTombstone
-from sentry.testutils import TestCase
-
-
-class GroupHashTombstoneTest(TestCase):
-    @mock.patch('django.utils.timezone.now')
-    def test(self, mock_now):
-        mock_now.return_value = datetime(2010, 1, 1, 0, 0, 0, 0, tzinfo=timezone.utc)
-
-        group = self.group
-
-        hash1 = 'a' * 32
-        GroupHash.objects.create(
-            project=group.project,
-            group=group,
-            hash=hash1,
-        )
-
-        GroupHashTombstone.tombstone_groups(
-            project_id=group.project_id,
-            group_ids=[group.id],
-        )
-
-        assert GroupHashTombstone.objects.filter(hash=hash1, deleted_at=mock_now.return_value).exists()
-        assert not GroupHash.objects.filter(group=group, hash=hash1).exists()
-
-        mock_now.return_value = datetime(2011, 1, 1, 0, 0, 0, 0, tzinfo=timezone.utc)
-
-        # hash1 returns
-        GroupHash.objects.create(
-            project=group.project,
-            group=group,
-            hash=hash1,
-        )
-
-        hash2 = 'b' * 32
-        GroupHash.objects.create(
-            project=group.project,
-            group=group,
-            hash=hash2,
-        )
-
-        GroupHashTombstone.tombstone_groups(
-            project_id=group.project_id,
-            group_ids=[group.id],
-        )
-
-        assert GroupHashTombstone.objects.filter(hash=hash1, deleted_at=mock_now.return_value).exists()
-        assert not GroupHash.objects.filter(group=group, hash=hash1).exists()
-        assert GroupHashTombstone.objects.filter(hash=hash2, deleted_at=mock_now.return_value).exists()
-        assert not GroupHash.objects.filter(group=group, hash=hash2).exists()
diff --git a/tests/snuba/test_snuba.py b/tests/snuba/test_snuba.py
index 3d61e0140d..68e424069d 100644
--- a/tests/snuba/test_snuba.py
+++ b/tests/snuba/test_snuba.py
@@ -5,8 +5,6 @@ import pytest
 import time
 import uuid
 
-from sentry import options
-from sentry.models import GroupHash, GroupHashTombstone
 from sentry.testutils import SnubaTestCase
 from sentry.utils import snuba
 
@@ -64,67 +62,6 @@ class SnubaTest(SnubaTestCase):
                 groupby=[")("],
             )
 
-    def test_project_issues_with_tombstones(self):
-        # Nothing to be done if we're using `group_id`.
-        # When this option is the default we can remove
-        # this test.
-        if options.get('snuba.use_group_id_column'):
-            return
-
-        base_time = datetime.utcnow()
-        hash = 'a' * 32
-
-        def _query_for_issue(group_id):
-            return snuba.query(
-                start=base_time - timedelta(days=1),
-                end=base_time + timedelta(days=1),
-                groupby=['issue'],
-                filter_keys={
-                    'project_id': [self.project.id],
-                    'issue': [group_id]
-                },
-            )
-
-        group1 = self.create_group()
-        group2 = self.create_group()
-
-        GroupHash.objects.create(
-            project=self.project,
-            group=group1,
-            hash=hash
-        )
-        assert snuba.get_project_issues([self.project], [group1.id]) == \
-            [(group1.id, group1.project_id, [('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', None)])]
-
-        # 1 event in the groups, no deletes have happened
-        self._insert_event_for_time(base_time, hash)
-        assert _query_for_issue(group1.id) == {group1.id: 1}
-
-        # group is deleted and then returns (as a new group with the same hash)
-        GroupHashTombstone.tombstone_groups(self.project.id, [group1.id])
-
-        ght = GroupHashTombstone.objects.get(project_id=self.project.id)
-        assert ght
-
-        GroupHash.objects.create(
-            project=self.project,
-            group=group2,
-            hash=hash,
-        )
-
-        # tombstone time is returned as expected
-        assert snuba.get_project_issues([self.project], [group2.id]) == \
-            [(group2.id, group2.project_id, [('aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
-                                              ght.deleted_at.strftime("%Y-%m-%d %H:%M:%S"))])]
-
-        # events <= to the tombstone date aren't returned
-        self._insert_event_for_time(ght.deleted_at, hash)
-        assert _query_for_issue(group2.id) == {}
-
-        # only the event > than the tombstone date is returned
-        self._insert_event_for_time(ght.deleted_at + timedelta(seconds=1), hash)
-        assert _query_for_issue(group2.id) == {group2.id: 1}
-
     def test_organization_retention_respected(self):
         base_time = datetime.utcnow()
 
