commit aec5cabf98c779260dc02c84acc40ca8f4c54512
Author: Markus Unterwaditzer <markus@unterwaditzer.net>
Date:   Wed Nov 27 18:18:16 2019 +0100

    ref(ingest_consumer): Inject project object (#15850)

diff --git a/src/sentry/ingest/ingest_consumer.py b/src/sentry/ingest/ingest_consumer.py
index 4d2cc6d9a3..737ca34ed2 100644
--- a/src/sentry/ingest/ingest_consumer.py
+++ b/src/sentry/ingest/ingest_consumer.py
@@ -79,7 +79,13 @@ class IngestConsumerWorker(AbstractBatchWorker):
         # Preprocess this event, which spawns either process_event or
         # save_event. Pass data explicitly to avoid fetching it again from the
         # cache.
-        preprocess_event(cache_key=cache_key, data=data, start_time=start_time, event_id=event_id)
+        preprocess_event(
+            cache_key=cache_key,
+            data=data,
+            start_time=start_time,
+            event_id=event_id,
+            project=project,
+        )
 
         # remember for an 1 hour that we saved this event (deduplication protection)
         cache.set(deduplication_key, "", 3600)
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index aff6e5083f..3d92bdeb0f 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -90,7 +90,7 @@ def submit_save_event(project, cache_key, event_id, start_time, data):
     )
 
 
-def _do_preprocess_event(cache_key, data, start_time, event_id, process_task):
+def _do_preprocess_event(cache_key, data, start_time, event_id, process_task, project):
     if cache_key and data is None:
         data = default_cache.get(cache_key)
 
@@ -106,7 +106,10 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_task):
     with configure_scope() as scope:
         scope.set_tag("project", project_id)
 
-    project = Project.objects.get_from_cache(id=project_id)
+    if project is None:
+        project = Project.objects.get_from_cache(id=project_id)
+    else:
+        assert project.id == project_id, (project.id, project_id)
 
     if should_process(data):
         from_reprocessing = process_task is process_event_from_reprocessing
@@ -122,8 +125,17 @@ def _do_preprocess_event(cache_key, data, start_time, event_id, process_task):
     time_limit=65,
     soft_time_limit=60,
 )
-def preprocess_event(cache_key=None, data=None, start_time=None, event_id=None, **kwargs):
-    return _do_preprocess_event(cache_key, data, start_time, event_id, process_event)
+def preprocess_event(
+    cache_key=None, data=None, start_time=None, event_id=None, project=None, **kwargs
+):
+    return _do_preprocess_event(
+        cache_key=cache_key,
+        data=data,
+        start_time=start_time,
+        event_id=event_id,
+        process_task=process_event,
+        project=project,
+    )
 
 
 @instrumented_task(
@@ -133,10 +145,15 @@ def preprocess_event(cache_key=None, data=None, start_time=None, event_id=None,
     soft_time_limit=60,
 )
 def preprocess_event_from_reprocessing(
-    cache_key=None, data=None, start_time=None, event_id=None, **kwargs
+    cache_key=None, data=None, start_time=None, event_id=None, project=None, **kwargs
 ):
     return _do_preprocess_event(
-        cache_key, data, start_time, event_id, process_event_from_reprocessing
+        cache_key=cache_key,
+        data=data,
+        start_time=start_time,
+        event_id=event_id,
+        process_task=process_event,
+        project=project,
     )
 
 
diff --git a/tests/sentry/ingest/test_ingest_consumer.py b/tests/sentry/ingest/test_ingest_consumer.py
index 28588111ac..fad53bb758 100644
--- a/tests/sentry/ingest/test_ingest_consumer.py
+++ b/tests/sentry/ingest/test_ingest_consumer.py
@@ -43,7 +43,7 @@ def _get_test_message(project):
         "ty": (0, ()),
         "start_time": time.time(),
         "event_id": event_id,
-        "project_id": 1,
+        "project_id": int(project_id),
         "payload": json.dumps(normalized_event),
     }
 
