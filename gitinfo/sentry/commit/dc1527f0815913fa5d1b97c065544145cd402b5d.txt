commit dc1527f0815913fa5d1b97c065544145cd402b5d
Author: ted kaemming <ted@kaemming.com>
Date:   Thu Feb 21 13:56:19 2019 -0800

    ref(eventstream): Rename "relay" to "post-process-forwarder" (#12140)

diff --git a/src/sentry/eventstream/base.py b/src/sentry/eventstream/base.py
index 97df031d4e..b1a3b01e49 100644
--- a/src/sentry/eventstream/base.py
+++ b/src/sentry/eventstream/base.py
@@ -9,9 +9,9 @@ from sentry.tasks.post_process import post_process_group
 logger = logging.getLogger(__name__)
 
 
-class RelayNotRequired(NotImplementedError):
+class ForwarderNotRequired(NotImplementedError):
     """
-    Exception raised if this backend does not require a relay process to
+    Exception raised if this backend does not require a forwarder process to
     enqueue post-processing tasks.
     """
 
@@ -27,7 +27,7 @@ class EventStream(Service):
         'end_unmerge',
         'start_delete_tag',
         'end_delete_tag',
-        'relay',
+        'run_post_process_forwarder',
     )
 
     def insert(self, group, event, is_new, is_sample, is_regression,
@@ -63,12 +63,12 @@ class EventStream(Service):
     def end_unmerge(self, state):
         pass
 
-    def relay(self, consumer_group, commit_log_topic,
-              synchronize_commit_group, commit_batch_size=100, initial_offset_reset='latest'):
-        raise RelayNotRequired
-
     def start_delete_tag(self, project_id, tag):
         pass
 
     def end_delete_tag(self, state):
         pass
+
+    def run_post_process_forwarder(self, consumer_group, commit_log_topic,
+                                   synchronize_commit_group, commit_batch_size=100, initial_offset_reset='latest'):
+        raise ForwarderNotRequired
diff --git a/src/sentry/eventstream/kafka/backend.py b/src/sentry/eventstream/kafka/backend.py
index 296386d62c..ac813a0938 100644
--- a/src/sentry/eventstream/kafka/backend.py
+++ b/src/sentry/eventstream/kafka/backend.py
@@ -22,7 +22,7 @@ logger = logging.getLogger(__name__)
 
 # Beware! Changing this protocol (introducing a new version, or the message
 # format/fields themselves) requires consideration of all downstream consumers.
-# This includes the post-processing relay code!
+# This includes the post-process forwarder code!
 EVENT_PROTOCOL_VERSION = 2
 
 # Version 1 format: (1, TYPE, [...REST...])
@@ -291,9 +291,9 @@ class KafkaEventStream(EventStream):
             asynchronous=False
         )
 
-    def relay(self, consumer_group, commit_log_topic,
-              synchronize_commit_group, commit_batch_size=100, initial_offset_reset='latest'):
-        logger.debug('Starting relay...')
+    def run_post_process_forwarder(self, consumer_group, commit_log_topic,
+                                   synchronize_commit_group, commit_batch_size=100, initial_offset_reset='latest'):
+        logger.debug('Starting post-process forwarder...')
 
         consumer = SynchronizedConsumer(
             bootstrap_servers=self.producer_configuration['bootstrap.servers'],
diff --git a/src/sentry/runner/commands/run.py b/src/sentry/runner/commands/run.py
index c9328375bb..088f526eec 100644
--- a/src/sentry/runner/commands/run.py
+++ b/src/sentry/runner/commands/run.py
@@ -253,32 +253,45 @@ def cron(**options):
         ).run()
 
 
-@run.command()
-@click.option('--consumer-group', default='snuba-post-processor',
-              help='Consumer group used to track event offsets that have been enqueued for post-processing.')
-@click.option('--commit-log-topic', default='snuba-commit-log',
-              help='Topic that the Snuba writer is publishing its committed offsets to.')
-@click.option('--synchronize-commit-group', default='snuba-consumers',
-              help='Consumer group that the Snuba writer is committing its offset as.')
-@click.option('--commit-batch-size', default=1000, type=int,
-              help='How many messages to process (may or may not result in an enqueued task) before committing offsets.')
-@click.option('--initial-offset-reset', default='latest', type=click.Choice(['earliest', 'latest']),
-              help='Position in the commit log topic to begin reading from when no prior offset has been recorded.')
-@log_options()
-@configuration
-def relay(**options):
-    from sentry import eventstream
-    from sentry.eventstream.base import RelayNotRequired
-    try:
-        eventstream.relay(
-            consumer_group=options['consumer_group'],
-            commit_log_topic=options['commit_log_topic'],
-            synchronize_commit_group=options['synchronize_commit_group'],
-            commit_batch_size=options['commit_batch_size'],
-            initial_offset_reset=options['initial_offset_reset'],
-        )
-    except RelayNotRequired:
-        sys.stdout.write(
-            'The configured event stream backend does not need a relay '
-            'process to enqueue post-processing tasks. Exiting...\n')
-        return
+def _make_forwarder_command():
+    # XXX: Calling ``run.command`` mutates the option specifications for some
+    # reason that I don't care to identify (they only get picked up for the
+    # first registered command), so we have to create two distinct instances of
+    # this function for the temporary "relay" alas to work correctly. After the
+    # alias is removed, this hack can be removed and the task function can be
+    # defined at module level like everything else is normally.
+
+    @click.option('--consumer-group', default='snuba-post-processor',
+                  help='Consumer group used to track event offsets that have been enqueued for post-processing.')
+    @click.option('--commit-log-topic', default='snuba-commit-log',
+                  help='Topic that the Snuba writer is publishing its committed offsets to.')
+    @click.option('--synchronize-commit-group', default='snuba-consumers',
+                  help='Consumer group that the Snuba writer is committing its offset as.')
+    @click.option('--commit-batch-size', default=1000, type=int,
+                  help='How many messages to process (may or may not result in an enqueued task) before committing offsets.')
+    @click.option('--initial-offset-reset', default='latest', type=click.Choice(['earliest', 'latest']),
+                  help='Position in the commit log topic to begin reading from when no prior offset has been recorded.')
+    @log_options()
+    @configuration
+    def post_process_forwarder(**options):
+        from sentry import eventstream
+        from sentry.eventstream.base import ForwarderNotRequired
+        try:
+            eventstream.run_post_process_forwarder(
+                consumer_group=options['consumer_group'],
+                commit_log_topic=options['commit_log_topic'],
+                synchronize_commit_group=options['synchronize_commit_group'],
+                commit_batch_size=options['commit_batch_size'],
+                initial_offset_reset=options['initial_offset_reset'],
+            )
+        except ForwarderNotRequired:
+            sys.stdout.write(
+                'The configured event stream backend does not need a forwarder '
+                'process to enqueue post-process tasks. Exiting...\n')
+            return
+
+    return post_process_forwarder
+
+
+run.command('relay')(_make_forwarder_command())  # temporary alias for compatibility
+run.command('post-process-forwarder')(_make_forwarder_command())
