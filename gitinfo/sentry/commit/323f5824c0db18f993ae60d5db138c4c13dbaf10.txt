commit 323f5824c0db18f993ae60d5db138c4c13dbaf10
Author: evanh <evanh@users.noreply.github.com>
Date:   Tue Jan 21 12:59:19 2020 -0500

    feat(discover2) Change field aliases to be parameterless functions (#16540)
    
    Change the field aliases (p95 etc) to support parameterless functions to better show
    to the user that they are not simple fields. Follow up PR to change this on the frontend as well.

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 57c4dccf72..4f32066787 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -109,7 +109,7 @@ rel_time_filter      = search_key sep rel_date_format
 # exact time filter for dates
 specific_time_filter = search_key sep date_format
 # Numeric comparison filter
-numeric_filter       = search_key sep operator? numeric_value
+numeric_filter       = (function_key / search_key) sep operator? numeric_value
 # Aggregate numeric filter
 aggregate_filter        = aggregate_key sep operator? numeric_value
 aggregate_date_filter   = aggregate_key sep operator? (date_format / rel_date_format)
@@ -119,7 +119,8 @@ has_filter           = negation? "has" sep (search_key / search_value)
 is_filter            = negation? "is" sep search_value
 tag_filter           = negation? "tags[" search_key "]" sep search_value
 
-aggregate_key        = key open_paren key closed_paren
+aggregate_key        = key space? open_paren space? key space? closed_paren
+function_key         = key space? open_paren space? closed_paren
 search_key           = key / quoted_key
 search_value         = quoted_value / value
 value                = ~r"[^()\s]*"
@@ -361,6 +362,7 @@ class SearchVisitor(NodeVisitor):
 
     def visit_numeric_filter(self, node, children):
         (search_key, _, operator, search_value) = children
+        search_key = search_key[0] if not isinstance(search_key, Node) else search_key
         operator = operator[0] if not isinstance(operator, Node) else "="
 
         if search_key.name in self.numeric_keys:
@@ -508,9 +510,24 @@ class SearchVisitor(NodeVisitor):
         return SearchKey(self.key_mappings_lookup.get(key, key))
 
     def visit_aggregate_key(self, node, children):
+        children = self.flatten(children)
+        children = self.remove_optional_nodes(children)
+        children = self.remove_space(children)
+
         key = "".join(children)
         return AggregateKey(self.key_mappings_lookup.get(key, key))
 
+    def visit_function_key(self, node, children):
+        children = self.flatten(children)
+        children = self.remove_optional_nodes(children)
+        children = self.remove_space(children)
+
+        key = "".join(children)
+        if key.strip("()") in FIELD_ALIASES:
+            key = key.strip("()")
+
+        return SearchKey(self.key_mappings_lookup.get(key, key))
+
     def visit_search_value(self, node, children):
         return SearchValue(children[0])
 
@@ -891,8 +908,9 @@ def resolve_field(field):
     if not isinstance(field, six.string_types):
         raise InvalidSearchQuery("Field names must be strings")
 
-    if field in FIELD_ALIASES:
-        special_field = deepcopy(FIELD_ALIASES[field])
+    sans_parens = field.strip("()")
+    if sans_parens in FIELD_ALIASES:
+        special_field = deepcopy(FIELD_ALIASES[sans_parens])
         return (special_field.get("fields", []), special_field.get("aggregations", []))
 
     # Basic fields don't require additional validation. They could be tag
@@ -935,8 +953,8 @@ def resolve_field_list(fields, snuba_args, auto_fields=True):
             fields.append("project.id")
 
     aggregations = []
-    groupby = []
     columns = []
+    groupby = []
     for field in fields:
         column_additions, agg_additions = resolve_field(field)
         if column_additions:
@@ -957,7 +975,7 @@ def resolve_field_list(fields, snuba_args, auto_fields=True):
             columns.append("id")
         if not aggregations and "project.id" not in columns:
             columns.append("project.id")
-        if aggregations and "latest_event" not in fields:
+        if aggregations and "latest_event" not in map(lambda a: a[-1], aggregations):
             aggregations.extend(deepcopy(FIELD_ALIASES["latest_event"]["aggregations"]))
         if aggregations and "project.id" not in columns:
             aggregations.append(["argMax", ["project.id", "timestamp"], "projectid"])
diff --git a/src/sentry/static/sentry/app/views/eventsV2/data.tsx b/src/sentry/static/sentry/app/views/eventsV2/data.tsx
index 88403402b9..d1e288a4ae 100644
--- a/src/sentry/static/sentry/app/views/eventsV2/data.tsx
+++ b/src/sentry/static/sentry/app/views/eventsV2/data.tsx
@@ -50,8 +50,8 @@ export const TRANSACTION_VIEWS: Readonly<Array<NewQuery>> = [
       'project',
       'count(id)',
       'avg(transaction.duration)',
-      'p75',
-      'p95',
+      'p75()',
+      'p95()',
     ],
     orderby: '-count_id',
     query: 'event.type:transaction',
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index e412c53eff..d8488eaced 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1130,6 +1130,37 @@ class ResolveFieldListTest(unittest.TestCase):
         ]
         assert result["groupby"] == []
 
+    def test_field_alias_duration_expansion_with_brackets(self):
+        fields = [
+            "avg(transaction.duration)",
+            "latest_event()",
+            "last_seen()",
+            "apdex()",
+            "impact()",
+            "p75()",
+            "p95()",
+            "p99()",
+        ]
+        result = resolve_field_list(fields, {})
+
+        assert result["selected_columns"] == []
+        assert result["aggregations"] == [
+            ["avg", "transaction.duration", "avg_transaction_duration"],
+            ["argMax", ["id", "timestamp"], "latest_event"],
+            ["max", "timestamp", "last_seen"],
+            ["apdex(duration, 300)", None, "apdex"],
+            [
+                "(1 - ((countIf(duration < 300) + (countIf((duration > 300) AND (duration < 1200)) / 2)) / count())) + ((1 - 1 / sqrt(uniq(user))) * 3)",
+                None,
+                "impact",
+            ],
+            ["quantile(0.75)(duration)", None, "p75"],
+            ["quantile(0.95)(duration)", None, "p95"],
+            ["quantile(0.99)(duration)", None, "p99"],
+            ["argMax", ["project.id", "timestamp"], "projectid"],
+        ]
+        assert result["groupby"] == []
+
     def test_field_alias_expansion(self):
         fields = ["title", "last_seen", "latest_event", "project", "user", "message"]
         result = resolve_field_list(fields, {})
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index 8c2dbd1904..85f1f564a5 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -349,6 +349,39 @@ class QueryTransformTest(TestCase):
             referrer=None,
         )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_selected_columns_aggregate_alias_with_brackets(self, mock_query):
+        mock_query.return_value = {
+            "meta": [{"name": "transaction"}, {"name": "p95()"}],
+            "data": [{"transaction": "api.do_things", "p95()": 200}],
+        }
+        discover.query(
+            selected_columns=["transaction", "p95()", "count_unique(transaction)"],
+            query="",
+            params={"project_id": [self.project.id]},
+            auto_fields=True,
+        )
+        mock_query.assert_called_with(
+            selected_columns=["transaction"],
+            aggregations=[
+                ["quantile(0.95)(duration)", None, "p95"],
+                ["uniq", "transaction", "count_unique_transaction"],
+                ["argMax", ["event_id", "timestamp"], "latest_event"],
+                ["argMax", ["project_id", "timestamp"], "projectid"],
+            ],
+            filter_keys={"project_id": [self.project.id]},
+            dataset=Dataset.Discover,
+            groupby=["transaction"],
+            conditions=[],
+            end=None,
+            start=None,
+            orderby=None,
+            having=[],
+            limit=50,
+            offset=None,
+            referrer=None,
+        )
+
     @patch("sentry.snuba.discover.raw_query")
     def test_orderby_limit_offset(self, mock_query):
         mock_query.return_value = {
@@ -659,6 +692,36 @@ class QueryTransformTest(TestCase):
             referrer=None,
         )
 
+    @patch("sentry.snuba.discover.raw_query")
+    def test_alias_aggregate_conditions_with_brackets(self, mock_query):
+        mock_query.return_value = {
+            "meta": [{"name": "transaction"}, {"name": "duration"}],
+            "data": [{"transaction": "api.do_things", "duration": 200}],
+        }
+        start_time = before_now(minutes=10)
+        end_time = before_now(seconds=1)
+        discover.query(
+            selected_columns=["transaction", "p95()"],
+            query="http.method:GET p95():>5",
+            params={"project_id": [self.project.id], "start": start_time, "end": end_time},
+        )
+
+        mock_query.assert_called_with(
+            selected_columns=["transaction"],
+            conditions=[["http_method", "=", "GET"]],
+            filter_keys={"project_id": [self.project.id]},
+            groupby=["transaction"],
+            dataset=Dataset.Discover,
+            aggregations=[["quantile(0.95)(duration)", None, "p95"]],
+            having=[["p95", ">", 5]],
+            end=end_time,
+            start=start_time,
+            orderby=None,
+            limit=50,
+            offset=None,
+            referrer=None,
+        )
+
     @patch("sentry.snuba.discover.raw_query")
     def test_aggregate_date_conditions(self, mock_query):
         mock_query.return_value = {
@@ -795,6 +858,19 @@ class TimeseriesQueryTest(SnubaTestCase, TestCase):
         )
         assert len(result.data["data"]) == 3
 
+    def test_field_alias_with_brackets(self):
+        result = discover.timeseries_query(
+            selected_columns=["p95()"],
+            query="event.type:transaction transaction:api.issue.delete",
+            params={
+                "start": self.day_ago,
+                "end": self.day_ago + timedelta(hours=2),
+                "project_id": [self.project.id],
+            },
+            rollup=3600,
+        )
+        assert len(result.data["data"]) == 3
+
     def test_aggregate_function(self):
         result = discover.timeseries_query(
             selected_columns=["count()"],
diff --git a/tests/snuba/api/endpoints/test_organization_events_v2.py b/tests/snuba/api/endpoints/test_organization_events_v2.py
index e99208a9bf..01e435b007 100644
--- a/tests/snuba/api/endpoints/test_organization_events_v2.py
+++ b/tests/snuba/api/endpoints/test_organization_events_v2.py
@@ -421,6 +421,38 @@ class OrganizationEventsV2EndpointTest(APITestCase, SnubaTestCase):
         assert data[0]["transaction"] == event.transaction
         assert data[0]["p95"] == 3000
 
+    def test_aggregation_alias_comparison_with_brackets(self):
+        self.login_as(user=self.user)
+        project = self.create_project()
+        data = load_data("transaction")
+        data["transaction"] = "/aggregates/1"
+        data["timestamp"] = iso_format(before_now(minutes=1))
+        data["start_timestamp"] = iso_format(before_now(minutes=1, seconds=5))
+        self.store_event(data, project_id=project.id)
+
+        data = load_data("transaction")
+        data["transaction"] = "/aggregates/2"
+        data["timestamp"] = iso_format(before_now(minutes=1))
+        data["start_timestamp"] = iso_format(before_now(minutes=1, seconds=3))
+        event = self.store_event(data, project_id=project.id)
+
+        with self.feature("organizations:events-v2"):
+            response = self.client.get(
+                self.url,
+                format="json",
+                data={
+                    "field": ["transaction", "p95()"],
+                    "query": "event.type:transaction p95():<4000",
+                    "orderby": ["transaction"],
+                },
+            )
+
+        assert response.status_code == 200, response.content
+        assert len(response.data["data"]) == 1
+        data = response.data["data"]
+        assert data[0]["transaction"] == event.transaction
+        assert data[0]["p95"] == 3000
+
     def test_aggregation_comparison_with_conditions(self):
         self.login_as(user=self.user)
         project = self.create_project()
