commit 0f600d86646a4d6a51390634121d4004e01f41c3
Author: Markus Unterwaditzer <markus@unterwaditzer.net>
Date:   Fri Feb 15 12:08:15 2019 +0100

    ref: Remove python normalizer (#12068)
    
    * wip
    
    * wip
    
    * test: Enable rust in snuba
    
    * fix: Use SnubaCompatibilityTagStorage for storing events
    
    * fix: Fix test_organization_group_index
    
    * fix: Fix test_organization_events
    
    * fix: Fix test_group_tags
    
    * fix: Fix test_group_events
    
    * fix: Fix test_group
    
    * ref: Remove Python normalization code
    
    * ref: Remove unused stuff from src/sentry/constants.py
    
    * ref: Add new option for sampling interface changes
    
    * ref: Bump semaphore version
    
    * fix: Bump semaphore
    
    * fix: Fix mysql fuzziness
    
    * fix: Fix crash serializing broken exception

diff --git a/.travis.yml b/.travis.yml
index 2effadbea8..bb5091a153 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -88,20 +88,6 @@ matrix:
       before_script:
         - psql -c 'create database sentry;' -U postgres
 
-    - python: 2.7
-      env:
-        - TEST_SUITE=postgres DB=postgres
-        - SENTRY_USE_RUST_NORMALIZER=true
-      services:
-        - memcached
-        - redis-server
-        - postgresql
-      install:
-        - python setup.py install_egg_info
-        - pip install -e ".[dev,tests,optional]"
-      before_script:
-        - psql -c 'create database sentry;' -U postgres
-
     - python: 2.7
       env: TEST_SUITE=mysql DB=mysql
       services:
diff --git a/requirements-base.txt b/requirements-base.txt
index 2b2529294a..8d473a2124 100644
--- a/requirements-base.txt
+++ b/requirements-base.txt
@@ -55,7 +55,7 @@ redis>=2.10.3,<2.10.6
 requests-oauthlib==0.3.3
 requests[security]>=2.20.0,<2.21.0
 selenium==3.11.0
-semaphore>=0.4.11,<0.5.0
+semaphore>=0.4.15,<0.5.0
 sentry-sdk>=0.7.0
 setproctitle>=1.1.7,<1.2.0
 simplejson>=3.2.0,<3.9.0
diff --git a/src/sentry/constants.py b/src/sentry/constants.py
index 27cee35729..84462b8cc3 100644
--- a/src/sentry/constants.py
+++ b/src/sentry/constants.py
@@ -123,9 +123,10 @@ DEFAULT_ALERT_GROUP_THRESHOLD = (1000, 25)  # 1000%, 25 events
 DEFAULT_SORT_OPTION = 'date'
 
 # Setup languages for only available locales
-LANGUAGE_MAP = dict(settings.LANGUAGES)
-LANGUAGES = [(k, LANGUAGE_MAP[k])
-             for k in get_all_languages() if k in LANGUAGE_MAP]
+_language_map = dict(settings.LANGUAGES)
+LANGUAGES = [(k, _language_map[k])
+             for k in get_all_languages() if k in _language_map]
+del _language_map
 
 # TODO(dcramer): We eventually want to make this user-editable
 TAG_LABELS = {
@@ -163,22 +164,6 @@ SENTRY_RULES = (
 HTTP_METHODS = ('GET', 'POST', 'PUT', 'OPTIONS', 'HEAD',
                 'DELETE', 'TRACE', 'CONNECT', 'PATCH')
 
-CLIENT_RESERVED_ATTRS = (
-    'project', 'errors', 'event_id', 'message', 'checksum', 'culprit', 'fingerprint', 'level',
-    'time_spent', 'logger', 'server_name', 'site', 'received', 'timestamp', 'extra', 'modules',
-    'tags', 'platform', 'release', 'dist', 'environment', 'transaction', '_meta',
-)
-
-# Deprecated or internal attributes that should be dropped silently
-CLIENT_IGNORED_ATTRS = (
-    # Internal attributes
-    'hashes', 'metadata', 'type', 'key_id', 'project', 'received',
-    # Derived attributes
-    'title', 'location',
-    # Deprecated attributes
-    'applecrashreport', 'device', 'repos', 'query',
-)
-
 # XXX: Must be all lowercase
 DEFAULT_SCRUBBED_FIELDS = (
     'password', 'secret', 'passwd', 'api_key', 'apikey', 'access_token', 'auth', 'credentials',
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index dcd4c04ab4..88fecbe537 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -7,9 +7,7 @@ sentry.event_manager
 from __future__ import absolute_import, print_function
 
 import logging
-import os
 import six
-import random
 import jsonschema
 
 from datetime import datetime, timedelta
@@ -17,14 +15,11 @@ from django.conf import settings
 from django.db import connection, IntegrityError, router, transaction
 from django.utils import timezone
 from django.utils.encoding import force_text
-from django.utils.functional import cached_property
-from sentry import options
 
 from sentry import buffer, eventtypes, eventstream, features, tagstore, tsdb, filters
 from sentry.constants import (
-    CLIENT_RESERVED_ATTRS, LOG_LEVELS, LOG_LEVELS_MAP, DEFAULT_LOG_LEVEL,
-    DEFAULT_LOGGER_NAME, MAX_CULPRIT_LENGTH, VALID_PLATFORMS, MAX_TAG_VALUE_LENGTH,
-    CLIENT_IGNORED_ATTRS,
+    LOG_LEVELS, LOG_LEVELS_MAP, MAX_CULPRIT_LENGTH, VALID_PLATFORMS,
+    MAX_TAG_VALUE_LENGTH,
 )
 from sentry.coreapi import (
     APIError,
@@ -35,10 +30,7 @@ from sentry.coreapi import (
     decode_data,
     safely_load_json_string,
 )
-from sentry.interfaces.base import get_interface, prune_empty_keys
-from sentry.interfaces.exception import normalize_mechanism_meta
-from sentry.interfaces.schemas import validate_and_default_interface
-from sentry.lang.native.utils import get_sdk_from_event
+from sentry.interfaces.base import get_interface
 from sentry.models import (
     Activity, Environment, Event, EventError, EventMapping, EventUser, Group,
     GroupEnvironment, GroupHash, GroupLink, GroupRelease, GroupResolution, GroupStatus,
@@ -59,8 +51,7 @@ from sentry.utils.data_filters import (
 )
 from sentry.utils.dates import to_timestamp
 from sentry.utils.db import is_postgres, is_mysql
-from sentry.utils.meta import Meta
-from sentry.utils.safe import ENABLE_TRIMMING, safe_execute, trim, trim_dict, get_path, set_path, setdefault_path
+from sentry.utils.safe import safe_execute, trim, get_path, setdefault_path
 from sentry.utils.strings import truncatechars
 from sentry.utils.geo import rust_geoip
 from sentry.utils.validators import is_float
@@ -81,8 +72,6 @@ SECURITY_REPORT_INTERFACES = (
     "expectstaple",
 )
 
-ENABLE_RUST = os.environ.get("SENTRY_USE_RUST_NORMALIZER", "false").lower() in ("1", "true")
-
 
 def pop_tag(data, key):
     data['tags'] = [kv for kv in data['tags'] if kv is None or kv[0] != key]
@@ -454,26 +443,9 @@ class EventManager(object):
 
         self._data = data
 
-    @cached_property
-    def use_rust_normalize(self):
-        if self._project is not None:
-            if self._project.id in options.get('store.projects-normalize-in-rust-opt-out'):
-                return False
-            if self._project.id in options.get('store.projects-normalize-in-rust-opt-in'):
-                return True
-            opt_in_rate = options.get('store.projects-normalize-in-rust-percent-opt-in')
-            if opt_in_rate != 0:
-                if opt_in_rate > 0.0:
-                    bucket = ((self._project.id * 2654435761) % (2 ** 32)) % 1000
-                    return bucket <= (opt_in_rate * 1000)
-                else:
-                    return random.random() < -opt_in_rate
-
-        return ENABLE_RUST
-
     def normalize(self):
         tags = {
-            'use_rust_normalize': six.text_type(self.use_rust_normalize)
+            'use_rust_normalize': True
         }
 
         with metrics.timer('events.store.normalize.duration', tags=tags):
@@ -481,7 +453,7 @@ class EventManager(object):
 
         data = self.get_data()
 
-        data['use_rust_normalize'] = self.use_rust_normalize
+        data['use_rust_normalize'] = True
 
         metrics.timing(
             'events.store.normalize.errors',
@@ -494,247 +466,27 @@ class EventManager(object):
             raise RuntimeError('Already normalized')
         self._normalized = True
 
-        if self.use_rust_normalize:
-            from semaphore.processing import StoreNormalizer
-            rust_normalizer = StoreNormalizer(
-                geoip_lookup=rust_geoip,
-                project_id=self._project.id if self._project else None,
-                client_ip=self._client_ip,
-                client=self._auth.client if self._auth else None,
-                key_id=six.text_type(self._key.id) if self._key else None,
-                protocol_version=six.text_type(self.version) if self.version is not None else None,
-                stacktrace_frames_hard_limit=settings.SENTRY_STACKTRACE_FRAMES_HARD_LIMIT,
-                max_stacktrace_frames=settings.SENTRY_MAX_STACKTRACE_FRAMES,
-                valid_platforms=list(VALID_PLATFORMS),
-                max_secs_in_future=MAX_SECS_IN_FUTURE,
-                max_secs_in_past=MAX_SECS_IN_PAST,
-                enable_trimming=ENABLE_TRIMMING,
-            )
-
-            self._data = CanonicalKeyDict(
-                rust_normalizer.normalize_event(dict(self._data))
-            )
-
-            normalize_user_agent(self._data)
-            return
-
-        data = self._data
-
-        # Before validating with a schema, attempt to cast values to their desired types
-        # so that the schema doesn't have to take every type variation into account.
-        text = six.text_type
-
-        def to_values(v):
-            return {'values': v} if v and isinstance(v, (tuple, list)) else v
-
-        casts = {
-            'environment': lambda v: text(v) if v is not None else v,
-            'event_id': lambda v: v.lower(),
-            'fingerprint': cast_fingerprint,
-            'release': lambda v: text(v) if v is not None else v,
-            'dist': lambda v: text(v).strip() if v is not None else v,
-            'time_spent': lambda v: int(v) if v is not None else v,
-            'tags': lambda v: [(text(v_k).replace(' ', '-').strip(), text(v_v).strip()) for (v_k, v_v) in dict(v).items()],
-            'platform': lambda v: v if v in VALID_PLATFORMS else 'other',
-            'logentry': lambda v: {'message': v} if (v and not isinstance(v, dict)) else (v or None),
-
-            # These can be sent as lists and need to be converted to {'values': [...]}
-            'exception': to_values,
-            'breadcrumbs': to_values,
-            'threads': to_values,
-        }
-
-        meta = Meta(data.get('_meta'))
-
-        for c in casts:
-            value = data.pop(c, None)
-            if value is not None:
-                try:
-                    data[c] = casts[c](value)
-                except Exception as e:
-                    meta.enter(c).add_error(EventError.INVALID_DATA, value, {
-                        'reason': six.text_type(e),
-                    })
-
-        data['timestamp'] = process_timestamp(data.get('timestamp'),
-                                              meta.enter('timestamp'))
-
-        # Fill in ip addresses marked as {{auto}}
-        if self._client_ip:
-            if get_path(data, 'request', 'env', 'REMOTE_ADDR') == '{{auto}}':
-                data['request']['env']['REMOTE_ADDR'] = self._client_ip
-
-            if get_path(data, 'user', 'ip_address') == '{{auto}}':
-                data['user']['ip_address'] = self._client_ip
-
-        # Validate main event body and tags against schema.
-        # XXX(ja): jsonschema does not like CanonicalKeyDict, so we need to pass
-        #          in the inner data dict.
-        validate_and_default_interface(data.data, 'event', meta=meta)
-        if data.get('tags') is not None:
-            validate_and_default_interface(
-                data['tags'], 'tags', name='tags', meta=meta.enter('tags'))
-
-        # Validate interfaces
-        for k in list(iter(data)):
-            if k in CLIENT_RESERVED_ATTRS:
-                continue
-
-            value = data.pop(k)
+        from semaphore.processing import StoreNormalizer
+        rust_normalizer = StoreNormalizer(
+            geoip_lookup=rust_geoip,
+            project_id=self._project.id if self._project else None,
+            client_ip=self._client_ip,
+            client=self._auth.client if self._auth else None,
+            key_id=six.text_type(self._key.id) if self._key else None,
+            protocol_version=six.text_type(self.version) if self.version is not None else None,
+            stacktrace_frames_hard_limit=settings.SENTRY_STACKTRACE_FRAMES_HARD_LIMIT,
+            max_stacktrace_frames=settings.SENTRY_MAX_STACKTRACE_FRAMES,
+            valid_platforms=list(VALID_PLATFORMS),
+            max_secs_in_future=MAX_SECS_IN_FUTURE,
+            max_secs_in_past=MAX_SECS_IN_PAST,
+            enable_trimming=True,
+        )
 
-            # Ignore all top-level None and empty values, regardless whether
-            # they are interfaces or not. For all other unrecognized attributes,
-            # we emit an explicit error, unless they are explicitly ignored.
-            if not value or k in CLIENT_IGNORED_ATTRS:
-                continue
+        self._data = CanonicalKeyDict(
+            rust_normalizer.normalize_event(dict(self._data))
+        )
 
-            try:
-                interface = get_interface(k)
-            except ValueError:
-                logger.debug('Ignored unknown attribute: %s', k)
-                meta.enter(k).add_error(EventError.INVALID_ATTRIBUTE)
-                continue
-
-            normalized = interface.normalize(value, meta.enter(k))
-            if normalized:
-                data[interface.path] = normalized
-
-        # Additional data coercion and defaulting we only do for store.
-        if self._for_store:
-            if self._project is not None:
-                data['project'] = self._project.id
-            if self._key is not None:
-                data['key_id'] = self._key.id
-            if self._auth is not None:
-                data['sdk'] = data.get('sdk') or parse_client_as_sdk(self._auth.client)
-
-            level = data.get('level') or DEFAULT_LOG_LEVEL
-            if isinstance(level, int) or (isinstance(level, six.string_types) and level.isdigit()):
-                level = LOG_LEVELS.get(int(level), DEFAULT_LOG_LEVEL)
-            if level not in LOG_LEVELS_MAP:
-                level = DEFAULT_LOG_LEVEL
-            data['level'] = level
-
-            if data.get('dist') and not data.get('release'):
-                data['dist'] = None
-
-            timestamp = data.get('timestamp')
-            if not timestamp:
-                timestamp = timezone.now()
-
-            # TODO (alex) can this all be replaced by utcnow?
-            # it looks like the only time that this would even be hit is when timestamp
-            # is not defined, as the earlier process_timestamp already converts existing
-            # timestamps to floats.
-            if isinstance(timestamp, datetime):
-                # We must convert date to local time so Django doesn't mess it up
-                # based on TIME_ZONE
-                if settings.TIME_ZONE:
-                    if not timezone.is_aware(timestamp):
-                        timestamp = timestamp.replace(tzinfo=timezone.utc)
-                elif timezone.is_aware(timestamp):
-                    timestamp = timestamp.replace(tzinfo=None)
-                timestamp = float(timestamp.strftime('%s'))
-
-            data['timestamp'] = timestamp
-            data['received'] = float(timezone.now().strftime('%s'))
-
-            setdefault_path(data, 'extra', value={})
-            setdefault_path(data, 'logger', value=DEFAULT_LOGGER_NAME)
-            setdefault_path(data, 'tags', value=[])
-
-            # Fix case where legacy apps pass 'environment' as a tag
-            # instead of a top level key.
-            # TODO (alex) save() just reinserts the environment into the tags
-            # TODO (markus) silly conversion between list and dict, hard to fix
-            # without messing up meta
-            tagsdict = dict(data['tags'])
-            environment_tag = tagsdict.pop("environment", None)
-            if not data.get('environment') and environment_tag:
-                data['environment'] = environment_tag
-            data['tags'] = tagsdict.items()
-
-            # the SDKs currently do not describe event types, and we must infer
-            # them from available attributes
-            data['type'] = eventtypes.infer(data).key
-            data['version'] = self.version
-
-        exceptions = get_path(data, 'exception', 'values', filter=True)
-        stacktrace = data.get('stacktrace')
-        if stacktrace and exceptions and len(exceptions) == 1:
-            exceptions[0]['stacktrace'] = stacktrace
-            stacktrace_meta = meta.enter('stacktrace')
-            meta.enter('exception', 'values', 0, 'stacktrace').merge(stacktrace_meta)
-            del data['stacktrace']
-            # TODO(ja): Remove meta data of data['stacktrace'] here, too
-
-        # Exception mechanism needs SDK information to resolve proper names in
-        # exception meta (such as signal names). "SDK Information" really means
-        # the operating system version the event was generated on. Some
-        # normalization still works without sdk_info, such as mach_exception
-        # names (they can only occur on macOS).
-        if exceptions:
-            sdk_info = get_sdk_from_event(data)
-            for ex in exceptions:
-                if 'mechanism' in ex:
-                    normalize_mechanism_meta(ex['mechanism'], sdk_info)
-
-        # This function parses the User Agent from the request if present and fills
-        # contexts with it.
-        normalize_user_agent(data)
-
-        if not get_path(data, "user", "ip_address"):
-            # If there is no User ip_address, update it either from the Http
-            # interface or the client_ip of the request.
-            http_ip = get_path(data, 'request', 'env', 'REMOTE_ADDR')
-            if http_ip:
-                set_path(data, 'user', 'ip_address', value=http_ip)
-            elif self._client_ip:
-                set_path(data, 'user', 'ip_address', value=self._client_ip)
-
-        # Trim values
-        if data.get('logger'):
-            data['logger'] = trim(data['logger'].strip(), 64)
-
-        if data.get('extra'):
-            trim_dict(data['extra'], max_size=settings.SENTRY_MAX_EXTRA_VARIABLE_SIZE)
-
-        if data.get('culprit'):
-            data['culprit'] = trim(data['culprit'], MAX_CULPRIT_LENGTH)
-
-        if data.get('transaction'):
-            # XXX: This will be trimmed again when inserted into tag values
-            data['transaction'] = trim(data['transaction'], MAX_CULPRIT_LENGTH)
-
-        # Move some legacy data into tags
-        site = data.pop('site', None)
-        if site is not None:
-            set_tag(data, 'site', site)
-        server_name = data.pop('server_name', None)
-        if server_name is not None:
-            set_tag(data, 'server_name', server_name)
-
-        for key in ('fingerprint', 'modules', 'tags', 'extra', 'contexts'):
-            if not data.get(key):
-                data.pop(key, None)
-
-        # Merge meta errors into the errors array. We need to iterate over the
-        # raw meta instead of data due to pruned null values.
-        errors = data.get('errors') or []
-        add_meta_errors(errors, meta)
-        add_meta_errors(errors, meta.enter('tags'))
-
-        if errors:
-            data['errors'] = errors
-        elif 'errors' in data:
-            del data['errors']
-
-        if meta.raw():
-            data['_meta'] = meta.raw()
-        elif '_meta' in data:
-            del data['_meta']
-
-        self._data = CanonicalKeyDict(prune_empty_keys(data))
+        normalize_user_agent(self._data)
 
     def should_filter(self):
         '''
diff --git a/src/sentry/interfaces/exception.py b/src/sentry/interfaces/exception.py
index 34368aa063..7cf56e76dd 100644
--- a/src/sentry/interfaces/exception.py
+++ b/src/sentry/interfaces/exception.py
@@ -1081,7 +1081,8 @@ class Exception(Interface):
         values = meta.get('values', meta)
         for index, value in six.iteritems(values):
             exc = self.values[int(index)]
-            result[index] = exc.get_api_meta(value, is_public=is_public)
+            if exc is not None:
+                result[index] = exc.get_api_meta(value, is_public=is_public)
 
         return {'values': result}
 
diff --git a/src/sentry/management/commands/serve_normalize.py b/src/sentry/management/commands/serve_normalize.py
index 8a2d363ef1..177ad31d99 100644
--- a/src/sentry/management/commands/serve_normalize.py
+++ b/src/sentry/management/commands/serve_normalize.py
@@ -168,10 +168,6 @@ class EventNormalizeHandler(SocketServer.BaseRequestHandler):
         self.request.close()
 
     def handle_data(self):
-        from sentry.event_manager import ENABLE_RUST
-        if not ENABLE_RUST:
-            return handle_data(self.data)
-
         @catch_errors
         def inner():
             # TODO: Remove this contraption once we no longer get segfaults
diff --git a/src/sentry/options/defaults.py b/src/sentry/options/defaults.py
index 8cfb5b579e..87f260075e 100644
--- a/src/sentry/options/defaults.py
+++ b/src/sentry/options/defaults.py
@@ -58,7 +58,11 @@ register(
 register('redis.options', type=Dict, flags=FLAG_NOSTORE)
 
 # symbolizer specifics
-register('dsym.cache-path', type=String, default='/tmp/sentry-dsym-cache', flags=FLAG_PRIORITIZE_DISK)
+register(
+    'dsym.cache-path',
+    type=String,
+    default='/tmp/sentry-dsym-cache',
+    flags=FLAG_PRIORITIZE_DISK)
 
 # Mail
 register('mail.backend', default='smtp', flags=FLAG_NOSTORE)
@@ -153,8 +157,11 @@ register('kafka-publisher.raw-event-sample-rate', default=0.0)
 register('kafka-publisher.max-event-size', default=100000)
 
 # Ingest refactor
-register('store.projects-normalize-in-rust-opt-in', type=Sequence, default=[])
-register('store.projects-normalize-in-rust-opt-out', type=Sequence, default=[])
+register('store.projects-normalize-in-rust-opt-in', type=Sequence, default=[])  # unused
+register('store.projects-normalize-in-rust-opt-out', type=Sequence, default=[])  # unused
 # positive value means stable opt-in in the range 0.0 to 1.0, negative value
 # means random opt-in with the same range.
-register('store.projects-normalize-in-rust-percent-opt-in', default=0.0)
+register('store.projects-normalize-in-rust-percent-opt-in', default=0.0)  # unused
+
+# From 0.0 to 1.0: Randomly disable normalization code in interfaces when loading from db
+register('store.empty-interface-sample-rate', default=0.0)
diff --git a/src/sentry/testutils/cases.py b/src/sentry/testutils/cases.py
index c64904346d..f7c1e299a9 100644
--- a/src/sentry/testutils/cases.py
+++ b/src/sentry/testutils/cases.py
@@ -17,6 +17,7 @@ __all__ = (
 
 import base64
 import calendar
+import contextlib
 import os
 import os.path
 import pytest
@@ -24,6 +25,7 @@ import requests
 import six
 import types
 import logging
+import mock
 
 from sentry_sdk import Hub
 
@@ -54,6 +56,7 @@ from sentry.auth.superuser import (
     COOKIE_SECURE as SU_COOKIE_SECURE, COOKIE_DOMAIN as SU_COOKIE_DOMAIN, COOKIE_PATH as SU_COOKIE_PATH
 )
 from sentry.constants import MODULE_ROOT
+from sentry.eventstream.snuba import SnubaEventStream
 from sentry.models import (
     GroupEnvironment, GroupHash, GroupMeta, ProjectOption, Repository, DeletedOrganization,
     Environment, GroupStatus, Organization, TotpInterface, UserReport,
@@ -61,6 +64,7 @@ from sentry.models import (
 )
 from sentry.plugins import plugins
 from sentry.rules import EventState
+from sentry.tagstore.snuba import SnubaCompatibilityTagStorage
 from sentry.utils import json
 from sentry.utils.auth import SSO_SESSION_KEY
 
@@ -844,9 +848,23 @@ class IntegrationTestCase(TestCase):
 class SnubaTestCase(TestCase):
     def setUp(self):
         super(SnubaTestCase, self).setUp()
-
+        self.snuba_eventstream = SnubaEventStream()
+        self.snuba_tagstore = SnubaCompatibilityTagStorage()
         assert requests.post(settings.SENTRY_SNUBA + '/tests/drop').status_code == 200
 
+    def store_event(self, *args, **kwargs):
+        with contextlib.nested(
+            mock.patch('sentry.eventstream.insert',
+                       self.snuba_eventstream.insert),
+            mock.patch('sentry.tagstore.delay_index_event_tags',
+                       self.snuba_tagstore.delay_index_event_tags),
+            mock.patch('sentry.tagstore.incr_tag_value_times_seen',
+                       self.snuba_tagstore.incr_tag_value_times_seen),
+            mock.patch('sentry.tagstore.incr_group_tag_value_times_seen',
+                       self.snuba_tagstore.incr_group_tag_value_times_seen),
+        ):
+            return super(SnubaTestCase, self).store_event(*args, **kwargs)
+
     def __wrap_event(self, event, data, primary_hash):
         # TODO: Abstract and combine this with the stream code in
         #       getsentry once it is merged, so that we don't alter one
@@ -872,6 +890,8 @@ class SnubaTestCase(TestCase):
         doesn't run them through the 'real' event pipeline. In a perfect
         world all test events would go through the full regular pipeline.
         """
+        # XXX: Use `store_event` instead of this!
+
         event = super(SnubaTestCase, self).create_event(*args, **kwargs)
 
         data = event.data.data
diff --git a/src/sentry/utils/safe.py b/src/sentry/utils/safe.py
index 52bfde5d11..cec7ca959c 100644
--- a/src/sentry/utils/safe.py
+++ b/src/sentry/utils/safe.py
@@ -7,7 +7,6 @@ sentry.utils.safe
 """
 from __future__ import absolute_import, print_function
 
-import os
 import collections
 import logging
 import six
@@ -20,9 +19,6 @@ from sentry.utils import json
 from sentry.utils.strings import truncatechars
 
 
-ENABLE_TRIMMING = os.environ.get("SENTRY_RUST_ENABLE_TRIMMING", "true") == "true"
-
-
 def safe_execute(func, *args, **kwargs):
     # TODO: we should make smart savepoints (only executing the savepoint server
     # side if we execute a query)
@@ -69,7 +65,7 @@ def trim(
         '_depth': _depth + 1,
     }
 
-    if _depth > max_depth and ENABLE_TRIMMING:
+    if _depth > max_depth:
         if not isinstance(value, six.string_types):
             value = json.dumps(value)
         return trim(value, _size=_size, max_size=max_size)
@@ -82,7 +78,7 @@ def trim(
             trim_v = trim(v, _size=_size, **options)
             result[k] = trim_v
             _size += len(force_text(trim_v)) + 1
-            if _size >= max_size and ENABLE_TRIMMING:
+            if _size >= max_size:
                 break
 
     elif isinstance(value, (list, tuple)):
@@ -92,12 +88,12 @@ def trim(
             trim_v = trim(v, _size=_size, **options)
             result.append(trim_v)
             _size += len(force_text(trim_v))
-            if _size >= max_size and ENABLE_TRIMMING:
+            if _size >= max_size:
                 break
         if isinstance(value, tuple):
             result = tuple(result)
 
-    elif isinstance(value, six.string_types) and ENABLE_TRIMMING:
+    elif isinstance(value, six.string_types):
         result = truncatechars(value, max_size - _size)
 
     else:
@@ -114,7 +110,7 @@ def trim_pairs(iterable, max_items=settings.SENTRY_MAX_DICTIONARY_ITEMS, **kwarg
     for idx, item in enumerate(iterable):
         key, value = item
         result.append((key, trim(value, **kwargs)))
-        if idx > max_items and ENABLE_TRIMMING:
+        if idx > max_items:
             return result
     return result
 
@@ -123,7 +119,7 @@ def trim_dict(value, max_items=settings.SENTRY_MAX_DICTIONARY_ITEMS, **kwargs):
     max_items -= 1
     for idx, key in enumerate(list(iter(value))):
         value[key] = trim(value[key], **kwargs)
-        if idx > max_items and ENABLE_TRIMMING:
+        if idx > max_items:
             del value[key]
     return value
 
diff --git a/tests/sentry/event_manager/test_event_manager.py b/tests/sentry/event_manager/test_event_manager.py
index 0b630b121b..e5fe45fa88 100644
--- a/tests/sentry/event_manager/test_event_manager.py
+++ b/tests/sentry/event_manager/test_event_manager.py
@@ -14,7 +14,7 @@ from time import time
 
 from sentry.app import tsdb
 from sentry.constants import VERSION_LENGTH
-from sentry.event_manager import HashDiscarded, EventManager, EventUser, ENABLE_RUST
+from sentry.event_manager import HashDiscarded, EventManager, EventUser
 from sentry.event_hashing import md5_from_hash
 from sentry.models import (
     Activity, Environment, Event, ExternalIssue, Group, GroupEnvironment,
@@ -611,8 +611,13 @@ class EventManagerTest(TransactionTestCase):
         assert event.group_id == event2.group_id
 
         group = Group.objects.get(id=event.group.id)
-        assert group.active_at == event2.datetime
-        assert group.active_at != event.datetime
+        # MySQL removes sub-second portion
+        assert group.active_at.replace(
+            second=0, microsecond=0) == event2.datetime.replace(
+            second=0, microsecond=0)
+        assert group.active_at.replace(
+            second=0, microsecond=0) != event.datetime.replace(
+            second=0, microsecond=0)
 
     def test_invalid_transaction(self):
         dict_input = {'messages': 'foo'}
@@ -903,8 +908,7 @@ class EventManagerTest(TransactionTestCase):
             'tags': [42],
         }))
         manager.normalize()
-        if ENABLE_RUST:
-            assert None in manager.get_data().get('tags', [])
+        assert None in manager.get_data().get('tags', [])
         assert 42 not in manager.get_data().get('tags', [])
         event = manager.save(self.project.id)
         assert 42 not in event.tags
@@ -1135,12 +1139,8 @@ class EventManagerTest(TransactionTestCase):
         manager.normalize()
         event = manager.save(self.project.id)
 
-        if ENABLE_RUST:
-            assert event.message == '["asdf"]'
-            assert 'logentry' in event.data
-        else:
-            assert event.message == '<unlabeled event>'
-            assert 'logentry' not in event.data
+        assert event.message == '["asdf"]'
+        assert 'logentry' in event.data
 
     def test_message_attribute_goes_to_interface(self):
         manager = EventManager(make_event(**{
diff --git a/tests/sentry/event_manager/test_normalization.py b/tests/sentry/event_manager/test_normalization.py
index 4ef4718a1a..30d4e1dcdb 100644
--- a/tests/sentry/event_manager/test_normalization.py
+++ b/tests/sentry/event_manager/test_normalization.py
@@ -8,7 +8,7 @@ from datetime import datetime
 from django.conf import settings
 
 from sentry.constants import MAX_CULPRIT_LENGTH, DEFAULT_LOGGER_NAME
-from sentry.event_manager import EventManager, ENABLE_RUST
+from sentry.event_manager import EventManager
 
 
 def make_event(**kwargs):
@@ -29,10 +29,7 @@ def test_tags_as_list():
     manager.normalize()
     data = manager.get_data()
 
-    if ENABLE_RUST:
-        assert data['tags'] == [['foo', 'bar']]
-    else:
-        assert data['tags'] == [('foo', 'bar')]
+    assert data['tags'] == [['foo', 'bar']]
 
 
 def test_tags_as_dict():
@@ -40,10 +37,7 @@ def test_tags_as_dict():
     manager.normalize()
     data = manager.get_data()
 
-    if ENABLE_RUST:
-        assert data['tags'] == [['foo', 'bar']]
-    else:
-        assert data['tags'] == [('foo', 'bar')]
+    assert data['tags'] == [['foo', 'bar']]
 
 
 def test_interface_is_relabeled():
@@ -74,35 +68,6 @@ def test_does_default_ip_address_to_user(user):
     assert data['user']['ip_address'] == '127.0.0.1'
 
 
-@mock.patch('sentry.interfaces.geo.Geo.from_ip_address')
-@pytest.mark.skipif(
-    ENABLE_RUST, reason="geoip is tested in semaphore repo, mock doesnt work for rust")
-def test_does_geo_from_ip(from_ip_address_mock):
-    from sentry.interfaces.geo import Geo
-
-    geo = {
-        'city': 'San Francisco',
-        'country_code': 'US',
-        'region': 'CA',
-    }
-    from_ip_address_mock.return_value = Geo.to_python(geo)
-
-    manager = EventManager(
-        make_event(
-            **{
-                'user': {
-                    'ip_address': '192.168.0.1',
-                },
-            }
-        )
-    )
-
-    manager.normalize()
-    data = manager.get_data()
-    assert data['user']['ip_address'] == '192.168.0.1'
-    assert data['user']['geo'] == geo
-
-
 @mock.patch('sentry.interfaces.geo.geo_by_addr')
 def test_skips_geo_with_no_result(geo_by_addr_mock):
     geo_by_addr_mock.return_value = None
@@ -162,9 +127,7 @@ def test_long_transaction():
 
 
 def test_long_message():
-    allowance = 0
-    if ENABLE_RUST:
-        allowance = 200
+    allowance = 200
     manager = EventManager(
         make_event(
             message='x' * (settings.SENTRY_MAX_MESSAGE_LENGTH + 1 + allowance),
@@ -207,8 +170,6 @@ def test_logger():
     manager.normalize()
     data = manager.get_data()
     assert data['logger'] == DEFAULT_LOGGER_NAME
-    if not ENABLE_RUST:
-        assert not any(e.get('name') == 'logger' for e in data.get('errors', []))
 
 
 def test_moves_stacktrace_to_exception():
@@ -291,25 +252,6 @@ def test_event_id_lowercase():
     assert data['event_id'] == '1234abcd' * 4
 
 
-@pytest.mark.parametrize('key', [
-    'fingerprint', 'modules', 'user', 'request', 'contexts',
-    'breadcrumbs', 'exception', 'stacktrace', 'threads', 'tags',
-    'extra', 'debug_meta', 'sdk', 'repos'
-])
-@pytest.mark.parametrize('value', [{}, [], None])
-def test_removes_some_empty_interfaces(key, value):
-    if ENABLE_RUST and value is not None:
-        # TODO(markus)
-        pytest.skip("Removing empty hashes not yet aligned with Rust")
-    event = make_event()
-    event[key] = value
-
-    manager = EventManager(event)
-    manager.normalize()
-    data = manager.get_data()
-    assert data.get(key) is None
-
-
 @pytest.mark.parametrize('key', ['applecrashreport', 'device', 'repos', 'query'])
 def test_deprecated_attrs(key):
     event = make_event()
diff --git a/tests/sentry/event_manager/test_validate_csp.py b/tests/sentry/event_manager/test_validate_csp.py
index e3fa5ef5dd..e461e6831c 100644
--- a/tests/sentry/event_manager/test_validate_csp.py
+++ b/tests/sentry/event_manager/test_validate_csp.py
@@ -3,7 +3,7 @@ from __future__ import absolute_import
 import pytest
 
 from sentry.coreapi import APIError
-from sentry.event_manager import EventManager, ENABLE_RUST
+from sentry.event_manager import EventManager
 
 
 def validate_and_normalize(report, client_ip='198.51.100.0',
@@ -81,10 +81,7 @@ def test_csp_tags_out_of_bounds():
         }
     }
     result = validate_and_normalize(report)
-    if ENABLE_RUST:
-        assert result['tags'] == [['effective-directive', 'img-src'], None]
-    else:
-        assert result['tags'] == [('effective-directive', 'img-src')]
+    assert result['tags'] == [['effective-directive', 'img-src'], None]
     assert len(result['errors']) == 1
 
 
@@ -138,10 +135,7 @@ def test_hpkp_validate_basic():
         ('port', '443'),
     ]
     assert result['user'] == {'ip_address': '198.51.100.0'}
-    if ENABLE_RUST:
-        expected_headers = [['User-Agent', 'Awesome Browser']]
-    else:
-        expected_headers = [('User-Agent', 'Awesome Browser')]
+    expected_headers = [['User-Agent', 'Awesome Browser']]
 
     assert result['request'] == {
         'url': 'www.example.com',
diff --git a/tests/sentry/event_manager/test_validate_data.py b/tests/sentry/event_manager/test_validate_data.py
index 1a100a307f..cd14aab5b3 100644
--- a/tests/sentry/event_manager/test_validate_data.py
+++ b/tests/sentry/event_manager/test_validate_data.py
@@ -5,7 +5,7 @@ import pytest
 from datetime import datetime, timedelta
 
 from sentry.constants import VERSION_LENGTH, MAX_CULPRIT_LENGTH
-from sentry.event_manager import EventManager, ENABLE_RUST
+from sentry.event_manager import EventManager
 
 
 def validate_and_normalize(data):
@@ -47,10 +47,7 @@ def test_invalid_event_id():
     data = validate_and_normalize({"event_id": "a" * 33})
     assert len(data["event_id"]) == 32
     assert len(data["errors"]) == 1
-    if ENABLE_RUST:
-        assert data["errors"][0]["type"] == "invalid_data"
-    else:
-        assert data["errors"][0]["type"] == "value_too_long"
+    assert data["errors"][0]["type"] == "invalid_data"
     assert data["errors"][0]["name"] == "event_id"
     assert data["errors"][0]["value"] == "a" * 33
 
@@ -64,10 +61,7 @@ def test_invalid_event_id():
 
 def test_unknown_attribute():
     data = validate_and_normalize({"message": "foo", "foo": "bar"})
-    if ENABLE_RUST:
-        assert data['foo'] is None
-    else:
-        assert "foo" not in data
+    assert data['foo'] is None
     assert len(data["errors"]) == 1
     assert data["errors"][0]["type"] == "invalid_attribute"
     assert data["errors"][0]["name"] == "foo"
@@ -75,10 +69,7 @@ def test_unknown_attribute():
 
 def test_invalid_interface_name():
     data = validate_and_normalize({"message": "foo", "foo.baz": "bar"})
-    if ENABLE_RUST:
-        assert data["foo.baz"] is None
-    else:
-        assert "foo.baz" not in data
+    assert data["foo.baz"] is None
     assert len(data["errors"]) == 1
     assert data["errors"][0]["type"] == "invalid_attribute"
     assert data["errors"][0]["name"] == "foo.baz"
@@ -88,10 +79,7 @@ def test_invalid_interface_import_path():
     data = validate_and_normalize(
         {"message": "foo", "exception2": "bar"}
     )
-    if ENABLE_RUST:
-        assert data['exception2'] is None
-    else:
-        assert "exception2" not in data
+    assert data['exception2'] is None
 
     assert len(data["errors"]) == 1
     assert data["errors"][0]["type"] == "invalid_attribute"
@@ -131,18 +119,12 @@ def test_invalid_log_level():
 
 def test_tags_as_string():
     data = validate_and_normalize({"message": "foo", "tags": "bar"})
-    if ENABLE_RUST:
-        assert data['tags'] == []
-    else:
-        assert "tags" not in data
+    assert data['tags'] == []
 
 
 def test_tags_with_spaces():
     data = validate_and_normalize({"message": "foo", "tags": {"foo bar": "baz bar"}})
-    if ENABLE_RUST:
-        assert data["tags"] == [["foo-bar", "baz bar"]]
-    else:
-        assert data["tags"] == [("foo-bar", "baz bar")]
+    assert data["tags"] == [["foo-bar", "baz bar"]]
 
 
 def test_tags_out_of_bounds():
@@ -152,10 +134,7 @@ def test_tags_out_of_bounds():
             "tags": {"f" * 33: "value", "foo": "v" * 201, "bar": "value"},
         }
     )
-    if ENABLE_RUST:
-        assert data["tags"] == [["bar", "value"], None, None]
-    else:
-        assert data["tags"] == [("bar", "value")]
+    assert data["tags"] == [["bar", "value"], None, None]
     assert len(data["errors"]) == 2
 
 
@@ -165,54 +144,32 @@ def test_tags_as_invalid_pair():
     )
     assert len(data["errors"]) == 1
     assert data["errors"][0]["type"] == "invalid_data"
-    if ENABLE_RUST:
-        assert data["errors"][0]["name"] == "tags.1"
-        assert data["errors"][0]["value"] == ["biz", "baz", "boz"]
-    else:
-        assert data["errors"][0]["name"] == "tags"
-        assert data["errors"][0]["value"] == [("foo", "bar"), ("biz", "baz", "boz")]
+    assert data["errors"][0]["name"] == "tags.1"
+    assert data["errors"][0]["value"] == ["biz", "baz", "boz"]
 
 
 def test_reserved_tags():
     data = validate_and_normalize(
         {"message": "foo", "tags": [("foo", "bar"), ("release", "abc123")]}
     )
-    if ENABLE_RUST:
-        assert data["tags"] == [["foo", "bar"]]
-    else:
-        assert data["tags"] == [("foo", "bar")]
-
-        assert len(data["errors"]) == 1
-        assert data["errors"][0]["type"] == "invalid_data"
-        assert data["errors"][0]["name"] == "tags.0"
-        assert data["errors"][0]["value"] == ("release", "abc123")
+    assert data["tags"] == [["foo", "bar"]]
 
 
 def test_tag_value():
     data = validate_and_normalize(
         {"message": "foo", "tags": [("foo", "b\nar"), ("biz", "baz")]}
     )
-    if ENABLE_RUST:
-        assert data["tags"] == [["foo", None], ["biz", "baz"]]
-    else:
-        assert data["tags"] == [("biz", "baz")]
+    assert data["tags"] == [["foo", None], ["biz", "baz"]]
 
     assert len(data["errors"]) == 1
     assert data["errors"][0]["type"] == "invalid_data"
-    if ENABLE_RUST:
-        assert data["errors"][0]["name"] == "tags.0.1"
-        assert data["errors"][0]["value"] == "b\nar"
-    else:
-        assert data["errors"][0]["name"] == "tags.0"
-        assert data["errors"][0]["value"] == ("foo", "b\nar")
+    assert data["errors"][0]["name"] == "tags.0.1"
+    assert data["errors"][0]["value"] == "b\nar"
 
 
 def test_extra_as_string():
     data = validate_and_normalize({"message": "foo", "extra": "bar"})
-    if ENABLE_RUST:
-        assert data['extra'] == {}
-    else:
-        assert 'extra' not in data
+    assert data['extra'] == {}
 
 
 def test_release_tag_max_len():
@@ -222,52 +179,26 @@ def test_release_tag_max_len():
         {"message": "foo", "tags": [[release_key, release_value]]}
     )
     assert "errors" not in data
-    if ENABLE_RUST:
-        assert data["tags"] == [[release_key, release_value]]
-    else:
-        assert data["tags"] == [(release_key, release_value)]
+    assert data["tags"] == [[release_key, release_value]]
 
 
 def test_server_name_too_long():
     key = u"server_name"
     value = "a" * (MAX_CULPRIT_LENGTH + 1)
     data = validate_and_normalize({key: value})
-    if ENABLE_RUST:
-        assert len(dict(data['tags']).get(key)) == MAX_CULPRIT_LENGTH
-    else:
-        assert not data.get(key)
-        assert not dict(data.get('tags') or ()).get(key)
-        assert len(data["errors"]) == 1
-        assert data["errors"][0]["type"] == "value_too_long"
-        assert data["errors"][0]["name"] == key
-        assert data["errors"][0]["value"] == value
+    assert len(dict(data['tags']).get(key)) == MAX_CULPRIT_LENGTH
 
 
 def test_site_too_long():
     key = u"site"
     value = "a" * (MAX_CULPRIT_LENGTH + 1)
     data = validate_and_normalize({key: value})
-    if ENABLE_RUST:
-        assert len(dict(data['tags']).get(key)) == MAX_CULPRIT_LENGTH
-    else:
-        assert not data.get(key)
-        assert not dict(data.get('tags') or ()).get(key)
-        assert len(data["errors"]) == 1
-        assert data["errors"][0]["type"] == "value_too_long"
-        assert data["errors"][0]["name"] == key
-        assert data["errors"][0]["value"] == value
+    assert len(dict(data['tags']).get(key)) == MAX_CULPRIT_LENGTH
 
 
 def test_release_too_long():
     data = validate_and_normalize({"release": "a" * (VERSION_LENGTH + 1)})
-    if ENABLE_RUST:
-        assert len(data.get("release")) == VERSION_LENGTH
-    else:
-        assert not data.get("release")
-        assert len(data["errors"]) == 1
-        assert data["errors"][0]["type"] == "value_too_long"
-        assert data["errors"][0]["name"] == "release"
-        assert data["errors"][0]["value"] == "a" * (VERSION_LENGTH + 1)
+    assert len(data.get("release")) == VERSION_LENGTH
 
 
 def test_release_as_non_string():
@@ -276,20 +207,10 @@ def test_release_as_non_string():
 
 
 def test_distribution_too_long():
-    if ENABLE_RUST:
-        dist_len = 201
-    else:
-        dist_len = 65
+    dist_len = 201
     data = validate_and_normalize({"release": "a" * 62, "dist": "b" * dist_len})
 
-    if ENABLE_RUST:
-        assert len(data.get("dist")) == dist_len - 1
-    else:
-        assert not data.get("dist")
-        assert len(data["errors"]) == 1
-        assert data["errors"][0]["type"] == "value_too_long"
-        assert data["errors"][0]["name"] == "dist"
-        assert data["errors"][0]["value"] == "b" * dist_len
+    assert len(data.get("dist")) == dist_len - 1
 
 
 def test_distribution_bad_char():
@@ -309,10 +230,7 @@ def test_distribution_strip():
 def test_distribution_as_non_string():
     data = validate_and_normalize({"release": "42", "dist": 23})
     assert data.get("release") == "42"
-    if ENABLE_RUST:
-        assert data.get("dist") is None
-    else:
-        assert data.get("dist") == "23"
+    assert data.get("dist") is None
 
 
 def test_distribution_no_release():
@@ -335,24 +253,16 @@ def test_invalid_platform():
     assert data.get("platform") == "other"
 
 
-@pytest.mark.skipif(ENABLE_RUST, reason='Rust allows larger environment')
 def test_environment_too_long():
     data = validate_and_normalize({"environment": "a" * 65})
-    assert not data.get("environment")
-    assert len(data["errors"]) == 1
-    assert data["errors"][0]["type"] == "value_too_long"
-    assert data["errors"][0]["name"] == "environment"
-    assert data["errors"][0]["value"] == "a" * 65
+    assert len(data['environment']) == 64
 
 
 def test_environment_invalid():
     data = validate_and_normalize({"environment": "a/b"})
     assert not data.get("environment")
     error, = data['errors']
-    if ENABLE_RUST:
-        error['type'] == 'invalid_data'
-    else:
-        error['type'] == 'invalid_environment'
+    error['type'] == 'invalid_data'
 
     assert error["name"] == "environment"
     assert error["value"] == "a/b"
@@ -360,20 +270,12 @@ def test_environment_invalid():
 
 def test_environment_as_non_string():
     data = validate_and_normalize({"environment": 42})
-    if ENABLE_RUST:
-        assert data.get("environment") is None
-    else:
-        assert data.get("environment") == "42"
+    assert data.get("environment") is None
 
 
-@pytest.mark.skipif(ENABLE_RUST, reason='attribute is not validated in Rust')
 def test_time_spent_too_large():
     data = validate_and_normalize({"time_spent": 2147483647 + 1})
-    assert not data.get("time_spent")
-    assert len(data["errors"]) == 1
-    assert data["errors"][0]["type"] == "value_too_long"
-    assert data["errors"][0]["name"] == "time_spent"
-    assert data["errors"][0]["value"] == 2147483647 + 1
+    assert data.get("time_spent") is None
 
 
 def test_time_spent_invalid():
@@ -387,10 +289,7 @@ def test_time_spent_invalid():
 
 def test_time_spent_non_int():
     data = validate_and_normalize({"time_spent": "123"})
-    if ENABLE_RUST:
-        assert data["time_spent"] is None
-    else:
-        assert data["time_spent"] == 123
+    assert data["time_spent"] is None
 
 
 def test_fingerprints():
@@ -415,11 +314,8 @@ def test_fingerprints():
 
     data = validate_and_normalize({"fingerprint": ["{{default}}", 1e100, -1e100, 1e10]})
     assert data.get("fingerprint") == ["{{default}}", "10000000000"]
-    if ENABLE_RUST:
-        assert data["errors"] == [{'type': 'invalid_data',
-                                   'name': 'fingerprint', 'value': [1e100, -1e100]}]
-    else:
-        assert "errors" not in data
+    assert data["errors"] == [{'type': 'invalid_data',
+                               'name': 'fingerprint', 'value': [1e100, -1e100]}]
 
     data = validate_and_normalize({"fingerprint": []})
     assert "fingerprint" not in data
diff --git a/tests/sentry/web/api/tests.py b/tests/sentry/web/api/tests.py
index 0a7fef6294..6b78da4d08 100644
--- a/tests/sentry/web/api/tests.py
+++ b/tests/sentry/web/api/tests.py
@@ -14,7 +14,6 @@ from sentry.signals import event_accepted, event_dropped, event_filtered
 from sentry.testutils import (assert_mock_called_once_with_partial, TestCase)
 from sentry.utils import json
 from sentry.utils.data_filters import FilterTypes
-from sentry.event_manager import ENABLE_RUST
 
 
 class SecurityReportCspTest(TestCase):
@@ -465,20 +464,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['lol'],
-                'foo': ['1'],
-                'bar': ['2'],
-                'baz': ['3']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': 'lol',
-                'foo': '1',
-                'bar': '2',
-                'baz': '3'
-            }
+        assert call_data['request']['data'] == {
+            'password': 'lol',
+            'foo': '1',
+            'bar': '2',
+            'baz': '3'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_scrub_data_on(self, mock_insert_data_to_database):
@@ -499,20 +490,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['lol'],
-                'foo': ['1'],
-                'bar': ['2'],
-                'baz': ['3']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': 'lol',
-                'foo': '1',
-                'bar': '2',
-                'baz': '3'
-            }
+        assert call_data['request']['data'] == {
+            'password': 'lol',
+            'foo': '1',
+            'bar': '2',
+            'baz': '3'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_scrub_data_defaults(self, mock_insert_data_to_database):
@@ -533,20 +516,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['[Filtered]'],
-                'foo': ['1'],
-                'bar': ['2'],
-                'baz': ['3']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': '[Filtered]',
-                'foo': '1',
-                'bar': '2',
-                'baz': '3'
-            }
+        assert call_data['request']['data'] == {
+            'password': '[Filtered]',
+            'foo': '1',
+            'bar': '2',
+            'baz': '3'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_scrub_data_sensitive_fields(self, mock_insert_data_to_database):
@@ -568,20 +543,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['[Filtered]'],
-                'foo': ['[Filtered]'],
-                'bar': ['[Filtered]'],
-                'baz': ['3']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': '[Filtered]',
-                'foo': '[Filtered]',
-                'bar': '[Filtered]',
-                'baz': '3'
-            }
+        assert call_data['request']['data'] == {
+            'password': '[Filtered]',
+            'foo': '[Filtered]',
+            'bar': '[Filtered]',
+            'baz': '3'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_scrub_data_org_override(self, mock_insert_data_to_database):
@@ -604,20 +571,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['[Filtered]'],
-                'foo': ['1'],
-                'bar': ['2'],
-                'baz': ['3']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': '[Filtered]',
-                'foo': '1',
-                'bar': '2',
-                'baz': '3'
-            }
+        assert call_data['request']['data'] == {
+            'password': '[Filtered]',
+            'foo': '1',
+            'bar': '2',
+            'baz': '3'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_scrub_data_org_override_sensitive_fields(self, mock_insert_data_to_database):
@@ -640,20 +599,12 @@ class StoreViewTest(TestCase):
         assert resp.status_code == 200, (resp.status_code, resp.content)
 
         call_data = mock_insert_data_to_database.call_args[0][0]
-        if not ENABLE_RUST:
-            assert call_data['request']['data'] == {
-                'password': ['[Filtered]'],
-                'foo': ['[Filtered]'],
-                'bar': ['[Filtered]'],
-                'baz': ['[Filtered]']
-            }
-        else:
-            assert call_data['request']['data'] == {
-                'password': '[Filtered]',
-                'foo': '[Filtered]',
-                'bar': '[Filtered]',
-                'baz': '[Filtered]'
-            }
+        assert call_data['request']['data'] == {
+            'password': '[Filtered]',
+            'foo': '[Filtered]',
+            'bar': '[Filtered]',
+            'baz': '[Filtered]'
+        }
 
     @mock.patch('sentry.coreapi.ClientApiHelper.insert_data_to_database')
     def test_uses_client_as_sdk(self, mock_insert_data_to_database):
diff --git a/tests/snuba/api/endpoints/test_group_events.py b/tests/snuba/api/endpoints/test_group_events.py
index 826f9adc4e..8b4c6037b5 100644
--- a/tests/snuba/api/endpoints/test_group_events.py
+++ b/tests/snuba/api/endpoints/test_group_events.py
@@ -7,7 +7,6 @@ from django.utils import timezone
 from freezegun import freeze_time
 
 from sentry import options
-from sentry.models import Environment
 from sentry.testutils import APITestCase, SnubaTestCase
 
 
@@ -185,19 +184,22 @@ class GroupEventsTest(APITestCase, SnubaTestCase):
 
     def test_environment(self):
         self.login_as(user=self.user)
-
-        group = self.create_group()
         events = {}
 
         for name in ['production', 'development']:
-            Environment.get_or_create(group.project, name)
-            events[name] = self.create_event(
-                group=group,
-                datetime=self.min_ago,
-                tags={'environment': name},
+            events[name] = self.store_event(
+                data={
+                    'fingerprint': ['put-me-in-group1'],
+                    'timestamp': self.min_ago.isoformat()[:19],
+                    'environment': name
+                },
+                project_id=self.project.id
             )
 
-        url = u'/api/0/issues/{}/events/'.format(group.id)
+        # Asserts that all are in the same group
+        group_id, = set(e.group.id for e in events.values())
+
+        url = u'/api/0/issues/{}/events/'.format(group_id)
         response = self.client.get(url + '?environment=production', format='json')
 
         assert response.status_code == 200, response.content
diff --git a/tests/snuba/api/endpoints/test_group_tags.py b/tests/snuba/api/endpoints/test_group_tags.py
index 8e7a040212..affeb4ea80 100644
--- a/tests/snuba/api/endpoints/test_group_tags.py
+++ b/tests/snuba/api/endpoints/test_group_tags.py
@@ -9,30 +9,36 @@ class GroupTagsTest(APITestCase, SnubaTestCase):
     def test_multi_env(self):
         now = timezone.now()
         min_ago = now - timedelta(minutes=1)
-        group = self.create_group(first_seen=min_ago, last_seen=now)
-        env = self.create_environment(project=group.project, name='prod')
-        env2 = self.create_environment(project=group.project, name='staging')
-        self.create_event(
-            group=group,
-            tags=[['foo', 'bar'], ['environment', env.name]],
-            datetime=min_ago,
+        env = self.create_environment(project=self.project, name='prod')
+        env2 = self.create_environment(project=self.project, name='staging')
+        self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'timestamp': min_ago.isoformat()[:19],
+                'environment': env.name,
+                'tags': {'foo': 'bar'},
+            },
+            project_id=self.project.id
         )
-        self.create_event(
-            group=group,
-            tags=[['biz', 'baz'], ['environment', env2.name]],
-            datetime=min_ago,
+        event2 = self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'timestamp': min_ago.isoformat()[:19],
+                'environment': env2.name,
+                'tags': {'biz': 'baz'},
+            },
+            project_id=self.project.id
         )
 
         self.login_as(user=self.user)
-        url = u'/api/0/issues/{}/tags/?enable_snuba=1'.format(group.id)
+        url = u'/api/0/issues/{}/tags/?enable_snuba=1'.format(event2.group.id)
         response = self.client.get(
             '%s&environment=%s&environment=%s' % (url, env.name, env2.name),
             format='json'
         )
         assert response.status_code == 200
-        assert sorted([
+        assert set([
             (tag['key'], tag['uniqueValues']) for tag in response.data
-        ], key=lambda x: x[0]) == [
+        ]) >= set([
             ('biz', 1), ('environment', 2), ('foo', 1)
-        ]
-        assert len(response.data) == 3
+        ])
diff --git a/tests/snuba/api/endpoints/test_organization_events.py b/tests/snuba/api/endpoints/test_organization_events.py
index 7a513b40a8..851c67f748 100644
--- a/tests/snuba/api/endpoints/test_organization_events.py
+++ b/tests/snuba/api/endpoints/test_organization_events.py
@@ -271,20 +271,25 @@ class OrganizationEventsEndpointTest(OrganizationEventsTestBase):
         environment = self.create_environment(project=project, name="production")
         environment2 = self.create_environment(project=project)
         null_env = self.create_environment(project=project, name='')
-        group = self.create_group(project=project)
 
-        event_1 = self.create_event(
-            'a' * 32, group=group, datetime=self.min_ago, tags={'environment': environment.name}
-        )
-        event_2 = self.create_event(
-            'b' * 32, group=group, datetime=self.min_ago, tags={'environment': environment.name}
-        )
-        event_3 = self.create_event(
-            'c' * 32, group=group, datetime=self.min_ago, tags={'environment': environment2.name}
-        )
-        event_4 = self.create_event(
-            'd' * 32, group=group, datetime=self.min_ago,
-        )
+        events = []
+        for event_id, env in [
+            ('a' * 32, environment),
+            ('b' * 32, environment),
+            ('c' * 32, environment2),
+            ('d' * 32, null_env),
+        ]:
+            events.append(self.store_event(
+                data={
+                    'event_id': event_id,
+                    'timestamp': self.min_ago.isoformat()[:19],
+                    'fingerprint': ['put-me-in-group1'],
+                    'environment': env.name or None,
+                },
+                project_id=project.id
+            ))
+
+        event_1, event_2, event_3, event_4 = events
 
         base_url = reverse(
             'sentry-api-0-organization-events',
diff --git a/tests/snuba/api/endpoints/test_organization_group_index.py b/tests/snuba/api/endpoints/test_organization_group_index.py
index 36bba156c9..c357878295 100644
--- a/tests/snuba/api/endpoints/test_organization_group_index.py
+++ b/tests/snuba/api/endpoints/test_organization_group_index.py
@@ -135,22 +135,22 @@ class GroupListTest(APITestCase, SnubaTestCase):
         assert response.status_code == 400
 
     def test_environment(self):
-        self.create_environment(name='production', organization=self.project.organization)
-        self.create_environment(name='staging', organization=self.project.organization)
-        group = self.create_group(
-            project=self.project,
+        self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'timestamp': self.min_ago.isoformat()[:19],
+                'environment': 'production',
+            },
+            project_id=self.project.id
         )
-        group2 = self.create_group(
-            project=self.project,
+        self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group2'],
+                'timestamp': self.min_ago.isoformat()[:19],
+                'environment': 'staging',
+            },
+            project_id=self.project.id
         )
-        self.create_event(tags={'environment': 'production'}, group=group, datetime=self.min_ago)
-        self.create_event(
-            tags={
-                'environment': 'staging'},
-            group=group2,
-            datetime=self.min_ago,
-            stacktrace=[
-                ['foo.py']])
 
         self.login_as(user=self.user)
 
@@ -1196,20 +1196,20 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         assert response.data['statusDetails']['actor']['id'] == six.text_type(self.user.id)
 
     def test_snooze_user_count(self):
-        group = self.create_group(
-            checksum='a' * 32,
-            status=GroupStatus.RESOLVED,
-            first_seen=self.min_ago - timedelta(seconds=100),
-            last_seen=timezone.now(),
-        )
         for i in range(100):
-            self.create_event(
-                group=group,
-                data={'checksum': six.binary_type(i)},
-                tags={'sentry:user': {'id': six.binary_type(i)}},
-                datetime=self.min_ago - timedelta(seconds=i),
+            event = self.store_event(
+                data={
+                    'fingerprint': ['put-me-in-group-1'],
+                    'user': {'id': six.binary_type(i)},
+                    'timestamp': (self.min_ago - timedelta(seconds=i)).isoformat()[:19]
+                },
+                project_id=self.project.id
             )
 
+        group = Group.objects.get(id=event.group.id)
+        group.status = GroupStatus.RESOLVED
+        group.save()
+
         self.login_as(user=self.user)
 
         response = self.get_valid_response(
diff --git a/tests/snuba/api/endpoints/test_organization_health.py b/tests/snuba/api/endpoints/test_organization_health.py
index 9979181f88..fe98e65ff4 100644
--- a/tests/snuba/api/endpoints/test_organization_health.py
+++ b/tests/snuba/api/endpoints/test_organization_health.py
@@ -68,44 +68,23 @@ class OrganizationHealthTest(APITestCase, SnubaTestCase):
         environment2 = self.create_environment(project=project)
         environment3 = self.create_environment(project=project)
         no_env = self.create_environment(project=project, name='')
-        group = self.create_group(project=project)
 
-        self.create_event(
-            'a' * 32,
-            group=group,
-            datetime=self.min_ago,
-            tags={
-                'environment': environment.name,
-                'sentry:user': 'id:%s' % (self.user.id,),
-            },
-        )
-        self.create_event(
-            'b' * 32,
-            group=group,
-            datetime=self.min_ago,
-            tags={
-                'environment': environment2.name,
-                'sentry:user': 'id:%s' % (self.user.id,),
-            },
-        )
-        self.create_event(
-            'c' * 32,
-            group=group,
-            datetime=self.min_ago,
-            tags={
-                'environment': environment3.name,
-                'sentry:user': 'id:%s' % (self.user.id,),
-            },
-        )
-        self.create_event(
-            'd' * 32,
-            group=group,
-            datetime=self.min_ago,
-            tags={
-                'environment': '',
-                'sentry:user': 'id:%s' % (self.user.id,),
-            },
-        )
+        for event_id, env in [
+            ('a' * 32, environment),
+            ('b' * 32, environment2),
+            ('c' * 32, environment3),
+            ('d' * 32, no_env),
+        ]:
+            self.store_event(
+                data={
+                    'event_id': event_id,
+                    'timestamp': self.min_ago.isoformat()[:19],
+                    'fingerprint': ['put-me-in-group1'],
+                    'environment': env.name or None,
+                    'user': {'id': self.user.id},
+                },
+                project_id=project.id
+            )
 
         base_url = reverse(
             'sentry-api-0-organization-health-graph',
@@ -127,7 +106,7 @@ class OrganizationHealthTest(APITestCase, SnubaTestCase):
         response = self.client.get(url, format='json')
 
         assert response.status_code == 200, response.content
-        assert response.data['totals']['count'] == 2
+        assert response.data['totals']['count'] == 2, response.data
 
         # test 'no environment' environment
         url = '%s?%s' % (base_url, urlencode((
diff --git a/tests/snuba/api/serializers/test_group.py b/tests/snuba/api/serializers/test_group.py
index 740c510de1..3d02b170a6 100644
--- a/tests/snuba/api/serializers/test_group.py
+++ b/tests/snuba/api/serializers/test_group.py
@@ -13,7 +13,7 @@ from mock import patch
 from sentry.api.serializers import serialize
 from sentry.api.serializers.models.group import GroupSerializerSnuba, StreamGroupSerializerSnuba, snuba_tsdb
 from sentry.models import (
-    Environment, GroupEnvironment, GroupLink, GroupResolution, GroupSnooze, GroupStatus,
+    Group, Environment, GroupEnvironment, GroupLink, GroupResolution, GroupSnooze, GroupStatus,
     GroupSubscription, UserOption, UserOptionValue
 )
 from sentry.testutils import APITestCase, SnubaTestCase
@@ -296,7 +296,33 @@ class GroupSerializerSnubaTest(APITestCase, SnubaTestCase):
         assert not result['isSubscribed']
 
     def test_seen_stats(self):
-        group = self.create_group(first_seen=self.week_ago, times_seen=5)
+        environment = self.create_environment(project=self.project)
+        environment2 = self.create_environment(project=self.project)
+
+        events = []
+
+        for event_id, env in [
+            ('a' * 32, environment),
+            ('b' * 32, environment),
+            ('c' * 32, environment2),
+        ]:
+            events.append(self.store_event(
+                data={
+                    'event_id': event_id,
+                    'fingerprint': ['put-me-in-group1'],
+                    'timestamp': self.min_ago.isoformat()[:19],
+                    'environment': env.name
+                },
+                project_id=self.project.id
+            ))
+
+        # Assert all events are in the same group
+        group_id, = set(e.group.id for e in events)
+
+        group = Group.objects.get(id=group_id)
+        group.times_seen = 5
+        group.first_seen = self.week_ago
+        group.save()
 
         # should use group columns when no environments arg passed
         result = serialize(group, serializer=GroupSerializerSnuba(environment_ids=[]))
@@ -304,25 +330,12 @@ class GroupSerializerSnubaTest(APITestCase, SnubaTestCase):
         assert result['lastSeen'] == group.last_seen
         assert result['firstSeen'] == group.first_seen
 
-        environment = self.create_environment(project=group.project)
-        environment2 = self.create_environment(project=group.project)
-
-        self.create_event(
-            'a' * 32, group=group, datetime=self.day_ago, tags={'environment': environment.name}
-        )
-        self.create_event(
-            'b' * 32, group=group, datetime=self.min_ago, tags={'environment': environment.name}
-        )
-        self.create_event(
-            'c' * 32, group=group, datetime=self.min_ago, tags={'environment': environment2.name}
-        )
-
         # update this to something different to make sure it's being used
-        group_env = GroupEnvironment.objects.get(group_id=group.id, environment_id=environment.id)
+        group_env = GroupEnvironment.objects.get(group_id=group_id, environment_id=environment.id)
         group_env.first_seen = self.day_ago - timedelta(days=3)
         group_env.save()
 
-        group_env2 = GroupEnvironment.objects.get(group_id=group.id, environment_id=environment2.id)
+        group_env2 = GroupEnvironment.objects.get(group_id=group_id, environment_id=environment2.id)
 
         result = serialize(
             group, serializer=GroupSerializerSnuba(
diff --git a/tests/snuba/search/test_backend.py b/tests/snuba/search/test_backend.py
index dc1dbb66ff..4caece0936 100644
--- a/tests/snuba/search/test_backend.py
+++ b/tests/snuba/search/test_backend.py
@@ -14,8 +14,8 @@ from sentry.api.issue_search import (
     parse_search_query,
 )
 from sentry.models import (
-    Environment, GroupAssignee, GroupBookmark, GroupEnvironment, GroupStatus,
-    GroupSubscription,
+    Environment, Group, GroupAssignee, GroupBookmark, GroupEnvironment,
+    GroupStatus, GroupSubscription
 )
 from sentry.search.base import ANY
 from sentry.search.snuba.backend import SnubaSearchBackend
@@ -31,74 +31,84 @@ class SnubaSearchTest(SnubaTestCase):
 
     def setUp(self):
         super(SnubaSearchTest, self).setUp()
-
         self.backend = SnubaSearchBackend()
-        self.environments = {}
+        self.base_datetime = (datetime.utcnow() - timedelta(days=3)).replace(tzinfo=pytz.utc)
 
-        self.base_datetime = (datetime.utcnow() - timedelta(days=7)).replace(tzinfo=pytz.utc)
-        self.group1 = self.create_group(
-            project=self.project,
-            checksum='a' * 32,
-            message='foo',
-            times_seen=5,
-            status=GroupStatus.UNRESOLVED,
-            last_seen=self.base_datetime,
-            first_seen=self.base_datetime - timedelta(days=31),
-        )
-        self.event1 = self.create_event(
-            event_id='a' * 32,
-            group=self.group1,
-            datetime=self.base_datetime - timedelta(days=31),
-            message='foo',
-            stacktrace={
-                'frames': [{
-                    'module': 'group1'
-                }]},
-            tags={
-                'server': 'example.com',
+        self.event1 = self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'event_id': 'a' * 32,
+                'message': 'foo',
                 'environment': 'production',
-            }
+                'tags': {
+                    'server': 'example.com',
+                },
+                'timestamp': (self.base_datetime - timedelta(days=21)).isoformat()[:19],
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group1'
+                    }]
+                },
+            },
+            project_id=self.project.id,
         )
-        self.event3 = self.create_event(
-            event_id='c' * 32,
-            group=self.group1,
-            datetime=self.base_datetime,
-            message='group1',
-            stacktrace={
-                'frames': [{
-                    'module': 'group1'
-                }]},
-            tags={
-                'server': 'example.com',
+        self.event3 = self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'event_id': 'c' * 32,
+                'message': 'group1',
                 'environment': 'production',
-            }
+                'tags': {
+                    'server': 'example.com',
+                },
+                'timestamp': self.base_datetime.isoformat()[:19],
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group1'
+                    }]
+                },
+            },
+            project_id=self.project.id,
         )
 
-        self.group2 = self.create_group(
-            project=self.project,
-            checksum='b' * 32,
-            message='bar',
-            times_seen=10,
-            status=GroupStatus.RESOLVED,
-            last_seen=self.base_datetime - timedelta(days=30),
-            first_seen=self.base_datetime - timedelta(days=30),
-        )
-        self.event2 = self.create_event(
-            event_id='b' * 32,
-            group=self.group2,
-            datetime=self.base_datetime - timedelta(days=30),
-            message='bar',
-            stacktrace={
-                'frames': [{
-                    'module': 'group2'
-                }]},
-            tags={
-                'server': 'example.com',
+        self.group1 = Group.objects.get(id=self.event1.group.id)
+        assert self.group1.id == self.event3.group.id
+
+        assert self.group1.first_seen == self.event1.datetime
+        assert self.group1.last_seen == self.event3.datetime
+
+        self.group1.times_seen = 5
+        self.group1.status = GroupStatus.UNRESOLVED
+        self.group1.save()
+
+        self.event2 = self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group2'],
+                'event_id': 'b' * 32,
+                'timestamp': (self.base_datetime - timedelta(days=20)).isoformat()[:19],
+                'message': 'bar',
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group2'
+                    }]
+                },
                 'environment': 'staging',
-                'url': 'http://example.com',
-            }
+                'tags': {
+                    'server': 'example.com',
+                    'url': 'http://example.com',
+                }
+            },
+            project_id=self.project.id
         )
 
+        self.group2 = Group.objects.get(id=self.event2.group.id)
+
+        assert self.group2.first_seen == self.group2.last_seen == self.event2.datetime
+
+        self.group2.status = GroupStatus.RESOLVED
+        self.group2.times_seen = 10
+        self.group2.save()
+
         GroupBookmark.objects.create(
             user=self.user,
             group=self.group2,
@@ -125,45 +135,36 @@ class SnubaSearchTest(SnubaTestCase):
             is_active=False,
         )
 
+        self.environments = {
+            'production': self.event1.get_environment(),
+            'staging': self.event2.get_environment(),
+        }
+
     def set_up_multi_project(self):
         self.project2 = self.create_project(organization=self.project.organization)
-        self.group_p2 = self.create_group(
-            project=self.project2,
-            checksum='a' * 32,
-            message='foo',
-            times_seen=6,
-            status=GroupStatus.UNRESOLVED,
-            last_seen=self.base_datetime - timedelta(days=1),
-            first_seen=self.base_datetime - timedelta(days=31),
-        )
-        self.event_p2 = self.create_event(
-            event_id='a' * 32,
-            group=self.group_p2,
-            datetime=self.base_datetime - timedelta(days=31),
-            message='foo',
-            stacktrace={
-                'frames': [{
-                    'module': 'group_p2'
-                }]},
-            tags={
-                'server': 'example.com',
+        self.event_p2 = self.store_event(
+            data={
+                'event_id': 'a' * 32,
+                'fingerprint': ['put-me-in-groupP2'],
+                'timestamp': (self.base_datetime - timedelta(days=21)).isoformat()[:19],
+                'message': 'foo',
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group_p2'
+                    }]
+                },
+                'tags': {
+                    'server': 'example.com',
+                },
                 'environment': 'production',
-            }
+            },
+            project_id=self.project2.id
         )
 
-    def create_event(self, *args, **kwargs):
-        event = super(SnubaSearchTest, self).create_event(*args, **kwargs)
-
-        data = event.data.data
-        tags = dict(data.get('tags', []))
-
-        if tags['environment'] not in self.environments:
-            self.environments[tags['environment']] = Environment.get_or_create(
-                event.project,
-                tags['environment'],
-            )
-
-        return event
+        self.group_p2 = Group.objects.get(id=self.event_p2.group.id)
+        self.group_p2.times_seen = 6
+        self.group_p2.last_seen = self.base_datetime - timedelta(days=1)
+        self.group_p2.save()
 
     def build_search_filter(self, query, projects=None, user=None, environments=None):
         user = user if user is not None else self.user
@@ -285,15 +286,19 @@ class SnubaSearchTest(SnubaTestCase):
                 self.group1.first_seen + timedelta(days=1),
                 self.group1.first_seen + timedelta(days=2),
                 self.group1.last_seen + timedelta(days=1)]:
-            self.create_event(
-                group=self.group2,
-                datetime=dt,
-                message='group2',
-                stacktrace={
-                    'frames': [{
-                        'module': 'group2'
-                    }]},
-                tags={'environment': 'production'}
+            self.store_event(
+                data={
+                    'fingerprint': ['put-me-in-group2'],
+                    'timestamp': dt.isoformat()[:19],
+                    'stacktrace': {
+                        'frames': [{
+                            'module': 'group2'
+                        }]
+                    },
+                    'environment': 'production',
+                    'message': 'group2'
+                },
+                project_id=self.project.id
             )
 
         results = self.make_query(
@@ -520,15 +525,19 @@ class SnubaSearchTest(SnubaTestCase):
                 self.group1.first_seen + timedelta(days=1),
                 self.group1.first_seen + timedelta(days=2),
                 self.group1.last_seen + timedelta(days=1)]:
-            self.create_event(
-                group=self.group2,
-                datetime=dt,
-                message='group2',
-                stacktrace={
-                    'frames': [{
-                        'module': 'group2'
-                    }]},
-                tags={'environment': 'production'}
+            self.store_event(
+                data={
+                    'fingerprint': ['put-me-in-group2'],
+                    'timestamp': dt.isoformat()[:19],
+                    'environment': 'production',
+                    'message': 'group2',
+                    'stacktrace': {
+                        'frames': [{
+                            'module': 'group2'
+                        }]
+                    },
+                },
+                project_id=self.project.id
             )
 
         results = self.backend.query(
@@ -646,17 +655,19 @@ class SnubaSearchTest(SnubaTestCase):
         )
         assert set(results) == set([])
 
-        self.create_event(
-            group=self.group1,
-            datetime=self.group1.first_seen + timedelta(days=1),
-            message='group1',
-            stacktrace={
-                'frames': [{
-                    'module': 'group1'
-                }]},
-            tags={
-                'environment': 'development',
-            }
+        self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'timestamp': (self.group1.first_seen + timedelta(days=1)).isoformat()[:19],
+                'message': 'group1',
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group1'
+                    }]
+                },
+                'environment': 'development'
+            },
+            project_id=self.project.id
         )
 
         results = self.make_query(
@@ -668,7 +679,7 @@ class SnubaSearchTest(SnubaTestCase):
         assert set(results) == set([])
 
         results = self.make_query(
-            environments=[self.environments['development']],
+            environments=[Environment.objects.get(name='development')],
             age_from=self.group1.first_seen,
             age_from_inclusive=False,
             search_filter_query='firstSeen:>%s' % date_to_query_format(self.group1.first_seen),
@@ -742,17 +753,19 @@ class SnubaSearchTest(SnubaTestCase):
         )
         assert set(results) == set([])
 
-        self.create_event(
-            group=self.group1,
-            datetime=self.group1.last_seen + timedelta(days=1),
-            message='group1',
-            stacktrace={
-                'frames': [{
-                    'module': 'group1'
-                }]},
-            tags={
+        self.store_event(
+            data={
+                'fingerprint': ['put-me-in-group1'],
+                'timestamp': (self.group1.last_seen + timedelta(days=1)).isoformat()[:19],
+                'message': 'group1',
+                'stacktrace': {
+                    'frames': [{
+                        'module': 'group1'
+                    }]
+                },
                 'environment': 'development',
-            }
+            },
+            project_id=self.project.id
         )
 
         self.group1.update(last_seen=self.group1.last_seen + timedelta(days=1))
@@ -766,7 +779,7 @@ class SnubaSearchTest(SnubaTestCase):
         assert set(results) == set([])
 
         results = self.make_query(
-            environments=[self.environments['development']],
+            environments=[Environment.objects.get(name='development')],
             last_seen_from=self.group1.last_seen,
             last_seen_from_inclusive=False,
             search_filter_query='lastSeen:>%s' % date_to_query_format(self.group1.last_seen),
@@ -776,7 +789,7 @@ class SnubaSearchTest(SnubaTestCase):
         results = self.backend.query(
             [self.project],
             date_to=self.group1.last_seen + timedelta(days=1),
-            environments=[self.environments['development']],
+            environments=[Environment.objects.get(name='development')],
             last_seen_from=self.group1.last_seen,
             last_seen_from_inclusive=True,
             search_filter_query='lastSeen:>=%s' % date_to_query_format(self.group1.last_seen),
@@ -1120,31 +1133,30 @@ class SnubaSearchTest(SnubaTestCase):
         # Every 3rd one is Unresolved
         # Evey 2nd one has tag match=1
         for i in range(400):
-            group = self.create_group(
-                project=self.project,
-                checksum=md5('group {}'.format(i)).hexdigest(),
-                message='group {}'.format(i),
-                times_seen=5,
-                status=GroupStatus.UNRESOLVED if i % 3 == 0 else GroupStatus.RESOLVED,
-                last_seen=self.base_datetime,
-                first_seen=self.base_datetime - timedelta(days=31),
-            )
-            self.create_event(
-                event_id=md5('event {}'.format(i)).hexdigest(),
-                group=group,
-                datetime=self.base_datetime - timedelta(days=31),
-                message='group {} event'.format(i),
-                stacktrace={
-                    'frames': [{
-                        'module': 'module {}'.format(i)
-                    }]
-                },
-                tags={
-                    'match': '{}'.format(i % 2),
+            event = self.store_event(
+                data={
+                    'event_id': md5('event {}'.format(i)).hexdigest(),
+                    'fingerprint': ['put-me-in-group{}'.format(i)],
+                    'timestamp': (self.base_datetime - timedelta(days=21)).isoformat()[:19],
+                    'message': 'group {} event'.format(i),
+                    'stacktrace': {
+                        'frames': [{
+                            'module': 'module {}'.format(i)
+                        }]
+                    },
+                    'tags': {
+                        'match': '{}'.format(i % 2),
+                    },
                     'environment': 'production',
-                }
+                },
+                project_id=self.project.id
             )
 
+            group = event.group
+            group.times_seen = 5
+            group.status = GroupStatus.UNRESOLVED if i % 3 == 0 else GroupStatus.RESOLVED
+            group.save()
+
         # Sample should estimate there are roughly 66 overall matching groups
         # based on a random sample of 100 (or $sample_size) of the total 200
         # snuba matches, of which 33% should pass the postgres filter.
