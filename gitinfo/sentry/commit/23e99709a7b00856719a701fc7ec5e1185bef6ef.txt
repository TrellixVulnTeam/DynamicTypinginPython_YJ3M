commit 23e99709a7b00856719a701fc7ec5e1185bef6ef
Author: Jan Michael Auer <jan.auer@sentry.io>
Date:   Wed Feb 26 22:30:21 2020 +0100

    Revert "ref(event_saved): Send event_saved signal in outcomes_consumer (#17291)" (#17326)
    
    This reverts commit 9c3c1b1b108fbe08c158a86159a97f49382e7511.

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 3244b76df1..64cf2b02b7 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -40,7 +40,6 @@ from sentry.coreapi import (
     decode_data,
     safely_load_json_string,
 )
-from sentry.ingest.outcomes_consumer import mark_signal_sent
 from sentry.interfaces.base import get_interface
 from sentry.lang.native.utils import STORE_CRASH_REPORTS_ALL, convert_crashreport_count
 from sentry.models import (
@@ -786,7 +785,6 @@ def _materialize_metadata_many(jobs):
 @metrics.wraps("save_event.send_event_saved_signal_many")
 def _send_event_saved_signal_many(jobs, projects):
     for job in jobs:
-        mark_signal_sent(project_id=job["project_id"], event_id=job["event"].event_id)
         event_saved.send_robust(
             project=projects[job["project_id"]], event_size=job["event"].size, sender=EventManager
         )
diff --git a/src/sentry/ingest/outcomes_consumer.py b/src/sentry/ingest/outcomes_consumer.py
index c1d8f0b49c..3ff8a23646 100644
--- a/src/sentry/ingest/outcomes_consumer.py
+++ b/src/sentry/ingest/outcomes_consumer.py
@@ -32,7 +32,7 @@ from django.core.cache import cache
 
 from sentry.models.project import Project
 from sentry.db.models.manager import BaseManager
-from sentry.signals import event_saved, event_filtered, event_dropped
+from sentry.signals import event_filtered, event_dropped
 from sentry.utils.kafka import create_batching_kafka_consumer
 from sentry.utils import json, metrics
 from sentry.utils.outcomes import Outcome
@@ -76,7 +76,7 @@ def _process_signal(msg):
         return  # no project. this is valid, so ignore silently.
 
     outcome = int(msg.get("outcome", -1))
-    if outcome not in (Outcome.FILTERED, Outcome.RATE_LIMITED, Outcome.ACCEPTED):
+    if outcome not in (Outcome.FILTERED, Outcome.RATE_LIMITED):
         metrics.incr("outcomes_consumer.skip_outcome", tags={"reason": "wrong_outcome_type"})
         return  # nothing to do here
 
@@ -99,9 +99,7 @@ def _process_signal(msg):
     reason = msg.get("reason")
     remote_addr = msg.get("remote_addr")
 
-    if outcome == Outcome.ACCEPTED:
-        event_saved.send_robust(project=project, sender=OutcomesConsumerWorker)
-    elif outcome == Outcome.FILTERED:
+    if outcome == Outcome.FILTERED:
         event_filtered.send_robust(ip=remote_addr, project=project, sender=OutcomesConsumerWorker)
     elif outcome == Outcome.RATE_LIMITED:
         event_dropped.send_robust(
diff --git a/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py b/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
index 6bfd228ee9..c2248b5976 100644
--- a/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
+++ b/tests/sentry/ingest/outcome_consumer/test_outcomes_kafka.py
@@ -5,7 +5,7 @@ import pytest
 import six.moves
 
 from sentry.ingest.outcomes_consumer import get_outcomes_consumer, mark_signal_sent, is_signal_sent
-from sentry.signals import event_filtered, event_dropped, event_saved
+from sentry.signals import event_filtered, event_dropped
 from sentry.testutils.factories import Factories
 from sentry.utils.outcomes import Outcome
 from django.conf import settings
@@ -101,7 +101,6 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
-    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -109,12 +108,8 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -135,7 +130,6 @@ def test_outcome_consumer_ignores_outcomes_already_handled(
     # verify that no signal was called (since the events have been previously processed)
     assert event_filtered_sink == ["127.33.44.2", "127.33.44.3"]
     assert len(event_dropped_sink) == 0
-    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -162,7 +156,6 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
-    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -170,12 +163,8 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -191,7 +180,6 @@ def test_outcome_consumer_ignores_invalid_outcomes(
     # verify that the appropriate filters were called
     assert event_filtered_sink == ["127.33.44.2", "127.33.44.3"]
     assert len(event_dropped_sink) == 0
-    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -219,7 +207,6 @@ def test_outcome_consumer_remembers_handled_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
-    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -227,12 +214,8 @@ def test_outcome_consumer_remembers_handled_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -249,63 +232,6 @@ def test_outcome_consumer_remembers_handled_outcomes(
     assert len(event_filtered_sink) == 1
     assert event_filtered_sink == ["127.33.44.1"]
     assert len(event_dropped_sink) == 0
-    assert len(event_saved_sink) == 0
-
-
-@pytest.mark.django_db
-def test_outcome_consumer_handles_accepted_outcomes(
-    kafka_producer, task_runner, kafka_admin, requires_kafka
-):
-    producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
-
-    group_id = "test-outcome-consumer-4"
-
-    # put a few outcome messages on the kafka topic
-    for i in six.moves.range(1, 3):
-        msg = _get_outcome(
-            event_id=i,
-            project_id=project_id,
-            outcome=Outcome.ACCEPTED,
-            reason="some_reason",
-            remote_addr="127.33.44.{}".format(i),
-        )
-
-        producer.produce(topic_name, msg)
-
-    # setup django signals for event_filtered and event_dropped
-    event_filtered_sink = []
-    event_dropped_sink = []
-    event_saved_sink = []
-
-    def event_filtered_receiver(**kwargs):
-        event_filtered_sink.append(kwargs.get("ip"))
-
-    def event_dropped_receiver(**kwargs):
-        event_dropped_sink.append("something")
-
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
-    event_filtered.connect(event_filtered_receiver)
-    event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
-
-    consumer = get_outcomes_consumer(
-        max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
-    )
-
-    # run the outcome consumer
-    with task_runner():
-        i = 0
-        while len(event_filtered_sink) < 2 and i < MAX_POLL_ITERATIONS:
-            consumer._run_once()
-            i += 1
-
-    # verify that the appropriate filters were called
-    assert len(event_saved_sink) == 2
-    assert set(event_saved_sink) == {"saved event"}
-    assert len(event_dropped_sink) == 0
-    assert len(event_filtered_sink) == 0
 
 
 @pytest.mark.django_db
@@ -314,7 +240,7 @@ def test_outcome_consumer_handles_filtered_outcomes(
 ):
     producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
 
-    group_id = "test-outcome-consumer-5"
+    group_id = "test-outcome-consumer-4"
 
     # put a few outcome messages on the kafka topic
     for i in six.moves.range(1, 3):
@@ -331,7 +257,6 @@ def test_outcome_consumer_handles_filtered_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
-    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append(kwargs.get("ip"))
@@ -339,12 +264,8 @@ def test_outcome_consumer_handles_filtered_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append("something")
 
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -359,9 +280,8 @@ def test_outcome_consumer_handles_filtered_outcomes(
 
     # verify that the appropriate filters were called
     assert len(event_filtered_sink) == 2
-    assert set(event_filtered_sink) == {"127.33.44.1", "127.33.44.2"}
+    assert set(event_filtered_sink) == set(["127.33.44.1", "127.33.44.2"])
     assert len(event_dropped_sink) == 0
-    assert len(event_saved_sink) == 0
 
 
 @pytest.mark.django_db
@@ -370,7 +290,7 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
 ):
     producer, project_id, topic_name = _setup_outcome_test(kafka_producer, kafka_admin)
 
-    group_id = "test-outcome-consumer-6"
+    group_id = "test-outcome-consumer-5"
 
     # put a few outcome messages on the kafka topic
     for i in six.moves.range(1, 3):
@@ -387,7 +307,6 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     # setup django signals for event_filtered and event_dropped
     event_filtered_sink = []
     event_dropped_sink = []
-    event_saved_sink = []
 
     def event_filtered_receiver(**kwargs):
         event_filtered_sink.append("something")
@@ -395,12 +314,8 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     def event_dropped_receiver(**kwargs):
         event_dropped_sink.append((kwargs.get("ip"), kwargs.get("reason_code")))
 
-    def event_saved_receiver(**kwargs):
-        event_saved_sink.append("saved event")
-
     event_filtered.connect(event_filtered_receiver)
     event_dropped.connect(event_dropped_receiver)
-    event_saved.connect(event_saved_receiver)
 
     consumer = get_outcomes_consumer(
         max_batch_size=1, max_batch_time=100, group_id=group_id, auto_offset_reset="earliest"
@@ -416,5 +331,6 @@ def test_outcome_consumer_handles_rate_limited_outcomes(
     # verify that the appropriate filters were called
     assert len(event_filtered_sink) == 0
     assert len(event_dropped_sink) == 2
-    assert set(event_dropped_sink) == {("127.33.44.1", "reason_1"), ("127.33.44.2", "reason_2")}
-    assert len(event_saved_sink) == 0
+    assert set(event_dropped_sink) == set(
+        [("127.33.44.1", "reason_1"), ("127.33.44.2", "reason_2")]
+    )
