commit 8651661a7732c43ebca558a598860fa5a9fb1849
Author: David Cramer <dcramer@gmail.com>
Date:   Wed Feb 13 13:48:28 2013 -0800

    Improve trends query

diff --git a/src/sentry/manager.py b/src/sentry/manager.py
index 024e61a1e3..8809be37c9 100644
--- a/src/sentry/manager.py
+++ b/src/sentry/manager.py
@@ -36,6 +36,7 @@ from sentry.processors.base import send_group_processors
 from sentry.signals import regression_signal
 from sentry.tasks.index import index_event
 from sentry.tasks.fetch_source import fetch_javascript_source
+from sentry.utils import cached_property
 from sentry.utils.cache import cache, Lock
 from sentry.utils.dates import get_sql_date_trunc, normalize_datetime
 from sentry.utils.db import get_db_engine, has_charts, attach_foreignkey
@@ -684,70 +685,76 @@ class GroupManager(BaseManager, ChartMixin):
     def get_by_natural_key(self, project, logger, culprit, checksum):
         return self.get(project=project, logger=logger, view=culprit, checksum=checksum)
 
+    @cached_property
+    def model_fields_clause(self):
+        return ', '.join('sentry_groupedmessage."%s"' % (f.column,) for f in self.model._meta.fields)
+
     def get_accelerated(self, project_ids, queryset=None, minutes=15):
         if not project_ids:
             return self.none()
 
-        from sentry.models import GroupCountByMinute
-        mcbm_tbl = GroupCountByMinute._meta.db_table
         if queryset is None:
-            queryset = self.filter(project__in=project_ids)
+            queryset = self.filter(
+                project__in=project_ids,
+                status=STATUS_UNRESOLVED,
+            )
         else:
             queryset = queryset._clone()
             queryset.query.select_related = False
 
         normalization = float(MINUTE_NORMALIZATION)
+
         assert minutes >= normalization
 
+        intervals = (60 / normalization)
+
         engine = get_db_engine(queryset.db)
         # We technically only support mysql and postgresql, since there seems to be no standard
         # way to get the epoch from a datetime/interval
         if engine.startswith('mysql'):
             minute_clause = "interval %s minute"
-            epoch_clause = "unix_timestamp(utc_timestamp()) - unix_timestamp(%(mcbm_tbl)s.date)"
+            epoch_clause = "unix_timestamp(utc_timestamp()) - unix_timestamp(mcbm.date)"
             now_clause = 'utc_timestamp()'
         else:
             minute_clause = "interval '%s minutes'"
-            epoch_clause = "extract(epoch from now()) - extract(epoch from %(mcbm_tbl)s.date)"
+            epoch_clause = "extract(epoch from now()) - extract(epoch from mcbm.date)"
             now_clause = 'now()'
 
-        epoch_clause = epoch_clause % dict(mcbm_tbl=mcbm_tbl)
-
-        queryset = queryset.annotate(x=Sum('groupcountbyminute__times_seen')).order_by('id')
-
         sql, params = queryset.query.get_compiler(queryset.db).as_sql()
         before_select, after_select = str(sql).split('SELECT ', 1)
-        before_where, after_where = after_select.split(' WHERE ', 1)
-        before_group, after_group = after_where.split(' GROUP BY ', 1)
+        after_where = after_select.split(' WHERE ', 1)[1]
 
         # Ensure we remove any ordering clause
-        after_group = after_group.split(' ORDER BY ')[0]
+        after_where = after_where.split(' ORDER BY ')[0]
 
         query = """
-        SELECT (SUM(%(mcbm_tbl)s.times_seen) * (%(norm)f / (%(epoch_clause)s / 60)) + 1.0) / (COALESCE(z.rate, 0) + 1.0) as sort_value,
-               (COALESCE(z.rate, 0) + 1.0) as prev_rate,
-               %(before_where)s
+        SELECT ((mcbm.times_seen + 1) / ((%(epoch_clause)s) / 60)) / (COALESCE(z.rate, 0) + 1) as sort_value,
+               (COALESCE(z.rate, 0) + 1) as prev_rate,
+               ((mcbm.times_seen + 1) / ((%(epoch_clause)s) / 60)) as cur_rate,
+               %(fields)s
+        FROM sentry_groupedmessage
+        INNER JOIN sentry_messagecountbyminute as mcbm
+            ON (sentry_groupedmessage.id = mcbm.group_id)
         LEFT JOIN (SELECT a.group_id, SUM(a.times_seen) / COUNT(a.times_seen) / %(norm)f as rate
-            FROM %(mcbm_tbl)s as a
+            FROM sentry_messagecountbyminute as a
             WHERE a.date >=  %(now)s - %(max_time)s
             AND a.date < %(now)s - %(min_time)s
             AND a.project_id IN (%(project_ids)s)
             GROUP BY a.group_id) as z
-        ON z.group_id = %(mcbm_tbl)s.group_id
-        WHERE %(mcbm_tbl)s.date >= %(now)s - %(min_time)s
-        AND %(mcbm_tbl)s.date < %(now)s - %(offset_time)s
-        AND %(before_group)s
-        GROUP BY prev_rate, %(mcbm_tbl)s.date, %(after_group)s
-        HAVING SUM(%(mcbm_tbl)s.times_seen) > 0
+        ON z.group_id = mcbm.group_id
+        WHERE mcbm.date >= %(now)s - %(min_time)s
+        AND mcbm.date < %(now)s - %(offset_time)s
+        AND mcbm.times_seen > 0
+        AND ((mcbm.times_seen + 1) / ((%(epoch_clause)s) / 60)) > (COALESCE(z.rate, 0) + 1)
+        AND %(after_where)s
+        GROUP BY prev_rate, mcbm.times_seen, mcbm.date, %(fields)s
         ORDER BY sort_value DESC
         """ % dict(
-            mcbm_tbl=mcbm_tbl,
-            before_where=before_where,
-            before_group=before_group,
-            after_group=after_group,
+            fields=self.model_fields_clause,
+            after_where=after_where,
             offset_time=minute_clause % (1,),
             min_time=minute_clause % (minutes + 1,),
-            max_time=minute_clause % (minutes * (60 / normalization),),
+            max_time=minute_clause % ((minutes + 1) * intervals,),
             norm=normalization,
             epoch_clause=epoch_clause,
             now=now_clause,
