commit 83a20b13d18d9e52ff2aed3d07e0409c7358fd24
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Fri Feb 10 18:28:03 2017 +0100

    Restructure stack handling to support frame caching

diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index 5cec5c7a43..a578453ce7 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -640,11 +640,15 @@ class JavaScriptStacktraceProcessor(StacktraceProcessor):
         self.populate_source_cache(frames)
         return True
 
-    def process_frame(self, frame, stacktrace_info, idx):
-        if not settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT or \
-           self.get_effective_platform(frame) != 'javascript':
-            return
+    def handles_frame(self, frame, stacktrace_info):
+        platform = frame.get('platform') or self.data.get('platform')
+        return (
+            settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT and
+            platform == 'javascript'
+        )
 
+    def process_frame(self, processable_frame):
+        frame = processable_frame.frame
         last_token = None
         token = None
 
diff --git a/src/sentry/lang/native/plugin.py b/src/sentry/lang/native/plugin.py
index d0b0d30da1..e325a3ce04 100644
--- a/src/sentry/lang/native/plugin.py
+++ b/src/sentry/lang/native/plugin.py
@@ -342,6 +342,7 @@ def preprocess_apple_crash_event(data):
 
 
 class NativeStacktraceProcessor(StacktraceProcessor):
+    platforms = ('cocoa',)
 
     def __init__(self, *args, **kwargs):
         StacktraceProcessor.__init__(self, *args, **kwargs)
@@ -377,14 +378,14 @@ class NativeStacktraceProcessor(StacktraceProcessor):
         # dict.
         return self.sym.resolve_missing_vmaddrs()
 
-    def find_best_instruction(self, frame, stacktrace_info, idx):
+    def find_best_instruction(self, processable_frame):
         """Given a frame, stacktrace info and frame index this returns the
         interpolated instruction address we then use for symbolication later.
         """
         meta = None
 
         # We only need to provide meta information for frame zero
-        if idx == 0:
+        if processable_frame.idx == 0:
             # The signal is useful information for symsynd in some situations
             # to disambiugate the first frame.  If we can get this information
             # from the mechanism we want to pass it onwards.
@@ -397,22 +398,22 @@ class NativeStacktraceProcessor(StacktraceProcessor):
                     signal = mechanism['posix_signal']['signal']
             meta = {
                 'frame_number': 0,
-                'registers': stacktrace_info.stacktrace.get('registers'),
+                'registers': processable_frame.stacktrace_info.stacktrace.get('registers'),
                 'signal': signal,
             }
 
-        return self.sym.find_best_instruction(frame, meta=meta)
+        return self.sym.find_best_instruction(processable_frame.frame, meta=meta)
 
-    def process_frame(self, frame, stacktrace_info, idx):
-        # XXX: warn on missing availability?
-
-        # Only process frames here that are of supported platforms and
-        # have the mandatory requirements for
-        if not self.available or \
-           self.get_effective_platform(frame) != 'cocoa' or \
-           'instruction_addr' not in frame:
-            return None
+    def handles_frame(self, frame, stacktrace_info):
+        platform = frame.get('platform') or self.data.get('platform')
+        return (
+            platform == 'cocoa' and
+            self.available and
+            'instruction_addr' not in frame
+        )
 
+    def process_frame(self, processable_frame):
+        frame = processable_frame.frame
         errors = []
 
         # Construct a raw frame that is used by the symbolizer
@@ -420,7 +421,7 @@ class NativeStacktraceProcessor(StacktraceProcessor):
         sym_input_frame = {
             'object_name': frame.get('package'),
             'instruction_addr': self.find_best_instruction(
-                frame, stacktrace_info, idx),
+                processable_frame),
             'symbol_name': frame.get('function'),
             'symbol_addr': frame.get('symbol_addr'),
         }
diff --git a/src/sentry/stacktraces.py b/src/sentry/stacktraces.py
index 872096bf9c..088e34839f 100644
--- a/src/sentry/stacktraces.py
+++ b/src/sentry/stacktraces.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 
 import logging
+import hashlib
 
 from sentry.models import Project
 from sentry.utils import metrics
@@ -11,6 +12,8 @@ from collections import namedtuple
 logger = logging.getLogger(__name__)
 
 
+ProcessableFrame = namedtuple('ProcessableFrame', [
+    'frame', 'idx', 'processor', 'stacktrace_info', 'cache_key'])
 StacktraceInfo = namedtuple('StacktraceInfo', [
     'stacktrace', 'container', 'platforms'])
 
@@ -30,13 +33,18 @@ class StacktraceProcessor(object):
     def preprocess_related_data(self):
         return False
 
-    def get_effective_platform(self, frame):
-        return frame.get('platform') or self.data['platform']
+    def handles_frame(self, frame, stacktrace_info):
+        return False
 
-    def process_frame(self, frame, stacktrace_info, idx):
+    def process_frame(self, processable_frame):
         pass
 
 
+def get_frame_cache_key(frame):
+    h = hashlib.md5()
+    return h.hexdigest()
+
+
 def find_stacktraces_in_data(data):
     """Finds all stracktraces in a given data blob and returns it
     together with some meta information.
@@ -111,6 +119,19 @@ def get_processors_for_stacktraces(data, infos):
     return processors
 
 
+def get_processable_frames(stacktrace_info, processors):
+    frame_count = len(stacktrace_info.stacktrace['frames'])
+    rv = []
+    for idx, frame in enumerate(stacktrace_info.stacktrace['frames']):
+        processor = next((p for p in processors
+                          if p.handles_frame(frame, stacktrace_info)), None)
+        if processor is not None:
+            rv.append(ProcessableFrame(
+                frame, frame_count - idx - 1, processor,
+                stacktrace_info, get_frame_cache_key(frame)))
+    return rv
+
+
 def process_single_stacktrace(stacktrace_info, processors):
     # TODO: associate errors with the frames and processing issues
     changed_raw = False
@@ -119,38 +140,26 @@ def process_single_stacktrace(stacktrace_info, processors):
     processed_frames = []
     all_errors = []
 
-    frame_count = len(stacktrace_info.stacktrace['frames'])
-    for idx, frame in enumerate(stacktrace_info.stacktrace['frames']):
-        need_processed_frame = True
-        need_raw_frame = True
-        errors = None
-        for processor in processors:
-            try:
-                rv = processor.process_frame(frame, stacktrace_info,
-                                             frame_count - idx - 1)
-                if rv is None:
-                    continue
-            except Exception:
-                logger.exception('Failed to process frame')
-                continue
-
-            expand_processed, expand_raw, errors = rv or (None, None, None)
-            if expand_processed is not None:
-                processed_frames.extend(expand_processed)
-                changed_processed = True
-                need_processed_frame = False
-
-            if expand_raw is not None:
-                raw_frames.extend(expand_raw)
-                changed_raw = True
-                need_raw_frame = False
-
-            break
-
-        if need_processed_frame:
-            processed_frames.append(frame)
-        if need_raw_frame:
-            raw_frames.append(frame)
+    processable_frames = get_processable_frames(stacktrace_info, processors)
+
+    for processable_frame in processable_frames:
+        try:
+            rv = processable_frame.processor.process_frame(processable_frame)
+        except Exception:
+            logger.exception('Failed to process frame')
+        expand_processed, expand_raw, errors = rv or (None, None, None)
+
+        if expand_processed is not None:
+            processed_frames.extend(expand_processed)
+            changed_processed = True
+        else:
+            processed_frames.append(processable_frame.frame)
+
+        if expand_raw is not None:
+            raw_frames.extend(expand_raw)
+            changed_raw = True
+        else:
+            raw_frames.append(processable_frame.frame)
         all_errors.extend(errors or ())
 
     return (
