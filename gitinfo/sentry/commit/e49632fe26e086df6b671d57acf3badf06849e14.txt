commit e49632fe26e086df6b671d57acf3badf06849e14
Author: Markus Unterwaditzer <markus@unterwaditzer.net>
Date:   Mon Nov 19 10:45:46 2018 +0100

    ref: Embed general into sentry (#10608)
    
    * ref: Embed general into sentry
    
    * fix: Pass timedelta config
    
    * fix: Add rust as featureflag, revert unrelated tests
    
    * fix: Move import
    
    * fix: Try to guard against segfaults
    
    * fix: Multiprocessing garbage
    
    * fix: Too many arguments
    
    * fix: Dont freeze when pool crashed
    
    * fix: Fix broken decorator
    
    * fix: Forgot to encode
    
    * fix: Add timeouts
    
    * fix: recv takes no args
    
    * build: Add travis job for rust normalization
    
    * build: xfail rust normalizer job

diff --git a/.travis.yml b/.travis.yml
index 70547b5351..f3f4363c8b 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -86,6 +86,19 @@ matrix:
       before_script:
         - psql -c 'create database sentry;' -U postgres
 
+    - python: 2.7
+      env:
+        - TEST_SUITE=postgres DB=postgres
+        - SENTRY_USE_RUST_NORMALIZER=true
+      services:
+        - memcached
+        - redis-server
+        - postgresql
+      install:
+        - pip install -e ".[dev,tests,optional]"
+      before_script:
+        - psql -c 'create database sentry;' -U postgres
+
     - python: 2.7
       env: TEST_SUITE=mysql DB=mysql
       services:
@@ -220,6 +233,11 @@ matrix:
     - language: node_js
       env: STORYBOOK_BUILD=1
 
+    - language: python
+      env:
+        - TEST_SUITE=postgres DB=postgres
+        - SENTRY_USE_RUST_NORMALIZER=true
+
 notifications:
   webhooks:
     urls:
diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index 2fe5343447..02a302766c 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -1416,6 +1416,14 @@ SENTRY_RELAY_WHITELIST_PK = []
 # whitelist can register.
 SENTRY_RELAY_OPEN_REGISTRATION = False
 
+# GeoIP
+# Used for looking up IP addresses.
+# For example /usr/local/share/GeoIP/GeoIPCity.dat
+GEOIP_PATH = None
+# Same file but in the newer format. Both are required.
+# For example /usr/local/share/GeoIP/GeoIPCity.mmdb
+GEOIP_PATH_MMDB = None
+
 # CDN
 # If this is an absolute url like e.g.: https://js.sentry-cdn.com/
 # the full url will look like this: https://js.sentry-cdn.com/<public_key>.min.js
diff --git a/src/sentry/constants.py b/src/sentry/constants.py
index dd8204030d..12fc48c5e0 100644
--- a/src/sentry/constants.py
+++ b/src/sentry/constants.py
@@ -73,7 +73,7 @@ MINUTE_NORMALIZATION = 15
 
 MAX_TAG_KEY_LENGTH = 32
 MAX_TAG_VALUE_LENGTH = 200
-MAX_CULPRIT_LENGTH = 200
+MAX_CULPRIT_LENGTH = 256
 MAX_EMAIL_FIELD_LENGTH = 75
 
 ENVIRONMENT_NAME_PATTERN = r'^[^\n\r\f\/]*$'
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 437e8953d8..c2e4080d29 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -7,6 +7,7 @@ sentry.event_manager
 from __future__ import absolute_import, print_function
 
 import logging
+import os
 import re
 import six
 import jsonschema
@@ -60,6 +61,7 @@ from sentry.utils.dates import to_timestamp
 from sentry.utils.db import is_postgres, is_mysql
 from sentry.utils.safe import safe_execute, trim, trim_dict, get_path
 from sentry.utils.strings import truncatechars
+from sentry.utils.geo import rust_geoip
 from sentry.utils.validators import is_float
 from sentry.stacktraces import normalize_in_app
 
@@ -69,7 +71,9 @@ logger = logging.getLogger("sentry.events")
 
 HASH_RE = re.compile(r'^[0-9a-f]{32}$')
 DEFAULT_FINGERPRINT_VALUES = frozenset(['{{ default }}', '{{default}}'])
-ALLOWED_FUTURE_DELTA = timedelta(minutes=1)
+MAX_SECS_IN_FUTURE = 60
+ALLOWED_FUTURE_DELTA = timedelta(seconds=MAX_SECS_IN_FUTURE)
+MAX_SECS_IN_PAST = 2592000  # 30 days
 SECURITY_REPORT_INTERFACES = (
     "csp",
     "hpkp",
@@ -77,6 +81,8 @@ SECURITY_REPORT_INTERFACES = (
     "expectstaple",
 )
 
+ENABLE_RUST = os.environ.get("SENTRY_USE_RUST_NORMALIZER", "false").lower() in ("1", "true")
+
 
 def count_limit(count):
     # TODO: could we do something like num_to_store = max(math.sqrt(100*count)+59, 200) ?
@@ -440,6 +446,25 @@ class EventManager(object):
         self._data = data
 
     def normalize(self):
+        if ENABLE_RUST:
+            from semaphore.processing import StoreNormalizer
+            rust_normalizer = StoreNormalizer(
+                geoip_lookup=rust_geoip,
+                project_id=self._project.id if self._project else None,
+                client_ip=self._client_ip,
+                client=self._auth.client if self._auth else None,
+                is_public_auth=self._auth.is_public if self._auth else False,
+                key_id=self._key.id if self._key else None,
+                protocol_version=self.version,
+                stacktrace_frames_hard_limit=settings.SENTRY_STACKTRACE_FRAMES_HARD_LIMIT,
+                valid_platforms=list(VALID_PLATFORMS),
+                max_secs_in_future=MAX_SECS_IN_FUTURE,
+                max_secs_in_past=MAX_SECS_IN_PAST
+            )
+
+            self._data = CanonicalKeyDict(rust_normalizer.normalize_event(dict(self._data)))
+            return
+
         data = self._data
         if self._project is not None:
             data['project'] = self._project.id
diff --git a/src/sentry/management/commands/serve_normalize.py b/src/sentry/management/commands/serve_normalize.py
index 651c4f0f6f..802078bd97 100644
--- a/src/sentry/management/commands/serve_normalize.py
+++ b/src/sentry/management/commands/serve_normalize.py
@@ -16,11 +16,97 @@ import time
 import traceback
 import json
 import resource
+import multiprocessing
 
 from django.core.management.base import BaseCommand, CommandError, make_option
 from django.utils.encoding import force_str
 
 
+# Here's where the normalization itself happens
+def process_event(data, meta):
+    from sentry.event_manager import EventManager, get_hashes_for_event
+    from sentry.tasks.store import should_process
+
+    event_manager = EventManager(
+        data,
+        client_ip=meta.get('REMOTE_ADDR'),
+        user_agent=meta.get('HTTP_USER_AGENT'),
+        auth=None,
+        key=None,
+        content_encoding=meta.get('HTTP_CONTENT_ENCODING')
+    )
+    event_manager.normalize()
+
+    event = event_manager.get_data()
+    group_hash = None
+
+    if not should_process(event):
+        group_hash = get_hashes_for_event(event_manager._get_event_instance(project_id=1))
+    return {
+        "event": dict(event),
+        "group_hash": group_hash,
+    }
+
+
+def decode(message):
+    meta, data_encoded = json.loads(message)
+    data = base64.b64decode(data_encoded)
+    return data, meta
+
+
+def encode(data):
+    # Normalized data should be serializable
+    return json.dumps(data)
+
+
+def handle_data(pipe, data):
+    @catch_errors
+    def inner(data):
+        mc = MetricCollector()
+
+        metrics_before = mc.collect_metrics()
+        data, meta = decode(data)
+        rv = process_event(data, meta)
+        metrics_after = mc.collect_metrics()
+
+        return encode({
+            'result': rv,
+            'metrics': {'before': metrics_before, 'after': metrics_after},
+            'error': None
+        })
+
+    pipe.send(inner(data))
+
+
+def catch_errors(f):
+    def wrapper(*args, **kwargs):
+        error = None
+        try:
+            return f(*args, **kwargs)
+        except Exception as e:
+            error = force_str(e.message) + ' ' + force_str(traceback.format_exc())
+
+        try:
+            return encode({
+                'result': None,
+                'error': error,
+                'metrics': None
+            })
+        except (ValueError, TypeError) as e:
+            try:
+                # Encoding error, try to send the exception instead
+                return encode({
+                    'result': None,
+                    'error': force_str(e.message) + ' ' + force_str(traceback.format_exc()),
+                    'metrics': None,
+                    'encoding_error': True,
+                })
+            except Exception:
+                return b'{}'
+
+    return wrapper
+
+
 class MetricCollector(object):
     def __init__(self):
         self.is_linux = sys.platform.startswith('linux')
@@ -75,73 +161,17 @@ class EventNormalizeHandler(SocketServer.BaseRequestHandler):
         self.request.sendall(response)
         self.request.close()
 
-    def encode(self, data):
-        # Normalized data should be serializable
-        return json.dumps(data)
-
-    def decode(self, message):
-        meta, data_encoded = json.loads(message)
-        data = base64.b64decode(data_encoded)
-        return data, meta
-
-    # Here's where the normalization itself happens
-    def process_event(self, data, meta):
-        from sentry.event_manager import EventManager, get_hashes_for_event
-        from sentry.tasks.store import should_process
-
-        event_manager = EventManager(
-            data,
-            client_ip=meta.get('REMOTE_ADDR'),
-            user_agent=meta.get('HTTP_USER_AGENT'),
-            auth=None,
-            key=None,
-            content_encoding=meta.get('HTTP_CONTENT_ENCODING')
-        )
-        event_manager.normalize()
-
-        event = event_manager.get_data()
-        group_hash = None
-
-        if not should_process(event):
-            group_hash = get_hashes_for_event(event_manager._get_event_instance(project_id=1))
-        return {
-            "event": dict(event),
-            "group_hash": group_hash,
-        }
-
     def handle_data(self):
-        result = None
-        error = None
-        metrics = None
-        mc = MetricCollector()
-        try:
-            data, meta = self.decode(self.data)
-
-            metrics_before = mc.collect_metrics()
-            result = self.process_event(data, meta)
-            metrics_after = mc.collect_metrics()
-
-            metrics = {'before': metrics_before, 'after': metrics_after}
-        except Exception as e:
-            error = force_str(e.message) + ' ' + force_str(traceback.format_exc())
-
-        try:
-            return self.encode({
-                'result': result,
-                'error': error,
-                'metrics': metrics
-            })
-        except (ValueError, TypeError) as e:
-            try:
-                # Encoding error, try to send the exception instead
-                return self.encode({
-                    'result': result,
-                    'error': force_str(e.message) + ' ' + force_str(traceback.format_exc()),
-                    'metrics': metrics,
-                    'encoding_error': True,
-                })
-            except Exception:
-                return b'{}'
+        @catch_errors
+        def inner():
+            parent_conn, child_conn = multiprocessing.Pipe()
+            p = multiprocessing.Process(target=handle_data, args=(child_conn, self.data,))
+            p.start()
+            p.join(1)
+            assert parent_conn.poll(), "Process crashed"
+            return parent_conn.recv()
+
+        return inner()
 
 
 class Command(BaseCommand):
diff --git a/src/sentry/tagstore/base.py b/src/sentry/tagstore/base.py
index 3a169fc07a..3dbd5f8b5c 100644
--- a/src/sentry/tagstore/base.py
+++ b/src/sentry/tagstore/base.py
@@ -345,7 +345,8 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def get_top_group_tag_values(self, project_id, group_id, environment_id, key, limit=TOP_VALUES_DEFAULT_LIMIT):
+    def get_top_group_tag_values(self, project_id, group_id,
+                                 environment_id, key, limit=TOP_VALUES_DEFAULT_LIMIT):
         """
         >>> get_top_group_tag_values(1, 2, 3, 'key1')
         """
@@ -400,14 +401,17 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def get_group_tag_keys_and_top_values(self, project_id, group_id, environment_id, keys=None, value_limit=TOP_VALUES_DEFAULT_LIMIT):
+    def get_group_tag_keys_and_top_values(
+            self, project_id, group_id, environment_id, keys=None, value_limit=TOP_VALUES_DEFAULT_LIMIT):
 
         # If keys is unspecified, we will grab all tag keys for this group.
         tag_keys = self.get_group_tag_keys(project_id, group_id, environment_id, keys=keys)
 
         for tk in tag_keys:
-            tk.top_values = self.get_top_group_tag_values(project_id, group_id, environment_id, tk.key, limit=value_limit)
+            tk.top_values = self.get_top_group_tag_values(
+                project_id, group_id, environment_id, tk.key, limit=value_limit)
             if tk.count is None:
-                tk.count = self.get_group_tag_value_count(project_id, group_id, environment_id, tk.key)
+                tk.count = self.get_group_tag_value_count(
+                    project_id, group_id, environment_id, tk.key)
 
         return tag_keys
diff --git a/src/sentry/utils/geo.py b/src/sentry/utils/geo.py
index f391522178..0d8d5baffe 100644
--- a/src/sentry/utils/geo.py
+++ b/src/sentry/utils/geo.py
@@ -10,19 +10,47 @@ logger = logging.getLogger(__name__)
 
 # default is no-op
 geo_by_addr = lambda ip: None
+rust_geoip = None
+
+
+def _init_geoip():
+    global geo_by_addr
+    try:
+        import GeoIP
+    except ImportError:
+        logger.warning("GeoIP module not available.")
+        return
 
-try:
-    import GeoIP
-except ImportError:
-    logger.warning("GeoIP module not available.")
-else:
     geoip_path = getattr(settings, 'GEOIP_PATH', None)
-    if geoip_path:
-        try:
-            geo_db = GeoIP.open(geoip_path, GeoIP.GEOIP_MEMORY_CACHE)
-        except Exception:
-            logger.warning("Error opening GeoIP database: %s" % geoip_path)
-        else:
-            geo_by_addr = geo_db.record_by_addr
-    else:
+    if not geoip_path:
         logger.warning("settings.GEOIP_PATH not configured.")
+        return
+
+    try:
+        geo_db = GeoIP.open(geoip_path, GeoIP.GEOIP_MEMORY_CACHE)
+    except Exception:
+        logger.warning("Error opening GeoIP database: %s" % geoip_path)
+        return
+
+    geo_by_addr = geo_db.record_by_addr
+
+
+def _init_geoip_rust():
+    global rust_geoip
+
+    geoip_path_mmdb = getattr(settings, 'GEOIP_PATH_MMDB', None)
+
+    if not geoip_path_mmdb:
+        logger.warning("No GeoIP MMDB database configured")
+        return
+
+    from semaphore.processing import GeoIpLookup
+
+    try:
+        rust_geoip = GeoIpLookup(geoip_path_mmdb)
+    except Exception:
+        logger.warning("Error opening GeoIP database in Rust: %s" % geoip_path_mmdb)
+
+
+_init_geoip()
+_init_geoip_rust()
