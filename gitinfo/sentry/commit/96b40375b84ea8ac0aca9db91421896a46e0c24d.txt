commit 96b40375b84ea8ac0aca9db91421896a46e0c24d
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Wed Jan 22 15:43:31 2020 -0800

    ref: Remove the Django Event model (#16558)
    
    ✂️

diff --git a/src/sentry/deletions/defaults/group.py b/src/sentry/deletions/defaults/group.py
index a81d68aa83..cad5fb988b 100644
--- a/src/sentry/deletions/defaults/group.py
+++ b/src/sentry/deletions/defaults/group.py
@@ -2,7 +2,8 @@ from __future__ import absolute_import, print_function
 
 import os
 from sentry import eventstore, nodestore
-from sentry.models import Event, EventAttachment, UserReport
+from sentry.eventstore.models import Event
+from sentry.models import EventAttachment, UserReport
 
 from ..base import BaseDeletionTask, BaseRelation, ModelDeletionTask, ModelRelation
 
diff --git a/src/sentry/migrations/0026_delete_event.py b/src/sentry/migrations/0026_delete_event.py
new file mode 100644
index 0000000000..cef164fa10
--- /dev/null
+++ b/src/sentry/migrations/0026_delete_event.py
@@ -0,0 +1,32 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.10.8 on 2020-01-21 19:40
+from __future__ import unicode_literals
+
+from django.db import migrations
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Adding indexes to large tables. These indexes should be created concurrently,
+    #   unfortunately we can't run migrations outside of a transaction until Django
+    #   1.10. So until then these should be run manually.
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = True
+
+
+    dependencies = [
+        ('sentry', '0025_organizationaccessrequest_requester'),
+    ]
+
+    operations = [
+        migrations.DeleteModel(
+            name='Event',
+        ),
+    ]
diff --git a/src/sentry/models/event.py b/src/sentry/models/event.py
index d0634e1bb8..3c64e974ba 100644
--- a/src/sentry/models/event.py
+++ b/src/sentry/models/event.py
@@ -5,24 +5,13 @@ import string
 
 from collections import OrderedDict
 from django.conf import settings
-from django.db import models
-from django.utils import timezone
 from django.utils.encoding import force_text
-from django.utils.translation import ugettext_lazy as _
 from hashlib import md5
 
 from semaphore.processing import StoreNormalizer
 
 from sentry import eventtypes
-from sentry.db.models import (
-    BoundedBigIntegerField,
-    BoundedIntegerField,
-    Model,
-    NodeData,
-    NodeField,
-    sane_repr,
-)
-from sentry.db.models.manager import BaseManager
+from sentry.db.models import NodeData
 from sentry.interfaces.base import get_interfaces
 from sentry.utils import json
 from sentry.utils.cache import memoize
@@ -376,61 +365,6 @@ class EventCommon(object):
         return trim(message.strip(), settings.SENTRY_MAX_MESSAGE_LENGTH)
 
 
-def ref_func(x):
-    return x.project_id or x.project.id
-
-
-class Event(EventCommon, Model):
-    """
-    An event backed by data stored in postgres.
-
-    """
-
-    __core__ = False
-
-    group_id = BoundedBigIntegerField(blank=True, null=True)
-    event_id = models.CharField(max_length=32, null=True, db_column="message_id")
-    project_id = BoundedBigIntegerField(blank=True, null=True)
-    message = models.TextField()
-    platform = models.CharField(max_length=64, null=True)
-    datetime = models.DateTimeField(default=timezone.now, db_index=True)
-    time_spent = BoundedIntegerField(null=True)
-    data = NodeField(
-        blank=True,
-        null=True,
-        ref_func=ref_func,
-        ref_version=2,
-        wrapper=EventDict,
-        skip_nodestore_save=True,
-    )
-
-    objects = BaseManager()
-
-    class Meta:
-        app_label = "sentry"
-        db_table = "sentry_message"
-        verbose_name = _("message")
-        verbose_name_plural = _("messages")
-        unique_together = (("project_id", "event_id"),)
-        index_together = (("group_id", "datetime"),)
-
-    __repr__ = sane_repr("project_id", "group_id")
-
-    def __getstate__(self):
-        state = Model.__getstate__(self)
-
-        # do not pickle cached info.  We want to fetch this on demand
-        # again.  In particular if we were to pickle interfaces we would
-        # pickle a CanonicalKeyView which old sentry workers do not know
-        # about
-        state.pop("_project_cache", None)
-        state.pop("_environment_cache", None)
-        state.pop("_group_cache", None)
-        state.pop("interfaces", None)
-
-        return state
-
-
 class EventSubjectTemplate(string.Template):
     idpattern = r"(tag:)?[_a-z][_a-z0-9]*"
 
diff --git a/tests/sentry/ingest/ingest_consumer/test_ingest_kafka.py b/tests/sentry/ingest/ingest_consumer/test_ingest_kafka.py
index 06ffb9cd72..4de4cd94e1 100644
--- a/tests/sentry/ingest/ingest_consumer/test_ingest_kafka.py
+++ b/tests/sentry/ingest/ingest_consumer/test_ingest_kafka.py
@@ -10,7 +10,6 @@ from django.conf import settings
 
 from sentry.event_manager import EventManager
 from sentry.ingest.ingest_consumer import ConsumerType, get_ingest_consumer
-from sentry.models.event import Event
 from sentry.utils import json
 from sentry.testutils.factories import Factories
 
@@ -59,6 +58,7 @@ def _shutdown_requested(max_secs, num_events):
     :param num_events: number of events after which to request a shutdown
     :return: True if a shutdown is requested False otherwise
     """
+    from sentry.models import Event
 
     def inner():
         end_time = time.time()
@@ -79,6 +79,8 @@ def _shutdown_requested(max_secs, num_events):
 def test_ingest_consumer_reads_from_topic_and_calls_celery_task(
     task_runner, kafka_producer, kafka_admin, requires_kafka
 ):
+    from sentry.models import Event
+
     group_id = "test-consumer"
     topic_event_name = ConsumerType.get_topic_name(ConsumerType.Events)
 
diff --git a/tests/sentry/ingest/ingest_consumer/test_ingest_processing.py b/tests/sentry/ingest/ingest_consumer/test_ingest_processing.py
index 4a6a0682d6..7d32472c10 100644
--- a/tests/sentry/ingest/ingest_consumer/test_ingest_processing.py
+++ b/tests/sentry/ingest/ingest_consumer/test_ingest_processing.py
@@ -13,7 +13,7 @@ from sentry.ingest.ingest_consumer import (
 )
 from sentry.attachments import attachment_cache
 from sentry.event_manager import EventManager
-from sentry.models import Event, EventAttachment, UserReport, EventUser
+from sentry.models import EventAttachment, UserReport, EventUser
 
 
 def get_normalized_event(data, project):
@@ -235,8 +235,6 @@ def test_userreport_reverse_order(default_project, monkeypatch):
     event_id = uuid.uuid4().hex
     start_time = time.time() - 3600
 
-    assert not Event.objects.all()
-
     assert process_userreport(
         {
             "type": "user_report",
