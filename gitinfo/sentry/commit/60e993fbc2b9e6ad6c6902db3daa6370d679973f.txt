commit 60e993fbc2b9e6ad6c6902db3daa6370d679973f
Author: Chris Fuller <cfuller@sentry.io>
Date:   Wed Feb 12 14:02:00 2020 -0500

    feat(workflow): Environment support for AlertRule (#16621)
    
    `environment` added to serializers to accept a list of environment names (and send it out)
    
    Snuba query now adds the environments to the query conditions.

diff --git a/src/sentry/api/serializers/models/alert_rule.py b/src/sentry/api/serializers/models/alert_rule.py
index 63b8a39cb6..419a9c8308 100644
--- a/src/sentry/api/serializers/models/alert_rule.py
+++ b/src/sentry/api/serializers/models/alert_rule.py
@@ -5,7 +5,12 @@ from collections import defaultdict
 import six
 
 from sentry.api.serializers import register, serialize, Serializer
-from sentry.incidents.models import AlertRule, AlertRuleExcludedProjects, AlertRuleTrigger
+from sentry.incidents.models import (
+    AlertRule,
+    AlertRuleExcludedProjects,
+    AlertRuleTrigger,
+    AlertRuleEnvironment,
+)
 from sentry.models import Rule
 
 
@@ -23,6 +28,15 @@ class AlertRuleSerializer(Serializer):
             )
             alert_rule_triggers.append(serialized)
 
+        alert_rule_environments = AlertRuleEnvironment.objects.select_related("environment").filter(
+            alert_rule__in=item_list
+        )
+        for are in alert_rule_environments:
+            alert_rule_environment = result[alert_rules[are.alert_rule.id]].setdefault(
+                "environment", []
+            )
+            alert_rule_environment.append(are.environment.name)
+
         return result
 
     def serialize(self, obj, attrs, user):
@@ -38,6 +52,7 @@ class AlertRuleSerializer(Serializer):
             "aggregation": obj.aggregation,
             "aggregations": [obj.aggregation],
             "timeWindow": obj.time_window,
+            "environment": attrs.get("environment", []),
             "resolution": obj.resolution,
             # TODO: Remove when frontend isn't using
             "alertThreshold": 0,
diff --git a/src/sentry/api/serializers/rest_framework/environment.py b/src/sentry/api/serializers/rest_framework/environment.py
new file mode 100644
index 0000000000..6a10b82923
--- /dev/null
+++ b/src/sentry/api/serializers/rest_framework/environment.py
@@ -0,0 +1,21 @@
+from __future__ import absolute_import
+
+from rest_framework import serializers
+
+from sentry.models import Environment
+
+ValidationError = serializers.ValidationError
+
+
+class EnvironmentField(serializers.Field):
+    def to_representation(self, value):
+        return value
+
+    def to_internal_value(self, data):
+        try:
+            environment = Environment.objects.get(
+                organization_id=self.context["organization"].id, name=data
+            )
+        except Environment.DoesNotExist:
+            raise ValidationError("Environment is not part of this organization")
+        return environment
diff --git a/src/sentry/incidents/endpoints/serializers.py b/src/sentry/incidents/endpoints/serializers.py
index dbf3b57645..9737138342 100644
--- a/src/sentry/incidents/endpoints/serializers.py
+++ b/src/sentry/incidents/endpoints/serializers.py
@@ -10,6 +10,7 @@ from rest_framework import serializers
 
 from sentry.api.serializers.rest_framework.base import CamelSnakeModelSerializer
 from sentry.api.serializers.rest_framework.project import ProjectField
+from sentry.api.serializers.rest_framework.environment import EnvironmentField
 from sentry.incidents.logic import (
     AlertRuleNameAlreadyUsedError,
     AlertRuleTriggerLabelAlreadyUsedError,
@@ -239,6 +240,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
      - `access`: An access object (from `request.access`)
     """
 
+    environment = serializers.ListField(child=EnvironmentField(), required=False)
     # TODO: These might be slow for many projects, since it will query for each
     # individually. If we find this to be a problem then we can look into batching.
     projects = serializers.ListField(child=ProjectField(), required=False)
@@ -251,6 +253,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
             "name",
             "query",
             "time_window",
+            "environment",
             "threshold_period",
             "aggregation",
             "projects",
@@ -375,9 +378,8 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
     def _remove_unchanged_fields(self, instance, validated_data):
         for field_name, value in list(six.iteritems(validated_data)):
             # Remove any fields that haven't actually changed
-            if field_name == "triggers":
-                continue  # No removal for triggers
-
+            if field_name == "triggers" or field_name == "environment":
+                continue  # No removal for triggers or environment
             if field_name == "projects":
                 project_slugs = Project.objects.filter(
                     querysubscription__alert_rules=instance
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index 35f975da83..1ff10ea695 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -16,6 +16,7 @@ from sentry.api.event_search import get_filter
 from sentry.incidents import tasks
 from sentry.incidents.models import (
     AlertRule,
+    AlertRuleEnvironment,
     AlertRuleExcludedProjects,
     AlertRuleQuerySubscription,
     AlertRuleStatus,
@@ -479,6 +480,10 @@ def bulk_get_incident_event_stats(incidents, query_params_list, data_points=50):
     ]
 
 
+def get_alert_rule_environment_names(alert_rule):
+    return [x.environment.name for x in AlertRuleEnvironment.objects.filter(alert_rule=alert_rule)]
+
+
 def get_incident_aggregates(incident):
     """
     Calculates aggregate stats across the life of an incident.
@@ -568,6 +573,7 @@ def create_alert_rule(
     aggregation,
     time_window,
     threshold_period,
+    environment=None,
     include_all_projects=False,
     excluded_projects=None,
     triggers=None,
@@ -583,6 +589,7 @@ def create_alert_rule(
     :param query: An event search query to subscribe to and monitor for alerts
     :param aggregation: A QueryAggregation to fetch for this alert rule
     :param time_window: Time period to aggregate over, in minutes
+    :param environment: List of environments that this rule applies to
     :param threshold_period: How many update periods the value of the
     subscription needs to exceed the threshold before triggering
     :param include_all_projects: Whether to include all current and future projects
@@ -610,6 +617,7 @@ def create_alert_rule(
             threshold_period=threshold_period,
             include_all_projects=include_all_projects,
         )
+
         if include_all_projects:
             excluded_projects = excluded_projects if excluded_projects else []
             projects = Project.objects.filter(organization=organization).exclude(
@@ -621,12 +629,16 @@ def create_alert_rule(
             ]
             AlertRuleExcludedProjects.objects.bulk_create(exclusions)
 
-        subscribe_projects_to_alert_rule(alert_rule, projects)
+        if environment:
+            for e in environment:
+                AlertRuleEnvironment.objects.create(alert_rule=alert_rule, environment=e)
 
         if triggers:
             for trigger_data in triggers:
                 create_alert_rule_trigger(alert_rule=alert_rule, **trigger_data)
 
+        subscribe_projects_to_alert_rule(alert_rule, projects)
+
     return alert_rule
 
 
@@ -637,6 +649,7 @@ def update_alert_rule(
     query=None,
     aggregation=None,
     time_window=None,
+    environment=None,
     threshold_period=None,
     include_all_projects=None,
     excluded_projects=None,
@@ -653,6 +666,7 @@ def update_alert_rule(
     :param query: An event search query to subscribe to and monitor for alerts
     :param aggregation: An AlertRuleAggregation that we want to fetch for this alert rule
     :param time_window: Time period to aggregate over, in minutes.
+    :param environment: List of environments that this rule applies to
     :param threshold_period: How many update periods the value of the
     subscription needs to exceed the threshold before triggering
     :param include_all_projects: Whether to include all current and future projects
@@ -753,18 +767,15 @@ def update_alert_rule(
             # values
             existing_subs = [sub for sub in existing_subs if sub.id]
 
-        if existing_subs and (
-            query is not None or aggregation is not None or time_window is not None
-        ):
-            # If updating any subscription details, update related Snuba subscriptions
-            # too
-            bulk_update_snuba_subscriptions(
-                existing_subs,
-                alert_rule.query,
-                QueryAggregations(alert_rule.aggregation),
-                timedelta(minutes=alert_rule.time_window),
-                timedelta(minutes=DEFAULT_ALERT_RULE_RESOLUTION),
-            )
+        if environment:
+            # Delete rows we don't have present in the updated data.
+            AlertRuleEnvironment.objects.filter(alert_rule=alert_rule).exclude(
+                environment__in=environment
+            ).delete()
+            for e in environment:
+                AlertRuleEnvironment.objects.get_or_create(alert_rule=alert_rule, environment=e)
+        else:
+            AlertRuleEnvironment.objects.filter(alert_rule=alert_rule).delete()
 
         if triggers is not None:
             # Delete triggers we don't have present in the updated data.
@@ -788,6 +799,20 @@ def update_alert_rule(
                         "This trigger label is already in use for this alert rule"
                     )
 
+        if existing_subs and (
+            query is not None or aggregation is not None or time_window is not None
+        ):
+            # If updating any subscription details, update related Snuba subscriptions
+            # too
+            bulk_update_snuba_subscriptions(
+                existing_subs,
+                alert_rule.query,
+                QueryAggregations(alert_rule.aggregation),
+                timedelta(minutes=alert_rule.time_window),
+                timedelta(minutes=DEFAULT_ALERT_RULE_RESOLUTION),
+                get_alert_rule_environment_names(alert_rule),
+            )
+
     return alert_rule
 
 
@@ -804,6 +829,7 @@ def subscribe_projects_to_alert_rule(alert_rule, projects):
         QueryAggregations(alert_rule.aggregation),
         timedelta(minutes=alert_rule.time_window),
         timedelta(minutes=alert_rule.resolution),
+        get_alert_rule_environment_names(alert_rule),
     )
     subscription_links = [
         AlertRuleQuerySubscription(query_subscription=subscription, alert_rule=alert_rule)
diff --git a/src/sentry/incidents/models.py b/src/sentry/incidents/models.py
index 5c21149437..99ff87d8a1 100644
--- a/src/sentry/incidents/models.py
+++ b/src/sentry/incidents/models.py
@@ -266,6 +266,18 @@ class AlertRuleManager(BaseManager):
         return self.filter(query_subscriptions__project=project)
 
 
+class AlertRuleEnvironment(Model):
+    __core__ = True
+
+    environment = FlexibleForeignKey("sentry.Environment")
+    alert_rule = FlexibleForeignKey("sentry.AlertRule")
+
+    class Meta:
+        app_label = "sentry"
+        db_table = "sentry_alertruleenvironment"
+        unique_together = (("alert_rule", "environment"),)
+
+
 class AlertRuleQuerySubscription(Model):
     __core__ = True
 
@@ -307,6 +319,9 @@ class AlertRule(Model):
     status = models.SmallIntegerField(default=AlertRuleStatus.PENDING.value)
     dataset = models.TextField()
     query = models.TextField()
+    environment = models.ManyToManyField(
+        "sentry.Environment", related_name="alert_rule_environment", through=AlertRuleEnvironment
+    )
     # Determines whether we include all current and future projects from this
     # organization in this rule.
     include_all_projects = models.BooleanField(default=False)
diff --git a/src/sentry/migrations/0035_auto_20200127_1711.py b/src/sentry/migrations/0035_auto_20200127_1711.py
new file mode 100644
index 0000000000..e1a6807cf0
--- /dev/null
+++ b/src/sentry/migrations/0035_auto_20200127_1711.py
@@ -0,0 +1,52 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.11.27 on 2020-01-27 17:11
+from __future__ import unicode_literals
+
+from django.db import migrations, models
+import django.db.models.deletion
+import sentry.db.models.fields.bounded
+import sentry.db.models.fields.foreignkey
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Adding indexes to large tables. These indexes should be created concurrently,
+    #   unfortunately we can't run migrations outside of a transaction until Django
+    #   1.10. So until then these should be run manually.
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = True
+
+
+    dependencies = [
+        ('sentry', '0034_auto_20200210_2311'),
+    ]
+
+    operations = [
+        migrations.CreateModel(
+            name='AlertRuleEnvironment',
+            fields=[
+                ('id', sentry.db.models.fields.bounded.BoundedBigAutoField(primary_key=True, serialize=False)),
+                ('alert_rule', sentry.db.models.fields.foreignkey.FlexibleForeignKey(on_delete=django.db.models.deletion.CASCADE, to='sentry.AlertRule')),
+                ('environment', sentry.db.models.fields.foreignkey.FlexibleForeignKey(on_delete=django.db.models.deletion.CASCADE, to='sentry.Environment')),
+            ],
+            options={
+                'db_table': 'sentry_alertruleenvironment',
+            },
+        ),
+        migrations.AddField(
+            model_name='alertrule',
+            name='environment',
+            field=models.ManyToManyField(related_name='alert_rule_environment', through='sentry.AlertRuleEnvironment', to='sentry.Environment'),
+        ),
+        migrations.AlterUniqueTogether(
+            name='alertruleenvironment',
+            unique_together=set([('alert_rule', 'environment')]),
+        ),
+    ]
diff --git a/src/sentry/snuba/subscriptions.py b/src/sentry/snuba/subscriptions.py
index f176c8d259..dc93368d29 100644
--- a/src/sentry/snuba/subscriptions.py
+++ b/src/sentry/snuba/subscriptions.py
@@ -16,7 +16,14 @@ query_aggregation_to_snuba = {
 
 
 def bulk_create_snuba_subscriptions(
-    projects, subscription_type, dataset, query, aggregation, time_window, resolution
+    projects,
+    subscription_type,
+    dataset,
+    query,
+    aggregation,
+    time_window,
+    resolution,
+    environment_names,
 ):
     """
     Creates a subscription to a snuba query for each project.
@@ -30,6 +37,7 @@ def bulk_create_snuba_subscriptions(
     :param aggregation: An aggregation to calculate over the time window
     :param time_window: The time window to aggregate over
     :param resolution: How often to receive updates/bucket size
+    :param environment_names: List of environment names to filter by
     :return: A list of QuerySubscriptions
     """
     subscriptions = []
@@ -37,14 +45,28 @@ def bulk_create_snuba_subscriptions(
     for project in projects:
         subscriptions.append(
             create_snuba_subscription(
-                project, subscription_type, dataset, query, aggregation, time_window, resolution
+                project,
+                subscription_type,
+                dataset,
+                query,
+                aggregation,
+                time_window,
+                resolution,
+                environment_names,
             )
         )
     return subscriptions
 
 
 def create_snuba_subscription(
-    project, subscription_type, dataset, query, aggregation, time_window, resolution
+    project,
+    subscription_type,
+    dataset,
+    query,
+    aggregation,
+    time_window,
+    resolution,
+    environment_names,
 ):
     """
     Creates a subscription to a snuba query.
@@ -58,13 +80,14 @@ def create_snuba_subscription(
     :param aggregation: An aggregation to calculate over the time window
     :param time_window: The time window to aggregate over
     :param resolution: How often to receive updates/bucket size
+    :param environment_names: List of environment names to filter by
     :return: The QuerySubscription representing the subscription
     """
     # TODO: Move this call to snuba into a task. This lets us successfully create a
     # subscription in postgres and rollback as needed without having to create/delete
     # from Snuba
     subscription_id = _create_in_snuba(
-        project, dataset, query, aggregation, time_window, resolution
+        project, dataset, query, aggregation, time_window, resolution, environment_names
     )
 
     return QuerySubscription.objects.create(
@@ -79,7 +102,9 @@ def create_snuba_subscription(
     )
 
 
-def bulk_update_snuba_subscriptions(subscriptions, query, aggregation, time_window, resolution):
+def bulk_update_snuba_subscriptions(
+    subscriptions, query, aggregation, time_window, resolution, environment_names
+):
     """
     Updates a list of query subscriptions.
 
@@ -89,18 +114,23 @@ def bulk_update_snuba_subscriptions(subscriptions, query, aggregation, time_wind
     :param aggregation: An aggregation to calculate over the time window
     :param time_window: The time window to aggregate over
     :param resolution: How often to receive updates/bucket size
+    :param environment_names: List of environment names to filter by
     :return: A list of QuerySubscriptions
     """
     updated_subscriptions = []
     # TODO: Batch this up properly once we move to tasks.
     for subscription in subscriptions:
         updated_subscriptions.append(
-            update_snuba_subscription(subscription, query, aggregation, time_window, resolution)
+            update_snuba_subscription(
+                subscription, query, aggregation, time_window, resolution, environment_names
+            )
         )
     return subscriptions
 
 
-def update_snuba_subscription(subscription, query, aggregation, time_window, resolution):
+def update_snuba_subscription(
+    subscription, query, aggregation, time_window, resolution, environment_names
+):
     """
     Updates a subscription to a snuba query.
 
@@ -109,6 +139,7 @@ def update_snuba_subscription(subscription, query, aggregation, time_window, res
     :param aggregation: An aggregation to calculate over the time window
     :param time_window: The time window to aggregate over
     :param resolution: How often to receive updates/bucket size
+    :param environment_names: List of environment names to filter by
     :return: The QuerySubscription representing the subscription
     """
     # TODO: Move this call to snuba into a task. This lets us successfully update a
@@ -122,6 +153,7 @@ def update_snuba_subscription(subscription, query, aggregation, time_window, res
         aggregation,
         time_window,
         resolution,
+        environment_names,
     )
     subscription.update(
         subscription_id=subscription_id,
@@ -158,7 +190,14 @@ def delete_snuba_subscription(subscription):
         _delete_from_snuba(subscription)
 
 
-def _create_in_snuba(project, dataset, query, aggregation, time_window, resolution):
+def _create_in_snuba(
+    project, dataset, query, aggregation, time_window, resolution, environment_names
+):
+    conditions = resolve_discover_aliases({"conditions": get_filter(query).conditions})[0][
+        "conditions"
+    ]
+    if environment_names:
+        conditions.append(["environment", "IN", environment_names])
     response = _snuba_pool.urlopen(
         "POST",
         "/%s/subscriptions" % (dataset.value,),
@@ -169,9 +208,7 @@ def _create_in_snuba(project, dataset, query, aggregation, time_window, resoluti
                 # We only care about conditions here. Filter keys only matter for
                 # filtering to project and groups. Projects are handled with an
                 # explicit param, and groups can't be queried here.
-                "conditions": resolve_discover_aliases(
-                    {"conditions": get_filter(query).conditions}
-                )[0]["conditions"],
+                "conditions": conditions,
                 "aggregations": [query_aggregation_to_snuba[aggregation]],
                 "time_window": int(time_window.total_seconds()),
                 "resolution": int(resolution.total_seconds()),
diff --git a/src/sentry/static/sentry/app/views/settings/incidentRules/constants.tsx b/src/sentry/static/sentry/app/views/settings/incidentRules/constants.tsx
index f0932e57a9..c128325585 100644
--- a/src/sentry/static/sentry/app/views/settings/incidentRules/constants.tsx
+++ b/src/sentry/static/sentry/app/views/settings/incidentRules/constants.tsx
@@ -25,5 +25,6 @@ export function createDefaultRule(): UnsavedIncidentRule {
     timeWindow: 1,
     triggers: [createDefaultTrigger()],
     projects: [],
+    environment: [],
   };
 }
diff --git a/src/sentry/static/sentry/app/views/settings/incidentRules/ruleConditionsForm.tsx b/src/sentry/static/sentry/app/views/settings/incidentRules/ruleConditionsForm.tsx
index ab55103c30..2788a9264a 100644
--- a/src/sentry/static/sentry/app/views/settings/incidentRules/ruleConditionsForm.tsx
+++ b/src/sentry/static/sentry/app/views/settings/incidentRules/ruleConditionsForm.tsx
@@ -5,6 +5,7 @@ import {Environment, Organization} from 'app/types';
 import {Panel, PanelBody, PanelHeader} from 'app/components/panels';
 import {addErrorMessage} from 'app/actionCreators/indicator';
 import {defined} from 'app/utils';
+import {getDisplayName} from 'app/utils/environment';
 import {t} from 'app/locale';
 import FormField from 'app/views/settings/components/forms/formField';
 import SearchBar from 'app/views/events/searchBar';
@@ -96,10 +97,14 @@ class RuleConditionsForm extends React.PureComponent<Props, State> {
             placeholder={t('All environments')}
             choices={
               defined(this.state.environments)
-                ? this.state.environments.map((env: Environment) => [env.id, env.name])
+                ? this.state.environments.map((env: Environment) => [
+                    env.name,
+                    getDisplayName(env),
+                  ])
                 : []
             }
             disabled={this.state.environments === null}
+            multiple
             isClearable
           />
           <FormField
diff --git a/src/sentry/static/sentry/app/views/settings/incidentRules/ruleForm/index.tsx b/src/sentry/static/sentry/app/views/settings/incidentRules/ruleForm/index.tsx
index a83c80eb5c..d7ae637865 100644
--- a/src/sentry/static/sentry/app/views/settings/incidentRules/ruleForm/index.tsx
+++ b/src/sentry/static/sentry/app/views/settings/incidentRules/ruleForm/index.tsx
@@ -403,6 +403,7 @@ class RuleFormContainer extends AsyncComponent<Props, State> {
               aggregation: rule.aggregation,
               query: rule.query || '',
               timeWindow: rule.timeWindow,
+              environment: rule.environment || [],
             }}
             saveOnBlur={false}
             onSubmit={this.handleSubmit}
diff --git a/src/sentry/static/sentry/app/views/settings/incidentRules/types.tsx b/src/sentry/static/sentry/app/views/settings/incidentRules/types.tsx
index b9c5f200b9..f10da43ae5 100644
--- a/src/sentry/static/sentry/app/views/settings/incidentRules/types.tsx
+++ b/src/sentry/static/sentry/app/views/settings/incidentRules/types.tsx
@@ -43,6 +43,7 @@ export type UnsavedIncidentRule = {
   aggregation: AlertRuleAggregations;
   aggregations: AlertRuleAggregations[];
   projects: string[];
+  environment: string[];
   query: string;
   timeWindow: number;
   triggers: Trigger[];
diff --git a/src/sentry/static/sentry/app/views/settings/projectAlerts/issueEditor/index.tsx b/src/sentry/static/sentry/app/views/settings/projectAlerts/issueEditor/index.tsx
index 5005db0c79..d0dd5a586f 100644
--- a/src/sentry/static/sentry/app/views/settings/projectAlerts/issueEditor/index.tsx
+++ b/src/sentry/static/sentry/app/views/settings/projectAlerts/issueEditor/index.tsx
@@ -285,6 +285,7 @@ class IssueRuleEditor extends React.Component<Props, State> {
                 value={environment}
                 choices={environmentChoices}
                 onChange={val => this.handleEnvironmentChange(val)}
+                multiple
               />
 
               <PanelSubHeader>
diff --git a/tests/sentry/incidents/endpoints/test_serializers.py b/tests/sentry/incidents/endpoints/test_serializers.py
index ab1d1d163c..60b510d966 100644
--- a/tests/sentry/incidents/endpoints/test_serializers.py
+++ b/tests/sentry/incidents/endpoints/test_serializers.py
@@ -18,8 +18,12 @@ from sentry.incidents.logic import (
     create_alert_rule_trigger_action,
     InvalidTriggerActionError,
 )
-from sentry.incidents.models import AlertRuleThresholdType, AlertRuleTriggerAction
-from sentry.models import Integration
+from sentry.incidents.models import (
+    AlertRuleThresholdType,
+    AlertRuleTriggerAction,
+    AlertRuleEnvironment,
+)
+from sentry.models import Integration, Environment
 from sentry.snuba.models import QueryAggregations
 from sentry.testutils import TestCase
 
@@ -93,6 +97,62 @@ class TestAlertRuleSerializer(TestCase):
             "triggers": field_is_required,
         }
 
+    def test_environment(self):
+        base_params = self.valid_params.copy()
+        env_1 = Environment.objects.create(organization_id=self.organization.id, name="test_env_1")
+        env_2 = Environment.objects.create(organization_id=self.organization.id, name="test_env_2")
+
+        base_params.update({"environment": [env_1.name]})
+        serializer = AlertRuleSerializer(context=self.context, data=base_params)
+        assert serializer.is_valid()
+        alert_rule = serializer.save()
+
+        # Make sure AlertRuleEnvironment entry was made:
+        alert_rule_env = AlertRuleEnvironment.objects.get(
+            environment=env_1.id, alert_rule=alert_rule
+        )
+        assert alert_rule_env
+
+        base_params.update({"id": alert_rule.id})
+        base_params.update({"environment": [env_1.name, env_2.name]})
+        serializer = AlertRuleSerializer(
+            context=self.context, instance=alert_rule, data=base_params
+        )
+        assert serializer.is_valid()
+        serializer.save()
+
+        assert len(AlertRuleEnvironment.objects.filter(alert_rule=alert_rule)) == 2
+
+        base_params.update({"environment": [env_2.name]})
+        serializer = AlertRuleSerializer(
+            context=self.context, instance=alert_rule, data=base_params
+        )
+        assert serializer.is_valid()
+        serializer.save()
+
+        # Make sure env_1 AlertRuleEnvironment was deleted:
+        try:
+            alert_rule_env = AlertRuleEnvironment.objects.get(
+                environment=env_1.id, alert_rule=alert_rule
+            )
+            assert False
+        except AlertRuleEnvironment.DoesNotExist:
+            assert True
+        # And that env_2 is still present:
+        assert len(AlertRuleEnvironment.objects.filter(alert_rule=alert_rule)) == 1
+        assert (
+            len(AlertRuleEnvironment.objects.filter(environment=env_2.id, alert_rule=alert_rule))
+            == 1
+        )
+
+        base_params.update({"environment": []})
+        serializer = AlertRuleSerializer(
+            context=self.context, instance=alert_rule, data=base_params
+        )
+        assert serializer.is_valid()
+        serializer.save()
+        assert len(AlertRuleEnvironment.objects.filter(alert_rule=alert_rule)) == 0
+
     def test_time_window(self):
         self.run_fail_validation_test(
             {"timeWindow": "a"}, {"timeWindow": ["A valid integer is required."]}
diff --git a/tests/sentry/snuba/test_subscriptions.py b/tests/sentry/snuba/test_subscriptions.py
index c4c031f58a..8bc0484716 100644
--- a/tests/sentry/snuba/test_subscriptions.py
+++ b/tests/sentry/snuba/test_subscriptions.py
@@ -21,7 +21,7 @@ class CreateSnubaSubscriptionTest(TestCase):
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
         subscription = create_snuba_subscription(
-            self.project, type, dataset, query, aggregation, time_window, resolution
+            self.project, type, dataset, query, aggregation, time_window, resolution, []
         )
         assert subscription.project == self.project
         assert subscription.type == type
@@ -40,7 +40,7 @@ class CreateSnubaSubscriptionTest(TestCase):
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
         subscription = create_snuba_subscription(
-            self.project, type, dataset, query, aggregation, time_window, resolution
+            self.project, type, dataset, query, aggregation, time_window, resolution, []
         )
         assert subscription.project == self.project
         assert subscription.type == type
@@ -62,6 +62,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             QueryAggregations.TOTAL,
             timedelta(minutes=10),
             timedelta(minutes=1),
+            [],
         )
 
         query = "level:warning"
@@ -69,7 +70,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
         time_window = timedelta(minutes=20)
         resolution = timedelta(minutes=2)
         old_subscription_id = subscription.subscription_id
-        update_snuba_subscription(subscription, query, aggregation, time_window, resolution)
+        update_snuba_subscription(subscription, query, aggregation, time_window, resolution, [])
         assert subscription.subscription_id != old_subscription_id
         assert subscription.query == query
         assert subscription.aggregation == aggregation.value
@@ -87,6 +88,7 @@ class BulkDeleteSnubaSubscriptionTest(TestCase):
             QueryAggregations.TOTAL,
             timedelta(minutes=10),
             timedelta(minutes=1),
+            [],
         )
         other_subscription = create_snuba_subscription(
             self.create_project(organization=self.organization),
@@ -96,6 +98,7 @@ class BulkDeleteSnubaSubscriptionTest(TestCase):
             QueryAggregations.TOTAL,
             timedelta(minutes=10),
             timedelta(minutes=1),
+            [],
         )
         subscription_ids = [subscription.id, other_subscription.id]
         bulk_delete_snuba_subscriptions([subscription, other_subscription])
@@ -112,6 +115,7 @@ class DeleteSnubaSubscriptionTest(TestCase):
             QueryAggregations.TOTAL,
             timedelta(minutes=10),
             timedelta(minutes=1),
+            [],
         )
         subscription_id = subscription.id
         delete_snuba_subscription(subscription)
