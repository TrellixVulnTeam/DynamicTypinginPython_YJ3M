commit f25ea5dcb79c770ab8d42116cdae1e5656151ef6
Author: MeredithAnya <meredith.a.heller@gmail.com>
Date:   Wed May 6 11:58:46 2020 -0700

    fix(api-doc-generator): Get it working again! (#16911)
    
    This PR, along with https://github.com/getsentry/sentry-docs/pull/1567/files, make the API doc generator work again.
    
    ## Why did it stop working?
    We had two big problems:
    1. Snuba was not being spun up and it is a required part of our infrastructure. So, some things stopped working.
    1. Since [this](https://github.com/getsentry/sentry/pull/13941/files) PR, we have nested routes. We were not traversing nested URLs.
    
    ## How does it work now?
    To run the API doc generator, you need to do the following steps (after https://github.com/getsentry/sentry-docs/pull/1567 has been merged):
    1. Clone sentry-docs
    1. Run `bin/update-api-docs`
    
    This will create a docker container and clone sentry inside it. Then, it'll run `generator.py` from this repo.
    
    `generator.py` will pull and run the following docker containers:
    1. Postgres
    1. Redis
    1. Clickhouse
    1. Snuba
    1. Relay
    1. Relay reverse proxy
    
    Wait, wait. Did you just say docker inside docker? Indeed. It allows us to keep all of sentry's dependencies in sentry (cause you're not spinning up Snuba from sentry-docs).
    
    Once we have all the docker containers spun up, `generator.py` will traverse through all the endpoints and run all the API scenarios. Then, it'll generate json and markdown files, which `bin/update-api-docs` will copy over into sentry-docs.
    
    ## Scope
    At this time, we're just trying to get the API doc generator working. There are a few problems in the generator that I have not fixed. Here's some problems:
    1. There is a scenario that returns a 500. [It used to return a 500](https://docs.sentry.io/api/projects/delete-project-details/). It continues to return a 500.
    2. There is another scenario that returns a 404. [It used to return a 404](https://docs.sentry.io/api/releases/put-organization-release-details/). It continues to return a 404.
    
    I'll make tickets to fix these too.

diff --git a/api-docs/generator.py b/api-docs/generator.py
index f44c326685..85b73942a5 100644
--- a/api-docs/generator.py
+++ b/api-docs/generator.py
@@ -1,40 +1,135 @@
+#!/usr/bin/env python2.7
 from __future__ import absolute_import
 
-import os
-import zlib
-import json
 import click
-import logging
+import docker
+import json
+import os
 import six
-
+import zlib
 from datetime import datetime
-from subprocess import Popen, PIPE, check_output
-from six.moves.urllib.parse import urlparse
+from contextlib import contextmanager
+from sentry.runner.commands.devservices import get_docker_client, get_or_create
+from sentry.utils.apidocs import MockUtils, iter_scenarios, iter_endpoints, get_sections
+from sentry.utils.integrationdocs import sync_docs
+from sentry.conf.server import SENTRY_DEVSERVICES
+from subprocess import Popen
 
 HERE = os.path.abspath(os.path.dirname(__file__))
+OUTPUT_PATH = "/usr/src/output"
 SENTRY_CONFIG = os.environ["SENTRY_CONF"] = os.path.join(HERE, "sentry.conf.py")
 os.environ["SENTRY_SKIP_BACKEND_VALIDATION"] = "1"
 
-# No sentry or django imports before this point
-from sentry.runner import configure
-
-configure()
-from django.conf import settings
-
-# Fair game from here
-from django.core.management import call_command
+client = get_docker_client()
+
+# Use a unique network and namespace for our apidocs
+namespace = "apidocs"
+
+# Define our set of containers we want to run
+APIDOC_CONTAINERS = ["postgres", "redis", "clickhouse", "snuba", "relay", "reverse_proxy"]
+devservices_settings = {
+    container_name: SENTRY_DEVSERVICES[container_name] for container_name in APIDOC_CONTAINERS
+}
+
+apidoc_containers_overrides = {
+    "postgres": {"environment": {"POSTGRES_DB": "sentry_api_docs"}, "volumes": None},
+    "redis": {"volumes": None},
+    "clickhouse": {"ports": None, "volumes": None, "only_if": None},
+    "snuba": {
+        "pull": None,
+        "command": ["devserver", "--no-workers"],
+        "environment": {
+            "CLICKHOUSE_HOST": namespace + "_clickhouse",
+            "DEFAULT_BROKERS": None,
+            "REDIS_HOST": namespace + "_redis",
+        },
+        "volumes": None,
+        "only_if": None,
+    },
+    "relay": {"pull": None, "volumes": None, "only_if": None, "with_devserver": None},
+    "reverse_proxy": {"volumes": None, "only_if": None, "with_devserver": None},
+}
+
+
+def deep_merge(defaults, overrides):
+    """
+    Deep merges two dictionaries.
 
-from sentry.utils.apidocs import Runner, MockUtils, iter_scenarios, iter_endpoints, get_sections
-from sentry.web.helpers import render_to_string
+    If the value is None in `overrides`, that key-value pair will not show up in the final result.
+    """
+    merged = {}
+    for key in defaults:
+        if isinstance(defaults[key], dict):
+            if key not in overrides:
+                merged[key] = defaults[key]
+            elif overrides[key] is None:
+                continue
+            elif isinstance(overrides[key], dict):
+                merged[key] = deep_merge(defaults[key], overrides[key])
+            else:
+                raise Exception("Types must match")
+        elif key in overrides and overrides[key] is None:
+            continue
+        elif key in overrides:
+            merged[key] = overrides[key]
+        else:
+            merged[key] = defaults[key]
+    return merged
+
+
+@contextmanager
+def apidoc_containers():
+    network = get_or_create(client, "network", namespace)
+
+    containers = deep_merge(devservices_settings, apidoc_containers_overrides)
+
+    # Massage our list into some shared settings instead of repeating
+    # it for each definition.
+    for name, options in containers.items():
+        options["network"] = namespace
+        options["detach"] = True
+        options["name"] = namespace + "_" + name
+        containers[name] = options
+
+    # Pull all of our unique images once.
+    pulled = set()
+
+    for name, options in containers.items():
+        if options["image"] not in pulled:
+            click.secho("> Pulling image '%s'" % options["image"], err=True, fg="green")
+            client.images.pull(options["image"])
+            pulled.add(options["image"])
+
+    # Run each of our containers, if found running already, delete first
+    # and create new. We never want to reuse.
+    for name, options in containers.items():
+        try:
+            container = client.containers.get(options["name"])
+        except docker.errors.NotFound:
+            pass
+        else:
+            container.stop()
+            container.remove()
 
+        click.secho("> Creating '%s' container" % options["name"], err=True, fg="yellow")
+        client.containers.run(**options)
 
-OUTPUT_PATH = os.path.join(HERE, "cache")
-HOST = urlparse(settings.SENTRY_OPTIONS["system.url-prefix"]).netloc
+    yield
 
+    # Delete all of our containers now. If it's not running, do nothing.
+    for name, options in containers.items():
+        try:
+            container = client.containers.get(options["name"])
+        except docker.errors.NotFound:
+            pass
+        else:
+            click.secho("> Removing '%s' container" % container.name, err=True, fg="red")
+            container.stop()
+            container.remove()
 
-# We don't care about you, go away
-_logger = logging.getLogger("sentry.events")
-_logger.disabled = True
+    # Remove our network that we created.
+    click.secho("> Removing '%s' network" % network.name, err=True, fg="red")
+    network.remove()
 
 
 def color_for_string(s):
@@ -51,76 +146,9 @@ def report(category, message, fg=None):
     )
 
 
-def launch_redis():
-    report("redis", "Launching redis server")
-    cl = Popen(["redis-server", "-"], stdin=PIPE, stdout=open(os.devnull, "r+"))
-    cl.stdin.write(
-        """
-    port %(port)s
-    databases %(databases)d
-    save ""
-    """
-        % {"port": six.text_type(settings.SENTRY_APIDOCS_REDIS_PORT), "databases": 4}
-    )
-    cl.stdin.flush()
-    cl.stdin.close()
-    return cl
-
-
-def spawn_sentry():
-    report("sentry", "Launching sentry server")
-    cl = Popen(
-        [
-            "sentry",
-            "--config=" + SENTRY_CONFIG,
-            "run",
-            "web",
-            "-w",
-            "1",
-            "--bind",
-            "127.0.0.1:%s" % settings.SENTRY_APIDOCS_WEB_PORT,
-        ]
-    )
-    return cl
-
-
-def init_db():
-    drop_db()
-    report("db", "Migrating database (this can take some time)")
-    call_command("syncdb", migrate=True, interactive=False, traceback=True, verbosity=0)
-
-
-def drop_db():
-    report("db", "Dropping database")
-    config = settings.DATABASES["default"]
-    check_output(["dropdb", "-U", config["USER"], "-h", config["HOST"], config["NAME"]])
-    check_output(["createdb", "-U", config["USER"], "-h", config["HOST"], config["NAME"]])
-
-
-class SentryBox(object):
-    def __init__(self):
-        self.redis = None
-        self.sentry = None
-        self.task_runner = None
-
-    def __enter__(self):
-        self.redis = launch_redis()
-        self.sentry = spawn_sentry()
-        init_db()
-        return self
-
-    def __exit__(self, exc_type, exc_value, tb):
-        if self.sentry is not None:
-            report("sentry", "Shutting down sentry server")
-            self.sentry.kill()
-            self.sentry.wait()
-        if self.redis is not None:
-            report("redis", "Stopping redis server")
-            self.redis.kill()
-            self.redis.wait()
-
-
 def run_scenario(vars, scenario_ident, func):
+    from sentry.utils.apidocs import Runner
+
     runner = Runner(scenario_ident, func, **vars)
     report("scenario", 'Running scenario "%s"' % scenario_ident)
     func(runner)
@@ -131,11 +159,40 @@ def run_scenario(vars, scenario_ident, func):
 @click.option("--output-path", type=click.Path())
 @click.option("--output-format", type=click.Choice(["json", "markdown", "both"]), default="both")
 def cli(output_path, output_format):
-    """API docs dummy generator."""
     global OUTPUT_PATH
     if output_path is not None:
         OUTPUT_PATH = os.path.abspath(output_path)
-    with SentryBox():
+
+    with apidoc_containers():
+        from sentry.runner import configure
+
+        configure()
+
+        sentry = Popen(
+            [
+                "sentry",
+                "--config=" + SENTRY_CONFIG,
+                "run",
+                "web",
+                "-w",
+                "1",
+                "--bind",
+                "127.0.0.1:9000",
+            ]
+        )
+
+        from django.core.management import call_command
+
+        call_command(
+            "migrate",
+            interactive=False,
+            traceback=True,
+            verbosity=0,
+            migrate=True,
+            merge=True,
+            ignore_ghost_migrations=True,
+        )
+
         utils = MockUtils()
         report("org", "Creating user and organization")
         user = utils.create_user("john@interstellar.invalid")
@@ -158,6 +215,12 @@ def cli(output_path, output_format):
             event2 = utils.create_event(project=project, release=release, platform="java")
             projects.append({"project": project, "release": release, "events": [event1, event2]})
 
+        # HACK: the scenario in ProjectDetailsEndpoint#put requires our integration docs to be in place
+        # so that we can validate the platform. We create the docker container that runs generator.py
+        # with SENTRY_LIGHT_BUILD=1, which doesn't run `sync_docs` and `sync_docs` requires sentry
+        # to be configured, which we do in this file. So, we need to do the sync_docs here.
+        sync_docs(quiet=True)
+
         vars = {
             "org": org,
             "me": user,
@@ -184,6 +247,11 @@ def cli(output_path, output_format):
         if output_format in ("markdown", "both"):
             output_markdown(sections, scenario_map, section_mapping)
 
+    if sentry is not None:
+        report("sentry", "Shutting down sentry server")
+        sentry.kill()
+        sentry.wait()
+
 
 def output_json(sections, scenarios, section_mapping):
     report("docs", "Generating JSON documents")
@@ -204,12 +272,19 @@ def output_json(sections, scenarios, section_mapping):
 
 def output_markdown(sections, scenarios, section_mapping):
     report("docs", "Generating markdown documents")
+
+    # With nested URLs, we can have groups of URLs that are nested under multiple base URLs. We only want
+    # them to show up once in the index.md. So, keep a set of endpoints we have already processed
+    # to avoid duplication.
+    processed_endpoints = set()
+
     for section, title in sections.items():
         i = 0
         links = []
         for endpoint in section_mapping.get(section, []):
             i += 1
             path = u"{}/{}.md".format(section, endpoint["endpoint_name"])
+
             auth = ""
             if len(endpoint["params"].get("auth", [])):
                 auth = endpoint["params"]["auth"][0]["description"]
@@ -229,7 +304,9 @@ def output_markdown(sections, scenarios, section_mapping):
             )
             dump_markdown(path, payload)
 
-            links.append({"title": endpoint["title"], "path": path})
+            if path not in processed_endpoints:
+                links.append({"title": endpoint["title"], "path": path})
+                processed_endpoints.add(path)
         dump_index_markdown(section, title, links)
 
 
@@ -245,6 +322,8 @@ def dump_json(path, data):
 
 
 def dump_index_markdown(section, title, links):
+    from sentry.web.helpers import render_to_string
+
     path = os.path.join(OUTPUT_PATH, "markdown", section, "index.md")
     try:
         os.makedirs(os.path.dirname(path))
diff --git a/api-docs/sentry.conf.py b/api-docs/sentry.conf.py
index 85bb23d7c8..bc8b6b5eb9 100644
--- a/api-docs/sentry.conf.py
+++ b/api-docs/sentry.conf.py
@@ -4,10 +4,6 @@ from sentry.conf.server import *
 import os
 import getpass
 
-
-SENTRY_APIDOCS_REDIS_PORT = 12355
-SENTRY_APIDOCS_WEB_PORT = 12356
-
 SENTRY_URL_PREFIX = "https://sentry.io"
 
 # Unsupported here
@@ -24,6 +20,7 @@ DATABASES = {
         "USER": "postgres",
         "PASSWORD": "",
         "HOST": "127.0.0.1",
+        "PORT": "",
     }
 }
 SENTRY_USE_BIG_INTS = True
@@ -31,17 +28,18 @@ SENTRY_USE_BIG_INTS = True
 SENTRY_CACHE = "sentry.cache.redis.RedisCache"
 
 CELERY_ALWAYS_EAGER = True
-BROKER_URL = "redis://127.0.0.1:%s" % SENTRY_APIDOCS_REDIS_PORT
 
 SENTRY_RATELIMITER = "sentry.ratelimits.redis.RedisRateLimiter"
 SENTRY_BUFFER = "sentry.buffer.redis.RedisBuffer"
 SENTRY_QUOTAS = "sentry.quotas.redis.RedisQuota"
-SENTRY_TSDB = "sentry.tsdb.redis.RedisTSDB"
+SENTRY_TSDB = "sentry.tsdb.redissnuba.RedisSnubaTSDB"
+SENTRY_SEARCH = "sentry.search.snuba.EventsDatasetSnubaSearchBackend"
+SENTRY_EVENTSTREAM = "sentry.eventstream.snuba.SnubaEventStream"
 
 LOGIN_REDIRECT_URL = SENTRY_URL_PREFIX + "/"
-
+SENTRY_USE_RELAY = True
 SENTRY_WEB_HOST = "127.0.0.1"
-SENTRY_WEB_PORT = SENTRY_APIDOCS_WEB_PORT
+SENTRY_APIDOCS_WEB_PORT = SENTRY_WEB_PORT
 SENTRY_WEB_OPTIONS = {
     "workers": 1,
     "limit_request_line": 0,
@@ -50,9 +48,6 @@ SENTRY_WEB_OPTIONS = {
 
 SENTRY_OPTIONS.update(
     {
-        "redis.clusters": {
-            "default": {"hosts": {i: {"port": SENTRY_APIDOCS_REDIS_PORT} for i in range(0, 4)}}
-        },
         "system.secret-key": "super secret secret key",
         "system.admin-email": "admin@sentry.io",
         "system.url-prefix": SENTRY_URL_PREFIX,
diff --git a/src/sentry/api/endpoints/organization_users.py b/src/sentry/api/endpoints/organization_users.py
index 5ef6a9d390..441df35c4d 100644
--- a/src/sentry/api/endpoints/organization_users.py
+++ b/src/sentry/api/endpoints/organization_users.py
@@ -2,14 +2,35 @@ from __future__ import absolute_import
 
 from rest_framework.response import Response
 
+from sentry.api.base import DocSection, EnvironmentMixin
 from sentry.api.bases.organization import OrganizationEndpoint
 from sentry.api.serializers import serialize
 from sentry.api.serializers.models import OrganizationMemberWithProjectsSerializer
 from sentry.models import OrganizationMember
+from sentry.utils.apidocs import scenario, attach_scenarios
 
 
-class OrganizationUsersEndpoint(OrganizationEndpoint):
+@scenario("ListOrganizationUsers")
+def list_organization_users_scenario(runner):
+    runner.request(method="GET", path="/organizations/%s/users/" % runner.org.slug)
+
+
+class OrganizationUsersEndpoint(OrganizationEndpoint, EnvironmentMixin):
+    doc_section = DocSection.ORGANIZATIONS
+
+    @attach_scenarios([list_organization_users_scenario])
     def get(self, request, organization):
+        """
+        List an Organization's Users
+        ````````````````````````````
+
+        Return a list of users that belong to a given organization.
+
+        :qparam string project: restrict results to users who have access to a given project ID
+        :pparam string organization_slug: the slug of the organization for which the users
+                                          should be listed.
+        :auth: required
+        """
         projects = self.get_projects(request, organization)
         qs = (
             OrganizationMember.objects.filter(
diff --git a/src/sentry/api/endpoints/project_group_index.py b/src/sentry/api/endpoints/project_group_index.py
index 3251015eb1..ff2f76f04d 100644
--- a/src/sentry/api/endpoints/project_group_index.py
+++ b/src/sentry/api/endpoints/project_group_index.py
@@ -279,6 +279,7 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint, EnvironmentMixin):
         search_fn = functools.partial(self._search, request, project)
         return update_groups(request, [project], project.organization_id, search_fn)
 
+    @attach_scenarios([bulk_remove_issues_scenario])
     def delete(self, request, project):
         """
         Bulk Remove a List of Issues
diff --git a/src/sentry/utils/apidocs.py b/src/sentry/utils/apidocs.py
index 83e0fad0a7..76e9f3e0f0 100644
--- a/src/sentry/utils/apidocs.py
+++ b/src/sentry/utils/apidocs.py
@@ -9,14 +9,17 @@ import mimetypes
 from binascii import hexlify
 
 from collections import defaultdict
+from copy import copy
 from contextlib import contextmanager
 from datetime import datetime, timedelta
 from django.conf import settings
+from django.conf.urls import RegexURLResolver, RegexURLPattern
 from django.db import transaction
 from docutils.core import publish_doctree
 from pytz import utc
 from random import randint
 from six import StringIO
+from sentry.utils.compat import map
 
 # Do not import from sentry here!  Bad things will happen
 
@@ -225,7 +228,7 @@ def camelcase_to_dashes(string):
     return camel_re.sub(handler, string).lstrip("-")
 
 
-def extract_endpoint_info(pattern, internal_endpoint):
+def extract_endpoint_info(pattern, internal_endpoint, parents):
     path = simplify_regex(pattern.regex.pattern)
     from sentry.constants import HTTP_METHODS
 
@@ -246,8 +249,14 @@ def extract_endpoint_info(pattern, internal_endpoint):
             endpoint_name = endpoint_name[:-8]
         endpoint_name = camelcase_to_dashes(endpoint_name)
         title, text, warning, params = parse_doc_string(doc)
+        if not parents:
+            api_path = API_PREFIX + path.lstrip("/")
+        else:
+            parents_prefix = "".join(map(lambda x: x.lstrip("/"), parents))
+            api_path = API_PREFIX + parents_prefix.lstrip("/") + path.lstrip("/")
+
         yield dict(
-            path=API_PREFIX + path.lstrip("/"),
+            path=api_path,
             method=method_name,
             title=title,
             text=text,
@@ -260,14 +269,40 @@ def extract_endpoint_info(pattern, internal_endpoint):
         )
 
 
+def flatten(l):
+    return [item for sublist in l for item in sublist]
+
+
+def resolve_nested_routes(pattern, current_parents=None):
+    """
+    Returns a list of tuples. The first element in the tuple is a RegexURLPattern. The second element is
+    a string list of all the parents that url pattern has.
+    """
+    if current_parents:
+        parents = copy(current_parents)
+    else:
+        parents = []
+
+    if isinstance(pattern, RegexURLPattern):
+        return [(pattern, current_parents)]
+    elif isinstance(pattern, RegexURLResolver):
+        parent = simplify_regex(pattern.regex.pattern)
+        parents.append(parent)
+        return flatten(map(lambda p: resolve_nested_routes(p, parents), pattern.url_patterns))
+    elif isinstance(pattern, list):
+        return flatten(map(lambda p: resolve_nested_routes(p, current_parents), pattern))
+
+
 def iter_endpoints():
     from sentry.api.urls import urlpatterns
 
-    for pattern in urlpatterns:
+    resolved_patterns = resolve_nested_routes(urlpatterns)
+
+    for pattern, parents in resolved_patterns:
         internal_endpoint = get_internal_endpoint_from_pattern(pattern)
         if internal_endpoint is None:
             continue
-        for endpoint in extract_endpoint_info(pattern, internal_endpoint):
+        for endpoint in extract_endpoint_info(pattern, internal_endpoint, parents):
             yield endpoint
 
 
