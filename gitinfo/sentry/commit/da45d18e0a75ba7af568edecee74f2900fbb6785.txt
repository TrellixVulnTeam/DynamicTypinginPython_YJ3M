commit da45d18e0a75ba7af568edecee74f2900fbb6785
Author: David Cramer <dcramer@gmail.com>
Date:   Thu Jul 9 12:03:44 2015 -0600

    Add BaseTSDB.rollup

diff --git a/src/sentry/tsdb/base.py b/src/sentry/tsdb/base.py
index 2b70578f5b..500789c787 100644
--- a/src/sentry/tsdb/base.py
+++ b/src/sentry/tsdb/base.py
@@ -50,8 +50,7 @@ class BaseTSDB(object):
 
     def normalize_to_epoch(self, timestamp, seconds):
         """
-        Given a ``timestamp`` (datetime object) normalize the datetime object
-        ``timestamp`` to an epoch timestmap (integer).
+        Given a ``timestamp`` (datetime object) normalize to an epoch timestamp.
 
         i.e. if the rollup is minutes, the resulting timestamp would have
         the seconds and microseconds rounded down.
@@ -59,14 +58,25 @@ class BaseTSDB(object):
         epoch = int(timestamp.strftime('%s'))
         return epoch - (epoch % seconds)
 
+    def normalize_ts_to_epoch(self, epoch, seconds):
+        """
+        Given a ``epoch`` normalize to an epoch rollup.
+        """
+        return epoch - (epoch % seconds)
+
     def normalize_to_rollup(self, timestamp, seconds):
         """
-        Given a ``timestamp`` (datetime object) normalize the datetime object
-        ``timestamp`` to an epoch rollup (integer).
+        Given a ``timestamp`` (datetime object) normalize to an epoch rollup.
         """
         epoch = int(timestamp.strftime('%s'))
         return int(epoch / seconds)
 
+    def normalize_ts_to_rollup(self, epoch, seconds):
+        """
+        Given a ``epoch`` normalize to an epoch rollup.
+        """
+        return int(epoch / seconds)
+
     def get_optimal_rollup(self, start_timestamp, end_timestamp):
         """
         Identify the lowest granularity rollup available within the given time
@@ -119,3 +129,22 @@ class BaseTSDB(object):
             for (key, points) in range_set.iteritems()
         )
         return sum_set
+
+    def rollup(self, values, rollup):
+        """
+        Given a set of values (as returned from ``get_range``), roll them up
+        using the ``rollup`` time (in seconds).
+        """
+        normalize_ts_to_epoch = self.normalize_ts_to_epoch
+        result = {}
+        for key, points in values.iteritems():
+            result[key] = []
+            last_new_ts = None
+            for (ts, count) in points:
+                new_ts = normalize_ts_to_epoch(ts, rollup)
+                if new_ts == last_new_ts:
+                    result[key][-1][1] += count
+                else:
+                    result[key].append([new_ts, count])
+                    last_new_ts = new_ts
+        return result
diff --git a/tests/sentry/tsdb/test_base.py b/tests/sentry/tsdb/test_base.py
new file mode 100644
index 0000000000..40d19a32e1
--- /dev/null
+++ b/tests/sentry/tsdb/test_base.py
@@ -0,0 +1,42 @@
+from __future__ import absolute_import
+
+import pytz
+
+from datetime import datetime, timedelta
+
+from sentry.testutils import TestCase
+from sentry.tsdb.base import BaseTSDB, ONE_MINUTE, ONE_HOUR, ONE_DAY
+
+
+class BaseTSDBTest(TestCase):
+    def setUp(self):
+        self.tsdb = BaseTSDB(rollups=(
+            # time in seconds, samples to keep
+            (10, 30),  # 5 minutes at 10 seconds
+            (ONE_MINUTE, 120),  # 2 hours at 1 minute
+            (ONE_HOUR, 24),  # 1 days at 1 hour
+            (ONE_DAY, 30),  # 30 days at 1 day
+        ))
+
+    def test_normalize_to_epoch(self):
+        timestamp = datetime(2013, 5, 18, 15, 13, 58, 132928, tzinfo=pytz.UTC)
+        normalize_to_epoch = self.tsdb.normalize_to_epoch
+
+        result = normalize_to_epoch(timestamp, 60)
+        assert result == 1368889980
+        result = normalize_to_epoch(timestamp + timedelta(seconds=20), 60)
+        assert result == 1368890040
+        result = normalize_to_epoch(timestamp + timedelta(seconds=30), 60)
+        assert result == 1368890040
+        result = normalize_to_epoch(timestamp + timedelta(seconds=70), 60)
+        assert result == 1368890100
+
+    def test_rollup(self):
+        pre_results = {
+            1: [(1368889980, 5), (1368890040, 10), (1368893640, 7)],
+        }
+        post_results = self.tsdb.rollup(pre_results, 3600)
+        assert len(post_results) == 1
+        assert post_results[1] == [
+            [1368889200, 15], [1368892800, 7]
+        ]
diff --git a/tests/sentry/tsdb/test_redis.py b/tests/sentry/tsdb/test_redis.py
index 54c0c9ac98..a7b5595464 100644
--- a/tests/sentry/tsdb/test_redis.py
+++ b/tests/sentry/tsdb/test_redis.py
@@ -1,6 +1,6 @@
 import pytz
 
-from datetime import datetime, timedelta
+from datetime import datetime
 
 from sentry.testutils import TestCase
 from sentry.tsdb.base import TSDBModel, ONE_MINUTE, ONE_HOUR, ONE_DAY
@@ -20,19 +20,6 @@ class RedisTSDBTest(TestCase):
         ), vnodes=64)
         self.db.conn.flushdb()
 
-    def test_normalize_to_epoch(self):
-        timestamp = datetime(2013, 5, 18, 15, 13, 58, 132928, tzinfo=pytz.UTC)
-        normalize_to_epoch = self.db.normalize_to_epoch
-
-        result = normalize_to_epoch(timestamp, 60)
-        assert result == 1368889980
-        result = normalize_to_epoch(timestamp + timedelta(seconds=20), 60)
-        assert result == 1368890040
-        result = normalize_to_epoch(timestamp + timedelta(seconds=30), 60)
-        assert result == 1368890040
-        result = normalize_to_epoch(timestamp + timedelta(seconds=70), 60)
-        assert result == 1368890100
-
     def test_make_key(self):
         result = self.db.make_key(TSDBModel.project, 1368889980, 1)
         assert result == 'ts:1:1368889980:1'
