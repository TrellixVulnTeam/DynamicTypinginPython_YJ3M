commit ea791cb482d6f77481beed41e64ccc52ce10bc65
Author: Jan Michael Auer <jan.auer@sentry.io>
Date:   Mon Mar 9 11:27:29 2020 +0100

    ref(signals): Only emit ingestion signals via outcomes (#17506)
    
    This concludes moving all ingestion signals to outcomes consumers by removing them from the ingestion path:
    
    - event_saved  ->  Outcome.ACCEPTED
    - event_discarded  ->  Outcome.FILTERED with reason "discarded-hash"
    - event_filtered  ->  Outcome.FILTERED
    - event_dropped  ->  Outcome.RATE_LIMITED

diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index a2befaad77..cecdd933a4 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -13,7 +13,7 @@ from django.db import connection, IntegrityError, router, transaction
 from django.db.models import Func
 from django.utils.encoding import force_text
 
-from sentry import buffer, eventstore, eventtypes, eventstream, features, tsdb, options
+from sentry import buffer, eventstore, eventtypes, eventstream, features, tsdb
 from sentry.attachments import attachment_cache
 from sentry.constants import (
     DataCategory,
@@ -41,7 +41,6 @@ from sentry.coreapi import (
     decode_data,
     safely_load_json_string,
 )
-from sentry.ingest.outcomes_consumer import mark_signal_sent
 from sentry.interfaces.base import get_interface
 from sentry.lang.native.utils import STORE_CRASH_REPORTS_ALL, convert_crashreport_count
 from sentry.models import (
@@ -72,7 +71,7 @@ from sentry.models import (
 )
 from sentry.plugins.base import plugins
 from sentry import quotas
-from sentry.signals import event_discarded, event_saved, first_event_received
+from sentry.signals import first_event_received
 from sentry.tasks.integrations import kick_off_status_syncs
 from sentry.utils import json, metrics
 from sentry.utils.canonical import CanonicalKeyDict
@@ -536,13 +535,6 @@ class EventManager(object):
                 event=job["event"], hashes=hashes, release=job["release"], **kwargs
             )
         except HashDiscarded:
-            if options.get("sentry:skip-discarded-signal-in-save-event") != "1":
-                event_discarded.send_robust(project=project, sender=EventManager)
-
-                # The outcomes_consumer generically handles all FILTERED outcomes,
-                # but needs to skip this since it cannot dispatch event_discarded.
-                mark_signal_sent(project_id, job["event"].event_id)
-
             project_key = None
             if job["key_id"] is not None:
                 try:
@@ -553,14 +545,14 @@ class EventManager(object):
             quotas.refund(project, key=project_key, timestamp=start_time)
 
             track_outcome(
-                project.organization_id,
-                project_id,
-                job["key_id"],
-                Outcome.FILTERED,
-                FilterStatKeys.DISCARDED_HASH,
-                to_datetime(job["start_time"]),
-                job["event"].event_id,
-                job["category"],
+                org_id=project.organization_id,
+                project_id=project_id,
+                key_id=job["key_id"],
+                outcome=Outcome.FILTERED,
+                reason=FilterStatKeys.DISCARDED_HASH,
+                timestamp=to_datetime(job["start_time"]),
+                event_id=job["event"].event_id,
+                category=job["category"],
             )
 
             metrics.incr(
@@ -572,9 +564,6 @@ class EventManager(object):
 
         job["event"].group = job["group"]
 
-        if options.get("sentry:skip-accepted-signal-in-save-event") != "1":
-            _send_event_saved_signal_many(jobs, projects)
-
         # store a reference to the group id to guarantee validation of isolation
         # XXX(markus): No clue what this does
         job["event"].data.bind_ref(job["event"])
@@ -823,18 +812,6 @@ def _materialize_metadata_many(jobs):
         data["culprit"] = job["culprit"]
 
 
-@metrics.wraps("save_event.send_event_saved_signal_many")
-def _send_event_saved_signal_many(jobs, projects):
-    for job in jobs:
-        event_saved.send_robust(
-            project=projects[job["project_id"]],
-            event_size=job["event"].size,
-            category=job["category"],
-            quantity=1,
-            sender=EventManager,
-        )
-
-
 @metrics.wraps("save_event.get_or_create_environment_many")
 def _get_or_create_environment_many(jobs, projects):
     for job in jobs:
@@ -954,19 +931,15 @@ def _track_outcome_accepted_many(jobs):
     for job in jobs:
         event = job["event"]
 
-        # This is where we can finally say that we have accepted the event.
-        if options.get("sentry:skip-accepted-signal-in-save-event") != "1":
-            mark_signal_sent(event.project.id, event.event_id)
-
         track_outcome(
-            event.project.organization_id,
-            job["project_id"],
-            job["key_id"],
-            Outcome.ACCEPTED,
-            None,
-            to_datetime(job["start_time"]),
-            event.event_id,
-            job["category"],
+            org_id=event.project.organization_id,
+            project_id=job["project_id"],
+            key_id=job["key_id"],
+            outcome=Outcome.ACCEPTED,
+            reason=None,
+            timestamp=to_datetime(job["start_time"]),
+            event_id=event.event_id,
+            category=job["category"],
         )
 
 
@@ -1398,8 +1371,6 @@ def save_transaction_events(jobs, projects):
     _derive_plugin_tags_many(jobs, projects)
     _derive_interface_tags_many(jobs)
     _materialize_metadata_many(jobs)
-    if options.get("sentry:skip-accepted-signal-in-save-event") != "1":
-        _send_event_saved_signal_many(jobs, projects)
     _get_or_create_environment_many(jobs, projects)
     _get_or_create_release_associated_models(jobs, projects)
     _tsdb_record_all_metrics(jobs)
diff --git a/src/sentry/utils/outcomes.py b/src/sentry/utils/outcomes.py
index eccde39761..4382487186 100644
--- a/src/sentry/utils/outcomes.py
+++ b/src/sentry/utils/outcomes.py
@@ -31,11 +31,6 @@ outcomes = settings.KAFKA_TOPICS[settings.KAFKA_OUTCOMES]
 outcomes_publisher = None
 
 
-def decide_signals_in_consumer():
-    rate = options.get("outcomes.signals-in-consumer-sample-rate")
-    return rate and rate > random.random()
-
-
 def decide_tsdb_in_consumer():
     rate = options.get("outcomes.tsdb-in-consumer-sample-rate")
     return rate and rate > random.random()
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 54af7befec..4d834853e5 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -45,7 +45,6 @@ from sentry.coreapi import (
     logger as api_logger,
 )
 from sentry.event_manager import EventManager
-from sentry.ingest.outcomes_consumer import mark_signal_sent
 from sentry.interfaces import schemas
 from sentry.interfaces.base import get_interface
 from sentry.lang.native.unreal import (
@@ -63,12 +62,12 @@ from sentry.lang.native.minidump import (
     MINIDUMP_ATTACHMENT_TYPE,
 )
 from sentry.models import Project, File, EventAttachment, Organization
-from sentry.signals import event_accepted, event_dropped, event_filtered, event_received
+from sentry.signals import event_accepted, event_received
 from sentry.quotas.base import RateLimit
 from sentry.utils import json, metrics
 from sentry.utils.data_filters import FilterStatKeys
 from sentry.utils.http import is_valid_origin, get_origins, is_same_domain, origin_from_request
-from sentry.utils.outcomes import Outcome, track_outcome, decide_signals_in_consumer
+from sentry.utils.outcomes import Outcome, track_outcome
 from sentry.utils.pubsub import QueuedPublisherService, KafkaPublisher
 from sentry.utils.safe import safe_execute
 from sentry.utils.sdk import configure_scope
@@ -203,14 +202,6 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
     data_category = DataCategory.from_event_type(data.get("type"))
 
     if should_filter:
-        signals_in_consumer = decide_signals_in_consumer()
-
-        if not signals_in_consumer:
-            # Mark that the event_filtered signal is sent. Do this before emitting
-            # the outcome to avoid a potential race between OutcomesConsumer and
-            # `event_filtered.send_robust` below.
-            mark_signal_sent(project_config.project_id, event_id)
-
         track_outcome(
             project_config.organization_id,
             project_config.project_id,
@@ -222,11 +213,6 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
         )
         metrics.incr("events.blacklisted", tags={"reason": filter_reason}, skip_internal=False)
 
-        if not signals_in_consumer:
-            event_filtered.send_robust(
-                ip=remote_addr, project=project, category=data_category, sender=process_event
-            )
-
         # relay will no longer be able to provide information about filter
         # status so to see the impact we're adding a way to turn on relay
         # like behavior here.
@@ -248,14 +234,6 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
         if rate_limit is None:
             api_logger.debug("Dropped event due to error with rate limiter")
 
-        signals_in_consumer = decide_signals_in_consumer()
-
-        if not signals_in_consumer:
-            # Mark that the event_dropped signal is sent. Do this before emitting
-            # the outcome to avoid a potential race between OutcomesConsumer and
-            # `event_dropped.send_robust` below.
-            mark_signal_sent(project_config.project_id, event_id)
-
         reason = rate_limit.reason_code if rate_limit else None
         track_outcome(
             project_config.organization_id,
@@ -267,14 +245,6 @@ def process_event(event_manager, project, key, remote_addr, helper, attachments,
             category=data_category,
         )
         metrics.incr("events.dropped", tags={"reason": reason or "unknown"}, skip_internal=False)
-        if not signals_in_consumer:
-            event_dropped.send_robust(
-                ip=remote_addr,
-                project=project,
-                reason_code=reason,
-                category=data_category,
-                sender=process_event,
-            )
 
         if rate_limit is not None:
             raise APIRateLimited(rate_limit.retry_after)
diff --git a/tests/sentry/event_manager/test_event_manager.py b/tests/sentry/event_manager/test_event_manager.py
index e593c58284..4a2310f1cf 100644
--- a/tests/sentry/event_manager/test_event_manager.py
+++ b/tests/sentry/event_manager/test_event_manager.py
@@ -36,7 +36,7 @@ from sentry.models import (
     OrganizationIntegration,
     UserReport,
 )
-from sentry.signals import event_discarded, event_saved
+from sentry.utils.outcomes import Outcome
 from sentry.testutils import assert_mock_called_once_with_partial, TestCase
 from sentry.utils.data_filters import FilterStatKeys
 from sentry.relay.config import get_project_config
@@ -1015,18 +1015,16 @@ class EventManagerTest(TestCase):
 
         manager = EventManager(make_event(message="foo", event_id="b" * 32, fingerprint=["a" * 32]))
 
-        mock_event_discarded = mock.Mock()
-        event_discarded.connect(mock_event_discarded)
-        mock_event_saved = mock.Mock()
-        event_saved.connect(mock_event_saved)
+        from sentry.utils.outcomes import track_outcome
 
-        with self.tasks():
-            with self.assertRaises(HashDiscarded):
-                event = manager.save(1)
+        mock_track_outcome = mock.Mock(wraps=track_outcome)
+        with mock.patch("sentry.event_manager.track_outcome", mock_track_outcome):
+            with self.tasks():
+                with self.assertRaises(HashDiscarded):
+                    event = manager.save(1)
 
-        assert not mock_event_saved.called
         assert_mock_called_once_with_partial(
-            mock_event_discarded, project=group.project, sender=EventManager, signal=event_discarded
+            mock_track_outcome, outcome=Outcome.FILTERED, reason=FilterStatKeys.DISCARDED_HASH
         )
 
         def query(model, key, **kwargs):
@@ -1042,17 +1040,15 @@ class EventManagerTest(TestCase):
         assert query(tsdb.models.organization_total_blacklisted, event.project.organization.id) == 1
         assert query(tsdb.models.project_total_blacklisted, event.project.id) == 1
 
-    def test_event_saved_signal(self):
-        mock_event_saved = mock.Mock()
-        event_saved.connect(mock_event_saved)
-
+    def test_event_accepted_outcome(self):
         manager = EventManager(make_event(message="foo"))
         manager.normalize()
-        event = manager.save(1)
 
-        assert_mock_called_once_with_partial(
-            mock_event_saved, project=event.group.project, sender=EventManager, signal=event_saved
-        )
+        mock_track_outcome = mock.Mock()
+        with mock.patch("sentry.event_manager.track_outcome", mock_track_outcome):
+            manager.save(1)
+
+        assert_mock_called_once_with_partial(mock_track_outcome, outcome=Outcome.ACCEPTED)
 
     def test_checksum_rehashed(self):
         checksum = "invalid checksum hash"
diff --git a/tests/sentry/web/api/tests.py b/tests/sentry/web/api/tests.py
index f8e9ba74f6..0ce44732db 100644
--- a/tests/sentry/web/api/tests.py
+++ b/tests/sentry/web/api/tests.py
@@ -12,7 +12,7 @@ from six import BytesIO
 
 from sentry.coreapi import APIRateLimited
 from sentry.models import ProjectKey, EventAttachment
-from sentry.signals import event_accepted, event_dropped, event_filtered
+from sentry.signals import event_accepted
 from sentry.testutils import assert_mock_called_once_with_partial, TestCase
 from sentry.utils import json
 from sentry.utils.data_filters import FilterTypes
@@ -595,40 +595,6 @@ class StoreViewTest(TestCase):
             mock_event_accepted, ip="127.0.0.1", project=self.project, signal=event_accepted
         )
 
-    @mock.patch("sentry.coreapi.ClientApiHelper.insert_data_to_database", Mock())
-    @mock.patch("sentry.app.quotas.is_rate_limited")
-    def test_dropped_signal(self, mock_is_rate_limited):
-        mock_is_rate_limited.is_limited = True
-
-        mock_event_dropped = Mock()
-
-        event_dropped.connect(mock_event_dropped)
-
-        resp = self._postWithHeader({"logentry": {"message": u"hello"}})
-
-        assert resp.status_code == 429, resp.content
-
-        assert_mock_called_once_with_partial(
-            mock_event_dropped, ip="127.0.0.1", project=self.project, signal=event_dropped
-        )
-
-    @mock.patch("sentry.coreapi.ClientApiHelper.insert_data_to_database", Mock())
-    @mock.patch("sentry.event_manager.EventManager.should_filter")
-    def test_filtered_signal(self, mock_should_filter):
-        mock_should_filter.return_value = (True, "ip-address")
-
-        mock_event_filtered = Mock()
-
-        event_filtered.connect(mock_event_filtered)
-
-        resp = self._postWithHeader({"logentry": {"message": u"hello"}})
-
-        assert resp.status_code == 403, resp.content
-
-        assert_mock_called_once_with_partial(
-            mock_event_filtered, ip="127.0.0.1", project=self.project, signal=event_filtered
-        )
-
 
 class CrossDomainXmlTest(TestCase):
     @fixture
