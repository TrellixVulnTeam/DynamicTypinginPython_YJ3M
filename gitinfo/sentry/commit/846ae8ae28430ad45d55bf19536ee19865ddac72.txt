commit 846ae8ae28430ad45d55bf19536ee19865ddac72
Author: William Mak <william@wmak.io>
Date:   Fri Jun 26 12:29:50 2020 -0400

    fix(discover): Remove unneccesary groupby on many queries (#19516)
    
    * fix(discover): Remove unneccesary groupby on many queries
    
    - This moves the project transform from an aggregation to a
      selected_column
    - Because the project transform that allows us to sort by project was
      being passed as an aggregate we were grouping by all the time
    - Also removing project transform as an auto field, looks like this was
      done accidentally and meant that a project transform would happen
      almost all the time when it wasn't always necessary
    - Removing `project` as a potentital groupby:
      - topEvents would get very confused since groupby would have both
        `project_id` and `project` (and translates project_id to mean project)
        going to groupby on only `project_id` instead which should be the
        equivalent result since project is a transform on id anyways

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 0a50c9e927..9322e27039 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -1404,12 +1404,20 @@ def resolve_orderby(orderby, fields, aggregations):
             validated.append(prefix + bare_column)
             continue
 
-        if bare_column in FIELD_ALIASES and FIELD_ALIASES[bare_column].get("column_alias"):
+        if (
+            bare_column in FIELD_ALIASES
+            and FIELD_ALIASES[bare_column].get("column_alias")
+            and bare_column != PROJECT_ALIAS
+        ):
             prefix = "-" if column.startswith("-") else ""
             validated.append(prefix + FIELD_ALIASES[bare_column]["column_alias"])
             continue
 
-        found = [col[2] for col in fields if isinstance(col, (list, tuple))]
+        found = [
+            col[2]
+            for col in fields
+            if isinstance(col, (list, tuple)) and col[2].strip("`") == bare_column
+        ]
         if found:
             prefix = "-" if column.startswith("-") else ""
             validated.append(prefix + bare_column)
@@ -1495,17 +1503,20 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
 
         project_ids = filtered_project_ids or snuba_filter.filter_keys.get("project_id", [])
         projects = Project.objects.filter(id__in=project_ids).values("slug", "id")
-        aggregations.append(
+        columns.append(
             [
-                u"transform({}, array({}), array({}), '')".format(
-                    "project_id",
-                    # Need to use join like this so we don't get a list including Ls which confuses clickhouse
-                    ",".join([six.text_type(project["id"]) for project in projects]),
-                    # Can't just format a list since we'll get u"string" instead of a plain 'string'
-                    ",".join([u"'{}'".format(project["slug"]) for project in projects]),
-                ),
-                None,
-                project_key,
+                "transform",
+                [
+                    # This is a workaround since having the column by itself currently is being treated as a function
+                    ["toString", ["project_id"]],
+                    ["array", [u"'{}'".format(project["id"]) for project in projects]],
+                    ["array", [u"'{}'".format(project["slug"]) for project in projects]],
+                    # Default case, what to do if a project id without a slug is found
+                    "''",
+                ],
+                # Need to explicitly state this is a column with backticks.
+                # Otherwise clickhouse can't parse project.name
+                "`{}`".format(project_key),
             ]
         )
 
@@ -1521,6 +1532,9 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
     if aggregations:
         for column in columns:
             if isinstance(column, (list, tuple)):
+                if column[0] == "transform":
+                    # When there's a project transform, we already group by project_id
+                    continue
                 groupby.append(column[2])
             else:
                 groupby.append(column)
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index a6e360aded..f458e2728b 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -867,6 +867,7 @@ def top_events_timeseries(
             aggregations=snuba_filter.aggregations,
             conditions=snuba_filter.conditions,
             filter_keys=snuba_filter.filter_keys,
+            selected_columns=snuba_filter.selected_columns,
             start=snuba_filter.start,
             end=snuba_filter.end,
             rollup=rollup,
diff --git a/src/sentry/utils/snuba.py b/src/sentry/utils/snuba.py
index 93e128de05..fd3532ac94 100644
--- a/src/sentry/utils/snuba.py
+++ b/src/sentry/utils/snuba.py
@@ -902,6 +902,9 @@ def resolve_snuba_aliases(snuba_filter, resolve_func, function_translations=None
     if selected_columns:
         for (idx, col) in enumerate(selected_columns):
             if isinstance(col, (list, tuple)):
+                if len(col) == 3 and col[0] == "transform":
+                    # Add the name from the project transform, and remove the backticks so its not treated as a new col
+                    derived_columns.add(col[2].strip("`"))
                 resolve_complex_column(col, resolve_func)
             else:
                 name = resolve_func(col)
diff --git a/tests/sentry/api/test_event_search.py b/tests/sentry/api/test_event_search.py
index 88382086ac..f324503455 100644
--- a/tests/sentry/api/test_event_search.py
+++ b/tests/sentry/api/test_event_search.py
@@ -1384,16 +1384,33 @@ class ResolveFieldListTest(unittest.TestCase):
     def test_blank_field_ignored(self):
         fields = ["", "title", "   "]
         result = resolve_field_list(fields, eventstore.Filter())
-        assert result["selected_columns"] == ["title", "id", "project.id"]
+        assert result["selected_columns"] == [
+            "title",
+            "id",
+            "project.id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project.name`",
+            ],
+        ]
 
     def test_automatic_fields_no_aggregates(self):
         fields = ["event.type", "message"]
         result = resolve_field_list(fields, eventstore.Filter())
-        assert result["selected_columns"] == ["event.type", "message", "id", "project.id"]
-        assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"],
+        assert result["selected_columns"] == [
+            "event.type",
+            "message",
+            "id",
+            "project.id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project.name`",
+            ],
         ]
-        assert result["groupby"] == ["event.type", "message", "id", "project.id"]
+        assert result["aggregations"] == []
+        assert result["groupby"] == []
 
     def test_field_alias_duration_expansion_with_brackets(self):
         fields = [
@@ -1439,11 +1456,15 @@ class ResolveFieldListTest(unittest.TestCase):
             "user.id",
             "message",
             "project.id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project`",
+            ],
         ]
         assert result["aggregations"] == [
             ["max", "timestamp", "last_seen"],
             ["argMax", ["id", "timestamp"], "latest_event"],
-            ["transform(project_id, array(), array(), '')", None, "project"],
         ]
         assert result["groupby"] == [
             "title",
@@ -1672,14 +1693,27 @@ class ResolveFieldListTest(unittest.TestCase):
             resolve_field_list(fields, eventstore.Filter(orderby="timestamp"))
         assert "Cannot order" in six.text_type(err)
 
+    def test_orderby_unselected_field_with_histogram(self):
+        fields = ["histogram(transaction.duration, 10, 1000, 0)", "message"]
+        with pytest.raises(InvalidSearchQuery) as err:
+            resolve_field_list(fields, eventstore.Filter(orderby="timestamp"))
+        assert "Cannot order" in six.text_type(err)
+
     def test_orderby_basic_field(self):
         fields = ["message"]
         result = resolve_field_list(fields, eventstore.Filter(orderby="-message"))
-        assert result["selected_columns"] == ["message", "id", "project.id"]
-        assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"],
+        assert result["selected_columns"] == [
+            "message",
+            "id",
+            "project.id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project.name`",
+            ],
         ]
-        assert result["groupby"] == ["message", "id", "project.id"]
+        assert result["aggregations"] == []
+        assert result["groupby"] == []
 
     def test_orderby_field_aggregate(self):
         fields = ["count(id)", "count_unique(user)"]
@@ -1695,17 +1729,31 @@ class ResolveFieldListTest(unittest.TestCase):
         fields = ["issue"]
         result = resolve_field_list(fields, eventstore.Filter(orderby="-issue"))
         assert result["orderby"] == ["-issue.id"]
-        assert result["selected_columns"] == ["issue.id", "id", "project.id"]
-        assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project.name"],
+        assert result["selected_columns"] == [
+            "issue.id",
+            "id",
+            "project.id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project.name`",
+            ],
         ]
-        assert result["groupby"] == ["issue.id", "id", "project.id"]
+        assert result["aggregations"] == []
+        assert result["groupby"] == []
 
     def test_orderby_project_alias(self):
         fields = ["project"]
         result = resolve_field_list(fields, eventstore.Filter(orderby="-project"))
-        assert result["orderby"] == ["-project"]
-        assert result["aggregations"] == [
-            ["transform(project_id, array(), array(), '')", None, "project"]
+        assert result["selected_columns"] == [
+            "project.id",
+            "id",
+            [
+                "transform",
+                [["toString", ["project_id"]], ["array", []], ["array", []], "''"],
+                "`project`",
+            ],
         ]
-        assert result["groupby"] == ["project.id", "id"]
+        assert result["orderby"] == ["-project"]
+        assert result["aggregations"] == []
+        assert result["groupby"] == []
diff --git a/tests/sentry/snuba/test_discover.py b/tests/sentry/snuba/test_discover.py
index 181d8c492b..fe9fc6f9ae 100644
--- a/tests/sentry/snuba/test_discover.py
+++ b/tests/sentry/snuba/test_discover.py
@@ -126,14 +126,14 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
         other_project.delete()
 
         result = discover.query(
-            selected_columns=["project.name", "message", "project"],
+            selected_columns=["message", "project"],
             query="",
             params={"project_id": project_ids},
-            orderby="project.name",
+            orderby="project",
         )
         data = result["data"]
         assert len(data) == 3
-        assert [item["project.name"] for item in data] == ["", "a" * 32, "z" * 32]
+        assert [item["project"] for item in data] == ["", "a" * 32, "z" * 32]
 
     def test_field_aliasing_in_selected_columns(self):
         result = discover.query(
@@ -210,7 +210,7 @@ class QueryIntegrationTest(SnubaTestCase, TestCase):
         assert data[0]["project.id"] == self.project.id
         assert data[0]["user.email"] == "bruce@example.com"
         assert data[0]["release"] == "first-release"
-        assert data[0]["project.name"] == self.project.slug, "should include project name for links"
+        assert data[0]["project.name"] == self.project.slug
 
         assert len(result["meta"]) == 5
         assert result["meta"][0] == {"name": "user.email", "type": "Nullable(String)"}
@@ -386,22 +386,30 @@ class QueryTransformTest(TestCase):
             selected_columns=["user", "project"], query="", params={"project_id": [self.project.id]}
         )
         mock_query.assert_called_with(
-            selected_columns=["email", "username", "ip_address", "user_id", "project_id"],
-            aggregations=[
+            selected_columns=[
+                "email",
+                "username",
+                "ip_address",
+                "user_id",
+                "project_id",
                 [
-                    "transform(project_id, array({}), array('{}'), '')".format(
-                        six.text_type(self.project.id), self.project.slug
-                    ),
-                    None,
-                    "project",
-                ]
+                    "transform",
+                    [
+                        ["toString", ["project_id"]],
+                        ["array", [u"'{}'".format(self.project.id)]],
+                        ["array", [u"'{}'".format(self.project.slug)]],
+                        "''",
+                    ],
+                    "`project`",
+                ],
             ],
+            aggregations=[],
             filter_keys={"project_id": [self.project.id]},
             dataset=Dataset.Discover,
             end=None,
             start=None,
             conditions=[],
-            groupby=["email", "username", "ip_address", "user_id", "project_id"],
+            groupby=[],
             having=[],
             orderby=None,
             limit=50,
@@ -422,16 +430,62 @@ class QueryTransformTest(TestCase):
             params={"project_id": [self.project.id, project2.id]},
         )
         mock_query.assert_called_with(
-            selected_columns=["title", "project_id"],
-            aggregations=[
+            selected_columns=[
+                "title",
+                "project_id",
                 [
-                    "transform(project_id, array({}), array('{}'), '')".format(
-                        six.text_type(project2.id), project2.slug
-                    ),
-                    None,
-                    "project",
-                ]
+                    "transform",
+                    [
+                        ["toString", ["project_id"]],
+                        ["array", [u"'{}'".format(project2.id)]],
+                        ["array", [u"'{}'".format(project2.slug)]],
+                        "''",
+                    ],
+                    "`project`",
+                ],
+            ],
+            aggregations=[],
+            filter_keys={"project_id": [project2.id]},
+            dataset=Dataset.Discover,
+            end=None,
+            start=None,
+            conditions=[["project_id", "=", project2.id]],
+            groupby=[],
+            having=[],
+            orderby=None,
+            limit=50,
+            offset=None,
+            referrer=None,
+        )
+
+    @patch("sentry.snuba.discover.raw_query")
+    def test_project_with_aggregate_grouping(self, mock_query):
+        project2 = self.create_project(organization=self.organization)
+        mock_query.return_value = {
+            "meta": [{"name": "title"}, {"name": "project_id"}],
+            "data": [{"title": "stuff", "project_id": project2.id}],
+        }
+        discover.query(
+            selected_columns=["title", "project", "p99()"],
+            query="project:{}".format(project2.slug),
+            params={"project_id": [self.project.id, project2.id]},
+        )
+        mock_query.assert_called_with(
+            selected_columns=[
+                "title",
+                "project_id",
+                [
+                    "transform",
+                    [
+                        ["toString", ["project_id"]],
+                        ["array", [u"'{}'".format(project2.id)]],
+                        ["array", [u"'{}'".format(project2.slug)]],
+                        "''",
+                    ],
+                    "`project`",
+                ],
             ],
+            aggregations=[[u"quantile(0.99)", "duration", u"p99"]],
             filter_keys={"project_id": [project2.id]},
             dataset=Dataset.Discover,
             end=None,
