commit 8d6dd13f5a32f0fa7516dd1ec6bc5b329d47650e
Author: William Mak <william@wmak.io>
Date:   Mon Apr 27 16:57:20 2020 -0400

    Fix(discover): Top events with array fields (#18473)
    
    * fix(discover): Top events with array fields
    
    - This basically ignored array fields in top events except in the
      groupby, this is cause they can't be used in the orderby
    - When generating the result_keys these array fields become the last
      item in the list, this is to match what the frontend does when getting
      an array
    - This also restricts results to the 5 result_keys from top_events.

diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index e236002c09..f4f36693c5 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -2,6 +2,7 @@ from __future__ import absolute_import
 
 import math
 import six
+import logging
 
 from collections import namedtuple
 from copy import deepcopy
@@ -49,6 +50,8 @@ __all__ = (
 )
 
 
+logger = logging.getLogger(__name__)
+
 ReferenceEvent = namedtuple("ReferenceEvent", ["organization", "slug", "fields", "start", "end"])
 ReferenceEvent.__new__.__defaults__ = (None, None)
 
@@ -800,7 +803,13 @@ def create_result_key(result_row, fields, issues):
         if field == "issue.id":
             values.append(issues.get(result_row["issue.id"], "unknown"))
         else:
-            values.append(six.text_type(result_row.get(field)))
+            value = result_row.get(field)
+            if isinstance(value, list):
+                if len(value) > 0:
+                    value = value[-1]
+                else:
+                    value = ""
+            values.append(six.text_type(value))
     return ",".join(values)
 
 
@@ -855,7 +864,14 @@ def top_events_timeseries(
             continue
         if field == "issue":
             field = FIELD_ALIASES["issue"]["column_alias"]
-        values = list({event.get(field) for event in top_events["data"] if field in event})
+        # Note that because orderby shouldn't be an array field its not included in the values
+        values = list(
+            {
+                event.get(field)
+                for event in top_events["data"]
+                if field in event and not isinstance(event.get(field), list)
+            }
+        )
         if values:
             # timestamp needs special handling, creating a big OR instead
             if field == "timestamp":
@@ -912,13 +928,22 @@ def top_events_timeseries(
     translated_groupby.sort()
 
     results = {}
-    for row in result["data"]:
-        result_key = create_result_key(row, translated_groupby, issues)
-        results.setdefault(result_key, {"data": []})["data"].append(row)
     # Using the top events add the order to the results
     for index, item in enumerate(top_events["data"]):
         result_key = create_result_key(item, translated_groupby, issues)
-        results[result_key]["order"] = index
+        results[result_key] = {
+            "order": index,
+            "data": [],
+        }
+    for row in result["data"]:
+        result_key = create_result_key(row, translated_groupby, issues)
+        if result_key in results:
+            results[result_key]["data"].append(row)
+        else:
+            logger.warning(
+                "discover.top-events.timeseries.key-mismatch",
+                extra={"result_key": result_key, "top_event_keys": results.keys()},
+            )
     for key, item in six.iteritems(results):
         results[key] = SnubaTSResult(
             {
diff --git a/tests/snuba/api/endpoints/test_organization_events_stats.py b/tests/snuba/api/endpoints/test_organization_events_stats.py
index a654ead1ec..6970add3a2 100644
--- a/tests/snuba/api/endpoints/test_organization_events_stats.py
+++ b/tests/snuba/api/endpoints/test_organization_events_stats.py
@@ -1185,3 +1185,65 @@ class OrganizationEventsStatsTopNEvents(APITestCase, SnubaTestCase):
             [{"count": 0}],
         ]
         assert results["order"] == 0
+
+    def test_top_events_with_error_handled(self):
+        data = self.event_data[0]
+        data["data"]["level"] = "error"
+        data["data"]["exception"] = {
+            "values": [
+                {
+                    "type": "ValidationError",
+                    "value": "Bad request",
+                    "mechanism": {"handled": True, "type": "generic"},
+                }
+            ]
+        }
+        self.store_event(data["data"], project_id=data["project"].id)
+        data["data"]["exception"] = {
+            "values": [
+                {
+                    "type": "ValidationError",
+                    "value": "Bad request",
+                    "mechanism": {"handled": False, "type": "generic"},
+                }
+            ]
+        }
+        self.store_event(data["data"], project_id=data["project"].id)
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(hours=1, minutes=59)),
+                    "interval": "1h",
+                    "yAxis": "count()",
+                    "orderby": ["-count()"],
+                    "field": ["count()", "error.handled"],
+                    "topEvents": 5,
+                },
+                format="json",
+            )
+
+        data = response.data
+
+        assert response.status_code == 200, response.content
+        assert len(data) == 3
+
+        results = data[""]
+        assert [attrs for time, attrs in results["data"]] == [
+            [{"count": 22}],
+            [{"count": 6}],
+        ]
+        assert results["order"] == 0
+
+        results = data["1"]
+        assert [attrs for time, attrs in results["data"]] == [
+            [{"count": 1}],
+            [{"count": 0}],
+        ]
+
+        results = data["0"]
+        assert [attrs for time, attrs in results["data"]] == [
+            [{"count": 1}],
+            [{"count": 0}],
+        ]
