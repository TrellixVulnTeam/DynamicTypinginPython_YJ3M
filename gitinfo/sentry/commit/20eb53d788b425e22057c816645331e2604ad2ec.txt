commit 20eb53d788b425e22057c816645331e2604ad2ec
Author: Ryan Skonnord <ryan.skonnord@sentry.io>
Date:   Tue Apr 21 17:34:18 2020 -0700

    ref(snuba): Add instrumentation to group queryset (#18371)
    
    The database query that underlies this Django query is a target for
    optimization. Add a span that will highlight when it is called and
    capture the result size.
    
    This will be useful in correlating the query's time cost to cases where
    the result set is too large to use anyway. If the time cost is large in
    such cases, it would justify making a separate 'count' query.

diff --git a/src/sentry/search/snuba/executors.py b/src/sentry/search/snuba/executors.py
index e3e4e6574e..92a6517344 100644
--- a/src/sentry/search/snuba/executors.py
+++ b/src/sentry/search/snuba/executors.py
@@ -5,6 +5,7 @@ from abc import ABCMeta, abstractmethod, abstractproperty
 import logging
 import time
 import six
+import sentry_sdk
 from datetime import timedelta
 from hashlib import md5
 
@@ -325,9 +326,14 @@ class PostgresSnubaQueryExecutor(AbstractQueryExecutor):
         # to something that we can send down to Snuba in a `group_id IN (...)`
         # clause.
         max_candidates = options.get("snuba.search.max-pre-snuba-candidates")
-        too_many_candidates = False
-        group_ids = list(group_queryset.values_list("id", flat=True)[: max_candidates + 1])
+
+        with sentry_sdk.start_span(op="snuba_group_query") as span:
+            group_ids = list(group_queryset.values_list("id", flat=True)[: max_candidates + 1])
+            span.set_data("Max Candidates", max_candidates)
+            span.set_data("Result Size", len(group_ids))
         metrics.timing("snuba.search.num_candidates", len(group_ids))
+
+        too_many_candidates = False
         if not group_ids:
             # no matches could possibly be found from this point on
             metrics.incr("snuba.search.no_candidates", skip_internal=False)
