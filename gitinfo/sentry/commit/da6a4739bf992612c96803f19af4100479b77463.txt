commit da6a4739bf992612c96803f19af4100479b77463
Author: David Cramer <dcramer@gmail.com>
Date:   Sat Mar 23 17:49:04 2013 -0700

    Move javascript source expansion into preprocessor
    
    This ensures that the checksum is calculcated correctly based on the expanded source.
    
    Caveat: every single event (non-sampled) now must be expanded

diff --git a/src/sentry/manager.py b/src/sentry/manager.py
index 4ecb9d9b7d..18ded24590 100644
--- a/src/sentry/manager.py
+++ b/src/sentry/manager.py
@@ -14,9 +14,10 @@ import hashlib
 import itertools
 import logging
 import re
+import time
 import warnings
 import weakref
-import time
+import uuid
 
 from celery.signals import task_postrun
 from django.conf import settings as dj_settings
@@ -35,7 +36,6 @@ from sentry.constants import STATUS_RESOLVED, STATUS_UNRESOLVED, MINUTE_NORMALIZ
 from sentry.processors.base import send_group_processors
 from sentry.signals import regression_signal
 from sentry.tasks.index import index_event
-from sentry.tasks.fetch_source import fetch_javascript_source
 from sentry.utils.cache import cache, memoize, Lock
 from sentry.utils.dates import get_sql_date_trunc, normalize_datetime
 from sentry.utils.db import get_db_engine, has_charts, attach_foreignkey
@@ -377,8 +377,56 @@ class ChartMixin(object):
 class GroupManager(BaseManager, ChartMixin):
     use_for_related_fields = True
 
-    @transaction.commit_on_success
+    def normalize_event_data(self, data):
+        # First we pull out our top-level (non-data attr) kwargs
+        if not data.get('level'):
+            data['level'] = logging.ERROR
+        if not data.get('logger'):
+            data['logger'] = settings.DEFAULT_LOGGER_NAME
+
+        tags = data.get('tags')
+        if not tags:
+            tags = []
+        # full support for dict syntax
+        elif isinstance(tags, dict):
+            tags = tags.items()
+        data['tags'] = tags
+
+        timestamp = data.get('timestamp')
+        if not timestamp:
+            timestamp = timezone.now()
+
+        if not data.get('culprit'):
+            data['culprit'] = ''
+
+        # We must convert date to local time so Django doesn't mess it up
+        # based on TIME_ZONE
+        if dj_settings.TIME_ZONE:
+            if not timezone.is_aware(timestamp):
+                timestamp = timestamp.replace(tzinfo=timezone.utc)
+        elif timezone.is_aware(timestamp):
+            timestamp = timestamp.replace(tzinfo=None)
+        data['timestamp'] = timestamp
+
+        if not data.get('event_id'):
+            data['event_id'] = uuid.uuid4().hex
+
+        data.setdefault('message', None)
+        data.setdefault('time_spent', None)
+        data.setdefault('server_name', None)
+        data.setdefault('site', None)
+        data.setdefault('checksum', None)
+        data.setdefault('platform', None)
+
+        return data
+
     def from_kwargs(self, project, **kwargs):
+        data = self.normalize_event_data(kwargs)
+
+        return self.save_data(project, data)
+
+    @transaction.commit_on_success
+    def save_data(self, project, data):
         # TODO: this function is way too damn long and needs refactored
         # the inner imports also suck so let's try to move it away from
         # the objects manager
@@ -391,33 +439,17 @@ class GroupManager(BaseManager, ChartMixin):
         project = Project.objects.get_from_cache(pk=project)
 
         # First we pull out our top-level (non-data attr) kwargs
-        event_id = kwargs.pop('event_id', None)
-        message = kwargs.pop('message', None)
-        culprit = kwargs.pop('culprit', None)
-        level = kwargs.pop('level', None) or logging.ERROR
-        time_spent = kwargs.pop('time_spent', None)
-        logger_name = kwargs.pop('logger', None) or settings.DEFAULT_LOGGER_NAME
-        server_name = kwargs.pop('server_name', None)
-        site = kwargs.pop('site', None)
-        date = kwargs.pop('timestamp', None) or timezone.now()
-        checksum = kwargs.pop('checksum', None)
-        tags = kwargs.pop('tags', [])
-        platform = kwargs.pop('platform', None)
-
-        # full support for dict syntax
-        if isinstance(tags, dict):
-            tags = tags.items()
-
-        # We must convert date to local time so Django doesn't mess it up
-        # based on TIME_ZONE
-        if dj_settings.TIME_ZONE:
-            if not timezone.is_aware(date):
-                date = date.replace(tzinfo=timezone.utc)
-        elif timezone.is_aware(date):
-            date = date.replace(tzinfo=None)
-
-        data = kwargs
-        data['tags'] = tags
+        event_id = data.pop('event_id')
+        message = data.pop('message')
+        culprit = data.pop('culprit')
+        level = data.pop('level')
+        time_spent = data.pop('time_spent')
+        logger_name = data.pop('logger')
+        server_name = data.pop('server_name')
+        site = data.pop('site')
+        date = data.pop('timestamp')
+        checksum = data.pop('checksum')
+        platform = data.pop('platform')
 
         kwargs = {
             'level': level,
@@ -453,8 +485,12 @@ class GroupManager(BaseManager, ChartMixin):
         })
 
         try:
-            group, is_new, is_sample = self._create_group(event, tags=tags, **group_kwargs)
-        except Exception, exc:
+            group, is_new, is_sample = self._create_group(
+                event=event,
+                tags=data['tags'],
+                **group_kwargs
+            )
+        except Exception as exc:
             # TODO: should we mail admins when there are failures?
             try:
                 logger.exception(u'Unable to process log entry: %s', exc)
@@ -482,13 +518,6 @@ class GroupManager(BaseManager, ChartMixin):
                 transaction.rollback_unless_managed(using=group._state.db)
                 logger.exception(u'Error indexing document: %s', e)
 
-        if settings.SCRAPE_JAVASCRIPT_CONTEXT and event.platform == 'javascript' and not is_sample:
-            try:
-                maybe_delay(fetch_javascript_source, event, expires=900)
-            except Exception, e:
-                transaction.rollback_unless_managed(using=group._state.db)
-                logger.exception(u'Error fetching javascript source: %s', e)
-
         if is_new:
             try:
                 regression_signal.send_robust(sender=self.model, instance=group)
diff --git a/src/sentry/services/udp.py b/src/sentry/services/udp.py
index cd8b5cd55a..3b2639049a 100644
--- a/src/sentry/services/udp.py
+++ b/src/sentry/services/udp.py
@@ -19,9 +19,10 @@ class CommandError(Exception):
 
 
 def handle_sentry(data, address):
-    from sentry.coreapi import project_from_auth_vars, decode_and_decompress_data, \
-        safely_load_json_string, validate_data, insert_data_to_database, APIError, \
-        APIForbidden
+    from sentry.coreapi import (project_from_auth_vars, decode_and_decompress_data,
+        safely_load_json_string, validate_data, insert_data_to_database, APIError,
+        APIForbidden)
+    from sentry.models import Group
     from sentry.exceptions import InvalidData
     from sentry.plugins import plugins
     from sentry.utils.auth import parse_auth_header
@@ -54,6 +55,8 @@ def handle_sentry(data, address):
         except InvalidData, e:
             raise APIError(u'Invalid data: %s (%s)' % (unicode(e), type(e)))
 
+        Group.objects.normalize_event_data(data)
+
         return insert_data_to_database(data)
     except APIError, error:
         logger.exception('bad message from %s' % (address,))
diff --git a/src/sentry/tasks/fetch_source.py b/src/sentry/tasks/fetch_source.py
index 3f6398200f..cae05a6d50 100644
--- a/src/sentry/tasks/fetch_source.py
+++ b/src/sentry/tasks/fetch_source.py
@@ -6,13 +6,13 @@ sentry.tasks.fetch_source
 :license: BSD, see LICENSE for more details.
 """
 
-import zlib
+import logging
 import hashlib
 import urllib2
+import zlib
 from collections import namedtuple
 from urlparse import urljoin
 
-from celery.task import task
 from django.utils.simplejson import JSONDecodeError
 from sentry.utils.cache import cache
 from sentry.utils.sourcemaps import sourcemap_to_index, find_source
@@ -22,9 +22,10 @@ BAD_SOURCE = -1
 # number of surrounding lines (on each side) to fetch
 LINES_OF_CONTEXT = 5
 
-
 UrlResult = namedtuple('UrlResult', ['url', 'headers', 'body'])
 
+logger = logging.getLogger(__name__)
+
 
 def trim_line(line):
     line = line.strip('\n')
@@ -100,10 +101,10 @@ def fetch_url(url, logger=None):
     """
     import sentry
 
-    cache_key = 'fetch_url:%s' % (hashlib.md5(url).hexdigest(),)
+    cache_key = 'fetch_url:v2:%s' % (hashlib.md5(url).hexdigest(),)
     result = cache.get(cache_key)
     if result is not None:
-        return result
+        return UrlResult(*result)
 
     try:
         opener = urllib2.build_opener()
@@ -122,11 +123,11 @@ def fetch_url(url, logger=None):
             logger.error('Unable to fetch remote source for %r', url, exc_info=True)
         return BAD_SOURCE
 
-    result = UrlResult(url, headers, body)
+    result = (url, headers, body)
 
     cache.set(cache_key, result, 60 * 5)
 
-    return result
+    return UrlResult(url, headers, body)
 
 
 def fetch_sourcemap(url, logger=None):
@@ -144,16 +145,12 @@ def fetch_sourcemap(url, logger=None):
         index = sourcemap_to_index(body)
     except JSONDecodeError:
         if logger:
-            logger.warning('Failed parsing sourcemap JSON: %r', body[:15],
-            exc_info=True)
+            logger.warning('Failed parsing sourcemap JSON: %r', body[:15], exc_info=True)
     else:
         return index
 
 
-@task(
-    name='sentry.tasks.fetch_source.fetch_javascript_source',
-    queue='sourcemaps')
-def fetch_javascript_source(event, **kwargs):
+def expand_javascript_source(data, **kwargs):
     """
     Attempt to fetch source code for javascript frames.
 
@@ -163,23 +160,28 @@ def fetch_javascript_source(event, **kwargs):
     - colno >= 0
     - abs_path is the HTTP URI to the source
     - context_line is empty
+
+    Mutates the input ``data`` with expanded context if available.
     """
-    logger = fetch_javascript_source.get_logger()
+    from sentry.interfaces import Stacktrace
 
     try:
-        stacktrace = event.interfaces['sentry.interfaces.Stacktrace']
+        stacktrace = Stacktrace(**data['sentry.interfaces.Stacktrace'])
     except KeyError:
-        logger.debug('No stacktrace for event %r', event.id)
+        logger.debug('No stacktrace for event %r', data['event_id'])
         return
 
     # build list of frames that we can actually grab source for
-    frames = [f for f in stacktrace.frames
+    frames = [
+        f for f in stacktrace.frames
         if f.lineno is not None
-            and f.context_line is None
-            and f.is_url()]
+        and f.context_line is None
+        and f.is_url()
+    ]
+
     if not frames:
-        logger.debug('Event %r has no frames with enough context to fetch remote source', event.id)
-        return
+        logger.debug('Event %r has no frames with enough context to fetch remote source', data['event_id'])
+        return data
 
     file_list = set()
     sourcemap_capable = set()
@@ -268,5 +270,4 @@ def fetch_javascript_source(event, **kwargs):
             source=source, lineno=frame.lineno)
 
     if has_changes:
-        event.data['sentry.interfaces.Stacktrace'] = stacktrace.serialize()
-        event.update(data=event.data)
+        data['sentry.interfaces.Stacktrace'] = stacktrace.serialize()
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index e79bee7ead..fc6114f5f0 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -7,13 +7,46 @@ sentry.tasks.store
 """
 
 from celery.task import task
+from sentry.conf import settings
+
+
+@task(name='sentry.tasks.store.preprocess_event', queue='events')
+def preprocess_event(data, **kwargs):
+    from sentry.models import Group
+    from sentry.tasks.fetch_source import expand_javascript_source
+    from sentry.utils.queue import maybe_delay
+
+    logger = preprocess_event.get_logger()
+
+    data = Group.objects.normalize_event_data(data)
+
+    try:
+        if settings.SCRAPE_JAVASCRIPT_CONTEXT and data['platform'] == 'javascript':
+            try:
+                expand_javascript_source(data)
+            except Exception, e:
+                logger.exception(u'Error fetching javascript source: %s', e)
+    finally:
+        maybe_delay(save_event, data=data)
+
+
+@task(name='sentry.tasks.store.save_event', queue='events')
+def save_event(data, **kwargs):
+    """
+    Saves an event to the database.
+    """
+    from sentry.models import Group
+
+    Group.objects.save_data(data.pop('project'), data)
 
 
 @task(name='sentry.tasks.store.store_event', queue='events')
 def store_event(data, **kwargs):
     """
     Saves an event to the database.
+
+    Deprecated.
     """
-    from sentry.models import Group
+    from sentry.utils.queue import maybe_delay
 
-    Group.objects.from_kwargs(**data)
+    maybe_delay(preprocess_event, data=data)
diff --git a/src/sentry/web/api.py b/src/sentry/web/api.py
index 4286eca84b..0424b9e7c7 100644
--- a/src/sentry/web/api.py
+++ b/src/sentry/web/api.py
@@ -263,14 +263,19 @@ class StoreView(APIView):
         data = safely_load_json_string(data)
 
         try:
+            # mutates data
             validate_data(project, data, auth.client)
         except InvalidData, e:
             raise APIError(u'Invalid data: %s (%s)' % (unicode(e), type(e)))
 
-        insert_data_to_database(data)
+        # mutates data
+        Group.objects.normalize_event_data(data)
 
         logger.debug('New event from project %s/%s (id=%s)', project.team.slug, project.slug, data['event_id'])
 
+        # mutates data (strips a lot of context if not queued)
+        insert_data_to_database(data)
+
 
 @csrf_exempt
 @has_access
diff --git a/tests/sentry/coreapi/tests.py b/tests/sentry/coreapi/tests.py
index bf57a114fc..a5d513c1c9 100644
--- a/tests/sentry/coreapi/tests.py
+++ b/tests/sentry/coreapi/tests.py
@@ -11,7 +11,7 @@ from sentry.models import Project
 from sentry.exceptions import InvalidTimestamp
 from sentry.coreapi import (project_from_id, project_from_api_key_and_id,
     extract_auth_vars, project_from_auth_vars, APIUnauthorized, APIForbidden,
-    process_data_timestamp, insert_data_to_database, validate_data, INTERFACE_ALIASES)
+    process_data_timestamp, validate_data, INTERFACE_ALIASES)
 from sentry.testutils import TestCase
 
 
@@ -211,15 +211,6 @@ class ProcessDataTimestampTest(BaseAPITest):
         })
 
 
-class InsertDataToDatabaseTest(BaseAPITest):
-    @mock.patch('sentry.models.Group.objects.from_kwargs')
-    def test_insert_data_to_database(self, from_kwargs):
-        insert_data_to_database({
-            'foo': 'bar'
-        })
-        from_kwargs.assert_called_once_with(foo='bar')
-
-
 class ValidateDataTest(BaseAPITest):
     def test_missing_project_id(self):
         data = validate_data(self.project, {
diff --git a/tests/sentry/manager/tests.py b/tests/sentry/manager/tests.py
index 77afde413d..acf0a75e0e 100644
--- a/tests/sentry/manager/tests.py
+++ b/tests/sentry/manager/tests.py
@@ -11,8 +11,8 @@ from django.utils import timezone
 from sentry.constants import MEMBER_OWNER, MEMBER_USER
 from sentry.interfaces import Interface
 from sentry.manager import get_checksum_from_event
-from sentry.models import Event, Group, Project, GroupCountByMinute, ProjectCountByMinute, \
-  SearchDocument, Team
+from sentry.models import (Event, Group, Project, GroupCountByMinute, ProjectCountByMinute,
+    SearchDocument, Team)
 from sentry.utils.db import has_trending  # NOQA
 from sentry.testutils import TestCase
 
@@ -218,14 +218,6 @@ class SentryManagerTest(TestCase):
         self.assertEquals(group.last_seen.replace(microsecond=0), event.datetime.replace(microsecond=0))
         self.assertEquals(group.message, 'foo bar')
 
-    @mock.patch('sentry.manager.maybe_delay')
-    def test_scrapes_javascript_source(self, maybe_delay):
-        from sentry.tasks.fetch_source import fetch_javascript_source
-        with self.Settings(SENTRY_SCRAPE_JAVASCRIPT_CONTEXT=True):
-            event = Group.objects.from_kwargs(1, message='hello', platform='javascript')
-
-            maybe_delay.assert_any_call(fetch_javascript_source, event, expires=900)
-
     def test_add_tags(self):
         event = Group.objects.from_kwargs(1, message='rrr')
         group = event.group
diff --git a/tests/sentry/tasks/fetch_source/tests.py b/tests/sentry/tasks/fetch_source/tests.py
index 84c1cf0659..122d91cc2f 100644
--- a/tests/sentry/tasks/fetch_source/tests.py
+++ b/tests/sentry/tasks/fetch_source/tests.py
@@ -4,21 +4,16 @@ from __future__ import absolute_import
 
 import mock
 
-from celery.task import Task
-from sentry.models import Event
-from sentry.tasks.fetch_source import fetch_javascript_source
+from sentry.tasks.fetch_source import expand_javascript_source
 from sentry.testutils import TestCase
 
 
-class StoreEventTest(TestCase):
-    def test_is_task(self):
-        self.assertTrue(isinstance(fetch_javascript_source, Task))
-
+class ExpandJavascriptSourceTest(TestCase):
     @mock.patch('sentry.models.Event.update')
     @mock.patch('sentry.tasks.fetch_source.fetch_url')
     @mock.patch('sentry.tasks.fetch_source.fetch_sourcemap')
     def test_calls_from_kwargs(self, fetch_sourcemap, fetch_url, update):
-        event = Event(data={
+        data = {
             'sentry.interfaces.Stacktrace': {
                 'frames': [
                     {
@@ -35,22 +30,21 @@ class StoreEventTest(TestCase):
                     },
                 ],
             },
-        })
+        }
         fetch_sourcemap.return_value = None
         fetch_url.return_value.body = '\n'.join('hello world')
 
-        fetch_javascript_source(event)
+        expand_javascript_source(data)
 
         fetch_url.assert_called_once_with('http://example.com/foo.js')
-        update.assert_called_once_with(data=event.data)
 
-        frame_list = event.interfaces['sentry.interfaces.Stacktrace'].frames
+        frame_list = data['sentry.interfaces.Stacktrace']['frames']
         frame = frame_list[0]
-        assert frame.pre_context == ['h', 'e', 'l']
-        assert frame.context_line == 'l'
-        assert frame.post_context == ['o', ' ', 'w', 'o', 'r']
+        assert frame['pre_context'] == ['h', 'e', 'l']
+        assert frame['context_line'] == 'l'
+        assert frame['post_context'] == ['o', ' ', 'w', 'o', 'r']
 
         frame = frame_list[1]
-        assert frame.pre_context == []
-        assert frame.context_line == 'h'
-        assert frame.post_context == ['e', 'l', 'l', 'o', ' ']
+        assert frame['pre_context'] == []
+        assert frame['context_line'] == 'h'
+        assert frame['post_context'] == ['e', 'l', 'l', 'o', ' ']
diff --git a/tests/sentry/tasks/store/tests.py b/tests/sentry/tasks/store/tests.py
index a33b311264..5808b9fcad 100644
--- a/tests/sentry/tasks/store/tests.py
+++ b/tests/sentry/tasks/store/tests.py
@@ -11,10 +11,10 @@ from sentry.testutils import TestCase
 
 class StoreEventTest(TestCase):
     def test_is_task(self):
-        self.assertTrue(isinstance(store_event, Task))
+        assert isinstance(store_event, Task)
 
-    @mock.patch('sentry.models.Group.objects.from_kwargs')
-    def test_calls_from_kwargs(self, from_kwargs):
+    @mock.patch('sentry.tasks.store.preprocess_event')
+    def test_calls_from_kwargs(self, preprocess_event):
         data = {'foo': 'bar'}
         store_event(data=data)
-        from_kwargs.assert_called_once_with(foo='bar')
+        preprocess_event.assert_called_once_with(data=data)
