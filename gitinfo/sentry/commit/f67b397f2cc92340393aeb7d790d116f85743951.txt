commit f67b397f2cc92340393aeb7d790d116f85743951
Author: Dan Fuller <dfuller@sentry.io>
Date:   Tue May 19 11:51:36 2020 -0700

    refs(alert_rules): Switch alert rule create/update code to use aggregate. (#18847)
    
    This moves all code to use the new `SnubaQuery.aggregate` field, and pass `aggregate` around
    (almost) everywhere. We still need to update this in the api, and there are still some places that
    need to change to be able to support aggregates that don't map to our previous default aggregates/

diff --git a/bin/load-mocks b/bin/load-mocks
index 47c5d5ec75..ab514e46e6 100755
--- a/bin/load-mocks
+++ b/bin/load-mocks
@@ -663,7 +663,7 @@ def main(num_events=1, extra_events=False):
             try:
                 # Metric alerts
                 alert_rule = create_alert_rule(
-                    org, [project], "My Alert Rule", "level:error", QueryAggregations.TOTAL, 10, 1
+                    org, [project], "My Alert Rule", "level:error", "count()", 10, 1
                 )
                 create_alert_rule_trigger(alert_rule, "critical", AlertRuleThresholdType.ABOVE, 10)
                 create_incident(
diff --git a/src/sentry/incidents/endpoints/serializers.py b/src/sentry/incidents/endpoints/serializers.py
index 979de17513..da441ed1cc 100644
--- a/src/sentry/incidents/endpoints/serializers.py
+++ b/src/sentry/incidents/endpoints/serializers.py
@@ -34,6 +34,7 @@ from sentry.models.organizationmember import OrganizationMember
 from sentry.models.team import Team
 from sentry.models.user import User
 from sentry.snuba.models import QueryAggregations
+from sentry.snuba.subscriptions import aggregation_function_translations
 from sentry.utils.compat import zip
 
 
@@ -279,7 +280,7 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
         required=True, min_value=1, max_value=int(timedelta(days=1).total_seconds() / 60)
     )
     threshold_period = serializers.IntegerField(default=1, min_value=1, max_value=20)
-    aggregation = serializers.IntegerField(required=False)
+    aggregation = serializers.IntegerField(required=True)
 
     class Meta:
         model = AlertRule
@@ -314,6 +315,8 @@ class AlertRuleSerializer(CamelSnakeModelSerializer):
         This includes ensuring there is either 1 or 2 triggers, which each have actions, and have proper thresholds set.
         The critical trigger should both alert and resolve 'after' the warning trigger (whether that means > or < the value depends on threshold type).
         """
+        data["aggregate"] = aggregation_function_translations[data.pop("aggregation")]
+
         triggers = data.get("triggers", [])
         if not triggers:
             raise serializers.ValidationError("Must include at least one trigger")
diff --git a/src/sentry/incidents/logic.py b/src/sentry/incidents/logic.py
index d3f53d5ab2..2b74e39a84 100644
--- a/src/sentry/incidents/logic.py
+++ b/src/sentry/incidents/logic.py
@@ -34,7 +34,6 @@ from sentry.incidents.models import (
 from sentry.models import Integration, Project
 from sentry.snuba.models import QueryDatasets
 from sentry.snuba.subscriptions import (
-    aggregate_to_query_aggregation,
     bulk_create_snuba_subscriptions,
     bulk_delete_snuba_subscriptions,
     create_snuba_query,
@@ -493,7 +492,7 @@ def create_alert_rule(
     projects,
     name,
     query,
-    aggregation,
+    aggregate,
     time_window,
     threshold_period,
     environment=None,
@@ -509,7 +508,7 @@ def create_alert_rule(
     :param name: Name for the alert rule. This will be used as part of the
     incident name, and must be unique per project
     :param query: An event search query to subscribe to and monitor for alerts
-    :param aggregation: A QueryAggregation to fetch for this alert rule
+    :param aggregate: A string representing the aggregate used in this alert rule
     :param time_window: Time period to aggregate over, in minutes
     :param environment: An optional environment that this rule applies to
     :param threshold_period: How many update periods the value of the
@@ -530,7 +529,7 @@ def create_alert_rule(
         snuba_query = create_snuba_query(
             dataset,
             query,
-            aggregation,
+            aggregate,
             timedelta(minutes=time_window),
             timedelta(minutes=resolution),
             environment,
@@ -597,7 +596,7 @@ def update_alert_rule(
     projects=None,
     name=None,
     query=None,
-    aggregation=None,
+    aggregate=None,
     time_window=None,
     environment=None,
     threshold_period=None,
@@ -613,7 +612,7 @@ def update_alert_rule(
     :param name: Name for the alert rule. This will be used as part of the
     incident name, and must be unique per project.
     :param query: An event search query to subscribe to and monitor for alerts
-    :param aggregation: An AlertRuleAggregation that we want to fetch for this alert rule
+    :param aggregate: A string representing the aggregate used in this alert rule
     :param time_window: Time period to aggregate over, in minutes.
     :param environment: An optional environment that this rule applies to
     :param threshold_period: How many update periods the value of the
@@ -638,8 +637,8 @@ def update_alert_rule(
     if query is not None:
         validate_alert_rule_query(query)
         updated_query_fields["query"] = query
-    if aggregation is not None:
-        updated_query_fields["aggregation"] = aggregation
+    if aggregate is not None:
+        updated_query_fields["aggregate"] = aggregate
     if time_window:
         updated_query_fields["time_window"] = timedelta(minutes=time_window)
     if threshold_period:
@@ -658,9 +657,7 @@ def update_alert_rule(
             updated_query_fields.setdefault("query", snuba_query.query)
             # XXX: We use the alert rule aggregation here since currently we're
             # expecting the enum value to be passed.
-            updated_query_fields.setdefault(
-                "aggregation", aggregate_to_query_aggregation[snuba_query.aggregate]
-            )
+            updated_query_fields.setdefault("aggregate", snuba_query.aggregate)
             updated_query_fields.setdefault(
                 "time_window", timedelta(seconds=snuba_query.time_window)
             )
@@ -674,7 +671,7 @@ def update_alert_rule(
         existing_subs = []
         if (
             query is not None
-            or aggregation is not None
+            or aggregate is not None
             or time_window is not None
             or projects is not None
             or include_all_projects is not None
diff --git a/src/sentry/snuba/subscriptions.py b/src/sentry/snuba/subscriptions.py
index af578c4fa9..03fb57fa21 100644
--- a/src/sentry/snuba/subscriptions.py
+++ b/src/sentry/snuba/subscriptions.py
@@ -22,17 +22,7 @@ aggregate_to_query_aggregation = {
 }
 
 
-def translate_aggregation(aggregation):
-    """
-    Temporary function to translate `QueryAggregations` into the discover aggregation
-    function format
-    :param aggregation:
-    :return: A string representing the aggregate function
-    """
-    return aggregation_function_translations[aggregation]
-
-
-def create_snuba_query(dataset, query, aggregation, time_window, resolution, environment):
+def create_snuba_query(dataset, query, aggregate, time_window, resolution, environment):
     """
     Creates a SnubaQuery.
 
@@ -48,14 +38,14 @@ def create_snuba_query(dataset, query, aggregation, time_window, resolution, env
     return SnubaQuery.objects.create(
         dataset=dataset.value,
         query=query,
-        aggregate=translate_aggregation(aggregation),
+        aggregate=aggregate,
         time_window=int(time_window.total_seconds()),
         resolution=int(resolution.total_seconds()),
         environment=environment,
     )
 
 
-def update_snuba_query(snuba_query, query, aggregation, time_window, resolution, environment):
+def update_snuba_query(snuba_query, query, aggregate, time_window, resolution, environment):
     """
     Updates a SnubaQuery. Triggers updates to any related QuerySubscriptions.
 
@@ -63,7 +53,7 @@ def update_snuba_query(snuba_query, query, aggregation, time_window, resolution,
     :param dataset: The snuba dataset to query and aggregate over
     :param query: An event search query that we can parse and convert into a
     set of Snuba conditions
-    :param aggregation: An aggregation to calculate over the time window
+    :param aggregate: An aggregate to calculate over the time window
     :param time_window: The time window to aggregate over
     :param resolution: How often to receive updates/bucket size
     :param environment: An optional environment to filter by
@@ -73,7 +63,7 @@ def update_snuba_query(snuba_query, query, aggregation, time_window, resolution,
         query_subscriptions = list(snuba_query.subscriptions.all())
         snuba_query.update(
             query=query,
-            aggregate=translate_aggregation(aggregation),
+            aggregate=aggregate,
             time_window=int(time_window.total_seconds()),
             resolution=int(resolution.total_seconds()),
             environment=environment,
diff --git a/src/sentry/testutils/factories.py b/src/sentry/testutils/factories.py
index 765f6509c8..aa25791ca1 100644
--- a/src/sentry/testutils/factories.py
+++ b/src/sentry/testutils/factories.py
@@ -73,7 +73,6 @@ from sentry.models import (
 )
 from sentry.models.integrationfeature import Feature, IntegrationFeature
 from sentry.signals import project_created
-from sentry.snuba.models import QueryAggregations
 from sentry.utils import loremipsum, json
 
 
@@ -336,7 +335,7 @@ class Factories(object):
                 "workspace": integration_id,
                 "channel_id": channel_id or "123453",
                 "channel": channel_name or "#general",
-            },
+            }
         ]
         return Factories.create_project_rule(project, action_data)
 
@@ -858,7 +857,7 @@ class Factories(object):
         projects,
         name=None,
         query="level:error",
-        aggregation=QueryAggregations.TOTAL,
+        aggregate="count()",
         time_window=10,
         threshold_period=1,
         include_all_projects=False,
@@ -874,7 +873,7 @@ class Factories(object):
             projects,
             name,
             query,
-            aggregation,
+            aggregate,
             time_window,
             threshold_period,
             environment=environment,
diff --git a/tests/acceptance/test_incidents.py b/tests/acceptance/test_incidents.py
index 4c0137b27a..87b450dfea 100644
--- a/tests/acceptance/test_incidents.py
+++ b/tests/acceptance/test_incidents.py
@@ -28,13 +28,7 @@ class OrganizationIncidentsListTest(AcceptanceTestCase, SnubaTestCase):
 
     def test_incidents_list(self):
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
         incident = create_incident(
diff --git a/tests/sentry/api/serializers/test_alert_rule.py b/tests/sentry/api/serializers/test_alert_rule.py
index 0fe6712436..66988bdb17 100644
--- a/tests/sentry/api/serializers/test_alert_rule.py
+++ b/tests/sentry/api/serializers/test_alert_rule.py
@@ -12,7 +12,6 @@ from sentry.api.serializers.models.alert_rule import (
 from sentry.models import Rule
 from sentry.incidents.logic import create_alert_rule, create_alert_rule_trigger
 from sentry.incidents.models import AlertRuleThresholdType
-from sentry.snuba.models import QueryAggregations
 from sentry.snuba.subscriptions import aggregate_to_query_aggregation
 from sentry.testutils import TestCase, APITestCase
 
@@ -77,13 +76,7 @@ class BaseAlertRuleSerializerTest(object):
 class AlertRuleSerializerTest(BaseAlertRuleSerializerTest, TestCase):
     def test_simple(self):
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
         result = serialize(alert_rule)
         self.assert_alert_rule_serialized(alert_rule, result)
diff --git a/tests/sentry/incidents/endpoints/test_organization_alert_rule_index.py b/tests/sentry/incidents/endpoints/test_organization_alert_rule_index.py
index e9163384b5..7d88a3137c 100644
--- a/tests/sentry/incidents/endpoints/test_organization_alert_rule_index.py
+++ b/tests/sentry/incidents/endpoints/test_organization_alert_rule_index.py
@@ -6,11 +6,8 @@ from freezegun import freeze_time
 from sentry.api.serializers import serialize
 from sentry.incidents.logic import create_alert_rule
 from sentry.incidents.models import AlertRule
-from sentry.snuba.models import QueryAggregations
 from sentry.testutils import APITestCase
 
-# from sentry.incidents.endpoints.serializers import CRITICAL_TRIGGER_LABEL, WARNING_TRIGGER_LABEL
-
 
 class AlertRuleListEndpointTest(APITestCase):
     endpoint = "sentry-api-0-organization-alert-rules"
@@ -30,13 +27,7 @@ class AlertRuleListEndpointTest(APITestCase):
     def test_simple(self):
         self.create_team(organization=self.organization, members=[self.user])
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
         self.login_as(self.user)
diff --git a/tests/sentry/incidents/endpoints/test_project_alert_rule_details.py b/tests/sentry/incidents/endpoints/test_project_alert_rule_details.py
index 8ef183ccff..598c4dbc7c 100644
--- a/tests/sentry/incidents/endpoints/test_project_alert_rule_details.py
+++ b/tests/sentry/incidents/endpoints/test_project_alert_rule_details.py
@@ -5,8 +5,6 @@ from exam import fixture
 from sentry.api.serializers import serialize
 from sentry.incidents.logic import create_alert_rule
 from sentry.incidents.models import AlertRule, AlertRuleStatus, Incident, IncidentStatus
-from sentry.snuba.models import QueryAggregations
-from sentry.snuba.subscriptions import aggregate_to_query_aggregation
 from sentry.testutils import APITestCase
 
 
@@ -77,13 +75,7 @@ class AlertRuleDetailsBase(object):
     @fixture
     def alert_rule(self):
         return create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
     def test_invalid_rule_id(self):
@@ -148,13 +140,7 @@ class AlertRuleDetailsPutEndpointTest(AlertRuleDetailsBase, APITestCase):
 
     def test_not_updated_fields(self):
         test_params = self.valid_params.copy()
-        test_params.update(
-            {
-                "aggregation": aggregate_to_query_aggregation[
-                    self.alert_rule.snuba_query.aggregate
-                ].value
-            }
-        )
+        test_params["aggregate"] = self.alert_rule.snuba_query.aggregate
 
         self.create_member(
             user=self.user, organization=self.organization, role="owner", teams=[self.team]
diff --git a/tests/sentry/incidents/endpoints/test_project_alert_rule_index.py b/tests/sentry/incidents/endpoints/test_project_alert_rule_index.py
index fe8ad1fe16..ff43f324b1 100644
--- a/tests/sentry/incidents/endpoints/test_project_alert_rule_index.py
+++ b/tests/sentry/incidents/endpoints/test_project_alert_rule_index.py
@@ -11,7 +11,6 @@ from freezegun import freeze_time
 from sentry.api.serializers import serialize
 from sentry.incidents.logic import create_alert_rule
 from sentry.incidents.models import AlertRule
-from sentry.snuba.models import QueryAggregations
 from sentry.testutils.helpers.datetime import before_now
 from sentry.testutils import TestCase, APITestCase
 from tests.sentry.api.serializers.test_alert_rule import BaseAlertRuleSerializerTest
@@ -38,13 +37,7 @@ class AlertRuleListEndpointTest(APITestCase):
     def test_simple(self):
         self.create_team(organization=self.organization, members=[self.user])
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
         self.login_as(self.user)
diff --git a/tests/sentry/incidents/endpoints/test_serializers.py b/tests/sentry/incidents/endpoints/test_serializers.py
index deccbb903b..33575683cc 100644
--- a/tests/sentry/incidents/endpoints/test_serializers.py
+++ b/tests/sentry/incidents/endpoints/test_serializers.py
@@ -87,6 +87,7 @@ class TestAlertRuleSerializer(TestCase):
             "timeWindow": field_is_required,
             "query": field_is_required,
             "triggers": field_is_required,
+            "aggregation": field_is_required,
         }
 
     def test_environment_non_list(self):
diff --git a/tests/sentry/incidents/test_logic.py b/tests/sentry/incidents/test_logic.py
index 8c8984c5b6..9b8c22a228 100644
--- a/tests/sentry/incidents/test_logic.py
+++ b/tests/sentry/incidents/test_logic.py
@@ -68,7 +68,6 @@ from sentry.incidents.models import (
     IncidentType,
 )
 from sentry.snuba.models import QueryAggregations, QueryDatasets
-from sentry.snuba.subscriptions import aggregation_function_translations
 from sentry.models.integration import Integration
 from sentry.testutils import TestCase, SnubaTestCase
 from sentry.testutils.helpers.datetime import iso_format, before_now
@@ -87,13 +86,7 @@ class CreateIncidentTest(TestCase):
         other_project = self.create_project(fire_project_created=True)
         other_group = self.create_group(project=other_project)
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
         self.record_event.reset_mock()
@@ -561,13 +554,7 @@ class CreateIncidentSnapshotTest(TestCase, BaseIncidentsTest):
 
         time_window = 1500  # more than 24 hours, so gets capped at 10 days
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            time_window,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", time_window, 1
         )
 
         incident = self.create_incident(self.organization)
@@ -628,17 +615,11 @@ class CreateAlertRuleTest(TestCase, BaseIncidentsTest):
     def test(self):
         name = "hello"
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count(*)"
         time_window = 10
         threshold_period = 1
         alert_rule = create_alert_rule(
-            self.organization,
-            [self.project],
-            name,
-            query,
-            aggregation,
-            time_window,
-            threshold_period,
+            self.organization, [self.project], name, query, aggregate, time_window, threshold_period
         )
         assert alert_rule.snuba_query.subscriptions.get().project == self.project
         assert alert_rule.name == name
@@ -646,7 +627,7 @@ class CreateAlertRuleTest(TestCase, BaseIncidentsTest):
         assert alert_rule.snuba_query.subscriptions.all().count() == 1
         assert alert_rule.snuba_query.dataset == QueryDatasets.EVENTS.value
         assert alert_rule.snuba_query.query == query
-        assert alert_rule.snuba_query.aggregate == aggregation_function_translations[aggregation]
+        assert alert_rule.snuba_query.aggregate == aggregate
         assert alert_rule.snuba_query.time_window == time_window * 60
         assert alert_rule.snuba_query.resolution == DEFAULT_ALERT_RULE_RESOLUTION * 60
         assert alert_rule.threshold_period == threshold_period
@@ -667,35 +648,25 @@ class CreateAlertRuleTest(TestCase, BaseIncidentsTest):
 
     def test_invalid_query(self):
         with self.assertRaises(InvalidSearchQuery):
-            create_alert_rule(
-                self.organization, [self.project], "hi", "has:", QueryAggregations.TOTAL, 1, 1
-            )
+            create_alert_rule(self.organization, [self.project], "hi", "has:", "count()", 1, 1)
 
     def test_existing_name(self):
         name = "uh oh"
-        create_alert_rule(
-            self.organization, [self.project], name, "level:error", QueryAggregations.TOTAL, 1, 1
-        )
+        create_alert_rule(self.organization, [self.project], name, "level:error", "count()", 1, 1)
         with self.assertRaises(AlertRuleNameAlreadyUsedError):
             create_alert_rule(
-                self.organization,
-                [self.project],
-                name,
-                "level:error",
-                QueryAggregations.TOTAL,
-                1,
-                1,
+                self.organization, [self.project], name, "level:error", "count()", 1, 1
             )
 
     def test_existing_name_allowed_when_archived(self):
         name = "allowed"
         alert_rule_1 = create_alert_rule(
-            self.organization, [self.project], name, "level:error", QueryAggregations.TOTAL, 1, 1
+            self.organization, [self.project], name, "level:error", "count()", 1, 1
         )
         alert_rule_1.update(status=AlertRuleStatus.SNAPSHOT.value)
 
         alert_rule_2 = create_alert_rule(
-            self.organization, [self.project], name, "level:error", QueryAggregations.TOTAL, 1, 1
+            self.organization, [self.project], name, "level:error", "count()", 1, 1
         )
 
         assert alert_rule_1.name == alert_rule_2.name
@@ -709,12 +680,12 @@ class CreateAlertRuleTest(TestCase, BaseIncidentsTest):
     def test_two_archived_with_same_name(self):
         name = "allowed"
         alert_rule_1 = create_alert_rule(
-            self.organization, [self.project], name, "level:error", QueryAggregations.TOTAL, 1, 1
+            self.organization, [self.project], name, "level:error", "count()", 1, 1
         )
         alert_rule_1.update(status=AlertRuleStatus.SNAPSHOT.value)
 
         alert_rule_2 = create_alert_rule(
-            self.organization, [self.project], name, "level:error", QueryAggregations.TOTAL, 1, 1
+            self.organization, [self.project], name, "level:error", "count()", 1, 1
         )
         alert_rule_2.update(status=AlertRuleStatus.SNAPSHOT.value)
 
@@ -727,19 +698,13 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
     @fixture
     def alert_rule(self):
         return create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
     def test(self):
         name = "uh oh"
         query = "level:warning"
-        aggregation = QueryAggregations.UNIQUE_USERS
+        aggregate = "count_unique(tags[sentry:user])"
         time_window = 50
         threshold_period = 2
 
@@ -750,7 +715,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
             projects=updated_projects,
             name=name,
             query=query,
-            aggregation=aggregation,
+            aggregate=aggregate,
             time_window=time_window,
             threshold_period=threshold_period,
         )
@@ -760,16 +725,12 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
         assert set([sub.project for sub in updated_subscriptions]) == set(updated_projects)
         for subscription in updated_subscriptions:
             assert subscription.snuba_query.query == query
-            assert (
-                subscription.snuba_query.aggregate == aggregation_function_translations[aggregation]
-            )
+            assert subscription.snuba_query.aggregate == aggregate
             assert subscription.snuba_query.time_window == int(
                 timedelta(minutes=time_window).total_seconds()
             )
         assert self.alert_rule.snuba_query.query == query
-        assert (
-            self.alert_rule.snuba_query.aggregate == aggregation_function_translations[aggregation]
-        )
+        assert self.alert_rule.snuba_query.aggregate == aggregate
         assert self.alert_rule.snuba_query.time_window == time_window * 60
         assert self.alert_rule.threshold_period == threshold_period
 
@@ -788,13 +749,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
     def test_name_used(self):
         used_name = "uh oh"
         create_alert_rule(
-            self.organization,
-            [self.project],
-            used_name,
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], used_name, "level:error", "count()", 10, 1
         )
         with self.assertRaises(AlertRuleNameAlreadyUsedError):
             update_alert_rule(self.alert_rule, name=used_name)
@@ -809,7 +764,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
             [self.project, self.create_project(fire_project_created=True)],
             "something",
             "level:error",
-            QueryAggregations.TOTAL,
+            "count()",
             10,
             1,
         )
@@ -822,7 +777,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
             [self.project, self.create_project(fire_project_created=True)],
             "something",
             "level:error",
-            QueryAggregations.TOTAL,
+            "count()",
             10,
             1,
         )
@@ -907,7 +862,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
                 self.alert_rule,
                 projects=updated_projects,
                 query="level:warning",
-                aggregation=QueryAggregations.UNIQUE_USERS,
+                aggregate="count_unique(tags[sentry:user])",
                 time_window=50,
                 threshold_period=2,
             )
@@ -927,10 +882,7 @@ class UpdateAlertRuleTest(TestCase, BaseIncidentsTest):
             assert rule_snapshot.name == updated_rule.name
             assert rule_snapshot.snuba_query.query == "level:error"
             assert rule_snapshot.snuba_query.time_window == 600
-            assert (
-                rule_snapshot.snuba_query.aggregate
-                == aggregation_function_translations[QueryAggregations.TOTAL]
-            )
+            assert rule_snapshot.snuba_query.aggregate == "count()"
             assert rule_snapshot.threshold_period == 1
 
             for incident in (incident, incident_2):
@@ -970,13 +922,7 @@ class DeleteAlertRuleTest(TestCase, BaseIncidentsTest):
     @fixture
     def alert_rule(self):
         return create_alert_rule(
-            self.organization,
-            [self.project],
-            "hello",
-            "level:error",
-            QueryAggregations.TOTAL,
-            10,
-            1,
+            self.organization, [self.project], "hello", "level:error", "count()", 10, 1
         )
 
     def test(self):
diff --git a/tests/sentry/incidents/test_subscription_processor.py b/tests/sentry/incidents/test_subscription_processor.py
index e4c38f2dc2..fea15ff6e5 100644
--- a/tests/sentry/incidents/test_subscription_processor.py
+++ b/tests/sentry/incidents/test_subscription_processor.py
@@ -38,7 +38,7 @@ from sentry.incidents.subscription_processor import (
     SubscriptionProcessor,
     update_alert_rule_stats,
 )
-from sentry.snuba.models import QueryAggregations, QuerySubscription
+from sentry.snuba.models import QuerySubscription
 from sentry.testutils import TestCase
 from sentry.utils.dates import to_timestamp
 from sentry.utils.compat import map
@@ -83,7 +83,7 @@ class ProcessUpdateTest(TestCase):
             [self.project, self.other_project],
             "some rule",
             query="",
-            aggregation=QueryAggregations.TOTAL,
+            aggregate="count()",
             time_window=1,
             threshold_period=1,
         )
diff --git a/tests/sentry/snuba/test_query_subscription_consumer.py b/tests/sentry/snuba/test_query_subscription_consumer.py
index 2c58160650..21e9ab97ef 100644
--- a/tests/sentry/snuba/test_query_subscription_consumer.py
+++ b/tests/sentry/snuba/test_query_subscription_consumer.py
@@ -13,7 +13,7 @@ from django.conf import settings
 from exam import fixture, patcher
 
 from sentry.utils.compat.mock import Mock
-from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
+from sentry.snuba.models import QueryDatasets, QuerySubscription
 from sentry.snuba.query_subscription_consumer import (
     InvalidMessageError,
     InvalidSchemaError,
@@ -99,7 +99,7 @@ class HandleMessageTest(BaseQuerySubscriptionTest, TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "hello",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
diff --git a/tests/sentry/snuba/test_subscriptions.py b/tests/sentry/snuba/test_subscriptions.py
index 1be0a75e53..1311ffd316 100644
--- a/tests/sentry/snuba/test_subscriptions.py
+++ b/tests/sentry/snuba/test_subscriptions.py
@@ -2,14 +2,12 @@ from __future__ import absolute_import
 
 from datetime import timedelta
 
-from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
+from sentry.snuba.models import QueryDatasets, QuerySubscription
 from sentry.snuba.subscriptions import (
-    aggregation_function_translations,
     bulk_delete_snuba_subscriptions,
     create_snuba_query,
     create_snuba_subscription,
     delete_snuba_subscription,
-    translate_aggregation,
     update_snuba_query,
     update_snuba_subscription,
 )
@@ -20,13 +18,13 @@ class CreateSnubaQueryTest(TestCase):
     def test(self):
         dataset = QueryDatasets.EVENTS
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        snuba_query = create_snuba_query(dataset, query, aggregation, time_window, resolution, None)
+        snuba_query = create_snuba_query(dataset, query, aggregate, time_window, resolution, None)
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
-        assert snuba_query.aggregate == translate_aggregation(aggregation)
+        assert snuba_query.aggregate == aggregate
         assert snuba_query.time_window == int(time_window.total_seconds())
         assert snuba_query.resolution == int(resolution.total_seconds())
         assert snuba_query.environment is None
@@ -34,15 +32,15 @@ class CreateSnubaQueryTest(TestCase):
     def test_environment(self):
         dataset = QueryDatasets.EVENTS
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
         snuba_query = create_snuba_query(
-            dataset, query, aggregation, time_window, resolution, self.environment
+            dataset, query, aggregate, time_window, resolution, self.environment
         )
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
-        assert snuba_query.aggregate == translate_aggregation(aggregation)
+        assert snuba_query.aggregate == aggregate
         assert snuba_query.time_window == int(time_window.total_seconds())
         assert snuba_query.resolution == int(resolution.total_seconds())
         assert snuba_query.environment == self.environment
@@ -53,11 +51,10 @@ class CreateSnubaSubscriptionTest(TestCase):
         type = "something"
         dataset = QueryDatasets.EVENTS
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
         snuba_query = create_snuba_query(
-            dataset, query, aggregation, time_window, resolution, self.environment
+            dataset, query, "count()", time_window, resolution, self.environment
         )
         subscription = create_snuba_subscription(self.project, type, snuba_query)
 
@@ -71,11 +68,10 @@ class CreateSnubaSubscriptionTest(TestCase):
             type = "something"
             dataset = QueryDatasets.EVENTS
             query = "level:error"
-            aggregation = QueryAggregations.TOTAL
             time_window = timedelta(minutes=10)
             resolution = timedelta(minutes=1)
             snuba_query = create_snuba_query(
-                dataset, query, aggregation, time_window, resolution, self.environment
+                dataset, query, "count()", time_window, resolution, self.environment
             )
             subscription = create_snuba_subscription(self.project, type, snuba_query)
             subscription = QuerySubscription.objects.get(id=subscription.id)
@@ -88,12 +84,11 @@ class CreateSnubaSubscriptionTest(TestCase):
         type = "something"
         dataset = QueryDatasets.EVENTS
         query = "event.type:error"
-        aggregation = QueryAggregations.TOTAL
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
         with self.tasks():
             snuba_query = create_snuba_query(
-                dataset, query, aggregation, time_window, resolution, self.environment
+                dataset, query, "count()", time_window, resolution, self.environment
             )
             subscription = create_snuba_subscription(self.project, type, snuba_query)
         subscription = QuerySubscription.objects.get(id=subscription.id)
@@ -109,19 +104,19 @@ class UpdateSnubaQueryTest(TestCase):
         snuba_query = create_snuba_query(
             dataset,
             "hello",
-            QueryAggregations.UNIQUE_USERS,
+            "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
             timedelta(minutes=2),
             self.environment,
         )
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregation, time_window, resolution, None)
+        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, None)
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
-        assert snuba_query.aggregate == translate_aggregation(aggregation)
+        assert snuba_query.aggregate == aggregate
         assert snuba_query.time_window == int(time_window.total_seconds())
         assert snuba_query.resolution == int(resolution.total_seconds())
         assert snuba_query.environment is None
@@ -131,7 +126,7 @@ class UpdateSnubaQueryTest(TestCase):
         snuba_query = create_snuba_query(
             dataset,
             "hello",
-            QueryAggregations.UNIQUE_USERS,
+            "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
             timedelta(minutes=2),
             self.environment,
@@ -139,13 +134,13 @@ class UpdateSnubaQueryTest(TestCase):
 
         new_env = self.create_environment()
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregation, time_window, resolution, new_env)
+        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, new_env)
         assert snuba_query.dataset == dataset.value
         assert snuba_query.query == query
-        assert snuba_query.aggregate == translate_aggregation(aggregation)
+        assert snuba_query.aggregate == aggregate
         assert snuba_query.time_window == int(time_window.total_seconds())
         assert snuba_query.resolution == int(resolution.total_seconds())
         assert snuba_query.environment == new_env
@@ -155,7 +150,7 @@ class UpdateSnubaQueryTest(TestCase):
         snuba_query = create_snuba_query(
             dataset,
             "hello",
-            QueryAggregations.UNIQUE_USERS,
+            "count_unique(tags[sentry:user])",
             timedelta(minutes=100),
             timedelta(minutes=2),
             self.environment,
@@ -164,10 +159,10 @@ class UpdateSnubaQueryTest(TestCase):
 
         new_env = self.create_environment()
         query = "level:error"
-        aggregation = QueryAggregations.TOTAL
+        aggregate = "count()"
         time_window = timedelta(minutes=10)
         resolution = timedelta(minutes=1)
-        update_snuba_query(snuba_query, query, aggregation, time_window, resolution, new_env)
+        update_snuba_query(snuba_query, query, aggregate, time_window, resolution, new_env)
         sub.refresh_from_db()
         assert sub.snuba_query == snuba_query
         assert sub.status == QuerySubscription.Status.UPDATING.value
@@ -179,7 +174,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
@@ -187,7 +182,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             subscription = create_snuba_subscription(self.project, "something", snuba_query)
 
         query = "level:warning"
-        aggregation = QueryAggregations.UNIQUE_USERS
+        aggregate = "count_unique(tags[sentry:user])"
         time_window = timedelta(minutes=20)
         resolution = timedelta(minutes=2)
         subscription = QuerySubscription.objects.get(id=subscription.id)
@@ -197,14 +192,14 @@ class UpdateSnubaSubscriptionTest(TestCase):
             time_window=int(time_window.total_seconds()),
             resolution=int(resolution.total_seconds()),
             environment=self.environment,
-            aggregate=aggregation_function_translations[aggregation],
+            aggregate=aggregate,
         )
         assert subscription_id is not None
         update_snuba_subscription(subscription, snuba_query)
         assert subscription.status == QuerySubscription.Status.UPDATING.value
         assert subscription.subscription_id == subscription_id
         assert subscription.snuba_query.query == query
-        assert subscription.snuba_query.aggregate == aggregation_function_translations[aggregation]
+        assert subscription.snuba_query.aggregate == aggregate
         assert subscription.snuba_query.time_window == int(time_window.total_seconds())
         assert subscription.snuba_query.resolution == int(resolution.total_seconds())
 
@@ -213,7 +208,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
@@ -221,7 +216,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
             subscription = create_snuba_subscription(self.project, "something", snuba_query)
 
             query = "level:warning"
-            aggregation = QueryAggregations.UNIQUE_USERS
+            aggregate = "count_unique(tags[sentry:user])"
             time_window = timedelta(minutes=20)
             resolution = timedelta(minutes=2)
             subscription = QuerySubscription.objects.get(id=subscription.id)
@@ -232,7 +227,7 @@ class UpdateSnubaSubscriptionTest(TestCase):
                 time_window=int(time_window.total_seconds()),
                 resolution=int(resolution.total_seconds()),
                 environment=self.environment,
-                aggregate=translate_aggregation(aggregation),
+                aggregate=aggregate,
             )
             update_snuba_subscription(subscription, snuba_query)
             subscription = QuerySubscription.objects.get(id=subscription.id)
@@ -247,7 +242,7 @@ class BulkDeleteSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
@@ -256,7 +251,7 @@ class BulkDeleteSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
@@ -282,7 +277,7 @@ class DeleteSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
@@ -301,7 +296,7 @@ class DeleteSnubaSubscriptionTest(TestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "level:error",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=10),
                 timedelta(minutes=1),
                 None,
diff --git a/tests/sentry/snuba/test_tasks.py b/tests/sentry/snuba/test_tasks.py
index a619882cca..9ca2bebdee 100644
--- a/tests/sentry/snuba/test_tasks.py
+++ b/tests/sentry/snuba/test_tasks.py
@@ -9,8 +9,7 @@ from exam import patcher
 from mock import Mock, patch
 from six import add_metaclass
 
-from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription, SnubaQuery
-from sentry.snuba.subscriptions import translate_aggregation
+from sentry.snuba.models import QueryDatasets, QuerySubscription, SnubaQuery
 from sentry.snuba.tasks import (
     create_subscription_in_snuba,
     update_subscription_in_snuba,
@@ -41,14 +40,14 @@ class BaseSnubaTaskTest(object):
         if status is None:
             status = self.expected_status
         dataset = QueryDatasets.EVENTS.value
-        aggregate = QueryAggregations.UNIQUE_USERS
+        aggregate = "count_unique(tags[sentry:user])"
         query = "hello"
         time_window = 60
         resolution = 60
 
         snuba_query = SnubaQuery.objects.create(
             dataset=dataset,
-            aggregate=translate_aggregation(aggregate),
+            aggregate=aggregate,
             query=query,
             time_window=time_window,
             resolution=resolution,
diff --git a/tests/snuba/incidents/test_tasks.py b/tests/snuba/incidents/test_tasks.py
index a6051c78e5..6a41f5baa6 100644
--- a/tests/snuba/incidents/test_tasks.py
+++ b/tests/snuba/incidents/test_tasks.py
@@ -27,7 +27,6 @@ from sentry.incidents.models import (
     TriggerStatus,
 )
 from sentry.incidents.tasks import INCIDENTS_SNUBA_SUBSCRIPTION_TYPE
-from sentry.snuba.models import QueryAggregations
 from sentry.snuba.query_subscription_consumer import QuerySubscriptionConsumer, subscriber_registry
 
 from sentry.testutils import TestCase
@@ -61,7 +60,7 @@ class HandleSnubaQueryUpdateTest(TestCase):
                 [self.project],
                 "some rule",
                 query="",
-                aggregation=QueryAggregations.TOTAL,
+                aggregate="count()",
                 time_window=1,
                 threshold_period=1,
             )
diff --git a/tests/snuba/snuba/test_query_subscription_consumer.py b/tests/snuba/snuba/test_query_subscription_consumer.py
index 69561d3ba5..1c162fe4a5 100644
--- a/tests/snuba/snuba/test_query_subscription_consumer.py
+++ b/tests/snuba/snuba/test_query_subscription_consumer.py
@@ -13,7 +13,7 @@ from django.test.utils import override_settings
 from exam import fixture
 from sentry.utils.compat.mock import call, Mock
 
-from sentry.snuba.models import QueryAggregations, QueryDatasets
+from sentry.snuba.models import QueryDatasets
 from sentry.snuba.query_subscription_consumer import (
     QuerySubscriptionConsumer,
     register_subscriber,
@@ -89,7 +89,7 @@ class QuerySubscriptionConsumerTest(TestCase, SnubaTestCase):
             snuba_query = create_snuba_query(
                 QueryDatasets.EVENTS,
                 "hello",
-                QueryAggregations.TOTAL,
+                "count()",
                 timedelta(minutes=1),
                 timedelta(minutes=1),
                 None,
