commit 760893922fa599266aa922920f0fd25cdc8a5597
Author: Jess MacQueen <jessmacqueen@gmail.com>
Date:   Mon Jan 28 15:45:05 2019 -0800

    feat(api): Add organization group index delete method

diff --git a/src/sentry/api/endpoints/organization_group_index.py b/src/sentry/api/endpoints/organization_group_index.py
index 88012afb67..dbf1637aeb 100644
--- a/src/sentry/api/endpoints/organization_group_index.py
+++ b/src/sentry/api/endpoints/organization_group_index.py
@@ -9,7 +9,7 @@ from rest_framework.response import Response
 
 from sentry.api.bases import OrganizationEventsEndpointBase
 from sentry.api.helpers.group_index import (
-    build_query_params_from_request, get_by_short_id, update_groups, ValidationError
+    build_query_params_from_request, delete_groups, get_by_short_id, update_groups, ValidationError
 )
 from sentry.api.serializers import serialize
 from sentry.api.serializers.models.group import StreamGroupSerializerSnuba
@@ -221,7 +221,8 @@ class OrganizationGroupIndexEndpoint(OrganizationEventsEndpointBase):
         projects = self.get_projects(request, organization)
 
         search_fn = functools.partial(
-            self._search, request, organization, projects, self.get_environments(request, organization), {
+            self._search, request, organization, projects,
+            self.get_environments(request, organization), {
                 'limit': 1000,
                 'paginator_options': {'max_limit': 1000},
             }
@@ -232,3 +233,40 @@ class OrganizationGroupIndexEndpoint(OrganizationEventsEndpointBase):
             organization.id,
             search_fn,
         )
+
+    def delete(self, request, organization):
+        """
+        Bulk Remove a List of Issues
+        ````````````````````````````
+
+        Permanently remove the given issues. The list of issues to
+        modify is given through the `id` query parameter.  It is repeated
+        for each issue that should be removed.
+
+        Only queries by 'id' are accepted.
+
+        If any ids are out of scope this operation will succeed without
+        any data mutation.
+
+        :qparam int id: a list of IDs of the issues to be removed.  This
+                        parameter shall be repeated for each issue.
+        :pparam string organization_slug: the slug of the organization the
+                                          issues belong to.
+        :auth: required
+        """
+        projects = self.get_projects(request, organization)
+
+        search_fn = functools.partial(
+            self._search, request, organization, projects,
+            self.get_environments(request, organization), {
+                'limit': 1000,
+                'paginator_options': {'max_limit': 1000},
+            }
+        )
+
+        return delete_groups(
+            request,
+            projects,
+            organization.id,
+            search_fn,
+        )
diff --git a/tests/snuba/api/endpoints/test_organization_group_index.py b/tests/snuba/api/endpoints/test_organization_group_index.py
index 219ae7b562..8df443be87 100644
--- a/tests/snuba/api/endpoints/test_organization_group_index.py
+++ b/tests/snuba/api/endpoints/test_organization_group_index.py
@@ -3,6 +3,8 @@ from __future__ import absolute_import
 import json
 import six
 from datetime import timedelta
+from uuid import uuid4
+
 from django.core.urlresolvers import reverse
 from django.utils import timezone
 from exam import fixture
@@ -1825,3 +1827,129 @@ class GroupUpdateTest(APITestCase, SnubaTestCase):
         assert tombstone.culprit == group1.culprit
         assert tombstone.project == group1.project
         assert tombstone.data == group1.data
+
+
+class GroupDeleteTest(APITestCase, SnubaTestCase):
+    @fixture
+    def path(self):
+        return u'/api/0/organizations/{}/issues/'.format(
+            self.project.organization.slug,
+        )
+
+    @patch('sentry.api.helpers.group_index.eventstream')
+    @patch('sentry.eventstream')
+    def test_delete_by_id(self, mock_eventstream_task, mock_eventstream_api):
+        eventstream_state = object()
+        mock_eventstream_api.start_delete_groups = Mock(return_value=eventstream_state)
+
+        group1 = self.create_group(checksum='a' * 32, status=GroupStatus.RESOLVED)
+        group2 = self.create_group(checksum='b' * 32, status=GroupStatus.UNRESOLVED)
+        group3 = self.create_group(checksum='c' * 32, status=GroupStatus.IGNORED)
+        group4 = self.create_group(
+            project=self.create_project(slug='foo'),
+            checksum='b' * 32,
+            status=GroupStatus.UNRESOLVED
+        )
+
+        hashes = []
+        for g in group1, group2, group3, group4:
+            hash = uuid4().hex
+            hashes.append(hash)
+            GroupHash.objects.create(
+                project=g.project,
+                hash=hash,
+                group=g,
+            )
+
+        self.login_as(user=self.user)
+        url = u'{url}?id={group1.id}&id={group2.id}&group4={group4.id}'.format(
+            url=self.path,
+            group1=group1,
+            group2=group2,
+            group4=group4,
+        )
+
+        response = self.client.delete(url, format='json')
+
+        mock_eventstream_api.start_delete_groups.assert_called_once_with(
+            group1.project_id, [group1.id, group2.id])
+
+        assert response.status_code == 204
+
+        assert Group.objects.get(id=group1.id).status == GroupStatus.PENDING_DELETION
+        assert not GroupHash.objects.filter(group_id=group1.id).exists()
+
+        assert Group.objects.get(id=group2.id).status == GroupStatus.PENDING_DELETION
+        assert not GroupHash.objects.filter(group_id=group2.id).exists()
+
+        assert Group.objects.get(id=group3.id).status != GroupStatus.PENDING_DELETION
+        assert GroupHash.objects.filter(group_id=group3.id).exists()
+
+        assert Group.objects.get(id=group4.id).status != GroupStatus.PENDING_DELETION
+        assert GroupHash.objects.filter(group_id=group4.id).exists()
+
+        Group.objects.filter(id__in=(group1.id, group2.id)).update(status=GroupStatus.UNRESOLVED)
+
+        with self.tasks():
+            response = self.client.delete(url, format='json')
+
+        mock_eventstream_task.end_delete_groups.assert_called_once_with(eventstream_state)
+
+        assert response.status_code == 204
+
+        assert not Group.objects.filter(id=group1.id).exists()
+        assert not GroupHash.objects.filter(group_id=group1.id).exists()
+
+        assert not Group.objects.filter(id=group2.id).exists()
+        assert not GroupHash.objects.filter(group_id=group2.id).exists()
+
+        assert Group.objects.filter(id=group3.id).exists()
+        assert GroupHash.objects.filter(group_id=group3.id).exists()
+
+        assert Group.objects.filter(id=group4.id).exists()
+        assert GroupHash.objects.filter(group_id=group4.id).exists()
+
+    def test_bulk_delete(self):
+        groups = []
+        for i in range(10, 41):
+            groups.append(
+                self.create_group(
+                    project=self.project,
+                    checksum=six.binary_type(i) * 16,
+                    status=GroupStatus.RESOLVED))
+
+        hashes = []
+        for group in groups:
+            hash = uuid4().hex
+            hashes.append(hash)
+            GroupHash.objects.create(
+                project=group.project,
+                hash=hash,
+                group=group,
+            )
+
+        self.login_as(user=self.user)
+
+        # if query is '' it defaults to is:unresolved
+        url = self.path + '?query='
+        response = self.client.delete(url, format='json')
+
+        assert response.status_code == 204
+
+        for group in groups:
+            assert Group.objects.get(id=group.id).status == GroupStatus.PENDING_DELETION
+            assert not GroupHash.objects.filter(group_id=group.id).exists()
+
+        Group.objects.filter(
+            id__in=[
+                group.id for group in groups]).update(
+            status=GroupStatus.UNRESOLVED)
+
+        with self.tasks():
+            response = self.client.delete(url, format='json')
+
+        assert response.status_code == 204
+
+        for group in groups:
+            assert not Group.objects.filter(id=group.id).exists()
+            assert not GroupHash.objects.filter(group_id=group.id).exists()
