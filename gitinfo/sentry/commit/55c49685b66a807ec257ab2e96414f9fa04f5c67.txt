commit 55c49685b66a807ec257ab2e96414f9fa04f5c67
Author: David Cramer <dcramer@gmail.com>
Date:   Wed Feb 13 00:12:06 2013 -0800

    Use existing infrastructure for doing alerts

diff --git a/src/sentry/app.py b/src/sentry/app.py
index ccf56b5747..b716259e2e 100644
--- a/src/sentry/app.py
+++ b/src/sentry/app.py
@@ -22,5 +22,4 @@ def get_instance(path, options):
     return cls(**options)
 
 buffer = get_instance(settings.BUFFER, settings.BUFFER_OPTIONS)
-counter = get_instance(settings.COUNTER, settings.COUNTER_OPTIONS)
 env = State()
diff --git a/src/sentry/conf/defaults.py b/src/sentry/conf/defaults.py
index 3adeec60cc..5f0c511f08 100644
--- a/src/sentry/conf/defaults.py
+++ b/src/sentry/conf/defaults.py
@@ -165,10 +165,6 @@ REDIS_OPTIONS = {}
 BUFFER = 'sentry.buffer.Buffer'
 BUFFER_OPTIONS = {}
 
-# Counter backend to use
-COUNTER = 'sentry.counter.Counter'
-COUNTER_OPTIONS = {}
-
 # Auth engines and the settings required for them to be listed
 AUTH_PROVIDERS = {
     'twitter': ('TWITTER_CONSUMER_KEY', 'TWITTER_CONSUMER_SECRET'),
diff --git a/src/sentry/counter/__init__.py b/src/sentry/counter/__init__.py
deleted file mode 100644
index cae8a8233e..0000000000
--- a/src/sentry/counter/__init__.py
+++ /dev/null
@@ -1,9 +0,0 @@
-"""
-sentry.counter
-~~~~~~~~~~~~~~
-
-:copyright: (c) 2010-2012 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
-
-from .base import Counter  # NOQA
diff --git a/src/sentry/counter/base.py b/src/sentry/counter/base.py
deleted file mode 100644
index fb5fec1f32..0000000000
--- a/src/sentry/counter/base.py
+++ /dev/null
@@ -1,43 +0,0 @@
-"""
-sentry.counter.base
-~~~~~~~~~~~~~~~~~~~
-
-:copyright: (c) 2010-2012 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
-
-
-class Counter(object):
-    """
-    A counter is a temporary store for real-time counts for recent historical
-    data on events.
-
-    Specifically, they store the following:
-
-    - events per project
-    - events per group (aggregate)
-
-    Each grouping tracks the following:
-
-    - # of total events
-
-    Each counter stores counts at minute-level intervals for 15 minutes.
-    """
-    MINUTES = 15
-
-    def __init__(self, **options):
-        pass
-
-    def incr(self, group, **kwargs):
-        """
-        >>> incr(group, is_new=False)
-        """
-        pass
-
-    def extract_counts(self, when=None, prefix='project', **kwargs):
-        return {
-            'when': when,
-            'results': [
-                # (project_id, count)
-            ],
-        }
diff --git a/src/sentry/counter/redis.py b/src/sentry/counter/redis.py
deleted file mode 100644
index 4b0e6b0710..0000000000
--- a/src/sentry/counter/redis.py
+++ /dev/null
@@ -1,69 +0,0 @@
-"""
-sentry.counter.redis
-~~~~~~~~~~~~~~~~~~~~
-
-:copyright: (c) 2010-2012 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
-
-from __future__ import with_statement
-
-import time
-from nydus.db import create_cluster
-from sentry.counter import Counter
-from sentry.conf import settings
-
-
-class RedisCounter(Counter):
-    def __init__(self, **options):
-        if not options:
-            # inherit default options from REDIS_OPTIONS
-            options = settings.REDIS_OPTIONS
-
-        super(RedisCounter, self).__init__(**options)
-        options.setdefault('hosts', {
-            0: {},
-        })
-        options.setdefault('router', 'nydus.db.routers.keyvalue.PartitionRouter')
-        self.conn = create_cluster({
-            'engine': 'nydus.db.backends.redis.Redis',
-            'router': options['router'],
-            'hosts': options['hosts'],
-        })
-
-    def _make_key(self, prefix, when=None):
-        """
-        Returns a Redis-compatible key for the given key/value combination.
-        """
-        if when is None:
-            when = time.time()
-        when = int(when / 60)  # chop it down to the minute
-        return 'sentry.counter:%s:%s' % (prefix, when)
-
-    def incr(self, group):
-        now = time.time()
-        with self.conn.map() as conn:
-            keys = [
-                (self._make_key('project', now), group.project_id),
-                (self._make_key('group', now), group.id),
-            ]
-
-            for key, member in keys:
-                conn.zincrby(key, member)
-                conn.expire(key, 60 * self.MINUTES)
-
-    def extract_counts(self, when=None, prefix='project'):
-        # TODO: this could become expensive as it scales linearly with the number of unique
-        # items to check
-        if not when:
-            when = time.time() - 60
-
-        with self.conn.map() as conn:
-            key = self._make_key(prefix, when)
-            results = conn.zrange(key, 0, -1, withscores=True)
-            conn.delete(key)
-
-        return {
-            'when': when,
-            'results': results,
-        }
diff --git a/src/sentry/manager.py b/src/sentry/manager.py
index 3c9d52d9a4..df95fa88f1 100644
--- a/src/sentry/manager.py
+++ b/src/sentry/manager.py
@@ -602,13 +602,6 @@ class GroupManager(BaseManager, ChartMixin):
         except Exception, e:
             logger.exception('Unable to record tags: %s' % (e,))
 
-        # It's important that we increment short-counters without using the queue otherwise they could
-        # quickly become inaccurate
-        try:
-            app.counter.incr(group=group)
-        except Exception, e:
-            logger.exception('Unable to increment counters: %s' % (e,))
-
         return group, is_new, is_sample
 
     def record_affected_user(self, group, user_ident, data=None):
diff --git a/src/sentry/tasks/check_alerts.py b/src/sentry/tasks/check_alerts.py
index 860db77c16..45194c80f8 100644
--- a/src/sentry/tasks/check_alerts.py
+++ b/src/sentry/tasks/check_alerts.py
@@ -34,12 +34,11 @@ Alert expiration threshold MUST be > MINUTE_NORMALIZATION.
 from __future__ import division
 
 import math
-import time
-from datetime import datetime, timedelta
+from datetime import timedelta
 from celery.task import periodic_task, task
 from celery.task.schedules import crontab
-from django.conf import settings as dj_settings
 from django.utils import timezone
+from sentry.constants import MINUTE_NORMALIZATION
 
 
 def fsteps(start, stop, steps):
@@ -66,20 +65,21 @@ def check_alerts(**kwargs):
     Iterates all current keys and fires additional tasks to check each individual
     project's alert settings.
     """
-    from sentry import app
+    from sentry.models import ProjectCountByMinute
     from sentry.utils.queue import maybe_delay
 
-    timestamp = time.time() - 60
-    when = datetime.fromtimestamp(timestamp)
-    if dj_settings.USE_TZ:
-        when = when.replace(tzinfo=timezone.utc)
+    when = timezone.now()
 
-    results = app.counter.extract_counts(prefix='project', when=timestamp)['results']
-    for project_id, count in results:
+    # find each project which has data for the last interval
+    # TODO: we could force more work on the db by eliminating onces which dont have the full aggregate we need
+    qs = ProjectCountByMinute.objects.filter(
+        date__gt=when - timedelta(minutes=MINUTE_NORMALIZATION),
+    ).values_list('project_id', 'date', 'times_seen')
+    for project_id, date, count in qs:
         maybe_delay(check_project_alerts,
-            project_id=int(project_id),
+            project_id=project_id,
             when=when,
-            count=int(count),
+            count=int(count / ((when - date).seconds / 60)),
             expires=120,
         )
 
@@ -90,7 +90,6 @@ def check_project_alerts(project_id, when, count, **kwargs):
     Given 'when' and 'count', which should signify recent times we compare it to historical data for this project
     and if over a given threshold, create an alert.
     """
-    from sentry.constants import MINUTE_NORMALIZATION
     from sentry.conf import settings
     from sentry.models import ProjectCountByMinute, ProjectOption, Alert
 
diff --git a/tests/sentry/counter/__init__.py b/tests/sentry/counter/__init__.py
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/tests/sentry/counter/redis/__init__.py b/tests/sentry/counter/redis/__init__.py
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/tests/sentry/counter/redis/tests.py b/tests/sentry/counter/redis/tests.py
deleted file mode 100644
index af76fb89f1..0000000000
--- a/tests/sentry/counter/redis/tests.py
+++ /dev/null
@@ -1,49 +0,0 @@
-# -*- coding: utf-8 -*-
-
-from __future__ import absolute_import
-
-import mock
-import time
-
-from sentry.counter.redis import RedisCounter
-from sentry.testutils import TestCase, fixture
-
-
-class RedisCounterTest(TestCase):
-    @fixture
-    def counter(self):
-        counter = RedisCounter(hosts={
-            0: {'db': 9}
-        })
-        counter.conn.flushdb()
-        return counter
-
-    def test_default_host_is_local(self):
-        counter = RedisCounter()
-        self.assertEquals(len(counter.conn.hosts), 1)
-        self.assertEquals(counter.conn.hosts[0].host, 'localhost')
-
-    @mock.patch('sentry.counter.redis.time')
-    def test_make_key_response(self, time_):
-        time_ = time_.time
-
-        time_.return_value = 1360644295.816033
-        assert self.counter._make_key('project') == 'sentry.counter:project:22677404'
-        time_.assert_called_once_with()
-
-        now = 1360654295.816033
-        assert self.counter._make_key('team', now) == 'sentry.counter:team:22677571'
-
-    def test_all_the_things(self):
-        # TODO
-        self.counter.incr(self.group)
-        self.counter.incr(self.group)
-        self.counter.incr(self.group)
-
-        when = time.time()
-
-        results = self.counter.extract_counts(prefix='project', when=when)
-        assert results == {
-            'when': when,
-            'results': [(str(self.project.id), 3.0)],
-        }
diff --git a/tests/sentry/manager/tests.py b/tests/sentry/manager/tests.py
index 61bc5d3ceb..77afde413d 100644
--- a/tests/sentry/manager/tests.py
+++ b/tests/sentry/manager/tests.py
@@ -246,21 +246,6 @@ class SentryManagerTest(TestCase):
         self.assertEquals(res.value, 'boz')
         self.assertEquals(res.times_seen, 1)
 
-    @mock.patch('sentry.manager.send_group_processors', mock.Mock())
-    @mock.patch('sentry.manager.app.counter.incr')
-    def test_calls_incr_counters(self, incr):
-        event = Group.objects.from_kwargs(1, message='foo', tags=[('foo', 'bar')])
-        group = event.group
-        incr.assert_called_once_with(group=group)
-
-    @mock.patch('sentry.manager.send_group_processors', mock.Mock())
-    @mock.patch('sentry.manager.app.counter.incr')
-    def test_handles_incr_counters_failure(self, incr):
-        incr.side_effect = Exception()
-        event = Group.objects.from_kwargs(1, message='foo')
-        group = event.group
-        incr.assert_called_once_with(group=group)
-
 
 class SearchManagerTest(TestCase):
     def test_search(self):
diff --git a/tests/sentry/tasks/check_alerts/tests.py b/tests/sentry/tasks/check_alerts/tests.py
index ecdfbcb434..fa24c40f79 100644
--- a/tests/sentry/tasks/check_alerts/tests.py
+++ b/tests/sentry/tasks/check_alerts/tests.py
@@ -1,5 +1,5 @@
 import mock
-from datetime import datetime, timedelta
+from datetime import timedelta
 from django.utils import timezone
 from sentry.models import ProjectCountByMinute, Alert
 from sentry.tasks.check_alerts import check_project_alerts, check_alerts
@@ -7,46 +7,40 @@ from sentry.testutils import TestCase
 from sentry.utils.dates import normalize_datetime
 
 
-class CheckAlertsTest(TestCase):
+class BaseTestCase(TestCase):
+    def create_counts(self, when, amount, minute_offset=0, normalize=True):
+        date = when - timedelta(minutes=minute_offset)
+        if normalize:
+            date = normalize_datetime(date)
+
+        ProjectCountByMinute.objects.create(
+            project=self.project,
+            date=date,
+            times_seen=amount,
+        )
+
+
+class CheckAlertsTest(BaseTestCase):
     @mock.patch('sentry.utils.queue.maybe_delay')
-    @mock.patch('sentry.app.counter')
-    @mock.patch('sentry.tasks.check_alerts.time')
-    def test_does_fire_jobs(self, time, counter, maybe_delay):
-        time = time.time
-        time.return_value = 1360721852.660331
+    def test_does_fire_jobs(self, maybe_delay):
+        when = timezone.now()
+        self.create_counts(when, 50, 5, normalize=False)
 
-        timestamp = time.return_value - 60
-        when = datetime.fromtimestamp(timestamp).replace(tzinfo=timezone.utc)
+        with mock.patch('sentry.tasks.check_alerts.timezone.now') as now:
+            now.return_value = when
+            check_alerts()
+            now.assert_called_once_with()
 
-        counter.extract_counts.return_value = {
-            'when': when,
-            'results': [
-                (str(self.project.id), 57.0),
-            ]
-        }
-        check_alerts()
-        time.assert_called_once_with()
-        counter.extract_counts.assert_called_once_with(
-            prefix='project',
-            when=timestamp,
-        )
         maybe_delay.assert_called_once_with(
             check_project_alerts,
             project_id=self.project.id,
             when=when,
-            count=57,
+            count=10,
             expires=120
         )
 
 
-class CheckProjectAlertsTest(TestCase):
-    def create_counts(self, when, amount, minute_offset=0):
-        ProjectCountByMinute.objects.create(
-            project=self.project,
-            date=normalize_datetime(when - timedelta(minutes=minute_offset)),
-            times_seen=amount,
-        )
-
+class CheckProjectAlertsTest(BaseTestCase):
     def test_it_works(self):
         now = timezone.now()
 
