commit 188c0e09f5b08f88d037386e54538738b0044e57
Author: ted kaemming <ted@kaemming.com>
Date:   Wed Nov 29 14:10:40 2017 -0800

    feat(tsdb): Add environments to relevant write path operations (#6496)

diff --git a/bin/load-mocks b/bin/load-mocks
index ddc8db53c4..77b095c76c 100755
--- a/bin/load-mocks
+++ b/bin/load-mocks
@@ -194,7 +194,7 @@ def create_sample_time_series(event, release=None):
         tsdb.incr_multi((
             (tsdb.models.project, project.id),
             (tsdb.models.group, group.id),
-        ), now, count)
+        ), now, count, environment_id=environment.id)
         tsdb.incr_multi((
             (tsdb.models.organization_total_received, project.organization_id),
             (tsdb.models.project_total_forwarded, project.id),
@@ -242,7 +242,7 @@ def create_sample_time_series(event, release=None):
         tsdb.incr_multi((
             (tsdb.models.project, group.project.id),
             (tsdb.models.group, group.id),
-        ), now, count)
+        ), now, count, environment_id=environment.id)
         tsdb.incr_multi((
             (tsdb.models.organization_total_received, project.organization_id),
             (tsdb.models.project_total_received, project.id),
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 156563f050..7a1dfd1d39 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -676,7 +676,7 @@ class EventManager(object):
         if release:
             counters.append((tsdb.models.release, release.id))
 
-        tsdb.incr_multi(counters, timestamp=event.datetime)
+        tsdb.incr_multi(counters, timestamp=event.datetime, environment_id=environment.id)
 
         frequencies = [
             # (tsdb.models.frequent_projects_by_organization, {
@@ -745,7 +745,8 @@ class EventManager(object):
                     (tsdb.models.users_affected_by_group, group.id, (event_user.tag_value, )),
                     (tsdb.models.users_affected_by_project, project.id, (event_user.tag_value, )),
                 ),
-                timestamp=event.datetime
+                timestamp=event.datetime,
+                environment_id=environment.id,
             )
 
         if is_new and release:
diff --git a/src/sentry/tasks/merge.py b/src/sentry/tasks/merge.py
index e62058b400..116bbcd361 100644
--- a/src/sentry/tasks/merge.py
+++ b/src/sentry/tasks/merge.py
@@ -42,6 +42,7 @@ def merge_group(
         GroupHash,
         GroupRuleStatus,
         GroupSubscription,
+        Environment,
         EventMapping,
         Event,
         UserReport,
@@ -120,16 +121,37 @@ def merge_group(
 
     features.merge(new_group, [group], allow_unsafe=True)
 
+    environment_ids = list(
+        Environment.objects.filter(
+            projects=group.project
+        ).values_list('id', flat=True)
+    )
+
     for model in [tsdb.models.group]:
-        tsdb.merge(model, new_group.id, [group.id])
+        tsdb.merge(
+            model,
+            new_group.id,
+            [group.id],
+            environment_ids=environment_ids if model in tsdb.models_with_environment_support else None
+        )
 
     for model in [tsdb.models.users_affected_by_group]:
-        tsdb.merge_distinct_counts(model, new_group.id, [group.id])
+        tsdb.merge_distinct_counts(
+            model,
+            new_group.id,
+            [group.id],
+            environment_ids=environment_ids if model in tsdb.models_with_environment_support else None,
+        )
 
     for model in [
         tsdb.models.frequent_releases_by_group, tsdb.models.frequent_environments_by_group
     ]:
-        tsdb.merge_frequencies(model, new_group.id, [group.id])
+        tsdb.merge_frequencies(
+            model,
+            new_group.id,
+            [group.id],
+            environment_ids=environment_ids if model in tsdb.models_with_environment_support else None,
+        )
 
     previous_group_id = group.id
 
diff --git a/src/sentry/tasks/unmerge.py b/src/sentry/tasks/unmerge.py
index 5c8807a8dd..cef3199600 100644
--- a/src/sentry/tasks/unmerge.py
+++ b/src/sentry/tasks/unmerge.py
@@ -249,13 +249,19 @@ def truncate_denormalizations(group):
         group_id=group.id,
     ).delete()
 
+    environment_ids = list(
+        Environment.objects.filter(
+            projects=group.project
+        ).values_list('id', flat=True)
+    )
+
     tsdb.delete([
         tsdb.models.group,
-    ], [group.id])
+    ], [group.id], environment_ids=environment_ids)
 
     tsdb.delete_distinct_counts([
         tsdb.models.users_affected_by_group,
-    ], [group.id])
+    ], [group.id], environment_ids=environment_ids)
 
     tsdb.delete_frequencies(
         [
@@ -402,19 +408,19 @@ def collect_tsdb_data(caches, project, events):
     )
 
     for event in events:
-        counters[event.datetime][tsdb.models.group][event.group_id] += 1
+        environment = caches['Environment'](
+            project.organization_id,
+            get_environment_name(event),
+        )
+
+        counters[event.datetime][tsdb.models.group][(event.group_id, environment.id)] += 1
 
         user = event.data.get('sentry.interfaces.User')
         if user:
-            sets[event.datetime][tsdb.models.users_affected_by_group][event.group_id].add(
+            sets[event.datetime][tsdb.models.users_affected_by_group][(event.group_id, environment.id)].add(
                 get_event_user_from_interface(user).tag_value,
             )
 
-        environment = caches['Environment'](
-            project.organization_id,
-            get_environment_name(event),
-        )
-
         frequencies[event.datetime][tsdb.models.frequent_environments_by_group
                                     ][event.group_id][environment.id] += 1
 
@@ -442,14 +448,14 @@ def repair_tsdb_data(caches, project, events):
 
     for timestamp, data in counters.items():
         for model, keys in data.items():
-            for key, value in keys.items():
-                tsdb.incr(model, key, timestamp, value)
+            for (key, environment_id), value in keys.items():
+                tsdb.incr(model, key, timestamp, value, environment_id=environment_id)
 
     for timestamp, data in sets.items():
         for model, keys in data.items():
-            for key, values in keys.items():
+            for (key, environment_id), values in keys.items():
                 # TODO: This should use `record_multi` rather than `record`.
-                tsdb.record(model, key, values, timestamp)
+                tsdb.record(model, key, values, timestamp, environment_id=environment_id)
 
     for timestamp, data in frequencies.items():
         tsdb.record_frequency_multi(data.items(), timestamp)
diff --git a/tests/sentry/tasks/test_unmerge.py b/tests/sentry/tasks/test_unmerge.py
index 365168ce33..bf433f9cc5 100644
--- a/tests/sentry/tasks/test_unmerge.py
+++ b/tests/sentry/tasks/test_unmerge.py
@@ -491,6 +491,15 @@ class UnmergeTestCase(TestCase):
             rollup_duration,
         )
 
+        environment_time_series = tsdb.get_range(
+            tsdb.models.group,
+            [source.id, destination.id],
+            now - timedelta(seconds=rollup_duration),
+            now + shift(16),
+            rollup_duration,
+            environment_id=environment.id,
+        )
+
         def get_expected_series_values(rollup, events, function=None):
             if function is None:
 
@@ -513,17 +522,18 @@ class UnmergeTestCase(TestCase):
             for key in set(actual.keys()) - set(expected.keys()):
                 assert actual.get(key, 0) == default
 
-        assert_series_contains(
-            get_expected_series_values(rollup_duration, events.values()[0]),
-            time_series[source.id],
-            0,
-        )
+        for series in [time_series, environment_time_series]:
+            assert_series_contains(
+                get_expected_series_values(rollup_duration, events.values()[0]),
+                series[source.id],
+                0,
+            )
 
-        assert_series_contains(
-            get_expected_series_values(rollup_duration, events.values()[1]),
-            time_series[destination.id],
-            0,
-        )
+            assert_series_contains(
+                get_expected_series_values(rollup_duration, events.values()[1]),
+                series[destination.id],
+                0,
+            )
 
         time_series = tsdb.get_distinct_counts_series(
             tsdb.models.users_affected_by_group,
@@ -533,6 +543,15 @@ class UnmergeTestCase(TestCase):
             rollup_duration,
         )
 
+        environment_time_series = tsdb.get_distinct_counts_series(
+            tsdb.models.users_affected_by_group,
+            [source.id, destination.id],
+            now - timedelta(seconds=rollup_duration),
+            now + shift(16),
+            rollup_duration,
+            environment_id=environment.id,
+        )
+
         def collect_by_user_tag(aggregate, event):
             aggregate = aggregate if aggregate is not None else set()
             aggregate.add(
@@ -542,29 +561,30 @@ class UnmergeTestCase(TestCase):
             )
             return aggregate
 
-        assert_series_contains(
-            {
-                timestamp: len(values)
-                for timestamp, values in get_expected_series_values(
-                    rollup_duration,
-                    events.values()[0],
-                    collect_by_user_tag,
-                ).items()
-            },
-            time_series[source.id],
-        )
+        for series in [time_series, environment_time_series]:
+            assert_series_contains(
+                {
+                    timestamp: len(values)
+                    for timestamp, values in get_expected_series_values(
+                        rollup_duration,
+                        events.values()[0],
+                        collect_by_user_tag,
+                    ).items()
+                },
+                series[source.id],
+            )
 
-        assert_series_contains(
-            {
-                timestamp: len(values)
-                for timestamp, values in get_expected_series_values(
-                    rollup_duration,
-                    events.values()[1],
-                    collect_by_user_tag,
-                ).items()
-            },
-            time_series[destination.id],
-        )
+            assert_series_contains(
+                {
+                    timestamp: len(values)
+                    for timestamp, values in get_expected_series_values(
+                        rollup_duration,
+                        events.values()[1],
+                        collect_by_user_tag,
+                    ).items()
+                },
+                time_series[destination.id],
+            )
 
         time_series = tsdb.get_most_frequent_series(
             tsdb.models.frequent_releases_by_group,
diff --git a/tests/sentry/test_event_manager.py b/tests/sentry/test_event_manager.py
index 902855d69c..a14a97b46f 100644
--- a/tests/sentry/test_event_manager.py
+++ b/tests/sentry/test_event_manager.py
@@ -18,7 +18,7 @@ from sentry.event_manager import (
     generate_culprit, md5_from_hash
 )
 from sentry.models import (
-    Activity, Event, Group, GroupHash, GroupRelease, GroupResolution, GroupStatus, GroupTombstone,
+    Activity, Environment, Event, Group, GroupHash, GroupRelease, GroupResolution, GroupStatus, GroupTombstone,
     EventMapping, Release
 )
 from sentry.testutils import TestCase, TransactionTestCase
@@ -625,6 +625,27 @@ class EventManagerTest(TransactionTestCase):
         data = manager.normalize()
         assert data['logger'] == DEFAULT_LOGGER_NAME
 
+    def test_tsdb(self):
+        project = self.project
+        manager = EventManager(self.make_event(
+            fingerprint=['totally unique super duper fingerprint'],
+            environment='totally unique super duper environment',
+        ))
+        event = manager.save(project)
+
+        def query(model, key, **kwargs):
+            return tsdb.get_sums(model, [key], event.datetime, event.datetime, **kwargs)[key]
+
+        assert query(tsdb.models.project, project.id) == 1
+        assert query(tsdb.models.group, event.group.id) == 1
+
+        environment_id = Environment.get_for_organization_id(
+            event.project.organization_id,
+            'totally unique super duper environment',
+        ).id
+        assert query(tsdb.models.project, project.id, environment_id=environment_id) == 1
+        assert query(tsdb.models.group, event.group.id, environment_id=environment_id) == 1
+
     @pytest.mark.xfail
     def test_record_frequencies(self):
         project = self.project
@@ -652,18 +673,45 @@ class EventManagerTest(TransactionTestCase):
         }
 
     def test_event_user(self):
-        manager = EventManager(self.make_event(**{'sentry.interfaces.User': {
-            'id': '1',
-        }}))
+        manager = EventManager(self.make_event(
+            environment='totally unique environment',
+            **{'sentry.interfaces.User': {
+                'id': '1',
+            }}
+        ))
         manager.normalize()
         with self.tasks():
             event = manager.save(self.project.id)
 
+        environment_id = Environment.get_for_organization_id(
+            event.project.organization_id,
+            'totally unique environment',
+        ).id
+
+        assert tsdb.get_distinct_counts_totals(
+            tsdb.models.users_affected_by_group,
+            (event.group.id, ),
+            event.datetime,
+            event.datetime,
+        ) == {
+            event.group.id: 1,
+        }
+
+        assert tsdb.get_distinct_counts_totals(
+            tsdb.models.users_affected_by_project,
+            (event.project.id, ),
+            event.datetime,
+            event.datetime,
+        ) == {
+            event.project.id: 1,
+        }
+
         assert tsdb.get_distinct_counts_totals(
             tsdb.models.users_affected_by_group,
             (event.group.id, ),
             event.datetime,
             event.datetime,
+            environment_id=environment_id,
         ) == {
             event.group.id: 1,
         }
@@ -673,6 +721,7 @@ class EventManagerTest(TransactionTestCase):
             (event.project.id, ),
             event.datetime,
             event.datetime,
+            environment_id=environment_id,
         ) == {
             event.project.id: 1,
         }
