commit 054b3dea84080d4cd5fae0b5bd97649c0d646971
Author: Lyn Nagara <lyn.nagara@gmail.com>
Date:   Fri Oct 11 10:38:13 2019 -0700

    chore(tagstore): Remove SnubaCompatibilityTagStorage (#15033)
    
    Since SnubaTagStorage is now the only supported tagstore we do not need
    to maintain compatibility with the legacy tagstores.

diff --git a/src/sentry/api/endpoints/project_tagkey_details.py b/src/sentry/api/endpoints/project_tagkey_details.py
index 77617e2bec..211342b586 100644
--- a/src/sentry/api/endpoints/project_tagkey_details.py
+++ b/src/sentry/api/endpoints/project_tagkey_details.py
@@ -45,10 +45,10 @@ class ProjectTagKeyDetailsEndpoint(ProjectEndpoint, EnvironmentMixin):
 
             eventstream_state = eventstream.start_delete_tag(project.id, key)
 
-            deleted = tagstore.delete_tag_key(project.id, lookup_key)
+            deleted = self.get_tag_keys_for_deletion(project.id, lookup_key)
 
             # NOTE: By sending the `end_delete_tag` message here we are making
-            # the assumption that the `tagstore.delete_tag_key` does its work
+            # the assumption that the `delete_tag_key` does its work
             # synchronously. As of this writing the Snuba `delete_tag_key` method
             # is a no-op and this message itself is what causes the deletion to
             # be done downstream.
@@ -66,3 +66,9 @@ class ProjectTagKeyDetailsEndpoint(ProjectEndpoint, EnvironmentMixin):
             )
 
         return Response(status=204)
+
+    def get_tag_keys_for_deletion(self, project_id, key):
+        try:
+            return [tagstore.get_tag_key(project_id=project_id, key=key, environment_id=None)]
+        except tagstore.TagKeyNotFound:
+            return []
diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index f9b2cd1dbe..9512ccdd45 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -549,7 +549,6 @@ CELERY_IMPORTS = (
     "sentry.tasks.store",
     "sentry.tasks.unmerge",
     "sentry.tasks.servicehooks",
-    "sentry.tagstore.tasks",
     "sentry.tasks.assemble",
     "sentry.tasks.integrations",
     "sentry.tasks.files",
@@ -568,7 +567,6 @@ CELERY_QUEUES = [
     Queue("digests.delivery", routing_key="digests.delivery"),
     Queue("digests.scheduling", routing_key="digests.scheduling"),
     Queue("email", routing_key="email"),
-    Queue("events.index_event_tags", routing_key="events.index_event_tags"),
     Queue("events.preprocess_event", routing_key="events.preprocess_event"),
     Queue(
         "events.reprocessing.preprocess_event", routing_key="events.reprocessing.preprocess_event"
@@ -1054,9 +1052,7 @@ SENTRY_NODESTORE = "sentry.nodestore.django.DjangoNodeStorage"
 SENTRY_NODESTORE_OPTIONS = {}
 
 # Tag storage backend
-SENTRY_TAGSTORE = os.environ.get(
-    "SENTRY_TAGSTORE", "sentry.tagstore.snuba.SnubaCompatibilityTagStorage"
-)
+SENTRY_TAGSTORE = os.environ.get("SENTRY_TAGSTORE", "sentry.tagstore.snuba.SnubaTagStorage")
 SENTRY_TAGSTORE_OPTIONS = {}
 
 # Search backend
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 044f136a2f..a079fdc84d 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -15,7 +15,7 @@ from django.db.models import Func
 from django.utils import timezone
 from django.utils.encoding import force_text
 
-from sentry import buffer, eventtypes, eventstream, tagstore, tsdb
+from sentry import buffer, eventtypes, eventstream, tsdb
 from sentry.constants import (
     DEFAULT_STORE_NORMALIZER_ARGS,
     LOG_LEVELS,
@@ -759,16 +759,6 @@ class EventManager(object):
             )
             return event
 
-        tagstore.delay_index_event_tags(
-            organization_id=project.organization_id,
-            project_id=project.id,
-            group_id=group.id if group else None,
-            environment_id=environment.id,
-            event_id=event.id,
-            tags=event.tags,
-            date_added=event.datetime,
-        )
-
         if event_user:
             counters = [
                 (tsdb.models.users_affected_by_project, project.id, (event_user.tag_value,))
@@ -799,15 +789,6 @@ class EventManager(object):
                     },
                 )
 
-        if group:
-            safe_execute(
-                Group.objects.add_tags,
-                group,
-                environment,
-                event.get_tags(),
-                _with_transaction=False,
-            )
-
         if not raw:
             if not project.first_event:
                 project.update(first_event=date)
diff --git a/src/sentry/models/group.py b/src/sentry/models/group.py
index 96c14f25cc..a275e5961e 100644
--- a/src/sentry/models/group.py
+++ b/src/sentry/models/group.py
@@ -223,29 +223,6 @@ class GroupManager(BaseManager):
 
         return Group.objects.filter(id__in=group_ids)
 
-    def add_tags(self, group, environment, tags):
-        project_id = group.project_id
-        date = group.last_seen
-
-        for tag_item in tags:
-            if len(tag_item) == 2:
-                (key, value), data = tag_item, None
-            else:
-                key, value, data = tag_item
-
-            tagstore.incr_tag_value_times_seen(
-                project_id, environment.id, key, value, extra={"last_seen": date, "data": data}
-            )
-
-            tagstore.incr_group_tag_value_times_seen(
-                project_id,
-                group.id,
-                environment.id,
-                key,
-                value,
-                extra={"project_id": project_id, "last_seen": date},
-            )
-
     def get_groups_by_external_issue(self, integration, external_issue_key):
         from sentry.models import ExternalIssue, GroupLink
 
diff --git a/src/sentry/runner/initializer.py b/src/sentry/runner/initializer.py
index 97e5e67cc1..586a0efdd5 100644
--- a/src/sentry/runner/initializer.py
+++ b/src/sentry/runner/initializer.py
@@ -584,18 +584,9 @@ def validate_snuba():
     if not settings.DEBUG:
         return
 
-    has_any_snuba_required_backends = (
-        settings.SENTRY_SEARCH == "sentry.search.snuba.SnubaSearchBackend"
-        or settings.SENTRY_TAGSTORE == "sentry.tagstore.snuba.SnubaCompatibilityTagStorage"
-        or
-        # TODO(mattrobenolt): Remove ServiceDelegator check
-        settings.SENTRY_TSDB
-        in ("sentry.tsdb.redissnuba.RedisSnubaTSDB", "sentry.utils.services.ServiceDelegator")
-    )
-
     has_all_snuba_required_backends = (
         settings.SENTRY_SEARCH == "sentry.search.snuba.SnubaSearchBackend"
-        and settings.SENTRY_TAGSTORE == "sentry.tagstore.snuba.SnubaCompatibilityTagStorage"
+        and settings.SENTRY_TAGSTORE == "sentry.tagstore.snuba.SnubaTagStorage"
         and
         # TODO(mattrobenolt): Remove ServiceDelegator check
         settings.SENTRY_TSDB
@@ -636,7 +627,7 @@ See: https://github.com/getsentry/snuba#sentry--snuba
         )
         raise ConfigurationError("Cannot continue without Snuba configured.")
 
-    if has_any_snuba_required_backends and not eventstream_is_snuba:
+    if not eventstream_is_snuba:
         from .importer import ConfigurationError
 
         show_big_error(
diff --git a/src/sentry/tagstore/base.py b/src/sentry/tagstore/base.py
index fcc5e955ea..a21a257c38 100644
--- a/src/sentry/tagstore/base.py
+++ b/src/sentry/tagstore/base.py
@@ -62,28 +62,6 @@ class TagStorage(Service):
         ]
     )
 
-    __write_methods__ = frozenset(
-        [
-            "create_tag_key",
-            "get_or_create_tag_key",
-            "create_tag_value",
-            "get_or_create_tag_value",
-            "create_group_tag_key",
-            "get_or_create_group_tag_key",
-            "create_group_tag_value",
-            "get_or_create_group_tag_value",
-            "create_event_tags",
-            "delete_tag_key",
-            "delete_all_group_tag_keys",
-            "delete_all_group_tag_values",
-            "incr_tag_value_times_seen",
-            "incr_group_tag_value_times_seen",
-            "update_group_tag_key_values_seen",
-            "update_group_for_events",
-            "delay_index_event_tags",
-        ]
-    )
-
     __all__ = (
         frozenset(
             [
@@ -97,7 +75,6 @@ class TagStorage(Service):
             ]
         )
         | __read_methods__
-        | __write_methods__
     )
 
     def setup_merge(self, grouptagkey_model, grouptagvalue_model):
@@ -142,64 +119,6 @@ class TagStorage(Service):
 
         return label
 
-    def create_tag_key(self, project_id, environment_id, key, **kwargs):
-        """
-        >>> create_tag_key(1, 2, "key1")
-        """
-        raise NotImplementedError
-
-    def get_or_create_tag_key(self, project_id, environment_id, key, **kwargs):
-        """
-        >>> get_or_create_tag_key(1, 2, "key1")
-        """
-        raise NotImplementedError
-
-    def create_tag_value(self, project_id, environment_id, key, value, **kwargs):
-        """
-        >>> create_tag_key(1, 2, "key1", "value1")
-        """
-        raise NotImplementedError
-
-    def get_or_create_tag_value(self, project_id, environment_id, key, value, **kwargs):
-        """
-        >>> get_or_create_tag_key(1, 2, "key1", "value1")
-        """
-        raise NotImplementedError
-
-    def create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
-        """
-        >>> create_group_tag_key(1, 2, 3, "key1")
-        """
-        raise NotImplementedError
-
-    def get_or_create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
-        """
-        >>> get_or_create_group_tag_key(1, 2, 3, "key1")
-        """
-        raise NotImplementedError
-
-    def create_group_tag_value(self, project_id, group_id, environment_id, key, value, **kwargs):
-        """
-        >>> create_group_tag_value(1, 2, 3, "key1", "value1")
-        """
-        raise NotImplementedError
-
-    def get_or_create_group_tag_value(
-        self, project_id, group_id, environment_id, key, value, **kwargs
-    ):
-        """
-        >>> get_or_create_group_tag_value(1, 2, 3, "key1", "value1")
-        """
-        raise NotImplementedError
-
-    def create_event_tags(
-        self, project_id, group_id, environment_id, event_id, tags, date_added=None
-    ):
-        """
-        >>> create_event_tags(1, 2, 3, 4, [('foo', 'bar'), ('baz', 'qux')])
-        """
-        raise NotImplementedError
-
     @raises([TagKeyNotFound])
     def get_tag_key(self, project_id, environment_id, key, status=TagKeyStatus.VISIBLE):
         """
@@ -268,40 +187,6 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def delete_tag_key(self, project_id, key):
-        """
-        >>> delete_tag_key(1, "key1")
-        """
-        raise NotImplementedError
-
-    def delete_all_group_tag_keys(self, project_id, group_id):
-        """
-        >>> delete_all_group_tag_keys(1, 2)
-        """
-        raise NotImplementedError
-
-    def delete_all_group_tag_values(self, project_id, group_id):
-        """
-        >>> delete_all_group_tag_values(1, 2)
-        """
-        raise NotImplementedError
-
-    def incr_tag_value_times_seen(
-        self, project_id, environment_id, key, value, extra=None, count=1
-    ):
-        """
-        >>> incr_tag_value_times_seen(1, 2, "key1", "value1")
-        """
-        raise NotImplementedError
-
-    def incr_group_tag_value_times_seen(
-        self, project_id, group_id, environment_id, key, value, extra=None, count=1
-    ):
-        """
-        >>> incr_group_tag_value_times_seen(1, 2, 3, "key1", "value1")
-        """
-        raise NotImplementedError
-
     def get_group_event_filter(self, project_id, group_id, environment_ids, tags, start, end):
         """
         >>> get_group_event_filter(1, 2, 3, {'key1': 'value1', 'key2': 'value2'})
@@ -397,18 +282,6 @@ class TagStorage(Service):
         """
         raise NotImplementedError
 
-    def update_group_for_events(self, project_id, event_ids, destination_id):
-        """
-        >>> update_group_for_events(1, [2, 3], 4)
-        """
-        raise NotImplementedError
-
-    def update_group_tag_key_values_seen(self, project_id, group_ids):
-        """
-        >>> update_group_tag_key_values_seen(1, [2, 3])
-        """
-        raise NotImplementedError
-
     def get_group_tag_keys_and_top_values(
         self,
         project_id,
@@ -438,11 +311,6 @@ class TagStorage(Service):
 
         return tag_keys
 
-    def delay_index_event_tags(
-        self, organization_id, project_id, group_id, environment_id, event_id, tags, date_added
-    ):
-        raise NotImplementedError
-
     def get_group_seen_values_for_environments(
         self, project_ids, group_id_list, environment_ids, start=None, end=None
     ):
diff --git a/src/sentry/tagstore/snuba/__init__.py b/src/sentry/tagstore/snuba/__init__.py
index 06f00aed44..7279106651 100644
--- a/src/sentry/tagstore/snuba/__init__.py
+++ b/src/sentry/tagstore/snuba/__init__.py
@@ -1,3 +1,3 @@
 from __future__ import absolute_import
 
-from .backend import SnubaTagStorage, SnubaCompatibilityTagStorage  # NOQA
+from .backend import SnubaTagStorage  # NOQA
diff --git a/src/sentry/tagstore/snuba/backend.py b/src/sentry/tagstore/snuba/backend.py
index 05d03d1cfb..6dfb8cf90e 100644
--- a/src/sentry/tagstore/snuba/backend.py
+++ b/src/sentry/tagstore/snuba/backend.py
@@ -726,88 +726,3 @@ class SnubaTagStorage(TagStorage):
             return None
 
         return {"event_id__in": event_id_set}
-
-
-class SnubaCompatibilityTagStorage(SnubaTagStorage):
-    """
-    This class extends the read-only SnubaTagStorage backend, implementing the
-    subset of the ``TagStorage`` write interface that is actually used by
-    callers external to the ``tagstore`` module.
-
-    This is necessary since writes to Snuba occur via the event stream and an
-    external writer process, instead of through this service backend. However,
-    we need still to "implement" these methods (so that at least they do not
-    raise a ``NotImplementedError``, as well as providing compatible return
-    types when required by the call site) so that other backends that *do*
-    require these methods in the application to be available can still be used.
-
-    If Snuba becomes the exclusive implementer of the ``TagStorage`` interface
-    in the future, this subclass can be removed (along with the entire
-    ``TagStorage`` write interface from the base implementation.)
-    """
-
-    def get_or_create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
-        # Called by ``unmerge.repair_tag_data``. The return value is not used.
-        pass
-
-    def get_or_create_group_tag_value(
-        self, project_id, group_id, environment_id, key, value, **kwargs
-    ):
-        # Called by ``unmerge.repair_tag_data``. The first member of the return
-        # value is not used, the second indicates whether or not an object was
-        # created (always False in our case.)
-        return None, False
-
-    def create_event_tags(
-        self, project_id, group_id, environment_id, event_id, tags, date_added=None
-    ):
-        # Called by ``post_process.index_event_tags``. The return value is not
-        # used.
-        pass
-
-    def delete_all_group_tag_keys(self, project_id, group_id):
-        # Called by ``unmerge.truncate_denormalizations``. The return value is
-        # not used.
-        pass
-
-    def delete_all_group_tag_values(self, project_id, group_id):
-        # Called by ``unmerge.truncate_denormalizations``. The return value is
-        # not used.
-        pass
-
-    def delete_tag_key(self, project_id, key):
-        # Called by ``ProjectTagKeyDetailsEndpoint.delete``. The return value
-        # is used for audit logging.
-        try:
-            return [self.get_tag_key(project_id=project_id, key=key, environment_id=None)]
-        except TagKeyNotFound:
-            return []
-
-    def incr_tag_value_times_seen(
-        self, project_id, environment_id, key, value, extra=None, count=1
-    ):
-        # Called by ``Group.add_tags``. The return value is not used.
-        pass
-
-    def incr_group_tag_value_times_seen(
-        self, project_id, group_id, environment_id, key, value, extra=None, count=1
-    ):
-        # Called by ``Group.add_tags`` (and ``unmerge.repair_tag_data`` if
-        # ``get_or_create_group_tag_value`` indicates an object is created --
-        # in our case this will never happen.) The return value is not used.
-        pass
-
-    def update_group_for_events(self, project_id, event_ids, destination_id):
-        # Called by ``unmerge.migrate_events``. The return value is not used.
-        pass
-
-    def update_group_tag_key_values_seen(self, project_id, group_ids):
-        # Called by ``unmerge``. The return value is not used.
-        pass
-
-    def delay_index_event_tags(
-        self, organization_id, project_id, group_id, environment_id, event_id, tags, date_added
-    ):
-        # Called by ``EventManager.save``. The return value is not
-        # used.
-        pass
diff --git a/src/sentry/tagstore/tasks.py b/src/sentry/tagstore/tasks.py
deleted file mode 100644
index e29e9f3502..0000000000
--- a/src/sentry/tagstore/tasks.py
+++ /dev/null
@@ -1,28 +0,0 @@
-from __future__ import absolute_import
-
-from uuid import uuid4
-
-from sentry.exceptions import DeleteAborted
-from sentry.tasks.base import instrumented_task, retry
-from sentry.tasks.deletion import MAX_RETRIES
-
-
-@instrumented_task(
-    name="sentry.tagstore.tasks.delete_tag_key",
-    queue="cleanup",
-    default_retry_delay=60 * 5,
-    max_retries=MAX_RETRIES,
-)
-@retry(exclude=(DeleteAborted,))
-def delete_tag_key(object_id, model, transaction_id=None, **kwargs):
-    from sentry import deletions
-
-    task = deletions.get(
-        model=model, query={"id": object_id}, transaction_id=transaction_id or uuid4().hex
-    )
-    has_more = task.chunk()
-    if has_more:
-        delete_tag_key.apply_async(
-            kwargs={"object_id": object_id, "model": model, "transaction_id": transaction_id},
-            countdown=15,
-        )
diff --git a/src/sentry/tasks/post_process.py b/src/sentry/tasks/post_process.py
index 360bcdada2..1accd7480a 100644
--- a/src/sentry/tasks/post_process.py
+++ b/src/sentry/tasks/post_process.py
@@ -248,33 +248,3 @@ def plugin_post_process_group(plugin_slug, event, **kwargs):
         expected_errors=(PluginError,),
         **kwargs
     )
-
-
-@instrumented_task(
-    name="sentry.tasks.index_event_tags",
-    queue="events.index_event_tags",
-    default_retry_delay=60 * 5,
-    max_retries=None,
-)
-def index_event_tags(
-    organization_id, project_id, event_id, tags, group_id, environment_id, date_added=None, **kwargs
-):
-    from sentry import tagstore
-
-    with configure_scope() as scope:
-        scope.set_tag("project", project_id)
-
-    create_event_tags_kwargs = {}
-    if date_added is not None:
-        create_event_tags_kwargs["date_added"] = date_added
-
-    metrics.timing("tagstore.tags_per_event", len(tags), tags={"organization_id": organization_id})
-
-    tagstore.create_event_tags(
-        project_id=project_id,
-        group_id=group_id,
-        environment_id=environment_id,
-        event_id=event_id,
-        tags=tags,
-        **create_event_tags_kwargs
-    )
diff --git a/src/sentry/tasks/unmerge.py b/src/sentry/tasks/unmerge.py
index 73370e82c2..3de2388182 100644
--- a/src/sentry/tasks/unmerge.py
+++ b/src/sentry/tasks/unmerge.py
@@ -5,7 +5,7 @@ from collections import defaultdict, OrderedDict
 
 from django.db import transaction
 
-from sentry import eventstore, eventstream, tagstore
+from sentry import eventstore, eventstream
 from sentry.app import tsdb
 from sentry.constants import DEFAULT_LOGGER_NAME, LOG_LEVELS_MAP
 from sentry.event_manager import generate_culprit
@@ -229,9 +229,6 @@ def migrate_events(
 
 
 def truncate_denormalizations(group):
-    tagstore.delete_all_group_tag_keys(group.project_id, group.id)
-    tagstore.delete_all_group_tag_values(group.project_id, group.id)
-
     GroupRelease.objects.filter(group_id=group.id).delete()
 
     # XXX: This can cause a race condition with the ``FirstSeenEventCondition``
@@ -303,43 +300,6 @@ def collect_tag_data(events):
     return results
 
 
-def repair_tag_data(caches, project, events):
-    for (group_id, env_name), keys in collect_tag_data(events).items():
-        environment = caches["Environment"](project.organization_id, env_name)
-        for key, values in keys.items():
-            tagstore.get_or_create_group_tag_key(
-                project_id=project.id, group_id=group_id, environment_id=environment.id, key=key
-            )
-
-            # XXX: `{first,last}_seen` columns don't totally replicate the
-            # ingestion logic (but actually represent a more accurate value.)
-            # See GH-5289 for more details.
-            for value, (times_seen, first_seen, last_seen) in values.items():
-                _, created = tagstore.get_or_create_group_tag_value(
-                    project_id=project.id,
-                    group_id=group_id,
-                    environment_id=environment.id,
-                    key=key,
-                    value=value,
-                    defaults={
-                        "first_seen": first_seen,
-                        "last_seen": last_seen,
-                        "times_seen": times_seen,
-                    },
-                )
-
-                if not created:
-                    tagstore.incr_group_tag_value_times_seen(
-                        project_id=project.id,
-                        group_id=group_id,
-                        environment_id=environment.id,
-                        key=key,
-                        value=value,
-                        count=times_seen,
-                        extra={"first_seen": first_seen},
-                    )
-
-
 def get_environment_name(event):
     return Environment.get_name_or_default(event.get_tag("environment"))
 
@@ -451,7 +411,6 @@ def repair_tsdb_data(caches, project, events):
 
 def repair_denormalizations(caches, project, events):
     repair_group_environment_data(caches, project, events)
-    repair_tag_data(caches, project, events)
     repair_group_release_data(caches, project, events)
     repair_tsdb_data(caches, project, events)
 
@@ -552,7 +511,6 @@ def unmerge(
 
     # If there are no more events to process, we're done with the migration.
     if not events:
-        tagstore.update_group_tag_key_values_seen(project_id, [source_id, destination_id])
         unlock_hashes(project_id, fingerprints)
         logger.warning("Unmerge complete (eventstream state: %s)", eventstream_state)
         if eventstream_state:
diff --git a/src/sentry/testutils/cases.py b/src/sentry/testutils/cases.py
index 4b1fd7d574..fc49451011 100644
--- a/src/sentry/testutils/cases.py
+++ b/src/sentry/testutils/cases.py
@@ -79,7 +79,7 @@ from sentry.models import (
 )
 from sentry.plugins import plugins
 from sentry.rules import EventState
-from sentry.tagstore.snuba import SnubaCompatibilityTagStorage
+from sentry.tagstore.snuba import SnubaTagStorage
 from sentry.utils import json
 from sentry.utils.auth import SSO_SESSION_KEY
 
@@ -767,24 +767,13 @@ class SnubaTestCase(BaseTestCase):
 
     def init_snuba(self):
         self.snuba_eventstream = SnubaEventStream()
-        self.snuba_tagstore = SnubaCompatibilityTagStorage()
+        self.snuba_tagstore = SnubaTagStorage()
         assert requests.post(settings.SENTRY_SNUBA + "/tests/events/drop").status_code == 200
         assert requests.post(settings.SENTRY_SNUBA + "/tests/transactions/drop").status_code == 200
 
     def store_event(self, *args, **kwargs):
         with contextlib.nested(
-            mock.patch("sentry.eventstream.insert", self.snuba_eventstream.insert),
-            mock.patch(
-                "sentry.tagstore.delay_index_event_tags", self.snuba_tagstore.delay_index_event_tags
-            ),
-            mock.patch(
-                "sentry.tagstore.incr_tag_value_times_seen",
-                self.snuba_tagstore.incr_tag_value_times_seen,
-            ),
-            mock.patch(
-                "sentry.tagstore.incr_group_tag_value_times_seen",
-                self.snuba_tagstore.incr_group_tag_value_times_seen,
-            ),
+            mock.patch("sentry.eventstream.insert", self.snuba_eventstream.insert)
         ):
             return Factories.store_event(*args, **kwargs)
 
diff --git a/tests/js/spec/views/admin/__snapshots__/adminQueue.spec.jsx.snap b/tests/js/spec/views/admin/__snapshots__/adminQueue.spec.jsx.snap
index 191145803f..18b6ec6dac 100644
--- a/tests/js/spec/views/admin/__snapshots__/adminQueue.spec.jsx.snap
+++ b/tests/js/spec/views/admin/__snapshots__/adminQueue.spec.jsx.snap
@@ -178,10 +178,6 @@ exports[`AdminQueue render() renders 1`] = `
                 "sentry.tasks.email_unlink_notifications",
                 "sentry.tasks.email_unlink_notifications",
               ],
-              Array [
-                "sentry.tasks.index_event_tags",
-                "sentry.tasks.index_event_tags",
-              ],
               Array [
                 "sentry.tasks.merge.merge_group",
                 "sentry.tasks.merge.merge_group",
diff --git a/tests/js/spec/views/admin/adminQueue.spec.jsx b/tests/js/spec/views/admin/adminQueue.spec.jsx
index aeaf3c471d..2d283ba41b 100644
--- a/tests/js/spec/views/admin/adminQueue.spec.jsx
+++ b/tests/js/spec/views/admin/adminQueue.spec.jsx
@@ -39,7 +39,6 @@ describe('AdminQueue', function() {
           'sentry.tasks.email.process_inbound_email',
           'sentry.tasks.email.send_email',
           'sentry.tasks.email_unlink_notifications',
-          'sentry.tasks.index_event_tags',
           'sentry.tasks.merge.merge_group',
           'sentry.tasks.merge.rehash_group_events',
           'sentry.tasks.post_process.plugin_post_process_group',
diff --git a/tests/sentry/api/endpoints/test_project_tagkey_details.py b/tests/sentry/api/endpoints/test_project_tagkey_details.py
index 51851691fd..ddaef735f7 100644
--- a/tests/sentry/api/endpoints/test_project_tagkey_details.py
+++ b/tests/sentry/api/endpoints/test_project_tagkey_details.py
@@ -76,8 +76,7 @@ class ProjectTagKeyDeleteTest(APITestCase):
         mock_eventstream.start_delete_tag.assert_called_once_with(project.id, "foo")
         mock_eventstream.end_delete_tag.assert_called_once_with(eventstream_state)
 
-    @mock.patch("sentry.tagstore.tasks.delete_tag_key")
-    def test_protected(self, mock_delete_tag_key):
+    def test_protected(self):
         project = self.create_project()
         self.store_event(
             data={"environment": "prod", "timestamp": iso_format(before_now(seconds=1))},
@@ -98,7 +97,6 @@ class ProjectTagKeyDeleteTest(APITestCase):
         response = self.client.delete(url)
 
         assert response.status_code == 403
-        assert mock_delete_tag_key.delay.call_count == 0
 
         assert (
             tagstore.get_tag_key(
diff --git a/tests/sentry/tasks/post_process/tests.py b/tests/sentry/tasks/post_process/tests.py
index ca79055455..9c33276021 100644
--- a/tests/sentry/tasks/post_process/tests.py
+++ b/tests/sentry/tasks/post_process/tests.py
@@ -3,18 +3,16 @@
 from __future__ import absolute_import
 
 from datetime import timedelta
-import pytest
 from django.utils import timezone
 from mock import Mock, patch, ANY
 
-from sentry import tagstore
 from sentry.models import Group, GroupSnooze, GroupStatus, ProjectOwnership
 from sentry.ownership.grammar import Rule, Matcher, Owner, dump_schema
 from sentry.testutils import TestCase
 from sentry.testutils.helpers import with_feature
 from sentry.testutils.helpers.datetime import iso_format
 from sentry.tasks.merge import merge_groups
-from sentry.tasks.post_process import index_event_tags, post_process_group
+from sentry.tasks.post_process import post_process_group
 
 
 class PostProcessGroupTest(TestCase):
@@ -390,49 +388,3 @@ class PostProcessGroupTest(TestCase):
         )
 
         assert not delay.called
-
-
-@pytest.mark.skip(reason="Legacy")
-class IndexEventTagsTest(TestCase):
-    def test_simple(self):
-        group = self.create_group(project=self.project)
-        event = self.create_event(group=group)
-
-        with self.tasks():
-            index_event_tags.delay(
-                event_id=event.id,
-                group_id=group.id,
-                project_id=self.project.id,
-                environment_id=self.environment.id,
-                organization_id=self.project.organization_id,
-                tags=[("foo", "bar"), ("biz", "baz")],
-            )
-
-        assert tagstore.get_group_event_filter(
-            self.project.id,
-            group.id,
-            [self.environment.id],
-            {"foo": "bar", "biz": "baz"},
-            None,
-            None,
-        ) == {"id__in": set([event.id])}
-
-        # ensure it safely handles repeat runs
-        with self.tasks():
-            index_event_tags.delay(
-                event_id=event.id,
-                group_id=group.id,
-                project_id=self.project.id,
-                environment_id=self.environment.id,
-                organization_id=self.project.organization_id,
-                tags=[("foo", "bar"), ("biz", "baz")],
-            )
-
-        assert tagstore.get_group_event_filter(
-            self.project.id,
-            group.id,
-            [self.environment.id],
-            {"foo": "bar", "biz": "baz"},
-            None,
-            None,
-        ) == {"id__in": set([event.id])}
diff --git a/tests/snuba/eventstream/test_eventstream.py b/tests/snuba/eventstream/test_eventstream.py
index 77c26608a4..267f7ab984 100644
--- a/tests/snuba/eventstream/test_eventstream.py
+++ b/tests/snuba/eventstream/test_eventstream.py
@@ -52,8 +52,7 @@ class SnubaEventStreamTest(TestCase, SnubaTestCase):
         snuba_eventstream._send(self.project.id, "insert", (payload1, payload2))
 
     @patch("sentry.eventstream.insert")
-    @patch("sentry.tagstore.delay_index_event_tags")
-    def test(self, mock_delay_index_event_tags, mock_eventstream_insert):
+    def test(self, mock_eventstream_insert):
         now = datetime.utcnow()
 
         def _get_event_count():
@@ -81,14 +80,11 @@ class SnubaEventStreamTest(TestCase, SnubaTestCase):
             "skip_consume": False,
         }
 
-        assert mock_delay_index_event_tags.call_count == 1
-
         self.__produce_event(*insert_args, **insert_kwargs)
         assert _get_event_count() == 1
 
     @patch("sentry.eventstream.insert")
-    @patch("sentry.tagstore.delay_index_event_tags")
-    def test_issueless(self, mock_delay_index_event_tags, mock_eventstream_insert):
+    def test_issueless(self, mock_eventstream_insert):
         now = datetime.utcnow()
         event = self.__build_event(now)
 
