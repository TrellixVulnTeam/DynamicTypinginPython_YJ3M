commit 150a892e556e034878330ac3c7be04495902b0d1
Author: David Cramer <dcramer@gmail.com>
Date:   Wed Feb 18 12:14:30 2015 -0800

    Abstract sourcemap processing into JavaScript plugin

diff --git a/src/sentry/conf/server.py b/src/sentry/conf/server.py
index aa6e136df4..4d0831aaf3 100644
--- a/src/sentry/conf/server.py
+++ b/src/sentry/conf/server.py
@@ -245,6 +245,7 @@ INSTALLED_APPS = (
     'sentry',
     'sentry.nodestore',
     'sentry.search',
+    'sentry.lang.javascript',
     'sentry.plugins.sentry_interface_types',
     'sentry.plugins.sentry_mail',
     'sentry.plugins.sentry_urls',
@@ -373,7 +374,6 @@ CELERY_IMPORTS = (
     'sentry.tasks.cleanup',
     'sentry.tasks.deletion',
     'sentry.tasks.email',
-    'sentry.tasks.fetch_source',
     'sentry.tasks.index',
     'sentry.tasks.merge',
     'sentry.tasks.store',
diff --git a/src/sentry/lang/__init__.py b/src/sentry/lang/__init__.py
new file mode 100644
index 0000000000..c3961685ab
--- /dev/null
+++ b/src/sentry/lang/__init__.py
@@ -0,0 +1 @@
+from __future__ import absolute_import
diff --git a/src/sentry/lang/javascript/__init__.py b/src/sentry/lang/javascript/__init__.py
new file mode 100644
index 0000000000..e1b7abb6c8
--- /dev/null
+++ b/src/sentry/lang/javascript/__init__.py
@@ -0,0 +1,7 @@
+from __future__ import absolute_import, print_function
+
+from sentry.plugins import register
+
+from .plugin import JavascriptPlugin
+
+register(JavascriptPlugin)
diff --git a/src/sentry/lang/javascript/cache.py b/src/sentry/lang/javascript/cache.py
new file mode 100644
index 0000000000..d30f5ec115
--- /dev/null
+++ b/src/sentry/lang/javascript/cache.py
@@ -0,0 +1,70 @@
+from __future__ import absolute_import, print_function
+
+__all__ = ['SourceCache', 'SourceMapCache']
+
+
+class SourceCache(object):
+    def __init__(self):
+        self._cache = {}
+        self._errors = {}
+        self._aliases = {}
+
+    def __contains__(self, url):
+        url = self._get_canonical_url(url)
+        return url in self._cache
+
+    def _get_canonical_url(self, url):
+        if url in self._aliases:
+            url = self._aliases[url]
+        return url
+
+    def get(self, url):
+        url = self._get_canonical_url(url)
+        return self._cache.get(url)
+
+    def get_errors(self, url):
+        url = self._get_canonical_url(url)
+        return self._errors.get(url, [])
+
+    def alias(self, u1, u2):
+        if u1 == u2:
+            return
+
+        if u1 in self._cache or u1 not in self._aliases:
+            self._aliases[u1] = u1
+        else:
+            self._aliases[u2] = u1
+
+    def add(self, url, source):
+        url = self._get_canonical_url(url)
+        self._cache[url] = source
+
+    def add_error(self, url, error):
+        url = self._get_canonical_url(url)
+        self._errors.setdefault(url, [])
+        self._errors[url].append(error)
+
+
+class SourceMapCache(object):
+    def __init__(self):
+        self._cache = {}
+        self._mapping = {}
+
+    def __contains__(self, sourcemap_url):
+        return sourcemap_url in self._cache
+
+    def link(self, url, sourcemap_url):
+        self._mapping[url] = sourcemap_url
+
+    def add(self, sourcemap_url, sourcemap_index):
+        self._cache[sourcemap_url] = sourcemap_index
+
+    def get(self, sourcemap_url):
+        return self._cache.get(sourcemap_url)
+
+    def get_link(self, url):
+        sourcemap_url = self._mapping.get(url)
+        if sourcemap_url:
+            sourcemap = self.get(sourcemap_url)
+            return (sourcemap_url, sourcemap)
+        return (None, None)
diff --git a/src/sentry/lang/javascript/plugin.py b/src/sentry/lang/javascript/plugin.py
new file mode 100644
index 0000000000..0f3e30cd80
--- /dev/null
+++ b/src/sentry/lang/javascript/plugin.py
@@ -0,0 +1,23 @@
+from __future__ import absolute_import, print_function
+
+from django.conf import settings
+
+from sentry.plugins import Plugin2
+
+from .processor import SourceProcessor
+
+
+class JavascriptEventProcessor(object):
+    def __call__(self, data):
+        if data.get('platform') != 'javascript':
+            return
+
+        processor = SourceProcessor()
+        return processor.process(data)
+
+
+class JavascriptPlugin(Plugin2):
+    def get_event_preprocessors(self, **kwargs):
+        if not settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT:
+            return []
+        return [JavascriptEventProcessor()]
diff --git a/src/sentry/tasks/fetch_source.py b/src/sentry/lang/javascript/processor.py
similarity index 51%
rename from src/sentry/tasks/fetch_source.py
rename to src/sentry/lang/javascript/processor.py
index 4286f29b22..97e83cc35e 100644
--- a/src/sentry/tasks/fetch_source.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -1,13 +1,7 @@
-"""
-sentry.tasks.fetch_source
-~~~~~~~~~~~~~~~~~~~~~~~~~
-
-:copyright: (c) 2010-2014 by the Sentry Team, see AUTHORS for more details.
-:license: BSD, see LICENSE for more details.
-"""
 from __future__ import absolute_import, print_function
 
-import itertools
+__all__ = ['SourceProcessor']
+
 import logging
 import hashlib
 import re
@@ -22,11 +16,15 @@ from urllib2 import HTTPError
 
 from sentry.constants import MAX_CULPRIT_LENGTH
 from sentry.http import safe_urlopen, safe_urlread
+from sentry.interfaces.stacktrace import Stacktrace
+from sentry.models import Project
 from sentry.utils.cache import cache
 from sentry.utils.http import is_valid_origin
-from sentry.utils.sourcemaps import sourcemap_to_index, find_source
 from sentry.utils.strings import truncatechars
 
+from .cache import SourceCache, SourceMapCache
+from .sourcemaps import sourcemap_to_index, find_source
+
 
 BAD_SOURCE = -1
 # number of surrounding lines (on each side) to fetch
@@ -231,9 +229,28 @@ def is_data_uri(url):
     return url[:BASE64_PREAMBLE_LENGTH] == BASE64_SOURCEMAP_PREAMBLE
 
 
-def expand_javascript_source(data, max_fetches=MAX_RESOURCE_FETCHES, **kwargs):
+def generate_module(src):
+    """
+    Converts a url into a made-up module name by doing the following:
+     * Extract just the path name
+     * Trimming off the initial /
+     * Trimming off the file extension
+     * Removes off useless folder prefixes
+
+    e.g. http://google.com/js/v1.0/foo/bar/baz.js -> foo/bar/baz
+    """
+    if not src:
+        return UNKNOWN_MODULE
+    return CLEAN_MODULE_RE.sub('', splitext(urlsplit(src).path)[0]) or UNKNOWN_MODULE
+
+
+def generate_culprit(frame):
+    return '%s in %s' % (frame.module, frame.function)
+
+
+class SourceProcessor(object):
     """
-    Attempt to fetch source code for javascript frames.
+    Attempts to fetch source code for javascript frames.
 
     Frames must match the following requirements:
 
@@ -244,208 +261,200 @@ def expand_javascript_source(data, max_fetches=MAX_RESOURCE_FETCHES, **kwargs):
 
     Mutates the input ``data`` with expanded context if available.
     """
-    from sentry.interfaces.stacktrace import Stacktrace
-    from sentry.models import Project
-
-    try:
-        stacktraces = [
-            Stacktrace.to_python(e['stacktrace'])
-            for e in data['sentry.interfaces.Exception']['values']
-            if e.get('stacktrace')
-        ]
-    except KeyError:
-        stacktraces = []
-
-    if not stacktraces:
-        logger.debug('No stacktrace for event %r', data['event_id'])
-        return
-
-    # build list of frames that we can actually grab source for
-    frames = []
-    for stacktrace in stacktraces:
-        frames.extend([
-            f for f in stacktrace.frames
-            if f.lineno is not None
-            and f.is_url()
-        ])
-
-    if not frames:
-        logger.debug('Event %r has no frames with enough context to fetch remote source', data['event_id'])
-        return data
+    def __init__(self, max_fetches=MAX_RESOURCE_FETCHES):
+        self.max_fetches = max_fetches
+        self.cache = SourceCache()
+        self.sourcemaps = SourceMapCache()
 
-    project = Project.objects.get_from_cache(id=data['project'])
-
-    pending_file_list = set()
-    done_file_list = set()
-    sourcemap_capable = set()
-    source_code = {}
-    sourcemap_idxs = {}
-    fetch_errors = {}
-
-    for f in frames:
-        pending_file_list.add(f.abs_path)
-        if f.colno is not None:
-            sourcemap_capable.add(f.abs_path)
-
-    idx = 0
-    while pending_file_list:
-        idx += 1
-        filename = pending_file_list.pop()
-        done_file_list.add(filename)
-
-        if idx > max_fetches:
-            fetch_errors[filename] = 'Too many remote sources'
-            logger.warn('Not fetching remote source %r due to max resource fetches', filename)
-            continue
-
-        # TODO: respect cache-contro/max-age headers to some extent
-        logger.debug('Fetching remote source %r', filename)
-        result = fetch_url(filename, project=project)
+    def get_stacktraces(self, data):
+        try:
+            stacktraces = [
+                Stacktrace.to_python(e['stacktrace'])
+                for e in data['sentry.interfaces.Exception']['values']
+                if e.get('stacktrace')
+            ]
+        except KeyError:
+            stacktraces = None
+
+        return stacktraces
+
+    def get_valid_frames(self, stacktraces):
+        # build list of frames that we can actually grab source for
+        frames = []
+        for stacktrace in stacktraces:
+            frames.extend([
+                f for f in stacktrace.frames
+                if f.lineno is not None
+                and f.is_url()
+            ])
+        return frames
+
+    def process(self, data):
+        stacktraces = self.get_stacktraces(data)
+        if not stacktraces:
+            logger.debug('No stacktrace for event %r', data['event_id'])
+            return
 
-        if result == BAD_SOURCE:
-            fetch_errors[filename] = 'File was unreachable or invalid'
-            logger.debug('Bad source file %r', filename)
-            continue
-
-        # If we didn't have a colno, a sourcemap wont do us any good
-        if filename not in sourcemap_capable:
-            fetch_errors[filename] = 'No column information available (required for sourcemap)'
-            logger.debug('Not capable of sourcemap: %r', filename)
-            source_code[filename] = (result.body.splitlines(), None, None)
-            continue
-
-        sourcemap = discover_sourcemap(result)
-
-        # TODO: we're currently running splitlines twice
-        if not sourcemap:
-            source_code[filename] = (result.body.splitlines(), None, None)
-            for f in frames:
-                if not f.module and f.abs_path == filename:
-                    f.module = generate_module(filename)
-            continue
-        else:
-            logger.debug('Found sourcemap %r for minified script %r', sourcemap[:256], result.url)
+        frames = self.get_valid_frames(stacktraces)
+        if not frames:
+            logger.debug('Event %r has no frames with enough context to fetch remote source', data['event_id'])
+            return
 
-        sourcemap_url = result.url[:1000]
-        sourcemap_key = hashlib.md5(sourcemap_url).hexdigest()
+        project = Project.objects.get_from_cache(
+            id=data['project'],
+        )
 
-        source_code[filename] = (result.body.splitlines(), sourcemap_url, sourcemap_key)
+        # all of these methods assume mutation on the original
+        # objects rather than re-creation
+        self.populate_source_cache(project, frames)
+        self.expand_frames(frames)
+        self.ensure_module_names(frames)
+        self.fix_culprit(data, stacktraces)
+        self.update_stacktraces(data, stacktraces)
 
-        if sourcemap in sourcemap_idxs:
-            continue
+        return data
 
-        # pull down sourcemap
-        index = fetch_sourcemap(sourcemap, project=project)
-        if not index:
-            fetch_errors[sourcemap_url] = 'Sourcemap was not parseable'
-            logger.debug('Failed parsing sourcemap index: %r', sourcemap[:15])
-            continue
+    def fix_culprit(self, data, stacktraces):
+        culprit_frame = stacktraces[0].frames[-1]
+        if culprit_frame.module and culprit_frame.function:
+            data['culprit'] = truncatechars(generate_culprit(culprit_frame), MAX_CULPRIT_LENGTH)
 
-        sourcemap_idxs[sourcemap_key] = (index, sourcemap_url)
+    def update_stacktraces(self, data, stacktraces):
+        for exception, stacktrace in zip(data['sentry.interfaces.Exception']['values'], stacktraces):
+            exception['stacktrace'] = stacktrace.to_json()
 
-        # queue up additional source files for download
-        for source in index.sources:
-            next_filename = urljoin(sourcemap_url, source)
-            if next_filename not in done_file_list:
-                if index.content:
-                    source_code[next_filename] = (index.content[source], None, None)
-                    done_file_list.add(next_filename)
+    def ensure_module_names(self, frames):
+        for frame in frames:
+            if not frame.module:
+                frame.module = generate_module(frame.abs_path)
+
+    def expand_frames(self, frames):
+        last_state = None
+        state = None
+        has_changes = False
+
+        cache = self.cache
+        sourcemaps = self.sourcemaps
+
+        for frame in frames:
+            errors = cache.get_errors(frame.abs_path)
+            if errors:
+                frame.errors = errors
+                has_changes = True
+
+            source = cache.get(frame.abs_path)
+            if source is None:
+                continue
+
+            sourcemap_url, sourcemap_idx = sourcemaps.get_link(frame.abs_path)
+            if sourcemap_idx and frame.colno is not None:
+                last_state = state
+                state = find_source(sourcemap_idx, frame.lineno, frame.colno)
+                abs_path = urljoin(sourcemap_url, state.src)
+                logger.debug('Mapping compressed source %r to mapping in %r', frame.abs_path, abs_path)
+                source = cache.get(abs_path)
+                if not source:
+                    frame.data = {
+                        'sourcemap': sourcemap_url,
+                    }
+                    frame.errors.append('Failed to map %r' % abs_path.encode('utf-8'))
+                    logger.debug('Failed mapping path %r', abs_path)
                 else:
-                    pending_file_list.add(next_filename)
-
-    last_state = None
-    state = None
-    has_changes = False
-    for frame in frames:
-        frame.errors = []
-        if frame.abs_path in fetch_errors:
-            frame.errors.append(fetch_errors[frame.abs_path])
-            has_changes = True
-
-        try:
-            source, sourcemap_url, sourcemap_key = source_code[frame.abs_path]
-        except KeyError:
-            # we must've failed pulling down the source
-            continue
-
-        if sourcemap_url in fetch_errors:
-            frame.errors.append(fetch_errors[sourcemap_url])
-            has_changes = True
-
-        # may have had a failure pulling down the sourcemap previously
-        if sourcemap_key in sourcemap_idxs and frame.colno is not None:
-            index, relative_to = sourcemap_idxs[sourcemap_key]
-            last_state = state
-            state = find_source(index, frame.lineno, frame.colno)
-            abs_path = urljoin(relative_to, state.src)
-            logger.debug('Mapping compressed source %r to mapping in %r', frame.abs_path, abs_path)
-            try:
-                source, _, _ = source_code[abs_path]
-            except KeyError:
+                    # Store original data in annotation
+                    frame.data = {
+                        'orig_lineno': frame.lineno,
+                        'orig_colno': frame.colno,
+                        'orig_function': frame.function,
+                        'orig_abs_path': frame.abs_path,
+                        'orig_filename': frame.filename,
+                        'sourcemap': sourcemap_url,
+                    }
+
+                    # SourceMap's return zero-indexed lineno's
+                    frame.lineno = state.src_line + 1
+                    frame.colno = state.src_col
+                    # The offending function is always the previous function in the stack
+                    # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
+                    if last_state:
+                        frame.function = last_state.name or frame.function
+                    else:
+                        frame.function = state.name or frame.function
+                    frame.abs_path = abs_path
+                    frame.filename = state.src
+                    frame.module = generate_module(state.src)
+            elif sourcemap_url:
                 frame.data = {
                     'sourcemap': sourcemap_url,
                 }
-                frame.errors.append('Failed to map %r' % abs_path.encode('utf-8'))
-                logger.debug('Failed mapping path %r', abs_path)
-            else:
-                # Store original data in annotation
-                frame.data = {
-                    'orig_lineno': frame.lineno,
-                    'orig_colno': frame.colno,
-                    'orig_function': frame.function,
-                    'orig_abs_path': frame.abs_path,
-                    'orig_filename': frame.filename,
-                    'sourcemap': sourcemap_url,
-                }
-
-                # SourceMap's return zero-indexed lineno's
-                frame.lineno = state.src_line + 1
-                frame.colno = state.src_col
-                # The offending function is always the previous function in the stack
-                # Honestly, no idea what the bottom most frame is, so we're ignoring that atm
-                if last_state:
-                    frame.function = last_state.name or frame.function
-                else:
-                    frame.function = state.name or frame.function
-                frame.abs_path = abs_path
-                frame.filename = state.src
-                frame.module = generate_module(state.src)
-        elif sourcemap_key in sourcemap_idxs:
-            frame.data = {
-                'sourcemap': sourcemap_url,
-            }
-
-        has_changes = True
-
-        # TODO: theoretically a minified source could point to another mapped, minified source
-        frame.pre_context, frame.context_line, frame.post_context = get_source_context(
-            source=source, lineno=frame.lineno, colno=frame.colno or 0)
-
-    if has_changes:
-        logger.debug('Updating stacktraces with expanded source context')
-        for exception, stacktrace in itertools.izip(data['sentry.interfaces.Exception']['values'], stacktraces):
-            exception['stacktrace'] = stacktrace.to_json()
-
-    # Attempt to fix the culrpit now that we have potentially useful information
-    culprit_frame = stacktraces[0].frames[-1]
-    if culprit_frame.module and culprit_frame.function:
-        data['culprit'] = truncatechars(generate_culprit(culprit_frame), MAX_CULPRIT_LENGTH)
-
 
-def generate_module(src):
-    """
-    Converts a url into a made-up module name by doing the following:
-     * Extract just the path name
-     * Trimming off the initial /
-     * Trimming off the file extension
-     * Removes off useless folder prefixes
-
-    e.g. http://google.com/js/v1.0/foo/bar/baz.js -> foo/bar/baz
-    """
-    if not src:
-        return UNKNOWN_MODULE
-    return CLEAN_MODULE_RE.sub('', splitext(urlsplit(src).path)[0]) or UNKNOWN_MODULE
-
-
-def generate_culprit(frame):
-    return '%s in %s' % (frame.module, frame.function)
+            # TODO: theoretically a minified source could point to another mapped, minified source
+            frame.pre_context, frame.context_line, frame.post_context = get_source_context(
+                source=source, lineno=frame.lineno, colno=frame.colno or 0)
+
+    def populate_source_cache(self, project, frames):
+        pending_file_list = set()
+        done_file_list = set()
+        sourcemap_capable = set()
+
+        cache = self.cache
+        sourcemaps = self.sourcemaps
+
+        for f in frames:
+            pending_file_list.add(f.abs_path)
+            if f.colno is not None:
+                sourcemap_capable.add(f.abs_path)
+
+        idx = 0
+        while pending_file_list:
+            idx += 1
+            filename = pending_file_list.pop()
+            done_file_list.add(filename)
+
+            if idx > self.max_fetches:
+                cache.add_error(filename, 'Not fetching due to too many remote sources')
+                continue
+
+            # TODO: respect cache-control/max-age headers to some extent
+            logger.debug('Fetching remote source %r', filename)
+            result = fetch_url(filename, project=project)
+
+            if result == BAD_SOURCE:
+                # TODO(dcramer): we want better errors here
+                cache.add_error(filename, 'File was unreachable or invalid')
+                continue
+
+            cache.add(filename, result.body.splitlines())
+            cache.alias(result.url, filename)
+
+            # If we didn't have a colno, a sourcemap wont do us any good
+            if filename not in sourcemap_capable:
+                cache.add_error(filename, 'No column information available')
+                continue
+
+            sourcemap_url = discover_sourcemap(result)
+            if not sourcemap_url:
+                continue
+
+            logger.debug('Found sourcemap %r for minified script %r', sourcemap_url[:256], result.url)
+
+            sourcemaps.link(filename, sourcemap_url)
+            if sourcemap_url in sourcemaps:
+                continue
+
+            # pull down sourcemap
+            sourcemap_idx = fetch_sourcemap(sourcemap_url, project=project)
+            if not sourcemap_idx:
+                cache.add_error(filename, 'Sourcemap was not parseable')
+                continue
+
+            sourcemaps.add(sourcemap_url, sourcemap_idx)
+
+            # queue up additional source files for download
+            for source in sourcemap_idx.sources:
+                next_filename = urljoin(sourcemap_url, source)
+                if next_filename not in done_file_list:
+                    if sourcemap_idx.content:
+                        cache.add(next_filename, sourcemap_idx.content[source])
+                        done_file_list.add(next_filename)
+                    else:
+                        pending_file_list.add(next_filename)
diff --git a/src/sentry/utils/sourcemaps.py b/src/sentry/lang/javascript/sourcemaps.py
similarity index 100%
rename from src/sentry/utils/sourcemaps.py
rename to src/sentry/lang/javascript/sourcemaps.py
diff --git a/src/sentry/tasks/store.py b/src/sentry/tasks/store.py
index 9a09a27ffc..8c81884438 100644
--- a/src/sentry/tasks/store.py
+++ b/src/sentry/tasks/store.py
@@ -8,8 +8,6 @@ sentry.tasks.store
 
 from __future__ import absolute_import
 
-from django.conf import settings
-
 from sentry.tasks.base import instrumented_task
 from sentry.utils.safe import safe_execute
 
@@ -20,7 +18,6 @@ from sentry.utils.safe import safe_execute
 def preprocess_event(cache_key=None, data=None, **kwargs):
     from sentry.app import cache
     from sentry.plugins import plugins
-    from sentry.tasks.fetch_source import expand_javascript_source
 
     if cache_key:
         data = cache.get(cache_key)
@@ -35,16 +32,6 @@ def preprocess_event(cache_key=None, data=None, **kwargs):
 
     # TODO(dcramer): ideally we would know if data changed by default
     has_changed = False
-
-    # TODO(dcramer): move js sourcemap processing into JS plugin
-    if settings.SENTRY_SCRAPE_JAVASCRIPT_CONTEXT and data.get('platform') == 'javascript':
-        try:
-            expand_javascript_source(data)
-        except Exception as e:
-            logger.exception(u'Error fetching javascript source: %r [%s]', data['event_id'], e)
-        else:
-            has_changed = True
-
     for plugin in plugins.all(version=2):
         for processor in (safe_execute(plugin.get_event_preprocessors) or ()):
             result = safe_execute(processor, data)
diff --git a/tests/sentry/lang/__init__.py b/tests/sentry/lang/__init__.py
new file mode 100644
index 0000000000..c3961685ab
--- /dev/null
+++ b/tests/sentry/lang/__init__.py
@@ -0,0 +1 @@
+from __future__ import absolute_import
diff --git a/tests/sentry/lang/javascript/__init__.py b/tests/sentry/lang/javascript/__init__.py
new file mode 100644
index 0000000000..c3961685ab
--- /dev/null
+++ b/tests/sentry/lang/javascript/__init__.py
@@ -0,0 +1 @@
+from __future__ import absolute_import
diff --git a/tests/sentry/tasks/fetch_source/tests.py b/tests/sentry/lang/javascript/test_processor.py
similarity index 90%
rename from tests/sentry/tasks/fetch_source/tests.py
rename to tests/sentry/lang/javascript/test_processor.py
index 79ff08823f..83884d6563 100644
--- a/tests/sentry/tasks/fetch_source/tests.py
+++ b/tests/sentry/lang/javascript/test_processor.py
@@ -4,18 +4,19 @@ from __future__ import absolute_import
 
 from mock import patch
 
-from sentry.tasks.fetch_source import (
-    UrlResult, expand_javascript_source, discover_sourcemap,
-    fetch_sourcemap, fetch_url, generate_module, BAD_SOURCE, trim_line)
-from sentry.utils.sourcemaps import (SourceMap, SourceMapIndex)
+from sentry.lang.javascript.processor import (
+    BAD_SOURCE, discover_sourcemap, fetch_sourcemap, fetch_url, generate_module,
+    SourceProcessor, trim_line, UrlResult
+)
+from sentry.lang.javascript.sourcemaps import SourceMap, SourceMapIndex
 from sentry.testutils import TestCase
 
 base64_sourcemap = 'data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiZ2VuZXJhdGVkLmpzIiwic291cmNlcyI6WyIvdGVzdC5qcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiO0FBQUEiLCJzb3VyY2VzQ29udGVudCI6WyJjb25zb2xlLmxvZyhcImhlbGxvLCBXb3JsZCFcIikiXX0='
 
 
 class FetchUrlTest(TestCase):
-    @patch('sentry.tasks.fetch_source.safe_urlopen')
-    @patch('sentry.tasks.fetch_source.safe_urlread')
+    @patch('sentry.lang.javascript.processor.safe_urlopen')
+    @patch('sentry.lang.javascript.processor.safe_urlread')
     def test_simple(self, safe_urlread, safe_urlopen):
         safe_urlopen.return_value.headers = (('content-type', 'application/json'),)
         safe_urlread.return_value = u'foo bar'
@@ -38,8 +39,8 @@ class FetchUrlTest(TestCase):
 
         assert result == result2
 
-    @patch('sentry.tasks.fetch_source.safe_urlopen')
-    @patch('sentry.tasks.fetch_source.safe_urlread')
+    @patch('sentry.lang.javascript.processor.safe_urlopen')
+    @patch('sentry.lang.javascript.processor.safe_urlread')
     def test_with_token(self, safe_urlread, safe_urlopen):
         self.project.update_option('sentry:token', 'foobar')
         self.project.update_option('sentry:origins', ['*'])
@@ -65,8 +66,8 @@ class FetchUrlTest(TestCase):
 
         assert result == result2
 
-    @patch('sentry.tasks.fetch_source.safe_urlopen')
-    @patch('sentry.tasks.fetch_source.safe_urlread')
+    @patch('sentry.lang.javascript.processor.safe_urlopen')
+    @patch('sentry.lang.javascript.processor.safe_urlread')
     def test_connection_failure(self, safe_urlread, safe_urlopen):
         safe_urlopen.side_effect = Exception()
 
@@ -86,8 +87,8 @@ class FetchUrlTest(TestCase):
 
         assert result == BAD_SOURCE
 
-    @patch('sentry.tasks.fetch_source.safe_urlopen')
-    @patch('sentry.tasks.fetch_source.safe_urlread')
+    @patch('sentry.lang.javascript.processor.safe_urlopen')
+    @patch('sentry.lang.javascript.processor.safe_urlread')
     def test_read_failure(self, safe_urlread, safe_urlopen):
         safe_urlopen.return_value.headers = (('content-type', 'application/json'),)
         safe_urlread.side_effect = Exception()
@@ -138,11 +139,15 @@ class DiscoverSourcemapTest(TestCase):
         assert discover_sourcemap(result) == 'http://example.com/source.map.js'
 
 
-class ExpandJavascriptSourceTest(TestCase):
+class SourceProcessorTest(TestCase):
+    def process(self, data):
+        processor = SourceProcessor()
+        return processor.process(data)
+
     @patch('sentry.models.Event.update')
-    @patch('sentry.tasks.fetch_source.fetch_url')
-    @patch('sentry.tasks.fetch_source.fetch_sourcemap')
-    @patch('sentry.tasks.fetch_source.discover_sourcemap')
+    @patch('sentry.lang.javascript.processor.fetch_url')
+    @patch('sentry.lang.javascript.processor.fetch_sourcemap')
+    @patch('sentry.lang.javascript.processor.discover_sourcemap')
     def test_simple(self, discover_sourcemap, fetch_sourcemap, fetch_url, update):
         data = {
             'project': self.project.id,
@@ -171,7 +176,7 @@ class ExpandJavascriptSourceTest(TestCase):
         fetch_sourcemap.return_value = None
         fetch_url.return_value.body = '\n'.join('hello world')
 
-        expand_javascript_source(data)
+        self.process(data)
 
         fetch_url.assert_called_once_with(
             'http://example.com/foo.js', project=self.project)
@@ -188,8 +193,8 @@ class ExpandJavascriptSourceTest(TestCase):
         assert frame['post_context'] == ['e', 'l', 'l', 'o', ' ']
 
     @patch('sentry.models.Event.update')
-    @patch('sentry.tasks.fetch_source.fetch_url')
-    @patch('sentry.tasks.fetch_source.discover_sourcemap')
+    @patch('sentry.lang.javascript.processor.fetch_url')
+    @patch('sentry.lang.javascript.processor.discover_sourcemap')
     def test_inlined_sources(self, discover_sourcemap, fetch_url, update):
         data = {
             'project': self.project.id,
@@ -212,7 +217,7 @@ class ExpandJavascriptSourceTest(TestCase):
         fetch_url.return_value.url = 'http://example.com/test.min.js'
         fetch_url.return_value.body = '\n'.join('<generated source>')
 
-        expand_javascript_source(data)
+        self.process(data)
         fetch_url.assert_called_once_with(
             'http://example.com/test.min.js', project=self.project)
 
diff --git a/tests/sentry/utils/sourcemaps/tests.py b/tests/sentry/lang/javascript/test_sourcemaps.py
similarity index 97%
rename from tests/sentry/utils/sourcemaps/tests.py
rename to tests/sentry/lang/javascript/test_sourcemaps.py
index 3908813ce2..8aa88f8137 100644
--- a/tests/sentry/utils/sourcemaps/tests.py
+++ b/tests/sentry/lang/javascript/test_sourcemaps.py
@@ -2,8 +2,9 @@
 
 from __future__ import absolute_import
 
-from sentry.utils.sourcemaps import (SourceMap, parse_vlq, parse_sourcemap, sourcemap_to_index,
-    find_source)
+from sentry.lang.javascript.sourcemaps import (
+    SourceMap, parse_vlq, parse_sourcemap, sourcemap_to_index, find_source
+)
 from sentry.testutils import TestCase
 
 from sentry.utils import json
diff --git a/tests/sentry/tasks/fetch_source/__init__.py b/tests/sentry/tasks/fetch_source/__init__.py
deleted file mode 100644
index e69de29bb2..0000000000
diff --git a/tests/sentry/utils/sourcemaps/__init__.py b/tests/sentry/utils/sourcemaps/__init__.py
deleted file mode 100644
index e69de29bb2..0000000000
