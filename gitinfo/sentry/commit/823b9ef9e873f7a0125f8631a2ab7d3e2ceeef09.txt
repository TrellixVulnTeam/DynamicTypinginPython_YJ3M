commit 823b9ef9e873f7a0125f8631a2ab7d3e2ceeef09
Author: Mark Story <mark@sentry.io>
Date:   Fri Sep 27 15:41:57 2019 -0400

    feat(discover2) Add a function to detect datasets (#14851)
    
    As part of the new discover implementation we need to transparently
    select either the events or transactions dataset based on the query the
    user provides us. This change also adds the field mappings for the
    transactions dataset and adds another map that will allow other utility
    functions to resolve column aliases based on the selected dataset.
    
    Refs SEN-1043

diff --git a/src/sentry/utils/snuba.py b/src/sentry/utils/snuba.py
index 2efdd2d33c..e27d2d7e66 100644
--- a/src/sentry/utils/snuba.py
+++ b/src/sentry/utils/snuba.py
@@ -36,6 +36,8 @@ MAX_HASHES = 5000
 SAFE_FUNCTION_RE = re.compile(r"-?[a-zA-Z_][a-zA-Z0-9_]*$")
 QUOTED_LITERAL_RE = re.compile(r"^'.*'$")
 
+TRANSACTIONS = "transactions"
+EVENTS = "events"
 
 # Global Snuba request option override dictionary. Only intended
 # to be used with the `options_override` contextmanager below.
@@ -120,6 +122,45 @@ SENTRY_SNUBA_MAP = {
     "user": "tags[sentry:user]",
 }
 
+TRANSACTIONS_SENTRY_SNUBA_MAP = {
+    # general
+    "id": "event_id",
+    "project.id": "project_id",
+    "trace_id": "trace_id",
+    "span_id": "span_id",
+    "title": "transaction_name",
+    "transaction": "transaction_name",
+    "transaction.name": "transaction_name",
+    "transaction.op": "transaction_op",
+    "transaction_op": "transaction_op",
+    "platform.name": "platform",
+    "environment": "environment",
+    "release": "release",
+    # Time related properties
+    "transaction.duration": "duration",
+    "transaction.start_time": "start_ts",
+    "transaction.end_time": "end_ts",
+    # User
+    "user": "user",
+    "user.id": "user_id",
+    "user.email": "user_email",
+    "user.username": "user_name",
+    "user.ip": "ip_address_v4",
+    # tags, contexts
+    "tags.key": "tags.key",
+    "tags.value": "tags.value",
+    "tags_key": "tags_key",
+    "tags_value": "tags_value",
+    "contexts.key": "contexts.key",
+    "contexts.value": "contexts.value",
+    # Shim to make queries that can act on
+    # events or transactions work more smoothly.
+    "timestamp": "start_ts",
+    "time": "bucketed_start",
+}
+
+DATASETS = {EVENTS: SENTRY_SNUBA_MAP, TRANSACTIONS: TRANSACTIONS_SENTRY_SNUBA_MAP}
+
 
 class SnubaError(Exception):
     pass
@@ -301,6 +342,48 @@ def get_snuba_column_name(name):
     return SENTRY_SNUBA_MAP.get(name, u"tags[{}]".format(name))
 
 
+def detect_dataset(query_args):
+    """
+    Determine the dataset to use based on the conditions, selected_columns,
+    groupby clauses.
+
+    This function operates on the end user field aliases and not the internal column
+    names that have been converted using the field mappings.
+    """
+    if query_args.get("dataset", None):
+        return query_args["dataset"]
+
+    dataset = EVENTS
+    transaction_fields = set(DATASETS[TRANSACTIONS].keys()) - set(DATASETS[EVENTS].keys())
+    for condition in query_args.get("conditions") or []:
+        if isinstance(condition[0], six.string_types) and condition[0] in transaction_fields:
+            return TRANSACTIONS
+        if condition == ["event.type", "=", "transaction"]:
+            return TRANSACTIONS
+        if condition == ["type", "=", "transaction"]:
+            return TRANSACTIONS
+
+    for field in query_args.get("selected_columns") or []:
+        if isinstance(field, six.string_types) and field in transaction_fields:
+            return TRANSACTIONS
+
+    for field in query_args.get("aggregations") or []:
+        if len(field) != 3:
+            continue
+        if isinstance(field[1], six.string_types) and field[1] in transaction_fields:
+            return TRANSACTIONS
+        if isinstance(field[1], (list, tuple)):
+            is_transaction = [column for column in field[1] if column in transaction_fields]
+            if is_transaction:
+                return TRANSACTIONS
+
+    for field in query_args.get("groupby") or []:
+        if field in transaction_fields:
+            return TRANSACTIONS
+
+    return dataset
+
+
 def get_function_index(column_expr, depth=0):
     """
     If column_expr list contains a function, returns the index of its function name
diff --git a/tests/sentry/utils/test_snuba.py b/tests/sentry/utils/test_snuba.py
index b18126da90..55f7efe748 100644
--- a/tests/sentry/utils/test_snuba.py
+++ b/tests/sentry/utils/test_snuba.py
@@ -5,7 +5,13 @@ import pytz
 
 from sentry.models import GroupRelease, Release
 from sentry.testutils import TestCase
-from sentry.utils.snuba import get_snuba_translators, zerofill, get_json_type, get_snuba_column_name
+from sentry.utils.snuba import (
+    get_snuba_translators,
+    zerofill,
+    get_json_type,
+    get_snuba_column_name,
+    detect_dataset,
+)
 
 
 class SnubaUtilsTest(TestCase):
@@ -168,3 +174,52 @@ class SnubaUtilsTest(TestCase):
         # This is odd behavior but captures what we do currently.
         assert get_snuba_column_name("tags[sentry:user]") == "tags[tags[sentry:user]]"
         assert get_snuba_column_name("organization") == "tags[organization]"
+
+
+class DetectDatasetTest(TestCase):
+    def test_dataset_key(self):
+        query = {"dataset": "events", "conditions": [["event.type", "=", "transaction"]]}
+        assert detect_dataset(query) == "events"
+
+    def test_event_type_condition(self):
+        query = {"conditions": [["event.type", "=", "transaction"]]}
+        assert detect_dataset(query) == "transactions"
+
+        query = {"conditions": [["event.type", "!=", "transaction"]]}
+        assert detect_dataset(query) == "events"
+
+        query = {"conditions": [["type", "=", "transaction"]]}
+        assert detect_dataset(query) == "transactions"
+
+        query = {"conditions": [["type", "=", "error"]]}
+        assert detect_dataset(query) == "events"
+
+    def test_conditions(self):
+        query = {"conditions": [["transaction", "=", "api.do_thing"]]}
+        assert detect_dataset(query) == "events"
+
+        query = {"conditions": [["transaction.name", "=", "api.do_thing"]]}
+        assert detect_dataset(query) == "transactions"
+
+        query = {"conditions": [["transaction.duration", ">", "3"]]}
+        assert detect_dataset(query) == "transactions"
+
+    def test_selected_columns(self):
+        query = {"selected_columns": ["id", "message"]}
+        assert detect_dataset(query) == "events"
+
+        query = {"selected_columns": ["id", "transaction", "transaction.duration"]}
+        assert detect_dataset(query) == "transactions"
+
+    def test_aggregations(self):
+        query = {"aggregations": [["argMax", ["id", "timestamp"], "latest_event"]]}
+        assert detect_dataset(query) == "events"
+
+        query = {"aggregations": [["argMax", ["id", "duration"], "longest"]]}
+        assert detect_dataset(query) == "events"
+
+        query = {"aggregations": [["quantileTiming(0.95)", "transaction.duration", "p95_duration"]]}
+        assert detect_dataset(query) == "transactions"
+
+        query = {"aggregations": [["uniq", "transaction.name", "uniq_transaction"]]}
+        assert detect_dataset(query) == "transactions"
