commit 17f2a1af3fc91f39ccfc41da1cba72c6885bc6f2
Author: Armin Ronacher <armin.ronacher@active-4.com>
Date:   Mon Dec 12 22:45:50 2016 +0100

    Switch on-hold -> unprocessed

diff --git a/src/sentry/api/endpoints/project_group_index.py b/src/sentry/api/endpoints/project_group_index.py
index 1795b093a6..58b5df62ca 100644
--- a/src/sentry/api/endpoints/project_group_index.py
+++ b/src/sentry/api/endpoints/project_group_index.py
@@ -71,7 +71,7 @@ STATUS_CHOICES = {
     'unresolved': GroupStatus.UNRESOLVED,
     'ignored': GroupStatus.IGNORED,
     'resolvedInNextRelease': GroupStatus.UNRESOLVED,
-    'on_hold': GroupStatus.ON_HOLD,
+    'unprocessed': GroupStatus.UNPROCESSED,
 
     # TODO(dcramer): remove in 9.0
     'muted': GroupStatus.IGNORED,
@@ -151,7 +151,7 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint):
             except InvalidQuery as e:
                 raise ValidationError(u'Your search query could not be parsed: {}'.format(e.message))
 
-        query_kwargs['include_on_hold'] = request.GET.get('includeOnHold') == '1'
+        query_kwargs['include_unprocessed'] = request.GET.get('includeUnprocessed') == '1'
 
         return query_kwargs
 
@@ -187,9 +187,9 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint):
         :qparam querystring query: an optional Sentry structured search
                                    query.  If not provided an implied
                                    ``"is:resolved"`` is assumed.)
-        :qparam bool includeOnHold: include events that are on hold.  This is
-                                    only used when filtering by status is not
-                                    used.
+        :qparam bool includeUnprocessed: include events that are unprocessed.
+                                         This is only used when filtering
+                                         by status is not used.
         :pparam string organization_slug: the slug of the organization the
                                           issues belong to.
         :pparam string project_slug: the slug of the project the issues
@@ -456,8 +456,8 @@ class ProjectGroupIndexEndpoint(ProjectEndpoint):
 
             result['statusDetails'] = {}
 
-        elif result.get('status') == 'on_hold':
-            return Response('{"detail": "Cannot put events on hold from '
+        elif result.get('status') == 'unprocessed':
+            return Response('{"detail": "Cannot set events to unprocessed from '
                             'the API"}', status=400)
         elif result.get('status'):
             new_status = STATUS_CHOICES[result['status']]
diff --git a/src/sentry/api/serializers/models/group.py b/src/sentry/api/serializers/models/group.py
index a4f2642249..6de57f9d25 100644
--- a/src/sentry/api/serializers/models/group.py
+++ b/src/sentry/api/serializers/models/group.py
@@ -186,8 +186,8 @@ class GroupSerializer(Serializer):
             status_label = 'pending_deletion'
         elif status == GroupStatus.PENDING_MERGE:
             status_label = 'pending_merge'
-        elif status == GroupStatus.ON_HOLD:
-            status_label = 'on_hold'
+        elif status == GroupStatus.UNPROCESSED:
+            status_label = 'unprocessed'
         else:
             status_label = 'unresolved'
 
diff --git a/src/sentry/constants.py b/src/sentry/constants.py
index 0e566c289c..b1a555eede 100644
--- a/src/sentry/constants.py
+++ b/src/sentry/constants.py
@@ -51,11 +51,13 @@ SEARCH_SORT_OPTIONS = OrderedDict((
 STATUS_UNRESOLVED = 0
 STATUS_RESOLVED = 1
 STATUS_IGNORED = 2
+STATUS_UNPROCESSED = 6
 
 STATUS_CHOICES = {
     'resolved': STATUS_RESOLVED,
     'unresolved': STATUS_UNRESOLVED,
     'ignored': STATUS_IGNORED,
+    'unprocessed': STATUS_UNPROCESSED,
 
     # TODO(dcramer): remove in 9.0
     'muted': STATUS_IGNORED,
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 5877685a6c..0c82a2d411 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -235,8 +235,8 @@ class EventManager(object):
         # First we pull out our top-level (non-data attr) kwargs
         data = self.data
 
-        # Do not put the group on hold for now.
-        data['on_hold'] = False
+        # Do not set the event to unprocessed by default
+        data['unprocessed'] = False
 
         if not isinstance(data.get('level'), (six.string_types, int)):
             data['level'] = logging.ERROR
@@ -405,7 +405,7 @@ class EventManager(object):
 
         data = self.data.copy()
 
-        on_hold = data.pop('on_hold', False)
+        unprocessed = data.pop('unprocessed', False)
 
         # First we pull out our top-level (non-data attr) kwargs
         event_id = data.pop('event_id')
@@ -587,7 +587,7 @@ class EventManager(object):
             event=event,
             hashes=hashes,
             release=release,
-            on_hold=on_hold,
+            unprocessed=unprocessed,
             **group_kwargs
         )
 
@@ -800,7 +800,7 @@ class EventManager(object):
             group=group,
         )
 
-    def _save_aggregate(self, event, hashes, release, on_hold=False, **kwargs):
+    def _save_aggregate(self, event, hashes, release, unprocessed=False, **kwargs):
         project = event.project
 
         # attempt to find a matching hash
@@ -816,10 +816,13 @@ class EventManager(object):
         # should be better tested/reviewed
         if existing_group_id is None:
             kwargs['score'] = ScoreClause.calculate(1, kwargs['last_seen'])
-            if on_hold:
-                kwargs['status'] = GroupStatus.ON_HOLD
+            if unprocessed:
+                kwargs['status'] = GroupStatus.UNPROCESSED
             with transaction.atomic():
-                short_id = project.next_short_id()
+                if unprocessed:
+                    short_id = None
+                else:
+                    short_id = project.next_short_id()
                 group, group_is_new = Group.objects.create(
                     project=project,
                     short_id=short_id,
@@ -864,7 +867,7 @@ class EventManager(object):
                 event=event,
                 data=kwargs,
                 release=release,
-                on_hold=on_hold,
+                unprocessed=unprocessed,
             )
         else:
             is_regression = False
@@ -877,7 +880,7 @@ class EventManager(object):
 
         return group, is_new, is_regression, is_sample
 
-    def _handle_regression(self, group, event, release, on_hold=False):
+    def _handle_regression(self, group, event, release, unprocessed=False):
         if not group.is_resolved():
             return
 
@@ -898,8 +901,8 @@ class EventManager(object):
             return
 
         group_status = GroupStatus.UNRESOLVED
-        if on_hold:
-            group_status = GroupStatus.ON_HOLD
+        if unprocessed:
+            group_status = GroupStatus.UNPROCESSED
 
         # we now think its a regression, rely on the database to validate that
         # no one beat us to this
@@ -970,7 +973,7 @@ class EventManager(object):
         return is_regression
 
     def _process_existing_aggregate(self, group, event, data, release,
-                                    on_hold=False):
+                                    unprocessed=False):
         date = max(event.datetime, group.last_seen)
         extra = {
             'last_seen': date,
@@ -985,7 +988,7 @@ class EventManager(object):
             extra['culprit'] = data['culprit']
 
         is_regression = self._handle_regression(group, event, release,
-                                                on_hold=on_hold)
+                                                unprocessed=unprocessed)
 
         group.last_seen = extra['last_seen']
 
diff --git a/src/sentry/models/group.py b/src/sentry/models/group.py
index f400dd6e94..89fec871d5 100644
--- a/src/sentry/models/group.py
+++ b/src/sentry/models/group.py
@@ -52,7 +52,7 @@ class GroupStatus(object):
     PENDING_DELETION = 3
     DELETION_IN_PROGRESS = 4
     PENDING_MERGE = 5
-    ON_HOLD = 6
+    UNPROCESSED = 6
 
     # TODO(dcramer): remove in 9.0
     MUTED = IGNORED
@@ -248,11 +248,11 @@ class Group(Model):
         return self.get_status() == GroupStatus.IGNORED
 
     def is_transient(self):
-        """Anything that is on-hold is also transient.  Transient groups are
+        """Anything that is unprocessed is also transient.  Transient groups are
         considered temporary and should not trigger notifications, do not
         allow issues to be filed etc.
         """
-        return self.status == GroupStatus.ON_HOLD
+        return self.status == GroupStatus.UNPROCESSED
 
     # TODO(dcramer): remove in 9.0 / after plugins no long ref
     is_muted = is_ignored
diff --git a/src/sentry/reprocessing.py b/src/sentry/reprocessing.py
index 02d652bad1..795c5ff54a 100644
--- a/src/sentry/reprocessing.py
+++ b/src/sentry/reprocessing.py
@@ -1,7 +1,6 @@
 from __future__ import absolute_import
 
-from sentry.models import ProcessingIssue, ProcessingIssueGroup, GroupStatus, \
-    Event
+from sentry.models import ProcessingIssue, ProcessingIssueGroup, Event
 from sentry.utils.query import batched_queryset_iter
 from sentry.tasks.store import preprocess_event
 
@@ -13,7 +12,7 @@ def record_processing_issue(event_data, type, key, release_bound=True,
     permit reprocessing when they are fixed.
     """
     if hold_group:
-        event_data['on_hold'] = True
+        event_data['unprocessed'] = True
     event_data.setdefault('processing_issues', []).append({
         'type': type,
         'key': key,
@@ -27,8 +26,7 @@ def resolve_processing_issue(project, type, key=None):
     """Resolves a processing issue.  This might trigger reprocessing."""
     q = ProcessingIssueGroup.objects.filter(
         issue__project=project,
-        issue__type=type,
-        group__status=GroupStatus.ON_HOLD
+        issue__type=type
     )
     if key is not None:
         q = q.filter(issue__key=key)
@@ -49,7 +47,6 @@ def resolve_processing_issue(project, type, key=None):
 
     q = ProcessingIssueGroup.objects.filter(
         issue__project=project,
-        group__status=GroupStatus.ON_HOLD,
         group__pk__in=list(affected_groups)
     )
     broken_groups = set(x.id for x in q)
diff --git a/src/sentry/search/base.py b/src/sentry/search/base.py
index fd6d687d1d..600777b5a1 100644
--- a/src/sentry/search/base.py
+++ b/src/sentry/search/base.py
@@ -28,7 +28,7 @@ class SearchBackend(object):
               bookmarked_by=None, assigned_to=None, first_release=None,
               sort_by='date', age_from=None, age_to=None,
               unassigned=None, date_from=None, date_to=None,
-              include_on_hold=False, cursor=None, limit=100):
+              include_unprocessed=False, cursor=None, limit=100):
         """
         The return value should be a CursorResult.
 
diff --git a/src/sentry/search/django/backend.py b/src/sentry/search/django/backend.py
index 27f38fc8da..8f35451efa 100644
--- a/src/sentry/search/django/backend.py
+++ b/src/sentry/search/django/backend.py
@@ -75,8 +75,7 @@ class DjangoSearchBackend(SearchBackend):
                         date_to=None, date_to_inclusive=True,
                         active_at_from=None, active_at_from_inclusive=True,
                         active_at_to=None, active_at_to_inclusive=True,
-                        include_on_hold=False, date_to=None,
-                        date_to_inclusive=True, cursor=None, limit=None):
+                        include_unprocessed=False, cursor=None, limit=None):
         from sentry.models import Event, Group, GroupSubscription, GroupStatus
 
         engine = get_db_engine('default')
@@ -99,8 +98,8 @@ class DjangoSearchBackend(SearchBackend):
                 GroupStatus.DELETION_IN_PROGRESS,
                 GroupStatus.PENDING_MERGE,
             )
-            if not include_on_hold:
-                status_in += (GroupStatus.ON_HOLD,)
+            if not include_unprocessed:
+                status_in += (GroupStatus.UNPROCESSED,)
             queryset = queryset.exclude(status__in=status_in)
         else:
             queryset = queryset.filter(status=status)
diff --git a/tests/sentry/api/serializers/test_group.py b/tests/sentry/api/serializers/test_group.py
index 5717bd42c1..af239f0c97 100644
--- a/tests/sentry/api/serializers/test_group.py
+++ b/tests/sentry/api/serializers/test_group.py
@@ -47,14 +47,14 @@ class GroupSerializerTest(TestCase):
         assert result['status'] == 'ignored'
         assert result['statusDetails'] == {'ignoreUntil': snooze.until}
 
-    def test_is_ignored_on_hold(self):
+    def test_is_ignored_unprocessed(self):
         user = self.create_user()
         group = self.create_group(
-            status=GroupStatus.ON_HOLD,
+            status=GroupStatus.UNPROCESSED,
         )
 
         result = serialize(group, user)
-        assert result['status'] == 'on_hold'
+        assert result['status'] == 'unprocessed'
         assert result['isTransient'] is True
 
     def test_resolved_in_next_release(self):
diff --git a/tests/sentry/models/test_group.py b/tests/sentry/models/test_group.py
index e30edd636a..6af342cdb6 100644
--- a/tests/sentry/models/test_group.py
+++ b/tests/sentry/models/test_group.py
@@ -37,10 +37,10 @@ class GroupTest(TestCase):
         assert group.is_resolved()
 
     def test_is_transient(self):
-        group = self.create_group(status=GroupStatus.ON_HOLD)
+        group = self.create_group(status=GroupStatus.UNPROCESSED)
         assert group.is_transient()
         assert group.is_ignored()
-        assert group.get_status() == GroupStatus.ON_HOLD
+        assert group.get_status() == GroupStatus.UNPROCESSED
 
         group = self.create_group(status=GroupStatus.RESOLVED)
         assert not group.is_transient()
diff --git a/tests/sentry/tasks/test_store.py b/tests/sentry/tasks/test_store.py
index 0e3dc5a75e..9d77344f84 100644
--- a/tests/sentry/tasks/test_store.py
+++ b/tests/sentry/tasks/test_store.py
@@ -14,7 +14,7 @@ class BasicPreprocessorPlugin(Plugin2):
             return data
 
         def put_on_hold(data):
-            data['on_hold'] = True
+            data['unprocessed'] = True
             return data
 
         if data.get('platform') == 'mattlang':
@@ -123,7 +123,7 @@ class StoreTasksTest(PluginTestCase):
 
     @mock.patch('sentry.tasks.store.save_event')
     @mock.patch('sentry.tasks.store.default_cache')
-    def test_process_event_on_hold(self, mock_default_cache, mock_save_event):
+    def test_process_event_unprocessed(self, mock_default_cache, mock_save_event):
         project = self.create_project()
 
         data = {
@@ -143,7 +143,7 @@ class StoreTasksTest(PluginTestCase):
                 'platform': 'holdmeclose',
                 'message': 'test',
                 'extra': {'foo': 'bar'},
-                'on_hold': True,
+                'unprocessed': True,
             }, 3600
         )
 
