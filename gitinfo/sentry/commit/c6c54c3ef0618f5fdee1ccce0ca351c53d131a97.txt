commit c6c54c3ef0618f5fdee1ccce0ca351c53d131a97
Author: ted kaemming <ted@kaemming.com>
Date:   Fri Jul 21 10:19:52 2017 -0700

    Repair similarity index after group unmerge. (#5749)

diff --git a/src/sentry/tasks/unmerge.py b/src/sentry/tasks/unmerge.py
index cbb3c193dc..88c5661baf 100644
--- a/src/sentry/tasks/unmerge.py
+++ b/src/sentry/tasks/unmerge.py
@@ -16,6 +16,7 @@ from sentry.models import (
     GroupHash, GroupRelease, GroupTagKey, GroupTagValue, Project, Release,
     UserReport
 )
+from sentry.similarity import features
 from sentry.tasks.base import instrumented_task
 
 
@@ -235,31 +236,33 @@ def migrate_events(caches, project, source_id, destination_id, fingerprints, eve
     return destination.id
 
 
-def truncate_denormalizations(group_id):
+def truncate_denormalizations(group):
     GroupTagKey.objects.filter(
-        group_id=group_id,
+        group_id=group.id,
     ).delete()
 
     GroupTagValue.objects.filter(
-        group_id=group_id,
+        group_id=group.id,
     ).delete()
 
     GroupRelease.objects.filter(
-        group_id=group_id,
+        group_id=group.id,
     ).delete()
 
     tsdb.delete([
         tsdb.models.group,
-    ], [group_id])
+    ], [group.id])
 
     tsdb.delete_distinct_counts([
         tsdb.models.users_affected_by_group,
-    ], [group_id])
+    ], [group.id])
 
     tsdb.delete_frequencies([
         tsdb.models.frequent_releases_by_group,
         tsdb.models.frequent_environments_by_group,
-    ], [group_id])
+    ], [group.id])
+
+    features.delete(group)
 
 
 def collect_tag_data(events):
@@ -455,6 +458,9 @@ def repair_denormalizations(caches, project, events):
     repair_group_release_data(caches, project, events)
     repair_tsdb_data(caches, project, events)
 
+    for event in events:
+        features.record(event)
+
 
 def update_tag_value_counts(id_list):
     instances = GroupTagKey.objects.filter(group_id__in=id_list)
@@ -510,22 +516,22 @@ def unmerge(
     # be run without iteration by passing around a state object and we could
     # just use that here instead.
 
+    source = Group.objects.get(
+        project_id=project_id,
+        id=source_id,
+    )
+
     # On the first iteration of this loop, we clear out all of the
     # denormalizations from the source group so that we can have a clean slate
     # for the new, repaired data.
     if cursor is None:
         fingerprints = lock_hashes(project_id, source_id, fingerprints)
-        truncate_denormalizations(source_id)
+        truncate_denormalizations(source)
 
     caches = get_caches()
 
     project = caches['Project'](project_id)
 
-    source = Group.objects.get(
-        project_id=project_id,
-        id=source_id,
-    )
-
     # We fetch the events in descending order by their primary key to get the
     # best approximation of the most recently received events.
     queryset = Event.objects.filter(
diff --git a/tests/sentry/tasks/test_unmerge.py b/tests/sentry/tasks/test_unmerge.py
index a527d36bcd..7c48bffa84 100644
--- a/tests/sentry/tasks/test_unmerge.py
+++ b/tests/sentry/tasks/test_unmerge.py
@@ -15,6 +15,7 @@ from sentry.models import (
     Activity, Environment, EnvironmentProject, Event, EventMapping, Group,
     GroupHash, GroupRelease, GroupTagKey, GroupTagValue, Release, UserReport
 )
+from sentry.similarity import features
 from sentry.tasks.unmerge import (
     get_caches, get_event_user_from_interface, get_fingerprint,
     get_group_backfill_attributes, get_group_creation_attributes, unmerge
@@ -236,6 +237,8 @@ class UnmergeTestCase(TestCase):
                 comments='Quack',
             )
 
+            features.record(event)
+
             return event
 
         events = OrderedDict()
@@ -273,6 +276,10 @@ class UnmergeTestCase(TestCase):
             (u'sentry:release', u'version', 17),
         ])
 
+        assert features.query(source) == [
+            (source.id, {'message:message:character-shingles': 1.0}),
+        ]
+
         with self.tasks():
             unmerge.delay(
                 source.project_id,
@@ -671,3 +678,16 @@ class UnmergeTestCase(TestCase):
             time_series[destination.id],
             {},
         )
+
+        source_similar_items = features.query(source)
+        assert source_similar_items[0] == (source.id, {'message:message:character-shingles': 1.0})
+        assert source_similar_items[1][0] == destination.id
+        assert source_similar_items[1][1].keys() == ['message:message:character-shingles']
+        assert source_similar_items[1][1]['message:message:character-shingles'] < 1.0
+
+        destination_similar_items = features.query(destination)
+        assert destination_similar_items[0] == (
+            destination.id, {'message:message:character-shingles': 1.0})
+        assert destination_similar_items[1][0] == source.id
+        assert destination_similar_items[1][1].keys() == ['message:message:character-shingles']
+        assert destination_similar_items[1][1]['message:message:character-shingles'] < 1.0
