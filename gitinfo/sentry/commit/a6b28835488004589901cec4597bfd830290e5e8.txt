commit a6b28835488004589901cec4597bfd830290e5e8
Author: William Mak <william@wmak.io>
Date:   Tue Apr 21 10:58:34 2020 -0400

    fix(discover): Supporting user field for top events (#18345)
    
    - Fixes a bug when the user field is supplied for top events
    - This widens the net quite a bit, as it does an IN for each user field
      and ORs them together.
    - Use the same logic as transform to make user 1 field in the result key
    - Also noticed that groupby had duplicates when there's user + user
      fields

diff --git a/src/sentry/api/event_search.py b/src/sentry/api/event_search.py
index 26f4c1c5be..d0f00b848e 100644
--- a/src/sentry/api/event_search.py
+++ b/src/sentry/api/event_search.py
@@ -1384,7 +1384,7 @@ def resolve_field_list(fields, snuba_filter, auto_fields=True):
             continue
         column_additions, agg_additions = resolve_field(field, snuba_filter.date_params)
         if column_additions:
-            columns.extend(column_additions)
+            columns.extend([column for column in column_additions if column not in columns])
 
         if agg_additions:
             aggregations.extend(agg_additions)
diff --git a/src/sentry/snuba/discover.py b/src/sentry/snuba/discover.py
index 472db602c2..90ce596391 100644
--- a/src/sentry/snuba/discover.py
+++ b/src/sentry/snuba/discover.py
@@ -831,6 +831,8 @@ def top_events_timeseries(
         timeseries_columns + selected_columns, user_query, params, rollup
     )
 
+    user_fields = FIELD_ALIASES["user"]["fields"]
+
     for field in selected_columns:
         # project is handled by filter_keys already
         if field in ["project", "project.id"]:
@@ -840,6 +842,11 @@ def top_events_timeseries(
             # timestamp needs special handling, creating a big OR instead
             if field == "timestamp":
                 snuba_filter.conditions.append([["timestamp", "=", value] for value in values])
+            # A user field can be any of its field aliases, do an OR across all the user fields
+            elif field == "user":
+                snuba_filter.conditions.append(
+                    [[resolve_column(user_field), "IN", values] for user_field in user_fields]
+                )
             else:
                 snuba_filter.conditions.append([resolve_column(field), "IN", values])
 
@@ -857,7 +864,17 @@ def top_events_timeseries(
         referrer=referrer,
     )
 
-    result = transform_results(result, translated_columns, snuba_filter)
+    result = transform_results(result, translated_columns, snuba_filter, selected_columns)
+
+    translated_columns["project_id"] = "project"
+    translated_groupby = [translated_columns.get(field, field) for field in snuba_filter.groupby]
+
+    if "user" in selected_columns:
+        # Determine user related fields to prune based on what wasn't selected, since transform_results does the same
+        for field in user_fields:
+            if field not in selected_columns:
+                translated_groupby.remove(field)
+        translated_groupby.append("user")
     issues = {}
     if "issue" in selected_columns:
         issues = Group.issues_mapping(
@@ -865,9 +882,6 @@ def top_events_timeseries(
             params["project_id"],
             organization,
         )
-
-    translated_columns["project_id"] = "project"
-    translated_groupby = [translated_columns.get(field, field) for field in snuba_filter.groupby]
     # so the result key is consistent
     translated_groupby.sort()
 
diff --git a/tests/snuba/api/endpoints/test_organization_events_stats.py b/tests/snuba/api/endpoints/test_organization_events_stats.py
index 1accb641b8..db3babbdad 100644
--- a/tests/snuba/api/endpoints/test_organization_events_stats.py
+++ b/tests/snuba/api/endpoints/test_organization_events_stats.py
@@ -1040,3 +1040,61 @@ class OrganizationEventsStatsTopNEvents(APITestCase, SnubaTestCase):
             [{"count": 3}],
             [{"count": 0}],
         ]
+
+    def test_top_events_with_user(self):
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(hours=1, minutes=59)),
+                    "interval": "1h",
+                    "yAxis": "count()",
+                    "orderby": ["-count()"],
+                    "field": ["user", "count()"],
+                    "topEvents": 5,
+                },
+                format="json",
+            )
+
+        data = response.data
+        assert response.status_code == 200, response.content
+        assert len(data) == 5
+
+        assert [attrs for time, attrs in data["bar@example.com"]["data"]] == [
+            [{"count": 6}],
+            [{"count": 0}],
+        ]
+        assert [attrs for time, attrs in data["127.0.0.1"]["data"]] == [
+            [{"count": 3}],
+            [{"count": 0}],
+        ]
+
+    def test_top_events_with_user_and_email(self):
+        with self.feature("organizations:discover-basic"):
+            response = self.client.get(
+                self.url,
+                data={
+                    "start": iso_format(self.day_ago),
+                    "end": iso_format(self.day_ago + timedelta(hours=1, minutes=59)),
+                    "interval": "1h",
+                    "yAxis": "count()",
+                    "orderby": ["-count()"],
+                    "field": ["user", "user.email", "count()"],
+                    "topEvents": 5,
+                },
+                format="json",
+            )
+
+        data = response.data
+        assert response.status_code == 200, response.content
+        assert len(data) == 5
+
+        assert [attrs for time, attrs in data["bar@example.com,bar@example.com"]["data"]] == [
+            [{"count": 6}],
+            [{"count": 0}],
+        ]
+        assert [attrs for time, attrs in data["127.0.0.1,None"]["data"]] == [
+            [{"count": 3}],
+            [{"count": 0}],
+        ]
