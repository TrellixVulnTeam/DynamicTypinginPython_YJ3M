commit d2b25138cef68f45bca90b5f61094f04856defec
Author: David Cramer <dcramer@gmail.com>
Date:   Tue Feb 12 16:32:24 2013 -0800

    Track events by group and remove excess fat

diff --git a/src/sentry/counter/base.py b/src/sentry/counter/base.py
index ddd9d34bcf..13e0be7e85 100644
--- a/src/sentry/counter/base.py
+++ b/src/sentry/counter/base.py
@@ -15,11 +15,11 @@ class Counter(object):
     Specifically, they store the following:
 
     - events per project
+    - events per group (aggregate)
 
     Each grouping tracks the following:
 
     - # of total events
-    - # of unique events
 
     Each counter stores counts at minute-level intervals for 15 minutes.
     """
diff --git a/src/sentry/counter/redis.py b/src/sentry/counter/redis.py
index 414bfcdf97..244620112a 100644
--- a/src/sentry/counter/redis.py
+++ b/src/sentry/counter/redis.py
@@ -31,58 +31,36 @@ class RedisCounter(Counter):
             'hosts': options['hosts'],
         })
 
-    def _make_key(self, prefix, when=None, is_new=False):
+    def _make_key(self, prefix, when=None):
         """
         Returns a Redis-compatible key for the given key/value combination.
         """
         if when is None:
             when = time.time()
         when = int(when / 60)  # chop it down to the minute
-        return 'sentry.counter:%s:%s:%s' % (prefix, when, int(is_new))
+        return 'sentry.counter:%s:%s' % (prefix, when)
 
-    def incr(self, group, is_new=False):
+    def incr(self, group):
         now = time.time()
         with self.conn.map() as conn:
-            keys = [self._make_key('project', now)]
-            if is_new:
-                keys.append(self._make_key('project', now, True))
+            keys = [(self._make_key('project', now), group.project_id)]
+            keys = [(self._make_key('group', now), group.id)]
 
-            for key in keys:
-                conn.zincrby(key, group.project_id)
+            for key, member in keys:
+                conn.zincrby(key, member)
                 conn.expire(key, 60 * self.MINUTES)
 
-    def extract_counts(self, prefix='project'):
-        now = time.time() - 60
+    def extract_counts(self, when=None, prefix='project'):
+        # TODO: this could become expensive as it scales linearly with the number of unique
+        # items to check
+        if not when:
+            when = time.time() - 60
         with self.conn.map() as conn:
-            key = self._make_key(prefix, now)
-            total = conn.zrange(key)
-            conn.delete(key)
-
-            key = self._make_key(prefix, now, True)
-            new = conn.zrange(key)
+            key = self._make_key(prefix, when)
+            results = conn.zrange(key)
             conn.delete(key)
 
         return {
-            'time': now,
-            'total': total,
-            'new': new,
+            'when': when,
+            'results': results,
         }
-
-    def _get_count(self, project, minutes=None, is_new=False):
-        if minutes is None:
-            minutes = self.MINUTES
-
-        now = time.time()
-        results = []
-        with self.conn.map() as conn:
-            for minute in xrange(minutes):
-                redis_key = self._make_key('project', now - (minute * 60), is_new)
-                results.append(conn.zscore(redis_key, project.id))
-
-        return sum(int(r or 0) for r in results)
-
-    def total(self, project, minutes=None):
-        return self._get_count(project, minutes=minutes, is_new=False)
-
-    def new(self, project, minutes=None):
-        return self._get_count(project, minutes=minutes, is_new=True)
diff --git a/src/sentry/manager.py b/src/sentry/manager.py
index bdae273e6d..3c9d52d9a4 100644
--- a/src/sentry/manager.py
+++ b/src/sentry/manager.py
@@ -605,18 +605,12 @@ class GroupManager(BaseManager, ChartMixin):
         # It's important that we increment short-counters without using the queue otherwise they could
         # quickly become inaccurate
         try:
-            self.incr_counters(group, is_new)
+            app.counter.incr(group=group)
         except Exception, e:
             logger.exception('Unable to increment counters: %s' % (e,))
 
         return group, is_new, is_sample
 
-    def incr_counters(self, group, is_new):
-        app.counter.incr(
-            group=group,
-            is_new=is_new,
-        )
-
     def record_affected_user(self, group, user_ident, data=None):
         from sentry.models import TrackedUser, AffectedUserByGroup
 
diff --git a/src/sentry/tasks/check_alerts.py b/src/sentry/tasks/check_alerts.py
index f94e89fc4c..de7e6910e3 100644
--- a/src/sentry/tasks/check_alerts.py
+++ b/src/sentry/tasks/check_alerts.py
@@ -33,6 +33,7 @@ Alert expiration threshold MUST be > MINUTE_NORMALIZATION.
 """
 from __future__ import division
 
+import time
 from datetime import timedelta
 from celery.task import periodic_task, task
 from celery.task.schedules import crontab
@@ -49,21 +50,27 @@ def fsteps(start, stop, steps):
 @periodic_task(ignore_result=True, run_every=crontab(minute='*'))
 def check_alerts(**kwargs):
     """
-    Iterates all current keys and checks if fires additional tasks
-    to check each individual project's alert settings.
+    Iterates all current keys and fires additional tasks to check each individual
+    project's alert settings.
     """
     from sentry import app
     from sentry.utils.queue import maybe_delay
 
-    count_results = app.counter.extract_counts(prefix='project')
-    when = timezone.fromtimestamp(count_results.pop('time'))
-    for name, results in count_results.iteritems():
-        for project_id, count in results.iteritems():
-            maybe_delay(check_project_alerts, name=name, project_id=project_id, when=when, count=count, expires=120)
+    when = time.time() - 60
+    datetime = timezone.fromtimestamp(when)
+
+    results = app.counter.extract_counts(prefix='project', when=when)['results']
+    for project_id, count in results.iteritems():
+        maybe_delay(check_project_alerts,
+            project_id=project_id,
+            when=datetime,
+            count=count,
+            expires=120,
+        )
 
 
 @task(ignore_result=True)
-def check_project_alerts(project_id, name, when, count, **kwargs):
+def check_project_alerts(project_id, when, count, **kwargs):
     """
     Given 'when' and 'count', which should signify recent times we compare it to historical data for this project
     and if over a given threshold, create an alert.
diff --git a/tests/sentry/counter/redis/tests.py b/tests/sentry/counter/redis/tests.py
index c8572f99c7..e4cbe04f2b 100644
--- a/tests/sentry/counter/redis/tests.py
+++ b/tests/sentry/counter/redis/tests.py
@@ -27,15 +27,14 @@ class RedisCounterTest(TestCase):
         time = time.time
 
         time.return_value = 1360644295.816033
-        assert self.counter._make_key('project', is_new=False) == 'sentry.counter:project:22677404:0'
+        assert self.counter._make_key('project') == 'sentry.counter:project:22677404'
         time.assert_called_once_with()
 
         now = 1360654295.816033
-        assert self.counter._make_key('team', now, is_new=True) == 'sentry.counter:team:22677571:1'
+        assert self.counter._make_key('team', now) == 'sentry.counter:team:22677571'
 
     def test_all_the_things(self):
-        self.counter.incr(self.group, is_new=False)
-        self.counter.incr(self.group, is_new=False)
-        self.counter.incr(self.group, is_new=True)
-        assert self.counter.total(self.project) == 3
-        assert self.counter.new(self.project) == 1
+        # TODO
+        self.counter.incr(self.group)
+        self.counter.incr(self.group)
+        self.counter.incr(self.group)
diff --git a/tests/sentry/manager/tests.py b/tests/sentry/manager/tests.py
index 439e28c74b..61bc5d3ceb 100644
--- a/tests/sentry/manager/tests.py
+++ b/tests/sentry/manager/tests.py
@@ -247,28 +247,19 @@ class SentryManagerTest(TestCase):
         self.assertEquals(res.times_seen, 1)
 
     @mock.patch('sentry.manager.send_group_processors', mock.Mock())
-    @mock.patch('sentry.manager.GroupManager.incr_counters')
-    def test_calls_incr_counters(self, incr_counters):
+    @mock.patch('sentry.manager.app.counter.incr')
+    def test_calls_incr_counters(self, incr):
         event = Group.objects.from_kwargs(1, message='foo', tags=[('foo', 'bar')])
         group = event.group
-        incr_counters.assert_called_once_with(group, True)
+        incr.assert_called_once_with(group=group)
 
     @mock.patch('sentry.manager.send_group_processors', mock.Mock())
-    @mock.patch('sentry.manager.GroupManager.incr_counters')
-    def test_handles_incr_counters_failure(self, incr_counters):
-        incr_counters.side_effect = Exception()
+    @mock.patch('sentry.manager.app.counter.incr')
+    def test_handles_incr_counters_failure(self, incr):
+        incr.side_effect = Exception()
         event = Group.objects.from_kwargs(1, message='foo')
         group = event.group
-        incr_counters.assert_called_once_with(group, True)
-
-    @mock.patch('sentry.manager.app.counter.incr')
-    def test_incr_counters_calls_buffer(self, incr):
-        is_new = mock.Mock()
-        Group.objects.incr_counters(self.group, is_new=is_new)
-        incr.assert_called_once_with(
-            group=self.group,
-            is_new=is_new,
-        )
+        incr.assert_called_once_with(group=group)
 
 
 class SearchManagerTest(TestCase):
