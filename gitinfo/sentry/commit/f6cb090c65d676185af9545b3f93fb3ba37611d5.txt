commit f6cb090c65d676185af9545b3f93fb3ba37611d5
Author: ted kaemming <ted@kaemming.com>
Date:   Mon Jun 5 15:41:29 2017 -0700

    Update aggregate fields for source group during unmerge. (#5512)
    
    This also repairs the [initial and backfill fields](https://github.com/getsentry/sentry/blob/92bb1058a0a9f5451cf509912e9966b491fff3a9/src/sentry/tasks/unmerge.py#L75-L112) for the source group during unmerging. (Previously, this only was used to update field values on the destination group.) This ensures that fields like `times_seen`, `score`, `first_seen`, etc. are derived from only the events that remain in the source group after the operation is completed.

diff --git a/src/sentry/tasks/unmerge.py b/src/sentry/tasks/unmerge.py
index 0678672679..9be671c202 100644
--- a/src/sentry/tasks/unmerge.py
+++ b/src/sentry/tasks/unmerge.py
@@ -492,8 +492,8 @@ def update_tag_value_counts(id_list):
 
 
 @instrumented_task(name='sentry.tasks.unmerge', queue='unmerge')
-def unmerge(project_id, source_id, destination_id, fingerprints, actor_id, cursor=None, batch_size=500):
-    from sentry.models import Event
+def unmerge(project_id, source_id, destination_id, fingerprints, actor_id, cursor=None, batch_size=500, source_fields_reset=False):
+    from sentry.models import Event, Group
 
     # XXX: If a ``GroupHash`` is unmerged *again* while this operation is
     # already in progress, some events from the fingerprint associated with the
@@ -517,9 +517,10 @@ def unmerge(project_id, source_id, destination_id, fingerprints, actor_id, curso
 
     project = caches['Project'](project_id)
 
-    # TODO: It might make sense to fetch the source group to assert that it is
-    # contained within the project, even though we don't actually directy use
-    # it anywhere.
+    source = Group.objects.get(
+        project_id=project_id,
+        id=source_id,
+    )
 
     # We fetch the events in descending order by their primary key to get the
     # best approximation of the most recently received events.
@@ -540,16 +541,37 @@ def unmerge(project_id, source_id, destination_id, fingerprints, actor_id, curso
 
     Event.objects.bind_nodes(events, 'data')
 
+    source_events = []
+    destination_events = []
+
+    for event in events:
+        (destination_events if get_fingerprint(event) in fingerprints else source_events).append(event)
+
+    if source_events:
+        if not source_fields_reset:
+            source.update(
+                **get_group_creation_attributes(
+                    caches,
+                    source_events,
+                )
+            )
+            source_fields_reset = True
+        else:
+            source.update(
+                **get_group_backfill_attributes(
+                    caches,
+                    source,
+                    source_events,
+                )
+            )
+
     destination_id = migrate_events(
         caches,
         project,
         source_id,
         destination_id,
         fingerprints,
-        filter(
-            lambda event: get_fingerprint(event) in fingerprints,
-            events,
-        ),
+        destination_events,
         actor_id,
     )
 
@@ -567,4 +589,5 @@ def unmerge(project_id, source_id, destination_id, fingerprints, actor_id, curso
         actor_id,
         cursor=events[-1].id,
         batch_size=batch_size,
+        source_fields_reset=source_fields_reset,
     )
diff --git a/tests/sentry/tasks/test_unmerge.py b/tests/sentry/tasks/test_unmerge.py
index 5574bb3887..e52d1d9344 100644
--- a/tests/sentry/tasks/test_unmerge.py
+++ b/tests/sentry/tasks/test_unmerge.py
@@ -286,6 +286,18 @@ class UnmergeTestCase(TestCase):
                 batch_size=5,
             )
 
+        assert list(
+            Group.objects.filter(id=source.id).values_list(
+                'times_seen',
+                'first_seen',
+                'last_seen',
+            )
+        ) == [(
+            10,
+            now + shift(0),
+            now + shift(9),
+        )]
+
         source_activity = Activity.objects.get(
             group_id=source.id,
             type=Activity.UNMERGE_SOURCE,
@@ -295,6 +307,18 @@ class UnmergeTestCase(TestCase):
             id=source_activity.data['destination_id'],
         )
 
+        assert list(
+            Group.objects.filter(id=destination.id).values_list(
+                'times_seen',
+                'first_seen',
+                'last_seen',
+            )
+        ) == [(
+            7,
+            now + shift(10),
+            now + shift(16),
+        )]
+
         assert source_activity.data == {
             'destination_id': destination.id,
             'fingerprints': [events.keys()[1]],
