commit b4a1f73873c42409ea6463be23ed814a4266efe6
Author: Alex Hofsteede <alex@hofsteede.com>
Date:   Fri Apr 13 10:45:07 2018 -0700

    feat(snuba): Tagstore backend (#7891)
    
    A tagstore backend that uses the Snuba service to to queries for
    tags,values,users,releases etc.  All read methods are implemented, and should return
    reasonable results. In cases where the tagstore API returns Django Model objects, the
    Snuba backend will return plain python objects with the same set of attributes. Methods
    that create TagKey, TagValue objects are effectively no-ops.
    
    This backend is currently suitable for side-by-side comparison of individual read methods
    with the existing live tagstore, but is not yet suitable to wholesale replace the existing
    backend until all the call sites for tagstore methods have been checked for compatibility,
    and the interface refactored as needed. (eg. removal of methods returning QuerySets)

diff --git a/src/sentry/tagstore/models.py b/src/sentry/tagstore/models.py
index 860d574d1c..5b24e705ad 100644
--- a/src/sentry/tagstore/models.py
+++ b/src/sentry/tagstore/models.py
@@ -26,5 +26,8 @@ elif settings.SENTRY_TAGSTORE.startswith('sentry.tagstore.multi'):
             from sentry.tagstore.legacy.models import *  # NOQA
         elif backend[0].startswith('sentry.tagstore.v2'):
             from sentry.tagstore.v2 import models as _v2_models  # NOQA
+elif settings.SENTRY_TAGSTORE.startswith('sentry.tagstore.snuba'):
+    # TODO this shouldn't really be required but some tests depend on importing them
+    from sentry.tagstore.v2.models import *  # NOQA
 else:
     raise ImproperlyConfigured("Found unknown tagstore backend '%s'" % settings.SENTRY_TAGSTORE)
diff --git a/src/sentry/tagstore/snuba/backend.py b/src/sentry/tagstore/snuba/backend.py
index 2a84090917..fec3ca8a13 100644
--- a/src/sentry/tagstore/snuba/backend.py
+++ b/src/sentry/tagstore/snuba/backend.py
@@ -8,77 +8,390 @@ sentry.tagstore.snuba.backend
 
 from __future__ import absolute_import
 
-from datetime import datetime, timedelta
-import pytz
+from collections import defaultdict
+from datetime import timedelta
+from django.utils import timezone
 import six
 
+from sentry.api.serializers import Serializer, register
 from sentry.tagstore import TagKeyStatus
 from sentry.tagstore.base import TagStorage
+from sentry.tagstore.exceptions import (
+    GroupTagKeyNotFound,
+    GroupTagValueNotFound,
+    TagKeyNotFound,
+    TagValueNotFound,
+)
 from sentry.utils import snuba
 
+SEEN_COLUMN = 'timestamp'
+
+
+class ObjectWrapper(object):
+    def __init__(self, dictionary):
+        dictionary['id'] = 0
+        self.__dict__ = dictionary
+
+
+@register(ObjectWrapper)
+class ObjectWrapperSerializer(Serializer):
+    def serialize(self, obj, attrs, user):
+        return self.__dict__
+
 
 class SnubaTagStorage(TagStorage):
 
-    # Tag keys and values
+    def get_time_range(self, days=90):
+        """
+        Returns the default (start, end) time range for querrying snuba.
+        """
+        # TODO this should use the per-project retention figure to limit
+        # the query to looking at only the retention window for the project.
+        end = timezone.now()
+        return (end - timedelta(days=days), end)
+
     def get_tag_key(self, project_id, environment_id, key, status=TagKeyStatus.VISIBLE):
-        pass
+        try:
+            return self.get_group_tag_key(project_id, None, environment_id, key)
+        except GroupTagKeyNotFound:
+            raise TagKeyNotFound
 
     def get_tag_keys(self, project_id, environment_id, status=TagKeyStatus.VISIBLE):
-        pass
+        return self.get_group_tag_keys(project_id, None, environment_id)
 
     def get_tag_value(self, project_id, environment_id, key, value):
-        pass
+        try:
+            return self.get_group_tag_value(project_id, None, environment_id, key, value)
+        except GroupTagValueNotFound:
+            raise TagValueNotFound
 
     def get_tag_values(self, project_id, environment_id, key):
-        pass
+        return self.get_group_tag_values(project_id, None, environment_id, key)
 
     def get_group_tag_key(self, project_id, group_id, environment_id, key):
-        pass
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+        }
+        if group_id is not None:
+            filters['issue'] = [group_id]
+        conditions = [[tag, '!=', '']]
+        aggregations = [['count', '', 'count']]
 
-    def get_group_tag_keys(self, project_id, group_id, environment_id, limit=None):
-        pass
+        result = snuba.query(start, end, [], conditions, filters, aggregations)
+        if result == 0:
+            raise GroupTagKeyNotFound
+        else:
+            return ObjectWrapper({
+                'times_seen': result,
+                'key': key,
+                'group_id': group_id,
+            })
+
+    def get_group_tag_keys(self, project_id, group_id, environment_id, limit=1000):
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+        }
+        if group_id is not None:
+            filters['issue'] = [group_id]
+        aggregations = [['count', '', 'count']]
+
+        result = snuba.query(start, end, ['tags.key'], [], filters, aggregations,
+                             limit=limit, orderby='-count', arrayjoin='tags')
+
+        return [ObjectWrapper({
+            'times_seen': count,
+            'key': name,
+            'group_id': group_id,
+        }) for name, count in six.iteritems(result)]
 
     def get_group_tag_value(self, project_id, group_id, environment_id, key, value):
-        pass
+        from sentry.tagstore.exceptions import GroupTagValueNotFound
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+        }
+        if group_id is not None:
+            filters['issue'] = [group_id]
+        conditions = [
+            [tag, '=', value]
+        ]
+        aggregations = [['count', '', 'count']]
+
+        result = snuba.query(start, end, [], conditions, filters, aggregations)
+
+        if result == 0:
+            raise GroupTagValueNotFound
+        else:
+            return ObjectWrapper({
+                'times_seen': result,
+                'key': key,
+                'value': value,
+                'group_id': group_id,
+            })
 
     def get_group_tag_values(self, project_id, group_id, environment_id, key):
-        pass
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+        }
+        if group_id is not None:
+            filters['issue'] = [group_id]
+        conditions = [[tag, '!=', '']]
+        aggregations = [
+            ['count', '', 'count'],
+            ['min', SEEN_COLUMN, 'first_seen'],
+            ['max', SEEN_COLUMN, 'last_seen'],
+        ]
 
-    def get_group_list_tag_value(self, project_id, group_id_list, environment_id, key, value):
-        pass
+        result = snuba.query(start, end, [tag], conditions, filters,
+                             aggregations)
+
+        return [ObjectWrapper({
+            'times_seen': val['count'],
+            'first_seen': val['first_seen'],
+            'last_seen': val['last_seen'],
+            'key': key,
+            'value': name,
+            'group_id': group_id,
+        }) for name, val in six.iteritems(result)]
+
+    def get_group_list_tag_value(self, project_id, group_ids, environment_id, key, value):
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+            'issue': group_ids,
+        }
+        conditions = [
+            [tag, '=', value]
+        ]
+        aggregations = [
+            ['count', '', 'count'],
+            ['min', SEEN_COLUMN, 'first_seen'],
+            ['max', SEEN_COLUMN, 'last_seen'],
+        ]
+
+        result = snuba.query(start, end, ['issue'], conditions, filters, aggregations)
+
+        return {
+            issue: ObjectWrapper({
+                'times_seen': val['count'],
+                'first_seen': val['first_seen'],
+                'last_seen': val['last_seen'],
+                'key': key,
+                'value': value,
+                'group_id': issue,
+            }) for issue, val in six.iteritems(result)}
 
     def get_group_tag_value_count(self, project_id, group_id, environment_id, key):
-        pass
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+            'issue': [group_id],
+        }
+        conditions = [[tag, '!=', '']]
+        aggregations = [['count', '', 'count']]
 
-    def get_group_tag_values_for_users(self, event_users, limit=100):
-        pass
+        return snuba.query(start, end, [], conditions, filters, aggregations)
 
     def get_top_group_tag_values(self, project_id, group_id, environment_id, key, limit=3):
-        pass
+        start, end = self.get_time_range()
+        tag = 'tags[{}]'.format(key)
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+            'issue': [group_id],
+        }
+        conditions = [[tag, '!=', '']]
+        aggregations = [
+            ['count', '', 'count'],
+            ['min', SEEN_COLUMN, 'first_seen'],
+            ['max', SEEN_COLUMN, 'last_seen'],
+        ]
+
+        result = snuba.query(start, end, [tag], conditions, filters,
+                             aggregations, limit=limit, orderby='-count')
+
+        return [ObjectWrapper({
+            'times_seen': val['count'],
+            'first_seen': val['first_seen'],
+            'last_seen': val['last_seen'],
+            'key': key,
+            'value': name,
+            'group_id': group_id,
+        }) for name, val in six.iteritems(result)]
+
+    def get_group_tag_keys_and_top_values(self, project_id, group_id, environment_id, user=None):
+        from sentry import tagstore
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+            'issue': [group_id],
+        }
+        aggregations = [
+            ['topK(10)', 'tags.value', 'top'],
+            ['count', '', 'count'],
+            ['uniq', 'tags.key', 'uniq'],
+        ]
+        results = snuba.query(start, end, ['tags.key'], None, filters,
+                              aggregations, arrayjoin='tags')
+
+        return [{
+            'id': key,
+            'name': tagstore.get_tag_key_label(key),
+            'key': tagstore.get_standardized_key(key),
+            'uniqueValues': res['uniq'],
+            'totalValues': res['count'],
+            'topValues': [{
+                'id': val,
+                'name': tagstore.get_tag_value_label(key, val),
+                'key': tagstore.get_standardized_key(key),
+                'value': val,
+            } for val in res['top']],
+        } for key, res in six.iteritems(results)]
+
+    def get_release(self, project_id, group_id, first=True):
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': [project_id],
+        }
+        conditions = [['release', 'IS NOT NULL', None]]
+        if group_id is not None:
+            filters['issue'] = [group_id]
+        aggregations = [['min' if first else 'max', SEEN_COLUMN, 'seen']]
+        orderby = 'seen' if first else '-seen'
+
+        result = snuba.query(start, end, ['release'], conditions, filters,
+                             aggregations, limit=1, orderby=orderby)
+        if not result:
+            return None
+        else:
+            return result.keys()[0]
 
-    # Releases
     def get_first_release(self, project_id, group_id):
-        pass
+        return self.get_release(project_id, group_id, True)
 
     def get_last_release(self, project_id, group_id):
-        pass
+        return self.get_release(project_id, group_id, False)
 
     def get_release_tags(self, project_ids, environment_id, versions):
-        pass
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': project_ids,
+            'environment': [environment_id],
+        }
+        # NB we add release as a condition rather than a filter because
+        # this method is already dealing with version strings rather than
+        # release ids which would need to be translated by the snuba util.
+        conditions = [['release', 'IN', versions]]
+        aggregations = [
+            ['count', '', 'count'],
+            ['min', SEEN_COLUMN, 'first_seen'],
+            ['max', SEEN_COLUMN, 'last_seen'],
+        ]
+
+        result = snuba.query(start, end, ['release'], conditions, filters, aggregations)
+
+        return [ObjectWrapper({
+            'times_seen': val['count'],
+            'first_seen': val['first_seen'],
+            'last_seen': val['last_seen'],
+            'key': 'release',
+            'value': name,
+        }) for name, val in six.iteritems(result)]
 
     def get_group_event_ids(self, project_id, group_id, environment_id, tags):
-        pass
+        start, end = self.get_time_range()
+        filters = {
+            'environment': [environment_id],
+            'project_id': [project_id],
+        }
+        # TODO implement environment_id exclusion, its a little bit more complex
+        # than adding a != condition because environment_ids need to be translated
+        # to filters in snuba.
+
+        or_conditions = [['tags[{}]'.format(tag), '=', val] for tag, val in six.iteritems(tags)]
+        conditions = [or_conditions]
+
+        events = snuba.query(start, end, ['event_id'], conditions, filters)
+        return events.keys()
 
     def get_group_ids_for_users(self, project_ids, event_users, limit=100):
-        pass
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': project_ids,
+        }
+        or_conditions = [cond for cond in [
+            ('user_id', 'IN', [eu.ident for eu in event_users if eu.ident]),
+            ('email', 'IN', [eu.email for eu in event_users if eu.email]),
+            ('username', 'IN', [eu.username for eu in event_users if eu.username]),
+            ('ip_address', 'IN', [eu.ip_address for eu in event_users if eu.ip_address]),
+        ] if cond[2] != []]
+        conditions = [or_conditions]
+        aggregations = [['max', SEEN_COLUMN, 'seen']]
+
+        result = snuba.query(start, end, ['issue'], conditions, filters,
+                             aggregations, limit=limit, orderby='-seen')
+        return result.keys()
+
+    def get_group_tag_values_for_users(self, event_users, limit=100):
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': [eu.project_id for eu in event_users]
+        }
+        or_conditions = [cond for cond in [
+            ('user_id', 'IN', [eu.ident for eu in event_users if eu.ident]),
+            ('email', 'IN', [eu.email for eu in event_users if eu.email]),
+            ('username', 'IN', [eu.username for eu in event_users if eu.username]),
+            ('ip_address', 'IN', [eu.ip_address for eu in event_users if eu.ip_address]),
+        ] if cond[2] != []]
+        conditions = [or_conditions]
+        aggregations = [
+            ['count', '', 'count'],
+            ['min', SEEN_COLUMN, 'first_seen'],
+            ['max', SEEN_COLUMN, 'last_seen'],
+        ]
+
+        result = snuba.query(start, end, ['user_id'], conditions, filters,
+                             aggregations, orderby='-last_seen', limit=limit)
+
+        return [ObjectWrapper({
+            'times_seen': val['count'],
+            'first_seen': val['first_seen'],
+            'last_seen': val['last_seen'],
+            'key': 'sentry:user',
+            'value': name,
+        }) for name, val in six.iteritems(result)]
 
     def get_groups_user_counts(self, project_id, group_ids, environment_id):
-        pass
+        start, end = self.get_time_range()
+        filters = {
+            'project_id': [project_id],
+            'environment': [environment_id],
+            'issue': group_ids,
+        }
+        aggregations = [['uniq', 'user_id', 'count']]
+
+        result = snuba.query(start, end, ['issue'], None, filters, aggregations)
+        return defaultdict(int, result.items())
 
     # Search
     def get_group_ids_for_search_filter(self, project_id, environment_id, tags):
         from sentry.search.base import ANY, EMPTY
-
+        start, end = self.get_time_range()
         # Any EMPTY value means there can be no results for this query so
         # return an empty list immediately.
         if any(val == EMPTY for _, val in six.iteritems(tags)):
@@ -97,12 +410,102 @@ class SnubaTagStorage(TagStorage):
             else:
                 conditions.append((col, '=', val))
 
-        end = datetime.utcnow().replace(tzinfo=pytz.UTC)
-        start = end - timedelta(days=90)
         issues = snuba.query(start, end, ['issue'], conditions, filters)
-
-        # convert
-        #    {issue1: count, ...}
-        # into
-        #    [issue1, ...]
         return issues.keys()
+
+    # Everything from here down is basically no-ops
+    def create_tag_key(self, project_id, environment_id, key, **kwargs):
+        return ObjectWrapper({
+            'times_seen': 0,
+            'key': key,
+            'update': lambda *args, **kwargs: None
+        })
+
+    def get_or_create_tag_key(self, project_id, environment_id, key, **kwargs):
+        try:
+            return self.get_tag_key(project_id, environment_id, key)
+        except TagKeyNotFound:
+            return (self.create_tag_key(project_id, environment_id, key, **kwargs), True)
+
+    def create_tag_value(self, project_id, environment_id, key, value, **kwargs):
+        return ObjectWrapper({
+            'times_seen': 0,
+            'key': key,
+            'value': value,
+            'update': lambda *args, **kwargs: None
+        })
+
+    def get_or_create_tag_value(self, project_id, environment_id, key, value, **kwargs):
+        try:
+            return self.get_tag_value(project_id, environment_id, key, value)
+        except TagValueNotFound:
+            return (self.create_tag_value(project_id, environment_id, key, value, **kwargs), True)
+
+    def create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
+        return ObjectWrapper({
+            'times_seen': 0,
+            'key': key,
+            'group_id': group_id,
+            'update': lambda *args, **kwargs: None
+        })
+
+    def get_or_create_group_tag_key(self, project_id, group_id, environment_id, key, **kwargs):
+        try:
+            return self.get_group_tag_key(project_id, group_id, environment_id, key)
+        except GroupTagKeyNotFound:
+            return (self.create_group_tag_key(
+                project_id, group_id, environment_id, key, **kwargs), True)
+
+    def create_group_tag_value(self, project_id, group_id, environment_id,
+                               key, value, **kwargs):
+        return ObjectWrapper({
+            'times_seen': 0,
+            'key': key,
+            'value': value,
+            'group_id': group_id,
+            'update': lambda *args, **kwargs: None
+        })
+
+    def get_or_create_group_tag_value(self, project_id, group_id,
+                                      environment_id, key, value, **kwargs):
+        try:
+            return self.get_group_tag_value(project_id, group_id, environment_id, key, value)
+        except GroupTagValueNotFound:
+            return (self.create_group_tag_value(project_id, group_id,
+                                                environment_id, key, value, **kwargs), True)
+
+    def create_event_tags(self, project_id, group_id, environment_id,
+                          event_id, tags, date_added=None):
+        pass
+
+    def delete_tag_key(self, project_id, key):
+        return []
+
+    def delete_all_group_tag_keys(self, project_id, group_id):
+        pass
+
+    def delete_all_group_tag_values(self, project_id, group_id):
+        pass
+
+    def incr_tag_value_times_seen(self, project_id, environment_id,
+                                  key, value, extra=None, count=1):
+        pass
+
+    def incr_group_tag_value_times_seen(self, project_id, group_id, environment_id,
+                                        key, value, extra=None, count=1):
+        pass
+
+    def update_group_for_events(self, project_id, event_ids, destination_id):
+        pass
+
+    def update_group_tag_key_values_seen(self, project_id, group_ids):
+        pass
+
+    def get_tag_value_qs(self, project_id, environment_id, key, query=None):
+        return None
+
+    def get_group_tag_value_qs(self, project_id, group_id, environment_id, key, value=None):
+        return None
+
+    def get_event_tag_qs(self, project_id, environment_id, key, value):
+        return None
diff --git a/src/sentry/utils/snuba.py b/src/sentry/utils/snuba.py
index 58e8e82ace..36a354a025 100644
--- a/src/sentry/utils/snuba.py
+++ b/src/sentry/utils/snuba.py
@@ -1,6 +1,7 @@
 from __future__ import absolute_import
 
 from dateutil.parser import parse as parse_datetime
+from itertools import chain
 import json
 import requests
 import six
@@ -13,7 +14,7 @@ SNUBA = os.environ.get('SNUBA', 'http://localhost:5000')
 
 
 def query(start, end, groupby, conditions=None, filter_keys=None,
-          aggregations=None, rollup=None, arrayjoin=None):
+          aggregations=None, rollup=None, arrayjoin=None, limit=None, orderby=None):
     """
     Sends a query to snuba.
 
@@ -44,9 +45,11 @@ def query(start, end, groupby, conditions=None, filter_keys=None,
                      for col, keys in six.iteritems(snuba_map)}
 
     for col, keys in six.iteritems(filter_keys):
+        keys = [k for k in keys if k is not None]
         if col in snuba_map:
-            keys = [snuba_map[col][k] for k in keys]
-        conditions.append((col, 'IN', keys))
+            keys = [snuba_map[col][k] for k in keys if k in snuba_map[col]]
+        if keys:
+            conditions.append((col, 'IN', keys))
 
     if 'project_id' in filter_keys:
         # If we are given a set of project ids, use those directly.
@@ -63,7 +66,10 @@ def query(start, end, groupby, conditions=None, filter_keys=None,
 
     # If the grouping, aggregation, or any of the conditions reference `issue`
     # we need to fetch the issue definitions (issue -> fingerprint hashes)
-    get_issues = 'issue' in groupby + [a[1] for a in aggregations] + [c[0] for c in conditions]
+    aggregate_cols = [a[1] for a in aggregations]
+    condition_cols = [c[0] for c in flat_conditions(conditions)]
+    all_cols = groupby + aggregate_cols + condition_cols
+    get_issues = 'issue' in all_cols
     issues = get_project_issues(project_ids, filter_keys.get('issue')) if get_issues else None
 
     url = '{0}/query'.format(SNUBA)
@@ -77,6 +83,8 @@ def query(start, end, groupby, conditions=None, filter_keys=None,
         'granularity': rollup,
         'issues': issues,
         'arrayjoin': arrayjoin,
+        'limit': limit,
+        'orderby': orderby,
     }) if v is not None}
 
     response = requests.post(url, data=json.dumps(request))
@@ -118,6 +126,14 @@ def nest_groups(data, groups, aggregate_cols):
             inter.setdefault(d[g], []).append(d)
         return {k: nest_groups(v, rest, aggregate_cols) for k, v in six.iteritems(inter)}
 
+
+def is_condition(cond_or_list):
+    return len(cond_or_list) == 3 and isinstance(cond_or_list[0], six.string_types)
+
+
+def flat_conditions(conditions):
+    return list(chain(*[[c] if is_condition(c) else c for c in conditions]))
+
 # The following are functions for resolving information from sentry models
 # about projects, environments, and issues (groups). Having this snuba
 # implementation have to know about these relationships is not ideal, and
diff --git a/tests/sentry/runner/commands/test_cleanup.py b/tests/sentry/runner/commands/test_cleanup.py
index 8beecaf93d..19638f93d2 100644
--- a/tests/sentry/runner/commands/test_cleanup.py
+++ b/tests/sentry/runner/commands/test_cleanup.py
@@ -24,6 +24,8 @@ class SentryCleanupTest(CliTestCase):
     elif settings.SENTRY_TAGSTORE.startswith('sentry.tagstore.multi'):
         fixtures += ['tests/fixtures/cleanup-tagstore-legacy.json',
                      'tests/fixtures/cleanup-tagstore-v2.json']
+    elif settings.SENTRY_TAGSTORE.startswith('sentry.tagstore.snuba'):
+        pass
     else:
         raise NotImplementedError
 
diff --git a/tests/sentry/tagstore/snuba/test_backend.py b/tests/sentry/tagstore/snuba/test_backend.py
deleted file mode 100644
index c4089c2389..0000000000
--- a/tests/sentry/tagstore/snuba/test_backend.py
+++ /dev/null
@@ -1,71 +0,0 @@
-from __future__ import absolute_import
-
-
-import json
-import responses
-
-from sentry.utils import snuba
-from sentry.models import GroupHash
-from sentry.testutils import TestCase
-from sentry.tagstore.snuba.backend import SnubaTagStorage
-
-
-class TagStorage(TestCase):
-    def setUp(self):
-        self.ts = SnubaTagStorage()
-
-        self.proj1 = self.create_project()
-
-        self.proj1env1 = self.create_environment(project=self.proj1, name='test')
-        self.proj1env2 = self.create_environment(project=self.proj1, name='prod')
-
-        self.proj1group1 = self.create_group(self.proj1)
-        self.proj1group2 = self.create_group(self.proj1)
-
-        GroupHash.objects.create(project=self.proj1, group=self.proj1group1, hash='1' * 32)
-        GroupHash.objects.create(project=self.proj1, group=self.proj1group2, hash='2' * 32)
-
-    @responses.activate
-    def test_get_group_ids_for_search_filter(self):
-        from sentry.search.base import ANY
-        tags = {
-            'foo': 'bar',
-            'baz': 'quux',
-        }
-
-        with responses.RequestsMock() as rsps:
-            def snuba_response(request):
-                body = json.loads(request.body)
-                assert body['project'] == [self.proj1.id]
-                assert body['groupby'] == ['issue']
-                assert body['issues']
-                assert ['tags[foo]', '=', 'bar'] in body['conditions']
-                assert ['tags[baz]', '=', 'quux'] in body['conditions']
-                return (200, {}, json.dumps({
-                    'meta': [{'name': 'issue'}, {'name': 'aggregate'}],
-                    'data': [{'issue': self.proj1group1.id, 'aggregate': 1}],
-                }))
-
-            rsps.add_callback(responses.POST, snuba.SNUBA + '/query', callback=snuba_response)
-            result = self.ts.get_group_ids_for_search_filter(self.proj1.id, self.proj1env1.id, tags)
-            assert result == [self.proj1group1.id]
-
-        tags = {
-            'foo': ANY,
-        }
-
-        with responses.RequestsMock() as rsps:
-            def snuba_response_2(request):
-                body = json.loads(request.body)
-                assert body['project'] == [self.proj1.id]
-                assert body['groupby'] == ['issue']
-                assert body['issues']
-                assert ['tags[foo]', 'IS NOT NULL', None] in body['conditions']
-                return (200, {}, json.dumps({
-                    'meta': [{'name': 'issue'}, {'name': 'aggregate'}],
-                    'data': [{'issue': self.proj1group2.id, 'aggregate': 1}],
-                }))
-
-            rsps.add_callback(responses.POST, snuba.SNUBA + '/query', callback=snuba_response_2)
-            result = self.ts.get_group_ids_for_search_filter(self.proj1.id, self.proj1env1.id, tags)
-            assert result == [self.proj1group2.id]
diff --git a/tests/snuba/tagstore/test_backend.py b/tests/snuba/tagstore/test_backend.py
new file mode 100644
index 0000000000..cd798bde56
--- /dev/null
+++ b/tests/snuba/tagstore/test_backend.py
@@ -0,0 +1,365 @@
+from __future__ import absolute_import
+
+
+import calendar
+from datetime import datetime, timedelta
+import json
+import pytest
+import requests
+import responses
+import six
+
+from sentry.utils import snuba
+from sentry.models import GroupHash, EventUser
+from sentry.testutils import TestCase
+from sentry.tagstore.exceptions import (
+    GroupTagKeyNotFound,
+    GroupTagValueNotFound,
+    TagKeyNotFound,
+    TagValueNotFound,
+)
+from sentry.tagstore.snuba.backend import SnubaTagStorage
+
+
+class TagStorage(TestCase):
+    def setUp(self):
+        assert requests.post(snuba.SNUBA + '/tests/drop').status_code == 200
+
+        self.ts = SnubaTagStorage()
+
+        self.proj1 = self.create_project()
+        self.proj1env1 = self.create_environment(project=self.proj1, name='test')
+
+        self.proj1group1 = self.create_group(self.proj1)
+        self.proj1group2 = self.create_group(self.proj1)
+
+        hash1 = '1' * 32
+        hash2 = '2' * 32
+        GroupHash.objects.create(project=self.proj1, group=self.proj1group1, hash=hash1)
+        GroupHash.objects.create(project=self.proj1, group=self.proj1group2, hash=hash2)
+
+        self.now = datetime.utcnow().replace(microsecond=0)
+        data = json.dumps([{
+            'event_id': six.text_type(r) * 32,
+            'primary_hash': hash1,
+            'project_id': self.proj1.id,
+            'message': 'message 1',
+            'platform': 'python',
+            'datetime': (self.now - timedelta(seconds=r)).strftime('%Y-%m-%dT%H:%M:%S.%fZ'),
+            'data': {
+                'received': calendar.timegm(self.now.timetuple()) - r,
+                'tags': {
+                    'foo': 'bar',
+                    'baz': 'quux',
+                    'environment': self.proj1env1.name,
+                    'sentry:release': 100 * r,
+                },
+                'sentry.interfaces.User': {
+                    'id': "user{}".format(r),
+                    'email': "user{}@sentry.io".format(r)
+                }
+            },
+        } for r in range(1, 3)] + [{
+            'event_id': '3' * 32,
+            'primary_hash': hash2,
+            'project_id': self.proj1.id,
+            'message': 'message 2',
+            'platform': 'python',
+            'datetime': (self.now - timedelta(seconds=r)).strftime('%Y-%m-%dT%H:%M:%S.%fZ'),
+            'data': {
+                'received': calendar.timegm(self.now.timetuple()) - r,
+                'tags': {
+                    'browser': 'chrome',
+                    'environment': self.proj1env1.name,
+                },
+                'sentry.interfaces.User': {
+                    'id': "user1"
+                }
+            },
+        }])
+
+        assert requests.post(snuba.SNUBA + '/tests/insert', data=data).status_code == 200
+
+    @responses.activate
+    def test_get_group_ids_for_search_filter(self):
+        from sentry.search.base import ANY
+        tags = {
+            'foo': 'bar',
+            'baz': 'quux',
+        }
+
+        with responses.RequestsMock() as rsps:
+            def snuba_response(request):
+                body = json.loads(request.body)
+                assert body['project'] == [self.proj1.id]
+                assert body['groupby'] == ['issue']
+                assert body['issues']
+                assert ['tags[foo]', '=', 'bar'] in body['conditions']
+                assert ['tags[baz]', '=', 'quux'] in body['conditions']
+                return (200, {}, json.dumps({
+                    'meta': [{'name': 'issue'}, {'name': 'aggregate'}],
+                    'data': [{'issue': self.proj1group1.id, 'aggregate': 1}],
+                }))
+
+            rsps.add_callback(responses.POST, snuba.SNUBA + '/query', callback=snuba_response)
+            result = self.ts.get_group_ids_for_search_filter(self.proj1.id, self.proj1env1.id, tags)
+            assert result == [self.proj1group1.id]
+
+        tags = {
+            'foo': ANY,
+        }
+
+        with responses.RequestsMock() as rsps:
+            def snuba_response_2(request):
+                body = json.loads(request.body)
+                assert body['project'] == [self.proj1.id]
+                assert body['groupby'] == ['issue']
+                assert body['issues']
+                assert ['tags[foo]', 'IS NOT NULL', None] in body['conditions']
+                return (200, {}, json.dumps({
+                    'meta': [{'name': 'issue'}, {'name': 'aggregate'}],
+                    'data': [{'issue': self.proj1group2.id, 'aggregate': 1}],
+                }))
+
+            rsps.add_callback(responses.POST, snuba.SNUBA + '/query', callback=snuba_response_2)
+            result = self.ts.get_group_ids_for_search_filter(self.proj1.id, self.proj1env1.id, tags)
+            assert result == [self.proj1group2.id]
+
+    def test_get_group_tag_keys_and_top_values(self):
+        result = self.ts.get_group_tag_keys_and_top_values(
+            self.proj1.id,
+            self.proj1group1.id,
+            self.proj1env1.id,
+        )
+        result.sort(key=lambda r: r['id'])
+        assert result[0]['key'] == 'baz'
+        assert result[1]['key'] == 'foo'
+
+        assert result[0]['uniqueValues'] == 1
+        assert result[0]['totalValues'] == 2
+
+        assert result[0]['topValues'][0]['value'] == 'quux'
+        assert result[1]['topValues'][0]['value'] == 'bar'
+
+    def test_get_top_group_tag_values(self):
+        resp = self.ts.get_top_group_tag_values(
+            self.proj1.id,
+            self.proj1group1.id,
+            self.proj1env1.id,
+            'foo',
+            1
+        )
+        assert len(resp) == 1
+        assert resp[0].times_seen == 2
+        assert resp[0].key == 'foo'
+        assert resp[0].value == 'bar'
+        assert resp[0].group_id == self.proj1group1.id
+
+    def test_get_group_tag_value_count(self):
+        assert self.ts.get_group_tag_value_count(
+            self.proj1.id,
+            self.proj1group1.id,
+            self.proj1env1.id,
+            'foo'
+        ) == 2
+
+    def test_get_group_tag_key(self):
+        with pytest.raises(GroupTagKeyNotFound):
+            self.ts.get_group_tag_key(
+                project_id=self.proj1.id,
+                group_id=self.proj1group1.id,
+                environment_id=self.proj1env1.id,
+                key='notreal',
+            )
+
+        assert self.ts.get_group_tag_key(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+            environment_id=self.proj1env1.id,
+            key='foo',
+        ).key == 'foo'
+
+        keys = self.ts.get_group_tag_keys(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+            environment_id=self.proj1env1.id,
+        )
+        keys.sort(key=lambda x: x.key)
+        assert len(keys) == 2
+        assert keys[0].key == 'baz'
+        assert keys[0].times_seen == 2
+        assert keys[1].key == 'foo'
+        assert keys[1].times_seen == 2
+
+    def test_get_group_tag_value(self):
+        with pytest.raises(GroupTagValueNotFound):
+            self.ts.get_group_tag_value(
+                project_id=self.proj1.id,
+                group_id=self.proj1group1.id,
+                environment_id=self.proj1env1.id,
+                key='foo',
+                value='notreal',
+            )
+
+        assert self.ts.get_group_tag_values(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+            environment_id=self.proj1env1.id,
+            key='notreal',
+        ) == []
+
+        assert self.ts.get_group_tag_values(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+            environment_id=self.proj1env1.id,
+            key='foo',
+        )[0].value == 'bar'
+
+        assert self.ts.get_group_tag_value(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+            environment_id=self.proj1env1.id,
+            key='foo',
+            value='bar',
+        ).value == 'bar'
+
+    def test_get_tag_key(self):
+        with pytest.raises(TagKeyNotFound):
+            self.ts.get_tag_key(
+                project_id=self.proj1.id,
+                environment_id=self.proj1env1.id,
+                key='notreal'
+            )
+
+    def test_get_tag_value(self):
+        with pytest.raises(TagValueNotFound):
+            self.ts.get_tag_value(
+                project_id=self.proj1.id,
+                environment_id=self.proj1env1.id,
+                key='foo',
+                value='notreal',
+            )
+
+    def test_get_groups_user_counts(self):
+        assert self.ts.get_groups_user_counts(
+            project_id=self.proj1.id,
+            group_ids=[self.proj1group1.id, self.proj1group2.id],
+            environment_id=self.proj1env1.id
+        ) == {
+            self.proj1group1.id: 2,
+            self.proj1group2.id: 1,
+        }
+
+    def test_get_releases(self):
+        assert self.ts.get_first_release(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+        ) == '200'
+
+        assert self.ts.get_first_release(
+            project_id=self.proj1.id,
+            group_id=self.proj1group2.id,
+        ) is None
+
+        assert self.ts.get_last_release(
+            project_id=self.proj1.id,
+            group_id=self.proj1group1.id,
+        ) == '100'
+
+        assert self.ts.get_last_release(
+            project_id=self.proj1.id,
+            group_id=self.proj1group2.id,
+        ) is None
+
+    def test_get_group_ids_for_users(self):
+        assert set(self.ts.get_group_ids_for_users(
+            [self.proj1.id],
+            [EventUser(project_id=self.proj1.id, ident='user1')]
+        )) == set([self.proj1group1.id, self.proj1group2.id])
+
+        assert set(self.ts.get_group_ids_for_users(
+            [self.proj1.id],
+            [EventUser(project_id=self.proj1.id, ident='user2')]
+        )) == set([self.proj1group1.id])
+
+    def test_get_group_tag_values_for_users(self):
+        result = self.ts.get_group_tag_values_for_users(
+            [EventUser(project_id=self.proj1.id, ident='user1')]
+        )
+        one_second_ago = (self.now - timedelta(seconds=1)).strftime('%Y-%m-%dT%H:%M:%S+00:00')
+        assert len(result) == 1
+        assert result[0].value == 'user1'
+        assert result[0].last_seen == one_second_ago
+
+        result = self.ts.get_group_tag_values_for_users(
+            [EventUser(project_id=self.proj1.id, ident='user2')]
+        )
+        two_seconds_ago = (self.now - timedelta(seconds=2)).strftime('%Y-%m-%dT%H:%M:%S+00:00')
+        assert len(result) == 1
+        assert result[0].value == 'user2'
+        assert result[0].last_seen == two_seconds_ago
+
+        # Test that users identified by different means are collected.
+        # (effectively tests OR conditions in snuba API)
+        result = self.ts.get_group_tag_values_for_users([
+            EventUser(project_id=self.proj1.id, email='user1@sentry.io'),
+            EventUser(project_id=self.proj1.id, ident='user2')
+        ])
+        two_seconds_ago = (self.now - timedelta(seconds=2)).strftime('%Y-%m-%dT%H:%M:%S+00:00')
+        assert len(result) == 2
+        result.sort(key=lambda x: x.value)
+        assert result[0].value == 'user1'
+        assert result[0].last_seen == one_second_ago
+        assert result[1].value == 'user2'
+        assert result[1].last_seen == two_seconds_ago
+
+    def test_get_release_tags(self):
+        tags = self.ts.get_release_tags(
+            [self.proj1.id],
+            None,
+            ['100']
+        )
+
+        assert len(tags) == 1
+        one_second_ago = (self.now - timedelta(seconds=1)).strftime('%Y-%m-%dT%H:%M:%S+00:00')
+        assert tags[0].last_seen == one_second_ago
+        assert tags[0].first_seen == one_second_ago
+        assert tags[0].times_seen == 1
+
+    def test_get_group_event_ids(self):
+        assert sorted(self.ts.get_group_event_ids(
+            self.proj1.id,
+            self.proj1group1.id,
+            self.proj1env1.id,
+            {
+                'foo': 'bar',
+            }
+        )) == ["1" * 32, "2" * 32]
+
+        assert sorted(self.ts.get_group_event_ids(
+            self.proj1.id,
+            self.proj1group1.id,
+            self.proj1env1.id,
+            {
+                'foo': 'bar',  # OR
+                'release': '200'
+            }
+        )) == ["1" * 32, "2" * 32]
+
+        assert self.ts.get_group_event_ids(
+            self.proj1.id,
+            self.proj1group2.id,
+            self.proj1env1.id,
+            {
+                'browser': 'chrome'
+            }
+        ) == ["3" * 32]
+
+        assert self.ts.get_group_event_ids(
+            self.proj1.id,
+            self.proj1group2.id,
+            self.proj1env1.id,
+            {
+                'browser': 'ie'
+            }
+        ) == []
