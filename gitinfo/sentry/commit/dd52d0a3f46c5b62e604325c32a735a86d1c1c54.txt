commit dd52d0a3f46c5b62e604325c32a735a86d1c1c54
Author: josh <josh@jrl.ninja>
Date:   Mon Nov 18 16:54:25 2019 -0800

    chore: remove is_postgres (#15647)

diff --git a/src/sentry/api/serializers/models/project.py b/src/sentry/api/serializers/models/project.py
index 8c946bbf2e..fd7a7e3538 100644
--- a/src/sentry/api/serializers/models/project.py
+++ b/src/sentry/api/serializers/models/project.py
@@ -32,7 +32,6 @@ from sentry.models import (
     DEFAULT_SUBJECT_TEMPLATE,
 )
 from sentry.utils.data_filters import FilterTypes
-from sentry.utils.db import is_postgres
 
 STATUS_LABELS = {
     ProjectStatus.VISIBLE: "active",
@@ -382,24 +381,22 @@ def bulk_fetch_project_latest_releases(projects):
     attribute representing the project that they're the latest release for. If
     no release found, no entry will be returned for the given project.
     """
-    if is_postgres():
-        # XXX: This query could be very inefficient for projects with a large
-        # number of releases. To work around this, we only check 20 releases
-        # ordered by highest release id, which is generally correlated with
-        # most recent releases for a project. This could potentially result in
-        # not having the correct most recent release, but in practice will
-        # likely work fine.
-        release_project_join_sql = """
-            JOIN (
-                SELECT *
-                FROM sentry_release_project lrp
-                WHERE lrp.project_id = p.id
-                ORDER BY lrp.release_id DESC
-                LIMIT 20
-            ) lrp ON lrp.release_id = lrr.id
-        """
-    else:
-        release_project_join_sql = "JOIN sentry_release_project lrp ON lrp.release_id = lrr.id"
+    # XXX: This query could be very inefficient for projects with a large
+    # number of releases. To work around this, we only check 20 releases
+    # ordered by highest release id, which is generally correlated with
+    # most recent releases for a project. This could potentially result in
+    # not having the correct most recent release, but in practice will
+    # likely work fine.
+    release_project_join_sql = """
+        JOIN (
+            SELECT *
+            FROM sentry_release_project lrp
+            WHERE lrp.project_id = p.id
+            ORDER BY lrp.release_id DESC
+            LIMIT 20
+        ) lrp ON lrp.release_id = lrr.id
+    """
+
     return list(
         Release.objects.raw(
             u"""
diff --git a/src/sentry/db/deletion.py b/src/sentry/db/deletion.py
index 2a125d24f9..0b2119803f 100644
--- a/src/sentry/db/deletion.py
+++ b/src/sentry/db/deletion.py
@@ -7,8 +7,6 @@ from datetime import timedelta
 from django.db import connections, router
 from django.utils import timezone
 
-from sentry.utils import db
-
 
 class BulkDeleteQuery(object):
     def __init__(self, model, project_id=None, dtfield=None, days=None, order_by=None):
@@ -19,7 +17,7 @@ class BulkDeleteQuery(object):
         self.order_by = order_by
         self.using = router.db_for_write(model)
 
-    def execute_postgres(self, chunk_size=10000):
+    def execute(self, chunk_size=10000):
         quote_name = connections[self.using].ops.quote_name
 
         where = []
@@ -75,50 +73,7 @@ class BulkDeleteQuery(object):
             cursor.execute(query)
             results = cursor.rowcount > 0
 
-    def execute_generic(self, chunk_size=100):
-        qs = self.get_generic_queryset()
-        return self._continuous_generic_query(qs, chunk_size)
-
-    def get_generic_queryset(self):
-        qs = self.model.objects.all()
-
-        if self.days:
-            cutoff = timezone.now() - timedelta(days=self.days)
-            qs = qs.filter(**{u"{}__lte".format(self.dtfield): cutoff})
-        if self.project_id:
-            if "project" in self.model._meta.get_all_field_names():
-                qs = qs.filter(project=self.project_id)
-            else:
-                qs = qs.filter(project_id=self.project_id)
-
-        return qs
-
-    def _continuous_generic_query(self, query, chunk_size):
-        # XXX: we step through because the deletion collector will pull all
-        # relations into memory
-        exists = True
-        while exists:
-            exists = False
-            for item in query[:chunk_size].iterator():
-                item.delete()
-                exists = True
-
-    def execute(self, chunk_size=10000):
-        if db.is_postgres():
-            self.execute_postgres(chunk_size)
-        else:
-            self.execute_generic(chunk_size)
-
-    def iterator(self, chunk_size=100):
-        if db.is_postgres():
-            g = self.iterator_postgres(chunk_size)
-        else:
-            g = self.iterator_generic(chunk_size)
-
-        for chunk in g:
-            yield chunk
-
-    def iterator_postgres(self, chunk_size, batch_size=100000):
+    def iterator(self, chunk_size=100, batch_size=100000):
         assert self.days is not None
         assert self.dtfield is not None and self.dtfield == self.order_by
 
@@ -192,17 +147,3 @@ class BulkDeleteQuery(object):
 
             if chunk:
                 yield tuple(chunk)
-
-    def iterator_generic(self, chunk_size):
-        from sentry.utils.query import RangeQuerySetWrapper
-
-        qs = self.get_generic_queryset()
-
-        chunk = []
-        for item in RangeQuerySetWrapper(qs):
-            chunk.append(item.id)
-            if len(chunk) == chunk_size:
-                yield tuple(chunk)
-                chunk = []
-        if chunk:
-            yield tuple(chunk)
diff --git a/src/sentry/db/models/fields/array.py b/src/sentry/db/models/fields/array.py
index 220ce21565..771ecc5bcf 100644
--- a/src/sentry/db/models/fields/array.py
+++ b/src/sentry/db/models/fields/array.py
@@ -25,10 +25,7 @@ class ArrayField(models.Field):
         super(ArrayField, self).__init__(**kwargs)
 
     def db_type(self, connection):
-        engine = connection.settings_dict["ENGINE"]
-        if "postgres" in engine:
-            return u"{}[]".format(self.of.db_type(connection))
-        return super(ArrayField, self).db_type(connection)
+        return u"{}[]".format(self.of.db_type(connection))
 
     def get_internal_type(self):
         return "TextField"
@@ -40,14 +37,6 @@ class ArrayField(models.Field):
             value = json.loads(value)
         return map(self.of.to_python, value)
 
-    def get_db_prep_value(self, value, connection, prepared=False):
-        if not prepared:
-            engine = connection.settings_dict["ENGINE"]
-            if "postgres" in engine:
-                return value
-            return json.dumps(value) if value else None
-        return value
-
     def get_prep_lookup(self, lookup_type, value):
         raise NotImplementedError(
             u"{!r} lookup type for {!r} is not supported".format(lookup_type, self)
diff --git a/src/sentry/db/models/fields/bounded.py b/src/sentry/db/models/fields/bounded.py
index f641d4c246..30eb215244 100644
--- a/src/sentry/db/models/fields/bounded.py
+++ b/src/sentry/db/models/fields/bounded.py
@@ -65,11 +65,7 @@ if settings.SENTRY_USE_BIG_INTS:
         MAX_VALUE = 9223372036854775807
 
         def db_type(self, connection):
-            engine = connection.settings_dict["ENGINE"]
-            if "postgres" in engine:
-                return "bigserial"
-            else:
-                raise NotImplementedError
+            return "bigserial"
 
         def get_related_db_type(self, connection):
             return BoundedBigIntegerField().db_type(connection)
diff --git a/src/sentry/db/models/fields/citext.py b/src/sentry/db/models/fields/citext.py
index 53b52517f9..ea20b837a5 100644
--- a/src/sentry/db/models/fields/citext.py
+++ b/src/sentry/db/models/fields/citext.py
@@ -11,10 +11,7 @@ __all__ = ("CITextField", "CICharField", "CIEmailField")
 
 class CIText(object):
     def db_type(self, connection):
-        engine = connection.settings_dict["ENGINE"]
-        if "postgres" in engine:
-            return "citext"
-        return super(CIText, self).db_type(connection)
+        return "citext"
 
 
 class CITextField(CIText, models.TextField):
@@ -36,17 +33,14 @@ if hasattr(models, "SubfieldBase"):
 
 
 def create_citext_extension(using, **kwargs):
-    from sentry.utils.db import is_postgres
-
     # We always need the citext extension installed for Postgres,
     # and for tests, it's not always guaranteed that we will have
     # run full migrations which installed it.
-    if is_postgres(using):
-        cursor = connections[using].cursor()
-        try:
-            cursor.execute("CREATE EXTENSION IF NOT EXISTS citext")
-        except Exception:
-            pass
+    cursor = connections[using].cursor()
+    try:
+        cursor.execute("CREATE EXTENSION IF NOT EXISTS citext")
+    except Exception:
+        pass
 
 
 pre_migrate.connect(create_citext_extension)
diff --git a/src/sentry/db/models/fields/uuid.py b/src/sentry/db/models/fields/uuid.py
index c137705088..ce1e3a52c9 100644
--- a/src/sentry/db/models/fields/uuid.py
+++ b/src/sentry/db/models/fields/uuid.py
@@ -59,10 +59,7 @@ class UUIDField(models.Field):
         super(UUIDField, self).__init__(**kwargs)
 
     def db_type(self, connection):
-        engine = connection.settings_dict["ENGINE"]
-        if "postgres" in engine:
-            return "uuid"
-        return super(UUIDField, self).db_type(connection)
+        return "uuid"
 
     def get_internal_type(self):
         return "CharField"
@@ -85,18 +82,6 @@ class UUIDField(models.Field):
         # Convert our value to a UUID.
         return UUID(value)
 
-    def get_db_prep_value(self, value, connection, prepared=False):
-        """Return a UUID object. Also, ensure that psycopg2 is
-        aware how to address that object.
-        """
-        engine = connection.settings_dict["ENGINE"]
-        if "postgres" not in engine:
-            if not prepared:
-                value = self.get_prep_value(value)
-            return six.text_type(value.hex) if value else None
-        # Run the normal functionality.
-        return super(UUIDField, self).get_db_prep_value(value, connection, prepared=prepared)
-
     def pre_save(self, instance, add):
         """If auto is set, generate a UUID at random."""
 
diff --git a/src/sentry/event_manager.py b/src/sentry/event_manager.py
index 072cd0b385..a62488e05c 100644
--- a/src/sentry/event_manager.py
+++ b/src/sentry/event_manager.py
@@ -77,7 +77,6 @@ from sentry.utils.data_filters import (
     FilterStatKeys,
 )
 from sentry.utils.dates import to_timestamp
-from sentry.utils.db import is_postgres
 from sentry.utils.safe import safe_execute, trim, get_path, setdefault_path
 from sentry.stacktraces.processing import normalize_stacktraces_for_grouping
 from sentry.culprit import generate_culprit
@@ -187,19 +186,14 @@ class ScoreClause(Func):
         return self.group.get_score() if self.group else 0
 
     def as_sql(self, compiler, connection, function=None, template=None):
-        db = getattr(connection, "alias", "default")
         has_values = self.last_seen is not None and self.times_seen is not None
-        if is_postgres(db):
-            if has_values:
-                sql = "log(times_seen + %d) * 600 + %d" % (
-                    self.times_seen,
-                    to_timestamp(self.last_seen),
-                )
-            else:
-                sql = "log(times_seen) * 600 + last_seen::abstime::int"
+        if has_values:
+            sql = "log(times_seen + %d) * 600 + %d" % (
+                self.times_seen,
+                to_timestamp(self.last_seen),
+            )
         else:
-            # XXX: if we cant do it atomically let's do it the best we can
-            sql = int(self)
+            sql = "log(times_seen) * 600 + last_seen::abstime::int"
 
         return (sql, [])
 
diff --git a/src/sentry/models/counter.py b/src/sentry/models/counter.py
index 12918d040d..0ce8300322 100644
--- a/src/sentry/models/counter.py
+++ b/src/sentry/models/counter.py
@@ -4,7 +4,6 @@ from django.db import connection, connections
 from django.db.models.signals import post_migrate
 
 from sentry.db.models import FlexibleForeignKey, Model, sane_repr, BoundedBigIntegerField
-from sentry.utils.db import is_postgres
 
 
 class Counter(Model):
@@ -32,16 +31,13 @@ def increment_project_counter(project, delta=1):
 
     cur = connection.cursor()
     try:
-        if is_postgres():
-            cur.execute(
-                """
-                select sentry_increment_project_counter(%s, %s)
-            """,
-                [project.id, delta],
-            )
-            return cur.fetchone()[0]
-        else:
-            raise AssertionError("Not implemented database engine path")
+        cur.execute(
+            """
+            select sentry_increment_project_counter(%s, %s)
+        """,
+            [project.id, delta],
+        )
+        return cur.fetchone()[0]
     finally:
         cur.close()
 
diff --git a/src/sentry/utils/db.py b/src/sentry/utils/db.py
index 287c8cab12..72f57eec81 100644
--- a/src/sentry/utils/db.py
+++ b/src/sentry/utils/db.py
@@ -2,22 +2,11 @@ from __future__ import absolute_import
 
 import six
 
-from django.conf import settings
 from django.db import connections, DEFAULT_DB_ALIAS
 
 from django.db.models.fields.related_descriptors import ReverseOneToOneDescriptor
 
 
-def get_db_engine(alias="default"):
-    value = settings.DATABASES[alias]["ENGINE"]
-    return value.rsplit(".", 1)[-1]
-
-
-def is_postgres(alias="default"):
-    engine = get_db_engine(alias)
-    return "postgres" in engine
-
-
 def attach_foreignkey(objects, field, related=(), database=None):
     """
     Shortcut method which handles a pythonic LEFT OUTER JOIN.
diff --git a/src/sentry/utils/query.py b/src/sentry/utils/query.py
index 6fb3f23c3e..95694414bf 100644
--- a/src/sentry/utils/query.py
+++ b/src/sentry/utils/query.py
@@ -9,8 +9,6 @@ from django.db.models import ForeignKey
 from django.db.models.deletion import Collector
 from django.db.models.signals import pre_delete, pre_save, post_save, post_delete
 
-from sentry.utils import db
-
 _leaf_re = re.compile(r"^(UserReport|Event|Group)(.+)")
 
 
@@ -298,29 +296,20 @@ def bulk_delete_objects(
         query.append("%s = %%s" % (quote_name(column),))
         params.append(value)
 
-    if db.is_postgres():
-        query = """
-            delete from %(table)s
-            where %(partition_query)s id = any(array(
-                select id
-                from %(table)s
-                where (%(query)s)
-                limit %(limit)d
-            ))
-        """ % dict(
-            partition_query=(" AND ".join(partition_query)) + (" AND " if partition_query else ""),
-            query=" AND ".join(query),
-            table=model._meta.db_table,
-            limit=limit,
-        )
-    else:
-        if logger is not None:
-            logger.warning("Using slow deletion strategy due to unknown database")
-        has_more = False
-        for obj in model.objects.filter(**filters)[:limit]:
-            obj.delete()
-            has_more = True
-        return has_more
+    query = """
+        delete from %(table)s
+        where %(partition_query)s id = any(array(
+            select id
+            from %(table)s
+            where (%(query)s)
+            limit %(limit)d
+        ))
+    """ % dict(
+        partition_query=(" AND ".join(partition_query)) + (" AND " if partition_query else ""),
+        query=" AND ".join(query),
+        table=model._meta.db_table,
+        limit=limit,
+    )
 
     cursor = connection.cursor()
     cursor.execute(query, params)
diff --git a/tests/sentry/db/postgres/test_base.py b/tests/sentry/db/postgres/test_base.py
index b7f044a613..dd81f9fc49 100644
--- a/tests/sentry/db/postgres/test_base.py
+++ b/tests/sentry/db/postgres/test_base.py
@@ -2,7 +2,6 @@
 from __future__ import absolute_import
 
 import pytest
-from sentry.utils.db import is_postgres
 from sentry.testutils import TestCase
 from sentry.constants import MAX_CULPRIT_LENGTH
 from django.utils.encoding import force_text
@@ -15,10 +14,7 @@ def psycopg2_version():
     return tuple(map(int, version))
 
 
-@pytest.mark.skipif(
-    not is_postgres() or psycopg2_version() < (2, 7),
-    reason="Test requires Postgres and psycopg 2.7+",
-)
+@pytest.mark.skipif(psycopg2_version() < (2, 7), reason="Test requires psycopg 2.7+")
 class CursorWrapperTestCase(TestCase):
     def test_null_bytes(self):
         from django.db import connection
diff --git a/tests/sentry/utils/db/__init__.py b/tests/sentry/utils/db/__init__.py
deleted file mode 100644
index c3961685ab..0000000000
--- a/tests/sentry/utils/db/__init__.py
+++ /dev/null
@@ -1 +0,0 @@
-from __future__ import absolute_import
diff --git a/tests/sentry/utils/db/tests.py b/tests/sentry/utils/db/tests.py
deleted file mode 100644
index 6ba5ab9654..0000000000
--- a/tests/sentry/utils/db/tests.py
+++ /dev/null
@@ -1,16 +0,0 @@
-# -*- coding: utf-8 -*-
-
-from __future__ import absolute_import
-
-from sentry.utils.db import get_db_engine
-from sentry.testutils import TestCase
-
-
-class GetDbEngineTest(TestCase):
-    def test_with_dotted_path(self):
-        with self.settings(DATABASES={"default": {"ENGINE": "blah.postgres"}}):
-            self.assertEquals(get_db_engine(), "postgres")
-
-    def test_no_path(self):
-        with self.settings(DATABASES={"default": {"ENGINE": "postgres"}}):
-            self.assertEquals(get_db_engine(), "postgres")
