commit f0e1a3fc48b532d468c1660ca2c5fd5dcbeb7f42
Author: David Cramer <dcramer@gmail.com>
Date:   Wed Mar 4 13:43:32 2015 -0800

    Improve error reporting/handling around souremaps

diff --git a/src/sentry/lang/javascript/processor.py b/src/sentry/lang/javascript/processor.py
index 191df33d91..5b3a70141b 100644
--- a/src/sentry/lang/javascript/processor.py
+++ b/src/sentry/lang/javascript/processor.py
@@ -10,12 +10,12 @@ import base64
 from django.conf import settings
 from collections import namedtuple
 from os.path import splitext
+from requests.exceptions import RequestException
 from simplejson import JSONDecodeError
 from urlparse import urlparse, urljoin, urlsplit
-from urllib2 import HTTPError
 
+from sentry import http
 from sentry.constants import MAX_CULPRIT_LENGTH
-from sentry.http import safe_urlopen, safe_urlread
 from sentry.interfaces.stacktrace import Stacktrace
 from sentry.models import Project, Release, ReleaseFile
 from sentry.utils.cache import cache
@@ -26,7 +26,6 @@ from .cache import SourceCache, SourceMapCache
 from .sourcemaps import sourcemap_to_index, find_source
 
 
-BAD_SOURCE = -1
 # number of surrounding lines (on each side) to fetch
 LINES_OF_CONTEXT = 5
 BASE64_SOURCEMAP_PREAMBLE = 'data:application/json;base64,'
@@ -52,6 +51,18 @@ UrlResult = namedtuple('UrlResult', ['url', 'headers', 'body'])
 logger = logging.getLogger(__name__)
 
 
+class BadSource(Exception):
+    pass
+
+
+class DomainBlacklisted(BadSource):
+    pass
+
+
+class CannotFetchSource(BadSource):
+    pass
+
+
 def trim_line(line, column=0):
     """
     Trims a line down to a goal of 140 characters, with a little
@@ -190,43 +201,38 @@ def fetch_url(url, project=None, release=None):
         domain_key = 'source:%s' % (hashlib.md5(domain.encode('utf-8')).hexdigest(),)
         domain_result = cache.get(domain_key)
         if domain_result:
-            return BAD_SOURCE
+            raise DomainBlacklisted
 
-        headers = []
+        headers = {}
         if project and is_valid_origin(url, project=project):
             token = project.get_option('sentry:token')
             if token:
-                headers.append(('X-Sentry-Token', token))
+                headers['X-Sentry-Token'] = token
+
+        http_session = http.build_session()
 
         try:
-            request = safe_urlopen(
+            response = http_session.get(
                 url,
                 allow_redirects=True,
-                verify_ssl=False,
+                verify=False,
                 headers=headers,
                 timeout=settings.SENTRY_SOURCE_FETCH_TIMEOUT,
             )
-        except HTTPError:
-            result = BAD_SOURCE
-        except Exception:
-            # it's likely we've failed due to a timeout, dns, etc so let's
-            # ensure we can't cascade the failure by pinning this for 5 minutes
+        except RequestException as exc:
             cache.set(domain_key, 1, 300)
             logger.warning('Disabling sources to %s for %ss', domain, 300,
                            exc_info=True)
-            return BAD_SOURCE
-        else:
-            try:
-                body = safe_urlread(request)
-            except Exception:
-                result = BAD_SOURCE
-            else:
-                result = (dict(request.headers), body)
+            raise CannotFetchSource('A {} error was hit while fetching the source'.format(type(exc)))
 
-        cache.set(cache_key, result, 60)
+        if response.status_code != 200:
+            cache.set(domain_key, 1, 300)
+            logger.warning('Disabling sources to %s for %ss (due to HTTP %s)',
+                          domain, 300, response.status_code)
+            raise CannotFetchSource('Received HTTP {} response'.format(response.status_code))
 
-    if result == BAD_SOURCE:
-        return result
+        result = (dict(response.headers), response.content)
+        cache.set(cache_key, result, 60)
 
     return UrlResult(url, *result)
 
@@ -236,9 +242,6 @@ def fetch_sourcemap(url, project=None, release=None):
         body = base64.b64decode(url[BASE64_PREAMBLE_LENGTH:])
     else:
         result = fetch_url(url, project=project, release=release)
-        if result == BAD_SOURCE:
-            return
-
         body = result.body
 
     # According to spec (https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit#heading=h.h7yy76c5il9v)
@@ -246,12 +249,8 @@ def fetch_sourcemap(url, project=None, release=None):
     # If the file starts with that string, ignore the entire first line.
     if body.startswith(")]}'"):
         body = body.split('\n', 1)[1]
-    try:
-        index = sourcemap_to_index(body)
-    except (JSONDecodeError, ValueError):
-        return
-    else:
-        return index
+
+    return sourcemap_to_index(body)
 
 
 def is_data_uri(url):
@@ -461,11 +460,10 @@ class SourceProcessor(object):
 
             # TODO: respect cache-control/max-age headers to some extent
             logger.debug('Fetching remote source %r', filename)
-            result = fetch_url(filename, project=project, release=release)
-
-            if result == BAD_SOURCE:
-                # TODO(dcramer): we want better errors here
-                cache.add_error(filename, 'File was unreachable or invalid')
+            try:
+                result = fetch_url(filename, project=project, release=release)
+            except BadSource as exc:
+                cache.add_error(filename, unicode(exc))
                 continue
 
             cache.add(filename, result.body.splitlines())
@@ -487,12 +485,16 @@ class SourceProcessor(object):
                 continue
 
             # pull down sourcemap
-            sourcemap_idx = fetch_sourcemap(
-                sourcemap_url,
-                project=project,
-                release=release,
-            )
-            if not sourcemap_idx:
+            try:
+                sourcemap_idx = fetch_sourcemap(
+                    sourcemap_url,
+                    project=project,
+                    release=release,
+                )
+            except BadSource as exc:
+                cache.add_error(filename, unicode(exc))
+                continue
+            except (JSONDecodeError, ValueError):
                 cache.add_error(filename, 'Sourcemap was not parseable')
                 continue
 
diff --git a/tests/sentry/lang/javascript/test_processor.py b/tests/sentry/lang/javascript/test_processor.py
index 197b313b48..6f5cd11267 100644
--- a/tests/sentry/lang/javascript/test_processor.py
+++ b/tests/sentry/lang/javascript/test_processor.py
@@ -2,10 +2,13 @@
 
 from __future__ import absolute_import
 
-from mock import patch
+import pytest
+import responses
+
+from requests.exceptions import RequestException
 
 from sentry.lang.javascript.processor import (
-    BAD_SOURCE, discover_sourcemap, fetch_sourcemap, fetch_url, generate_module,
+    BadSource, discover_sourcemap, fetch_sourcemap, fetch_url, generate_module,
     trim_line, UrlResult
 )
 from sentry.lang.javascript.sourcemaps import SourceMap, SourceMapIndex
@@ -15,99 +18,57 @@ base64_sourcemap = 'data:application/json;base64,eyJ2ZXJzaW9uIjozLCJmaWxlIjoiZ2V
 
 
 class FetchUrlTest(TestCase):
-    @patch('sentry.lang.javascript.processor.safe_urlopen')
-    @patch('sentry.lang.javascript.processor.safe_urlread')
-    def test_simple(self, safe_urlread, safe_urlopen):
-        safe_urlopen.return_value.headers = (('content-type', 'application/json'),)
-        safe_urlread.return_value = u'foo bar'
+    @responses.activate
+    def test_simple(self):
+        responses.add(responses.GET, 'http://example.com', body='foo bar',
+                      content_type='application/json')
 
         result = fetch_url('http://example.com')
 
-        safe_urlopen.assert_called_once_with(
-            'http://example.com', allow_redirects=True, timeout=5,
-            headers=[], verify_ssl=False)
-        safe_urlread.assert_called_once_with(safe_urlopen.return_value)
+        assert len(responses.calls) == 1
 
         assert result.url == 'http://example.com'
-        assert result.body == u'foo bar'
-        assert result.headers == {'content-type': 'application/json'}
+        assert result.body == 'foo bar'
+        assert result.headers == {'Content-Type': 'application/json'}
 
         # ensure we use the cached result
         result2 = fetch_url('http://example.com')
 
-        safe_urlopen.assert_called_once()
+        assert len(responses.calls) == 1
 
         assert result == result2
 
-    @patch('sentry.lang.javascript.processor.safe_urlopen')
-    @patch('sentry.lang.javascript.processor.safe_urlread')
-    def test_with_token(self, safe_urlread, safe_urlopen):
+    @responses.activate
+    def test_with_token(self):
+        responses.add(responses.GET, 'http://example.com', body='foo bar',
+                      content_type='application/json')
+
         self.project.update_option('sentry:token', 'foobar')
         self.project.update_option('sentry:origins', ['*'])
 
-        safe_urlopen.return_value.headers = (('content-type', 'application/json'),)
-        safe_urlread.return_value = u'foo bar'
-
         result = fetch_url('http://example.com', project=self.project)
 
-        safe_urlopen.assert_called_once_with(
-            'http://example.com', allow_redirects=True, timeout=5,
-            headers=[('X-Sentry-Token', 'foobar')], verify_ssl=False)
-        safe_urlread.assert_called_once_with(safe_urlopen.return_value)
+        assert len(responses.calls) == 1
+        assert responses.calls[0].request.headers['X-Sentry-Token'] == 'foobar'
 
         assert result.url == 'http://example.com'
-        assert result.body == u'foo bar'
-        assert result.headers == {'content-type': 'application/json'}
-
-        # ensure we use the cached result
-        result2 = fetch_url('http://example.com')
-
-        safe_urlopen.assert_called_once()
-
-        assert result == result2
-
-    @patch('sentry.lang.javascript.processor.safe_urlopen')
-    @patch('sentry.lang.javascript.processor.safe_urlread')
-    def test_connection_failure(self, safe_urlread, safe_urlopen):
-        safe_urlopen.side_effect = Exception()
+        assert result.body == 'foo bar'
+        assert result.headers == {'Content-Type': 'application/json'}
 
-        result = fetch_url('http://example.com')
+    @responses.activate
+    def test_connection_failure(self):
+        responses.add(responses.GET, 'http://example.com', body=RequestException())
 
-        safe_urlopen.assert_called_once_with(
-            'http://example.com', allow_redirects=True, timeout=5,
-            headers=[], verify_ssl=False)
-        assert not safe_urlread.mock_calls
+        with pytest.raises(BadSource):
+            result = fetch_url('http://example.com')
 
-        assert result == BAD_SOURCE
+        assert len(responses.calls) == 1
 
         # ensure we use the cached domain-wide failure for the second call
-        result = fetch_url('http://example.com/foo/bar')
-
-        safe_urlopen.assert_called_once()
-
-        assert result == BAD_SOURCE
-
-    @patch('sentry.lang.javascript.processor.safe_urlopen')
-    @patch('sentry.lang.javascript.processor.safe_urlread')
-    def test_read_failure(self, safe_urlread, safe_urlopen):
-        safe_urlopen.return_value.headers = (('content-type', 'application/json'),)
-        safe_urlread.side_effect = Exception()
-
-        result = fetch_url('http://example.com')
-
-        safe_urlopen.assert_called_once_with(
-            'http://example.com', allow_redirects=True, timeout=5,
-            headers=[], verify_ssl=False)
-        safe_urlread.assert_called_once_with(safe_urlopen.return_value)
-
-        assert result == BAD_SOURCE
-
-        # ensure we use the cached failure for the second call
-        result = fetch_url('http://example.com')
-
-        safe_urlopen.assert_called_once()
+        with pytest.raises(BadSource):
+            result = fetch_url('http://example.com/foo/bar')
 
-        assert result == BAD_SOURCE
+        assert len(responses.calls) == 1
 
 
 class DiscoverSourcemapTest(TestCase):
