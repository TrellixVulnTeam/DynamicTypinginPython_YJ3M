commit 4f5c332eeab7fcd500d7c575a051ae4362336217
Author: Dan Fuller <dfuller@sentry.io>
Date:   Mon May 11 11:16:35 2020 -0700

    feat(alerts): Convert subscription creation to rely on `SnubaQuery` (#18706)
    
    This converts subscription creation to rely on the `SnubaQuery` model. While testing this, I ran
    into a bug in snuba when using aliased fields. To work around this, I switched `UNIQUE_USERS` to use
    the tag explicitly, and also migrate the data across. Before we can fully support custom
    aggregations this bug will need to be fixed, but this allows us to move forward for now.

diff --git a/migrations_lockfile.txt b/migrations_lockfile.txt
index a12630f7d1..ba6723b670 100644
--- a/migrations_lockfile.txt
+++ b/migrations_lockfile.txt
@@ -10,7 +10,7 @@ auth: 0008_alter_user_username_max_length
 contenttypes: 0002_remove_content_type_name
 jira_ac: 0001_initial
 nodestore: 0001_initial
-sentry: 0074_add_metric_alert_feature
+sentry: 0075_metric_alerts_fix_releases
 sessions: 0001_initial
 sites: 0002_alter_domain_unique
 social_auth: 0001_initial
diff --git a/src/sentry/migrations/0075_metric_alerts_fix_releases.py b/src/sentry/migrations/0075_metric_alerts_fix_releases.py
new file mode 100644
index 0000000000..b6af6ef172
--- /dev/null
+++ b/src/sentry/migrations/0075_metric_alerts_fix_releases.py
@@ -0,0 +1,41 @@
+# -*- coding: utf-8 -*-
+# Generated by Django 1.11.29 on 2020-05-08 20:43
+from __future__ import unicode_literals
+
+from django.db import migrations
+
+from sentry.utils.query import RangeQuerySetWrapperWithProgressBar
+
+
+def migrate_alert_query_model(apps, schema_editor):
+    SnubaQuery = apps.get_model("sentry", "SnubaQuery")
+    for snuba_query in RangeQuerySetWrapperWithProgressBar(
+        SnubaQuery.objects.filter(aggregate="count_unique(user)")
+    ):
+        snuba_query.aggregate = "count_unique(tags[sentry:user])"
+        snuba_query.save()
+
+
+class Migration(migrations.Migration):
+    # This flag is used to mark that a migration shouldn't be automatically run in
+    # production. We set this to True for operations that we think are risky and want
+    # someone from ops to run manually and monitor.
+    # General advice is that if in doubt, mark your migration as `is_dangerous`.
+    # Some things you should always mark as dangerous:
+    # - Large data migrations. Typically we want these to be run manually by ops so that
+    #   they can be monitored. Since data migrations will now hold a transaction open
+    #   this is even more important.
+    # - Adding columns to highly active tables, even ones that are NULL.
+    is_dangerous = False
+
+    # This flag is used to decide whether to run this migration in a transaction or not.
+    # By default we prefer to run in a transaction, but for migrations where you want
+    # to `CREATE INDEX CONCURRENTLY` this needs to be set to False. Typically you'll
+    # want to create an index concurrently when adding one to an existing table.
+    atomic = False
+
+    dependencies = [("sentry", "0074_add_metric_alert_feature")]
+
+    operations = [
+        migrations.RunPython(migrate_alert_query_model, reverse_code=migrations.RunPython.noop)
+    ]
diff --git a/src/sentry/snuba/subscriptions.py b/src/sentry/snuba/subscriptions.py
index c9f4caaa9a..33b694b870 100644
--- a/src/sentry/snuba/subscriptions.py
+++ b/src/sentry/snuba/subscriptions.py
@@ -20,7 +20,7 @@ logger = logging.getLogger(__name__)
 
 aggregation_function_translations = {
     QueryAggregations.TOTAL: "count()",
-    QueryAggregations.UNIQUE_USERS: "count_unique(user)",
+    QueryAggregations.UNIQUE_USERS: "count_unique(tags[sentry:user])",
 }
 
 
diff --git a/src/sentry/snuba/tasks.py b/src/sentry/snuba/tasks.py
index 2ad4c104b5..bdca348c3b 100644
--- a/src/sentry/snuba/tasks.py
+++ b/src/sentry/snuba/tasks.py
@@ -2,15 +2,9 @@ from __future__ import absolute_import
 
 import json
 
-from sentry.api.event_search import get_filter
-from sentry.models import Environment
+from sentry.api.event_search import get_filter, resolve_field_list
 from sentry.snuba.discover import resolve_discover_aliases
-from sentry.snuba.models import (
-    QueryAggregations,
-    QueryDatasets,
-    QuerySubscription,
-    query_aggregation_to_snuba,
-)
+from sentry.snuba.models import QueryDatasets, QuerySubscription
 from sentry.tasks.base import instrumented_task
 from sentry.utils import metrics
 from sentry.utils.snuba import _snuba_pool, SnubaError
@@ -80,7 +74,9 @@ def update_subscription_in_snuba(query_subscription_id):
         return
 
     if subscription.subscription_id is not None:
-        _delete_from_snuba(QueryDatasets(subscription.dataset), subscription.subscription_id)
+        _delete_from_snuba(
+            QueryDatasets(subscription.snuba_query.dataset), subscription.subscription_id
+        )
 
     subscription_id = _create_in_snuba(subscription)
     subscription.update(
@@ -116,31 +112,28 @@ def delete_subscription_from_snuba(query_subscription_id):
 
 
 def _create_in_snuba(subscription):
-    conditions = resolve_discover_aliases(get_filter(subscription.query))[0].conditions
-    try:
-        environment = subscription.environments.all()[:1].get()
-    except Environment.DoesNotExist:
-        environment = None
-
-    if environment:
-        conditions.append(["environment", "=", environment.name])
-    conditions = apply_dataset_conditions(QueryDatasets(subscription.dataset), conditions)
+    snuba_query = subscription.snuba_query
+    snuba_filter = get_filter(snuba_query.query)
+    snuba_filter.update_with(
+        resolve_field_list([snuba_query.aggregate], snuba_filter, auto_fields=False)
+    )
+    snuba_filter = resolve_discover_aliases(snuba_filter)[0]
+    if snuba_query.environment:
+        snuba_filter.conditions.append(["environment", "=", snuba_query.environment.name])
+    conditions = apply_dataset_conditions(
+        QueryDatasets(snuba_query.dataset), snuba_filter.conditions
+    )
     response = _snuba_pool.urlopen(
         "POST",
         "/%s/subscriptions" % (subscription.dataset,),
         body=json.dumps(
             {
                 "project_id": subscription.project_id,
-                "dataset": subscription.dataset,
-                # We only care about conditions here. Filter keys only matter for
-                # filtering to project and groups. Projects are handled with an
-                # explicit param, and groups can't be queried here.
+                "dataset": snuba_query.dataset,
                 "conditions": conditions,
-                "aggregations": [
-                    query_aggregation_to_snuba[QueryAggregations(subscription.aggregation)]
-                ],
-                "time_window": subscription.time_window,
-                "resolution": subscription.resolution,
+                "aggregations": snuba_filter.aggregations,
+                "time_window": snuba_query.time_window,
+                "resolution": snuba_query.resolution,
             }
         ),
     )
diff --git a/tests/sentry/snuba/test_tasks.py b/tests/sentry/snuba/test_tasks.py
index f02601c6f5..b356c6f0a3 100644
--- a/tests/sentry/snuba/test_tasks.py
+++ b/tests/sentry/snuba/test_tasks.py
@@ -9,7 +9,8 @@ from exam import patcher
 from mock import Mock, patch
 from six import add_metaclass
 
-from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription
+from sentry.snuba.models import QueryAggregations, QueryDatasets, QuerySubscription, SnubaQuery
+from sentry.snuba.subscriptions import translate_aggregation
 from sentry.snuba.tasks import (
     create_subscription_in_snuba,
     update_subscription_in_snuba,
@@ -39,16 +40,30 @@ class BaseSnubaTaskTest(object):
     def create_subscription(self, status=None, subscription_id=None):
         if status is None:
             status = self.expected_status
+        dataset = QueryDatasets.EVENTS.value
+        aggregate = QueryAggregations.UNIQUE_USERS
+        query = "hello"
+        time_window = 60
+        resolution = 60
+
+        snuba_query = SnubaQuery.objects.create(
+            dataset=dataset,
+            aggregate=translate_aggregation(aggregate),
+            query=query,
+            time_window=time_window,
+            resolution=resolution,
+        )
         return QuerySubscription.objects.create(
+            snuba_query=snuba_query,
             status=status.value,
             subscription_id=subscription_id,
             project=self.project,
             type="something",
-            dataset=QueryDatasets.EVENTS.value,
-            query="hello",
-            aggregation=QueryAggregations.UNIQUE_USERS.value,
-            time_window=60,
-            resolution=60,
+            dataset=dataset,
+            query=query,
+            aggregation=aggregate.value,
+            time_window=time_window,
+            resolution=resolution,
         )
 
     def test_no_subscription(self):
