commit f05ac30df18f17c87eb87951c2b6139bd20dd87a
Author: Ted Kaemming <ted@kaemming.com>
Date:   Wed Oct 28 12:21:31 2015 -0700

    Fix key composition in digest schedule script.
    
    Incorrectly constructing the last processed timestamp in the Lua script
    caused digests to be scheduled too quickly upon receiving new events --
    instead of additional events delaying scheduling processing, they
    actually reduced the delay:
    https://github.com/getsentry/sentry/blob/e60b095bf3ba3e371ce3230b66b3301a36af7450/src/sentry/digests/backends/redis.py#L99-L104
    
    This patch changes the the last processed timestamp to be passed as a
    key to the script, ensuring that it is constructed for reading using the
    same method as is used when it is set during processing. This removes
    the potential for these two methods of key generation to diverge.
    
    This also verifies the presence of all keys and arguments to the
    schedule script. This ensures the correct number of keys and arguments
    are provided, throwing an error if too few arguments are passed
    (otherwise, missing argument or keys would have been silently converted
    to `nil`.)

diff --git a/src/sentry/digests/backends/redis.py b/src/sentry/digests/backends/redis.py
index 272813173e..b926261709 100644
--- a/src/sentry/digests/backends/redis.py
+++ b/src/sentry/digests/backends/redis.py
@@ -1,6 +1,5 @@
 from __future__ import absolute_import
 
-import functools
 import itertools
 import logging
 import random
@@ -74,7 +73,7 @@ def make_record_key(timeline_key, record):
 
 # Ensures an timeline is scheduled to be digested, adjusting the schedule time
 # if necessary.
-# KEYS: {WAITING, READY}
+# KEYS: {WAITING, READY, LAST_PROCESSED_TIMESTAMP}
 # ARGV: {
 #   TIMELINE,   -- timeline key
 #   TIMESTAMP,  --
@@ -84,33 +83,42 @@ def make_record_key(timeline_key, record):
 #               -- digestion
 # }
 ENSURE_TIMELINE_SCHEDULED_SCRIPT = """\
+local WAITING = KEYS[1] or error("incorrect number of keys provided")
+local READY = KEYS[2] or error("incorrect number of keys provided")
+local LAST_PROCESSED_TIMESTAMP = KEYS[3] or error("incorrect number of keys provided")
+
+local TIMELINE = ARGV[1] or error("incorrect number of arguments provided")
+local TIMESTAMP = ARGV[2] or error("incorrect number of arguments provided")
+local INCREMENT = ARGV[3] or error("incorrect number of arguments provided")
+local MAXIMUM = ARGV[4] or error("incorrect number of arguments provided")
+
 -- If the timeline is already in the "ready" set, this is a noop.
-if tonumber(redis.call('ZSCORE', KEYS[2], ARGV[1])) ~= nil then
+if tonumber(redis.call('ZSCORE', READY, TIMELINE)) ~= nil then
     return false
 end
 
 -- Otherwise, check to see if the timeline is in the "waiting" set.
-local score = tonumber(redis.call('ZSCORE', KEYS[1], ARGV[1]))
+local score = tonumber(redis.call('ZSCORE', WAITING, TIMELINE))
 if score ~= nil then
     -- If the timeline is already in the "waiting" set, increase the delay by
     -- min(current schedule + increment value, maximum delay after last processing time).
-    local last = tonumber(redis.call('GET', ARGV[1] .. ':{TIMELINE_LAST_PROCESSED_TIMESTAMP_PATH_COMPONENT}'))
+    local last = tonumber(redis.call('GET', LAST_PROCESSED_TIMESTAMP))
     local update = nil;
     if last == nil then
         -- If the last processed timestamp is missing for some reason (possibly
         -- evicted), be conservative and allow the timeline to be scheduled
         -- with either the current schedule time or provided timestamp,
         -- whichever is smaller.
-        update = math.min(score, ARGV[2])
+        update = math.min(score, TIMESTAMP)
     else
         update = math.min(
-            score + tonumber(ARGV[3]),
-            last + tonumber(ARGV[4])
+            score + tonumber(INCREMENT),
+            last + tonumber(MAXIMUM)
         )
     end
 
     if update ~= score then
-        redis.call('ZADD', KEYS[1], update, ARGV[1])
+        redis.call('ZADD', WAITING, update, TIMELINE)
     end
     return false
 end
@@ -118,11 +126,9 @@ end
 -- If the timeline isn't already in either set, add it to the "ready" set with
 -- the provided timestamp. This allows for immediate scheduling, bypassing the
 -- imposed delay of the "waiting" state.
-redis.call('ZADD', KEYS[2], ARGV[2], ARGV[1])
+redis.call('ZADD', READY, TIMESTAMP, TIMELINE)
 return true
-""".format(
-    TIMELINE_LAST_PROCESSED_TIMESTAMP_PATH_COMPONENT=TIMELINE_LAST_PROCESSED_TIMESTAMP_PATH_COMPONENT,
-)
+"""
 
 
 # Trims a timeline to a maximum number of records.
@@ -247,9 +253,10 @@ class RedisBackend(Backend):
             pipeline.expire(timeline_key, self.ttl)
 
             ensure_timeline_scheduled(
-                map(
-                    functools.partial(make_schedule_key, self.namespace),
-                    (SCHEDULE_STATE_WAITING, SCHEDULE_STATE_READY,),
+                (
+                    make_schedule_key(self.namespace, SCHEDULE_STATE_WAITING),
+                    make_schedule_key(self.namespace, SCHEDULE_STATE_READY),
+                    make_last_processed_timestamp_key(timeline_key),
                 ),
                 (
                     key,
diff --git a/tests/sentry/digests/backends/test_redis.py b/tests/sentry/digests/backends/test_redis.py
index 90b7b4b775..7fe595a676 100644
--- a/tests/sentry/digests/backends/test_redis.py
+++ b/tests/sentry/digests/backends/test_redis.py
@@ -60,46 +60,49 @@ class RedisScriptTestCase(BaseRedisBackendTestCase):
 
         waiting_set_size = functools.partial(client.zcard, 'waiting')
         ready_set_size = functools.partial(client.zcard, 'ready')
+
         timeline_score_in_waiting_set = functools.partial(client.zscore, 'waiting', timeline)
         timeline_score_in_ready_set = functools.partial(client.zscore, 'ready', timeline)
 
+        keys = ('waiting', 'ready', 'last-processed')
+
         # The first addition should cause the timeline to be added to the ready set.
         with self.assertChanges(ready_set_size, before=0, after=1), \
                 self.assertChanges(timeline_score_in_ready_set, before=None, after=timestamp):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp, 1, 10), client) == 1
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp, 1, 10), client) == 1
 
         # Adding it again with a timestamp in the future should not change the schedule time.
         with self.assertDoesNotChange(waiting_set_size), \
                 self.assertDoesNotChange(ready_set_size), \
                 self.assertDoesNotChange(timeline_score_in_ready_set):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp + 50, 1, 10), client) is None
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp + 50, 1, 10), client) is None
 
         # Move the timeline from the ready set to the waiting set.
         client.zrem('ready', timeline)
         client.zadd('waiting', timestamp, timeline)
-        client.set(make_last_processed_timestamp_key(timeline), timestamp)
+        client.set('last-processed', timestamp)
 
         increment = 1
         with self.assertDoesNotChange(waiting_set_size), \
                 self.assertChanges(timeline_score_in_waiting_set, before=timestamp, after=timestamp + increment):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp, increment, 10), client) is None
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp, increment, 10), client) is None
 
         # Make sure the schedule respects the maximum value.
         with self.assertDoesNotChange(waiting_set_size), \
                 self.assertChanges(timeline_score_in_waiting_set, before=timestamp + 1, after=timestamp):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp, increment, 0), client) is None
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp, increment, 0), client) is None
 
         # Test to ensure a missing last processed timestamp can be handled
         # correctly (chooses minimum of schedule value and record timestamp.)
         client.zadd('waiting', timestamp, timeline)
-        client.delete(make_last_processed_timestamp_key(timeline))
+        client.delete('last-processed')
         with self.assertDoesNotChange(waiting_set_size), \
                 self.assertDoesNotChange(timeline_score_in_waiting_set):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp + 100, increment, 10), client) is None
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp + 100, increment, 10), client) is None
 
         with self.assertDoesNotChange(waiting_set_size), \
                 self.assertChanges(timeline_score_in_waiting_set, before=timestamp, after=timestamp - 100):
-            assert ensure_timeline_scheduled(('waiting', 'ready'), (timeline, timestamp - 100, increment, 10), client) is None
+            assert ensure_timeline_scheduled(keys, (timeline, timestamp - 100, increment, 10), client) is None
 
     def test_truncate_timeline_script(self):
         client = StrictRedis(db=9)
