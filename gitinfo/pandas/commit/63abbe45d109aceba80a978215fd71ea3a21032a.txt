commit 63abbe45d109aceba80a978215fd71ea3a21032a
Author: Matthew Lurie <mlurie@novumrx.com>
Date:   Mon Feb 1 14:40:58 2016 -0600

    ENH: add s3_host from env variables
    
    closes #12198

diff --git a/doc/source/whatsnew/v0.18.0.txt b/doc/source/whatsnew/v0.18.0.txt
index 92fd7a7e9..ffba68156 100644
--- a/doc/source/whatsnew/v0.18.0.txt
+++ b/doc/source/whatsnew/v0.18.0.txt
@@ -193,6 +193,7 @@ Other enhancements
 - Handle truncated floats in SAS xport files (:issue:`11713`)
 - Added option to hide index in ``Series.to_string`` (:issue:`11729`)
 - ``read_excel`` now supports s3 urls of the format ``s3://bucketname/filename`` (:issue:`11447`)
+- add support for ``AWS_S3_HOST`` env variable when reading from s3 (:issue:`12198`)
 - A simple version of ``Panel.round()`` is now implemented (:issue:`11763`)
 - For Python 3.x, ``round(DataFrame)``, ``round(Series)``, ``round(Panel)`` will work (:issue:`11763`)
 - ``DataFrame`` has gained a ``_repr_latex_`` method in order to allow for automatic conversion to latex in a ipython/jupyter notebook using nbconvert. Options ``display.latex.escape`` and ``display.latex.longtable`` have been added to the configuration and are used automatically by the ``to_latex`` method. (:issue:`11778`)
diff --git a/pandas/io/common.py b/pandas/io/common.py
index f60322660..c5f433cea 100644
--- a/pandas/io/common.py
+++ b/pandas/io/common.py
@@ -274,14 +274,15 @@ def get_filepath_or_buffer(filepath_or_buffer, encoding=None,
             import boto
         except:
             raise ImportError("boto is required to handle s3 files")
-        # Assuming AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY
+        # Assuming AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY and AWS_S3_HOST
         # are environment variables
         parsed_url = parse_url(filepath_or_buffer)
+        s3_host = os.environ.get('AWS_S3_HOST', 's3.amazonaws.com')
 
         try:
-            conn = boto.connect_s3()
+            conn = boto.connect_s3(host=s3_host)
         except boto.exception.NoAuthHandlerFound:
-            conn = boto.connect_s3(anon=True)
+            conn = boto.connect_s3(host=s3_host, anon=True)
 
         b = conn.get_bucket(parsed_url.netloc, validate=False)
         if compat.PY2 and (compression == 'gzip' or
