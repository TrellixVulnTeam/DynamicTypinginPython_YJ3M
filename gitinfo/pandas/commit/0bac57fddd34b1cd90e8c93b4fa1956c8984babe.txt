commit 0bac57fddd34b1cd90e8c93b4fa1956c8984babe
Author: jreback <jeff@reback.net>
Date:   Tue May 21 19:02:14 2013 -0400

    BUG: inserting dups into blocks ok
    
    CLN: finished duplicate item insert/delete - whoosh! (GH3679)
    
    BUG: insert almost working
    
    BUG: fixed insertion of dup columns!
    
    ENH: added allow_duplicates kw to DataFrame.insert to indicate that inserting of
    
         a duplicate column should be allowed (default is False)

diff --git a/RELEASE.rst b/RELEASE.rst
index 38a8b42fc..7607954e3 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -102,6 +102,8 @@ pandas 0.11.1
     GH3675_, GH3676_).
   - Deprecated display.height, display.width is now only a formatting option
     does not control triggering of summary, similar to < 0.11.0.
+  - Add the keyword ``allow_duplicates`` to ``DataFrame.insert`` to allow a duplicate column
+    to be inserted if ``True``, default is ``False`` (same as prior to 0.11.1) (GH3679_)
 
 **Bug Fixes**
 
@@ -133,6 +135,7 @@ pandas 0.11.1
     - Duplicate indexes with and empty DataFrame.from_records will return a correct frame (GH3562_)
     - Concat to produce a non-unique columns when duplicates are across dtypes is fixed (GH3602_)
     - Non-unique indexing with a slice via ``loc`` and friends fixed (GH3659_)
+    - Allow insert/delete to non-unique columns (GH3679_)
   - Fixed bug in groupby with empty series referencing a variable before assignment. (GH3510_)
   - Fixed bug in mixed-frame assignment with aligned series (GH3492_)
   - Fixed bug in selecting month/quarter/year from a series would not select the time element
@@ -242,6 +245,8 @@ pandas 0.11.1
 .. _GH3606: https://github.com/pydata/pandas/issues/3606
 .. _GH3659: https://github.com/pydata/pandas/issues/3659
 .. _GH3649: https://github.com/pydata/pandas/issues/3649
+.. _GH3679: https://github.com/pydata/pandas/issues/3679
+.. _Gh3616: https://github.com/pydata/pandas/issues/3616
 .. _GH1818: https://github.com/pydata/pandas/issues/1818
 .. _GH3572: https://github.com/pydata/pandas/issues/3572
 .. _GH3582: https://github.com/pydata/pandas/issues/3582
diff --git a/doc/source/v0.11.1.txt b/doc/source/v0.11.1.txt
index ac769ed2f..bd4a7c49f 100644
--- a/doc/source/v0.11.1.txt
+++ b/doc/source/v0.11.1.txt
@@ -71,6 +71,8 @@ API changes
     ``DataFrame.fillna()`` and ``DataFrame.replace()`` instead. (GH3582_,
     GH3675_, GH3676_)
 
+  - Add the keyword ``allow_duplicates`` to ``DataFrame.insert`` to allow a duplicate column
+    to be inserted if ``True``, default is ``False`` (same as prior to 0.11.1) (GH3679_)
 
 Enhancements
 ~~~~~~~~~~~~
@@ -209,6 +211,7 @@ Bug Fixes
       and handle missing elements like unique indices (GH3561_)
     - Duplicate indexes with and empty DataFrame.from_records will return a correct frame (GH3562_)
     - Concat to produce a non-unique columns when duplicates are across dtypes is fixed (GH3602_)
+    - Allow insert/delete to non-unique columns (GH3679_)
 
     For example you can do
 
@@ -270,3 +273,4 @@ on GitHub for a complete list.
 .. _GH3676: https://github.com/pydata/pandas/issues/3676
 .. _GH3675: https://github.com/pydata/pandas/issues/3675
 .. _GH3682: https://github.com/pydata/pandas/issues/3682
+.. _GH3679: https://github.com/pydata/pandas/issues/3679
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 68edceb29..458197d43 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -2162,10 +2162,10 @@ class DataFrame(NDFrame):
         value = self._sanitize_column(key, value)
         NDFrame._set_item(self, key, value)
 
-    def insert(self, loc, column, value):
+    def insert(self, loc, column, value, allow_duplicates=False):
         """
-        Insert column into DataFrame at specified location. Raises Exception if
-        column is already contained in the DataFrame
+        Insert column into DataFrame at specified location.
+        if allow_duplicates is False, Raises Exception if column is already contained in the DataFrame
 
         Parameters
         ----------
@@ -2175,7 +2175,7 @@ class DataFrame(NDFrame):
         value : int, Series, or array-like
         """
         value = self._sanitize_column(column, value)
-        self._data.insert(loc, column, value)
+        self._data.insert(loc, column, value, allow_duplicates=allow_duplicates)
 
     def _sanitize_column(self, key, value):
         # Need to make sure new columns (which go into the BlockManager as new
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index ca04bd3fe..a7758af07 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -71,6 +71,10 @@ class Block(object):
             self._ref_locs = indexer
         return self._ref_locs
 
+    def reset_ref_locs(self):
+        """ reset the block ref_locs """
+        self._ref_locs = np.empty(len(self.items),dtype='int64')
+
     def set_ref_locs(self, placement):
         """ explicity set the ref_locs indexer, only necessary for duplicate indicies """
         if placement is not None:
@@ -129,7 +133,11 @@ class Block(object):
         values = self.values
         if deep:
             values = values.copy()
-        return make_block(values, self.items, self.ref_items, klass=self.__class__, fastpath=True)
+        block = make_block(values, self.items, self.ref_items, klass=self.__class__, fastpath=True)
+        ref_locs = getattr(self,'_ref_locs',None)
+        if ref_locs is not None:
+            block.set_ref_locs(ref_locs.copy())
+        return block
 
     def merge(self, other):
         if not self.ref_items.equals(other.ref_items):
@@ -201,31 +209,6 @@ class Block(object):
         new_values = np.delete(self.values, loc, 0)
         return make_block(new_values, new_items, self.ref_items, klass=self.__class__, fastpath=True)
 
-    def split_block_at(self, item):
-        """
-        Split block into zero or more blocks around columns with given label,
-        for "deleting" a column without having to copy data by returning views
-        on the original array.
-
-        Returns
-        -------
-        generator of Block
-        """
-        loc = self.items.get_loc(item)
-
-        if type(loc) == slice or type(loc) == int:
-            mask = [True] * len(self)
-            mask[loc] = False
-        else:  # already a mask, inverted
-            mask = -loc
-
-        for s, e in com.split_ranges(mask):
-            yield make_block(self.values[s:e],
-                             self.items[s:e].copy(),
-                             self.ref_items,
-                             klass=self.__class__,
-                             fastpath=True)
-
     def fillna(self, value, inplace=False, downcast=None):
         if not self._can_hold_na:
             if inplace:
@@ -1031,11 +1014,11 @@ class BlockManager(object):
     def ndim(self):
         return len(self.axes)
 
-    def set_axis(self, axis, value):
+    def set_axis(self, axis, value, maybe_rename=True):
         cur_axis = self.axes[axis]
         value = _ensure_index(value)
 
-        if len(value) != len(cur_axis):
+        if maybe_rename and len(value) != len(cur_axis):
             raise Exception('Length mismatch (%d vs %d)'
                             % (len(value), len(cur_axis)))
 
@@ -1049,11 +1032,33 @@ class BlockManager(object):
 
             # take via ref_locs
             for block in self.blocks:
-                block.set_ref_items(self.items, maybe_rename=True)
+                block.set_ref_items(self.items, maybe_rename=maybe_rename)
 
             # set/reset ref_locs based on the new index
             self._set_ref_locs(labels=value, do_refs=True)
 
+
+    def _reset_ref_locs(self):
+        """ take the current _ref_locs and reset ref_locs on the blocks
+            to correctly map, ignoring Nones;
+            reset both _items_map and _ref_locs """
+
+        if self.items.is_unique: return
+        
+        # let's reset the ref_locs in individual blocks
+        for b in self.blocks:
+            b.reset_ref_locs()
+
+        # reset the ref_locs on the individual blocks
+        item_count = 0
+        for v in self._ref_locs:
+            if v is not None:
+                block, item_loc = v
+                block._ref_locs[item_loc] = item_count
+                item_count += 1
+        self._ref_locs  = None
+        self._items_map = None
+
     def _set_ref_locs(self, labels=None, do_refs=False):
         """
         if we have a non-unique index on this axis, set the indexers
@@ -1092,13 +1097,6 @@ class BlockManager(object):
             if im is None:
 
                 im = dict()
-                def maybe_create_block(block):
-                    try:
-                        return d[block]
-                    except:
-                        im[block] = l = [ None ] * len(block.items)
-                    return l
-
                 count_items = 0
                 for block in self.blocks:
 
@@ -1111,7 +1109,7 @@ class BlockManager(object):
                     except:
                         rl = np.arange(num_items) + count_items
 
-                    m = maybe_create_block(block)
+                    m = maybe_create_block_in_items_map(im,block)
                     for i, item in enumerate(block.items):
                         m[i] = rl[i]
                     count_items += num_items
@@ -1123,7 +1121,7 @@ class BlockManager(object):
             for block, items in im.items():
                 for i, loc in enumerate(items):
                     rl[loc] = (block,i)
-            self._ref_locs = rl
+            self._ref_locs = rl.tolist()
             return rl
 
         # return our cached _ref_locs (or will compute again 
@@ -1147,20 +1145,13 @@ class BlockManager(object):
         im = dict()
         rl = self._set_ref_locs()
 
-        def maybe_create_block(block):
-            try:
-                return im[block]
-            except:
-                im[block] = l = [ None ] * len(block.items)
-            return l
-
         # we have a non-duplicative index
         if rl is None:
 
             axis = self.axes[0]
             for block in self.blocks:
 
-                m = maybe_create_block(block)
+                m = maybe_create_block_in_items_map(im,block)
                 for i, item in enumerate(block.items):
                     m[i] = axis.get_loc(item)
 
@@ -1170,7 +1161,7 @@ class BlockManager(object):
 
             for i, (block, idx) in enumerate(rl):
                 
-                m = maybe_create_block(block)
+                m = maybe_create_block_in_items_map(im,block)
                 m[idx] = i
 
         self._items_map = im
@@ -1640,7 +1631,15 @@ class BlockManager(object):
 
     def _consolidate_inplace(self):
         if not self.is_consolidated():
+
             self.blocks = _consolidate(self.blocks, self.items)
+
+            # reset our mappings
+            if not self.items.is_unique:
+                self._ref_locs = None
+                self._items_map = None
+                self._set_ref_locs(do_refs=True)
+
             self._is_consolidated = True
             self._known_consolidated = True
 
@@ -1672,18 +1671,37 @@ class BlockManager(object):
         return blk.values[full_loc]
 
     def delete(self, item):
-        i, _ = self._find_block(item)
+
+        is_unique = self.items.is_unique
         loc = self.items.get_loc(item)
 
-        self._delete_from_block(i, item)
-        if com._is_bool_indexer(loc):  # dupe keys may return mask
+        # dupe keys may return mask
+        if com._is_bool_indexer(loc):
             loc = [i for i, v in enumerate(loc) if v]
+        elif isinstance(loc,slice):
+            loc = range(loc.start,loc.stop)
 
-        new_items = self.items.delete(loc)
+        if isinstance(loc, (list,tuple,np.ndarray)):
 
+            # the blocks are changing each iteration!
+            for l in loc:
+                for i, b in enumerate(self.blocks):
+                    if item in b.items:
+                        self._delete_from_block(i, item)
+    
+        else:
+            i, _ = self._find_block(item)
+            self._delete_from_block(i, item)
+    
+        # _ref_locs, and _items_map are good here
+        new_items = self.items.delete(loc)
         self.set_items_norename(new_items)
+
         self._known_consolidated = False
 
+        if not is_unique:
+            self._consolidate_inplace()
+
     def set(self, item, value):
         """
         Set new item in-place. Does not consolidate. Adds new Block if not
@@ -1720,8 +1738,9 @@ class BlockManager(object):
 
         self._known_consolidated = False
 
-    def insert(self, loc, item, value):
-        if item in self.items:
+    def insert(self, loc, item, value, allow_duplicates=False):
+
+        if not allow_duplicates and item in self.items:
             raise Exception('cannot insert %s, already exists' % item)
 
         try:
@@ -1747,20 +1766,71 @@ class BlockManager(object):
         self._known_consolidated = False
 
     def set_items_norename(self, value):
-        value = _ensure_index(value)
-        self.axes[0] = value
-
-        for block in self.blocks:
-            block.set_ref_items(value, maybe_rename=False)
+        self.set_axis(0, value, maybe_rename=False)
 
     def _delete_from_block(self, i, item):
         """
         Delete and maybe remove the whole block
+
+        Remap the split blocks to there old ranges,
+        so after this function, _ref_locs and _items_map (if used)
+        are correct for the items, None fills holes in _ref_locs
         """
-        block = self.blocks.pop(i)
-        for b in block.split_block_at(item):
-            self.blocks.append(b)
+        block     = self.blocks.pop(i)
+        ref_locs  = self._set_ref_locs()
+        prev_items_map = self._items_map.pop(block) if ref_locs is not None else None
+
+        # compute the split mask
+        loc = block.items.get_loc(item)
+        if type(loc) == slice or com.is_integer(loc):
+            mask = np.array([True] * len(block))
+            mask[loc] = False
+        else:  # already a mask, inverted
+            mask = -loc
+
+        # split the block
+        counter = 0
+        for s, e in com.split_ranges(mask):
+
+            sblock = make_block(block.values[s:e],
+                                block.items[s:e].copy(),
+                                block.ref_items,
+                                klass=block.__class__,
+                                fastpath=True)
+
+            self.blocks.append(sblock)
+
+            # update the _ref_locs/_items_map
+            if ref_locs is not None:
+
+                # fill the item_map out for this sub-block
+                m = maybe_create_block_in_items_map(self._items_map,sblock)
+                for j, itm in enumerate(sblock.items):
+
+                    # is this item masked (e.g. was deleted)?
+                    while (True):
 
+                        if counter > len(mask) or mask[counter]:
+                            break
+                        else:
+                            counter += 1
+
+                    # find my mapping location
+                    m[j] = prev_items_map[counter]
+                    counter += 1
+
+                # set the ref_locs in this block
+                sblock.set_ref_locs(m)
+
+        # reset the ref_locs to the new structure
+        if ref_locs is not None:
+
+            # items_map is now good, with the original locations
+            self._set_ref_locs(do_refs=True)
+
+            # reset the ref_locs based on the now good block._ref_locs
+            self._reset_ref_locs()
+            
     def _add_new_block(self, item, value, loc=None):
         # Do we care about dtype at the moment?
 
@@ -1771,6 +1841,26 @@ class BlockManager(object):
                                self.items, fastpath=True)
         self.blocks.append(new_block)
 
+        # set ref_locs based on the this new block
+        # and add to the ref/items maps
+        if not self.items.is_unique:
+
+            # insert into the ref_locs at the appropriate location
+            # _ref_locs is already long enough,
+            # but may need to shift elements
+            new_block.set_ref_locs([0])
+
+            # need to shift elements to the right
+            if self._ref_locs[loc] is not None:
+                for i in reversed(range(loc+1,len(self._ref_locs))):
+                    self._ref_locs[i] = self._ref_locs[i-1]
+
+            self._ref_locs[loc] = (new_block, 0)
+            
+            # and reset
+            self._reset_ref_locs()
+            self._set_ref_locs(do_refs=True)
+            
     def _find_block(self, item):
         self._check_have(item)
         for i, block in enumerate(self.blocks):
@@ -2077,6 +2167,15 @@ def create_block_manager_from_arrays(arrays, names, axes):
     except (ValueError):
         construction_error(len(arrays),arrays[0].shape[1:],axes)
 
+def maybe_create_block_in_items_map(im,block):
+    """ create/return the block in an items_map """
+    try:
+        return im[block]
+    except:
+        im[block] = l = [ None ] * len(block.items)
+    return l
+
+
 def form_blocks(arrays, names, axes):
 
     # pre-filter out items if we passed it
@@ -2308,7 +2407,16 @@ def _merge_blocks(blocks, items, dtype=None):
     new_values = _vstack([ b.values for b in blocks ], dtype)
     new_items = blocks[0].items.append([b.items for b in blocks[1:]])
     new_block = make_block(new_values, new_items, items)
-    return new_block.reindex_items_from(items)
+
+    # unique, can reindex
+    if items.is_unique:
+        return new_block.reindex_items_from(items)
+
+    # merge the ref_locs
+    new_ref_locs = [ b._ref_locs for b in blocks ]
+    if all([ x is not None for x in new_ref_locs ]):
+        new_block.set_ref_locs(np.concatenate(new_ref_locs))
+    return new_block    
 
 
 def _block_shape(values, ndim=1, shape=None):
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 3711a814c..9e83e5f4e 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -2825,6 +2825,67 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                           [('a', [8]), ('a', [5]), ('b', [6])],
                           columns=['b', 'a', 'a'])
 
+
+    def test_column_duplicates_operations(self):
+        df = DataFrame([[1,1,1,5],[1,1,2,5],[2,1,3,5]],columns=['foo','bar','foo','hello'])
+
+        # insert
+        df['string'] = 'bah'
+        expected = DataFrame([[1,1,1,5,'bah'],[1,1,2,5,'bah'],[2,1,3,5,'bah']],columns=['foo','bar','foo','hello','string'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # insert same dtype
+        df['foo2'] = 3
+        expected = DataFrame([[1,1,1,5,'bah',3],[1,1,2,5,'bah',3],[2,1,3,5,'bah',3]],columns=['foo','bar','foo','hello','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # delete (non dup)
+        del df['bar']
+        expected = DataFrame([[1,1,5,'bah',3],[1,2,5,'bah',3],[2,3,5,'bah',3]],columns=['foo','foo','hello','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # try to delete again (its not consolidated)
+        del df['hello']
+        expected = DataFrame([[1,1,'bah',3],[1,2,'bah',3],[2,3,'bah',3]],columns=['foo','foo','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # consolidate
+        df = df.consolidate()
+        expected = DataFrame([[1,1,'bah',3],[1,2,'bah',3],[2,3,'bah',3]],columns=['foo','foo','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # insert
+        df.insert(2,'new_col',5.)
+        expected = DataFrame([[1,1,5.,'bah',3],[1,2,5.,'bah',3],[2,3,5.,'bah',3]],columns=['foo','foo','new_col','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # insert a dup
+        self.assertRaises(Exception, df.insert, 2, 'new_col', 4.)
+        df.insert(2,'new_col',4.,allow_duplicates=True)
+        expected = DataFrame([[1,1,4.,5.,'bah',3],[1,2,4.,5.,'bah',3],[2,3,4.,5.,'bah',3]],columns=['foo','foo','new_col','new_col','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
+        # delete (dup)
+        del df['foo']
+        expected = DataFrame([[4.,5.,'bah',3],[4.,5.,'bah',3],[4.,5.,'bah',3]],columns=['new_col','new_col','string','foo2'])
+        assert_frame_equal(df,expected)
+        df.dtypes
+        str(df)
+
     def test_constructor_single_value(self):
 
         # expecting single value upcasting here
diff --git a/pandas/tests/test_internals.py b/pandas/tests/test_internals.py
index e25bd0de7..3cafbc9d7 100644
--- a/pandas/tests/test_internals.py
+++ b/pandas/tests/test_internals.py
@@ -1,7 +1,7 @@
 # pylint: disable=W0102
 
 import unittest
-
+import nose
 import numpy as np
 
 from pandas import Index, MultiIndex, DataFrame, Series
@@ -173,6 +173,11 @@ class TestBlock(unittest.TestCase):
         self.assertRaises(Exception, self.fblock.delete, 'b')
 
     def test_split_block_at(self):
+
+        # with dup column support this method was taken out
+        # GH3679
+        raise nose.SkipTest
+
         bs = list(self.fblock.split_block_at('a'))
         self.assertEqual(len(bs), 1)
         self.assertTrue(np.array_equal(bs[0].items, ['c', 'e']))
