commit 1de23c437cd865e127ca4fe867d14779e84681e0
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Aug 27 18:58:04 2011 -0400

    DOC: reformatted release notes, deprecated DataFrame.tapply

diff --git a/LICENSE b/LICENSE
index a56695d6b..2206ea322 100644
--- a/LICENSE
+++ b/LICENSE
@@ -1,7 +1,7 @@
 Copyright (c) 2008-2011 AQR Capital Management, LLC
 All rights reserved.
 
-Copyright (c) 2011 pandas developers
+Copyright (c) 2011 Wes McKinney and pandas developers
 All rights reserved.
 
 Redistribution and use in source and binary forms, with or without
diff --git a/RELEASE.rst b/RELEASE.rst
index 75d5c4d8f..d9dcc5e8e 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -1,9 +1,7 @@
-
-************************
+========================
 pandas 0.4 Release Notes
-************************
+========================
 
-==========
 What is it
 ==========
 
@@ -14,7 +12,6 @@ statistical modeling and large, inhomogeneous data sets in mind. It is
 particularly well suited for, among other things, financial data analysis
 applications.
 
-===============
 Where to get it
 ===============
 
@@ -22,7 +19,6 @@ Source code: http://github.com/wesm/pandas
 Binary installers on PyPI: http://pypi.python.org/pypi/pandas
 Documentation: http://pandas.sourceforge.net
 
-=============
 Release notes
 =============
 
@@ -35,13 +31,17 @@ Release notes
   will result in significant performance boosts, and smaller memory
   footprint. Added `to_sparse` methods to `Series`, `DataFrame`, and
   `WidePanel`. See online documentation for more on these
+
 * Fancy indexing operator on Series / DataFrame, e.g. via .ix operator. Both
   getting and setting of values is supported; however, setting values will only
   currently work on homogeneously-typed DataFrame objects. Things like:
+
   * series.ix[[d1, d2, d3]]
   * frame.ix[5:10, ['C', 'B', 'A']], frame.ix[5:10, 'A':'C']
   * frame.ix[date1:date2]
+
 * Significantly enhanced `groupby` functionality
+
   * Can groupby multiple keys, e.g. df.groupby(['key1', 'key2']). Iteration with
     multiple groupings products a flattened tuple
   * "Nuisance" columns (non-aggregatable) will automatically be excluded from
@@ -49,44 +49,64 @@ Release notes
   * Added automatic "dispatching to Series / DataFrame methods to more easily
     invoke methods on groups. e.g. s.groupby(crit).std() will work even though
     `std` is not implemented on the `GroupBy` class
+
 * `Index` objects (labels for axes) are now capable of holding tuples
+
 * `Series.describe`, `DataFrame.describe`: produces an R-like table of summary
   statistics about each data column
+
 * `DataFrame.quantile`, `Series.quantile` for computing sample quantiles of data
   across requested axis
+
 * Added general `DataFrame.dropna` method to replace `dropIncompleteRows` and
   `dropEmptyRows`, deprecated those.
+
 * `Series` arithmetic methods with optional fill_value for missing data,
   e.g. a.add(b, fill_value=0). If a location is missing for both it will still
   be missing in the result though.
+
 * fill_value option has been added to `DataFrame`.{add, mul, sub, div} methods
   similar to `Series`
+
 * Boolean indexing with `DataFrame` objects: data[data > 0.1] = 0.1 or
   data[data> other] = 1.
+
 * `pytz` / tzinfo support in `DateRange`
+
   * `tz_localize`, `tz_normalize`, and `tz_validate` methods added
+
 * Added `ExcelFile` class to `pandas.io.parsers` for parsing multiple sheets out
   of a single Excel 2003 document
+
 * `GroupBy` aggregations can now optionally *broadcast*, e.g. produce an object
   of the same size with the aggregated value propagated
+
 * Added `select` function in all data structures: reindex axis based on
   arbitrary criterion (function returning boolean value),
   e.g. frame.select(lambda x: 'foo' in x, axis=1)
+
 * `DataFrame.consolidate` method, API function relating to redesigned internals
+
 * `DataFrame.insert` method for inserting column at a specified location rather
   than the default __setitem__ behavior (which puts it at the end)
+
 * `HDFStore` class in `pandas.io.pytables` has been largely rewritten using
   patches from Jeff Reback from others. It now supports mixed-type `DataFrame`
   and `Series` data and can store `WidePanel` objects. It also has the option to
   query `DataFrame` and `WidePanel` data. Loading data from legacy `HDFStore`
   files is supported explicitly in the code
+
 * Added `set_printoptions` method to modify appearance of DataFrame tabular
   output
+
 * `rolling_quantile` functions; a moving version of `Series.quantile` /
   `DataFrame.quantile`
+
 * Generic `rolling_apply` moving window function
+
 * New `drop` method added to `Series`, `DataFrame`, etc. which can drop a set of
   labels from an axis, producing a new object
+
 * `reindex` methods now sport a `copy` option so that data is not forced to be
   copied then the resulting object is indexed the same
 
@@ -96,37 +116,51 @@ Release notes
   redesigned internally into a single class `DataFrame`, preserving where
   possible their optimal performance characteristics. This should reduce
   confusion from users about which class to use.
+
   * Note that under ther hood there is a new essentially "lazy evaluation"
     scheme within respect to adding columns to DataFrame. During some
     operations, like-typed blocks will be "consolidated" but not before.
+
 * `DataFrame` accessing columns repeatedly is now significantly faster than
   `DataMatrix` used to be in 0.3.0 due to an internal Series caching mechanism
   (which are all views on the underlying data)
+
 * Column ordering for mixed type data is now completely consistent in
   `DataFrame`. In prior releases, there was inconsistent column ordering in
   `DataMatrix`
+
 * Improved console / string formatting of DataMatrix with negative numbers
+
 * Improved tabular data parsing functions, `read_table` and `read_csv`:
+
   * Added `skiprows` and `na_values` arguments to `pandas.io.parsers` functions
     for more flexible IO
   * `parseCSV` / `read_csv` functions and others in `pandas.io.parsers` now can
     take a list of custom NA values, and also a list of rows to skip
+
 * Can slice `DataFrame` and get a view of the data (when homogeneously typed),
   e.g. frame.xs(idx, copy=False) or frame.ix[idx]
+
 * Many speed optimizations throughout `Series` and `DataFrame`
+
 * Eager evaluation of groups when calling ``groupby`` functions, so if there is
   an exception with the grouping function it will raised immediately versus
   sometime later on when the groups are needed
+
 * `datetools.WeekOfMonth` offset can be parameterized with `n` different than 1
   or -1.
+
 * Statistical methods on DataFrame like `mean`, `std`, `var`, `skew` will now
   ignore non-numerical data. Before a not very useful error message was
   generated. A flag `numeric_only` has been added to `DataFrame.sum` and
   `DataFrame.count` to enable this behavior in those methods if so desired
   (disabled by default)
+
 * `DataFrame.pivot` generalized to enable pivoting multiple columns into a
   `WidePanel`
+
 * `DataFrame` constructor can accept structured / record arrays
+
 * `WidePanel` constructor can accept a dict of DataFrame-like objects. Do not
   need to use `from_dict` anymore (`from_dict` is there to stay, though).
 
@@ -134,59 +168,86 @@ Release notes
 
 * The `DataMatrix` variable now refers to `DataFrame`, will be removed within
   two releases
+
 * Cython is now required to build `pandas` from a development branch. This was
   done to avoid continuing to check in cythonized C files into source
   control. Builds from released source distributions will not require Cython
+
 * Cython code has been moved up to a top level `pandas/src` directory. Cython
   extension modules have been renamed and promoted from the `lib` subpackage to
   the top level, i.e.
+
   * `pandas.lib.tseries` -> `pandas._tseries`
   * `pandas.lib.sparse` -> `pandas._sparse`
+
 * `DataFrame` pickling format has changed. Backwards compatibility for legacy
   pickles is provided, but it's recommended to consider PyTables-based
   `HDFStore` for storing data with a longer expected shelf life
+
 * A `copy` argument has been added to the `DataFrame` constructor to avoid
   unnecessary copying of data. Data is no longer copied by default when passed
   into the constructor
+
 * Handling of boolean dtype in `DataFrame` has been improved to support storage
   of boolean data with NA / NaN values. Before it was being converted to float64
   so this should not (in theory) cause API breakage
+
 * To optimize performance, Index objects now only check that their labels are
   unique when uniqueness matters (i.e. when someone goes to perform a
   lookup). This is a potentially dangerous tradeoff, but will lead to much
   better performance in many places (like groupby).
+
 * Boolean indexing using Series must now have the same indices (labels)
+
 * Backwards compatibility support for begin/end/nPeriods keyword arguments in
   DateRange class has been removed
+
 * More intuitive / shorter filling aliases `ffill` (for `pad`) and `bfill` (for
   `backfill`) have been added to the functions that use them: `reindex`,
   `asfreq`, `fillna`.
+
 * `pandas.core.mixins` code moved to `pandas.core.generic`
+
 * `buffer` keyword arguments (e.g. `DataFrame.toString`) renamed to `buf` to
   avoid using Python built-in name
+
 * `DataFrame.rows()` removed (use `DataFrame.index`)
+
 * Added deprecation warning to `DataFrame.cols()`, to be removed in next release
+
 * `DataFrame` deprecations and de-camelCasing: `merge`, `asMatrix`,
   `toDataMatrix`, `_firstTimeWithValue`, `_lastTimeWithValue`, `toRecords`,
   `fromRecords`, `tgroupby`
+
 * `pandas.io.parsers` method deprecations
+
   * `parseCSV` is now `read_csv` and keyword arguments have been de-camelCased
   * `parseText` is now `read_table`
   * `parseExcel` is replaced by the `ExcelFile` class and its `parse` method
+
 * `fillMethod` arguments (deprecated in prior release) removed, should be
   replaced with `method`
+
 * `Series.fill`, `DataFrame.fill`, and `WidePanel.fill` removed, use `fillna`
   instead
+
 * `groupby` functions now exclude NA / NaN values from the list of groups. This
   matches R behavior with NAs in factors e.g. with the `tapply` function
+
 * Removed `parseText`, `parseCSV` and `parseExcel` from pandas namespace
+
 * `Series.combineFunc` renamed to `Series.combine` and made a bit more general
   with a `fill_value` keyword argument defaulting to NaN
+
 * Removed `pandas.core.pytools` module. Code has been moved to
   `pandas.core.common`
+
 * Tacked on `groupName` attribute for groups in GroupBy renamed to `name`
+
 * WidePanel/LongPanel `dims` attribute renamed to `shape` to be more conformant
+
 * Slicing a `Series` returns a view now
+
 * More Series deprecations / renaming: `toCSV` to `to_csv`, `asOf` to `asof`,
   `merge` to `map`, `applymap` to `apply`, `toDict` to `to_dict`,
   `combineFirst` to `combine_first`. Will print `FutureWarning`.
@@ -195,19 +256,31 @@ Release notes
 
 * Column ordering in `pandas.io.parsers.parseCSV` will match CSV in the presence
   of mixed-type data
+
 * Fixed handling of Excel 2003 dates in `pandas.io.parsers`
+
 * `DateRange` caching was happening with high resolution `DateOffset` objects,
   e.g. `DateOffset(seconds=1)`. This has been fixed
+
 * Fixed __truediv__ issue in `DataFrame`
+
 * Fixed `DataFrame.toCSV` bug preventing IO round trips in some cases
+
 * Fixed bug in `Series.plot` causing matplotlib to barf in exceptional cases
+
 * Disabled `Index` objects from being hashable, like ndarrays
+
 * Added `__ne__` implementation to `Index` so that operations like ts[ts != idx]
   will work
+
 * Added `__ne__` implementation to `DataFrame`
+
 * Bug / unintuitive result when calling `fillna` on unordered labels
+
 * Bug calling `sum` on boolean DataFrame
+
 * Bug fix when creating a DataFrame from a dict with scalar values
+
 * Series.{sum, mean, std, ...} now return NA/NaN when the whole Series is NA
 
 Thanks
diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index effe14022..545a30416 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -5,15 +5,18 @@
 Data structure basics
 *********************
 
-This is a quick, non-comprehensive overview of the fundamental data structures
-in pandas to get you started. The fundamental behavior about data types,
-indexing, and axis labeling / alignment apply across all of the objects. To get
-started, load pandas into your namespace:
+We'll start with a quick, non-comprehensive overview of the fundamental data
+structures in pandas to get you started. The fundamental behavior about data
+types, indexing, and axis labeling / alignment apply across all of the
+objects. To get started, import numpy and load pandas into your namespace:
 
 .. ipython:: python
 
+   import numpy as np
    from pandas import *
 
+Here is a basic tenet to keep in mind: **data alignment is intrinsic**. Link
+between label and datum will not be broken unless done so explicitly by you.
 
 Series
 ------
@@ -41,7 +44,9 @@ len(data) - 1]``.
 
 .. ipython:: python
 
-   Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])
+   s = Series(np.random.randn(5), index=['a', 'b', 'c', 'd', 'e'])
+   s
+
    Series(np.random.randn(5))
 
 **Case 2:** If **data** is a dict, if **index** is passed the values in data**
@@ -65,13 +70,148 @@ will be repeated to match the length of **index**
 
    Series(5., index=['a', 'b', 'c', 'd', 'e'])
 
+Series is ndarray-like
+~~~~~~~~~~~~~~~~~~~~~~
+
+As a subclass of ndarray, Series is a valid argument to most NumPy functions
+and behaves similarly to a NumPy array. However, things like slicing also slice
+the index.
+
+.. ipython :: python
+
+    s[0]
+    s[:3]
+    s[s > s.median()]
+    s[[4, 3, 1]]
+    np.exp(s)
+
+Series is dict-like
+~~~~~~~~~~~~~~~~~~~
+
+A Series is alike a fixed-size dict in that you can get and set values by index
+label:
+
+.. ipython :: python
+
+    s['a']
+    s['e'] = 12.
+    s
+
+If a label is not contained, an exception
+
+.. code-block:: python
+
+    >>> s['f']
+    KeyError: 'f'
+
+    >>> s.get('f')
+    nan
+
+
+
 DataFrame
 ---------
 
 **DataFrame** is a 2-dimensional labeled data structure with columns of
 potentially different types. You can think of it like a spreadsheet or SQL
-table, or preferably a dict of Series objects. It is generally the most
-commonly used pandas object.
+table, or a dict of Series objects. It is generally the most commonly used
+pandas object. Like Series, DataFrame accepts many different kinds of input:
+
+ - Dict of 1D ndarrays, lists, or Series
+ - 2-D numpy.ndarray
+ - `Structured or record
+   <http://docs.scipy.org/doc/numpy/user/basics.rec.html>`__ ndarray
+ - Another DataFrame
+
+Along with the data, you can optionally pass **index** (row labels) and
+**columns** (column labels) arguments. If you pass an index and / or columns,
+you are guaranteeing the index and / or columns of the resulting
+DataFrame. Thus, a dict of Series plus a specific index will discard all data
+not matching up to the passed index.
+
+If axis labels are not passed, they will be constructed from the input data
+based on common sense rules. Here are the various cases:
+
+**Case 1, dict of Series**: the result **index** will be the **union** of the
+indexes of the various Series. If no columns are passed, the columns will be
+the sorted list of dict keys.
+
+.. ipython:: python
+
+    d = {'one' : Series([1., 2., 3.], index=['a', 'b', 'c']),
+         'two' : Series([1., 2., 3., 4.], index=['a', 'b', 'c', 'd'])}
+    DataFrame(d)
+    DataFrame(d, index=['d', 'b', 'a'])
+    DataFrame(d, index=['d', 'b', 'a'], columns=['two', 'three'])
+
+**Case 2, dict of ndarrays / lists**: The ndarrays must all be the same
+length. If an index is passed, it must clearly also be the same length as the
+arrays. If no index is passed, the result will be ``range(n)``, where ``n`` is
+the array length.
+
+.. ipython:: python
+
+    d = {'one' : [1., 2., 3., 4.],
+         'two' : [4., 3., 2., 1.]}
+    DataFrame(d)
+    DataFrame(d, index=['a', 'b', 'c', 'd'])
+
+**Case 3, structured or record array**: This case is handled identically to a
+dict of arrays.
+
+.. ipython:: python
+
+   data = np.zeros((2,),dtype=[('A', 'i4'),('B', 'f4'),('C', 'a10')])
+   data[:] = [(1,2.,'Hello'),(2,3.,"World")]
+
+   DataFrame(data)
+   DataFrame(data, index=['first', 'second'])
+   DataFrame(data, columns=['C', 'A', 'B'])
+
+Column selection, addition, deletion
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Indexing / Selection
+~~~~~~~~~~~~~~~~~~~~
+The basics of indexing are as follows:
+
+.. csv-table::
+    :header: "Operation", "Syntax", "Result"
+    :widths: 30, 20, 10
+
+    Select column, ``df[col]``, Series
+    Select row by label, ``df.xs(label)`` or ``df.ix[label]``, Series
+    Select row by location (int), ``df.ix[loc]``, Series
+    Slice rows, ``df[5:10]``, DataFrame
+    Select rows by boolean vector, ``df[bool_vec]``, DataFrame
+
+For a more exhaustive treatment of more sophisticated label-based indexing and
+slicing, see the `section on indexing <indexing>`__.
 
 WidePanel
 ---------
+
+WidePanel is a less-used, but still important container for 3-dimensional
+data. The term `panel data <http://en.wikipedia.org/wiki/Panel_data>`__ is
+derived from econometrics and is partially responsible for the name pandas:
+pan(el)-da(ta)-s.
+
+Binary operations between objects
+---------------------------------
+
+Alignment and reindexing
+------------------------
+
+Deleting labels from an axis
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Function application and basic stats
+------------------------------------
+
+Copying, type casting
+---------------------
+
+Pickling and serialization
+--------------------------
+
+
diff --git a/doc/source/conf.py b/doc/source/conf.py
index f6c6c4bd3..46d4b3f13 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -61,7 +61,7 @@ master_doc = 'index'
 
 # General information about the project.
 project = u'pandas'
-copyright = u'2008-2011, AQR, Wes McKinney'
+copyright = u'2008-2011, AQR and Wes McKinney'
 
 # The version info for the project you're documenting, acts as replacement for
 # |version| and |release|, also used in various other places throughout the
@@ -70,28 +70,6 @@ copyright = u'2008-2011, AQR, Wes McKinney'
 # The short X.Y version.
 import pandas
 
-# def svn_version():
-#     import os, subprocess, re, warnings
-#     env = os.environ.copy()
-#     env['LC_ALL'] = 'C'
-#     try:
-#         out = subprocess.Popen(['svn', 'info'], stdout=subprocess.PIPE,
-#                 env=env).communicate()[0]
-#     except OSError:
-#         warnings.warn(" --- Could not run svn info --- ")
-#         return ""
-
-#     r = re.compile('Revision: ([0-9]+)')
-#     svnver = None
-#     for line in out.split('\n'):
-#         m = r.match(line)
-#         if m:
-#             svnver = m.group(1)
-
-#     if not svnver:
-#         raise ValueError("Error while parsing svn version ?")
-#     return svnver
-
 # version = '%s r%s' % (pandas.__version__, svn_version())
 version = '%s' % (pandas.__version__)
 
diff --git a/doc/source/groupby.rst b/doc/source/groupby.rst
index e2a55fb29..597487d79 100644
--- a/doc/source/groupby.rst
+++ b/doc/source/groupby.rst
@@ -5,6 +5,16 @@
 Group by: split-apply-combine
 *****************************
 
+GroupBy is a process involving the following stages
+
+ - **Splitting** the data into groups based on some criteria
+ - **Applying** a function to each group independently
+ - **Combining** the results into a data structure
+
+Of these, the split step is the most straightforward. In fact, in many
+situations you may simply wish to split the data set into groups and do
+something with those groups yourself.
+
 
 When we talk about *group by* operations, we are referring to performing
 operations on subsets of a data structure determined by some group membership
@@ -233,3 +243,7 @@ Transformation
 
 Iterating through groups
 ------------------------
+
+Topical Examples
+----------------
+
diff --git a/doc/source/index.rst b/doc/source/index.rst
index fd22fd119..7313880b7 100755
--- a/doc/source/index.rst
+++ b/doc/source/index.rst
@@ -1,8 +1,23 @@
 .. Pandas documentation master file, created by
 
-
+*********************************************
 pandas: powerful Python data analysis library
-=============================================
+*********************************************
+
+.. note::
+
+    This documentation is currently (as of 8/26) undergoing heavy work. Check
+    back over the next week or two for continuous updates.
+
+`PDF Version <pandas.pdf>`__
+
+.. module:: pandas
+
+**Date**: |today| **Version**: |version|
+
+**Installers:** http://pypi.python.org/pypi/pandas
+
+**Code Repository:** http://github.com/wesm/pandas
 
 :mod:`pandas` is a `Python <http://www.python.org>`__ package providing fast,
 flexible, and expressive data structures designed to make working with
@@ -26,7 +41,7 @@ The two primary data structures of pandas, :class:`Series` (1-dimensional)
 and :class:`DataFrame` (2-dimensional), handle the vast majority of typical use
 cases in finance, statistics, social science, and many areas of
 engineering. For R users, :class:`DataFrame` provides everything that R's
-``data.frame`` provides and much more. pandas is build on top of `NumPy
+``data.frame`` provides and much more. pandas is built on top of `NumPy
 <http://www.numpy.org>`__ and is intended to integrate well within a scientific
 computing environment with many other 3rd party libraries.
 
@@ -74,7 +89,7 @@ Some other notes
    specialized tool.
 
  - pandas will soon become a dependency of `statsmodels
-   <http://statsmodels.sourceforge.net>`__, making it a important part of the
+   <http://statsmodels.sourceforge.net>`__, making it an important part of the
    statistical computing ecosystem in Python.
 
  - pandas has been used extensively in production in financial applications.
@@ -87,71 +102,25 @@ Some other notes
 
 See the package overview for more detail about what's in the library.
 
-User manual
------------
-
-`PDF Version <pandas.pdf>`__
-
-.. module:: pandas
-
-**Date**: |today|
-
-**Version**: |version|
-
-**License:** BSD
-
-**Requirements:** python 2.5 to 2.7, NumPy, and python-dateutil
-
-**Suggested:** scikits.statsmodels
-
-**Code Repository:** http://github.com/wesm/pandas
-
-Library documentation
----------------------
 
 .. toctree::
-    :maxdepth: 2
+    :hidden:
+    :maxdepth: 3
 
     install
     overview
     basics
     indexing
-    conform
+    missing_data
     groupby
     merging
     reshaping
     timeseries
     datetools
+	visualization
     stats
     io
-
-Other topics of interest
-------------------------
-
-.. toctree::
-    :maxdepth: 2
-
+    sparse
     r_interface
-    missing_data
     related
     faq
-
-Indices and tables
-------------------
-
-* :ref:`genindex`
-* :ref:`modindex`
-* :ref:`search`
-
-History
--------
-
-pandas development began at `AQR Capital Management <http://www.aqr.com>`__ in
-April 2008. It was open-sourced at the end of 2009 and continues to be actively
-used and maintained.
-
-Contact
--------
-
-Please feel free to send comments or questions directly to
-wesmckinn@gmail.com or the pystatsmodels mailing list.
diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 34d51dd93..c4883abe8 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -2,9 +2,9 @@
 
 .. currentmodule:: pandas
 
-**********************
-Indexing and selection
-**********************
+***************************
+Indexing and selecting data
+***************************
 
 Basics
 ------
diff --git a/doc/source/missing_data.rst b/doc/source/missing_data.rst
index 02c98169d..174b385ef 100644
--- a/doc/source/missing_data.rst
+++ b/doc/source/missing_data.rst
@@ -1,6 +1,19 @@
+.. currentmodule:: pandas
 .. _missing_data:
 
-***************************************
-Design issues for handling missing data
-***************************************
+*************************
+Working with missing data
+*************************
+
+Calculations with missing data
+------------------------------
+
+Cleaning missing data
+---------------------
+
+Dropping missing rows / columns
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Filling missing values
+~~~~~~~~~~~~~~~~~~~~~~
 
diff --git a/doc/source/overview.rst b/doc/source/overview.rst
index 54ca8a4cf..e79e18187 100644
--- a/doc/source/overview.rst
+++ b/doc/source/overview.rst
@@ -6,34 +6,41 @@
 Package overview
 ****************
 
-:mod:`pandas` is a library providing, among other things, a set of
-convenient and powerful data structures for working with labeled
-statistical (financial, economic, econometric) data sets. We will
-refer to this data as *time series* and *cross-sectional* (or
-*longitudinal*) which are common terms in statistics and
-econometrics. pandas has multiple target audiences:
-
- * Users of R or MATLAB who wish to switch to Python for interactive
-   data analysis and implementation of statistical models
-
- * NumPy users who are looking for richer data structures for working
-   with time series and cross-sectional data.
-
- * System developers who wish to have a robust and well-tested library
-   for building production applications involving such data sets.
+:mod:`pandas` consists of the following things
+
+ * A set of labeled array data structures, the primary of which are
+   Series/TimeSeries and DataFrame
+ * Index objects enabling both simple axis indexing and multi-level /
+   hierarchical axis indexing
+ * An integrated group by for aggregating and transforming data sets
+ * Date range generation (DateRange) and custom date offsets enabling the
+   implementation of customized frequencies
+ * Input/Output tools: loading tabular data from flat files (CSV, delimited,
+   Excel 2003), and saving and loading pandas objects from the fast and
+   efficient PyTables/HDF5 format.
+ * "Sparse" versions of the standard data structures for storing data that is
+   mostly missing or mostly constant (some fixed value)
+ * Moving window statistics (rolling mean, rolling standard deviation, etc.)
+ * Static and moving window linear and `panel regression
+   <http://en.wikipedia.org/wiki/Panel_data>`__
+
+License
+-------
+
+pandas is released under a standard 3-clause BSD license
 
 Data structures at a glance
 ---------------------------
 
 .. csv-table::
     :header: "Dimensions", "Name", "Description"
-    :widths: 10, 15, 50
+    :widths: 15, 20, 50
 
-    1, Series, "Most generic 1D structure"
-    1, TimeSeries, "Series indexed by datetimes"
-    2, DataFrame, "General 2D indexed tabular structure"
-    3, WidePanel, "General 3D panel data"
-    3, LongPanel, "Stacked (2D) format panel data"
+    1, Series, "1D labeled homogeneously-typed array"
+    1, TimeSeries, "Series with index containing datetimes"
+    2, DataFrame, "General 2D labeled, size-mutable tabular structure with
+    potentially heterogeneously-typed columns"
+    3, WidePanel, "General 3D labeled, also size-mutable array"
 
 Why more than 1 data structure?
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -46,46 +53,44 @@ insert and remove objects from these containers in a dictionary-like fashion.
 Also, we would like sensible default behaviors for the common API functions
 which take into account the typical orientation of time series and
 cross-sectional data sets. When using ndarrays to store 2- and 3-dimensional
-data, a burden is placed on the user to consider the orientation of the data set
-when writing functions; axes are considered more or less equivalent (except when
-C- or Fortran-contiguousness matters for performance). In pandas, the axes are
-intended to lend more semantic meaning to the data; i.e., for a particular data
-set there is likely to be a "right" way to orient the data. The goal, then, is
-to reduce the amount of thought required to code up data transformations in
-downstream functions.
-
-Lest we be too hand-wavy, here are some common use cases to
-illustrate:
+data, a burden is placed on the user to consider the orientation of the data
+set when writing functions; axes are considered more or less equivalent (except
+when C- or Fortran-contiguousness matters for performance). In pandas, the axes
+are intended to lend more semantic meaning to the data; i.e., for a particular
+data set there is likely to be a "right" way to orient the data. The goal,
+then, is to reduce the amount of mental effort required to code up data
+transformations in downstream functions.
 
- (A) :ref:`DataFrame <dataframe>` containing multiple related time series
+For example, with tabular data (DataFrame) it is more semantically helpful to
+think of the **index** (the rows) and the **columns** rather than axis 0 and
+axis 1. And iterating through the columns of the DataFrame thus results in more
+readable code:
 
-  * **columns**: "data type" associated with each time series
-  * **index**:  dates shared by time series
+::
 
- (B) :ref:`DataFrame <dataframe>` containing multiple cross-sections
+    for col in df.columns:
+        series = df[col]
+        # do something with series
 
-  * **columns**: "data type" associated with each cross-section
-  * **index**:  individual / entity labels common to cross-sections
+Mutability and copying of data
+------------------------------
 
- (C) :ref:`WidePanel <panel>` containing panel data
+All pandas data structures are value-mutable (the values they contain can be
+altered) but not always size-mutable. The length of a Series cannot be changed,
+but, for example, columns can be inserted into a DataFrame. However, the vast
+majority of methods produce new objects and leave the input data untouched. In
+general, though, we like to **favor immutability** where sensible.
 
-  * **items**: "data type" associated with each collection of time series
-  * **major_axis**: dates shared by time series
-  * **minor_axis**: individual / entity labels common to time series
 
-Lastly, particularly if you don't buy the above explanation, having a
-specialized vocabulary to refer to types of data sets often serves as
-a benefit when discussing a dataset with other users (or reading their
-code).
+History
+-------
 
-A quick note on mutation
-~~~~~~~~~~~~~~~~~~~~~~~~
+pandas development began at `AQR Capital Management <http://www.aqr.com>`__ in
+April 2008. It was open-sourced at the end of 2009 and continues to be actively
+used and maintained.
 
-Most instance methods on the pandas data structures return a new
-object, rather than updating the original object in-place. However,
-when working with the contents (e.g. a column in a DataFrame),
-mutations **will** be reflected in the original structure. In general,
-though, we like to "favor immutability" where sensible.
+Contact
+-------
 
-What else is in the package?
-----------------------------
+Please feel free to send comments or questions directly to Wes McKinney at
+wesmckinn (-at-) gmail (-dot-) com or the pystatsmodels mailing list.
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 20c3ebe1b..180688fa2 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1904,12 +1904,6 @@ class DataFrame(NDFrame):
 
         return panel
 
-    def tapply(self, func):
-        """
-        Apply func to the transposed DataFrame, results as per apply
-        """
-        return self.apply(func, axis=1)
-
     def applymap(self, func):
         """
         Apply a function to a DataFrame that is intended to operate
@@ -2773,6 +2767,14 @@ class DataFrame(NDFrame):
         else:
             return self.dropna(axis=0, subset=specificColumns, thresh=minObs)
 
+    def tapply(self, func):
+        """
+        Apply func to the transposed DataFrame, results as per apply
+        """
+        warnings.warn("tapply is deprecated. Use apply(f, axis=1)",
+                      FutureWarning)
+        return self.apply(func, axis=1)
+
     def tgroupby(self, keyfunc, applyfunc):  # pragma: no cover
         """
         Aggregate columns based on passed function
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 1caa934a2..5e5dd5b6c 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -105,6 +105,8 @@ class Series(np.ndarray, PandasObject):
     dtype : numpy.dtype or None
         If None, dtype will be inferred copy : boolean, default False Copy
         input data
+    copy : boolean, default False
+
     """
     _AXIS_NUMBERS = {
         'index' : 0
