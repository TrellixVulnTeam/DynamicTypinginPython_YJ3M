commit 491e3c3dffad6016ad79f36776ea3efcefa89d66
Author: jreback <jeff@reback.net>
Date:   Mon Aug 19 10:00:36 2013 -0400

    TST: GH4604, reindexing with a method of 'ffill' gives incorrect results
    
    BUG/CLN: (GH4604) Refactor Series.reindex to core/generic.py allow method= in reindexing
      on a Series to work
    
    API/CLN: GH4604 Infer and downcast dtype if appropriate on ffill/bfill
      this is for consistency when doing: df.reindex().ffill() and df.reindex(method='ffill')
    
    CLN: allow backfill/pad/interpolate to operate on integers (by float conversion)
         provide downcasting back to original dtype where needed core.internals.interpolate
    
    ENH: provide core.index.identical method to compare values and attributes similar to .equals
    
    API: changed back to pre-GH3482 where a reindex with no args will by default copy

diff --git a/doc/source/release.rst b/doc/source/release.rst
index 390c6e857..ec2117223 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -144,8 +144,6 @@ See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
   - support attribute access for setting
   - filter supports same api as original ``DataFrame`` filter
 
-- Reindex called with no arguments will now return a copy of the input object
-
 - Series now inherits from ``NDFrame`` rather than directly from ``ndarray``.
   There are several minor changes that affect the API.
 
@@ -185,6 +183,11 @@ See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
 
 - Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)
 
+- Refactor Series.reindex to core/generic.py (:issue:`4604`), allow ``method=`` in reindexing
+  on a Series to work
+
+- Infer and downcast dtype if appropriate on ``ffill/bfill`` (:issue:`4604`)
+
 **Experimental Features**
 
 **Bug Fixes**
@@ -210,7 +213,7 @@ See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
   - In ``to_json``, raise if a passed ``orient`` would cause loss of data because
     of a duplicate index (:issue:`4359`)
   - In ``to_json``, fix date handling so milliseconds are the default timestamp
-    as the docstring says (:issue:`4362`). 
+    as the docstring says (:issue:`4362`).
   - JSON NaT handling fixed, NaTs are now serialised to `null` (:issue:`4498`)
   - Fixed passing ``keep_default_na=False`` when ``na_values=None`` (:issue:`4318`)
   - Fixed bug with ``values`` raising an error on a DataFrame with duplicate columns and mixed
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index 9776c3e46..34733e03d 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -237,6 +237,11 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
 
 - Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)
 
+- Refactor Series.reindex to core/generic.py (:issue:`4604`), allow ``method=`` in reindexing
+  on a Series to work
+
+- Infer and downcast dtype if appropriate on ``ffill/bfill`` (:issue:`4604`)
+
 Bug Fixes
 ~~~~~~~~~
 
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 5765340f2..2bfdaccb3 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -961,16 +961,43 @@ def _possibly_downcast_to_dtype(result, dtype):
     """ try to cast to the specified dtype (e.g. convert back to bool/int
         or could be an astype of float64->float32 """
 
-    if np.isscalar(result):
+    if np.isscalar(result) or not len(result):
         return result
 
+    if isinstance(dtype, compat.string_types):
+        if dtype == 'infer':
+            inferred_type = lib.infer_dtype(_ensure_object(result.ravel()))
+            if inferred_type == 'boolean':
+                dtype = 'bool'
+            elif inferred_type == 'integer':
+                dtype = 'int64'
+            elif inferred_type == 'datetime64':
+                dtype = 'datetime64[ns]'
+            elif inferred_type == 'timedelta64':
+                dtype = 'timedelta64[ns]'
+
+            # try to upcast here
+            elif inferred_type == 'floating':
+                dtype = 'int64'
+
+            else:
+                dtype = 'object'
+
+    if isinstance(dtype, compat.string_types):
+        dtype = np.dtype(dtype)
+
     try:
         if issubclass(dtype.type, np.floating):
             return result.astype(dtype)
         elif dtype == np.bool_ or issubclass(dtype.type, np.integer):
-            if issubclass(result.dtype.type, np.number) and notnull(result).all():
+            if issubclass(result.dtype.type, (np.object_,np.number)) and notnull(result).all():
                 new_result = result.astype(dtype)
                 if (new_result == result).all():
+
+                    # a comparable, e.g. a Decimal may slip in here
+                    if not isinstance(result.ravel()[0], (np.integer,np.floating,np.bool,int,float,bool)):
+                        return result
+
                     return new_result
     except:
         pass
@@ -1052,6 +1079,9 @@ def pad_1d(values, limit=None, mask=None):
         _method = getattr(algos, 'pad_inplace_%s' % dtype, None)
     elif is_datetime64_dtype(values):
         _method = _pad_1d_datetime
+    elif is_integer_dtype(values):
+        values = _ensure_float64(values)
+        _method = algos.pad_inplace_float64
     elif values.dtype == np.object_:
         _method = algos.pad_inplace_object
 
@@ -1062,7 +1092,7 @@ def pad_1d(values, limit=None, mask=None):
         mask = isnull(values)
     mask = mask.view(np.uint8)
     _method(values, mask, limit=limit)
-
+    return values
 
 def backfill_1d(values, limit=None, mask=None):
 
@@ -1072,6 +1102,9 @@ def backfill_1d(values, limit=None, mask=None):
         _method = getattr(algos, 'backfill_inplace_%s' % dtype, None)
     elif is_datetime64_dtype(values):
         _method = _backfill_1d_datetime
+    elif is_integer_dtype(values):
+        values = _ensure_float64(values)
+        _method = algos.backfill_inplace_float64
     elif values.dtype == np.object_:
         _method = algos.backfill_inplace_object
 
@@ -1083,7 +1116,7 @@ def backfill_1d(values, limit=None, mask=None):
     mask = mask.view(np.uint8)
 
     _method(values, mask, limit=limit)
-
+    return values
 
 def pad_2d(values, limit=None, mask=None):
 
@@ -1093,6 +1126,9 @@ def pad_2d(values, limit=None, mask=None):
         _method = getattr(algos, 'pad_2d_inplace_%s' % dtype, None)
     elif is_datetime64_dtype(values):
         _method = _pad_2d_datetime
+    elif is_integer_dtype(values):
+        values = _ensure_float64(values)
+        _method = algos.pad_2d_inplace_float64
     elif values.dtype == np.object_:
         _method = algos.pad_2d_inplace_object
 
@@ -1108,7 +1144,7 @@ def pad_2d(values, limit=None, mask=None):
     else:
         # for test coverage
         pass
-
+    return values
 
 def backfill_2d(values, limit=None, mask=None):
 
@@ -1118,6 +1154,9 @@ def backfill_2d(values, limit=None, mask=None):
         _method = getattr(algos, 'backfill_2d_inplace_%s' % dtype, None)
     elif is_datetime64_dtype(values):
         _method = _backfill_2d_datetime
+    elif is_integer_dtype(values):
+        values = _ensure_float64(values)
+        _method = algos.backfill_2d_inplace_float64
     elif values.dtype == np.object_:
         _method = algos.backfill_2d_inplace_object
 
@@ -1133,7 +1172,7 @@ def backfill_2d(values, limit=None, mask=None):
     else:
         # for test coverage
         pass
-
+    return values
 
 def interpolate_2d(values, method='pad', axis=0, limit=None, missing=None):
     """ perform an actual interpolation of values, values will be make 2-d if needed
@@ -1153,10 +1192,11 @@ def interpolate_2d(values, method='pad', axis=0, limit=None, missing=None):
     else:  # todo create faster fill func without masking
         mask = mask_missing(transf(values), missing)
 
+    method = _clean_fill_method(method)
     if method == 'pad':
-        pad_2d(transf(values), limit=limit, mask=mask)
+        values = transf(pad_2d(transf(values), limit=limit, mask=mask))
     else:
-        backfill_2d(transf(values), limit=limit, mask=mask)
+        values = transf(backfill_2d(transf(values), limit=limit, mask=mask))
 
     # reshape back
     if ndim == 1:
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 91c5804d4..f84582457 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -1003,11 +1003,15 @@ class NDFrame(PandasObject):
             except:
                 pass
 
-        # perform the reindex on the axes
-        if copy and not com._count_not_none(*axes.values()):
-            return self.copy()
+        # if all axes that are requested to reindex are equal, then only copy if indicated
+        # must have index names equal here as well as values
+        if all([ self._get_axis(axis).identical(ax) for axis, ax in axes.items() if ax is not None ]):
+            if copy:
+                return self.copy()
+            return self
 
-        return self._reindex_axes(axes, level, limit, method, fill_value, copy, takeable=takeable)
+        # perform the reindex on the axes
+        return self._reindex_axes(axes, level, limit, method, fill_value, copy, takeable=takeable)._propogate_attributes(self)
 
     def _reindex_axes(self, axes, level, limit, method, fill_value, copy, takeable=False):
         """ perform the reinxed for all the axes """
@@ -1025,7 +1029,8 @@ class NDFrame(PandasObject):
             new_index, indexer = self._get_axis(a).reindex(
                 labels, level=level, limit=limit, takeable=takeable)
             obj = obj._reindex_with_indexers(
-                {axis: [labels, indexer]}, method, fill_value, copy)
+                {axis: [new_index, indexer]}, method=method, fill_value=fill_value,
+                limit=limit, copy=copy)
 
         return obj
 
@@ -1079,9 +1084,10 @@ class NDFrame(PandasObject):
         axis_values = self._get_axis(axis_name)
         new_index, indexer = axis_values.reindex(labels, method, level,
                                                  limit=limit, copy_if_needed=True)
-        return self._reindex_with_indexers({axis: [new_index, indexer]}, method, fill_value, copy)
+        return self._reindex_with_indexers({axis: [new_index, indexer]}, method=method, fill_value=fill_value,
+                                           limit=limit, copy=copy)._propogate_attributes(self)
 
-    def _reindex_with_indexers(self, reindexers, method=None, fill_value=np.nan, copy=False):
+    def _reindex_with_indexers(self, reindexers, method=None, fill_value=np.nan, limit=None, copy=False):
 
         # reindex doing multiple operations on different axes if indiciated
         new_data = self._data
@@ -1089,11 +1095,15 @@ class NDFrame(PandasObject):
             index, indexer = reindexers[axis]
             baxis = self._get_block_manager_axis(axis)
 
+            if index is None:
+                continue
+            index = _ensure_index(index)
+
             # reindex the axis
             if method is not None:
                 new_data = new_data.reindex_axis(
                     index, method=method, axis=baxis,
-                    fill_value=fill_value, copy=copy)
+                    fill_value=fill_value, limit=limit, copy=copy)
 
             elif indexer is not None:
                 # TODO: speed up on homogeneous DataFrame objects
@@ -1435,14 +1445,20 @@ class NDFrame(PandasObject):
             if self._is_mixed_type and axis == 1:
                 if inplace:
                     raise NotImplementedError()
-                return self.T.fillna(method=method, limit=limit).T
+                result = self.T.fillna(method=method, limit=limit).T
+
+                # need to downcast here because of all of the transposes
+                result._data = result._data.downcast()
+
+                return result
 
             method = com._clean_fill_method(method)
             new_data = self._data.interpolate(method=method,
                                               axis=axis,
                                               limit=limit,
                                               inplace=inplace,
-                                              coerce=True)
+                                              coerce=True,
+                                              downcast=downcast)
         else:
             if method is not None:
                 raise ValueError('cannot specify both a fill method and value')
@@ -1474,11 +1490,11 @@ class NDFrame(PandasObject):
 
     def ffill(self, axis=0, inplace=False, limit=None):
         return self.fillna(method='ffill', axis=axis, inplace=inplace,
-                           limit=limit)
+                           limit=limit, downcast='infer')
 
     def bfill(self, axis=0, inplace=False, limit=None):
         return self.fillna(method='bfill', axis=axis, inplace=inplace,
-                           limit=limit)
+                           limit=limit, downcast='infer')
 
     def replace(self, to_replace=None, value=None, inplace=False, limit=None,
                 regex=False, method=None, axis=None):
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 73aff7bca..aea168654 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -83,6 +83,7 @@ class Index(FrozenNDArray):
 
     name = None
     asi8 = None
+    _comparables = ['name']
 
     _engine_type = _index.ObjectEngine
 
@@ -545,6 +546,13 @@ class Index(FrozenNDArray):
 
         return np.array_equal(self, other)
 
+    def identical(self, other):
+        """
+        Similar to equals, but check that other comparable attributes are also equal
+        """
+        return self.equals(other) and all(
+            [ getattr(self,c,None) == getattr(other,c,None) for c in self._comparables ])
+
     def asof(self, label):
         """
         For a sorted index, return the most recent label up to and including
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index f1578303e..fb2776958 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -203,7 +203,7 @@ class Block(PandasObject):
             new_values, self.items, self.ref_items, ndim=self.ndim, fastpath=True,
             placement=self._ref_locs)
 
-    def reindex_items_from(self, new_ref_items, copy=True):
+    def reindex_items_from(self, new_ref_items, indexer=None, method=None, fill_value=None, limit=None, copy=True):
         """
         Reindex to only those items contained in the input set of items
 
@@ -214,16 +214,26 @@ class Block(PandasObject):
         -------
         reindexed : Block
         """
-        new_ref_items, indexer = self.items.reindex(new_ref_items)
+        if indexer is None:
+            new_ref_items, indexer = self.items.reindex(new_ref_items, limit=limit)
 
+        new_items = new_ref_items
         if indexer is None:
-            new_items = new_ref_items
             new_values = self.values.copy() if copy else self.values
         else:
-            masked_idx = indexer[indexer != -1]
-            new_values = com.take_nd(self.values, masked_idx, axis=0,
-                                     allow_fill=False)
-            new_items = self.items.take(masked_idx)
+            if fill_value is None:
+                fill_value = self.fill_value
+
+            # single block reindex
+            if self.ndim == 1:
+                new_values = com.take_nd(self.values, indexer, axis=0,
+                                         fill_value=fill_value)
+            else:
+                masked_idx = indexer[indexer != -1]
+                new_values = com.take_nd(self.values, masked_idx, axis=0,
+                                         allow_fill=False)
+                new_items = self.items.take(masked_idx)
+
         return make_block(new_values, new_items, new_ref_items, ndim=self.ndim, fastpath=True)
 
     def get(self, item):
@@ -305,22 +315,37 @@ class Block(PandasObject):
     def downcast(self, dtypes=None):
         """ try to downcast each item to the dict of dtypes if present """
 
+        values = self.values
+
+        # single block handling
+        if self._is_single_block:
+            if dtypes is None:
+                return [ self ]
+
+            nv = _possibly_downcast_to_dtype(values, dtypes)
+            return [ make_block(nv, self.items, self.ref_items, ndim=self.ndim, fastpath=True) ]
+
+        # ndim > 1
         if dtypes is None:
             dtypes = dict()
+        elif dtypes == 'infer':
+            pass
 
-        values = self.values
         blocks = []
         for i, item in enumerate(self.items):
 
-            dtype = dtypes.get(item, self._downcast_dtype)
+            if dtypes == 'infer':
+                dtype = 'infer'
+            else:
+                dtype = dtypes.get(item, self._downcast_dtype)
+
             if dtype is None:
                 nv = _block_shape(values[i])
-                blocks.append(make_block(nv, [item], self.ref_items))
-                continue
+            else:
+                nv = _possibly_downcast_to_dtype(values[i], dtype)
+                nv = _block_shape(nv)
 
-            nv = _possibly_downcast_to_dtype(values[i], np.dtype(dtype))
-            nv = _block_shape(nv)
-            blocks.append(make_block(nv, [item], self.ref_items))
+            blocks.append(make_block(nv, Index([item]), self.ref_items, ndim=self.ndim, fastpath=True))
 
         return blocks
 
@@ -578,7 +603,8 @@ class Block(PandasObject):
         return [make_block(new_values, self.items, self.ref_items, fastpath=True)]
 
     def interpolate(self, method='pad', axis=0, inplace=False,
-                    limit=None, missing=None, coerce=False):
+                    limit=None, fill_value=None, coerce=False,
+                    downcast=None):
 
         # if we are coercing, then don't force the conversion
         # if the block can't hold the type
@@ -590,8 +616,15 @@ class Block(PandasObject):
                     return [self.copy()]
 
         values = self.values if inplace else self.values.copy()
-        values = com.interpolate_2d(values, method, axis, limit, missing)
-        return [make_block(values, self.items, self.ref_items, ndim=self.ndim, klass=self.__class__, fastpath=True)]
+        values = com.interpolate_2d(values, method, axis, limit, fill_value)
+
+        block = make_block(values, self.items, self.ref_items, ndim=self.ndim, klass=self.__class__, fastpath=True)
+
+        # try to downcast back to original dtype if we can
+        # as we could have reindexed then down a ffill
+        if downcast is None:
+            downcast = 'infer'
+        return block.downcast(downcast)
 
     def take(self, indexer, ref_items, axis=1):
         if axis < 1:
@@ -1290,10 +1323,10 @@ class SparseBlock(Block):
         return make_block(new_values, items, ref_items, ndim=self.ndim, fastpath=fastpath)
 
     def interpolate(self, method='pad', axis=0, inplace=False,
-                    limit=None, missing=None, **kwargs):
+                    limit=None, fill_value=None, **kwargs):
 
         values = com.interpolate_2d(
-            self.values.to_dense(), method, axis, limit, missing)
+            self.values.to_dense(), method, axis, limit, fill_value)
         return self.make_block(values, self.items, self.ref_items)
 
     def fillna(self, value, inplace=False, downcast=None):
@@ -1336,7 +1369,7 @@ class SparseBlock(Block):
             fill_value = self.fill_value
         return self.make_block(self.values.take(indexer), items=self.items, fill_value=fill_value)
 
-    def reindex_items_from(self, new_ref_items, copy=True):
+    def reindex_items_from(self, new_ref_items, indexer=None, method=None, fill_value=None, limit=None, copy=True):
         """
         Reindex to only those items contained in the input set of items
 
@@ -1348,17 +1381,13 @@ class SparseBlock(Block):
         reindexed : Block
         """
 
-        # 2-d
-        if self.ndim >= 2:
-            if self.items[0] not in self.ref_items:
-                return None
-            return self.make_block(self.values, ref_items=new_ref_items, copy=copy)
-
-        # 1-d
-        new_ref_items, indexer = self.items.reindex(new_ref_items)
+        # 1-d always
+        if indexer is None:
+            new_ref_items, indexer = self.items.reindex(new_ref_items, limit=limit)
         if indexer is None:
             indexer = np.arange(len(self.items))
 
+        # note that we DO NOT FILL HERE
         return self.make_block(com.take_1d(self.values.values, indexer), items=new_ref_items, ref_items=new_ref_items, copy=copy)
 
     def sparse_reindex(self, new_index):
@@ -2522,15 +2551,18 @@ class BlockManager(PandasObject):
                 return self
 
         if axis == 0:
-            if method is not None:
-                raise AssertionError('method argument not supported for '
-                                     'axis == 0')
+            if method is not None or limit is not None:
+                return self.reindex_axis0_with_method(new_axis, method=method, fill_value=fill_value, limit=limit, copy=copy)
             return self.reindex_items(new_axis, copy=copy, fill_value=fill_value)
 
         new_axis, indexer = cur_axis.reindex(
             new_axis, method, copy_if_needed=True)
         return self.reindex_indexer(new_axis, indexer, axis=axis, fill_value=fill_value)
 
+    def reindex_axis0_with_method(self, new_axis, method=None, fill_value=None, limit=None, copy=True):
+        raise AssertionError('method argument not supported for '
+                             'axis == 0')
+
     def reindex_indexer(self, new_axis, indexer, axis=1, fill_value=None):
         """
         pandas-indexer with -1's only.
@@ -2843,19 +2875,28 @@ class SingleBlockManager(BlockManager):
             self._shape = tuple([len(self.axes[0])])
         return self._shape
 
-    def reindex(self, new_axis, method=None, limit=None, copy=True):
+    def reindex(self, new_axis, indexer=None, method=None, fill_value=None, limit=None, copy=True):
 
         # if we are the same and don't copy, just return
         if not copy and self.index.equals(new_axis):
             return self
-        block = self._block.reindex_items_from(new_axis, copy=copy)
+        block = self._block.reindex_items_from(new_axis, indexer=indexer, method=method,
+                                               fill_value=fill_value, limit=limit, copy=copy)
 
         if method is not None or limit is not None:
-            block = block.interpolate(method=method, limit=limit)
+            block = block.interpolate(method=method, fill_value=fill_value, limit=limit, downcast=self.dtype)
+
         mgr = SingleBlockManager(block, new_axis)
         mgr._consolidate_inplace()
         return mgr
 
+    def _reindex_indexer_items(self, new_items, indexer, fill_value):
+        # equiv to a reindex
+        return self.reindex(new_items, indexer=indexer, fill_value=fill_value, copy=False)
+
+    def reindex_axis0_with_method(self, new_axis, method=None, fill_value=None, limit=None, copy=True):
+        return self.reindex(new_axis, method=method, fill_value=fill_value, limit=limit, copy=copy)
+
     def get_slice(self, slobj, raise_on_error=False):
         if raise_on_error:
             _check_slice_bounds(slobj, self.index)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 2e2026dfd..051b44563 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -2737,77 +2737,18 @@ class Series(generic.NDFrame):
             return left, right
 
     def _reindex_indexer(self, new_index, indexer, copy):
-        if indexer is not None:
-            new_values = com.take_1d(self.values, indexer)
-        else:
+        if indexer is None:
             if copy:
-                result = self.copy()
-            else:
-                result = self
-            return result
+                return self.copy()
+            return self
 
         # be subclass-friendly
+        new_values = com.take_1d(self.get_values(), indexer)
         return self._constructor(new_values, new_index, name=self.name)
 
-    def reindex(self, index=None, method=None, level=None, fill_value=pa.NA,
-                limit=None, copy=True, takeable=False):
-        """Conform Series to new index with optional filling logic, placing
-        NA/NaN in locations having no value in the previous index. A new object
-        is produced unless the new index is equivalent to the current one and
-        copy=False
-
-        Parameters
-        ----------
-        index : array-like or Index
-            New labels / index to conform to. Preferably an Index object to
-            avoid duplicating data
-        method : {'backfill', 'bfill', 'pad', 'ffill', None}
-            Method to use for filling holes in reindexed Series
-            pad / ffill: propagate LAST valid observation forward to next valid
-            backfill / bfill: use NEXT valid observation to fill gap
-        copy : boolean, default True
-            Return a new object, even if the passed indexes are the same
-        level : int or name
-            Broadcast across a level, matching Index values on the
-            passed MultiIndex level
-        fill_value : scalar, default NaN
-            Value to use for missing values. Defaults to NaN, but can be any
-            "compatible" value
-        limit : int, default None
-            Maximum size gap to forward or backward fill
-        takeable : the labels are locations (and not labels)
-
-        Returns
-        -------
-        reindexed : Series
-        """
-        if index is None:
-            raise ValueError('Must pass Index or sequence, not None')
-
-        index = _ensure_index(index)
-        if self.index.equals(index):
-            if copy:
-                result = self.copy()
-                result.index = index
-                return result
-            else:
-                return self
-
-        if len(self.index) == 0:
-            return self._constructor(nan, index=index, name=self.name)
-
-        new_index, indexer = self.index.reindex(index, method=method,
-                                                level=level, limit=limit,
-                                                takeable=takeable)
-
-        # GH4246 (dispatch to a common method with frame to handle possibly
-        # duplicate index)
-        return self._reindex_with_indexers({ 0 : [new_index, indexer] }, copy=copy, fill_value=fill_value)
-
-    def _reindex_with_indexers(self, reindexers, copy, fill_value=None):
-        index, indexer = reindexers[0]
-        new_values = com.take_1d(self.values, indexer, fill_value=fill_value)
-        return self._constructor(new_values, index=index, name=self.name)
+    def _needs_reindex_multi(self, axes, method, level):
+        """ check if we do need a multi reindex; this is for compat with higher dims """
+        return False
 
     def reindex_axis(self, labels, axis=0, **kwargs):
         """ for compatibility with higher dims """
@@ -3472,14 +3413,6 @@ def _resolve_offset(freq, kwds):
     return offset
 
 
-def _get_fill_func(method):
-    method = com._clean_fill_method(method)
-    if method == 'pad':
-        fill_f = com.pad_1d
-    elif method == 'backfill':
-        fill_f = com.backfill_1d
-    return fill_f
-
 # backwards compatiblity
 TimeSeries = Series
 
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 00a9d4111..ff6334b9f 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -471,6 +471,7 @@ class SparseDataFrame(DataFrame):
 
         for col, series in compat.iteritems(this):
             new_data[col] = func(series.values, other.values)
+            #new_data[col] = func(series.as_sparse_array(fill_value=np.nan), other.as_sparse_array(fill_value=np.nan))
 
         # fill_value is a function of our operator
         if isnull(other.fill_value) or isnull(self.default_fill_value):
@@ -573,7 +574,10 @@ class SparseDataFrame(DataFrame):
         return SparseDataFrame(sdict, index=self.index, columns=columns,
                                default_fill_value=self._default_fill_value)
 
-    def _reindex_with_indexers(self, reindexers, method=None, copy=False, fill_value=np.nan):
+    def _reindex_with_indexers(self, reindexers, method=None, fill_value=np.nan, limit=None, copy=False):
+
+        if limit is not None:
+            raise NotImplementedError("cannot take limit with a sparse tyep")
 
         index,   row_indexer = reindexers.get(0, (None, None))
         columns, col_indexer = reindexers.get(1, (None, None))
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index 6d7e4994f..21a054e6f 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -565,19 +565,6 @@ class SparseSeries(Series):
                                  sparse_index=new_index,
                                  fill_value=self.fill_value)
 
-    def _reindex_indexer(self, new_index, indexer, copy):
-        if indexer is not None:
-            new_values = com.take_1d(self.values.values, indexer)
-        else:
-            if copy:
-                result = self.copy()
-            else:
-                result = self
-            return result
-
-        # be subclass-friendly
-        return self._constructor(new_values, new_index, name=self.name)
-
     def take(self, indices, axis=0, convert=True):
         """
         Sparse-compatible version of ndarray.take
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 430e5df83..8ad88374f 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -1051,7 +1051,7 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
         # don't necessarily copy
         result = self.panel.reindex(major=self.panel.major_axis, copy=False)
         assert_panel_equal(result,self.panel)
-        self.assert_((result is self.panel) == False)
+        self.assert_((result is self.panel) == True)
 
     def test_reindex_like(self):
         # reindex_like
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index add8ebf73..9b34631ec 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -786,7 +786,7 @@ class TestPanel4d(unittest.TestCase, CheckIndexing, SafeForSparse,
         result = self.panel4d.reindex(
             major=self.panel4d.major_axis, copy=False)
         assert_panel4d_equal(result,self.panel4d)
-        self.assert_((result is self.panel4d) == False)
+        self.assert_((result is self.panel4d) == True)
 
     def test_not_hashable(self):
         p4D_empty = Panel4D()
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 094a68a4c..a015eeb1c 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -4034,7 +4034,9 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         for idx, val in compat.iteritems(subNonContig):
             self.assertEqual(val, self.ts[idx])
 
-        self.assertRaises(ValueError, self.ts.reindex)
+        # return a copy the same index here
+        result = self.ts.reindex()
+        self.assert_((result is self.ts) == False)
 
     def test_reindex_corner(self):
         # (don't forget to fix this) I think it's fixed
@@ -4052,8 +4054,8 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertRaises(Exception, ts.reindex, self.ts.index, method='foo')
 
     def test_reindex_pad(self):
-        s = Series(np.arange(10), np.arange(10))
 
+        s = Series(np.arange(10), np.arange(10))
         s2 = s[::2]
 
         reindexed = s2.reindex(s.index, method='pad')
@@ -4065,6 +4067,26 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
                           index=np.arange(10))
         assert_series_equal(reindexed, expected)
 
+        # GH4604
+        s = Series([1,2,3,4,5], index=['a', 'b', 'c', 'd', 'e'])
+        new_index = ['a','g','c','f']
+        expected = Series([1,1,3,3],index=new_index)
+
+        # this changes dtype because the ffill happens after
+        result = s.reindex(new_index).ffill()
+        assert_series_equal(result, expected)
+
+        # this preserves dtype
+        result = s.reindex(new_index, method='ffill')
+        assert_series_equal(result, expected)
+
+        # inferrence of new dtype
+        s = Series([True,False,False,True],index=list('abcd'))
+        new_index='agc'
+        result = s.reindex(list(new_index)).ffill()
+        expected = Series([True,True,False],index=list(new_index))
+        assert_series_equal(result, expected)
+
     def test_reindex_backfill(self):
         pass
 
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 67adc6bf8..5cfe22781 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -316,6 +316,7 @@ class TestMerge(unittest.TestCase):
         df2['float'] = 1.
 
         for kind in JOIN_TYPES:
+
             joined = df1.join(df2, how=kind)
             expected = _join_by_hand(df1, df2, how=kind)
             assert_frame_equal(joined, expected)
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 7af1dd657..7e54d6ebc 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -139,6 +139,7 @@ class DatetimeIndex(Int64Index):
     _engine_type = _index.DatetimeEngine
 
     offset = None
+    _comparables = ['name','freqstr','tz']
 
     def __new__(cls, data=None,
                 freq=None, start=None, end=None, periods=None,
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index bf9d7b2cf..b28da7c9d 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -61,6 +61,7 @@ class Period(PandasObject):
     second : int, default 0
     """
     __slots__ = ['freq', 'ordinal']
+    _comparables = ['name','freqstr']
 
     def __init__(self, value=None, freq=None, ordinal=None,
                  year=None, month=1, quarter=None, day=1,
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index 357c64407..3fdeacad5 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -566,19 +566,19 @@ class TestResample(unittest.TestCase):
     def test_how_lambda_functions(self):
 
         ts = _simple_ts('1/1/2000', '4/1/2000')
-                
+
         result = ts.resample('M', how=lambda x: x.mean())
         exp = ts.resample('M', how='mean')
         tm.assert_series_equal(result, exp)
-        
+
         self.assertRaises(Exception, ts.resample, 'M',
                           how=[lambda x: x.mean(), lambda x: x.std(ddof=1)])
-                
+
         result = ts.resample('M', how={'foo': lambda x: x.mean(),
                                        'bar': lambda x: x.std(ddof=1)})
         foo_exp = ts.resample('M', how='mean')
         bar_exp = ts.resample('M', how='std')
-        
+
         tm.assert_series_equal(result['foo'], foo_exp)
         tm.assert_series_equal(result['bar'], bar_exp)
 
@@ -771,7 +771,7 @@ class TestResamplePeriodIndex(unittest.TestCase):
                                   ts.index[-1].asfreq('D', 'end'),
                                   freq='Q-%s' % month)
 
-            expected = stamps.reindex(qdates.to_timestamp('D', 'e'),
+            expected = stamps.reindex(qdates.to_timestamp('D', 's'),
                                       method='ffill')
             expected.index = qdates
 
