commit 77cbbc6bbedcc33bc3c539acdb787686cd30599b
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Apr 21 21:26:53 2012 -0400

    ENH: ship parts of scipy.stats, close #1092

diff --git a/RELEASE.rst b/RELEASE.rst
index 0122a1f34..28bc68c6b 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -30,6 +30,11 @@ pandas 0.8.0
   - Add GroupBy.prod optimized aggregation function and 'prod' fast time series
     conversion method (#1018)
 
+**Improvements to existing features**
+
+  - Shipping some functions from scipy.stats to reduce dependency,
+    e.g. Series.describe and DataFrame.describe (GH #1092)
+
 **API Changes**
 
   - Change BDay (business day) to not normalize dates by default
diff --git a/pandas/compat/scipy.py b/pandas/compat/scipy.py
index e69de29bb..9f021a01e 100644
--- a/pandas/compat/scipy.py
+++ b/pandas/compat/scipy.py
@@ -0,0 +1,242 @@
+"""
+Shipping functions from SciPy to reduce dependency on having SciPy installed
+"""
+
+import numpy as np
+
+
+def scoreatpercentile(a, per, limit=(), interpolation_method='fraction'):
+    """
+    Calculate the score at the given `per` percentile of the sequence `a`.
+
+    For example, the score at `per=50` is the median. If the desired quantile
+    lies between two data points, we interpolate between them, according to
+    the value of `interpolation`. If the parameter `limit` is provided, it
+    should be a tuple (lower, upper) of two values. Values of `a` outside
+    this (closed) interval will be ignored.
+
+    The `interpolation_method` parameter supports three values, namely
+    `fraction` (default), `lower` and `higher`. Interpolation is done only,
+    if the desired quantile lies between two data points `i` and `j`. For
+    `fraction`, the result is an interpolated value between `i` and `j`;
+    for `lower`, the result is `i`, for `higher` the result is `j`.
+
+    Parameters
+    ----------
+    a : ndarray
+        Values from which to extract score.
+    per : scalar
+        Percentile at which to extract score.
+    limit : tuple, optional
+        Tuple of two scalars, the lower and upper limits within which to
+        compute the percentile.
+    interpolation : {'fraction', 'lower', 'higher'}, optional
+        This optional parameter specifies the interpolation method to use,
+        when the desired quantile lies between two data points `i` and `j`:
+
+        - fraction: `i + (j - i)*fraction`, where `fraction` is the
+                    fractional part of the index surrounded by `i` and `j`.
+        -lower: `i`.
+        - higher: `j`.
+
+    Returns
+    -------
+    score : float
+        Score at percentile.
+
+    See Also
+    --------
+    percentileofscore
+
+    Examples
+    --------
+    >>> from scipy import stats
+    >>> a = np.arange(100)
+    >>> stats.scoreatpercentile(a, 50)
+    49.5
+
+    """
+    # TODO: this should be a simple wrapper around a well-written quantile
+    # function.  GNU R provides 9 quantile algorithms (!), with differing
+    # behaviour at, for example, discontinuities.
+    values = np.sort(a, axis=0)
+    if limit:
+        values = values[(limit[0] <= values) & (values <= limit[1])]
+
+    idx = per /100. * (values.shape[0] - 1)
+    if (idx % 1 == 0):
+        score = values[idx]
+    else:
+        if interpolation_method == 'fraction':
+            score = _interpolate(values[int(idx)], values[int(idx) + 1],
+                                 idx % 1)
+        elif interpolation_method == 'lower':
+            score = values[np.floor(idx)]
+        elif interpolation_method == 'higher':
+            score = values[np.ceil(idx)]
+        else:
+            raise ValueError("interpolation_method can only be 'fraction', " \
+                             "'lower' or 'higher'")
+
+    return score
+
+
+def _interpolate(a, b, fraction):
+    """Returns the point at the given fraction between a and b, where
+    'fraction' must be between 0 and 1.
+    """
+    return a + (b - a)*fraction
+
+
+def rankdata(a):
+    """
+    Ranks the data, dealing with ties appropriately.
+
+    Equal values are assigned a rank that is the average of the ranks that
+    would have been otherwise assigned to all of the values within that set.
+    Ranks begin at 1, not 0.
+
+    Parameters
+    ----------
+    a : array_like
+        This array is first flattened.
+
+    Returns
+    -------
+    rankdata : ndarray
+         An array of length equal to the size of `a`, containing rank scores.
+
+    Examples
+    --------
+    >>> stats.rankdata([0, 2, 2, 3])
+    array([ 1. ,  2.5,  2.5,  4. ])
+
+    """
+    a = np.ravel(a)
+    n = len(a)
+    svec, ivec = fastsort(a)
+    sumranks = 0
+    dupcount = 0
+    newarray = np.zeros(n, float)
+    for i in xrange(n):
+        sumranks += i
+        dupcount += 1
+        if i==n-1 or svec[i] != svec[i+1]:
+            averank = sumranks / float(dupcount) + 1
+            for j in xrange(i-dupcount+1,i+1):
+                newarray[ivec[j]] = averank
+            sumranks = 0
+            dupcount = 0
+    return newarray
+
+
+def fastsort(a):
+    """
+    Sort an array and provide the argsort.
+
+    Parameters
+    ----------
+    a : array_like
+        Input array.
+
+    Returns
+    -------
+    fastsort : ndarray of type int
+        sorted indices into the original array
+
+    """
+    # TODO: the wording in the docstring is nonsense.
+    it = np.argsort(a)
+    as_ = a[it]
+    return as_, it
+
+
+def percentileofscore(a, score, kind='rank'):
+    '''
+    The percentile rank of a score relative to a list of scores.
+
+    A `percentileofscore` of, for example, 80% means that 80% of the
+    scores in `a` are below the given score. In the case of gaps or
+    ties, the exact definition depends on the optional keyword, `kind`.
+
+    Parameters
+    ----------
+    a: array like
+        Array of scores to which `score` is compared.
+    score: int or float
+        Score that is compared to the elements in `a`.
+    kind: {'rank', 'weak', 'strict', 'mean'}, optional
+        This optional parameter specifies the interpretation of the
+        resulting score:
+
+        - "rank": Average percentage ranking of score.  In case of
+                  multiple matches, average the percentage rankings of
+                  all matching scores.
+        - "weak": This kind corresponds to the definition of a cumulative
+                  distribution function.  A percentileofscore of 80%
+                  means that 80% of values are less than or equal
+                  to the provided score.
+        - "strict": Similar to "weak", except that only values that are
+                    strictly less than the given score are counted.
+        - "mean": The average of the "weak" and "strict" scores, often used in
+                  testing.  See
+
+                  http://en.wikipedia.org/wiki/Percentile_rank
+
+    Returns
+    -------
+    pcos : float
+        Percentile-position of score (0-100) relative to `a`.
+
+    Examples
+    --------
+    Three-quarters of the given values lie below a given score:
+
+    >>> percentileofscore([1, 2, 3, 4], 3)
+    75.0
+
+    With multiple matches, note how the scores of the two matches, 0.6
+    and 0.8 respectively, are averaged:
+
+    >>> percentileofscore([1, 2, 3, 3, 4], 3)
+    70.0
+
+    Only 2/5 values are strictly less than 3:
+
+    >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='strict')
+    40.0
+
+    But 4/5 values are less than or equal to 3:
+
+    >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='weak')
+    80.0
+
+    The average between the weak and the strict scores is
+
+    >>> percentileofscore([1, 2, 3, 3, 4], 3, kind='mean')
+    60.0
+
+    '''
+    a = np.array(a)
+    n = len(a)
+
+    if kind == 'rank':
+        if not(np.any(a == score)):
+            a = np.append(a, score)
+            a_len = np.array(range(len(a)))
+        else:
+            a_len = np.array(range(len(a))) + 1.0
+
+        a = np.sort(a)
+        idx = [a == score]
+        pct = (np.mean(a_len[idx]) / n) * 100.0
+        return pct
+
+    elif kind == 'strict':
+        return sum(a < score) / float(n) * 100
+    elif kind == 'weak':
+        return sum(a <= score) / float(n) * 100
+    elif kind == 'mean':
+        return (sum(a < score) + sum(a <= score)) * 50 / float(n)
+    else:
+        raise ValueError("kind can only be 'rank', 'strict', 'weak' or 'mean'")
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 2c9e28109..cc99f0763 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -31,6 +31,7 @@ from pandas.core.index import Index, DatetimeIndex, MultiIndex, _ensure_index
 from pandas.core.indexing import _NDFrameIndexer, _maybe_droplevels
 from pandas.core.internals import BlockManager, make_block, form_blocks
 from pandas.core.series import Series, _radd_compat
+from pandas.compat.scipy import scoreatpercentile as _quantile
 from pandas.util import py3compat
 from pandas.util.terminal import get_terminal_size
 from pandas.util.decorators import deprecate, Appender, Substitution
@@ -3810,7 +3811,6 @@ class DataFrame(NDFrame):
         -------
         quantiles : Series
         """
-        from scipy.stats import scoreatpercentile
         per = q * 100
 
         def f(arr):
@@ -3821,7 +3821,7 @@ class DataFrame(NDFrame):
             if len(arr) == 0:
                 return nan
             else:
-                return scoreatpercentile(arr, per)
+                return _quantile(arr, per)
 
         return self.apply(f, axis=axis)
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 009e1ad65..6dbf2c12f 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -30,6 +30,8 @@ import pandas.core.nanops as nanops
 import pandas._tseries as lib
 from pandas.util.decorators import Appender, Substitution
 
+from pandas.compat.scipy import scoreatpercentile as _quantile
+
 __all__ = ['Series', 'TimeSeries']
 
 _np_version = np.version.short_version
@@ -1249,11 +1251,10 @@ copy : boolean, default False
         -------
         quantile : float
         """
-        from scipy.stats import scoreatpercentile
         valid_values = self.dropna().values
         if len(valid_values) == 0:
             return np.nan
-        return scoreatpercentile(valid_values, q * 100)
+        return _quantile(valid_values, q * 100)
 
     def describe(self, percentile_width=50):
         """
diff --git a/pandas/stats/misc.py b/pandas/stats/misc.py
index 07fbb391a..e301c5ae7 100644
--- a/pandas/stats/misc.py
+++ b/pandas/stats/misc.py
@@ -3,6 +3,8 @@ import numpy as np
 
 from pandas.core.api import Series, DataFrame, isnull, notnull
 from pandas.core.series import remove_na
+from pandas.compat.scipy import scoreatpercentile
+
 
 __all__ = ['bucket', 'bucketpanel']
 
@@ -293,16 +295,10 @@ def quantileTS(frame, percentile):
     percentile: int
        nth percentile
 
-    See also
-    --------
-    scipy.stats.scoreatpercentile
-
     Returns
     -------
     Series (or TimeSeries)
     """
-    from scipy.stats import scoreatpercentile
-
     def func(x):
         x = np.asarray(x.valid())
         if x.any():
@@ -340,15 +336,11 @@ def percentileRank(frame, column=None, kind='mean'):
 
                   http://en.wikipedia.org/wiki/Percentile_rank
 
-    See also
-    --------
-    scipy.stats.percentileofscore
-
     Returns
     -------
     TimeSeries or DataFrame, depending on input
     """
-    from scipy.stats import percentileofscore
+    from pandas.compat.scipy import percentileofscore
     fun = lambda xs, score: percentileofscore(remove_na(xs),
                                               score, kind=kind)
 
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 8837fb3a3..142374887 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -4552,10 +4552,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self._check_stat_op('median', wrapper, frame=self.intframe)
 
     def test_quantile(self):
-        try:
-            from scipy.stats import scoreatpercentile
-        except ImportError:
-            return
+        from pandas.compat.scipy import scoreatpercentile
 
         q = self.tsframe.quantile(0.1, axis=0)
         self.assertEqual(q['A'], scoreatpercentile(self.tsframe['A'], 10))
@@ -4615,14 +4612,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         df.cumprod(1)
 
     def test_rank(self):
-        from scipy.stats import rankdata
+        from pandas.compat.scipy import rankdata
 
         self.frame['A'][::2] = np.nan
         self.frame['B'][::3] = np.nan
         self.frame['C'][::4] = np.nan
         self.frame['D'][::5] = np.nan
 
-
         ranks0 = self.frame.rank()
         ranks1 = self.frame.rank(1)
         mask =  np.isnan(self.frame.values)
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index fcf40b490..cc8236ada 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1214,7 +1214,7 @@ class TestGroupBy(unittest.TestCase):
         self.assert_(result.columns.equals(df.columns[:-1]))
 
     def test_pass_args_kwargs(self):
-        from scipy.stats import scoreatpercentile
+        from pandas.compat.scipy import scoreatpercentile
 
         def f(x, q=None):
             return scoreatpercentile(x, q)
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 2e6f1eefa..38e089ef2 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1047,7 +1047,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assert_(not isinstance(result, Series))
 
     def test_quantile(self):
-        from scipy.stats import scoreatpercentile
+        from pandas.compat.scipy import scoreatpercentile
 
         q = self.ts.quantile(0.1)
         self.assertEqual(q, scoreatpercentile(self.ts.valid(), 10))
@@ -1698,7 +1698,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_almost_equal(expected, ordered.valid().values)
 
     def test_rank(self):
-        from scipy.stats import rankdata
+        from pandas.compat.scipy import rankdata
 
         self.ts[::2] = np.nan
         self.ts[:10][::3] = 4.
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index cdeada769..49f410ef5 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -1,5 +1,6 @@
 import unittest
 
+from numpy import nan
 import numpy as np
 from pandas import Index, isnull
 from pandas.util.testing import assert_almost_equal
@@ -163,7 +164,7 @@ def test_groupsort_indexer():
 
 
 def test_duplicated_with_nas():
-    keys = [0, 1, np.nan, 0, 2, np.nan]
+    keys = [0, 1, nan, 0, 2, nan]
 
     result = lib.duplicated(keys)
     expected = [False, False, False, True, False, True]
@@ -173,7 +174,7 @@ def test_duplicated_with_nas():
     expected = [True, False, True, False, False, False]
     assert(np.array_equal(result, expected))
 
-    keys = [(0, 0), (0, np.nan), (np.nan, 0), (np.nan, np.nan)] * 2
+    keys = [(0, 0), (0, nan), (nan, 0), (nan, nan)] * 2
 
     result = lib.duplicated(keys)
     falses = [False] * 4
@@ -186,7 +187,7 @@ def test_duplicated_with_nas():
     assert(np.array_equal(result, expected))
 
 def test_convert_objects():
-    arr = np.array(['a', 'b', np.nan, np.nan, 'd', 'e', 'f'], dtype='O')
+    arr = np.array(['a', 'b', nan, nan, 'd', 'e', 'f'], dtype='O')
     result = lib.maybe_convert_objects(arr)
     assert(result.dtype == np.object_)
 
@@ -201,15 +202,15 @@ def test_convert_objects_ints():
         assert(issubclass(result.dtype.type, np.integer))
 
 def test_rank():
-    from scipy.stats import rankdata
-    from numpy import nan
+    from pandas.compat.scipy import rankdata
+
     def _check(arr):
         mask = -np.isfinite(arr)
         arr = arr.copy()
         result = lib.rank_1d_float64(arr)
         arr[mask] = np.inf
         exp = rankdata(arr)
-        exp[mask] = np.nan
+        exp[mask] = nan
         assert_almost_equal(result, exp)
 
     _check(np.array([nan, nan, 5., 5., 5., nan, 1, 2, 3, nan]))
@@ -419,7 +420,7 @@ def test_group_ohlc():
 
     def _ohlc(group):
         if isnull(group).all():
-            return np.repeat(np.nan, 4)
+            return np.repeat(nan, 4)
         return [group[0], group.max(), group.min(), group[-1]]
 
     expected = np.array([_ohlc(obj[:6]), _ohlc(obj[6:12]),
@@ -428,9 +429,9 @@ def test_group_ohlc():
     assert_almost_equal(out, expected)
     assert_almost_equal(counts, [6, 6, 8])
 
-    obj[:6] = np.nan
+    obj[:6] = nan
     lib.group_ohlc(out, counts, obj[:, None], bins)
-    expected[0] = np.nan
+    expected[0] = nan
     assert_almost_equal(out, expected)
 
 def test_try_parse_dates():
