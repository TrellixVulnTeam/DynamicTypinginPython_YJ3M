commit de100c92da4da25ee89c58e3561cde7a848e454e
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Sep 24 22:39:19 2012 -0400

    ENH: a bit more progress for today

diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 4f486b1f4..3d1815e5a 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -605,6 +605,8 @@ class CParserWrapper(object):
         self.names = kwds.pop('names', None)
         self.index_col = kwds.pop('index_col', None)
 
+        self.as_recarray = kwds.get('as_recarray', False)
+
         if self.names is not None:
             kwds['header'] = None
 
@@ -619,6 +621,11 @@ class CParserWrapper(object):
 
         names, data = self._reader.read(nrows)
         index, names, data = self._get_index(names, data)
+
+        # rename dict keys
+        data = sorted(data.items())
+        data = dict((k, v) for k, (i, v) in zip(names, data))
+
         return index, names, data
 
     def _get_index(self, names, data):
@@ -629,8 +636,13 @@ class CParserWrapper(object):
             names = range(len(data))
 
         if self.index_col is not None:
-            pass
+            (idx_names, names,
+             self.index_col) = _clean_index_names(names, self.index_col)
 
+            arrays = []
+            for i in self.index_col:
+                arrays.append(data.pop(i))
+            index = MultiIndex.from_arrays(arrays, names=idx_names)
         elif len(data) > len(names):
             # possible implicit index
             pass
@@ -641,6 +653,8 @@ class CParserWrapper(object):
 
         return index, names, data
 
+
+
 def TextParser(*args, **kwds):
     """
     Converts lists of lists/tuples into DataFrames with proper type inference
@@ -850,7 +864,9 @@ class PythonParser(object):
 
         elif self._has_complex_date_col:
             if not self._name_processed:
-                self.index_name = self._explicit_index_names(list(columns))
+                (self.index_name, _,
+                 self.index_col) = _clean_index_names(list(columns),
+                                                      self.index_col)
                 self._name_processed = True
             index = self._get_complex_date_index(data, columns)
             index = self._agg_index(index, False)
@@ -1002,10 +1018,13 @@ class PythonParser(object):
                 if len(next_line) == len(line) + len(columns):
                     # column and index names on diff rows
                     implicit_first_cols = 0
+
                     self.index_col = range(len(line))
                     self.buf = self.buf[1:]
+
                     for c in reversed(line):
                         columns.insert(0, c)
+
                     return line, columns, orig_columns
 
         if implicit_first_cols > 0:
@@ -1015,38 +1034,11 @@ class PythonParser(object):
             index_name = None
 
         else:
-            index_name = self._explicit_index_names(columns)
+            (index_name, columns,
+             self.index_col) = _clean_index_names(columns, self.index_col)
 
         return index_name, orig_columns, columns
 
-    def _explicit_index_names(self, columns):
-
-        if self.index_col is None:
-            return None
-
-        cp_cols = list(columns)
-        index_name = []
-        index_col = list(self.index_col)
-        for i, c in enumerate(index_col):
-            if isinstance(c, basestring):
-                index_name.append(c)
-                for j, name in enumerate(cp_cols):
-                    if name == c:
-                        index_col[i] = j
-                        columns.remove(name)
-                        break
-            else:
-                name = cp_cols[c]
-                columns.remove(name)
-                index_name.append(name)
-        self.index_col = index_col
-
-        # hack
-        if index_name[0] is not None and 'Unnamed' in index_name[0]:
-            index_name[0] = None
-
-        return index_name
-
     def _rows_to_cols(self, content):
         zipped_content = list(lib.to_object_array(content).T)
 
@@ -1153,19 +1145,23 @@ class PythonParser(object):
         return index
 
     def _agg_index(self, index, try_parse_dates=True):
-
         arrays = []
         for i, arr in enumerate(index):
+
             if (try_parse_dates and self._should_parse_dates(i)):
                 arr = self._conv_date(arr)
+
             col_na_values = self.na_values
+
             if isinstance(self.na_values, dict):
                 col_name = self.index_name[i]
                 if col_name is not None:
                     col_na_values = _get_na_values(col_name,
                                                    self.na_values)
+
             arr, _ = _convert_types(arr, col_na_values)
             arrays.append(arr)
+
         index = MultiIndex.from_arrays(arrays, names=self.index_name)
 
         return index
@@ -1308,6 +1304,37 @@ class PythonParser(object):
         return self._check_thousands(lines)
 
 
+def _clean_index_names(columns, index_col):
+    if index_col is None:
+        return None, columns, index_col
+
+    columns = list(columns)
+
+    cp_cols = list(columns)
+    index_name = []
+
+    # don't mutate
+    index_col = list(index_col)
+
+    for i, c in enumerate(index_col):
+        if isinstance(c, basestring):
+            index_name.append(c)
+            for j, name in enumerate(cp_cols):
+                if name == c:
+                    index_col[i] = j
+                    columns.remove(name)
+                    break
+        else:
+            name = cp_cols[c]
+            columns.remove(name)
+            index_name.append(name)
+
+    # hack
+    if index_name[0] is not None and 'Unnamed' in index_name[0]:
+        index_name[0] = None
+
+    return index_name, columns, index_col
+
 
 def _get_empty_meta(columns, index_col, index_name):
     columns = list(columns)
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 70f98297c..d5fd28b90 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -139,7 +139,7 @@ index2,b,d,f
 
     def test_1000_sep(self):
         data = """A|B|C
-1|2,334.0|5
+1|2,334|5
 10|13|10.
 """
         expected = [[1, 2334., 5],
@@ -151,19 +151,6 @@ index2,b,d,f
         df = self.read_table(StringIO(data), sep='|', thousands=',')
         assert_almost_equal(df.values, expected)
 
-    def test_comment(self):
-        data = """A,B,C
-1,2.,4.#hello world
-5.,NaN,10.0
-"""
-        expected = [[1., 2., 4.],
-                    [5., np.nan, 10.]]
-        df = self.read_csv(StringIO(data), comment='#')
-        assert_almost_equal(df.values, expected)
-
-        df = self.read_table(StringIO(data), sep=',', comment='#', na_values=['NaN'])
-        assert_almost_equal(df.values, expected)
-
     def test_squeeze(self):
         data = """\
 a,1
@@ -1419,6 +1406,19 @@ class TestPythonParser(ParserTests, unittest.TestCase):
         kwds['engine'] = 'python'
         return read_table(*args, **kwds)
 
+    def test_comment(self):
+        data = """A,B,C
+1,2.,4.#hello world
+5.,NaN,10.0
+"""
+        expected = [[1., 2., 4.],
+                    [5., np.nan, 10.]]
+        df = self.read_csv(StringIO(data), comment='#')
+        assert_almost_equal(df.values, expected)
+
+        df = self.read_table(StringIO(data), sep=',', comment='#', na_values=['NaN'])
+        assert_almost_equal(df.values, expected)
+
     def test_1000_fwf(self):
         data = """
  1 2,334.0    5
@@ -1489,17 +1489,17 @@ class TestPythonParser(ParserTests, unittest.TestCase):
                           colspecs=colspecs, widths=[6, 10, 10, 7])
 
 
-# class TestCParser(ParserTests, unittest.TestCase):
+class TestCParser(ParserTests, unittest.TestCase):
 
-#     def read_csv(self, *args, **kwds):
-#         kwds = kwds.copy()
-#         kwds['engine'] = 'c'
-#         return read_csv(*args, **kwds)
+    def read_csv(self, *args, **kwds):
+        kwds = kwds.copy()
+        kwds['engine'] = 'c'
+        return read_csv(*args, **kwds)
 
-#     def read_table(self, *args, **kwds):
-#         kwds = kwds.copy()
-#         kwds['engine'] = 'c'
-#         return read_table(*args, **kwds)
+    def read_table(self, *args, **kwds):
+        kwds = kwds.copy()
+        kwds['engine'] = 'c'
+        return read_table(*args, **kwds)
 
 
 class TestParseSQL(unittest.TestCase):
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index cc6104ade..ea402c15e 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -183,8 +183,9 @@ cdef class TextReader:
     cdef:
         parser_t *parser
         object file_handle, should_close
-        bint factorize, na_filter
+        bint factorize, na_filter, verbose
         int parser_start
+        float64_t clk
 
     cdef public:
         object delimiter, na_values, converters, delim_whitespace
@@ -284,6 +285,7 @@ cdef class TextReader:
         self.as_recarray = as_recarray
         self.header = None
 
+        self.verbose = verbose
         self.low_memory = low_memory
 
     def __init__(self, *args, **kwards):
@@ -396,32 +398,36 @@ cdef class TextReader:
     cdef _read_high_memory(self, rows):
         # start = time.clock()
 
+        self._start_clock()
         if rows is not None:
             raise NotImplementedError
         else:
             with nogil:
                 status = tokenize_all_rows(self.parser)
-
-        # end = time.clock()
-        # print 'Tokenization took %.4f sec' % (end - start)
+        self._end_clock('Tokenization')
 
         if status < 0:
             raise_parser_error('Error tokenizing data', self.parser)
 
-        # start = time.clock()
-
+        self._start_clock()
         columns, names = self._convert_column_data()
+        self._end_clock('Type conversion')
 
         header = self.get_header()
         if header is not None:
             names = header
 
-        # end = time.clock()
-        # print 'Type conversion took %.4f sec' % (end - start)
         # debug_print_parser(self.parser)
 
         return names, columns
 
+    cdef _start_clock(self):
+        self.clk = time.clock()
+
+    cdef _end_clock(self, what):
+        if self.verbose:
+            print '%s took: %.4fms' % (time.clock() - self.clk) * 1000
+
     def _convert_column_data(self):
         cdef:
             Py_ssize_t i, ncols
@@ -451,7 +457,7 @@ cdef class TextReader:
 
             if conv:
                 col_res = _apply_converter(conv, self.parser, i, start, end)
-                results[i] = col_res
+                results[i] = lib.maybe_convert_numeric(col_res)
                 continue
 
             col_res = None
