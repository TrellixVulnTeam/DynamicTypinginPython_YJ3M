commit d75f0529323502bf52a907b8fc8ad5a30f32be15
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Jun 7 13:27:10 2010 +0000

    unit tests
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@190 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/doc/source/dataframe.rst b/doc/source/dataframe.rst
index ce416ba03..0892fc6de 100644
--- a/doc/source/dataframe.rst
+++ b/doc/source/dataframe.rst
@@ -28,16 +28,20 @@ multiple time series or cross sections with ease.
              Series indices.
 
        **index** : {array_like}
-           Explicit index to conform to, required for ndarray data argument
+           Explicit index to conform to, defaults to range(N) if not input
 
        **columns** : {array_like}
-           Explicit set of columns to include, required for ndarray data argument
+           Explicit set of columns to include, defaults to range(N) if not input
 
        **dtype** : Python type alias or :class:`~numpy.dtype`
-           Type to attempt to cast data to
-
-:class:`~pandas.DataMatrix` has a similar constructor and can be used interchangeably.
+           Type to *attempt* to cast data to
 
+:class:`~pandas.DataMatrix` has an identical constructor (barring an
+extra keyword argument necessary for supporting mixed-type data, which
+you can safely ignore). :ref:`Elsewhere in the documentation
+<framevs>` we will explain the difference between the objects (which
+**only** matters in performance sensitive applications and can be
+ignored by most users).
 
 Basics
 ------
@@ -605,9 +609,9 @@ Function application
 You will often want to perform some other computation with the
 DataFrame other than the statistical operators above. Likewise, you
 may want to transform the data in some way (like taking the square
-root or natural logarithm). To solve these problems, you should use
-the **apply** function. In short, **apply** will call a function that
-you pass on each row or column of the DataFrame and, depending on the
+root or natural logarithm). In most cases, you will want to use the
+**apply** function. In short, **apply** will call a function that you
+pass on each row or column of the DataFrame and, depending on the
 return type of the function, return a Series or DataFrame.
 
 ::
@@ -655,8 +659,17 @@ the date where the maximum value for each column occurred:
     B    2009-02-27 00:00:00
     C    2009-06-30 00:00:00
 
+DataFrame and DataMatrix also implement the ndarray *array interface*
+which allows you to call ufuncs (like sqrt, exp, log, etc.) directly
+on the object. So the following two expressions would be equivalent:
+
+::
+
+    >>> np.sqrt(df)
+    >>> df.apply(np.sqrt)
+
 Another useful feature is the ability to pass Series methods to carry
-out some Series operation on each columns or row:
+out some Series operation on each column or row:
 
 ::
 
@@ -717,22 +730,40 @@ DataFrame's iterator functions are consistent with the dict interface:
    DataFrame.cols
    DataFrame.iteritems
 
-Reindexing
-----------
+Reindexing and filling / padding values
+---------------------------------------
 
 .. seealso:: :ref:`Series reindexing <series.reindexing>`
 
 Similar to Series, the **reindex** method conforms a DataFrame to a
 new index or list of columns.
 
+::
+
+    >>> reindexed = df.reindex(index=new_index,
+                               columns=new_columns)
+
+For time series data, if the new index is higher frequency than the
+old one, you may wish to "fill" holes with the values as of each date:
+
+::
+
+    >>> filled = df.reindex(new_index, fillMethod='pad')
+
 .. autosummary::
    :toctree: generated/
 
    DataFrame.reindex
+   DataFrame.fill
+
+Filtering / selecting columns or indices
+----------------------------------------
+
+.. autosummary::
+   :toctree: generated/
+
    DataFrame.dropEmptyRows
    DataFrame.dropIncompleteRows
-   DataFrame.merge
-   DataFrame.fill
    DataFrame.filter
 
 Sorting
@@ -753,7 +784,84 @@ TODO
 Joining / merging DataFrames
 ----------------------------
 
-TODO
+The **join** method provides effectively SQL-like semantic for
+combining related data sets. The basic join consists of two DataFrame
+arguments and
+
+::
+
+    >>> df1
+			   A              B
+    2000-01-03 00:00:00    -0.1174        -0.941
+    2000-01-04 00:00:00    -0.6034        -0.008094
+    2000-01-05 00:00:00    -0.3816        -0.9338
+    2000-01-06 00:00:00    -0.3298        -0.9548
+    2000-01-07 00:00:00    0.9576         0.4652
+    2000-01-10 00:00:00    -0.7208        -1.131
+    2000-01-11 00:00:00    1.568          0.8498
+    2000-01-12 00:00:00    0.3717         -0.2323
+    2000-01-13 00:00:00    -1.428         -1.997
+    2000-01-14 00:00:00    -1.084         -0.271
+
+    >>> df2
+			   C              D
+    2000-01-03 00:00:00    0.2833         -0.1937
+    2000-01-05 00:00:00    1.868          1.207
+    2000-01-07 00:00:00    -0.8586        -0.7367
+    2000-01-11 00:00:00    2.121          0.9104
+    2000-01-13 00:00:00    0.7856         0.9063
+
+
+    df1.join(df2)
+			   A              B              C              D
+    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
+    2000-01-04 00:00:00    -0.6034        -0.008094      NaN            NaN
+    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
+    2000-01-06 00:00:00    -0.3298        -0.9548        NaN            NaN
+    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
+    2000-01-10 00:00:00    -0.7208        -1.131         NaN            NaN
+    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
+    2000-01-12 00:00:00    0.3717         -0.2323        NaN            NaN
+    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
+    2000-01-14 00:00:00    -1.084         -0.271         NaN            NaN
+
+::
+
+    >>> df1.join(df2, how='inner')
+			   A              B              C              D
+    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
+    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
+    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
+    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
+    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
+
+The index (row labels) are the default key for joining, but a column
+can also be used for a similar SQL-like join: It is also frequently
+necessary to join (or *merge*) data sets based on some other key
+mapping.
+
+::
+
+    >>> df2
+			   C              D              key
+    2000-01-03 00:00:00    0.2833         -0.1937        0
+    2000-01-05 00:00:00    1.868          1.207          1
+    2000-01-07 00:00:00    -0.8586        -0.7367        0
+    2000-01-11 00:00:00    2.121          0.9104         1
+    2000-01-13 00:00:00    0.7856         0.9063         0
+
+    >>> df3
+	 code
+    0    foo
+    1    bar
+
+    >>> df2.join(df3, on='key')
+			   C              D              code           key
+    2000-01-03 00:00:00    0.2833         -0.1937        foo            0
+    2000-01-05 00:00:00    1.868          1.207          bar            1
+    2000-01-07 00:00:00    -0.8586        -0.7367        foo            0
+    2000-01-11 00:00:00    2.121          0.9104         bar            1
+    2000-01-13 00:00:00    0.7856         0.9063         foo            0
 
 .. autosummary::
    :toctree: generated/
diff --git a/doc/source/datetools.rst b/doc/source/datetools.rst
index 75197dc7c..875a62ac3 100644
--- a/doc/source/datetools.rst
+++ b/doc/source/datetools.rst
@@ -6,102 +6,123 @@
 Date and frequency tools
 ************************
 
+In dealing with the economic realities of time series data, we will
+frequently seek to:
 
+* generate sequences of fixed-frequency dates
+
+* conform or convert time series to a particular frequency
+
+* compute "relative" dates based on various non-standard time
+  increments (e.g. 5 business days before the last business day of the
+  year), or "roll" dates forward or backward
+
+pandas provides a relatively compact and self-contained set of tools
+for performing the above tasks. The functionality revolves around the
+**DateOffset** class and its subclasses, which are objects which can
+be added and subtracted from regular Python **datetime** objects.
 
 .. _datetools.offsets:
 
 DateOffset and subclasses
 -------------------------
 
-It is often necessary to do non-standard date logic, adding business
-days, rolling to the next month or quarter end, rolling to the next
-business month end, etc. One might wish to aggregate more granular
-data based on these fixed-frequency periods, or maybe you want to
-shift a TimeSeries in some particular way without resorting to a hack.
-
-In searching for the most "pythonic" approach to this problem (and I
-don't know if I have found it or not), I chose to create objects
-representing the frequency increments in the form of the DateOffset
-object specifying the mechanics of the "increment", and one can then
-define different offset logic via subclasses. The vanilla version of
-the DateOffset works identically to an object in the dateutil package,
+A **DateOffset** instance represents a frequency increment. Different
+offset logic via subclasses. The vanilla version of the DateOffset
+works identically to an object in the dateutil package,
 dateutil.relativedelta, which works like:
 
 ::
 
-    In [319]: d = datetime(2008, 8, 18)
-
-    In [321]: d + relativedelta(months=4, days=5)
-    Out[321]: datetime.datetime(2008, 12, 23, 0, 0)
+    >>> d = datetime(2008, 8, 18)
+    >>> d + relativedelta(months=4, days=5)
+    datetime.datetime(2008, 12, 23, 0, 0)
 
-
-You could write this using DateOffset in nearly the same way (here I
-have not imported the DateOffset name in this example, so you could do
-"from daterange import DateOffset" to avoid having to write the module
-name):
+The basic DateOffset class accepts the same set of arguments that
+relativedelta does:
 
 ::
 
-	In [323]: d + daterange.DateOffset(months=4, days=5)
-	Out[323]: datetime.datetime(2008, 12, 23, 0, 0)
-
+    >>> d + DateOffset(months=4, days=5)
+    datetime.datetime(2008, 12, 23, 0, 0)
 
-The key characteristics of the DateOffset are:
+The key characteristics of a DateOffset are:
 
-  - it can be added / subtracted to/from a datetime object to obtain a
-    shifted date
-  - it can be multiplied by an integer to multiple the effect as
-    desired
+* it can be added / subtracted to/from a datetime object to obtain a
+  shifted date
 
-::
-    In [325]: d - 5 * daterange.BDay()
-    Out[325]: datetime.datetime(2008, 8, 11, 0, 0)
+* it can be multiplied by an integer to multiple the effect as
+  desired
 
-  - in the subclass one only need redefine the method 'apply' which
-    describes the interaction with a datetime object.
+Subclasses of DateOffset define specialized logic for various
+increments of interest, such a weekday / business day.
 
 ::
 
-    class BMonthEnd(DateOffset):
-	"""DateOffset increments between business EOM dates"""
+    class BDay(DateOffset):
+	"""DateOffset increments between business days"""
 	def apply(self, other):
 	    ...
 
-Turns out each of these 'apply' methods for various standard offsets
-are pretty easy to write (the longest is 10 lines), and I've written a
-few so far:
+::
 
-business day (BDay)
-business month end aka EOM (BMonthEnd)
-month end (MonthEnd), quarter end (QuarterEnd), year end/begin (YearEnd / YearBegin)
+    >>> d - 5 * BDay()
+    datetime.datetime(2008, 8, 11, 0, 0)
 
-Each of these when initialized with the parameter 0 (e.g. BMonthEnd(0)
-) have the effect of rolling forward to the nearest date lying on a
-particular offset:
+A subclass need only redefine the method 'apply' which describes the
+interaction with a datetime object.
 
 ::
 
-    In [324]: d + daterange.BMonthEnd(0)
-    Out[324]: datetime.datetime(2008, 8, 29, 0, 0)
+    >>> d + BMonthEnd(0)
+    datetime.datetime(2008, 8, 29, 0, 0)
 
+An offset is also *callable* as functions to avoid those times where
+you might otherwise create a lambda, for example:
 
-For convenience, the daterange module has shorthand instances of these
-classes available for a number of reasons:
+::
 
-bday, monthEnd, bmonthEnd, yearEnd, etc.
+    map(BDay(), dateList) versus
+    map(lambda x: x + BDay(), dateList)
 
-::
+.. csv-table::
+    :header: "Class name", "Description"
+    :widths: 15, 65
+
+    DateOffset, "Generic offset, arguments as **datetime.relativedelta**"
+    BDay, "business day (weekday)"
+    Week, "one week, optionally anchored on a day of the week"
+    MonthEnd, "calendar month end"
+    BMonthEnd, "business month end"
+    YearEnd, "calendar year end"
+    YearBegin, "calendar year begin"
+    BYearEnd, "business year end"
+    Hour, "one hour"
+    Minute, "one minute"
+    Second, "one second"
 
-    In [326]: d - 5 * daterange.bday
-    Out[326]: datetime.datetime(2008, 8, 11, 0, 0)
+.. _daterange:
 
+Creating date ranges (DateRange)
+--------------------------------
 
-These offsets are also *callable* as functions to avoid those times
-where you might otherwise create a lambda, for example:
+The DateRange class utilizes these offsets (and any ones that we might
+add) to generate lists of dates for general purposes:
 
-    map(daterange.bday, dateList) versus
-    map(lambda x: x + daterange.bday, dateList)
+::
 
+    In [327]: DateRange(fromDate=d, nPeriods=10, offset=daterange.bmonthEnd)
+    Out[327]:
+    [datetime.datetime(2008, 8, 29, 0, 0),
+     datetime.datetime(2008, 9, 30, 0, 0),
+     datetime.datetime(2008, 10, 31, 0, 0),
+     datetime.datetime(2008, 11, 28, 0, 0),
+     datetime.datetime(2008, 12, 31, 0, 0),
+     datetime.datetime(2009, 1, 30, 0, 0),
+     datetime.datetime(2009, 2, 27, 0, 0),
+     datetime.datetime(2009, 3, 31, 0, 0),
+     datetime.datetime(2009, 4, 30, 0, 0),
+     datetime.datetime(2009, 5, 29, 0, 0)]
 
 
 One can also specify a 'toDate', the endpoints are included if and
@@ -147,46 +168,7 @@ by some amount:
     2008-06-06 00:00:00     0.031957
     2008-07-07 00:00:00     -0.058455
 
-.. csv-table::
-    :header: "Class name", "Description"
-    :widths: 15, 65
-
-    DateOffset, ""
-    BDay, ""
-    Week, ""
-    MonthEnd, ""
-    BMonthEnd, ""
-    YearEnd, ""
-    YearBegin, ""
-    BYearEnd, ""
-    Hour, ""
-    Minute, ""
-    Second, ""
-
-.. _daterange:
-
-Creating date ranges (DateRange)
---------------------------------
-
-The DateRange class utilizes these offsets (and any ones that we might
-add) to generate lists of dates for general purposes:
-
-::
-
-    In [327]: DateRange(fromDate=d, nPeriods=10, offset=daterange.bmonthEnd)
-    Out[327]:
-    [datetime.datetime(2008, 8, 29, 0, 0),
-     datetime.datetime(2008, 9, 30, 0, 0),
-     datetime.datetime(2008, 10, 31, 0, 0),
-     datetime.datetime(2008, 11, 28, 0, 0),
-     datetime.datetime(2008, 12, 31, 0, 0),
-     datetime.datetime(2009, 1, 30, 0, 0),
-     datetime.datetime(2009, 2, 27, 0, 0),
-     datetime.datetime(2009, 3, 31, 0, 0),
-     datetime.datetime(2009, 4, 30, 0, 0),
-     datetime.datetime(2009, 5, 29, 0, 0)]
-
-Defining custom frequencies
+Tips for custom frequencies
 ---------------------------
 
 .. _datetools.timerules:
diff --git a/doc/source/frame_vs_matrix.rst b/doc/source/frame_vs_matrix.rst
new file mode 100644
index 000000000..e9280e46d
--- /dev/null
+++ b/doc/source/frame_vs_matrix.rst
@@ -0,0 +1,5 @@
+.. _framevs:
+
+***********************************
+When to use DataFrame or DataMatrix
+***********************************
\ No newline at end of file
diff --git a/doc/source/r_interface.rst b/doc/source/r_interface.rst
index 454ea3be8..a91aca3f3 100644
--- a/doc/source/r_interface.rst
+++ b/doc/source/r_interface.rst
@@ -40,5 +40,10 @@ Calling R functions with pandas objects
 Transferring R data sets into Python
 ------------------------------------
 
+The **load_data** function retrieves an R data set and converts
+it to the appropriate pandas object (most likely a DataFrame):
+
+
+
 High-level interface to R estimators
 ------------------------------------
\ No newline at end of file
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 0d09efe5a..f85232b66 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -218,6 +218,45 @@ class DataFrame(Picklable, Groupable):
 
         return cls(dataDict, index=index)
 
+    @classmethod
+    def fromcsv(cls, path, header=0, delimiter=',', index_col=0):
+        """
+        Read delimited file into DataFrame
+
+        Parameters
+        ----------
+        path : string
+        header : int, default 0
+            Row to use at header (skip prior rows)
+        delimiter : string, default ','
+        index_col : int
+            Column to use for index
+
+        Notes
+        -----
+        Will attempt to convert index to datetimes for time series
+        data. Uses numpy.genfromtxt to do the actual parsing into
+        ndarray
+
+        Returns
+        -------
+        y : DataFrame or DataMatrix
+        """
+        from datetime import datetime
+
+        data = np.genfromtxt(path, delimiter=delimiter, dtype=None,
+                             skip_header=header, names=True)
+
+        field = data.dtype.names[index_col]
+        df = cls.fromRecords(data, indexField=field)
+
+        # have dates?
+        test_val = datetools.to_datetime(df.index[0])
+        if isinstance(test_val, datetime):
+            df = df.rename(index=datetools.to_datetime)
+
+        return df
+
     def toRecords(self):
         """
         Convert DataFrame to record array. Index will be put in the
@@ -232,9 +271,6 @@ class DataFrame(Picklable, Groupable):
 
         return np.rec.fromarrays(arrays, names=names)
 
-    def fromcsv(self, path, header=0):
-        pass
-
 #-------------------------------------------------------------------------------
 # Magic methods
 
@@ -471,39 +507,51 @@ class DataFrame(Picklable, Groupable):
 # Public methods
 
     def toCSV(self, path, nanRep='', cols=None, header=True,
-              index=True, verbose=False):
+              index=True, mode='wb'):
         """
         Write the DataFrame to a CSV file
-        """
-        f = open(path, 'w')
+
+        Parameters
+        ----------
+        path : string
+            File path
+        nanRep : string, default ''
+            Missing data rep'n
+        cols : sequence, optional
+        header : boolean, default True
+            Write out column names
+        index : boolean, default True
+            Write row names (index)
+        """
+        f = open(path, mode)
 
         if cols is None:
             cols = self.cols()
 
+        series = self._series
         if header:
+            joined_cols = ','.join([str(c) for c in cols])
             if index:
-                f.write(',' + ','.join([str(c) for c in cols]))
+                # this could be dangerous
+                f.write('index,%s' % joined_cols)
             else:
-                f.write(','.join([str(c) for c in cols]))
+                f.write(joined_cols)
             f.write('\n')
 
         for idx in self.index:
             if index:
-                f.write(str(idx) + ',')
+                f.write(str(idx))
             for col in cols:
-                val = self._series[col].get(idx)
+                val = series[col].get(idx)
                 if isnull(val):
                     val = nanRep
                 else:
                     val = str(val)
-                f.write(val + ',')
+                f.write(',%s' % val)
             f.write('\n')
 
         f.close()
 
-        if verbose: # pragma: no cover
-            print 'CSV file written successfully: %s' % path
-
     def toDataMatrix(self):
         from pandas.core.matrix import DataMatrix
 
@@ -543,6 +591,22 @@ class DataFrame(Picklable, Groupable):
                                   float_format=float_format)
                 print >> buffer, ot
 
+    def head(self, buffer=sys.stdout):
+        chunk = self[:5]
+        if len(self.cols()) > 6:
+            print 'Probably too wide to display, transposing'
+            chunk = chunk.T
+
+        chunk.toString(buffer=buffer)
+
+    def tail(self, buffer=sys.stdout):
+        chunk = self[-5:]
+        if len(self.cols()) > 6:
+            print 'Probably too wide to display, transposing'
+            chunk = chunk.T
+
+        chunk.toString(buffer=buffer)
+
     def info(self, buffer=sys.stdout):
         """Concise summary of a DataFrame, used in __repr__ when very large."""
         print >> buffer, 'Index: %s entries' % len(self.index),
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 06b8fad8a..02e68a7a1 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -83,9 +83,10 @@ class GroupBy(object):
         """
         Groupby iterator
 
-        Yields
-        ------
-        Sequence of (groupName, subsetted object) for each group
+        Returns
+        -------
+        Generator yielding sequence of (groupName, subsetted object)
+        for each group
         """
         try:
             groupNames = sorted(self.groups)
@@ -165,7 +166,7 @@ class SeriesGroupBy(GroupBy):
         return DataFrame(results)
 
     def _aggregate_simple(self, applyfunc):
-        values = self.obj.values()
+        values = self.obj.values
         result = {}
         for k, v in self.group_indices.iteritems():
             result[k] = applyfunc(values.take(v))
diff --git a/pandas/core/index.py b/pandas/core/index.py
index a13e3187b..fa41323e9 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -220,6 +220,10 @@ class Index(np.ndarray):
 
     __sub__ = diff
 
+    def take(self, *args, **kwargs):
+        taken = self.view(np.ndarray).take(*args, **kwargs)
+        return Index(taken)
+
 # For utility purposes
 
 NULL_INDEX = Index([])
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 1a4aff159..fe6878e9e 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -757,55 +757,6 @@ class DataMatrix(DataFrame):
 #-------------------------------------------------------------------------------
 # Outputting
 
-    def toCSV(self, path, nanRep='', writeMode='wb', index=True,
-              header=True, cols=None, verbose=False):
-        """
-        Write the DataMatrix to a CSV file
-
-        Parameters
-        ----------
-        path : string
-            Output file path
-        nanRep : string, default=''
-            Appearance of NaN values in output
-        index : boolean, default=True
-            Prints index if True
-        header : boolean, default=True
-            Prints header if True
-        cols : list of strings
-            Prints the values in order specified by cols.
-            By default, prints all columns in lexicographical order.
-        """
-        f = open(path, writeMode)
-
-        if cols is None:
-            cols = self.cols()
-        series = self._series
-
-        if header:
-            if index:
-                f.write(',')
-            f.write(','.join([str(c) for c in cols]))
-            f.write('\n')
-
-        for idx in self.index:
-            if index:
-                f.write(str(idx) + ',')
-
-            for col in cols:
-                val = series[col][idx]
-                if isnull(val):
-                    val = nanRep
-                else:
-                    val = str(val)
-                f.write(val + ',')
-            f.write('\n')
-
-        f.close()
-
-        if verbose: # pragma: no cover
-            print 'CSV file written successfully: %s' % path
-
     def toString(self, buffer=sys.stdout, columns=None, colSpace=15,
                  nanRep='NaN', formatters=None, float_format=None):
         """
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index c1b665b67..6dca08524 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1048,8 +1048,8 @@ class LongPanel(Panel):
 
             # Is it a factor?
             if not np.issctype(series.dtype):
-                factor_dict[col] = Factor.fromarray(series)
-                del data[col]
+                factor_dict[col] = factor = Factor.fromarray(series)
+                data[col] = factor.labels
 
         items = sorted(data)
         values = np.array([data[k] for k in items]).T
@@ -1311,6 +1311,9 @@ class LongPanel(Panel):
             row = format_row(major[major_i], minor[minor_i], self.values[i])
             print >> buffer, row
 
+    def _fill_factors(self):
+        values = self.values.astype(object)
+
     def swapaxes(self):
         """
         Swap major and minor axes and reorder values to be grouped by
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 6f275c29a..e2d941e42 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -10,6 +10,7 @@ from numpy import random
 import numpy as np
 
 import pandas.core.datetools as datetools
+from pandas.core.index import NULL_INDEX
 from pandas.core.api import DataFrame, Index, Series, notnull
 
 from pandas.util.testing import (assert_almost_equal,
@@ -180,9 +181,23 @@ class TestDataFrame(unittest.TestCase):
         self.assertRaises(Exception, self.klass, mat,
                           columns=['A', 'B'], index=[1, 2])
 
-        # have to pass columns and index
-        self.assertRaises(Exception, self.klass, mat, index=[1])
-        self.assertRaises(Exception, self.klass, mat, columns=['A', 'B', 'C'])
+        # automatic labeling
+        frame = self.klass(mat)
+        self.assert_(np.array_equal(frame.index, range(2)))
+        self.assert_(np.array_equal(frame.cols(), range(3)))
+
+        frame = self.klass(mat, index=[1, 2])
+        self.assert_(np.array_equal(frame.cols(), range(3)))
+
+        frame = self.klass(mat, columns=['A', 'B', 'C'])
+        self.assert_(np.array_equal(frame.index, range(2)))
+
+        # 0-length axis
+        frame = self.klass(np.empty((0, 3)))
+        self.assert_(frame.index is NULL_INDEX)
+
+        frame = self.klass(np.empty((3, 0)))
+        self.assert_(len(frame.cols()) == 0)
 
     def test_array_interface(self):
         result = np.sqrt(self.frame)
@@ -284,6 +299,16 @@ class TestDataFrame(unittest.TestCase):
         # columns are not sortable
         foo = repr(self.unsortable)
 
+        # do not fail!
+        self.frame.head(buffer=buf)
+        self.frame.tail(buffer=buf)
+
+        for i in range(5):
+            self.frame['foo%d' % i] = 1
+
+        self.frame.head(buffer=buf)
+        self.frame.tail(buffer=buf)
+
     def test_toString(self):
         # big mixed
         biggie = self.klass({'A' : randn(1000),
@@ -514,7 +539,7 @@ class TestDataFrame(unittest.TestCase):
         self.assert_(result.index is self.empty.index)
         self.assertEqual(len(result.columns), 0)
 
-    def test_toCSV(self):
+    def test_toCSV_fromcsv(self):
         path = '__tmp__'
 
         self.frame['A'][:5] = np.NaN
@@ -524,6 +549,13 @@ class TestDataFrame(unittest.TestCase):
         self.frame.toCSV(path, header=False)
         self.frame.toCSV(path, index=False)
 
+        # test roundtrip
+
+        self.tsframe.toCSV(path)
+        recons = self.klass.fromcsv(path)
+
+        assert_frame_equal(self.tsframe, recons)
+
         os.remove(path)
 
     def test_toDataMatrix(self):
@@ -973,13 +1005,21 @@ class TestDataFrame(unittest.TestCase):
 
         # transform
         transformed = grouped.transform(lambda x: x - x.mean())
-        self.assertEqual(len(aggregated), 5)
-        self.assertEqual(len(aggregated.cols()), 4)
+        self.assertEqual(len(transformed), 30)
+        self.assertEqual(len(transformed.cols()), 4)
 
         # iterate
         for weekday, group in grouped:
             self.assert_(group.index[0].weekday() == weekday)
 
+        # groups / group_indices
+        groups = grouped.groups
+        indices = grouped.group_indices
+
+        for k, v in groups.iteritems():
+            samething = self.tsframe.index.take(indices[k])
+            self.assert_(np.array_equal(v, samething))
+
     def test_groupby_columns(self):
         mapping = {
             'A' : 0, 'B' : 0, 'C' : 1, 'D' : 1
diff --git a/pandas/core/tests/test_panel.py b/pandas/core/tests/test_panel.py
index 477b52544..f2aca91d6 100644
--- a/pandas/core/tests/test_panel.py
+++ b/pandas/core/tests/test_panel.py
@@ -628,6 +628,20 @@ class TestLongPanel(unittest.TestCase):
         self.assertRaises(Exception, LongPanel.fromRecords, np.zeros((3, 3)),
                           0, 1)
 
+    def test_factors(self):
+        # structured array
+        K = 10
+
+        recs = np.zeros(K, dtype='O,O,f8,f8,O,O')
+        recs['f0'] = ['one'] * 5 + ['two'] * 5
+        recs['f1'] = ['A', 'B', 'C', 'D', 'E'] * 2
+        recs['f2'] = np.arange(K) * 2
+        recs['f3'] = np.arange(K)
+        recs['f4'] = ['A', 'B', 'C', 'D', 'E'] * 2
+        recs['f5'] = ['foo', 'bar'] * 5
+
+        lp = LongPanel.fromRecords(recs, 'f0', 'f1')
+
     def test_columns(self):
         self.assert_(np.array_equal(self.panel.items, self.panel.columns))
         self.assert_(np.array_equal(self.panel.items, self.panel.cols()))
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
new file mode 100644
index 000000000..fba7497d1
--- /dev/null
+++ b/pandas/io/tests/test_pytables.py
@@ -0,0 +1,21 @@
+import pandas.util.testing as T
+
+class TesttHDFStore(object):
+
+    def test_series(self):
+        pass
+
+    def test_frame(self):
+        pass
+
+    def test_matrix(self):
+        pass
+
+    def test_matrix_mixed(self):
+        pass
+
+    def test_widepanel(self):
+        pass
+
+    def _roundtrip(self, obj, comparator):
+        pass
diff --git a/pandas/rpy/__init__.py b/pandas/rpy/__init__.py
index 8b1378917..98330688d 100644
--- a/pandas/rpy/__init__.py
+++ b/pandas/rpy/__init__.py
@@ -1 +1 @@
-
+from pandas.rpy.common import importr, r, load_data
