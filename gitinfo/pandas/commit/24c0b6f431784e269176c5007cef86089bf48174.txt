commit 24c0b6f431784e269176c5007cef86089bf48174
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Nov 21 17:00:20 2009 +0000

    reorganized cython code. rolling moment implementations
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@37 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/lib/include/datetime.pxi b/pandas/lib/include/datetime.pxi
index e0df966d4..91e25fe9c 100644
--- a/pandas/lib/include/datetime.pxi
+++ b/pandas/lib/include/datetime.pxi
@@ -1,14 +1,14 @@
 cdef extern from "datetime.h":
-    
+
     ctypedef extern class datetime.datetime [object PyDateTime_DateTime]:
         cdef int *data
         cdef long hashcode
         cdef char hastzinfo
-        
+
     int PyDateTime_GET_YEAR(datetime o)
     int PyDateTime_GET_MONTH(datetime o)
     int PyDateTime_GET_DAY(datetime o)
-    int PyDateTime_TIME_GET_HOUR(datetime o)
-    int PyDateTime_TIME_GET_MINUTE(datetime o)
-    int PyDateTime_TIME_GET_SECOND(datetime o)
-    int PyDateTime_TIME_GET_MICROSECOND(datetime o)
\ No newline at end of file
+    int PyDateTime_DATE_GET_HOUR(datetime o)
+    int PyDateTime_DATE_GET_MINUTE(datetime o)
+    int PyDateTime_DATE_GET_SECOND(datetime o)
+    int PyDateTime_DATE_GET_MICROSECOND(datetime o)
diff --git a/pandas/lib/include/numpy.pxi b/pandas/lib/include/numpy.pxi
index 0f2f1ec13..6fcb9d2da 100644
--- a/pandas/lib/include/numpy.pxi
+++ b/pandas/lib/include/numpy.pxi
@@ -4,12 +4,12 @@ cdef extern from "numpy/arrayobject.h":
 
 	cdef enum NPY_TYPES:
 		NPY_BOOL
-		NPY_BYTE	
+		NPY_BYTE
 		NPY_UBYTE
 		NPY_SHORT
-		NPY_USHORT 
+		NPY_USHORT
 		NPY_INT
-		NPY_UINT 
+		NPY_UINT
 		NPY_LONG
 		NPY_ULONG
 		NPY_LONGLONG
@@ -40,7 +40,7 @@ cdef extern from "numpy/arrayobject.h":
 		NPY_WRITEABLE
 		NPY_UPDATEIFCOPY
 		NPY_ARR_HAS_DESCR
-		
+
 		NPY_BEHAVED
 		NPY_BEHAVED_NS
 		NPY_CARRAY
@@ -48,21 +48,21 @@ cdef extern from "numpy/arrayobject.h":
 		NPY_FARRAY
 		NPY_FARRAY_RO
 		NPY_DEFAULT
-		
+
 		NPY_IN_ARRAY
 		NPY_OUT_ARRAY
 		NPY_INOUT_ARRAY
 		NPY_IN_FARRAY
 		NPY_OUT_FARRAY
 		NPY_INOUT_FARRAY
-		
-		NPY_UPDATE_ALL 
+
+		NPY_UPDATE_ALL
 
 	cdef enum NPY_SORTKIND:
 		NPY_QUICKSORT
 		NPY_HEAPSORT
 		NPY_MERGESORT
-	
+
 	cdef enum defines:
 		NPY_MAXDIMS
 
@@ -73,9 +73,9 @@ cdef extern from "numpy/arrayobject.h":
 	ctypedef struct npy_cfloat:
 		double real
 		double imag
-	
+
 	ctypedef int npy_intp
-	
+
 	ctypedef extern class numpy.dtype [object PyArray_Descr]:
 		cdef int type_num, elsize, alignment
 		cdef char type, kind, byteorder, hasobject
@@ -90,13 +90,13 @@ cdef extern from "numpy/arrayobject.h":
 		cdef object base
 		cdef dtype descr
 		cdef int flags
-		
+
 	ctypedef extern class numpy.flatiter [object PyArrayIterObject]:
 		cdef int  nd_m1
 		cdef npy_intp index, size
 		cdef ndarray ao
 		cdef char *dataptr
-        
+
 	ctypedef extern class numpy.broadcast [object PyArrayMultiIterObject]:
 		cdef int numiter
 		cdef npy_intp size, index
@@ -109,20 +109,20 @@ cdef extern from "numpy/arrayobject.h":
 	dtype PyArray_DescrFromTypeNum(NPY_TYPES type_num)
 	object PyArray_SimpleNew(int ndims, npy_intp* dims, NPY_TYPES type_num)
 	int PyArray_Check(object obj)
-	object PyArray_ContiguousFromAny(object obj, int type, 
+	object PyArray_ContiguousFromAny(object obj, int type,
 		int mindim, int maxdim)
-	object PyArray_ContiguousFromObject(object obj, NPY_TYPES type, 
+	object PyArray_ContiguousFromObject(object obj, NPY_TYPES type,
 		int mindim, int maxdim)
 	npy_intp PyArray_SIZE(ndarray arr)
 	npy_intp PyArray_NBYTES(ndarray arr)
 	npy_intp *PyArray_DIMS(object arr)
 	void *PyArray_DATA(ndarray arr)
 	int PyArray_ITEMSIZE(object arr)
-	
+
 	int PyArray_ISBEHAVED(ndarray arr)
-	
+
 	int PyArray_TYPE(object arr)
-		
+
 	object PyArray_GETITEM(object obj, void* itemptr)
 	int PyArray_SETITEM(object obj, void* itemptr, object item)
 	object PyArray_FromAny(object obj, dtype newtype, int mindim, int maxdim,
@@ -132,19 +132,19 @@ cdef extern from "numpy/arrayobject.h":
 	object PyArray_NewFromDescr(object subtype, dtype newtype, int nd,
 								npy_intp* dims, npy_intp* strides, void* data,
 								int flags, object parent)
-	
+
 	object PyArray_FROM_OTF(object obj, NPY_TYPES type, int flags)
 	object PyArray_EnsureArray(object)
-	
+
 	object PyArray_MultiIterNew(int n, ...)
-	
+
 	char *PyArray_MultiIter_DATA(broadcast multi, int i)
-	void PyArray_MultiIter_NEXTi(broadcast multi, int i) 
+	void PyArray_MultiIter_NEXTi(broadcast multi, int i)
 	void PyArray_MultiIter_NEXT(broadcast multi)
-	
+
 	object PyArray_IterNew(object arr)
 	void PyArray_ITER_NEXT(flatiter it)
 	void PyArray_ITER_GOTO(flatiter it, npy_intp* i)
 	void PyArray_ITER_GOTO1D(flatiter it, npy_intp i)
-	
+
 	void import_array()
diff --git a/pandas/lib/src/common.pyx b/pandas/lib/src/common.pyx
new file mode 100644
index 000000000..4f69949c9
--- /dev/null
+++ b/pandas/lib/src/common.pyx
@@ -0,0 +1,82 @@
+include "datetime.pxi"
+include "numpy.pxi"
+include "Python.pxi"
+
+# initialize numpy
+import_array()
+
+cimport numpy as np
+cimport cython
+from numpy cimport *
+from python_dict cimport *
+from python_float cimport PyFloat_Check
+
+import numpy as np
+isnan = np.isnan
+cdef double NaN = <double> np.NaN
+
+from datetime import datetime as pydatetime
+
+cdef inline object trycall(object func, object arg):
+    try:
+        return func(arg)
+    except:
+        raise Exception('Error calling func on index %s' % arg)
+
+cdef inline int int_max(int a, int b): return a if a >= b else b
+cdef inline int int_min(int a, int b): return a if a >= b else b
+
+ctypedef unsigned char UChar
+
+cdef int is_contiguous(ndarray arr):
+    return np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS)
+
+cdef int _contiguous_check(ndarray arr):
+    if not is_contiguous(arr):
+        raise ValueError('Tried to use data field on non-contiguous array!')
+
+cdef int16_t *get_int16_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <int16_t *> arr.data
+
+cdef int32_t *get_int32_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <int32_t *> arr.data
+
+cdef double_t *get_double_ptr(ndarray arr):
+    _contiguous_check(arr)
+
+    return <double_t *> arr.data
+
+cpdef map_indices(ndarray index):
+    '''
+    Produce a dict mapping the values of the input array to their respective
+    locations.
+
+    Example:
+        array(['hi', 'there']) --> {'hi' : 0 , 'there' : 1}
+
+    Better to do this with Cython because of the enormous speed boost.
+    '''
+    cdef int i, length
+    cdef flatiter iter
+    cdef dict result
+    cdef object idx
+
+    result = {}
+
+    iter = PyArray_IterNew(index)
+
+    length = PyArray_SIZE(index)
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(index, <void *> iter.dataptr)
+        result[idx] = i
+        PyArray_ITER_NEXT(iter)
+
+    return result
+
+cdef extern from "math.h":
+    double sqrt(double x)
diff --git a/pandas/lib/src/groupby.pyx b/pandas/lib/src/groupby.pyx
new file mode 100644
index 000000000..8537cde26
--- /dev/null
+++ b/pandas/lib/src/groupby.pyx
@@ -0,0 +1,277 @@
+
+#-------------------------------------------------------------------------------
+# Groupby-related functions
+
+@cython.boundscheck(False)
+def arrmap(ndarray[object, ndim=1] index, object func):
+    cdef int length = index.shape[0]
+    cdef int i = 0
+
+    cdef ndarray[object, ndim=1] result = np.empty(length, dtype=np.object_)
+
+    for i from 0 <= i < length:
+        result[i] = func(index[i])
+
+    return result
+
+@cython.boundscheck(False)
+def groupby_withnull_old(ndarray[object, ndim = 1] index, object keyfunc):
+    cdef dict groups
+    cdef int length = index.shape[0]
+    cdef object idx
+    cdef object curKey, key
+    cdef list members
+
+    groups = PyDict_New()
+
+    if length != index.shape[0]:
+        raise Exception('Dates and values were not the same length!')
+
+    cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
+
+    cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
+
+    bool_mask = null_mask.astype(bool)
+
+    null_values = np.asarray(index)[bool_mask]
+
+    if null_values.any():
+        PyDict_SetItem(groups, np.NaN, null_values)
+
+    cdef int i = 0
+    idx = index[0]
+    key = mapped_index[0]
+
+    # Algorithm notes
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
+    #   'lazily' evaluates
+
+    while i < length:
+        if not PyDict_Contains(groups, key):
+            members = [idx]
+            PyDict_SetItem(groups, key, members)
+            i += 1
+            curKey = key
+            while i < length:
+                if null_mask[i]:
+                    i += 1
+                    continue
+
+                idx = index[i]
+                key = mapped_index[i]
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+        else:
+            members = <list> PyDict_GetItem(groups, key)
+            members.append(idx)
+            i += 1
+            curKey = key
+            while null_mask[i] and i < length:
+                i += 1
+
+            while i < length:
+                if null_mask[i]:
+                    i += 1
+                    continue
+
+                idx = index[i]
+                key = mapped_index[i]
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+
+    return groups
+
+@cython.boundscheck(False)
+def groupby_withnull(ndarray[object, ndim = 1] index, object keyfunc):
+    cdef dict groups
+    cdef int length = index.shape[0]
+    cdef object idx
+    cdef object curKey, key
+    cdef list members
+
+    groups = PyDict_New()
+
+    if length != index.shape[0]:
+        raise Exception('Dates and values were not the same length!')
+
+    cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
+
+    cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
+
+    bool_mask = null_mask.astype(bool)
+
+    null_values = np.asarray(index)[bool_mask]
+
+    if null_values.any():
+        PyDict_SetItem(groups, np.NaN, null_values)
+
+    cdef int i = 0
+    idx = index[0]
+    key = mapped_index[0]
+
+    # Algorithm notes
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
+    #   'lazily' evaluates
+
+    while i < length:
+        if key not in groups:
+            members = [idx]
+            groups[key] = members
+            i += 1
+            curKey = key
+            while i < length:
+                if null_mask[i]:
+                    i += 1
+                    continue
+
+                idx = index[i]
+                key = mapped_index[i]
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+        else:
+            members = <list> groups[key]
+            members.append(idx)
+            i += 1
+            curKey = key
+            while null_mask[i] and i < length:
+                i += 1
+
+            while i < length:
+                if null_mask[i]:
+                    i += 1
+                    continue
+
+                idx = index[i]
+                key = mapped_index[i]
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+
+    return groups
+
+@cython.boundscheck(False)
+def groupby(ndarray[object, ndim = 1] index, object keyfunc):
+    cdef dict groups
+    cdef int length = index.shape[0]
+    cdef object idx
+    cdef object curKey, key
+    cdef list members
+
+    groups = PyDict_New()
+
+    if length != index.shape[0]:
+        raise Exception('Dates and values were not the same length!')
+
+    cdef int i = 0
+    idx = index[i]
+    key = keyfunc(idx)
+
+    # Algorithm notes
+    #   - Tries to reduce the number of calls to PyDict_GetItem, 'lazily' evaluates
+
+    while i < length:
+        if not PyDict_Contains(groups, key):
+            members = [idx]
+            PyDict_SetItem(groups, key, members)
+            i += 1
+            curKey = key
+            while i < length:
+                idx = index[i]
+                key = trycall(keyfunc, idx)
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+        else:
+            members = <list> PyDict_GetItem(groups, key)
+            members.append(idx)
+            i += 1
+            curKey = key
+            while i < length:
+                idx = index[i]
+                key = trycall(keyfunc, idx)
+                if key == curKey:
+                    members.append(idx)
+                    i += 1
+                else:
+                    break
+
+    return groups
+
+@cython.boundscheck(False)
+def groupbyfunc(ndarray[object, ndim = 1] index,
+                ndarray[npy_float64, ndim = 1] values,
+                object keyfunc, object applyfunc):
+    '''
+    Doing this proper in Cython
+    Not sure how much it will really speed things up
+    '''
+    cdef dict groups
+    cdef int length = values.shape[0]
+    cdef object idx
+    cdef object curKey, key
+    cdef list members, grouplist
+
+    groups = PyDict_New()
+
+    if length != index.shape[0]:
+        raise Exception('Dates and values were not the same length!')
+
+    cdef int i = 0
+    idx = index[i]
+    key = trycall(keyfunc, idx)
+
+    # Algorithm notes
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
+    #   'lazily' evaluates
+
+    while i < length:
+        if not PyDict_Contains(groups, key):
+            members = [values[i]]
+            PyDict_SetItem(groups, key, members)
+            i += 1
+            curKey = key
+            while i < length:
+                idx = index[i]
+                key = trycall(keyfunc, idx)
+                if key == curKey:
+                    members.append(values[i])
+                    i += 1
+                else:
+                    break
+        else:
+            members = <list> PyDict_GetItem(groups, key)
+            members.append(values[i])
+            i += 1
+            curKey = key
+            while i < length:
+                idx = index[i]
+                key = trycall(keyfunc, idx)
+                if key == curKey:
+                    members.append(values[i])
+                    i += 1
+                else:
+                    break
+
+    grouplist = PyDict_Keys(groups)
+
+    i = 0
+    length = len(grouplist)
+    for i from 0 <= i < length:
+        key = grouplist[i]
+        members = <list> PyDict_GetItem(groups, key)
+        PyDict_SetItem(groups, key, applyfunc(np.asarray(members)))
+
+    return groups
diff --git a/pandas/lib/src/isnull.pyx b/pandas/lib/src/isnull.pyx
new file mode 100644
index 000000000..f37b60dbe
--- /dev/null
+++ b/pandas/lib/src/isnull.pyx
@@ -0,0 +1,72 @@
+
+cdef double INF = <double> np.inf
+cdef double NEGINF = -INF
+
+cdef inline _checknull(object val):
+    return val is None or val != val or val == INF or val == NEGINF
+
+cdef ndarray _isnullobj(input):
+    cdef int i, length
+    cdef object val
+    cdef ndarray[npy_int8, ndim=1] result
+    cdef flatiter iter
+
+    length = PyArray_SIZE(input)
+
+    result = <ndarray> np.zeros(length, dtype=np.int8)
+
+    iter= PyArray_IterNew(input)
+
+    for i from 0 <= i < length:
+        val = PyArray_GETITEM(input, <void *> iter.dataptr)
+
+        if _checknull(val):
+            result[i] = 1
+
+        PyArray_ITER_NEXT(iter)
+
+    return result
+
+def isnull(input):
+    '''
+    Replacement for numpy.isnan / -numpy.isfinite which is suitable
+    for use on object arrays.
+
+    Parameters
+    ----------
+    arr: ndarray or object value
+
+    Returns
+    -------
+    boolean ndarray or boolean
+    '''
+    cdef ndarray[npy_int8, ndim=1] result
+
+    if isinstance(input, np.ndarray):
+        if input.dtype.kind in ('O', 'S'):
+            result = _isnullobj(input)
+
+            return result.astype(np.bool)
+        else:
+            return -np.isfinite(input)
+    else:
+        return _checknull(input)
+
+def notnull(input):
+    '''
+    Replacement for numpy.isfinite / -numpy.isnan which is suitable
+    for use on object arrays.
+
+    Parameters
+    ----------
+    arr: ndarray or object value
+
+    Returns
+    -------
+    boolean ndarray or boolean
+    '''
+    if isinstance(input, np.ndarray):
+        return -isnull(input)
+    else:
+        return not bool(_checknull(input))
+
diff --git a/pandas/lib/src/moments.pyx b/pandas/lib/src/moments.pyx
new file mode 100644
index 000000000..73432c60a
--- /dev/null
+++ b/pandas/lib/src/moments.pyx
@@ -0,0 +1,789 @@
+# Cython implementations of rolling sum, mean, variance, skewness,
+# other statistical moment functions
+
+cdef extern from "wirth.h":
+    double kth_smallest(double *a, int n, int k)
+
+#-------------------------------------------------------------------------------
+# Rolling sum
+
+cdef void _roll_sum(double_t *input, double_t *output,
+                    int win, int minp, int N):
+    cdef double val, prev, sum_x = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        if nobs >= minp:
+            output[i] = sum_x
+        else:
+            output[i] = NaN
+
+def _roll_sum_noncontig(ndarray[double_t, ndim=1] input,
+                        ndarray[double_t, ndim=1] output,
+                        int win, int minp, int N):
+    cdef double val, prev, sum_x = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        if nobs >= minp:
+            output[i] = sum_x
+        else:
+            output[i] = NaN
+
+#-------------------------------------------------------------------------------
+# Rolling mean
+
+cdef void _roll_mean(double_t *input, double_t *output,
+                    int win, int minp, int N):
+    cdef double val, prev, sum_x = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        if nobs >= minp:
+            output[i] = sum_x / nobs
+        else:
+            output[i] = NaN
+
+def _roll_mean_noncontig(ndarray[double_t, ndim=1] input,
+                         ndarray[double_t, ndim=1] output,
+                         int win, int minp, int N):
+    cdef double val, prev, sum_x = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+
+        if nobs >= minp:
+            output[i] = sum_x / nobs
+        else:
+            output[i] = NaN
+
+#-------------------------------------------------------------------------------
+# Exponentially weighted moving average
+
+cdef void _ewma(double_t *input, double_t *output,
+                      int com, int N):
+    cdef double cur, prev, neww, oldw, adj
+    cdef int i
+
+    neww = 1. / (1 + com)
+    oldw = 1 - neww
+    adj = oldw
+
+    output[0] = neww * input[0]
+
+    for i from 1 <= i < N:
+        cur = input[i]
+        prev = output[i - 1]
+
+        if cur == cur:
+            if prev == prev:
+                output[i] = oldw * prev + neww * cur
+            else:
+                output[i] = neww * cur
+        else:
+            output[i] = prev
+
+    for i from 0 <= i < N:
+        cur = input[i]
+        output[i] = output[i] / (1 - adj)
+
+        if cur == cur:
+            adj *= oldw
+
+def _ewma_noncontig(ndarray[double_t, ndim=1] input,
+                          ndarray[double_t, ndim=1] output,
+                          int com, int N):
+    cdef double cur, prev, neww, oldw, adj
+    cdef int i
+
+    neww = 1. / (1 + com)
+    oldw = 1 - neww
+    adj = oldw
+
+    output[0] = neww * input[0]
+
+    for i from 1 <= i < N:
+        cur = input[i]
+        prev = output[i - 1]
+
+        if cur == cur:
+            if prev == prev:
+                output[i] = oldw * prev + neww * cur
+            else:
+                output[i] = neww * cur
+        else:
+            output[i] = prev
+
+    for i from 0 <= i < N:
+        cur = input[i]
+        output[i] = output[i] / (1 - adj)
+
+        if cur == cur:
+            adj *= oldw
+
+#-------------------------------------------------------------------------------
+# Rolling variance
+
+cdef void _roll_var(double_t *input, double_t *output,
+                    int win, int minp, int N):
+    cdef double val, prev, sum_x = 0, sum_xx = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+            sum_xx += val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                sum_xx -= prev * prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+            sum_xx += val * val
+
+        if nobs >= minp:
+            output[i] = (nobs * sum_xx - sum_x * sum_x) / (nobs * nobs - nobs)
+        else:
+            output[i] = NaN
+
+
+def _roll_var_noncontig(ndarray[double_t, ndim=1] input,
+                        ndarray[double_t, ndim=1] output,
+                        int win, int minp, int N):
+    cdef double val, prev, sum_x = 0, sum_xx = 0
+    cdef int nobs = 0, i
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            sum_x += val
+            sum_xx += val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                sum_x -= prev
+                sum_xx -= prev * prev
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            sum_x += val
+            sum_xx += val * val
+
+        if nobs >= minp:
+            output[i] = (nobs * sum_xx - sum_x * sum_x) / (nobs * nobs - nobs)
+        else:
+            output[i] = NaN
+
+#-------------------------------------------------------------------------------
+# Rolling skewness
+
+cdef void _roll_skew(double_t *input, double_t *output,
+                    int win, int minp, int N):
+    cdef double val, prev
+    cdef double x = 0, xx = 0, xxx = 0
+    cdef int nobs = 0, i
+
+    # 3 components of the skewness equation
+    cdef double A, B, C, R
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                x -= prev
+                xx -= prev * prev
+                xxx -= prev * prev * prev
+
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+
+        if nobs >= minp:
+            A = x / nobs
+            B = xx / nobs - A * A
+            C = xxx / nobs - A * A * A - 3 * A * B
+
+            R = sqrt(B)
+
+            output[i] = ((sqrt(nobs * (nobs - 1.)) * C) /
+                         ((nobs-2) * R * R * R))
+        else:
+            output[i] = NaN
+
+
+def _roll_skew_noncontig(ndarray[double_t, ndim=1] input,
+                         ndarray[double_t, ndim=1] output,
+                         int win, int minp, int N):
+    cdef double val, prev
+    cdef double x = 0, xx = 0, xxx = 0
+    cdef int nobs = 0, i
+
+    # 3 components of the skewness equation
+    cdef double A, B, C, R
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                x -= prev
+                xx -= prev * prev
+                xxx -= prev * prev * prev
+
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+
+        if nobs >= minp:
+            A = x / nobs
+            B = xx / nobs - A * A
+            C = xxx / nobs - A * A * A - 3 * A * B
+
+            R = sqrt(B)
+
+            output[i] = ((sqrt(nobs * (nobs - 1.)) * C) /
+                         ((nobs-2) * R * R * R))
+        else:
+            output[i] = NaN
+
+#-------------------------------------------------------------------------------
+# Rolling kurtosis
+
+
+cdef void _roll_kurt(double_t *input, double_t *output,
+                     int win, int minp, int N):
+    cdef double val, prev
+    cdef double x = 0, xx = 0, xxx = 0, xxxx = 0
+    cdef int nobs = 0, i
+
+    # 5 components of the kurtosis equation
+    cdef double A, B, C, D, R, K
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+            xxxx += val * val * val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                x -= prev
+                xx -= prev * prev
+                xxx -= prev * prev * prev
+                xxxx -= prev * prev * prev * prev
+
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+            xxxx += val * val * val * val
+
+        if nobs >= minp:
+            A = x / nobs
+            R = A * A
+            B = xx / nobs - R
+            R = R * A
+            C = xxx / nobs - R - 3 * A * B
+            R = R * A
+            D = xxxx / nobs - R - 6*B*A*A - 4*C*A
+
+            K = (nobs * nobs - 1.)*D/(B*B) - 3*((nobs-1.)**2)
+            K = K / ((nobs - 2.)*(nobs-3.))
+
+            output[i] = K
+        else:
+            output[i] = NaN
+
+def _roll_kurt_noncontig(ndarray[double_t, ndim=1] input,
+                         ndarray[double_t, ndim=1] output,
+                         int win, int minp, int N):
+    cdef double val, prev
+    cdef double x = 0, xx = 0, xxx = 0, xxxx = 0
+    cdef int nobs = 0, i
+
+    # 5 components of the kurtosis equation
+    cdef double A, B, C, D, R, K
+
+    if minp > N:
+        minp = N + 1
+
+    for i from 0 <= i < minp - 1:
+        val = input[i]
+
+        # Not NaN
+        if val == val:
+            nobs += 1
+
+            # seriously don't ask me why this is faster
+            x += val
+            xx += val * val
+            xxx += val * val * val
+            xxxx += val * val * val * val
+
+        output[i] = NaN
+
+    for i from minp - 1 <= i < N:
+        val = input[i]
+
+        if i > win - 1:
+            prev = input[i - win]
+            if prev == prev:
+                x -= prev
+                xx -= prev * prev
+                xxx -= prev * prev * prev
+                xxxx -= prev * prev * prev * prev
+
+                nobs -= 1
+
+        if val == val:
+            nobs += 1
+            x += val
+            xx += val * val
+            xxx += val * val * val
+            xxxx += val * val * val * val
+
+        if nobs >= minp:
+            A = x / nobs
+            R = A * A
+            B = xx / nobs - R
+            R = R * A
+            C = xxx / nobs - R - 3 * A * B
+            R = R * A
+            D = xxxx / nobs - R - 6*B*A*A - 4*C*A
+
+            K = (nobs * nobs - 1.)*D/(B*B) - 3*((nobs-1.)**2)
+            K = K / ((nobs - 2.)*(nobs-3.))
+
+            output[i] = K
+        else:
+            output[i] = NaN
+
+#-------------------------------------------------------------------------------
+# Rolling median
+
+def median(ndarray arr):
+    cdef double *values
+    cdef int n = len(arr)
+
+    if len(arr) == 0:
+        return np.NaN
+
+    if not np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS):
+        arr = np.array(arr)
+
+    values = <double *> arr.data
+
+    if n % 2:
+        return kth_smallest(values, n, n / 2)
+    else:
+        return (kth_smallest(values, n, n / 2) +
+                kth_smallest(values, n, n / 2 - 1)) / 2
+
+def roll_median(ndarray[npy_float64, ndim=1] arr, int window, int minp):
+    cdef char *mask_data
+    cdef ndarray mask
+    cdef ndarray[npy_float64, ndim=1] result
+    cdef int i, n
+
+    n = len(arr)
+    arr = arr.copy()
+
+    mask = <ndarray> np.isfinite(arr)
+    mask_data = <char *> mask.data
+
+    result = np.empty(len(arr), dtype=float)
+
+    for i from minp <= i <= n:
+        pass
+
+
+#-------------------------------------------------------------------------------
+# Rolling min / max
+
+cdef void _roll_max(double_t *input, double_t *output,
+                    int win, int N):
+    cdef double val
+    cdef int i, j
+
+    for i from 0 <= i < win - 1:
+        output[i] = NaN
+
+    for i from win - 1 <= i < N:
+        val = input[i - win + 1]
+
+        for j from (i - win + 1) <= j <= i:
+            val = max(val, input[j])
+
+        output[j] = val
+
+def _roll_max_noncontig(ndarray[double_t, ndim=1] input,
+                        ndarray[double_t, ndim=1] output,
+                        int win, int N):
+    cdef double val
+    cdef int i, j
+
+    for i from 0 <= i < win - 1:
+        output[i] = NaN
+
+    for i from win - 1 <= i < N:
+        val = input[i - win + 1]
+
+        for j from (i - win + 1) <= j <= i:
+            val = max(val, input[j])
+
+        output[j] = val
+
+cdef void _roll_min(double_t *input, double_t *output,
+                    int win, int N):
+    cdef double val
+    cdef int i, j
+
+    for i from 0 <= i < win - 1:
+        output[i] = NaN
+
+    for i from win - 1 <= i < N:
+        val = input[i - win + 1]
+
+        for j from (i - win + 1) <= j <= i:
+            val = min(val, input[j])
+
+        output[j] = val
+
+def _roll_min_noncontig(ndarray[double_t, ndim=1] input,
+                        ndarray[double_t, ndim=1] output,
+                        int win, int N):
+    cdef double val
+    cdef int i, j
+
+    for i from 0 <= i < win - 1:
+        output[i] = NaN
+
+    for i from win - 1 <= i < N:
+        val = input[i - win + 1]
+
+        for j from (i - win + 1) <= j <= i:
+            val = min(val, input[j])
+
+        output[j] = val
+
+#-------------------------------------------------------------------------------
+# Python interface
+
+# I could use function pointers here and trim down the code duplication
+
+def rolling_sum(ndarray input, window, minp=None):
+    '''
+    Compute rolling sum of input array
+
+    Parameters
+    ----------
+    input: ndarray
+    window: int
+    minp: int
+
+    Returns
+    -------
+    ndarray with length of input
+    '''
+    N = len(input)
+
+    if minp is None:
+        minp = window
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _roll_sum(get_double_ptr(input), get_double_ptr(output),
+                   window, minp, N)
+    else:
+        _roll_sum_noncontig(input, output, window, minp, N)
+
+    return output
+
+def rolling_mean(ndarray input, window, minp=None):
+    N = len(input)
+
+    if minp is None:
+        minp = window
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _roll_mean(get_double_ptr(input), get_double_ptr(output),
+                   window, minp, N)
+    else:
+        _roll_mean_noncontig(input, output, window, minp, N)
+
+    return output
+
+
+def ewma(ndarray input, com):
+    N = len(input)
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _ewma(get_double_ptr(input), get_double_ptr(output),
+              com, N)
+    else:
+        _ewma_noncontig(input, output, com, N)
+
+    return output
+
+def rolling_var(ndarray input, window, minp=None):
+    N = len(input)
+
+    if minp is None:
+        minp = window
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _roll_var(get_double_ptr(input), get_double_ptr(output),
+                   window, minp, N)
+    else:
+        _roll_var_noncontig(input, output, window, minp, N)
+
+    return output
+
+def rolling_std(ndarray input, window, minp=None):
+    output = rolling_var(input, window, minp=minp)
+
+    return np.sqrt(output)
+
+def rolling_skew(ndarray input, window, minp=None):
+    N = len(input)
+
+    if minp is None:
+        minp = window
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _roll_skew(get_double_ptr(input), get_double_ptr(output),
+                   window, minp, N)
+    else:
+        _roll_skew_noncontig(input, output, window, minp, N)
+
+    return output
+
+def rolling_kurt(ndarray input, window, minp=None):
+    N = len(input)
+
+    if minp is None:
+        minp = window
+
+    if not issubclass(input.dtype.type, float):
+        input = input.astype(float)
+
+    cdef ndarray output = np.empty(N, dtype=float)
+
+    if is_contiguous(input):
+        _roll_kurt(get_double_ptr(input), get_double_ptr(output),
+                   window, minp, N)
+    else:
+        _roll_kurt_noncontig(input, output, window, minp, N)
+
+    return output
diff --git a/pandas/lib/src/operators.pyx b/pandas/lib/src/operators.pyx
new file mode 100644
index 000000000..81981ca11
--- /dev/null
+++ b/pandas/lib/src/operators.pyx
@@ -0,0 +1,87 @@
+cdef double __add(double a, double b):
+    return a + b
+cdef double __sub(double a, double b):
+    return a - b
+cdef double __div(double a, double b):
+    return a / b
+cdef double __mul(double a, double b):
+    return a * b
+cdef double __eq(double a, double b):
+    return a == b
+cdef double __ne(double a, double b):
+    return a != b
+cdef double __lt(double a, double b):
+    return a < b
+cdef double __gt(double a, double b):
+    return a > b
+cdef double __pow(double a, double b):
+    return a ** b
+
+ctypedef double (* double_func)(double a, double b)
+
+cdef ndarray _applyFunc(double_func func, ndarray index, object ao,
+                        object bo, dict aMap, dict bMap):
+    '''
+    C function taking a function pointer for quickly adding two Series objects.
+    '''
+    cdef ndarray A, B, result
+    cdef double *result_data
+    cdef int i, length
+    cdef flatiter itera, iterb, iteridx
+    cdef double nan
+    cdef object idx
+
+    # This is EXTREMELY important, otherwise you will get very
+    # undesired results
+    A = PyArray_ContiguousFromAny(ao, NPY_DOUBLE, 1, 1)
+    B = PyArray_ContiguousFromAny(bo, NPY_DOUBLE, 1, 1)
+
+    nan = <double> np.NaN
+    length = PyArray_SIZE(index)
+
+    result = <ndarray> np.empty(length, np.float64)
+    result_data = <double *>result.data
+
+    itera = <flatiter> PyArray_IterNew(A)
+    iterb = <flatiter> PyArray_IterNew(B)
+    iteridx = PyArray_IterNew(index)
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
+        PyArray_ITER_NEXT(iteridx)
+
+        if idx not in aMap or idx not in bMap:
+            result_data[i] = nan
+            continue
+
+        result_data[i] = func((<double *>A.data)[aMap[idx]],
+                            (<double *>B.data)[bMap[idx]])
+
+    return result
+
+def combineFunc(object name, ndarray index, object ao,
+                object bo, dict aMap, dict bMap):
+    '''
+    Combine two series (values and index maps for each passed in) using the
+    indicated function.
+    '''
+    if name == "__add__":
+        return _applyFunc(__add, index, ao, bo, aMap, bMap)
+    elif name == "__sub__":
+        return _applyFunc(__sub, index, ao, bo, aMap, bMap)
+    elif name == "__div__":
+        return _applyFunc(__div, index, ao, bo, aMap, bMap)
+    elif name == "__mul__":
+        return _applyFunc(__mul, index, ao, bo, aMap, bMap)
+    elif name == "__eq__":
+        return _applyFunc(__eq, index, ao, bo, aMap, bMap)
+    elif name == "__ne__":
+        return _applyFunc(__ne, index, ao, bo, aMap, bMap)
+    elif name == "__lt__":
+        return _applyFunc(__lt, index, ao, bo, aMap, bMap)
+    elif name == "__gt__":
+        return _applyFunc(__gt, index, ao, bo, aMap, bMap)
+    elif name == "__pow__":
+        return _applyFunc(__pow, index, ao, bo, aMap, bMap)
+    else:
+        raise Exception('bad funcname requested of Cython code')
diff --git a/pandas/lib/src/reindex.pyx b/pandas/lib/src/reindex.pyx
new file mode 100644
index 000000000..300dde893
--- /dev/null
+++ b/pandas/lib/src/reindex.pyx
@@ -0,0 +1,456 @@
+def reindexNew(ndarray index, ndarray arr, dict idxMap):
+    '''
+    Using the provided new index, a given array, and a mapping of index-value
+    correpondences in the value array, return a new ndarray conforming to
+    the new index.
+
+    This is significantly faster than doing it in pure Python.
+    '''
+    cdef ndarray result
+    cdef double *result_data
+    cdef int i, length
+    cdef flatiter itera, iteridx
+    cdef double nan
+    cdef object idx
+
+    nan = <double> np.NaN
+
+    length = PyArray_SIZE(index)
+
+    result = <ndarray> np.empty(length, np.float64)
+
+    result_data = <double *> result.data
+
+    itera = PyArray_IterNew(arr)
+    iteridx = PyArray_IterNew(index)
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
+        PyArray_ITER_NEXT(iteridx)
+        if idx not in idxMap:
+            result_data[i] = nan
+            continue
+        PyArray_ITER_GOTO1D(itera, idxMap[idx])
+        result_data[i] = (<double *>(itera.dataptr))[0]
+
+    return result
+
+
+def reindex(ndarray index, ndarray arr, dict idxMap):
+    '''
+    Using the provided new index, a given array, and a mapping of index-value
+    correpondences in the value array, return a new ndarray conforming to
+    the new index.
+
+    This is significantly faster than doing it in pure Python.
+    '''
+    cdef ndarray result
+    cdef double *result_data
+    cdef int i, length
+    cdef flatiter itera, iteridx
+    cdef double nan
+    cdef object idx
+
+    nan = <double> np.NaN
+
+    length = PyArray_SIZE(index)
+
+    result = <ndarray> np.empty(length, np.float64)
+
+    result_data = <double *> result.data
+
+    itera = PyArray_IterNew(arr)
+    iteridx = PyArray_IterNew(index)
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
+        PyArray_ITER_NEXT(iteridx)
+        if idx not in idxMap:
+            result_data[i] = nan
+            continue
+        PyArray_ITER_GOTO1D(itera, idxMap[idx])
+        result_data[i] = (<double *>(itera.dataptr))[0]
+
+    return result
+
+def reindexObj(ndarray index, ndarray arr, dict idxMap):
+    '''
+    Using the provided new index, a given array, and a mapping of index-value
+    correpondences in the value array, return a new ndarray conforming to
+    the new index.
+
+    This is significantly faster than doing it in pure Python.
+    '''
+    cdef ndarray result
+    cdef int i, length
+    cdef flatiter itera, iteridx, iterresult
+    cdef object idx, nan, obj
+
+    nan = np.NaN
+    length = PyArray_SIZE(index)
+
+    result = <ndarray> np.empty(length, dtype=np.object_)
+
+    itera = PyArray_IterNew(arr)
+    iteridx = PyArray_IterNew(index)
+    iterresult = PyArray_IterNew(result)
+
+    cdef int res
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
+        PyArray_ITER_NEXT(iteridx)
+
+        if idx not in idxMap:
+            PyArray_SETITEM(result, <void *> iterresult.dataptr, nan)
+            PyArray_ITER_NEXT(iterresult)
+            continue
+
+        PyArray_ITER_GOTO1D(itera, idxMap[idx])
+        obj = PyArray_GETITEM(arr, <void *> itera.dataptr)
+
+        res = PyArray_SETITEM(result, <void *> iterresult.dataptr, obj)
+        PyArray_ITER_NEXT(iterresult)
+
+    return result
+
+@cython.boundscheck(False)
+def reindexObject(ndarray[object, ndim=1] index,
+                  ndarray[object, ndim=1] arr,
+                  dict idxMap):
+    '''
+    Using the provided new index, a given array, and a mapping of index-value
+    correpondences in the value array, return a new ndarray conforming to
+    the new index.
+    '''
+    cdef int j, loc, length
+    cdef object idx, value
+    cdef object nan = np.NaN
+
+    length = index.shape[0]
+    cdef ndarray[object, ndim = 1] result = np.empty(length, dtype=object)
+
+    loc = 0
+    cdef int i = 0
+    for i from 0 <= i < length:
+        idx = index[i]
+        if not PyDict_Contains(idxMap, idx):
+            result[i] = nan
+            continue
+        value = arr[idxMap[idx]]
+        result[i] = value
+    return result
+
+cdef tuple _nofill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
+    cdef int *fillLocs
+    cdef char *mask
+    cdef int i, j, length, newLength
+
+    cdef flatiter iterold
+    cdef object idx
+    cdef ndarray fillVec
+    cdef ndarray maskVec
+
+    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
+    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
+
+    fillLocs = <int *> fillVec.data
+    mask = <char *> maskVec.data
+
+    newLength = PyArray_SIZE(fillVec)
+
+    length = PyArray_SIZE(oldIndex)
+    iterold = PyArray_IterNew(oldIndex)
+
+    for i from 0 <= i < length:
+        idx = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
+        if i < length - 1:
+           PyArray_ITER_NEXT(iterold)
+        if idx in newMap:
+            j = newMap[idx]
+            fillLocs[j] = i
+            mask[j] = 1
+
+    for i from 0 <= i < newLength:
+        if mask[i] == 0:
+            fillLocs[i] = -1
+
+    return fillVec, maskVec
+
+cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
+    '''
+    Backfilling logic for generating fill vector
+
+    Diagram of what's going on
+
+    Old      New    Fill vector    Mask
+             .        0               1
+             .        0               1
+             .        0               1
+    A        A        0               1
+             .        1               1
+             .        1               1
+             .        1               1
+             .        1               1
+             .        1               1
+    B        B        1               1
+             .        2               1
+             .        2               1
+             .        2               1
+    C        C        2               1
+             .                        0
+             .                        0
+    D
+    '''
+    cdef int i, j, oldLength, newLength, curLoc
+    # Make empty vectors
+    cdef ndarray fillVec
+    cdef ndarray maskVec
+    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
+    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
+
+    # Get references
+    cdef int *fillLocs
+    cdef char *mask
+    fillLocs = <int *> fillVec.data
+    mask = <char *> maskVec.data
+
+    # Create the iterators
+    cdef flatiter iterold, iternew
+    iterold = PyArray_IterNew(oldIndex)
+    iternew = PyArray_IterNew(newIndex)
+
+    # Get the size
+    oldLength = PyArray_SIZE(oldIndex)
+    newLength = PyArray_SIZE(newIndex)
+
+    # Current positions
+    cdef int newPos, oldPos
+    oldPos = oldLength - 1
+    newPos = newLength - 1
+
+    # References holding indices
+    cdef object prevOld, curOld
+
+    while newPos >= 0:
+        # Move to the current position
+        PyArray_ITER_GOTO1D(iternew, newPos)
+        PyArray_ITER_GOTO1D(iterold, oldPos)
+
+        # Get the current index
+        curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
+
+        # Until we reach a point where we are before the curOld point
+        while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > curOld:
+            newPos -= 1
+            if newPos < 0:
+                break
+            PyArray_ITER_GOTO1D(iternew, newPos)
+
+        # Get the location in the old index
+        curLoc = oldMap[curOld]
+
+        # At the beginning of the old index
+        if oldPos == 0:
+
+            # Make sure we are before the curOld index
+            if PyArray_GETITEM(newIndex, <void *> iternew.dataptr) <= curOld:
+                fillVec[:newPos + 1] = curLoc
+                maskVec[:newPos + 1] = 1
+
+            # Exit the main loop
+            break
+
+        else:
+            # Move one position back
+            PyArray_ITER_GOTO1D(iterold, oldPos - 1)
+
+            # Get the index there
+            prevOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
+
+            # Until we reach the previous index
+            while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > prevOld:
+
+                # Set the current fill location
+                fillLocs[newPos] = curLoc
+                mask[newPos] = 1
+
+                newPos -= 1
+                if newPos < 0:
+                    break
+
+                # Move the iterator back
+                PyArray_ITER_GOTO1D(iternew, newPos)
+
+        # Move one period back
+        oldPos -= 1
+
+    for i from 0 <= i < newLength:
+        if mask[i] == 0:
+            # Fill from some generic location
+            fillLocs[i] = -1
+
+    return (fillVec, maskVec)
+
+cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
+    '''
+    Padding logic for generating fill vector
+
+    Diagram of what's going on
+
+    Old      New    Fill vector    Mask
+             .                        0
+             .                        0
+             .                        0
+    A        A        0               1
+             .        0               1
+             .        0               1
+             .        0               1
+             .        0               1
+             .        0               1
+    B        B        1               1
+             .        1               1
+             .        1               1
+             .        1               1
+    C        C        2               1
+    '''
+
+    # Declare variables
+    cdef ndarray fillVec
+    cdef ndarray maskVec
+    cdef int *fillLocs
+    cdef char *mask
+    cdef int i, j, oldLength, newLength, curLoc, newPos, oldPos
+    cdef flatiter iterold, iternew
+    cdef object nextOld, curOld
+    cdef char done
+
+    # Make empty fill vector and mask vector, cast to ndarray
+    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
+    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
+
+    # Get reference to the arrays inside
+    fillLocs = <int *> fillVec.data
+    mask = <char *> maskVec.data
+
+    # Create simple ndarray iterators using C API
+    iterold = PyArray_IterNew(oldIndex)
+    iternew = PyArray_IterNew(newIndex)
+
+    # Length of each index
+    oldLength = PyArray_SIZE(oldIndex)
+    newLength = PyArray_SIZE(newIndex)
+
+    oldPos = 0
+    newPos = 0
+    while newPos < newLength:
+        curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
+
+        # At beginning, keep going until we go exceed the
+        # first OLD index in the NEW index
+        while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < curOld:
+            newPos += 1
+            if newPos > newLength - 1:
+                break
+            PyArray_ITER_NEXT(iternew)
+
+        # We got there, get the current location in the old index
+        curLoc = oldMap[curOld]
+
+        # We're at the end of the road, need to propagate this value to the end
+        if oldPos == oldLength - 1:
+            if PyArray_GETITEM(newIndex, <void *> iternew.dataptr) >= curOld:
+                fillVec[newPos:] = curLoc
+                maskVec[newPos:] = 1
+            break
+        else:
+            # Not at the end, need to go about filling
+
+            # Get the next index so we know when to stop propagating this value
+            PyArray_ITER_NEXT(iterold)
+            nextOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
+
+            done = 0
+
+            # Until we reach the next OLD value in the NEW index
+            while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < nextOld:
+
+                # Use this location to fill
+                fillLocs[newPos] = curLoc
+
+                # Set mask to be 1 so will not be NaN'd
+                mask[newPos] = 1
+                newPos += 1
+
+                # We got to the end of the new index
+                if newPos > newLength - 1:
+                    done = 1
+                    break
+
+                # Advance the pointer
+                PyArray_ITER_NEXT(iternew)
+
+            # We got to the end of the new index
+            if done:
+                break
+
+        # We already advanced the iterold pointer to the next value,
+        # inc the count
+        oldPos += 1
+
+    # Places where the mask is 0, fill with an arbitrary value
+    # (will be NA'd out)
+    for i from 0 <= i < newLength:
+        if mask[i] == 0:
+            fillLocs[i] = -1
+
+    return fillVec, maskVec
+
+def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
+               object kind):
+
+    if kind == '':
+        fillVec, maskVec = _nofill(oldIndex, newIndex, oldMap, newMap)
+    elif kind == 'PAD':
+        fillVec, maskVec = _pad(oldIndex, newIndex, oldMap, newMap)
+    elif kind == 'BACKFILL':
+        fillVec, maskVec = _backfill(oldIndex, newIndex, oldMap, newMap)
+
+    return fillVec, maskVec.astype(np.bool)
+
+def getMergeVec(ndarray values, dict indexMap):
+    cdef int *fillLocs
+    cdef char *mask
+    cdef int i, j, length
+
+    cdef flatiter itervals
+    cdef object val
+    cdef ndarray fillVec
+    cdef ndarray maskVec
+
+    cdef int newLength = len(values)
+
+    fillVec = <ndarray> np.empty(newLength, dtype = np.int32)
+    maskVec = <ndarray> np.zeros(newLength, dtype = np.int8)
+
+    fillLocs = <int *> fillVec.data
+    mask = <char *> maskVec.data
+
+    length = PyArray_SIZE(values)
+    itervals = PyArray_IterNew(values)
+
+    for i from 0 <= i < length:
+        val = PyArray_GETITEM(values, <void *> itervals.dataptr)
+        if val in indexMap:
+            j = indexMap[val]
+            fillLocs[i] = j
+            mask[i] = 1
+
+        PyArray_ITER_NEXT(itervals)
+
+    for i from 0 <= i < newLength:
+        if mask[i] == 0:
+            fillLocs[i] = -1
+
+    return fillVec, maskVec.astype(np.bool)
+
diff --git a/pandas/lib/src/tseries.pyx b/pandas/lib/src/tseries.pyx
index aabc8a2d2..dc31345ce 100644
--- a/pandas/lib/src/tseries.pyx
+++ b/pandas/lib/src/tseries.pyx
@@ -1,1053 +1,6 @@
-include "numpy.pxi"
-include "Python.pxi"
-
-# initialize numpy
-import_array()
-
-import numpy as np
-cimport numpy as np
-
-isnan = np.isnan
-cdef double NaN = <double> np.NaN
-
-from python_dict cimport *
-from numpy cimport ndarray, npy_float64, npy_int32, npy_int8, npy_float128
-
-cimport cython
-
-cdef inline object trycall(object func, object arg):
-    cdef object result
-    try:
-        result = func(arg)
-    except:
-        raise Exception('Error calling func on index %s' % arg)
-    return result
-
-cdef inline int int_max(int a, int b): return a if a >= b else b
-cdef inline int int_min(int a, int b): return a if a >= b else b
-
-cdef extern from "wirth.h":
-    double kth_smallest(double *a, int n, int k)
-
-def median(ndarray arr):
-    cdef double *values
-    cdef int n = len(arr)
-
-    if len(arr) == 0:
-        return np.NaN
-
-    if not np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS):
-        arr = np.array(arr)
-
-    values = <double *> arr.data
-
-    if n % 2:
-        return kth_smallest(values, n, n / 2)
-    else:
-        return (kth_smallest(values, n, n / 2) +
-                kth_smallest(values, n, n / 2 - 1)) / 2
-
-def roll_median(ndarray[npy_float64, ndim=1] arr, int window, int minp):
-    cdef char *mask_data
-    cdef ndarray mask
-    cdef ndarray[npy_float64, ndim=1] result
-    cdef int i, n
-
-    n = len(arr)
-    arr = arr.copy()
-
-    mask = <ndarray> np.isfinite(arr)
-    mask_data = <char *> mask.data
-
-    result = np.empty(len(arr), dtype=float)
-
-    for i from minp <= i <= n:
-        pass
-
-def map_indices(ndarray index):
-    '''
-    Produce a dict mapping the values of the input array to their respective
-    locations.
-
-    Example:
-        array(['hi', 'there']) --> {'hi' : 0 , 'there' : 1}
-
-    Better to do this with Cython because of the enormous speed boost.
-    '''
-    cdef int i, length
-    cdef flatiter iter
-    cdef dict result
-    cdef object idx
-
-    result = {}
-
-    iter = PyArray_IterNew(index)
-
-    length = PyArray_SIZE(index)
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(index, <void *> iter.dataptr)
-        result[idx] = i
-        PyArray_ITER_NEXT(iter)
-
-    return result
-
-def match(ndarray A, ndarray B):
-    '''
-    --> match(a, b)
-
-    Close equivalent of R's match function.
-
-    For given input index A, find matching locations for values of A in B.
-
-    Example:
-    >>> b
-    array([[ 0.        ,  0.26929312],
-           [ 1.        ,  0.49540359],
-           [ 2.        ,  0.66389941],
-           [ 3.        ,  0.66235806],
-           [ 4.        ,  0.97993956],
-           [ 5.        ,  0.83804732],
-           [ 6.        ,  0.75033074],
-           [ 7.        ,  0.10250388],
-           [ 8.        ,  0.66591799],
-           [ 9.        ,  0.18337242]])
-    >>> a
-        array([1, 3, 6, 8, 4, 5, 7, 0, 2, 9])
-
-    # Now with match we can realign b based on a
-
-    >>> b[match(a, b[:,0]),:]
-    array([[ 1.        ,  0.49540359],
-           [ 3.        ,  0.66235806],
-           [ 6.        ,  0.75033074],
-           [ 8.        ,  0.66591799],
-           [ 4.        ,  0.97993956],
-           [ 5.        ,  0.83804732],
-           [ 7.        ,  0.10250388],
-           [ 0.        ,  0.26929312],
-           [ 2.        ,  0.66389941],
-           [ 9.        ,  0.18337242]])
-
-    '''
-
-    cdef int i, length
-    cdef flatiter itera
-    cdef dict bmap
-    cdef double *result_data
-    cdef double nan
-    cdef object idx
-    cdef ndarray result
-
-    nan = <double> np.NaN
-
-    bmap = map_indices(B)
-
-    itera = PyArray_IterNew(A)
-    length = PyArray_SIZE(A)
-
-    result = <ndarray> np.empty(length, np.float64)
-
-    result_data = <double *> result.data
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(A, <void *> itera.dataptr)
-        if idx in bmap:
-            result_data[i] = <double> bmap[idx]
-        else:
-            result_data[i] = nan
-
-        PyArray_ITER_NEXT(itera)
-
-    return result.astype(int)
-
-def reindex(ndarray index, ndarray arr, dict idxMap):
-    '''
-    Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to
-    the new index.
-
-    This is significantly faster than doing it in pure Python.
-    '''
-    cdef ndarray result
-    cdef double *result_data
-    cdef int i, length
-    cdef flatiter itera, iteridx
-    cdef double nan
-    cdef object idx
-
-    nan = <double> np.NaN
-
-    length = PyArray_SIZE(index)
-
-    result = <ndarray> np.empty(length, np.float64)
-
-    result_data = <double *> result.data
-
-    itera = PyArray_IterNew(arr)
-    iteridx = PyArray_IterNew(index)
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
-        PyArray_ITER_NEXT(iteridx)
-        if idx not in idxMap:
-            result_data[i] = nan
-            continue
-        PyArray_ITER_GOTO1D(itera, idxMap[idx])
-        result_data[i] = (<double *>(itera.dataptr))[0]
-
-    return result
-
-def reindexObj(ndarray index, ndarray arr, dict idxMap):
-    '''
-    Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to
-    the new index.
-
-    This is significantly faster than doing it in pure Python.
-    '''
-    cdef ndarray result
-    cdef int i, length
-    cdef flatiter itera, iteridx, iterresult
-    cdef object idx, nan, obj
-
-    nan = np.NaN
-    length = PyArray_SIZE(index)
-
-    result = <ndarray> np.empty(length, dtype=np.object_)
-
-    itera = PyArray_IterNew(arr)
-    iteridx = PyArray_IterNew(index)
-    iterresult = PyArray_IterNew(result)
-
-    cdef int res
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
-        PyArray_ITER_NEXT(iteridx)
-
-        if idx not in idxMap:
-            PyArray_SETITEM(result, <void *> iterresult.dataptr, nan)
-            PyArray_ITER_NEXT(iterresult)
-            continue
-
-        PyArray_ITER_GOTO1D(itera, idxMap[idx])
-        obj = PyArray_GETITEM(arr, <void *> itera.dataptr)
-
-        res = PyArray_SETITEM(result, <void *> iterresult.dataptr, obj)
-        PyArray_ITER_NEXT(iterresult)
-
-    return result
-
-@cython.boundscheck(False)
-def reindexObject(ndarray[object, ndim=1] index,
-                  ndarray[object, ndim=1] arr,
-                  dict idxMap):
-    '''
-    Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to
-    the new index.
-    '''
-    cdef int j, loc, length
-    cdef object idx, value
-    cdef object nan = np.NaN
-
-    length = index.shape[0]
-    cdef ndarray[object, ndim = 1] result = np.empty(length, dtype=object)
-
-    loc = 0
-    cdef int i = 0
-    for i from 0 <= i < length:
-        idx = index[i]
-        if not PyDict_Contains(idxMap, idx):
-            result[i] = nan
-            continue
-        value = arr[idxMap[idx]]
-        result[i] = value
-    return result
-
-cdef tuple _nofill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
-    cdef int *fillLocs
-    cdef char *mask
-    cdef int i, j, length, newLength
-
-    cdef flatiter iterold
-    cdef object idx
-    cdef ndarray fillVec
-    cdef ndarray maskVec
-
-    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
-    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
-
-    fillLocs = <int *> fillVec.data
-    mask = <char *> maskVec.data
-
-    newLength = PyArray_SIZE(fillVec)
-
-    length = PyArray_SIZE(oldIndex)
-    iterold = PyArray_IterNew(oldIndex)
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-        if i < length - 1:
-           PyArray_ITER_NEXT(iterold)
-        if idx in newMap:
-            j = newMap[idx]
-            fillLocs[j] = i
-            mask[j] = 1
-
-    for i from 0 <= i < newLength:
-        if mask[i] == 0:
-            fillLocs[i] = -1
-
-    return fillVec, maskVec
-
-cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
-    '''
-    Backfilling logic for generating fill vector
-
-    Diagram of what's going on
-
-    Old      New    Fill vector    Mask
-             .        0               1
-             .        0               1
-             .        0               1
-    A        A        0               1
-             .        1               1
-             .        1               1
-             .        1               1
-             .        1               1
-             .        1               1
-    B        B        1               1
-             .        2               1
-             .        2               1
-             .        2               1
-    C        C        2               1
-             .                        0
-             .                        0
-    D
-    '''
-    cdef int i, j, oldLength, newLength, curLoc
-    # Make empty vectors
-    cdef ndarray fillVec
-    cdef ndarray maskVec
-    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
-    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
-
-    # Get references
-    cdef int *fillLocs
-    cdef char *mask
-    fillLocs = <int *> fillVec.data
-    mask = <char *> maskVec.data
-
-    # Create the iterators
-    cdef flatiter iterold, iternew
-    iterold = PyArray_IterNew(oldIndex)
-    iternew = PyArray_IterNew(newIndex)
-
-    # Get the size
-    oldLength = PyArray_SIZE(oldIndex)
-    newLength = PyArray_SIZE(newIndex)
-
-    # Current positions
-    cdef int newPos, oldPos
-    oldPos = oldLength - 1
-    newPos = newLength - 1
-
-    # References holding indices
-    cdef object prevOld, curOld
-
-    while newPos >= 0:
-        # Move to the current position
-        PyArray_ITER_GOTO1D(iternew, newPos)
-        PyArray_ITER_GOTO1D(iterold, oldPos)
-
-        # Get the current index
-        curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-
-        # Until we reach a point where we are before the curOld point
-        while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > curOld:
-            newPos -= 1
-            if newPos < 0:
-                break
-            PyArray_ITER_GOTO1D(iternew, newPos)
-
-        # Get the location in the old index
-        curLoc = oldMap[curOld]
-
-        # At the beginning of the old index
-        if oldPos == 0:
-
-            # Make sure we are before the curOld index
-            if PyArray_GETITEM(newIndex, <void *> iternew.dataptr) <= curOld:
-                fillVec[:newPos + 1] = curLoc
-                maskVec[:newPos + 1] = 1
-
-            # Exit the main loop
-            break
-
-        else:
-            # Move one position back
-            PyArray_ITER_GOTO1D(iterold, oldPos - 1)
-
-            # Get the index there
-            prevOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-
-            # Until we reach the previous index
-            while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > prevOld:
-
-                # Set the current fill location
-                fillLocs[newPos] = curLoc
-                mask[newPos] = 1
-
-                newPos -= 1
-                if newPos < 0:
-                    break
-
-                # Move the iterator back
-                PyArray_ITER_GOTO1D(iternew, newPos)
-
-        # Move one period back
-        oldPos -= 1
-
-    for i from 0 <= i < newLength:
-        if mask[i] == 0:
-            # Fill from some generic location
-            fillLocs[i] = -1
-
-    return (fillVec, maskVec)
-
-cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
-    '''
-    Padding logic for generating fill vector
-
-    Diagram of what's going on
-
-    Old      New    Fill vector    Mask
-             .                        0
-             .                        0
-             .                        0
-    A        A        0               1
-             .        0               1
-             .        0               1
-             .        0               1
-             .        0               1
-             .        0               1
-    B        B        1               1
-             .        1               1
-             .        1               1
-             .        1               1
-    C        C        2               1
-    '''
-
-    # Declare variables
-    cdef ndarray fillVec
-    cdef ndarray maskVec
-    cdef int *fillLocs
-    cdef char *mask
-    cdef int i, j, oldLength, newLength, curLoc, newPos, oldPos
-    cdef flatiter iterold, iternew
-    cdef object nextOld, curOld
-    cdef char done
-
-    # Make empty fill vector and mask vector, cast to ndarray
-    fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
-    maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
-
-    # Get reference to the arrays inside
-    fillLocs = <int *> fillVec.data
-    mask = <char *> maskVec.data
-
-    # Create simple ndarray iterators using C API
-    iterold = PyArray_IterNew(oldIndex)
-    iternew = PyArray_IterNew(newIndex)
-
-    # Length of each index
-    oldLength = PyArray_SIZE(oldIndex)
-    newLength = PyArray_SIZE(newIndex)
-
-    oldPos = 0
-    newPos = 0
-    while newPos < newLength:
-        curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-
-        # At beginning, keep going until we go exceed the
-        # first OLD index in the NEW index
-        while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < curOld:
-            newPos += 1
-            if newPos > newLength - 1:
-                break
-            PyArray_ITER_NEXT(iternew)
-
-        # We got there, get the current location in the old index
-        curLoc = oldMap[curOld]
-
-        # We're at the end of the road, need to propagate this value to the end
-        if oldPos == oldLength - 1:
-            if PyArray_GETITEM(newIndex, <void *> iternew.dataptr) >= curOld:
-                fillVec[newPos:] = curLoc
-                maskVec[newPos:] = 1
-            break
-        else:
-            # Not at the end, need to go about filling
-
-            # Get the next index so we know when to stop propagating this value
-            PyArray_ITER_NEXT(iterold)
-            nextOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-
-            done = 0
-
-            # Until we reach the next OLD value in the NEW index
-            while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < nextOld:
-
-                # Use this location to fill
-                fillLocs[newPos] = curLoc
-
-                # Set mask to be 1 so will not be NaN'd
-                mask[newPos] = 1
-                newPos += 1
-
-                # We got to the end of the new index
-                if newPos > newLength - 1:
-                    done = 1
-                    break
-
-                # Advance the pointer
-                PyArray_ITER_NEXT(iternew)
-
-            # We got to the end of the new index
-            if done:
-                break
-
-        # We already advanced the iterold pointer to the next value,
-        # inc the count
-        oldPos += 1
-
-    # Places where the mask is 0, fill with an arbitrary value
-    # (will be NA'd out)
-    for i from 0 <= i < newLength:
-        if mask[i] == 0:
-            fillLocs[i] = -1
-
-    return fillVec, maskVec
-
-def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
-               object kind):
-
-    if kind == '':
-        fillVec, maskVec = _nofill(oldIndex, newIndex, oldMap, newMap)
-    elif kind == 'PAD':
-        fillVec, maskVec = _pad(oldIndex, newIndex, oldMap, newMap)
-    elif kind == 'BACKFILL':
-        fillVec, maskVec = _backfill(oldIndex, newIndex, oldMap, newMap)
-
-    return fillVec, maskVec.astype(np.bool)
-
-def getMergeVec(ndarray values, dict indexMap):
-    cdef int *fillLocs
-    cdef char *mask
-    cdef int i, j, length
-
-    cdef flatiter itervals
-    cdef object val
-    cdef ndarray fillVec
-    cdef ndarray maskVec
-
-    cdef int newLength = len(values)
-
-    fillVec = <ndarray> np.empty(newLength, dtype = np.int32)
-    maskVec = <ndarray> np.zeros(newLength, dtype = np.int8)
-
-    fillLocs = <int *> fillVec.data
-    mask = <char *> maskVec.data
-
-    length = PyArray_SIZE(values)
-    itervals = PyArray_IterNew(values)
-
-    for i from 0 <= i < length:
-        val = PyArray_GETITEM(values, <void *> itervals.dataptr)
-        if val in indexMap:
-            j = indexMap[val]
-            fillLocs[i] = j
-            mask[i] = 1
-
-        PyArray_ITER_NEXT(itervals)
-
-    for i from 0 <= i < newLength:
-        if mask[i] == 0:
-            fillLocs[i] = -1
-
-    return fillVec, maskVec.astype(np.bool)
-
-cdef double INF = <double> np.inf
-cdef double NEGINF = -INF
-
-cdef inline _checknull(object val):
-    return val is None or val != val or val == INF or val == NEGINF
-
-cdef ndarray _isnullobj(input):
-    cdef int i, length
-    cdef object val
-    cdef ndarray[npy_int8, ndim=1] result
-    cdef flatiter iter
-
-    length = PyArray_SIZE(input)
-
-    result = <ndarray> np.zeros(length, dtype=np.int8)
-
-    iter= PyArray_IterNew(input)
-
-    for i from 0 <= i < length:
-        val = PyArray_GETITEM(input, <void *> iter.dataptr)
-
-        if _checknull(val):
-            result[i] = 1
-
-        PyArray_ITER_NEXT(iter)
-
-    return result
-
-def isnull(input):
-    '''
-    Replacement for numpy.isnan / -numpy.isfinite which is suitable
-    for use on object arrays.
-
-    Parameters
-    ----------
-    arr: ndarray or object value
-
-    Returns
-    -------
-    boolean ndarray or boolean
-    '''
-    cdef ndarray[npy_int8, ndim=1] result
-
-    if isinstance(input, np.ndarray):
-        if input.dtype.kind in ('O', 'S'):
-            result = _isnullobj(input)
-
-            return result.astype(np.bool)
-        else:
-            return -np.isfinite(input)
-    else:
-        return _checknull(input)
-
-def notnull(input):
-    '''
-    Replacement for numpy.isfinite / -numpy.isnan which is suitable
-    for use on object arrays.
-
-    Parameters
-    ----------
-    arr: ndarray or object value
-
-    Returns
-    -------
-    boolean ndarray or boolean
-    '''
-    if isinstance(input, np.ndarray):
-        return -isnull(input)
-    else:
-        return not bool(_checknull(input))
-
-def reindexNew(ndarray index, ndarray arr, dict idxMap):
-    '''
-    Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to
-    the new index.
-
-    This is significantly faster than doing it in pure Python.
-    '''
-    cdef ndarray result
-    cdef double *result_data
-    cdef int i, length
-    cdef flatiter itera, iteridx
-    cdef double nan
-    cdef object idx
-
-    nan = <double> np.NaN
-
-    length = PyArray_SIZE(index)
-
-    result = <ndarray> np.empty(length, np.float64)
-
-    result_data = <double *> result.data
-
-    itera = PyArray_IterNew(arr)
-    iteridx = PyArray_IterNew(index)
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
-        PyArray_ITER_NEXT(iteridx)
-        if idx not in idxMap:
-            result_data[i] = nan
-            continue
-        PyArray_ITER_GOTO1D(itera, idxMap[idx])
-        result_data[i] = (<double *>(itera.dataptr))[0]
-
-    return result
-
-cdef double __add(double a, double b):
-    return a + b
-cdef double __sub(double a, double b):
-    return a - b
-cdef double __div(double a, double b):
-    return a / b
-cdef double __mul(double a, double b):
-    return a * b
-cdef double __eq(double a, double b):
-    return a == b
-cdef double __ne(double a, double b):
-    return a != b
-cdef double __lt(double a, double b):
-    return a < b
-cdef double __gt(double a, double b):
-    return a > b
-cdef double __pow(double a, double b):
-    return a ** b
-
-ctypedef double (* double_func)(double a, double b)
-
-cdef ndarray _applyFunc(double_func func, ndarray index, object ao,
-                        object bo, dict aMap, dict bMap):
-    '''
-    C function taking a function pointer for quickly adding two Series objects.
-    '''
-    cdef ndarray A, B, result
-    cdef double *result_data
-    cdef int i, length
-    cdef flatiter itera, iterb, iteridx
-    cdef double nan
-    cdef object idx
-
-    # This is EXTREMELY important, otherwise you will get very
-    # undesired results
-    A = PyArray_ContiguousFromAny(ao, NPY_DOUBLE, 1, 1)
-    B = PyArray_ContiguousFromAny(bo, NPY_DOUBLE, 1, 1)
-
-    nan = <double> np.NaN
-    length = PyArray_SIZE(index)
-
-    result = <ndarray> np.empty(length, np.float64)
-    result_data = <double *>result.data
-
-    itera = <flatiter> PyArray_IterNew(A)
-    iterb = <flatiter> PyArray_IterNew(B)
-    iteridx = PyArray_IterNew(index)
-
-    for i from 0 <= i < length:
-        idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
-        PyArray_ITER_NEXT(iteridx)
-
-        if idx not in aMap or idx not in bMap:
-            result_data[i] = nan
-            continue
-
-        result_data[i] = func((<double *>A.data)[aMap[idx]],
-                            (<double *>B.data)[bMap[idx]])
-
-    return result
-
-def combineFunc(object name, ndarray index, object ao,
-                object bo, dict aMap, dict bMap):
-    '''
-    Combine two series (values and index maps for each passed in) using the
-    indicated function.
-    '''
-    if name == "__add__":
-        return _applyFunc(__add, index, ao, bo, aMap, bMap)
-    elif name == "__sub__":
-        return _applyFunc(__sub, index, ao, bo, aMap, bMap)
-    elif name == "__div__":
-        return _applyFunc(__div, index, ao, bo, aMap, bMap)
-    elif name == "__mul__":
-        return _applyFunc(__mul, index, ao, bo, aMap, bMap)
-    elif name == "__eq__":
-        return _applyFunc(__eq, index, ao, bo, aMap, bMap)
-    elif name == "__ne__":
-        return _applyFunc(__ne, index, ao, bo, aMap, bMap)
-    elif name == "__lt__":
-        return _applyFunc(__lt, index, ao, bo, aMap, bMap)
-    elif name == "__gt__":
-        return _applyFunc(__gt, index, ao, bo, aMap, bMap)
-    elif name == "__pow__":
-        return _applyFunc(__pow, index, ao, bo, aMap, bMap)
-    else:
-        raise Exception('bad funcname requested of Cython code')
-
-#-------------------------------------------------------------------------------
-# Groupby-related functions
-
-@cython.boundscheck(False)
-def arrmap(ndarray[object, ndim=1] index, object func):
-    cdef int length = index.shape[0]
-    cdef int i = 0
-
-    cdef ndarray[object, ndim=1] result = np.empty(length, dtype=np.object_)
-
-    for i from 0 <= i < length:
-        result[i] = func(index[i])
-
-    return result
-
-@cython.boundscheck(False)
-def groupby_withnull_old(ndarray[object, ndim = 1] index, object keyfunc):
-    cdef dict groups
-    cdef int length = index.shape[0]
-    cdef object idx
-    cdef object curKey, key
-    cdef list members
-
-    groups = PyDict_New()
-
-    if length != index.shape[0]:
-        raise Exception('Dates and values were not the same length!')
-
-    cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
-
-    cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
-
-    bool_mask = null_mask.astype(bool)
-
-    null_values = np.asarray(index)[bool_mask]
-
-    if null_values.any():
-        PyDict_SetItem(groups, np.NaN, null_values)
-
-    cdef int i = 0
-    idx = index[0]
-    key = mapped_index[0]
-
-    # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem,
-    #   'lazily' evaluates
-
-    while i < length:
-        if not PyDict_Contains(groups, key):
-            members = [idx]
-            PyDict_SetItem(groups, key, members)
-            i += 1
-            curKey = key
-            while i < length:
-                if null_mask[i]:
-                    i += 1
-                    continue
-
-                idx = index[i]
-                key = mapped_index[i]
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-        else:
-            members = <list> PyDict_GetItem(groups, key)
-            members.append(idx)
-            i += 1
-            curKey = key
-            while null_mask[i] and i < length:
-                i += 1
-
-            while i < length:
-                if null_mask[i]:
-                    i += 1
-                    continue
-
-                idx = index[i]
-                key = mapped_index[i]
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-
-    return groups
-
-@cython.boundscheck(False)
-def groupby_withnull(ndarray[object, ndim = 1] index, object keyfunc):
-    cdef dict groups
-    cdef int length = index.shape[0]
-    cdef object idx
-    cdef object curKey, key
-    cdef list members
-
-    groups = PyDict_New()
-
-    if length != index.shape[0]:
-        raise Exception('Dates and values were not the same length!')
-
-    cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
-
-    cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
-
-    bool_mask = null_mask.astype(bool)
-
-    null_values = np.asarray(index)[bool_mask]
-
-    if null_values.any():
-        PyDict_SetItem(groups, np.NaN, null_values)
-
-    cdef int i = 0
-    idx = index[0]
-    key = mapped_index[0]
-
-    # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem,
-    #   'lazily' evaluates
-
-    while i < length:
-        if key not in groups:
-            members = [idx]
-            groups[key] = members
-            i += 1
-            curKey = key
-            while i < length:
-                if null_mask[i]:
-                    i += 1
-                    continue
-
-                idx = index[i]
-                key = mapped_index[i]
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-        else:
-            members = <list> groups[key]
-            members.append(idx)
-            i += 1
-            curKey = key
-            while null_mask[i] and i < length:
-                i += 1
-
-            while i < length:
-                if null_mask[i]:
-                    i += 1
-                    continue
-
-                idx = index[i]
-                key = mapped_index[i]
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-
-    return groups
-
-@cython.boundscheck(False)
-def groupby(ndarray[object, ndim = 1] index, object keyfunc):
-    cdef dict groups
-    cdef int length = index.shape[0]
-    cdef object idx
-    cdef object curKey, key
-    cdef list members
-
-    groups = PyDict_New()
-
-    if length != index.shape[0]:
-        raise Exception('Dates and values were not the same length!')
-
-    cdef int i = 0
-    idx = index[i]
-    key = keyfunc(idx)
-
-    # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem, 'lazily' evaluates
-
-    while i < length:
-        if not PyDict_Contains(groups, key):
-            members = [idx]
-            PyDict_SetItem(groups, key, members)
-            i += 1
-            curKey = key
-            while i < length:
-                idx = index[i]
-                key = trycall(keyfunc, idx)
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-        else:
-            members = <list> PyDict_GetItem(groups, key)
-            members.append(idx)
-            i += 1
-            curKey = key
-            while i < length:
-                idx = index[i]
-                key = trycall(keyfunc, idx)
-                if key == curKey:
-                    members.append(idx)
-                    i += 1
-                else:
-                    break
-
-    return groups
-
-@cython.boundscheck(False)
-def groupbyfunc(ndarray[object, ndim = 1] index,
-                ndarray[npy_float64, ndim = 1] values,
-                object keyfunc, object applyfunc):
-    '''
-    Doing this proper in Cython
-    Not sure how much it will really speed things up
-    '''
-    cdef dict groups
-    cdef int length = values.shape[0]
-    cdef object idx
-    cdef object curKey, key
-    cdef list members, grouplist
-
-    groups = PyDict_New()
-
-    if length != index.shape[0]:
-        raise Exception('Dates and values were not the same length!')
-
-    cdef int i = 0
-    idx = index[i]
-    key = trycall(keyfunc, idx)
-
-    # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem,
-    #   'lazily' evaluates
-
-    while i < length:
-        if not PyDict_Contains(groups, key):
-            members = [values[i]]
-            PyDict_SetItem(groups, key, members)
-            i += 1
-            curKey = key
-            while i < length:
-                idx = index[i]
-                key = trycall(keyfunc, idx)
-                if key == curKey:
-                    members.append(values[i])
-                    i += 1
-                else:
-                    break
-        else:
-            members = <list> PyDict_GetItem(groups, key)
-            members.append(values[i])
-            i += 1
-            curKey = key
-            while i < length:
-                idx = index[i]
-                key = trycall(keyfunc, idx)
-                if key == curKey:
-                    members.append(values[i])
-                    i += 1
-                else:
-                    break
-
-    grouplist = PyDict_Keys(groups)
-
-    i = 0
-    length = len(grouplist)
-    for i from 0 <= i < length:
-        key = grouplist[i]
-        members = <list> PyDict_GetItem(groups, key)
-        PyDict_SetItem(groups, key, applyfunc(np.asarray(members)))
-
-    return groups
+include "common.pyx"
+include "isnull.pyx"
+include "groupby.pyx"
+include "moments.pyx"
+include "reindex.pyx"
+include "operators.pyx"
