commit 4edf938aedf55b9e6fbfb3199f70f857e8ec7e41
Author: Simon Hawkins <simonjayhawkins@gmail.com>
Date:   Wed Jul 10 17:17:54 2019 +0100

    TST/CLN: replace %s formatting syntax with .format in tests (#27324)

diff --git a/pandas/tests/arrays/categorical/test_dtypes.py b/pandas/tests/arrays/categorical/test_dtypes.py
index be64b1f28..c08ad1da3 100644
--- a/pandas/tests/arrays/categorical/test_dtypes.py
+++ b/pandas/tests/arrays/categorical/test_dtypes.py
@@ -92,20 +92,22 @@ class TestCategoricalDtypes:
         result = Categorical(["foo", "bar", "baz"])
         assert result.codes.dtype == "int8"
 
-        result = Categorical(["foo%05d" % i for i in range(400)])
+        result = Categorical(["foo{i:05d}".format(i=i) for i in range(400)])
         assert result.codes.dtype == "int16"
 
-        result = Categorical(["foo%05d" % i for i in range(40000)])
+        result = Categorical(["foo{i:05d}".format(i=i) for i in range(40000)])
         assert result.codes.dtype == "int32"
 
         # adding cats
         result = Categorical(["foo", "bar", "baz"])
         assert result.codes.dtype == "int8"
-        result = result.add_categories(["foo%05d" % i for i in range(400)])
+        result = result.add_categories(["foo{i:05d}".format(i=i) for i in range(400)])
         assert result.codes.dtype == "int16"
 
         # removing cats
-        result = result.remove_categories(["foo%05d" % i for i in range(300)])
+        result = result.remove_categories(
+            ["foo{i:05d}".format(i=i) for i in range(300)]
+        )
         assert result.codes.dtype == "int8"
 
     @pytest.mark.parametrize("ordered", [True, False])
diff --git a/pandas/tests/arrays/sparse/test_libsparse.py b/pandas/tests/arrays/sparse/test_libsparse.py
index 183eaada1..a6836c583 100644
--- a/pandas/tests/arrays/sparse/test_libsparse.py
+++ b/pandas/tests/arrays/sparse/test_libsparse.py
@@ -596,6 +596,6 @@ class TestSparseOperators:
 
     @pytest.mark.parametrize("opname", ["add", "sub", "mul", "truediv", "floordiv"])
     def test_op(self, opname):
-        sparse_op = getattr(splib, "sparse_%s_float64" % opname)
+        sparse_op = getattr(splib, "sparse_{opname}_float64".format(opname=opname))
         python_op = getattr(operator, opname)
         self._op_tests(sparse_op, python_op)
diff --git a/pandas/tests/computation/test_eval.py b/pandas/tests/computation/test_eval.py
index 49d11f58e..8c0930c04 100644
--- a/pandas/tests/computation/test_eval.py
+++ b/pandas/tests/computation/test_eval.py
@@ -736,16 +736,16 @@ class TestEvalNumexprPandas:
 
         df = pd.DataFrame({"A": [1000000000.0009, 1000000000.0011, 1000000000.0015]})
         cutoff = 1000000000.0006
-        result = df.query("A < %.4f" % cutoff)
+        result = df.query("A < {cutoff:.4f}".format(cutoff=cutoff))
         assert result.empty
 
         cutoff = 1000000000.0010
-        result = df.query("A > %.4f" % cutoff)
+        result = df.query("A > {cutoff:.4f}".format(cutoff=cutoff))
         expected = df.loc[[1, 2], :]
         tm.assert_frame_equal(expected, result)
 
         exact = 1000000000.0011
-        result = df.query("A == %.4f" % exact)
+        result = df.query("A == {exact:.4f}".format(exact=exact))
         expected = df.loc[[1], :]
         tm.assert_frame_equal(expected, result)
 
diff --git a/pandas/tests/dtypes/test_inference.py b/pandas/tests/dtypes/test_inference.py
index 6824266c9..0b440e018 100644
--- a/pandas/tests/dtypes/test_inference.py
+++ b/pandas/tests/dtypes/test_inference.py
@@ -1349,7 +1349,7 @@ class TestIsScalar:
 
 def test_datetimeindex_from_empty_datetime64_array():
     for unit in ["ms", "us", "ns"]:
-        idx = DatetimeIndex(np.array([], dtype="datetime64[%s]" % unit))
+        idx = DatetimeIndex(np.array([], dtype="datetime64[{unit}]".format(unit=unit)))
         assert len(idx) == 0
 
 
diff --git a/pandas/tests/frame/test_alter_axes.py b/pandas/tests/frame/test_alter_axes.py
index 912e8b5fb..c57b2a696 100644
--- a/pandas/tests/frame/test_alter_axes.py
+++ b/pandas/tests/frame/test_alter_axes.py
@@ -342,7 +342,7 @@ class TestDataFrameAlterAxes:
                 self.color = color
 
             def __str__(self):
-                return "<Thing %r>" % (self.name,)
+                return "<Thing {self.name!r}>".format(self=self)
 
             # necessary for pretty KeyError
             __repr__ = __str__
@@ -419,7 +419,7 @@ class TestDataFrameAlterAxes:
                 self.color = color
 
             def __str__(self):
-                return "<Thing %r>" % (self.name,)
+                return "<Thing {self.name!r}>".format(self=self)
 
         thing1 = Thing("One", "red")
         thing2 = Thing("Two", "blue")
diff --git a/pandas/tests/frame/test_api.py b/pandas/tests/frame/test_api.py
index 76a210e12..fe59f0574 100644
--- a/pandas/tests/frame/test_api.py
+++ b/pandas/tests/frame/test_api.py
@@ -74,19 +74,19 @@ class SharedWithSparse:
 
     def test_add_prefix_suffix(self, float_frame):
         with_prefix = float_frame.add_prefix("foo#")
-        expected = pd.Index(["foo#%s" % c for c in float_frame.columns])
+        expected = pd.Index(["foo#{c}".format(c=c) for c in float_frame.columns])
         tm.assert_index_equal(with_prefix.columns, expected)
 
         with_suffix = float_frame.add_suffix("#foo")
-        expected = pd.Index(["%s#foo" % c for c in float_frame.columns])
+        expected = pd.Index(["{c}#foo".format(c=c) for c in float_frame.columns])
         tm.assert_index_equal(with_suffix.columns, expected)
 
         with_pct_prefix = float_frame.add_prefix("%")
-        expected = pd.Index(["%{}".format(c) for c in float_frame.columns])
+        expected = pd.Index(["%{c}".format(c=c) for c in float_frame.columns])
         tm.assert_index_equal(with_pct_prefix.columns, expected)
 
         with_pct_suffix = float_frame.add_suffix("%")
-        expected = pd.Index(["{}%".format(c) for c in float_frame.columns])
+        expected = pd.Index(["{c}%".format(c=c) for c in float_frame.columns])
         tm.assert_index_equal(with_pct_suffix.columns, expected)
 
     def test_get_axis(self, float_frame):
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index eca827f82..a3817d3c2 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -264,7 +264,7 @@ class TestDataFrameConstructors:
         nitems = 100
         nums = list(range(nitems))
         random.shuffle(nums)
-        expected = ["A%d" % i for i in nums]
+        expected = ["A{i:d}".format(i=i) for i in nums]
         df = DataFrame(OrderedDict(zip(expected, [[0]] * nitems)))
         assert expected == list(df.columns)
 
diff --git a/pandas/tests/frame/test_query_eval.py b/pandas/tests/frame/test_query_eval.py
index 0781e20a7..82c197ac0 100644
--- a/pandas/tests/frame/test_query_eval.py
+++ b/pandas/tests/frame/test_query_eval.py
@@ -453,7 +453,9 @@ class TestDataFrameQueryNumExprPandas:
 
         for op in ["<", ">", "<=", ">="]:
             with pytest.raises(TypeError):
-                df.query("dates %s nondate" % op, parser=parser, engine=engine)
+                df.query(
+                    "dates {op} nondate".format(op=op), parser=parser, engine=engine
+                )
 
     def test_query_syntax_error(self):
         engine, parser = self.engine, self.parser
@@ -688,7 +690,7 @@ class TestDataFrameQueryNumExprPandas:
         ops = "==", "!="
         d = dict(zip(ops, (operator.eq, operator.ne)))
         for op, f in d.items():
-            q = "a %s inf" % op
+            q = "a {op} inf".format(op=op)
             expected = df[f(df.a, np.inf)]
             result = df.query(q, engine=self.engine, parser=self.parser)
             assert_frame_equal(result, expected)
diff --git a/pandas/tests/frame/test_repr_info.py b/pandas/tests/frame/test_repr_info.py
index c33b758d2..48f42b5f1 100644
--- a/pandas/tests/frame/test_repr_info.py
+++ b/pandas/tests/frame/test_repr_info.py
@@ -285,7 +285,7 @@ class TestDataFrameReprInfoEtc(TestData):
         df.info(buf=buf)
         res = buf.getvalue()
         for i, dtype in enumerate(dtypes):
-            name = "%d    %d non-null %s" % (i, n, dtype)
+            name = "{i:d}    {n:d} non-null {dtype}".format(i=i, n=n, dtype=dtype)
             assert name in res
 
     def test_info_max_cols(self):
diff --git a/pandas/tests/frame/test_timeseries.py b/pandas/tests/frame/test_timeseries.py
index 1ca833315..b8708e6ca 100644
--- a/pandas/tests/frame/test_timeseries.py
+++ b/pandas/tests/frame/test_timeseries.py
@@ -223,7 +223,7 @@ class TestDataFrameTimeSeriesMethods(TestData):
         ns_dtype = np.dtype("M8[ns]")
 
         for unit in units:
-            dtype = np.dtype("M8[%s]" % unit)
+            dtype = np.dtype("M8[{unit}]".format(unit=unit))
             vals = np.arange(n, dtype=np.int64).view(dtype)
 
             df = DataFrame({"ints": np.arange(n)}, index=np.arange(n))
@@ -239,7 +239,7 @@ class TestDataFrameTimeSeriesMethods(TestData):
         df["dates"] = np.arange(n, dtype=np.int64).view(ns_dtype)
 
         for unit in units:
-            dtype = np.dtype("M8[%s]" % unit)
+            dtype = np.dtype("M8[{unit}]".format(unit=unit))
             vals = np.arange(n, dtype=np.int64).view(dtype)
 
             tmp = df.copy()
diff --git a/pandas/tests/frame/test_to_csv.py b/pandas/tests/frame/test_to_csv.py
index 33f29c6f8..28051d9b7 100644
--- a/pandas/tests/frame/test_to_csv.py
+++ b/pandas/tests/frame/test_to_csv.py
@@ -718,7 +718,7 @@ class TestDataFrameToCSV(TestData):
 
     def test_to_csv_mixed(self):
         def create_cols(name):
-            return ["%s%03d" % (name, i) for i in range(5)]
+            return ["{name}{i:03d}".format(name=name, i=i) for i in range(5)]
 
         df_float = DataFrame(
             np.random.randn(100, 5), dtype="float64", columns=create_cols("float")
diff --git a/pandas/tests/groupby/aggregate/test_other.py b/pandas/tests/groupby/aggregate/test_other.py
index 7905575a4..103ebf514 100644
--- a/pandas/tests/groupby/aggregate/test_other.py
+++ b/pandas/tests/groupby/aggregate/test_other.py
@@ -473,7 +473,8 @@ def test_agg_timezone_round_trip():
     assert result3 == ts
 
     dates = [
-        pd.Timestamp("2016-01-0%d 12:00:00" % i, tz="US/Pacific") for i in range(1, 5)
+        pd.Timestamp("2016-01-0{i:d} 12:00:00".format(i=i), tz="US/Pacific")
+        for i in range(1, 5)
     ]
     df = pd.DataFrame({"A": ["a", "b"] * 2, "B": dates})
     grouped = df.groupby("A")
diff --git a/pandas/tests/groupby/test_apply.py b/pandas/tests/groupby/test_apply.py
index 44a583bf6..765885495 100644
--- a/pandas/tests/groupby/test_apply.py
+++ b/pandas/tests/groupby/test_apply.py
@@ -265,7 +265,7 @@ def test_apply_concat_preserve_names(three_group):
         result = group.describe()
 
         # names are different
-        result.index.name = "stat_%d" % len(group)
+        result.index.name = "stat_{:d}".format(len(group))
 
         result = result[: len(group)]
         # weirdo
diff --git a/pandas/tests/groupby/test_bin_groupby.py b/pandas/tests/groupby/test_bin_groupby.py
index 7c12b490f..b240876de 100644
--- a/pandas/tests/groupby/test_bin_groupby.py
+++ b/pandas/tests/groupby/test_bin_groupby.py
@@ -95,7 +95,7 @@ def test_group_ohlc():
         counts = np.zeros(len(out), dtype=np.int64)
         labels = ensure_int64(np.repeat(np.arange(3), np.diff(np.r_[0, bins])))
 
-        func = getattr(groupby, "group_ohlc_%s" % dtype)
+        func = getattr(groupby, "group_ohlc_{dtype}".format(dtype=dtype))
         func(out, counts, obj[:, None], labels)
 
         def _ohlc(group):
diff --git a/pandas/tests/groupby/test_counting.py b/pandas/tests/groupby/test_counting.py
index 5a864b3ab..7e5180a5c 100644
--- a/pandas/tests/groupby/test_counting.py
+++ b/pandas/tests/groupby/test_counting.py
@@ -197,8 +197,11 @@ class TestCounting:
     @pytest.mark.parametrize(
         "datetimelike",
         [
-            [Timestamp("2016-05-%02d 20:09:25+00:00" % i) for i in range(1, 4)],
-            [Timestamp("2016-05-%02d 20:09:25" % i) for i in range(1, 4)],
+            [
+                Timestamp("2016-05-{i:02d} 20:09:25+00:00".format(i=i))
+                for i in range(1, 4)
+            ],
+            [Timestamp("2016-05-{i:02d} 20:09:25".format(i=i)) for i in range(1, 4)],
             [Timedelta(x, unit="h") for x in range(1, 4)],
             [Period(freq="2W", year=2017, month=x) for x in range(1, 4)],
         ],
diff --git a/pandas/tests/indexes/datetimelike.py b/pandas/tests/indexes/datetimelike.py
index 1b3c4e65d..7523b250e 100644
--- a/pandas/tests/indexes/datetimelike.py
+++ b/pandas/tests/indexes/datetimelike.py
@@ -36,7 +36,7 @@ class DatetimeLike(Base):
         # test the string repr
         idx = self.create_index()
         idx.name = "foo"
-        assert not "length=%s" % len(idx) in str(idx)
+        assert not "length={}".format(len(idx)) in str(idx)
         assert "'foo'" in str(idx)
         assert idx.__class__.__name__ in str(idx)
 
@@ -44,7 +44,7 @@ class DatetimeLike(Base):
             if idx.tz is not None:
                 assert idx.tz in str(idx)
         if hasattr(idx, "freq"):
-            assert "freq='%s'" % idx.freqstr in str(idx)
+            assert "freq='{idx.freqstr}'".format(idx=idx) in str(idx)
 
     def test_view(self):
         i = self.create_index()
diff --git a/pandas/tests/indexes/datetimes/test_datetime.py b/pandas/tests/indexes/datetimes/test_datetime.py
index aeff48986..bb3fe7a13 100644
--- a/pandas/tests/indexes/datetimes/test_datetime.py
+++ b/pandas/tests/indexes/datetimes/test_datetime.py
@@ -90,7 +90,7 @@ class TestDatetimeIndex:
     def test_hash_error(self):
         index = date_range("20010101", periods=10)
         with pytest.raises(
-            TypeError, match=("unhashable type: %r" % type(index).__name__)
+            TypeError, match=("unhashable type: {0.__name__!r}".format(type(index)))
         ):
             hash(index)
 
diff --git a/pandas/tests/indexes/multi/test_integrity.py b/pandas/tests/indexes/multi/test_integrity.py
index dba75b624..472a404c2 100644
--- a/pandas/tests/indexes/multi/test_integrity.py
+++ b/pandas/tests/indexes/multi/test_integrity.py
@@ -253,7 +253,9 @@ def test_rangeindex_fallback_coercion_bug():
 
 def test_hash_error(indices):
     index = indices
-    with pytest.raises(TypeError, match=("unhashable type: %r" % type(index).__name__)):
+    with pytest.raises(
+        TypeError, match=("unhashable type: {0.__name__!r}".format(type(index)))
+    ):
         hash(indices)
 
 
diff --git a/pandas/tests/indexes/period/test_construction.py b/pandas/tests/indexes/period/test_construction.py
index eab55b91b..8c75fbbae 100644
--- a/pandas/tests/indexes/period/test_construction.py
+++ b/pandas/tests/indexes/period/test_construction.py
@@ -363,7 +363,7 @@ class TestPeriodIndex:
         year = pd.Series([2001, 2002, 2003])
         quarter = year - 2000
         idx = PeriodIndex(year=year, quarter=quarter)
-        strs = ["%dQ%d" % t for t in zip(quarter, year)]
+        strs = ["{t[0]:d}Q{t[1]:d}".format(t=t) for t in zip(quarter, year)]
         lops = list(map(Period, strs))
         p = PeriodIndex(lops)
         tm.assert_index_equal(p, idx)
diff --git a/pandas/tests/indexes/period/test_tools.py b/pandas/tests/indexes/period/test_tools.py
index 1db2c5c3a..a9c0ecd1a 100644
--- a/pandas/tests/indexes/period/test_tools.py
+++ b/pandas/tests/indexes/period/test_tools.py
@@ -161,7 +161,7 @@ class TestPeriodIndex:
     @pytest.mark.parametrize("month", MONTHS)
     def test_to_period_quarterly(self, month):
         # make sure we can make the round trip
-        freq = "Q-%s" % month
+        freq = "Q-{month}".format(month=month)
         rng = period_range("1989Q3", "1991Q3", freq=freq)
         stamps = rng.to_timestamp()
         result = stamps.to_period(freq)
diff --git a/pandas/tests/indexes/test_common.py b/pandas/tests/indexes/test_common.py
index b9bdaf40f..0400b7810 100644
--- a/pandas/tests/indexes/test_common.py
+++ b/pandas/tests/indexes/test_common.py
@@ -163,7 +163,7 @@ class TestCommon:
     def test_hash_error(self, indices):
         index = indices
         with pytest.raises(
-            TypeError, match=("unhashable type: %r" % type(index).__name__)
+            TypeError, match=("unhashable type: {0.__name__!r}".format(type(index)))
         ):
             hash(indices)
 
diff --git a/pandas/tests/indexes/timedeltas/test_timedelta.py b/pandas/tests/indexes/timedeltas/test_timedelta.py
index 018ccfb24..e790a913f 100644
--- a/pandas/tests/indexes/timedeltas/test_timedelta.py
+++ b/pandas/tests/indexes/timedeltas/test_timedelta.py
@@ -239,7 +239,7 @@ class TestTimedeltaIndex(DatetimeLike):
     def test_hash_error(self):
         index = timedelta_range("1 days", periods=10)
         with pytest.raises(
-            TypeError, match=("unhashable type: %r" % type(index).__name__)
+            TypeError, match=("unhashable type: {0.__name__!r}".format(type(index)))
         ):
             hash(index)
 
diff --git a/pandas/tests/indexing/common.py b/pandas/tests/indexing/common.py
index 9f1ab82ec..9ceeb06b6 100644
--- a/pandas/tests/indexing/common.py
+++ b/pandas/tests/indexing/common.py
@@ -16,7 +16,7 @@ _verbose = False
 
 
 def _mklbl(prefix, n):
-    return ["%s%s" % (prefix, i) for i in range(n)]
+    return ["{prefix}{i}".format(prefix=prefix, i=i) for i in range(n)]
 
 
 def _axify(obj, key, axis):
@@ -105,7 +105,7 @@ class Base:
 
             d = dict()
             for t in self._typs:
-                d[t] = getattr(self, "%s_%s" % (o, t), None)
+                d[t] = getattr(self, "{o}_{t}".format(o=o, t=t), None)
 
             setattr(self, o, d)
 
@@ -247,7 +247,7 @@ class Base:
                 # if we are in fails, the ok, otherwise raise it
                 if fails is not None:
                     if isinstance(detail, fails):
-                        result = "ok (%s)" % type(detail).__name__
+                        result = "ok ({0.__name__})".format(type(detail))
                         _print(result)
                         return
 
diff --git a/pandas/tests/indexing/test_iloc.py b/pandas/tests/indexing/test_iloc.py
index 60a6a509c..85eab91af 100644
--- a/pandas/tests/indexing/test_iloc.py
+++ b/pandas/tests/indexing/test_iloc.py
@@ -729,7 +729,9 @@ class TestiLoc(Base):
                     r = expected.get(key)
                     if r != ans:
                         raise AssertionError(
-                            "[%s] does not match [%s], received [%s]" % (key, ans, r)
+                            "[{key}] does not match [{ans}], received [{r}]".format(
+                                key=key, ans=ans, r=r
+                            )
                         )
 
     def test_iloc_non_unique_indexing(self):
diff --git a/pandas/tests/indexing/test_ix.py b/pandas/tests/indexing/test_ix.py
index ee62c91ad..45ccd8d1b 100644
--- a/pandas/tests/indexing/test_ix.py
+++ b/pandas/tests/indexing/test_ix.py
@@ -292,8 +292,8 @@ class TestIX:
     def test_ix_setitem_out_of_bounds_axis_0(self):
         df = DataFrame(
             np.random.randn(2, 5),
-            index=["row%s" % i for i in range(2)],
-            columns=["col%s" % i for i in range(5)],
+            index=["row{i}".format(i=i) for i in range(2)],
+            columns=["col{i}".format(i=i) for i in range(5)],
         )
         with catch_warnings(record=True):
             msg = "cannot set by positional indexing with enlargement"
@@ -303,8 +303,8 @@ class TestIX:
     def test_ix_setitem_out_of_bounds_axis_1(self):
         df = DataFrame(
             np.random.randn(5, 2),
-            index=["row%s" % i for i in range(5)],
-            columns=["col%s" % i for i in range(2)],
+            index=["row{i}".format(i=i) for i in range(5)],
+            columns=["col{i}".format(i=i) for i in range(2)],
         )
         with catch_warnings(record=True):
             msg = "cannot set by positional indexing with enlargement"
diff --git a/pandas/tests/internals/test_internals.py b/pandas/tests/internals/test_internals.py
index 2d4fb87d0..655e484bc 100644
--- a/pandas/tests/internals/test_internals.py
+++ b/pandas/tests/internals/test_internals.py
@@ -110,7 +110,9 @@ def create_block(typestr, placement, item_shape=None, num_offset=0):
     elif typestr in ("complex", "c16", "c8"):
         values = 1.0j * (mat.astype(typestr) + num_offset)
     elif typestr in ("object", "string", "O"):
-        values = np.reshape(["A%d" % i for i in mat.ravel() + num_offset], shape)
+        values = np.reshape(
+            ["A{i:d}".format(i=i) for i in mat.ravel() + num_offset], shape
+        )
     elif typestr in ("b", "bool"):
         values = np.ones(shape, dtype=np.bool_)
     elif typestr in ("datetime", "dt", "M8[ns]"):
diff --git a/pandas/tests/io/excel/test_readers.py b/pandas/tests/io/excel/test_readers.py
index cd8848828..a39cface0 100644
--- a/pandas/tests/io/excel/test_readers.py
+++ b/pandas/tests/io/excel/test_readers.py
@@ -537,7 +537,7 @@ class TestReaders:
             # fails on some systems
             import platform
 
-            pytest.skip("failing on %s" % " ".join(platform.uname()).strip())
+            pytest.skip("failing on {}".format(" ".join(platform.uname()).strip()))
 
         tm.assert_frame_equal(url_table, local_table)
 
diff --git a/pandas/tests/io/excel/test_style.py b/pandas/tests/io/excel/test_style.py
index 7ee84077a..8862f85ae 100644
--- a/pandas/tests/io/excel/test_style.py
+++ b/pandas/tests/io/excel/test_style.py
@@ -108,7 +108,7 @@ def test_styler_to_excel(engine):
         for col1, col2 in zip(wb["frame"].columns, wb["styled"].columns):
             assert len(col1) == len(col2)
             for cell1, cell2 in zip(col1, col2):
-                ref = "%s%d" % (cell2.column, cell2.row)
+                ref = "{cell2.column}{cell2.row:d}".format(cell2=cell2)
                 # XXX: this isn't as strong a test as ideal; we should
                 #      confirm that differences are exclusive
                 if ref == "B2":
@@ -156,7 +156,7 @@ def test_styler_to_excel(engine):
         for col1, col2 in zip(wb["frame"].columns, wb["custom"].columns):
             assert len(col1) == len(col2)
             for cell1, cell2 in zip(col1, col2):
-                ref = "%s%d" % (cell2.column, cell2.row)
+                ref = "{cell2.column}{cell2.row:d}".format(cell2=cell2)
                 if ref in ("B2", "C3", "D4", "B5", "C6", "D7", "B8", "B9"):
                     assert not cell1.font.bold
                     assert cell2.font.bold
diff --git a/pandas/tests/io/formats/test_style.py b/pandas/tests/io/formats/test_style.py
index f2fb54796..61c163d2c 100644
--- a/pandas/tests/io/formats/test_style.py
+++ b/pandas/tests/io/formats/test_style.py
@@ -362,7 +362,7 @@ class TestStyler:
             strings, black otherwise.
             """
             color = "red" if val < 0 else "black"
-            return "color: %s" % color
+            return "color: {color}".format(color=color)
 
         dic = {
             ("a", "d"): [-1.12, 2.11],
diff --git a/pandas/tests/io/formats/test_to_latex.py b/pandas/tests/io/formats/test_to_latex.py
index a8a6a96f6..924b2a19e 100644
--- a/pandas/tests/io/formats/test_to_latex.py
+++ b/pandas/tests/io/formats/test_to_latex.py
@@ -610,7 +610,9 @@ AA &  BB \\
 
         idx_names = tuple(n or "{}" for n in names)
         idx_names_row = (
-            "%s & %s &    &    &    &    \\\\\n" % idx_names
+            "{idx_names[0]} & {idx_names[1]} &    &    &    &    \\\\\n".format(
+                idx_names=idx_names
+            )
             if (0 in axes and any(names))
             else ""
         )
diff --git a/pandas/tests/io/generate_legacy_storage_files.py b/pandas/tests/io/generate_legacy_storage_files.py
index 3ccb29f07..2d2938697 100755
--- a/pandas/tests/io/generate_legacy_storage_files.py
+++ b/pandas/tests/io/generate_legacy_storage_files.py
@@ -352,7 +352,7 @@ def write_legacy_pickles(output_dir):
     pickle.dump(create_pickle_data(), fh, pickle.HIGHEST_PROTOCOL)
     fh.close()
 
-    print("created pickle file: %s" % pth)
+    print("created pickle file: {pth}".format(pth=pth))
 
 
 def write_legacy_msgpack(output_dir, compress):
@@ -369,7 +369,7 @@ def write_legacy_msgpack(output_dir, compress):
     pth = "{0}.msgpack".format(platform_name())
     to_msgpack(os.path.join(output_dir, pth), create_msgpack_data(), compress=compress)
 
-    print("created msgpack file: %s" % pth)
+    print("created msgpack file: {pth}".format(pth=pth))
 
 
 def write_legacy_file():
diff --git a/pandas/tests/io/msgpack/test_case.py b/pandas/tests/io/msgpack/test_case.py
index 15b7090c1..a868da69d 100644
--- a/pandas/tests/io/msgpack/test_case.py
+++ b/pandas/tests/io/msgpack/test_case.py
@@ -5,7 +5,11 @@ from pandas.io.msgpack import packb, unpackb
 
 def check(length, obj):
     v = packb(obj)
-    assert len(v) == length, "%r length should be %r but get %r" % (obj, length, len(v))
+    assert (
+        len(v) == length
+    ), "{obj!r} length should be {length!r} but get {got:!r}".format(
+        obj=obj, length=length, got=len(v)
+    )
     assert unpackb(v, use_list=0) == obj
 
 
diff --git a/pandas/tests/io/msgpack/test_extension.py b/pandas/tests/io/msgpack/test_extension.py
index 12f27459f..85ed43fa0 100644
--- a/pandas/tests/io/msgpack/test_extension.py
+++ b/pandas/tests/io/msgpack/test_extension.py
@@ -48,7 +48,7 @@ def test_extension_type():
             typecode = 123  # application specific typecode
             data = tobytes(obj)
             return ExtType(typecode, data)
-        raise TypeError("Unknown type object %r" % (obj,))
+        raise TypeError("Unknown type object {obj!r}".format(obj))
 
     def ext_hook(code, data):
         print("ext_hook called", code, data)
diff --git a/pandas/tests/io/parser/test_common.py b/pandas/tests/io/parser/test_common.py
index d469d3c2e..b94d5cd49 100644
--- a/pandas/tests/io/parser/test_common.py
+++ b/pandas/tests/io/parser/test_common.py
@@ -979,7 +979,7 @@ def test_nonexistent_path(all_parsers):
     # gh-2428: pls no segfault
     # gh-14086: raise more helpful FileNotFoundError
     parser = all_parsers
-    path = "%s.csv" % tm.rands(10)
+    path = "{}.csv".format(tm.rands(10))
 
     msg = "does not exist" if parser.engine == "c" else r"\[Errno 2\]"
     with pytest.raises(FileNotFoundError, match=msg) as e:
@@ -1078,7 +1078,7 @@ A,B,C
 4,5,6""".replace(
         ",", sep
     )
-    path = "__%s__.csv" % tm.rands(10)
+    path = "__{}__.csv".format(tm.rands(10))
     kwargs = dict(sep=sep, skiprows=2)
     utf8 = "utf-8"
 
@@ -1982,7 +1982,7 @@ def test_internal_eof_byte_to_file(all_parsers):
     parser = all_parsers
     data = b'c1,c2\r\n"test \x1a    test", test\r\n'
     expected = DataFrame([["test \x1a    test", " test"]], columns=["c1", "c2"])
-    path = "__%s__.csv" % tm.rands(10)
+    path = "__{}__.csv".format(tm.rands(10))
 
     with tm.ensure_clean(path) as path:
         with open(path, "wb") as f:
diff --git a/pandas/tests/io/parser/test_multi_thread.py b/pandas/tests/io/parser/test_multi_thread.py
index 392628ee7..c94adf9da 100644
--- a/pandas/tests/io/parser/test_multi_thread.py
+++ b/pandas/tests/io/parser/test_multi_thread.py
@@ -41,7 +41,9 @@ def test_multi_thread_string_io_read_csv(all_parsers):
     num_files = 100
 
     bytes_to_df = [
-        "\n".join(["%d,%d,%d" % (i, i, i) for i in range(max_row_range)]).encode()
+        "\n".join(
+            ["{i:d},{i:d},{i:d}".format(i=i) for i in range(max_row_range)]
+        ).encode()
         for _ in range(num_files)
     ]
     files = [BytesIO(b) for b in bytes_to_df]
diff --git a/pandas/tests/io/parser/test_parse_dates.py b/pandas/tests/io/parser/test_parse_dates.py
index 5d79f6e28..36391e19a 100644
--- a/pandas/tests/io/parser/test_parse_dates.py
+++ b/pandas/tests/io/parser/test_parse_dates.py
@@ -1101,7 +1101,7 @@ def test_bad_date_parse(all_parsers, cache_dates, value):
     # if we have an invalid date make sure that we handle this with
     # and w/o the cache properly
     parser = all_parsers
-    s = StringIO(("%s,\n" % value) * 50000)
+    s = StringIO(("{value},\n".format(value=value)) * 50000)
 
     parser.read_csv(
         s,
diff --git a/pandas/tests/io/parser/test_read_fwf.py b/pandas/tests/io/parser/test_read_fwf.py
index 72885315e..9ddaccc4d 100644
--- a/pandas/tests/io/parser/test_read_fwf.py
+++ b/pandas/tests/io/parser/test_read_fwf.py
@@ -260,7 +260,7 @@ def test_fwf_regression():
     # Turns out "T060" is parsable as a datetime slice!
     tz_list = [1, 10, 20, 30, 60, 80, 100]
     widths = [16] + [8] * len(tz_list)
-    names = ["SST"] + ["T%03d" % z for z in tz_list[1:]]
+    names = ["SST"] + ["T{z:03d}".format(z=z) for z in tz_list[1:]]
 
     data = """  2009164202000   9.5403  9.4105  8.6571  7.8372  6.0612  5.8843  5.5192
 2009164203000   9.5435  9.2010  8.6167  7.8176  6.0804  5.8728  5.4869
diff --git a/pandas/tests/io/parser/test_unsupported.py b/pandas/tests/io/parser/test_unsupported.py
index 8bdf53c3c..b23ddf5bd 100644
--- a/pandas/tests/io/parser/test_unsupported.py
+++ b/pandas/tests/io/parser/test_unsupported.py
@@ -95,10 +95,10 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
 1,2,3,4,"""
 
         for default in py_unsupported:
-            msg = "The %r option is not supported with the %r engine" % (
-                default,
-                python_engine,
-            )
+            msg = (
+                "The {default!r} option is not supported with the {python_engine!r}"
+                " engine"
+            ).format(default=default, python_engine=python_engine)
 
             kwargs = {default: object()}
             with pytest.raises(ValueError, match=msg):
diff --git a/pandas/tests/io/pytables/test_pytables.py b/pandas/tests/io/pytables/test_pytables.py
index fb87749ea..946334b5d 100644
--- a/pandas/tests/io/pytables/test_pytables.py
+++ b/pandas/tests/io/pytables/test_pytables.py
@@ -168,7 +168,7 @@ class Base:
         tm.set_testing_mode()
 
     def setup_method(self, method):
-        self.path = "tmp.__%s__.h5" % tm.rands(10)
+        self.path = "tmp.__{}__.h5".format(tm.rands(10))
 
     def teardown_method(self, method):
         pass
@@ -736,7 +736,7 @@ class TestHDFStore(Base):
 
             # not stores
             for x in ["mode", "path", "handle", "complib"]:
-                getattr(store, "_%s" % x)
+                getattr(store, "_{x}".format(x=x))
 
     def test_put(self):
 
@@ -773,7 +773,9 @@ class TestHDFStore(Base):
 
         with ensure_clean_store(self.path) as store:
 
-            index = Index(["I am a very long string index: %s" % i for i in range(20)])
+            index = Index(
+                ["I am a very long string index: {i}".format(i=i) for i in range(20)]
+            )
             s = Series(np.arange(20), index=index)
             df = DataFrame({"A": s, "B": s})
 
@@ -786,7 +788,7 @@ class TestHDFStore(Base):
             # mixed length
             index = Index(
                 ["abcdefghijklmnopqrstuvwxyz1234567890"]
-                + ["I am a very long string index: %s" % i for i in range(20)]
+                + ["I am a very long string index: {i}".format(i=i) for i in range(20)]
             )
             s = Series(np.arange(21), index=index)
             df = DataFrame({"A": s, "B": s})
@@ -2109,7 +2111,7 @@ class TestHDFStore(Base):
                 df = tm.makeDataFrame()
                 df[n] = f
                 with pytest.raises(TypeError):
-                    store.append("df1_%s" % n, df)
+                    store.append("df1_{n}".format(n=n), df)
 
         # frame
         df = tm.makeDataFrame()
@@ -2802,14 +2804,14 @@ class TestHDFStore(Base):
             expected = df[df.boolv == True].reindex(columns=["A", "boolv"])  # noqa
             for v in [True, "true", 1]:
                 result = store.select(
-                    "df", "boolv == %s" % str(v), columns=["A", "boolv"]
+                    "df", "boolv == {v!s}".format(v=v), columns=["A", "boolv"]
                 )
                 tm.assert_frame_equal(expected, result)
 
             expected = df[df.boolv == False].reindex(columns=["A", "boolv"])  # noqa
             for v in [False, "false", 0]:
                 result = store.select(
-                    "df", "boolv == %s" % str(v), columns=["A", "boolv"]
+                    "df", "boolv == {v!s}".format(v=v), columns=["A", "boolv"]
                 )
                 tm.assert_frame_equal(expected, result)
 
@@ -2896,7 +2898,7 @@ class TestHDFStore(Base):
                     users=["a"] * 50
                     + ["b"] * 50
                     + ["c"] * 100
-                    + ["a%03d" % i for i in range(100)],
+                    + ["a{i:03d}".format(i=i) for i in range(100)],
                 )
             )
             _maybe_remove(store, "df")
@@ -2917,7 +2919,7 @@ class TestHDFStore(Base):
             tm.assert_frame_equal(expected, result)
 
             # big selector along the columns
-            selector = ["a", "b", "c"] + ["a%03d" % i for i in range(60)]
+            selector = ["a", "b", "c"] + ["a{i:03d}".format(i=i) for i in range(60)]
             result = store.select(
                 "df", "ts>=Timestamp('2012-02-01') and users=selector"
             )
@@ -2990,7 +2992,7 @@ class TestHDFStore(Base):
 
             df1 = tm.makeTimeDataFrame(500)
             store.append("df1", df1, data_columns=True)
-            df2 = tm.makeTimeDataFrame(500).rename(columns=lambda x: "%s_2" % x)
+            df2 = tm.makeTimeDataFrame(500).rename(columns="{}_2".format)
             df2["foo"] = "bar"
             store.append("df2", df2)
 
@@ -3029,19 +3031,21 @@ class TestHDFStore(Base):
 
             # select w/o iterator and where clause, single term, begin
             # of range, works
-            where = "index >= '%s'" % beg_dt
+            where = "index >= '{beg_dt}'".format(beg_dt=beg_dt)
             result = store.select("df", where=where)
             tm.assert_frame_equal(expected, result)
 
             # select w/o iterator and where clause, single term, end
             # of range, works
-            where = "index <= '%s'" % end_dt
+            where = "index <= '{end_dt}'".format(end_dt=end_dt)
             result = store.select("df", where=where)
             tm.assert_frame_equal(expected, result)
 
             # select w/o iterator and where clause, inclusive range,
             # works
-            where = "index >= '%s' & index <= '%s'" % (beg_dt, end_dt)
+            where = "index >= '{beg_dt}' & index <= '{end_dt}'".format(
+                beg_dt=beg_dt, end_dt=end_dt
+            )
             result = store.select("df", where=where)
             tm.assert_frame_equal(expected, result)
 
@@ -3061,19 +3065,21 @@ class TestHDFStore(Base):
             tm.assert_frame_equal(expected, result)
 
             # select w/iterator and where clause, single term, begin of range
-            where = "index >= '%s'" % beg_dt
+            where = "index >= '{beg_dt}'".format(beg_dt=beg_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             tm.assert_frame_equal(expected, result)
 
             # select w/iterator and where clause, single term, end of range
-            where = "index <= '%s'" % end_dt
+            where = "index <= '{end_dt}'".format(end_dt=end_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             tm.assert_frame_equal(expected, result)
 
             # select w/iterator and where clause, inclusive range
-            where = "index >= '%s' & index <= '%s'" % (beg_dt, end_dt)
+            where = "index >= '{beg_dt}' & index <= '{end_dt}'".format(
+                beg_dt=beg_dt, end_dt=end_dt
+            )
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             tm.assert_frame_equal(expected, result)
@@ -3095,21 +3101,23 @@ class TestHDFStore(Base):
             end_dt = expected.index[-2]
 
             # select w/iterator and where clause, single term, begin of range
-            where = "index >= '%s'" % beg_dt
+            where = "index >= '{beg_dt}'".format(beg_dt=beg_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             rexpected = expected[expected.index >= beg_dt]
             tm.assert_frame_equal(rexpected, result)
 
             # select w/iterator and where clause, single term, end of range
-            where = "index <= '%s'" % end_dt
+            where = "index <= '{end_dt}'".format(end_dt=end_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             rexpected = expected[expected.index <= end_dt]
             tm.assert_frame_equal(rexpected, result)
 
             # select w/iterator and where clause, inclusive range
-            where = "index >= '%s' & index <= '%s'" % (beg_dt, end_dt)
+            where = "index >= '{beg_dt}' & index <= '{end_dt}'".format(
+                beg_dt=beg_dt, end_dt=end_dt
+            )
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             rexpected = expected[
@@ -3127,7 +3135,7 @@ class TestHDFStore(Base):
             end_dt = expected.index[-1]
 
             # select w/iterator and where clause, single term, begin of range
-            where = "index > '%s'" % end_dt
+            where = "index > '{end_dt}'".format(end_dt=end_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             assert 0 == len(results)
 
@@ -3149,14 +3157,14 @@ class TestHDFStore(Base):
             end_dt = expected.index[chunksize - 1]
 
             # select w/iterator and where clause, single term, begin of range
-            where = "index >= '%s'" % beg_dt
+            where = "index >= '{beg_dt}'".format(beg_dt=beg_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
             result = concat(results)
             rexpected = expected[expected.index >= beg_dt]
             tm.assert_frame_equal(rexpected, result)
 
             # select w/iterator and where clause, single term, end of range
-            where = "index <= '%s'" % end_dt
+            where = "index <= '{end_dt}'".format(end_dt=end_dt)
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
 
             assert len(results) == 1
@@ -3165,7 +3173,9 @@ class TestHDFStore(Base):
             tm.assert_frame_equal(rexpected, result)
 
             # select w/iterator and where clause, inclusive range
-            where = "index >= '%s' & index <= '%s'" % (beg_dt, end_dt)
+            where = "index >= '{beg_dt}' & index <= '{end_dt}'".format(
+                beg_dt=beg_dt, end_dt=end_dt
+            )
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
 
             # should be 1, is 10
@@ -3183,7 +3193,9 @@ class TestHDFStore(Base):
             # return [] e.g. `for e in []: print True` never prints
             # True.
 
-            where = "index <= '%s' & index >= '%s'" % (beg_dt, end_dt)
+            where = "index <= '{beg_dt}' & index >= '{end_dt}'".format(
+                beg_dt=beg_dt, end_dt=end_dt
+            )
             results = [s for s in store.select("df", where=where, chunksize=chunksize)]
 
             # should be []
@@ -3608,7 +3620,7 @@ class TestHDFStore(Base):
             _maybe_remove(store, "df1")
             _maybe_remove(store, "df2")
             df1 = tm.makeTimeDataFrame()
-            df2 = tm.makeTimeDataFrame().rename(columns=lambda x: "%s_2" % x)
+            df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
             store.append("df1", df1, data_columns=["A", "B"])
             store.append("df2", df2)
 
@@ -3680,7 +3692,7 @@ class TestHDFStore(Base):
 
     def test_append_to_multiple(self):
         df1 = tm.makeTimeDataFrame()
-        df2 = tm.makeTimeDataFrame().rename(columns=lambda x: "%s_2" % x)
+        df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df2["foo"] = "bar"
         df = concat([df1, df2], axis=1)
 
@@ -3710,7 +3722,7 @@ class TestHDFStore(Base):
 
     def test_append_to_multiple_dropna(self):
         df1 = tm.makeTimeDataFrame()
-        df2 = tm.makeTimeDataFrame().rename(columns=lambda x: "%s_2" % x)
+        df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df1.iloc[1, df1.columns.get_indexer(["A", "B"])] = np.nan
         df = concat([df1, df2], axis=1)
 
@@ -3730,7 +3742,7 @@ class TestHDFStore(Base):
     )
     def test_append_to_multiple_dropna_false(self):
         df1 = tm.makeTimeDataFrame()
-        df2 = tm.makeTimeDataFrame().rename(columns=lambda x: "%s_2" % x)
+        df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df1.iloc[1, df1.columns.get_indexer(["A", "B"])] = np.nan
         df = concat([df1, df2], axis=1)
 
@@ -3749,7 +3761,7 @@ class TestHDFStore(Base):
     def test_select_as_multiple(self):
 
         df1 = tm.makeTimeDataFrame()
-        df2 = tm.makeTimeDataFrame().rename(columns=lambda x: "%s_2" % x)
+        df2 = tm.makeTimeDataFrame().rename(columns="{}_2".format)
         df2["foo"] = "bar"
 
         with ensure_clean_store(self.path) as store:
@@ -3920,8 +3932,8 @@ class TestHDFStore(Base):
     def test_select_filter_corner(self):
 
         df = DataFrame(np.random.randn(50, 100))
-        df.index = ["%.3d" % c for c in df.index]
-        df.columns = ["%.3d" % c for c in df.columns]
+        df.index = ["{c:3d}".format(c=c) for c in df.index]
+        df.columns = ["{c:3d}".format(c=c) for c in df.columns]
 
         with ensure_clean_store(self.path) as store:
             store.put("frame", df, format="table")
@@ -4355,7 +4367,7 @@ class TestHDFStore(Base):
         df5 = DataFrame({("1", 2, object): np.random.randn(10)})
 
         with ensure_clean_store(self.path) as store:
-            name = "df_%s" % tm.rands(10)
+            name = "df_{}".format(tm.rands(10))
             store.append(name, df)
 
             for d in (df2, df3, df4, df5):
@@ -4775,16 +4787,16 @@ class TestHDFStore(Base):
             store.append("test", df, format="table", data_columns=True)
 
             cutoff = 1000000000.0006
-            result = store.select("test", "A < %.4f" % cutoff)
+            result = store.select("test", "A < {cutoff:.4f}".format(cutoff=cutoff))
             assert result.empty
 
             cutoff = 1000000000.0010
-            result = store.select("test", "A > %.4f" % cutoff)
+            result = store.select("test", "A > {cutoff:.4f}".format(cutoff=cutoff))
             expected = df.loc[[1, 2], :]
             tm.assert_frame_equal(expected, result)
 
             exact = 1000000000.0011
-            result = store.select("test", "A == %.4f" % exact)
+            result = store.select("test", "A == {exact:.4f}".format(exact=exact))
             expected = df.loc[[1], :]
             tm.assert_frame_equal(expected, result)
 
@@ -5084,7 +5096,9 @@ class TestTimezones(Base):
                 a_e = a.loc[i, c]
                 b_e = b.loc[i, c]
                 if not (a_e == b_e and a_e.tz == b_e.tz):
-                    raise AssertionError("invalid tz comparison [%s] [%s]" % (a_e, b_e))
+                    raise AssertionError(
+                        "invalid tz comparison [{a_e}] [{b_e}]".format(a_e=a_e, b_e=b_e)
+                    )
 
     def test_append_with_timezones_dateutil(self):
 
diff --git a/pandas/tests/io/test_html.py b/pandas/tests/io/test_html.py
index 9752b4c62..6d06113df 100644
--- a/pandas/tests/io/test_html.py
+++ b/pandas/tests/io/test_html.py
@@ -902,8 +902,8 @@ class TestReadHtml:
 
     def test_wikipedia_states_table(self, datapath):
         data = datapath("io", "data", "wikipedia_states.html")
-        assert os.path.isfile(data), "%r is not a file" % data
-        assert os.path.getsize(data), "%r is an empty file" % data
+        assert os.path.isfile(data), "{data!r} is not a file".format(data=data)
+        assert os.path.getsize(data), "{data!r} is an empty file".format(data=data)
         result = self.read_html(data, "Arizona", header=1)[0]
         assert result["sq mi"].dtype == np.dtype("float64")
 
diff --git a/pandas/tests/io/test_packers.py b/pandas/tests/io/test_packers.py
index fb1f65790..33a11087f 100644
--- a/pandas/tests/io/test_packers.py
+++ b/pandas/tests/io/test_packers.py
@@ -101,7 +101,7 @@ def check_arbitrary(a, b):
 @pytest.mark.filterwarnings("ignore:.*msgpack:FutureWarning")
 class TestPackers:
     def setup_method(self, method):
-        self.path = "__%s__.msg" % tm.rands(10)
+        self.path = "__{}__.msg".format(tm.rands(10))
 
     def teardown_method(self, method):
         pass
diff --git a/pandas/tests/io/test_pickle.py b/pandas/tests/io/test_pickle.py
index 7aba2a367..076d0c9f9 100644
--- a/pandas/tests/io/test_pickle.py
+++ b/pandas/tests/io/test_pickle.py
@@ -48,7 +48,7 @@ def compare_element(result, expected, typ, version=None):
         return
 
     if typ.startswith("sp_"):
-        comparator = getattr(tm, "assert_%s_equal" % typ)
+        comparator = getattr(tm, "assert_{typ}_equal".format(typ=typ))
         comparator(result, expected, exact_indices=False)
     elif typ == "timestamp":
         if expected is pd.NaT:
@@ -57,7 +57,9 @@ def compare_element(result, expected, typ, version=None):
             assert result == expected
             assert result.freq == expected.freq
     else:
-        comparator = getattr(tm, "assert_%s_equal" % typ, tm.assert_almost_equal)
+        comparator = getattr(
+            tm, "assert_{typ}_equal".format(typ=typ), tm.assert_almost_equal
+        )
         comparator(result, expected)
 
 
@@ -242,7 +244,7 @@ def test_pickle_path_localpath():
 
 @pytest.fixture
 def get_random_path():
-    return "__%s__.pickle" % tm.rands(10)
+    return "__{}__.pickle".format(tm.rands(10))
 
 
 class TestCompression:
diff --git a/pandas/tests/io/test_sql.py b/pandas/tests/io/test_sql.py
index 347e28023..d8465a427 100644
--- a/pandas/tests/io/test_sql.py
+++ b/pandas/tests/io/test_sql.py
@@ -217,7 +217,9 @@ class MixInBase:
 class MySQLMixIn(MixInBase):
     def drop_table(self, table_name):
         cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS %s" % sql._get_valid_mysql_name(table_name))
+        cur.execute(
+            "DROP TABLE IF EXISTS {}".format(sql._get_valid_mysql_name(table_name))
+        )
         self.conn.commit()
 
     def _get_all_tables(self):
@@ -237,7 +239,7 @@ class MySQLMixIn(MixInBase):
 class SQLiteMixIn(MixInBase):
     def drop_table(self, table_name):
         self.conn.execute(
-            "DROP TABLE IF EXISTS %s" % sql._get_valid_sqlite_name(table_name)
+            "DROP TABLE IF EXISTS {}".format(sql._get_valid_sqlite_name(table_name))
         )
         self.conn.commit()
 
@@ -405,7 +407,11 @@ class PandasSQLTest:
     def _count_rows(self, table_name):
         result = (
             self._get_exec()
-            .execute("SELECT count(*) AS count_1 FROM %s" % table_name)
+            .execute(
+                "SELECT count(*) AS count_1 FROM {table_name}".format(
+                    table_name=table_name
+                )
+            )
             .fetchone()
         )
         return result[0]
@@ -1201,7 +1207,7 @@ class TestSQLiteFallbackApi(SQLiteMixIn, _TestSQLApi):
         for col in schema.split("\n"):
             if col.split()[0].strip('""') == column:
                 return col.split()[1]
-        raise ValueError("Column %s not found" % (column))
+        raise ValueError("Column {column} not found".format(column=column))
 
     def test_sqlite_type_mapping(self):
 
@@ -2193,12 +2199,14 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
     def _get_index_columns(self, tbl_name):
         ixs = sql.read_sql_query(
             "SELECT * FROM sqlite_master WHERE type = 'index' "
-            + "AND tbl_name = '%s'" % tbl_name,
+            + "AND tbl_name = '{tbl_name}'".format(tbl_name=tbl_name),
             self.conn,
         )
         ix_cols = []
         for ix_name in ixs.name:
-            ix_info = sql.read_sql_query("PRAGMA index_info(%s)" % ix_name, self.conn)
+            ix_info = sql.read_sql_query(
+                "PRAGMA index_info({ix_name})".format(ix_name=ix_name), self.conn
+            )
             ix_cols.append(ix_info.name.tolist())
         return ix_cols
 
@@ -2211,11 +2219,15 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
         self._transaction_test()
 
     def _get_sqlite_column_type(self, table, column):
-        recs = self.conn.execute("PRAGMA table_info(%s)" % table)
+        recs = self.conn.execute("PRAGMA table_info({table})".format(table=table))
         for cid, name, ctype, not_null, default, pk in recs:
             if name == column:
                 return ctype
-        raise ValueError("Table %s, column %s not found" % (table, column))
+        raise ValueError(
+            "Table {table}, column {column} not found".format(
+                table=table, column=column
+            )
+        )
 
     def test_dtype(self):
         if self.flavor == "mysql":
@@ -2285,7 +2297,7 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
             sql.table_exists(weird_name, self.conn)
 
             df2 = DataFrame([[1, 2], [3, 4]], columns=["a", weird_name])
-            c_tbl = "test_weird_col_name%d" % ndx
+            c_tbl = "test_weird_col_name{ndx:d}".format(ndx=ndx)
             df2.to_sql(c_tbl, self.conn)
             sql.table_exists(c_tbl, self.conn)
 
@@ -2300,15 +2312,15 @@ def date_format(dt):
 
 
 _formatters = {
-    datetime: lambda dt: "'%s'" % date_format(dt),
-    str: lambda x: "'%s'" % x,
-    np.str_: lambda x: "'%s'" % x,
-    bytes: lambda x: "'%s'" % x,
-    float: lambda x: "%.8f" % x,
-    int: lambda x: "%s" % x,
+    datetime: "'{}'".format,
+    str: "'{}'".format,
+    np.str_: "'{}'".format,
+    bytes: "'{}'".format,
+    float: "{:.8f}".format,
+    int: "{:d}".format,
     type(None): lambda x: "NULL",
-    np.float64: lambda x: "%.10f" % x,
-    bool: lambda x: "'%s'" % x,
+    np.float64: "{:.10f}".format,
+    bool: "'{!s}'".format,
 }
 
 
@@ -2490,7 +2502,7 @@ class TestXSQLite(SQLiteMixIn):
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
-        sql_select = "SELECT * FROM %s" % table_name
+        sql_select = "SELECT * FROM {table_name}".format(table_name=table_name)
 
         def clean_up(test_table_to_drop):
             """
@@ -2778,7 +2790,7 @@ class TestXMySQL(MySQLMixIn):
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
-        sql_select = "SELECT * FROM %s" % table_name
+        sql_select = "SELECT * FROM {table_name}".format(table_name=table_name)
 
         def clean_up(test_table_to_drop):
             """
diff --git a/pandas/tests/plotting/test_series.py b/pandas/tests/plotting/test_series.py
index 4c5b1e66d..8b4a78e91 100644
--- a/pandas/tests/plotting/test_series.py
+++ b/pandas/tests/plotting/test_series.py
@@ -856,10 +856,10 @@ class TestSeriesPlots(TestPlotBase):
 
     def test_xticklabels(self):
         # GH11529
-        s = Series(np.arange(10), index=["P%02d" % i for i in range(10)])
+        s = Series(np.arange(10), index=["P{i:02d}".format(i=i) for i in range(10)])
         _, ax = self.plt.subplots()
         ax = s.plot(xticks=[0, 3, 5, 9], ax=ax)
-        exp = ["P%02d" % i for i in [0, 3, 5, 9]]
+        exp = ["P{i:02d}".format(i=i) for i in [0, 3, 5, 9]]
         self._check_text_labels(ax.get_xticklabels(), exp)
 
     def test_custom_business_day_freq(self):
diff --git a/pandas/tests/resample/test_period_index.py b/pandas/tests/resample/test_period_index.py
index 2ced95565..30febe3d2 100644
--- a/pandas/tests/resample/test_period_index.py
+++ b/pandas/tests/resample/test_period_index.py
@@ -101,7 +101,9 @@ class TestPeriodIndex:
     def test_annual_upsample_cases(
         self, targ, conv, meth, month, simple_period_range_series
     ):
-        ts = simple_period_range_series("1/1/1990", "12/31/1991", freq="A-%s" % month)
+        ts = simple_period_range_series(
+            "1/1/1990", "12/31/1991", freq="A-{month}".format(month=month)
+        )
 
         result = getattr(ts.resample(targ, convention=conv), meth)()
         expected = result.to_timestamp(targ, how=conv)
@@ -370,14 +372,16 @@ class TestPeriodIndex:
 
     def test_resample_to_quarterly(self, simple_period_range_series):
         for month in MONTHS:
-            ts = simple_period_range_series("1990", "1992", freq="A-%s" % month)
-            quar_ts = ts.resample("Q-%s" % month).ffill()
+            ts = simple_period_range_series(
+                "1990", "1992", freq="A-{month}".format(month=month)
+            )
+            quar_ts = ts.resample("Q-{month}".format(month=month)).ffill()
 
             stamps = ts.to_timestamp("D", how="start")
             qdates = period_range(
                 ts.index[0].asfreq("D", "start"),
                 ts.index[-1].asfreq("D", "end"),
-                freq="Q-%s" % month,
+                freq="Q-{month}".format(month=month),
             )
 
             expected = stamps.reindex(qdates.to_timestamp("D", "s"), method="ffill")
diff --git a/pandas/tests/reshape/merge/test_join.py b/pandas/tests/reshape/merge/test_join.py
index 16cfe3a46..305d7b978 100644
--- a/pandas/tests/reshape/merge/test_join.py
+++ b/pandas/tests/reshape/merge/test_join.py
@@ -790,7 +790,9 @@ def _check_join(left, right, result, join_col, how="left", lsuffix="_x", rsuffix
         except KeyError:
             if how in ("left", "inner"):
                 raise AssertionError(
-                    "key %s should not have been in the join" % str(group_key)
+                    "key {group_key!s} should not have been in the join".format(
+                        group_key=group_key
+                    )
                 )
 
             _assert_all_na(l_joined, left.columns, join_col)
@@ -802,7 +804,9 @@ def _check_join(left, right, result, join_col, how="left", lsuffix="_x", rsuffix
         except KeyError:
             if how in ("right", "inner"):
                 raise AssertionError(
-                    "key %s should not have been in the join" % str(group_key)
+                    "key {group_key!s} should not have been in the join".format(
+                        group_key=group_key
+                    )
                 )
 
             _assert_all_na(r_joined, right.columns, join_col)
diff --git a/pandas/tests/reshape/test_melt.py b/pandas/tests/reshape/test_melt.py
index 1b067c08d..5b1f151da 100644
--- a/pandas/tests/reshape/test_melt.py
+++ b/pandas/tests/reshape/test_melt.py
@@ -339,8 +339,8 @@ class TestLreshape:
         df = DataFrame(data)
 
         spec = {
-            "visitdt": ["visitdt%d" % i for i in range(1, 4)],
-            "wt": ["wt%d" % i for i in range(1, 4)],
+            "visitdt": ["visitdt{i:d}".format(i=i) for i in range(1, 4)],
+            "wt": ["wt{i:d}".format(i=i) for i in range(1, 4)],
         }
         result = lreshape(df, spec)
 
@@ -529,8 +529,8 @@ class TestLreshape:
         tm.assert_frame_equal(result, exp)
 
         spec = {
-            "visitdt": ["visitdt%d" % i for i in range(1, 3)],
-            "wt": ["wt%d" % i for i in range(1, 4)],
+            "visitdt": ["visitdt{i:d}".format(i=i) for i in range(1, 3)],
+            "wt": ["wt{i:d}".format(i=i) for i in range(1, 4)],
         }
         msg = "All column lists must be same length"
         with pytest.raises(ValueError, match=msg):
diff --git a/pandas/tests/reshape/test_reshape.py b/pandas/tests/reshape/test_reshape.py
index 1c9e3e57b..149930059 100644
--- a/pandas/tests/reshape/test_reshape.py
+++ b/pandas/tests/reshape/test_reshape.py
@@ -166,7 +166,8 @@ class TestGetDummies:
         s = [e, eacute, eacute]
         res = get_dummies(s, prefix="letter", sparse=sparse)
         exp = DataFrame(
-            {"letter_e": [1, 0, 0], "letter_%s" % eacute: [0, 1, 1]}, dtype=np.uint8
+            {"letter_e": [1, 0, 0], "letter_{eacute}".format(eacute=eacute): [0, 1, 1]},
+            dtype=np.uint8,
         )
         if sparse:
             exp = exp.apply(pd.SparseArray, fill_value=0)
diff --git a/pandas/tests/scalar/period/test_period.py b/pandas/tests/scalar/period/test_period.py
index 771a67dfc..4404b93e8 100644
--- a/pandas/tests/scalar/period/test_period.py
+++ b/pandas/tests/scalar/period/test_period.py
@@ -307,7 +307,7 @@ class TestPeriodConstruction:
     @pytest.mark.parametrize("month", MONTHS)
     def test_period_cons_quarterly(self, month):
         # bugs in scikits.timeseries
-        freq = "Q-%s" % month
+        freq = "Q-{month}".format(month=month)
         exp = Period("1989Q3", freq=freq)
         assert "1989Q3" in str(exp)
         stamp = exp.to_timestamp("D", how="end")
@@ -321,7 +321,7 @@ class TestPeriodConstruction:
     @pytest.mark.parametrize("month", MONTHS)
     def test_period_cons_annual(self, month):
         # bugs in scikits.timeseries
-        freq = "A-%s" % month
+        freq = "A-{month}".format(month=month)
         exp = Period("1989", freq=freq)
         stamp = exp.to_timestamp("D", how="end") + timedelta(days=30)
         p = Period(stamp, freq=freq)
@@ -332,8 +332,8 @@ class TestPeriodConstruction:
     @pytest.mark.parametrize("day", DAYS)
     @pytest.mark.parametrize("num", range(10, 17))
     def test_period_cons_weekly(self, num, day):
-        daystr = "2011-02-%d" % num
-        freq = "W-%s" % day
+        daystr = "2011-02-{num}".format(num=num)
+        freq = "W-{day}".format(day=day)
 
         result = Period(daystr, freq=freq)
         expected = Period(daystr, freq="D").asfreq(freq)
diff --git a/pandas/tests/scalar/timestamp/test_timestamp.py b/pandas/tests/scalar/timestamp/test_timestamp.py
index 7b0ff83ae..401fc2854 100644
--- a/pandas/tests/scalar/timestamp/test_timestamp.py
+++ b/pandas/tests/scalar/timestamp/test_timestamp.py
@@ -576,7 +576,7 @@ class TestTimestampConstructors:
 
         for date_string in out_of_bounds_dates:
             for unit in time_units:
-                dt64 = np.datetime64(date_string, dtype="M8[%s]" % unit)
+                dt64 = np.datetime64(date_string, dtype="M8[{unit}]".format(unit=unit))
                 with pytest.raises(ValueError):
                     Timestamp(dt64)
 
@@ -584,7 +584,7 @@ class TestTimestampConstructors:
 
         for date_string in in_bounds_dates:
             for unit in time_units:
-                dt64 = np.datetime64(date_string, dtype="M8[%s]" % unit)
+                dt64 = np.datetime64(date_string, dtype="M8[{unit}]".format(unit=unit))
                 Timestamp(dt64)
 
     def test_min_valid(self):
diff --git a/pandas/tests/series/test_analytics.py b/pandas/tests/series/test_analytics.py
index 67373686d..32d32a5d1 100644
--- a/pandas/tests/series/test_analytics.py
+++ b/pandas/tests/series/test_analytics.py
@@ -99,7 +99,7 @@ class TestSeriesAnalytics:
         assert issubclass(argsorted.dtype.type, np.integer)
 
         # GH 2967 (introduced bug in 0.11-dev I think)
-        s = Series([Timestamp("201301%02d" % (i + 1)) for i in range(5)])
+        s = Series([Timestamp("201301{i:02d}".format(i=i)) for i in range(1, 6)])
         assert s.dtype == "datetime64[ns]"
         shifted = s.shift(-1)
         assert shifted.dtype == "datetime64[ns]"
diff --git a/pandas/tests/series/test_api.py b/pandas/tests/series/test_api.py
index 2097264ba..2870677e4 100644
--- a/pandas/tests/series/test_api.py
+++ b/pandas/tests/series/test_api.py
@@ -155,7 +155,9 @@ class SharedWithSparse:
 
     def test_constructor_ordereddict(self):
         # GH3283
-        data = OrderedDict(("col%s" % i, np.random.random()) for i in range(12))
+        data = OrderedDict(
+            ("col{i}".format(i=i), np.random.random()) for i in range(12)
+        )
 
         series = self.series_klass(data)
         expected = self.series_klass(list(data.values()), list(data.keys()))
diff --git a/pandas/tests/sparse/frame/test_frame.py b/pandas/tests/sparse/frame/test_frame.py
index 6527d41ea..55a37da6b 100644
--- a/pandas/tests/sparse/frame/test_frame.py
+++ b/pandas/tests/sparse/frame/test_frame.py
@@ -967,7 +967,7 @@ class TestSparseDataFrame(SharedWithSparse):
         )
         tm.assert_sp_frame_equal(result, expected)
 
-        result = float_frame.rename(columns=lambda x: "%s%d" % (x, 1))
+        result = float_frame.rename(columns="{}1".format)
         data = {
             "A1": [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],
             "B1": [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],
diff --git a/pandas/tests/sparse/series/test_series.py b/pandas/tests/sparse/series/test_series.py
index eb217283c..ad4c898b0 100644
--- a/pandas/tests/sparse/series/test_series.py
+++ b/pandas/tests/sparse/series/test_series.py
@@ -619,7 +619,9 @@ class TestSparseSeries(SharedWithSparse):
 
         inplace_ops = ["add", "sub", "mul", "truediv", "floordiv", "pow"]
         for op in inplace_ops:
-            _check_inplace_op(getattr(operator, "i%s" % op), getattr(operator, op))
+            _check_inplace_op(
+                getattr(operator, "i{op}".format(op=op)), getattr(operator, op)
+            )
 
     @pytest.mark.parametrize(
         "values, op, fill_value",
diff --git a/pandas/tests/test_expressions.py b/pandas/tests/test_expressions.py
index a7281e002..407062498 100644
--- a/pandas/tests/test_expressions.py
+++ b/pandas/tests/test_expressions.py
@@ -81,7 +81,7 @@ class TestExpressions:
                         assert expected.dtype.kind == "f"
                 assert_func(expected, result)
             except Exception:
-                pprint_thing("Failed test with operator %r" % op.__name__)
+                pprint_thing("Failed test with operator {op.__name__!r}".format(op=op))
                 raise
 
     def test_integer_arithmetic(self):
@@ -129,8 +129,8 @@ class TestExpressions:
                     assert not used_numexpr, "Used numexpr unexpectedly."
                 assert_func(expected, result)
             except Exception:
-                pprint_thing("Failed test with operation %r" % arith)
-                pprint_thing("test_flex was %r" % test_flex)
+                pprint_thing("Failed test with operation {arith!r}".format(arith=arith))
+                pprint_thing("test_flex was {test_flex!r}".format(test_flex=test_flex))
                 raise
 
     def run_frame(self, df, other, binary_comp=None, run_binary=True, **kwargs):
diff --git a/pandas/tests/test_nanops.py b/pandas/tests/test_nanops.py
index f6e936630..21ab28c94 100644
--- a/pandas/tests/test_nanops.py
+++ b/pandas/tests/test_nanops.py
@@ -179,9 +179,9 @@ class TestnanopsDataFrame:
                         self.check_results(targ, res, axis, check_dtype=check_dtype)
                 except BaseException as exc:
                     exc.args += (
-                        "axis: %s of %s" % (axis, testarval.ndim - 1),
-                        "skipna: %s" % skipna,
-                        "kwargs: %s" % kwargs,
+                        "axis: {axis} of {of}".format(axis=axis, of=testarval.ndim - 1),
+                        "skipna: {skipna}".format(skipna=skipna),
+                        "kwargs: {kwargs}".format(kwargs=kwargs),
                     )
                     raise
 
@@ -234,9 +234,9 @@ class TestnanopsDataFrame:
             )
         except BaseException as exc:
             exc.args += (
-                "testar: %s" % testar,
-                "targar: %s" % targar,
-                "targarnan: %s" % targarnan,
+                "testar: {testar}".format(testar=testar),
+                "targar: {targar}".format(targar=targar),
+                "targarnan: {targarnan}".format(targarnan=targarnan),
             )
             raise
 
@@ -712,7 +712,7 @@ class TestnanopsDataFrame:
                 res2 = checkfun(arr_float_nan, arr_nan_float1)
                 tm.assert_numpy_array_equal(targ2, res2, check_dtype=False)
             except Exception as exc:
-                exc.args += ("ndim: %s" % arr_float.ndim,)
+                exc.args += ("ndim: {arr_float.ndim}".format(arr_float=arr_float),)
                 raise
 
             try:
@@ -760,7 +760,7 @@ class TestnanopsDataFrame:
                 else:
                     assert not res0
             except BaseException as exc:
-                exc.args += ("dim: %s" % getattr(value, "ndim", value),)
+                exc.args += ("dim: {}".format(getattr(value, "ndim", value)),)
                 raise
             if not hasattr(value, "ndim"):
                 break
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index 2df5460a0..fca88ff3c 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -2039,7 +2039,7 @@ class TestMoments(Base):
             tm.assert_series_equal(result, expected)
 
             # shifter index
-            s = ["x%d" % x for x in range(12)]
+            s = ["x{x:d}".format(x=x) for x in range(12)]
 
             if has_min_periods:
                 minp = 10
diff --git a/pandas/tests/tseries/frequencies/test_inference.py b/pandas/tests/tseries/frequencies/test_inference.py
index 4c8f6253c..50844aabb 100644
--- a/pandas/tests/tseries/frequencies/test_inference.py
+++ b/pandas/tests/tseries/frequencies/test_inference.py
@@ -178,7 +178,7 @@ def test_infer_freq_delta(base_delta_code_pair, count):
     inc = base_delta * count
     index = DatetimeIndex([b + inc * j for j in range(3)])
 
-    exp_freq = "%d%s" % (count, code) if count > 1 else code
+    exp_freq = "{count:d}{code}".format(count=count, code=code) if count > 1 else code
     assert frequencies.infer_freq(index) == exp_freq
 
 
diff --git a/pandas/tests/tseries/offsets/common.py b/pandas/tests/tseries/offsets/common.py
index 079fcc36f..fbf445410 100644
--- a/pandas/tests/tseries/offsets/common.py
+++ b/pandas/tests/tseries/offsets/common.py
@@ -13,14 +13,18 @@ def assert_offset_equal(offset, base, expected):
         assert actual_apply == expected
     except AssertionError:
         raise AssertionError(
-            "\nExpected: %s\nActual: %s\nFor Offset: %s)"
-            "\nAt Date: %s" % (expected, actual, offset, base)
+            "\nExpected: {expected}\nActual: {actual}\nFor Offset: {offset})"
+            "\nAt Date: {base}".format(
+                expected=expected, actual=actual, offset=offset, base=base
+            )
         )
 
 
 def assert_onOffset(offset, date, expected):
     actual = offset.onOffset(date)
     assert actual == expected, (
-        "\nExpected: %s\nActual: %s\nFor Offset: %s)"
-        "\nAt Date: %s" % (expected, actual, offset, date)
+        "\nExpected: {expected}\nActual: {actual}\nFor Offset: {offset})"
+        "\nAt Date: {date}".format(
+            expected=expected, actual=actual, offset=offset, date=date
+        )
     )
diff --git a/pandas/tests/tseries/offsets/test_fiscal.py b/pandas/tests/tseries/offsets/test_fiscal.py
index c24d917a5..8b1aaafb9 100644
--- a/pandas/tests/tseries/offsets/test_fiscal.py
+++ b/pandas/tests/tseries/offsets/test_fiscal.py
@@ -79,10 +79,10 @@ def test_get_offset():
 
     for name, expected in pairs:
         offset = get_offset(name)
-        assert offset == expected, "Expected %r to yield %r (actual: %r)" % (
-            name,
-            expected,
-            offset,
+        assert (
+            offset == expected
+        ), "Expected {name!r} to yield {expected!r} (actual: {offset!r})".format(
+            name=name, expected=expected, offset=offset
         )
 
 
diff --git a/pandas/tests/tseries/offsets/test_offsets.py b/pandas/tests/tseries/offsets/test_offsets.py
index 2654d83ee..1abc8aece 100644
--- a/pandas/tests/tseries/offsets/test_offsets.py
+++ b/pandas/tests/tseries/offsets/test_offsets.py
@@ -3969,10 +3969,10 @@ def test_get_offset():
 
     for name, expected in pairs:
         offset = get_offset(name)
-        assert offset == expected, "Expected %r to yield %r (actual: %r)" % (
-            name,
-            expected,
-            offset,
+        assert (
+            offset == expected
+        ), "Expected {name!r} to yield {expected!r} (actual: {offset!r})".format(
+            name=name, expected=expected, offset=offset
         )
 
 
