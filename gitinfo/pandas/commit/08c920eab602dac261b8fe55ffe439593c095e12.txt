commit 08c920eab602dac261b8fe55ffe439593c095e12
Author: Marc Garcia <garcia.marc@gmail.com>
Date:   Thu Dec 27 00:19:42 2018 +0000

    DOC: Fixing more doc warnings (#24438)

diff --git a/doc/source/advanced.rst b/doc/source/advanced.rst
index 1ed365d09..e681cb59f 100644
--- a/doc/source/advanced.rst
+++ b/doc/source/advanced.rst
@@ -778,12 +778,12 @@ a ``Categorical`` will return a ``CategoricalIndex``, indexed according to the c
 of the **passed** ``Categorical`` dtype. This allows one to arbitrarily index these even with
 values **not** in the categories, similarly to how you can reindex **any** pandas index.
 
-.. ipython :: python
+.. ipython:: python
 
-   df2.reindex(['a','e'])
-   df2.reindex(['a','e']).index
-   df2.reindex(pd.Categorical(['a','e'],categories=list('abcde')))
-   df2.reindex(pd.Categorical(['a','e'],categories=list('abcde'))).index
+   df2.reindex(['a', 'e'])
+   df2.reindex(['a', 'e']).index
+   df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde')))
+   df2.reindex(pd.Categorical(['a', 'e'], categories=list('abcde'))).index
 
 .. warning::
 
@@ -1040,7 +1040,8 @@ than integer locations. Therefore, with an integer axis index *only*
 label-based indexing is possible with the standard tools like ``.loc``. The
 following code will generate exceptions:
 
-.. code-block:: python
+.. ipython:: python
+   :okexcept:
 
    s = pd.Series(range(5))
    s[-1]
@@ -1130,7 +1131,7 @@ index can be somewhat complicated. For example, the following does not work:
 
 ::
 
-    s.loc['c':'e'+1]
+    s.loc['c':'e' + 1]
 
 A very common use case is to limit a time series to start and end at two
 specific dates. To enable this, we made the design to make label-based
diff --git a/doc/source/categorical.rst b/doc/source/categorical.rst
index 72d4fec0c..68e39e682 100644
--- a/doc/source/categorical.rst
+++ b/doc/source/categorical.rst
@@ -977,21 +977,17 @@ categorical (categories and ordering). So if you read back the CSV file you have
 relevant columns back to `category` and assign the right categories and categories ordering.
 
 .. ipython:: python
-    :suppress:
 
-
-.. ipython:: python
-
-    from pandas.compat import StringIO
+    import io
     s = pd.Series(pd.Categorical(['a', 'b', 'b', 'a', 'a', 'd']))
     # rename the categories
     s.cat.categories = ["very good", "good", "bad"]
     # reorder the categories and add missing categories
     s = s.cat.set_categories(["very bad", "bad", "medium", "good", "very good"])
     df = pd.DataFrame({"cats": s, "vals": [1, 2, 3, 4, 5, 6]})
-    csv = StringIO()
+    csv = io.StringIO()
     df.to_csv(csv)
-    df2 = pd.read_csv(StringIO(csv.getvalue()))
+    df2 = pd.read_csv(io.StringIO(csv.getvalue()))
     df2.dtypes
     df2["cats"]
     # Redo the category
@@ -1206,6 +1202,7 @@ Use ``copy=True`` to prevent such a behaviour or simply don't reuse ``Categorica
     cat
 
 .. note::
+
     This also happens in some cases when you supply a NumPy array instead of a ``Categorical``:
     using an int array (e.g. ``np.array([1,2,3,4])``) will exhibit the same behavior, while using
     a string array (e.g. ``np.array(["a","b","c","a"])``) will not.
diff --git a/doc/source/conf.py b/doc/source/conf.py
index 2d1369499..2bef64cce 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -296,7 +296,10 @@ header = """\
    np.random.seed(123456)
    np.set_printoptions(precision=4, suppress=True)
    pd.options.display.max_rows = 15
-"""
+
+   import os
+   os.chdir('{}')
+""".format(os.path.dirname(os.path.dirname(__file__)))
 
 
 html_context = {
diff --git a/doc/source/cookbook.rst b/doc/source/cookbook.rst
index 1b2e856e9..0c192a0aa 100644
--- a/doc/source/cookbook.rst
+++ b/doc/source/cookbook.rst
@@ -1236,7 +1236,7 @@ the following Python code will read the binary file ``'binary.dat'`` into a
 pandas ``DataFrame``, where each element of the struct corresponds to a column
 in the frame:
 
-.. code-block:: python
+.. ipython:: python
 
    names = 'count', 'avg', 'scale'
 
@@ -1399,7 +1399,6 @@ of the data values:
 
 .. ipython:: python
 
-
    def expand_grid(data_dict):
        rows = itertools.product(*data_dict.values())
        return pd.DataFrame.from_records(rows, columns=data_dict.keys())
diff --git a/doc/source/gotchas.rst b/doc/source/gotchas.rst
index 7d1ba865d..2b42eebf7 100644
--- a/doc/source/gotchas.rst
+++ b/doc/source/gotchas.rst
@@ -301,9 +301,7 @@ Byte-Ordering Issues
 --------------------
 Occasionally you may have to deal with data that were created on a machine with
 a different byte order than the one on which you are running Python. A common
-symptom of this issue is an error like:
-
-.. code-block:: python-traceback
+symptom of this issue is an error like:::
 
     Traceback
         ...
diff --git a/doc/source/io.rst b/doc/source/io.rst
index 9aff1e54d..b22f52e44 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -4879,7 +4879,7 @@ below and the SQLAlchemy `documentation <https://docs.sqlalchemy.org/en/latest/c
 
 If you want to manage your own connections you can pass one of those instead:
 
-.. code-block:: python
+.. ipython:: python
 
    with engine.connect() as conn, conn.begin():
        data = pd.read_sql_table('data', conn)
diff --git a/doc/source/merging.rst b/doc/source/merging.rst
index 6f7ee4917..c97935803 100644
--- a/doc/source/merging.rst
+++ b/doc/source/merging.rst
@@ -1122,6 +1122,8 @@ This is equivalent but less verbose and more memory efficient / faster than this
           labels=['left', 'right'], vertical=False);
    plt.close('all');
 
+.. _merging.join_with_two_multi_indexes:
+
 Joining with two MultiIndexes
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
diff --git a/doc/source/sparse.rst b/doc/source/sparse.rst
index 9316dad76..540e52fc2 100644
--- a/doc/source/sparse.rst
+++ b/doc/source/sparse.rst
@@ -151,6 +151,7 @@ It raises if any value cannot be coerced to specified dtype.
 .. code-block:: ipython
 
    In [1]: ss = pd.Series([1, np.nan, np.nan]).to_sparse()
+   Out[1]:
    0    1.0
    1    NaN
    2    NaN
@@ -160,6 +161,7 @@ It raises if any value cannot be coerced to specified dtype.
    Block lengths: array([1], dtype=int32)
 
    In [2]: ss.astype(np.int64)
+   Out[2]:
    ValueError: unable to coerce current fill_value nan to int64 dtype
 
 .. _sparse.calculation:
@@ -223,10 +225,6 @@ A :meth:`SparseSeries.to_coo` method is implemented for transforming a ``SparseS
 
 The method requires a ``MultiIndex`` with two or more levels.
 
-.. ipython:: python
-   :suppress:
-
-
 .. ipython:: python
 
    s = pd.Series([3.0, np.nan, 1.0, 3.0, np.nan, np.nan])
@@ -271,9 +269,6 @@ Specifying different row and column labels (and not sorting them) yields a diffe
 
 A convenience method :meth:`SparseSeries.from_coo` is implemented for creating a ``SparseSeries`` from a ``scipy.sparse.coo_matrix``.
 
-.. ipython:: python
-   :suppress:
-
 .. ipython:: python
 
    from scipy import sparse
diff --git a/doc/source/whatsnew/v0.13.1.rst b/doc/source/whatsnew/v0.13.1.rst
index 568dab2d5..8a89450be 100644
--- a/doc/source/whatsnew/v0.13.1.rst
+++ b/doc/source/whatsnew/v0.13.1.rst
@@ -220,7 +220,7 @@ Enhancements
 
       pd.MultiIndex.from_product([shades, colors], names=['shade', 'color'])
 
-- Panel :meth:`~pandas.Panel.apply` will work on non-ufuncs. See :ref:`the docs<basics.apply_panel>`.
+- Panel :meth:`~pandas.Panel.apply` will work on non-ufuncs. See :ref:`the docs<basics.apply>`.
 
   .. ipython:: python
 
diff --git a/doc/source/whatsnew/v0.19.0.rst b/doc/source/whatsnew/v0.19.0.rst
index 6f4e8e36c..38208e9ff 100644
--- a/doc/source/whatsnew/v0.19.0.rst
+++ b/doc/source/whatsnew/v0.19.0.rst
@@ -1250,8 +1250,8 @@ Operators now preserve dtypes
    s
    s.astype(np.int64)
 
-  ``astype`` fails if data contains values which cannot be converted to specified ``dtype``.
-  Note that the limitation is applied to ``fill_value`` which default is ``np.nan``.
+``astype`` fails if data contains values which cannot be converted to specified ``dtype``.
+Note that the limitation is applied to ``fill_value`` which default is ``np.nan``.
 
 .. code-block:: ipython
 
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index aadca1fcb..a85e5b3ea 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -59,8 +59,8 @@ _doc_read_csv_and_table = r"""
 Also supports optionally iterating or breaking of the file
 into chunks.
 
-Additional help can be found in the `online docs for IO Tools
-<http://pandas.pydata.org/pandas-docs/stable/io.html>`_.
+Additional help can be found in the online docs for
+`IO Tools <http://pandas.pydata.org/pandas-docs/stable/io.html>`_.
 
 Parameters
 ----------
