commit afe7f1de9bb03a9a1a5122a6e32458225f8c007a
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Mon May 11 10:19:01 2020 -0700

    PERF: use is_foo_dtype fastpaths (#34111)

diff --git a/pandas/core/arrays/categorical.py b/pandas/core/arrays/categorical.py
index d07a6db43..dd5ff7781 100644
--- a/pandas/core/arrays/categorical.py
+++ b/pandas/core/arrays/categorical.py
@@ -134,7 +134,7 @@ def _cat_compare_op(op):
                     "use 'np.asarray(cat) <op> other'."
                 )
 
-            if isinstance(other, ExtensionArray) and needs_i8_conversion(other):
+            if isinstance(other, ExtensionArray) and needs_i8_conversion(other.dtype):
                 # We would return NotImplemented here, but that messes up
                 #  ExtensionIndex's wrapped methods
                 return op(other, self)
diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index 973fdbdc4..357ef5f5e 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -363,7 +363,7 @@ default 'raise'
 
     def _round(self, freq, mode, ambiguous, nonexistent):
         # round the local times
-        if is_datetime64tz_dtype(self):
+        if is_datetime64tz_dtype(self.dtype):
             # operate on naive timestamps, then convert back to aware
             naive = self.tz_localize(None)
             result = naive._round(freq, mode, ambiguous, nonexistent)
@@ -1032,7 +1032,7 @@ class DatetimeLikeArrayMixin(
                     values = values.copy()
 
                 new_values = func(values, limit=limit, mask=mask)
-                if is_datetime64tz_dtype(self):
+                if is_datetime64tz_dtype(self.dtype):
                     # we need to pass int64 values to the constructor to avoid
                     #  re-localizing incorrectly
                     new_values = new_values.view("i8")
@@ -1379,6 +1379,7 @@ class DatetimeLikeArrayMixin(
 
     @unpack_zerodim_and_defer("__add__")
     def __add__(self, other):
+        other_dtype = getattr(other, "dtype", None)
 
         # scalar others
         if other is NaT:
@@ -1398,16 +1399,16 @@ class DatetimeLikeArrayMixin(
             result = self._time_shift(other)
 
         # array-like others
-        elif is_timedelta64_dtype(other):
+        elif is_timedelta64_dtype(other_dtype):
             # TimedeltaIndex, ndarray[timedelta64]
             result = self._add_timedelta_arraylike(other)
-        elif is_object_dtype(other):
+        elif is_object_dtype(other_dtype):
             # e.g. Array/Index of DateOffset objects
             result = self._addsub_object_array(other, operator.add)
-        elif is_datetime64_dtype(other) or is_datetime64tz_dtype(other):
+        elif is_datetime64_dtype(other_dtype) or is_datetime64tz_dtype(other_dtype):
             # DatetimeIndex, ndarray[datetime64]
             return self._add_datetime_arraylike(other)
-        elif is_integer_dtype(other):
+        elif is_integer_dtype(other_dtype):
             if not is_period_dtype(self.dtype):
                 raise integer_op_not_supported(self)
             result = self._addsub_int_array(other, operator.add)
@@ -1419,7 +1420,7 @@ class DatetimeLikeArrayMixin(
             #  In remaining cases, this will end up raising TypeError.
             return NotImplemented
 
-        if is_timedelta64_dtype(result) and isinstance(result, np.ndarray):
+        if isinstance(result, np.ndarray) and is_timedelta64_dtype(result.dtype):
             from pandas.core.arrays import TimedeltaArray
 
             return TimedeltaArray(result)
@@ -1455,13 +1456,13 @@ class DatetimeLikeArrayMixin(
             result = self._sub_period(other)
 
         # array-like others
-        elif is_timedelta64_dtype(other):
+        elif is_timedelta64_dtype(other_dtype):
             # TimedeltaIndex, ndarray[timedelta64]
             result = self._add_timedelta_arraylike(-other)
-        elif is_object_dtype(other):
+        elif is_object_dtype(other_dtype):
             # e.g. Array/Index of DateOffset objects
             result = self._addsub_object_array(other, operator.sub)
-        elif is_datetime64_dtype(other) or is_datetime64tz_dtype(other):
+        elif is_datetime64_dtype(other_dtype) or is_datetime64tz_dtype(other_dtype):
             # DatetimeIndex, ndarray[datetime64]
             result = self._sub_datetime_arraylike(other)
         elif is_period_dtype(other_dtype):
@@ -1475,14 +1476,16 @@ class DatetimeLikeArrayMixin(
             # Includes ExtensionArrays, float_dtype
             return NotImplemented
 
-        if is_timedelta64_dtype(result) and isinstance(result, np.ndarray):
+        if isinstance(result, np.ndarray) and is_timedelta64_dtype(result.dtype):
             from pandas.core.arrays import TimedeltaArray
 
             return TimedeltaArray(result)
         return result
 
     def __rsub__(self, other):
-        if is_datetime64_any_dtype(other) and is_timedelta64_dtype(self.dtype):
+        other_dtype = getattr(other, "dtype", None)
+
+        if is_datetime64_any_dtype(other_dtype) and is_timedelta64_dtype(self.dtype):
             # ndarray[datetime64] cannot be subtracted from self, so
             # we need to wrap in DatetimeArray/Index and flip the operation
             if lib.is_scalar(other):
@@ -1504,7 +1507,7 @@ class DatetimeLikeArrayMixin(
             raise TypeError(
                 f"cannot subtract {type(self).__name__} from {type(other).__name__}"
             )
-        elif is_period_dtype(self.dtype) and is_timedelta64_dtype(other):
+        elif is_period_dtype(self.dtype) and is_timedelta64_dtype(other_dtype):
             # TODO: Can we simplify/generalize these cases at all?
             raise TypeError(f"cannot subtract {type(self).__name__} from {other.dtype}")
         elif is_timedelta64_dtype(self.dtype):
diff --git a/pandas/core/arrays/datetimes.py b/pandas/core/arrays/datetimes.py
index fda852e25..dc17f13da 100644
--- a/pandas/core/arrays/datetimes.py
+++ b/pandas/core/arrays/datetimes.py
@@ -631,7 +631,9 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
     def _assert_tzawareness_compat(self, other):
         # adapted from _Timestamp._assert_tzawareness_compat
         other_tz = getattr(other, "tzinfo", None)
-        if is_datetime64tz_dtype(other):
+        other_dtype = getattr(other, "dtype", None)
+
+        if is_datetime64tz_dtype(other_dtype):
             # Get tzinfo from Series dtype
             other_tz = other.dtype.tz
         if other is NaT:
@@ -1913,8 +1915,9 @@ def sequence_to_dt64ns(
 
     # By this point we are assured to have either a numpy array or Index
     data, copy = maybe_convert_dtype(data, copy)
+    data_dtype = getattr(data, "dtype", None)
 
-    if is_object_dtype(data) or is_string_dtype(data):
+    if is_object_dtype(data_dtype) or is_string_dtype(data_dtype):
         # TODO: We do not have tests specific to string-dtypes,
         #  also complex or categorical or other extension
         copy = False
@@ -1927,15 +1930,16 @@ def sequence_to_dt64ns(
                 data, dayfirst=dayfirst, yearfirst=yearfirst
             )
             tz = maybe_infer_tz(tz, inferred_tz)
+        data_dtype = data.dtype
 
     # `data` may have originally been a Categorical[datetime64[ns, tz]],
     # so we need to handle these types.
-    if is_datetime64tz_dtype(data):
+    if is_datetime64tz_dtype(data_dtype):
         # DatetimeArray -> ndarray
         tz = maybe_infer_tz(tz, data.tz)
         result = data._data
 
-    elif is_datetime64_dtype(data):
+    elif is_datetime64_dtype(data_dtype):
         # tz-naive DatetimeArray or ndarray[datetime64]
         data = getattr(data, "_data", data)
         if data.dtype != DT64NS_DTYPE:
diff --git a/pandas/core/arrays/sparse/array.py b/pandas/core/arrays/sparse/array.py
index 9b6d4ad73..2720c831b 100644
--- a/pandas/core/arrays/sparse/array.py
+++ b/pandas/core/arrays/sparse/array.py
@@ -1517,7 +1517,7 @@ def make_sparse(arr: np.ndarray, kind="block", fill_value=None, dtype=None, copy
         mask = notna(arr)
     else:
         # cast to object comparison to be safe
-        if is_string_dtype(arr):
+        if is_string_dtype(arr.dtype):
             arr = arr.astype(object)
 
         if is_object_dtype(arr.dtype):
diff --git a/pandas/core/dtypes/cast.py b/pandas/core/dtypes/cast.py
index 9865a7d28..21e05b0c3 100644
--- a/pandas/core/dtypes/cast.py
+++ b/pandas/core/dtypes/cast.py
@@ -1366,7 +1366,7 @@ def maybe_cast_to_datetime(value, dtype, errors: str = "raise"):
                             # is solved. String data that is passed with a
                             # datetime64tz is assumed to be naive which should
                             # be localized to the timezone.
-                            is_dt_string = is_string_dtype(value)
+                            is_dt_string = is_string_dtype(value.dtype)
                             value = to_datetime(value, errors=errors).array
                             if is_dt_string:
                                 # Strings here are naive, so directly localize
diff --git a/pandas/core/dtypes/concat.py b/pandas/core/dtypes/concat.py
index e7e8d016e..ca3a41813 100644
--- a/pandas/core/dtypes/concat.py
+++ b/pandas/core/dtypes/concat.py
@@ -40,14 +40,14 @@ def get_dtype_kinds(l):
         dtype = arr.dtype
         if is_categorical_dtype(dtype):
             typ = "category"
-        elif is_sparse(arr):
+        elif is_sparse(dtype):
             typ = "sparse"
         elif isinstance(arr, ABCRangeIndex):
             typ = "range"
-        elif is_datetime64tz_dtype(arr):
+        elif is_datetime64tz_dtype(dtype):
             # if to_concat contains different tz,
             # the result must be object dtype
-            typ = str(arr.dtype)
+            typ = str(dtype)
         elif is_datetime64_dtype(dtype):
             typ = "datetime"
         elif is_timedelta64_dtype(dtype):
@@ -57,7 +57,7 @@ def get_dtype_kinds(l):
         elif is_bool_dtype(dtype):
             typ = "bool"
         elif is_extension_array_dtype(dtype):
-            typ = str(arr.dtype)
+            typ = str(dtype)
         else:
             typ = dtype.kind
         typs.add(typ)
diff --git a/pandas/core/dtypes/missing.py b/pandas/core/dtypes/missing.py
index ab8df492f..443206754 100644
--- a/pandas/core/dtypes/missing.py
+++ b/pandas/core/dtypes/missing.py
@@ -393,7 +393,7 @@ def array_equivalent(left, right, strict_nan: bool = False) -> bool:
 
     # Object arrays can contain None, NaN and NaT.
     # string dtypes must be come to this path for NumPy 1.7.1 compat
-    if is_string_dtype(left) or is_string_dtype(right):
+    if is_string_dtype(left.dtype) or is_string_dtype(right.dtype):
 
         if not strict_nan:
             # isna considers NaN and None to be equivalent.
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 56c868c7b..85b6a8431 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -6907,9 +6907,9 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
             index = df.index
             methods = {"index", "values", "nearest", "time"}
             is_numeric_or_datetime = (
-                is_numeric_dtype(index)
-                or is_datetime64_any_dtype(index)
-                or is_timedelta64_dtype(index)
+                is_numeric_dtype(index.dtype)
+                or is_datetime64_any_dtype(index.dtype)
+                or is_timedelta64_dtype(index.dtype)
             )
             if method not in methods and not is_numeric_or_datetime:
                 raise ValueError(
@@ -8588,7 +8588,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
             right = right.fillna(method=method, axis=fill_axis, limit=limit)
 
         # if DatetimeIndex have different tz, convert to UTC
-        if is_datetime64tz_dtype(left.index):
+        if is_datetime64tz_dtype(left.index.dtype):
             if left.index.tz != right.index.tz:
                 if join_index is not None:
                     left.index = join_index
@@ -8675,7 +8675,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
 
         # if DatetimeIndex have different tz, convert to UTC
         if is_series or (not is_series and axis == 0):
-            if is_datetime64tz_dtype(left.index):
+            if is_datetime64tz_dtype(left.index.dtype):
                 if left.index.tz != right.index.tz:
                     if join_index is not None:
                         left.index = join_index
@@ -9957,13 +9957,13 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
             return pd.Series(d, index=stat_index, name=data.name)
 
         def describe_1d(data):
-            if is_bool_dtype(data):
+            if is_bool_dtype(data.dtype):
                 return describe_categorical_1d(data)
             elif is_numeric_dtype(data):
                 return describe_numeric_1d(data)
-            elif is_datetime64_any_dtype(data):
+            elif is_datetime64_any_dtype(data.dtype):
                 return describe_timestamp_1d(data)
-            elif is_timedelta64_dtype(data):
+            elif is_timedelta64_dtype(data.dtype):
                 return describe_numeric_1d(data)
             else:
                 return describe_categorical_1d(data)
diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index 438babda9..69c67a180 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -690,7 +690,7 @@ class SeriesGroupBy(GroupBy[Series]):
             lab = lev.take(lab.cat.codes)
             llab = lambda lab, inc: lab[inc]._multiindex.codes[-1]
 
-        if is_interval_dtype(lab):
+        if is_interval_dtype(lab.dtype):
             # TODO: should we do this inside II?
             sorter = np.lexsort((lab.left, lab.right, ids))
         else:
diff --git a/pandas/core/groupby/ops.py b/pandas/core/groupby/ops.py
index d7ec5c63e..361619701 100644
--- a/pandas/core/groupby/ops.py
+++ b/pandas/core/groupby/ops.py
@@ -461,12 +461,12 @@ class BaseGrouper:
         # are not setup for dim transforming
         if is_categorical_dtype(values.dtype) or is_sparse(values.dtype):
             raise NotImplementedError(f"{values.dtype} dtype not supported")
-        elif is_datetime64_any_dtype(values):
+        elif is_datetime64_any_dtype(values.dtype):
             if how in ["add", "prod", "cumsum", "cumprod"]:
                 raise NotImplementedError(
                     f"datetime64 type does not support {how} operations"
                 )
-        elif is_timedelta64_dtype(values):
+        elif is_timedelta64_dtype(values.dtype):
             if how in ["prod", "cumprod"]:
                 raise NotImplementedError(
                     f"timedelta64 type does not support {how} operations"
diff --git a/pandas/core/indexes/category.py b/pandas/core/indexes/category.py
index 80d3e5c8a..25df4a0be 100644
--- a/pandas/core/indexes/category.py
+++ b/pandas/core/indexes/category.py
@@ -17,6 +17,7 @@ from pandas.core.dtypes.common import (
     is_interval_dtype,
     is_list_like,
     is_scalar,
+    pandas_dtype,
 )
 from pandas.core.dtypes.dtypes import CategoricalDtype
 from pandas.core.dtypes.missing import is_valid_nat_for_dtype, isna
@@ -372,6 +373,9 @@ class CategoricalIndex(ExtensionIndex, accessor.PandasDelegate):
 
     @doc(Index.astype)
     def astype(self, dtype, copy=True):
+        if dtype is not None:
+            dtype = pandas_dtype(dtype)
+
         if is_interval_dtype(dtype):
             from pandas import IntervalIndex
 
diff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py
index bfde82d6f..4666b0c5b 100644
--- a/pandas/core/internals/blocks.py
+++ b/pandas/core/internals/blocks.py
@@ -2714,7 +2714,7 @@ def make_block(values, placement, klass=None, ndim=None, dtype=None):
         dtype = dtype or values.dtype
         klass = get_block_type(values, dtype)
 
-    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values):
+    elif klass is DatetimeTZBlock and not is_datetime64tz_dtype(values.dtype):
         # TODO: This is no longer hit internally; does it need to be retained
         #  for e.g. pyarrow?
         values = DatetimeArray._simple_new(values, dtype=dtype)
diff --git a/pandas/core/internals/concat.py b/pandas/core/internals/concat.py
index b88287f2c..f02ad2102 100644
--- a/pandas/core/internals/concat.py
+++ b/pandas/core/internals/concat.py
@@ -339,7 +339,7 @@ def _get_empty_dtype_and_na(join_units):
     if len(join_units) == 1:
         blk = join_units[0].block
         if blk is None:
-            return np.float64, np.nan
+            return np.dtype(np.float64), np.nan
 
     if _is_uniform_reindex(join_units):
         # FIXME: integrate property
@@ -424,7 +424,7 @@ def _get_empty_dtype_and_na(join_units):
                 return g, g.type(np.nan)
             elif is_numeric_dtype(g):
                 if has_none_blocks:
-                    return np.float64, np.nan
+                    return np.dtype(np.float64), np.nan
                 else:
                     return g, None
 
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 1e1044a8a..01035b97c 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -759,12 +759,12 @@ def nanvar(values, axis=None, skipna=True, ddof=1, mask=None):
     values = extract_array(values, extract_numpy=True)
     dtype = values.dtype
     mask = _maybe_get_mask(values, skipna, mask)
-    if is_any_int_dtype(values):
+    if is_any_int_dtype(dtype):
         values = values.astype("f8")
         if mask is not None:
             values[mask] = np.nan
 
-    if is_float_dtype(values):
+    if is_float_dtype(values.dtype):
         count, d = _get_counts_nanvar(values.shape, mask, axis, ddof, values.dtype)
     else:
         count, d = _get_counts_nanvar(values.shape, mask, axis, ddof)
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index 1bb095d9b..bb62cd6b3 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -118,7 +118,7 @@ def cat_safe(list_of_columns: List, sep: str):
     return result
 
 
-def _na_map(f, arr, na_result=None, dtype=object):
+def _na_map(f, arr, na_result=None, dtype=np.dtype(object)):
     if is_extension_array_dtype(arr.dtype):
         if na_result is None:
             na_result = libmissing.NA
@@ -200,7 +200,7 @@ def _map_stringarray(
         return lib.map_infer_mask(arr, func, mask.view("uint8"))
 
 
-def _map_object(f, arr, na_mask=False, na_value=np.nan, dtype=object):
+def _map_object(f, arr, na_mask=False, na_value=np.nan, dtype=np.dtype(object)):
     if not len(arr):
         return np.ndarray(0, dtype=dtype)
 
@@ -454,8 +454,8 @@ def str_contains(arr, pat, case=True, flags=0, na=np.nan, regex=True):
             upper_pat = pat.upper()
             f = lambda x: upper_pat in x
             uppered = _na_map(lambda x: x.upper(), arr)
-            return _na_map(f, uppered, na, dtype=bool)
-    return _na_map(f, arr, na, dtype=bool)
+            return _na_map(f, uppered, na, dtype=np.dtype(bool))
+    return _na_map(f, arr, na, dtype=np.dtype(bool))
 
 
 def str_startswith(arr, pat, na=np.nan):
@@ -510,7 +510,7 @@ def str_startswith(arr, pat, na=np.nan):
     dtype: bool
     """
     f = lambda x: x.startswith(pat)
-    return _na_map(f, arr, na, dtype=bool)
+    return _na_map(f, arr, na, dtype=np.dtype(bool))
 
 
 def str_endswith(arr, pat, na=np.nan):
@@ -565,7 +565,7 @@ def str_endswith(arr, pat, na=np.nan):
     dtype: bool
     """
     f = lambda x: x.endswith(pat)
-    return _na_map(f, arr, na, dtype=bool)
+    return _na_map(f, arr, na, dtype=np.dtype(bool))
 
 
 def str_replace(arr, pat, repl, n=-1, case=None, flags=0, regex=True):
@@ -824,10 +824,9 @@ def str_match(
 
     regex = re.compile(pat, flags=flags)
 
-    dtype = bool
     f = lambda x: regex.match(x) is not None
 
-    return _na_map(f, arr, na, dtype=dtype)
+    return _na_map(f, arr, na, dtype=np.dtype(bool))
 
 
 def str_fullmatch(
@@ -868,10 +867,9 @@ def str_fullmatch(
 
     regex = re.compile(pat, flags=flags)
 
-    dtype = bool
     f = lambda x: regex.fullmatch(x) is not None
 
-    return _na_map(f, arr, na, dtype=dtype)
+    return _na_map(f, arr, na, dtype=np.dtype(bool))
 
 
 def _get_single_group_name(rx):
@@ -1422,7 +1420,7 @@ def str_find(arr, sub, start=0, end=None, side="left"):
     else:
         f = lambda x: getattr(x, method)(sub, start, end)
 
-    return _na_map(f, arr, dtype="int64")
+    return _na_map(f, arr, dtype=np.dtype("int64"))
 
 
 def str_index(arr, sub, start=0, end=None, side="left"):
@@ -1442,7 +1440,7 @@ def str_index(arr, sub, start=0, end=None, side="left"):
     else:
         f = lambda x: getattr(x, method)(sub, start, end)
 
-    return _na_map(f, arr, dtype="int64")
+    return _na_map(f, arr, dtype=np.dtype("int64"))
 
 
 def str_pad(arr, width, side="left", fillchar=" "):
@@ -3284,7 +3282,7 @@ class StringMethods(NoNewAttributesMixin):
         len,
         docstring=_shared_docs["len"],
         forbidden_types=None,
-        dtype="int64",
+        dtype=np.dtype("int64"),
         returns_string=False,
     )
 
@@ -3559,69 +3557,69 @@ class StringMethods(NoNewAttributesMixin):
     _doc_args["istitle"] = dict(type="titlecase", method="istitle")
     _doc_args["isnumeric"] = dict(type="numeric", method="isnumeric")
     _doc_args["isdecimal"] = dict(type="decimal", method="isdecimal")
-    # force _noarg_wrapper return type with dtype=bool (GH 29624)
+    # force _noarg_wrapper return type with dtype=np.dtype(bool) (GH 29624)
     isalnum = _noarg_wrapper(
         lambda x: x.isalnum(),
         name="isalnum",
         docstring=_shared_docs["ismethods"] % _doc_args["isalnum"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isalpha = _noarg_wrapper(
         lambda x: x.isalpha(),
         name="isalpha",
         docstring=_shared_docs["ismethods"] % _doc_args["isalpha"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isdigit = _noarg_wrapper(
         lambda x: x.isdigit(),
         name="isdigit",
         docstring=_shared_docs["ismethods"] % _doc_args["isdigit"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isspace = _noarg_wrapper(
         lambda x: x.isspace(),
         name="isspace",
         docstring=_shared_docs["ismethods"] % _doc_args["isspace"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     islower = _noarg_wrapper(
         lambda x: x.islower(),
         name="islower",
         docstring=_shared_docs["ismethods"] % _doc_args["islower"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isupper = _noarg_wrapper(
         lambda x: x.isupper(),
         name="isupper",
         docstring=_shared_docs["ismethods"] % _doc_args["isupper"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     istitle = _noarg_wrapper(
         lambda x: x.istitle(),
         name="istitle",
         docstring=_shared_docs["ismethods"] % _doc_args["istitle"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isnumeric = _noarg_wrapper(
         lambda x: x.isnumeric(),
         name="isnumeric",
         docstring=_shared_docs["ismethods"] % _doc_args["isnumeric"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
     isdecimal = _noarg_wrapper(
         lambda x: x.isdecimal(),
         name="isdecimal",
         docstring=_shared_docs["ismethods"] % _doc_args["isdecimal"],
         returns_string=False,
-        dtype=bool,
+        dtype=np.dtype(bool),
     )
 
     @classmethod
diff --git a/pandas/core/tools/datetimes.py b/pandas/core/tools/datetimes.py
index 207c5cc98..d27b30fc3 100644
--- a/pandas/core/tools/datetimes.py
+++ b/pandas/core/tools/datetimes.py
@@ -290,8 +290,9 @@ def _convert_listlike_datetimes(
     if isinstance(arg, (list, tuple)):
         arg = np.array(arg, dtype="O")
 
+    arg_dtype = getattr(arg, "dtype", None)
     # these are shortcutable
-    if is_datetime64tz_dtype(arg):
+    if is_datetime64tz_dtype(arg_dtype):
         if not isinstance(arg, (DatetimeArray, DatetimeIndex)):
             return DatetimeIndex(arg, tz=tz, name=name)
         if tz == "utc":
@@ -300,7 +301,7 @@ def _convert_listlike_datetimes(
             arg = arg.tz_convert(None).tz_localize(tz)  # type: ignore
         return arg
 
-    elif is_datetime64_ns_dtype(arg):
+    elif is_datetime64_ns_dtype(arg_dtype):
         if not isinstance(arg, (DatetimeArray, DatetimeIndex)):
             try:
                 return DatetimeIndex(arg, tz=tz, name=name)
diff --git a/pandas/core/tools/numeric.py b/pandas/core/tools/numeric.py
index 72831b29a..41548931f 100644
--- a/pandas/core/tools/numeric.py
+++ b/pandas/core/tools/numeric.py
@@ -140,9 +140,10 @@ def to_numeric(arg, errors="raise", downcast=None):
     else:
         values = arg
 
-    if is_numeric_dtype(values):
+    values_dtype = getattr(values, "dtype", None)
+    if is_numeric_dtype(values_dtype):
         pass
-    elif is_datetime_or_timedelta_dtype(values):
+    elif is_datetime_or_timedelta_dtype(values_dtype):
         values = values.astype(np.int64)
     else:
         values = ensure_object(values)
@@ -157,7 +158,7 @@ def to_numeric(arg, errors="raise", downcast=None):
 
     # attempt downcast only if the data has been successfully converted
     # to a numerical dtype and if a downcast method has been specified
-    if downcast is not None and is_numeric_dtype(values):
+    if downcast is not None and is_numeric_dtype(values.dtype):
         typecodes = None
 
         if downcast in ("integer", "signed"):
diff --git a/pandas/io/formats/format.py b/pandas/io/formats/format.py
index 68ad55996..02339f434 100644
--- a/pandas/io/formats/format.py
+++ b/pandas/io/formats/format.py
@@ -1116,7 +1116,7 @@ def format_array(
     fmt_klass: Type[GenericArrayFormatter]
     if is_datetime64_dtype(values.dtype):
         fmt_klass = Datetime64Formatter
-    elif is_datetime64tz_dtype(values):
+    elif is_datetime64tz_dtype(values.dtype):
         fmt_klass = Datetime64TZFormatter
     elif is_timedelta64_dtype(values.dtype):
         fmt_klass = Timedelta64Formatter
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index c657a925a..c2915f6fc 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -89,7 +89,7 @@ def _handle_date_column(col, utc=None, format=None):
             format = "s"
         if format in ["D", "d", "h", "m", "s", "ms", "us", "ns"]:
             return to_datetime(col, errors="coerce", unit=format, utc=utc)
-        elif is_datetime64tz_dtype(col):
+        elif is_datetime64tz_dtype(col.dtype):
             # coerce to UTC timezone
             # GH11216
             return to_datetime(col, utc=True)
@@ -108,7 +108,7 @@ def _parse_date_columns(data_frame, parse_dates):
     # we could in theory do a 'nice' conversion from a FixedOffset tz
     # GH11216
     for col_name, df_col in data_frame.items():
-        if is_datetime64tz_dtype(df_col) or col_name in parse_dates:
+        if is_datetime64tz_dtype(df_col.dtype) or col_name in parse_dates:
             try:
                 fmt = parse_dates[col_name]
             except TypeError:
diff --git a/pandas/tests/base/test_misc.py b/pandas/tests/base/test_misc.py
index 72417d3af..527f80648 100644
--- a/pandas/tests/base/test_misc.py
+++ b/pandas/tests/base/test_misc.py
@@ -73,7 +73,7 @@ def test_none_comparison(series_with_simple_index):
     assert result.iat[0]
     assert result.iat[1]
 
-    if is_datetime64_dtype(series) or is_datetime64tz_dtype(series):
+    if is_datetime64_dtype(series.dtype) or is_datetime64tz_dtype(series.dtype):
         # Following DatetimeIndex (and Timestamp) convention,
         # inequality comparisons with Series[datetime64] raise
         msg = "Invalid comparison"
diff --git a/pandas/tests/base/test_unique.py b/pandas/tests/base/test_unique.py
index 9703faff4..8cf234012 100644
--- a/pandas/tests/base/test_unique.py
+++ b/pandas/tests/base/test_unique.py
@@ -23,7 +23,7 @@ def test_unique(index_or_series_obj):
         tm.assert_index_equal(result, expected)
     elif isinstance(obj, pd.Index):
         expected = pd.Index(unique_values, dtype=obj.dtype)
-        if is_datetime64tz_dtype(obj):
+        if is_datetime64tz_dtype(obj.dtype):
             expected = expected.normalize()
         tm.assert_index_equal(result, expected)
     else:
@@ -61,7 +61,7 @@ def test_unique_null(null_obj, index_or_series_obj):
 
     if isinstance(obj, pd.Index):
         expected = pd.Index(unique_values, dtype=obj.dtype)
-        if is_datetime64tz_dtype(obj):
+        if is_datetime64tz_dtype(obj.dtype):
             result = result.normalize()
             expected = expected.normalize()
         elif isinstance(obj, pd.CategoricalIndex):
