commit 95770dff28022c58633ad07b93b707881378a99a
Author: Naomi Bonnin <naomi172839@gmail.com>
Date:   Fri Dec 27 10:29:37 2019 -0500

    Replace "foo!r" to "repr(foo)" syntax #29886 (#30502)

diff --git a/pandas/_version.py b/pandas/_version.py
index dfed9574c..66e756a47 100644
--- a/pandas/_version.py
+++ b/pandas/_version.py
@@ -79,17 +79,17 @@ def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False):
             if e.errno == errno.ENOENT:
                 continue
             if verbose:
-                print("unable to run {dispcmd}".format(dispcmd=dispcmd))
+                print(f"unable to run {dispcmd}")
                 print(e)
             return None
     else:
         if verbose:
-            print("unable to find command, tried %s" % (commands,))
+            print(f"unable to find command, tried {commands}")
         return None
     stdout = p.communicate()[0].strip().decode()
     if p.returncode != 0:
         if verbose:
-            print("unable to run {dispcmd} (error)".format(dispcmd=dispcmd))
+            print(f"unable to run {dispcmd} (error)")
         return None
     return stdout
 
@@ -101,10 +101,8 @@ def versions_from_parentdir(parentdir_prefix, root, verbose):
     if not dirname.startswith(parentdir_prefix):
         if verbose:
             print(
-                "guessing rootdir is '{root}', but '{dirname}' "
-                "doesn't start with prefix '{parentdir_prefix}'".format(
-                    root=root, dirname=dirname, parentdir_prefix=parentdir_prefix
-                )
+                f"guessing rootdir is '{root}', but '{dirname}' "
+                f"doesn't start with prefix '{parentdir_prefix}'"
             )
         raise NotThisMethod("rootdir doesn't start with parentdir_prefix")
     return {
@@ -163,15 +161,15 @@ def git_versions_from_keywords(keywords, tag_prefix, verbose):
         # "stabilization", as well as "HEAD" and "master".
         tags = {r for r in refs if re.search(r"\d", r)}
         if verbose:
-            print("discarding '{}', no digits".format(",".join(refs - tags)))
+            print(f"discarding '{','.join(refs - tags)}', no digits")
     if verbose:
-        print("likely tags: {}".format(",".join(sorted(tags))))
+        print(f"likely tags: {','.join(sorted(tags))}")
     for ref in sorted(tags):
         # sorting will prefer e.g. "2.0" over "2.0rc1"
         if ref.startswith(tag_prefix):
             r = ref[len(tag_prefix) :]
             if verbose:
-                print("picking {r}".format(r=r))
+                print(f"picking {r}")
             return {
                 "version": r,
                 "full-revisionid": keywords["full"].strip(),
@@ -198,7 +196,7 @@ def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
 
     if not os.path.exists(os.path.join(root, ".git")):
         if verbose:
-            print("no .git in {root}".format(root=root))
+            print(f"no .git in {root}")
         raise NotThisMethod("no .git directory")
 
     GITS = ["git"]
@@ -240,17 +238,13 @@ def git_pieces_from_vcs(tag_prefix, root, verbose, run_command=run_command):
         mo = re.search(r"^(.+)-(\d+)-g([0-9a-f]+)$", git_describe)
         if not mo:
             # unparseable. Maybe git-describe is misbehaving?
-            pieces["error"] = (
-                "unable to parse git-describe output: "
-                "'{describe_out}'".format(describe_out=describe_out)
-            )
+            pieces["error"] = f"unable to parse git-describe output: '{describe_out}'"
             return pieces
 
         # tag
         full_tag = mo.group(1)
         if not full_tag.startswith(tag_prefix):
-            fmt = "tag '{full_tag}' doesn't start with prefix '{tag_prefix}'"
-            msg = fmt.format(full_tag=full_tag, tag_prefix=tag_prefix)
+            msg = f"tag '{full_tag}' doesn't start with prefix '{tag_prefix}'"
             if verbose:
                 print(msg)
             pieces["error"] = msg
@@ -291,12 +285,12 @@ def render_pep440(pieces):
         rendered = pieces["closest-tag"]
         if pieces["distance"] or pieces["dirty"]:
             rendered += plus_or_dot(pieces)
-            rendered += "{:d}.g{}".format(pieces["distance"], pieces["short"])
+            rendered += f"{pieces['distance']:d}.g{pieces['short']}"
             if pieces["dirty"]:
                 rendered += ".dirty"
     else:
         # exception #1
-        rendered = "0+untagged.{:d}.g{}".format(pieces["distance"], pieces["short"])
+        rendered = f"0+untagged.{pieces['distance']:d}.g{pieces['short']}"
         if pieces["dirty"]:
             rendered += ".dirty"
     return rendered
@@ -311,10 +305,10 @@ def render_pep440_pre(pieces):
     if pieces["closest-tag"]:
         rendered = pieces["closest-tag"]
         if pieces["distance"]:
-            rendered += ".post.dev%d" % pieces["distance"]
+            rendered += f".post.dev{pieces['distance']:d}"
     else:
         # exception #1
-        rendered = "0.post.dev%d" % pieces["distance"]
+        rendered = f"0.post.dev{pieces['distance']:d}"
     return rendered
 
 
@@ -330,17 +324,17 @@ def render_pep440_post(pieces):
     if pieces["closest-tag"]:
         rendered = pieces["closest-tag"]
         if pieces["distance"] or pieces["dirty"]:
-            rendered += ".post{:d}".format(pieces["distance"])
+            rendered += f".post{pieces['distance']:d}"
             if pieces["dirty"]:
                 rendered += ".dev0"
             rendered += plus_or_dot(pieces)
-            rendered += "g{}".format(pieces["short"])
+            rendered += f"g{pieces['short']}"
     else:
         # exception #1
-        rendered = "0.post%d" % pieces["distance"]
+        rendered = f"0.pos{pieces['distance']:d}"
         if pieces["dirty"]:
             rendered += ".dev0"
-        rendered += "+g{}".format(pieces["short"])
+        rendered += f"+g{pieces['short']}"
     return rendered
 
 
@@ -353,12 +347,12 @@ def render_pep440_old(pieces):
     if pieces["closest-tag"]:
         rendered = pieces["closest-tag"]
         if pieces["distance"] or pieces["dirty"]:
-            rendered += ".post%d" % pieces["distance"]
+            rendered += f".post{pieces['distance']:d}"
             if pieces["dirty"]:
                 rendered += ".dev0"
     else:
         # exception #1
-        rendered = "0.post%d" % pieces["distance"]
+        rendered = f"0.post{pieces['distance']:d}"
         if pieces["dirty"]:
             rendered += ".dev0"
     return rendered
@@ -374,7 +368,7 @@ def render_git_describe(pieces):
     if pieces["closest-tag"]:
         rendered = pieces["closest-tag"]
         if pieces["distance"]:
-            rendered += "-{:d}-g{}".format(pieces["distance"], pieces["short"])
+            rendered += f"-{pieces['distance']:d}-g{pieces['short']}"
     else:
         # exception #1
         rendered = pieces["short"]
@@ -392,7 +386,7 @@ def render_git_describe_long(pieces):
 
     if pieces["closest-tag"]:
         rendered = pieces["closest-tag"]
-        rendered += "-{:d}-g{}".format(pieces["distance"], pieces["short"])
+        rendered += f"-{pieces['distance']:d}-g{pieces['short']}"
     else:
         # exception #1
         rendered = pieces["short"]
@@ -426,7 +420,7 @@ def render(pieces, style):
     elif style == "git-describe-long":
         rendered = render_git_describe_long(pieces)
     else:
-        raise ValueError("unknown style '{style}'".format(style=style))
+        raise ValueError(f"unknown style '{style}'")
 
     return {
         "version": rendered,
diff --git a/pandas/io/formats/style.py b/pandas/io/formats/style.py
index d3a12ccb7..0c9d2d54d 100644
--- a/pandas/io/formats/style.py
+++ b/pandas/io/formats/style.py
@@ -255,7 +255,7 @@ class Styler:
         BLANK_VALUE = ""
 
         def format_attr(pair):
-            return "{key}={value}".format(**pair)
+            return f"{pair['key']}={pair['value']}"
 
         # for sparsifying a MultiIndex
         idx_lengths = _get_level_lengths(self.index)
diff --git a/pandas/tests/indexes/period/test_period.py b/pandas/tests/indexes/period/test_period.py
index 6a3137785..c11dda8f6 100644
--- a/pandas/tests/indexes/period/test_period.py
+++ b/pandas/tests/indexes/period/test_period.py
@@ -126,7 +126,7 @@ class TestPeriodIndex(DatetimeLike):
 
     def test_hash_error(self):
         index = period_range("20010101", periods=10)
-        msg = "unhashable type: '{}'".format(type(index).__name__)
+        msg = f"unhashable type: '{type(index).__name__}'"
         with pytest.raises(TypeError, match=msg):
             hash(index)
 
diff --git a/pandas/tests/io/test_sql.py b/pandas/tests/io/test_sql.py
index fe65820a7..d5c2b368a 100644
--- a/pandas/tests/io/test_sql.py
+++ b/pandas/tests/io/test_sql.py
@@ -215,9 +215,7 @@ class MixInBase:
 class MySQLMixIn(MixInBase):
     def drop_table(self, table_name):
         cur = self.conn.cursor()
-        cur.execute(
-            "DROP TABLE IF EXISTS {}".format(sql._get_valid_mysql_name(table_name))
-        )
+        cur.execute(f"DROP TABLE IF EXISTS {sql._get_valid_mysql_name(table_name)}")
         self.conn.commit()
 
     def _get_all_tables(self):
@@ -237,7 +235,7 @@ class MySQLMixIn(MixInBase):
 class SQLiteMixIn(MixInBase):
     def drop_table(self, table_name):
         self.conn.execute(
-            "DROP TABLE IF EXISTS {}".format(sql._get_valid_sqlite_name(table_name))
+            f"DROP TABLE IF EXISTS {sql._get_valid_sqlite_name(table_name)}"
         )
         self.conn.commit()
 
@@ -405,11 +403,7 @@ class PandasSQLTest:
     def _count_rows(self, table_name):
         result = (
             self._get_exec()
-            .execute(
-                "SELECT count(*) AS count_1 FROM {table_name}".format(
-                    table_name=table_name
-                )
-            )
+            .execute(f"SELECT count(*) AS count_1 FROM {table_name}")
             .fetchone()
         )
         return result[0]
@@ -1207,7 +1201,7 @@ class TestSQLiteFallbackApi(SQLiteMixIn, _TestSQLApi):
         for col in schema.split("\n"):
             if col.split()[0].strip('""') == column:
                 return col.split()[1]
-        raise ValueError("Column {column} not found".format(column=column))
+        raise ValueError(f"Column {column} not found")
 
     def test_sqlite_type_mapping(self):
 
@@ -1272,7 +1266,7 @@ class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
             # to test if connection can be made:
             self.conn.connect()
         except sqlalchemy.exc.OperationalError:
-            pytest.skip("Can't connect to {0} server".format(self.flavor))
+            pytest.skip(f"Can't connect to {self.flavor} server")
 
     def test_read_sql(self):
         self._read_sql_iris()
@@ -1414,7 +1408,7 @@ class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
 
             else:
                 raise AssertionError(
-                    "DateCol loaded with incorrect type -> {0}".format(col.dtype)
+                    f"DateCol loaded with incorrect type -> {col.dtype}"
                 )
 
         # GH11216
@@ -2051,15 +2045,13 @@ class _TestPostgreSQLAlchemy:
                 writer.writerows(data_iter)
                 s_buf.seek(0)
 
-                columns = ", ".join('"{}"'.format(k) for k in keys)
+                columns = ", ".join(f'"{k}"' for k in keys)
                 if table.schema:
-                    table_name = "{}.{}".format(table.schema, table.name)
+                    table_name = f"{table.schema}.{table.name}"
                 else:
                     table_name = table.name
 
-                sql_query = "COPY {} ({}) FROM STDIN WITH CSV".format(
-                    table_name, columns
-                )
+                sql_query = f"COPY {table_name} ({columns}) FROM STDIN WITH CSV"
                 cur.copy_expert(sql=sql_query, file=s_buf)
 
         expected = DataFrame({"col1": [1, 2], "col2": [0.1, 0.2], "col3": ["a", "n"]})
@@ -2199,14 +2191,12 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
     def _get_index_columns(self, tbl_name):
         ixs = sql.read_sql_query(
             "SELECT * FROM sqlite_master WHERE type = 'index' "
-            + "AND tbl_name = '{tbl_name}'".format(tbl_name=tbl_name),
+            + f"AND tbl_name = '{tbl_name}'",
             self.conn,
         )
         ix_cols = []
         for ix_name in ixs.name:
-            ix_info = sql.read_sql_query(
-                "PRAGMA index_info({ix_name})".format(ix_name=ix_name), self.conn
-            )
+            ix_info = sql.read_sql_query(f"PRAGMA index_info({ix_name})", self.conn)
             ix_cols.append(ix_info.name.tolist())
         return ix_cols
 
@@ -2217,15 +2207,11 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
         self._transaction_test()
 
     def _get_sqlite_column_type(self, table, column):
-        recs = self.conn.execute("PRAGMA table_info({table})".format(table=table))
+        recs = self.conn.execute(f"PRAGMA table_info({table})")
         for cid, name, ctype, not_null, default, pk in recs:
             if name == column:
                 return ctype
-        raise ValueError(
-            "Table {table}, column {column} not found".format(
-                table=table, column=column
-            )
-        )
+        raise ValueError(f"Table {table}, column {column} not found")
 
     def test_dtype(self):
         if self.flavor == "mysql":
@@ -2295,7 +2281,7 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
             sql.table_exists(weird_name, self.conn)
 
             df2 = DataFrame([[1, 2], [3, 4]], columns=["a", weird_name])
-            c_tbl = "test_weird_col_name{ndx:d}".format(ndx=ndx)
+            c_tbl = f"test_weird_col_name{ndx:d}"
             df2.to_sql(c_tbl, self.conn)
             sql.table_exists(c_tbl, self.conn)
 
@@ -2500,7 +2486,7 @@ class TestXSQLite(SQLiteMixIn):
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
-        sql_select = "SELECT * FROM {table_name}".format(table_name=table_name)
+        sql_select = f"SELECT * FROM {table_name}"
 
         def clean_up(test_table_to_drop):
             """
@@ -2788,7 +2774,7 @@ class TestXMySQL(MySQLMixIn):
         df_if_exists_1 = DataFrame({"col1": [1, 2], "col2": ["A", "B"]})
         df_if_exists_2 = DataFrame({"col1": [3, 4, 5], "col2": ["C", "D", "E"]})
         table_name = "table_if_exists"
-        sql_select = "SELECT * FROM {table_name}".format(table_name=table_name)
+        sql_select = f"SELECT * FROM {table_name}"
 
         def clean_up(test_table_to_drop):
             """
diff --git a/pandas/tests/scalar/timedelta/test_timedelta.py b/pandas/tests/scalar/timedelta/test_timedelta.py
index 20ecfd0f8..b988a72fd 100644
--- a/pandas/tests/scalar/timedelta/test_timedelta.py
+++ b/pandas/tests/scalar/timedelta/test_timedelta.py
@@ -399,7 +399,7 @@ class TestTimedeltas:
                     [np.timedelta64(i, "m") for i in np.arange(5).tolist()]
                 )
 
-            str_repr = ["{}{}".format(x, unit) for x in np.arange(5)]
+            str_repr = [f"{x}{unit}" for x in np.arange(5)]
             result = to_timedelta(wrapper(str_repr))
             tm.assert_index_equal(result, expected)
             result = TimedeltaIndex(wrapper(str_repr))
@@ -416,9 +416,9 @@ class TestTimedeltas:
             if unit == "M":
                 expected = Timedelta(np.timedelta64(2, "m").astype("timedelta64[ns]"))
 
-            result = to_timedelta("2{}".format(unit))
+            result = to_timedelta(f"2{unit}")
             assert result == expected
-            result = Timedelta("2{}".format(unit))
+            result = Timedelta(f"2{unit}")
             assert result == expected
 
     @pytest.mark.parametrize("unit", ["Y", "y", "M"])
diff --git a/pandas/tests/series/test_missing.py b/pandas/tests/series/test_missing.py
index 196749a96..c49cd6930 100644
--- a/pandas/tests/series/test_missing.py
+++ b/pandas/tests/series/test_missing.py
@@ -275,7 +275,7 @@ class TestSeriesMissingData:
                 ["2011-01-01 10:00", pd.NaT, "2011-01-03 10:00", pd.NaT], tz=tz
             )
             s = pd.Series(idx)
-            assert s.dtype == "datetime64[ns, {0}]".format(tz)
+            assert s.dtype == f"datetime64[ns, {tz}]"
             tm.assert_series_equal(pd.isna(s), null_loc)
 
             result = s.fillna(pd.Timestamp("2011-01-02 10:00"))
@@ -1284,7 +1284,7 @@ class TestSeriesInterpolateData:
     def test_interp_invalid_method(self, invalid_method):
         s = Series([1, 3, np.nan, 12, np.nan, 25])
 
-        msg = "method must be one of.* Got '{}' instead".format(invalid_method)
+        msg = f"method must be one of.* Got '{invalid_method}' instead"
         with pytest.raises(ValueError, match=msg):
             s.interpolate(method=invalid_method)
 
@@ -1608,9 +1608,9 @@ class TestSeriesInterpolateData:
         else:
             expected_error = (
                 "Index column must be numeric or datetime type when "
-                "using {method} method other than linear. "
+                f"using {method} method other than linear. "
                 "Try setting a numeric or datetime index column before "
-                "interpolating.".format(method=method)
+                "interpolating."
             )
             with pytest.raises(ValueError, match=expected_error):
                 df[0].interpolate(method=method, **kwargs)
