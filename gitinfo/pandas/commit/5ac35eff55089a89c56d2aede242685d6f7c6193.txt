commit 5ac35eff55089a89c56d2aede242685d6f7c6193
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Jul 23 15:36:43 2011 -0400

    ENH: some refactoring plus mystery bugfix in LongPanel.sort. need to investigate

diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 539cc6475..e17cfc954 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -39,7 +39,7 @@ class AxisProperty(object):
         data = getattr(obj, '_data')
         data.set_axis(self.axis, value)
 
-class NDFrame(Picklable):
+class PandasObject(Picklable):
 
     _AXIS_NUMBERS = {
         'index' : 0,
@@ -49,57 +49,6 @@ class NDFrame(Picklable):
     _AXIS_ALIASES = {}
     _AXIS_NAMES = dict((v, k) for k, v in _AXIS_NUMBERS.iteritems())
 
-    _default_stat_axis = 0
-
-    def __init__(self, data, axes=None, copy=False):
-        self._data = data
-
-    @property
-    def _constructor(self):
-        return NDFrame
-
-    @property
-    def axes(self):
-        return self._data.axes
-
-    def __repr__(self):
-        # TODO
-        return 'NDFrame'
-
-    @property
-    def values(self):
-        return self._data.as_matrix()
-
-    @property
-    def ndim(self):
-        return self._data.ndim
-
-    #----------------------------------------------------------------------
-    # Consolidation of internals
-
-    def _consolidate_inplace(self):
-        self._data = self._data.consolidate()
-
-    def consolidate(self):
-        """
-        Compute DataFrame with "consolidated" internals (data of each dtype
-        grouped together in a single ndarray). Mainly an internal API function,
-        but available here to the savvy user
-
-        Returns
-        -------
-        consolidated : DataFrame
-        """
-        cons_data = self._data.consolidate()
-        if cons_data is self._data:
-            cons_data = cons_data.copy()
-        return self._constructor(cons_data)
-
-    @property
-    def _is_mixed_type(self):
-        self._consolidate_inplace()
-        return len(self._data.blocks) > 1
-
     #----------------------------------------------------------------------
     # Axis name business
 
@@ -130,11 +79,7 @@ class NDFrame(Picklable):
         name = self._get_axis_name(axis)
         return getattr(self, name)
 
-    @property
-    def axes(self):
-        return self._data.axes
-
-    def groupby(self, mapper):
+    def groupby(self, mapper, axis=0):
         """
         Goup series using mapper (dict or key function, apply given
         function to group, return result as series).
@@ -151,7 +96,27 @@ class NDFrame(Picklable):
         GroupBy object
         """
         from pandas.core.groupby import groupby
-        return groupby(self, mapper)
+        return groupby(self, mapper, axis=axis)
+
+    def truncate(self, before=None, after=None):
+        """Function truncate a sorted DataFrame / Series before and/or after
+        some particular dates.
+
+        Parameters
+        ----------
+        before : date
+            Truncate before date
+        after : date
+            Truncate after date
+
+        Returns
+        -------
+        truncated : type of caller
+        """
+        before = datetools.to_datetime(before)
+        after = datetools.to_datetime(after)
+        # returns view, want to copy
+        return self.ix[before:after].copy()
 
     def _select_generic(self, crit, axis=0):
         """
@@ -172,6 +137,64 @@ class NDFrame(Picklable):
         new_axis = axis[np.asarray([crit(label) for label in axis])]
         return self.reindex(**{axis_name : new_axis})
 
+class NDFrame(PandasObject):
+
+    # kludge
+    _default_stat_axis = 0
+
+    def __init__(self, data, axes=None, copy=False):
+        self._data = data
+
+    @property
+    def _constructor(self):
+        return NDFrame
+
+    @property
+    def axes(self):
+        return self._data.axes
+
+    def __repr__(self):
+        # TODO
+        return 'NDFrame'
+
+    @property
+    def values(self):
+        return self._data.as_matrix()
+
+    @property
+    def ndim(self):
+        return self._data.ndim
+
+    #----------------------------------------------------------------------
+    # Consolidation of internals
+
+    def _consolidate_inplace(self):
+        self._data = self._data.consolidate()
+
+    def consolidate(self):
+        """
+        Compute DataFrame with "consolidated" internals (data of each dtype
+        grouped together in a single ndarray). Mainly an internal API function,
+        but available here to the savvy user
+
+        Returns
+        -------
+        consolidated : DataFrame
+        """
+        cons_data = self._data.consolidate()
+        if cons_data is self._data:
+            cons_data = cons_data.copy()
+        return self._constructor(cons_data)
+
+    @property
+    def _is_mixed_type(self):
+        self._consolidate_inplace()
+        return len(self._data.blocks) > 1
+
+    @property
+    def axes(self):
+        return self._data.axes
+
     def _reindex_axis(self, new_index, fill_method, axis):
         if axis == 0:
             new_data = self._data.reindex_items(new_index)
@@ -180,26 +203,6 @@ class NDFrame(Picklable):
                                                method=fill_method)
         return self._constructor(new_data)
 
-    def truncate(self, before=None, after=None):
-        """Function truncate a sorted DataFrame / Series before and/or after
-        some particular dates.
-
-        Parameters
-        ----------
-        before : date
-            Truncate before date
-        after : date
-            Truncate after date
-
-        Returns
-        -------
-        truncated : type of caller
-        """
-        before = datetools.to_datetime(before)
-        after = datetools.to_datetime(after)
-        # returns view, want to copy
-        return self.ix[before:after].copy()
-
     def cumsum(self, axis=None):
         """
         Return DataFrame of cumulative sums over requested axis.
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 98b8fcdb2..f882e1997 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -51,7 +51,6 @@ def _get_group_indices(labels, grouper):
         # some kind of callable
         return _tseries.func_groupby_indices(labels, grouper)
 
-
 class GroupBy(object):
     """
     Class for grouping and aggregating relational data.
@@ -62,20 +61,12 @@ class GroupBy(object):
         self.obj = obj
         self.axis = axis
 
-        group_axis = obj._get_axis(axis)
-        if isinstance(grouper, basestring):
-            grouper = obj[grouper]
-
         if groupings is not None:
             self.groupings = groupings
-        elif isinstance(grouper, (tuple, list)):
-            if axis != 0:
-                raise NotImplementedError('multi-grouping only done valid for '
-                                          'axis=0')
-            self.groupings = [Grouping(group_axis, obj[col_name])
-                              for col_name in grouper]
         else:
-            self.groupings = [Grouping(group_axis, grouper)]
+            groupers = _convert_strings(obj, grouper)
+            group_axis = obj._get_axis(axis)
+            self.groupings = [Grouping(group_axis, arg) for arg in groupers]
 
     @property
     def primary(self):
@@ -140,6 +131,23 @@ class GroupBy(object):
 def _get_groupings(obj, grouper, axis=0):
     pass
 
+def _group_reorder(values, label_list):
+    indexer = np.lexsort(label_list[::-1])
+
+    sorted_labels = [labels.take(indexer) for labels in label_list]
+    sorted_values = values.take(indexer)
+    return sorted_values, sorted_labels
+
+def _convert_strings(obj, groupers):
+    def _convert(arg):
+        if isinstance(arg, basestring):
+            return obj[arg]
+        return arg
+
+    if isinstance(groupers, (tuple, list)):
+        return [_convert(arg) for arg in groupers]
+    else:
+        return [_convert(groupers)]
 
 def _convert_grouper(axis, grouper):
     if isinstance(grouper, dict):
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 86e893f34..6e3a05073 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1237,7 +1237,7 @@ class LongPanel(Panel, Picklable):
 
         new_major = self.index.major_labels.take(indexer)
         new_minor = self.index.minor_labels.take(indexer)
-        new_values = self.values.take(indexer)
+        new_values = self.values.take(indexer, axis=0)
 
         new_index = LongPanelIndex(self.major_axis, self.minor_axis,
                                    new_major, new_minor)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index a79d9dde2..3807de4c3 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -15,7 +15,7 @@ import numpy as np
 
 from pandas.core.common import isnull, notnull, _ensure_index
 from pandas.core.daterange import DateRange
-from pandas.core.generic import NDFrame
+from pandas.core.generic import PandasObject
 from pandas.core.index import Index
 import pandas.core.datetools as datetools
 import pandas._tseries as _tseries
@@ -92,7 +92,7 @@ def _flex_method(op, name):
 #-------------------------------------------------------------------------------
 # Series class
 
-class Series(np.ndarray, NDFrame):
+class Series(np.ndarray, PandasObject):
     """
     Generic indexed (labeled) vector (time series or cross-section)
 
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 3f26252df..d2b4b207e 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -209,6 +209,49 @@ cdef void _aggregate_group(double_t *out, double_t *values,
             offset += stride
             start = end
 
+def group_aggregate_generic(ndarray[double_t] values, list label_list,
+                            object shape, object func):
+    cdef:
+        list sorted_labels
+        ndarray result
+        agg_func func
+
+    values, sorted_labels = _group_reorder(values, label_list)
+    result = np.empty(shape, dtype=np.float64)
+    result.fill(nan)
+
+    _aggregate_group_generic(<double_t*> result.data, <double_t*> values.data,
+                             sorted_labels, 0, len(values), shape, 0, 0, func)
+
+    return result, sorted_labels
+
+cpdef _aggregate_group_generic(double_t *out, double_t *values,
+                               list labels, int start, int end, tuple shape,
+                               Py_ssize_t which, Py_ssize_t offset,
+                               object func):
+    cdef:
+        ndarray[int32_t] axis
+        cdef Py_ssize_t stride
+
+    axis = labels[which]
+
+    # time to actually aggregate
+    if which == len(labels) - 1:
+        # print axis, start, end
+        func(out, values, <int32_t*> axis.data, start, end, offset)
+    else:
+        stride = np.prod(shape[which+1:])
+        # get group counts on axisp
+        edges = axis.searchsorted(np.arange(1, shape[which] + 1), side='left')
+        # print edges, axis
+        start = 0
+        # aggregate each subgroup
+        for end in edges:
+            _aggregate_group(out, values, labels, start, end,
+                             shape, which + 1, offset, func)
+            offset += stride
+            start = end
+
 cdef double_t _group_add(double_t *out, double_t *values, int32_t *labels,
                          int start, int end, Py_ssize_t offset):
     cdef:
