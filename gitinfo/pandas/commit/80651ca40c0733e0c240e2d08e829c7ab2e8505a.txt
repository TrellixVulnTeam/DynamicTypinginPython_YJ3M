commit 80651ca40c0733e0c240e2d08e829c7ab2e8505a
Author: jreback <jeff@reback.net>
Date:   Mon Sep 30 20:42:54 2013 -0400

    CLN: autopep8 packers.py/test_packers.py

diff --git a/doc/source/io.rst b/doc/source/io.rst
index 41a29e7a4..9442f5942 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1752,8 +1752,8 @@ both on the writing (serialization), and reading (deserialization).
 .. warning::
 
    This is a very new feature of pandas. We intend to provide certain
-   optimizations in the io of the ``msgpack`` data. We do not intend this
-   format to change (however it is experimental)
+   optimizations in the io of the ``msgpack`` data. Since this is marked
+   as an EXPERIMENTAL LIBRARY, the storage format may not be stable until a future release.
 
 .. ipython:: python
 
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index a21f4a318..98099bac1 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -567,7 +567,7 @@ Experimental
 
   .. warning::
 
-     Since this is EXPERIMENTAL LIBRARY, the storage format may not be stable until a future release.
+     Since this is an EXPERIMENTAL LIBRARY, the storage format may not be stable until a future release.
 
   .. ipython:: python
 
diff --git a/pandas/io/packers.py b/pandas/io/packers.py
index 34ffc0ae5..d6aa1ebeb 100644
--- a/pandas/io/packers.py
+++ b/pandas/io/packers.py
@@ -3,7 +3,7 @@ Msgpack serializer support for reading and writing pandas data structures
 to disk
 """
 
-# porfions of msgpack_numpy package, by Lev Givon were incorporated
+# portions of msgpack_numpy package, by Lev Givon were incorporated
 # into this module (and tests_packers.py)
 
 """
@@ -41,25 +41,17 @@ OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 """
 
 from datetime import datetime, date, timedelta
-import time
-import re
-import copy
-import itertools
-import warnings
 from dateutil.parser import parse
 
 import numpy as np
 from pandas import compat
 from pandas.compat import u
 from pandas import (
-    Timestamp, Period, Series, TimeSeries, DataFrame, Panel, Panel4D,
+    Timestamp, Period, Series, DataFrame, Panel, Panel4D,
     Index, MultiIndex, Int64Index, PeriodIndex, DatetimeIndex, Float64Index, NaT
 )
 from pandas.sparse.api import SparseSeries, SparseDataFrame, SparsePanel
 from pandas.sparse.array import BlockIndex, IntIndex
-from pandas.tseries.api import PeriodIndex, DatetimeIndex
-from pandas.core.index import Int64Index, _ensure_index
-import pandas.core.common as com
 from pandas.core.generic import NDFrame
 from pandas.core.common import needs_i8_conversion
 from pandas.core.internals import BlockManager, make_block
@@ -74,10 +66,11 @@ try:
 except:
     _BLOSC = False
 
-## until we can pass this into our conversion functions,
-## this is pretty hacky
+# until we can pass this into our conversion functions,
+# this is pretty hacky
 compressor = None
 
+
 def to_msgpack(path, *args, **kwargs):
     """
     msgpack (serialize) object to input file path
@@ -94,18 +87,15 @@ def to_msgpack(path, *args, **kwargs):
     compress : type of compressor (zlib or blosc), default to None (no compression)
     """
     global compressor
-    compressor = kwargs.pop('compress',None)
-    append = kwargs.pop('append',None)
+    compressor = kwargs.pop('compress', None)
+    append = kwargs.pop('append', None)
     if append:
         f = open(path, 'a+b')
     else:
         f = open(path, 'wb')
     try:
-        if len(args) == 1:
-            f.write(pack(args[0],**kwargs))
-        else:
-            for a in args:
-                f.write(pack(a,**kwargs))
+        for a in args:
+            f.write(pack(a, **kwargs))
     finally:
         f.close()
 
@@ -133,18 +123,19 @@ def read_msgpack(path, iterator=False, **kwargs):
     if iterator:
         return Iterator(path)
 
-    with open(path,'rb') as fh:
+    with open(path, 'rb') as fh:
         l = list(unpack(fh))
         if len(l) == 1:
             return l[0]
         return l
 
-dtype_dict = { 21 : np.dtype('M8[ns]'),
-               u('datetime64[ns]') : np.dtype('M8[ns]'),
-               u('datetime64[us]') : np.dtype('M8[us]'),
-               22 : np.dtype('m8[ns]'),
-               u('timedelta64[ns]') : np.dtype('m8[ns]'),
-               u('timedelta64[us]') : np.dtype('m8[us]') }
+dtype_dict = {21: np.dtype('M8[ns]'),
+              u('datetime64[ns]'): np.dtype('M8[ns]'),
+              u('datetime64[us]'): np.dtype('M8[us]'),
+              22: np.dtype('m8[ns]'),
+              u('timedelta64[ns]'): np.dtype('m8[ns]'),
+              u('timedelta64[us]'): np.dtype('m8[us]')}
+
 
 def dtype_for(t):
     if t in dtype_dict:
@@ -156,16 +147,17 @@ c2f_dict = {'complex':    np.float64,
             'complex64':  np.float32}
 
 # numpy 1.6.1 compat
-if hasattr(np,'float128'):
+if hasattr(np, 'float128'):
     c2f_dict['complex256'] = np.float128
 
+
 def c2f(r, i, ctype_name):
     """
     Convert strings to complex number instance with specified numpy type.
     """
 
     ftype = c2f_dict[ctype_name]
-    return np.typeDict[ctype_name](ftype(r)+1j*ftype(i))
+    return np.typeDict[ctype_name](ftype(r) + 1j * ftype(i))
 
 
 def convert(values):
@@ -194,7 +186,7 @@ def convert(values):
 
         # convert to a bytes array
         v = v.tostring()
-        return blosc.compress(v,typesize=dtype.itemsize)
+        return blosc.compress(v, typesize=dtype.itemsize)
 
     # ndarray (on original dtype)
     if dtype == 'float64' or dtype == 'int64':
@@ -203,15 +195,16 @@ def convert(values):
     # as a list
     return v.tolist()
 
+
 def unconvert(values, dtype, compress=None):
 
     if dtype == np.object_:
-        return np.array(values,dtype=object)
+        return np.array(values, dtype=object)
 
     if compress == 'zlib':
 
         values = zlib.decompress(values)
-        return np.frombuffer(values,dtype=dtype)
+        return np.frombuffer(values, dtype=dtype)
 
     elif compress == 'blosc':
 
@@ -221,10 +214,11 @@ def unconvert(values, dtype, compress=None):
         # decompress
         values = blosc.decompress(values)
 
-        return np.frombuffer(values,dtype=dtype)
+        return np.frombuffer(values, dtype=dtype)
 
     # as a list
-    return np.array(values,dtype=dtype)
+    return np.array(values, dtype=dtype)
+
 
 def encode(obj):
     """
@@ -234,68 +228,70 @@ def encode(obj):
     tobj = type(obj)
     if isinstance(obj, Index):
         if isinstance(obj, PeriodIndex):
-            return {'typ' : 'period_index',
-                    'klass' : obj.__class__.__name__,
-                    'name' : getattr(obj,'name',None),
-                    'freq' : obj.freqstr,
+            return {'typ': 'period_index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'freq': obj.freqstr,
                     'dtype': obj.dtype.num,
-                    'data': convert(obj.asi8) }
+                    'data': convert(obj.asi8)}
         elif isinstance(obj, DatetimeIndex):
-            return {'typ' : 'datetime_index',
-                    'klass' : obj.__class__.__name__,
-                    'name' : getattr(obj,'name',None),
+            return {'typ': 'datetime_index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
                     'dtype': obj.dtype.num,
                     'data': convert(obj.asi8),
-                    'freq' : obj.freqstr,
-                    'tz'   : obj.tz}
+                    'freq': obj.freqstr,
+                    'tz': obj.tz}
         elif isinstance(obj, MultiIndex):
-            return {'typ' : 'multi_index',
-                    'klass' : obj.__class__.__name__,
-                    'names' : getattr(obj,'names',None),
+            return {'typ': 'multi_index',
+                    'klass': obj.__class__.__name__,
+                    'names': getattr(obj, 'names', None),
                     'dtype': obj.dtype.num,
-                    'data': convert(obj.values) }
+                    'data': convert(obj.values)}
         else:
-            return {'typ' : 'index',
-                    'klass' : obj.__class__.__name__,
-                    'name' : getattr(obj,'name',None),
+            return {'typ': 'index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
                     'dtype': obj.dtype.num,
-                    'data': obj.tolist() }
+                    'data': obj.tolist()}
     elif isinstance(obj, Series):
         if isinstance(obj, SparseSeries):
-            d = {'typ' : 'sparse_series',
-                 'klass' : obj.__class__.__name__,
+            d = {'typ': 'sparse_series',
+                 'klass': obj.__class__.__name__,
                  'dtype': obj.dtype.num,
-                 'index' : obj.index,
-                 'sp_index' : obj.sp_index,
-                 'sp_values' : convert(obj.sp_values),
-                 'compress' : compressor}
-            for f in ['name','fill_value','kind']:
-                d[f] = getattr(obj,f,None)
+                 'index': obj.index,
+                 'sp_index': obj.sp_index,
+                 'sp_values': convert(obj.sp_values),
+                 'compress': compressor}
+            for f in ['name', 'fill_value', 'kind']:
+                d[f] = getattr(obj, f, None)
             return d
         else:
-            return {'typ' : 'series',
-                    'klass' : obj.__class__.__name__,
-                    'name' : getattr(obj,'name',None),
-                    'index' : obj.index,
+            return {'typ': 'series',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'index': obj.index,
                     'dtype': obj.dtype.num,
                     'data': convert(obj.values),
-                    'compress' : compressor}
+                    'compress': compressor}
     elif issubclass(tobj, NDFrame):
         if isinstance(obj, SparseDataFrame):
-            d = {'typ' : 'sparse_dataframe',
-                 'klass' : obj.__class__.__name__,
-                 'columns' : obj.columns }
-            for f in ['default_fill_value','default_kind']:
-                d[f] = getattr(obj,f,None)
-            d['data'] = dict([ (name,ss) for name,ss in compat.iteritems(obj) ])
+            d = {'typ': 'sparse_dataframe',
+                 'klass': obj.__class__.__name__,
+                 'columns': obj.columns}
+            for f in ['default_fill_value', 'default_kind']:
+                d[f] = getattr(obj, f, None)
+            d['data'] = dict([(name, ss)
+                             for name, ss in compat.iteritems(obj)])
             return d
         elif isinstance(obj, SparsePanel):
-            d = {'typ' : 'sparse_panel',
-                 'klass' : obj.__class__.__name__,
-                 'items' : obj.items }
-            for f in ['default_fill_value','default_kind']:
-                d[f] = getattr(obj,f,None)
-            d['data'] = dict([ (name,df) for name,df in compat.iteritems(obj) ])
+            d = {'typ': 'sparse_panel',
+                 'klass': obj.__class__.__name__,
+                 'items': obj.items}
+            for f in ['default_fill_value', 'default_kind']:
+                d[f] = getattr(obj, f, None)
+            d['data'] = dict([(name, df)
+                             for name, df in compat.iteritems(obj)])
             return d
         else:
 
@@ -304,18 +300,18 @@ def encode(obj):
                 data = data.consolidate()
 
            # the block manager
-            return {'typ' : 'block_manager',
-                    'klass'  : obj.__class__.__name__,
-                    'axes'   : data.axes,
-                    'blocks' : [ { 'items'  : b.items,
-                                   'values' : convert(b.values),
-                                   'shape'  : b.values.shape,
-                                   'dtype'  : b.dtype.num,
-                                   'klass' : b.__class__.__name__,
-                                   'compress' : compressor
-                                   } for b in data.blocks ] }
-
-    elif isinstance(obj, (datetime,date,np.datetime64,timedelta,np.timedelta64)):
+            return {'typ': 'block_manager',
+                    'klass': obj.__class__.__name__,
+                    'axes': data.axes,
+                    'blocks': [{'items': b.items,
+                                'values': convert(b.values),
+                                'shape': b.values.shape,
+                                'dtype': b.dtype.num,
+                                'klass': b.__class__.__name__,
+                                'compress': compressor
+                                } for b in data.blocks]}
+
+    elif isinstance(obj, (datetime, date, np.datetime64, timedelta, np.timedelta64)):
         if isinstance(obj, Timestamp):
             tz = obj.tzinfo
             if tz is not None:
@@ -323,66 +319,67 @@ def encode(obj):
             offset = obj.offset
             if offset is not None:
                 offset = offset.freqstr
-            return {'typ' : 'timestamp',
+            return {'typ': 'timestamp',
                     'value': obj.value,
-                    'offset' : offset,
-                    'tz' : tz}
+                    'offset': offset,
+                    'tz': tz}
         elif isinstance(obj, np.timedelta64):
-            return { 'typ' : 'timedelta64',
-                     'data' : obj.view('i8') }
+            return {'typ': 'timedelta64',
+                    'data': obj.view('i8')}
         elif isinstance(obj, timedelta):
-            return { 'typ' : 'timedelta',
-                     'data' : (obj.days,obj.seconds,obj.microseconds) }
+            return {'typ': 'timedelta',
+                    'data': (obj.days, obj.seconds, obj.microseconds)}
         elif isinstance(obj, np.datetime64):
-            return { 'typ' : 'datetime64',
-                     'data' : str(obj) }
+            return {'typ': 'datetime64',
+                    'data': str(obj)}
         elif isinstance(obj, datetime):
-            return { 'typ' : 'datetime',
-                     'data' : obj.isoformat() }
+            return {'typ': 'datetime',
+                    'data': obj.isoformat()}
         elif isinstance(obj, date):
-            return { 'typ' : 'date',
-                     'data' : obj.isoformat() }
+            return {'typ': 'date',
+                    'data': obj.isoformat()}
         raise Exception("cannot encode this datetimelike object: %s" % obj)
     elif isinstance(obj, Period):
-        return {'typ' : 'period',
-                'ordinal' : obj.ordinal,
-                'freq' : obj.freq }
+        return {'typ': 'period',
+                'ordinal': obj.ordinal,
+                'freq': obj.freq}
     elif isinstance(obj, BlockIndex):
-        return { 'typ' : 'block_index',
-                 'klass' : obj.__class__.__name__,
-                 'blocs' : obj.blocs,
-                 'blengths' : obj.blengths,
-                 'length' : obj.length }
+        return {'typ': 'block_index',
+                'klass': obj.__class__.__name__,
+                'blocs': obj.blocs,
+                'blengths': obj.blengths,
+                'length': obj.length}
     elif isinstance(obj, IntIndex):
-        return { 'typ' : 'int_index',
-                 'klass' : obj.__class__.__name__,
-                 'indices' : obj.indices,
-                 'length' : obj.length }
-    elif isinstance(obj, np.ndarray) and obj.dtype not in ['float64','int64']:
-        return {'typ' : 'ndarray',
+        return {'typ': 'int_index',
+                'klass': obj.__class__.__name__,
+                'indices': obj.indices,
+                'length': obj.length}
+    elif isinstance(obj, np.ndarray) and obj.dtype not in ['float64', 'int64']:
+        return {'typ': 'ndarray',
                 'shape': obj.shape,
                 'ndim': obj.ndim,
                 'dtype': obj.dtype.num,
                 'data': convert(obj),
-                'compress' : compressor }
+                'compress': compressor}
     elif isinstance(obj, np.number):
         if np.iscomplexobj(obj):
-            return {'typ' : 'np_scalar',
-                    'sub_typ' : 'np_complex',
+            return {'typ': 'np_scalar',
+                    'sub_typ': 'np_complex',
                     'dtype': obj.dtype.name,
                     'real': obj.real.__repr__(),
                     'imag': obj.imag.__repr__()}
         else:
-            return {'typ' : 'np_scalar',
+            return {'typ': 'np_scalar',
                     'dtype': obj.dtype.name,
                     'data': obj.__repr__()}
     elif isinstance(obj, complex):
-        return {'typ' : 'np_complex',
+        return {'typ': 'np_complex',
                 'real': obj.real.__repr__(),
                 'imag': obj.imag.__repr__()}
 
     return obj
 
+
 def decode(obj):
     """
     Decoder for deserializing numpy data types.
@@ -392,31 +389,31 @@ def decode(obj):
     if typ is None:
         return obj
     elif typ == 'timestamp':
-        return Timestamp(obj['value'],tz=obj['tz'],offset=obj['offset'])
+        return Timestamp(obj['value'], tz=obj['tz'], offset=obj['offset'])
     elif typ == 'period':
-        return Period(ordinal=obj['ordinal'],freq=obj['freq'])
+        return Period(ordinal=obj['ordinal'], freq=obj['freq'])
     elif typ == 'index':
         dtype = dtype_for(obj['dtype'])
         data = obj['data']
-        return globals()[obj['klass']](data,dtype=dtype,name=obj['name'])
+        return globals()[obj['klass']](data, dtype=dtype, name=obj['name'])
     elif typ == 'multi_index':
-        return globals()[obj['klass']].from_tuples(obj['data'],names=obj['names'])
+        return globals()[obj['klass']].from_tuples(obj['data'], names=obj['names'])
     elif typ == 'period_index':
-        return globals()[obj['klass']](obj['data'],name=obj['name'],freq=obj['freq'])
+        return globals()[obj['klass']](obj['data'], name=obj['name'], freq=obj['freq'])
     elif typ == 'datetime_index':
-        return globals()[obj['klass']](obj['data'],freq=obj['freq'],tz=obj['tz'],name=obj['name'])
+        return globals()[obj['klass']](obj['data'], freq=obj['freq'], tz=obj['tz'], name=obj['name'])
     elif typ == 'series':
         dtype = dtype_for(obj['dtype'])
         index = obj['index']
-        return globals()[obj['klass']](unconvert(obj['data'],dtype,obj['compress']),index=index,name=obj['name'])
+        return globals()[obj['klass']](unconvert(obj['data'], dtype, obj['compress']), index=index, name=obj['name'])
     elif typ == 'block_manager':
         axes = obj['axes']
 
         def create_block(b):
             dtype = dtype_for(b['dtype'])
-            return make_block(unconvert(b['values'],dtype,b['compress']).reshape(b['shape']),b['items'],axes[0],klass=getattr(internals,b['klass']))
+            return make_block(unconvert(b['values'], dtype, b['compress']).reshape(b['shape']), b['items'], axes[0], klass=getattr(internals, b['klass']))
 
-        blocks = [ create_block(b) for b in obj['blocks'] ]
+        blocks = [create_block(b) for b in obj['blocks']]
         return globals()[obj['klass']](BlockManager(blocks, axes))
     elif typ == 'datetime':
         return parse(obj['data'])
@@ -430,20 +427,21 @@ def decode(obj):
         return np.timedelta64(int(obj['data']))
     elif typ == 'sparse_series':
         dtype = dtype_for(obj['dtype'])
-        return globals()[obj['klass']](unconvert(obj['sp_values'],dtype,obj['compress']),sparse_index=obj['sp_index'],
-                                       index=obj['index'],fill_value=obj['fill_value'],kind=obj['kind'],name=obj['name'])
+        return globals(
+        )[obj['klass']](unconvert(obj['sp_values'], dtype, obj['compress']), sparse_index=obj['sp_index'],
+                        index=obj['index'], fill_value=obj['fill_value'], kind=obj['kind'], name=obj['name'])
     elif typ == 'sparse_dataframe':
         return globals()[obj['klass']](obj['data'],
-                                       columns=obj['columns'],default_fill_value=obj['default_fill_value'],default_kind=obj['default_kind'])
+                                       columns=obj['columns'], default_fill_value=obj['default_fill_value'], default_kind=obj['default_kind'])
     elif typ == 'sparse_panel':
         return globals()[obj['klass']](obj['data'],
-                                       items=obj['items'],default_fill_value=obj['default_fill_value'],default_kind=obj['default_kind'])
+                                       items=obj['items'], default_fill_value=obj['default_fill_value'], default_kind=obj['default_kind'])
     elif typ == 'block_index':
-        return globals()[obj['klass']](obj['length'],obj['blocs'],obj['blengths'])
+        return globals()[obj['klass']](obj['length'], obj['blocs'], obj['blengths'])
     elif typ == 'int_index':
-        return globals()[obj['klass']](obj['length'],obj['indices'])
+        return globals()[obj['klass']](obj['length'], obj['indices'])
     elif typ == 'ndarray':
-        return unconvert(obj['data'],np.typeDict[obj['dtype']],obj.get('compress')).reshape(obj['shape'])
+        return unconvert(obj['data'], np.typeDict[obj['dtype']], obj.get('compress')).reshape(obj['shape'])
     elif typ == 'np_scalar':
         if obj.get('sub_typ') == 'np_complex':
             return c2f(obj['real'], obj['imag'], obj['dtype'])
@@ -454,12 +452,13 @@ def decode(obj):
             except:
                 return dtype.type(obj['data'])
     elif typ == 'np_complex':
-        return complex(obj['real']+'+'+obj['imag']+'j')
-    elif isinstance(obj, (dict,list,set)):
+        return complex(obj['real'] + '+' + obj['imag'] + 'j')
+    elif isinstance(obj, (dict, list, set)):
         return obj
     else:
         return obj
 
+
 def pack(o, default=encode,
          encoding='utf-8', unicode_errors='strict', use_single_float=False):
     """
@@ -467,8 +466,9 @@ def pack(o, default=encode,
     """
 
     return Packer(default=default, encoding=encoding,
-           unicode_errors=unicode_errors,
-           use_single_float=use_single_float).pack(o)
+                  unicode_errors=unicode_errors,
+                  use_single_float=use_single_float).pack(o)
+
 
 def unpack(packed, object_hook=decode,
            list_hook=None, use_list=False, encoding='utf-8',
@@ -484,7 +484,9 @@ def unpack(packed, object_hook=decode,
                     unicode_errors=unicode_errors,
                     object_pairs_hook=object_pairs_hook)
 
+
 class Packer(_Packer):
+
     def __init__(self, default=encode,
                  encoding='utf-8',
                  unicode_errors='strict',
@@ -494,7 +496,9 @@ class Packer(_Packer):
                                      unicode_errors=unicode_errors,
                                      use_single_float=use_single_float)
 
+
 class Unpacker(_Unpacker):
+
     def __init__(self, file_like=None, read_size=0, use_list=False,
                  object_hook=decode,
                  object_pairs_hook=None, list_hook=None, encoding='utf-8',
@@ -509,7 +513,9 @@ class Unpacker(_Unpacker):
                                        unicode_errors=unicode_errors,
                                        max_buffer_size=max_buffer_size)
 
+
 class Iterator(object):
+
     """ manage the unpacking iteration,
         close the file on completion """
 
@@ -520,7 +526,7 @@ class Iterator(object):
     def __iter__(self):
 
         try:
-            fh   = open(self.path,'rb')
+            fh = open(self.path, 'rb')
             unpacker = unpack(fh)
             for o in unpacker:
                 yield o
diff --git a/pandas/io/tests/test_packers.py b/pandas/io/tests/test_packers.py
index f8325ef6d..79b421ff7 100644
--- a/pandas/io/tests/test_packers.py
+++ b/pandas/io/tests/test_packers.py
@@ -1,8 +1,5 @@
 import nose
 import unittest
-import os
-import sys
-import warnings
 
 import datetime
 import numpy as np
@@ -20,30 +17,31 @@ from pandas.tests.test_panel import assert_panel_equal
 
 import pandas
 from pandas.sparse.tests.test_sparse import assert_sp_series_equal, assert_sp_frame_equal
-from pandas import concat, Timestamp, tslib
+from pandas import Timestamp, tslib
 
-from numpy.testing.decorators import slow
 nan = np.nan
 
 from pandas.io.packers import to_msgpack, read_msgpack
 
 _multiprocess_can_split_ = False
 
+
 def check_arbitrary(a, b):
 
-    if isinstance(a,(list,tuple)) and isinstance(b,(list,tuple)):
+    if isinstance(a, (list, tuple)) and isinstance(b, (list, tuple)):
         assert(len(a) == len(b))
-        for a_, b_ in zip(a,b):
-            check_arbitrary(a_,b_)
-    elif isinstance(a,Panel):
-        assert_panel_equal(a,b)
-    elif isinstance(a,DataFrame):
-        assert_frame_equal(a,b)
-    elif isinstance(a,Series):
-        assert_series_equal(a,b)
+        for a_, b_ in zip(a, b):
+            check_arbitrary(a_, b_)
+    elif isinstance(a, Panel):
+        assert_panel_equal(a, b)
+    elif isinstance(a, DataFrame):
+        assert_frame_equal(a, b)
+    elif isinstance(a, Series):
+        assert_series_equal(a, b)
     else:
         assert(a == b)
 
+
 class Test(unittest.TestCase):
 
     def setUp(self):
@@ -54,125 +52,133 @@ class Test(unittest.TestCase):
 
     def encode_decode(self, x, **kwargs):
         with ensure_clean(self.path) as p:
-            to_msgpack(p,x,**kwargs)
-            return read_msgpack(p,**kwargs)
+            to_msgpack(p, x, **kwargs)
+            return read_msgpack(p, **kwargs)
+
 
 class TestNumpy(Test):
 
     def test_numpy_scalar_float(self):
         x = np.float32(np.random.rand())
         x_rec = self.encode_decode(x)
-        self.assert_(np.allclose(x,x_rec) and type(x) == type(x_rec))
+        self.assert_(np.allclose(x, x_rec) and type(x) == type(x_rec))
 
     def test_numpy_scalar_complex(self):
-        x = np.complex64(np.random.rand()+1j*np.random.rand())
+        x = np.complex64(np.random.rand() + 1j * np.random.rand())
         x_rec = self.encode_decode(x)
-        self.assert_(np.allclose(x,x_rec) and type(x) == type(x_rec))
+        self.assert_(np.allclose(x, x_rec) and type(x) == type(x_rec))
 
     def test_scalar_float(self):
         x = np.random.rand()
         x_rec = self.encode_decode(x)
-        self.assert_(np.allclose(x,x_rec) and type(x) == type(x_rec))
+        self.assert_(np.allclose(x, x_rec) and type(x) == type(x_rec))
 
     def test_scalar_complex(self):
-        x = np.random.rand()+1j*np.random.rand()
+        x = np.random.rand() + 1j * np.random.rand()
         x_rec = self.encode_decode(x)
-        self.assert_(np.allclose(x,x_rec) and type(x) == type(x_rec))
+        self.assert_(np.allclose(x, x_rec) and type(x) == type(x_rec))
 
     def test_list_numpy_float(self):
         raise nose.SkipTest('buggy test')
         x = [np.float32(np.random.rand()) for i in range(5)]
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y:
-                             x == y, x, x_rec)) and \
-                       all(map(lambda x,y: type(x) == type(y), x, x_rec)))
+        self.assert_(all(map(lambda x, y:
+                             x == y, x, x_rec)) and
+                     all(map(lambda x, y: type(x) == type(y), x, x_rec)))
 
     def test_list_numpy_float_complex(self):
-        if not hasattr(np,'complex128'):
+        if not hasattr(np, 'complex128'):
             raise nose.SkipTest('numpy cant handle complex128')
 
         # buggy test
         raise nose.SkipTest('buggy test')
         x = [np.float32(np.random.rand()) for i in range(5)] + \
-          [np.complex128(np.random.rand()+1j*np.random.rand()) for i in range(5)]
+            [np.complex128(np.random.rand() + 1j * np.random.rand())
+             for i in range(5)]
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                       all(map(lambda x,y: type(x) == type(y), x, x_rec)))
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     all(map(lambda x, y: type(x) == type(y), x, x_rec)))
 
     def test_list_float(self):
         x = [np.random.rand() for i in range(5)]
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                       all(map(lambda x,y: type(x) == type(y), x, x_rec)))
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     all(map(lambda x, y: type(x) == type(y), x, x_rec)))
 
     def test_list_float_complex(self):
         x = [np.random.rand() for i in range(5)] + \
-          [(np.random.rand()+1j*np.random.rand()) for i in range(5)]
+            [(np.random.rand() + 1j * np.random.rand()) for i in range(5)]
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                       all(map(lambda x,y: type(x) == type(y), x, x_rec)))
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     all(map(lambda x, y: type(x) == type(y), x, x_rec)))
 
     def test_dict_float(self):
         x = {'foo': 1.0, 'bar': 2.0}
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x.values(), x_rec.values())) and \
-                       all(map(lambda x,y: type(x) == type(y), x.values(), x_rec.values())))
+        self.assert_(all(map(lambda x, y: x == y, x.values(), x_rec.values())) and
+                     all(map(lambda x, y: type(x) == type(y), x.values(), x_rec.values())))
 
     def test_dict_complex(self):
-        x = {'foo': 1.0+1.0j, 'bar': 2.0+2.0j}
+        x = {'foo': 1.0 + 1.0j, 'bar': 2.0 + 2.0j}
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x.values(), x_rec.values())) and \
-                       all(map(lambda x,y: type(x) == type(y), x.values(), x_rec.values())))
+        self.assert_(all(map(lambda x, y: x == y, x.values(), x_rec.values())) and
+                     all(map(lambda x, y: type(x) == type(y), x.values(), x_rec.values())))
 
     def test_dict_numpy_float(self):
         x = {'foo': np.float32(1.0), 'bar': np.float32(2.0)}
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x.values(), x_rec.values())) and \
-                       all(map(lambda x,y: type(x) == type(y), x.values(), x_rec.values())))
+        self.assert_(all(map(lambda x, y: x == y, x.values(), x_rec.values())) and
+                     all(map(lambda x, y: type(x) == type(y), x.values(), x_rec.values())))
 
     def test_dict_numpy_complex(self):
-        x = {'foo': np.complex128(1.0+1.0j), 'bar': np.complex128(2.0+2.0j)}
+        x = {'foo': np.complex128(
+            1.0 + 1.0j), 'bar': np.complex128(2.0 + 2.0j)}
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x.values(), x_rec.values())) and \
-                       all(map(lambda x,y: type(x) == type(y), x.values(), x_rec.values())))
+        self.assert_(all(map(lambda x, y: x == y, x.values(), x_rec.values())) and
+                     all(map(lambda x, y: type(x) == type(y), x.values(), x_rec.values())))
 
     def test_numpy_array_float(self):
         x = np.random.rand(5).astype(np.float32)
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                                     x.dtype == x_rec.dtype)
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     x.dtype == x_rec.dtype)
+
     def test_numpy_array_complex(self):
-        x = (np.random.rand(5)+1j*np.random.rand(5)).astype(np.complex128)
+        x = (np.random.rand(5) + 1j * np.random.rand(5)).astype(np.complex128)
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                       x.dtype == x_rec.dtype)
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     x.dtype == x_rec.dtype)
 
     def test_list_mixed(self):
         x = [1.0, np.float32(3.5), np.complex128(4.25), u('foo')]
         x_rec = self.encode_decode(x)
-        self.assert_(all(map(lambda x,y: x == y, x, x_rec)) and \
-                           all(map(lambda x,y: type(x) == type(y), x, x_rec)))
+        self.assert_(all(map(lambda x, y: x == y, x, x_rec)) and
+                     all(map(lambda x, y: type(x) == type(y), x, x_rec)))
+
+
 class TestBasic(Test):
 
     def test_timestamp(self):
 
-        for i in [ Timestamp('20130101'), Timestamp('20130101',tz='US/Eastern'),
-                   Timestamp('201301010501') ]:
+        for i in [Timestamp(
+            '20130101'), Timestamp('20130101', tz='US/Eastern'),
+                Timestamp('201301010501')]:
             i_rec = self.encode_decode(i)
             self.assert_(i == i_rec)
 
     def test_datetimes(self):
 
-        for i in [ datetime.datetime(2013,1,1), datetime.datetime(2013,1,1,5,1),
-                   datetime.date(2013,1,1), np.datetime64(datetime.datetime(2013,1,5,2,15)) ]:
+        for i in [datetime.datetime(
+            2013, 1, 1), datetime.datetime(2013, 1, 1, 5, 1),
+                datetime.date(2013, 1, 1), np.datetime64(datetime.datetime(2013, 1, 5, 2, 15))]:
             i_rec = self.encode_decode(i)
             self.assert_(i == i_rec)
 
     def test_timedeltas(self):
 
-        for i in [ datetime.timedelta(days=1),
-                   datetime.timedelta(days=1,seconds=10),
-                   np.timedelta64(1000000) ]:
+        for i in [datetime.timedelta(days=1),
+                  datetime.timedelta(days=1, seconds=10),
+                  np.timedelta64(1000000)]:
             i_rec = self.encode_decode(i)
             self.assert_(i == i_rec)
 
@@ -183,21 +189,21 @@ class TestIndex(Test):
         super(TestIndex, self).setUp()
 
         self.d = {
-            'string' : tm.makeStringIndex(100),
-            'date'   : tm.makeDateIndex(100),
-            'int'    : tm.makeIntIndex(100),
-            'float'  : tm.makeFloatIndex(100),
-            'empty'  : Index([]),
-            'tuple'   : Index(zip(['foo', 'bar', 'baz'], [1, 2, 3])),
-            'period'  : Index(period_range('2012-1-1', freq='M', periods=3)),
-            'date2'   : Index(date_range('2013-01-1', periods=10)),
-            'bdate'   : Index(bdate_range('2013-01-02',periods=10)),
-            }
+            'string': tm.makeStringIndex(100),
+            'date': tm.makeDateIndex(100),
+            'int': tm.makeIntIndex(100),
+            'float': tm.makeFloatIndex(100),
+            'empty': Index([]),
+            'tuple': Index(zip(['foo', 'bar', 'baz'], [1, 2, 3])),
+            'period': Index(period_range('2012-1-1', freq='M', periods=3)),
+            'date2': Index(date_range('2013-01-1', periods=10)),
+            'bdate': Index(bdate_range('2013-01-02', periods=10)),
+        }
 
         self.mi = {
-            'reg' : MultiIndex.from_tuples([('bar', 'one'), ('baz', 'two'), ('foo', 'two'),
-                                            ('qux', 'one'), ('qux', 'two')], names=['first','second']),
-            }
+            'reg': MultiIndex.from_tuples([('bar', 'one'), ('baz', 'two'), ('foo', 'two'),
+                                           ('qux', 'one'), ('qux', 'two')], names=['first', 'second']),
+        }
 
     def test_basic_index(self):
 
@@ -216,6 +222,7 @@ class TestIndex(Test):
         i_rec = self.encode_decode(i)
         self.assert_(i.equals(i_rec))
 
+
 class TestSeries(Test):
 
     def setUp(self):
@@ -223,7 +230,6 @@ class TestSeries(Test):
 
         self.d = {}
 
-
         s = tm.makeStringSeries()
         s.name = 'string'
         self.d['string'] = s
@@ -240,18 +246,19 @@ class TestSeries(Test):
             'B': [0, 1, 0, 1, 0],
             'C': ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],
             'D': date_range('1/1/2009', periods=5),
-            'E' : [0., 1, Timestamp('20100101'),'foo',2.],
-            }
+            'E': [0., 1, Timestamp('20100101'), 'foo', 2.],
+        }
 
         self.d['float'] = Series(data['A'])
-        self.d['int']   = Series(data['B'])
+        self.d['int'] = Series(data['B'])
         self.d['mixed'] = Series(data['E'])
 
     def test_basic(self):
 
         for s, i in self.d.items():
             i_rec = self.encode_decode(i)
-            assert_series_equal(i,i_rec)
+            assert_series_equal(i, i_rec)
+
 
 class TestNDFrame(Test):
 
@@ -263,58 +270,64 @@ class TestNDFrame(Test):
             'B': [0, 1, 0, 1, 0],
             'C': ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],
             'D': date_range('1/1/2009', periods=5),
-            'E' : [0., 1, Timestamp('20100101'),'foo',2.],
-            }
+            'E': [0., 1, Timestamp('20100101'), 'foo', 2.],
+        }
 
-        self.frame = { 'float' : DataFrame(dict(A = data['A'], B = Series(data['A']) + 1)),
-                       'int'   : DataFrame(dict(A = data['B'], B = Series(data['B']) + 1)),
-                       'mixed' : DataFrame(dict([ (k,data[k]) for k in ['A','B','C','D']])) }
+        self.frame = {
+            'float': DataFrame(dict(A=data['A'], B=Series(data['A']) + 1)),
+            'int': DataFrame(dict(A=data['B'], B=Series(data['B']) + 1)),
+            'mixed': DataFrame(dict([(k, data[k]) for k in ['A', 'B', 'C', 'D']]))}
 
-        self.panel = { 'float' : Panel(dict(ItemA = self.frame['float'], ItemB = self.frame['float']+1)) }
+        self.panel = {
+            'float': Panel(dict(ItemA=self.frame['float'], ItemB=self.frame['float'] + 1))}
 
     def test_basic_frame(self):
 
         for s, i in self.frame.items():
             i_rec = self.encode_decode(i)
-            assert_frame_equal(i,i_rec)
+            assert_frame_equal(i, i_rec)
 
     def test_basic_panel(self):
 
         for s, i in self.panel.items():
             i_rec = self.encode_decode(i)
-            assert_panel_equal(i,i_rec)
+            assert_panel_equal(i, i_rec)
 
     def test_multi(self):
 
         i_rec = self.encode_decode(self.frame)
         for k in self.frame.keys():
-            assert_frame_equal(self.frame[k],i_rec[k])
+            assert_frame_equal(self.frame[k], i_rec[k])
 
-        l = tuple([ self.frame['float'], self.frame['float'].A, self.frame['float'].B, None ])
+        l = tuple(
+            [self.frame['float'], self.frame['float'].A, self.frame['float'].B, None])
         l_rec = self.encode_decode(l)
-        check_arbitrary(l,l_rec)
+        check_arbitrary(l, l_rec)
 
         # this is an oddity in that packed lists will be returned as tuples
-        l = [ self.frame['float'], self.frame['float'].A, self.frame['float'].B, None ]
+        l = [self.frame['float'], self.frame['float']
+             .A, self.frame['float'].B, None]
         l_rec = self.encode_decode(l)
-        self.assert_(isinstance(l_rec,tuple))
-        check_arbitrary(l,l_rec)
+        self.assert_(isinstance(l_rec, tuple))
+        check_arbitrary(l, l_rec)
 
     def test_iterator(self):
 
-        l = [ self.frame['float'], self.frame['float'].A, self.frame['float'].B, None ]
+        l = [self.frame['float'], self.frame['float']
+             .A, self.frame['float'].B, None]
 
         with ensure_clean(self.path) as path:
-            to_msgpack(path,*l)
+            to_msgpack(path, *l)
             for i, packed in enumerate(read_msgpack(path, iterator=True)):
-                check_arbitrary(packed,l[i])
+                check_arbitrary(packed, l[i])
+
 
 class TestSparse(Test):
 
     def _check_roundtrip(self, obj, comparator, **kwargs):
 
         i_rec = self.encode_decode(obj)
-        comparator(obj,i_rec,**kwargs)
+        comparator(obj, i_rec, **kwargs)
 
     def test_sparse_series(self):
 
diff --git a/pandas/msgpack.pyx b/pandas/msgpack.pyx
index 7af31e2b8..2c8d7fd01 100644
--- a/pandas/msgpack.pyx
+++ b/pandas/msgpack.pyx
@@ -17,7 +17,7 @@ import cython
 import numpy as np
 from numpy cimport *
 
-class UnpackException(Exception):
+class UnpackException(IOError):
     pass
 
 
@@ -41,7 +41,7 @@ class ExtraData(ValueError):
     def __str__(self):
         return "unpack(b) recieved extra data."
 
-class PackException(Exception):
+class PackException(IOError):
     pass
 
 class PackValueError(PackException, ValueError):
@@ -354,9 +354,9 @@ cdef class Packer(object):
 
     cdef inline pack_pair(self, object k, object v, int nest_limit):
         ret = self._pack(k, nest_limit-1)
-        if ret != 0: raise Exception("cannot pack : %s" % k)
+        if ret != 0: raise PackException("cannot pack : %s" % k)
         ret = self._pack(v, nest_limit-1)
-        if ret != 0: raise Exception("cannot pack : %s" % v)
+        if ret != 0: raise PackException("cannot pack : %s" % v)
         return ret
 
 def pack(object o, object stream, default=None, encoding='utf-8', unicode_errors='strict'):
@@ -569,7 +569,7 @@ cdef class Unpacker(object):
         cdef char* buf
         cdef Py_ssize_t buf_len
         if self.file_like is not None:
-            raise AssertionError(
+            raise TypeError(
                     "unpacker.feed() is not be able to use with `file_like`.")
         PyObject_AsReadBuffer(next_bytes, <const_void_ptr*>&buf, &buf_len)
         self.append_buffer(buf, buf_len)
