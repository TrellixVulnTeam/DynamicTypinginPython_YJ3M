commit c7625ec5059d7f9b8fd8ca058c4ad7554832e996
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Aug 24 00:39:18 2011 -0400

    DOC: DataFrame docs, sort unit tests, other cleanup. deprecated tgroupby

diff --git a/RELEASE.rst b/RELEASE.rst
index 3484e00aa..75d5c4d8f 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -168,7 +168,7 @@ Release notes
 * Added deprecation warning to `DataFrame.cols()`, to be removed in next release
 * `DataFrame` deprecations and de-camelCasing: `merge`, `asMatrix`,
   `toDataMatrix`, `_firstTimeWithValue`, `_lastTimeWithValue`, `toRecords`,
-  `fromRecords`
+  `fromRecords`, `tgroupby`
 * `pandas.io.parsers` method deprecations
   * `parseCSV` is now `read_csv` and keyword arguments have been de-camelCased
   * `parseText` is now `read_table`
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 4014c183e..2dd5b9863 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -29,6 +29,7 @@ from pandas.core.index import Index, MultiIndex, NULL_INDEX
 from pandas.core.indexing import _DataFrameIndexer, _maybe_droplevels
 from pandas.core.internals import BlockManager, make_block, form_blocks
 from pandas.core.series import Series, _is_bool_indexer
+from pandas.util.decorators import deprecate
 import pandas.core.common as common
 import pandas.core.datetools as datetools
 import pandas._tseries as _tseries
@@ -37,7 +38,8 @@ import pandas._tseries as _tseries
 # Factory helper methods
 
 _arith_doc = """
-Arithmetic method: %s
+Binary operator %s with support to substitute a fill_value for missing data in
+one of the inputs
 
 Parameters
 ----------
@@ -99,28 +101,32 @@ def comp_method(func, name):
 
 class DataFrame(NDFrame):
     """
-    Homogenously indexed table with named columns, with intelligent arithmetic
-    operations, slicing, reindexing, aggregation, etc. Can function
-    interchangeably as a dictionary.
+    Two-dimensional size-mutable, potentially heterogeneous tabular data
+    structure with labeled axes (rows and columns). Arithmetic operations align
+    on both row and column labels. Can be thought of as a dict-like container
+    for Series objects. The primary pandas data structure
 
     Parameters
     ----------
-    data : numpy ndarray or dict of sequence-like objects
-        Dict can contain Series, arrays, or list-like objects
-        Constructor can understand various kinds of inputs
+    data : numpy ndarray (structured or homogeneous), dict, or DataFrame
+        Dict can contain Series, arrays, constants, or list-like objects
     index : Index or array-like
-        Index to use for resulting frame (optional if provided dict of Series)
+        Index to use for resulting frame. Will default to np.arange(n) if no
+        indexing information part of input data and no index provided
     columns : Index or array-like
-        Required if data is ndarray
-    dtype : dtype, default None (infer)
-        Data type to force
+        Will default to np.arange(n) if not column labels provided
+    dtype : dtype, default None
+        Data type to force, otherwise infer
     copy : boolean, default False
         Copy data from inputs. Only affects DataFrame / 2d ndarray input
 
     Examples
     --------
-        >>> d = {'col1' : ts1, 'col2' : ts2}
-        >>> df = DataFrame(data=d, index=someIndex)
+    >>> d = {'col1' : ts1, 'col2' : ts2}
+    >>> df = DataFrame(data=d, index=index)
+    >>> df2 = DataFrame(np.random.randn(10, 5))
+    >>> df3 = DataFrame(np.random.randn(10, 5),
+                        columns=['a', 'b', 'c', 'd', 'e'])
     """
     _auto_consolidate = True
 
@@ -278,21 +284,15 @@ class DataFrame(NDFrame):
         return ((k, series[k]) for k in self.columns)
 
     def __len__(self):
-        """
-        Returns number of columns/Series inside
-        """
+        """Returns length of index"""
         return len(self.index)
 
     def __contains__(self, key):
-        """
-        True if DataFrame has this column
-        """
+        """True if DataFrame has this column"""
         return key in self.columns
 
     def copy(self):
-        """
-        Make a copy of this DataFrame
-        """
+        """Make a deep copy of this DataFrame"""
         return self._constructor(self._data.copy())
 
     #----------------------------------------------------------------------
@@ -328,9 +328,7 @@ class DataFrame(NDFrame):
     def __neg__(self):
         return self * -1
 
-    #----------------------------------------------------------------------
     # Comparison methods
-
     __eq__ = comp_method(operator.eq, '__eq__')
     __ne__ = comp_method(operator.ne, '__ne__')
     __lt__ = comp_method(operator.lt, '__lt__')
@@ -343,43 +341,59 @@ class DataFrame(NDFrame):
 
     def to_dict(self):
         """
-        Convert DataFrame to nested dictionary (non-pandas)
+        Convert DataFrame to nested dictionary
 
         Return
         ------
-        nested dict mapping: {column -> index -> value}
+        result : dict like {column -> {index -> value}}
         """
         return dict((k, v.to_dict()) for k, v in self.iteritems())
 
     @classmethod
-    def from_records(cls, data, indexField=None):
+    def from_records(cls, data, index=None, indexField=None):
         """
         Convert structured or record ndarray to DataFrame
 
         Parameters
         ----------
-        input : NumPy structured array
+        data : NumPy structured array
+        index : string or array-like
+            Field of array to use as the index, alternately a specific set of
+            input labels to use
 
         Returns
         -------
-        DataFrame
+        df : DataFrame
         """
         if not data.dtype.names:
             raise Exception('Input was not a structured array!')
 
-        columns, sdict = _rec_to_dict(data)
         if indexField is not None:
-            index = sdict.pop(indexField)
-            columns.remove(indexField)
+            warnings.warn("indexField argument is deprecated. Use index "
+                          "instead", FutureWarning)
+            index = indexField
+
+        columns, sdict = _rec_to_dict(data)
+        if index is not None:
+            if isinstance(index, basestring):
+                result_index = sdict.pop(index)
+                columns.remove(index)
+            else:
+                result_index = index
         else:
-            index = np.arange(len(data))
+            result_index = np.arange(len(data))
 
-        return cls(sdict, index=index, columns=columns)
+        return cls(sdict, index=result_index, columns=columns)
 
     def to_records(self, index=True):
         """
         Convert DataFrame to record array. Index will be put in the
-        'index' field of the record array.
+        'index' field of the record array if requested
+
+        Parameters
+        ----------
+        index : boolean, default True
+            Include index in resulting record array, stored in 'index' field
 
         Returns
         -------
@@ -405,14 +419,13 @@ class DataFrame(NDFrame):
         header : int, default 0
             Row to use at header (skip prior rows)
         delimiter : string, default ','
-        index_col : int
+        index_col : int, default 0
             Column to use for index
 
         Notes
         -----
         Will attempt to convert index to datetimes for time series
-        data. Uses numpy.genfromtxt to do the actual parsing into
-        ndarray
+        data. Use read_csv for more options
 
         Returns
         -------
@@ -441,10 +454,10 @@ class DataFrame(NDFrame):
                                default_kind=kind,
                                default_fill_value=fill_value)
 
-    def toCSV(self, path, nanRep='', cols=None, header=True,
+    def to_csv(self, path, nanRep='', cols=None, header=True,
               index=True, mode='wb'):
         """
-        Write the DataFrame to a CSV file
+        Write DataFrame to a comma-separated values (csv) file
 
         Parameters
         ----------
@@ -457,6 +470,7 @@ class DataFrame(NDFrame):
             Write out column names
         index : boolean, default True
             Write row names (index)
+        mode : Python write mode, default 'wb'
         """
         f = open(path, mode)
 
@@ -564,6 +578,12 @@ class DataFrame(NDFrame):
     def info(self, verbose=True, buf=sys.stdout):
         """
         Concise summary of a DataFrame, used in __repr__ when very large.
+
+        Parameters
+        ----------
+        verbose : boolean, default True
+            If False, don't print column count summary
+        buf : writable buffer, defaults to sys.stdout
         """
         print >> buf, str(type(self))
         print >> buf, self.index.summary()
@@ -623,10 +643,20 @@ class DataFrame(NDFrame):
 
     def as_matrix(self, columns=None):
         """
-        Convert the frame to its Numpy-array matrix representation
+        Convert the frame to its Numpy-array matrix representation. Columns
+        are presented in sorted order unless a specific list of columns is
+        provided.
 
-        Columns are presented in sorted order unless a specific list
-        of columns is provided.
+        Parameters
+        ----------
+        columns : array-like
+            Specific column order
+
+        Returns
+        -------
+        values : ndarray
+            If the DataFrame is heterogeneous and contains booleans or objects,
+            the result will be of dtype=object
         """
         self._consolidate_inplace()
         return self._data.as_matrix(columns).T
@@ -635,8 +665,8 @@ class DataFrame(NDFrame):
 
     def transpose(self):
         """
-        Returns a DataFrame with the rows/columns switched. Copy of data is not
-        made by default
+        Returns a DataFrame with the rows/columns switched. If the DataFrame is
+        homogeneously-typed, the data is not copied
         """
         return self._constructor(data=self.values.T, index=self.columns,
                                  columns=self.index, copy=False)
@@ -659,6 +689,7 @@ class DataFrame(NDFrame):
             self._unpickle_matrix_compat(state)
         self._series_cache = {}
 
+    # legacy pickle formats
     def _unpickle_frame_compat(self, state):  # pragma: no cover
         from pandas.core.common import _unpickle_array
         if len(state) == 2:  # pragma: no cover
@@ -723,29 +754,11 @@ class DataFrame(NDFrame):
     # getitem/setitem related
 
     def __getitem__(self, key):
-        """
-        Retrieve column, slice, or subset from DataFrame.
-
-        Possible inputs
-        ---------------
-        single value : retrieve a column as a Series
-        slice : reindex to indices specified by slice
-        boolean vector : like slice but more general, reindex to indices
-          where the input vector is True
-
-        Examples
-        --------
-        column = dm['A']
-        dmSlice = dm[:20] # First 20 rows
-        dmSelect = dm[dm.count(axis=1) > 10]
-
-        Notes
-        -----
-        This is a magic method. Do NOT call explicity.
-        """
+        # slice rows
         if isinstance(key, slice):
             new_data = self._data.get_slice(key, axis=1)
             return self._constructor(new_data)
+        # either boolean or fancy integer index
         elif isinstance(key, np.ndarray):
             if len(key) != len(self.index):
                 raise ValueError('Item wrong length %d instead of %d!' %
@@ -794,16 +807,8 @@ class DataFrame(NDFrame):
         return res
 
     def __setitem__(self, key, value):
-        """
-        Add series to DataFrame in specified column.
-
-        If series is a numpy-array (not a Series/TimeSeries), it must be the
-        same length as the DataFrame's index or an error will be thrown.
-
-        Series/TimeSeries will be conformed to the DataFrame's index to
-        ensure homogeneity.
-        """
-        # Array
+        # support boolean setting with DataFrame input, e.g.
+        # df[df > df2] = 0
         if isinstance(key, DataFrame):
             if not (key.index.equals(self.index) and
                     key.columns.equals(self.columns)):
@@ -812,6 +817,7 @@ class DataFrame(NDFrame):
 
             self._boolean_set(key, value)
         else:
+            # set column
             self._set_item(key, value)
 
     def _boolean_set(self, key, value):
@@ -896,12 +902,11 @@ class DataFrame(NDFrame):
 
     def pop(self, item):
         """
-        Return column and drop from frame. Raise KeyError if not
-        found.
+        Return column and drop from frame. Raise KeyError if not found.
 
         Returns
         -------
-        Series
+        column : Series
         """
         result = self[item]
         del self[item]
@@ -914,19 +919,17 @@ class DataFrame(NDFrame):
 
     def xs(self, key, copy=True):
         """
-        Returns a row from the DataFrame as a Series object.
+        Returns a row (cross-section) from the DataFrame as a Series object
 
         Parameters
         ----------
-        key : some index contained in the index
+        key : object
+            Some label contained in the index, or partially in a MultiIndex
 
         Returns
         -------
         xs : Series
         """
-        # if key not in self.index:
-        #     raise Exception('No cross-section for %s' % key)
-
         self._consolidate_inplace()
         new_data = self._data.xs(key, axis=1, copy=copy)
         if new_data.ndim == 1:
@@ -940,25 +943,32 @@ class DataFrame(NDFrame):
     # Reindexing
 
     def reindex(self, index=None, columns=None, method=None, copy=True):
-        """
-        Reindex data inside, optionally filling according to some rule.
+        """Conform Series to new index with optional filling logic, placing
+        NA/NaN in locations having no value in the previous index. A new object
+        is produced unless the new index is equivalent to the current one and
+        copy=False
 
         Parameters
         ----------
         index : array-like, optional
-            preferably an Index object (to avoid duplicating data)
+            New labels / index to conform to. Preferably an Index object to
+            avoid duplicating data
         columns : array-like, optional
+            Same usage as index argument
         method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None
-            Method to use for filling holes in reindexed Series
-
+            Method to use for filling holes in reindexed DataFrame
             pad / ffill: propagate last valid observation forward to next valid
             backfill / bfill: use NEXT valid observation to fill gap
         copy : boolean, default True
             Return a new object, even if the passed indexes are the same
 
+        Examples
+        --------
+        >>> df.reindex(index=[date1, date2, date3], columns=['A', 'B', 'C'])
+
         Returns
         -------
-        y : same type as calling instance
+        reindexed : same type as calling instance
         """
         self._consolidate_inplace()
         frame = self
@@ -993,7 +1003,8 @@ class DataFrame(NDFrame):
 
     def reindex_like(self, other, method=None, copy=True):
         """
-        Reindex DataFrame to match indices of another DataFrame
+        Reindex DataFrame to match indices of another DataFrame, optionally
+        with filling logic
 
         Parameters
         ----------
@@ -1003,13 +1014,13 @@ class DataFrame(NDFrame):
 
         Notes
         -----
-        Like calling s.reindex(index=other.index, columns=other.columns)
+        Like calling s.reindex(index=other.index, columns=other.columns,
+                               method=...)
 
         Returns
         -------
         reindexed : DataFrame
         """
-        # todo: object columns
         return self.reindex(index=other.index, columns=other.columns,
                             method=method, copy=copy)
 
@@ -1059,7 +1070,7 @@ class DataFrame(NDFrame):
 
         Notes
         -----
-        Arguments are mutually exclusive!
+        Arguments are mutually exclusive, but this is not checked for
 
         Returns
         -------
@@ -1083,13 +1094,15 @@ class DataFrame(NDFrame):
 
         Parameters
         ----------
-        axis : int
+        axis : {0, 1}
         how : {'any', 'all'}
             any : if any NA values are present, drop that label
             all : if all values are NA, drop that label
         thresh : int, default None
             int value : require that many non-NA values
         subset : array-like
+            Labels along other axis to consider, e.g. if you are dropping rows
+            these would be a list of columns to include
 
         Returns
         -------
@@ -1132,7 +1145,8 @@ class DataFrame(NDFrame):
 
     def sort(self, column=None, axis=0, ascending=True):
         """
-        Sort DataFrame either by index (default) by the values in a column
+        Sort DataFrame either by labels (along either axis) or by the values in
+        a column
 
         Parameters
         ----------
@@ -1140,23 +1154,32 @@ class DataFrame(NDFrame):
             Column name in frame
         ascending : boolean, default True
             Sort ascending vs. descending
+        axis : {0, 1}
+            Sort index/rows versus columns
 
         Returns
         -------
         sorted : DataFrame
         """
         if column:
+            assert(axis == 0)
             series = self[column].order(na_last=False)
             sort_index = series.index
         else:
-            index = np.asarray(self.index)
-            argsorted = np.argsort(index)
-            sort_index = index[argsorted.astype(int)]
+            assert(axis in (0, 1))
+            if axis == 0:
+                labels = self.index
+            else:
+                labels = self.columns
+            sort_index = labels.take(labels.argsort())
 
         if not ascending:
             sort_index = sort_index[::-1]
 
-        return self.reindex(sort_index)
+        if axis == 0:
+            return self.reindex(sort_index)
+        else:
+            return self.reindex(columns=sort_index)
 
     def sortlevel(self, level=0, axis=0, ascending=True):
         """
@@ -1167,7 +1190,7 @@ class DataFrame(NDFrame):
         Parameters
         ----------
         level : int
-        axis : int
+        axis : {0, 1}
         ascending : bool, default True
 
         Returns
@@ -1200,28 +1223,25 @@ class DataFrame(NDFrame):
 
     def fillna(self, value=None, method='pad'):
         """
-        Fill nan values using the specified method.
-
-        Member Series / TimeSeries are filled separately.
+        Fill NA/NaN values using the specified method. Member Series /
+        TimeSeries are filled separately
 
         Parameters
         ----------
         method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'
             Method to use for filling holes in reindexed Series
-
             pad / ffill: propagate last valid observation forward to next valid
             backfill / bfill: use NEXT valid observation to fill gap
-
         value : any kind (should be same type as array)
             Value to use to fill holes (e.g. 0)
 
-        Returns
-        -------
-        y : DataFrame
-
         See also
         --------
-        DataFrame.reindex, DataFrame.asfreq
+        reindex, asfreq
+
+        Returns
+        -------
+        filled : DataFrame
         """
         if value is None:
             result = {}
@@ -1244,7 +1264,8 @@ class DataFrame(NDFrame):
 
     def rename(self, index=None, columns=None):
         """
-        Alter index and / or columns using input function or functions
+        Alter index and / or columns using input function or
+        functions. Function / dict values must be unique (1-to-1)
 
         Parameters
         ----------
@@ -1257,13 +1278,9 @@ class DataFrame(NDFrame):
         --------
         Series.rename
 
-        Notes
-        -----
-        Function / dict values must be unique (1-to-1)
-
         Returns
         -------
-        y : DataFrame (new object)
+        renamed : DataFrame (new object)
         """
         if isinstance(index, (dict, Series)):
             index = index.__getitem__
@@ -1298,18 +1315,6 @@ class DataFrame(NDFrame):
     # Arithmetic / combination related
 
     def _combine_frame(self, other, func, fill_value=None):
-        """
-        Methodology, briefly
-        - Really concerned here about speed, space
-
-        - Get new index
-        - Reindex to new index
-        - Determine new_columns and commonColumns
-        - Add common columns over all (new) indices
-        - Fill to new set of columns
-
-        Could probably deal with some Cython action in here at some point
-        """
         new_index = self.index.union(other.index)
 
         # some shortcuts
@@ -1430,10 +1435,12 @@ class DataFrame(NDFrame):
         Parameters
         ----------
         other : DataFrame
+        func : function
+        fill_value : scalar value
 
         Returns
         -------
-        DataFrame
+        result : DataFrame
         """
         if not other:
             return self.copy()
@@ -1483,21 +1490,21 @@ class DataFrame(NDFrame):
 
     def combine_first(self, other):
         """
-        Combine two DataFrame objects and default to value
-        in frame calling the method.
+        Combine two DataFrame objects and default to non-null values in frame
+        calling the method. Result index will be the union of the two indexes
 
         Parameters
         ----------
-        otherFrame : DataFrame
+        other : DataFrame
 
         Examples
         --------
-        a.combine_first(b)
+        >>> a.combine_first(b)
             a's values prioritized, use values from b to fill holes
 
         Returns
         -------
-        DataFrame
+        combined : DataFrame
         """
         combiner = lambda x, y: np.where(isnull(x), y, x)
         return self.combine(other, combiner)
@@ -1506,26 +1513,36 @@ class DataFrame(NDFrame):
     # Misc methods
 
     def first_valid_index(self):
+        """
+        Return label for first non-NA/null value
+        """
         return self.index[self.count(1) > 0][0]
 
     def last_valid_index(self):
+        """
+        Return label for last non-NA/null value
+        """
         return self.index[self.count(1) > 0][-1]
 
-    def head(self):
-        return self[:5]
+    def head(self, n=5):
+        """Returns first n rows of DataFrame
+        """
+        return self[:n]
 
-    def tail(self):
-        return self[-5:]
+    def tail(self, n=5):
+        """Returns last n rows of DataFrame
+        """
+        return self[-n:]
 
     #----------------------------------------------------------------------
     # Data reshaping
 
     def pivot(self, index=None, columns=None, values=None):
         """
-        Produce 'pivot' table this DataFrame. Uses unique values from index /
-        columns to form axes and return either DataFrame or WidePanel,
-        depending on whether you request a single value column (DataFrame) or
-        all columns (WidePanel)
+        Reshape data (produce a "pivot" table) based on column values. Uses
+        unique values from index / columns to form axes and return either
+        DataFrame or WidePanel, depending on whether you request a single value
+        column (DataFrame) or all columns (WidePanel)
 
         Parameters
         ----------
@@ -1536,6 +1553,11 @@ class DataFrame(NDFrame):
         values : string or object, optional
             Column name to use for populating new frame's values
 
+        Notes
+        -----
+        For finer-tuned control, see hierarchical indexing documentation along
+        with the related stack/unstack methods
+
         Examples
         --------
         >>> df
@@ -1586,7 +1608,8 @@ class DataFrame(NDFrame):
 
     def stack(self):
         """
-        Convert DataFrame to Series with multi-level Index
+        Convert DataFrame to Series with multi-level Index. Columns become the
+        second level of the resulting hierarchical index
 
         Returns
         -------
@@ -1607,7 +1630,7 @@ class DataFrame(NDFrame):
         Parameters
         ----------
         level : int, default last level
-            Level to "unstack"
+            Level to unstack
 
         Examples
         --------
@@ -1642,7 +1665,9 @@ class DataFrame(NDFrame):
         labeling information in the columns under names 'level_0', 'level_1',
         etc.
 
-        Note: experimental, subject ot API change
+        Notes
+        -----
+        Experimental, subject to API change
 
         Returns
         -------
@@ -1666,20 +1691,21 @@ class DataFrame(NDFrame):
 
     def asfreq(self, freq, method=None):
         """
-        Convert all TimeSeries inside to specified frequency using
-        DateOffset objects. Optionally provide fill method to pad or
-        backfill missing values.
+        Convert all TimeSeries inside to specified frequency using DateOffset
+        objects. Optionally provide fill method to pad/backfill missing values.
 
         Parameters
         ----------
         offset : DateOffset object, or string in {'WEEKDAY', 'EOM'}
             DateOffset object or subclass (e.g. monthEnd)
-
         method : {'backfill', 'bfill', 'pad', 'ffill', None}
             Method to use for filling holes in reindexed Series
-
             pad / ffill: propagate last valid observation forward to next valid
             backfill / bfill: use NEXT valid observation to fill methdo
+
+        Returns
+        -------
+        converted : DataFrame
         """
         if len(self.index) == 0:
             return self.copy()
@@ -1692,17 +1718,29 @@ class DataFrame(NDFrame):
         return self.reindex(dateRange, method=method)
 
     def diff(self, periods=1):
+        """
+        1st discrete difference of object
+
+        Parameters
+        ----------
+        periods : int, default 1
+            Periods to shift for forming difference
+
+        Returns
+        -------
+        diffed : DataFrame
+        """
         return self - self.shift(periods)
 
     def shift(self, periods, offset=None, timeRule=None):
         """
-        Shift the underlying series of the DataFrame and Series objects within
-        by given number (positive or negative) of periods.
+        Shift the index of the DataFrame by desired number of periods with an
+        optional time offset
 
         Parameters
         ----------
-        periods : int (+ or -)
-            Number of periods to move
+        periods : int
+            Number of periods to move, can be positive or negative
         offset : DateOffset, optional
             Increment to use from datetools module
         timeRule : string
@@ -1710,7 +1748,7 @@ class DataFrame(NDFrame):
 
         Returns
         -------
-        DataFrame
+        shifted : DataFrame
         """
         if periods == 0:
             return self
@@ -1756,10 +1794,11 @@ class DataFrame(NDFrame):
 
     def apply(self, func, axis=0, broadcast=False):
         """
-        Applies func to columns (Series) of this DataFrame and returns either
-        a DataFrame (if the function produces another series) or a Series
-        indexed on the column names of the DataFrame if the function produces
-        a value.
+        Applies function along input axis of DataFrame. Objects passed to
+        functions are Series objects having index either the DataFrame's index
+        (axis=0) or the columns (axis=1). Returns either a DataFrame (if the
+        function produces another Series) or a Series indexed on either the
+        index or columns if the function produces an aggregated value.
 
         Parameters
         ----------
@@ -1773,11 +1812,16 @@ class DataFrame(NDFrame):
         Examples
         --------
         >>> df.apply(numpy.sqrt) --> DataFrame
-        >>> df.apply(numpy.sum) --> Series
+        >>> df.apply(numpy.sum, axis=0) # equiv to df.sum(0)
+        >>> df.apply(numpy.sum, axis=1) # equiv to df.sum(1)
 
         Notes
         -----
-        Functions altering the index are not supported (yet)
+        Functions should not alter the index of the Series passed to them
+
+        Returns
+        -------
+        applied : Series or DataFrame
         """
         if not len(self.columns):
             return self
@@ -1869,25 +1913,29 @@ class DataFrame(NDFrame):
     def applymap(self, func):
         """
         Apply a function to a DataFrame that is intended to operate
-        elementwise, i.e. like doing
-            map(func, series) for each series in the DataFrame
+        elementwise, i.e. like doing map(func, series) for each series in the
+        DataFrame
 
         Parameters
         ----------
         func : function
             Python function, returns a single value from a single value
 
-        Note : try to avoid using this function if you can, very slow.
+        Returns
+        -------
+        applied : DataFrame
         """
         npfunc = np.frompyfunc(func, 1, 1)
-        results = npfunc(self.values)
-        try:
-            results = results.astype(self.values.dtype)
-        except Exception:
-            pass
 
-        return self._constructor(results, index=self.index,
-                                 columns=self.columns)
+        def f(x):
+            result = npfunc(x)
+            try:
+                result = result.astype(x.dtype)
+            except Exception:
+                pass
+            return result
+
+        return self.apply(f)
 
     #----------------------------------------------------------------------
     # Merging / joining methods
@@ -1895,8 +1943,11 @@ class DataFrame(NDFrame):
     def append(self, other):
         """
         Append columns of other to end of this frame's columns and index.
-
         Columns not in this frame are added as new columns.
+
+        Returns
+        -------
+        appended : DataFrame
         """
         if not other:
             return self.copy()
@@ -1997,16 +2048,20 @@ class DataFrame(NDFrame):
 
     def groupby(self, by=None, axis=0, level=None):
         """
-        Goup series using mapper (dict or key function, apply given function to
-        group, return result as series) or by a series of columns
+        Group series using mapper (dict or key function, apply given function
+        to group, return result as series) or by a series of columns
 
         Parameters
         ----------
-        by : mapping function, dict, Series, or tuple / list of column names
-            Called on each element of the object index to determine
-            the groups.  If a dict or Series is passed, the Series or
-            dict VALUES will be used to determine the groups
+        by : mapping function / list of functions, dict, Series, or tuple /
+            list of column names.
+            Called on each element of the object index to determine the groups.
+            If a dict or Series is passed, the Series or dict VALUES will be
+            used to determine the groups
         axis : int, default 0
+        level : int, default None
+            If the axis is a MultiIndex (hierarchical), group by a particular
+            level
 
         Examples
         --------
@@ -2016,7 +2071,7 @@ class DataFrame(NDFrame):
         # DataFrame result
         >>> data.groupby(['col1', 'col2'])['col3'].mean()
 
-        # WidePanel result
+        # DataFrame with hierarchical index
         >>> data.groupby(['col1', 'col2']).mean()
 
         Returns
@@ -2026,21 +2081,6 @@ class DataFrame(NDFrame):
         from pandas.core.groupby import groupby
         return groupby(self, by, axis=axis, level=level)
 
-    def tgroupby(self, keyfunc, applyfunc):
-        """
-        Aggregate columns based on passed function
-
-        Parameters
-        ----------
-        keyfunc : function
-        applyfunc : function
-
-        Returns
-        -------
-        y : DataFrame
-        """
-        return self.T.groupby(keyfunc).aggregate(applyfunc).T
-
     #----------------------------------------------------------------------
     # Statistical methods, etc.
 
@@ -2683,11 +2723,6 @@ class DataFrame(NDFrame):
         """
         return self.mul(other, fill_value=1.)
 
-    def combineFirst(self, other):  # pragma: no cover
-        warnings.warn("combineFirst is deprecated. Use combine_first",
-                      FutureWarning)
-        return self.combine_first(other)
-
     def toDataMatrix(self):  # pragma: no cover
         warnings.warn("toDataMatrix will disappear in next release "
                       "as there is no longer a DataMatrix class",
@@ -2706,46 +2741,25 @@ class DataFrame(NDFrame):
                       "removed in next release", FutureWarning)
         return list(self.columns)
 
-    def getXS(self, key):  # pragma: no cover
-        warnings.warn("'getXS' is deprecated. Use 'xs' instead",
-                      FutureWarning)
-        return self.xs(key)
-
-    def merge(self, *args, **kwargs):  # pragma: no cover
-        warnings.warn("merge is deprecated. Use 'join' instead",
-                      FutureWarning)
-        return self.join(*args, **kwargs)
-
     def asMatrix(self, *args, **kwargs):  # pragma: no cover
         warnings.warn("asMatrix is deprecated. Use 'as_matrix' or .values "
                       "instead", FutureWarning)
         return self.as_matrix(*args, **kwargs)
 
-    def toRecords(self, *args, **kwargs):  # pragma: no cover
-        warnings.warn("toRecords is deprecated. Use 'to_records' "
-                      "instead", FutureWarning)
-        return self.to_records(*args, **kwargs)
-
-    def toDict(self):  # pragma: no cover
-        warnings.warn("toDict is deprecated. Use 'to_dic' instead",
-                      FutureWarning)
-        return dict((k, v.to_dict()) for k, v in self.iteritems())
-
     @classmethod
     def fromRecords(cls, *args, **kwargs):  # pragma: no cover
         warnings.warn("fromRecords is deprecated. Use 'from_records' "
                       "instead", FutureWarning)
         return cls.from_records(*args, **kwargs)
 
-    def _firstTimeWithValue(self):  # pragma: no cover
-        warnings.warn("_firstTimeWithValue is deprecated. Use "
-                      "first_valid_index instead", FutureWarning)
-        return self.first_valid_index()
-
-    def _lastTimeWithValue(self):  # pragma: no cover
-        warnings.warn("_firstTimeWithValue is deprecated. Use "
-                      "last_valid_index instead", FutureWarning)
-        return self.last_valid_index()
+    combineFirst = deprecate('combineFirst', combine_first)
+    getXS = deprecate('getXS', xs)
+    merge = deprecate('merge', join)
+    toRecords = deprecate('toRecords', to_records)
+    toDict = deprecate('toDict', to_dict)
+    _firstTimeWithValue = deprecate('_firstTimeWithValue', first_valid_index)
+    _lastTimeWithValue = deprecate('_lastTimeWithValue', last_valid_index)
+    toCSV = deprecate('toCSV', to_csv)
 
     def dropEmptyRows(self, specificColumns=None):  # pragma: no cover
         """
@@ -2795,6 +2809,22 @@ class DataFrame(NDFrame):
         else:
             return self.dropna(axis=0, subset=specificColumns, thresh=minObs)
 
+    def tgroupby(self, keyfunc, applyfunc):  # pragma: no cover
+        """
+        Aggregate columns based on passed function
+
+        Parameters
+        ----------
+        keyfunc : function
+        applyfunc : function
+
+        Returns
+        -------
+        y : DataFrame
+        """
+        warnings.warn("tgroupby is deprecated. Use groupby with axis=1",
+                      FutureWarning)
+        return self.T.groupby(keyfunc).aggregate(applyfunc).T
 
 def group_agg(values, bounds, f):
     """
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 2c350f0dd..763eabbcc 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -523,13 +523,17 @@ class MultiIndex(Index):
         new_labels = [lab.take(*args, **kwargs) for lab in self.labels]
         return MultiIndex(levels=self.levels, labels=new_labels)
 
+    def argsort(self, *args, **kwargs):
+        return self.get_tuple_index().argsort()
+
     def drop(self, labels):
         try:
             if not isinstance(labels, np.ndarray):
                 labels = _asarray_tuplesafe(labels)
             indexer, mask = self.get_indexer(labels)
             if not mask.all():
-                raise ValueError('labels %s not contained in axis' % labels[-mask])
+                raise ValueError('labels %s not contained in axis'
+                                 % labels[-mask])
             return self.delete(indexer)
         except Exception:
             pass
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 50046f192..8bf65afff 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -299,7 +299,9 @@ def _is_label_slice(labels, obj):
     return not crit(obj.start) or not crit(obj.stop)
 
 def _need_slice(obj):
-    return obj.start is not None or obj.stop is not None
+    return (obj.start is not None or
+            obj.stop is not None or
+            (obj.step is not None and obj.step != 1))
 
 def _maybe_droplevels(index, key):
     # drop levels
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 84b37e7ee..d8e3ff5ac 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -721,15 +721,20 @@ class Series(np.ndarray, PandasObject):
 
         return np.corrcoef(this, that)[0, 1]
 
-    def diff(self):
+    def diff(self, periods=1):
         """
         1st discrete difference of object
 
+        Parameters
+        ----------
+        periods : int, default 1
+            Periods to shift for forming difference
+
         Returns
         -------
         diffed : Series
         """
-        return (self - self.shift(1))
+        return (self - self.shift(periods))
 
     def autocorr(self):
         """
@@ -1478,8 +1483,8 @@ class Series(np.ndarray, PandasObject):
     def asfreq(self, freq, method=None):
         """
         Convert this TimeSeries to the provided frequency using DateOffset
-        object or time rule. Optionally provide fill method to
-        pad/backfill/interpolate missing values.
+        object or time rule. Optionally provide fill method to pad/backfill
+        missing values.
 
         Parameters
         ----------
@@ -1570,7 +1575,7 @@ class Series(np.ndarray, PandasObject):
 
         Returns
         -------
-        y : Series (new object)
+        renamed : Series (new object)
         """
         if isinstance(mapper, (dict, Series)):
             mapper = mapper.__getitem__
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index f30cddbd6..997b0f0c7 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -973,7 +973,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         arr[:] = [(1,2.,'Hello'),(2,3.,"World")]
 
         frame = DataFrame.from_records(arr)
-        indexed_frame = DataFrame.from_records(arr, indexField='f1')
+        indexed_frame = DataFrame.from_records(arr, index='f1')
 
         self.assertRaises(Exception, DataFrame.from_records, np.zeros((2, 3)))
 
@@ -985,7 +985,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assertEqual(len(records.dtype.names), 2)
         self.assert_('index' not in records.dtype.names)
 
-
     def test_get_agg_axis(self):
         cols = self.frame._get_agg_axis(0)
         self.assert_(cols is self.frame.columns)
@@ -1336,19 +1335,19 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         test_comp(operator.ge)
         test_comp(operator.le)
 
-    def test_toCSV_fromcsv(self):
+    def test_to_csv_fromcsv(self):
         path = '__tmp__'
 
         self.frame['A'][:5] = nan
 
-        self.frame.toCSV(path)
-        self.frame.toCSV(path, cols=['A', 'B'])
-        self.frame.toCSV(path, header=False)
-        self.frame.toCSV(path, index=False)
+        self.frame.to_csv(path)
+        self.frame.to_csv(path, cols=['A', 'B'])
+        self.frame.to_csv(path, header=False)
+        self.frame.to_csv(path, index=False)
 
         # test roundtrip
 
-        self.tsframe.toCSV(path)
+        self.tsframe.to_csv(path)
         recons = DataFrame.fromcsv(path)
 
         assert_frame_equal(self.tsframe, recons)
@@ -1358,14 +1357,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
 
         # no index
-        self.tsframe.toCSV(path, index=False)
+        self.tsframe.to_csv(path, index=False)
         recons = DataFrame.fromcsv(path, index_col=None)
         assert_almost_equal(self.tsframe.values, recons.values)
 
         # corner case
         dm = DataFrame({'s1' : Series(range(3),range(3)),
                         's2' : Series(range(2),range(2))})
-        dm.toCSV(path)
+        dm.to_csv(path)
         recons = DataFrame.fromcsv(path)
         assert_frame_equal(dm, recons)
 
@@ -1999,12 +1998,39 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         assert_frame_equal(result, expected)
 
     def test_sort(self):
-        # what to test?
-        sorted = self.frame.sort()
-        sorted_A = self.frame.sort(column='A')
-
-        sorted = self.frame.sort(ascending=False)
-        sorted_A = self.frame.sort(column='A', ascending=False)
+        frame = DataFrame(np.random.randn(4, 4), index=[1, 2, 3, 4],
+                          columns=['A', 'B', 'C', 'D'])
+
+        # axis=0
+        unordered = frame.ix[[3, 2, 4, 1]]
+        sorted_df = unordered.sort()
+        expected = frame
+        assert_frame_equal(sorted_df, expected)
+
+        sorted_df = unordered.sort(ascending=False)
+        expected = frame[::-1]
+        assert_frame_equal(sorted_df, expected)
+
+        # axis=1
+        unordered = frame.ix[:, ['D', 'B', 'C', 'A']]
+        sorted_df = unordered.sort(axis=1)
+        expected = frame
+        assert_frame_equal(sorted_df, expected)
+
+        sorted_df = unordered.sort(axis=1, ascending=False)
+        expected = frame.ix[:, ::-1]
+        assert_frame_equal(sorted_df, expected)
+
+        # by column
+        sorted_df = frame.sort(column='A')
+        indexer = frame['A'].argsort().values
+        expected = frame.ix[frame.index[indexer]]
+        assert_frame_equal(sorted_df, expected)
+
+        sorted_df = frame.sort(column='A', ascending=False)
+        indexer = indexer[::-1]
+        expected = frame.ix[frame.index[indexer]]
+        assert_frame_equal(sorted_df, expected)
 
     def test_combine_first(self):
         # disjoint
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 8e64e692a..d8ea2c873 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -382,17 +382,17 @@ class TestGroupBy(unittest.TestCase):
         for k, v in grouped:
             self.assertEqual(len(v.columns), 2)
 
-        # tgroupby
-        grouping = {
-            'A' : 0,
-            'B' : 1,
-            'C' : 0,
-            'D' : 1
-        }
-
-        grouped = self.frame.tgroupby(grouping.get, np.mean)
-        self.assertEqual(len(grouped), len(self.frame.index))
-        self.assertEqual(len(grouped.columns), 2)
+        # # tgroupby
+        # grouping = {
+        #     'A' : 0,
+        #     'B' : 1,
+        #     'C' : 0,
+        #     'D' : 1
+        # }
+
+        # grouped = self.frame.tgroupby(grouping.get, np.mean)
+        # self.assertEqual(len(grouped), len(self.frame.index))
+        # self.assertEqual(len(grouped.columns), 2)
 
     def test_multi_iter(self):
         s = Series(np.arange(6))
