commit 12a0dc49ac63b63bcc5f93bccf71bce51c60bdad
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Fri Oct 12 06:12:15 2018 -0700

    STYLE: Avoid using backslash to continue code to the next line (#23073)

diff --git a/pandas/compat/numpy/__init__.py b/pandas/compat/numpy/__init__.py
index a6f586c7f..d4e3def84 100644
--- a/pandas/compat/numpy/__init__.py
+++ b/pandas/compat/numpy/__init__.py
@@ -60,8 +60,8 @@ def np_array_datetime64_compat(arr, *args, **kwargs):
     if not _np_version_under1p11:
 
         # is_list_like
-        if hasattr(arr, '__iter__') and not \
-           isinstance(arr, string_and_binary_types):
+        if (hasattr(arr, '__iter__') and
+                not isinstance(arr, string_and_binary_types)):
             arr = [tz_replacer(s) for s in arr]
         else:
             arr = tz_replacer(arr)
diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index e91cc8ec1..4607aba07 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -275,8 +275,8 @@ def match(to_match, values, na_sentinel=-1):
         # replace but return a numpy array
         # use a Series because it handles dtype conversions properly
         from pandas import Series
-        result = Series(result.ravel()).replace(-1, na_sentinel).values.\
-            reshape(result.shape)
+        result = Series(result.ravel()).replace(-1, na_sentinel)
+        result = result.values.reshape(result.shape)
 
     return result
 
diff --git a/pandas/core/base.py b/pandas/core/base.py
index 00c049497..91ae8375c 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -395,8 +395,8 @@ class SelectionMixin(object):
 
                     elif isinstance(obj, ABCSeries):
                         nested_renaming_depr()
-                    elif isinstance(obj, ABCDataFrame) and \
-                            k not in obj.columns:
+                    elif (isinstance(obj, ABCDataFrame) and
+                          k not in obj.columns):
                         raise KeyError(
                             "Column '{col}' does not exist!".format(col=k))
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index bb82c531b..1158a025b 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -5651,8 +5651,8 @@ class NDFrame(PandasObject, SelectionMixin):
                 # fill in 2d chunks
                 result = {col: s.fillna(method=method, value=value)
                           for col, s in self.iteritems()}
-                new_obj = self._constructor.\
-                    from_dict(result).__finalize__(self)
+                prelim_obj = self._constructor.from_dict(result)
+                new_obj = prelim_obj.__finalize__(self)
                 new_data = new_obj._data
 
             else:
diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index f15b1203a..957f3be8c 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -1027,8 +1027,9 @@ class SeriesGroupBy(GroupBy):
         try:
             sorter = np.lexsort((val, ids))
         except TypeError:  # catches object dtypes
-            assert val.dtype == object, \
-                'val.dtype must be object, got %s' % val.dtype
+            msg = ('val.dtype must be object, got {dtype}'
+                   .format(dtype=val.dtype))
+            assert val.dtype == object, msg
             val, _ = algorithms.factorize(val, sort=False)
             sorter = np.lexsort((val, ids))
             _isna = lambda a: a == -1
diff --git a/pandas/core/groupby/groupby.py b/pandas/core/groupby/groupby.py
index 61dadd833..025be781d 100644
--- a/pandas/core/groupby/groupby.py
+++ b/pandas/core/groupby/groupby.py
@@ -578,8 +578,8 @@ b  2""")
             # a little trickery for aggregation functions that need an axis
             # argument
             kwargs_with_axis = kwargs.copy()
-            if 'axis' not in kwargs_with_axis or \
-               kwargs_with_axis['axis'] is None:
+            if ('axis' not in kwargs_with_axis or
+                    kwargs_with_axis['axis'] is None):
                 kwargs_with_axis['axis'] = self.axis
 
             def curried_with_axis(x):
@@ -1490,8 +1490,10 @@ class GroupBy(_GroupBy):
         self._set_group_selection()
 
         if not dropna:
-            mask = np.in1d(self._cumcount_array(), nth_values) | \
-                np.in1d(self._cumcount_array(ascending=False) + 1, -nth_values)
+            mask_left = np.in1d(self._cumcount_array(), nth_values)
+            mask_right = np.in1d(self._cumcount_array(ascending=False) + 1,
+                                 -nth_values)
+            mask = mask_left | mask_right
 
             out = self._selected_obj[mask]
             if not self.as_index:
@@ -1552,8 +1554,8 @@ class GroupBy(_GroupBy):
             result.loc[mask] = np.nan
 
         # reset/reindex to the original groups
-        if len(self.obj) == len(dropped) or \
-           len(result) == len(self.grouper.result_index):
+        if (len(self.obj) == len(dropped) or
+                len(result) == len(self.grouper.result_index)):
             result.index = self.grouper.result_index
         else:
             result = result.reindex(self.grouper.result_index)
diff --git a/pandas/core/groupby/grouper.py b/pandas/core/groupby/grouper.py
index e7144fb1d..1c8fe0e6c 100644
--- a/pandas/core/groupby/grouper.py
+++ b/pandas/core/groupby/grouper.py
@@ -157,8 +157,8 @@ class Grouper(object):
         if self.key is not None:
             key = self.key
             # The 'on' is already defined
-            if getattr(self.grouper, 'name', None) == key and \
-                    isinstance(obj, ABCSeries):
+            if (getattr(self.grouper, 'name', None) == key and
+                    isinstance(obj, ABCSeries)):
                 ax = self._grouper.take(obj.index)
             else:
                 if key not in obj._info_axis:
@@ -530,9 +530,9 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True,
     except Exception:
         all_in_columns_index = False
 
-    if not any_callable and not all_in_columns_index and \
-       not any_arraylike and not any_groupers and \
-       match_axis_length and level is None:
+    if (not any_callable and not all_in_columns_index and
+            not any_arraylike and not any_groupers and
+            match_axis_length and level is None):
         keys = [com.asarray_tuplesafe(keys)]
 
     if isinstance(level, (tuple, list)):
@@ -593,15 +593,15 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True,
 
         # create the Grouping
         # allow us to passing the actual Grouping as the gpr
-        ping = Grouping(group_axis,
-                        gpr,
-                        obj=obj,
-                        name=name,
-                        level=level,
-                        sort=sort,
-                        observed=observed,
-                        in_axis=in_axis) \
-            if not isinstance(gpr, Grouping) else gpr
+        ping = (Grouping(group_axis,
+                         gpr,
+                         obj=obj,
+                         name=name,
+                         level=level,
+                         sort=sort,
+                         observed=observed,
+                         in_axis=in_axis)
+                if not isinstance(gpr, Grouping) else gpr)
 
         groupings.append(ping)
 
diff --git a/pandas/core/groupby/ops.py b/pandas/core/groupby/ops.py
index d9f7b4d9c..b199127ac 100644
--- a/pandas/core/groupby/ops.py
+++ b/pandas/core/groupby/ops.py
@@ -521,8 +521,8 @@ class BaseGrouper(object):
                 result = result.astype('float64')
                 result[mask] = np.nan
 
-        if kind == 'aggregate' and \
-           self._filter_empty_groups and not counts.all():
+        if (kind == 'aggregate' and
+                self._filter_empty_groups and not counts.all()):
             if result.ndim == 2:
                 try:
                     result = lib.row_bool_subset(
@@ -743,8 +743,9 @@ class BinGrouper(BaseGrouper):
         else:
             comp_ids = np.repeat(np.r_[-1, np.arange(ngroups)], rep)
 
-        return comp_ids.astype('int64', copy=False), \
-            obs_group_ids.astype('int64', copy=False), ngroups
+        return (comp_ids.astype('int64', copy=False),
+                obs_group_ids.astype('int64', copy=False),
+                ngroups)
 
     @cache_readonly
     def ngroups(self):
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index b3c913f21..0c6aaf4b4 100755
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -1836,8 +1836,8 @@ class _LocIndexer(_LocationIndexer):
         """Translate any partial string timestamp matches in key, returning the
         new key (GH 10331)"""
         if isinstance(labels, MultiIndex):
-            if isinstance(key, compat.string_types) and \
-                    labels.levels[0].is_all_dates:
+            if (isinstance(key, compat.string_types) and
+                    labels.levels[0].is_all_dates):
                 # Convert key '2016-01-01' to
                 # ('2016-01-01'[, slice(None, None, None)]+)
                 key = tuple([key] + [slice(None)] * (len(labels.levels) - 1))
@@ -1847,8 +1847,8 @@ class _LocIndexer(_LocationIndexer):
                 # (..., slice('2016-01-01', '2016-01-01', None), ...)
                 new_key = []
                 for i, component in enumerate(key):
-                    if isinstance(component, compat.string_types) and \
-                            labels.levels[i].is_all_dates:
+                    if (isinstance(component, compat.string_types) and
+                            labels.levels[i].is_all_dates):
                         new_key.append(slice(component, component, None))
                     else:
                         new_key.append(component)
diff --git a/pandas/core/internals/concat.py b/pandas/core/internals/concat.py
index 6d6707000..1fc9d9612 100644
--- a/pandas/core/internals/concat.py
+++ b/pandas/core/internals/concat.py
@@ -184,8 +184,8 @@ class JoinUnit(object):
                     if len(values) and values[0] is None:
                         fill_value = None
 
-                if getattr(self.block, 'is_datetimetz', False) or \
-                        is_datetimetz(empty_dtype):
+                if (getattr(self.block, 'is_datetimetz', False) or
+                        is_datetimetz(empty_dtype)):
                     if self.block is None:
                         array = empty_dtype.construct_array_type()
                         missing_arr = array([fill_value], dtype=empty_dtype)
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index b525dddeb..22e591e77 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -140,8 +140,8 @@ def pivot_table(data, values=None, index=None, columns=None, aggfunc='mean',
                              margins_name=margins_name, fill_value=fill_value)
 
     # discard the top level
-    if values_passed and not values_multi and not table.empty and \
-       (table.columns.nlevels > 1):
+    if (values_passed and not values_multi and not table.empty and
+            (table.columns.nlevels > 1)):
         table = table[values[0]]
 
     if len(index) == 0 and len(columns) > 0:
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index 50f6e3107..495e59d08 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -745,9 +745,8 @@ def get_dummies(data, prefix=None, prefix_sep='_', dummy_na=False,
 
             if is_list_like(item):
                 if not len(item) == data_to_encode.shape[1]:
-                    len_msg = \
-                        len_msg.format(name=name, len_item=len(item),
-                                       len_enc=data_to_encode.shape[1])
+                    len_msg = len_msg.format(name=name, len_item=len(item),
+                                             len_enc=data_to_encode.shape[1])
                     raise ValueError(len_msg)
 
         check_len(prefix, 'prefix')
diff --git a/pandas/core/tools/datetimes.py b/pandas/core/tools/datetimes.py
index eb8d2b0b6..dcba51d26 100644
--- a/pandas/core/tools/datetimes.py
+++ b/pandas/core/tools/datetimes.py
@@ -724,8 +724,9 @@ def _attempt_YYYYMMDD(arg, errors):
         result = np.empty(carg.shape, dtype='M8[ns]')
         iresult = result.view('i8')
         iresult[~mask] = tslibs.iNaT
-        result[mask] = calc(carg[mask].astype(np.float64).astype(np.int64)). \
-            astype('M8[ns]')
+
+        masked_result = calc(carg[mask].astype(np.float64).astype(np.int64))
+        result[mask] = masked_result.astype('M8[ns]')
         return result
 
     # try intlike / strings that are ints
diff --git a/pandas/core/window.py b/pandas/core/window.py
index ea0ec79d6..7d4896760 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -98,11 +98,11 @@ class _Window(PandasObject, SelectionMixin):
     def validate(self):
         if self.center is not None and not is_bool(self.center):
             raise ValueError("center must be a boolean")
-        if self.min_periods is not None and not \
-           is_integer(self.min_periods):
+        if (self.min_periods is not None and
+                not is_integer(self.min_periods)):
             raise ValueError("min_periods must be an integer")
-        if self.closed is not None and self.closed not in \
-           ['right', 'both', 'left', 'neither']:
+        if (self.closed is not None and
+                self.closed not in ['right', 'both', 'left', 'neither']):
             raise ValueError("closed must be 'right', 'left', 'both' or "
                              "'neither'")
 
diff --git a/pandas/io/common.py b/pandas/io/common.py
index 405911eda..9bf7c5af2 100644
--- a/pandas/io/common.py
+++ b/pandas/io/common.py
@@ -430,8 +430,8 @@ def _get_handle(path_or_buf, mode, encoding=None, compression=None,
         handles.append(f)
 
     # in Python 3, convert BytesIO or fileobjects passed with an encoding
-    if compat.PY3 and is_text and\
-            (compression or isinstance(f, need_text_wrapping)):
+    if (compat.PY3 and is_text and
+            (compression or isinstance(f, need_text_wrapping))):
         from io import TextIOWrapper
         f = TextIOWrapper(f, encoding=encoding)
         handles.append(f)
diff --git a/pandas/io/excel.py b/pandas/io/excel.py
index 00b4c704c..c1cbccb7c 100644
--- a/pandas/io/excel.py
+++ b/pandas/io/excel.py
@@ -1755,14 +1755,14 @@ class _XlsxStyler(object):
                     props[k] = ['none', 'thin', 'medium', 'dashed', 'dotted',
                                 'thick', 'double', 'hair', 'mediumDashed',
                                 'dashDot', 'mediumDashDot', 'dashDotDot',
-                                'mediumDashDotDot', 'slantDashDot'].\
-                        index(props[k])
+                                'mediumDashDotDot',
+                                'slantDashDot'].index(props[k])
                 except ValueError:
                     props[k] = 2
 
         if isinstance(props.get('font_script'), string_types):
-            props['font_script'] = ['baseline', 'superscript', 'subscript'].\
-                index(props['font_script'])
+            props['font_script'] = ['baseline', 'superscript',
+                                    'subscript'].index(props['font_script'])
 
         if isinstance(props.get('underline'), string_types):
             props['underline'] = {'none': 0, 'single': 1, 'double': 2,
diff --git a/pandas/io/formats/style.py b/pandas/io/formats/style.py
index f4bb53ba4..ad6ad5bca 100644
--- a/pandas/io/formats/style.py
+++ b/pandas/io/formats/style.py
@@ -14,10 +14,9 @@ try:
         PackageLoader, Environment, ChoiceLoader, FileSystemLoader
     )
 except ImportError:
-    msg = "pandas.Styler requires jinja2. "\
-          "Please install with `conda install Jinja2`\n"\
-          "or `pip install Jinja2`"
-    raise ImportError(msg)
+    raise ImportError("pandas.Styler requires jinja2. "
+                      "Please install with `conda install Jinja2`\n"
+                      "or `pip install Jinja2`")
 
 from pandas.core.dtypes.common import is_float, is_string_like
 
diff --git a/pandas/io/formats/terminal.py b/pandas/io/formats/terminal.py
index 2846525ad..ac73363b9 100644
--- a/pandas/io/formats/terminal.py
+++ b/pandas/io/formats/terminal.py
@@ -40,9 +40,8 @@ def get_terminal_size():
         if tuple_xy is None:
             tuple_xy = _get_terminal_size_tput()
             # needed for window's python in cygwin's xterm!
-    if current_os == 'Linux' or \
-        current_os == 'Darwin' or \
-            current_os.startswith('CYGWIN'):
+    if (current_os == 'Linux' or current_os == 'Darwin' or
+            current_os.startswith('CYGWIN')):
         tuple_xy = _get_terminal_size_linux()
     if tuple_xy is None:
         tuple_xy = (80, 25)      # default value
diff --git a/pandas/io/json/normalize.py b/pandas/io/json/normalize.py
index 03f0905d2..5c7b964cf 100644
--- a/pandas/io/json/normalize.py
+++ b/pandas/io/json/normalize.py
@@ -250,11 +250,10 @@ def json_normalize(data, record_path=None, meta=None,
                             if errors == 'ignore':
                                 meta_val = np.nan
                             else:
-                                raise \
-                                    KeyError("Try running with "
-                                             "errors='ignore' as key "
-                                             "{err} is not always present"
-                                             .format(err=e))
+                                raise KeyError("Try running with "
+                                               "errors='ignore' as key "
+                                               "{err} is not always present"
+                                               .format(err=e))
                     meta_vals[key].append(meta_val)
 
                 records.extend(recs)
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 2def3b81c..1edc6f6e1 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -883,15 +883,15 @@ class TextFileReader(BaseIterator):
         # C engine not supported yet
         if engine == 'c':
             if options['skipfooter'] > 0:
-                fallback_reason = "the 'c' engine does not support"\
-                                  " skipfooter"
+                fallback_reason = ("the 'c' engine does not support"
+                                   " skipfooter")
                 engine = 'python'
 
         encoding = sys.getfilesystemencoding() or 'utf-8'
         if sep is None and not delim_whitespace:
             if engine == 'c':
-                fallback_reason = "the 'c' engine does not support"\
-                                  " sep=None with delim_whitespace=False"
+                fallback_reason = ("the 'c' engine does not support"
+                                   " sep=None with delim_whitespace=False")
                 engine = 'python'
         elif sep is not None and len(sep) > 1:
             if engine == 'c' and sep == r'\s+':
@@ -899,10 +899,10 @@ class TextFileReader(BaseIterator):
                 del result['delimiter']
             elif engine not in ('python', 'python-fwf'):
                 # wait until regex engine integrated
-                fallback_reason = "the 'c' engine does not support"\
-                                  " regex separators (separators > 1 char and"\
-                                  r" different from '\s+' are"\
-                                  " interpreted as regex)"
+                fallback_reason = ("the 'c' engine does not support"
+                                   " regex separators (separators > 1 char and"
+                                   r" different from '\s+' are"
+                                   " interpreted as regex)")
                 engine = 'python'
         elif delim_whitespace:
             if 'python' in engine:
@@ -915,10 +915,10 @@ class TextFileReader(BaseIterator):
             except UnicodeDecodeError:
                 encodeable = False
             if not encodeable and engine not in ('python', 'python-fwf'):
-                fallback_reason = "the separator encoded in {encoding}" \
-                                  " is > 1 char long, and the 'c' engine" \
-                                  " does not support such separators".format(
-                                      encoding=encoding)
+                fallback_reason = ("the separator encoded in {encoding}"
+                                   " is > 1 char long, and the 'c' engine"
+                                   " does not support such separators"
+                                   .format(encoding=encoding))
                 engine = 'python'
 
         quotechar = options['quotechar']
@@ -3203,8 +3203,8 @@ def _clean_index_names(columns, index_col):
             index_names.append(name)
 
     # hack
-    if isinstance(index_names[0], compat.string_types)\
-            and 'Unnamed' in index_names[0]:
+    if (isinstance(index_names[0], compat.string_types) and
+            'Unnamed' in index_names[0]):
         index_names[0] = None
 
     return index_names, columns, index_col
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index ff3703653..d2b523461 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -1804,8 +1804,8 @@ class IndexCol(StringMixin):
         if self.meta == 'category':
             new_metadata = self.metadata
             cur_metadata = handler.read_metadata(self.cname)
-            if new_metadata is not None and cur_metadata is not None \
-                    and not array_equivalent(new_metadata, cur_metadata):
+            if (new_metadata is not None and cur_metadata is not None and
+                    not array_equivalent(new_metadata, cur_metadata)):
                 raise ValueError("cannot append a categorical with "
                                  "different categories to the existing")
 
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index a321e315f..68b2182c2 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -442,8 +442,8 @@ def _datetime_to_stata_elapsed_vec(dates, fmt):
         conv_dates = 4 * (d.year - stata_epoch.year) + (d.month - 1) // 3
     elif fmt in ["%th", "th"]:
         d = parse_dates_safe(dates, year=True)
-        conv_dates = 2 * (d.year - stata_epoch.year) + \
-                         (d.month > 6).astype(np.int)
+        conv_dates = (2 * (d.year - stata_epoch.year) +
+                      (d.month > 6).astype(np.int))
     elif fmt in ["%ty", "ty"]:
         d = parse_dates_safe(dates, year=True)
         conv_dates = d.year
@@ -568,16 +568,18 @@ def _cast_to_stata_types(data):
         elif dtype in (np.float32, np.float64):
             value = data[col].max()
             if np.isinf(value):
-                msg = 'Column {0} has a maximum value of infinity which is ' \
-                      'outside the range supported by Stata.'
-                raise ValueError(msg.format(col))
+                raise ValueError('Column {col} has a maximum value of '
+                                 'infinity which is outside the range '
+                                 'supported by Stata.'.format(col=col))
             if dtype == np.float32 and value > float32_max:
                 data[col] = data[col].astype(np.float64)
             elif dtype == np.float64:
                 if value > float64_max:
-                    msg = 'Column {0} has a maximum value ({1}) outside the ' \
-                          'range supported by Stata ({1})'
-                    raise ValueError(msg.format(col, value, float64_max))
+                    raise ValueError('Column {col} has a maximum value '
+                                     '({val}) outside the range supported by '
+                                     'Stata ({float64_max})'
+                                     .format(col=col, val=value,
+                                             float64_max=float64_max))
 
     if ws:
         warnings.warn(ws, PossiblePrecisionLoss)
@@ -1704,9 +1706,10 @@ class StataReader(StataParser, BaseIterator):
                     vc = Series(categories).value_counts()
                     repeats = list(vc.index[vc > 1])
                     repeats = '\n' + '-' * 80 + '\n'.join(repeats)
-                    msg = 'Value labels for column {0} are not unique. The ' \
-                          'repeated labels are:\n{1}'.format(col, repeats)
-                    raise ValueError(msg)
+                    raise ValueError('Value labels for column {col} are not '
+                                     'unique. The repeated labels are:\n'
+                                     '{repeats}'
+                                     .format(col=col, repeats=repeats))
                 # TODO: is the next line needed above in the data(...) method?
                 cat_data = Series(cat_data, index=data.index)
                 cat_converted_data.append((col, cat_data))
@@ -2066,8 +2069,8 @@ class StataWriter(StataParser):
                 name = text_type(name)
 
             for c in name:
-                if (c < 'A' or c > 'Z') and (c < 'a' or c > 'z') and \
-                        (c < '0' or c > '9') and c != '_':
+                if ((c < 'A' or c > 'Z') and (c < 'a' or c > 'z') and
+                        (c < '0' or c > '9') and c != '_'):
                     name = name.replace(c, '_')
 
             # Variable name must not be a reserved word
diff --git a/pandas/plotting/__init__.py b/pandas/plotting/__init__.py
index 385d4d7f0..ff5351bb6 100644
--- a/pandas/plotting/__init__.py
+++ b/pandas/plotting/__init__.py
@@ -12,9 +12,9 @@ from pandas.plotting._core import boxplot
 from pandas.plotting._style import plot_params
 from pandas.plotting._tools import table
 try:
-    from pandas.plotting._converter import \
-        register as register_matplotlib_converters
-    from pandas.plotting._converter import \
-        deregister as deregister_matplotlib_converters
+    from pandas.plotting._converter import (
+        register as register_matplotlib_converters)
+    from pandas.plotting._converter import (
+        deregister as deregister_matplotlib_converters)
 except ImportError:
     pass
