commit e957fbc0aa9cdfe9d4c5592c088416b20cb23b28
Author: Jeffrey Tratner <jeffrey.tratner@gmail.com>
Date:   Sun Jul 28 01:10:35 2013 -0400

    CLN/ENH: Merge compat with py3compat and six
    
    For simplicity, move the relevant portions of six into
    compat and combine py3compat and compat together (given the distinctions
    were relatively arbitrary already). Also switch to importing u to make
    things cleaner.

diff --git a/LICENSES/SIX b/LICENSES/SIX
new file mode 100644
index 000000000..6fd669af2
--- /dev/null
+++ b/LICENSES/SIX
@@ -0,0 +1,21 @@
+six license (substantial portions used in the python 3 compatibility module)
+===========================================================================
+Copyright (c) 2010-2013 Benjamin Peterson
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+#
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+#
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
diff --git a/bench/alignment.py b/bench/alignment.py
index 1f32064db..0cc0de797 100644
--- a/bench/alignment.py
+++ b/bench/alignment.py
@@ -1,5 +1,5 @@
 # Setup
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import numpy as np
 import pandas
 import la
diff --git a/bench/bench_get_put_value.py b/bench/bench_get_put_value.py
index cf1b827e1..405f22450 100644
--- a/bench/bench_get_put_value.py
+++ b/bench/bench_get_put_value.py
@@ -1,6 +1,6 @@
 from pandas import *
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 
 N = 1000
 K = 50
diff --git a/bench/bench_groupby.py b/bench/bench_groupby.py
index aa337acf9..76c92407d 100644
--- a/bench/bench_groupby.py
+++ b/bench/bench_groupby.py
@@ -1,6 +1,6 @@
 from pandas import *
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 
 import string
 import random
diff --git a/bench/bench_khash_dict.py b/bench/bench_khash_dict.py
index 784704cbb..7e9f3c103 100644
--- a/bench/bench_khash_dict.py
+++ b/bench/bench_khash_dict.py
@@ -8,7 +8,7 @@ import os
 
 from vbench.api import Benchmark
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import pandas._tseries as lib
 import pandas._sandbox as sbx
 import time
diff --git a/bench/bench_merge.py b/bench/bench_merge.py
index c4f595eb0..da2706dcf 100644
--- a/bench/bench_merge.py
+++ b/bench/bench_merge.py
@@ -1,7 +1,9 @@
+import random
+import gc
+import time
 from pandas import *
+from pandas.util.compat import range, lrange, StringIO
 from pandas.util.testing import rands
-from pandas.util.py3compat import range, lrange
-import random
 
 N = 10000
 ngroups = 10
@@ -29,10 +31,6 @@ def get_test_data(ngroups=100, n=N):
 #                  'value' : np.random.randn(N // 10)})
 # result = merge.merge(df, df2, on='key2')
 
-from collections import defaultdict
-import gc
-import time
-from pandas.util.testing import rands
 N = 10000
 
 indices = np.array([rands(10) for _ in range(N)], dtype='O')
@@ -66,7 +64,6 @@ results.columns = ['dont_sort', 'sort']
 
 
 # R results
-from pandas.util.py3compat import StringIO, lrange
 # many to one
 r_results = read_table(StringIO("""      base::merge   plyr data.table
 inner      0.2475 0.1183     0.1100
@@ -94,7 +91,6 @@ nosort_results['Ratio'] = nosort_results['R'] / nosort_results['pandas']
 
 # many to many
 
-from pandas.util.py3compat import StringIO, lrange
 # many to one
 r_results = read_table(StringIO("""base::merge   plyr data.table
 inner      0.4610 0.1276     0.1269
diff --git a/bench/bench_merge_sqlite.py b/bench/bench_merge_sqlite.py
index cc2e31971..6a8829e31 100644
--- a/bench/bench_merge_sqlite.py
+++ b/bench/bench_merge_sqlite.py
@@ -4,7 +4,7 @@ import gc
 import time
 from pandas import DataFrame
 from pandas.util.testing import rands
-from pandas.util.py3compat import range, zip
+from pandas.util.compat import range, zip
 import random
 
 N = 10000
diff --git a/bench/bench_take_indexing.py b/bench/bench_take_indexing.py
index 51a8e6441..cce9035a4 100644
--- a/bench/bench_take_indexing.py
+++ b/bench/bench_take_indexing.py
@@ -6,7 +6,7 @@ import pandas._tseries as lib
 
 from pandas import DataFrame
 import timeit
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip
 
 setup = """
 from pandas import Series
diff --git a/bench/bench_unique.py b/bench/bench_unique.py
index 8ede875b2..0c89f636f 100644
--- a/bench/bench_unique.py
+++ b/bench/bench_unique.py
@@ -1,8 +1,7 @@
 from __future__ import print_function
 from pandas import *
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, zip
 import pandas._tseries as lib
 import numpy as np
 import matplotlib.pyplot as plt
diff --git a/bench/better_unique.py b/bench/better_unique.py
index f1d8115b1..97c667fbf 100644
--- a/bench/better_unique.py
+++ b/bench/better_unique.py
@@ -1,13 +1,12 @@
 from __future__ import print_function
 from pandas import DataFrame
-from pandas.util.py3compat import range
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, zip
 import timeit
 
 setup = """
 from pandas import Series
 import pandas._tseries as _tseries
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import random
 import numpy as np
 
diff --git a/bench/io_roundtrip.py b/bench/io_roundtrip.py
index a033ef0c7..bd2293d8f 100644
--- a/bench/io_roundtrip.py
+++ b/bench/io_roundtrip.py
@@ -5,7 +5,7 @@ import numpy as np
 
 import la
 import pandas
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from pandas import datetools, DateRange
 
 
diff --git a/bench/serialize.py b/bench/serialize.py
index bc8376223..7a6d5838f 100644
--- a/bench/serialize.py
+++ b/bench/serialize.py
@@ -1,5 +1,5 @@
 from __future__ import print_function
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import time
 import os
 import numpy as np
diff --git a/bench/test.py b/bench/test.py
index 3008fc67a..49396f608 100644
--- a/bench/test.py
+++ b/bench/test.py
@@ -1,9 +1,8 @@
-from pandas.util.py3compat import range
 import numpy as np
 import itertools
 import collections
 import scipy.ndimage as ndi
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip, range
 
 N = 10000
 
diff --git a/doc/plots/stats/moment_plots.py b/doc/plots/stats/moment_plots.py
index a078651d2..0e7ee89bd 100644
--- a/doc/plots/stats/moment_plots.py
+++ b/doc/plots/stats/moment_plots.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import numpy as np
 
 import matplotlib.pyplot as plt
diff --git a/doc/source/conf.py b/doc/source/conf.py
index 128e4ade9..736d19011 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -12,7 +12,7 @@
 
 import sys
 import os
-import six
+from pandas.util.compat import u
 
 # If extensions (or modules to document with autodoc) are in another directory,
 # add these directories to sys.path here. If the directory is relative to the
@@ -64,8 +64,8 @@ source_suffix = '.rst'
 master_doc = 'index'
 
 # General information about the project.
-project = six.u('pandas')
-copyright = six.u('2008-2012, the pandas development team')
+project = u('pandas')
+copyright = u('2008-2012, the pandas development team')
 
 # The version info for the project you're documenting, acts as replacement for
 # |version| and |release|, also used in various other places throughout the
@@ -212,8 +212,8 @@ htmlhelp_basename = 'pandas'
 # (source start file, target name, title, author, documentclass [howto/manual]).
 latex_documents = [
     ('index', 'pandas.tex',
-     six.u('pandas: powerful Python data analysis toolkit'),
-     six.u('Wes McKinney\n\& PyData Development Team'), 'manual'),
+     u('pandas: powerful Python data analysis toolkit'),
+     u('Wes McKinney\n\& PyData Development Team'), 'manual'),
 ]
 
 # The name of an image file (relative to this directory) to place at the top of
diff --git a/doc/source/io.rst b/doc/source/io.rst
index ee6c35187..7290e499c 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1184,7 +1184,7 @@ You can even pass in an instance of ``StringIO`` if you so desire
 
 .. ipython:: python
 
-   from six.moves import cStringIO as StringIO
+   from cStringIO import StringIO
 
    with open(file_path, 'r') as f:
        sio = StringIO(f.read())
diff --git a/doc/sphinxext/comment_eater.py b/doc/sphinxext/comment_eater.py
index 6d216162a..f1c290b30 100755
--- a/doc/sphinxext/comment_eater.py
+++ b/doc/sphinxext/comment_eater.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import cStringIO
+from pandas.util.compat import cStringIO
 import compiler
 import inspect
 import textwrap
diff --git a/doc/sphinxext/compiler_unparse.py b/doc/sphinxext/compiler_unparse.py
index 0fa3983ab..69a4f8e9b 100755
--- a/doc/sphinxext/compiler_unparse.py
+++ b/doc/sphinxext/compiler_unparse.py
@@ -12,7 +12,7 @@
 """
 
 import sys
-from pandas.util.py3compat import cStringIO as StringIO
+from pandas.util.compat import cStringIO as StringIO
 from compiler.ast import Const, Name, Tuple, Div, Mul, Sub, Add
 
 def unparse(ast, single_line_functions=False):
diff --git a/doc/sphinxext/docscrape.py b/doc/sphinxext/docscrape.py
index 5d27810a1..1cc57b415 100755
--- a/doc/sphinxext/docscrape.py
+++ b/doc/sphinxext/docscrape.py
@@ -8,8 +8,7 @@ import textwrap
 import re
 import pydoc
 from warnings import warn
-from six import StringIO
-import six
+from pandas.util.compat import StringIO, callable
 
 class Reader(object):
     """A line-based string reader.
@@ -372,7 +371,7 @@ class NumpyDocString(object):
         idx = self['index']
         out = []
         out += ['.. index:: %s' % idx.get('default','')]
-        for section, references in six.iteritems(idx):
+        for section, references in compat.iteritems(idx):
             if section == 'default':
                 continue
             out += ['   :%s: %s' % (section, ', '.join(references))]
@@ -491,7 +490,7 @@ class ClassDoc(NumpyDocString):
         if self._cls is None:
             return []
         return [name for name,func in inspect.getmembers(self._cls)
-                if not name.startswith('_') and six.callable(func)]
+                if not name.startswith('_') and callable(func)]
 
     @property
     def properties(self):
diff --git a/doc/sphinxext/docscrape_sphinx.py b/doc/sphinxext/docscrape_sphinx.py
index 896ae070d..0f3280776 100755
--- a/doc/sphinxext/docscrape_sphinx.py
+++ b/doc/sphinxext/docscrape_sphinx.py
@@ -1,7 +1,7 @@
 import re, inspect, textwrap, pydoc
 import sphinx
 from .docscrape import NumpyDocString, FunctionDoc, ClassDoc
-import six
+from pandas.util.compat import callable
 
 class SphinxDocString(NumpyDocString):
     def __init__(self, docstring, config={}):
@@ -128,7 +128,7 @@ class SphinxDocString(NumpyDocString):
             return out
 
         out += ['.. index:: %s' % idx.get('default','')]
-        for section, references in six.iteritems(idx):
+        for section, references in compat.iteritems(idx):
             if section == 'default':
                 continue
             elif section == 'refguide':
@@ -212,7 +212,7 @@ def get_doc_object(obj, what=None, doc=None, config={}):
             what = 'class'
         elif inspect.ismodule(obj):
             what = 'module'
-        elif six.callable(obj):
+        elif callable(obj):
             what = 'function'
         else:
             what = 'object'
diff --git a/doc/sphinxext/ipython_directive.py b/doc/sphinxext/ipython_directive.py
index 195875047..49e6ac913 100644
--- a/doc/sphinxext/ipython_directive.py
+++ b/doc/sphinxext/ipython_directive.py
@@ -58,8 +58,7 @@ from __future__ import print_function
 #-----------------------------------------------------------------------------
 
 # Stdlib
-from pandas.util.py3compat import range, lmap
-from pandas.util.py3compat import map, cStringIO as StringIO
+from pandas.util.compat import zip, range, map, lmap, u, cStringIO as StringIO
 import ast
 import os
 import re
@@ -71,8 +70,6 @@ import matplotlib
 from docutils.parsers.rst import directives
 from docutils import nodes
 from sphinx.util.compat import Directive
-import six
-from pandas.util.py3compat import zip
 
 matplotlib.use('Agg')
 
@@ -493,7 +490,7 @@ class EmbeddedSphinxShell(object):
                     multiline = True
                     cont_len = len(str(lineno)) + 2
                     line_to_process = line.strip('\\')
-                    output.extend([six.u("%s %s") % (fmtin%lineno,line)])
+                    output.extend([u("%s %s") % (fmtin%lineno,line)])
                     continue
                 else: # no we're still not
                     line_to_process = line.strip('\\')
@@ -501,12 +498,12 @@ class EmbeddedSphinxShell(object):
                 line_to_process += line.strip('\\')
                 if line_stripped.endswith('\\'): # and we still are
                     continuation = '.' * cont_len
-                    output.extend([(six.u('   %s: ')+line_stripped) % continuation])
+                    output.extend([(u('   %s: ')+line_stripped) % continuation])
                     continue
                 # else go ahead and run this multiline then carry on
 
             # get output of line
-            self.process_input_line(six.text_type(line_to_process.strip()),
+            self.process_input_line(compat.text_type(line_to_process.strip()),
                                     store_history=False)
             out_line = self.cout.getvalue()
             self.clear_cout()
@@ -520,15 +517,15 @@ class EmbeddedSphinxShell(object):
 
             # line numbers don't actually matter, they're replaced later
             if not multiline:
-                in_line = six.u("%s %s") % (fmtin%lineno,line)
+                in_line = u("%s %s") % (fmtin%lineno,line)
 
                 output.extend([in_line])
             else:
-                output.extend([(six.u('   %s: ')+line_stripped) % continuation])
+                output.extend([(u('   %s: ')+line_stripped) % continuation])
                 multiline = False
             if len(out_line):
                 output.extend([out_line])
-            output.extend([six.u('')])
+            output.extend([u('')])
 
         return output
 
@@ -570,19 +567,19 @@ class EmbeddedSphinxShell(object):
                 output.extend([line])
                 continue
 
-            continuation  = six.u('   %s:')% ''.join(['.']*(len(str(ct))+2))
+            continuation  = u('   %s:')% ''.join(['.']*(len(str(ct))+2))
             if not multiline:
-                modified = six.u("%s %s") % (fmtin % ct, line_stripped)
+                modified = u("%s %s") % (fmtin % ct, line_stripped)
                 output.append(modified)
                 ct += 1
                 try:
                     ast.parse(line_stripped)
-                    output.append(six.u(''))
+                    output.append(u(''))
                 except Exception:
                     multiline = True
                     multiline_start = lineno
             else:
-                modified = six.u('%s %s') % (continuation, line)
+                modified = u('%s %s') % (continuation, line)
                 output.append(modified)
 
                 try:
@@ -594,7 +591,7 @@ class EmbeddedSphinxShell(object):
 
                         continue
 
-                    output.extend([continuation, six.u('')])
+                    output.extend([continuation, u('')])
                     multiline = False
                 except Exception:
                     pass
diff --git a/doc/sphinxext/numpydoc.py b/doc/sphinxext/numpydoc.py
index 4ddc12e4c..8857c1f80 100755
--- a/doc/sphinxext/numpydoc.py
+++ b/doc/sphinxext/numpydoc.py
@@ -17,13 +17,13 @@ It will:
 """
 
 import sphinx
-import six
 
 if sphinx.__version__ < '1.0.1':
     raise RuntimeError("Sphinx 1.0.1 or newer is required")
 
 import os, re, pydoc
 from .docscrape_sphinx import get_doc_object, SphinxDocString
+from pandas.util.compat import u, callable
 from sphinx.util.compat import Directive
 import inspect
 
@@ -35,28 +35,28 @@ def mangle_docstrings(app, what, name, obj, options, lines,
 
     if what == 'module':
         # Strip top title
-        title_re = re.compile(six.u(r'^\s*[#*=]{4,}\n[a-z0-9 -]+\n[#*=]{4,}\s*'),
+        title_re = re.compile(u(r'^\s*[#*=]{4,}\n[a-z0-9 -]+\n[#*=]{4,}\s*'),
                               re.I|re.S)
-        lines[:] = title_re.sub(six.u(''), six.u("\n").join(lines)).split(six.u("\n"))
+        lines[:] = title_re.sub(u(''), u("\n").join(lines)).split(u("\n"))
     else:
-        doc = get_doc_object(obj, what, six.u("\n").join(lines), config=cfg)
-        lines[:] = six.text_type(doc).split(six.u("\n"))
+        doc = get_doc_object(obj, what, u("\n").join(lines), config=cfg)
+        lines[:] = compat.text_type(doc).split(u("\n"))
 
     if app.config.numpydoc_edit_link and hasattr(obj, '__name__') and \
            obj.__name__:
         if hasattr(obj, '__module__'):
-            v = dict(full_name=six.u("%s.%s") % (obj.__module__, obj.__name__))
+            v = dict(full_name=u("%s.%s") % (obj.__module__, obj.__name__))
         else:
             v = dict(full_name=obj.__name__)
-        lines += [six.u(''), six.u('.. htmlonly::'), '']
-        lines += [six.u('    %s') % x for x in
+        lines += [u(''), u('.. htmlonly::'), '']
+        lines += [u('    %s') % x for x in
                   (app.config.numpydoc_edit_link % v).split("\n")]
 
     # replace reference numbers so that there are no duplicates
     references = []
     for line in lines:
         line = line.strip()
-        m = re.match(six.u(r'^.. \[([a-z0-9_.-])\]'), line, re.I)
+        m = re.match(u(r'^.. \[([a-z0-9_.-])\]'), line, re.I)
         if m:
             references.append(m.group(1))
 
@@ -65,14 +65,14 @@ def mangle_docstrings(app, what, name, obj, options, lines,
     if references:
         for i, line in enumerate(lines):
             for r in references:
-                if re.match(six.u(r'^\d+$'), r):
-                    new_r = six.u("R%d") % (reference_offset[0] + int(r))
+                if re.match(u(r'^\d+$'), r):
+                    new_r = u("R%d") % (reference_offset[0] + int(r))
                 else:
-                    new_r = six.u("%s%d") % (r, reference_offset[0])
-                lines[i] = lines[i].replace(six.u('[%s]_') % r,
-                                            six.u('[%s]_') % new_r)
-                lines[i] = lines[i].replace(six.u('.. [%s]') % r,
-                                            six.u('.. [%s]') % new_r)
+                    new_r = u("%s%d") % (r, reference_offset[0])
+                lines[i] = lines[i].replace(u('[%s]_') % r,
+                                            u('[%s]_') % new_r)
+                lines[i] = lines[i].replace(u('.. [%s]') % r,
+                                            u('.. [%s]') % new_r)
 
     reference_offset[0] += len(references)
 
@@ -83,13 +83,13 @@ def mangle_signature(app, what, name, obj, options, sig, retann):
         'initializes x; see ' in pydoc.getdoc(obj.__init__))):
         return '', ''
 
-    if not (six.callable(obj) or hasattr(obj, '__argspec_is_invalid_')): return
+    if not (callable(obj) or hasattr(obj, '__argspec_is_invalid_')): return
     if not hasattr(obj, '__doc__'): return
 
     doc = SphinxDocString(pydoc.getdoc(obj))
     if doc['Signature']:
-        sig = re.sub(six.u("^[^(]*"), six.u(""), doc['Signature'])
-        return sig, six.u('')
+        sig = re.sub(u("^[^(]*"), u(""), doc['Signature'])
+        return sig, u('')
 
 def setup(app, get_doc_object_=get_doc_object):
     global get_doc_object
diff --git a/doc/sphinxext/plot_directive.py b/doc/sphinxext/plot_directive.py
index 9c648f474..e48899a06 100755
--- a/doc/sphinxext/plot_directive.py
+++ b/doc/sphinxext/plot_directive.py
@@ -75,13 +75,11 @@ TODO
 
 """
 
-from pandas.util.py3compat import range
+from pandas.util.compat import range, cStringIO as StringIO, map
 import sys, os, glob, shutil, imp, warnings, re, textwrap, traceback
-from pandas.util.py3compat import cStringIO as StringIO
 import sphinx
 
 import warnings
-from pandas.util.py3compat import map
 warnings.warn("A plot_directive module is also available under "
               "matplotlib.sphinxext; expect this numpydoc.plot_directive "
               "module to be deprecated after relevant features have been "
diff --git a/doc/sphinxext/tests/test_docscrape.py b/doc/sphinxext/tests/test_docscrape.py
index 1abf11b77..e9de8cf63 100755
--- a/doc/sphinxext/tests/test_docscrape.py
+++ b/doc/sphinxext/tests/test_docscrape.py
@@ -2,12 +2,12 @@ from __future__ import print_function
 # -*- encoding:utf-8 -*-
 
 import sys, os
-import six
 sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
 
 from docscrape import NumpyDocString, FunctionDoc, ClassDoc
 from docscrape_sphinx import SphinxDocString, SphinxClassDoc
 from nose.tools import *
+from pandas.util.compat import u
 
 doc_txt = '''\
   numpy.multivariate_normal(mean, cov, shape=None)
@@ -289,7 +289,7 @@ of the one-dimensional normal distribution to higher dimensions.
         The drawn samples, arranged according to `shape`.  If the
         shape given is (m,n,...), then the shape of `out` is is
         (m,n,...,N).
-        
+
         In other words, each entry ``out[i,j,...,:]`` is an N-dimensional
         value drawn from the distribution.
 
@@ -298,12 +298,12 @@ of the one-dimensional normal distribution to higher dimensions.
     Certain warnings apply.
 
 .. seealso::
-    
+
     :obj:`some`, :obj:`other`, :obj:`funcs`
-    
+
     :obj:`otherfunc`
         relationship
-    
+
 .. rubric:: Notes
 
 Instead of specifying the full covariance matrix, popular
@@ -350,7 +350,7 @@ standard deviation:
 [True, True]
 """)
 
-       
+
 doc2 = NumpyDocString("""
     Returns array of indices of the maximum values of along the given axis.
 
@@ -493,7 +493,7 @@ def test_unicode():
         äää
 
     """)
-    assert doc['Summary'][0] == six.u('öäöäöäöäöåååå').encode('utf-8')
+    assert doc['Summary'][0] == u('öäöäöäöäöåååå').encode('utf-8')
 
 def test_plot_examples():
     cfg = dict(use_plots=True)
@@ -511,7 +511,7 @@ def test_plot_examples():
     Examples
     --------
     .. plot::
-    
+
        import matplotlib.pyplot as plt
        plt.plot([1,2,3],[4,5,6])
        plt.show()
diff --git a/doc/sphinxext/traitsdoc.py b/doc/sphinxext/traitsdoc.py
index 0298a441e..2c74e70bb 100755
--- a/doc/sphinxext/traitsdoc.py
+++ b/doc/sphinxext/traitsdoc.py
@@ -18,6 +18,7 @@ import inspect
 import os
 import pydoc
 
+from pandas.util.compat import callable
 from . import docscrape
 from . import docscrape_sphinx
 from .docscrape_sphinx import SphinxClassDoc, SphinxFunctionDoc, SphinxDocString
@@ -117,7 +118,7 @@ def get_doc_object(obj, what=None, config=None):
             what = 'class'
         elif inspect.ismodule(obj):
             what = 'module'
-        elif six.callable(obj):
+        elif callable(obj):
             what = 'function'
         else:
             what = 'object'
diff --git a/examples/finance.py b/examples/finance.py
index a8fb580f9..f795b0c72 100644
--- a/examples/finance.py
+++ b/examples/finance.py
@@ -3,7 +3,7 @@ Some examples playing around with yahoo finance data
 """
 
 from datetime import datetime
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip
 
 import matplotlib.finance as fin
 import numpy as np
diff --git a/pandas/compat/scipy.py b/pandas/compat/scipy.py
index 53436c517..7b357e2ff 100644
--- a/pandas/compat/scipy.py
+++ b/pandas/compat/scipy.py
@@ -2,7 +2,7 @@
 Shipping functions from SciPy to reduce dependency on having SciPy installed
 """
 
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import numpy as np
 
 
diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 21b6f3289..95bc7351a 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -4,11 +4,11 @@ intended for public consumption
 """
 
 import numpy as np
-import six
 
 import pandas.core.common as com
 import pandas.algos as algos
 import pandas.hashtable as htable
+import pandas.util.compat as compat
 
 
 def match(to_match, values, na_sentinel=-1):
@@ -32,7 +32,7 @@ def match(to_match, values, na_sentinel=-1):
     match : ndarray of integers
     """
     values = com._asarray_tuplesafe(values)
-    if issubclass(values.dtype.type, six.string_types):
+    if issubclass(values.dtype.type, compat.string_types):
         values = np.array(values, dtype='O')
 
     f = lambda htype, caster: _match_generic(to_match, values, htype, caster)
diff --git a/pandas/core/array.py b/pandas/core/array.py
index 842bbdbf1..c9a8a00b7 100644
--- a/pandas/core/array.py
+++ b/pandas/core/array.py
@@ -3,7 +3,6 @@ Isolate pandas's exposure to NumPy
 """
 
 import numpy as np
-import six
 
 Array = np.ndarray
 
diff --git a/pandas/core/base.py b/pandas/core/base.py
index 6122e78fa..1f3cb7f9e 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -1,7 +1,7 @@
 """
 Base class(es) for all pandas objects.
 """
-from pandas.util import py3compat
+from pandas.util import compat
 
 class StringMixin(object):
     """implements string methods so long as object defines a `__unicode__` method.
@@ -15,7 +15,7 @@ class StringMixin(object):
         Yields Bytestring in Py2, Unicode String in py3.
         """
 
-        if py3compat.PY3:
+        if compat.PY3:
             return self.__unicode__()
         return self.__bytes__()
 
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 3af0d7dba..2fdfe90f7 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -14,10 +14,8 @@ import pandas.algos as algos
 import pandas.lib as lib
 import pandas.tslib as tslib
 
-from pandas.util import py3compat
-from pandas.util.py3compat import StringIO, BytesIO, range, long
-from pandas.util.py3compat import zip, map
-import six
+from pandas.util import compat
+from pandas.util.compat import StringIO, BytesIO, range, long, u, zip, map
 
 
 from pandas.core.config import get_option
@@ -689,7 +687,7 @@ def _infer_dtype_from_scalar(val):
         dtype = val.dtype
         val   = val.item()
 
-    elif isinstance(val, six.string_types):
+    elif isinstance(val, compat.string_types):
 
         # If we create an empty array using a string to infer
         # the dtype, NumPy will only allocate one character per entry
@@ -782,7 +780,7 @@ def _maybe_promote(dtype, fill_value=np.nan):
         dtype = np.object_
 
     # in case we have a string that looked like a number
-    if issubclass(np.dtype(dtype).type, six.string_types):
+    if issubclass(np.dtype(dtype).type, compat.string_types):
         dtype = np.object_
 
     return dtype, fill_value
@@ -1169,7 +1167,7 @@ def _possibly_cast_to_datetime(value, dtype, coerce = False):
     """ try to cast the array/value to a datetimelike dtype, converting float nan to iNaT """
 
     if dtype is not None:
-        if isinstance(dtype, six.string_types):
+        if isinstance(dtype, compat.string_types):
             dtype = np.dtype(dtype)
 
         is_datetime64  = is_datetime64_dtype(dtype)
@@ -1339,7 +1337,7 @@ def _join_unicode(lines, sep=''):
     try:
         return sep.join(lines)
     except UnicodeDecodeError:
-        sep = six.text_type(sep)
+        sep = compat.text_type(sep)
         return sep.join([x.decode('utf-8') if isinstance(x, str) else x
                          for x in lines])
 
@@ -1479,7 +1477,7 @@ def _asarray_tuplesafe(values, dtype=None):
 
     result = np.asarray(values, dtype=dtype)
 
-    if issubclass(result.dtype.type, six.string_types):
+    if issubclass(result.dtype.type, compat.string_types):
         result = np.asarray(values, dtype=object)
 
     if result.ndim == 2:
@@ -1495,7 +1493,7 @@ def _asarray_tuplesafe(values, dtype=None):
 
 
 def _index_labels_to_array(labels):
-    if isinstance(labels, (six.string_types, tuple)):
+    if isinstance(labels, (compat.string_types, tuple)):
         labels = [labels]
 
     if not isinstance(labels, (list, np.ndarray)):
@@ -1610,13 +1608,13 @@ def is_re_compilable(obj):
 
 
 def is_list_like(arg):
-    return hasattr(arg, '__iter__') and not isinstance(arg, six.string_types)
+    return hasattr(arg, '__iter__') and not isinstance(arg, compat.string_types)
 
 def _is_sequence(x):
     try:
         iter(x)
         len(x) # it has a length
-        return not isinstance(x, six.string_types) and True
+        return not isinstance(x, compat.string_types) and True
     except Exception:
         return False
 
@@ -1650,7 +1648,7 @@ def _astype_nansafe(arr, dtype, copy = True):
             return arr.astype(object)
 
         # in py3, timedelta64[ns] are int64
-        elif (py3compat.PY3 and dtype not in [_INT64_DTYPE,_TD_DTYPE]) or (not py3compat.PY3 and dtype != _TD_DTYPE):
+        elif (compat.PY3 and dtype not in [_INT64_DTYPE,_TD_DTYPE]) or (not compat.PY3 and dtype != _TD_DTYPE):
             raise TypeError("cannot astype a timedelta from [%s] to [%s]" % (arr.dtype,dtype))
         return arr.astype(_TD_DTYPE)
     elif (np.issubdtype(arr.dtype, np.floating) and
@@ -1725,7 +1723,7 @@ def _get_handle(path, mode, encoding=None, compression=None):
             raise ValueError('Unrecognized compression type: %s' %
                              compression)
 
-    if py3compat.PY3:  # pragma: no cover
+    if compat.PY3:  # pragma: no cover
         if encoding:
             f = open(path, mode, encoding=encoding)
         else:
@@ -1734,7 +1732,7 @@ def _get_handle(path, mode, encoding=None, compression=None):
         f = open(path, mode)
     return f
 
-if py3compat.PY3:  # pragma: no cover
+if compat.PY3:  # pragma: no cover
     def UnicodeReader(f, dialect=csv.excel, encoding="utf-8", **kwds):
         # ignore encoding
         return csv.reader(f, dialect=dialect, **kwds)
@@ -1757,7 +1755,7 @@ else:
 
         def next(self):
             row = next(self.reader)
-            return [six.text_type(s, "utf-8") for s in row]
+            return [compat.text_type(s, "utf-8") for s in row]
 
         # python 3 iterator
         __next__ = next
@@ -1958,9 +1956,9 @@ def _pprint_seq(seq, _nest_lvl=0, **kwds):
     bounds length of printed sequence, depending on options
     """
     if isinstance(seq,set):
-        fmt = six.u("set([%s])")
+        fmt = u("set([%s])")
     else:
-        fmt = six.u("[%s]") if hasattr(seq, '__setitem__') else six.u("(%s)")
+        fmt = u("[%s]") if hasattr(seq, '__setitem__') else u("(%s)")
 
     nitems = get_option("max_seq_items") or len(seq)
 
@@ -1983,10 +1981,10 @@ def _pprint_dict(seq, _nest_lvl=0,**kwds):
     internal. pprinter for iterables. you should probably use pprint_thing()
     rather then calling this directly.
     """
-    fmt = six.u("{%s}")
+    fmt = u("{%s}")
     pairs = []
 
-    pfmt = six.u("%s: %s")
+    pfmt = u("%s: %s")
 
     nitems = get_option("max_seq_items") or len(seq)
 
@@ -2032,7 +2030,7 @@ def pprint_thing(thing, _nest_lvl=0, escape_chars=None, default_escapes=False,
         #should deal with it himself.
 
         try:
-            result = six.text_type(thing)  # we should try this first
+            result = compat.text_type(thing)  # we should try this first
         except UnicodeDecodeError:
             # either utf-8 or we replace errors
             result = str(thing).decode('utf-8', "replace")
@@ -2052,11 +2050,11 @@ def pprint_thing(thing, _nest_lvl=0, escape_chars=None, default_escapes=False,
         for c in escape_chars:
             result = result.replace(c, translate[c])
 
-        return six.text_type(result)
+        return compat.text_type(result)
 
-    if (py3compat.PY3 and hasattr(thing, '__next__')) or \
+    if (compat.PY3 and hasattr(thing, '__next__')) or \
             hasattr(thing, 'next'):
-        return six.text_type(thing)
+        return compat.text_type(thing)
     elif (isinstance(thing, dict) and
           _nest_lvl < get_option("display.pprint_nest_depth")):
         result = _pprint_dict(thing, _nest_lvl,quote_strings=True)
@@ -2064,8 +2062,8 @@ def pprint_thing(thing, _nest_lvl=0, escape_chars=None, default_escapes=False,
             get_option("display.pprint_nest_depth"):
         result = _pprint_seq(thing, _nest_lvl, escape_chars=escape_chars,
                              quote_strings=quote_strings)
-    elif isinstance(thing,six.string_types) and quote_strings:
-        if py3compat.PY3:
+    elif isinstance(thing,compat.string_types) and quote_strings:
+        if compat.PY3:
             fmt = "'%s'"
         else:
             fmt = "u'%s'"
@@ -2073,7 +2071,7 @@ def pprint_thing(thing, _nest_lvl=0, escape_chars=None, default_escapes=False,
     else:
         result = as_escaped_unicode(thing)
 
-    return six.text_type(result)  # always unicode
+    return compat.text_type(result)  # always unicode
 
 
 def pprint_thing_encoded(object, encoding='utf-8', errors='replace', **kwds):
diff --git a/pandas/core/config.py b/pandas/core/config.py
index 26fda8d3d..d55888bc1 100644
--- a/pandas/core/config.py
+++ b/pandas/core/config.py
@@ -52,8 +52,8 @@ import re
 
 from collections import namedtuple
 import warnings
-import six
-from pandas.util.py3compat import map, lmap
+from pandas.util.compat import map, lmap, u
+import pandas.util.compat as compat
 
 DeprecatedOption = namedtuple('DeprecatedOption', 'key msg rkey removal_ver')
 RegisteredOption = namedtuple(
@@ -149,7 +149,7 @@ def _describe_option(pat='', _print_desc=True):
     if len(keys) == 0:
         raise KeyError('No such keys(s)')
 
-    s = six.u('')
+    s = u('')
     for k in keys:  # filter by pat
         s += _build_option_description(k)
 
@@ -588,9 +588,9 @@ def _build_option_description(k):
     o = _get_registered_option(k)
     d = _get_deprecated_option(k)
 
-    s = six.u('%s: ') % k
+    s = u('%s: ') % k
     if o:
-        s += six.u('[default: %s] [currently: %s]') % (o.defval, _get_option(k, True))
+        s += u('[default: %s] [currently: %s]') % (o.defval, _get_option(k, True))
 
     if o.doc:
         s += '\n' + '\n    '.join(o.doc.strip().split('\n'))
@@ -598,9 +598,9 @@ def _build_option_description(k):
         s += 'No description available.\n'
 
     if d:
-        s += six.u('\n\t(Deprecated')
-        s += (six.u(', use `%s` instead.') % d.rkey if d.rkey else '')
-        s += six.u(')\n')
+        s += u('\n\t(Deprecated')
+        s += (u(', use `%s` instead.') % d.rkey if d.rkey else '')
+        s += u(')\n')
 
     s += '\n'
     return s
@@ -757,5 +757,5 @@ is_int = is_type_factory(int)
 is_bool = is_type_factory(bool)
 is_float = is_type_factory(float)
 is_str = is_type_factory(str)
-is_unicode = is_type_factory(six.text_type)
+is_unicode = is_type_factory(compat.text_type)
 is_text = is_instance_factory((str, bytes))
diff --git a/pandas/core/format.py b/pandas/core/format.py
index 150eade61..1381d4e2e 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -3,13 +3,11 @@ from __future__ import print_function
 
 from pandas.util import compat
 import sys
-import six
 
-from pandas.util.py3compat import StringIO, lzip, range, map, zip, reduce
+from pandas.util.compat import StringIO, lzip, range, map, zip, reduce, u, OrderedDict
 from pandas.core.common import adjoin, isnull, notnull
 from pandas.core.index import Index, MultiIndex, _ensure_index
-from pandas.util import py3compat
-from pandas.util.compat import OrderedDict
+from pandas.util import compat
 from pandas.util.terminal import get_terminal_size
 from pandas.core.config import get_option, set_option, reset_option
 import pandas.core.common as com
@@ -81,7 +79,7 @@ class SeriesFormatter(object):
         self.dtype  = dtype
 
     def _get_footer(self):
-        footer = six.u('')
+        footer = u('')
 
         if self.name:
             if getattr(self.series.index, 'freq', None):
@@ -106,7 +104,7 @@ class SeriesFormatter(object):
                     footer += ', '
                 footer += 'dtype: %s' % com.pprint_thing(self.series.dtype.name)
 
-        return six.text_type(footer)
+        return compat.text_type(footer)
 
     def _get_formatted_index(self):
         index = self.series.index
@@ -129,7 +127,7 @@ class SeriesFormatter(object):
         series = self.series
 
         if len(series) == 0:
-            return six.u('')
+            return u('')
 
         fmt_index, have_header = self._get_formatted_index()
         fmt_values = self._get_formatted_values()
@@ -149,10 +147,10 @@ class SeriesFormatter(object):
         if footer:
             result.append(footer)
 
-        return six.text_type(six.u('\n').join(result))
+        return compat.text_type(u('\n').join(result))
 
 def _strlen_func():
-    if py3compat.PY3:  # pragma: no cover
+    if compat.PY3:  # pragma: no cover
         _strlen = len
     else:
         encoding = get_option("display.encoding")
@@ -283,7 +281,7 @@ class DataFrameFormatter(TableFormatter):
         frame = self.frame
 
         if len(frame.columns) == 0 or len(frame.index) == 0:
-            info_line = (six.u('Empty %s\nColumns: %s\nIndex: %s')
+            info_line = (u('Empty %s\nColumns: %s\nIndex: %s')
                          % (type(self.frame).__name__,
                             com.pprint_thing(frame.columns),
                             com.pprint_thing(frame.index)))
@@ -345,7 +343,7 @@ class DataFrameFormatter(TableFormatter):
         frame = self.frame
 
         if len(frame.columns) == 0 or len(frame.index) == 0:
-            info_line = (six.u('Empty %s\nColumns: %s\nIndex: %s')
+            info_line = (u('Empty %s\nColumns: %s\nIndex: %s')
                          % (type(self.frame).__name__,
                             frame.columns, frame.index))
             strcols = [[info_line]]
@@ -358,7 +356,7 @@ class DataFrameFormatter(TableFormatter):
                 column_format = 'l%s' % ''.join(map(get_col_type, dtypes))
             else:
                 column_format = '%s' % ''.join(map(get_col_type, dtypes))
-        elif not isinstance(column_format, six.string_types):
+        elif not isinstance(column_format, compat.string_types):
             raise AssertionError(('column_format must be str or unicode, not %s'
                                   % type(column_format)))
 
@@ -381,7 +379,7 @@ class DataFrameFormatter(TableFormatter):
 
         if hasattr(self.buf, 'write'):
             write(self.buf, frame, column_format, strcols)
-        elif isinstance(self.buf, six.string_types):
+        elif isinstance(self.buf, compat.string_types):
             with open(self.buf, 'w') as f:
                 write(f, frame, column_format, strcols)
         else:
@@ -402,7 +400,7 @@ class DataFrameFormatter(TableFormatter):
         html_renderer = HTMLFormatter(self, classes=classes)
         if hasattr(self.buf, 'write'):
             html_renderer.write_result(self.buf)
-        elif isinstance(self.buf, six.string_types):
+        elif isinstance(self.buf, compat.string_types):
             with open(self.buf, 'w') as f:
                 html_renderer.write_result(f)
         else:
@@ -1834,9 +1832,9 @@ class EngFormatter(object):
         mant = sign * dnum / (10 ** pow10)
 
         if self.accuracy is None:  # pragma: no cover
-            format_str = six.u("% g%s")
+            format_str = u("% g%s")
         else:
-            format_str = (six.u("%% .%if%%s") % self.accuracy)
+            format_str = (u("%% .%if%%s") % self.accuracy)
 
         formatted = format_str % (mant, prefix)
 
@@ -1862,8 +1860,8 @@ def set_eng_float_format(precision=None, accuracy=3, use_eng_prefix=False):
 
 
 def _put_lines(buf, lines):
-    if any(isinstance(x, six.text_type) for x in lines):
-        lines = [six.text_type(x) for x in lines]
+    if any(isinstance(x, compat.text_type) for x in lines):
+        lines = [compat.text_type(x) for x in lines]
     buf.write('\n'.join(lines))
 
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 827ebc53d..080abe8b0 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -12,7 +12,7 @@ labeling information
 # pylint: disable=E1101,E1103
 # pylint: disable=W0212,W0231,W0703,W0622
 
-from pandas.util.py3compat import range, zip, lrange, lmap, lzip, StringIO
+from pandas.util.compat import range, zip, lrange, lmap, lzip, StringIO, u, OrderedDict
 from pandas.util import compat
 import operator
 import sys
@@ -36,8 +36,7 @@ from pandas.core.internals import (BlockManager,
 from pandas.core.series import Series, _radd_compat
 import pandas.core.expressions as expressions
 from pandas.compat.scipy import scoreatpercentile as _quantile
-from pandas.util.compat import OrderedDict
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.util.terminal import get_terminal_size
 from pandas.util.decorators import deprecate, Appender, Substitution
 
@@ -56,7 +55,6 @@ import pandas.tslib as tslib
 import pandas.algos as _algos
 
 from pandas.core.config import get_option, set_option
-import six
 
 #----------------------------------------------------------------------
 # Docstring templates
@@ -440,7 +438,7 @@ class DataFrame(NDFrame):
                                   'incompatible data and dtype')
 
             if arr.ndim == 0 and index is not None and columns is not None:
-                if isinstance(data, six.string_types) and dtype is None:
+                if isinstance(data, compat.string_types) and dtype is None:
                     dtype = np.object_
                 if dtype is None:
                     dtype, data = _infer_dtype_from_scalar(data)
@@ -656,7 +654,7 @@ class DataFrame(NDFrame):
         Invoked by unicode(df) in py2 only. Yields a Unicode String in both
         py2/py3.
         """
-        buf = StringIO(six.u(""))
+        buf = StringIO(u(""))
         fits_vertical = self._repr_fits_vertical_()
         fits_horizontal = False
         if fits_vertical:
@@ -683,7 +681,7 @@ class DataFrame(NDFrame):
                 self.info(buf=buf, verbose=verbose)
 
         value = buf.getvalue()
-        if not isinstance(value, six.text_type):
+        if not isinstance(value, compat.text_type):
             raise AssertionError()
 
         return value
@@ -715,7 +713,7 @@ class DataFrame(NDFrame):
                         'max-width:1500px;overflow:auto;">\n' +
                         self.to_html() + '\n</div>')
             else:
-                buf = StringIO(six.u(""))
+                buf = StringIO(u(""))
                 max_info_rows = get_option('display.max_info_rows')
                 verbose = (max_info_rows is None or
                            self.shape[0] <= max_info_rows)
@@ -789,7 +787,7 @@ class DataFrame(NDFrame):
         return zip(*arrays)
 
     iterkv = iteritems
-    if py3compat.PY3:  # pragma: no cover
+    if compat.PY3:  # pragma: no cover
         items = iteritems
 
     def __len__(self):
@@ -851,7 +849,7 @@ class DataFrame(NDFrame):
     __xor__ = _arith_method(operator.xor, '__xor__')
 
     # Python 2 division methods
-    if not py3compat.PY3:
+    if not compat.PY3:
         __div__ = _arith_method(operator.div, '__div__', '/',
                                 default_axis=None, fill_zeros=np.inf, truediv=False)
         __rdiv__ = _arith_method(lambda x, y: y / x, '__rdiv__',
@@ -1028,7 +1026,7 @@ class DataFrame(NDFrame):
                 return cls()
 
             try:
-                if py3compat.PY3:
+                if compat.PY3:
                     first_row = next(data)
                 else:
                     first_row = next(data)
@@ -1093,7 +1091,7 @@ class DataFrame(NDFrame):
 
         result_index = None
         if index is not None:
-            if (isinstance(index, six.string_types) or
+            if (isinstance(index, compat.string_types) or
                     not hasattr(index, "__iter__")):
                 i = columns.get_loc(index)
                 exclude.add(index)
@@ -1452,7 +1450,7 @@ class DataFrame(NDFrame):
         """
         from pandas.io.excel import ExcelWriter
         need_save = False
-        if isinstance(excel_writer, six.string_types):
+        if isinstance(excel_writer, compat.string_types):
             excel_writer = ExcelWriter(excel_writer)
             need_save = True
 
@@ -3028,7 +3026,7 @@ class DataFrame(NDFrame):
         if items is not None:
             return self.reindex(columns=[r for r in items if r in self])
         elif like:
-            matchf = lambda x: (like in x if isinstance(x, six.string_types)
+            matchf = lambda x: (like in x if isinstance(x, compat.string_types)
                                 else like in str(x))
             return self.select(matchf, axis=1)
         elif regex:
@@ -3150,7 +3148,7 @@ class DataFrame(NDFrame):
         if cols is None:
             values = list(_m8_to_i8(self.values.T))
         else:
-            if np.iterable(cols) and not isinstance(cols, six.string_types):
+            if np.iterable(cols) and not isinstance(cols, compat.string_types):
                 if isinstance(cols, tuple):
                     if cols in self.columns:
                         values = [self[cols]]
@@ -4313,7 +4311,7 @@ class DataFrame(NDFrame):
 
         offset = _resolve_offset(freq, kwds)
 
-        if isinstance(offset, six.string_types):
+        if isinstance(offset, compat.string_types):
             offset = datetools.to_offset(offset)
 
         if offset is None:
@@ -4945,7 +4943,7 @@ class DataFrame(NDFrame):
         # python 2.5
         mask = notnull(frame.values).view(np.uint8)
 
-        if isinstance(level, six.string_types):
+        if isinstance(level, compat.string_types):
             level = self.index._get_level_number(level)
 
         level_index = frame.index.levels[level]
@@ -5994,7 +5992,7 @@ def install_ipython_completers():  # pragma: no cover
     @complete_object.when_type(DataFrame)
     def complete_dataframe(obj, prev_completions):
         return prev_completions + [c for c in obj.columns
-                                   if isinstance(c, six.string_types) and py3compat.isidentifier(c)]
+                                   if isinstance(c, compat.string_types) and compat.isidentifier(c)]
 
 
 # Importing IPython brings in about 200 modules, so we want to avoid it unless
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index d7fc4ce21..c4be0fc35 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -10,8 +10,7 @@ import pandas.core.indexing as indexing
 from pandas.core.indexing import _maybe_convert_indices
 from pandas.tseries.index import DatetimeIndex
 import pandas.core.common as com
-import six
-from pandas.util.py3compat import map, zip
+from pandas.util.compat import map, zip
 
 
 class PandasError(Exception):
@@ -80,7 +79,7 @@ class PandasContainer(PandasObject):
 
     def _get_axis_name(self, axis):
         axis = self._AXIS_ALIASES.get(axis, axis)
-        if isinstance(axis, six.string_types):
+        if isinstance(axis, compat.string_types):
             if axis in self._AXIS_NUMBERS:
                 return axis
         else:
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index f65d10730..ed0636259 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1,11 +1,10 @@
 import types
 import numpy as np
 
-import six
-from pandas.util.py3compat import range, long, lrange, lzip
-from pandas.util.compat import OrderedDict
+from pandas.util.compat import(
+    zip, builtins, range, long, lrange, lzip, OrderedDict, callable
+)
 from pandas.util import compat
-from pandas.util.py3compat import zip, builtins
 
 from pandas.core.base import PandasObject
 from pandas.core.categorical import Categorical
@@ -1261,7 +1260,7 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
 
     if level is not None:
         if not isinstance(group_axis, MultiIndex):
-            if isinstance(level, six.string_types):
+            if isinstance(level, compat.string_types):
                 if obj.index.name != level:
                     raise ValueError('level name %s is not the name of the index' % level)
             elif level > 0:
@@ -1283,7 +1282,7 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
 
     # what are we after, exactly?
     match_axis_length = len(keys) == len(group_axis)
-    any_callable = any(six.callable(g) or isinstance(g, dict) for g in keys)
+    any_callable = any(callable(g) or isinstance(g, dict) for g in keys)
     any_arraylike = any(isinstance(g, (list, tuple, np.ndarray))
                         for g in keys)
 
@@ -1338,7 +1337,7 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
 
 
 def _is_label_like(val):
-    return isinstance(val, six.string_types) or np.isscalar(val)
+    return isinstance(val, compat.string_types) or np.isscalar(val)
 
 
 def _convert_grouper(axis, grouper):
@@ -1410,7 +1409,7 @@ class SeriesGroupBy(GroupBy):
         -------
         Series or DataFrame
         """
-        if isinstance(func_or_funcs, six.string_types):
+        if isinstance(func_or_funcs, compat.string_types):
             return getattr(self, func_or_funcs)(*args, **kwargs)
 
         if hasattr(func_or_funcs, '__iter__'):
@@ -1450,7 +1449,7 @@ class SeriesGroupBy(GroupBy):
             # list of functions / function names
             columns = []
             for f in arg:
-                if isinstance(f, six.string_types):
+                if isinstance(f, compat.string_types):
                     columns.append(f)
                 else:
                     columns.append(f.__name__)
@@ -1538,7 +1537,7 @@ class SeriesGroupBy(GroupBy):
             result = result.values
         dtype = result.dtype
 
-        if isinstance(func, six.string_types):
+        if isinstance(func, compat.string_types):
             wrapper = lambda x: getattr(x, func)(*args, **kwargs)
         else:
             wrapper = lambda x: func(x, *args, **kwargs)
@@ -1580,7 +1579,7 @@ class SeriesGroupBy(GroupBy):
         -------
         filtered : Series
         """
-        if isinstance(func, six.string_types):
+        if isinstance(func, compat.string_types):
             wrapper = lambda x: getattr(x, func)(*args, **kwargs)
         else:
             wrapper = lambda x: func(x, *args, **kwargs)
@@ -1694,7 +1693,7 @@ class NDFrameGroupBy(GroupBy):
 
     @Appender(_agg_doc)
     def aggregate(self, arg, *args, **kwargs):
-        if isinstance(arg, six.string_types):
+        if isinstance(arg, compat.string_types):
             return getattr(self, arg)(*args, **kwargs)
 
         result = OrderedDict()
@@ -2002,7 +2001,7 @@ class NDFrameGroupBy(GroupBy):
         return concatenated
 
     def _define_paths(self, func, *args, **kwargs):
-        if isinstance(func, six.string_types):
+        if isinstance(func, compat.string_types):
             fast_path = lambda group: getattr(group, func)(*args, **kwargs)
             slow_path = lambda group: group.apply(lambda x: getattr(x, func)(*args, **kwargs), axis=self.axis)
         else:
@@ -2253,7 +2252,7 @@ class PanelGroupBy(NDFrameGroupBy):
         -------
         aggregated : Panel
         """
-        if isinstance(arg, six.string_types):
+        if isinstance(arg, compat.string_types):
             return getattr(self, arg)(*args, **kwargs)
 
         return self._aggregate_generic(arg, *args, **kwargs)
@@ -2656,7 +2655,7 @@ def numpy_groupby(data, labels, axis=0):
 # Helper functions
 
 
-from pandas.util import py3compat
+from pandas.util import compat
 import sys
 
 
@@ -2668,7 +2667,7 @@ def install_ipython_completers():  # pragma: no cover
     @complete_object.when_type(DataFrameGroupBy)
     def complete_dataframe(obj, prev_completions):
         return prev_completions + [c for c in obj.obj.columns
-                                   if isinstance(c, six.string_types) and py3compat.isidentifier(c)]
+                                   if isinstance(c, compat.string_types) and compat.isidentifier(c)]
 
 
 # Importing IPython brings in about 200 modules, so we want to avoid it unless
diff --git a/pandas/core/index.py b/pandas/core/index.py
index c54aa895f..713400619 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1,7 +1,6 @@
 # pylint: disable=E1101,E1103,W0232
 
-from pandas.util.py3compat import range, zip, lrange, lzip
-import six
+from pandas.util.compat import range, zip, lrange, lzip
 from pandas.util import compat
 import numpy as np
 
@@ -1350,7 +1349,7 @@ class Int64Index(Index):
                 data = list(data)
             data = np.asarray(data)
 
-        if issubclass(data.dtype.type, six.string_types):
+        if issubclass(data.dtype.type, compat.string_types):
             raise TypeError('String dtype not supported, you may need '
                             'to explicitly cast to int')
         elif issubclass(data.dtype.type, np.integer):
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 1518aa3c9..2ad006123 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -3,10 +3,9 @@
 from datetime import datetime
 from pandas.core.common import _asarray_tuplesafe
 from pandas.core.index import Index, MultiIndex, _ensure_index
-from pandas.util.py3compat import range
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, zip
+import pandas.util.compat as compat
 import pandas.core.common as com
-import six
 import pandas.lib as lib
 
 import numpy as np
@@ -923,7 +922,7 @@ def _convert_to_index_sliceable(obj, key):
             indexer = obj.ix._convert_to_indexer(key, axis=0)
         return indexer
 
-    elif isinstance(key, six.string_types):
+    elif isinstance(key, compat.string_types):
 
         # we are an actual column
         if key in obj._data.items:
@@ -1080,7 +1079,7 @@ def _is_label_like(key):
 def _is_list_like(obj):
     # Consider namedtuples to be not list like as they are useful as indices
     return (np.iterable(obj)
-            and not isinstance(obj, six.string_types)
+            and not isinstance(obj, compat.string_types)
             and not (isinstance(obj, tuple) and type(obj) is not tuple))
 
 
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 21cfa8658..ca1200b87 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -1,6 +1,5 @@
 import itertools
 import re
-import six
 from datetime import datetime
 
 from numpy import nan
@@ -18,9 +17,8 @@ import pandas.tslib as tslib
 import pandas.core.expressions as expressions
 
 from pandas.tslib import Timestamp
-from pandas.util import py3compat
-from pandas.util.py3compat import range, lrange, lmap
-from pandas.util.py3compat import map, zip
+from pandas.util import compat
+from pandas.util.compat import range, lrange, lmap, callable, map, zip
 
 
 class Block(PandasObject):
@@ -689,7 +687,7 @@ class ObjectBlock(Block):
     _can_hold_na = True
 
     def __init__(self, values, items, ref_items, ndim=2, fastpath=False, placement=None):
-        if issubclass(values.dtype.type, six.string_types):
+        if issubclass(values.dtype.type, compat.string_types):
             values = np.array(values, dtype=object)
 
         super(ObjectBlock, self).__init__(values, items, ref_items,
@@ -815,7 +813,7 @@ class ObjectBlock(Block):
 
         # deal with replacing values with objects (strings) that match but
         # whose replacement is not a string (numeric, nan, object)
-        if isnull(value) or not isinstance(value, six.string_types):
+        if isnull(value) or not isinstance(value, compat.string_types):
             def re_replacer(s):
                 try:
                     return value if rx.search(s) is not None else s
@@ -1269,7 +1267,7 @@ class BlockManager(PandasObject):
                 if not blk.items.isin(filter).any():
                     result_blocks.append(blk)
                     continue
-            if six.callable(f):
+            if callable(f):
                 applied = f(blk, *args, **kwargs)
             else:
                 applied = getattr(blk,f)(*args, **kwargs)
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 937235730..20fcc1430 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -12,8 +12,7 @@ import pandas.algos as algos
 import pandas.hashtable as _hash
 import pandas.tslib as tslib
 
-from pandas.util.py3compat import builtins
-import six
+from pandas.util.compat import builtins
 
 
 try:
@@ -35,7 +34,7 @@ class disallow(object):
     def __call__(self, f):
         @functools.wraps(f)
         def _f(*args, **kwargs):
-            obj_iter = itertools.chain(args, six.itervalues(kwargs))
+            obj_iter = itertools.chain(args, compat.itervalues(kwargs))
             if any(self.check(obj) for obj in obj_iter):
                 raise TypeError('reduction operation {0!r} not allowed for '
                                 'this dtype'.format(f.__name__.replace('nan',
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 35e5d1e23..29a8ecf94 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -3,7 +3,7 @@ Contains data structures designed for manipulating panel (3-dimensional) data
 """
 # pylint: disable=E1103,W0231,W0212,W0621
 
-from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.compat import map, zip, range, lrange, lmap, u, OrderedDict, OrderedDefaultdict
 from pandas.util import compat
 import operator
 import sys
@@ -22,13 +22,11 @@ from pandas.core.internals import (BlockManager,
 from pandas.core.series import Series
 from pandas.core.frame import DataFrame
 from pandas.core.generic import NDFrame
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.util.decorators import deprecate, Appender, Substitution
 import pandas.core.common as com
 import pandas.core.nanops as nanops
 import pandas.lib as lib
-import six
-from pandas.util.py3compat import map, zip
 
 
 def _ensure_like_indices(time, panels):
@@ -227,7 +225,7 @@ class Panel(NDFrame):
     __rfloordiv__ = _arith_method(lambda x, y: y // x, '__rfloordiv__')
     __rpow__ = _arith_method(lambda x, y: y ** x, '__rpow__')
 
-    if not py3compat.PY3:
+    if not compat.PY3:
         __div__ = _arith_method(operator.div, '__div__')
         __rdiv__ = _arith_method(lambda x, y: y / x, '__rdiv__')
 
@@ -275,7 +273,6 @@ class Panel(NDFrame):
             return cls(data, **d)
 
     def _init_dict(self, data, axes, dtype=None):
-        from pandas.util.compat import OrderedDict
         haxis = axes.pop(self._het_axis)
 
         # prefilter if haxis passed
@@ -347,7 +344,6 @@ class Panel(NDFrame):
         -------
         Panel
         """
-        from pandas.util.compat import OrderedDict,OrderedDefaultdict
 
         orient = orient.lower()
         if orient == 'minor':
@@ -477,17 +473,17 @@ class Panel(NDFrame):
         class_name = str(self.__class__)
 
         shape = self.shape
-        dims = six.u('Dimensions: %s') % ' x '.join(
+        dims = u('Dimensions: %s') % ' x '.join(
             ["%d (%s)" % (s, a) for a, s in zip(self._AXIS_ORDERS, shape)])
 
         def axis_pretty(a):
             v = getattr(self, a)
             if len(v) > 0:
-                return six.u('%s axis: %s to %s') % (a.capitalize(),
+                return u('%s axis: %s to %s') % (a.capitalize(),
                                                com.pprint_thing(v[0]),
                                                com.pprint_thing(v[-1]))
             else:
-                return six.u('%s axis: None') % a.capitalize()
+                return u('%s axis: None') % a.capitalize()
 
         output = '\n'.join(
             [class_name, dims] + [axis_pretty(a) for a in self._AXIS_ORDERS])
@@ -1137,7 +1133,7 @@ class Panel(NDFrame):
         """
         # construct the args
         args = list(args)
-        aliases = tuple(six.iterkeys(kwargs))
+        aliases = tuple(compat.iterkeys(kwargs))
 
         for a in self._AXIS_ORDERS:
             if not a in kwargs:
@@ -1487,7 +1483,7 @@ class Panel(NDFrame):
         if not isinstance(values, np.ndarray):
             values = np.asarray(values)
             # NumPy strings are a pain, convert to object
-            if issubclass(values.dtype.type, six.string_types):
+            if issubclass(values.dtype.type, compat.string_types):
                 values = np.array(values, dtype=object, copy=True)
         else:
             if copy:
@@ -1511,7 +1507,6 @@ class Panel(NDFrame):
         -------
         dict of aligned results & indicies
         """
-        from pandas.util.compat import OrderedDict
 
         result = dict()
         if isinstance(frames,OrderedDict): # caller differs dict/ODict, presered type
@@ -1715,8 +1710,8 @@ def install_ipython_completers():  # pragma: no cover
     @complete_object.when_type(Panel)
     def complete_dataframe(obj, prev_completions):
         return prev_completions + [c for c in obj.keys()
-                                   if isinstance(c, six.string_types)
-                                        and py3compat.isidentifier(c)]
+                                   if isinstance(c, compat.string_types)
+                                        and compat.isidentifier(c)]
 
 # Importing IPython brings in about 200 modules, so we want to avoid it unless
 # we're in IPython (when those modules are loaded anyway).
diff --git a/pandas/core/panelnd.py b/pandas/core/panelnd.py
index 71d815482..e1706a44f 100644
--- a/pandas/core/panelnd.py
+++ b/pandas/core/panelnd.py
@@ -1,8 +1,8 @@
 """ Factory methods to create N-D panels """
 
 import pandas.lib as lib
-from pandas.util.py3compat import zip
-import six
+from pandas.util.compat import zip
+import pandas.util.compat as compat
 
 
 def create_nd_panel_factory(klass_name, axis_orders, axis_slices, slicer, axis_aliases=None, stat_axis=2,ns=None):
@@ -29,7 +29,7 @@ def create_nd_panel_factory(klass_name, axis_orders, axis_slices, slicer, axis_a
     """
 
     # if slicer is a name, get the object
-    if isinstance(slicer, six.string_types):
+    if isinstance(slicer, compat.string_types):
         import pandas
         try:
             slicer = getattr(pandas, slicer)
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index 136f48930..c73d0803f 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -1,10 +1,8 @@
 # pylint: disable=E1101,E1103
 # pylint: disable=W0703,W0622,W0613,W0201
 
-from pandas.util.py3compat import range
+from pandas.util.compat import range, zip
 from pandas.util import compat
-from pandas.util.py3compat import zip
-import six
 import itertools
 
 import numpy as np
@@ -693,7 +691,7 @@ def melt(frame, id_vars=None, value_vars=None,
         else:
             var_name = [frame.columns.name if frame.columns.name is not None
                         else 'variable']
-    if isinstance(var_name, six.string_types):
+    if isinstance(var_name, compat.string_types):
         var_name = [var_name]
 
     N, K = frame.shape
diff --git a/pandas/core/series.py b/pandas/core/series.py
index b25afe5d9..294898bbd 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -25,9 +25,9 @@ from pandas.core.indexing import (_SeriesIndexer, _check_bool_indexer,
                                   _check_slice_bounds, _maybe_convert_indices)
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.util.terminal import get_terminal_size
-from pandas.util.py3compat import zip, lzip
+from pandas.util.compat import zip, lzip, u, OrderedDict
 
 import pandas.core.array as pa
 
@@ -44,7 +44,6 @@ import pandas.index as _index
 
 from pandas.compat.scipy import scoreatpercentile as _quantile
 from pandas.core.config import get_option
-import six
 
 __all__ = ['Series', 'TimeSeries']
 
@@ -450,7 +449,6 @@ class Series(generic.PandasContainer, pa.Array):
                 data = data.reindex(index).values
         elif isinstance(data, dict):
             if index is None:
-                from pandas.util.compat import OrderedDict
                 if isinstance(data, OrderedDict):
                     index = Index(data)
                 else:
@@ -1118,9 +1116,9 @@ class Series(generic.PandasContainer, pa.Array):
                                     name=True,
                                     dtype=True)
         else:
-            result = six.u('Series([], dtype: %s)') % self.dtype
+            result = u('Series([], dtype: %s)') % self.dtype
 
-        if not (isinstance(result, six.text_type)):
+        if not (isinstance(result, compat.text_type)):
             raise AssertionError()
         return result
 
@@ -1139,12 +1137,12 @@ class Series(generic.PandasContainer, pa.Array):
         result = head + '\n...\n' + tail
         result = '%s\n%s' % (result, self._repr_footer())
 
-        return six.text_type(result)
+        return compat.text_type(result)
 
     def _repr_footer(self):
-        namestr = six.u("Name: %s, ") % com.pprint_thing(
+        namestr = u("Name: %s, ") % com.pprint_thing(
             self.name) if self.name is not None else ""
-        return six.u('%sLength: %d, dtype: %s') % (namestr, len(self),
+        return u('%sLength: %d, dtype: %s') % (namestr, len(self),
                                              str(self.dtype.name))
 
     def to_string(self, buf=None, na_rep='NaN', float_format=None,
@@ -1182,7 +1180,7 @@ class Series(generic.PandasContainer, pa.Array):
                                   length=length, dtype=dtype, name=name)
 
         # catch contract violations
-        if not isinstance(the_repr, six.text_type):
+        if not isinstance(the_repr, compat.text_type):
             raise AssertionError("expected unicode string")
 
         if buf is None:
@@ -1205,7 +1203,7 @@ class Series(generic.PandasContainer, pa.Array):
                                         length=length, dtype=dtype, na_rep=na_rep,
                                         float_format=float_format)
         result = formatter.to_string()
-        if not (isinstance(result, six.text_type)):
+        if not (isinstance(result, compat.text_type)):
             raise AssertionError()
         return result
 
@@ -1222,7 +1220,7 @@ class Series(generic.PandasContainer, pa.Array):
         return lzip(iter(self.index), iter(self))
 
     iterkv = iteritems
-    if py3compat.PY3:  # pragma: no cover
+    if compat.PY3:  # pragma: no cover
         items = iteritems
 
     #----------------------------------------------------------------------
@@ -1275,7 +1273,7 @@ class Series(generic.PandasContainer, pa.Array):
     __ipow__ = __pow__
 
     # Python 2 division operators
-    if not py3compat.PY3:
+    if not compat.PY3:
         __div__ = _arith_method(operator.div, '__div__', fill_zeros=np.inf)
         __rdiv__ = _arith_method(lambda x, y: y / x, '__div__', fill_zeros=np.inf)
         __idiv__ = __div__
@@ -1386,7 +1384,7 @@ class Series(generic.PandasContainer, pa.Array):
         if level is not None:
             mask = notnull(self.values)
 
-            if isinstance(level, six.string_types):
+            if isinstance(level, compat.string_types):
                 level = self.index._get_level_number(level)
 
             level_index = self.index.levels[level]
@@ -3048,7 +3046,7 @@ class Series(generic.PandasContainer, pa.Array):
 
         offset = _resolve_offset(freq, kwds)
 
-        if isinstance(offset, six.string_types):
+        if isinstance(offset, compat.string_types):
             offset = datetools.to_offset(offset)
 
         def _get_values():
@@ -3101,7 +3099,7 @@ class Series(generic.PandasContainer, pa.Array):
         -------
         value or NaN
         """
-        if isinstance(where, six.string_types):
+        if isinstance(where, compat.string_types):
             where = datetools.to_datetime(where)
 
         values = self.values
@@ -3409,7 +3407,7 @@ def _sanitize_array(data, index, dtype=None, copy=False,
 
     # This is to prevent mixed-type Series getting all casted to
     # NumPy string type, e.g. NaN --> '-1#IND'.
-    if issubclass(subarr.dtype.type, six.string_types):
+    if issubclass(subarr.dtype.type, compat.string_types):
         subarr = pa.array(data, dtype=object, copy=copy)
 
     return subarr
@@ -3432,7 +3430,7 @@ def _resolve_offset(freq, kwds):
     if 'timeRule' in kwds or 'offset' in kwds:
         offset = kwds.get('offset', None)
         offset = kwds.get('timeRule', offset)
-        if isinstance(offset, six.string_types):
+        if isinstance(offset, compat.string_types):
             offset = datetools.getOffset(offset)
         warn = True
     else:
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index c625438df..4ab6b379f 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -1,9 +1,9 @@
 import numpy as np
 
-from pandas.util.py3compat import zip
-import six
+from pandas.util.compat import zip
 from pandas.core.common import isnull
 from pandas.core.series import Series
+import pandas.util.compat as compat
 import re
 import pandas.lib as lib
 
@@ -283,17 +283,17 @@ def str_repeat(arr, repeats):
     if np.isscalar(repeats):
         def rep(x):
             try:
-                return six.binary_type.__mul__(x, repeats)
+                return compat.binary_type.__mul__(x, repeats)
             except TypeError:
-                return six.text_type.__mul__(x, repeats)
+                return compat.text_type.__mul__(x, repeats)
 
         return _na_map(rep, arr)
     else:
         def rep(x, r):
             try:
-                return six.binary_type.__mul__(x, r)
+                return compat.binary_type.__mul__(x, r)
             except TypeError:
-                return six.text_type.__mul__(x, r)
+                return compat.text_type.__mul__(x, r)
 
         repeats = np.asarray(repeats, dtype=object)
         result = lib.vec_binop(arr, repeats, rep)
diff --git a/pandas/io/clipboard.py b/pandas/io/clipboard.py
index fa3e38459..ba0b80f2e 100644
--- a/pandas/io/clipboard.py
+++ b/pandas/io/clipboard.py
@@ -1,5 +1,5 @@
 """ io on the clipboard """
-from pandas.util.py3compat import StringIO
+from pandas.util.compat import StringIO
 
 def read_clipboard(**kwargs):  # pragma: no cover
     """
diff --git a/pandas/io/common.py b/pandas/io/common.py
index 93f4f0b5d..dc3001053 100644
--- a/pandas/io/common.py
+++ b/pandas/io/common.py
@@ -4,11 +4,11 @@ import sys
 import zipfile
 from contextlib import contextmanager, closing
 
-from pandas.util.py3compat import StringIO
-from pandas.util import py3compat
+from pandas.util.compat import StringIO
+from pandas.util import compat
 
 
-if py3compat.PY3:
+if compat.PY3:
     from urllib.request import urlopen
     _urlopen = urlopen
     from urllib.parse import urlparse as parse_url
@@ -83,7 +83,7 @@ def get_filepath_or_buffer(filepath_or_buffer, encoding=None):
 
     if _is_url(filepath_or_buffer):
         req = _urlopen(filepath_or_buffer)
-        if py3compat.PY3:  # pragma: no cover
+        if compat.PY3:  # pragma: no cover
             if encoding:
                 errors = 'strict'
             else:
diff --git a/pandas/io/data.py b/pandas/io/data.py
index 04d6cbc95..d1962648a 100644
--- a/pandas/io/data.py
+++ b/pandas/io/data.py
@@ -12,14 +12,15 @@ from collections import defaultdict
 
 import numpy as np
 
-from pandas.util.py3compat import StringIO, bytes_to_str, range, lrange, lmap
+from pandas.util.compat import(
+    StringIO, bytes_to_str, range, lrange, lmap, zip
+)
+import pandas.util.compat as compat
 from pandas import Panel, DataFrame, Series, read_csv, concat
 from pandas.core.common import PandasError
 from pandas.io.parsers import TextParser
 from pandas.io.common import urlopen, ZipFile, urlencode
 from pandas.util.testing import _network_error_classes
-import six
-from pandas.util.py3compat import map, zip
 
 
 class SymbolWarning(UserWarning):
@@ -101,19 +102,20 @@ def _in_chunks(seq, size):
 _yahoo_codes = {'symbol': 's', 'last': 'l1', 'change_pct': 'p2', 'PE': 'r',
                 'time': 't1', 'short_ratio': 's7'}
 
+
 def get_quote_yahoo(symbols):
     """
     Get current yahoo quote
 
     Returns a DataFrame
     """
-    if isinstance(symbols, six.string_types):
+    if isinstance(symbols, compat.string_types):
         sym_list = symbols
     else:
         sym_list = '+'.join(symbols)
 
     # for codes see: http://www.gummy-stuff.org/Yahoo-data.htm
-    request = ''.join(six.itervalues(_yahoo_codes))  # code request string
+    request = ''.join(compat.itervalues(_yahoo_codes))  # code request string
     header = list(_yahoo_codes.keys())
 
     data = defaultdict(list)
@@ -202,10 +204,9 @@ def _get_hist_google(sym, start, end, retry_count, pause):
 
     # www.google.com/finance/historical?q=GOOG&startdate=Jun+9%2C+2011&enddate=Jun+8%2C+2013&output=csv
     url = google_URL + urlencode({"q": sym,
-                                         "startdate": start.strftime('%b %d, '
-                                                                     '%Y'),
-                                         "enddate": end.strftime('%b %d, %Y'),
-                                         "output": "csv"})
+                                  "startdate": start.strftime('%b %d, ' '%Y'),
+                                  "enddate": end.strftime('%b %d, %Y'),
+                                  "output": "csv"})
     return _retry_read_url(url, retry_count, pause, 'Google')
 
 
@@ -322,6 +323,7 @@ def _dl_mult_symbols(symbols, start, end, chunksize, retry_count, pause,
 
 _source_functions = {'google': _get_hist_google, 'yahoo': _get_hist_yahoo}
 
+
 def _get_data_from(symbols, start, end, retry_count, pause, adjust_price,
                    ret_index, chunksize, source, name):
     if name is not None:
@@ -332,7 +334,7 @@ def _get_data_from(symbols, start, end, retry_count, pause, adjust_price,
     src_fn = _source_functions[source]
 
     # If a single symbol, (e.g., 'GOOG')
-    if isinstance(symbols, (six.string_types, int)):
+    if isinstance(symbols, (compat.string_types, int)):
         hist_data = src_fn(symbols, start, end, retry_count, pause)
     # Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])
     elif isinstance(symbols, DataFrame):
diff --git a/pandas/io/date_converters.py b/pandas/io/date_converters.py
index c0e9b4da8..26c3162ec 100644
--- a/pandas/io/date_converters.py
+++ b/pandas/io/date_converters.py
@@ -1,5 +1,5 @@
 """This module is designed for community supported date conversion functions"""
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import numpy as np
 import pandas.lib as lib
 
diff --git a/pandas/io/excel.py b/pandas/io/excel.py
index f592d80f3..bf59d3620 100644
--- a/pandas/io/excel.py
+++ b/pandas/io/excel.py
@@ -11,9 +11,9 @@ import numpy as np
 from pandas.io.parsers import TextParser
 from pandas.tseries.period import Period
 from pandas import json
-from pandas.util.py3compat import map, zip, reduce
-from pandas.util.py3compat import range, lrange
-import six
+from pandas.util.compat import map, zip, reduce, range, lrange
+import pandas.util.compat as compat
+
 
 def read_excel(path_or_buf, sheetname, kind=None, **kwds):
     """Read an Excel table into a pandas DataFrame
@@ -67,15 +67,17 @@ class ExcelFile(object):
     def __init__(self, path_or_buf, kind=None, **kwds):
         self.kind = kind
 
-        import xlrd # throw an ImportError if we need to
-        ver = tuple(map(int,xlrd.__VERSION__.split(".")[:2]))
+        import xlrd  # throw an ImportError if we need to
+
+        ver = tuple(map(int, xlrd.__VERSION__.split(".")[:2]))
         if ver < (0, 9):
-            raise ImportError("pandas requires xlrd >= 0.9.0 for excel support, current version "+xlrd.__VERSION__)
+            raise ImportError("pandas requires xlrd >= 0.9.0 for excel "
+                              "support, current version " + xlrd.__VERSION__)
 
         self.path_or_buf = path_or_buf
         self.tmpfile = None
 
-        if isinstance(path_or_buf, six.string_types):
+        if isinstance(path_or_buf, compat.string_types):
             self.book = xlrd.open_workbook(path_or_buf)
         else:
             data = path_or_buf.read()
@@ -110,8 +112,8 @@ class ExcelFile(object):
         na_values : list-like, default None
             List of additional strings to recognize as NA/NaN
         keep_default_na : bool, default True
-            If na_values are specified and keep_default_na is False the default NaN
-            values are overridden, otherwise they're appended to
+            If na_values are specified and keep_default_na is False the default
+            NaN values are overridden, otherwise they're appended to
         verbose : boolean, default False
             Indicate number of NA values placed in non-numeric columns
 
@@ -126,14 +128,14 @@ class ExcelFile(object):
         if skipfooter is not None:
             skip_footer = skipfooter
 
-        return  self._parse_excel(sheetname, header=header, skiprows=skiprows,
-                                  index_col=index_col,
-                                  has_index_names=has_index_names,
-                                  parse_cols=parse_cols,
-                                  parse_dates=parse_dates,
-                                  date_parser=date_parser, na_values=na_values,
-                                  thousands=thousands, chunksize=chunksize,
-                                  skip_footer=skip_footer, **kwds)
+        return self._parse_excel(sheetname, header=header, skiprows=skiprows,
+                                 index_col=index_col,
+                                 has_index_names=has_index_names,
+                                 parse_cols=parse_cols,
+                                 parse_dates=parse_dates,
+                                 date_parser=date_parser, na_values=na_values,
+                                 thousands=thousands, chunksize=chunksize,
+                                 skip_footer=skip_footer, **kwds)
 
     def _should_parse(self, i, parse_cols):
 
@@ -149,7 +151,8 @@ class ExcelFile(object):
             """
             def _excel2num(x):
                 "Convert Excel column name like 'AB' to 0-based column index"
-                return reduce(lambda s, a: s * 26 + ord(a) - ord('A') + 1, x.upper().strip(), 0) - 1
+                return reduce(lambda s, a: s * 26 + ord(a) - ord('A') + 1,
+                              x.upper().strip(), 0) - 1
 
             cols = []
             for rng in areas.split(','):
@@ -162,7 +165,7 @@ class ExcelFile(object):
 
         if isinstance(parse_cols, int):
             return i <= parse_cols
-        elif isinstance(parse_cols, six.string_types):
+        elif isinstance(parse_cols, compat.string_types):
             return i in _range2cols(parse_cols)
         else:
             return i in parse_cols
@@ -175,7 +178,7 @@ class ExcelFile(object):
                           XL_CELL_ERROR, XL_CELL_BOOLEAN)
 
         datemode = self.book.datemode
-        if isinstance(sheetname, six.string_types):
+        if isinstance(sheetname, compat.string_types):
             sheet = self.book.sheet_by_name(sheetname)
         else:  # assume an integer if not a string
             sheet = self.book.sheet_by_index(sheetname)
@@ -185,7 +188,7 @@ class ExcelFile(object):
         for i in range(sheet.nrows):
             row = []
             for j, (value, typ) in enumerate(zip(sheet.row_values(i),
-                                                  sheet.row_types(i))):
+                                                 sheet.row_types(i))):
                 if parse_cols is not None and j not in should_parse:
                     should_parse[j] = self._should_parse(j, parse_cols)
 
@@ -458,4 +461,3 @@ class ExcelWriter(object):
                 wks.write(startrow + cell.row,
                           startcol + cell.col,
                           val, style)
-
diff --git a/pandas/io/ga.py b/pandas/io/ga.py
index 74157464b..19b478732 100644
--- a/pandas/io/ga.py
+++ b/pandas/io/ga.py
@@ -17,10 +17,9 @@ from pandas.util.decorators import Appender, Substitution
 
 from apiclient.errors import HttpError
 from oauth2client.client import AccessTokenRefreshError
-import six
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip, u
 
-TYPE_MAP = {six.u('INTEGER'): int, six.u('FLOAT'): float, six.u('TIME'): int}
+TYPE_MAP = {u('INTEGER'): int, u('FLOAT'): float, u('TIME'): int}
 
 NO_CALLBACK = auth.OOB_CALLBACK_URN
 DOC_URL = auth.DOC_URL
@@ -264,7 +263,7 @@ class GDataReader(OAuthDataReader):
         profile_id = profile.get('id')
 
         if index_col is None and dimensions is not None:
-            if isinstance(dimensions, six.string_types):
+            if isinstance(dimensions, compat.string_types):
                 dimensions = [dimensions]
             index_col = _clean_index(list(dimensions), parse_dates)
 
@@ -315,7 +314,7 @@ class GDataReader(OAuthDataReader):
 
         if isinstance(sort, bool) and sort:
             return df.sort_index()
-        elif isinstance(sort, (six.string_types, list, tuple, np.ndarray)):
+        elif isinstance(sort, (compat.string_types, list, tuple, np.ndarray)):
             return df.sort_index(by=sort)
 
         return df
@@ -340,7 +339,7 @@ class GAnalytics(GDataReader):
 def format_query(ids, metrics, start_date, end_date=None, dimensions=None,
                  segment=None, filters=None, sort=None, start_index=None,
                  max_results=10000, **kwargs):
-    if isinstance(metrics, six.string_types):
+    if isinstance(metrics, compat.string_types):
         metrics = [metrics]
     met = ','.join(['ga:%s' % x for x in metrics])
 
@@ -359,7 +358,7 @@ def format_query(ids, metrics, start_date, end_date=None, dimensions=None,
     lst = [dimensions, filters, sort]
     [_maybe_add_arg(qry, n, d) for n, d in zip(names, lst)]
 
-    if isinstance(segment, six.string_types):
+    if isinstance(segment, compat.string_types):
         _maybe_add_arg(qry, 'segment', segment, 'dynamic::ga')
     elif isinstance(segment, int):
         _maybe_add_arg(qry, 'segment', segment, 'gaid:')
@@ -377,7 +376,7 @@ def format_query(ids, metrics, start_date, end_date=None, dimensions=None,
 
 def _maybe_add_arg(query, field, data, prefix='ga'):
     if data is not None:
-        if isinstance(data, (six.string_types, int)):
+        if isinstance(data, (compat.string_types, int)):
             data = [data]
         data = ','.join(['%s:%s' % (prefix, x) for x in data])
         query[field] = data
@@ -438,12 +437,12 @@ def _get_column_types(header_info):
 
 def _get_dim_names(header_info):
     return [x['name'][3:] for x in header_info
-            if x['columnType'] == six.u('DIMENSION')]
+            if x['columnType'] == u('DIMENSION')]
 
 
 def _get_met_names(header_info):
     return [x['name'][3:] for x in header_info
-            if x['columnType'] == six.u('METRIC')]
+            if x['columnType'] == u('METRIC')]
 
 
 def _get_data_types(header_info):
diff --git a/pandas/io/html.py b/pandas/io/html.py
index 2617566ad..841fd1bf9 100644
--- a/pandas/io/html.py
+++ b/pandas/io/html.py
@@ -14,10 +14,8 @@ import numpy as np
 
 from pandas import DataFrame, MultiIndex, isnull
 from pandas.io.common import _is_url, urlopen, parse_url
-from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.compat import range, lrange, lmap, u, map
 from pandas.util import compat
-import six
-from pandas.util.py3compat import map
 
 
 try:
@@ -122,7 +120,7 @@ def _read(io):
     elif os.path.isfile(io):
         with open(io) as f:
             raw_text = f.read()
-    elif isinstance(io, six.string_types):
+    elif isinstance(io, compat.string_types):
         raw_text = io
     else:
         raise TypeError("Cannot read object of type "
@@ -452,8 +450,8 @@ def _build_node_xpath_expr(attrs):
     if 'class_' in attrs:
         attrs['class'] = attrs.pop('class_')
 
-    s = (six.u("@{k}='{v}'").format(k=k, v=v) for k, v in compat.iteritems(attrs))
-    return six.u('[{0}]').format(' and '.join(s))
+    s = (u("@{k}='{v}'").format(k=k, v=v) for k, v in compat.iteritems(attrs))
+    return u('[{0}]').format(' and '.join(s))
 
 
 _re_namespace = {'re': 'http://exslt.org/regular-expressions'}
@@ -494,9 +492,9 @@ class _LxmlFrameParser(_HtmlFrameParser):
         pattern = match.pattern
 
         # check all descendants for the given pattern
-        check_all_expr = six.u('//*')
+        check_all_expr = u('//*')
         if pattern:
-            check_all_expr += six.u("[re:test(text(), '{0}')]").format(pattern)
+            check_all_expr += u("[re:test(text(), '{0}')]").format(pattern)
 
         # go up the tree until we find a table
         check_table_expr = '/ancestor::table'
@@ -735,10 +733,10 @@ def _parser_dispatch(flavor):
 def _validate_parser_flavor(flavor):
     if flavor is None:
         flavor = ['lxml', 'bs4']
-    elif isinstance(flavor, six.string_types):
+    elif isinstance(flavor, compat.string_types):
         flavor = [flavor]
     elif isinstance(flavor, collections.Iterable):
-        if not all(isinstance(flav, six.string_types) for flav in flavor):
+        if not all(isinstance(flav, compat.string_types) for flav in flavor):
             raise TypeError('{0} is not an iterable of strings'.format(flavor))
     else:
         raise TypeError('{0} is not a valid "flavor"'.format(flavor))
diff --git a/pandas/io/json.py b/pandas/io/json.py
index ef53d0b9e..35709b4dd 100644
--- a/pandas/io/json.py
+++ b/pandas/io/json.py
@@ -1,14 +1,12 @@
 
 # pylint: disable-msg=E1101,W0613,W0603
-from pandas.util.py3compat import StringIO
+from pandas.util.compat import StringIO, long
 from pandas.util import compat
-from pandas.util.py3compat import long
 import os
 
 from pandas import Series, DataFrame, to_datetime
 from pandas.io.common import get_filepath_or_buffer
 import pandas.json as _json
-import six
 loads = _json.loads
 dumps = _json.dumps
 
@@ -29,7 +27,7 @@ def to_json(path_or_buf, obj, orient=None, date_format='epoch', double_precision
     else:
         raise NotImplementedError
 
-    if isinstance(path_or_buf, six.string_types):
+    if isinstance(path_or_buf, compat.string_types):
         with open(path_or_buf,'w') as fh:
             fh.write(s)
     elif path_or_buf is None:
@@ -185,7 +183,7 @@ def read_json(path_or_buf=None, orient=None, typ='frame', dtype=True,
     """
 
     filepath_or_buffer,_ = get_filepath_or_buffer(path_or_buf)
-    if isinstance(filepath_or_buffer, six.string_types):
+    if isinstance(filepath_or_buffer, compat.string_types):
         if os.path.exists(filepath_or_buffer):
             with open(filepath_or_buffer,'r') as fh:
                 json = fh.read()
@@ -470,7 +468,7 @@ class FrameParser(Parser):
 
         def is_ok(col):
             """ return if this col is ok to try for a date parse """
-            if not isinstance(col, six.string_types): return False
+            if not isinstance(col, compat.string_types): return False
 
             if (col.endswith('_at') or
                 col.endswith('_time') or
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 85d5ad0d3..433e6d0f8 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -2,7 +2,7 @@
 Module contains tools for processing files into DataFrames or other objects
 """
 from __future__ import print_function
-from pandas.util.py3compat import range, lrange, StringIO, lzip
+from pandas.util.compat import range, lrange, StringIO, lzip, zip
 from pandas.util import compat
 import re
 import csv
@@ -14,7 +14,7 @@ from pandas.core.index import Index, MultiIndex
 from pandas.core.frame import DataFrame
 import datetime
 import pandas.core.common as com
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.io.date_converters import generic_parser
 from pandas.io.common import get_filepath_or_buffer
 
@@ -24,8 +24,6 @@ import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.parser as _parser
 from pandas.tseries.period import Period
-import six
-from pandas.util.py3compat import zip
 
 _parser_params = """Also supports optionally iterating or breaking of the file
 into chunks.
@@ -787,7 +785,7 @@ class ParserBase(object):
 
     def _get_simple_index(self, data, columns):
         def ix(col):
-            if not isinstance(col, six.string_types):
+            if not isinstance(col, compat.string_types):
                 return col
             raise ValueError('Index %s invalid' % col)
         index = None
@@ -810,7 +808,7 @@ class ParserBase(object):
 
     def _get_complex_date_index(self, data, col_names):
         def _get_name(icol):
-            if isinstance(icol, six.string_types):
+            if isinstance(icol, compat.string_types):
                 return icol
 
             if col_names is None:
@@ -949,7 +947,7 @@ class CParserWrapper(ParserBase):
         ParserBase.__init__(self, kwds)
 
         if 'utf-16' in (kwds.get('encoding') or ''):
-            if isinstance(src, six.string_types):
+            if isinstance(src, compat.string_types):
                 src = open(src, 'rb')
             src = com.UTF8Recoder(src, kwds['encoding'])
             kwds['encoding'] = 'utf-8'
@@ -1230,7 +1228,7 @@ class PythonParser(ParserBase):
         self.comment = kwds['comment']
         self._comment_lines = []
 
-        if isinstance(f, six.string_types):
+        if isinstance(f, compat.string_types):
             f = com._get_handle(f, 'r', encoding=self.encoding,
                                 compression=self.compression)
         elif self.compression:
@@ -1320,7 +1318,7 @@ class PythonParser(ParserBase):
             def _read():
                 line = next(f)
                 pat = re.compile(sep)
-                if (py3compat.PY3 and isinstance(line, bytes)):
+                if (compat.PY3 and isinstance(line, bytes)):
                     yield pat.split(line.decode('utf-8').strip())
                     for line in f:
                         yield pat.split(line.decode('utf-8').strip())
@@ -1490,7 +1488,7 @@ class PythonParser(ParserBase):
         for l in lines:
             rl = []
             for x in l:
-                if (not isinstance(x, six.string_types) or
+                if (not isinstance(x, compat.string_types) or
                         self.comment not in x):
                     rl.append(x)
                 else:
@@ -1509,7 +1507,7 @@ class PythonParser(ParserBase):
         for l in lines:
             rl = []
             for x in l:
-                if (not isinstance(x, six.string_types) or
+                if (not isinstance(x, compat.string_types) or
                     self.thousands not in x or
                         nonnum.search(x.strip())):
                     rl.append(x)
@@ -1809,7 +1807,7 @@ def _clean_index_names(columns, index_col):
     index_col = list(index_col)
 
     for i, c in enumerate(index_col):
-        if isinstance(c, six.string_types):
+        if isinstance(c, compat.string_types):
             index_names.append(c)
             for j, name in enumerate(cp_cols):
                 if name == c:
@@ -1822,7 +1820,7 @@ def _clean_index_names(columns, index_col):
             index_names.append(name)
 
     # hack
-    if isinstance(index_names[0], six.string_types) and 'Unnamed' in index_names[0]:
+    if isinstance(index_names[0], compat.string_types) and 'Unnamed' in index_names[0]:
         index_names[0] = None
 
     return index_names, columns, index_col
@@ -1903,13 +1901,13 @@ def _get_col_names(colspec, columns):
 
 def _concat_date_cols(date_cols):
     if len(date_cols) == 1:
-        if py3compat.PY3:
-            return np.array([six.text_type(x) for x in date_cols[0]], dtype=object)
+        if compat.PY3:
+            return np.array([compat.text_type(x) for x in date_cols[0]], dtype=object)
         else:
-            return np.array([str(x) if not isinstance(x, six.string_types) else x
+            return np.array([str(x) if not isinstance(x, compat.string_types) else x
                              for x in date_cols[0]], dtype=object)
 
-    rs = np.array([' '.join([six.text_type(y) for y in x])
+    rs = np.array([' '.join([compat.text_type(y) for y in x])
                    for x in zip(*date_cols)], dtype=object)
     return rs
 
diff --git a/pandas/io/pickle.py b/pandas/io/pickle.py
index 56bca476c..314a566d2 100644
--- a/pandas/io/pickle.py
+++ b/pandas/io/pickle.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import cPickle as pkl
+from pandas.util.compat import cPickle as pkl, PY3
 
 def to_pickle(obj, path):
     """
@@ -35,7 +35,6 @@ def read_pickle(path):
         with open(path, 'rb') as fh:
             return pkl.load(fh)
     except:
-        from pandas.util.py3compat import PY3
         if PY3:
             with open(path, 'rb') as fh:
                 return pkl.load(fh, encoding='latin1')
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 908091942..14de4d17e 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -6,7 +6,7 @@ from __future__ import print_function
 
 # pylint: disable-msg=E1101,W0613,W0603
 from datetime import datetime, date
-from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.compat import map, range, zip, lrange, lmap, u
 from pandas.util import compat
 import time
 import re
@@ -30,7 +30,7 @@ from pandas.core.reshape import block2d_to_blocknd, factor_indexer
 from pandas.core.index import _ensure_index
 import pandas.core.common as com
 from pandas.tools.merge import concat
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.io.common import PerformanceWarning
 
 import pandas.lib as lib
@@ -38,8 +38,6 @@ import pandas.algos as algos
 import pandas.tslib as tslib
 
 from contextlib import contextmanager
-import six
-from pandas.util.py3compat import map, zip
 
 # versioning attribute
 _version = '0.10.1'
@@ -58,7 +56,7 @@ def _ensure_decoded(s):
 def _ensure_encoding(encoding):
     # set the encoding if we need
     if encoding is None:
-        if py3compat.PY3:
+        if compat.PY3:
             encoding = _default_encoding
     return encoding
 
@@ -92,40 +90,40 @@ map directly to c-types [inferred_type->%s,key->%s] [items->%s]
 # map object types
 _TYPE_MAP = {
 
-    Series: six.u('series'),
-    SparseSeries: six.u('sparse_series'),
-    TimeSeries: six.u('series'),
-    DataFrame: six.u('frame'),
-    SparseDataFrame: six.u('sparse_frame'),
-    Panel: six.u('wide'),
-    Panel4D: six.u('ndim'),
-    SparsePanel: six.u('sparse_panel')
+    Series: u('series'),
+    SparseSeries: u('sparse_series'),
+    TimeSeries: u('series'),
+    DataFrame: u('frame'),
+    SparseDataFrame: u('sparse_frame'),
+    Panel: u('wide'),
+    Panel4D: u('ndim'),
+    SparsePanel: u('sparse_panel')
 }
 
 # storer class map
 _STORER_MAP = {
-    six.u('TimeSeries')    : 'LegacySeriesStorer',
-    six.u('Series')        : 'LegacySeriesStorer',
-    six.u('DataFrame')     : 'LegacyFrameStorer',
-    six.u('DataMatrix')    : 'LegacyFrameStorer',
-    six.u('series')        : 'SeriesStorer',
-    six.u('sparse_series') : 'SparseSeriesStorer',
-    six.u('frame')         : 'FrameStorer',
-    six.u('sparse_frame')  : 'SparseFrameStorer',
-    six.u('wide')          : 'PanelStorer',
-    six.u('sparse_panel')  : 'SparsePanelStorer',
+    u('TimeSeries')    : 'LegacySeriesStorer',
+    u('Series')        : 'LegacySeriesStorer',
+    u('DataFrame')     : 'LegacyFrameStorer',
+    u('DataMatrix')    : 'LegacyFrameStorer',
+    u('series')        : 'SeriesStorer',
+    u('sparse_series') : 'SparseSeriesStorer',
+    u('frame')         : 'FrameStorer',
+    u('sparse_frame')  : 'SparseFrameStorer',
+    u('wide')          : 'PanelStorer',
+    u('sparse_panel')  : 'SparsePanelStorer',
 }
 
 # table class map
 _TABLE_MAP = {
-    six.u('generic_table')    : 'GenericTable',
-    six.u('appendable_frame')      : 'AppendableFrameTable',
-    six.u('appendable_multiframe') : 'AppendableMultiFrameTable',
-    six.u('appendable_panel') : 'AppendablePanelTable',
-    six.u('appendable_ndim')  : 'AppendableNDimTable',
-    six.u('worm')             : 'WORMTable',
-    six.u('legacy_frame')     : 'LegacyFrameTable',
-    six.u('legacy_panel')     : 'LegacyPanelTable',
+    u('generic_table')    : 'GenericTable',
+    u('appendable_frame')      : 'AppendableFrameTable',
+    u('appendable_multiframe') : 'AppendableMultiFrameTable',
+    u('appendable_panel') : 'AppendablePanelTable',
+    u('appendable_ndim')  : 'AppendableNDimTable',
+    u('worm')             : 'WORMTable',
+    u('legacy_frame')     : 'LegacyFrameTable',
+    u('legacy_panel')     : 'LegacyPanelTable',
 }
 
 # axes map
@@ -194,7 +192,7 @@ def to_hdf(path_or_buf, key, value, mode=None, complevel=None, complib=None, app
     else:
         f = lambda store: store.put(key, value, **kwargs)
 
-    if isinstance(path_or_buf, six.string_types):
+    if isinstance(path_or_buf, compat.string_types):
         with get_store(path_or_buf, mode=mode, complevel=complevel, complib=complib) as store:
             f(store)
     else:
@@ -204,7 +202,7 @@ def read_hdf(path_or_buf, key, **kwargs):
     """ read from the store, closeit if we opened it """
     f = lambda store, auto_close: store.select(key, auto_close=auto_close, **kwargs)
 
-    if isinstance(path_or_buf, six.string_types):
+    if isinstance(path_or_buf, compat.string_types):
 
         # can't auto open/close if we are using an iterator
         # so delegate to the iterator
@@ -372,7 +370,7 @@ class HDFStore(StringMixin):
         self._mode = mode
         if warn and mode == 'w':  # pragma: no cover
             while True:
-                if py3compat.PY3:
+                if compat.PY3:
                     raw_input = input
                 response = raw_input("Re-opening as mode='w' will delete the "
                                      "current file. Continue (y/n)?")
@@ -520,7 +518,7 @@ class HDFStore(StringMixin):
         # default to single select
         if isinstance(keys, (list, tuple)) and len(keys) == 1:
             keys = keys[0]
-        if isinstance(keys, six.string_types):
+        if isinstance(keys, compat.string_types):
             return self.select(key=keys, where=where, columns=columns, start=start, stop=stop, iterator=iterator, chunksize=chunksize, **kwargs)
 
         if not isinstance(keys, (list, tuple)):
@@ -751,7 +749,7 @@ class HDFStore(StringMixin):
         """ return a list of all the top-level nodes (that are not themselves a pandas storage object) """
         _tables()
         return [ g for g in self._handle.walkNodes() if getattr(g._v_attrs,'pandas_type',None) or getattr(
-            g,'table',None) or (isinstance(g,_table_mod.table.Table) and g._v_name != six.u('table')) ]
+            g,'table',None) or (isinstance(g,_table_mod.table.Table) and g._v_name != u('table')) ]
 
     def get_node(self, key):
         """ return the node with the key or None if it does not exist """
@@ -830,8 +828,8 @@ class HDFStore(StringMixin):
 
                 _tables()
                 if getattr(group,'table',None) or isinstance(group,_table_mod.table.Table):
-                    pt = six.u('frame_table')
-                    tt = six.u('generic_table')
+                    pt = u('frame_table')
+                    tt = u('generic_table')
                 else:
                     raise TypeError("cannot create a storer if the object is not existing nor a value are passed")
             else:
@@ -843,10 +841,10 @@ class HDFStore(StringMixin):
 
                 # we are actually a table
                 if table or append:
-                    pt += six.u('_table')
+                    pt += u('_table')
 
         # a storer node
-        if six.u('table') not in pt:
+        if u('table') not in pt:
             try:
                 return globals()[_STORER_MAP[pt]](self, group, **kwargs)
             except:
@@ -858,26 +856,26 @@ class HDFStore(StringMixin):
             # if we are a writer, determin the tt
             if value is not None:
 
-                if pt == six.u('frame_table'):
+                if pt == u('frame_table'):
                     index = getattr(value,'index',None)
                     if index is not None:
                         if index.nlevels == 1:
-                            tt = six.u('appendable_frame')
+                            tt = u('appendable_frame')
                         elif index.nlevels > 1:
-                            tt = six.u('appendable_multiframe')
-                elif pt == six.u('wide_table'):
-                    tt  = six.u('appendable_panel')
-                elif pt == six.u('ndim_table'):
-                    tt = six.u('appendable_ndim')
+                            tt = u('appendable_multiframe')
+                elif pt == u('wide_table'):
+                    tt  = u('appendable_panel')
+                elif pt == u('ndim_table'):
+                    tt = u('appendable_ndim')
 
             else:
 
                 # distiguish between a frame/table
-                tt = six.u('legacy_panel')
+                tt = u('legacy_panel')
                 try:
                     fields = group.table._v_attrs.fields
-                    if len(fields) == 1 and fields[0] == six.u('value'):
-                        tt = six.u('legacy_frame')
+                    if len(fields) == 1 and fields[0] == u('value'):
+                        tt = u('legacy_frame')
                 except:
                     pass
 
@@ -1147,7 +1145,7 @@ class IndexCol(StringMixin):
     def maybe_set_size(self, min_itemsize=None, **kwargs):
         """ maybe set a string col itemsize:
                min_itemsize can be an interger or a dict with this columns name with an integer size """
-        if _ensure_decoded(self.kind) == six.u('string'):
+        if _ensure_decoded(self.kind) == u('string'):
 
             if isinstance(min_itemsize, dict):
                 min_itemsize = min_itemsize.get(self.name)
@@ -1167,7 +1165,7 @@ class IndexCol(StringMixin):
 
         # validate this column for string truncation (or reset to the max size)
         dtype = getattr(self, 'dtype', None)
-        if _ensure_decoded(self.kind) == six.u('string'):
+        if _ensure_decoded(self.kind) == u('string'):
 
             c = self.col
             if c is not None:
@@ -1297,7 +1295,7 @@ class DataCol(IndexCol):
         super(DataCol, self).__init__(
             values=values, kind=kind, typ=typ, cname=cname, **kwargs)
         self.dtype = None
-        self.dtype_attr = six.u("%s_dtype") % self.name
+        self.dtype_attr = u("%s_dtype") % self.name
         self.set_data(data)
 
     def __unicode__(self):
@@ -1326,15 +1324,15 @@ class DataCol(IndexCol):
         # set my kind if we can
         if self.dtype is not None:
             dtype = _ensure_decoded(self.dtype)
-            if dtype.startswith(six.u('string')) or dtype.startswith(six.u('bytes')):
+            if dtype.startswith(u('string')) or dtype.startswith(u('bytes')):
                 self.kind = 'string'
-            elif dtype.startswith(six.u('float')):
+            elif dtype.startswith(u('float')):
                 self.kind = 'float'
-            elif dtype.startswith(six.u('int')) or dtype.startswith(six.u('uint')):
+            elif dtype.startswith(u('int')) or dtype.startswith(u('uint')):
                 self.kind = 'integer'
-            elif dtype.startswith(six.u('date')):
+            elif dtype.startswith(u('date')):
                 self.kind = 'datetime'
-            elif dtype.startswith(six.u('bool')):
+            elif dtype.startswith(u('bool')):
                 self.kind = 'bool'
             else:
                 raise AssertionError("cannot interpret dtype of [%s] in [%s]" % (dtype,self))
@@ -1508,7 +1506,7 @@ class DataCol(IndexCol):
             dtype = _ensure_decoded(self.dtype)
 
             # reverse converts
-            if dtype == six.u('datetime64'):
+            if dtype == u('datetime64'):
                 # recreate the timezone
                 if self.tz is not None:
 
@@ -1521,10 +1519,10 @@ class DataCol(IndexCol):
                 else:
                     self.data = np.asarray(self.data, dtype='M8[ns]')
 
-            elif dtype == six.u('date'):
+            elif dtype == u('date'):
                 self.data = np.array(
                     [date.fromtimestamp(v) for v in self.data], dtype=object)
-            elif dtype == six.u('datetime'):
+            elif dtype == u('datetime'):
                 self.data = np.array(
                     [datetime.fromtimestamp(v) for v in self.data],
                     dtype=object)
@@ -1536,7 +1534,7 @@ class DataCol(IndexCol):
                     self.data = self.data.astype('O')
 
         # convert nans / decode
-        if _ensure_decoded(self.kind) == six.u('string'):
+        if _ensure_decoded(self.kind) == u('string'):
             self.data = _unconvert_string_array(self.data, nan_rep=nan_rep, encoding=encoding)
 
         return self
@@ -1560,7 +1558,7 @@ class DataIndexableCol(DataCol):
 
     @property
     def is_searchable(self):
-        return _ensure_decoded(self.kind) == six.u('string')
+        return _ensure_decoded(self.kind) == u('string')
 
     def get_atom_string(self, block, itemsize):
         return _tables().StringCol(itemsize=itemsize)
@@ -1797,7 +1795,7 @@ class GenericStorer(Storer):
             else:
                 ret = data
 
-            if dtype == six.u('datetime64'):
+            if dtype == u('datetime64'):
                 ret = np.array(ret, dtype='M8[ns]')
 
         if transposed:
@@ -1808,13 +1806,13 @@ class GenericStorer(Storer):
     def read_index(self, key):
         variety = _ensure_decoded(getattr(self.attrs, '%s_variety' % key))
 
-        if variety == six.u('multi'):
+        if variety == u('multi'):
             return self.read_multi_index(key)
-        elif variety == six.u('block'):
+        elif variety == u('block'):
             return self.read_block_index(key)
-        elif variety == six.u('sparseint'):
+        elif variety == u('sparseint'):
             return self.read_sparse_intindex(key)
-        elif variety == six.u('regular'):
+        elif variety == u('regular'):
             _, index = self.read_index_node(getattr(self.group, key))
             return index
         else:  # pragma: no cover
@@ -1923,13 +1921,13 @@ class GenericStorer(Storer):
         factory = self._get_index_factory(index_class)
 
         kwargs = {}
-        if six.u('freq') in node._v_attrs:
+        if u('freq') in node._v_attrs:
             kwargs['freq'] = node._v_attrs['freq']
 
-        if six.u('tz') in node._v_attrs:
+        if u('tz') in node._v_attrs:
             kwargs['tz'] = node._v_attrs['tz']
 
-        if kind in (six.u('date'), six.u('datetime')):
+        if kind in (u('date'), u('datetime')):
             index = factory(_unconvert_index(data, kind, encoding=self.encoding), dtype=object,
                             **kwargs)
         else:
@@ -2038,7 +2036,7 @@ class LegacyFrameStorer(LegacyStorer):
         return DataFrame(values, index=index, columns=columns)
 
 class SeriesStorer(GenericStorer):
-    pandas_kind = six.u('series')
+    pandas_kind = u('series')
     attributes = ['name']
 
     @property
@@ -2065,7 +2063,7 @@ class SeriesStorer(GenericStorer):
         self.attrs.name = obj.name
 
 class SparseSeriesStorer(GenericStorer):
-    pandas_kind = six.u('sparse_series')
+    pandas_kind = u('sparse_series')
     attributes = ['name','fill_value','kind']
 
     def read(self, **kwargs):
@@ -2074,7 +2072,7 @@ class SparseSeriesStorer(GenericStorer):
         sp_values = self.read_array('sp_values')
         sp_index = self.read_index('sp_index')
         return SparseSeries(sp_values, index=index, sparse_index=sp_index,
-                            kind=self.kind or six.u('block'), fill_value=self.fill_value,
+                            kind=self.kind or u('block'), fill_value=self.fill_value,
                             name=self.name)
 
     def write(self, obj, **kwargs):
@@ -2087,7 +2085,7 @@ class SparseSeriesStorer(GenericStorer):
         self.attrs.kind = obj.kind
 
 class SparseFrameStorer(GenericStorer):
-    pandas_kind = six.u('sparse_frame')
+    pandas_kind = u('sparse_frame')
     attributes = ['default_kind','default_fill_value']
 
     def read(self, **kwargs):
@@ -2119,7 +2117,7 @@ class SparseFrameStorer(GenericStorer):
         self.write_index('columns', obj.columns)
 
 class SparsePanelStorer(GenericStorer):
-    pandas_kind = six.u('sparse_panel')
+    pandas_kind = u('sparse_panel')
     attributes = ['default_kind','default_fill_value']
 
     def read(self, **kwargs):
@@ -2223,11 +2221,11 @@ class BlockManagerStorer(GenericStorer):
             self.write_index('block%d_items' % i, blk.items)
 
 class FrameStorer(BlockManagerStorer):
-    pandas_kind = six.u('frame')
+    pandas_kind = u('frame')
     obj_type    = DataFrame
 
 class PanelStorer(BlockManagerStorer):
-    pandas_kind = six.u('wide')
+    pandas_kind = u('wide')
     obj_type    = Panel
     is_shape_reversed = True
 
@@ -2252,7 +2250,7 @@ class Table(Storer):
         levels        : the names of levels
 
         """
-    pandas_kind = six.u('wide_table')
+    pandas_kind = u('wide_table')
     table_type  = None
     levels      = 1
     is_table    = True
@@ -2326,7 +2324,7 @@ class Table(Storer):
     @property
     def is_exists(self):
         """ has this table been created """
-        return six.u('table') in self.group
+        return u('table') in self.group
 
     @property
     def storable(self):
@@ -2845,7 +2843,7 @@ class WORMTable(Table):
          table. writing is a one-time operation the data are stored in a format
          that allows for searching the data on disk
          """
-    table_type = six.u('worm')
+    table_type = u('worm')
 
     def read(self, **kwargs):
         """ read the indicies and the indexing array, calculate offset rows and
@@ -2870,7 +2868,7 @@ class LegacyTable(Table):
                    IndexCol(name='column', axis=2,
                             pos=1, index_kind='columns_kind'),
                    DataCol(name='fields', cname='values', kind_attr='fields', pos=2)]
-    table_type = six.u('legacy')
+    table_type = u('legacy')
     ndim = 3
 
     def write(self, **kwargs):
@@ -2960,8 +2958,8 @@ class LegacyTable(Table):
 
 class LegacyFrameTable(LegacyTable):
     """ support the legacy frame table """
-    pandas_kind = six.u('frame_table')
-    table_type = six.u('legacy_frame')
+    pandas_kind = u('frame_table')
+    table_type = u('legacy_frame')
     obj_type = Panel
 
     def read(self, *args, **kwargs):
@@ -2970,14 +2968,14 @@ class LegacyFrameTable(LegacyTable):
 
 class LegacyPanelTable(LegacyTable):
     """ support the legacy panel table """
-    table_type = six.u('legacy_panel')
+    table_type = u('legacy_panel')
     obj_type = Panel
 
 
 class AppendableTable(LegacyTable):
     """ suppor the new appendable table formats """
     _indexables = None
-    table_type = six.u('appendable')
+    table_type = u('appendable')
 
     def write(self, obj, axes=None, append=False, complib=None,
               complevel=None, fletcher32=None, min_itemsize=None, chunksize=None,
@@ -3140,8 +3138,8 @@ class AppendableTable(LegacyTable):
 
 class AppendableFrameTable(AppendableTable):
     """ suppor the new appendable table formats """
-    pandas_kind = six.u('frame_table')
-    table_type = six.u('appendable_frame')
+    pandas_kind = u('frame_table')
+    table_type = u('appendable_frame')
     ndim = 2
     obj_type = DataFrame
 
@@ -3195,8 +3193,8 @@ class AppendableFrameTable(AppendableTable):
 
 class GenericTable(AppendableFrameTable):
     """ a table that read/writes the generic pytables table format """
-    pandas_kind = six.u('frame_table')
-    table_type = six.u('generic_table')
+    pandas_kind = u('frame_table')
+    table_type = u('generic_table')
     ndim = 2
     obj_type = DataFrame
 
@@ -3240,13 +3238,13 @@ class GenericTable(AppendableFrameTable):
 
 class AppendableMultiFrameTable(AppendableFrameTable):
     """ a frame with a multi-index """
-    table_type = six.u('appendable_multiframe')
+    table_type = u('appendable_multiframe')
     obj_type = DataFrame
     ndim = 2
 
     @property
     def table_type_short(self):
-        return six.u('appendable_multi')
+        return u('appendable_multi')
 
     def write(self, obj, data_columns=None, **kwargs):
         if data_columns is None:
@@ -3271,7 +3269,7 @@ class AppendableMultiFrameTable(AppendableFrameTable):
 
 class AppendablePanelTable(AppendableTable):
     """ suppor the new appendable table formats """
-    table_type = six.u('appendable_panel')
+    table_type = u('appendable_panel')
     ndim = 3
     obj_type = Panel
 
@@ -3288,7 +3286,7 @@ class AppendablePanelTable(AppendableTable):
 
 class AppendableNDimTable(AppendablePanelTable):
     """ suppor the new appendable table formats """
-    table_type = six.u('appendable_ndim')
+    table_type = u('appendable_ndim')
     ndim = 4
     obj_type = Panel4D
 
@@ -3356,18 +3354,18 @@ def _convert_index(index, encoding=None):
 
 def _unconvert_index(data, kind, encoding=None):
     kind = _ensure_decoded(kind)
-    if kind == six.u('datetime64'):
+    if kind == u('datetime64'):
         index = DatetimeIndex(data)
-    elif kind == six.u('datetime'):
+    elif kind == u('datetime'):
         index = np.array([datetime.fromtimestamp(v) for v in data],
                          dtype=object)
-    elif kind == six.u('date'):
+    elif kind == u('date'):
         index = np.array([date.fromtimestamp(v) for v in data], dtype=object)
-    elif kind in (six.u('integer'), six.u('float')):
+    elif kind in (u('integer'), u('float')):
         index = np.array(data)
-    elif kind in (six.u('string')):
+    elif kind in (u('string')):
         index = _unconvert_string_array(data, nan_rep=None, encoding=encoding)
-    elif kind == six.u('object'):
+    elif kind == u('object'):
         index = np.array(data[0])
     else:  # pragma: no cover
         raise ValueError('unrecognized index type %s' % kind)
@@ -3375,11 +3373,11 @@ def _unconvert_index(data, kind, encoding=None):
 
 def _unconvert_index_legacy(data, kind, legacy=False, encoding=None):
     kind = _ensure_decoded(kind)
-    if kind == six.u('datetime'):
+    if kind == u('datetime'):
         index = lib.time64_to_datetime(data)
-    elif kind in (six.u('integer')):
+    elif kind in (u('integer')):
         index = np.array(data, dtype=object)
-    elif kind in (six.u('string')):
+    elif kind in (u('string')):
         index = _unconvert_string_array(data, nan_rep=None, encoding=encoding)
     else:  # pragma: no cover
         raise ValueError('unrecognized index type %s' % kind)
@@ -3437,7 +3435,7 @@ def _get_converter(kind, encoding):
 
 def _need_convert(kind):
     kind = _ensure_decoded(kind)
-    if kind in (six.u('datetime'), six.u('datetime64'), six.u('string')):
+    if kind in (u('datetime'), u('datetime64'), u('string')):
         return True
     return False
 
@@ -3503,7 +3501,7 @@ class Term(StringMixin):
             self.value = field.value
 
         # a string expression (or just the field)
-        elif isinstance(field, six.string_types):
+        elif isinstance(field, compat.string_types):
 
             # is a term is passed
             s = self._search.match(field)
@@ -3516,7 +3514,7 @@ class Term(StringMixin):
                 self.field = field
 
                 # is an op passed?
-                if isinstance(op, six.string_types) and op in self._ops:
+                if isinstance(op, compat.string_types) and op in self._ops:
                     self.op = op
                     self.value = value
                 else:
@@ -3537,7 +3535,7 @@ class Term(StringMixin):
 
         # we have valid conditions
         if self.op in ['>', '>=', '<', '<=']:
-            if hasattr(self.value, '__iter__') and len(self.value) > 1 and not isinstance(self.value,six.string_types):
+            if hasattr(self.value, '__iter__') and len(self.value) > 1 and not isinstance(self.value,compat.string_types):
                 raise ValueError("an inequality condition cannot have multiple values [%s]" % str(self))
 
         if not is_list_like(self.value):
@@ -3627,36 +3625,36 @@ class Term(StringMixin):
             return value
 
         kind = _ensure_decoded(self.kind)
-        if kind == six.u('datetime64') or kind == six.u('datetime'):
+        if kind == u('datetime64') or kind == u('datetime'):
             v = lib.Timestamp(v)
             if v.tz is not None:
                 v = v.tz_convert('UTC')
             return TermValue(v,v.value,kind)
         elif (isinstance(v, datetime) or hasattr(v, 'timetuple')
-              or kind == six.u('date')):
+              or kind == u('date')):
             v = time.mktime(v.timetuple())
             return TermValue(v,Timestamp(v),kind)
-        elif kind == six.u('integer'):
+        elif kind == u('integer'):
             v = int(float(v))
             return TermValue(v,v,kind)
-        elif kind == six.u('float'):
+        elif kind == u('float'):
             v = float(v)
             return TermValue(v,v,kind)
-        elif kind == six.u('bool'):
-            if isinstance(v, six.string_types):
-                poss_vals = [six.u('false'), six.u('f'), six.u('no'),
-                             six.u('n'), six.u('none'), six.u('0'),
-                             six.u('[]'), six.u('{}'), six.u('')]
+        elif kind == u('bool'):
+            if isinstance(v, compat.string_types):
+                poss_vals = [u('false'), u('f'), u('no'),
+                             u('n'), u('none'), u('0'),
+                             u('[]'), u('{}'), u('')]
                 v = not v.strip().lower() in poss_vals
             else:
                 v = bool(v)
             return TermValue(v,v,kind)
-        elif not isinstance(v, six.string_types):
+        elif not isinstance(v, compat.string_types):
             v = stringify(v)
-            return TermValue(v,stringify(v),six.u('string'))
+            return TermValue(v,stringify(v),u('string'))
 
         # string quoting
-        return TermValue(v,stringify(v),six.u('string'))
+        return TermValue(v,stringify(v),u('string'))
 
 class TermValue(object):
     """ hold a term value the we use to construct a condition/filter """
@@ -3669,7 +3667,7 @@ class TermValue(object):
     def tostring(self, encoding):
         """ quote the string if not encoded
             else encode and return """
-        if self.kind == six.u('string'):
+        if self.kind == u('string'):
             if encoding is not None:
                 return self.converted
             return '"%s"' % self.converted
@@ -3744,7 +3742,7 @@ class Selection(object):
             # operands inside any terms
             if not any([isinstance(w, (list, tuple, Term)) for w in where]):
 
-                if not any([isinstance(w, six.string_types) and Term._search.match(w) for w in where]):
+                if not any([isinstance(w, compat.string_types) and Term._search.match(w) for w in where]):
                     where = [where]
 
         queryables = self.table.queryables()
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index c5111c77c..3a88f4e3b 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -5,14 +5,13 @@ retrieval and to reduce dependency on DB-specific API.
 from __future__ import print_function
 from datetime import datetime, date
 
-from pandas.util.py3compat import range, lzip
+from pandas.util.compat import range, lzip, map, zip
+import pandas.util.compat as compat
 import numpy as np
 import traceback
 
 from pandas.core.datetools import format as date_format
-from pandas.core.api import DataFrame, isnull
-from pandas.util.py3compat import map, zip
-import six
+from pandas.core.api import DataFrame
 
 #------------------------------------------------------------------------------
 # Helper execution function
@@ -176,6 +175,7 @@ def read_frame(sql, con, index_col=None, coerce_float=True, params=None):
 frame_query = read_frame
 read_sql = read_frame
 
+
 def write_frame(frame, name, con, flavor='sqlite', if_exists='fail', **kwargs):
     """
     Write records stored in a DataFrame to a SQL database.
@@ -197,9 +197,9 @@ def write_frame(frame, name, con, flavor='sqlite', if_exists='fail', **kwargs):
         warnings.warn("append is deprecated, use if_exists instead",
                       FutureWarning)
         if kwargs['append']:
-            if_exists='append'
+            if_exists = 'append'
         else:
-            if_exists='fail'
+            if_exists = 'fail'
     exists = table_exists(name, con, flavor)
     if if_exists == 'fail' and exists:
         raise ValueError("Table '%s' already exists." % name)
@@ -219,8 +219,8 @@ def write_frame(frame, name, con, flavor='sqlite', if_exists='fail', **kwargs):
     cur = con.cursor()
     # Replace spaces in DataFrame column names with _.
     safe_names = [s.replace(' ', '_').strip() for s in frame.columns]
-    flavor_picker = {'sqlite' : _write_sqlite,
-                     'mysql' : _write_mysql}
+    flavor_picker = {'sqlite': _write_sqlite,
+                     'mysql': _write_mysql}
 
     func = flavor_picker.get(flavor, None)
     if func is None:
@@ -229,6 +229,7 @@ def write_frame(frame, name, con, flavor='sqlite', if_exists='fail', **kwargs):
     cur.close()
     con.commit()
 
+
 def _write_sqlite(frame, table, names, cur):
     bracketed_names = ['[' + column + ']' for column in names]
     col_names = ','.join(bracketed_names)
@@ -236,12 +237,13 @@ def _write_sqlite(frame, table, names, cur):
     insert_query = 'INSERT INTO %s (%s) VALUES (%s)' % (
         table, col_names, wildcards)
     # pandas types are badly handled if there is only 1 column ( Issue #3628 )
-    if   not len(frame.columns  )==1 :
+    if not len(frame.columns) == 1:
         data = [tuple(x) for x in frame.values]
-    else :
+    else:
         data = [tuple(x) for x in frame.values.tolist()]
     cur.executemany(insert_query, data)
 
+
 def _write_mysql(frame, table, names, cur):
     bracketed_names = ['`' + column + '`' for column in names]
     col_names = ','.join(bracketed_names)
@@ -251,16 +253,18 @@ def _write_mysql(frame, table, names, cur):
     data = [tuple(x) for x in frame.values]
     cur.executemany(insert_query, data)
 
+
 def table_exists(name, con, flavor):
     flavor_map = {
         'sqlite': ("SELECT name FROM sqlite_master "
                    "WHERE type='table' AND name='%s';") % name,
-        'mysql' : "SHOW TABLES LIKE '%s'" % name}
+        'mysql': "SHOW TABLES LIKE '%s'" % name}
     query = flavor_map.get(flavor, None)
     if query is None:
         raise NotImplementedError
     return len(tquery(query, con)) > 0
 
+
 def get_sqltype(pytype, flavor):
     sqltype = {'mysql': 'VARCHAR (63)',
                'sqlite': 'TEXT'}
@@ -288,6 +292,7 @@ def get_sqltype(pytype, flavor):
 
     return sqltype[flavor]
 
+
 def get_schema(frame, name, flavor, keys=None):
     "Return a CREATE TABLE statement to suit the contents of a DataFrame."
     lookup_type = lambda dtype: get_sqltype(dtype.type, flavor)
@@ -301,7 +306,7 @@ def get_schema(frame, name, flavor, keys=None):
 
     keystr = ''
     if keys is not None:
-        if isinstance(keys, six.string_types):
+        if isinstance(keys, compat.string_types):
             keys = (keys,)
         keystr = ', PRIMARY KEY (%s)' % ','.join(keys)
     template = """CREATE TABLE %(name)s (
@@ -312,6 +317,7 @@ def get_schema(frame, name, flavor, keys=None):
                                    'keystr': keystr}
     return create_statement
 
+
 def sequence2dict(seq):
     """Helper function for cx_Oracle.
 
@@ -324,6 +330,6 @@ def sequence2dict(seq):
     http://www.gingerandjohn.com/archives/2004/02/26/cx_oracle-executemany-example/
     """
     d = {}
-    for k,v in zip(range(1, 1 + len(seq)), seq):
+    for k, v in zip(range(1, 1 + len(seq)), seq):
         d[str(k)] = v
     return d
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 338c6e1ac..1ffd99b1c 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -19,9 +19,9 @@ from pandas.core.frame import DataFrame
 from pandas.core.series import Series
 from pandas.core.categorical import Categorical
 import datetime
-from pandas.util import py3compat
 from pandas.util import compat
-from pandas.util.py3compat import StringIO, long, lrange, lmap, lzip
+from pandas.util import compat
+from pandas.util.compat import StringIO, long, lrange, lmap, lzip
 from pandas import isnull
 from pandas.io.parsers import _parser_params, Appender
 from pandas.io.common import get_filepath_or_buffer
@@ -256,7 +256,7 @@ class StataParser(object):
             }
 
     def _decode_bytes(self, str, errors=None):
-        if py3compat.PY3:
+        if compat.PY3:
             return str.decode(self._encoding, errors)
         else:
             return str
@@ -298,7 +298,7 @@ class StataReader(StataParser):
             if encoding is not None:
                 self._encoding = encoding
 
-        if type(path_or_buf) is str:
+        if isinstance(path_or_buf, (str, compat.text_type, bytes)):
             self.path_or_buf = open(path_or_buf, 'rb')
         else:
             self.path_or_buf = path_or_buf
@@ -403,7 +403,7 @@ class StataReader(StataParser):
         return d
 
     def _null_terminate(self, s):
-        if py3compat.PY3:  # have bytes not strings, so must decode
+        if compat.PY3:  # have bytes not strings, so must decode
             null_byte = b"\0"
             try:
                 s = s[:s.index(null_byte)]
@@ -545,7 +545,7 @@ class StataReader(StataParser):
                 data[col] = data[col].apply(_stata_elapsed_date_to_datetime, args=(self.fmtlist[i],))
 
         if convert_categoricals:
-            cols = np.where(lmap(lambda x: x in six.iterkeys(self.value_label_dict), self.lbllist))[0]
+            cols = np.where(lmap(lambda x: x in compat.iterkeys(self.value_label_dict), self.lbllist))[0]
             for i in cols:
                 col = data.columns[i]
                 labeled_data = np.copy(data[col])
@@ -751,7 +751,7 @@ class StataWriter(StataParser):
         """
         Helper to call encode before writing to file for Python 3 compat.
         """
-        if py3compat.PY3:
+        if compat.PY3:
             self._file.write(to_write.encode(self._encoding))
         else:
             self._file.write(to_write)
@@ -907,7 +907,7 @@ class StataWriter(StataParser):
 
     def _null_terminate(self, s, as_string=False):
         null_byte = '\x00'
-        if py3compat.PY3 and not as_string:
+        if compat.PY3 and not as_string:
             s += null_byte
             return s.encode(self._encoding)
         else:
diff --git a/pandas/io/tests/generate_legacy_pickles.py b/pandas/io/tests/generate_legacy_pickles.py
index 85052ed2b..ab08ff505 100644
--- a/pandas/io/tests/generate_legacy_pickles.py
+++ b/pandas/io/tests/generate_legacy_pickles.py
@@ -1,7 +1,7 @@
 """ self-contained to write legacy pickle files """
 from __future__ import print_function
 
-from pandas.util.py3compat import zip, cPickle as pickle
+from pandas.util.compat import zip, cPickle as pickle
 
 def _create_sp_series():
 
diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index b3c88611d..d15262bb6 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -2,7 +2,7 @@
 C/Cython ascii file parser tests
 """
 
-from pandas.util.py3compat import StringIO, BytesIO
+from pandas.util.compat import StringIO, BytesIO, map
 from datetime import datetime
 from pandas.util import compat
 import csv
@@ -23,15 +23,13 @@ from pandas.io.parsers import (read_csv, read_table, read_fwf,
 from pandas.util.testing import (assert_almost_equal, assert_frame_equal,
                                  assert_series_equal, network)
 import pandas.lib as lib
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.lib import Timestamp
 
 import pandas.util.testing as tm
 
 from pandas.parser import TextReader
 import pandas.parser as parser
-import six
-from pandas.util.py3compat import map
 
 
 class TestCParser(unittest.TestCase):
diff --git a/pandas/io/tests/test_data.py b/pandas/io/tests/test_data.py
index a6ccc56fb..1e1267558 100644
--- a/pandas/io/tests/test_data.py
+++ b/pandas/io/tests/test_data.py
@@ -14,7 +14,6 @@ from pandas.io.data import DataReader, SymbolWarning
 from pandas.util.testing import (assert_series_equal, assert_produces_warning,
                                  network, assert_frame_equal)
 from numpy.testing import assert_array_equal
-import six
 
 
 def assert_n_failed_equals_n_null_columns(wngs, obj, cls=SymbolWarning):
diff --git a/pandas/io/tests/test_date_converters.py b/pandas/io/tests/test_date_converters.py
index 396912c0f..13f03683d 100644
--- a/pandas/io/tests/test_date_converters.py
+++ b/pandas/io/tests/test_date_converters.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import StringIO, BytesIO
+from pandas.util.compat import StringIO, BytesIO
 from datetime import date, datetime
 import csv
 import os
@@ -19,7 +19,7 @@ from pandas.io.parsers import (read_csv, read_table, read_fwf,
 from pandas.util.testing import (assert_almost_equal, assert_frame_equal,
                                  assert_series_equal, network)
 import pandas.lib as lib
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.lib import Timestamp
 import pandas.io.date_converters as conv
 
diff --git a/pandas/io/tests/test_excel.py b/pandas/io/tests/test_excel.py
index 7726711de..764c5959e 100644
--- a/pandas/io/tests/test_excel.py
+++ b/pandas/io/tests/test_excel.py
@@ -1,9 +1,8 @@
 # pylint: disable=E1101
 
-from pandas.util.py3compat import StringIO, BytesIO, PY3
+from pandas.util.compat import StringIO, BytesIO, PY3, u, range, map
 from datetime import datetime
 from os.path import split as psplit
-from pandas.util.py3compat import range
 import csv
 import os
 import sys
@@ -28,7 +27,7 @@ import pandas.util.testing as tm
 import pandas as pd
 
 import pandas.lib as lib
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.lib import Timestamp
 from pandas.tseries.index import date_range
 import pandas.tseries.tools as tools
@@ -36,8 +35,6 @@ import pandas.tseries.tools as tools
 from numpy.testing.decorators import slow
 
 from pandas.parser import OverflowError
-import six
-from pandas.util.py3compat import map
 
 def _skip_if_no_xlrd():
     try:
@@ -710,7 +707,7 @@ class ExcelTests(unittest.TestCase):
         _skip_if_no_excelsuite()
 
         for ext in ['xls', 'xlsx']:
-            filename = six.u('\u0192u.') + ext
+            filename = u('\u0192u.') + ext
 
             try:
                 f = open(filename, 'wb')
diff --git a/pandas/io/tests/test_html.py b/pandas/io/tests/test_html.py
index 3c6848d86..09e2c86dd 100644
--- a/pandas/io/tests/test_html.py
+++ b/pandas/io/tests/test_html.py
@@ -1,10 +1,8 @@
 from __future__ import print_function
 import os
 import re
-from pandas.util.py3compat import StringIO
 from unittest import TestCase
 import warnings
-import six
 from distutils.version import LooseVersion
 from pandas.io.common import URLError
 
@@ -14,7 +12,8 @@ from nose.tools import assert_raises
 import numpy as np
 from numpy.random import rand
 from numpy.testing.decorators import slow
-from pandas.util.py3compat import map, zip
+from pandas.util.compat import map, zip, StringIO
+import pandas.util.compat as compat
 
 try:
     from importlib import import_module
@@ -45,7 +44,7 @@ def _skip_if_no(module_name):
 
 
 def _skip_if_none_of(module_names):
-    if isinstance(module_names, six.string_types):
+    if isinstance(module_names, compat.string_types):
         _skip_if_no(module_names)
         if module_names == 'bs4':
             import bs4
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index f27345b91..94138ccbc 100644
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -2,10 +2,9 @@
 # pylint: disable-msg=W0612,E1101
 from copy import deepcopy
 from datetime import datetime, timedelta
-from pandas.util.py3compat import range, lrange, StringIO
+from pandas.util.compat import range, lrange, StringIO, cPickle as pickle
 from pandas.util import compat
 from pandas.io.common import URLError
-from pandas.util.py3compat import cPickle as pickle
 import operator
 import os
 import unittest
diff --git a/pandas/io/tests/test_json/test_ujson.py b/pandas/io/tests/test_json/test_ujson.py
index cbea04ffb..6d89daa7e 100644
--- a/pandas/io/tests/test_json/test_ujson.py
+++ b/pandas/io/tests/test_json/test_ujson.py
@@ -16,12 +16,10 @@ import re
 import random
 import decimal
 from functools import partial
-from pandas.util.py3compat import range, StringIO
+from pandas.util.compat import range, zip, StringIO, u
 from pandas.util import compat
 import pandas.json as ujson
-import six
-from pandas.util.py3compat import zip
-import pandas.util.py3compat as py3compat
+import pandas.util.compat as compat
 
 import numpy as np
 from pandas.util.testing import assert_almost_equal
@@ -72,7 +70,7 @@ class UltraJSONTests(TestCase):
         helper(html_encoded, ensure_ascii=False, encode_html_chars=True)
 
     def test_doubleLongIssue(self):
-        sut = {six.u('a'): -4342969734183514}
+        sut = {u('a'): -4342969734183514}
         encoded = json.dumps(sut)
         decoded = json.loads(encoded)
         self.assertEqual(sut, decoded)
@@ -81,7 +79,7 @@ class UltraJSONTests(TestCase):
         self.assertEqual(sut, decoded)
 
     def test_doubleLongDecimalIssue(self):
-        sut = {six.u('a'): -12345678901234.56789012}
+        sut = {u('a'): -12345678901234.56789012}
         encoded = json.dumps(sut)
         decoded = json.loads(encoded)
         self.assertEqual(sut, decoded)
@@ -91,12 +89,12 @@ class UltraJSONTests(TestCase):
 
 
     def test_encodeDecodeLongDecimal(self):
-        sut = {six.u('a'): -528656961.4399388}
+        sut = {u('a'): -528656961.4399388}
         encoded = ujson.dumps(sut, double_precision=15)
         ujson.decode(encoded)
 
     def test_decimalDecodeTestPrecise(self):
-        sut = {six.u('a'): 4.56}
+        sut = {u('a'): 4.56}
         encoded = ujson.encode(sut)
         decoded = ujson.decode(encoded, precise_float=True)
         self.assertEqual(sut, decoded)
@@ -112,16 +110,16 @@ class UltraJSONTests(TestCase):
         self.assert_(np.allclose(num, ujson.decode(ujson.encode(num))))
 
     def test_encodeDictWithUnicodeKeys(self):
-        input = {six.u("key1"): six.u("value1"), six.u("key1"):
-                six.u("value1"), six.u("key1"): six.u("value1"),
-                six.u("key1"): six.u("value1"), six.u("key1"):
-                six.u("value1"), six.u("key1"): six.u("value1")}
+        input = {u("key1"): u("value1"), u("key1"):
+                u("value1"), u("key1"): u("value1"),
+                u("key1"): u("value1"), u("key1"):
+                u("value1"), u("key1"): u("value1")}
         output = ujson.encode(input)
 
-        input = {six.u("بن"): six.u("value1"), six.u("بن"): six.u("value1"),
-                six.u("بن"): six.u("value1"), six.u("بن"): six.u("value1"),
-                six.u("بن"): six.u("value1"), six.u("بن"): six.u("value1"),
-                six.u("بن"): six.u("value1")}
+        input = {u("بن"): u("value1"), u("بن"): u("value1"),
+                u("بن"): u("value1"), u("بن"): u("value1"),
+                u("بن"): u("value1"), u("بن"): u("value1"),
+                u("بن"): u("value1")}
         output = ujson.encode(input)
 
         pass
@@ -370,7 +368,7 @@ class UltraJSONTests(TestCase):
         self.assertEquals(dec, json.loads(enc))
 
     def test_decodeFromUnicode(self):
-        input = six.u("{\"obj\": 31337}")
+        input = u("{\"obj\": 31337}")
         dec1 = ujson.decode(input)
         dec2 = ujson.decode(str(input))
         self.assertEquals(dec1, dec2)
@@ -620,7 +618,7 @@ class UltraJSONTests(TestCase):
         self.assertEquals(output, json.dumps(input))
         self.assertEquals(input, ujson.decode(output))
 
-        self.assertEquals('"  \\u0000\\r\\n "', ujson.dumps(six.u("  \u0000\r\n ")))
+        self.assertEquals('"  \\u0000\\r\\n "', ujson.dumps(u("  \u0000\r\n ")))
         pass
 
     def test_decodeNullCharacter(self):
@@ -779,7 +777,7 @@ class UltraJSONTests(TestCase):
 
     def test_encodeBigEscape(self):
         for x in range(10):
-            if py3compat.PY3:
+            if compat.PY3:
                 base = '\u00e5'.encode('utf-8')
             else:
                 base = "\xc3\xa5"
@@ -788,16 +786,16 @@ class UltraJSONTests(TestCase):
 
     def test_decodeBigEscape(self):
         for x in range(10):
-            if py3compat.PY3:
+            if compat.PY3:
                 base = '\u00e5'.encode('utf-8')
             else:
                 base = "\xc3\xa5"
-            quote = py3compat.str_to_bytes("\"")
+            quote = compat.str_to_bytes("\"")
             input = quote + (base * 1024 * 1024 * 2) + quote
             output = ujson.decode(input)
 
     def test_toDict(self):
-        d = {six.u("key"): 31337}
+        d = {u("key"): 31337}
 
         class DictTest:
             def toDict(self):
@@ -1043,16 +1041,16 @@ class NumpyJSONTests(TestCase):
         output = ujson.loads(ujson.dumps(input), numpy=True, labelled=True)
         self.assertTrue((np.array([42]) == output[0]).all())
         self.assertTrue(output[1] is None)
-        self.assertTrue((np.array([six.u('a')]) == output[2]).all())
+        self.assertTrue((np.array([u('a')]) == output[2]).all())
 
         # py3 is non-determinstic on the ordering......
-        if not py3compat.PY3:
+        if not compat.PY3:
             input = [{'a': 42, 'b':31}, {'a': 24, 'c': 99}, {'a': 2.4, 'b': 78}]
             output = ujson.loads(ujson.dumps(input), numpy=True, labelled=True)
             expectedvals = np.array([42, 31, 24, 99, 2.4, 78], dtype=int).reshape((3,2))
             self.assertTrue((expectedvals == output[0]).all())
             self.assertTrue(output[1] is None)
-            self.assertTrue((np.array([six.u('a'), 'b']) == output[2]).all())
+            self.assertTrue((np.array([u('a'), 'b']) == output[2]).all())
 
 
             input = {1: {'a': 42, 'b':31}, 2: {'a': 24, 'c': 99}, 3: {'a': 2.4, 'b': 78}}
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index eeb34862f..0f46ffa90 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -12,7 +12,9 @@ from numpy import nan
 import numpy as np
 
 from pandas import DataFrame, Series, Index, MultiIndex, DatetimeIndex
-from pandas.util.py3compat import StringIO, BytesIO, PY3, range, long, lrange, lmap
+from pandas.util.compat import(
+    StringIO, BytesIO, PY3, range, long, lrange, lmap, u, map, StringIO
+)
 from pandas.io.common import urlopen, URLError
 import pandas.io.parsers as parsers
 from pandas.io.parsers import (read_csv, read_table, read_fwf,
@@ -26,7 +28,7 @@ import pandas.util.testing as tm
 import pandas as pd
 
 import pandas.lib as lib
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.lib import Timestamp
 from pandas.tseries.index import date_range
 import pandas.tseries.tools as tools
@@ -34,8 +36,6 @@ import pandas.tseries.tools as tools
 from numpy.testing.decorators import slow
 
 from pandas.parser import OverflowError
-import six
-from pandas.util.py3compat import map
 
 
 class ParserTests(object):
@@ -108,12 +108,12 @@ g,7,seven
         tm.assert_frame_equal(xp.reindex(columns=df.columns), df)
 
     def test_read_csv(self):
-        if not py3compat.PY3:
+        if not compat.PY3:
             if 'win' in sys.platform:
-                prefix = six.u("file:///")
+                prefix = u("file:///")
             else:
-                prefix = six.u("file://")
-            fname = prefix + six.text_type(self.csv1)
+                prefix = u("file://")
+            fname = prefix + compat.text_type(self.csv1)
             # it works!
             df1 = read_csv(fname, index_col=0, parse_dates=True)
 
@@ -315,7 +315,7 @@ KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000"""
 
         df = self.read_csv(StringIO(data), parse_dates={'nominal': [1, 2]})
-        self.assert_(not isinstance(df.nominal[0], six.string_types))
+        self.assert_(not isinstance(df.nominal[0], compat.string_types))
 
     ts_data = """\
 ID,date,nominalTime,actualTime,A,B,C,D,E
@@ -869,9 +869,9 @@ baz,7,8,9
         tm.assert_frame_equal(df, df2)
 
     def test_read_table_unicode(self):
-        fin = BytesIO(six.u('\u0141aski, Jan;1').encode('utf-8'))
+        fin = BytesIO(u('\u0141aski, Jan;1').encode('utf-8'))
         df1 = read_table(fin, sep=";", encoding="utf-8", header=None)
-        tm.assert_isinstance(df1[0].values[0], six.text_type)
+        tm.assert_isinstance(df1[0].values[0], compat.text_type)
 
     def test_read_table_wrong_num_columns(self):
         # too few!
@@ -1556,13 +1556,13 @@ False,NA,True"""
 
     def test_utf16_bom_skiprows(self):
         # #2298
-        data = six.u("""skip this
+        data = u("""skip this
 skip this too
 A\tB\tC
 1\t2\t3
 4\t5\t6""")
 
-        data2 = six.u("""skip this
+        data2 = u("""skip this
 skip this too
 A,B,C
 1,2,3
@@ -1578,7 +1578,7 @@ A,B,C
                         f.write(bytes)
 
                     s = BytesIO(dat.encode('utf-8'))
-                    if py3compat.PY3:
+                    if compat.PY3:
                         # somewhat False since the code never sees bytes
                         from io import TextIOWrapper
                         s = TextIOWrapper(s, encoding='utf-8')
@@ -1597,7 +1597,7 @@ A,B,C
         result = self.read_table(path, encoding='utf-16')
         self.assertEquals(len(result), 50)
 
-        if not py3compat.PY3:
+        if not compat.PY3:
             buf = BytesIO(open(path, 'rb').read())
             result = self.read_table(buf, encoding='utf-16')
             self.assertEquals(len(result), 50)
@@ -1607,7 +1607,6 @@ A,B,C
         if hash(np.int64(-1)) != -2:
             raise nose.SkipTest
 
-        from pandas.util.py3compat import StringIO, lrange, lmap
         csv = """id,score,days
 1,2,12
 2,2-5,
@@ -1669,7 +1668,7 @@ A,B,C
         result = result.set_index(0)
 
         got = result[1][1632]
-        expected = six.u('\xc1 k\xf6ldum klaka (Cold Fever) (1994)')
+        expected = u('\xc1 k\xf6ldum klaka (Cold Fever) (1994)')
 
         self.assertEquals(got, expected)
 
@@ -1797,7 +1796,7 @@ baz|7|8|9
                               sep=None, skiprows=2)
         tm.assert_frame_equal(data, data3)
 
-        text = six.u("""ignore this
+        text = u("""ignore this
 ignore this too
 index|A|B|C
 foo|1|2|3
@@ -1806,7 +1805,7 @@ baz|7|8|9
 """).encode('utf-8')
 
         s = BytesIO(text)
-        if py3compat.PY3:
+        if compat.PY3:
             # somewhat False since the code never sees bytes
             from io import TextIOWrapper
             s = TextIOWrapper(s, encoding='utf-8')
@@ -2371,10 +2370,10 @@ class TestParseSQL(unittest.TestCase):
         assert_same_values_and_dtype(result, expected)
 
     def test_convert_sql_column_unicode(self):
-        arr = np.array([six.u('1.5'), None, six.u('3'), six.u('4.2')],
+        arr = np.array([u('1.5'), None, u('3'), u('4.2')],
                        dtype=object)
         result = lib.convert_sql_column(arr)
-        expected = np.array([six.u('1.5'), np.nan, six.u('3'), six.u('4.2')],
+        expected = np.array([u('1.5'), np.nan, u('3'), u('4.2')],
                             dtype=object)
         assert_same_values_and_dtype(result, expected)
 
diff --git a/pandas/io/tests/test_pickle.py b/pandas/io/tests/test_pickle.py
index 69a52f448..55e4756dc 100644
--- a/pandas/io/tests/test_pickle.py
+++ b/pandas/io/tests/test_pickle.py
@@ -14,7 +14,7 @@ import pandas.util.testing as tm
 import pandas as pd
 from pandas import Index
 from pandas.sparse.tests import test_sparse
-from pandas.util import py3compat
+from pandas.util import compat
 from pandas.util.misc import is_little_endian
 
 class TestPickle(unittest.TestCase):
@@ -36,7 +36,7 @@ class TestPickle(unittest.TestCase):
             # we are trying to read a py3 pickle in py2.....
             return
         except:
-            if not py3compat.PY3:
+            if not compat.PY3:
                 raise
             with open(vf,'rb') as fh:
                 data = pickle.load(fh, encoding='latin1')
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index e10c5ad41..ee5b70ccb 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1,5 +1,5 @@
 from __future__ import print_function
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange, u
 import nose
 import unittest
 import os
@@ -19,10 +19,9 @@ import pandas.util.testing as tm
 from pandas.tests.test_series import assert_series_equal
 from pandas.tests.test_frame import assert_frame_equal
 from pandas import concat, Timestamp
-from pandas.util import py3compat
+from pandas.util import compat
 
 from numpy.testing.decorators import slow
-import six
 
 try:
     import tables
@@ -1332,8 +1331,8 @@ class TestHDFStore(unittest.TestCase):
             l = [('date', datetime.date(2001, 1, 2))]
 
             # py3 ok for unicode
-            if not py3compat.PY3:
-                l.append(('unicode', six.u('\u03c3')))
+            if not compat.PY3:
+                l.append(('unicode', u('\u03c3')))
 
             ### currently not supported dtypes ####
             for n, f in l:
@@ -2813,7 +2812,7 @@ class TestHDFStore(unittest.TestCase):
 
     def test_unicode_index(self):
 
-        unicode_values = [six.u('\u03c3'), six.u('\u03c3\u03c3')]
+        unicode_values = [u('\u03c3'), u('\u03c3\u03c3')]
         warnings.filterwarnings('ignore', category=PerformanceWarning)
         s = Series(np.random.randn(len(unicode_values)), unicode_values)
         self._check_roundtrip(s, tm.assert_series_equal)
diff --git a/pandas/io/tests/test_sql.py b/pandas/io/tests/test_sql.py
index 5dc719953..8990515ce 100644
--- a/pandas/io/tests/test_sql.py
+++ b/pandas/io/tests/test_sql.py
@@ -11,8 +11,8 @@ import numpy as np
 
 from pandas.core.datetools import format as date_format
 from pandas.core.api import DataFrame, isnull
-from pandas.util.py3compat import StringIO, range, lrange
-import six
+from pandas.util.compat import StringIO, range, lrange
+import pandas.util.compat as compat
 
 import pandas.io.sql as sql
 import pandas.util.testing as tm
@@ -23,8 +23,8 @@ _formatters = {
     datetime: lambda dt: "'%s'" % date_format(dt),
     str: lambda x: "'%s'" % x,
     np.str_: lambda x: "'%s'" % x,
-    six.text_type: lambda x: "'%s'" % x,
-    six.binary_type: lambda x: "'%s'" % x,
+    compat.text_type: lambda x: "'%s'" % x,
+    compat.binary_type: lambda x: "'%s'" % x,
     float: lambda x: "%.8f" % x,
     int: lambda x: "%s" % x,
     type(None): lambda x: "NULL",
diff --git a/pandas/io/tests/test_stata.py b/pandas/io/tests/test_stata.py
index 3f2115052..d75de149d 100644
--- a/pandas/io/tests/test_stata.py
+++ b/pandas/io/tests/test_stata.py
@@ -13,7 +13,6 @@ from pandas.io.parsers import read_csv
 from pandas.io.stata import read_stata, StataReader
 import pandas.util.testing as tm
 from pandas.util.misc import is_little_endian
-import six
 
 
 class StataTests(unittest.TestCase):
diff --git a/pandas/io/tests/test_wb.py b/pandas/io/tests/test_wb.py
index e1492c13c..e85c63d7d 100644
--- a/pandas/io/tests/test_wb.py
+++ b/pandas/io/tests/test_wb.py
@@ -5,22 +5,21 @@ from pandas.util.testing import network
 from pandas.util.testing import assert_frame_equal
 from numpy.testing.decorators import slow
 from pandas.io.wb import search, download
-import six
 
 
 @slow
 @network
 def test_wdi_search():
     raise nose.SkipTest
-    expected = {six.u('id'): {2634: six.u('GDPPCKD'),
-                        4649: six.u('NY.GDP.PCAP.KD'),
-                        4651: six.u('NY.GDP.PCAP.KN'),
-                        4653: six.u('NY.GDP.PCAP.PP.KD')},
-                six.u('name'): {2634: six.u('GDP per Capita, constant US$, '
+    expected = {u('id'): {2634: u('GDPPCKD'),
+                        4649: u('NY.GDP.PCAP.KD'),
+                        4651: u('NY.GDP.PCAP.KN'),
+                        4653: u('NY.GDP.PCAP.PP.KD')},
+                u('name'): {2634: u('GDP per Capita, constant US$, '
                                              'millions'),
-                          4649: six.u('GDP per capita (constant 2000 US$)'),
-                          4651: six.u('GDP per capita (constant LCU)'),
-                          4653: six.u('GDP per capita, PPP (constant 2005 '
+                          4649: u('GDP per capita (constant 2000 US$)'),
+                          4651: u('GDP per capita (constant LCU)'),
+                          4653: u('GDP per capita, PPP (constant 2005 '
                                       'international $)')}}
     result = search('gdp.*capita.*constant').ix[:, :2]
     expected = pandas.DataFrame(expected)
@@ -32,7 +31,7 @@ def test_wdi_search():
 @network
 def test_wdi_download():
     raise nose.SkipTest
-    expected = {'GDPPCKN': {(six.u('United States'), six.u('2003')): six.u('40800.0735367688'), (six.u('Canada'), six.u('2004')): six.u('37857.1261134552'), (six.u('United States'), six.u('2005')): six.u('42714.8594790102'), (six.u('Canada'), six.u('2003')): six.u('37081.4575704003'), (six.u('United States'), six.u('2004')): six.u('41826.1728310667'), (six.u('Mexico'), six.u('2003')): six.u('72720.0691255285'), (six.u('Mexico'), six.u('2004')): six.u('74751.6003347038'), (six.u('Mexico'), six.u('2005')): six.u('76200.2154469437'), (six.u('Canada'), six.u('2005')): six.u('38617.4563629611')}, 'GDPPCKD': {(six.u('United States'), six.u('2003')): six.u('40800.0735367688'), (six.u('Canada'), six.u('2004')): six.u('34397.055116118'), (six.u('United States'), six.u('2005')): six.u('42714.8594790102'), (six.u('Canada'), six.u('2003')): six.u('33692.2812368928'), (six.u('United States'), six.u('2004')): six.u('41826.1728310667'), (six.u('Mexico'), six.u('2003')): six.u('7608.43848670658'), (six.u('Mexico'), six.u('2004')): six.u('7820.99026814334'), (six.u('Mexico'), six.u('2005')): six.u('7972.55364129367'), (six.u('Canada'), six.u('2005')): six.u('35087.8925933298')}}
+    expected = {'GDPPCKN': {(u('United States'), u('2003')): u('40800.0735367688'), (u('Canada'), u('2004')): u('37857.1261134552'), (u('United States'), u('2005')): u('42714.8594790102'), (u('Canada'), u('2003')): u('37081.4575704003'), (u('United States'), u('2004')): u('41826.1728310667'), (u('Mexico'), u('2003')): u('72720.0691255285'), (u('Mexico'), u('2004')): u('74751.6003347038'), (u('Mexico'), u('2005')): u('76200.2154469437'), (u('Canada'), u('2005')): u('38617.4563629611')}, 'GDPPCKD': {(u('United States'), u('2003')): u('40800.0735367688'), (u('Canada'), u('2004')): u('34397.055116118'), (u('United States'), u('2005')): u('42714.8594790102'), (u('Canada'), u('2003')): u('33692.2812368928'), (u('United States'), u('2004')): u('41826.1728310667'), (u('Mexico'), u('2003')): u('7608.43848670658'), (u('Mexico'), u('2004')): u('7820.99026814334'), (u('Mexico'), u('2005')): u('7972.55364129367'), (u('Canada'), u('2005')): u('35087.8925933298')}}
     expected = pandas.DataFrame(expected)
     result = download(country=['CA', 'MX', 'US', 'junk'], indicator=['GDPPCKD',
                                                                      'GDPPCKN', 'junk'], start=2003, end=2005)
diff --git a/pandas/io/wb.py b/pandas/io/wb.py
index 4563c0a08..867032cc9 100644
--- a/pandas/io/wb.py
+++ b/pandas/io/wb.py
@@ -1,7 +1,6 @@
 from __future__ import print_function
 
-from pandas.util.py3compat import map, reduce
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import map, reduce, range, lrange
 from pandas.io.common import urlopen
 from pandas.io import json
 import pandas
diff --git a/pandas/rpy/common.py b/pandas/rpy/common.py
index 66e3e1777..54fe50b44 100644
--- a/pandas/rpy/common.py
+++ b/pandas/rpy/common.py
@@ -4,8 +4,7 @@ developer-friendly.
 """
 from __future__ import print_function
 
-from pandas.util.py3compat import zip
-from pandas.util.py3compat import range
+from pandas.util.compat import zip, range
 import numpy as np
 
 import pandas as pd
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index 48fa9caa0..7dee8230b 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -11,7 +11,7 @@ import operator
 from pandas.core.base import PandasObject
 import pandas.core.common as com
 
-from pandas.util import py3compat
+from pandas.util import compat
 
 from pandas._sparse import BlockIndex, IntIndex
 import pandas._sparse as splib
@@ -216,7 +216,7 @@ to sparse
     __ipow__ = disable
 
     # Python 2 division operators
-    if not py3compat.PY3:
+    if not compat.PY3:
         __div__ = _sparse_op_wrap(operator.div, 'div')
         __rdiv__ = _sparse_op_wrap(lambda x, y: y / x, '__rdiv__')
         __idiv__ = disable
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index c889d4c19..4505aac4e 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -6,7 +6,7 @@ with float64 data
 # pylint: disable=E1101,E1103,W0231,E0202
 
 from numpy import nan
-from pandas.util.py3compat import range, lmap
+from pandas.util.compat import range, lmap, map
 from pandas.util import compat
 import numpy as np
 
@@ -23,7 +23,6 @@ import pandas.core.datetools as datetools
 from pandas.sparse.series import SparseSeries
 from pandas.util.decorators import Appender
 import pandas.lib as lib
-from pandas.util.py3compat import map
 
 
 class _SparseMockBlockManager(object):
diff --git a/pandas/sparse/panel.py b/pandas/sparse/panel.py
index e16dfdafd..3f6b5e0d7 100644
--- a/pandas/sparse/panel.py
+++ b/pandas/sparse/panel.py
@@ -5,8 +5,7 @@ with float64 data
 
 # pylint: disable=E1101,E1103,W0231
 
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, lrange, zip
 from pandas.util import compat
 import numpy as np
 
@@ -17,7 +16,6 @@ from pandas.sparse.frame import SparseDataFrame
 from pandas.util.decorators import deprecate
 
 import pandas.core.common as com
-import six
 
 
 class SparsePanelAxis(object):
@@ -35,7 +33,7 @@ class SparsePanelAxis(object):
         if isinstance(value, MultiIndex):
             raise NotImplementedError
 
-        for v in six.itervalues(obj._frames):
+        for v in compat.itervalues(obj._frames):
             setattr(v, self.frame_attr, value)
 
         setattr(obj, self.cache_field, value)
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index 802808954..866ee5cb1 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -17,7 +17,7 @@ from pandas.core.frame import DataFrame
 import pandas.core.common as com
 import pandas.core.datetools as datetools
 
-from pandas.util import py3compat
+from pandas.util import compat
 
 from pandas.sparse.array import (make_sparse, _sparse_array_op, SparseArray)
 from pandas._sparse import BlockIndex, IntIndex
@@ -265,7 +265,7 @@ class SparseSeries(SparseArray, Series):
     __rpow__ = _sparse_op_wrap(lambda x, y: y ** x, '__rpow__')
 
     # Python 2 division operators
-    if not py3compat.PY3:
+    if not compat.PY3:
         __div__ = _sparse_op_wrap(operator.div, 'div')
         __rdiv__ = _sparse_op_wrap(lambda x, y: y / x, '__rdiv__')
 
diff --git a/pandas/sparse/tests/test_array.py b/pandas/sparse/tests/test_array.py
index 178f8ea8c..f11632e28 100644
--- a/pandas/sparse/tests/test_array.py
+++ b/pandas/sparse/tests/test_array.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import re
 from numpy import nan, ndarray
 import numpy as np
diff --git a/pandas/sparse/tests/test_list.py b/pandas/sparse/tests/test_list.py
index 47ad7b0c1..8be3026dd 100644
--- a/pandas/sparse/tests/test_list.py
+++ b/pandas/sparse/tests/test_list.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import unittest
 
 from numpy import nan
diff --git a/pandas/sparse/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
index b39ec61f2..6a4280e05 100644
--- a/pandas/sparse/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -22,9 +22,8 @@ from pandas.tseries.index import DatetimeIndex
 import pandas.core.datetools as datetools
 from pandas.core.common import isnull
 import pandas.util.testing as tm
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange, cPickle as pickle, StringIO, lrange
 from pandas.util import compat
-from pandas.util.py3compat import cPickle as pickle
 
 import pandas.sparse.frame as spf
 
@@ -36,7 +35,6 @@ from pandas.sparse.api import (SparseSeries, SparseTimeSeries,
 import pandas.tests.test_frame as test_frame
 import pandas.tests.test_panel as test_panel
 import pandas.tests.test_series as test_series
-from pandas.util.py3compat import StringIO, lrange
 
 from .test_array import assert_sp_array_equal
 
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index 040e12922..b94ec6df7 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -1,7 +1,6 @@
 from __future__ import print_function
-from pandas.util.py3compat import range
+from pandas.util.compat import range, cStringIO as StringIO
 import os
-from pandas.util.py3compat import cStringIO as StringIO
 
 header = """
 cimport numpy as np
diff --git a/pandas/stats/fama_macbeth.py b/pandas/stats/fama_macbeth.py
index 9e4e62a07..04dd7e045 100644
--- a/pandas/stats/fama_macbeth.py
+++ b/pandas/stats/fama_macbeth.py
@@ -1,7 +1,6 @@
 from pandas.core.base import StringMixin
-from pandas.util.py3compat import StringIO
+from pandas.util.compat import StringIO, range
 
-from pandas.util.py3compat import range
 import numpy as np
 
 from pandas.core.api import Series, DataFrame
diff --git a/pandas/stats/math.py b/pandas/stats/math.py
index 7a36654a4..583c588c9 100644
--- a/pandas/stats/math.py
+++ b/pandas/stats/math.py
@@ -3,7 +3,7 @@
 
 from __future__ import division
 
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import numpy as np
 import numpy.linalg as linalg
 
diff --git a/pandas/stats/misc.py b/pandas/stats/misc.py
index 00c93e07c..aeeec7068 100644
--- a/pandas/stats/misc.py
+++ b/pandas/stats/misc.py
@@ -4,8 +4,7 @@ import numpy as np
 
 from pandas.core.api import Series, DataFrame, isnull, notnull
 from pandas.core.series import remove_na
-import six
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip
 
 
 def zscore(series):
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index f5ca39d01..9ea85739d 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -4,11 +4,8 @@ Ordinary least squares regression
 
 # pylint: disable-msg=W0201
 
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip, range, StringIO
 from itertools import starmap
-from pandas.util.py3compat import StringIO
-
-from pandas.util.py3compat import range
 from pandas.util import compat
 import numpy as np
 
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index fb9f3aadc..923f1b427 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -6,7 +6,7 @@ Linear regression objects for panel data
 # pylint: disable-msg=E1101,E1103
 
 from __future__ import division
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from pandas.util import compat
 import warnings
 
diff --git a/pandas/stats/tests/test_fama_macbeth.py b/pandas/stats/tests/test_fama_macbeth.py
index 2e55c3d5a..6d315ceec 100644
--- a/pandas/stats/tests/test_fama_macbeth.py
+++ b/pandas/stats/tests/test_fama_macbeth.py
@@ -2,7 +2,7 @@ from pandas import DataFrame, Panel
 from pandas.stats.api import fama_macbeth
 from .common import assert_almost_equal, BaseTest
 
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from pandas.util import compat
 import numpy as np
 
diff --git a/pandas/stats/tests/test_moments.py b/pandas/stats/tests/test_moments.py
index df483aa58..233ca78ce 100644
--- a/pandas/stats/tests/test_moments.py
+++ b/pandas/stats/tests/test_moments.py
@@ -1,5 +1,3 @@
-from pandas.util.py3compat import range
-from pandas.util.py3compat import zip
 import unittest
 import nose
 import sys
@@ -13,10 +11,10 @@ from pandas import Series, DataFrame, bdate_range, isnull, notnull
 from pandas.util.testing import (
     assert_almost_equal, assert_series_equal, assert_frame_equal
 )
-from pandas.util.py3compat import PY3
 import pandas.core.datetools as datetools
 import pandas.stats.moments as mom
 import pandas.util.testing as tm
+from pandas.util.compat import range, zip, PY3, StringIO
 
 N, K = 100, 10
 
@@ -489,7 +487,6 @@ class TestMoments(unittest.TestCase):
             assert_frame_equal(frame_xp, frame_rs)
 
     def test_legacy_time_rule_arg(self):
-        from pandas.util.py3compat import StringIO
         # suppress deprecation warnings
         sys.stderr = StringIO()
 
diff --git a/pandas/stats/tests/test_var.py b/pandas/stats/tests/test_var.py
index 99ee9f3bf..1c7eec126 100644
--- a/pandas/stats/tests/test_var.py
+++ b/pandas/stats/tests/test_var.py
@@ -3,7 +3,7 @@ from numpy.testing import run_module_suite, assert_equal, TestCase
 
 from pandas.util.testing import assert_almost_equal
 
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import nose
 import unittest
 
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index 524098292..2337dcf9c 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -1,7 +1,6 @@
 from __future__ import division
 
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip, reduce
+from pandas.util.compat import range, lrange, zip, reduce
 from pandas.util import compat
 import numpy as np
 from pandas.core.base import StringMixin
diff --git a/pandas/tests/test_algos.py b/pandas/tests/test_algos.py
index 4c832f785..af3b56e04 100644
--- a/pandas/tests/test_algos.py
+++ b/pandas/tests/test_algos.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import unittest
 
 import numpy as np
diff --git a/pandas/tests/test_categorical.py b/pandas/tests/test_categorical.py
index b0722c49e..dc60cda24 100644
--- a/pandas/tests/test_categorical.py
+++ b/pandas/tests/test_categorical.py
@@ -1,7 +1,7 @@
 # pylint: disable=E1101,E1103,W0232
 
 from datetime import datetime
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import unittest
 import nose
 
diff --git a/pandas/tests/test_common.py b/pandas/tests/test_common.py
index dc4ed0255..7001f582e 100644
--- a/pandas/tests/test_common.py
+++ b/pandas/tests/test_common.py
@@ -1,5 +1,4 @@
 from datetime import datetime
-from pandas.util.py3compat import range, long, lrange, lmap
 import sys
 import re
 
@@ -7,6 +6,7 @@ import nose
 import unittest
 
 from pandas import Series, DataFrame, date_range, DatetimeIndex, Timestamp
+from pandas.util.compat import range, long, lrange, lmap, u, map
 from pandas.core.common import notnull, isnull
 import pandas.core.common as com
 import pandas.util.testing as tm
@@ -15,9 +15,7 @@ import pandas.core.config as cf
 import numpy as np
 
 from pandas.tslib import iNaT
-from pandas.util import py3compat
-import six
-from pandas.util.py3compat import map
+from pandas.util import compat
 
 _multiprocess_can_split_ = True
 
@@ -27,7 +25,7 @@ def test_is_sequence():
     assert(is_seq((1, 2)))
     assert(is_seq([1, 2]))
     assert(not is_seq("abcd"))
-    assert(not is_seq(six.u("abcd")))
+    assert(not is_seq(u("abcd")))
     assert(not is_seq(np.int64))
 
     class A(object):
@@ -97,7 +95,7 @@ def test_isnull_lists():
     result = isnull(['foo', 'bar'])
     assert(not result.any())
 
-    result = isnull([six.u('foo'), six.u('bar')])
+    result = isnull([u('foo'), u('bar')])
     assert(not result.any())
 
 
@@ -314,7 +312,7 @@ def test_ensure_platform_int():
 #     On Python 2, if sys.stdin.encoding is None (IPython with zmq frontend)
 #     common.console_encode should encode things as utf-8.
 #     """
-#     if py3compat.PY3:
+#     if compat.PY3:
 #         raise nose.SkipTest
 
 #     with tm.stdin_encoding(encoding=None):
@@ -335,8 +333,8 @@ def test_is_re():
 
 
 def test_is_recompilable():
-    passes = (r'a', six.u('x'), r'asdf', re.compile('adsf'),
-              six.u(r'\u2233\s*'), re.compile(r''))
+    passes = (r'a', u('x'), r'asdf', re.compile('adsf'),
+              u(r'\u2233\s*'), re.compile(r''))
     fails = 1, [], object()
 
     for p in passes:
diff --git a/pandas/tests/test_py3compat.py b/pandas/tests/test_compat.py
similarity index 96%
rename from pandas/tests/test_py3compat.py
rename to pandas/tests/test_compat.py
index e74b8a86e..fe5c7590d 100644
--- a/pandas/tests/test_py3compat.py
+++ b/pandas/tests/test_compat.py
@@ -1,8 +1,8 @@
 """
-Testing that functions from py3compat work as expected
+Testing that functions from compat work as expected
 """
 
-from pandas.util.py3compat import (
+from pandas.util.compat import (
     range, zip, map, filter,
     lrange, lzip, lmap, lfilter,
     builtins
diff --git a/pandas/tests/test_expressions.py b/pandas/tests/test_expressions.py
index 018440dd0..8cfffaacc 100644
--- a/pandas/tests/test_expressions.py
+++ b/pandas/tests/test_expressions.py
@@ -17,7 +17,7 @@ from pandas.core import expressions as expr
 from pandas.util.testing import (assert_almost_equal,
                                  assert_series_equal,
                                  assert_frame_equal)
-from pandas.util import py3compat
+from pandas.util import compat
 
 import pandas.util.testing as tm
 import pandas.lib as lib
@@ -55,7 +55,7 @@ class TestExpressions(unittest.TestCase):
     def run_arithmetic_test(self, df, assert_func, check_dtype=False):
         expr._MIN_ELEMENTS = 0
         operations = ['add', 'sub', 'mul','mod','truediv','floordiv','pow']
-        if not py3compat.PY3:
+        if not compat.PY3:
             operations.append('div')
         for arith in operations:
             op = getattr(operator, arith)
diff --git a/pandas/tests/test_format.py b/pandas/tests/test_format.py
index fdd11b7bd..7cd484f50 100644
--- a/pandas/tests/test_format.py
+++ b/pandas/tests/test_format.py
@@ -1,7 +1,8 @@
 from __future__ import print_function
 # -*- coding: utf-8 -*-
 
-from pandas.util.py3compat import range, zip, lrange, StringIO, PY3, lzip
+from pandas.util.compat import range, zip, lrange, StringIO, PY3, lzip, u
+import pandas.util.compat as compat
 import os
 import sys
 import unittest
@@ -21,7 +22,6 @@ import pandas
 import pandas as pd
 from pandas.core.config import (set_option, get_option,
                                 option_context, reset_option)
-import six
 
 _frame = DataFrame(tm.getSeriesData())
 
@@ -151,9 +151,9 @@ class TestDataFrameFormatting(unittest.TestCase):
 
 
         data = [8, 5, 3, 5]
-        index1 = [six.u("\u03c3"), six.u("\u03c4"), six.u("\u03c5"),
-                  six.u("\u03c6")]
-        cols = [six.u("\u03c8")]
+        index1 = [u("\u03c3"), u("\u03c4"), u("\u03c5"),
+                  u("\u03c6")]
+        cols = [u("\u03c8")]
         df = DataFrame(data, columns=cols, index=index1)
         self.assertTrue(type(df.__repr__() == str))  # both py2 / 3
 
@@ -245,7 +245,7 @@ class TestDataFrameFormatting(unittest.TestCase):
     def test_to_string_repr_unicode(self):
         buf = StringIO()
 
-        unicode_values = [six.u('\u03c3')] * 10
+        unicode_values = [u('\u03c3')] * 10
         unicode_values = np.array(unicode_values, dtype=object)
         df = DataFrame({'unicode': unicode_values})
         df.to_string(col_space=10, buf=buf)
@@ -253,7 +253,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         # it works!
         repr(df)
 
-        idx = Index(['abc', six.u('\u03c3a'), 'aegdvg'])
+        idx = Index(['abc', u('\u03c3a'), 'aegdvg'])
         ser = Series(np.random.randn(len(idx)), idx)
         rs = repr(ser).split('\n')
         line_len = len(rs[0])
@@ -274,7 +274,7 @@ class TestDataFrameFormatting(unittest.TestCase):
             sys.stdin = _stdin
 
     def test_to_string_unicode_columns(self):
-        df = DataFrame({six.u('\u03c3'): np.arange(10.)})
+        df = DataFrame({u('\u03c3'): np.arange(10.)})
 
         buf = StringIO()
         df.to_string(buf=buf)
@@ -285,17 +285,17 @@ class TestDataFrameFormatting(unittest.TestCase):
         buf.getvalue()
 
         result = self.frame.to_string()
-        tm.assert_isinstance(result, six.text_type)
+        tm.assert_isinstance(result, compat.text_type)
 
     def test_to_string_utf8_columns(self):
-        n = six.u("\u05d0").encode('utf-8')
+        n = u("\u05d0").encode('utf-8')
 
         with option_context('display.max_rows', 1):
             df = pd.DataFrame([1, 2], columns=[n])
             repr(df)
 
     def test_to_string_unicode_two(self):
-        dm = DataFrame({six.u('c/\u03c3'): []})
+        dm = DataFrame({u('c/\u03c3'): []})
         buf = StringIO()
         dm.to_string(buf)
 
@@ -322,17 +322,17 @@ class TestDataFrameFormatting(unittest.TestCase):
         self.assertEqual(result, result2)
 
     def test_to_string_with_formatters_unicode(self):
-        df = DataFrame({six.u('c/\u03c3'): [1, 2, 3]})
-        result = df.to_string(formatters={six.u('c/\u03c3'):
+        df = DataFrame({u('c/\u03c3'): [1, 2, 3]})
+        result = df.to_string(formatters={u('c/\u03c3'):
                               lambda x: '%s' % x})
-        self.assertEqual(result, six.u('  c/\u03c3\n') +
+        self.assertEqual(result, u('  c/\u03c3\n') +
                                  '0   1\n1   2\n2   3')
 
     def test_to_string_buffer_all_unicode(self):
         buf = StringIO()
 
-        empty = DataFrame({six.u('c/\u03c3'): Series()})
-        nonempty = DataFrame({six.u('c/\u03c3'): Series([1, 2, 3])})
+        empty = DataFrame({u('c/\u03c3'): Series()})
+        nonempty = DataFrame({u('c/\u03c3'): Series([1, 2, 3])})
 
         print(empty, file=buf)
         print(nonempty, file=buf)
@@ -373,9 +373,9 @@ class TestDataFrameFormatting(unittest.TestCase):
 
     def test_to_html_unicode(self):
         # it works!
-        df = DataFrame({six.u('\u03c3'): np.arange(10.)})
+        df = DataFrame({u('\u03c3'): np.arange(10.)})
         df.to_html()
-        df = DataFrame({'A': [six.u('\u03c3')]})
+        df = DataFrame({'A': [u('\u03c3')]})
         df.to_html()
 
     def test_to_html_escaped(self):
@@ -699,8 +699,8 @@ class TestDataFrameFormatting(unittest.TestCase):
         self.assert_(len(lines[1]) == len(lines[2]))
 
     def test_unicode_problem_decoding_as_ascii(self):
-        dm = DataFrame({six.u('c/\u03c3'): Series({'test': np.NaN})})
-        six.text_type(dm.to_string())
+        dm = DataFrame({u('c/\u03c3'): Series({'test': np.NaN})})
+        compat.text_type(dm.to_string())
 
     def test_string_repr_encoding(self):
         filepath = tm.get_data_path('unicode_series.csv')
@@ -768,24 +768,24 @@ class TestDataFrameFormatting(unittest.TestCase):
         if PY3:
             raise nose.SkipTest()
 
-        self.assertEquals(pp_t('a') , six.u('a'))
-        self.assertEquals(pp_t(six.u('a')) , six.u('a'))
+        self.assertEquals(pp_t('a') , u('a'))
+        self.assertEquals(pp_t(u('a')) , u('a'))
         self.assertEquals(pp_t(None) , 'None')
-        self.assertEquals(pp_t(six.u('\u05d0'), quote_strings=True),
-                          six.u("u'\u05d0'"))
-        self.assertEquals(pp_t(six.u('\u05d0'), quote_strings=False),
-                          six.u('\u05d0'))
-        self.assertEquals(pp_t((six.u('\u05d0'),
-                                six.u('\u05d1')), quote_strings=True),
-                          six.u("(u'\u05d0', u'\u05d1')"))
-        self.assertEquals(pp_t((six.u('\u05d0'), (six.u('\u05d1'),
-                                                  six.u('\u05d2'))),
+        self.assertEquals(pp_t(u('\u05d0'), quote_strings=True),
+                          u("u'\u05d0'"))
+        self.assertEquals(pp_t(u('\u05d0'), quote_strings=False),
+                          u('\u05d0'))
+        self.assertEquals(pp_t((u('\u05d0'),
+                                u('\u05d1')), quote_strings=True),
+                          u("(u'\u05d0', u'\u05d1')"))
+        self.assertEquals(pp_t((u('\u05d0'), (u('\u05d1'),
+                                                  u('\u05d2'))),
                                quote_strings=True),
-                          six.u("(u'\u05d0', (u'\u05d1', u'\u05d2'))"))
-        self.assertEquals(pp_t(('foo', six.u('\u05d0'), (six.u('\u05d0'),
-                                                         six.u('\u05d0'))),
+                          u("(u'\u05d0', (u'\u05d1', u'\u05d2'))"))
+        self.assertEquals(pp_t(('foo', u('\u05d0'), (u('\u05d0'),
+                                                         u('\u05d0'))),
                                quote_strings=True),
-                          six.u("(u'foo', u'\u05d0', (u'\u05d0', u'\u05d0'))"))
+                          u("(u'foo', u'\u05d0', (u'\u05d0', u'\u05d0'))"))
 
         # escape embedded tabs in string
         # GH #2038
@@ -927,13 +927,13 @@ class TestDataFrameFormatting(unittest.TestCase):
         # multi-index
         y = df.set_index(['id1', 'id2', 'id3'])
         result = y.to_string()
-        expected = six.u('             value\nid1 id2 id3       \n1a3 NaN 78d    123\n9h4 d67 79d     64')
+        expected = u('             value\nid1 id2 id3       \n1a3 NaN 78d    123\n9h4 d67 79d     64')
         self.assert_(result == expected)
 
         # index
         y = df.set_index('id2')
         result = y.to_string()
-        expected = six.u('     id1  id3  value\nid2                 \nNaN  1a3  78d    123\nd67  9h4  79d     64')
+        expected = u('     id1  id3  value\nid2                 \nNaN  1a3  78d    123\nd67  9h4  79d     64')
         self.assert_(result == expected)
 
         # all-nan in mi
@@ -941,7 +941,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         df2.ix[:,'id2'] = np.nan
         y = df2.set_index('id2')
         result = y.to_string()
-        expected = six.u('     id1  id3  value\nid2                 \nNaN  1a3  78d    123\nNaN  9h4  79d     64')
+        expected = u('     id1  id3  value\nid2                 \nNaN  1a3  78d    123\nNaN  9h4  79d     64')
         self.assert_(result == expected)
 
         # partial nan in mi
@@ -949,7 +949,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         df2.ix[:,'id2'] = np.nan
         y = df2.set_index(['id2','id3'])
         result = y.to_string()
-        expected = six.u('         id1  value\nid2 id3            \nNaN 78d  1a3    123\n    79d  9h4     64')
+        expected = u('         id1  value\nid2 id3            \nNaN 78d  1a3    123\n    79d  9h4     64')
         self.assert_(result == expected)
 
         df = DataFrame({'id1': {0: np.nan, 1: '9h4'}, 'id2': {0: np.nan, 1: 'd67'},
@@ -957,7 +957,7 @@ class TestDataFrameFormatting(unittest.TestCase):
 
         y = df.set_index(['id1','id2','id3'])
         result = y.to_string()
-        expected = six.u('             value\nid1 id2 id3       \nNaN NaN NaN    123\n9h4 d67 79d     64')
+        expected = u('             value\nid1 id2 id3       \nNaN NaN NaN    123\n9h4 d67 79d     64')
         self.assert_(result == expected)
 
     def test_to_string(self):
@@ -978,7 +978,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         self.assert_(retval is None)
         self.assertEqual(buf.getvalue(), s)
 
-        tm.assert_isinstance(s, six.string_types)
+        tm.assert_isinstance(s, compat.string_types)
 
         # print in right order
         result = biggie.to_string(columns=['B', 'A'], col_space=17,
@@ -1118,8 +1118,8 @@ class TestDataFrameFormatting(unittest.TestCase):
 
     def test_to_string_ascii_error(self):
         data = [('0  ',
-                 six.u('                        .gitignore '),
-                 six.u('     5 '),
+                 u('                        .gitignore '),
+                 u('     5 '),
                  ' \xe2\x80\xa2\xe2\x80\xa2\xe2\x80'
                  '\xa2\xe2\x80\xa2\xe2\x80\xa2')]
         df = DataFrame(data)
@@ -1207,7 +1207,7 @@ c  10  11  12  13  14\
         self.assert_(retval is None)
         self.assertEqual(buf.getvalue(), s)
 
-        tm.assert_isinstance(s, six.string_types)
+        tm.assert_isinstance(s, compat.string_types)
 
         biggie.to_html(columns=['B', 'A'], col_space=17)
         biggie.to_html(columns=['B', 'A'],
@@ -1542,10 +1542,10 @@ class TestSeriesFormatting(unittest.TestCase):
         self.ts = tm.makeTimeSeries()
 
     def test_repr_unicode(self):
-        s = Series([six.u('\u03c3')] * 10)
+        s = Series([u('\u03c3')] * 10)
         repr(s)
 
-        a = Series([six.u("\u05d0")] * 1000)
+        a = Series([u("\u05d0")] * 1000)
         a.name = 'title1'
         repr(a)
 
@@ -1589,16 +1589,16 @@ class TestSeriesFormatting(unittest.TestCase):
     def test_to_string_mixed(self):
         s = Series(['foo', np.nan, -1.23, 4.56])
         result = s.to_string()
-        expected = (six.u('0     foo\n') +
-                    six.u('1     NaN\n') +
-                    six.u('2   -1.23\n') +
-                    six.u('3    4.56'))
+        expected = (u('0     foo\n') +
+                    u('1     NaN\n') +
+                    u('2   -1.23\n') +
+                    u('3    4.56'))
         self.assertEqual(result, expected)
 
         # but don't count NAs as floats
         s = Series(['foo', np.nan, 'bar', 'baz'])
         result = s.to_string()
-        expected = (six.u('0    foo\n') +
+        expected = (u('0    foo\n') +
                     '1    NaN\n' +
                     '2    bar\n' +
                     '3    baz')
@@ -1606,7 +1606,7 @@ class TestSeriesFormatting(unittest.TestCase):
 
         s = Series(['foo', 5, 'bar', 'baz'])
         result = s.to_string()
-        expected = (six.u('0    foo\n') +
+        expected = (u('0    foo\n') +
                     '1      5\n' +
                     '2    bar\n' +
                     '3    baz')
@@ -1617,7 +1617,7 @@ class TestSeriesFormatting(unittest.TestCase):
         s[::2] = np.nan
 
         result = s.to_string()
-        expected = (six.u('0       NaN\n') +
+        expected = (u('0       NaN\n') +
                     '1    1.5678\n' +
                     '2       NaN\n' +
                     '3   -3.0000\n' +
@@ -1625,8 +1625,8 @@ class TestSeriesFormatting(unittest.TestCase):
         self.assertEqual(result, expected)
 
     def test_unicode_name_in_footer(self):
-        s = Series([1, 2], name=six.u('\u05e2\u05d1\u05e8\u05d9\u05ea'))
-        sf = fmt.SeriesFormatter(s, name=six.u('\u05e2\u05d1\u05e8\u05d9\u05ea'))
+        s = Series([1, 2], name=u('\u05e2\u05d1\u05e8\u05d9\u05ea'))
+        sf = fmt.SeriesFormatter(s, name=u('\u05e2\u05d1\u05e8\u05d9\u05ea'))
         sf._get_footer()  # should not raise exception
 
     def test_float_trim_zeros(self):
@@ -1920,7 +1920,7 @@ class TestEngFormatter(unittest.TestCase):
 
         formatter = fmt.EngFormatter(accuracy=3, use_eng_prefix=True)
         result = formatter(0)
-        self.assertEqual(result, six.u(' 0.000'))
+        self.assertEqual(result, u(' 0.000'))
 
 
 def _three_digit_exp():
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 9104a2140..25397c09c 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -7,13 +7,11 @@ import re
 import unittest
 import nose
 
-from pandas.util import py3compat
-from pandas.util.py3compat import cPickle as pickle
-from pandas.util.py3compat import StringIO, range, long, lrange, lmap, lzip
-from pandas.util.compat import OrderedDict
+from pandas.util.compat import(
+    map, zip, range, long, lrange, lmap, lzip,
+    OrderedDict, cPickle as pickle, u, StringIO
+)
 from pandas.util import compat
-import six
-from pandas.util.py3compat import map, zip
 
 from numpy import random, nan
 from numpy.random import randn
@@ -63,7 +61,7 @@ def _check_mixed_float(df, dtype = None):
 
     # float16 are most likely to be upcasted to float32
     dtypes = dict(A = 'float32', B = 'float32', C = 'float16', D = 'float64')
-    if isinstance(dtype, six.string_types):
+    if isinstance(dtype, compat.string_types):
         dtypes = dict([ (k,dtype) for k, v in dtypes.items() ])
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
@@ -78,7 +76,7 @@ def _check_mixed_float(df, dtype = None):
 
 def _check_mixed_int(df, dtype = None):
     dtypes = dict(A = 'int32', B = 'uint64', C = 'uint8', D = 'int64')
-    if isinstance(dtype, six.string_types):
+    if isinstance(dtype, compat.string_types):
         dtypes = dict([ (k,dtype) for k, v in dtypes.items() ])
     elif isinstance(dtype, dict):
         dtypes.update(dtype)
@@ -3843,7 +3841,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         warnings.filters = warn_filters
 
     def test_repr_unicode(self):
-        uval = six.u('\u03c3\u03c3\u03c3\u03c3')
+        uval = u('\u03c3\u03c3\u03c3\u03c3')
         bval = uval.encode('utf-8')
         df = DataFrame({'A': [uval, uval]})
 
@@ -3856,16 +3854,16 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertEqual(result.split('\n')[0].rstrip(), ex_top)
 
     def test_unicode_string_with_unicode(self):
-        df = DataFrame({'A': [six.u("\u05d0")]})
+        df = DataFrame({'A': [u("\u05d0")]})
 
-        if py3compat.PY3:
+        if compat.PY3:
             str(df)
         else:
-            six.text_type(df)
+            compat.text_type(df)
 
     def test_bytestring_with_unicode(self):
-        df = DataFrame({'A': [six.u("\u05d0")]})
-        if py3compat.PY3:
+        df = DataFrame({'A': [u("\u05d0")]})
+        if compat.PY3:
             bytes(df)
         else:
             str(df)
@@ -4144,7 +4142,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         _check_unary_op(operator.neg)
 
     def test_logical_typeerror(self):
-        if py3compat.PY3:
+        if compat.PY3:
             pass
         else:
             self.assertRaises(TypeError, self.frame.__eq__, 'foo')
@@ -4823,7 +4821,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                        recons = DataFrame.from_csv(path,header=0,parse_dates=False)
 
                def _to_uni(x):
-                   if not isinstance(x, six.text_type):
+                   if not isinstance(x, compat.text_type):
                        return x.decode('utf8')
                    return x
                if dupe_col:
@@ -5282,7 +5280,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_to_csv_unicode(self):
 
-        df = DataFrame({six.u('c/\u03c3'): [1, 2, 3]})
+        df = DataFrame({u('c/\u03c3'): [1, 2, 3]})
         with ensure_clean() as path:
 
             df.to_csv(path, encoding='UTF-8')
@@ -5296,10 +5294,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_to_csv_unicode_index_col(self):
         buf = StringIO('')
         df = DataFrame(
-            [[six.u("\u05d0"), "d2", "d3", "d4"], ["a1", "a2", "a3", "a4"]],
-            columns=[six.u("\u05d0"),
-                     six.u("\u05d1"), six.u("\u05d2"), six.u("\u05d3")],
-            index=[six.u("\u05d0"), six.u("\u05d1")])
+            [[u("\u05d0"), "d2", "d3", "d4"], ["a1", "a2", "a3", "a4"]],
+            columns=[u("\u05d0"),
+                     u("\u05d1"), u("\u05d2"), u("\u05d3")],
+            index=[u("\u05d0"), u("\u05d1")])
 
         df.to_csv(buf, encoding='UTF-8')
         buf.seek(0)
@@ -8311,7 +8309,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_('foo' in filtered)
 
         # unicode columns, won't ascii-encode
-        df = self.frame.rename(columns={'B': six.u('\u2202')})
+        df = self.frame.rename(columns={'B': u('\u2202')})
         filtered = df.filter(like='C')
         self.assertTrue('C' in filtered)
 
diff --git a/pandas/tests/test_graphics.py b/pandas/tests/test_graphics.py
index c03041e39..4364e741c 100644
--- a/pandas/tests/test_graphics.py
+++ b/pandas/tests/test_graphics.py
@@ -6,7 +6,7 @@ import unittest
 from datetime import datetime, date
 
 from pandas import Series, DataFrame, MultiIndex, PeriodIndex, date_range
-from pandas.util.py3compat import range, lrange, StringIO, lmap, lzip
+from pandas.util.compat import range, lrange, StringIO, lmap, lzip, u, map, zip
 import pandas.util.testing as tm
 from pandas.util.testing import ensure_clean
 from pandas.core.config import set_option
@@ -18,9 +18,6 @@ from numpy import random
 from numpy.testing import assert_array_equal
 from numpy.testing.decorators import slow
 import pandas.tools.plotting as plotting
-import six
-from pandas.util.py3compat import map
-from pandas.util.py3compat import zip
 
 
 def _skip_if_no_scipy():
@@ -337,21 +334,21 @@ class TestDataFramePlots(unittest.TestCase):
         _check_plot_works(df.plot, use_index=True)
 
         # unicode
-        index = MultiIndex.from_tuples([(six.u('\u03b1'), 0),
-                                        (six.u('\u03b1'), 1),
-                                        (six.u('\u03b2'), 2),
-                                        (six.u('\u03b2'), 3),
-                                        (six.u('\u03b3'), 4),
-                                        (six.u('\u03b3'), 5),
-                                        (six.u('\u03b4'), 6),
-                                        (six.u('\u03b4'), 7)], names=['i0', 'i1'])
-        columns = MultiIndex.from_tuples([('bar', six.u('\u0394')),
-                                        ('bar', six.u('\u0395'))], names=['c0',
+        index = MultiIndex.from_tuples([(u('\u03b1'), 0),
+                                        (u('\u03b1'), 1),
+                                        (u('\u03b2'), 2),
+                                        (u('\u03b2'), 3),
+                                        (u('\u03b3'), 4),
+                                        (u('\u03b3'), 5),
+                                        (u('\u03b4'), 6),
+                                        (u('\u03b4'), 7)], names=['i0', 'i1'])
+        columns = MultiIndex.from_tuples([('bar', u('\u0394')),
+                                        ('bar', u('\u0395'))], names=['c0',
                                                                     'c1'])
         df = DataFrame(np.random.randint(0, 10, (8, 2)),
                        columns=columns,
                        index=index)
-        _check_plot_works(df.plot, title=six.u('\u03A3'))
+        _check_plot_works(df.plot, title=u('\u03A3'))
 
     def test_nonnumeric_exclude(self):
         import matplotlib.pyplot as plt
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 005babf6f..58b7d808e 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1,7 +1,4 @@
 from __future__ import print_function
-from pandas.util.py3compat import range, long, lrange, StringIO, lmap, lzip
-from pandas.util import compat
-from pandas.util.py3compat import map, zip, builtins
 import nose
 import unittest
 
@@ -16,6 +13,10 @@ from pandas.core.groupby import GroupByError, SpecificationError, DataError
 from pandas.core.series import Series
 from pandas.util.testing import (assert_panel_equal, assert_frame_equal,
                                  assert_series_equal, assert_almost_equal)
+from pandas.util.compat import(
+    range, long, lrange, StringIO, lmap, lzip, map, zip, builtins, OrderedDict
+)
+from pandas.util import compat
 from pandas.core.panel import Panel
 from pandas.tools.merge import concat
 from collections import defaultdict
@@ -443,7 +444,6 @@ class TestGroupBy(unittest.TestCase):
             self.assert_((self.df.ix[v]['B'] == k[1]).all())
 
     def test_aggregate_str_func(self):
-        from pandas.util.compat import OrderedDict
 
         def _check_results(grouped):
             # single series
@@ -1068,7 +1068,6 @@ class TestGroupBy(unittest.TestCase):
         assert_series_equal(result, expected)
 
     def test_groupby_as_index_agg(self):
-        from pandas.util.compat import OrderedDict
         grouped = self.df.groupby('A', as_index=False)
 
         # single-key
@@ -2238,7 +2237,6 @@ class TestGroupBy(unittest.TestCase):
 
     def test_more_flexible_frame_multi_function(self):
         from pandas import concat
-        from pandas.util.compat import OrderedDict
 
         grouped = self.df.groupby('A')
 
@@ -2277,7 +2275,6 @@ class TestGroupBy(unittest.TestCase):
 
     def test_multi_function_flexible_mix(self):
         # GH #1268
-        from pandas.util.compat import OrderedDict
         grouped = self.df.groupby('A')
 
         d = OrderedDict([['C', OrderedDict([['foo', 'mean'],
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 4dae4378c..46fd7f218 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -1,7 +1,7 @@
 # pylint: disable=E1101,E1103,W0232
 
 from datetime import datetime, timedelta
-from pandas.util.py3compat import range, lrange, lzip
+from pandas.util.compat import range, lrange, lzip, u, zip
 import operator
 import pickle
 import unittest
@@ -13,7 +13,7 @@ from numpy.testing import assert_array_equal
 
 from pandas.core.index import Index, Int64Index, MultiIndex
 from pandas.util.testing import assert_almost_equal
-from pandas.util import py3compat
+from pandas.util import compat
 
 import pandas.util.testing as tm
 import pandas.core.config as cf
@@ -23,8 +23,6 @@ import pandas.tseries.offsets as offsets
 
 import pandas as pd
 from pandas.lib import Timestamp
-import six
-from pandas.util.py3compat import zip
 
 
 class TestIndex(unittest.TestCase):
@@ -371,13 +369,13 @@ class TestIndex(unittest.TestCase):
         # 2845
         index = Index([1, 2.0+3.0j, np.nan])
         formatted = index.format()
-        expected = [str(index[0]), str(index[1]), six.u('NaN')]
+        expected = [str(index[0]), str(index[1]), u('NaN')]
         self.assertEquals(formatted, expected)
 
         # is this really allowed?
         index = Index([1, 2.0+3.0j, None])
         formatted = index.format()
-        expected = [str(index[0]), str(index[1]), six.u('NaN')]
+        expected = [str(index[0]), str(index[1]), u('NaN')]
         self.assertEquals(formatted, expected)
 
         self.strIndex[:0].format()
@@ -900,7 +898,7 @@ class TestInt64Index(unittest.TestCase):
 
     def test_print_unicode_columns(self):
         df = pd.DataFrame(
-            {six.u("\u05d0"): [1, 2, 3], "\u05d1": [4, 5, 6], "c": [7, 8, 9]})
+            {u("\u05d0"): [1, 2, 3], "\u05d1": [4, 5, 6], "c": [7, 8, 9]})
         repr(df.columns)  # should not raise UnicodeDecodeError
 
     def test_repr_summary(self):
@@ -912,14 +910,14 @@ class TestInt64Index(unittest.TestCase):
     def test_unicode_string_with_unicode(self):
         idx = Index(lrange(1000))
 
-        if py3compat.PY3:
+        if compat.PY3:
             str(idx)
         else:
-            six.text_type(idx)
+            compat.text_type(idx)
 
     def test_bytestring_with_unicode(self):
         idx = Index(lrange(1000))
-        if py3compat.PY3:
+        if compat.PY3:
             bytes(idx)
         else:
             str(idx)
@@ -1065,7 +1063,7 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(self.index.equals(unpickled))
 
     def test_legacy_pickle(self):
-        if py3compat.PY3:
+        if compat.PY3:
             raise nose.SkipTest
 
         def curpath():
@@ -1775,24 +1773,24 @@ class TestMultiIndex(unittest.TestCase):
         self.assertEqual(result, exp)
 
     def test_repr_with_unicode_data(self):
-        d = {"a": [six.u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
+        d = {"a": [u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
         index = pd.DataFrame(d).set_index(["a", "b"]).index
         self.assertFalse("\\u" in repr(index))  # we don't want unicode-escaped
 
     def test_unicode_string_with_unicode(self):
-        d = {"a": [six.u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
+        d = {"a": [u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
         idx = pd.DataFrame(d).set_index(["a", "b"]).index
 
-        if py3compat.PY3:
+        if compat.PY3:
             str(idx)
         else:
-            six.text_type(idx)
+            compat.text_type(idx)
 
     def test_bytestring_with_unicode(self):
-        d = {"a": [six.u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
+        d = {"a": [u("\u05d0"), 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
         idx = pd.DataFrame(d).set_index(["a", "b"]).index
 
-        if py3compat.PY3:
+        if compat.PY3:
             bytes(idx)
         else:
             str(idx)
diff --git a/pandas/tests/test_indexing.py b/pandas/tests/test_indexing.py
index a053b43f1..f2b22a4d9 100644
--- a/pandas/tests/test_indexing.py
+++ b/pandas/tests/test_indexing.py
@@ -3,7 +3,7 @@ import unittest
 import nose
 import itertools
 
-from pandas.util.py3compat import range, lrange, StringIO, lmap
+from pandas.util.compat import range, lrange, StringIO, lmap, map
 from numpy import random, nan
 from numpy.random import randn
 import numpy as np
@@ -15,13 +15,12 @@ from pandas.core.api import (DataFrame, Index, Series, Panel, notnull, isnull,
                              MultiIndex, DatetimeIndex, Timestamp)
 from pandas.util.testing import (assert_almost_equal, assert_series_equal,
                                  assert_frame_equal, assert_panel_equal)
-from pandas.util import py3compat
+from pandas.util import compat
 
 import pandas.util.testing as tm
 import pandas.lib as lib
 from pandas import date_range
 from numpy.testing.decorators import slow
-from pandas.util.py3compat import map
 
 _verbose = False
 
diff --git a/pandas/tests/test_internals.py b/pandas/tests/test_internals.py
index 9d2439b7c..2490fa211 100644
--- a/pandas/tests/test_internals.py
+++ b/pandas/tests/test_internals.py
@@ -11,8 +11,7 @@ import pandas.util.testing as tm
 
 from pandas.util.testing import (
     assert_almost_equal, assert_frame_equal, randn)
-import six
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip, u
 
 
 def assert_block_equal(left, right):
@@ -201,7 +200,7 @@ class TestBlock(unittest.TestCase):
         mat = np.empty((N, 2), dtype=object)
         mat[:, 0] = 'foo'
         mat[:, 1] = 'bar'
-        cols = ['b', six.u("\u05d0")]
+        cols = ['b', u("\u05d0")]
         str_repr = repr(make_block(mat.T, cols, TEST_COLS))
 
     def test_get(self):
@@ -537,7 +536,7 @@ class TestBlockManager(unittest.TestCase):
     def test_missing_unicode_key(self):
         df = DataFrame({"a": [1]})
         try:
-            df.ix[:, six.u("\u05d0")]  # should not raise UnicodeEncodeError
+            df.ix[:, u("\u05d0")]  # should not raise UnicodeEncodeError
         except KeyError:
             pass  # this is the expected exception
 
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index ea2ab8a1d..a98b613ae 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -13,13 +13,11 @@ from pandas.util.testing import (assert_almost_equal,
                                  assert_frame_equal)
 import pandas.core.common as com
 import pandas.util.testing as tm
-from pandas.util.py3compat import range, lrange, StringIO, lzip
-from pandas.util.compat import product as cart_product
+from pandas.util.compat import (range, lrange, StringIO, lzip, u, cPickle,
+                                product as cart_product, zip)
 import pandas as pd
 
 import pandas.index as _index
-import six
-from pandas.util.py3compat import zip, cPickle
 
 
 class TestMultiLevel(unittest.TestCase):
@@ -430,7 +428,6 @@ class TestMultiLevel(unittest.TestCase):
 
     def test_xs_level_multiple(self):
         from pandas import read_table
-        from pandas.util.py3compat import StringIO, lrange, lzip
         text = """                      A       B       C       D        E
 one two three   four
 a   b   10.0032 5    -0.5109 -2.3358 -0.4645  0.05076  0.3640
@@ -455,7 +452,6 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
 
     def test_xs_level0(self):
         from pandas import read_table
-        from pandas.util.py3compat import StringIO, lrange, lzip
         text = """                      A       B       C       D        E
 one two three   four
 a   b   10.0032 5    -0.5109 -2.3358 -0.4645  0.05076  0.3640
@@ -1674,7 +1670,7 @@ Thur,Lunch,Yes,51.51,17"""
         self.assert_(result.index.names == ['one', 'two'])
 
     def test_unicode_repr_issues(self):
-        levels = [Index([six.u('a/\u03c3'), six.u('b/\u03c3'), six.u('c/\u03c3')]),
+        levels = [Index([u('a/\u03c3'), u('b/\u03c3'), u('c/\u03c3')]),
                   Index([0, 1])]
         labels = [np.arange(3).repeat(2), np.tile(np.arange(2), 3)]
         index = MultiIndex(levels=levels, labels=labels)
@@ -1686,7 +1682,7 @@ Thur,Lunch,Yes,51.51,17"""
 
     def test_unicode_repr_level_names(self):
         index = MultiIndex.from_tuples([(0, 0), (1, 1)],
-                                       names=[six.u('\u0394'), 'i1'])
+                                       names=[u('\u0394'), 'i1'])
 
         s = Series(lrange(2), index=index)
         df = DataFrame(np.random.randn(2, 4), index=index)
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 5fdb48780..38117a591 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -1,7 +1,7 @@
 # pylint: disable=W0612,E1101
 
 from datetime import datetime
-from pandas.util.py3compat import range, lrange, StringIO
+from pandas.util.compat import range, lrange, StringIO, cPickle, OrderedDict
 from pandas.util import compat
 import operator
 import unittest
@@ -15,8 +15,7 @@ from pandas.core.frame import group_agg
 from pandas.core.panel import Panel
 from pandas.core.series import remove_na
 import pandas.core.common as com
-from pandas.util import py3compat
-from pandas.util.py3compat import cPickle
+from pandas.util import compat
 
 from pandas.util.testing import (assert_panel_equal,
                                  assert_frame_equal,
@@ -311,7 +310,7 @@ class SafeForSparse(object):
         check_op(operator.add, 'add')
         check_op(operator.sub, 'subtract')
         check_op(operator.mul, 'multiply')
-        if py3compat.PY3:
+        if compat.PY3:
             check_op(operator.truediv, 'divide')
         else:
             check_op(operator.div, 'divide')
@@ -916,7 +915,6 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
         self.assertRaises(Exception, Panel, data)
 
     def test_ctor_orderedDict(self):
-        from pandas.util.compat import OrderedDict
         keys = list(set(np.random.randint(0,5000,100)))[:50] # unique random int  keys
         d = OrderedDict([(k,mkdf(10,5)) for k in keys])
         p = Panel(d)
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index 8f5d7641c..f1b9bc645 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -1,5 +1,5 @@
 from datetime import datetime
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import os
 import operator
 import unittest
@@ -15,7 +15,7 @@ from pandas.core.panel4d import Panel4D
 from pandas.core.series import remove_na
 import pandas.core.common as com
 import pandas.core.panel as panelmod
-from pandas.util import py3compat
+from pandas.util import compat
 
 from pandas.util.testing import (assert_panel_equal,
                                  assert_panel4d_equal,
diff --git a/pandas/tests/test_panelnd.py b/pandas/tests/test_panelnd.py
index 5675cfec5..452fd2470 100644
--- a/pandas/tests/test_panelnd.py
+++ b/pandas/tests/test_panelnd.py
@@ -9,7 +9,7 @@ import numpy as np
 from pandas.core import panelnd
 from pandas.core.panel import Panel
 import pandas.core.common as com
-from pandas.util import py3compat
+from pandas.util import compat
 
 from pandas.util.testing import (assert_panel_equal,
                                  assert_panel4d_equal,
diff --git a/pandas/tests/test_reshape.py b/pandas/tests/test_reshape.py
index d0d5f260e..e285d9764 100644
--- a/pandas/tests/test_reshape.py
+++ b/pandas/tests/test_reshape.py
@@ -15,9 +15,7 @@ import numpy as np
 
 from pandas.core.reshape import melt, convert_dummies, lreshape
 import pandas.util.testing as tm
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range
-from pandas.util.py3compat import cPickle
+from pandas.util.compat import StringIO, cPickle, range
 
 _multiprocess_can_split_ = True
 
diff --git a/pandas/tests/test_rplot.py b/pandas/tests/test_rplot.py
index 95ef66eb8..176ffa231 100644
--- a/pandas/tests/test_rplot.py
+++ b/pandas/tests/test_rplot.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import unittest
 import pandas.tools.rplot as rplot
 import pandas.util.testing as tm
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 5e23efca2..3ab924312 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -23,14 +23,12 @@ import pandas.lib as lib
 import pandas.core.datetools as datetools
 import pandas.core.nanops as nanops
 
-from pandas.util.py3compat import StringIO, lrange, range, zip
+from pandas.util.compat import StringIO, lrange, range, zip, u, OrderedDict
 from pandas.util import compat
-from pandas.util import py3compat
 from pandas.util.testing import (assert_series_equal,
                                  assert_almost_equal,
                                  ensure_clean)
 import pandas.util.testing as tm
-import six
 
 
 def _skip_if_no_scipy():
@@ -519,7 +517,6 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_orderedDict_ctor(self):
         # GH3283
-        from pandas.util.compat import OrderedDict
         import pandas, random
         data = OrderedDict([('col%s' % i, random.random()) for i in range(12)])
         s = pandas.Series(data)
@@ -527,7 +524,6 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_orderedDict_subclass_ctor(self):
         # GH3283
-        from pandas.util.compat import OrderedDict
         import pandas, random
         class A(OrderedDict):
             pass
@@ -1288,13 +1284,13 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         repr(ots)
 
         # various names
-        for name in ['', 1, 1.2, 'foo', six.u('\u03B1\u03B2\u03B3'),
+        for name in ['', 1, 1.2, 'foo', u('\u03B1\u03B2\u03B3'),
                      'loooooooooooooooooooooooooooooooooooooooooooooooooooong',
                      ('foo', 'bar', 'baz'),
                      (1, 2),
                      ('foo', 1, 2.3),
-                     (six.u('\u03B1'), six.u('\u03B2'), six.u('\u03B3')),
-                     (six.u('\u03B1'), 'bar')]:
+                     (u('\u03B1'), u('\u03B2'), u('\u03B3')),
+                     (u('\u03B1'), 'bar')]:
             self.series.name = name
             repr(self.series)
 
@@ -1318,7 +1314,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertFalse("a\n" in repr(ser))
 
     def test_tidy_repr(self):
-        a = Series([six.u("\u05d0")] * 1000)
+        a = Series([u("\u05d0")] * 1000)
         a.name = 'title1'
         repr(a)         # should not raise exception
 
@@ -1343,7 +1339,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         # it works!
         repr(s)
 
-        s.name = (six.u("\u05d0"),) * 2
+        s.name = (u("\u05d0"),) * 2
         repr(s)
 
     def test_repr_should_return_str(self):
@@ -1356,20 +1352,20 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         """
         data = [8, 5, 3, 5]
-        index1 = [six.u("\u03c3"), six.u("\u03c4"), six.u("\u03c5"), six.u("\u03c6")]
+        index1 = [u("\u03c3"), u("\u03c4"), u("\u03c5"), u("\u03c6")]
         df = Series(data, index=index1)
         self.assertTrue(type(df.__repr__() == str))  # both py2 / 3
 
     def test_unicode_string_with_unicode(self):
-        df = Series([six.u("\u05d0")], name=six.u("\u05d1"))
-        if py3compat.PY3:
+        df = Series([u("\u05d0")], name=u("\u05d1"))
+        if compat.PY3:
             str(df)
         else:
-            six.text_type(df)
+            compat.text_type(df)
 
     def test_bytestring_with_unicode(self):
-        df = Series([six.u("\u05d0")], name=six.u("\u05d1"))
-        if py3compat.PY3:
+        df = Series([u("\u05d0")], name=u("\u05d1"))
+        if compat.PY3:
             bytes(df)
         else:
             str(df)
@@ -1790,7 +1786,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         p = DataFrame({ 'first' : [3,4,5,8], 'second' : [1,1,1,1] })
         result = p['first'] / p['second']
-        if py3compat.PY3:
+        if compat.PY3:
             assert_series_equal(result,p['first'].astype('float64'))
         else:
             assert_series_equal(result,p['first'])
@@ -2406,7 +2402,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         ops = [Series.add, Series.sub, Series.mul, Series.div]
         equivs = [operator.add, operator.sub, operator.mul]
-        if py3compat.PY3:
+        if compat.PY3:
             equivs.append(operator.truediv)
         else:
             equivs.append(operator.div)
@@ -2622,7 +2618,6 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(hist, expected)
 
         # GH 3002, datetime64[ns]
-        from pandas.util.py3compat import StringIO, lrange
         import pandas as pd
         f = StringIO("xxyyzz20100101PIE\nxxyyzz20100101GUM\nxxyyww20090101EGG\nfoofoo20080909PIE")
         df = pd.read_fwf(f, widths=[6,8,3], names=["person_id", "dt", "food"], parse_dates=["dt"])
@@ -2821,7 +2816,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_to_csv_unicode_index(self):
         buf = StringIO()
-        s = Series([six.u("\u05d0"), "d2"], index=[six.u("\u05d0"), six.u("\u05d1")])
+        s = Series([u("\u05d0"), "d2"], index=[u("\u05d0"), u("\u05d1")])
 
         s.to_csv(buf, encoding='UTF-8')
         buf.seek(0)
diff --git a/pandas/tests/test_stats.py b/pandas/tests/test_stats.py
index 8dc582342..c8fb09cb3 100644
--- a/pandas/tests/test_stats.py
+++ b/pandas/tests/test_stats.py
@@ -11,7 +11,6 @@ from pandas.util.compat import product
 from pandas.util.testing import (assert_frame_equal,
                                  assert_series_equal,
                                  assert_almost_equal)
-import six
 
 
 class TestRank(unittest.TestCase):
diff --git a/pandas/tests/test_strings.py b/pandas/tests/test_strings.py
index 7c05c9fa2..d3bdb4372 100644
--- a/pandas/tests/test_strings.py
+++ b/pandas/tests/test_strings.py
@@ -1,7 +1,6 @@
 # pylint: disable-msg=E1101,W0612
 
 from datetime import datetime, timedelta, date
-from pandas.util.py3compat import range, lrange
 import os
 import operator
 import re
@@ -14,6 +13,8 @@ import numpy as np
 from numpy.testing import assert_array_equal
 from numpy.random import randint
 
+from pandas.util.compat import range, lrange, u
+import pandas.util.compat as compat
 from pandas import (Index, Series, TimeSeries, DataFrame, isnull, notnull,
                     bdate_range, date_range)
 import pandas.core.common as com
@@ -22,7 +23,6 @@ from pandas.util.testing import assert_series_equal, assert_almost_equal
 import pandas.util.testing as tm
 
 import pandas.core.strings as strings
-import six
 
 
 class TestStringMethods(unittest.TestCase):
@@ -44,7 +44,7 @@ class TestStringMethods(unittest.TestCase):
 
             for el in s:
                 # each element of the series is either a basestring/str or nan
-                self.assert_(isinstance(el, six.string_types) or isnull(el))
+                self.assert_(isinstance(el, compat.string_types) or isnull(el))
 
         # desired behavior is to iterate until everything would be nan on the
         # next iter so make sure the last element of the iterator was 'l' in
@@ -156,7 +156,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = [six.u('foo'), six.u('foofoo'), NA, six.u('foooofooofommmfoo')]
+        values = [u('foo'), u('foofoo'), NA, u('foooofooofommmfoo')]
 
         result = strings.str_count(values, 'f[o]+')
         exp = [1, 2, NA, 4]
@@ -191,7 +191,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = [six.u('foo'), NA, six.u('fooommm__foo'), six.u('mmm_')]
+        values = [u('foo'), NA, u('fooommm__foo'), u('mmm_')]
         pat = 'mmm[_]+'
 
         result = strings.str_contains(values, pat)
@@ -231,8 +231,8 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('om'), NA, six.u('foo_nom'), six.u('nom'), six.u('bar_foo'), NA,
-                         six.u('foo')])
+        values = Series([u('om'), NA, u('foo_nom'), u('nom'), u('bar_foo'), NA,
+                         u('foo')])
 
         result = values.str.startswith('foo')
         exp = Series([False, NA, True, False, False, NA, True])
@@ -259,8 +259,8 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('om'), NA, six.u('foo_nom'), six.u('nom'), six.u('bar_foo'), NA,
-                         six.u('foo')])
+        values = Series([u('om'), NA, u('foo_nom'), u('nom'), u('bar_foo'), NA,
+                         u('foo')])
 
         result = values.str.endswith('foo')
         exp = Series([False, NA, False, False, True, NA, True])
@@ -284,10 +284,10 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(mixed, exp)
 
         # unicode
-        values = Series([six.u("FOO"), NA, six.u("bar"), six.u("Blurg")])
+        values = Series([u("FOO"), NA, u("bar"), u("Blurg")])
 
         results = values.str.title()
-        exp = Series([six.u("Foo"), NA, six.u("Bar"), six.u("Blurg")])
+        exp = Series([u("Foo"), NA, u("Bar"), u("Blurg")])
 
         tm.assert_series_equal(results, exp)
 
@@ -311,10 +311,10 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('om'), NA, six.u('nom'), six.u('nom')])
+        values = Series([u('om'), NA, u('nom'), u('nom')])
 
         result = values.str.upper()
-        exp = Series([six.u('OM'), NA, six.u('NOM'), six.u('NOM')])
+        exp = Series([u('OM'), NA, u('NOM'), u('NOM')])
         tm.assert_series_equal(result, exp)
 
         result = result.str.lower()
@@ -341,14 +341,14 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('fooBAD__barBAD'), NA])
+        values = Series([u('fooBAD__barBAD'), NA])
 
         result = values.str.replace('BAD[_]*', '')
-        exp = Series([six.u('foobar'), NA])
+        exp = Series([u('foobar'), NA])
         tm.assert_series_equal(result, exp)
 
         result = values.str.replace('BAD[_]*', '', n=1)
-        exp = Series([six.u('foobarBAD'), NA])
+        exp = Series([u('foobarBAD'), NA])
         tm.assert_series_equal(result, exp)
 
         #flags + unicode
@@ -379,17 +379,17 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a'), six.u('b'), NA, six.u('c'), NA,
-                         six.u('d')])
+        values = Series([u('a'), u('b'), NA, u('c'), NA,
+                         u('d')])
 
         result = values.str.repeat(3)
-        exp = Series([six.u('aaa'), six.u('bbb'), NA, six.u('ccc'), NA,
-                      six.u('ddd')])
+        exp = Series([u('aaa'), u('bbb'), NA, u('ccc'), NA,
+                      u('ddd')])
         tm.assert_series_equal(result, exp)
 
         result = values.str.repeat([1, 2, 3, 4, 5, 6])
-        exp = Series([six.u('a'), six.u('bb'), NA, six.u('cccc'), NA,
-                      six.u('dddddd')])
+        exp = Series([u('a'), u('bb'), NA, u('cccc'), NA,
+                      u('dddddd')])
         tm.assert_series_equal(result, exp)
 
     def test_match(self):
@@ -409,10 +409,10 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('fooBAD__barBAD'), NA, six.u('foo')])
+        values = Series([u('fooBAD__barBAD'), NA, u('foo')])
 
         result = values.str.match('.*(BAD[_]+).*(BAD)')
-        exp = Series([(six.u('BAD__'), six.u('BAD')), NA, []])
+        exp = Series([(u('BAD__'), u('BAD')), NA, []])
         tm.assert_series_equal(result, exp)
 
     def test_join(self):
@@ -431,8 +431,8 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a_b_c'), six.u('c_d_e'), np.nan,
-                         six.u('f_g_h')])
+        values = Series([u('a_b_c'), u('c_d_e'), np.nan,
+                         u('f_g_h')])
         result = values.str.split('_').str.join('_')
         tm.assert_series_equal(values, result)
 
@@ -454,8 +454,8 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('foo'), six.u('fooo'), six.u('fooooo'), np.nan,
-                         six.u('fooooooo')])
+        values = Series([u('foo'), u('fooo'), u('fooooo'), np.nan,
+                         u('fooooooo')])
 
         result = values.str.len()
         exp = values.map(lambda x: len(x) if com.notnull(x) else NA)
@@ -479,11 +479,11 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('fooBAD__barBAD'), NA, six.u('foo'),
-                         six.u('BAD')])
+        values = Series([u('fooBAD__barBAD'), NA, u('foo'),
+                         u('BAD')])
 
         result = values.str.findall('BAD[_]*')
-        exp = Series([[six.u('BAD__'), six.u('BAD')], NA, [], [six.u('BAD')]])
+        exp = Series([[u('BAD__'), u('BAD')], NA, [], [u('BAD')]])
         tm.assert_almost_equal(result, exp)
 
     def test_pad(self):
@@ -530,22 +530,22 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a'), six.u('b'), NA, six.u('c'), NA,
-                         six.u('eeeeee')])
+        values = Series([u('a'), u('b'), NA, u('c'), NA,
+                         u('eeeeee')])
 
         result = values.str.pad(5, side='left')
-        exp = Series([six.u('    a'), six.u('    b'), NA, six.u('    c'), NA,
-                      six.u('eeeeee')])
+        exp = Series([u('    a'), u('    b'), NA, u('    c'), NA,
+                      u('eeeeee')])
         tm.assert_almost_equal(result, exp)
 
         result = values.str.pad(5, side='right')
-        exp = Series([six.u('a    '), six.u('b    '), NA, six.u('c    '), NA,
-                      six.u('eeeeee')])
+        exp = Series([u('a    '), u('b    '), NA, u('c    '), NA,
+                      u('eeeeee')])
         tm.assert_almost_equal(result, exp)
 
         result = values.str.pad(5, side='both')
-        exp = Series([six.u('  a  '), six.u('  b  '), NA, six.u('  c  '), NA,
-                      six.u('eeeeee')])
+        exp = Series([u('  a  '), u('  b  '), NA, u('  c  '), NA,
+                      u('eeeeee')])
         tm.assert_almost_equal(result, exp)
 
     def test_center(self):
@@ -567,12 +567,12 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a'), six.u('b'), NA, six.u('c'), NA,
-                         six.u('eeeeee')])
+        values = Series([u('a'), u('b'), NA, u('c'), NA,
+                         u('eeeeee')])
 
         result = values.str.center(5)
-        exp = Series([six.u('  a  '), six.u('  b  '), NA, six.u('  c  '), NA,
-                      six.u('eeeeee')])
+        exp = Series([u('  a  '), u('  b  '), NA, u('  c  '), NA,
+                      u('eeeeee')])
         tm.assert_almost_equal(result, exp)
 
     def test_split(self):
@@ -599,12 +599,12 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a_b_c'), six.u('c_d_e'), NA, six.u('f_g_h')])
+        values = Series([u('a_b_c'), u('c_d_e'), NA, u('f_g_h')])
 
         result = values.str.split('_')
-        exp = Series([[six.u('a'), six.u('b'), six.u('c')],
-                      [six.u('c'), six.u('d'), six.u('e')], NA,
-                      [six.u('f'), six.u('g'), six.u('h')]])
+        exp = Series([[u('a'), u('b'), u('c')],
+                      [u('c'), u('d'), u('e')], NA,
+                      [u('f'), u('g'), u('h')]])
         tm.assert_series_equal(result, exp)
 
     def test_split_noargs(self):
@@ -665,11 +665,11 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('aafootwo'), six.u('aabartwo'), NA,
-                         six.u('aabazqux')])
+        values = Series([u('aafootwo'), u('aabartwo'), NA,
+                         u('aabazqux')])
 
         result = values.str.slice(2, 5)
-        exp = Series([six.u('foo'), six.u('bar'), NA, six.u('baz')])
+        exp = Series([u('foo'), u('bar'), NA, u('baz')])
         tm.assert_series_equal(result, exp)
 
     def test_slice_replace(self):
@@ -718,19 +718,19 @@ class TestStringMethods(unittest.TestCase):
 
     def test_strip_lstrip_rstrip_unicode(self):
         # unicode
-        values = Series([six.u('  aa   '), six.u(' bb \n'), NA,
-                         six.u('cc  ')])
+        values = Series([u('  aa   '), u(' bb \n'), NA,
+                         u('cc  ')])
 
         result = values.str.strip()
-        exp = Series([six.u('aa'), six.u('bb'), NA, six.u('cc')])
+        exp = Series([u('aa'), u('bb'), NA, u('cc')])
         tm.assert_series_equal(result, exp)
 
         result = values.str.lstrip()
-        exp = Series([six.u('aa   '), six.u('bb \n'), NA, six.u('cc  ')])
+        exp = Series([u('aa   '), u('bb \n'), NA, u('cc  ')])
         tm.assert_series_equal(result, exp)
 
         result = values.str.rstrip()
-        exp = Series([six.u('  aa'), six.u(' bb'), NA, six.u('cc')])
+        exp = Series([u('  aa'), u(' bb'), NA, u('cc')])
         tm.assert_series_equal(result, exp)
 
     def test_strip_lstrip_rstrip_args(self):
@@ -749,18 +749,18 @@ class TestStringMethods(unittest.TestCase):
         assert_series_equal(rs, xp)
 
     def test_strip_lstrip_rstrip_args_unicode(self):
-        values = Series([six.u('xxABCxx'), six.u('xx BNSD'),
-                         six.u('LDFJH xx')])
+        values = Series([u('xxABCxx'), u('xx BNSD'),
+                         u('LDFJH xx')])
 
-        rs = values.str.strip(six.u('x'))
+        rs = values.str.strip(u('x'))
         xp = Series(['ABC', ' BNSD', 'LDFJH '])
         assert_series_equal(rs, xp)
 
-        rs = values.str.lstrip(six.u('x'))
+        rs = values.str.lstrip(u('x'))
         xp = Series(['ABCxx', ' BNSD', 'LDFJH xx'])
         assert_series_equal(rs, xp)
 
-        rs = values.str.rstrip(six.u('x'))
+        rs = values.str.rstrip(u('x'))
         xp = Series(['xxABC', 'xx BNSD', 'LDFJH '])
         assert_series_equal(rs, xp)
 
@@ -786,11 +786,11 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         # unicode
-        values = Series([six.u('a_b_c'), six.u('c_d_e'), np.nan,
-                         six.u('f_g_h')])
+        values = Series([u('a_b_c'), u('c_d_e'), np.nan,
+                         u('f_g_h')])
 
         result = values.str.split('_').str.get(1)
-        expected = Series([six.u('b'), six.u('d'), np.nan, six.u('g')])
+        expected = Series([u('b'), u('d'), np.nan, u('g')])
         tm.assert_series_equal(result, expected)
 
     def test_more_contains(self):
@@ -891,7 +891,7 @@ class TestStringMethods(unittest.TestCase):
         self.assertEquals(result[0], True)
 
     def test_encode_decode(self):
-        base = Series([six.u('a'), six.u('b'), six.u('a\xe4')])
+        base = Series([u('a'), u('b'), u('a\xe4')])
         series = base.str.encode('utf-8')
 
         f = lambda x: x.decode('utf-8')
@@ -901,7 +901,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_series_equal(result, exp)
 
     def test_encode_decode_errors(self):
-        encodeBase = Series([six.u('a'), six.u('b'), six.u('a\x9d')])
+        encodeBase = Series([u('a'), u('b'), u('a\x9d')])
 
         self.assertRaises(UnicodeEncodeError,
                           encodeBase.str.encode, 'cp1252')
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 5ce0041bf..651c888a0 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -1,5 +1,3 @@
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip
 import unittest
 
 from numpy import nan
@@ -7,6 +5,7 @@ import numpy as np
 from pandas import Index, isnull, Timestamp
 from pandas.util.testing import assert_almost_equal
 import pandas.util.testing as common
+from pandas.util.compat import range, lrange, zip
 import pandas.lib as lib
 import pandas.algos as algos
 from datetime import datetime
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 2987a73b3..04c7dfa6e 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -1,12 +1,11 @@
 """
 SQL-style merge routines
 """
+import types
 
-from pandas.util.py3compat import range, long, lrange, lzip
-from pandas.util.py3compat import zip
-import six
 import numpy as np
-import types
+from pandas.util.compat import range, long, lrange, lzip, zip
+import pandas.util.compat as compat
 from pandas.core.categorical import Categorical
 from pandas.core.frame import DataFrame, _merge_doc
 from pandas.core.generic import NDFrame
@@ -1299,7 +1298,7 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
 
 
 def _should_fill(lname, rname):
-    if not isinstance(lname, six.string_types) or not isinstance(rname, six.string_types):
+    if not isinstance(lname, compat.string_types) or not isinstance(rname, compat.string_types):
         return True
     return lname == rname
 
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index e4aa0a7d6..ed463fbe6 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -5,11 +5,9 @@ from pandas.core.index import MultiIndex
 from pandas.core.reshape import _unstack_multiple
 from pandas.tools.merge import concat
 from pandas.tools.util import cartesian_product
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange, zip
 from pandas.util import compat
-import six
 import pandas.core.common as com
-from pandas.util.py3compat import zip
 import numpy as np
 
 
@@ -155,7 +153,7 @@ def _add_margins(table, data, values, rows=None, cols=None, aggfunc=np.mean):
     grand_margin = {}
     for k, v in compat.iteritems(data[values]):
         try:
-            if isinstance(aggfunc, six.string_types):
+            if isinstance(aggfunc, compat.string_types):
                 grand_margin[k] = getattr(v, aggfunc)()
             else:
                 grand_margin[k] = aggfunc(v)
diff --git a/pandas/tools/plotting.py b/pandas/tools/plotting.py
index b83b2d176..aef035ec4 100644
--- a/pandas/tools/plotting.py
+++ b/pandas/tools/plotting.py
@@ -1,6 +1,5 @@
 # being a bit too dynamic
 # pylint: disable=E1101
-import six
 import datetime
 import warnings
 import re
@@ -16,8 +15,8 @@ from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
 from pandas.tseries.frequencies import get_period_alias, get_base_alias
 from pandas.tseries.offsets import DateOffset
-from pandas.util.py3compat import range, lrange, lmap
-from pandas.util.py3compat import map, zip
+from pandas.util.compat import range, lrange, lmap, map, zip
+import pandas.util.compat as compat
 
 try:  # mpl optional
     import pandas.tseries.converter as conv
@@ -99,7 +98,7 @@ def _get_standard_colors(num_colors=None, colormap=None, color_type='default',
     import matplotlib.pyplot as plt
 
     if color is None and colormap is not None:
-        if isinstance(colormap, six.string_types):
+        if isinstance(colormap, compat.string_types):
             import matplotlib.cm as cm
             cmap = colormap
             colormap = cm.get_cmap(colormap)
@@ -114,7 +113,7 @@ def _get_standard_colors(num_colors=None, colormap=None, color_type='default',
     else:
         if color_type == 'default':
             colors = plt.rcParams.get('axes.color_cycle', list('bgrcmyk'))
-            if isinstance(colors, six.string_types):
+            if isinstance(colors, compat.string_types):
                 colors = list(colors)
         elif color_type == 'random':
             import random
diff --git a/pandas/tools/rplot.py b/pandas/tools/rplot.py
index 2bc377524..0bd1e79a1 100644
--- a/pandas/tools/rplot.py
+++ b/pandas/tools/rplot.py
@@ -1,9 +1,8 @@
-from pandas.util.py3compat import range
-from pandas.util.py3compat import zip
-import numpy as np
 import random
 from copy import deepcopy
 
+import numpy as np
+from pandas.util.compat import range, zip
 #
 # TODO:
 # * Make sure legends work properly
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 742bc81d4..c3b91ed27 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -9,8 +9,7 @@ from numpy import nan
 import numpy as np
 import random
 
-from pandas.util.py3compat import range, lrange, lzip
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, lrange, lzip, zip
 from pandas.util import compat
 from pandas.tseries.index import DatetimeIndex
 from pandas.tools.merge import merge, concat, ordered_merge, MergeError
diff --git a/pandas/tools/tests/test_pivot.py b/pandas/tools/tests/test_pivot.py
index 084715291..8d3f25a7d 100644
--- a/pandas/tools/tests/test_pivot.py
+++ b/pandas/tools/tests/test_pivot.py
@@ -1,14 +1,15 @@
-from pandas.util.py3compat import range
+import datetime
 import unittest
 
 import numpy as np
 from numpy.testing import assert_equal
 
+import pandas
 from pandas import DataFrame, Series, Index, MultiIndex
 from pandas.tools.merge import concat
 from pandas.tools.pivot import pivot_table, crosstab
+from pandas.util.compat import range, u, product
 import pandas.util.testing as tm
-import six
 
 
 class TestPivotTable(unittest.TestCase):
@@ -74,18 +75,18 @@ class TestPivotTable(unittest.TestCase):
         pv_col = df.pivot_table('quantity', 'month', ['customer', 'product'], dropna=False)
         pv_ind = df.pivot_table('quantity', ['customer', 'product'], 'month', dropna=False)
 
-        m = MultiIndex.from_tuples([(six.u('A'), six.u('a')),
-                                    (six.u('A'), six.u('b')),
-                                    (six.u('A'), six.u('c')),
-                                    (six.u('A'), six.u('d')),
-                                    (six.u('B'), six.u('a')),
-                                    (six.u('B'), six.u('b')),
-                                    (six.u('B'), six.u('c')),
-                                    (six.u('B'), six.u('d')),
-                                    (six.u('C'), six.u('a')),
-                                    (six.u('C'), six.u('b')),
-                                    (six.u('C'), six.u('c')),
-                                    (six.u('C'), six.u('d'))])
+        m = MultiIndex.from_tuples([(u('A'), u('a')),
+                                    (u('A'), u('b')),
+                                    (u('A'), u('c')),
+                                    (u('A'), u('d')),
+                                    (u('B'), u('a')),
+                                    (u('B'), u('b')),
+                                    (u('B'), u('c')),
+                                    (u('B'), u('d')),
+                                    (u('C'), u('a')),
+                                    (u('C'), u('b')),
+                                    (u('C'), u('c')),
+                                    (u('C'), u('d'))])
 
         assert_equal(pv_col.columns.values, m.values)
         assert_equal(pv_ind.index.values, m.values)
@@ -162,7 +163,7 @@ class TestPivotTable(unittest.TestCase):
         nan = np.nan
         df = DataFrame({"a":['R1', 'R2', nan, 'R4'], 'b':["C1", "C2", "C3" , "C4"], "c":[10, 15, nan , 20]})
         result = df.pivot('a','b','c')
-        expected = DataFrame([[nan,nan,nan,nan],[nan,10,nan,nan], 
+        expected = DataFrame([[nan,nan,nan,nan],[nan,10,nan,nan],
                               [nan,nan,nan,nan],[nan,nan,15,20]],
                              index = Index(['R1','R2',nan,'R4'],name='a'),
                              columns = Index(['C1','C2','C3','C4'],name='b'))
@@ -217,9 +218,6 @@ class TestPivotTable(unittest.TestCase):
 
     def test_pivot_integer_columns(self):
         # caused by upstream bug in unstack
-        from pandas.util.compat import product
-        import datetime
-        import pandas
 
         d = datetime.date.min
         data = list(product(['foo', 'bar'], ['A', 'B', 'C'], ['x1', 'x2'],
@@ -247,9 +245,6 @@ class TestPivotTable(unittest.TestCase):
         tm.assert_frame_equal(table, expected)
 
     def test_pivot_columns_lexsorted(self):
-        import datetime
-        import numpy as np
-        import pandas
 
         n = 10000
 
diff --git a/pandas/tools/tests/test_tile.py b/pandas/tools/tests/test_tile.py
index 09095ba80..d939bebde 100644
--- a/pandas/tools/tests/test_tile.py
+++ b/pandas/tools/tests/test_tile.py
@@ -3,7 +3,7 @@ import nose
 import unittest
 
 import numpy as np
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip
 
 from pandas import DataFrame, Series, unique
 import pandas.util.testing as tm
diff --git a/pandas/tools/tile.py b/pandas/tools/tile.py
index fd9d290d6..f987042bb 100644
--- a/pandas/tools/tile.py
+++ b/pandas/tools/tile.py
@@ -8,7 +8,7 @@ from pandas.core.index import _ensure_index
 import pandas.core.algorithms as algos
 import pandas.core.common as com
 import pandas.core.nanops as nanops
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip
 
 import numpy as np
 
diff --git a/pandas/tseries/converter.py b/pandas/tseries/converter.py
index 3e79bdf01..3226a1cb4 100644
--- a/pandas/tseries/converter.py
+++ b/pandas/tseries/converter.py
@@ -1,6 +1,4 @@
 from datetime import datetime, timedelta
-from pandas.util.py3compat import range, lrange
-import six
 import datetime as pydt
 import numpy as np
 
@@ -12,6 +10,8 @@ import matplotlib.dates as dates
 from matplotlib.ticker import Formatter, AutoLocator, Locator
 from matplotlib.transforms import nonsingular
 
+from pandas.util.compat import range, lrange
+import pandas.util.compat as compat
 import pandas.lib as lib
 import pandas.core.common as com
 from pandas.core.index import Index
@@ -38,7 +38,7 @@ def _to_ordinalf(tm):
 
 
 def time2num(d):
-    if isinstance(d, six.string_types):
+    if isinstance(d, compat.string_types):
         parsed = tools.to_datetime(d)
         if not isinstance(parsed, datetime):
             raise ValueError('Could not parse time %s' % d)
@@ -163,7 +163,7 @@ class DatetimeConverter(dates.DateConverter):
             return dates.date2num(values)
         elif (com.is_integer(values) or com.is_float(values)):
             return values
-        elif isinstance(values, six.string_types):
+        elif isinstance(values, compat.string_types):
             return try_parse(values)
         elif isinstance(values, (list, tuple, np.ndarray)):
             if not isinstance(values, np.ndarray):
@@ -810,7 +810,7 @@ def _annual_finder(vmin, vmax, freq):
 
 
 def get_finder(freq):
-    if isinstance(freq, six.string_types):
+    if isinstance(freq, compat.string_types):
         freq = frequencies.get_freq(freq)
     fgroup = frequencies.get_freq_group(freq)
 
@@ -847,7 +847,7 @@ class TimeSeries_DateLocator(Locator):
 
     def __init__(self, freq, minor_locator=False, dynamic_mode=True,
                  base=1, quarter=1, month=1, day=1, plot_obj=None):
-        if isinstance(freq, six.string_types):
+        if isinstance(freq, compat.string_types):
             freq = frequencies.get_freq(freq)
         self.freq = freq
         self.base = base
@@ -926,7 +926,7 @@ class TimeSeries_DateFormatter(Formatter):
 
     def __init__(self, freq, minor_locator=False, dynamic_mode=True,
                  plot_obj=None):
-        if isinstance(freq, six.string_types):
+        if isinstance(freq, compat.string_types):
             freq = frequencies.get_freq(freq)
         self.format = None
         self.freq = freq
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index d6065a9a5..f6e792d4b 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -1,8 +1,6 @@
 from datetime import datetime
-from pandas.util.py3compat import range, long
+from pandas.util.compat import range, long, zip
 from pandas.util import compat
-from pandas.util.py3compat import zip
-import six
 import re
 
 import numpy as np
@@ -58,14 +56,14 @@ def get_to_timestamp_base(base):
 
 
 def get_freq_group(freq):
-    if isinstance(freq, six.string_types):
+    if isinstance(freq, compat.string_types):
         base, mult = get_freq_code(freq)
         freq = base
     return (freq // 1000) * 1000
 
 
 def get_freq(freq):
-    if isinstance(freq, six.string_types):
+    if isinstance(freq, compat.string_types):
         base, mult = get_freq_code(freq)
         freq = base
     return freq
@@ -420,7 +418,7 @@ def to_offset(freqstr):
     if isinstance(freqstr, tuple):
         name = freqstr[0]
         stride = freqstr[1]
-        if isinstance(stride, six.string_types):
+        if isinstance(stride, compat.string_types):
             name, stride = stride, name
         name, _ = _base_and_stride(name)
         delta = get_offset(name) * stride
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 2bff7c0e4..63e96efc2 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -8,6 +8,8 @@ import numpy as np
 
 from pandas.core.common import isnull, _NS_DTYPE, _INT64_DTYPE
 from pandas.core.index import Index, Int64Index
+import pandas.util.compat as compat
+from pandas.util.compat import u
 from pandas.tseries.frequencies import (
     infer_freq, to_offset, get_period_alias,
     Resolution, get_reso_string)
@@ -23,7 +25,6 @@ import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.algos as _algos
 import pandas.index as _index
-import six
 
 
 def _utc():
@@ -71,7 +72,7 @@ def _dt_index_cmp(opname):
             other = _to_m8(other, tz=self.tz)
         elif isinstance(other, list):
             other = DatetimeIndex(other)
-        elif isinstance(other, six.string_types):
+        elif isinstance(other, compat.string_types):
             other = _to_m8(other, tz=self.tz)
         elif not isinstance(other, np.ndarray):
             other = _ensure_datetime64(other)
@@ -208,7 +209,7 @@ class DatetimeIndex(Int64Index):
 
                     return data
 
-        if issubclass(data.dtype.type, six.string_types):
+        if issubclass(data.dtype.type, compat.string_types):
             data = _str_to_dt_array(data, offset, dayfirst=dayfirst,
                                       yearfirst=yearfirst)
 
@@ -582,21 +583,21 @@ class DatetimeIndex(Int64Index):
     def _format_with_header(self, header, **kwargs):
         return header + self._format_native_types(**kwargs)
 
-    def _format_native_types(self, na_rep=six.u('NaT'), **kwargs):
+    def _format_native_types(self, na_rep=u('NaT'), **kwargs):
         data = list(self)
 
         # tz formatter or time formatter
         zero_time = time(0, 0)
         for d in data:
             if d.time() != zero_time or d.tzinfo is not None:
-                return [six.u('%s') % x for x in data]
+                return [u('%s') % x for x in data]
 
         values = np.array(data,dtype=object)
         mask = isnull(self.values)
         values[mask] = na_rep
 
         imask = -mask
-        values[imask] = np.array([six.u('%d-%.2d-%.2d') % (
+        values[imask] = np.array([u('%d-%.2d-%.2d') % (
                                   dt.year, dt.month, dt.day)
                                   for dt in values[imask] ])
         return values.tolist()
@@ -769,7 +770,7 @@ class DatetimeIndex(Int64Index):
         shifted : DatetimeIndex
         """
         if freq is not None and freq != self.offset:
-            if isinstance(freq, six.string_types):
+            if isinstance(freq, compat.string_types):
                 freq = to_offset(freq)
             result = Index.shift(self, n, freq)
             result.tz = self.tz
@@ -1233,7 +1234,7 @@ class DatetimeIndex(Int64Index):
         """
         Index.slice_locs, customized to handle partial ISO-8601 string slicing
         """
-        if isinstance(start, six.string_types) or isinstance(end, six.string_types):
+        if isinstance(start, compat.string_types) or isinstance(end, compat.string_types):
 
             if self.is_monotonic:
                 try:
@@ -1546,7 +1547,7 @@ class DatetimeIndex(Int64Index):
         if asof:
             raise NotImplementedError
 
-        if isinstance(time, six.string_types):
+        if isinstance(time, compat.string_types):
             time = parse(time).time()
 
         if time.tzinfo:
@@ -1576,10 +1577,10 @@ class DatetimeIndex(Int64Index):
         """
         from dateutil.parser import parse
 
-        if isinstance(start_time, six.string_types):
+        if isinstance(start_time, compat.string_types):
             start_time = parse(start_time).time()
 
-        if isinstance(end_time, six.string_types):
+        if isinstance(end_time, compat.string_types):
             end_time = parse(end_time).time()
 
         if start_time.tzinfo or end_time.tzinfo:
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 303a11929..565abc195 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -1,7 +1,6 @@
 from datetime import date, datetime, timedelta
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from pandas.util import compat
-import six
 import numpy as np
 
 from pandas.tseries.tools import to_datetime
@@ -140,7 +139,7 @@ class DateOffset(object):
         if other is None:
             return False
 
-        if isinstance(other, six.string_types):
+        if isinstance(other, compat.string_types):
             from pandas.tseries.frequencies import to_offset
             other = to_offset(other)
 
@@ -431,7 +430,7 @@ class CustomBusinessDay(BusinessDay):
 
     @staticmethod
     def _to_dt64(dt, dtype='datetime64'):
-        if isinstance(dt, (datetime, six.string_types)):
+        if isinstance(dt, (datetime, compat.string_types)):
             dt = np.datetime64(dt, dtype=dtype)
         if isinstance(dt, np.datetime64):
             dt = dt.astype(dtype)
@@ -1169,7 +1168,7 @@ class Tick(DateOffset):
         return self.apply(other)
 
     def __eq__(self, other):
-        if isinstance(other, six.string_types):
+        if isinstance(other, compat.string_types):
             from pandas.tseries.frequencies import to_offset
             other = to_offset(other)
 
@@ -1184,7 +1183,7 @@ class Tick(DateOffset):
         return hash(self._params())
 
     def __ne__(self, other):
-        if isinstance(other, six.string_types):
+        if isinstance(other, compat.string_types):
             from pandas.tseries.frequencies import to_offset
             other = to_offset(other)
 
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index 9fce35652..c512331ae 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -14,14 +14,13 @@ import pandas.tseries.frequencies as _freq_mod
 
 import pandas.core.common as com
 from pandas.core.common import isnull, _NS_DTYPE, _INT64_DTYPE
-from pandas.util import py3compat
+from pandas.util import compat
 
 from pandas.lib import Timestamp
 import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.algos as _algos
-import six
-from pandas.util.py3compat import map, zip
+from pandas.util.compat import map, zip, u
 
 
 #---------------
@@ -49,7 +48,7 @@ class Period(PandasObject):
 
     Parameters
     ----------
-    value : Period or six.string_types, default None
+    value : Period or compat.string_types, default None
         The time period represented (e.g., '4Q2005')
     freq : str, default None
         e.g., 'B' for businessday, ('T', 5) or '5T' for 5 minutes
@@ -101,7 +100,7 @@ class Period(PandasObject):
                 converted = other.asfreq(freq)
                 self.ordinal = converted.ordinal
 
-        elif isinstance(value, six.string_types) or com.is_integer(value):
+        elif isinstance(value, compat.string_types) or com.is_integer(value):
             if com.is_integer(value):
                 value = str(value)
 
@@ -269,7 +268,7 @@ class Period(PandasObject):
         formatted = tslib.period_format(self.ordinal, base)
         freqstr = _freq_mod._reverse_period_code_map[base]
 
-        if not py3compat.PY3:
+        if not compat.PY3:
             encoding = com.get_option("display.encoding")
             formatted = formatted.encode(encoding)
 
@@ -668,7 +667,7 @@ class PeriodIndex(Int64Index):
 
     def __contains__(self, key):
         if not isinstance(key, Period) or key.freq != self.freq:
-            if isinstance(key, six.string_types):
+            if isinstance(key, compat.string_types):
                 try:
                     self.get_loc(key)
                     return True
@@ -948,7 +947,7 @@ class PeriodIndex(Int64Index):
         """
         Index.slice_locs, customized to handle partial ISO-8601 string slicing
         """
-        if isinstance(start, six.string_types) or isinstance(end, six.string_types):
+        if isinstance(start, compat.string_types) or isinstance(end, compat.string_types):
             try:
                 if start:
                     start_loc = self._get_string_slice(start).start
@@ -1059,14 +1058,14 @@ class PeriodIndex(Int64Index):
     def _format_with_header(self, header, **kwargs):
         return header + self._format_native_types(**kwargs)
 
-    def _format_native_types(self, na_rep=six.u('NaT'), **kwargs):
+    def _format_native_types(self, na_rep=u('NaT'), **kwargs):
 
         values = np.array(list(self),dtype=object)
         mask = isnull(self.values)
         values[mask] = na_rep
 
         imask = -mask
-        values[imask] = np.array([six.u('%s') % dt for dt in values[imask]])
+        values[imask] = np.array([u('%s') % dt for dt in values[imask]])
         return values.tolist()
 
     def __array_finalize__(self, obj):
@@ -1086,8 +1085,8 @@ class PeriodIndex(Int64Index):
 
     def __unicode__(self):
         output = self.__class__.__name__
-        output += six.u('(')
-        prefix = '' if py3compat.PY3 else 'u'
+        output += u('(')
+        prefix = '' if compat.PY3 else 'u'
         mapper = "{0}'{{0}}'".format(prefix)
         output += '[{0}]'.format(', '.join(map(mapper.format, self)))
         output += ", freq='{0}'".format(self.freq)
@@ -1099,7 +1098,7 @@ class PeriodIndex(Int64Index):
         return self.__unicode__().encode(encoding, 'replace')
 
     def __str__(self):
-        if py3compat.PY3:
+        if compat.PY3:
             return self.__unicode__()
         return self.__bytes__()
 
diff --git a/pandas/tseries/resample.py b/pandas/tseries/resample.py
index 253abcbd8..687d505db 100644
--- a/pandas/tseries/resample.py
+++ b/pandas/tseries/resample.py
@@ -1,6 +1,5 @@
 from datetime import timedelta
 
-import six
 import numpy as np
 
 from pandas.core.groupby import BinGrouper, CustomGrouper
@@ -10,6 +9,7 @@ from pandas.tseries.offsets import DateOffset, Tick, _delta_to_nanoseconds
 from pandas.tseries.period import PeriodIndex, period_range
 import pandas.tseries.tools as tools
 import pandas.core.common as com
+import pandas.util.compat as compat
 
 from pandas.lib import Timestamp
 import pandas.lib as lib
@@ -231,7 +231,7 @@ class TimeGrouper(CustomGrouper):
                                        limit=self.limit)
 
         loffset = self.loffset
-        if isinstance(loffset, six.string_types):
+        if isinstance(loffset, compat.string_types):
             loffset = to_offset(self.loffset)
 
         if isinstance(loffset, (DateOffset, timedelta)):
@@ -292,7 +292,7 @@ def _take_new_index(obj, indexer, new_index, axis=0):
 
 
 def _get_range_edges(axis, offset, closed='left', base=0):
-    if isinstance(offset, six.string_types):
+    if isinstance(offset, compat.string_types):
         offset = to_offset(offset)
 
     if isinstance(offset, Tick):
diff --git a/pandas/tseries/tests/test_converter.py b/pandas/tseries/tests/test_converter.py
index aca714080..0d6449ec7 100644
--- a/pandas/tseries/tests/test_converter.py
+++ b/pandas/tseries/tests/test_converter.py
@@ -6,7 +6,7 @@ import unittest
 import nose
 
 import numpy as np
-import six
+from pandas.util.compat import u
 
 try:
     import pandas.tseries.converter as converter
@@ -15,7 +15,7 @@ except ImportError:
 
 
 def test_timtetonum_accepts_unicode():
-    assert(converter.time2num("00:01") == converter.time2num(six.u("00:01")))
+    assert(converter.time2num("00:01") == converter.time2num(u("00:01")))
 
 
 class TestDateTimeConverter(unittest.TestCase):
@@ -26,7 +26,7 @@ class TestDateTimeConverter(unittest.TestCase):
 
     def test_convert_accepts_unicode(self):
         r1 = self.dtc.convert("12:22", None, None)
-        r2 = self.dtc.convert(six.u("12:22"), None, None)
+        r2 = self.dtc.convert(u("12:22"), None, None)
         assert(r1 == r2), "DatetimeConverter.convert should accept unicode"
 
     def test_conversion(self):
diff --git a/pandas/tseries/tests/test_daterange.py b/pandas/tseries/tests/test_daterange.py
index b9f5e7315..ad1c04739 100644
--- a/pandas/tseries/tests/test_daterange.py
+++ b/pandas/tseries/tests/test_daterange.py
@@ -1,5 +1,5 @@
 from datetime import datetime
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import pickle
 import unittest
 import nose
diff --git a/pandas/tseries/tests/test_frequencies.py b/pandas/tseries/tests/test_frequencies.py
index bcaba1fee..24d268972 100644
--- a/pandas/tseries/tests/test_frequencies.py
+++ b/pandas/tseries/tests/test_frequencies.py
@@ -1,5 +1,5 @@
 from datetime import datetime, time, timedelta
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import sys
 import os
 import unittest
diff --git a/pandas/tseries/tests/test_offsets.py b/pandas/tseries/tests/test_offsets.py
index 3f4960520..3e64e4c03 100644
--- a/pandas/tseries/tests/test_offsets.py
+++ b/pandas/tseries/tests/test_offsets.py
@@ -1,5 +1,5 @@
 from datetime import date, datetime, timedelta
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from pandas.util import compat
 import unittest
 import nose
diff --git a/pandas/tseries/tests/test_period.py b/pandas/tseries/tests/test_period.py
index 909c8b361..c2faf4511 100644
--- a/pandas/tseries/tests/test_period.py
+++ b/pandas/tseries/tests/test_period.py
@@ -22,15 +22,13 @@ import pandas.tseries.period as pmod
 import pandas.core.datetools as datetools
 import pandas as pd
 import numpy as np
-import six
-from pandas.util.py3compat import range, lrange, lmap
-from pandas.util.py3compat import map, zip
+from pandas.util.compat import range, lrange, lmap, map, zip
 randn = np.random.randn
 
 from pandas import Series, TimeSeries, DataFrame
 from pandas.util.testing import assert_series_equal, assert_almost_equal
 import pandas.util.testing as tm
-from pandas.util import py3compat
+from pandas.util import compat
 from numpy.testing import assert_array_equal
 
 
@@ -213,7 +211,7 @@ class TestPeriodProperties(TestCase):
         p = Period('2000-1-1 12:34:12', freq='S')
         res = p.strftime('%Y-%m-%d %H:%M:%S')
         self.assertEqual(res,  '2000-01-01 12:34:12')
-        tm.assert_isinstance(res, six.text_type) # GH3363
+        tm.assert_isinstance(res, compat.text_type) # GH3363
 
     def test_sub_delta(self):
         left, right = Period('2011', freq='A'), Period('2007', freq='A')
@@ -1625,45 +1623,45 @@ class TestPeriodIndex(TestCase):
     def test_period_index_unicode(self):
         pi = PeriodIndex(freq='A', start='1/1/2001', end='12/1/2009')
         assert_equal(len(pi), 9)
-        assert_equal(pi, eval(six.text_type(pi)))
+        assert_equal(pi, eval(compat.text_type(pi)))
 
         pi = PeriodIndex(freq='Q', start='1/1/2001', end='12/1/2009')
         assert_equal(len(pi), 4 * 9)
-        assert_equal(pi, eval(six.text_type(pi)))
+        assert_equal(pi, eval(compat.text_type(pi)))
 
         pi = PeriodIndex(freq='M', start='1/1/2001', end='12/1/2009')
         assert_equal(len(pi), 12 * 9)
-        assert_equal(pi, eval(six.text_type(pi)))
+        assert_equal(pi, eval(compat.text_type(pi)))
 
         start = Period('02-Apr-2005', 'B')
         i1 = PeriodIndex(start=start, periods=20)
         assert_equal(len(i1), 20)
         assert_equal(i1.freq, start.freq)
         assert_equal(i1[0], start)
-        assert_equal(i1, eval(six.text_type(i1)))
+        assert_equal(i1, eval(compat.text_type(i1)))
 
         end_intv = Period('2006-12-31', 'W')
         i1 = PeriodIndex(end=end_intv, periods=10)
         assert_equal(len(i1), 10)
         assert_equal(i1.freq, end_intv.freq)
         assert_equal(i1[-1], end_intv)
-        assert_equal(i1, eval(six.text_type(i1)))
+        assert_equal(i1, eval(compat.text_type(i1)))
 
         end_intv = Period('2006-12-31', '1w')
         i2 = PeriodIndex(end=end_intv, periods=10)
         assert_equal(len(i1), len(i2))
         self.assert_((i1 == i2).all())
         assert_equal(i1.freq, i2.freq)
-        assert_equal(i1, eval(six.text_type(i1)))
-        assert_equal(i2, eval(six.text_type(i2)))
+        assert_equal(i1, eval(compat.text_type(i1)))
+        assert_equal(i2, eval(compat.text_type(i2)))
 
         end_intv = Period('2006-12-31', ('w', 1))
         i2 = PeriodIndex(end=end_intv, periods=10)
         assert_equal(len(i1), len(i2))
         self.assert_((i1 == i2).all())
         assert_equal(i1.freq, i2.freq)
-        assert_equal(i1, eval(six.text_type(i1)))
-        assert_equal(i2, eval(six.text_type(i2)))
+        assert_equal(i1, eval(compat.text_type(i1)))
+        assert_equal(i2, eval(compat.text_type(i2)))
 
         try:
             PeriodIndex(start=start, end=end_intv)
@@ -1673,7 +1671,7 @@ class TestPeriodIndex(TestCase):
 
         end_intv = Period('2005-05-01', 'B')
         i1 = PeriodIndex(start=start, end=end_intv)
-        assert_equal(i1, eval(six.text_type(i1)))
+        assert_equal(i1, eval(compat.text_type(i1)))
 
         try:
             PeriodIndex(start=start)
@@ -1686,12 +1684,12 @@ class TestPeriodIndex(TestCase):
         i2 = PeriodIndex([end_intv, Period('2005-05-05', 'B')])
         assert_equal(len(i2), 2)
         assert_equal(i2[0], end_intv)
-        assert_equal(i2, eval(six.text_type(i2)))
+        assert_equal(i2, eval(compat.text_type(i2)))
 
         i2 = PeriodIndex(np.array([end_intv, Period('2005-05-05', 'B')]))
         assert_equal(len(i2), 2)
         assert_equal(i2[0], end_intv)
-        assert_equal(i2, eval(six.text_type(i2)))
+        assert_equal(i2, eval(compat.text_type(i2)))
 
         # Mixed freq should fail
         vals = [end_intv, Period('2006-12-31', 'w')]
@@ -2001,9 +1999,9 @@ class TestPeriodIndex(TestCase):
         index = PeriodIndex(raw, freq='A')
         types = str,
 
-        if py3compat.PY3:
+        if compat.PY3:
             # unicode
-            types += six.text_type,
+            types += compat.text_type,
 
         for t in types:
             expected = np.array(lmap(t, raw), dtype=object)
diff --git a/pandas/tseries/tests/test_plotting.py b/pandas/tseries/tests/test_plotting.py
index 95bfa98d3..e4a707f28 100644
--- a/pandas/tseries/tests/test_plotting.py
+++ b/pandas/tseries/tests/test_plotting.py
@@ -3,8 +3,7 @@ from datetime import datetime, timedelta, date, time
 
 import unittest
 import nose
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, lrange, zip
 
 import numpy as np
 from numpy.testing.decorators import slow
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index 1db735896..52055d13f 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -2,8 +2,7 @@
 
 from datetime import datetime, timedelta
 
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip
+from pandas.util.compat import range, lrange, zip, product
 import numpy as np
 
 from pandas import Series, TimeSeries, DataFrame, Panel, isnull, notnull, Timestamp
@@ -605,7 +604,6 @@ def _simple_pts(start, end, freq='D'):
 
 
 from pandas.tseries.frequencies import MONTHS, DAYS
-from pandas.util.compat import product
 
 
 class TestResamplePeriodIndex(unittest.TestCase):
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 779166f3c..e2213a85a 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -28,15 +28,15 @@ import pandas.tslib as tslib
 
 import pandas.index as _index
 
-from pandas.util.py3compat import range, long, StringIO, lrange, lmap
-from pandas.util.compat import product
-from pandas.util.py3compat import map, zip, cPickle as pickle
+from pandas.util.compat import(
+    range, long, StringIO, lrange, lmap, map, zip, cPickle as pickle, product
+)
 from pandas import read_pickle
 import pandas.core.datetools as dt
 from numpy.random import rand
 from numpy.testing import assert_array_equal
 from pandas.util.testing import assert_frame_equal
-import pandas.util.py3compat as py3compat
+import pandas.util.compat as compat
 from pandas.core.datetools import BDay
 import pandas.core.common as com
 from pandas import concat
@@ -1966,7 +1966,7 @@ class TestLegacySupport(unittest.TestCase):
 
     @classmethod
     def setUpClass(cls):
-        if py3compat.PY3:
+        if compat.PY3:
             raise nose.SkipTest
 
         pth, _ = os.path.split(os.path.abspath(__file__))
@@ -2816,7 +2816,7 @@ class TestTimestamp(unittest.TestCase):
         check(days,unit='D',h=0)
 
         # using truediv, so these are like floats
-        if py3compat.PY3:
+        if compat.PY3:
             check((val+500000)/long(1000000000),unit='s',us=500)
             check((val+500000000)/long(1000000000),unit='s',us=500000)
             check((val+500000)/long(1000000),unit='ms',us=500)
diff --git a/pandas/tseries/tests/test_timezones.py b/pandas/tseries/tests/test_timezones.py
index 7ee89f7ca..47e006af3 100644
--- a/pandas/tseries/tests/test_timezones.py
+++ b/pandas/tseries/tests/test_timezones.py
@@ -27,9 +27,8 @@ import pandas.lib as lib
 import pandas.core.datetools as dt
 from numpy.random import rand
 from pandas.util.testing import assert_frame_equal
-import pandas.util.py3compat as py3compat
-from pandas.util.py3compat import range, lrange
-from pandas.util.py3compat import zip, cPickle as pickle
+import pandas.util.compat as compat
+from pandas.util.compat import range, lrange, zip, cPickle as pickle
 from pandas.core.datetools import BDay
 import pandas.core.common as com
 
diff --git a/pandas/tseries/tests/test_util.py b/pandas/tseries/tests/test_util.py
index 5bfdbba56..84666b019 100644
--- a/pandas/tseries/tests/test_util.py
+++ b/pandas/tseries/tests/test_util.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import nose
 import unittest
 
diff --git a/pandas/tseries/tools.py b/pandas/tseries/tools.py
index f043dcb87..f7eafdac1 100644
--- a/pandas/tseries/tools.py
+++ b/pandas/tseries/tools.py
@@ -2,13 +2,13 @@ from datetime import datetime, timedelta
 import re
 import sys
 
-import six
 import numpy as np
 
 import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.core.common as com
-from pandas.util.py3compat import StringIO
+from pandas.util.compat import StringIO, callable
+import pandas.util.compat as compat
 
 try:
     import dateutil
@@ -41,7 +41,7 @@ def _infer_tzinfo(start, end):
 
 
 def _maybe_get_tz(tz):
-    if isinstance(tz, six.string_types):
+    if isinstance(tz, compat.string_types):
         import pytz
         tz = pytz.timezone(tz)
     if com.is_integer(tz):
@@ -149,7 +149,7 @@ def parse_time_string(arg, freq=None, dayfirst=None, yearfirst=None):
 
     Parameters
     ----------
-    arg : six.string_types
+    arg : compat.string_types
     freq : str or DateOffset, default None
         Helps with interpreting time string if supplied
     dayfirst : bool, default None
@@ -166,7 +166,7 @@ def parse_time_string(arg, freq=None, dayfirst=None, yearfirst=None):
     from pandas.tseries.frequencies import (_get_rule_month, _month_numbers,
                                             _get_freq_str)
 
-    if not isinstance(arg, six.string_types):
+    if not isinstance(arg, compat.string_types):
         return arg
 
     arg = arg.upper()
@@ -272,14 +272,14 @@ def dateutil_parse(timestr, default,
     if res.weekday is not None and not res.day:
         ret = ret + relativedelta.relativedelta(weekday=res.weekday)
     if not ignoretz:
-        if six.callable(tzinfos) or tzinfos and res.tzname in tzinfos:
-            if six.callable(tzinfos):
+        if callable(tzinfos) or tzinfos and res.tzname in tzinfos:
+            if callable(tzinfos):
                 tzdata = tzinfos(res.tzname, res.tzoffset)
             else:
                 tzdata = tzinfos.get(res.tzname)
             if isinstance(tzdata, datetime.tzinfo):
                 tzinfo = tzdata
-            elif isinstance(tzdata, six.string_types):
+            elif isinstance(tzdata, compat.string_types):
                 tzinfo = tz.tzstr(tzdata)
             elif isinstance(tzdata, int):
                 tzinfo = tz.tzoffset(res.tzname, tzdata)
diff --git a/pandas/tseries/util.py b/pandas/tseries/util.py
index 5021214ac..33d33045c 100644
--- a/pandas/tseries/util.py
+++ b/pandas/tseries/util.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import numpy as np
 
 import pandas as pd
diff --git a/pandas/util/compat.py b/pandas/util/compat.py
index 1f57d0025..27f5671ca 100644
--- a/pandas/util/compat.py
+++ b/pandas/util/compat.py
@@ -1,22 +1,113 @@
-import sys
-import six
-from pandas.util.py3compat import map, filter
-from pandas.util.py3compat import range
+"""
+compat
+======
+
+Cross-compatible functions for Python 2 and 3.
+
+Key items to import for 2/3 compatible code:
+* iterators: range(), map(), zip(), filter(), reduce()
+* lists: lrange(), lmap(), lzip(), lfilter()
+* unicode: u() [u"" is a syntax error in Python 3.0-3.2]
+* longs: long (int in Python 3)
+* callable
+* iterable method compatibility: iteritems, iterkeys, itervalues
+  * Uses the original method if available, otherwise uses items, keys, values.
+* types:
+    * text_type: unicode in Python 2, str in Python 3
+    * binary_type: str in Python 2, bythes in Python 3
+    * string_types: basestring in Python 2, str in Python 3
+* bind_method: binds functions to classes
+
+Python 2.6 compatibility:
+* OrderedDict
+* Counter
+
+Other items:
+* OrderedDefaultDict
+"""
+# pylint disable=W0611
+import functools
+import itertools
 from itertools import product
+import sys
+import types
 
+PY3 = (sys.version_info[0] >= 3)
+# import iterator versions of these functions
 
-# OrderedDict Shim from  Raymond Hettinger, python core dev
-# http://code.activestate.com/recipes/576693-ordered-dictionary-for-py24/
-# here to support versions before 2.6
 try:
-    from thread import get_ident as _get_ident
+    import __builtin__ as builtins
+    # not writeable when instantiated with string, doesn't handle unicode well
+    from cStringIO import StringIO as cStringIO
+    # always writeable
+    from StringIO import StringIO
+    BytesIO = StringIO
+    import cPickle
 except ImportError:
-    from dummy_thread import get_ident as _get_ident
+    import builtins
+    from io import StringIO, BytesIO
+    cStringIO = StringIO
+    import pickle as cPickle
 
-try:
-    from _abcoll import KeysView, ValuesView, ItemsView
-except ImportError:
-    pass
+
+if PY3:
+    def isidentifier(s):
+        return s.isidentifier()
+
+    def str_to_bytes(s, encoding='ascii'):
+        return s.encode(encoding)
+
+    def bytes_to_str(b, encoding='utf-8'):
+        return b.decode(encoding)
+
+    # have to explicitly put builtins into the namespace
+    range = range
+    map = map
+    zip = zip
+    filter = filter
+    reduce = functools.reduce
+    long = int
+    unichr = chr
+
+    # list-producing versions of the major Python iterating functions
+    def lrange(*args, **kwargs):
+        return list(range(*args, **kwargs))
+
+    def lzip(*args, **kwargs):
+        return list(zip(*args, **kwargs))
+
+    def lmap(*args, **kwargs):
+        return list(map(*args, **kwargs))
+
+    def lfilter(*args, **kwargs):
+        return list(filter(*args, **kwargs))
+else:
+    # Python 2
+    import re
+    _name_re = re.compile(r"[a-zA-Z_][a-zA-Z0-9_]*$")
+
+    def isidentifier(s, dotted=False):
+        return bool(_name_re.match(s))
+
+    def str_to_bytes(s, encoding='ascii'):
+        return s
+
+    def bytes_to_str(b, encoding='ascii'):
+        return b
+
+    range = xrange
+    zip = itertools.izip
+    filter = itertools.ifilter
+    map = itertools.imap
+    reduce = reduce
+    long = long
+    unichr = unichr
+
+    # Python 2-builtin ranges produce lists
+    lrange = builtins.range
+    lzip = builtins.zip
+    lmap = builtins.map
+    lfilter = builtins.filter
 
 
 def iteritems(obj, **kwargs):
@@ -24,13 +115,104 @@ def iteritems(obj, **kwargs):
        uses 'iteritems' if available and otherwise uses 'items'.
 
        Passes kwargs to method."""
-    if hasattr(obj, "iteritems"):
-        return obj.iteritems(**kwargs)
+    func = getattr(obj, "iteritems", None)
+    if not func:
+        func = obj.items
+    return func(**kwargs)
+
+
+def iterkeys(obj, **kwargs):
+    func = getattr(obj, "iterkeys", None)
+    if not func:
+        func = obj.keys
+    return func(**kwargs)
+
+
+def itervalues(obj, **kwargs):
+    func = getattr(obj, "itervalues", None)
+    if not func:
+        func = obj.values
+    return func(**kwargs)
+
+
+def bind_method(cls, name, func):
+    """Bind a method to class, python 2 and python 3 compatible.
+
+    Parameters
+    ----------
+
+    cls : type
+        class to receive bound method
+    name : basestring
+        name of method on class instance
+    func : function
+        function to be bound as method
+
+
+    Returns
+    -------
+    None
+    """
+    # only python 2 has bound/unbound method issue
+    if not PY3:
+        setattr(cls, name, types.MethodType(func, None, cls))
     else:
-        return obj.items(**kwargs)
+        setattr(cls, name, func)
+# ----------------------------------------------------------------------------
+# functions largely based / taken from the six module
+
+# Much of the code in this module comes from Benjamin Peterson's six library.
+# The license for this library can be found in LICENSES/SIX and the code can be
+# found at https://bitbucket.org/gutworth/six
+
+if PY3:
+    string_types = str,
+    integer_types = int,
+    class_types = type,
+    text_type = str
+    binary_type = bytes
+
+    def u(s):
+        return s
+else:
+    string_types = basestring,
+    integer_types = (int, long)
+    class_types = (type, types.ClassType)
+    text_type = unicode
+    binary_type = str
+
+    def u(s):
+        return unicode(s, "unicode_escape")
+
+try:
+    # callable reintroduced in later versions of Python
+    callable = callable
+except NameError:
+    def callable(obj):
+        return any("__call__" in klass.__dict__ for klass in type(obj).__mro__)
+
+# ----------------------------------------------------------------------------
+# Python 2.6 compatibility shims
+#
+
+# OrderedDict Shim from  Raymond Hettinger, python core dev
+# http://code.activestate.com/recipes/576693-ordered-dictionary-for-py24/
+# here to support versions before 2.6
+if not PY3:
+    # don't need this except in 2.6
+    try:
+        from thread import get_ident as _get_ident
+    except ImportError:
+        from dummy_thread import get_ident as _get_ident
+
+try:
+    from _abcoll import KeysView, ValuesView, ItemsView
+except ImportError:
+    pass
 
 
 class _OrderedDict(dict):
+
     'Dictionary that remembers insertion order'
     # An inherited dict maps keys to values.
     # The inherited dict provides __getitem__, __len__, __contains__, and get.
@@ -38,10 +220,11 @@ class _OrderedDict(dict):
     # Big-O running times for all methods are the same as for regular
     # dictionaries.
 
-    # The internal self.__map dictionary maps keys to links in a doubly linked list.
-    # The circular doubly linked list starts and ends with a sentinel element.
-    # The sentinel element never gets deleted (this simplifies the algorithm).
-    # Each link is stored as a list of length three:  [PREV, NEXT, KEY].
+    # The internal self.__map dictionary maps keys to links in a doubly linked
+    # list.  The circular doubly linked list starts and ends with a sentinel
+    # element.  The sentinel element never gets deleted (this simplifies the
+    # algorithm).  Each link is stored as a list of length three:  [PREV, NEXT,
+    # KEY].
 
     def __init__(self, *args, **kwds):
         '''Initialize an ordered dictionary.  Signature is the same as for
@@ -61,9 +244,9 @@ class _OrderedDict(dict):
 
     def __setitem__(self, key, value, dict_setitem=dict.__setitem__):
         'od.__setitem__(i, y) <==> od[i]=y'
-        # Setting a new item creates a new link which goes at the end of the linked
-        # list, and the inherited dictionary is updated with the new key/value
-        # pair.
+        # Setting a new item creates a new link which goes at the end of the
+        # linked list, and the inherited dictionary is updated with the new
+        # key/value pair.
         if key not in self:
             root = self.__root
             last = root[0]
@@ -99,7 +282,7 @@ class _OrderedDict(dict):
     def clear(self):
         'od.clear() -> None.  Remove all items from od.'
         try:
-            for node in six.itervalues(self.__map):
+            for node in itervalues(self.__map):
                 del node[:]
             root = self.__root
             root[:] = [root, root, None]
@@ -110,8 +293,8 @@ class _OrderedDict(dict):
 
     def popitem(self, last=True):
         '''od.popitem() -> (k, v), return and remove a (key, value) pair.
-        Pairs are returned in LIFO order if last is true or FIFO order if false.
-
+        Pairs are returned in LIFO order if last is true or FIFO order if
+        false.
         '''
         if not self:
             raise KeyError('dictionary is empty')
@@ -162,11 +345,10 @@ class _OrderedDict(dict):
     def update(*args, **kwds):
         '''od.update(E, **F) -> None.  Update od from dict/iterable E and F.
 
-        If E is a dict instance, does:           for k in E: od[k] = E[k]
-        If E has a .keys() method, does:         for k in E.keys(): od[k] = E[k]
-        Or if E is an iterable of items, does:   for k, v in E: od[k] = v
-        In either case, this is followed by:     for k, v in F.items(): od[k] = v
-
+        If E is a dict instance, does:        for k in E: od[k] = E[k]
+        If E has a .keys() method, does:      for k in E.keys(): od[k] = E[k]
+        Or if E is an iterable of items, does:for k, v in E: od[k] = v
+        In either case, this is followed by:  for k, v in F.items(): od[k] = v
         '''
         if len(args) > 2:
             raise TypeError('update() takes at most 2 positional '
@@ -189,15 +371,15 @@ class _OrderedDict(dict):
                 self[key] = value
         for key, value in kwds.items():
             self[key] = value
-
-    __update = update  # let subclasses override update without breaking __init__
+    # let subclasses override update without breaking __init__
+    __update = update
 
     __marker = object()
 
     def pop(self, key, default=__marker):
-        '''od.pop(k[,d]) -> v, remove specified key and return the corresponding value.
-        If key is not found, d is returned if given, otherwise KeyError is raised.
-
+        '''od.pop(k[,d]) -> v, remove specified key and return the\
+        corresponding value.  If key is not found, d is returned if given,
+        otherwise KeyError is raised.
         '''
         if key in self:
             result = self[key]
@@ -243,9 +425,8 @@ class _OrderedDict(dict):
 
     @classmethod
     def fromkeys(cls, iterable, value=None):
-        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S
-        and values equal to v (which defaults to None).
-
+        '''OD.fromkeys(S[, v]) -> New ordered dictionary with keys from S and
+        values equal to v (which defaults to None).
         '''
         d = cls()
         for key in iterable:
@@ -253,12 +434,13 @@ class _OrderedDict(dict):
         return d
 
     def __eq__(self, other):
-        '''od.__eq__(y) <==> od==y.  Comparison to another OD is order-sensitive
-        while comparison to a regular mapping is order-insensitive.
-
+        '''od.__eq__(y) <==> od==y.  Comparison to another OD is
+        order-sensitive while comparison to a regular mapping is
+        order-insensitive.
         '''
         if isinstance(other, OrderedDict):
-            return len(self) == len(other) and list(self.items()) == list(other.items())
+            return (len(self) == len(other) and
+                    list(self.items()) == list(other.items()))
         return dict.__eq__(self, other)
 
     def __ne__(self, other):
@@ -279,7 +461,7 @@ class _OrderedDict(dict):
         return ItemsView(self)
 
 
-## {{{ http://code.activestate.com/recipes/576611/ (r11)
+# {{{ http://code.activestate.com/recipes/576611/ (r11)
 
 try:
     from operator import itemgetter
@@ -289,6 +471,7 @@ except ImportError:
 
 
 class _Counter(dict):
+
     '''Dict subclass for counting hashable objects.  Sometimes called a bag
     or multiset.  Elements are stored as dictionary keys and their counts
     are stored as dictionary values.
@@ -303,10 +486,10 @@ class _Counter(dict):
         from an input iterable.  Or, initialize the count from another mapping
         of elements to their counts.
 
-        >>> c = Counter()                           # a new, empty counter
-        >>> c = Counter('gallahad')                 # a new counter from an iterable
-        >>> c = Counter({'a': 4, 'b': 2})           # a new counter from a mapping
-        >>> c = Counter(a=4, b=2)                   # a new counter from keyword args
+        >>> c = Counter()                    # a new, empty counter
+        >>> c = Counter('gallahad')          # a new counter from an iterable
+        >>> c = Counter({'a': 4, 'b': 2})    # a new counter from a mapping
+        >>> c = Counter(a=4, b=2)            # a new counter from keyword args
 
         '''
         self.update(iterable, **kwds)
@@ -382,7 +565,8 @@ class _Counter(dict):
         return Counter(self)
 
     def __delitem__(self, elem):
-        'Like dict.__delitem__() but does not raise KeyError for missing values.'
+        '''Like dict.__delitem__() but does not raise KeyError for missing
+        values.'''
         if elem in self:
             dict.__delitem__(self, elem)
 
@@ -479,13 +663,15 @@ else:
 # http://stackoverflow.com/questions/4126348
 # Thanks to @martineau at SO
 
+
 class OrderedDefaultdict(OrderedDict):
+
     def __init__(self, *args, **kwargs):
         newdefault = None
         newargs = ()
         if args:
             newdefault = args[0]
-            if not (newdefault is None or six.callable(newdefault)):
+            if not (newdefault is None or callable(newdefault)):
                 raise TypeError('first argument must be callable or None')
             newargs = args[1:]
         self.default_factory = newdefault
diff --git a/pandas/util/counter.py b/pandas/util/counter.py
index 86200f5ed..f07478246 100644
--- a/pandas/util/counter.py
+++ b/pandas/util/counter.py
@@ -5,8 +5,7 @@ from pandas.util import compat
 import heapq as _heapq
 from itertools import repeat as _repeat, chain as _chain, starmap as _starmap
 from operator import itemgetter as _itemgetter
-import six
-from pandas.util.py3compat import map
+from pandas.util.compat import map
 
 try:
     from collections import Mapping
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index a5f4cc7e1..9711f3600 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -1,6 +1,5 @@
-from pandas.util.py3compat import StringIO
+from pandas.util.compat import StringIO, callable
 from pandas.lib import cache_readonly
-import six
 import sys
 import warnings
 
@@ -164,7 +163,7 @@ def knownfailureif(fail_condition, msg=None):
         msg = 'Test skipped due to known failure'
 
     # Allow for both boolean or callable known failure conditions.
-    if six.callable(fail_condition):
+    if callable(fail_condition):
         fail_val = fail_condition
     else:
         fail_val = lambda: fail_condition
diff --git a/pandas/util/py3compat.py b/pandas/util/py3compat.py
deleted file mode 100644
index 9361bad20..000000000
--- a/pandas/util/py3compat.py
+++ /dev/null
@@ -1,72 +0,0 @@
-import sys
-
-PY3 = (sys.version_info[0] >= 3)
-# import iterator versions of these functions
-from six.moves import zip, filter, reduce, map
-
-try:
-    import __builtin__ as builtins
-    # not writeable when instantiated with string, doesn't handle unicode well
-    from cStringIO import StringIO as StringIO
-    # always writeable
-    from StringIO import StringIO
-    BytesIO = StringIO
-    import cPickle
-except ImportError:
-    import builtins
-    from io import StringIO, BytesIO
-    cStringIO = StringIO
-    import pickle as cPickle
-
-if PY3:
-    def isidentifier(s):
-        return s.isidentifier()
-
-    def str_to_bytes(s, encoding='ascii'):
-        return s.encode(encoding)
-
-    def bytes_to_str(b, encoding='utf-8'):
-        return b.decode(encoding)
-
-    # list-producing versions of the major Python iterating functions
-    def lrange(*args, **kwargs):
-        return list(range(*args, **kwargs))
-
-    def lzip(*args, **kwargs):
-        return list(zip(*args, **kwargs))
-
-    def lmap(*args, **kwargs):
-        return list(map(*args, **kwargs))
-
-    def lfilter(*args, **kwargs):
-        return list(filter(*args, **kwargs))
-
-    # need to put range in the namespace
-    range = range
-    long = int
-    unichr = chr
-else:
-    # Python 2
-    import re
-    _name_re = re.compile(r"[a-zA-Z_][a-zA-Z0-9_]*$")
-
-    def isidentifier(s, dotted=False):
-        return bool(_name_re.match(s))
-
-    def str_to_bytes(s, encoding='ascii'):
-        return s
-
-    def bytes_to_str(b, encoding='ascii'):
-        return b
-
-    # Python 2-builtin ranges produce lists
-    lrange = builtins.range
-    lzip = builtins.zip
-    lmap = builtins.map
-    lfilter = builtins.filter
-
-    # have to explicitly put builtins into the namespace
-    range = xrange
-    long = long
-    unichr = unichr
-
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 6ee3ba3b7..469612698 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -2,8 +2,6 @@ from __future__ import division
 
 # pylint: disable-msg=W0402
 
-from pandas.util.py3compat import range, unichr, lrange, lmap, lzip
-from pandas.util.py3compat import zip
 import random
 import string
 import sys
@@ -14,7 +12,7 @@ import os
 
 from datetime import datetime
 from functools import wraps
-from contextlib import contextmanager, closing
+from contextlib import contextmanager
 from distutils.version import LooseVersion
 
 from numpy.random import randn
@@ -27,14 +25,15 @@ import pandas.core.frame as frame
 import pandas.core.panel as panel
 import pandas.core.panel4d as panel4d
 import pandas.util.compat as compat
+from pandas.util.compat import(
+    map, zip, range, unichr, lrange, lmap, lzip, u, callable, Counter
+)
 
 from pandas import bdate_range
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex
 
 from pandas.io.common import urlopen, HTTPException
-import six
-from pandas.util.py3compat import map
 
 Index = index.Index
 MultiIndex = index.MultiIndex
@@ -54,7 +53,7 @@ def rands(n):
 
 
 def randu(n):
-    choices = six.u("").join(map(unichr, lrange(1488, 1488 + 26)))
+    choices = u("").join(map(unichr, lrange(1488, 1488 + 26)))
     choices += string.digits
     return ''.join([random.choice(choices) for _ in range(n)])
 
@@ -142,7 +141,7 @@ def assert_almost_equal(a, b, check_less_precise = False):
     if isinstance(a, dict) or isinstance(b, dict):
         return assert_dict_equal(a, b)
 
-    if isinstance(a, six.string_types):
+    if isinstance(a, compat.string_types):
         assert a == b, "%s != %s" % (a, b)
         return True
 
@@ -446,7 +445,6 @@ def makeCustomIndex(nentries, nlevels, prefix='#', names=False, ndupe_l=None,
         if unspecified, string labels will be generated.
     """
 
-    from pandas.util.compat import Counter
     if ndupe_l is None:
         ndupe_l = [1] * nlevels
     assert (_is_sequence(ndupe_l) and len(ndupe_l) <= nlevels)
@@ -463,7 +461,7 @@ def makeCustomIndex(nentries, nlevels, prefix='#', names=False, ndupe_l=None,
         names = None
 
     # make singelton case uniform
-    if isinstance(names, six.string_types) and nlevels == 1:
+    if isinstance(names, compat.string_types) and nlevels == 1:
         names = [names]
 
     # specific 1D index type requested?
@@ -694,7 +692,7 @@ def optional_args(decorator):
         def dec(f):
             return decorator(f, *args, **kwargs)
 
-        is_decorating = not kwargs and len(args) == 1 and six.callable(args[0])
+        is_decorating = not kwargs and len(args) == 1 and callable(args[0])
         if is_decorating:
             f = args[0]
             args = []
diff --git a/scripts/bench_join.py b/scripts/bench_join.py
index a3bd4157a..e82d9cee6 100644
--- a/scripts/bench_join.py
+++ b/scripts/bench_join.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range, lrange
+from pandas.util.compat import range, lrange
 import numpy as np
 import pandas.lib as lib
 from pandas import *
diff --git a/scripts/bench_join_multi.py b/scripts/bench_join_multi.py
index 818ac3009..7e67eeb42 100644
--- a/scripts/bench_join_multi.py
+++ b/scripts/bench_join_multi.py
@@ -1,9 +1,8 @@
 from pandas import *
 
 import numpy as np
-from pandas.util.py3compat import zip
+from pandas.util.compat import zip, range, lzip
 from pandas.util.testing import rands
-from pandas.util.py3compat import range, lzip
 import pandas.lib as lib
 
 N = 100000
diff --git a/scripts/bench_refactor.py b/scripts/bench_refactor.py
index 812c42b0e..9ec57633f 100644
--- a/scripts/bench_refactor.py
+++ b/scripts/bench_refactor.py
@@ -1,5 +1,5 @@
 from pandas import *
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 try:
     import pandas.core.internals as internals
     reload(internals)
diff --git a/scripts/find_commits_touching_func.py b/scripts/find_commits_touching_func.py
index a4c76671d..29a9c780c 100755
--- a/scripts/find_commits_touching_func.py
+++ b/scripts/find_commits_touching_func.py
@@ -4,9 +4,7 @@
 # copryright 2013, y-p @ github
 
 from __future__ import print_function
-from pandas.util.py3compat import range, lrange
-import six
-from pandas.util.py3compat import map
+from pandas.util.compat import range, lrange, map
 
 """Search the git history for all commits touching a named method
 
@@ -96,7 +94,7 @@ def get_hits(defname,files=()):
 
 def get_commit_info(c,fmt,sep='\t'):
     r=sh.git('log', "--format={}".format(fmt), '{}^..{}'.format(c,c),"-n","1",_tty_out=False)
-    return six.text_type(r).split(sep)
+    return compat.text_type(r).split(sep)
 
 def get_commit_vitals(c,hlen=HASH_LEN):
     h,s,d= get_commit_info(c,'%H\t%s\t%ci',"\t")
@@ -185,11 +183,11 @@ You must specify the -y argument to ignore this warning.
 !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
 """)
         return
-    if isinstance(args.file_masks,six.string_types):
+    if isinstance(args.file_masks,compat.string_types):
         args.file_masks = args.file_masks.split(',')
-    if isinstance(args.path_masks,six.string_types):
+    if isinstance(args.path_masks,compat.string_types):
         args.path_masks = args.path_masks.split(',')
-    if isinstance(args.dir_masks,six.string_types):
+    if isinstance(args.dir_masks,compat.string_types):
         args.dir_masks = args.dir_masks.split(',')
 
     logger.setLevel(getattr(logging,args.debug_level))
diff --git a/scripts/groupby_sample.py b/scripts/groupby_sample.py
index af422bd4b..a5e7dc60d 100644
--- a/scripts/groupby_sample.py
+++ b/scripts/groupby_sample.py
@@ -1,7 +1,6 @@
 from pandas import *
 import numpy as np
 import string
-import six
 import pandas.util.compat as compat
 
 g1 = np.array(list(string.letters))[:-1]
@@ -45,7 +44,7 @@ def do_shuffle(arr):
 
 def shuffle_uri(df, grouped):
     perm = np.r_[tuple([np.random.permutation(
-        idxs) for idxs in six.itervalues(grouped.groups)])]
+        idxs) for idxs in compat.itervalues(grouped.groups)])]
     df['state_permuted'] = np.asarray(df.ix[perm]['value'])
 
 df2 = df.copy()
diff --git a/scripts/groupby_test.py b/scripts/groupby_test.py
index 6dbf1b073..b6f9152af 100644
--- a/scripts/groupby_test.py
+++ b/scripts/groupby_test.py
@@ -8,7 +8,7 @@ from pandas import *
 import pandas.lib as tseries
 import pandas.core.groupby as gp
 import pandas.util.testing as tm
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 reload(gp)
 
 """
diff --git a/scripts/hdfstore_panel_perf.py b/scripts/hdfstore_panel_perf.py
index 18668d729..d530a02de 100644
--- a/scripts/hdfstore_panel_perf.py
+++ b/scripts/hdfstore_panel_perf.py
@@ -1,6 +1,6 @@
 from pandas import *
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 
 i, j, k = 7, 771, 5532
 
diff --git a/scripts/json_manip.py b/scripts/json_manip.py
index 7bea33055..3ad0edac2 100644
--- a/scripts/json_manip.py
+++ b/scripts/json_manip.py
@@ -67,15 +67,14 @@ Simplifying
 """
 from __future__ import print_function
 
-from collections import Counter, namedtuple
+from collections import namedtuple
 import csv
 import itertools
 from itertools import product
 from operator import attrgetter as aget, itemgetter as iget
 import operator
 import sys
-import six
-from pandas.util.py3compat import map
+from pandas.util.compat import map, u, callable, Counter
 import pandas.util.compat as compat
 
 
@@ -92,77 +91,77 @@ ex1 = {
 }
 
 ## much longer example
-ex2 = {six.u('metadata'): {six.u('accessibilities'): [{six.u('name'): six.u('accessibility.tabfocus'),
-    six.u('value'): 7},
-   {six.u('name'): six.u('accessibility.mouse_focuses_formcontrol'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.browsewithcaret'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.win32.force_disabled'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.typeaheadfind.startlinksonly'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.usebrailledisplay'), six.u('value'): six.u('')},
-   {six.u('name'): six.u('accessibility.typeaheadfind.timeout'), six.u('value'): 5000},
-   {six.u('name'): six.u('accessibility.typeaheadfind.enabletimeout'), six.u('value'): True},
-   {six.u('name'): six.u('accessibility.tabfocus_applies_to_xul'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.typeaheadfind.flashBar'), six.u('value'): 1},
-   {six.u('name'): six.u('accessibility.typeaheadfind.autostart'), six.u('value'): True},
-   {six.u('name'): six.u('accessibility.blockautorefresh'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.browsewithcaret_shortcut.enabled'),
-    six.u('value'): True},
-   {six.u('name'): six.u('accessibility.typeaheadfind.enablesound'), six.u('value'): True},
-   {six.u('name'): six.u('accessibility.typeaheadfind.prefillwithselection'),
-    six.u('value'): True},
-   {six.u('name'): six.u('accessibility.typeaheadfind.soundURL'), six.u('value'): six.u('beep')},
-   {six.u('name'): six.u('accessibility.typeaheadfind'), six.u('value'): False},
-   {six.u('name'): six.u('accessibility.typeaheadfind.casesensitive'), six.u('value'): 0},
-   {six.u('name'): six.u('accessibility.warn_on_browsewithcaret'), six.u('value'): True},
-   {six.u('name'): six.u('accessibility.usetexttospeech'), six.u('value'): six.u('')},
-   {six.u('name'): six.u('accessibility.accesskeycausesactivation'), six.u('value'): True},
-   {six.u('name'): six.u('accessibility.typeaheadfind.linksonly'), six.u('value'): False},
-   {six.u('name'): six.u('isInstantiated'), six.u('value'): True}],
-  six.u('extensions'): [{six.u('id'): six.u('216ee7f7f4a5b8175374cd62150664efe2433a31'),
-    six.u('isEnabled'): True},
-   {six.u('id'): six.u('1aa53d3b720800c43c4ced5740a6e82bb0b3813e'), six.u('isEnabled'): False},
-   {six.u('id'): six.u('01ecfac5a7bd8c9e27b7c5499e71c2d285084b37'), six.u('isEnabled'): True},
-   {six.u('id'): six.u('1c01f5b22371b70b312ace94785f7b0b87c3dfb2'), six.u('isEnabled'): True},
-   {six.u('id'): six.u('fb723781a2385055f7d024788b75e959ad8ea8c3'), six.u('isEnabled'): True}],
-  six.u('fxVersion'): six.u('9.0'),
-  six.u('location'): six.u('zh-CN'),
-  six.u('operatingSystem'): six.u('WINNT Windows NT 5.1'),
-  six.u('surveyAnswers'): six.u(''),
-  six.u('task_guid'): six.u('d69fbd15-2517-45b5-8a17-bb7354122a75'),
-  six.u('tpVersion'): six.u('1.2'),
-  six.u('updateChannel'): six.u('beta')},
- six.u('survey_data'): {
-  six.u('extensions'): [{six.u('appDisabled'): False,
-    six.u('id'): six.u('testpilot?labs.mozilla.com'),
-    six.u('isCompatible'): True,
-    six.u('isEnabled'): True,
-    six.u('isPlatformCompatible'): True,
-    six.u('name'): six.u('Test Pilot')},
-   {six.u('appDisabled'): True,
-    six.u('id'): six.u('dict?www.youdao.com'),
-    six.u('isCompatible'): False,
-    six.u('isEnabled'): False,
-    six.u('isPlatformCompatible'): True,
-    six.u('name'): six.u('Youdao Word Capturer')},
-   {six.u('appDisabled'): False,
-    six.u('id'): six.u('jqs?sun.com'),
-    six.u('isCompatible'): True,
-    six.u('isEnabled'): True,
-    six.u('isPlatformCompatible'): True,
-    six.u('name'): six.u('Java Quick Starter')},
-   {six.u('appDisabled'): False,
-    six.u('id'): six.u('?20a82645-c095-46ed-80e3-08825760534b?'),
-    six.u('isCompatible'): True,
-    six.u('isEnabled'): True,
-    six.u('isPlatformCompatible'): True,
-    six.u('name'): six.u('Microsoft .NET Framework Assistant')},
-   {six.u('appDisabled'): False,
-    six.u('id'): six.u('?a0d7ccb3-214d-498b-b4aa-0e8fda9a7bf7?'),
-    six.u('isCompatible'): True,
-    six.u('isEnabled'): True,
-    six.u('isPlatformCompatible'): True,
-    six.u('name'): six.u('WOT')}],
-  six.u('version_number'): 1}}
+ex2 = {u('metadata'): {u('accessibilities'): [{u('name'): u('accessibility.tabfocus'),
+    u('value'): 7},
+   {u('name'): u('accessibility.mouse_focuses_formcontrol'), u('value'): False},
+   {u('name'): u('accessibility.browsewithcaret'), u('value'): False},
+   {u('name'): u('accessibility.win32.force_disabled'), u('value'): False},
+   {u('name'): u('accessibility.typeaheadfind.startlinksonly'), u('value'): False},
+   {u('name'): u('accessibility.usebrailledisplay'), u('value'): u('')},
+   {u('name'): u('accessibility.typeaheadfind.timeout'), u('value'): 5000},
+   {u('name'): u('accessibility.typeaheadfind.enabletimeout'), u('value'): True},
+   {u('name'): u('accessibility.tabfocus_applies_to_xul'), u('value'): False},
+   {u('name'): u('accessibility.typeaheadfind.flashBar'), u('value'): 1},
+   {u('name'): u('accessibility.typeaheadfind.autostart'), u('value'): True},
+   {u('name'): u('accessibility.blockautorefresh'), u('value'): False},
+   {u('name'): u('accessibility.browsewithcaret_shortcut.enabled'),
+    u('value'): True},
+   {u('name'): u('accessibility.typeaheadfind.enablesound'), u('value'): True},
+   {u('name'): u('accessibility.typeaheadfind.prefillwithselection'),
+    u('value'): True},
+   {u('name'): u('accessibility.typeaheadfind.soundURL'), u('value'): u('beep')},
+   {u('name'): u('accessibility.typeaheadfind'), u('value'): False},
+   {u('name'): u('accessibility.typeaheadfind.casesensitive'), u('value'): 0},
+   {u('name'): u('accessibility.warn_on_browsewithcaret'), u('value'): True},
+   {u('name'): u('accessibility.usetexttospeech'), u('value'): u('')},
+   {u('name'): u('accessibility.accesskeycausesactivation'), u('value'): True},
+   {u('name'): u('accessibility.typeaheadfind.linksonly'), u('value'): False},
+   {u('name'): u('isInstantiated'), u('value'): True}],
+  u('extensions'): [{u('id'): u('216ee7f7f4a5b8175374cd62150664efe2433a31'),
+    u('isEnabled'): True},
+   {u('id'): u('1aa53d3b720800c43c4ced5740a6e82bb0b3813e'), u('isEnabled'): False},
+   {u('id'): u('01ecfac5a7bd8c9e27b7c5499e71c2d285084b37'), u('isEnabled'): True},
+   {u('id'): u('1c01f5b22371b70b312ace94785f7b0b87c3dfb2'), u('isEnabled'): True},
+   {u('id'): u('fb723781a2385055f7d024788b75e959ad8ea8c3'), u('isEnabled'): True}],
+  u('fxVersion'): u('9.0'),
+  u('location'): u('zh-CN'),
+  u('operatingSystem'): u('WINNT Windows NT 5.1'),
+  u('surveyAnswers'): u(''),
+  u('task_guid'): u('d69fbd15-2517-45b5-8a17-bb7354122a75'),
+  u('tpVersion'): u('1.2'),
+  u('updateChannel'): u('beta')},
+ u('survey_data'): {
+  u('extensions'): [{u('appDisabled'): False,
+    u('id'): u('testpilot?labs.mozilla.com'),
+    u('isCompatible'): True,
+    u('isEnabled'): True,
+    u('isPlatformCompatible'): True,
+    u('name'): u('Test Pilot')},
+   {u('appDisabled'): True,
+    u('id'): u('dict?www.youdao.com'),
+    u('isCompatible'): False,
+    u('isEnabled'): False,
+    u('isPlatformCompatible'): True,
+    u('name'): u('Youdao Word Capturer')},
+   {u('appDisabled'): False,
+    u('id'): u('jqs?sun.com'),
+    u('isCompatible'): True,
+    u('isEnabled'): True,
+    u('isPlatformCompatible'): True,
+    u('name'): u('Java Quick Starter')},
+   {u('appDisabled'): False,
+    u('id'): u('?20a82645-c095-46ed-80e3-08825760534b?'),
+    u('isCompatible'): True,
+    u('isEnabled'): True,
+    u('isPlatformCompatible'): True,
+    u('name'): u('Microsoft .NET Framework Assistant')},
+   {u('appDisabled'): False,
+    u('id'): u('?a0d7ccb3-214d-498b-b4aa-0e8fda9a7bf7?'),
+    u('isCompatible'): True,
+    u('isEnabled'): True,
+    u('isPlatformCompatible'): True,
+    u('name'): u('WOT')}],
+  u('version_number'): 1}}
 
 # class SurveyResult(object):
 
@@ -274,7 +273,7 @@ def flatten(*stack):
         except StopIteration:
             stack.pop(0)
             continue
-        if hasattr(x,'next') and six.callable(getattr(x,'next')):
+        if hasattr(x,'next') and callable(getattr(x,'next')):
             stack.insert(0, x)
 
         #if isinstance(x, (GeneratorType,listerator)):
diff --git a/scripts/leak.py b/scripts/leak.py
index 5b81a3dfc..3416213cd 100644
--- a/scripts/leak.py
+++ b/scripts/leak.py
@@ -1,5 +1,5 @@
 from pandas import *
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import numpy as np
 import pandas.util.testing as tm
 import os
diff --git a/scripts/roll_median_leak.py b/scripts/roll_median_leak.py
index 6dbb1a74d..cd3feb60e 100644
--- a/scripts/roll_median_leak.py
+++ b/scripts/roll_median_leak.py
@@ -6,7 +6,7 @@ import os
 
 from vbench.api import Benchmark
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import pandas.lib as lib
 import pandas._sandbox as sbx
 import time
diff --git a/scripts/testmed.py b/scripts/testmed.py
index c90734912..c3724af27 100644
--- a/scripts/testmed.py
+++ b/scripts/testmed.py
@@ -2,7 +2,7 @@
 
 from random import random
 from math import log, ceil
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 from numpy.random import randn
 from pandas.lib.skiplist import rolling_median
 
diff --git a/vb_suite/groupby.py b/vb_suite/groupby.py
index 748b101b1..88aac2498 100644
--- a/vb_suite/groupby.py
+++ b/vb_suite/groupby.py
@@ -1,6 +1,6 @@
 from vbench.api import Benchmark
 from datetime import datetime
-from pandas.util.py3compat import map
+from pandas.util.compat import map
 
 common_setup = """from pandas_vb_common import *
 """
diff --git a/vb_suite/indexing.py b/vb_suite/indexing.py
index 8a56ef8ff..03961821b 100644
--- a/vb_suite/indexing.py
+++ b/vb_suite/indexing.py
@@ -106,7 +106,7 @@ indexing_dataframe_boolean = \
               start_date=datetime(2012, 1, 1))
 
 setup = common_setup + """
-from pandas.util.py3compat import range
+from pandas.util.compat import range
 import pandas.core.expressions as expr
 df  = DataFrame(np.random.randn(50000, 100))
 df2 = DataFrame(np.random.randn(50000, 100))
diff --git a/vb_suite/pandas_vb_common.py b/vb_suite/pandas_vb_common.py
index 8206c3554..77d0e2e27 100644
--- a/vb_suite/pandas_vb_common.py
+++ b/vb_suite/pandas_vb_common.py
@@ -4,7 +4,6 @@ from datetime import timedelta
 from numpy.random import randn
 from numpy.random import randint
 from numpy.random import permutation
-import pandas.util.compat as compat
 import pandas.util.testing as tm
 import random
 import numpy as np
@@ -24,9 +23,3 @@ try:
     from pandas.core.index import MultiIndex
 except ImportError:
     pass
-try:
-    # if no range in py3compat, then don't import zip or map either
-    from pandas.util.py3compat import range
-    from pandas.util.py3compat import zip, map
-except ImportError:
-    pass
diff --git a/vb_suite/parser.py b/vb_suite/parser.py
index caae86afd..1d5f809f1 100644
--- a/vb_suite/parser.py
+++ b/vb_suite/parser.py
@@ -44,7 +44,7 @@ read_csv_comment2 = Benchmark(stmt, setup,
                               start_date=datetime(2011, 11, 1))
 
 setup = common_setup + """
-from pandas.util.py3compat import cStringIO as StringIO
+from pandas.util.compat import cStringIO as StringIO
 import os
 N = 10000
 K = 8
@@ -63,7 +63,7 @@ sdate = datetime(2012, 5, 7)
 read_table_multiple_date = Benchmark(cmd, setup, start_date=sdate)
 
 setup = common_setup + """
-from pandas.util.py3compat import cStringIO as StringIO
+from pandas.util.compat import cStringIO as StringIO
 import os
 N = 10000
 K = 8
diff --git a/vb_suite/source/conf.py b/vb_suite/source/conf.py
index 2b5753a03..ac24d1d03 100644
--- a/vb_suite/source/conf.py
+++ b/vb_suite/source/conf.py
@@ -12,7 +12,8 @@
 
 import sys
 import os
-import six
+
+from pandas/util.compat import u
 
 # If extensions (or modules to document with autodoc) are in another directory,
 # add these directories to sys.path here. If the directory is relative to the
@@ -50,8 +51,8 @@ source_suffix = '.rst'
 master_doc = 'index'
 
 # General information about the project.
-project = six.u('pandas')
-copyright = six.u('2008-2011, the pandas development team')
+project = u('pandas')
+copyright = u('2008-2011, the pandas development team')
 
 # The version info for the project you're documenting, acts as replacement for
 # |version| and |release|, also used in various other places throughout the
@@ -198,8 +199,8 @@ htmlhelp_basename = 'performance'
 # (source start file, target name, title, author, documentclass [howto/manual]).
 latex_documents = [
     ('index', 'performance.tex',
-     six.u('pandas vbench Performance Benchmarks'),
-     six.u('Wes McKinney'), 'manual'),
+     u('pandas vbench Performance Benchmarks'),
+     u('Wes McKinney'), 'manual'),
 ]
 
 # The name of an image file (relative to this directory) to place at the top of
diff --git a/vb_suite/test_perf.py b/vb_suite/test_perf.py
index 5101cf7f9..095eb04ec 100755
--- a/vb_suite/test_perf.py
+++ b/vb_suite/test_perf.py
@@ -27,8 +27,7 @@ everything and calculate a ration for the timing information.
 """
 from __future__ import print_function
 
-from pandas.util.py3compat import range
-from pandas.util.py3compat import map
+from pandas.util.compat import range, lmap
 import shutil
 import os
 import sys
@@ -140,7 +139,7 @@ def get_results_df(db, rev):
     """Takes a git commit hash and returns a Dataframe of benchmark results
     """
     bench = DataFrame(db.get_benchmarks())
-    results = DataFrame(map(list,db.get_rev_results(rev).values()))
+    results = DataFrame(lmap(list,db.get_rev_results(rev).values()))
 
     # Sinch vbench.db._reg_rev_results returns an unlabeled dict,
     # we have to break encapsulation a bit.
