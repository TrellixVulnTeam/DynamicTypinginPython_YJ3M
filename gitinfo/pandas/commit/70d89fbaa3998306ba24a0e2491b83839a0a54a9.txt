commit 70d89fbaa3998306ba24a0e2491b83839a0a54a9
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Jan 13 18:13:24 2010 +0000

    Python 2.4 compatibility and enabling to be used without having SciPy installed
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@115 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/__init__.py b/pandas/__init__.py
index 54c37ee6e..7e1febdf6 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -12,49 +12,3 @@ from pandas.info import __doc__
 from pandas.core.api import *
 from pandas.io.parsers import parseCSV, parseText, parseExcel
 from pandas.stats.api import *
-
-# Same NoseWrapper used in scikits.statsmodels
-
-from numpy.testing import Tester
-class NoseWrapper(Tester):
-    '''
-    This is simply a monkey patch for numpy.testing.Tester, so
-    that extra_argv can be changed from its default None to ['--exe']
-    so that the tests can be run the same across platforms.
-    '''
-    def test(self, label='fast', verbose=1, extra_argv=['--exe'], doctests=False,
-             coverage=False):
-        ''' Run tests for module using nose
-
-        %(test_header)s
-        doctests : boolean
-            If True, run doctests in module, default False
-        coverage : boolean
-            If True, report coverage of NumPy code, default False
-            (Requires the coverage module:
-             http://nedbatchelder.com/code/modules/coverage.html)
-        '''
-
-        # cap verbosity at 3 because nose becomes *very* verbose beyond that
-        verbose = min(verbose, 3)
-
-        from numpy.testing import utils
-        utils.verbose = verbose
-
-        if doctests:
-            print "Running unit tests and doctests for %s" % self.package_name
-        else:
-            print "Running unit tests for %s" % self.package_name
-
-        self._show_system_info()
-
-        # reset doctest state on every run
-        import doctest
-        doctest.master = None
-
-        argv, plugins = self.prepare_test_args(label, verbose, extra_argv,
-                                               doctests, coverage)
-        from numpy.testing.noseclasses import NumpyTestProgram
-        t = NumpyTestProgram(argv=argv, exit=False, plugins=plugins)
-        return t.result
-test = NoseWrapper().test
diff --git a/pandas/core/api.py b/pandas/core/api.py
index c55204ec4..0ea51b803 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -2,14 +2,14 @@
 
 import numpy as np
 
-from pandas.core.daterange import DateRange
 from pandas.core.datetools import DateOffset
-from pandas.core.frame import DataFrame
+import pandas.core.datetools as datetools
+
 from pandas.core.index import Index
+from pandas.core.daterange import DateRange
+from pandas.core.series import Series, TimeSeries
+from pandas.core.frame import DataFrame
 from pandas.core.matrix import DataMatrix
 from pandas.core.panel import WidePanel, LongPanel, pivot
-from pandas.core.series import Series, TimeSeries
-
-import pandas.core.datetools as datetools
 
 from pandas.lib.tseries import isnull, notnull
diff --git a/pandas/core/collection.py b/pandas/core/collection.py
index e200e718f..13dfc3376 100644
--- a/pandas/core/collection.py
+++ b/pandas/core/collection.py
@@ -1,5 +1,3 @@
-from __future__ import with_statement
-
 from collections import defaultdict
 from pandas.core.mixins import Picklable
 from pandas.core.index import Index
@@ -12,7 +10,7 @@ __all__ = ['PickleContainer']
 class PickleContainer(Picklable):
     """
     Store collection of objects on disk with this dict-like object.
-    
+
     Parameters
     ----------
     dirPath: string
@@ -24,9 +22,9 @@ class PickleContainer(Picklable):
         self.dirPath = dirPath
         if not os.path.exists(dirPath):
             os.mkdir(dirPath)
-    
+
         self._lruSize = lruSize
-        
+
         self._paths = {}
         self._classes = {}
         self._lru = {}
@@ -36,48 +34,54 @@ class PickleContainer(Picklable):
         keys, values = zip(*self._classes.iteritems())
         output += adjoin(5, map(str, keys), map(str, values))
         return output
-    
+
     def __setitem__(self, key, value):
         theKey = rands(10)
         filePath = self.dirPath + '/' + theKey
 
         self._paths[key] = filePath
-        
+
         if isinstance(value, Picklable):
             value.save(filePath)
         else:
-            with open(filePath, 'w') as f:
+            f = open(filePath, 'w')
+            try:
                 cPickle.dump(value, f)
+            finally:
+                f.close()
 
         self._paths[key] = filePath
         self._classes[key] = value.__class__
-        
+
     def __getitem__(self, key):
         if key not in self._paths:
             raise Exception('Requested key not in this container!')
-        
+
         thePath = self._paths[key]
         theClass = self._classes[key]
-        
+
         if issubclass(theClass, Picklable):
             obj = theClass.load(thePath)
         else:
-            with open(thePath, 'rb') as f:
+            f = open(thePath, 'rb')
+            try:
                 obj = cPickle.load(f)
-        
+            finally:
+                f.close()
+
         return obj
 
     def __delitem__(self, key):
         del self._paths[key]
         del self._classes[key]
-    
+
     def __iter__(self):
         return iter(self._paths)
-    
+
     def iteritems(self):
         for key, path in self._paths.iteritems():
             yield key, self[key]
-    
+
     def keys(self):
         return self._paths.keys()
 
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 3e7577a4a..0b6a5e9a0 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -22,9 +22,14 @@ def _pfixed(s, space, nanRep=None, float_format=None):
         if nanRep is not None and isnull(s):
             return nanRep.ljust(space)
 
-        formatted = float_format(s) if float_format else '%.4g' % s
+        if float_format:
+            formatted = float_format(s)
+        else:
+            formatted = '%.4g' % s
 
         return formatted.ljust(space)
     else:
         return str(s)[:space-4].ljust(space)
 
+#-------------------------------------------------------------------------------
+# Functions needed from scipy
diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index 0edd24233..db94f3fa8 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -3,6 +3,7 @@
 from datetime import datetime, timedelta
 from dateutil import parser
 from dateutil.relativedelta import relativedelta
+
 import calendar
 
 #-------------------------------------------------------------------------------
@@ -23,14 +24,14 @@ def ole2datetime(oledt):
         raise Exception("Value is outside of acceptable range: %s " % val)
     return OLE_TIME_ZERO + timedelta(days=val)
 
-def to_datetime(input):
-    """Attempts to convert input to datetime"""
-    if input is None or isinstance(input, datetime):
-        return input
+def to_datetime(arg):
+    """Attempts to convert arg to datetime"""
+    if arg is None or isinstance(arg, datetime):
+        return arg
     try:
-        return parser.parse(input)
+        return parser.parse(arg)
     except Exception:
-        return input
+        return arg
 
 def normalize_date(dt):
     return datetime(dt.year, dt.month, dt.day)
@@ -122,7 +123,13 @@ class DateOffset(object):
                 continue
             if attr not in exclude:
                 attrs.append('='.join((attr, repr(getattr(self, attr)))))
-        out = '<%s ' % self.n + className + ('s' if abs(self.n) != 1 else '')
+
+        if abs(self.n) != 1:
+            plural = 's'
+        else:
+            plural = ''
+
+        out = '<%s ' % self.n + className + plural
         if attrs:
             out += ': ' + ', '.join(attrs)
         out += '>'
@@ -208,7 +215,12 @@ class BDay(DateOffset):
         if self.offset:
             attrs = ['offset=%s' % self.offset]
 
-        out = '<%s ' % self.n + className + ('s' if abs(self.n) != 1 else '')
+        if abs(self.n) != 1:
+            plural = 's'
+        else:
+            plural = ''
+
+        out = '<%s ' % self.n + className + plural
         if attrs:
             out += ': ' + ', '.join(attrs)
         out += '>'
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 31eb4212a..7e708de58 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -64,6 +64,7 @@ class DataFrame(Picklable, Groupable):
         >>> d = {'col1' : ts1, 'col2' : ts2}
         >>> df = DataFrame(data=d, index=someIndex)
     """
+
     def __init__(self, data=None, index=None, columns=None):
         self._series = {}
         if data is not None and len(data) > 0:
@@ -517,7 +518,8 @@ class DataFrame(Picklable, Groupable):
         """
         f = open(path, 'w')
 
-        cols = self.cols() if cols is None else cols
+        if cols is None:
+            cols = self.cols()
 
         if header:
             if index:
@@ -868,7 +870,10 @@ class DataFrame(Picklable, Groupable):
             after = self.index[-1]
         elif after not in self.index:
             loc = self.index.searchsorted(after, side='right') - 1
-            loc = loc if loc < len(self.index) else -1
+
+            if loc >= len(self.index):
+                loc = -1
+
             after = self.index[loc]
 
         beg_slice = self.index.indexMap[before]
@@ -934,7 +939,10 @@ class DataFrame(Picklable, Groupable):
         -------
         y : same type as calling instance
         """
-        fillMethod = fillMethod.upper() if fillMethod else ''
+        if fillMethod:
+            fillMethod = fillMethod.upper()
+        else:
+            fillMethod = ''
 
         if fillMethod not in ['BACKFILL', 'PAD', '']:
             raise Exception("Don't recognize fillMethod: %s" % fillMethod)
@@ -1152,17 +1160,15 @@ class DataFrame(Picklable, Groupable):
         TODO
         """
         import re
-
         if items is not None:
-            data = dict([(r, self[r]) for r in items if r in self])
-            return DataFrame(data=data, index=self.index)
+            columns = [r for r in items if r in self]
         elif like:
             columns = [c for c in self.cols() if like in c]
-            return self.reindex(columns=columns)
         elif regex:
             matcher = re.compile(regex)
             columns = [c for c in self.cols() if matcher.match(c)]
-            return self.reindex(columns=columns)
+
+        return self.reindex(columns=columns)
 
     def filterItems(self, items):
         """
@@ -1277,7 +1283,7 @@ class DataFrame(Picklable, Groupable):
             elif col in other:
                 result[col] = other[col]
 
-        return type(self)(result, index=unionIndex)
+        return DataFrame(result, index=unionIndex)
 
     def combineFirst(self, other):
         """
@@ -1403,7 +1409,7 @@ class DataFrame(Picklable, Groupable):
         # Check for column overlap
         overlap = set(self.cols()) & set(other.cols())
 
-        if any(overlap):
+        if overlap:
             raise Exception('Columns overlap: %s' % sorted(overlap))
 
         fillVec, mask = tseries.getMergeVec(self[on], other.index.indexMap)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index f48f90a09..84e860a69 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1,6 +1,5 @@
 import numpy as np
 
-from collections import defaultdict
 from cStringIO import StringIO
 
 from pandas.core.frame import DataFrame
@@ -16,12 +15,12 @@ def groupby_withnull(index, mapper):
     if issubclass(mapped_index.dtype.type, basestring):
         mapped_index = mapped_index.astype(object)
 
-    result = GroupDict(list)
+    result = GroupDict()
 
     mask = isnull(mapped_index)
     nullkeys = index[mask]
 
-    if any(nullkeys):
+    if nullkeys:
         result[np.NaN] = nullkeys
 
     notmask = -mask
@@ -29,11 +28,11 @@ def groupby_withnull(index, mapper):
     mapped_index = mapped_index[notmask]
 
     for idx, key in zip(index, mapped_index):
-        result[key].append(idx)
+        result.setdefault(key, []).append(idx)
 
     return result
 
-class GroupDict(defaultdict):
+class GroupDict(dict):
     def __repr__(self):
         stringDict = dict((str(x), x) for x in self)
         sortedKeys = sorted(stringDict)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 768263b48..aee619b80 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -26,7 +26,6 @@ class Index(np.ndarray):
     Note that the Index can ONLY contain immutable objects. Mutable objects are not
     hashable, and that's bad!
     """
-    __md5 = None
     def __new__(cls, data, dtype=object, copy=False):
         subarr = np.array(data, dtype=dtype, copy=copy)
 
@@ -99,9 +98,6 @@ class Index(np.ndarray):
     def equals(self, other):
         """
         Determines if two Index objects contain the same elements.
-
-        If the compared object is of the right type and length, the MD5
-        checksum is compared
         """
         if self is other:
             return True
@@ -111,21 +107,6 @@ class Index(np.ndarray):
 
         return np.array_equal(self, other)
 
-    def _computeMD5(self):
-        import hashlib
-        return hashlib.md5(self.data).hexdigest()
-
-    @property
-    def _md5(self):
-        """
-        Return MD5 hex-digested hash for the Index elements. Note that
-        this quantity is only computed once.
-        """
-        if self.__md5 is None:
-            self.__md5 = self._computeMD5()
-
-        return self.__md5
-
     def asOfDate(self, date):
         if date not in self.indexMap:
             loc = self.searchsorted(date, side='left')
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 25571f1e4..1d882cd08 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -178,7 +178,11 @@ class DataMatrix(DataFrame):
 
     def _matrix_state(self, pickle_index=True):
         columns = _pickle_array(self.columns)
-        index = _pickle_array(self.index) if pickle_index else None
+
+        if pickle_index:
+            index = _pickle_array(self.index)
+        else:
+            index = None
 
         return self.values, index, columns
 
@@ -723,6 +727,65 @@ class DataMatrix(DataFrame):
 
         return self.index[selector][0]
 
+    # XXX
+
+    def combine(self, other, func, fill_value=None):
+        """
+        Add two DataFrame / DataMatrix objects and do not propagate NaN values,
+        so if for a (column, time) one frame is missing a value, it will
+        default to the other frame's value (which might be NaN as well)
+
+        Parameters
+        ----------
+        other : DataFrame / Matrix
+
+        Returns
+        -------
+        DataFrame
+        """
+        if not other:
+            return self
+
+        if not self:
+            return other
+
+        if self.index is not other.index:
+            unionIndex = self.index + other.index
+            frame = self.reindex(unionIndex)
+            other = other.reindex(unionIndex)
+        else:
+            unionIndex = self.index
+            frame = self
+
+        do_fill = fill_value is not None
+        unionCols = sorted(set(frame.cols() + other.cols()))
+
+        result = {}
+        for col in unionCols:
+            if col in frame and col in other:
+                series = frame[col].values()
+                otherSeries = other[col].values()
+
+                if do_fill:
+                    this_mask = isnull(series)
+                    other_mask = isnull(otherSeries)
+                    series = series.copy()
+                    otherSeries = otherSeries.copy()
+                    series[this_mask] = fill_value
+                    otherSeries[other_mask] = fill_value
+
+                result[col] = func(series, otherSeries)
+
+                if do_fill:
+                    result[col][this_mask & other_mask] = np.NaN
+
+            elif col in frame:
+                result[col] = frame[col]
+            elif col in other:
+                result[col] = other[col]
+
+        return DataMatrix(result, index=unionIndex)
+
     def _combineFrame(self, other, func):
         """
         Methodology, briefly
@@ -1383,7 +1446,7 @@ class DataMatrix(DataFrame):
 
         for frame in frames:
             cols = set(frame.columns)
-            if any(unionCols & cols):
+            if unionCols & cols:
                 raise Exception('Overlapping columns!')
             unionCols |= cols
 
diff --git a/pandas/core/mixins.py b/pandas/core/mixins.py
index e3e978afc..208723681 100644
--- a/pandas/core/mixins.py
+++ b/pandas/core/mixins.py
@@ -1,5 +1,3 @@
-from __future__ import with_statement
-
 import cPickle
 
 #-------------------------------------------------------------------------------
@@ -7,15 +5,19 @@ import cPickle
 
 class Picklable(object):
     def save(self, fileName):
-        with open(fileName, 'wb') as f:
+        f = open(fileName, 'wb')
+        try:
             cPickle.dump(self, f, protocol=cPickle.HIGHEST_PROTOCOL)
+        finally:
+            f.close()
 
     @classmethod
     def load(cls, fileName):
-        with open(fileName, 'rb') as f:
-            obj = cPickle.load(f)
-            return obj
-        raise Exception("Error trying to unpickle %s" % fileName)
+        f = open(fileName, 'rb')
+        try:
+            return cPickle.load(f)
+        finally:
+            f.close()
 
 #-------------------------------------------------------------------------------
 # Groupable mixin
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index d53a3c221..bee753e09 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -7,7 +7,6 @@ Contains data structures designed for manipulating panel (3-dimensional) data
 # pylint: disable-msg=W0621
 
 from cStringIO import StringIO
-from functools import partial
 import operator
 import sys
 
@@ -264,8 +263,8 @@ class WidePanel(Panel):
         else:
             new_items = Index(np.concatenate((self.items[:loc],
                                               self.items[loc + 1:])))
-            new_values = np.row_stack(self.values[:loc],
-                                      self.values[loc + 1:])
+            new_values = np.row_stack((self.values[:loc],
+                                      self.values[loc + 1:]))
 
         self.items = new_items
         self.values = new_values
@@ -1105,7 +1104,10 @@ class LongPanel(Panel):
         elif isinstance(data, DataFrame):
             data = data._series.copy()
 
-        exclude = set(exclude) if exclude is not None else set()
+        if exclude is None:
+            exclude = set()
+        else:
+            exclude = set(exclude)
 
         if major_field in data:
             major_vec = data.pop(major_field)
@@ -1606,10 +1608,12 @@ class LongPanel(Panel):
         return panel
 
     def mean(self, axis='major', broadcast=False):
-        return self.applyToAxis(partial(np.mean, axis=0), axis, broadcast)
+        return self.applyToAxis(lambda x: np.mean(x, axis=0),
+                                axis, broadcast)
 
     def sum(self, axis='major', broadcast=False):
-        return self.applyToAxis(partial(np.sum, axis=0), axis, broadcast)
+        return self.applyToAxis(lambda x: np.sum(x, axis=0),
+                                axis, broadcast)
 
     def apply(self, f):
         return LongPanel(f(self.values), self.items, self.index)
@@ -1710,7 +1714,11 @@ def _makeItemName(item, prefix=None):
     if prefix is None:
         return item
 
-    template = '%g%s' if isinstance(item, float) else '%s%s'
+    if isinstance(item, float):
+        template = '%g%s'
+    else:
+        template = '%s%s'
+
     return template % (prefix, item)
 
 def _homogenize(frames, intersect=True):
diff --git a/pandas/core/pytools.py b/pandas/core/pytools.py
index 3d14fe60a..9b7e1d86d 100644
--- a/pandas/core/pytools.py
+++ b/pandas/core/pytools.py
@@ -1,9 +1,6 @@
 """A collection of tools for various purely Python operations"""
 from random import Random
-import base64
-import functools
 import itertools
-import os
 import string
 
 # In theory should be few to no imports outside perhaps stdlib here
diff --git a/pandas/core/series.py b/pandas/core/series.py
index b9679ac46..6abc92873 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -429,30 +429,24 @@ class Series(np.ndarray, Picklable, Groupable):
             return NaN
         return ndarray.var(nona, axis, dtype, out, ddof)
 
-    def skew(self, bias=False):
+    def skew(self):
         """
         Computes the skewness of the non-null values
 
-        Parameters
-        ----------
-        bias : bool
-            If False, then the calculations are corrected for
-            statistical bias.
+        Returns
+        -------
+        float
         """
+        y = np.array(self.values())
+        mask = notnull(y)
+        count = mask.sum()
+        y[-mask] = 0
 
-        from scipy.stats import skew
-        nona = remove_na(self.values())
-
-        if len(nona) < 3:
-            return NaN
+        A = y.sum() / count
+        B = (y**2).sum() / count  - A**2
+        C = (y**3).sum() / count - A**3 - 3*A*B
 
-        theSkew = skew(nona, bias=bias)
-
-        # Hack for SciPy < 0.8
-        if isinstance(theSkew, ndarray):
-            theSkew = theSkew.item()
-
-        return theSkew
+        return (np.sqrt((count**2-count))*C) / ((count-2)*np.sqrt(B)**3)
 
     def keys(self):
         """
@@ -716,7 +710,11 @@ class Series(np.ndarray, Picklable, Groupable):
         elif kind == 'bar':
             xinds = np.arange(N) + 0.25
             plt.bar(xinds, self.values(), 0.5, bottom=np.zeros(N), linewidth=1)
-            fontsize = 12 if N < 10 else 10
+
+            if N < 10:
+                fontsize = 12
+            else:
+                fontsize = 10
 
             plt.xticks(xinds + 0.25, self.index, rotation=rot,
                        fontsize=fontsize)
@@ -852,7 +850,10 @@ class Series(np.ndarray, Picklable, Groupable):
             after = self.index[-1]
         elif after not in self.index:
             loc = self.index.searchsorted(after, side='right') - 1
-            loc = loc if loc < len(self.index) else -1
+
+            if loc >= len(self.index):
+                loc = -1
+
             after = self.index[loc]
 
         beg_slice = self.index.indexMap[before]
@@ -883,8 +884,8 @@ class Series(np.ndarray, Picklable, Groupable):
             candidates = self.index[notnull(self)]
             candidates = candidates[candidates <= date]
 
-            if any(candidates):
-                asOfDate = max(candidates)
+            if candidates.any():
+                asOfDate = candidates[-1]
             else:
                 return NaN
 
diff --git a/pandas/core/setup.py b/pandas/core/setup.py
new file mode 100644
index 000000000..93e174cc1
--- /dev/null
+++ b/pandas/core/setup.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+
+def configuration(parent_package='',top_path=None):
+    from numpy.distutils.misc_util import Configuration
+    config = Configuration('core', parent_package, top_path)
+    config.add_subpackage('tests')
+    return config
+
+if __name__ == '__main__':
+    print('This is the wrong setup.py file to run')
+
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index c496cae6f..0cdff0de0 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -1,5 +1,4 @@
 # pylint: disable-msg=W0612
-
 from copy import deepcopy
 from cStringIO import StringIO
 import os
@@ -996,7 +995,11 @@ class TestDataFrame(unittest.TestCase):
         self._check_statistic(self.frame, 'std', f)
 
     def test_skew(self):
-        from scipy.stats import skew
+        try:
+            from scipy.stats import skew
+        except ImportError:
+            return
+
         def f(x):
             x = np.asarray(x)
             return skew(x[notnull(x)], bias=False)
diff --git a/pandas/core/tests/test_index.py b/pandas/core/tests/test_index.py
index b3d9f294d..e1f84cad2 100644
--- a/pandas/core/tests/test_index.py
+++ b/pandas/core/tests/test_index.py
@@ -1,4 +1,4 @@
-from datetime import datetime, timedelta
+from datetime import timedelta
 from pandas.core.index import Index
 import pandas.core.tests.common as common
 import pandas.lib.tseries as tseries
@@ -56,11 +56,6 @@ class TestIndex(unittest.TestCase):
         # Must also be an Index
         self.assertFalse(Index(['a', 'b', 'c']).equals(['a', 'b', 'c']))
 
-    def test_md5(self):
-        self.strIndex._md5
-        self.dateIndex._md5
-        self.intIndex._md5
-
     def test_asOfDate(self):
         d = self.dateIndex[0]
         self.assert_(self.dateIndex.asOfDate(d) is d)
diff --git a/pandas/core/tests/test_panel.py b/pandas/core/tests/test_panel.py
index faaf021f8..10c938e80 100644
--- a/pandas/core/tests/test_panel.py
+++ b/pandas/core/tests/test_panel.py
@@ -133,8 +133,11 @@ class PanelTests(object):
         self._check_statistic(self.panel, 'std', f)
 
     def test_skew(self):
-        return
-        from scipy.stats import skew
+        try:
+            from scipy.stats import skew
+        except ImportError:
+            return
+
         def f(x):
             x = np.asarray(x)
             return skew(x[notnull(x)], bias=False)
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index a3f5bbcfd..ff224c673 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -205,8 +205,6 @@ class TestSeries(unittest.TestCase):
             self.assertEqual(val, self.ts[idx])
 
     def test_stats(self):
-        from scipy.stats import skew
-
         self.series[5:15] = np.NaN
 
         s1 = np.array(self.series)
@@ -218,7 +216,12 @@ class TestSeries(unittest.TestCase):
         self.assertEquals(np.mean(s1), self.series.mean())
         self.assertEquals(np.std(s1, ddof=1), self.series.std())
         self.assertEquals(np.var(s1, ddof=1), self.series.var())
-        self.assertEquals(skew(s1, bias=False), self.series.skew())
+
+        try:
+            from scipy.stats import skew
+            self.assertEquals(skew(s1, bias=False), self.series.skew())
+        except ImportError:
+            pass
 
         self.assert_(not np.isnan(np.sum(self.series)))
         self.assert_(not np.isnan(np.mean(self.series)))
diff --git a/pandas/core/tests/test_tseries.py b/pandas/core/tests/test_tseries.py
index 05fa4666d..d95a92cb0 100644
--- a/pandas/core/tests/test_tseries.py
+++ b/pandas/core/tests/test_tseries.py
@@ -1,8 +1,8 @@
+import unittest
+
 import pandas.core.tests.common as common
 import pandas.lib.tseries as tseries
 
-import unittest
-
 class TestUtil(unittest.TestCase):
 
     def test_map_indices(self):
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index fde3c8d5f..78cd584d3 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -9,18 +9,6 @@ from pandas.core.series import Series
 
 from datetime import datetime, timedelta
 
-try:
-    from dateutil import parser
-except ImportError:
-    # just a little hack for now
-    class parser(object):
-        @classmethod
-        def parse(cls, val):
-            try:
-                return datetime.strptime(val, '%m/%d/%Y')
-            except:
-                return val
-
 from itertools import izip
 import numpy as np
 import string
@@ -36,9 +24,13 @@ def simpleParser(nestedList, forceFloat=True, colNames=None,
     lines = nestedList
     data = {}
     if header is not None:
-        columns = lines[header]
-        columns = [c if c != '' else 'Unnamed: ' + string.ascii_uppercase[i]
-                   for i, c in enumerate(columns)]
+        columns = []
+        for i, c in enumerate(lines[header]):
+            if c == '':
+                columns.append('Unnamed: ' + string.ascii_uppercase[i])
+            else:
+                columns.append(c)
+
         content = lines[header+1:]
 
         colCounts = dict(((col, 0) for col in columns))
diff --git a/pandas/lib/setup.py b/pandas/lib/setup.py
new file mode 100644
index 000000000..503dcb753
--- /dev/null
+++ b/pandas/lib/setup.py
@@ -0,0 +1,36 @@
+#!/usr/bin/env python
+
+from distutils.core import Extension
+import numpy
+
+def get_cython_ext():
+    from Cython.Distutils import build_ext
+
+    pyx_ext = Extension('tseries', ['pandas/lib/src/tseries.pyx',
+                                    'pandas/lib/src/wirth.c'],
+                        include_dirs=[numpy.get_include(),
+                                      'pandas/lib/include/'])
+
+
+    setup(name='pandas.lib.tseries', description='Nothing',
+          ext_modules=[pyx_ext],
+          cmdclass = {
+              'build_ext' : build_ext
+          })
+
+def configuration(parent_package='', top_path=None):
+    from numpy.distutils.misc_util import Configuration
+
+    config = Configuration('lib', parent_package, top_path)
+    config.set_options(assume_default_configuration=True,
+                       quiet=True)
+
+    config.add_extension('tseries',
+                         sources=['src/tseries.c',
+                                  'src/wirth.c'],
+                         include_dirs=[numpy.get_include(),
+                                       'include/'])
+    config.add_extension('tdates',
+                         sources=['src/tdates.c'])
+
+    return config
diff --git a/pandas/setup.py b/pandas/setup.py
new file mode 100644
index 000000000..1d2716db3
--- /dev/null
+++ b/pandas/setup.py
@@ -0,0 +1,15 @@
+#!/usr/bin/env python
+
+def configuration(parent_package='',top_path=None):
+    from numpy.distutils.misc_util import Configuration
+    config = Configuration('pandas', parent_package, top_path)
+    config.add_subpackage('core')
+    config.add_subpackage('stats')
+    config.add_subpackage('io')
+    config.add_subpackage('util')
+    config.add_subpackage('lib')
+    return config
+
+if __name__ == '__main__':
+    print('This is the wrong setup.py file to run')
+
diff --git a/pandas/stats/api.py b/pandas/stats/api.py
index e440d2e77..81db968db 100644
--- a/pandas/stats/api.py
+++ b/pandas/stats/api.py
@@ -4,6 +4,18 @@ Common namespace of statistical functions
 
 # pylint: disable-msg=W0611,W0614
 
-from pandas.stats.interface import ols
-from pandas.stats.fama_macbeth import fama_macbeth
 from pandas.stats.moments import *
+
+try:
+    import scipy.stats as _stats
+
+    from pandas.stats.interface import ols
+    from pandas.stats.fama_macbeth import fama_macbeth
+
+    del _stats
+except ImportError:
+    def ols(*args, **kwargs):
+        """
+        Stub to give error message for missing SciPy
+        """
+        raise Exception('Must install SciPy to use OLS functionality')
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 176ee0044..c008f4f20 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -79,7 +79,8 @@ def _rollingMoment(arg, window, func, minp=None, timeRule=None):
     minp : int
         Minimum number of observations required to have a value
     """
-    minp = minp if minp is not None else window
+    if minp is None:
+        minp = window
 
     types = (DataFrame, DataMatrix, TimeSeries)
     if timeRule is not None and isinstance(arg, types):
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index ecd4012c9..8313a8d9f 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -510,7 +510,10 @@ class MovingOLS(OLS):
         self._window = int(window)
         self._window_type = common._get_window_type(window_type)
 
-        self._min_periods = window if min_periods is None else min_periods
+        if min_periods is None:
+            min_periods = window
+
+        self._min_periods = min_periods
 
 #-------------------------------------------------------------------------------
 # "Public" results
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 3ac08e680..88f707c43 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -163,11 +163,19 @@ class PanelOLS(OLS):
         data_long = data.toLong()
 
         x_filt = filtered.filterItems(x_names)
-        weights_filt = filtered['__weights__'] if self._weights else None
+
+        if self._weights:
+            weights_filt = filtered['__weights__']
+        else:
+            weights_filt = None
 
         x = data_long.filterItems(x_names)
         y = data_long['__y__']
-        weights = data_long['__weights__'] if self._weights else None
+
+        if self._weights:
+            weights = data_long['__weights__']
+        else:
+            weights = None
 
         return x, x_filt, y, weights, weights_filt, cat_mapping
 
@@ -269,8 +277,10 @@ class PanelOLS(OLS):
 
             if dropped_dummy or not self._use_all_dummies:
                 if effect in self._dropped_dummies:
-                    to_exclude = self._dropped_dummies.get(effect)
-                    mapped_name = val_map[to_exclude] if val_map else to_exclude
+                    to_exclude = mapped_name = self._dropped_dummies.get(effect)
+
+                    if val_map:
+                        mapped_name = val_map[to_exclude]
                 else:
                     to_exclude = mapped_name = dummies.items[0]
 
@@ -493,7 +503,11 @@ def _convertDummies(dummies, mapping):
     new_items = []
     for item in dummies.items:
         if not mapping:
-            var = '%g' % item if isinstance(item, float) else '%s' % item
+            if isinstance(item, float):
+                var = '%g' % item
+            else:
+                var = '%s' % item
+
             new_items.append(var)
         else:
             # renames the dummies if a conversion dict is provided
@@ -591,7 +605,11 @@ class MovingPanelOLS(MovingOLS, PanelOLS):
 
         self._window_type = common._get_window_type(window_type)
         self._window = window
-        self._min_periods = window if min_periods is None else min_periods
+
+        if min_periods is None:
+            min_periods = window
+
+        self._min_periods = min_periods
 
     @cache_readonly
     def resid(self):
diff --git a/pandas/stats/setup.py b/pandas/stats/setup.py
new file mode 100644
index 000000000..5d2f765ed
--- /dev/null
+++ b/pandas/stats/setup.py
@@ -0,0 +1,11 @@
+#!/usr/bin/env python
+
+def configuration(parent_package='',top_path=None):
+    from numpy.distutils.misc_util import Configuration
+    config = Configuration('stats', parent_package, top_path)
+    config.add_subpackage('tests')
+    return config
+
+if __name__ == '__main__':
+    print('This is the wrong setup.py file to run')
+
diff --git a/setup.py b/setup.py
index 35a3e54b3..e91fbe7f4 100644
--- a/setup.py
+++ b/setup.py
@@ -1,11 +1,7 @@
 #/usr/bin/env python
 
-from distutils.core import Extension
-
 from numpy.distutils.misc_util import Configuration
-import setuptools
 from numpy.distutils.core import setup
-import numpy
 
 DESCRIPTION = "Cross-section and time series data analysis toolkit"
 LONG_DESCRIPTION = """
@@ -50,55 +46,25 @@ MINOR = 1
 def get_version():
     return '%d.%d' % (MAJOR, MINOR)
 
-def get_cython_ext():
-    from Cython.Distutils import build_ext
-
-    pyx_ext = Extension('tseries', ['pandas/lib/src/tseries.pyx',
-                                    'pandas/lib/src/wirth.c'],
-                        include_dirs=[numpy.get_include(),
-                                      'pandas/lib/include/'])
-
 
-    setup(name='pandas.lib.tseries', description='Nothing',
-          ext_modules=[pyx_ext],
-          cmdclass = {
-              'build_ext' : build_ext
-          })
-
-def configuration(parent_package='', top_path=None, package_name=DISTNAME):
+def configuration(parent_package='', top_path=None):
     config = Configuration(None, parent_package, top_path,
-                           name=DISTNAME,
-                           version=get_version(),
-                           maintainer=MAINTAINER,
-                           maintainer_email=MAINTAINER_EMAIL,
-                           description=DESCRIPTION,
-                           license=LICENSE,
-                           url=URL,
-                           download_url=DOWNLOAD_URL,
-                           long_description=LONG_DESCRIPTION)
-
-    config.add_extension('lib.tseries',
-                         sources=['pandas/lib/src/tseries.c',
-                                  'pandas/lib/src/wirth.c'],
-                         include_dirs=[numpy.get_include(),
-                                       'pandas/lib/include/'])
-    config.add_extension('lib.tdates',
-                         sources=['pandas/lib/src/tdates.c'])
-
-    config.set_options(
-            ignore_setup_xxx_py=True,
-            assume_default_configuration=True,
-            delegate_options_to_subpackages=True,
-            quiet=False,
-            )
+                           version=get_version())
+    config.set_options(assume_default_configuration=True,
+                       quiet=True)
 
+    config.add_subpackage('pandas')
     return config
 
 if __name__ == '__main__':
-    setup(configuration=configuration,
-          packages=setuptools.find_packages(),
+    setup(name=DISTNAME,
+          maintainer=MAINTAINER,
+          maintainer_email=MAINTAINER_EMAIL,
+          description=DESCRIPTION,
+          license=LICENSE,
+          url=URL,
+          download_url=DOWNLOAD_URL,
+          long_description=LONG_DESCRIPTION,
           classifiers=CLASSIFIERS,
-          requires=['numpy'],
           platforms='any',
-          test_suite='nose.collector',
-          zip_safe=False)
+          configuration=configuration)
