commit ae17462d54e54f76e756831ead918edd525bda9c
Author: jreback <jeff@reback.net>
Date:   Tue Dec 11 16:24:20 2012 -0500

    ENH: ndim tables in HDFStore
         changes axes_to_index keyword in table creation to axes
         allow passing of numeric or named axes (e.g. 0 or 'minor_axis') in axes
         create_axes now checks for current table scheme; raises if this indexing scheme is violated
         added many p4d tests for appending/selection/partial selection/and axis permuation
         added addition Term tests to include p4d
         add __eq__ operators to IndexCol/DataCol/Table to comparisons
         updated docs with Panel4D saving & issues relating to threading
         supporting non-regular indexables:
           e.g. can index a Panel4D on say [labels,major_axis,minor_axis], rather
                than the default of [items,major_axis,minor_axis]
         support column oriented DataFrames (e.g. queryable by the columns)

diff --git a/doc/source/io.rst b/doc/source/io.rst
index bbf473628..336634308 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1140,15 +1140,17 @@ Delete from a Table
 
 .. ipython:: python
 
+   # returns the number of rows deleted
    store.remove('wp', 'major_axis>20000102' )
    store.select('wp')
 
 Notes & Caveats
 ~~~~~~~~~~~~~~~
 
-   - Selection by items (the top level panel dimension) is not possible; you always get all of the items in the returned Panel
    - Once a ``table`` is created its items (Panel) / columns (DataFrame) are fixed; only exactly the same columns can be appended
    - You can not append/select/delete to a non-table (table creation is determined on the first append, or by passing ``table=True`` in a put operation)
+   - ``HDFStore`` is **not-threadsafe for writing**. The underlying ``PyTables`` only supports concurrent reads (via threading or processes). If you need reading and writing *at the same time*, you need to serialize these operations in a single thread in a single process. You will corrupt your data otherwise. See the issue <https://github.com/pydata/pandas/issues/2397> for more information.
+
    - ``PyTables`` only supports fixed-width string columns in ``tables``. The sizes of a string based indexing column (e.g. *column* or *minor_axis*) are determined as the maximum size of the elements in that axis or by passing the parameter ``min_itemsize`` on the first table creation (``min_itemsize`` can be an integer or a dict of column name to an integer). If subsequent appends introduce elements in the indexing axis that are larger than the supported indexer, an Exception will be raised (otherwise you could have a silent truncation of these indexers, leading to loss of information). This is **ONLY** necessary for storing ``Panels`` (as the indexing column is stored directly in a column)
 
      .. ipython:: python
@@ -1183,6 +1185,27 @@ Performance
      use the pytables utilities ``ptrepack`` to rewrite the file (and also can change compression methods)
    - Duplicate rows can be written, but are filtered out in selection (with the last items being selected; thus a table is unique on major, minor pairs)
 
+Experimental
+~~~~~~~~~~~~
+
+HDFStore supports ``Panel4D`` storage.
+
+.. ipython:: python
+
+   p4d = Panel4D({ 'l1' : wp })
+   p4d
+   store.append('p4d', p4d)
+   store
+
+These, by default, index the three axes ``items, major_axis, minor_axis``. On an ``AppendableTable`` it is possible to setup with the first append a different indexing scheme, depending on how you want to store your data. Pass the ``axes`` keyword with a list of dimension (currently must by exactly 1 less than the total dimensions of the object). This cannot be changed after table creation.
+
+.. ipython:: python
+
+   from pandas.io.pytables import Term
+   store.append('p4d2', p4d, axes = ['labels','major_axis','minor_axis'])
+   store
+   store.select('p4d2', [ Term('labels=l1'), Term('items=Item1'), Term('minor_axis=A_big_strings') ])
+
 .. ipython:: python
    :suppress:
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 866275638..e5d0dd76d 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -390,7 +390,7 @@ class HDFStore(object):
         if group is not None:
 
             # remove the node
-            if where is None or not len(where):
+            if where is None:
                 group = self.get_node(key)
                 group._f_remove(recursive=True)
             
@@ -617,10 +617,6 @@ class HDFStore(object):
 
         return BlockManager(blocks, axes)
 
-    def _write_frame_table(self, group, df, append=False, comp=None, **kwargs):
-        t = create_table(self, group, typ = 'appendable_frame')
-        t.write(axes_to_index=[0], obj=df, append=append, compression=comp, **kwargs)
-
     def _write_wide(self, group, panel):
         panel._consolidate_inplace()
         self._write_block_manager(group, panel._data)
@@ -628,23 +624,33 @@ class HDFStore(object):
     def _read_wide(self, group, where=None):
         return Panel(self._read_block_manager(group))
 
-    def _write_wide_table(self, group, panel, append=False, comp=None, **kwargs):
-        t = create_table(self, group, typ = 'appendable_panel')
-        t.write(axes_to_index=[1,2], obj=panel,
-                append=append, compression=comp, **kwargs)
-
-    def _write_ndim_table(self, group, obj, append=False, comp=None, axes_to_index=None, **kwargs):
-        if axes_to_index is None:
-            axes_to_index=[1,2,3]
+    def _write_ndim_table(self, group, obj, append=False, comp=None, axes=None, **kwargs):
+        if axes is None:
+            axes = [1,2,3]
         t = create_table(self, group, typ = 'appendable_ndim')
-        t.write(axes_to_index=axes_to_index, obj=obj,
+        t.write(axes=axes, obj=obj,
                 append=append, compression=comp, **kwargs)
 
-    def _read_wide_table(self, group, where=None):
+    def _read_ndim_table(self, group, where=None):
         t = create_table(self, group)
         return t.read(where)
 
-    _read_ndim_table = _read_wide_table
+    def _write_frame_table(self, group, df, append=False, comp=None, axes=None, **kwargs):
+        if axes is None:
+            axes = [0]
+        t = create_table(self, group, typ = 'appendable_frame')
+        t.write(axes=axes, obj=df, append=append, compression=comp, **kwargs)
+
+    _read_frame_table = _read_ndim_table
+
+    def _write_wide_table(self, group, panel, append=False, comp=None, axes=None, **kwargs):
+        if axes is None:
+            axes = [1,2]
+        t = create_table(self, group, typ = 'appendable_panel')
+        t.write(axes=axes, obj=panel,
+                append=append, compression=comp, **kwargs)
+
+    _read_wide_table = _read_ndim_table
 
     def _write_index(self, group, key, index):
         if isinstance(index, MultiIndex):
@@ -860,11 +866,6 @@ class HDFStore(object):
         kind = node._v_attrs.kind
         return _unconvert_index_legacy(data, kind)
 
-    def _read_frame_table(self, group, where=None):
-        t = create_table(self, group)
-        return t.read(where)
-
-
 class IndexCol(object):
     """ an index column description class
 
@@ -928,6 +929,10 @@ class IndexCol(object):
 
     __str__ = __repr__
 
+    def __eq__(self, other):
+        """ compare 2 col items """
+        return all([ getattr(self,a,None) == getattr(other,a,None) for a in ['name','cname','axis','pos'] ])
+
     def copy(self):
         new_self = copy.copy(self)
         return new_self
@@ -1034,6 +1039,10 @@ class DataCol(IndexCol):
     def __repr__(self):
         return "name->%s,cname->%s,dtype->%s,shape->%s" % (self.name,self.cname,self.dtype,self.shape)
 
+    def __eq__(self, other):
+        """ compare 2 col items """
+        return all([ getattr(self,a,None) == getattr(other,a,None) for a in ['name','cname','dtype','pos'] ])
+
     def set_data(self, data):
         self.data = data
         if data is not None:
@@ -1129,10 +1138,25 @@ class Table(object):
 
     def __repr__(self):
         """ return a pretty representatgion of myself """
-        return "%s (typ->%s,nrows->%s)" % (self.pandas_type,self.table_type_short,self.nrows)
+        self.infer_axes()
+        return "%s (typ->%s,nrows->%s,indexers->[%s])" % (self.pandas_type,self.table_type_short,self.nrows,','.join([ a.name for a in self.index_axes ]))
 
     __str__ = __repr__
 
+    def copy(self):
+        new_self = copy.copy(self)
+        return new_self
+
+    def __eq__(self, other):
+        """ return True if we are 'equal' to this other table (in all respects that matter) """
+        for c in ['index_axes','non_index_axes','values_axes']:
+            if getattr(self,c,None) != getattr(other,c,None):
+                return False
+        return True
+
+    def __ne__(self, other):
+        return not self.__eq__(other)
+
     @property
     def nrows(self):
         return getattr(self.table,'nrows',None)
@@ -1178,6 +1202,15 @@ class Table(object):
     def axes(self):
         return itertools.chain(self.index_axes, self.values_axes)
 
+    @property
+    def is_transposed(self):
+        return False
+
+    @property
+    def data_orientation(self):
+        """ return a tuple of my permutated axes, non_indexable at the front """
+        return tuple(itertools.chain([ a[0] for a in self.non_index_axes ], [ a.axis for a in self.index_axes ]))
+
     def queryables(self):
         """ return a dict of the kinds allowable columns for this object """
         return dict([ (a.cname,a.kind) for a in self.index_axes ] + [ (self.obj_type._AXIS_NAMES[axis],None) for axis, values in self.non_index_axes ])
@@ -1243,10 +1276,7 @@ class Table(object):
 
         """
 
-        table = self.table
-        if table is None: return
-
-        self.infer_axes()
+        if not self.infer_axes(): return
 
         if columns is None:
             columns = [ self.index_axes[0].name ]
@@ -1259,16 +1289,17 @@ class Table(object):
         if kind is not None:
             kw['kind']     = kind
 
+        table = self.table
         for c in columns:
             v = getattr(table.cols,c,None)
             if v is not None and not v.is_indexed:
                 v.createIndex(**kw)
 
     def read_axes(self, where):
-        """ create and return the axes sniffed from the table """
+        """ create and return the axes sniffed from the table: return boolean for success """
 
         # infer the data kind
-        self.infer_axes()
+        if not self.infer_axes(): return False
 
         # create the selection
         self.selection = Selection(self, where)
@@ -1278,25 +1309,54 @@ class Table(object):
         for a in self.axes:
             a.convert(self.selection)
 
+        return True
+
     def infer_axes(self):
-        """ infer the axes from the indexables """
+        """ infer the axes from the indexables:
+              return a boolean indicating if we have a valid table or not """
+
+        table = self.table
+        if table is None: 
+            return False
+
         self.index_axes, self.values_axes = [ a.infer(self.table) for a in self.indexables if a.is_indexable ], [ a.infer(self.table) for a in self.indexables if not a.is_indexable ]
-        self.non_index_axes = getattr(self.attrs,'non_index_axes',None) or []
+        self.non_index_axes   = getattr(self.attrs,'non_index_axes',None) or []
+
+        return True
 
-    def create_axes(self, axes_to_index, obj, validate = True, min_itemsize = None):
+    def get_data_blocks(self, obj):
+        """ return the data blocks for this obj """
+        return obj._data.blocks
+
+    def create_axes(self, axes, obj, validate = True, min_itemsize = None):
         """ create and return the axes
               leagcy tables create an indexable column, indexable index, non-indexable fields
 
         """
 
-        self.index_axes     = []
-        self.non_index_axes = []
+        # map axes to numbers
+        axes = set([ obj._get_axis_number(a) for a in axes ])
+
+        # do we have an existing table (if so, use its axes)?
+        if self.infer_axes():
+            existing_table = self.copy()
+            axes = [ a.axis for a in existing_table.index_axes]
+        else:
+            existing_table = None
+
+        # currently support on ndim-1 axes
+        if len(axes) != self.ndim-1:
+            raise Exception("currenctly only support ndim-1 indexers in an AppendableTable")
+
+        # create according to the new data
+        self.index_axes       = []
+        self.non_index_axes   = []
 
         # create axes to index and non_index
         j = 0
         for i, a in enumerate(obj.axes):
 
-            if i in axes_to_index:
+            if i in axes:
                 name = obj._AXIS_NAMES[i]
                 self.index_axes.append(_convert_index(a).set_name(name).set_axis(i).set_pos(j))
                 j += 1
@@ -1309,17 +1369,23 @@ class Table(object):
             for a in self.axes:
                 a.maybe_set_size(min_itemsize = min_itemsize)
 
+
+        blocks = self.get_data_blocks(obj)
+
         # add my values
         self.values_axes = []
-        for i, b in enumerate(obj._data.blocks):
+        for i, b in enumerate(blocks):
+
+            # shape of the data column are the indexable axes
+            shape  = b.shape[0]
             values = b.values
 
             # a string column
             if b.dtype.name == 'object':
-                atom  = _tables().StringCol(itemsize = values.dtype.itemsize, shape = b.shape[0])
+                atom  = _tables().StringCol(itemsize = values.dtype.itemsize, shape = shape)
                 utype = 'S8'
             else:
-                atom  = getattr(_tables(),"%sCol" % b.dtype.name.capitalize())(shape = b.shape[0])
+                atom  = getattr(_tables(),"%sCol" % b.dtype.name.capitalize())(shape = shape)
                 utype = atom._deftype
 
             # coerce data to this type
@@ -1332,6 +1398,11 @@ class Table(object):
             j += 1
             self.values_axes.append(dc)
 
+        # validate the axes if we have an existing table
+        if existing_table is not None:
+            if self != existing_table:
+                raise Exception("try to write axes [%s] that are invalid to an existing table [%s]!" % (axes,self.group))
+
     def create_description(self, compression = None, complevel = None):
         """ create the description of the table from the axes & values """
 
@@ -1392,10 +1463,11 @@ class LegacyTable(Table):
           that can be easily searched
 
         """
-    _indexables = [IndexCol(name = 'index',  axis = 0, pos = 0),
-                   IndexCol(name = 'column', axis = 1, pos = 1, index_kind = 'columns_kind'), 
+    _indexables = [IndexCol(name = 'index',  axis = 1, pos = 0),
+                   IndexCol(name = 'column', axis = 2, pos = 1, index_kind = 'columns_kind'), 
                    DataCol( name = 'fields', cname = 'values', kind_attr = 'fields', pos = 2) ]
     table_type = 'legacy'
+    ndim       = 3
 
     def write(self, **kwargs):
         raise Exception("write operations are not allowed on legacy tables!")
@@ -1403,7 +1475,7 @@ class LegacyTable(Table):
     def read(self, where=None):
         """ we have n indexable columns, with an arbitrary number of data axes """
 
-        self.read_axes(where)
+        if not self.read_axes(where): return None
 
         indicies = [ i.values for i in self.index_axes ]
         factors  = [ Factor.from_array(i) for i in indicies ]
@@ -1428,10 +1500,17 @@ class LegacyTable(Table):
                 
                 take_labels   = [ l.take(sorter) for l in labels ]
                 items         = Index(c.values)
+                block         = block2d_to_blocknd(sorted_values, items, tuple(N), take_labels)
 
-                block = block2d_to_blocknd(sorted_values, items, tuple(N), take_labels)
+                # create the object
                 mgr = BlockManager([block], [items] + levels)
-                objs.append(self.obj_type(mgr))
+                obj = self.obj_type(mgr)
+
+                # permute if needed
+                if self.is_transposed:
+                    obj = obj.transpose(*self.data_orientation)
+
+                objs.append(obj)
 
         else:
             if not self._quiet:  # pragma: no cover
@@ -1466,9 +1545,12 @@ class LegacyTable(Table):
         for axis,labels in self.non_index_axes:
             wp = wp.reindex_axis(labels,axis=axis,copy=False)
 
+        # apply the selection filters (but keep in the same order)
         if self.selection.filter:
-            new_minor = sorted(set(wp.minor_axis) & self.selection.filter)
-            wp = wp.reindex(minor=new_minor, copy = False)
+            filter_axis_name = wp._get_axis_name(self.non_index_axes[0][0])
+            ordered  = getattr(wp,filter_axis_name)
+            new_axis = sorted(ordered & self.selection.filter)
+            wp = wp.reindex(**{ filter_axis_name : new_axis, 'copy' : False })
 
         return wp
 
@@ -1489,7 +1571,7 @@ class AppendableTable(LegacyTable):
     _indexables = None
     table_type = 'appendable'
 
-    def write(self, axes_to_index, obj, append=False, compression=None,
+    def write(self, axes, obj, append=False, compression=None,
               complevel=None, min_itemsize = None, **kwargs):
 
         # create the table if it doesn't exist (or get it if it does)
@@ -1498,7 +1580,7 @@ class AppendableTable(LegacyTable):
                 self.handle.removeNode(self.group, 'table')
 
         # create the axes
-        self.create_axes(axes_to_index = axes_to_index, obj = obj, validate = append, min_itemsize = min_itemsize)
+        self.create_axes(axes = axes, obj = obj, validate = append, min_itemsize = min_itemsize)
 
         if 'table' not in self.group:
 
@@ -1530,9 +1612,9 @@ class AppendableTable(LegacyTable):
     def write_data(self):
         """ fast writing of data: requires specific cython routines each axis shape """
 
+        # create the masks & values
+        #import pdb; pdb.set_trace()
         masks  = []
-
-        # create the masks
         for a in self.values_axes:
 
             # figure the mask: only do if we can successfully process this column, otherwise ignore the mask
@@ -1549,7 +1631,7 @@ class AppendableTable(LegacyTable):
         for m in masks[1:]:
             m = mask & m
 
-        # the arguments & values
+        # the arguments
         args   = [ a.cvalues for a in self.index_axes ]
         values = [ a.data for a in self.values_axes ]
 
@@ -1562,17 +1644,22 @@ class AppendableTable(LegacyTable):
             if len(rows):
                 self.table.append(rows)
         except (Exception), detail:
+            #import pdb; pdb.set_trace()
             raise Exception("tables cannot write this data -> %s" % str(detail))
 
     def delete(self, where = None):
-        if where is None:
-            return super(LegacyTable, self).delete()
+
+        # delete all rows (and return the nrows)
+        if where is None or not len(where):
+            nrows = self.nrows
+            self.handle.removeNode(self.group, recursive=True)
+            return nrows
 
         # infer the data kind
-        table = self.table
-        self.infer_axes()
+        if not self.infer_axes(): return None
 
         # create the selection
+        table = self.table
         self.selection = Selection(self, where)
         self.selection.select_coords()
 
@@ -1603,32 +1690,53 @@ class AppendableFrameTable(AppendableTable):
     ndim       = 2
     obj_type   = DataFrame
 
+    @property
+    def is_transposed(self):
+        return self.index_axes[0].axis == 1
+
+    def get_data_blocks(self, obj):
+        """ these are written transposed """
+        if self.is_transposed:
+            obj = obj.T
+        return obj._data.blocks
+
     def read(self, where=None):
 
-        self.read_axes(where)
+        if not self.read_axes(where): return None
 
         index   = Index(self.index_axes[0].values)
         frames  = []
         for a in self.values_axes:
             columns = Index(a.values)
-            block   = make_block(a.cvalues.T, columns, columns)
-            mgr     = BlockManager([ block ], [ columns, index ])
+
+            if self.is_transposed:
+                values   = a.cvalues
+                index_   = columns
+                columns_ = index
+            else:
+                values   = a.cvalues.T
+                index_   = index
+                columns_ = columns
+
+            block   = make_block(values, columns_, columns_)
+            mgr     = BlockManager([ block ], [ columns_, index_ ])
             frames.append(DataFrame(mgr))
         df = concat(frames, axis = 1, verify_integrity = True)
 
         # sort the indicies & reorder the columns
         for axis,labels in self.non_index_axes:
             df = df.reindex_axis(labels,axis=axis,copy=False)
-        columns_ordered = df.columns
 
-        # apply the column filter (but keep columns in the same order)
-        if self.selection.filter:
-            columns = Index(set(columns_ordered) & self.selection.filter)
-            columns = sorted(columns_ordered.get_indexer(columns))
-            df      = df.reindex(columns = columns_ordered.take(columns), copy = False)
+        # apply the selection filters (but keep in the same order)
+        filter_axis_name = df._get_axis_name(self.non_index_axes[0][0])
 
+        ordered = getattr(df,filter_axis_name)
+        if self.selection.filter:
+            ordd = ordered & self.selection.filter
+            ordd = sorted(ordered.get_indexer(ordd))
+            df      = df.reindex(**{ filter_axis_name : ordered.take(ordd), 'copy' : False })
         else:
-            df      = df.reindex(columns = columns_ordered, copy = False)
+            df      = df.reindex(**{ filter_axis_name : ordered , 'copy' : False })
 
         return df
 
@@ -1638,6 +1746,16 @@ class AppendablePanelTable(AppendableTable):
     ndim       = 3
     obj_type   = Panel
 
+    def get_data_blocks(self, obj):
+        """ these are written transposed """
+        if self.is_transposed:
+            obj = obj.transpose(*self.data_orientation)
+        return obj._data.blocks
+
+    @property
+    def is_transposed(self):
+        return self.data_orientation != tuple(range(self.ndim))
+
 class AppendableNDimTable(AppendablePanelTable):
     """ suppor the new appendable table formats """
     table_type = 'appendable_ndim'
@@ -1957,8 +2075,11 @@ class Term(object):
         if not self.is_valid:
             raise Exception("query term is not valid [%s]" % str(self))
 
-        # convert values
-        values = [ self.convert_value(v) for v in self.value ]
+        # convert values if we are in the table
+        if self.is_in_table:
+            values = [ self.convert_value(v) for v in self.value ]
+        else:
+            values = [ [v, v] for v in self.value ]
 
         # equality conditions
         if self.op in ['=','!=']:
@@ -1983,6 +2104,10 @@ class Term(object):
 
                 self.condition = '(%s %s %s)' % (self.field, self.op, values[0][0])
 
+            else:
+
+                raise Exception("passing a filterable condition to a non-table indexer [%s]" % str(self))
+
     def convert_value(self, v):
 
         #### a little hacky here, need to really figure out what we should convert ####x
@@ -2052,7 +2177,7 @@ class Selection(object):
         """
         generate the selection
         """
-        self.values = self.table.table.getWhereList(self.condition)
+        self.values = self.table.table.getWhereList(self.condition, sort = True)
 
 
 def _get_index_factory(klass):
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index 7ecb0bc2f..455182fc2 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -158,50 +158,108 @@ class TestHDFStore(unittest.TestCase):
         self._check_roundtrip(df, tm.assert_frame_equal)
 
     def test_append(self):
-        pth = '__test_append__.h5'
 
-        try:
-            store = HDFStore(pth)
-
-            df = tm.makeTimeDataFrame()
-            store.append('df1', df[:10])
-            store.append('df1', df[10:])
-            tm.assert_frame_equal(store['df1'], df)
-
-            store.put('df2', df[:10], table=True)
-            store.append('df2', df[10:])
-            tm.assert_frame_equal(store['df2'], df)
-
-            store.append('/df3', df[:10])
-            store.append('/df3', df[10:])
-            tm.assert_frame_equal(store['df3'], df)
-
-            # this is allowed by almost always don't want to do it
-            import warnings
-            import tables
-            warnings.filterwarnings('ignore', category=tables.NaturalNameWarning)
-            store.append('/df3 foo', df[:10])
-            store.append('/df3 foo', df[10:])
-            tm.assert_frame_equal(store['df3 foo'], df)
-            warnings.filterwarnings('always', category=tables.NaturalNameWarning)
-
-            # panel
-            wp = tm.makePanel()
-            store.append('wp1', wp.ix[:,:10,:])
-            store.append('wp1', wp.ix[:,10:,:])
-            tm.assert_panel_equal(store['wp1'], wp)
-
-            # ndim
-            p4d = tm.makePanel4D()
-            store.append('p4d', p4d.ix[:,:,:10,:])
-            store.append('p4d', p4d.ix[:,:,10:,:])
-            tm.assert_panel4d_equal(store['p4d'], p4d)
-
-        except:
-            raise
-        finally:
-            store.close()
-            os.remove(pth)
+        df = tm.makeTimeDataFrame()
+        self.store.remove('df1')
+        self.store.append('df1', df[:10])
+        self.store.append('df1', df[10:])
+        tm.assert_frame_equal(self.store['df1'], df)
+
+        self.store.remove('df2')
+        self.store.put('df2', df[:10], table=True)
+        self.store.append('df2', df[10:])
+        tm.assert_frame_equal(self.store['df2'], df)
+
+        self.store.remove('df3')
+        self.store.append('/df3', df[:10])
+        self.store.append('/df3', df[10:])
+        tm.assert_frame_equal(self.store['df3'], df)
+
+        # this is allowed by almost always don't want to do it
+        import warnings
+        import tables
+        warnings.filterwarnings('ignore', category=tables.NaturalNameWarning)
+        self.store.remove('/df3 foo')
+        self.store.append('/df3 foo', df[:10])
+        self.store.append('/df3 foo', df[10:])
+        tm.assert_frame_equal(self.store['df3 foo'], df)
+        warnings.filterwarnings('always', category=tables.NaturalNameWarning)
+        
+        # panel
+        wp = tm.makePanel()
+        self.store.remove('wp1')
+        self.store.append('wp1', wp.ix[:,:10,:])
+        self.store.append('wp1', wp.ix[:,10:,:])
+        tm.assert_panel_equal(self.store['wp1'], wp)
+
+        # ndim
+        p4d = tm.makePanel4D()
+        self.store.remove('p4d')
+        self.store.append('p4d', p4d.ix[:,:,:10,:])
+        self.store.append('p4d', p4d.ix[:,:,10:,:])
+        tm.assert_panel4d_equal(self.store['p4d'], p4d)
+
+        # test using axis labels
+        self.store.remove('p4d')
+        self.store.append('p4d', p4d.ix[:,:,:10,:], axes=['items','major_axis','minor_axis'])
+        self.store.append('p4d', p4d.ix[:,:,10:,:], axes=['items','major_axis','minor_axis'])
+        tm.assert_panel4d_equal(self.store['p4d'], p4d)
+
+    def test_append_frame_column_oriented(self):
+
+        # column oriented
+        df = tm.makeTimeDataFrame()
+        self.store.remove('df1')
+        self.store.append('df1', df.ix[:,:2], axes = ['columns'])
+        self.store.append('df1', df.ix[:,2:])
+        tm.assert_frame_equal(self.store['df1'], df)
+
+        result = self.store.select('df1', 'columns=A')
+        expected = df.reindex(columns=['A'])
+        tm.assert_frame_equal(expected, result)
+
+        # this isn't supported
+        self.assertRaises(Exception, self.store.select, 'df1', ('columns=A', Term('index','>',df.index[4])))
+
+        # selection on the non-indexable
+        result = self.store.select('df1', ('columns=A', Term('index','=',df.index[0:4])))
+        expected = df.reindex(columns=['A'],index=df.index[0:4])
+        tm.assert_frame_equal(expected, result)
+
+    def test_ndim_indexables(self):
+        """ test using ndim tables in new ways"""
+
+        p4d = tm.makePanel4D()
+
+        # append then change (will take existing schema)
+        self.store.remove('p4d')
+        self.store.append('p4d', p4d.ix[:,:,:10,:], axes=['items','major_axis','minor_axis'])
+        self.store.append('p4d', p4d.ix[:,:,10:,:], axes=['labels','items','major_axis'])
+
+        # pass incorrect number of axes
+        self.store.remove('p4d')
+        self.assertRaises(Exception, self.store.append, 'p4d', p4d.ix[:,:,:10,:], axes=['major_axis','minor_axis'])
+
+        # different than default indexables
+        self.store.remove('p4d')
+        self.store.append('p4d', p4d.ix[:,:,:10,:], axes=[0,2,3])
+        self.store.append('p4d', p4d.ix[:,:,10:,:], axes=[0,2,3])
+        tm.assert_panel4d_equal(self.store['p4d'], p4d)
+
+        # partial selection
+        result = self.store.select('p4d',['labels=l1'])
+        expected = p4d.reindex(labels = ['l1'])
+        tm.assert_panel4d_equal(result, expected)
+
+        # partial selection2
+        result = self.store.select('p4d',[Term('labels=l1'), Term('items=ItemA'), Term('minor_axis=B')])
+        expected = p4d.reindex(labels = ['l1'], items = ['ItemA'], minor_axis = ['B'])
+        tm.assert_panel4d_equal(result, expected)
+
+        # non-existant partial selection
+        result = self.store.select('p4d',[Term('labels=l1'), Term('items=Item1'), Term('minor_axis=B')])
+        expected = p4d.reindex(labels = ['l1'], items = [], minor_axis = ['B'])
+        tm.assert_panel4d_equal(result, expected)
 
     def test_append_with_strings(self):
         wp = tm.makePanel()
@@ -317,6 +375,21 @@ class TestHDFStore(unittest.TestCase):
         self.store.append('p1_mixed', p1)
         tm.assert_panel_equal(self.store.select('p1_mixed'), p1)
 
+        # ndim
+        def _make_one_p4d():
+            wp = tm.makePanel4D()
+            wp['obj1'] = 'foo'
+            wp['obj2'] = 'bar'
+            wp['bool1'] = wp['l1'] > 0
+            wp['bool2'] = wp['l2'] > 0
+            wp['int1'] = 1
+            wp['int2'] = 2
+            return wp.consolidate()
+
+        p4d = _make_one_p4d()
+        self.store.append('p4d_mixed', p4d)
+        tm.assert_panel4d_equal(self.store.select('p4d_mixed'), p4d)
+
     def test_remove(self):
         ts = tm.makeTimeSeries()
         df = tm.makeDataFrame()
@@ -366,7 +439,10 @@ class TestHDFStore(unittest.TestCase):
         # empty where
         self.store.remove('wp')
         self.store.put('wp', wp, table=True)
-        self.store.remove('wp', [])
+
+        # deleted number (entire table)
+        n = self.store.remove('wp', [])
+        assert(n == 120)
 
         # non - empty where
         self.store.remove('wp')
@@ -387,8 +463,14 @@ class TestHDFStore(unittest.TestCase):
 
         crit1 = Term('major_axis','>',date)
         crit2 = Term('minor_axis',['A', 'D'])
-        self.store.remove('wp', where=[crit1])
-        self.store.remove('wp', where=[crit2])
+        n = self.store.remove('wp', where=[crit1])
+
+        # deleted number
+        assert(n == 56)
+
+        n = self.store.remove('wp', where=[crit2])
+        assert(n == 32)
+
         result = self.store['wp']
         expected = wp.truncate(after=date).reindex(minor=['B', 'C'])
         tm.assert_panel_equal(result, expected)
@@ -447,8 +529,8 @@ class TestHDFStore(unittest.TestCase):
         tm.assert_panel_equal(result, expected)
 
         # p4d
-        result = self.store.select('p4d',[ Term('major_axis<20000108'), Term('minor_axis', '=', ['A','B']) ])
-        expected = p4d.truncate(after='20000108').reindex(minor=['A', 'B'])
+        result = self.store.select('p4d',[ Term('major_axis<20000108'), Term('minor_axis', '=', ['A','B']), Term('items', '=', ['ItemA','ItemB']) ])
+        expected = p4d.truncate(after='20000108').reindex(minor=['A', 'B'],items=['ItemA','ItemB'])
         tm.assert_panel4d_equal(result, expected)
 
         # valid terms
@@ -464,12 +546,23 @@ class TestHDFStore(unittest.TestCase):
             (('minor_axis', ['A','B']),),
             (('minor_axis', ['A','B']),),
             ((('minor_axis', ['A','B']),),),
+            (('items', ['ItemA','ItemB']),),
+            ('items=ItemA'),
             ]
 
         for t in terms:
            self.store.select('wp', t)
            self.store.select('p4d', t)
 
+        # valid for p4d only
+        terms = [
+            (('labels', '=', ['l1','l2']),),
+            Term('labels', '=', ['l1','l2']),
+            ]
+
+        for t in terms:
+           self.store.select('p4d', t)
+
     def test_series(self):
         s = tm.makeStringSeries()
         self._check_roundtrip(s, tm.assert_series_equal)
