commit b50076ec3a9e6c1f326b7ab23b87c50131aa23a7
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Apr 3 01:56:07 2012 -0400

    ENH: Working on getting to merge ready, cleanup. See full commit message
    
    - get rid of Ts class, simplify timestamp creation
    - rename tzinfo to tz
    - get rid of deprecated / new offset mapping, will deal with users
    - add Index.is_unique, check via is_monotonic cython routine
    - tofreq -> asfreq again
    - work around numpy refcount bug in Index.append with datetime64 type promotion
    - fix bug in Index.join with empty indexes
    - handle legacy DateRange unpickling in BlockManager
    - date_range/bdate_range factory functions, test refactoring
    - got rid of all deprecation warnings in test suite, usages of DateRange
    - fix merge issue? in generate_code.py
    - attach tz in DatetimeIndex.asobject
    - failing duplicate timestamp test
    - _tseries.pyd depends on datetime.pyx

diff --git a/pandas/core/api.py b/pandas/core/api.py
index 43a3464dc..340d319c7 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -7,11 +7,14 @@ import pandas.core.datetools as datetools
 
 from pandas.core.common import isnull, notnull, save, load
 from pandas.core.format import set_printoptions
-from pandas.core.index import (Index, Int64Index, Factor, MultiIndex, 
+from pandas.core.index import (Index, Int64Index, Factor, MultiIndex,
                                DatetimeIndex, IntervalIndex)
 
+# deprecated
 from pandas.core.daterange import DateRange
-from pandas.core.datetools import Ts, Interval
+
+from pandas.core.daterange import date_range, bdate_range
+from pandas.core.datetools import Timestamp, Interval
 
 from pandas.core.series import Series, TimeSeries
 from pandas.core.frame import DataFrame
diff --git a/pandas/core/common.py b/pandas/core/common.py
index ccf1fff70..b60b57fe9 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -163,6 +163,8 @@ def take_1d(arr, indexer, out=None, fill_value=np.nan):
         # Cython methods expects 32-bit integers
         indexer = np.array(indexer, dtype=np.int32)
 
+    indexer = _ensure_int32(indexer)
+
     out_passed = out is not None
 
     if dtype_str in ('int32', 'int64', 'bool'):
diff --git a/pandas/core/daterange.py b/pandas/core/daterange.py
index 913fc2d45..e0711e46c 100644
--- a/pandas/core/daterange.py
+++ b/pandas/core/daterange.py
@@ -3,12 +3,13 @@
 from pandas.core.index import DatetimeIndex, Index
 import pandas.core.datetools as datetools
 
-__all__ = ['DateRange']
 
 #-----------------------------------------------------------------------------
 # DateRange class
 
-class DateRange(DatetimeIndex):
+class DateRange(Index):
+
+    offset = tzinfo = None
 
     def __new__(cls, start=None, end=None, periods=None,
                 offset=datetools.bday, time_rule=None,
@@ -24,10 +25,25 @@ class DateRange(DatetimeIndex):
         elif 'timeRule' in kwds and kwds['timeRule'] is not None:
             offset = datetools._offsetMap[kwds['timeRule']]
 
-        return super(DateRange, cls).__new__(cls, start=start, end=end,
-                periods=periods, offset=offset, tzinfo=tzinfo, name=name,
-                _deprecated=True, **kwds)
-
+        return DatetimeIndex(start=start, end=end,
+                             periods=periods, offset=offset,
+                             tzinfo=tzinfo, name=name, _deprecated=True,
+                             **kwds)
+
+    def __setstate__(self, aug_state):
+        """Necessary for making this object picklable"""
+        index_state = aug_state[:1]
+        offset = aug_state[1]
+
+        # for backwards compatibility
+        if len(aug_state) > 2:
+            tzinfo = aug_state[2]
+        else: # pragma: no cover
+            tzinfo = None
+
+        self.offset = offset
+        self.tzinfo = tzinfo
+        Index.__setstate__(self, *index_state)
 
 def date_range(start=None, end=None, periods=None, freq='D', tz=None):
     """
diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index 50272faee..cda40720e 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -24,20 +24,20 @@ except ImportError: # pragma: no cover
 #-------------------------------------------------------------------------------
 # Boxing and unboxing
 
-def _dt_box(key, offset=None, tzinfo=None):
+def _dt_box(key, offset=None, tz=None):
     '''
     timestamp-like (int64, python datetime, etc.) => Timestamp
     '''
-    return Timestamp(key, offset=offset, tzinfo=tzinfo)
+    return Timestamp(key, offset=offset, tz=tz)
 
-def _dt_box_array(arr, offset=None, tzinfo=None):
+def _dt_box_array(arr, offset=None, tz=None):
     if arr is None:
         return arr
 
     if not isinstance(arr, np.ndarray):
         return arr
 
-    boxfunc = lambda x: _dt_box(x, offset=offset, tzinfo=tzinfo)
+    boxfunc = lambda x: _dt_box(x, offset=offset, tz=tz)
     boxer = np.frompyfunc(boxfunc, 1, 1)
     return boxer(arr)
 
@@ -65,27 +65,35 @@ def _str_to_dt_array(arr):
     data = p_ufunc(arr)
     return np.array(data, dtype='M8[us]')
 
-class Ts(lib.Timestamp):
-    """
-    Convenience class to expose cython-based Timestamp to user. This is the
-    box class for the index values of DatetimeIndex.
-    """
-    def __new__(self, value, freq=None, tzinfo=None):
-        ts = to_timestamp(value, freq, tzinfo)
-        return lib.Timestamp.__new__(Ts, ts, freq, tzinfo)
 
-    @property
-    def freq(self):
-        return self.offset
+def to_datetime(arg):
+    """Attempts to convert arg to datetime"""
+    if arg is None:
+        return arg
+    elif isinstance(arg, datetime):
+        return arg
+    try:
+        return parser.parse(arg)
+    except Exception:
+        return arg
 
-    def to_interval(self, freq=None):
-        """
-        Return an interval of which this timestamp is an observation.
-        """
-        if freq == None:
-            freq = self.freq
 
-        return Interval(self, freq=freq)
+def to_timestamp(arg, offset=None, tz=None):
+    if arg is None:
+        return arg
+    return Timestamp(arg, offset=offset, tz=tz)
+
+
+def to_interval(arg, freq=None):
+    """ Attempts to convert arg to timestamp """
+    if arg is None:
+        return arg
+
+    if type(arg) == float:
+        raise TypeError("Cannot convert a float to interval")
+
+    return Interval(arg, freq=freq)
+
 
 #---------------
 # Interval logic
@@ -195,6 +203,18 @@ class Interval(object):
         raise ValueError("Cannot sub with non-integer value")
 
     def resample(self, freq=None, how='E'):
+        """
+
+        Parameters
+        ----------
+        freq :
+        how :
+
+        Returns
+        -------
+        resampled : Interval
+        """
+
         if how not in ('S', 'E'):
             raise ValueError('How must be one of S or E')
 
@@ -206,6 +226,9 @@ class Interval(object):
 
         return Interval(new_ordinal, (base2, mult2))
 
+    # for skts compatibility
+    asfreq = resample
+
     def to_timestamp(self):
         base, mult = _get_freq_code('S')
         new_val = self.resample('S', 'S').ordinal
@@ -545,7 +568,7 @@ def _skts_alias_dictionary():
     alias_dict = {}
 
     M_aliases = ["M", "MTH", "MONTH", "MONTHLY"]
-    B_aliases = ["B", "BUS", "BUSINESS", "BUSINESSLY"]
+    B_aliases = ["B", "BUS", "BUSINESS", "BUSINESSLY", 'WEEKDAY']
     D_aliases = ["D", "DAY", "DLY", "DAILY"]
     H_aliases = ["H", "HR", "HOUR", "HRLY", "HOURLY"]
     T_aliases = ["T", "MIN", "MINUTE", "MINUTELY"]
@@ -700,32 +723,6 @@ def ole2datetime(oledt):
 
     return OLE_TIME_ZERO + timedelta(days=val)
 
-def to_timestamp(arg, freq=None, tzinfo=None):
-    """ Attempts to convert arg to timestamp """
-    if arg is None:
-        return arg
-
-    if type(arg) == float:
-        # to do, do we want to support this, ie with fractional seconds?
-        raise TypeError("Cannot convert a float to datetime")
-
-    if isinstance(arg, basestring):
-        try:
-            arg = parser.parse(arg)
-        except Exception:
-            pass
-
-    return lib.Timestamp(arg, offset=freq, tzinfo=tzinfo)
-
-def to_interval(arg, freq=None):
-    """ Attempts to convert arg to timestamp """
-    if arg is None:
-        return arg
-
-    if type(arg) == float:
-        raise TypeError("Cannot convert a float to interval")
-
-    return Interval(arg, freq=freq)
 
 class DateParseError(Exception):
     pass
@@ -800,17 +797,6 @@ def parse_time_string(arg):
     except Exception, e:
         raise DateParseError(e)
 
-def to_datetime(arg):
-    """Attempts to convert arg to datetime"""
-    if arg is None:
-        return arg
-    elif isinstance(arg, datetime):
-        return arg
-    try:
-        return parser.parse(arg)
-    except Exception:
-        return arg
-
 def normalize_date(dt):
     if isinstance(dt, np.datetime64):
         dt = _dt_box(dt)
@@ -1011,9 +997,9 @@ class DateOffset(object):
         if type(self) == DateOffset:
             return True
 
-        # Default (slow) method for determining if some date is a
-        # member of the DateRange generated by this offset. Subclasses
-        # may have this re-implemented in a nicer way.
+        # Default (slow) method for determining if some date is a member of the
+        # date range generated by this offset. Subclasses may have this
+        # re-implemented in a nicer way.
         a = someDate
         b = ((someDate + self) - self)
         return a == b
@@ -1659,33 +1645,9 @@ isBMonthEnd = BMonthEnd().onOffset
 #-------------------------------------------------------------------------------
 # Offset names ("time rules") and related functions
 
-# deprecated
-_offsetMap = {
+_offset_map = {
     "WEEKDAY"  : BDay(1),
-    "EOM"      : BMonthEnd(1),
-    "W@MON"    : Week(weekday=0),
-    "W@TUE"    : Week(weekday=1),
-    "W@WED"    : Week(weekday=2),
-    "W@THU"    : Week(weekday=3),
-    "W@FRI"    : Week(weekday=4),
-    "Q@JAN"    : BQuarterEnd(startingMonth=1),
-    "Q@FEB"    : BQuarterEnd(startingMonth=2),
-    "Q@MAR"    : BQuarterEnd(startingMonth=3),
-    "A@JAN"    : BYearEnd(month=1),
-    "A@FEB"    : BYearEnd(month=2),
-    "A@MAR"    : BYearEnd(month=3),
-    "A@APR"    : BYearEnd(month=4),
-    "A@MAY"    : BYearEnd(month=5),
-    "A@JUN"    : BYearEnd(month=6),
-    "A@JUL"    : BYearEnd(month=7),
-    "A@AUG"    : BYearEnd(month=8),
-    "A@SEP"    : BYearEnd(month=9),
-    "A@OCT"    : BYearEnd(month=10),
-    "A@NOV"    : BYearEnd(month=11),
-    "A@DEC"    : BYearEnd()
-}
 
-_newOffsetMap = {
     # Annual - Calendar
     "A@JAN" : YearEnd(month=1),
     "A@FEB" : YearEnd(month=2),
@@ -1799,15 +1761,21 @@ _newOffsetMap = {
     "BQS@NOV" : BQuarterBegin(startingMonth=11),
     "BQS@DEC" : BQuarterBegin(startingMonth=12),
     # Monthly - Calendar
+    "EOM"      : BMonthEnd(1),  # legacy, deprecated?
+
     "M"      : MonthEnd(),
-    "EOM"    : MonthEnd(),
     "MS"     : MonthBegin(),
-    "SOM"    : MonthBegin(),
+
+
     # Monthly - Business
     "BM"     : BMonthEnd(),
-    "BEOM"   : BMonthEnd(),
     "BMS"    : BMonthBegin(),
-    "BSOM"   : BMonthBegin(),
+
+    # "EOM"    : MonthEnd(),
+    # "SOM"    : MonthBegin(),
+    # "BEOM"   : BMonthEnd(),
+    # "BSOM"   : BMonthBegin(),
+
     # Weekly
     "W@MON" : Week(weekday=0),
     "WS"    : Week(weekday=0),
@@ -1832,38 +1800,29 @@ _newOffsetMap = {
 
 for i, weekday in enumerate(['MON', 'TUE', 'WED', 'THU', 'FRI']):
     for iweek in xrange(4):
-        _offsetMap['WOM@%d%s' % (iweek + 1, weekday)] = \
-            WeekOfMonth(week=iweek, weekday=i)
-        _newOffsetMap['WOM@%d%s' % (iweek + 1, weekday)] = \
+        _offset_map['WOM@%d%s' % (iweek + 1, weekday)] = \
             WeekOfMonth(week=iweek, weekday=i)
 
 # for helping out with pretty-printing and name-lookups
 
-_offsetNames = {}
-for name, offset in _offsetMap.iteritems():
-    offset.name = name
-    _offsetNames[offset] = name
-
-_offsetNames = dict([(v, k) for k, v in _offsetMap.iteritems()])
-
-_newOffsetNames = {}
-for name, offset in _newOffsetMap.iteritems():
+_offset_names = {}
+for name, offset in _offset_map.iteritems():
     if offset is None:
         continue
     offset.name = name
-    _newOffsetNames[offset] = name
+    _offset_names[offset] = name
 
-def inferTimeRule(index, _deprecated=True):
+
+def inferTimeRule(index):
     if len(index) < 3:
         raise Exception('Need at least three dates to infer time rule!')
 
     first, second, third = index[:3]
-    if _deprecated:
-        items = _offsetMap.iteritems()
-    else:
-        items = _newOffsetMap.iteritems()
+    items = _offset_map.iteritems()
 
     for rule, offset in items:
+        if offset is None:
+            continue
         if (first + offset) == second and (second + offset) == third:
             return rule
 
@@ -1884,7 +1843,7 @@ def to_offset(freqstr):
 
     name, stride = _base_and_stride(freqstr)
 
-    offset = _newOffsetMap.get(name)
+    offset = _offset_map.get(name)
 
     if offset is None:
         raise ValueError('Bad offset request: %s' % name)
@@ -1916,7 +1875,7 @@ def _base_and_stride(freqstr):
     return (base, stride)
 
 
-def getOffset(name, _deprecated=True):
+def getOffset(name):
     """
     Return DateOffset object associated with rule name
 
@@ -1924,10 +1883,7 @@ def getOffset(name, _deprecated=True):
     -------
     getOffset('EOM') --> BMonthEnd(1)
     """
-    if _deprecated:
-        offset = _offsetMap.get(name)
-    else:
-        offset = _newOffsetMap.get(name)
+    offset = _offset_map.get(name)
 
     if offset is not None:
         return offset
@@ -1935,9 +1891,9 @@ def getOffset(name, _deprecated=True):
         raise Exception('Bad rule name requested: %s!' % name)
 
 def hasOffsetName(offset):
-    return offset in _offsetNames
+    return offset in _offset_names
 
-def getOffsetName(offset, _deprecated=True):
+def getOffsetName(offset):
     """
     Return rule name associated with a DateOffset object
 
@@ -1945,10 +1901,7 @@ def getOffsetName(offset, _deprecated=True):
     -------
     getOffsetName(BMonthEnd(1)) --> 'EOM'
     """
-    if _deprecated:
-        name = _offsetNames.get(offset)
-    else:
-        name = _newOffsetNames.get(offset)
+    name = _offset_names.get(offset)
 
     if name is not None:
         return name
@@ -2014,9 +1967,6 @@ def generate_range(start=None, end=None, periods=None,
     -------
     dates : generator object
 
-    See also
-    --------
-    DateRange, dateutil.rrule
     """
 
     if time_rule is not None:
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index ad8eec31e..32335e0ef 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -26,7 +26,6 @@ import numpy.ma as ma
 
 from pandas.core.common import (isnull, notnull, PandasError, _try_sort,
                                 _default_index, _stringify)
-from pandas.core.daterange import DateRange
 from pandas.core.generic import NDFrame
 from pandas.core.index import (Index, DatetimeIndex, MultiIndex, NULL_INDEX,
                                _ensure_index)
@@ -2032,7 +2031,7 @@ class DataFrame(NDFrame):
 
         index = MultiIndex.from_arrays(arrays, names=cols)
 
-        if verify_integrity and not index._verify_integrity():
+        if verify_integrity and not index.is_unique:
             duplicates = index.get_duplicates()
             raise Exception('Index has duplicate keys: %s' % duplicates)
 
@@ -2880,7 +2879,7 @@ class DataFrame(NDFrame):
     #----------------------------------------------------------------------
     # Time series-related
 
-    def tofreq(self, freq, method=None):
+    def asfreq(self, freq, method=None):
         """
         Convert all TimeSeries inside to specified frequency using DateOffset
         objects. Optionally provide fill method to pad/backfill missing values.
@@ -2897,46 +2896,12 @@ class DataFrame(NDFrame):
         -------
         converted : DataFrame
         """
+        from pandas.core.daterange import date_range
         if len(self.index) == 0:
             return self.copy()
-        dti = DatetimeIndex(self.index[0], self.index[-1], freq=freq)
+        dti = date_range(self.index[0], self.index[-1], freq=freq)
         return self.reindex(dti, method=method)
 
-
-    def asfreq(self, offset, method=None):
-        """
-        Convert all TimeSeries inside to specified frequency using DateOffset
-        objects. Optionally provide fill method to pad/backfill missing values.
-
-        Parameters
-        ----------
-        offset : DateOffset object, or string in {'WEEKDAY', 'EOM'}
-            DateOffset object or subclass (e.g. monthEnd)
-        method : {'backfill', 'bfill', 'pad', 'ffill', None}
-            Method to use for filling holes in reindexed Series
-            pad / ffill: propagate last valid observation forward to next valid
-            backfill / bfill: use NEXT valid observation to fill methdo
-
-        Returns
-        -------
-        converted : DataFrame
-        """
-
-        import warnings
-        warnings.warn("The 'asfreq' method is deprecated; use 'tofreq' "
-                      " and the new pandas offsets",
-                      FutureWarning)
-        
-        if len(self.index) == 0:
-            return self.copy()
-
-        if isinstance(offset, datetools.DateOffset):
-            dateRange = DateRange(self.index[0], self.index[-1], offset=offset)
-        else:
-            dateRange = DateRange(self.index[0], self.index[-1], time_rule=offset)
-
-        return self.reindex(dateRange, method=method)
-
     def diff(self, periods=1):
         """
         1st discrete difference of object
@@ -2968,24 +2933,12 @@ class DataFrame(NDFrame):
         -------
         shifted : DataFrame
         """
+        from pandas.core.series import _resolve_offset
+
         if periods == 0:
             return self
 
-        if 'timeRule' in kwds or 'offset' in kwds:
-            offset = kwds.get('offset')
-            offset = kwds.get('timeRule', offset)
-            if isinstance(offset, basestring):
-                offset = datetools.getOffset(offset)
-            warn = True
-        else:
-            offset = freq
-            warn = False
-
-        if warn:
-            import warnings
-            warnings.warn("'timeRule' and 'offset' parameters are deprecated,"
-                          " please use 'freq' instead",
-                          FutureWarning)
+        offset = _resolve_offset(freq, kwds)
 
         if isinstance(offset, basestring):
             offset = datetools.to_offset(offset)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 99d9cc7ff..5160f45eb 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -105,6 +105,9 @@ class Index(np.ndarray):
     def __array_finalize__(self, obj):
         self.name = getattr(obj, 'name', None)
 
+    def _shallow_copy(self):
+        return self.view(type(self))
+
     def astype(self, dtype):
         return Index(self.values.astype(dtype), name=self.name,
                      dtype=dtype)
@@ -159,13 +162,27 @@ class Index(np.ndarray):
     def values(self):
         return np.asarray(self)
 
-    @cache_readonly
+    @property
     def is_monotonic(self):
+        return self._monotonicity_check[0]
+
+    @property
+    def is_unique(self):
+        is_unique = self._monotonicity_check[1]
+
+        if is_unique is None:
+            return self._engine.has_integrity
+        else:
+            return is_unique
+
+    @cache_readonly
+    def _monotonicity_check(self):
         try:
             # wrong buffer type raises ValueError
-            return self._is_monotonic(self.values)
+            is_monotonic, is_unique = self._is_monotonic(self.values)
+            return is_monotonic, is_unique
         except TypeError:
-            return False
+            return False, None
 
     def is_numeric(self):
         return self.inferred_type in ['integer', 'floating']
@@ -214,9 +231,6 @@ class Index(np.ndarray):
             level = 0
         return level
 
-    def _verify_integrity(self):
-        return self._engine.has_integrity
-
     @cache_readonly
     def inferred_type(self):
         return lib.infer_dtype(self)
@@ -290,15 +304,18 @@ class Index(np.ndarray):
         -------
         appended : Index
         """
+        to_concat = [self]
+
         if isinstance(other, (list, tuple)):
-            to_concat = (self.values,) + tuple(other)
+            to_concat = to_concat + list(other)
         else:
-            to_concat = self.values, other.values
+            to_concat.append(other)
 
-        try:
-            return Index(np.concatenate(to_concat))
-        except TypeError:
-            return Index(np.concatenate(map(_maybe_box_dtindex, to_concat)))
+        to_concat = _ensure_compat_concat(to_concat)
+        to_concat = [x.values if isinstance(x, Index) else x
+                     for x in to_concat]
+        concatenated = np.concatenate(to_concat)
+        return Index(concatenated)
 
     def take(self, *args, **kwargs):
         """
@@ -430,6 +447,7 @@ class Index(np.ndarray):
 
         if len(other) == 0 or self.equals(other):
             return self
+
         if len(self) == 0:
             return _ensure_index(other)
 
@@ -536,6 +554,18 @@ class Index(np.ndarray):
         theDiff = sorted(set(self) - set(other))
         return Index(theDiff)
 
+    def unique(self):
+        """
+        Return array of unique values in the Index. Significantly faster than
+        numpy.unique
+
+        Returns
+        -------
+        uniques : ndarray
+        """
+        from pandas.core.nanops import unique1d
+        return unique1d(self.values)
+
     def get_loc(self, key):
         """
         Get integer location for requested label
@@ -712,6 +742,22 @@ class Index(np.ndarray):
 
         other = _ensure_index(other)
 
+        if len(other) == 0 and how in ('left', 'outer'):
+            join_index = self._shallow_copy()
+            if return_indexers:
+                rindexer = np.repeat(-1, len(join_index))
+                return join_index, None, rindexer
+            else:
+                return join_index
+
+        if len(self) == 0 and how in ('right', 'outer'):
+            join_index = other._shallow_copy()
+            if return_indexers:
+                lindexer = np.repeat(-1, len(join_index))
+                return join_index, lindexer, None
+            else:
+                return join_index
+
         if self.dtype != other.dtype:
             this = self.astype('O')
             other = other.astype('O')
@@ -1088,6 +1134,13 @@ def _dt_index_op(opname):
             return func(other)
     return wrapper
 
+def _ensure_compat_concat(indexes):
+    is_m8 = [isinstance(idx, DatetimeIndex) for idx in indexes]
+    if any(is_m8) and not all(is_m8):
+        return [_maybe_box_dtindex(idx) for idx in indexes]
+    return indexes
+
+
 def _maybe_box_dtindex(idx):
     if isinstance(idx, DatetimeIndex):
         return Index(_dt_box_array(idx.asi8), dtype='object')
@@ -1148,7 +1201,7 @@ class DatetimeIndex(Int64Index):
 
     def __new__(cls, data=None,
                 freq=None, start=None, end=None, periods=None,
-                dtype=None, copy=False, name=None, tzinfo=None,
+                dtype=None, copy=False, name=None, tz=None,
                 **kwds):
 
         warn = False
@@ -1185,8 +1238,8 @@ class DatetimeIndex(Int64Index):
 
             useCache = datetools._will_use_cache(offset)
 
-            start, end, tzinfo = datetools._figure_out_timezone(start, end,
-                                                                tzinfo)
+            start, end, tz = datetools._figure_out_timezone(start, end,
+                                                                tz)
 
             useCache = useCache and datetools._naive_in_cache_range(start, end)
 
@@ -1216,7 +1269,7 @@ class DatetimeIndex(Int64Index):
             index = index.view(cls)
             index.name = name
             index.offset = offset
-            index.tzinfo = tzinfo
+            index.tz = tz
 
             return index
 
@@ -1262,10 +1315,17 @@ class DatetimeIndex(Int64Index):
         subarr = subarr.view(cls)
         subarr.name = name
         subarr.offset = offset
-        subarr.tzinfo = tzinfo
+        subarr.tz = tz
 
         return subarr
 
+    @property
+    def tzinfo(self):
+        """
+        Alias for tz attribute
+        """
+        return self.tz
+
     @classmethod
     def _cached_range(cls, start=None, end=None, periods=None, offset=None,
                       name=None):
@@ -1287,7 +1347,7 @@ class DatetimeIndex(Int64Index):
 
             cachedRange = arr.view(DatetimeIndex)
             cachedRange.offset = offset
-            cachedRange.tzinfo = None
+            cachedRange.tz = None
             cachedRange.name = None
             drc[offset] = cachedRange
         else:
@@ -1333,7 +1393,7 @@ class DatetimeIndex(Int64Index):
     def __repr__(self):
         if self.offset is not None:
             output = str(self.__class__) + '\n'
-            output += 'offset: %s, tzinfo: %s\n' % (self.offset, self.tzinfo)
+            output += 'offset: %s, timezone: %s\n' % (self.offset, self.tz)
             if len(self) > 0:
                 output += '[%s, ..., %s]\n' % (self[0], self[-1])
             output += 'length: %d' % len(self)
@@ -1346,7 +1406,7 @@ class DatetimeIndex(Int64Index):
     def __reduce__(self):
         """Necessary for making this object picklable"""
         object_state = list(np.ndarray.__reduce__(self))
-        subclass_state = self.name, self.offset, self.tzinfo
+        subclass_state = self.name, self.offset, self.tz
         object_state[2] = (object_state[2], subclass_state)
         return tuple(object_state)
 
@@ -1356,26 +1416,8 @@ class DatetimeIndex(Int64Index):
             nd_state, own_state = state
             self.name = own_state[0]
             self.offset = own_state[1]
-            self.tzinfo = own_state[2]
+            self.tz = own_state[2]
             np.ndarray.__setstate__(self, nd_state)
-        elif len(state) == 3: 
-            # legacy format: daterange
-            offset = state[1]
-
-            if len(state) > 2:
-                tzinfo = state[2]
-            else: # pragma: no cover
-                tzinfo = None
-
-            self.offset = offset
-            self.tzinfo = tzinfo
-
-            # extract the raw datetime data, turn into datetime64
-            index_state = state[0]
-            raw_data = index_state[0][4]
-            raw_data = np.array(raw_data, dtype='M8[us]')
-            new_state = raw_data.__reduce__()
-            np.ndarray.__setstate__(self, new_state[2])
         else:  # pragma: no cover
             np.ndarray.__setstate__(self, state)
 
@@ -1395,10 +1437,9 @@ class DatetimeIndex(Int64Index):
         """
         Unbox to an index of type object
         """
-        if hasattr(self, 'offset') and self.offset is not None:
-            return Index(_dt_box_array(self.asi8, self.offset), dtype='object')
-        else:
-            return Index(_dt_box_array(self.asi8), dtype='object')
+        offset = getattr(self, 'offset', None)
+        boxed_values = _dt_box_array(self.asi8, self.offset, self.tz)
+        return Index(boxed_values, dtype=object)
 
     def to_interval(self, freq=None):
         """
@@ -1472,17 +1513,17 @@ class DatetimeIndex(Int64Index):
 
     def union(self, other):
         """
-        Specialized union for DateRange objects. If combine
+        Specialized union for DatetimeIndex objects. If combine
         overlapping ranges with the same DateOffset, will be much
         faster than Index.union
 
         Parameters
         ----------
-        other : DateRange or array-like
+        other : DatetimeIndex or array-like
 
         Returns
         -------
-        y : Index or DateRange
+        y : Index or DatetimeIndex
         """
         if self._can_fast_union(other):
             return self._fast_union(other)
@@ -1506,6 +1547,9 @@ class DatetimeIndex(Int64Index):
         if offset is None:
             return False
 
+        if len(other) == 0:
+            return True
+
         # to make our life easier, "sort" the two ranges
         if self[0] <= other[0]:
             left, right = self, other
@@ -1519,6 +1563,9 @@ class DatetimeIndex(Int64Index):
         return (left_end + offset) >= right_start
 
     def _fast_union(self, other):
+        if len(other) == 0:
+            return self.view(type(self))
+
         # to make our life easier, "sort" the two ranges
         if self[0] <= other[0]:
             left, right = self, other
@@ -1540,27 +1587,27 @@ class DatetimeIndex(Int64Index):
         else:
             return type(self)(start=left_start,
                               end=max(left_end, right_end),
-                              offset=left.offset)
+                              freq=left.offset)
 
     def __array_finalize__(self, obj):
         if self.ndim == 0: # pragma: no cover
             return self.item()
 
         self.offset = getattr(obj, 'offset', None)
-        self.tzinfo = getattr(obj, 'tzinfo', None)
+        self.tz = getattr(obj, 'tz', None)
 
     def intersection(self, other):
         """
-        Specialized intersection for DateRange objects. May be much faster than
-        Index.union
+        Specialized intersection for DatetimeIndex objects. May be much faster
+        than Index.union
 
         Parameters
         ----------
-        other : DateRange or array-like
+        other : DatetimeIndex or array-like
 
         Returns
         -------
-        y : Index or DateRange
+        y : Index or DatetimeIndex
         """
         if other.offset != self.offset:
             return super(DatetimeIndex, self).intersection(self, other)
@@ -1651,10 +1698,8 @@ class DatetimeIndex(Int64Index):
         arr_idx = self.view(np.ndarray)
         if np.isscalar(key):
             val = arr_idx[key]
-            if hasattr(self, 'offset') and self.offset is not None:
-                return _dt_box(val, offset=self.offset, tzinfo=self.tzinfo)
-            else:
-                return _dt_box(val, tzinfo=self.tzinfo)
+            offset = getattr(self, 'offset', None)
+            return _dt_box(val, offset=offset, tz=self.tz)
         else:
             new_offset = None
             if (type(key) == slice):
@@ -1671,7 +1716,7 @@ class DatetimeIndex(Int64Index):
                 return result
 
             return DatetimeIndex(result, name=self.name, freq=new_offset,
-                                 tzinfo=self.tzinfo)
+                                 tz=self.tz)
 
     # Try to run function on index first, and then on elements of index
     # Especially important for group-by functionality
@@ -1816,35 +1861,35 @@ class DatetimeIndex(Int64Index):
     def _view_like(self, ndarray):
         result = ndarray.view(type(self))
         result.offset = self.offset
-        result.tzinfo = self.tzinfo
+        result.tz = self.tz
         result.name = self.name
         return result
 
     def tz_normalize(self, tz):
         """
-        Convert DateRange from one time zone to another (using pytz)
+        Convert DatetimeIndex from one time zone to another (using pytz)
 
         Returns
         -------
-        normalized : DateRange
+        normalized : DatetimeIndex
         """
-        new_dates = lib.tz_normalize_array(self.asi8, self.tzinfo, tz)
+        new_dates = lib.tz_normalize_array(self.asi8, self.tz, tz)
         new_dates = new_dates.view('M8[us]')
         new_dates = new_dates.view(self.__class__)
         new_dates.offset = self.offset
-        new_dates.tzinfo = tz
+        new_dates.tz = tz
         new_dates.name = self.name
         return new_dates
 
     def tz_localize(self, tz):
         """
-        Localize tzinfo-naive DateRange to given time zone (using pytz)
+        Localize tz-naive DatetimeIndex to given time zone (using pytz)
 
         Returns
         -------
         localized : DatetimeIndex
         """
-        if self.tzinfo is not None:
+        if self.tz is not None:
             raise ValueError("Already have timezone info, "
                              "use tz_normalize to convert.")
 
@@ -1852,7 +1897,7 @@ class DatetimeIndex(Int64Index):
         new_dates = new_dates.view('M8[us]')
         new_dates = new_dates.view(self.__class__)
         new_dates.offset = self.offset
-        new_dates.tzinfo = tz
+        new_dates.tz = tz
         new_dates.name = self.name
         return new_dates
 
@@ -1868,12 +1913,12 @@ class DatetimeIndex(Int64Index):
         """
         import pytz
 
-        if self.tzinfo is None or self.tzinfo is pytz.utc:
+        if self.tz is None or self.tz is pytz.utc:
             return True
 
         # See if there are any DST resolution problems
         try:
-            lib.tz_localize_array(self.asi8, self.tzinfo)
+            lib.tz_localize_array(self.asi8, self.tz)
         except:
             return False
 
@@ -1989,7 +2034,7 @@ class IntervalIndex(Int64Index):
                     raise ValueError('freq cannot be none')
 
                 if isinstance(freq, datetools.DateOffset):
-                    freq = datetools._newOffsetNames[freq]
+                    freq = datetools.getOffsetName(freq)
 
                 if data.dtype == np.datetime64:
                     data = datetools.dt64arr_to_sktsarr(data, freq)
@@ -3507,3 +3552,24 @@ def _sanitize_and_check(indexes):
         return indexes, 'special'
     else:
         return indexes, 'array'
+
+
+#----------------------------------------------------------------------
+# legacy unpickling
+
+def _handle_legacy_indexes(indexes):
+    from pandas.core.daterange import DateRange
+
+    converted = []
+    for index in indexes:
+        if isinstance(index, DateRange):
+            index = _convert_daterange(index)
+
+        converted.append(index)
+
+    return converted
+
+def _convert_daterange(obj):
+    return DatetimeIndex(start=obj[0], end=obj[-1],
+                         freq=obj.offset, tz=obj.tzinfo)
+
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index cb262593e..31595d260 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -3,7 +3,7 @@ import itertools
 from numpy import nan
 import numpy as np
 
-from pandas.core.index import Index, _ensure_index
+from pandas.core.index import Index, _ensure_index, _handle_legacy_indexes
 import pandas.core.common as com
 import pandas._tseries as lib
 
@@ -378,6 +378,8 @@ class BlockManager(object):
         ax_arrays, bvalues, bitems = state[:3]
 
         self.axes = [_ensure_index(ax) for ax in ax_arrays]
+        self.axes = _handle_legacy_indexes(self.axes)
+
         blocks = []
         for values, items in zip(bvalues, bitems):
             blk = make_block(values, items, self.axes[0],
@@ -920,7 +922,7 @@ class BlockManager(object):
 
     def rename_axis(self, mapper, axis=1):
         new_axis = Index([mapper(x) for x in self.axes[axis]])
-        new_axis._verify_integrity()
+        assert(new_axis.is_unique)
 
         new_axes = list(self.axes)
         new_axes[axis] = new_axis
@@ -928,7 +930,7 @@ class BlockManager(object):
 
     def rename_items(self, mapper, copydata=True):
         new_items = Index([mapper(x) for x in self.items])
-        new_items._verify_integrity()
+        new_items.is_unique
 
         new_blocks = []
         for block in self.blocks:
@@ -1128,6 +1130,7 @@ def _consolidate(blocks, items):
 
     return new_blocks
 
+
 # TODO: this could be much optimized
 
 def _merge_blocks(blocks, items):
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 1ce4094a0..6370027d7 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -17,9 +17,9 @@ import numpy.ma as ma
 from pandas.core.common import (isnull, notnull, _is_bool_indexer,
                                 _default_index, _maybe_upcast,
                                 _asarray_tuplesafe)
-from pandas.core.daterange import DateRange
 from pandas.core.index import (Index, MultiIndex, InvalidIndexError,
-                               _ensure_index, DatetimeIndex)
+                               _ensure_index, DatetimeIndex,
+                               _handle_legacy_indexes)
 from pandas.core.indexing import _SeriesIndexer
 from pandas.util import py3compat
 from pandas.util.terminal import get_terminal_size
@@ -362,7 +362,7 @@ copy : boolean, default False
         if len(own_state) > 1:
             name = own_state[1]
 
-        self.index = index
+        self.index = _handle_legacy_indexes([index])[0]
         self.name = name
 
     _ix = None
@@ -2099,7 +2099,7 @@ copy : boolean, default False
                 return tsp.tsplot(self)
             if isinstance(self.index, DatetimeIndex):
                 offset = self.index.freq
-                name = datetools._newOffsetNames.get(offset, None)
+                name = datetools._offset_names.get(offset, None)
                 if name is not None:
                     try:
                         code = datetools._interval_str_to_code(name)
@@ -2321,21 +2321,7 @@ copy : boolean, default False
         if periods == 0:
             return self.copy()
 
-        if 'timeRule' in kwds or 'offset' in kwds:
-            offset = kwds.get('offset')
-            offset = kwds.get('timeRule', offset)
-            if isinstance(offset, basestring):
-                offset = datetools.getOffset(offset)
-            warn = True
-        else:
-            offset = freq
-            warn = False
-
-        if warn:
-            import warnings
-            warnings.warn("'timeRule' and 'offset' parameters are deprecated,"
-                          " please use 'freq' instead",
-                          FutureWarning)
+        offset = _resolve_offset(freq, kwds)
 
         if isinstance(offset, basestring):
             offset = datetools.to_offset(offset)
@@ -2397,28 +2383,26 @@ copy : boolean, default False
 
     def asfreq(self, freq, method=None):
         """
-        Convert this TimeSeries to the provided frequency using DateOffset
-        object or time rule. Optionally provide fill method to pad/backfill
-        missing values.
+        Convert all TimeSeries inside to specified frequency using DateOffset
+        objects. Optionally provide fill method to pad/backfill missing values.
 
         Parameters
         ----------
-        freq : DateOffset object, or corresponding string
-            DateOffset object or subclass (e.g. monthEnd)
-        method : {'backfill', 'pad', None}
-            Method to use for filling holes in new index
+        freq : DateOffset object, or string
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}
+            Method to use for filling holes in reindexed Series
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill methdo
 
         Returns
         -------
-        converted : TimeSeries
+        converted : DataFrame
         """
-
-        if isinstance(freq, datetools.DateOffset):
-            dateRange = DateRange(self.index[0], self.index[-1], offset=freq)
-        else:
-            dateRange = DateRange(self.index[0], self.index[-1], time_rule=freq)
-
-        return self.reindex(dateRange, method=method)
+        from pandas.core.daterange import date_range
+        if len(self.index) == 0:
+            return self.copy()
+        dti = date_range(self.index[0], self.index[-1], freq=freq)
+        return self.reindex(dti, method=method)
 
     def interpolate(self, method='linear'):
         """
@@ -2601,3 +2585,26 @@ def _get_rename_function(mapper):
         f = mapper
 
     return f
+
+
+def _resolve_offset(freq, kwds):
+    from pandas.core.datetools import getOffset
+
+    if 'timeRule' in kwds or 'offset' in kwds:
+        offset = kwds.get('offset')
+        offset = kwds.get('timeRule', offset)
+        if isinstance(offset, basestring):
+            offset = datetools.getOffset(offset)
+        warn = True
+    else:
+        offset = freq
+        warn = False
+
+    if warn:
+        import warnings
+        foo
+        warnings.warn("'timeRule' and 'offset' parameters are deprecated,"
+                      " please use 'freq' instead",
+                      FutureWarning)
+
+    return offset
diff --git a/pandas/info.py b/pandas/info.py
index 736839678..754741c11 100644
--- a/pandas/info.py
+++ b/pandas/info.py
@@ -9,9 +9,12 @@ Series
 DataFrame
 Panel
 Index
-DateRange
+DatetimeIndex
 HDFStore
+bdate_range
+date_range
 read_csv
-read_talbe
+read_fwf
+read_table
 ols
 """
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 75d4e9842..bd16603af 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -483,7 +483,7 @@ class TextParser(object):
         else:
             index = Index(np.arange(len(content)))
 
-        if not index._verify_integrity():
+        if not index.is_unique:
             dups = index.get_duplicates()
             idx_str = 'Index' if not self.implicit_idx else 'Implicit index'
             err_msg = ('%s (columns %s) have duplicate values %s'
@@ -793,7 +793,7 @@ class ExcelWriter(object):
             sheet = self.book.create_sheet()
             sheet.title = sheet_name
             row_idx = 0
-        
+
         conv_row = []
         for val in row:
             if isinstance(val, np.int64):
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index 7d09d5625..3a27f7871 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -6,7 +6,7 @@ import sys
 from datetime import datetime
 import numpy as np
 
-from pandas import Series, DataFrame, Panel, DateRange, MultiIndex
+from pandas import Series, DataFrame, Panel, MultiIndex, bdate_range
 from pandas.io.pytables import HDFStore
 import pandas.util.testing as tm
 
@@ -192,7 +192,7 @@ class TesttHDFStore(unittest.TestCase):
         if sys.version_info[0] == 2 and sys.version_info[1] < 7:
             raise nose.SkipTest
 
-        dr = DateRange('1/1/1940', '1/1/1960')
+        dr = bdate_range('1/1/1940', '1/1/1960')
         ts = Series(np.random.randn(len(dr)), index=dr)
         try:
             self._check_roundtrip(ts, tm.assert_series_equal)
@@ -230,7 +230,7 @@ class TesttHDFStore(unittest.TestCase):
                           tm.assert_frame_equal)
 
     def test_can_serialize_dates(self):
-        rng = [x.date() for x in DateRange('1/1/2000', '1/30/2000')]
+        rng = [x.date() for x in bdate_range('1/1/2000', '1/30/2000')]
         frame = DataFrame(np.random.randn(len(rng), 4), index=rng)
         self._check_roundtrip(frame, tm.assert_frame_equal)
 
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index c86d24771..9cb7b6ddd 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -674,12 +674,13 @@ class SparseDataFrame(DataFrame):
         """
         return self.apply(lambda x: x.cumsum(), axis=axis)
 
-    def shift(self, periods, offset=None, timeRule=None):
+    def shift(self, periods, freq=None, **kwds):
         """
         Analogous to DataFrame.shift
         """
-        if timeRule is not None and offset is None:
-            offset = datetools.getOffset(timeRule)
+        from pandas.core.series import _resolve_offset
+
+        offset = _resolve_offset(freq, kwds)
 
         new_series = {}
         if offset is None:
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index c0f734b07..623760834 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -481,23 +481,24 @@ to sparse
         else:
             return dense_valid.to_sparse(fill_value=self.fill_value)
 
-    def shift(self, periods, offset=None, timeRule=None):
+    def shift(self, periods, freq=None, **kwds):
         """
         Analogous to Series.shift
         """
+        from pandas.core.series import _resolve_offset
+
+        offset = _resolve_offset(freq, kwds)
+
         # no special handling of fill values yet
         if not isnull(self.fill_value):
-            dense_shifted = self.to_dense().shift(periods, offset=offset,
-                                                  timeRule=timeRule)
+            dense_shifted = self.to_dense().shift(periods, freq=freq,
+                                                  **kwds)
             return dense_shifted.to_sparse(fill_value=self.fill_value,
                                            kind=self.kind)
 
         if periods == 0:
             return self.copy()
 
-        if timeRule is not None and offset is None:
-            offset = datetools.getOffset(timeRule)
-
         if offset is not None:
             return SparseSeries(self.sp_values,
                                 sparse_index=self.sp_index,
diff --git a/pandas/sparse/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
index 32c6ec4ef..a526a7a82 100644
--- a/pandas/sparse/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -14,8 +14,9 @@ from pandas.util.testing import (assert_almost_equal, assert_series_equal,
                                  assert_frame_equal, assert_panel_equal)
 from numpy.testing import assert_equal
 
-from pandas import Series, DataFrame, DateRange, Panel
+from pandas import Series, DataFrame, bdate_range, Panel
 from pandas.core.datetools import BDay
+from pandas.core.index import DatetimeIndex
 import pandas.core.datetools as datetools
 import pandas.util.testing as tm
 
@@ -109,7 +110,7 @@ class TestSparseSeries(TestCase,
     def setUp(self):
         arr, index = _test_data1()
 
-        date_index = DateRange('1/1/2011', periods=len(index))
+        date_index = bdate_range('1/1/2011', periods=len(index))
 
         self.bseries = SparseSeries(arr, index=index, kind='block')
         self.bseries.name = 'bseries'
@@ -196,7 +197,7 @@ class TestSparseSeries(TestCase,
         assert_sp_series_equal(s4, self.zbseries)
 
         # Sparse time series works
-        date_index = DateRange('1/1/2000', periods=len(self.bseries))
+        date_index = bdate_range('1/1/2000', periods=len(self.bseries))
         s5 = SparseSeries(self.bseries, index=date_index)
         self.assert_(isinstance(s5, SparseTimeSeries))
 
@@ -629,11 +630,11 @@ class TestSparseSeries(TestCase,
         _dense_series_compare(series, f)
 
         series = SparseSeries([nan, 1., 2., 3., nan, nan],
-                              index=DateRange('1/1/2000', periods=6))
-        f = lambda s: s.shift(2, timeRule='WEEKDAY')
+                              index=bdate_range('1/1/2000', periods=6))
+        f = lambda s: s.shift(2, freq='B')
         _dense_series_compare(series, f)
 
-        f = lambda s: s.shift(2, offset=datetools.bday)
+        f = lambda s: s.shift(2, freq=datetools.bday)
         _dense_series_compare(series, f)
 
     def test_cumsum(self):
@@ -672,7 +673,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
                      'C' : np.arange(10),
                      'D' : [0, 1, 2, 3, 4, 5, nan, nan, nan, nan]}
 
-        self.dates = DateRange('1/1/2011', periods=10)
+        self.dates = bdate_range('1/1/2011', periods=10)
 
         self.frame = SparseDataFrame(self.data, index=self.dates)
         self.iframe = SparseDataFrame(self.data, index=self.dates,
@@ -872,6 +873,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         self.assert_(not empty)
 
         foo = self.frame + self.empty
+        self.assert_(isinstance(foo.index, DatetimeIndex))
         assert_frame_equal(foo, self.frame * np.nan)
 
         foo = self.empty + self.frame
@@ -1143,7 +1145,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         self.assert_('G' not in self.frame)
 
     def test_reindex_fill_value(self):
-        rng = DateRange('20110110', periods=20)
+        rng = bdate_range('20110110', periods=20)
         result = self.zframe.reindex(rng, fill_value=0)
         expected = self.zframe.reindex(rng).fillna(0)
         assert_sp_frame_equal(result, expected)
@@ -1207,10 +1209,10 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
             f = lambda s: s.shift(-2)
             _dense_frame_compare(frame, f)
 
-            f = lambda s: s.shift(2, timeRule='WEEKDAY')
+            f = lambda s: s.shift(2, freq='B')
             _dense_frame_compare(frame, f)
 
-            f = lambda s: s.shift(2, offset=datetools.bday)
+            f = lambda s: s.shift(2, freq=datetools.bday)
             _dense_frame_compare(frame, f)
 
         self._check_all(_check)
@@ -1274,7 +1276,7 @@ def _dense_frame_compare(frame, f):
     assert_frame_equal(result.to_dense(), dense_result)
 
 def panel_data1():
-    index = DateRange('1/1/2011', periods=8)
+    index = bdate_range('1/1/2011', periods=8)
 
     return DataFrame({
         'A' : [nan, nan, nan, 0, 1, 2, 3, 4],
@@ -1285,7 +1287,7 @@ def panel_data1():
 
 
 def panel_data2():
-    index = DateRange('1/1/2011', periods=9)
+    index = bdate_range('1/1/2011', periods=9)
 
     return DataFrame({
         'A' : [nan, nan, nan, 0, 1, 2, 3, 4, 5],
@@ -1296,7 +1298,7 @@ def panel_data2():
 
 
 def panel_data3():
-    index = DateRange('1/1/2011', periods=10).shift(-2)
+    index = bdate_range('1/1/2011', periods=10).shift(-2)
 
     return DataFrame({
         'A' : [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],
diff --git a/pandas/src/datetime.pyx b/pandas/src/datetime.pyx
index 0a0168492..d56e1a1fd 100644
--- a/pandas/src/datetime.pyx
+++ b/pandas/src/datetime.pyx
@@ -13,6 +13,8 @@ from libc.math cimport floor
 from datetime cimport *
 from util cimport is_integer_object, is_datetime64_object
 
+from dateutil.parser import parse as parse_date
+
 # initialize numpy
 import_array()
 import_ufunc()
@@ -38,8 +40,18 @@ ctypedef enum time_res:
 # Python front end to C extension type _Timestamp
 # This serves as the box for datetime64
 class Timestamp(_Timestamp):
-    def __new__(cls, object ts_input, object offset=None, tzinfo=None):
-        ts = convert_to_tsobject(ts_input, tzinfo)
+    def __new__(cls, object ts_input, object offset=None, tz=None):
+        if isinstance(ts_input, float):
+            # to do, do we want to support this, ie with fractional seconds?
+            raise TypeError("Cannot convert a float to datetime")
+
+        if isinstance(ts_input, basestring):
+            try:
+                ts_input = parse_date(ts_input)
+            except Exception:
+                pass
+
+        ts = convert_to_tsobject(ts_input, tz)
 
         # make datetime happy
         ts_base = _Timestamp.__new__(
@@ -59,6 +71,13 @@ class Timestamp(_Timestamp):
 
         return ts_base
 
+    @property
+    def tz(self):
+        """
+        Alias for tzinfo
+        """
+        return self.tzinfo
+
     @property
     def freq(self):
         return self.offset
@@ -72,6 +91,17 @@ class Timestamp(_Timestamp):
         object_state = self.value, self.offset, self.tzinfo
         return (Timestamp, object_state)
 
+    def to_interval(self, freq=None):
+        """
+        Return an interval of which this timestamp is an observation.
+        """
+        from pandas.core.datetools import Interval
+
+        if freq == None:
+            freq = self.freq
+
+        return Interval(self, freq=freq)
+
 
 # This is PITA. Because we inherit from datetime, which has very specific
 # construction requirements, we need to do object instantiation in python
@@ -786,7 +816,7 @@ def fast_field_accessor(ndarray[int64_t] dtindex, object field):
         int isleap
         npy_datetimestruct dts
 
-    _month_offset = np.array( 
+    _month_offset = np.array(
         [[ 0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365 ],
          [ 0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366 ]],
          dtype=np.int32 )
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index 7cd336d4b..76dfb007d 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -408,9 +408,15 @@ def backfill_2d_inplace_%(name)s(ndarray[%(c_type)s, ndim=2] values,
 is_monotonic_template = """@cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_%(name)s(ndarray[%(c_type)s] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         %(c_type)s prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -421,10 +427,11 @@ def is_monotonic_%(name)s(ndarray[%(c_type)s] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 """
 
 map_indices_template = """@cython.wraparound(False)
@@ -748,28 +755,24 @@ def generate_put_functions():
     return output.getvalue()
 
 
-# name, ctype, capable of holding NA, NA representation
+# name, ctype, capable of holding NA
 function_list = [
-    ('float64', 'float64_t', 'np.float64', True, 'NaN'),
-    ('object', 'object', 'object', True, 'NaN'),
-    ('int32', 'int32_t', 'np.int32', False, ''),
-    ('int64', 'int64_t', 'np.int64', False, ''),
-    ('bool', 'uint8_t', 'np.bool', False, ''),
+    ('float64', 'float64_t', 'np.float64', True),
+    ('object', 'object', 'object', True),
+    ('int32', 'int32_t', 'np.int32', False),
+    ('int64', 'int64_t', 'np.int64', False),
+    ('bool', 'uint8_t', 'np.bool', False)
 ]
 
 def generate_from_template(template, ndim=1, exclude=None):
     output = StringIO()
-    for name, c_type, dtype, can_hold_na, na_val in function_list:
+    for name, c_type, dtype, can_hold_na in function_list:
         if exclude is not None and name in exclude:
             continue
 
-        if ndim == 1:
-            na_action = set_na(na=na_val) if can_hold_na else raise_on_na
-        elif ndim == 2:
-            na_action = set_na_2d(na=na_val) if can_hold_na else raise_on_na
-
-        func = template % {'name' : name, 'c_type' : c_type,
-                           'dtype' : dtype, 'na_action' : na_action}
+        func = template % {'name': name, 'c_type': c_type,
+                           'dtype': dtype,
+                           'raise_on_na': 'False' if can_hold_na else 'True'}
         output.write(func)
     return output.getvalue()
 
diff --git a/pandas/src/generated.pyx b/pandas/src/generated.pyx
index e07fbead5..4956d1cea 100644
--- a/pandas/src/generated.pyx
+++ b/pandas/src/generated.pyx
@@ -1088,9 +1088,15 @@ def take_1d_bool(ndarray[uint8_t] values, ndarray[int32_t] indexer,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_float64(ndarray[float64_t] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         float64_t prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -1101,16 +1107,23 @@ def is_monotonic_float64(ndarray[float64_t] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_object(ndarray[object] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         object prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -1121,16 +1134,23 @@ def is_monotonic_object(ndarray[object] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_int32(ndarray[int32_t] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         int32_t prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -1141,16 +1161,23 @@ def is_monotonic_int32(ndarray[int32_t] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_int64(ndarray[int64_t] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         int64_t prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -1161,16 +1188,23 @@ def is_monotonic_int64(ndarray[int64_t] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def is_monotonic_bool(ndarray[uint8_t] arr):
+    '''
+    Returns
+    -------
+    is_monotonic, is_unique
+    '''
     cdef:
         Py_ssize_t i, n
         uint8_t prev, cur
+        bint is_unique = 1
 
     n = len(arr)
 
@@ -1181,10 +1215,11 @@ def is_monotonic_bool(ndarray[uint8_t] arr):
     for i in range(1, n):
         cur = arr[i]
         if cur < prev:
-            return False
+            return False, None
+        elif cur == prev:
+            is_unique = 0
         prev = cur
-    return True
-
+    return True, is_unique
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
diff --git a/pandas/stats/tests/common.py b/pandas/stats/tests/common.py
index 7f4357f72..b2060d30e 100644
--- a/pandas/stats/tests/common.py
+++ b/pandas/stats/tests/common.py
@@ -7,13 +7,13 @@ import nose
 
 import numpy as np
 
-from pandas.core.api import DataFrame, DateRange
+from pandas import DataFrame, bdate_range
 from pandas.util.testing import assert_almost_equal # imported in other tests
 N = 100
 K = 4
 
 start = datetime(2007, 1, 1)
-DATE_RANGE = DateRange(start, periods=N)
+DATE_RANGE = bdate_range(start, periods=N)
 
 COLS = ['Col' + c for c in string.ascii_uppercase[:K]]
 
diff --git a/pandas/stats/tests/test_moments.py b/pandas/stats/tests/test_moments.py
index a68193e2a..a905f1512 100644
--- a/pandas/stats/tests/test_moments.py
+++ b/pandas/stats/tests/test_moments.py
@@ -5,7 +5,7 @@ from datetime import datetime
 from numpy.random import randn
 import numpy as np
 
-from pandas.core.api import Series, DataFrame, DateRange
+from pandas import Series, DataFrame, bdate_range
 from pandas.util.testing import assert_almost_equal
 import pandas.core.datetools as datetools
 import pandas.stats.moments as mom
@@ -23,7 +23,7 @@ class TestMoments(unittest.TestCase):
         arr[self._nan_locs] = np.NaN
 
         self.arr = arr
-        self.rng = DateRange(datetime(2009, 1, 1), periods=N)
+        self.rng = bdate_range(datetime(2009, 1, 1), periods=N)
 
         self.series = Series(arr.copy(), index=self.rng)
 
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index a92d28397..fa484ff4a 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -11,8 +11,9 @@ import unittest
 import nose
 import numpy as np
 
+from pandas import date_range, bdate_range
 from pandas.core.panel import Panel
-from pandas import DataFrame, Index, DateRange, Series, notnull, datetools
+from pandas import DataFrame, Index, Series, notnull, datetools
 from pandas.stats.api import ols
 from pandas.stats.ols import _filter_data
 from pandas.stats.plm import NonPooledPanelOLS, PanelOLS
@@ -705,23 +706,23 @@ def _period_slice(panelModel, i):
 class TestOLSFilter(unittest.TestCase):
 
     def setUp(self):
-        date_index = DateRange(datetime(2009, 12, 11), periods=3,
-                               offset=datetools.bday)
+        date_index = date_range(datetime(2009, 12, 11), periods=3,
+                                freq=datetools.bday)
         ts = Series([3, 1, 4], index=date_index)
         self.TS1 = ts
 
-        date_index = DateRange(datetime(2009, 12, 11), periods=5,
-                               offset=datetools.bday)
+        date_index = date_range(datetime(2009, 12, 11), periods=5,
+                                freq=datetools.bday)
         ts = Series([1, 5, 9, 2, 6], index=date_index)
         self.TS2 = ts
 
-        date_index = DateRange(datetime(2009, 12, 11), periods=3,
-                               offset=datetools.bday)
+        date_index = date_range(datetime(2009, 12, 11), periods=3,
+                                freq=datetools.bday)
         ts = Series([5, np.nan, 3], index=date_index)
         self.TS3 = ts
 
-        date_index = DateRange(datetime(2009, 12, 11), periods=5,
-                               offset=datetools.bday)
+        date_index = date_range(datetime(2009, 12, 11), periods=5,
+                                freq=datetools.bday)
         ts = Series([np.nan, 5, 8, 9, 7], index=date_index)
         self.TS4 = ts
 
diff --git a/pandas/tests/test_daterange.py b/pandas/tests/test_daterange.py
index 23cf074d2..5925a8a3a 100644
--- a/pandas/tests/test_daterange.py
+++ b/pandas/tests/test_daterange.py
@@ -7,7 +7,7 @@ import numpy as np
 import pandas.core.datetools as datetools
 from pandas.core.datetools import generate_range
 from pandas.core.index import Index, DatetimeIndex
-from pandas.core.daterange import DateRange
+from pandas.core.daterange import bdate_range, date_range
 import pandas.util.testing as tm
 
 import pandas._tseries as lib
@@ -17,63 +17,66 @@ try:
 except ImportError:
     pass
 
-def eqXDateRange(kwargs, expected):
+def eq_gen_range(kwargs, expected):
     rng = generate_range(**kwargs)
     assert(np.array_equal(list(rng), expected))
 
 START, END = datetime(2009, 1, 1), datetime(2010, 1, 1)
 
-class TestDateRangeGeneration(unittest.TestCase):
+class TestGenRangeGeneration(unittest.TestCase):
     def test_generate(self):
         rng1 = list(generate_range(START, END, offset=datetools.bday))
         rng2 = list(generate_range(START, END, time_rule='WEEKDAY'))
         self.assert_(np.array_equal(rng1, rng2))
 
     def test_1(self):
-        eqXDateRange(dict(start=datetime(2009, 3, 25), periods=2),
+        eq_gen_range(dict(start=datetime(2009, 3, 25), periods=2),
                      [datetime(2009, 3, 25), datetime(2009, 3, 26)])
 
     def test_2(self):
-        eqXDateRange(dict(start=datetime(2008, 1, 1),
+        eq_gen_range(dict(start=datetime(2008, 1, 1),
                           end=datetime(2008, 1, 3)),
                      [datetime(2008, 1, 1),
                       datetime(2008, 1, 2),
                       datetime(2008, 1, 3)])
 
     def test_3(self):
-        eqXDateRange(dict(start = datetime(2008, 1, 5),
+        eq_gen_range(dict(start = datetime(2008, 1, 5),
                           end = datetime(2008, 1, 6)),
                      [])
 
 class TestDateRange(unittest.TestCase):
 
     def setUp(self):
-        self.rng = DateRange(START, END, offset=datetools.bday)
+        self.rng = bdate_range(START, END)
 
     def test_constructor(self):
-        rng = DateRange(START, END, offset=datetools.bday)
-        rng = DateRange(START, periods=20, offset=datetools.bday)
-        rng = DateRange(end=START, periods=20, offset=datetools.bday)
+        rng = bdate_range(START, END, freq=datetools.bday)
+        rng = bdate_range(START, periods=20, freq=datetools.bday)
+        rng = bdate_range(end=START, periods=20, freq=datetools.bday)
 
     def test_cached_range(self):
-        rng = DateRange._cached_range(START, END, offset=datetools.bday)
-        rng = DateRange._cached_range(START, periods=20, offset=datetools.bday)
-        rng = DateRange._cached_range(end=START, periods=20, offset=datetools.bday)
+        rng = DatetimeIndex._cached_range(START, END,
+                                          offset=datetools.bday)
+        rng = DatetimeIndex._cached_range(START, periods=20,
+                                          offset=datetools.bday)
+        rng = DatetimeIndex._cached_range(end=START, periods=20,
+                                          offset=datetools.bday)
 
-        self.assertRaises(Exception, DateRange._cached_range, START, END)
+        self.assertRaises(Exception, DatetimeIndex._cached_range, START, END)
 
-        self.assertRaises(Exception, DateRange._cached_range, START,
-                          offset=datetools.bday)
+        self.assertRaises(Exception, DatetimeIndex._cached_range, START,
+                          freq=datetools.bday)
 
-        self.assertRaises(Exception, DateRange._cached_range, end=END,
-                          offset=datetools.bday)
+        self.assertRaises(Exception, DatetimeIndex._cached_range, end=END,
+                          freq=datetools.bday)
 
-        self.assertRaises(Exception, DateRange._cached_range, periods=20,
-                          offset=datetools.bday)
+        self.assertRaises(Exception, DatetimeIndex._cached_range, periods=20,
+                          freq=datetools.bday)
 
     def test_cached_range_bug(self):
-        rng = DateRange('2010-09-01 05:00:00', periods=50,
-                        offset=datetools.DateOffset(hours=6))
+        rng = date_range('2010-09-01 05:00:00', periods=50,
+                         freq=datetools.DateOffset(hours=6))
         self.assertEquals(len(rng), 50)
         self.assertEquals(rng[0], datetime(2010, 9, 1, 5))
 
@@ -103,7 +106,8 @@ class TestDateRange(unittest.TestCase):
 
         fancy_indexed = self.rng[[4, 3, 2, 1, 0]]
         self.assertEquals(len(fancy_indexed), 5)
-        self.assert_(not isinstance(fancy_indexed, DateRange))
+        self.assert_(isinstance(fancy_indexed, DatetimeIndex))
+        self.assert_(fancy_indexed.freq is None)
 
         # 32-bit vs. 64-bit platforms
         self.assertEquals(self.rng[4], self.rng[np.int_(4)])
@@ -126,7 +130,7 @@ class TestDateRange(unittest.TestCase):
         self.assertEquals(shifted[0], self.rng[0])
         self.assertEquals(shifted.offset, self.rng.offset)
 
-        rng = DateRange(START, END, offset=datetools.bmonthEnd)
+        rng = date_range(START, END, freq=datetools.bmonthEnd)
         shifted = rng.shift(1, freq=datetools.bday)
         self.assertEquals(shifted[0], rng[0] + datetools.bday)
 
@@ -142,7 +146,7 @@ class TestDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DateRange))
+        self.assert_(isinstance(the_union, DatetimeIndex))
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
@@ -156,49 +160,51 @@ class TestDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DateRange))
+        self.assert_(isinstance(the_union, DatetimeIndex))
 
         # order does not matter
         self.assert_(np.array_equal(right.union(left), the_union))
 
         # overlapping, but different offset
-        rng = DateRange(START, END, offset=datetools.bmonthEnd)
+        rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_union = self.rng.union(rng)
-        self.assert_(isinstance(the_union, DateRange))
+        self.assert_(isinstance(the_union, DatetimeIndex))
 
     def test_outer_join(self):
-        """ should behave just as union test"""
+        # should just behave as union
+
         # overlapping
         left = self.rng[:10]
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DateRange))
+        self.assert_(isinstance(the_join, DatetimeIndex))
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
         right = self.rng[10:]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, Index))
-        self.assert_(not isinstance(the_join, DateRange))
+        self.assert_(isinstance(the_join, DatetimeIndex))
+        self.assert_(the_join.freq is None)
 
         # non-overlapping, no gap
         left = self.rng[:5]
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DateRange))
+        self.assert_(isinstance(the_join, DatetimeIndex))
 
         # overlapping, but different offset
-        rng = DateRange(START, END, offset=datetools.bmonthEnd)
+        rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_join = self.rng.join(rng, how='outer')
-        self.assert_(not isinstance(the_join, DateRange))
+        self.assert_(isinstance(the_join, DatetimeIndex))
+        self.assert_(the_join.freq is None)
 
     def test_union_not_cacheable(self):
-        rng = DateRange('1/1/2000', periods=50, offset=datetools.Minute())
+        rng = date_range('1/1/2000', periods=50, freq=datetools.Minute())
         rng1 = rng[10:]
         rng2 = rng[:25]
         the_union = rng1.union(rng2)
@@ -211,16 +217,16 @@ class TestDateRange(unittest.TestCase):
         self.assert_(the_union.equals(expected))
 
     def test_intersection(self):
-        rng = DateRange('1/1/2000', periods=50, offset=datetools.Minute())
+        rng = date_range('1/1/2000', periods=50, freq=datetools.Minute())
         rng1 = rng[10:]
         rng2 = rng[:25]
         the_int = rng1.intersection(rng2)
         expected = rng[10:25]
         self.assert_(the_int.equals(expected))
-        self.assert_(isinstance(the_int, DateRange))
+        self.assert_(isinstance(the_int, DatetimeIndex))
         self.assert_(the_int.offset == rng.offset)
 
-        the_int = rng1.intersection(rng2.view(DateRange))
+        the_int = rng1.intersection(rng2.view(DatetimeIndex))
         self.assert_(the_int.equals(expected))
 
         # non-overlapping
@@ -230,46 +236,46 @@ class TestDateRange(unittest.TestCase):
 
     def test_intersection_bug(self):
         # GH #771
-        a = DateRange('11/30/2011','12/31/2011')
-        b = DateRange('12/10/2011','12/20/2011')
+        a = bdate_range('11/30/2011','12/31/2011')
+        b = bdate_range('12/10/2011','12/20/2011')
         result = a.intersection(b)
         self.assert_(result.equals(b))
 
-    def test_with_tzinfo(self):
+    def test_with_tz(self):
         _skip_if_no_pytz()
         tz = pytz.timezone('US/Central')
 
         # just want it to work
         start = datetime(2011, 3, 12, tzinfo=pytz.utc)
-        dr = DateRange(start, periods=50, offset=datetools.Hour())
-        self.assert_(dr.tzinfo is not None)
-        self.assert_(dr.tzinfo is start.tzinfo)
+        dr = bdate_range(start, periods=50, freq=datetools.Hour())
+        self.assert_(dr.tz is not None)
+        self.assert_(dr.tz is start.tzinfo)
 
         # DateRange with naive datetimes
-        dr = DateRange('1/1/2005', '1/1/2009', tzinfo=pytz.utc)
-        dr = DateRange('1/1/2005', '1/1/2009', tzinfo=tz)
+        dr = bdate_range('1/1/2005', '1/1/2009', tz=pytz.utc)
+        dr = bdate_range('1/1/2005', '1/1/2009', tz=tz)
 
         # normalized
         central = dr.tz_normalize(tz)
-        self.assert_(central.tzinfo is tz)
-        self.assert_(central[0].tzinfo is tz)
+        self.assert_(central.tz is tz)
+        self.assert_(central[0].tz is tz)
 
         # datetimes with tzinfo set
-        dr = DateRange(datetime(2005, 1, 1, tzinfo=pytz.utc),
-                       '1/1/2009', tzinfo=pytz.utc)
+        dr = bdate_range(datetime(2005, 1, 1, tzinfo=pytz.utc),
+                         '1/1/2009', tz=pytz.utc)
 
-        self.assertRaises(Exception, DateRange,
+        self.assertRaises(Exception, bdate_range,
                           datetime(2005, 1, 1, tzinfo=pytz.utc),
-                          '1/1/2009', tzinfo=tz)
+                          '1/1/2009', tz=tz)
 
     def test_tz_localize(self):
         _skip_if_no_pytz()
-        dr = DateRange('1/1/2009', '1/1/2010')
-        dr_utc = DateRange('1/1/2009', '1/1/2010', tzinfo=pytz.utc)
+        dr = bdate_range('1/1/2009', '1/1/2010')
+        dr_utc = bdate_range('1/1/2009', '1/1/2010', tz=pytz.utc)
         localized = dr.tz_localize(pytz.utc)
         self.assert_(np.array_equal(dr_utc, localized))
 
-    def test_with_tzinfo_ambiguous_times(self):
+    def test_with_tz_ambiguous_times(self):
         _skip_if_no_pytz()
         tz = pytz.timezone('US/Eastern')
 
@@ -277,36 +283,36 @@ class TestDateRange(unittest.TestCase):
         self.assert_(self.rng.tz_validate())
 
         # March 13, 2011, spring forward, skip from 2 AM to 3 AM
-        dr = DateRange(datetime(2011, 3, 13, 1, 30), periods=3,
-                       offset=datetools.Hour(), tzinfo=tz)
+        dr = date_range(datetime(2011, 3, 13, 1, 30), periods=3,
+                        freq=datetools.Hour(), tz=tz)
         self.assert_(not dr.tz_validate())
 
         # after dst transition
-        dr = DateRange(datetime(2011, 3, 13, 3, 30), periods=3,
-                       offset=datetools.Hour(), tzinfo=tz)
+        dr = date_range(datetime(2011, 3, 13, 3, 30), periods=3,
+                        freq=datetools.Hour(), tz=tz)
         self.assert_(dr.tz_validate())
 
         # November 6, 2011, fall back, repeat 2 AM hour
-        dr = DateRange(datetime(2011, 11, 6, 1, 30), periods=3,
-                       offset=datetools.Hour(), tzinfo=tz)
+        dr = date_range(datetime(2011, 11, 6, 1, 30), periods=3,
+                        freq=datetools.Hour(), tz=tz)
         self.assert_(not dr.tz_validate())
 
         # UTC is OK
-        dr = DateRange(datetime(2011, 3, 13), periods=48,
-                       offset=datetools.Minute(30), tzinfo=pytz.utc)
+        dr = date_range(datetime(2011, 3, 13), periods=48,
+                        freq=datetools.Minute(30), tz=pytz.utc)
         self.assert_(dr.tz_validate())
 
     def test_summary(self):
         self.rng.summary()
         self.rng[2:2].summary()
         try:
-            DateRange('1/1/2005', '1/1/2009', tzinfo=pytz.utc).summary()
+            bdate_range('1/1/2005', '1/1/2009', tz=pytz.utc).summary()
         except Exception:
             pass
 
     def test_misc(self):
         end = datetime(2009, 5, 13)
-        dr = DateRange(end=end, periods=20)
+        dr = bdate_range(end=end, periods=20)
         firstDate = end - 19 * datetools.bday
 
         assert len(dr) == 20
@@ -314,7 +320,7 @@ class TestDateRange(unittest.TestCase):
         assert dr[-1] == end
 
     # test utility methods
-    def test_infer_tzinfo(self):
+    def test_infer_tz(self):
         _skip_if_no_pytz()
         eastern = pytz.timezone('US/Eastern')
         utc = pytz.utc
@@ -338,11 +344,11 @@ class TestDateRange(unittest.TestCase):
 
     def test_date_parse_failure(self):
         badly_formed_date = '2007/100/1'
-        self.assertRaises(ValueError, DateRange, start=badly_formed_date,
+        self.assertRaises(ValueError, bdate_range, start=badly_formed_date,
                           periods=10)
-        self.assertRaises(ValueError, DateRange, end=badly_formed_date,
+        self.assertRaises(ValueError, bdate_range, end=badly_formed_date,
                           periods=10)
-        self.assertRaises(ValueError, DateRange, badly_formed_date,
+        self.assertRaises(ValueError, bdate_range, badly_formed_date,
                           badly_formed_date)
 
     def test_equals(self):
@@ -350,21 +356,21 @@ class TestDateRange(unittest.TestCase):
 
     def test_daterange_bug_456(self):
         # GH #456
-        rng1 = DateRange('12/5/2011', '12/5/2011')
-        rng2 = DateRange('12/2/2011', '12/5/2011')
+        rng1 = bdate_range('12/5/2011', '12/5/2011')
+        rng2 = bdate_range('12/2/2011', '12/5/2011')
         rng2.offset = datetools.BDay()
 
         result = rng1.union(rng2)
-        self.assert_(type(result) == DateRange)
+        self.assert_(isinstance(result, DatetimeIndex))
 
     def test_error_with_zero_monthends(self):
-        self.assertRaises(ValueError, DateRange, '1/1/2000', '1/1/2001',
-                          offset=datetools.MonthEnd(0))
+        self.assertRaises(ValueError, date_range, '1/1/2000', '1/1/2001',
+                          freq=datetools.MonthEnd(0))
 
     def test_range_bug(self):
         # GH #770
         offset = datetools.DateOffset(months=3)
-        result = DateRange("2011-1-1", "2012-1-31", offset=offset)
+        result = date_range("2011-1-1", "2012-1-31", freq=offset)
 
         start = datetime(2011, 1, 1)
         exp_values = [start + i * offset for i in range(5)]
@@ -543,7 +549,7 @@ class TestDatetimePyx(unittest.TestCase):
     def test_dayofmonthoffset(self):
         for week in (-1, 0, 1):
             for day in (0, 2, 4):
-                off = lib.DayOfMonthOffset(week=-1, day=day, 
+                off = lib.DayOfMonthOffset(week=-1, day=day,
                                            anchor=datetime(2002,1,1))
 
                 stack = []
@@ -551,7 +557,7 @@ class TestDatetimePyx(unittest.TestCase):
                 for i in range(500):
                     t = lib.Timestamp(off.ts)
                     stack.append(t)
-                    self.assert_(t.weekday() == day) 
+                    self.assert_(t.weekday() == day)
                     off.next()
 
                 for i in range(499, -1, -1):
@@ -563,8 +569,8 @@ class TestDatetimePyx(unittest.TestCase):
     def test_catch_infinite_loop(self):
         offset = datetools.DateOffset(minute=5)
         # blow up, don't loop forever
-        self.assertRaises(Exception, DateRange, datetime(2011,11,11),
-                          datetime(2011,11,12), offset=offset)
+        self.assertRaises(Exception, date_range, datetime(2011,11,11),
+                          datetime(2011,11,12), freq=offset)
 
 def _skip_if_no_pytz():
     try:
diff --git a/pandas/tests/test_datetime64.py b/pandas/tests/test_datetime64.py
index d5ac8359d..258473a86 100644
--- a/pandas/tests/test_datetime64.py
+++ b/pandas/tests/test_datetime64.py
@@ -3,10 +3,9 @@ from datetime import datetime
 
 import cPickle as pickle
 
-from pandas.core.index import DatetimeIndex
+from pandas.core.index import DatetimeIndex, Index
 from pandas.core.frame import DataFrame
 
-from pandas.core.daterange import DateRange
 from pandas.core.index import Int64Index
 
 import unittest
@@ -19,7 +18,7 @@ from numpy.random import rand
 from pandas.util.testing import assert_series_equal, assert_frame_equal
 
 from pandas.core.groupby import Tinterval
-from pandas.core.datetools import Minute, BDay
+from pandas.core.datetools import Minute, BDay, Timestamp
 
 try:
     import pytz
@@ -214,7 +213,7 @@ class TestDatetime64(unittest.TestCase):
     def test_dayofmonthoffset(self):
         for week in (-1, 0, 1):
             for day in (0, 2, 4):
-                off = lib.DayOfMonthOffset(week=-1, day=day, 
+                off = lib.DayOfMonthOffset(week=-1, day=day,
                                            anchor=datetime(2002,1,1))
 
                 stack = []
@@ -222,7 +221,7 @@ class TestDatetime64(unittest.TestCase):
                 for i in range(500):
                     t = lib.Timestamp(off.ts)
                     stack.append(t)
-                    self.assert_(t.weekday() == day) 
+                    self.assert_(t.weekday() == day)
                     off.next()
 
                 for i in range(499, -1, -1):
@@ -276,14 +275,14 @@ class TestDatetime64(unittest.TestCase):
         dti = DatetimeIndex(freq='WOM@1FRI', start=datetime(2005,1,1),
                             end=datetime(2010,1,1))
 
-        s = Series(np.arange(len(dti)), index=dti) 
+        s = Series(np.arange(len(dti)), index=dti)
 
         self.assertEquals(s[48], 48)
         self.assertEquals(s['1/2/2009'], 48)
         self.assertEquals(s['2009-1-2'], 48)
         self.assertEquals(s[datetime(2009,1,2)], 48)
         self.assertEquals(s[lib.Timestamp(datetime(2009,1,2))], 48)
-        self.assertRaises(KeyError, s.__getitem__, '2009-1-3') 
+        self.assertRaises(KeyError, s.__getitem__, '2009-1-3')
 
         assert_series_equal(s['3/6/2009':'2009-06-05'],
                             s[datetime(2009,3,6):datetime(2009,6,5)])
@@ -292,7 +291,7 @@ class TestDatetime64(unittest.TestCase):
         dti = DatetimeIndex(freq='WOM@1FRI', start=datetime(2005,1,1),
                             end=datetime(2010,1,1))
 
-        s = Series(np.arange(len(dti)), index=dti) 
+        s = Series(np.arange(len(dti)), index=dti)
         s[48] = -1
         self.assertEquals(s[48], -1)
         s['1/2/2009'] = -2
@@ -459,6 +458,14 @@ class TestDatetime64(unittest.TestCase):
                             freq='L')
         self.assertRaises(pytz.AmbiguousTimeError, dti.tz_localize, tz)
 
+    def test_asobject_tz_box(self):
+        tz = pytz.timezone('US/Eastern')
+        index = DatetimeIndex(start='1/1/2005', periods=10, tz=tz,
+                              freq='B')
+
+        result = index.asobject
+        self.assert_(result[0].tz is tz)
+
     def test_slice_year(self):
         dti = DatetimeIndex(freq='B', start=datetime(2005,1,1), periods=500)
 
@@ -491,27 +498,26 @@ class TestDatetime64(unittest.TestCase):
         unpickled = pickle.loads(f.read())
         f.close()
 
-        dtindex = DateRange(start='1/3/2005', end='1/14/2005',
-                            offset=BDay(1))
+        dtindex = DatetimeIndex(start='1/3/2005', end='1/14/2005',
+                                freq=BDay(1))
 
-        self.assertEquals(type(unpickled.index), DateRange)
+        self.assertEquals(type(unpickled.index), DatetimeIndex)
         self.assertEquals(len(unpickled), 10)
         self.assert_((unpickled.columns == Int64Index(np.arange(5))).all())
         self.assert_((unpickled.index == dtindex).all())
         self.assertEquals(unpickled.index.offset, BDay(1))
 
     def test_unpickle_legacy_series(self):
-        from pandas.core.daterange import DateRange
         from pandas.core.datetools import BDay
 
         f = open('pandas/tests/data/series.pickle', 'r')
         unpickled = pickle.loads(f.read())
         f.close()
 
-        dtindex = DateRange(start='1/3/2005', end='1/14/2005',
-                            offset=BDay(1))
+        dtindex = DatetimeIndex(start='1/3/2005', end='1/14/2005',
+                                freq=BDay(1))
 
-        self.assertEquals(type(unpickled.index), DateRange)
+        self.assertEquals(type(unpickled.index), DatetimeIndex)
         self.assertEquals(len(unpickled), 10)
         self.assert_((unpickled.index == dtindex).all())
         self.assertEquals(unpickled.index.offset, BDay(1))
@@ -546,8 +552,6 @@ class TestDatetime64(unittest.TestCase):
             self.assert_( (idx1.values == other.values).all() )
 
     def test_dti_slicing(self):
-        from pandas.core.datetools import Ts
-
         dti = DatetimeIndex(start='1/1/2005', end='12/1/2005', freq='M')
         dti2 = dti[[1,3,5]]
 
@@ -555,9 +559,9 @@ class TestDatetime64(unittest.TestCase):
         v2 = dti2[1]
         v3 = dti2[2]
 
-        self.assertEquals(v1, Ts('2/28/2005'))
-        self.assertEquals(v2, Ts('4/30/2005'))
-        self.assertEquals(v3, Ts('6/30/2005'))
+        self.assertEquals(v1, Timestamp('2/28/2005'))
+        self.assertEquals(v2, Timestamp('4/30/2005'))
+        self.assertEquals(v3, Timestamp('6/30/2005'))
 
         # don't carry freq through irregular slicing
         self.assertEquals(dti2.freq, None)
@@ -573,7 +577,7 @@ class TestDatetime64(unittest.TestCase):
 
         res = dti.snap(freq='W@MON')
 
-        exp = DatetimeIndex(['12/31/2001', '12/31/2001', '12/31/2001', 
+        exp = DatetimeIndex(['12/31/2001', '12/31/2001', '12/31/2001',
                              '1/7/2002', '1/7/2002', '1/7/2002', '1/7/2002'],
                              freq='W@MON')
 
@@ -594,6 +598,17 @@ class TestDatetime64(unittest.TestCase):
         d3 = d2.set_index('index')
         assert_frame_equal(d1, d3)
 
+    def test_datetimeindex_union_join_empty(self):
+        dti = DatetimeIndex(start='1/1/2001', end='2/1/2001', freq='D')
+        empty = Index([])
+
+        result = dti.union(empty)
+        self.assert_(isinstance(result, DatetimeIndex))
+        self.assert_(result is result)
+
+        result = dti.join(empty)
+        self.assert_(isinstance(result, DatetimeIndex))
+
     # TODO: test merge & concat with datetime64 block
 
 if __name__ == '__main__':
diff --git a/pandas/tests/test_datetools.py b/pandas/tests/test_datetools.py
index a9bfcf72b..5d931e733 100644
--- a/pandas/tests/test_datetools.py
+++ b/pandas/tests/test_datetools.py
@@ -50,10 +50,9 @@ def test_normalize_date():
     assert actual == datetime(2007, 10, 1)
 
 def test_datetime64_unbox():
-    valb = datetime(2007,10,1)
+    valb = datetime(2007, 10, 1)
     valu = _dt_unbox(valb)
-    print valu
-    #assert type(valu) == np.datetime64
+    assert type(valu) == np.datetime64
     #assert valu == np.datetime64(datetime(2007,10,1))
 
 #def test_datetime64_box():
@@ -1256,8 +1255,8 @@ def test_inferTimeRule():
               datetime(2010, 3, 27, 0, 0),
               datetime(2010, 3, 29, 0, 0)]
 
-    assert inferTimeRule(index1) == 'EOM'
-    assert inferTimeRule(index2) == 'WEEKDAY'
+    assert inferTimeRule(index1) == 'BM'
+    assert inferTimeRule(index2) == 'B'
 
     assert_raises(Exception, inferTimeRule, index1[:2])
     assert_raises(Exception, inferTimeRule, index3)
@@ -1269,13 +1268,13 @@ def test_hasOffsetName():
 def test_getOffsetName():
     assert_raises(Exception, getOffsetName, BDay(2))
 
-    assert getOffsetName(BDay()) == 'WEEKDAY'
-    assert getOffsetName(BMonthEnd()) == 'EOM'
-    assert getOffsetName(Week(weekday=0)) == 'W@MON'
-    assert getOffsetName(Week(weekday=1)) == 'W@TUE'
+    assert getOffsetName(BDay()) in ['WEEKDAY', 'B']
+    assert getOffsetName(BMonthEnd()) in ['EOM', 'BM']
+    assert getOffsetName(Week(weekday=0)) in ['W@MON', 'WS']
+    assert getOffsetName(Week(weekday=1)) =='W@TUE'
     assert getOffsetName(Week(weekday=2)) == 'W@WED'
     assert getOffsetName(Week(weekday=3)) == 'W@THU'
-    assert getOffsetName(Week(weekday=4)) == 'W@FRI'
+    assert getOffsetName(Week(weekday=4)) in ['W@FRI', 'BW']
 
 
 def test_getOffset():
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 99ce8a017..4bfcc10ab 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1753,24 +1753,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         unpickled = pickle.loads(pickle.dumps(self.empty))
         repr(unpickled)
 
-    def test_unpickle_legacy_frame(self):
-        from pandas.core.daterange import DateRange
-        from pandas.core.datetools import BDay
-        from pandas.core.index import Int64Index
-
-        f = open('pandas/tests/data/frame.pickle', 'r')
-        unpickled = pickle.loads(f.read())
-        f.close()
-
-        dtindex = DateRange(start='1/3/2005', end='1/14/2005',
-                            offset=BDay(1))
-
-        self.assertEquals(type(unpickled.index), DateRange)
-        self.assertEquals(len(unpickled), 10)
-        self.assert_((unpickled.columns == Int64Index(np.arange(5))).all())
-        self.assert_((unpickled.index == dtindex).all())
-        self.assertEquals(unpickled.index.offset, BDay(1))
-
     def test_to_dict(self):
         test_data = {
                 'A' : {'1' : 1, '2' : 2},
@@ -2743,16 +2725,16 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         result = zero_length.asfreq('EOM')
         self.assert_(result is not zero_length)
 
-    def test_asfreq_DateRange(self):
-        from pandas.core.daterange import DateRange
+    def test_asfreq_datetimeindex(self):
+        from pandas import DatetimeIndex
         df = DataFrame({'A': [1,2,3]},
                        index=[datetime(2011,11,01), datetime(2011,11,2),
                               datetime(2011,11,3)])
         df = df.asfreq('WEEKDAY')
-        self.assert_(isinstance(df.index, DateRange))
+        self.assert_(isinstance(df.index, DatetimeIndex))
 
         ts = df['A'].asfreq('WEEKDAY')
-        self.assert_(isinstance(ts.index, DateRange))
+        self.assert_(isinstance(ts.index, DatetimeIndex))
 
     def test_as_matrix(self):
         frame = self.frame
@@ -3619,10 +3601,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(unshifted, self.tsframe)
 
         # shift by DateOffset
-        shiftedFrame = self.tsframe.shift(5, offset=datetools.BDay())
+        shiftedFrame = self.tsframe.shift(5, freq=datetools.BDay())
         self.assert_(len(shiftedFrame) == len(self.tsframe))
 
-        shiftedFrame2 = self.tsframe.shift(5, timeRule='WEEKDAY')
+        shiftedFrame2 = self.tsframe.shift(5, freq='WEEKDAY')
         assert_frame_equal(shiftedFrame, shiftedFrame2)
 
         d = self.tsframe.index[0]
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index a36df4aaf..e7d9140b0 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -4,7 +4,7 @@ import unittest
 from datetime import datetime
 from numpy import nan
 
-from pandas.core.daterange import DateRange
+from pandas import bdate_range
 from pandas.core.index import Index, MultiIndex
 from pandas.core.common import rands
 from pandas.core.frame import DataFrame
@@ -22,7 +22,7 @@ import numpy as np
 import pandas.util.testing as tm
 
 def commonSetUp(self):
-    self.dateRange = DateRange('1/1/2005', periods=250, offset=dt.bday)
+    self.dateRange = bdate_range('1/1/2005', periods=250)
     self.stringIndex = Index([rands(8).upper() for x in xrange(250)])
 
     self.groupId = Series([x[0] for x in self.stringIndex],
@@ -1081,7 +1081,7 @@ class TestGroupBy(unittest.TestCase):
         assert_almost_equal(grouped.grouper.labels[0], exp_labels)
 
     def test_cython_fail_agg(self):
-        dr = DateRange('1/1/2000', periods=50)
+        dr = bdate_range('1/1/2000', periods=50)
         ts = Series(['A', 'B', 'C', 'D', 'E'] * 10, index=dr)
 
         grouped = ts.groupby(lambda x: x.month)
@@ -1095,7 +1095,7 @@ class TestGroupBy(unittest.TestCase):
                               'demeaned' : piece - piece.mean(),
                               'logged' : np.log(piece)})
 
-        dr = DateRange('1/1/2000', periods=100)
+        dr = bdate_range('1/1/2000', periods=100)
         ts = Series(np.random.randn(100), index=dr)
 
         grouped = ts.groupby(lambda x: x.month)
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index ece38299e..b3a37807e 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -42,7 +42,7 @@ class TestIndex(unittest.TestCase):
 
     def test_duplicates(self):
         idx = Index([0, 0, 0])
-        self.assert_(not idx._verify_integrity())
+        self.assert_(not idx.is_unique)
         self.assertRaises(Exception, getattr, idx, 'indexMap')
 
     def test_sort(self):
diff --git a/pandas/tests/test_interval.py b/pandas/tests/test_interval.py
index e9f4562fb..e78ff5c93 100644
--- a/pandas/tests/test_interval.py
+++ b/pandas/tests/test_interval.py
@@ -78,12 +78,12 @@ class TestIntervalProperties(TestCase):
         self.assertEquals(i1, i2)
 
     def test_properties_annually(self):
-        "Test properties on Intervals with annually frequency."
+        # Test properties on Intervals with annually frequency.
         a_date = Interval(freq='A', year=2007)
         assert_equal(a_date.year, 2007)
 
     def test_properties_quarterly(self):
-        "Test properties on Intervals with daily frequency."
+        # Test properties on Intervals with daily frequency.
         qedec_date = Interval(freq="Q@DEC", year=2007, quarter=1)
         qejan_date = Interval(freq="Q@JAN", year=2007, quarter=1)
         qejun_date = Interval(freq="Q@JUN", year=2007, quarter=1)
@@ -95,7 +95,7 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_monthly(self):
-        "Test properties on Intervals with daily frequency."
+        # Test properties on Intervals with daily frequency.
         m_date = Interval(freq='M', year=2007, month=1)
         for x in range(11):
             m_ival_x = m_date + x
@@ -112,7 +112,7 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_weekly(self):
-        "Test properties on Intervals with daily frequency."
+        # Test properties on Intervals with daily frequency.
         w_date = Interval(freq='WK', year=2007, month=1, day=7)
         #
         assert_equal(w_date.year, 2007)
@@ -123,7 +123,7 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_daily(self):
-        "Test properties on Intervals with daily frequency."
+        # Test properties on Intervals with daily frequency.
         b_date = Interval(freq='B', year=2007, month=1, day=1)
         #
         assert_equal(b_date.year, 2007)
@@ -144,7 +144,7 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_hourly(self):
-        "Test properties on Intervals with hourly frequency."
+        # Test properties on Intervals with hourly frequency.
         h_date = Interval(freq='H', year=2007, month=1, day=1, hour=0)
         #
         assert_equal(h_date.year, 2007)
@@ -158,8 +158,8 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_minutely(self):
-        "Test properties on Intervals with minutely frequency."
-        t_date = Interval(freq='Min', year=2007, month=1, day=1, hour=0, 
+        # Test properties on Intervals with minutely frequency.
+        t_date = Interval(freq='Min', year=2007, month=1, day=1, hour=0,
                           minute=0)
         #
         assert_equal(t_date.quarter, 1)
@@ -172,7 +172,7 @@ class TestIntervalProperties(TestCase):
 
 
     def test_properties_secondly(self):
-        "Test properties on Intervals with secondly frequency."
+        # Test properties on Intervals with secondly frequency.
         s_date = Interval(freq='Min', year=2007, month=1, day=1,
                                        hour=0, minute=0, second=0)
         #
@@ -196,7 +196,7 @@ class TestFreqConversion(TestCase):
         TestCase.__init__(self, *args, **kwds)
 
     def test_conv_annual(self):
-        "frequency conversion tests: from Annual Frequency"
+        # frequency conversion tests: from Annual Frequency
 
         ival_A = Interval(freq='A', year=2007)
 
@@ -264,7 +264,7 @@ class TestFreqConversion(TestCase):
 
 
     def test_conv_quarterly(self):
-        "frequency conversion tests: from Quarterly Frequency"
+        # frequency conversion tests: from Quarterly Frequency
 
         ival_Q = Interval(freq='Q', year=2007, quarter=1)
         ival_Q_end_of_year = Interval(freq='Q', year=2007, quarter=4)
@@ -327,7 +327,7 @@ class TestFreqConversion(TestCase):
 
 
     def test_conv_monthly(self):
-        "frequency conversion tests: from Monthly Frequency"
+        # frequency conversion tests: from Monthly Frequency
 
         ival_M = Interval(freq='M', year=2007, month=1)
         ival_M_end_of_year = Interval(freq='M', year=2007, month=12)
@@ -375,7 +375,7 @@ class TestFreqConversion(TestCase):
 
 
     def test_conv_weekly(self):
-        "frequency conversion tests: from Weekly Frequency"
+        # frequency conversion tests: from Weekly Frequency
 
         ival_W = Interval(freq='WK', year=2007, month=1, day=1)
 
@@ -415,10 +415,10 @@ class TestFreqConversion(TestCase):
             ival_W_to_A_end_of_year = Interval(freq='A', year=2008)
 
         if Interval(freq='D', year=2007, month=3, day=31).weekday == 6:
-            ival_W_to_Q_end_of_quarter = Interval(freq='Q', year=2007, 
+            ival_W_to_Q_end_of_quarter = Interval(freq='Q', year=2007,
                                                   quarter=1)
         else:
-            ival_W_to_Q_end_of_quarter = Interval(freq='Q', year=2007, 
+            ival_W_to_Q_end_of_quarter = Interval(freq='Q', year=2007,
                                                   quarter=2)
 
         if Interval(freq='D', year=2007, month=1, day=31).weekday == 6:
@@ -444,10 +444,10 @@ class TestFreqConversion(TestCase):
                                     hour=23, minute=59, second=59)
 
         assert_equal(ival_W.resample('A'), ival_W_to_A)
-        assert_equal(ival_W_end_of_year.resample('A'), 
+        assert_equal(ival_W_end_of_year.resample('A'),
                      ival_W_to_A_end_of_year)
         assert_equal(ival_W.resample('Q'), ival_W_to_Q)
-        assert_equal(ival_W_end_of_quarter.resample('Q'), 
+        assert_equal(ival_W_end_of_quarter.resample('Q'),
                      ival_W_to_Q_end_of_quarter)
         assert_equal(ival_W.resample('M'), ival_W_to_M)
         assert_equal(ival_W_end_of_month.resample('M'),
@@ -485,7 +485,7 @@ class TestFreqConversion(TestCase):
 
 
     def test_conv_business(self):
-        "frequency conversion tests: from Business Frequency"
+        # frequency conversion tests: from Business Frequency"
 
         ival_B = Interval(freq='B', year=2007, month=1, day=1)
         ival_B_end_of_year = Interval(freq='B', year=2007, month=12, day=31)
@@ -533,7 +533,7 @@ class TestFreqConversion(TestCase):
 
 
     def test_conv_daily(self):
-        "frequency conversion tests: from Business Frequency"
+        # frequency conversion tests: from Business Frequency"
 
         ival_D = Interval(freq='D', year=2007, month=1, day=1)
         ival_D_end_of_year = Interval(freq='D', year=2007, month=12, day=31)
@@ -610,7 +610,7 @@ class TestFreqConversion(TestCase):
         assert_equal(ival_D.resample('D'), ival_D)
 
     def test_conv_hourly(self):
-        "frequency conversion tests: from Hourly Frequency"
+        # frequency conversion tests: from Hourly Frequency"
 
         ival_H = Interval(freq='H', year=2007, month=1, day=1, hour=0)
         ival_H_end_of_year = Interval(freq='H', year=2007, month=12, day=31,
@@ -663,7 +663,7 @@ class TestFreqConversion(TestCase):
         assert_equal(ival_H.resample('H'), ival_H)
 
     def test_conv_minutely(self):
-        "frequency conversion tests: from Minutely Frequency"
+        # frequency conversion tests: from Minutely Frequency"
 
         ival_T = Interval(freq='Min', year=2007, month=1, day=1,
                         hour=0, minute=0)
@@ -716,7 +716,7 @@ class TestFreqConversion(TestCase):
         assert_equal(ival_T.resample('Min'), ival_T)
 
     def test_conv_secondly(self):
-        "frequency conversion tests: from Secondly Frequency"
+        # frequency conversion tests: from Secondly Frequency"
 
         ival_S = Interval(freq='S', year=2007, month=1, day=1,
                         hour=0, minute=0, second=0)
@@ -921,12 +921,12 @@ class TestIntervalIndex(TestCase):
         self.assert_(s['05Q4'] == s[2])
 
     def test_interval_dt64_round_trip(self):
-        dti = DatetimeIndex(['1/1/2002', '1/2/2002', '1/3/2002', '1/4/2002', 
+        dti = DatetimeIndex(['1/1/2002', '1/2/2002', '1/3/2002', '1/4/2002',
                              '1/5/2002', '1/6/2002', '1/7/2002'], freq='B')
         ii = dti.to_interval()
         self.assert_(ii.to_timestamp().equals(dti))
 
-        dti = DatetimeIndex(['1/1/2002', '1/2/2002', '1/3/2002', '1/4/2002', 
+        dti = DatetimeIndex(['1/1/2002', '1/2/2002', '1/3/2002', '1/4/2002',
                              '1/5/2002', '1/6/2002', '1/7/2002'], freq='B')
         ii = dti.to_interval(freq='3H')
         self.assert_(ii.to_timestamp().equals(dti))
@@ -936,8 +936,8 @@ class TestIntervalIndex(TestCase):
         self.assertEquals(ii[0], Interval('1/1/10', '2M'))
         self.assertEquals(ii[1], Interval('3/1/10', '2M'))
 
-        self.assertEquals(ii[0].resample('6M'), ii[2].resample('6M')) 
-        self.assertEquals(ii[0].resample('A'), ii[2].resample('A')) 
+        self.assertEquals(ii[0].resample('6M'), ii[2].resample('6M'))
+        self.assertEquals(ii[0].resample('A'), ii[2].resample('A'))
 
         self.assertEquals(ii[0].resample('M', how='S'),
                           Interval('Jan 2010', '1M'))
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index c5ff58a6a..2cb5e1dd1 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -237,7 +237,7 @@ class SafeForSparse(object):
         tm.equalContents(self.panel.keys(), self.panel.items)
 
     def test_iteritems(self):
-        """Test panel.iteritems(), aka panel.iterkv()"""
+        # Test panel.iteritems(), aka panel.iterkv()
         # just test that it works
         for k, v in self.panel.iterkv():
             pass
@@ -406,14 +406,15 @@ class CheckIndexing(object):
         self.assert_(self.panel['ItemP'].values.dtype == np.bool_)
 
     def test_setitem_ndarray(self):
-        from pandas import DateRange, datetools
+        from pandas import date_range, datetools
 
-        timeidx = DateRange(start=datetime(2009,1,1),
-                            end=datetime(2009,12,31),
-                            offset=datetools.MonthEnd())
+        timeidx = date_range(start=datetime(2009,1,1),
+                             end=datetime(2009,12,31),
+                             freq=datetools.MonthEnd())
         lons_coarse = np.linspace(-177.5, 177.5, 72)
         lats_coarse = np.linspace(-87.5, 87.5, 36)
-        P = Panel(items=timeidx, major_axis=lons_coarse, minor_axis=lats_coarse)
+        P = Panel(items=timeidx, major_axis=lons_coarse,
+                  minor_axis=lats_coarse)
         data = np.random.randn(72*36).reshape((72,36))
         key = datetime(2009,2,28)
         P[key] = data
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 5f0ef43be..8f08a94d7 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -12,7 +12,8 @@ from numpy import nan
 import numpy as np
 import numpy.ma as ma
 
-from pandas import Index, Series, TimeSeries, DataFrame, isnull, notnull
+from pandas import (Index, Series, TimeSeries, DataFrame, isnull, notnull,
+                    bdate_range)
 from pandas.core.index import MultiIndex
 
 import pandas.core.datetools as datetools
@@ -464,7 +465,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_getitem_setitem_boolean_corner(self):
         ts = self.ts
-        mask_shifted = ts.shift(1, offset=datetools.bday) > ts.median()
+        mask_shifted = ts.shift(1, freq=datetools.bday) > ts.median()
         self.assertRaises(Exception, ts.__getitem__, mask_shifted)
         self.assertRaises(Exception, ts.__setitem__, mask_shifted, 1)
 
@@ -942,7 +943,6 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(Series([nan, 0, 0, 0, nan]), r)
 
     def _check_stat_op(self, name, alternate, check_objects=False):
-        from pandas import DateRange
         import pandas.core.nanops as nanops
 
         def testit():
@@ -966,9 +966,9 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
             s = Series([1, 2, 3, None, 5])
             f(s)
 
-            # check DateRange
+            # check date range
             if check_objects:
-                s = Series(DateRange('1/1/2000', periods=10))
+                s = Series(bdate_range('1/1/2000', periods=10))
                 res = f(s)
                 exp = alternate(s)
                 self.assertEqual(res, exp)
@@ -1130,9 +1130,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(result, expected)
 
     def test_comparison_operators_with_nas(self):
-        from pandas import DateRange
-
-        s = Series(DateRange('1/1/2000', periods=10), dtype=object)
+        s = Series(bdate_range('1/1/2000', periods=10), dtype=object)
         s[::2] = np.nan
 
         # test that comparions work
@@ -1173,9 +1171,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
             assert_series_equal(result, expected)
 
     def test_between(self):
-        from pandas import DateRange
-
-        s = Series(DateRange('1/1/2000', periods=20), dtype=object)
+        s = Series(bdate_range('1/1/2000', periods=20), dtype=object)
         s[::2] = np.nan
 
         result = s[s.between(s[3], s[17])]
@@ -1708,16 +1704,16 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         tm.assert_dict_equal(unshifted.valid(), self.ts, compare_keys=False)
 
         offset = datetools.bday
-        shifted = self.ts.shift(1, offset=offset)
-        unshifted = shifted.shift(-1, offset=offset)
+        shifted = self.ts.shift(1, freq=offset)
+        unshifted = shifted.shift(-1, freq=offset)
 
         assert_series_equal(unshifted, self.ts)
 
-        unshifted = self.ts.shift(0, offset=offset)
+        unshifted = self.ts.shift(0, freq=offset)
         assert_series_equal(unshifted, self.ts)
 
-        shifted = self.ts.shift(1, timeRule='WEEKDAY')
-        unshifted = shifted.shift(-1, timeRule='WEEKDAY')
+        shifted = self.ts.shift(1, freq='WEEKDAY')
+        unshifted = shifted.shift(-1, freq='WEEKDAY')
 
         assert_series_equal(unshifted, self.ts)
 
diff --git a/pandas/tests/test_timeseries.py b/pandas/tests/test_timeseries.py
new file mode 100644
index 000000000..ab28d06ec
--- /dev/null
+++ b/pandas/tests/test_timeseries.py
@@ -0,0 +1,64 @@
+# pylint: disable-msg=E1101,W0612
+
+from cStringIO import StringIO
+from datetime import datetime, timedelta
+import os
+import operator
+import unittest
+
+import nose
+
+from numpy import nan
+import numpy as np
+import numpy.ma as ma
+
+from pandas import Index, Series, TimeSeries, DataFrame, isnull, notnull
+from pandas.core.index import MultiIndex
+
+from pandas import DatetimeIndex
+
+import pandas.core.datetools as datetools
+import pandas.core.nanops as nanops
+
+from pandas.util import py3compat
+from pandas.util.testing import assert_series_equal, assert_almost_equal
+import pandas.util.testing as tm
+import pandas
+
+class TestTimeSeriesDuplicates(unittest.TestCase):
+
+    def setUp(self):
+        dates = [datetime(2000, 1, 2), datetime(2000, 1, 2),
+                 datetime(2000, 1, 2), datetime(2000, 1, 3),
+                 datetime(2000, 1, 3), datetime(2000, 1, 3),
+                 datetime(2000, 1, 4), datetime(2000, 1, 4),
+                 datetime(2000, 1, 4), datetime(2000, 1, 5)]
+
+        self.dups = Series(np.random.randn(len(dates)), index=dates)
+
+    def test_constructor(self):
+        self.assert_(isinstance(self.dups, TimeSeries))
+        self.assert_(isinstance(self.dups.index, DatetimeIndex))
+
+    def test_is_unique_monotonic(self):
+        self.assert_(not self.dups.index.is_unique)
+
+
+    def test_duplicate_dates_indexing(self):
+
+        for date in ts.index.unique():
+            result = ts[date]
+
+            mask = ts.index == date
+            total = (ts.index == date).sum()
+            expected = ts[mask]
+            if total > 1:
+                assert_series_equal(result, expected)
+            else:
+                assert_almost_equal(result, expected[0])
+
+
+
+if __name__ == '__main__':
+    nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
+                   exit=False)
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 19f0d77e4..1b8b88e53 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -944,7 +944,7 @@ class _Concatenator(object):
 
     def _maybe_check_integrity(self, concat_index):
         if self.verify_integrity:
-            if not concat_index._verify_integrity():
+            if not concat_index.is_unique:
                 overlap = concat_index.get_duplicates()
                 raise Exception('Indexes have overlapping values: %s'
                                 % str(overlap))
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 035f6feb6..1f471e67f 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -14,18 +14,17 @@ import numpy as np
 
 from pandas.core.common import isnull
 import pandas.core.index as index
-import pandas.core.daterange as daterange
 import pandas.core.series as series
 import pandas.core.frame as frame
 import pandas.core.panel as panel
 
+from pandas import bdate_range
 from pandas.core.index import DatetimeIndex, IntervalIndex
 
 # to_reload = ['index', 'daterange', 'series', 'frame', 'matrix', 'panel']
 # for mod in to_reload:
 #     reload(locals()[mod])
 
-DateRange = daterange.DateRange
 Index = index.Index
 Series = series.Series
 DataFrame = frame.DataFrame
@@ -166,7 +165,7 @@ def makeFloatIndex(k):
     return Index(values * (10 ** np.random.randint(0, 9)))
 
 def makeDateIndex(k):
-    dates = list(DateRange(datetime(2000, 1, 1), periods=k))
+    dates = list(bdate_range(datetime(2000, 1, 1), periods=k))
     return Index(dates)
 
 def makeFloatSeries():
@@ -201,14 +200,14 @@ def getMixedTypeDict():
         'A' : [0., 1., 2., 3., 4.],
         'B' : [0., 1., 0., 1., 0.],
         'C' : ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],
-        'D' : DateRange('1/1/2009', periods=5)
+        'D' : bdate_range('1/1/2009', periods=5)
     }
 
     return index, data
 
 def makeDateIndex(k):
     dt = datetime(2000,1,1)
-    dr = DateRange(dt, periods=k)
+    dr = bdate_range(dt, periods=k)
     return DatetimeIndex(dr)
 
 def makeIntervalIndex(k):
diff --git a/setup.py b/setup.py
index 6e1625b9f..8e38b97c9 100755
--- a/setup.py
+++ b/setup.py
@@ -329,7 +329,7 @@ else:
     cmdclass['sdist'] =  CheckSDist
 
 tseries_depends = ['reindex', 'groupby', 'skiplist', 'moments',
-                   'generated', 'reduce', 'stats',
+                   'generated', 'reduce', 'stats', 'datetime',
                    'inference', 'properties', 'internals',
                    'hashtable', 'join']
 
diff --git a/ts_todo.txt b/ts_todo.txt
new file mode 100644
index 000000000..7638e78f0
--- /dev/null
+++ b/ts_todo.txt
@@ -0,0 +1,17 @@
+- DatetimeIndex.union empty -> error
+- DateOffset display sucks -> 1 Day
+
+- get rid of Ts class, simplify timestamp creation
+- rename tzinfo to tz
+- get rid of deprecated / new offset mapping, will deal with users
+- add Index.is_unique, check via is_monotonic cython routine
+- tofreq -> asfreq again
+- work around numpy refcount bug in Index.append with datetime64 type promotion
+- fix bug in Index.join with empty indexes
+- handle legacy DateRange unpickling in BlockManager
+- date_range/bdate_range factory functions, test refactoring
+- got rid of all deprecation warnings in test suite, usages of DateRange
+- fix merge issue? in generate_code.py
+- attach tz in DatetimeIndex.asobject
+- failing duplicate timestamp test
+- _tseries.pyd depends on datetime.pyx
