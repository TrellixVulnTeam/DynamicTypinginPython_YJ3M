commit 7dd12cce711ffc478b69ebee2e8fa013d34ba746
Author: jreback <jeff@reback.net>
Date:   Fri Jun 7 18:42:56 2013 -0400

    CLN: revised json support to use the to_json/read_json in pandas.io.json
    
    DOC: docs in io.rst/whatsnew/release notes/api
    
    TST: cleaned up cruft in test_series/test_frame

diff --git a/doc/source/api.rst b/doc/source/api.rst
index e26355446..bb6f0ac07 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -45,6 +45,16 @@ Excel
    read_excel
    ExcelFile.parse
 
+JSON
+~~~~
+
+.. currentmodule:: pandas.io.json
+
+.. autosummary::
+   :toctree: generated/
+
+   read_json
+
 HTML
 ~~~~
 
@@ -597,6 +607,7 @@ Serialization / IO / Conversion
    DataFrame.to_hdf
    DataFrame.to_dict
    DataFrame.to_excel
+   DataFrame.to_json
    DataFrame.to_html
    DataFrame.to_stata
    DataFrame.to_records
diff --git a/doc/source/io.rst b/doc/source/io.rst
index ac5d49e03..625ff39cd 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -35,6 +35,7 @@ object.
     * ``read_excel``
     * ``read_hdf``
     * ``read_sql``
+    * ``read_json``
     * ``read_html``
     * ``read_stata``
     * ``read_clipboard``
@@ -45,6 +46,7 @@ The corresponding ``writer`` functions are object methods that are accessed like
     * ``to_excel``
     * ``to_hdf``
     * ``to_sql``
+    * ``to_json``
     * ``to_html``
     * ``to_stata``
     * ``to_clipboard``
@@ -937,6 +939,30 @@ The Series object also has a ``to_string`` method, but with only the ``buf``,
 which, if set to ``True``, will additionally output the length of the Series.
 
 
+
+JSON
+----
+
+Read and write ``JSON`` format files.
+
+.. _io.json:
+
+Writing JSON
+~~~~~~~~~~~~
+
+.. ipython:: python
+
+   df = DataFrame(randn(10, 2), columns=list('AB'))
+   s = df.to_json()
+   s
+
+Reading JSON
+~~~~~~~~~~~~
+
+.. ipython:: python
+
+   pd.read_json(s)
+
 HTML
 ----
 
@@ -2193,7 +2219,6 @@ into a .dta file. The format version of this file is always the latest one, 115.
 
 .. ipython:: python
 
-   from pandas.io.stata import StataWriter
    df = DataFrame(randn(10, 2), columns=list('AB'))
    df.to_stata('stata.dta')
 
diff --git a/doc/source/v0.11.1.txt b/doc/source/v0.11.1.txt
index 70d840f8c..5045f7337 100644
--- a/doc/source/v0.11.1.txt
+++ b/doc/source/v0.11.1.txt
@@ -16,6 +16,7 @@ API changes
     * ``read_excel``
     * ``read_hdf``
     * ``read_sql``
+    * ``read_json``
     * ``read_html``
     * ``read_stata``
     * ``read_clipboard``
@@ -26,6 +27,7 @@ API changes
     * ``to_excel``
     * ``to_hdf``
     * ``to_sql``
+    * ``to_json``
     * ``to_html``
     * ``to_stata``
     * ``to_clipboard``
@@ -175,6 +177,10 @@ Enhancements
     accessable via ``read_stata`` top-level function for reading,
     and ``to_stata`` DataFrame method for writing, :ref:`See the docs<io.stata>`
 
+  - Added module for reading and writing json format files: ``pandas.io.json``
+    accessable via ``read_json`` top-level function for reading,
+    and ``to_json`` DataFrame method for writing, :ref:`See the docs<io.json>`
+
   - ``DataFrame.replace()`` now allows regular expressions on contained
     ``Series`` with object dtype. See the examples section in the regular docs
     :ref:`Replacing via String Expression <missing_data.replace_expression>`
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 2925bb3e3..9c0a28433 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -5593,106 +5593,6 @@ class DataFrame(NDFrame):
         """
         return self.where(~cond, NA)
 
-
-@classmethod
-def from_json(cls, json, orient="columns", dtype=None, numpy=True):
-    """
-    Convert JSON string to DataFrame
-
-    Parameters
-    ----------
-    json : The JSON string to parse.
-    orient : {'split', 'records', 'index', 'columns', 'values'},
-             default 'columns'
-        The format of the JSON string
-        split : dict like
-            {index -> [index], columns -> [columns], data -> [values]}
-        records : list like [{column -> value}, ... , {column -> value}]
-        index : dict like {index -> {column -> value}}
-        columns : dict like {column -> {index -> value}}
-        values : just the values array
-    dtype : dtype of the resulting DataFrame
-    nupmpy: direct decoding to numpy arrays. default True but falls back
-        to standard decoding if a problem occurs.
-
-    Returns
-    -------
-    result : DataFrame
-    """
-    from pandas.json import loads
-
-    df = None
-
-    if dtype is not None and orient == "split":
-        numpy = False
-
-    if numpy:
-        try:
-            if orient == "columns":
-                args = loads(json, dtype=dtype, numpy=True, labelled=True)
-                if args:
-                    args = (args[0].T, args[2], args[1])
-                df = DataFrame(*args)
-            elif orient == "split":
-                decoded = loads(json, dtype=dtype, numpy=True)
-                decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                df = DataFrame(**decoded)
-            elif orient == "values":
-                df = DataFrame(loads(json, dtype=dtype, numpy=True))
-            else:
-                df = DataFrame(*loads(json, dtype=dtype, numpy=True,
-                                      labelled=True))
-        except ValueError:
-            numpy = False
-    if not numpy:
-        if orient == "columns":
-            df = DataFrame(loads(json), dtype=dtype)
-        elif orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in loads(json).iteritems())
-            df = DataFrame(dtype=dtype, **decoded)
-        elif orient == "index":
-            df = DataFrame(loads(json), dtype=dtype).T
-        else:
-            df = DataFrame(loads(json), dtype=dtype)
-
-    return df
-DataFrame.from_json = from_json
-
-
-def to_json(self, orient="columns", double_precision=10,
-            force_ascii=True):
-    """
-    Convert DataFrame to a JSON string.
-
-    Note NaN's and None will be converted to null and datetime objects
-    will be converted to UNIX timestamps.
-
-    Parameters
-    ----------
-    orient : {'split', 'records', 'index', 'columns', 'values'},
-             default 'columns'
-        The format of the JSON string
-        split : dict like
-            {index -> [index], columns -> [columns], data -> [values]}
-        records : list like [{column -> value}, ... , {column -> value}]
-        index : dict like {index -> {column -> value}}
-        columns : dict like {column -> {index -> value}}
-        values : just the values array
-    double_precision : The number of decimal places to use when encoding
-        floating point values, default 10.
-    force_ascii : force encoded string to be ASCII, default True.
-
-    Returns
-    -------
-    result : JSON compatible string
-    """
-    from pandas.json import dumps
-    return dumps(self, orient=orient, double_precision=double_precision,
-                 ensure_ascii=force_ascii)
-DataFrame.to_json = to_json
-
-
 _EMPTY_SERIES = Series([])
 
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 553358474..7a947f9b4 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -495,6 +495,38 @@ class PandasObject(object):
         from pandas.io import clipboard
         clipboard.to_clipboard(self)
 
+    def to_json(self, orient=None, double_precision=10,
+                force_ascii=True):
+        """
+        Convert the object to a JSON string.
+
+        Note NaN's and None will be converted to null and datetime objects
+        will be converted to UNIX timestamps.
+
+        Parameters
+        ----------
+        orient : {'split', 'records', 'index', 'columns', 'values'},
+            default is 'index' for Series, 'columns' for DataFrame
+
+            The format of the JSON string
+            split : dict like
+                {index -> [index], columns -> [columns], data -> [values]}
+            records : list like [{column -> value}, ... , {column -> value}]
+            index : dict like {index -> {column -> value}}
+            columns : dict like {column -> {index -> value}}
+            values : just the values array
+        double_precision : The number of decimal places to use when encoding
+            floating point values, default 10.
+        force_ascii : force encoded string to be ASCII, default True.
+
+        Returns
+        -------
+        result : JSON compatible string
+        """
+        from pandas.io import json
+        return json.to_json(self, orient=orient, double_precision=double_precision,
+                            force_ascii=force_ascii)
+
 # install the indexerse
 for _name, _indexer in indexing.get_indexers_list():
     PandasObject._create_indexer(_name,_indexer)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 9147e64f5..3a7a7d0f4 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -3298,88 +3298,6 @@ class Series(pa.Array, generic.PandasObject):
         from pandas.core.strings import StringMethods
         return StringMethods(self)
 
-
-@classmethod
-def from_json(cls, json, orient="index", dtype=None, numpy=True):
-    """
-    Convert JSON string to Series
-
-    Parameters
-    ----------
-    json : The JSON string to parse.
-    orient : {'split', 'records', 'index'}, default 'index'
-        The format of the JSON string
-        split : dict like
-            {index -> [index], name -> name, data -> [values]}
-        records : list like [value, ... , value]
-        index : dict like {index -> value}
-    dtype : dtype of the resulting Series
-    nupmpy: direct decoding to numpy arrays. default True but falls back
-        to standard decoding if a problem occurs.
-
-    Returns
-    -------
-    result : Series
-    """
-    from pandas.json import loads
-    s = None
-
-    if dtype is not None and orient == "split":
-        numpy = False
-
-    if numpy:
-        try:
-            if orient == "split":
-                decoded = loads(json, dtype=dtype, numpy=True)
-                decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                s = Series(**decoded)
-            elif orient == "columns" or orient == "index":
-                s = Series(*loads(json, dtype=dtype, numpy=True,
-                                  labelled=True))
-            else:
-                s = Series(loads(json, dtype=dtype, numpy=True))
-        except ValueError:
-            numpy = False
-    if not numpy:
-        if orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in loads(json).iteritems())
-            s = Series(dtype=dtype, **decoded)
-        else:
-            s = Series(loads(json), dtype=dtype)
-
-    return s
-Series.from_json = from_json
-
-def to_json(self, orient="index", double_precision=10, force_ascii=True):
-    """
-    Convert Series to a JSON string
-
-    Note NaN's and None will be converted to null and datetime objects
-    will be converted to UNIX timestamps.
-
-    Parameters
-    ----------
-    orient : {'split', 'records', 'index'}, default 'index'
-        The format of the JSON string
-        split : dict like
-            {index -> [index], name -> name, data -> [values]}
-        records : list like [value, ... , value]
-        index : dict like {index -> value}
-    double_precision : The number of decimal places to use when encoding
-        floating point values, default 10.
-    force_ascii : force encoded string to be ASCII, default True.
-
-    Returns
-    -------
-    result : JSON compatible string
-    """
-    from pandas.json import dumps
-    return dumps(self, orient=orient, double_precision=double_precision,
-                 ensure_ascii=force_ascii)
-Series.to_json = to_json
-
-
 _INDEX_TYPES = ndarray, Index, list, tuple
 
 #------------------------------------------------------------------------------
diff --git a/pandas/io/api.py b/pandas/io/api.py
index f17351921..48566399f 100644
--- a/pandas/io/api.py
+++ b/pandas/io/api.py
@@ -6,6 +6,7 @@ from pandas.io.parsers import read_csv, read_table, read_fwf
 from pandas.io.clipboard import read_clipboard
 from pandas.io.excel import ExcelFile, ExcelWriter, read_excel
 from pandas.io.pytables import HDFStore, Term, get_store, read_hdf
+from pandas.io.json import read_json
 from pandas.io.html import read_html
 from pandas.io.sql import read_sql
 from pandas.io.stata import read_stata
diff --git a/pandas/io/json.py b/pandas/io/json.py
new file mode 100644
index 000000000..7c8f6f40b
--- /dev/null
+++ b/pandas/io/json.py
@@ -0,0 +1,152 @@
+
+# pylint: disable-msg=E1101,W0613,W0603
+from pandas import Series, DataFrame
+
+import pandas.json as _json
+loads = _json.loads
+dumps = _json.dumps
+
+### interface to/from ###
+
+def to_json(obj, orient=None, double_precision=10,
+            force_ascii=True):
+        """
+        Convert the object to a JSON string.
+
+        Note NaN's and None will be converted to null and datetime objects
+        will be converted to UNIX timestamps.
+
+        Parameters
+        ----------
+        orient : {'split', 'records', 'index', 'columns', 'values'},
+            default is 'index' for Series, 'columns' for DataFrame
+
+            The format of the JSON string
+            split : dict like
+                {index -> [index], columns -> [columns], data -> [values]}
+            records : list like [{column -> value}, ... , {column -> value}]
+            index : dict like {index -> {column -> value}}
+            columns : dict like {column -> {index -> value}}
+            values : just the values array
+        double_precision : The number of decimal places to use when encoding
+            floating point values, default 10.
+        force_ascii : force encoded string to be ASCII, default True.
+
+        Returns
+        -------
+        result : JSON compatible string
+        """
+        if orient is None:
+            if isinstance(obj, Series):
+                orient = 'index'
+            elif isinstance(obj, DataFrame):
+                orient = 'columns'
+
+        return dumps(obj, orient=orient, double_precision=double_precision,
+                     ensure_ascii=force_ascii)
+
+def read_json(json, typ='frame', orient=None, dtype=None, numpy=True):
+    """
+    Convert JSON string to pandas object
+
+    Parameters
+    ----------
+    json : The JSON string to parse.
+    typ : type of object to recover (series or frame), default 'frame'
+    orient : {'split', 'records', 'index'}, default 'index'
+        The format of the JSON string
+        split : dict like
+            {index -> [index], name -> name, data -> [values]}
+        records : list like [value, ... , value]
+        index : dict like {index -> value}
+    dtype : dtype of the resulting Series
+    nupmpy: direct decoding to numpy arrays. default True but falls back
+        to standard decoding if a problem occurs.
+
+    Returns
+    -------
+    result : Series or DataFrame
+    """
+
+    obj = None
+    if typ == 'frame':
+        if orient is None:
+            orient = 'columns'
+        obj = load_frame(json, orient, dtype, numpy)
+
+    if typ == 'series' or obj is None:
+        if orient == 'columns':
+            orient = 'index'
+        obj = load_series(json, orient, dtype, numpy)
+
+    return obj
+
+def load_series(json, orient, dtype, numpy):
+    s = None
+
+    if dtype is not None and orient == "split":
+        numpy = False
+
+    if numpy:
+        try:
+            if orient == "split":
+                decoded = loads(json, dtype=dtype, numpy=True)
+                decoded = dict((str(k), v) for k, v in decoded.iteritems())
+                s = Series(**decoded)
+            elif orient == "columns" or orient == "index":
+                s = Series(*loads(json, dtype=dtype, numpy=True,
+                                  labelled=True))
+            else:
+                s = Series(loads(json, dtype=dtype, numpy=True))
+        except ValueError:
+            numpy = False
+
+    if not numpy:
+        if orient == "split":
+            decoded = dict((str(k), v)
+                           for k, v in loads(json).iteritems())
+            s = Series(dtype=dtype, **decoded)
+        else:
+            s = Series(loads(json), dtype=dtype)
+
+    return s
+
+        
+def load_frame(json, orient, dtype, numpy):
+    """ try to recover a frame, return None if we didn't get anything """
+
+    if dtype is not None and orient == "split":
+        numpy = False
+
+    if numpy:
+        try:
+            if orient == "columns":
+                args = loads(json, dtype=dtype, numpy=True, labelled=True)
+                if args:
+                    args = (args[0].T, args[2], args[1])
+                df = DataFrame(*args)
+            elif orient == "split":
+                decoded = loads(json, dtype=dtype, numpy=True)
+                decoded = dict((str(k), v) for k, v in decoded.iteritems())
+                df = DataFrame(**decoded)
+            elif orient == "values":
+                df = DataFrame(loads(json, dtype=dtype, numpy=True))
+            else:
+                df = DataFrame(*loads(json, dtype=dtype, numpy=True,
+                                     labelled=True))
+        except ValueError:
+            numpy = False
+
+    if not numpy:
+        if orient == "columns":
+            df = DataFrame(loads(json), dtype=dtype)
+        elif orient == "split":
+            decoded = dict((str(k), v)
+                           for k, v in loads(json).iteritems())
+            df = DataFrame(dtype=dtype, **decoded)
+        elif orient == "index":
+            df = DataFrame(loads(json), dtype=dtype).T
+        else:
+            df = DataFrame(loads(json), dtype=dtype)
+
+    return df
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index 506aa3824..f4cb7ed03 100644
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -1,3 +1,4 @@
+
 # pylint: disable-msg=W0612,E1101
 from copy import deepcopy
 from datetime import datetime, timedelta
@@ -11,6 +12,7 @@ import numpy as np
 
 from pandas import Series, DataFrame, DatetimeIndex
 import pandas as pd
+read_json = pd.read_json
 
 from pandas.util.testing import (assert_almost_equal, assert_frame_equal,
                                  assert_series_equal)
@@ -55,8 +57,8 @@ class TestPandasObjects(unittest.TestCase):
         def _check_orient(df, orient, dtype=None, numpy=True):
             df = df.sort()
             dfjson = df.to_json(orient=orient)
-            unser = DataFrame.from_json(dfjson, orient=orient, dtype=dtype,
-                                        numpy=numpy)
+            unser = read_json(dfjson, orient=orient, dtype=dtype,
+                              numpy=numpy)
             unser = unser.sort()
             if df.index.dtype.type == np.datetime64:
                 unser.index = DatetimeIndex(unser.index.values.astype('i8'))
@@ -136,50 +138,50 @@ class TestPandasObjects(unittest.TestCase):
         _check_orient(df.transpose().transpose(), "index")
 
     def test_frame_from_json_bad_data(self):
-        self.assertRaises(ValueError, DataFrame.from_json, '{"key":b:a:d}')
+        self.assertRaises(ValueError, read_json, '{"key":b:a:d}')
 
         # too few indices
         json = ('{"columns":["A","B"],'
                 '"index":["2","3"],'
                 '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(ValueError, DataFrame.from_json, json,
+        self.assertRaises(ValueError, read_json, json,
                           orient="split")
 
         # too many columns
         json = ('{"columns":["A","B","C"],'
                 '"index":["1","2","3"],'
                 '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(AssertionError, DataFrame.from_json, json,
+        self.assertRaises(AssertionError, read_json, json,
                           orient="split")
 
         # bad key
         json = ('{"badkey":["A","B"],'
                 '"index":["2","3"],'
                 '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(TypeError, DataFrame.from_json, json,
+        self.assertRaises(TypeError, read_json, json,
                           orient="split")
 
     def test_frame_from_json_nones(self):
         df = DataFrame([[1, 2], [4, 5, 6]])
-        unser = DataFrame.from_json(df.to_json())
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
         df = DataFrame([['1', '2'], ['4', '5', '6']])
-        unser = DataFrame.from_json(df.to_json())
+        unser = read_json(df.to_json())
         self.assert_(unser['2'][0] is None)
 
-        unser = DataFrame.from_json(df.to_json(), numpy=False)
+        unser = read_json(df.to_json(), numpy=False)
         self.assert_(unser['2'][0] is None)
 
         # infinities get mapped to nulls which get mapped to NaNs during
         # deserialisation
         df = DataFrame([[1, 2], [4, 5, 6]])
         df[2][0] = np.inf
-        unser = DataFrame.from_json(df.to_json())
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
         df[2][0] = np.NINF
-        unser = DataFrame.from_json(df.to_json())
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
     def test_frame_to_json_except(self):
@@ -190,8 +192,8 @@ class TestPandasObjects(unittest.TestCase):
 
         def _check_orient(series, orient, dtype=None, numpy=True):
             series = series.sort_index()
-            unser = Series.from_json(series.to_json(orient=orient),
-                                     orient=orient, numpy=numpy, dtype=dtype)
+            unser = read_json(series.to_json(orient=orient), typ='series',
+                              orient=orient, numpy=numpy, dtype=dtype)
             unser = unser.sort_index()
             if series.index.dtype.type == np.datetime64:
                 unser.index = DatetimeIndex(unser.index.values.astype('i8'))
@@ -238,3 +240,17 @@ class TestPandasObjects(unittest.TestCase):
     def test_series_to_json_except(self):
         s = Series([1, 2, 3])
         self.assertRaises(ValueError, s.to_json, orient="garbage")
+
+    def test_typ(self):
+
+        s = Series(range(6), index=['a','b','c','d','e','f'])
+        result = read_json(s.to_json(),typ=None)
+        assert_series_equal(result,s)
+
+    def test_reconstruction_index(self):
+
+        df = DataFrame([[1, 2, 3], [4, 5, 6]])
+        result = read_json(df.to_json())
+
+        # the index is serialized as strings....correct?
+        #assert_frame_equal(result,df)
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index d674a2f44..2c6d3b221 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -3338,146 +3338,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             for k2, v2 in v.iteritems():
                 self.assertEqual(v2, recons_data[k][k2])
 
-    def test_from_json_to_json(self):
-        raise nose.SkipTest
-
-        def _check_orient(df, orient, dtype=None, numpy=True):
-            df = df.sort()
-            dfjson = df.to_json(orient=orient)
-            unser = DataFrame.from_json(dfjson, orient=orient, dtype=dtype,
-                                        numpy=numpy)
-            unser = unser.sort()
-            if df.index.dtype.type == np.datetime64:
-                unser.index = DatetimeIndex(unser.index.values.astype('i8'))
-            if orient == "records":
-                # index is not captured in this orientation
-                assert_almost_equal(df.values, unser.values)
-                self.assert_(df.columns.equals(unser.columns))
-            elif orient == "values":
-                # index and cols are not captured in this orientation
-                assert_almost_equal(df.values, unser.values)
-            elif orient == "split":
-                # index and col labels might not be strings
-                unser.index = [str(i) for i in unser.index]
-                unser.columns = [str(i) for i in unser.columns]
-                unser = unser.sort()
-                assert_almost_equal(df.values, unser.values)
-            else:
-                assert_frame_equal(df, unser)
-
-        def _check_all_orients(df, dtype=None):
-            _check_orient(df, "columns", dtype=dtype)
-            _check_orient(df, "records", dtype=dtype)
-            _check_orient(df, "split", dtype=dtype)
-            _check_orient(df, "index", dtype=dtype)
-            _check_orient(df, "values", dtype=dtype)
-
-            _check_orient(df, "columns", dtype=dtype, numpy=False)
-            _check_orient(df, "records", dtype=dtype, numpy=False)
-            _check_orient(df, "split", dtype=dtype, numpy=False)
-            _check_orient(df, "index", dtype=dtype, numpy=False)
-            _check_orient(df, "values", dtype=dtype, numpy=False)
-
-        # basic
-        _check_all_orients(self.frame)
-        self.assertEqual(self.frame.to_json(),
-                         self.frame.to_json(orient="columns"))
-
-        _check_all_orients(self.intframe, dtype=self.intframe.values.dtype)
-
-        # big one
-        # index and columns are strings as all unserialised JSON object keys
-        # are assumed to be strings
-        biggie = DataFrame(np.zeros((200, 4)),
-                           columns=[str(i) for i in range(4)],
-                           index=[str(i) for i in range(200)])
-        _check_all_orients(biggie)
-
-        # dtypes
-        _check_all_orients(DataFrame(biggie, dtype=np.float64),
-                           dtype=np.float64)
-        _check_all_orients(DataFrame(biggie, dtype=np.int64), dtype=np.int64)
-        _check_all_orients(DataFrame(biggie, dtype='<U3'), dtype='<U3')
-
-        # empty
-        _check_all_orients(self.empty)
-
-        # time series data
-        _check_all_orients(self.tsframe)
-
-        # mixed data
-        index = Index(['a', 'b', 'c', 'd', 'e'])
-        data = {
-            'A': [0., 1., 2., 3., 4.],
-            'B': [0., 1., 0., 1., 0.],
-            'C': ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],
-            'D': [True, False, True, False, True]
-        }
-        df = DataFrame(data=data, index=index)
-        _check_orient(df, "split")
-        _check_orient(df, "records")
-        _check_orient(df, "values")
-        _check_orient(df, "columns")
-        # index oriented is problematic as it is read back in in a transposed
-        # state, so the columns are interpreted as having mixed data and
-        # given object dtypes.
-        # force everything to have object dtype beforehand
-        _check_orient(df.transpose().transpose(), "index")
-
-    def test_from_json_bad_data(self):
-        raise nose.SkipTest
-        self.assertRaises(ValueError, DataFrame.from_json, '{"key":b:a:d}')
-
-        # too few indices
-        json = ('{"columns":["A","B"],'
-                '"index":["2","3"],'
-                '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(AssertionError, DataFrame.from_json, json,
-                          orient="split")
-
-        # too many columns
-        json = ('{"columns":["A","B","C"],'
-                '"index":["1","2","3"],'
-                '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(AssertionError, DataFrame.from_json, json,
-                          orient="split")
-
-        # bad key
-        json = ('{"badkey":["A","B"],'
-                '"index":["2","3"],'
-                '"data":[[1.0,"1"],[2.0,"2"],[null,"3"]]}"')
-        self.assertRaises(TypeError, DataFrame.from_json, json,
-                          orient="split")
-
-    def test_from_json_nones(self):
-        raise nose.SkipTest
-        df = DataFrame([[1, 2], [4, 5, 6]])
-        unser = DataFrame.from_json(df.to_json())
-        self.assert_(np.isnan(unser['2'][0]))
-
-        df = DataFrame([['1', '2'], ['4', '5', '6']])
-        unser = DataFrame.from_json(df.to_json())
-        self.assert_(unser['2'][0] is None)
-
-        unser = DataFrame.from_json(df.to_json(), numpy=False)
-        self.assert_(unser['2'][0] is None)
-
-        # infinities get mapped to nulls which get mapped to NaNs during
-        # deserialisation
-        df = DataFrame([[1, 2], [4, 5, 6]])
-        df[2][0] = np.inf
-        unser = DataFrame.from_json(df.to_json())
-        self.assert_(np.isnan(unser['2'][0]))
-
-        df[2][0] = np.NINF
-        unser = DataFrame.from_json(df.to_json())
-        self.assert_(np.isnan(unser['2'][0]))
-
-    def test_to_json_except(self):
-        raise nose.SkipTest
-        df = DataFrame([1, 2, 3])
-        self.assertRaises(ValueError, df.to_json, orient="garbage")
-
     def test_to_records_dt64(self):
         df = DataFrame([["one", "two", "three"],
                         ["four", "five", "six"]],
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index e1589b949..88990bdde 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -561,62 +561,6 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         series = Series(data, dtype=float)
         self.assert_(series.dtype == np.float64)
 
-    def test_from_json_to_json(self):
-        raise nose.SkipTest
-
-        def _check_orient(series, orient, dtype=None, numpy=True):
-            series = series.sort_index()
-            unser = Series.from_json(series.to_json(orient=orient),
-                                     orient=orient, numpy=numpy, dtype=dtype)
-            unser = unser.sort_index()
-            if series.index.dtype.type == np.datetime64:
-                unser.index = DatetimeIndex(unser.index.values.astype('i8'))
-            if orient == "records" or orient == "values":
-                assert_almost_equal(series.values, unser.values)
-            else:
-                try:
-                    assert_series_equal(series, unser)
-                except:
-                    raise
-                if orient == "split":
-                    self.assert_(series.name == unser.name)
-
-        def _check_all_orients(series, dtype=None):
-            _check_orient(series, "columns", dtype=dtype)
-            _check_orient(series, "records", dtype=dtype)
-            _check_orient(series, "split", dtype=dtype)
-            _check_orient(series, "index", dtype=dtype)
-            _check_orient(series, "values", dtype=dtype)
-
-            _check_orient(series, "columns", dtype=dtype, numpy=False)
-            _check_orient(series, "records", dtype=dtype, numpy=False)
-            _check_orient(series, "split", dtype=dtype, numpy=False)
-            _check_orient(series, "index", dtype=dtype, numpy=False)
-            _check_orient(series, "values", dtype=dtype, numpy=False)
-
-        # basic
-        _check_all_orients(self.series)
-        self.assertEqual(self.series.to_json(),
-                         self.series.to_json(orient="index"))
-
-        objSeries = Series([str(d) for d in self.objSeries],
-                           index=self.objSeries.index,
-                           name=self.objSeries.name)
-        _check_all_orients(objSeries)
-        _check_all_orients(self.empty)
-        _check_all_orients(self.ts)
-
-        # dtype
-        s = Series(range(6), index=['a', 'b', 'c', 'd', 'e', 'f'])
-        _check_all_orients(Series(s, dtype=np.float64), dtype=np.float64)
-        _check_all_orients(Series(s, dtype=np.int), dtype=np.int)
-
-
-    def test_to_json_except(self):
-        raise nose.SkipTest
-        s = Series([1, 2, 3])
-        self.assertRaises(ValueError, s.to_json, orient="garbage")
-
     def test_setindex(self):
         # wrong type
         series = self.series.copy()
