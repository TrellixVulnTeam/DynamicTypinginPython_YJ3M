commit 00cf4b656a5c0d07ac5971f9633e2cea4e7b20f0
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Apr 19 04:15:48 2010 +0000

    test coverage. deleted deprecated filter* methods. working on docs for 0.2 release
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@159 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/doc/source/dataframe.rst b/doc/source/dataframe.rst
index 6f7f3650e..53f6772f6 100644
--- a/doc/source/dataframe.rst
+++ b/doc/source/dataframe.rst
@@ -838,8 +838,7 @@ TODO
    DataFrame.combineFirst
    DataFrame.combineAdd
    DataFrame.combineMult
-   DataFrame.outerJoin
-   DataFrame.leftJoin
+   DataFrame.join
    DataFrame.plot
 
 DataFrame vs. DataMatrix
diff --git a/doc/source/datetools.rst b/doc/source/datetools.rst
index d6e2a5c9c..706686ce5 100644
--- a/doc/source/datetools.rst
+++ b/doc/source/datetools.rst
@@ -1,5 +1,8 @@
-DateRange and DateOffset objects
-================================
+.. _datetools:
+
+***************************************
+DateRange, date offsets, and time rules
+***************************************
 
 It is often necessary to do non-standard date logic, adding business
 days, rolling to the next month or quarter end, rolling to the next
diff --git a/doc/source/examples.rst b/doc/source/examples.rst
new file mode 100644
index 000000000..2aede8361
--- /dev/null
+++ b/doc/source/examples.rst
@@ -0,0 +1,9 @@
+.. _examples:
+
+********************
+Example applications
+********************
+
+.. currentmodule:: pandas
+
+
diff --git a/doc/source/groupby.rst b/doc/source/groupby.rst
new file mode 100644
index 000000000..9259ea041
--- /dev/null
+++ b/doc/source/groupby.rst
@@ -0,0 +1,9 @@
+.. _groupby:
+
+*******************
+Group-by operations
+*******************
+
+.. currentmodule:: pandas
+
+
diff --git a/doc/source/index.rst b/doc/source/index.rst
index d4555bfc9..bb2263bc9 100755
--- a/doc/source/index.rst
+++ b/doc/source/index.rst
@@ -57,8 +57,11 @@ User manual
 
     installation
     core
+    groupby
     datetools
     stats
+    examples
+    missing_data
 
 .. Quick Reference
 .. ---------------
diff --git a/doc/source/indexobj.rst b/doc/source/indexobj.rst
index 407b0a352..571fcb33c 100644
--- a/doc/source/indexobj.rst
+++ b/doc/source/indexobj.rst
@@ -1,3 +1,88 @@
+.. _indexobj.rst
 
+
+*****
 Index
-=====
+*****
+
+.. currentmodule:: pandas
+
+The pandas data model is relatively simple: link data to a set of
+unique labels. This labelling is implemented through the
+:class:`Index` class:
+
+.. class:: Index
+
+   a 1-D NumPy :class:`~numpy.ndarray` subclass which represents an
+   *ordered set*.
+
+   :Parameters:
+       **labels** : {array_like}
+
+           Any data that is valid for constructing a 1-D
+           :class:`~numpy.ndarray` can be used here. The order of the
+           labels is preserved and they need not be sorted.
+
+.. note::
+
+    An Index instance will always be of **object** dtype. The reason
+    for this is to avoid occasional type-casting snafus when holding
+    strings in NumPy arrays.
+
+Usage and behavior
+------------------
+
+In general, users will seldom need to create Index instances
+themselves. However, understanding their internal structure will
+be important for developers. Creating an Index is simple:
+
+::
+
+    >>> index = Index(['a', 'b', 'c', 'd', 'e'])
+    >>> index
+    Index([a, b, c, d, e], dtype=object)
+
+The Index stores the labels in two ways: one as a vector, and the
+other in a dict:
+
+::
+
+    >>> index.indexMap
+    {'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4}
+
+This dict allows the pandas data structures to perform fast lookups
+and determine membership:
+
+::
+
+    >>> 'a' in index
+    True
+    >>> 'f' in index
+    False
+
+Slicing produces a new index with the **indexMap** field adjusted
+appropriately.
+
+::
+
+    >>> index_slice = index[2:]
+    >>> index_slice.indexMap
+    {'c': 0, 'd': 1, 'e': 2}
+
+To prevent undesired behavior, Index instances are immutable:
+
+::
+
+    In [11]: index[2] = 'd'
+	---------------------------------------------------------------------------
+	Exception                                 Traceback (most recent call last)
+
+	pandas/core/index.pyc in __setitem__(self, key, value)
+	     98     def __setitem__(self, key, value):
+	     99         """Disable the setting of values."""
+	--> 100         raise Exception(str(self.__class__) + ' object is immutable' )
+	    101
+	    102     def __getitem__(self, key):
+
+	Exception: <class 'pandas.core.index.Index'> object is immutable
+
diff --git a/doc/source/missing_data.rst b/doc/source/missing_data.rst
new file mode 100644
index 000000000..02c98169d
--- /dev/null
+++ b/doc/source/missing_data.rst
@@ -0,0 +1,6 @@
+.. _missing_data:
+
+***************************************
+Design issues for handling missing data
+***************************************
+
diff --git a/doc/source/series.rst b/doc/source/series.rst
index 2f6b8c798..c8394764c 100644
--- a/doc/source/series.rst
+++ b/doc/source/series.rst
@@ -24,7 +24,8 @@ NumPy-based functions expecting one-dimensional ndarrays.
    :Parameters:
        **data** : {array_like, dict}
            Data to store in the array. Any data that is valid for
-           constructing a :class:`~numpy.ndarray` can be used here.
+           constructing a 1-D :class:`~numpy.ndarray` can be used
+           here.
 
            * a sequence of objects (numbers, characters, objects)
            * an :class:`~numpy.ndarray` or one of its subclass.
@@ -69,7 +70,7 @@ We could also create this Series from a dict representing the data:
 ::
 
     >>> data = {'a': 0.0, 'b': 1.0, 'c': 2.0, 'd': 3.0, 'e': 4.0}
-    >>> Series.fromDict(data)
+    >>> Series(data)
     a    0.0
     b    1.0
     c    2.0
@@ -118,15 +119,17 @@ the TimeSeries constructor):
     >>> type(ts)
     <class 'pandas.core.series.TimeSeries'>
 
-Summary of constructors
-~~~~~~~~~~~~~~~~~~~~~~~
+An alternate constructor, :func:`Series.fromValue`, is also available
+to facilitate creating a Series composed of a single value:
 
-.. autosummary::
-   :toctree: generated/
+::
 
-   Series.__new__
-   Series.fromDict
-   Series.fromValue
+    >>> Series.fromValue(1, index=labels)
+    a    1
+    b    1
+    c    1
+    d    1
+    e    1
 
 Indexing
 --------
@@ -145,7 +148,7 @@ index value:
 If the index contains integers and there is ambiguity, the index will
 be preferred.
 
-For completeness of the dict-like interface, the **get** function is
+For completeness of the dict-like interface, :func:`Series.get` is
 provided for analogous behavior:
 
 ::
@@ -226,7 +229,7 @@ Handling missing data and reindexing
 
 For all of the pandas data structures, we chose to represent missing
 data as NaN. However, missing data could be represented in some other
-forms (e.g. *None* values generated from DBNULL values in SQL
+forms (e.g. *None* values generated from null values in SQL
 data). This problem is compounded by the fact that *numpy.isnan* is
 only valid on float arrays. For this reason, pandas includes two
 functions for testing validity, **isnull** and **notnull**. These
@@ -234,6 +237,14 @@ functions are implemented in Cython and provide reasonably good
 performance on object arrays. For numerical arrays, the performance
 will be equivalent to *numpy.isfinite*.
 
+.. note::
+
+    The choice of using NaN for missing data was largely for
+    simplicity and performance reasons. IIt differs from the
+    MaskedArray approach of, for example,
+    :mod:`scikits.timeseries`. For a discussion of the issues with the
+    various approaches, :ref:`see here <missing_data>`
+
 ::
 
     >>> s
@@ -271,12 +282,6 @@ from a Series. Since this is such a common operation, a method
     d    3.0
     e    4.0
 
-.. note::
-
-    The choice of using NaN for missing data was one of practicality
-    and ease-of-implementation. It differs from the MaskedArray
-    approach of, for example, :mod:`scikits.timeseries`.
-
 .. _series.reindexing:
 
 Reindexing
@@ -323,6 +328,11 @@ back-filling:
     2009-01-06 00:00:00    4.0
     2009-01-07 00:00:00    4.0
 
+.. note::
+
+    This filling logic assumes that the both the new and old Index
+    objects have ordered values.
+
 Two common reindexing methods are provided: **valid** (which we
 already mentioned) and **truncate** (for selecting intervals of index
 values).
@@ -536,7 +546,7 @@ the 2- and 3-D cases, but the basic concept is the same:
 
     >>> s = Series(['six', 'seven', 'six', 'seven', 'six'],
                    index=['a', 'b', 'c', 'd', 'e'])
-    >>> t = Series.fromDict({'six' : 6., 'seven' : 7.})
+    >>> t = Series({'six' : 6., 'seven' : 7.})
 
     >>> s
     a	six
@@ -562,7 +572,69 @@ the 2- and 3-D cases, but the basic concept is the same:
 Sorting
 -------
 
-TODO
+A number of methods for sorting Series data are provided:
+
+::
+
+    >>> s = Series(randn(5), index=['a', 'b', 'c', 'd', 'e'])
+    >>> s
+    a    -0.308339649397
+    b    -0.447658314192
+    c    -0.391847354208
+    d    0.427084101354
+    e    1.51816072219
+
+    >>> s.order()
+    b    -0.447658314192
+    c    -0.391847354208
+    a    -0.308339649397
+    d    0.427084101354
+    e    1.51816072219
+
+    >>> s.argsort()
+    a    1
+    b    2
+    c    0
+    d    3
+    e    4
+
+    >>> s.sort()    # in-place sort
+    >>> s
+    b    -0.447658314192
+    c    -0.391847354208
+    a    -0.308339649397
+    d    0.427084101354
+    e    1.51816072219
+
+:func:`Series.order` is intended to behave similarly to the R function
+of the same name. In the presence of missing data it accepts an
+optional argument specifying where to sort the NaN values (either the
+end or the beginning). The default is to sort them to the end, which
+is the new sorting behavior in NumPy >= 1.4.0:
+
+::
+
+    >>> s
+    a    -2.21668112685
+    b    -0.520791835078
+    c    NaN
+    d    -0.788775281233
+    e    -0.779555719818
+
+    >>> s.order()
+    a    -2.21668112685
+    d    -0.788775281233
+    e    -0.779555719818
+    b    -0.520791835078
+    c    NaN
+
+    >>> s.order(missingAtEnd=False)
+    c    NaN
+    a    -2.21668112685
+    d    -0.788775281233
+    e    -0.779555719818
+    b    -0.520791835078
+
 
 .. autosummary::
    :toctree: generated/
@@ -574,7 +646,91 @@ TODO
 TimeSeries-oriented methods
 ---------------------------
 
-TODO
+.. seealso::
+    :ref:`Reindexing methods <series.reindexing>`;
+    :ref:`DateRange and date offsets / time rules <datetools>`
+
+.. note::
+
+    While pandas does not force you to sort your dates, many of these
+    methods may have unexpected or incorrect behavior in that case. In
+    other words, *be careful*.
+
+When working with time series data, a number of different
+time-oriented operations may be useful. The first is **frequency
+conversion**, which has similar options to :func:`Series.reindex`:
+
+::
+
+    >>> dr = DateRange('1/1/2010', periods=10,
+                       offset=datetools.BMonthEnd())
+    >>> ts = Series(np.arange(10.), index=dr)
+    >>> ts
+    2010-01-29 00:00:00    0.0
+    2010-02-26 00:00:00    1.0
+    2010-03-31 00:00:00    2.0
+    2010-04-30 00:00:00    3.0
+    2010-05-31 00:00:00    4.0
+    2010-06-30 00:00:00    5.0
+    2010-07-30 00:00:00    6.0
+    2010-08-31 00:00:00    7.0
+    2010-09-30 00:00:00    8.0
+    2010-10-29 00:00:00    9.0
+
+    >>> ts.asfreq('WEEKDAY', fillMethod='pad')
+    2010-01-29 00:00:00    0.0
+    2010-02-01 00:00:00    0.0
+    2010-02-02 00:00:00    0.0
+    2010-02-03 00:00:00    0.0
+    2010-02-04 00:00:00    0.0
+    <snip>
+    2010-10-22 00:00:00    8.0
+    2010-10-25 00:00:00    8.0
+    2010-10-26 00:00:00    8.0
+    2010-10-27 00:00:00    8.0
+    2010-10-28 00:00:00    8.0
+    2010-10-29 00:00:00    9.0
+
+We often will also want to **shift** or *lag* a TimeSeries:
+
+::
+
+    >>> ts.shift(1)
+    2010-01-29 00:00:00    NaN
+    2010-02-26 00:00:00    0.0
+    2010-03-31 00:00:00    1.0
+    2010-04-30 00:00:00    2.0
+    2010-05-31 00:00:00    3.0
+    2010-06-30 00:00:00    4.0
+    2010-07-30 00:00:00    5.0
+    2010-08-31 00:00:00    6.0
+    2010-09-30 00:00:00    7.0
+    2010-10-29 00:00:00    8.0
+
+    >>> ts.shift(5, offset=datetools.bday)
+    2010-02-05 00:00:00    0.0
+    2010-03-05 00:00:00    1.0
+    2010-04-07 00:00:00    2.0
+    2010-05-07 00:00:00    3.0
+    2010-06-07 00:00:00    4.0
+    2010-07-07 00:00:00    5.0
+    2010-08-06 00:00:00    6.0
+    2010-09-07 00:00:00    7.0
+    2010-10-07 00:00:00    8.0
+    2010-11-05 00:00:00    9.0
+
+In the presence of missing data with sorted dates
+
+A convenience method for selecting weekdays, similar to
+:mod:`scikits.timeseries` is also provided:
+
+::
+
+    >>> dr = DateRange('1/1/2010', periods=10, offset=datetools.bday)
+    >>> ts = Series(np.arange(10.), index=dr)
+    >>> ts[ts.weekday == 2]
+    2010-01-06 00:00:00    3.0
+    2010-01-13 00:00:00    8.0
 
 .. autosummary::
    :toctree: generated/
diff --git a/doc/source/stats.ols.rst b/doc/source/stats.ols.rst
index 4caa97a50..132f9bd2f 100644
--- a/doc/source/stats.ols.rst
+++ b/doc/source/stats.ols.rst
@@ -1,7 +1,3 @@
 Ordinary least squares
 ----------------------
 
-.. automodule:: pandas.stats.ols
-   :members:
-   :undoc-members:
-   :show-inheritance:
diff --git a/doc/source/stats.plm.rst b/doc/source/stats.plm.rst
index 45f481090..9b1da6f8e 100644
--- a/doc/source/stats.plm.rst
+++ b/doc/source/stats.plm.rst
@@ -1,7 +1,2 @@
 OLS Panel regression
 --------------------
-
-.. automodule:: pandas.stats.plm
-   .. :members:
-   .. :undoc-members:
-   .. :show-inheritance:
diff --git a/doc/source/stats.rst b/doc/source/stats.rst
index b54146ba1..ead411a5a 100755
--- a/doc/source/stats.rst
+++ b/doc/source/stats.rst
@@ -2,9 +2,9 @@
 
 .. _stats:
 
-*****************
-Statistical tools
-*****************
+*************************
+Statistical functionality
+*************************
 
 Least-squares entry-point
 -------------------------
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 52706888a..d928cb0af 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -724,7 +724,7 @@ class DataFrame(Picklable, Groupable):
         This DataFrame with rows containing any NaN values deleted
         """
         if specificColumns:
-            theCount = self.filterItems(specificColumns).count(axis=1)
+            theCount = self.filter(items=specificColumns).count(axis=1)
         else:
             theCount = self.count(axis=1)
 
@@ -758,7 +758,7 @@ class DataFrame(Picklable, Groupable):
 
             N = len(intersection)
 
-            filtered = self.filterItems(intersection)
+            filtered = self.filter(items=intersection)
             theCount = filtered.count(axis=1)
         else:
             theCount = self.count(axis=1)
@@ -1109,7 +1109,24 @@ class DataFrame(Picklable, Groupable):
 
     def filter(self, items=None, like=None, regex=None):
         """
-        TODO
+        Restrict frame's columns to set of items or wildcard
+
+        Parameters
+        ----------
+        items : list-like
+            List of columns to restrict to (must not all be present)
+        like : string
+            Keep columns where "arg in col == True"
+        regex : string (regular expression)
+            Keep columns with re.search(regex, col) == True
+
+        Notes
+        -----
+        Arguments are mutually exclusive!
+
+        Returns
+        -------
+        DataFrame with filtered columns
         """
         import re
         if items is not None:
@@ -1124,37 +1141,6 @@ class DataFrame(Picklable, Groupable):
 
         return self.reindex(columns=columns)
 
-    def filterItems(self, items):
-        """
-        Restrict frame's columns to input set of items.
-
-        Parameters
-        ----------
-        items : list-like
-            List of columns to restrict to (must not all be present)
-
-        Returns
-        -------
-        DataFrame with filtered columns
-        """
-        return self.filter(items=items)
-
-    def filterLike(self, arg):
-        """
-        Filter to columns partially matching the import argument.
-
-        Keep columns where "arg in col == True"
-
-        Parameter
-        ---------
-        arg : string
-
-        Return
-        ------
-        DataFrame with matching columns
-        """
-        return self.filter(like=arg)
-
     def sortUp(self, column=None):
         """
         Sort DataFrame in ascending order according to specified column,
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index d66efe986..4700ec573 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -219,10 +219,6 @@ class WidePanel(Panel):
     def keys(self):
         return list(self.items)
 
-    def iteritems(self):
-        for item in self.items:
-            yield item, self[item]
-
     def _get_values(self):
         return self._values
 
@@ -254,20 +250,9 @@ class WidePanel(Panel):
         except KeyError:
             raise KeyError('%s not contained in panel data items!' % key)
 
-        if loc == 0:
-            new_items = self.items[1:]
-            new_values = self.values[1:]
-        elif loc == (len(self.items) - 1):
-            new_items = self.items[:-1]
-            new_values = self.values[:-1]
-        else:
-            new_items = Index(np.concatenate((self.items[:loc],
-                                              self.items[loc + 1:])))
-            new_values = np.row_stack((self.values[:loc],
-                                      self.values[loc + 1:]))
-
-        self.items = new_items
-        self.values = new_values
+        indices = range(loc) + range(loc + 1, len(self.items))
+        self.items = self.items[indices]
+        self.values = self.values.take(indices, axis=0)
 
     def pop(self, key):
         """
@@ -634,7 +619,7 @@ class WidePanel(Panel):
 
         return LongPanel(values, self.items, index)
 
-    def filterItems(self, items):
+    def filter(self, items):
         """
         Restrict items in panel to input list
 
@@ -917,19 +902,19 @@ class WidePanel(Panel):
 
 
     def truncate(self, before=None, after=None, axis='major'):
-        """Function truncate a sorted DataFrame before and/or after
-        some particular dates.
+        """Function truncates a sorted Panel before and/or after
+        some particular dates
 
         Parameters
         ----------
         before : date
-            Truncate before date
+            Left boundary
         after : date
-            Truncate after date
+            Right boundary
 
         Returns
         -------
-        DataFrame
+        WidePanel
         """
         axis = self._get_axis_name(axis)
         index = self._get_axis(axis)
@@ -1374,7 +1359,7 @@ class LongPanel(Panel):
         return LongPanel(self.values[left : right],
                          self.items, new_index)
 
-    def filterItems(self, items):
+    def filter(self, items):
         """
         Restrict items in panel to input list
 
@@ -1864,7 +1849,7 @@ def _homogenize(frames, intersect=True):
 
     if intersect:
         for key, frame in adj_frames.iteritems():
-            result[key] = frame.filterItems(columns).reindex(index)
+            result[key] = frame.filter(columns).reindex(index)
     else:
         for key, frame in adj_frames.iteritems():
             if not isinstance(frame, DataMatrix):
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 66622203c..16b98e2e6 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -95,8 +95,8 @@ class Series(np.ndarray, Picklable, Groupable):
         and index sequence are used, the index will override the keys
         found in the dict.
 
-    Note
-    ----
+    Notes
+    -----
     If you combine two series, all values for an index position must
     be present or the value for that index position will be nan. The
     new index is the sorted union of the two Series indices.
@@ -111,10 +111,16 @@ class Series(np.ndarray, Picklable, Groupable):
             data = [data[idx] for idx in index]
 
         # Make a copy of the data, infer type
-        subarr = np.array(data, dtype=dtype, copy=copy)
+        try:
+            subarr = np.array(data, dtype=dtype, copy=copy)
+        except ValueError:
+            if dtype:
+                raise
+
+            subarr = np.array(data, dtype=object)
 
         if subarr.ndim == 0:
-            if isinstance(data, list):
+            if isinstance(data, list): # pragma: no cover
                 subarr = np.array(data, dtype=object)
             else:
                 return subarr.item()
@@ -532,15 +538,6 @@ class Series(np.ndarray, Picklable, Groupable):
         result = Series(np.where(isnull(this), other, this), index=newIndex)
         return result
 
-    def argsort(self, axis=0, kind='quicksort', order=None):
-        """
-        Overriding numpy's built-in cumsum functionality
-        """
-        arr = self.values().copy()
-        okLocs = notnull(arr)
-        arr[okLocs] = np.argsort(arr[okLocs])
-        return self.__class__(arr, index=self.index)
-
     def cumsum(self, axis=0, dtype=None, out=None):
         """
         Overriding numpy's built-in cumsum functionality
@@ -600,6 +597,21 @@ class Series(np.ndarray, Picklable, Groupable):
         self[:] = sortedSeries
         self.index = sortedSeries.index
 
+    def argsort(self, axis=0, kind='quicksort', order=None):
+        """
+        Overriding numpy's built-in cumsum functionality
+        """
+        values = self.values()
+        mask = isnull(values)
+
+        if mask.any():
+            result = values.copy()
+            notmask = -mask
+            result[notmask] = np.argsort(values[notmask])
+            return Series(result, index=self.index)
+        else:
+            return Series(np.argsort(values), index=self.index)
+
     def order(self, missingAtEnd=True):
         """
         Sorts Series object, by value, maintaining index-value object
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index f33b8a567..e85f09dbc 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -178,6 +178,14 @@ class TestDataFrame(unittest.TestCase):
         self.assertRaises(Exception, self.klass, mat, index=[1])
         self.assertRaises(Exception, self.klass, mat, columns=['A', 'B', 'C'])
 
+    def test_array_interface(self):
+        result = np.sqrt(self.frame)
+        self.assert_(type(result) is type(self.frame))
+        self.assert_(result.index is self.frame.index)
+        self.assert_(result.cols() == self.frame.cols())
+
+        assert_frame_equal(result, self.frame.apply(np.sqrt))
+
     def test_pickle(self):
         unpickled = pickle.loads(pickle.dumps(self.mixed_frame))
         assert_frame_equal(self.mixed_frame, unpickled)
@@ -925,7 +933,7 @@ class TestDataFrame(unittest.TestCase):
     def test_filter(self):
         # items
 
-        filtered = self.frame.filterItems(['A', 'B', 'E'])
+        filtered = self.frame.filter(['A', 'B', 'E'])
         self.assertEqual(len(filtered.cols()), 2)
         self.assert_('E' not in filtered)
 
@@ -933,7 +941,7 @@ class TestDataFrame(unittest.TestCase):
         fcopy = self.frame.copy()
         fcopy['AA'] = 1
 
-        filtered = fcopy.filterLike('A')
+        filtered = fcopy.filter(like='A')
         self.assertEqual(len(filtered.cols()), 2)
         self.assert_('AA' in filtered)
 
@@ -1034,19 +1042,43 @@ class TestDataFrame(unittest.TestCase):
         comb = self.empty.combineMult(self.frame)
         self.assert_(comb is self.frame)
 
-    def test_leftJoin(self):
+    def test_join_index(self):
+        # left / right
+
         f = self.frame.reindex(columns=['A', 'B'])[:10]
         f2 = self.frame.reindex(columns=['C', 'D'])
 
-        joined = f.join(f2, how='left')
+        joined = f.join(f2)
         self.assert_(f.index.equals(joined.index))
         self.assertEqual(len(joined.cols()), 4)
 
+        joined = f.join(f2, how='left')
+        self.assert_(joined.index.equals(f.index))
+        self.assertEqual(len(joined.cols()), 4)
+
+        joined = f.join(f2, how='right')
+        self.assert_(joined.index.equals(f2.index))
+        self.assertEqual(len(joined.cols()), 4)
+
         # corner case
         self.assertRaises(Exception, self.frame.join, self.frame,
                           how='left')
 
-    def test_outerJoin(self):
+        # inner
+
+        f = self.frame.reindex(columns=['A', 'B'])[:10]
+        f2 = self.frame.reindex(columns=['C', 'D'])
+
+        joined = f.join(f2, how='inner')
+        self.assert_(joined.index.equals(f.index.intersection(f2.index)))
+        self.assertEqual(len(joined.cols()), 4)
+
+        # corner case
+        self.assertRaises(Exception, self.frame.join, self.frame,
+                          how='inner')
+
+        # outer
+
         f = self.frame.reindex(columns=['A', 'B'])[:10]
         f2 = self.frame.reindex(columns=['C', 'D'])
 
@@ -1058,6 +1090,8 @@ class TestDataFrame(unittest.TestCase):
         self.assertRaises(Exception, self.frame.join, self.frame,
                           how='outer')
 
+        self.assertRaises(Exception, f.join, f2, how='foo')
+
     def test_join(self):
         index, data = common.getMixedTypeDict()
         target = self.klass(data, index=index)
diff --git a/pandas/core/tests/test_panel.py b/pandas/core/tests/test_panel.py
index 5f5a5b401..2562327f8 100644
--- a/pandas/core/tests/test_panel.py
+++ b/pandas/core/tests/test_panel.py
@@ -8,9 +8,10 @@ import numpy as np
 from pandas.core.api import Index, notnull
 from pandas.core.datetools import bday
 from pandas.core.panel import WidePanel, LongPanelIndex, LongPanel
-from pandas.util.testing import (assert_frame_equal,
-                                      assert_series_equal,
-                                      assert_almost_equal)
+from pandas.util.testing import (assert_panel_equal,
+                                 assert_frame_equal,
+                                 assert_series_equal,
+                                 assert_almost_equal)
 import pandas.util.testing as common
 
 class PanelTests(object):
@@ -215,24 +216,53 @@ class TestWidePanel(unittest.TestCase, PanelTests):
                          len(self.panel.items))
 
     def test_values(self):
-        pass
+        self.assertRaises(Exception, WidePanel, np.random.randn(5, 5, 5),
+                          range(5), range(5), range(4))
 
     def test_getitem(self):
-        pass
+        self.assertRaises(Exception, self.panel.__getitem__, 'ItemQ')
 
-    def test_delitem_pop(self):
+    def test_delitem_and_pop(self):
         expected = self.panel['ItemA']
         result = self.panel.pop('ItemA')
         assert_frame_equal(expected, result)
         self.assert_('ItemA' not in self.panel.items)
 
+        del self.panel['ItemB']
+        self.assert_('ItemB' not in self.panel.items)
+        self.assertRaises(Exception, self.panel.__delitem__, 'ItemB')
+
+        values = np.empty((3, 3, 3))
+        values[0] = 0
+        values[1] = 1
+        values[2] = 2
+
+        panel = WidePanel(values, range(3), range(3), range(3))
+
+        # did we delete the right row?
+
+        panelc = panel.copy()
+        del panelc[0]
+        assert_frame_equal(panelc[1], panel[1])
+        assert_frame_equal(panelc[2], panel[2])
+
+        panelc = panel.copy()
+        del panelc[1]
+        assert_frame_equal(panelc[0], panel[0])
+        assert_frame_equal(panelc[2], panel[2])
+
+        panelc = panel.copy()
+        del panelc[2]
+        assert_frame_equal(panelc[1], panel[1])
+        assert_frame_equal(panelc[0], panel[0])
+
     def test_setitem(self):
 
         # LongPanel with one item
-        lp = self.panel.filterItems(['ItemA']).toLong()
+        lp = self.panel.filter(['ItemA']).toLong()
         self.panel['ItemE'] = lp
 
-        lp = self.panel.filterItems(['ItemA', 'ItemB']).toLong()
+        lp = self.panel.filter(['ItemA', 'ItemB']).toLong()
         self.assertRaises(Exception, self.panel.__setitem__,
                           'ItemE', lp)
 
@@ -265,12 +295,12 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         assert_frame_equal(result['ItemB'], ref)
 
         # major
-        new_major = self.panel.major_axis[:10]
+        new_major = list(self.panel.major_axis[:10])
         result = self.panel.reindex(major=new_major)
         assert_frame_equal(result['ItemB'], ref.reindex(index=new_major))
 
         # minor
-        new_minor = self.panel.minor_axis[:2]
+        new_minor = list(self.panel.minor_axis[:2])
         result = self.panel.reindex(minor=new_minor)
         assert_frame_equal(result['ItemB'], ref.reindex(columns=new_minor))
 
@@ -329,11 +359,19 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         check_op(operator.div, 'divide')
 
     def test_combinePanel(self):
-        pass
+        result = self.panel.add(self.panel)
+        assert_panel_equal(result, self.panel * 2)
+
+        long = self.panel.toLong(filter_observations=False)
+        result = self.panel.add(long)
+        assert_panel_equal(result, self.panel * 2)
 
     def test_operators(self):
         pass
 
+    def test_neg(self):
+        assert_panel_equal(-self.panel, self.panel * -1)
+
     def test_getMajorXS(self):
         ref = self.panel['ItemA']
 
@@ -374,6 +412,9 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         result = self.panel.swapaxes(0, 1)
         self.assert_(result.items is self.panel.major_axis)
 
+        # this should also work
+        self.assertRaises(Exception, self.panel.swapaxes, 'items', 'items')
+
     def test_toLong(self):
         # filtered
         filtered = self.panel.toLong()
@@ -381,13 +422,20 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         # unfiltered
         unfiltered = self.panel.toLong(filter_observations=False)
 
+        assert_panel_equal(unfiltered.toWide(), self.panel)
 
-    def test_filterItems(self):
+    def test_filter(self):
         pass
 
     def test_apply(self):
         pass
 
+    def test_compound(self):
+        compounded = self.panel.compound()
+
+        assert_series_equal(compounded['ItemA'],
+                            (1 + self.panel['ItemA']).product(0) - 1)
+
     def test_shift(self):
         # major
         idx = self.panel.major_axis[0]
@@ -407,7 +455,7 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         assert_frame_equal(self.panel.getMinorXS(idx),
                            shifted.getMinorXS(idx_lag))
 
-        self.assertRaises(Exception, self.panel.shift, axis='items')
+        self.assertRaises(Exception, self.panel.shift, 1, axis='items')
 
 class TestLongPanelIndex(unittest.TestCase):
 
@@ -563,7 +611,7 @@ class TestLongPanel(unittest.TestCase):
     def test_truncate(self):
         pass
 
-    def test_filterItems(self):
+    def test_filter(self):
         pass
 
     def test_getAxisDummies(self):
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index 011d152f5..631a6d77d 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -52,6 +52,12 @@ class TestSeries(unittest.TestCase):
         self.assertRaises(Exception, Series, np.random.randn(3, 3),
                           index=np.arange(3))
 
+    def test_constructor_corner(self):
+        df = common.makeTimeDataFrame()
+        objs = [df, df]
+        s = Series(objs, index=[0, 1])
+        self.assert_(isinstance(s, Series))
+
     def test_fromDict(self):
         data = {'a' : 0, 'b' : 1, 'c' : 2, 'd' : 3}
 
@@ -372,6 +378,9 @@ class TestSeries(unittest.TestCase):
 
             self.assert_(np.array_equal(result, expected))
 
+        argsorted = self.ts.argsort()
+        self.assert_(argsorted.dtype == np.int_)
+
     def test_median(self):
         self.assertAlmostEqual(np.median(self.ts), self.ts.median())
 
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index acfd0f112..4425b5ff2 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -10,6 +10,7 @@ from StringIO import StringIO
 import numpy as np
 
 from pandas.core.api import DataFrame, DataMatrix, Series
+from pandas.core.panel import WidePanel
 from pandas.util.decorators import cache_readonly
 import pandas.lib.tseries as tseries
 import pandas.stats.common as common
@@ -630,13 +631,14 @@ class MovingOLS(OLS):
     @cache_readonly
     def var_beta(self):
         """Returns the covariance of beta."""
-        result = []
+        result = {}
+        result_index = self._result_index
         for i in xrange(len(self._var_beta_raw)):
             dm = DataMatrix(self._var_beta_raw[i], columns=self.beta.cols(),
                             index=self.beta.cols())
-            result.append(dm)
+            result[result_index[i]] = dm
 
-        return Series(result, index=self._result_index)
+        return WidePanel.fromDict(result, intersect=False)
 
     @cache_readonly
     def y_fitted(self):
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index d8651eeef..6d5c6b78e 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -117,9 +117,8 @@ class PanelOLS(OLS):
         x_filtered = self._add_dummies(x_filtered, cat_mapping)
 
         if self._x_effects:
-            x = x.filterItems(x.items - self._x_effects)
-            x_filtered = x_filtered.filterItems(x_filtered.items
-                                                - self._x_effects)
+            x = x.filter(x.items - self._x_effects)
+            x_filtered = x_filtered.filter(x_filtered.items - self._x_effects)
 
         if self._time_effects:
             x_regressor = x.subtract(x.mean(broadcast=True))
@@ -170,14 +169,14 @@ class PanelOLS(OLS):
         data['__y__'] = self._y_orig
         data_long = data.toLong()
 
-        x_filt = filtered.filterItems(x_names)
+        x_filt = filtered.filter(x_names)
 
         if self._weights:
             weights_filt = filtered['__weights__']
         else:
             weights_filt = None
 
-        x = data_long.filterItems(x_names)
+        x = data_long.filter(x_names)
         y = data_long['__y__']
 
         if self._weights:
@@ -254,7 +253,7 @@ class PanelOLS(OLS):
 
             self.log('-- Excluding dummy for entity: %s' % to_exclude)
 
-            dummies = dummies.filterItems(dummies.items - [to_exclude])
+            dummies = dummies.filter(dummies.items - [to_exclude])
 
         dummies = dummies.addPrefix('FE_')
         panel = panel.leftJoin(dummies)
@@ -298,7 +297,7 @@ class PanelOLS(OLS):
 
                 self.log('-- Excluding dummy for %s: %s' % (effect, to_exclude))
 
-                dummies = dummies.filterItems(dummies.items - [mapped_name])
+                dummies = dummies.filter(dummies.items - [mapped_name])
                 dropped_dummy = True
 
             dummies = _convertDummies(dummies, cat_mappings.get(effect))
diff --git a/pandas/stats/tests/common.py b/pandas/stats/tests/common.py
index d08411775..cf6473555 100644
--- a/pandas/stats/tests/common.py
+++ b/pandas/stats/tests/common.py
@@ -61,9 +61,9 @@ class BaseTest(unittest.TestCase):
         self.panel_y = A
         self.panel_x = {'B' : B, 'C' : C}
 
-        self.series_panel_y = A.filterItems(['ColA'])
-        self.series_panel_x = {'B' : B.filterItems(['ColA']),
-                               'C' : C.filterItems(['ColA'])}
+        self.series_panel_y = A.filter(['ColA'])
+        self.series_panel_x = {'B' : B.filter(['ColA']),
+                               'C' : C.filter(['ColA'])}
         self.series_y = A['ColA']
         self.series_x = {'B' : B['ColA'],
                          'C' : C['ColA']}
@@ -76,7 +76,8 @@ class BaseTest(unittest.TestCase):
                    datetime(2000, 1, 2),
                    datetime(2000, 1, 3)]
         y_cols = ['A', 'B']
-        self.panel_y2 = DataMatrix(np.array(y_data), index=y_index, columns=y_cols)
+        self.panel_y2 = DataMatrix(np.array(y_data), index=y_index,
+                                   columns=y_cols)
 
         x1_data = [[6, np.NaN],
                    [7, 8],
@@ -87,7 +88,8 @@ class BaseTest(unittest.TestCase):
                     datetime(2000, 1, 3),
                     datetime(2000, 1, 4)]
         x1_cols = ['A', 'B']
-        x1 = DataMatrix(np.array(x1_data), index=x1_index, columns=x1_cols)
+        x1 = DataMatrix(np.array(x1_data), index=x1_index,
+                        columns=x1_cols)
 
         x2_data = [[13, 14, np.NaN],
                    [15, np.NaN, np.NaN],
@@ -100,7 +102,8 @@ class BaseTest(unittest.TestCase):
                     datetime(2000, 1, 4),
                     datetime(2000, 1, 5)]
         x2_cols = ['C', 'A', 'B']
-        x2 = DataMatrix(np.array(x2_data), index=x2_index, columns=x2_cols)
+        x2 = DataMatrix(np.array(x2_data), index=x2_index,
+                        columns=x2_cols)
 
         self.panel_x2 = {'x1' : x1, 'x2' : x2}
 
@@ -110,20 +113,23 @@ class BaseTest(unittest.TestCase):
         y_index = [datetime(2000, 1, 1),
                    datetime(2000, 1, 2)]
         y_cols = ['A', 'B']
-        self.panel_y3 = DataMatrix(np.array(y_data), index=y_index, columns=y_cols)
+        self.panel_y3 = DataMatrix(np.array(y_data), index=y_index,
+                                   columns=y_cols)
 
         x1_data = [['A', 'B'],
                    ['C', 'A']]
         x1_index = [datetime(2000, 1, 1),
                     datetime(2000, 1, 2)]
         x1_cols = ['A', 'B']
-        x1 = DataMatrix(np.array(x1_data), index=x1_index, columns=x1_cols)
+        x1 = DataMatrix(np.array(x1_data), index=x1_index,
+                        columns=x1_cols)
 
         x2_data = [['3.14', '1.59'],
                    ['2.65', '3.14']]
         x2_index = [datetime(2000, 1, 1),
                     datetime(2000, 1, 2)]
         x2_cols = ['A', 'B']
-        x2 = DataMatrix(np.array(x2_data), index=x2_index, columns=x2_cols)
+        x2 = DataMatrix(np.array(x2_data), index=x2_index,
+                        columns=x2_cols)
 
         self.panel_x3 = {'x1' : x1, 'x2' : x2}
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index 0dd1cb5d2..55ca67b7a 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -115,8 +115,7 @@ class VAR(object):
         for col in self._columns:
             d[col] = {}
             for i in xrange(1, 1 + self._p):
-                lagged_data = self._lagged_data[i].filterItems(
-                    self._columns - [col])
+                lagged_data = self._lagged_data[i].filter(self._columns - [col])
 
                 for key, value in lagged_data.iteritems():
                     d[col][_make_param_name(i, key)] = value
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index f85333c28..141afba8c 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -77,6 +77,14 @@ def assert_frame_equal(left, right):
     for col in right:
         assert(col in left)
 
+def assert_panel_equal(left, right):
+    for col, series in left.iteritems():
+        assert(col in right)
+        assert_frame_equal(series, right[col])
+
+    for col in right:
+        assert(col in left)
+
 def assert_contains_all(iterable, dic):
     for k in iterable:
         assert(k in dic)
