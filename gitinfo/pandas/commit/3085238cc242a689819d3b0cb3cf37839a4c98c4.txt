commit 3085238cc242a689819d3b0cb3cf37839a4c98c4
Author: Adam Klein <adamklein@gmail.com>
Date:   Thu Jan 5 13:45:02 2012 -0500

    fixed docstring copying

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 998f828ae..bccb58299 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -32,7 +32,7 @@ from pandas.core.internals import BlockManager, make_block, form_blocks
 from pandas.core.series import Series
 from pandas.util import py3compat
 from pandas.util.terminal import get_terminal_size
-from pandas.util.decorators import deprecate, Appender
+from pandas.util.decorators import deprecate, Appender, Substitution
 
 from pandas.core.format import DataFrameFormatter, docstring_to_string
 
@@ -162,19 +162,12 @@ Returns
 merged : DataFrame
 """
 
-def _add_stat_doc(f, name, shortname, na_action=_doc_exclude_na,
-                  extras=''):
-    doc = _stat_doc % {'name' : name,
-                       'shortname' : shortname,
-                       'na_action' : na_action,
-                       'extras' : extras}
-    f.__doc__ = doc
-
 
 #----------------------------------------------------------------------
 # Factory helper methods
 
 def _arith_method(func, name, default_axis='columns'):
+    @Appender(_arith_doc % name)
     def f(self, other, axis=default_axis, level=None, fill_value=None):
         if isinstance(other, DataFrame):    # Another DataFrame
             return self._combine_frame(other, func, fill_value, level)
@@ -184,12 +177,12 @@ def _arith_method(func, name, default_axis='columns'):
             return self._combine_const(other, func)
 
     f.__name__ = name
-    f.__doc__ = _arith_doc % name
 
     return f
 
 
 def comp_method(func, name):
+    @Appender('Wrapper for comparison method %s' % name)
     def f(self, other):
         if isinstance(other, DataFrame):    # Another DataFrame
             return self._compare_frame(other, func)
@@ -199,7 +192,6 @@ def comp_method(func, name):
             return self._combine_const(other, func)
 
     f.__name__ = name
-    f.__doc__ = 'Wrapper for comparison method %s' % name
 
     return f
 
@@ -2844,6 +2836,8 @@ class DataFrame(NDFrame):
             return concat([self] + list(other), axis=1, join=how,
                           join_axes=join_axes, verify_integrity=True)
 
+    @Substitution('')
+    @Appender(_merge_doc, indents=2)
     def merge(self, right, how='inner', on=None, left_on=None, right_on=None,
               left_index=False, right_index=False, sort=True,
               suffixes=('.x', '.y'), copy=True):
@@ -2852,7 +2846,6 @@ class DataFrame(NDFrame):
                      left_on=left_on, right_on=right_on,
                      left_index=left_index, right_index=right_index, sort=sort,
                      suffixes=suffixes, copy=copy)
-    if __debug__: merge.__doc__ = _merge_doc % ''
 
     #----------------------------------------------------------------------
     # Statistical methods, etc.
@@ -3061,56 +3054,71 @@ class DataFrame(NDFrame):
         else:
             return result
 
+    @Substitution(name='sum', shortname='sum', na_action=_doc_exclude_na,
+                  extras=_numeric_only_doc)
+    @Appender(_stat_doc)
     def sum(self, axis=0, numeric_only=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('sum', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nansum, axis=axis, skipna=skipna,
                             numeric_only=numeric_only)
-    _add_stat_doc(sum, 'sum', 'sum', extras=_numeric_only_doc)
 
+    @Substitution(name='mean', shortname='mean', na_action=_doc_exclude_na,
+                  extras='')
+    @Appender(_stat_doc)
     def mean(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('mean', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanmean, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(mean, 'mean', 'mean')
 
+    @Substitution(name='minimum', shortname='min', na_action=_doc_exclude_na,
+                  extras='')
+    @Appender(_stat_doc)
     def min(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('min', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanmin, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(min, 'minimum', 'min')
 
+    @Substitution(name='maximum', shortname='max', na_action=_doc_exclude_na,
+                  extras='')
+    @Appender(_stat_doc)
     def max(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('max', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanmax, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(max, 'maximum', 'max')
 
+    @Substitution(name='product', shortname='product',
+                  na_action='NA/null values are treated as 1', extras='')
+    @Appender(_stat_doc)
     def prod(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('prod', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanprod, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(prod, 'product', 'product',
-                  na_action='NA/null values are treated as 1')
+
     product = prod
 
+    @Substitution(name='median', shortname='median', na_action=_doc_exclude_na,
+                  extras='')
+    @Appender(_stat_doc)
     def median(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('median', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanmedian, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(median, 'median', 'median')
 
+    @Substitution(name='median absolute deviation', shortname='mad', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def mad(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('mad', axis=axis, level=level,
@@ -3123,30 +3131,35 @@ class DataFrame(NDFrame):
         else:
             demeaned = frame.sub(frame.mean(axis=1), axis=0)
         return np.abs(demeaned).mean(axis=axis, skipna=skipna)
-    _add_stat_doc(mad, 'mean absolute deviation', 'mad')
 
+    @Substitution(name='unbiased variance', shortname='var',
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def var(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('var', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanvar, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(var, 'unbiased variance', 'var')
 
+    @Substitution(name='unbiased standard deviation', shortname='std',
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def std(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('std', axis=axis, level=level,
                                       skipna=skipna)
         return np.sqrt(self.var(axis=axis, skipna=skipna))
-    _add_stat_doc(std, 'unbiased standard deviation', 'std')
 
+    @Substitution(name='unbiased skewness', shortname='skew',
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def skew(self, axis=0, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('skew', axis=axis, level=level,
                                       skipna=skipna)
         return self._reduce(nanops.nanskew, axis=axis, skipna=skipna,
                             numeric_only=None)
-    _add_stat_doc(skew, 'unbiased skewness', 'skew')
 
     def _agg_by_level(self, name, axis=0, level=0, skipna=True):
         grouped = self.groupby(level=level, axis=axis)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index f42599c9e..a11a4ddde 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -9,7 +9,7 @@ from pandas.core.index import Index, MultiIndex
 from pandas.core.internals import BlockManager
 from pandas.core.series import Series
 from pandas.core.panel import Panel
-from pandas.util.decorators import cache_readonly
+from pandas.util.decorators import cache_readonly, Appender
 import pandas._tseries as lib
 
 
@@ -472,6 +472,7 @@ class GroupBy(object):
                                            axis=self.axis,
                                            factory=factory)
 
+@Appender(GroupBy.__doc__)
 def groupby(obj, by, **kwds):
     if isinstance(obj, Series):
         klass = SeriesGroupBy
@@ -481,7 +482,6 @@ def groupby(obj, by, **kwds):
         raise TypeError('invalid type: %s' % type(obj))
 
     return klass(obj, by, **kwds)
-groupby.__doc__ = GroupBy.__doc__
 
 def _get_axes(group):
     if isinstance(group, Series):
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 3c1ae9364..b091b8e5d 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -16,7 +16,7 @@ from pandas.core.internals import BlockManager, make_block, form_blocks
 from pandas.core.frame import DataFrame
 from pandas.core.generic import NDFrame
 from pandas.util import py3compat
-from pandas.util.decorators import deprecate
+from pandas.util.decorators import deprecate, Appender, Substitution
 import pandas.core.common as com
 import pandas.core.nanops as nanops
 import pandas._tseries as lib
@@ -97,6 +97,7 @@ def _arith_method(func, name):
     return f
 
 def _panel_arith_method(op, name):
+    @Substitution(op)
     def f(self, other, axis='items'):
         """
         Wrapper method for %s
@@ -114,9 +115,6 @@ def _panel_arith_method(op, name):
         return self._combine(other, op, axis=axis)
 
     f.__name__ = name
-    if __debug__:
-        f.__doc__ = f.__doc__ % str(op)
-
     return f
 
 
@@ -141,11 +139,6 @@ NA/null values are %s.
 If all values are NA, result will be NA"""
 
 
-def _add_docs(method, desc, outname):
-    doc = _agg_doc % {'desc' : desc,
-                      'outname' : outname}
-    method.__doc__ = doc
-
 class Panel(NDFrame):
     _AXIS_NUMBERS = {
         'items' : 0,
@@ -982,45 +975,55 @@ class Panel(NDFrame):
 
         return self._wrap_result(result, axis)
 
+    @Substitution(desc='sum', outname='sum')
+    @Appender(_agg_doc)
     def sum(self, axis='major', skipna=True):
         return self._reduce(nanops.nansum, axis=axis, skipna=skipna)
-    _add_docs(sum, 'sum', 'sum')
 
+    @Substitution(desc='mean', outname='mean')
+    @Appender(_agg_doc)
     def mean(self, axis='major', skipna=True):
         return self._reduce(nanops.nanmean, axis=axis, skipna=skipna)
-    _add_docs(mean, 'mean', 'mean')
 
+    @Substitution(desc='unbiased variance', outname='variance')
+    @Appender(_agg_doc)
     def var(self, axis='major', skipna=True):
         return self._reduce(nanops.nanvar, axis=axis, skipna=skipna)
-    _add_docs(var, 'unbiased variance', 'variance')
 
+    @Substitution(desc='unbiased standard deviation', outname='stdev')
+    @Appender(_agg_doc)
     def std(self, axis='major', skipna=True):
         return self.var(axis=axis, skipna=skipna).apply(np.sqrt)
-    _add_docs(std, 'unbiased standard deviation', 'stdev')
 
+    @Substitution(desc='unbiased skewness', outname='skew')
+    @Appender(_agg_doc)
     def skew(self, axis='major', skipna=True):
         return self._reduce(nanops.nanskew, axis=axis, skipna=skipna)
-    _add_docs(std, 'unbiased skewness', 'skew')
 
+    @Substitution(desc='product', outname='prod')
+    @Appender(_agg_doc)
     def prod(self, axis='major', skipna=True):
         return self._reduce(nanops.nanprod, axis=axis, skipna=skipna)
-    _add_docs(prod, 'product', 'prod')
 
+    @Substitution(desc='compounded percentage', outname='compounded')
+    @Appender(_agg_doc)
     def compound(self, axis='major', skipna=True):
         return (1 + self).prod(axis=axis, skipna=skipna) - 1
-    _add_docs(compound, 'compounded percentage', 'compounded')
 
+    @Substitution(desc='median', outname='median')
+    @Appender(_agg_doc)
     def median(self, axis='major', skipna=True):
         return self._reduce(nanops.nanmedian, axis=axis, skipna=skipna)
-    _add_docs(median, 'median', 'median')
 
+    @Substitution(desc='maximum', outname='maximum')
+    @Appender(_agg_doc)
     def max(self, axis='major', skipna=True):
         return self._reduce(nanops.nanmax, axis=axis, skipna=skipna)
-    _add_docs(max, 'maximum', 'maximum')
 
+    @Substitution(desc='minimum', outname='minimum')
+    @Appender(_agg_doc)
     def min(self, axis='major', skipna=True):
         return self._reduce(nanops.nanmin, axis=axis, skipna=skipna)
-    _add_docs(min, 'minimum', 'minimum')
 
     def shift(self, lags, axis='major'):
         """
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 80bc21e5d..0d60b1847 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -28,6 +28,8 @@ import pandas.core.nanops as nanops
 import pandas._tseries as lib
 import pandas._engines as _gin
 
+from pandas.util.decorators import Appender, Substitution
+
 __all__ = ['Series', 'TimeSeries']
 
 #-------------------------------------------------------------------------------
@@ -68,10 +70,7 @@ def _maybe_match_name(a, b):
     return name
 
 def _flex_method(op, name):
-    def f(self, other, level=None, fill_value=None):
-        return self._binop(other, op, level=level, fill_value=fill_value)
-
-    f.__doc__ = """
+    doc = """
     Binary operator %s with support to substitute a fill_value for missing data
     in one of the inputs
 
@@ -89,17 +88,22 @@ def _flex_method(op, name):
     -------
     result : Series
     """ % name
+
+    @Appender(doc)
+    def f(self, other, level=None, fill_value=None):
+        return self._binop(other, op, level=level, fill_value=fill_value)
+
     f.__name__ = name
     return f
 
 def _unbox(func):
+    @Appender(func.__doc__)
     def f(self, *args, **kwargs):
         result = func(self, *args, **kwargs)
         if isinstance(result, np.ndarray) and result.ndim == 0:
             return result.item()
         else:  # pragma: no cover
             return result
-    f.__doc__ = func.__doc__
     f.__name__ = func.__name__
     return f
 
@@ -123,14 +127,6 @@ _doc_exclude_na = "NA/null values are excluded"
 _doc_ndarray_interface = ("Extra parameters are to preserve ndarray"
                           "interface.\n")
 
-def _add_stat_doc(f, name, shortname, na_action=_doc_exclude_na,
-                  extras=''):
-    doc = _stat_doc % {'name' : name,
-                       'shortname' : shortname,
-                       'na_action' : na_action,
-                       'extras' : extras}
-    f.__doc__ = doc
-
 #-------------------------------------------------------------------------------
 # Series class
 
@@ -705,71 +701,91 @@ copy : boolean, default False
         """
         return len(self.value_counts())
 
+    @Substitution(name='sum', shortname='sum', na_action=_doc_exclude_na,
+                  extras=_doc_ndarray_interface)
+    @Appender(_stat_doc)
     def sum(self, axis=0, dtype=None, out=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('sum', level=level, skipna=skipna)
         return nanops.nansum(self.values, skipna=skipna, copy=True)
-    _add_stat_doc(sum, 'sum', 'sum', extras=_doc_ndarray_interface)
 
+    @Substitution(name='mean', shortname='mean', na_action=_doc_exclude_na,
+                  extras=_doc_ndarray_interface)
+    @Appender(_stat_doc)
     def mean(self, axis=0, dtype=None, out=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('mean', level=level, skipna=skipna)
         return nanops.nanmean(self.values, skipna=skipna)
-    _add_stat_doc(mean, 'mean', 'mean', extras=_doc_ndarray_interface)
 
+    @Substitution(name='mean absolute deviation', shortname='mad', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def mad(self, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('mad', level=level, skipna=skipna)
 
         demeaned = self - self.mean(skipna=skipna)
         return np.abs(demeaned).mean(skipna=skipna)
-    _add_stat_doc(mad, 'mean absolute deviation', 'mad')
 
+    @Substitution(name='median', shortname='median', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def median(self, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('median', level=level, skipna=skipna)
         return nanops.nanmedian(self.values, skipna=skipna)
-    _add_stat_doc(median, 'median', 'median')
 
+    @Substitution(name='product', shortname='product', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def prod(self, axis=None, dtype=None, out=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('prod', level=level, skipna=skipna)
         return nanops.nanprod(self.values, skipna=skipna)
-    _add_stat_doc(prod, 'product', 'product')
 
+    @Substitution(name='minimum', shortname='min', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def min(self, axis=None, out=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('min', level=level, skipna=skipna)
         return nanops.nanmin(self.values, skipna=skipna, copy=True)
-    _add_stat_doc(min, 'minimum', 'min')
 
+    @Substitution(name='maximum', shortname='max', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def max(self, axis=None, out=None, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('max', level=level, skipna=skipna)
         return nanops.nanmax(self.values, skipna=skipna, copy=True)
-    _add_stat_doc(max, 'maximum', 'max')
 
+    @Substitution(name='unbiased standard deviation', shortname='stdev', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def std(self, axis=None, dtype=None, out=None, ddof=1, skipna=True,
             level=None):
         if level is not None:
             return self._agg_by_level('std', level=level, skipna=skipna)
         return np.sqrt(nanops.nanvar(self.values, skipna=skipna, copy=True,
                                      ddof=ddof))
-    _add_stat_doc(std, 'unbiased standard deviation', 'stdev')
 
+    @Substitution(name='unbiased variance', shortname='var', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def var(self, axis=None, dtype=None, out=None, ddof=1, skipna=True,
             level=None):
         if level is not None:
             return self._agg_by_level('var', level=level, skipna=skipna)
         return nanops.nanvar(self.values, skipna=skipna, copy=True, ddof=ddof)
-    _add_stat_doc(var, 'unbiased variance', 'var')
 
+    @Substitution(name='unbiased skewness', shortname='skew', 
+                  na_action=_doc_exclude_na, extras='')
+    @Appender(_stat_doc)
     def skew(self, skipna=True, level=None):
         if level is not None:
             return self._agg_by_level('skew', level=level, skipna=skipna)
 
         return nanops.nanskew(self.values, skipna=skipna, copy=True)
-    _add_stat_doc(skew, 'unbiased skewness', 'skew')
 
     def _agg_by_level(self, name, level=0, skipna=True):
         grouped = self.groupby(level=level)
@@ -873,6 +889,7 @@ copy : boolean, default False
 
         return Series(result, index=self.index)
 
+    @Appender(np.ndarray.round.__doc__)
     def round(self, decimals=0, out=None):
         """
 
@@ -882,7 +899,6 @@ copy : boolean, default False
             result = Series(result, index=self.index, name=self.name)
 
         return result
-    round.__doc__ = np.ndarray.round.__doc__
 
     def quantile(self, q=0.5):
         """
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 3fb459d2c..a9eba10e2 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -3,7 +3,6 @@ Module contains tools for processing files into DataFrames or other objects
 """
 from StringIO import StringIO
 import re
-import zipfile
 
 import numpy as np
 
@@ -11,63 +10,7 @@ from pandas.core.index import Index, MultiIndex
 from pandas.core.frame import DataFrame
 import pandas._tseries as lib
 
-def read_csv(filepath_or_buffer, sep=None, header=0, index_col=None, names=None,
-             skiprows=None, na_values=None, parse_dates=False,
-             date_parser=None, nrows=None, iterator=False, chunksize=None,
-             skip_footer=0, converters=None):
-    if hasattr(filepath_or_buffer, 'read'):
-        f = filepath_or_buffer
-    else:
-        try:
-            # universal newline mode
-            f = open(filepath_or_buffer, 'U')
-        except Exception: # pragma: no cover
-            f = open(filepath_or_buffer, 'r')
-
-    if date_parser is not None:
-        parse_dates = True
-
-    parser = TextParser(f, header=header, index_col=index_col,
-                        names=names, na_values=na_values,
-                        parse_dates=parse_dates,
-                        date_parser=date_parser,
-                        skiprows=skiprows,
-                        delimiter=sep,
-                        chunksize=chunksize,
-                        skip_footer=skip_footer,
-                        converters=converters)
-
-    if nrows is not None:
-        return parser.get_chunk(nrows)
-    elif chunksize or iterator:
-        return parser
-
-    return parser.get_chunk()
-
-
-def read_table(filepath_or_buffer, sep='\t', header=0, index_col=None,
-               names=None, skiprows=None, na_values=None, parse_dates=False,
-               date_parser=None, nrows=None, iterator=False, chunksize=None,
-               skip_footer=0, converters=None):
-    return read_csv(filepath_or_buffer, sep=sep, header=header,
-                    skiprows=skiprows, index_col=index_col,
-                    na_values=na_values, date_parser=date_parser,
-                    names=names, parse_dates=parse_dates,
-                    nrows=nrows, iterator=iterator, chunksize=chunksize,
-                    skip_footer=skip_footer, converters=converters)
-
-def read_clipboard(**kwargs):  # pragma: no cover
-    """
-    Read text from clipboard and pass to read_table. See read_table for the full
-    argument list
-
-    Returns
-    -------
-    parsed : DataFrame
-    """
-    from pandas.util.clipboard import clipboard_get
-    text = clipboard_get()
-    return read_table(StringIO(text), **kwargs)
+from pandas.util.decorators import Appender
 
 _parser_params = """Also supports optionally iterating or breaking of the file
 into chunks.
@@ -116,7 +59,7 @@ _csv_sep = """sep : string, default None
 _table_sep = """sep : string, default \\t (tab-stop)
     Delimiter to use"""
 
-read_csv.__doc__ = """
+_read_csv_doc = """
 Read CSV (comma-separated) file into DataFrame
 
 %s
@@ -126,7 +69,17 @@ Returns
 parsed : DataFrame
 """ % (_parser_params % _csv_sep)
 
-read_table.__doc__ = """
+_read_csv_doc = """
+Read CSV (comma-separated) file into DataFrame
+
+%s
+
+Returns
+-------
+parsed : DataFrame
+""" % (_parser_params % _csv_sep)
+
+_read_table_doc = """
 Read delimited file into DataFrame
 
 %s
@@ -136,6 +89,65 @@ Returns
 parsed : DataFrame
 """ % (_parser_params % _table_sep)
 
+@Appender(_read_csv_doc)
+def read_csv(filepath_or_buffer, sep=None, header=0, index_col=None, names=None,
+             skiprows=None, na_values=None, parse_dates=False,
+             date_parser=None, nrows=None, iterator=False, chunksize=None,
+             skip_footer=0, converters=None):
+    if hasattr(filepath_or_buffer, 'read'):
+        f = filepath_or_buffer
+    else:
+        try:
+            # universal newline mode
+            f = open(filepath_or_buffer, 'U')
+        except Exception: # pragma: no cover
+            f = open(filepath_or_buffer, 'r')
+
+    if date_parser is not None:
+        parse_dates = True
+
+    parser = TextParser(f, header=header, index_col=index_col,
+                        names=names, na_values=na_values,
+                        parse_dates=parse_dates,
+                        date_parser=date_parser,
+                        skiprows=skiprows,
+                        delimiter=sep,
+                        chunksize=chunksize,
+                        skip_footer=skip_footer,
+                        converters=converters)
+
+    if nrows is not None:
+        return parser.get_chunk(nrows)
+    elif chunksize or iterator:
+        return parser
+
+    return parser.get_chunk()
+
+@Appender(_read_table_doc)
+def read_table(filepath_or_buffer, sep='\t', header=0, index_col=None,
+               names=None, skiprows=None, na_values=None, parse_dates=False,
+               date_parser=None, nrows=None, iterator=False, chunksize=None,
+               skip_footer=0, converters=None):
+    return read_csv(filepath_or_buffer, sep=sep, header=header,
+                    skiprows=skiprows, index_col=index_col,
+                    na_values=na_values, date_parser=date_parser,
+                    names=names, parse_dates=parse_dates,
+                    nrows=nrows, iterator=iterator, chunksize=chunksize,
+                    skip_footer=skip_footer, converters=converters)
+
+def read_clipboard(**kwargs):  # pragma: no cover
+    """
+    Read text from clipboard and pass to read_table. See read_table for the full
+    argument list
+
+    Returns
+    -------
+    parsed : DataFrame
+    """
+    from pandas.util.clipboard import clipboard_get
+    text = clipboard_get()
+    return read_table(StringIO(text), **kwargs)
+
 
 class BufferedReader(object):
     """
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 1d724e005..8b9959482 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -17,6 +17,7 @@ from pandas.util.decorators import cache_readonly
 import pandas.core.datetools as datetools
 
 from pandas.sparse.series import SparseSeries
+from pandas.util.decorators import Appender
 
 
 class _SparseMockBlockManager(object):
@@ -316,11 +317,10 @@ class SparseDataFrame(DataFrame):
             else: # pragma: no cover
                 raise
 
+    @Appender(DataFrame.get_value.__doc__, indents=0)
     def get_value(self, index, col):
         s = self._series[col]
         return s.get_value(index)
-    if __debug__:
-        get_value.__doc__ = DataFrame.get_value.__doc__
 
     def set_value(self, index, col, value):
         """
@@ -601,9 +601,9 @@ class SparseDataFrame(DataFrame):
                                default_kind=self.default_kind)
     T = property(transpose)
 
+    @Appender(DataFrame.count.__doc__)
     def count(self, axis=0, **kwds):
         return self.apply(lambda x: x.count(), axis=axis)
-    count.__doc__ = DataFrame.count.__doc__
 
     def cumsum(self, axis=0):
         """
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 93b99474e..c683fc3db 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -12,6 +12,8 @@ import numpy as np
 from pandas.core.api import DataFrame, Series, notnull
 import pandas._tseries as _tseries
 
+from pandas.util.decorators import Substitution, Appender
+
 __all__ = ['rolling_count', 'rolling_max', 'rolling_min',
            'rolling_sum', 'rolling_mean', 'rolling_std', 'rolling_cov',
            'rolling_corr', 'rolling_var', 'rolling_skew', 'rolling_kurt',
@@ -19,6 +21,78 @@ __all__ = ['rolling_count', 'rolling_max', 'rolling_min',
            'rolling_corr_pairwise',
            'ewma', 'ewmvar', 'ewmstd', 'ewmvol', 'ewmcorr', 'ewmcov']
 
+#-------------------------------------------------------------------------------
+# Docs
+
+_doc_template = """
+%s
+
+Parameters
+----------
+%s
+window : Number of observations used for calculating statistic
+min_periods : int
+    Minimum number of observations in window required to have a value
+time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    Name of time rule to conform to before computing statistic
+
+Returns
+-------
+%s
+"""
+
+
+_ewm_doc = r"""%s
+
+Parameters
+----------
+%s
+com : float. optional
+    Center of mass: \alpha = com / (1 + com),
+span : float, optional
+    Specify decay in terms of span, \alpha = 2 / (span + 1)
+min_periods : int, default 0
+    Number of observations in sample to require (only affects
+    beginning)
+time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default None
+    Name of time rule to conform to before computing statistic
+%s
+Notes
+-----
+Either center of mass or span must be specified
+
+EWMA is sometimes specified using a "span" parameter s, we have have that the
+decay parameter \alpha is related to the span as :math:`\alpha = 1 - 2 / (s + 1)
+= c / (1 + c)`
+
+where c is the center of mass. Given a span, the associated center of mass is
+:math:`c = (s - 1) / 2`
+
+So a "20-day EWMA" would have center 9.5.
+
+Returns
+-------
+y : type of input argument
+"""
+
+_type_of_input = "y : type of input argument"
+
+_flex_retval = """y : type depends on inputs
+    DataFrame / DataFrame -> DataFrame (matches on columns)
+    DataFrame / Series -> Computes result for each column
+    Series / Series -> Series"""
+
+_unary_arg = "arg : Series, DataFrame"
+
+_binary_arg_flex = """arg1 : Series, DataFrame, or ndarray
+arg2 : Series, DataFrame, or ndarray"""
+
+_binary_arg = """arg1 : Series, DataFrame, or ndarray
+arg2 : Series, DataFrame, or ndarray"""
+
+_bias_doc = r"""bias : boolean, default False
+    Use a standard estimation bias correction
+"""
 def rolling_count(arg, window, time_rule=None):
     """
     Rolling count of number of non-NaN observations inside provided window.
@@ -46,6 +120,8 @@ def rolling_count(arg, window, time_rule=None):
 
     return return_hook(result)
 
+@Substitution("Unbiased moving covariance", _binary_arg_flex, _flex_retval)
+@Appender(_doc_template)
 def rolling_cov(arg1, arg2, window, min_periods=None, time_rule=None):
     def _get_cov(X, Y):
         mean = lambda x: rolling_mean(x, window, min_periods, time_rule)
@@ -54,6 +130,8 @@ def rolling_cov(arg1, arg2, window, min_periods=None, time_rule=None):
         return (mean(X * Y) - mean(X) * mean(Y)) * bias_adj
     return _flex_binary_moment(arg1, arg2, _get_cov)
 
+@Substitution("Moving sample correlation", _binary_arg_flex, _flex_retval)
+@Appender(_doc_template)
 def rolling_corr(arg1, arg2, window, min_periods=None, time_rule=None):
     def _get_corr(a, b):
         num = rolling_cov(a, b, window, min_periods, time_rule)
@@ -182,7 +260,8 @@ def _get_center_of_mass(com, span):
 
     return float(com)
 
-
+@Substitution("Exponentially-weighted moving average", _unary_arg, "")
+@Appender(_ewm_doc)
 def ewma(arg, com=None, span=None, min_periods=0, time_rule=None):
     com = _get_center_of_mass(com, span)
     arg = _conv_timerule(arg, time_rule)
@@ -201,6 +280,8 @@ def _first_valid_index(arr):
     # argmax scans from left
     return notnull(arr).argmax()
 
+@Substitution("Exponentially-weighted moving variance", _unary_arg, _bias_doc)
+@Appender(_ewm_doc)
 def ewmvar(arg, com=None, span=None, min_periods=0, bias=False,
            time_rule=None):
     com = _get_center_of_mass(com, span)
@@ -214,6 +295,8 @@ def ewmvar(arg, com=None, span=None, min_periods=0, bias=False,
 
     return result
 
+@Substitution("Exponentially-weighted moving std", _unary_arg, _bias_doc)
+@Appender(_ewm_doc)
 def ewmstd(arg, com=None, span=None, min_periods=0, bias=False,
            time_rule=None):
     result = ewmvar(arg, com=com, span=span, time_rule=time_rule,
@@ -222,6 +305,8 @@ def ewmstd(arg, com=None, span=None, min_periods=0, bias=False,
 
 ewmvol = ewmstd
 
+@Substitution("Exponentially-weighted moving covariance", _binary_arg, "")
+@Appender(_ewm_doc)
 def ewmcov(arg1, arg2, com=None, span=None, min_periods=0, bias=False,
            time_rule=None):
     X, Y = _prep_binary(arg1, arg2)
@@ -238,6 +323,8 @@ def ewmcov(arg1, arg2, com=None, span=None, min_periods=0, bias=False,
 
     return result
 
+@Substitution("Exponentially-weighted moving " "correlation", _binary_arg, "")
+@Appender(_ewm_doc)
 def ewmcorr(arg1, arg2, com=None, span=None, min_periods=0,
             time_rule=None):
     X, Y = _prep_binary(arg1, arg2)
@@ -260,95 +347,6 @@ def _prep_binary(arg1, arg2):
 
     return X, Y
 
-#-------------------------------------------------------------------------------
-# Docs
-
-_doc_template = """
-%s
-
-Parameters
-----------
-%s
-window : Number of observations used for calculating statistic
-min_periods : int
-    Minimum number of observations in window required to have a value
-time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
-    Name of time rule to conform to before computing statistic
-
-Returns
--------
-%s
-"""
-
-
-_ewm_doc = r"""%s
-
-Parameters
-----------
-%s
-com : float. optional
-    Center of mass: \alpha = com / (1 + com),
-span : float, optional
-    Specify decay in terms of span, \alpha = 2 / (span + 1)
-min_periods : int, default 0
-    Number of observations in sample to require (only affects
-    beginning)
-time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default None
-    Name of time rule to conform to before computing statistic
-%s
-Notes
------
-Either center of mass or span must be specified
-
-EWMA is sometimes specified using a "span" parameter s, we have have that the
-decay parameter \alpha is related to the span as :math:`\alpha = 1 - 2 / (s + 1)
-= c / (1 + c)`
-
-where c is the center of mass. Given a span, the associated center of mass is
-:math:`c = (s - 1) / 2`
-
-So a "20-day EWMA" would have center 9.5.
-
-Returns
--------
-y : type of input argument
-"""
-
-_type_of_input = "y : type of input argument"
-
-_flex_retval = """y : type depends on inputs
-    DataFrame / DataFrame -> DataFrame (matches on columns)
-    DataFrame / Series -> Computes result for each column
-    Series / Series -> Series"""
-
-_unary_arg = "arg : Series, DataFrame"
-
-_binary_arg_flex = """arg1 : Series, DataFrame, or ndarray
-arg2 : Series, DataFrame, or ndarray"""
-
-_binary_arg = """arg1 : Series, DataFrame, or ndarray
-arg2 : Series, DataFrame, or ndarray"""
-
-_bias_doc = r"""bias : boolean, default False
-    Use a standard estimation bias correction
-"""
-
-rolling_cov.__doc__ = _doc_template % ("Unbiased moving covariance",
-                                       _binary_arg_flex, _flex_retval)
-rolling_corr.__doc__ = _doc_template % ("Moving sample correlation",
-                                        _binary_arg_flex, _flex_retval)
-
-ewma.__doc__ = _ewm_doc % ("Exponentially-weighted moving average",
-                           _unary_arg, "")
-ewmstd.__doc__ = _ewm_doc % ("Exponentially-weighted moving std",
-                             _unary_arg, _bias_doc)
-ewmvar.__doc__ = _ewm_doc % ("Exponentially-weighted moving variance",
-                             _unary_arg, _bias_doc)
-ewmcorr.__doc__ = _ewm_doc % ("Exponentially-weighted moving "
-                              "correlation", _binary_arg, "")
-ewmcov.__doc__ = _ewm_doc % ("Exponentially-weighted moving covariance",
-                             _binary_arg, "")
-
 #-------------------------------------------------------------------------------
 # Python interface to Cython functions
 
@@ -375,6 +373,8 @@ def _use_window(minp, window):
         return minp
 
 def _rolling_func(func, desc, check_minp=_use_window):
+    @Substitution(desc, _unary_arg, _type_of_input)
+    @Appender(_doc_template)
     @wraps(func)
     def f(arg, window, min_periods=None, time_rule=None):
         def call_cython(arg, window, minp):
@@ -383,8 +383,6 @@ def _rolling_func(func, desc, check_minp=_use_window):
         return _rolling_moment(arg, window, call_cython, min_periods,
                                time_rule=time_rule)
 
-    f.__doc__ = _doc_template % (desc, _unary_arg, _type_of_input)
-
     return f
 
 rolling_max = _rolling_func(_tseries.roll_max, 'Moving maximum')
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 224e6473d..4828ce681 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -9,12 +9,16 @@ from pandas.core.groupby import get_group_index
 from pandas.core.index import Index, MultiIndex, _get_combined_index
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
                                    make_block, _consolidate)
+from pandas.util.decorators import cache_readonly, Appender, Substitution
+
 from pandas.sparse.frame import SparseDataFrame
 from pandas.util.decorators import cache_readonly
 import pandas.core.common as com
 
 import pandas._tseries as lib
 
+@Substitution('\nleft : DataFrame')
+@Appender(_merge_doc, indents=0)
 def merge(left, right, how='inner', on=None, left_on=None, right_on=None,
           left_index=False, right_index=False, sort=True,
           suffixes=('.x', '.y'), copy=True):
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index 8512d38d9..4c00427f0 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -91,8 +91,8 @@ class Appender(object):
         self.join = join
 
     def __call__(self, func):
-        docitems = [func.__doc__, self.addendum]
-        func.__doc__ = func.__doc__ and ''.join(docitems)
+        docitems = [func.__doc__ if func.__doc__ else '', self.addendum]
+        func.__doc__ = ''.join(docitems)
         return func
 
 def indent(text, indents=1):
