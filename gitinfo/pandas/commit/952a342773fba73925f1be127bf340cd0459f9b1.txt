commit 952a342773fba73925f1be127bf340cd0459f9b1
Author: jreback <jeff@reback.net>
Date:   Thu Aug 22 18:01:02 2013 -0400

    API: the ``fmt`` keyword now replaces the table keyword; allowed values are ``s|t``
         the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies 's' (Storer) format
         and ``append`` imples 't' (Table) format

diff --git a/doc/source/io.rst b/doc/source/io.rst
index f09ae1563..73a7c2d1e 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1803,6 +1803,7 @@ The examples above show storing using ``put``, which write the HDF5 to ``PyTable
 the ``storer`` format. These types of stores are are **not** appendable once written (though you can simply
 remove them and rewrite). Nor are they **queryable**; they must be
 retrieved in their entirety. These offer very fast writing and slightly faster reading than ``table`` stores.
+This format is specified by default when using ``put`` or by ``fmt='s'``
 
 .. warning::
 
@@ -1826,7 +1827,7 @@ Table Format
 format. Conceptually a ``table`` is shaped very much like a DataFrame,
 with rows and columns. A ``table`` may be appended to in the same or
 other sessions.  In addition, delete & query type operations are
-supported.
+supported. This format is specified by ``fmt='t'`` to ``append`` or ``put``.
 
 .. ipython:: python
    :suppress:
@@ -1853,7 +1854,7 @@ supported.
 
 .. note::
 
-   You can also create a ``table`` by passing ``table=True`` to a ``put`` operation.
+   You can also create a ``table`` by passing ``fmt='t'`` to a ``put`` operation.
 
 .. _io.hdf5-keys:
 
diff --git a/doc/source/release.rst b/doc/source/release.rst
index 8400dab2a..21fea6b64 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -98,6 +98,7 @@ pandas 0.13
     - removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will
       be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)
     - allow a passed locations array or mask as a ``where`` condition (:issue:`4467`)
+    - the ``fmt`` keyword now replaces the ``table`` keyword; allowed values are ``s|t``
   - ``JSON``
 
     - added ``date_unit`` parameter to specify resolution of timestamps. Options
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index 5003aa654..c0e3f5e6b 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -66,6 +66,12 @@ API changes
          store2.close()
          store2
 
+      .. ipython:: python
+         :suppress:
+
+         import os
+         os.remove(path)
+
     - removed the ``_quiet`` attribute, replace by a ``DuplicateWarning`` if retrieving
       duplicate rows from a table (:issue:`4367`)
     - removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will
@@ -73,6 +79,20 @@ API changes
     - allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).
       See :ref:`here<io.hdf5-where_mask>` for an example.
 
+    - the ``fmt`` keyword now replaces the ``table`` keyword; allowed values are ``s|t``
+      the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies 's' (Storer) format
+      and ``append`` imples 't' (Table) format
+
+      .. ipython:: python
+
+         path = 'test.h5'
+         df = DataFrame(randn(10,2))
+         df.to_hdf(path,'df_table',fmt='t')
+         df.to_hdf(path,'df_table2',append=True)
+         df.to_hdf(path,'df_storer')
+         with get_store(path) as store:
+            print store
+
       .. ipython:: python
          :suppress:
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 0d944afad..1eb8b0f26 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -100,6 +100,23 @@ your performance may suffer as PyTables will pickle object types that it cannot
 map directly to c-types [inferred_type->%s,key->%s] [items->%s]
 """
 
+# formats
+_FORMAT_MAP = {
+    u('s') : 's',
+    u('storer') : 's',
+    u('t') : 't',
+    u('table') : 't',
+    }
+
+fmt_deprecate_doc = """
+the table keyword has been deprecated
+use the fmt='s|t' keyword instead
+  s : specifies the Storer format
+      and is the default for put operations
+  t : specifies the Table format
+      and is the default for append operations
+"""
+
 # map object types
 _TYPE_MAP = {
 
@@ -545,7 +562,7 @@ class HDFStore(StringMixin):
 
     def unique(self, key, column, **kwargs):
         warnings.warn("unique(key,column) is deprecated\n"
-                      "use select_column(key,column).unique() instead")
+                      "use select_column(key,column).unique() instead",FutureWarning)
         return self.get_storer(key).read_column(column=column, **kwargs).unique()
 
     def select_column(self, key, column, **kwargs):
@@ -641,7 +658,7 @@ class HDFStore(StringMixin):
 
         return TableIterator(self, func, nrows=nrows, start=start, stop=stop, auto_close=auto_close).get_values()
 
-    def put(self, key, value, table=None, append=False, **kwargs):
+    def put(self, key, value, fmt=None, append=False, **kwargs):
         """
         Store object in HDFStore
 
@@ -649,16 +666,20 @@ class HDFStore(StringMixin):
         ----------
         key      : object
         value    : {Series, DataFrame, Panel}
-        table    : boolean, default False
-            Write as a PyTables Table structure which may perform worse but
-            allow more flexible operations like searching / selecting subsets
-            of the data
+        fmt      : 's|t', default is 's' for storer format
+            s : storer format
+                Fast writing/reading. Not-appendable, nor searchable
+            t : table format
+                Write as a PyTables Table structure which may perform worse but
+                allow more flexible operations like searching / selecting subsets
+                of the data
         append   : boolean, default False
             For table data structures, append the input data to the existing
             table
         encoding : default None, provide an encoding for strings
         """
-        self._write_to_group(key, value, table=table, append=append, **kwargs)
+        kwargs = self._validate_format(fmt or 's', kwargs)
+        self._write_to_group(key, value, append=append, **kwargs)
 
     def remove(self, key, where=None, start=None, stop=None):
         """
@@ -709,7 +730,7 @@ class HDFStore(StringMixin):
                     'can only remove with where on objects written as tables')
             return s.delete(where=where, start=start, stop=stop)
 
-    def append(self, key, value, columns=None, append=True, **kwargs):
+    def append(self, key, value, fmt=None, append=True, columns=None, **kwargs):
         """
         Append to Table in file. Node must already exist and be Table
         format.
@@ -718,6 +739,11 @@ class HDFStore(StringMixin):
         ----------
         key : object
         value : {Series, DataFrame, Panel, Panel4D}
+        fmt   : 't', default is 't' for table format
+            t : table format
+                Write as a PyTables Table structure which may perform worse but
+                allow more flexible operations like searching / selecting subsets
+                of the data
         append   : boolean, default True, append the input data to the existing
         data_columns : list of columns to create as data columns, or True to use all columns
         min_itemsize : dict of columns that specify minimum string sizes
@@ -735,7 +761,7 @@ class HDFStore(StringMixin):
             raise Exception(
                 "columns is not a supported keyword in append, try data_columns")
 
-        kwargs['table'] = True
+        kwargs = self._validate_format(fmt or 't', kwargs)
         self._write_to_group(key, value, append=append, **kwargs)
 
     def append_to_multiple(self, d, value, selector, data_columns=None, axes=None, **kwargs):
@@ -901,13 +927,39 @@ class HDFStore(StringMixin):
         if not self.is_open:
             raise ClosedFileError("{0} file is not open!".format(self._path))
 
-    def _create_storer(self, group, value=None, table=False, append=False, **kwargs):
+    def _validate_format(self, fmt, kwargs):
+        """ validate / deprecate formats; return the new kwargs """
+        kwargs = kwargs.copy()
+
+        if 'format' in kwargs:
+            raise TypeError("pls specify an object format with the 'fmt' keyword")
+
+        # table arg
+        table = kwargs.pop('table',None)
+
+        if table is not None:
+            warnings.warn(fmt_deprecate_doc,FutureWarning)
+
+            if table:
+                fmt = 't'
+            else:
+                fmt = 's'
+
+        # validate
+        try:
+            kwargs['fmt'] = _FORMAT_MAP[fmt.lower()]
+        except:
+            raise TypeError("invalid HDFStore format specified [{0}]".format(fmt))
+
+        return kwargs
+
+    def _create_storer(self, group, fmt=None, value=None, append=False, **kwargs):
         """ return a suitable Storer class to operate """
 
         def error(t):
             raise TypeError(
-                "cannot properly create the storer for: [%s] [group->%s,value->%s,table->%s,append->%s,kwargs->%s]" %
-                            (t, group, type(value), table, append, kwargs))
+                "cannot properly create the storer for: [%s] [group->%s,value->%s,fmt->%s,append->%s,kwargs->%s]" %
+                            (t, group, type(value), fmt, append, kwargs))
 
         pt = _ensure_decoded(getattr(group._v_attrs, 'pandas_type', None))
         tt = _ensure_decoded(getattr(group._v_attrs, 'table_type', None))
@@ -931,7 +983,7 @@ class HDFStore(StringMixin):
                     error('_TYPE_MAP')
 
                 # we are actually a table
-                if table or append:
+                if fmt == 't':
                     pt += u('_table')
 
         # a storer node
@@ -983,7 +1035,7 @@ class HDFStore(StringMixin):
             error('_TABLE_MAP')
 
     def _write_to_group(
-        self, key, value, index=True, table=False, append=False,
+        self, key, value, fmt, index=True, append=False,
                         complib=None, encoding=None, **kwargs):
         group = self.get_node(key)
 
@@ -994,7 +1046,7 @@ class HDFStore(StringMixin):
 
         # we don't want to store a table node at all if are object is 0-len
         # as there are not dtypes
-        if getattr(value,'empty',None) and (table or append):
+        if getattr(value,'empty',None) and (fmt == 't' or append):
             return
 
         if group is None:
@@ -1014,12 +1066,12 @@ class HDFStore(StringMixin):
                     group = self._handle.createGroup(path, p)
                 path = new_path
 
-        s = self._create_storer(group, value, table=table, append=append,
+        s = self._create_storer(group, fmt, value, append=append,
                                 encoding=encoding, **kwargs)
         if append:
             # raise if we are trying to append to a non-table,
             #       or a table that exists (and we are putting)
-            if not s.is_table or (s.is_table and table is None and s.is_exists):
+            if not s.is_table or (s.is_table and fmt == 's' and s.is_exists):
                 raise ValueError('Can only append to Tables')
             if not s.is_exists:
                 s.set_object_info()
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index 0de509601..e2d923551 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -163,12 +163,33 @@ class TestHDFStore(unittest.TestCase):
             df.iloc[10:].to_hdf(path,'df',append=True,table=True)
             assert_frame_equal(read_hdf(path,'df'),df)
 
+        with tm.ensure_clean(self.path) as path:
+
+            df = tm.makeDataFrame()
+            df.iloc[:10].to_hdf(path,'df',append=True)
+            df.iloc[10:].to_hdf(path,'df',append=True,table='t')
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            # append to False
+            df.iloc[:10].to_hdf(path,'df',append=False,table='t')
+            df.iloc[10:].to_hdf(path,'df',append=True)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
         with tm.ensure_clean(self.path) as path:
 
             df = tm.makeDataFrame()
             df.to_hdf(path,'df',append=False,table=False)
             assert_frame_equal(read_hdf(path,'df'),df)
 
+            df.to_hdf(path,'df',append=False,fmt='s')
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            df.to_hdf(path,'df',append=False)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            df.to_hdf(path,'df')
+            assert_frame_equal(read_hdf(path,'df'),df)
+
         with ensure_clean(self.path) as store:
 
             df = tm.makeDataFrame()
@@ -181,6 +202,26 @@ class TestHDFStore(unittest.TestCase):
             store.append('df',df.iloc[10:],append=True,table=True)
             assert_frame_equal(read_hdf(path,'df'),df)
 
+            # formats
+            store.append('df',df.iloc[:10],append=False,fmt='t')
+            store.append('df',df.iloc[10:],append=True,fmt='t')
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            _maybe_remove(store,'df')
+            store.append('df',df.iloc[:10],append=False,fmt='t')
+            store.append('df',df.iloc[10:],append=True,fmt=None)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+        with tm.ensure_clean(self.path) as path:
+
+            # invalid
+            df = tm.makeDataFrame()
+            self.assertRaises(ValueError, df.to_hdf, path,'df',append=True,fmt='s')
+
+            self.assertRaises(TypeError, df.to_hdf, path,'df',append=True,fmt='foo')
+            self.assertRaises(TypeError, df.to_hdf, path,'df',append=False,fmt='bar')
+            self.assertRaises(TypeError, df.to_hdf, path,'df',format='s')
+
     def test_keys(self):
 
         with ensure_clean(self.path) as store:
@@ -1705,7 +1746,7 @@ class TestHDFStore(unittest.TestCase):
             # try to remove non-table (with crit)
             # non-table ok (where = None)
             wp = tm.makePanel()
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
             store.remove('wp', [('minor_axis', ['A', 'D'])])
             rs = store.select('wp')
             expected = wp.reindex(minor_axis=['B', 'C'])
@@ -1713,7 +1754,7 @@ class TestHDFStore(unittest.TestCase):
 
             # empty where
             _maybe_remove(store, 'wp')
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
 
             # deleted number (entire table)
             n = store.remove('wp', [])
@@ -1721,12 +1762,12 @@ class TestHDFStore(unittest.TestCase):
 
             # non - empty where
             _maybe_remove(store, 'wp')
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
             self.assertRaises(ValueError, store.remove,
                               'wp', ['foo'])
 
             # selectin non-table with a where
-            # store.put('wp2', wp, table=False)
+            # store.put('wp2', wp, fmt='s')
             # self.assertRaises(ValueError, store.remove,
             #                  'wp2', [('column', ['A', 'D'])])
 
@@ -1739,7 +1780,7 @@ class TestHDFStore(unittest.TestCase):
             # group row removal
             date4 = wp.major_axis.take([0, 1, 2, 4, 5, 6, 8, 9, 10])
             crit4 = Term('major_axis', date4)
-            store.put('wp3', wp, table=True)
+            store.put('wp3', wp, fmt='t')
             n = store.remove('wp3', where=[crit4])
             assert(n == 36)
             result = store.select('wp3')
@@ -1747,7 +1788,7 @@ class TestHDFStore(unittest.TestCase):
             assert_panel_equal(result, expected)
 
             # upper half
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
             date = wp.major_axis[len(wp.major_axis) // 2]
 
             crit1 = Term('major_axis', '>', date)
@@ -1764,7 +1805,7 @@ class TestHDFStore(unittest.TestCase):
             assert_panel_equal(result, expected)
 
             # individual row elements
-            store.put('wp2', wp, table=True)
+            store.put('wp2', wp, fmt='t')
 
             date1 = wp.major_axis[1:3]
             crit1 = Term('major_axis', date1)
@@ -1790,7 +1831,7 @@ class TestHDFStore(unittest.TestCase):
             assert_panel_equal(result, expected)
 
             # corners
-            store.put('wp4', wp, table=True)
+            store.put('wp4', wp, fmt='t')
             n = store.remove(
                 'wp4', where=[Term('major_axis', '>', wp.major_axis[-1])])
             result = store.select('wp4')
@@ -1802,8 +1843,8 @@ class TestHDFStore(unittest.TestCase):
 
             wp = tm.makePanel()
             p4d = tm.makePanel4D()
-            store.put('wp', wp, table=True)
-            store.put('p4d', p4d, table=True)
+            store.put('wp', wp, fmt='t')
+            store.put('p4d', p4d, fmt='t')
 
             # some invalid terms
             terms = [
@@ -2158,8 +2199,8 @@ class TestHDFStore(unittest.TestCase):
     def test_wide_table_dups(self):
         wp = tm.makePanel()
         with ensure_clean(self.path) as store:
-            store.put('panel', wp, table=True)
-            store.put('panel', wp, table=True, append=True)
+            store.put('panel', wp, fmt='t')
+            store.put('panel', wp, fmt='t', append=True)
 
             with tm.assert_produces_warning(expected_warning=DuplicateWarning):
                 recons = store['panel']
@@ -2225,12 +2266,12 @@ class TestHDFStore(unittest.TestCase):
 
             # put/select ok
             _maybe_remove(store, 'wp')
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
             store.select('wp')
 
             # non-table ok (where = None)
             _maybe_remove(store, 'wp')
-            store.put('wp2', wp, table=False)
+            store.put('wp2', wp)
             store.select('wp2')
 
             # selection on the non-indexable with a large number of columns
@@ -2411,7 +2452,7 @@ class TestHDFStore(unittest.TestCase):
         with tm.ensure_clean(self.path) as path:
 
             df = tm.makeTimeDataFrame(500)
-            df.to_hdf(path,'df',table=True)
+            df.to_hdf(path,'df',fmt='t')
 
             results = []
             for x in read_hdf(path,'df',chunksize=100):
@@ -2462,7 +2503,7 @@ class TestHDFStore(unittest.TestCase):
 
         with ensure_clean(self.path) as store:
             _maybe_remove(store,'data')
-            store.put('data', df, table=True)
+            store.put('data', df, fmt='t')
 
             result = store.get('data')
             tm.assert_frame_equal(df,result)
@@ -2520,7 +2561,7 @@ class TestHDFStore(unittest.TestCase):
         wp = tm.makePanel()
 
         with ensure_clean(self.path) as store:
-            store.put('wp', wp, table=True)
+            store.put('wp', wp, fmt='t')
             date = wp.major_axis[len(wp.major_axis) // 2]
 
             crit1 = ('major_axis', '>=', date)
@@ -2540,7 +2581,7 @@ class TestHDFStore(unittest.TestCase):
         df = tm.makeTimeDataFrame()
 
         with ensure_clean(self.path) as store:
-            store.put('frame', df, table=True)
+            store.put('frame', df,fmt='t')
             date = df.index[len(df) // 2]
 
             crit1 = ('index', '>=', date)
@@ -2848,7 +2889,7 @@ class TestHDFStore(unittest.TestCase):
         df.columns = ['%.3d' % c for c in df.columns]
 
         with ensure_clean(self.path) as store:
-            store.put('frame', df, table=True)
+            store.put('frame', df, fmt='t')
 
             crit = Term('columns', df.columns[:75])
             result = store.select('frame', [crit])
@@ -2886,7 +2927,7 @@ class TestHDFStore(unittest.TestCase):
             options['complib'] = _default_compressor
 
         with ensure_clean(self.path, 'w', **options) as store:
-            store.put('obj', obj, table=True)
+            store.put('obj', obj, fmt='t')
             retrieved = store['obj']
             # sorted_obj = _test_sort(obj)
             comparator(retrieved, obj)
@@ -2897,7 +2938,7 @@ class TestHDFStore(unittest.TestCase):
         with tm.ensure_clean(self.path) as path:
 
             df = tm.makeDataFrame()
-            df.to_hdf(path,'df',mode='w',table=True)
+            df.to_hdf(path,'df',mode='w',fmt='t')
 
             # single
             store = HDFStore(path)
@@ -2959,7 +3000,7 @@ class TestHDFStore(unittest.TestCase):
         with tm.ensure_clean(self.path) as path:
 
             df = tm.makeDataFrame()
-            df.to_hdf(path,'df',mode='w',table=True)
+            df.to_hdf(path,'df',mode='w',fmt='t')
 
             store = HDFStore(path)
             store.close()
@@ -3202,7 +3243,7 @@ class TestHDFStore(unittest.TestCase):
     #                   index=[np.arange(5).repeat(2),
     #                          np.tile(np.arange(2), 5)])
 
-    #    self.assertRaises(Exception, store.put, 'foo', df, table=True)
+    #    self.assertRaises(Exception, store.put, 'foo', df, fmt='t')
 
 
 def _test_sort(obj):
