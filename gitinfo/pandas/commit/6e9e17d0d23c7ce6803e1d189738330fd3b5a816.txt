commit 6e9e17d0d23c7ce6803e1d189738330fd3b5a816
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jan 10 17:10:26 2012 -0500

    DOC: add reasonably complete concat docs

diff --git a/.gitignore b/.gitignore
index fafb416be..e8d1b434d 100644
--- a/.gitignore
+++ b/.gitignore
@@ -11,6 +11,8 @@ MANIFEST
 pandas/version.py
 doc/source/generated
 doc/source/_static
+doc/source/vbench
+doc/source/vbench.rst
 *flymake*
 scikits
 .coverage
diff --git a/doc/source/api.rst b/doc/source/api.rst
index 73366f49a..4fe11315b 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -12,12 +12,14 @@ General functions
 
 Data manipulations
 ~~~~~~~~~~~~~~~~~~
-.. currentmodule:: pandas.tools.pivot
+.. currentmodule:: pandas
 
 .. autosummary::
    :toctree: generated/
 
    pivot_table
+   merge
+   concat
 
 Pickling
 ~~~~~~~~
diff --git a/doc/source/dsintro.rst b/doc/source/dsintro.rst
index 3edea78de..fb9f4fdc6 100644
--- a/doc/source/dsintro.rst
+++ b/doc/source/dsintro.rst
@@ -562,8 +562,7 @@ R package):
    :suppress:
 
    # force a summary to be printed
-   print_config = core.common.GlobalPrintConfig
-   core.common.GlobalPrintConfig.max_rows = 5
+   set_printoptions(max_rows=5)
 
 .. ipython:: python
 
@@ -574,7 +573,7 @@ R package):
    :suppress:
 
    # restore GlobalPrintConfig
-   core.common.GlobalPrintConfig = print_config
+   reset_printoptions()
 
 However, using ``to_string`` will return a string representation of the
 DataFrame in tabular form, though it won't always fit the console width:
diff --git a/doc/source/merging.rst b/doc/source/merging.rst
index ad177aaae..312da83ec 100644
--- a/doc/source/merging.rst
+++ b/doc/source/merging.rst
@@ -10,9 +10,244 @@
    randn = np.random.randn
    np.set_printoptions(precision=4, suppress=True)
 
-***************************
-Merging / Joining data sets
-***************************
+****************************
+Merge, join, and concatenate
+****************************
+
+pandas provides various facilities for easily combining together Series,
+DataFrame, and Panel objects with various kinds of set logic for the indexes
+and relational algebra functionality in the case of join / merge-type
+operations.
+
+.. _merging.concat:
+
+Concatenating objects
+---------------------
+
+The ``concat`` function (in the main pandas namespace) does all of the heavy
+lifting of performing concatenation operations along an axis while performing
+optional set logic (union or intersection) of the indexes (if any) on the other
+axes. Note that I say "if any" because there is only a single possible axis of
+concatenation for Series.
+
+Before diving into all of the details of ``concat`` and what it can do, here is
+a simple example:
+
+.. ipython:: python
+
+   df = DataFrame(np.random.randn(10, 4))
+   df
+
+   # break it into pieces
+   pieces = [df[:3], df[3:7], df[7:]]
+
+   concatenated = concat(pieces)
+   concatenated
+
+Like its sibling function on ndarrays, ``numpy.concatenate``, ``pandas.concat``
+takes a list or dict of homogeneously-typed objects and concatenates them with
+some configurable handling of "what to do with the other axes":
+
+::
+
+    concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False,
+           keys=None, levels=None, names=None, verify_integrity=False)
+
+- ``objs``: list or dict of Series, DataFrame, or Panel objects. If a dict is
+  passed, the sorted keys will be used as the `keys` argument, unless it is
+  passed, in which case the values will be selected (see below)
+- ``axis``: {0, 1, ...}, default 0. The axis to concatenate along
+- ``join``: {'inner', 'outer'}, default 'outer'. How to handle indexes on
+  other axis(es). Outer for union and inner for intersection
+- ``join_axes``: list of Index objects. Specific indexes to use for the other
+  n - 1 axes instead of performing inner/outer set logic
+- ``keys``: sequence, default None. Construct hierarchical index using the
+  passed keys as the outermost level If multiple levels passed, should
+  contain tuples.
+- ``levels`` : list of sequences, default None. If keys passed, specific
+  levels to use for the resulting MultiIndex. Otherwise they will be inferred
+  from the keys
+- ``names``: list, default None. Names for the levels in the resulting
+  hierarchical index
+- ``verify_integrity``: boolean, default False. Check whether the new
+  concatenated axis contains duplicates. This can be very expensive relative
+  to the actual data concatenation
+
+Without a little bit of context and example many of these arguments don't make
+much sense. Let's take the above example. Suppose we wanted to associate
+specific keys with each of the pieces of the chopped up DataFrame. We can do
+this using the ``keys`` argument:
+
+.. ipython:: python
+
+   concatenated = concat(pieces, keys=['first', 'second', 'third'])
+   concatenated
+
+As you can see (if you've read the rest of the documentation), the resulting
+object's index has a :ref:`hierarchical index <indexing.hierarchical>`. This
+means that we can now do stuff like select out each chunk by key:
+
+.. ipython:: python
+
+   concatenated.ix['second']
+
+It's not a stretch to see how this can be very useful. More detail on this
+functionality below.
+
+Set logic on the other axes
+~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+When gluing together multiple DataFrames (or Panels or...), for example, you
+have a choice of how to handle the other axes (other than the one being
+concatenated). This can be done in three ways:
+
+- Take the (sorted) union of them all, ``join='outer'``. This is the default
+  option as it results in zero information loss.
+- Take the intersection, ``join='inner'``.
+- Use a specific index (in the case of DataFrame) or indexes (in the case of
+  Panel or future higher dimensional objects), i.e. the ``join_axes`` argument
+
+Here is a example of each of these methods. First, the default ``join='outer'``
+behavior:
+
+.. ipython:: python
+
+   from pandas.util.testing import rands
+   df = DataFrame(np.random.randn(10, 4), columns=['a', 'b', 'c', 'd'],
+                  index=[rands(5) for _ in xrange(10)])
+   df
+
+   concat([df.ix[:7, ['a', 'b']], df.ix[2:-2, ['c']],
+           df.ix[-7:, ['d']]], axis=1)
+
+Note that the row indexes have been unioned and sorted. Here is the same thing
+with ``join='inner'``:
+
+.. ipython:: python
+
+   concat([df.ix[:7, ['a', 'b']], df.ix[2:-2, ['c']],
+           df.ix[-7:, ['d']]], axis=1, join='inner')
+
+Lastly, suppose we just wanted to reuse the *exact index* from the original
+DataFrame:
+
+.. ipython:: python
+
+   concat([df.ix[:7, ['a', 'b']], df.ix[2:-2, ['c']],
+           df.ix[-7:, ['d']]], axis=1, join_axes=[df.index])
+
+Concatenating using ``append``
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+A useful shortcut to ``concat`` are the ``append`` instance methods on Series
+and DataFrame. These methods actually predated ``concat``. They concatenate
+along ``axis=0``, namely the index:
+
+.. ipython:: python
+
+   s = Series(randn(10), index=np.arange(10))
+   s1 = s[:5]
+   s2 = s[-5:]
+   s1.append(s2)
+
+In the case of DataFrame, the indexes must be disjoint but the columns do not
+need to be:
+
+.. ipython:: python
+
+   df = DataFrame(randn(6, 4), index=DateRange('1/1/2000', periods=6),
+                  columns=['A', 'B', 'C', 'D'])
+   df1 = df.ix[:3]
+   df2 = df.ix[3:, :3]
+   df1
+   df2
+   df1.append(df2)
+
+.. _merging.ignore_index:
+
+Ignoring indexes on the concatenation axis
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+For DataFrames which don't have a meaningful index, you may wish to append them
+and ignore the fact that they may have overlapping indexes:
+
+.. ipython:: python
+
+   df1 = DataFrame(randn(6, 4), columns=['A', 'B', 'C', 'D'])
+   df2 = DataFrame(randn(3, 4), columns=['A', 'B', 'C', 'D'])
+
+   df1
+   df2
+
+To do this, use the ``ignore_index`` argument:
+
+.. ipython:: python
+
+   concat([df1, df2], ignore_index=True)
+
+This is also a valid argument to ``DataFrame.append``:
+
+.. ipython:: python
+
+   df1.append(df2, ignore_index=True)
+
+More concatenating with group keys
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Let's consider a variation on the first example presented:
+
+.. ipython:: python
+
+   df = DataFrame(np.random.randn(10, 4))
+   df
+
+   # break it into pieces
+   pieces = [df.ix[:, [0, 1]], df.ix[:, [2]], df.ix[:, [3]]]
+
+   result = concat(pieces, axis=1, keys=['one', 'two', 'three'])
+   result
+
+The MultiIndex created has levels that are constructed from the passed keys and
+the columns of the DataFrame pieces:
+
+.. ipython:: python
+
+   result.columns.levels
+
+If you wish to specify other levels (as will occasionally be the case), you can
+do so using the ``levels`` argument:
+
+.. ipython:: python
+
+   result = concat(pieces, axis=1, keys=['one', 'two', 'three'],
+                   levels=[['three', 'two', 'one', 'zero']],
+                   names=['group_key'])
+   result
+   result.columns.levels
+
+Yes, this is fairly esoteric, but is actually necessary for implementing things
+like GroupBy where the order of a categorical variable is meaningful.
+
+.. _merging.append.row:
+
+Appending single rows to a DataFrame
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+While not especially efficient (since a new object must be created), you can
+append a row to a DataFrame by passing a Series to ``append``, which returns a
+new DataFrame as above:
+
+.. ipython:: python
+
+   df = DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
+   df
+   s = df.xs(3)
+   df.append(s, ignore_index=True)
+
+
+.. _merging.join:
+
+Database-style DataFrame joining/merging
+----------------------------------------
 
 pandas has full-featured, **high performance** in-memory join operations
 idiomatically very similar to relational databases like SQL. These methods
@@ -21,11 +256,6 @@ better) than other open source implementations (like ``base::merge.data.frame``
 in R). The reason for this is careful algorithmic design and internal layout of
 the data in DataFrame.
 
-.. _merging.join:
-
-Database-style DataFrame joining/merging
-----------------------------------------
-
 pandas provides a single function, ``merge``, as the entry point for all
 standard database join operations between DataFrame objects:
 
@@ -259,73 +489,17 @@ columns:
 ``DataFrame.join`` has ``lsuffix`` and ``rsuffix`` arguments which behave
 similarly.
 
-Joining multiple DataFrame objects at once
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-This has not been implemented yet, but is due to be implemented soon.
-
-.. _merging.append:
-
-Appending DataFrame objects (row-wise)
---------------------------------------
-
-Series and DataFrame have an ``append`` method which will glue together objects
-each of whose ``index`` (Series labels or DataFrame rows) is mutually
-exclusive.
-
-.. ipython:: python
-
-   s = Series(randn(10), index=np.arange(10))
-   s1 = s[:5]
-   s2 = s[-5:]
-   s1.append(s2)
+Joining multiple DataFrame or Panel objects
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-In the case of DataFrame, the indexes must be disjoint but the columns do not need to be:
+A list or tuple of DataFrames can also be passed to ``DataFrame.join`` to join
+them together on their indexes. The same is true for ``Panel.join``.
 
 .. ipython:: python
 
-   df = DataFrame(randn(6, 4), index=DateRange('1/1/2000', periods=6),
-                  columns=['A', 'B', 'C', 'D'])
-   df1 = df.ix[:3]
-   df2 = df.ix[3:, :3]
+   df1 = df.ix[:, ['A', 'B']]
+   df2 = df.ix[:, ['C', 'D']]
+   df3 = df.ix[:, ['key']]
    df1
-   df2
-   df1.append(df2)
-
-Appending record-array like DataFrames
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+   df1.join([df2, df3])
 
-For DataFrames which don't have a meaningful index, you may wish to append them
-and ignore the fact that they may have overlapping indexes:
-
-.. ipython:: python
-
-   df1 = DataFrame(randn(6, 4), columns=['A', 'B', 'C', 'D'])
-   df2 = DataFrame(randn(3, 4), columns=['A', 'B', 'C', 'D'])
-
-   df1
-   df2
-
-.. _merging.ignore_index:
-
-To do this, use the ``ignore_index`` argument:
-
-.. ipython:: python
-
-   df1.append(df2, ignore_index=True)
-
-.. _merging.append.row:
-
-Appending single rows to a DataFrame
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-While not especially efficient (since a new object must be created), you can
-append a row to a DataFrame by passing a Series to ``append``, which returns a
-new DataFrame as above:
-
-.. ipython:: python
-
-   df = DataFrame(np.random.randn(8, 4), columns=['A','B','C','D'])
-   df
-   s = df.xs(3)
-   df.append(s, ignore_index=True)
