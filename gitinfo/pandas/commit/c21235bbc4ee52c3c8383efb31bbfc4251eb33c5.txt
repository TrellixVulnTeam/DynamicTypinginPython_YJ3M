commit c21235bbc4ee52c3c8383efb31bbfc4251eb33c5
Author: garanews <puntogtg@tiscali.it>
Date:   Tue Oct 29 15:45:58 2019 +0100

    DOC: Misc typos fixed in docs and code comments (#28785)

diff --git a/ci/setup_env.sh b/ci/setup_env.sh
index 794130355..4d454f9c5 100755
--- a/ci/setup_env.sh
+++ b/ci/setup_env.sh
@@ -123,8 +123,8 @@ conda list pandas
 echo "[Build extensions]"
 python setup.py build_ext -q -i
 
-# XXX: Some of our environments end up with old verisons of pip (10.x)
-# Adding a new enough verison of pip to the requirements explodes the
+# XXX: Some of our environments end up with old versions of pip (10.x)
+# Adding a new enough version of pip to the requirements explodes the
 # solve time. Just using pip to update itself.
 # - py35_macos
 # - py35_compat
diff --git a/doc/source/whatsnew/v0.25.0.rst b/doc/source/whatsnew/v0.25.0.rst
index 2106d13dd..be137eaab 100644
--- a/doc/source/whatsnew/v0.25.0.rst
+++ b/doc/source/whatsnew/v0.25.0.rst
@@ -797,7 +797,7 @@ The columns were lexicographically sorted previously,
 
 The column order now matches the insertion-order of the keys in the ``dict``,
 considering all the records from top to bottom. As a consequence, the column
-order of the resulting DataFrame has changed compared to previous pandas verisons.
+order of the resulting DataFrame has changed compared to previous pandas versions.
 
 .. ipython:: python
 
@@ -886,7 +886,7 @@ Other API changes
 - Using an unsupported version of Beautiful Soup 4 will now raise an ``ImportError`` instead of a ``ValueError`` (:issue:`27063`)
 - :meth:`Series.to_excel` and :meth:`DataFrame.to_excel` will now raise a ``ValueError`` when saving timezone aware data. (:issue:`27008`, :issue:`7056`)
 - :meth:`ExtensionArray.argsort` places NA values at the end of the sorted array. (:issue:`21801`)
-- :meth:`DataFrame.to_hdf` and :meth:`Series.to_hdf` will now raise a ``NotImplementedError`` when saving a :class:`MultiIndex` with extention data types for a ``fixed`` format. (:issue:`7775`)
+- :meth:`DataFrame.to_hdf` and :meth:`Series.to_hdf` will now raise a ``NotImplementedError`` when saving a :class:`MultiIndex` with extension data types for a ``fixed`` format. (:issue:`7775`)
 - Passing duplicate ``names`` in :meth:`read_csv` will now raise a ``ValueError`` (:issue:`17346`)
 
 .. _whatsnew_0250.deprecations:
@@ -1106,7 +1106,7 @@ Indexing
 
 - Improved exception message when calling :meth:`DataFrame.iloc` with a list of non-numeric objects (:issue:`25753`).
 - Improved exception message when calling ``.iloc`` or ``.loc`` with a boolean indexer with different length (:issue:`26658`).
-- Bug in ``KeyError`` exception message when indexing a :class:`MultiIndex` with a non-existant key not displaying the original key (:issue:`27250`).
+- Bug in ``KeyError`` exception message when indexing a :class:`MultiIndex` with a non-existent key not displaying the original key (:issue:`27250`).
 - Bug in ``.iloc`` and ``.loc`` with a boolean indexer not raising an ``IndexError`` when too few items are passed (:issue:`26658`).
 - Bug in :meth:`DataFrame.loc` and :meth:`Series.loc` where ``KeyError`` was not raised for a ``MultiIndex`` when the key was less than or equal to the number of levels in the :class:`MultiIndex` (:issue:`14885`).
 - Bug in which :meth:`DataFrame.append` produced an erroneous warning indicating that a ``KeyError`` will be thrown in the future when the data to be appended contains new columns (:issue:`22252`).
diff --git a/pandas/_libs/tslibs/parsing.pyx b/pandas/_libs/tslibs/parsing.pyx
index 796d14001..39dabf4f3 100644
--- a/pandas/_libs/tslibs/parsing.pyx
+++ b/pandas/_libs/tslibs/parsing.pyx
@@ -92,7 +92,7 @@ cdef inline object _parse_delimited_date(object date_string, bint dayfirst):
     At the beginning function tries to parse date in MM/DD/YYYY format, but
     if month > 12 - in DD/MM/YYYY (`dayfirst == False`).
     With `dayfirst == True` function makes an attempt to parse date in
-    DD/MM/YYYY, if an attemp is wrong - in DD/MM/YYYY
+    DD/MM/YYYY, if an attempt is wrong - in DD/MM/YYYY
 
     Note
     ----
@@ -730,7 +730,7 @@ class _timelex:
         stream = self.stream.replace('\x00', '')
 
         # TODO: Change \s --> \s+ (this doesn't match existing behavior)
-        # TODO: change the punctuation block to punc+ (doesnt match existing)
+        # TODO: change the punctuation block to punc+ (does not match existing)
         # TODO: can we merge the two digit patterns?
         tokens = re.findall('\s|'
                             '(?<![\.\d])\d+\.\d+(?![\.\d])'
@@ -987,12 +987,12 @@ def _concat_date_cols(tuple date_cols, bint keep_trivial_numbers=True):
                                                       keep_trivial_numbers)
             PyArray_ITER_NEXT(it)
     else:
-        # create fixed size list - more effecient memory allocation
+        # create fixed size list - more efficient memory allocation
         list_to_join = [None] * col_count
         iters = np.zeros(col_count, dtype=object)
 
         # create memoryview of iters ndarray, that will contain some
-        # flatiter's for each array in `date_cols` - more effecient indexing
+        # flatiter's for each array in `date_cols` - more efficient indexing
         iters_view = iters
         for col_idx, array in enumerate(date_cols):
             iters_view[col_idx] = PyArray_IterNew(array)
diff --git a/pandas/core/arrays/categorical.py b/pandas/core/arrays/categorical.py
index 4d065bd23..c50870563 100644
--- a/pandas/core/arrays/categorical.py
+++ b/pandas/core/arrays/categorical.py
@@ -338,7 +338,7 @@ class Categorical(ExtensionArray, PandasObject):
         )
         # At this point, dtype is always a CategoricalDtype, but
         # we may have dtype.categories be None, and we need to
-        # infer categories in a factorization step futher below
+        # infer categories in a factorization step further below
 
         if fastpath:
             self._codes = coerce_indexer_dtype(values, dtype.categories)
diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index 7a6f28a86..4b83dd0cf 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -1441,7 +1441,7 @@ class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray)
             values = self.asi8
 
         if not len(values):
-            # short-circut for empty max / min
+            # short-circuit for empty max / min
             return NaT
 
         result = nanops.nanmax(values, skipna=skipna)
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index d7043a8cd..2208a0b87 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1271,7 +1271,7 @@ class DataFrame(NDFrame):
         array([[1, 3],
                [2, 4]])
 
-        With heterogenous data, the lowest common type will have to
+        With heterogeneous data, the lowest common type will have to
         be used.
 
         >>> df = pd.DataFrame({"A": [1, 2], "B": [3.0, 4.5]})
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 79d97a13e..187c7e2f3 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -4417,7 +4417,7 @@ class Index(IndexOpsMixin, PandasObject):
         every entry in the `where` argument.
 
         As in the `asof` function, if the label (a particular entry in
-        `where`) is not in the index, the latest index label upto the
+        `where`) is not in the index, the latest index label up to the
         passed label is chosen and its index returned.
 
         If all of the labels in the index are later than a label in `where`,
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index 3b6ac25e7..c95540166 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -747,7 +747,7 @@ class IntervalIndex(IntervalMixin, Index):
         Returns
         -------
         key: scalar or list-like
-            The original key if no conversion occured, int if converted scalar,
+            The original key if no conversion occurred, int if converted scalar,
             Int64Index if converted list-like.
         """
         original = key
diff --git a/pandas/core/ops/missing.py b/pandas/core/ops/missing.py
index 4fe69f64b..3bb7bb022 100644
--- a/pandas/core/ops/missing.py
+++ b/pandas/core/ops/missing.py
@@ -1,7 +1,7 @@
 """
 Missing data handling for arithmetic operations.
 
-In particular, pandas conventions regarding divison by zero differ
+In particular, pandas conventions regarding division by zero differ
 from numpy in the following ways:
     1) np.array([-1, 0, 1], dtype=dtype1) // np.array([0, 0, 0], dtype=dtype2)
        gives [nan, nan, nan] for most dtype combinations, and [0, 0, 0] for
diff --git a/pandas/io/json/_normalize.py b/pandas/io/json/_normalize.py
index cf8b9d901..702241bde 100644
--- a/pandas/io/json/_normalize.py
+++ b/pandas/io/json/_normalize.py
@@ -183,7 +183,7 @@ def json_normalize(
     1   {'height': 130, 'weight': 60}  NaN    Mose Reg
     2   {'height': 130, 'weight': 60}  2.0  Faye Raker
 
-    Normalizes nested data upto level 1.
+    Normalizes nested data up to level 1.
 
     >>> data = [{'id': 1,
     ...          'name': "Cole Volk",
diff --git a/pandas/io/pickle.py b/pandas/io/pickle.py
index 621e8e092..adf0aa961 100644
--- a/pandas/io/pickle.py
+++ b/pandas/io/pickle.py
@@ -140,7 +140,7 @@ def read_pickle(path, compression="infer"):
     path = _stringify_path(path)
     f, fh = _get_handle(path, "rb", compression=compression, is_text=False)
 
-    # 1) try standard libary Pickle
+    # 1) try standard library Pickle
     # 2) try pickle_compat (older pandas version) to handle subclass changes
     # 3) try pickle_compat with latin1 encoding
 
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 679b74cab..07475f224 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -2730,7 +2730,7 @@ class StataStrLWriter:
         Modifies the DataFrame in-place.
 
         The DataFrame returned encodes the (v,o) values as uint64s. The
-        encoding depends on teh dta version, and can be expressed as
+        encoding depends on the dta version, and can be expressed as
 
         enc = v + o * 2 ** (o_size * 8)
 
diff --git a/pandas/tests/frame/test_timezones.py b/pandas/tests/frame/test_timezones.py
index 3e110a4b0..26ab4ff0d 100644
--- a/pandas/tests/frame/test_timezones.py
+++ b/pandas/tests/frame/test_timezones.py
@@ -37,7 +37,7 @@ class TestDataFrameTimezones:
         expected = np.concatenate([expected, expected], axis=1)
         tm.assert_numpy_array_equal(result, expected)
 
-        # three columns, heterogenous
+        # three columns, heterogeneous
         est = "US/Eastern"
         df = df.assign(C=df.A.dt.tz_convert(est))
 
diff --git a/pandas/tests/indexes/multi/test_copy.py b/pandas/tests/indexes/multi/test_copy.py
index 35a5cccc0..266819753 100644
--- a/pandas/tests/indexes/multi/test_copy.py
+++ b/pandas/tests/indexes/multi/test_copy.py
@@ -74,7 +74,7 @@ def test_copy_method(deep):
 @pytest.mark.parametrize(
     "kwarg, value",
     [
-        ("names", ["thrid", "fourth"]),
+        ("names", ["third", "fourth"]),
         ("levels", [["foo2", "bar2"], ["fizz2", "buzz2"]]),
         ("codes", [[1, 0, 0, 0], [1, 1, 0, 0]]),
     ],
diff --git a/pandas/tests/io/formats/test_format.py b/pandas/tests/io/formats/test_format.py
index 9aba4c8aa..704de378b 100644
--- a/pandas/tests/io/formats/test_format.py
+++ b/pandas/tests/io/formats/test_format.py
@@ -54,7 +54,7 @@ def filepath_or_buffer_id(request):
 @pytest.fixture
 def filepath_or_buffer(filepath_or_buffer_id, tmp_path):
     """
-    A fixture yeilding a string representing a filepath, a path-like object
+    A fixture yielding a string representing a filepath, a path-like object
     and a StringIO buffer. Also checks that buffer is not closed.
     """
     if filepath_or_buffer_id == "buffer":
diff --git a/pandas/tests/io/json/test_normalize.py b/pandas/tests/io/json/test_normalize.py
index aa4f522ef..a3ca61cb1 100644
--- a/pandas/tests/io/json/test_normalize.py
+++ b/pandas/tests/io/json/test_normalize.py
@@ -554,7 +554,7 @@ class TestNestedToRecord:
 
     def test_nonetype_top_level_bottom_level(self):
         # GH21158: If inner level json has a key with a null value
-        # make sure it doesnt do a new_d.pop twice and except
+        # make sure it does not do a new_d.pop twice and except
         data = {
             "id": None,
             "location": {
@@ -586,7 +586,7 @@ class TestNestedToRecord:
 
     def test_nonetype_multiple_levels(self):
         # GH21158: If inner level json has a key with a null value
-        # make sure it doesnt do a new_d.pop twice and except
+        # make sure it does not do a new_d.pop twice and except
         data = {
             "id": None,
             "location": {
diff --git a/pandas/tests/tseries/offsets/test_offsets.py b/pandas/tests/tseries/offsets/test_offsets.py
index 5cc10bf00..81aff4211 100644
--- a/pandas/tests/tseries/offsets/test_offsets.py
+++ b/pandas/tests/tseries/offsets/test_offsets.py
@@ -670,7 +670,7 @@ class TestBusinessDay(Base):
         self.offset2 = BDay(2)
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
@@ -912,7 +912,7 @@ class TestBusinessHour(Base):
             BusinessHour(start=start, end=end)
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
@@ -2278,7 +2278,7 @@ class TestCustomBusinessHour(Base):
             CustomBusinessHour(start="14:00:05")
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
@@ -2556,7 +2556,7 @@ class TestCustomBusinessDay(Base):
         self.offset2 = CDay(2)
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
@@ -2827,7 +2827,7 @@ class TestCustomBusinessMonthEnd(CustomBusinessMonthBase, Base):
     _offset = CBMonthEnd
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
@@ -2976,7 +2976,7 @@ class TestCustomBusinessMonthBegin(CustomBusinessMonthBase, Base):
     _offset = CBMonthBegin
 
     def test_different_normalize_equals(self):
-        # GH#21404 changed __eq__ to return False when `normalize` doesnt match
+        # GH#21404 changed __eq__ to return False when `normalize` does not match
         offset = self._offset()
         offset2 = self._offset(normalize=True)
         assert offset != offset2
