commit 0583191f724d90f8504a523239303024e78b24e6
Author: jreback <jeff@reback.net>
Date:   Thu Sep 19 08:21:07 2013 -0400

    BUG: bug in getitem with a duplicate index when using where (GH4879)

diff --git a/doc/source/release.rst b/doc/source/release.rst
index 4224880d3..5a49f13cd 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -429,9 +429,11 @@ Bug Fixes
     ``ascending`` was being interpreted as ``True`` (:issue:`4839`,
     :issue:`4846`)
   - Fixed ``Panel.tshift`` not working. Added `freq` support to ``Panel.shift`` (:issue:`4853`)
-  - Fix an issue in TextFileReader w/ Python engine (i.e. PythonParser) 
+  - Fix an issue in TextFileReader w/ Python engine (i.e. PythonParser)
     with thousands != "," (:issue:`4596`)
-    
+  - Bug in getitem with a duplicate index when using where (:issue:`4879`)
+
+
 pandas 0.12.0
 -------------
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 70fcc2c9d..cf0afe426 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1840,8 +1840,12 @@ class DataFrame(NDFrame):
         if self.columns.is_unique:
             return self._get_item_cache(key)
 
-        # duplicate columns
-        return self._constructor(self._data.get(key))
+        # duplicate columns & possible reduce dimensionaility
+        result = self._constructor(self._data.get(key))
+        if result.columns.is_unique:
+            result = result[key]
+
+        return result
 
     def _getitem_slice(self, key):
         return self._slice(key, axis=0)
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 4b9fdb042..585b1c817 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -401,7 +401,7 @@ class Block(PandasObject):
             if values is None:
                 values = com._astype_nansafe(self.values, dtype, copy=True)
             newb = make_block(
-                values, self.items, self.ref_items, ndim=self.ndim,
+                values, self.items, self.ref_items, ndim=self.ndim, placement=self._ref_locs,
                 fastpath=True, dtype=dtype, klass=klass)
         except:
             if raise_on_error is True:
@@ -716,7 +716,7 @@ class Block(PandasObject):
         if inplace:
             return [self]
 
-        return [make_block(new_values, self.items, self.ref_items, fastpath=True)]
+        return [make_block(new_values, self.items, self.ref_items, placement=self._ref_locs, fastpath=True)]
 
     def interpolate(self, method='pad', axis=0, inplace=False,
                     limit=None, fill_value=None, coerce=False,
@@ -2853,12 +2853,13 @@ class BlockManager(PandasObject):
         # TODO: less efficient than I'd like
 
         item_order = com.take_1d(self.items.values, indexer)
+        new_axes = [new_items] + self.axes[1:]
+        new_blocks = []
+        is_unique = new_items.is_unique
 
         # keep track of what items aren't found anywhere
+        l = np.arange(len(item_order))
         mask = np.zeros(len(item_order), dtype=bool)
-        new_axes = [new_items] + self.axes[1:]
-
-        new_blocks = []
         for blk in self.blocks:
             blk_indexer = blk.items.get_indexer(item_order)
             selector = blk_indexer != -1
@@ -2872,12 +2873,19 @@ class BlockManager(PandasObject):
             new_block_items = new_items.take(selector.nonzero()[0])
             new_values = com.take_nd(blk.values, blk_indexer[selector], axis=0,
                                      allow_fill=False)
-            new_blocks.append(make_block(new_values, new_block_items,
-                                         new_items, fastpath=True))
+            placement = l[selector] if not is_unique else None
+            new_blocks.append(make_block(new_values,
+                                         new_block_items,
+                                         new_items,
+                                         placement=placement,
+                                         fastpath=True))
 
         if not mask.all():
             na_items = new_items[-mask]
-            na_block = self._make_na_block(na_items, new_items,
+            placement = l[-mask] if not is_unique else None
+            na_block = self._make_na_block(na_items,
+                                           new_items,
+                                           placement=placement,
                                            fill_value=fill_value)
             new_blocks.append(na_block)
             new_blocks = _consolidate(new_blocks, new_items)
@@ -2943,7 +2951,7 @@ class BlockManager(PandasObject):
 
         return self.__class__(new_blocks, new_axes)
 
-    def _make_na_block(self, items, ref_items, fill_value=None):
+    def _make_na_block(self, items, ref_items, placement=None, fill_value=None):
         # TODO: infer dtypes other than float64 from fill_value
 
         if fill_value is None:
@@ -2954,8 +2962,7 @@ class BlockManager(PandasObject):
         dtype, fill_value = com._infer_dtype_from_scalar(fill_value)
         block_values = np.empty(block_shape, dtype=dtype)
         block_values.fill(fill_value)
-        na_block = make_block(block_values, items, ref_items)
-        return na_block
+        return make_block(block_values, items, ref_items, placement=placement)
 
     def take(self, indexer, new_index=None, axis=1, verify=True):
         if axis < 1:
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index d216cebc1..0bc454d6e 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -3150,6 +3150,36 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         expected = DataFrame([[1],[1],[1]],columns=['bar'])
         check(df,expected)
 
+    def test_column_dups_indexing(self):
+
+        def check(result, expected=None):
+            if expected is not None:
+                assert_frame_equal(result,expected)
+            result.dtypes
+            str(result)
+
+        # boolean indexing
+        # GH 4879
+        dups = ['A', 'A', 'C', 'D']
+        df = DataFrame(np.arange(12).reshape(3,4), columns=['A', 'B', 'C', 'D'],dtype='float64')
+        expected = df[df.C > 6]
+        expected.columns = dups
+        df = DataFrame(np.arange(12).reshape(3,4), columns=dups,dtype='float64')
+        result = df[df.C > 6]
+        check(result,expected)
+
+        # where
+        df = DataFrame(np.arange(12).reshape(3,4), columns=['A', 'B', 'C', 'D'],dtype='float64')
+        expected = df[df > 6]
+        expected.columns = dups
+        df = DataFrame(np.arange(12).reshape(3,4), columns=dups,dtype='float64')
+        result = df[df > 6]
+        check(result,expected)
+
+        # boolean with the duplicate raises
+        df = DataFrame(np.arange(12).reshape(3,4), columns=dups,dtype='float64')
+        self.assertRaises(ValueError, lambda : df[df.A > 6])
+
     def test_insert_benchmark(self):
         # from the vb_suite/frame_methods/frame_insert_columns
         N = 10
diff --git a/pandas/tests/test_indexing.py b/pandas/tests/test_indexing.py
index 3453e69ed..aad9fb2f9 100644
--- a/pandas/tests/test_indexing.py
+++ b/pandas/tests/test_indexing.py
@@ -1233,9 +1233,10 @@ class TestIndexing(unittest.TestCase):
 
         # GH 4146, not returning a block manager when selecting a unique index
         # from a duplicate index
-        expected = DataFrame([['a',1,1]],index=['A1'],columns=['h1','h3','h5'],).T
+        # as of 4879, this returns a Series (which is similar to what happens with a non-unique)
+        expected = Series(['a',1,1],index=['h1','h3','h5'])
         result = df2['A']['A1']
-        assert_frame_equal(result,expected)
+        assert_series_equal(result,expected)
 
         # selecting a non_unique from the 2nd level
         expected = DataFrame([['d',4,4],['e',5,5]],index=Index(['B2','B2'],name='sub'),columns=['h1','h3','h5'],).T
