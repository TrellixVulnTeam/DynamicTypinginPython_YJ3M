commit b3e5f2d76c3d90ea8fd67c559ce26e3b42c7fa2c
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Sep 26 16:04:35 2011 -0400

    ENH: reindex functions no longer return masks. related refactoring

diff --git a/pandas/core/common.py b/pandas/core/common.py
index 7928c3832..97c53f0ad 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -8,7 +8,7 @@ import itertools
 from numpy.lib.format import read_array, write_array
 import numpy as np
 
-import pandas._tseries as _tseries
+import pandas._tseries as lib
 
 # XXX: HACK for NumPy 1.5.1 to suppress warnings
 try:
@@ -39,7 +39,7 @@ def isnull(input):
             # Working around NumPy ticket 1542
             shape = input.shape
             result = np.empty(shape, dtype=bool)
-            vec = _tseries.isnullobj(input.ravel())
+            vec = lib.isnullobj(input.ravel())
             result[:] = vec.reshape(shape)
 
             if isinstance(input, Series):
@@ -50,7 +50,7 @@ def isnull(input):
         # TODO: optimize for DataFrame, etc.
         return input.apply(isnull)
     else:
-        result = _tseries.checknull(input)
+        result = lib.checknull(input)
 
     return result
 
@@ -87,6 +87,56 @@ def null_out_axis(arr, mask, axis):
 
     arr[tuple(indexer)] = np.NaN
 
+def _take_1d_bool(arr, indexer, out):
+    view = arr.view(np.uint8)
+    outview = out.view(np.uint8)
+    lib.take_1d_bool(view, indexer, outview)
+
+_take1d_dict = {
+    'float64' : lib.take_1d_float64,
+    'int32' : lib.take_1d_int32,
+    'int64' : lib.take_1d_int64,
+    'object' : lib.take_1d_object,
+    'bool' : _take_1d_bool
+}
+
+def take_1d(arr, indexer):
+    """
+    Specialized Cython take which sets NaN values
+    """
+    dtype_str = arr.dtype.name
+
+    if dtype_str in ('int32', 'int64', 'bool'):
+        mask = indexer == -1
+        if mask.any():
+            out = arr.take(indexer)
+            out = _maybe_upcast(out)
+            np.putmask(out, mask, np.nan)
+        else:
+            out = np.empty(len(indexer), dtype=arr.dtype)
+            take_f = _take1d_dict[dtype_str]
+            take_f(arr, indexer, out=out)
+    elif dtype_str in ('float64', 'object'):
+        out = np.empty(len(indexer), dtype=arr.dtype)
+        take_f = _take1d_dict[dtype_str]
+        take_f(arr, indexer, out=out)
+    else:
+        out = arr.take(indexer)
+        mask = indexer == -1
+        if mask.any():
+            out = _maybe_upcast(out)
+            np.putmask(out, mask, np.nan)
+
+    return out
+
+def _maybe_upcast(values):
+    if issubclass(values.dtype.type, np.int_):
+        values = values.astype(float)
+    elif issubclass(values.dtype.type, np.bool_):
+        values = values.astype(object)
+
+    return values
+
 #-------------------------------------------------------------------------------
 # Lots of little utilities
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index c6844b15e..3a0a47c47 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -21,13 +21,13 @@ import numpy as np
 
 from pandas.core.common import (isnull, notnull, PandasError,
                                 _try_sort, _pfixed, _default_index,
-                                _infer_dtype, _stringify)
+                                _infer_dtype, _stringify, _maybe_upcast)
 from pandas.core.daterange import DateRange
 from pandas.core.generic import AxisProperty, NDFrame
 from pandas.core.index import Index, MultiIndex, NULL_INDEX, _ensure_index
 from pandas.core.indexing import _NDFrameIndexer, _maybe_droplevels
 from pandas.core.internals import BlockManager, make_block, form_blocks
-from pandas.core.series import Series, _is_bool_indexer, _maybe_upcast
+from pandas.core.series import Series, _is_bool_indexer
 from pandas.util.decorators import deprecate
 import pandas.core.common as common
 import pandas.core.datetools as datetools
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 77b842942..2eb03342a 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -757,7 +757,7 @@ class SeriesGroupBy(GroupBy):
         for name, group in self:
             group.name = name
             res = func(group, *args, **kwargs)
-            indexer, _ = self.obj.index.get_indexer(group.index)
+            indexer = self.obj.index.get_indexer(group.index)
             np.put(result, indexer, res)
 
         return result
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 9111528d9..8dd5629c4 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -9,7 +9,7 @@ from pandas.core.common import (_format, adjoin as _adjoin, _stringify,
                                 _is_bool_indexer, _asarray_tuplesafe)
 from pandas.util.decorators import deprecate, cache_readonly
 import pandas.core.common as common
-import pandas._tseries as _tseries
+import pandas._tseries as lib
 
 __all__ = ['Index']
 
@@ -70,7 +70,7 @@ class Index(np.ndarray):
     def indexMap(self):
         "{label -> location}"
         if self._indexMap is None:
-            self._indexMap = _tseries.map_indices_buf(self)
+            self._indexMap = lib.map_indices_buf(self)
             self._verify_integrity()
 
         return self._indexMap
@@ -81,7 +81,7 @@ class Index(np.ndarray):
         Checks that all the labels are datetime objects
         """
         if self._allDates is None:
-            self._allDates = _tseries.isAllDates(self)
+            self._allDates = lib.isAllDates(self)
 
         return self._allDates
 
@@ -232,7 +232,7 @@ class Index(np.ndarray):
         if len(self) == 0:
             return _ensure_index(other)
 
-        return Index(_tseries.fast_unique_multiple([self, other]))
+        return Index(lib.fast_unique_multiple([self, other]))
 
     def intersection(self, other):
         """
@@ -323,19 +323,24 @@ class Index(np.ndarray):
         (indexer, mask) : (ndarray, ndarray)
         """
         if method:
-            method = method.upper()
+            method = method.lower()
 
         aliases = {
-            'FFILL' : 'PAD',
-            'BFILL' : 'BACKFILL'
+            'ffill' : 'pad',
+            'bfill' : 'backfill'
         }
-
         target = _ensure_index(target)
-
         method = aliases.get(method, method)
-        indexer, mask = _tseries.getFillVec(self, target, self.indexMap,
-                                            target.indexMap, method)
-        return indexer, mask
+
+        if method == 'pad':
+            indexer = lib.pad(self, target, self.indexMap, target.indexMap)
+        elif method == 'backfill':
+            indexer = lib.backfill(self, target, self.indexMap, target.indexMap)
+        elif method is None:
+            indexer = lib.merge_indexer(target, self.indexMap)
+        else:
+            raise ValueError('unrecognized method: %s' % method)
+        return indexer
 
     def reindex(self, target, method=None):
         """
@@ -347,8 +352,8 @@ class Index(np.ndarray):
         -------
         (new_index, indexer, mask) : tuple
         """
-        indexer, mask = self.get_indexer(target, method=method)
-        return target, indexer, mask
+        indexer = self.get_indexer(target, method=method)
+        return target, indexer
 
     def slice_locs(self, start=None, end=None):
         """
@@ -428,9 +433,10 @@ class Index(np.ndarray):
         dropped : Index
         """
         labels = np.asarray(list(labels), dtype=object)
-        indexer, mask = self.get_indexer(labels)
-        if not mask.all():
-            raise ValueError('labels %s not contained in axis' % labels[-mask])
+        indexer = self.get_indexer(labels)
+        mask = indexer == -1
+        if mask.any():
+            raise ValueError('labels %s not contained in axis' % labels[mask])
         return self.delete(indexer)
 
     def copy(self, order='C'):
@@ -500,8 +506,8 @@ class Factor(np.ndarray):
             return np.ndarray.__getitem__(self, key)
 
 def unique_with_labels(values):
-    uniques = Index(_tseries.fast_unique(values))
-    labels = _tseries.get_unique_labels(values, uniques.indexMap)
+    uniques = Index(lib.fast_unique(values))
+    labels = lib.get_unique_labels(values, uniques.indexMap)
     return uniques, labels
 
 class MultiIndex(Index):
@@ -596,7 +602,7 @@ class MultiIndex(Index):
                 return 0
 
         for k in range(self.nlevels, 0, -1):
-            if _tseries.is_lexsorted(self.labels[:k]):
+            if lib.is_lexsorted(self.labels[:k]):
                 return k
 
         return 0
@@ -649,7 +655,7 @@ class MultiIndex(Index):
     def indexMap(self):
         if self._indexMap is None:
             zipped = zip(*self.labels)
-            self._indexMap = _tseries.map_indices_list(zipped)
+            self._indexMap = lib.map_indices_list(zipped)
             self._verify_integrity()
 
         return self._indexMap
@@ -731,10 +737,11 @@ class MultiIndex(Index):
         try:
             if not isinstance(labels, np.ndarray):
                 labels = _asarray_tuplesafe(labels)
-            indexer, mask = self.get_indexer(labels)
-            if not mask.all():
+            indexer = self.get_indexer(labels)
+            mask = indexer == -1
+            if mask.any():
                 raise ValueError('labels %s not contained in axis'
-                                 % labels[-mask])
+                                 % labels[mask])
             return self.delete(indexer)
         except Exception:
             pass
@@ -858,11 +865,11 @@ class MultiIndex(Index):
         (indexer, mask) : (ndarray, ndarray)
         """
         if method:
-            method = method.upper()
+            method = method.lower()
 
         aliases = {
-            'FFILL' : 'PAD',
-            'BFILL' : 'BACKFILL'
+            'ffill' : 'pad',
+            'bfill' : 'backfill'
         }
         method = aliases.get(method, method)
 
@@ -878,10 +885,16 @@ class MultiIndex(Index):
             target_index = target
 
         self_index = self.get_tuple_index()
-        indexer, mask = _tseries.getFillVec(self_index, target_index,
-                                            self_index.indexMap,
-                                            target.indexMap, method)
-        return indexer, mask
+
+        if method == 'pad':
+            indexer = lib.pad(self_index, target_index, self_index.indexMap,
+                              target.indexMap)
+        elif method == 'backfill':
+            indexer = lib.backfill(self_index, target_index, self_index.indexMap,
+                                   target.indexMap)
+        else:
+            indexer = lib.merge_indexer(target_index, self_index.indexMap)
+        return indexer
 
     def reindex(self, target, method=None):
         """
@@ -893,13 +906,13 @@ class MultiIndex(Index):
         -------
         (new_index, indexer, mask) : (MultiIndex, ndarray, ndarray)
         """
-        indexer, mask = self.get_indexer(target, method=method)
+        indexer = self.get_indexer(target, method=method)
 
         # hopefully?
         if not isinstance(target, MultiIndex):
             target = MultiIndex.from_tuples(target)
 
-        return target, indexer, mask
+        return target, indexer
 
     def get_tuple_index(self):
         """
@@ -1109,8 +1122,7 @@ class MultiIndex(Index):
         self_tuples = self.get_tuple_index()
         other_tuples = other.get_tuple_index()
 
-        uniq_tuples = _tseries.fast_unique_multiple([self_tuples,
-                                                     other_tuples])
+        uniq_tuples = lib.fast_unique_multiple([self_tuples, other_tuples])
         return MultiIndex.from_arrays(zip(*uniq_tuples), sortorder=0)
 
     def intersection(self, other):
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 93898e0cc..7a41b1e2c 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -214,9 +214,10 @@ class _NDFrameIndexer(object):
                 if _is_integer_dtype(objarr) and not is_int_index:
                     return objarr
 
-                indexer, mask = index.get_indexer(objarr)
-                if not mask.all():
-                    raise KeyError('%s not in index' % objarr[-mask])
+                indexer = index.get_indexer(objarr)
+                mask = indexer == -1
+                if mask.any():
+                    raise KeyError('%s not in index' % objarr[mask])
 
                 return indexer
         else:
@@ -292,9 +293,10 @@ class _SeriesIndexer(_NDFrameIndexer):
                 obj[key] = value
 
             def do_list_like():
-                inds, mask = obj.index.get_indexer(key)
-                if not mask.all():
-                    raise IndexingError('Indices %s not found' % key[-mask])
+                inds = obj.index.get_indexer(key)
+                mask = inds == -1
+                if mask.any():
+                    raise IndexingError('Indices %s not found' % key[mask])
                 obj.put(inds, value)
         op = do_default
         if _isboolarr(key):
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 492696e08..f8ffc2f6c 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -5,7 +5,7 @@ import numpy as np
 
 from pandas.core.index import Index, _ensure_index
 import pandas.core.common as common
-import pandas._tseries as _tseries
+import pandas._tseries as lib
 
 class Block(object):
     """
@@ -39,8 +39,8 @@ class Block(object):
     @property
     def ref_locs(self):
         if self._ref_locs is None:
-            indexer, mask = self.ref_items.get_indexer(self.items)
-            assert(mask.all())
+            indexer = self.ref_items.get_indexer(self.items)
+            assert((indexer != -1).all())
             self._ref_locs = indexer
         return self._ref_locs
 
@@ -126,7 +126,8 @@ class Block(object):
         -------
         reindexed : Block
         """
-        new_ref_items, indexer, mask = self.items.reindex(new_ref_items)
+        new_ref_items, indexer = self.items.reindex(new_ref_items)
+        mask = indexer != -1
         masked_idx = indexer[mask]
         new_values = self.values.take(masked_idx, axis=0)
         new_items = self.items.take(masked_idx)
@@ -423,8 +424,8 @@ class BlockManager(object):
         # By construction, all of the item should be covered by one of the
         # blocks
         for block in self.blocks:
-            indexer, mask = items.get_indexer(block.items)
-            assert(mask.all())
+            indexer = items.get_indexer(block.items)
+            assert((indexer != -1).all())
             result[indexer] = block.values
             itemmask[indexer] = 1
         assert(itemmask.all())
@@ -555,15 +556,15 @@ class BlockManager(object):
         new_axis = _ensure_index(new_axis)
         cur_axis = self.axes[axis]
 
-        new_axis, indexer, mask = cur_axis.reindex(new_axis, method)
+        new_axis, indexer = cur_axis.reindex(new_axis, method)
+        mask = indexer == -1
 
         # TODO: deal with length-0 case? or does it fall out?
-        notmask = -mask
-        needs_masking = len(new_axis) > 0 and notmask.any()
+        needs_masking = len(new_axis) > 0 and mask.any()
 
         new_blocks = []
         for block in self.blocks:
-            newb = block.reindex_axis(indexer, notmask, needs_masking,
+            newb = block.reindex_axis(indexer, mask, needs_masking,
                                       axis=axis)
             new_blocks.append(newb)
 
@@ -582,8 +583,8 @@ class BlockManager(object):
             return data.reindex_items(new_items)
 
         # TODO: this part could be faster (!)
-        new_items, _, mask = self.items.reindex(new_items)
-        notmask = -mask
+        new_items, indexer = self.items.reindex(new_items)
+        mask = indexer == -1
 
         new_blocks = []
         for block in self.blocks:
@@ -591,8 +592,8 @@ class BlockManager(object):
             if len(newb.items) > 0:
                 new_blocks.append(newb)
 
-        if notmask.any():
-            extra_items = new_items[notmask]
+        if mask.any():
+            extra_items = new_items[mask]
 
             block_shape = list(self.shape)
             block_shape[0] = len(extra_items)
@@ -695,16 +696,14 @@ class BlockManager(object):
         this, other = self._maybe_rename_join(other, lsuffix, rsuffix)
 
         other_axis = other.axes[axis]
-        indexer, mask = _tseries.getMergeVec(on.astype(object),
-                                             other_axis.indexMap)
+        indexer = lib.merge_indexer(on.astype(object), other_axis.indexMap)
 
         # TODO: deal with length-0 case? or does it fall out?
-        notmask = -mask
-        needs_masking = len(on) > 0 and notmask.any()
+        mask = indexer == -1
+        needs_masking = len(on) > 0 and mask.any()
         other_blocks = []
         for block in other.blocks:
-            newb = block.reindex_axis(indexer, notmask, needs_masking,
-                                      axis=axis)
+            newb = block.reindex_axis(indexer, mask, needs_masking, axis=axis)
             other_blocks.append(newb)
 
         cons_items = this.items + other.items
@@ -757,8 +756,8 @@ class BlockManager(object):
         result.fill(-1)
 
         for i, blk in enumerate(self.blocks):
-            indexer, mask = self.items.get_indexer(blk.items)
-            assert(mask.all())
+            indexer = self.items.get_indexer(blk.items)
+            assert((indexer != -1).all())
             result.put(indexer, i)
 
         assert((result >= 0).all())
@@ -908,7 +907,7 @@ def _union_block_items(blocks):
     if slow:
         the_union = _union_items_slow(all_items)
     else:
-        the_union = Index(_tseries.fast_unique_multiple(all_items))
+        the_union = Index(lib.fast_unique_multiple(all_items))
 
     if tot_len > len(the_union):
         raise Exception('item names overlap')
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 2ceb33fd4..7c464635d 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -14,14 +14,15 @@ from numpy import nan, ndarray
 import numpy as np
 
 from pandas.core.common import (isnull, notnull, _is_bool_indexer,
-                                _default_index)
+                                _default_index, _maybe_upcast)
 from pandas.core.daterange import DateRange
 from pandas.core.generic import PandasObject
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.core.indexing import _SeriesIndexer, _maybe_droplevels
 from pandas.util.decorators import deprecate
+import pandas.core.common as common
 import pandas.core.datetools as datetools
-import pandas._tseries as _tseries
+import pandas._tseries as lib
 
 __all__ = ['Series', 'TimeSeries']
 
@@ -580,7 +581,7 @@ copy : boolean, default False
             if not mask.all():
                 return np.nan
 
-        return _tseries.median(arr)
+        return lib.median(arr)
 
     def prod(self, axis=0, dtype=None, out=None, skipna=True):
         """
@@ -1238,18 +1239,11 @@ copy : boolean, default False
             if isinstance(arg, dict):
                 arg = Series(arg)
 
-            indexer, mask = _tseries.getMergeVec(self.values.astype(object),
-                                                 arg.index.indexMap)
-            notmask = -mask
-
-            new_values = arg.view(np.ndarray).take(indexer)
-
-            if notmask.any():
-                new_values = _maybe_upcast(new_values)
-                np.putmask(new_values, notmask, np.nan)
+            indexer = lib.merge_indexer(self.values.astype(object),
+                                        arg.index.indexMap)
 
-            newSer = Series(new_values, index=self.index)
-            return newSer
+            new_values = common.take_1d(np.asarray(arg), indexer)
+            return Series(new_values, index=self.index)
         else:
             return Series([arg(x) for x in self], index=self.index)
 
@@ -1303,14 +1297,8 @@ copy : boolean, default False
         if len(self.index) == 0:
             return Series(nan, index=index)
 
-        new_index, fill_vec, mask = self.index.reindex(index, method=method)
-        new_values = self.values.take(fill_vec)
-
-        notmask = -mask
-        if notmask.any():
-            new_values = _maybe_upcast(new_values)
-            np.putmask(new_values, notmask, nan)
-
+        new_index, fill_vec = self.index.reindex(index, method=method)
+        new_values = common.take_1d(self.values, fill_vec)
         return Series(new_values, index=new_index)
 
     def reindex_like(self, other, method=None):
@@ -1393,9 +1381,9 @@ copy : boolean, default False
             mask = mask.astype(np.uint8)
 
             if method == 'pad':
-                indexer = _tseries.get_pad_indexer(mask)
+                indexer = lib.get_pad_indexer(mask)
             elif method == 'backfill':
-                indexer = _tseries.get_backfill_indexer(mask)
+                indexer = lib.get_backfill_indexer(mask)
 
             new_values = self.values.take(indexer)
             return Series(new_values, index=self.index)
@@ -1774,14 +1762,6 @@ def remove_na(arr):
     """
     return arr[notnull(arr)]
 
-def _maybe_upcast(values):
-    if issubclass(values.dtype.type, np.int_):
-        values = values.astype(float)
-    elif issubclass(values.dtype.type, np.bool_):
-        values = values.astype(object)
-
-    return values
-
 def _seriesRepr(index, vals, nanRep='NaN'):
     string_index = index.format()
     maxlen = max(len(x) for x in string_index)
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index f9bc1ed81..02ef007dd 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -17,6 +17,7 @@ from pandas.core.series import Series, TimeSeries
 from pandas.core.frame import (DataFrame, extract_index, _prep_ndarray,
                                _default_index)
 from pandas.core.panel import Panel, LongPanel
+import pandas.core.common as common
 import pandas.core.datetools as datetools
 
 from pandas._sparse import BlockIndex, IntIndex
@@ -448,14 +449,8 @@ to sparse
             return SparseSeries(values, index=new_index,
                                 fill_value=self.fill_value)
 
-        values = self.values
-        indexer, mask = self.index.get_indexer(new_index, method=method)
-        new_values = values.take(indexer)
-
-        notmask = -mask
-        if notmask.any():
-            np.putmask(new_values, notmask, nan)
-
+        new_index, fill_vec = self.index.reindex(index, method=method)
+        new_values = common.take_1d(self.values, fill_vec)
         return SparseSeries(new_values, index=new_index,
                             fill_value=self.fill_value)
 
@@ -1019,9 +1014,9 @@ class SparseDataFrame(DataFrame):
         if len(self.index) == 0:
             return SparseDataFrame(index=index, columns=self.columns)
 
-        indexer, mask = self.index.get_indexer(index, method)
-        notmask = -mask
-        need_mask = notmask.any()
+        indexer = self.index.get_indexer(index, method)
+        mask = indexer == -1
+        need_mask = mask.any()
 
         new_series = {}
         for col, series in self.iteritems():
@@ -1029,7 +1024,7 @@ class SparseDataFrame(DataFrame):
             new = values.take(indexer)
 
             if need_mask:
-                new[notmask] = nan
+                np.putmask(new, mask, nan)
 
             new_series[col] = new
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 0fa2aeb80..ed410f365 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -12,7 +12,7 @@ import numpy as np
 from pandas import (Series, TimeSeries, DataFrame, Panel, LongPanel,
                     MultiIndex)
 from pandas.core.common import adjoin
-import pandas._tseries as _tseries
+import pandas._tseries as lib
 
 # reading and writing the full object in one go
 _TYPE_MAP = {
@@ -663,12 +663,12 @@ class HDFStore(object):
 
             # need a better algorithm
             tuple_index = long_index.get_tuple_index()
-            index_map = _tseries.map_indices_buf(tuple_index)
+            index_map = lib.map_indices_buf(tuple_index)
 
-            unique_tuples = _tseries.fast_unique(tuple_index)
+            unique_tuples = lib.fast_unique(tuple_index)
             unique_tuples = _asarray_tuplesafe(unique_tuples)
 
-            indexer, _ = _tseries.getMergeVec(unique_tuples, index_map)
+            indexer = lib.merge_indexer(unique_tuples, index_map)
 
             new_index = long_index.take(indexer)
             new_values = lp.values.take(indexer, axis=0)
@@ -739,7 +739,7 @@ def _unconvert_index(data, kind):
 
 def _unconvert_index_legacy(data, kind, legacy=False):
     if kind == 'datetime':
-        index = _tseries.array_to_datetime(data)
+        index = lib.array_to_datetime(data)
     elif kind in ('string', 'integer'):
         index = np.array(data, dtype=object)
     else: # pragma: no cover
diff --git a/pandas/src/reindex.pyx b/pandas/src/reindex.pyx
index 731e49a18..c8930baec 100644
--- a/pandas/src/reindex.pyx
+++ b/pandas/src/reindex.pyx
@@ -1,20 +1,7 @@
-def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
-               kind=None):
-
-    if kind is None:
-        fillVec, maskVec = getMergeVec(newIndex, oldMap)
-    elif kind == 'PAD':
-        fillVec, maskVec = _pad(oldIndex, newIndex, oldMap, newMap)
-    elif kind == 'BACKFILL':
-        fillVec, maskVec = _backfill(oldIndex, newIndex, oldMap, newMap)
-    else:
-        raise Exception("Don't recognize method: %s" % kind)
-
-    return fillVec, maskVec.astype(np.bool)
-
+@cython.boundscheck(False)
 @cython.wraparound(False)
-def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
-              dict oldMap, dict newMap):
+def backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
+             dict oldMap, dict newMap):
     '''
     Backfilling logic for generating fill vector
 
@@ -41,8 +28,7 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
     '''
     cdef int i, j, oldLength, newLength, curLoc
     # Make empty vectors
-    cdef ndarray[int32_t, ndim=1] fillVec
-    cdef ndarray[int8_t, ndim=1] mask
+    cdef ndarray[int32_t, ndim=1] fill_vec
     cdef int newPos, oldPos
     cdef object prevOld, curOld
 
@@ -50,10 +36,8 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
     oldLength = len(oldIndex)
     newLength = len(newIndex)
 
-    fillVec = np.empty(len(newIndex), dtype = np.int32)
-    fillVec.fill(-1)
-
-    mask = np.zeros(len(newIndex), dtype = np.int8)
+    fill_vec = np.empty(len(newIndex), dtype = np.int32)
+    fill_vec.fill(-1)
 
     # Current positions
     oldPos = oldLength - 1
@@ -61,7 +45,7 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
 
     # corner case, no filling possible
     if newIndex[0] > oldIndex[oldLength - 1]:
-        return fillVec, mask
+        return fill_vec
 
     while newPos >= 0:
         curOld = oldIndex[oldPos]
@@ -79,8 +63,7 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
         if oldPos == 0:
             # Make sure we are before the curOld index
             if newIndex[newPos] <= curOld:
-                fillVec[:newPos + 1] = curLoc
-                mask[:newPos + 1] = 1
+                fill_vec[:newPos + 1] = curLoc
             # Exit the main loop
             break
         else:
@@ -90,8 +73,7 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
             # Until we reach the previous index
             while newIndex[newPos] > prevOld:
                 # Set the current fill location
-                fillVec[newPos] = curLoc
-                mask[newPos] = 1
+                fill_vec[newPos] = curLoc
 
                 newPos -= 1
                 if newPos < 0:
@@ -100,11 +82,12 @@ def _backfill(ndarray[object] oldIndex, ndarray[object] newIndex,
         # Move one period back
         oldPos -= 1
 
-    return (fillVec, mask)
+    return fill_vec
 
+@cython.boundscheck(False)
 @cython.wraparound(False)
-def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
-         dict oldMap, dict newMap):
+def pad(ndarray[object] oldIndex, ndarray[object] newIndex,
+        dict oldMap, dict newMap):
     '''
     Padding logic for generating fill vector
 
@@ -128,8 +111,7 @@ def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
     '''
     cdef int i, j, oldLength, newLength, curLoc
     # Make empty vectors
-    cdef ndarray[int32_t, ndim=1] fillVec
-    cdef ndarray[int8_t, ndim=1] mask
+    cdef ndarray[int32_t, ndim=1] fill_vec
     cdef int newPos, oldPos
     cdef object prevOld, curOld
 
@@ -137,17 +119,15 @@ def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
     oldLength = len(oldIndex)
     newLength = len(newIndex)
 
-    fillVec = np.empty(len(newIndex), dtype = np.int32)
-    fillVec.fill(-1)
-
-    mask = np.zeros(len(newIndex), dtype = np.int8)
+    fill_vec = np.empty(len(newIndex), dtype = np.int32)
+    fill_vec.fill(-1)
 
     oldPos = 0
     newPos = 0
 
     # corner case, no filling possible
     if newIndex[newLength - 1] < oldIndex[0]:
-        return fillVec, mask
+        return fill_vec
 
     while newPos < newLength:
         curOld = oldIndex[oldPos]
@@ -165,8 +145,7 @@ def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
         # We're at the end of the road, need to propagate this value to the end
         if oldPos == oldLength - 1:
             if newIndex[newPos] >= curOld:
-                fillVec[newPos:] = curLoc
-                mask[newPos:] = 1
+                fill_vec[newPos:] = curLoc
             break
         else:
             # Not at the end, need to go about filling
@@ -179,10 +158,7 @@ def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
             # Until we reach the next OLD value in the NEW index
             while newIndex[newPos] < nextOld:
                 # Use this location to fill
-                fillVec[newPos] = curLoc
-
-                # Set mask to be 1 so will not be NaN'd
-                mask[newPos] = 1
+                fill_vec[newPos] = curLoc
                 newPos += 1
 
                 # We got to the end of the new index
@@ -198,7 +174,7 @@ def _pad(ndarray[object] oldIndex, ndarray[object] newIndex,
         # inc the count
         oldPos += 1
 
-    return fillVec, mask
+    return fill_vec
 
 def pad_inplace_float64(ndarray[float64_t] values,
                         ndarray[np.uint8_t, cast=True] mask):
@@ -289,30 +265,26 @@ def backfill_inplace_float64(ndarray[float64_t] values,
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def getMergeVec(ndarray[object] values, dict oldMap):
+def merge_indexer(ndarray[object] values, dict oldMap):
     cdef int i, j, length, newLength
     cdef object idx
-    cdef ndarray[int32_t] fillVec
-    cdef ndarray[int8_t] mask
+    cdef ndarray[int32_t] fill_vec
 
     newLength = len(values)
-    fillVec = np.empty(newLength, dtype=np.int32)
+    fill_vec = np.empty(newLength, dtype=np.int32)
     mask = np.zeros(newLength, dtype=np.int8)
     for i from 0 <= i < newLength:
         idx = values[i]
         if idx in oldMap:
-            fillVec[i] = oldMap[idx]
-            mask[i] = 1
-
-    for i from 0 <= i < newLength:
-        if mask[i] == 0:
-            fillVec[i] = -1
+            fill_vec[i] = oldMap[idx]
+        else:
+            fill_vec[i] = -1
 
-    return fillVec, mask.astype(bool)
+    return fill_vec
 
 def ordered_left_join(ndarray[object] left, ndarray[object] right):
     # cdef dict right_map = map_indices_buf(right)
-    # return getMergeVec(left, right_map)
+    # return merge_indexer(left, right_map)
     cdef:
         Py_ssize_t i, j, k, n
         ndarray[int32_t] indexer
@@ -708,8 +680,8 @@ def take_axis1(ndarray[float64_t, ndim=2] values,
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def take_1d(ndarray[float64_t] values, ndarray[int32_t] indexer,
-            out=None):
+def take_1d_float64(ndarray[float64_t] values, ndarray[int32_t] indexer,
+                    out=None):
     cdef:
         Py_ssize_t i, n, idx
         ndarray[float64_t] outbuf
@@ -728,6 +700,97 @@ def take_1d(ndarray[float64_t] values, ndarray[int32_t] indexer,
         else:
             outbuf[i] = values[idx]
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def take_1d_object(ndarray[object] values, ndarray[int32_t] indexer,
+                   out=None):
+    cdef:
+        Py_ssize_t i, n, idx
+        ndarray[object] outbuf
+        object nan
+
+    nan = np.nan
+
+    n = len(indexer)
+
+    if out is None:
+        outbuf = np.empty(n, dtype=values.dtype)
+    else:
+        outbuf = out
+
+    for i from 0 <= i < n:
+        idx = indexer[i]
+        if idx == -1:
+            outbuf[i] = nan
+        else:
+            outbuf[i] = values[idx]
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def take_1d_int32(ndarray[int32_t] values, ndarray[int32_t] indexer,
+                  out=None):
+    cdef:
+        Py_ssize_t i, n, idx
+        ndarray[int32_t] outbuf
+
+    n = len(indexer)
+
+    if out is None:
+        outbuf = np.empty(n, dtype=values.dtype)
+    else:
+        outbuf = out
+
+    for i from 0 <= i < n:
+        idx = indexer[i]
+        if idx == -1:
+            raise ValueError('No NA values allowed')
+        else:
+            outbuf[i] = values[idx]
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def take_1d_int64(ndarray[int64_t] values, ndarray[int32_t] indexer,
+                  out=None):
+    cdef:
+        Py_ssize_t i, n, idx
+        ndarray[int64_t] outbuf
+
+    n = len(indexer)
+
+    if out is None:
+        outbuf = np.empty(n, dtype=values.dtype)
+    else:
+        outbuf = out
+
+    for i from 0 <= i < n:
+        idx = indexer[i]
+        if idx == -1:
+            raise ValueError('No NA values allowed')
+        else:
+            outbuf[i] = values[idx]
+
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def take_1d_bool(ndarray[uint8_t] values, ndarray[int32_t] indexer,
+                 out=None):
+    cdef:
+        Py_ssize_t i, n, idx
+        ndarray[uint8_t] outbuf
+
+    n = len(indexer)
+
+    if out is None:
+        outbuf = np.empty(n, dtype=values.dtype)
+    else:
+        outbuf = out
+
+    for i from 0 <= i < n:
+        idx = indexer[i]
+        if idx == -1:
+            raise ValueError('No NA values allowed')
+        else:
+            outbuf[i] = values[idx]
+
 def ordered_put_indexer(ndarray[int64_t] left, ndarray[int64_t] right,
                         ndarray[float64_t, ndim=2] lvalues,
                         ndarray[float64_t, ndim=2] rvalues,
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index cf7f141f0..f3bb75d99 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -255,25 +255,20 @@ class TestIndex(unittest.TestCase):
         idx1 = Index([1, 2, 3, 4, 5])
         idx2 = Index([2, 4, 6])
 
-        r1, r2 = idx1.get_indexer(idx2)
+        r1 = idx1.get_indexer(idx2)
         assert_almost_equal(r1, [1, 3, -1])
-        assert_almost_equal(r2, [True, True, False])
 
-        r1, r2 = idx2.get_indexer(idx1, method='pad')
+        r1 = idx2.get_indexer(idx1, method='pad')
         assert_almost_equal(r1, [-1, 0, 0, 1, 1])
-        assert_almost_equal(r2, [False, True, True, True, True])
 
-        rffill1, rffill2 = idx2.get_indexer(idx1, method='ffill')
+        rffill1 = idx2.get_indexer(idx1, method='ffill')
         assert_almost_equal(r1, rffill1)
-        assert_almost_equal(r2, rffill2)
 
-        r1, r2 = idx2.get_indexer(idx1, method='backfill')
+        r1 = idx2.get_indexer(idx1, method='backfill')
         assert_almost_equal(r1, [0, 0, 1, 1, 2])
-        assert_almost_equal(r2, [True, True, True, True, True])
 
-        rbfill1, rbfill2 = idx2.get_indexer(idx1, method='bfill')
+        rbfill1 = idx2.get_indexer(idx1, method='bfill')
         assert_almost_equal(r1, rbfill1)
-        assert_almost_equal(r2, rbfill2)
 
     def test_slice_locs(self):
         idx = Index([0, 1, 2, 5, 6, 7, 9, 10])
@@ -526,31 +521,25 @@ class TestMultiIndex(unittest.TestCase):
         idx1 = index[:5]
         idx2 = index[[1,3,5]]
 
-        r1, r2 = idx1.get_indexer(idx2)
+        r1 = idx1.get_indexer(idx2)
         assert_almost_equal(r1, [1, 3, -1])
-        assert_almost_equal(r2, [True, True, False])
 
-        r1, r2 = idx2.get_indexer(idx1, method='pad')
+        r1 = idx2.get_indexer(idx1, method='pad')
         assert_almost_equal(r1, [-1, 0, 0, 1, 1])
-        assert_almost_equal(r2, [False, True, True, True, True])
 
-        rffill1, rffill2 = idx2.get_indexer(idx1, method='ffill')
+        rffill1 = idx2.get_indexer(idx1, method='ffill')
         assert_almost_equal(r1, rffill1)
-        assert_almost_equal(r2, rffill2)
 
-        r1, r2 = idx2.get_indexer(idx1, method='backfill')
+        r1 = idx2.get_indexer(idx1, method='backfill')
         assert_almost_equal(r1, [0, 0, 1, 1, 2])
-        assert_almost_equal(r2, [True, True, True, True, True])
 
-        rbfill1, rbfill2 = idx2.get_indexer(idx1, method='bfill')
+        rbfill1 = idx2.get_indexer(idx1, method='bfill')
         assert_almost_equal(r1, rbfill1)
-        assert_almost_equal(r2, rbfill2)
 
         # pass non-MultiIndex
-        r1, r2 = idx1.get_indexer(idx2.get_tuple_index())
-        rexp1, rexp2 = idx1.get_indexer(idx2)
+        r1 = idx1.get_indexer(idx2.get_tuple_index())
+        rexp1 = idx1.get_indexer(idx2)
         assert_almost_equal(r1, rexp1)
-        assert_almost_equal(r2, rexp2)
 
         self.assertRaises(Exception, idx1.get_indexer,
                           list(zip(*idx2.get_tuple_index())[0]))
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 73227e624..ff6cabd28 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -23,80 +23,54 @@ class TestTseriesUtil(unittest.TestCase):
     def test_groupby_withnull(self):
         pass
 
-    def test_getMergeVec(self):
+    def test_merge_indexer(self):
         old = Index([1, 5, 10])
         new = Index(range(12))
 
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, None)
+        filler = lib.merge_indexer(new, old.indexMap)
 
         expect_filler = [-1, 0, -1, -1, -1, 1, -1, -1, -1, -1, 2, -1]
-        expect_mask = np.zeros(12, dtype=bool)
-        expect_mask[[1, 5, 10]] = True
-
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
         # corner case
         old = Index([1, 4])
         new = Index(range(5, 10))
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, None)
-
+        filler = lib.merge_indexer(new, old.indexMap)
         expect_filler = [-1, -1, -1, -1, -1]
-        expect_mask = np.zeros(5, dtype=bool)
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
     def test_backfill(self):
         old = Index([1, 5, 10])
         new = Index(range(12))
 
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, 'BACKFILL')
+        filler = lib.backfill(old, new, old.indexMap, new.indexMap)
 
         expect_filler = [0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 2, -1]
-        expect_mask = np.ones(12, dtype=bool)
-        expect_mask[-1] = False
-
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
         # corner case
         old = Index([1, 4])
         new = Index(range(5, 10))
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, 'BACKFILL')
+        filler = lib.backfill(old, new, old.indexMap, new.indexMap)
 
         expect_filler = [-1, -1, -1, -1, -1]
-        expect_mask = np.zeros(5, dtype=bool)
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
     def test_pad(self):
         old = Index([1, 5, 10])
         new = Index(range(12))
 
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, 'PAD')
+        filler = lib.pad(old, new, old.indexMap, new.indexMap)
 
         expect_filler = [-1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2]
-        expect_mask = np.ones(12, dtype=bool)
-        expect_mask[0] = False
-
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
         # corner case
         old = Index([5, 10])
         new = Index(range(5))
-        filler, mask = lib.getFillVec(old, new, old.indexMap,
-                                          new.indexMap, 'PAD')
-
+        filler = lib.pad(old, new, old.indexMap, new.indexMap)
         expect_filler = [-1, -1, -1, -1, -1]
-        expect_mask = np.zeros(5, dtype=bool)
         self.assert_(np.array_equal(filler, expect_filler))
-        self.assert_(np.array_equal(mask, expect_mask))
 
 def test_inner_join_indexer():
     a = np.array([1, 2, 3, 4, 5], dtype=np.int64)
