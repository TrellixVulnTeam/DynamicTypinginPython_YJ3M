commit 2e5953b5c4d847af592be94403f5b27f1a809049
Author: jreback <jeff@reback.net>
Date:   Thu Mar 7 18:23:47 2013 -0500

    DOC: doc updates/formatting in basics,indexing,10min

diff --git a/doc/source/10min.rst b/doc/source/10min.rst
index a6945eed1..e38bb52ff 100644
--- a/doc/source/10min.rst
+++ b/doc/source/10min.rst
@@ -126,11 +126,11 @@ See the :ref:`Indexing section <indexing>`
 Getting
 ~~~~~~~
 
-Selecting a single column, which yields a ``Series``
+Selecting a single column, which yields a ``Series``,
+equivalent to ``df.A``
 
 .. ipython:: python
 
-   # equivalently ``df.A``
    df['A']
 
 Selecting via ``[]``, which slices the rows.
@@ -143,6 +143,8 @@ Selecting via ``[]``, which slices the rows.
 Selection by Label
 ~~~~~~~~~~~~~~~~~~
 
+See more in :ref:`Selection by Label <indexing.label>`
+
 For getting a cross section using a label
 
 .. ipython:: python
@@ -182,6 +184,8 @@ For getting fast access to a scalar (equiv to the prior method)
 Selection by Position
 ~~~~~~~~~~~~~~~~~~~~~
 
+See more in :ref:`Selection by Position <indexing.integer>`
+
 Select via the position of the passed integers
 
 .. ipython:: python
@@ -286,6 +290,11 @@ Setting by assigning with a numpy array
 .. ipython:: python
 
    df.loc[:,'D'] = np.array([5] * len(df))
+
+The result of the prior setting operations
+
+.. ipython:: python
+
    df
 
 A ``where`` operation with setting.
@@ -517,7 +526,7 @@ unstacks the **last level**:
 
 Pivot Tables
 ~~~~~~~~~~~~
-See the section on :ref:`Pivot Tables <reshaping.pivot>`).
+See the section on :ref:`Pivot Tables <reshaping.pivot>`.
 
 .. ipython:: python
 
diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index d32cbf7dc..2b89d5e0b 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -989,7 +989,10 @@ attribute for DataFrames returns a Series with the data type of each column.
 
 .. ipython:: python
 
-   dft = DataFrame(dict( A = np.random.rand(3), B = 1, C = 'foo', D = Timestamp('20010102'), 
+   dft = DataFrame(dict( A = np.random.rand(3), 
+                         B = 1, 
+                         C = 'foo', 
+                         D = Timestamp('20010102'), 
                          E = Series([1.0]*3).astype('float32'), 
 			 F = False,
 			 G = Series([1]*3,dtype='int8')))
@@ -1014,8 +1017,8 @@ general).
    # string data forces an ``object`` dtype
    Series([1, 2, 3, 6., 'foo'])
 
-The related method ``get_dtype_counts`` will return the number of columns of
-each type:
+The method ``get_dtype_counts`` will return the number of columns of
+each type in a ``DataFrame``:
 
 .. ipython:: python
 
@@ -1023,7 +1026,8 @@ each type:
 
 Numeric dtypes will propagate and can coexist in DataFrames (starting in v0.11.0). 
 If a dtype is passed (either directly via the ``dtype`` keyword, a passed ``ndarray``, 
-or a passed ``Series``, then it will be preserved in DataFrame operations. Furthermore, different numeric dtypes will **NOT** be combined. The following example will give you a taste.
+or a passed ``Series``, then it will be preserved in DataFrame operations. Furthermore, 
+different numeric dtypes will **NOT** be combined. The following example will give you a taste.
 
 .. ipython:: python
 
@@ -1039,9 +1043,8 @@ or a passed ``Series``, then it will be preserved in DataFrame operations. Furth
 defaults
 ~~~~~~~~
 
-By default integer types are ``int64`` and float types are ``float64``, *REGARDLESS* of platform (32-bit or 64-bit).
-
-The following will all result in ``int64`` dtypes.
+By default integer types are ``int64`` and float types are ``float64``, 
+*REGARDLESS* of platform (32-bit or 64-bit). The following will all result in ``int64`` dtypes.
 
 .. ipython:: python
 
@@ -1050,13 +1053,18 @@ The following will all result in ``int64`` dtypes.
     DataFrame({'a' : 1 }, index=range(2)).dtypes
 
 Numpy, however will choose *platform-dependent* types when creating arrays.
-Thus, ``DataFrame(np.array([1,2]))`` **WILL** result in ``int32`` on 32-bit platform.
+The following **WILL** result in ``int32`` on 32-bit platform.
+
+.. ipython:: python
+
+    frame = DataFrame(np.array([1,2]))
 
 
 upcasting
 ~~~~~~~~~
 
-Types can potentially be *upcasted* when combined with other types, meaning they are promoted from the current type (say ``int`` to ``float``)
+Types can potentially be *upcasted* when combined with other types, meaning they are promoted 
+from the current type (say ``int`` to ``float``)
 
 .. ipython:: python
 
@@ -1064,7 +1072,8 @@ Types can potentially be *upcasted* when combined with other types, meaning they
    df3
    df3.dtypes
 
-The ``values`` attribute on a DataFrame return the *lower-common-denominator* of the dtypes, meaning the dtype that can accomodate **ALL** of the types in the resulting homogenous dtyped numpy array. This can 
+The ``values`` attribute on a DataFrame return the *lower-common-denominator* of the dtypes, meaning 
+the dtype that can accomodate **ALL** of the types in the resulting homogenous dtyped numpy array. This can 
 force some *upcasting*.
 
 .. ipython:: python
@@ -1076,7 +1085,10 @@ astype
 
 .. _basics.cast:
 
-You can use the ``astype`` method to convert dtypes from one to another. These *always* return a copy. 
+You can use the ``astype`` method to explicity convert dtypes from one to another. These will by default return a copy,
+even if the dtype was unchanged (pass ``copy=False`` to change this behavior). In addition, they will raise an
+exception if the astype operation is invalid.
+
 Upcasting is always according to the **numpy** rules. If two different dtypes are involved in an operation, 
 then the more *general* one will be used as the result of the operation.
 
@@ -1091,17 +1103,13 @@ then the more *general* one will be used as the result of the operation.
 object conversion
 ~~~~~~~~~~~~~~~~~
 
-To force conversion of specific types of number conversion, pass ``convert_numeric = True``. 
-This will force strings and numbers alike to be numbers if possible, otherwise the will be set to ``np.nan``.
-To force conversion to ``datetime64[ns]``, pass ``convert_dates = 'coerce'``. 
-This will convert any datetimelike object to dates, forcing other values to ``NaT``.
-
-In addition, ``convert_objects`` will attempt to *soft* conversion of any *object* dtypes, meaning that if all 
-the objects in a Series are of the same type, the Series will have that dtype.
+``convert_objects`` is a method to try to force conversion of types from the ``object`` dtype to other types.
+To force conversion of specific types that are *number like*, e.g. could be a string that represents a number,
+pass ``convert_numeric=True``. This will force strings and numbers alike to be numbers if possible, otherwise 
+they will be set to ``np.nan``.
 
 .. ipython:: python
 
-   # mixed type conversions
    df3['D'] = '1.'
    df3['E'] = '1'
    df3.convert_objects(convert_numeric=True).dtypes
@@ -1111,14 +1119,21 @@ the objects in a Series are of the same type, the Series will have that dtype.
    df3['E'] = df3['E'].astype('int32')
    df3.dtypes
 
-This is a *forced coercion* on datelike types. This might be useful if you are reading in data which is mostly dates, but occasionally has non-dates intermixed and you want to make those values ``nan``.
+To force conversion to ``datetime64[ns]``, pass ``convert_dates='coerce'``. 
+This will convert any datetimelike object to dates, forcing other values to ``NaT``.
+This might be useful if you are reading in data which is mostly dates,
+but occasionally has non-dates intermixed and you want to represent as missing.
 
 .. ipython:: python
 
-   s = Series([datetime(2001,1,1,0,0), 'foo', 1.0, 1, Timestamp('20010104'), '20010105'],dtype='O')
+   s = Series([datetime(2001,1,1,0,0), 
+              'foo', 1.0, 1, Timestamp('20010104'), 
+              '20010105'],dtype='O')
    s
    s.convert_objects(convert_dates='coerce')
 
+In addition, ``convert_objects`` will attempt the *soft* conversion of any *object* dtypes, meaning that if all 
+the objects in a Series are of the same type, the Series will have that dtype.
 
 gotchas
 ~~~~~~~
diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 02aa00b7e..392768a21 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -75,7 +75,7 @@ three types of multi-axis indexing.
 
     See more at :ref:`Advanced Indexing <indexing.advanced>` and :ref:`Advanced Hierarchical <indexing.advanced_hierarchical>`
 
-Getting values from object with multi-axes uses the following notation (using ``.loc`` as an 
+Getting values from an object with multi-axes selection uses the following notation (using ``.loc`` as an 
 example, but applies to ``.iloc`` and ``.ix`` as well) Any of the axes accessors may be the null 
 slice ``:``. Axes left out of the specification are assumed to be ``:``.
 (e.g. ``p.loc['a']`` is equiv to ``p.loc['a',:,:]``)
@@ -103,13 +103,11 @@ See the section :ref:`Selection by Position <indexing.integer>` for substitutes.
 .. _indexing.xs:
 
 Cross-sectional slices on non-hierarchical indices are now easily performed using
-``.loc`` and/or ``.loc``. The methods:
+``.loc`` and/or ``.loc``. These methods now exist primarily for backward compatibility.
 
   - ``xs`` (for DataFrame),
   - ``minor_xs`` and ``major_xs`` (for Panel)
 
-now exist primarily for backward compatibility.
-
 See the section at :ref:`Selection by Label <indexing.label>` for substitutes.
 
 .. _indexing.basics:
@@ -230,9 +228,7 @@ must be in the index or a ``KeyError`` will be raised!
 When slicing, the start bound is *included*, **AND** the stop bound is *included*.
 Integers are valid labels, but they refer to the label *and not the position*.
 
-The ``.loc`` attribute is the primary access method.
-
-The following are valid inputs:
+The ``.loc`` attribute is the primary access method. The following are valid inputs:
 
     - A single label, e.g. ``5`` or ``'a'``
 
@@ -261,7 +257,9 @@ With a DataFrame
 
 .. ipython:: python
 
-   df1 = DataFrame(np.random.randn(6,4),index=list('abcdef'),columns=list('ABCD'))
+   df1 = DataFrame(np.random.randn(6,4),
+                   index=list('abcdef'),
+                   columns=list('ABCD'))
    df1
    df1.loc[['a','b','d'],:]
 
@@ -302,9 +300,7 @@ The semantics follow closely python and numpy slicing. These are ``0-based`` ind
 When slicing, the start bounds is *included*, while the upper bound is *excluded*.
 Trying to use a non-integer, even a **valid** label will raise a ``IndexError``.
 
-The ``.iloc`` attribute is the primary access method .
-
-The following are valid inputs:
+The ``.iloc`` attribute is the primary access method. The following are valid inputs:
 
    - An integer e.g. ``5``
    - A list or array of integers ``[4, 3, 0]``
@@ -329,7 +325,9 @@ With a DataFrame
 
 .. ipython:: python
 
-   df1 = DataFrame(np.random.randn(6,4),index=range(0,12,2),columns=range(0,8,2))
+   df1 = DataFrame(np.random.randn(6,4),
+                   index=range(0,12,2),
+                   columns=range(0,8,2))
    df1
 
 Select via integer slicing
@@ -428,6 +426,8 @@ Boolean indexing
 .. _indexing.boolean:
 
 Another common operation is the use of boolean vectors to filter the data.
+The operators are: ``|`` for ``or``, ``&`` for ``and``, and ``~`` for ``not``.
+These are grouped using parentheses.
 
 Using a boolean vector to index a Series works exactly as in a numpy ndarray:
 
@@ -436,6 +436,7 @@ Using a boolean vector to index a Series works exactly as in a numpy ndarray:
    s[s > 0]
    s[(s < 0) & (s > -0.5)]
    s[(s < -1) | (s > 1 )]
+   s[~(s < 0)]
 
 You may select rows from a DataFrame using a boolean vector the same length as
 the DataFrame's index (for example, something derived from one of the columns
@@ -472,11 +473,15 @@ more complex criteria:
    # Multiple criteria
    df2[criterion & (df2['b'] == 'x')]
 
-
 Note, with the choice methods :ref:`Selection by Label <indexing.label>`, :ref:`Selection by Position <indexing.integer>`,
-and :ref:`Advanced Indexing <indexing.advanced>` may select along more than one axis using boolean vectors combined with other
+and :ref:`Advanced Indexing <indexing.advanced>` you may select along more than one axis using boolean vectors combined with other
 indexing expressions.
 
+.. ipython:: python
+
+   df2.loc[criterion & (df2['b'] == 'x'),'b':'c']
+  
+
 Where and Masking
 ~~~~~~~~~~~~~~~~~
 
@@ -484,21 +489,24 @@ Selecting values from a Series with a boolean vector generally returns a subset
 To guarantee that selection output has the same shape as the original data, you can use the
 ``where`` method in ``Series`` and ``DataFrame``.
 
+
+To return only the selected rows
+
 .. ipython:: python
 
-   # return only the selected rows
    s[s > 0]
 
-   # return a Series of the same shape as the original
+To return a Series of the same shape as the original
+
+.. ipython:: python
+
    s.where(s > 0)
 
 Selecting values from a DataFrame with a boolean critierion now also preserves input data shape.
-``where`` is used under the hood as the implementation.
+``where`` is used under the hood as the implementation. Equivalent is ``df.where(df < 0)``
 
 .. ipython:: python
 
-   # return a DataFrame of the same shape as the original
-   # this is equiavalent to ``df.where(df < 0)``
    df[df < 0]
 
 In addition, ``where`` takes an optional ``other`` argument for replacement of values where the
@@ -665,7 +673,7 @@ Advanced Indexing with ``.ix``
 
    The recent addition of ``.loc`` and ``.iloc`` have enabled users to be quite
    explicit about indexing choices. ``.ix`` allows a great flexibility to specify
-   indexing locations by *label* an/or *integer position*. Pandas will attempt
+   indexing locations by *label* and/or *integer position*. Pandas will attempt
    to use any passed *integer* as *label* locations first (like what ``.loc``
    would do, then to fall back on *positional* indexing, like what ``.iloc`` would do).
 
diff --git a/doc/source/v0.11.0.txt b/doc/source/v0.11.0.txt
index ea174629c..cd7540328 100644
--- a/doc/source/v0.11.0.txt
+++ b/doc/source/v0.11.0.txt
@@ -12,9 +12,6 @@ pay close attention to.
 There is a new section in the documentation, :ref:`10 Minutes to Pandas <10min>`,
 primarily geared to new users.
 
-API changes
-~~~~~~~~~~~
-
 Selection Choices
 ~~~~~~~~~~~~~~~~~
 
@@ -62,7 +59,7 @@ three types of multi-axis indexing.
 Selection Deprecations
 ~~~~~~~~~~~~~~~~~~~~~~
 
-Starting in version 0.11.0, the methods may be deprecated in future versions.
+Starting in version 0.11.0, these methods may be deprecated in future versions.
 
   - ``irow``
   - ``icol``
@@ -90,7 +87,9 @@ Numeric dtypes will propagate and can coexist in DataFrames. If a dtype is passe
    df1 = DataFrame(randn(8, 1), columns = ['A'], dtype = 'float32')
    df1
    df1.dtypes
-   df2 = DataFrame(dict( A = Series(randn(8),dtype='float16'), B = Series(randn(8)), C = Series(randn(8),dtype='uint8') ))
+   df2 = DataFrame(dict( A = Series(randn(8),dtype='float16'), 
+                         B = Series(randn(8)), 
+                         C = Series(randn(8),dtype='uint8') ))
    df2
    df2.dtypes
 
@@ -102,15 +101,22 @@ Numeric dtypes will propagate and can coexist in DataFrames. If a dtype is passe
 Dtype Conversion
 ~~~~~~~~~~~~~~~~
 
+This is lower-common-denomicator upcasting, meaning you get the dtype which can accomodate all of the types
+
 .. ipython:: python
 
-   # this is lower-common-denomicator upcasting (meaning you get the dtype which can accomodate all of the types)
    df3.values.dtype
 
-   # conversion of dtypes
+Conversion
+
+.. ipython:: python
+
    df3.astype('float32').dtypes
 
-   # mixed type conversions
+Mixed Conversion
+
+.. ipython:: python
+
    df3['D'] = '1.'
    df3['E'] = '1'
    df3.convert_objects(convert_numeric=True).dtypes
@@ -120,7 +126,10 @@ Dtype Conversion
    df3['E'] = df3['E'].astype('int32')
    df3.dtypes
 
-   # forcing date coercion
+Forcing Date coercion (and setting ``NaT`` when not datelike)
+
+.. ipython:: python
+
    s = Series([datetime(2001,1,1,0,0), 'foo', 1.0, 1,
                Timestamp('20010104'), '20010105'],dtype='O')
    s.convert_objects(convert_dates='coerce')
@@ -148,7 +157,7 @@ Keep in mind that ``DataFrame(np.array([1,2]))`` **WILL** result in ``int32`` on
 **Upcasting Gotchas**
 
 Performing indexing operations on integer type data can easily upcast the data.
-The dtype of the input data will be preserved in cases where ``nans`` are not introduced (coming soon).
+The dtype of the input data will be preserved in cases where ``nans`` are not introduced.
 
 .. ipython:: python
 
@@ -209,11 +218,14 @@ Astype conversion on ``datetime64[ns]`` to ``object``, implicity converts ``NaT`
    s.dtype
 
 
+API changes
+~~~~~~~~~~~
+
 Enhancements
 ~~~~~~~~~~~~
 
   - In ``HDFStore``, provide dotted attribute access to ``get`` from stores
-    (e.g. store.df == store['df'])
+    (e.g. ``store.df == store['df']``)
 
   - ``Squeeze`` to possibly remove length 1 dimensions from an object.
 
