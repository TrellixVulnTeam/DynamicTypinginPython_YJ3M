commit c72b02fc44c8e41ff9f694fe27edb5f9b52ecd6d
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Fri Nov 2 06:31:36 2018 -0700

    REF: cython cleanup, typing, optimizations (#23456)

diff --git a/pandas/_libs/algos_common_helper.pxi.in b/pandas/_libs/algos_common_helper.pxi.in
index 518664d70..2835c95c9 100644
--- a/pandas/_libs/algos_common_helper.pxi.in
+++ b/pandas/_libs/algos_common_helper.pxi.in
@@ -1,16 +1,6 @@
 """
 Template for each `dtype` helper function using 1-d template
 
-# 1-d template
-- pad
-- pad_1d
-- pad_2d
-- backfill
-- backfill_1d
-- backfill_2d
-- is_monotonic
-- arrmap
-
 WARNING: DO NOT edit .pxi FILE directly, .pxi is generated from .pxi.in
 """
 
diff --git a/pandas/_libs/groupby_helper.pxi.in b/pandas/_libs/groupby_helper.pxi.in
index addbb2b3e..335c8ee5c 100644
--- a/pandas/_libs/groupby_helper.pxi.in
+++ b/pandas/_libs/groupby_helper.pxi.in
@@ -313,7 +313,7 @@ def group_last_{{name}}(ndarray[{{c_type}}, ndim=2] out,
         raise AssertionError("len(index) != len(labels)")
 
     nobs = np.zeros((<object> out).shape, dtype=np.int64)
-    {{if name=='object'}}
+    {{if name == 'object'}}
     resx = np.empty((<object> out).shape, dtype=object)
     {{else}}
     resx = np.empty_like(out)
diff --git a/pandas/_libs/hashtable.pyx b/pandas/_libs/hashtable.pyx
index 2ced98198..d38b72cce 100644
--- a/pandas/_libs/hashtable.pyx
+++ b/pandas/_libs/hashtable.pyx
@@ -2,10 +2,8 @@
 
 cimport cython
 
-from cpython cimport (PyObject, Py_INCREF, PyList_Check, PyTuple_Check,
-                      PyMem_Malloc, PyMem_Realloc, PyMem_Free,
-                      PyString_Check, PyBytes_Check,
-                      PyUnicode_Check)
+from cpython cimport (PyObject, Py_INCREF,
+                      PyMem_Malloc, PyMem_Realloc, PyMem_Free)
 
 from libc.stdlib cimport malloc, free
 
@@ -153,7 +151,7 @@ def unique_label_indices(ndarray[int64_t, ndim=1] labels):
     cdef:
         int ret = 0
         Py_ssize_t i, n = len(labels)
-        kh_int64_t * table = kh_init_int64()
+        kh_int64_t *table = kh_init_int64()
         Int64Vector idx = Int64Vector()
         ndarray[int64_t, ndim=1] arr
         Int64VectorData *ud = idx.data
diff --git a/pandas/_libs/hashtable_class_helper.pxi.in b/pandas/_libs/hashtable_class_helper.pxi.in
index c061102fb..27758234c 100644
--- a/pandas/_libs/hashtable_class_helper.pxi.in
+++ b/pandas/_libs/hashtable_class_helper.pxi.in
@@ -5,9 +5,9 @@ WARNING: DO NOT edit .pxi FILE directly, .pxi is generated from .pxi.in
 """
 
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # VectorData
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 {{py:
 
@@ -53,9 +53,9 @@ ctypedef fused vector_data:
 cdef inline bint needs_resize(vector_data *data) nogil:
     return data.n == data.m
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # Vector
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 {{py:
 
@@ -134,8 +134,7 @@ cdef class StringVector:
         bint external_view_exists
 
     def __cinit__(self):
-        self.data = <StringVectorData *>PyMem_Malloc(
-            sizeof(StringVectorData))
+        self.data = <StringVectorData *>PyMem_Malloc(sizeof(StringVectorData))
         if not self.data:
             raise MemoryError()
         self.external_view_exists = False
@@ -184,7 +183,7 @@ cdef class StringVector:
         self.data.m = self.data.n
         return ao
 
-    cdef inline void append(self, char * x):
+    cdef inline void append(self, char *x):
 
         if needs_resize(self.data):
             self.resize()
@@ -240,9 +239,9 @@ cdef class ObjectVector:
         for i in range(len(x)):
             self.append(x[i])
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # HashTable
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 
 cdef class HashTable:
@@ -283,9 +282,9 @@ cdef class {{name}}HashTable(HashTable):
 
     def sizeof(self, deep=False):
         """ return the size of my table in bytes """
-        return self.table.n_buckets * (sizeof({{dtype}}_t) + # keys
-                                       sizeof(Py_ssize_t) + # vals
-                                       sizeof(uint32_t)) # flags
+        return self.table.n_buckets * (sizeof({{dtype}}_t) +  # keys
+                                       sizeof(Py_ssize_t) +  # vals
+                                       sizeof(uint32_t))  # flags
 
     cpdef get_item(self, {{dtype}}_t val):
         cdef khiter_t k
@@ -679,7 +678,7 @@ cdef class StringHashTable(HashTable):
         for i in range(n):
             val = values[i]
 
-            if PyUnicode_Check(val) or PyString_Check(val):
+            if isinstance(val, (str, unicode)):
                 v = util.get_c_string(val)
             else:
                 v = util.get_c_string(self.na_string_sentinel)
@@ -712,7 +711,7 @@ cdef class StringHashTable(HashTable):
         for i in range(n):
             val = values[i]
 
-            if PyUnicode_Check(val) or PyString_Check(val):
+            if isinstance(val, (str, unicode)):
                 v = util.get_c_string(val)
             else:
                 v = util.get_c_string(self.na_string_sentinel)
@@ -773,7 +772,7 @@ cdef class StringHashTable(HashTable):
         for i in range(n):
             val = values[i]
 
-            if ((PyUnicode_Check(val) or PyString_Check(val))
+            if (isinstance(val, (str, unicode))
                     and not (use_na_value and val == na_value)):
                 v = util.get_c_string(val)
                 vecs[i] = v
diff --git a/pandas/_libs/hashtable_func_helper.pxi.in b/pandas/_libs/hashtable_func_helper.pxi.in
index 3d35e7014..801c67832 100644
--- a/pandas/_libs/hashtable_func_helper.pxi.in
+++ b/pandas/_libs/hashtable_func_helper.pxi.in
@@ -4,9 +4,9 @@ Template for each `dtype` helper function for hashtable
 WARNING: DO NOT edit .pxi FILE directly, .pxi is generated from .pxi.in
 """
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # VectorData
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 {{py:
 
@@ -80,7 +80,7 @@ cpdef value_count_{{dtype}}(ndarray[{{dtype}}] values, bint dropna):
 cpdef value_count_{{dtype}}({{scalar}}[:] values, bint dropna):
 {{endif}}
     cdef:
-        Py_ssize_t i=0
+        Py_ssize_t i = 0
         kh_{{ttype}}_t *table
 
         {{if dtype != 'object'}}
@@ -141,7 +141,7 @@ def duplicated_{{dtype}}({{scalar}}[:] values, object keep='first'):
         {{dtype}}_t value
         {{endif}}
         Py_ssize_t k, i, n = len(values)
-        kh_{{ttype}}_t * table = kh_init_{{ttype}}()
+        kh_{{ttype}}_t *table = kh_init_{{ttype}}()
         ndarray[uint8_t, ndim=1, cast=True] out = np.empty(n, dtype='bool')
 
     kh_resize_{{ttype}}(table, min(n, _SIZE_HINT_LIMIT))
@@ -202,9 +202,9 @@ def duplicated_{{dtype}}({{scalar}}[:] values, object keep='first'):
     return out
 
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # Membership
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 
 @cython.wraparound(False)
@@ -237,7 +237,7 @@ def ismember_{{dtype}}({{scalar}}[:] arr, {{scalar}}[:] values):
         int ret = 0
         ndarray[uint8_t] result
         {{scalar}} val
-        kh_{{ttype}}_t * table = kh_init_{{ttype}}()
+        kh_{{ttype}}_t *table = kh_init_{{ttype}}()
 
     # construct the table
     n = len(values)
@@ -275,9 +275,9 @@ def ismember_{{dtype}}({{scalar}}[:] arr, {{scalar}}[:] values):
 {{endfor}}
 
 
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 # Mode Computations
-#----------------------------------------------------------------------
+# ----------------------------------------------------------------------
 
 {{py:
 
@@ -305,17 +305,13 @@ def mode_{{dtype}}({{ctype}}[:] values, bint dropna):
 {{endif}}
     cdef:
         int count, max_count = 1
-        int j = -1 # so you can do +=
+        int j = -1  # so you can do +=
         Py_ssize_t k
         kh_{{table_type}}_t *table
         ndarray[{{ctype}}] modes
 
     table = kh_init_{{table_type}}()
-    {{if dtype == 'object'}}
-    build_count_table_{{dtype}}(values, table, dropna)
-    {{else}}
     build_count_table_{{dtype}}(values, table, dropna)
-    {{endif}}
 
     modes = np.empty(table.n_buckets, dtype=np.{{npy_dtype}})
 
diff --git a/pandas/_libs/lib.pyx b/pandas/_libs/lib.pyx
index c5d5a431e..6ec9a7e93 100644
--- a/pandas/_libs/lib.pyx
+++ b/pandas/_libs/lib.pyx
@@ -473,6 +473,8 @@ def array_equivalent_object(left: object[:], right: object[:]) -> bint:
     return True
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def astype_intsafe(ndarray[object] arr, new_dtype):
     cdef:
         Py_ssize_t i, n = len(arr)
@@ -494,6 +496,8 @@ def astype_intsafe(ndarray[object] arr, new_dtype):
     return result
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def astype_unicode(arr: ndarray,
                    skipna: bool=False) -> ndarray[object]:
     """
@@ -528,6 +532,8 @@ def astype_unicode(arr: ndarray,
     return result
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def astype_str(arr: ndarray,
                skipna: bool=False) -> ndarray[object]:
     """
@@ -562,6 +568,8 @@ def astype_str(arr: ndarray,
     return result
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def clean_index_list(list obj):
     """
     Utility used in pandas.core.index.ensure_index
@@ -583,11 +591,9 @@ def clean_index_list(list obj):
 
     # don't force numpy coerce with nan's
     inferred = infer_dtype(obj)
-    if inferred in ['string', 'bytes', 'unicode',
-                    'mixed', 'mixed-integer']:
+    if inferred in ['string', 'bytes', 'unicode', 'mixed', 'mixed-integer']:
         return np.asarray(obj, dtype=object), 0
     elif inferred in ['integer']:
-
         # TODO: we infer an integer but it *could* be a unint64
         try:
             return np.asarray(obj, dtype='int64'), 0
diff --git a/pandas/_libs/missing.pxd b/pandas/_libs/missing.pxd
index 2c1f13eeb..9f660cc67 100644
--- a/pandas/_libs/missing.pxd
+++ b/pandas/_libs/missing.pxd
@@ -1,7 +1,5 @@
 # -*- coding: utf-8 -*-
 
-from tslibs.nattype cimport is_null_datetimelike
-
 cpdef bint checknull(object val)
 cpdef bint checknull_old(object val)
 
diff --git a/pandas/_libs/reduction.pyx b/pandas/_libs/reduction.pyx
index 681ea2c62..119060bd2 100644
--- a/pandas/_libs/reduction.pyx
+++ b/pandas/_libs/reduction.pyx
@@ -438,6 +438,7 @@ cdef inline _extract_result(object res):
                 res = res[0]
     return res
 
+
 cdef class Slider:
     """
     Only handles contiguous data for now
diff --git a/pandas/_libs/sparse.pyx b/pandas/_libs/sparse.pyx
index 6b6c44263..705d93da1 100644
--- a/pandas/_libs/sparse.pyx
+++ b/pandas/_libs/sparse.pyx
@@ -275,6 +275,7 @@ cdef class IntIndex(SparseIndex):
                ndarray[int32_t, ndim=1] indices):
         pass
 
+
 cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
     cdef:
         Py_ssize_t init_len, i, npoints, result_indexer = 0
@@ -315,6 +316,7 @@ cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
     lens = lens[:result_indexer]
     return locs, lens
 
+
 # -----------------------------------------------------------------------------
 # BlockIndex
 
@@ -670,12 +672,14 @@ cdef class BlockMerge(object):
             self.xi = yi
             self.yi = xi
 
+
 cdef class BlockIntersection(BlockMerge):
     """
     not done yet
     """
     pass
 
+
 cdef class BlockUnion(BlockMerge):
     """
     Object-oriented approach makes sharing state between recursive functions a
@@ -805,10 +809,11 @@ include "sparse_op_helper.pxi"
 # Indexing operations
 
 def get_reindexer(ndarray[object, ndim=1] values, dict index_map):
-    cdef object idx
-    cdef Py_ssize_t i
-    cdef Py_ssize_t new_length = len(values)
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef:
+        object idx
+        Py_ssize_t i
+        Py_ssize_t new_length = len(values)
+        ndarray[int32_t, ndim=1] indexer
 
     indexer = np.empty(new_length, dtype=np.int32)
 
@@ -861,10 +866,11 @@ def reindex_integer(ndarray[float64_t, ndim=1] values,
 # SparseArray mask create operations
 
 def make_mask_object_ndarray(ndarray[object, ndim=1] arr, object fill_value):
-    cdef object value
-    cdef Py_ssize_t i
-    cdef Py_ssize_t new_length = len(arr)
-    cdef ndarray[int8_t, ndim=1] mask
+    cdef:
+        object value
+        Py_ssize_t i
+        Py_ssize_t new_length = len(arr)
+        ndarray[int8_t, ndim=1] mask
 
     mask = np.ones(new_length, dtype=np.int8)
 
diff --git a/pandas/_libs/tslibs/conversion.pyx b/pandas/_libs/tslibs/conversion.pyx
index f9c604cd7..21d3250d0 100644
--- a/pandas/_libs/tslibs/conversion.pyx
+++ b/pandas/_libs/tslibs/conversion.pyx
@@ -49,10 +49,10 @@ TD_DTYPE = np.dtype('m8[ns]')
 
 UTC = pytz.UTC
 
+
 # ----------------------------------------------------------------------
 # Misc Helpers
 
-# TODO: How to declare np.datetime64 as the input type?
 cdef inline int64_t get_datetime64_nanos(object val) except? -1:
     """
     Extract the value and unit from a np.datetime64 object, then convert the
@@ -74,6 +74,8 @@ cdef inline int64_t get_datetime64_nanos(object val) except? -1:
     return ival
 
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
 def ensure_datetime64ns(ndarray arr, copy=True):
     """
     Ensure a np.datetime64 array has dtype specifically 'datetime64[ns]'
@@ -138,6 +140,8 @@ def ensure_timedelta64ns(ndarray arr, copy=True):
     return arr.astype(TD_DTYPE, copy=copy)
 
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
 def datetime_to_datetime64(object[:] values):
     """
     Convert ndarray of datetime-like objects to int64 array representing
@@ -145,11 +149,11 @@ def datetime_to_datetime64(object[:] values):
 
     Parameters
     ----------
-    values : ndarray
+    values : ndarray[object]
 
     Returns
     -------
-    result : ndarray with dtype int64
+    result : ndarray[int64_t]
     inferred_tz : tzinfo or None
     """
     cdef:
@@ -225,6 +229,7 @@ cdef class _TSObject:
 
     @property
     def value(self):
+        # This is needed in order for `value` to be accessible in lib.pyx
         return self.value
 
 
@@ -756,6 +761,8 @@ cpdef int64_t tz_convert_single(int64_t val, object tz1, object tz2):
         return _tz_convert_dst(arr, tz2, to_utc=False)[0]
 
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
 cdef inline int64_t[:] _tz_convert_one_way(int64_t[:] vals, object tz,
                                            bint to_utc):
     """
@@ -1051,7 +1058,7 @@ cdef inline str _render_tstamp(int64_t val):
 # Normalization
 
 
-def normalize_date(object dt):
+def normalize_date(dt: object) -> datetime:
     """
     Normalize datetime.datetime value to midnight. Returns datetime.date as a
     datetime.datetime at midnight
@@ -1085,7 +1092,7 @@ def normalize_date(object dt):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-def normalize_i8_timestamps(int64_t[:] stamps, tz=None):
+def normalize_i8_timestamps(int64_t[:] stamps, object tz=None):
     """
     Normalize each of the (nanosecond) timestamps in the given array by
     rounding down to the beginning of the day (i.e. midnight).  If `tz`
@@ -1122,7 +1129,7 @@ def normalize_i8_timestamps(int64_t[:] stamps, tz=None):
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
-cdef int64_t[:] _normalize_local(int64_t[:] stamps, object tz):
+cdef int64_t[:] _normalize_local(int64_t[:] stamps, tzinfo tz):
     """
     Normalize each of the (nanosecond) timestamps in the given array by
     rounding down to the beginning of the day (i.e. midnight) for the
@@ -1131,7 +1138,7 @@ cdef int64_t[:] _normalize_local(int64_t[:] stamps, object tz):
     Parameters
     ----------
     stamps : int64 ndarray
-    tz : tzinfo or None
+    tz : tzinfo
 
     Returns
     -------
@@ -1207,6 +1214,8 @@ cdef inline int64_t _normalized_stamp(npy_datetimestruct *dts) nogil:
     return dtstruct_to_dt64(dts)
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def is_date_array_normalized(int64_t[:] stamps, tz=None):
     """
     Check if all of the given (nanosecond) timestamps are normalized to
diff --git a/pandas/_libs/tslibs/fields.pyx b/pandas/_libs/tslibs/fields.pyx
index 1af9cd619..216128cae 100644
--- a/pandas/_libs/tslibs/fields.pyx
+++ b/pandas/_libs/tslibs/fields.pyx
@@ -40,6 +40,8 @@ def get_time_micros(ndarray[int64_t] dtindex):
     return micros
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def build_field_sarray(int64_t[:] dtindex):
     """
     Datetime as int64 representation to a structured array of fields
diff --git a/pandas/_libs/tslibs/nattype.pyx b/pandas/_libs/tslibs/nattype.pyx
index 0eec84ecf..a52ad1fba 100644
--- a/pandas/_libs/tslibs/nattype.pyx
+++ b/pandas/_libs/tslibs/nattype.pyx
@@ -97,7 +97,8 @@ cdef class _NaT(datetime):
         return hash(self.value)
 
     def __richcmp__(_NaT self, object other, int op):
-        cdef int ndim = getattr(other, 'ndim', -1)
+        cdef:
+            int ndim = getattr(other, 'ndim', -1)
 
         if ndim == -1:
             return _nat_scalar_rules[op]
@@ -181,7 +182,7 @@ cdef class _NaT(datetime):
 
     def to_datetime64(self):
         """ Returns a numpy.datetime64 object with 'ns' precision """
-        return np.datetime64('NaT')
+        return np.datetime64('NaT', 'ns')
 
 
 class NaTType(_NaT):
diff --git a/pandas/_libs/tslibs/np_datetime.pyx b/pandas/_libs/tslibs/np_datetime.pyx
index e0ecfc248..61d0f697e 100644
--- a/pandas/_libs/tslibs/np_datetime.pyx
+++ b/pandas/_libs/tslibs/np_datetime.pyx
@@ -136,6 +136,7 @@ cdef inline void dt64_to_dtstruct(int64_t dt64,
     pandas_datetime_to_datetimestruct(dt64, NPY_FR_ns, out)
     return
 
+
 cdef inline void td64_to_tdstruct(int64_t td64,
                                   pandas_timedeltastruct* out) nogil:
     """Convenience function to call pandas_timedelta_to_timedeltastruct
diff --git a/pandas/_libs/tslibs/offsets.pyx b/pandas/_libs/tslibs/offsets.pyx
index 5baacfe5f..528d30ddd 100644
--- a/pandas/_libs/tslibs/offsets.pyx
+++ b/pandas/_libs/tslibs/offsets.pyx
@@ -5,6 +5,7 @@ from cython import Py_ssize_t
 
 import time
 from cpython.datetime cimport (PyDateTime_IMPORT,
+                               PyDateTime_Check,
                                datetime, timedelta,
                                time as dt_time)
 PyDateTime_IMPORT
@@ -354,7 +355,7 @@ class _BaseOffset(object):
             return NotImplemented
 
     def __sub__(self, other):
-        if isinstance(other, datetime):
+        if PyDateTime_Check(other):
             raise TypeError('Cannot subtract datetime from offset.')
         elif type(other) == type(self):
             return type(self)(self.n - other.n, normalize=self.normalize,
@@ -496,7 +497,7 @@ class _Tick(object):
 # ----------------------------------------------------------------------
 # RelativeDelta Arithmetic
 
-cpdef datetime shift_day(datetime other, int days):
+def shift_day(other: datetime, days: int) -> datetime:
     """
     Increment the datetime `other` by the given number of days, retaining
     the time-portion of the datetime.  For tz-naive datetimes this is
@@ -988,8 +989,7 @@ cpdef int roll_qtrday(datetime other, int n, int month, object day_opt,
     return n
 
 
-cpdef int roll_yearday(datetime other, int n, int month,
-                       object day_opt) except? -1:
+def roll_yearday(other: datetime, n: int, month: int, day_opt: object) -> int:
     """
     Possibly increment or decrement the number of periods to shift
     based on rollforward/rollbackward conventions.
diff --git a/pandas/_libs/tslibs/parsing.pyx b/pandas/_libs/tslibs/parsing.pyx
index 3887957ae..71bb8f796 100644
--- a/pandas/_libs/tslibs/parsing.pyx
+++ b/pandas/_libs/tslibs/parsing.pyx
@@ -361,7 +361,7 @@ cdef dateutil_parse(object timestr, object default, ignoretz=False,
     return ret, reso
 
 
-cpdef object _get_rule_month(object source, object default='DEC'):
+cdef object _get_rule_month(object source, object default='DEC'):
     """
     Return starting month of given freq, default is December.
 
diff --git a/pandas/_libs/tslibs/period.pyx b/pandas/_libs/tslibs/period.pyx
index 73fccb912..a769bbb08 100644
--- a/pandas/_libs/tslibs/period.pyx
+++ b/pandas/_libs/tslibs/period.pyx
@@ -2,7 +2,6 @@
 from datetime import datetime, date
 
 from cpython cimport (
-    PyUnicode_Check,
     PyObject_RichCompareBool,
     Py_EQ, Py_NE)
 
@@ -14,9 +13,9 @@ from libc.stdlib cimport free, malloc
 from libc.time cimport strftime, tm
 from libc.string cimport strlen, memset
 
-cimport cython
+import cython
 
-from cpython.datetime cimport (PyDateTime_Check, PyDelta_Check,
+from cpython.datetime cimport (PyDateTime_Check, PyDelta_Check, PyDate_Check,
                                PyDateTime_IMPORT)
 # import datetime C API
 PyDateTime_IMPORT
@@ -47,7 +46,7 @@ from frequencies cimport (get_freq_code, get_base_alias,
                           get_rule_month)
 from parsing import parse_time_string
 from resolution import Resolution
-from nattype import nat_strings, NaT, iNaT
+from nattype import nat_strings, NaT
 from nattype cimport _nat_scalar_rules, NPY_NAT, is_null_datetimelike
 from offsets cimport to_offset
 from offsets import _Tick
@@ -307,6 +306,7 @@ cdef inline int64_t transform_via_day(int64_t ordinal,
     result = second_func(result, af_info)
     return result
 
+
 # --------------------------------------------------------------------
 # Conversion _to_ Daily Freq
 
@@ -551,7 +551,7 @@ cdef int64_t asfreq_AtoA(int64_t ordinal, asfreq_info *af_info):
 cdef int64_t asfreq_AtoQ(int64_t ordinal, asfreq_info *af_info):
     return transform_via_day(ordinal, af_info,
                              <freq_conv_func>asfreq_AtoDT,
-                             <freq_conv_func>asfreq_DTtoQ);
+                             <freq_conv_func>asfreq_DTtoQ)
 
 
 cdef int64_t asfreq_AtoM(int64_t ordinal, asfreq_info *af_info):
@@ -976,7 +976,6 @@ cdef inline int month_to_quarter(int month):
 # ----------------------------------------------------------------------
 # Period logic
 
-
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def dt64arr_to_periodarr(int64_t[:] dtarr, int freq, tz=None):
@@ -1041,8 +1040,8 @@ cpdef int64_t period_asfreq(int64_t ordinal, int freq1, int freq2, bint end):
         freq_conv_func func
         asfreq_info af_info
 
-    if ordinal == iNaT:
-        return iNaT
+    if ordinal == NPY_NAT:
+        return NPY_NAT
 
     func = get_asfreq_func(freq1, freq2)
     get_asfreq_info(freq1, freq2, end, &af_info)
@@ -1106,6 +1105,8 @@ cdef inline int calc_week_end(int freq, int group) nogil:
     return freq - group
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def period_asfreq_arr(ndarray[int64_t] arr, int freq1, int freq2, bint end):
     """
     Convert int64-array of period ordinals from one frequency to another, and
@@ -1124,11 +1125,11 @@ def period_asfreq_arr(ndarray[int64_t] arr, int freq1, int freq2, bint end):
     func = get_asfreq_func(freq1, freq2)
     get_asfreq_info(freq1, freq2, end, &af_info)
 
-    mask = arr == iNaT
+    mask = arr == NPY_NAT
     if mask.any():      # NaT process
         for i in range(n):
             val = arr[i]
-            if val != iNaT:
+            if val != NPY_NAT:
                 val = func(val, &af_info)
                 if val == INT32_MIN:
                     raise ValueError("Unable to convert to desired frequency.")
@@ -1192,7 +1193,7 @@ def period_format(int64_t value, int freq, object fmt=None):
     cdef:
         int freq_group
 
-    if value == iNaT:
+    if value == NPY_NAT:
         return repr(NaT)
 
     if fmt is None:
@@ -1248,7 +1249,7 @@ cdef object _period_strftime(int64_t value, int freq, object fmt):
         list found_pat = [False] * len(extra_fmts)
         int year, quarter
 
-    if PyUnicode_Check(fmt):
+    if isinstance(fmt, unicode):
         fmt = fmt.encode('utf-8')
 
     get_date_info(value, freq, &dts)
@@ -1381,6 +1382,8 @@ cdef int pdays_in_month(int64_t ordinal, int freq):
     return ccalendar.get_days_in_month(dts.year, dts.month)
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def get_period_field_arr(int code, int64_t[:] arr, int freq):
     cdef:
         Py_ssize_t i, sz
@@ -1395,7 +1398,7 @@ def get_period_field_arr(int code, int64_t[:] arr, int freq):
     out = np.empty(sz, dtype=np.int64)
 
     for i in range(sz):
-        if arr[i] == iNaT:
+        if arr[i] == NPY_NAT:
             out[i] = -1
             continue
         out[i] = func(arr[i], freq)
@@ -1431,6 +1434,8 @@ cdef accessor _get_accessor_func(int code):
     return NULL
 
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
 def extract_ordinals(object[:] values, freq):
     cdef:
         Py_ssize_t i, n = len(values)
@@ -1443,7 +1448,7 @@ def extract_ordinals(object[:] values, freq):
         p = values[i]
 
         if is_null_datetimelike(p):
-            ordinals[i] = iNaT
+            ordinals[i] = NPY_NAT
         else:
             try:
                 ordinals[i] = p.ordinal
@@ -1456,7 +1461,7 @@ def extract_ordinals(object[:] values, freq):
                 p = Period(p, freq=freq)
                 if p is NaT:
                     # input may contain NaT-like string
-                    ordinals[i] = iNaT
+                    ordinals[i] = NPY_NAT
                 else:
                     ordinals[i] = p.ordinal
 
@@ -1581,7 +1586,7 @@ cdef class _Period(object):
         """
         Fast creation from an ordinal and freq that are already validated!
         """
-        if ordinal == iNaT:
+        if ordinal == NPY_NAT:
             return NaT
         else:
             freq = cls._maybe_convert_freq(freq)
@@ -2420,7 +2425,7 @@ class Period(_Period):
             if (year is None and month is None and
                     quarter is None and day is None and
                     hour is None and minute is None and second is None):
-                ordinal = iNaT
+                ordinal = NPY_NAT
             else:
                 if freq is None:
                     raise ValueError("If value is None, freq cannot be None")
@@ -2446,7 +2451,7 @@ class Period(_Period):
                 ordinal = converted.ordinal
 
         elif is_null_datetimelike(value) or value in nat_strings:
-            ordinal = iNaT
+            ordinal = NPY_NAT
 
         elif is_string_object(value) or util.is_integer_object(value):
             if util.is_integer_object(value):
@@ -2454,7 +2459,7 @@ class Period(_Period):
             value = value.upper()
             dt, _, reso = parse_time_string(value, freq)
             if dt is NaT:
-                ordinal = iNaT
+                ordinal = NPY_NAT
 
             if freq is None:
                 try:
@@ -2464,7 +2469,7 @@ class Period(_Period):
                         "Invalid frequency or could not infer: {reso}"
                         .format(reso=reso))
 
-        elif isinstance(value, datetime):
+        elif PyDateTime_Check(value):
             dt = value
             if freq is None:
                 raise ValueError('Must supply freq for datetime value')
@@ -2472,7 +2477,7 @@ class Period(_Period):
             dt = Timestamp(value)
             if freq is None:
                 raise ValueError('Must supply freq for datetime value')
-        elif isinstance(value, date):
+        elif PyDate_Check(value):
             dt = datetime(year=value.year, month=value.month, day=value.day)
             if freq is None:
                 raise ValueError('Must supply freq for datetime value')
diff --git a/pandas/_libs/tslibs/timestamps.pyx b/pandas/_libs/tslibs/timestamps.pyx
index 93fa99ce1..1c481c73a 100644
--- a/pandas/_libs/tslibs/timestamps.pyx
+++ b/pandas/_libs/tslibs/timestamps.pyx
@@ -118,6 +118,7 @@ cdef inline _npdivmod(x1, x2):
 try:
     from numpy import divmod as npdivmod
 except ImportError:
+    # numpy < 1.13
     npdivmod = _npdivmod
 
 
@@ -278,7 +279,8 @@ cdef class _Timestamp(datetime):
 
     cdef bint _compare_outside_nanorange(_Timestamp self, datetime other,
                                          int op) except -1:
-        cdef datetime dtval = self.to_pydatetime()
+        cdef:
+            datetime dtval = self.to_pydatetime()
 
         self._assert_tzawareness_compat(other)
 
@@ -298,8 +300,7 @@ cdef class _Timestamp(datetime):
             elif op == Py_GE:
                 return dtval >= other
 
-    cdef int _assert_tzawareness_compat(_Timestamp self,
-                                        object other) except -1:
+    cdef _assert_tzawareness_compat(_Timestamp self, datetime other):
         if self.tzinfo is None:
             if other.tzinfo is not None:
                 raise TypeError('Cannot compare tz-naive and tz-aware '
@@ -307,7 +308,7 @@ cdef class _Timestamp(datetime):
         elif other.tzinfo is None:
             raise TypeError('Cannot compare tz-naive and tz-aware timestamps')
 
-    cpdef datetime to_pydatetime(_Timestamp self, warn=True):
+    cpdef datetime to_pydatetime(_Timestamp self, bint warn=True):
         """
         Convert a Timestamp object to a native Python datetime object.
 
diff --git a/pandas/_libs/tslibs/timezones.pyx b/pandas/_libs/tslibs/timezones.pyx
index 1fc1347c8..19a00fbd3 100644
--- a/pandas/_libs/tslibs/timezones.pyx
+++ b/pandas/_libs/tslibs/timezones.pyx
@@ -36,8 +36,8 @@ cdef inline bint is_tzlocal(object tz):
 
 
 cdef inline bint treat_tz_as_pytz(object tz):
-    return hasattr(tz, '_utc_transition_times') and hasattr(
-        tz, '_transition_info')
+    return (hasattr(tz, '_utc_transition_times') and
+            hasattr(tz, '_transition_info'))
 
 
 cdef inline bint treat_tz_as_dateutil(object tz):
diff --git a/pandas/_libs/window.pyx b/pandas/_libs/window.pyx
index 989dc4dd1..c7cfaab60 100644
--- a/pandas/_libs/window.pyx
+++ b/pandas/_libs/window.pyx
@@ -122,14 +122,14 @@ cdef class MockFixedWindowIndexer(WindowIndexer):
 
     Parameters
     ----------
-    input: ndarray
-        input data array
+    values: ndarray
+        values data array
     win: int64_t
         window size
     minp: int64_t
         min number of obs in a window to consider non-NaN
     index: object
-        index of the input
+        index of the values
     floor: optional
         unit for flooring
     left_closed: bint
@@ -138,13 +138,13 @@ cdef class MockFixedWindowIndexer(WindowIndexer):
         right endpoint closedness
 
     """
-    def __init__(self, ndarray input, int64_t win, int64_t minp,
+    def __init__(self, ndarray values, int64_t win, int64_t minp,
                  bint left_closed, bint right_closed,
                  object index=None, object floor=None):
 
         assert index is None
         self.is_variable = 0
-        self.N = len(input)
+        self.N = len(values)
         self.minp = _check_minp(win, minp, self.N, floor=floor)
         self.start = np.empty(0, dtype='int64')
         self.end = np.empty(0, dtype='int64')
@@ -160,14 +160,14 @@ cdef class FixedWindowIndexer(WindowIndexer):
 
     Parameters
     ----------
-    input: ndarray
-        input data array
+    values: ndarray
+        values data array
     win: int64_t
         window size
     minp: int64_t
         min number of obs in a window to consider non-NaN
     index: object
-        index of the input
+        index of the values
     floor: optional
         unit for flooring the unit
     left_closed: bint
@@ -176,14 +176,14 @@ cdef class FixedWindowIndexer(WindowIndexer):
         right endpoint closedness
 
     """
-    def __init__(self, ndarray input, int64_t win, int64_t minp,
+    def __init__(self, ndarray values, int64_t win, int64_t minp,
                  bint left_closed, bint right_closed,
                  object index=None, object floor=None):
         cdef ndarray start_s, start_e, end_s, end_e
 
         assert index is None
         self.is_variable = 0
-        self.N = len(input)
+        self.N = len(values)
         self.minp = _check_minp(win, minp, self.N, floor=floor)
 
         start_s = np.zeros(win, dtype='int64')
@@ -205,14 +205,14 @@ cdef class VariableWindowIndexer(WindowIndexer):
 
     Parameters
     ----------
-    input: ndarray
-        input data array
+    values: ndarray
+        values data array
     win: int64_t
         window size
     minp: int64_t
         min number of obs in a window to consider non-NaN
     index: ndarray
-        index of the input
+        index of the values
     left_closed: bint
         left endpoint closedness
         True if the left endpoint is closed, False if open
@@ -222,7 +222,7 @@ cdef class VariableWindowIndexer(WindowIndexer):
     floor: optional
         unit for flooring the unit
     """
-    def __init__(self, ndarray input, int64_t win, int64_t minp,
+    def __init__(self, ndarray values, int64_t win, int64_t minp,
                  bint left_closed, bint right_closed, ndarray index,
                  object floor=None):
 
@@ -294,18 +294,18 @@ cdef class VariableWindowIndexer(WindowIndexer):
                     end[i] -= 1
 
 
-def get_window_indexer(input, win, minp, index, closed,
+def get_window_indexer(values, win, minp, index, closed,
                        floor=None, use_mock=True):
     """
     return the correct window indexer for the computation
 
     Parameters
     ----------
-    input: 1d ndarray
+    values: 1d ndarray
     win: integer, window size
     minp: integer, minimum periods
     index: 1d ndarray, optional
-        index to the input array
+        index to the values array
     closed: string, default None
         {'right', 'left', 'both', 'neither'}
         window endpoint closedness. Defaults to 'right' in
@@ -342,13 +342,13 @@ def get_window_indexer(input, win, minp, index, closed,
         left_closed = True
 
     if index is not None:
-        indexer = VariableWindowIndexer(input, win, minp, left_closed,
+        indexer = VariableWindowIndexer(values, win, minp, left_closed,
                                         right_closed, index, floor)
     elif use_mock:
-        indexer = MockFixedWindowIndexer(input, win, minp, left_closed,
+        indexer = MockFixedWindowIndexer(values, win, minp, left_closed,
                                          right_closed, index, floor)
     else:
-        indexer = FixedWindowIndexer(input, win, minp, left_closed,
+        indexer = FixedWindowIndexer(values, win, minp, left_closed,
                                      right_closed, index, floor)
     return indexer.get_data()
 
@@ -357,7 +357,7 @@ def get_window_indexer(input, win, minp, index, closed,
 # this is only an impl for index not None, IOW, freq aware
 
 
-def roll_count(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_count(ndarray[double_t] values, int64_t win, int64_t minp,
                object index, object closed):
     cdef:
         double val, count_x = 0.0
@@ -366,7 +366,7 @@ def roll_count(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, _ = get_window_indexer(input, win,
+    start, end, N, win, minp, _ = get_window_indexer(values, win,
                                                      minp, index, closed)
     output = np.empty(N, dtype=float)
 
@@ -381,7 +381,7 @@ def roll_count(ndarray[double_t] input, int64_t win, int64_t minp,
                 # setup
                 count_x = 0.0
                 for j in range(s, e):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         count_x += 1.0
 
@@ -389,13 +389,13 @@ def roll_count(ndarray[double_t] input, int64_t win, int64_t minp,
 
                 # calculate deletes
                 for j in range(start[i - 1], s):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         count_x -= 1.0
 
                 # calculate adds
                 for j in range(end[i - 1], e):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         count_x += 1.0
 
@@ -438,7 +438,7 @@ cdef inline void remove_sum(double val, int64_t *nobs, double *sum_x) nogil:
         sum_x[0] = sum_x[0] - val
 
 
-def roll_sum(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_sum(ndarray[double_t] values, int64_t win, int64_t minp,
              object index, object closed):
     cdef:
         double val, prev_x, sum_x = 0
@@ -448,7 +448,7 @@ def roll_sum(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, is_variable = get_window_indexer(input, win,
+    start, end, N, win, minp, is_variable = get_window_indexer(values, win,
                                                                minp, index,
                                                                closed,
                                                                floor=0)
@@ -473,17 +473,17 @@ def roll_sum(ndarray[double_t] input, int64_t win, int64_t minp,
                     sum_x = 0.0
                     nobs = 0
                     for j in range(s, e):
-                        add_sum(input[j], &nobs, &sum_x)
+                        add_sum(values[j], &nobs, &sum_x)
 
                 else:
 
                     # calculate deletes
                     for j in range(start[i - 1], s):
-                        remove_sum(input[j], &nobs, &sum_x)
+                        remove_sum(values[j], &nobs, &sum_x)
 
                     # calculate adds
                     for j in range(end[i - 1], e):
-                        add_sum(input[j], &nobs, &sum_x)
+                        add_sum(values[j], &nobs, &sum_x)
 
                 output[i] = calc_sum(minp, nobs, sum_x)
 
@@ -496,15 +496,15 @@ def roll_sum(ndarray[double_t] input, int64_t win, int64_t minp,
         with nogil:
 
             for i in range(0, range_endpoint):
-                add_sum(input[i], &nobs, &sum_x)
+                add_sum(values[i], &nobs, &sum_x)
                 output[i] = NaN
 
             for i in range(range_endpoint, N):
-                val = input[i]
+                val = values[i]
                 add_sum(val, &nobs, &sum_x)
 
                 if i > win - 1:
-                    prev_x = input[i - win]
+                    prev_x = values[i - win]
                     remove_sum(prev_x, &nobs, &sum_x)
 
                 output[i] = calc_sum(minp, nobs, sum_x)
@@ -557,7 +557,7 @@ cdef inline void remove_mean(double val, Py_ssize_t *nobs, double *sum_x,
             neg_ct[0] = neg_ct[0] - 1
 
 
-def roll_mean(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_mean(ndarray[double_t] values, int64_t win, int64_t minp,
               object index, object closed):
     cdef:
         double val, prev_x, result, sum_x = 0
@@ -567,7 +567,7 @@ def roll_mean(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, is_variable = get_window_indexer(input, win,
+    start, end, N, win, minp, is_variable = get_window_indexer(values, win,
                                                                minp, index,
                                                                closed)
     output = np.empty(N, dtype=float)
@@ -590,19 +590,19 @@ def roll_mean(ndarray[double_t] input, int64_t win, int64_t minp,
                     sum_x = 0.0
                     nobs = 0
                     for j in range(s, e):
-                        val = input[j]
+                        val = values[j]
                         add_mean(val, &nobs, &sum_x, &neg_ct)
 
                 else:
 
                     # calculate deletes
                     for j in range(start[i - 1], s):
-                        val = input[j]
+                        val = values[j]
                         remove_mean(val, &nobs, &sum_x, &neg_ct)
 
                     # calculate adds
                     for j in range(end[i - 1], e):
-                        val = input[j]
+                        val = values[j]
                         add_mean(val, &nobs, &sum_x, &neg_ct)
 
                 output[i] = calc_mean(minp, nobs, neg_ct, sum_x)
@@ -611,16 +611,16 @@ def roll_mean(ndarray[double_t] input, int64_t win, int64_t minp,
 
         with nogil:
             for i in range(minp - 1):
-                val = input[i]
+                val = values[i]
                 add_mean(val, &nobs, &sum_x, &neg_ct)
                 output[i] = NaN
 
             for i in range(minp - 1, N):
-                val = input[i]
+                val = values[i]
                 add_mean(val, &nobs, &sum_x, &neg_ct)
 
                 if i > win - 1:
-                    prev_x = input[i - win]
+                    prev_x = values[i - win]
                     remove_mean(prev_x, &nobs, &sum_x, &neg_ct)
 
                 output[i] = calc_mean(minp, nobs, neg_ct, sum_x)
@@ -685,7 +685,7 @@ cdef inline void remove_var(double val, double *nobs, double *mean_x,
             ssqdm_x[0] = 0
 
 
-def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_var(ndarray[double_t] values, int64_t win, int64_t minp,
              object index, object closed, int ddof=1):
     """
     Numerically stable implementation using Welford's method.
@@ -698,7 +698,7 @@ def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, is_variable = get_window_indexer(input, win,
+    start, end, N, win, minp, is_variable = get_window_indexer(values, win,
                                                                minp, index,
                                                                closed)
     output = np.empty(N, dtype=float)
@@ -724,7 +724,7 @@ def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
                 if i == 0:
 
                     for j in range(s, e):
-                        add_var(input[j], &nobs, &mean_x, &ssqdm_x)
+                        add_var(values[j], &nobs, &mean_x, &ssqdm_x)
 
                 else:
 
@@ -733,11 +733,11 @@ def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
 
                     # calculate adds
                     for j in range(end[i - 1], e):
-                        add_var(input[j], &nobs, &mean_x, &ssqdm_x)
+                        add_var(values[j], &nobs, &mean_x, &ssqdm_x)
 
                     # calculate deletes
                     for j in range(start[i - 1], s):
-                        remove_var(input[j], &nobs, &mean_x, &ssqdm_x)
+                        remove_var(values[j], &nobs, &mean_x, &ssqdm_x)
 
                 output[i] = calc_var(minp, ddof, nobs, ssqdm_x)
 
@@ -748,7 +748,7 @@ def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
             # Over the first window, observations can only be added, never
             # removed
             for i in range(win):
-                add_var(input[i], &nobs, &mean_x, &ssqdm_x)
+                add_var(values[i], &nobs, &mean_x, &ssqdm_x)
                 output[i] = calc_var(minp, ddof, nobs, ssqdm_x)
 
             # a part of Welford's method for the online variance-calculation
@@ -757,8 +757,8 @@ def roll_var(ndarray[double_t] input, int64_t win, int64_t minp,
             # After the first window, observations can both be added and
             # removed
             for i in range(win, N):
-                val = input[i]
-                prev = input[i - win]
+                val = values[i]
+                prev = values[i - win]
 
                 if notnan(val):
                     if prev == prev:
@@ -845,7 +845,7 @@ cdef inline void remove_skew(double val, int64_t *nobs, double *x, double *xx,
         xxx[0] = xxx[0] - val * val * val
 
 
-def roll_skew(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_skew(ndarray[double_t] values, int64_t win, int64_t minp,
               object index, object closed):
     cdef:
         double val, prev
@@ -856,7 +856,7 @@ def roll_skew(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, is_variable = get_window_indexer(input, win,
+    start, end, N, win, minp, is_variable = get_window_indexer(values, win,
                                                                minp, index,
                                                                closed)
     output = np.empty(N, dtype=float)
@@ -875,7 +875,7 @@ def roll_skew(ndarray[double_t] input, int64_t win, int64_t minp,
                 if i == 0:
 
                     for j in range(s, e):
-                        val = input[j]
+                        val = values[j]
                         add_skew(val, &nobs, &x, &xx, &xxx)
 
                 else:
@@ -885,12 +885,12 @@ def roll_skew(ndarray[double_t] input, int64_t win, int64_t minp,
 
                     # calculate adds
                     for j in range(end[i - 1], e):
-                        val = input[j]
+                        val = values[j]
                         add_skew(val, &nobs, &x, &xx, &xxx)
 
                     # calculate deletes
                     for j in range(start[i - 1], s):
-                        val = input[j]
+                        val = values[j]
                         remove_skew(val, &nobs, &x, &xx, &xxx)
 
                 output[i] = calc_skew(minp, nobs, x, xx, xxx)
@@ -899,16 +899,16 @@ def roll_skew(ndarray[double_t] input, int64_t win, int64_t minp,
 
         with nogil:
             for i in range(minp - 1):
-                val = input[i]
+                val = values[i]
                 add_skew(val, &nobs, &x, &xx, &xxx)
                 output[i] = NaN
 
             for i in range(minp - 1, N):
-                val = input[i]
+                val = values[i]
                 add_skew(val, &nobs, &x, &xx, &xxx)
 
                 if i > win - 1:
-                    prev = input[i - win]
+                    prev = values[i - win]
                     remove_skew(prev, &nobs, &x, &xx, &xxx)
 
                 output[i] = calc_skew(minp, nobs, x, xx, xxx)
@@ -984,7 +984,7 @@ cdef inline void remove_kurt(double val, int64_t *nobs, double *x, double *xx,
         xxxx[0] = xxxx[0] - val * val * val * val
 
 
-def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
+def roll_kurt(ndarray[double_t] values, int64_t win, int64_t minp,
               object index, object closed):
     cdef:
         double val, prev
@@ -995,7 +995,7 @@ def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
         ndarray[int64_t] start, end
         ndarray[double_t] output
 
-    start, end, N, win, minp, is_variable = get_window_indexer(input, win,
+    start, end, N, win, minp, is_variable = get_window_indexer(values, win,
                                                                minp, index,
                                                                closed)
     output = np.empty(N, dtype=float)
@@ -1014,7 +1014,7 @@ def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
                 if i == 0:
 
                     for j in range(s, e):
-                        add_kurt(input[j], &nobs, &x, &xx, &xxx, &xxxx)
+                        add_kurt(values[j], &nobs, &x, &xx, &xxx, &xxxx)
 
                 else:
 
@@ -1023,11 +1023,11 @@ def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
 
                     # calculate adds
                     for j in range(end[i - 1], e):
-                        add_kurt(input[j], &nobs, &x, &xx, &xxx, &xxxx)
+                        add_kurt(values[j], &nobs, &x, &xx, &xxx, &xxxx)
 
                     # calculate deletes
                     for j in range(start[i - 1], s):
-                        remove_kurt(input[j], &nobs, &x, &xx, &xxx, &xxxx)
+                        remove_kurt(values[j], &nobs, &x, &xx, &xxx, &xxxx)
 
                 output[i] = calc_kurt(minp, nobs, x, xx, xxx, xxxx)
 
@@ -1036,14 +1036,14 @@ def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
         with nogil:
 
             for i in range(minp - 1):
-                add_kurt(input[i], &nobs, &x, &xx, &xxx, &xxxx)
+                add_kurt(values[i], &nobs, &x, &xx, &xxx, &xxxx)
                 output[i] = NaN
 
             for i in range(minp - 1, N):
-                add_kurt(input[i], &nobs, &x, &xx, &xxx, &xxxx)
+                add_kurt(values[i], &nobs, &x, &xx, &xxx, &xxxx)
 
                 if i > win - 1:
-                    prev = input[i - win]
+                    prev = values[i - win]
                     remove_kurt(prev, &nobs, &x, &xx, &xxx, &xxxx)
 
                 output[i] = calc_kurt(minp, nobs, x, xx, xxx, xxxx)
@@ -1054,7 +1054,7 @@ def roll_kurt(ndarray[double_t] input, int64_t win, int64_t minp,
 # Rolling median, min, max
 
 
-def roll_median_c(ndarray[float64_t] input, int64_t win, int64_t minp,
+def roll_median_c(ndarray[float64_t] values, int64_t win, int64_t minp,
                   object index, object closed):
     cdef:
         double val, res, prev
@@ -1070,7 +1070,7 @@ def roll_median_c(ndarray[float64_t] input, int64_t win, int64_t minp,
     # we use the Fixed/Variable Indexer here as the
     # actual skiplist ops outweigh any window computation costs
     start, end, N, win, minp, is_variable = get_window_indexer(
-        input, win,
+        values, win,
         minp, index, closed,
         use_mock=False)
     output = np.empty(N, dtype=float)
@@ -1088,7 +1088,7 @@ def roll_median_c(ndarray[float64_t] input, int64_t win, int64_t minp,
             if i == 0:
 
                 # setup
-                val = input[i]
+                val = values[i]
                 if notnan(val):
                     nobs += 1
                     err = skiplist_insert(sl, val) != 1
@@ -1099,14 +1099,14 @@ def roll_median_c(ndarray[float64_t] input, int64_t win, int64_t minp,
 
                 # calculate deletes
                 for j in range(start[i - 1], s):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         skiplist_remove(sl, val)
                         nobs -= 1
 
                 # calculate adds
                 for j in range(end[i - 1], e):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         nobs += 1
                         err = skiplist_insert(sl, val) != 1
@@ -1180,14 +1180,14 @@ cdef inline numeric calc_mm(int64_t minp, Py_ssize_t nobs,
     return result
 
 
-def roll_max(ndarray[numeric] input, int64_t win, int64_t minp,
+def roll_max(ndarray[numeric] values, int64_t win, int64_t minp,
              object index, object closed):
     """
     Moving max of 1d array of any numeric type along axis=0 ignoring NaNs.
 
     Parameters
     ----------
-    input: numpy array
+    values: numpy array
     window: int, size of rolling window
     minp: if number of observations in window
           is below this, output a NaN
@@ -1197,27 +1197,27 @@ def roll_max(ndarray[numeric] input, int64_t win, int64_t minp,
             make the interval closed on the right, left,
             both or neither endpoints
     """
-    return _roll_min_max(input, win, minp, index, closed=closed, is_max=1)
+    return _roll_min_max(values, win, minp, index, closed=closed, is_max=1)
 
 
-def roll_min(ndarray[numeric] input, int64_t win, int64_t minp,
+def roll_min(ndarray[numeric] values, int64_t win, int64_t minp,
              object index, object closed):
     """
     Moving max of 1d array of any numeric type along axis=0 ignoring NaNs.
 
     Parameters
     ----------
-    input: numpy array
+    values: numpy array
     window: int, size of rolling window
     minp: if number of observations in window
           is below this, output a NaN
     index: ndarray, optional
        index for window computation
     """
-    return _roll_min_max(input, win, minp, index, is_max=0, closed=closed)
+    return _roll_min_max(values, win, minp, index, is_max=0, closed=closed)
 
 
-cdef _roll_min_max(ndarray[numeric] input, int64_t win, int64_t minp,
+cdef _roll_min_max(ndarray[numeric] values, int64_t win, int64_t minp,
                    object index, object closed, bint is_max):
     """
     Moving min/max of 1d array of any numeric type along axis=0
@@ -1229,17 +1229,17 @@ cdef _roll_min_max(ndarray[numeric] input, int64_t win, int64_t minp,
         bint is_variable
 
     starti, endi, N, win, minp, is_variable = get_window_indexer(
-        input, win,
+        values, win,
         minp, index, closed)
 
     if is_variable:
-        return _roll_min_max_variable(input, starti, endi, N, win, minp,
+        return _roll_min_max_variable(values, starti, endi, N, win, minp,
                                       is_max)
     else:
-        return _roll_min_max_fixed(input, starti, endi, N, win, minp, is_max)
+        return _roll_min_max_fixed(values, starti, endi, N, win, minp, is_max)
 
 
-cdef _roll_min_max_variable(ndarray[numeric] input,
+cdef _roll_min_max_variable(ndarray[numeric] values,
                             ndarray[int64_t] starti,
                             ndarray[int64_t] endi,
                             int64_t N,
@@ -1266,16 +1266,16 @@ cdef _roll_min_max_variable(ndarray[numeric] input,
         # So the code was optimized for that
 
         for i from starti[0] <= i < endi[0]:
-            ai = init_mm(input[i], &nobs, is_max)
+            ai = init_mm(values[i], &nobs, is_max)
 
             # Discard previous entries if we find new min or max
             if is_max:
-                while not Q.empty() and ((ai >= input[Q.back()]) or
-                                         (input[Q.back()] != input[Q.back()])):
+                while not Q.empty() and ((ai >= values[Q.back()]) or
+                                         values[Q.back()] != values[Q.back()]):
                     Q.pop_back()
             else:
-                while not Q.empty() and ((ai <= input[Q.back()]) or
-                                         (input[Q.back()] != input[Q.back()])):
+                while not Q.empty() and ((ai <= values[Q.back()]) or
+                                         values[Q.back()] != values[Q.back()]):
                     Q.pop_back()
             Q.push_back(i)
             W.push_back(i)
@@ -1286,20 +1286,20 @@ cdef _roll_min_max_variable(ndarray[numeric] input,
         for i in range(endi[0], endi[N-1]):
             if not Q.empty():
                 output[i-1+close_offset] = calc_mm(
-                    minp, nobs, input[Q.front()])
+                    minp, nobs, values[Q.front()])
             else:
                 output[i-1+close_offset] = NaN
 
-            ai = init_mm(input[i], &nobs, is_max)
+            ai = init_mm(values[i], &nobs, is_max)
 
             # Discard previous entries if we find new min or max
             if is_max:
-                while not Q.empty() and ((ai >= input[Q.back()]) or
-                                         (input[Q.back()] != input[Q.back()])):
+                while not Q.empty() and ((ai >= values[Q.back()]) or
+                                         values[Q.back()] != values[Q.back()]):
                     Q.pop_back()
             else:
-                while not Q.empty() and ((ai <= input[Q.back()]) or
-                                         (input[Q.back()] != input[Q.back()])):
+                while not Q.empty() and ((ai <= values[Q.back()]) or
+                                         values[Q.back()] != values[Q.back()]):
                     Q.pop_back()
 
             # Maintain window/nobs retention
@@ -1307,18 +1307,18 @@ cdef _roll_min_max_variable(ndarray[numeric] input,
             while not Q.empty() and Q.front() <= i - curr_win_size:
                 Q.pop_front()
             while not W.empty() and W.front() <= i - curr_win_size:
-                remove_mm(input[W.front()], &nobs)
+                remove_mm(values[W.front()], &nobs)
                 W.pop_front()
 
             Q.push_back(i)
             W.push_back(i)
 
-        output[N-1] = calc_mm(minp, nobs, input[Q.front()])
+        output[N-1] = calc_mm(minp, nobs, values[Q.front()])
 
     return output
 
 
-cdef _roll_min_max_fixed(ndarray[numeric] input,
+cdef _roll_min_max_fixed(ndarray[numeric] values,
                          ndarray[int64_t] starti,
                          ndarray[int64_t] endi,
                          int64_t N,
@@ -1345,18 +1345,18 @@ cdef _roll_min_max_fixed(ndarray[numeric] input,
     end = ring + win
     last = ring
     minvalue = ring
-    ai = input[0]
-    minvalue[0] = init_mm(input[0], &nobs, is_max)
+    ai = values[0]
+    minvalue[0] = init_mm(values[0], &nobs, is_max)
     death[0] = win
     nobs = 0
 
     with nogil:
 
         for i in range(N):
-            ai = init_mm(input[i], &nobs, is_max)
+            ai = init_mm(values[i], &nobs, is_max)
 
             if i >= win:
-                remove_mm(input[i - win], &nobs)
+                remove_mm(values[i - win], &nobs)
 
             if death[minvalue - ring] == i:
                 minvalue = minvalue + 1
@@ -1425,7 +1425,7 @@ interpolation_types = {
 }
 
 
-def roll_quantile(ndarray[float64_t, cast=True] input, int64_t win,
+def roll_quantile(ndarray[float64_t, cast=True] values, int64_t win,
                   int64_t minp, object index, object closed,
                   double quantile, str interpolation):
     """
@@ -1455,7 +1455,7 @@ def roll_quantile(ndarray[float64_t, cast=True] input, int64_t win,
     # we use the Fixed/Variable Indexer here as the
     # actual skiplist ops outweigh any window computation costs
     start, end, N, win, minp, is_variable = get_window_indexer(
-        input, win,
+        values, win,
         minp, index, closed,
         use_mock=False)
     output = np.empty(N, dtype=float)
@@ -1471,7 +1471,7 @@ def roll_quantile(ndarray[float64_t, cast=True] input, int64_t win,
             if i == 0:
 
                 # setup
-                val = input[i]
+                val = values[i]
                 if notnan(val):
                     nobs += 1
                     skiplist_insert(skiplist, val)
@@ -1480,14 +1480,14 @@ def roll_quantile(ndarray[float64_t, cast=True] input, int64_t win,
 
                 # calculate deletes
                 for j in range(start[i - 1], s):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         skiplist_remove(skiplist, val)
                         nobs -= 1
 
                 # calculate adds
                 for j in range(end[i - 1], e):
-                    val = input[j]
+                    val = values[j]
                     if notnan(val):
                         nobs += 1
                         skiplist_insert(skiplist, val)
@@ -1635,18 +1635,18 @@ def roll_generic(object obj,
     return output
 
 
-def roll_window(ndarray[float64_t, ndim=1, cast=True] input,
+def roll_window(ndarray[float64_t, ndim=1, cast=True] values,
                 ndarray[float64_t, ndim=1, cast=True] weights,
                 int minp, bint avg=True):
     """
-    Assume len(weights) << len(input)
+    Assume len(weights) << len(values)
     """
     cdef:
         ndarray[double_t] output, tot_wgt, counts
         Py_ssize_t in_i, win_i, win_n, win_k, in_n, in_k
         float64_t val_in, val_win, c, w
 
-    in_n = len(input)
+    in_n = len(values)
     win_n = len(weights)
     output = np.zeros(in_n, dtype=float)
     counts = np.zeros(in_n, dtype=float)
@@ -1662,7 +1662,7 @@ def roll_window(ndarray[float64_t, ndim=1, cast=True] input,
                 continue
 
             for in_i from 0 <= in_i < in_n - (win_n - win_i) + 1:
-                val_in = input[in_i]
+                val_in = values[in_i]
                 if val_in == val_in:
                     output[in_i + (win_n - win_i) - 1] += val_in * val_win
                     counts[in_i + (win_n - win_i) - 1] += 1
@@ -1686,7 +1686,7 @@ def roll_window(ndarray[float64_t, ndim=1, cast=True] input,
                 continue
 
             for in_i from 0 <= in_i < in_n - (win_n - win_i) + 1:
-                val_in = input[in_i]
+                val_in = values[in_i]
 
                 if val_in == val_in:
                     output[in_i + (win_n - win_i) - 1] += val_in * val_win
