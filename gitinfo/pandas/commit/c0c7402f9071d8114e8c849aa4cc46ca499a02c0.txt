commit c0c7402f9071d8114e8c849aa4cc46ca499a02c0
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Oct 1 14:59:24 2012 -0400

    ENH: change default header names in read_* functions from X.1, X.2, ... to X0, X1, ... close #2000

diff --git a/RELEASE.rst b/RELEASE.rst
index 38312a5c4..463a08737 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -63,6 +63,8 @@ pandas 0.9.0
 
 **API Changes**
 
+  - Change default header names in read_* functions to more Pythonic X0, X1,
+    etc. instead of X.1, X.2. (#2000)
   - Deprecated ``day_of_year`` API removed from PeriodIndex, use ``dayofyear``
     (#1723)
   - Don't modify NumPy suppress printoption at import time
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 88bad2a54..5f43b4e86 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -613,7 +613,7 @@ class TextParser(object):
 
             ncols = len(line)
             if not names:
-                columns = ['X.%d' % (i + 1) for i in range(ncols)]
+                columns = ['X%d' % i for i in range(ncols)]
             else:
                 columns = names
 
@@ -747,7 +747,7 @@ class TextParser(object):
             else:
                 index_name = columns[self.index_col]
 
-            if index_name is not None and 'Unnamed' in index_name:
+            if index_name is not None and 'Unnamed' in str(index_name):
                 index_name = None
 
         elif self.index_col is not None:
@@ -1160,19 +1160,9 @@ def _convert_types(values, na_values):
 
     return result, na_count
 
-def _get_col_names(colspec, columns):
-    colset = set(columns)
-    colnames = []
-    for c in colspec:
-        if c in colset:
-            colnames.append(str(c))
-        elif isinstance(c, int):
-            colnames.append(str(columns[c]))
-    return colnames
-
 def _try_convert_dates(parser, colspec, data_dict, columns):
     colspec = _get_col_names(colspec, columns)
-    new_name = '_'.join(colspec)
+    new_name = '_'.join([str(x) for x in colspec])
 
     to_parse = [data_dict[c] for c in colspec if c in data_dict]
     try:
@@ -1181,6 +1171,17 @@ def _try_convert_dates(parser, colspec, data_dict, columns):
         new_col = parser(_concat_date_cols(to_parse))
     return new_name, new_col, colspec
 
+def _get_col_names(colspec, columns):
+    colset = set(columns)
+    colnames = []
+    for c in colspec:
+        if c in colset:
+            colnames.append(c)
+        elif isinstance(c, int):
+            colnames.append(columns[c])
+    return colnames
+
+
 def _concat_date_cols(date_cols):
     if len(date_cols) == 1:
         return np.array([str(x) for x in date_cols[0]], dtype=object)
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 3c724fce2..ba91d7250 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -215,10 +215,10 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
                                    'actual' : [1,3]})
         self.assert_('nominal' in df)
         self.assert_('actual' in df)
-        self.assert_('X.2' not in df)
-        self.assert_('X.3' not in df)
-        self.assert_('X.4' not in df)
-        from datetime import datetime
+        self.assert_('X1' not in df)
+        self.assert_('X2' not in df)
+        self.assert_('X3' not in df)
+
         d = datetime(1999, 1, 27, 19, 0)
         self.assert_(df.ix[0, 'nominal'] == d)
 
@@ -229,9 +229,10 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
                       keep_date_col=True)
         self.assert_('nominal' in df)
         self.assert_('actual' in df)
-        self.assert_('X.2' in df)
-        self.assert_('X.3' in df)
-        self.assert_('X.4' in df)
+
+        self.assert_('X1' in df)
+        self.assert_('X2' in df)
+        self.assert_('X3' in df)
 
         data = """\
 KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
@@ -243,22 +244,24 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 """
         df = read_csv(StringIO(data), header=None,
                       parse_dates=[[1, 2], [1,3]])
-        self.assert_('X.2_X.3' in df)
-        self.assert_('X.2_X.4' in df)
-        self.assert_('X.2' not in df)
-        self.assert_('X.3' not in df)
-        self.assert_('X.4' not in df)
-        from datetime import datetime
+
+        self.assert_('X1_X2' in df)
+        self.assert_('X1_X3' in df)
+        self.assert_('X1' not in df)
+        self.assert_('X2' not in df)
+        self.assert_('X3' not in df)
+
         d = datetime(1999, 1, 27, 19, 0)
-        self.assert_(df.ix[0, 'X.2_X.3'] == d)
+        self.assert_(df.ix[0, 'X1_X2'] == d)
 
         df = read_csv(StringIO(data), header=None,
                       parse_dates=[[1, 2], [1,3]], keep_date_col=True)
-        self.assert_('X.2_X.3' in df)
-        self.assert_('X.2_X.4' in df)
-        self.assert_('X.2' in df)
-        self.assert_('X.3' in df)
-        self.assert_('X.4' in df)
+
+        self.assert_('X1_X2' in df)
+        self.assert_('X1_X3' in df)
+        self.assert_('X1' in df)
+        self.assert_('X2' in df)
+        self.assert_('X3' in df)
 
         data = '''\
 KORD,19990127 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
@@ -269,7 +272,6 @@ KORD,19990127 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 '''
         df = read_csv(StringIO(data), sep=',', header=None,
                       parse_dates=[1], index_col=1)
-        from datetime import datetime
         d = datetime(1999, 1, 27, 19, 0)
         self.assert_(df.index[0] == d)
 
@@ -561,7 +563,7 @@ ignore,this,row
                          index_col=0, parse_dates=True)
 
         expected = DataFrame(np.arange(1., 10.).reshape((3,3)),
-                             columns=['X.2', 'X.3', 'X.4'],
+                             columns=['X1', 'X2', 'X3'],
                              index=[datetime(2000, 1, 1), datetime(2000, 1, 2),
                                     datetime(2000, 1, 3)])
         assert_frame_equal(data, expected)
@@ -706,7 +708,7 @@ c,4,5
         assert_almost_equal(df.values, expected)
         assert_almost_equal(df.values, df2.values)
         self.assert_(np.array_equal(df.columns,
-                                    ['X.1', 'X.2', 'X.3', 'X.4', 'X.5']))
+                                    ['X0', 'X1', 'X2', 'X3', 'X4']))
         self.assert_(np.array_equal(df2.columns, names))
 
     def test_header_with_index_col(self):
@@ -848,7 +850,7 @@ baz,7,8,9
     def test_read_table_unicode(self):
         fin = StringIO('\u0141aski, Jan;1')
         df1 = read_table(fin, sep=";", encoding="utf-8", header=None)
-        self.assert_(isinstance(df1['X.1'].values[0], unicode))
+        self.assert_(isinstance(df1['X0'].values[0], unicode))
 
     def test_read_table_wrong_num_columns(self):
         data = """A,B,C,D,E,F
@@ -1286,8 +1288,8 @@ qux foo
 foo
 bar"""
         df = read_csv(StringIO(text), header=None)
-        expected = DataFrame({'X.1' : ['foo', 'bar baz', 'qux foo',
-                                       'foo', 'bar']})
+        expected = DataFrame({'X0' : ['foo', 'bar baz', 'qux foo',
+                                      'foo', 'bar']})
         assert_frame_equal(df, expected)
 
     def test_parse_dates_custom_euroformat(self):
diff --git a/pandas/tests/test_format.py b/pandas/tests/test_format.py
index 48800d7df..9d45273e7 100644
--- a/pandas/tests/test_format.py
+++ b/pandas/tests/test_format.py
@@ -237,7 +237,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         filepath = os.path.join(pth, 'data', 'unicode_series.csv')
         df = pandas.read_csv(filepath, header=None)
         repr(df)
-        repr(df['X.2'])
+        repr(df['X1'])
 
     def test_repr_corner(self):
         # representing infs poses no problems
