commit 7a1dad130ce183a96f76f303120b688e998e129c
Author: MomIsBestFriend <50263213+MomIsBestFriend@users.noreply.github.com>
Date:   Thu Jan 16 20:34:42 2020 +0200

    CLN/STY: Some stuff that got the attention of my eye (#31076)

diff --git a/pandas/_libs/hashtable.pyx b/pandas/_libs/hashtable.pyx
index 59ba1705d..884db9ee9 100644
--- a/pandas/_libs/hashtable.pyx
+++ b/pandas/_libs/hashtable.pyx
@@ -13,26 +13,45 @@ cnp.import_array()
 cdef extern from "numpy/npy_math.h":
     float64_t NAN "NPY_NAN"
 
-
 from pandas._libs.khash cimport (
     khiter_t,
-
-    kh_str_t, kh_init_str, kh_put_str, kh_exist_str,
-    kh_get_str, kh_destroy_str, kh_resize_str,
-
-    kh_put_strbox, kh_get_strbox, kh_init_strbox,
-
-    kh_int64_t, kh_init_int64, kh_resize_int64, kh_destroy_int64,
-    kh_get_int64, kh_exist_int64, kh_put_int64,
-
-    kh_float64_t, kh_exist_float64, kh_put_float64, kh_init_float64,
-    kh_get_float64, kh_destroy_float64, kh_resize_float64,
-
-    kh_resize_uint64, kh_exist_uint64, kh_destroy_uint64, kh_put_uint64,
-    kh_get_uint64, kh_init_uint64,
-
-    kh_destroy_pymap, kh_exist_pymap, kh_init_pymap, kh_get_pymap,
-    kh_put_pymap, kh_resize_pymap)
+    kh_str_t,
+    kh_init_str,
+    kh_put_str,
+    kh_exist_str,
+    kh_get_str,
+    kh_destroy_str,
+    kh_resize_str,
+    kh_put_strbox,
+    kh_get_strbox,
+    kh_init_strbox,
+    kh_int64_t,
+    kh_init_int64,
+    kh_resize_int64,
+    kh_destroy_int64,
+    kh_get_int64,
+    kh_exist_int64,
+    kh_put_int64,
+    kh_float64_t,
+    kh_exist_float64,
+    kh_put_float64,
+    kh_init_float64,
+    kh_get_float64,
+    kh_destroy_float64,
+    kh_resize_float64,
+    kh_resize_uint64,
+    kh_exist_uint64,
+    kh_destroy_uint64,
+    kh_put_uint64,
+    kh_get_uint64,
+    kh_init_uint64,
+    kh_destroy_pymap,
+    kh_exist_pymap,
+    kh_init_pymap,
+    kh_get_pymap,
+    kh_put_pymap,
+    kh_resize_pymap,
+)
 
 
 cimport pandas._libs.util as util
@@ -63,8 +82,9 @@ cdef class Factorizer:
     def get_count(self):
         return self.count
 
-    def factorize(self, ndarray[object] values, sort=False, na_sentinel=-1,
-                  na_value=None):
+    def factorize(
+        self, ndarray[object] values, sort=False, na_sentinel=-1, na_value=None
+    ):
         """
         Factorize values with nans replaced by na_sentinel
         >>> factorize(np.array([1,2,np.nan], dtype='O'), na_sentinel=20)
diff --git a/pandas/_libs/window/aggregations.pyx b/pandas/_libs/window/aggregations.pyx
index fe74d701e..f67581859 100644
--- a/pandas/_libs/window/aggregations.pyx
+++ b/pandas/_libs/window/aggregations.pyx
@@ -56,8 +56,9 @@ cdef:
 cdef inline int int_max(int a, int b): return a if a >= b else b
 cdef inline int int_min(int a, int b): return a if a <= b else b
 
-cdef inline bint is_monotonic_start_end_bounds(ndarray[int64_t, ndim=1] start,
-                                               ndarray[int64_t, ndim=1] end):
+cdef inline bint is_monotonic_start_end_bounds(
+    ndarray[int64_t, ndim=1] start, ndarray[int64_t, ndim=1] end
+):
     return is_monotonic(start, False)[0] and is_monotonic(end, False)[0]
 
 # Cython implementations of rolling sum, mean, variance, skewness,
@@ -90,8 +91,12 @@ cdef inline bint is_monotonic_start_end_bounds(ndarray[int64_t, ndim=1] start,
 # this is only an impl for index not None, IOW, freq aware
 
 
-def roll_count(ndarray[float64_t] values, ndarray[int64_t] start, ndarray[int64_t] end,
-               int64_t minp):
+def roll_count(
+    ndarray[float64_t] values,
+    ndarray[int64_t] start,
+    ndarray[int64_t] end,
+    int64_t minp,
+):
     cdef:
         float64_t val, count_x = 0.0
         int64_t s, e, nobs, N = len(values)
diff --git a/pandas/io/sas/sas.pyx b/pandas/io/sas/sas.pyx
index b4f8eeb3d..40fea0aaf 100644
--- a/pandas/io/sas/sas.pyx
+++ b/pandas/io/sas/sas.pyx
@@ -13,8 +13,7 @@ ctypedef unsigned short     uint16_t
 # algorithm.  It is partially documented here:
 #
 # https://cran.r-project.org/package=sas7bdat/vignettes/sas7bdat.pdf
-cdef const uint8_t[:] rle_decompress(int result_length,
-                                     const uint8_t[:] inbuff):
+cdef const uint8_t[:] rle_decompress(int result_length, const uint8_t[:] inbuff):
 
     cdef:
         uint8_t control_byte, x
@@ -117,8 +116,7 @@ cdef const uint8_t[:] rle_decompress(int result_length,
 # rdc_decompress decompresses data using the Ross Data Compression algorithm:
 #
 # http://collaboration.cmc.ec.gc.ca/science/rpn/biblio/ddj/Website/articles/CUJ/1992/9210/ross/ross.htm
-cdef const uint8_t[:] rdc_decompress(int result_length,
-                                     const uint8_t[:] inbuff):
+cdef const uint8_t[:] rdc_decompress(int result_length, const uint8_t[:] inbuff):
 
     cdef:
         uint8_t cmd
@@ -233,8 +231,7 @@ cdef class Parser:
         int subheader_pointer_length
         int current_page_type
         bint is_little_endian
-        const uint8_t[:] (*decompress)(int result_length,
-                                       const uint8_t[:] inbuff)
+        const uint8_t[:] (*decompress)(int result_length, const uint8_t[:] inbuff)
         object parser
 
     def __init__(self, object parser):
@@ -267,9 +264,7 @@ cdef class Parser:
             elif column_types[j] == b's':
                 self.column_types[j] = column_type_string
             else:
-                raise ValueError(
-                    f"unknown column type: {self.parser.columns[j].ctype}"
-                )
+                raise ValueError(f"unknown column type: {self.parser.columns[j].ctype}")
 
         # compression
         if parser.compression == const.rle_compression:
@@ -296,8 +291,7 @@ cdef class Parser:
 
         # update the parser
         self.parser._current_row_on_page_index = self.current_row_on_page_index
-        self.parser._current_row_in_chunk_index =\
-            self.current_row_in_chunk_index
+        self.parser._current_row_in_chunk_index = self.current_row_in_chunk_index
         self.parser._current_row_in_file_index = self.current_row_in_file_index
 
     cdef bint read_next_page(self):
@@ -318,9 +312,9 @@ cdef class Parser:
         self.current_page_type = self.parser._current_page_type
         self.current_page_block_count = self.parser._current_page_block_count
         self.current_page_data_subheader_pointers_len = len(
-            self.parser._current_page_data_subheader_pointers)
-        self.current_page_subheaders_count =\
-            self.parser._current_page_subheaders_count
+            self.parser._current_page_data_subheader_pointers
+        )
+        self.current_page_subheaders_count = self.parser._current_page_subheaders_count
 
     cdef readline(self):
 
@@ -358,19 +352,18 @@ cdef class Parser:
                 return False
             elif (self.current_page_type == page_mix_types_0 or
                     self.current_page_type == page_mix_types_1):
-                align_correction = (bit_offset + subheader_pointers_offset +
-                                    self.current_page_subheaders_count *
-                                    subheader_pointer_length)
+                align_correction = (
+                    bit_offset
+                    + subheader_pointers_offset
+                    + self.current_page_subheaders_count * subheader_pointer_length
+                )
                 align_correction = align_correction % 8
                 offset = bit_offset + align_correction
                 offset += subheader_pointers_offset
-                offset += (self.current_page_subheaders_count *
-                           subheader_pointer_length)
+                offset += self.current_page_subheaders_count * subheader_pointer_length
                 offset += self.current_row_on_page_index * self.row_length
-                self.process_byte_array_with_data(offset,
-                                                  self.row_length)
-                mn = min(self.parser.row_count,
-                         self.parser._mix_page_row_count)
+                self.process_byte_array_with_data(offset, self.row_length)
+                mn = min(self.parser.row_count, self.parser._mix_page_row_count)
                 if self.current_row_on_page_index == mn:
                     done = self.read_next_page()
                     if done:
@@ -378,11 +371,12 @@ cdef class Parser:
                 return False
             elif self.current_page_type & page_data_type == page_data_type:
                 self.process_byte_array_with_data(
-                    bit_offset + subheader_pointers_offset +
-                    self.current_row_on_page_index * self.row_length,
-                    self.row_length)
-                flag = (self.current_row_on_page_index ==
-                        self.current_page_block_count)
+                    bit_offset
+                    + subheader_pointers_offset
+                    + self.current_row_on_page_index * self.row_length,
+                    self.row_length,
+                )
+                flag = self.current_row_on_page_index == self.current_page_block_count
                 if flag:
                     done = self.read_next_page()
                     if done:
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index d31c23c7c..2808d74e6 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -2667,8 +2667,8 @@ def _delta_to_tick(delta: timedelta) -> Tick:
                 return Second(seconds)
     else:
         nanos = delta_to_nanoseconds(delta)
-        if nanos % 1000000 == 0:
-            return Milli(nanos // 1000000)
+        if nanos % 1_000_000 == 0:
+            return Milli(nanos // 1_000_000)
         elif nanos % 1000 == 0:
             return Micro(nanos // 1000)
         else:  # pragma: no cover
diff --git a/setup.py b/setup.py
index c33ce063c..6635b58cd 100755
--- a/setup.py
+++ b/setup.py
@@ -356,7 +356,7 @@ class CheckSDist(sdist_class):
                     sourcefile = pyxfile[:-3] + extension
                     msg = (
                         f"{extension}-source file '{sourcefile}' not found.\n"
-                        f"Run 'setup.py cython' before sdist."
+                        "Run 'setup.py cython' before sdist."
                     )
                     assert os.path.isfile(sourcefile), msg
         sdist_class.run(self)
