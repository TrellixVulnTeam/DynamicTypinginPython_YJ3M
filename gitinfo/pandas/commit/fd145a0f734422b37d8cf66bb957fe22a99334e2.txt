commit fd145a0f734422b37d8cf66bb957fe22a99334e2
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Aug 25 00:36:00 2011 -0400

    DOC: documentation pass on groupby and rest of pandas.core

diff --git a/pandas/core/api.py b/pandas/core/api.py
index 8daa089d2..ffe6298b6 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -5,11 +5,12 @@ import numpy as np
 from pandas.core.datetools import DateOffset
 import pandas.core.datetools as datetools
 
-from pandas.core.common import isnull, notnull
+from pandas.core.common import isnull, notnull, set_printoptions
 from pandas.core.index import Index, Factor, MultiIndex
 from pandas.core.daterange import DateRange
 from pandas.core.series import Series, TimeSeries
 from pandas.core.frame import DataFrame
 from pandas.core.panel import WidePanel, LongPanel, pivot
+from pandas.core.groupby import groupby
 
 DataMatrix = DataFrame
diff --git a/pandas/core/daterange.py b/pandas/core/daterange.py
index 5ed271665..0123f0ca1 100644
--- a/pandas/core/daterange.py
+++ b/pandas/core/daterange.py
@@ -40,6 +40,8 @@ class DateRange(Index):
     offset : DateOffset, default is 1 BusinessDay
         Used to determine the dates returned
     timeRule : timeRule to use
+    tzinfo : pytz.timezone
+        To endow DateRange with time zone information
     """
     _cache = {}
     def __new__(cls, start=None, end=None, periods=None,
@@ -433,7 +435,7 @@ def generate_range(start=None, end=None, periods=None,
 #         return False
 
 def _in_range(start, end, rng_start, rng_end):
-    return start > rng_start and end
+    return start > rng_start and end < rng_end
 
 def _naive_in_cache_range(start, end):
     if start is None or end is None:
diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index bec577b29..c92fd91d8 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -277,9 +277,10 @@ class BDay(DateOffset, CacheableOffset):
 
 
 class MonthEnd(DateOffset, CacheableOffset):
-    _normalizeFirst = True
     """DateOffset of one month end"""
 
+    _normalizeFirst = True
+
     def apply(self, other):
         n = self.n
         _, nDaysInMonth = calendar.monthrange(other.year, other.month)
@@ -323,6 +324,8 @@ class BMonthEnd(DateOffset, CacheableOffset):
 
 class Week(DateOffset, CacheableOffset):
     """
+    Weekly offset
+
     weekday
     0: Mondays
     1: Tuedays
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 3b0e61f0c..08d731ded 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -2043,44 +2043,6 @@ class DataFrame(NDFrame):
 
         return join_index
 
-    #----------------------------------------------------------------------
-    # groupby
-
-    def groupby(self, by=None, axis=0, level=None):
-        """
-        Group series using mapper (dict or key function, apply given function
-        to group, return result as series) or by a series of columns
-
-        Parameters
-        ----------
-        by : mapping function / list of functions, dict, Series, or tuple /
-            list of column names.
-            Called on each element of the object index to determine the groups.
-            If a dict or Series is passed, the Series or dict VALUES will be
-            used to determine the groups
-        axis : int, default 0
-        level : int, default None
-            If the axis is a MultiIndex (hierarchical), group by a particular
-            level
-
-        Examples
-        --------
-        # DataFrame result
-        >>> data.groupby(func, axis=0).mean()
-
-        # DataFrame result
-        >>> data.groupby(['col1', 'col2'])['col3'].mean()
-
-        # DataFrame with hierarchical index
-        >>> data.groupby(['col1', 'col2']).mean()
-
-        Returns
-        -------
-        GroupBy object
-        """
-        from pandas.core.groupby import groupby
-        return groupby(self, by, axis=axis, level=level)
-
     #----------------------------------------------------------------------
     # Statistical methods, etc.
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index a5ac9b5e8..66f9ef98a 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -80,24 +80,40 @@ class PandasObject(Picklable):
         name = self._get_axis_name(axis)
         return getattr(self, name)
 
-    def groupby(self, mapper=None, axis=0, level=None):
+    def groupby(self, by=None, axis=0, level=None):
         """
-        Goup series using mapper (dict or key function, apply given
-        function to group, return result as series).
+        Group series using mapper (dict or key function, apply given function
+        to group, return result as series) or by a series of columns
 
         Parameters
         ----------
-        mapper: function, dict or Series
-            Called on each element of the object index to determine
-            the groups.  If a dict or Series is passed, the Series or
-            dict VALUES will be used to determine the groups
+        by : mapping function / list of functions, dict, Series, or tuple /
+            list of column names.
+            Called on each element of the object index to determine the groups.
+            If a dict or Series is passed, the Series or dict VALUES will be
+            used to determine the groups
+        axis : int, default 0
+        level : int, default None
+            If the axis is a MultiIndex (hierarchical), group by a particular
+            level
+
+        Examples
+        --------
+        # DataFrame result
+        >>> data.groupby(func, axis=0).mean()
+
+        # DataFrame result
+        >>> data.groupby(['col1', 'col2'])['col3'].mean()
+
+        # DataFrame with hierarchical index
+        >>> data.groupby(['col1', 'col2']).mean()
 
         Returns
         -------
         GroupBy object
         """
         from pandas.core.groupby import groupby
-        return groupby(self, mapper, axis=axis, level=level)
+        return groupby(self, by, axis=axis, level=level)
 
     def truncate(self, before=None, after=None):
         """Function truncate a sorted DataFrame / Series before and/or after
@@ -161,6 +177,13 @@ class PandasObject(Picklable):
         new_axis = axis.drop(labels)
         return self.reindex(**{axis_name : new_axis})
 
+    @property
+    def ix(self):
+        raise NotImplementedError
+
+    def reindex(self, **kwds):
+        raise NotImplementedError
+
 class NDFrame(PandasObject):
     """
     N-dimensional analogue of DataFrame. Store multi-dimensional in a
@@ -204,7 +227,6 @@ class NDFrame(PandasObject):
         return self._data.axes
 
     def __repr__(self):
-        # TODO
         return 'NDFrame'
 
     @property
@@ -223,13 +245,13 @@ class NDFrame(PandasObject):
 
     def consolidate(self):
         """
-        Compute DataFrame with "consolidated" internals (data of each dtype
+        Compute NDFrame with "consolidated" internals (data of each dtype
         grouped together in a single ndarray). Mainly an internal API function,
         but available here to the savvy user
 
         Returns
         -------
-        consolidated : DataFrame
+        consolidated : type of caller
         """
         cons_data = self._data.consolidate()
         if cons_data is self._data:
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index eb0f6a13d..48d20a324 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -13,26 +13,76 @@ from pandas.util.decorators import cache_readonly
 import pandas._tseries as _tseries
 
 
-def groupby(obj, grouper, **kwds):
-    """
-    Intercepts creation and dispatches to the appropriate class based
-    on type.
+class GroupBy(object):
     """
-    if isinstance(obj, Series):
-        klass = SeriesGroupBy
-    elif isinstance(obj, DataFrame):
-        klass = DataFrameGroupBy
-    else: # pragma: no cover
-        raise TypeError('invalid type: %s' % type(obj))
+    Class for grouping and aggregating relational data. See aggregate,
+    transform, and apply functions on this object.
 
-    return klass(obj, grouper, **kwds)
+    It's easiest to use obj.groupby(...) to use GroupBy, but you can also do:
 
-class GroupBy(object):
-    """
-    Class for grouping and aggregating relational data.
+    Parameters
+    ----------
+    obj : pandas object
+    axis : int, default 0
+    level : int, default None
+        Level of MultiIndex
+    groupings : list of Grouping objects
+        Most users should ignore this
+    exclusions : array-like, optional
+        List of columns to exclude
+    name : string
+        Most users should ignore this
+
+    Notes
+    -----
+    After grouping, see aggregate, apply, and transform functions. Here are
+    some other brief notes about usage:
+
+      * When grouping by multiple groups, the result index will be a MultiIndex
+        (hierarhical) by default.
+
+      * Iteration produces (key, group) tuples, i.e. chunking the data by
+        group. So you can write code like:
+
+        grouped = obj.groupby(grouper, axis=axis)
+        for key, group in grouped:
+            # do something with the data
+
+      * Function calls on GroupBy, if not specially implemented, "dispatch" to
+        the grouped data. So if you group a DataFrame and wish to invoke the
+        std() method on each group, you can simply do:
+
+        df.groupby(mapper).std()
+
+        rather than
+
+        df.groupby(mapper).aggregate(np.std)
+
+        You can pass arguments to these "wrapped" functions, too.
+
+    See the online documentation for full exposition on these topics and much
+    more
 
-    Supported classes: Series, DataFrame
+    Returns
+    -------
+    **Attributes**
+    groups : dict
+        {group name -> group labels}
+    len(grouped) : int
+        Number of groups
     """
+    def __new__(cls, obj, **kwargs):
+        if isinstance(obj, Series):
+            klass = SeriesGroupBy
+        elif isinstance(obj, DataFrame):
+            klass = DataFrameGroupBy
+        elif isinstance(obj, WidePanel):
+            klass = WidePanelGroupBy
+        else: # pragma: no cover
+            raise TypeError('invalid type: %s' % type(obj))
+
+        return klass(obj, **kwds)
+
     def __init__(self, obj, grouper=None, axis=0, level=None,
                  groupings=None, exclusions=None, name=None):
         self._name = name
@@ -168,7 +218,40 @@ class GroupBy(object):
 
     def apply(self, func):
         """
-        Apply function, combine results together
+        Apply function and combine results together in an intelligent way. The
+        split-apply-combine combination rules attempt to be as common sense
+        based as possible. For example:
+
+        case 1:
+        group DataFrame
+        apply aggregation function (f(chunk) -> Series)
+        yield DataFrame, with group axis having group labels
+
+        case 2:
+        group DataFrame
+        apply transform function ((f(chunk) -> DataFrame with same indexes)
+        yield DataFrame with resulting chunks glued together
+
+        case 3:
+        group Series
+        apply function with f(chunk) -> DataFrame
+        yield DataFrame with result of chunks glued together
+
+        Parameters
+        ----------
+        func : function
+
+        Notes
+        -----
+        See online documentation for full exposition on how to use apply
+
+        See also
+        --------
+        aggregate, transform
+
+        Returns
+        -------
+        applied : type depending on grouped object and function
         """
         return self._python_apply_general(func)
 
@@ -176,10 +259,13 @@ class GroupBy(object):
         raise NotImplementedError
 
     def agg(self, func):
+        """
+        See docstring for aggregate
+        """
         return self.aggregate(func)
 
     def _get_names(self):
-        axes = [ping.levels for ping in self.groupings]
+        axes = [ping.group_index for ping in self.groupings]
         grouping_names = [ping.name for ping in self.groupings]
         shape = self._group_shape
         return zip(grouping_names, _ravel_names(axes, shape))
@@ -193,12 +279,16 @@ class GroupBy(object):
     def mean(self):
         """
         Compute mean of groups, excluding missing values
+
+        For multiple groupings, the result index will be a MultiIndex
         """
         return self._cython_agg_general('mean')
 
     def sum(self):
         """
         Compute sum of values, excluding missing values
+
+        For multiple groupings, the result index will be a MultiIndex
         """
         try:
             return self._cython_agg_general('add')
@@ -326,6 +416,17 @@ class GroupBy(object):
                                            axis=self.axis,
                                            factory=factory)
 
+def groupby(obj, by, **kwds):
+    if isinstance(obj, Series):
+        klass = SeriesGroupBy
+    elif isinstance(obj, DataFrame):
+        klass = DataFrameGroupBy
+    else: # pragma: no cover
+        raise TypeError('invalid type: %s' % type(obj))
+
+    return klass(obj, by, **kwds)
+groupby.__doc__ = GroupBy.__doc__
+
 def _is_indexed_like(obj, other):
     if isinstance(obj, Series):
         if not isinstance(other, Series):
@@ -342,7 +443,20 @@ def _is_indexed_like(obj, other):
     return False
 
 class Grouping(object):
+    """
+    Holds the grouping information for a single key
 
+    Returns
+    -------
+    **Attributes**:
+      * indices : dict of {group -> index_list}
+      * labels : ndarray, group labels
+      * ids : mapping of label -> group
+      * reverse_ids : mapping of group -> label
+      * counts : array of group counts
+      * group_index : unique groups
+      * groups : dict of {group -> label_list}
+    """
     def __init__(self, index, grouper=None, name=None, level=None):
         self.name = name
         self.level = level
@@ -363,8 +477,6 @@ class Grouping(object):
         if not isinstance(self.grouper, np.ndarray):
             self.grouper = _tseries.arrmap(self.index, self.grouper)
 
-        self.indices = _tseries.groupby_indices(self.grouper)
-
     def __repr__(self):
         return 'Grouping(%s)' % self.name
 
@@ -375,6 +487,10 @@ class Grouping(object):
     _ids = None
     _counts = None
 
+    @cache_readonly
+    def indices(self):
+        return _tseries.groupby_indices(self.grouper)
+
     @property
     def labels(self):
         if self._labels is None:
@@ -391,10 +507,6 @@ class Grouping(object):
     def reverse_ids(self):
         return dict((v, k) for k, v in self.ids.iteritems())
 
-    @property
-    def levels(self):
-        return [self.ids[k] for k in sorted(self.ids)]
-
     @property
     def counts(self):
         if self._counts is None:
@@ -403,8 +515,7 @@ class Grouping(object):
 
     @cache_readonly
     def group_index(self):
-        # XXX
-        return Index(Series(self.ids, index=np.arange(len(self.ids))).values)
+        return Index([self.ids[i] for i in range(len(self.ids))])
 
     def _make_labels(self):
         ids, labels, counts  = _tseries.group_labels(self.grouper)
@@ -471,46 +582,70 @@ class SeriesGroupBy(GroupBy):
     def _agg_stride_shape(self):
         return ()
 
-    # def get_group(self, name, obj=None):
-    #     # faster get_group for Series
-    #     if obj is None:
-    #         obj = self.obj
-
-    #     inds = self.primary.indices[name]
-    #     return obj.take(inds)
-
-    def aggregate(self, arg):
+    def aggregate(self, func_or_funcs):
         """
-        See doc for DataFrame.groupby, group series using mapper (dict or key
-        function, apply given function to group, return result as series).
-
-        Main difference here is that applyfunc must return a value, so that the
-        result is a sensible series.
+        Apply aggregation function or functions to groups, yielding most likely
+        Series but in some cases DataFrame depending on the output of the
+        aggregation function
 
         Parameters
         ----------
-        mapper : function
-            Called on each element of the Series index to determine the groups
-        arg : function
-            Function to use to aggregate each group
+        func_or_funcs : function or list / dict of functions
+            List/dict of functions will produce DataFrame with column names
+            determined by the function names themselves (list) or the keys in
+            the dict
+
+        Notes
+        -----
+        agg is an alias for aggregate. Use it.
+
+        Example
+        -------
+        >>> series
+        bar    1.0
+        baz    2.0
+        qot    3.0
+        qux    4.0
+
+        >>> mapper = lambda x: x[0] # first letter
+        >>> grouped = series.groupby(mapper)
+
+        >>> grouped.aggregate(np.sum)
+        b    3.0
+        q    7.0
+
+        >>> grouped.aggregate([np.sum, np.mean, np.std])
+           mean  std  sum
+        b  1.5   0.5  3
+        q  3.5   0.5  7
+
+        >>> grouped.agg({'result' : lambda x: x.mean() / x.std(),
+                         'total' : np.sum})
+           result  total
+        b  2.121   3
+        q  4.95    7
+
+        See also
+        --------
+        apply, transform
 
         Returns
         -------
         Series or DataFrame
         """
-        if isinstance(arg, basestring):
-            return getattr(self, arg)()
+        if isinstance(func_or_funcs, basestring):
+            return getattr(self, func_or_funcs)()
 
         if len(self.groupings) > 1:
-            return self._python_agg_general(arg)
+            return self._python_agg_general(func_or_funcs)
 
-        if hasattr(arg,'__iter__'):
-            ret = self._aggregate_multiple_funcs(arg)
+        if hasattr(func_or_funcs,'__iter__'):
+            ret = self._aggregate_multiple_funcs(func_or_funcs)
         else:
             try:
-                result = self._aggregate_simple(arg)
+                result = self._aggregate_simple(func_or_funcs)
             except Exception:
-                result = self._aggregate_named(arg)
+                result = self._aggregate_named(func_or_funcs)
 
             if len(result) > 0:
                 if isinstance(result.values()[0], Series):
@@ -597,33 +732,21 @@ class SeriesGroupBy(GroupBy):
 
     def transform(self, func):
         """
-        For given Series, group index by given mapper function or dict, take
-        the sub-Series (reindex) for this group and call apply(applyfunc)
-        on this sub-Series. Return a Series of the results for each
-        key.
+        Call function producing a like-indexed Series on each group and return
+        a Series with the transformed values
 
         Parameters
         ----------
-        mapper : function
-            on being called on each element of the Series
-            index, determines the groups.
-
-        applyfunc : function to apply to each group
-
-        Note
-        ----
-        This function does not aggregate like groupby/tgroupby,
-        the results of the given function on the subSeries should be another
-        Series.
+        func : function
+            To apply to each group. Should return a Series with the same index
 
         Example
         -------
-        series.transform(lambda x: mapping[x],
-                         lambda x: (x - x.mean()) / x.std())
+        >>> grouped.transform(lambda x: (x - x.mean()) / x.std())
 
         Returns
         -------
-        Series standardized by each unique value of mapping
+        transformed : Series
         """
         result = self.obj.copy()
 
@@ -693,7 +816,6 @@ class DataFrameGroupBy(GroupBy):
         Parameters
         ----------
         arg : function or dict
-
             Function to use for aggregating groups. If a function, must either
             work when passed a DataFrame or when passed to DataFrame.apply. If
             pass a dict, the keys must be DataFrame column names
@@ -798,20 +920,12 @@ class DataFrameGroupBy(GroupBy):
 
     def transform(self, func):
         """
-        For given DataFrame, group index by given mapper function or dict, take
-        the sub-DataFrame (reindex) for this group and call apply(func)
-        on this sub-DataFrame. Return a DataFrame of the results for each
-        key.
-
-        Note: this function does not aggregate like groupby/tgroupby,
-        the results of the given function on the subDataFrame should be another
-        DataFrame.
+        Call function producing a like-indexed DataFrame on each group and
+        return a DataFrame having the same indexes as the original object
+        filled with the transformed values
 
         Parameters
         ----------
-        mapper : function, dict-like, or string
-            Mapping or mapping function. If string given, must be a column
-            name in the frame
         func : function
             Function to apply to each subframe
 
@@ -933,23 +1047,18 @@ class WidePanelGroupBy(GroupBy):
 
     def aggregate(self, func):
         """
-        For given DataFrame, group index by given mapper function or dict, take
-        the sub-DataFrame (reindex) for this group and call apply(func)
-        on this sub-DataFrame. Return a DataFrame of the results for each
-        key.
+        Aggregate using input function or dict of {column -> function}
 
         Parameters
         ----------
-        mapper : function, dict-like, or string
-            Mapping or mapping function. If string given, must be a column
-            name in the frame
-        func : function
-            Function to use for aggregating groups
-
-        N.B.: func must produce one value from a Series, otherwise
-        an error will occur.
+        arg : function or dict
+            Function to use for aggregating groups. If a function, must either
+            work when passed a WidePanel or when passed to WidePanel.apply. If
+            pass a dict, the keys must be DataFrame column names
 
-        Optional: provide set mapping as dictionary
+        Returns
+        -------
+        aggregated : WidePanel
         """
         return self._aggregate_generic(func, axis=self.axis)
 
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 2831dc205..8ff8c574e 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -134,18 +134,6 @@ def _sparse_fillop(this, other, name):
 
     return result, result_index
 
-"""
-Notes.
-
-- Not sure if subclassing is the way to go, could just lead to trouble on down
-  the road (e.g. if putting a SparseSeries in a regular DataFrame...). But on
-  the other hand you do get many things for free...
-
-- Will need to "disable" a number of methods?
-"""
-
-# from line_profiler import LineProfiler
-# prof = LineProfiler()
 
 class SparseSeries(Series):
     """
@@ -157,12 +145,14 @@ class SparseSeries(Series):
     kind : {'block', 'integer'}
     fill_value : float
         Defaults to NaN (code for missing)
+    sparse_index : {BlockIndex, IntIndex}, optional
+        Only if you have one. Mainly used internally
 
     Notes
     -----
-    SparseSeries objects are immutable via the typical Python means. If you must
-    change values, convert to dense, make your changes, then convert back to
-    sparse
+    SparseSeries objects are immutable via the typical Python means. If you
+    must change values, convert to dense, make your changes, then convert back
+    to sparse
     """
     __array_priority__ = 15
 
@@ -370,7 +360,7 @@ class SparseSeries(Series):
 
         Returns
         -------
-        y : ndarray
+        taken : ndarray
         """
         indices = np.asarray(indices, dtype=int)
 
@@ -408,11 +398,20 @@ class SparseSeries(Series):
         else:
             return Series(self.values, index=self.index)
 
-    def astype(self, dtype):
-        # HACK?
+    def astype(self, dtype=None):
+        """
+
+        """
+        if dtype is not None and dtype not in (np.float_, float):
+            raise Exception('Can only support floating point data')
+
         return self.copy()
 
     def copy(self):
+        """
+        Make a copy of the SparseSeries. Only the actual sparse values need to
+        be copied
+        """
         values = self.sp_values.copy()
         return SparseSeries(values, index=self.index,
                             sparse_index=self.sp_index,
@@ -471,17 +470,20 @@ class SparseSeries(Series):
         new_values = self.sp_index.to_int_index().reindex(self.sp_values,
                                                           self.fill_value,
                                                           new_index)
-
-        # indexer = self.sp_index.get_indexer(new_index)
-
-        # new_values = self.sp_values.take(indexer)
-        # new_values[indexer == -1] = self.fill_value
-
         return SparseSeries(new_values, index=self.index,
                             sparse_index=new_index,
                             fill_value=self.fill_value)
 
     def count(self):
+        """
+        Compute sum of non-NA/null observations in SparseSeries. If the
+        fill_value is not NaN, the "sparse" locations will be included in the
+        observation count
+
+        Returns
+        -------
+        nobs : int
+        """
         sp_values = self.sp_values
         valid_spvals = np.isfinite(sp_values).sum()
         if self._null_fill_value:
@@ -501,7 +503,11 @@ class SparseSeries(Series):
 
     def sum(self, axis=None, dtype=None, out=None):
         """
-        Sum of non-null values
+        Sum of non-NA/null values
+
+        Returns
+        -------
+        sum : float
         """
         valid_vals = self._valid_sp_values
         sp_sum = valid_vals.sum()
@@ -513,13 +519,13 @@ class SparseSeries(Series):
 
     def cumsum(self, axis=0, dtype=None, out=None):
         """
-        Cumulative sum of values. Preserves NaN values
+        Cumulative sum of values. Preserves locations of NaN values
 
         Extra parameters are to preserve ndarray interface.
 
         Returns
         -------
-
+        cumsum : Series
         """
         if not np.isnan(self.fill_value):
             return self.to_dense().cumsum()
@@ -530,7 +536,11 @@ class SparseSeries(Series):
 
     def mean(self, axis=None, dtype=None, out=None):
         """
-        Mean of non-null values
+        Mean of non-NA/null values
+
+        Returns
+        -------
+        mean : float
         """
         valid_vals = self._valid_sp_values
         sp_sum = valid_vals.sum()
@@ -595,6 +605,18 @@ class SparseDataFrame(DataFrame):
     """
     DataFrame containing sparse floating point data in the form of SparseSeries
     objects
+
+    Parameters
+    ----------
+    data : same types as can be passed to DataFrame
+    index : array-like, optional
+    column : array-like, optional
+    default_kind : {'block', 'integer'}, default 'block'
+        Default sparse kind for converting Series to SparseSeries. Will not
+        override SparseSeries passed into constructor
+    default_fill_value : float
+        Default fill_value for converting Series to SparseSeries. Will not
+        override SparseSeries passed in
     """
     _columns = None
     _series = None
@@ -763,7 +785,7 @@ class SparseDataFrame(DataFrame):
 
     def copy(self):
         """
-        Make a deep copy of this frame
+        Make a deep copy of this SparseDataFrame
         """
         return SparseDataFrame(self._series, index=self.index,
                                columns=self.columns,
@@ -893,7 +915,8 @@ class SparseDataFrame(DataFrame):
 
     def xs(self, key):
         """
-        Returns a row from the DataFrame as a Series object.
+        Returns a row (cross-section) from the SparseDataFrame as a Series
+        object.
 
         Parameters
         ----------
@@ -901,7 +924,7 @@ class SparseDataFrame(DataFrame):
 
         Returns
         -------
-        Series
+        xs : Series
         """
         i = self.index.get_loc(key)
         series = self._series
@@ -1070,23 +1093,8 @@ class SparseDataFrame(DataFrame):
     T = property(transpose)
 
     def count(self, axis=0, **kwds):
-        """
-        Return array or Series of # observations over requested axis.
-
-        Parameters
-        ----------
-        axis : {0, 1}
-            0 for row-wise, 1 for column-wise
-
-        Notes
-        -----
-        Also examines non-float data and checks for None and NaN in such data
-
-        Returns
-        -------
-        Series or TimeSeries
-        """
         return self.apply(SparseSeries.count, axis=axis)
+    count.__doc__ = DataFrame.count.__doc__
 
     def cumsum(self, axis=0):
         """
@@ -1290,8 +1298,12 @@ class SparseWidePanel(WidePanel):
     items : array-like
     major_axis : array-like
     minor_axis : array-like
-    default_fill_value : float, default NaN
-    default_kind : {'block', 'integer'}
+    default_kind : {'block', 'integer'}, default 'block'
+        Default sparse kind for converting Series to SparseSeries. Will not
+        override SparseSeries passed into constructor
+    default_fill_value : float
+        Default fill_value for converting Series to SparseSeries. Will not
+        override SparseSeries passed in
 
     Notes
     -----
@@ -1334,7 +1346,10 @@ class SparseWidePanel(WidePanel):
         pass
 
     @classmethod
-    def from_dict(cls, data, intersect=False):
+    def from_dict(cls, data):
+        """
+        Analogous to WidePanel.from_dict
+        """
         return SparseWidePanel(data)
 
     def to_dense(self):
diff --git a/pandas/info.py b/pandas/info.py
index 2bbff9663..92a5f95b5 100644
--- a/pandas/info.py
+++ b/pandas/info.py
@@ -1,33 +1,17 @@
 """
-Pandas - a library for panel, time series, or cross-sectional data analysis
-===========================================================================
+pandas - a powerful data analysis and manipulation library for Python
+=====================================================================
 
-Main data structures (see docstrings for detailed documentation)
---------------------
-Index
-    Represent row or column labels in Series / DataFrame structures
-
-Series / TimeSeries
-    Represents standard 1-dimensional cross-section (resp. time series)
-    As an numpy.ndarray subclass, compatible with ufuncs and other NumPy
-    functions
+See http://pandas.sourceforge.net for full documentation. Otherwise, see the
+docstrings of the various objects in the pandas namespace:
 
+Series
 DataFrame
-    Represents collections of Series objects, enable easy management
-    of multiple time series / cross-sections
-
+WidePanel
+Index
 DateRange
-    Index subclass for generating arrays of fixed frequency dates
-
-Subpackages
------------
-core
-    Implementations of core data structures, basic building blocks. Most of
-    the user-relevant code is accessible through the top-level namespace
-io
-    Persistence, parsing, and data loading tools
-lib
-    C, Cython, and Fortran extensions for other components
-stats
-    Statistical and econometric functions
+HDFStore
+read_csv
+read_talbe
+ols
 """
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 997b0f0c7..5a1f60973 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -594,22 +594,28 @@ class CheckIndexing(object):
     def test_setitem_boolean_missing(self):
         pass
 
-class TestDataFrame(unittest.TestCase, CheckIndexing):
-    klass = DataFrame
+_seriesd = tm.getSeriesData()
+_tsd = tm.getTimeSeriesData()
 
-    def setUp(self):
-        self.seriesd = tm.getSeriesData()
-        self.tsd = tm.getTimeSeriesData()
+_frame = DataFrame(_seriesd)
+_frame2 = DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])
+_intframe = DataFrame(dict((k, v.astype(int))
+                           for k, v in _seriesd.iteritems()))
 
-        self.frame = DataFrame(self.seriesd)
-        self.frame2 = DataFrame(self.seriesd, columns=['D', 'C', 'B', 'A'])
-        self.intframe = DataFrame(dict((k, v.astype(int))
-                                        for k, v in self.seriesd.iteritems()))
+_tsframe = DataFrame(_tsd)
 
-        self.tsframe = DataFrame(self.tsd)
+_mixed_frame = _frame.copy()
+_mixed_frame['foo'] = 'bar'
 
-        self.mixed_frame = self.frame.copy()
-        self.mixed_frame['foo'] = 'bar'
+class TestDataFrame(unittest.TestCase, CheckIndexing):
+    klass = DataFrame
+
+    def setUp(self):
+        self.frame = _frame.copy()
+        self.frame2 = _frame2.copy()
+        self.intframe = _intframe.copy()
+        self.tsframe = _tsframe.copy()
+        self.mixed_frame = _mixed_frame.copy()
 
         self.ts1 = tm.makeTimeSeries()
         self.ts2 = tm.makeTimeSeries()[5:]
@@ -624,13 +630,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         }
         self.empty = DataFrame({})
 
-        self.unsortable = DataFrame(
-            {'foo' : [1] * 1000,
-             datetime.today() : [1] * 1000,
-             'bar' : ['bar'] * 1000,
-             datetime.today() + timedelta(1) : ['bar'] * 1000},
-            index=np.arange(1000))
-
         arr = np.array([[1., 2., 3.],
                         [4., 5., 6.],
                         [7., 8., 9.]])
@@ -1053,7 +1052,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.empty.info(buf=buf)
 
         # columns are not sortable
-        foo = repr(self.unsortable)
+
+        unsortable = DataFrame({'foo' : [1] * 50,
+                                datetime.today() : [1] * 50,
+                                'bar' : ['bar'] * 50,
+                                datetime.today() + timedelta(1) : ['bar'] * 50},
+                               index=np.arange(50))
+        foo = repr(unsortable)
 
         import pandas.core.common as common
         common.set_printoptions(precision=3, column_space=10)
diff --git a/pandas/tests/test_sparse.py b/pandas/tests/test_sparse.py
index db726c170..fdfec2cf9 100644
--- a/pandas/tests/test_sparse.py
+++ b/pandas/tests/test_sparse.py
@@ -218,7 +218,7 @@ class TestSparseSeries(TestCase):
         assert_equal(sp_series.values, arr)
 
     def test_copy_astype(self):
-        cop = self.bseries.astype(np.int32)
+        cop = self.bseries.astype(np.float_)
         self.assert_(cop is not self.bseries)
         self.assert_(cop.sp_index is self.bseries.sp_index)
         self.assert_(cop.dtype == np.float64)
