commit 31c2558b33d727d6bd2fcb21f97e49d5a016513f
Author: Michael Mueller <michaeldmueller7@gmail.com>
Date:   Fri Sep 19 11:36:22 2014 -0400

    Squashed commit of the following:
    
    commit 0e9d792fc9d5159179efd810a1092671dbbef3b1
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Wed Sep 17 14:49:31 2014 -0400
    
        Added warnings about API changes
    
    commit 06472c21000b489841cc8e486ceddf05fd87a1c5
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Fri Sep 12 22:36:06 2014 -0400
    
        Changed parameter name to skip_blank_lines
    
    commit afd3be30b4afcae0d9bc6278237aab6a4c9e7eb8
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Fri Sep 12 21:50:08 2014 -0400
    
        Minor doc changes
    
    commit b47876e074f5f683a9a51768e480e24d9d3249ab
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Fri Sep 12 19:26:22 2014 -0400
    
        Extended blank line skipping to custom line terminated/whitespace delimited reading
    
    commit 3f4a20a831b1bc0ca29779b315dc72d78ad2301e
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Fri Sep 12 11:35:17 2014 -0400
    
        Changed around io docs section
    
    commit 223e17ecdcbe377cc69fd962221e03412f5e54d3
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Tue Sep 9 23:13:37 2014 -0400
    
        Turned empty line skipping into a keyword parameter feature
    
    commit dcd31ca6bd0849eab87ea1c3c5441c8630ca3a35
    Author: Michael Mueller <michaeldmueller7@gmail.com>
    Date:   Wed Sep 3 21:35:09 2014 -0400
    
        Squashed commit of the following:
    
        commit 9aea77954681c2f7d1336d94366221222d186c2b
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Tue Aug 26 22:43:21 2014 -0400
    
            Fixed header/skiprows combination issue
    
        commit 1975affea3bf0bd6f1769a79e4b0c7fde17962df
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Wed Jun 25 19:35:24 2014 -0400
    
            Added warning/notes about functionality change in docs, removed HTML changes
    
        commit 693c820092d9f17f9101074d29c2d7d53fa5a8ae
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Wed Jun 25 15:38:41 2014 -0400
    
            Fixed problem with HTML reading and infinite loop in PythonParser __init__
    
        commit 2a0a4babac7a5e53279eaa8281d0a51406caeb27
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Mon Jun 23 08:37:33 2014 -0400
    
            Updated docs with new read_csv functionality, removed unreachable code
    
        commit 19b5811e8d78c4e618e19ff5768aa2cfff041620
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Wed Jun 18 21:43:47 2014 -0400
    
            Fixed error in empty/whitespace removal function
    
        commit 3fd11a822cc0bee123d68240c62627da11ee88c2
        Author: Michael Mueller <michaeldmueller7@gmail.com>
        Date:   Wed Jun 18 18:48:08 2014 -0400
    
            Squashed commit of the following:
    
            commit 60a1cd1bc1042a9959ae75ff006052c433d98825
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Wed Jun 18 18:40:17 2014 -0400
    
                Fixed error with string/numerical types
    
            commit 7fe1bcf75466ea2b19d947aff0769c9f03bc23f5
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Wed Jun 18 17:47:56 2014 -0400
    
                release notes
    
            commit 835e490c8d3a3a96aeb6a6c3846217d36469656b
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Wed Jun 18 17:15:17 2014 -0400
    
                Release note
    
            commit 25cee3167b81b9c81e969629cd83968c6736a94f
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Wed Jun 18 16:56:44 2014 -0400
    
                Fixed whitespace issue, made C parser check for delimiters in whitespace lines
    
            commit 593495eb15162833de78d2da65f377fa977ad225
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Wed Jun 18 15:41:52 2014 -0400
    
                Added new functionality to Python reader
    
            commit 8a8325ed883034f176c929b41fe6fad16420e9b5
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Tue Jun 17 19:52:41 2014 -0400
    
                Adjusted tokenizer to ignore whitespace-only lines, fixed tests
    
            commit 3ea2eed22884a63a6e8dec1b795acdf29b030949
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Mon Jun 16 12:36:14 2014 -0400
    
                Moved tests to C parsing suite, corrected multi-index test
    
            commit d5540311ca44992148932ae27e16fc4d02a2a018
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Mon Jun 16 12:35:46 2014 -0400
    
                Changed empty file handling so that a ValueError is raised as expected
    
            commit 03a4c3d27c18052f04bd7cb862d289eabbc773ba
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Sun Jun 15 23:07:17 2014 -0400
    
                Wrote tests for empty lines and comment lines
    
            commit 01db817e97fc8ee0da85cc17603578b56d294b1b
            Author: Michael Mueller <michaeldmueller7@gmail.com>
            Date:   Sun Jun 15 23:02:04 2014 -0400
    
                Modified C tokenizer so that comments and empty lines are ignored

diff --git a/doc/source/install.rst b/doc/source/install.rst
index 1994bdf8c..2dfda3be0 100644
--- a/doc/source/install.rst
+++ b/doc/source/install.rst
@@ -276,7 +276,7 @@ Optional Dependencies
 ~~~~~~~~~~~~~~~~~~~~~
 
 * `Cython <http://www.cython.org>`__: Only necessary to build development
-  version. Version 0.17.1 or higher.
+  version. Version 0.19.1 or higher.
 * `SciPy <http://www.scipy.org>`__: miscellaneous statistical functions
 * `PyTables <http://www.pytables.org>`__: necessary for HDF5-based storage. Version 3.0.0 or higher required.
 * `SQLAlchemy <http://www.sqlalchemy.org>`__: for SQL database support. Version 0.8.1 or higher recommended.
diff --git a/doc/source/io.rst b/doc/source/io.rst
index b467e6243..46a68e53c 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -100,8 +100,10 @@ They can take a number of arguments:
     a list of integers that specify row locations for a multi-index on the columns
     E.g. [0,1,3]. Intervening rows that are not specified will be
     skipped (e.g. 2 in this example are skipped). Note that this parameter
-    ignores commented lines, so header=0 denotes the first line of
-    data rather than the first line of the file.
+    ignores commented lines and empty lines if ``skip_blank_lines=True`` (the default),
+    so header=0 denotes the first line of data rather than the first line of the file.
+  - ``skip_blank_lines``: whether to skip over blank lines rather than interpreting
+    them as NaN values
   - ``skiprows``: A collection of numbers for rows in the file to skip. Can
     also be an integer to skip the first ``n`` rows
   - ``index_col``: column number, column name, or list of column numbers/names,
@@ -149,7 +151,7 @@ They can take a number of arguments:
   - ``escapechar`` : string, to specify how to escape quoted data
   - ``comment``: Indicates remainder of line should not be parsed. If found at the
     beginning of a line, the line will be ignored altogether. This parameter
-    must be a single character. Also, fully commented lines
+    must be a single character. Like empty lines, fully commented lines
     are ignored by the parameter `header` but not by `skiprows`. For example,
     if comment='#', parsing '#empty\n1,2,3\na,b,c' with `header=0` will
     result in '1,2,3' being treated as the header.
@@ -266,27 +268,6 @@ after a delimiter:
    print(data)
    pd.read_csv(StringIO(data), skipinitialspace=True)
 
-Moreover, ``read_csv`` ignores any completely commented lines:
-
-.. ipython:: python
-
-   data = 'a,b,c\n# commented line\n1,2,3\n#another comment\n4,5,6'
-   print(data)
-   pd.read_csv(StringIO(data), comment='#')
-
-.. note::
-
-   The presence of ignored lines might create ambiguities involving line numbers;
-   the parameter ``header`` uses row numbers (ignoring commented
-   lines), while ``skiprows`` uses line numbers (including commented lines):
-
-   .. ipython:: python
-
-      data = '#comment\na,b,c\nA,B,C\n1,2,3'
-      pd.read_csv(StringIO(data), comment='#', header=1)
-      data = 'A,B,C\n#comment\na,b,c\n1,2,3'
-      pd.read_csv(StringIO(data), comment='#', skiprows=2)
-
 The parsers make every attempt to "do the right thing" and not be very
 fragile. Type inference is a pretty big deal. So if a column can be coerced to
 integer dtype without altering the contents, it will do so. Any non-numeric
@@ -363,6 +344,50 @@ file, either using the column names or position numbers:
     pd.read_csv(StringIO(data), usecols=['b', 'd'])
     pd.read_csv(StringIO(data), usecols=[0, 2, 3])
 
+.. _io.skiplines:
+
+Ignoring line comments and empty lines
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+If the ``comment`` parameter is specified, then completely commented lines will
+be ignored. By default, completely blank lines will be ignored as well. Both of
+these are API changes introduced in version 0.15.
+
+.. ipython:: python
+
+   data = '\na,b,c\n  \n# commented line\n1,2,3\n\n4,5,6'
+   print(data)
+   pd.read_csv(StringIO(data), comment='#')
+
+If ``skip_blank_lines=False``, then ``read_csv`` will not ignore blank lines:
+
+.. ipython:: python
+
+   data = 'a,b,c\n\n1,2,3\n\n\n4,5,6'
+   pd.read_csv(StringIO(data), skip_blank_lines=False)
+
+.. warning::
+
+   The presence of ignored lines might create ambiguities involving line numbers;
+   the parameter ``header`` uses row numbers (ignoring commented/empty
+   lines), while ``skiprows`` uses line numbers (including commented/empty lines):
+
+   .. ipython:: python
+
+      data = '#comment\na,b,c\nA,B,C\n1,2,3'
+      pd.read_csv(StringIO(data), comment='#', header=1)
+      data = 'A,B,C\n#comment\na,b,c\n1,2,3'
+      pd.read_csv(StringIO(data), comment='#', skiprows=2)
+
+   If both ``header`` and ``skiprows`` are specified, ``header`` will be
+   relative to the end of ``skiprows``. For example:
+
+   .. ipython:: python
+
+      data = '# empty\n# second empty line\n# third empty' \
+                'line\nX,Y,Z\n1,2,3\nA,B,C\n1,2.,4.\n5.,NaN,10.0'
+      print(data)
+      pd.read_csv(StringIO(data), comment='#', skiprows=4, header=1)
+
 .. _io.unicode:
 
 Dealing with Unicode Data
diff --git a/doc/source/v0.15.0.txt b/doc/source/v0.15.0.txt
index 5465b308a..1aa0f0de3 100644
--- a/doc/source/v0.15.0.txt
+++ b/doc/source/v0.15.0.txt
@@ -153,6 +153,11 @@ API changes
 
     ewma(s, com=3., min_periods=2)
 
+- Made both the C-based and Python engines for `read_csv` and `read_table` ignore empty lines in input as well as
+  whitespace-filled lines, as long as `sep` is not whitespace. This is an API change
+  that can be controlled by the keyword parameter `skip_blank_lines`.
+  (:issue:`4466`, see :ref:`skiplines <_io.skiplines>`)
+
 - :func:`ewmstd`, :func:`ewmvol`, :func:`ewmvar`, :func:`ewmcov`, and :func:`ewmcorr`
   now have an optional ``adjust`` argument, just like :func:`ewma` does,
   affecting how the weights are calculated.
@@ -680,8 +685,6 @@ Enhancements
 
 
 
-
-
 - ``tz_localize`` now accepts the ``ambiguous`` keyword which allows for passing an array of bools
   indicating whether the date belongs in DST or not, 'NaT' for setting transition times to NaT,
   'infer' for inferring DST/non-DST, and 'raise' (default) for an AmbiguousTimeError to be raised (:issue:`7943`).
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index e0243964c..72d8b2720 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -65,8 +65,8 @@ header : int row number(s) to use as the column names, and the start of the
     a list of integers that specify row locations for a multi-index on the
     columns E.g. [0,1,3]. Intervening rows that are not specified will be
     skipped (e.g. 2 in this example are skipped). Note that this parameter
-    ignores commented lines, so header=0 denotes the first line of
-    data rather than the first line of the file.
+    ignores commented lines and empty lines if ``skip_blank_lines=True``, so header=0
+    denotes the first line of data rather than the first line of the file.
 skiprows : list-like or integer
     Line numbers to skip (0-indexed) or number of lines to skip (int)
     at the start of the file
@@ -110,10 +110,11 @@ thousands : str, default None
 comment : str, default None
     Indicates remainder of line should not be parsed. If found at the
     beginning of a line, the line will be ignored altogether. This parameter
-    must be a single character. Also, fully commented lines
-    are ignored by the parameter `header` but not by `skiprows`. For example,
-    if comment='#', parsing '#empty\n1,2,3\na,b,c' with `header=0` will
-    result in '1,2,3' being treated as the header.
+    must be a single character. Like empty lines (as long as ``skip_blank_lines=True``),
+    fully commented lines are ignored by the parameter `header`
+    but not by `skiprows`. For example, if comment='#', parsing
+    '#empty\n1,2,3\na,b,c' with `header=0` will result in '1,2,3' being
+    treated as the header.
 decimal : str, default '.'
     Character to recognize as decimal point. E.g. use ',' for European data
 nrows : int, default None
@@ -160,6 +161,8 @@ warn_bad_lines : boolean, default True
 infer_datetime_format : boolean, default False
     If True and parse_dates is enabled for a column, attempt to infer
     the datetime format to speed up the processing
+skip_blank_lines : boolean, default True
+    If True, skip over blank lines rather than interpreting as NaN values
 
 Returns
 -------
@@ -288,6 +291,7 @@ _parser_defaults = {
     'mangle_dupe_cols': True,
     'tupleize_cols': False,
     'infer_datetime_format': False,
+    'skip_blank_lines': True
 }
 
 
@@ -380,7 +384,8 @@ def _make_parser_function(name, sep=','):
                  squeeze=False,
                  mangle_dupe_cols=True,
                  tupleize_cols=False,
-                 infer_datetime_format=False):
+                 infer_datetime_format=False,
+                 skip_blank_lines=True):
 
         # Alias sep -> delimiter.
         if delimiter is None:
@@ -452,7 +457,8 @@ def _make_parser_function(name, sep=','):
                     buffer_lines=buffer_lines,
                     mangle_dupe_cols=mangle_dupe_cols,
                     tupleize_cols=tupleize_cols,
-                    infer_datetime_format=infer_datetime_format)
+                    infer_datetime_format=infer_datetime_format,
+                    skip_blank_lines=skip_blank_lines)
 
         return _read(filepath_or_buffer, kwds)
 
@@ -1346,6 +1352,7 @@ class PythonParser(ParserBase):
         self.quoting = kwds['quoting']
         self.mangle_dupe_cols = kwds.get('mangle_dupe_cols', True)
         self.usecols = kwds['usecols']
+        self.skip_blank_lines = kwds['skip_blank_lines']
 
         self.names_passed = kwds['names'] or None
 
@@ -1401,6 +1408,7 @@ class PythonParser(ParserBase):
 
         # needs to be cleaned/refactored
         # multiple date column thing turning into a real spaghetti factory
+
         if not self._has_complex_date_col:
             (index_names,
              self.orig_names, self.columns) = self._get_index_name(self.columns)
@@ -1598,6 +1606,7 @@ class PythonParser(ParserBase):
 
                 while self.line_pos <= hr:
                     line = self._next_line()
+
                 unnamed_count = 0
                 this_columns = []
                 for i, c in enumerate(line):
@@ -1735,25 +1744,35 @@ class PythonParser(ParserBase):
                     line = self._check_comments([self.data[self.pos]])[0]
                     self.pos += 1
                     # either uncommented or blank to begin with
-                    if self._empty(self.data[self.pos - 1]) or line:
+                    if not self.skip_blank_lines and (self._empty(self.data[
+                            self.pos - 1]) or line):
                         break
+                    elif self.skip_blank_lines:
+                        ret = self._check_empty([line])
+                        if ret:
+                            line = ret[0]
+                            break
                 except IndexError:
                     raise StopIteration
         else:
             while self.pos in self.skiprows:
-                next(self.data)
                 self.pos += 1
+                next(self.data)
 
             while True:
                 orig_line = next(self.data)
                 line = self._check_comments([orig_line])[0]
                 self.pos += 1
-                if self._empty(orig_line) or line:
+                if not self.skip_blank_lines and (self._empty(orig_line) or line):
                     break
+                elif self.skip_blank_lines:
+                    ret = self._check_empty([line])
+                    if ret:
+                        line = ret[0]
+                        break
 
         self.line_pos += 1
         self.buf.append(line)
-
         return line
 
     def _check_comments(self, lines):
@@ -1774,6 +1793,15 @@ class PythonParser(ParserBase):
             ret.append(rl)
         return ret
 
+    def _check_empty(self, lines):
+        ret = []
+        for l in lines:
+            # Remove empty lines and lines with only one whitespace value
+            if len(l) > 1 or len(l) == 1 and (not isinstance(l[0],
+                                compat.string_types) or l[0].strip()):
+                ret.append(l)
+        return ret
+
     def _check_thousands(self, lines):
         if self.thousands is None:
             return lines
@@ -1909,7 +1937,6 @@ class PythonParser(ParserBase):
 
         # already fetched some number
         if rows is not None:
-
             # we already have the lines in the buffer
             if len(self.buf) >= rows:
                 new_rows, self.buf = self.buf[:rows], self.buf[rows:]
@@ -1974,6 +2001,8 @@ class PythonParser(ParserBase):
             lines = lines[:-self.skip_footer]
 
         lines = self._check_comments(lines)
+        if self.skip_blank_lines:
+            lines = self._check_empty(lines)
         return self._check_thousands(lines)
 
 
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index a381e1802..02f995471 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -732,7 +732,6 @@ Klosterdruckerei\tKlosterdruckerei <Kempten> (1609-1805)\tHochfurstliche Buchhan
             return buf
 
         data = StringIO('\n'.join([ f(i, v) for i, v in enumerate(_NA_VALUES) ]))
-
         expected = DataFrame(np.nan,columns=range(nv),index=range(nv))
         df = self.read_csv(data, header=None)
         tm.assert_frame_equal(df, expected)
@@ -1288,11 +1287,11 @@ R_l0_g3,R_l1_g3,R3C0,R3C1,R3C2
 R_l0_g4,R_l1_g4,R4C0,R4C1,R4C2
 """
 
-        df = self.read_csv(StringIO(data), header=[0, 2, 3, 4], index_col=[0, 1], tupleize_cols=False)
+        df = self.read_csv(StringIO(data), header=[0, 1, 2, 3], index_col=[0, 1], tupleize_cols=False)
         tm.assert_frame_equal(df, expected)
 
         # skipping lines in the header
-        df = self.read_csv(StringIO(data), header=[0, 2, 3, 4], index_col=[0, 1], tupleize_cols=False)
+        df = self.read_csv(StringIO(data), header=[0, 1, 2, 3], index_col=[0, 1], tupleize_cols=False)
         tm.assert_frame_equal(df, expected)
 
         #### invalid options ####
@@ -2809,6 +2808,58 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
         actual = self.read_table(StringIO(data), sep='\s+')
         tm.assert_frame_equal(actual, expected)
 
+    def test_line_comment(self):
+        data = """# empty
+A,B,C
+1,2.,4.#hello world
+#ignore this line
+5.,NaN,10.0
+"""
+        expected = [[1., 2., 4.],
+                    [5., np.nan, 10.]]
+        df = self.read_csv(StringIO(data), comment='#')
+        tm.assert_almost_equal(df.values, expected)
+
+    def test_empty_lines(self):
+        data = """\
+A,B,C
+1,2.,4.
+
+
+5.,NaN,10.0
+
+-70,.4,1
+"""
+        expected = [[1., 2., 4.],
+                    [5., np.nan, 10.],
+                    [-70., .4, 1.]]
+        df = self.read_csv(StringIO(data))
+        tm.assert_almost_equal(df.values, expected)
+        df = self.read_csv(StringIO(data.replace(',', '  ')), sep='\s+')
+        tm.assert_almost_equal(df.values, expected)
+        expected = [[1., 2., 4.],
+                    [np.nan, np.nan, np.nan],
+                    [np.nan, np.nan, np.nan],
+                    [5., np.nan, 10.],
+                    [np.nan, np.nan, np.nan],
+                    [-70., .4, 1.]]
+        df = self.read_csv(StringIO(data), skip_blank_lines=False)
+        tm.assert_almost_equal(list(df.values), list(expected))
+
+    def test_whitespace_lines(self):
+        data = """
+
+\t  \t\t 
+  \t  
+A,B,C
+  \t    1,2.,4.
+5.,NaN,10.0
+"""
+        expected = [[1, 2., 4.],
+                     [5., np.nan, 10.]]
+        df = self.read_csv(StringIO(data))
+        tm.assert_almost_equal(df.values, expected)
+
 class TestFwfColspaceSniffing(tm.TestCase):
     def test_full_file(self):
         # File with all values
@@ -3015,6 +3066,46 @@ A,B,C
         df = self.read_csv(StringIO(data), comment='#', skiprows=4, header=1)
         tm.assert_almost_equal(df.values, expected)
 
+    def test_empty_lines(self):
+        data = """\
+A,B,C
+1,2.,4.
+
+
+5.,NaN,10.0
+
+-70,.4,1
+"""
+        expected = [[1., 2., 4.],
+                    [5., np.nan, 10.],
+                    [-70., .4, 1.]]
+        df = self.read_csv(StringIO(data))
+        tm.assert_almost_equal(df.values, expected)
+        df = self.read_csv(StringIO(data.replace(',', '  ')), sep='\s+')
+        tm.assert_almost_equal(df.values, expected)
+        expected = [[1., 2., 4.],
+                    [np.nan, np.nan, np.nan],
+                    [np.nan, np.nan, np.nan],
+                    [5., np.nan, 10.],
+                    [np.nan, np.nan, np.nan],
+                    [-70., .4, 1.]]
+        df = self.read_csv(StringIO(data), skip_blank_lines=False)
+        tm.assert_almost_equal(list(df.values), list(expected))
+
+    def test_whitespace_lines(self):
+        data = """
+
+\t  \t\t 
+  \t  
+A,B,C
+  \t    1,2.,4.
+5.,NaN,10.0
+"""
+        expected = [[1, 2., 4.],
+                     [5., np.nan, 10.]]
+        df = self.read_csv(StringIO(data))
+        tm.assert_almost_equal(df.values, expected)
+
     def test_passing_dtype(self):
         # GH 6607
         # This is a copy which should eventually be merged into ParserTests
@@ -3480,6 +3571,7 @@ class TestMiscellaneous(tm.TestCase):
         data = '    a b c\n1 2 3 \n4 5  6\n 7 8 9'
         result_c = pd.read_table(StringIO(data), sep='\s+', engine='c')
         result_py = pd.read_table(StringIO(data), sep='\s+', engine='python')
+        print(result_c)
         tm.assert_frame_equal(result_c, result_py)
 
     def test_fallback_to_python(self):
diff --git a/pandas/parser.pyx b/pandas/parser.pyx
index 5905fada0..5f56bd312 100644
--- a/pandas/parser.pyx
+++ b/pandas/parser.pyx
@@ -85,6 +85,7 @@ cdef extern from "parser/tokenizer.h":
         EAT_WHITESPACE
         EAT_COMMENT
         EAT_LINE_COMMENT
+        WHITESPACE_LINE
         FINISHED
 
     enum: ERROR_OVERFLOW
@@ -164,6 +165,8 @@ cdef extern from "parser/tokenizer.h":
         char *warn_msg
         char *error_msg
 
+        int skip_empty_lines
+
     ctypedef struct coliter_t:
         char **words
         int *line_start
@@ -325,7 +328,8 @@ cdef class TextReader:
                   verbose=False,
                   mangle_dupe_cols=True,
                   tupleize_cols=False,
-                  float_precision=None):
+                  float_precision=None,
+                  skip_blank_lines=True):
 
         self.parser = parser_new()
         self.parser.chunksize = tokenize_chunksize
@@ -356,6 +360,7 @@ cdef class TextReader:
 
         self.parser.doublequote = doublequote
         self.parser.skipinitialspace = skipinitialspace
+        self.parser.skip_empty_lines = skip_blank_lines
 
         if lineterminator is not None:
             if len(lineterminator) != 1:
@@ -552,7 +557,7 @@ cdef class TextReader:
 
         if isinstance(source, basestring):
             if not isinstance(source, bytes):
-                source = source.encode(sys.getfilesystemencoding() or 'utf-8') 
+                source = source.encode(sys.getfilesystemencoding() or 'utf-8')
 
             if self.memory_map:
                 ptr = new_mmap(source)
@@ -614,16 +619,21 @@ cdef class TextReader:
                 if self.parser.lines < hr + 1:
                     self._tokenize_rows(hr + 2)
 
+                if self.parser.lines == 0:
+                    field_count = 0
+                    start = self.parser.line_start[0]
+
                 # e.g., if header=3 and file only has 2 lines
-                if self.parser.lines < hr + 1:
+                elif self.parser.lines < hr + 1:
                     msg = self.orig_header
                     if isinstance(msg,list):
                            msg = "[%s], len of %d," % (','.join([ str(m) for m in msg ]),len(msg))
                     raise CParserError('Passed header=%s but only %d lines in file'
                                        % (msg, self.parser.lines))
 
-                field_count = self.parser.line_fields[hr]
-                start = self.parser.line_start[hr]
+                else:
+                    field_count = self.parser.line_fields[hr]
+                    start = self.parser.line_start[hr]
 
                 # TODO: Py3 vs. Py2
                 counts = {}
diff --git a/pandas/src/parser/tokenizer.c b/pandas/src/parser/tokenizer.c
index 79d854dd0..f817b2026 100644
--- a/pandas/src/parser/tokenizer.c
+++ b/pandas/src/parser/tokenizer.c
@@ -693,15 +693,34 @@ int tokenize_delimited(parser_t *self, size_t line_limit)
 
             if (c == '\n') {
                 // \n\r possible?
-                END_LINE();
+                if (self->skip_empty_lines)
+                {
+                    self->file_lines++;
+                }
+                else
+                {
+                    END_LINE();
+                }
                 break;
-            } else if (c == '\r') {
-                self->state = EAT_CRNL;
+            }
+            else if (c == '\r') {
+                if (self->skip_empty_lines)
+                {
+                    self->file_lines++;
+                    self->state = EAT_CRNL_NOP;
+                }
+                else
+                    self->state = EAT_CRNL;
                 break;
-            } else if (c == self->commentchar) {
+            } 
+            else if (c == self->commentchar) {
                 self->state = EAT_LINE_COMMENT;
                 break;
             }
+            else if (IS_WHITESPACE(c) && c != self->delimiter && self->skip_empty_lines) {
+                self->state = WHITESPACE_LINE;
+                break;
+            }
 
             /* normal character - handle as START_FIELD */
             self->state = START_FIELD;
@@ -747,6 +766,32 @@ int tokenize_delimited(parser_t *self, size_t line_limit)
             }
             break;
 
+        case WHITESPACE_LINE: // check if line is whitespace-only
+            if (c == '\n') {
+                self->file_lines++;
+                self->state = START_RECORD; // ignore empty line
+            }
+            else if (c == '\r') {
+                self->file_lines++;
+                self->state = EAT_CRNL_NOP;
+            }
+            else if (IS_WHITESPACE(c) && c != self->delimiter)
+                ;
+            else { // backtrack
+                /* We have to use i + 1 because buf has been incremented but not i */
+                while (i + 1 > self->datapos && *buf != '\n') {
+                    --buf;
+                    --i;
+                }
+                if (i + 1 > self->datapos) // reached a newline rather than the beginning
+                {
+                    ++buf; // move pointer to first char after newline
+                    ++i;
+                }
+                self->state = START_FIELD;
+            }
+            break;
+
         case ESCAPED_CHAR:
             /* if (c == '\0') */
             /*  c = '\n'; */
@@ -904,7 +949,6 @@ int tokenize_delimited(parser_t *self, size_t line_limit)
                 --buf;
             }
             break;
-
         default:
             break;
 
@@ -966,13 +1010,25 @@ int tokenize_delim_customterm(parser_t *self, size_t line_limit)
             // start of record
             if (c == self->lineterminator) {
                 // \n\r possible?
-                END_LINE();
+                if (self->skip_empty_lines)
+                {
+                    self->file_lines++;
+                }
+                else
+                {
+                    END_LINE();
+                }
                 break;
             }
             else if (c == self->commentchar) {
                 self->state = EAT_LINE_COMMENT;
                 break;
             }
+            else if (IS_WHITESPACE(c) && c != self->delimiter && self->skip_empty_lines)
+            {
+                self->state = WHITESPACE_LINE;
+                break;
+            }
             /* normal character - handle as START_FIELD */
             self->state = START_FIELD;
             /* fallthru */
@@ -1014,6 +1070,28 @@ int tokenize_delim_customterm(parser_t *self, size_t line_limit)
             }
             break;
 
+        case WHITESPACE_LINE: // check if line is whitespace-only
+            if (c == self->lineterminator) {
+                self->file_lines++;
+                self->state = START_RECORD; // ignore empty line
+            }
+            else if (IS_WHITESPACE(c) && c != self->delimiter)
+                ;
+            else { // backtrack
+                /* We have to use i + 1 because buf has been incremented but not i */
+                while (i + 1 > self->datapos && *buf != self->lineterminator) {
+                    --buf;
+                    --i;
+                }
+                if (i + 1 > self->datapos) // reached a newline rather than the beginning
+                {
+                    ++buf; // move pointer to first char after newline
+                    ++i;
+                }
+                self->state = START_FIELD;
+            }
+            break;
+
         case ESCAPED_CHAR:
             /* if (c == '\0') */
             /*  c = '\n'; */
@@ -1174,9 +1252,27 @@ int tokenize_whitespace(parser_t *self, size_t line_limit)
                self->state));
 
         switch(self->state) {
+        case WHITESPACE_LINE:
+            if (c == '\n') {
+                self->file_lines++;
+                self->state = START_RECORD;
+                break;
+            }
+            else if (c == '\r') {
+                self->file_lines++;
+                self->state = EAT_CRNL_NOP;
+                break;
+            }
+            // fall through
 
         case EAT_WHITESPACE:
-            if (!IS_WHITESPACE(c)) {
+            if (c == '\n') {
+                END_LINE();
+                self->state = START_RECORD;
+            } else if (c == '\r') {
+                self->state = EAT_CRNL;
+                break;
+            } else if (!IS_WHITESPACE(c)) {
                 // END_FIELD();
                 self->state = START_FIELD;
                 // Fall through to subsequent state
@@ -1189,13 +1285,29 @@ int tokenize_whitespace(parser_t *self, size_t line_limit)
             // start of record
             if (c == '\n') {
                 // \n\r possible?
-                END_LINE();
+                if (self->skip_empty_lines)
+                {
+                    self->file_lines++;
+                }
+                else
+                {
+                    END_LINE();
+                }
                 break;
             } else if (c == '\r') {
-                self->state = EAT_CRNL;
+                if (self->skip_empty_lines)
+                {
+                    self->file_lines++;
+                    self->state = EAT_CRNL_NOP;
+                }
+                else
+                    self->state = EAT_CRNL;
                 break;
             } else if (IS_WHITESPACE(c)) {
-                self->state = EAT_WHITESPACE;
+                /*if (self->skip_empty_lines)
+                    self->state = WHITESPACE_LINE;
+                    else*/
+                    self->state = EAT_WHITESPACE;
                 break;
             } else if (c == self->commentchar) {
                 self->state = EAT_LINE_COMMENT;
diff --git a/pandas/src/parser/tokenizer.h b/pandas/src/parser/tokenizer.h
index 62e890f60..1ad7106ef 100644
--- a/pandas/src/parser/tokenizer.h
+++ b/pandas/src/parser/tokenizer.h
@@ -125,6 +125,7 @@ typedef enum {
     EAT_WHITESPACE,
     EAT_COMMENT,
     EAT_LINE_COMMENT,
+    WHITESPACE_LINE,
     FINISHED
 } ParserState;
 
@@ -207,6 +208,8 @@ typedef struct parser_t {
     // error handling
     char *warn_msg;
     char *error_msg;
+
+    int skip_empty_lines;
 } parser_t;
 
 
