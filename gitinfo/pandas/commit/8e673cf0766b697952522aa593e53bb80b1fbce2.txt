commit 8e673cf0766b697952522aa593e53bb80b1fbce2
Author: jreback <jeff@reback.net>
Date:   Sun Jun 9 01:19:52 2013 -0400

    ENH: removed json argument, now path_or_buf can be a path,buffer,url,or JSON string
    
         added keywords parse_dates,keep_default_dates to allow for date parsing in columns
         of a Frame (default is False, not to parse dates)

diff --git a/doc/source/io.rst b/doc/source/io.rst
index f1480b654..ee234bc35 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -953,7 +953,7 @@ A ``Series`` or ``DataFrame`` can be converted to a valid JSON string. Use ``to_
 with optional parameters:
 
 - path_or_buf : the pathname or buffer to write the output
-  This can be ``None`` in which case a ``StringIO`` converted string is returned
+  This can be ``None`` in which case a JSON string is returned
 - orient : The format of the JSON string, default is ``index`` for ``Series``, ``columns`` for ``DataFrame``
 
   * split   : dict like {index -> [index], columns -> [columns], data -> [values]}
@@ -969,9 +969,19 @@ Note NaN's and None will be converted to null and datetime objects will be conve
 
 .. ipython:: python
 
-   df = DataFrame(randn(10, 2), columns=list('AB'))
-   json = df.to_json(None)
-   json.getvalue()
+   dfj = DataFrame(randn(5, 2), columns=list('AB'))
+   json = dfj.to_json()
+   json
+
+Writing to a file, with a date index and a date column
+
+.. ipython:: python
+
+   dfj2 = dfj.copy()
+   dfj2['date'] = Timestamp('20130101')
+   dfj2.index = date_range('20130101',periods=5)
+   dfj2.to_json('test.json')
+   open('test.json').read()
 
 Reading JSON
 ~~~~~~~~~~~~
@@ -984,7 +994,6 @@ is ``None``. To explicity force ``Series`` parsing, pass ``typ=series``
   a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host
   is expected. For instance, a local file could be
   file ://localhost/path/to/table.json
-- json : a VALID JSON string, optional, used if filepath_or_buffer is not provided
 - typ    : type of object to recover (series or frame), default 'frame'
 - orient : The format of the JSON string, one of the following
 
@@ -992,8 +1001,10 @@ is ``None``. To explicity force ``Series`` parsing, pass ``typ=series``
   * records : list like [value, ... , value]
   * index : dict like {index -> value}
 
-- dtype : dtype of the resulting Series
+- dtype : dtype of the resulting object
 - numpy : direct decoding to numpy arrays. default True but falls back to standard decoding if a problem occurs.
+- parse_dates : a list of columns to parse for dates; If True, then try to parse datelike columns, default is True
+- keep_default_dates : boolean, default True. If parsing dates, then parse the default datelike columns
 
 The parser will raise one of ``ValueError/TypeError/AssertionError`` if the JSON is
 not parsable.
@@ -1002,13 +1013,19 @@ Reading from a JSON string
 
 .. ipython:: python
 
-   pd.read_json(json='{"0":{"0":1,"1":3},"1":{"0":2,"1":4}}')
+   pd.read_json(json)
+
+Reading from a file, parsing dates
+
+.. ipython:: python
 
-Reading from a StringIO
+   pd.read_json('test.json',parse_dates=True)
 
 .. ipython:: python
+   :suppress:
 
-   pd.read_json(json)
+   import os
+   os.remove('test.json')
 
 HTML
 ----
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index ac9663a34..7e6ac4d5b 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -495,7 +495,7 @@ class PandasObject(object):
         from pandas.io import clipboard
         clipboard.to_clipboard(self)
 
-    def to_json(self, path_or_buf, orient=None, double_precision=10,
+    def to_json(self, path_or_buf=None, orient=None, double_precision=10,
                 force_ascii=True):
         """
         Convert the object to a JSON string.
@@ -529,7 +529,7 @@ class PandasObject(object):
         """
 
         from pandas.io import json
-        return json.to_json(path_or_buf, self, orient=orient, double_precision=double_precision,
+        return json.to_json(path_or_buf=path_or_buf, obj=self, orient=orient, double_precision=double_precision,
                             force_ascii=force_ascii)
 
 # install the indexerse
diff --git a/pandas/io/json.py b/pandas/io/json.py
index 48412f21f..446cadf47 100644
--- a/pandas/io/json.py
+++ b/pandas/io/json.py
@@ -1,47 +1,19 @@
 
 # pylint: disable-msg=E1101,W0613,W0603
-from pandas import Series, DataFrame
-from pandas.io.common import get_filepath_or_buffer
 from StringIO import StringIO
+import os
 
+from pandas import Series, DataFrame, to_datetime
+from pandas.io.common import get_filepath_or_buffer
 import pandas.json as _json
 loads = _json.loads
 dumps = _json.dumps
 
-### interface to/from ###
+import numpy as np
 
-def to_json(path_or_buf, obj, orient=None, double_precision=10,
-            force_ascii=True):
-        """
-        Convert the object to a JSON string
-
-        Note NaN's and None will be converted to null and datetime objects
-        will be converted to UNIX timestamps.
-
-        Parameters
-        ----------
-        path_or_buf : the pathname or buffer to write the output
-            if this is None, return a StringIO of the converted string
-        orient : {'split', 'records', 'index', 'columns', 'values'},
-            default is 'index' for Series, 'columns' for DataFrame
-
-            The format of the JSON string
-            split : dict like
-                {index -> [index], columns -> [columns], data -> [values]}
-            records : list like [{column -> value}, ... , {column -> value}]
-            index : dict like {index -> {column -> value}}
-            columns : dict like {column -> {index -> value}}
-            values : just the values array
-        double_precision : The number of decimal places to use when encoding
-            floating point values, default 10.
-        force_ascii : force encoded string to be ASCII, default True.
-
-        Returns
-        -------
-        result : a JSON compatible string written to the path_or_buf;
-                 if the path_or_buf is none, return a StringIO of the result
+### interface to/from ###
 
-        """
+def to_json(path_or_buf, obj, orient=None, double_precision=10, force_ascii=True):
         
         if orient is None:
             if isinstance(obj, Series):
@@ -55,126 +27,229 @@ def to_json(path_or_buf, obj, orient=None, double_precision=10,
             with open(path_or_buf,'w') as fh:
                 fh.write(s)
         elif path_or_buf is None:
-            return StringIO(s)
+            return s
         else:
             path_or_buf.write(s)
 
-def read_json(filepath_or_buffer=None, json=None, typ='frame', orient=None, dtype=None, numpy=True):
+def read_json(path_or_buf=None, orient=None, typ='frame', dtype=None, numpy=True,
+              parse_dates=False, keep_default_dates=True):
     """
     Convert JSON string to pandas object
 
     Parameters
     ----------
-    filepath_or_buffer : a VALID JSON StringIO or file handle / StringIO. The string could be
+    filepath_or_buffer : a VALID JSON string or file handle / StringIO. The string could be
         a URL. Valid URL schemes include http, ftp, s3, and file. For file URLs, a host
         is expected. For instance, a local file could be
         file ://localhost/path/to/table.json
-    json : a VALID JSON string, optional, used if filepath_or_buffer is not provided
-    typ : type of object to recover (series or frame), default 'frame'
     orient : {'split', 'records', 'index'}, default 'index'
         The format of the JSON string
         split : dict like
             {index -> [index], name -> name, data -> [values]}
         records : list like [value, ... , value]
         index : dict like {index -> value}
-    dtype : dtype of the resulting Series
+    typ : type of object to recover (series or frame), default 'frame'
+    dtype : dtype of the resulting object
     numpy: direct decoding to numpy arrays. default True but falls back
         to standard decoding if a problem occurs.
+    parse_dates : a list of columns to parse for dates; If True, then try to parse datelike columns
+        default is False
+    keep_default_dates : boolean, default True. If parsing dates,
+        then parse the default datelike columns
 
     Returns
     -------
     result : Series or DataFrame
     """
 
-    if json is None:
-        filepath_or_buffer,_ = get_filepath_or_buffer(filepath_or_buffer)
-        if isinstance(filepath_or_buffer, basestring):
-                with open(filepath_or_buffer,'r') as fh:
-                        json = fh.read()
-        elif hasattr(filepath_or_buffer, 'read'):
-                json = filepath_or_buffer.read()
+    filepath_or_buffer,_ = get_filepath_or_buffer(path_or_buf)
+    if isinstance(filepath_or_buffer, basestring):
+        if os.path.exists(filepath_or_buffer):
+            with open(filepath_or_buffer,'r') as fh:
+                json = fh.read()
         else:
-                json = filepath_or_buffer
+            json = filepath_or_buffer
+    elif hasattr(filepath_or_buffer, 'read'):
+        json = filepath_or_buffer.read()
+    else:
+        json = filepath_or_buffer
 
     obj = None
     if typ == 'frame':
-        if orient is None:
-            orient = 'columns'
-        obj = load_frame(json, orient, dtype, numpy)
+        obj = FrameParser(json, orient, dtype, numpy, parse_dates, keep_default_dates).parse()
 
     if typ == 'series' or obj is None:
-        if orient == 'columns':
-            orient = 'index'
-        obj = load_series(json, orient, dtype, numpy)
+        obj = SeriesParser(json, orient, dtype, numpy).parse()
 
     return obj
 
-def load_series(json, orient, dtype, numpy):
-    s = None
+class Parser(object):
+    _min_date = 31536000000000000L
+    
+    def __init__(self, json, orient, dtype, numpy, parse_dates=False, keep_default_dates=False):
+        self.json = json
 
-    if dtype is not None and orient == "split":
-        numpy = False
+        if orient is None:
+            orient = self._default_orient
+            
+        self.orient = orient
+        self.dtype = dtype
 
-    if numpy:
-        try:
-            if orient == "split":
-                decoded = loads(json, dtype=dtype, numpy=True)
-                decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                s = Series(**decoded)
-            elif orient == "columns" or orient == "index":
-                s = Series(*loads(json, dtype=dtype, numpy=True,
-                                  labelled=True))
-            else:
-                s = Series(loads(json, dtype=dtype, numpy=True))
-        except ValueError:
+        if dtype is not None and orient == "split":
             numpy = False
 
-    if not numpy:
-        if orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in loads(json).iteritems())
-            s = Series(dtype=dtype, **decoded)
-        else:
-            s = Series(loads(json), dtype=dtype)
-
-    return s
-
-        
-def load_frame(json, orient, dtype, numpy):
-    """ try to recover a frame, return None if we didn't get anything """
+        self.numpy = numpy
+        self.parse_dates = parse_dates
+        self.keep_default_dates = keep_default_dates
+        self.obj = None
+
+    def parse(self):
+        self._parse()
+        if self.obj is not None:
+            self.convert_axes()
+            if self.parse_dates:
+                self.try_parse_dates()
+        return self.obj
+
+    def try_parse_dates(self):
+        raise NotImplementedError
+
+class SeriesParser(Parser):
+    _default_orient = 'index'
+
+    def _parse(self):
+
+        json = self.json
+        dtype = self.dtype
+        orient = self.orient
+        numpy = self.numpy
+    
+        if numpy:
+            try:
+                if orient == "split":
+                    decoded = loads(json, dtype=dtype, numpy=True)
+                    decoded = dict((str(k), v) for k, v in decoded.iteritems())
+                    self.obj = Series(**decoded)
+                elif orient == "columns" or orient == "index":
+                    self.obj = Series(*loads(json, dtype=dtype, numpy=True,
+                                             labelled=True))
+                else:
+                    self.obj = Series(loads(json, dtype=dtype, numpy=True))
+            except ValueError:
+                numpy = False
+
+        if not numpy:
+            if orient == "split":
+                decoded = dict((str(k), v)
+                               for k, v in loads(json).iteritems())
+                self.obj = Series(dtype=dtype, **decoded)
+            else:
+                self.obj = Series(loads(json), dtype=dtype)
 
-    if dtype is not None and orient == "split":
-        numpy = False
+    def convert_axes(self):
+        """ try to axes if they are datelike """
+        if self.obj is None: return
 
-    if numpy:
         try:
+           self.obj.index = to_datetime(self.obj.index.astype('int64'))
+        except:
+           pass
+
+class FrameParser(Parser):
+    _default_orient = 'columns'
+
+    def _parse(self):
+
+        json = self.json
+        dtype = self.dtype
+        orient = self.orient
+        numpy = self.numpy
+
+        if numpy:
+            try:
+                if orient == "columns":
+                    args = loads(json, dtype=dtype, numpy=True, labelled=True)
+                    if args:
+                        args = (args[0].T, args[2], args[1])
+                    self.obj = DataFrame(*args)
+                elif orient == "split":
+                    decoded = loads(json, dtype=dtype, numpy=True)
+                    decoded = dict((str(k), v) for k, v in decoded.iteritems())
+                    self.obj = DataFrame(**decoded)
+                elif orient == "values":
+                    self.obj = DataFrame(loads(json, dtype=dtype, numpy=True))
+                else:
+                    self.obj = DataFrame(*loads(json, dtype=dtype, numpy=True,
+                                         labelled=True))
+            except ValueError:
+                numpy = False
+
+        if not numpy:
             if orient == "columns":
-                args = loads(json, dtype=dtype, numpy=True, labelled=True)
-                if args:
-                    args = (args[0].T, args[2], args[1])
-                df = DataFrame(*args)
+                self.obj = DataFrame(loads(json), dtype=dtype)
             elif orient == "split":
-                decoded = loads(json, dtype=dtype, numpy=True)
-                decoded = dict((str(k), v) for k, v in decoded.iteritems())
-                df = DataFrame(**decoded)
-            elif orient == "values":
-                df = DataFrame(loads(json, dtype=dtype, numpy=True))
+                decoded = dict((str(k), v)
+                               for k, v in loads(json).iteritems())
+                self.obj = DataFrame(dtype=dtype, **decoded)
+            elif orient == "index":
+                self.obj = DataFrame(loads(json), dtype=dtype).T
             else:
-                df = DataFrame(*loads(json, dtype=dtype, numpy=True,
-                                     labelled=True))
-        except ValueError:
-            numpy = False
+                self.obj = DataFrame(loads(json), dtype=dtype)
 
-    if not numpy:
-        if orient == "columns":
-            df = DataFrame(loads(json), dtype=dtype)
-        elif orient == "split":
-            decoded = dict((str(k), v)
-                           for k, v in loads(json).iteritems())
-            df = DataFrame(dtype=dtype, **decoded)
-        elif orient == "index":
-            df = DataFrame(loads(json), dtype=dtype).T
+    def convert_axes(self):
+        """ try to axes if they are datelike """
+        if self.obj is None: return
+
+        if self.orient == 'columns':
+            axis = 'index'
+        elif self.orient == 'index':
+            axis = 'columns'
         else:
-            df = DataFrame(loads(json), dtype=dtype)
+            return
+
+        try:
+            a = getattr(self.obj,axis).astype('int64')
+            if (a>self._min_date).all():
+                setattr(self.obj,axis,to_datetime(a))
+        except:
+            pass
+
+    def try_parse_dates(self):
+        """
+        try to parse out dates
+        these are only in in64 columns
+        """
 
-    return df
+        if self.obj is None: return
+
+        # our columns to parse
+        parse_dates = self.parse_dates
+        if parse_dates is True:
+            parse_dates = []
+        parse_dates = set(parse_dates)
+
+        def is_ok(col, c):
+            """ return if this col is ok to try for a date parse """
+            if not isinstance(col, basestring): return False
+
+            if issubclass(c.dtype.type,np.number) and (c<self._min_date).all():
+                return False
+                    
+            if (col.endswith('_at') or
+                col.endswith('_time') or
+                col.lower() == 'modified' or
+                col.lower() == 'date' or
+                col.lower() == 'datetime'):
+                    return True
+            return False
+
+
+        for col, c in self.obj.iteritems():
+            if (self.keep_default_dates and is_ok(col, c)) or col in parse_dates:
+                try:
+                    self.obj[col] = to_datetime(c)
+                except:
+                    try:
+                        self.obj[col] = to_datetime(c.astype('int64'))
+                    except:
+                        pass
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index e9bb35876..80f602964 100755
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -10,12 +10,13 @@ import unittest
 
 import numpy as np
 
-from pandas import Series, DataFrame, DatetimeIndex
+from pandas import Series, DataFrame, DatetimeIndex, Timestamp
 import pandas as pd
 read_json = pd.read_json
 
 from pandas.util.testing import (assert_almost_equal, assert_frame_equal,
-                                 assert_series_equal, network)
+                                 assert_series_equal, network,
+                                 ensure_clean)
 import pandas.util.testing as tm
 from numpy.testing.decorators import slow
 
@@ -57,7 +58,7 @@ class TestPandasObjects(unittest.TestCase):
 
         def _check_orient(df, orient, dtype=None, numpy=True):
             df = df.sort()
-            dfjson = df.to_json(None, orient=orient)
+            dfjson = df.to_json(orient=orient)
             unser = read_json(dfjson, orient=orient, dtype=dtype,
                               numpy=numpy)
             unser = unser.sort()
@@ -94,8 +95,8 @@ class TestPandasObjects(unittest.TestCase):
 
         # basic
         _check_all_orients(self.frame)
-        self.assertEqual(self.frame.to_json(None).read(),
-                         self.frame.to_json(None,orient="columns").read())
+        self.assertEqual(self.frame.to_json(),
+                         self.frame.to_json(orient="columns"))
 
         _check_all_orients(self.intframe, dtype=self.intframe.values.dtype)
 
@@ -164,36 +165,36 @@ class TestPandasObjects(unittest.TestCase):
 
     def test_frame_from_json_nones(self):
         df = DataFrame([[1, 2], [4, 5, 6]])
-        unser = read_json(df.to_json(None))
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
         df = DataFrame([['1', '2'], ['4', '5', '6']])
-        unser = read_json(df.to_json(None))
+        unser = read_json(df.to_json())
         self.assert_(unser['2'][0] is None)
 
-        unser = read_json(df.to_json(None), numpy=False)
+        unser = read_json(df.to_json(), numpy=False)
         self.assert_(unser['2'][0] is None)
 
         # infinities get mapped to nulls which get mapped to NaNs during
         # deserialisation
         df = DataFrame([[1, 2], [4, 5, 6]])
         df[2][0] = np.inf
-        unser = read_json(df.to_json(None))
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
         df[2][0] = np.NINF
-        unser = read_json(df.to_json(None))
+        unser = read_json(df.to_json())
         self.assert_(np.isnan(unser['2'][0]))
 
     def test_frame_to_json_except(self):
         df = DataFrame([1, 2, 3])
-        self.assertRaises(ValueError, df.to_json, None, orient="garbage")
+        self.assertRaises(ValueError, df.to_json, orient="garbage")
 
     def test_series_from_json_to_json(self):
 
         def _check_orient(series, orient, dtype=None, numpy=True):
             series = series.sort_index()
-            unser = read_json(series.to_json(None,orient=orient), typ='series',
+            unser = read_json(series.to_json(orient=orient), typ='series',
                               orient=orient, numpy=numpy, dtype=dtype)
             unser = unser.sort_index()
             if series.index.dtype.type == np.datetime64:
@@ -223,8 +224,8 @@ class TestPandasObjects(unittest.TestCase):
 
         # basic
         _check_all_orients(self.series)
-        self.assertEqual(self.series.to_json(None).read(),
-                         self.series.to_json(None,orient="index").read())
+        self.assertEqual(self.series.to_json(),
+                         self.series.to_json(orient="index"))
 
         objSeries = Series([str(d) for d in self.objSeries],
                            index=self.objSeries.index,
@@ -240,35 +241,63 @@ class TestPandasObjects(unittest.TestCase):
 
     def test_series_to_json_except(self):
         s = Series([1, 2, 3])
-        self.assertRaises(ValueError, s.to_json, None, orient="garbage")
+        self.assertRaises(ValueError, s.to_json, orient="garbage")
 
     def test_typ(self):
 
         s = Series(range(6), index=['a','b','c','d','e','f'])
-        result = read_json(s.to_json(None),typ=None)
+        result = read_json(s.to_json(),typ=None)
         assert_series_equal(result,s)
 
     def test_reconstruction_index(self):
 
         df = DataFrame([[1, 2, 3], [4, 5, 6]])
-        result = read_json(df.to_json(None))
+        result = read_json(df.to_json())
 
         # the index is serialized as strings....correct?
         #assert_frame_equal(result,df)
 
+    def test_path(self):
+        with ensure_clean('test.json') as path:
+
+            for df in [ self.frame, self.frame2, self.intframe, self.tsframe, self.mixed_frame ]:
+                df.to_json(path)
+                read_json(path)
+
+    def test_axis_dates(self):
+
+        # axis conversion
+        json = self.tsframe.to_json()
+        result = read_json(json)
+        assert_frame_equal(result,self.tsframe)
+
+    def test_parse_dates(self):
+
+        df = self.tsframe.copy()
+        df['date'] = Timestamp('20130101')
+
+        json = df.to_json()
+        result = read_json(json,parse_dates=True)
+        assert_frame_equal(result,df)
+
+        df['foo'] = 1.
+        json = df.to_json()
+        result = read_json(json,parse_dates=True)
+        assert_frame_equal(result,df)
+
     @network
     @slow
     def test_url(self):
         import urllib2
         try:
-            # HTTP(S)
+
             url = 'https://api.github.com/repos/pydata/pandas/issues?per_page=5'
-            result = read_json(url)
-            #print result
+            result = read_json(url,parse_dates=True)
+            for c in ['created_at','closed_at','updated_at']:
+                self.assert_(result[c].dtype == 'datetime64[ns]')
             
             url = 'http://search.twitter.com/search.json?q=pandas%20python'
             result = read_json(url)
-            #print result
             
         except urllib2.URLError:
             raise nose.SkipTest
