commit e60013189f4ed6f3cc059394104e46a8fa46a98a
Author: Jonathan Chambers <jonathan.chambers@ben-energy.com>
Date:   Tue Jan 14 22:11:09 2014 +0000

    ENH #4163 Added tests and documentation
    
    Initial draft of doc updates
    
    minor doc updates
    
    Added tests and reduced code repetition. Updated Docs. Added test coverage for legacy names
    
    Documentation updates, more tests
    
    Added depreciation warnings for legacy names.
    
    Updated docs and test doc build
    
    ENH #4163 - finalized tests and docs, ready for wider useâ€¦
    
    TST added sqlalchemy to TravisCI build dep for py 2.7 and 3.3
    
    TST Import sqlalchemy on Travis.
    
    DOC add docstrings to read sql
    
    ENH read_sql connects via Connection, Engine, file path, or :memory: string
    
    CLN Separate legacy code into new file, and fallback so that all old tests pass.
    
    ENH #4163 added version added coment
    
    ENH #4163 added depreciation warning for tquery and uquery
    
    ENH #4163 Documentation and tests

diff --git a/ci/requirements-2.6.txt b/ci/requirements-2.6.txt
index 8199fdd9b..ef48d33a5 100644
--- a/ci/requirements-2.6.txt
+++ b/ci/requirements-2.6.txt
@@ -6,3 +6,4 @@ http://www.crummy.com/software/BeautifulSoup/bs4/download/4.2/beautifulsoup4-4.2
 html5lib==1.0b2
 bigquery==2.0.17
 numexpr==1.4.2
+sqlalchemy==0.8.1
diff --git a/doc/source/io.rst b/doc/source/io.rst
index 34af31747..f3cffefc1 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1823,7 +1823,7 @@ class. The following two command are equivalent:
     read_excel('path_to_file.xls', 'Sheet1', index_col=None, na_values=['NA'])
 
 The class based approach can be used to read multiple sheets or to introspect
-the sheet names using the ``sheet_names`` attribute. 
+the sheet names using the ``sheet_names`` attribute.
 
 .. note::
 
@@ -3068,13 +3068,48 @@ SQL Queries
 -----------
 
 The :mod:`pandas.io.sql` module provides a collection of query wrappers to both
-facilitate data retrieval and to reduce dependency on DB-specific API. These
-wrappers only support the Python database adapters which respect the `Python
-DB-API <http://www.python.org/dev/peps/pep-0249/>`__. See some
-:ref:`cookbook examples <cookbook.sql>` for some advanced strategies
+facilitate data retrieval and to reduce dependency on DB-specific API. Database abstraction
+is provided by SQLAlchemy if installed, in addition you will need a driver library for
+your database.
 
-For example, suppose you want to query some data with different types from a
-table such as:
+.. versionadded:: 0.14.0
+
+
+If SQLAlchemy is not installed a legacy fallback is provided for sqlite and mysql.
+These legacy modes require Python database adapters which respect the `Python
+DB-API <http://www.python.org/dev/peps/pep-0249/>`__.
+
+See also some :ref:`cookbook examples <cookbook.sql>` for some advanced strategies.
+
+The key functions are:
+:func:`~pandas.io.sql.to_sql`
+:func:`~pandas.io.sql.read_sql`
+:func:`~pandas.io.sql.read_table`
+
+
+
+
+In the following example, we use the `SQlite <http://www.sqlite.org/>`__ SQL database
+engine. You can use a temporary SQLite database where data are stored in
+"memory".
+
+To connect with SQLAlchemy you use the :func:`create_engine` function to create an engine
+object from database URI. You only need to create the engine once per database you are
+connecting to.
+
+For more information on :func:`create_engine` and the URI formatting, see the examples
+below and the SQLAlchemy `documentation <http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html>`__
+
+.. code-block:: python
+
+   from sqlalchemy import create_engine
+   from pandas.io import sql
+   # Create your connection.
+   engine = create_engine('sqlite:///:memory:')
+
+
+Assuming the following data is in a DataFrame "data", we can insert it into
+the database using :func:`~pandas.io.sql.to_sql`.
 
 
 +-----+------------+-------+-------+-------+
@@ -3088,81 +3123,107 @@ table such as:
 +-----+------------+-------+-------+-------+
 
 
-Functions from :mod:`pandas.io.sql` can extract some data into a DataFrame. In
-the following example, we use the `SQlite <http://www.sqlite.org/>`__ SQL database
-engine. You can use a temporary SQLite database where data are stored in
-"memory". Just do:
-
-.. code-block:: python
-
-   import sqlite3
-   from pandas.io import sql
-   # Create your connection.
-   cnx = sqlite3.connect(':memory:')
-
 .. ipython:: python
    :suppress:
 
-   import sqlite3
+   from sqlalchemy import create_engine
    from pandas.io import sql
-   cnx = sqlite3.connect(':memory:')
+   engine = create_engine('sqlite:///:memory:')
 
 .. ipython:: python
    :suppress:
 
-   cu = cnx.cursor()
-   # Create a table named 'data'.
-   cu.execute("""CREATE TABLE data(id integer,
-                                   date date,
-                                   Col_1 string,
-                                   Col_2 float,
-                                   Col_3 bool);""")
-   cu.executemany('INSERT INTO data VALUES (?,?,?,?,?)',
-                  [(26, datetime.datetime(2010,10,18), 'X', 27.5, True),
-                   (42, datetime.datetime(2010,10,19), 'Y', -12.5, False),
-                   (63, datetime.datetime(2010,10,20), 'Z', 5.73, True)])
+   c = ['id', 'Date', 'Col_1', 'Col_2', 'Col_3']
+   d = [(26, datetime.datetime(2010,10,18), 'X', 27.5, True),
+   (42, datetime.datetime(2010,10,19), 'Y', -12.5, False),
+   (63, datetime.datetime(2010,10,20), 'Z', 5.73, True)]
+
+   data  = DataFrame(d, columns=c)
+
+.. ipython:: python
 
+   sql.to_sql(data, 'data', engine)
 
-Let ``data`` be the name of your SQL table. With a query and your database
-connection, just use the :func:`~pandas.io.sql.read_sql` function to get the
-query results into a DataFrame:
+You can read from the database simply by
+specifying a table name using the :func:`~pandas.io.sql.read_table` function.
 
 .. ipython:: python
 
-   sql.read_sql("SELECT * FROM data;", cnx)
+   sql.read_table('data', engine)
 
 You can also specify the name of the column as the DataFrame index:
 
 .. ipython:: python
 
-   sql.read_sql("SELECT * FROM data;", cnx, index_col='id')
-   sql.read_sql("SELECT * FROM data;", cnx, index_col='date')
+   sql.read_table('data', engine, index_col='id')
 
-Of course, you can specify a more "complex" query.
+You can also query using raw SQL in the :func:`~pandas.io.sql.read_sql` function.
 
 .. ipython:: python
 
-   sql.read_sql("SELECT id, Col_1, Col_2 FROM data WHERE id = 42;", cnx)
+  sql.read_sql('SELECT * FROM data', engine)
+
+Of course, you can specify a more "complex" query.
 
 .. ipython:: python
-   :suppress:
 
-   cu.close()
-   cnx.close()
+   sql.read_frame("SELECT id, Col_1, Col_2 FROM data WHERE id = 42;", engine)
 
 
 There are a few other available functions:
 
-  - ``tquery`` returns a list of tuples corresponding to each row.
-  - ``uquery`` does the same thing as tquery, but instead of returning results
-    it returns the number of related rows.
-  - ``write_frame`` writes records stored in a DataFrame into the SQL table.
-  - ``has_table`` checks if a given SQLite table exists.
+:func:`~pandas.io.sql.has_table` checks if a given table exists.
 
-.. note::
+:func:`~pandas.io.sql.tquery` returns a list of tuples corresponding to each row.
+
+:func:`~pandas.io.sql.uquery` does the same thing as tquery, but instead of
+returning results it returns the number of related rows.
+
+In addition, the class :class:`~pandas.io.sql.PandasSQLWithEngine` can be
+instantiated directly for more manual control over the SQL interaction.
+
+Engine connection examples
+~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. code-block:: python
+
+  from sqlalchemy import create_engine
+
+  engine = create_engine('postgresql://scott:tiger@localhost:5432/mydatabase')
+
+  engine = create_engine('mysql+mysqldb://scott:tiger@localhost/foo')
+
+  engine = create_engine('oracle://scott:tiger@127.0.0.1:1521/sidname')
+
+  engine = create_engine('mssql+pyodbc://mydsn')
+
+  # sqlite://<nohostname>/<path>
+  # where <path> is relative:
+  engine = create_engine('sqlite:///foo.db')
+
+  # or absolute, starting with a slash:
+  engine = create_engine('sqlite:////absolute/path/to/foo.db')
+
+
+Legacy
+~~~~~~
+To use the sqlite support without SQLAlchemy, you can create connections like so:
+
+.. code-block:: python
+
+   import sqlite3
+   from pandas.io import sql
+   cnx = sqlite3.connect(':memory:')
+
+And then issue the following queries, remembering to also specify the flavor of SQL
+you are using.
+
+.. code-block:: python
+
+   sql.to_sql(data, 'data', cnx,  flavor='sqlite')
+
+   sql.read_sql("SELECT * FROM data", cnx, flavor='sqlite')
 
-   For now, writing your DataFrame into a database works only with
-   **SQLite**. Moreover, the **index** will currently be **dropped**.
 
 .. _io.bigquery:
 
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 25b04a34b..d09847a4b 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -18,10 +18,6 @@ class SQLAlchemyRequired(ImportError):
     pass
 
 
-class LegacyMySQLConnection(Exception):
-    pass
-
-
 class DatabaseError(IOError):
     pass
 
@@ -37,7 +33,7 @@ def _convert_params(sql, params):
     return args
 
 
-def execute(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
+def execute(sql, con, cur=None, params=[], flavor='sqlite'):
     """
     Execute the given SQL query using the provided connection object.
 
@@ -52,7 +48,8 @@ def execute(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
     cur: depreciated, cursor is obtained from connection
     params: list or tuple, optional
         List of parameters to pass to execute method.
-    flavor : string {sqlite, mysql} specifying the flavor of SQL to use.
+    flavor : string "sqlite", "mysql"
+        Specifies the flavor of SQL to use.
         Ignored when using SQLAlchemy engine. Required when using DBAPI2 connection.
     Returns
     -------
@@ -63,7 +60,7 @@ def execute(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
     return pandas_sql.execute(*args)
 
 
-def tquery(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
+def tquery(sql, con, cur=None, params=[], flavor='sqlite'):
     """
     Returns list of tuples corresponding to each row in given sql
     query.
@@ -81,9 +78,15 @@ def tquery(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
     cur: depreciated, cursor is obtained from connection
     params: list or tuple, optional
         List of parameters to pass to execute method.
-    flavor : string {sqlite, mysql} specifying the flavor of SQL to use.
+    flavor : string "sqlite", "mysql"
+        Specifies the flavor of SQL to use.
         Ignored when using SQLAlchemy engine. Required when using DBAPI2 connection.
+    Returns
+    -------
+    Results Iterable
     """
+    warnings.warn("tquery is depreciated, and will be removed in future versions", DeprecationWarning)
+
     pandas_sql = pandasSQL_builder(con=con, flavor=flavor)
     args = _convert_params(sql, params)
     return pandas_sql.tquery(*args)
@@ -105,9 +108,14 @@ def uquery(sql, con, cur=None, params=[], engine=None, flavor='sqlite'):
     cur: depreciated, cursor is obtained from connection
     params: list or tuple, optional
         List of parameters to pass to execute method.
-    flavor : string {sqlite, mysql} specifying the flavor of SQL to use.
+    flavor : string "sqlite", "mysql"
+        Specifies the flavor of SQL to use.
         Ignored when using SQLAlchemy engine. Required when using DBAPI2 connection.
+    Returns
+    -------
+    Number of affected rows
     """
+    warnings.warn("uquery is depreciated, and will be removed in future versions", DeprecationWarning)
     pandas_sql = pandasSQL_builder(con=con, flavor=flavor)
     args = _convert_params(sql, params)
     return pandas_sql.uquery(*args)
@@ -123,7 +131,7 @@ def read_sql(sql, con, index_col=None, flavor='sqlite', coerce_float=True, param
     string.
 
     Optionally provide an index_col parameter to use one of the
-    columns as the index. Otherwise will be 0 to len(results) - 1.
+    columns as the index, otherwise default integer index will be used
 
     Parameters
     ----------
@@ -143,11 +151,11 @@ def read_sql(sql, con, index_col=None, flavor='sqlite', coerce_float=True, param
     cur: depreciated, cursor is obtained from connection
     params: list or tuple, optional
         List of parameters to pass to execute method.
-    flavor : string {sqlite, mysql} specifying the flavor of SQL to use.
-        Ignored when using SQLAlchemy engine. Required when using DBAPI2 connection.
 
+    Returns
+    -------
+    DataFrame
     """
-
     pandas_sql = pandasSQL_builder(con=con, flavor=flavor)
     return pandas_sql.read_sql(sql, index_col=index_col, params=params, coerce_float=coerce_float)
 
@@ -174,6 +182,27 @@ def to_sql(frame, name, con, flavor='sqlite', if_exists='fail'):
     pandas_sql.to_sql(frame, name, if_exists=if_exists)
 
 
+def has_table(table_name, con, meta=None, flavor='sqlite'):
+    """
+    Check if DB has named table
+
+    Parameters
+    ----------
+    frame: DataFrame
+    name: name of SQL table
+    con: SQLAlchemy engine or DBAPI2 connection (legacy mode)
+        Using SQLAlchemy makes it possible to use any DB supported by that
+        library.
+        If a DBAPI2 object is given, a supported SQL flavor name must also be provided
+    flavor: {'sqlite', 'mysql'}, default 'sqlite', ignored when using engine
+    Returns
+    -------
+    boolean
+    """
+    pandas_sql = pandasSQL_builder(con=con, flavor=flavor)
+    return pandas_sql.has_table(table_name)
+
+
 # This is an awesome function
 def read_table(table_name, con, meta=None, index_col=None, coerce_float=True):
     """Given a table name and SQLAlchemy engine, return a DataFrame.
@@ -188,7 +217,9 @@ def read_table(table_name, con, meta=None, index_col=None, coerce_float=True):
     coerce_float : boolean, default True
         Attempt to convert values to non-string, non-numeric objects (like
         decimal.Decimal) to floating point. Can result in loss of Precision.
-
+    Returns
+    -------
+    DataFrame
     """
     pandas_sql = PandasSQLWithEngine(con, meta=meta)
     table = pandas_sql.get_table(table_name)
@@ -197,7 +228,7 @@ def read_table(table_name, con, meta=None, index_col=None, coerce_float=True):
         sql_select = table.select()
         return pandas_sql.read_sql(sql_select, index_col=index_col, coerce_float=coerce_float)
     else:
-        raise ValueError("Table %s not found with %s." % table_name, con)
+        raise ValueError("Table %s not found" % table_name, con)
 
 
 def pandasSQL_builder(con, flavor=None, meta=None):
@@ -211,34 +242,7 @@ def pandasSQL_builder(con, flavor=None, meta=None):
         if isinstance(con, sqlalchemy.engine.Engine):
             return PandasSQLWithEngine(con, meta=meta)
         else:
-<<<<<<< HEAD
-            if_exists = 'fail'
-
-    if if_exists not in ('fail', 'replace', 'append'):
-        raise ValueError("'%s' is not valid for if_exists" % if_exists)
-
-    exists = table_exists(name, con, flavor)
-    if if_exists == 'fail' and exists:
-        raise ValueError("Table '%s' already exists." % name)
-
-    # creation/replacement dependent on the table existing and if_exist criteria
-    create = None
-    if exists:
-        if if_exists == 'fail':
-            raise ValueError("Table '%s' already exists." % name)
-        elif if_exists == 'replace':
-            cur = con.cursor()
-            cur.execute("DROP TABLE %s;" % name)
-            cur.close()
-            create = get_schema(frame, name, flavor)
-    else:
-        create = get_schema(frame, name, flavor)
-
-    if create is not None:
-        cur = con.cursor()
-        cur.execute(create)
-=======
-            warnings.warn("Not a valid SQLAlchemy engine, attempting to use as legacy DBAPI connection")
+            warnings.warn("Not an SQLAlchemy engine, attempting to use as legacy DBAPI connection")
             if flavor is None:
                 raise ValueError("""PandasSQL must be created with an SQLAlchemy engine
                     or a DBAPI2 connection and SQL flavour""")
@@ -523,7 +527,7 @@ class PandasSQLWithCon(PandasSQL):
                                                  index_col=index_col,
                                                  coerce_float=coerce_float)
 
-    def to_sql(self, frame, name, con=None, if_exists='fail'):
+    def to_sql(self, frame, name, if_exists='fail'):
         """
         Write records stored in a DataFrame to a SQL database.
 
@@ -531,7 +535,6 @@ class PandasSQLWithCon(PandasSQL):
         ----------
         frame: DataFrame
         name: name of SQL table
-        con: an open SQL database connection object
         flavor: {'sqlite', 'mysql', 'postgres'}, default 'sqlite'
         if_exists: {'fail', 'replace', 'append'}, default 'fail'
             fail: If table exists, do nothing.
@@ -580,7 +583,6 @@ class PandasSQLWithCon(PandasSQL):
 
         cur = self.con.cursor()
         cur.executemany(insert_query, data)
->>>>>>> 1259dca... ENH #4163 Use SQLAlchemy for DB abstraction
         cur.close()
 
     def _create_table(self, frame, name, keys=None):
@@ -646,8 +648,8 @@ class PandasSQLWithCon(PandasSQL):
         return _SQL_TYPES[pytype_name][self.flavor]
 
 
-# legacy names
-def get_schema(frame, name, con=None, flavor='sqlite', engine=None):
+# legacy names, with depreciation warnings and copied docs
+def get_schema(frame, name, con, flavor='sqlite'):
     """
     Get the SQL db table schema for the given frame
 
@@ -664,8 +666,21 @@ def get_schema(frame, name, con=None, flavor='sqlite', engine=None):
     return pandas_sql._create_sql_schema()
 
 
+def read_frame(*args, **kwargs):
+    """DEPRECIATED - use read_sql
+    """
+    warnings.warn("read_frame is depreciated, use read_sql", DeprecationWarning)
+    return read_sql(*args, **kwargs)
+
+
+def write_frame(*args, **kwargs):
+    """DEPRECIATED - use to_sql
+    """
+    warnings.warn("write_frame is depreciated, use to_sql", DeprecationWarning)
+    return to_sql(*args, **kwargs)
+
 
-#TODO: add depreciation warnings
-read_frame = read_sql
-write_frame = to_sql
+#Append wrapped function docstrings
+read_frame.__doc__ += read_sql.__doc__
+write_frame.__doc__ += to_sql.__doc__
 
diff --git a/pandas/io/sql_legacy.py b/pandas/io/sql_legacy.py
deleted file mode 100644
index a8a5d968d..000000000
--- a/pandas/io/sql_legacy.py
+++ /dev/null
@@ -1,332 +0,0 @@
-"""
-Collection of query wrappers / abstractions to both facilitate data
-retrieval and to reduce dependency on DB-specific API.
-"""
-from datetime import datetime, date
-
-import numpy as np
-import traceback
-
-from pandas.core.datetools import format as date_format
-from pandas.core.api import DataFrame, isnull
-
-#------------------------------------------------------------------------------
-# Helper execution function
-
-
-def execute(sql, con, retry=True, cur=None, params=None):
-    """
-    Execute the given SQL query using the provided connection object.
-
-    Parameters
-    ----------
-    sql: string
-        Query to be executed
-    con: database connection instance
-        Database connection.  Must implement PEP249 (Database API v2.0).
-    retry: bool
-        Not currently implemented
-    cur: database cursor, optional
-        Must implement PEP249 (Datbase API v2.0).  If cursor is not provided,
-        one will be obtained from the database connection.
-    params: list or tuple, optional
-        List of parameters to pass to execute method.
-
-    Returns
-    -------
-    Cursor object
-    """
-    try:
-        if cur is None:
-            cur = con.cursor()
-
-        if params is None:
-            cur.execute(sql)
-        else:
-            cur.execute(sql, params)
-        return cur
-    except Exception:
-        try:
-            con.rollback()
-        except Exception:  # pragma: no cover
-            pass
-
-        print ('Error on sql %s' % sql)
-        raise
-
-
-def _safe_fetch(cur):
-    try:
-        result = cur.fetchall()
-        if not isinstance(result, list):
-            result = list(result)
-        return result
-    except Exception, e:  # pragma: no cover
-        excName = e.__class__.__name__
-        if excName == 'OperationalError':
-            return []
-
-
-def tquery(sql, con=None, cur=None, retry=True):
-    """
-    Returns list of tuples corresponding to each row in given sql
-    query.
-
-    If only one column selected, then plain list is returned.
-
-    Parameters
-    ----------
-    sql: string
-        SQL query to be executed
-    con: SQLConnection or DB API 2.0-compliant connection
-    cur: DB API 2.0 cursor
-
-    Provide a specific connection or a specific cursor if you are executing a
-    lot of sequential statements and want to commit outside.
-    """
-    cur = execute(sql, con, cur=cur)
-    result = _safe_fetch(cur)
-
-    if con is not None:
-        try:
-            cur.close()
-            con.commit()
-        except Exception as e:
-            excName = e.__class__.__name__
-            if excName == 'OperationalError':  # pragma: no cover
-                print ('Failed to commit, may need to restart interpreter')
-            else:
-                raise
-
-            traceback.print_exc()
-            if retry:
-                return tquery(sql, con=con, retry=False)
-
-    if result and len(result[0]) == 1:
-        # python 3 compat
-        result = list(list(zip(*result))[0])
-    elif result is None:  # pragma: no cover
-        result = []
-
-    return result
-
-
-def uquery(sql, con=None, cur=None, retry=True, params=None):
-    """
-    Does the same thing as tquery, but instead of returning results, it
-    returns the number of rows affected.  Good for update queries.
-    """
-    cur = execute(sql, con, cur=cur, retry=retry, params=params)
-
-    result = cur.rowcount
-    try:
-        con.commit()
-    except Exception as e:
-        excName = e.__class__.__name__
-        if excName != 'OperationalError':
-            raise
-
-        traceback.print_exc()
-        if retry:
-            print ('Looks like your connection failed, reconnecting...')
-            return uquery(sql, con, retry=False)
-    return result
-
-
-def read_frame(sql, con, index_col=None, coerce_float=True, params=None):
-    """
-    Returns a DataFrame corresponding to the result set of the query
-    string.
-
-    Optionally provide an index_col parameter to use one of the
-    columns as the index. Otherwise will be 0 to len(results) - 1.
-
-    Parameters
-    ----------
-    sql: string
-        SQL query to be executed
-    con: DB connection object, optional
-    index_col: string, optional
-        column name to use for the returned DataFrame object.
-    coerce_float : boolean, default True
-        Attempt to convert values to non-string, non-numeric objects (like
-        decimal.Decimal) to floating point, useful for SQL result sets
-    params: list or tuple, optional
-        List of parameters to pass to execute method.
-    """
-    cur = execute(sql, con, params=params)
-    rows = _safe_fetch(cur)
-    columns = [col_desc[0] for col_desc in cur.description]
-
-    cur.close()
-    con.commit()
-
-    result = DataFrame.from_records(rows, columns=columns,
-                                    coerce_float=coerce_float)
-
-    if index_col is not None:
-        result = result.set_index(index_col)
-
-    return result
-
-frame_query = read_frame
-read_sql = read_frame
-
-
-def write_frame(frame, name, con, flavor='sqlite', if_exists='fail', **kwargs):
-    """
-    Write records stored in a DataFrame to a SQL database.
-
-    Parameters
-    ----------
-    frame: DataFrame
-    name: name of SQL table
-    con: an open SQL database connection object
-    flavor: {'sqlite', 'mysql', 'oracle'}, default 'sqlite'
-    if_exists: {'fail', 'replace', 'append'}, default 'fail'
-        fail: If table exists, do nothing.
-        replace: If table exists, drop it, recreate it, and insert data.
-        append: If table exists, insert data. Create if does not exist.
-    """
-
-    if 'append' in kwargs:
-        import warnings
-        warnings.warn("append is deprecated, use if_exists instead",
-                      FutureWarning)
-        if kwargs['append']:
-            if_exists='append'
-        else:
-            if_exists='fail'
-    exists = table_exists(name, con, flavor)
-    if if_exists == 'fail' and exists:
-        raise ValueError, "Table '%s' already exists." % name
-
-    #create or drop-recreate if necessary
-    create = None
-    if exists and if_exists == 'replace':
-        create = "DROP TABLE %s" % name
-    elif not exists:
-        create = get_schema(frame, name, flavor)
-
-    if create is not None:
-        cur = con.cursor()
-        cur.execute(create)
-        cur.close()
-
-    cur = con.cursor()
-    # Replace spaces in DataFrame column names with _.
-    safe_names = [s.replace(' ', '_').strip() for s in frame.columns]
-    flavor_picker = {'sqlite' : _write_sqlite,
-                     'mysql' : _write_mysql}
-
-    func = flavor_picker.get(flavor, None)
-    if func is None:
-        raise NotImplementedError
-    func(frame, name, safe_names, cur)
-    cur.close()
-    con.commit()
-
-
-def _write_sqlite(frame, table, names, cur):
-    bracketed_names = ['[' + column + ']' for column in names]
-    col_names = ','.join(bracketed_names)
-    wildcards = ','.join(['?'] * len(names))
-    insert_query = 'INSERT INTO %s (%s) VALUES (%s)' % (
-        table, col_names, wildcards)
-    # pandas types are badly handled if there is only 1 column ( Issue #3628 )
-    if   not len(frame.columns  )==1 :
-        data = [tuple(x) for x in frame.values]
-    else :
-        data = [tuple(x) for x in frame.values.tolist()]
-    cur.executemany(insert_query, data)
-
-
-def _write_mysql(frame, table, names, cur):
-    bracketed_names = ['`' + column + '`' for column in names]
-    col_names = ','.join(bracketed_names)
-    wildcards = ','.join([r'%s'] * len(names))
-    insert_query = "INSERT INTO %s (%s) VALUES (%s)" % (
-        table, col_names, wildcards)
-    data = [tuple(x) for x in frame.values]
-    cur.executemany(insert_query, data)
-
-
-def table_exists(name, con, flavor):
-    flavor_map = {
-        'sqlite': ("SELECT name FROM sqlite_master "
-                   "WHERE type='table' AND name='%s';") % name,
-        'mysql' : "SHOW TABLES LIKE '%s'" % name}
-    query = flavor_map.get(flavor, None)
-    if query is None:
-        raise NotImplementedError
-    return len(tquery(query, con)) > 0
-
-
-def get_sqltype(pytype, flavor):
-    sqltype = {'mysql': 'VARCHAR (63)',
-               'sqlite': 'TEXT'}
-
-    if issubclass(pytype, np.floating):
-        sqltype['mysql'] = 'FLOAT'
-        sqltype['sqlite'] = 'REAL'
-
-    if issubclass(pytype, np.integer):
-        #TODO: Refine integer size.
-        sqltype['mysql'] = 'BIGINT'
-        sqltype['sqlite'] = 'INTEGER'
-
-    if issubclass(pytype, np.datetime64) or pytype is datetime:
-        # Caution: np.datetime64 is also a subclass of np.number.
-        sqltype['mysql'] = 'DATETIME'
-        sqltype['sqlite'] = 'TIMESTAMP'
-
-    if pytype is datetime.date:
-        sqltype['mysql'] = 'DATE'
-        sqltype['sqlite'] = 'TIMESTAMP'
-
-    if issubclass(pytype, np.bool_):
-        sqltype['sqlite'] = 'INTEGER'
-
-    return sqltype[flavor]
-
-
-def get_schema(frame, name, flavor, keys=None):
-    "Return a CREATE TABLE statement to suit the contents of a DataFrame."
-    lookup_type = lambda dtype: get_sqltype(dtype.type, flavor)
-    # Replace spaces in DataFrame column names with _.
-    safe_columns = [s.replace(' ', '_').strip() for s in frame.dtypes.index]
-    column_types = zip(safe_columns, map(lookup_type, frame.dtypes))
-    if flavor == 'sqlite':
-        columns = ',\n  '.join('[%s] %s' % x for x in column_types)
-    else:
-        columns = ',\n  '.join('`%s` %s' % x for x in column_types)
-
-    keystr = ''
-    if keys is not None:
-        if isinstance(keys, basestring):
-            keys = (keys,)
-        keystr = ', PRIMARY KEY (%s)' % ','.join(keys)
-    template = """CREATE TABLE %(name)s (
-                  %(columns)s
-                  %(keystr)s
-                  );"""
-    create_statement = template % {'name': name, 'columns': columns,
-                                   'keystr': keystr}
-    return create_statement
-
-
-def sequence2dict(seq):
-    """Helper function for cx_Oracle.
-
-    For each element in the sequence, creates a dictionary item equal
-    to the element and keyed by the position of the item in the list.
-    >>> sequence2dict(("Matt", 1))
-    {'1': 'Matt', '2': 1}
-
-    Source:
-    http://www.gingerandjohn.com/archives/2004/02/26/cx_oracle-executemany-example/
-    """
-    d = {}
-    for k,v in zip(range(1, 1 + len(seq)), seq):
-        d[str(k)] = v
-    return d
diff --git a/pandas/io/tests/test_sql.py b/pandas/io/tests/test_sql.py
index ffde31103..491bfb44e 100644
--- a/pandas/io/tests/test_sql.py
+++ b/pandas/io/tests/test_sql.py
@@ -6,29 +6,24 @@ import os
 
 import numpy as np
 
-#from pandas.core.datetools import format as date_format
 from pandas import DataFrame
 from pandas.compat import range, lrange, iteritems
-
+#from pandas.core.datetools import format as date_format
 
 import pandas.io.sql as sql
 import pandas.util.testing as tm
 
-import sqlalchemy
 
+try:
+    import sqlalchemy
+    SQLALCHEMY_INSTALLED = True
+except ImportError:
+    SQLALCHEMY_INSTALLED = False
 
-class TestSQLAlchemy(unittest.TestCase):
-    '''
-    Test the sqlalchemy backend against an in-memory sqlite database.
-    Assume that sqlalchemy takes case of the DB specifics
-    '''
 
-    def setUp(self):
-        self.engine = sqlalchemy.create_engine('sqlite:///:memory:')
-        self._load_iris_data(self.engine)
-
-        self.test_frame_time = tm.makeTimeDataFrame()
-        self._load_test1_data()
+class PandasSQLTest(unittest.TestCase):
+    """Base class with common private methods for
+    SQLAlchemy and fallback case test suits"""
 
     def _load_iris_data(self, engine):
         self.dirpath = tm.get_data_path()
@@ -49,7 +44,14 @@ class TestSQLAlchemy(unittest.TestCase):
                 VALUES(?, ?, ?, ?, ?)
                 """
             for row in r:
-                engine.execute(ins, *row)
+                engine.execute(ins, row)
+
+    def _check_iris_loaded_frame(self, iris_frame):
+        pytype = iris_frame.dtypes[0].type
+        row = iris_frame.iloc[0]
+
+        self.assertTrue(issubclass(pytype, np.floating), 'Loaded frame has incorrect type')
+        tm.equalContents(row.values, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
 
     def _load_test1_data(self):
         test1_csv_file = os.path.join(self.dirpath, 'test1.csv')
@@ -58,106 +60,165 @@ class TestSQLAlchemy(unittest.TestCase):
             dr = csv.DictReader(test1_csv)
             self.test_frame1 = DataFrame(list(dr))
 
-    def _test_iris_loaded_frame(self, iris_frame):
-        pytype = iris_frame.dtypes[0].type
-        row = iris_frame.iloc[0]
-
-        self.assertTrue(issubclass(pytype, np.floating), 'Loaded frame has incorrect type')
-        tm.equalContents(row.values, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
+    def _count_rows(self, table_name, con):
+        result = con.execute("SELECT count(*) AS count_1 FROM %s" % table_name).fetchone()
+        return result[0]
 
-    def test_read_sql(self):
-        iris_frame = sql.read_sql("SELECT * FROM iris", con=self.engine)
-        self._test_iris_loaded_frame(iris_frame)
-
-    def test_read_table(self):
-        iris_frame = sql.read_table("iris", con=self.engine)
-        self._test_iris_loaded_frame(iris_frame)
+    def _read_sql_iris(self):
+        iris_frame = self.pandasSQL.read_sql("SELECT * FROM iris")
+        self._check_iris_loaded_frame(iris_frame)
 
-    def test_to_sql(self):
+    def _to_sql(self):
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine)
-        self.assertTrue(self.engine.has_table('test_frame1'), 'Table not written to DB')
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1')
+        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-    def test_to_sql_fail(self):
+    def _to_sql_fail(self):
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine, if_exists='fail')
-        self.assertTrue(self.engine.has_table('test_frame1'), 'Table not written to DB')
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1', if_exists='fail')
+        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
-        self.assertRaises(ValueError, sql.to_sql, self.test_frame1, 'test_frame1', con=self.engine, if_exists='fail')
+        self.assertRaises(ValueError, self.pandasSQL.to_sql, self.test_frame1, 'test_frame1', if_exists='fail')
 
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-    def test_to_sql_replace(self):
+    def _to_sql_replace(self):
         # Nuke table just in case
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine, if_exists='fail')
+        self.drop_table('test_frame1', self.conn)
+
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1', if_exists='fail')
         # Add to table again
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine, if_exists='replace')
-        self.assertTrue(self.engine.has_table('test_frame1'), 'Table not written to DB')
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1', if_exists='replace')
+        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
         num_entries = len(self.test_frame1)
-
-        result = self.engine.execute("SELECT count(*) AS count_1 FROM test_frame1").fetchone()
-        num_rows = result[0]
+        num_rows = self._count_rows('test_frame1', self.conn)
 
         self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
 
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-    def test_to_sql_append(self):
+    def _to_sql_append(self):
         # Nuke table just in case
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine, if_exists='fail')
+        self.drop_table('test_frame1', self.conn)
+
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1', if_exists='fail')
+
         # Add to table again
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.engine, if_exists='append')
-        self.assertTrue(self.engine.has_table('test_frame1'), 'Table not written to DB')
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame1', if_exists='append')
+        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
         num_entries = 2*len(self.test_frame1)
-        result = self.engine.execute("SELECT count(*) AS count_1 FROM test_frame1").fetchone()
-        num_rows = result[0]
+        num_rows = self._count_rows('test_frame1', self.conn)
 
         self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
 
         # Nuke table
-        self.engine.execute("DROP TABLE IF EXISTS test_frame1")
+        self.drop_table('test_frame1', self.conn)
 
-    def test_create_table(self):
-        temp_engine = sqlalchemy.create_engine('sqlite:///:memory:')
-        temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
+    def _roundtrip(self):
+        self.pandasSQL.to_sql(self.test_frame1, 'test_frame_roundtrip')
+        result = self.pandasSQL.read_sql('SELECT * FROM test_frame_roundtrip')
 
-        pandasSQL = sql.PandasSQLWithEngine(temp_engine)
-        pandasSQL._create_table(temp_frame, 'temp_frame')
+        # HACK!
+        result.index = self.test_frame1.index
 
-        self.assertTrue(temp_engine.has_table('temp_frame'), 'Table not written to DB')
+        tm.assert_frame_equal(result, self.test_frame1)
 
-    def test_drop_table(self):
-        temp_engine = sqlalchemy.create_engine('sqlite:///:memory:')
+    def _execute_sql(self):
+        # drop_sql = "DROP TABLE IF EXISTS test"  # should already be done
+        iris_results = self.pandasSQL.execute("SELECT * FROM iris")
+        row = iris_results.fetchone()
+        tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
 
-        temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
+    def _tquery(self):
+        iris_results = self.pandasSQL.tquery("SELECT * FROM iris")
+        row = iris_results[0]
+        tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
 
-        pandasSQL = sql.PandasSQLWithEngine(temp_engine)
-        pandasSQL._create_table(temp_frame, 'temp_frame')
 
-        self.assertTrue(temp_engine.has_table('temp_frame'), 'Table not written to DB')
+class TestSQLApi(PandasSQLTest):
+    """Test the public API as it would be used
+    directly, including legacy names
 
-        pandasSQL._drop_table('temp_frame')
+    Notes:
+    flavor can always be passed even in SQLAlchemy mode,
+    should be correctly ignored.
 
-        self.assertFalse(temp_engine.has_table('temp_frame'), 'Table not deleted from DB')
+    we don't use drop_table because that isn't part of the public api
 
-    def test_roundtrip(self):
-        #temp_engine = sqlalchemy.create_engine('sqlite:///:memory:')
+    """
+    def connect(self):
+        if SQLALCHEMY_INSTALLED:
+            return sqlalchemy.create_engine('sqlite:///:memory:')
+        else:
+            return sqlite3.connect(':memory:')
+
+    def setUp(self):
+        self.conn = self.connect()
+        self._load_iris_data(self.conn)
+        self._load_test1_data()
+
+    def test_read_sql_iris(self):
+        iris_frame = sql.read_sql("SELECT * FROM iris", self.conn, flavor='sqlite')
+        self._check_iris_loaded_frame(iris_frame)
+
+    def test_legacy_read_frame(self):
+        """Test legacy name read_frame"""
+        iris_frame = sql.read_frame("SELECT * FROM iris", self.conn, flavor='sqlite')
+        self._check_iris_loaded_frame(iris_frame)
+
+    def test_to_sql(self):
+        sql.to_sql(self.test_frame1, 'test_frame1', self.conn, flavor='sqlite')
+        self.assertTrue(sql.has_table('test_frame1', self.conn, flavor='sqlite'), 'Table not written to DB')
+
+    def test_to_sql_fail(self):
+        sql.to_sql(self.test_frame1, 'test_frame2', self.conn, flavor='sqlite', if_exists='fail')
+        self.assertTrue(sql.has_table('test_frame2', self.conn, flavor='sqlite'), 'Table not written to DB')
+
+        self.assertRaises(ValueError, sql.to_sql, self.test_frame1, 'test_frame2', self.conn, flavor='sqlite', if_exists='fail')
+
+    def test_to_sql_replace(self):
+        sql.to_sql(self.test_frame1, 'test_frame3', self.conn, flavor='sqlite', if_exists='fail')
+        # Add to table again
+        sql.to_sql(self.test_frame1, 'test_frame3', self.conn, flavor='sqlite', if_exists='replace')
+        self.assertTrue(sql.has_table('test_frame3', self.conn, flavor='sqlite'), 'Table not written to DB')
 
-        sql.to_sql(self.test_frame1, 'test_frame_roundtrip', con=self.engine)
-        result = sql.read_table('test_frame_roundtrip', con=self.engine)
+        num_entries = len(self.test_frame1)
+        num_rows = self._count_rows('test_frame3', self.conn)
+
+        self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
+
+    def test_to_sql_append(self):
+        sql.to_sql(self.test_frame1, 'test_frame4', self.conn, flavor='sqlite', if_exists='fail')
+
+        # Add to table again
+        sql.to_sql(self.test_frame1, 'test_frame4', self.conn, flavor='sqlite', if_exists='append')
+        self.assertTrue(sql.has_table('test_frame4', self.conn, flavor='sqlite'), 'Table not written to DB')
+
+        num_entries = 2*len(self.test_frame1)
+        num_rows = self._count_rows('test_frame4', self.conn)
+
+        self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
+
+    def test_legacy_write_frame(self):
+        """Test legacy write frame name.
+        Assume that functionality is already tested above so just do quick check that it basically works"""
+        sql.write_frame(self.test_frame1, 'test_frame_legacy', self.conn, flavor='sqlite')
+        self.assertTrue(sql.has_table('test_frame_legacy', self.conn, flavor='sqlite'), 'Table not written to DB')
+
+    def test_roundtrip(self):
+        sql.to_sql(self.test_frame1, 'test_frame_roundtrip', con=self.conn, flavor='sqlite')
+        result = sql.read_sql('SELECT * FROM test_frame_roundtrip', con=self.conn, flavor='sqlite')
 
         # HACK!
         result.index = self.test_frame1.index
@@ -166,244 +227,138 @@ class TestSQLAlchemy(unittest.TestCase):
 
     def test_execute_sql(self):
         # drop_sql = "DROP TABLE IF EXISTS test"  # should already be done
-        iris_results = sql.execute("SELECT * FROM iris", con=self.engine)
+        iris_results = sql.execute("SELECT * FROM iris", con=self.conn, flavor='sqlite')
         row = iris_results.fetchone()
         tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
 
     def test_tquery(self):
-        iris_results = sql.tquery("SELECT * FROM iris", con=self.engine)
+        iris_results = sql.tquery("SELECT * FROM iris", con=self.conn, flavor='sqlite')
         row = iris_results[0]
         tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
 
-# --- Test SQLITE fallback
-
 
-class TestSQLite(unittest.TestCase):
+class TestSQLAlchemy(PandasSQLTest):
     '''
     Test the sqlalchemy backend against an in-memory sqlite database.
     Assume that sqlalchemy takes case of the DB specifics
     '''
+    def connect(self):
+        return sqlalchemy.create_engine('sqlite:///:memory:')
 
-<<<<<<< HEAD
-        try:
-            sys.stdout = StringIO()
+    def drop_table(self, table_name, conn):
+        conn.execute("DROP TABLE IF EXISTS %s" % table_name)
 
-            self.assertRaises(sqlite3.OperationalError, sql.tquery,
-                              'insert into blah values (1)', con=self.db)
+    def setUp(self):
+        # Skip this test if SQLAlchemy not available
+        if not SQLALCHEMY_INSTALLED:
+            raise unittest.SkipTest('SQLAlchemy not installed')
 
-            self.assertRaises(sqlite3.OperationalError, sql.tquery,
-                              'insert into blah values (1)', con=self.db,
-                              retry=True)
-        finally:
-            sys.stdout = sys.__stdout__
+        self.conn = self.connect()
+        self.pandasSQL = sql.PandasSQLWithEngine(self.conn)
 
-    def test_keyword_as_column_names(self):
-        '''
-        '''
-        df = DataFrame({'From':np.ones(5)})
-        sql.write_frame(df, con = self.db, name = 'testkeywords')
+        self._load_iris_data(self.conn)
 
-    def test_onecolumn_of_integer(self):
-        # GH 3628
-        # a column_of_integers dataframe should transfer well to sql
+        self._load_test1_data()
 
-        mono_df=DataFrame([1 , 2], columns=['c0'])
-        sql.write_frame(mono_df, con = self.db, name = 'mono_df')
-        # computing the sum via sql
-        con_x=self.db
-        the_sum=sum([my_c0[0] for  my_c0 in con_x.execute("select * from mono_df")])
-        # it should not fail, and gives 3 ( Issue #3628 )
-        self.assertEqual(the_sum , 3)
+    def test_read_sql(self):
+        self._read_sql_iris()
 
-        result = sql.read_frame("select * from mono_df",con_x)
-        tm.assert_frame_equal(result,mono_df)
+    def test_read_table(self):
+        iris_frame = sql.read_table("iris", con=self.conn)
+        self._check_iris_loaded_frame(iris_frame)
 
-    def test_if_exists(self):
-        df_if_exists_1 = DataFrame({'col1': [1, 2], 'col2': ['A', 'B']})
-        df_if_exists_2 = DataFrame({'col1': [3, 4, 5], 'col2': ['C', 'D', 'E']})
-        table_name = 'table_if_exists'
-        sql_select = "SELECT * FROM %s" % table_name
+    def test_read_table_absent(self):
+        self.assertRaises(ValueError, sql.read_table, "this_doesnt_exist", con=self.conn)
 
-        def clean_up(test_table_to_drop):
-            """
-            Drops tables created from individual tests
-            so no dependencies arise from sequential tests
-            """
-            if sql.table_exists(test_table_to_drop, self.db, flavor='sqlite'):
-                cur = self.db.cursor()
-                cur.execute("DROP TABLE %s" % test_table_to_drop)
-                cur.close()
+    def test_to_sql(self):
+        self._to_sql()
 
-        # test if invalid value for if_exists raises appropriate error
-        self.assertRaises(ValueError,
-                          sql.write_frame,
-                          frame=df_if_exists_1,
-                          con=self.db,
-                          name=table_name,
-                          flavor='sqlite',
-                          if_exists='notvalidvalue')
-        clean_up(table_name)
+    def test_to_sql_fail(self):
+        self._to_sql_fail()
 
-        # test if_exists='fail'
-        sql.write_frame(frame=df_if_exists_1, con=self.db, name=table_name,
-                        flavor='sqlite', if_exists='fail')
-        self.assertRaises(ValueError,
-                          sql.write_frame,
-                          frame=df_if_exists_1,
-                          con=self.db,
-                          name=table_name,
-                          flavor='sqlite',
-                          if_exists='fail')
+    def test_to_sql_replace(self):
+        self._to_sql_replace()
 
-        # test if_exists='replace'
-        sql.write_frame(frame=df_if_exists_1, con=self.db, name=table_name,
-                        flavor='sqlite', if_exists='replace')
-        self.assertEqual(sql.tquery(sql_select, con=self.db),
-                         [(1, 'A'), (2, 'B')])
-        sql.write_frame(frame=df_if_exists_2, con=self.db, name=table_name,
-                        flavor='sqlite', if_exists='replace')
-        self.assertEqual(sql.tquery(sql_select, con=self.db),
-                         [(3, 'C'), (4, 'D'), (5, 'E')])
-        clean_up(table_name)
-                        
-        # test if_exists='append'
-        sql.write_frame(frame=df_if_exists_1, con=self.db, name=table_name,
-                        flavor='sqlite', if_exists='fail')
-        self.assertEqual(sql.tquery(sql_select, con=self.db),
-                         [(1, 'A'), (2, 'B')])
-        sql.write_frame(frame=df_if_exists_2, con=self.db, name=table_name,
-                        flavor='sqlite', if_exists='append')
-        self.assertEqual(sql.tquery(sql_select, con=self.db),
-                         [(1, 'A'), (2, 'B'), (3, 'C'), (4, 'D'), (5, 'E')])
-        clean_up(table_name)
+    def test_to_sql_append(self):
+        self._to_sql_append()
 
+    def test_create_table(self):
+        temp_conn = self.connect()
+        temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
 
-class TestMySQL(tm.TestCase):
-=======
-    def setUp(self):
-        self.conn = sqlite3.connect(':memory:')
-        self.pandasSQL = sql.PandasSQLWithCon(self.conn, 'sqlite')
+        pandasSQL = sql.PandasSQLWithEngine(temp_conn)
+        pandasSQL._create_table(temp_frame, 'temp_frame')
 
-        self._load_iris_data(self.conn)
+        self.assertTrue(temp_conn.has_table('temp_frame'), 'Table not written to DB')
 
-        self.test_frame_time = tm.makeTimeDataFrame()
-        self._load_test1_data()
+    def test_drop_table(self):
+        temp_conn = self.connect()
 
-    def _load_iris_data(self, conn):
-        self.dirpath = tm.get_data_path()
-        iris_csv_file = os.path.join(self.dirpath, 'iris.csv')
-        cur = conn.cursor()
-        cur.execute("""CREATE TABLE iris (
-                `SepalLength` REAL,
-                `SepalWidth` REAL,
-                `PetalLength` REAL,
-                `PetalWidth` REAL,
-                `Name` TEXT
-            )""")
+        temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
 
-        with open(iris_csv_file, 'rU') as iris_csv:
-            r = csv.reader(iris_csv)
-            next(r)  # skip header row
-            ins = """
-                INSERT INTO iris
-                VALUES(?, ?, ?, ?, ?)
-                """
-            for row in r:
-                cur.execute(ins, row)
-        conn.commit()
+        pandasSQL = sql.PandasSQLWithEngine(temp_conn)
+        pandasSQL._create_table(temp_frame, 'temp_frame')
 
-    def _load_test1_data(self):
-        test1_csv_file = os.path.join(self.dirpath, 'test1.csv')
+        self.assertTrue(temp_conn.has_table('temp_frame'), 'Table not written to DB')
 
-        with open(test1_csv_file, 'rU') as test1_csv:
-            dr = csv.DictReader(test1_csv)
-            self.test_frame1 = DataFrame(list(dr))
+        pandasSQL._drop_table('temp_frame')
 
-    def test_read_sql(self):
-        iris_frame = sql.read_sql("SELECT * FROM iris", con=self.conn)
-        pytype = iris_frame.dtypes[0].type
-        row = iris_frame.iloc[0]
+        self.assertFalse(temp_conn.has_table('temp_frame'), 'Table not deleted from DB')
 
-        self.assertTrue(issubclass(pytype, np.floating), 'Loaded frame has incorrect type')
-        tm.equalContents(row.values, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
+    def test_roundtrip(self):
+        self._roundtrip()
 
-    def test_to_sql(self):
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
-        
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, flavor='sqlite')
-        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
+    def test_execute_sql(self):
+        self._execute_sql()
 
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
+    def test_tquery(self):
+        self._tquery()
 
-    def test_to_sql_fail(self):
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, if_exists='fail', flavor='sqlite')
-        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
-        self.assertRaises(ValueError, sql.to_sql, self.test_frame1, 'test_frame1', con=self.conn, if_exists='fail')
+# --- Test SQLITE fallback
 
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
 
-    def test_to_sql_replace(self):
-        # Nuke table just in case
+class TestSQLite(PandasSQLTest):
+    '''
+    Test the sqlalchemy backend against an in-memory sqlite database.
+    Assume that sqlalchemy takes case of the DB specifics
+    '''
+    def connect(self):
+        return sqlite3.connect(':memory:')
+
+    def drop_table(self, table_name, conn):
         cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
+        cur.execute("DROP TABLE IF EXISTS %s" % table_name)
         self.conn.commit()
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, if_exists='fail', flavor='sqlite')
-        # Add to table again
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, if_exists='replace')
-        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
 
-        num_entries = len(self.test_frame1)
-
-        result = self.conn.execute("SELECT count(*) AS count_1 FROM test_frame1").fetchone()
-        num_rows = result[0]
+    def setUp(self):
+        self.conn = self.connect()
+        self.pandasSQL = sql.PandasSQLWithCon(self.conn, 'sqlite')
 
-        self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
->>>>>>> 1259dca... ENH #4163 Use SQLAlchemy for DB abstraction
+        self._load_iris_data(self.conn)
 
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
+        self._load_test1_data()
 
-    def test_to_sql_append(self):
-        # Nuke table just in case
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
+    def test_invalid_flavor(self):
+        self.assertRaises(NotImplementedError, sql.PandasSQLWithCon, self.conn, 'oracle')
 
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, if_exists='fail', flavor='sqlite')
+    def test_read_sql(self):
+        self._read_sql_iris()
 
-        # Add to table again
-        sql.to_sql(self.test_frame1, 'test_frame1', con=self.conn, if_exists='append')
-        self.assertTrue(self.pandasSQL.has_table('test_frame1'), 'Table not written to DB')
+    def test_to_sql(self):
+        self._to_sql()
 
-        num_entries = 2*len(self.test_frame1)
-        result = self.conn.execute("SELECT count(*) AS count_1 FROM test_frame1").fetchone()
-        num_rows = result[0]
+    def test_to_sql_fail(self):
+        self._to_sql_fail()
 
-        self.assertEqual(num_rows, num_entries, "not the same number of rows as entries")
+    def test_to_sql_replace(self):
+        self._to_sql_replace()
 
-        # Nuke table
-        cur = self.conn.cursor()
-        cur.execute("DROP TABLE IF EXISTS test_frame1")
-        self.conn.commit()
+    def test_to_sql_append(self):
+        self._to_sql_append()
 
     def test_create_table(self):
-        temp_conn = sqlite3.connect(':memory:')
+        temp_conn = self.connect()
         temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
 
         pandasSQL = sql.PandasSQLWithCon(temp_conn, 'sqlite')
@@ -412,7 +367,7 @@ class TestMySQL(tm.TestCase):
         self.assertTrue(pandasSQL.has_table('temp_frame'), 'Table not written to DB')
 
     def test_drop_table(self):
-        temp_conn = sqlite3.connect(':memory:')
+        temp_conn = self.connect()
 
         temp_frame = DataFrame({'one': [1., 2., 3., 4.], 'two': [4., 3., 2., 1.]})
 
@@ -426,27 +381,13 @@ class TestMySQL(tm.TestCase):
         self.assertFalse(pandasSQL.has_table('temp_frame'), 'Table not deleted from DB')
 
     def test_roundtrip(self):
-
-        sql.to_sql(self.test_frame1, 'test_frame_roundtrip', con=self.conn, flavor='sqlite')
-        result = sql.read_sql('SELECT * FROM test_frame_roundtrip', con=self.conn, flavor='sqlite')
-
-        # HACK!
-        result.index = self.test_frame1.index
-
-        tm.assert_frame_equal(result, self.test_frame1)
+        self._roundtrip()
 
     def test_execute_sql(self):
-        # drop_sql = "DROP TABLE IF EXISTS test"  # should already be done
-        iris_results = sql.execute("SELECT * FROM iris", con=self.conn, flavor='sqlite')
-        row = iris_results.fetchone()
-        tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
+        self._execute_sql()
 
     def test_tquery(self):
-        iris_results = sql.tquery("SELECT * FROM iris", con=self.conn, flavor='sqlite')
-        row = iris_results[0]
-        tm.equalContents(row, [5.1, 3.5, 1.4, 0.2, 'Iris-setosa'])
-
-
+        self._tquery()
 
 
 """
@@ -556,7 +497,7 @@ class TestSQLA_MySQLdb(TestSQLAlchemy):
         self.assertEqual(sql.tquery(sql_select, con=self.db),
                          [(3, 'C'), (4, 'D'), (5, 'E')])
         clean_up(table_name)
-                        
+
         # test if_exists='append'
         sql.write_frame(frame=df_if_exists_1, con=self.db, name=table_name,
                         flavor='mysql', if_exists='fail')
diff --git a/pandas/io/tests/test_sql_legacy.py b/pandas/io/tests/test_sql_legacy.py
deleted file mode 100644
index 3c6e99209..000000000
--- a/pandas/io/tests/test_sql_legacy.py
+++ /dev/null
@@ -1,497 +0,0 @@
-from __future__ import with_statement
-from pandas.compat import StringIO
-import unittest
-import sqlite3
-import sys
-
-import warnings
-
-import nose
-
-import numpy as np
-
-from pandas.core.datetools import format as date_format
-from pandas.core.api import DataFrame, isnull
-from pandas.compat import StringIO, range, lrange
-import pandas.compat as compat
-
-import pandas.io.sql as sql
-from pandas.io.sql import DatabaseError
-import pandas.util.testing as tm
-from pandas import Series, Index, DataFrame
-from datetime import datetime
-
-_formatters = {
-    datetime: lambda dt: "'%s'" % date_format(dt),
-    str: lambda x: "'%s'" % x,
-    np.str_: lambda x: "'%s'" % x,
-    compat.text_type: lambda x: "'%s'" % x,
-    compat.binary_type: lambda x: "'%s'" % x,
-    float: lambda x: "%.8f" % x,
-    int: lambda x: "%s" % x,
-    type(None): lambda x: "NULL",
-    np.float64: lambda x: "%.10f" % x,
-    bool: lambda x: "'%s'" % x,
-}
-
-def format_query(sql, *args):
-    """
-
-    """
-    processed_args = []
-    for arg in args:
-        if isinstance(arg, float) and isnull(arg):
-            arg = None
-
-        formatter = _formatters[type(arg)]
-        processed_args.append(formatter(arg))
-
-    return sql % tuple(processed_args)
-
-def _skip_if_no_MySQLdb():
-    try:
-        import MySQLdb
-    except ImportError:
-        raise nose.SkipTest('MySQLdb not installed, skipping')
-
-class TestSQLite(unittest.TestCase):
-
-    def setUp(self):
-        self.db = sqlite3.connect(':memory:')
-
-    def test_basic(self):
-        frame = tm.makeTimeDataFrame()
-        self._check_roundtrip(frame)
-
-    def test_write_row_by_row(self):
-        frame = tm.makeTimeDataFrame()
-        frame.ix[0, 0] = np.nan
-        create_sql = sql.get_schema(frame, 'test', 'sqlite')
-        cur = self.db.cursor()
-        cur.execute(create_sql)
-
-        cur = self.db.cursor()
-
-        ins = "INSERT INTO test VALUES (%s, %s, %s, %s)"
-        for idx, row in frame.iterrows():
-            fmt_sql = format_query(ins, *row)
-            sql.tquery(fmt_sql, cur=cur)
-
-        self.db.commit()
-
-        result = sql.read_frame("select * from test", con=self.db)
-        result.index = frame.index
-        tm.assert_frame_equal(result, frame)
-
-    def test_execute(self):
-        frame = tm.makeTimeDataFrame()
-        create_sql = sql.get_schema(frame, 'test', 'sqlite')
-        cur = self.db.cursor()
-        cur.execute(create_sql)
-        ins = "INSERT INTO test VALUES (?, ?, ?, ?)"
-
-        row = frame.ix[0]
-        sql.execute(ins, self.db, params=tuple(row))
-        self.db.commit()
-
-        result = sql.read_frame("select * from test", self.db)
-        result.index = frame.index[:1]
-        tm.assert_frame_equal(result, frame[:1])
-
-    def test_schema(self):
-        frame = tm.makeTimeDataFrame()
-        create_sql = sql.get_schema(frame, 'test', 'sqlite')
-        lines = create_sql.splitlines()
-        for l in lines:
-            tokens = l.split(' ')
-            if len(tokens) == 2 and tokens[0] == 'A':
-                self.assert_(tokens[1] == 'DATETIME')
-
-        frame = tm.makeTimeDataFrame()
-        create_sql = sql.get_schema(frame, 'test', 'sqlite', keys=['A', 'B'],)
-        lines = create_sql.splitlines()
-        self.assert_('PRIMARY KEY (A,B)' in create_sql)
-        cur = self.db.cursor()
-        cur.execute(create_sql)
-
-    def test_execute_fail(self):
-        create_sql = """
-        CREATE TABLE test
-        (
-        a TEXT,
-        b TEXT,
-        c REAL,
-        PRIMARY KEY (a, b)
-        );
-        """
-        cur = self.db.cursor()
-        cur.execute(create_sql)
-
-        sql.execute('INSERT INTO test VALUES("foo", "bar", 1.234)', self.db)
-        sql.execute('INSERT INTO test VALUES("foo", "baz", 2.567)', self.db)
-
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(Exception, sql.execute,
-                              'INSERT INTO test VALUES("foo", "bar", 7)',
-                              self.db)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_execute_closed_connection(self):
-        create_sql = """
-        CREATE TABLE test
-        (
-        a TEXT,
-        b TEXT,
-        c REAL,
-        PRIMARY KEY (a, b)
-        );
-        """
-        cur = self.db.cursor()
-        cur.execute(create_sql)
-
-        sql.execute('INSERT INTO test VALUES("foo", "bar", 1.234)', self.db)
-        self.db.close()
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(Exception, sql.tquery, "select * from test",
-                              con=self.db)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_na_roundtrip(self):
-        pass
-
-    def _check_roundtrip(self, frame):
-        sql.write_frame(frame, name='test_table', con=self.db)
-        result = sql.read_frame("select * from test_table", self.db)
-
-        # HACK! Change this once indexes are handled properly.
-        result.index = frame.index
-
-        expected = frame
-        tm.assert_frame_equal(result, expected)
-
-        frame['txt'] = ['a'] * len(frame)
-        frame2 = frame.copy()
-        frame2['Idx'] = Index(lrange(len(frame2))) + 10
-        sql.write_frame(frame2, name='test_table2', con=self.db)
-        result = sql.read_frame("select * from test_table2", self.db,
-                                index_col='Idx')
-        expected = frame.copy()
-        expected.index = Index(lrange(len(frame2))) + 10
-        expected.index.name = 'Idx'
-        print(expected.index.names)
-        print(result.index.names)
-        tm.assert_frame_equal(expected, result)
-
-    def test_tquery(self):
-        frame = tm.makeTimeDataFrame()
-        sql.write_frame(frame, name='test_table', con=self.db)
-        result = sql.tquery("select A from test_table", self.db)
-        expected = frame.A
-        result = Series(result, frame.index)
-        tm.assert_series_equal(result, expected)
-
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'select * from blah', con=self.db)
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'select * from blah', con=self.db, retry=True)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_uquery(self):
-        frame = tm.makeTimeDataFrame()
-        sql.write_frame(frame, name='test_table', con=self.db)
-        stmt = 'INSERT INTO test_table VALUES(2.314, -123.1, 1.234, 2.3)'
-        self.assertEqual(sql.uquery(stmt, con=self.db), 1)
-
-        try:
-            sys.stdout = StringIO()
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'insert into blah values (1)', con=self.db)
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'insert into blah values (1)', con=self.db,
-                              retry=True)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_keyword_as_column_names(self):
-        '''
-        '''
-        df = DataFrame({'From':np.ones(5)})
-        sql.write_frame(df, con = self.db, name = 'testkeywords')
-
-    def test_onecolumn_of_integer(self):
-        '''
-        GH 3628
-        a column_of_integers dataframe should transfer well to sql
-        '''
-        mono_df=DataFrame([1 , 2], columns=['c0'])
-        sql.write_frame(mono_df, con = self.db, name = 'mono_df')
-        # computing the sum via sql
-        con_x=self.db
-        the_sum=sum([my_c0[0] for  my_c0 in con_x.execute("select * from mono_df")])
-        # it should not fail, and gives 3 ( Issue #3628 )
-        self.assertEqual(the_sum , 3)
-
-        result = sql.read_frame("select * from mono_df",con_x)
-        tm.assert_frame_equal(result,mono_df)
-
-
-class TestMySQL(unittest.TestCase):
-
-    def setUp(self):
-        _skip_if_no_MySQLdb()
-        import MySQLdb
-        try:
-            # Try Travis defaults.
-            # No real user should allow root access with a blank password.
-            self.db = MySQLdb.connect(host='localhost', user='root', passwd='',
-                                    db='pandas_nosetest')
-        except:
-            pass
-        else:
-            return
-        try:
-            self.db = MySQLdb.connect(read_default_group='pandas')
-        except MySQLdb.ProgrammingError as e:
-            raise nose.SkipTest(
-                "Create a group of connection parameters under the heading "
-                "[pandas] in your system's mysql default file, "
-                "typically located at ~/.my.cnf or /etc/.my.cnf. ")
-        except MySQLdb.Error as e:
-            raise nose.SkipTest(
-                "Cannot connect to database. "
-                "Create a group of connection parameters under the heading "
-                "[pandas] in your system's mysql default file, "
-                "typically located at ~/.my.cnf or /etc/.my.cnf. ")
-
-    def test_basic(self):
-        _skip_if_no_MySQLdb()
-        frame = tm.makeTimeDataFrame()
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "For more robust support.*")
-            self._check_roundtrip(frame)
-
-    def test_write_row_by_row(self):
-        _skip_if_no_MySQLdb()
-        frame = tm.makeTimeDataFrame()
-        frame.ix[0, 0] = np.nan
-        drop_sql = "DROP TABLE IF EXISTS test"
-        create_sql = sql.get_schema(frame, 'test', 'mysql')
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        cur.execute(create_sql)
-        ins = "INSERT INTO test VALUES (%s, %s, %s, %s)"
-        for idx, row in frame.iterrows():
-            fmt_sql = format_query(ins, *row)
-            sql.tquery(fmt_sql, cur=cur)
-
-        self.db.commit()
-
-        result = sql.read_frame("select * from test", con=self.db)
-        result.index = frame.index
-        tm.assert_frame_equal(result, frame)
-
-    def test_execute(self):
-        _skip_if_no_MySQLdb()
-        frame = tm.makeTimeDataFrame()
-        drop_sql = "DROP TABLE IF EXISTS test"
-        create_sql = sql.get_schema(frame, 'test', 'mysql')
-        cur = self.db.cursor()
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "Unknown table.*")
-            cur.execute(drop_sql)
-        cur.execute(create_sql)
-        ins = "INSERT INTO test VALUES (%s, %s, %s, %s)"
-
-        row = frame.ix[0]
-        sql.execute(ins, self.db, params=tuple(row))
-        self.db.commit()
-
-        result = sql.read_frame("select * from test", self.db)
-        result.index = frame.index[:1]
-        tm.assert_frame_equal(result, frame[:1])
-
-    def test_schema(self):
-        _skip_if_no_MySQLdb()
-        frame = tm.makeTimeDataFrame()
-        create_sql = sql.get_schema(frame, 'test', 'mysql')
-        lines = create_sql.splitlines()
-        for l in lines:
-            tokens = l.split(' ')
-            if len(tokens) == 2 and tokens[0] == 'A':
-                self.assert_(tokens[1] == 'DATETIME')
-
-        frame = tm.makeTimeDataFrame()
-        drop_sql = "DROP TABLE IF EXISTS test"
-        create_sql = sql.get_schema(frame, 'test', 'mysql', keys=['A', 'B'],)
-        lines = create_sql.splitlines()
-        self.assert_('PRIMARY KEY (A,B)' in create_sql)
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        cur.execute(create_sql)
-
-    def test_execute_fail(self):
-        _skip_if_no_MySQLdb()
-        drop_sql = "DROP TABLE IF EXISTS test"
-        create_sql = """
-        CREATE TABLE test
-        (
-        a TEXT,
-        b TEXT,
-        c REAL,
-        PRIMARY KEY (a(5), b(5))
-        );
-        """
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        cur.execute(create_sql)
-
-        sql.execute('INSERT INTO test VALUES("foo", "bar", 1.234)', self.db)
-        sql.execute('INSERT INTO test VALUES("foo", "baz", 2.567)', self.db)
-
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(Exception, sql.execute,
-                              'INSERT INTO test VALUES("foo", "bar", 7)',
-                              self.db)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_execute_closed_connection(self):
-        _skip_if_no_MySQLdb()
-        drop_sql = "DROP TABLE IF EXISTS test"
-        create_sql = """
-        CREATE TABLE test
-        (
-        a TEXT,
-        b TEXT,
-        c REAL,
-        PRIMARY KEY (a(5), b(5))
-        );
-        """
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        cur.execute(create_sql)
-
-        sql.execute('INSERT INTO test VALUES("foo", "bar", 1.234)', self.db)
-        self.db.close()
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(Exception, sql.tquery, "select * from test",
-                              con=self.db)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_na_roundtrip(self):
-        _skip_if_no_MySQLdb()
-        pass
-
-    def _check_roundtrip(self, frame):
-        _skip_if_no_MySQLdb()
-        drop_sql = "DROP TABLE IF EXISTS test_table"
-        cur = self.db.cursor()
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "Unknown table.*")
-            cur.execute(drop_sql)
-        sql.write_frame(frame, name='test_table', con=self.db, flavor='mysql')
-        result = sql.read_frame("select * from test_table", self.db)
-
-        # HACK! Change this once indexes are handled properly.
-        result.index = frame.index
-        result.index.name = frame.index.name
-
-        expected = frame
-        tm.assert_frame_equal(result, expected)
-
-        frame['txt'] = ['a'] * len(frame)
-        frame2 = frame.copy()
-        index = Index(lrange(len(frame2))) + 10
-        frame2['Idx'] = index
-        drop_sql = "DROP TABLE IF EXISTS test_table2"
-        cur = self.db.cursor()
-        with warnings.catch_warnings():
-            warnings.filterwarnings("ignore", "Unknown table.*")
-            cur.execute(drop_sql)
-        sql.write_frame(frame2, name='test_table2', con=self.db, flavor='mysql')
-        result = sql.read_frame("select * from test_table2", self.db,
-                                index_col='Idx')
-        expected = frame.copy()
-
-        # HACK! Change this once indexes are handled properly.
-        expected.index = index
-        expected.index.names = result.index.names
-        tm.assert_frame_equal(expected, result)
-
-    def test_tquery(self):
-        try:
-            import MySQLdb
-        except ImportError:
-            raise nose.SkipTest
-        frame = tm.makeTimeDataFrame()
-        drop_sql = "DROP TABLE IF EXISTS test_table"
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        sql.write_frame(frame, name='test_table', con=self.db, flavor='mysql')
-        result = sql.tquery("select A from test_table", self.db)
-        expected = frame.A
-        result = Series(result, frame.index)
-        tm.assert_series_equal(result, expected)
-
-        try:
-            sys.stdout = StringIO()
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'select * from blah', con=self.db)
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'select * from blah', con=self.db, retry=True)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_uquery(self):
-        try:
-            import MySQLdb
-        except ImportError:
-            raise nose.SkipTest
-        frame = tm.makeTimeDataFrame()
-        drop_sql = "DROP TABLE IF EXISTS test_table"
-        cur = self.db.cursor()
-        cur.execute(drop_sql)
-        sql.write_frame(frame, name='test_table', con=self.db, flavor='mysql')
-        stmt = 'INSERT INTO test_table VALUES(2.314, -123.1, 1.234, 2.3)'
-        self.assertEqual(sql.uquery(stmt, con=self.db), 1)
-
-        try:
-            sys.stdout = StringIO()
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'insert into blah values (1)', con=self.db)
-
-            self.assertRaises(DatabaseError, sql.tquery,
-                              'insert into blah values (1)', con=self.db,
-                              retry=True)
-        finally:
-            sys.stdout = sys.__stdout__
-
-    def test_keyword_as_column_names(self):
-        '''
-        '''
-        _skip_if_no_MySQLdb()
-        df = DataFrame({'From':np.ones(5)})
-        sql.write_frame(df, name='testkeywords', con=self.db,
-                        if_exists='replace', flavor='mysql')
-
-if __name__ == '__main__':
-    # unittest.main()
-    # nose.runmodule(argv=[__file__,'-vvs','-x', '--pdb-failure'],
-    #                exit=False)
-    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
-                   exit=False)
