commit 31103e714a7cea560dd1d160c39bcda207c87c1e
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Apr 19 00:57:35 2011 -0400

    SparseSeries and SparseDataFrame work, piecing things together

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 53305fed8..86432c670 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -157,9 +157,9 @@ class DataFrame(Picklable, Groupable):
 
             data = dict((k, v) for k, v in data.iteritems() if k in columns)
         else:
-            columns = Index(_try_sort(data.keys()))
+            columns = Index(try_sort(data.keys()))
 
-        index = _extract_index(data, index)
+        index = extract_index(data, index)
 
         sdict = {}
         for k, v in data.iteritems():
@@ -1265,9 +1265,13 @@ class DataFrame(Picklable, Groupable):
         frame = self
 
         if index is not None:
+            if not isinstance(index, Index):
+                index = Index(index)
             frame = frame._reindex_index(index, method)
 
         if columns is not None:
+            if not isinstance(columns, Index):
+                columns = Index(columns)
             frame = frame._reindex_columns(columns)
 
         return frame
@@ -1276,9 +1280,6 @@ class DataFrame(Picklable, Groupable):
         if self.index.equals(index):
             return self.copy()
 
-        if not isinstance(index, Index):
-            index = Index(index)
-
         if len(self.index) == 0:
             return DataFrame(index=index, columns=self.columns)
 
@@ -1320,11 +1321,8 @@ class DataFrame(Picklable, Groupable):
         return DataFrame(newSeries, index=index, columns=self.columns)
 
     def _reindex_columns(self, columns):
-        if not isinstance(columns, Index):
-            columns = Index(columns)
-
         sdict = dict((k, v) for k, v in self.iteritems() if k in columns)
-        return DataFrame(sdict, index=self.index, columns=columns)
+        return self._constructor(sdict, index=self.index, columns=columns)
 
     def reindex_like(self, other, method=None):
         """
@@ -1689,7 +1687,7 @@ class DataFrame(Picklable, Groupable):
             this = self.reindex(new_index)
             other = other.reindex(new_index)
 
-        new_columns = _try_sort(set(this.cols() + other.cols()))
+        new_columns = try_sort(set(this.cols() + other.cols()))
         do_fill = fill_value is not None
 
         result = {}
@@ -1816,7 +1814,7 @@ class DataFrame(Picklable, Groupable):
         overlap = set(self.cols()) & set(other.cols())
 
         if overlap:
-            raise Exception('Columns overlap: %s' % _try_sort(overlap))
+            raise Exception('Columns overlap: %s' % try_sort(overlap))
 
         if len(other.index) == 0:
             result = self.copy()
@@ -1900,7 +1898,7 @@ class DataFrame(Picklable, Groupable):
         else:
             x = range(len(self))
 
-        for i, col in enumerate(_try_sort(self.columns)):
+        for i, col in enumerate(try_sort(self.columns)):
             if subplots:
                 ax = axes[i]
                 ax.plot(x, self[col].values, 'k', label=col, **kwds)
@@ -1925,7 +1923,7 @@ class DataFrame(Picklable, Groupable):
             k += 1
         _, axes = plt.subplots(nrows=k, ncols=k)
 
-        for i, col in enumerate(_try_sort(self.columns)):
+        for i, col in enumerate(try_sort(self.columns)):
             ax = axes[i / k][i % k]
             ax.hist(self[col].values)
             ax.set_title(col)
@@ -2347,14 +2345,14 @@ class DataFrame(Picklable, Groupable):
 
         return Series(theSkew, index=self._get_agg_axis(axis))
 
-def _try_sort(iterable):
+def try_sort(iterable):
     listed = list(iterable)
     try:
         return sorted(listed)
     except Exception:
         return listed
 
-def _extract_index(data, index):
+def extract_index(data, index):
     if len(data) == 0:
         if index is None:
             index = NULL_INDEX
@@ -2375,7 +2373,7 @@ def _extract_index(data, index):
 
             elif isinstance(v, dict):
                 if index is None:
-                    index = Index(_try_sort(v))
+                    index = Index(try_sort(v))
                 elif need_labels:
                     raise Exception('Cannot mix Series / dict objects'
                                     ' with ndarray / sequence input')
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 2f927599a..e9299e7d3 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -8,7 +8,7 @@ from numpy import NaN
 import numpy as np
 
 from pandas.core.common import (_pickle_array, _unpickle_array)
-from pandas.core.frame import (DataFrame, _try_sort, _extract_index,
+from pandas.core.frame import (DataFrame, try_sort, extract_index,
                                _default_index)
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.series import Series
@@ -118,7 +118,7 @@ class DataMatrix(DataFrame):
             colset = set(columns)
             data = dict((k, v) for k, v in data.iteritems() if k in colset)
 
-        index = _extract_index(data, index)
+        index = extract_index(data, index)
 
         objectDict = {}
         if objects is not None and isinstance(objects, dict):
@@ -148,8 +148,8 @@ class DataMatrix(DataFrame):
                 objectDict[k] = v
 
         if columns is None:
-            columns = Index(_try_sort(valueDict))
-            objectColumns = Index(_try_sort(objectDict))
+            columns = Index(try_sort(valueDict))
+            objectColumns = Index(try_sort(objectDict))
         else:
             objectColumns = Index([c for c in columns if c in objectDict])
             columns = Index([c for c in columns if c not in objectDict])
@@ -268,9 +268,6 @@ class DataMatrix(DataFrame):
         if index is self.index:
             return self.copy()
 
-        if not isinstance(index, Index):
-            index = Index(index)
-
         if len(self.index) == 0:
             return DataMatrix(index=index, columns=self.columns)
 
@@ -299,9 +296,6 @@ class DataMatrix(DataFrame):
         if len(columns) == 0:
             return DataMatrix(index=self.index)
 
-        if not isinstance(columns, Index):
-            columns = Index(columns)
-
         if self.objects is not None:
             object_columns = columns.intersection(self.objects.columns)
             columns = columns - object_columns
diff --git a/pandas/core/series.py b/pandas/core/series.py
index e4b8dd363..e20e6e693 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -857,7 +857,6 @@ class Series(np.ndarray, Picklable, Groupable):
         if method is not None:
             method = method.upper()
 
-        # Cython for blazing speed
         fillVec, mask = tseries.getFillVec(self.index, new_index,
                                            self.index.indexMap,
                                            new_index.indexMap,
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 6a27dcff5..41ff43af8 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -1,15 +1,23 @@
+"""
+Data structures for sparse float data. Life is made simpler by dealing only with
+float64 data
+"""
+
+from numpy import NaN
 import numpy as np
 
 import operator
 
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.series import Series, TimeSeries
-from pandas.core.frame import DataFrame
+from pandas.core.frame import DataFrame, extract_index, try_sort
+import pandas.core.common as common
 
 from pandas.lib.sparse import BlockIndex, IntIndex
 import pandas.lib.sparse as splib
+import pandas.lib.tseries as tseries
 
-def make_sparse(arr, kind='block', sparse_value=np.NaN):
+def make_sparse(arr, kind='block', fill_value=np.NaN):
     """
     Convert ndarray to sparse format
 
@@ -17,7 +25,7 @@ def make_sparse(arr, kind='block', sparse_value=np.NaN):
     ----------
     arr : ndarray
     kind : {'block', 'integer'}
-    sparse_value : NaN or another value
+    fill_value : NaN or another value
 
     Returns
     -------
@@ -28,10 +36,10 @@ def make_sparse(arr, kind='block', sparse_value=np.NaN):
 
     length = len(arr)
 
-    if np.isnan(sparse_value):
+    if np.isnan(fill_value):
         mask = -np.isnan(arr)
     else:
-        mask = arr != sparse_value
+        mask = arr != fill_value
 
     indices = np.arange(length, dtype=np.int32)[mask]
 
@@ -46,6 +54,87 @@ def make_sparse(arr, kind='block', sparse_value=np.NaN):
     sparsified_values = arr[mask]
     return sparsified_values, index
 
+def to_sparse_series(series, kind='block', fill_value=np.NaN):
+    sp_values, sp_index = make_sparse(series, kind=kind, fill_value=fill_value)
+    return SparseSeries(sp_values, index=series.index, sparse_index=sp_index,
+                        fill_value=fill_value)
+
+#-------------------------------------------------------------------------------
+# Wrapper function for Series arithmetic methods
+_MIRROR_OPS = {
+    '__add__' : '__radd__',
+    '__sub__' : '__rsub__',
+    '__div__' : '__rdiv__',
+    '__truediv__' : '__rdiv__',
+    '__mul__' : '__rmul__',
+}
+
+def _sparse_op_wrap(name):
+    """
+    Wrapper function for Series arithmetic operations, to avoid
+    code duplication.
+    """
+    def wrapper(self, other):
+        py_op = getattr(operator, name)
+
+        if isinstance(other, SparseSeries):
+            if np.isnan(self.fill_value):
+                sparse_op = lambda a, b: _sparse_nanop(a, b, name)
+            else:
+                if self.fill_value != other.fill_value:
+                    raise Exception('Fill values must be the same')
+                sparse_op = lambda a, b: _sparse_fillop(a, b, name)
+
+            new_index = self.index + other.index
+            if self.index.equals(new_index):
+                this = self
+            else:
+                this = self.reindex(new_index)
+                other = other.reindex(new_index)
+
+            if self.sparse_index.equals(other.sparse_index):
+                result = py_op(this.sparse_values, other.sparse_values)
+                result_index = self.sparse_index
+            else:
+                result, result_index = sparse_op(this, other)
+
+            return SparseSeries(result, index=self.index,
+                                sparse_index=result_index,
+                                fill_value=self.fill_value)
+
+        elif isinstance(other, SparseDataFrame):
+            reverse_op = _MIRROR_OPS.get(name)
+            if reverse_op is None:
+                raise Exception('Cannot do %s op, sorry!')
+            return getattr(other, reverse_op)(self)
+        elif np.isscalar(other):
+            return SparseSeries(py_op(self.sparse_values, other),
+                                index=self.index,
+                                sparse_index=self.sparse_index,
+                                fill_value=py_op(self.fill_value, other))
+
+    wrapper.__name__ = name
+    return wrapper
+
+def _sparse_nanop(this, other, name):
+    sparse_op = getattr(splib, 'sparse_nan%d' % name)
+    result, result_index = sparse_op(this.sparse_values,
+                                     this.sparse_index,
+                                     other.sparse_values,
+                                     other.sparse_index)
+
+    return result, result_index
+
+def _sparse_fillop(this, other, name):
+    # TODO!
+    sparse_op = getattr(splib, 'sparse_%d' % name)
+    result, result_index = sparse_op(this.sparse_values,
+                                     this.sparse_index,
+                                     other.sparse_values,
+                                     other.sparse_index)
+
+    return result, result_index
+
 class SparseSeries(Series):
     """
     Data structure for labeled, sparse floating point data
@@ -53,21 +142,21 @@ class SparseSeries(Series):
     Parameters
     ----------
     kind : {'block', 'integer'}
-    sparse_value : float
+    fill_value : float
         Defaults to NaN (code for missing)
     """
     sparse_index = None
-    sparse_value = None
+    fill_value = None
 
-    def __new__(cls, data, index=None, sparse_index=None, copy=False,
-                kind='block', sparse_value=None):
+    def __new__(cls, data, index=None, sparse_index=None,
+                kind='block', fill_value=None, copy=False):
 
         if isinstance(data, SparseSeries):
             if index is None:
                 index = data.index
 
-            if sparse_value is None:
-                sparse_index = data.sparse_value
+            if fill_value is None:
+                sparse_index = data.fill_value
 
             if index is not None:
                 assert(len(index) == data.length)
@@ -99,7 +188,7 @@ class SparseSeries(Series):
         # Change the class of the array to be the subclass type.
         subarr = subarr.view(cls)
         subarr.sparse_index = sparse_index
-        subarr.sparse_value = sparse_value
+        subarr.fill_value = fill_value
         subarr.index = index
         return subarr
 
@@ -110,19 +199,39 @@ class SparseSeries(Series):
         """
         self._index = getattr(obj, '_index', None)
         self.sparse_index = getattr(obj, 'sparse_index', None)
-        self.sparse_value = getattr(obj, 'sparse_value', None)
+        self.fill_value = getattr(obj, 'fill_value', None)
 
     def __len__(self):
         return self.sparse_index.length
 
+    # Arithmetic operators
+
+    __add__ = _sparse_op_wrap('add')
+    __sub__ = _sparse_op_wrap('sub')
+    __mul__ = _sparse_op_wrap('mul')
+    __div__ = _sparse_op_wrap('div')
+    __truediv__ = _sparse_op_wrap('div')
+    __pow__ = _sparse_op_wrap('pow')
+
+    # Inplace operators
+    __iadd__ = __add__
+    __isub__ = __sub__
+    __imul__ = __mul__
+    __idiv__ = __div__
+    __ipow__ = __pow__
+
     @property
     def values(self):
         output = np.empty(self.sparse_index.length, dtype=np.float64)
         int_index = self.sparse_index.to_int_index()
-        output.fill(self.sparse_value)
+        output.fill(self.fill_value)
         output.put(int_index.indices, self)
         return output
 
+    @property
+    def sparse_values(self):
+        return np.asarray(self)
+
     def to_dense(self):
         """
         Convert SparseSeries to (dense) Series
@@ -134,44 +243,52 @@ class SparseSeries(Series):
         return self.copy()
 
     def copy(self):
-        values = np.asarray(self).copy()
+        values = self.sparse_values.copy()
         return SparseSeries(values, index=self.index,
                             sparse_index=self.sparse_index)
 
+    def reindex(self, new_index):
+        return SparseSeries(self.to_dense().reindex(new_index))
+
+        if self.index.equals(new_index):
+            return self.copy()
+
+        if not isinstance(new_index, Index):
+            new_index = Index(new_index)
+
+        if len(self.index) == 0:
+            return Series(NaN, index=new_index)
+
+        indexer, mask = tseries.getFillVec(self.index, new_index,
+                                           self.index.indexMap,
+                                           new_index.indexMap)
+
+    def take(self, indices):
+        pass
+
+    def put(self, indices, values):
+        pass
+
 class SparseTimeSeries(SparseSeries, TimeSeries):
     pass
 
 class SparseDataFrame(DataFrame):
+    """
+    DataFrame containing sparse floating point data in the form of SparseSeries
+    objects
+    """
     _columns = None
 
-    def __init__(self, data=None, index=None, columns=None, dtype=None):
-        if isinstance(data, dict):
-            sdict, columns, index = self._init_dict(data, index, columns, dtype)
-        elif isinstance(data, (np.ndarray, list)):
-            sdict, columns, index = self._init_matrix(data, index, columns,
-                                                      dtype)
-        elif isinstance(data, DataFrame):
-            sdict = data._series.copy()
-
-            if dtype is not None:
-                sdict = dict((k, v.astype(dtype)) for k, v in data.iteritems())
-            index = data.index
-            columns = data.columns
-        elif data is None:
-            sdict = {}
-
-            if index is None:
-                index = NULL_INDEX
-
-            if columns is None:
-                columns = NULL_INDEX
-            else:
-                for c in columns:
-                    sdict[c] = Series(np.NaN, index=index)
+    def __init__(self, data=None, index=None, columns=None, kind='block',
+                 fill_value=None):
+        self.kind = kind
+        self.fill_value = fill_value
+        DataFrame.__init__(self, data, index=index, columns=columns,
+                           dtype=None)
 
-        self._series = sdict
-        self.columns = columns
-        self.index = index
+    @property
+    def _constructor(self):
+        return SparseDataFrame
 
     def _init_dict(self, data, index, columns, dtype):
         # pre-filter out columns if we passed it
@@ -181,57 +298,67 @@ class SparseDataFrame(DataFrame):
 
             data = dict((k, v) for k, v in data.iteritems() if k in columns)
         else:
-            columns = Index(_try_sort(data.keys()))
+            columns = Index(try_sort(data.keys()))
 
-        index = _extract_index(data, index)
+        index = extract_index(data, index)
 
         sdict = {}
         for k, v in data.iteritems():
             if isinstance(v, Series):
                 # Forces alignment and copies data
-                sdict[k] = v.reindex(index)
+                v = v.reindex(index)
+                if not isinstance(v, SparseSeries):
+                    v = to_sparse_series(v, kind=self.kind,
+                                         fill_value=self.fill_value)
             else:
                 if isinstance(v, dict):
                     v = [v.get(i, NaN) for i in index]
 
-                try:
-                    v = Series(v, dtype=dtype, index=index)
-                except Exception:
-                    v = Series(v, index=index)
+                v = SparseSeries(v, index=index, kind=self.kind).copy()
 
-                sdict[k] = v.copy()
+            sdict[k] = v
 
+        # TODO: figure out how to handle this case, all nan's?
         # add in any other columns we want to have (completeness)
         for c in columns:
             if c not in sdict:
-                sdict[c] = Series(np.NaN, index=index)
+                sdict[c] = SparseSeries([], index=index,
+                                        fill_value=self.fill_value)
 
         return sdict, columns, index
 
-    def _init_matrix(self, data, index, columns, dtype):
-        if not isinstance(data, np.ndarray):
-            arr = np.array(data)
-            if issubclass(arr.dtype.type, basestring):
-                arr = np.array(data, dtype=object, copy=True)
+    def _reindex_index(self, index, method):
+        if self.index.equals(index):
+            return self.copy()
 
-            data = arr
+        if not isinstance(index, Index):
+            index = Index(index)
 
-        if data.ndim == 1:
-            data = data.reshape((len(data), 1))
-        elif data.ndim != 2:
-            raise Exception('Must pass 2-d input!')
+        if len(self.index) == 0:
+            return SparseDataFrame(index=index, columns=self.columns)
 
-        N, K = data.shape
+        indexer, mask = common.get_indexer(self.index, index, method)
+        notmask = -mask
+        need_mask = notmask.any()
 
-        if index is None:
-            index = _default_index(N)
+        new_series = {}
+        for col, series in self.iteritems():
+            values = series.values
+            new = values.take(indexer)
+
+            if need_mask:
+                new[notmask] = np.NaN
+
+            new_series[col] = new
+
+        return SparseDataFrame(new_series, index=index, columns=self.columns)
+
+class SparsePanel(object):
+    """
+
+    """
 
-        if columns is None:
-            columns = _default_index(K)
+    def __init__(self, frames):
+        pass
 
-        if len(columns) != K:
-            raise Exception('Column length mismatch: %d vs. %d' %
-                            (len(columns), K))
 
-        data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
-        return self._init_dict(data, index, columns, dtype)
diff --git a/pandas/lib/src/reindex.pyx b/pandas/lib/src/reindex.pyx
index c1d232338..6ca485fb3 100644
--- a/pandas/lib/src/reindex.pyx
+++ b/pandas/lib/src/reindex.pyx
@@ -1,5 +1,5 @@
 def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
-               object kind):
+               kind=None):
 
     if kind is None:
         fillVec, maskVec = getMergeVec(newIndex, oldMap)
diff --git a/pandas/lib/src/sparse.pyx b/pandas/lib/src/sparse.pyx
index b86c410a6..e2576b6cf 100644
--- a/pandas/lib/src/sparse.pyx
+++ b/pandas/lib/src/sparse.pyx
@@ -12,6 +12,8 @@ ctypedef Py_ssize_t pyst
 #-------------------------------------------------------------------------------
 # Preamble stuff
 
+cdef float64_t NaN = <float64_t> np.NaN
+
 cdef inline int int_max(int a, int b): return a if a >= b else b
 cdef inline int int_min(int a, int b): return a if a <= b else b
 
@@ -44,7 +46,15 @@ cdef class SparseIndex:
         raise NotImplementedError
 
 cdef class IntIndex(SparseIndex):
+    '''
+    Object for holding exact integer sparse indexing information
 
+    Parameters
+    ----------
+    length : integer
+    indices : array-like
+        Contains integers corresponding to
+    '''
     cdef readonly:
         pyst length, npoints
         ndarray indices
@@ -65,6 +75,13 @@ cdef class IntIndex(SparseIndex):
         output += 'Indices: %s\n' % repr(self.indices)
         return output
 
+    def check_integrity(self):
+        '''
+        Only need be strictly ascending and nothing less than 0 or greater than
+        totall ength
+        '''
+        pass
+
     def equals(self, other):
         if not isinstance(other, IntIndex):
             raise Exception('Can only compare with like object')
@@ -143,9 +160,11 @@ cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
 
 cdef class BlockIndex(SparseIndex):
     '''
+    Object for holding block-based sparse indexing information
 
+    Parameters
+    ----------
     '''
-
     cdef readonly:
         pyst nblocks, npoints, length
         ndarray blocs, blengths
@@ -340,7 +359,7 @@ cdef class BlockIndex(SparseIndex):
         pass
 
 #-------------------------------------------------------------------------------
-# Sparse operations
+# Sparse arithmetic
 
 cpdef sparse_nanadd(ndarray x, SparseIndex xindex,
                     ndarray y, SparseIndex yindex):
@@ -358,6 +377,10 @@ cpdef sparse_nandiv(ndarray x, SparseIndex xindex,
                     ndarray y, SparseIndex yindex):
     return sparse_nancombine(x, xindex, y, yindex, __div)
 
+cpdef sparse_nanpow(ndarray x, SparseIndex xindex,
+                    ndarray y, SparseIndex yindex):
+    return sparse_nancombine(x, xindex, y, yindex, __pow)
+
 cdef tuple sparse_nancombine(ndarray x, SparseIndex xindex,
                              ndarray y, SparseIndex yindex, double_func op):
     if isinstance(xindex, BlockIndex):
@@ -370,6 +393,7 @@ cdef tuple sparse_nancombine(ndarray x, SparseIndex xindex,
 # NaN-based arithmetic operation-- no handling of fill values
 # TODO: faster to convert everything to dense?
 
+@cython.boundscheck(False)
 cdef tuple block_nanop(ndarray[float64_t, ndim=1] x, BlockIndex xindex,
                        ndarray[float64_t, ndim=1] y, BlockIndex yindex,
                        double_func op):
@@ -428,6 +452,7 @@ cdef tuple block_nanop(ndarray[float64_t, ndim=1] x, BlockIndex xindex,
 
     return out, out_index
 
+@cython.boundscheck(False)
 cdef tuple int_nanop(ndarray[float64_t, ndim=1] x, IntIndex xindex,
                      ndarray[float64_t, ndim=1] y, IntIndex yindex,
                      double_func op):
@@ -458,3 +483,61 @@ cdef tuple int_nanop(ndarray[float64_t, ndim=1] x, IntIndex xindex,
         yi += 1
 
     return out, out_index
+
+
+cdef tuple block_op(ndarray[float64_t, ndim=1] x, BlockIndex xindex,
+                    ndarray[float64_t, ndim=1] y, BlockIndex yindex,
+                    float64_t fill_value, double_func op):
+    pass
+
+cdef tuple int_op(ndarray[float64_t, ndim=1] x, BlockIndex xindex,
+                  ndarray[float64_t, ndim=1] y, BlockIndex yindex,
+                  float64_t fill_value, double_func op):
+    pass
+
+#-------------------------------------------------------------------------------
+# Indexing operations
+
+def get_reindexer(ndarray[object, ndim=1] values, dict index_map):
+    cdef object idx
+    cdef Py_ssize_t i
+    cdef int new_length = len(values)
+    cdef ndarray[int32_t, ndim=1] indexer
+
+    indexer = np.empty(new_length, dtype=np.int32)
+
+    for i from 0 <= i < new_length:
+        idx = values[i]
+        if idx in index_map:
+            indexer[i] = index_map[idx]
+        else:
+            indexer[i] = -1
+
+    return indexer
+
+def reindex_block(ndarray[float64_t, ndim=1] values,
+                  BlockIndex sparse_index,
+                  ndarray[int32_t, ndim=1] indexer):
+    cdef:
+        pyst i, length
+        ndarray[float64_t, ndim=1] out
+
+    out = np.empty(length, dtype=np.float64)
+
+    for i from 0 <= i < length:
+        if indexer[i] == -1:
+            pass
+
+def reindex_integer(ndarray[float64_t, ndim=1] values,
+                    IntIndex sparse_index,
+                    ndarray[int32_t, ndim=1] indexer):
+    pass
+
+def sparse_put(ndarray[float64_t, ndim=1] values, SparseIndex index,
+               ndarray[int32_t, ndim=1] indices, object to_put):
+    pass
+
+def sparse_take(ndarray[float64_t, ndim=1] values, SparseIndex index,
+                ndarray[int32_t, ndim=1] indices):
+    pass
+
