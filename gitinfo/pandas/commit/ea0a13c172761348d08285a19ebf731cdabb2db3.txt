commit ea0a13c172761348d08285a19ebf731cdabb2db3
Author: Jan Schulz <jasc@gmx.net>
Date:   Tue Jul 1 14:39:23 2014 +0200

    Categorical: Thanks for Jan Schulz for much of the work on Categoricals
    
    Doc: Add Release notes for #7217
    
    DOC: update v0.15.0 notes
    
    Categorical: .codes should be immutable
    
    ERR: codes modification raises ValueError always
    
    Categorical: use Categorical.from_codes() in a few places
    
    Categorical: Fix assigning a Categorical to an existing string column
    
    CLN: CategoricalDtype repr now yields category
    DISPLAY: show dtype when displaying Categorical series (for consistency)
    
    BUG: fix groupby with multiple non-compressed categoricals
    
    Categorical: minor doc cleanups
    
    ENH: add a metaclass to CategoricalDtype to provide issubclass support (for select_dtypes)
    
    TST: io/pytables.py tests now raise NotImplementedError for dtype==category
    
    DOC: document the new category dtype in select_dtypes

diff --git a/doc/source/api.rst b/doc/source/api.rst
index 081b4ff0d..88aab0ced 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -485,6 +485,7 @@ and has the following usable methods and properties (all available as
    :toctree: generated/
 
    Categorical
+   Categorical.from_codes
    Categorical.levels
    Categorical.ordered
    Categorical.reorder_levels
@@ -492,11 +493,18 @@ and has the following usable methods and properties (all available as
    Categorical.min
    Categorical.max
    Categorical.mode
+   Categorical.describe
+
+``np.asarray(categorical)`` works by implementing the array interface. Be aware, that this converts
+the Categorical back to a numpy array, so levels and order information is not preserved!
+
+.. autosummary::
+   :toctree: generated/
+
+   Categorical.__array__
 
 To create compatibility with `pandas.Series` and `numpy` arrays, the following (non-API) methods
-are also introduced. Apart from these methods, ``np.asarray(categorical)`` works by implementing the
-array interface (`Categorical.__array__()`). Be aware, that this converts the
-Categorical back to a numpy array, so levels and order information is not preserved!
+are also introduced.
 
 .. autosummary::
    :toctree: generated/
@@ -507,13 +515,11 @@ Categorical back to a numpy array, so levels and order information is not preser
    Categorical.dtype
    Categorical.ndim
    Categorical.sort
-   Categorical.describe
    Categorical.equals
    Categorical.unique
    Categorical.order
    Categorical.argsort
    Categorical.fillna
-   Categorical.__array__
 
 
 Plotting
diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index 681d25fed..32c0a78e3 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -1574,7 +1574,8 @@ dtypes:
                    'float64': np.arange(4.0, 7.0),
                    'bool1': [True, False, True],
                    'bool2': [False, True, False],
-                   'dates': pd.date_range('now', periods=3).values})
+                   'dates': pd.date_range('now', periods=3).values}),
+                   'category': pd.Categorical(list("ABC))
    df['tdeltas'] = df.dates.diff()
    df['uint64'] = np.arange(3, 6).astype('u8')
    df['other_dates'] = pd.date_range('20130101', periods=3).values
@@ -1630,6 +1631,11 @@ All numpy dtypes are subclasses of ``numpy.generic``:
 
     subdtypes(np.generic)
 
+.. note::
+
+    Pandas also defines an additional ``category`` dtype, which is not integrated into the normal
+    numpy hierarchy and wont show up with the above function.
+
 .. note::
 
    The ``include`` and ``exclude`` parameters must be non-string sequences.
diff --git a/doc/source/categorical.rst b/doc/source/categorical.rst
index 900568eb0..87b59dc73 100644
--- a/doc/source/categorical.rst
+++ b/doc/source/categorical.rst
@@ -27,8 +27,8 @@ Categorical
     `Categorical` data in `Series` and `DataFrame` is new.
 
 
-This is a short introduction to pandas `Categorical` type, including a short comparison with R's
-`factor`.
+This is a introduction to pandas :class:`pandas.Categorical` type, including a short comparison
+with R's `factor`.
 
 `Categoricals` are a pandas data type, which correspond to categorical variables in
 statistics: a variable, which can take on only a limited, and usually fixed,
@@ -41,7 +41,7 @@ operations (additions, divisions, ...) are not possible.
 
 All values of the `Categorical` are either in `levels` or `np.nan`. Order is defined by
 the order of the `levels`, not lexical order of the values. Internally, the data structure
-consists of a levels array and an integer array of level_codes which point to the real value in the
+consists of a levels array and an integer array of `codes` which point to the real value in the
 levels array.
 
 `Categoricals` are useful in the following cases:
@@ -108,7 +108,7 @@ By using some special functions:
     creation time. Use `levels` to change the levels after creation time.
 
 To get back to the original Series or `numpy` array, use ``Series.astype(original_dtype)`` or
-``Categorical.get_values()``:
+``np.asarray(categorical)``:
 
 .. ipython:: python
 
@@ -118,7 +118,33 @@ To get back to the original Series or `numpy` array, use ``Series.astype(origina
     s2
     s3 = s2.astype('string')
     s3
-    s2.cat.get_values()
+    np.asarray(s2.cat)
+
+If you have already `codes` and `levels`, you can use the :func:`~pandas.Categorical.from_codes`
+constructor to save the factorize step during normal constructor mode:
+
+.. ipython:: python
+
+    splitter = np.random.choice([0,1], 5, p=[0.5,0.5])
+    pd.Categorical.from_codes(splitter, levels=["train", "test"])
+
+Description
+-----------
+
+Using ``.describe()`` on a ``Categorical(...)`` or a ``Series(Categorical(...))`` will show
+different output.
+
+
+As part of a `Dataframe` or as a `Series` a similar output as for a `Series` of type ``string`` is
+shown. Calling ``Categorical.describe()`` will show the frequencies for each level, with NA for
+unused levels.
+
+.. ipython:: python
+
+    cat = pd.Categorical(["a","c","c",np.nan], levels=["b","a","c",np.nan] )
+    df = pd.DataFrame({"cat":cat, "s":["a","c","c",np.nan]})
+    df.describe()
+    cat.describe()
 
 Working with levels
 -------------------
@@ -153,7 +179,8 @@ It's also possible to pass in the levels in a specific order:
 
 .. note::
 
-    Passing in a `levels` argument implies ``ordered=True``.
+    Passing in a `levels` argument implies ``ordered=True``. You can of course overwrite that by
+    passing in an explicit ``ordered=False``.
 
 Any value omitted in the levels argument will be replaced by `np.nan`:
 
@@ -178,8 +205,7 @@ Renaming levels is done by assigning new values to the ``Category.levels`` or
 
 .. note::
 
-    I contrast to R's `factor` function, a `Categorical` can have levels of other types than
-    string.
+    I contrast to R's `factor`, a `Categorical` can have levels of other types than string.
 
 Levels must be unique or a `ValueError` is raised:
 
@@ -190,7 +216,7 @@ Levels must be unique or a `ValueError` is raised:
     except ValueError as e:
         print("ValueError: " + str(e))
 
-Appending a level can be done by assigning a levels list longer than the current levels:
+Appending levels can be done by assigning a levels list longer than the current levels:
 
 .. ipython:: python
 
@@ -198,6 +224,8 @@ Appending a level can be done by assigning a levels list longer than the current
     s.cat.levels
     s
 
+.. note::
+    Adding levels in other positions can be done with ``.reorder_levels(<levels_including_new>)``.
 
 Removing a level is also possible, but only the last level(s) can be removed by assigning a
 shorter list than current levels. Values which are omitted are replaced by `np.nan`.
@@ -236,8 +264,8 @@ Ordered or not...
 -----------------
 
 If a `Categoricals` is ordered (``cat.ordered == True``), then the order of the levels has a
-meaning and certain operations are possible. If the the categorical is unordered,
-a `TypeError` is raised.
+meaning and certain operations are possible. If the categorical is unordered, a `TypeError` is
+raised.
 
 .. ipython:: python
 
@@ -268,7 +296,8 @@ This is even true for strings and numeric data:
     print(s.min(), s.max())
 
 Reordering the levels is possible via the ``Categorical.reorder_levels(new_levels)``  or
-``Series.cat.reorder_levels(new_levels)`` methods:
+``Series.cat.reorder_levels(new_levels)`` methods. All old levels must be included in the new
+levels.
 
 .. ipython:: python
 
@@ -287,6 +316,15 @@ Reordering the levels is possible via the ``Categorical.reorder_levels(new_level
     way values are sorted is different afterwards, but not that individual values in the
     `Series` are changed.
 
+You can also add new levels with :func:`Categorical.reorder_levels`, as long as you include all
+old levels:
+
+.. ipython:: python
+
+    s3 = pd.Series(pd.Categorical(["a","b","d"]))
+    s3.cat.reorder_levels(["a","b","c",d"])
+    s3
+
 
 Operations
 ----------
@@ -317,8 +355,8 @@ The mode:
 .. note::
 
     Numeric operations like ``+``, ``-``, ``*``, ``/`` and operations based on them (e.g.
-    ``Categorical.median()``, which would need to compute the mean between two values if the
-    length of an array is even) do not work and raise a `TypeError`.
+    ``.median()``, which would need to compute the mean between two values if the length of an
+    array is even) do not work and raise a `TypeError`.
 
 `Series` methods like `Series.value_counts()` will use all levels, even if some levels are not
 present in the data:
@@ -338,7 +376,6 @@ Groupby will also show "unused" levels:
 
     cats2 = pd.Categorical(["a","a","b","b"], levels=["a","b","c"])
     df2 = pd.DataFrame({"cats":cats2,"B":["c","d","c","d"], "values":[1,2,3,4]})
-    # This doesn't work yet with two columns -> see failing unittests
     df2.groupby(["cats","B"]).mean()
 
 
@@ -353,7 +390,7 @@ Pivot tables:
 Data munging
 ------------
 
-The optimized pandas data access methods  ``.loc``, ``.iloc`` ``ix`` ``.at``, and``.iat``,
+The optimized pandas data access methods  ``.loc``, ``.iloc``, ``.ix`` ``.at``, and ``.iat``,
 work as normal, the only difference is the return type (for getting) and
 that only values already in the levels can be assigned.
 
@@ -393,7 +430,7 @@ of length "1".
     df.at["h","cats"] # returns a string
 
 .. note::
-    Note that this is a difference to R's `factor` function, where ``factor(c(1,2,3))[1]``
+    This is a difference to R's `factor` function, where ``factor(c(1,2,3))[1]``
     returns a single value `factor`.
 
 To get a single value `Series` of type ``category`` pass in a single value list:
@@ -455,7 +492,9 @@ but the levels of these `Categoricals` need to be the same:
         cat = pd.Categorical(["a","b"], levels=["a","b"])
         vals = [1,2]
         df = pd.DataFrame({"cats":cat, "vals":vals})
-        pd.concat([df,df])
+        res = pd.concat([df,df])
+        res
+        res.dtypes
 
         df_different = df.copy()
         df_different["cats"].cat.levels = ["a","b","c"]
@@ -501,28 +540,32 @@ store does not yet work.
 
 
 Writing to a csv file will convert the data, effectively removing any information about the
-`Categorical` (`levels` and ordering). So if you read back the csv file you have to convert the
-relevant columns back to `category` and assign the right `levels` and level ordering.
+`Categorical` (levels and ordering). So if you read back the csv file you have to convert the
+relevant columns back to `category` and assign the right levels and level ordering.
 
 .. ipython:: python
    :suppress:
 
     from pandas.compat import StringIO
-    csv_file = StringIO
 
 .. ipython:: python
 
-    s = pd.Series(pd.Categorical(['a', 'b', 'b', 'a', 'a', 'c'], levels=['a','b','c','d']))
-    df = pd.DataFrame({"s":s, "vals":[1,2,3,4,5,6]})
-    df.to_csv(csv_file)
-    df2 = pd.read_csv(csv_file)
-    df2.dtype
-    df2["vals"]
+    s = pd.Series(pd.Categorical(['a', 'b', 'b', 'a', 'a', 'd']))
+    # rename the levels
+    s.cat.levels = ["very good", "good", "bad"]
+    # reorder the levels and add missing levels
+    s.cat.reorder_levels(["very bad", "bad", "medium", "good", "very good"])
+    df = pd.DataFrame({"cats":s, "vals":[1,2,3,4,5,6]})
+    csv = StringIO()
+    df.to_csv(csv)
+    df2 = pd.read_csv(StringIO(csv.getvalue()))
+    df2.dtypes
+    df2["cats"]
     # Redo the category
-    df2["vals"] = df2["vals"].astype("category")
-    df2["vals"].cat.levels = ['a','b','c','d']
-    df2.dtype
-    df2["vals"]
+    df2["cats"] = df2["cats"].astype("category")
+    df2["cats"].cat.reorder_levels(["very bad", "bad", "medium", "good", "very good"])
+    df2.dtypes
+    df2["cats"]
 
 
 Missing Data
@@ -576,8 +619,8 @@ object and not as a low level `numpy` array dtype. This leads to some problems.
     dtype == np.str_
     np.str_ == dtype
 
-Using ``numpy`` functions on a `Series` of type ``category`` should not work as `Categoricals`
-are not numeric data (even in the case that levels is numeric).
+Using `numpy` functions on a `Series` of type ``category`` should not work as `Categoricals`
+are not numeric data (even in the case that ``.levels`` is numeric).
 
 .. ipython:: python
 
@@ -612,6 +655,7 @@ means that changes to the `Series` will in most cases change the original `Categ
 Use ``copy=True`` to prevent such a behaviour:
 
 .. ipython:: python
+
     cat = pd.Categorical([1,2,3,10], levels=[1,2,3,4,10])
     s = pd.Series(cat, name="cat", copy=True)
     cat
@@ -619,40 +663,45 @@ Use ``copy=True`` to prevent such a behaviour:
     cat
 
 .. note::
-    This also happens in some cases when you supply a `numpy` array: using an int array
-    (e.g. ``np.array([1,2,3,4])``) will exhibit the same behaviour, but using a string
-    array (e.g. ``np.array(["a","b","c","a"])``) will not.
+    This also happens in some cases when you supply a `numpy` array instea dof a `Categorical`:
+    using an int array (e.g. ``np.array([1,2,3,4])``) will exhibit the same behaviour, but using
+    a string array (e.g. ``np.array(["a","b","c","a"])``) will not.
 
 
 Danger of confusion
 ~~~~~~~~~~~~~~~~~~~
 
-Both `Series` and `Categorical` have a method ``.reorder_levels()`` . For Series of type
-``category`` this means that there is some danger to confuse both methods.
+Both `Series` and `Categorical` have a method ``.reorder_levels()`` but for different things. For
+Series of type ``category`` this means that there is some danger to confuse both methods.
 
 .. ipython:: python
 
     s = pd.Series(pd.Categorical([1,2,3,4]))
+    print(s.cat.levels)
     # wrong and raises an error:
     try:
         s.reorder_levels([4,3,2,1])
     except Exception as e:
         print("Exception: " + str(e))
     # right
-    print(s.cat.levels)
-    print([4,3,2,1])
     s.cat.reorder_levels([4,3,2,1])
+    print(s.cat.levels)
+
+See also the API documentation for :func:`pandas.Series.reorder_levels` and
+:func:`pandas.Categorical.reorder_levels`
 
 Old style constructor usage
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-I earlier versions, a `Categorical` could be constructed by passing in precomputed `level_codes`
-(called then `labels`) instead of values with levels. The `level_codes` are interpreted as pointers
+I earlier versions, a `Categorical` could be constructed by passing in precomputed `codes`
+(called then `labels`) instead of values with levels. The `codes` are interpreted as pointers
 to the levels with `-1` as `NaN`. This usage is now deprecated and not available unless
 ``compat=True`` is passed to the constructor of `Categorical`.
 
 .. ipython:: python
+    :okwarning:
 
+    # This raises a FutureWarning:
     cat = pd.Categorical([1,2], levels=[1,2,3], compat=True)
     cat.get_values()
 
@@ -664,9 +713,9 @@ In the default case (``compat=False``) the first argument is interpreted as valu
     cat.get_values()
 
 .. warning::
-    Using Categorical with precomputed level_codes and levels is deprecated and a `FutureWarning`
-    is raised. Please change your code to use one of the proper constructor modes instead of
-    adding ``compat=False``.
+    Using Categorical with precomputed codes and levels is deprecated and a `FutureWarning`
+    is raised. Please change your code to use the :func:`~pandas.Categorical.from_codes`
+    constructor instead of adding ``compat=False``.
 
 No categorical index
 ~~~~~~~~~~~~~~~~~~~~
@@ -682,9 +731,13 @@ ordering of the levels:
     values = [4,2,3,1]
     df = pd.DataFrame({"strings":strings, "values":values}, index=cats)
     df.index
-    # This should sort by levels but doesn't!
+    # This should sort by levels but does not as there is no CategoricalIndex!
     df.sort_index()
 
+.. note::
+    This could change if a `CategoricalIndex` is implemented (see
+    https://github.com/pydata/pandas/issues/7629)
+
 dtype in apply
 ~~~~~~~~~~~~~~
 
diff --git a/doc/source/v0.15.0.txt b/doc/source/v0.15.0.txt
index d776848de..f305d088e 100644
--- a/doc/source/v0.15.0.txt
+++ b/doc/source/v0.15.0.txt
@@ -9,7 +9,7 @@ users upgrade to this version.
 
 - Highlights include:
 
-  - Add highlites here
+  - The ``Categorical`` type was integrated as a first-class pandas type, see here: :ref:`Categorical Changes <whatsnew_0150.cat>`
 
 - :ref:`Other Enhancements <whatsnew_0150.enhancements>`
 
@@ -30,13 +30,45 @@ users upgrade to this version.
 API changes
 ~~~~~~~~~~~
 
+.. _whatsnew_0150.cat:
 
+Categoricals in Series/DataFrame
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
+:class:`~pandas.Categorical` can now be included in `Series` and `DataFrames` and gained new
+methods to manipulate. Thanks to Jan Schultz for much of this API/implementation. (:issue:`3943`, :issue:`5313`, :issue:`5314`, :issue:`7444`).
 
+.. ipython:: python
 
+    df = pd.DataFrame({"id":[1,2,3,4,5,6], "raw_grade":['a', 'b', 'b', 'a', 'a', 'e']})
 
+    # convert the raw grades to a categorical
+    df["grade"] = pd.Categorical(df["raw_grade"])
 
+    # Alternative: df["grade"] = df["raw_grade"].astype("category")
+    df["grade"]
 
+    # Rename the levels
+    df["grade"].cat.levels = ["very good", "good", "very bad"]
+
+    # Reorder the levels and simultaneously add the missing levels
+    df["grade"].cat.reorder_levels(["very bad", "bad", "medium", "good", "very good"])
+    df["grade"]
+    df.sort("grade")
+    df.groupby("grade").size()
+
+See the :ref:`Categorical introduction<_categorical>` and the :ref:`API documentation<api.categorical>`.
+
+- `pandas.core.group_agg` and `pandas.core.factor_agg` were removed. As an alternative, construct
+  a dataframe and use `df.groupby(<group>).agg(<func>)`.
+
+- Supplying "codes/labels and levels" to the `pandas.Categorical` constructor is deprecated and does
+  not work without supplying ``compat=True``. The default mode now uses "values and levels".
+  Please change your code to use the ``Categorical.from_codes(...)`` constructor.
+
+- The `pandas.Categorical.labels` attribute was renamed to `pandas.Categorical.codes` and is read
+  only. If you want to manipulate the `Categorical`, please use one of the
+  :ref:`API methods on Categoricals<api.categorical>`.
 
 
 
diff --git a/pandas/core/categorical.py b/pandas/core/categorical.py
index ab1b7bf43..d049a6d64 100644
--- a/pandas/core/categorical.py
+++ b/pandas/core/categorical.py
@@ -75,8 +75,7 @@ all level-items at a higher position are set to NaN. If the number of
 level-items is more that the current number of level-items, new
 (unused) levels are added at the end.
 
-To add level-items in between, you need to assign them to the end and
-then reorder the levels.
+To add level-items in between, use `reorder_levels`.
 
 Raises
 ------
@@ -123,6 +122,8 @@ class Categorical(PandasObject):
     ----------
     levels : ndarray
         The levels of this categorical
+    codes : Index
+        The codes (integer positions, which point to the levels) of this categorical, read only
     ordered : boolean
         Whether or not this Categorical is ordered
     name : string
@@ -286,18 +287,67 @@ class Categorical(PandasObject):
         """
         return Categorical(data)
 
+    @classmethod
+    def from_codes(cls, codes, levels, ordered=True, name=None):
+        """
+        Make a Categorical type from codes and levels arrays.
+
+        This constructor is useful if you already have codes and levels and so do not need the
+        (computation intensive) factorization step, which is usually done on the constructor.
+
+        If your data does not follow this convention, please use the normal constructor.
+
+        Parameters
+        ----------
+        codes : array-like, integers
+            An integer array, where each integer points to a level in levels or -1 for NaN
+        levels : index-like
+            The levels for the categorical. Items need to be unique.
+        ordered : boolean, optional
+            Whether or not this categorical is treated as a ordered categorical. If not given,
+            the resulting categorical will be ordered.
+        name : str, optional
+            Name for the Categorical variable.
+        """
+        try:
+            codes = np.asarray(codes, np.int64)
+        except:
+            raise ValueError("codes need to be convertible to an arrays of integers")
+
+        levels = cls._validate_levels(levels)
+
+        if codes.max() >= len(levels) or codes.min() < -1:
+            raise ValueError("codes need to be between -1 and len(levels)-1")
+
+
+        return Categorical(codes, levels=levels, ordered=ordered, name=name, fastpath=True)
+
     _codes = None
 
     def _get_codes(self):
-        """ Get the level codes. """
-        # TODO: return a copy so that no manipulation is possible?
-        return self._codes
+        """ Get the level codes.
 
-    codes = property(fget=_get_codes, doc=_codes_doc)
+        Returns
+        -------
+        codes : integer array view
+            A non writable view of the `codes` array.
+        """
+        v = self._codes.view()
+        v.flags.writeable = False
+        return v
+
+    def _set_codes(self, codes):
+        """
+        Not settable by the user directly
+        """
+        raise ValueError("cannot set Categorical codes directly")
+
+    codes = property(fget=_get_codes, fset=_set_codes, doc=_codes_doc)
 
     _levels = None
 
-    def _validate_levels(self, levels):
+    @classmethod
+    def _validate_levels(cls, levels):
         """" Validates that we have good levels """
         levels = _ensure_index(levels)
         if not levels.is_unique:
@@ -323,12 +373,15 @@ class Categorical(PandasObject):
     def reorder_levels(self, new_levels, ordered=None):
         """ Reorders levels as specified in new_levels.
 
+        `new_levels` must include all old levels but can also include new level items. In
+        contrast to assigning to `levels`, these new level items can be in arbitrary positions.
+
         The level reordering is done inplace.
 
         Raises
         ------
         ValueError
-            If the new levels do not contain the same level items as before
+            If the new levels do not contain all old level items
 
         Parameters
         ----------
@@ -340,10 +393,8 @@ class Categorical(PandasObject):
         """
         new_levels = self._validate_levels(new_levels)
 
-        if len(new_levels) != len(self._levels):
-            raise ValueError('Reordered levels must be of same length as old levels')
-        if len(new_levels-self._levels):
-            raise ValueError('Reordered levels be the same as the original levels')
+        if len(new_levels) < len(self._levels) or len(self._levels-new_levels):
+            raise ValueError('Reordered levels must include all original levels')
         values = self.__array__()
         self._codes = _get_codes_for_values(values, new_levels)
         self._levels = new_levels
@@ -612,26 +663,52 @@ class Categorical(PandasObject):
                                                   footer=False)
 
         result = '%s\n...\n%s' % (head, tail)
-        # TODO: tidy_repr for footer since there may be a ton of levels?
         result = '%s\n%s' % (result, self._repr_footer())
 
         return compat.text_type(result)
 
+    def _repr_level_info(self):
+        """ Returns a string representation of the footer."""
+
+        max_levels = (10 if get_option("display.max_levels") == 0
+                    else get_option("display.max_levels"))
+        level_strs = fmt.format_array(self.levels.get_values(), None)
+        if len(level_strs) > max_levels:
+            num = max_levels // 2
+            head = level_strs[:num]
+            tail = level_strs[-(max_levels - num):]
+            level_strs = head + ["..."] + tail
+        # Strip all leading spaces, which format_array adds for columns...
+        level_strs = [x.strip() for x in level_strs]
+        levheader = "Levels (%d, %s): " % (len(self.levels),
+                                               self.levels.dtype)
+        width, height = get_terminal_size()
+        max_width = (width if get_option("display.width") == 0
+                    else get_option("display.width"))
+        if com.in_ipython_frontend():
+            # 0 = no breaks
+            max_width = 0
+        levstring = ""
+        start = True
+        cur_col_len = len(levheader)
+        sep_len, sep = (3, " < ") if self.ordered else (2, ", ")
+        for val in level_strs:
+            if max_width != 0 and cur_col_len + sep_len + len(val) > max_width:
+                levstring += "\n" + (" "* len(levheader))
+                cur_col_len = len(levheader)
+            if not start:
+                levstring += sep
+                cur_col_len += len(val)
+            levstring += val
+            start = False
+        # replace to simple save space by
+        return levheader + "["+levstring.replace(" < ... < ", " ... ")+"]"
+
     def _repr_footer(self):
-        levheader = 'Levels (%d): ' % len(self.levels)
-        # TODO: should max_line_width respect a setting?
-        levstring = np.array_repr(self.levels, max_line_width=60)
-        indent = ' ' * (levstring.find('[') + len(levheader) + 1)
-        lines = levstring.split('\n')
-        levstring = '\n'.join([lines[0]] +
-                              [indent + x.lstrip() for x in lines[1:]])
-        if self.ordered:
-            order = ", ordered"
-        else:
-            order = ", unordered"
+
         namestr = "Name: %s, " % self.name if self.name is not None else ""
-        return u('%s\n%sLength: %d' % (levheader + levstring + order, namestr,
-                                       len(self)))
+        return u('%sLength: %d\n%s') % (namestr,
+                                       len(self), self._repr_level_info())
 
     def _get_repr(self, name=False, length=True, na_rep='NaN', footer=True):
         formatter = fmt.CategoricalFormatter(self, name=name,
@@ -655,7 +732,7 @@ class Categorical(PandasObject):
             result = 'Categorical([], %s' % self._get_repr(name=True,
                                                            length=False,
                                                            footer=True,
-                                                           )
+                                                           ).replace("\n",", ")
 
         return result
 
diff --git a/pandas/core/common.py b/pandas/core/common.py
index a6e1c5159..53f7415ac 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -106,7 +106,15 @@ def bind_method(cls, name, func):
     else:
         setattr(cls, name, func)
 
+class CategoricalDtypeType(type):
+    """
+    the type of CategoricalDtype, this metaclass determines subclass ability
+    """
+    def __init__(cls, name, bases, attrs):
+        pass
+
 class CategoricalDtype(object):
+    __meta__ = CategoricalDtypeType
     """
     A np.dtype duck-typed class, suitable for holding a custom categorical dtype.
 
@@ -114,7 +122,7 @@ class CategoricalDtype(object):
     """
     name = 'category'
     names = None
-    type = np.object_
+    type = CategoricalDtypeType
     subdtype = None
     kind = 'O'
     str = '|O08'
@@ -128,6 +136,38 @@ class CategoricalDtype(object):
     def __unicode__(self):
         return self.name
 
+    def __str__(self):
+        """
+        Return a string representation for a particular Object
+
+        Invoked by str(df) in both py2/py3.
+        Yields Bytestring in Py2, Unicode String in py3.
+        """
+
+        if compat.PY3:
+            return self.__unicode__()
+        return self.__bytes__()
+
+    def __bytes__(self):
+        """
+        Return a string representation for a particular object.
+
+        Invoked by bytes(obj) in py3 only.
+        Yields a bytestring in both py2/py3.
+        """
+        from pandas.core.config import get_option
+
+        encoding = get_option("display.encoding")
+        return self.__unicode__().encode(encoding, 'replace')
+
+    def __repr__(self):
+        """
+        Return a string representation for a particular object.
+
+        Yields Bytestring in Py2, Unicode String in py3.
+        """
+        return str(self)
+
     def __hash__(self):
         # make myself hashable
         return hash(str(self))
@@ -1670,6 +1710,8 @@ def _get_dtype_from_object(dtype):
     elif isinstance(dtype, compat.string_types):
         if dtype == 'datetime' or dtype == 'timedelta':
             dtype += '64'
+        elif dtype == 'category':
+            return CategoricalDtypeType
         try:
             return _get_dtype_from_object(getattr(np, dtype))
         except AttributeError:
@@ -1680,10 +1722,6 @@ def _get_dtype_from_object(dtype):
     return _get_dtype_from_object(np.dtype(dtype))
 
 
-_string_dtypes = frozenset(map(_get_dtype_from_object, (compat.binary_type,
-                                                        compat.text_type)))
-
-
 def _get_info_slice(obj, indexer):
     """Slice the info axis of `obj` with `indexer`."""
     if not hasattr(obj, '_info_axis_number'):
@@ -2351,6 +2389,7 @@ def is_bool_dtype(arr_or_dtype):
 def is_categorical_dtype(arr_or_dtype):
     if hasattr(arr_or_dtype,'dtype'):
         arr_or_dtype = arr_or_dtype.dtype
+
     if isinstance(arr_or_dtype, CategoricalDtype):
         return True
     try:
@@ -2395,6 +2434,10 @@ def _is_sequence(x):
         return False
 
 
+_string_dtypes = frozenset(map(_get_dtype_from_object, (compat.binary_type,
+                                                        compat.text_type)))
+
+
 _ensure_float64 = algos.ensure_float64
 _ensure_float32 = algos.ensure_float32
 _ensure_int64 = algos.ensure_int64
diff --git a/pandas/core/config_init.py b/pandas/core/config_init.py
index f9f3b0da2..9c360f7ca 100644
--- a/pandas/core/config_init.py
+++ b/pandas/core/config_init.py
@@ -51,6 +51,12 @@ pc_max_cols_doc = """
     'None' value means unlimited.
 """
 
+pc_max_levels_doc = """
+: int
+    This sets the maximum number of levels pandas should output when printing
+    out a `Categorical`.
+"""
+
 pc_max_info_cols_doc = """
 : int
     max_info_columns is used in DataFrame.info method to decide if
@@ -223,6 +229,7 @@ with cf.config_prefix('display'):
                        validator=is_instance_factory((int, type(None))))
     cf.register_option('max_rows', 60, pc_max_rows_doc,
                        validator=is_instance_factory([type(None), int]))
+    cf.register_option('max_levels', 8, pc_max_levels_doc, validator=is_int)
     cf.register_option('max_colwidth', 50, max_colwidth_doc, validator=is_int)
     cf.register_option('max_columns', 20, pc_max_cols_doc,
                        validator=is_instance_factory([type(None), int]))
diff --git a/pandas/core/format.py b/pandas/core/format.py
index bae67352f..be4074bdb 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -93,24 +93,12 @@ class CategoricalFormatter(object):
                 footer += ', '
             footer += "Length: %d" % len(self.categorical)
 
-        levheader = 'Levels (%d): ' % len(self.categorical.levels)
+        level_info = self.categorical._repr_level_info()
 
-        # TODO: should max_line_width respect a setting?
-        try:
-            levstring = np.array_repr(self.categorical.levels, max_line_width=60)
-        except:
-            levstring = str(self.categorical.levels)
-        indent = ' ' * (levstring.find('[') + len(levheader) + 1)
-        lines = levstring.split('\n')
-        levstring = '\n'.join([lines[0]] +
-                              [indent + x.lstrip() for x in lines[1:]])
+        # Levels are added in a newline
         if footer:
-            footer += ', '
-        footer += levheader + levstring
-        if self.categorical.ordered:
-            footer += ", ordered"
-        else:
-            footer += ", unordered"
+            footer += '\n'
+        footer += level_info
 
         return compat.text_type(footer)
 
@@ -164,7 +152,9 @@ class SeriesFormatter(object):
                 footer += 'Freq: %s' % self.series.index.freqstr
 
             if footer and self.series.name is not None:
-                footer += ', '
+                # categories have already a comma + linebreak
+                if not com.is_categorical_dtype(self.series.dtype):
+                    footer += ', '
 
             series_name = com.pprint_thing(self.series.name,
                                            escape_chars=('\t', '\r', '\n'))
@@ -176,6 +166,7 @@ class SeriesFormatter(object):
                 footer += ', '
             footer += 'Length: %d' % len(self.series)
 
+        # TODO: in tidy_repr, with freq index, no dtype is shown -> also include a guard here?
         if self.dtype:
             name = getattr(self.series.dtype, 'name', None)
             if name:
@@ -183,6 +174,15 @@ class SeriesFormatter(object):
                     footer += ', '
                 footer += 'dtype: %s' % com.pprint_thing(name)
 
+        # level infos are added to the end and in a new line, like it is done for Categoricals
+        # Only added when we request a name
+        if self.name and com.is_categorical_dtype(self.series.dtype):
+            level_info = self.series.cat._repr_level_info()
+            if footer:
+                footer += "\n"
+            footer += level_info
+
+
         return compat.text_type(footer)
 
     def _get_formatted_index(self):
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index f07ce11a7..a461dd0e2 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -4556,74 +4556,6 @@ DataFrame._add_numeric_operations()
 
 _EMPTY_SERIES = Series([])
 
-
-def group_agg(values, bounds, f):
-    """
-    R-style aggregator
-
-    Parameters
-    ----------
-    values : N-length or N x K ndarray
-    bounds : B-length ndarray
-    f : ndarray aggregation function
-
-    Returns
-    -------
-    ndarray with same length as bounds array
-    """
-    if values.ndim == 1:
-        N = len(values)
-        result = np.empty(len(bounds), dtype=float)
-    elif values.ndim == 2:
-        N, K = values.shape
-        result = np.empty((len(bounds), K), dtype=float)
-
-    testagg = f(values[:min(1, len(values))])
-    if isinstance(testagg, np.ndarray) and testagg.ndim == 2:
-        raise AssertionError('Function must reduce')
-
-    for i, left_bound in enumerate(bounds):
-        if i == len(bounds) - 1:
-            right_bound = N
-        else:
-            right_bound = bounds[i + 1]
-
-        result[i] = f(values[left_bound:right_bound])
-
-    return result
-
-
-def factor_agg(factor, vec, func):
-    """
-    Aggregate array based on Categorical
-
-    Parameters
-    ----------
-    factor : Categorical
-        length n
-    vec : sequence
-        length n
-    func : function
-        1D array aggregation function
-
-    Returns
-    -------
-    ndarray corresponding to factor levels
-
-    See Also
-    --------
-    pandas.Categorical
-    """
-    indexer = np.argsort(factor.codes)
-    unique_labels = np.arange(len(factor.levels))
-
-    ordered_labels = factor.codes.take(indexer)
-    ordered_vec = np.asarray(vec).take(indexer)
-    bounds = ordered_labels.searchsorted(unique_labels)
-
-    return group_agg(ordered_vec, bounds, func)
-
-
 def _arrays_to_mgr(arrays, arr_names, index, columns, dtype=None):
     """
     Segregate Series based on type and coerce into matrices.
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 57cd2eb50..ac8747284 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -3630,7 +3630,7 @@ class NDFrame(PandasObject):
             if result[1] > 0:
                 top, freq = objcounts.index[0], objcounts.iloc[0]
 
-                if data.dtype == object:
+                if data.dtype == object or com.is_categorical_dtype(data.dtype):
                     names += ['top', 'freq']
                     result += [top, freq]
 
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 7c7b1871b..08d3fbe33 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1361,7 +1361,9 @@ class BaseGrouper(object):
         name_list = []
         for ping, labels in zip(self.groupings, recons_labels):
             labels = com._ensure_platform_int(labels)
-            name_list.append(ping.group_index.take(labels))
+            levels = ping.group_index.take(labels)
+
+            name_list.append(levels)
 
         return name_list
 
@@ -1707,6 +1709,11 @@ class BinGrouper(BaseGrouper):
     def names(self):
         return [self.binlabels.name]
 
+    @property
+    def groupings(self):
+        # for compat
+        return None
+
     def size(self):
         """
         Compute group sizes
@@ -2632,7 +2639,7 @@ class NDFrameGroupBy(GroupBy):
         if isinstance(values[0], DataFrame):
             return self._concat_objects(keys, values,
                                         not_indexed_same=not_indexed_same)
-        elif hasattr(self.grouper, 'groupings'):
+        elif self.grouper.groupings is not None:
             if len(self.grouper.groupings) > 1:
                 key_index = MultiIndex.from_tuples(keys, names=key_names)
 
@@ -3058,7 +3065,7 @@ class DataFrameGroupBy(NDFrameGroupBy):
         if self.axis == 1:
             result = result.T
 
-        return result.convert_objects()
+        return self._reindex_output(result).convert_objects()
 
     def _wrap_agged_blocks(self, items, blocks):
         if not self.as_index:
@@ -3080,7 +3087,27 @@ class DataFrameGroupBy(NDFrameGroupBy):
         if self.axis == 1:
             result = result.T
 
-        return result.convert_objects()
+        return self._reindex_output(result).convert_objects()
+
+    def _reindex_output(self, result):
+        """
+        if we have categorical groupers, then we want to make sure that
+        we have a fully reindex-output to the levels. These may have not participated in
+        the groupings (e.g. may have all been nan groups)
+
+        This can re-expand the output space
+        """
+        groupings = self.grouper.groupings
+        if groupings is None:
+            return result
+        elif len(groupings) == 1:
+            return result
+        elif not any([ping._was_factor for ping in groupings]):
+            return result
+
+        levels_list = [ ping._group_index for ping in groupings ]
+        index = MultiIndex.from_product(levels_list, names=self.grouper.names)
+        return result.reindex(**{ self.obj._get_axis_name(self.axis) : index, 'copy' : False }).sortlevel()
 
     def _iterate_column_groupbys(self):
         for i, colname in enumerate(self._selected_obj.columns):
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index c6a5b048a..2bd318ec2 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -1426,9 +1426,9 @@ class ObjectBlock(Block):
         return element
 
     def should_store(self, value):
-        return not issubclass(value.dtype.type,
+        return not (issubclass(value.dtype.type,
                               (np.integer, np.floating, np.complexfloating,
-                               np.datetime64, np.bool_))
+                               np.datetime64, np.bool_)) or com.is_categorical_dtype(value))
 
     def replace(self, to_replace, value, inplace=False, filter=None,
                 regex=False):
@@ -1639,6 +1639,19 @@ class CategoricalBlock(NonConsolidatableMixIn, ObjectBlock):
 
         return True
 
+    def to_native_types(self, slicer=None, na_rep='', **kwargs):
+        """ convert to our native types format, slicing if desired """
+
+        values = self.values
+        if slicer is not None:
+            # Categorical is always one dimension
+            values = values[slicer]
+        values = np.array(values, dtype=object)
+        mask = isnull(values)
+        values[mask] = na_rep
+        # Blocks.to_native_type returns list of lists, but we are always only a list
+        return [values.tolist()]
+
 class DatetimeBlock(Block):
     __slots__ = ()
     is_datetime = True
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 24092a8e9..eff558d87 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -882,6 +882,9 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
 
     def _repr_footer(self):
 
+        namestr = u("Name: %s, ") % com.pprint_thing(
+            self.name) if self.name is not None else ""
+
         # time series
         if self.is_time_series:
             if self.index.freq is not None:
@@ -889,13 +892,17 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
             else:
                 freqstr = u('')
 
-            namestr = u("Name: %s, ") % com.pprint_thing(
-                self.name) if self.name is not None else ""
             return u('%s%sLength: %d') % (freqstr, namestr, len(self))
 
+        # Categorical
+        if com.is_categorical_dtype(self.dtype):
+            level_info = self.cat._repr_level_info()
+            return u('%sLength: %d, dtype: %s\n%s') % (namestr,
+                                                       len(self),
+                                                       str(self.dtype.name),
+                                                       level_info)
+
         # reg series
-        namestr = u("Name: %s, ") % com.pprint_thing(
-            self.name) if self.name is not None else ""
         return u('%sLength: %d, dtype: %s') % (namestr,
                                                len(self),
                                                str(self.dtype.name))
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 6d765fb31..0e6c41a25 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -1773,6 +1773,9 @@ class DataCol(IndexCol):
             raise TypeError(
                 "[unicode] is not implemented as a table column")
 
+        elif dtype == 'category':
+            raise NotImplementedError
+
         # this is basically a catchall; if say a datetime64 has nans then will
         # end up here ###
         elif inferred_type == 'string' or dtype == 'object':
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index d0d1b0257..6a9442840 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -9,7 +9,7 @@ import datetime
 import numpy as np
 
 import pandas
-from pandas import (Series, DataFrame, Panel, MultiIndex, bdate_range,
+from pandas import (Series, DataFrame, Panel, MultiIndex, Categorical, bdate_range,
                     date_range, Index, DatetimeIndex, isnull)
 from pandas.io.pytables import (HDFStore, get_store, Term, read_hdf,
                                 IncompatibilityWarning, PerformanceWarning,
@@ -4348,6 +4348,28 @@ class TestHDFStore(tm.TestCase):
             result = store.select('test', 'a = "test & test"')
         tm.assert_frame_equal(expected, result)
 
+    def test_categorical(self):
+        # FIXME
+
+        with ensure_clean_store(self.path) as store:
+
+            s = Series(Categorical(['a', 'b', 'b', 'a', 'a', 'c'], levels=['a','b','c','d']))
+
+            self.assertRaises(NotImplementedError, store.append, 's', s, format='table')
+            #store.append('s', s, format='table')
+            #result = store.select('s')
+            #tm.assert_series_equal(s, result)
+
+            df = DataFrame({"s":s, "vals":[1,2,3,4,5,6]})
+            self.assertRaises(NotImplementedError, store.append, 'df', df, format='table')
+            #store.append('df', df, format='table')
+            #result = store.select('df')
+            #tm.assert_frame_equal(df, df2)
+
+            # Ok, this doesn't work yet
+            # FIXME: TypeError: cannot pass a where specification when reading from a Fixed format store. this store must be selected in its entirety
+            #result = store.select('df', where = ['index>2'])
+            #tm.assert_frame_equal(df[df.index>2],result)
 
 def _test_sort(obj):
     if isinstance(obj, DataFrame):
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 3c6711942..54b687e27 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -759,7 +759,6 @@ class NonPooledPanelOLS(object):
 
 def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
                     nw_lags, nobs, df, nw_overlap):
-    from pandas.core.frame import group_agg
     xx_inv = math.inv(xx)
 
     yv = y.values
@@ -782,7 +781,7 @@ def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
             x = x.swaplevel(0, 1).sortlevel(0)
             resid = resid.swaplevel(0, 1).sortlevel(0)
 
-        m = group_agg(x.values * resid.values, x.index._bounds,
+        m = _group_agg(x.values * resid.values, x.index._bounds,
                       lambda x: np.sum(x, axis=0))
 
         if nw_lags is None:
@@ -795,6 +794,40 @@ def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
 
         return np.dot(xx_inv, np.dot(xox, xx_inv))
 
+def _group_agg(values, bounds, f):
+    """
+    R-style aggregator
+
+    Parameters
+    ----------
+    values : N-length or N x K ndarray
+    bounds : B-length ndarray
+    f : ndarray aggregation function
+
+    Returns
+    -------
+    ndarray with same length as bounds array
+    """
+    if values.ndim == 1:
+        N = len(values)
+        result = np.empty(len(bounds), dtype=float)
+    elif values.ndim == 2:
+        N, K = values.shape
+        result = np.empty((len(bounds), K), dtype=float)
+
+    testagg = f(values[:min(1, len(values))])
+    if isinstance(testagg, np.ndarray) and testagg.ndim == 2:
+        raise AssertionError('Function must reduce')
+
+    for i, left_bound in enumerate(bounds):
+        if i == len(bounds) - 1:
+            right_bound = N
+        else:
+            right_bound = bounds[i + 1]
+
+        result[i] = f(values[left_bound:right_bound])
+
+    return result
 
 def _xx_time_effects(x, y):
     """
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index c6caadad3..5a34048fd 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -787,6 +787,21 @@ class TestPanelOLS(BaseTest):
 
         assert_frame_equal(window_model.beta, rolling_model.beta)
 
+    def test_group_agg(self):
+        from pandas.stats.plm import _group_agg
+
+        values = np.ones((10, 2)) * np.arange(10).reshape((10, 1))
+        bounds = np.arange(5) * 2
+        f = lambda x: x.mean(axis=0)
+
+        agged = _group_agg(values, bounds, f)
+
+        assert(agged[1][0] == 2.5)
+        assert(agged[2][0] == 4.5)
+
+        # test a function that doesn't aggregate
+        f2 = lambda x: np.zeros((2, 2))
+        self.assertRaises(Exception, _group_agg, values, bounds, f2)
 
 def _check_non_raw_results(model):
     _check_repr(model)
diff --git a/pandas/tests/test_categorical.py b/pandas/tests/test_categorical.py
index 24e65ce9c..0aa7f2b67 100644
--- a/pandas/tests/test_categorical.py
+++ b/pandas/tests/test_categorical.py
@@ -2,17 +2,14 @@
 
 from datetime import datetime
 from pandas.compat import range, lrange, u
-import nose
 import re
-import os
 
 import numpy as np
 import pandas as pd
 
-from pandas import (Categorical, Index, Int64Index, MultiIndex,
-                    Series, DataFrame, PeriodIndex, Timestamp)
+from pandas import (Categorical, Index, Series, DataFrame, PeriodIndex,
+                    Timestamp, _np_version_under1p7)
 
-from pandas.util.testing import assert_almost_equal
 import pandas.core.common as com
 import pandas.compat as compat
 import pandas.util.testing as tm
@@ -114,16 +111,37 @@ class TestCategorical(tm.TestCase):
         cat = pd.Categorical([1,2,3,np.nan], levels=[1,2,3])
         self.assertTrue(com.is_integer_dtype(cat.levels))
 
-    def test_factor_agg(self):
-        import pandas.core.frame as frame
+    def test_from_codes(self):
 
-        arr = np.arange(len(self.factor))
+        # too few levels
+        def f():
+            Categorical.from_codes([1,2], [1,2])
+        self.assertRaises(ValueError, f)
+
+        # no int codes
+        def f():
+            Categorical.from_codes(["a"], [1,2])
+        self.assertRaises(ValueError, f)
+
+        # no unique levels
+        def f():
+            Categorical.from_codes([0,1,2], ["a","a","b"])
+        self.assertRaises(ValueError, f)
+
+        # too negative
+        def f():
+            Categorical.from_codes([-2,1,2], ["a","b","c"])
+        self.assertRaises(ValueError, f)
+
+
+        exp = Categorical(["a","b","c"])
+        res = Categorical.from_codes([0,1,2], ["a","b","c"])
+        self.assertTrue(exp.equals(res))
 
-        f = np.sum
-        agged = frame.factor_agg(self.factor, arr, f)
-        pointers = self.factor._codes
-        for i, idx in enumerate(self.factor.levels):
-            self.assertEqual(f(arr[pointers == i]), agged[i])
+        # Not available in earlier numpy versions
+        if hasattr(np.random, "choice"):
+            codes = np.random.choice([0,1], 5, p=[0.9,0.1])
+            pd.Categorical.from_codes(codes, levels=["train", "test"])
 
     def test_comparisons(self):
         result = self.factor[self.factor == 'a']
@@ -198,14 +216,9 @@ class TestCategorical(tm.TestCase):
 
     def test_print(self):
         expected = [" a", " b", " b", " a", " a", " c", " c", " c",
-                    "Levels (3): Index([a, b, c], dtype=object), ordered"]
+                    "Levels (3, object): [a < b < c]"]
         expected = "\n".join(expected)
-        # hack because array_repr changed in numpy > 1.6.x
         actual = repr(self.factor)
-        pat = "Index\(\['a', 'b', 'c']"
-        sub = "Index([a, b, c]"
-        actual = re.sub(pat, sub, actual)
-
         self.assertEqual(actual, expected)
 
     def test_big_print(self):
@@ -213,45 +226,31 @@ class TestCategorical(tm.TestCase):
         expected = [" a", " b", " c", " a", " b", " c", " a", " b", " c",
                     " a", " b", " c", " a", "...", " c", " a", " b", " c",
                     " a", " b", " c", " a", " b", " c", " a", " b", " c",
-                    "Levels (3): Index([a, b, c], dtype=object), unordered",
-                    "Name: cat, Length: 600" ]
+                    "Name: cat, Length: 600",
+                    "Levels (3, object): [a, b, c]"]
         expected = "\n".join(expected)
 
-        # hack because array_repr changed in numpy > 1.6.x
         actual = repr(factor)
-        pat = "Index\(\['a', 'b', 'c']"
-        sub = "Index([a, b, c]"
-        actual = re.sub(pat, sub, actual)
 
-        self.assertEqual(actual, expected)
+        self.assertEqual(expected, actual)
 
     def test_empty_print(self):
         factor = Categorical([], ["a","b","c"], name="cat")
-        expected = ("Categorical([], Name: cat, Levels (3): "
-                    "Index([a, b, c], dtype=object), ordered")
+        expected = ("Categorical([], Name: cat, Levels (3, object): [a < b < c]")
         # hack because array_repr changed in numpy > 1.6.x
         actual = repr(factor)
-        pat = "Index\(\['a', 'b', 'c']"
-        sub = "Index([a, b, c]"
-        actual = re.sub(pat, sub, actual)
 
         self.assertEqual(actual, expected)
 
         factor = Categorical([], ["a","b","c"])
-        expected = ("Categorical([], Levels (3): "
-                    "Index([a, b, c], dtype=object), ordered")
-        # hack because array_repr changed in numpy > 1.6.x
+        expected = ("Categorical([], Levels (3, object): [a < b < c]")
         actual = repr(factor)
-        pat = "Index\(\['a', 'b', 'c']"
-        sub = "Index([a, b, c]"
-        actual = re.sub(pat, sub, actual)
 
-        self.assertEqual(actual, expected)
+        self.assertEqual(expected, actual)
 
         factor = Categorical([], [])
-        expected = ("Categorical([], Levels (0): "
-                    "Index([], dtype=object), ordered")
-        self.assertEqual(repr(factor), expected)
+        expected = ("Categorical([], Levels (0, object): []")
+        self.assertEqual(expected, repr(factor))
 
     def test_periodindex(self):
         idx1 = PeriodIndex(['2014-01', '2014-01', '2014-02', '2014-02',
@@ -300,7 +299,7 @@ class TestCategorical(tm.TestCase):
         self.assertTrue(np.isnan(s.__array__()[2]))
         self.assert_numpy_array_equal(s.levels, np.array([1,2]))
 
-    def test_category_reorder_levels(self):
+    def test_reorder_levels(self):
         cat = Categorical(["a","b","c","a"], ordered=True)
         exp_levels = np.array(["c","b","a"])
         exp_values = np.array(["a","b","c","a"])
@@ -308,17 +307,20 @@ class TestCategorical(tm.TestCase):
         self.assert_numpy_array_equal(cat.levels, exp_levels)
         self.assert_numpy_array_equal(cat.__array__(), exp_values)
 
+        # not all "old" included in "new"
         def f():
             cat.reorder_levels(["a"])
         self.assertRaises(ValueError, f)
 
+        # still not all "old" in "new"
         def f():
             cat.reorder_levels(["a","b","d"])
         self.assertRaises(ValueError, f)
 
-        def f():
-            cat.reorder_levels(["a","b","c", "d"])
-        self.assertRaises(ValueError, f)
+        # This works: all "old" included in "new"
+        cat.reorder_levels(["a","b","c","d"])
+        exp_levels = np.array(["a","b","c","d"])
+        self.assert_numpy_array_equal(cat.levels, exp_levels)
 
         # internals...
         c = Categorical([1,2,3,4,1], levels=[1,2,3,4])
@@ -344,12 +346,12 @@ class TestCategorical(tm.TestCase):
 
     def test_nan_handling(self):
 
-        # Nans are represented as -1 in labels
+        # Nans are represented as -1 in codes
         c = Categorical(["a","b",np.nan,"a"])
         self.assert_numpy_array_equal(c.levels , np.array(["a","b"]))
         self.assert_numpy_array_equal(c._codes , np.array([0,1,-1,0]))
 
-        # If levels have nan included, the label should point to that instead
+        # If levels have nan included, the code should point to that instead
         c = Categorical(["a","b",np.nan,"a"], levels=["a","b",np.nan])
         self.assert_numpy_array_equal(c.levels , np.array(["a","b",np.nan],dtype=np.object_))
         self.assert_numpy_array_equal(c._codes , np.array([0,1,2,0]))
@@ -360,6 +362,36 @@ class TestCategorical(tm.TestCase):
         self.assert_numpy_array_equal(c.levels , np.array(["a","b",np.nan],dtype=np.object_))
         self.assert_numpy_array_equal(c._codes , np.array([0,1,2,0]))
 
+    def test_codes_immutable(self):
+
+        # Codes should be read only
+        c = Categorical(["a","b","c","a", np.nan])
+        exp = np.array([0,1,2,0, -1])
+        self.assert_numpy_array_equal(c.codes, exp)
+
+        # Assignments to codes should raise
+        def f():
+            c.codes = np.array([0,1,2,0,1])
+        self.assertRaises(ValueError, f)
+
+        # changes in the codes array should raise
+        # np 1.6.1 raises RuntimeError rather than ValueError
+        codes= c.codes
+        def f():
+            codes[4] = 1
+        if _np_version_under1p7:
+            self.assertRaises(RuntimeError, f)
+        else:
+            self.assertRaises(ValueError, f)
+
+        # But even after getting the codes, the original array should still be writeable!
+        c[4] = "a"
+        exp = np.array([0,1,2,0, 0])
+        self.assert_numpy_array_equal(c.codes, exp)
+        c._codes[4] = 2
+        exp = np.array([0,1,2,0, 2])
+        self.assert_numpy_array_equal(c.codes, exp)
+
 
     def test_min_max(self):
 
@@ -548,6 +580,19 @@ class TestCategoricalAsBlock(tm.TestCase):
         res = s.astype('category')
         tm.assert_series_equal(res, exp)
 
+        df = pd.DataFrame({"cats":[1,2,3,4,5,6], "vals":[1,2,3,4,5,6]})
+        cats = Categorical([1,2,3,4,5,6])
+        exp_df = pd.DataFrame({"cats":cats, "vals":[1,2,3,4,5,6]})
+        df["cats"] =  df["cats"].astype("category")
+        tm.assert_frame_equal(exp_df, df)
+
+
+        df = pd.DataFrame({"cats":['a', 'b', 'b', 'a', 'a', 'd'], "vals":[1,2,3,4,5,6]})
+        cats = Categorical(['a', 'b', 'b', 'a', 'a', 'd'])
+        exp_df = pd.DataFrame({"cats":cats, "vals":[1,2,3,4,5,6]})
+        df["cats"] =  df["cats"].astype("category")
+        tm.assert_frame_equal(exp_df, df)
+
     def test_sideeffects_free(self):
 
         # Passing a categorical to a Series and then changing values in either the series or the
@@ -696,12 +741,11 @@ class TestCategoricalAsBlock(tm.TestCase):
 
     def test_describe(self):
 
-        ###FIXME###
-        # This should(?) only includes the value column, not the value_group
-        result = self.cat['value_group'].describe()
+        # Categoricals should not show up together with numerical columns
         result = self.cat.describe()
         self.assertEquals(len(result.columns),1)
 
+        # empty levels show up as NA
         s = Series(Categorical(["a","b","b","b"], levels=['a','b','c'], ordered=True))
         result = s.cat.describe()
 
@@ -710,15 +754,48 @@ class TestCategoricalAsBlock(tm.TestCase):
                              index=Index(['a','b','c'],name='levels'))
         tm.assert_frame_equal(result,expected)
 
-        ###FIXME###x: this correctly returns 2 for the uniques, should we add an attribute levels?
         result = s.describe()
-        expected = Series([4,2],index=['count','unique'])
+        expected = Series([4,2,"b",3],index=['count','unique','top', 'freq'])
         tm.assert_series_equal(result,expected)
 
-    def test_groupby(self):
+        # NA as a level
+        cat = pd.Categorical(["a","c","c",np.nan], levels=["b","a","c",np.nan] )
+        result = cat.describe()
+
+        expected = DataFrame([[np.nan, np.nan],[1,0.25],[2,0.5], [1,0.25]],
+                             columns=['counts','freqs'],
+                             index=Index(['b','a','c',np.nan],name='levels'))
+        tm.assert_frame_equal(result,expected)
+
+
+        # In a frame, describe() for the cat should be the same as for string arrays (count, unique,
+        # top, freq)
+        cat = pd.Series(pd.Categorical(["a","b","c","c"]))
+        df3 = pd.DataFrame({"cat":cat, "s":["a","b","c","c"]})
+        res = df3.describe()
+        self.assert_numpy_array_equal(res["cat"].values, res["s"].values)
+
+    def test_repr(self):
+        a = pd.Series(pd.Categorical([1,2,3,4], name="a"))
+        exp = u("0    1\n1    2\n2    3\n3    4\n" +
+              "Name: a, dtype: category\nLevels (4, int64): [1 < 2 < 3 < 4]")
+
+        self.assertEqual(exp, a.__unicode__())
+
+        a = pd.Series(pd.Categorical(["a","b"] *25, name="a"))
+        exp = u("".join(["%s    a\n%s    b\n"%(i,i+1) for i in range(0,10,2)]) + "...\n" +
+                "".join(["%s    a\n%s    b\n"%(i,i+1) for i in range(40,50,2)]) +
+                "Name: a, Length: 50, dtype: category\n" +
+                "Levels (2, object): [a < b]")
+        self.assertEqual(exp,a._tidy_repr())
+
+        levs = list("abcdefghijklmnopqrstuvwxyz")
+        a = pd.Series(pd.Categorical(["a","b"], name="a", levels=levs))
+        exp = u("0    a\n1    b\n" +
+                "Name: a, dtype: category\n"
+                "Levels (26, object): [a < b < c < d ... w < x < y < z]")
+        self.assertEqual(exp,a.__unicode__())
 
-        result = self.cat['value_group'].unique()
-        result = self.cat.groupby(['value_group'])['value_group'].count()
 
     def test_groupby_sort(self):
 
@@ -790,52 +867,52 @@ class TestCategoricalAsBlock(tm.TestCase):
         cats = Categorical(["a", "a", "a", "b", "b", "b", "c", "c", "c"], levels=["a","b","c","d"])
         data = DataFrame({"a":[1,1,1,2,2,2,3,4,5], "b":cats})
 
+        expected = DataFrame({ 'a' : Series([1,2,4,np.nan],index=Index(['a','b','c','d'],name='b')) })
         result = data.groupby("b").mean()
-        result = result["a"].values
-        exp = np.array([1,2,4,np.nan])
-        self.assert_numpy_array_equivalent(result, exp)
-
-        ### FIXME ###
-
-        #res = len(data.groupby("b"))
-        #self.assertEqual(res ,4)
+        tm.assert_frame_equal(result, expected)
 
         raw_cat1 = Categorical(["a","a","b","b"], levels=["a","b","z"])
         raw_cat2 = Categorical(["c","d","c","d"], levels=["c","d","y"])
         df = DataFrame({"A":raw_cat1,"B":raw_cat2, "values":[1,2,3,4]})
-        gb = df.groupby("A")
 
-        #idx = gb.indices
-        #self.assertEqual(len(gb), 3)
-        #num = 0
-        #for _ in gb:
-        #    num +=1
-        #self.assertEqual(len(gb), 3)
-        #gb = df.groupby(["B"])
-        #idx2 = gb.indices
-        #self.assertEqual(len(gb), 3)
-        #num = 0
-        #for _ in gb:
-        #    num +=1
-        #self.assertEqual(len(gb), 3)
-        #gb = df.groupby(["A","B"])
-        #res = len(gb)
-        #idx3 = gb.indices
-        #self.assertEqual(res, 9)
-        #num = 0
-        #for _ in gb:
-        #    num +=1
-        #self.assertEqual(len(gb), 9)
+        # single grouper
+        gb = df.groupby("A")
+        expected = DataFrame({ 'values' : Series([3,7,np.nan],index=Index(['a','b','z'],name='A')) })
+        result = gb.sum()
+        tm.assert_frame_equal(result, expected)
+
+        # multiple groupers
+        gb = df.groupby(['A','B'])
+        expected = DataFrame({ 'values' : Series([1,2,np.nan,3,4,np.nan,np.nan,np.nan,np.nan],
+                                                 index=pd.MultiIndex.from_product([['a','b','z'],['c','d','y']],names=['A','B'])) })
+        result = gb.sum()
+        tm.assert_frame_equal(result, expected)
+
+        # multiple groupers with a non-cat
+        df = df.copy()
+        df['C'] = ['foo','bar']*2
+        gb = df.groupby(['A','B','C'])
+        expected = DataFrame({ 'values' :
+                               Series(np.nan,index=pd.MultiIndex.from_product([['a','b','z'],
+                                                                               ['c','d','y'],
+                                                                               ['foo','bar']],
+                                                                              names=['A','B','C']))
+                               }).sortlevel()
+        expected.iloc[[1,2,7,8],0] = [1,2,3,4]
+        result = gb.sum()
+        tm.assert_frame_equal(result, expected)
 
     def test_pivot_table(self):
 
         raw_cat1 = Categorical(["a","a","b","b"], levels=["a","b","z"])
         raw_cat2 = Categorical(["c","d","c","d"], levels=["c","d","y"])
         df = DataFrame({"A":raw_cat1,"B":raw_cat2, "values":[1,2,3,4]})
-        res = pd.pivot_table(df, values='values', index=['A', 'B'])
+        result = pd.pivot_table(df, values='values', index=['A', 'B'])
 
-        ### FIXME ###
-        #self.assertEqual(len(res), 9)
+        expected = Series([1,2,np.nan,3,4,np.nan,np.nan,np.nan,np.nan],
+                          index=pd.MultiIndex.from_product([['a','b','z'],['c','d','y']],names=['A','B']),
+                          name='values')
+        tm.assert_series_equal(result, expected)
 
     def test_count(self):
 
@@ -1432,53 +1509,6 @@ class TestCategoricalAsBlock(tm.TestCase):
         # invalid ufunc
         self.assertRaises(TypeError, lambda : np.log(s))
 
-    def test_io_hdf(self):
-        from pandas.io.tests.test_pytables import safe_remove
-        from pandas.io.pytables import  read_hdf
-
-        hdf_file = 'test.h5'
-
-        try:
-            s = Series(Categorical(['a', 'b', 'b', 'a', 'a', 'c'], levels=['a','b','c','d']))
-            # FIXME: AttributeError: 'Categorical' object has no attribute 'T'
-            s.to_hdf(hdf_file, "series_alone")
-            s2 = read_hdf(hdf_file, "series_alone")
-            tm.assert_series_equal(s, s2)
-            df = DataFrame({"s":s, "vals":[1,2,3,4,5,6]})
-            df.to_hdf(hdf_file, "frame_alone")
-            df2 = read_hdf(hdf_file, "frame_alone")
-            tm.assert_frame_equal(df, df2)
-            # Ok, this doesn't work yet
-            # FIXME: TypeError: cannot pass a where specification when reading from a Fixed format store. this store must be selected in its entirety
-            #result = read_hdf(hdf_file, "frame_alone", where = ['index>2'])
-            #tm.assert_frame_equal(df[df.index>2],result)
-
-        finally:
-            safe_remove(hdf_file)
-
-    def test_io_csv(self):
-
-        # CSV should result in the same output as when one would add a normal Series/DataFrame
-        from pandas.compat import StringIO
-
-        s = Series(Categorical(['a', 'b', 'b', 'a', 'a', 'c', 'c', 'c']))
-        s2 = Series(['a', 'b', 'b', 'a', 'a', 'c', 'c', 'c'])
-        res = StringIO()
-        s.to_csv(res)
-        exp = StringIO()
-        s2.to_csv(exp)
-        self.assertEqual(res.getvalue(), exp.getvalue())
-
-        df = DataFrame({"s":s})
-        df2 = DataFrame({"s":s2})
-        res = StringIO()
-        # FIXME: IndexError: too many indices
-        #df.to_csv(res)
-        #exp = StringIO()
-        #df2.to_csv(exp)
-        #self.assertEqual(res.getvalue(), exp.getvalue())
-
-
 if __name__ == '__main__':
     import nose
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 1cada8efb..2e1bbc88e 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -6365,6 +6365,27 @@ class TestDataFrame(tm.TestCase, CheckIndexing,
                     'three,3,6\n')
         self.assertEqual(buf.getvalue(), expected)
 
+    def test_to_csv_from_csv_categorical(self):
+
+        # CSV with categoricals should result in the same output as when one would add a "normal"
+        # Series/DataFrame.
+        s = Series(pd.Categorical(['a', 'b', 'b', 'a', 'a', 'c', 'c', 'c']))
+        s2 = Series(['a', 'b', 'b', 'a', 'a', 'c', 'c', 'c'])
+        res = StringIO()
+        s.to_csv(res)
+        exp = StringIO()
+        s2.to_csv(exp)
+        self.assertEqual(res.getvalue(), exp.getvalue())
+
+        df = DataFrame({"s":s})
+        df2 = DataFrame({"s":s2})
+        res = StringIO()
+        df.to_csv(res)
+        exp = StringIO()
+        df2.to_csv(exp)
+        self.assertEqual(res.getvalue(), exp.getvalue())
+
+
     def test_info(self):
         io = StringIO()
         self.frame.info(buf=io)
@@ -12999,11 +13020,16 @@ starting,ending,measure
                         'b': list(range(1, 4)),
                         'c': np.arange(3, 6).astype('u1'),
                         'd': np.arange(4.0, 7.0, dtype='float64'),
-                        'e': [True, False, True]})
+                        'e': [True, False, True],
+                        'f': pd.Categorical(list('abc'))})
         ri = df.select_dtypes(include=[np.number])
         ei = df[['b', 'c', 'd']]
         tm.assert_frame_equal(ri, ei)
 
+        ri = df.select_dtypes(include=[np.number,'category'])
+        ei = df[['b', 'c', 'd', 'f']]
+        tm.assert_frame_equal(ri, ei)
+
     def test_select_dtypes_exclude(self):
         df = DataFrame({'a': list('abc'),
                         'b': list(range(1, 4)),
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index be589af2a..ea4d66074 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -2901,9 +2901,9 @@ class TestGroupBy(tm.TestCase):
 
     def test_groupby_categorical(self):
         levels = ['foo', 'bar', 'baz', 'qux']
-        labels = np.random.randint(0, 4, size=100)
+        codes = np.random.randint(0, 4, size=100)
 
-        cats = Categorical(labels, levels, name='myfactor', fastpath=True)
+        cats = Categorical.from_codes(codes, levels, name='myfactor')
 
         data = DataFrame(np.random.randn(100, 4))
 
@@ -3049,18 +3049,18 @@ class TestGroupBy(tm.TestCase):
     def test_groupby_categorical_no_compress(self):
         data = Series(np.random.randn(9))
 
-        labels = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])
-        cats = Categorical(labels, [0, 1, 2], fastpath=True)
+        codes = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])
+        cats = Categorical.from_codes(codes, [0, 1, 2])
 
         result = data.groupby(cats).mean()
-        exp = data.groupby(labels).mean()
+        exp = data.groupby(codes).mean()
         assert_series_equal(result, exp)
 
-        labels = np.array([0, 0, 0, 1, 1, 1, 3, 3, 3])
-        cats = Categorical(labels, [0, 1, 2, 3], fastpath=True)
+        codes = np.array([0, 0, 0, 1, 1, 1, 3, 3, 3])
+        cats = Categorical.from_codes(codes, [0, 1, 2, 3])
 
         result = data.groupby(cats).mean()
-        exp = data.groupby(labels).mean().reindex(cats.levels)
+        exp = data.groupby(codes).mean().reindex(cats.levels)
         assert_series_equal(result, exp)
 
         cats = Categorical(["a", "a", "a", "b", "b", "b", "c", "c", "c"], levels=["a","b","c","d"])
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 255da1af7..f8798e794 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -8,7 +8,6 @@ import numpy as np
 
 from pandas import Series, DataFrame, Index, isnull, notnull, pivot, MultiIndex
 from pandas.core.datetools import bday
-from pandas.core.frame import group_agg
 from pandas.core.panel import Panel
 from pandas.core.series import remove_na
 import pandas.core.common as com
@@ -1827,19 +1826,6 @@ class TestPanel(tm.TestCase, PanelTests, CheckIndexing,
         self.panel['i'] = self.panel['ItemA']
         assert_frame_equal(self.panel['i'], self.panel.i)
 
-    def test_group_agg(self):
-        values = np.ones((10, 2)) * np.arange(10).reshape((10, 1))
-        bounds = np.arange(5) * 2
-        f = lambda x: x.mean(axis=0)
-
-        agged = group_agg(values, bounds, f)
-
-        assert(agged[1][0] == 2.5)
-        assert(agged[2][0] == 4.5)
-
-        # test a function that doesn't aggregate
-        f2 = lambda x: np.zeros((2, 2))
-        self.assertRaises(Exception, group_agg, values, bounds, f2)
 
     def test_from_frame_level1_unsorted(self):
         tuples = [('MSFT', 3), ('MSFT', 2), ('AAPL', 2),
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index 7dc5d9bd4..e88a8c3b2 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -8,7 +8,6 @@ import numpy as np
 
 from pandas import Series, DataFrame, Index, isnull, notnull, pivot, MultiIndex
 from pandas.core.datetools import bday
-from pandas.core.frame import group_agg
 from pandas.core.panel import Panel
 from pandas.core.panel4d import Panel4D
 from pandas.core.series import remove_na
@@ -1027,19 +1026,6 @@ class TestPanel4d(tm.TestCase, CheckIndexing, SafeForSparse,
     def test_get_attr(self):
         assert_panel_equal(self.panel4d['l1'], self.panel4d.l1)
 
-    def test_group_agg(self):
-        values = np.ones((10, 2)) * np.arange(10).reshape((10, 1))
-        bounds = np.arange(5) * 2
-        f = lambda x: x.mean(axis=0)
-
-        agged = group_agg(values, bounds, f)
-
-        assert(agged[1][0] == 2.5)
-        assert(agged[2][0] == 4.5)
-
-        # test a function that doesn't aggregate
-        f2 = lambda x: np.zeros((2, 2))
-        self.assertRaises(Exception, group_agg, values, bounds, f2)
 
     def test_from_frame_level1_unsorted(self):
         raise nose.SkipTest("skipping for now")
