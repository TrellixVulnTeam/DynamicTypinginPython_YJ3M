commit 0d8997a6db0f4aca6cb397cd116143355baba2e9
Author: Phillip Cloud <cpcloud@gmail.com>
Date:   Mon Sep 2 18:00:22 2013 -0400

    ENH: add in, not in, and string/list query support

diff --git a/bench/bench_with_subset.R b/bench/bench_with_subset.R
new file mode 100644
index 000000000..69d0f7a9e
--- /dev/null
+++ b/bench/bench_with_subset.R
@@ -0,0 +1,53 @@
+library(microbenchmark)
+library(data.table)
+
+
+data.frame.subset.bench <- function (n=1e7, times=30) {
+    df <- data.frame(a=rnorm(n), b=rnorm(n), c=rnorm(n))
+    print(microbenchmark(subset(df, a <= b & b <= (c ^ 2 + b ^ 2 - a) & b > c),
+                         times=times))
+}
+
+
+# data.table allows something very similar to query with an expression
+# but we have chained comparisons AND we're faster BOO YAH!
+data.table.subset.expression.bench <- function (n=1e7, times=30) {
+    dt <- data.table(a=rnorm(n), b=rnorm(n), c=rnorm(n))
+    print(microbenchmark(dt[, a <= b & b <= (c ^ 2 + b ^ 2 - a) & b > c],
+                         times=times))
+}
+
+
+# compare against subset with data.table for good measure
+data.table.subset.bench <- function (n=1e7, times=30) {
+    dt <- data.table(a=rnorm(n), b=rnorm(n), c=rnorm(n))
+    print(microbenchmark(subset(dt, a <= b & b <= (c ^ 2 + b ^ 2 - a) & b > c),
+                         times=times))
+}
+
+
+data.frame.with.bench <- function (n=1e7, times=30) {
+    df <- data.frame(a=rnorm(n), b=rnorm(n), c=rnorm(n))
+
+    print(microbenchmark(with(df, a + b * (c ^ 2 + b ^ 2 - a) / (a * c) ^ 3),
+                         times=times))
+}
+
+
+data.table.with.bench <- function (n=1e7, times=30) {
+    dt <- data.table(a=rnorm(n), b=rnorm(n), c=rnorm(n))
+    print(microbenchmark(with(dt, a + b * (c ^ 2 + b ^ 2 - a) / (a * c) ^ 3),
+                         times=times))
+}
+
+
+bench <- function () {
+    data.frame.subset.bench()
+    data.table.subset.expression.bench()
+    data.table.subset.bench()
+    data.frame.with.bench()
+    data.table.with.bench()
+}
+
+
+bench()
diff --git a/bench/bench_with_subset.py b/bench/bench_with_subset.py
new file mode 100644
index 000000000..878b9c08e
--- /dev/null
+++ b/bench/bench_with_subset.py
@@ -0,0 +1,37 @@
+#!/usr/bin/env python
+
+"""
+Microbenchmarks for comparison with R's "with" and "subset" functions
+"""
+
+from __future__ import print_function
+from timeit import timeit
+
+
+def bench_with(n=1e7, times=10, repeat=3):
+    setup = "from pandas import DataFrame\n"
+    setup += "from numpy.random import randn\n"
+    setup += "df = DataFrame(randn(%d, 3), columns=list('abc'))\n" % n
+    setup += "s = 'a + b * (c ** 2 + b ** 2 - a) / (a * c) ** 3'"
+    print('DataFrame.eval:')
+    print(timeit('df.eval(s)', setup=setup, repeat=repeat, number=times))
+
+
+def bench_subset(n=1e7, times=10, repeat=3):
+    setup = "from pandas import DataFrame\n"
+    setup += "from numpy.random import randn\n"
+    setup += "df = DataFrame(randn(%d, 3), columns=list('abc'))\n" % n
+    setup += "s = 'a <= b <= (c ** 2 + b ** 2 - a) and b > c'"
+    print('DataFrame.query:')
+    print(timeit('df.query(s)', setup=setup, repeat=repeat, number=times))
+    print('DataFrame.__getitem__:')
+    print(timeit('df[s]', setup=setup, repeat=repeat, number=times))
+
+
+def bench():
+    bench_with()
+    bench_subset()
+
+
+if __name__ == '__main__':
+    bench()
diff --git a/doc/source/api.rst b/doc/source/api.rst
index affa84078..28c1515e9 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -514,6 +514,7 @@ Computations / Descriptive Stats
    DataFrame.cumsum
    DataFrame.describe
    DataFrame.diff
+   DataFrame.eval
    DataFrame.kurt
    DataFrame.mad
    DataFrame.max
diff --git a/doc/source/comparison_with_r.rst b/doc/source/comparison_with_r.rst
index 575976805..012a6fe6b 100644
--- a/doc/source/comparison_with_r.rst
+++ b/doc/source/comparison_with_r.rst
@@ -1,28 +1,88 @@
 .. currentmodule:: pandas
 .. _compare_with_r:
 
-*******************************
 Comparison with R / R libraries
 *******************************
 
-Since pandas aims to provide a lot of the data manipulation and analysis
-functionality that people use R for, this page was started to provide a more
-detailed look at the R language and it's many 3rd party libraries as they
-relate to pandas. In offering comparisons with R and CRAN libraries, we care
-about the following things:
+Since ``pandas`` aims to provide a lot of the data manipulation and analysis
+functionality that people use `R <http://www.r-project.org/>`__ for, this page
+was started to provide a more detailed look at the `R language
+<http://en.wikipedia.org/wiki/R_(programming_language)>`__ and its many third
+party libraries as they relate to ``pandas``. In comparisons with R and CRAN
+libraries, we care about the following things:
 
-  - **Functionality / flexibility**: what can / cannot be done with each tool
-  - **Performance**: how fast are operations. Hard numbers / benchmarks are
+  - **Functionality / flexibility**: what can/cannot be done with each tool
+  - **Performance**: how fast are operations. Hard numbers/benchmarks are
     preferable
-  - **Ease-of-use**: is one tool easier or harder to use (you may have to be
-    the judge of this given side-by-side code comparisons)
+  - **Ease-of-use**: Is one tool easier/harder to use (you may have to be
+    the judge of this, given side-by-side code comparisons)
+
+This page is also here to offer a bit of a translation guide for users of these
+R packages.
+
+Base R
+------
+
+|subset|_
+~~~~~~~~~~
+
+.. versionadded:: 0.13
+
+The :meth:`~pandas.DataFrame.query` method is similar to the base R ``subset``
+function. In R you might want to get the rows of a ``data.frame`` where one
+column's values are less than another column's values:
+
+    .. code-block:: r
+
+       df <- data.frame(a=rnorm(10), b=rnorm(10))
+       subset(df, a <= b)
+       df[df$a <= df$b,]  # note the comma
+
+In ``pandas``, there are a few ways to perform subsetting. You can use
+:meth:`~pandas.DataFrame.query` or pass an expression as if it were an
+index/slice as well as standard boolean indexing:
+
+    .. ipython:: python
+
+       from pandas import DataFrame
+       from numpy.random import randn
+
+       df = DataFrame({'a': randn(10), 'b': randn(10)})
+       df.query('a <= b')
+       df['a <= b']
+       df[df.a <= df.b]
+       df.loc[df.a <= df.b]
 
-As I do not have an encyclopedic knowledge of R packages, feel free to suggest
-additional CRAN packages to add to this list. This is also here to offer a big
-of a translation guide for users of these R packages.
+For more details and examples see :ref:`the query documentation
+<indexing.query>`.
 
-data.frame
-----------
+
+|with|_
+~~~~~~~~
+
+.. versionadded:: 0.13
+
+An expression using a data.frame called ``df`` in R with the columns ``a`` and
+``b`` would be evaluated using ``with`` like so:
+
+    .. code-block:: r
+
+       df <- data.frame(a=rnorm(10), b=rnorm(10))
+       with(df, a + b)
+       df$a + df$b  # same as the previous expression
+
+In ``pandas`` the equivalent expression, using the
+:meth:`~pandas.DataFrame.eval` method, would be:
+
+    .. ipython:: python
+
+       df = DataFrame({'a': randn(10), 'b': randn(10)})
+       df.eval('a + b')
+       df.a + df.b  # same as the previous expression
+
+In certain cases :meth:`~pandas.DataFrame.eval` will be much faster than
+evaluation in pure Python. For more details and examples see :ref:`the eval
+documentation <enhancingperf.eval>`.
 
 zoo
 ---
@@ -36,3 +96,9 @@ plyr
 reshape / reshape2
 ------------------
 
+
+.. |with| replace:: ``with``
+.. _with: http://finzi.psych.upenn.edu/R/library/base/html/with.html
+
+.. |subset| replace:: ``subset``
+.. _subset: http://finzi.psych.upenn.edu/R/library/base/html/subset.html
diff --git a/doc/source/enhancingperf.rst b/doc/source/enhancingperf.rst
index 47d2acc57..ffd765ed7 100644
--- a/doc/source/enhancingperf.rst
+++ b/doc/source/enhancingperf.rst
@@ -292,14 +292,13 @@ Read more in the `cython docs <http://docs.cython.org/>`__.
 
 .. _enhancingperf.eval:
 
-.. versionadded:: 0.13
-
 Expression Evaluation via :func:`~pandas.eval`
 ----------------------------------------------
 
-New in pandas v0.13 a top-level function :func:`~pandas.eval` implements
-expression evaluation of expressions containing :class:`~pandas.Series` and
-:class:`~pandas.DataFrame` objects.
+.. versionadded:: 0.13
+
+The top-level function :func:`~pandas.eval` implements expression evaluation of
+:class:`~pandas.Series` and :class:`~pandas.DataFrame` objects.
 
 .. note::
 
@@ -307,11 +306,11 @@ expression evaluation of expressions containing :class:`~pandas.Series` and
    install ``numexpr``. See the :ref:`recommended dependencies section
    <install.recommended_dependencies>` for more details.
 
-The major benefit of using :func:`~pandas.eval` for expression evaluation
-rather than just straight-up Python is two-fold: large
-:class:`~pandas.DataFrame` objects are evaluated more efficiently and large
-expressions are evaluated all at once by the underlying engine (by default
-``numexpr`` is used for evaluation).
+The point of using :func:`~pandas.eval` for expression evaluation rather than
+plain Python is two-fold: 1) large :class:`~pandas.DataFrame` objects are
+evaluated more efficiently and 2) large arithmetic and boolean expressions are
+evaluated all at once by the underlying engine (by default ``numexpr`` is used
+for evaluation).
 
 .. note::
 
@@ -323,11 +322,8 @@ expressions are evaluated all at once by the underlying engine (by default
    :class:`~pandas.core.frame.DataFrame` with more than 10,000 rows.
 
 
-:func:`~pandas.eval` supports all arithmetic expressions
-supported by the engine. The ``numexpr`` engine uses ``numexpr`` under the hood
-to evaluate expressions efficiently, while allowing a slightly modified--and we
-think more intuitive--syntax for expressions.
-
+:func:`~pandas.eval` supports all arithmetic expressions supported by the
+engine in addition to some extensions available only in pandas.
 
 .. note::
 
@@ -338,8 +334,7 @@ think more intuitive--syntax for expressions.
 :func:`~pandas.eval` Examples
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-:func:`~pandas.eval` works wonders for expressions containing
-large arrays
+:func:`~pandas.eval` works wonders for expressions containing large arrays
 
 First let's create 4 decent-sized arrays to play with:
 
@@ -377,7 +372,7 @@ Now let's do the same thing but with comparisons:
    %timeit pd.eval('(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)')
 
 
-:func:`~pandas.eval` also works with "unaligned" pandas objects:
+:func:`~pandas.eval` also works with unaligned pandas objects:
 
 
 .. ipython:: python
@@ -389,13 +384,76 @@ Now let's do the same thing but with comparisons:
 
    %timeit pd.eval('df1 + df2 + df3 + df4 + s')
 
-There are also two different flavors of parsers and and two different engines
-to use as the backend.
+The ``DataFrame.eval`` method
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+In addition to the top level :func:`~pandas.eval` function you can also
+evaluate an expression in the "context" of a ``DataFrame``.
+
+
+.. ipython:: python
+
+   df = DataFrame(randn(10, 2), columns=['a', 'b'])
+   df.eval('a + b')
+
+
+Any expression that is a valid :func:`~pandas.eval` expression is also a valid
+``DataFrame.eval`` expression, with the added benefit that *you don't have to
+prefix the name of the* ``DataFrame`` *to the column you're interested in
+evaluating*.
+
+
+Local Variables
+~~~~~~~~~~~~~~~
+
+You can refer to local variables the same way you would in vanilla Python
+
+.. ipython:: python
+
+   df = DataFrame(randn(10, 2), columns=['a', 'b'])
+   newcol = randn(len(df))
+   df.eval('b + newcol')
+
+.. note::
+
+   The one exception is when you have a local (or global) with the same name as
+   a column in the ``DataFrame``
+
+    .. ipython:: python
+       :okexcept:
+
+       df = DataFrame(randn(10, 2), columns=['a', 'b'])
+       a = randn(len(df))
+       df.eval('a + b')
+
+   To deal with these conflicts, a special syntax exists for referring
+   variables with the same name as a column
+
+    .. ipython:: python
+
+       df.eval('@a + b')
+
+   The same is true for :meth:`~pandas.DataFrame.query` and
+   :meth:`~pandas.DataFrame.__getitem__` passed an expression
+
+    .. ipython:: python
+
+       df.query('@a < b')
+       df['@a < b']
+
+    .. ipython:: python
+       :suppress:
+
+       del a
+
 
 :func:`~pandas.eval` Parsers
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-The default ``"pandas"`` parser allows a more intuitive syntax for expressing
+There are two different parsers and and two different engines you can use as
+the backend.
+
+The default ``'pandas'`` parser allows a more intuitive syntax for expressing
 query-like operations (comparisons, conjunctions and disjunctions). In
 particular, the precedence of the ``&`` and ``|`` operators is made equal to
 the precedence of the corresponding boolean operations ``and`` and ``or``.
@@ -413,7 +471,8 @@ semantics.
    np.all(x == y)
 
 
-The same expression can be "anded" with the word :keyword:`and` as well:
+The same expression can be "anded" together with the word :keyword:`and` as
+well:
 
 .. ipython:: python
 
@@ -424,6 +483,10 @@ The same expression can be "anded" with the word :keyword:`and` as well:
    np.all(x == y)
 
 
+The ``and`` and ``or`` operators here have the same precedence that they would
+in vanilla Python.
+
+
 :func:`~pandas.eval` Backends
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -432,11 +495,9 @@ ol' Python.
 
 .. note::
 
-   Using the ``'python'`` engine is generally *not* useful, except for
-   comparing performance and testing other
-   :func:`~pandas.eval` engines against it. You will acheive
-   **no** performance benefits using :func:`~pandas.eval` with
-   ``engine='python'``.
+   Using the ``'python'`` engine is generally *not* useful, except for testing
+   other :func:`~pandas.eval` engines against it. You will acheive **no**
+   performance benefits using :func:`~pandas.eval` with ``engine='python'``.
 
 You can see this by using :func:`~pandas.eval` with the ``'python'`` engine is
 actually a bit slower (not by much) than evaluating the same expression in
@@ -449,3 +510,23 @@ Python:
 .. ipython:: python
 
    %timeit pd.eval('df1 + df2 + df3 + df4', engine='python')
+
+
+:func:`~pandas.eval` Performance
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+:func:`~pandas.eval` is intended to speed up certain kinds of operations. In
+particular, those operations involving complex expressions with large
+``DataFrame``/``Series`` objects should see a significant performance benefit.
+Here is a plot showing the running time of :func:`~pandas.eval` as function of
+the size of the frame involved in the computation. The two lines are two
+different engines.
+
+
+.. image:: _static/eval-perf.png
+
+
+Note that operations with smallish objects (around 15,000 rows) are faster
+using plain Python:
+
+.. image:: _static/eval-perf-intersect.png
diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index e5e6e84cc..9cf574247 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -1008,10 +1008,11 @@ convert to an integer index:
 
 .. _indexing.query:
 
-.. versionadded:: 0.13
-
 The :meth:`~pandas.DataFrame.query` Method
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. versionadded:: 0.13
+
 :class:`~pandas.DataFrame` objects have a :meth:`~pandas.DataFrame.query`
 method that allows selection using a string consisting of columns of the
 calling :class:`~pandas.DataFrame`.
@@ -1042,13 +1043,76 @@ with the name ``a``.
    df
    df.query('a < b and b < c')
 
-A use case for :meth:`~pandas.DataFrame.query` is when you have a collection of
-:class:`~pandas.DataFrame` s that have a subset of column names (or index
-names) in common. You can pass the same query to both frames *without* having
-to specify which frame you're interested in querying
+If instead you don't want to or cannot name your index, you can use the name
+``index`` in your query expression:
+
+.. ipython:: python
+   :suppress:
+
+   old_index = index
+   del index
+
+.. ipython:: python
+
+   df = DataFrame(randint(n, size=(n, 2)), columns=list('bc'))
+   df
+   df.query('index < b < c')
+
+.. ipython:: python
+   :suppress:
+
+   index = old_index
+   del old_index
+
+
+:class:`~pandas.MultiIndex` :meth:`~pandas.DataFrame.query` Syntax
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+You can also use the levels of a ``DataFrame`` with a
+:class:`~pandas.MultiIndex` as if they were columns in the frame:
+
+.. ipython:: python
+
+   import pandas.util.testing as tm
+
+   colors = tm.choice(['red', 'green'], size=10)
+   foods = tm.choice(['eggs', 'ham'], size=10)
+   colors
+   foods
+
+   index = MultiIndex.from_arrays([colors, foods], names=['color', 'food'])
+   df = DataFrame(randn(10, 2), index=index)
+   df
+   df.query('color == "red"')
+
+If the levels of the ``MultiIndex`` are unnamed, you can refer to them using
+special names:
+
 
 .. ipython:: python
 
+   index.names = [None, None]
+   df = DataFrame(randn(10, 2), index=index)
+   df
+   df.query('ilevel_0 == "red"')
+
+
+The convention is ``ilevel_0``, which means "index level 0" for the 0th level
+of the ``index``.
+
+
+:meth:`~pandas.DataFrame.query` Use Cases
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+One use case for :meth:`~pandas.DataFrame.query` is when you have a collection of
+:class:`~pandas.DataFrame` objects that have a subset of column names (or index
+levels/names) in common. You can pass the same query to both frames *without*
+having to specify which frame you're interested in querying
+
+.. ipython:: python
+
+   df = DataFrame(randint(n, size=(n, 2)), columns=list('bc'))
+   df.index.name = 'a'
    df2 = DataFrame(randint(n + 10, size=(n + 10, 3)), columns=list('abc'))
    df2
    expr = 'a < b & b < c'
@@ -1069,11 +1133,18 @@ This functionality can of course be combined with a slightly modified and more
 readable Python syntax implemented in the workhorse function that underlies
 :meth:`~pandas.DataFrame.query`--:func:`~pandas.eval`.
 
+
+:meth:`~pandas.DataFrame.query` Python versus pandas Syntax Comparison
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
 Full numpy-like syntax
 
 .. ipython:: python
 
+   df = DataFrame(randint(n, size=(n, 3)), columns=list('abc'))
+   df
    df['(a < b) & (b < c)']
+   df[(df.a < df.b) & (df.b < df.c)]
 
 Slightly nicer by removing the parentheses
 
@@ -1097,8 +1168,94 @@ As you can see, these are all equivalent ways to express the same operation (in
 fact, they are all ultimately parsed into something very similar to the first
 example of the indexing syntax above).
 
-You can also negate boolean expressions with the word ``not`` or the ``~``
-operator.
+The ``in`` and ``not in`` operators
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+:meth:`~pandas.DataFrame.query` also supports special use of Python's ``in`` and
+``not in`` comparison operators, providing a succint syntax for calling the
+``isin`` method of a ``Series`` or ``DataFrame``.
+
+.. ipython:: python
+   :suppress:
+
+   old_d = d
+   del d
+
+.. ipython:: python
+
+   # get all rows where columns "a" and "b" have overlapping values
+   df = DataFrame({'a': list('aaaabbbbcccc'), 'b': list('aabbccddeeff'),
+                   'c': randint(5, size=12), 'd': randint(9, size=12)})
+   df
+   df['a in b']
+
+   # How you'd do it in pure Python
+   df[df.b.isin(df.a)]
+
+   df['a not in b']
+
+   # pure Python
+   df[~df.b.isin(df.a)]
+
+
+You can, of course, combine this with other expressions for very succinct
+queries:
+
+
+.. ipython:: python
+
+   # rows where cols a and b have overlapping values and col c's values are less than col d's
+   df['a in b and c < d']
+
+   # pure Python
+   df[df.b.isin(df.a) & (df.c < df.d)]
+
+
+.. note::
+
+   Note that ``in`` and ``not in`` are evaluated in Python, since ``numexpr``
+   has no equivalent of this operation. However, **only the** ``in``/``not in``
+   **expression itself** is evaluated in vanilla Python. For example, in the
+   expression
+
+       .. code-block:: python
+
+          df['a in b + c + d']
+
+   ``(b + c + d)`` is evaluated by ``numexpr`` and *then* the ``in``
+   operation is evaluated in plain Python. In general, any operations that can
+   be evaluated using ``numexpr`` will be.
+
+Special use of the ``==`` operator with ``list`` objects
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Comparing a ``list`` of values to a column using ``==``/``!=`` works similarly
+to ``in``/``not in``
+
+.. ipython:: python
+
+   df['b == ["a", "b", "c"]']
+
+   # pure Python
+   df[df.b.isin(["a", "b", "c"])]
+
+   df['c == [1, 2]']
+
+   df['c != [1, 2]']
+
+   # using in/not in
+   df['[1, 2] in c']
+
+   df['[1, 2] not in c']
+
+   # pure Python
+   df[df.c.isin([1, 2])]
+
+
+Boolean Operators
+~~~~~~~~~~~~~~~~~
+
+You can negate boolean expressions with the word ``not`` or the ``~`` operator.
 
 .. ipython:: python
 
@@ -1113,26 +1270,38 @@ Of course, expressions can be arbitrarily complex too
 
 .. ipython:: python
 
-   # nice short query syntax
-   pretty = df['a < b < c and (not bools) or bools > 2']
+   # short query syntax
+   shorter = df['a < b < c and (not bools) or bools > 2']
 
-   # equivalent in pure Python, yuck!
-   yuck = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
+   # equivalent in pure Python
+   longer = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
 
-   pretty
-   yuck
+   shorter
+   longer
+
+   shorter == longer
+
+.. ipython:: python
+   :suppress:
+
+   d = old_d
+   del old_d
 
-   yuck == pretty
 
 .. _indexing.class:
 
 Index objects
 -------------
 
-The pandas Index class and its subclasses can be viewed as implementing an
-*ordered set* in addition to providing the support infrastructure necessary for
-lookups, data alignment, and reindexing. The easiest way to create one directly
-is to pass a list or other sequence to ``Index``:
+The pandas :class:`~pandas.Index` class and its subclasses can be viewed as
+implementing an *ordered multiset*. Duplicates are allowed. However, if you try
+to convert an :class:`~pandas.Index` object with duplicate entries into a
+``set``, an exception will be raised.
+
+:class:`~pandas.Index` also provides the infrastructure necessary for
+lookups, data alignment, and reindexing. The easiest way to create an
+:class:`~pandas.Index` directly is to pass a ``list`` or other sequence to
+:class:`~pandas.Index`:
 
 .. ipython:: python
 
diff --git a/doc/source/io.rst b/doc/source/io.rst
index 19fcbd6f4..7ebfe753e 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -2032,7 +2032,26 @@ The right-hand side of the sub-expression (after a comparsion operator) can be:
    - lists, e.g. ``"['A','B']"``
    - variables that are defined in the local names space, e.g. ``date``
 
-Here is an example:
+Here are some examples:
+
+.. ipython:: python
+
+    dfq = DataFrame(randn(10,4),columns=list('ABCD'),index=date_range('20130101',periods=10))
+    store.append('dfq',dfq,format='table',data_columns=True)
+
+Use boolean expressions, with in-line function evaluation.
+
+.. ipython:: python
+
+    store.select('dfq',"index>Timestamp('20130104') & columns=['A', 'B']")
+
+Use and inline column reference
+
+.. ipython:: python
+
+   store.select('dfq',where="A>0 or C>0")
+
+Works with a Panel as well.
 
 .. ipython:: python
 
@@ -2060,6 +2079,15 @@ space. These are in terms of the total number of rows in a table.
    store.select('wp',"major_axis>20000102 & minor_axis=['A','B']",
                 start=0, stop=10)
 
+.. note::
+
+   ``select`` will raise a ``ValueError`` if the query expression has an unknown
+   variable reference. Usually this means that you are trying to select on a column
+   that is **not** a data_column.
+
+   ``select`` will raise a ``SyntaxError`` if the query expression is not valid.
+
+
 .. _io.hdf5-timedelta:
 
 **Using timedelta64[ns]**
diff --git a/doc/source/v0.10.0.txt b/doc/source/v0.10.0.txt
index 476760e4b..0c86add12 100644
--- a/doc/source/v0.10.0.txt
+++ b/doc/source/v0.10.0.txt
@@ -258,10 +258,11 @@ Updated PyTables Support
    store.append('wp',wp)
 
    # selecting via A QUERY
-   store.select('wp', "major_axis>20000102 & minor_axis=['A','B']")
+   store.select('wp',
+     [ Term('major_axis>20000102'), Term('minor_axis', '=', ['A','B']) ])
 
    # removing data from tables
-   store.remove('wp', 'major_axis>wp.major_axis[3]')
+   store.remove('wp', Term('major_axis>20000103'))
    store.select('wp')
 
    # deleting a store
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index c56af23e8..4f43cd5e0 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -187,6 +187,96 @@ Indexing API Changes
        p
        p.loc[:,:,'C']
 
+HDFStore API Changes
+~~~~~~~~~~~~~~~~~~~~
+
+  - Query Format Changes. A much more string-like query format is now supported.
+
+    .. ipython:: python
+
+       path = 'test_query.h5'
+       dfq = DataFrame(randn(10,4),columns=list('ABCD'),index=date_range('20130101',periods=10))
+       dfq.to_hdf(path,'dfq',format='table',data_columns=True)
+
+    Use boolean expressions, with in-line function evaluation.
+
+    .. ipython:: python
+
+       read_hdf(path,'dfq',where="index>Timestamp('20130104') & columns=['A', 'B']")
+
+    Use an inline column reference
+
+    .. ipython:: python
+
+       read_hdf(path,'dfq',where="A>0 or C>0")
+
+    See :ref:`the docs<io.hdf5-query>`.
+
+  - Significant table writing performance improvements
+  - handle a passed ``Series`` in table format (:issue:`4330`)
+  - added an ``is_open`` property to indicate if the underlying file handle is_open;
+    a closed store will now report 'CLOSED' when viewing the store (rather than raising an error)
+    (:issue:`4409`)
+  - a close of a ``HDFStore`` now will close that instance of the ``HDFStore``
+    but will only close the actual file if the ref count (by ``PyTables``) w.r.t. all of the open handles
+    are 0. Essentially you have a local instance of ``HDFStore`` referenced by a variable. Once you
+    close it, it will report closed. Other references (to the same file) will continue to operate
+    until they themselves are closed. Performing an action on a closed file will raise
+    ``ClosedFileError``
+
+    .. ipython:: python
+
+       path = 'test.h5'
+       df = DataFrame(randn(10,2))
+       store1 = HDFStore(path)
+       store2 = HDFStore(path)
+       store1.append('df',df)
+       store2.append('df2',df)
+
+       store1
+       store2
+       store1.close()
+       store2
+       store2.close()
+       store2
+
+    .. ipython:: python
+       :suppress:
+
+       import os
+       os.remove(path)
+
+  - removed the ``_quiet`` attribute, replace by a ``DuplicateWarning`` if retrieving
+    duplicate rows from a table (:issue:`4367`)
+  - removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will
+    be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)
+  - allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).
+    See :ref:`here<io.hdf5-where_mask>` for an example.
+
+  - the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``
+    the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies 'fixed` or 'f' (Fixed) format
+    and ``append`` imples 'table' or 't' (Table) format
+
+    .. ipython:: python
+
+       path = 'test.h5'
+       df = DataFrame(randn(10,2))
+       df.to_hdf(path,'df_table',format='table')
+       df.to_hdf(path,'df_table2',append=True)
+       df.to_hdf(path,'df_fixed')
+       with get_store(path) as store:
+          print store
+
+    .. ipython:: python
+       :suppress:
+
+       import os
+       os.remove('test.h5')
+       os.remove('test_query.h5')
+  - add the keyword ``dropna=True`` to ``append`` to change whether ALL nan rows are not written
+    to the store (default is ``True``, ALL nan rows are NOT written), also settable
+    via the option ``io.hdf.dropna_table`` (:issue:`4625`)
+
 Enhancements
 ~~~~~~~~~~~~
 
@@ -271,6 +361,90 @@ Enhancements
     is evaluated, respecttively. See scipy docs.
   - DataFrame constructor now accepts a numpy masked record array (:issue:`3478`)
 
+
+.. _whatsnew_0130.enhancingperf:
+
+Performance Enhancments
+~~~~~~~~~~~~~~~~~~~~~~~
+
+- :func:`~pandas.eval`:
+
+  - The new :func:`~pandas.eval` function implements expression evaluation using
+    ``numexpr`` behind the scenes. This results in large speedups for
+    complicated expressions involving large DataFrames/Series. For example,
+
+      .. ipython:: python
+
+         nrows, ncols = 20000, 100
+         df1, df2, df3, df4 = [DataFrame(randn(nrows, ncols))
+                               for _ in xrange(4)]
+
+      .. ipython:: python
+
+         %timeit pd.eval('df1 + df2 + df3 + df4')
+
+    For more details, see the :ref:`enhancing performance documentation on eval
+    <enhancingperf.eval>`
+
+- :meth:`~pandas.DataFrame.eval`
+
+  - Similar to :func:`~pandas.eval`, :class:`~pandas.DataFrame` has a new
+    :meth:`~pandas.DataFrame.eval` that evaluates an expression in the context
+    of the ``DataFrame``. For example,
+
+      .. ipython:: python
+         :suppress:
+
+         try:
+            del a
+         except NameError:
+            pass
+
+         try:
+            del b
+         except NameError:
+            pass
+
+      .. ipython:: python
+
+         df = DataFrame(randn(10, 2), columns=['a', 'b'])
+         df.eval('a + b')
+
+
+- :meth:`~pandas.DataFrame.query`
+
+  - In 0.13 a :meth:`~pandas.DataFrame.query` method has been added that allows
+    you to select elements of a ``DataFrame`` using a natural query syntax
+    nearly identical to Python syntax. For example,
+
+      .. ipython:: python
+         :suppress:
+
+         try:
+            del a
+         except NameError:
+            pass
+
+         try:
+            del b
+         except NameError:
+            pass
+
+         try:
+            del c
+         except NameError:
+            pass
+
+      .. ipython:: python
+
+         n = 20
+         df = DataFrame(randint(n, size=(n, 3)), columns=['a', 'b', 'c'])
+         df['a < b < c']
+
+    selects all the rows of ``df`` where ``a < b < c`` evaluates to ``True``.
+    For more details see the :ref:`indexing documentation on query
+    <indexing.query>`.
+
 .. _whatsnew_0130.refactoring:
 
 Internal Refactoring
diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index ec51887ff..60975bdc8 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -1,3 +1,6 @@
+"""Core eval alignment algorithms
+"""
+
 import warnings
 from functools import partial, wraps
 from pandas.compat import zip, range
@@ -7,7 +10,6 @@ import numpy as np
 import pandas as pd
 from pandas import compat
 import pandas.core.common as com
-from pandas.computation.ops import is_const
 
 
 def _align_core_single_unary_op(term):
@@ -129,11 +131,12 @@ def _align_core(terms):
                 term_axis_size = len(ti.axes[axis])
                 reindexer_size = len(reindexer)
 
-                if (np.log10(abs(reindexer_size - term_axis_size)) >= 1 and
-                    reindexer_size >= 10000):
+                ordm = np.log10(abs(reindexer_size - term_axis_size))
+                if ordm >= 1 and reindexer_size >= 10000:
                     warnings.warn("Alignment difference on axis {0} is larger"
                                   " than an order of magnitude on term {1!r}, "
-                                  "performance may suffer".format(axis, term),
+                                  "by more than {2:.4g}; performance may suffer"
+                                  "".format(axis, term.name, ordm),
                                   category=pd.io.common.PerformanceWarning)
 
                 if transpose:
@@ -164,7 +167,7 @@ def _align_core(terms):
 
 def _filter_terms(flat):
     # numeric literals
-    literals = frozenset(filter(is_const, flat))
+    literals = frozenset(filter(lambda x: isinstance(x, Constant), flat))
 
     # these are strings which are variable names
     names = frozenset(flat) - literals
@@ -213,7 +216,7 @@ def _reconstruct_object(typ, obj, axes, dtype):
 
     Returns
     -------
-    reconst : typ
+    ret : typ
         An object of type ``typ`` with the value `obj` and possible axes
         `axes`.
     """
@@ -231,7 +234,11 @@ def _reconstruct_object(typ, obj, axes, dtype):
         issubclass(typ, pd.core.generic.PandasObject)):
         return typ(obj, dtype=res_t, **axes)
 
-    ret_value = typ(obj).astype(res_t)
+    # special case for pathological things like ~True/~False
+    if hasattr(res_t, 'type') and typ == np.bool_ and res_t != np.bool_:
+        ret_value = res_t.type(obj)
+    else:
+        ret_value = typ(obj).astype(res_t)
 
     try:
         ret = ret_value.item()
diff --git a/pandas/computation/common.py b/pandas/computation/common.py
index 325303905..9af2197a4 100644
--- a/pandas/computation/common.py
+++ b/pandas/computation/common.py
@@ -1,10 +1,11 @@
 import numpy as np
+import pandas as pd
 
 
 def _ensure_decoded(s):
     """ if we have bytes, decode them to unicode """
     if isinstance(s, (np.bytes_, bytes)):
-        s = s.decode('UTF-8')
+        s = s.decode(pd.get_option('display.encoding'))
     return s
 
 
diff --git a/pandas/computation/engines.py b/pandas/computation/engines.py
index 794b80615..88efc9eea 100644
--- a/pandas/computation/engines.py
+++ b/pandas/computation/engines.py
@@ -1,3 +1,6 @@
+"""Engine classes for :func:`~pandas.eval`
+"""
+
 import abc
 
 from pandas import compat
@@ -5,8 +8,10 @@ from pandas.core import common as com
 from pandas.computation.align import _align, _reconstruct_object
 from pandas.computation.ops import UndefinedVariableError
 
+
 class AbstractEngine(object):
-    """AbstractEngine object serving as a base class for all engines."""
+    """Object serving as a base class for all engines."""
+
     __metaclass__ = abc.ABCMeta
 
     has_neg_frac = False
@@ -62,7 +67,7 @@ class AbstractEngine(object):
 
         Notes
         -----
-        This method must be implemented by any class the subclasses this class.
+        Must be implemented by subclasses.
         """
         pass
 
@@ -74,13 +79,16 @@ class NumExprEngine(AbstractEngine):
     def __init__(self, expr):
         super(NumExprEngine, self).__init__(expr)
 
+    def convert(self):
+        return str(super(NumExprEngine, self).convert())
+
     def _evaluate(self):
         import numexpr as ne
 
         # add the resolvers to locals
         self.expr.add_resolvers_to_locals()
 
-        # convert the expression to syntactically valid Python
+        # convert the expression to a valid numexpr expression
         s = self.convert()
 
         try:
diff --git a/pandas/computation/eval.py b/pandas/computation/eval.py
index ff0738893..36b1e2bc9 100644
--- a/pandas/computation/eval.py
+++ b/pandas/computation/eval.py
@@ -1,18 +1,38 @@
 #!/usr/bin/env python
 
+"""Top level ``eval`` module.
+"""
+
 import numbers
 import numpy as np
 
+from pandas.core import common as com
 from pandas.compat import string_types
 from pandas.computation.expr import Expr, _parsers, _ensure_scope
 from pandas.computation.engines import _engines
 
 
 def _check_engine(engine):
-    """make sure a valid engine is passed"""
+    """Make sure a valid engine is passed.
+
+    Parameters
+    ----------
+    engine : str
+
+    Raises
+    ------
+    KeyError
+      * If an invalid engine is passed
+    ImportError
+      * If numexpr was requested but doesn't exist
+    """
     if engine not in _engines:
         raise KeyError('Invalid engine {0!r} passed, valid engines are'
-                       ' {1}'.format(engine, _engines.keys()))
+                       ' {1}'.format(engine, list(_engines.keys())))
+
+    # TODO: validate this in a more general way (thinking of future engines
+    # that won't necessarily be import-able)
+    # Could potentially be done on engine instantiation
     if engine == 'numexpr':
         try:
             import numexpr
@@ -22,12 +42,76 @@ def _check_engine(engine):
 
 
 def _check_parser(parser):
-    """make sure a valid parser is passed"""
+    """Make sure a valid parser is passed.
+
+    Parameters
+    ----------
+    parser : str
+
+    Raises
+    ------
+    KeyError
+      * If an invalid parser is passed
+    """
     if parser not in _parsers:
         raise KeyError('Invalid parser {0!r} passed, valid parsers are'
                        ' {1}'.format(parser, _parsers.keys()))
 
 
+def _check_resolvers(resolvers):
+    if resolvers is not None:
+        for resolver in resolvers:
+            if not hasattr(resolver, '__getitem__'):
+                name = type(resolver).__name__
+                raise AttributeError('Resolver of type {0!r} must implement '
+                                     'the __getitem__ method'.format(name))
+
+
+def _check_expression(expr):
+    """Make sure an expression is not an empty string
+
+    Parameters
+    ----------
+    expr : object
+        An object that can be converted to a string
+
+    Raises
+    ------
+    ValueError
+      * If expr is an empty string
+    """
+    if not expr:
+        raise ValueError("expr cannot be an empty string")
+
+
+def _convert_expression(expr):
+    """Convert an object to an expression.
+
+    Thus function converts an object to an expression (a unicode string) and
+    checks to make sure it isn't empty after conversion. This is used to
+    convert operators to their string representation for recursive calls to
+    :func:`~pandas.eval`.
+
+    Parameters
+    ----------
+    expr : object
+        The object to be converted to a string.
+
+    Returns
+    -------
+    s : unicode
+        The string representation of an object.
+
+    Raises
+    ------
+    ValueError
+      * If the expression is empty.
+    """
+    s = com.pprint_thing(expr)
+    _check_expression(s)
+    return s
+
+
 def eval(expr, parser='pandas', engine='numexpr', truediv=True,
          local_dict=None, global_dict=None, resolvers=None, level=2):
     """Evaluate a Python expression as a string using various backends.
@@ -43,13 +127,19 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
 
     Parameters
     ----------
-    expr : string
-        The expression to evaluate.
+    expr : str or unicode
+        The expression to evaluate. This string cannot contain any Python
+        `statements
+        <http://docs.python.org/2/reference/simple_stmts.html#simple-statements>`__,
+        only Python `expressions
+        <http://docs.python.org/2/reference/simple_stmts.html#expression-statements>`__.
     parser : string, default 'pandas', {'pandas', 'python'}
         The parser to use to construct the syntax tree from the expression. The
-        default of 'pandas' parses code slightly different than standard
-        Python. See the :ref:`enhancing performance <enhancingperf.eval>`
-        documentation for more details.
+        default of ``'pandas'`` parses code slightly different than standard
+        Python. Alternatively, you can parse an expression using the
+        ``'python'`` parser to retain strict Python semantics.  See the
+        :ref:`enhancing performance <enhancingperf.eval>` documentation for
+        more details.
     engine : string, default 'numexpr', {'python', 'numexpr'}
 
         The engine used to evaluate the expression. Supported engines are
@@ -60,27 +150,29 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
         - ``'python'``: Performs operations as if you had ``eval``'d in top
                         level python. This engine is generally not that useful.
 
-    truediv : bool, default True
+        More backends may be available in the future.
+
+    truediv : bool, optional
         Whether to use true division, like in Python >= 3
-    local_dict : dict or None, default None
+    local_dict : dict or None, optional
         A dictionary of local variables, taken from locals() by default.
-    global_dict : dict or None, default None
+    global_dict : dict or None, optional
         A dictionary of global variables, taken from globals() by default.
-    resolvers : dict of dict-like or None, default None
-        A dictionary of dict-like object (specifically they must implement the
-        ``get`` method) that you can use to inject an additional collection of
-        namespaces to use for variable lookup. This is used in the
+    resolvers : list of dict-like or None, optional
+        A list of objects implementing the ``__getitem__`` special method that
+        you can use to inject an additional collection of namespaces to use for
+        variable lookup. For example, this is used in the
         :meth:`~pandas.DataFrame.query` method to inject the
         :attr:`~pandas.DataFrame.index` and :attr:`~pandas.DataFrame.columns`
         variables that refer to their respective :class:`~pandas.DataFrame`
         instance attributes.
-    level : int, default 2
+    level : int, optional
         The number of prior stack frames to traverse and add to the current
-        scope.
+        scope. Most users will **not** need to change this parameter.
 
     Returns
     -------
-    ret : ndarray, numeric scalar, :class:`~pandas.DataFrame`, :class:`~pandas.Series`
+    ndarray, numeric scalar, DataFrame, Series
 
     Notes
     -----
@@ -93,30 +185,22 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
     See Also
     --------
     pandas.DataFrame.query
+    pandas.DataFrame.eval
     """
-    # make sure we're passed a valid engine and parser
+    expr = _convert_expression(expr)
     _check_engine(engine)
     _check_parser(parser)
+    _check_resolvers(resolvers)
 
+    # get our (possibly passed-in) scope
     env = _ensure_scope(global_dict=global_dict, local_dict=local_dict,
                         resolvers=resolvers, level=level)
 
-    if isinstance(expr, string_types):
-        parsed_expr = Expr(expr, engine=engine, parser=parser, env=env,
-                           truediv=truediv)
-    else:
-        raise TypeError("eval only accepts strings, you passed an object of "
-                        "type {0!r}".format(expr.__class__.__name__))
+    parsed_expr = Expr(expr, engine=engine, parser=parser, env=env,
+                       truediv=truediv)
 
-    # construct the engine and evaluate
+    # construct the engine and evaluate the parsed expression
     eng = _engines[engine]
     eng_inst = eng(parsed_expr)
     ret = eng_inst.evaluate()
-
-    # sanity check for a number if it's a scalar result
-    # TODO: eventually take out
-    if np.isscalar(ret):
-        if not isinstance(ret, (np.number, np.bool_, numbers.Number)):
-            raise TypeError('scalar result must be numeric or bool, return'
-                            ' type is {0!r}'.format(ret.__class__.__name__))
     return ret
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index 1fbc0b722..d8969e129 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -1,9 +1,13 @@
+""":func:`~pandas.eval` parsers
+"""
+
 import ast
 import operator
 import sys
 import inspect
 import tokenize
 import datetime
+import struct
 
 from functools import partial
 
@@ -16,16 +20,20 @@ from pandas.computation.common import NameResolutionError
 from pandas.computation.ops import (_cmp_ops_syms, _bool_ops_syms,
                                     _arith_ops_syms, _unary_ops_syms, is_term)
 from pandas.computation.ops import _reductions, _mathops, _LOCAL_TAG
-from pandas.computation.ops import BinOp, UnaryOp, Term, Constant, Div
+from pandas.computation.ops import Op, BinOp, UnaryOp, Term, Constant, Div
 
 
 def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
                   **kwargs):
-    """ ensure that we are grabbing the correct scope """
-    return Scope(global_dict, local_dict, level=level, resolvers=resolvers)
+    """Ensure that we are grabbing the correct scope."""
+    return Scope(gbls=global_dict, lcls=local_dict, level=level,
+                 resolvers=resolvers)
 
 
 def _check_disjoint_resolver_names(resolver_keys, local_keys, global_keys):
+    """Make sure that variables in resolvers don't overlap with locals or
+    globals.
+    """
     res_locals = list(com.intersection(resolver_keys, local_keys))
     if res_locals:
         msg = "resolvers and locals overlap on names {0}".format(res_locals)
@@ -37,6 +45,29 @@ def _check_disjoint_resolver_names(resolver_keys, local_keys, global_keys):
         raise NameResolutionError(msg)
 
 
+def _replacer(x, pad_size):
+    """Replace a number with its padded hexadecimal representation. Used to tag
+    temporary variables with their calling scope's id.
+    """
+    # get the hex repr of the binary char and remove 0x and pad by pad_size
+    # zeros
+    try:
+        hexin = ord(x)
+    except TypeError:
+        # bytes literals masquerade as ints when iterating in py3
+        hexin = x
+
+    return hex(hexin).replace('0x', '').rjust(pad_size, '0')
+
+
+def _raw_hex_id(obj, pad_size=2):
+    """Return the padded hexadecimal id of ``obj``."""
+    # interpret as a pointer since that's what really what id returns
+    packed = struct.pack('@P', id(obj))
+
+    return ''.join(_replacer(x, pad_size) for x in packed)
+
+
 class Scope(StringMixin):
     """Object to hold scope, with a few bells to deal with some custom syntax
     added by pandas.
@@ -57,14 +88,14 @@ class Scope(StringMixin):
     resolver_keys : frozenset
     """
     __slots__ = ('globals', 'locals', 'resolvers', '_global_resolvers',
-                 'resolver_keys', '_resolver', 'level')
+                 'resolver_keys', '_resolver', 'level', 'ntemps')
 
     def __init__(self, gbls=None, lcls=None, level=1, resolvers=None):
         self.level = level
         self.resolvers = tuple(resolvers or [])
         self.globals = dict()
         self.locals = dict()
-        self.ntemps = 0  # number of temporary variables in this scope
+        self.ntemps = 1  # number of temporary variables in this scope
 
         if isinstance(lcls, Scope):
             ld, lcls = lcls, dict()
@@ -88,21 +119,20 @@ class Scope(StringMixin):
         self.globals['True'] = True
         self.globals['False'] = False
 
-
-        self.resolver_keys = frozenset(reduce(operator.add, (list(o.keys()) for
-                                                             o in
-                                                             self.resolvers),
-                                              []))
+        res_keys = (list(o.keys()) for o in self.resolvers)
+        self.resolver_keys = frozenset(reduce(operator.add, res_keys, []))
         self._global_resolvers = self.resolvers + (self.locals, self.globals)
         self._resolver = None
-        self.resolver_dict = dict((k, self.resolve(k))
-                                  for k in self.resolver_keys)
+
+        self.resolver_dict = {}
+        for o in self.resolvers:
+            self.resolver_dict.update(dict(o))
 
     def __unicode__(self):
         return com.pprint_thing("locals: {0}\nglobals: {0}\nresolvers: "
-                                "{0}".format(self.locals.keys(),
-                                             self.globals.keys(),
-                                             self.resolver_keys))
+                                "{0}".format(list(self.locals.keys()),
+                                             list(self.globals.keys()),
+                                             list(self.resolver_keys)))
 
     def __getitem__(self, key):
         return self.resolve(key, globally=False)
@@ -171,18 +201,32 @@ class Scope(StringMixin):
         if not isinstance(d, dict):
             raise TypeError("Cannot add value to object of type {0!r}, "
                             "scope must be a dictionary"
-                            "".format(d.__class__.__name__))
-        name = 'tmp_var_{0}_{1}_{2}'.format(value.__class__.__name__,
-                                            self.ntemps,
-                                            pd.util.testing.rands(10))
+                            "".format(type(d).__name__))
+        name = 'tmp_var_{0}_{1}_{2}'.format(type(value).__name__, self.ntemps,
+                                            _raw_hex_id(self))
         d[name] = value
 
         # only increment if the variable gets put in the scope
         self.ntemps += 1
         return name
 
+    def remove_tmp(self, name, where='locals'):
+        d = getattr(self, where, None)
+        if d is None:
+            raise AttributeError("Cannot remove value from non-existent scope "
+                                 "{0!r}".format(where))
+        if not isinstance(d, dict):
+            raise TypeError("Cannot remove value from object of type {0!r}, "
+                            "scope must be a dictionary"
+                            "".format(type(d).__name__))
+        del d[name]
+        self.ntemps -= 1
+
 
 def _rewrite_assign(source):
+    """Rewrite the assignment operator for PyTables expression that want to use
+    ``=`` as a substitute for ``==``.
+    """
     res = []
     g = tokenize.generate_tokens(StringIO(source).readline)
     for toknum, tokval, _, _, _ in g:
@@ -191,17 +235,30 @@ def _rewrite_assign(source):
 
 
 def _replace_booleans(source):
+    """Replace ``&`` with ``and`` and ``|`` with ``or`` so that bitwise
+    precedence is changed to boolean precedence.
+    """
     return source.replace('|', ' or ').replace('&', ' and ')
 
 
 def _replace_locals(source, local_symbol='@'):
+    """Replace local variables with a syntacticall valid name."""
     return source.replace(local_symbol, _LOCAL_TAG)
 
 
 def _preparse(source):
+    """Compose assignment and boolean replacement."""
     return _replace_booleans(_rewrite_assign(source))
 
 
+def _is_type(t):
+    """Factory for a type checking function of type ``t`` or tuple of types."""
+    return lambda x: isinstance(x.value, t)
+
+
+_is_list = _is_type(list)
+_is_str = _is_type(string_types)
+
 
 # partition all AST nodes
 _all_nodes = frozenset(filter(lambda x: isinstance(x, type) and
@@ -210,6 +267,7 @@ _all_nodes = frozenset(filter(lambda x: isinstance(x, type) and
 
 
 def _filter_nodes(superclass, all_nodes=_all_nodes):
+    """Filter out AST nodes that are subclasses of ``superclass``."""
     node_names = (node.__name__ for node in all_nodes
                   if issubclass(node, superclass))
     return frozenset(node_names)
@@ -238,8 +296,7 @@ _hacked_nodes = frozenset(['Assign', 'Module', 'Expr'])
 
 _unsupported_expr_nodes = frozenset(['Yield', 'GeneratorExp', 'IfExp',
                                      'DictComp', 'SetComp', 'Repr', 'Lambda',
-                                     'Set', 'In', 'NotIn', 'AST', 'Is',
-                                     'IsNot'])
+                                     'Set', 'AST', 'Is', 'IsNot'])
 
 # these nodes are low priority or won't ever be supported (e.g., AST)
 _unsupported_nodes = ((_stmt_nodes | _mod_nodes | _handler_nodes |
@@ -257,6 +314,9 @@ assert not _unsupported_nodes & _base_supported_nodes, _msg
 
 
 def _node_not_implemented(node_name, cls):
+    """Return a function that raises a NotImplementedError with a passed node
+    name.
+    """
     def f(self, *args, **kwargs):
         raise NotImplementedError("{0!r} nodes are not "
                                   "implemented".format(node_name))
@@ -264,10 +324,17 @@ def _node_not_implemented(node_name, cls):
 
 
 def disallow(nodes):
+    """Decorator to disallow certain nodes from parsing. Raises a
+    NotImplementedError instead.
+
+    Returns
+    -------
+    disallowed : callable
+    """
     def disallowed(cls):
         cls.unsupported_nodes = ()
         for node in nodes:
-            new_method =  _node_not_implemented(node, cls)
+            new_method = _node_not_implemented(node, cls)
             name = 'visit_{0}'.format(node)
             cls.unsupported_nodes += (name,)
             setattr(cls, name, new_method)
@@ -276,14 +343,29 @@ def disallow(nodes):
 
 
 def _op_maker(op_class, op_symbol):
+    """Return a function to create an op class with its symbol already passed.
+
+    Returns
+    -------
+    f : callable
+    """
     def f(self, node, *args, **kwargs):
+        """Return a partial function with an Op subclass with an operator
+        already passed.
+
+        Returns
+        -------
+        f : callable
+        """
         return partial(op_class, op_symbol, *args, **kwargs)
     return f
 
 
 _op_classes = {'binary': BinOp, 'unary': UnaryOp}
 
+
 def add_ops(op_classes):
+    """Decorator to add default implementation of ops."""
     def f(cls):
         for op_attr_name, op_class in compat.iteritems(op_classes):
             ops = getattr(cls, '{0}_ops'.format(op_attr_name))
@@ -291,8 +373,8 @@ def add_ops(op_classes):
             for op in ops:
                 op_node = ops_map[op]
                 if op_node is not None:
-                    setattr(cls, 'visit_{0}'.format(op_node),
-                            _op_maker(op_class, op))
+                    made_op = _op_maker(op_class, op)
+                    setattr(cls, 'visit_{0}'.format(op_node), made_op)
         return cls
     return f
 
@@ -300,21 +382,36 @@ def add_ops(op_classes):
 @disallow(_unsupported_nodes)
 @add_ops(_op_classes)
 class BaseExprVisitor(ast.NodeVisitor):
+    """Custom ast walker. Parsers of other engines should subclass this class
+    if necessary.
+
+    Parameters
+    ----------
+    env : Scope
+    engine : str
+    parser : str
+    preparser : callable
+    """
     const_type = Constant
     term_type = Term
 
-    """Custom ast walker
-    """
     binary_ops = _cmp_ops_syms + _bool_ops_syms + _arith_ops_syms
-    binary_op_nodes = ('Gt', 'Lt', 'GtE', 'LtE', 'Eq', 'NotEq', 'BitAnd',
-                       'BitOr', 'And', 'Or', 'Add', 'Sub', 'Mult', None,
-                       'Pow', 'FloorDiv', 'Mod')
+    binary_op_nodes = ('Gt', 'Lt', 'GtE', 'LtE', 'Eq', 'NotEq', 'In', 'NotIn',
+                       'BitAnd', 'BitOr', 'And', 'Or', 'Add', 'Sub', 'Mult',
+                       None, 'Pow', 'FloorDiv', 'Mod')
     binary_op_nodes_map = dict(zip(binary_ops, binary_op_nodes))
 
     unary_ops = _unary_ops_syms
     unary_op_nodes = 'UAdd', 'USub', 'Invert', 'Not'
     unary_op_nodes_map = dict(zip(unary_ops, unary_op_nodes))
 
+    rewrite_map = {
+        ast.Eq: ast.In,
+        ast.NotEq: ast.NotIn,
+        ast.In: ast.In,
+        ast.NotIn: ast.NotIn
+    }
+
     def __init__(self, env, engine, parser, preparser=_preparse):
         self.env = env
         self.engine = engine
@@ -342,11 +439,74 @@ class BaseExprVisitor(ast.NodeVisitor):
     def visit_Expr(self, node, **kwargs):
         return self.visit(node.value, **kwargs)
 
+    def _rewrite_membership_op(self, node, left, right):
+        # the kind of the operator (is actually an instance)
+        op_instance = node.op
+        op_type = type(op_instance)
+
+        # must be two terms and the comparison operator must be ==/!=/in/not in
+        if is_term(left) and is_term(right) and op_type in self.rewrite_map:
+
+            left_list, right_list = map(_is_list, (left, right))
+            left_str, right_str = map(_is_str, (left, right))
+
+            # if there are any strings or lists in the expression
+            if left_list or right_list or left_str or right_str:
+                op_instance = self.rewrite_map[op_type]()
+
+            # pop the string variable out of locals and replace it with a list
+            # of one string, kind of a hack
+            if right_str:
+                self.env.remove_tmp(right.name)
+                name = self.env.add_tmp([right.value])
+                right = self.term_type(name, self.env)
+
+            # swap the operands so things like a == [1, 2] are translated to
+            # [1, 2] in a -> a.isin([1, 2])
+            if right_list or right_str:
+                left, right = right, left
+
+        op = self.visit(op_instance)
+        return op, op_instance, left, right
+
+    def _possibly_transform_eq_ne(self, node, left=None, right=None):
+        if left is None:
+            left = self.visit(node.left, side='left')
+        if right is None:
+            right = self.visit(node.right, side='right')
+        op, op_class, left, right = self._rewrite_membership_op(node, left,
+                                                                right)
+        return op, op_class, left, right
+
+    def _possibly_eval(self, binop, eval_in_python):
+        # eval `in` and `not in` (for now) in "partial" python space
+        # things that can be evaluated in "eval" space will be turned into
+        # temporary variables. for example,
+        # [1,2] in a + 2 * b
+        # in that case a + 2 * b will be evaluated using numexpr, and the "in"
+        # call will be evaluated using isin (in python space)
+        return binop.evaluate(self.env, self.engine, self.parser,
+                              self.term_type, eval_in_python)
+
+    def _possibly_evaluate_binop(self, op, op_class, lhs, rhs,
+                                 eval_in_python=('in', 'not in'),
+                                 maybe_eval_in_python=('==', '!=')):
+        res = op(lhs, rhs)
+
+        # "in"/"not in" ops are always evaluated in python
+        if res.op in eval_in_python:
+            return self._possibly_eval(res, eval_in_python)
+        elif (lhs.return_type == object or rhs.return_type == object and
+              self.engine != 'pytables'):
+            # evaluate "==" and "!=" in python if either of our operands has an
+            # object return type
+            return self._possibly_eval(res, eval_in_python +
+                                       maybe_eval_in_python)
+        return res
+
     def visit_BinOp(self, node, **kwargs):
-        op = self.visit(node.op)
-        left = self.visit(node.left, side='left')
-        right = self.visit(node.right, side='right')
-        return op(left, right)
+        op, op_class, left, right = self._possibly_transform_eq_ne(node)
+        return self._possibly_evaluate_binop(op, op_class, left, right)
 
     def visit_Div(self, node, **kwargs):
         return lambda lhs, rhs: Div(lhs, rhs,
@@ -380,16 +540,15 @@ class BaseExprVisitor(ast.NodeVisitor):
     def visit_Subscript(self, node, **kwargs):
         value = self.visit(node.value)
         slobj = self.visit(node.slice)
-        expr = com.pprint_thing(slobj)
-        result = pd.eval(expr, local_dict=self.env, engine=self.engine,
+        result = pd.eval(slobj, local_dict=self.env, engine=self.engine,
                          parser=self.parser)
         try:
             # a Term instance
             v = value.value[result]
         except AttributeError:
             # an Op instance
-            lhs = pd.eval(com.pprint_thing(value), local_dict=self.env,
-                          engine=self.engine, parser=self.parser)
+            lhs = pd.eval(value, local_dict=self.env, engine=self.engine,
+                          parser=self.parser)
             v = lhs[result]
         name = self.env.add_tmp(v)
         return self.term_type(name, env=self.env)
@@ -454,61 +613,62 @@ class BaseExprVisitor(ast.NodeVisitor):
         keywords = {}
         for key in node.keywords:
             if not isinstance(key, ast.keyword):
-                raise ValueError(
-                    "keyword error in function call '{0}'".format(node.func.id))
+                raise ValueError("keyword error in function call "
+                                 "'{0}'".format(node.func.id))
             keywords[key.arg] = self.visit(key.value).value
         if node.kwargs is not None:
             keywords.update(self.visit(node.kwargs).value)
 
         return self.const_type(res(*args, **keywords), self.env)
 
+    def translate_In(self, op):
+        return op
+
     def visit_Compare(self, node, **kwargs):
         ops = node.ops
         comps = node.comparators
 
-        def translate(op):
-            if isinstance(op, ast.In):
-                return ast.Eq()
-            return op
-
+        # base case: we have something like a CMP b
         if len(comps) == 1:
-            return self.visit(translate(ops[0]))(self.visit(node.left, side='left'),
-                                                 self.visit(comps[0], side='right'))
+            op = self.translate_In(ops[0])
+            binop = ast.BinOp(op=op, left=node.left, right=comps[0])
+            return self.visit(binop)
+
+        # recursive case: we have a chained comparison, a CMP b CMP c, etc.
         left = node.left
         values = []
         for op, comp in zip(ops, comps):
             new_node = self.visit(ast.Compare(comparators=[comp], left=left,
-                                              ops=[translate(op)]))
+                                              ops=[self.translate_In(op)]))
             left = comp
             values.append(new_node)
         return self.visit(ast.BoolOp(op=ast.And(), values=values))
 
+    def _try_visit_binop(self, bop):
+        if isinstance(bop, (Op, Term)):
+            return bop
+        return self.visit(bop)
+
     def visit_BoolOp(self, node, **kwargs):
-        op = self.visit(node.op)
         def visitor(x, y):
-            try:
-                lhs = self.visit(x)
-            except TypeError:
-                lhs = x
-
-            try:
-                rhs = self.visit(y)
-            except TypeError:
-                rhs = y
+            lhs = self._try_visit_binop(x)
+            rhs = self._try_visit_binop(y)
 
-            return op(lhs, rhs)
+            op, op_class, lhs, rhs = self._possibly_transform_eq_ne(node, lhs,
+                                                                    rhs)
+            return self._possibly_evaluate_binop(op, node.op, lhs, rhs)
 
         operands = node.values
         return reduce(visitor, operands)
 
 
 _python_not_supported = frozenset(['Assign', 'Tuple', 'Dict', 'Call',
-                                   'BoolOp'])
+                                   'BoolOp', 'In', 'NotIn'])
 _numexpr_supported_calls = frozenset(_reductions + _mathops)
 
 
 @disallow((_unsupported_nodes | _python_not_supported) -
-          (_boolop_nodes | frozenset(['BoolOp', 'Attribute'])))
+          (_boolop_nodes | frozenset(['BoolOp', 'Attribute', 'In', 'NotIn'])))
 class PandasExprVisitor(BaseExprVisitor):
     def __init__(self, env, engine, parser,
                  preparser=lambda x: _replace_locals(_replace_booleans(x))):
@@ -523,7 +683,7 @@ class PythonExprVisitor(BaseExprVisitor):
 
 
 class Expr(StringMixin):
-    """Expr object holding scope
+    """Object encapsulating an expression.
 
     Parameters
     ----------
@@ -578,25 +738,58 @@ class Expr(StringMixin):
         _check_disjoint_resolver_names(res_keys, lcl_keys, gbl_keys)
 
     def add_resolvers_to_locals(self):
+        """Add the extra scope (resolvers) to local scope
+
+        Notes
+        -----
+        This should be done after parsing and pre-evaluation, otherwise
+        unnecessary name clashes will occur.
+        """
         self.env.locals.update(self.env.resolver_dict)
 
 
-_needs_filter = frozenset(['and', 'or', 'not'])
+# these we don't look for since column names can have these characters
+_needs_filter = frozenset(['and', 'or', 'not', 'not in', 'in'])
+
+# these OTOH can only be operators, so you cannot create column names that are
+# valid expressions
+_ops_to_filter = frozenset([' and ', ' or ', 'not ', ' in '])
+
+# if you don't filter out the above expressions you'll get a stack overflow,
+# because DataFrame.__getitem__ will continue to search for a column name then
+# an expression then a column name then an expression, and so on, until you
+# blow up the stack and kill a kitten.
 
 
 def maybe_expression(s, kind='pandas'):
-    """ loose checking if s is an expression """
+    """Loose checking if ``s`` is an expression.
+
+    Parameters
+    ----------
+    s : str or unicode
+        The expression to check
+    kind : str or unicode
+        The parser whose ops to check
+
+    Returns
+    -------
+    bool
+        ``True`` the expression contains some operators that would be valid
+        when parsed with the ``kind`` parser, otherwise ``False``.
+    """
     if not isinstance(s, string_types):
         return False
+
     visitor = _parsers[kind]
     ops = visitor.binary_ops + visitor.unary_ops
-    filtered = frozenset(ops) - _needs_filter
+    filtered = (frozenset(ops) | _ops_to_filter) - _needs_filter
+
     # make sure we have an op at least
-    return any(op in s or ' and ' in s or ' or ' in s or 'not ' in s for op in
-               filtered)
+    return any(op in s for op in filtered)
 
 
 def isexpr(s, check_names=True):
+    """Strict checking for a valid expression."""
     try:
         Expr(s, env=_ensure_scope() if check_names else None)
     except SyntaxError:
@@ -606,8 +799,4 @@ def isexpr(s, check_names=True):
     return True
 
 
-def _check_syntax(s):
-    ast.parse(s)
-
-
 _parsers = {'python': PythonExprVisitor, 'pandas': PandasExprVisitor}
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index 0ae2d2f28..14f67a3ab 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -1,3 +1,6 @@
+"""Operator classes for eval.
+"""
+
 import re
 import operator as op
 from functools import partial
@@ -23,6 +26,7 @@ _TAG_RE = re.compile('^{0}'.format(_LOCAL_TAG))
 
 
 class UndefinedVariableError(NameError):
+    """NameError subclass for local variables."""
     def __init__(self, *args):
         msg = 'name {0!r} is not defined'
         subbed = _TAG_RE.sub('', args[0])
@@ -32,18 +36,6 @@ class UndefinedVariableError(NameError):
         super(UndefinedVariableError, self).__init__(msg.format(subbed))
 
 
-class OperatorError(Exception):
-    pass
-
-
-class UnaryOperatorError(OperatorError):
-    pass
-
-
-class BinaryOperatorError(OperatorError):
-    pass
-
-
 def _possibly_update_key(d, value, old_key, new_key=None):
     if new_key is None:
         new_key = old_key
@@ -58,6 +50,13 @@ def _possibly_update_key(d, value, old_key, new_key=None):
 
 
 class Term(StringMixin):
+    def __new__(cls, name, env, side=None, encoding=None):
+        klass = Constant if not isinstance(name, string_types) else cls
+        supr_new = super(Term, klass).__new__
+        if PY3:
+            return supr_new(klass)
+        return supr_new(klass, name, env, side=side, encoding=encoding)
+
     def __init__(self, name, env, side=None, encoding=None):
         self._name = name
         self.env = env
@@ -76,8 +75,10 @@ class Term(StringMixin):
     def __call__(self, *args, **kwargs):
         return self.value
 
+    def evaluate(self, *args, **kwargs):
+        return self
+
     def _resolve_name(self):
-        #import ipdb; ipdb.set_trace()
         env = self.env
         key = self.name
         res = env.resolve(self.local_name, globally=not self.local)
@@ -194,8 +195,9 @@ class Term(StringMixin):
 
 
 class Constant(Term):
-    def __init__(self, value, env):
-        super(Constant, self).__init__(value, env)
+    def __init__(self, value, env, side=None, encoding=None):
+        super(Constant, self).__init__(value, env, side=side,
+                                       encoding=encoding)
 
     def _resolve_name(self):
         return self._name
@@ -205,19 +207,14 @@ class Constant(Term):
         return self.value
 
 
-def _print_operand(opr):
-    return opr.name if is_term(opr) else com.pprint_thing(opr)
-
-
-def _get_op(op):
-    return {'not': '~', 'and': '&', 'or': '|'}.get(op, op)
+_bool_op_map = {'not': '~', 'and': '&', 'or': '|'}
 
 
 class Op(StringMixin):
     """Hold an operator of unknown arity
     """
     def __init__(self, op, operands, *args, **kwargs):
-        self.op = _get_op(op)
+        self.op = _bool_op_map.get(op, op)
         self.operands = operands
         self.encoding = kwargs.get('encoding', None)
 
@@ -228,7 +225,7 @@ class Op(StringMixin):
         """Print a generic n-ary operator and its operands using infix
         notation"""
         # recurse over the operands
-        parened = ('({0})'.format(_print_operand(opr))
+        parened = ('({0})'.format(com.pprint_thing(opr))
                    for opr in self.operands)
         return com.pprint_thing(' {0} '.format(self.op).join(parened))
 
@@ -239,16 +236,33 @@ class Op(StringMixin):
             return np.bool_
         return np.result_type(*(term.type for term in com.flatten(self)))
 
-    @property
-    def raw(self):
-        parened = ('{0}({1!r}, {2})'.format(self.__class__.__name__, self.op,
-                                            ', '.join('{0}'.format(opr.raw) for
-                                                      opr in self.operands)))
-        return parened
+
+def _in(x, y):
+    """Compute the vectorized membership of ``x in y`` if possible, otherwise
+    use Python.
+    """
+    try:
+        return y.isin(x)
+    except AttributeError:
+        return x in y
+    except TypeError:
+        return y.isin([x])
 
 
-_cmp_ops_syms = '>', '<', '>=', '<=', '==', '!='
-_cmp_ops_funcs = op.gt, op.lt, op.ge, op.le, op.eq, op.ne
+def _not_in(x, y):
+    """Compute the vectorized membership of ``x not in y`` if possible,
+    otherwise use Python.
+    """
+    try:
+        return ~y.isin(x)
+    except AttributeError:
+        return x not in y
+    except TypeError:
+        return ~y.isin([x])
+
+
+_cmp_ops_syms = '>', '<', '>=', '<=', '==', '!=', 'in', 'not in'
+_cmp_ops_funcs = op.gt, op.lt, op.ge, op.le, op.eq, op.ne, _in, _not_in
 _cmp_ops_dict = dict(zip(_cmp_ops_syms, _cmp_ops_funcs))
 
 _bool_ops_syms = '&', '|', 'and', 'or'
@@ -272,6 +286,15 @@ for d in (_cmp_ops_dict, _bool_ops_dict, _arith_ops_dict):
 
 
 def _cast_inplace(terms, dtype):
+    """Cast an expression inplace.
+
+    Parameters
+    ----------
+    terms : Op
+        The expression that should cast.
+    dtype : str or numpy.dtype
+        The dtype to cast to.
+    """
     dt = np.dtype(dtype)
     for term in terms:
         try:
@@ -285,18 +308,14 @@ def is_term(obj):
     return isinstance(obj, Term)
 
 
-def is_const(obj):
-    return isinstance(obj, Constant)
-
-
 class BinOp(Op):
     """Hold a binary operator and its operands
 
     Parameters
     ----------
-    op : str or Op
-    left : str or Op
-    right : str or Op
+    op : str
+    left : Term or Op
+    right : Term or Op
     """
     def __init__(self, op, lhs, rhs, **kwargs):
         super(BinOp, self).__init__(op, (lhs, rhs))
@@ -309,39 +328,71 @@ class BinOp(Op):
             self.func = _binary_ops_dict[op]
         except KeyError:
             keys = _binary_ops_dict.keys()
-            raise BinaryOperatorError('Invalid binary operator {0!r}, valid'
+            raise ValueError('Invalid binary operator {0!r}, valid'
                                       ' operators are {1}'.format(op, keys))
 
     def __call__(self, env):
+        """Recursively evaluate an expression in Python space.
+
+        Parameters
+        ----------
+        env : Scope
+
+        Returns
+        -------
+        object
+            The result of an evaluated expression.
+        """
         # handle truediv
         if self.op == '/' and env.locals['truediv']:
             self.func = op.truediv
 
-        # recurse over the left nodes
-        try:
-            left = self.lhs(env)
-        except TypeError:
-            left = self.lhs
+        # recurse over the left/right nodes
+        left = self.lhs(env)
+        right = self.rhs(env)
 
-        # recurse over the right nodes
-        try:
-            right = self.rhs(env)
-        except TypeError:
-            right = self.rhs
-
-        # base cases
-        if is_term(left) and is_term(right):
-            res = self.func(left.value, right.value)
-        elif not is_term(left) and is_term(right):
-            res = self.func(left, right.value)
-        elif is_term(left) and not is_term(right):
-            res = self.func(left.value, right)
-        elif not (is_term(left) or is_term(right)):
-            res = self.func(left, right)
+        return self.func(left, right)
 
-        return res
+    def evaluate(self, env, engine, parser, term_type, eval_in_python):
+        """Evaluate a binary operation *before* being passed to the engine.
+
+        Parameters
+        ----------
+        env : Scope
+        engine : str
+        parser : str
+        term_type : type
+        eval_in_python : list
+
+        Returns
+        -------
+        term_type
+            The "pre-evaluated" expression as an instance of ``term_type``
+        """
+        if engine == 'python':
+            res = self(env)
+        else:
+            # recurse over the left/right nodes
+            left = self.lhs.evaluate(env, engine=engine, parser=parser,
+                                     term_type=term_type,
+                                     eval_in_python=eval_in_python)
+            right = self.rhs.evaluate(env, engine=engine, parser=parser,
+                                      term_type=term_type,
+                                      eval_in_python=eval_in_python)
+
+            # base cases
+            if self.op in eval_in_python:
+                res = self.func(left.value, right.value)
+            else:
+                res = pd.eval(self, local_dict=env, engine=engine,
+                              parser=parser)
+
+        name = env.add_tmp(res)
+        return term_type(name, env=env)
 
     def convert_values(self):
+        """Convert datetimes to a comparable value in an expression.
+        """
         def stringify(value):
             if self.encoding is not None:
                 encoder = partial(com.pprint_thing_encoded,
@@ -376,8 +427,19 @@ class BinOp(Op):
 
 
 class Div(BinOp):
+    """Div operator to special case casting.
+
+    Parameters
+    ----------
+    lhs, rhs : Term or Op
+        The Terms or Ops in the ``/`` expression.
+    truediv : bool
+        Whether or not to use true division. With Python 3 this happens
+        regardless of the value of ``truediv``.
+    """
     def __init__(self, lhs, rhs, truediv=True, *args, **kwargs):
         super(Div, self).__init__('/', lhs, rhs, *args, **kwargs)
+
         if truediv or PY3:
             _cast_inplace(com.flatten(self), np.float_)
 
@@ -389,6 +451,18 @@ _unary_ops_dict = dict(zip(_unary_ops_syms, _unary_ops_funcs))
 
 class UnaryOp(Op):
     """Hold a unary operator and its operands
+
+    Parameters
+    ----------
+    op : str
+        The token used to represent the operator.
+    operand : Term or Op
+        The Term or Op operand to the operator.
+
+    Raises
+    ------
+    ValueError
+        * If no function associated with the passed operator token is found.
     """
     def __init__(self, op, operand):
         super(UnaryOp, self).__init__(op, (operand,))
@@ -397,27 +471,12 @@ class UnaryOp(Op):
         try:
             self.func = _unary_ops_dict[op]
         except KeyError:
-            raise UnaryOperatorError('Invalid unary operator {0}, valid '
-                                     'operators are '
-                                     '{1}'.format(op, _unary_ops_syms))
+            raise ValueError('Invalid unary operator {0!r}, valid operators '
+                             'are {1}'.format(op, _unary_ops_syms))
 
     def __call__(self, env):
-        operand = self.operand
-
-        # recurse if operand is an Op
-        try:
-            operand = self.operand(env)
-        except TypeError:
-            operand = self.operand
-
-        v = operand.value if is_term(operand) else operand
-
-        try:
-            res = self.func(v)
-        except TypeError:
-            res = self.func(v.values)
-
-        return res
+        operand = self.operand(env)
+        return self.func(operand)
 
     def __unicode__(self):
         return com.pprint_thing('{0}({1})'.format(self.op, self.operand))
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index 4067c22be..53973970e 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -7,7 +7,8 @@ from functools import partial
 from datetime import datetime
 
 import pandas as pd
-from pandas.compat import u, string_types
+from pandas.compat import u, string_types, PY3
+from pandas.core.base import StringMixin
 import pandas.core.common as com
 from pandas.computation import expr, ops
 from pandas.computation.ops import is_term
@@ -28,9 +29,15 @@ class Scope(expr.Scope):
 
 
 class Term(ops.Term):
+    def __new__(cls, name, env, side=None, encoding=None):
+        klass = Constant if not isinstance(name, string_types) else cls
+        supr_new = StringMixin.__new__
+        if PY3:
+            return supr_new(klass)
+        return supr_new(klass, name, env, side=side, encoding=encoding)
 
-    def __init__(self, name, env, side=None):
-        super(Term, self).__init__(name, env, side=side)
+    def __init__(self, name, env, side=None, encoding=None):
+        super(Term, self).__init__(name, env, side=side, encoding=encoding)
 
     def _resolve_name(self):
         # must be a queryables
@@ -49,8 +56,9 @@ class Term(ops.Term):
 
 
 class Constant(Term):
-    def __init__(self, value, env):
-        super(Constant, self).__init__(value, env)
+    def __init__(self, value, env, side=None, encoding=None):
+        super(Constant, self).__init__(value, env, side=side,
+                                       encoding=encoding)
 
     def _resolve_name(self):
         return self._name
@@ -405,6 +413,9 @@ class ExprVisitor(BaseExprVisitor):
     def translate_In(self, op):
         return ast.Eq() if isinstance(op, ast.In) else op
 
+    def _rewrite_membership_op(self, node, left, right):
+        return self.visit(node.op), node.op, left, right
+
 
 class Expr(expr.Expr):
 
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index df60ce427..8fb1b35ab 100755
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -9,7 +9,7 @@ import ast
 import nose
 from nose.tools import assert_raises, assert_true, assert_false, assert_equal
 
-from numpy.random import randn, rand
+from numpy.random import randn, rand, randint
 import numpy as np
 from numpy.testing import assert_array_equal, assert_allclose
 from numpy.testing.decorators import slow
@@ -27,6 +27,7 @@ from pandas.computation.ops import (_binary_ops_dict, _unary_ops_dict,
                                     _special_case_arith_ops_syms,
                                     _arith_ops_syms, _bool_ops_syms)
 import pandas.computation.expr as expr
+import pandas.util.testing as tm
 from pandas.util.testing import (assert_frame_equal, randbool,
                                  assertRaisesRegexp,
                                  assert_produces_warning, assert_series_equal)
@@ -135,7 +136,7 @@ class TestEvalNumexprPandas(unittest.TestCase):
         self.bin_ops = expr._bool_ops_syms
         self.special_case_ops = _special_case_arith_ops_syms
         self.arith_ops = _good_arith_ops
-        self.unary_ops = '+', '-', '~', 'not '
+        self.unary_ops = '-', '~', 'not '
 
     def setUp(self):
         self.setup_ops()
@@ -179,13 +180,6 @@ class TestEvalNumexprPandas(unittest.TestCase):
         for lhs, rhs in product(self.lhses, self.rhses):
             self.check_pow(lhs, '**', rhs)
 
-    @slow
-    def test_unary_arith_ops(self):
-        for unary_op, lhs, arith_op, rhs in product(self.unary_ops, self.lhses,
-                                                    self.arith_ops,
-                                                    self.rhses):
-            self.check_unary_arith_op(lhs, arith_op, rhs, unary_op)
-
     @slow
     def test_single_invert_op(self):
         for lhs, op, rhs in product(self.lhses, self.cmp_ops, self.rhses):
@@ -434,33 +428,224 @@ class TestEvalNumexprPandas(unittest.TestCase):
                 ev = pd.eval(ex, engine=self.engine, parser=self.parser)
                 assert_array_equal(ev, result)
 
-    @skip_incompatible_operand
-    def check_unary_arith_op(self, lhs, arith1, rhs, unary_op):
-        # simple
-        ex = '{0}lhs'.format(unary_op, arith1)
-        f = _unary_ops_dict[unary_op]
-        bad_types = np.floating, float, numbers.Real
+    def ex(self, op, var_name='lhs'):
+        return '{0}{1}'.format(op, var_name)
 
-        if isinstance(lhs, bad_types):
-            raise nose.SkipTest("Incompatiable type for ~ operator")
-        if isinstance(rhs, bad_types):
-            raise nose.SkipTest("Incompatiable type for ~ operator")
+    def test_frame_invert(self):
+        expr = self.ex('~')
 
-        try:
-            expected = f(lhs.values)
-        except AttributeError:
-            expected = f(lhs)
+        ## ~ ##
+        # frame
+        ## float always raises
+        lhs = DataFrame(randn(5, 2))
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+
+        ## int raises on numexpr
+        lhs = DataFrame(randint(5, size=(5, 2)))
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = ~lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_frame_equal(expect, result)
+
+        ## bool always works
+        lhs = DataFrame(rand(5, 2) > 0.5)
+        expect = ~lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_frame_equal(expect, result)
+
+        ## object raises
+        lhs = DataFrame({'b': ['a', 1, 2.0], 'c': rand(3) > 0.5})
+        if self.engine == 'numexpr':
+            with tm.assertRaises(ValueError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+
+    def test_series_invert(self):
+        #### ~ ####
+        expr = self.ex('~')
+
+        # series
+        ## float raises
+        lhs = Series(randn(5))
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+
+        ## int raises on numexpr
+        lhs = Series(randint(5, size=5))
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = ~lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_series_equal(expect, result)
+
+        ## bool
+        lhs = Series(rand(5) > 0.5)
+        expect = ~lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_series_equal(expect, result)
+
+        # float
+        # int
+        # bool
+
+        # object
+        lhs = Series(['a', 1, 2.0])
+        if self.engine == 'numexpr':
+            with tm.assertRaises(ValueError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+
+    def test_frame_negate(self):
+        expr = self.ex('-')
+
+        # float
+        lhs = DataFrame(randn(5, 2))
+        expect = -lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_frame_equal(expect, result)
+
+        # int
+        lhs = DataFrame(randint(5, size=(5, 2)))
+        expect = -lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_frame_equal(expect, result)
+
+        # bool doesn't work with numexpr but works elsewhere
+        lhs = DataFrame(rand(5, 2) > 0.5)
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = -lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_frame_equal(expect, result)
+
+    def test_series_negate(self):
+        expr = self.ex('-')
+
+        # float
+        lhs = Series(randn(5))
+        expect = -lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_series_equal(expect, result)
+
+        # int
+        lhs = Series(randint(5, size=5))
+        expect = -lhs
+        result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        assert_series_equal(expect, result)
+
+        # bool doesn't work with numexpr but works elsewhere
+        lhs = Series(rand(5) > 0.5)
+        if self.engine == 'numexpr':
+            with tm.assertRaises(NotImplementedError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = -lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_series_equal(expect, result)
 
-        result = pd.eval(ex, engine=self.engine, parser=self.parser)
-        assert_array_equal(result, expected)
+    def test_frame_pos(self):
+        expr = self.ex('+')
 
-        for engine in self.current_engines:
-            skip_if_no_ne(engine)
-            assert_array_equal(result, pd.eval(ex, engine=engine,
-                                               parser=self.parser))
+        # float
+        lhs = DataFrame(randn(5, 2))
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_frame_equal(expect, result)
 
-        ex = '{0}(lhs {1} rhs)'.format(unary_op, arith1)
-        result = pd.eval(ex, engine=self.engine, parser=self.parser)
+        # int
+        lhs = DataFrame(randint(5, size=(5, 2)))
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_frame_equal(expect, result)
+
+        # bool doesn't work with numexpr but works elsewhere
+        lhs = DataFrame(rand(5, 2) > 0.5)
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_frame_equal(expect, result)
+
+    def test_series_pos(self):
+        expr = self.ex('+')
+
+        # float
+        lhs = Series(randn(5))
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_series_equal(expect, result)
+
+        # int
+        lhs = Series(randint(5, size=5))
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_series_equal(expect, result)
+
+        # bool doesn't work with numexpr but works elsewhere
+        lhs = Series(rand(5) > 0.5)
+        if self.engine == 'python':
+            with tm.assertRaises(TypeError):
+                result = pd.eval(expr, engine=self.engine, parser=self.parser)
+        else:
+            expect = lhs
+            result = pd.eval(expr, engine=self.engine, parser=self.parser)
+            assert_series_equal(expect, result)
+
+    def test_scalar_unary(self):
+        with tm.assertRaises(TypeError):
+            pd.eval('~1.0', engine=self.engine, parser=self.parser)
+
+        self.assertEqual(pd.eval('-1.0', parser=self.parser, engine=self.engine), -1.0)
+        self.assertEqual(pd.eval('+1.0', parser=self.parser, engine=self.engine), +1.0)
+
+        self.assertEqual(pd.eval('~1', parser=self.parser, engine=self.engine), ~1)
+        self.assertEqual(pd.eval('-1', parser=self.parser, engine=self.engine), -1)
+        self.assertEqual(pd.eval('+1', parser=self.parser, engine=self.engine), +1)
+
+        self.assertEqual(pd.eval('~True', parser=self.parser, engine=self.engine), ~True)
+        self.assertEqual(pd.eval('~False', parser=self.parser, engine=self.engine), ~False)
+        self.assertEqual(pd.eval('-True', parser=self.parser, engine=self.engine), -True)
+        self.assertEqual(pd.eval('-False', parser=self.parser, engine=self.engine), -False)
+        self.assertEqual(pd.eval('+True', parser=self.parser, engine=self.engine), +True)
+        self.assertEqual(pd.eval('+False', parser=self.parser, engine=self.engine), +False)
 
 
 class TestEvalNumexprPython(TestEvalNumexprPandas):
@@ -473,9 +658,11 @@ class TestEvalNumexprPython(TestEvalNumexprPandas):
         cls.parser = 'python'
 
     def setup_ops(self):
-        self.cmp_ops = expr._cmp_ops_syms
+        self.cmp_ops = list(filter(lambda x: x not in ('in', 'not in'),
+                                   expr._cmp_ops_syms))
         self.cmp2_ops = self.cmp_ops[::-1]
-        self.bin_ops = (s for s in expr._bool_ops_syms if s not in ('and', 'or'))
+        self.bin_ops = [s for s in expr._bool_ops_syms
+                        if s not in ('and', 'or')]
         self.special_case_ops = _special_case_arith_ops_syms
         self.arith_ops = _good_arith_ops
         self.unary_ops = '+', '-', '~'
@@ -714,7 +901,7 @@ class TestAlignment(object):
         for engine, parser in ENGINES_PARSERS:
             yield self.check_complex_series_frame_alignment, engine, parser
 
-    def check_performance_warning_for_asenine_alignment(self, engine, parser):
+    def check_performance_warning_for_poor_alignment(self, engine, parser):
         skip_if_no_ne(engine)
         df = DataFrame(randn(1000, 10))
         s = Series(randn(10000))
@@ -735,9 +922,32 @@ class TestAlignment(object):
         with assert_produces_warning(False):
             pd.eval('df + s', engine=engine, parser=parser)
 
-    def test_performance_warning_for_asenine_alignment(self):
+        df = DataFrame(randn(10, 10))
+        s = Series(randn(10000))
+
+        is_python_engine = engine == 'python'
+
+        if not is_python_engine:
+            wrn = pd.io.common.PerformanceWarning
+        else:
+            wrn = False
+
+        with assert_produces_warning(wrn) as w:
+            pd.eval('df + s', engine=engine, parser=parser)
+
+            if not is_python_engine:
+                assert_equal(len(w), 1)
+                msg = str(w[0].message)
+                expected = ("Alignment difference on axis {0} is larger"
+                            " than an order of magnitude on term {1!r}, "
+                            "by more than {2:.4g}; performance may suffer"
+                            "".format(1, 's', np.log10(s.size - df.shape[1])))
+                assert_equal(msg, expected)
+
+
+    def test_performance_warning_for_poor_alignment(self):
         for engine, parser in ENGINES_PARSERS:
-            yield self.check_performance_warning_for_asenine_alignment, engine, parser
+            yield self.check_performance_warning_for_poor_alignment, engine, parser
 
 
 #------------------------------------
@@ -749,6 +959,7 @@ class TestOperationsNumExprPandas(unittest.TestCase):
         skip_if_no_ne()
         cls.engine = 'numexpr'
         cls.parser = 'pandas'
+        cls.arith_ops = expr._arith_ops_syms + expr._cmp_ops_syms
 
     @classmethod
     def tearDownClass(cls):
@@ -760,7 +971,7 @@ class TestOperationsNumExprPandas(unittest.TestCase):
         return pd.eval(*args, **kwargs)
 
     def test_simple_arith_ops(self):
-        ops = expr._arith_ops_syms + expr._cmp_ops_syms
+        ops = self.arith_ops
 
         for op in filter(lambda x: x != '//', ops):
             ex = '1 {0} 1'.format(op)
@@ -943,6 +1154,9 @@ class TestOperationsNumExprPython(TestOperationsNumExprPandas):
             raise nose.SkipTest("numexpr engine not installed")
         cls.engine = 'numexpr'
         cls.parser = 'python'
+        cls.arith_ops = expr._arith_ops_syms + expr._cmp_ops_syms
+        cls.arith_ops = filter(lambda x: x not in ('in', 'not in'),
+                               cls.arith_ops)
 
     def test_fails_and(self):
         df = DataFrame(np.random.randn(5, 3))
@@ -1011,9 +1225,11 @@ class TestOperationsPythonPython(TestOperationsNumExprPython):
     @classmethod
     def setUpClass(cls):
         cls.engine = cls.parser = 'python'
+        cls.arith_ops = expr._arith_ops_syms + expr._cmp_ops_syms
+        cls.arith_ops = filter(lambda x: x not in ('in', 'not in'),
+                               cls.arith_ops)
 
     def test_fails_ampersand(self):
-        raise nose.SkipTest("known failer for now")
         df = DataFrame(np.random.randn(5, 3))
         self.assertRaises(TypeError, pd.eval,
                           '(df + 2)[df > 1] > 0 & (df > 0)',
@@ -1021,7 +1237,6 @@ class TestOperationsPythonPython(TestOperationsNumExprPython):
                           engine=self.engine)
 
     def test_fails_pipe(self):
-        raise nose.SkipTest("known failer for now")
         df = DataFrame(np.random.randn(5, 3))
         self.assertRaises(TypeError, pd.eval,
                           '(df + 2)[df > 1] > 0 | (df > 0)',
@@ -1034,6 +1249,7 @@ class TestOperationsPythonPandas(TestOperationsNumExprPandas):
     def setUpClass(cls):
         cls.engine = 'python'
         cls.parser = 'pandas'
+        cls.arith_ops = expr._arith_ops_syms + expr._cmp_ops_syms
 
 
 _var_s = randn(10)
diff --git a/pandas/core/common.py b/pandas/core/common.py
index c1ff6a220..d3fa10abc 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -9,6 +9,8 @@ import codecs
 import csv
 import sys
 
+from datetime import timedelta
+
 from distutils.version import LooseVersion
 
 from numpy.lib.format import read_array, write_array
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index ed3ecd370..c3504477b 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1903,8 +1903,31 @@ class DataFrame(NDFrame):
             raise ValueError('Must pass DataFrame with boolean values only')
         return self.where(key)
 
+    def _get_index_resolvers(self, axis):
+        # index or columns
+        axis_index = getattr(self, axis)
+        d = dict()
+
+        for i, name in enumerate(axis_index.names):
+            if name is not None:
+                key = level = name
+            else:
+                # prefix with 'i' or 'c' depending on the input axis
+                # e.g., you must do ilevel_0 for the 0th level of an unnamed
+                # multiiindex
+                level_string = '{prefix}level_{i}'.format(prefix=axis[0], i=i)
+                key = level_string
+                level = i
+
+            d[key] = Series(axis_index.get_level_values(level).values,
+                            index=axis_index, name=level)
+
+        # put the index/columns itself in the dict
+        d[axis] = axis_index
+        return d
+
     def query(self, expr, **kwargs):
-        """Query the columns of a frame with an expression.
+        """Query the columns of a frame with a boolean expression.
 
         Parameters
         ----------
@@ -1950,16 +1973,18 @@ class DataFrame(NDFrame):
         For further details and examples see the ``query`` documentation in
         :ref:`indexing <indexing.query>`.
 
-        Raises
-        ------
-        NameError
-          * If not all identifiers in the query can be found
-        SyntaxError
-          * If a syntactically invalid Python expression is passed
-
         See Also
         --------
         pandas.eval
+        DataFrame.eval
+
+        Examples
+        --------
+        >>> from numpy.random import randn
+        >>> from pandas import DataFrame
+        >>> df = DataFrame(randn(10, 2), columns=list('ab'))
+        >>> df.query('a > b')
+        >>> df[df.a > df.b]  # same result as the previous expression
         """
         # need to go up at least 4 stack frames
         # 4 expr.Scope
@@ -1972,17 +1997,56 @@ class DataFrame(NDFrame):
             raise ValueError("Going up fewer than 4 stack frames will not"
                              " capture the necessary variable scope for a "
                              "query expression")
-        return self[self.eval(expr, **kwargs)]
+
+        res = self.eval(expr, **kwargs)
+
+        try:
+            return self.loc[res]
+        except ValueError:
+            # when res is multi-dimensional loc raises, but this is sometimes a
+            # valid query
+            return self[res]
 
     def eval(self, expr, **kwargs):
+        """Evaluate an expression in the context of the calling DataFrame
+        instance.
+
+        Parameters
+        ----------
+        expr : string
+            The expression string to evaluate.
+        kwargs : dict
+            See the documentation for :func:`~pandas.eval` for complete details
+            on the keyword arguments accepted by
+            :meth:`~pandas.DataFrame.query`.
+
+        Returns
+        -------
+        ret : ndarray, scalar, or pandas object
+
+        See Also
+        --------
+        pandas.DataFrame.query
+        pandas.eval
+
+        Notes
+        -----
+        For more details see the API documentation for :func:`~pandas.eval`.
+        For detailed examples see :ref:`enhancing performance with eval
+        <enhancingperf.eval>`.
+
+        Examples
+        --------
+        >>> from numpy.random import randn
+        >>> from pandas import DataFrame
+        >>> df = DataFrame(randn(10, 2), columns=list('ab'))
+        >>> df.eval('a + b')
+        """
         resolvers = kwargs.pop('resolvers', None)
         if resolvers is None:
-            index_resolvers = {}
-            if self.index.name is not None:
-                index_resolvers[self.index.name] = self.index
-            index_resolvers.update({'index': self.index,
-                                    'columns': self.columns})
-            resolvers = [index_resolvers, self]
+            index_resolvers = self._get_index_resolvers('index')
+            index_resolvers.update(self._get_index_resolvers('columns'))
+            resolvers = [self, index_resolvers]
         kwargs['local_dict'] = _ensure_scope(resolvers=resolvers, **kwargs)
         return _eval(expr, **kwargs)
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index a4491a87b..b79408a1b 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -4244,7 +4244,17 @@ class Selection(object):
         if where is None:
             return None
 
-        return Expr(where, queryables=self.table.queryables(), encoding=self.table.encoding)
+        q = self.table.queryables()
+        try:
+            return Expr(where, queryables=q, encoding=self.table.encoding)
+        except (NameError) as detail:
+
+            # raise a nice message, suggesting that the user should use data_columns
+            raise ValueError("The passed where expression: {0}\n"
+                             "            contains an invalid variable reference\n"
+                             "            all of the variable refrences must be a reference to\n"
+                             "            an axis (e.g. 'index' or 'columns'), or a data_column\n"
+                             "            The currently defined references are: {1}\n".format(where,','.join(q.keys())))
 
     def select(self):
         """
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index ee42a58a3..87def1132 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -2036,9 +2036,9 @@ class TestHDFStore(unittest.TestCase):
             store.put('p4d', p4d, format='table')
 
             # some invalid terms
-            self.assertRaises(NameError, store.select, 'wp', "minor=['A', 'B']")
-            self.assertRaises(NameError, store.select, 'wp', ["index=['20121114']"])
-            self.assertRaises(NameError, store.select, 'wp', ["index=['20121114', '20121114']"])
+            self.assertRaises(ValueError, store.select, 'wp', "minor=['A', 'B']")
+            self.assertRaises(ValueError, store.select, 'wp', ["index=['20121114']"])
+            self.assertRaises(ValueError, store.select, 'wp', ["index=['20121114', '20121114']"])
 
             # deprecations
             with tm.assert_produces_warning(expected_warning=DeprecationWarning):
@@ -2054,6 +2054,22 @@ class TestHDFStore(unittest.TestCase):
             self.assertRaises(SyntaxError, store.select, 'df','index>')
             self.assertRaises(ValueError,  store.select, 'wp', "major_axis<'20000108' & minor_axis['A', 'B']")
 
+        # from the docs
+        with tm.ensure_clean(self.path) as path:
+            dfq = DataFrame(np.random.randn(10,4),columns=list('ABCD'),index=date_range('20130101',periods=10))
+            dfq.to_hdf(path,'dfq',format='table',data_columns=True)
+
+            # check ok
+            read_hdf(path,'dfq',where="index>Timestamp('20130104') & columns=['A', 'B']")
+            read_hdf(path,'dfq',where="A>0 or C>0")
+
+        # catch the invalid reference
+        with tm.ensure_clean(self.path) as path:
+            dfq = DataFrame(np.random.randn(10,4),columns=list('ABCD'),index=date_range('20130101',periods=10))
+            dfq.to_hdf(path,'dfq',format='table')
+
+            self.assertRaises(ValueError, read_hdf, path,'dfq',where="A>0 or C>0")
+
     def test_terms(self):
 
         with ensure_clean(self.path) as store:
@@ -2123,6 +2139,25 @@ class TestHDFStore(unittest.TestCase):
             for t in terms:
                 store.select('p4d', t)
 
+    def test_term_compat(self):
+        with ensure_clean(self.path) as store:
+
+            wp = Panel(np.random.randn(2, 5, 4), items=['Item1', 'Item2'],
+                       major_axis=date_range('1/1/2000', periods=5),
+                       minor_axis=['A', 'B', 'C', 'D'])
+            store.append('wp',wp)
+
+            with tm.assert_produces_warning(expected_warning=DeprecationWarning):
+                result = store.select('wp', [Term('major_axis>20000102'),
+                                                Term('minor_axis', '=', ['A','B']) ])
+                expected = wp.loc[:,wp.major_axis>Timestamp('20000102'),['A','B']]
+                assert_panel_equal(result, expected)
+
+            store.remove('wp', Term('major_axis>20000103'))
+            result = store.select('wp')
+            expected = wp.loc[:,wp.major_axis<=Timestamp('20000103'),:]
+            assert_panel_equal(result, expected)
+
     def test_same_name_scoping(self):
 
         with ensure_clean(self.path) as store:
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 8145fd9c5..ae37953da 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -42,11 +42,12 @@ from pandas.util.testing import (assert_almost_equal,
                                  assert_series_equal,
                                  assert_frame_equal,
                                  assertRaisesRegexp,
+                                 assertRaises,
                                  makeCustomDataframe as mkdf,
                                  ensure_clean)
 from pandas.core.indexing import IndexingError
 from pandas.core.common import PandasError
-from pandas.util.compat import OrderedDict
+from pandas.compat import OrderedDict
 from pandas.computation.expr import Expr
 import pandas.computation as comp
 
@@ -11113,6 +11114,7 @@ starting,ending,measure
         with tm.assertRaises(TypeError):
             df.isin('aaa')
 
+
 def skip_if_no_ne(engine='numexpr'):
     if engine == 'numexpr':
         try:
@@ -11288,6 +11290,187 @@ class TestDataFrameQueryNumExprPandas(unittest.TestCase):
         assert_frame_equal(res, expec)
 
 
+class TestDataFrameQueryWithMultiIndex(object):
+    def check_query_with_named_multiindex(self, parser, engine):
+        skip_if_no_ne(engine)
+        a = tm.choice(['red', 'green'], size=10)
+        b = tm.choice(['eggs', 'ham'], size=10)
+        index = MultiIndex.from_arrays([a, b], names=['color', 'food'])
+        df = DataFrame(randn(10, 2), index=index)
+        ind = Series(df.index.get_level_values('color').values, index=index,
+                     name='color')
+
+        # equality
+        #import ipdb; ipdb.set_trace()
+        res1 = df.query('color == "red"', parser=parser, engine=engine)
+        res2 = df.query('"red" == color', parser=parser, engine=engine)
+        exp = df[ind == 'red']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # inequality
+        res1 = df.query('color != "red"', parser=parser, engine=engine)
+        res2 = df.query('"red" != color', parser=parser, engine=engine)
+        exp = df[ind != 'red']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # list equality (really just set membership)
+        res1 = df.query('color == ["red"]', parser=parser, engine=engine)
+        res2 = df.query('["red"] == color', parser=parser, engine=engine)
+        exp = df[ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('color != ["red"]', parser=parser, engine=engine)
+        res2 = df.query('["red"] != color', parser=parser, engine=engine)
+        exp = df[~ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # in/not in ops
+        res1 = df.query('["red"] in color', parser=parser, engine=engine)
+        res2 = df.query('"red" in color', parser=parser, engine=engine)
+        exp = df[ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('["red"] not in color', parser=parser, engine=engine)
+        res2 = df.query('"red" not in color', parser=parser, engine=engine)
+        exp = df[~ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+    def test_query_with_named_multiindex(self):
+        for parser, engine in product(['pandas'], ENGINES):
+            yield self.check_query_with_named_multiindex, parser, engine
+
+    def check_query_with_unnamed_multiindex(self, parser, engine):
+        skip_if_no_ne(engine)
+        a = tm.choice(['red', 'green'], size=10)
+        b = tm.choice(['eggs', 'ham'], size=10)
+        index = MultiIndex.from_arrays([a, b])
+        df = DataFrame(randn(10, 2), index=index)
+        ind = Series(df.index.get_level_values(0).values, index=index)
+
+        res1 = df.query('ilevel_0 == "red"', parser=parser, engine=engine)
+        res2 = df.query('"red" == ilevel_0', parser=parser, engine=engine)
+        exp = df[ind == 'red']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # inequality
+        res1 = df.query('ilevel_0 != "red"', parser=parser, engine=engine)
+        res2 = df.query('"red" != ilevel_0', parser=parser, engine=engine)
+        exp = df[ind != 'red']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # list equality (really just set membership)
+        res1 = df.query('ilevel_0 == ["red"]', parser=parser, engine=engine)
+        res2 = df.query('["red"] == ilevel_0', parser=parser, engine=engine)
+        exp = df[ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('ilevel_0 != ["red"]', parser=parser, engine=engine)
+        res2 = df.query('["red"] != ilevel_0', parser=parser, engine=engine)
+        exp = df[~ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # in/not in ops
+        res1 = df.query('["red"] in ilevel_0', parser=parser, engine=engine)
+        res2 = df.query('"red" in ilevel_0', parser=parser, engine=engine)
+        exp = df[ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('["red"] not in ilevel_0', parser=parser, engine=engine)
+        res2 = df.query('"red" not in ilevel_0', parser=parser, engine=engine)
+        exp = df[~ind.isin(['red'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        #### LEVEL 1 ####
+        ind = Series(df.index.get_level_values(1).values, index=index)
+        res1 = df.query('ilevel_1 == "eggs"', parser=parser, engine=engine)
+        res2 = df.query('"eggs" == ilevel_1', parser=parser, engine=engine)
+        exp = df[ind == 'eggs']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # inequality
+        res1 = df.query('ilevel_1 != "eggs"', parser=parser, engine=engine)
+        res2 = df.query('"eggs" != ilevel_1', parser=parser, engine=engine)
+        exp = df[ind != 'eggs']
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # list equality (really just set membership)
+        res1 = df.query('ilevel_1 == ["eggs"]', parser=parser, engine=engine)
+        res2 = df.query('["eggs"] == ilevel_1', parser=parser, engine=engine)
+        exp = df[ind.isin(['eggs'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('ilevel_1 != ["eggs"]', parser=parser, engine=engine)
+        res2 = df.query('["eggs"] != ilevel_1', parser=parser, engine=engine)
+        exp = df[~ind.isin(['eggs'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        # in/not in ops
+        res1 = df.query('["eggs"] in ilevel_1', parser=parser, engine=engine)
+        res2 = df.query('"eggs" in ilevel_1', parser=parser, engine=engine)
+        exp = df[ind.isin(['eggs'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+        res1 = df.query('["eggs"] not in ilevel_1', parser=parser, engine=engine)
+        res2 = df.query('"eggs" not in ilevel_1', parser=parser, engine=engine)
+        exp = df[~ind.isin(['eggs'])]
+        assert_frame_equal(res1, exp)
+        assert_frame_equal(res2, exp)
+
+    def test_query_with_unnamed_multiindex(self):
+        for parser, engine in product(['pandas'], ENGINES):
+            yield self.check_query_with_unnamed_multiindex, parser, engine
+
+    def check_query_with_partially_named_multiindex(self, parser, engine):
+        skip_if_no_ne(engine)
+        a = tm.choice(['red', 'green'], size=10)
+        b = np.arange(10)
+        index = MultiIndex.from_arrays([a, b])
+        index.names = [None, 'rating']
+        df = DataFrame(randn(10, 2), index=index)
+        res = df.query('rating == 1', parser=parser, engine=engine)
+        ind = Series(df.index.get_level_values('rating').values, index=index,
+                     name='rating')
+        exp = df[ind == 1]
+        assert_frame_equal(res, exp)
+
+        res = df.query('rating != 1', parser=parser, engine=engine)
+        ind = Series(df.index.get_level_values('rating').values, index=index,
+                     name='rating')
+        exp = df[ind != 1]
+        assert_frame_equal(res, exp)
+
+        res = df.query('ilevel_0 == "red"', parser=parser, engine=engine)
+        ind = Series(df.index.get_level_values(0).values, index=index)
+        exp = df[ind == "red"]
+        assert_frame_equal(res, exp)
+
+        res = df.query('ilevel_0 != "red"', parser=parser, engine=engine)
+        ind = Series(df.index.get_level_values(0).values, index=index)
+        exp = df[ind != "red"]
+        assert_frame_equal(res, exp)
+
+    def test_query_with_partially_named_multiindex(self):
+        for parser, engine in product(['pandas'], ENGINES):
+            yield self.check_query_with_partially_named_multiindex, parser, engine
+
+
 class TestDataFrameQueryNumExprPython(TestDataFrameQueryNumExprPandas):
     @classmethod
     def setUpClass(cls):
@@ -11391,13 +11574,20 @@ class TestDataFrameQueryGetitem(unittest.TestCase):
         assert_frame_equal(res, expec)
 
     def test_query_expressions_correct_failure(self):
+        import random
+        import string
+
         df = self.frame
         exprs = 'and', 'or', 'not'
         exprs += tuple(x + tm.rands(5) for x in exprs)
-        exprs += tuple(tm.rands(5) + x for x in exprs)
+        exprs += tuple(random.choice(string.ascii_letters) + tm.rands(5) + x
+                       for x in exprs)
+
+        exprs += 'inb',
 
         for e in exprs:
-            self.assertRaises(KeyError, df.__getitem__, e)
+            with self.assertRaises(KeyError):
+                df[e]
 
         for e in (' and ', ' or ', ' not '):
             self.assertRaises(SyntaxError, df.__getitem__, e)
@@ -11405,6 +11595,8 @@ class TestDataFrameQueryGetitem(unittest.TestCase):
         x = tm.randbool(size=(self.frame.shape[0],))
         self.assertRaises(KeyError, df.__getitem__, 'x')
 
+        self.assertRaises(NameError, df.__getitem__, 'not inb')
+
     def test_query_expressions_with_index(self):
         df = DataFrame(np.random.randint(10, size=(10, 3)),
                        index=Index(range(10), name='blob'),
@@ -11463,13 +11655,40 @@ ENGINES = 'python', 'numexpr'
 
 class TestDataFrameQueryStrings(object):
     def check_str_query_method(self, parser, engine):
-        skip_if_no_pandas_parser(parser)
+        skip_if_no_ne(engine)
         df = DataFrame(randn(10, 1), columns=['b'])
         df['strings'] = Series(list('aabbccddee'))
         expect = df[df.strings == 'a']
-        res = df.query('strings == "a"', engine=engine, parser=parser)
-        assert_frame_equal(res, expect)
-        assert_frame_equal(res, df[df.strings.isin(['a'])])
+
+        if parser != 'pandas':
+            col = 'strings'
+            lst = '"a"'
+
+            lhs = [col] * 2 + [lst] * 2
+            rhs = lhs[::-1]
+
+            eq, ne = '==', '!='
+            ops = 2 * ([eq] + [ne])
+
+            for lhs, op, rhs in zip(lhs, ops, rhs):
+                ex = '{lhs} {op} {rhs}'.format(lhs=lhs, op=op, rhs=rhs)
+                assertRaises(NotImplementedError, df.query, ex, engine=engine,
+                             parser=parser, local_dict={'strings': df.strings})
+        else:
+            res = df.query('"a" == strings', engine=engine, parser=parser)
+            assert_frame_equal(res, expect)
+
+            res = df.query('strings == "a"', engine=engine, parser=parser)
+            assert_frame_equal(res, expect)
+            assert_frame_equal(res, df[df.strings.isin(['a'])])
+
+            expect = df[df.strings != 'a']
+            res = df.query('strings != "a"', engine=engine, parser=parser)
+            assert_frame_equal(res, expect)
+
+            res = df.query('"a" != strings', engine=engine, parser=parser)
+            assert_frame_equal(res, expect)
+            assert_frame_equal(res, df[~df.strings.isin(['a'])])
 
     def test_str_query_method(self):
         for parser, engine in product(PARSERS, ENGINES):
@@ -11480,14 +11699,45 @@ class TestDataFrameQueryStrings(object):
             yield self.check_str_list_query_method, parser, engine
 
     def check_str_list_query_method(self, parser, engine):
-        skip_if_no_pandas_parser(parser)
+        skip_if_no_ne(engine)
         df = DataFrame(randn(10, 1), columns=['b'])
         df['strings'] = Series(list('aabbccddee'))
         expect = df[df.strings.isin(['a', 'b'])]
-        res = df.query('strings == ["a", "b"]', engine=engine, parser=parser)
-        assert_frame_equal(res, expect)
 
-    def test_str_query(self):
+        if parser != 'pandas':
+            col = 'strings'
+            lst = '["a", "b"]'
+
+            lhs = [col] * 2 + [lst] * 2
+            rhs = lhs[::-1]
+
+            eq, ne = '==', '!='
+            ops = 2 * ([eq] + [ne])
+
+            for lhs, op, rhs in zip(lhs, ops, rhs):
+                ex = '{lhs} {op} {rhs}'.format(lhs=lhs, op=op, rhs=rhs)
+                assertRaises(NotImplementedError, df.query, ex, engine=engine,
+                             parser=parser, local_dict={'strings': df.strings})
+        else:
+            res = df.query('strings == ["a", "b"]', engine=engine,
+                           parser=parser)
+            assert_frame_equal(res, expect)
+
+            res = df.query('["a", "b"] == strings', engine=engine,
+                           parser=parser)
+            assert_frame_equal(res, expect)
+
+            expect = df[~df.strings.isin(['a', 'b'])]
+
+            res = df.query('strings != ["a", "b"]', engine=engine,
+                           parser=parser)
+            assert_frame_equal(res, expect)
+
+            res = df.query('["a", "b"] != strings', engine=engine,
+                           parser=parser)
+            assert_frame_equal(res, expect)
+
+    def test_str_query_getitem(self):
         skip_if_no_ne()
         df = DataFrame(randn(10, 1), columns=['b'])
         df['strings'] = Series(list('aabbccddee'))
@@ -11498,10 +11748,18 @@ class TestDataFrameQueryStrings(object):
         res = df['"a" == strings']
         assert_frame_equal(res, expect)
 
-    def test_str_query_list(self):
+        expect = df[df.strings != 'a']
+        res = df['strings != "a"']
+        assert_frame_equal(res, expect)
+
+        res = df['"a" != strings']
+        assert_frame_equal(res, expect)
+
+    def test_str_query_list_getitem(self):
         skip_if_no_ne()
         df = DataFrame(randn(10, 1), columns=['b'])
         df['strings'] = Series(list('aabbccddee'))
+
         expect = df[df.strings.isin(['a', 'b'])]
         res = df['strings == ["a", "b"]']
         assert_frame_equal(res, expect)
@@ -11509,6 +11767,85 @@ class TestDataFrameQueryStrings(object):
         res = df['["a", "b"] == strings']
         assert_frame_equal(res, expect)
 
+        expect = df[~df.strings.isin(['a', 'b'])]
+        res = df['strings != ["a", "b"]']
+        assert_frame_equal(res, expect)
+
+        res = df['["a", "b"] != strings']
+        assert_frame_equal(res, expect)
+
+    def check_query_with_string_columns(self, parser, engine):
+        skip_if_no_ne(engine)
+        df = DataFrame({'a': list('aaaabbbbcccc'),
+                        'b': list('aabbccddeeff'),
+                        'c': np.random.randint(5, size=12),
+                        'd': np.random.randint(9, size=12)})
+        if parser == 'pandas':
+            res = df.query('a in b', parser=parser, engine=engine)
+            expec = df[df.b.isin(df.a)]
+            assert_frame_equal(res, expec)
+
+            res = df.query('a in b and c < d', parser=parser, engine=engine)
+            expec = df[df.b.isin(df.a) & (df.c < df.d)]
+            assert_frame_equal(res, expec)
+        else:
+            with assertRaises(NotImplementedError):
+                df.query('a in b', parser=parser, engine=engine)
+
+            with assertRaises(NotImplementedError):
+                df.query('a in b and c < d', parser=parser, engine=engine)
+
+    def test_query_with_string_columns(self):
+        for parser, engine in product(PARSERS, ENGINES):
+            yield self.check_query_with_string_columns, parser, engine
+
+    def test_query_with_string_columns_numexpr(self):
+        skip_if_no_ne()
+        df = DataFrame({'a': list('aaaabbbbcccc'),
+                        'b': list('aabbccddeeff'),
+                        'c': np.random.randint(5, size=12),
+                        'd': np.random.randint(9, size=12)})
+        res = df['a in b']
+        expec = df[df.b.isin(df.a)]
+        assert_frame_equal(res, expec)
+
+        res = df['a in b and c < d']
+        expec = df[df.b.isin(df.a) & (df.c < df.d)]
+        assert_frame_equal(res, expec)
+
+    def check_object_array_eq_ne(self, parser, engine):
+        skip_if_no_ne(engine)
+        df = DataFrame({'a': list('aaaabbbbcccc'),
+                        'b': list('aabbccddeeff'),
+                        'c': np.random.randint(5, size=12),
+                        'd': np.random.randint(9, size=12)})
+        res = df.query('a == b', parser=parser, engine=engine)
+        exp = df[df.a == df.b]
+        assert_frame_equal(res, exp)
+
+        res = df.query('a != b', parser=parser, engine=engine)
+        exp = df[df.a != df.b]
+        assert_frame_equal(res, exp)
+
+    def test_object_array_eq_ne(self):
+        for parser, engine in product(PARSERS, ENGINES):
+            yield self.check_object_array_eq_ne, parser, engine
+
+    def test_object_array_eq_ne_getitem(self):
+        skip_if_no_ne()
+        df = DataFrame({'a': list('aaaabbbbcccc'),
+                        'b': list('aabbccddeeff'),
+                        'c': np.random.randint(5, size=12),
+                        'd': np.random.randint(9, size=12)})
+        res = df['a == b']
+        exp = df[df.a == df.b]
+        assert_frame_equal(res, exp)
+
+        res = df['a != b']
+        exp = df[df.a != df.b]
+        assert_frame_equal(res, exp)
+
+
 class TestDataFrameEvalNumExprPandas(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index bf895e2ab..0718dc892 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -62,6 +62,14 @@ def randu(n):
     choices += string.digits
     return ''.join([random.choice(choices) for _ in range(n)])
 
+
+def choice(x, size=10):
+    """sample with replacement; uniform over the input"""
+    try:
+        return np.random.choice(x, size=size)
+    except AttributeError:
+        return np.random.randint(len(x), size=size).choose(x)
+
 #------------------------------------------------------------------------------
 # Console debugging tools
 
