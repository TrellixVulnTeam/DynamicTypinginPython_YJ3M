commit e8d2a204aa090abead3ef2868562e1f2b756cef3
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Nov 4 21:06:17 2011 -0400

    BUG: need to shift start date 1 month back for Yahoo API, GH #329

diff --git a/pandas/io/data.py b/pandas/io/data.py
index fa7d8aa51..707d80af9 100644
--- a/pandas/io/data.py
+++ b/pandas/io/data.py
@@ -13,12 +13,12 @@ from StringIO import StringIO
 
 from pandas import DataFrame, read_csv
 
-class DataReader(list):
-
+def DataReader(name, data_source=None, start=None, end=None):
     """
     Imports data from a number of online sources.
 
-    Currently supports Yahoo! finance, St. Louis FED (FRED), and Kenneth French's data library.
+    Currently supports Yahoo! finance, St. Louis FED (FRED), and Kenneth
+    French's data library.
 
     Parameters
     ----------
@@ -46,102 +46,99 @@ class DataReader(list):
     ff = DataReader("6_Portfolios_2x3", "famafrench")
     ff = DataReader("F-F_ST_Reversal_Factor", "famafrench")
     """
-    def __new__(cls, name, data_source=None, start=None, end=None, **kwds):
-
-        if(start is None):
-            start = dt.datetime(2010, 1, 1)
-        if(end is None):
-            end = dt.datetime.today()
-
-        self = super(DataReader, cls).__new__(cls)
-
-        if(data_source == "yahoo"):
-            return self.get_data_yahoo(name=name, start=start, end=end)
-        elif(data_source == "fred"):
-            return self.get_data_fred(name=name, start=start, end=end)
-        elif(data_source == "famafrench"):
-            return self.get_data_famafrench(name=name)
-
-    def get_data_yahoo(self, name=None, start=None, end=None):
-        """
-        Get historical data for the given name from yahoo.
-        Date format is datetime
-
-        Returns a DataFrame.
-        """
-
-        if(name is None):
-            print "Need to provide a name"
-            return None
-
-        yahoo_URL = 'http://ichart.yahoo.com/table.csv?'
+    start, end = _sanitize_dates(start, end)
+
+    if(data_source == "yahoo"):
+        return get_data_yahoo(name=name, start=start, end=end)
+    elif(data_source == "fred"):
+        return get_data_fred(name=name, start=start, end=end)
+    elif(data_source == "famafrench"):
+        return get_data_famafrench(name=name)
+
+def _sanitize_dates(start, end):
+    if start is None:
+        start = dt.datetime.today() - dt.timedelta(365)
+    if end is None:
+        end = dt.datetime.today()
+    return start, end
+
+def get_data_yahoo(name=None, start=None, end=None):
+    """
+    Get historical data for the given name from yahoo.
+    Date format is datetime
 
-        url = yahoo_URL + 's=%s' % name + \
-          '&a=%s' % start.month + \
-          '&b=%s' % start.day + \
-          '&c=%s' % start.year + \
-          '&d=%s' % end.month + \
-          '&e=%s' % end.day + \
-          '&f=%s' % end.year + \
-          '&g=d' + \
-          '&ignore=.csv'
+    Returns a DataFrame.
+    """
+    from dateutil.relativedelta import relativedelta
 
-        lines = urllib.urlopen(url).read()
-        return read_csv(StringIO(lines), index_col=0, parse_dates=True)
+    start, end = _sanitize_dates(start, end)
 
-    def get_data_fred(self, name=None, start=dt.datetime(2010, 1, 1),
-                      end=dt.datetime.today()):
-        """
-        Get data for the given name from the St. Louis FED (FRED).
-        Date format is datetime
+    if(name is None):
+        print "Need to provide a name"
+        return None
 
-        Returns a DataFrame.
-        """
+    yahoo_URL = 'http://ichart.yahoo.com/table.csv?'
 
-        if(name is None):
-            print "Need to provide a name"
-            return None
+    start -= relativedelta(months=1)
 
-        fred_URL = "http://research.stlouisfed.org/fred2/series/"
+    url = yahoo_URL + 's=%s' % name + \
+      '&a=%s' % start.month + \
+      '&b=%s' % start.day + \
+      '&c=%s' % start.year + \
+      '&d=%s' % end.month + \
+      '&e=%s' % end.day + \
+      '&f=%s' % end.year + \
+      '&g=d' + \
+      '&ignore=.csv'
 
-        url = fred_URL + '%s' % name + \
-          '/downloaddata/%s' % name + '.csv'
+    lines = urllib.urlopen(url).read()
+    return read_csv(StringIO(lines), index_col=0, parse_dates=True)[::-1]
 
-        days = urllib.urlopen(url).readlines()
+def get_data_fred(name=None, start=dt.datetime(2010, 1, 1),
+                  end=dt.datetime.today()):
+    """
+    Get data for the given name from the St. Louis FED (FRED).
+    Date format is datetime
 
-        data = np.array([day[:-2].split(',') for day in days])
-        header = [str.lower(name) for name in data[0]]
-        index = np.array([dt.datetime.strptime(row[0], "%Y-%m-%d") for row in data[1:]])
-        data = np.array([[row[1]] for row in data[1:]], dtype=float)
+    Returns a DataFrame.
+    """
+    start, end = _sanitize_dates(start, end)
 
-        data = DataFrame(data, index, columns=header[1:]).sort().truncate(start, end)
+    if(name is None):
+        print "Need to provide a name"
+        return None
 
-        return data
+    fred_URL = "http://research.stlouisfed.org/fred2/series/"
 
+    url = fred_URL + '%s' % name + \
+      '/downloaddata/%s' % name + '.csv'
+    data = read_csv(urllib.urlopen(url), index_col=0, parse_dates=True)
+    return data.truncate(start, end)
 
-    def get_data_famafrench(self, name):
+def get_data_famafrench(name):
+    start, end = _sanitize_dates(start, end)
 
-        # path of zip files
-        zipFileURL = "http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/"
+    # path of zip files
+    zipFileURL = "http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/"
 
-        url = urllib.urlopen(zipFileURL + name + ".zip")
-        zipfile = ZipFile(StringIO(url.read()))
-        data = zipfile.open(name + ".txt").readlines()
+    url = urllib.urlopen(zipFileURL + name + ".zip")
+    zipfile = ZipFile(StringIO(url.read()))
+    data = zipfile.open(name + ".txt").readlines()
 
-        file_edges = np.where(np.array([len(d) for d in data]) == 2)[0]
+    file_edges = np.where(np.array([len(d) for d in data]) == 2)[0]
 
-        datasets = {}
-        for i in range(len(file_edges)-1):
-            dataset = [d.split() for d in data[(file_edges[i] + 1):file_edges[i+1]]]
-            if(len(dataset) > 10):
-                ncol = np.median(np.array([len(d) for d in dataset]))
-                header_index = np.where(np.array([len(d) for d in dataset]) == (ncol-1))[0][-1]
-                header = dataset[header_index]
-                # to ensure the header is unique
-                header = [str(j + 1) + " " + header[j] for j in range(len(header))]
-                index = np.array([d[0] for d in dataset[(header_index + 1):]], dtype=int)
-                dataset = np.array([d[1:] for d in dataset[(header_index + 1):]], dtype=float)
-                datasets[i] = DataFrame(dataset, index, columns=header)
+    datasets = {}
+    for i in range(len(file_edges)-1):
+        dataset = [d.split() for d in data[(file_edges[i] + 1):file_edges[i+1]]]
+        if(len(dataset) > 10):
+            ncol = np.median(np.array([len(d) for d in dataset]))
+            header_index = np.where(np.array([len(d) for d in dataset]) == (ncol-1))[0][-1]
+            header = dataset[header_index]
+            # to ensure the header is unique
+            header = [str(j + 1) + " " + header[j] for j in range(len(header))]
+            index = np.array([d[0] for d in dataset[(header_index + 1):]], dtype=int)
+            dataset = np.array([d[1:] for d in dataset[(header_index + 1):]], dtype=float)
+            datasets[i] = DataFrame(dataset, index, columns=header)
 
-        return datasets
+    return datasets
 
