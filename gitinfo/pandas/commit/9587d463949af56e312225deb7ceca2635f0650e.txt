commit 9587d463949af56e312225deb7ceca2635f0650e
Author: Jeff Reback <jeff@reback.net>
Date:   Sat Nov 21 10:38:28 2015 -0500

    DOC: update docs for back-refs to groupby & window functions

diff --git a/doc/source/api.rst b/doc/source/api.rst
index 12dc0b0cb..eb683fff3 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -194,65 +194,6 @@ Top-level evaluation
 
    eval
 
-Standard moving window functions
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-   :toctree: generated/
-
-   rolling_count
-   rolling_sum
-   rolling_mean
-   rolling_median
-   rolling_var
-   rolling_std
-   rolling_min
-   rolling_max
-   rolling_corr
-   rolling_corr_pairwise
-   rolling_cov
-   rolling_skew
-   rolling_kurt
-   rolling_apply
-   rolling_quantile
-   rolling_window
-
-.. _api.functions_expanding:
-
-Standard expanding window functions
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-   :toctree: generated/
-
-   expanding_count
-   expanding_sum
-   expanding_mean
-   expanding_median
-   expanding_var
-   expanding_std
-   expanding_min
-   expanding_max
-   expanding_corr
-   expanding_corr_pairwise
-   expanding_cov
-   expanding_skew
-   expanding_kurt
-   expanding_apply
-   expanding_quantile
-
-Exponentially-weighted moving window functions
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-.. autosummary::
-   :toctree: generated/
-
-   ewma
-   ewmstd
-   ewmvar
-   ewmcorr
-   ewmcov
-
 .. _api.series:
 
 Series
@@ -260,6 +201,9 @@ Series
 
 Constructor
 ~~~~~~~~~~~
+
+.. currentmodule:: pandas
+
 .. autosummary::
    :toctree: generated/
 
@@ -344,14 +288,17 @@ Binary operator functions
    Series.ne
    Series.eq
 
-Function application, GroupBy
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Function application, GroupBy & Window
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 .. autosummary::
    :toctree: generated/
 
    Series.apply
    Series.map
    Series.groupby
+   Series.rolling
+   Series.expanding
+   Series.ewm
 
 .. _api.series.stats:
 
@@ -846,14 +793,17 @@ Binary operator functions
    DataFrame.combine
    DataFrame.combine_first
 
-Function application, GroupBy
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+Function application, GroupBy & Window
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 .. autosummary::
    :toctree: generated/
 
    DataFrame.apply
    DataFrame.applymap
    DataFrame.groupby
+   DataFrame.rolling
+   DataFrame.expanding
+   DataFrame.ewm
 
 .. _api.dataframe.stats:
 
@@ -1551,6 +1501,79 @@ Conversion
    TimedeltaIndex.to_series
    TimedeltaIndex.round
 
+Window
+------
+.. currentmodule:: pandas.core.window
+
+Rolling objects are returned by rolling calls: :func:`pandas.DataFrame.rolling`, :func:`pandas.Series.rolling`, etc.
+Expanding objects are returned by rolling calls: :func:`pandas.DataFrame.expanding`, :func:`pandas.Series.expanding`, etc.
+EWM objects are returned by rolling calls: :func:`pandas.DataFrame.ewm`, :func:`pandas.Series.ewm`, etc.
+
+Standard moving window functions
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. currentmodule:: pandas.core.window
+
+.. autosummary::
+   :toctree: generated/
+
+   Rolling.count
+   Rolling.sum
+   Rolling.mean
+   Rolling.median
+   Rolling.var
+   Rolling.std
+   Rolling.min
+   Rolling.max
+   Rolling.corr
+   Rolling.corr_pairwise
+   Rolling.cov
+   Rolling.skew
+   Rolling.kurt
+   Rolling.apply
+   Rolling.quantile
+   Rolling.window
+
+.. _api.functions_expanding:
+
+Standard expanding window functions
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. currentmodule:: pandas.core.window
+
+.. autosummary::
+   :toctree: generated/
+
+   Expanding.count
+   Expanding.sum
+   Expanding.mean
+   Expanding.median
+   Expanding.var
+   Expanding.std
+   Expanding.min
+   Expanding.max
+   Expanding.corr
+   Expanding.corr_pairwise
+   Expanding.cov
+   Expanding.skew
+   Expanding.kurt
+   Expanding.apply
+   Expanding.quantile
+
+Exponentially-weighted moving window functions
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. currentmodule:: pandas.core.window
+
+.. autosummary::
+   :toctree: generated/
+
+   EWM.mean
+   EWM.std
+   EWM.var
+   EWM.corr
+   EWM.cov
+
 GroupBy
 -------
 .. currentmodule:: pandas.core.groupby
diff --git a/doc/source/computation.rst b/doc/source/computation.rst
index b2fa7f674..bf593acd7 100644
--- a/doc/source/computation.rst
+++ b/doc/source/computation.rst
@@ -21,7 +21,7 @@
 Computational tools
 ===================
 
-Statistical functions
+Statistical Functions
 ---------------------
 
 .. _computation.pct_change:
@@ -196,90 +196,118 @@ parameter:
   - ``max`` : highest rank in the group
   - ``first`` : ranks assigned in the order they appear in the array
 
+.. _stats.moments:
 
-.. currentmodule:: pandas
-
-.. currentmodule:: pandas.stats.api
+Window Functions
+----------------
 
-.. _stats.moments:
+.. warning::
 
-Moving (rolling) statistics / moments
--------------------------------------
+   Prior to version 0.18.0, these were module level functions that have been deprecated.
+   You can see the previous documentation
+   `here <http://pandas.pydata.org/pandas-docs/version/0.17.1/computation.html#moving-rolling-statistics-moments>`__
 
-For working with time series data, a number of functions are provided for
-computing common *moving* or *rolling* statistics. Among these are count, sum,
+For working with data, a number of windows functions are provided for
+computing common *window* or *rolling* statistics. Among these are count, sum,
 mean, median, correlation, variance, covariance, standard deviation, skewness,
-and kurtosis. All of these methods are in the :mod:`pandas` namespace, but
-otherwise they can be found in :mod:`pandas.stats.moments`.
+and kurtosis.
 
-.. currentmodule:: pandas
+.. currentmodule:: pandas.core.window
 
-.. csv-table::
-    :header: "Function", "Description"
-    :widths: 20, 80
+.. note::
 
-    :func:`rolling_count`, Number of non-null observations
-    :func:`rolling_sum`, Sum of values
-    :func:`rolling_mean`, Mean of values
-    :func:`rolling_median`, Arithmetic median of values
-    :func:`rolling_min`, Minimum
-    :func:`rolling_max`, Maximum
-    :func:`rolling_std`, Unbiased standard deviation
-    :func:`rolling_var`, Unbiased variance
-    :func:`rolling_skew`, Unbiased skewness (3rd moment)
-    :func:`rolling_kurt`, Unbiased kurtosis (4th moment)
-    :func:`rolling_quantile`, Sample quantile (value at %)
-    :func:`rolling_apply`, Generic apply
-    :func:`rolling_cov`, Unbiased covariance (binary)
-    :func:`rolling_corr`, Correlation (binary)
-    :func:`rolling_window`, Moving window function
-
-Generally these methods all have the same interface. The binary operators
-(e.g. :func:`rolling_corr`) take two Series or DataFrames. Otherwise, they all
+   The API for window statistics is quite similar to the way one works with ``Groupby`` objects, see the documentation :ref:`here <groupby>`
+
+We work with ``rolling``, ``expanding`` and ``exponentially weighted`` data through the corresponding
+objects, :class:`~pandas.core.window.Rolling`, :class:`~pandas.core.window.Expanding` and :class:`~pandas.core.window.EWM`.
+
+.. ipython:: python
+
+   s = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))
+   s = s.cumsum()
+   s
+
+These are created from methods on ``Series`` and ``DataFrames``.
+
+.. ipython:: python
+
+   r = s.rolling(window=60)
+   r
+
+Generally these methods all have the same interface. They all
 accept the following arguments:
 
-  - ``window``: size of moving window
-  - ``min_periods``: threshold of non-null data points to require (otherwise
-    result is NA)
-  - ``freq``: optionally specify a :ref:`frequency string <timeseries.alias>`
-    or :ref:`DateOffset <timeseries.offsets>` to pre-conform the data to.
-    Note that prior to pandas v0.8.0, a keyword argument ``time_rule`` was used
-    instead of ``freq`` that referred to the legacy time rule constants
-  - ``how``: optionally specify method for down or re-sampling.  Default is
-    is min for :func:`rolling_min`, max for :func:`rolling_max`, median for
-    :func:`rolling_median`, and mean for all other rolling functions.  See
-    :meth:`DataFrame.resample`'s how argument for more information.
+- ``window``: size of moving window
+- ``min_periods``: threshold of non-null data points to require (otherwise
+  result is NA)
+- ``freq``: optionally specify a :ref:`frequency string <timeseries.alias>`
+  or :ref:`DateOffset <timeseries.offsets>` to pre-conform the data to.
+- ``how``: optionally specify method for down or re-sampling.  Default is
+  is ``min`` for :meth:`~Rolling.min`, ``max`` for :meth:`~Rolling.max`, ``median`` for
+  :meth:`~Rolling.median`, and ``mean`` for all other rolling functions.  See
+  :meth:`DataFrame.resample`'s how argument for more information.
 
-These functions can be applied to ndarrays or Series objects:
+We can then call functions on these ``rolling`` objects. Which return like-indexed objects:
 
 .. ipython:: python
 
-   ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))
-   ts = ts.cumsum()
+   r.mean()
 
-   ts.plot(style='k--')
+.. ipython:: python
 
-   @savefig rolling_mean_ex.png
-   pd.rolling_mean(ts, 60).plot(style='k')
+   s.plot(style='k--')
 
-They can also be applied to DataFrame objects. This is really just syntactic
-sugar for applying the moving window operator to all of the DataFrame's columns:
+   @savefig rolling_mean_ex.png
+   r.mean().plot(style='k')
 
 .. ipython:: python
    :suppress:
 
    plt.close('all')
 
+They can also be applied to DataFrame objects. This is really just syntactic
+sugar for applying the moving window operator to all of the DataFrame's columns:
+
 .. ipython:: python
 
-   df = pd.DataFrame(np.random.randn(1000, 4), index=ts.index,
-                  columns=['A', 'B', 'C', 'D'])
+   df = pd.DataFrame(np.random.randn(1000, 4), index=s.index,
+                     columns=['A', 'B', 'C', 'D'])
    df = df.cumsum()
 
    @savefig rolling_mean_frame.png
-   pd.rolling_sum(df, 60).plot(subplots=True)
+   df.rolling(window=60).sum().plot(subplots=True)
+
+.. _stats.summary:
+
+Method Summary
+~~~~~~~~~~~~~~
 
-The :func:`rolling_apply` function takes an extra ``func`` argument and performs
+We provide a number of the common statistical functions:
+
+.. currentmodule:: pandas.core.window
+
+.. csv-table::
+    :header: "Method", "Description"
+    :widths: 20, 80
+
+    :meth:`~Rolling.count`, Number of non-null observations
+    :meth:`~Rolling.sum`, Sum of values
+    :meth:`~Rolling.mean`, Mean of values
+    :meth:`~Rolling.median`, Arithmetic median of values
+    :meth:`~Rolling.min`, Minimum
+    :meth:`~Rolling.max`, Maximum
+    :meth:`~Rolling.std`, Unbiased standard deviation
+    :meth:`~Rolling.var`, Unbiased variance
+    :meth:`~Rolling.skew`, Unbiased skewness (3rd moment)
+    :meth:`~Rolling.kurt`, Unbiased kurtosis (4th moment)
+    :meth:`~Rolling.quantile`, Sample quantile (value at %)
+    :meth:`~Rolling.apply`, Generic apply
+    :meth:`~Rolling.cov`, Unbiased covariance (binary)
+    :meth:`~Rolling.corr`, Correlation (binary)
+    :meth:`~Window.mean`, Moving window mean function
+    :meth:`~Window.sum`, Moving window sum function
+
+The :meth:`~Rolling.apply` function takes an extra ``func`` argument and performs
 generic rolling computations. The ``func`` argument should be a single function
 that produces a single value from an ndarray input. Suppose we wanted to
 compute the mean absolute deviation on a rolling basis:
@@ -288,46 +316,50 @@ compute the mean absolute deviation on a rolling basis:
 
    mad = lambda x: np.fabs(x - x.mean()).mean()
    @savefig rolling_apply_ex.png
-   pd.rolling_apply(ts, 60, mad).plot(style='k')
+   s.rolling(window=60).apply(mad).plot(style='k')
+
+.. _stats.rolling_window:
 
-The :func:`rolling_window` function performs a generic rolling window computation
+Rolling Windows
+~~~~~~~~~~~~~~~
+
+The :meth:`~Window.mean`, and :meth:`~Window.sum` functions performs a generic rolling window computation
 on the input data. The weights used in the window are specified by the ``win_type``
 keyword. The list of recognized types are:
 
-    - ``boxcar``
-    - ``triang``
-    - ``blackman``
-    - ``hamming``
-    - ``bartlett``
-    - ``parzen``
-    - ``bohman``
-    - ``blackmanharris``
-    - ``nuttall``
-    - ``barthann``
-    - ``kaiser`` (needs beta)
-    - ``gaussian`` (needs std)
-    - ``general_gaussian`` (needs power, width)
-    - ``slepian`` (needs width).
+- ``boxcar``
+- ``triang``
+- ``blackman``
+- ``hamming``
+- ``bartlett``
+- ``parzen``
+- ``bohman``
+- ``blackmanharris``
+- ``nuttall``
+- ``barthann``
+- ``kaiser`` (needs beta)
+- ``gaussian`` (needs std)
+- ``general_gaussian`` (needs power, width)
+- ``slepian`` (needs width).
 
 .. ipython:: python
 
    ser = pd.Series(np.random.randn(10), index=pd.date_range('1/1/2000', periods=10))
 
-   pd.rolling_window(ser, 5, 'triang')
+   ser.rolling(window=5, win_type='triang').mean()
 
-Note that the ``boxcar`` window is equivalent to :func:`rolling_mean`.
+Note that the ``boxcar`` window is equivalent to :meth:`~Rolling.mean`.
 
 .. ipython:: python
 
-   pd.rolling_window(ser, 5, 'boxcar')
-
-   pd.rolling_mean(ser, 5)
+   ser.rolling(window=5, win_type='boxcar').mean()
+   ser.rolling(window=5).mean()
 
 For some windowing functions, additional parameters must be specified:
 
 .. ipython:: python
 
-   pd.rolling_window(ser, 5, 'gaussian', std=0.1)
+   ser.rolling(window=5, win_type='gaussian').mean(std=0.1)
 
 By default the labels are set to the right edge of the window, but a
 ``center`` keyword is available so the labels can be set at the center.
@@ -335,32 +367,32 @@ This keyword is available in other rolling functions as well.
 
 .. ipython:: python
 
-   pd.rolling_window(ser, 5, 'boxcar')
+   ser.rolling(window=5, win_type='boxcar').mean()
 
-   pd.rolling_window(ser, 5, 'boxcar', center=True)
+   ser.rolling(window=5, win_type='boxcar', center=True).mean()
 
-   pd.rolling_mean(ser, 5, center=True)
+   ser.rolling(window=5, center=True).mean()
 
 .. _stats.moments.normalization:
 
 .. note::
 
-    In rolling sum mode (``mean=False``) there is no normalization done to the
+    For ``.sum()`` with a ``win_type``, there is no normalization done to the
     weights. Passing custom weights of ``[1, 1, 1]`` will yield a different
     result than passing weights of ``[2, 2, 2]``, for example. When passing a
     ``win_type`` instead of explicitly specifying the weights, the weights are
     already normalized so that the largest weight is 1.
 
-    In contrast, the nature of the rolling mean calculation (``mean=True``)is
+    In contrast, the nature of the ``.mean()`` calculation is
     such that the weights are normalized with respect to each other. Weights
     of ``[1, 1, 1]`` and ``[2, 2, 2]`` yield the same result.
 
 .. _stats.moments.binary:
 
-Binary rolling moments
-~~~~~~~~~~~~~~~~~~~~~~
+Binary Window Functions
+~~~~~~~~~~~~~~~~~~~~~~~
 
-:func:`rolling_cov` and :func:`rolling_corr` can compute moving window statistics about
+:meth:`~Rolling.cov` and :meth:`~Rolling.corr` can compute moving window statistics about
 two ``Series`` or any combination of ``DataFrame/Series`` or
 ``DataFrame/DataFrame``. Here is the behavior in each case:
 
@@ -378,7 +410,7 @@ For example:
 .. ipython:: python
 
    df2 = df[:20]
-   pd.rolling_corr(df2, df2['B'], window=5)
+   df2.rolling(window=5).corr(df2['B'])
 
 .. _stats.moments.corr_pairwise:
 
@@ -403,23 +435,16 @@ can even be omitted:
 
 .. ipython:: python
 
-   covs = pd.rolling_cov(df[['B','C','D']], df[['A','B','C']], 50, pairwise=True)
+   covs = df[['B','C','D']].rolling(window=50).cov(df[['A','B','C']], pairwise=True)
    covs[df.index[-50]]
 
 .. ipython:: python
 
-   correls = pd.rolling_corr(df, 50)
+   correls = df.rolling(window=50).corr()
    correls[df.index[-50]]
 
-.. note::
-
-    Prior to version 0.14 this was available through ``rolling_corr_pairwise``
-    which is now simply syntactic sugar for calling ``rolling_corr(...,
-    pairwise=True)`` and deprecated. This is likely to be removed in a future
-    release.
-
 You can efficiently retrieve the time series of correlations between two
-columns using ``ix`` indexing:
+columns using ``.loc`` indexing:
 
 .. ipython:: python
    :suppress:
@@ -429,62 +454,153 @@ columns using ``ix`` indexing:
 .. ipython:: python
 
    @savefig rolling_corr_pairwise_ex.png
-   correls.ix[:, 'A', 'C'].plot()
+   correls.loc[:, 'A', 'C'].plot()
+
+.. _stats.aggregate:
+
+Aggregation
+-----------
+
+Once the ``Rolling``, ``Expanding`` or ``EWM`` objects have been created, several methods are available to
+perform multiple computations on the data. This is very similar to a ``.groupby.agg`` seen :ref:`here <groupby.aggregate>`.
+
+An obvious one is aggregation via the ``aggregate`` or equivalently ``agg`` method:
+
+.. ipython:: python
+
+   dfa = pd.DataFrame(np.random.randn(1000, 3), index=s.index,
+                     columns=['A', 'B', 'C'])
+   r = dfa.rolling(window=60,min_periods=1)
+   r
+
+We can aggregate by passing a function to the entire DataFrame, or select a Series (or multiple Series) via standard getitem.
+
+.. ipython:: python
+
+   r.aggregate(np.sum)
+
+   r['A'].aggregate(np.sum)
+
+   r['A','B'].aggregate(np.sum)
+
+As you can see, the result of the aggregation will have the selection columns, or all
+columns if none are selected.
+
+.. _stats.aggregate.multifunc:
+
+Applying multiple functions at once
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+With windowed Series you can also pass a list or dict of functions to do
+aggregation with, outputting a DataFrame:
+
+.. ipython:: python
+
+   r['A'].agg([np.sum, np.mean, np.std])
+
+If a dict is passed, the keys will be used to name the columns. Otherwise the
+function's name (stored in the function object) will be used.
+
+.. ipython:: python
+
+   r['A'].agg({'result1' : np.sum,
+               'result2' : np.mean})
+
+On a widowed DataFrame, you can pass a list of functions to apply to each
+column, which produces an aggregated result with a hierarchical index:
+
+.. ipython:: python
+
+   r.agg([np.sum, np.mean])
+
+Passing a dict of functions has different behavior by default, see the next
+section.
+
+Applying different functions to DataFrame columns
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+By passing a dict to ``aggregate`` you can apply a different aggregation to the
+columns of a DataFrame:
+
+.. ipython:: python
+
+   r.agg({'A' : np.sum,
+          'B' : lambda x: np.std(x, ddof=1)})
+
+The function names can also be strings. In order for a string to be valid it
+must be either implemented on the Windowed object
+
+.. ipython:: python
+
+   r.agg({'A' : 'sum', 'B' : 'std'})
+
+Furthermore you can pass a nested dict to indicate different aggregations on different columns.
+
+.. ipython:: python
+
+   r.agg({'A' : {'ra' : 'sum'}, 'B' : {'rb' : 'std' }})
+
 
 .. _stats.moments.expanding:
 
-Expanding window moment functions
----------------------------------
+Expanding Windows
+-----------------
+
 A common alternative to rolling statistics is to use an *expanding* window,
 which yields the value of the statistic with all the data available up to that
-point in time. As these calculations are a special case of rolling statistics,
+point in time.
+
+These follow a similar interface to ``.rolling``, with the ``.expanding`` method
+returning an :class:`~pandas.core.window.Expanding` object.
+
+As these calculations are a special case of rolling statistics,
 they are implemented in pandas such that the following two calls are equivalent:
 
 .. ipython:: python
 
-   pd.rolling_mean(df, window=len(df), min_periods=1)[:5]
+   df.rolling(window=len(df), min_periods=1).mean()[:5]
 
-   pd.expanding_mean(df)[:5]
+   df.expanding(min_periods=1).mean()[:5]
 
-Like the ``rolling_`` functions, the following methods are included in the
-``pandas`` namespace or can be located in ``pandas.stats.moments``.
+These have a similar set of methods to ``.rolling`` methods.
 
-.. currentmodule:: pandas
+Method Summary
+~~~~~~~~~~~~~~
+
+.. currentmodule:: pandas.core.window
 
 .. csv-table::
     :header: "Function", "Description"
     :widths: 20, 80
 
-    :func:`expanding_count`, Number of non-null observations
-    :func:`expanding_sum`, Sum of values
-    :func:`expanding_mean`, Mean of values
-    :func:`expanding_median`, Arithmetic median of values
-    :func:`expanding_min`, Minimum
-    :func:`expanding_max`, Maximum
-    :func:`expanding_std`, Unbiased standard deviation
-    :func:`expanding_var`, Unbiased variance
-    :func:`expanding_skew`, Unbiased skewness (3rd moment)
-    :func:`expanding_kurt`, Unbiased kurtosis (4th moment)
-    :func:`expanding_quantile`, Sample quantile (value at %)
-    :func:`expanding_apply`, Generic apply
-    :func:`expanding_cov`, Unbiased covariance (binary)
-    :func:`expanding_corr`, Correlation (binary)
+    :meth:`~Expanding.count`, Number of non-null observations
+    :meth:`~Expanding.sum`, Sum of values
+    :meth:`~Expanding.mean`, Mean of values
+    :meth:`~Expanding.median`, Arithmetic median of values
+    :meth:`~Expanding.min`, Minimum
+    :meth:`~Expanding.max`, Maximum
+    :meth:`~Expanding.std`, Unbiased standard deviation
+    :meth:`~Expanding.var`, Unbiased variance
+    :meth:`~Expanding.skew`, Unbiased skewness (3rd moment)
+    :meth:`~Expanding.kurt`, Unbiased kurtosis (4th moment)
+    :meth:`~Expanding.quantile`, Sample quantile (value at %)
+    :meth:`~Expanding.apply`, Generic apply
+    :meth:`~Expanding.cov`, Unbiased covariance (binary)
+    :meth:`~Expanding.corr`, Correlation (binary)
 
 Aside from not having a ``window`` parameter, these functions have the same
-interfaces as their ``rolling_`` counterpart. Like above, the parameters they
+interfaces as their ``.rolling`` counterparts. Like above, the parameters they
 all accept are:
 
-  - ``min_periods``: threshold of non-null data points to require. Defaults to
-    minimum needed to compute statistic. No ``NaNs`` will be output once
-    ``min_periods`` non-null data points have been seen.
-  - ``freq``: optionally specify a :ref:`frequency string <timeseries.alias>`
-    or :ref:`DateOffset <timeseries.offsets>` to pre-conform the data to.
-    Note that prior to pandas v0.8.0, a keyword argument ``time_rule`` was used
-    instead of ``freq`` that referred to the legacy time rule constants
+- ``min_periods``: threshold of non-null data points to require. Defaults to
+  minimum needed to compute statistic. No ``NaNs`` will be output once
+  ``min_periods`` non-null data points have been seen.
+- ``freq``: optionally specify a :ref:`frequency string <timeseries.alias>`
+  or :ref:`DateOffset <timeseries.offsets>` to pre-conform the data to.
 
 .. note::
 
-   The output of the ``rolling_`` and ``expanding_`` functions do not return a
+   The output of the ``.rolling`` and ``.expanding`` methods do not return a
    ``NaN`` if there are at least ``min_periods`` non-null values in the current
    window. This differs from ``cumsum``, ``cumprod``, ``cummax``, and
    ``cummin``, which return ``NaN`` in the output wherever a ``NaN`` is
@@ -493,7 +609,7 @@ all accept are:
 An expanding window statistic will be more stable (and less responsive) than
 its rolling window counterpart as the increasing window size decreases the
 relative impact of an individual data point. As an example, here is the
-:func:`expanding_mean` output for the previous time series dataset:
+:meth:`~Expanding.mean` output for the previous time series dataset:
 
 .. ipython:: python
    :suppress:
@@ -502,31 +618,34 @@ relative impact of an individual data point. As an example, here is the
 
 .. ipython:: python
 
-   ts.plot(style='k--')
+   s.plot(style='k--')
 
    @savefig expanding_mean_frame.png
-   pd.expanding_mean(ts).plot(style='k')
+   s.expanding().mean().plot(style='k')
+
 
 .. _stats.moments.exponentially_weighted:
 
-Exponentially weighted moment functions
----------------------------------------
+Exponentially Weighted Windows
+------------------------------
 
 A related set of functions are exponentially weighted versions of several of
-the above statistics. A number of expanding EW (exponentially weighted)
-functions are provided:
+the above statistics. A similar interface to ``.rolling`` and ``.expanding`` is accessed
+thru the ``.ewm`` method to receive a :class:`~pandas.core.window.EWM` object.
+A number of expanding EW (exponentially weighted)
+methods are provided:
 
-.. currentmodule:: pandas
+.. currentmodule:: pandas.core.window
 
 .. csv-table::
     :header: "Function", "Description"
     :widths: 20, 80
 
-    :func:`ewma`, EW moving average
-    :func:`ewmvar`, EW moving variance
-    :func:`ewmstd`, EW moving standard deviation
-    :func:`ewmcorr`, EW moving correlation
-    :func:`ewmcov`, EW moving covariance
+    :meth:`~EWM.mean`, EW moving average
+    :meth:`~EWM.var`, EW moving variance
+    :meth:`~EWM.std`, EW moving standard deviation
+    :meth:`~EWM.corr`, EW moving correlation
+    :meth:`~EWM.cov`, EW moving covariance
 
 In general, a weighted moving average is calculated as
 
@@ -621,20 +740,20 @@ Here is an example for a univariate time series:
 
 .. ipython:: python
 
-   ts.plot(style='k--')
+   s.plot(style='k--')
 
    @savefig ewma_ex.png
-   pd.ewma(ts, span=20).plot(style='k')
+   s.ewm(span=20).mean().plot(style='k')
 
-All the EW functions have a ``min_periods`` argument, which has the same
-meaning it does for all the ``expanding_`` and ``rolling_`` functions:
+EWM has a ``min_periods`` argument, which has the same
+meaning it does for all the ``.expanding`` and ``.rolling`` methods:
 no output values will be set until at least ``min_periods`` non-null values
 are encountered in the (expanding) window.
 (This is a change from versions prior to 0.15.0, in which the ``min_periods``
 argument affected only the ``min_periods`` consecutive entries starting at the
 first non-null value.)
 
-All the EW functions also have an ``ignore_na`` argument, which deterines how
+EWM also has an ``ignore_na`` argument, which deterines how
 intermediate null values affect the calculation of the weights.
 When ``ignore_na=False`` (the default), weights are calculated based on absolute
 positions, so that intermediate null values affect the result.
@@ -653,7 +772,7 @@ Whereas if ``ignore_na=True``, the weighted average would be calculated as
 
 	\frac{(1-\alpha) \cdot 3 + 1 \cdot 5}{(1-\alpha) + 1}.
 
-The :func:`ewmvar`, :func:`ewmstd`, and :func:`ewmcov` functions have a ``bias`` argument,
+The :meth:`~Ewm.var`, :meth:`~Ewm.std`, and :meth:`~Ewm.cov` functions have a ``bias`` argument,
 specifying whether the result should contain biased or unbiased statistics.
 For example, if ``bias=True``, ``ewmvar(x)`` is calculated as
 ``ewmvar(x) = ewma(x**2) - ewma(x)**2``;
diff --git a/doc/source/whatsnew/v0.18.0.txt b/doc/source/whatsnew/v0.18.0.txt
index a5c1e9b1d..b8fc0fff7 100644
--- a/doc/source/whatsnew/v0.18.0.txt
+++ b/doc/source/whatsnew/v0.18.0.txt
@@ -27,10 +27,10 @@ New features
 
 .. _whatsnew_0180.enhancements.moments:
 
-Computation moments are now methods
-^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
+Window functions are now methods
+^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
 
-Computational moments have been refactored to be method on ``Series/DataFrame`` objects, rather than top-level functions, which are now deprecated. This allows these window-type functions, to have a similar API to that of ``.groupby``. See the full documentation :ref:`here <stats.moments>` (:issue:`11603`)
+Window functions have been refactored to be methods on ``Series/DataFrame`` objects, rather than top-level functions, which are now deprecated. This allows these window-type functions, to have a similar API to that of ``.groupby``. See the full documentation :ref:`here <stats.moments>` (:issue:`11603`)
 
 .. ipython:: python
 
@@ -56,24 +56,36 @@ Previous Behavior:
    8   7  0.079587
    9   8 -0.954504
 
-  New Behavior:
+New Behavior:
 
-  .. ipython:: python
+.. ipython:: python
+
+   r = df.rolling(window=3)
 
-    r = df.rolling(window=3)
+These show a descriptive repr, with tab-completion of available methods
+
+.. ipython:: python
 
-    # descriptive repr
-    r
+   r
+
+The methods operate on this ``Rolling`` object itself
+
+.. ipython:: python
 
-    # operate on this Rolling object itself
-    r.mean()
+   r.mean()
 
-    # getitem access
-    r['A'].mean()
+They provide getitem accessors
+
+.. ipython:: python
+
+   r['A'].mean()
+
+And multiple aggregations
+
+.. ipython:: python
 
-    # aggregates
-    r.agg({'A' : {'ra' : ['mean','std']},
-           'B' : {'rb' : ['mean','std']}})
+   r.agg({'A' : {'ra' : ['mean','std']},
+          'B' : {'rb' : ['mean','std']}})
 
 .. _whatsnew_0180.enhancements.other:
 
diff --git a/pandas/core/base.py b/pandas/core/base.py
index e5a825599..fafd6b782 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -7,7 +7,8 @@ import numpy as np
 from pandas.core import common as com
 import pandas.core.nanops as nanops
 import pandas.lib as lib
-from pandas.util.decorators import Appender, cache_readonly, deprecate_kwarg
+from pandas.util.decorators import (Appender, Substitution,
+                                    cache_readonly, deprecate_kwarg)
 from pandas.core.common import AbstractMethodError
 
 _shared_docs = dict()
@@ -356,14 +357,19 @@ Returns
 aggregated : DataFrame
 """
 
-    @Appender(_agg_doc)
-    def agg(self, func, *args, **kwargs):
-        return self.aggregate(func, *args, **kwargs)
+    _see_also_template = """
+
+See also
+--------
+:func:`pandas.Series.%(name)s`
+:func:`pandas.DataFrame.%(name)s`
+"""
 
-    @Appender(_agg_doc)
     def aggregate(self, func, *args, **kwargs):
         raise AbstractMethodError(self)
 
+    agg = aggregate
+
     def _aggregate(self, arg, *args, **kwargs):
         """
         provide an implementation for the aggregators
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 38c0a0b14..61fcf55af 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -20,7 +20,7 @@ from pandas.core.index import Index, MultiIndex, CategoricalIndex, _ensure_index
 from pandas.core.internals import BlockManager, make_block
 from pandas.core.series import Series
 from pandas.core.panel import Panel
-from pandas.util.decorators import (cache_readonly, Appender, make_signature,
+from pandas.util.decorators import (cache_readonly, Substitution, Appender, make_signature,
                                     deprecate_kwarg)
 import pandas.core.algorithms as algos
 import pandas.core.common as com
@@ -37,6 +37,19 @@ import pandas.tslib as tslib
 import pandas.algos as _algos
 import pandas.hashtable as _hash
 
+_doc_template = """
+
+Returns
+-------
+same type as input
+
+See also
+--------
+:func:`pandas.Series.%(name)s`
+:func:`pandas.DataFrame.%(name)s`
+:func:`pandas.Panel.%(name)s`
+"""
+
 # special case to prevent duplicate plots when catching exceptions when
 # forwarding methods from NDFrames
 _plotting_methods = frozenset(['plot', 'boxplot', 'hist'])
@@ -71,6 +84,12 @@ _cython_transforms = frozenset(['cumprod', 'cumsum', 'shift'])
 
 def _groupby_function(name, alias, npfunc, numeric_only=True,
                       _convert=False):
+
+    _local_template = "Compute %(f)s of group values"
+
+    @Substitution(name='groupby',f=name)
+    @Appender(_doc_template)
+    @Appender(_local_template)
     def f(self):
         self._set_selection_from_grouper()
         try:
@@ -83,8 +102,7 @@ def _groupby_function(name, alias, npfunc, numeric_only=True,
                 result = result._convert(datetime=True)
             return result
 
-    f.__doc__ = "Compute %s of group values" % name
-    f.__name__ = name
+        f.__name__ = name
 
     return f
 
@@ -608,50 +626,46 @@ class GroupBy(PandasObject, SelectionMixin):
         """
         return self.grouper.get_iterator(self.obj, axis=self.axis)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def apply(self, func, *args, **kwargs):
-        """
-        Apply function and combine results together in an intelligent way. The
-        split-apply-combine combination rules attempt to be as common sense
-        based as possible. For example:
-
-        case 1:
-        group DataFrame
-        apply aggregation function (f(chunk) -> Series)
-        yield DataFrame, with group axis having group labels
-
-        case 2:
-        group DataFrame
-        apply transform function ((f(chunk) -> DataFrame with same indexes)
-        yield DataFrame with resulting chunks glued together
-
-        case 3:
-        group Series
-        apply function with f(chunk) -> DataFrame
-        yield DataFrame with result of chunks glued together
-
-        Parameters
-        ----------
-        func : function
-
-        Notes
-        -----
-        See online documentation for full exposition on how to use apply.
-
-        In the current implementation apply calls func twice on the
-        first group to decide whether it can take a fast or slow code
-        path. This can lead to unexpected behavior if func has
-        side-effects, as they will take effect twice for the first
-        group.
-
-
-        See also
-        --------
-        aggregate, transform
-
-        Returns
-        -------
-        applied : type depending on grouped object and function
-        """
+        """Apply function and combine results together in an intelligent way. The
+split-apply-combine combination rules attempt to be as common sense
+based as possible. For example:
+
+case 1:
+group DataFrame
+apply aggregation function (f(chunk) -> Series)
+yield DataFrame, with group axis having group labels
+
+case 2:
+group DataFrame
+apply transform function ((f(chunk) -> DataFrame with same indexes)
+yield DataFrame with resulting chunks glued together
+
+case 3:
+group Series
+apply function with f(chunk) -> DataFrame
+yield DataFrame with result of chunks glued together
+
+Parameters
+----------
+func : function
+
+Notes
+-----
+See online documentation for full exposition on how to use apply.
+
+In the current implementation apply calls func twice on the
+first group to decide whether it can take a fast or slow code
+path. This can lead to unexpected behavior if func has
+side-effects, as they will take effect twice for the first
+group.
+
+
+See also
+--------
+aggregate, transform"""
         func = self._is_builtin_func(func)
 
         @wraps(func)
@@ -685,15 +699,18 @@ class GroupBy(PandasObject, SelectionMixin):
                       FutureWarning, stacklevel=2)
         return self.nth(i)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def count(self):
-        """ Compute count of group, excluding missing values """
+        """Compute count of group, excluding missing values"""
 
         # defined here for API doc
         raise NotImplementedError
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def mean(self):
-        """
-        Compute mean of groups, excluding missing values
+        """Compute mean of groups, excluding missing values
 
         For multiple groupings, the result index will be a MultiIndex
         """
@@ -706,9 +723,10 @@ class GroupBy(PandasObject, SelectionMixin):
             f = lambda x: x.mean(axis=self.axis)
             return self._python_agg_general(f)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def median(self):
-        """
-        Compute median of groups, excluding missing values
+        """Compute median of groups, excluding missing values
 
         For multiple groupings, the result index will be a MultiIndex
         """
@@ -725,21 +743,33 @@ class GroupBy(PandasObject, SelectionMixin):
                 return x.median(axis=self.axis)
             return self._python_agg_general(f)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def std(self, ddof=1):
-        """
-        Compute standard deviation of groups, excluding missing values
+        """Compute standard deviation of groups, excluding missing values
+
+For multiple groupings, the result index will be a MultiIndex
+
+Parameters
+----------
+ddof : integer, default 1
+degrees of freedom"""
 
-        For multiple groupings, the result index will be a MultiIndex
-        """
         # todo, implement at cython level?
         return np.sqrt(self.var(ddof=ddof))
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def var(self, ddof=1):
-        """
-        Compute variance of groups, excluding missing values
+        """Compute variance of groups, excluding missing values
+
+For multiple groupings, the result index will be a MultiIndex
+
+Parameters
+----------
+ddof : integer, default 1
+degrees of freedom"""
 
-        For multiple groupings, the result index will be a MultiIndex
-        """
         if ddof == 1:
             return self._cython_agg_general('var')
         else:
@@ -747,19 +777,24 @@ class GroupBy(PandasObject, SelectionMixin):
             f = lambda x: x.var(ddof=ddof)
             return self._python_agg_general(f)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def sem(self, ddof=1):
-        """
-        Compute standard error of the mean of groups, excluding missing values
+        """Compute standard error of the mean of groups, excluding missing values
+
+For multiple groupings, the result index will be a MultiIndex
+
+Parameters
+----------
+ddof : integer, default 1
+degrees of freedom"""
 
-        For multiple groupings, the result index will be a MultiIndex
-        """
         return self.std(ddof=ddof)/np.sqrt(self.count())
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def size(self):
-        """
-        Compute group sizes
-
-        """
+        """Compute group sizes"""
         return self.grouper.size()
 
     sum = _groupby_function('sum', 'add', np.sum)
@@ -771,58 +806,59 @@ class GroupBy(PandasObject, SelectionMixin):
     last = _groupby_function('last', 'last', _last_compat, numeric_only=False,
                              _convert=True)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def ohlc(self):
-        """
-        Compute sum of values, excluding missing values
-        For multiple groupings, the result index will be a MultiIndex
-        """
+        """Compute sum of values, excluding missing values
+For multiple groupings, the result index will be a MultiIndex"""
+
         return self._apply_to_column_groupbys(
             lambda x: x._cython_agg_general('ohlc'))
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def nth(self, n, dropna=None):
-        """
-        Take the nth row from each group if n is an int, or a subset of rows
-        if n is a list of ints.
-
-        If dropna, will take the nth non-null row, dropna is either
-        Truthy (if a Series) or 'all', 'any' (if a DataFrame); this is equivalent
-        to calling dropna(how=dropna) before the groupby.
-
-        Parameters
-        ----------
-        n : int or list of ints
-            a single nth value for the row or a list of nth values
-        dropna : None or str, optional
-            apply the specified dropna operation before counting which row is
-            the nth row. Needs to be None, 'any' or 'all'
-
-        Examples
-        --------
-        >>> df = DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])
-        >>> g = df.groupby('A')
-        >>> g.nth(0)
-           A   B
-        0  1 NaN
-        2  5   6
-        >>> g.nth(1)
-           A  B
-        1  1  4
-        >>> g.nth(-1)
-           A  B
-        1  1  4
-        2  5  6
-        >>> g.nth(0, dropna='any')
-           B
+        """Take the nth row from each group if n is an int, or a subset of rows
+if n is a list of ints.
+
+If dropna, will take the nth non-null row, dropna is either
+Truthy (if a Series) or 'all', 'any' (if a DataFrame); this is equivalent
+to calling dropna(how=dropna) before the groupby.
+
+Parameters
+----------
+n : int or list of ints
+    a single nth value for the row or a list of nth values
+dropna : None or str, optional
+    apply the specified dropna operation before counting which row is
+    the nth row. Needs to be None, 'any' or 'all'
+
+Examples
+--------
+>>> df = DataFrame([[1, np.nan], [1, 4], [5, 6]], columns=['A', 'B'])
+>>> g = df.groupby('A')
+>>> g.nth(0)
+       A   B
+    0  1 NaN
+    2  5   6
+>>> g.nth(1)
+       A  B
+    1  1  4
+>>> g.nth(-1)
+       A  B
+    1  1  4
+    2  5  6
+>>> g.nth(0, dropna='any')
+       B
+       A
+    1  4
+    5  6
+>>> g.nth(1, dropna='any')  # NaNs denote group exhausted when using dropna
+        B
         A
-        1  4
-        5  6
-        >>> g.nth(1, dropna='any')  # NaNs denote group exhausted when using dropna
-            B
-        A
-        1 NaN
-        5 NaN
+    1 NaN
+    5 NaN"""
 
-        """
         if isinstance(n, int):
             nth_values = [n]
         elif isinstance(n, (set, list, tuple)):
@@ -914,80 +950,85 @@ class GroupBy(PandasObject, SelectionMixin):
 
         return result
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def cumcount(self, ascending=True):
-        """
-        Number each item in each group from 0 to the length of that group - 1.
+        """Number each item in each group from 0 to the length of that group - 1.
+
+Essentially this is equivalent to
+
+>>> self.apply(lambda x: Series(np.arange(len(x)), x.index))
+
+Parameters
+----------
+ascending : bool, default True
+    If False, number in reverse, from length of group - 1 to 0.
+
+Examples
+--------
+
+>>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
+    ...               columns=['A'])
+>>> df
+       A
+    0  a
+    1  a
+    2  a
+    3  b
+    4  b
+    5  a
+>>> df.groupby('A').cumcount()
+    0    0
+    1    1
+    2    2
+    3    0
+    4    1
+    5    3
+    dtype: int64
+>>> df.groupby('A').cumcount(ascending=False)
+    0    3
+    1    2
+    2    1
+    3    1
+    4    0
+    5    0
+    dtype: int64"""
 
-        Essentially this is equivalent to
-
-        >>> self.apply(lambda x: Series(np.arange(len(x)), x.index))
-
-        Parameters
-        ----------
-        ascending : bool, default True
-            If False, number in reverse, from length of group - 1 to 0.
-
-        Examples
-        --------
-
-        >>> df = pd.DataFrame([['a'], ['a'], ['a'], ['b'], ['b'], ['a']],
-        ...                   columns=['A'])
-        >>> df
-           A
-        0  a
-        1  a
-        2  a
-        3  b
-        4  b
-        5  a
-        >>> df.groupby('A').cumcount()
-        0    0
-        1    1
-        2    2
-        3    0
-        4    1
-        5    3
-        dtype: int64
-        >>> df.groupby('A').cumcount(ascending=False)
-        0    3
-        1    2
-        2    1
-        3    1
-        4    0
-        5    0
-        dtype: int64
-
-        """
         self._set_selection_from_grouper()
 
         index = self._selected_obj.index
         cumcounts = self._cumcount_array(ascending=ascending)
         return Series(cumcounts, index)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def cumprod(self, axis=0):
-        """
-        Cumulative product for each group
-
-        """
+        """Cumulative product for each group"""
         if axis != 0:
             return self.apply(lambda x: x.cumprod(axis=axis))
 
         return self._cython_transform('cumprod')
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def cumsum(self, axis=0):
-        """
-        Cumulative sum for each group
-
-        """
+        """Cumulative sum for each group"""
         if axis != 0:
             return self.apply(lambda x: x.cumprod(axis=axis))
 
         return self._cython_transform('cumsum')
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def shift(self, periods=1, freq=None, axis=0):
-        """
-        Shift each group by periods observations
-        """
+        """Shift each group by periods observations
+
+Parameters
+----------
+periods : integer, default 1
+    number of periods to shift
+freq : frequency string
+axis : axis to shift, default 0"""
 
         if freq is not None or axis != 0:
             return self.apply(lambda x: x.shift(periods, freq, axis))
@@ -1003,55 +1044,53 @@ class GroupBy(PandasObject, SelectionMixin):
 
         return self._wrap_transformed_output(output)
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def head(self, n=5):
-        """
-        Returns first n rows of each group.
-
-        Essentially equivalent to ``.apply(lambda x: x.head(n))``,
-        except ignores as_index flag.
-
-        Examples
-        --------
-
-        >>> df = DataFrame([[1, 2], [1, 4], [5, 6]],
-                            columns=['A', 'B'])
-        >>> df.groupby('A', as_index=False).head(1)
-           A  B
-        0  1  2
-        2  5  6
-        >>> df.groupby('A').head(1)
-           A  B
-        0  1  2
-        2  5  6
-
-        """
+        """Returns first n rows of each group.
+
+Essentially equivalent to ``.apply(lambda x: x.head(n))``,
+except ignores as_index flag.
+
+Examples
+--------
+
+>>> df = DataFrame([[1, 2], [1, 4], [5, 6]],
+                   columns=['A', 'B'])
+>>> df.groupby('A', as_index=False).head(1)
+       A  B
+    0  1  2
+    2  5  6
+>>> df.groupby('A').head(1)
+       A  B
+    0  1  2
+    2  5  6"""
         obj = self._selected_obj
         in_head = self._cumcount_array() < n
         head = obj[in_head]
         return head
 
+    @Substitution(name='groupby')
+    @Appender(_doc_template)
     def tail(self, n=5):
-        """
-        Returns last n rows of each group
-
-        Essentially equivalent to ``.apply(lambda x: x.tail(n))``,
-        except ignores as_index flag.
-
-        Examples
-        --------
-
-        >>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
-                            columns=['A', 'B'])
-        >>> df.groupby('A').tail(1)
-           A  B
-        1  a  2
-        3  b  2
-        >>> df.groupby('A').head(1)
-           A  B
-        0  a  1
-        2  b  1
-
-        """
+        """Returns last n rows of each group
+
+Essentially equivalent to ``.apply(lambda x: x.tail(n))``,
+except ignores as_index flag.
+
+Examples
+--------
+
+>>> df = DataFrame([['a', 1], ['a', 2], ['b', 1], ['b', 2]],
+                   columns=['A', 'B'])
+>>> df.groupby('A').tail(1)
+       A  B
+    1  a  2
+    3  b  2
+>>> df.groupby('A').head(1)
+       A  B
+    0  a  1
+    2  b  1"""
         obj = self._selected_obj
         rng = np.arange(0, -self.grouper._max_groupsize, -1, dtype='int64')
         in_tail = self._cumcount_array(rng, ascending=False) > -n
@@ -1059,8 +1098,7 @@ class GroupBy(PandasObject, SelectionMixin):
         return tail
 
     def _cumcount_array(self, arr=None, ascending=True):
-        """
-        arr is where cumcount gets its values from
+        """arr is where cumcount gets its values from
 
         note: this is currently implementing sort=False (though the default is sort=True)
               for groupby in general
@@ -2389,6 +2427,8 @@ class SeriesGroupBy(GroupBy):
 
         return ret
 
+    agg = aggregate
+
     def _aggregate_multiple_funcs(self, arg):
         if isinstance(arg, dict):
             columns = list(arg.keys())
@@ -2861,7 +2901,6 @@ class NDFrameGroupBy(GroupBy):
             obj = obj.swapaxes(0, 1)
         return obj
 
-    @Appender(SelectionMixin._agg_doc)
     def aggregate(self, arg, *args, **kwargs):
 
         _level = kwargs.pop('_level',None)
@@ -2891,6 +2930,8 @@ class NDFrameGroupBy(GroupBy):
 
         return result._convert(datetime=True)
 
+    agg = aggregate
+
     def _aggregate_generic(self, func, *args, **kwargs):
         if self.grouper.nkeys != 1:
             raise AssertionError('Number of keys must be 1')
@@ -3337,6 +3378,14 @@ class DataFrameGroupBy(NDFrameGroupBy):
 
     _block_agg_axis = 1
 
+    @Substitution(name='groupby')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
     def _gotitem(self, key, ndim, subset=None):
         """
         sub-classes to define
@@ -3500,6 +3549,14 @@ DataFrameGroupBy.boxplot = boxplot_frame_groupby
 
 class PanelGroupBy(NDFrameGroupBy):
 
+    @Substitution(name='groupby')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(PanelGroupBy, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
     def _iterate_slices(self):
         if self.axis == 0:
             # kludge
diff --git a/pandas/core/window.py b/pandas/core/window.py
index 208a9d862..2c311a05f 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -19,6 +19,19 @@ import pandas.algos as algos
 from pandas import compat
 from pandas.util.decorators import Substitution, Appender
 
+_shared_docs = dict()
+_doc_template = """
+
+Returns
+-------
+same type as input
+
+See also
+--------
+:func:`pandas.Series.%(name)s`
+:func:`pandas.DataFrame.%(name)s`
+"""
+
 class _Window(PandasObject, SelectionMixin):
     _attributes = ['window','min_periods','freq','center','how','win_type','axis']
     exclusions = set()
@@ -190,11 +203,14 @@ class _Window(PandasObject, SelectionMixin):
         if self.freq is not None and isinstance(self.obj, (Series, DataFrame)):
             self.obj = self.obj.resample(self.freq, how=self.how)
 
-    @Appender(SelectionMixin._agg_doc)
     def aggregate(self, arg, *args, **kwargs):
         result, how = self._aggregate(arg, *args, **kwargs)
+        if result is None:
+            return self.apply(arg, args=args, kwargs=kwargs)
         return result
 
+    agg = aggregate
+
 class Window(_Window):
 
     def _prep_window(self, **kwargs):
@@ -257,9 +273,21 @@ class Window(_Window):
 
         return self._wrap_results(results, blocks)
 
+    @Substitution(name='rolling')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(Window, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
     def sum(self, **kwargs):
         return self._apply_window(mean=False, **kwargs)
 
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
     def mean(self, **kwargs):
         return self._apply_window(mean=True, **kwargs)
 
@@ -286,7 +314,6 @@ class _Rolling(_Window):
         -------
         y : type of input
         """
-
         if center is None:
             center = self.center
         if window is None:
@@ -340,17 +367,10 @@ class _Rolling(_Window):
 
         return self._wrap_results(results, blocks)
 
-class Rolling(_Rolling):
+class _Rolling_and_Expanding(_Rolling):
 
+    _shared_docs['count'] = """%(name)s count of number of non-NaN observations inside provided window."""
     def count(self):
-        """
-        Rolling count of number of non-NaN observations inside provided window.
-
-        Returns
-        -------
-        same type as input
-        """
-
         obj = self._selected_obj
         window = self._get_window()
         window = min(window, len(obj)) if not self.center else window
@@ -366,16 +386,15 @@ class Rolling(_Rolling):
         result[result.isnull()] = 0
         return result
 
-    def apply(self, func, args=(), kwargs={}):
-        """
-        Moving function apply
+    _shared_docs['apply'] = """%(name)s function apply
 
-        Parameters
-        ----------
-        func : function
-            Must produce a single value from an ndarray input
-        *args and **kwargs are passed to the function
-        """
+Parameters
+----------
+func : function
+    Must produce a single value from an ndarray input
+*args and **kwargs are passed to the function"""
+    def apply(self, func, args=(), kwargs={}):
+        _level = kwargs.pop('_level',None)
         window = self._get_window()
         offset = _offset(window, self.center)
         def f(arg, window, min_periods):
@@ -384,62 +403,49 @@ class Rolling(_Rolling):
 
         return self._apply(f, center=False)
 
+    _shared_docs['sum'] = """%(name)s sum"""
     def sum(self):
-        """
-        Moving sum
-        """
         return self._apply('roll_sum')
 
-    def max(self, how='max'):
-        """
-        Moving max
+    _shared_docs['max'] = """%(name)s maximum
 
-        Parameters
-        ----------
-        how : string, default max
-          Method for down- or re-sampling
-        """
+Parameters
+----------
+how : string, default max
+    Method for down- or re-sampling"""
+    def max(self, how='max'):
         return self._apply('roll_max', how=how)
 
-    def min(self, how='min'):
-        """
-        Moving min
+    _shared_docs['min'] = """%(name)s minimum
 
-        Parameters
-        ----------
-        how : string, default min
-          Method for down- or re-sampling
-        """
+Parameters
+----------
+how : string, default min
+    Method for down- or re-sampling"""
+    def min(self, how='min'):
         return self._apply('roll_min', how=how)
 
+    _shared_docs['mean'] = """%(name)s mean"""
     def mean(self):
-        """
-        Moving mean
-        """
         return self._apply('roll_mean')
 
-    def median(self, how='median'):
-        """
-        Moving median
-
-        Parameters
-        ----------
-        how : string, default median
-          Method for down- or re-sampling
-        """
+    _shared_docs['median'] = """%(name)s median
 
+Parameters
+----------
+how : string, default median
+    Method for down- or re-sampling"""
+    def median(self, how='median'):
         return self._apply('roll_median_c', how=how)
 
-    def std(self, ddof=1):
-        """
-        Moving standard deviation
+    _shared_docs['std'] = """%(name)s standard deviation
 
-        Parameters
-        ----------
-        ddof : int, default 1
-           Delta Degrees of Freedom.  The divisor used in calculations
-           is ``N - ddof``, where ``N`` represents the number of elements.
-        """
+Parameters
+----------
+ddof : int, default 1
+    Delta Degrees of Freedom.  The divisor used in calculations
+    is ``N - ddof``, where ``N`` represents the number of elements."""
+    def std(self, ddof=1):
         window = self._get_window()
         def f(arg, *args, **kwargs):
             minp = _require_min_periods(1)(self.min_periods, window)
@@ -447,43 +453,35 @@ class Rolling(_Rolling):
 
         return self._apply(f, check_minp=_require_min_periods(1))
 
-    def var(self, ddof=1):
-        """
-        Moving variance
+    _shared_docs['var'] = """%(name)s variance
 
-        Parameters
-        ----------
-        ddof : int, default 1
-           Delta Degrees of Freedom.  The divisor used in calculations
-           is ``N - ddof``, where ``N`` represents the number of elements.
-        """
+Parameters
+----------
+ddof : int, default 1
+    Delta Degrees of Freedom.  The divisor used in calculations
+    is ``N - ddof``, where ``N`` represents the number of elements."""
+    def var(self, ddof=1):
         return self._apply('roll_var',
                            check_minp=_require_min_periods(1),
                            ddof=ddof)
 
+    _shared_docs['skew'] = """Unbiased %(name)s skewness"""
     def skew(self):
-        """
-        Unbiased moving skewness
-        """
         return self._apply('roll_skew',
                            check_minp=_require_min_periods(3))
 
+    _shared_docs['kurt'] = """Unbiased %(name)s kurtosis"""
     def kurt(self):
-        """
-        Unbiased moving kurtosis
-        """
         return self._apply('roll_kurt',
                            check_minp=_require_min_periods(4))
 
-    def quantile(self, quantile):
-        """
-        Rolling quantile
+    _shared_docs['quantile'] = """%(name)s quantile
 
-        Parameters
-        ----------
-        quantile : float
-            0 <= quantile <= 1
-        """
+Parameters
+----------
+quantile : float
+0 <= quantile <= 1"""
+    def quantile(self, quantile):
         window = self._get_window()
         def f(arg, *args, **kwargs):
             minp = _use_window(self.min_periods, window)
@@ -491,24 +489,22 @@ class Rolling(_Rolling):
 
         return self._apply(f)
 
+    _shared_docs['cov'] = """%(name)s sample covariance
+
+Parameters
+----------
+other : Series, DataFrame, or ndarray, optional
+    if not supplied then will default to self and produce pairwise output
+pairwise : bool, default False
+    If False then only matching columns between self and other will be used and
+    the output will be a DataFrame.
+    If True then all pairwise combinations will be calculated and the output
+    will be a Panel in the case of DataFrame inputs. In the case of missing
+    elements, only complete pairwise observations will be used.
+ddof : int, default 1
+    Delta Degrees of Freedom.  The divisor used in calculations
+    is ``N - ddof``, where ``N`` represents the number of elements."""
     def cov(self, other=None, pairwise=False, ddof=1):
-        """
-        Moving sample covariance
-
-        Parameters
-        ----------
-        other : Series, DataFrame, or ndarray, optional
-            if not supplied then will default to self and produce pairwise output
-        pairwise : bool, default False
-            If False then only matching columns between self and other will be used and
-            the output will be a DataFrame.
-            If True then all pairwise combinations will be calculated and the output
-            will be a Panel in the case of DataFrame inputs. In the case of missing
-            elements, only complete pairwise observations will be used.
-        ddof : int, default 1
-            Delta Degrees of Freedom.  The divisor used in calculations
-           is ``N - ddof``, where ``N`` represents the number of elements.
-        """
         if other is None:
             other = self._selected_obj
             pairwise = True
@@ -522,22 +518,20 @@ class Rolling(_Rolling):
             return (mean(X * Y) - mean(X) * mean(Y)) * bias_adj
         return _flex_binary_moment(self._selected_obj, other._selected_obj, _get_cov, pairwise=bool(pairwise))
 
+    _shared_docs['corr'] = """
+%(name)s sample correlation
+
+Parameters
+----------
+other : Series, DataFrame, or ndarray, optional
+    if not supplied then will default to self and produce pairwise output
+pairwise : bool, default False
+    If False then only matching columns between self and other will be used and
+    the output will be a DataFrame.
+    If True then all pairwise combinations will be calculated and the output
+    will be a Panel in the case of DataFrame inputs. In the case of missing
+    elements, only complete pairwise observations will be used."""
     def corr(self, other=None, pairwise=False):
-        """
-        Moving sample correlation
-
-        Parameters
-        ----------
-        other : Series, DataFrame, or ndarray, optional
-            if not supplied then will default to self and produce pairwise output
-        pairwise : bool, default False
-            If False then only matching columns between self and other will be used and
-            the output will be a DataFrame.
-            If True then all pairwise combinations will be calculated and the output
-            will be a Panel in the case of DataFrame inputs. In the case of missing
-            elements, only complete pairwise observations will be used.
-        """
-
         if other is None:
             other = self._selected_obj
             pairwise = True
@@ -557,7 +551,101 @@ class Rolling(_Rolling):
             return a.cov(b) / (a.std() * b.std())
         return _flex_binary_moment(self._selected_obj, other._selected_obj, _get_corr, pairwise=bool(pairwise))
 
-class Expanding(Rolling):
+class Rolling(_Rolling_and_Expanding):
+
+    @Substitution(name='rolling')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(Rolling, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['count'])
+    def count(self):
+        return super(Rolling, self).count()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['apply'])
+    def apply(self, func, args=(), kwargs={}):
+        return super(Rolling, self).apply(func, args=args, kwargs=kwargs)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['sum'])
+    def sum(self):
+        return super(Rolling, self).sum()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['max'])
+    def max(self, how='max'):
+        return super(Rolling, self).max(how=how)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['min'])
+    def min(self, how='min'):
+        return super(Rolling, self).min()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['mean'])
+    def mean(self):
+        return super(Rolling, self).mean()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['median'])
+    def median(self, how='median'):
+        return super(Rolling, self).median(how=how)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['std'])
+    def std(self, ddof=1):
+        return super(Rolling, self).std(ddof=ddof)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['var'])
+    def var(self, ddof=1):
+        return super(Rolling, self).var(ddof=ddof)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['skew'])
+    def skew(self):
+        return super(Rolling, self).skew()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['kurt'])
+    def kurt(self):
+        return super(Rolling, self).kurt()
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['quantile'])
+    def quantile(self, quantile):
+        return super(Rolling, self).quantile(quantile=quantile)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['cov'])
+    def cov(self, other=None, pairwise=False, ddof=1):
+        return super(Rolling, self).cov(other=other, pairwise=pairwise, ddof=ddof)
+
+    @Substitution(name='rolling')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['corr'])
+    def corr(self, other=None, pairwise=False):
+        return super(Rolling, self).corr(other=other, pairwise=pairwise)
+
+class Expanding(_Rolling_and_Expanding):
     _attributes = ['min_periods','freq','center','how','axis']
 
     @property
@@ -570,6 +658,98 @@ class Expanding(Rolling):
             return max(len(obj), self.min_periods) if self.min_periods else len(obj)
         return max((len(obj) + len(obj)), self.min_periods) if self.min_periods else (len(obj) + len(obj))
 
+    @Substitution(name='expanding')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(Expanding, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['count'])
+    def count(self):
+        return super(Expanding, self).count()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['apply'])
+    def apply(self, func, args=(), kwargs={}):
+        return super(Expanding, self).apply(func, args=args, kwargs=kwargs)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['sum'])
+    def sum(self):
+        return super(Expanding, self).sum()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['max'])
+    def max(self, how='max'):
+        return super(Expanding, self).max(how=how)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['min'])
+    def min(self, how='min'):
+        return super(Expanding, self).min()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['mean'])
+    def mean(self):
+        return super(Expanding, self).mean()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['median'])
+    def median(self, how='median'):
+        return super(Expanding, self).median(how=how)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['std'])
+    def std(self, ddof=1):
+        return super(Expanding, self).std(ddof=ddof)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['var'])
+    def var(self, ddof=1):
+        return super(Expanding, self).var(ddof=ddof)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['skew'])
+    def skew(self):
+        return super(Expanding, self).skew()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['kurt'])
+    def kurt(self):
+        return super(Expanding, self).kurt()
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['quantile'])
+    def quantile(self, quantile):
+        return super(Expanding, self).quantile(quantile=quantile)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['cov'])
+    def cov(self, other=None, pairwise=False, ddof=1):
+        return super(Expanding, self).cov(other=other, pairwise=pairwise, ddof=ddof)
+
+    @Substitution(name='expanding')
+    @Appender(_doc_template)
+    @Appender(_shared_docs['corr'])
+    def corr(self, other=None, pairwise=False):
+        return super(Expanding, self).corr(other=other, pairwise=pairwise)
+
 class EWM(_Rolling):
     _attributes = ['com','min_periods','freq','adjust','how','ignore_na','axis']
 
@@ -589,9 +769,16 @@ class EWM(_Rolling):
     def _constructor(self):
         return EWM
 
+    @Substitution(name='ewm')
+    @Appender(SelectionMixin._agg_doc)
+    @Appender(SelectionMixin._see_also_template)
+    def aggregate(self, arg, *args, **kwargs):
+        return super(EWM, self).aggregate(arg, *args, **kwargs)
+
+    agg = aggregate
+
     def _apply(self, func, **kwargs):
-        """
-        Rolling statistical measure using supplied function. Designed to be
+        """Rolling statistical measure using supplied function. Designed to be
         used with passed-in Cython array-based functions.
 
         Parameters
@@ -628,15 +815,16 @@ class EWM(_Rolling):
 
         return self._wrap_results(results, blocks)
 
+    @Substitution(name='ewm')
+    @Appender(_doc_template)
     def mean(self):
-        """
-        exponential weighted moving average
-        """
+        """exponential weighted moving average"""
         return self._apply('ewma')
 
+    @Substitution(name='ewm')
+    @Appender(_doc_template)
     def std(self, bias=False):
-        """
-        exponential weighted moving stddev
+        """exponential weighted moving stddev
 
         Parameters
         ----------
@@ -646,9 +834,10 @@ class EWM(_Rolling):
         return _zsqrt(self.var(bias=bias))
     vol=std
 
+    @Substitution(name='ewm')
+    @Appender(_doc_template)
     def var(self, bias=False):
-        """
-        exponential weighted moving average
+        """exponential weighted moving average
 
         Parameters
         ----------
@@ -666,9 +855,10 @@ class EWM(_Rolling):
 
         return self._apply(f)
 
+    @Substitution(name='ewm')
+    @Appender(_doc_template)
     def cov(self, other=None, pairwise=False, bias=False):
-        """
-        exponential weighted sample covariance
+        """exponential weighted sample covariance
 
         Parameters
         ----------
@@ -702,9 +892,10 @@ class EWM(_Rolling):
 
         return _flex_binary_moment(self._selected_obj, other._selected_obj, _get_cov, pairwise=bool(pairwise))
 
+    @Substitution(name='ewm')
+    @Appender(_doc_template)
     def corr(self, other=None, pairwise=False):
-        """
-        exponential weighted sample correlation
+        """exponential weighted sample correlation
 
         Parameters
         ----------
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index 1aa9ccf4b..41d2c8fa8 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -160,6 +160,14 @@ class TestApi(Base):
                                                       ('B','rb','mean'),('B','rb','std')])
         compare(result, expected)
 
+
+        # passed lambda
+        result = r.agg({'A' : np.sum,
+                        'B' : lambda x: np.std(x, ddof=1)})
+        rcustom = r['B'].apply(lambda x: np.std(x,ddof=1))
+        expected = pd.concat([a_sum,rcustom],axis=1)
+        compare(result, expected)
+
 class TestMoments(Base):
 
     def setUp(self):
