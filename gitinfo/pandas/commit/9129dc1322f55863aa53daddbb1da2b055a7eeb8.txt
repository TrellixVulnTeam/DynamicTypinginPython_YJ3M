commit 9129dc1322f55863aa53daddbb1da2b055a7eeb8
Author: jreback <jeff@reback.net>
Date:   Wed Aug 14 21:02:36 2013 -0400

    DOC: updated v0.13.0/release.rst for Internal Refactoring changes
    
    TST: additional test for series dtype conversion with where (and fix!)
    
    DOC: update docstrings in to_json/to_hdf/pd.read_hdf
    
    BLD: ujson rebase issue fixed

diff --git a/doc/source/dsintro.rst b/doc/source/dsintro.rst
index a913bdc35..397a3ab79 100644
--- a/doc/source/dsintro.rst
+++ b/doc/source/dsintro.rst
@@ -48,7 +48,7 @@ Series
 
    In 0.13.0 ``Series`` has internaly been refactored to no longer sub-class ``ndarray``
    but instead subclass ``NDFrame``, similarly to the rest of the pandas containers. This should be
-   a transparent change with only very limited API implications (See the :ref:`release notes <release.refactoring_0_13_0>`)
+   a transparent change with only very limited API implications (See the :ref:`Internal Refactoring<whatsnew_0130.refactoring>`)
 
 :class:`Series` is a one-dimensional labeled array capable of holding any data
 type (integers, strings, floating point numbers, Python objects, etc.). The axis
diff --git a/doc/source/release.rst b/doc/source/release.rst
index e0a48c552..390c6e857 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -117,31 +117,32 @@ pandas 0.13
 
 **Internal Refactoring**
 
-.. _release.refactoring_0_13_0:
-
 In 0.13.0 there is a major refactor primarily to subclass ``Series`` from ``NDFrame``,
 which is the base class currently for ``DataFrame`` and ``Panel``, to unify methods
-and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`4080`,:issue:`3862`,:issue:`816`)
+and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`4080`, :issue:`3862`, :issue:`816`)
+See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
 
 - Refactor of series.py/frame.py/panel.py to move common code to generic.py
-  - added _setup_axes to created generic NDFrame structures
+
+  - added ``_setup_axes`` to created generic NDFrame structures
   - moved methods
 
-    - from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop
-    - __iter__,keys,__contains__,__len__,__neg__,__invert__
-    - convert_objects,as_blocks,as_matrix,values
-    - __getstate__,__setstate__ (though compat remains in frame/panel)
-    - __getattr__,__setattr__
-    - _indexed_same,reindex_like,reindex,align,where,mask
-    - fillna,replace
-    - filter (also added axis argument to selectively filter on a different axis)
-    - reindex,reindex_axis (which was the biggest change to make generic)
-    - truncate (moved to become part of ``NDFrame``)
+    - ``from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop``
+    - ``__iter__,keys,__contains__,__len__,__neg__,__invert__``
+    - ``convert_objects,as_blocks,as_matrix,values``
+    - ``__getstate__,__setstate__`` (compat remains in frame/panel)
+    - ``__getattr__,__setattr__``
+    - ``_indexed_same,reindex_like,align,where,mask``
+    - ``fillna,replace`` (``Series`` replace is now consistent with ``DataFrame``)
+    - ``filter`` (also added axis argument to selectively filter on a different axis)
+    - ``reindex,reindex_axis`` (which was the biggest change to make generic)
+    - ``truncate`` (moved to become part of ``NDFrame``)
 
 - These are API changes which make ``Panel`` more consistent with ``DataFrame``
-  - swapaxes on a Panel with the same axes specified now return a copy
+
+  - ``swapaxes`` on a ``Panel`` with the same axes specified now return a copy
   - support attribute access for setting
-  - filter supports same api as original DataFrame filter
+  - filter supports same api as original ``DataFrame`` filter
 
 - Reindex called with no arguments will now return a copy of the input object
 
@@ -149,11 +150,9 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
   There are several minor changes that affect the API.
 
   - numpy functions that do not support the array interface will now
-    return ``ndarrays`` rather than series, e.g. ``np.diff`` and ``np.where``
+    return ``ndarrays`` rather than series, e.g. ``np.diff`` and ``np.ones_like``
   - ``Series(0.5)`` would previously return the scalar ``0.5``, this is no
     longer supported
-  - several methods from frame/series have moved to ``NDFrame``
-    (convert_objects,where,mask)
   - ``TimeSeries`` is now an alias for ``Series``. the property ``is_time_series``
     can be used to distinguish (if desired)
 
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index d834fb9a0..9776c3e46 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -6,6 +6,12 @@ v0.13.0 (August ??, 2013)
 This is a major release from 0.12.0 and includes several new features and
 enhancements along with a large number of bug fixes.
 
+.. warning::
+
+   In 0.13.0 ``Series`` has internaly been refactored to no longer sub-class ``ndarray``
+   but instead subclass ``NDFrame``, similarly to the rest of the pandas containers. This should be
+   a transparent change with only very limited API implications. See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
+
 API changes
 ~~~~~~~~~~~
 
@@ -134,32 +140,61 @@ Enhancements
          from pandas import offsets
          td + offsets.Minute(5) + offsets.Milli(5)
 
+.. _whatsnew_0130.refactoring:
+
 Internal Refactoring
 ~~~~~~~~~~~~~~~~~~~~
 
 In 0.13.0 there is a major refactor primarily to subclass ``Series`` from ``NDFrame``,
 which is the base class currently for ``DataFrame`` and ``Panel``, to unify methods
-and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`4080`,:issue:`3862`,:issue:`816`)
+and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`4080`, :issue:`3862`, :issue:`816`)
+
+.. warning::
+
+   There are two potential incompatibilities from < 0.13.0
+
+   - Using certain numpy functions would previously return a ``Series`` if passed a ``Series``
+     as an argument. This seems only to affect ``np.ones_like``, ``np.empty_like``, and
+     ``np.diff``. These now return ``ndarrays``.
+
+     .. ipython:: python
+
+        s = Series([1,2,3,4])
+
+        # numpy usage
+        np.ones_like(s)
+        np.diff(s)
+
+        # pandonic usage
+        Series(1,index=s.index)
+        s.diff()
+
+   - Passing a ``Series`` directly to a cython function expecting an ``ndarray`` type will no
+     long work directly, you must pass ``Series.values``, See :ref:`Enhancing Performance<enhancingperf.ndarray>`
+
+   - ``Series(0.5)`` would previously return the scalar ``0.5``, instead this will return a 1-element ``Series``
 
 - Refactor of series.py/frame.py/panel.py to move common code to generic.py
-  - added _setup_axes to created generic NDFrame structures
+
+  - added ``_setup_axes`` to created generic NDFrame structures
   - moved methods
 
-    - from_axes,_wrap_array,axes,ix,shape,empty,swapaxes,transpose,pop
-    - __iter__,keys,__contains__,__len__,__neg__,__invert__
-    - convert_objects,as_blocks,as_matrix,values
-    - __getstate__,__setstate__ (though compat remains in frame/panel)
-    - __getattr__,__setattr__
-    - _indexed_same,reindex_like,reindex,align,where,mask
-    - fillna,replace
-    - filter (also added axis argument to selectively filter on a different axis)
-    - reindex,reindex_axis (which was the biggest change to make generic)
-    - truncate (moved to become part of ``NDFrame``)
+    - ``from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop``
+    - ``__iter__,keys,__contains__,__len__,__neg__,__invert__``
+    - ``convert_objects,as_blocks,as_matrix,values``
+    - ``__getstate__,__setstate__`` (compat remains in frame/panel)
+    - ``__getattr__,__setattr__``
+    - ``_indexed_same,reindex_like,align,where,mask``
+    - ``fillna,replace`` (``Series`` replace is now consistent with ``DataFrame``)
+    - ``filter`` (also added axis argument to selectively filter on a different axis)
+    - ``reindex,reindex_axis`` (which was the biggest change to make generic)
+    - ``truncate`` (moved to become part of ``NDFrame``)
 
 - These are API changes which make ``Panel`` more consistent with ``DataFrame``
-  - swapaxes on a Panel with the same axes specified now return a copy
+
+  - ``swapaxes`` on a ``Panel`` with the same axes specified now return a copy
   - support attribute access for setting
-  - filter supports same api as original DataFrame filter
+  - filter supports same api as original ``DataFrame`` filter
 
 - Reindex called with no arguments will now return a copy of the input object
 
@@ -167,11 +202,9 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
   There are several minor changes that affect the API.
 
   - numpy functions that do not support the array interface will now
-    return ``ndarrays`` rather than series, e.g. ``np.diff`` and ``np.where``
+    return ``ndarrays`` rather than series, e.g. ``np.diff`` and ``np.ones_like``
   - ``Series(0.5)`` would previously return the scalar ``0.5``, this is no
     longer supported
-  - several methods from frame/series have moved to ``NDFrame``
-    (convert_objects,where,mask)
   - ``TimeSeries`` is now an alias for ``Series``. the property ``is_time_series``
     can be used to distinguish (if desired)
 
@@ -199,7 +232,7 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
 - Internal type checking is now done via a suite of generated classes, allowing ``isinstance(value, klass)``
   without having to directly import the klass, courtesy of @jtratner
 
-- Bug in Series update where the parent frame is not updating its cached based on
+- Bug in Series update where the parent frame is not updating its cache based on
   changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)
 
 - Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index ab8cab011..91c5804d4 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -536,51 +536,11 @@ class NDFrame(PandasObject):
     #----------------------------------------------------------------------
     # IO
 
-    def to_pickle(self, path):
-        """
-        Pickle (serialize) object to input file path
-
-        Parameters
-        ----------
-        path : string
-            File path
-        """
-        from pandas.io.pickle import to_pickle
-        return to_pickle(self, path)
-
-    def save(self, path):  # TODO remove in 0.13
-        import warnings
-        from pandas.io.pickle import to_pickle
-        warnings.warn("save is deprecated, use to_pickle", FutureWarning)
-        return to_pickle(self, path)
-
-    def load(self, path):  # TODO remove in 0.13
-        import warnings
-        from pandas.io.pickle import read_pickle
-        warnings.warn("load is deprecated, use pd.read_pickle", FutureWarning)
-        return read_pickle(path)
-
-    def to_hdf(self, path_or_buf, key, **kwargs):
-        """ activate the HDFStore """
-        from pandas.io import pytables
-        return pytables.to_hdf(path_or_buf, key, self, **kwargs)
-
-    def to_clipboard(self):
-        """
-        Attempt to write text representation of object to the system clipboard
-
-        Notes
-        -----
-        Requirements for your platform
-          - Linux: xclip, or xsel (with gtk or PyQt4 modules)
-          - Windows:
-          - OS X:
-        """
-        from pandas.io import clipboard
-        clipboard.to_clipboard(self)
+    #----------------------------------------------------------------------
+    # I/O Methods
 
     def to_json(self, path_or_buf=None, orient=None, date_format='epoch',
-                double_precision=10, force_ascii=True):
+                double_precision=10, force_ascii=True, date_unit='ms'):
         """
         Convert the object to a JSON string.
 
@@ -616,18 +576,96 @@ class NDFrame(PandasObject):
         double_precision : The number of decimal places to use when encoding
             floating point values, default 10.
         force_ascii : force encoded string to be ASCII, default True.
+        date_unit : string, default 'ms' (milliseconds)
+            The time unit to encode to, governs timestamp and ISO8601
+            precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,
+            microsecond, and nanosecond respectively.
 
         Returns
         -------
-        result : a JSON compatible string written to the path_or_buf;
-                 if the path_or_buf is none, return a StringIO of the result
+        same type as input object with filtered info axis
 
         """
 
         from pandas.io import json
         return json.to_json(
-            path_or_buf=path_or_buf, obj=self, orient=orient, date_format=date_format,
-            double_precision=double_precision, force_ascii=force_ascii)
+            path_or_buf=path_or_buf,
+            obj=self, orient=orient,
+            date_format=date_format,
+            double_precision=double_precision,
+            force_ascii=force_ascii,
+            date_unit=date_unit)
+
+    def to_hdf(self, path_or_buf, key, **kwargs):
+        """ activate the HDFStore
+
+        Parameters
+        ----------
+        path_or_buf : the path (string) or buffer to put the store
+        key : string, an indentifier for the group in the store
+        mode : optional, {'a', 'w', 'r', 'r+'}, default 'a'
+
+          ``'r'``
+              Read-only; no data can be modified.
+          ``'w'``
+              Write; a new file is created (an existing file with the same
+              name would be deleted).
+          ``'a'``
+              Append; an existing file is opened for reading and writing,
+              and if the file does not exist it is created.
+          ``'r+'``
+              It is similar to ``'a'``, but the file must already exist.
+        complevel : int, 1-9, default 0
+            If a complib is specified compression will be applied
+            where possible
+        complib : {'zlib', 'bzip2', 'lzo', 'blosc', None}, default None
+            If complevel is > 0 apply compression to objects written
+            in the store wherever possible
+        fletcher32 : bool, default False
+            If applying compression use the fletcher32 checksum
+
+        """
+
+        from pandas.io import pytables
+        return pytables.to_hdf(path_or_buf, key, self, **kwargs)
+
+    def to_pickle(self, path):
+        """
+        Pickle (serialize) object to input file path
+
+        Parameters
+        ----------
+        path : string
+            File path
+        """
+        from pandas.io.pickle import to_pickle
+        return to_pickle(self, path)
+
+    def save(self, path):  # TODO remove in 0.13
+        import warnings
+        from pandas.io.pickle import to_pickle
+        warnings.warn("save is deprecated, use to_pickle", FutureWarning)
+        return to_pickle(self, path)
+
+    def load(self, path):  # TODO remove in 0.13
+        import warnings
+        from pandas.io.pickle import read_pickle
+        warnings.warn("load is deprecated, use pd.read_pickle", FutureWarning)
+        return read_pickle(path)
+
+    def to_clipboard(self):
+        """
+        Attempt to write text representation of object to the system clipboard
+
+        Notes
+        -----
+        Requirements for your platform
+          - Linux: xclip, or xsel (with gtk or PyQt4 modules)
+          - Windows:
+          - OS X:
+        """
+        from pandas.io import clipboard
+        clipboard.to_clipboard(self)
 
     #----------------------------------------------------------------------
     # Fancy Indexing
@@ -2542,77 +2580,6 @@ class NDFrame(PandasObject):
 
         return new_obj
 
-    #----------------------------------------------------------------------
-    # I/O Methods
-
-    def to_json(self, path_or_buf=None, orient=None, date_format='epoch',
-                double_precision=10, force_ascii=True, date_unit='ms'):
-        """
-        Parameters
-        ----------
-        columns : array-like
-            Specific column order
-        date_format : string, default 'epoch'
-            type of date conversion, 'epoch' for timestamp, 'iso' for ISO8601
-        double_precision : The number of decimal places to use when encoding
-            floating point values, default 10.
-        force_ascii : force encoded string to be ASCII, default True.
-        date_unit : string, default 'ms' (milliseconds)
-            The time unit to encode to, governs timestamp and ISO8601
-            precision.  One of 's', 'ms', 'us', 'ns' for second, millisecond,
-            microsecond, and nanosecond respectively.
-
-        Returns
-        -------
-        same type as input object with filtered info axis
-
-        """
-
-        from pandas.io import json
-        return json.to_json(
-            path_or_buf=path_or_buf,
-            obj=self, orient=orient,
-            date_format=date_format,
-            double_precision=double_precision,
-            force_ascii=force_ascii,
-            date_unit=date_unit)
-
-    def to_hdf(self, path_or_buf, key, **kwargs):
-        """ activate the HDFStore
-
-        Parameters
-        ----------
-        path_or_buf: the path or buffer to put the store
-        key: string, an indentifier for the group in the store
-
-        """
-
-        from pandas.io import pytables
-        return pytables.to_hdf(path_or_buf, key, self, **kwargs)
-
-    def to_pickle(self, path):
-        """
-        Pickle (serialize) object to input file path
-
-        Parameters
-        ----------
-        path : string
-            File path
-        """
-
-        from pandas.io.pickle import to_pickle
-        return to_pickle(self, path)
-
-    def save(self, path):  # TODO remove in 0.13
-        from pandas.io.pickle import to_pickle
-        warnings.warn("save is deprecated, use to_pickle", FutureWarning)
-        return to_pickle(self, path)
-
-    def load(self, path):  # TODO remove in 0.13
-        from pandas.io.pickle import read_pickle
-        warnings.warn("load is deprecated, use pd.read_pickle", FutureWarning)
-        return read_pickle(path)
-
 # install the indexerse
 for _name, _indexer in indexing.get_indexers_list():
     NDFrame._create_indexer(_name, _indexer)
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 675b2f5e1..f1578303e 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -745,8 +745,9 @@ class Block(PandasObject):
                     return result
 
         # see if we can operate on the entire block, or need item-by-item
+        # or if we are a single block (ndim == 1)
         result = func(cond, values, other)
-        if self._can_hold_na:
+        if self._can_hold_na or self.ndim == 1:
 
             if not isinstance(result, np.ndarray):
                 raise TypeError('Could not compare [%s] with block values'
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 8a98bb6c1..aee839c35 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -206,7 +206,29 @@ def to_hdf(path_or_buf, key, value, mode=None, complevel=None, complib=None, app
         f(path_or_buf)
 
 def read_hdf(path_or_buf, key, **kwargs):
-    """ read from the store, closeit if we opened it """
+    """ read from the store, closeit if we opened it
+
+        Retrieve pandas object stored in file, optionally based on where
+        criteria
+
+        Parameters
+        ----------
+        path_or_buf : path (string), or buffer to read from
+        key : group identifier in the store
+        where : list of Term (or convertable) objects, optional
+        start : optional, integer (defaults to None), row number to start selection
+        stop  : optional, integer (defaults to None), row number to stop selection
+        columns : optional, a list of columns that if not None, will limit the return columns
+        iterator : optional, boolean, return an iterator, default False
+        chunksize : optional, nrows to include in iteration, return an iterator
+        auto_close : optional, boolean, should automatically close the store when finished, default is False
+
+        Returns
+        -------
+        The selected object
+
+        """
+
     f = lambda store, auto_close: store.select(key, auto_close=auto_close, **kwargs)
 
     if isinstance(path_or_buf, compat.string_types):
@@ -468,6 +490,10 @@ class HDFStore(StringMixin):
         chunksize : nrows to include in iteration, return an iterator
         auto_close : boolean, should automatically close the store when finished, default is False
 
+        Returns
+        -------
+        The selected object
+
         """
         group = self.get_node(key)
         if group is None:
diff --git a/pandas/src/ujson/python/objToJSON.c b/pandas/src/ujson/python/objToJSON.c
index d413ece44..22f9cf8d7 100644
--- a/pandas/src/ujson/python/objToJSON.c
+++ b/pandas/src/ujson/python/objToJSON.c
@@ -1456,8 +1456,8 @@ ISITERABLE:
     {
       PRINTMARK();
       tc->type = JT_OBJECT;
-      pc->columnLabelsLen = PyArray_SIZE(obj);
-      pc->columnLabels = NpyArr_encodeLabels((PyArrayObject*) PyObject_GetAttrString(PyObject_GetAttrString(obj, "index"), "values"), (JSONObjectEncoder*) enc, pc->columnLabelsLen);
+      pc->columnLabelsLen = PyArray_DIM(pc->newObj, 0);
+      pc->columnLabels = NpyArr_encodeLabels((PyArrayObject*) PyObject_GetAttrString(obj, "index"), (JSONObjectEncoder*) enc, pc->columnLabelsLen);
       if (!pc->columnLabels)
       {
         goto INVALID;
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 7ee432416..9d6311b7e 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1233,6 +1233,12 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
             s[mask] = [0] * 5
         self.assertRaises(ValueError, f)
 
+        # dtype changes
+        s = Series([1,2,3,4])
+        result = s.where(s>2,np.nan)
+        expected = Series([np.nan,np.nan,3,4])
+        assert_series_equal(result, expected)
+
     def test_where_broadcast(self):
         # Test a variety of differently sized series
         for size in range(2, 6):
