commit 9ad40fbf147a103fabb514a55c1318d7ffba6e32
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Jan 1 22:47:32 2012 -0500

    BUG: numpy.integer type-checking in indexing, groupby test coverage

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index da8851597..af6f433a0 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -151,10 +151,6 @@ class GroupBy(object):
     def _group_shape(self):
         return tuple(len(ping.counts) for ping in self.groupings)
 
-    @property
-    def _agg_stride_shape(self):
-        raise NotImplementedError
-
     def __getattr__(self, attr):
         if hasattr(self.obj, attr):
             return self._make_wrapper(attr)
@@ -228,13 +224,10 @@ class GroupBy(object):
                 yield it
 
     def _multi_iter(self):
-        tipo = type(self.obj)
         data = self.obj
         if (isinstance(self.obj, NDFrame) and
             not isinstance(self.obj, DataFrame)):
             data = self.obj._data
-        elif isinstance(self.obj, Series):
-            tipo = Series
 
         id_list = [ping.ids for ping in self.groupings]
         shape = tuple(len(ids) for ids in id_list)
@@ -357,12 +350,12 @@ class GroupBy(object):
 
         output = {}
         for name, obj in self._iterate_slices():
-            if issubclass(obj.dtype.type, (np.number, np.bool_)):
-                if obj.dtype != np.float64:
-                    obj = obj.astype('f8')
-            else:
+            if not issubclass(obj.dtype.type, (np.number, np.bool_)):
                 continue
 
+            if obj.dtype != np.float64:
+                obj = obj.astype('f8')
+
             result, counts =  cython_aggregate(obj, group_index, shape,
                                                how=how)
             result = result.ravel()
@@ -611,7 +604,8 @@ class Grouping(object):
         if self._group_index is None:
             ids = self.ids
             values = np.arange(len(self.ids), dtype='O')
-            self._group_index = Index(lib.lookup_values(values, ids))
+            self._group_index = Index(lib.lookup_values(values, ids),
+                                      name=self.name)
         return self._group_index
 
     def _make_labels(self):
@@ -686,10 +680,6 @@ class SeriesGroupBy(GroupBy):
 
     _cythonized_methods = set(['add', 'mean'])
 
-    @property
-    def _agg_stride_shape(self):
-        return ()
-
     def aggregate(self, func_or_funcs, *args, **kwargs):
         """
         Apply aggregation function or functions to groups, yielding most likely
@@ -775,10 +765,8 @@ class SeriesGroupBy(GroupBy):
         return DataFrame(results)
 
     def _wrap_aggregated_output(self, output, mask):
-        if isinstance(output, dict):
-            # sort of a kludge
-            output = output[self.name]
-
+        # sort of a kludge
+        output = output[self.name]
         index = self._get_multi_index(mask)
         return Series(output, index=index)
 
@@ -875,21 +863,6 @@ def _ravel_names(axes, shape):
 
 class DataFrameGroupBy(GroupBy):
 
-    @property
-    def _agg_stride_shape(self):
-        if self._column is not None:
-            # ffffff
-            return 1,
-
-        if self.axis == 0:
-            n = len(self.obj.columns)
-        else:
-            n = len(self.obj.index)
-
-        n -= len(self.exclusions)
-
-        return n,
-
     def __getitem__(self, key):
         if self._column is not None:
             raise Exception('Column %s already selected' % self._column)
@@ -988,6 +961,8 @@ class DataFrameGroupBy(GroupBy):
         return result
 
     def _aggregate_generic(self, func, *args, **kwargs):
+        assert(len(self.groupings) == 1)
+
         axis = self.axis
         obj = self._obj_with_exclusions
 
@@ -1008,13 +983,8 @@ class DataFrameGroupBy(GroupBy):
                     wrapper = lambda x: func(x, *args, **kwargs)
                     result[name] = data.apply(wrapper, axis=axis)
 
-        index_name = (self.groupings[0].name
-                      if len(self.groupings) == 1 else None)
-
         result_index = self.groupings[0].group_index
 
-        # result_index = Index(sorted(result), name=index_name)
-
         if result:
             if axis == 0:
                 result = DataFrame(result, index=obj.columns,
@@ -1051,21 +1021,19 @@ class DataFrameGroupBy(GroupBy):
     def _wrap_aggregated_output(self, output, mask):
         agg_axis = 0 if self.axis == 1 else 1
         agg_labels = self._obj_with_exclusions._get_axis(agg_axis)
-        if isinstance(output, dict):
-            if len(output) == len(agg_labels):
-                output_keys = agg_labels
-            else:
-                output_keys = sorted(output)
-                try:
-                    output_keys.sort()
-                except Exception:  # pragma: no cover
-                    pass
 
-                if isinstance(agg_labels, MultiIndex):
-                    output_keys = MultiIndex.from_tuples(output_keys,
-                                                         names=agg_labels.names)
-        else:
+        if len(output) == len(agg_labels):
             output_keys = agg_labels
+        else:
+            output_keys = sorted(output)
+            try:
+                output_keys.sort()
+            except Exception:  # pragma: no cover
+                pass
+
+            if isinstance(agg_labels, MultiIndex):
+                output_keys = MultiIndex.from_tuples(output_keys,
+                                                     names=agg_labels.names)
 
         if not self.as_index:
             result = DataFrame(output, columns=output_keys)
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 35446454f..248c9b820 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -2,6 +2,7 @@
 
 from pandas.core.common import _asarray_tuplesafe
 from pandas.core.index import Index, MultiIndex
+import pandas.core.common as com
 
 import numpy as np
 
@@ -153,7 +154,7 @@ class _NDFrameIndexer(object):
             is_int_index = _is_integer_index(labels)
 
             idx = key
-            if _is_int_like(key):
+            if com.is_integer(key):
                 if isinstance(labels, MultiIndex):
                     try:
                         return self._getitem_xs(key, axis=0)
@@ -168,7 +169,7 @@ class _NDFrameIndexer(object):
         else:
             labels = self.obj._get_axis(axis)
             lab = key
-            if _is_int_like(key) and not _is_integer_index(labels):
+            if com.is_integer(key) and not _is_integer_index(labels):
                 lab = labels[key]
             return self._getitem_xs(lab, axis=axis)
 
@@ -248,7 +249,7 @@ class _NDFrameIndexer(object):
 
                 return indexer
         else:
-            if _is_int_like(obj) and not is_int_index:
+            if com.is_integer(obj) and not is_int_index:
                 return obj
             return index.get_loc(obj)
 
@@ -394,10 +395,7 @@ def _is_integer_index(index):
     if len(index) == 0: # pragma: no cover
         return False
     else:
-        return _is_int_like(index[0])
-
-def _is_int_like(val):
-    return isinstance(val, (int, np.integer))
+        return com.is_integer(index[0])
 
 def _is_label_like(key):
     # select a label or row
@@ -412,7 +410,7 @@ def _is_label_slice(labels, obj):
             _ = labels.get_loc(x)
             return False
         except KeyError:
-            return isinstance(x, int) or x is None
+            return com.is_integer(x) or x is None
 
     return not crit(obj.start) or not crit(obj.stop)
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 8d6c68371..a149ec1ec 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -333,6 +333,11 @@ class TestGroupBy(unittest.TestCase):
         expected = grouped.sum()
         assert_series_equal(result, expected)
 
+    def test_series_index_name(self):
+        grouped = self.df.ix[:, ['C']].groupby(self.df['A'])
+        result = grouped.agg(lambda x: x.mean())
+        self.assertEqual(result.index.name, 'A')
+
     def test_frame_describe_multikey(self):
         grouped = self.tsframe.groupby([lambda x: x.year,
                                         lambda x: x.month])
@@ -482,6 +487,12 @@ class TestGroupBy(unittest.TestCase):
             groups[key] = gp
         self.assertEquals(len(groups), 2)
 
+        # axis = 1
+        three_levels = self.three_group.groupby(['A', 'B', 'C']).mean()
+        grouped = three_levels.T.groupby(axis=1, level=(1, 2))
+        for key, group in grouped:
+            pass
+
     def test_multi_iter_panel(self):
         wp = tm.makePanel()
         grouped = wp.groupby([lambda x: x.month, lambda x: x.weekday()],
@@ -679,6 +690,7 @@ class TestGroupBy(unittest.TestCase):
 
     def test_omit_nuisance(self):
         grouped = self.df.groupby('A')
+
         result = grouped.mean()
         expected = self.df.ix[:, ['A', 'C', 'D']].groupby('A').mean()
         assert_frame_equal(result, expected)
@@ -705,6 +717,25 @@ class TestGroupBy(unittest.TestCase):
         exp = grouped.mean()
         assert_frame_equal(agged, exp)
 
+    def test_empty_groups_corner(self):
+        # handle empty groups
+        df = DataFrame({'k1' : np.array(['b', 'b', 'b', 'a', 'a', 'a']),
+                        'k2' : np.array(['1', '1', '1', '2', '2', '2']),
+                        'k3' : ['foo', 'bar'] * 3,
+                        'v1' : np.random.randn(6),
+                        'v2' : np.random.randn(6)})
+
+        grouped = df.groupby(['k1', 'k2'])
+        result = grouped.agg(np.mean)
+        expected = grouped.mean()
+        assert_frame_equal(result, expected)
+
+        grouped = self.mframe[3:5].groupby(level=0)
+        agged = grouped.apply(lambda x: x.mean())
+        agged_A = grouped['A'].apply(np.mean)
+        assert_series_equal(agged['A'], agged_A)
+        self.assertEquals(agged.index.name, 'first')
+
     def test_apply_concat_preserve_names(self):
         grouped = self.three_group.groupby(['A', 'B'])
 
@@ -862,6 +893,16 @@ class TestGroupBy(unittest.TestCase):
         assert_frame_equal(result0, expected0)
         assert_frame_equal(result1, expected1)
 
+    def test_level_preserve_order(self):
+        grouped = self.mframe.groupby(level=0)
+        exp_labels = np.array([0, 0, 0, 1, 1, 2, 2, 3, 3, 3])
+        assert_almost_equal(grouped.groupings[0].labels, exp_labels)
+
+    def test_grouping_labels(self):
+        grouped = self.mframe.groupby(self.mframe.index.get_level_values(0))
+        exp_labels = np.array([2, 2, 2, 0, 0, 1, 1, 3, 3, 3])
+        assert_almost_equal(grouped.groupings[0].labels, exp_labels)
+
     def test_cython_fail_agg(self):
         dr = DateRange('1/1/2000', periods=50)
         ts = Series(['A', 'B', 'C', 'D', 'E'] * 10, index=dr)
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index ef99d7fbd..e249a0c98 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -280,6 +280,14 @@ class TestMultiLevel(unittest.TestCase):
         expected.columns = expected.columns.droplevel(0).droplevel(0)
         assert_frame_equal(result, expected)
 
+    def test_getitem_slice_not_sorted(self):
+        df = self.frame.sortlevel(1).T
+
+        # buglet with int typechecking
+        result = df.ix[:, :np.int32(3)]
+        expected = df.reindex(columns=df.columns[:3])
+        assert_frame_equal(result, expected)
+
     def test_setitem_change_dtype(self):
         dft = self.frame.T
         s = dft['foo', 'two']
diff --git a/scripts/git_code_churn.py b/scripts/git_code_churn.py
index ed1409f7e..7d3cb5731 100644
--- a/scripts/git_code_churn.py
+++ b/scripts/git_code_churn.py
@@ -103,14 +103,14 @@ if __name__ == '__main__':
         if path.endswith('.pyx') or path.endswith('.py'):
             file_include.append(path)
     commits_include = [sha for sha in churn.minor_axis
-                       if 'LF' not in hists[sha]]
+                       if 'LF' not in repo.messages[sha]]
     commits_include.remove('dcf3490')
 
     clean_churn = churn.reindex(major=file_include, minor=commits_include)
 
     by_commit = clean_churn.sum('major').sum(1)
 
-    by_date = by_commit.groupby(commits).sum()
+    by_date = by_commit.groupby(repo.commit_date).sum()
 
     by_date = by_date.drop([datetime(2011, 6, 10)])
 
