commit b8dae948311d0f07f46a6dfb1b39dd98ae27934f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Nov 19 23:53:17 2012 -0500

    BUG: fix issues with \r-delimited files in C tokenization code. close #2296

diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index bd137151d..e0b58f67c 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -265,6 +265,40 @@ a,b,c
         self.assertTrue((result[1] == exp[1]).all())
         self.assertTrue((result[2] == exp[2]).all())
 
+    def test_cr_delimited(self):
+        def _test(text, **kwargs):
+            nice_text = text.replace('\r', '\r\n')
+            result = TextReader(StringIO(text), **kwargs).read()
+            expected = TextReader(StringIO(nice_text), **kwargs).read()
+            assert_array_dicts_equal(result, expected)
+
+        data = 'a,b,c\r1,2,3\r4,5,6\r7,8,9\r10,11,12'
+        _test(data, delimiter=',')
+
+        data = 'a  b  c\r1  2  3\r4  5  6\r7  8  9\r10  11  12'
+        _test(data, delim_whitespace=True)
+
+        data = 'a,b,c\r1,2,3\r4,5,6\r,88,9\r10,11,12'
+        _test(data, delimiter=',')
+
+        sample = ('A,B,C,D,E,F,G,H,I,J,K,L,M,N,O\r'
+                  'AAAAA,BBBBB,0,0,0,0,0,0,0,0,0,0,0,0,0\r'
+                  ',BBBBB,0,0,0,0,0,0,0,0,0,0,0,0,0')
+        _test(sample, delimiter=',')
+
+        data = 'A  B  C\r  2  3\r4  5  6'
+        _test(data, delim_whitespace=True)
+
+    def test_empty_field_eof(self):
+        data = 'a,b,c\n1,2,3\n4,,'
+
+        result = TextReader(StringIO(data), delimiter=',').read()
+
+        expected = {0: np.array([1, 4]),
+                    1: np.array(['2', ''], dtype=object),
+                    2: np.array(['3', ''], dtype=object)}
+        assert_array_dicts_equal(result, expected)
+
 
 def assert_array_dicts_equal(left, right):
     for k, v in left.iteritems():
diff --git a/pandas/src/parse_helper.h b/pandas/src/parse_helper.h
index cbe8fb27a..02f3003cc 100644
--- a/pandas/src/parse_helper.h
+++ b/pandas/src/parse_helper.h
@@ -17,7 +17,7 @@ int to_double(char *item, double *p_value, char sci, char decimal)
   #define PyBytes_AS_STRING            PyString_AS_STRING
 #endif
 
-PANDAS_INLINE int floatify(PyObject* str, double *result) {
+int floatify(PyObject* str, double *result) {
     int status;
     char *data;
     PyObject* tmp = NULL;
diff --git a/pandas/src/parser/tokenizer.c b/pandas/src/parser/tokenizer.c
index 445ef0527..6929c7b26 100644
--- a/pandas/src/parser/tokenizer.c
+++ b/pandas/src/parser/tokenizer.c
@@ -377,7 +377,10 @@ int P_INLINE end_field(parser_t *self) {
     // set pointer and metadata
     self->words[self->words_len] = self->pword_start;
 
-    TRACE(("Saw word %s at: %d\n", self->pword_start, self->word_start))
+    TRACE(("Char diff: %d\n", self->pword_start - self->words[0]));
+
+    TRACE(("Saw word %s at: %d. Total: %d\n",
+           self->pword_start, self->word_start, self->words_len + 1))
 
     self->word_starts[self->words_len] = self->word_start;
     self->words_len++;
@@ -399,6 +402,9 @@ int P_INLINE end_line(parser_t *self) {
 
     fields = self->line_fields[self->lines];
 
+    TRACE(("Line end, nfields: %d\n", fields));
+
+
     if (self->lines > 0) {
         ex_fields = self->line_fields[self->lines - 1];
     }
@@ -524,9 +530,18 @@ int parser_buffer_bytes(parser_t *self, size_t nbytes) {
 
 //    printf("pushing %c\n", c);
 
+#if defined(VERBOSE)
+#define PUSH_CHAR(c)                                \
+    printf("Pushing %c, slen now: %d\n", c, slen);  \
+    *stream++ = c;                                  \
+    slen++;
+#else
 #define PUSH_CHAR(c)                           \
     *stream++ = c;                             \
     slen++;
+#endif
+
+
 
 // This is a little bit of a hack but works for now
 
@@ -538,12 +553,12 @@ int parser_buffer_bytes(parser_t *self, size_t nbytes) {
     stream = self->stream + self->stream_len;  \
     slen = self->stream_len;
 
-#define END_LINE()                                                      \
+#define END_LINE_STATE(STATE)                                           \
     self->stream_len = slen;                                            \
     if (end_line(self) < 0) {                                           \
         goto parsingerror;                                              \
     }                                                                   \
-    self->state = START_RECORD;                                         \
+    self->state = STATE;                                                \
     if (line_limit > 0 && self->lines == start_lines + line_limit) {    \
         goto linelimit;                                                 \
                                                                         \
@@ -551,6 +566,24 @@ int parser_buffer_bytes(parser_t *self, size_t nbytes) {
     stream = self->stream + self->stream_len;                           \
     slen = self->stream_len;
 
+#define END_LINE_AND_FIELD_STATE(STATE)                                 \
+    self->stream_len = slen;                                            \
+    if (end_line(self) < 0) {                                           \
+        goto parsingerror;                                              \
+    }                                                                   \
+    if (end_field(self) < 0) {                                          \
+        goto parsingerror;                                              \
+    }                                                                   \
+    stream = self->stream + self->stream_len;                           \
+    slen = self->stream_len;                                            \
+    self->state = STATE;                                                \
+    if (line_limit > 0 && self->lines == start_lines + line_limit) {    \
+        goto linelimit;                                                 \
+                                                                        \
+    }
+
+#define END_LINE() END_LINE_STATE(START_RECORD)
+
 #define IS_WHITESPACE(c) ((c == ' ' || c == '\t'))
 
 typedef int (*parser_op)(parser_t *self, size_t line_limit);
@@ -747,14 +780,15 @@ int tokenize_delimited(parser_t *self, size_t line_limit)
             if (c == '\n') {
                 END_LINE();
                 /* self->state = START_RECORD; */
+            } else if (c == self->delimiter){
+                // Handle \r-delimited files
+                END_LINE_AND_FIELD_STATE(START_FIELD);
             } else {
-                /* self->error_msg = ("new-line character seen in" */
-                /*                 " unquoted field - do you need" */
-                /*                 " to open the file in " */
-                /*                 "universal-newline mode?"); */
-                goto parsingerror;
+                PUSH_CHAR(c);
+                END_LINE_STATE(IN_FIELD);
             }
             break;
+
         default:
             break;
 
@@ -804,8 +838,9 @@ int tokenize_whitespace(parser_t *self, size_t line_limit)
         // Next character in file
         c = *buf++;
 
-        TRACE(("Iter: %d Char: %c Line %d field_count %d\n",
-               i, c, self->file_lines + 1, self->line_fields[self->lines]));
+        TRACE(("Iter: %d Char: %c Line %d field_count %d, state %d\n",
+               i, c, self->file_lines + 1, self->line_fields[self->lines],
+               self->state));
 
         switch(self->state) {
 
@@ -828,10 +863,14 @@ int tokenize_whitespace(parser_t *self, size_t line_limit)
             } else if (c == '\r') {
                 self->state = EAT_CRNL;
                 break;
+            } else if (IS_WHITESPACE(c)) {
+                END_FIELD();
+                self->state = EAT_WHITESPACE;
+                break;
+            } else {
+                /* normal character - handle as START_FIELD */
+                self->state = START_FIELD;
             }
-
-            /* normal character - handle as START_FIELD */
-            self->state = START_FIELD;
             /* fallthru */
         case START_FIELD:
             /* expecting field */
@@ -972,14 +1011,15 @@ int tokenize_whitespace(parser_t *self, size_t line_limit)
             if (c == '\n') {
                 END_LINE();
                 /* self->state = START_RECORD; */
+            } else if (IS_WHITESPACE(c)){
+                // Handle \r-delimited files
+                END_LINE_AND_FIELD_STATE(EAT_WHITESPACE);
             } else {
-                /* self->error_msg = ("new-line character seen in" */
-                /*                 " unquoted field - do you need" */
-                /*                 " to open the file in " */
-                /*                 "universal-newline mode?"); */
-                goto parsingerror;
+                PUSH_CHAR(c);
+                END_LINE_STATE(IN_FIELD);
             }
             break;
+
         default:
             break;
 
@@ -1009,13 +1049,13 @@ linelimit:
 
 
 int parser_handle_eof(parser_t *self) {
-    TRACE(("handling eof, datalen: %d\n", self->datalen))
+    TRACE(("handling eof, datalen: %d, pstate: %d\n", self->datalen, self->state))
     if (self->datalen == 0 && (self->state != START_RECORD)) {
         // test cases needed here
         // TODO: empty field at end of line
         TRACE(("handling eof\n"));
 
-        if (self->state == IN_FIELD) {
+        if (self->state == IN_FIELD || self->state == START_FIELD) {
             if (end_field(self) < 0)
                 return -1;
         } else if (self->state == QUOTE_IN_QUOTED_FIELD) {
@@ -1213,6 +1253,8 @@ int _tokenize_helper(parser_t *self, size_t nrows, int all) {
 
         status = tokenize_bytes(self, nrows);
 
+        /* debug_print_parser(self); */
+
         if (status < 0) {
             // XXX
             TRACE(("Status %d returned from tokenize_bytes, breaking\n",
diff --git a/pandas/src/parser/tokenizer.h b/pandas/src/parser/tokenizer.h
index 1b988e353..7f3037ea0 100644
--- a/pandas/src/parser/tokenizer.h
+++ b/pandas/src/parser/tokenizer.h
@@ -43,7 +43,7 @@ See LICENSE for the license
   #if defined(__GNUC__)
     #define P_INLINE __inline__
   #elif defined(_MSC_VER)
-    #define P_INLINE 
+    #define P_INLINE
   #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
     #define P_INLINE inline
   #else
