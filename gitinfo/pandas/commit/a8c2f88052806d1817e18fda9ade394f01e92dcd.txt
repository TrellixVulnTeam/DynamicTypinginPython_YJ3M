commit a8c2f88052806d1817e18fda9ade394f01e92dcd
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue May 31 18:03:32 2011 +0100

    some refactoring, starting work on fast time series reductions

diff --git a/Makefile b/Makefile
index 4cfaaa282..96317215c 100644
--- a/Makefile
+++ b/Makefile
@@ -1,6 +1,10 @@
 clean:
 	-rm -rf build dist
 
+tseries: pandas/lib/src/tseries.pyx
+	touch pandas/lib/src/tseries.pyx
+	python build_cython.py build_ext --inplace
+
 sparse: pandas/lib/src/sparse.pyx
 	-python build_cython.py build_ext --inplace
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 6295a7b13..636405a19 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -898,8 +898,11 @@ class DataFrame(PandasGeneric):
         offset : DateOffset object, or string in {'WEEKDAY', 'EOM'}
             DateOffset object or subclass (e.g. monthEnd)
 
-        fillMethod : {'backfill', 'pad', None}
-                    Method to use for filling holes in new inde
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill methdo
         """
         if len(self.index) == 0:
             return self.copy()
@@ -1143,8 +1146,11 @@ class DataFrame(PandasGeneric):
 
         Parameters
         ----------
-        method : {'backfill', 'pad', None}
-            Method to use for filling holes in new inde
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         value : any kind (should be same type as array)
             Value to use to fill holes (e.g. 0)
@@ -1239,9 +1245,11 @@ class DataFrame(PandasGeneric):
         index : array-like, optional
             preferably an Index object (to avoid duplicating data)
         columns : array-like, optional
-        method : {'backfill', 'pad', None}
-            Method to use for filling data holes using the index. See
-            Series.reindex for more information
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         Returns
         -------
diff --git a/pandas/core/functions.py b/pandas/core/functions.py
new file mode 100644
index 000000000..d07244d80
--- /dev/null
+++ b/pandas/core/functions.py
@@ -0,0 +1,95 @@
+from pandas.core.common import isnull
+import numpy as np
+
+#-------------------------------------------------------------------------------
+# NaN-friendly reductions and such
+
+def reduce_mean(values, index, buckets, inclusive=False):
+    def _reduceat_mean(values, mask, locs):
+        the_sum = np.add.reduceat(values, locs)
+        the_count = np.add.reduceat(-mask, locs)
+        return the_sum / the_count
+    return _reduce_generic(values, index, buckets, _reduceat_mean,
+                           inclusive=inclusive, na_fill=0)
+
+
+def _reduceat_var(values, mask, locs):
+    XX = np.add.reduceat(values ** 2, locs)
+    X = np.add.reduceat(values, locs)
+    nobs = np.add.reduceat(-mask, locs)
+    return (XX - X * X) / (nobs - 1)
+
+def reduce_std(values, index, buckets, inclusive=False):
+    result = _reduce_generic(values, index, buckets, _reduceat_var,
+                             inclusive=inclusive, na_fill=0)
+    return np.sqrt(result)
+
+def reduce_prod(values, index, buckets, inclusive=False):
+    def _reduceat_prod(values, mask, locs):
+        return np.multiply.reduceat(values, locs)
+    return _reduce_generic(values, index, buckets, _reduceat_prod,
+                           inclusive=inclusive, na_fill=1)
+
+def reduce_min(values, index, buckets, inclusive=False):
+    def _reduceat_min(values, mask, locs):
+        return np.minimum.reduceat(values, locs)
+    return _reduce_generic(values, index, buckets, _reduceat_min,
+                           inclusive=inclusive, na_fill=np.inf)
+
+def reduce_max(values, index, buckets, inclusive=False):
+    def _reduceat_max(values, mask, locs):
+        return np.maximum.reduceat(values, locs)
+    return _reduce_generic(values, index, buckets, _reduceat_max,
+                           inclusive=inclusive, na_fill=-np.inf)
+
+def _reduce_generic(values, index, buckets, freduce, inclusive=False,
+                    na_fill=None):
+    """
+
+    """
+    locs = _bucket_locs(index, buckets, inclusive=inclusive)
+
+    values = np.asarray(values)
+    mask = isnull(values)
+
+    if na_fill is not None:
+        values = values.copy()
+        np.putmask(values, mask, na_fill)
+
+    return freduce(values, mask, locs)
+
+def _reduceat_count(values, mask, locs):
+    return np.add.reduceat(-mask, locs)
+
+def _bucket_locs(index, buckets, inclusive=False):
+    if inclusive:
+        locs = index.searchsorted(buckets, side='left')
+    else:
+        locs = index.searchsorted(buckets, side='right')
+
+    return locs
+
+def get_bucket(date, bucks):
+    if date in bucks:
+        idx = bucks.indexMap[date] + 1
+    else:
+        idx = bucks.searchsorted(date)
+    return bucks[idx]
+
+def dumb_way(series, buckets):
+    sampled2 = hfseries.groupby(lambda x: get_bucket(x, buckets)).mean()
+    sampled2 = sampled2.reindex(buckets)
+    return sampled2
+
+if __name__ == '__main__':
+    N = 1000000
+    K = 1000
+
+    values = np.random.randn(N)
+    index = np.arange(N).astype(object)
+    buckets = np.arange(0, N, N // K).astype(object)
+
+    result = reduce_mean(values, index, buckets)
+
+    import pandas.lib.tseries as tseries
+    tseries.ts_upsample_mean(index, buckets, values)
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
new file mode 100644
index 000000000..187b42005
--- /dev/null
+++ b/pandas/core/generic.py
@@ -0,0 +1,102 @@
+import numpy as np
+import cPickle
+
+#-------------------------------------------------------------------------------
+# Picklable mixin
+
+class Picklable(object):
+
+    def save(self, fileName):
+        f = open(fileName, 'wb')
+        try:
+            cPickle.dump(self, f, protocol=cPickle.HIGHEST_PROTOCOL)
+        finally:
+            f.close()
+
+    @classmethod
+    def load(cls, fileName):
+        f = open(fileName, 'rb')
+        try:
+            return cPickle.load(f)
+        finally:
+            f.close()
+
+class PandasError(Exception):
+    pass
+
+class PandasGeneric(Picklable):
+
+    _AXIS_NUMBERS = {
+        'index' : 0,
+        'columns' : 1
+    }
+
+    _AXIS_ALIASES = {}
+
+    _AXIS_NAMES = dict((v, k) for k, v in _AXIS_NUMBERS.iteritems())
+
+    @classmethod
+    def _get_axis_number(cls, axis):
+        axis = cls._AXIS_ALIASES.get(axis, axis)
+
+        if isinstance(axis, int):
+            if axis in cls._AXIS_NAMES:
+                return axis
+            else:
+                raise Exception('No %d axis' % axis)
+        else:
+            return cls._AXIS_NUMBERS[axis]
+
+    @classmethod
+    def _get_axis_name(cls, axis):
+        axis = cls._AXIS_ALIASES.get(axis, axis)
+        if isinstance(axis, basestring):
+            if axis in cls._AXIS_NUMBERS:
+                return axis
+            else:
+                raise Exception('No axis named %s' % axis)
+        else:
+            return cls._AXIS_NAMES[axis]
+
+    def _get_axis(self, axis):
+        name = self._get_axis_name(axis)
+        return getattr(self, name)
+
+    def groupby(self, mapper):
+        """
+        Goup series using mapper (dict or key function, apply given
+        function to group, return result as series).
+
+        Parameters
+        ----------
+        mapper: function, dict or Series
+            Called on each element of the object index to determine
+            the groups.  If a dict or Series is passed, the Series or
+            dict VALUES will be used to determine the groups
+
+        Returns
+        -------
+        GroupBy object
+        """
+        from pandas.core.groupby import groupby
+        return groupby(self, mapper)
+
+    def _select_generic(self, crit, axis=0):
+        """
+        Return data corresponding to axis labels matching criteria
+
+        Parameters
+        ----------
+        crit : function
+            To be called on each index (label). Should return True or False
+        axis : {0, 1}
+
+        Returns
+        -------
+        selection : type of caller
+        """
+        axis_name = self._get_axis_name(axis)
+        axis = self._get_axis(axis)
+        new_axis = axis[np.asarray([crit(label) for label in axis])]
+        return self.reindex(**{axis_name : new_axis})
+
diff --git a/pandas/core/index.py b/pandas/core/index.py
index f166fe5fe..f4fcb6ba6 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -249,6 +249,12 @@ class Index(np.ndarray):
         if method:
             method = method.upper()
 
+        aliases = {
+            'FFILL' : 'PAD',
+            'BFILL' : 'BACKFILL'
+        }
+
+        method = aliases.get(method, method)
         indexer, mask = tseries.getFillVec(self, target, self.indexMap,
                                            target.indexMap, method)
         return indexer, mask
diff --git a/pandas/core/mixins.py b/pandas/core/mixins.py
deleted file mode 100644
index 22a56f0d9..000000000
--- a/pandas/core/mixins.py
+++ /dev/null
@@ -1,45 +0,0 @@
-import cPickle
-
-#-------------------------------------------------------------------------------
-# Picklable mixin
-
-class Picklable(object):
-    def save(self, fileName):
-        f = open(fileName, 'wb')
-        try:
-            cPickle.dump(self, f, protocol=cPickle.HIGHEST_PROTOCOL)
-        finally:
-            f.close()
-
-    @classmethod
-    def load(cls, fileName):
-        f = open(fileName, 'rb')
-        try:
-            return cPickle.load(f)
-        finally:
-            f.close()
-
-#-------------------------------------------------------------------------------
-# Groupable mixin
-
-
-class Groupable(object):
-
-    def groupby(self, mapper):
-        """
-        Goup series using mapper (dict or key function, apply given
-        function to group, return result as series).
-
-        Parameters
-        ----------
-        mapper: function, dict or Series
-            Called on each element of the object index to determine
-            the groups.  If a dict or Series is passed, the Series or
-            dict VALUES will be used to determine the groups
-
-        Returns
-        -------
-        GroupBy object
-        """
-        from pandas.core.groupby import groupby
-        return groupby(self, mapper)
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index d2fe1c01e..53426649d 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -370,8 +370,11 @@ class WidePanel(Panel, PandasGeneric):
         items : Index or sequence, default None
         minor : Index or sequence, default None
             Can also use 'minor_axis' keyword
-        method : {'backfill', 'pad', 'interpolate', None}
-            Method to use for filling holes in reindexed panel
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default None
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         Returns
         -------
@@ -498,8 +501,11 @@ class WidePanel(Panel, PandasGeneric):
         value : any kind (should be same type as array)
             Value to use to fill holes (e.g. 0)
 
-        method : {'backfill', 'pad', None}
-            Method to use for filling holes in new inde
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         Returns
         -------
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 884530d4c..4713cd54a 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -877,11 +877,11 @@ class Series(np.ndarray, PandasGeneric):
         ----------
         index : array-like
             Preferably an Index object (to avoid duplicating data)
-        method : {'backfill', 'pad', None}
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}
             Method to use for filling holes in reindexed Series
 
-            pad : propagate last valid observation forward to next valid
-            backfill : use NEXT valid observation to fill gap
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         Returns
         -------
@@ -950,8 +950,11 @@ class Series(np.ndarray, PandasGeneric):
         value : any kind (should be same type as array)
             Value to use to fill holes (e.g. 0)
 
-        method : {'backfill', 'pad', None}
-            Method to use for filling holes in new inde
+        method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'
+            Method to use for filling holes in reindexed Series
+
+            pad / ffill: propagate last valid observation forward to next valid
+            backfill / bfill: use NEXT valid observation to fill gap
 
         Returns
         -------
@@ -1331,6 +1334,33 @@ class Series(np.ndarray, PandasGeneric):
 class TimeSeries(Series):
     pass
 
+
+def ts_upsample(dates, buckets, values, aggfunc, inclusive=True):
+    '''
+    put something here
+    '''
+    nbuckets = len(buckets)
+    nvalues = len(dates)
+    output = np.empty(nbuckets, dtype=float)
+
+    if inclusive:
+        _check = lambda x, y: x < y
+    else:
+        _check = lambda x, y: x <= y
+
+    j = 0
+    for i, bound in enumerate(buckets):
+        next_bound = buckets[i + 1]
+        jstart = j
+
+        while _check(dates[j], next_bound) and j < nvalues:
+            j += 1
+
+        output[i] = aggfunc(values[jstart:j])
+
+    return Series(output, index=buckets)
+
+
 #-------------------------------------------------------------------------------
 # Supplementary functions
 
diff --git a/pandas/core/tests/foo.py b/pandas/core/tests/foo.py
new file mode 100644
index 000000000..f0ad5cc44
--- /dev/null
+++ b/pandas/core/tests/foo.py
@@ -0,0 +1,9 @@
+from test_sparse import *
+
+data_dict = {
+    'item1' : panel_data1(),
+    'item2' : panel_data2(),
+    'item3' : panel_data3()
+}
+panel = SparseWidePanel(data_dict)
+
diff --git a/pandas/core/tests/test_functions.py b/pandas/core/tests/test_functions.py
new file mode 100644
index 000000000..bb5d8168e
--- /dev/null
+++ b/pandas/core/tests/test_functions.py
@@ -0,0 +1,30 @@
+from pandas import Index, isnull
+import pandas.core.functions as fns
+import numpy as np
+import unittest
+import numpy as np
+
+
+class TestReductions(unittest.TestCase):
+
+    def setUp(self):
+        self.index = Index(np.arange(100))
+        pass
+
+    def test_upsample_mean(self):
+        pass
+
+    def test_upsample_max(self):
+        pass
+
+    def test_upsample_min(self):
+        pass
+
+    def test_upsample_generic(self):
+        pass
+
+if __name__ == '__main__':
+    import nose
+    nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
+                   exit=False)
+
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index caf6abf73..6891d76d8 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -665,9 +665,9 @@ class TestSeries(unittest.TestCase):
 
         for idx, val in subTS.iteritems():
             self.assertEqual(val, self.ts[idx])
-        crapSeries = self.ts.reindex(subIndex)
+        stuffSeries = self.ts.reindex(subIndex)
 
-        self.assert_(np.isnan(crapSeries).all())
+        self.assert_(np.isnan(stuffSeries).all())
 
         # This is extremely important for the Cython code to not screw up
         nonContigIndex = self.ts.index[::2]
@@ -675,20 +675,36 @@ class TestSeries(unittest.TestCase):
         for idx, val in subNonContig.iteritems():
             self.assertEqual(val, self.ts[idx])
 
-        # bad fill method
-        ts = self.ts[::2]
-        self.assertRaises(Exception, ts.reindex, self.ts.index, method='foo')
+    def test_reindex_corner(self):
+        # (don't forget to fix this) I think it's fixed
+        reindexed_dep = self.empty.reindex(self.ts.index, method='pad')
 
         # corner case: pad empty series
         reindexed = self.empty.reindex(self.ts.index, method='pad')
 
-        # don't forget to fix this
-        reindexed_dep = self.empty.reindex(self.ts.index, method='pad')
-
         # pass non-Index
         reindexed = self.ts.reindex(list(self.ts.index))
         assert_series_equal(self.ts, reindexed)
 
+        # bad fill method
+        ts = self.ts[::2]
+        self.assertRaises(Exception, ts.reindex, self.ts.index, method='foo')
+
+    def test_reindex_pad(self):
+        s = Series(np.arange(10), np.arange(10))
+
+        s2 = s[::2]
+
+        reindexed = s2.reindex(s.index, method='pad')
+        reindexed2 = s2.reindex(s.index, method='ffill')
+        assert_series_equal(reindexed, reindexed2)
+
+        expected = Series([0, 0, 2, 2, 4, 4, 6, 6, 8, 8], index=np.arange(10))
+        assert_series_equal(reindexed, expected)
+
+    def test_reindex_backfill(self):
+        pass
+
     def test_reindex_int(self):
         ts = self.ts[::2]
         int_ts = Series(np.zeros(len(ts), dtype=int), index=ts.index)
