commit 3d4f1e61da99aed95c236883848ce4ce6f0d171a
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Nov 26 16:11:43 2012 -0500

    ENH: streamline factorization, don't compute counts array. speed up groupby

diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 9df6de22c..bc33cb848 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -121,13 +121,13 @@ def factorize(values, sort=False, order=None, na_sentinel=-1):
 
     table = hash_klass(len(values))
     uniques = vec_klass()
-    labels, counts = table.get_labels(values, uniques, 0, na_sentinel)
+    labels = table.get_labels(values, uniques, 0, na_sentinel)
 
     labels = com._ensure_platform_int(labels)
 
     uniques = uniques.to_array(xfer_data=True)
 
-    if sort and len(counts) > 0:
+    if sort and len(uniques) > 0:
         sorter = uniques.argsort()
         reverse_indexer = np.empty(len(sorter), dtype=np.int_)
         reverse_indexer.put(sorter, np.arange(len(sorter)))
@@ -137,12 +137,11 @@ def factorize(values, sort=False, order=None, na_sentinel=-1):
         np.putmask(labels, mask, -1)
 
         uniques = uniques.take(sorter)
-        counts = counts.take(sorter)
 
     if is_datetime:
-        uniques = np.array(uniques, dtype='M8[ns]')
+        uniques = uniques.view('M8[ns]')
 
-    return labels, uniques, counts
+    return labels, uniques
 
 
 def value_counts(values, sort=True, ascending=False):
diff --git a/pandas/core/categorical.py b/pandas/core/categorical.py
index 1ff23bcce..a093a81a6 100644
--- a/pandas/core/categorical.py
+++ b/pandas/core/categorical.py
@@ -53,9 +53,9 @@ class Categorical(object):
             labels, levels = data.factorize()
         else:
             try:
-                labels, levels, _ = factorize(data, sort=True)
+                labels, levels = factorize(data, sort=True)
             except TypeError:
-                labels, levels, _ = factorize(data, sort=False)
+                labels, levels = factorize(data, sort=False)
 
         return Categorical(labels, levels,
                            name=getattr(data, 'name', None))
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 7cd02f5eb..9648077ea 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -632,7 +632,7 @@ class Grouper(object):
         all_labels = [ping.labels for ping in self.groupings]
         if self._overflow_possible:
             tups = lib.fast_zip(all_labels)
-            labs, uniques, _ = algos.factorize(tups)
+            labs, uniques = algos.factorize(tups)
 
             if self.sort:
                 uniques, labs = _reorder_by_uniques(uniques, labs)
@@ -1056,7 +1056,7 @@ class Grouping(object):
                 self._was_factor = True
 
                 # all levels may not be observed
-                labels, uniques, counts = algos.factorize(inds, sort=True)
+                labels, uniques = algos.factorize(inds, sort=True)
 
                 if len(uniques) < len(level_index):
                     level_index = level_index.take(uniques)
@@ -1090,7 +1090,6 @@ class Grouping(object):
         return iter(self.indices)
 
     _labels = None
-    _counts = None
     _group_index = None
 
     @property
@@ -1107,16 +1106,6 @@ class Grouping(object):
             self._make_labels()
         return self._labels
 
-    @property
-    def counts(self):
-        if self._counts is None:
-            if self._was_factor:
-                self._counts = lib.group_count(com._ensure_int64(self.labels),
-                                               self.ngroups)
-            else:
-                self._make_labels()
-        return self._counts
-
     @property
     def group_index(self):
         if self._group_index is None:
@@ -1127,12 +1116,11 @@ class Grouping(object):
         if self._was_factor:  # pragma: no cover
             raise Exception('Should not call this method grouping by level')
         else:
-            labs, uniques, counts = algos.factorize(self.grouper,
+            labs, uniques = algos.factorize(self.grouper,
                                                     sort=self.sort)
             uniques = Index(uniques, name=self.name)
             self._labels = labs
             self._group_index = uniques
-            self._counts = counts
 
     _groups = None
 
@@ -2145,7 +2133,7 @@ def _lexsort_indexer(keys, orders=None):
         if not key.dtype == np.object_:
             key = key.astype('O')
 
-        ids, _ = rizer.factorize(key, sort=True)
+        ids = rizer.factorize(key, sort=True)
 
         n = len(rizer.uniques)
         shape.append(n)
diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index 7f0d1a804..1498b4cbf 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -268,7 +268,6 @@ cdef class StringHashTable(HashTable):
         cdef:
             Py_ssize_t i, n = len(values)
             ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
-            ndarray[int64_t] counts = np.empty(n, dtype=np.int64)
             dict reverse = {}
             Py_ssize_t idx, count = 0
             int ret = 0
@@ -283,7 +282,6 @@ cdef class StringHashTable(HashTable):
             if k != self.table.n_buckets:
                 idx = self.table.vals[k]
                 labels[i] = idx
-                counts[idx] = counts[idx] + 1
             else:
                 k = kh_put_str(self.table, buf, &ret)
                 # print 'putting %s, %s' % (val, count)
@@ -293,11 +291,10 @@ cdef class StringHashTable(HashTable):
                 self.table.vals[k] = count
                 reverse[count] = val
                 labels[i] = count
-                counts[count] = 1
                 count += 1
 
         # return None
-        return reverse, labels, counts[:count].copy()
+        return reverse, labels
 
 cdef class Int32HashTable(HashTable):
     cdef kh_int32_t *table
@@ -376,7 +373,6 @@ cdef class Int32HashTable(HashTable):
         cdef:
             Py_ssize_t i, n = len(values)
             ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
-            ndarray[int64_t] counts = np.empty(n, dtype=np.int64)
             dict reverse = {}
             Py_ssize_t idx, count = 0
             int ret = 0
@@ -389,7 +385,6 @@ cdef class Int32HashTable(HashTable):
             if k != self.table.n_buckets:
                 idx = self.table.vals[k]
                 labels[i] = idx
-                counts[idx] = counts[idx] + 1
             else:
                 k = kh_put_int32(self.table, val, &ret)
                 if not ret:
@@ -397,11 +392,10 @@ cdef class Int32HashTable(HashTable):
                 self.table.vals[k] = count
                 reverse[count] = val
                 labels[i] = count
-                counts[count] = 1
                 count += 1
 
         # return None
-        return reverse, labels, counts[:count].copy()
+        return reverse, labels
 
 cdef class Int64HashTable(HashTable):
     cdef kh_int64_t *table
@@ -518,22 +512,20 @@ cdef class Int64HashTable(HashTable):
 
     def factorize(self, ndarray[object] values):
         reverse = {}
-        labels, counts = self.get_labels(values, reverse, 0)
-        return reverse, labels, counts
+        labels = self.get_labels(values, reverse, 0)
+        return reverse, labels
 
     def get_labels(self, ndarray[int64_t] values, Int64Vector uniques,
                    Py_ssize_t count_prior, Py_ssize_t na_sentinel):
         cdef:
             Py_ssize_t i, n = len(values)
             ndarray[int64_t] labels
-            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             int64_t val
             khiter_t k
 
         labels = np.empty(n, dtype=np.int64)
-        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -541,16 +533,14 @@ cdef class Int64HashTable(HashTable):
             if k != self.table.n_buckets:
                 idx = self.table.vals[k]
                 labels[i] = idx
-                counts[idx] = counts[idx] + 1
             else:
                 k = kh_put_int64(self.table, val, &ret)
                 self.table.vals[k] = count
                 uniques.append(val)
                 labels[i] = count
-                counts[count] = 1
                 count += 1
 
-        return labels, counts[:count].copy()
+        return labels
 
     def get_labels_groupby(self, ndarray[int64_t] values):
         cdef:
@@ -615,37 +605,6 @@ cdef class Int64HashTable(HashTable):
 
         return result
 
-def value_count_int64(ndarray[int64_t] values):
-    cdef:
-        Py_ssize_t i, n = len(values)
-        kh_int64_t *table
-        int ret = 0
-
-    table = kh_init_int64()
-    kh_resize_int64(table, n)
-
-    for i in range(n):
-        val = values[i]
-        k = kh_get_int64(table, val)
-        if k != table.n_buckets:
-            table.vals[k] += 1
-        else:
-            k = kh_put_int64(table, val, &ret)
-            table.vals[k] = 1
-
-    # for (k = kh_begin(h); k != kh_end(h); ++k)
-    # 	if (kh_exist(h, k)) kh_value(h, k) = 1;
-    i = 0
-    result_keys = np.empty(table.n_occupied, dtype=np.int64)
-    result_counts = np.zeros(table.n_occupied, dtype=np.int64)
-    for k in range(table.n_buckets):
-        if kh_exist_int64(table, k):
-            result_keys[i] = table.keys[k]
-            result_counts[i] = table.vals[k]
-            i += 1
-    kh_destroy_int64(table)
-
-    return result_keys, result_counts
 
 cdef class Float64HashTable(HashTable):
     cdef kh_float64_t *table
@@ -665,8 +624,8 @@ cdef class Float64HashTable(HashTable):
 
     def factorize(self, ndarray[float64_t] values):
         uniques = Float64Vector()
-        labels, counts = self.get_labels(values, uniques, 0, -1)
-        return uniques.to_array(xfer_data=True), labels, counts
+        labels = self.get_labels(values, uniques, 0, -1)
+        return uniques.to_array(xfer_data=True), labels
 
     cpdef get_labels(self, ndarray[float64_t] values,
                      Float64Vector uniques,
@@ -674,14 +633,12 @@ cdef class Float64HashTable(HashTable):
         cdef:
             Py_ssize_t i, n = len(values)
             ndarray[int64_t] labels
-            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             float64_t val
             khiter_t k
 
         labels = np.empty(n, dtype=np.int64)
-        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -694,16 +651,14 @@ cdef class Float64HashTable(HashTable):
             if k != self.table.n_buckets:
                 idx = self.table.vals[k]
                 labels[i] = idx
-                counts[idx] = counts[idx] + 1
             else:
                 k = kh_put_float64(self.table, val, &ret)
                 self.table.vals[k] = count
                 uniques.append(val)
                 labels[i] = count
-                counts[count] = 1
                 count += 1
 
-        return labels, counts[:count].copy()
+        return labels
 
     def map_locations(self, ndarray[float64_t] values):
         cdef:
@@ -897,14 +852,12 @@ cdef class PyObjectHashTable(HashTable):
         cdef:
             Py_ssize_t i, n = len(values)
             ndarray[int64_t] labels
-            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             object val
             khiter_t k
 
         labels = np.empty(n, dtype=np.int64)
-        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -918,16 +871,14 @@ cdef class PyObjectHashTable(HashTable):
             if k != self.table.n_buckets:
                 idx = self.table.vals[k]
                 labels[i] = idx
-                counts[idx] = counts[idx] + 1
             else:
                 k = kh_put_pymap(self.table, <PyObject*>val, &ret)
                 self.table.vals[k] = count
                 uniques.append(val)
                 labels[i] = count
-                counts[count] = 1
                 count += 1
 
-        return labels, counts[:count].copy()
+        return labels
 
 
 cdef class Factorizer:
@@ -944,8 +895,8 @@ cdef class Factorizer:
         return self.count
 
     def factorize(self, ndarray[object] values, sort=False, na_sentinel=-1):
-        labels, counts = self.table.get_labels(values, self.uniques,
-                                               self.count, na_sentinel)
+        labels = self.table.get_labels(values, self.uniques,
+                                       self.count, na_sentinel)
 
         # sort on
         if sort:
@@ -957,10 +908,9 @@ cdef class Factorizer:
             reverse_indexer.put(sorter, np.arange(len(sorter)))
 
             labels = reverse_indexer.take(labels)
-            counts = counts.take(sorter)
 
-        self.count = len(counts)
-        return labels, counts
+        self.count = len(self.uniques)
+        return labels
 
     def unique(self, ndarray[object] values):
         # just for fun
@@ -982,8 +932,8 @@ cdef class Int64Factorizer:
 
     def factorize(self, ndarray[int64_t] values, sort=False,
                   na_sentinel=-1):
-        labels, counts = self.table.get_labels(values, self.uniques,
-                                               self.count, na_sentinel)
+        labels = self.table.get_labels(values, self.uniques,
+                                       self.count, na_sentinel)
 
         # sort on
         if sort:
@@ -995,26 +945,8 @@ cdef class Int64Factorizer:
             reverse_indexer.put(sorter, np.arange(len(sorter)))
 
             labels = reverse_indexer.take(labels)
-            counts = counts.take(sorter)
-
-        self.count = len(counts)
-        return labels, counts
-
 
+        self.count = len(self.uniques)
+        return labels
 
-def lookup2(ndarray[object] values):
-    cdef:
-        Py_ssize_t i, n = len(values)
-        int ret = 0
-        object val
-        khiter_t k
-        long hval
-        ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
-
-    # for i in range(n):
-    #     val = values[i]
-        # hval = PyObject_Hash(val)
-        # k = kh_get_pymap(self.table, <PyObject*>val)
-
-    return locs
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 7e614d1a9..8361bae1f 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1109,24 +1109,6 @@ class TestGroupBy(unittest.TestCase):
         agged2 = df.groupby(keys).aggregate(aggfun)
         self.assertEqual(len(agged2.columns) + 1, len(df.columns))
 
-    def test_grouping_attrs(self):
-        deleveled = self.mframe.reset_index()
-        grouped = deleveled.groupby(['first', 'second'])
-
-        for i, ping in enumerate(grouped.grouper.groupings):
-            the_counts = self.mframe.groupby(level=i).count()['A']
-            other_counts = Series(ping.counts, ping.group_index)
-            assert_almost_equal(the_counts,
-                                other_counts.reindex(the_counts.index))
-
-        # compute counts when group by level
-        grouped = self.mframe.groupby(level=0)
-        ping = grouped.grouper.groupings[0]
-        the_counts = grouped.size()
-        other_counts = Series(ping.counts, ping.group_index)
-        assert_almost_equal(the_counts,
-                            other_counts.reindex(the_counts.index))
-
     def test_groupby_level(self):
         frame = self.mframe
         deleveled = frame.reset_index()
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 2dacfc6e9..a50fd8ca6 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -566,8 +566,8 @@ def _factorize_keys(lk, rk, sort=True):
 
     rizer = klass(max(len(lk), len(rk)))
 
-    llab, _ = rizer.factorize(lk)
-    rlab, _ = rizer.factorize(rk)
+    llab = rizer.factorize(lk)
+    rlab = rizer.factorize(rk)
 
     count = rizer.get_count()
 
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index fefea3645..85b3654ba 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -699,7 +699,7 @@ class PeriodIndex(Int64Index):
         Specialized factorize that boxes uniques
         """
         from pandas.core.algorithms import factorize
-        labels, uniques, counts = factorize(self.values)
+        labels, uniques = factorize(self.values)
         uniques = PeriodIndex(ordinal=uniques, freq=self.freq)
         return labels, uniques
 
