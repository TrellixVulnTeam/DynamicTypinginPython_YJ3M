commit 93496813ccfa6b635b72a307d00f296412e6eda6
Author: jreback <jeff@reback.net>
Date:   Fri Mar 15 19:30:36 2013 -0400

    PERF: cythonized parts of to_csv for increased perf

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index d8d2f07ac..896880995 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1362,53 +1362,7 @@ class DataFrame(NDFrame):
             data_index = self.index.to_timestamp()
 
         nlevels = getattr(data_index, 'nlevels', 1)
-        if not index:
-            nlevels = 0
-
-        # In crude testing, N>100 yields little marginal improvement
-        N=100
-
-        # pre-allocate  rows
-        rows = [[None]*(nlevels+len(cols)) for x in range(N)]
-
-        all_cols = False
-        if len(cols) < 10000: # 10000 as in "usually"
-            all_cols = list(enumerate(cols))
-
-        j = None
-        if nlevels == 1:
-            for j, idx in enumerate(data_index):
-                row = rows[j % N]
-                row[0] = idx
-                for i, col in (all_cols or enumerate(cols)):
-                    val = series[col][j]
-                    row[nlevels+i] = np.asscalar(val) if isinstance(val,np.number) else val
-
-                if j >= N-1 and j % N == N-1:
-                    writer.writerows(rows)
-        elif nlevels > 1:
-            for j, idx in enumerate(data_index):
-                row = rows[j % N]
-                row[:nlevels] = list(idx)
-                for i, col in (all_cols or enumerate(cols)):
-                    val = series[col][j]
-                    row[nlevels+i] = np.asscalar(val) if isinstance(val,np.number) else val
-
-                if j >= N-1 and j % N == N-1:
-                    writer.writerows(rows)
-        else:
-            for j, idx in enumerate(data_index):
-                row = rows[j % N]
-                for i, col in (all_cols or enumerate(cols)):
-                    val = series[col][j]
-                    row[nlevels+i] = np.asscalar(val) if isinstance(val,np.number) else val
-
-                if j >= N-1 and j % N == N-1:
-                    writer.writerows(rows)
-
-        if  j is not None and (j < N-1 or (j % N) != N-1 ):
-            writer.writerows(rows[:((j+1) % N)])
-
+        lib.write_csv_rows(series, list(data_index), index, nlevels, list(cols), writer)
 
     def to_csv(self, path_or_buf, sep=",", na_rep='', float_format=None,
                cols=None, header=True, index=True, index_label=None,
diff --git a/pandas/lib.pyx b/pandas/lib.pyx
index 1fd579553..051c4e74a 100644
--- a/pandas/lib.pyx
+++ b/pandas/lib.pyx
@@ -784,6 +784,51 @@ def array_replace_from_nan_rep(ndarray[object, ndim=1] arr, object nan_rep, obje
 
     return arr
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def write_csv_rows(dict series, list data_index, object index, int nlevels, list cols, object writer):
+    
+    cdef int N, j, i, ncols, ndata_index
+    cdef list rows, row_fields, spaces
+    cdef object v
+
+    ncols = len(cols)
+    spaces = [None] *  len(cols)
+    if index:
+        if nlevels == 1:
+            row_fields_f = lambda x: [x] + spaces
+        else:  # handle MultiIndex
+            row_fields_f = lambda x: list(x) + spaces
+    else:
+        nlevels = 0
+        row_fields_f = lambda x: [None] *  len(cols)
+
+    # In crude testing, N>100 yields little marginal improvement
+    N=100
+    rows = [None]*N
+
+    ndata_index = len(data_index)
+    for j in range(ndata_index):
+       row_fields = row_fields_f(data_index[j])
+
+       for i in range(len(row_fields)):
+           v = row_fields[i]
+           if isinstance(v,np.number):
+              row_fields[i] = np.asscalar(v)
+       for i in range(ncols):
+           v = series[cols[i]][j]
+           if isinstance(v,np.number):
+              v = np.asscalar(v)
+           row_fields[i+nlevels] = v
+
+       rows[ j % N ] = row_fields
+
+       if j >= N-1 and j % N == N-1:
+            writer.writerows(rows)
+
+    if ndata_index and (j < N-1 or (j % N) != N-1 ):
+            writer.writerows(rows[:((j+1) % N)])
+
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def create_hdf_rows_2d(ndarray indexer0, 
