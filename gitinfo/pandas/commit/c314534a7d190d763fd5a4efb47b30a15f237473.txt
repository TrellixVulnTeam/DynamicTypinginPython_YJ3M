commit c314534a7d190d763fd5a4efb47b30a15f237473
Author: jreback <jeff@reback.net>
Date:   Sun Dec 23 10:40:50 2012 -0500

    BUG: renamed method select_multiple -> select_as_multiple
         renamed keyword 'columns' to 'data_columns' when passed to 'append' (to avoid confusion with 'columns' keyword in select)

diff --git a/RELEASE.rst b/RELEASE.rst
index 6e2a6a70e..72345a336 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -33,14 +33,14 @@ pandas 0.10.1
 
   - ``HDFStore``
     - enables storing of multi-index dataframes (closes GH1277_)
-    - support data column indexing and selection, via ``columns`` keyword in append
+    - support data column indexing and selection, via ``data_columns`` keyword in append
     - support write chunking to reduce memory footprint, via ``chunksize`` keywork to append
     - support automagic indexing via ``index`` keywork to append
     - support ``expectedrows`` keyword in append to inform ``PyTables`` about the expected tablesize
     - support ``start`` and ``stop`` keywords in select to limit the row selection space
     - added ``get_store`` context manager to automatically import with pandas
     - added column filtering via ``columns`` keyword in select
-    - added methods select_multiple/select_as_coordinates to do multiple-table selection
+    - added methods select_as_multiple/select_as_coordinates to do multiple-table selection
 
 **Bug fixes**
 
diff --git a/doc/source/conf.py b/doc/source/conf.py
index 692c7757e..6895f0041 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -16,6 +16,7 @@ import sys, os
 # add these directories to sys.path here. If the directory is relative to the
 # documentation root, use os.path.abspath to make it absolute, like shown here.
 #sys.path.append(os.path.abspath('.'))
+sys.path.insert(0, '/home/jreback/pandas')
 sys.path.insert(0, os.path.abspath('../sphinxext'))
 
 sys.path.extend([
diff --git a/doc/source/io.rst b/doc/source/io.rst
index c66801af3..70b65f2e4 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -1222,7 +1222,7 @@ You can designate (and index) certain columns that you want to be able to perfor
    df_dc
 
    # on-disk operations
-   store.append('df_dc', df_dc, columns = ['B','C','string','string2'])
+   store.append('df_dc', df_dc, data_columns = ['B','C','string','string2'])
    store.select('df_dc',[ Term('B>0') ])
 
    # getting creative
@@ -1257,7 +1257,7 @@ If you want to inspect the table object, retrieve via ``get_table``. You could u
 Multiple Table Queries
 ~~~~~~~~~~~~~~~~~~~~~~
 
-New in 0.10.1 is the method ``select_multiple``, that can perform selections from multiple tables and return a combined result, by using ``where`` on a selector table. The purpose is to allow fast selection from really wide tables. Construct 2 (or more) tables, where your indexing criteria is contained in a relatively small table. Then put your data in another table. Queries will be quite fast, yet you can allow your tables to grow (in column space). **THE USER IS RESPONSIBLE FOR SYNCHRONIZING THE TABLES**. This means, append to the tables in the same order. You can pass the ``axis`` parameter to control concatenation. Default is on the ``columns`` axis.
+New in 0.10.1 is the method ``select_as_multiple``, that can perform selections from multiple tables and return a combined result, by using ``where`` on a selector table. The purpose is to allow fast selection from really wide tables. Construct 2 (or more) tables, where your indexing criteria is contained in a relatively small table. Then put your data in another table. Queries will be quite fast, yet you can allow your tables to grow (in column space). **THE USER IS RESPONSIBLE FOR SYNCHRONIZING THE TABLES**. This means, append to the tables in the same order. You can pass the ``axis`` parameter to control concatenation. Default is on the ``columns`` axis.
 
 .. ipython:: python
 
@@ -1267,10 +1267,10 @@ New in 0.10.1 is the method ``select_multiple``, that can perform selections fro
    df2_mt['foo'] = 'bar'
 
    # you can use data columns as well
-   store.append('df1_mt',df1_mt, columns = ['A','B'])
+   store.append('df1_mt',df1_mt, data_columns = ['A','B'])
    store.append('df2_mt',df2_mt)
 
-   store.select_multiple(['df1_mt','df2_mt'], where = [ 'A>0','B>0' ], axis = 1, selector = 'df1_mt')
+   store.select_as_multiple(['df1_mt','df2_mt'], where = [ 'A>0','B>0' ], axis = 1, selector = 'df1_mt')
   
 
 Delete from a Table
diff --git a/doc/source/v0.10.1.txt b/doc/source/v0.10.1.txt
index f57844e0d..6ba326bb4 100644
--- a/doc/source/v0.10.1.txt
+++ b/doc/source/v0.10.1.txt
@@ -23,7 +23,7 @@ HDFStore
 
    os.remove('store.h5')
 
-You can designate (and index) certain columns that you want to be able to perform queries on a table, by passing a list to ``columns``
+You can designate (and index) certain columns that you want to be able to perform queries on a table, by passing a list to ``data_columns``
 
 .. ipython:: python
 
@@ -37,7 +37,7 @@ You can designate (and index) certain columns that you want to be able to perfor
    df
 
    # on-disk operations
-   store.append('df', df, columns = ['B','C','string','string2'])
+   store.append('df', df, data_columns = ['B','C','string','string2'])
    store.select('df',[ Term('B>0') ])
 
    # getting creative
@@ -82,7 +82,7 @@ Multi-table Selection via ``select_multiple`` can perform selections from multip
    df2_mt['foo'] = 'bar'
 
    # you can use data columns as well
-   store.append('df1_mt',df1_mt, columns = ['A','B'])
+   store.append('df1_mt',df1_mt, data_columns = ['A','B'])
    store.append('df2_mt',df2_mt)
 
    store.select_multiple(['df1_mt','df2_mt'], where = [ 'A>0' ], axis = 1, selector = 'df1_mt')
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 894518992..f99bc2452 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -372,7 +372,7 @@ class HDFStore(object):
         """
         return self.get_table(key).read_coordinates(where = where, **kwargs)
 
-    def select_multiple(self, keys, where=None, selector=None, columns=None, axis=1, **kwargs):
+    def select_as_multiple(self, keys, where=None, selector=None, columns=None, axis=1, **kwargs):
         """ Retrieve pandas objects from multiple tables
 
         Parameters
@@ -478,7 +478,7 @@ class HDFStore(object):
 
         return None
 
-    def append(self, key, value, **kwargs):
+    def append(self, key, value, columns = None, **kwargs):
         """
         Append to Table in file. Node must already exist and be Table
         format.
@@ -490,7 +490,7 @@ class HDFStore(object):
 
         Optional Parameters
         -------------------
-        columns      : list of columns to create as data columns
+        data_columns : list of columns to create as data columns
         min_itemsize : dict of columns that specify minimum string sizes
         nan_rep      : string to use as string nan represenation
         chunksize    : size to chunk the writing
@@ -501,6 +501,9 @@ class HDFStore(object):
         Does *not* check if data being appended overlaps with existing
         data in the table, so be careful
         """
+        if columns is not None:
+            raise Exception("columns is not a supported keyword in append, try data_columns")
+
         self._write_to_group(key, value, table=True, append=True, **kwargs)
 
     def create_table_index(self, key, **kwargs):
@@ -1336,7 +1339,7 @@ class Table(object):
         index_axes    : a list of tuples of the (original indexing axis and index column)
         non_index_axes: a list of tuples of the (original index axis and columns on a non-indexing axis)
         values_axes   : a list of the columns which comprise the data of this table
-        data_columns  : a list of columns that we are allowing indexing (these become single columns in values_axes)
+        data_columns  : a list of the columns that we are allowing indexing (these become single columns in values_axes)
         nan_rep       : the string to use for nan representations for string objects
         levels        : the names of levels
 
@@ -1609,7 +1612,7 @@ class Table(object):
         """ return the data for this obj """
         return obj
 
-    def create_axes(self, axes, obj, validate = True, nan_rep = None, columns = None, min_itemsize = None, **kwargs):
+    def create_axes(self, axes, obj, validate = True, nan_rep = None, data_columns = None, min_itemsize = None, **kwargs):
         """ create and return the axes
               leagcy tables create an indexable column, indexable index, non-indexable fields
     
@@ -1620,7 +1623,7 @@ class Table(object):
             validate: validate the obj against an existiing object already written
             min_itemsize: a dict of the min size for a column in bytes
             nan_rep : a values to use for string column nan_rep
-            columns : a list of columns that we want to create separate to allow indexing
+            data_columns : a list of columns that we want to create separate to allow indexing
 
         """
 
@@ -1630,9 +1633,9 @@ class Table(object):
         # do we have an existing table (if so, use its axes & data_columns)
         if self.infer_axes():
             existing_table = self.copy()
-            axes    = [ a.axis for a in existing_table.index_axes]
-            columns = existing_table.data_columns
-            nan_rep = existing_table.nan_rep
+            axes         = [ a.axis for a in existing_table.index_axes]
+            data_columns = existing_table.data_columns
+            nan_rep      = existing_table.nan_rep
         else:
             existing_table = None
 
@@ -1694,13 +1697,13 @@ class Table(object):
         block_obj = self.get_object(obj)
         blocks    = None
 
-        if columns is not None and len(self.non_index_axes):
-            axis        = self.non_index_axes[0][0]
-            axis_labels = self.non_index_axes[0][1]
-            columns = [ c for c in columns if c in axis_labels ]
-            if len(columns):
-                blocks    = block_obj.reindex_axis(Index(axis_labels)-Index(columns), axis = axis, copy = False)._data.blocks
-                for c in columns:
+        if data_columns is not None and len(self.non_index_axes):
+            axis         = self.non_index_axes[0][0]
+            axis_labels  = self.non_index_axes[0][1]
+            data_columns = [ c for c in data_columns if c in axis_labels ]
+            if len(data_columns):
+                blocks    = block_obj.reindex_axis(Index(axis_labels)-Index(data_columns), axis = axis, copy = False)._data.blocks
+                for c in data_columns:
                     blocks.extend(block_obj.reindex_axis([ c ], axis = axis, copy = False)._data.blocks)
 
         if blocks is None:
@@ -1715,7 +1718,7 @@ class Table(object):
             name   = None
 
             # we have a data_column
-            if columns and len(b.items) == 1 and b.items[0] in columns:
+            if data_columns and len(b.items) == 1 and b.items[0] in data_columns:
                 klass = DataIndexableCol
                 name  = b.items[0]
                 self.data_columns.append(name)
@@ -2139,14 +2142,14 @@ class AppendableMultiFrameTable(AppendableFrameTable):
     def table_type_short(self):
         return 'appendable_multi'
 
-    def write(self, obj, columns = None, **kwargs):
-        if columns is None:
-            columns = []
+    def write(self, obj, data_columns = None, **kwargs):
+        if data_columns is None:
+            data_columns = []
         for n in obj.index.names:
-            if n not in columns:
-                columns.insert(0,n)
+            if n not in data_columns:
+                data_columns.insert(0,n)
         self.levels = obj.index.names
-        return super(AppendableMultiFrameTable, self).write(obj = obj.reset_index(), columns = columns, **kwargs)
+        return super(AppendableMultiFrameTable, self).write(obj = obj.reset_index(), data_columns = data_columns, **kwargs)
 
     def read(self, *args, **kwargs):
         df = super(AppendableMultiFrameTable, self).read(*args, **kwargs)
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index 878aedb83..f8c71a3f2 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -427,7 +427,7 @@ class TestHDFStore(unittest.TestCase):
 
         df = tm.makeTimeDataFrame()
         self.store.remove('df')
-        self.store.append('df', df[:2], columns = ['B'])
+        self.store.append('df', df[:2], data_columns = ['B'])
         self.store.append('df', df[2:])
         tm.assert_frame_equal(self.store['df'], df)
 
@@ -452,7 +452,7 @@ class TestHDFStore(unittest.TestCase):
         df_new['string'][1:4] = np.nan
         df_new['string'][5:6] = 'bar'
         self.store.remove('df')
-        self.store.append('df', df_new, columns = ['string'])
+        self.store.append('df', df_new, data_columns = ['string'])
         result = self.store.select('df', [ Term('string', '=', 'foo') ])
         expected = df_new[df_new.string == 'foo']
         tm.assert_frame_equal(result, expected)
@@ -466,7 +466,7 @@ class TestHDFStore(unittest.TestCase):
         df_new['string2'][2:5] = np.nan
         df_new['string2'][7:8] = 'bar'
         self.store.remove('df')
-        self.store.append('df', df_new, columns = ['A','B','string','string2'])
+        self.store.append('df', df_new, data_columns = ['A','B','string','string2'])
         result = self.store.select('df', [ Term('string', '=', 'foo'), Term('string2=foo'), Term('A>0'), Term('B<0') ])
         expected = df_new[(df_new.string == 'foo') & (df_new.string2 == 'foo') & (df_new.A > 0) & (df_new.B < 0)]
         tm.assert_frame_equal(result, expected)
@@ -484,7 +484,7 @@ class TestHDFStore(unittest.TestCase):
         df_dc['string2'] = 'cool'
         df_dc
         self.store.remove('df_dc')
-        self.store.append('df_dc', df_dc, columns = ['B','C','string','string2'])
+        self.store.append('df_dc', df_dc, data_columns = ['B','C','string','string2'])
         result = self.store.select('df_dc',[ Term('B>0') ])
         expected = df_dc[df_dc.B > 0]
         tm.assert_frame_equal(result, expected)
@@ -1299,14 +1299,14 @@ class TestHDFStore(unittest.TestCase):
 
         # with a data column
         self.store.remove('df')
-        self.store.append('df',df, columns = ['A'])
+        self.store.append('df',df, data_columns = ['A'])
         result = self.store.select('df', [ 'A > 0' ], columns = ['A','B'])
         expected = df[df.A > 0].reindex(columns = ['A','B'])
         tm.assert_frame_equal(expected, result)
 
         # with a data column, but different columns
         self.store.remove('df')
-        self.store.append('df',df, columns = ['A'])
+        self.store.append('df',df, data_columns = ['A'])
         result = self.store.select('df', [ 'A > 0' ], columns = ['C','D'])
         expected = df[df.A > 0].reindex(columns = ['C','D'])
         tm.assert_frame_equal(expected, result)
@@ -1397,7 +1397,7 @@ class TestHDFStore(unittest.TestCase):
         self.store.remove('df2')
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns = lambda x: "%s_2" % x)
-        self.store.append('df1',df1, columns = ['A','B'])
+        self.store.append('df1',df1, data_columns = ['A','B'])
         self.store.append('df2',df2)
 
         c = self.store.select_as_coordinates('df1', [ 'A>0','B>0' ])
@@ -1409,37 +1409,37 @@ class TestHDFStore(unittest.TestCase):
         expected = expected[(expected.A > 0) & (expected.B > 0)]
         tm.assert_frame_equal(result, expected)
 
-    def test_select_multiple(self):
+    def test_select_as_multiple(self):
         df1 = tm.makeTimeDataFrame()
         df2 = tm.makeTimeDataFrame().rename(columns = lambda x: "%s_2" % x)
         df2['foo'] = 'bar'
-        self.store.append('df1',df1, columns = ['A','B'])
+        self.store.append('df1',df1, data_columns = ['A','B'])
         self.store.append('df2',df2)
 
         # exceptions
-        self.assertRaises(Exception, self.store.select_multiple, None, where = [ 'A>0','B>0' ], selector = 'df1')
-        self.assertRaises(Exception, self.store.select_multiple, [ None ], where = [ 'A>0','B>0' ], selector = 'df1')
+        self.assertRaises(Exception, self.store.select_as_multiple, None, where = [ 'A>0','B>0' ], selector = 'df1')
+        self.assertRaises(Exception, self.store.select_as_multiple, [ None ], where = [ 'A>0','B>0' ], selector = 'df1')
 
         # default select
         result = self.store.select('df1', ['A>0','B>0'])
-        expected = self.store.select_multiple([ 'df1' ], where = [ 'A>0','B>0' ], selector = 'df1')
+        expected = self.store.select_as_multiple([ 'df1' ], where = [ 'A>0','B>0' ], selector = 'df1')
         tm.assert_frame_equal(result, expected)
 
         # multiple
-        result = self.store.select_multiple(['df1','df2'], where = [ 'A>0','B>0' ], selector = 'df1')
+        result = self.store.select_as_multiple(['df1','df2'], where = [ 'A>0','B>0' ], selector = 'df1')
         expected = concat([ df1, df2 ], axis=1)
         expected = expected[(expected.A > 0) & (expected.B > 0)]
         tm.assert_frame_equal(result, expected)
 
         # multiple (diff selector)
-        result = self.store.select_multiple(['df1','df2'], where = [ Term('index', '>', df2.index[4]) ], selector = 'df2')
+        result = self.store.select_as_multiple(['df1','df2'], where = [ Term('index', '>', df2.index[4]) ], selector = 'df2')
         expected = concat([ df1, df2 ], axis=1)
         expected = expected[5:]
         tm.assert_frame_equal(result, expected)
 
         # test excpection for diff rows
         self.store.append('df3',tm.makeTimeDataFrame(nper=50))
-        self.assertRaises(Exception, self.store.select_multiple, ['df1','df3'], where = [ 'A>0','B>0' ], selector = 'df1')
+        self.assertRaises(Exception, self.store.select_as_multiple, ['df1','df3'], where = [ 'A>0','B>0' ], selector = 'df1')
 
     def test_start_stop(self):
         
