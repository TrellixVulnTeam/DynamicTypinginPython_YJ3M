commit 55e0f7b09181a8d27963602073dab852f540e855
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Mar 31 23:02:28 2010 +0000

    moving ols speed enhancements and import optimization
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@149 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 3fd9465fd..9fba03fa4 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -127,7 +127,8 @@ class DataFrame(Picklable, Groupable):
     @staticmethod
     def _extract_index(data, index):
         if len(data) == 0:
-            index = NULL_INDEX
+            if index is None:
+                index = NULL_INDEX
         elif len(data) > 0 and index is None:
             # aggregate union of indices
             need_labels = False
@@ -1485,10 +1486,16 @@ class DataFrame(Picklable, Groupable):
         """
         def get_cumsum(y):
             y = np.array(y)
-            mask = isnull(y)
+
             if not issubclass(y.dtype.type, np.int_):
+                mask = isnull(y)
                 y[mask] = 0
-            result = y.cumsum()
+                result = y.cumsum()
+
+                has_obs = (-mask).astype(int).cumsum() > 0
+                result[-has_obs] = np.NaN
+            else:
+                result = y.cumsum()
 
             return result
 
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index f26481ea8..96013d9fe 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -360,16 +360,19 @@ class DataMatrix(DataFrame):
 
         columns = []
         for j, col in enumerate(self.columns):
-            columns.append('%s%d  non-null values' %
-                           (_pfixed(col, space), counts[j]))
+            columns.append((col, '%s%d  non-null values' %
+                           (_pfixed(col, space), counts[j])))
 
         if self.objects is not None and len(self.objects.columns) > 0:
             n = len(self.objects.index)
             for col in self.objects:
                 line = '%s%d  non-null values' % (_pfixed(col, space), n)
-                columns.append(line)
+                columns.append((col, line))
 
-        columns.sort()
+        try:
+            columns = [c[1] for c in sorted(columns)]
+        except TypeError:
+            columns = sorted([c[1] for c in columns])
 
         dtypeLine = ''
 
@@ -861,10 +864,15 @@ class DataMatrix(DataFrame):
         """
         y = np.array(self.values, subok=True)
         if not issubclass(y.dtype.type, np.int_):
-            y[np.isnan(self.values)] = 0
-        theSum = y.cumsum(axis)
+            mask = np.isnan(self.values)
+            y[mask] = 0
+            result = y.cumsum(axis)
+            has_obs = (-mask).astype(int).cumsum(axis) > 0
+            result[-has_obs] = np.NaN
+        else:
+            result = y.cumsum(axis)
 
-        return DataMatrix(theSum, index=self.index,
+        return DataMatrix(result, index=self.index,
                           columns=self.columns, objects=self.objects)
 
     def dropEmptyRows(self, specificColumns=None):
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index d4902db22..d02ee73f1 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1817,8 +1817,15 @@ def _homogenize(frames, intersect=True):
     index = None
     columns = None
 
+    adj_frames = {}
+    for k, v in frames.iteritems():
+        if isinstance(v, dict):
+            adj_frames[k] = DataMatrix(v)
+        else:
+            adj_frames[k] = v
+
     if intersect:
-        for key, frame in frames.iteritems():
+        for key, frame in adj_frames.iteritems():
             if index is None:
                 index = frame.index
             elif index is not frame.index:
@@ -1829,7 +1836,7 @@ def _homogenize(frames, intersect=True):
             else:
                 columns &= set(frame.cols())
     else:
-        for key, frame in frames.iteritems():
+        for key, frame in adj_frames.iteritems():
             if index is None:
                 index = frame.index
             elif index is not frame.index:
@@ -1843,10 +1850,10 @@ def _homogenize(frames, intersect=True):
     columns = sorted(columns)
 
     if intersect:
-        for key, frame in frames.iteritems():
+        for key, frame in adj_frames.iteritems():
             result[key] = frame.filterItems(columns).reindex(index)
     else:
-        for key, frame in frames.iteritems():
+        for key, frame in adj_frames.iteritems():
             if not isinstance(frame, DataMatrix):
                 frame = frame.toDataMatrix()
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 0dcb1d3ae..18f6702f9 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -70,7 +70,7 @@ def _seriesOpWrap(opname):
 
 class Series(np.ndarray, Picklable, Groupable):
     """
-    Generic indexed series (time series or otherwise) object.
+    Generic indexed series (time series or cross-section)
 
     Contains values in a numpy-ndarray with an optional bound index
     (also an array of dates, strings, or whatever you want the 'row
@@ -87,10 +87,13 @@ class Series(np.ndarray, Picklable, Groupable):
 
     Parameters
     ----------
-    data : array-like
-        Underlying values of Series, preferably as numpy ndarray
+    data : array-like or dict
+        Contains data stored in Series
     index : array-like
         Index object (or other iterable of same length as data)
+        Must be input if first argument is not a dict. If both a dict
+        and index sequence are used, the index will override the keys
+        found in the dict.
 
     Note
     ----
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index e2988f6fc..61621f622 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -96,6 +96,11 @@ class TestDataFrame(unittest.TestCase):
         frame = self.klass({'A' : {'1' : 1, '2' : 2}})
         self.assert_(np.array_equal(frame.index, ['1', '2']))
 
+        # empty dict plus index
+        idx = Index([0, 1, 2])
+        frame = self.klass({}, index=idx)
+        self.assert_(frame.index is idx)
+
     def test_constructor_dict_cast(self):
         # cast float tests
         test_data = {
diff --git a/pandas/stats/api.py b/pandas/stats/api.py
index 81db968db..fabd25825 100644
--- a/pandas/stats/api.py
+++ b/pandas/stats/api.py
@@ -2,20 +2,8 @@
 Common namespace of statistical functions
 """
 
-# pylint: disable-msg=W0611,W0614
+# pylint: disable-msg=W0611,W0614,W0401
 
 from pandas.stats.moments import *
-
-try:
-    import scipy.stats as _stats
-
-    from pandas.stats.interface import ols
-    from pandas.stats.fama_macbeth import fama_macbeth
-
-    del _stats
-except ImportError:
-    def ols(*args, **kwargs):
-        """
-        Stub to give error message for missing SciPy
-        """
-        raise Exception('Must install SciPy to use OLS functionality')
+from pandas.stats.interface import ols
+from pandas.stats.fama_macbeth import fama_macbeth
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
index 7a2f7218a..eb0dead5e 100644
--- a/pandas/stats/interface.py
+++ b/pandas/stats/interface.py
@@ -72,6 +72,11 @@ def ols(**kwargs):
     # Run expanding panel OLS with window 10 and entity clustering.
     result = ols(y=y, x=x, cluster=ENTITY, window_type=EXPANDING, window=10)
     """
+    try:
+        import scipy as _
+    except ImportError:
+        raise Exception('Must install SciPy to use OLS functionality')
+
     pool = kwargs.get('pool')
     if 'pool' in kwargs:
         del kwargs['pool']
diff --git a/pandas/stats/math.py b/pandas/stats/math.py
index b5f565f9d..c9c3ce68f 100644
--- a/pandas/stats/math.py
+++ b/pandas/stats/math.py
@@ -3,7 +3,6 @@
 
 from __future__ import division
 
-from scipy import stats
 import numpy as np
 import numpy.linalg as linalg
 
@@ -109,6 +108,7 @@ def calc_F(R, r, beta, var_beta, nobs, df):
     -------
     F value, (q, df_resid), p value
     """
+    from scipy.stats import f
 
     hyp = np.dot(R, beta.reshape(len(beta), 1)) - r
     RSR = np.dot(R, np.dot(var_beta, R.T))
@@ -117,7 +117,7 @@ def calc_F(R, r, beta, var_beta, nobs, df):
 
     F = np.dot(hyp.T, np.dot(inv(RSR), hyp)).squeeze() / q
 
-    p_value = 1 - stats.f.cdf(F, q, nobs - df)
+    p_value = 1 - f.cdf(F, q, nobs - df)
 
     return F, (q, nobs - df), p_value
 
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index fa709355c..acfd0f112 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -8,7 +8,6 @@ from itertools import izip, starmap
 from StringIO import StringIO
 
 import numpy as np
-from scipy import stats
 
 from pandas.core.api import DataFrame, DataMatrix, Series
 from pandas.util.decorators import cache_readonly
@@ -136,6 +135,8 @@ class OLS(object):
     @cache_readonly
     def _f_stat_raw(self):
         """Returns the raw f-stat value."""
+        from scipy.stats import f
+
         cols = self._x.columns
 
         if self._nw_lags is None:
@@ -146,7 +147,7 @@ class OLS(object):
                 q -= 1
 
             shape = q, self.df_resid
-            p_value = 1 - stats.f.cdf(F, shape[0], shape[1])
+            p_value = 1 - f.cdf(F, shape[0], shape[1])
             return F, shape, p_value
 
         k = len(cols)
@@ -221,8 +222,10 @@ class OLS(object):
     @cache_readonly
     def _p_value_raw(self):
         """Returns the raw p values."""
-        return 2 * stats.t.sf(np.fabs(self._t_stat_raw),
-                              self._df_resid_raw)
+        from scipy.stats import t
+
+        return 2 * t.sf(np.fabs(self._t_stat_raw),
+                        self._df_resid_raw)
 
     @cache_readonly
     def p_value(self):
@@ -232,8 +235,10 @@ class OLS(object):
     @cache_readonly
     def _r2_raw(self):
         """Returns the raw r-squared values."""
+        has_intercept = np.abs(self._resid_raw.sum()) < _FP_ERR
+
         if self._intercept:
-            return self.sm_ols.rsquared
+            return 1 - self.sm_ols.ssr / self.sm_ols.centered_tss
         else:
             return 1 - self.sm_ols.ssr / self.sm_ols.uncentered_tss
 
@@ -729,13 +734,21 @@ class MovingOLS(OLS):
         valid = self._time_has_obs
         cum_xx = []
 
+        if isinstance(x, DataFrame):
+            _indexMap = x.index.indexMap
+            def slicer(df, dt):
+                i = _indexMap[dt]
+                return df.values[i:i+1, :]
+        else:
+            slicer = lambda df, dt: df.truncate(dt, dt).values
+
         last = np.zeros((K, K))
         for i, date in enumerate(dates):
             if not valid[i]:
                 cum_xx.append(last)
                 continue
 
-            x_slice = x.truncate(date, date).values
+            x_slice = slicer(x, date)
             xx = last = last + np.dot(x_slice.T, x_slice)
             cum_xx.append(xx)
 
@@ -746,14 +759,32 @@ class MovingOLS(OLS):
         valid = self._time_has_obs
         cum_xy = []
 
+        if isinstance(x, DataFrame):
+            _x_indexMap = x.index.indexMap
+            def x_slicer(df, dt):
+                i = _x_indexMap[dt]
+                return df.values[i:i+1, :]
+        else:
+            x_slicer = lambda df, dt: df.truncate(dt, dt).values
+
+
+        if isinstance(y, Series):
+            _y_indexMap = y.index.indexMap
+            _values = y.values()
+            def y_slicer(df, dt):
+                i = _y_indexMap[dt]
+                return _values[i:i+1]
+        else:
+            y_slicer = lambda s, dt: _y_converter(s.truncate(dt, dt))
+
         last = np.zeros(len(x.cols()))
         for i, date in enumerate(dates):
             if not valid[i]:
                 cum_xy.append(last)
                 continue
 
-            x_slice = x.truncate(date, date).values
-            y_slice = _y_converter(y.truncate(date, date))
+            x_slice = x_slicer(x, date)
+            y_slice = y_slicer(y, date)
 
             xy = last = last + np.dot(x_slice.T, y_slice)
             cum_xy.append(xy)
@@ -783,6 +814,8 @@ class MovingOLS(OLS):
     @cache_readonly
     def _f_stat_raw(self):
         """Returns the raw f-stat value."""
+        from scipy.stats import f
+
         items = self.beta.columns
         nobs = self._nobs
         df = self._df_raw
@@ -797,7 +830,7 @@ class MovingOLS(OLS):
                 q -= 1
 
             def get_result_simple(Fst, d):
-                return Fst, (q, d), 1 - stats.f.cdf(Fst, q, d)
+                return Fst, (q, d), 1 - f.cdf(Fst, q, d)
 
             # Compute the P-value for each pair
             result = starmap(get_result_simple, izip(F, df_resid))
@@ -825,7 +858,9 @@ class MovingOLS(OLS):
     @cache_readonly
     def _p_value_raw(self):
         """Returns the raw p values."""
-        result = [2 * stats.t.sf(a, b)
+        from scipy.stats import t
+
+        result = [2 * t.sf(a, b)
                   for a, b in izip(np.fabs(self._t_stat_raw),
                                    self._df_resid_raw)]
 
@@ -1102,7 +1137,7 @@ def _combine_rhs(rhs):
     if isinstance(rhs, Series):
         series['x'] = rhs
     elif isinstance(rhs, DataFrame):
-        _safe_update(series, rhs)
+        return rhs
     elif isinstance(rhs, dict):
         for name, value in rhs.iteritems():
             if isinstance(value, Series):
@@ -1137,23 +1172,34 @@ def _filter_data(lhs, rhs):
 
     combined_rhs = _combine_rhs(rhs)
 
-    pre_filtered_rhs = DataMatrix(combined_rhs).dropIncompleteRows()
+    if not isinstance(combined_rhs, DataFrame):
+        rhs = DataMatrix(combined_rhs)
 
-    # Union of all indices
-    combined_rhs['_y'] = lhs
-    full_dataset = DataMatrix(combined_rhs)
+    rhs_valid = np.isfinite(rhs.values).sum(1) == len(rhs.columns)
 
-    index = full_dataset.index
+    if not rhs_valid.all():
+        pre_filtered_rhs = rhs[rhs_valid]
+    else:
+        pre_filtered_rhs = rhs
 
-    obs_count = full_dataset.count(axis=1).values()
-    valid = obs_count == len(full_dataset.cols())
+    index = lhs.index + rhs.index
+    if not index.equals(rhs.index) or not index.equals(lhs.index):
+        rhs = rhs.reindex(index)
+        lhs = lhs.reindex(index)
 
-    filtered_rhs = full_dataset.reindex(index[valid])
-    filtered_lhs = filtered_rhs.pop('_y')
+        rhs_valid = np.isfinite(rhs.values).sum(1) == len(rhs.columns)
 
-    return filtered_lhs, filtered_rhs, pre_filtered_rhs, index, valid
+    lhs_valid = np.isfinite(lhs.values())
+    valid = rhs_valid & lhs_valid
 
+    if not valid.all():
+        filt_index = rhs.index[valid]
+        filtered_rhs = rhs.reindex(filt_index)
+        filtered_lhs = lhs.reindex(filt_index)
+    else:
+        filtered_rhs, filtered_lhs = rhs, lhs
 
+    return filtered_lhs, filtered_rhs, pre_filtered_rhs, index, valid
 
 # A little kludge so we can use this method for both
 # MovingOLS and MovingPanelOLS
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index 34006058f..0dd1cb5d2 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -2,7 +2,6 @@ from __future__ import division
 
 from itertools import izip
 import numpy as np
-import scipy as sp
 
 from pandas.util.decorators import cache_readonly
 from pandas.core.matrix import DataFrame, DataMatrix
@@ -108,6 +107,7 @@ class VAR(object):
         p-values of the f-stats.
         """
         from pandas.stats.api import ols
+        from scipy.stats import f
 
         params = self._k * self._p
 
@@ -142,7 +142,7 @@ class VAR(object):
                 f_stat = ((ssr_reduced - ssr_full) / M) / (ssr_full / (N - K))
                 f_stats.append(f_stat)
 
-                p_value = 1 - sp.stats.f.cdf(f_stat, M, N - K)
+                p_value = 1 - f.cdf(f_stat, M, N - K)
                 p_values.append(p_value)
 
             f_stat_dict[col] = Series(f_stats, self._columns)
diff --git a/setup.py b/setup.py
index cbe02a732..ceb41c01f 100644
--- a/setup.py
+++ b/setup.py
@@ -41,10 +41,10 @@ CLASSIFIERS = [
 ]
 
 MAJOR = 0
-MINOR = 2
+MINOR = '2beta'
 
 def get_version():
-    return '%d.%d' % (MAJOR, MINOR)
+    return '%s.%s' % (MAJOR, MINOR)
 
 
 def configuration(parent_package='', top_path=None):
