commit ff457456b3a5da00b3ee74f7e2589227282aacae
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue May 8 21:35:45 2012 -0400

    REF: great int32 -> int64 migration, though 0.01% chance of success on 32-bit

diff --git a/pandas/core/common.py b/pandas/core/common.py
index 7096e3204..1af5efee6 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -195,7 +195,7 @@ def take_1d(arr, indexer, out=None, fill_value=np.nan):
         # Cython methods expects 32-bit integers
         indexer = np.array(indexer, dtype=np.int32)
 
-    indexer = _ensure_int32(indexer)
+    indexer = _ensure_int64(indexer)
     out_passed = out is not None
     take_f = _take1d_dict.get(dtype_str)
 
@@ -239,8 +239,8 @@ def take_2d_multi(arr, row_idx, col_idx, fill_value=np.nan):
 
     take_f = _get_take2d_function(dtype_str, axis='multi')
 
-    row_idx = _ensure_int32(row_idx)
-    col_idx = _ensure_int32(col_idx)
+    row_idx = _ensure_int64(row_idx)
+    col_idx = _ensure_int64(col_idx)
 
     out_shape = len(row_idx), len(col_idx)
 
@@ -280,7 +280,7 @@ def take_2d(arr, indexer, out=None, mask=None, needs_masking=None, axis=0,
         # Cython methods expects 32-bit integers
         indexer = np.array(indexer, dtype=np.int32)
 
-    indexer = _ensure_int32(indexer)
+    indexer = _ensure_int64(indexer)
 
     if dtype_str in ('int32', 'int64', 'bool'):
         if mask is None:
diff --git a/pandas/core/factor.py b/pandas/core/factor.py
index 8ffb6934b..9f0d55c5a 100644
--- a/pandas/core/factor.py
+++ b/pandas/core/factor.py
@@ -60,7 +60,7 @@ def unique_with_labels(values):
 
     try:
         sorter = uniques.argsort()
-        reverse_indexer = np.empty(len(sorter), dtype='i4')
+        reverse_indexer = np.empty(len(sorter), dtype=np.int64)
         reverse_indexer.put(sorter, np.arange(len(sorter)))
         labels = reverse_indexer.take(labels)
         uniques = uniques.take(sorter)
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index e4f074208..d7db4b288 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -2061,7 +2061,7 @@ class DataFrame(NDFrame):
                                copy, fill_value):
         new_data = self._data
         if row_indexer is not None:
-            row_indexer = com._ensure_int32(row_indexer)
+            row_indexer = com._ensure_int64(row_indexer)
             new_data = new_data.reindex_indexer(index, row_indexer, axis=1,
                                                 fill_value=fill_value)
         elif index is not None and index is not new_data.axes[1]:
@@ -2070,7 +2070,7 @@ class DataFrame(NDFrame):
 
         if col_indexer is not None:
             # TODO: speed up on homogeneous DataFrame objects
-            col_indexer = com._ensure_int32(col_indexer)
+            col_indexer = com._ensure_int64(col_indexer)
             new_data = new_data.reindex_indexer(columns, col_indexer, axis=0,
                                                 fill_value=fill_value)
         elif columns is not None and columns is not new_data.axes[0]:
@@ -2239,7 +2239,7 @@ class DataFrame(NDFrame):
                 return self.reindex(columns=new_columns)
         else:
             new_values = com.take_2d(self.values,
-                                     com._ensure_int32(indices),
+                                     com._ensure_int64(indices),
                                      axis=axis)
             if axis == 0:
                 new_columns = self.columns
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 45d024f46..fc81102ea 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -563,7 +563,7 @@ class Grouper(object):
         comp_ids, obs_group_ids = self._get_compressed_labels()
 
         ngroups = len(obs_group_ids)
-        comp_ids = com._ensure_int32(comp_ids)
+        comp_ids = com._ensure_int64(comp_ids)
         return comp_ids, obs_group_ids, ngroups
 
     def _get_compressed_labels(self):
@@ -653,7 +653,7 @@ class Grouper(object):
 
         # will be filled in Cython function
         result = np.empty(out_shape, dtype=np.float64)
-        counts = np.zeros(self.ngroups, dtype=np.int32)
+        counts = np.zeros(self.ngroups, dtype=np.int64)
 
         result = self._aggregate(result, counts, values, how)
 
@@ -773,7 +773,7 @@ def generate_bins_generic(values, binner, closed):
     if values[lenidx-1] > binner[lenbin-1]:
         raise ValueError("Values falls after last bin")
 
-    bins   = np.empty(lenbin - 1, dtype=np.int32)
+    bins   = np.empty(lenbin - 1, dtype=np.int64)
 
     j  = 0 # index into values
     bc = 0 # bin count
@@ -803,7 +803,7 @@ class CustomGrouper(object):
 class BinGrouper(Grouper):
 
     def __init__(self, bins, binlabels, filter_empty=False):
-        self.bins = com._ensure_int32(bins)
+        self.bins = com._ensure_int64(bins)
         self.binlabels = _ensure_index(binlabels)
         self._filter_empty_groups = filter_empty
 
@@ -1809,7 +1809,7 @@ def generate_groups(data, group_index, ngroups, axis=0, factory=lambda x: x):
     -------
     generator
     """
-    group_index = com._ensure_int32(group_index)
+    group_index = com._ensure_int64(group_index)
 
     indexer = lib.groupsort_indexer(group_index, ngroups)[0]
     group_index = group_index.take(indexer)
@@ -1906,7 +1906,7 @@ def _indexer_from_factorized(labels, shape, compress=True):
         comp_ids = group_index
         max_group = np.prod(shape)
 
-    indexer, _ = lib.groupsort_indexer(comp_ids.astype('i4'), max_group)
+    indexer, _ = lib.groupsort_indexer(comp_ids.astype(np.int64), max_group)
 
     return indexer
 
@@ -1932,7 +1932,7 @@ class _KeyMapper(object):
     def __init__(self, comp_ids, ngroups, labels, levels):
         self.levels = levels
         self.labels = labels
-        self.comp_ids = comp_ids.astype('i8')
+        self.comp_ids = comp_ids.astype(np.int64)
 
         self.k = len(labels)
         self.tables = [lib.Int64HashTable(ngroups) for _ in range(self.k)]
@@ -1941,7 +1941,7 @@ class _KeyMapper(object):
 
     def _populate_tables(self):
         for labs, table in zip(self.labels, self.tables):
-            table.map(self.comp_ids, labs.astype('i8'))
+            table.map(self.comp_ids, labs.astype(np.int64))
 
     def get_key(self, comp_id):
         return tuple(level[table.get_item(comp_id)]
@@ -1966,7 +1966,7 @@ def _compress_group_index(group_index, sort=True):
     comp_ids = table.get_labels_groupby(group_index, uniques)
 
     # these are the unique ones we observed, in the order we observed them
-    obs_group_ids = np.array(uniques, dtype='i8')
+    obs_group_ids = np.array(uniques, dtype=np.int64)
 
     if sort and len(obs_group_ids) > 0:
         obs_group_ids, comp_ids = _reorder_by_uniques(obs_group_ids, comp_ids)
@@ -1978,7 +1978,7 @@ def _reorder_by_uniques(uniques, labels):
     sorter = uniques.argsort()
 
     # reverse_indexer is where elements came from
-    reverse_indexer = np.empty(len(sorter), dtype='i4')
+    reverse_indexer = np.empty(len(sorter), dtype=np.int64)
     reverse_indexer.put(sorter, np.arange(len(sorter)))
 
     mask = labels < 0
diff --git a/pandas/core/index.py b/pandas/core/index.py
index ca9e299c2..c50713eca 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -886,7 +886,7 @@ class Index(np.ndarray):
             old_level.join(right, how=how, return_indexers=True)
 
         if left_lev_indexer is not None:
-            left_lev_indexer = com._ensure_int32(left_lev_indexer)
+            left_lev_indexer = com._ensure_int64(left_lev_indexer)
             rev_indexer = lib.get_reverse_indexer(left_lev_indexer,
                                                   len(old_level))
 
@@ -1166,7 +1166,7 @@ class MultiIndex(Index):
             return Index(levels[0], name=name).take(labels[0])
 
         levels = [_ensure_index(lev) for lev in levels]
-        labels = [np.asarray(labs, dtype=np.int32) for labs in labels]
+        labels = [np.asarray(labs, dtype=np.int64) for labs in labels]
 
         values = [np.asarray(lev).take(lab)
                   for lev, lab in zip(levels, labels)]
diff --git a/pandas/src/datetime.pyx b/pandas/src/datetime.pyx
index 9e19c1596..bcbc080fc 100644
--- a/pandas/src/datetime.pyx
+++ b/pandas/src/datetime.pyx
@@ -212,7 +212,7 @@ cdef class _Timestamp(datetime):
         else:
             return datetime.__sub__(self, other)
 
-    def _get_field(self, field):
+    cpdef _get_field(self, field):
         out = fast_field_accessor(np.array([self.value], dtype=np.int64),
                                   field)
         return out[0]
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index 419b467a7..ee151b6eb 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -3,7 +3,7 @@ from pandas.util.py3compat import StringIO
 take_1d_template = """@cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_%(name)s(ndarray[%(c_type)s] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -38,7 +38,7 @@ def take_1d_%(name)s(ndarray[%(c_type)s] values,
 take_2d_axis0_template = """@cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_%(name)s(ndarray[%(c_type)s, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -78,7 +78,7 @@ def take_2d_axis0_%(name)s(ndarray[%(c_type)s, ndim=2] values,
 take_2d_axis1_template = """@cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_%(name)s(ndarray[%(c_type)s, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -120,8 +120,8 @@ def take_2d_axis1_%(name)s(ndarray[%(c_type)s, ndim=2] values,
 take_2d_multi_template = """@cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_%(name)s(ndarray[%(c_type)s, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -204,13 +204,13 @@ backfill_template = """@cython.boundscheck(False)
 def backfill_%(name)s(ndarray[%(c_type)s] old, ndarray[%(c_type)s] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef %(c_type)s cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -269,13 +269,13 @@ pad_template = """@cython.boundscheck(False)
 def pad_%(name)s(ndarray[%(c_type)s] old, ndarray[%(c_type)s] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef %(c_type)s cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -558,7 +558,7 @@ def left_join_indexer_%(name)s(ndarray[%(c_type)s] left,
                              ndarray[%(c_type)s] right):
     cdef:
         Py_ssize_t i, j, nleft, nright
-        ndarray[int32_t] indexer
+        ndarray[int64_t] indexer
         %(c_type)s lval, rval
 
     i = 0
@@ -566,7 +566,7 @@ def left_join_indexer_%(name)s(ndarray[%(c_type)s] left,
     nleft = len(left)
     nright = len(right)
 
-    indexer = np.empty(nleft, dtype=np.int32)
+    indexer = np.empty(nleft, dtype=np.int64)
     while True:
         if i == nleft:
             break
@@ -609,7 +609,7 @@ def inner_join_indexer_%(name)s(ndarray[%(c_type)s] left,
     cdef:
         Py_ssize_t i, j, k, nright, nleft, count
         %(c_type)s lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[%(c_type)s] result
 
     nleft = len(left)
@@ -635,8 +635,8 @@ def inner_join_indexer_%(name)s(ndarray[%(c_type)s] left,
 
     # do it again now that result size is known
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=%(dtype)s)
 
     i = 0
@@ -671,7 +671,7 @@ def outer_join_indexer_%(name)s(ndarray[%(c_type)s] left,
     cdef:
         Py_ssize_t i, j, nright, nleft, count
         %(c_type)s lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[%(c_type)s] result
 
     nleft = len(left)
@@ -706,8 +706,8 @@ def outer_join_indexer_%(name)s(ndarray[%(c_type)s] left,
 
             count += 1
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=%(dtype)s)
 
     # do it again, but populate the indexers / result
@@ -767,7 +767,7 @@ def outer_join_indexer_%(name)s(ndarray[%(c_type)s] left,
 
 put2d_template = """
 def put2d_%(name)s_%(dest_type)s(ndarray[%(c_type)s, ndim=2, cast=True] values,
-                              ndarray[int32_t] indexer, Py_ssize_t loc,
+                              ndarray[int64_t] indexer, Py_ssize_t loc,
                               ndarray[%(dest_type2)s] out):
     cdef:
         Py_ssize_t i, j, k
diff --git a/pandas/src/generated.pyx b/pandas/src/generated.pyx
index f92cf0ef0..ed5f12791 100644
--- a/pandas/src/generated.pyx
+++ b/pandas/src/generated.pyx
@@ -114,13 +114,13 @@ cpdef map_indices_bool(ndarray[uint8_t] index):
 def pad_float64(ndarray[float64_t] old, ndarray[float64_t] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef float64_t cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -175,13 +175,13 @@ def pad_float64(ndarray[float64_t] old, ndarray[float64_t] new,
 def pad_object(ndarray[object] old, ndarray[object] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef object cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -236,13 +236,13 @@ def pad_object(ndarray[object] old, ndarray[object] new,
 def pad_int32(ndarray[int32_t] old, ndarray[int32_t] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef int32_t cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -297,13 +297,13 @@ def pad_int32(ndarray[int32_t] old, ndarray[int32_t] new,
 def pad_int64(ndarray[int64_t] old, ndarray[int64_t] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef int64_t cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -358,13 +358,13 @@ def pad_int64(ndarray[int64_t] old, ndarray[int64_t] new,
 def pad_bool(ndarray[uint8_t] old, ndarray[uint8_t] new,
                    limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef uint8_t cur, next
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -420,13 +420,13 @@ def pad_bool(ndarray[uint8_t] old, ndarray[uint8_t] new,
 def backfill_float64(ndarray[float64_t] old, ndarray[float64_t] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef float64_t cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -482,13 +482,13 @@ def backfill_float64(ndarray[float64_t] old, ndarray[float64_t] new,
 def backfill_object(ndarray[object] old, ndarray[object] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef object cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -544,13 +544,13 @@ def backfill_object(ndarray[object] old, ndarray[object] new,
 def backfill_int32(ndarray[int32_t] old, ndarray[int32_t] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef int32_t cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -606,13 +606,13 @@ def backfill_int32(ndarray[int32_t] old, ndarray[int32_t] new,
 def backfill_int64(ndarray[int64_t] old, ndarray[int64_t] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef int64_t cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -668,13 +668,13 @@ def backfill_int64(ndarray[int64_t] old, ndarray[int64_t] new,
 def backfill_bool(ndarray[uint8_t] old, ndarray[uint8_t] new,
                       limit=None):
     cdef Py_ssize_t i, j, nleft, nright
-    cdef ndarray[int32_t, ndim=1] indexer
+    cdef ndarray[int64_t, ndim=1] indexer
     cdef uint8_t cur, prev
     cdef int lim, fill_count = 0
 
     nleft = len(old)
     nright = len(new)
-    indexer = np.empty(nright, dtype=np.int32)
+    indexer = np.empty(nright, dtype=np.int64)
     indexer.fill(-1)
 
     if limit is None:
@@ -1318,7 +1318,7 @@ def backfill_2d_inplace_bool(ndarray[uint8_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_float64(ndarray[float64_t] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -1351,7 +1351,7 @@ def take_1d_float64(ndarray[float64_t] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_object(ndarray[object] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -1384,7 +1384,7 @@ def take_1d_object(ndarray[object] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_int32(ndarray[int32_t] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -1417,7 +1417,7 @@ def take_1d_int32(ndarray[int32_t] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_int64(ndarray[int64_t] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -1450,7 +1450,7 @@ def take_1d_int64(ndarray[int64_t] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_1d_bool(ndarray[uint8_t] values,
-                     ndarray[int32_t] indexer,
+                     ndarray[int64_t] indexer,
                      out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, n, idx
@@ -1812,7 +1812,7 @@ def arrmap_bool(ndarray[uint8_t] index, object func):
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_float64(ndarray[float64_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -1850,7 +1850,7 @@ def take_2d_axis0_float64(ndarray[float64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_object(ndarray[object, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -1888,7 +1888,7 @@ def take_2d_axis0_object(ndarray[object, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_int32(ndarray[int32_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -1926,7 +1926,7 @@ def take_2d_axis0_int32(ndarray[int32_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_int64(ndarray[int64_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -1964,7 +1964,7 @@ def take_2d_axis0_int64(ndarray[int64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis0_bool(ndarray[uint8_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2003,7 +2003,7 @@ def take_2d_axis0_bool(ndarray[uint8_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_float64(ndarray[float64_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2043,7 +2043,7 @@ def take_2d_axis1_float64(ndarray[float64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_object(ndarray[object, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2083,7 +2083,7 @@ def take_2d_axis1_object(ndarray[object, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_int32(ndarray[int32_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2123,7 +2123,7 @@ def take_2d_axis1_int32(ndarray[int32_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_int64(ndarray[int64_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2163,7 +2163,7 @@ def take_2d_axis1_int64(ndarray[int64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_axis1_bool(ndarray[uint8_t, ndim=2] values,
-                           ndarray[int32_t] indexer,
+                           ndarray[int64_t] indexer,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2204,8 +2204,8 @@ def take_2d_axis1_bool(ndarray[uint8_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_float64(ndarray[float64_t, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2250,8 +2250,8 @@ def take_2d_multi_float64(ndarray[float64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_object(ndarray[object, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2296,8 +2296,8 @@ def take_2d_multi_object(ndarray[object, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_int32(ndarray[int32_t, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2342,8 +2342,8 @@ def take_2d_multi_int32(ndarray[int32_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_int64(ndarray[int64_t, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2388,8 +2388,8 @@ def take_2d_multi_int64(ndarray[int64_t, ndim=2] values,
 @cython.wraparound(False)
 @cython.boundscheck(False)
 def take_2d_multi_bool(ndarray[uint8_t, ndim=2] values,
-                           ndarray[int32_t] idx0,
-                           ndarray[int32_t] idx1,
+                           ndarray[int64_t] idx0,
+                           ndarray[int64_t] idx1,
                            out=None, fill_value=np.nan):
     cdef:
         Py_ssize_t i, j, k, n, idx
@@ -2438,7 +2438,7 @@ def left_join_indexer_float64(ndarray[float64_t] left,
                              ndarray[float64_t] right):
     cdef:
         Py_ssize_t i, j, nleft, nright
-        ndarray[int32_t] indexer
+        ndarray[int64_t] indexer
         float64_t lval, rval
 
     i = 0
@@ -2446,7 +2446,7 @@ def left_join_indexer_float64(ndarray[float64_t] left,
     nleft = len(left)
     nright = len(right)
 
-    indexer = np.empty(nleft, dtype=np.int32)
+    indexer = np.empty(nleft, dtype=np.int64)
     while True:
         if i == nleft:
             break
@@ -2483,7 +2483,7 @@ def left_join_indexer_object(ndarray[object] left,
                              ndarray[object] right):
     cdef:
         Py_ssize_t i, j, nleft, nright
-        ndarray[int32_t] indexer
+        ndarray[int64_t] indexer
         object lval, rval
 
     i = 0
@@ -2491,7 +2491,7 @@ def left_join_indexer_object(ndarray[object] left,
     nleft = len(left)
     nright = len(right)
 
-    indexer = np.empty(nleft, dtype=np.int32)
+    indexer = np.empty(nleft, dtype=np.int64)
     while True:
         if i == nleft:
             break
@@ -2528,7 +2528,7 @@ def left_join_indexer_int32(ndarray[int32_t] left,
                              ndarray[int32_t] right):
     cdef:
         Py_ssize_t i, j, nleft, nright
-        ndarray[int32_t] indexer
+        ndarray[int64_t] indexer
         int32_t lval, rval
 
     i = 0
@@ -2536,7 +2536,7 @@ def left_join_indexer_int32(ndarray[int32_t] left,
     nleft = len(left)
     nright = len(right)
 
-    indexer = np.empty(nleft, dtype=np.int32)
+    indexer = np.empty(nleft, dtype=np.int64)
     while True:
         if i == nleft:
             break
@@ -2573,7 +2573,7 @@ def left_join_indexer_int64(ndarray[int64_t] left,
                              ndarray[int64_t] right):
     cdef:
         Py_ssize_t i, j, nleft, nright
-        ndarray[int32_t] indexer
+        ndarray[int64_t] indexer
         int64_t lval, rval
 
     i = 0
@@ -2581,7 +2581,7 @@ def left_join_indexer_int64(ndarray[int64_t] left,
     nleft = len(left)
     nright = len(right)
 
-    indexer = np.empty(nleft, dtype=np.int32)
+    indexer = np.empty(nleft, dtype=np.int64)
     while True:
         if i == nleft:
             break
@@ -2620,7 +2620,7 @@ def outer_join_indexer_float64(ndarray[float64_t] left,
     cdef:
         Py_ssize_t i, j, nright, nleft, count
         float64_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[float64_t] result
 
     nleft = len(left)
@@ -2655,8 +2655,8 @@ def outer_join_indexer_float64(ndarray[float64_t] left,
 
             count += 1
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.float64)
 
     # do it again, but populate the indexers / result
@@ -2716,7 +2716,7 @@ def outer_join_indexer_object(ndarray[object] left,
     cdef:
         Py_ssize_t i, j, nright, nleft, count
         object lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[object] result
 
     nleft = len(left)
@@ -2751,8 +2751,8 @@ def outer_join_indexer_object(ndarray[object] left,
 
             count += 1
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=object)
 
     # do it again, but populate the indexers / result
@@ -2812,7 +2812,7 @@ def outer_join_indexer_int32(ndarray[int32_t] left,
     cdef:
         Py_ssize_t i, j, nright, nleft, count
         int32_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[int32_t] result
 
     nleft = len(left)
@@ -2847,8 +2847,8 @@ def outer_join_indexer_int32(ndarray[int32_t] left,
 
             count += 1
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.int32)
 
     # do it again, but populate the indexers / result
@@ -2908,7 +2908,7 @@ def outer_join_indexer_int64(ndarray[int64_t] left,
     cdef:
         Py_ssize_t i, j, nright, nleft, count
         int64_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[int64_t] result
 
     nleft = len(left)
@@ -2943,8 +2943,8 @@ def outer_join_indexer_int64(ndarray[int64_t] left,
 
             count += 1
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.int64)
 
     # do it again, but populate the indexers / result
@@ -3008,7 +3008,7 @@ def inner_join_indexer_float64(ndarray[float64_t] left,
     cdef:
         Py_ssize_t i, j, k, nright, nleft, count
         float64_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[float64_t] result
 
     nleft = len(left)
@@ -3034,8 +3034,8 @@ def inner_join_indexer_float64(ndarray[float64_t] left,
 
     # do it again now that result size is known
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.float64)
 
     i = 0
@@ -3071,7 +3071,7 @@ def inner_join_indexer_object(ndarray[object] left,
     cdef:
         Py_ssize_t i, j, k, nright, nleft, count
         object lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[object] result
 
     nleft = len(left)
@@ -3097,8 +3097,8 @@ def inner_join_indexer_object(ndarray[object] left,
 
     # do it again now that result size is known
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=object)
 
     i = 0
@@ -3134,7 +3134,7 @@ def inner_join_indexer_int32(ndarray[int32_t] left,
     cdef:
         Py_ssize_t i, j, k, nright, nleft, count
         int32_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[int32_t] result
 
     nleft = len(left)
@@ -3160,8 +3160,8 @@ def inner_join_indexer_int32(ndarray[int32_t] left,
 
     # do it again now that result size is known
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.int32)
 
     i = 0
@@ -3197,7 +3197,7 @@ def inner_join_indexer_int64(ndarray[int64_t] left,
     cdef:
         Py_ssize_t i, j, k, nright, nleft, count
         int64_t lval, rval
-        ndarray[int32_t] lindexer, rindexer
+        ndarray[int64_t] lindexer, rindexer
         ndarray[int64_t] result
 
     nleft = len(left)
@@ -3223,8 +3223,8 @@ def inner_join_indexer_int64(ndarray[int64_t] left,
 
     # do it again now that result size is known
 
-    lindexer = np.empty(count, dtype=np.int32)
-    rindexer = np.empty(count, dtype=np.int32)
+    lindexer = np.empty(count, dtype=np.int64)
+    rindexer = np.empty(count, dtype=np.int64)
     result = np.empty(count, dtype=np.int64)
 
     i = 0
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 6bb21e0d2..049f70b5f 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -72,22 +72,22 @@ cpdef groupby_indices_naive(ndarray[object] values):
 def groupby_indices(ndarray values):
     cdef:
         Py_ssize_t i, n = len(values)
-        ndarray[int32_t] labels, counts, arr, seen
-        int32_t loc
+        ndarray[int64_t] labels, counts, arr, seen
+        int64_t loc
         dict ids = {}
         object val
-        int32_t k
+        int64_t k
 
     ids, labels, counts = group_labels(values)
     seen = np.zeros_like(counts)
 
     # try not to get in trouble here...
-    cdef int32_t **vecs = <int32_t **> malloc(len(ids) * sizeof(int32_t*))
+    cdef int64_t **vecs = <int64_t **> malloc(len(ids) * sizeof(int64_t*))
     result = {}
     for i from 0 <= i < len(counts):
-        arr = np.empty(counts[i], dtype=np.int32)
+        arr = np.empty(counts[i], dtype=np.int64)
         result[ids[i]] = arr
-        vecs[i] = <int32_t *> arr.data
+        vecs[i] = <int64_t *> arr.data
 
     for i from 0 <= i < n:
         k = labels[i]
@@ -110,18 +110,18 @@ def is_lexsorted(list list_of_arrays):
     cdef:
         int i
         Py_ssize_t n, nlevels
-        int32_t k, cur, pre
+        int64_t k, cur, pre
         ndarray arr
 
     nlevels = len(list_of_arrays)
     n = len(list_of_arrays[0])
 
-    cdef int32_t **vecs = <int32_t**> malloc(nlevels * sizeof(int32_t*))
+    cdef int64_t **vecs = <int64_t**> malloc(nlevels * sizeof(int64_t*))
     for i from 0 <= i < nlevels:
-        # vecs[i] = <int32_t *> (<ndarray> list_of_arrays[i]).data
+        # vecs[i] = <int64_t *> (<ndarray> list_of_arrays[i]).data
 
         arr = list_of_arrays[i]
-        vecs[i] = <int32_t *> arr.data
+        vecs[i] = <int64_t *> arr.data
     # assume uniqueness??
 
     for i from 1 <= i < n:
@@ -148,12 +148,12 @@ def group_labels(ndarray[object] values):
     '''
     cdef:
         Py_ssize_t i, n = len(values)
-        ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
-        ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
+        ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
+        ndarray[int64_t] counts = np.empty(n, dtype=np.int64)
         dict ids = {}, reverse = {}
-        int32_t idx
+        int64_t idx
         object val
-        int32_t count = 0
+        int64_t count = 0
 
     for i from 0 <= i < n:
         val = values[i]
@@ -184,9 +184,9 @@ def group_labels(ndarray[object] values):
 def get_unique_labels(ndarray[object] values, dict idMap):
     cdef int i, length
     cdef object idx
-    cdef ndarray[int32_t] fillVec
+    cdef ndarray[int64_t] fillVec
     length = len(values)
-    fillVec = np.empty(length, dtype=np.int32)
+    fillVec = np.empty(length, dtype=np.int64)
     for i from 0 <= i < length:
         idx = values[i]
         fillVec[i] = idMap[idx]
@@ -195,24 +195,24 @@ def get_unique_labels(ndarray[object] values, dict idMap):
 
 @cython.boundscheck(False)
 @cython.wraparound(False)
-def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
+def groupsort_indexer(ndarray[int64_t] index, Py_ssize_t ngroups):
     cdef:
         Py_ssize_t i, loc, label, n
-        ndarray[int32_t] counts, where, result
+        ndarray[int64_t] counts, where, result
 
     # count group sizes, location 0 for NA
-    counts = np.zeros(ngroups + 1, dtype='i4')
+    counts = np.zeros(ngroups + 1, dtype=np.int64)
     n = len(index)
     for i from 0 <= i < n:
         counts[index[i] + 1] += 1
 
     # mark the start of each contiguous group of like-indexed data
-    where = np.zeros(ngroups + 1, dtype='i4')
+    where = np.zeros(ngroups + 1, dtype=np.int64)
     for i from 1 <= i < ngroups + 1:
         where[i] = where[i - 1] + counts[i - 1]
 
     # this is our indexer
-    result = np.zeros(n, dtype='i4')
+    result = np.zeros(n, dtype=np.int64)
     for i from 0 <= i < n:
         label = index[i] + 1
         result[where[label]] = i
@@ -225,9 +225,9 @@ def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_add(ndarray[float64_t, ndim=2] out,
-              ndarray[int32_t] counts,
+              ndarray[int64_t] counts,
               ndarray[float64_t, ndim=2] values,
-              ndarray[int32_t] labels):
+              ndarray[int64_t] labels):
     '''
     Only aggregates on axis=0
     '''
@@ -279,9 +279,9 @@ def group_add(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_prod(ndarray[float64_t, ndim=2] out,
-               ndarray[int32_t] counts,
+               ndarray[int64_t] counts,
                ndarray[float64_t, ndim=2] values,
-               ndarray[int32_t] labels):
+               ndarray[int64_t] labels):
     '''
     Only aggregates on axis=0
     '''
@@ -334,9 +334,9 @@ def group_prod(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_min(ndarray[float64_t, ndim=2] out,
-              ndarray[int32_t] counts,
+              ndarray[int64_t] counts,
               ndarray[float64_t, ndim=2] values,
-              ndarray[int32_t] labels):
+              ndarray[int64_t] labels):
     '''
     Only aggregates on axis=0
     '''
@@ -393,9 +393,9 @@ def group_min(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_max(ndarray[float64_t, ndim=2] out,
-              ndarray[int32_t] counts,
+              ndarray[int64_t] counts,
               ndarray[float64_t, ndim=2] values,
-              ndarray[int32_t] labels):
+              ndarray[int64_t] labels):
     '''
     Only aggregates on axis=0
     '''
@@ -452,9 +452,9 @@ def group_max(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_mean(ndarray[float64_t, ndim=2] out,
-               ndarray[int32_t] counts,
+               ndarray[int64_t] counts,
                ndarray[float64_t, ndim=2] values,
-               ndarray[int32_t] labels):
+               ndarray[int64_t] labels):
     cdef:
         Py_ssize_t i, j, N, K, lab
         float64_t val, count
@@ -502,9 +502,9 @@ def group_mean(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_var(ndarray[float64_t, ndim=2] out,
-              ndarray[int32_t] counts,
+              ndarray[int64_t] counts,
               ndarray[float64_t, ndim=2] values,
-              ndarray[int32_t] labels):
+              ndarray[int64_t] labels):
     cdef:
         Py_ssize_t i, j, N, K, lab
         float64_t val, ct
@@ -572,7 +572,7 @@ def generate_bins_dt64(ndarray[int64_t] values, ndarray[int64_t] binner,
     """
     cdef:
         Py_ssize_t lenidx, lenbin, i, j, bc, vc
-        ndarray[int32_t] bins
+        ndarray[int64_t] bins
         int64_t l_bin, r_bin
         bint right_closed = closed == 'right'
 
@@ -589,7 +589,7 @@ def generate_bins_dt64(ndarray[int64_t] values, ndarray[int64_t] binner,
     if values[lenidx-1] > binner[lenbin-1]:
         raise ValueError("Values falls after last bin")
 
-    bins   = np.empty(lenbin - 1, dtype=np.int32)
+    bins   = np.empty(lenbin - 1, dtype=np.int64)
 
     j  = 0 # index into values
     bc = 0 # bin count
@@ -614,9 +614,9 @@ def generate_bins_dt64(ndarray[int64_t] values, ndarray[int64_t] binner,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_add_bin(ndarray[float64_t, ndim=2] out,
-                  ndarray[int32_t] counts,
+                  ndarray[int64_t] counts,
                   ndarray[float64_t, ndim=2] values,
-                  ndarray[int32_t] bins):
+                  ndarray[int64_t] bins):
     '''
     Only aggregates on axis=0
     '''
@@ -671,9 +671,9 @@ def group_add_bin(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_prod_bin(ndarray[float64_t, ndim=2] out,
-                  ndarray[int32_t] counts,
+                  ndarray[int64_t] counts,
                   ndarray[float64_t, ndim=2] values,
-                  ndarray[int32_t] bins):
+                  ndarray[int64_t] bins):
     '''
     Only aggregates on axis=0
     '''
@@ -728,9 +728,9 @@ def group_prod_bin(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_min_bin(ndarray[float64_t, ndim=2] out,
-                   ndarray[int32_t] counts,
+                   ndarray[int64_t] counts,
                    ndarray[float64_t, ndim=2] values,
-                   ndarray[int32_t] bins):
+                   ndarray[int64_t] bins):
     '''
     Only aggregates on axis=0
     '''
@@ -790,9 +790,9 @@ def group_min_bin(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_max_bin(ndarray[float64_t, ndim=2] out,
-                  ndarray[int32_t] counts,
+                  ndarray[int64_t] counts,
                   ndarray[float64_t, ndim=2] values,
-                  ndarray[int32_t] bins):
+                  ndarray[int64_t] bins):
     '''
     Only aggregates on axis=0
     '''
@@ -852,9 +852,9 @@ def group_max_bin(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_ohlc(ndarray[float64_t, ndim=2] out,
-                  ndarray[int32_t] counts,
+                  ndarray[int64_t] counts,
                   ndarray[float64_t, ndim=2] values,
-                  ndarray[int32_t] bins):
+                  ndarray[int64_t] bins):
     '''
     Only aggregates on axis=0
     '''
@@ -927,9 +927,9 @@ def group_ohlc(ndarray[float64_t, ndim=2] out,
 # @cython.boundscheck(False)
 # @cython.wraparound(False)
 def group_mean_bin(ndarray[float64_t, ndim=2] out,
-                   ndarray[int32_t] counts,
+                   ndarray[int64_t] counts,
                    ndarray[float64_t, ndim=2] values,
-                   ndarray[int32_t] bins):
+                   ndarray[int64_t] bins):
     cdef:
         Py_ssize_t i, j, N, K, ngroups, b
         float64_t val, count
@@ -982,9 +982,9 @@ def group_mean_bin(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_var_bin(ndarray[float64_t, ndim=2] out,
-                  ndarray[int32_t] counts,
+                  ndarray[int64_t] counts,
                   ndarray[float64_t, ndim=2] values,
-                  ndarray[int32_t] bins):
+                  ndarray[int64_t] bins):
 
     cdef:
         Py_ssize_t i, j, N, K, ngroups, b
@@ -1066,12 +1066,12 @@ def row_bool_subset(ndarray[float64_t, ndim=2] values,
 
 
 
-def group_count(ndarray[int32_t] values, Py_ssize_t size):
+def group_count(ndarray[int64_t] values, Py_ssize_t size):
     cdef:
         Py_ssize_t i, n = len(values)
-        ndarray[int32_t] counts
+        ndarray[int64_t] counts
 
-    counts = np.zeros(size, dtype='i4')
+    counts = np.zeros(size, dtype=np.int64)
     for i in range(n):
         counts[values[i]] += 1
     return counts
@@ -1143,7 +1143,7 @@ def _bucket_locs(index, buckets, inclusive=False):
     return locs
 
 def count_level_1d(ndarray[uint8_t, cast=True] mask,
-                   ndarray[int32_t] labels, Py_ssize_t max_bin):
+                   ndarray[int64_t] labels, Py_ssize_t max_bin):
     cdef:
         Py_ssize_t i, n
         ndarray[int64_t] counts
@@ -1159,7 +1159,7 @@ def count_level_1d(ndarray[uint8_t, cast=True] mask,
     return counts
 
 def count_level_2d(ndarray[uint8_t, ndim=2, cast=True] mask,
-                   ndarray[int32_t] labels, Py_ssize_t max_bin):
+                   ndarray[int64_t] labels, Py_ssize_t max_bin):
     cdef:
         Py_ssize_t i, j, k, n
         ndarray[int64_t, ndim=2] counts
@@ -1203,16 +1203,16 @@ def duplicated(list values, take_last=False):
     return result.view(np.bool_)
 
 
-def generate_slices(ndarray[int32_t] labels, Py_ssize_t ngroups):
+def generate_slices(ndarray[int64_t] labels, Py_ssize_t ngroups):
     cdef:
         Py_ssize_t i, group_size, n, lab, start
         object slobj
-        ndarray[int32_t] starts
+        ndarray[int64_t] starts
 
     n = len(labels)
 
-    starts = np.zeros(ngroups, dtype='i4')
-    ends = np.zeros(ngroups, dtype='i4')
+    starts = np.zeros(ngroups, dtype=np.int64)
+    ends = np.zeros(ngroups, dtype=np.int64)
 
     start = 0
     group_size = 0
@@ -1228,17 +1228,11 @@ def generate_slices(ndarray[int32_t] labels, Py_ssize_t ngroups):
     return starts, ends
 
 
-def groupby_arrays(ndarray index, ndarray _labels):
+def groupby_arrays(ndarray index, ndarray[int64_t] labels):
     cdef:
         Py_ssize_t i, lab, cur, start, n = len(index)
-        ndarray[int32_t] labels
         dict result = {}
 
-    if _labels.dtype == np.int32:
-        labels = _labels
-    else:
-        labels = _labels.astype(np.int32)
-
     index = np.asarray(index)
 
     # this is N log N. If this is a bottleneck may we worth fixing someday
diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index 40c31acd9..1f604eb4b 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -84,9 +84,9 @@ cdef class StringHashTable(HashTable):
     def get_indexer(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
+            ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
             char *buf
-            int32_t *resbuf = <int32_t*> labels.data
+            int64_t *resbuf = <int64_t*> labels.data
             khiter_t k
             kh_str_t *table = self.table
 
@@ -127,8 +127,8 @@ cdef class StringHashTable(HashTable):
     def factorize(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
-            ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
+            ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
+            ndarray[int64_t] counts = np.empty(n, dtype=np.int64)
             dict reverse = {}
             Py_ssize_t idx, count = 0
             int ret = 0
@@ -220,7 +220,7 @@ cdef class Int32HashTable(HashTable):
             int ret = 0
             int32_t val
             khiter_t k
-            ndarray[int32_t] locs = np.empty(n, dtype='i4')
+            ndarray[int32_t] locs = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -235,8 +235,8 @@ cdef class Int32HashTable(HashTable):
     def factorize(self, ndarray[int32_t] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
-            ndarray[int32_t] counts = np.empty(n, dtype=np.int32)
+            ndarray[int64_t] labels = np.empty(n, dtype=np.int64)
+            ndarray[int64_t] counts = np.empty(n, dtype=np.int64)
             dict reverse = {}
             Py_ssize_t idx, count = 0
             int ret = 0
@@ -346,7 +346,7 @@ cdef class Int64HashTable(HashTable):
             int ret = 0
             int64_t val
             khiter_t k
-            ndarray[int64_t] locs = np.empty(n, dtype='i8')
+            ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -364,7 +364,7 @@ cdef class Int64HashTable(HashTable):
             int ret = 0
             int64_t val
             khiter_t k
-            ndarray[int32_t] locs = np.empty(n, dtype='i4')
+            ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -385,15 +385,15 @@ cdef class Int64HashTable(HashTable):
                    Py_ssize_t count_prior, Py_ssize_t na_sentinel):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels
-            ndarray[int32_t] counts
+            ndarray[int64_t] labels
+            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             int64_t val
             khiter_t k
 
-        labels = np.empty(n, dtype=np.int32)
-        counts = np.empty(count_prior + n, dtype=np.int32)
+        labels = np.empty(n, dtype=np.int64)
+        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -415,13 +415,13 @@ cdef class Int64HashTable(HashTable):
     def get_labels_groupby(self, ndarray[int64_t] values, list uniques):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels
+            ndarray[int64_t] labels
             Py_ssize_t idx, count = 0
             int ret = 0
             int64_t val
             khiter_t k
 
-        labels = np.empty(n, dtype=np.int32)
+        labels = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -520,18 +520,18 @@ cdef class Float64HashTable(HashTable):
         return uniques, labels, counts
 
     cpdef get_labels(self, ndarray[float64_t] values, list uniques,
-                     Py_ssize_t count_prior, int32_t na_sentinel):
+                     Py_ssize_t count_prior, int64_t na_sentinel):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels
-            ndarray[int32_t] counts
+            ndarray[int64_t] labels
+            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             float64_t val
             khiter_t k
 
-        labels = np.empty(n, dtype=np.int32)
-        counts = np.empty(count_prior + n, dtype=np.int32)
+        labels = np.empty(n, dtype=np.int64)
+        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -571,7 +571,7 @@ cdef class Float64HashTable(HashTable):
             int ret = 0
             float64_t val
             khiter_t k
-            ndarray[int32_t] locs = np.empty(n, dtype=np.int32)
+            ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -682,7 +682,7 @@ cdef class PyObjectHashTable(HashTable):
             int ret = 0
             object val
             khiter_t k
-            ndarray[int32_t] locs = np.empty(n, dtype='i4')
+            ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -702,7 +702,7 @@ cdef class PyObjectHashTable(HashTable):
             object val
             khiter_t k
             long hval
-            ndarray[int32_t] locs = np.empty(n, dtype='i4')
+            ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
         # for i in range(n):
         #     val = values[i]
@@ -736,18 +736,18 @@ cdef class PyObjectHashTable(HashTable):
         return uniques
 
     cpdef get_labels(self, ndarray[object] values, list uniques,
-                     Py_ssize_t count_prior, int32_t na_sentinel):
+                     Py_ssize_t count_prior, int64_t na_sentinel):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels
-            ndarray[int32_t] counts
+            ndarray[int64_t] labels
+            ndarray[int64_t] counts
             Py_ssize_t idx, count = count_prior
             int ret = 0
             object val
             khiter_t k
 
-        labels = np.empty(n, dtype=np.int32)
-        counts = np.empty(count_prior + n, dtype=np.int32)
+        labels = np.empty(n, dtype=np.int64)
+        counts = np.empty(count_prior + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -793,7 +793,7 @@ cdef class Factorizer:
         # sort on
         if sort:
             sorter = list_to_object_array(self.uniques).argsort()
-            reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+            reverse_indexer = np.empty(len(sorter), dtype=np.int64)
             reverse_indexer.put(sorter, np.arange(len(sorter)))
 
             labels = reverse_indexer.take(labels)
@@ -827,7 +827,7 @@ cdef class Int64Factorizer:
         # sort on
         if sort:
             sorter = list_to_object_array(self.uniques).argsort()
-            reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+            reverse_indexer = np.empty(len(sorter), dtype=np.int64)
             reverse_indexer.put(sorter, np.arange(len(sorter)))
 
             labels = reverse_indexer.take(labels)
@@ -863,14 +863,14 @@ cdef class DictFactorizer:
     def get_labels(self, ndarray[object] values):
         cdef:
             Py_ssize_t i, n = len(values)
-            ndarray[int32_t] labels
-            ndarray[int32_t] counts
+            ndarray[int64_t] labels
+            ndarray[int64_t] counts
             Py_ssize_t idx, count = self.count
             int ret = 0
             object val
 
-        labels = np.empty(n, dtype=np.int32)
-        counts = np.empty(count + n, dtype=np.int32)
+        labels = np.empty(n, dtype=np.int64)
+        counts = np.empty(count + n, dtype=np.int64)
 
         for i in range(n):
             val = values[i]
@@ -894,7 +894,7 @@ cdef class DictFactorizer:
         # sort on
         if sort:
             sorter = list_to_object_array(self.uniques).argsort()
-            reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+            reverse_indexer = np.empty(len(sorter), dtype=np.int64)
             reverse_indexer.put(sorter, np.arange(len(sorter)))
 
             labels = reverse_indexer.take(labels)
@@ -939,7 +939,7 @@ def lookup2(ndarray[object] values):
         object val
         khiter_t k
         long hval
-        ndarray[int32_t] locs = np.empty(n, dtype='i4')
+        ndarray[int64_t] locs = np.empty(n, dtype=np.int64)
 
     # for i in range(n):
     #     val = values[i]
diff --git a/pandas/src/internals.pyx b/pandas/src/internals.pyx
deleted file mode 100644
index ed51c54d6..000000000
--- a/pandas/src/internals.pyx
+++ /dev/null
@@ -1,14 +0,0 @@
-def get_reverse_indexer(ndarray[int32_t] indexer, Py_ssize_t length):
-    cdef:
-        Py_ssize_t i, n = len(indexer)
-        ndarray[int32_t] rev_indexer
-        int32_t idx
-
-    rev_indexer = np.empty(length, dtype='i4')
-    rev_indexer.fill(-1)
-    for i in range(n):
-        idx = indexer[i]
-        if idx != -1:
-            rev_indexer[idx] = i
-
-    return rev_indexer
diff --git a/pandas/src/join.pyx b/pandas/src/join.pyx
index 16bf3842a..ea4bf2f98 100644
--- a/pandas/src/join.pyx
+++ b/pandas/src/join.pyx
@@ -1,12 +1,12 @@
 import time
 
-def inner_join(ndarray[int32_t] left, ndarray[int32_t] right,
+def inner_join(ndarray[int64_t] left, ndarray[int64_t] right,
                Py_ssize_t max_groups):
     cdef:
         Py_ssize_t i, j, k, count = 0
-        ndarray[int32_t] left_count, right_count, left_sorter, right_sorter
-        ndarray[int32_t] left_indexer, right_indexer
-        int32_t lc, rc
+        ndarray[int64_t] left_count, right_count, left_sorter, right_sorter
+        ndarray[int64_t] left_indexer, right_indexer
+        int64_t lc, rc
 
     # NA group in location 0
 
@@ -30,8 +30,8 @@ def inner_join(ndarray[int32_t] left, ndarray[int32_t] right,
     left_pos = left_count[0]
     right_pos = right_count[0]
 
-    left_indexer = np.empty(count, dtype='i4')
-    right_indexer = np.empty(count, dtype='i4')
+    left_indexer = np.empty(count, dtype=np.int64)
+    right_indexer = np.empty(count, dtype=np.int64)
 
     for i in range(1, max_groups + 1):
         lc = left_count[i]
@@ -50,13 +50,13 @@ def inner_join(ndarray[int32_t] left, ndarray[int32_t] right,
     return (_get_result_indexer(left_sorter, left_indexer),
             _get_result_indexer(right_sorter, right_indexer))
 
-def left_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
+def left_outer_join(ndarray[int64_t] left, ndarray[int64_t] right,
                     Py_ssize_t max_groups, sort=True):
     cdef:
         Py_ssize_t i, j, k, count = 0
-        ndarray[int32_t] left_count, right_count, left_sorter, right_sorter
-        ndarray[int32_t] left_indexer, right_indexer
-        int32_t lc, rc
+        ndarray[int64_t] left_count, right_count, left_sorter, right_sorter
+        ndarray[int64_t] left_indexer, right_indexer
+        int64_t lc, rc
 
     # NA group in location 0
 
@@ -79,8 +79,8 @@ def left_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
     left_pos = left_count[0]
     right_pos = right_count[0]
 
-    left_indexer = np.empty(count, dtype='i4')
-    right_indexer = np.empty(count, dtype='i4')
+    left_indexer = np.empty(count, dtype=np.int64)
+    right_indexer = np.empty(count, dtype=np.int64)
 
     for i in range(1, max_groups + 1):
         lc = left_count[i]
@@ -105,7 +105,7 @@ def left_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
     right_indexer = _get_result_indexer(right_sorter, right_indexer)
 
     if not sort:
-        rev = np.empty(len(left), dtype='i4')
+        rev = np.empty(len(left), dtype=np.int64)
         rev.put(left_sorter, np.arange(len(left)))
 
         right_indexer = right_indexer.take(rev)
@@ -114,13 +114,13 @@ def left_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
     return left_indexer, right_indexer
 
 
-def full_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
+def full_outer_join(ndarray[int64_t] left, ndarray[int64_t] right,
                     Py_ssize_t max_groups):
     cdef:
         Py_ssize_t i, j, k, count = 0
-        ndarray[int32_t] left_count, right_count, left_sorter, right_sorter
-        ndarray[int32_t] left_indexer, right_indexer
-        int32_t lc, rc
+        ndarray[int64_t] left_count, right_count, left_sorter, right_sorter
+        ndarray[int64_t] left_indexer, right_indexer
+        int64_t lc, rc
 
     # NA group in location 0
 
@@ -146,8 +146,8 @@ def full_outer_join(ndarray[int32_t] left, ndarray[int32_t] right,
     left_pos = left_count[0]
     right_pos = right_count[0]
 
-    left_indexer = np.empty(count, dtype='i4')
-    right_indexer = np.empty(count, dtype='i4')
+    left_indexer = np.empty(count, dtype=np.int64)
+    right_indexer = np.empty(count, dtype=np.int64)
 
     for i in range(1, max_groups + 1):
         lc = left_count[i]
@@ -184,24 +184,24 @@ def _get_result_indexer(sorter, indexer):
 
 @cython.boundscheck(False)
 @cython.wraparound(False)
-def join_sorter(ndarray[int32_t] index, Py_ssize_t ngroups):
+def join_sorter(ndarray[int64_t] index, Py_ssize_t ngroups):
     cdef:
         Py_ssize_t i, loc, label, n
-        ndarray[int32_t] counts, where, result
+        ndarray[int64_t] counts, where, result
 
     # count group sizes, location 0 for NA
-    counts = np.zeros(ngroups + 1, dtype='i4')
+    counts = np.zeros(ngroups + 1, dtype=np.int64)
     n = len(index)
     for i from 0 <= i < n:
         counts[index[i] + 1] += 1
 
     # mark the start of each contiguous group of like-indexed data
-    where = np.zeros(ngroups + 1, dtype='i4')
+    where = np.zeros(ngroups + 1, dtype=np.int64)
     for i from 1 <= i < ngroups + 1:
         where[i] = where[i - 1] + counts[i - 1]
 
     # this is our indexer
-    result = np.zeros(n, dtype='i4')
+    result = np.zeros(n, dtype=np.int64)
     for i from 0 <= i < n:
         label = index[i] + 1
         result[where[label]] = i
diff --git a/pandas/src/reduce.pyx b/pandas/src/reduce.pyx
index 312e5abce..3aa6388a1 100644
--- a/pandas/src/reduce.pyx
+++ b/pandas/src/reduce.pyx
@@ -143,13 +143,13 @@ cdef class SeriesBinGrouper:
     def get_result(self):
         cdef:
             ndarray arr, result
-            ndarray[int32_t] counts
+            ndarray[int64_t] counts
             Py_ssize_t i, n, group_size
             object res, chunk
             bint initialized = 0
             Slider vslider, islider
 
-        counts = np.zeros(self.ngroups, dtype='i4')
+        counts = np.zeros(self.ngroups, dtype=np.int64)
 
         if self.ngroups > 0:
             counts[0] = self.bins[0]
@@ -246,14 +246,14 @@ cdef class SeriesGrouper:
     def get_result(self):
         cdef:
             ndarray arr, result
-            ndarray[int32_t] labels, counts
+            ndarray[int64_t] labels, counts
             Py_ssize_t i, n, group_size, lab
             object res, chunk
             bint initialized = 0
             Slider vslider, islider
 
         labels = self.labels
-        counts = np.zeros(self.ngroups, dtype='i4')
+        counts = np.zeros(self.ngroups, dtype=np.int64)
         chunk = self.dummy
         group_size = 0
         n = len(self.arr)
diff --git a/pandas/src/tseries.pyx b/pandas/src/tseries.pyx
index 1b2d8472c..8f8ce424d 100644
--- a/pandas/src/tseries.pyx
+++ b/pandas/src/tseries.pyx
@@ -379,6 +379,23 @@ def fast_zip(list ndarrays):
 
     return result
 
+
+def get_reverse_indexer(ndarray[int64_t] indexer, Py_ssize_t length):
+    cdef:
+        Py_ssize_t i, n = len(indexer)
+        ndarray[int64_t] rev_indexer
+        int64_t idx
+
+    rev_indexer = np.empty(length, dtype=np.int64)
+    rev_indexer.fill(-1)
+    for i in range(n):
+        idx = indexer[i]
+        if idx != -1:
+            rev_indexer[idx] = i
+
+    return rev_indexer
+
+
 def has_infs_f4(ndarray[float32_t] arr):
     cdef:
         Py_ssize_t i, n = len(arr)
@@ -659,6 +676,5 @@ include "reduce.pyx"
 include "stats.pyx"
 include "properties.pyx"
 include "inference.pyx"
-include "internals.pyx"
 include "join.pyx"
 include "engines.pyx"
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index dcad7b8c8..ed818bb0d 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -540,9 +540,9 @@ class TestInt64Index(unittest.TestCase):
 
         eres = Int64Index([0, 1, 2, 4, 5, 6, 7, 8, 10, 12, 14, 16, 18, 25])
         elidx = np.array([0, -1, 1, 2, -1, 3, -1, 4, 5, 6, 7, 8, 9, -1],
-                         dtype='i4')
+                         dtype=np.int64)
         eridx = np.array([-1, 3, 4, -1, 5, -1, 0, -1, -1, 1, -1, -1, -1, 2],
-                         dtype='i4')
+                         dtype=np.int64)
 
         self.assert_(isinstance(res, Int64Index))
         self.assert_(res.equals(eres))
@@ -556,7 +556,7 @@ class TestInt64Index(unittest.TestCase):
         self.assert_(res.equals(noidx_res))
 
         eridx = np.array([-1, 0, 1, -1, 2, -1, 3, -1, -1, 4, -1, -1, -1, 5],
-                         dtype='i4')
+                         dtype=np.int64)
         self.assert_(isinstance(res, Int64Index))
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
@@ -607,7 +607,7 @@ class TestInt64Index(unittest.TestCase):
                                           return_indexers=True)
         eres = self.index
         eridx = np.array([-1, 4, -1, -1, -1, -1, 1, -1, -1, -1],
-                         dtype='i4')
+                         dtype=np.int64)
 
         self.assert_(isinstance(res, Int64Index))
         self.assert_(res.equals(eres))
@@ -618,7 +618,7 @@ class TestInt64Index(unittest.TestCase):
         res, lidx, ridx = self.index.join(other_mono, how='left',
                                           return_indexers=True)
         eridx = np.array([-1, 1, -1, -1, -1, -1, 4, -1, -1, -1],
-                         dtype='i4')
+                         dtype=np.int64)
         self.assert_(isinstance(res, Int64Index))
         self.assert_(res.equals(eres))
         self.assert_(lidx is None)
@@ -633,7 +633,7 @@ class TestInt64Index(unittest.TestCase):
                                           return_indexers=True)
         eres = other
         elidx = np.array([-1, 6, -1, -1, 1, -1],
-                         dtype='i4')
+                         dtype=np.int64)
 
         self.assert_(isinstance(other, Int64Index))
         self.assert_(res.equals(eres))
@@ -645,7 +645,7 @@ class TestInt64Index(unittest.TestCase):
                                           return_indexers=True)
         eres = other_mono
         elidx = np.array([-1, 1, -1, -1, 6, -1],
-                         dtype='i4')
+                         dtype=np.int64)
         self.assert_(isinstance(other, Int64Index))
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index e61948a09..86c031f5e 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -63,7 +63,7 @@ def test_left_join_indexer():
     b = np.array([2, 2, 3, 4, 4], dtype=np.int64)
 
     result = lib.left_join_indexer_int64(b, a)
-    expected = np.array([1, 1, 2, 3, 3], dtype='i4')
+    expected = np.array([1, 1, 2, 3, 3], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
 def test_left_outer_join_bug():
@@ -72,9 +72,9 @@ def test_left_outer_join_bug():
                      3, 0, 0, 1, 0, 3, 1, 0, 1, 0, 1, 1, 0, 2, 2, 2, 2, 2, 0,
                      3, 1, 2, 0, 0, 3, 1, 3, 2, 2, 0, 1, 3, 0, 2, 3, 2, 3, 3,
                      2, 3, 3, 1, 3, 2, 0, 0, 3, 1, 1, 1, 0, 2, 3, 3, 1, 2, 0,
-                     3, 1, 2, 0, 2], dtype=np.int32)
+                     3, 1, 2, 0, 2], dtype=np.int64)
 
-    right = np.array([3, 1], dtype=np.int32)
+    right = np.array([3, 1], dtype=np.int64)
     max_groups = 4
 
     lidx, ridx = lib.left_outer_join(left, right, max_groups, sort=False)
@@ -110,7 +110,7 @@ def test_outer_join_indexer():
     index_exp = np.array([0, 1, 2, 3, 4, 5, 7, 9], dtype=np.int64)
     assert_almost_equal(index, index_exp)
 
-    aexp = np.array([-1, 0, 1, 2, 3, 4, -1, -1], dtype=np.int32)
+    aexp = np.array([-1, 0, 1, 2, 3, 4, -1, -1], dtype=np.int64)
     bexp = np.array([0, -1, -1, 1, -1, 2, 3, 4])
     assert_almost_equal(ares, aexp)
     assert_almost_equal(bres, bexp)
@@ -138,17 +138,17 @@ def test_is_lexsorted():
     assert(not lib.is_lexsorted(failure))
 
 # def test_get_group_index():
-#     a = np.array([0, 1, 2, 0, 2, 1, 0, 0], dtype='i4')
-#     b = np.array([1, 0, 3, 2, 0, 2, 3, 0], dtype='i4')
-#     expected = np.array([1, 4, 11, 2, 8, 6, 3, 0], dtype='i4')
+#     a = np.array([0, 1, 2, 0, 2, 1, 0, 0], dtype=np.int64)
+#     b = np.array([1, 0, 3, 2, 0, 2, 3, 0], dtype=np.int64)
+#     expected = np.array([1, 4, 11, 2, 8, 6, 3, 0], dtype=np.int64)
 
 #     result = lib.get_group_index([a, b], (3, 4))
 
 #     assert(np.array_equal(result, expected))
 
 def test_groupsort_indexer():
-    a = np.random.randint(0, 1000, 100).astype('i4')
-    b = np.random.randint(0, 1000, 100).astype('i4')
+    a = np.random.randint(0, 1000, 100).astype(np.int64)
+    b = np.random.randint(0, 1000, 100).astype(np.int64)
 
     result = lib.groupsort_indexer(a, 1000)[0]
 
@@ -223,9 +223,9 @@ def test_rank():
     _check(np.array([4., nan, 5., 5., 5., nan, 1, 2, 4., nan]))
 
 def test_get_reverse_indexer():
-    indexer = np.array([-1, -1, 1, 2, 0, -1, 3, 4], dtype='i4')
+    indexer = np.array([-1, -1, 1, 2, 0, -1, 3, 4], dtype=np.int64)
     result = lib.get_reverse_indexer(indexer, 5)
-    expected = np.array([4, 2, 3, 6, 7], dtype='i4')
+    expected = np.array([4, 2, 3, 6, 7], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
 def test_pad_backfill_object_segfault():
@@ -234,19 +234,19 @@ def test_pad_backfill_object_segfault():
     new = np.array([datetime(2010, 12, 31)], dtype='O')
 
     result = lib.pad_object(old, new)
-    expected = np.array([-1], dtype='i4')
+    expected = np.array([-1], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
     result = lib.pad_object(new, old)
-    expected = np.array([], dtype='i4')
+    expected = np.array([], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
     result = lib.backfill_object(old, new)
-    expected = np.array([-1], dtype='i4')
+    expected = np.array([-1], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
     result = lib.backfill_object(new, old)
-    expected = np.array([], dtype='i4')
+    expected = np.array([], dtype=np.int64)
     assert(np.array_equal(result, expected))
 
 def test_arrmap():
@@ -259,7 +259,7 @@ def test_series_grouper():
     obj = Series(np.random.randn(10))
     dummy = obj[:0]
 
-    labels = np.array([-1, -1, -1, 0, 0, 0, 1, 1, 1, 1], dtype='i4')
+    labels = np.array([-1, -1, -1, 0, 0, 0, 1, 1, 1, 1], dtype=np.int64)
 
     grouper = lib.SeriesGrouper(obj, np.mean, labels, 2, dummy)
     result, counts = grouper.get_result()
@@ -267,7 +267,7 @@ def test_series_grouper():
     expected = np.array([obj[3:6].mean(), obj[6:].mean()])
     assert_almost_equal(result, expected)
 
-    exp_counts = np.array([3, 4], dtype=np.int32)
+    exp_counts = np.array([3, 4], dtype=np.int64)
     assert_almost_equal(counts, exp_counts)
 
 def test_series_bin_grouper():
@@ -283,7 +283,7 @@ def test_series_bin_grouper():
     expected = np.array([obj[:3].mean(), obj[3:6].mean(), obj[6:].mean()])
     assert_almost_equal(result, expected)
 
-    exp_counts = np.array([3, 3, 4], dtype=np.int32)
+    exp_counts = np.array([3, 3, 4], dtype=np.int64)
     assert_almost_equal(counts, exp_counts)
 
 def test_generate_bins():
@@ -309,8 +309,8 @@ class TestBinGroupers(unittest.TestCase):
 
     def setUp(self):
         self.obj = np.random.randn(10, 1)
-        self.labels = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
-        self.bins = np.array([3, 6], dtype=np.int32)
+        self.labels = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int64)
+        self.bins = np.array([3, 6], dtype=np.int64)
 
     def test_group_bin_functions(self):
         funcs = ['add', 'mean', 'prod', 'min', 'max', 'var']
@@ -333,21 +333,21 @@ class TestBinGroupers(unittest.TestCase):
     def _check_versions(self, irr_func, bin_func, np_func):
         obj = self.obj
 
-        cts = np.zeros(3, dtype=np.int32)
+        cts = np.zeros(3, dtype=np.int64)
         exp = np.zeros((3, 1), np.float64)
         irr_func(exp, cts, obj, self.labels)
 
         # bin-based version
-        bins = np.array([3, 6], dtype=np.int32)
+        bins = np.array([3, 6], dtype=np.int64)
         out  = np.zeros((3, 1), np.float64)
-        counts = np.zeros(len(out), dtype=np.int32)
+        counts = np.zeros(len(out), dtype=np.int64)
         bin_func(out, counts, obj, bins)
 
         assert_almost_equal(out, exp)
 
-        bins = np.array([3, 9, 10], dtype=np.int32)
+        bins = np.array([3, 9, 10], dtype=np.int64)
         out  = np.zeros((3, 1), np.float64)
-        counts = np.zeros(len(out), dtype=np.int32)
+        counts = np.zeros(len(out), dtype=np.int64)
         bin_func(out, counts, obj, bins)
         exp = np.array([np_func(obj[:3]), np_func(obj[3:9]),
                         np_func(obj[9:])],
@@ -355,9 +355,9 @@ class TestBinGroupers(unittest.TestCase):
         assert_almost_equal(out.squeeze(), exp)
 
         # duplicate bins
-        bins = np.array([3, 6, 10, 10], dtype=np.int32)
+        bins = np.array([3, 6, 10, 10], dtype=np.int64)
         out  = np.zeros((4, 1), np.float64)
-        counts = np.zeros(len(out), dtype=np.int32)
+        counts = np.zeros(len(out), dtype=np.int64)
         bin_func(out, counts, obj, bins)
         exp = np.array([np_func(obj[:3]), np_func(obj[3:6]),
                         np_func(obj[6:10]), np.nan],
@@ -368,9 +368,9 @@ class TestBinGroupers(unittest.TestCase):
 def test_group_ohlc():
     obj = np.random.randn(20)
 
-    bins = np.array([6, 12], dtype=np.int32)
+    bins = np.array([6, 12], dtype=np.int64)
     out  = np.zeros((3, 4), np.float64)
-    counts = np.zeros(len(out), dtype=np.int32)
+    counts = np.zeros(len(out), dtype=np.int64)
 
     lib.group_ohlc(out, counts, obj[:, None], bins)
 
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 0b61db569..7f8409b39 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -145,9 +145,11 @@ class _MergeOperation(object):
             # max groups = largest possible number of distinct groups
             left_key, right_key, max_groups = self._get_group_keys()
 
+            # left_key = com._ensure_int64(left_key)
+            # right_key = com._ensure_int64(right_key)
+
             join_func = _join_functions[self.how]
-            left_indexer, right_indexer = join_func(left_key.astype('i4'),
-                                                    right_key.astype('i4'),
+            left_indexer, right_indexer = join_func(left_key, right_key,
                                                     max_groups)
 
             if self.right_index:
@@ -339,8 +341,8 @@ def _get_multiindex_indexer(join_keys, index, sort=False):
                          sort=False)
 
     left_indexer, right_indexer = \
-        lib.left_outer_join(left_group_key.astype('i4'),
-                            right_group_key.astype('i4'),
+        lib.left_outer_join(com._ensure_int64(left_group_key),
+                            com._ensure_int64(right_group_key),
                             max_groups, sort=False)
 
     return left_indexer, right_indexer
@@ -349,7 +351,8 @@ def _get_single_indexer(join_key, index, sort=False):
     left_key, right_key, count = _factorize_objects(join_key, index, sort=sort)
 
     left_indexer, right_indexer = \
-        lib.left_outer_join(left_key.astype('i4'), right_key.astype('i4'),
+        lib.left_outer_join(com._ensure_int64(left_key),
+                            com._ensure_int64(right_key),
                             count, sort=sort)
 
     return left_indexer, right_indexer
@@ -395,11 +398,8 @@ def _factorize_int64(left_index, right_index, sort=True):
     rizer = lib.Int64Factorizer(max(len(left_index), len(right_index)))
 
     # 32-bit compatibility
-    if left_index.dtype != np.int64:  # pragma: no cover
-        left_index = left_index.astype('i8')
-
-    if right_index.dtype != np.int64:  # pragma: no cover
-        right_index = right_index.astype('i8')
+    left_index = com._ensure_int64(left_index)
+    right_index = com._ensure_int64(right_index)
 
     llab, _ = rizer.factorize(left_index)
     rlab, _ = rizer.factorize(right_index)
@@ -431,7 +431,7 @@ def _sort_labels(uniques, left, right):
 
     sorter = uniques.argsort()
 
-    reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+    reverse_indexer = np.empty(len(sorter), dtype=np.int64)
     reverse_indexer.put(sorter, np.arange(len(sorter)))
 
     new_left = reverse_indexer.take(left)
@@ -538,7 +538,7 @@ class _BlockJoinOperation(object):
 
             if unit.indexer is None:
             # is this really faster than assigning to arr.flat?
-                com.take_fast(blk.values, np.arange(n, dtype='i4'),
+                com.take_fast(blk.values, np.arange(n, dtype=np.int64),
                               None, False,
                               axis=self.axis, out=out_chunk)
             else:
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 03011756b..4482e0529 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -62,8 +62,8 @@ class TestMerge(unittest.TestCase):
                            index=['d', 'b', 'c', 'a'])
 
     def test_cython_left_outer_join(self):
-        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype='i4')
-        right = a_([1, 1, 0, 4, 2, 2, 1], dtype='i4')
+        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype=np.int64)
+        right = a_([1, 1, 0, 4, 2, 2, 1], dtype=np.int64)
         max_group = 5
 
         ls, rs = lib.left_outer_join(left, right, max_group)
@@ -86,8 +86,8 @@ class TestMerge(unittest.TestCase):
         self.assert_(np.array_equal(rs, exp_rs))
 
     def test_cython_right_outer_join(self):
-        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype='i4')
-        right = a_([1, 1, 0, 4, 2, 2, 1], dtype='i4')
+        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype=np.int64)
+        right = a_([1, 1, 0, 4, 2, 2, 1], dtype=np.int64)
         max_group = 5
 
         rs, ls  = lib.left_outer_join(right, left, max_group)
@@ -112,8 +112,8 @@ class TestMerge(unittest.TestCase):
         self.assert_(np.array_equal(rs, exp_rs))
 
     def test_cython_inner_join(self):
-        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype='i4')
-        right = a_([1, 1, 0, 4, 2, 2, 1, 4], dtype='i4')
+        left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype=np.int64)
+        right = a_([1, 1, 0, 4, 2, 2, 1, 4], dtype=np.int64)
         max_group = 5
 
         ls, rs = lib.inner_join(left, right, max_group)
diff --git a/setup.py b/setup.py
index 3cec86053..75747e1d9 100755
--- a/setup.py
+++ b/setup.py
@@ -336,8 +336,7 @@ else:
 
 tseries_depends = ['reindex', 'groupby', 'skiplist', 'moments',
                    'generated', 'reduce', 'stats', 'datetime',
-                   'inference', 'properties', 'internals',
-                   'join', 'engines']
+                   'hashtable', 'inference', 'properties', 'join', 'engines']
 
 def srcpath(name=None, suffix='.pyx', subdir='src'):
     return pjoin('pandas', subdir, name+suffix)
