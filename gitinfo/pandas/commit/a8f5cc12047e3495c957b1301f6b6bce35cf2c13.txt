commit a8f5cc12047e3495c957b1301f6b6bce35cf2c13
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Nov 21 17:27:42 2009 +0000

    added OLS and PanelOLS functionality
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@38 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/stats/api.py b/pandas/stats/api.py
new file mode 100644
index 000000000..eea990d25
--- /dev/null
+++ b/pandas/stats/api.py
@@ -0,0 +1,7 @@
+"""
+Common namespace of statistical functions
+"""
+
+from pandas.stats.common import ROLLING, EXPANDING, TIME, ENTITY
+from pandas.stats.interface import ols
+from pandas.stats.fama_macbeth import fama_macbeth
diff --git a/pandas/stats/common.py b/pandas/stats/common.py
new file mode 100644
index 000000000..bfab8429a
--- /dev/null
+++ b/pandas/stats/common.py
@@ -0,0 +1,56 @@
+FULL_SAMPLE = 0
+ROLLING = 1
+EXPANDING = 2
+
+TIME = 0
+ENTITY = 1
+
+def _get_cluster_type(cluster_type):
+    if cluster_type in (TIME, ENTITY):
+        return cluster_type
+    elif isinstance(cluster_type, basestring):
+        cluster_type_up = cluster_type.upper()
+
+        if cluster_type_up == 'ENTITY':
+            return ENTITY
+        elif cluster_type_up == 'TIME':
+            return TIME
+
+    raise Exception('Unrecognized clustering type: %s' % cluster_type)
+
+def _get_window_type(window_type):
+    if window_type in (FULL_SAMPLE, ROLLING, EXPANDING):
+        return window_type
+    elif isinstance(window_type, basestring):
+        window_type_up = window_type.upper()
+
+        if window_type_up in ('FULL SAMPLE', 'FULL_SAMPLE'):
+            return FULL_SAMPLE
+        elif window_type_up == 'ROLLING':
+            return ROLLING
+        elif window_type_up == 'EXPANDING':
+            return EXPANDING
+
+    raise Exception('Unrecognized window type: %s' % window_type)
+
+def banner(text, width=80):
+    """
+
+    """
+    toFill = width - len(text)
+
+    left = toFill // 2
+    right = toFill - left
+
+    return '%s%s%s' % ('-' * left, text, '-' * right)
+
+def f_stat_to_dict(result):
+    f_stat, shape, p_value = result
+
+    result = {}
+    result['f-stat'] = f_stat
+    result['DF X'] = shape[0]
+    result['DF Resid'] = shape[1]
+    result['p-value'] = p_value
+
+    return result
diff --git a/pandas/stats/fama_macbeth.py b/pandas/stats/fama_macbeth.py
new file mode 100644
index 000000000..d78c8dfd9
--- /dev/null
+++ b/pandas/stats/fama_macbeth.py
@@ -0,0 +1,215 @@
+from cStringIO import StringIO
+
+import numpy as np
+
+from pandas.core.api import Series, DataMatrix
+from pandas.stats.common import banner, FULL_SAMPLE, ROLLING, EXPANDING
+from pandas.util.decorators import cache_readonly
+
+def fama_macbeth(**kwargs):
+    """Runs Fama-MacBeth regression.
+
+    Parameters
+    ----------
+    Takes the same arguments as a panel OLS, in addition to:
+
+    nw_lags_beta: int
+       Newey-West adjusts the betas by the given lags
+    """
+    window_type = kwargs.get('window_type')
+    if window_type is None:
+        klass = FamaMacBeth
+    else:
+        klass = MovingFamaMacBeth
+
+    return klass(**kwargs)
+
+class FamaMacBeth(object):
+    def __init__(self, y, x, weights=None, intercept=True, nw_lags=None,
+                 nw_lags_beta=None,
+                 entity_effects=False, time_effects=False, x_effects=None,
+                 cluster=None, dropped_dummies={}, verbose=False):
+        self._nw_lags_beta = nw_lags_beta
+
+        from pandas.stats.plm import MovingPanelOLS
+        self._ols_result = MovingPanelOLS(
+            y=y, x=x, weights=weights, window_type=ROLLING, window=1,
+            intercept=intercept,
+            nw_lags=nw_lags, entity_effects=entity_effects,
+            time_effects=time_effects, x_effects=x_effects, cluster=cluster,
+            dropped_dummies=dropped_dummies, verbose=verbose)
+
+        self._cols = self._ols_result._x.items
+
+    @cache_readonly
+    def _beta_raw(self):
+        return self._ols_result._beta_raw
+
+    @cache_readonly
+    def _stats(self):
+        return _calc_t_stat(self._beta_raw, self._nw_lags_beta)
+
+    @cache_readonly
+    def _mean_beta_raw(self):
+        return self._stats[0]
+
+    @cache_readonly
+    def _std_beta_raw(self):
+        return self._stats[1]
+
+    @cache_readonly
+    def _t_stat_raw(self):
+        return self._stats[2]
+
+    def _make_result(self, result):
+        return Series(result, index=self._cols)
+
+    @cache_readonly
+    def mean_beta(self):
+        return self._make_result(self._mean_beta_raw)
+
+    @cache_readonly
+    def std_beta(self):
+        return self._make_result(self._std_beta_raw)
+
+    @cache_readonly
+    def t_stat(self):
+        return self._make_result(self._t_stat_raw)
+
+    @cache_readonly
+    def _result_index(self):
+        return self._index[-len(self._stats[0]):]
+
+    @cache_readonly
+    def _results(self):
+        return {
+            'mean_beta' : self._mean_beta_raw,
+            'std_beta' : self._std_beta_raw,
+            't_stat' : self._t_stat_raw,
+        }
+
+    @cache_readonly
+    def _coef_table(self):
+        buffer = StringIO()
+        buffer.write('%13s %13s %13s %13s %13s %13s\n' %
+            ('Variable','Beta', 'Std Err','t-stat','CI 2.5%','CI 97.5%'))
+        template = '%13s %13.4f %13.4f %13.2f %13.4f %13.4f\n'
+
+        for i, name in enumerate(self._cols):
+            if i and not (i % 5):
+                buffer.write('\n' + banner(''))
+
+            mean_beta = self._results['mean_beta'][i]
+            std_beta = self._results['std_beta'][i]
+            t_stat = self._results['std_beta'][i]
+            ci1 = mean_beta - 1.96 * std_beta
+            ci2 = mean_beta + 1.96 * std_beta
+
+            values = '(%s)' % name, mean_beta, std_beta, t_stat, ci1, ci2
+
+            buffer.write(template % values)
+
+        if self._nw_lags_beta is not None:
+            buffer.write('\n')
+            buffer.write('*** The Std Err, t-stat are Newey-West '
+                         'adjusted with Lags %5d\n' % self._nw_lags_beta)
+
+        return buffer.getvalue()
+
+    def __repr__(self):
+        return self.summary
+
+    @cache_readonly
+    def summary(self):
+        template = """
+----------------------Summary of Fama-MacBeth Analysis-------------------------
+
+Formula: Y ~ %(formulaRHS)s
+# betas : %(nu)3d
+
+----------------------Summary of Estimated Coefficients------------------------
+%(coefTable)s
+--------------------------------End of Summary---------------------------------
+"""
+        params = {
+            'formulaRHS' : ' + '.join(self._cols),
+            'nu' : len(self._beta_raw),
+            'coefTable' : self._coef_table,
+        }
+
+        return template % params
+
+class MovingFamaMacBeth(FamaMacBeth):
+    def __init__(self, y, x, weights=None, window_type=ROLLING, window=10,
+                 intercept=True, nw_lags=None, nw_lags_beta=None,
+                 entity_effects=False, time_effects=False, x_effects=None,
+                 cluster=None, dropped_dummies={}, verbose=False):
+        self._window_type = window_type
+        self._window = window
+
+        FamaMacBeth.__init__(
+            self, y=y, x=x, weights=weights, intercept=intercept, nw_lags=nw_lags,
+            nw_lags_beta=nw_lags_beta, entity_effects=entity_effects,
+            time_effects=time_effects, x_effects=x_effects, cluster=cluster,
+            dropped_dummies=dropped_dummies, verbose=verbose)
+
+        self._index = self._ols_result._y.major_axis
+        self._T = len(self._index)
+
+    @cache_readonly
+    def _stats(self):
+        mean_betas = []
+        std_betas = []
+        t_stats = []
+
+        start = self._window - 1
+
+        for i in xrange(start, self._T):
+            if self._window_type == ROLLING:
+                begin = i - start
+            else:
+                begin = 0
+
+            beta = self._beta_raw[begin : i + 1]
+            result = _calc_t_stat(beta, self._nw_lags_beta)
+
+            mean_beta, std_beta, t_stat = result
+
+            mean_betas.append(mean_beta)
+            std_betas.append(std_beta)
+            t_stats.append(t_stat)
+
+        return np.array([mean_betas, std_betas, t_stats])
+
+    def _make_result(self, result):
+        return DataMatrix(result, index=self._result_index, columns=self._cols)
+
+    @cache_readonly
+    def _result_index(self):
+        return self._index[-len(self._stats[0]):]
+
+    @cache_readonly
+    def _results(self):
+        return {
+            'mean_beta' : self._mean_beta_raw[-1],
+            'std_beta' : self._std_beta_raw[-1],
+            't_stat' : self._t_stat_raw[-1],
+        }
+
+def _calc_t_stat(beta, nw_lags_beta):
+    N = len(beta)
+    B = beta - beta.mean(0)
+    C = np.dot(B.T, B) / N
+
+    if nw_lags_beta is not None:
+        for i in xrange(nw_lags_beta + 1):
+
+            cov = np.dot(B[i:].T, B[:(N - i)]) / N
+            weight = i / (nw_lags_beta + 1)
+            C += 2 * (1 - weight) * cov
+
+    mean_beta = beta.mean(0)
+    std_beta = np.sqrt(np.diag(C)) / np.sqrt(N)
+    t_stat = mean_beta / std_beta
+
+    return mean_beta, std_beta, t_stat
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
new file mode 100644
index 000000000..07c89e3c3
--- /dev/null
+++ b/pandas/stats/interface.py
@@ -0,0 +1,105 @@
+from pandas.core.api import Series
+
+from pandas.stats.ols import OLS, MovingOLS
+from pandas.stats.plm import PanelOLS, MovingPanelOLS, NonPooledPanelOLS
+import pandas.stats.common as common
+
+def ols(**kwargs):
+    """Returns the appropriate OLS object depending on whether you need
+    simple or panel OLS, and a full-sample or rolling/expanding OLS.
+
+    Parameters
+    ----------
+    y: Series for simple OLS.  DataFrame for panel OLS.
+    x: Series, DataFrame, or dict of Series for simple OLS.
+       Dict of DataFrame for panel OLS.
+    intercept: bool
+        True if you want an intercept.  Defaults to True.
+    nw_lags: None or int
+        Number of Newey-West lags.  Defaults to None.
+    nw_overlap: bool
+        Whether there are overlaps in the NW lags.  Defaults to False.
+    window_type: int
+        FULL_SAMPLE, ROLLING, EXPANDING.  FULL_SAMPLE by default.
+    window: int
+        size of window (for rolling/expanding OLS)
+
+    Panel OLS options:
+        pool: bool
+            Whether to run pooled panel regression.  Defaults to true.
+        weights: DataFrame
+            Weight for each observation.  The weights are not normalized;
+            they're multiplied directly by each observation.
+        entity_effects: bool
+            Whether to account for entity fixed effects.  Defaults to false.
+        time_effects: bool
+            Whether to account for time fixed effects.  Defaults to false.
+        x_effects: list
+            List of x's to account for fixed effects.  Defaults to none.
+        dropped_dummies: dict
+            Key is the name of the variable for the fixed effect.
+            Value is the value of that variable for which we drop the dummy.
+
+            For entity fixed effects, key equals 'entity'.
+
+            By default, the first dummy is dropped if no dummy is specified.
+        cluster: int
+            ENTITY or TIME, indicating entity/time clustering
+
+    Returns
+    -------
+    The appropriate OLS object, which allows you to obtain betas and various
+    statistics, such as std err, t-stat, etc.
+
+    Example
+    --------
+    # Run simple OLS.
+    result = ols(y=y, x=x)
+
+    # Run rolling simple OLS with window of size 10.
+    result = ols(y=y, x=x, window_type=ROLLING, window=10)
+    print result.beta
+
+    result = ols(y=y, x=x, nw_lags=1)
+
+    # Set up LHS and RHS for data across all items
+    y = A
+    x = {'B' : B, 'C' : C}
+
+    # Run panel OLS.
+    result = ols(y=y, x=x)
+
+    # Run expanding panel OLS with window 10 and entity clustering.
+    result = ols(y=y, x=x, cluster=ENTITY, window_type=EXPANDING, window=10)
+    """
+    pool = kwargs.get('pool')
+    if 'pool' in kwargs:
+        del kwargs['pool']
+
+    window_type = kwargs.get('window_type', common.FULL_SAMPLE)
+    window_type = common._get_window_type(window_type)
+
+    y = kwargs.get('y')
+    if window_type == common.FULL_SAMPLE:
+        if 'window_type' in kwargs:
+            del kwargs['window_type']
+        if 'window' in kwargs:
+            del kwargs['window']
+
+        if isinstance(y, Series):
+            klass = OLS
+        else:
+            if pool == False:
+                klass = NonPooledPanelOLS
+            else:
+                klass = PanelOLS
+    else:
+        if isinstance(y, Series):
+            klass = MovingOLS
+        else:
+            if pool == False:
+                klass = NonPooledPanelOLS
+            else:
+                klass = MovingPanelOLS
+
+    return klass(**kwargs)
diff --git a/pandas/stats/math.py b/pandas/stats/math.py
new file mode 100644
index 000000000..84a23d3c6
--- /dev/null
+++ b/pandas/stats/math.py
@@ -0,0 +1,313 @@
+# pylint: disable-msg=E1103
+# pylint: disable-msg=W0212
+
+from __future__ import division
+
+from scipy import stats
+import numpy as np
+import numpy.linalg as linalg
+
+from pandas.stats.common import FULL_SAMPLE, EXPANDING, ROLLING, TIME, ENTITY
+
+def rank(X, cond=1.0e-12):
+    """
+    Return the rank of a matrix X based on its generalized inverse,
+    not the SVD.
+    """
+    X = np.asarray(X)
+    if len(X.shape) == 2:
+        import scipy.linalg as SL
+        D = SL.svdvals(X)
+        result = np.add.reduce(np.greater(D / D.max(), cond))
+        return int(result.astype(np.int32))
+    else:
+        return int(not np.alltrue(np.equal(X, 0.)))
+
+def solve(a, b):
+    """Returns the solution of A X = B."""
+    try:
+        return linalg.solve(a, b)
+    except linalg.LinAlgError:
+        return np.dot(linalg.pinv(a), b)
+
+def inv(a):
+    """Returns the inverse of A."""
+    try:
+        return np.linalg.inv(a)
+    except linalg.LinAlgError:
+        return np.linalg.pinv(a)
+
+def rolling_ols(x, y, window_type, window):
+    """Returns rolling betas for rolling/expanding """
+    xx = []
+    xy = []
+
+    xx.append(np.dot(x[0 : 1, :].T, x[0 : 1, :]))
+    xy.append(np.dot(x[0 : 1, :].T, y[0 : 1]))
+
+    for i in xrange(1, len(y)):
+        next_x = x[i : i + 1]
+        xx.append(xx[i - 1] + np.dot(next_x.T, next_x))
+        xy.append(xy[i - 1] + np.dot(next_x.T, y[i : i + 1]))
+
+    # Now calculate the coefficients
+
+    xn, xk = x.shape
+
+    betas = np.empty(((xn - window + 1), xk), dtype=float)
+    start = window - 1
+    for i in xrange(start, xn):
+        temp_xx = xx[i]
+        temp_xy = xy[i]
+
+        if window_type == ROLLING and i >= window:
+            temp_xx = temp_xx - xx[i - window]
+            temp_xy = temp_xy - xy[i - window]
+
+        betas[i - start] = solve(temp_xx, temp_xy)
+
+    return betas
+
+def get_xx_xy(x, y, idx, time_index):
+    x_slice = x.getValueSlice(time_index[idx], time_index[idx])
+    y_slice = y.getValueSlice(time_index[idx], time_index[idx])
+
+    xx = np.zeros((x_slice.shape[1], x_slice.shape[1]))
+    xy = np.zeros((x_slice.shape[1], 1))
+    for i in xrange(len(x_slice)):
+        xs = x_slice[i : i + 1]
+        ys = y_slice[i : i + 1]
+        xx += np.dot(xs.T, xs)
+        xy += np.dot(xs.T, ys)
+
+    return xx, xy
+
+def calc_xx_with_time_effects(x, y):
+    """
+    Returns X'X - (X'T) (T'T)^-1 (T'X)
+    """
+    # X'X
+    xx = np.dot(x.values.T, x.values)
+    xt = x.sum().values
+
+    # X'X - (T'T)^-1 (T'X)
+    count = y.count()
+    selector = count > 0
+
+    xt = xt[selector]
+    count = count[selector]
+
+    return xx - np.dot(xt.T / count, xt)
+
+def is_psd(m):
+    eigvals = linalg.eigvals(m)
+
+    return np.isreal(eigvals).all() and (eigvals >= 0).all()
+
+def newey_west(m, nw_lags, nobs, df, nw_overlap=False):
+    """Returns the Newey West values."""
+    Xeps = np.dot(m.T, m)
+    for lag in xrange(1, nw_lags + 1):
+        auto_cov = np.dot(m[:-lag].T, m[lag:])
+        weight = lag / (nw_lags + 1)
+        if nw_overlap:
+            weight = 0
+        bb = auto_cov + auto_cov.T
+        dd = (1 - weight) * bb
+        Xeps += dd
+
+    Xeps *= nobs / (nobs - df)
+
+    if nw_overlap and not is_psd(Xeps):
+        new_nw_lags = int(np.ceil(nw_lags * 1.5))
+        print ('nw_overlap is True and newey_west generated a non positive '
+               'semidefinite matrix, so using newey_west with nw_lags of %d.'
+               % new_nw_lags)
+        return newey_west(m, new_nw_lags, nobs, df)
+
+    return Xeps
+
+def var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
+                   nw_lags, nobs, df, nw_overlap):
+
+    from pandas.core.panel import LongPanel, group_agg
+
+    xx_inv = inv(xx)
+
+    if cluster_axis is None:
+        if nw_lags is None:
+            return xx_inv * (rmse ** 2)
+        else:
+            resid = y.values.squeeze() - np.dot(x.values, beta)
+            m = (x.values.T * resid).T
+
+            xeps = newey_west(m, nw_lags, nobs, df, nw_overlap)
+
+            return np.dot(xx_inv, np.dot(xeps, xx_inv))
+    else:
+        Xb = np.dot(x.values, beta).reshape((len(x.values), 1))
+        resid = LongPanel(y.values - Xb, ['resid'], y.index)
+
+        if cluster_axis == 1:
+            x = x.swapaxes()
+            resid = resid.swapaxes()
+
+        m = group_agg(x.values * resid.values, x.index._bounds,
+                      lambda x: np.sum(x, axis=0))
+
+        if nw_lags is None:
+            nw_lags = 0
+
+        xox = 0
+        for i in range(len(x.major_axis)):
+            xox += newey_west(m[i : i + 1], nw_lags,
+                              nobs, df, nw_overlap)
+
+        return np.dot(xx_inv, np.dot(xox, xx_inv))
+
+
+def xx_time_effects(x, y):
+    """
+    Returns X'X - (X'T) (T'T)^-1 (T'X)
+    """
+    # X'X
+    xx = np.dot(x.values.T, x.values)
+    xt = x.sum().values
+
+    count = y.count()
+    selector = count > 0
+
+    # X'X - (T'T)^-1 (T'X)
+    xt = xt[selector]
+    count = count[selector]
+
+    return xx - np.dot(xt.T / count, xt)
+
+def calc_var_beta(x, y, nw_lags, rmse, beta, nobs, df, window_type=FULL_SAMPLE,
+                  window=None, nw_overlap=False):
+    """Returns the covariance of beta.
+
+    For a full-sample regression, this returns the covariance matrix of betas.
+    For rolling/expanding regressions, this returns the variances of betas.
+    """
+    if window_type == FULL_SAMPLE:
+        xx = np.dot(x.T, x)
+    else:
+        cum_xx = []
+        cum_xx.append(np.dot(x[0 : 1].T, x[0 : 1]))
+
+        for i in xrange(1, len(y)):
+            cum_xx.append(cum_xx[i - 1] + np.dot(x[i : i + 1].T,
+                      x[i : i + 1]))
+
+    if window_type == FULL_SAMPLE:
+        if nw_lags is None:
+            return inv(xx) * (rmse ** 2)
+        else:
+            resid = y - np.dot(x, beta)
+            m = (x.T * resid).T
+
+            xeps = newey_west(m, nw_lags, nobs, df, nw_overlap)
+
+            xx_inv = inv(xx)
+            return np.dot(xx_inv, np.dot(xeps, xx_inv))
+    else:
+        results = []
+        start = window - 1
+        for i in xrange(start, len(y)):
+            if nw_lags is None:
+                temp_xx = cum_xx[i]
+                if window_type == ROLLING and i >= window:
+                    temp_xx = temp_xx - cum_xx[i - window]
+                result = inv(temp_xx) * (rmse[i - start] ** 2)
+            else:
+                temp_xx = cum_xx[i]
+
+                if window_type == EXPANDING:
+                    begin = 0
+                else:
+                    begin = i - start
+                    if i >= window:
+                        temp_xx = temp_xx - cum_xx[i - window]
+
+                section = slice(begin, i + 1)
+
+                resid = y[section] - np.dot(x[section], beta[i - start])
+                m = (x[section].T * resid).T
+
+                window_nobs = i + 1 - begin
+                window_df = df[i - start]
+
+                xeps = newey_west(m, nw_lags, window_nobs,
+                                  window_df, nw_overlap)
+
+                xx_inv = inv(temp_xx)
+                result = np.dot(xx_inv, np.dot(xeps, xx_inv))
+
+            results.append(result)
+
+        return results
+
+def calc_F(R, r, beta, var_beta, nobs, df):
+    hyp = np.dot(R, beta.reshape(len(beta), 1)) - r
+    RSR = np.dot(R, np.dot(var_beta, R.T))
+
+    q = len(r)
+
+    F = np.dot(hyp.T, np.dot(inv(RSR), hyp)).squeeze() / q
+
+    p_value = 1 - stats.f.cdf(F, q, nobs - df)
+
+    return F, (q, nobs - df), p_value
+
+def calc_f_stat(nw_lags, r2, r2_adj, cols, beta, var_beta, nobs, df,
+                window=None, T=None):
+    if nw_lags is None:
+        F = r2 / (r2 - r2_adj)
+
+        q = len(cols)
+        if 'intercept' in cols:
+            q -= 1
+
+        if window is None:
+            shape = q, nobs - df
+            p_value = 1 - stats.f.cdf(F, shape[0], shape[1])
+            return F, shape, p_value
+
+        results = []
+
+        start = window - 1
+        for i in xrange(start, T):
+            shape = q, nobs[i - start] - df[i - start]
+            p_value = 1 - stats.f.cdf(F[i - start], shape[0], shape[1])
+            result = F[i - start], shape, p_value
+            results.append(result)
+
+        return results
+
+    k = len(cols)
+
+    R = np.eye(k)
+    r = np.zeros((k, 1))
+
+    intercept = cols.indexMap.get('intercept')
+
+    if intercept is not None:
+        R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
+        r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
+
+    if window is None:
+        return calc_F(R, r, beta, var_beta, nobs, df)
+
+    results = []
+
+    start = window - 1
+    for i in xrange(start, T):
+        b = beta[i - start]
+        vb = var_beta[i - start]
+        n = nobs[i - start]
+        d = df[i - start]
+        result = calc_F(R, r, b, vb, n, d)
+        results.append(result)
+
+    return results
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
new file mode 100644
index 000000000..36d0219c0
--- /dev/null
+++ b/pandas/stats/ols.py
@@ -0,0 +1,836 @@
+"""
+Simple OLS.
+"""
+from __future__ import division
+
+from StringIO import StringIO
+
+import numpy as np
+from scipy import stats
+
+from pandas.core.api import DataFrame, DataMatrix, Series
+from pandas.util.decorators import cache_readonly
+import pandas.stats.common as common
+import pandas.stats.math as math
+
+
+class OLS(object):
+    """Runs a simple OLS.
+
+    Parameters
+    ----------
+    y: Series
+    x: Series, DataFrame, or dict of Series
+    intercept: bool
+        True if you want an intercept.
+    nw_lags: None or int
+        Number of Newey-West lags.
+    """
+    def __init__(self, y, x, intercept=True, nw_lags=None, nw_overlap=False):
+        import scikits.statsmodels as sm
+
+        self._x_orig = x
+        self._y_orig = y
+        self._intercept = intercept
+        self._nw_lags = nw_lags
+        self._nw_overlap = nw_overlap
+
+        self._y, self._x, self._x_filtered = self._prepare_data()
+        self._x_raw = self._x.values
+        self._y_raw = self._y.view(np.ndarray)
+        self._nobs = len(self._y_raw)
+        self._index = self._y.index
+
+        self.sm_ols = sm.OLS(self._y_raw, self._x_raw).fit()
+
+    def _prepare_data(self):
+        """
+        Filters the data and sets up an intercept if necessary.
+
+        Returns
+        -------
+        (DataFrame, Series).
+        """
+
+        y, x, x_filtered = _filter_data(self._y_orig, self._x_orig)
+
+        if self._intercept:
+            x['intercept'] = x_filtered['intercept'] = 1.
+
+        return y, x, x_filtered
+
+    @property
+    def nobs(self):
+        return self._nobs
+
+    @property
+    def nw_lags(self):
+        return self._nw_lags
+
+    @property
+    def x(self):
+        """Returns the filtered x used in the regression."""
+        return self._x
+
+    @property
+    def y(self):
+        """Returns the filtered y used in the regression."""
+        return self._y
+
+    @cache_readonly
+    def _beta_raw(self):
+        """Runs the regression and returns the beta."""
+        return self.sm_ols.params
+
+    @cache_readonly
+    def beta(self):
+        """Returns the betas in Series form."""
+        return Series(self._beta_raw, index=self._x.cols())
+
+    @cache_readonly
+    def _df_raw(self):
+        """Returns the degrees of freedom."""
+        return math.rank(self._x_raw)
+
+    @cache_readonly
+    def df(self):
+        """Returns the degrees of freedom.
+
+        This equals the rank of the X matrix."""
+        return self._df_raw
+
+    @cache_readonly
+    def _df_model_raw(self):
+        """Returns the raw model degrees of freedom."""
+        return self.sm_ols.df_model
+
+    @cache_readonly
+    def df_model(self):
+        """Returns the degrees of freedom of the model."""
+        return self._df_model_raw
+
+    @cache_readonly
+    def _df_resid_raw(self):
+        """Returns the raw residual degrees of freedom."""
+        return self.sm_ols.df_resid
+
+    @cache_readonly
+    def df_resid(self):
+        """Returns the degrees of freedom of the residuals."""
+        return self._df_resid_raw
+
+    @cache_readonly
+    def _f_stat_raw(self):
+        """Returns the raw f-stat value."""
+        return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
+                                self._x.columns, self._beta_raw,
+                                self._var_beta_raw,self._nobs, self.df)
+    @cache_readonly
+    def f_stat(self):
+        """Returns the f-stat value."""
+        return common.f_stat_to_dict(self._f_stat_raw)
+
+    def f_test(self, hypothesis):
+        """Runs the F test, given a joint hypothesis.  The hypothesis is
+        represented by a collection of equations, in the form
+
+        A*x_1+B*x_2=C
+
+        You must provide the coefficients even if they're 1.  No spaces.
+
+        The equations can be passed as either a single string or a
+        list of strings.
+
+        Examples:
+        o = ols(...)
+        o.f_test('1*x1+2*x2=0,1*x3=0')
+        o.f_test(['1*x1+2*x2=0','1*x3=0'])
+        """
+
+        x_names = self._x.columns
+
+        R = []
+        r = []
+
+        if isinstance(hypothesis, str):
+            eqs = hypothesis.split(',')
+        elif isinstance(hypothesis, list):
+            eqs = hypothesis
+        else:
+            raise Exception('hypothesis must be either string or list')
+        for equation in eqs:
+            row = np.zeros(len(x_names))
+            lhs, rhs = equation.split('=')
+            for s in lhs.split('+'):
+                ss = s.split('*')
+                coeff = float(ss[0])
+                x_name = ss[1]
+                idx = x_names.indexMap[x_name]
+                row[idx] = coeff
+            rhs = float(rhs)
+
+            R.append(row)
+            r.append(rhs)
+
+        R = np.array(R)
+        q = len(r)
+        r = np.array(r).reshape(q, 1)
+
+        result = math.calc_F(R, r, self._beta_raw, self._var_beta_raw,
+                             self.nobs, self.df)
+
+        return common.f_stat_to_dict(result)
+
+    @cache_readonly
+    def _p_value_raw(self):
+        """Returns the raw p values."""
+        t_stat = self._t_stat_raw
+        p_value = 2 * (1 - stats.t.cdf(np.fabs(t_stat),
+            (self._nobs - self._df_raw)))
+        return np.array(p_value)
+
+    @cache_readonly
+    def p_value(self):
+        """Returns the p values."""
+        index = self.beta.index
+        return Series(self._p_value_raw, index=index)
+
+    @cache_readonly
+    def _r2_raw(self):
+        """Returns the raw r-squared values."""
+        return self.sm_ols.rsquared
+
+    @cache_readonly
+    def r2(self):
+        """Returns the r-squared values."""
+        return self._r2_raw
+
+    @cache_readonly
+    def _r2_adj_raw(self):
+        """Returns the raw r-squared adjusted values."""
+        return self.sm_ols.rsquared_adj
+
+    @cache_readonly
+    def r2_adj(self):
+        """Returns the r-squared adjusted values."""
+        return self._r2_adj_raw
+
+    @cache_readonly
+    def _resid_raw(self):
+        """Returns the raw residuals."""
+        return self.sm_ols.resid
+
+    @cache_readonly
+    def resid(self):
+        """Returns the residuals."""
+        index = self._x.index
+
+        return Series(self._resid_raw, index=index)
+
+    @cache_readonly
+    def _rmse_raw(self):
+        """Returns the raw rmse values."""
+        return np.sqrt(self.sm_ols.mse_resid)
+
+    @cache_readonly
+    def rmse(self):
+        """Returns the rmse value."""
+        return self._rmse_raw
+
+    @cache_readonly
+    def _std_err_raw(self):
+        """Returns the raw standard err values."""
+        return np.nan_to_num(np.sqrt(np.diag(self._var_beta_raw)))
+
+    @cache_readonly
+    def std_err(self):
+        """Returns the standard err values of the betas."""
+        index = self.beta.index
+        return Series(self._std_err_raw, index=index)
+
+    @cache_readonly
+    def _t_stat_raw(self):
+        """Returns the raw t-stat value."""
+        return np.nan_to_num(self._beta_raw / self._std_err_raw)
+
+    @cache_readonly
+    def t_stat(self):
+        """Returns the t-stat values of the betas."""
+        return Series(self._t_stat_raw, index=self.beta.index)
+
+    @cache_readonly
+    def _var_beta_raw(self):
+        """Returns the raw covariance of beta."""
+        result = math.calc_var_beta(x=self._x_raw, y=self._y_raw,
+                                    nw_lags=self._nw_lags, rmse=self._rmse_raw,
+                                    beta=self._beta_raw, nobs=self.nobs,
+                                    df=self._df_raw, nw_overlap=self._nw_overlap)
+        return np.array(result)
+
+    @cache_readonly
+    def var_beta(self):
+        """Returns the variance-covariance matrix of beta."""
+        return DataMatrix(self._var_beta_raw, index=self.beta.index,
+                          columns=self.beta.index)
+
+    @cache_readonly
+    def _y_fitted_raw(self):
+        """Returns the raw fitted y values."""
+        return self.sm_ols.fittedvalues
+
+    @cache_readonly
+    def y_fitted(self):
+        """Returns the fitted y values.  This equals BX."""
+        index = self._x_filtered.index
+        return Series(self._y_fitted_raw, index=index)
+
+    @cache_readonly
+    def _y_predict_raw(self):
+        """Returns the raw predicted y values."""
+        return self._y_fitted_raw
+
+    @cache_readonly
+    def y_predict(self):
+        """Returns the predicted y values.
+
+        For in-sample, this is same as y_fitted."""
+        return self.y_fitted
+
+    RESULT_FIELDS = ['r2', 'r2_adj', 'df', 'df_model', 'df_resid', 'rmse',
+                     'f_stat', 'beta', 'std_err', 't_stat', 'p_value']
+
+    @cache_readonly
+    def _results(self):
+        results = {}
+        for result in self.RESULT_FIELDS:
+            results[result] = getattr(self, result)
+
+        return results
+
+    @cache_readonly
+    def _coef_table(self):
+        buf = StringIO()
+
+        buf.write('%14s %10s %10s %10s %10s %10s %10s\n' %
+                  ('Variable', 'Coef', 'Std Err', 't-stat',
+                   'p-value', 'CI 2.5%', 'CI 97.5%'))
+        buf.write(common.banner(''))
+        coef_template = '\n%14s %10.4f %10.4f %10.2f %10.4f %10.4f %10.4f'
+
+        results = self._results
+
+        beta = results['beta']
+
+        for i, name in enumerate(beta.index):
+            if i and not (i % 5):
+                buf.write('\n' + common.banner(''))
+
+            std_err = results['std_err'][name]
+            CI1 = beta[name] - 1.96 * std_err
+            CI2 = beta[name] + 1.96 * std_err
+
+            t_stat = results['t_stat'][name]
+            p_value = results['p_value'][name]
+
+            line = coef_template % (name,
+                beta[name], std_err, t_stat, p_value, CI1, CI2)
+
+            buf.write(line)
+
+        if self.nw_lags is not None:
+            buf.write('\n')
+            buf.write('*** The calculations are Newey-West '
+                      'adjusted with lags %5d\n' % self.nw_lags)
+
+        return buf.getvalue()
+
+    @cache_readonly
+    def summary_as_matrix(self):
+        """Returns the formatted results of the OLS as a DataMatrix."""
+        results = self._results
+        beta = results['beta']
+        data = {'beta' : results['beta'],
+                't-stat' : results['t_stat'],
+                'p-value' : results['p_value'],
+                'std err' : results['std_err']}
+        return DataFrame(data, beta.index).T
+
+    @cache_readonly
+    def summary(self):
+        """
+        This returns the formatted result of the OLS computation
+        """
+        template = """
+%(bannerTop)s
+
+Formula: Y ~ %(formula)s
+
+Number of Observations:         %(nobs)d
+Number of Degrees of Freedom:   %(df)d
+
+R-squared:     %(r2)10.4f
+Adj R-squared: %(r2_adj)10.4f
+
+Rmse:          %(rmse)10.4f
+
+F-stat %(f_stat_shape)s: %(f_stat)10.4f, p-value: %(f_stat_p_value)10.4f
+
+Degrees of Freedom: model %(df_model)d, resid %(df_resid)d
+
+%(bannerCoef)s
+%(coef_table)s
+%(bannerEnd)s
+"""
+        coef_table = self._coef_table
+
+        results = self._results
+
+        f_stat = results['f_stat']
+
+        bracketed = ['<%s>' % c for c in results['beta'].index]
+
+        formula = StringIO()
+        formula.write(bracketed[0])
+        tot = len(bracketed[0])
+        line = 1
+        for coef in bracketed[1:]:
+            tot = tot + len(coef) + 3
+
+            if tot // (68 * line):
+                formula.write('\n' + ' ' * 12)
+                line += 1
+
+            formula.write(' + ' + coef)
+
+        params = {
+            'bannerTop' : common.banner('Summary of Regression Analysis'),
+            'bannerCoef' : common.banner('Summary of Estimated Coefficients'),
+            'bannerEnd' : common.banner('End of Summary'),
+            'formula' : formula.getvalue(),
+            'r2' : results['r2'],
+            'r2_adj' : results['r2_adj'],
+            'nobs' : self.nobs,
+            'df'  : results['df'],
+            'df_model'  : results['df_model'],
+            'df_resid'  : results['df_resid'],
+            'coef_table' : coef_table,
+            'rmse' : results['rmse'],
+            'f_stat' : f_stat['f-stat'],
+            'f_stat_shape' : '(%d, %d)' % (f_stat['DF X'], f_stat['DF Resid']),
+            'f_stat_p_value' : f_stat['p-value'],
+        }
+
+        return template % params
+
+    def __repr__(self):
+        return self.summary
+
+
+class MovingOLS(OLS):
+    """
+    Runs a rolling/expanding simple OLS.
+
+    Parameters
+    ----------
+    y: Series
+    x: Series, DataFrame, or dict of Series
+    intercept: bool
+        True if you want an intercept.
+    nw_lags: None or int
+        Number of Newey-West lags.
+    window_type: int
+        FULL_SAMPLE, ROLLING, EXPANDING.  FULL_SAMPLE by default.
+    window: int
+        size of window (for rolling/expanding OLS)
+    """
+    def __init__(self, y, x, window_type=common.ROLLING, window=10,
+                 intercept=True, nw_lags=None, nw_overlap=False):
+
+        self._args = dict(intercept=intercept, nw_lags=nw_lags,
+                          nw_overlap=nw_overlap)
+
+        OLS.__init__(self, y=y, x=x, **self._args)
+
+        self._window_type = common._get_window_type(window_type)
+        self._window = window
+
+    @cache_readonly
+    def _beta_raw(self):
+        """Runs the regression and returns the beta."""
+        Y  = self._y_raw
+        X  = self._x_raw
+
+        return math.rolling_ols(X, Y, self._window_type, self._window)
+
+    @cache_readonly
+    def beta(self):
+        """Returns the betas in Series/DataMatrix form."""
+        return DataMatrix(
+            self._beta_raw, index=self._index[-len(self._beta_raw):],
+            columns=self._x.cols())
+
+    @cache_readonly
+    def _df_raw(self):
+        """Returns the degrees of freedom."""
+        df = []
+        start = self._window - 1
+        for i in xrange(start, len(self._x_raw)):
+            if self._window_type == common.ROLLING:
+                begin = i - start
+            else:
+                begin = 0
+
+            df.append(math.rank(self._x_raw[begin : i + 1]))
+
+        return np.array(df)
+
+    @cache_readonly
+    def df(self):
+        """Returns the degrees of freedom."""
+        index = self.beta.index
+        return Series(self._df_raw, index=index)
+
+
+    @cache_readonly
+    def _df_model_raw(self):
+        """Returns the raw model degrees of freedom."""
+        return self._df_raw - 1
+
+    @cache_readonly
+    def df_model(self):
+        """Returns the model degrees of freedom."""
+        index = self.beta.index
+
+        return Series(self._df_model_raw, index=index)
+
+    @cache_readonly
+    def _df_resid_raw(self):
+        """Returns the raw residual degrees of freedom."""
+        df = []
+
+        start = self._window - 1
+        for i in xrange(start, self._nobs):
+            if self._window_type == common.ROLLING:
+                nobs = self._window
+            else:
+                nobs = i + 1
+
+            df.append(nobs - self._df_raw[i - start])
+
+        return np.array(df)
+
+    @cache_readonly
+    def df_resid(self):
+        """Returns the residual degrees of freedom."""
+        index = self.beta.index
+
+        return Series(self._df_resid_raw, index=index)
+
+    @cache_readonly
+    def _f_stat_raw(self):
+        """Returns the raw f-stat value."""
+        return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
+                                self._x.columns, self._beta_raw,
+                                self._var_beta_raw, self._window_nobs, self.df,
+                                self._window, self._nobs)
+
+    @cache_readonly
+    def f_stat(self):
+        """Returns the f-stat value."""
+        f_stat_dicts = dict((date, common.f_stat_to_dict(f_stat))
+                            for date, f_stat in zip(self.beta.index,
+                                                    self._f_stat_raw))
+
+        return DataFrame.fromDict(f_stat_dicts).T
+
+    def f_test(self, hypothesis):
+        raise Exception('f_test not supported for rolling/expanding OLS')
+
+    @cache_readonly
+    def _p_value_raw(self):
+        """Returns the raw p values."""
+        p_value = []
+        start = self._window - 1
+        for i in xrange(start, self._nobs):
+            if self._window_type == common.EXPANDING:
+                nobs = i + 1
+            else:
+                nobs = self._window
+            fabs = np.fabs(self._t_stat_raw[i - start])
+            result = 2 * (1 - stats.t.cdf(fabs,
+                nobs - self._df_raw[i - start]))
+            p_value.append(result)
+
+        return np.array(p_value)
+
+    @cache_readonly
+    def p_value(self):
+        """Returns the p values."""
+        cols = self.beta.cols()
+        rows = self.beta.index
+        return DataMatrix(self._p_value_raw, columns=cols, index=rows)
+
+    @cache_readonly
+    def _r2_raw(self):
+        """Returns the raw r-squared values."""
+        window = self._window
+        _r2 = []
+
+        X = self._x_raw
+        Y = self._y_raw
+
+        for i in xrange(window - 1, self._nobs):
+            if self._window_type == common.EXPANDING:
+                section = slice(None, i + 1)
+            else:
+                section = slice(i - window + 1, i + 1)
+            SSerr = ((Y[section] - np.dot(X[section],
+                      self._beta_raw[i - window + 1])) ** 2).sum()
+            SStotal = ((Y[section] - np.mean(Y[section])) ** 2).sum()
+            _r2.append(1 - SSerr / SStotal)
+
+        return np.array(_r2)
+
+    @cache_readonly
+    def r2(self):
+        """Returns the r-squared values."""
+        index = self.beta.index
+
+        return Series(self._r2_raw, index=index)
+
+    @cache_readonly
+    def _resid_raw(self):
+        """Returns the raw residuals."""
+        start = self._window - 1
+        return self._y_raw[start:] - self._y_fitted_raw
+
+    @cache_readonly
+    def resid(self):
+        """Returns the residuals."""
+        index = self.beta.index
+        return Series(self._resid_raw, index=index)
+
+    @cache_readonly
+    def _r2_adj_raw(self):
+        """Returns the raw r-squared adjusted values."""
+        Pa = []
+        start = self._window - 1
+        for i in xrange(start, self._nobs):
+            if self._window_type == common.EXPANDING:
+                nobs = i + 1
+            else:
+                nobs = self._window
+
+            Pa.append((nobs - 1) / (nobs - self._df_raw[i - start]))
+
+        _r2_adj_raw = 1 - (1 - self._r2_raw) * (Pa)
+
+        return np.array(_r2_adj_raw)
+
+    @cache_readonly
+    def r2_adj(self):
+        """Returns the r-squared adjusted values."""
+        index = self.r2.index
+
+        return Series(self._r2_adj_raw, index=index)
+
+
+    @cache_readonly
+    def _rmse_raw(self):
+        """Returns the raw rmse values."""
+        window = self._window
+        X = self._x_raw
+        Y = self._y_raw
+
+        results = []
+        start = window - 1
+        for i in xrange(start, self._nobs):
+            if self._window_type == common.EXPANDING:
+                section = slice(0, i + 1)
+            else:
+                section = slice(i - start, i + 1)
+            estimate = np.dot(X[section], self._beta_raw[i - start])
+            s = ((Y[section] - estimate) ** 2).sum()
+            df = self._df_raw[i - start]
+            nobs = len(Y[section])
+            result = np.sqrt(s / (nobs - df))
+            results.append(result)
+
+        return np.array(results)
+
+    @cache_readonly
+    def rmse(self):
+        """Returns the rmse values."""
+        index = self.beta.index
+
+        return Series(self._rmse_raw, index=index)
+
+    @cache_readonly
+    def _std_err_raw(self):
+        """Returns the raw standard err values."""
+        results = []
+        for i in xrange(len(self._var_beta_raw)):
+            results.append(np.sqrt(np.diag(self._var_beta_raw[i])))
+
+        return np.nan_to_num(np.array(results))
+
+    @cache_readonly
+    def std_err(self):
+        """Returns the standard err values."""
+        index = self.beta.index
+        cols = self.beta.cols()
+        return DataMatrix(self._std_err_raw, columns=cols, index=index)
+
+    @cache_readonly
+    def _t_stat_raw(self):
+        """Returns the raw t-stat value."""
+        results = []
+        start = self._window - 1
+        for i in xrange(start, self._nobs):
+            results.append(np.nan_to_num(self._beta_raw[i - start] /
+                self._std_err_raw[i - start]))
+
+        return np.array(results)
+
+    @cache_readonly
+    def t_stat(self):
+        """Returns the t-stat value."""
+        cols = self.beta.cols()
+        rows = self.beta.index
+        return DataMatrix(self._t_stat_raw, columns=cols, index=rows)
+
+    @cache_readonly
+    def _var_beta_raw(self):
+        """Returns the raw covariance of beta."""
+        result = math.calc_var_beta(x=self._x_raw, y=self._y_raw,
+                                    window_type=self._window_type,
+                                    window=self._window, nw_lags=self._nw_lags,
+                                    rmse=self._rmse_raw, beta=self._beta_raw,
+                                    nobs=self.nobs, df=self._df_raw,
+                                    nw_overlap=self._nw_overlap)
+        return np.array(result)
+
+    @cache_readonly
+    def var_beta(self):
+        """Returns the covariance of beta."""
+        result = []
+        for i in xrange(len(self._var_beta_raw)):
+            result.append(DataMatrix(
+                self._var_beta_raw[i], columns=self.beta.cols(),
+                index=self.beta.cols()))
+
+        return Series(result, index=self.beta.index)
+
+    @cache_readonly
+    def _y_fitted_raw(self):
+        """Returns the raw fitted y values."""
+        start = self._window - 1
+        return (self._x_raw[start:] * self._beta_raw).sum(1)
+
+    @cache_readonly
+    def y_fitted(self):
+        """Returns the fitted y values."""
+        index = self.beta.index
+        return Series(self._y_fitted_raw, index=index)
+
+    @cache_readonly
+    def _y_predict_raw(self):
+        """Returns the raw predicted y values."""
+        bx = self._beta_raw[: -1] * self._x_raw[self._window :]
+        return bx.sum(1)
+
+    @cache_readonly
+    def y_predict(self):
+        """Returns the predicted y values."""
+        index = self.beta.index[1 :]
+        return Series(self._y_predict_raw, index=index)
+
+    @cache_readonly
+    def _results(self):
+        results = {}
+        for result in self.RESULT_FIELDS:
+            value = getattr(self, result)
+            if isinstance(value, Series):
+                value = value[self.beta.index[-1]]
+            elif isinstance(value, DataFrame):
+                value = value.getXS(self.beta.index[-1])
+            else:
+                raise Exception('Problem retrieving %s' % result)
+            results[result] = value
+
+        return results
+
+    @cache_readonly
+    def _window_nobs(self):
+        results = []
+        start = self._window - 1
+        for i in xrange(start, self._nobs):
+            if self._window_type == common.EXPANDING:
+                result = i + 1
+            else:
+                result = self._window
+
+            results.append(result)
+
+        return results
+
+def _filter_rhs(rhs):
+    merged_df = None
+
+    if isinstance(rhs, Series):
+        merged_df = DataFrame({'x' : rhs})
+    elif isinstance(rhs, DataFrame):
+        merged_df = rhs
+    else:
+        for name, value in rhs.iteritems():
+            if isinstance(value, Series):
+                df = DataFrame({name : value})
+            elif isinstance(value, DataFrame):
+                df = value
+            elif isinstance(value, dict):
+                df = DataFrame(dict)
+            else:
+                raise Exception('Invalid RHS data type: %s' % str(type(value)))
+
+            if merged_df is None:
+                merged_df = df
+            else:
+                merged_df = merged_df.leftJoin(df)
+
+    merged_df = merged_df.dropIncompleteRows()
+
+    return merged_df
+
+def _filter_data(lhs, rhs):
+    """
+    Cleans the input for single OLS.
+
+    Parameters
+    ----------
+    lhs: Series
+        Dependent variable in the regression.
+
+    rhs: dict, whose values are Series, DataFrame, or dict
+        Explanatory variables of the regression.
+
+    Returns
+    -------
+    Series, DataFrame
+        Cleaned lhs and rhs
+    """
+    if not isinstance(lhs, Series):
+        raise Exception('lhs must be a Series')
+
+    pre_filtered_rhs = _filter_rhs(rhs)
+
+    frame = pre_filtered_rhs.copy().reindex(lhs.index)
+
+    frame['_y'] = lhs
+    frame = frame.dropIncompleteRows()
+
+    filtered_lhs = frame['_y']
+    del frame['_y']
+
+    filtered_rhs = frame
+
+    return filtered_lhs, filtered_rhs, pre_filtered_rhs
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
new file mode 100644
index 000000000..fdf8d5d4c
--- /dev/null
+++ b/pandas/stats/plm.py
@@ -0,0 +1,1071 @@
+"""
+Linear regression objects for panel data
+"""
+
+# pylint: disable-msg=W0231
+# pylint: disable-msg=E1103
+
+from __future__ import division
+from itertools import izip, starmap
+
+import numpy as np
+from scipy import stats
+
+from pandas.core.panel import WidePanel, LongPanel
+from pandas.core.matrix import DataMatrix
+from pandas.core.series import Series
+from pandas.stats.ols import OLS, MovingOLS
+from pandas.util.decorators import cache_readonly
+
+import pandas.stats.common as common
+import pandas.stats.math as math
+import pandas.stats.moments as moments
+
+class PanelOLS(OLS):
+    """Implements panel OLS.
+
+    Parameters
+    ----------
+    y: DataFrame
+    x: Dict of DataFrame or WidePanel
+    intercept: bool
+        True if you want an intercept.  True by default.
+    nw_lags: None or int
+        Number of Newey-West lags.  None by default.
+    nw_overlap: bool
+        Whether there are overlaps in the NW lags.  Defaults to False.
+    window_type: int
+        FULL_SAMPLE, ROLLING, EXPANDING.  FULL_SAMPLE by default.
+    window: int
+        size of window (for rolling/expanding OLS)
+    weights: DataFrame
+        Weight for each observation.  The weights are not normalized;
+        they're multiplied directly by each observation.
+    pool: bool, default True
+        Whether to run pooled panel regression
+    entity_effects: bool, deafult False
+        Whether to account for entity fixed effects
+    time_effects: bool, default False
+        Whether to account for time fixed effects
+    x_effects: list, default None
+        List of x's to account for fixed effects
+    dropped_dummies: dict
+        Key is the name of the variable for the fixed effect.
+        Value is the value of that variable for which we drop the dummy.
+
+        For entity fixed effects, key equals 'entity', e.g. {'entity' : 'US'}
+
+        By default, the first item is dropped if one is not specified.
+    cluster: int
+        ENTITY or TIME, indicating entity/time clustering
+    """
+    def __init__(self, y, x, weights=None,
+                 intercept=True, nw_lags=None, entity_effects=False,
+                 time_effects=False, x_effects=None, cluster=None,
+                 dropped_dummies=None, verbose=False, nw_overlap=False):
+        self._x_orig = x
+        self._y_orig = y
+        self._weights = weights
+        self._intercept = intercept
+        self._nw_lags = nw_lags
+        self._nw_overlap = nw_overlap
+        self._entity_effects = entity_effects
+        self._time_effects = time_effects
+        self._x_effects = x_effects
+        self._dropped_dummies = dropped_dummies or {}
+        self._cluster = cluster
+        self._verbose = verbose
+
+        (self._x, self._x_trans,
+         self._x_filtered, self._y,
+         self._y_trans) = self._prepare_data()
+
+        self._x_raw = self._x.values
+        self._x_trans_raw = self._x_trans.values
+        self._y_trans_raw = self._y_trans.values.squeeze()
+
+        self._index = self._y.major_axis
+        self._T = len(self._index)
+
+        self._nobs = len(self._y_trans_raw)
+
+    def log(self, msg):
+        if self._verbose:
+            print msg
+
+    def _prepare_data(self):
+        """Cleans and converts input data into LongPanel classes.
+
+        If time effects is True, then we turn off intercepts and omit an item
+        from every (entity and x) fixed effect.
+
+        Otherwise:
+           - If we have an intercept, we omit an item from every fixed effect.
+           - Else, we omit an item from every fixed effect except one of them.
+
+        The categorical variables will get dropped from x.
+        """
+        (x, x_filtered, y, weights,
+         weights_filt, cat_mapping) = self._filter_data()
+
+        self.log('Adding dummies to X variables')
+        x = self._add_dummies(x, cat_mapping)
+
+        self.log('Adding dummies to filtered X variables')
+        x_filtered = self._add_dummies(x_filtered, cat_mapping)
+
+        if self._x_effects:
+            x = x.filterItems(x.items - self._x_effects)
+            x_filtered = x_filtered.filterItems(x_filtered.items
+                                                - self._x_effects)
+
+        if self._time_effects:
+            x_regressor = x.subtract(x.mean(broadcast=True))
+            y_regressor = y.subtract(y.mean(broadcast=True))
+
+        elif self._intercept:
+            # only add intercept when no time effects
+            self.log('Adding intercept')
+            x = x_regressor = add_intercept(x)
+            x_filtered = add_intercept(x_filtered)
+            y_regressor = y
+        else:
+            self.log('No intercept added')
+
+            x_regressor = x
+            y_regressor = y
+
+        if weights is not None:
+            x = x.multiply(weights)
+            x_regressor = x_regressor.multiply(weights)
+            x_filtered = x_filtered.multiply(weights_filt)
+            y = y.multiply(weights)
+            y_regressor = y_regressor.multiply(weights)
+
+        return x, x_regressor, x_filtered, y, y_regressor
+
+    def _filter_data(self):
+        """
+
+        """
+        data, cat_mapping = self._convert_x()
+        x_names = data.keys()
+
+        if isinstance(data, LongPanel):
+            data = data.toWide()
+
+        elif not isinstance(data, WidePanel):
+            data = WidePanel.fromDict(data)
+
+        if self._weights is not None:
+            data['__weights__'] = self._weights
+
+        # Filter x's without y (so we can make a prediction)
+        filtered = data.toLong()
+
+        # Filter all data together using toLong
+        data['__y__'] = self._y_orig
+        data_long = data.toLong()
+
+        x_filt = filtered.filterItems(x_names)
+        weights_filt = filtered['__weights__'] if self._weights else None
+
+        x = data_long.filterItems(x_names)
+        y = data_long['__y__']
+        weights = data_long['__weights__'] if self._weights else None
+
+        return x, x_filt, y, weights, weights_filt, cat_mapping
+
+    def _convert_x(self):
+
+        # Converts non-numeric data in x to floats. x_converted is the
+        # DataMatrix with converted values, and x_conversion is a dict that
+        # provides the reverse mapping.  For example, if 'A' was converted to 0
+        # for x named 'variety', then x_conversion['variety'][0] is 'A'.
+        x_converted = {}
+        x_conversion = {}
+        for key, value in self._x_orig.iteritems():
+            df = value
+            if _is_numeric(df):
+                x_converted[key] = df
+            else:
+                values = df.values
+                distinct_values = sorted(set(values.flat))
+                x_conversion[key] = dict(enumerate(distinct_values))
+                new_values = np.searchsorted(distinct_values, values)
+                x_converted[key] = DataMatrix(new_values, index=df.index,
+                                              columns=df.columns)
+
+        data = x_converted.copy()
+
+        return data, x_conversion
+
+    def _add_dummies(self, panel, mapping):
+        """
+        Add entity and / or categorical dummies to input X LongPanel
+
+        Returns
+        -------
+        LongPanel
+        """
+        panel = self._add_entity_effects(panel)
+        panel = self._add_categorical_dummies(panel, mapping)
+
+        return panel
+
+    def _add_entity_effects(self, panel):
+        """
+        Add entity dummies to panel
+
+        Returns
+        -------
+        LongPanel
+        """
+        if not self._entity_effects:
+            return panel
+
+        self.log('-- Adding entity fixed effect dummies')
+
+        dummies = panel.getAxisDummies(axis='minor')
+
+        if not self._use_all_dummies:
+            if 'entity' in self._dropped_dummies:
+                to_exclude = self._dropped_dummies.get('entity')
+            else:
+                to_exclude = panel.minor_axis[0]
+
+            if to_exclude not in dummies.items:
+                raise Exception('%s not in %s' % (to_exclude,
+                                                  dummies.items))
+
+            self.log('-- Excluding dummy for entity: %s' % to_exclude)
+
+            dummies = dummies.filterItems(dummies.items - [to_exclude])
+
+        dummies = dummies.addPrefix('fe_')
+        panel = panel.merge(dummies)
+
+        return panel
+
+    def _add_categorical_dummies(self, panel, cat_mappings):
+        """
+        Add categorical dummies to panel
+
+        Returns
+        -------
+        LongPanel
+        """
+        if not self._x_effects:
+            return panel
+
+        dropped_dummy = (self._entity_effects and not self._use_all_dummies)
+
+        for effect in self._x_effects:
+            self.log('-- Adding fixed effect dummies for %s' % effect)
+
+            dummies = panel.getItemDummies(effect)
+
+            val_map = cat_mappings.get(effect)
+            if val_map:
+                val_map = dict((v, k) for k, v in val_map.iteritems())
+
+            if dropped_dummy or not self._use_all_dummies:
+                if effect in self._dropped_dummies:
+                    to_exclude = self._dropped_dummies.get(effect)
+                    mapped_name = val_map[to_exclude] if val_map else to_exclude
+                else:
+                    to_exclude = mapped_name = dummies.items[0]
+
+                if mapped_name not in dummies.items:
+                    raise Exception('%s not in %s' % (to_exclude,
+                                                      dummies.items))
+
+                self.log('-- Excluding dummy for %s: %s' % (effect, to_exclude))
+
+                dummies = dummies.filterItems(dummies.items - [mapped_name])
+                dropped_dummy = True
+
+            dummies = _convertDummies(dummies, cat_mappings.get(effect))
+            dummies = dummies.addPrefix('%s_' % effect)
+            panel = panel.merge(dummies)
+
+        return panel
+
+    @property
+    def _use_all_dummies(self):
+        """
+        In the case of using an intercept or including time fixed
+        effects, completely partitioning the sample would make the X
+        not full rank.
+        """
+        return (not self._intercept and not self._time_effects)
+
+    @cache_readonly
+    def _beta_raw(self):
+        """Runs the regression and returns the beta."""
+        X = self._x_trans_raw
+        Y = self._y_trans_raw
+
+        XX = np.dot(X.T, X)
+        XY = np.dot(X.T, Y)
+
+        return math.solve(XX, XY)
+
+    @cache_readonly
+    def beta(self):
+        return Series(self._beta_raw, index=self._x.items)
+
+    @cache_readonly
+    def _df_model_raw(self):
+        """Returns the raw model degrees of freedom."""
+        return self._df_raw - 1
+
+    @cache_readonly
+    def _df_resid_raw(self):
+        """Returns the raw residual degrees of freedom."""
+        return self._nobs - self._df_raw
+
+    @cache_readonly
+    def _df_raw(self):
+        """Returns the degrees of freedom."""
+        df = math.rank(self._x_trans_raw)
+        if self._time_effects:
+            df += self._total_times
+
+        return df
+
+    @cache_readonly
+    def _f_stat_raw(self):
+        """Returns the raw f-stat value."""
+        return math.calc_f_stat(self._nw_lags, self._r2_raw, self._r2_adj_raw,
+                                self._x.items, self._beta_raw,
+                                self._var_beta_raw, self._nobs, self.df)
+
+    @cache_readonly
+    def _r2_raw(self):
+        Y = self._y_trans_raw
+        Y_orig = self._y.values
+        X = self._x_trans_raw
+
+        resid = Y - np.dot(X, self._beta_raw)
+        SS_err = (resid ** 2).sum()
+
+        SS_total = ((Y_orig - np.mean(Y_orig)) ** 2).sum()
+
+        return 1 - SS_err / SS_total
+
+    @cache_readonly
+    def _r2_adj_raw(self):
+        """Returns the raw r-squared adjusted values."""
+        factor = ((self._nobs - 1) / (self._nobs - self._df_raw))
+        return 1 - (1 - self._r2_raw) * factor
+
+    @cache_readonly
+    def _resid_raw(self):
+        Y = self._y_trans.values.squeeze()
+        X = self._x_trans.values
+        return Y - np.dot(X, self._beta_raw)
+
+    @cache_readonly
+    def resid(self):
+        return self._unstack_vector(self._resid_raw)
+
+    @cache_readonly
+    def _rmse_raw(self):
+        """Returns the raw rmse values."""
+        X = self._x_trans_raw
+        Y = self._y_trans_raw
+        resid = Y - np.dot(X, self._beta_raw)
+        ss = (resid ** 2).sum()
+        return np.sqrt(ss / (self._nobs - self._df_raw))
+
+    @cache_readonly
+    def _var_beta_raw(self):
+        cluster_axis = None
+        if self._cluster == common.TIME:
+            cluster_axis = 0
+        elif self._cluster == common.ENTITY:
+            cluster_axis = 1
+
+        if self._time_effects:
+            xx = math.xx_time_effects(self._x, self._y)
+        else:
+            xx = np.dot(self._x.values.T, self._x.values)
+
+        return math.var_beta_panel(self._y, self._x, self._beta_raw, xx,
+                                   self._rmse_raw, cluster_axis, self._nw_lags,
+                                   self.nobs, self._df_raw, self._nw_overlap)
+
+    @cache_readonly
+    def _y_fitted_raw(self):
+        """Returns the raw fitted y values."""
+        return np.dot(self._x_filtered.values, self._beta_raw)
+
+    @cache_readonly
+    def y_fitted(self):
+        return self._unstack_vector(self._y_fitted_raw,
+                                    index=self._x_filtered.index)
+
+    def f_test(self, hypothesis):
+        """Runs the F test, given a joint hypothesis.  The hypothesis is
+        represented by a collection of equations, in the form
+
+        A*x_1+B*x_2=C
+
+        You must provide the coefficients even if they're 1.  No spaces.
+
+        The equations can be passed as either a single string or a
+        list of strings.
+
+        Examples:
+        o = ols(...)
+        o.f_test('1*x1+2*x2=0,1*x3=0')
+        o.f_test(['1*x1+2*x2=0','1*x3=0'])
+        """
+
+        x_names = self._x.items
+
+        R = []
+        r = []
+
+        if isinstance(hypothesis, str):
+            eqs = hypothesis.split(',')
+        elif isinstance(hypothesis, list):
+            eqs = hypothesis
+        else:
+            raise Exception('hypothesis must be either string or list')
+        for equation in eqs:
+            row = np.zeros(len(x_names))
+            lhs, rhs = equation.split('=')
+            for s in lhs.split('+'):
+                ss = s.split('*')
+                coeff = float(ss[0])
+                x_name = ss[1]
+                idx = x_names.indexMap[x_name]
+                row[idx] = coeff
+            rhs = float(rhs)
+
+            R.append(row)
+            r.append(rhs)
+
+        R = np.array(R)
+        q = len(r)
+        r = np.array(r).reshape(q, 1)
+
+        result = math.calc_F(R, r, self._beta_raw, self._var_beta_raw,
+                             self.nobs, self.df)
+
+        return common.f_stat_to_dict(result)
+
+    def _unstack_vector(self, vec, index=None):
+        if index is None:
+            index = self._y_trans.index
+        panel = LongPanel(vec.reshape((len(vec), 1)), ['dummy'],
+                          index=index)
+
+        return panel.toWide()['dummy']
+
+    def _unstack_y(self, vec):
+        unstacked = self._unstack_vector(vec)
+        return unstacked.reindex(self.beta.index)
+
+    @cache_readonly
+    def _time_obs_count(self):
+        # XXX
+        return self._y.count()
+
+    @cache_readonly
+    def _time_has_obs(self):
+        return self._time_obs_count > 0
+
+    @property
+    def _total_times(self):
+        return self._time_has_obs.sum()
+
+def _convertDummies(dummies, mapping):
+    # cleans up the names of the generated dummies
+    new_items = []
+    for item in dummies.items:
+        if not mapping:
+            var = '%g' % item if isinstance(item, float) else '%s' % item
+            new_items.append(var)
+        else:
+            # renames the dummies if a conversion dict is provided
+            new_items.append(mapping[int(item)])
+
+    dummies = LongPanel(dummies.values, new_items, dummies.index)
+
+    return dummies
+
+def _is_numeric(df):
+    for col in df:
+        if df[col].dtype.name == 'object':
+            return False
+
+    return True
+
+def add_intercept(panel, name='intercept'):
+    """
+    Add column of ones to input panel
+
+    Parameters
+    ----------
+    panel: Panel (Long or Wide)
+    name: string, default 'intercept']
+
+    Returns
+    -------
+    New object (same type as input)
+    """
+    panel = panel.copy()
+    panel[name] = 1
+
+    return panel
+
+class MovingPanelOLS(PanelOLS, MovingOLS):
+    """Implements rolling/expanding panel OLS.
+
+    Parameters
+    ----------
+    y: DataFrame
+    x: Dict of DataFrame
+    intercept: bool
+        True if you want an intercept.
+    nw_lags: None or int
+        Number of Newey-West lags.
+    window_type: int
+        FULL_SAMPLE, ROLLING, EXPANDING.  FULL_SAMPLE by default.
+    window: int
+        size of window (for rolling/expanding OLS)
+    weights: DataFrame
+        Weight for each observation.  The weights are not normalized;
+        they're multiplied directly by each observation.
+    pool: bool
+        Whether to run pooled panel regression.  Defaults to true.
+    entity_effects: bool
+        Whether to account for entity fixed effects.  Defaults to false.
+    time_effects: bool
+        Whether to account for time fixed effects.  Defaults to false.
+    x_effects: list
+        List of x's to account for fixed effects.  Defaults to none.
+    dropped_dummies: dict
+        Key is the name of the variable for the fixed effect.
+        Value is the value of that variable for which we drop the dummy.
+
+        For entity fixed effects, key equals 'entity'.
+
+        By default, the first dummy is dropped if no dummy is specified.
+    cluster: int
+        ENTITY or TIME, indicating entity/time clustering
+    """
+    def __init__(self, y, x, weights=None,
+                 window_type=common.ROLLING, window=10, min_periods=0,
+                 intercept=True,
+                 nw_lags=None, nw_overlap=False,
+                 entity_effects=False,
+                 time_effects=False,
+                 x_effects=None,
+                 cluster=None,
+                 dropped_dummies=None,
+                 verbose=False):
+
+        self._args = dict(weights=weights,
+                          intercept=intercept,
+                          nw_lags=nw_lags,
+                          nw_overlap=nw_overlap,
+                          entity_effects=entity_effects,
+                          time_effects=time_effects,
+                          x_effects=x_effects,
+                          cluster=cluster,
+                          dropped_dummies=dropped_dummies,
+                          verbose=verbose)
+
+        PanelOLS.__init__(self, y=y, x=x, **self._args)
+
+        self._window_type = common._get_window_type(window_type)
+        self._window = window
+        self._min_periods = min_periods
+
+    @cache_readonly
+    def beta(self):
+        return DataMatrix(self._beta_raw,
+                          index=self._result_index,
+                          columns=self._x.items)
+
+    @cache_readonly
+    def _beta_raw(self):
+        """Runs the regression and returns the beta."""
+        beta, indices = self._rolling_ols_call
+
+        return beta[indices]
+
+    @cache_readonly
+    def rank(self):
+        return Series(self._rank_raw, index=self._result_index)
+
+    @cache_readonly
+    def _rank_raw(self):
+        rank = self._rolling_rank
+
+        return rank[self._valid_indices]
+
+    @cache_readonly
+    def _result_index(self):
+        return self._index[self._valid_indices]
+
+    @property
+    def _valid_indices(self):
+        return self._rolling_ols_call[1]
+
+    @cache_readonly
+    def _rolling_ols_call(self):
+        return self._calc_betas()
+
+    def _calc_betas(self):
+        N = len(self._index)
+        K = len(self._x.items)
+
+        betas = np.empty((N, K), dtype=float)
+        betas[:] = np.NaN
+
+        valid = self._time_has_obs
+        enough = self._enough_obs
+        window_obs = self._window_time_obs
+
+        # Use transformed (demeaned) Y, X variables
+        cum_xx = self._cum_xx(self._x_trans)
+        cum_xy = self._cum_xy(self._x_trans, self._y_trans)
+
+        for i in xrange(N):
+            # XXX
+            if not valid[i] or not enough[i]:
+                continue
+
+            xx = cum_xx[i]
+            xy = cum_xy[i]
+            obs = window_obs[i]
+            if self._is_rolling and i >= obs:
+                xx = xx - cum_xx[i - obs]
+                xy = xy - cum_xy[i - obs]
+
+            betas[i] = math.solve(xx, xy).squeeze()
+
+        have_betas = np.arange(N)[-np.isnan(betas).any(axis=1)]
+
+        return betas, have_betas
+
+    def _cum_xx(self, x):
+        dates = x.index.major_axis
+        K = len(x.items)
+        valid = self._time_has_obs
+        cum_xx = []
+
+        last = np.zeros((K, K))
+        for i in xrange(len(dates)):
+            if not valid[i]:
+                cum_xx.append(last)
+                continue
+
+            date = dates[i]
+            x_slice = x.getValueSlice(date, date)
+            xx = last = last + np.dot(x_slice.T, x_slice)
+            cum_xx.append(xx)
+
+        return cum_xx
+
+    def _cum_xy(self, x, y):
+        dates = x.index.major_axis
+        valid = self._time_has_obs
+        cum_xy = []
+
+        last = np.zeros((len(x.items), 1))
+        for i in xrange(len(dates)):
+            if not valid[i]:
+                cum_xy.append(last)
+                continue
+
+            date = dates[i]
+            x_slice = x.getValueSlice(date, date)
+            y_slice = y.getValueSlice(date, date)
+
+            xy = last = last + np.dot(x_slice.T, y_slice)
+            cum_xy.append(xy)
+
+        return cum_xy
+
+    @property
+    def _is_rolling(self):
+        return self._window_type == common.ROLLING
+
+    @cache_readonly
+    def _rolling_rank(self):
+        dates = self._x.index.major_axis
+
+        N = len(dates)
+        ranks = np.empty(N, dtype=float)
+        ranks[:] = np.NaN
+
+        enough = self._enough_obs
+        time_periods = self._window_time_obs
+
+        for i in xrange(N):
+            if not enough[i]:
+                continue
+
+            if self._is_rolling:
+                prior_date = dates[i - time_periods[i] + 1]
+            else:
+                prior_date = dates[0]
+
+            date = dates[i]
+            x_slice = self._x.getValueSlice(prior_date, date)
+            ranks[i] = math.rank(x_slice)
+
+        return ranks
+
+    @cache_readonly
+    def _df_raw(self):
+        """Returns the degrees of freedom."""
+        df = self._rolling_rank
+
+        if self._time_effects:
+            df += self._window_time_obs
+
+        return df[self._valid_indices]
+
+    @cache_readonly
+    def _df_resid_raw(self):
+        """Returns the raw residual degrees of freedom."""
+        return self._window_nobs - self._df_raw
+
+    @cache_readonly
+    def _var_beta_raw(self):
+        """Returns the raw covariance of beta."""
+        x = self._x
+        y = self._y
+        dates = x.index.major_axis
+
+        cluster_axis = None
+        if self._cluster == common.TIME:
+            cluster_axis = 0
+        elif self._cluster == common.ENTITY:
+            cluster_axis = 1
+
+        time_periods = self._window_time_obs
+        window_nobs = self._window_nobs
+        rmse = self._rmse_raw
+        beta = self._beta_raw
+        df = self._df_raw
+
+        if not self._time_effects:
+            # Non-transformed X
+
+            cum_xx = self._cum_xx(self._x)
+
+        results = []
+        for n, i in enumerate(self._valid_indices):
+            obs = time_periods[i]
+
+            if self._is_rolling:
+                prior_date = dates[i - obs + 1]
+            else:
+                prior_date = dates[0]
+
+            date = dates[i]
+
+            x_slice = x.getSlice(prior_date, date)
+            y_slice = y.getSlice(prior_date, date)
+
+            if self._time_effects:
+                xx = math.xx_time_effects(x_slice, y_slice)
+            else:
+                xx = cum_xx[i]
+                if self._is_rolling and i >= obs:
+                    xx = xx - cum_xx[i - time_periods[i]]
+
+            result = math.var_beta_panel(y_slice, x_slice, beta[n], xx, rmse[n],
+                                         cluster_axis, self._nw_lags,
+                                         window_nobs[n], df[n],
+                                         self._nw_overlap)
+
+            results.append(result)
+
+        return np.array(results)
+
+    def f_test(self, hypothesis):
+        raise Exception('f_test not supported for rolling/expanding OLS')
+
+    @cache_readonly
+    def _f_stat_raw(self):
+        """Returns the raw f-stat value."""
+        items = self._x.items
+        nobs = self._window_nobs
+        df = self._df_raw
+        df_resid = nobs - df
+
+        # var_beta has not been newey-west adjusted
+        if self._nw_lags is None:
+            F = self._r2_raw / (self._r2_raw - self._r2_adj_raw)
+
+            q = len(items)
+            if 'intercept' in items:
+                q -= 1
+
+            def get_result_simple(Fst, d):
+                return Fst, (q, d), 1 - stats.f.cdf(Fst, q, d)
+
+            # Compute the P-value for each pair
+            result = starmap(get_result_simple, izip(F, df_resid))
+
+            return list(result)
+
+        K = len(items)
+        R = np.eye(K)
+        r = np.zeros((K, 1))
+
+        intercept = items.indexMap.get('intercept')
+
+        if intercept is not None:
+            R = np.concatenate((R[0 : intercept], R[intercept + 1:]))
+            r = np.concatenate((r[0 : intercept], r[intercept + 1:]))
+
+        def get_result(beta, vcov, n, d):
+            return math.calc_F(R, r, beta, vcov, n, d)
+
+        results = starmap(get_result,
+                          izip(self._beta_raw, self._var_beta_raw, nobs, df))
+
+        return list(results)
+
+    @cache_readonly
+    def _resid_stats(self):
+        Y = self._y_trans
+        Y_orig = self._y
+        X = self._x_trans
+        dates = self._index
+        time_periods = self._window_time_obs
+
+        sst = []
+        sse = []
+
+        for n, index in enumerate(self._valid_indices):
+
+            if self._is_rolling:
+                prior_date = dates[index - time_periods[index] + 1]
+            else:
+                prior_date = dates[0]
+
+            date = dates[index]
+
+            X_slice = X.getValueSlice(prior_date, date)
+            Y_slice = Y.getValueSlice(prior_date, date).squeeze()
+            Y_orig_slice = Y_orig.getValueSlice(prior_date, date).squeeze()
+
+            beta_slice = self._beta_raw[n]
+
+            resid = Y_slice - np.dot(X_slice, beta_slice)
+            SS_err = (resid ** 2).sum()
+
+            Y_mean = np.mean(Y_orig_slice)
+            SS_total = ((Y_orig_slice - Y_mean) ** 2).sum()
+
+            sse.append(SS_err)
+            sst.append(SS_total)
+
+        sse = np.array(sse)
+        sst = np.array(sst)
+
+        return {
+            'sse' : sse,
+            'sst' : sst,
+        }
+
+    @cache_readonly
+    def _rmse_raw(self):
+        """Returns the raw rmse values."""
+        return np.sqrt(self._resid_stats['sse'] / self._df_resid_raw)
+
+    @cache_readonly
+    def _r2_raw(self):
+        rs = self._resid_stats
+        return 1 - rs['sse'] / rs['sst']
+
+    @cache_readonly
+    def _r2_adj_raw(self):
+        """Returns the raw r-squared adjusted values."""
+        nobs = self._window_nobs
+        factors = (nobs - 1) / (nobs - self._df_raw)
+        return 1 - (1 - self._r2_raw) * factors
+
+    @cache_readonly
+    def _t_stat_raw(self):
+        """Returns the raw t-stat value."""
+        return np.nan_to_num(self._beta_raw / self._std_err_raw)
+
+    @cache_readonly
+    def _p_value_raw(self):
+        """Returns the raw p values."""
+        get_prob = lambda a, b: 2 * (1 - stats.t.cdf(a, b))
+
+        result = starmap(get_prob,
+                         izip(np.fabs(self._t_stat_raw),
+                              self._window_nobs - self._df_raw))
+
+        result = np.array(list(result))
+
+        return result
+
+    @cache_readonly
+    def _resid_raw(self):
+        beta_matrix = self._beta_matrix(lag=0)
+
+        Y = self._y_trans.values.squeeze()
+        X = self._x_trans.values
+        resid = Y - (X * beta_matrix).sum(1)
+
+        return resid
+
+    @cache_readonly
+    def _y_fitted_raw(self):
+        x = self._x_raw
+        betas = self._beta_matrix(lag=0)
+        return (betas * x).sum(1)
+
+    @cache_readonly
+    def _y_predict_raw(self):
+        """Returns the raw predicted y values."""
+        x = self._x_raw
+        betas = self._beta_matrix(lag=1)
+        return (betas * x).sum(1)
+
+    @cache_readonly
+    def resid(self):
+        return self._unstack_y(self._resid_raw)
+
+    @cache_readonly
+    def y_fitted(self):
+        return self._unstack_y(self._y_fitted_raw)
+
+    @cache_readonly
+    def y_predict(self):
+        """Returns the predicted y values."""
+        return self._unstack_y(self._y_predict_raw)
+
+    def _beta_matrix(self, lag=0):
+        assert(lag >= 0)
+
+        labels = self._y_trans.index.major_labels - lag
+        indexer = self._valid_indices.searchsorted(labels, side='left')
+
+        beta_matrix = self._beta_raw[indexer]
+        beta_matrix[labels < 0] = np.NaN
+
+        return beta_matrix
+
+    @cache_readonly
+    def _window_nobs_raw(self):
+        if self._window_type == common.EXPANDING:
+            window = len(self._index)
+        else:
+            window = self._window
+
+        result = moments.rollingSum(self._time_obs_count, window,
+                                    minPeriods=1)
+
+        return result.astype(int)
+
+    @cache_readonly
+    def _window_nobs(self):
+        return self._window_nobs_raw[self._valid_indices]
+
+    @cache_readonly
+    def _window_time_obs(self):
+        window_obs = moments.rollingSum(self._time_obs_count > 0,
+                                        self._window,
+                                        minPeriods=1)
+
+        window_obs[np.isnan(window_obs)] = 0
+        return window_obs.astype(int)
+
+    @cache_readonly
+    def _enough_obs(self):
+        return self._window_nobs_raw >= max(self._min_periods,
+                                            len(self._x.items) * 2)
+
+def create_ols_dict(attr):
+    def attr_getter(self):
+        d = {}
+        for k, v in self.results.iteritems():
+            result = getattr(v, attr)
+            d[k] = result
+
+        return d
+
+    return attr_getter
+
+def create_ols_attr(attr):
+    return property(create_ols_dict(attr))
+
+class NonPooledPanelOLS(object):
+    """Implements non-pooled panel OLS.
+
+    Parameters
+    ----------
+    y: DataFrame
+    x: Series, DataFrame, or dict of Series
+    intercept: bool
+        True if you want an intercept.
+    nw_lags: None or int
+        Number of Newey-West lags.
+    window_type: int
+        FULL_SAMPLE, ROLLING, EXPANDING.  FULL_SAMPLE by default.
+    window: int
+        size of window (for rolling/expanding OLS)
+    """
+
+    ATTRIBUTES = [
+        'beta',
+        'df',
+        'df_model',
+        'df_resid',
+        'f_stat',
+        'p_value',
+        'r2',
+        'r2_adj',
+        'resid',
+        'rmse',
+        'std_err',
+        'summary_as_matrix',
+        't_stat',
+        'var_beta',
+        'x',
+        'y',
+        'y_fitted',
+        'y_predict'
+    ]
+
+    def __init__(self, y, x, window_type=common.FULL_SAMPLE, window=None,
+                 intercept=True, nw_lags=None, nw_overlap=False):
+
+        for attr in self.ATTRIBUTES:
+            setattr(self.__class__, attr, create_ols_attr(attr))
+
+        results = {}
+
+        for entity in y:
+            entity_y = y[entity]
+
+            entity_x = {}
+            for x_var in x:
+                entity_x[x_var] = x[x_var][entity]
+
+            from pandas.stats.interface import ols
+            results[entity] = ols(y=entity_y,
+                                  x=entity_x,
+                                  window_type=window_type,
+                                  window=window,
+                                  intercept=intercept,
+                                  nw_lags=nw_lags,
+                                  nw_overlap=nw_overlap)
+
+        self.results = results
diff --git a/pandas/stats/tests/common.py b/pandas/stats/tests/common.py
new file mode 100644
index 000000000..73f112f09
--- /dev/null
+++ b/pandas/stats/tests/common.py
@@ -0,0 +1,153 @@
+from datetime import datetime
+import string
+import unittest
+
+import numpy as np
+
+from pandas.core.api import DataMatrix, DateRange
+
+
+N = 100
+K = 4
+
+start = datetime(2007, 1, 1)
+DATE_RANGE = DateRange(start, periods=N)
+
+COLS = ['Col' + c for c in string.ascii_uppercase[:K]]
+
+def makeDataMatrix():
+    data = DataMatrix(np.random.randn(N, K),
+                      columns=COLS,
+                      index=DATE_RANGE)
+
+    return data
+
+def isiterable(obj):
+    return getattr(obj, '__iter__', False)
+
+def assert_almost_equal(a, b):
+    if isiterable(a):
+        np.testing.assert_(isiterable(b))
+        np.testing.assert_equal(len(a), len(b))
+        for i in xrange(len(a)):
+            assert_almost_equal(a[i], b[i])
+        return
+
+    err_msg = lambda a, b: 'expected %.5f but got %.5f' % (a, b)
+
+    if np.isnan(a):
+        np.testing.assert_(np.isnan(b))
+        return
+
+    # case for zero
+    if abs(a) < 1e-5:
+        np.testing.assert_almost_equal(
+            a, b, decimal=5, err_msg=err_msg(a, b), verbose=False)
+    else:
+        np.testing.assert_almost_equal(
+            1, a/b, decimal=5, err_msg=err_msg(a, b), verbose=False)
+
+
+def getBasicDatasets():
+    A = makeDataMatrix()
+    B = makeDataMatrix()
+    C = makeDataMatrix()
+
+    return A, B, C
+
+class BaseTest(unittest.TestCase):
+    def setUp(self):
+        self.A, self.B, self.C = getBasicDatasets()
+
+        self.createData1()
+        self.createData2()
+        self.createData3()
+
+    def createData1(self):
+        date = datetime(2007, 1, 1)
+        date2 = datetime(2007, 1, 15)
+        date3 = datetime(2007, 1, 22)
+
+        A = self.A.copy()
+        B = self.B.copy()
+        C = self.C.copy()
+
+        A['ColA'][date] = np.NaN
+        B['ColA'][date] = np.NaN
+        C['ColA'][date] = np.NaN
+        C['ColA'][date2] = np.NaN
+
+        # truncate data to save time
+        A = A[:30]
+        B = B[:30]
+        C = C[:30]
+
+        self.panel_y = A
+        self.panel_x = {'B' : B, 'C' : C}
+
+        self.series_panel_y = A.filterItems(['ColA'])
+        self.series_panel_x = {'B' : B.filterItems(['ColA']),
+                               'C' : C.filterItems(['ColA'])}
+        self.series_y = A['ColA']
+        self.series_x = {'B' : B['ColA'],
+                         'C' : C['ColA']}
+
+    def createData2(self):
+        y_data = [[1, np.NaN],
+                  [2, 3],
+                  [4, 5]]
+        y_index = [datetime(2000, 1, 1),
+                   datetime(2000, 1, 2),
+                   datetime(2000, 1, 3)]
+        y_cols = ['A', 'B']
+        self.panel_y2 = DataMatrix(np.array(y_data), index=y_index, columns=y_cols)
+
+        x1_data = [[6, np.NaN],
+                   [7, 8],
+                   [9, 30],
+                   [11, 12]]
+        x1_index = [datetime(2000, 1, 1),
+                    datetime(2000, 1, 2),
+                    datetime(2000, 1, 3),
+                    datetime(2000, 1, 4)]
+        x1_cols = ['A', 'B']
+        x1 = DataMatrix(np.array(x1_data), index=x1_index, columns=x1_cols)
+
+        x2_data = [[13, 14, np.NaN],
+                   [15, np.NaN, np.NaN],
+                   [16, 17, 48],
+                   [19, 20, 21],
+                   [22, 23, 24]]
+        x2_index = [datetime(2000, 1, 1),
+                    datetime(2000, 1, 2),
+                    datetime(2000, 1, 3),
+                    datetime(2000, 1, 4),
+                    datetime(2000, 1, 5)]
+        x2_cols = ['C', 'A', 'B']
+        x2 = DataMatrix(np.array(x2_data), index=x2_index, columns=x2_cols)
+
+        self.panel_x2 = {'x1' : x1, 'x2' : x2}
+
+    def createData3(self):
+        y_data = [[1, 2],
+                  [3, 4]]
+        y_index = [datetime(2000, 1, 1),
+                   datetime(2000, 1, 2)]
+        y_cols = ['A', 'B']
+        self.panel_y3 = DataMatrix(np.array(y_data), index=y_index, columns=y_cols)
+
+        x1_data = [['A', 'B'],
+                   ['C', 'A']]
+        x1_index = [datetime(2000, 1, 1),
+                    datetime(2000, 1, 2)]
+        x1_cols = ['A', 'B']
+        x1 = DataMatrix(np.array(x1_data), index=x1_index, columns=x1_cols)
+
+        x2_data = [['3.14', '1.59'],
+                   ['2.65', '3.14']]
+        x2_index = [datetime(2000, 1, 1),
+                    datetime(2000, 1, 2)]
+        x2_cols = ['A', 'B']
+        x2 = DataMatrix(np.array(x2_data), index=x2_index, columns=x2_cols)
+
+        self.panel_x3 = {'x1' : x1, 'x2' : x2}
diff --git a/pandas/stats/tests/test_fama_macbeth.py b/pandas/stats/tests/test_fama_macbeth.py
new file mode 100644
index 000000000..dd035e0b4
--- /dev/null
+++ b/pandas/stats/tests/test_fama_macbeth.py
@@ -0,0 +1,32 @@
+from pandas.stats.api import *
+from pandas.stats.tests.common import assert_almost_equal, BaseTest
+
+class TestFamaMacBeth(BaseTest):
+    def testFamaMacBethRolling(self):
+        self.checkFamaMacBethExtended(ROLLING, self.panel_x, self.panel_y)
+
+    def checkFamaMacBethExtended(self, window_type, x, y, **kwds):
+        window = 25
+
+        result = fama_macbeth(y=y, x=x, window_type=window_type, window=window,
+                              **kwds)
+
+        index =  result._index
+        time = len(index)
+
+        for i in xrange(time - window + 1):
+            if window_type == ROLLING:
+                start = index[i]
+            else:
+                start = index[0]
+
+            end = index[i + window - 1]
+
+            x2 = {}
+            for k, v in x.iteritems():
+                x2[k] = v.truncate(start, end)
+            y2 = y.truncate(start, end)
+
+            reference = fama_macbeth(y=y2, x=x2, **kwds)
+
+            assert_almost_equal(reference._stats, result._stats[:, i])
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
new file mode 100644
index 000000000..69066dd5a
--- /dev/null
+++ b/pandas/stats/tests/test_ols.py
@@ -0,0 +1,453 @@
+"""
+Unit test suite for OLS and PanelOLS classes
+"""
+
+# pylint: disable-msg=W0212
+
+from __future__ import division
+
+from datetime import datetime
+import unittest
+
+from numpy.testing import dec
+import numpy as np
+import scikits.statsmodels as sm
+import scikits.statsmodels.datasets as datasets
+from scikits.statsmodels import tools
+
+from pandas.core.panel import LongPanel
+from pandas.core.api import DataMatrix, Index, Series
+from pandas.stats.api import *
+from pandas.stats.plm import NonPooledPanelOLS
+from pandas.stats.tests.common import assert_almost_equal, BaseTest
+
+class TestOLS(BaseTest):
+
+    FIELDS = ['beta', 'df', 'df_model', 'df_resid', 'f_stat', 'p_value',
+              'r2', 'r2_adj', 'resid', 'rmse', 'std_err', 't_stat',
+              'var_beta', 'y_fitted']
+
+    # TODO: Add tests for OLS y predict
+    # TODO: Right now we just check for consistency between full-sample and
+    # rolling/expanding results of the panel OLS.  We should also cross-check
+    # with trusted implementations of panel OLS (e.g. R).
+    # TODO: Add tests for non pooled OLS.
+
+    def testOLSWithDatasets(self):
+        self.checkDataSet(datasets.ccard.Load(), skip_moving=True)
+        self.checkDataSet(datasets.cpunish.Load(), skip_moving=True)
+        self.checkDataSet(datasets.longley.Load(), skip_moving=True)
+        self.checkDataSet(datasets.stackloss.Load(), skip_moving=True)
+
+        self.checkDataSet(datasets.ccard.Load(), 39, 49) # one col in X all 0s
+        self.checkDataSet(datasets.copper.Load())
+        self.checkDataSet(datasets.scotland.Load())
+
+    def checkDataSet(self, dataset, start=None, end=None, skip_moving=False):
+        exog = dataset.exog[start : end]
+        endog = dataset.endog[start : end]
+        x = DataMatrix(exog, index=np.arange(exog.shape[0]),
+                       columns=np.arange(exog.shape[1]))
+        y = Series(endog, index=np.arange(len(endog)))
+
+        self.checkOLS(exog, endog, x, y)
+
+        if not skip_moving:
+            self.checkMovingOLS(ROLLING, x, y)
+            self.checkMovingOLS(ROLLING, x, y, nw_lags=0)
+            self.checkMovingOLS(EXPANDING, x, y, nw_lags=0)
+            self.checkMovingOLS(ROLLING, x, y, nw_lags=1)
+            self.checkMovingOLS(EXPANDING, x, y, nw_lags=1)
+            self.checkMovingOLS(EXPANDING, x, y, nw_lags=1, nw_overlap=True)
+
+    def checkOLS(self, exog, endog, x, y):
+        reference = sm.OLS(endog, sm.add_constant(exog)).fit()
+        result = ols(y=y, x=x)
+
+        assert_almost_equal(reference.params, result._beta_raw)
+        assert_almost_equal(reference.df_model, result._df_model_raw)
+        assert_almost_equal(reference.df_resid, result._df_resid_raw)
+        assert_almost_equal(reference.fvalue, result._f_stat_raw[0])
+        assert_almost_equal(reference.pvalues, result._p_value_raw)
+        assert_almost_equal(reference.rsquared, result._r2_raw)
+        assert_almost_equal(reference.rsquared_adj, result._r2_adj_raw)
+        assert_almost_equal(reference.resid, result._resid_raw)
+        assert_almost_equal(reference.bse, result._std_err_raw)
+        assert_almost_equal(reference.t(), result._t_stat_raw)
+        assert_almost_equal(reference.cov_params(), result._var_beta_raw)
+        assert_almost_equal(reference.fittedvalues, result._y_fitted_raw)
+
+        _check_non_raw_results(result)
+
+    def checkMovingOLS(self, window_type, x, y, **kwds):
+        window = tools.rank(x.values) + 2
+
+        moving = ols(y=y, x=x, window_type=window_type, window=window,
+                     **kwds)
+
+        if isinstance(moving.y, Series):
+            index = moving.y.index
+        elif isinstance(moving.y, LongPanel):
+            index = moving.y.major_axis
+
+        time = len(index)
+
+        reference_last_only = ['resid', 'y_fitted']
+
+        for i in xrange(time - window + 1):
+            if window_type == ROLLING:
+                start = index[i]
+            else:
+                start = index[0]
+
+            end = index[i + window - 1]
+
+            x2 = {}
+            for k, v in x.iteritems():
+                x2[k] = v.truncate(start, end)
+            y2 = y.truncate(start, end)
+
+            static = ols(y=y2, x=x2, **kwds)
+
+            self.compare(static, moving, reference_last_only, i)
+
+            # y-predict (just non-null check)
+            self.assertTrue(np.isfinite(moving._y_predict_raw).all())
+
+        _check_non_raw_results(moving)
+
+    def compare(self, reference, result, reference_last_only=None,
+                result_index=None):
+        for field in self.FIELDS:
+            attr = '_%s_raw' % field
+
+            ref = getattr(reference, attr)
+
+            if (reference_last_only is not None
+                and field in reference_last_only):
+                ref = ref[-1]
+
+            res = getattr(result, attr)
+
+            if result_index is not None:
+                res = res[result_index]
+
+            assert_almost_equal(ref, res)
+
+class TestPanelOLS(BaseTest):
+
+
+    FIELDS = ['beta', 'df', 'df_model', 'df_resid', 'f_stat',
+              'p_value', 'r2', 'r2_adj', 'rmse', 'std_err',
+              't_stat', 'var_beta']
+
+    _other_fields = ['resid', 'y_fitted']
+
+    def testFiltering(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2)
+
+        x = result._x
+        index = [x.major_axis[i] for i in x.index.major_labels]
+        index = Index(sorted(set(index)))
+        exp_index = Index([datetime(2000, 1, 1), datetime(2000, 1, 3)])
+        self.assertTrue(exp_index.equals(index))
+
+        index = [x.minor_axis[i] for i in x.index.minor_labels]
+        index = Index(sorted(set(index)))
+        exp_index = Index(['A', 'B'])
+        self.assertTrue(exp_index.equals(index))
+
+        x = result._x_filtered
+        index = [x.major_axis[i] for i in x.index.major_labels]
+        index = Index(sorted(set(index)))
+        exp_index = Index([datetime(2000, 1, 1),
+                           datetime(2000, 1, 3),
+                           datetime(2000, 1, 4)])
+        self.assertTrue(exp_index.equals(index))
+
+        assert_almost_equal(result._y.values.flat, [1, 4, 5])
+
+        exp_x = [[6, 14, 1],
+                 [9, 17, 1],
+                 [30, 48, 1]]
+        assert_almost_equal(exp_x, result._x.values)
+
+        exp_x_filtered = [[6, 14, 1], [9, 17, 1], [30, 48, 1], [11, 20, 1],
+                          [12, 21, 1]]
+        assert_almost_equal(exp_x_filtered, result._x_filtered.values)
+
+        self.assertTrue(result._x_filtered.major_axis.equals(
+            result.y_fitted.index))
+
+    def testWithWeights(self):
+        data = np.arange(10).reshape((5, 2))
+        index = [datetime(2000, 1, 1),
+                 datetime(2000, 1, 2),
+                 datetime(2000, 1, 3),
+                 datetime(2000, 1, 4),
+                 datetime(2000, 1, 5)]
+        cols = ['A', 'B']
+        weights = DataMatrix(data, index=index, columns=cols)
+
+        result = ols(y=self.panel_y2, x=self.panel_x2, weights=weights)
+
+        assert_almost_equal(result._y.values.flat, [0, 16, 25])
+
+        exp_x = [[0, 0, 0],
+                 [36, 68, 4],
+                 [150, 240, 5]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_x_filtered = [[0, 0, 0],
+                          [36, 68, 4],
+                          [150, 240, 5],
+                          [66, 120, 6],
+                          [84, 147, 7]]
+
+        assert_almost_equal(result._x_filtered.values, exp_x_filtered)
+
+        # _check_non_raw_results(result)
+
+    def testWithTimeEffects(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2, time_effects=True)
+
+        assert_almost_equal(result._y_trans.values.flat, [0, -0.5, 0.5])
+
+        exp_x = [[0, 0], [-10.5, -15.5], [10.5, 15.5]]
+        assert_almost_equal(result._x_trans.values, exp_x)
+
+        # _check_non_raw_results(result)
+
+    def testWithEntityEffects(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2, entity_effects=True)
+
+        assert_almost_equal(result._y.values.flat, [1, 4, 5])
+        exp_x = [[6, 14, 0, 1], [9, 17, 0, 1], [30, 48, 1, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1', 'x2', 'fe_B', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testWithEntityEffectsAndDroppedDummies(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2, entity_effects=True,
+                     dropped_dummies={'entity' : 'B'})
+
+        assert_almost_equal(result._y.values.flat, [1, 4, 5])
+        exp_x = [[6, 14, 1, 1], [9, 17, 1, 1], [30, 48, 0, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1', 'x2', 'fe_A', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testWithXEffects(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2, x_effects=['x1'])
+
+        assert_almost_equal(result._y.values.flat, [1, 4, 5])
+        exp_x = [[0, 0, 14, 1], [0, 1, 17, 1], [1, 0, 48, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1_30', 'x1_9', 'x2', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testWithXEffectsAndDroppedDummies(self):
+        result = ols(y=self.panel_y2, x=self.panel_x2, x_effects=['x1'],
+                     dropped_dummies={'x1' : 30})
+
+        assert_almost_equal(result._y.values.flat, [1, 4, 5])
+        exp_x = [[1, 0, 14, 1], [0, 1, 17, 1], [0, 0, 48, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1_6', 'x1_9', 'x2', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testWithXEffectsAndConversion(self):
+        result = ols(y=self.panel_y3, x=self.panel_x3, x_effects=['x1', 'x2'])
+
+        assert_almost_equal(result._y.values.flat, [1, 2, 3, 4])
+        exp_x = [[0, 0, 0, 1, 1], [1, 0, 0, 0, 1], [0, 1, 1, 0, 1],
+                 [0, 0, 0, 1, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1_B', 'x1_C', 'x2_2.65', 'x2_3.14', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testWithXEffectsAndConversionAndDroppedDummies(self):
+        result = ols(y=self.panel_y3, x=self.panel_x3, x_effects=['x1', 'x2'],
+                     dropped_dummies={'x2' : '3.14'})
+
+        assert_almost_equal(result._y.values.flat, [1, 2, 3, 4])
+        exp_x = [[0, 0, 0, 0, 1], [1, 0, 1, 0, 1], [0, 1, 0, 1, 1],
+                 [0, 0, 0, 0, 1]]
+        assert_almost_equal(result._x.values, exp_x)
+
+        exp_index = Index(['x1_B', 'x1_C', 'x2_1.59', 'x2_2.65', 'intercept'])
+        self.assertTrue(exp_index.equals(result._x.items))
+
+        # _check_non_raw_results(result)
+
+    def testForSeries(self):
+        self.checkForSeries(self.series_panel_x, self.series_panel_y,
+                            self.series_x, self.series_y)
+
+        self.checkForSeries(self.series_panel_x, self.series_panel_y,
+                            self.series_x, self.series_y, nw_lags=0)
+
+        self.checkForSeries(self.series_panel_x, self.series_panel_y,
+                            self.series_x, self.series_y, nw_lags=1,
+                            nw_overlap=True)
+
+    def testRollingWithWeights(self):
+        weights = self.panel_y.copy()
+
+        weights.values = np.random.standard_normal(weights.values.shape)
+        self.checkRollingOLS(self.panel_x,
+                            self.panel_y, weights=weights)
+
+    def testRolling(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y)
+
+    def testRollingWithFixedEffects(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            entity_effects=True)
+
+    def testRollingWithTimeEffects(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            time_effects=True)
+
+    def testRollingWithNeweyWest(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            nw_lags=1)
+
+    def testRollingWithEntityCluster(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            cluster=ENTITY)
+
+    def testRollingWithTimeEffectsAndEntityCluster(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            time_effects=True, cluster=ENTITY)
+
+    def testRollingWithTimeCluster(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            cluster=TIME)
+
+    def testRollingWithNeweyWestAndEntityCluster(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            nw_lags=1, cluster=ENTITY)
+
+    def testRollingWithNeweyWestAndTimeEffectsAndEntityCluster(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y,
+                            nw_lags=1, cluster=ENTITY, time_effects=True)
+
+    def testExpanding(self):
+        self.checkRollingOLS(self.panel_x, self.panel_y, window_type=EXPANDING)
+
+    def testNonPooled(self):
+        self.checkNonPooled(y=self.panel_y, x=self.panel_x)
+        self.checkNonPooled(y=self.panel_y, x=self.panel_x,
+                                    window_type=ROLLING, window=25)
+
+    def checkNonPooled(self, x, y, **kwds):
+        # For now, just check that it doesn't crash
+        result = ols(y=y, x=x, pool=False, **kwds)
+        print result
+        for attr in NonPooledPanelOLS.ATTRIBUTES:
+            print getattr(result, attr)
+
+    def checkRollingOLS(self, x, y, window_type=ROLLING, **kwds):
+        window = 25  # must be larger than rank of x
+
+        moving = ols(y=y, x=x, window_type=window_type,
+                     window=window, **kwds)
+
+        if isinstance(moving.y, Series):
+            index = moving.y.index
+        elif isinstance(moving.y, LongPanel):
+            index = moving.y.major_axis
+
+        time_periods = moving._window_time_obs
+
+        for n, i in enumerate(moving._valid_indices):
+            if window_type == ROLLING:
+                prior_date = index[i - time_periods[i] + 1]
+            else:
+                prior_date = index[0]
+
+            date = index[i]
+
+            x_iter = {}
+            for k, v in x.iteritems():
+                x_iter[k] = v.truncate(before=prior_date, after=date)
+            y_iter = y.truncate(before=prior_date, after=date)
+
+            static = ols(y=y_iter, x=x_iter, **kwds)
+
+            self.compare(static, moving, event_index=i,
+                         result_index=n)
+
+        _check_non_raw_results(moving)
+
+    def checkForSeries(self, x, y, series_x, series_y, **kwds):
+        # Consistency check with simple OLS.
+        result = ols(y=y, x=x, **kwds)
+        reference = ols(y=series_y, x=series_x, **kwds)
+
+        self.compare(reference, result)
+
+    def compare(self, static, moving, event_index=None,
+                result_index=None):
+
+        # Check resid if we have a time index specified
+        if event_index is not None:
+            staticSlice = _period_slice(static, -1)
+            movingSlice = _period_slice(moving, event_index)
+
+            ref = static._resid_raw[staticSlice]
+            res = moving._resid_raw[movingSlice]
+
+            assert_almost_equal(ref, res)
+
+            ref = static._y_fitted_raw[staticSlice]
+            res = moving._y_fitted_raw[movingSlice]
+
+            assert_almost_equal(ref, res)
+
+        # Check y_fitted
+
+        for field in self.FIELDS:
+            attr = '_%s_raw' % field
+
+            ref = getattr(static, attr)
+            res = getattr(moving, attr)
+
+            if result_index is not None:
+                res = res[result_index]
+
+            assert_almost_equal(ref, res)
+
+def _check_non_raw_results(model):
+    print model
+    print model.resid
+    print model.summary_as_matrix
+    print model.y_fitted
+    print model.y_predict
+
+def _period_slice(panelModel, i):
+    index = panelModel._x_trans.index
+    period = index.major_axis[i]
+
+    L, R = index.getMajorBounds(period, period)
+
+    return slice(L, R)
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/pandas/stats/tests/test_ols_filter.py b/pandas/stats/tests/test_ols_filter.py
new file mode 100644
index 000000000..14dcac499
--- /dev/null
+++ b/pandas/stats/tests/test_ols_filter.py
@@ -0,0 +1,78 @@
+from datetime import datetime
+import unittest
+
+from numpy import NaN
+
+from pandas.core.datetools import bday
+from pandas.core.api import DateRange, Series, DataFrame
+from pandas.stats.ols import _filter_data
+
+class TestOLSFilter(unittest.TestCase):
+
+    def setUp(self):
+        date_index = DateRange(datetime(2009, 12, 11), periods=3, offset=bday)
+        ts = Series([3, 1, 4], index=date_index)
+        self.TS1 = ts
+
+        date_index = DateRange(datetime(2009, 12, 11), periods=5, offset=bday)
+        ts = Series([1, 5, 9, 2, 6], index=date_index)
+        self.TS2 = ts
+
+        date_index = DateRange(datetime(2009, 12, 11), periods=3, offset=bday)
+        ts = Series([5, NaN, 3], index=date_index)
+        self.TS3 = ts
+
+        date_index = DateRange(datetime(2009, 12, 11), periods=5, offset=bday)
+        ts = Series([NaN, 5, 8, 9, 7], index=date_index)
+        self.TS4 = ts
+
+        data = {'x1' : self.TS2, 'x2' : self.TS4}
+        self.DF1 = DataFrame(data=data)
+
+        data = {'x1' : self.TS2, 'x2' : self.TS4}
+        self.DICT1 = data
+
+    def testFilterWithSeriesRHS(self):
+        lhs, rhs, rhs_pre = _filter_data(self.TS1, {'x1' : self.TS2})
+        self.tsAssertEqual(self.TS1, lhs)
+        self.tsAssertEqual(self.TS2[:3], rhs['x1'])
+        self.tsAssertEqual(self.TS2, rhs_pre['x1'])
+
+    def testFilterWithSeriesRHS2(self):
+        lhs, rhs, rhs_pre = _filter_data(self.TS2, {'x1' : self.TS1})
+        self.tsAssertEqual(self.TS2[:3], lhs)
+        self.tsAssertEqual(self.TS1, rhs['x1'])
+        self.tsAssertEqual(self.TS1, rhs_pre['x1'])
+
+    def testFilterWithSeriesRHS3(self):
+        lhs, rhs, rhs_pre = _filter_data(self.TS3, {'x1' : self.TS4})
+        exp_lhs = self.TS3[2]
+        exp_rhs = self.TS4[2]
+        exp_rhs_pre = self.TS4[1:]
+        self.tsAssertEqual(exp_lhs, lhs)
+        self.tsAssertEqual(exp_rhs, rhs['x1'])
+        self.tsAssertEqual(exp_rhs_pre, rhs_pre['x1'])
+
+    def testFilterWithDataFrameRHS(self):
+        lhs, rhs, _ = _filter_data(self.TS1, self.DF1)
+        exp_lhs = self.TS1[1:]
+        exp_rhs1 = self.TS2[1:3]
+        exp_rhs2 = self.TS4[1:3]
+        self.tsAssertEqual(exp_lhs, lhs)
+        self.tsAssertEqual(exp_rhs1, rhs['x1'])
+        self.tsAssertEqual(exp_rhs2, rhs['x2'])
+
+    def testFilterWithDictRHS(self):
+        lhs, rhs, _ = _filter_data(self.TS1, self.DICT1)
+        exp_lhs = self.TS1[1:]
+        exp_rhs1 = self.TS2[1:3]
+        exp_rhs2 = self.TS4[1:3]
+        self.tsAssertEqual(exp_lhs, lhs)
+        self.tsAssertEqual(exp_rhs1, rhs['x1'])
+        self.tsAssertEqual(exp_rhs2, rhs['x2'])
+
+    def tsAssertEqual(self, ts1, ts2):
+        self.assert_((ts1 == ts2).all())
+
+if __name__ == '__main__':
+    unittest.main()
diff --git a/pandas/util/__init__.py b/pandas/util/__init__.py
new file mode 100644
index 000000000..e69de29bb
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
new file mode 100644
index 000000000..438e259fa
--- /dev/null
+++ b/pandas/util/decorators.py
@@ -0,0 +1,222 @@
+"""
+Pierre G-M's caching decorators
+"""
+
+import warnings
+
+__all__ = ['resettable_cache','cache_readonly', 'cache_writable']
+
+#-------------------------------------------------------------------------------
+# Pierre G-M's caching decorators
+
+class CacheWriteWarning(UserWarning):
+    pass
+
+
+class ResettableCache(dict):
+    """
+    Dictionary whose elements mey depend one from another.
+
+    If entry `B` depends on entry `A`, changing the values of entry `A` will
+    reset the value of entry `B` to a default (None); deleteing entry `A` will
+    delete entry `B`.  The connections between entries are stored in a
+    `_resetdict` private attribute.
+
+    Parameters
+    ----------
+    reset : dictionary, optional
+        An optional dictionary, associated a sequence of entries to any key
+        of the object.
+    items : var, optional
+        An optional dictionary used to initialize the dictionary
+
+    Examples
+    --------
+    >>> reset = dict(a=('b',), b=('c',))
+    >>> cache = resettable_cache(a=0, b=1, c=2, reset=reset)
+    >>> assert_equal(cache, dict(a=0, b=1, c=2))
+
+    >>> print "Try resetting a"
+    >>> cache['a'] = 1
+    >>> assert_equal(cache, dict(a=1, b=None, c=None))
+    >>> cache['c'] = 2
+    >>> assert_equal(cache, dict(a=1, b=None, c=2))
+    >>> cache['b'] = 0
+    >>> assert_equal(cache, dict(a=1, b=0, c=None))
+
+    >>> print "Try deleting b"
+    >>> del(cache['a'])
+    >>> assert_equal(cache, {})
+    """
+
+    def __init__(self, reset=None, **items):
+        self._resetdict = reset or {}
+        dict.__init__(self, **items)
+
+    def __setitem__(self, key, value):
+        dict.__setitem__(self, key, value)
+        for mustreset in self._resetdict.get(key, []):
+            self[mustreset] = None
+
+    def __delitem__(self, key):
+        dict.__delitem__(self, key)
+        for mustreset in self._resetdict.get(key, []):
+            del(self[mustreset])
+
+resettable_cache = ResettableCache
+
+class CachedAttribute(object):
+
+    def __init__(self, func, cachename=None, resetlist=None):
+        self.fget = func
+        self.name = func.__name__
+        self.cachename = cachename or '_cache'
+        self.resetlist = resetlist or ()
+
+    def __get__(self, obj, type=None):
+        if obj is None:
+            return self.fget
+        # Get the cache or set a default one if needed
+        _cachename = self.cachename
+        _cache = getattr(obj, _cachename, None)
+        if _cache is None:
+            setattr(obj, _cachename, resettable_cache())
+            _cache = getattr(obj, _cachename)
+        # Get the name of the attribute to set and cache
+        name = self.name
+        _cachedval = _cache.get(name, None)
+#        print "[_cachedval=%s]" % _cachedval
+        if _cachedval is None:
+            # Call the "fget" function
+            _cachedval = self.fget(obj)
+            # Set the attribute in obj
+#            print "Setting %s in cache to %s" % (name, _cachedval)
+            try:
+                _cache[name] = _cachedval
+            except KeyError:
+                setattr(_cache, name, _cachedval)
+            # Update the reset list if needed (and possible)
+            resetlist = self.resetlist
+            if resetlist is not ():
+                try:
+                    _cache._resetdict[name] = self.resetlist
+                except AttributeError:
+                    pass
+#        else:
+#            print "Reading %s from cache (%s)" % (name, _cachedval)
+        return _cachedval
+
+    def __set__(self, obj, value):
+        errmsg = "The attribute '%s' cannot be overwritten" % self.name
+        warnings.warn(errmsg, CacheWriteWarning)
+
+class CachedWritableAttribute(CachedAttribute):
+    #
+    def __set__(self, obj, value):
+        _cache = getattr(obj, self.cachename)
+        name = self.name
+        try:
+            _cache[name] = value
+        except KeyError:
+            setattr(_cache, name, value)
+
+class _cache_readonly(object):
+    """
+    Decorator for CachedAttribute
+    """
+
+    def __init__(self, cachename=None, resetlist=None):
+        self.func = None
+        self.cachename = cachename
+        self.resetlist = resetlist or None
+
+    def __call__(self, func):
+        return CachedAttribute(func,
+                               cachename=self.cachename,
+                               resetlist=self.resetlist)
+cache_readonly = _cache_readonly()
+
+class cache_writable(_cache_readonly):
+    """
+    Decorator for CachedWritableAttribute
+    """
+    def __call__(self, func):
+        return CachedWritableAttribute(func,
+                                       cachename=self.cachename,
+                                       resetlist=self.resetlist)
+
+
+if __name__ == "__main__":
+### Tests resettable_cache ----------------------------------------------------
+
+    from numpy.testing import *
+
+    reset = dict(a=('b',), b=('c',))
+    cache = resettable_cache(a=0, b=1, c=2, reset=reset)
+    assert_equal(cache, dict(a=0, b=1, c=2))
+    #
+    print "Try resetting a"
+    cache['a'] = 1
+    assert_equal(cache, dict(a=1, b=None, c=None))
+    cache['c'] = 2
+    assert_equal(cache, dict(a=1, b=None, c=2))
+    cache['b'] = 0
+    assert_equal(cache, dict(a=1, b=0, c=None))
+    #
+    print "Try deleting b"
+    del(cache['a'])
+    assert_equal(cache, {})
+### ---------------------------------------------------------------------------
+
+
+    class Example(object):
+        #
+        def __init__(self):
+            self._cache = resettable_cache()
+            self.a = 0
+        #
+        @cache_readonly
+        def b(self):
+            return 1
+        @cache_writable(resetlist='d')
+        def c(self):
+            return 2
+        @cache_writable(resetlist=('e', 'f'))
+        def d(self):
+            return self.c + 1
+        #
+        @cache_readonly
+        def e(self):
+            return 4
+        @cache_readonly
+        def f(self):
+            return self.e + 1
+
+    ex = Example()
+    print "(attrs  : %s)" % str(ex.__dict__)
+    print "(cached : %s)" % str(ex._cache)
+    print "Try a   :", ex.a
+    print "Try accessing/setting a readonly attribute"
+    assert_equal(ex.__dict__, dict(a=0, _cache={}))
+    print "Try b #1:", ex.b
+    b = ex.b
+    assert_equal(b, 1)
+    assert_equal(ex.__dict__, dict(a=0, _cache=dict(b=1,)))
+#   assert_equal(ex.__dict__, dict(a=0, b=1, _cache=dict(b=1)))
+    ex.b = -1
+    print "Try dict", ex.__dict__
+    assert_equal(ex._cache, dict(b=1,))
+    #
+    print "Try accessing/resetting a cachewritable attribute"
+    c = ex.c
+    assert_equal(c, 2)
+    assert_equal(ex._cache, dict(b=1, c=2))
+    d = ex.d
+    assert_equal(d, 3)
+    assert_equal(ex._cache, dict(b=1, c=2, d=3))
+    ex.c = 0
+    assert_equal(ex._cache, dict(b=1, c=0, d=None, e=None, f=None))
+    d = ex.d
+    assert_equal(ex._cache, dict(b=1, c=0, d=1, e=None, f=None))
+    ex.d = 5
+    assert_equal(ex._cache, dict(b=1, c=0, d=5, e=None, f=None))
