commit f74c5201f4954f1eb91bb66e5a6c5254bbfe29f3
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Dec 29 22:16:46 2011 -0500

    TST: refactoring and consolidating join /merge unit tests

diff --git a/pandas/__init__.py b/pandas/__init__.py
index 11c8eea2f..3073742ae 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -30,4 +30,4 @@ from pandas.io.pytables import HDFStore
 from pandas.util.testing import debug
 
 from pandas.tools.pivot import pivot_table
-
+from pandas.tools.merge import merge
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index d99ee24d4..4a5c81fb6 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1309,7 +1309,7 @@ def generate_groups(data, label_list, shape, axis=0, factory=lambda x: x):
         na_mask |= arr == -1
     group_index[na_mask] = -1
     indexer = lib.groupsort_indexer(group_index.astype('i4'),
-                                    np.prod(shape))
+                                    np.prod(shape))[0]
     group_index = group_index.take(indexer)
 
     if isinstance(data, BlockManager):
@@ -1363,7 +1363,7 @@ def _aggregate_series_fast(obj, func, group_index, ngroups):
 
     # avoids object / Series creation overhead
     dummy = obj[:0]
-    indexer = lib.groupsort_indexer(group_index, ngroups)
+    indexer = lib.groupsort_indexer(group_index, ngroups)[0]
     obj = obj.take(indexer)
     group_index = group_index.take(indexer)
     grouper = lib.SeriesGrouper(obj, func, group_index, ngroups,
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 2d455bb7a..5dc7aa087 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -261,6 +261,7 @@ def get_unique_labels(ndarray[object] values, dict idMap):
 
     return fillVec
 
+@cython.boundscheck(False)
 @cython.wraparound(False)
 def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
     cdef:
@@ -285,8 +286,7 @@ def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
         result[where[label]] = i
         where[label] += 1
 
-    return result
-
+    return result, counts
 
 
 # TODO: aggregate multiple columns in single pass
diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index eb2acbc14..c2ca5cc93 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -510,9 +510,19 @@ cdef class Factorizer:
     def get_count(self):
         return self.count
 
-    def factorize(self, ndarray[object] values):
+    def factorize(self, ndarray[object] values, sort=False):
         labels, counts = self.table.get_labels(values, self.uniques,
                                                self.count)
+
+        # sort on
+        if sort:
+            sorter = list_to_object_array(self.uniques).argsort()
+            reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+            reverse_indexer.put(sorter, np.arange(len(sorter)))
+
+            labels = reverse_indexer.take(labels)
+            counts = counts.take(sorter)
+
         self.count = len(counts)
         return labels, counts
 
diff --git a/pandas/src/join.pyx b/pandas/src/join.pyx
index 0c0f13fbc..d4a9c9ac1 100644
--- a/pandas/src/join.pyx
+++ b/pandas/src/join.pyx
@@ -170,30 +170,3 @@ def _get_result_indexer(sorter, indexer):
     res = sorter.take(indexer)
     np.putmask(res, indexer == -1, -1)
     return res
-
-@cython.boundscheck(False)
-@cython.wraparound(False)
-def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
-    cdef:
-        Py_ssize_t i, loc, label, n
-        ndarray[int32_t] counts, where, result
-
-    # count group sizes, location 0 for NA
-    counts = np.zeros(ngroups + 1, dtype='i4')
-    n = len(index)
-    for i from 0 <= i < n:
-        counts[index[i] + 1] += 1
-
-    # mark the start of each contiguous group of like-indexed data
-    where = np.zeros(ngroups + 1, dtype='i4')
-    for i from 1 <= i < ngroups + 1:
-        where[i] = where[i - 1] + counts[i - 1]
-
-    # this is our indexer
-    result = np.zeros(n, dtype='i4')
-    for i from 0 <= i < n:
-        label = index[i] + 1
-        result[where[label]] = i
-        where[label] += 1
-
-    return result, counts
diff --git a/pandas/src/sandbox.pyx b/pandas/src/sandbox.pyx
index 96d827a95..5d7cc8167 100644
--- a/pandas/src/sandbox.pyx
+++ b/pandas/src/sandbox.pyx
@@ -173,6 +173,3 @@ def roll_median(ndarray[float64_t] arg, int win, int minp):
     skiplist_destroy(sl)
 
     return output
-
-include "hashtable.pyx"
-include "join.pyx"
diff --git a/pandas/src/tseries.pyx b/pandas/src/tseries.pyx
index 04369c8ef..5e8ad5c9a 100644
--- a/pandas/src/tseries.pyx
+++ b/pandas/src/tseries.pyx
@@ -481,3 +481,5 @@ include "stats.pyx"
 include "properties.pyx"
 include "inference.pyx"
 include "internals.pyx"
+include "hashtable.pyx"
+include "join.pyx"
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 3047a2e9f..04e164114 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -4063,235 +4063,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         exp = Y['g'].sum()
         self.assert_(isnull(Y['g']['c']))
 
-class TestDataFrameJoin(unittest.TestCase):
-
-    def setUp(self):
-        index, data = tm.getMixedTypeDict()
-        self.target = DataFrame(data, index=index)
-
-        # Join on string value
-        self.source = DataFrame({'MergedA' : data['A'], 'MergedD' : data['D']},
-                                index=data['C'])
-
-    def test_join_on(self):
-        target = self.target
-        source = self.source
-
-        merged = target.join(source, on='C')
-        self.assert_(np.array_equal(merged['MergedA'], target['A']))
-        self.assert_(np.array_equal(merged['MergedD'], target['D']))
-
-        # join with duplicates (fix regression from DataFrame/Matrix merge)
-        df = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c']})
-        df2 = DataFrame({'value' : [0, 1, 2]}, index=['a', 'b', 'c'])
-        joined = df.join(df2, on='key')
-        expected = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c'],
-                              'value' : [0, 0, 1, 1, 2]})
-        assert_frame_equal(joined, expected)
-
-        # Test when some are missing
-        df_a = DataFrame([[1], [2], [3]], index=['a', 'b', 'c'],
-                         columns=['one'])
-        df_b = DataFrame([['foo'], ['bar']], index=[1, 2],
-                         columns=['two'])
-        df_c = DataFrame([[1], [2]], index=[1, 2],
-                         columns=['three'])
-        joined = df_a.join(df_b, on='one')
-        joined = joined.join(df_c, on='one')
-        self.assert_(np.isnan(joined['two']['c']))
-        self.assert_(np.isnan(joined['three']['c']))
-
-        # merge column not p resent
-        self.assertRaises(Exception, target.join, source, on='E')
-
-        # overlap
-        source_copy = source.copy()
-        source_copy['A'] = 0
-        self.assertRaises(Exception, target.join, source_copy, on='A')
-
-    def test_join_on_pass_vector(self):
-        expected = self.target.join(self.source, on='C')
-        del expected['C']
-
-        join_col = self.target.pop('C')
-        result = self.target.join(self.source, on=join_col)
-        assert_frame_equal(result, expected)
-
-    def test_join_with_len0(self):
-        # nothing to merge
-        merged = self.target.join(self.source.reindex([]), on='C')
-        for col in self.source:
-            self.assert_(col in merged)
-            self.assert_(merged[col].isnull().all())
-
-        merged2 = self.target.join(self.source.reindex([]), on='C',
-                                   how='inner')
-        self.assert_(merged2.columns.equals(merged.columns))
-        self.assertEqual(len(merged2), 0)
-
-    def test_join_on_inner(self):
-        df = DataFrame({'key' : ['a', 'a', 'd', 'b', 'b', 'c']})
-        df2 = DataFrame({'value' : [0, 1]}, index=['a', 'b'])
-
-        joined = df.join(df2, on='key', how='inner')
-
-        expected = df.join(df2, on='key')
-        expected = expected[expected['value'].notnull()]
-        self.assert_(np.array_equal(joined['key'], expected['key']))
-        self.assert_(np.array_equal(joined['value'], expected['value']))
-        self.assert_(joined.index.equals(expected.index))
-
-    def test_join_on_singlekey_list(self):
-        df = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c']})
-        df2 = DataFrame({'value' : [0, 1, 2]}, index=['a', 'b', 'c'])
-
-        # corner cases
-        joined = df.join(df2, on=['key'])
-        expected = df.join(df2, on='key')
-
-        assert_frame_equal(joined, expected)
-
-    def test_join_on_multikey(self):
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
-                                   ['one', 'two', 'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
-                           names=['first', 'second'])
-        to_join = DataFrame(np.random.randn(10, 3), index=index,
-                            columns=['j_one', 'j_two', 'j_three'])
-
-        # a little relevant example with NAs
-        key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux',
-                'qux', 'snap']
-        key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',
-                'three', 'one']
-
-        data = np.random.randn(len(key1))
-        data = DataFrame({'key1' : key1, 'key2' : key2,
-                          'data' : data})
-
-        joined = data.join(to_join, on=['key1', 'key2'])
-
-        join_key = Index(zip(key1, key2))
-        indexer = to_join.index.get_indexer(join_key)
-        ex_values = to_join.values.take(indexer, axis=0)
-        ex_values[indexer == -1] = np.nan
-        expected = data.join(DataFrame(ex_values, columns=to_join.columns))
-
-        # TODO: columns aren't in the same order yet
-        assert_frame_equal(joined, expected.ix[:, joined.columns])
-
-    def test_join_on_series(self):
-        result = self.target.join(self.source['MergedA'], on='C')
-        expected = self.target.join(self.source[['MergedA']], on='C')
-        assert_frame_equal(result, expected)
-
-    def test_join_index_mixed(self):
-
-        df1 = DataFrame({'A' : 1., 'B' : 2, 'C' : 'foo', 'D' : True},
-                        index=np.arange(10),
-                        columns=['A', 'B', 'C', 'D'])
-        self.assert_(df1['B'].dtype == np.int64)
-        self.assert_(df1['D'].dtype == np.bool_)
-
-        df2 = DataFrame({'A' : 1., 'B' : 2, 'C' : 'foo', 'D' : True},
-                        index=np.arange(0, 10, 2),
-                        columns=['A', 'B', 'C', 'D'])
-
-        # overlap
-        joined = df1.join(df2, lsuffix='_one', rsuffix='_two')
-        expected_columns = ['A_one', 'B_one', 'C_one', 'D_one',
-                            'A_two', 'B_two', 'C_two', 'D_two']
-        df1.columns = expected_columns[:4]
-        df2.columns = expected_columns[4:]
-        expected = _join_by_hand(df1, df2)
-        assert_frame_equal(joined, expected)
-
-        # no overlapping blocks
-        df1 = DataFrame(index=np.arange(10))
-        df1['bool'] = True
-        df1['string'] = 'foo'
-
-        df2 = DataFrame(index=np.arange(5, 15))
-        df2['int'] = 1
-        df2['float'] = 1.
-
-        for kind in JOIN_TYPES:
-            joined = df1.join(df2, how=kind)
-            expected = _join_by_hand(df1, df2, how=kind)
-            assert_frame_equal(joined, expected)
-
-            joined = df2.join(df1, how=kind)
-            expected = _join_by_hand(df2, df1, how=kind)
-            assert_frame_equal(joined, expected)
-
-    def test_join_empty_bug(self):
-        # generated an exception in 0.4.3
-        x = DataFrame()
-        x.join(DataFrame([3], index=[0], columns=['A']), how='outer')
-
-    def test_join_unconsolidated(self):
-        # GH #331
-        a = DataFrame(randn(30,2), columns=['a','b'])
-        c = Series(randn(30))
-        a['c'] = c
-        d = DataFrame(randn(30,1), columns=['d'])
-
-        # it works!
-        a.join(d)
-        d.join(a)
-
-    def test_join_multiindex(self):
-        index1 = MultiIndex.from_arrays([['a','a','a','b','b','b'],
-                                         [1,2,3,1,2,3]],
-                                        names=['first', 'second'])
-
-        index2 = MultiIndex.from_arrays([['b','b','b','c','c','c'],
-                                         [1,2,3,1,2,3]],
-                                        names=['first', 'second'])
-
-        df1 = DataFrame(data=np.random.randn(6), index=index1,
-                        columns=['var X'])
-        df2 = DataFrame(data=np.random.randn(6), index=index2,
-                        columns=['var Y'])
-
-        df1 = df1.sortlevel(0)
-        df2 = df2.sortlevel(0)
-
-        joined = df1.join(df2, how='outer')
-        ex_index = index1.get_tuple_index() + index2.get_tuple_index()
-        expected = df1.reindex(ex_index).join(df2.reindex(ex_index))
-        assert_frame_equal(joined, expected)
-        self.assertEqual(joined.index.names, index1.names)
-
-        df1 = df1.sortlevel(1)
-        df2 = df2.sortlevel(1)
-
-        joined = df1.join(df2, how='outer').sortlevel(0)
-        ex_index = index1.get_tuple_index() + index2.get_tuple_index()
-        expected = df1.reindex(ex_index).join(df2.reindex(ex_index))
-        assert_frame_equal(joined, expected)
-        self.assertEqual(joined.index.names, index1.names)
-
-    def test_join_float64_float32(self):
-        a = DataFrame(randn(10,2), columns=['a','b'])
-        b = DataFrame(randn(10,1), columns=['c']).astype(np.float32)
-        joined = a.join(b)
-        expected = a.join(b.astype('f8'))
-        assert_frame_equal(joined, expected)
-
-def _join_by_hand(a, b, how='left'):
-    join_index = a.index.join(b.index, how=how)
-
-    a_re = a.reindex(join_index)
-    b_re = b.reindex(join_index)
-
-    result_columns = a.columns.append(b.columns)
-
-    for col, s in b_re.iteritems():
-        a_re[col] = s
-    return a_re.reindex(columns=result_columns)
-
 if __name__ == '__main__':
     # unittest.main()
     import nose
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 59297a132..c068b90e0 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -135,7 +135,7 @@ def test_groupsort_indexer():
     a = np.random.randint(0, 1000, 100).astype('i4')
     b = np.random.randint(0, 1000, 100).astype('i4')
 
-    result = lib.groupsort_indexer(a, 1000)
+    result = lib.groupsort_indexer(a, 1000)[0]
 
     # need to use a stable sort
     expected = np.argsort(a, kind='mergesort')
@@ -143,7 +143,7 @@ def test_groupsort_indexer():
 
     # compare with lexsort
     key = a * 1000 + b
-    result = lib.groupsort_indexer(key, 1000000)
+    result = lib.groupsort_indexer(key, 1000000)[0]
     expected = np.lexsort((b, a))
     assert(np.array_equal(result, expected))
 
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 533857dcb..d994265d9 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -10,7 +10,6 @@ from pandas.core.internals import _JoinOperation
 import pandas.core.common as com
 
 import pandas._tseries as lib
-from pandas._sandbox import Factorizer
 
 def merge(left, right, how='left', on=None, left_on=None, right_on=None,
           left_index=False, right_index=False, sort=True,
@@ -31,26 +30,23 @@ def merge(left, right, how='left', on=None, left_on=None, right_on=None,
         * outer: use union of keys from both frames (SQL: full outer join)
         * inner: use intersection of keys from both frames (SQL: inner join)
     on : label or list
-
+        Field names to join on. Must be found in both DataFrames
     left_on : label or list
-
+        Field names to join on in left DataFrame
     right_on : label or list
-
+        Field names to join on in right DataFrame
     left_index : boolean, default True
-
+        Use the index from the left DataFrame as the join key
     right_index : boolean, default True
-
+        Use the index from the right DataFrame as the join key
     sort : boolean, default True
-
+        Sort the join keys lexicographically in the result DataFrame
     suffixes : 2-length sequence (tuple, list, ...)
         Suffix to apply to overlapping column names in the left and right
         side, respectively
     copy : boolean, default True
         If False, do not copy data unnecessarily
 
-    Examples
-    --------
-
     Returns
     -------
     merged : DataFrame
@@ -235,7 +231,7 @@ def _get_group_keys(left_keys, right_keys, sort=True):
     group_sizes = []
 
     for lk, rk in zip(left_keys, right_keys):
-        rizer = Factorizer(max(len(lk), len(rk)))
+        rizer = lib.Factorizer(max(len(lk), len(rk)))
 
         llab, _ = rizer.factorize(lk.astype('O'))
         rlab, _ = rizer.factorize(rk.astype('O'))
@@ -262,20 +258,18 @@ def _get_group_keys(left_keys, right_keys, sort=True):
 
     return left_group_key, right_group_key, max_groups
 
-import pandas._sandbox as sbx
-
 def _maybe_make_list(obj):
     if obj is not None and not isinstance(obj, (tuple, list)):
         return [obj]
     return obj
 
 def _right_outer_join(x, y, max_groups):
-    right_indexer, left_indexer = sbx.left_outer_join(y, x, max_groups)
+    right_indexer, left_indexer = lib.left_outer_join(y, x, max_groups)
     return left_indexer, right_indexer
 
 _join_functions = {
-    'inner' : sbx.inner_join,
-    'left' : sbx.left_outer_join,
+    'inner' : lib.inner_join,
+    'left' : lib.left_outer_join,
     'right' : _right_outer_join,
-    'outer' : sbx.full_outer_join,
+    'outer' : lib.full_outer_join,
 }
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 0821378ee..385621029 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -1,17 +1,22 @@
 import nose
 import unittest
 
+from numpy.random import randn
 import numpy as np
 import random
 
 from pandas import *
 from pandas.tools.merge import merge
-import pandas._sandbox as sbx
+from pandas.util.testing import assert_frame_equal, assert_series_equal
+import pandas._tseries as lib
+import pandas.util.testing as tm
 
 a_ = np.array
 
 N = 50
 NGROUPS = 8
+JOIN_TYPES = ['inner', 'outer', 'left', 'right']
+
 
 def get_test_data(ngroups=NGROUPS, n=N):
     unique_groups = range(ngroups)
@@ -46,7 +51,7 @@ class TestMerge(unittest.TestCase):
         right = a_([1, 1, 0, 4, 2, 2, 1], dtype='i4')
         max_group = 5
 
-        ls, rs = sbx.left_outer_join(left, right, max_group)
+        ls, rs = lib.left_outer_join(left, right, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
@@ -70,7 +75,7 @@ class TestMerge(unittest.TestCase):
         right = a_([1, 1, 0, 4, 2, 2, 1], dtype='i4')
         max_group = 5
 
-        rs, ls  = sbx.left_outer_join(right, left, max_group)
+        rs, ls  = lib.left_outer_join(right, left, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
@@ -92,13 +97,11 @@ class TestMerge(unittest.TestCase):
         self.assert_(np.array_equal(rs, exp_rs))
 
     def test_cython_inner_join(self):
-        raise nose.SkipTest
-
         left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype='i4')
         right = a_([1, 1, 0, 4, 2, 2, 1, 4], dtype='i4')
         max_group = 5
 
-        ls, rs = sbx.inner_join(left, right, max_group)
+        ls, rs = lib.inner_join(left, right, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
@@ -153,10 +156,16 @@ class TestMerge(unittest.TestCase):
                     how='inner')
 
     def test_handle_overlap(self):
-        pass
+        joined = merge(self.df, self.df2, on='key2',
+                       suffixes=['.foo', '.bar'])
+
+        self.assert_('key1.foo' in joined)
+        self.assert_('key1.bar' in joined)
 
     def test_merge_common(self):
-        pass
+        joined = merge(self.df, self.df2)
+        exp = merge(self.df, self.df2, on=['key1', 'key2'])
+        tm.assert_frame_equal(joined, exp)
 
     def test_merge_index(self):
         pass
@@ -229,6 +238,237 @@ def _assert_all_na(join_chunk, source_columns, join_col):
             continue
         assert(join_chunk[c].isnull().all())
 
+
+class TestDataFrameJoin(unittest.TestCase):
+
+    def setUp(self):
+        index, data = tm.getMixedTypeDict()
+        self.target = DataFrame(data, index=index)
+
+        # Join on string value
+        self.source = DataFrame({'MergedA' : data['A'], 'MergedD' : data['D']},
+                                index=data['C'])
+
+    def test_join_on(self):
+        target = self.target
+        source = self.source
+
+        merged = target.join(source, on='C')
+        self.assert_(np.array_equal(merged['MergedA'], target['A']))
+        self.assert_(np.array_equal(merged['MergedD'], target['D']))
+
+        # join with duplicates (fix regression from DataFrame/Matrix merge)
+        df = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c']})
+        df2 = DataFrame({'value' : [0, 1, 2]}, index=['a', 'b', 'c'])
+        joined = df.join(df2, on='key')
+        expected = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c'],
+                              'value' : [0, 0, 1, 1, 2]})
+        assert_frame_equal(joined, expected)
+
+        # Test when some are missing
+        df_a = DataFrame([[1], [2], [3]], index=['a', 'b', 'c'],
+                         columns=['one'])
+        df_b = DataFrame([['foo'], ['bar']], index=[1, 2],
+                         columns=['two'])
+        df_c = DataFrame([[1], [2]], index=[1, 2],
+                         columns=['three'])
+        joined = df_a.join(df_b, on='one')
+        joined = joined.join(df_c, on='one')
+        self.assert_(np.isnan(joined['two']['c']))
+        self.assert_(np.isnan(joined['three']['c']))
+
+        # merge column not p resent
+        self.assertRaises(Exception, target.join, source, on='E')
+
+        # overlap
+        source_copy = source.copy()
+        source_copy['A'] = 0
+        self.assertRaises(Exception, target.join, source_copy, on='A')
+
+    def test_join_on_pass_vector(self):
+        expected = self.target.join(self.source, on='C')
+        del expected['C']
+
+        join_col = self.target.pop('C')
+        result = self.target.join(self.source, on=join_col)
+        assert_frame_equal(result, expected)
+
+    def test_join_with_len0(self):
+        # nothing to merge
+        merged = self.target.join(self.source.reindex([]), on='C')
+        for col in self.source:
+            self.assert_(col in merged)
+            self.assert_(merged[col].isnull().all())
+
+        merged2 = self.target.join(self.source.reindex([]), on='C',
+                                   how='inner')
+        self.assert_(merged2.columns.equals(merged.columns))
+        self.assertEqual(len(merged2), 0)
+
+    def test_join_on_inner(self):
+        df = DataFrame({'key' : ['a', 'a', 'd', 'b', 'b', 'c']})
+        df2 = DataFrame({'value' : [0, 1]}, index=['a', 'b'])
+
+        joined = df.join(df2, on='key', how='inner')
+
+        expected = df.join(df2, on='key')
+        expected = expected[expected['value'].notnull()]
+        self.assert_(np.array_equal(joined['key'], expected['key']))
+        self.assert_(np.array_equal(joined['value'], expected['value']))
+        self.assert_(joined.index.equals(expected.index))
+
+    def test_join_on_singlekey_list(self):
+        df = DataFrame({'key' : ['a', 'a', 'b', 'b', 'c']})
+        df2 = DataFrame({'value' : [0, 1, 2]}, index=['a', 'b', 'c'])
+
+        # corner cases
+        joined = df.join(df2, on=['key'])
+        expected = df.join(df2, on='key')
+
+        assert_frame_equal(joined, expected)
+
+    def test_join_on_multikey(self):
+        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
+                                   ['one', 'two', 'three']],
+                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
+                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
+                           names=['first', 'second'])
+        to_join = DataFrame(np.random.randn(10, 3), index=index,
+                            columns=['j_one', 'j_two', 'j_three'])
+
+        # a little relevant example with NAs
+        key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux',
+                'qux', 'snap']
+        key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',
+                'three', 'one']
+
+        data = np.random.randn(len(key1))
+        data = DataFrame({'key1' : key1, 'key2' : key2,
+                          'data' : data})
+
+        joined = data.join(to_join, on=['key1', 'key2'])
+
+        join_key = Index(zip(key1, key2))
+        indexer = to_join.index.get_indexer(join_key)
+        ex_values = to_join.values.take(indexer, axis=0)
+        ex_values[indexer == -1] = np.nan
+        expected = data.join(DataFrame(ex_values, columns=to_join.columns))
+
+        # TODO: columns aren't in the same order yet
+        assert_frame_equal(joined, expected.ix[:, joined.columns])
+
+    def test_join_on_series(self):
+        result = self.target.join(self.source['MergedA'], on='C')
+        expected = self.target.join(self.source[['MergedA']], on='C')
+        assert_frame_equal(result, expected)
+
+    def test_join_index_mixed(self):
+
+        df1 = DataFrame({'A' : 1., 'B' : 2, 'C' : 'foo', 'D' : True},
+                        index=np.arange(10),
+                        columns=['A', 'B', 'C', 'D'])
+        self.assert_(df1['B'].dtype == np.int64)
+        self.assert_(df1['D'].dtype == np.bool_)
+
+        df2 = DataFrame({'A' : 1., 'B' : 2, 'C' : 'foo', 'D' : True},
+                        index=np.arange(0, 10, 2),
+                        columns=['A', 'B', 'C', 'D'])
+
+        # overlap
+        joined = df1.join(df2, lsuffix='_one', rsuffix='_two')
+        expected_columns = ['A_one', 'B_one', 'C_one', 'D_one',
+                            'A_two', 'B_two', 'C_two', 'D_two']
+        df1.columns = expected_columns[:4]
+        df2.columns = expected_columns[4:]
+        expected = _join_by_hand(df1, df2)
+        assert_frame_equal(joined, expected)
+
+        # no overlapping blocks
+        df1 = DataFrame(index=np.arange(10))
+        df1['bool'] = True
+        df1['string'] = 'foo'
+
+        df2 = DataFrame(index=np.arange(5, 15))
+        df2['int'] = 1
+        df2['float'] = 1.
+
+        for kind in JOIN_TYPES:
+            joined = df1.join(df2, how=kind)
+            expected = _join_by_hand(df1, df2, how=kind)
+            assert_frame_equal(joined, expected)
+
+            joined = df2.join(df1, how=kind)
+            expected = _join_by_hand(df2, df1, how=kind)
+            assert_frame_equal(joined, expected)
+
+    def test_join_empty_bug(self):
+        # generated an exception in 0.4.3
+        x = DataFrame()
+        x.join(DataFrame([3], index=[0], columns=['A']), how='outer')
+
+    def test_join_unconsolidated(self):
+        # GH #331
+        a = DataFrame(randn(30,2), columns=['a','b'])
+        c = Series(randn(30))
+        a['c'] = c
+        d = DataFrame(randn(30,1), columns=['d'])
+
+        # it works!
+        a.join(d)
+        d.join(a)
+
+    def test_join_multiindex(self):
+        index1 = MultiIndex.from_arrays([['a','a','a','b','b','b'],
+                                         [1,2,3,1,2,3]],
+                                        names=['first', 'second'])
+
+        index2 = MultiIndex.from_arrays([['b','b','b','c','c','c'],
+                                         [1,2,3,1,2,3]],
+                                        names=['first', 'second'])
+
+        df1 = DataFrame(data=np.random.randn(6), index=index1,
+                        columns=['var X'])
+        df2 = DataFrame(data=np.random.randn(6), index=index2,
+                        columns=['var Y'])
+
+        df1 = df1.sortlevel(0)
+        df2 = df2.sortlevel(0)
+
+        joined = df1.join(df2, how='outer')
+        ex_index = index1.get_tuple_index() + index2.get_tuple_index()
+        expected = df1.reindex(ex_index).join(df2.reindex(ex_index))
+        assert_frame_equal(joined, expected)
+        self.assertEqual(joined.index.names, index1.names)
+
+        df1 = df1.sortlevel(1)
+        df2 = df2.sortlevel(1)
+
+        joined = df1.join(df2, how='outer').sortlevel(0)
+        ex_index = index1.get_tuple_index() + index2.get_tuple_index()
+        expected = df1.reindex(ex_index).join(df2.reindex(ex_index))
+        assert_frame_equal(joined, expected)
+        self.assertEqual(joined.index.names, index1.names)
+
+    def test_join_float64_float32(self):
+        a = DataFrame(randn(10,2), columns=['a','b'])
+        b = DataFrame(randn(10,1), columns=['c']).astype(np.float32)
+        joined = a.join(b)
+        expected = a.join(b.astype('f8'))
+        assert_frame_equal(joined, expected)
+
+def _join_by_hand(a, b, how='left'):
+    join_index = a.index.join(b.index, how=how)
+
+    a_re = a.reindex(join_index)
+    b_re = b.reindex(join_index)
+
+    result_columns = a.columns.append(b.columns)
+
+    for col, s in b_re.iteritems():
+        a_re[col] = s
+    return a_re.reindex(columns=result_columns)
+
+
 if __name__ == '__main__':
     import nose
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
diff --git a/setup.py b/setup.py
index 3191c3c50..710e149f3 100755
--- a/setup.py
+++ b/setup.py
@@ -294,7 +294,8 @@ else:
 
 tseries_depends = ['reindex', 'groupby', 'skiplist', 'moments',
                    'generated', 'parsing', 'reduce', 'stats',
-                   'inference', 'properties', 'internals']
+                   'inference', 'properties', 'internals',
+                   'hashtable', 'join']
 def srcpath(name=None, suffix='.pyx', subdir='src'):
     return pjoin('pandas', subdir, name+suffix)
 
