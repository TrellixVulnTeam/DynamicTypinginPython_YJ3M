commit 684e9dd448b183506b6d68b8efa18bd1fddf998c
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Sep 18 17:09:19 2012 -0400

    BUG: fix indexing issue with duplicate dates, close #1821

diff --git a/RELEASE.rst b/RELEASE.rst
index 1a7209ce4..2cbdfee26 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -195,6 +195,8 @@ pandas 0.9.0
   - Fix DataFrame.apply with axis=1 on a non-unique index (#1878)
   - Proper handling of Index subclasses in pandas.unique (#1759)
   - Set index names in DataFrame.from_records (#1744)
+  - Fix time series indexing error with duplicates, under and over hash table
+    size cutoff (#1821)
 
 pandas 0.8.1
 ============
diff --git a/pandas/src/engines.pyx b/pandas/src/engines.pyx
index a31566aa3..ca0a91074 100644
--- a/pandas/src/engines.pyx
+++ b/pandas/src/engines.pyx
@@ -416,6 +416,7 @@ cdef class DatetimeEngine(Int64Engine):
 
         if self.over_size_threshold and self.is_monotonic:
             if not self.is_unique:
+                val = _to_i8(val)
                 return self._get_loc_duplicates(val)
             values = self._get_index_values()
             conv = _to_i8(val)
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 38c90c1a3..e6694fdbd 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -100,6 +100,45 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
         expected = self.dups.groupby(self.dups.index).mean()
         assert_series_equal(result, expected)
 
+    def test_indexing_over_size_cutoff(self):
+        import datetime
+        # #1821
+
+        old_cutoff = lib._SIZE_CUTOFF
+        try:
+            lib._SIZE_CUTOFF = 1000
+
+            # create large list of non periodic datetime
+            dates = []
+            sec = datetime.timedelta(seconds=1)
+            half_sec = sec / 2
+            d = datetime.datetime(2011, 12, 5, 20, 30)
+            n = 1100
+            for i in range(n):
+                dates.append(d)
+                dates.append(d + sec)
+                dates.append(d + sec + half_sec)
+                dates.append(d + sec + sec + half_sec)
+                d += 3 * sec
+
+            # duplicate some values in the list
+            duplicate_positions = np.random.randint(0, len(dates) - 1, 20)
+            for p in duplicate_positions:
+                dates[p + 1] = dates[p]
+
+            df = DataFrame(np.random.randn(len(dates), 4),
+                           index=dates,
+                           columns=list('ABCD'))
+
+            pos = n * 3
+            timestamp = df.index[pos]
+            self.assert_(timestamp in df.index)
+
+            # it works!
+            df.ix[timestamp]
+            self.assert_(len(df.ix[[timestamp]]) > 0)
+        finally:
+            lib._SIZE_CUTOFF = old_cutoff
 
 def assert_range_equal(left, right):
     assert(left.equals(right))
