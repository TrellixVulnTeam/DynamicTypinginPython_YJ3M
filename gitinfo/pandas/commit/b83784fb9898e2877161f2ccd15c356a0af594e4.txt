commit b83784fb9898e2877161f2ccd15c356a0af594e4
Author: Jeffrey Tratner <jeffrey.tratner@gmail.com>
Date:   Sat Jul 27 21:52:33 2013 -0400

    CLN/ENH: Add list versions of iterator methods.
    
    py3compat now has lrange, lzip, lmap, lreduce and lfilter, which work
    like the python builtins and produce lists (to make it more clear where
    looking for iterators vs. containers).

diff --git a/bench/alignment.py b/bench/alignment.py
index a5ffe9614..1f32064db 100644
--- a/bench/alignment.py
+++ b/bench/alignment.py
@@ -1,5 +1,5 @@
 # Setup
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import numpy as np
 import pandas
 import la
@@ -7,8 +7,8 @@ N = 1000
 K = 50
 arr1 = np.random.randn(N, K)
 arr2 = np.random.randn(N, K)
-idx1 = list(range(N))
-idx2 = list(range(K))
+idx1 = lrange(N)
+idx2 = lrange(K)
 
 # pandas
 dma1 = pandas.DataFrame(arr1, idx1, idx2)
diff --git a/bench/bench_merge.py b/bench/bench_merge.py
index 7820c7792..c4f595eb0 100644
--- a/bench/bench_merge.py
+++ b/bench/bench_merge.py
@@ -1,6 +1,6 @@
 from pandas import *
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import random
 
 N = 10000
@@ -8,7 +8,7 @@ ngroups = 10
 
 
 def get_test_data(ngroups=100, n=N):
-    unique_groups = list(range(ngroups))
+    unique_groups = lrange(ngroups)
     arr = np.asarray(np.tile(unique_groups, n / ngroups), dtype=object)
 
     if len(arr) < n:
@@ -66,7 +66,7 @@ results.columns = ['dont_sort', 'sort']
 
 
 # R results
-from pandas.util.py3compat import StringIO
+from pandas.util.py3compat import StringIO, lrange
 # many to one
 r_results = read_table(StringIO("""      base::merge   plyr data.table
 inner      0.2475 0.1183     0.1100
@@ -94,7 +94,7 @@ nosort_results['Ratio'] = nosort_results['R'] / nosort_results['pandas']
 
 # many to many
 
-from pandas.util.py3compat import StringIO
+from pandas.util.py3compat import StringIO, lrange
 # many to one
 r_results = read_table(StringIO("""base::merge   plyr data.table
 inner      0.4610 0.1276     0.1269
diff --git a/bench/bench_merge_sqlite.py b/bench/bench_merge_sqlite.py
index e15a482f3..cc2e31971 100644
--- a/bench/bench_merge_sqlite.py
+++ b/bench/bench_merge_sqlite.py
@@ -4,8 +4,7 @@ import gc
 import time
 from pandas import DataFrame
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, zip
 import random
 
 N = 10000
diff --git a/bench/bench_take_indexing.py b/bench/bench_take_indexing.py
index b6a7b04eb..51a8e6441 100644
--- a/bench/bench_take_indexing.py
+++ b/bench/bench_take_indexing.py
@@ -6,7 +6,7 @@ import pandas._tseries as lib
 
 from pandas import DataFrame
 import timeit
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 setup = """
 from pandas import Series
diff --git a/bench/bench_unique.py b/bench/bench_unique.py
index 8a2463063..8ede875b2 100644
--- a/bench/bench_unique.py
+++ b/bench/bench_unique.py
@@ -2,7 +2,7 @@ from __future__ import print_function
 from pandas import *
 from pandas.util.testing import rands
 from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import zip
 import pandas._tseries as lib
 import numpy as np
 import matplotlib.pyplot as plt
diff --git a/bench/better_unique.py b/bench/better_unique.py
index f8881ecd7..f1d8115b1 100644
--- a/bench/better_unique.py
+++ b/bench/better_unique.py
@@ -1,7 +1,7 @@
 from __future__ import print_function
 from pandas import DataFrame
 from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import zip
 import timeit
 
 setup = """
diff --git a/bench/serialize.py b/bench/serialize.py
index 9c0ba8420..bc8376223 100644
--- a/bench/serialize.py
+++ b/bench/serialize.py
@@ -1,5 +1,5 @@
 from __future__ import print_function
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import time
 import os
 import numpy as np
@@ -22,7 +22,7 @@ def roundtrip_archive(N, iterations=10):
     # Create data
     arr = np.random.randn(N, N)
     lar = la.larry(arr)
-    dma = pandas.DataFrame(arr, list(range(N)), list(range(N)))
+    dma = pandas.DataFrame(arr, lrange(N), lrange(N))
 
     # filenames
     filename_numpy = '/Users/wesm/tmp/numpy.npz'
diff --git a/bench/test.py b/bench/test.py
index 9d47c091b..3008fc67a 100644
--- a/bench/test.py
+++ b/bench/test.py
@@ -3,7 +3,7 @@ import numpy as np
 import itertools
 import collections
 import scipy.ndimage as ndi
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 N = 10000
 
diff --git a/doc/sphinxext/comment_eater.py b/doc/sphinxext/comment_eater.py
index 3b15bd178..6d216162a 100755
--- a/doc/sphinxext/comment_eater.py
+++ b/doc/sphinxext/comment_eater.py
@@ -1,4 +1,4 @@
-from six.moves import cStringIO
+from pandas.util.py3compat import cStringIO
 import compiler
 import inspect
 import textwrap
diff --git a/doc/sphinxext/compiler_unparse.py b/doc/sphinxext/compiler_unparse.py
index 240dd1724..0fa3983ab 100755
--- a/doc/sphinxext/compiler_unparse.py
+++ b/doc/sphinxext/compiler_unparse.py
@@ -12,7 +12,7 @@
 """
 
 import sys
-from six.moves import cStringIO as StringIO
+from pandas.util.py3compat import cStringIO as StringIO
 from compiler.ast import Const, Name, Tuple, Div, Mul, Sub, Add
 
 def unparse(ast, single_line_functions=False):
diff --git a/doc/sphinxext/ipython_directive.py b/doc/sphinxext/ipython_directive.py
index b74808f0e..195875047 100644
--- a/doc/sphinxext/ipython_directive.py
+++ b/doc/sphinxext/ipython_directive.py
@@ -58,8 +58,8 @@ from __future__ import print_function
 #-----------------------------------------------------------------------------
 
 # Stdlib
-from pandas.util.py3compat import range
-from six.moves import map, cStringIO as StringIO
+from pandas.util.py3compat import range, lmap
+from pandas.util.py3compat import map, cStringIO as StringIO
 import ast
 import os
 import re
@@ -72,7 +72,7 @@ from docutils.parsers.rst import directives
 from docutils import nodes
 from sphinx.util.compat import Directive
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 matplotlib.use('Agg')
 
@@ -303,7 +303,7 @@ class EmbeddedSphinxShell(object):
         def _remove_first_space_if_any(line):
             return line[1:] if line.startswith(' ') else line
 
-        input_lines = list(map(_remove_first_space_if_any, input.split('\n')))
+        input_lines = lmap(_remove_first_space_if_any, input.split('\n'))
 
         self.datacontent = data
 
diff --git a/doc/sphinxext/plot_directive.py b/doc/sphinxext/plot_directive.py
index 795410380..9c648f474 100755
--- a/doc/sphinxext/plot_directive.py
+++ b/doc/sphinxext/plot_directive.py
@@ -77,11 +77,11 @@ TODO
 
 from pandas.util.py3compat import range
 import sys, os, glob, shutil, imp, warnings, re, textwrap, traceback
-from six.moves import cStringIO as StringIO
+from pandas.util.py3compat import cStringIO as StringIO
 import sphinx
 
 import warnings
-from six.moves import map
+from pandas.util.py3compat import map
 warnings.warn("A plot_directive module is also available under "
               "matplotlib.sphinxext; expect this numpydoc.plot_directive "
               "module to be deprecated after relevant features have been "
diff --git a/examples/finance.py b/examples/finance.py
index 069f299d5..a8fb580f9 100644
--- a/examples/finance.py
+++ b/examples/finance.py
@@ -3,6 +3,7 @@ Some examples playing around with yahoo finance data
 """
 
 from datetime import datetime
+from pandas.util.py3compat import zip
 
 import matplotlib.finance as fin
 import numpy as np
@@ -19,7 +20,7 @@ endDate = datetime(2009, 9, 1)
 
 def getQuotes(symbol, start, end):
     quotes = fin.quotes_historical_yahoo(symbol, start, end)
-    dates, open, close, high, low, volume = list(zip(*quotes))
+    dates, open, close, high, low, volume = zip(*quotes)
 
     data = {
         'open': open,
diff --git a/pandas/compat/scipy.py b/pandas/compat/scipy.py
index 26a70963d..53436c517 100644
--- a/pandas/compat/scipy.py
+++ b/pandas/compat/scipy.py
@@ -2,7 +2,7 @@
 Shipping functions from SciPy to reduce dependency on having SciPy installed
 """
 
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import numpy as np
 
 
@@ -224,9 +224,9 @@ def percentileofscore(a, score, kind='rank'):
     if kind == 'rank':
         if not(np.any(a == score)):
             a = np.append(a, score)
-            a_len = np.array(list(range(len(a))))
+            a_len = np.array(lrange(len(a)))
         else:
-            a_len = np.array(list(range(len(a)))) + 1.0
+            a_len = np.array(lrange(len(a))) + 1.0
 
         a = np.sort(a)
         idx = [a == score]
diff --git a/pandas/core/common.py b/pandas/core/common.py
index f4ae9e9c8..3af0d7dba 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -16,7 +16,7 @@ import pandas.tslib as tslib
 
 from pandas.util import py3compat
 from pandas.util.py3compat import StringIO, BytesIO, range, long
-from six.moves import zip, map
+from pandas.util.py3compat import zip, map
 import six
 
 
diff --git a/pandas/core/config.py b/pandas/core/config.py
index 34dd2b744..26fda8d3d 100644
--- a/pandas/core/config.py
+++ b/pandas/core/config.py
@@ -53,7 +53,7 @@ import re
 from collections import namedtuple
 import warnings
 import six
-from six.moves import map
+from pandas.util.py3compat import map, lmap
 
 DeprecatedOption = namedtuple('DeprecatedOption', 'key msg rkey removal_ver')
 RegisteredOption = namedtuple(
@@ -746,7 +746,7 @@ def is_one_of_factory(legal_values):
     def inner(x):
         from pandas.core.common import pprint_thing as pp
         if not x in legal_values:
-            pp_values = list(map(pp, legal_values))
+            pp_values = lmap(pp, legal_values)
             raise ValueError("Value must be one of %s" % pp("|".join(pp_values)))
 
     return inner
diff --git a/pandas/core/format.py b/pandas/core/format.py
index 8676d9a54..150eade61 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -1,13 +1,11 @@
 from __future__ import print_function
 # pylint: disable=W0141
 
-from pandas.util.py3compat import range
 from pandas.util import compat
 import sys
 import six
-from six.moves import map, zip, reduce
 
-from pandas.util.py3compat import StringIO
+from pandas.util.py3compat import StringIO, lzip, range, map, zip, reduce
 from pandas.core.common import adjoin, isnull, notnull
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.util import py3compat
@@ -419,7 +417,7 @@ class DataFrameFormatter(TableFormatter):
 
         if isinstance(self.columns, MultiIndex):
             fmt_columns = self.columns.format(sparsify=False, adjoin=False)
-            fmt_columns = list(zip(*fmt_columns))
+            fmt_columns = lzip(*fmt_columns)
             dtypes = self.frame.dtypes.values
             need_leadsp = dict(zip(fmt_columns, map(is_numeric_dtype, dtypes)))
             str_columns = list(zip(*[[' ' + y
@@ -718,7 +716,7 @@ class HTMLFormatter(TableFormatter):
 
         idx_values = frame.index.format(sparsify=False, adjoin=False,
                                         names=False)
-        idx_values = list(zip(*idx_values))
+        idx_values = lzip(*idx_values)
 
         if self.fmt.sparsify:
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 1c2ff4130..827ebc53d 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -12,9 +12,7 @@ labeling information
 # pylint: disable=E1101,E1103
 # pylint: disable=W0212,W0231,W0703,W0622
 
-from six.moves import zip
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, zip, lrange, lmap, lzip, StringIO
 from pandas.util import compat
 import operator
 import sys
@@ -59,7 +57,6 @@ import pandas.algos as _algos
 
 from pandas.core.config import get_option, set_option
 import six
-from six.moves import map
 
 #----------------------------------------------------------------------
 # Docstring templates
@@ -1151,7 +1148,7 @@ class DataFrame(NDFrame):
             else:
                 if isinstance(self.index, MultiIndex):
                     # array of tuples to numpy cols. copy copy copy
-                    ix_vals = list(map(np.array,zip(*self.index.values)))
+                    ix_vals = lmap(np.array,zip(*self.index.values))
                 else:
                     ix_vals = [self.index.values]
 
@@ -1166,10 +1163,10 @@ class DataFrame(NDFrame):
                         count += 1
             elif index_names[0] is None:
                 index_names = ['index']
-            names = index_names + list(map(str, self.columns))
+            names = index_names + lmap(str, self.columns)
         else:
             arrays = [self[c].values for c in self.columns]
-            names = list(map(str, self.columns))
+            names = lmap(str, self.columns)
 
         dtype = np.dtype([(x, v.dtype) for x, v in zip(names, arrays)])
         return np.rec.fromarrays(arrays, dtype=dtype, names=names)
@@ -1197,7 +1194,7 @@ class DataFrame(NDFrame):
         -------
         frame : DataFrame
         """
-        keys, values = list(zip(*items))
+        keys, values = lzip(*items)
 
         if orient == 'columns':
             if columns is not None:
@@ -2911,7 +2908,7 @@ class DataFrame(NDFrame):
 
             if not drop:
                 names = self.index.names
-                zipped = list(zip(self.index.levels, self.index.labels))
+                zipped = lzip(self.index.levels, self.index.labels)
 
                 multi_col = isinstance(self.columns, MultiIndex)
                 for i, (lev, lab) in reversed(list(enumerate(zipped))):
@@ -4536,7 +4533,7 @@ class DataFrame(NDFrame):
     def applymap(self, func):
         """
         Apply a function to a DataFrame that is intended to operate
-        elementwise, i.e. like doing list(map(func, series)) for each series in the
+        elementwise, i.e. like doing map(func, series) for each series in the
         DataFrame
 
         Parameters
@@ -4889,7 +4886,7 @@ class DataFrame(NDFrame):
                            series.min(), series.quantile(lb), series.median(),
                            series.quantile(ub), series.max()])
 
-        return self._constructor(list(map(list, zip(*destat))), index=destat_columns,
+        return self._constructor(lmap(list, zip(*destat)), index=destat_columns,
                                  columns=numdata.columns)
 
     #----------------------------------------------------------------------
@@ -5850,7 +5847,7 @@ def _to_arrays(data, columns, coerce_float=False, dtype=None):
         return arrays, columns
     else:
         # last ditch effort
-        data = list(map(tuple, data))
+        data = lmap(tuple, data)
         return _list_to_arrays(data, columns,
                                coerce_float=coerce_float,
                                dtype=dtype)
@@ -5924,7 +5921,7 @@ def _convert_object_array(content, columns, coerce_float=False, dtype=None):
 
 
 def _get_names_from_index(data):
-    index = list(range(len(data)))
+    index = lrange(len(data))
     has_some_name = any([s.name is not None for s in data])
     if not has_some_name:
         return index
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 2dce7430c..0cf9a066e 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -11,7 +11,7 @@ from pandas.core.indexing import _maybe_convert_indices
 from pandas.tseries.index import DatetimeIndex
 import pandas.core.common as com
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 
 class PandasError(Exception):
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index d465ce8b1..f65d10730 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -2,10 +2,10 @@ import types
 import numpy as np
 
 import six
-from pandas.util.py3compat import range, long
+from pandas.util.py3compat import range, long, lrange, lzip
 from pandas.util.compat import OrderedDict
 from pandas.util import compat
-from six.moves import zip, builtins
+from pandas.util.py3compat import zip, builtins
 
 from pandas.core.base import PandasObject
 from pandas.core.categorical import Categorical
@@ -675,7 +675,7 @@ class Grouper(object):
         if len(self.groupings) == 1:
             return self.groupings[0].groups
         else:
-            to_groupby = list(zip(*(ping.grouper for ping in self.groupings)))
+            to_groupby = lzip(*(ping.grouper for ping in self.groupings))
             to_groupby = Index(to_groupby)
 
             return self.axis.groupby(to_groupby)
@@ -1017,13 +1017,13 @@ class BinGrouper(Grouper):
         else:
             start = 0
             for edge, label in zip(self.bins, self.binlabels):
-                inds = list(range(start, edge))
+                inds = lrange(start, edge)
                 yield label, data.take(inds, axis=axis)
                 start = edge
 
             n = len(data.axes[axis])
             if start < n:
-                inds = list(range(start, n))
+                inds = lrange(start, n)
                 yield self.binlabels[-1], data.take(inds, axis=axis)
 
     def apply(self, f, data, axis=0, keep_internal=False):
@@ -1445,7 +1445,7 @@ class SeriesGroupBy(GroupBy):
                    for x in arg]
 
             # indicated column order
-            columns = list(zip(*arg))[0]
+            columns = lzip(*arg)[0]
         else:
             # list of functions / function names
             columns = []
@@ -1454,7 +1454,7 @@ class SeriesGroupBy(GroupBy):
                     columns.append(f)
                 else:
                     columns.append(f.__name__)
-            arg = list(zip(columns, arg))
+            arg = lzip(columns, arg)
 
         results = {}
 
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 8b2f420d8..c54aa895f 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1,7 +1,6 @@
 # pylint: disable=E1101,E1103,W0232
 
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, zip, lrange, lzip
 import six
 from pandas.util import compat
 import numpy as np
@@ -1802,7 +1801,7 @@ class MultiIndex(Index):
         elif isinstance(tuples, list):
             arrays = list(lib.to_object_array_tuples(tuples).T)
         else:
-            arrays = list(zip(*tuples))
+            arrays = lzip(*tuples)
 
         return MultiIndex.from_arrays(arrays, sortorder=sortorder,
                                       names=names)
@@ -1942,7 +1941,7 @@ class MultiIndex(Index):
             if isinstance(loc, int):
                 inds.append(loc)
             else:
-                inds.extend(list(range(loc.start, loc.stop)))
+                inds.extend(lrange(loc.start, loc.stop))
 
         return self.delete(inds)
 
@@ -2490,7 +2489,7 @@ class MultiIndex(Index):
         result_names = self.names if self.names == other.names else None
 
         uniq_tuples = lib.fast_unique_multiple([self.values, other.values])
-        return MultiIndex.from_arrays(list(zip(*uniq_tuples)), sortorder=0,
+        return MultiIndex.from_arrays(lzip(*uniq_tuples), sortorder=0,
                                       names=result_names)
 
     def intersection(self, other):
@@ -2520,7 +2519,7 @@ class MultiIndex(Index):
                               labels=[[]] * self.nlevels,
                               names=result_names)
         else:
-            return MultiIndex.from_arrays(list(zip(*uniq_tuples)), sortorder=0,
+            return MultiIndex.from_arrays(lzip(*uniq_tuples), sortorder=0,
                                           names=result_names)
 
     def diff(self, other):
@@ -2637,7 +2636,7 @@ class MultiIndex(Index):
 # For utility purposes
 
 def _sparsify(label_list, start=0,sentinal=''):
-    pivoted = list(zip(*label_list))
+    pivoted = lzip(*label_list)
     k = len(label_list)
 
     result = pivoted[:start + 1]
@@ -2661,7 +2660,7 @@ def _sparsify(label_list, start=0,sentinal=''):
 
         prev = cur
 
-    return list(zip(*result))
+    return lzip(*result)
 
 
 def _ensure_index(index_like):
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index cb841169d..1518aa3c9 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -4,7 +4,7 @@ from datetime import datetime
 from pandas.core.common import _asarray_tuplesafe
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import zip
 import pandas.core.common as com
 import six
 import pandas.lib as lib
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 37aa4e4ca..e2b3131fa 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -19,8 +19,8 @@ import pandas.core.expressions as expressions
 
 from pandas.tslib import Timestamp
 from pandas.util import py3compat
-from pandas.util.py3compat import range
-from six.moves import map, zip
+from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.py3compat import map, zip
 
 
 class Block(PandasObject):
@@ -833,7 +833,7 @@ class ObjectBlock(Block):
         f = np.vectorize(re_replacer, otypes=[self.dtype])
 
         try:
-            filt = list(map(self.items.get_loc, filter))
+            filt = lmap(self.items.get_loc, filter)
         except TypeError:
             filt = slice(None)
 
@@ -1925,7 +1925,7 @@ class BlockManager(PandasObject):
 
             # need to shift elements to the right
             if self._ref_locs[loc] is not None:
-                for i in reversed(list(range(loc+1,len(self._ref_locs)))):
+                for i in reversed(lrange(loc+1,len(self._ref_locs))):
                     self._ref_locs[i] = self._ref_locs[i-1]
 
             self._ref_locs[loc] = (new_block, 0)
@@ -2535,5 +2535,5 @@ def _possibly_convert_to_indexer(loc):
     if com._is_bool_indexer(loc):
         loc = [i for i, v in enumerate(loc) if v]
     elif isinstance(loc,slice):
-        loc = list(range(loc.start,loc.stop))
+        loc = lrange(loc.start,loc.stop)
     return loc
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 699d0ac21..937235730 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -12,7 +12,7 @@ import pandas.algos as algos
 import pandas.hashtable as _hash
 import pandas.tslib as tslib
 
-from six.moves import builtins
+from pandas.util.py3compat import builtins
 import six
 
 
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 63c554883..35e5d1e23 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -3,7 +3,7 @@ Contains data structures designed for manipulating panel (3-dimensional) data
 """
 # pylint: disable=E1103,W0231,W0212,W0621
 
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, lmap
 from pandas.util import compat
 import operator
 import sys
@@ -28,7 +28,7 @@ import pandas.core.common as com
 import pandas.core.nanops as nanops
 import pandas.lib as lib
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 
 def _ensure_like_indices(time, panels):
@@ -808,13 +808,13 @@ class Panel(NDFrame):
         new_minor, indexer2 = self.minor_axis.reindex(minor)
 
         if indexer0 is None:
-            indexer0 = list(range(len(new_items)))
+            indexer0 = lrange(len(new_items))
 
         if indexer1 is None:
-            indexer1 = list(range(len(new_major)))
+            indexer1 = lrange(len(new_major))
 
         if indexer2 is None:
-            indexer2 = list(range(len(new_minor)))
+            indexer2 = lrange(len(new_minor))
 
         for i, ind in enumerate(indexer0):
             com.take_2d_multi(values[ind], (indexer1, indexer2),
@@ -1141,7 +1141,7 @@ class Panel(NDFrame):
 
         for a in self._AXIS_ORDERS:
             if not a in kwargs:
-                where = list(map(a.startswith, aliases))
+                where = lmap(a.startswith, aliases)
 
                 if any(where):
                     if sum(where) != 1:
diff --git a/pandas/core/panelnd.py b/pandas/core/panelnd.py
index 3981850d9..71d815482 100644
--- a/pandas/core/panelnd.py
+++ b/pandas/core/panelnd.py
@@ -1,7 +1,7 @@
 """ Factory methods to create N-D panels """
 
 import pandas.lib as lib
-from six.moves import zip
+from pandas.util.py3compat import zip
 import six
 
 
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index a89f5f270..136f48930 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -3,7 +3,7 @@
 
 from pandas.util.py3compat import range
 from pandas.util import compat
-from six.moves import zip
+from pandas.util.py3compat import zip
 import six
 import itertools
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index c8075e223..b25afe5d9 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -6,7 +6,6 @@ Data structure for 1-dimensional cross-sectional and time series data
 # pylint: disable=W0703,W0622,W0613,W0201
 
 from pandas.util import compat
-from six.moves import zip
 import operator
 from distutils.version import LooseVersion
 import types
@@ -28,6 +27,7 @@ from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
 from pandas.util import py3compat
 from pandas.util.terminal import get_terminal_size
+from pandas.util.py3compat import zip, lzip
 
 import pandas.core.array as pa
 
@@ -1219,7 +1219,7 @@ class Series(generic.PandasContainer, pa.Array):
         """
         Lazily iterate over (index, value) tuples
         """
-        return list(zip(iter(self.index), iter(self)))
+        return lzip(iter(self.index), iter(self))
 
     iterkv = iteritems
     if py3compat.PY3:  # pragma: no cover
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index dbf50aef5..c625438df 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -1,6 +1,6 @@
 import numpy as np
 
-from six.moves import zip
+from pandas.util.py3compat import zip
 import six
 from pandas.core.common import isnull
 from pandas.core.series import Series
diff --git a/pandas/io/data.py b/pandas/io/data.py
index 90e046998..04d6cbc95 100644
--- a/pandas/io/data.py
+++ b/pandas/io/data.py
@@ -12,14 +12,14 @@ from collections import defaultdict
 
 import numpy as np
 
-from pandas.util.py3compat import StringIO, bytes_to_str, range
+from pandas.util.py3compat import StringIO, bytes_to_str, range, lrange, lmap
 from pandas import Panel, DataFrame, Series, read_csv, concat
 from pandas.core.common import PandasError
 from pandas.io.parsers import TextParser
 from pandas.io.common import urlopen, ZipFile, urlencode
 from pandas.util.testing import _network_error_classes
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 
 class SymbolWarning(UserWarning):
@@ -465,7 +465,7 @@ def get_data_famafrench(name):
         with ZipFile(tmpf, 'r') as zf:
             data = zf.open(name + '.txt').readlines()
 
-    line_lengths = np.array(list(map(len, data)))
+    line_lengths = np.array(lmap(len, data))
     file_edges = np.where(line_lengths == 2)[0]
 
     datasets = {}
@@ -473,7 +473,7 @@ def get_data_famafrench(name):
     for i, (left_edge, right_edge) in enumerate(edges):
         dataset = [d.split() for d in data[left_edge:right_edge]]
         if len(dataset) > 10:
-            ncol_raw = np.array(list(map(len, dataset)))
+            ncol_raw = np.array(lmap(len, dataset))
             ncol = np.median(ncol_raw)
             header_index = np.where(ncol_raw == ncol - 1)[0][-1]
             header = dataset[header_index]
@@ -809,7 +809,7 @@ class Options(object):
         data : dict of str, DataFrame
         """
         warnings.warn("get_forward_data() is deprecated", FutureWarning)
-        in_months = list(range(CUR_MONTH, CUR_MONTH + months + 1))
+        in_months = lrange(CUR_MONTH, CUR_MONTH + months + 1)
         in_years = [CUR_YEAR] * (months + 1)
 
         # Figure out how many items in in_months go past 12
diff --git a/pandas/io/excel.py b/pandas/io/excel.py
index 132b1549e..f592d80f3 100644
--- a/pandas/io/excel.py
+++ b/pandas/io/excel.py
@@ -11,8 +11,8 @@ import numpy as np
 from pandas.io.parsers import TextParser
 from pandas.tseries.period import Period
 from pandas import json
-from six.moves import map, zip, reduce
-from pandas.util.py3compat import range
+from pandas.util.py3compat import map, zip, reduce
+from pandas.util.py3compat import range, lrange
 import six
 
 def read_excel(path_or_buf, sheetname, kind=None, **kwds):
@@ -155,7 +155,7 @@ class ExcelFile(object):
             for rng in areas.split(','):
                 if ':' in rng:
                     rng = rng.split(':')
-                    cols += list(range(_excel2num(rng[0]), _excel2num(rng[1]) + 1))
+                    cols += lrange(_excel2num(rng[0]), _excel2num(rng[1]) + 1)
                 else:
                     cols.append(_excel2num(rng))
             return cols
diff --git a/pandas/io/ga.py b/pandas/io/ga.py
index b0db040b0..74157464b 100644
--- a/pandas/io/ga.py
+++ b/pandas/io/ga.py
@@ -18,7 +18,7 @@ from pandas.util.decorators import Appender, Substitution
 from apiclient.errors import HttpError
 from oauth2client.client import AccessTokenRefreshError
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 TYPE_MAP = {six.u('INTEGER'): int, six.u('FLOAT'): float, six.u('TIME'): int}
 
diff --git a/pandas/io/html.py b/pandas/io/html.py
index 9805c194d..2617566ad 100644
--- a/pandas/io/html.py
+++ b/pandas/io/html.py
@@ -14,10 +14,10 @@ import numpy as np
 
 from pandas import DataFrame, MultiIndex, isnull
 from pandas.io.common import _is_url, urlopen, parse_url
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, lmap
 from pandas.util import compat
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 
 try:
@@ -93,9 +93,9 @@ def _get_skiprows_iter(skiprows):
         A proper iterator to use to skip rows of a DataFrame.
     """
     if isinstance(skiprows, slice):
-        return list(range(skiprows.start or 0, skiprows.stop, skiprows.step or 1))
+        return lrange(skiprows.start or 0, skiprows.stop, skiprows.step or 1)
     elif isinstance(skiprows, numbers.Integral):
-        return list(range(skiprows))
+        return lrange(skiprows)
     elif isinstance(skiprows, collections.Container):
         return skiprows
     else:
@@ -345,14 +345,14 @@ class _HtmlFrameParser(object):
         thead = self._parse_thead(table)
         res = []
         if thead:
-            res = list(map(self._text_getter, self._parse_th(thead[0])))
+            res = lmap(self._text_getter, self._parse_th(thead[0]))
         return np.array(res).squeeze() if res and len(res) == 1 else res
 
     def _parse_raw_tfoot(self, table):
         tfoot = self._parse_tfoot(table)
         res = []
         if tfoot:
-            res = list(map(self._text_getter, self._parse_td(tfoot[0])))
+            res = lmap(self._text_getter, self._parse_td(tfoot[0]))
         return np.array(res).squeeze() if res and len(res) == 1 else res
 
     def _parse_raw_tbody(self, table):
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 760d14467..85d5ad0d3 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -2,8 +2,7 @@
 Module contains tools for processing files into DataFrames or other objects
 """
 from __future__ import print_function
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, StringIO, lzip
 from pandas.util import compat
 import re
 import csv
@@ -26,7 +25,7 @@ import pandas.tslib as tslib
 import pandas.parser as _parser
 from pandas.tseries.period import Period
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 _parser_params = """Also supports optionally iterating or breaking of the file
 into chunks.
@@ -562,7 +561,7 @@ class TextFileReader(object):
         na_values, na_fvalues = _clean_na_values(na_values, keep_default_na)
 
         if com.is_integer(skiprows):
-            skiprows = list(range(skiprows))
+            skiprows = lrange(skiprows)
         skiprows = set() if skiprows is None else set(skiprows)
 
         # put stuff back
@@ -731,7 +730,7 @@ class ParserBase(object):
         field_count = len(header[0])
         def extract(r):
             return tuple([ r[i] for i in range(field_count) if i not in sic ])
-        columns = list(zip(*[ extract(r) for r in header ]))
+        columns = lzip(*[ extract(r) for r in header ])
         names = ic + columns
 
         # if we find 'Unnamed' all of a single level, then our header was too long
@@ -980,7 +979,7 @@ class CParserWrapper(ParserBase):
                 self.names = ['X%d' % i
                               for i in range(self._reader.table_width)]
             else:
-                self.names = list(range(self._reader.table_width))
+                self.names = lrange(self._reader.table_width)
 
         # XXX
         self._set_noconvert_columns()
@@ -1454,7 +1453,7 @@ class PythonParser(ParserBase):
                 if self.prefix:
                     columns = [ ['X%d' % i for i in range(ncols)] ]
                 else:
-                    columns = [ list(range(ncols)) ]
+                    columns = [ lrange(ncols) ]
             else:
                 columns = [ names ]
 
@@ -1552,7 +1551,7 @@ class PythonParser(ParserBase):
                     # column and index names on diff rows
                     implicit_first_cols = 0
 
-                    self.index_col = list(range(len(line)))
+                    self.index_col = lrange(len(line))
                     self.buf = self.buf[1:]
 
                     for c in reversed(line):
@@ -1563,7 +1562,7 @@ class PythonParser(ParserBase):
         if implicit_first_cols > 0:
             self._implicit_index = True
             if self.index_col is None:
-                self.index_col = list(range(implicit_first_cols))
+                self.index_col = lrange(implicit_first_cols)
             index_name = None
 
         else:
diff --git a/pandas/io/pickle.py b/pandas/io/pickle.py
index b1dee20e6..56bca476c 100644
--- a/pandas/io/pickle.py
+++ b/pandas/io/pickle.py
@@ -1,4 +1,4 @@
-from six.moves import cPickle as pkl
+from pandas.util.py3compat import cPickle as pkl
 
 def to_pickle(obj, path):
     """
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index f03928366..908091942 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -6,7 +6,7 @@ from __future__ import print_function
 
 # pylint: disable-msg=E1101,W0613,W0603
 from datetime import datetime, date
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, lmap
 from pandas.util import compat
 import time
 import re
@@ -39,7 +39,7 @@ import pandas.tslib as tslib
 
 from contextlib import contextmanager
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 # versioning attribute
 _version = '0.10.1'
@@ -3127,7 +3127,7 @@ class AppendableTable(LegacyTable):
             # we must remove in reverse order!
             pg = groups.pop()
             for g in reversed(groups):
-                rows = l.take(list(range(g, pg)))
+                rows = l.take(lrange(g, pg))
                 table.removeRows(start=rows[rows.index[0]
                                             ], stop=rows[rows.index[-1]] + 1)
                 pg = g
@@ -3547,7 +3547,7 @@ class Term(StringMixin):
             self.eval()
 
     def __unicode__(self):
-        attrs = list(map(pprint_thing, (self.field, self.op, self.value)))
+        attrs = lmap(pprint_thing, (self.field, self.op, self.value))
         return "field->%s,op->%s,value->%s" % tuple(attrs)
 
     @property
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 16ccafcd1..c5111c77c 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -5,13 +5,13 @@ retrieval and to reduce dependency on DB-specific API.
 from __future__ import print_function
 from datetime import datetime, date
 
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lzip
 import numpy as np
 import traceback
 
 from pandas.core.datetools import format as date_format
 from pandas.core.api import DataFrame, isnull
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 import six
 
 #------------------------------------------------------------------------------
@@ -108,7 +108,7 @@ def tquery(sql, con=None, cur=None, retry=True):
 
     if result and len(result[0]) == 1:
         # python 3 compat
-        result = list(list(zip(*result))[0])
+        result = list(lzip(*result)[0])
     elif result is None:  # pragma: no cover
         result = []
 
@@ -293,7 +293,7 @@ def get_schema(frame, name, flavor, keys=None):
     lookup_type = lambda dtype: get_sqltype(dtype.type, flavor)
     # Replace spaces in DataFrame column names with _.
     safe_columns = [s.replace(' ', '_').strip() for s in frame.dtypes.index]
-    column_types = list(zip(safe_columns, map(lookup_type, frame.dtypes)))
+    column_types = lzip(safe_columns, map(lookup_type, frame.dtypes))
     if flavor == 'sqlite':
         columns = ',\n  '.join('[%s] %s' % x for x in column_types)
     else:
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index f76a6f154..338c6e1ac 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -21,7 +21,7 @@ from pandas.core.categorical import Categorical
 import datetime
 from pandas.util import py3compat
 from pandas.util import compat
-from pandas.util.py3compat import StringIO, long
+from pandas.util.py3compat import StringIO, long, lrange, lmap, lzip
 from pandas import isnull
 from pandas.io.parsers import _parser_params, Appender
 from pandas.io.common import get_filepath_or_buffer
@@ -226,7 +226,7 @@ class StataParser(object):
         # we're going to drop the label and cast to int
         self.DTYPE_MAP = \
             dict(
-                list(zip(range(1, 245), ['a' + str(i) for i in range(1, 245)])) +
+                lzip(range(1, 245), ['a' + str(i) for i in range(1, 245)]) +
                 [
                     (251, np.int16),
                     (252, np.int32),
@@ -235,7 +235,7 @@ class StataParser(object):
                     (255, np.float64)
                 ]
             )
-        self.TYPE_MAP = list(range(251)) + list('bhlfd')
+        self.TYPE_MAP = lrange(251) + list('bhlfd')
         #NOTE: technically, some of these are wrong. there are more numbers
         # that can be represented. it's the 27 ABOVE and BELOW the max listed
         # numeric data type in [U] 12.2.2 of the 11.2 manual
@@ -385,7 +385,7 @@ class StataReader(StataParser):
     def _col_size(self, k=None):
         """Calculate size of a data record."""
         if len(self.col_sizes) == 0:
-            self.col_sizes = list(map(lambda x: self._calcsize(x), self.typlist))
+            self.col_sizes = lmap(lambda x: self._calcsize(x), self.typlist)
         if k is None:
             return self.col_sizes
         else:
@@ -539,13 +539,13 @@ class StataReader(StataParser):
                     data[col] = Series(data[col], data[col].index, self.dtyplist[i])
 
         if convert_dates:
-            cols = np.where(list(map(lambda x: x in _date_formats, self.fmtlist)))[0]
+            cols = np.where(lmap(lambda x: x in _date_formats, self.fmtlist))[0]
             for i in cols:
                 col = data.columns[i]
                 data[col] = data[col].apply(_stata_elapsed_date_to_datetime, args=(self.fmtlist[i],))
 
         if convert_categoricals:
-            cols = np.where(list(map(lambda x: x in six.iterkeys(self.value_label_dict), self.lbllist)))[0]
+            cols = np.where(lmap(lambda x: x in six.iterkeys(self.value_label_dict), self.lbllist))[0]
             for i in cols:
                 col = data.columns[i]
                 labeled_data = np.copy(data[col])
diff --git a/pandas/io/tests/generate_legacy_pickles.py b/pandas/io/tests/generate_legacy_pickles.py
index 7659b22e4..85052ed2b 100644
--- a/pandas/io/tests/generate_legacy_pickles.py
+++ b/pandas/io/tests/generate_legacy_pickles.py
@@ -1,7 +1,7 @@
 """ self-contained to write legacy pickle files """
 from __future__ import print_function
 
-from six.moves import zip, cPickle as pickle
+from pandas.util.py3compat import zip, cPickle as pickle
 
 def _create_sp_series():
 
diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index 2063b34c9..b3c88611d 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -31,7 +31,7 @@ import pandas.util.testing as tm
 from pandas.parser import TextReader
 import pandas.parser as parser
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 
 class TestCParser(unittest.TestCase):
diff --git a/pandas/io/tests/test_excel.py b/pandas/io/tests/test_excel.py
index 251a32cc3..7726711de 100644
--- a/pandas/io/tests/test_excel.py
+++ b/pandas/io/tests/test_excel.py
@@ -37,7 +37,7 @@ from numpy.testing.decorators import slow
 
 from pandas.parser import OverflowError
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 def _skip_if_no_xlrd():
     try:
diff --git a/pandas/io/tests/test_html.py b/pandas/io/tests/test_html.py
index fc78d630b..3c6848d86 100644
--- a/pandas/io/tests/test_html.py
+++ b/pandas/io/tests/test_html.py
@@ -14,7 +14,7 @@ from nose.tools import assert_raises
 import numpy as np
 from numpy.random import rand
 from numpy.testing.decorators import slow
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 try:
     from importlib import import_module
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index 36bf0306d..f27345b91 100644
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -2,11 +2,10 @@
 # pylint: disable-msg=W0612,E1101
 from copy import deepcopy
 from datetime import datetime, timedelta
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, StringIO
 from pandas.util import compat
 from pandas.io.common import URLError
-from six.moves import cPickle as pickle
+from pandas.util.py3compat import cPickle as pickle
 import operator
 import os
 import unittest
@@ -323,7 +322,7 @@ class TestPandasContainer(unittest.TestCase):
         _check_all_orients(self.ts)
 
         # dtype
-        s = Series(list(range(6)), index=['a','b','c','d','e','f'])
+        s = Series(lrange(6), index=['a','b','c','d','e','f'])
         _check_all_orients(Series(s, dtype=np.float64), dtype=np.float64)
         _check_all_orients(Series(s, dtype=np.int), dtype=np.int)
 
@@ -343,7 +342,7 @@ class TestPandasContainer(unittest.TestCase):
 
     def test_typ(self):
 
-        s = Series(list(range(6)), index=['a','b','c','d','e','f'], dtype='int64')
+        s = Series(lrange(6), index=['a','b','c','d','e','f'], dtype='int64')
         result = read_json(s.to_json(),typ=None)
         assert_series_equal(result,s)
 
@@ -442,7 +441,7 @@ class TestPandasContainer(unittest.TestCase):
     def test_doc_example(self):
         dfj2 = DataFrame(np.random.randn(5, 2), columns=list('AB'))
         dfj2['date'] = Timestamp('20130101')
-        dfj2['ints'] = list(range(5))
+        dfj2['ints'] = lrange(5)
         dfj2['bools'] = True
         dfj2.index = pd.date_range('20130101',periods=5)
 
diff --git a/pandas/io/tests/test_json/test_ujson.py b/pandas/io/tests/test_json/test_ujson.py
index 1e5e455dd..cbea04ffb 100644
--- a/pandas/io/tests/test_json/test_ujson.py
+++ b/pandas/io/tests/test_json/test_ujson.py
@@ -20,7 +20,7 @@ from pandas.util.py3compat import range, StringIO
 from pandas.util import compat
 import pandas.json as ujson
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 import pandas.util.py3compat as py3compat
 
 import numpy as np
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 5796ea577..eeb34862f 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -12,7 +12,7 @@ from numpy import nan
 import numpy as np
 
 from pandas import DataFrame, Series, Index, MultiIndex, DatetimeIndex
-from pandas.util.py3compat import StringIO, BytesIO, PY3, range, long
+from pandas.util.py3compat import StringIO, BytesIO, PY3, range, long, lrange, lmap
 from pandas.io.common import urlopen, URLError
 import pandas.io.parsers as parsers
 from pandas.io.parsers import (read_csv, read_table, read_fwf,
@@ -35,7 +35,7 @@ from numpy.testing.decorators import slow
 
 from pandas.parser import OverflowError
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 
 class ParserTests(object):
@@ -609,7 +609,7 @@ ignore,this,row
 
         # GH 3062
         df = DataFrame(dict({
-                    'A' : np.asarray(list(range(10)),dtype='float64'),
+                    'A' : np.asarray(lrange(10),dtype='float64'),
                     'B' : pd.Timestamp('20010101') }))
         df.iloc[3:6,:] = np.nan
 
@@ -639,7 +639,7 @@ ignore,this,row
 1/2/2000,4,5,6
 1/3/2000,7,8,9
 """
-        data = self.read_csv(StringIO(text), skiprows=list(range(6)), header=None,
+        data = self.read_csv(StringIO(text), skiprows=lrange(6), header=None,
                              index_col=0, parse_dates=True)
 
         data2 = self.read_csv(StringIO(text), skiprows=6, header=None,
@@ -792,20 +792,20 @@ c,4,5
 15/01/2010;P;P;50;1;14/1/2011
 01/05/2010;P;P;50;1;15/1/2011'''
 
-        expected = self.read_csv(StringIO(data), sep=";", index_col=list(range(4)))
+        expected = self.read_csv(StringIO(data), sep=";", index_col=lrange(4))
 
         lev = expected.index.levels[0]
         expected.index.levels[0] = lev.to_datetime(dayfirst=True)
         expected['aux_date'] = to_datetime(expected['aux_date'],
                                            dayfirst=True)
-        expected['aux_date'] = list(map(Timestamp, expected['aux_date']))
+        expected['aux_date'] = lmap(Timestamp, expected['aux_date'])
         tm.assert_isinstance(expected['aux_date'][0], datetime)
 
-        df = self.read_csv(StringIO(data), sep=";", index_col=list(range(4)),
+        df = self.read_csv(StringIO(data), sep=";", index_col=lrange(4),
                            parse_dates=[0, 5], dayfirst=True)
         tm.assert_frame_equal(df, expected)
 
-        df = self.read_csv(StringIO(data), sep=";", index_col=list(range(4)),
+        df = self.read_csv(StringIO(data), sep=";", index_col=lrange(4),
                            parse_dates=['date', 'aux_date'], dayfirst=True)
         tm.assert_frame_equal(df, expected)
 
@@ -828,7 +828,7 @@ c,4,5
 
         self.assert_(np.array_equal(df_pref.columns,
                                     ['X0', 'X1', 'X2', 'X3', 'X4']))
-        self.assert_(np.array_equal(df.columns, list(range(5))))
+        self.assert_(np.array_equal(df.columns, lrange(5)))
 
         self.assert_(np.array_equal(df2.columns, names))
 
@@ -1550,7 +1550,7 @@ False,NA,True"""
 
         sfile = StringIO(s)
         # it's 33 columns
-        result = self.read_csv(sfile, names=list(range(33)), na_values=['-9999.0'],
+        result = self.read_csv(sfile, names=lrange(33), na_values=['-9999.0'],
                                header=None, skipinitialspace=True)
         self.assertTrue(pd.isnull(result.ix[0, 29]))
 
@@ -1607,7 +1607,7 @@ A,B,C
         if hash(np.int64(-1)) != -2:
             raise nose.SkipTest
 
-        from pandas.util.py3compat import StringIO
+        from pandas.util.py3compat import StringIO, lrange, lmap
         csv = """id,score,days
 1,2,12
 2,2-5,
@@ -1643,7 +1643,7 @@ A,B,C
             if not x:
                 return np.nan
             if x.find('-') > 0:
-                valmin, valmax = list(map(int, x.split('-')))
+                valmin, valmax = lmap(int, x.split('-'))
                 val = 0.5 * (valmin + valmax)
             else:
                 val = float(x)
@@ -2322,9 +2322,9 @@ No,No,No"""
         data = "1,2\n3,4,5"
 
         result = self.read_csv(StringIO(data), header=None,
-                               names=list(range(50)))
+                               names=lrange(50))
         expected = self.read_csv(StringIO(data), header=None,
-                                 names=list(range(3))).reindex(columns=list(range(50)))
+                                 names=lrange(3)).reindex(columns=lrange(50))
 
         tm.assert_frame_equal(result, expected)
 
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index bbfe7e931..e10c5ad41 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1,5 +1,5 @@
 from __future__ import print_function
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import nose
 import unittest
 import os
@@ -130,7 +130,7 @@ class TestHDFStore(unittest.TestCase):
             tm.assert_panel_equal(o, roundtrip('panel',o))
 
             # table
-            df = DataFrame(dict(A=list(range(5)), B=list(range(5))))
+            df = DataFrame(dict(A=lrange(5), B=lrange(5)))
             df.to_hdf(self.path,'table',append=True)
             result = read_hdf(self.path, 'table', where = ['index>2'])
             assert_frame_equal(df[df.index>2],result)
@@ -484,7 +484,7 @@ class TestHDFStore(unittest.TestCase):
             raise nose.SkipTest('system byteorder is not little, skipping test_encoding!')
 
         with ensure_clean(self.path) as store:
-            df = DataFrame(dict(A='foo',B='bar'),index=list(range(5)))
+            df = DataFrame(dict(A='foo',B='bar'),index=lrange(5))
             df.loc[2,'A'] = np.nan
             df.loc[3,'B'] = np.nan
             _maybe_remove(store, 'df')
@@ -607,7 +607,7 @@ class TestHDFStore(unittest.TestCase):
             for i in range(10):
 
                 df = DataFrame(np.random.randn(10,2),columns=list('AB'))
-                df['index'] = list(range(10))
+                df['index'] = lrange(10)
                 df['index'] += i*10
                 df['int64'] = Series([1]*len(df),dtype='int64')
                 df['int16'] = Series([1]*len(df),dtype='int16')
@@ -783,7 +783,7 @@ class TestHDFStore(unittest.TestCase):
             def check_col(key,name,size):
                 self.assert_(getattr(store.get_storer(key).table.description,name).itemsize == size)
 
-            df = DataFrame(dict(A = 'foo', B = 'bar'),index=list(range(10)))
+            df = DataFrame(dict(A = 'foo', B = 'bar'),index=lrange(10))
 
             # a min_itemsize that creates a data_column
             _maybe_remove(store, 'df')
@@ -1018,8 +1018,9 @@ class TestHDFStore(unittest.TestCase):
         raise nose.SkipTest('no big table frame')
 
         # create and write a big table
-        df = DataFrame(np.random.randn(2000 * 100, 100), index=list(range(
-            2000 * 100)), columns=['E%03d' % i for i in range(100)])
+        df = DataFrame(np.random.randn(2000 * 100, 100),
+                       index=lrange(2000 * 100),
+                       columns=['E%03d' % i for i in range(100)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
 
@@ -1042,7 +1043,7 @@ class TestHDFStore(unittest.TestCase):
         import time
         start_time = time.time()
         df = DataFrame(np.random.randn(1000 * 1000, 60),
-                       index=list(range(int(1000 * 1000))),
+                       index=lrange(int(1000 * 1000)),
                        columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
@@ -1071,8 +1072,8 @@ class TestHDFStore(unittest.TestCase):
         print ("\nbig_put start")
         import time
         start_time = time.time()
-        df = DataFrame(np.random.randn(1000 * 1000, 60), index=list(range(int(
-            1000 * 1000))), columns=['E%03d' % i for i in range(60)])
+        df = DataFrame(np.random.randn(1000 * 1000, 60), index=lrange(int(
+            1000 * 1000)), columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
         for x in range(20):
@@ -1381,14 +1382,14 @@ class TestHDFStore(unittest.TestCase):
             compare(store.select('df_tz',where=Term('A','>=',df.A[3])),df[df.A>=df.A[3]])
 
             _maybe_remove(store, 'df_tz')
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130103',tz='US/Eastern')),index=list(range(5)))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130103',tz='US/Eastern')),index=lrange(5))
             store.append('df_tz',df)
             result = store['df_tz']
             compare(result,df)
             assert_frame_equal(result,df)
 
             _maybe_remove(store, 'df_tz')
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='EET')),index=list(range(5)))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='EET')),index=lrange(5))
             self.assertRaises(TypeError, store.append, 'df_tz', df)
 
             # this is ok
@@ -1399,14 +1400,14 @@ class TestHDFStore(unittest.TestCase):
             assert_frame_equal(result,df)
 
             # can't append with diff timezone
-            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='CET')),index=list(range(5)))
+            df = DataFrame(dict(A = Timestamp('20130102',tz='US/Eastern'), B = Timestamp('20130102',tz='CET')),index=lrange(5))
             self.assertRaises(ValueError, store.append, 'df_tz', df)
 
         # as index
         with ensure_clean(self.path) as store:
 
             # GH 4098 example
-            df = DataFrame(dict(A = Series(list(range(3)), index=date_range('2000-1-1',periods=3,freq='H', tz='US/Eastern'))))
+            df = DataFrame(dict(A = Series(lrange(3), index=date_range('2000-1-1',periods=3,freq='H', tz='US/Eastern'))))
 
             _maybe_remove(store, 'df')
             store.put('df',df)
@@ -2096,7 +2097,7 @@ class TestHDFStore(unittest.TestCase):
 
             df = DataFrame(dict(ts=bdate_range('2012-01-01', periods=300),
                                 A=np.random.randn(300),
-                                B=list(range(300)),
+                                B=lrange(300),
                                 users = ['a']*50 + ['b']*50 + ['c']*100 + ['a%03d' % i for i in range(100)]))
             _maybe_remove(store, 'df')
             store.append('df', df, data_columns=['ts', 'A', 'B', 'users'])
@@ -2117,7 +2118,7 @@ class TestHDFStore(unittest.TestCase):
             expected = df[ (df.ts >= Timestamp('2012-02-01')) & df.users.isin(selector) ]
             tm.assert_frame_equal(expected, result)
 
-            selector = list(range(100,200))
+            selector = lrange(100,200)
             result = store.select('df', [Term('B', selector)])
             expected = df[ df.B.isin(selector) ]
             tm.assert_frame_equal(expected, result)
@@ -2215,7 +2216,7 @@ class TestHDFStore(unittest.TestCase):
     def test_retain_index_attributes(self):
 
         # GH 3499, losing frequency info on index recreation
-        df = DataFrame(dict(A = Series(list(range(3)),
+        df = DataFrame(dict(A = Series(lrange(3),
                                        index=date_range('2000-1-1',periods=3,freq='H'))))
 
         with ensure_clean(self.path) as store:
@@ -2232,7 +2233,7 @@ class TestHDFStore(unittest.TestCase):
 
             # try to append a table with a different frequency
             warnings.filterwarnings('ignore', category=AttributeConflictWarning)
-            df2 = DataFrame(dict(A = Series(list(range(3)),
+            df2 = DataFrame(dict(A = Series(lrange(3),
                                             index=date_range('2002-1-1',periods=3,freq='D'))))
             store.append('data',df2)
             warnings.filterwarnings('always', category=AttributeConflictWarning)
@@ -2241,10 +2242,10 @@ class TestHDFStore(unittest.TestCase):
 
             # this is ok
             _maybe_remove(store,'df2')
-            df2 = DataFrame(dict(A = Series(list(range(3)),
+            df2 = DataFrame(dict(A = Series(lrange(3),
                                             index=[Timestamp('20010101'),Timestamp('20010102'),Timestamp('20020101')])))
             store.append('df2',df2)
-            df3 = DataFrame(dict(A = Series(list(range(3)),index=date_range('2002-1-1',periods=3,freq='D'))))
+            df3 = DataFrame(dict(A = Series(lrange(3),index=date_range('2002-1-1',periods=3,freq='D'))))
             store.append('df2',df3)
 
     def test_retain_index_attributes2(self):
@@ -2253,20 +2254,20 @@ class TestHDFStore(unittest.TestCase):
 
             warnings.filterwarnings('ignore', category=AttributeConflictWarning)
 
-            df  = DataFrame(dict(A = Series(list(range(3)), index=date_range('2000-1-1',periods=3,freq='H'))))
+            df  = DataFrame(dict(A = Series(lrange(3), index=date_range('2000-1-1',periods=3,freq='H'))))
             df.to_hdf(path,'data',mode='w',append=True)
-            df2 = DataFrame(dict(A = Series(list(range(3)), index=date_range('2002-1-1',periods=3,freq='D'))))
+            df2 = DataFrame(dict(A = Series(lrange(3), index=date_range('2002-1-1',periods=3,freq='D'))))
             df2.to_hdf(path,'data',append=True)
 
             idx = date_range('2000-1-1',periods=3,freq='H')
             idx.name = 'foo'
-            df  = DataFrame(dict(A = Series(list(range(3)), index=idx)))
+            df  = DataFrame(dict(A = Series(lrange(3), index=idx)))
             df.to_hdf(path,'data',mode='w',append=True)
             self.assert_(read_hdf(path,'data').index.name == 'foo')
 
             idx2 = date_range('2001-1-1',periods=3,freq='H')
             idx2.name = 'bar'
-            df2 = DataFrame(dict(A = Series(list(range(3)), index=idx2)))
+            df2 = DataFrame(dict(A = Series(lrange(3), index=idx2)))
             df2.to_hdf(path,'data',append=True)
             self.assert_(read_hdf(path,'data').index.name is None)
 
@@ -2426,7 +2427,7 @@ class TestHDFStore(unittest.TestCase):
             # get coordinates back & test vs frame
             _maybe_remove(store, 'df')
 
-            df = DataFrame(dict(A=list(range(5)), B=list(range(5))))
+            df = DataFrame(dict(A=lrange(5), B=lrange(5)))
             store.append('df', df)
             c = store.select_as_coordinates('df', ['index<3'])
             assert((c.values == np.arange(3)).all() == True)
@@ -2755,7 +2756,7 @@ class TestHDFStore(unittest.TestCase):
                        columns=['A', 'B', 'C'])
         store.append('mi', df)
 
-        df = DataFrame(dict(A = 'foo', B = 'bar'),index=list(range(10)))
+        df = DataFrame(dict(A = 'foo', B = 'bar'),index=lrange(10))
         store.append('df', df, data_columns = ['B'], min_itemsize={'A' : 200 })
 
         store.close()
diff --git a/pandas/io/tests/test_sql.py b/pandas/io/tests/test_sql.py
index 28703975f..5dc719953 100644
--- a/pandas/io/tests/test_sql.py
+++ b/pandas/io/tests/test_sql.py
@@ -11,7 +11,7 @@ import numpy as np
 
 from pandas.core.datetools import format as date_format
 from pandas.core.api import DataFrame, isnull
-from pandas.util.py3compat import StringIO, range
+from pandas.util.py3compat import StringIO, range, lrange
 import six
 
 import pandas.io.sql as sql
@@ -173,12 +173,12 @@ class TestSQLite(unittest.TestCase):
 
         frame['txt'] = ['a'] * len(frame)
         frame2 = frame.copy()
-        frame2['Idx'] = Index(list(range(len(frame2)))) + 10
+        frame2['Idx'] = Index(lrange(len(frame2))) + 10
         sql.write_frame(frame2, name='test_table2', con=self.db)
         result = sql.read_frame("select * from test_table2", self.db,
                                 index_col='Idx')
         expected = frame.copy()
-        expected.index = Index(list(range(len(frame2)))) + 10
+        expected.index = Index(lrange(len(frame2))) + 10
         expected.index.name = 'Idx'
         print(expected.index.names)
         print(result.index.names)
@@ -410,7 +410,7 @@ class TestMySQL(unittest.TestCase):
 
         frame['txt'] = ['a'] * len(frame)
         frame2 = frame.copy()
-        index = Index(list(range(len(frame2)))) + 10
+        index = Index(lrange(len(frame2))) + 10
         frame2['Idx'] = index
         drop_sql = "DROP TABLE IF EXISTS test_table2"
         cur = self.db.cursor()
diff --git a/pandas/io/wb.py b/pandas/io/wb.py
index 65a666228..4563c0a08 100644
--- a/pandas/io/wb.py
+++ b/pandas/io/wb.py
@@ -1,7 +1,7 @@
 from __future__ import print_function
 
-from six.moves import map, reduce
-from pandas.util.py3compat import range
+from pandas.util.py3compat import map, reduce
+from pandas.util.py3compat import range, lrange
 from pandas.io.common import urlopen
 from pandas.io import json
 import pandas
@@ -142,7 +142,7 @@ def get_indicators():
     data.topics = data.topics.apply(lambda x: ' ; '.join(x))
     # Clean outpu
     data = data.sort(columns='id')
-    data.index = pandas.Index(list(range(data.shape[0])))
+    data.index = pandas.Index(lrange(data.shape[0]))
     return data
 
 
diff --git a/pandas/rpy/common.py b/pandas/rpy/common.py
index 75065a19d..66e3e1777 100644
--- a/pandas/rpy/common.py
+++ b/pandas/rpy/common.py
@@ -4,7 +4,7 @@ developer-friendly.
 """
 from __future__ import print_function
 
-from six.moves import zip
+from pandas.util.py3compat import zip
 from pandas.util.py3compat import range
 import numpy as np
 
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 26c0a151a..c889d4c19 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -6,7 +6,7 @@ with float64 data
 # pylint: disable=E1101,E1103,W0231,E0202
 
 from numpy import nan
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lmap
 from pandas.util import compat
 import numpy as np
 
@@ -23,7 +23,7 @@ import pandas.core.datetools as datetools
 from pandas.sparse.series import SparseSeries
 from pandas.util.decorators import Appender
 import pandas.lib as lib
-from six.moves import map
+from pandas.util.py3compat import map
 
 
 class _SparseMockBlockManager(object):
@@ -853,7 +853,7 @@ class SparseDataFrame(DataFrame):
     def applymap(self, func):
         """
         Apply a function to a DataFrame that is intended to operate
-        elementwise, i.e. like doing list(map(func, series)) for each series in the
+        elementwise, i.e. like doing map(func, series) for each series in the
         DataFrame
 
         Parameters
@@ -865,7 +865,7 @@ class SparseDataFrame(DataFrame):
         -------
         applied : DataFrame
         """
-        return self.apply(lambda x: list(map(func, x)))
+        return self.apply(lambda x: lmap(func, x))
 
     @Appender(DataFrame.fillna.__doc__)
     def fillna(self, value=None, method=None, inplace=False, limit=None):
diff --git a/pandas/sparse/panel.py b/pandas/sparse/panel.py
index 494cbaf83..e16dfdafd 100644
--- a/pandas/sparse/panel.py
+++ b/pandas/sparse/panel.py
@@ -5,8 +5,8 @@ with float64 data
 
 # pylint: disable=E1101,E1103,W0231
 
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip
 from pandas.util import compat
 import numpy as np
 
@@ -209,7 +209,7 @@ class SparsePanel(Panel):
 
     def __delitem__(self, key):
         loc = self.items.get_loc(key)
-        indices = list(range(loc)) + list(range(loc + 1, len(self.items)))
+        indices = lrange(loc) + lrange(loc + 1, len(self.items))
         del self._frames[key]
         self._items = self._items.take(indices)
 
diff --git a/pandas/sparse/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
index ff9d57bed..b39ec61f2 100644
--- a/pandas/sparse/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -22,9 +22,9 @@ from pandas.tseries.index import DatetimeIndex
 import pandas.core.datetools as datetools
 from pandas.core.common import isnull
 import pandas.util.testing as tm
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 from pandas.util import compat
-from six.moves import cPickle as pickle
+from pandas.util.py3compat import cPickle as pickle
 
 import pandas.sparse.frame as spf
 
@@ -36,7 +36,7 @@ from pandas.sparse.api import (SparseSeries, SparseTimeSeries,
 import pandas.tests.test_frame as test_frame
 import pandas.tests.test_panel as test_panel
 import pandas.tests.test_series as test_series
-from pandas.util.py3compat import StringIO
+from pandas.util.py3compat import StringIO, lrange
 
 from .test_array import assert_sp_array_equal
 
@@ -828,7 +828,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
     def test_constructor_convert_index_once(self):
         arr = np.array([1.5, 2.5, 3.5])
-        sdf = SparseDataFrame(columns=list(range(4)), index=arr)
+        sdf = SparseDataFrame(columns=lrange(4), index=arr)
         self.assertTrue(sdf[0].index is sdf[1].index)
 
     def test_constructor_from_series(self):
@@ -1219,7 +1219,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         self.assertRaises(Exception, self.frame.astype, np.int64)
 
     def test_fillna(self):
-        df = self.zframe.reindex(list(range(5)))
+        df = self.zframe.reindex(lrange(5))
         result = df.fillna(0)
         expected = df.to_dense().fillna(0).to_sparse(fill_value=0)
         assert_sp_frame_equal(result, expected)
diff --git a/pandas/stats/misc.py b/pandas/stats/misc.py
index 3e5db98d8..00c93e07c 100644
--- a/pandas/stats/misc.py
+++ b/pandas/stats/misc.py
@@ -5,7 +5,7 @@ import numpy as np
 from pandas.core.api import Series, DataFrame, isnull, notnull
 from pandas.core.series import remove_na
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 
 def zscore(series):
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index f1ac35cad..f5ca39d01 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -4,7 +4,7 @@ Ordinary least squares regression
 
 # pylint: disable-msg=W0201
 
-from six.moves import zip
+from pandas.util.py3compat import zip
 from itertools import starmap
 from pandas.util.py3compat import StringIO
 
diff --git a/pandas/stats/tests/test_moments.py b/pandas/stats/tests/test_moments.py
index 3780455c0..df483aa58 100644
--- a/pandas/stats/tests/test_moments.py
+++ b/pandas/stats/tests/test_moments.py
@@ -1,5 +1,5 @@
 from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import zip
 import unittest
 import nose
 import sys
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index 5f4a4ec13..524098292 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -1,7 +1,7 @@
 from __future__ import division
 
-from pandas.util.py3compat import range
-from six.moves import zip, reduce
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip, reduce
 from pandas.util import compat
 import numpy as np
 from pandas.core.base import StringMixin
@@ -80,7 +80,7 @@ class VAR(StringMixin):
         DataFrame
         """
         forecast = self._forecast_raw(h)[:, 0, :]
-        return DataFrame(forecast, index=list(range(1, 1 + h)),
+        return DataFrame(forecast, index=lrange(1, 1 + h),
                          columns=self._columns)
 
     def forecast_cov(self, h):
@@ -103,7 +103,7 @@ class VAR(StringMixin):
         DataFrame
         """
         return DataFrame(self._forecast_std_err_raw(h),
-                         index=list(range(1, 1 + h)), columns=self._columns)
+                         index=lrange(1, 1 + h), columns=self._columns)
 
     @cache_readonly
     def granger_causality(self):
@@ -345,7 +345,7 @@ BIC:                            %(bic).3f
 
             for t in range(T + 1):
                 index = t + p
-                y = values.take(list(range(index, index - p, -1)), axis=0).ravel()
+                y = values.take(lrange(index, index - p, -1), axis=0).ravel()
                 trans_Z = np.hstack(([1], y))
                 trans_Z = trans_Z.reshape(1, len(trans_Z))
 
@@ -535,7 +535,7 @@ class PanelVAR(VAR):
         Returns the forecasts at 1, 2, ..., n timesteps in the future.
         """
         forecast = self._forecast_raw(h).T.swapaxes(1, 2)
-        index = list(range(1, 1 + h))
+        index = lrange(1, 1 + h)
         w = Panel(forecast, items=self._data.items, major_axis=index,
                   minor_axis=self._data.minor_axis)
         return w
diff --git a/pandas/tests/test_categorical.py b/pandas/tests/test_categorical.py
index 9bab218e7..b0722c49e 100644
--- a/pandas/tests/test_categorical.py
+++ b/pandas/tests/test_categorical.py
@@ -1,7 +1,7 @@
 # pylint: disable=E1101,E1103,W0232
 
 from datetime import datetime
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import unittest
 import nose
 
@@ -104,7 +104,7 @@ class TestCategorical(unittest.TestCase):
     def test_na_flags_int_levels(self):
         # #1457
 
-        levels = list(range(10))
+        levels = lrange(10)
         labels = np.random.randint(0, 10, 20)
         labels[::5] = -1
 
diff --git a/pandas/tests/test_common.py b/pandas/tests/test_common.py
index 048b4c6f1..dc4ed0255 100644
--- a/pandas/tests/test_common.py
+++ b/pandas/tests/test_common.py
@@ -1,5 +1,5 @@
 from datetime import datetime
-from pandas.util.py3compat import range, long
+from pandas.util.py3compat import range, long, lrange, lmap
 import sys
 import re
 
@@ -17,7 +17,7 @@ import numpy as np
 from pandas.tslib import iNaT
 from pandas.util import py3compat
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 _multiprocess_can_split_ = True
 
@@ -123,7 +123,7 @@ def test_datetimeindex_from_empty_datetime64_array():
 def test_nan_to_nat_conversions():
 
     df = DataFrame(dict({
-        'A' : np.asarray(list(range(10)),dtype='float64'),
+        'A' : np.asarray(lrange(10),dtype='float64'),
         'B' : Timestamp('20010101') }))
     df.iloc[3:6,:] = np.nan
     result = df.loc[4,'B'].value
@@ -196,7 +196,7 @@ def test_split_ranges():
     # exhaustively test all possible mask sequences of length 8
     ncols = 8
     for i in range(2 ** ncols):
-        cols = list(map(int, list(_bin(i, ncols))))  # count up in base2
+        cols = lmap(int, list(_bin(i, ncols)))  # count up in base2
         mask = [cols[i] == 1 for i in range(len(cols))]
         test_locs(mask)
 
diff --git a/pandas/tests/test_format.py b/pandas/tests/test_format.py
index 50cf5a0d5..fdd11b7bd 100644
--- a/pandas/tests/test_format.py
+++ b/pandas/tests/test_format.py
@@ -1,13 +1,7 @@
 from __future__ import print_function
 # -*- coding: utf-8 -*-
 
-try:
-    from pandas.util.py3compat import StringIO
-except:
-    from io import StringIO
-
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, zip, lrange, StringIO, PY3, lzip
 import os
 import sys
 import unittest
@@ -19,7 +13,6 @@ from numpy.random import randn
 import numpy as np
 
 from pandas import DataFrame, Series, Index
-from pandas.util.py3compat import PY3
 
 import pandas.core.format as fmt
 import pandas.util.testing as tm
@@ -90,7 +83,7 @@ class TestDataFrameFormatting(unittest.TestCase):
     def test_repr_tuples(self):
         buf = StringIO()
 
-        df = DataFrame({'tups': list(zip(range(10), range(10)))})
+        df = DataFrame({'tups': lzip(range(10), range(10))})
         repr(df)
         df.to_string(col_space=10, buf=buf)
 
@@ -105,7 +98,7 @@ class TestDataFrameFormatting(unittest.TestCase):
 
             _strlen = fmt._strlen_func()
 
-            for line, value in list(zip(r.split('\n'), df['B'])):
+            for line, value in lzip(r.split('\n'), df['B']):
                 if _strlen(value) + 1 > max_len:
                     self.assert_('...' in line)
                 else:
@@ -136,10 +129,10 @@ class TestDataFrameFormatting(unittest.TestCase):
 
         #unlimited
         reset_option("display.max_seq_items")
-        self.assertTrue(len(com.pprint_thing(list(range(1000))))> 2000)
+        self.assertTrue(len(com.pprint_thing(lrange(1000)))> 2000)
 
         with option_context("display.max_seq_items",5):
-            self.assertTrue(len(com.pprint_thing(list(range(1000))))< 100)
+            self.assertTrue(len(com.pprint_thing(lrange(1000)))< 100)
 
     def test_repr_is_valid_construction_code(self):
         import pandas as pd
@@ -171,8 +164,8 @@ class TestDataFrameFormatting(unittest.TestCase):
 
     def test_expand_frame_repr(self):
         df_small = DataFrame('hello', [0], [0])
-        df_wide = DataFrame('hello', [0], list(range(10)))
-        df_tall = DataFrame('hello', list(range(30)), list(range(5)))
+        df_wide = DataFrame('hello', [0], lrange(10))
+        df_tall = DataFrame('hello', lrange(30), lrange(5))
 
         with option_context('mode.sim_interactive', True):
             with option_context('display.max_columns', 10,
@@ -197,7 +190,7 @@ class TestDataFrameFormatting(unittest.TestCase):
     def test_repr_non_interactive(self):
         # in non interactive mode, there can be no dependency on the
         # result of terminal auto size detection
-        df = DataFrame('hello', list(range(1000)), list(range(5)))
+        df = DataFrame('hello', lrange(1000), lrange(5))
 
         with option_context('mode.sim_interactive', False,
                             'display.width', 0,
@@ -321,7 +314,7 @@ class TestDataFrameFormatting(unittest.TestCase):
                       ('float', lambda x: '[% 4.1f]' % x),
                       ('object', lambda x: '-%s-' % str(x))]
         result = df.to_string(formatters=dict(formatters))
-        result2 = df.to_string(formatters=list(zip(*formatters))[1])
+        result2 = df.to_string(formatters=lzip(*formatters)[1])
         self.assertEqual(result, ('  int  float    object\n'
                                   '0 0x1 [ 1.0]  -(1, 2)-\n'
                                   '1 0x2 [ 2.0]    -True-\n'
@@ -661,7 +654,7 @@ class TestDataFrameFormatting(unittest.TestCase):
 
     def test_to_html_index_formatter(self):
         df = DataFrame([[0, 1], [2, 3], [4, 5], [6, 7]],
-                       columns=['foo', None], index=list(range(4)))
+                       columns=['foo', None], index=lrange(4))
 
         f = lambda x: 'abcd'[x]
         result = df.to_html(formatters={'__index__': f})
@@ -974,7 +967,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         # big mixed
         biggie = DataFrame({'A': randn(200),
                             'B': tm.makeStringIndex(200)},
-                           index=list(range(200)))
+                           index=lrange(200))
 
         biggie['A'][:20] = nan
         biggie['B'][:20] = nan
@@ -1112,7 +1105,7 @@ class TestDataFrameFormatting(unittest.TestCase):
 
     def test_to_string_float_index(self):
         index = Index([1.5, 2, 3, 4, 5])
-        df = DataFrame(list(range(5)), index=index)
+        df = DataFrame(lrange(5), index=index)
 
         result = df.to_string()
         expected = ('     0\n'
@@ -1147,7 +1140,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         self.assertEqual(output, expected)
 
     def test_to_string_index_formatter(self):
-        df = DataFrame([list(range(5)), list(range(5, 10)), list(range(10, 15))])
+        df = DataFrame([lrange(5), lrange(5, 10), lrange(10, 15)])
 
         rs = df.to_string(formatters={'__index__': lambda x: 'abc'[x]})
 
@@ -1195,7 +1188,7 @@ c  10  11  12  13  14\
         self.assertEqual(result, expected)
 
     def test_to_string_line_width(self):
-        df = pd.DataFrame(123, list(range(10, 15)), list(range(30)))
+        df = pd.DataFrame(123, lrange(10, 15), lrange(30))
         s = df.to_string(line_width=80)
         self.assertEqual(max(len(l) for l in s.split('\n')), 80)
 
@@ -1203,7 +1196,7 @@ c  10  11  12  13  14\
         # big mixed
         biggie = DataFrame({'A': randn(200),
                             'B': tm.makeStringIndex(200)},
-                           index=list(range(200)))
+                           index=lrange(200))
 
         biggie['A'][:20] = nan
         biggie['B'][:20] = nan
@@ -1230,7 +1223,7 @@ c  10  11  12  13  14\
     def test_to_html_filename(self):
         biggie = DataFrame({'A': randn(200),
                             'B': tm.makeStringIndex(200)},
-                           index=list(range(200)))
+                           index=lrange(200))
 
         biggie['A'][:20] = nan
         biggie['B'][:20] = nan
@@ -1258,7 +1251,7 @@ c  10  11  12  13  14\
 
     def test_to_html_multiindex(self):
         columns = pandas.MultiIndex.from_tuples(list(zip(np.arange(2).repeat(2),
-                                                    np.mod(list(range(4)), 2))),
+                                                    np.mod(lrange(4), 2))),
                                                 names=['CL0', 'CL1'])
         df = pandas.DataFrame([list('abcd'), list('efgh')], columns=columns)
         result = df.to_html(justify='left')
@@ -1298,7 +1291,7 @@ c  10  11  12  13  14\
         self.assertEqual(result, expected)
 
         columns = pandas.MultiIndex.from_tuples(list(zip(range(4),
-                                                    np.mod(list(range(4)), 2))))
+                                                    np.mod(lrange(4), 2))))
         df = pandas.DataFrame([list('abcd'), list('efgh')], columns=columns)
 
         result = df.to_html(justify='right')
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index aadfea05c..9104a2140 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -2,18 +2,18 @@ from __future__ import print_function
 # pylint: disable-msg=W0612,E1101
 from copy import deepcopy
 from datetime import datetime, timedelta, time
-import cPickle as pickle
 import operator
 import re
 import unittest
 import nose
 
 from pandas.util import py3compat
-from pandas.util.py3compat import StringIO, range, long
+from pandas.util.py3compat import cPickle as pickle
+from pandas.util.py3compat import StringIO, range, long, lrange, lmap, lzip
 from pandas.util.compat import OrderedDict
 from pandas.util import compat
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 from numpy import random, nan
 from numpy.random import randn
@@ -177,7 +177,7 @@ class CheckIndexing(object):
         assert_series_equal(self.frame['B'], data['A'])
         assert_series_equal(self.frame['A'], data['B'])
 
-        df = DataFrame(0, list(range(3)), ['tt1', 'tt2'], dtype=np.int_)
+        df = DataFrame(0, lrange(3), ['tt1', 'tt2'], dtype=np.int_)
         df.ix[1, ['tt1', 'tt2']] = [1, 2]
 
         result = df.ix[1, ['tt1', 'tt2']]
@@ -196,7 +196,7 @@ class CheckIndexing(object):
         assert_almost_equal(self.frame[['A', 'B']].values, data)
 
     def test_setitem_list_of_tuples(self):
-        tuples = list(zip(self.frame['A'], self.frame['B']))
+        tuples = lzip(self.frame['A'], self.frame['B'])
         self.frame['tuples'] = tuples
 
         result = self.frame['tuples']
@@ -362,7 +362,7 @@ class CheckIndexing(object):
                           'NONEXISTENT_NAME')
 
     def test_setattr_column(self):
-        df = DataFrame({'foobar': 1}, index=list(range(10)))
+        df = DataFrame({'foobar': 1}, index=lrange(10))
 
         df.foobar = 5
         self.assert_((df.foobar == 5).all())
@@ -566,11 +566,11 @@ class CheckIndexing(object):
         from decimal import Decimal
 
         # created as float type
-        dm = DataFrame(index=list(range(3)), columns=list(range(3)))
+        dm = DataFrame(index=lrange(3), columns=lrange(3))
 
         coercable_series = Series([Decimal(1) for _ in range(3)],
-                                  index=list(range(3)))
-        uncoercable_series = Series(['foo', 'bzr', 'baz'], index=list(range(3)))
+                                  index=lrange(3))
+        uncoercable_series = Series(['foo', 'bzr', 'baz'], index=lrange(3))
 
         dm[0] = np.ones(3)
         self.assertEqual(len(dm.columns), 3)
@@ -668,7 +668,7 @@ class CheckIndexing(object):
         self.assert_(isnull(df.ix[:8:2]).values.all())
 
     def test_getitem_setitem_integer_slice_keyerrors(self):
-        df = DataFrame(np.random.randn(10, 5), index=list(range(0, 20, 2)))
+        df = DataFrame(np.random.randn(10, 5), index=lrange(0, 20, 2))
 
         # this is OK
         cp = df.copy()
@@ -781,11 +781,11 @@ class CheckIndexing(object):
         assert_frame_equal(frame, expected)
 
         # new corner case of boolean slicing / setting
-        frame = DataFrame(list(zip([2, 3, 9, 6, 7], [np.nan] * 5)),
+        frame = DataFrame(lzip([2, 3, 9, 6, 7], [np.nan] * 5),
                           columns=['a', 'b'])
         lst = [100]
         lst.extend([np.nan] * 4)
-        expected = DataFrame(list(zip([100, 3, 9, 6, 7], lst)),
+        expected = DataFrame(lzip([100, 3, 9, 6, 7], lst),
                              columns=['a', 'b'])
         frame[frame['a'] == 2] = 100
         assert_frame_equal(frame, expected)
@@ -1492,7 +1492,7 @@ class CheckIndexing(object):
         self.assertRaises(ValueError, res3.set_value, 'foobar', 'baz', 'sam')
 
     def test_set_value_with_index_dtype_change(self):
-        df = DataFrame(randn(3, 3), index=list(range(3)), columns=list('ABC'))
+        df = DataFrame(randn(3, 3), index=lrange(3), columns=list('ABC'))
         res = df.set_value('C', 2, 1.0)
         self.assert_(list(res.index) == list(df.index) + ['C'])
         self.assert_(list(res.columns) == list(df.columns) + [2])
@@ -1500,7 +1500,7 @@ class CheckIndexing(object):
     def test_get_set_value_no_partial_indexing(self):
         # partial w/ MultiIndex raise exception
         index = MultiIndex.from_tuples([(0, 1), (0, 2), (1, 1), (1, 2)])
-        df = DataFrame(index=index, columns=list(range(4)))
+        df = DataFrame(index=index, columns=lrange(4))
         self.assertRaises(KeyError, df.get_value, 0, 1)
         # self.assertRaises(KeyError, df.set_value, 0, 1, 0)
 
@@ -1513,7 +1513,7 @@ class CheckIndexing(object):
         self.assert_(com.is_integer(result))
 
     def test_irow(self):
-        df = DataFrame(np.random.randn(10, 4), index=list(range(0, 20, 2)))
+        df = DataFrame(np.random.randn(10, 4), index=lrange(0, 20, 2))
 
         result = df.irow(1)
         exp = df.ix[2]
@@ -1540,7 +1540,7 @@ class CheckIndexing(object):
         assert_frame_equal(result, expected)
 
     def test_icol(self):
-        df = DataFrame(np.random.randn(4, 10), columns=list(range(0, 20, 2)))
+        df = DataFrame(np.random.randn(4, 10), columns=lrange(0, 20, 2))
 
         result = df.icol(1)
         exp = df.ix[:, 2]
@@ -2072,7 +2072,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         result = DataFrame([DataFrame([])])
         self.assert_(result.shape == (1,0))
 
-        result = DataFrame([DataFrame(dict(A = list(range(5))))])
+        result = DataFrame([DataFrame(dict(A = lrange(5)))])
         tm.assert_isinstance(result.iloc[0,0], DataFrame)
 
     def test_constructor_mixed_dtypes(self):
@@ -2086,7 +2086,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                 dtypes = MIXED_FLOAT_DTYPES
                 arrays = [ np.array(np.random.randint(10, size=10), dtype = d) for d in dtypes ]
 
-            zipper = list(zip(dtypes,arrays))
+            zipper = lzip(dtypes,arrays)
             for d,a in zipper:
                 assert(a.dtype == d)
             if ad is None:
@@ -2162,7 +2162,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_constructor_ordereddict(self):
         import random
         nitems = 100
-        nums = list(range(nitems))
+        nums = lrange(nitems)
         random.shuffle(nums)
         expected = ['A%d' % i for i in nums]
         df = DataFrame(OrderedDict(zip(expected, [[0]] * nitems)))
@@ -2362,14 +2362,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # automatic labeling
         frame = DataFrame(mat)
-        self.assert_(np.array_equal(frame.index, list(range(2))))
-        self.assert_(np.array_equal(frame.columns, list(range(3))))
+        self.assert_(np.array_equal(frame.index, lrange(2)))
+        self.assert_(np.array_equal(frame.columns, lrange(3)))
 
         frame = DataFrame(mat, index=[1, 2])
-        self.assert_(np.array_equal(frame.columns, list(range(3))))
+        self.assert_(np.array_equal(frame.columns, lrange(3)))
 
         frame = DataFrame(mat, columns=['A', 'B', 'C'])
-        self.assert_(np.array_equal(frame.index, list(range(2))))
+        self.assert_(np.array_equal(frame.index, lrange(2)))
 
         # 0-length axis
         frame = DataFrame(np.empty((0, 3)))
@@ -2420,14 +2420,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # automatic labeling
         frame = DataFrame(mat)
-        self.assert_(np.array_equal(frame.index, list(range(2))))
-        self.assert_(np.array_equal(frame.columns, list(range(3))))
+        self.assert_(np.array_equal(frame.index, lrange(2)))
+        self.assert_(np.array_equal(frame.columns, lrange(3)))
 
         frame = DataFrame(mat, index=[1, 2])
-        self.assert_(np.array_equal(frame.columns, list(range(3))))
+        self.assert_(np.array_equal(frame.columns, lrange(3)))
 
         frame = DataFrame(mat, columns=['A', 'B', 'C'])
-        self.assert_(np.array_equal(frame.index, list(range(2))))
+        self.assert_(np.array_equal(frame.index, lrange(2)))
 
         # 0-length axis
         frame = DataFrame(ma.masked_all((0, 3)))
@@ -2508,11 +2508,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertEqual(df.values.shape, (0, 0))
 
         # empty but with specified dtype
-        df = DataFrame(index=list(range(10)), columns=['a', 'b'], dtype=object)
+        df = DataFrame(index=lrange(10), columns=['a', 'b'], dtype=object)
         self.assert_(df.values.dtype == np.object_)
 
         # does not error but ends up float
-        df = DataFrame(index=list(range(10)), columns=['a', 'b'], dtype=int)
+        df = DataFrame(index=lrange(10), columns=['a', 'b'], dtype=int)
         self.assert_(df.values.dtype == np.object_)
 
         # #1783 empty dtype object
@@ -2686,7 +2686,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertRaises(Exception, DataFrame, data)
 
     def test_constructor_scalar(self):
-        idx = Index(list(range(3)))
+        idx = Index(lrange(3))
         df = DataFrame({"a": 0}, index=idx)
         expected = DataFrame({"a": [0, 0, 0]}, index=idx)
         assert_frame_equal(df, expected, check_dtype=False)
@@ -2855,7 +2855,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # assignment
         # GH 3687
         arr = np.random.randn(3, 2)
-        idx = list(range(2))
+        idx = lrange(2)
         df = DataFrame(arr, columns=['A', 'A'])
         df.columns = idx
         expected = DataFrame(arr,columns=idx)
@@ -2956,11 +2956,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # from the vb_suite/frame_methods/frame_insert_columns
         N = 10
         K = 5
-        df = DataFrame(index=list(range(N)))
+        df = DataFrame(index=lrange(N))
         new_col = np.random.randn(N)
         for i in range(K):
             df[i] = new_col
-        expected = DataFrame(np.repeat(new_col,K).reshape(N,K),index=list(range(N)))
+        expected = DataFrame(np.repeat(new_col,K).reshape(N,K),index=lrange(N))
         assert_frame_equal(df,expected)
 
     def test_constructor_single_value(self):
@@ -3096,12 +3096,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         expected = Series({'float64' : 1})
         assert_series_equal(result, expected)
 
-        df = DataFrame({'a' : 1 }, index=list(range(3)))
+        df = DataFrame({'a' : 1 }, index=lrange(3))
         result = df.get_dtype_counts()
         expected = Series({'int64': 1})
         assert_series_equal(result, expected)
 
-        df = DataFrame({'a' : 1. }, index=list(range(3)))
+        df = DataFrame({'a' : 1. }, index=lrange(3))
         result = df.get_dtype_counts()
         expected = Series({'float64': 1 })
         assert_series_equal(result, expected)
@@ -3206,7 +3206,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test__slice_consolidate_invalidate_item_cache(self):
         # #3970
-        df = DataFrame({ "aa":list(range(5)), "bb":[2.2]*5})
+        df = DataFrame({ "aa":lrange(5), "bb":[2.2]*5})
 
         # Creates a second float block
         df["cc"] = 0.0
@@ -3579,7 +3579,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         str_dates = ['20120209', '20120222']
         dt_dates = [datetime(2012, 2, 9), datetime(2012, 2, 22)]
 
-        A = DataFrame(str_dates, index=list(range(2)), columns=['aa'])
+        A = DataFrame(str_dates, index=lrange(2), columns=['aa'])
         C = DataFrame([[1, 2], [3, 4]], index=str_dates, columns=dt_dates)
 
         tst = A.join(C, on='aa')
@@ -3631,7 +3631,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # tuples is in the order of the columns
         result = DataFrame.from_records(tuples)
-        self.assert_(np.array_equal(result.columns, list(range(8))))
+        self.assert_(np.array_equal(result.columns, lrange(8)))
 
         # test exclude parameter & we are casting the results here (as we don't have dtype info to recover)
         columns_to_test = [ columns.index('C'), columns.index('E1') ]
@@ -3714,7 +3714,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                 return iter(self.args)
 
         recs = [Record(1, 2, 3), Record(4, 5, 6), Record(7, 8, 9)]
-        tups = list(map(tuple, recs))
+        tups = lmap(tuple, recs)
 
         result = DataFrame.from_records(recs)
         expected = DataFrame.from_records(tups)
@@ -3773,7 +3773,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # big mixed
         biggie = DataFrame({'A': randn(200),
                             'B': tm.makeStringIndex(200)},
-                           index=list(range(200)))
+                           index=lrange(200))
         biggie['A'][:20] = nan
         biggie['B'][:20] = nan
 
@@ -3809,8 +3809,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         buf = StringIO()
 
         # big one
-        biggie = DataFrame(np.zeros((200, 4)), columns=list(range(4)),
-                           index=list(range(200)))
+        biggie = DataFrame(np.zeros((200, 4)), columns=lrange(4),
+                           index=lrange(200))
         foo = repr(biggie)
 
     def test_repr_unsortable(self):
@@ -3977,7 +3977,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             assert_series_equal(s, expected)
 
         df = DataFrame({'floats': np.random.randn(5),
-                        'ints': list(range(5))}, columns=['floats', 'ints'])
+                        'ints': lrange(5)}, columns=['floats', 'ints'])
 
         for tup in df.itertuples(index=False):
             tm.assert_isinstance(tup[1], np.integer)
@@ -4642,7 +4642,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(df[-mask_b], df.ix[1:1, :])
 
     def test_float_none_comparison(self):
-        df = DataFrame(np.random.randn(8, 3), index=list(range(8)),
+        df = DataFrame(np.random.randn(8, 3), index=lrange(8),
                        columns=['A', 'B', 'C'])
 
         self.assertRaises(TypeError, df.__eq__, None)
@@ -4685,8 +4685,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
              assert_almost_equal(self.tsframe.values, recons.values)
 
              # corner case
-             dm = DataFrame({'s1': Series(list(range(3)), list(range(3))),
-                             's2': Series(list(range(2)), list(range(2)))})
+             dm = DataFrame({'s1': Series(lrange(3), lrange(3)),
+                             's2': Series(lrange(2), lrange(2))})
              dm.to_csv(path)
              recons = DataFrame.from_csv(path)
              assert_frame_equal(dm, recons)
@@ -4729,8 +4729,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             df2.to_csv(path,mode='a',header=False)
             xp = pd.concat([df1,df2])
             rs = pd.read_csv(path,index_col=0)
-            rs.columns = list(map(int,rs.columns))
-            xp.columns = list(map(int,xp.columns))
+            rs.columns = lmap(int,rs.columns)
+            xp.columns = lmap(int,xp.columns)
             assert_frame_equal(xp,rs)
 
     def test_to_csv_cols_reordering(self):
@@ -4813,10 +4813,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                      dupe_col=False):
 
                if cnlvl:
-                   header = list(range(cnlvl))
+                   header = lrange(cnlvl)
                    with ensure_clean(path) as path:
                         df.to_csv(path,encoding='utf8',chunksize=chunksize,tupleize_cols=False)
-                        recons = DataFrame.from_csv(path,header=list(range(cnlvl)),tupleize_cols=False,parse_dates=False)
+                        recons = DataFrame.from_csv(path,header=lrange(cnlvl),tupleize_cols=False,parse_dates=False)
                else:
                    with ensure_clean(path) as path:
                        df.to_csv(path,encoding='utf8',chunksize=chunksize)
@@ -4840,14 +4840,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                if r_dtype:
                     if r_dtype == 'u': # unicode
                         r_dtype='O'
-                        recons.index = np.array(list(map(_to_uni,recons.index)),
+                        recons.index = np.array(lmap(_to_uni,recons.index),
                                                 dtype=r_dtype)
-                        df.index = np.array(list(map(_to_uni,df.index)),dtype=r_dtype)
+                        df.index = np.array(lmap(_to_uni,df.index),dtype=r_dtype)
                     if r_dtype == 'dt': # unicode
                         r_dtype='O'
-                        recons.index = np.array(list(map(Timestamp,recons.index)),
+                        recons.index = np.array(lmap(Timestamp,recons.index),
                                                 dtype=r_dtype)
-                        df.index = np.array(list(map(Timestamp,df.index)),dtype=r_dtype)
+                        df.index = np.array(lmap(Timestamp,df.index),dtype=r_dtype)
                     elif r_dtype == 'p':
                         r_dtype='O'
                         recons.index = np.array(list(map(Timestamp,
@@ -4863,19 +4863,19 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                if c_dtype:
                     if c_dtype == 'u':
                         c_dtype='O'
-                        recons.columns = np.array(list(map(_to_uni,recons.columns)),
+                        recons.columns = np.array(lmap(_to_uni,recons.columns),
                                                 dtype=c_dtype)
-                        df.columns = np.array(list(map(_to_uni,df.columns)),dtype=c_dtype )
+                        df.columns = np.array(lmap(_to_uni,df.columns),dtype=c_dtype )
                     elif c_dtype == 'dt':
                         c_dtype='O'
-                        recons.columns = np.array(list(map(Timestamp,recons.columns)),
+                        recons.columns = np.array(lmap(Timestamp,recons.columns),
                                                 dtype=c_dtype )
-                        df.columns = np.array(list(map(Timestamp,df.columns)),dtype=c_dtype)
+                        df.columns = np.array(lmap(Timestamp,df.columns),dtype=c_dtype)
                     elif c_dtype == 'p':
                         c_dtype='O'
-                        recons.columns = np.array(list(map(Timestamp,recons.columns.to_datetime())),
+                        recons.columns = np.array(lmap(Timestamp,recons.columns.to_datetime()),
                                                 dtype=c_dtype)
-                        df.columns = np.array(list(map(Timestamp,df.columns.to_datetime())),dtype=c_dtype )
+                        df.columns = np.array(lmap(Timestamp,df.columns.to_datetime()),dtype=c_dtype )
                     else:
                         c_dtype= type_map.get(c_dtype)
                         recons.columns = np.array(recons.columns,dtype=c_dtype )
@@ -4956,7 +4956,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             _do_test(df,path,dupe_col=True)
 
 
-        _do_test(DataFrame(index=list(range(10))),path)
+        _do_test(DataFrame(index=lrange(10)),path)
         _do_test(mkdf(chunksize//2+1, 2,r_idx_nlevels=2),path,rnlvl=2)
         for ncols in [2,3,4]:
             base = int(chunksize//ncols)
@@ -5132,15 +5132,15 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
             # catch invalid headers
             def testit():
-                read_csv(path,tupleize_cols=False,header=list(range(3)),index_col=0)
+                read_csv(path,tupleize_cols=False,header=lrange(3),index_col=0)
             assertRaisesRegexp(CParserError, 'Passed header=\[0,1,2\] are too many rows for this multi_index of columns', testit)
 
             def testit():
-                read_csv(path,tupleize_cols=False,header=list(range(7)),index_col=0)
+                read_csv(path,tupleize_cols=False,header=lrange(7),index_col=0)
             assertRaisesRegexp(CParserError, 'Passed header=\[0,1,2,3,4,5,6\], len of 7, but only 6 lines in file', testit)
 
             for i in [3,4,5,6,7]:
-                 self.assertRaises(Exception, read_csv, path, tupleize_cols=False, header=list(range(i)), index_col=0)
+                 self.assertRaises(Exception, read_csv, path, tupleize_cols=False, header=lrange(i), index_col=0)
             self.assertRaises(Exception, read_csv, path, tupleize_cols=False, header=[0,2], index_col=0)
 
             # write with cols
@@ -5209,7 +5209,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_to_csv_dups_cols(self):
 
-        df        = DataFrame(np.random.randn(1000, 30),columns=list(range(15))+list(range(15)),dtype='float64')
+        df        = DataFrame(np.random.randn(1000, 30),columns=lrange(15)+lrange(15),dtype='float64')
 
         with ensure_clean() as filename:
             df.to_csv(filename) # single dtype, fine
@@ -5219,9 +5219,9 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         df_float  = DataFrame(np.random.randn(1000, 3),dtype='float64')
         df_int    = DataFrame(np.random.randn(1000, 3),dtype='int64')
-        df_bool   = DataFrame(True,index=df_float.index,columns=list(range(3)))
-        df_object = DataFrame('foo',index=df_float.index,columns=list(range(3)))
-        df_dt     = DataFrame(Timestamp('20010101'),index=df_float.index,columns=list(range(3)))
+        df_bool   = DataFrame(True,index=df_float.index,columns=lrange(3))
+        df_object = DataFrame('foo',index=df_float.index,columns=lrange(3))
+        df_dt     = DataFrame(Timestamp('20010101'),index=df_float.index,columns=lrange(3))
         df        = pan.concat([ df_float, df_int, df_bool, df_object, df_dt ], axis=1, ignore_index=True)
 
         cols = []
@@ -5258,7 +5258,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_to_csv_chunking(self):
 
-        aa=DataFrame({'A':list(range(100000))})
+        aa=DataFrame({'A':lrange(100000)})
         aa['B'] = aa.A + 1.0
         aa['C'] = aa.A + 2.0
         aa['D'] = aa.A + 3.0
@@ -5938,7 +5938,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(dropped, expected)
 
         dropped = df.dropna(axis=0)
-        expected = df.ix[list(range(2, 6))]
+        expected = df.ix[lrange(2, 6)]
         assert_frame_equal(dropped, expected)
 
         # threshold
@@ -5947,7 +5947,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(dropped, expected)
 
         dropped = df.dropna(axis=0, thresh=4)
-        expected = df.ix[list(range(2, 6))]
+        expected = df.ix[lrange(2, 6)]
         assert_frame_equal(dropped, expected)
 
         dropped = df.dropna(axis=1, thresh=4)
@@ -5993,7 +5993,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': ['one', 'one', 'two', 'two',
                               'two', 'two', 'one', 'two'],
                         'C': [1, 1, 2, 2, 2, 2, 1, 2],
-                        'D': list(range(8))})
+                        'D': lrange(8)})
 
         # single column
         result = df.drop_duplicates('AAA')
@@ -6033,7 +6033,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': ['one', 'one', 'two', 'two',
                               'two', 'two', 'one', 'two'],
                         'C': [1, 1, 2, 2, 2, 2, 1, 2],
-                        'D': list(range(8))})
+                        'D': lrange(8)})
 
         # single column
         result = df.drop_duplicates(('AA', 'AB'))
@@ -6056,7 +6056,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': ['one', 'one', 'two', 'two',
                               'two', 'two', 'one', 'two'],
                         'C': [1.0, np.nan, np.nan, np.nan, 1., 1., 1, 1.],
-                        'D': list(range(8))})
+                        'D': lrange(8)})
 
         # single column
         result = df.drop_duplicates('A')
@@ -6082,7 +6082,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': ['one', 'one', 'two', 'two',
                               'two', 'two', 'one', 'two'],
                         'C': [1.0, np.nan, np.nan, np.nan, 1., 1., 1, 1.],
-                        'D': list(range(8))})
+                        'D': lrange(8)})
 
         # single column
         result = df.drop_duplicates('C')
@@ -6108,7 +6108,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                           'B': ['one', 'one', 'two', 'two',
                                 'two', 'two', 'one', 'two'],
                           'C': [1, 1, 2, 2, 2, 2, 1, 2],
-                          'D': list(range(8))})
+                          'D': lrange(8)})
 
         # single column
         df = orig.copy()
@@ -6313,7 +6313,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_regex_replace_scalar(self):
         obj = {'a': list('ab..'), 'b': list('efgh')}
         dfobj = DataFrame(obj)
-        mix = {'a': list(range(4)), 'b': list('ab..')}
+        mix = {'a': lrange(4), 'b': list('ab..')}
         dfmix = DataFrame(mix)
 
         ### simplest cases
@@ -6379,7 +6379,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_regex_replace_scalar_inplace(self):
         obj = {'a': list('ab..'), 'b': list('efgh')}
         dfobj = DataFrame(obj)
-        mix = {'a': list(range(4)), 'b': list('ab..')}
+        mix = {'a': lrange(4), 'b': list('ab..')}
         dfmix = DataFrame(mix)
 
         ### simplest cases
@@ -6587,14 +6587,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_regex_replace_list_mixed(self):
         ## mixed frame to make sure this doesn't break things
-        mix = {'a': list(range(4)), 'b': list('ab..')}
+        mix = {'a': lrange(4), 'b': list('ab..')}
         dfmix = DataFrame(mix)
 
         ## lists of regexes and values
         # list of [re1, re2, ..., reN] -> [v1, v2, ..., vN]
         to_replace_res = [r'\s*\.\s*', r'a']
         values = [nan, 'crap']
-        mix2 = {'a': list(range(4)), 'b': list('ab..'), 'c': list('halo')}
+        mix2 = {'a': lrange(4), 'b': list('ab..'), 'c': list('halo')}
         dfmix2 = DataFrame(mix2)
         res = dfmix2.replace(to_replace_res, values, regex=True)
         expec = DataFrame({'a': mix2['a'], 'b': ['crap', 'b', nan, nan],
@@ -6625,7 +6625,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(res, expec)
 
     def test_regex_replace_list_mixed_inplace(self):
-        mix = {'a': list(range(4)), 'b': list('ab..')}
+        mix = {'a': lrange(4), 'b': list('ab..')}
         dfmix = DataFrame(mix)
         # the same inplace
         ## lists of regexes and values
@@ -6664,7 +6664,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(res, expec)
 
     def test_regex_replace_dict_mixed(self):
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         dfmix = DataFrame(mix)
 
         ## dicts
@@ -6721,7 +6721,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_regex_replace_dict_nested(self):
         # nested dicts will not work until this is implemented for Series
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         dfmix = DataFrame(mix)
         res = dfmix.replace({'b': {r'\s*\.\s*': nan}}, regex=True)
         res2 = dfmix.copy()
@@ -6742,7 +6742,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(df.replace({'Type': {'Q':0,'T':1}}), expected)
 
     def test_regex_replace_list_to_scalar(self):
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         df = DataFrame(mix)
         res = df.replace([r'\s*\.\s*', 'a|b'], nan, regex=True)
         res2 = df.copy()
@@ -6757,7 +6757,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_regex_replace_str_to_numeric(self):
         # what happens when you try to replace a numeric value with a regex?
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         df = DataFrame(mix)
         res = df.replace(r'\s*\.\s*', 0, regex=True)
         res2 = df.copy()
@@ -6771,7 +6771,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(res3, expec)
 
     def test_regex_replace_regex_list_to_numeric(self):
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         df = DataFrame(mix)
         res = df.replace([r'\s*\.\s*', 'b'], 0, regex=True)
         res2 = df.copy()
@@ -6786,7 +6786,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(res3, expec)
 
     def test_regex_replace_series_of_regexes(self):
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         df = DataFrame(mix)
         s1 = Series({'b': r'\s*\.\s*'})
         s2 = Series({'b': nan})
@@ -6802,7 +6802,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(res3, expec)
 
     def test_regex_replace_numeric_to_object_conversion(self):
-        mix = {'a': list(range(4)), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
+        mix = {'a': lrange(4), 'b': list('ab..'), 'c': ['a', 'b', nan, 'd']}
         df = DataFrame(mix)
         res = df.replace(0, 'a')
         expec = DataFrame({'a': ['a', 1, 2, 3], 'b': mix['b'], 'c': mix['c']})
@@ -7343,42 +7343,42 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         df = DataFrame(np.random.randn(10, 4))
 
         # axis=0
-        result = df.reindex(list(range(15)))
+        result = df.reindex(lrange(15))
         self.assert_(np.isnan(result.values[-5:]).all())
 
-        result = df.reindex(list(range(15)), fill_value=0)
-        expected = df.reindex(list(range(15))).fillna(0)
+        result = df.reindex(lrange(15), fill_value=0)
+        expected = df.reindex(lrange(15)).fillna(0)
         assert_frame_equal(result, expected)
 
         # axis=1
-        result = df.reindex(columns=list(range(5)), fill_value=0.)
+        result = df.reindex(columns=lrange(5), fill_value=0.)
         expected = df.copy()
         expected[4] = 0.
         assert_frame_equal(result, expected)
 
-        result = df.reindex(columns=list(range(5)), fill_value=0)
+        result = df.reindex(columns=lrange(5), fill_value=0)
         expected = df.copy()
         expected[4] = 0
         assert_frame_equal(result, expected)
 
-        result = df.reindex(columns=list(range(5)), fill_value='foo')
+        result = df.reindex(columns=lrange(5), fill_value='foo')
         expected = df.copy()
         expected[4] = 'foo'
         assert_frame_equal(result, expected)
 
         # reindex_axis
-        result = df.reindex_axis(list(range(15)), fill_value=0., axis=0)
-        expected = df.reindex(list(range(15))).fillna(0)
+        result = df.reindex_axis(lrange(15), fill_value=0., axis=0)
+        expected = df.reindex(lrange(15)).fillna(0)
         assert_frame_equal(result, expected)
 
-        result = df.reindex_axis(list(range(5)), fill_value=0., axis=1)
-        expected = df.reindex(columns=list(range(5))).fillna(0)
+        result = df.reindex_axis(lrange(5), fill_value=0., axis=1)
+        expected = df.reindex(columns=lrange(5)).fillna(0)
         assert_frame_equal(result, expected)
 
         # other dtypes
         df['foo'] = 'foo'
-        result = df.reindex(list(range(15)), fill_value=0)
-        expected = df.reindex(list(range(15))).fillna(0)
+        result = df.reindex(lrange(15), fill_value=0)
+        expected = df.reindex(lrange(15)).fillna(0)
         assert_frame_equal(result, expected)
 
     def test_align(self):
@@ -8964,12 +8964,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         tm.assert_isinstance(ct2, Series)
 
         # GH #423
-        df = DataFrame(index=list(range(10)))
+        df = DataFrame(index=lrange(10))
         result = df.count(1)
         expected = Series(0, index=df.index)
         assert_series_equal(result, expected)
 
-        df = DataFrame(columns=list(range(10)))
+        df = DataFrame(columns=lrange(10))
         result = df.count(0)
         expected = Series(0, index=df.columns)
         assert_series_equal(result, expected)
@@ -9152,7 +9152,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             print (df)
             self.assertFalse(len(_f()))
 
-            df['a'] = list(range(len(df)))
+            df['a'] = lrange(len(df))
             self.assert_(len(getattr(df, name)()))
 
         if has_skipna:
@@ -9531,12 +9531,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_series_equal(result, expected)
 
     def test_combine_first_mixed(self):
-        a = Series(['a', 'b'], index=list(range(2)))
-        b = Series(list(range(2)), index=list(range(2)))
+        a = Series(['a', 'b'], index=lrange(2))
+        b = Series(lrange(2), index=lrange(2))
         f = DataFrame({'A': a, 'B': b})
 
-        a = Series(['a', 'b'], index=list(range(5, 7)))
-        b = Series(list(range(2)), index=list(range(5, 7)))
+        a = Series(['a', 'b'], index=lrange(5, 7))
+        b = Series(lrange(2), index=lrange(5, 7))
         g = DataFrame({'A': a, 'B': b})
 
         combined = f.combine_first(g)
@@ -9554,7 +9554,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_(reindexed.values.dtype == np.object_)
         self.assert_(isnull(reindexed[0][1]))
 
-        reindexed = frame.reindex(columns=list(range(3)))
+        reindexed = frame.reindex(columns=lrange(3))
         self.assert_(reindexed.values.dtype == np.object_)
         self.assert_(isnull(reindexed[1]).all())
 
@@ -9614,22 +9614,22 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_reindex_multi(self):
         df = DataFrame(np.random.randn(3, 3))
 
-        result = df.reindex(list(range(4)), list(range(4)))
-        expected = df.reindex(list(range(4))).reindex(columns=list(range(4)))
+        result = df.reindex(lrange(4), lrange(4))
+        expected = df.reindex(lrange(4)).reindex(columns=lrange(4))
 
         assert_frame_equal(result, expected)
 
         df = DataFrame(np.random.randint(0, 10, (3, 3)))
 
-        result = df.reindex(list(range(4)), list(range(4)))
-        expected = df.reindex(list(range(4))).reindex(columns=list(range(4)))
+        result = df.reindex(lrange(4), lrange(4))
+        expected = df.reindex(lrange(4)).reindex(columns=lrange(4))
 
         assert_frame_equal(result, expected)
 
         df = DataFrame(np.random.randint(0, 10, (3, 3)))
 
-        result = df.reindex(list(range(2)), list(range(2)))
-        expected = df.reindex(list(range(2))).reindex(columns=list(range(2)))
+        result = df.reindex(lrange(2), lrange(2))
+        expected = df.reindex(lrange(2)).reindex(columns=lrange(2))
 
         assert_frame_equal(result, expected)
 
@@ -9665,7 +9665,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_cumsum_corner(self):
         dm = DataFrame(np.arange(20).reshape(4, 5),
-                       index=list(range(4)), columns=list(range(5)))
+                       index=lrange(4), columns=lrange(5))
         result = dm.cumsum()
 
     #----------------------------------------------------------------------
@@ -9875,13 +9875,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(rs, xp)
 
         rs = df.reset_index('a', col_fill=None)
-        xp = DataFrame(full, Index(list(range(3)), name='d'),
+        xp = DataFrame(full, Index(lrange(3), name='d'),
                        columns=[['a', 'b', 'b', 'c'],
                                 ['a', 'mean', 'median', 'mean']])
         assert_frame_equal(rs, xp)
 
         rs = df.reset_index('a', col_fill='blah', col_level=1)
-        xp = DataFrame(full, Index(list(range(3)), name='d'),
+        xp = DataFrame(full, Index(lrange(3), name='d'),
                        columns=[['blah', 'b', 'b', 'c'],
                                 ['a', 'mean', 'median', 'mean']])
         assert_frame_equal(rs, xp)
@@ -10156,7 +10156,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_xs_view(self):
         dm = DataFrame(np.arange(20.).reshape(4, 5),
-                       index=list(range(4)), columns=list(range(5)))
+                       index=lrange(4), columns=lrange(5))
 
         dm.xs(2, copy=False)[:] = 5
         self.assert_((dm.xs(2) == 5).all())
@@ -10174,7 +10174,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_((dm.xs(3) == 10).all())
 
     def test_boolean_indexing(self):
-        idx = list(range(3))
+        idx = lrange(3)
         cols = ['A','B','C']
         df1 = DataFrame(index=idx, columns=cols,
                         data=np.array([[0.0, 0.5, 1.0],
@@ -10220,15 +10220,15 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertRaises(ValueError, df.__setitem__, df>0.3, 1)
 
     def test_sum_bools(self):
-        df = DataFrame(index=list(range(1)), columns=list(range(10)))
+        df = DataFrame(index=lrange(1), columns=lrange(10))
         bools = isnull(df)
         self.assert_(bools.sum(axis=1)[0] == 10)
 
     def test_fillna_col_reordering(self):
-        idx = list(range(20))
+        idx = lrange(20)
         cols = ["COL." + str(i) for i in range(5, 0, -1)]
         data = np.random.rand(20, 5)
-        df = DataFrame(index=list(range(20)), columns=cols, data=data)
+        df = DataFrame(index=lrange(20), columns=cols, data=data)
         filled = df.fillna(method='ffill')
         self.assert_(df.columns.tolist() == filled.columns.tolist())
 
@@ -10355,8 +10355,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         result = A.dot(b)
 
         # unaligned
-        df = DataFrame(randn(3, 4), index=[1, 2, 3], columns=list(range(4)))
-        df2 = DataFrame(randn(5, 3), index=list(range(5)), columns=[1, 2, 3])
+        df = DataFrame(randn(3, 4), index=[1, 2, 3], columns=lrange(4))
+        df2 = DataFrame(randn(5, 3), index=lrange(5), columns=[1, 2, 3])
 
         self.assertRaises(ValueError, df.dot, df2)
 
diff --git a/pandas/tests/test_graphics.py b/pandas/tests/test_graphics.py
index ebc00bb7c..c03041e39 100644
--- a/pandas/tests/test_graphics.py
+++ b/pandas/tests/test_graphics.py
@@ -1,4 +1,3 @@
-from pandas.util.py3compat import range
 import nose
 import os
 import string
@@ -7,6 +6,7 @@ import unittest
 from datetime import datetime, date
 
 from pandas import Series, DataFrame, MultiIndex, PeriodIndex, date_range
+from pandas.util.py3compat import range, lrange, StringIO, lmap, lzip
 import pandas.util.testing as tm
 from pandas.util.testing import ensure_clean
 from pandas.core.config import set_option
@@ -19,8 +19,8 @@ from numpy.testing import assert_array_equal
 from numpy.testing.decorators import slow
 import pandas.tools.plotting as plotting
 import six
-from six.moves import map
-from six.moves import zip
+from pandas.util.py3compat import map
+from pandas.util.py3compat import zip
 
 
 def _skip_if_no_scipy():
@@ -119,7 +119,7 @@ class TestSeriesPlots(unittest.TestCase):
 
         rects = ax.patches
 
-        rgba_colors = list(map(cm.jet, np.linspace(0, 1, 5)))
+        rgba_colors = lmap(cm.jet, np.linspace(0, 1, 5))
         for i, rect in enumerate(rects[::5]):
             xp = rgba_colors[i]
             rs = rect.get_facecolor()
@@ -132,7 +132,7 @@ class TestSeriesPlots(unittest.TestCase):
 
         rects = ax.patches
 
-        rgba_colors = list(map(cm.jet, np.linspace(0, 1, 5)))
+        rgba_colors = lmap(cm.jet, np.linspace(0, 1, 5))
         for i, rect in enumerate(rects[::5]):
             xp = rgba_colors[i]
             rs = rect.get_facecolor()
@@ -275,7 +275,7 @@ class TestSeriesPlots(unittest.TestCase):
 
     @slow
     def test_valid_object_plot(self):
-        s = Series(list(range(10)), dtype=object)
+        s = Series(lrange(10), dtype=object)
         kinds = 'line', 'bar', 'barh', 'kde', 'density'
 
         for kind in kinds:
@@ -331,7 +331,7 @@ class TestDataFramePlots(unittest.TestCase):
         _check_plot_works(df.plot, subplots=True, title='blah')
         _check_plot_works(df.plot, title='blah')
 
-        tuples = list(zip(string.ascii_letters[:10], range(10)))
+        tuples = lzip(string.ascii_letters[:10], range(10))
         df = DataFrame(np.random.rand(10, 3),
                        index=MultiIndex.from_tuples(tuples))
         _check_plot_works(df.plot, use_index=True)
@@ -388,7 +388,7 @@ class TestDataFramePlots(unittest.TestCase):
         self._check_data(df.plot(y='B'), df.B.plot())
 
         # columns.inferred_type == 'integer'
-        df.columns = list(range(1, len(df.columns) + 1))
+        df.columns = lrange(1, len(df.columns) + 1)
         self._check_data(df.plot(x=1, y=2),
                          df.set_index(1)[2].plot())
         self._check_data(df.plot(x=1), df.set_index(1).plot())
@@ -501,7 +501,7 @@ class TestDataFramePlots(unittest.TestCase):
 
         df = DataFrame(np.random.randn(10, 15),
                        index=list(string.ascii_letters[:10]),
-                       columns=list(range(15)))
+                       columns=lrange(15))
         _check_plot_works(df.plot, kind='bar')
 
         df = DataFrame({'a': [0, 1], 'b': [1, 0]})
@@ -509,13 +509,13 @@ class TestDataFramePlots(unittest.TestCase):
 
     def test_bar_stacked_center(self):
         # GH2157
-        df = DataFrame({'A': [3] * 5, 'B': list(range(5))}, index=list(range(5)))
+        df = DataFrame({'A': [3] * 5, 'B': lrange(5)}, index=lrange(5))
         ax = df.plot(kind='bar', stacked='True', grid=True)
         self.assertEqual(ax.xaxis.get_ticklocs()[0],
                          ax.patches[0].get_x() + ax.patches[0].get_width() / 2)
 
     def test_bar_center(self):
-        df = DataFrame({'A': [3] * 5, 'B': list(range(5))}, index=list(range(5)))
+        df = DataFrame({'A': [3] * 5, 'B': lrange(5)}, index=lrange(5))
         ax = df.plot(kind='bar', grid=True)
         self.assertEqual(ax.xaxis.get_ticklocs()[0],
                          ax.patches[0].get_x() + ax.patches[0].get_width())
@@ -525,7 +525,7 @@ class TestDataFramePlots(unittest.TestCase):
         # GH3254, GH3298 matplotlib/matplotlib#1882, #1892
         # regressions in 1.2.1
 
-        df = DataFrame({'A': [3] * 5, 'B': list(range(1, 6))}, index=list(range(5)))
+        df = DataFrame({'A': [3] * 5, 'B': lrange(1, 6)}, index=lrange(5))
         ax = df.plot(kind='bar', grid=True, log=True)
         self.assertEqual(ax.yaxis.get_ticklocs()[0], 1.0)
 
@@ -769,7 +769,6 @@ class TestDataFramePlots(unittest.TestCase):
     def test_line_colors(self):
         import matplotlib.pyplot as plt
         import sys
-        from pandas.util.py3compat import StringIO
         from matplotlib import cm
 
         custom_colors = 'rgcby'
@@ -800,7 +799,7 @@ class TestDataFramePlots(unittest.TestCase):
 
         ax = df.plot(colormap='jet')
 
-        rgba_colors = list(map(cm.jet, np.linspace(0, 1, len(df))))
+        rgba_colors = lmap(cm.jet, np.linspace(0, 1, len(df)))
 
         lines = ax.get_lines()
         for i, l in enumerate(lines):
@@ -812,7 +811,7 @@ class TestDataFramePlots(unittest.TestCase):
 
         ax = df.plot(colormap=cm.jet)
 
-        rgba_colors = list(map(cm.jet, np.linspace(0, 1, len(df))))
+        rgba_colors = lmap(cm.jet, np.linspace(0, 1, len(df)))
 
         lines = ax.get_lines()
         for i, l in enumerate(lines):
@@ -891,7 +890,7 @@ class TestDataFrameGroupByPlots(unittest.TestCase):
         _check_plot_works(grouped.boxplot)
         _check_plot_works(grouped.boxplot, subplots=False)
 
-        tuples = list(zip(string.ascii_letters[:10], range(10)))
+        tuples = lzip(string.ascii_letters[:10], range(10))
         df = DataFrame(np.random.rand(10, 3),
                        index=MultiIndex.from_tuples(tuples))
         grouped = df.groupby(level=1)
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 9fe98e27c..005babf6f 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1,7 +1,7 @@
 from __future__ import print_function
-from pandas.util.py3compat import range, long
+from pandas.util.py3compat import range, long, lrange, StringIO, lmap, lzip
 from pandas.util import compat
-from six.moves import map, zip, builtins
+from pandas.util.py3compat import map, zip, builtins
 import nose
 import unittest
 
@@ -193,9 +193,9 @@ class TestGroupBy(unittest.TestCase):
         assert_frame_equal(nth, expected, check_names=False)
 
         # GH 2763, first/last shifting dtypes
-        idx = list(range(10))
+        idx = lrange(10)
         idx.append(9)
-        s = Series(data=list(range(11)), index=idx, name='IntCol')
+        s = Series(data=lrange(11), index=idx, name='IntCol')
         self.assert_(s.dtype == 'int64')
         f = s.groupby(level=0).first()
         self.assert_(f.dtype == 'int64')
@@ -267,7 +267,7 @@ class TestGroupBy(unittest.TestCase):
 
         # GH 3911, mixed frame non-conversion
         df = self.df_mixed_floats.copy()
-        df['value'] = list(range(len(df)))
+        df['value'] = lrange(len(df))
 
         def max_value(group):
             return group.ix[group['value'].idxmax()]
@@ -512,11 +512,11 @@ class TestGroupBy(unittest.TestCase):
 
     def test_basic_regression(self):
         # regression
-        T = [1.0 * x for x in list(range(1, 10)) * 10][:1095]
-        result = Series(T, list(range(0, len(T))))
+        T = [1.0 * x for x in lrange(1, 10) * 10][:1095]
+        result = Series(T, lrange(0, len(T)))
 
         groupings = np.random.random((1100,))
-        groupings = Series(groupings, list(range(0, len(groupings)))) * 10.
+        groupings = Series(groupings, lrange(0, len(groupings))) * 10.
 
         grouped = result.groupby(groupings)
         grouped.mean()
@@ -711,12 +711,12 @@ class TestGroupBy(unittest.TestCase):
                 return y
 
         df = DataFrame({'a':[1,2,2,2],
-                        'b':list(range(4)),
-                        'c':list(range(5,9))})
+                        'b':lrange(4),
+                        'c':lrange(5,9)})
 
         df2 = DataFrame({'a':[3,2,2,2],
-                         'b':list(range(4)),
-                         'c':list(range(5,9))})
+                         'b':lrange(4),
+                         'c':lrange(5,9)})
 
 
         # correct result
@@ -1157,7 +1157,7 @@ class TestGroupBy(unittest.TestCase):
         result = grouped.mean()
         expected = data.groupby(['A', 'B']).mean()
 
-        arrays = list(zip(*expected.index._tuple_index))
+        arrays = lzip(*expected.index._tuple_index)
         expected.insert(0, 'A', arrays[0])
         expected.insert(1, 'B', arrays[1])
         expected.index = np.arange(len(expected))
@@ -1420,7 +1420,7 @@ class TestGroupBy(unittest.TestCase):
 
     def test_groupby_level_index_names(self):
         ## GH4014 this used to raise ValueError since 'exp'>1 (in py2)
-        df = DataFrame({'exp' : ['A']*3 + ['B']*3, 'var1' : list(range(6)),}).set_index('exp')
+        df = DataFrame({'exp' : ['A']*3 + ['B']*3, 'var1' : lrange(6),}).set_index('exp')
         df.groupby(level='exp')
         self.assertRaises(ValueError, df.groupby, level='foo')
 
@@ -1569,7 +1569,7 @@ class TestGroupBy(unittest.TestCase):
         mydf = DataFrame({
                 'cat1' : ['a'] * 8 + ['b'] * 6,
                 'cat2' : ['c'] * 2 + ['d'] * 2 + ['e'] * 2 + ['f'] * 2 + ['c'] * 2 + ['d'] * 2 + ['e'] * 2,
-                'cat3' : list(map(lambda x: 'g%s' % x, list(range(1,15)))),
+                'cat3' : lmap(lambda x: 'g%s' % x, lrange(1,15)),
                 'val' : np.random.randint(100, size=14),
                 })
 
@@ -1589,7 +1589,7 @@ class TestGroupBy(unittest.TestCase):
     def test_apply_chunk_view(self):
         # Low level tinkering could be unsafe, make sure not
         df = DataFrame({'key': [1, 1, 1, 2, 2, 2, 3, 3, 3],
-                        'value': list(range(9))})
+                        'value': lrange(9)})
 
         # return view
         f = lambda x: x[:2]
@@ -1601,7 +1601,7 @@ class TestGroupBy(unittest.TestCase):
     def test_apply_no_name_column_conflict(self):
         df = DataFrame({'name': [1, 1, 1, 1, 1, 1, 2, 2, 2, 2],
                         'name2': [0, 0, 0, 1, 1, 1, 0, 0, 1, 1],
-                        'value': list(range(10))[::-1]})
+                        'value': lrange(10)[::-1]})
 
         # it works! #2605
         grouped = df.groupby(['name', 'name2'])
@@ -1814,7 +1814,6 @@ class TestGroupBy(unittest.TestCase):
 
     def test_groupby_wrong_multi_labels(self):
         from pandas import read_csv
-        from pandas.util.py3compat import StringIO
         data = """index,foo,bar,baz,spam,data
 0,foo1,bar1,baz1,spam2,20
 1,foo1,bar2,baz1,spam3,30
@@ -1853,8 +1852,8 @@ class TestGroupBy(unittest.TestCase):
     def test_cython_grouper_series_bug_noncontig(self):
         arr = np.empty((100, 100))
         arr.fill(np.nan)
-        obj = Series(arr[:, 0], index=list(range(100)))
-        inds = np.tile(list(range(10)), 10)
+        obj = Series(arr[:, 0], index=lrange(100))
+        inds = np.tile(lrange(10), 10)
 
         result = obj.groupby(inds).agg(Series.median)
         self.assert_(result.isnull().all())
@@ -1876,7 +1875,7 @@ class TestGroupBy(unittest.TestCase):
 
         from decimal import Decimal
 
-        s = Series(list(range(5)))
+        s = Series(lrange(5))
         labels = np.array(['a', 'b', 'c', 'd', 'e'], dtype='O')
 
         def convert_fast(x):
@@ -1991,7 +1990,7 @@ class TestGroupBy(unittest.TestCase):
         assert_almost_equal(result, expected)
 
     def test_groupby_2d_malformed(self):
-        d = DataFrame(index=list(range(2)))
+        d = DataFrame(index=lrange(2))
         d['group'] = ['g1', 'g2']
         d['zeros'] = [0, 0]
         d['ones'] = [1, 1]
@@ -2050,18 +2049,18 @@ class TestGroupBy(unittest.TestCase):
                         'c': [0, 1, 2],
                         'd': np.random.randn(3)})
 
-        tups = list(map(tuple, df[['a', 'b', 'c']].values))
+        tups = lmap(tuple, df[['a', 'b', 'c']].values)
         tups = com._asarray_tuplesafe(tups)
         result = df.groupby(['a', 'b', 'c'], sort=True).sum()
         self.assert_(np.array_equal(result.index.values,
                                     tups[[1, 2, 0]]))
 
-        tups = list(map(tuple, df[['c', 'a', 'b']].values))
+        tups = lmap(tuple, df[['c', 'a', 'b']].values)
         tups = com._asarray_tuplesafe(tups)
         result = df.groupby(['c', 'a', 'b'], sort=True).sum()
         self.assert_(np.array_equal(result.index.values, tups))
 
-        tups = list(map(tuple, df[['b', 'c', 'a']].values))
+        tups = lmap(tuple, df[['b', 'c', 'a']].values)
         tups = com._asarray_tuplesafe(tups)
         result = df.groupby(['b', 'c', 'a'], sort=True).sum()
         self.assert_(np.array_equal(result.index.values,
@@ -2676,7 +2675,7 @@ def assert_fp_equal(a, b):
 
 
 def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
-    tups = list(map(tuple, df[keys].values))
+    tups = lmap(tuple, df[keys].values)
     tups = com._asarray_tuplesafe(tups)
     expected = f(df.groupby(tups)[field])
     for k, v in compat.iteritems(expected):
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index d77c60ecb..4dae4378c 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -1,7 +1,7 @@
 # pylint: disable=E1101,E1103,W0232
 
 from datetime import datetime, timedelta
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, lzip
 import operator
 import pickle
 import unittest
@@ -24,7 +24,7 @@ import pandas.tseries.offsets as offsets
 import pandas as pd
 from pandas.lib import Timestamp
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 
 class TestIndex(unittest.TestCase):
@@ -37,7 +37,7 @@ class TestIndex(unittest.TestCase):
         self.intIndex = tm.makeIntIndex(100)
         self.floatIndex = tm.makeFloatIndex(100)
         self.empty = Index([])
-        self.tuples = Index(list(zip(['foo', 'bar', 'baz'], [1, 2, 3])))
+        self.tuples = Index(lzip(['foo', 'bar', 'baz'], [1, 2, 3]))
 
     def test_hash_error(self):
         self.assertRaises(TypeError, hash, self.strIndex)
@@ -470,8 +470,8 @@ class TestIndex(unittest.TestCase):
     def test_drop(self):
         n = len(self.strIndex)
 
-        dropped = self.strIndex.drop(self.strIndex[list(range(5, 10))])
-        expected = self.strIndex[list(range(5)) + list(range(10, n))]
+        dropped = self.strIndex.drop(self.strIndex[lrange(5, 10)])
+        expected = self.strIndex[lrange(5) + lrange(10, n)]
         self.assert_(dropped.equals(expected))
 
         self.assertRaises(ValueError, self.strIndex.drop, ['foo', 'bar'])
@@ -893,8 +893,8 @@ class TestInt64Index(unittest.TestCase):
     def test_int_name_format(self):
         from pandas import Series, DataFrame
         index = Index(['a', 'b', 'c'], name=0)
-        s = Series(list(range(3)), index)
-        df = DataFrame(list(range(3)), index=index)
+        s = Series(lrange(3), index)
+        df = DataFrame(lrange(3), index=index)
         repr(s)
         repr(df)
 
@@ -910,7 +910,7 @@ class TestInt64Index(unittest.TestCase):
             self.assertTrue("..." in r)
 
     def test_unicode_string_with_unicode(self):
-        idx = Index(list(range(1000)))
+        idx = Index(lrange(1000))
 
         if py3compat.PY3:
             str(idx)
@@ -918,7 +918,7 @@ class TestInt64Index(unittest.TestCase):
             six.text_type(idx)
 
     def test_bytestring_with_unicode(self):
-        idx = Index(list(range(1000)))
+        idx = Index(lrange(1000))
         if py3compat.PY3:
             bytes(idx)
         else:
@@ -1154,9 +1154,9 @@ class TestMultiIndex(unittest.TestCase):
         self.assertRaises(KeyError, self.index.get_loc, 'quux')
 
         # 3 levels
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])])
@@ -1176,9 +1176,9 @@ class TestMultiIndex(unittest.TestCase):
         assert(rs == xp)
 
     def test_get_loc_level(self):
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])])
@@ -1196,7 +1196,7 @@ class TestMultiIndex(unittest.TestCase):
 
         self.assertRaises(KeyError, index.get_loc_level, (2, 2))
 
-        index = MultiIndex(levels=[[2000], list(range(4))],
+        index = MultiIndex(levels=[[2000], lrange(4)],
                            labels=[np.array([0, 0, 0, 0]),
                                    np.array([0, 1, 2, 3])])
         result, new_index = index.get_loc_level((2000, slice(None, None)))
@@ -1222,9 +1222,9 @@ class TestMultiIndex(unittest.TestCase):
         tm.assert_almost_equal(sliced.values, expected.values)
 
     def test_slice_locs_not_sorted(self):
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])])
@@ -1279,11 +1279,11 @@ class TestMultiIndex(unittest.TestCase):
 
     def test_consistency(self):
         # need to construct an overflow
-        major_axis = list(range(70000))
-        minor_axis = list(range(10))
+        major_axis = lrange(70000)
+        minor_axis = lrange(10)
 
         major_labels = np.arange(70000)
-        minor_labels = np.repeat(list(range(10)), 7000)
+        minor_labels = np.repeat(lrange(10), 7000)
 
         # the fact that is works means it's consistent
         index = MultiIndex(levels=[major_axis, minor_axis],
@@ -1298,8 +1298,8 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(not index.is_unique)
 
     def test_truncate(self):
-        major_axis = Index(list(range(4)))
-        minor_axis = Index(list(range(2)))
+        major_axis = Index(lrange(4))
+        minor_axis = Index(lrange(2))
 
         major_labels = np.array([0, 0, 1, 2, 3, 3])
         minor_labels = np.array([0, 1, 0, 1, 0, 1])
@@ -1322,8 +1322,8 @@ class TestMultiIndex(unittest.TestCase):
         self.assertRaises(ValueError, index.truncate, 3, 1)
 
     def test_get_indexer(self):
-        major_axis = Index(list(range(4)))
-        minor_axis = Index(list(range(2)))
+        major_axis = Index(lrange(4))
+        minor_axis = Index(lrange(2))
 
         major_labels = np.array([0, 0, 1, 2, 2, 3, 3])
         minor_labels = np.array([0, 1, 0, 0, 1, 0, 1])
@@ -1405,9 +1405,9 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(self.index.equals(self.index._tuple_index))
 
         # different number of levels
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])])
@@ -1418,8 +1418,8 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(not index.equal_levels(index2))
 
         # levels are different
-        major_axis = Index(list(range(4)))
-        minor_axis = Index(list(range(2)))
+        major_axis = Index(lrange(4))
+        minor_axis = Index(lrange(2))
 
         major_labels = np.array([0, 0, 1, 2, 2, 3])
         minor_labels = np.array([0, 1, 0, 0, 1, 0])
@@ -1638,9 +1638,9 @@ class TestMultiIndex(unittest.TestCase):
         dropped = index.droplevel(0)
         self.assertEqual(dropped.name, 'second')
 
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])],
@@ -1653,9 +1653,9 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(dropped.equals(expected))
 
     def test_droplevel_multiple(self):
-        index = MultiIndex(levels=[Index(list(range(4))),
-                                   Index(list(range(4))),
-                                   Index(list(range(4)))],
+        index = MultiIndex(levels=[Index(lrange(4)),
+                                   Index(lrange(4)),
+                                   Index(lrange(4))],
                            labels=[np.array([0, 0, 1, 2, 2, 2, 3, 3]),
                                    np.array([0, 1, 0, 0, 0, 1, 0, 1]),
                                    np.array([1, 0, 1, 1, 0, 0, 1, 0])],
diff --git a/pandas/tests/test_indexing.py b/pandas/tests/test_indexing.py
index b7297fc86..a053b43f1 100644
--- a/pandas/tests/test_indexing.py
+++ b/pandas/tests/test_indexing.py
@@ -1,10 +1,9 @@
 # pylint: disable-msg=W0612,E1101
-from pandas.util.py3compat import range
 import unittest
 import nose
 import itertools
-from pandas.util.py3compat import StringIO
 
+from pandas.util.py3compat import range, lrange, StringIO, lmap
 from numpy import random, nan
 from numpy.random import randn
 import numpy as np
@@ -22,7 +21,7 @@ import pandas.util.testing as tm
 import pandas.lib as lib
 from pandas import date_range
 from numpy.testing.decorators import slow
-from six.moves import map
+from pandas.util.py3compat import map
 
 _verbose = False
 
@@ -38,7 +37,7 @@ def _generate_indices(f, values=False):
 
     axes = f.axes
     if values:
-        axes = [ list(range(len(a))) for a in axes ]
+        axes = [ lrange(len(a)) for a in axes ]
 
     return itertools.product(*axes)
 
@@ -96,9 +95,9 @@ class TestIndexing(unittest.TestCase):
         import warnings
         warnings.filterwarnings(action='ignore', category=FutureWarning)
 
-        self.series_ints   = Series(np.random.rand(4), index=list(range(0,8,2)))
-        self.frame_ints    = DataFrame(np.random.randn(4, 4), index=list(range(0, 8, 2)), columns=list(range(0,12,3)))
-        self.panel_ints    = Panel(np.random.rand(4,4,4), items=list(range(0,8,2)),major_axis=list(range(0,12,3)),minor_axis=list(range(0,16,4)))
+        self.series_ints = Series(np.random.rand(4), index=lrange(0,8,2))
+        self.frame_ints = DataFrame(np.random.randn(4, 4), index=lrange(0, 8, 2), columns=lrange(0,12,3))
+        self.panel_ints = Panel(np.random.rand(4,4,4), items=lrange(0,8,2),major_axis=lrange(0,12,3),minor_axis=lrange(0,16,4))
 
         self.series_labels = Series(np.random.randn(4), index=list('abcd'))
         self.frame_labels  = DataFrame(np.random.randn(4, 4), index=list('abcd'), columns=list('ABCD'))
@@ -344,7 +343,7 @@ class TestIndexing(unittest.TestCase):
     def test_iloc_getitem_array(self):
 
         # array like
-        s = Series(index=list(range(1,4)))
+        s = Series(index=lrange(1,4))
         self.check_result('array like', 'iloc', s.index, 'ix', { 0 : [2,4,6], 1 : [3,6,9], 2: [4,8,12] }, typs = ['ints'])
 
     def test_iloc_getitem_bool(self):
@@ -549,7 +548,7 @@ class TestIndexing(unittest.TestCase):
 
     def test_iloc_getitem_frame(self):
         """ originally from test_frame.py"""
-        df = DataFrame(np.random.randn(10, 4), index=list(range(0, 20, 2)), columns=list(range(0,8,2)))
+        df = DataFrame(np.random.randn(10, 4), index=lrange(0, 20, 2), columns=lrange(0,8,2))
 
         result = df.iloc[2]
         exp = df.ix[4]
@@ -588,7 +587,7 @@ class TestIndexing(unittest.TestCase):
         assert_frame_equal(result, expected)
 
         # with index-like
-        s = Series(index=list(range(1,5)))
+        s = Series(index=lrange(1,5))
         result = df.iloc[s.index]
         expected = df.ix[[2,4,6,8]]
         assert_frame_equal(result, expected)
@@ -635,7 +634,7 @@ class TestIndexing(unittest.TestCase):
         assert_frame_equal(result, expected)
 
     def test_iloc_setitem_series(self):
-        s = Series(np.random.randn(10), index=list(range(0,20,2)))
+        s = Series(np.random.randn(10), index=lrange(0,20,2))
 
         s.iloc[1] = 1
         result = s.iloc[1]
@@ -798,7 +797,7 @@ class TestIndexing(unittest.TestCase):
 
         # GH 3561, dups not in selected order
         ind = ['A', 'A', 'B', 'C']
-        df = DataFrame({'test':list(range(len(ind)))}, index=ind)
+        df = DataFrame({'test':lrange(len(ind))}, index=ind)
         rows = ['C', 'B']
         res = df.ix[rows]
         self.assert_(rows == list(res.index))
@@ -880,8 +879,8 @@ class TestIndexing(unittest.TestCase):
         # GH 3626, an assignement of a sub-df to a df
         df = DataFrame({'FC':['a','b','a','b','a','b'],
                         'PF':[0,0,0,0,1,1],
-                        'col1':list(range(6)),
-                        'col2':list(range(6,12))})
+                        'col1':lrange(6),
+                        'col2':lrange(6,12)})
         df.ix[1,0]=np.nan
         df2 = df.copy()
 
@@ -920,7 +919,7 @@ class TestIndexing(unittest.TestCase):
         assert_series_equal(df.B, orig + 1)
 
         # GH 3668, mixed frame with series value
-        df = DataFrame({'x':list(range(10)), 'y':list(range(10,20)),'z' : 'bar'})
+        df = DataFrame({'x':lrange(10), 'y':lrange(10,20),'z' : 'bar'})
         expected = df.copy()
         expected.ix[0, 'y'] = 1000
         expected.ix[2, 'y'] = 1200
@@ -934,10 +933,10 @@ class TestIndexing(unittest.TestCase):
     def test_iloc_mask(self):
 
         # GH 3631, iloc with a mask (of a series) should raise
-        df = DataFrame(list(range(5)), list('ABCDE'), columns=['a'])
+        df = DataFrame(lrange(5), list('ABCDE'), columns=['a'])
         mask = (df.a%2 == 0)
         self.assertRaises(ValueError, df.iloc.__getitem__, tuple([mask]))
-        mask.index = list(range(len(mask)))
+        mask.index = lrange(len(mask))
         self.assertRaises(NotImplementedError, df.iloc.__getitem__, tuple([mask]))
 
         # ndarray ok
@@ -947,7 +946,7 @@ class TestIndexing(unittest.TestCase):
         # the possibilities
         locs = np.arange(4)
         nums = 2**locs
-        reps = list(map(bin, nums))
+        reps = lmap(bin, nums)
         df = DataFrame({'locs':locs, 'nums':nums}, reps)
 
         expected = {
@@ -1044,7 +1043,7 @@ class TestIndexing(unittest.TestCase):
 
         #GH 4017, non-unique indexing (on the axis)
         df = DataFrame({'A' : [0.1] * 3000, 'B' : [1] * 3000})
-        idx = np.array(list(range(30))) * 99
+        idx = np.array(lrange(30)) * 99
         expected = df.iloc[idx]
 
         df3 = pd.concat([df, 2*df, 3*df])
@@ -1111,7 +1110,7 @@ class TestIndexing(unittest.TestCase):
 
         columns = list('ABCDEFG')
         def gen_test(l,l2):
-            return pd.concat([ DataFrame(randn(l,len(columns)),index=list(range(l)),columns=columns),
+            return pd.concat([ DataFrame(randn(l,len(columns)),index=lrange(l),columns=columns),
                                DataFrame(np.ones((l2,len(columns))),index=[0]*l2,columns=columns) ])
 
 
diff --git a/pandas/tests/test_internals.py b/pandas/tests/test_internals.py
index b1d29a97b..9d2439b7c 100644
--- a/pandas/tests/test_internals.py
+++ b/pandas/tests/test_internals.py
@@ -12,7 +12,7 @@ import pandas.util.testing as tm
 from pandas.util.testing import (
     assert_almost_equal, assert_frame_equal, randn)
 import six
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 
 def assert_block_equal(left, right):
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index 82f1fa824..ea2ab8a1d 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -13,14 +13,13 @@ from pandas.util.testing import (assert_almost_equal,
                                  assert_frame_equal)
 import pandas.core.common as com
 import pandas.util.testing as tm
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, StringIO, lzip
 from pandas.util.compat import product as cart_product
 import pandas as pd
 
 import pandas.index as _index
 import six
-from six.moves import zip, cPickle
+from pandas.util.py3compat import zip, cPickle
 
 
 class TestMultiLevel(unittest.TestCase):
@@ -46,7 +45,7 @@ class TestMultiLevel(unittest.TestCase):
         # create test series object
         arrays = [['bar', 'bar', 'baz', 'baz', 'qux', 'qux', 'foo', 'foo'],
                   ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]
-        tuples = list(zip(*arrays))
+        tuples = lzip(*arrays)
         index = MultiIndex.from_tuples(tuples)
         s = Series(randn(8), index=index)
         s[3] = np.NaN
@@ -92,7 +91,7 @@ class TestMultiLevel(unittest.TestCase):
                                   ['x', 'y', 'x', 'y']])
         tm.assert_isinstance(multi.index, MultiIndex)
 
-        multi = Series(list(range(4)), index=[['a', 'a', 'b', 'b'],
+        multi = Series(lrange(4), index=[['a', 'a', 'b', 'b'],
                                         ['x', 'y', 'x', 'y']])
         tm.assert_isinstance(multi.index, MultiIndex)
 
@@ -351,8 +350,8 @@ class TestMultiLevel(unittest.TestCase):
 
     def test_getitem_tuple_plus_slice(self):
         # GH #671
-        df = DataFrame({'a': list(range(10)),
-                        'b': list(range(10)),
+        df = DataFrame({'a': lrange(10),
+                        'b': lrange(10),
                         'c': np.random.randn(10),
                         'd': np.random.randn(10)})
 
@@ -431,7 +430,7 @@ class TestMultiLevel(unittest.TestCase):
 
     def test_xs_level_multiple(self):
         from pandas import read_table
-        from pandas.util.py3compat import StringIO
+        from pandas.util.py3compat import StringIO, lrange, lzip
         text = """                      A       B       C       D        E
 one two three   four
 a   b   10.0032 5    -0.5109 -2.3358 -0.4645  0.05076  0.3640
@@ -445,7 +444,7 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
         assert_frame_equal(result, expected)
 
         # GH2107
-        dates = list(range(20111201, 20111205))
+        dates = lrange(20111201, 20111205)
         ids = 'abcde'
         idx = MultiIndex.from_tuples([x for x in cart_product(dates, ids)])
         idx.names = ['date', 'secid']
@@ -456,7 +455,7 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
 
     def test_xs_level0(self):
         from pandas import read_table
-        from pandas.util.py3compat import StringIO
+        from pandas.util.py3compat import StringIO, lrange, lzip
         text = """                      A       B       C       D        E
 one two three   four
 a   b   10.0032 5    -0.5109 -2.3358 -0.4645  0.05076  0.3640
@@ -590,7 +589,7 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
 
         # with integer labels
         df = self.frame.copy()
-        df.columns = list(range(3))
+        df.columns = lrange(3)
         df.ix[('bar', 'two'), 1] = 7
         self.assertEquals(df.ix[('bar', 'two'), 1], 7)
 
@@ -1169,7 +1168,7 @@ Thur,Lunch,Yes,51.51,17"""
     def test_series_getitem_not_sorted(self):
         arrays = [['bar', 'bar', 'baz', 'baz', 'qux', 'qux', 'foo', 'foo'],
                  ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]
-        tuples = list(zip(*arrays))
+        tuples = lzip(*arrays)
         index = MultiIndex.from_tuples(tuples)
         s = Series(randn(8), index=index)
 
@@ -1213,7 +1212,7 @@ Thur,Lunch,Yes,51.51,17"""
 
     def test_series_group_min_max(self):
         for op, level, skipna in cart_product(self.AGG_FUNCTIONS,
-                                              list(range(2)),
+                                              lrange(2),
                                               [False, True]):
             grouped = self.series.groupby(level=level)
             aggf = lambda x: getattr(x, op)(skipna=skipna)
@@ -1227,7 +1226,7 @@ Thur,Lunch,Yes,51.51,17"""
         self.frame.ix[7, [0, 1]] = np.nan
 
         for op, level, axis, skipna in cart_product(self.AGG_FUNCTIONS,
-                                                    list(range(2)), list(range(2)),
+                                                    lrange(2), lrange(2),
                                                     [False, True]):
             if axis == 0:
                 frame = self.frame
@@ -1689,7 +1688,7 @@ Thur,Lunch,Yes,51.51,17"""
         index = MultiIndex.from_tuples([(0, 0), (1, 1)],
                                        names=[six.u('\u0394'), 'i1'])
 
-        s = Series(list(range(2)), index=index)
+        s = Series(lrange(2), index=index)
         df = DataFrame(np.random.randn(2, 4), index=index)
         repr(s)
         repr(df)
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 1d9707858..5fdb48780 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -1,7 +1,7 @@
 # pylint: disable=W0612,E1101
 
 from datetime import datetime
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange, StringIO
 from pandas.util import compat
 import operator
 import unittest
@@ -16,7 +16,7 @@ from pandas.core.panel import Panel
 from pandas.core.series import remove_na
 import pandas.core.common as com
 from pandas.util import py3compat
-from six.moves import cPickle
+from pandas.util.py3compat import cPickle
 
 from pandas.util.testing import (assert_panel_equal,
                                  assert_frame_equal,
@@ -392,7 +392,7 @@ class CheckIndexing(object):
         values[1] = 1
         values[2] = 2
 
-        panel = Panel(values, list(range(3)), list(range(3)), list(range(3)))
+        panel = Panel(values, lrange(3), lrange(3), lrange(3))
 
         # did we delete the right row?
 
@@ -813,8 +813,8 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
 
     def test_constructor_observe_dtype(self):
         # GH #411
-        panel = Panel(items=list(range(3)), major_axis=list(range(3)),
-                      minor_axis=list(range(3)), dtype='O')
+        panel = Panel(items=lrange(3), major_axis=lrange(3),
+                      minor_axis=lrange(3), dtype='O')
         self.assert_(panel.values.dtype == np.object_)
 
     def test_constructor_dtypes(self):
@@ -826,19 +826,19 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
 
         # only nan holding types allowed here
         for dtype in ['float64','float32','object']:
-            panel = Panel(items=list(range(2)),major_axis=list(range(10)),minor_axis=list(range(5)),dtype=dtype)
+            panel = Panel(items=lrange(2),major_axis=lrange(10),minor_axis=lrange(5),dtype=dtype)
             _check_dtype(panel,dtype)
 
         for dtype in ['float64','float32','int64','int32','object']:
-            panel = Panel(np.array(np.random.randn(2,10,5),dtype=dtype),items=list(range(2)),major_axis=list(range(10)),minor_axis=list(range(5)),dtype=dtype)
+            panel = Panel(np.array(np.random.randn(2,10,5),dtype=dtype),items=lrange(2),major_axis=lrange(10),minor_axis=lrange(5),dtype=dtype)
             _check_dtype(panel,dtype)
 
         for dtype in ['float64','float32','int64','int32','object']:
-            panel = Panel(np.array(np.random.randn(2,10,5),dtype='O'),items=list(range(2)),major_axis=list(range(10)),minor_axis=list(range(5)),dtype=dtype)
+            panel = Panel(np.array(np.random.randn(2,10,5),dtype='O'),items=lrange(2),major_axis=lrange(10),minor_axis=lrange(5),dtype=dtype)
             _check_dtype(panel,dtype)
 
         for dtype in ['float64','float32','int64','int32','object']:
-            panel = Panel(np.random.randn(2,10,5),items=list(range(2)),major_axis=list(range(10)),minor_axis=list(range(5)),dtype=dtype)
+            panel = Panel(np.random.randn(2,10,5),items=lrange(2),major_axis=lrange(10),minor_axis=lrange(5),dtype=dtype)
             _check_dtype(panel,dtype)
 
     def test_consolidate(self):
@@ -963,15 +963,15 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
     def test_constructor_error_msgs(self):
 
         def testit():
-            Panel(np.random.randn(3,4,5), list(range(4)), list(range(5)), list(range(5)))
+            Panel(np.random.randn(3,4,5), lrange(4), lrange(5), lrange(5))
         assertRaisesRegexp(ValueError, "Shape of passed values is \(3, 4, 5\), indices imply \(4, 5, 5\)", testit)
 
         def testit():
-            Panel(np.random.randn(3,4,5), list(range(5)), list(range(4)), list(range(5)))
+            Panel(np.random.randn(3,4,5), lrange(5), lrange(4), lrange(5))
         assertRaisesRegexp(ValueError, "Shape of passed values is \(3, 4, 5\), indices imply \(5, 4, 5\)", testit)
 
         def testit():
-            Panel(np.random.randn(3,4,5), list(range(5)), list(range(5)), list(range(4)))
+            Panel(np.random.randn(3,4,5), lrange(5), lrange(5), lrange(4))
         assertRaisesRegexp(ValueError, "Shape of passed values is \(3, 4, 5\), indices imply \(5, 5, 4\)", testit)
 
     def test_conform(self):
@@ -1617,8 +1617,6 @@ class TestLongPanel(unittest.TestCase):
         self.assert_(is_sorted(sorted_major.index.labels[0]))
 
     def test_to_string(self):
-        from pandas.util.py3compat import StringIO
-
         buf = StringIO()
         self.panel.to_string(buf)
 
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index a1566bf30..8f5d7641c 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -1,5 +1,5 @@
 from datetime import datetime
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import os
 import operator
 import unittest
@@ -307,7 +307,7 @@ class CheckIndexing(object):
         values[2] = 2
         values[3] = 3
 
-        panel4d = Panel4D(values, list(range(4)), list(range(4)), list(range(4)), list(range(4)))
+        panel4d = Panel4D(values, lrange(4), lrange(4), lrange(4), lrange(4))
 
         # did we delete the right row?
 
@@ -609,8 +609,8 @@ class TestPanel4d(unittest.TestCase, CheckIndexing, SafeForSparse,
 
     def test_constructor_observe_dtype(self):
         # GH #411
-        panel = Panel(items=list(range(3)), major_axis=list(range(3)),
-                      minor_axis=list(range(3)), dtype='O')
+        panel = Panel(items=lrange(3), major_axis=lrange(3),
+                      minor_axis=lrange(3), dtype='O')
         self.assert_(panel.values.dtype == np.object_)
 
     def test_consolidate(self):
@@ -720,7 +720,7 @@ class TestPanel4d(unittest.TestCase, CheckIndexing, SafeForSparse,
 
     def test_values(self):
         self.assertRaises(Exception, Panel, np.random.randn(5, 5, 5),
-                          list(range(5)), list(range(5)), list(range(4)))
+                          lrange(5), lrange(5), lrange(4))
 
     def test_conform(self):
         p = self.panel4d['l1'].filter(items=['ItemA', 'ItemB'])
diff --git a/pandas/tests/test_py3compat.py b/pandas/tests/test_py3compat.py
new file mode 100644
index 000000000..e74b8a86e
--- /dev/null
+++ b/pandas/tests/test_py3compat.py
@@ -0,0 +1,70 @@
+"""
+Testing that functions from py3compat work as expected
+"""
+
+from pandas.util.py3compat import (
+    range, zip, map, filter,
+    lrange, lzip, lmap, lfilter,
+    builtins
+)
+import unittest
+import nose
+import pandas.util.testing as tm
+
+class TestBuiltinIterators(unittest.TestCase):
+    def check_result(self, actual, expected, lengths):
+        for (iter_res, list_res), exp, length in zip(actual, expected, lengths):
+            self.assert_(not isinstance(iter_res, list))
+            tm.assert_isinstance(list_res, list)
+            iter_res = list(iter_res)
+            self.assertEqual(len(list_res), length)
+            self.assertEqual(len(iter_res), length)
+            self.assertEqual(iter_res, exp)
+            self.assertEqual(list_res, exp)
+
+    def test_range(self):
+        actual1 = range(10)
+        actual2 = lrange(10)
+        actual = [actual1, actual2],
+        expected = list(builtins.range(10)),
+        lengths = 10,
+
+        actual1 = range(1, 10, 2)
+        actual2 = lrange(1, 10, 2)
+        actual += [actual1, actual2],
+        lengths += 5,
+        expected += list(builtins.range(1, 10, 2)),
+        self.check_result(actual, expected, lengths)
+
+    def test_map(self):
+        func = lambda x, y, z: x + y + z
+        lst = [builtins.range(10), builtins.range(10), builtins.range(10)]
+        actual1 = map(func, *lst)
+        actual2 = lmap(func, *lst)
+        actual = [actual1, actual2],
+        expected = list(builtins.map(func, *lst)),
+        lengths = 10,
+        self.check_result(actual, expected, lengths)
+
+
+    def test_filter(self):
+        func = lambda x: x
+        lst = list(builtins.range(10))
+        actual1 = filter(func, lst)
+        actual2 = lfilter(func, lst)
+        actual = [actual1, actual2],
+        lengths = 9,
+        expected = list(builtins.filter(func, lst)),
+        self.check_result(actual, expected, lengths)
+
+    def test_zip(self):
+        lst = [builtins.range(10), builtins.range(10), builtins.range(10)]
+        actual = [zip(*lst), lzip(*lst)],
+        expected = list(builtins.zip(*lst)),
+        lengths = 10,
+        self.check_result(actual, expected, lengths)
+
+if __name__ == '__main__':
+    nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
+                   # '--with-coverage', '--cover-package=pandas.core'],
+                   exit=False)
diff --git a/pandas/tests/test_reshape.py b/pandas/tests/test_reshape.py
index 3b34934f1..d0d5f260e 100644
--- a/pandas/tests/test_reshape.py
+++ b/pandas/tests/test_reshape.py
@@ -17,7 +17,7 @@ from pandas.core.reshape import melt, convert_dummies, lreshape
 import pandas.util.testing as tm
 from pandas.util.py3compat import StringIO
 from pandas.util.py3compat import range
-from six.moves import cPickle
+from pandas.util.py3compat import cPickle
 
 _multiprocess_can_split_ = True
 
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 3b7f693c8..5e23efca2 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1,9 +1,6 @@
 # pylint: disable-msg=E1101,W0612
 
 from datetime import datetime, timedelta, date
-from pandas.util.py3compat import range
-from six.moves import zip
-from pandas.util import compat
 import os
 import operator
 import unittest
@@ -26,7 +23,8 @@ import pandas.lib as lib
 import pandas.core.datetools as datetools
 import pandas.core.nanops as nanops
 
-from pandas.util.py3compat import StringIO
+from pandas.util.py3compat import StringIO, lrange, range, zip
+from pandas.util import compat
 from pandas.util import py3compat
 from pandas.util.testing import (assert_series_equal,
                                  assert_almost_equal,
@@ -144,7 +142,7 @@ class CheckNameIntegration(object):
                            labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
                                    [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
                            names=['first', 'second'])
-        s = Series(list(range(0, len(index))), index=index, name='sth')
+        s = Series(lrange(0, len(index)), index=index, name='sth')
         expected = ["first  second",
                     "foo    one       0",
                     "       two       1",
@@ -181,7 +179,7 @@ class CheckNameIntegration(object):
         s.name = None
         self.assert_(not "Name:" in repr(s))
         # test big series (diff code path)
-        s = Series(list(range(0, 1000)))
+        s = Series(lrange(0, 1000))
         s.name = "test"
         self.assert_("Name: test" in repr(s))
         s.name = None
@@ -235,7 +233,7 @@ class TestNanops(unittest.TestCase):
 
     def test_none_comparison(self):
         # bug brought up by #1079
-        s = Series(np.random.randn(10), index=list(range(0, 20, 2)))
+        s = Series(np.random.randn(10), index=lrange(0, 20, 2))
         self.assertRaises(TypeError, s.__eq__, None)
 
     def test_sum_zero(self):
@@ -324,8 +322,8 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         empty2 = Series([])
         assert_series_equal(empty, empty2)
 
-        empty = Series(index=list(range(10)))
-        empty2 = Series(np.nan, index=list(range(10)))
+        empty = Series(index=lrange(10))
+        empty2 = Series(np.nan, index=lrange(10))
         assert_series_equal(empty, empty2)
 
     def test_constructor_series(self):
@@ -340,12 +338,12 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         gen = (i for i in range(10))
 
         result = Series(gen)
-        exp = Series(list(range(10)))
+        exp = Series(lrange(10))
         assert_series_equal(result, exp)
 
         gen = (i for i in range(10))
-        result = Series(gen, index=list(range(10, 20)))
-        exp.index = list(range(10, 20))
+        result = Series(gen, index=lrange(10, 20))
+        exp.index = lrange(10, 20)
         assert_series_equal(result, exp)
 
     def test_constructor_maskedarray(self):
@@ -438,10 +436,10 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertEquals(s.dtype, np.dtype('f8'))
 
     def test_constructor_pass_none(self):
-        s = Series(None, index=list(range(5)))
+        s = Series(None, index=lrange(5))
         self.assert_(s.dtype == np.float64)
 
-        s = Series(None, index=list(range(5)), dtype=object)
+        s = Series(None, index=lrange(5), dtype=object)
         self.assert_(s.dtype == np.object_)
 
     def test_constructor_cast(self):
@@ -459,15 +457,15 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
     def test_constructor_dtype_datetime64(self):
         import pandas.tslib as tslib
 
-        s = Series(tslib.iNaT, dtype='M8[ns]', index=list(range(5)))
+        s = Series(tslib.iNaT, dtype='M8[ns]', index=lrange(5))
         self.assert_(isnull(s).all() == True)
 
         #### in theory this should be all nulls, but since
         #### we are not specifying a dtype is ambiguous
-        s = Series(tslib.iNaT, index=list(range(5)))
+        s = Series(tslib.iNaT, index=lrange(5))
         self.assert_(isnull(s).all() == False)
 
-        s = Series(nan, dtype='M8[ns]', index=list(range(5)))
+        s = Series(nan, dtype='M8[ns]', index=lrange(5))
         self.assert_(isnull(s).all() == True)
 
         s = Series([datetime(2001, 1, 2, 0, 0), tslib.iNaT], dtype='M8[ns]')
@@ -643,7 +641,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertRaises(KeyError, self.ts.__getitem__, d)
 
     def test_iget(self):
-        s = Series(np.random.randn(10), index=list(range(0, 20, 2)))
+        s = Series(np.random.randn(10), index=lrange(0, 20, 2))
         for i in range(len(s)):
             result = s.iget(i)
             exp = s[s.index[i]]
@@ -668,12 +666,12 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertEqual(s.iget(2), 2)
 
     def test_getitem_regression(self):
-        s = Series(list(range(5)), index=list(range(5)))
-        result = s[list(range(5))]
+        s = Series(lrange(5), index=lrange(5))
+        result = s[lrange(5)]
         assert_series_equal(result, s)
 
     def test_getitem_setitem_slice_bug(self):
-        s = Series(list(range(10)), list(range(10)))
+        s = Series(lrange(10), lrange(10))
         result = s[-12:]
         assert_series_equal(result, s)
 
@@ -683,7 +681,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         result = s[:-12]
         assert_series_equal(result, s[:0])
 
-        s = Series(list(range(10)), list(range(10)))
+        s = Series(lrange(10), lrange(10))
         s[-12:] = 0
         self.assert_((s == 0).all())
 
@@ -783,12 +781,12 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         tm.assert_isinstance(value, np.float64)
 
     def test_getitem_ambiguous_keyerror(self):
-        s = Series(list(range(10)), index=list(range(0, 20, 2)))
+        s = Series(lrange(10), index=lrange(0, 20, 2))
         self.assertRaises(KeyError, s.__getitem__, 1)
         self.assertRaises(KeyError, s.ix.__getitem__, 1)
 
     def test_getitem_unordered_dup(self):
-        obj = Series(list(range(5)), index=['c', 'a', 'a', 'b', 'b'])
+        obj = Series(lrange(5), index=['c', 'a', 'a', 'b', 'b'])
         self.assert_(np.isscalar(obj['c']))
         self.assert_(obj['c'] == 0)
 
@@ -802,7 +800,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(result,expected)
 
     def test_setitem_ambiguous_keyerror(self):
-        s = Series(list(range(10)), index=list(range(0, 20, 2)))
+        s = Series(lrange(10), index=lrange(0, 20, 2))
         self.assertRaises(KeyError, s.__setitem__, 1, 5)
         self.assertRaises(KeyError, s.ix.__setitem__, 1, 5)
 
@@ -975,7 +973,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(result, expected)
 
         # integer indexes, be careful
-        s = Series(np.random.randn(10), index=list(range(0, 20, 2)))
+        s = Series(np.random.randn(10), index=lrange(0, 20, 2))
         inds = [0, 2, 5, 7, 8]
         arr_inds = np.array([0, 2, 5, 7, 8])
         result = s[inds]
@@ -1002,7 +1000,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(cp, exp)
 
         # integer indexes, be careful
-        s = Series(np.random.randn(10), index=list(range(0, 20, 2)))
+        s = Series(np.random.randn(10), index=lrange(0, 20, 2))
         inds = [0, 4, 6]
         arr_inds = np.array([0, 4, 6])
 
@@ -1051,7 +1049,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertRaises(KeyError, ts2.ix.__setitem__, slice(d1, d2), 0)
 
     def test_ix_getitem_setitem_integer_slice_keyerrors(self):
-        s = Series(np.random.randn(10), index=list(range(0, 20, 2)))
+        s = Series(np.random.randn(10), index=lrange(0, 20, 2))
 
         # this is OK
         cp = s.copy()
@@ -1115,8 +1113,8 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         for dtype in [ np.int8, np.int16, np.int32, np.int64, np.float16, np.float32, np.float64 ]:
             s = Series(np.arange(10), dtype=dtype)
             mask = s < 5
-            s[mask] = list(range(2,7))
-            expected = Series(list(range(2,7)) + list(range(5,10)), dtype=dtype)
+            s[mask] = lrange(2,7)
+            expected = Series(lrange(2,7) + lrange(5,10), dtype=dtype)
             assert_series_equal(s, expected)
             self.assertEquals(s.dtype, expected.dtype)
 
@@ -1126,7 +1124,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
             mask = s < 5
             values = [2.5,3.5,4.5,5.5,6.5]
             s[mask] = values
-            expected = Series(values + list(range(5,10)), dtype='float64')
+            expected = Series(values + lrange(5,10), dtype='float64')
             assert_series_equal(s, expected)
             self.assertEquals(s.dtype, expected.dtype)
 
@@ -1140,8 +1138,8 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         # GH3235
         s = Series(np.arange(10),dtype='int64')
         mask = s < 5
-        s[mask] = list(range(2,7))
-        expected = Series(list(range(2,7)) + list(range(5,10)),dtype='int64')
+        s[mask] = lrange(2,7)
+        expected = Series(lrange(2,7) + lrange(5,10),dtype='int64')
         assert_series_equal(s, expected)
         self.assertEquals(s.dtype, expected.dtype)
 
@@ -1451,7 +1449,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self._check_stat_op('median', np.median)
 
         # test with integers, test failure
-        int_ts = TimeSeries(np.ones(10, dtype=int), index=list(range(10)))
+        int_ts = TimeSeries(np.ones(10, dtype=int), index=lrange(10))
         self.assertAlmostEqual(np.median(int_ts), int_ts.median())
 
     def test_prod(self):
@@ -1512,11 +1510,11 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assert_(isnull(shifted[4]) == True)
 
         result = s.argsort()
-        expected = Series(list(range(5)),dtype='int64')
+        expected = Series(lrange(5),dtype='int64')
         assert_series_equal(result,expected)
 
         result = shifted.argsort()
-        expected = Series(list(range(4)) + [-1],dtype='int64')
+        expected = Series(lrange(4) + [-1],dtype='int64')
         assert_series_equal(result,expected)
 
     def test_argsort_stable(self):
@@ -1595,7 +1593,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
             # 2888
             l = [0]
-            l.extend(list(range(2**40,2**40+1000)))
+            l.extend(lrange(2**40,2**40+1000))
             s = Series(l, dtype='int64')
             assert_almost_equal(float(f(s)), float(alternate(s.values)))
 
@@ -1638,7 +1636,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertEqual(result.name, self.ts.name)
 
     def test_prod_numpy16_bug(self):
-        s = Series([1., 1., 1.], index=list(range(3)))
+        s = Series([1., 1., 1.], index=lrange(3))
         result = s.prod()
         self.assert_(not isinstance(result, Series))
 
@@ -2624,7 +2622,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         assert_series_equal(hist, expected)
 
         # GH 3002, datetime64[ns]
-        from pandas.util.py3compat import StringIO
+        from pandas.util.py3compat import StringIO, lrange
         import pandas as pd
         f = StringIO("xxyyzz20100101PIE\nxxyyzz20100101GUM\nxxyyww20090101EGG\nfoofoo20080909PIE")
         df = pd.read_fwf(f, widths=[6,8,3], names=["person_id", "dt", "food"], parse_dates=["dt"])
@@ -3347,7 +3345,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
     def test_astype_datetimes(self):
         import pandas.tslib as tslib
 
-        s = Series(tslib.iNaT, dtype='M8[ns]', index=list(range(5)))
+        s = Series(tslib.iNaT, dtype='M8[ns]', index=lrange(5))
         s = s.astype('O')
         self.assert_(s.dtype == np.object_)
 
@@ -3395,7 +3393,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assert_(not isnull(merged['c']))
 
     def test_map_type_inference(self):
-        s = Series(list(range(3)))
+        s = Series(lrange(3))
         s2 = s.map(lambda x: np.where(x == 0, 0, 1))
         self.assert_(issubclass(s2.dtype.type, np.integer))
 
@@ -4306,7 +4304,7 @@ class TestSeriesNonUnique(unittest.TestCase):
     def test_set_index_makes_timeseries(self):
         idx = tm.makeDateIndex(10)
 
-        s = Series(list(range(10)))
+        s = Series(lrange(10))
         s.index = idx
 
         self.assertTrue(isinstance(s, TimeSeries))
diff --git a/pandas/tests/test_strings.py b/pandas/tests/test_strings.py
index d54aedc43..7c05c9fa2 100644
--- a/pandas/tests/test_strings.py
+++ b/pandas/tests/test_strings.py
@@ -1,7 +1,7 @@
 # pylint: disable-msg=E1101,W0612
 
 from datetime import datetime, timedelta, date
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import os
 import operator
 import re
@@ -75,7 +75,7 @@ class TestStringMethods(unittest.TestCase):
 
     def test_iter_numeric_try_string(self):
         # behavior identical to empty series
-        dsi = Series(list(range(4)))
+        dsi = Series(lrange(4))
 
         i, s = 100, 'h'
 
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 22679d36b..5ce0041bf 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -1,5 +1,5 @@
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip
 import unittest
 
 from numpy import nan
@@ -32,7 +32,7 @@ class TestTseriesUtil(unittest.TestCase):
 
     def test_backfill(self):
         old = Index([1, 5, 10])
-        new = Index(list(range(12)))
+        new = Index(lrange(12))
 
         filler = algos.backfill_int64(old, new)
 
@@ -41,7 +41,7 @@ class TestTseriesUtil(unittest.TestCase):
 
         # corner case
         old = Index([1, 4])
-        new = Index(list(range(5, 10)))
+        new = Index(lrange(5, 10))
         filler = algos.backfill_int64(old, new)
 
         expect_filler = [-1, -1, -1, -1, -1]
@@ -49,7 +49,7 @@ class TestTseriesUtil(unittest.TestCase):
 
     def test_pad(self):
         old = Index([1, 5, 10])
-        new = Index(list(range(12)))
+        new = Index(lrange(12))
 
         filler = algos.pad_int64(old, new)
 
@@ -58,7 +58,7 @@ class TestTseriesUtil(unittest.TestCase):
 
         # corner case
         old = Index([5, 10])
-        new = Index(list(range(5)))
+        new = Index(lrange(5))
         filler = algos.pad_int64(old, new)
         expect_filler = [-1, -1, -1, -1, -1]
         self.assert_(np.array_equal(filler, expect_filler))
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 63d78ddde..2987a73b3 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -2,8 +2,8 @@
 SQL-style merge routines
 """
 
-from pandas.util.py3compat import range, long
-from six.moves import zip
+from pandas.util.py3compat import range, long, lrange, lzip
+from pandas.util.py3compat import zip
 import six
 import numpy as np
 import types
@@ -1136,7 +1136,7 @@ class _Concatenator(object):
                 raise AssertionError()
 
             # ufff...
-            indices = list(range(ndim))
+            indices = lrange(ndim)
             indices.remove(self.axis)
 
             for i, ax in zip(indices, self.join_axes):
@@ -1201,7 +1201,7 @@ def _concat_indexes(indexes):
 def _make_concat_multiindex(indexes, keys, levels=None, names=None):
     if ((levels is None and isinstance(keys[0], tuple)) or
             (levels is not None and len(levels) > 1)):
-        zipped = list(zip(*keys))
+        zipped = lzip(*keys)
         if names is None:
             names = [None] * len(zipped)
 
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index f1d1ba322..e4aa0a7d6 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -5,11 +5,11 @@ from pandas.core.index import MultiIndex
 from pandas.core.reshape import _unstack_multiple
 from pandas.tools.merge import concat
 from pandas.tools.util import cartesian_product
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 from pandas.util import compat
 import six
 import pandas.core.common as com
-from six.moves import zip
+from pandas.util.py3compat import zip
 import numpy as np
 
 
@@ -200,7 +200,7 @@ def _add_margins(table, data, values, rows=None, cols=None, aggfunc=np.mean):
         row_margin = row_margin.stack()
 
         # slight hack
-        new_order = [len(cols)] + list(range(len(cols)))
+        new_order = [len(cols)] + lrange(len(cols))
         row_margin.index = row_margin.index.reorder_levels(new_order)
     else:
         row_margin = Series(np.nan, index=result.columns)
diff --git a/pandas/tools/plotting.py b/pandas/tools/plotting.py
index e356e9e9f..b83b2d176 100644
--- a/pandas/tools/plotting.py
+++ b/pandas/tools/plotting.py
@@ -16,8 +16,8 @@ from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
 from pandas.tseries.frequencies import get_period_alias, get_base_alias
 from pandas.tseries.offsets import DateOffset
-from pandas.util.py3compat import range
-from six.moves import map, zip
+from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.py3compat import map, zip
 
 try:  # mpl optional
     import pandas.tseries.converter as conv
@@ -105,7 +105,7 @@ def _get_standard_colors(num_colors=None, colormap=None, color_type='default',
             colormap = cm.get_cmap(colormap)
             if colormap is None:
                 raise ValueError("Colormap {0} is not recognized".format(cmap))
-        colors = list(map(colormap, np.linspace(0, 1, num=num_colors)))
+        colors = lmap(colormap, np.linspace(0, 1, num=num_colors))
     elif color is not None:
         if colormap is not None:
             warnings.warn("'color' and 'colormap' cannot be used "
@@ -122,7 +122,7 @@ def _get_standard_colors(num_colors=None, colormap=None, color_type='default',
                 random.seed(column)
                 return [random.random() for _ in range(3)]
 
-            colors = list(map(random_color, list(range(num_colors))))
+            colors = lmap(random_color, lrange(num_colors))
         else:
             raise NotImplementedError
 
@@ -243,8 +243,8 @@ def scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, grid=False,
 
     marker = _get_marker_compat(marker)
 
-    for i, a in zip(list(range(n)), df.columns):
-        for j, b in zip(list(range(n)), df.columns):
+    for i, a in zip(lrange(n), df.columns):
+        for j, b in zip(lrange(n), df.columns):
             ax = axes[i, j]
 
             if i == j:
@@ -503,7 +503,7 @@ def bootstrap_plot(series, fig=None, size=50, samples=500, **kwds):
                           for sampling in samplings])
     if fig is None:
         fig = plt.figure()
-    x = list(range(samples))
+    x = lrange(samples)
     axes = []
     ax1 = fig.add_subplot(2, 3, 1)
     ax1.set_xlabel("Sample")
@@ -601,7 +601,7 @@ def parallel_coordinates(data, class_column, cols=None, ax=None, colors=None,
             raise ValueError('Length of xticks must match number of columns')
         x = xticks
     else:
-        x = list(range(ncols))
+        x = lrange(ncols)
 
     if ax is None:
         ax = plt.gca()
@@ -684,7 +684,7 @@ def autocorrelation_plot(series, ax=None):
     def r(h):
         return ((data[:n - h] - mean) * (data[h:] - mean)).sum() / float(n) / c0
     x = np.arange(n) + 1
-    y = list(map(r, x))
+    y = lmap(r, x)
     z95 = 1.959963984540054
     z99 = 2.5758293035489004
     ax.axhline(y=z99 / np.sqrt(n), linestyle='--', color='grey')
@@ -1038,9 +1038,9 @@ class MPLPlot(object):
                 x = self.data.index._mpl_repr()
             else:
                 self._need_to_set_index = True
-                x = list(range(len(index)))
+                x = lrange(len(index))
         else:
-            x = list(range(len(index)))
+            x = lrange(len(index))
 
         return x
 
diff --git a/pandas/tools/rplot.py b/pandas/tools/rplot.py
index f2d2b1fd6..2bc377524 100644
--- a/pandas/tools/rplot.py
+++ b/pandas/tools/rplot.py
@@ -1,5 +1,5 @@
 from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import zip
 import numpy as np
 import random
 from copy import deepcopy
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index ea57fc752..742bc81d4 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -9,8 +9,8 @@ from numpy import nan
 import numpy as np
 import random
 
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, lrange, lzip
+from pandas.util.py3compat import zip
 from pandas.util import compat
 from pandas.tseries.index import DatetimeIndex
 from pandas.tools.merge import merge, concat, ordered_merge, MergeError
@@ -29,7 +29,7 @@ JOIN_TYPES = ['inner', 'outer', 'left', 'right']
 
 
 def get_test_data(ngroups=NGROUPS, n=N):
-    unique_groups = list(range(ngroups))
+    unique_groups = lrange(ngroups)
     arr = np.asarray(np.tile(unique_groups, n // ngroups))
 
     if len(arr) < n:
@@ -558,8 +558,8 @@ class TestMerge(unittest.TestCase):
         assert_almost_equal(merged['value_y'], [6, np.nan, 5, 8, 5, 8, 7])
 
     def test_merge_nocopy(self):
-        left = DataFrame({'a': 0, 'b': 1}, index=list(range(10)))
-        right = DataFrame({'c': 'foo', 'd': 'bar'}, index=list(range(10)))
+        left = DataFrame({'a': 0, 'b': 1}, index=lrange(10))
+        right = DataFrame({'c': 'foo', 'd': 'bar'}, index=lrange(10))
 
         merged = merge(left, right, left_index=True,
                        right_index=True, copy=False)
@@ -585,15 +585,15 @@ class TestMerge(unittest.TestCase):
 
         # smoke test
         joined = left.join(right, on='key', sort=False)
-        self.assert_(np.array_equal(joined.index, list(range(4))))
+        self.assert_(np.array_equal(joined.index, lrange(4)))
 
     def test_intelligently_handle_join_key(self):
         # #733, be a bit more 1337 about not returning unconsolidated DataFrame
 
         left = DataFrame({'key': [1, 1, 2, 2, 3],
-                          'value': list(range(5))}, columns=['value', 'key'])
+                          'value': lrange(5)}, columns=['value', 'key'])
         right = DataFrame({'key': [1, 1, 2, 3, 4, 5],
-                           'rvalue': list(range(6))})
+                           'rvalue': lrange(6)})
 
         joined = merge(left, right, on='key', how='outer')
         expected = DataFrame({'key': [1, 1, 1, 1, 2, 2, 3, 4, 5.],
@@ -607,8 +607,8 @@ class TestMerge(unittest.TestCase):
 
     def test_handle_join_key_pass_array(self):
         left = DataFrame({'key': [1, 1, 2, 2, 3],
-                          'value': list(range(5))}, columns=['value', 'key'])
-        right = DataFrame({'rvalue': list(range(6))})
+                          'value': lrange(5)}, columns=['value', 'key'])
+        right = DataFrame({'rvalue': lrange(6)})
         key = np.array([1, 1, 2, 3, 4, 5])
 
         merged = merge(left, right, left_on='key', right_on=key, how='outer')
@@ -618,8 +618,8 @@ class TestMerge(unittest.TestCase):
         self.assert_(merged['key'].notnull().all())
         self.assert_(merged2['key'].notnull().all())
 
-        left = DataFrame({'value': list(range(5))}, columns=['value'])
-        right = DataFrame({'rvalue': list(range(6))})
+        left = DataFrame({'value': lrange(5)}, columns=['value'])
+        right = DataFrame({'rvalue': lrange(6)})
         lkey = np.array([1, 1, 2, 2, 3])
         rkey = np.array([1, 1, 2, 3, 4, 5])
 
@@ -627,8 +627,8 @@ class TestMerge(unittest.TestCase):
         self.assert_(np.array_equal(merged['key_0'],
                                     np.array([1, 1, 1, 1, 2, 2, 3, 4, 5])))
 
-        left = DataFrame({'value': list(range(3))})
-        right = DataFrame({'rvalue': list(range(6))})
+        left = DataFrame({'value': lrange(3)})
+        right = DataFrame({'rvalue': lrange(6)})
 
         key = np.array([0, 1, 1, 2, 2, 3])
         merged = merge(left, right, left_index=True, right_on=key, how='outer')
@@ -790,7 +790,7 @@ class TestMergeMulti(unittest.TestCase):
     def test_merge_on_multikey(self):
         joined = self.data.join(self.to_join, on=['key1', 'key2'])
 
-        join_key = Index(list(zip(self.data['key1'], self.data['key2'])))
+        join_key = Index(lzip(self.data['key1'], self.data['key2']))
         indexer = self.to_join.index.get_indexer(join_key)
         ex_values = self.to_join.values.take(indexer, axis=0)
         ex_values[indexer == -1] = np.nan
@@ -1616,7 +1616,7 @@ class TestConcatenate(unittest.TestCase):
 
         s2.name = None
         result = concat([s, s2], axis=1)
-        self.assertTrue(np.array_equal(result.columns, list(range(2))))
+        self.assertTrue(np.array_equal(result.columns, lrange(2)))
 
         # must reindex, #2603
         s = Series(randn(3), index=['c', 'a', 'b'], name='A')
diff --git a/pandas/tools/tests/test_tile.py b/pandas/tools/tests/test_tile.py
index 54b8f05b6..09095ba80 100644
--- a/pandas/tools/tests/test_tile.py
+++ b/pandas/tools/tests/test_tile.py
@@ -3,7 +3,7 @@ import nose
 import unittest
 
 import numpy as np
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 from pandas import DataFrame, Series, unique
 import pandas.util.testing as tm
diff --git a/pandas/tools/tile.py b/pandas/tools/tile.py
index 31db8ed70..fd9d290d6 100644
--- a/pandas/tools/tile.py
+++ b/pandas/tools/tile.py
@@ -8,7 +8,7 @@ from pandas.core.index import _ensure_index
 import pandas.core.algorithms as algos
 import pandas.core.common as com
 import pandas.core.nanops as nanops
-from six.moves import zip
+from pandas.util.py3compat import zip
 
 import numpy as np
 
diff --git a/pandas/tseries/converter.py b/pandas/tseries/converter.py
index efbd80350..3e79bdf01 100644
--- a/pandas/tseries/converter.py
+++ b/pandas/tseries/converter.py
@@ -1,5 +1,5 @@
 from datetime import datetime, timedelta
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import six
 import datetime as pydt
 import numpy as np
@@ -886,7 +886,7 @@ class TimeSeries_DateLocator(Locator):
             base = self.base
             (d, m) = divmod(vmin, base)
             vmin = (d + 1) * base
-            locs = list(range(vmin, vmax + 1, base))
+            locs = lrange(vmin, vmax + 1, base)
         return locs
 
     def autoscale(self):
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index 3157c694b..d6065a9a5 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -1,7 +1,7 @@
 from datetime import datetime
 from pandas.util.py3compat import range, long
 from pandas.util import compat
-from six.moves import zip
+from pandas.util.py3compat import zip
 import six
 import re
 
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index 0a7b57387..9fce35652 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -21,7 +21,7 @@ import pandas.lib as lib
 import pandas.tslib as tslib
 import pandas.algos as _algos
 import six
-from six.moves import map, zip
+from pandas.util.py3compat import map, zip
 
 
 #---------------
diff --git a/pandas/tseries/tests/test_period.py b/pandas/tseries/tests/test_period.py
index 2057a418f..909c8b361 100644
--- a/pandas/tseries/tests/test_period.py
+++ b/pandas/tseries/tests/test_period.py
@@ -23,8 +23,8 @@ import pandas.core.datetools as datetools
 import pandas as pd
 import numpy as np
 import six
-from pandas.util.py3compat import range
-from six.moves import map, zip
+from pandas.util.py3compat import range, lrange, lmap
+from pandas.util.py3compat import map, zip
 randn = np.random.randn
 
 from pandas import Series, TimeSeries, DataFrame
@@ -1118,7 +1118,7 @@ class TestPeriodIndex(TestCase):
 
     def test_constructor_arrays_negative_year(self):
         years = np.arange(1960, 2000).repeat(4)
-        quarters = np.tile(list(range(1, 5)), 40)
+        quarters = np.tile(lrange(1, 5), 40)
 
         pindex = PeriodIndex(year=years, quarter=quarters)
 
@@ -1126,8 +1126,8 @@ class TestPeriodIndex(TestCase):
         self.assert_(np.array_equal(pindex.quarter, quarters))
 
     def test_constructor_invalid_quarters(self):
-        self.assertRaises(ValueError, PeriodIndex, year=list(range(2000, 2004)),
-                          quarter=list(range(4)), freq='Q-DEC')
+        self.assertRaises(ValueError, PeriodIndex, year=lrange(2000, 2004),
+                          quarter=lrange(4), freq='Q-DEC')
 
     def test_constructor_corner(self):
         self.assertRaises(ValueError, PeriodIndex, periods=10, freq='A')
@@ -1216,7 +1216,7 @@ class TestPeriodIndex(TestCase):
 
     def test_getitem_datetime(self):
         rng = period_range(start='2012-01-01', periods=10, freq='W-MON')
-        ts = Series(list(range(len(rng))), index=rng)
+        ts = Series(lrange(len(rng)), index=rng)
 
         dt1 = datetime(2011, 10, 2)
         dt4 = datetime(2012, 4, 20)
@@ -1288,7 +1288,7 @@ class TestPeriodIndex(TestCase):
 
     def test_to_timestamp_quarterly_bug(self):
         years = np.arange(1960, 2000).repeat(4)
-        quarters = np.tile(list(range(1, 5)), 40)
+        quarters = np.tile(lrange(1, 5), 40)
 
         pindex = PeriodIndex(year=years, quarter=quarters)
 
@@ -2006,7 +2006,7 @@ class TestPeriodIndex(TestCase):
             types += six.text_type,
 
         for t in types:
-            expected = np.array(list(map(t, raw)), dtype=object)
+            expected = np.array(lmap(t, raw), dtype=object)
             res = index.map(t)
 
             # should return an array
diff --git a/pandas/tseries/tests/test_plotting.py b/pandas/tseries/tests/test_plotting.py
index f6242139e..95bfa98d3 100644
--- a/pandas/tseries/tests/test_plotting.py
+++ b/pandas/tseries/tests/test_plotting.py
@@ -3,8 +3,8 @@ from datetime import datetime, timedelta, date, time
 
 import unittest
 import nose
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip
 
 import numpy as np
 from numpy.testing.decorators import slow
@@ -188,7 +188,7 @@ class TestTSPlot(unittest.TestCase):
         plt.clf()
         fig.add_subplot(111)
         rng = date_range('2001-1-1', '2001-1-10')
-        ts = Series(list(range(len(rng))), rng)
+        ts = Series(lrange(len(rng)), rng)
         ts = ts[:3].append(ts[5:])
         ax = ts.plot()
         self.assert_(not hasattr(ax, 'freq'))
@@ -944,7 +944,7 @@ class TestTSPlot(unittest.TestCase):
     def test_ax_plot(self):
         x = DatetimeIndex(start='2012-01-02', periods=10,
                           freq='D')
-        y = list(range(len(x)))
+        y = lrange(len(x))
         import matplotlib.pyplot as plt
         fig = plt.figure()
         ax = fig.add_subplot(111)
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index b5e6d9de4..1db735896 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -2,8 +2,8 @@
 
 from datetime import datetime, timedelta
 
-from pandas.util.py3compat import range
-from six.moves import zip
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip
 import numpy as np
 
 from pandas import Series, TimeSeries, DataFrame, Panel, isnull, notnull, Timestamp
@@ -862,7 +862,7 @@ class TestResamplePeriodIndex(unittest.TestCase):
 
     def test_resample_tz_localized(self):
         dr = date_range(start='2012-4-13', end='2012-5-1')
-        ts = Series(list(range(len(dr))), dr)
+        ts = Series(lrange(len(dr)), dr)
 
         ts_utc = ts.tz_localize('UTC')
         ts_local = ts_utc.tz_convert('America/Los_Angeles')
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 68ea73a66..779166f3c 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -28,9 +28,9 @@ import pandas.tslib as tslib
 
 import pandas.index as _index
 
-from pandas.util.py3compat import range, long, StringIO
+from pandas.util.py3compat import range, long, StringIO, lrange, lmap
 from pandas.util.compat import product
-from six.moves import map, zip, cPickle as pickle
+from pandas.util.py3compat import map, zip, cPickle as pickle
 from pandas import read_pickle
 import pandas.core.datetools as dt
 from numpy.random import rand
@@ -238,17 +238,17 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
 
         # GH3546 (not including times on the last day)
         idx = date_range(start='2013-05-31 00:00', end='2013-05-31 23:00', freq='H')
-        ts  = Series(list(range(len(idx))), index=idx)
+        ts  = Series(lrange(len(idx)), index=idx)
         expected = ts['2013-05']
         assert_series_equal(expected,ts)
 
         idx = date_range(start='2013-05-31 00:00', end='2013-05-31 23:59', freq='S')
-        ts  = Series(list(range(len(idx))), index=idx)
+        ts  = Series(lrange(len(idx)), index=idx)
         expected = ts['2013-05']
         assert_series_equal(expected,ts)
 
         idx = [ Timestamp('2013-05-31 00:00'), Timestamp(datetime(2013,5,31,23,59,59,999999))]
-        ts  = Series(list(range(len(idx))), index=idx)
+        ts  = Series(lrange(len(idx)), index=idx)
         expected = ts['2013']
         assert_series_equal(expected,ts)
 
@@ -452,7 +452,7 @@ class TestTimeSeries(unittest.TestCase):
         # 2155
         columns = DatetimeIndex(start='1/1/2012', end='2/1/2012',
                                 freq=datetools.bday)
-        index = list(range(10))
+        index = lrange(10)
         data = DataFrame(columns=columns, index=index)
         t = datetime(2012, 11, 1)
         ts = Timestamp(t)
@@ -663,7 +663,7 @@ class TestTimeSeries(unittest.TestCase):
         rng = date_range('1/1/2000 00:00:00', periods=10, freq='10s')
         series = Series(rng)
 
-        result = series.reindex(list(range(15)))
+        result = series.reindex(lrange(15))
         self.assert_(np.issubdtype(result.dtype, np.dtype('M8[ns]')))
 
         mask = result.isnull()
@@ -674,7 +674,7 @@ class TestTimeSeries(unittest.TestCase):
         rng = date_range('1/1/2000 00:00:00', periods=10, freq='10s')
         df = DataFrame({'A': np.random.randn(len(rng)), 'B': rng})
 
-        result = df.reindex(list(range(15)))
+        result = df.reindex(lrange(15))
         self.assert_(np.issubdtype(result['B'].dtype, np.dtype('M8[ns]')))
 
         mask = com.isnull(result)['B']
@@ -889,7 +889,7 @@ class TestTimeSeries(unittest.TestCase):
         ### array = ['2012','20120101','20120101 12:01:01']
         array = ['20120101','20120101 12:01:01']
         expected = list(to_datetime(array))
-        result = list(map(Timestamp,array))
+        result = lmap(Timestamp,array)
         tm.assert_almost_equal(result,expected)
 
         ### currently fails ###
@@ -1512,11 +1512,11 @@ class TestTimeSeries(unittest.TestCase):
         dr = date_range(start='1/1/2012', freq='5min', periods=10)
 
         # BAD Example, datetimes first
-        s = Series(np.arange(10), index=[dr, list(range(10))])
+        s = Series(np.arange(10), index=[dr, lrange(10)])
         grouped = s.groupby(lambda x: x[1] % 2 == 0)
         result = grouped.count()
 
-        s = Series(np.arange(10), index=[list(range(10)), dr])
+        s = Series(np.arange(10), index=[lrange(10), dr])
         grouped = s.groupby(lambda x: x[0] % 2 == 0)
         expected = grouped.count()
 
@@ -1667,7 +1667,7 @@ class TestTimeSeries(unittest.TestCase):
         df2_obj = DataFrame.from_records(rows, columns=['date', 'test'])
 
         ind = date_range(start="2000/1/1", freq="D", periods=10)
-        df1 = DataFrame({'date': ind, 'test':list(range(10))})
+        df1 = DataFrame({'date': ind, 'test':lrange(10)})
 
         # it works!
         pd.concat([df1, df2_obj])
@@ -1686,7 +1686,7 @@ class TestDatetimeIndex(unittest.TestCase):
         import datetime
         start=datetime.datetime.now()
         idx=DatetimeIndex(start=start,freq="1d",periods=10)
-        df=DataFrame(list(range(10)),index=idx)
+        df=DataFrame(lrange(10),index=idx)
         df["2013-01-14 23:44:34.437768-05:00":] # no exception here
 
     def test_append_join_nondatetimeindex(self):
@@ -1980,7 +1980,6 @@ class TestLegacySupport(unittest.TestCase):
             cls.series = pickle.load(f)
 
     def test_pass_offset_warn(self):
-        from pandas.util.py3compat import StringIO
         buf = StringIO()
 
         sys.stderr = buf
@@ -2401,7 +2400,6 @@ class TestLegacySupport(unittest.TestCase):
 class TestLegacyCompat(unittest.TestCase):
 
     def setUp(self):
-        from pandas.util.py3compat import StringIO
         # suppress deprecation warnings
         sys.stderr = StringIO()
 
@@ -2649,7 +2647,7 @@ class TestDatetime64(unittest.TestCase):
     def test_slice_locs_indexerror(self):
         times = [datetime(2000, 1, 1) + timedelta(minutes=i * 10)
                  for i in range(100000)]
-        s = Series(list(range(100000)), times)
+        s = Series(lrange(100000), times)
         s.ix[datetime(1900, 1, 1):datetime(2100, 1, 1)]
 
 
diff --git a/pandas/tseries/tests/test_timezones.py b/pandas/tseries/tests/test_timezones.py
index 1c7607c63..7ee89f7ca 100644
--- a/pandas/tseries/tests/test_timezones.py
+++ b/pandas/tseries/tests/test_timezones.py
@@ -28,8 +28,8 @@ import pandas.core.datetools as dt
 from numpy.random import rand
 from pandas.util.testing import assert_frame_equal
 import pandas.util.py3compat as py3compat
-from pandas.util.py3compat import range
-from six.moves import zip, cPickle as pickle
+from pandas.util.py3compat import range, lrange
+from pandas.util.py3compat import zip, cPickle as pickle
 from pandas.core.datetools import BDay
 import pandas.core.common as com
 
@@ -394,7 +394,7 @@ class TestTimeZoneSupport(unittest.TestCase):
         _skip_if_no_pytz()
         rng = date_range('1/1/2000', periods=20, tz='US/Eastern')
 
-        result = rng.take(list(range(5)))
+        result = rng.take(lrange(5))
         self.assert_(result.tz == rng.tz)
         self.assert_(result.freq == rng.freq)
 
@@ -747,7 +747,7 @@ class TestTimeZones(unittest.TestCase):
         test2 = DataFrame(np.zeros((3, 3)),
                           index=date_range("2012-11-15 00:00:00", periods=3,
                                            freq="250L", tz="US/Central"),
-                          columns=list(range(3, 6)))
+                          columns=lrange(3, 6))
 
         result = test1.join(test2, how='outer')
         ex_index = test1.index.union(test2.index)
@@ -816,7 +816,7 @@ class TestTimeZones(unittest.TestCase):
         # mixed
 
         rng1 = date_range('1/1/2011 01:00', periods=1, freq='H')
-        rng2 = list(range(100))
+        rng2 = lrange(100)
         ts1 = Series(np.random.randn(len(rng1)), index=rng1)
         ts2 = Series(np.random.randn(len(rng2)), index=rng2)
         ts_result = ts1.append(ts2)
diff --git a/pandas/tseries/util.py b/pandas/tseries/util.py
index 92ec7d2be..5021214ac 100644
--- a/pandas/tseries/util.py
+++ b/pandas/tseries/util.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import numpy as np
 
 import pandas as pd
@@ -54,12 +54,12 @@ def pivot_annual(series, freq=None):
         # adjust for leap year
         offset[(-isleapyear(year)) & (offset >= 59)] += 1
 
-        columns = list(range(1, 367))
+        columns = lrange(1, 367)
         # todo: strings like 1/1, 1/25, etc.?
     elif freq in ('M', 'BM'):
         width = 12
         offset = index.month - 1
-        columns = list(range(1, 13))
+        columns = lrange(1, 13)
     elif freq == 'H':
         width = 8784
         grouped = series.groupby(series.index.year)
@@ -67,7 +67,7 @@ def pivot_annual(series, freq=None):
         defaulted.index = defaulted.index.droplevel(0)
         offset = np.asarray(defaulted.index)
         offset[-isleapyear(year) & (offset >= 1416)] += 24
-        columns = list(range(1, 8785))
+        columns = lrange(1, 8785)
     else:
         raise NotImplementedError(freq)
 
diff --git a/pandas/util/compat.py b/pandas/util/compat.py
index 413cc0a9d..1f57d0025 100644
--- a/pandas/util/compat.py
+++ b/pandas/util/compat.py
@@ -1,6 +1,6 @@
 import sys
 import six
-from six.moves import map, filter
+from pandas.util.py3compat import map, filter
 from pandas.util.py3compat import range
 from itertools import product
 
diff --git a/pandas/util/counter.py b/pandas/util/counter.py
index 90e71d3b8..86200f5ed 100644
--- a/pandas/util/counter.py
+++ b/pandas/util/counter.py
@@ -6,7 +6,7 @@ import heapq as _heapq
 from itertools import repeat as _repeat, chain as _chain, starmap as _starmap
 from operator import itemgetter as _itemgetter
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 try:
     from collections import Mapping
diff --git a/pandas/util/py3compat.py b/pandas/util/py3compat.py
index 969ba94fd..9361bad20 100644
--- a/pandas/util/py3compat.py
+++ b/pandas/util/py3compat.py
@@ -1,6 +1,22 @@
 import sys
 
 PY3 = (sys.version_info[0] >= 3)
+# import iterator versions of these functions
+from six.moves import zip, filter, reduce, map
+
+try:
+    import __builtin__ as builtins
+    # not writeable when instantiated with string, doesn't handle unicode well
+    from cStringIO import StringIO as StringIO
+    # always writeable
+    from StringIO import StringIO
+    BytesIO = StringIO
+    import cPickle
+except ImportError:
+    import builtins
+    from io import StringIO, BytesIO
+    cStringIO = StringIO
+    import pickle as cPickle
 
 if PY3:
     def isidentifier(s):
@@ -12,6 +28,20 @@ if PY3:
     def bytes_to_str(b, encoding='utf-8'):
         return b.decode(encoding)
 
+    # list-producing versions of the major Python iterating functions
+    def lrange(*args, **kwargs):
+        return list(range(*args, **kwargs))
+
+    def lzip(*args, **kwargs):
+        return list(zip(*args, **kwargs))
+
+    def lmap(*args, **kwargs):
+        return list(map(*args, **kwargs))
+
+    def lfilter(*args, **kwargs):
+        return list(filter(*args, **kwargs))
+
+    # need to put range in the namespace
     range = range
     long = int
     unichr = chr
@@ -29,22 +59,14 @@ else:
     def bytes_to_str(b, encoding='ascii'):
         return b
 
-    range = xrange
+    # Python 2-builtin ranges produce lists
+    lrange = builtins.range
+    lzip = builtins.zip
+    lmap = builtins.map
+    lfilter = builtins.filter
+
     # have to explicitly put builtins into the namespace
+    range = xrange
     long = long
     unichr = unichr
 
-try:
-    # not writeable if instantiated with string, not good with unicode
-    from cStringIO import StringIO as cStringIO
-    # writeable and handles unicode
-    from StringIO import StringIO
-except ImportError:
-    # no more StringIO
-    from io import StringIO
-    cStringIO = StringIO
-
-try:
-    from io import BytesIO
-except ImportError:
-    from cStringIO import StringIO as BytesIO
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index d235298e8..6ee3ba3b7 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -2,8 +2,8 @@ from __future__ import division
 
 # pylint: disable-msg=W0402
 
-from pandas.util.py3compat import range, unichr
-from six.moves import zip
+from pandas.util.py3compat import range, unichr, lrange, lmap, lzip
+from pandas.util.py3compat import zip
 import random
 import string
 import sys
@@ -34,7 +34,7 @@ from pandas.tseries.period import PeriodIndex
 
 from pandas.io.common import urlopen, HTTPException
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 Index = index.Index
 MultiIndex = index.MultiIndex
@@ -54,7 +54,7 @@ def rands(n):
 
 
 def randu(n):
-    choices = six.u("").join(map(unichr, list(range(1488, 1488 + 26))))
+    choices = six.u("").join(map(unichr, lrange(1488, 1488 + 26)))
     choices += string.digits
     return ''.join([random.choice(choices) for _ in range(n)])
 
@@ -318,7 +318,7 @@ def makeUnicodeIndex(k):
 
 
 def makeIntIndex(k):
-    return Index(list(range(k)))
+    return Index(lrange(k))
 
 
 def makeFloatIndex(k):
@@ -490,7 +490,7 @@ def makeCustomIndex(nentries, nlevels, prefix='#', names=False, ndupe_l=None,
         def keyfunc(x):
             import re
             numeric_tuple = re.sub("[^\d_]_?","",x).split("_")
-            return list(map(int,numeric_tuple))
+            return lmap(int,numeric_tuple)
 
         # build a list of lists to create the index from
         div_factor = nentries // ndupe_l[i] + 1
@@ -502,7 +502,7 @@ def makeCustomIndex(nentries, nlevels, prefix='#', names=False, ndupe_l=None,
         result = list(sorted(cnt.elements(), key=keyfunc))[:nentries]
         tuples.append(result)
 
-    tuples = list(zip(*tuples))
+    tuples = lzip(*tuples)
 
     # convert tuples to index
     if nentries == 1:
diff --git a/scripts/bench_join.py b/scripts/bench_join.py
index 758a4fedd..a3bd4157a 100644
--- a/scripts/bench_join.py
+++ b/scripts/bench_join.py
@@ -1,4 +1,4 @@
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import numpy as np
 import pandas.lib as lib
 from pandas import *
@@ -28,8 +28,8 @@ bvf = np.random.randn(n, K)
 a_series = Series(av, index=a)
 b_series = Series(bv, index=b)
 
-a_frame = DataFrame(avf, index=a, columns=list(range(K)))
-b_frame = DataFrame(bvf, index=b, columns=list(range(K, 2 * K)))
+a_frame = DataFrame(avf, index=a, columns=lrange(K))
+b_frame = DataFrame(bvf, index=b, columns=lrange(K, 2 * K))
 
 
 def do_left_join(a, b, av, bv):
@@ -163,8 +163,8 @@ def bench_python(n=100000, pct_overlap=0.20, K=1):
         avf = np.random.randn(n, K)
         bvf = np.random.randn(n, K)
 
-        a_frame = DataFrame(avf, index=a, columns=list(range(K)))
-        b_frame = DataFrame(bvf, index=b, columns=list(range(K, 2 * K)))
+        a_frame = DataFrame(avf, index=a, columns=lrange(K))
+        b_frame = DataFrame(bvf, index=b, columns=lrange(K, 2 * K))
 
         all_results[logn] = result = {}
 
diff --git a/scripts/bench_join_multi.py b/scripts/bench_join_multi.py
index 0683fbb67..818ac3009 100644
--- a/scripts/bench_join_multi.py
+++ b/scripts/bench_join_multi.py
@@ -1,9 +1,9 @@
 from pandas import *
 
 import numpy as np
-from six.moves import zip
+from pandas.util.py3compat import zip
 from pandas.util.testing import rands
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lzip
 import pandas.lib as lib
 
 N = 100000
@@ -11,17 +11,17 @@ N = 100000
 key1 = [rands(10) for _ in range(N)]
 key2 = [rands(10) for _ in range(N)]
 
-zipped = list(zip(key1, key2))
+zipped = lzip(key1, key2)
 
 
 def _zip(*args):
     arr = np.empty(N, dtype=object)
-    arr[:] = list(zip(*args))
+    arr[:] = lzip(*args)
     return arr
 
 
 def _zip2(*args):
-    return lib.list_to_object_array(list(zip(*args)))
+    return lib.list_to_object_array(lzip(*args))
 
 index = MultiIndex.from_arrays([key1, key2])
 to_join = DataFrame({'j1': np.random.randn(100000)}, index=index)
diff --git a/scripts/find_commits_touching_func.py b/scripts/find_commits_touching_func.py
index 925d40d0f..a4c76671d 100755
--- a/scripts/find_commits_touching_func.py
+++ b/scripts/find_commits_touching_func.py
@@ -4,9 +4,9 @@
 # copryright 2013, y-p @ github
 
 from __future__ import print_function
-from pandas.util.py3compat import range
+from pandas.util.py3compat import range, lrange
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 
 """Search the git history for all commits touching a named method
 
@@ -162,7 +162,7 @@ def pprint_hits(hits):
 
     print("\nThese commits touched the %s method in these files on these dates:\n" \
           % args.funcname)
-    for i in sorted(list(range(len(hits))),key=sorter):
+    for i in sorted(lrange(len(hits)),key=sorter):
         hit = hits[i]
         h,s,d=get_commit_vitals(hit.commit)
         p=hit.path.split(os.path.realpath(os.curdir)+os.path.sep)[-1]
diff --git a/scripts/json_manip.py b/scripts/json_manip.py
index 4733df68c..7bea33055 100644
--- a/scripts/json_manip.py
+++ b/scripts/json_manip.py
@@ -75,7 +75,7 @@ from operator import attrgetter as aget, itemgetter as iget
 import operator
 import sys
 import six
-from six.moves import map
+from pandas.util.py3compat import map
 import pandas.util.compat as compat
 
 
diff --git a/vb_suite/groupby.py b/vb_suite/groupby.py
index 665a33f92..748b101b1 100644
--- a/vb_suite/groupby.py
+++ b/vb_suite/groupby.py
@@ -1,6 +1,6 @@
 from vbench.api import Benchmark
 from datetime import datetime
-from six.moves import map
+from pandas.util.py3compat import map
 
 common_setup = """from pandas_vb_common import *
 """
@@ -285,12 +285,12 @@ n_columns = 3
 share_na = 0.1
 
 dates = date_range('1997-12-31', periods=n_dates, freq='B')
-dates = Index(list(map(lambda x: x.year * 10000 + x.month * 100 + x.day, dates)))
+dates = Index(lmap(lambda x: x.year * 10000 + x.month * 100 + x.day, dates))
 
 secid_min = int('10000000', 16)
 secid_max = int('F0000000', 16)
 step = (secid_max - secid_min) // (n_securities - 1)
-security_ids = list(map(lambda x: hex(x)[2:10].upper(), range(secid_min, secid_max + 1, step)))
+security_ids = lmap(lambda x: hex(x)[2:10].upper(), range(secid_min, secid_max + 1, step))
 
 data_index = MultiIndex(levels=[dates.values, security_ids],
     labels=[[i for i in xrange(n_dates) for _ in xrange(n_securities)], range(n_securities) * n_dates],
diff --git a/vb_suite/pandas_vb_common.py b/vb_suite/pandas_vb_common.py
index 37775557f..8206c3554 100644
--- a/vb_suite/pandas_vb_common.py
+++ b/vb_suite/pandas_vb_common.py
@@ -27,6 +27,6 @@ except ImportError:
 try:
     # if no range in py3compat, then don't import zip or map either
     from pandas.util.py3compat import range
-    from six.moves import zip, map
+    from pandas.util.py3compat import zip, map
 except ImportError:
     pass
diff --git a/vb_suite/parser.py b/vb_suite/parser.py
index 8bcba2b20..caae86afd 100644
--- a/vb_suite/parser.py
+++ b/vb_suite/parser.py
@@ -44,7 +44,7 @@ read_csv_comment2 = Benchmark(stmt, setup,
                               start_date=datetime(2011, 11, 1))
 
 setup = common_setup + """
-from six.moves import cStringIO as StringIO
+from pandas.util.py3compat import cStringIO as StringIO
 import os
 N = 10000
 K = 8
@@ -63,7 +63,7 @@ sdate = datetime(2012, 5, 7)
 read_table_multiple_date = Benchmark(cmd, setup, start_date=sdate)
 
 setup = common_setup + """
-from six.moves import cStringIO as StringIO
+from pandas.util.py3compat import cStringIO as StringIO
 import os
 N = 10000
 K = 8
diff --git a/vb_suite/test_perf.py b/vb_suite/test_perf.py
index d7a5b9d3e..5101cf7f9 100755
--- a/vb_suite/test_perf.py
+++ b/vb_suite/test_perf.py
@@ -28,7 +28,7 @@ everything and calculate a ration for the timing information.
 from __future__ import print_function
 
 from pandas.util.py3compat import range
-from six.moves import map
+from pandas.util.py3compat import map
 import shutil
 import os
 import sys
