commit 1e5c9d05c5bb5b8e171d84afb8d6c8176e8982e9
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Dec 9 14:12:31 2012 -0500

    API: add prefix option to parsers for default column names. make default column names consistent with range(n) DataFrame constructor behavior. close #2034

diff --git a/pandas/core/series.py b/pandas/core/series.py
index 38e756a73..9bffca696 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -2619,7 +2619,7 @@ copy : boolean, default False
         df = DataFrame.from_csv(path, header=header, index_col=index_col,
                                 sep=sep, parse_dates=parse_dates,
                                 encoding=encoding)
-        result = df.ix[:, 0]
+        result = df.icol(0)
         result.index.name = result.name = None
         return result
 
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 87a2ca469..fb92d3947 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -54,6 +54,8 @@ index_col : int or sequence, default None
 names : array-like
     List of column names to use. If file contains no header row, then you
     should explicitly pass header=None
+prefix : string or None (default)
+    Prefix to add to column numbers when no header, e.g 'X' for X0, X1, ...
 na_values : list-like or dict, default None
     Additional strings to recognize as NA/NaN. If dict passed, specific
     per-column NA values
@@ -207,6 +209,7 @@ _parser_defaults = {
     'header': 0,
     'index_col': None,
     'names': None,
+    'prefix': None,
     'skiprows': None,
     'na_values': None,
     'true_values': None,
@@ -276,6 +279,7 @@ def _make_parser_function(name, sep=','):
                  header=0,
                  index_col=None,
                  names=None,
+                 prefix=None,
                  skiprows=None,
                  skipfooter=None,
                  skip_footer=0,
@@ -335,6 +339,7 @@ def _make_parser_function(name, sep=','):
                     header=header,
                     index_col=index_col,
                     names=names,
+                    prefix=prefix,
                     skiprows=skiprows,
                     na_values=na_values,
                     true_values=true_values,
@@ -630,6 +635,7 @@ class ParserBase(object):
     def __init__(self, kwds):
         self.names = kwds.get('names')
         self.orig_names = None
+        self.prefix = kwds.pop('prefix', None)
 
         self.index_col = kwds.pop('index_col', None)
         self.index_names = None
@@ -845,7 +851,6 @@ class CParserWrapper(ParserBase):
         kwds = kwds.copy()
 
         self.as_recarray = kwds.get('as_recarray', False)
-
         ParserBase.__init__(self, kwds)
 
         if 'utf-16' in (kwds.get('encoding') or ''):
@@ -859,14 +864,19 @@ class CParserWrapper(ParserBase):
         # XXX
         self.usecols = self._reader.usecols
 
+        passed_names = self.names is None
+
         if self._reader.header is None:
             self.names = None
         else:
             self.names = list(self._reader.header)
 
         if self.names is None:
-            self.names = ['X%d' % i
-                          for i in range(self._reader.table_width)]
+            if self.prefix:
+                self.names = ['X%d' % i
+                              for i in range(self._reader.table_width)]
+            else:
+                self.names = range(self._reader.table_width)
 
         # XXX
         self._set_noconvert_columns()
@@ -880,6 +890,9 @@ class CParserWrapper(ParserBase):
                  self.index_col) = _clean_index_names(self.names,
                                                       self.index_col)
 
+            if self._reader.header is None and not passed_names:
+                self.index_names = [None] * len(self.index_names)
+
         self._implicit_index = self._reader.leading_cols > 0
 
     def _set_noconvert_columns(self):
@@ -1266,7 +1279,10 @@ class PythonParser(ParserBase):
 
             ncols = len(line)
             if not names:
-                columns = ['X%d' % i for i in range(ncols)]
+                if self.prefix:
+                    columns = ['X%d' % i for i in range(ncols)]
+                else:
+                    columns = range(ncols)
             else:
                 columns = names
 
@@ -1552,11 +1568,13 @@ def _try_convert_dates(parser, colspec, data_dict, columns):
 
     for c in colspec:
         if c in colset:
-            colnames.append(str(c))
-        elif isinstance(c, int):
+            colnames.append(c)
+        elif isinstance(c, int) and c not in columns:
             colnames.append(str(columns[c]))
+        else:
+            colnames.append(c)
 
-    new_name = '_'.join(colnames)
+    new_name = '_'.join([str(x) for x in colnames])
     to_parse = [data_dict[c] for c in colnames if c in data_dict]
 
     try:
@@ -1610,7 +1628,7 @@ def _clean_index_names(columns, index_col):
             index_names.append(name)
 
     # hack
-    if index_names[0] is not None and 'Unnamed' in index_names[0]:
+    if isinstance(index_names[0], basestring) and 'Unnamed' in index_names[0]:
         index_names[0] = None
 
     return index_names, columns, index_col
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 9efdfb243..b0e0a5ab6 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -178,6 +178,7 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 
         df = self.read_csv(StringIO(data), header=None,
                            date_parser=func,
+                           prefix='X',
                            parse_dates={'nominal' : [1, 2],
                                         'actual' : [1,3]})
         self.assert_('nominal' in df)
@@ -197,9 +198,9 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
         self.assert_('nominal' in df)
         self.assert_('actual' in df)
 
-        self.assert_('X1' in df)
-        self.assert_('X2' in df)
-        self.assert_('X3' in df)
+        self.assert_(1 in df)
+        self.assert_(2 in df)
+        self.assert_(3 in df)
 
         data = """\
 KORD,19990127, 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
@@ -210,6 +211,7 @@ KORD,19990127, 22:00:00, 21:56:00, -0.5900, 1.7100, 5.1000, 0.0000, 290.0000
 KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
 """
         df = read_csv(StringIO(data), header=None,
+                      prefix='X',
                       parse_dates=[[1, 2], [1,3]])
 
         self.assert_('X1_X2' in df)
@@ -224,11 +226,11 @@ KORD,19990127, 23:00:00, 22:56:00, -0.5900, 1.7100, 4.6000, 0.0000, 280.0000
         df = read_csv(StringIO(data), header=None,
                       parse_dates=[[1, 2], [1,3]], keep_date_col=True)
 
-        self.assert_('X1_X2' in df)
-        self.assert_('X1_X3' in df)
-        self.assert_('X1' in df)
-        self.assert_('X2' in df)
-        self.assert_('X3' in df)
+        self.assert_('1_2' in df)
+        self.assert_('1_3' in df)
+        self.assert_(1 in df)
+        self.assert_(2 in df)
+        self.assert_(3 in df)
 
         data = '''\
 KORD,19990127 19:00:00, 18:56:00, 0.8100, 2.8100, 7.2000, 0.0000, 280.0000
@@ -506,13 +508,12 @@ ignore,this,row
                               index_col=0, parse_dates=True)
 
         expected = DataFrame(np.arange(1., 10.).reshape((3,3)),
-                             columns=['X1', 'X2', 'X3'],
+                             columns=[1, 2, 3],
                              index=[datetime(2000, 1, 1), datetime(2000, 1, 2),
                                     datetime(2000, 1, 3)])
         tm.assert_frame_equal(data, expected)
         tm.assert_frame_equal(data, data2)
 
-
     def test_detect_string_na(self):
         data = """A,B
 foo,bar
@@ -666,6 +667,9 @@ c,4,5
 11,12,13,14,15
 """
         df = self.read_table(StringIO(data), sep=',', header=None)
+        df_pref = self.read_table(StringIO(data), sep=',', prefix='X',
+                                  header=None)
+
         names = ['foo', 'bar', 'baz', 'quux', 'panda']
         df2 = self.read_table(StringIO(data), sep=',', header=None,
                               names=names)
@@ -674,8 +678,11 @@ c,4,5
                     [11,12,13,14,15]]
         assert_almost_equal(df.values, expected)
         assert_almost_equal(df.values, df2.values)
-        self.assert_(np.array_equal(df.columns,
+
+        self.assert_(np.array_equal(df_pref.columns,
                                     ['X0', 'X1', 'X2', 'X3', 'X4']))
+        self.assert_(np.array_equal(df.columns, range(5)))
+
         self.assert_(np.array_equal(df2.columns, names))
 
     def test_header_with_index_col(self):
@@ -717,7 +724,7 @@ baz,7,8,9
     def test_read_table_unicode(self):
         fin = BytesIO(u'\u0141aski, Jan;1'.encode('utf-8'))
         df1 = read_table(fin, sep=";", encoding="utf-8", header=None)
-        self.assert_(isinstance(df1['X0'].values[0], unicode))
+        self.assert_(isinstance(df1[0].values[0], unicode))
 
     def test_read_table_wrong_num_columns(self):
         # too few!
@@ -1053,7 +1060,7 @@ c,4,5,01/03/2009
         f = lambda x: x.strip()
         converter = {0: f}
         df = self.read_csv(StringIO(data), header=None, converters=converter)
-        self.assert_(df.X0.dtype == object)
+        self.assert_(df[0].dtype == object)
 
     def test_converters_euro_decimal_format(self):
         data = """Id;Number1;Number2;Text1;Text2;Number3
@@ -1096,8 +1103,8 @@ qux foo
 foo
 bar"""
         df = read_csv(StringIO(text), header=None)
-        expected = DataFrame({'X0' : ['foo', 'bar baz', 'qux foo',
-                                      'foo', 'bar']})
+        expected = DataFrame({0 : ['foo', 'bar baz', 'qux foo',
+                                   'foo', 'bar']})
         tm.assert_frame_equal(df, expected)
 
     def test_parse_dates_custom_euroformat(self):
@@ -1441,9 +1448,9 @@ A,B,C
         pth = os.path.join(pth, 'tests/data/unicode_series.csv')
 
         result = self.read_csv(pth, header=None, encoding='latin-1')
-        result = result.set_index('X0')
+        result = result.set_index(0)
 
-        got = result['X1'][1632]
+        got = result[1][1632]
         expected = u'\xc1 k\xf6ldum klaka (Cold Fever) (1994)'
 
         self.assertEquals(got, expected)
diff --git a/pandas/tests/test_format.py b/pandas/tests/test_format.py
index db9a64270..b0b311179 100644
--- a/pandas/tests/test_format.py
+++ b/pandas/tests/test_format.py
@@ -392,7 +392,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         filepath = os.path.join(pth, 'data', 'unicode_series.csv')
         df = pandas.read_csv(filepath, header=None,encoding='latin1')
         repr(df)
-        repr(df['X1'])
+        repr(df[1])
 
     def test_repr_corner(self):
         # representing infs poses no problems
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index f3d6f1c89..88c78044d 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -2143,6 +2143,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.ts.to_csv(path)
         ts = Series.from_csv(path)
         assert_series_equal(self.ts, ts)
+        self.assertTrue(ts.index.name is None)
 
         self.series.to_csv(path)
         series = Series.from_csv(path)
