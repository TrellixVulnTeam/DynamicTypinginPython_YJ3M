commit 6c1f1119f84492a85d0537cdc074d8956db10cad
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat May 19 12:28:10 2012 -0400

    REF: more nanosecond support fixes, test suite passes #1238

diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 44673249d..d46a199a2 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -108,6 +108,8 @@ def factorize(values, sort=False, order=None, na_sentinel=-1):
     Returns
     -------
     """
+    values = np.asarray(values)
+    is_datetime = com.is_datetime64_dtype(values)
     hash_klass, values = _get_data_algo(values, _hashtables)
 
     uniques = []
@@ -129,6 +131,9 @@ def factorize(values, sort=False, order=None, na_sentinel=-1):
         uniques = uniques.take(sorter)
         counts = counts.take(sorter)
 
+    if is_datetime:
+        uniques = np.array(uniques, dtype='M8[ns]')
+
     return labels, uniques, counts
 
 def value_counts(values, sort=True, ascending=False):
@@ -179,6 +184,9 @@ def _get_data_algo(values, func_map):
     if com.is_float_dtype(values):
         f = func_map['float64']
         values = com._ensure_float64(values)
+    elif com.is_datetime64_dtype(values):
+        f = func_map['int64']
+        values = values.view('i8')
     elif com.is_integer_dtype(values):
         f = func_map['int64']
         values = com._ensure_int64(values)
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 2da212cbd..f8418788b 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -171,7 +171,7 @@ _take1d_dict = {
     'int64' : _algos.take_1d_int64,
     'object' : _algos.take_1d_object,
     'bool' : _view_wrapper(_algos.take_1d_bool, np.uint8),
-    'datetime64[us]' : _view_wrapper(_algos.take_1d_int64, np.int64,
+    'datetime64[ns]' : _view_wrapper(_algos.take_1d_int64, np.int64,
                                      na_override=lib.NaT),
 }
 
@@ -181,7 +181,7 @@ _take2d_axis0_dict = {
     'int64' : _algos.take_2d_axis0_int64,
     'object' : _algos.take_2d_axis0_object,
     'bool' : _view_wrapper(_algos.take_2d_axis0_bool, np.uint8),
-    'datetime64[us]' : _view_wrapper(_algos.take_2d_axis0_int64, np.int64,
+    'datetime64[ns]' : _view_wrapper(_algos.take_2d_axis0_int64, np.int64,
                                      na_override=lib.NaT),
 }
 
@@ -191,7 +191,7 @@ _take2d_axis1_dict = {
     'int64' : _algos.take_2d_axis1_int64,
     'object' : _algos.take_2d_axis1_object,
     'bool' : _view_wrapper(_algos.take_2d_axis1_bool, np.uint8),
-    'datetime64[us]' : _view_wrapper(_algos.take_2d_axis1_int64, np.int64,
+    'datetime64[ns]' : _view_wrapper(_algos.take_2d_axis1_int64, np.int64,
                                      na_override=lib.NaT),
 }
 
@@ -201,7 +201,7 @@ _take2d_multi_dict = {
     'int64' : _algos.take_2d_multi_int64,
     'object' : _algos.take_2d_multi_object,
     'bool' : _view_wrapper(_algos.take_2d_multi_bool, np.uint8),
-    'datetime64[us]' : _view_wrapper(_algos.take_2d_multi_int64, np.int64,
+    'datetime64[ns]' : _view_wrapper(_algos.take_2d_multi_int64, np.int64,
                                      na_override=lib.NaT),
 }
 
@@ -246,7 +246,7 @@ def take_1d(arr, indexer, out=None, fill_value=np.nan):
                                     out.dtype)
                 out = _maybe_upcast(out)
                 np.putmask(out, mask, fill_value)
-    elif dtype_str in ('float64', 'object', 'datetime64[us]'):
+    elif dtype_str in ('float64', 'object', 'datetime64[ns]'):
         if out is None:
             out = np.empty(n, dtype=arr.dtype)
         take_f(arr, _ensure_int64(indexer), out=out, fill_value=fill_value)
@@ -284,7 +284,7 @@ def take_2d_multi(arr, row_idx, col_idx, fill_value=np.nan):
                    _ensure_int64(col_idx), out=out,
                    fill_value=fill_value)
             return out
-    elif dtype_str in ('float64', 'object', 'datetime64[us]'):
+    elif dtype_str in ('float64', 'object', 'datetime64[ns]'):
         out = np.empty(out_shape, dtype=arr.dtype)
         take_f(arr, _ensure_int64(row_idx), _ensure_int64(col_idx), out=out,
                fill_value=fill_value)
@@ -326,7 +326,7 @@ def take_2d(arr, indexer, out=None, mask=None, needs_masking=None, axis=0,
             take_f = _get_take2d_function(dtype_str, axis=axis)
             take_f(arr, _ensure_int64(indexer), out=out, fill_value=fill_value)
             return out
-    elif dtype_str in ('float64', 'object', 'datetime64[us]'):
+    elif dtype_str in ('float64', 'object', 'datetime64[ns]'):
         if out is None:
             out = np.empty(out_shape, dtype=arr.dtype)
         take_f = _get_take2d_function(dtype_str, axis=axis)
diff --git a/pandas/core/factor.py b/pandas/core/factor.py
index 650ff033f..6bc45924a 100644
--- a/pandas/core/factor.py
+++ b/pandas/core/factor.py
@@ -18,11 +18,17 @@ class Factor(np.ndarray):
       * levels : ndarray
     """
     def __new__(cls, data):
-        data = np.asarray(data, dtype=object)
-        levels, factor = unique_with_labels(data)
-        factor = factor.view(Factor)
-        factor.levels = levels
-        return factor
+        from pandas.core.index import _ensure_index
+        from pandas.core.algorithms import factorize
+
+        try:
+            labels, levels, _ = factorize(data, sort=True)
+        except TypeError:
+            labels, levels, _ = factorize(data, sort=False)
+
+        labels = labels.view(Factor)
+        labels.levels = _ensure_index(levels)
+        return labels
 
     levels = None
 
@@ -51,21 +57,3 @@ class Factor(np.ndarray):
         else:
             return np.ndarray.__getitem__(self, key)
 
-
-def unique_with_labels(values):
-    from pandas.core.index import Index
-    rizer = lib.Factorizer(len(values))
-    labels, _ = rizer.factorize(values, sort=False)
-    uniques = Index(rizer.uniques)
-    labels = com._ensure_platform_int(labels)
-    try:
-        sorter = uniques.argsort()
-        reverse_indexer = np.empty(len(sorter), dtype=np.int_)
-        reverse_indexer.put(sorter, np.arange(len(sorter)))
-        labels = reverse_indexer.take(labels)
-        uniques = uniques.take(sorter)
-    except TypeError:
-        pass
-
-    return uniques, labels
-
diff --git a/pandas/core/format.py b/pandas/core/format.py
index 6ae204b94..c22e2df22 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -571,16 +571,30 @@ class Datetime64Formatter(GenericArrayFormatter):
         if self.formatter:
             formatter = self.formatter
         else:
-            def formatter(x):
-                if isnull(x):
-                    return 'NaT'
-                else:
-                    return str(x)
+            formatter = _format_datetime64
 
         fmt_values = [formatter(x) for x in self.values]
-
         return _make_fixed_width(fmt_values, self.justify)
 
+def _format_datetime64(x):
+    if isnull(x):
+        return 'NaT'
+
+    stamp = lib.Timestamp(x)
+    base = stamp.strftime('%Y-%m-%d %H:%M:%S')
+
+    fraction = stamp.microsecond * 1000 + stamp.nanosecond
+    digits = 9
+
+    if fraction == 0:
+        return base
+
+    while (fraction % 10) == 0:
+        fraction /= 10
+        digits -= 1
+
+    return base + ('.%%.%id' % digits) % fraction
+
 
 def _make_fixed_width(strings, justify='right'):
     if len(strings) == 0:
diff --git a/pandas/core/index.py b/pandas/core/index.py
index dee176472..0b10fbbbd 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -691,8 +691,8 @@ class Index(np.ndarray):
             return pself.get_indexer(ptarget, method=method, limit=limit)
 
         if self.dtype != target.dtype:
-            this = Index(self, dtype=object)
-            target = Index(target, dtype=object)
+            this = self.astype(object)
+            target = target.astype(object)
             return this.get_indexer(target, method=method, limit=limit)
 
         if not self.is_unique:
@@ -1172,8 +1172,12 @@ class MultiIndex(Index):
         levels = [_ensure_index(lev) for lev in levels]
         labels = [np.asarray(labs, dtype=np.int_) for labs in labels]
 
-        values = [ndtake(np.asarray(lev), lab)
+        values = [ndtake(lev.values, lab)
                   for lev, lab in zip(levels, labels)]
+
+        # Need to box timestamps, etc.
+        values = _clean_arrays(values)
+
         subarr = lib.fast_zip(values).view(cls)
 
         subarr.levels = levels
@@ -2372,3 +2376,13 @@ def _maybe_box_dtindex(idx):
         return Index(_dt_box_array(idx.asi8), dtype='object')
     return idx
 
+def _clean_arrays(values):
+    result = []
+    for arr in values:
+        if np.issubdtype(arr.dtype, np.datetime_):
+            result.append(lib.map_infer(arr, lib.Timestamp))
+        else:
+            result.append(arr)
+    return result
+
+
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index e742bdb55..ad65a589c 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -405,7 +405,7 @@ def unique1d(values):
         uniques = np.array(table.unique(com._ensure_int64(values)),
                            dtype=np.int64)
 
-        if values.dtype == np.datetime64:
+        if issubclass(values.dtype.type, np.datetime_):
             uniques = uniques.view('M8[ns]')
     else:
         table = lib.PyObjectHashTable(len(values))
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 7ac5ad901..b8724e854 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -839,8 +839,7 @@ class HDFStore(object):
 
         columns = _maybe_convert(sel.values['column'],
                                  table._v_attrs.columns_kind)
-        index = _maybe_convert(sel.values['index'],
-                               table._v_attrs.index_kind)
+        index = _maybe_convert(sel.values['index'], table._v_attrs.index_kind)
         values = sel.values['values']
 
         major = Factor(index)
@@ -995,7 +994,7 @@ def _maybe_convert(values, val_kind):
 
 def _get_converter(kind):
     if kind == 'datetime64':
-        return lambda x: np.datetime64(x)
+        return lambda x: np.array(x, dtype='M8[ns]')
     if kind == 'datetime':
         return lib.convert_timestamps
     else: # pragma: no cover
@@ -1069,7 +1068,7 @@ class Selection(object):
             field = c['field']
 
             if field == 'index' and self.index_kind == 'datetime64':
-                val = np.datetime64(value).view('i8')
+                val = lib.Timestamp(value).value
                 self.conditions.append('(%s %s %s)' % (field,op,val))
             elif field == 'index' and isinstance(value, datetime):
                 value = time.mktime(value.timetuple())
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 5fccc5a39..f07e95cb2 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -376,7 +376,8 @@ c,4,5
         lev = expected.index.levels[0]
         expected.index.levels[0] = lev.to_datetime(dayfirst=True)
         expected['aux_date'] = to_datetime(expected['aux_date'],
-                                           dayfirst=True).astype('O')
+                                           dayfirst=True)
+        expected['aux_date'] = map(Timestamp, expected['aux_date'])
         self.assert_(isinstance(expected['aux_date'][0], datetime))
 
         df = read_csv(StringIO(data), sep=";", index_col = range(4),
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 9291d9076..673d759de 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -741,6 +741,23 @@ class SparseDataFrame(DataFrame):
             else:
                 return self._apply_broadcast(func, axis)
 
+    def applymap(self, func):
+        """
+        Apply a function to a DataFrame that is intended to operate
+        elementwise, i.e. like doing map(func, series) for each series in the
+        DataFrame
+
+        Parameters
+        ----------
+        func : function
+            Python function, returns a single value from a single value
+
+        Returns
+        -------
+        applied : DataFrame
+        """
+        return self.apply(lambda x: map(func, x))
+
     @Appender(DataFrame.fillna.__doc__)
     def fillna(self, value=None, method='pad', inplace=False, limit=None):
         new_series = {}
diff --git a/pandas/src/datetime.pyx b/pandas/src/datetime.pyx
index f623376bd..a73a71f76 100644
--- a/pandas/src/datetime.pyx
+++ b/pandas/src/datetime.pyx
@@ -136,6 +136,11 @@ class Timestamp(_Timestamp):
         conv = tz.normalize(self)
         return Timestamp(conv)
 
+    def replace(self, **kwds):
+        return Timestamp(datetime.replace(self, **kwds),
+                         offset=self.offset)
+
+
 cdef inline bint is_timestamp(object o):
     return isinstance(o, Timestamp)
 
@@ -194,10 +199,38 @@ def apply_offset(ndarray[object] values, object offset):
 # (see Timestamp class above). This will serve as a C extension type that
 # shadows the python class, where we do any heavy lifting.
 cdef class _Timestamp(datetime):
-    cdef public:
+    cdef readonly:
         int64_t value, nanosecond
         object offset       # frequency reference
 
+    def __richcmp__(_Timestamp self, object other, int op):
+        cdef _Timestamp ots
+
+        if isinstance(other, _Timestamp):
+            ots = other
+        elif isinstance(other, datetime):
+            ots = Timestamp(other)
+        else:
+            if op == 2:
+                return False
+            elif op == 3:
+                return True
+            else:
+                raise TypeError('Cannot compare Timestamp with %s' % str(other))
+
+        if op == 2: # ==
+            return self.value == ots.value
+        elif op == 3: # !=
+            return self.value != ots.value
+        elif op == 0: # <
+            return self.value < ots.value
+        elif op == 1: # <=
+            return self.value <= ots.value
+        elif op == 4: # >
+            return self.value > ots.value
+        elif op == 5: # >=
+            return self.value >= ots.value
+
     def __add__(self, other):
         if is_integer_object(other):
             if self.offset is None:
@@ -313,6 +346,7 @@ cdef inline int64_t _pydatetime_to_dts(object val, pandas_datetimestruct *dts):
     dts.min = PyDateTime_DATE_GET_MINUTE(val)
     dts.sec = PyDateTime_DATE_GET_SECOND(val)
     dts.us = PyDateTime_DATE_GET_MICROSECOND(val)
+    dts.ps = dts.as = 0
     return pandas_datetimestruct_to_datetime(PANDAS_FR_ns, dts)
 
 cdef inline int64_t _dtlike_to_datetime64(object val,
@@ -324,6 +358,7 @@ cdef inline int64_t _dtlike_to_datetime64(object val,
     dts.min = val.minute
     dts.sec = val.second
     dts.us = val.microsecond
+    dts.ps = dts.as = 0
     return pandas_datetimestruct_to_datetime(PANDAS_FR_ns, dts)
 
 cdef inline int64_t _date_to_datetime64(object val,
@@ -331,10 +366,8 @@ cdef inline int64_t _date_to_datetime64(object val,
     dts.year = PyDateTime_GET_YEAR(val)
     dts.month = PyDateTime_GET_MONTH(val)
     dts.day = PyDateTime_GET_DAY(val)
-    dts.hour = 0
-    dts.min = 0
-    dts.sec = 0
-    dts.us = 0
+    dts.hour = dts.min = dts.sec = dts.us = 0
+    dts.ps = dts.as = 0
     return pandas_datetimestruct_to_datetime(PANDAS_FR_ns, dts)
 
 
@@ -928,7 +961,7 @@ cpdef ndarray _unbox_utcoffsets(object transinfo):
     arr = np.empty(sz, dtype='i8')
 
     for i in range(sz):
-        arr[i] = int(total_seconds(transinfo[i][0])) * 1000000
+        arr[i] = int(total_seconds(transinfo[i][0])) * 1000000000
 
     return arr
 
@@ -1243,7 +1276,7 @@ def dt64arr_to_periodarr(ndarray[int64_t] dtarr, int freq):
     for i in range(l):
         pandas_datetime_to_datetimestruct(dtarr[i], PANDAS_FR_ns, &dts)
         out[i] = get_period_ordinal(dts.year, dts.month, dts.day,
-                                  dts.hour, dts.min, dts.sec, freq)
+                                    dts.hour, dts.min, dts.sec, freq)
     return out
 
 def periodarr_to_dt64arr(ndarray[int64_t] periodarr, int freq):
@@ -1338,7 +1371,7 @@ cpdef int64_t period_ordinal_to_dt64(int64_t ordinal, int freq):
     dts.hour = dinfo.hour
     dts.min = dinfo.minute
     dts.sec = int(dinfo.second)
-    dts.us = 0
+    dts.us = dts.ps = 0
 
     return pandas_datetimestruct_to_datetime(PANDAS_FR_ns, &dts)
 
diff --git a/pandas/src/inference.pyx b/pandas/src/inference.pyx
index 6c88d2931..63e6776ab 100644
--- a/pandas/src/inference.pyx
+++ b/pandas/src/inference.pyx
@@ -491,15 +491,13 @@ def map_infer(ndarray arr, object f):
     '''
     cdef:
         Py_ssize_t i, n
-        flatiter it
         ndarray[object] result
         object val
 
-    it = <flatiter> PyArray_IterNew(arr)
     n = len(arr)
     result = np.empty(n, dtype=object)
     for i in range(n):
-        val = f(PyArray_GETITEM(arr, PyArray_ITER_DATA(it)))
+        val = f(util.get_value_at(arr, i))
 
         # unbox 0-dim arrays, GH #690
         if is_array(val) and PyArray_NDIM(val) == 0:
@@ -508,9 +506,6 @@ def map_infer(ndarray arr, object f):
 
         result[i] = val
 
-
-        PyArray_ITER_NEXT(it)
-
     return maybe_convert_objects(result, try_float=0)
 
 def to_object_array(list rows):
diff --git a/pandas/src/reduce.pyx b/pandas/src/reduce.pyx
index 2a956c53f..49cdddb4b 100644
--- a/pandas/src/reduce.pyx
+++ b/pandas/src/reduce.pyx
@@ -85,11 +85,14 @@ cdef class Reducer:
         except Exception, e:
             if hasattr(e, 'args'):
                 e.args = e.args + (i,)
+            raise
         finally:
             # so we don't free the wrong memory
             chunk.data = dummy_buf
+
         if result.dtype == np.object_:
             result = maybe_convert_objects(result)
+
         return result
 
     def _get_result_array(self, object res):
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 904596ddc..843471ae9 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1629,7 +1629,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertEqual(2, frame['C'][2])
 
         # masked np.datetime64 stays (use lib.NaT as null)
-        mat = ma.masked_all((2, 3), dtype=np.datetime64)
+        mat = ma.masked_all((2, 3), dtype='M8[ns]')
         # 2-D input
         frame = DataFrame(mat, columns=['A', 'B', 'C'], index=[1, 2])
 
@@ -5546,7 +5546,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         idx2 = IndexType("baz", "bof")
         index = Index([idx1, idx2], name="composite_index")
         df = DataFrame([(1, 2), (3, 4)], index=index, columns=["A", "B"])
-        print df.ix[IndexType("foo", "bar")]["A"]
         self.assertEqual(df.ix[IndexType("foo", "bar")]["A"], 1)
 
     def test_bool_raises_value_error_1069(self):
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index fd3402ee0..8f1873a45 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1305,7 +1305,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertRaises(ValueError, a.__lt__, b)
 
     def test_between(self):
-        s = Series(bdate_range('1/1/2000', periods=20), dtype=object)
+        s = Series(bdate_range('1/1/2000', periods=20).asobject)
         s[::2] = np.nan
 
         result = s[s.between(s[3], s[17])]
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index 4501e1d6a..6eb6e9487 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -753,10 +753,10 @@ class _FrequencyInferer(object):
                 return _maybe_add_count('L', delta / _ONE_MILLI)
             elif _is_multiple(delta, _ONE_MICRO):
                 # Microseconds
-                return _maybe_add_count('L', delta / _ONE_MICRO)
+                return _maybe_add_count('U', delta / _ONE_MICRO)
             else:
                 # Nanoseconds
-                return _maybe_add_count('U', delta)
+                return _maybe_add_count('N', delta)
 
     @cache_readonly
     def day_deltas(self):
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 4b3e63990..051477fa7 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -1229,8 +1229,7 @@ def _dt_box_array(arr, offset=None, tz=None):
         return arr
 
     boxfunc = lambda x: Timestamp(x, offset=offset, tz=tz)
-    boxer = np.frompyfunc(boxfunc, 1, 1)
-    return boxer(arr)
+    return lib.map_infer(arr, boxfunc)
 
 
 def _to_m8(key):
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 46d22700f..3db105db4 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -990,11 +990,13 @@ def _delta_to_tick(delta):
             else:
                 return Second(seconds)
     else:
-        mus = _delta_to_nanoseconds(delta)
-        if mus % 1000 == 0:
-            return Milli(mus // 1000)
+        nanos = _delta_to_nanoseconds(delta)
+        if nanos % 1000000 == 0:
+            return Milli(nanos // 1000000)
+        elif nanos % 1000 == 0:
+            return Micro(nanos // 1000)
         else:
-            return Micro(mus)
+            return Nano(nanos)
 
 def _delta_to_nanoseconds(delta):
     if isinstance(delta, Tick):
@@ -1030,6 +1032,10 @@ class Micro(Tick):
     _inc = timedelta(microseconds=1)
     _rule_base = 'U'
 
+class Nano(Tick):
+    _inc = 1
+    _rule_base = 'N'
+
 BDay = BusinessDay
 BMonthEnd = BusinessMonthEnd
 BMonthBegin = BusinessMonthBegin
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index a662c3539..5cae2375c 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -466,6 +466,9 @@ def _period_box_array(arr, freq):
     return boxer(arr)
 
 def dt64arr_to_periodarr(data, freq):
+    if data.dtype != np.dtype('M8[ns]'):
+        raise ValueError('Wrong dtype: %s' % data.dtype)
+
     if data is None:
         return data
 
@@ -607,7 +610,7 @@ class PeriodIndex(Int64Index):
                     raise ValueError(('freq not specified and cannot be '
                                       'inferred from first element'))
 
-                if data.dtype == np.datetime64:
+                if issubclass(data.dtype.type, np.datetime_):
                     data = dt64arr_to_periodarr(data, freq)
                 elif data.dtype == np.int64:
                     pass
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index 875b5c94f..ce568f5a9 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -54,7 +54,7 @@ class TestResample(unittest.TestCase):
         # construct expected val
         arr = [1] + [5] * 2592
         idx = dti[0:-1:5]
-        idx = idx.append(DatetimeIndex([np.datetime64(dti[-1])]))
+        idx = idx.append(dti[-1:])
         expect = Series(arr, index=idx)
 
         # cython returns float for now
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 5fae73c72..e8f78eead 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -351,7 +351,7 @@ class TestTimeSeries(unittest.TestCase):
         self.assert_(not mask[:-5].any())
 
     def test_series_repr_nat(self):
-        series = Series([0, 1, 2, NaT], dtype='M8[ns]')
+        series = Series([0, 1000, 2000, NaT], dtype='M8[ns]')
 
         result = repr(series)
         expected = ('0          1970-01-01 00:00:00\n'
@@ -1160,13 +1160,35 @@ class TestTimestamp(unittest.TestCase):
         self.assert_(stamp.nanosecond == 500)
 
     def test_comparison(self):
-        arr = np.array(['1/1/2000'], dtype='M8[ns]')
-
-        x = Timestamp(arr[0].view('i8') + 500)
-        y = Timestamp(arr[0].view('i8'))
+        # 5-18-2012 00:00:00.000
+        stamp = 1337299200000000000L
+
+        val = Timestamp(stamp)
+
+        self.assert_(val == val)
+        self.assert_(not val != val)
+        self.assert_(not val < val)
+        self.assert_(val <= val)
+        self.assert_(not val > val)
+        self.assert_(val >= val)
+
+        other = datetime(2012, 5, 18)
+        self.assert_(val == other)
+        self.assert_(not val != other)
+        self.assert_(not val < other)
+        self.assert_(val <= other)
+        self.assert_(not val > other)
+        self.assert_(val >= other)
+
+        other = Timestamp(stamp + 100)
+
+        self.assert_(not val == other)
+        self.assert_(val != other)
+        self.assert_(val < other)
+        self.assert_(val <= other)
+        self.assert_(other > val)
+        self.assert_(other >= val)
 
-        self.assert_(arr[0].astype('O') == x)
-        self.assert_(x != y)
 
 """
 
