commit 0c2aa796122805577b6950324ddeb68f9ed609fd
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Feb 2 12:21:15 2012 -0500

    TST: test coverage

diff --git a/pandas/core/common.py b/pandas/core/common.py
index f6b336ec3..5e59592d2 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -3,7 +3,7 @@ Misc tools for implementing data structures
 """
 try:
     import cPickle as pickle
-except ImportError:
+except ImportError:  # pragma: no cover
     import pickle
 
 try:
@@ -854,7 +854,7 @@ class UnicodeReader:
     """
     A CSV reader which will iterate over lines in the CSV file "f",
     which is encoded in the given encoding.
-    
+
     On Python 3, this is replaced (below) by csv.reader, which handles unicode.
     """
 
@@ -866,9 +866,9 @@ class UnicodeReader:
         row = self.reader.next()
         return [unicode(s, "utf-8") for s in row]
 
-    def __iter__(self):
+    def __iter__(self):  # pragma: no cover
         return self
 
-if py3compat.PY3:
+if py3compat.PY3:  # pragma: no cover
     UnicodeReader = csv.reader
 
diff --git a/pandas/core/format.py b/pandas/core/format.py
index b924f870b..91d203041 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -1,7 +1,7 @@
 from itertools import izip
 
 from StringIO import StringIO
-from pandas.core.common import adjoin, isnull, _format
+from pandas.core.common import adjoin, _format
 from pandas.core.index import MultiIndex, _ensure_index
 from pandas.util import py3compat
 
@@ -38,7 +38,9 @@ docstring_to_string = """
         Left or right-justify the column labels. If None uses the option from
         the configuration in pandas.core.common, 'left' out of the box
     index_names : bool, optional
-        Prints the names of the indexes, default True """
+        Prints the names of the indexes, default True
+    force_unicode : bool, default False
+        Always return a unicode result"""
 
 class SeriesFormatter(object):
 
@@ -214,9 +216,9 @@ class DataFrameFormatter(object):
             if force_unicode:
                 to_write = [unicode(s) for s in to_write]
             else:
-                # generally everything is plain strings, which has ascii encoding.
-                # problem is when there is a char with value over 127 - everything
-                # then gets converted to unicode.
+                # generally everything is plain strings, which has ascii
+                # encoding.  problem is when there is a char with value over 127
+                # - everything then gets converted to unicode.
                 try:
                     for s in to_write:
                         str(s)
@@ -226,8 +228,6 @@ class DataFrameFormatter(object):
         self.buf.writelines(to_write)
 
     def _get_col_formatter(self, dtype):
-        from pandas.core.common import _format
-
         def formatter(x, col_width=None):
             return _format(x, dtype, space=self.col_space,
                            na_rep=self.na_rep,
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index f3a2315be..6b961f552 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -815,7 +815,7 @@ class DataFrame(NDFrame):
 
         self._consolidate_inplace()
 
-        # minor axis must be sorted 
+        # minor axis must be sorted
         if self.index.lexsort_depth < 2:
             selfsorted = self.sortlevel(0)
         else:
@@ -867,7 +867,7 @@ class DataFrame(NDFrame):
             Field delimiter for the output file.
         encoding : string, optional
             a string representing the encoding to use if the contents are
-            non-ascii, for python versions prior to 3
+            non-ascii, for Python 2.x series
         """
         f = open(path, mode)
         csvout = csv.writer(f, lineterminator='\n', delimiter=sep)
@@ -950,7 +950,7 @@ class DataFrame(NDFrame):
     def to_string(self, buf=None, columns=None, col_space=None, colSpace=None,
                   header=True, index=True, na_rep='NaN', formatters=None,
                   float_format=None, sparsify=True, nanRep=None,
-                  index_names=True, justify='left'):
+                  index_names=True, justify='left', force_unicode=False):
         """
         Render a DataFrame to a console-friendly tabular output.
         """
@@ -975,7 +975,7 @@ class DataFrame(NDFrame):
                                        justify=justify,
                                        index_names=index_names,
                                        header=header, index=index)
-        formatter.to_string()
+        formatter.to_string(force_unicode=force_unicode)
 
         if buf is None:
             return formatter.buf.getvalue()
@@ -1522,9 +1522,6 @@ class DataFrame(NDFrame):
                 indexer = loc
 
             result = self.ix[indexer]
-
-            # new_ax = result._get_axis(axis).droplevel(level)
-
             setattr(result, result._get_axis_name(axis), new_ax)
             return result
 
@@ -1548,10 +1545,6 @@ class DataFrame(NDFrame):
         else:
             result = self[loc]
             result.index = new_index
-
-            # new_data = self._data.xs(key, axis=1, copy=copy)
-            # result = DataFrame(new_data)
-            # result.index = _maybe_droplevels(result.index, key)
             return result
 
     def lookup(self, row_labels, col_labels):
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 9a798f1bd..eff0ebb81 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -301,7 +301,7 @@ class GroupBy(object):
             return self._cython_agg_general('mean')
         except GroupByError:
             raise
-        except Exception:
+        except Exception:  # pragma: no cover
             f = lambda x: x.mean(axis=self.axis)
             return self._python_agg_general(f)
 
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 4fb7fddd9..1888060b7 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1514,12 +1514,7 @@ class MultiIndex(Index):
         ----------
         """
         order = [self._get_level_number(i) for i in order]
-        try:
-            assert(set(order) == set(range(self.nlevels)))
-        except AssertionError:
-            raise Exception('New order must be permutation of range(%d)' %
-                            self.nlevels)
-
+        assert(len(order) == self.nlevels)
         new_levels = [self.levels[i] for i in order]
         new_labels = [self.labels[i] for i in order]
         new_names = [self.names[i] for i in order]
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 31732cf7c..66eb26ff2 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1838,6 +1838,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # it works!
         repr(df)
 
+        # it works even if sys.stdin in None
+        sys.stdin = None
+        repr(df)
+        sys.stdin = sys.__stdin__
+
     def test_to_string_unicode_columns(self):
         df = DataFrame({u'\u03c3' : np.arange(10.)})
 
@@ -1849,6 +1854,9 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         df.info(buf=buf)
         buf.getvalue()
 
+        result = self.frame.to_string(force_unicode=True)
+        self.assert_(isinstance(result, unicode))
+
     def test_to_string_unicode_two(self):
         dm = DataFrame({u'c/\u03c3': []})
         buf = StringIO()
@@ -2490,6 +2498,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         assert_frame_equal(df, df2)
         os.remove(path)
 
+        df.to_csv(path, index=False, encoding='UTF-8')
+
     def test_info(self):
         io = StringIO()
         self.frame.info(buf=io)
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 0e44abcc6..0132e761c 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -6,7 +6,7 @@ from numpy import nan
 
 from pandas.core.daterange import DateRange
 from pandas.core.index import Index, MultiIndex
-from pandas.core.common import rands, groupby
+from pandas.core.common import rands
 from pandas.core.frame import DataFrame
 from pandas.core.groupby import GroupByError
 from pandas.core.series import Series
@@ -15,7 +15,6 @@ from pandas.util.testing import (assert_panel_equal, assert_frame_equal,
 from pandas.core.panel import Panel
 from pandas.tools.merge import concat
 from collections import defaultdict
-import pandas._tseries as lib
 import pandas.core.datetools as dt
 import numpy as np
 
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 2b8705be7..f5d5d22e2 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -714,6 +714,8 @@ class TestMultiIndex(unittest.TestCase):
         self.assertEqual(self.index._get_level_number(0), 1)
         self.assertRaises(Exception, self.index._get_level_number, 2)
 
+        self.assertRaises(Exception, self.index._get_level_number, 'fourth')
+
     def test_from_arrays(self):
         arrays = []
         for lev, lab in zip(self.index.levels, self.index.labels):
@@ -743,6 +745,11 @@ class TestMultiIndex(unittest.TestCase):
         expected = self.index.get_level_values(0)
         self.assert_(np.array_equal(result, expected))
 
+    def test_reorder_levels(self):
+        # this blows up
+        self.assertRaises(Exception, self.index.reorder_levels,
+                          [2, 1, 0])
+
     def test_nlevels(self):
         self.assertEquals(self.index.nlevels, 2)
 
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index a4155b163..2aa437bca 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -4,7 +4,6 @@ from datetime import datetime, timedelta
 import os
 import operator
 import unittest
-import cStringIO as StringIO
 
 import nose
 
@@ -749,6 +748,11 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.series[5:7] = np.NaN
         str(self.series)
 
+        # with Nones
+        ots = self.ts.astype('O')
+        ots[::2] = None
+        repr(ots)
+
         # tuple name, e.g. from hierarchical index
         self.series.name = ('foo', 'bar', 'baz')
         repr(self.series)
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 000778a0d..a9df68cbe 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -15,7 +15,6 @@ from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
 from pandas.util.decorators import cache_readonly, Appender, Substitution
 
 from pandas.sparse.frame import SparseDataFrame
-from pandas.util.decorators import cache_readonly
 import pandas.core.common as com
 
 import pandas._tseries as lib
@@ -300,15 +299,11 @@ def _get_keys(frame, on, drop=False):
             keys.append(frame[k].values)
             names.append(k)
 
-
     if drop:
         frame = frame.copy()
         for k in to_drop:
             del frame[k]
 
-        # this is a bit too expensive...
-        # frame = frame.drop(to_drop, axis=1)
-
     return frame, keys, names
 
 
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index d32a586b8..01a12e320 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -23,11 +23,10 @@ JOIN_TYPES = ['inner', 'outer', 'left', 'right']
 
 def get_test_data(ngroups=NGROUPS, n=N):
     unique_groups = range(ngroups)
-    arr = np.asarray(np.tile(unique_groups, n // ngroups), dtype=object)
+    arr = np.asarray(np.tile(unique_groups, n // ngroups))
 
     if len(arr) < n:
-        arr = np.asarray(list(arr) + unique_groups[:n - len(arr)],
-                         dtype=object)
+        arr = np.asarray(list(arr) + unique_groups[:n - len(arr)])
 
     random.shuffle(arr)
     return arr
@@ -185,6 +184,21 @@ class TestMerge(unittest.TestCase):
         self.assert_('key1.foo' in joined)
         self.assert_('key2.bar' in joined)
 
+        # result = merge(self.df, self.df2, on='key1')
+        # left_on = self.df['key2'].copy()
+        # left_on.name = 'baz'
+        # right_on = self.df2['key1'].copy()
+        # right_on.name = 'baz'
+
+        # grouped = self.df2.groupby('key1').mean()
+        # self.assert_('key2' in grouped)
+
+        # joined = merge(self.df, grouped, left_on='key1',
+        #                right_index=True, suffixes=['.foo', '.bar'])
+        # foo
+        # self.assert_('key2.foo' in joined)
+        # self.assert_('key2.bar' in joined)
+
     def test_merge_common(self):
         joined = merge(self.df, self.df2)
         exp = merge(self.df, self.df2, on=['key1', 'key2'])
