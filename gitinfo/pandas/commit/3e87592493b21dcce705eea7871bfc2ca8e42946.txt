commit 3e87592493b21dcce705eea7871bfc2ca8e42946
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Dec 10 18:31:27 2011 -0500

    ENH: refactoring sparse classes to create SparseArray subclass for SparseSeries re: #436

diff --git a/pandas/__init__.py b/pandas/__init__.py
index bb29f1cea..5395121c0 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -28,3 +28,6 @@ from pandas.stats.api import *
 from pandas.util.testing import debug
 
 from pandas.tools.pivot import pivot_table
+
+from pandas.sparse.api import (SparseArray, SparseSeries, SparseDataFrame,
+                               SparsePanel)
diff --git a/pandas/core/api.py b/pandas/core/api.py
index 3b4e2c4e5..5c2423ab9 100644
--- a/pandas/core/api.py
+++ b/pandas/core/api.py
@@ -13,7 +13,6 @@ from pandas.core.frame import DataFrame
 from pandas.core.panel import Panel, LongPanel
 from pandas.core.groupby import groupby
 from pandas.core.reshape import pivot_simple as pivot
-from pandas.core.sparse import SparseSeries, SparseDataFrame, SparsePanel
 
 DataMatrix = DataFrame
 WidePanel = Panel
diff --git a/pandas/core/common.py b/pandas/core/common.py
index edcff33ae..01c1b3208 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -660,6 +660,9 @@ def _asarray_tuplesafe(values, dtype=None):
 
     return result
 
+def is_integer(obj):
+    return isinstance(obj, (int, np.integer))
+
 def is_integer_dtype(arr):
     return issubclass(arr.dtype.type, np.integer)
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 8fa6b937d..16d2f826e 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1433,8 +1433,9 @@ copy : boolean, default False
                     new_values = series.values.copy()
                 else:
                     new_values = series.values
-            result = Series(new_values, join_index, name=series.name)
-            return result
+
+            # be subclass-friendly
+            return series._constructor(new_values, join_index, name=series.name)
 
         left = _align_series(self, lidx)
         right = _align_series(other, ridx)
diff --git a/pandas/sparse/api.py b/pandas/sparse/api.py
new file mode 100644
index 000000000..b8df3be2a
--- /dev/null
+++ b/pandas/sparse/api.py
@@ -0,0 +1,4 @@
+from pandas.sparse.array import SparseArray
+from pandas.sparse.series import SparseSeries
+from pandas.sparse.frame import SparseDataFrame
+from pandas.sparse.panel import SparsePanel
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index e69de29bb..2f9ce9faf 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -0,0 +1,438 @@
+"""
+SparseArray data structure
+"""
+
+# pylint: disable=E1101,E1103,W0231
+
+from numpy import nan, ndarray
+import numpy as np
+
+import operator
+import pandas.core.common as com
+
+from pandas.util import py3compat
+
+from pandas._sparse import BlockIndex, IntIndex
+import pandas._sparse as splib
+import pandas._engines as _gin
+
+
+def _sparse_op_wrap(op, name):
+    """
+    Wrapper function for Series arithmetic operations, to avoid
+    code duplication.
+    """
+    def wrapper(self, other):
+        if isinstance(other, np.ndarray):
+            assert(len(self) == len(other))
+            if not isinstance(other, SparseArray):
+                other = SparseArray(other, fill_value=self.fill_value)
+            return _sparse_array_op(self, other, op, name)
+        elif np.isscalar(other):
+            new_fill_value = op(np.float64(self.fill_value),
+                                np.float64(other))
+
+            return SparseArray(op(self.sp_values, other),
+                               sparse_index=self.sp_index,
+                               fill_value=new_fill_value)
+        else: # pragma: no cover
+            raise TypeError('operation with %s not supported' % type(other))
+
+    wrapper.__name__ = name
+    return wrapper
+
+def _sparse_array_op(left, right, op, name):
+    if np.isnan(left.fill_value):
+        sparse_op = lambda a, b: _sparse_nanop(a, b, name)
+    else:
+        sparse_op = lambda a, b: _sparse_fillop(a, b, name)
+
+    if left.sp_index.equals(right.sp_index):
+        result = op(left.sp_values, right.sp_values)
+        result_index = left.sp_index
+    else:
+        result, result_index = sparse_op(left, right)
+
+    try:
+        fill_value = op(left.fill_value, right.fill_value)
+    except ZeroDivisionError:
+        fill_value = nan
+
+    return SparseArray(result, sparse_index=result_index,
+                       fill_value=fill_value)
+
+def _sparse_nanop(this, other, name):
+    sparse_op = getattr(splib, 'sparse_nan%s' % name)
+    result, result_index = sparse_op(this.sp_values,
+                                     this.sp_index,
+                                     other.sp_values,
+                                     other.sp_index)
+
+    return result, result_index
+
+def _sparse_fillop(this, other, name):
+    sparse_op = getattr(splib, 'sparse_%s' % name)
+    result, result_index = sparse_op(this.sp_values,
+                                     this.sp_index,
+                                     this.fill_value,
+                                     other.sp_values,
+                                     other.sp_index,
+                                     other.fill_value)
+
+    return result, result_index
+
+
+class SparseArray(np.ndarray):
+    """Data structure for labeled, sparse floating point data
+
+Parameters
+----------
+data : {array-like, Series, SparseSeries, dict}
+kind : {'block', 'integer'}
+fill_value : float
+    Defaults to NaN (code for missing)
+sparse_index : {BlockIndex, IntIndex}, optional
+    Only if you have one. Mainly used internally
+
+Notes
+-----
+SparseSeries objects are immutable via the typical Python means. If you
+must change values, convert to dense, make your changes, then convert back
+to sparse
+    """
+    __array_priority__ = 15
+
+    sp_index = None
+    fill_value = None
+
+    def __new__(cls, data, sparse_index=None, kind='block', fill_value=None,
+                copy=False):
+
+        is_sparse_array = isinstance(data, SparseArray)
+        if fill_value is None:
+            if is_sparse_array:
+                fill_value = data.fill_value
+            else:
+                fill_value = nan
+
+        if is_sparse_array:
+            sparse_index = data.sp_index
+            values = np.asarray(data)
+        else:
+            # array-like
+            if sparse_index is None:
+                values, sparse_index = make_sparse(data, kind=kind,
+                                                   fill_value=fill_value)
+            else:
+                values = data
+                assert(len(values) == sparse_index.npoints)
+
+        # Create array, do *not* copy data by default
+        if copy:
+            subarr = np.array(values, dtype=np.float64, copy=True)
+        else:
+            subarr = np.asarray(values, dtype=np.float64)
+
+        # Change the class of the array to be the subclass type.
+        output = subarr.view(cls)
+        output._sp_values = subarr
+        output.sp_index = sparse_index
+        output.fill_value = np.float64(fill_value)
+        return output
+
+    @property
+    def _constructor(self):
+        return lambda x: SparseArray(x, fill_value=self.fill_value,
+                                     kind=self.kind)
+
+    @property
+    def kind(self):
+        if isinstance(self.sp_index, BlockIndex):
+            return 'block'
+        elif isinstance(self.sp_index, IntIndex):
+            return 'integer'
+
+    def __array_finalize__(self, obj):
+        """
+        Gets called after any ufunc or other array operations, necessary
+        to pass on the index.
+        """
+        self.sp_index = getattr(obj, 'sp_index', None)
+        self.fill_value = getattr(obj, 'fill_value', None)
+
+    def __reduce__(self):
+        """Necessary for making this object picklable"""
+        object_state = list(ndarray.__reduce__(self))
+        subclass_state = self.fill_value, self.sp_index
+        object_state[2] = (object_state[2], subclass_state)
+        return tuple(object_state)
+
+    def __setstate__(self, state):
+        """Necessary for making this object picklable"""
+        nd_state, own_state = state
+        ndarray.__setstate__(self, nd_state)
+
+        fill_value, sp_index = own_state[:2]
+        self.sp_index = sp_index
+        self.fill_value = fill_value
+
+    def __len__(self):
+        return self.sp_index.length
+
+    def __repr__(self):
+        return '%s\n%s' % (np.ndarray.__repr__(self),
+                           repr(self.sp_index))
+
+    # Arithmetic operators
+
+    __add__ = _sparse_op_wrap(operator.add, 'add')
+    __sub__ = _sparse_op_wrap(operator.sub, 'sub')
+    __mul__ = _sparse_op_wrap(operator.mul, 'mul')
+    __truediv__ = _sparse_op_wrap(operator.truediv, 'truediv')
+    __floordiv__ = _sparse_op_wrap(operator.floordiv, 'floordiv')
+    __pow__ = _sparse_op_wrap(operator.pow, 'pow')
+
+    # reverse operators
+    __radd__ = _sparse_op_wrap(operator.add, '__radd__')
+    __rsub__ = _sparse_op_wrap(lambda x, y: y - x, '__rsub__')
+    __rmul__ = _sparse_op_wrap(operator.mul, '__rmul__')
+    __rtruediv__ = _sparse_op_wrap(lambda x, y: y / x, '__rtruediv__')
+    __rfloordiv__ = _sparse_op_wrap(lambda x, y: y // x, 'floordiv')
+    __rpow__ = _sparse_op_wrap(lambda x, y: y ** x, '__rpow__')
+
+    # Inplace operators
+    __iadd__ = __add__
+    __isub__ = __sub__
+    __imul__ = __mul__
+    __itruediv__ = __truediv__
+    __ifloordiv__ = __floordiv__
+    __ipow__ = __pow__
+
+    # Python 2 division operators
+    if not py3compat.PY3:
+        __div__ = _sparse_op_wrap(operator.div, 'div')
+        __rdiv__ = _sparse_op_wrap(lambda x, y: y / x, '__rdiv__')
+        __idiv__ = __div__
+
+    @property
+    def values(self):
+        """
+        Dense values
+        """
+        output = np.empty(len(self), dtype=np.float64)
+        int_index = self.sp_index.to_int_index()
+        output.fill(self.fill_value)
+        output.put(int_index.indices, self)
+        return output
+
+    @property
+    def sp_values(self):
+        # caching not an option, leaks memory
+        return self.view(np.ndarray)
+
+    def __getitem__(self, key):
+        """
+
+        """
+        if com.is_integer(key):
+            return self._get_val_at(key)
+        else:
+            data_slice = self.values[key]
+            return self._constructor(data_slice)
+
+    def _get_val_at(self, loc):
+        n = len(self)
+        if loc < 0:
+            loc += n
+
+        if loc >= len(self) or loc < 0:
+            raise Exception('Out of bounds access')
+
+        sp_loc = self.sp_index.lookup(loc)
+        if sp_loc == -1:
+            return self.fill_value
+        else:
+            return _gin.get_value_at(self, sp_loc)
+
+    def take(self, indices):
+        """
+        Sparse-compatible version of ndarray.take
+
+        Returns
+        -------
+        taken : ndarray
+        """
+        indices = np.asarray(indices, dtype=int)
+
+        n = len(self)
+        if (indices < 0).any() or (indices >= n).any():
+            raise Exception('out of bounds access')
+
+        if self.sp_index.npoints > 0:
+            locs = np.array([self.sp_index.lookup(loc) for loc in indices])
+            result = self.sp_values.take(locs)
+            result[locs == -1] = self.fill_value
+        else:
+            result = np.empty(len(indices))
+            result.fill(self.fill_value)
+
+        return result
+
+    def __setitem__(self, key, value):
+        raise Exception('SparseArray objects are immutable')
+
+    def __setslice__(self, i, j, value):
+        raise Exception('SparseArray objects are immutable')
+
+    def to_dense(self):
+        """
+        Convert SparseSeries to (dense) Series
+        """
+        return self.values
+
+    def astype(self, dtype=None):
+        """
+
+        """
+        if dtype is not None and dtype not in (np.float_, float):
+            raise Exception('Can only support floating point data')
+        return self.copy()
+
+    def copy(self, deep=True):
+        """
+        Make a copy of the SparseSeries. Only the actual sparse values need to
+        be copied
+        """
+        if deep:
+            values = self.sp_values.copy()
+        else:
+            values = self.sp_values
+        return SparseArray(values, sparse_index=self.sp_index,
+                           fill_value=self.fill_value)
+
+    def count(self):
+        """
+        Compute sum of non-NA/null observations in SparseSeries. If the
+        fill_value is not NaN, the "sparse" locations will be included in the
+        observation count
+
+        Returns
+        -------
+        nobs : int
+        """
+        sp_values = self.sp_values
+        valid_spvals = np.isfinite(sp_values).sum()
+        if self._null_fill_value:
+            return valid_spvals
+        else:
+            return valid_spvals + (len(self) - len(sp_values))
+
+    @property
+    def _null_fill_value(self):
+        return np.isnan(self.fill_value)
+
+    @property
+    def _valid_sp_values(self):
+        sp_vals = self.sp_values
+        mask = np.isfinite(sp_vals)
+        return sp_vals[mask]
+
+    def sum(self, axis=None, dtype=None, out=None):
+        """
+        Sum of non-NA/null values
+
+        Returns
+        -------
+        sum : float
+        """
+        valid_vals = self._valid_sp_values
+        sp_sum = valid_vals.sum()
+        if self._null_fill_value:
+            return sp_sum
+        else:
+            nsparse = self.sp_index.npoints
+            return sp_sum + self.fill_value * nsparse
+
+    def cumsum(self, axis=0, dtype=None, out=None):
+        """
+        Cumulative sum of values. Preserves locations of NaN values
+
+        Extra parameters are to preserve ndarray interface.
+
+        Returns
+        -------
+        cumsum : Series
+        """
+
+
+
+
+        if com.notnull(self.fill_value):
+            return self.to_dense().cumsum()
+        # TODO: what if sp_values contains NaN??
+        return SparseArray(self.sp_values.cumsum(),
+                           sparse_index=self.sp_index,
+                           fill_value=self.fill_value)
+
+    def mean(self, axis=None, dtype=None, out=None):
+        """
+        Mean of non-NA/null values
+
+        Returns
+        -------
+        mean : float
+        """
+        valid_vals = self._valid_sp_values
+        sp_sum = valid_vals.sum()
+        ct = len(valid_vals)
+
+        if self._null_fill_value:
+            return sp_sum / ct
+        else:
+            nsparse = self.sp_index.npoints
+            return (sp_sum + self.fill_value * nsparse) / (ct + nsparse)
+
+    def valid(self):
+        """
+        Analogous to Series.valid
+        """
+        # TODO: make more efficient
+        dense_valid = self.to_dense().valid()
+        return dense_valid.to_sparse(fill_value=self.fill_value)
+
+
+
+def make_sparse(arr, kind='block', fill_value=nan):
+    """
+    Convert ndarray to sparse format
+
+    Parameters
+    ----------
+    arr : ndarray
+    kind : {'block', 'integer'}
+    fill_value : NaN or another value
+
+    Returns
+    -------
+    (sparse_values, index) : (ndarray, SparseIndex)
+    """
+    arr = np.asarray(arr)
+    length = len(arr)
+
+    if np.isnan(fill_value):
+        mask = -np.isnan(arr)
+    else:
+        mask = arr != fill_value
+
+    indices = np.arange(length, dtype=np.int32)[mask]
+
+    if kind == 'block':
+        locs, lens = splib.get_blocks(indices)
+        index = BlockIndex(length, locs, lens)
+    elif kind == 'integer':
+        index = IntIndex(length, indices)
+    else: # pragma: no cover
+        raise ValueError('must be block or integer type')
+
+    sparsified_values = arr[mask]
+    return sparsified_values, index
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index 6247e356f..08717a42e 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -19,43 +19,10 @@ import pandas.core.datetools as datetools
 
 from pandas.util import py3compat
 
+from pandas.sparse.array import (make_sparse, _sparse_array_op, SparseArray)
 from pandas._sparse import BlockIndex, IntIndex
 import pandas._sparse as splib
 
-def make_sparse(arr, kind='block', fill_value=nan):
-    """
-    Convert ndarray to sparse format
-
-    Parameters
-    ----------
-    arr : ndarray
-    kind : {'block', 'integer'}
-    fill_value : NaN or another value
-
-    Returns
-    -------
-    (sparse_values, index) : (ndarray, SparseIndex)
-    """
-    arr = np.asarray(arr)
-    length = len(arr)
-
-    if np.isnan(fill_value):
-        mask = -np.isnan(arr)
-    else:
-        mask = arr != fill_value
-
-    indices = np.arange(length, dtype=np.int32)[mask]
-
-    if kind == 'block':
-        locs, lens = splib.get_blocks(indices)
-        index = BlockIndex(length, locs, lens)
-    elif kind == 'integer':
-        index = IntIndex(length, indices)
-    else: # pragma: no cover
-        raise ValueError('must be block or integer type')
-
-    sparsified_values = arr[mask]
-    return sparsified_values, index
 
 #-------------------------------------------------------------------------------
 # Wrapper function for Series arithmetic methods
@@ -88,56 +55,18 @@ def _sparse_op_wrap(op, name):
     return wrapper
 
 def _sparse_series_op(left, right, op, name):
-    if np.isnan(left.fill_value):
-        sparse_op = lambda a, b: _sparse_nanop(a, b, name)
-    else:
-        sparse_op = lambda a, b: _sparse_fillop(a, b, name)
-
-    new_index = left.index + right.index
-    if not left.index.equals(new_index):
-        left = left.reindex(new_index)
-
-    if not right.index.equals(new_index):
-        right = right.reindex(new_index)
-
-    if left.sp_index.equals(right.sp_index):
-        result = op(left.sp_values, right.sp_values)
-        result_index = left.sp_index
-    else:
-        result, result_index = sparse_op(left, right)
-
-    try:
-        fill_value = op(left.fill_value, right.fill_value)
-    except ZeroDivisionError:
-        fill_value = nan
-
+    left, right = left.align(right, join='outer', copy=False)
+    new_index = left.index
     new_name = _maybe_match_name(left, right)
-    return SparseSeries(result, index=new_index,
-                        sparse_index=result_index,
-                        fill_value=fill_value, name=new_name)
 
-def _sparse_nanop(this, other, name):
-    sparse_op = getattr(splib, 'sparse_nan%s' % name)
-    result, result_index = sparse_op(this.sp_values,
-                                     this.sp_index,
-                                     other.sp_values,
-                                     other.sp_index)
+    result = _sparse_array_op(left, right, op, name)
+    result = result.view(SparseSeries)
+    result.index = new_index
+    result.name = new_name
 
-    return result, result_index
+    return result
 
-def _sparse_fillop(this, other, name):
-    sparse_op = getattr(splib, 'sparse_%s' % name)
-    result, result_index = sparse_op(this.sp_values,
-                                     this.sp_index,
-                                     this.fill_value,
-                                     other.sp_values,
-                                     other.sp_index,
-                                     other.fill_value)
-
-    return result, result_index
-
-
-class SparseSeries(Series):
+class SparseSeries(SparseArray, Series):
     __array_priority__ = 15
 
     sp_index = None
@@ -321,22 +250,6 @@ to sparse
         __rdiv__ = _sparse_op_wrap(lambda x, y: y / x, '__rdiv__')
         __idiv__ = __div__
 
-    @property
-    def values(self):
-        output = np.empty(len(self), dtype=np.float64)
-        int_index = self.sp_index.to_int_index()
-        output.fill(self.fill_value)
-        output.put(int_index.indices, self)
-        return output
-
-    @property
-    def sp_values(self):
-        try:
-            return self._sp_values
-        except AttributeError:
-            self._sp_values = ret = np.asarray(self)
-            return ret
-
     def __getitem__(self, key):
         """
 
@@ -382,20 +295,6 @@ to sparse
         else:
             return default
 
-    def _get_val_at(self, loc):
-        n = len(self)
-        if loc < 0:
-            loc += n
-
-        if loc >= len(self) or loc < 0:
-            raise Exception('Out of bounds access')
-
-        sp_loc = self.sp_index.lookup(loc)
-        if sp_loc == -1:
-            return self.fill_value
-        else:
-            return ndarray.__getitem__(self, sp_loc)
-
     def get_value(self, label):
         """
         Retrieve single value at passed index label
@@ -436,36 +335,6 @@ to sparse
         dense = self.to_dense().set_value(label, value)
         return dense.to_sparse(kind=self.kind, fill_value=self.fill_value)
 
-    def take(self, indices):
-        """
-        Sparse-compatible version of ndarray.take
-
-        Returns
-        -------
-        taken : ndarray
-        """
-        indices = np.asarray(indices, dtype=int)
-
-        n = len(self)
-        if (indices < 0).any() or (indices >= n).any():
-            raise Exception('out of bounds access')
-
-        if self.sp_index.npoints > 0:
-            locs = np.array([self.sp_index.lookup(loc) for loc in indices])
-            result = self.sp_values.take(locs)
-            result[locs == -1] = self.fill_value
-        else:
-            result = np.empty(len(indices))
-            result.fill(self.fill_value)
-
-        return result
-
-    def __setitem__(self, key, value):
-        raise Exception('SparseSeries objects are immutable')
-
-    def __setslice__(self, i, j, value):
-        raise Exception('SparseSeries objects are immutable')
-
     def to_dense(self, sparse_only=False):
         """
         Convert SparseSeries to (dense) Series
@@ -550,49 +419,12 @@ to sparse
                             sparse_index=new_index,
                             fill_value=self.fill_value)
 
-    def count(self):
-        """
-        Compute sum of non-NA/null observations in SparseSeries. If the
-        fill_value is not NaN, the "sparse" locations will be included in the
-        observation count
-
-        Returns
-        -------
-        nobs : int
-        """
-        sp_values = self.sp_values
-        valid_spvals = np.isfinite(sp_values).sum()
-        if self._null_fill_value:
-            return valid_spvals
-        else:
-            return valid_spvals + (len(self) - len(sp_values))
-
-    @property
-    def _null_fill_value(self):
-        return np.isnan(self.fill_value)
-
     @property
     def _valid_sp_values(self):
         sp_vals = self.sp_values
         mask = np.isfinite(sp_vals)
         return sp_vals[mask]
 
-    def sum(self, axis=None, dtype=None, out=None):
-        """
-        Sum of non-NA/null values
-
-        Returns
-        -------
-        sum : float
-        """
-        valid_vals = self._valid_sp_values
-        sp_sum = valid_vals.sum()
-        if self._null_fill_value:
-            return sp_sum
-        else:
-            nsparse = self.sp_index.npoints
-            return sp_sum + self.fill_value * nsparse
-
     def cumsum(self, axis=0, dtype=None, out=None):
         """
         Cumulative sum of values. Preserves locations of NaN values
@@ -605,29 +437,10 @@ to sparse
         """
         if not np.isnan(self.fill_value):
             return self.to_dense().cumsum()
-        return SparseSeries(self.sp_values.cumsum(),
-                            index=self.index,
-                            sparse_index=self.sp_index,
+        return SparseSeries(self.sp_values.cumsum(), index=self.index,
+                            sparse_index=self.sp_index, name=self.name,
                             fill_value=self.fill_value)
 
-    def mean(self, axis=None, dtype=None, out=None):
-        """
-        Mean of non-NA/null values
-
-        Returns
-        -------
-        mean : float
-        """
-        valid_vals = self._valid_sp_values
-        sp_sum = valid_vals.sum()
-        ct = len(valid_vals)
-
-        if self._null_fill_value:
-            return sp_sum / ct
-        else:
-            nsparse = self.sp_index.npoints
-            return (sp_sum + self.fill_value * nsparse) / (ct + nsparse)
-
     def valid(self):
         """
         Analogous to Series.valid
diff --git a/pandas/sparse/tests/test_array.py b/pandas/sparse/tests/test_array.py
new file mode 100644
index 000000000..7c8b1af86
--- /dev/null
+++ b/pandas/sparse/tests/test_array.py
@@ -0,0 +1,8 @@
+import numpy as np
+
+import unittest
+
+class TestSparseArray(unittest.TestCase):
+
+    def setUp(self):
+        pass
diff --git a/pandas/tests/test_libsparse.py b/pandas/sparse/tests/test_libsparse.py
similarity index 100%
rename from pandas/tests/test_libsparse.py
rename to pandas/sparse/tests/test_libsparse.py
diff --git a/pandas/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
similarity index 99%
rename from pandas/tests/test_sparse.py
rename to pandas/sparse/tests/test_sparse.py
index 898fa62fb..fd2db872b 100644
--- a/pandas/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -619,6 +619,7 @@ class TestSparseSeries(TestCase,
         result = self.bseries.cumsum()
         expected = self.bseries.to_dense().cumsum()
         self.assert_(isinstance(result, SparseSeries))
+        self.assertEquals(result.name, self.bseries.name)
         assert_series_equal(result.to_dense(), expected)
 
         result = self.zbseries.cumsum()
diff --git a/pandas/src/iterator.pyx b/pandas/src/iterator.pyx
new file mode 100644
index 000000000..28dae38e5
--- /dev/null
+++ b/pandas/src/iterator.pyx
@@ -0,0 +1,33 @@
+cdef class RowIterator(object):
+    cdef:
+        ndarray arr, iterbuf
+        Py_ssize_t N, K, itemsize
+        char* buf
+
+    def __init__(self, ndarray arr):
+        self.arr = arr
+        self.N, self.K = arr.shape
+        self.itemsize = arr.dtype.itemsize
+        self.iterbuf = np.empty(self.K, dtype=self.arr.dtype)
+        self.buf = self.iterbuf.data
+
+    def __del__(self):
+        self.iterbuf.data = self.buf
+
+    def __iter__(self):
+        cdef:
+            ndarray result = np.empty(self.K, dtype=self.arr.dtype)
+            char* buf, arr_buf
+            Py_ssize_t i, inc
+
+        buf = result.data
+        arr_buf = arr.data
+
+        inc = self.itemsize * self.K
+
+        for i from 0 <= i < self.N:
+            result.data = arr_buf
+            yield result
+            arr_buf = arr_buf + inc
+
+        result.data = buf
