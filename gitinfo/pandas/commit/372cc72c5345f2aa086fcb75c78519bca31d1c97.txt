commit 372cc72c5345f2aa086fcb75c78519bca31d1c97
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Apr 17 21:04:33 2011 -0400

    more sparse work

diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 8b26afca7..c0029e4a1 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -5,8 +5,250 @@ import operator
 from pandas.core.series import Series
 from pandas.core.frame import DataFrame
 
+import pandas.lib.sparse as splib
+
+def make_sparse(series, kind='block', sparse_value=np.NaN):
+    """
+
+    kind : {'block', 'integer'}
+    """
+
 class SparseSeries(Series):
-    pass
+    """
+    Data structure for labeled, sparse floating point data
+    """
+
+    def __new__(cls, data, index=None, copy=False):
+        if isinstance(data, Series):
+            if index is None:
+                index = data.index
+        elif isinstance(data, dict):
+            if index is None:
+                index = Index(sorted(data.keys()))
+            data = [data[idx] for idx in index]
+
+        # Create array, do *not* copy data by default, infer type
+        try:
+            subarr = np.array(data, dtype=dtype, copy=copy)
+        except ValueError:
+            if dtype:
+                raise
+
+            subarr = np.array(data, dtype=object)
+
+        if subarr.ndim == 0:
+            if isinstance(data, list): # pragma: no cover
+                subarr = np.array(data, dtype=object)
+            elif index is not None:
+                value = data
+
+                # If we create an empty array using a string to infer
+                # the dtype, NumPy will only allocate one character per entry
+                # so this is kind of bad. Alternately we could use np.repeat
+                # instead of np.empty (but then you still don't want things
+                # coming out as np.str_!
+                if isinstance(value, basestring) and dtype is None:
+                    dtype = np.object_
+
+                if dtype is None:
+                    subarr = np.empty(len(index), dtype=type(value))
+                else:
+                    subarr = np.empty(len(index), dtype=dtype)
+                subarr.fill(value)
+            else:
+                return subarr.item()
+
+        elif subarr.ndim > 1:
+            raise Exception('Data must be 1-dimensional')
+
+        if index is None:
+            raise Exception('Index cannot be None!')
+
+        # This is to prevent mixed-type Series getting all casted to
+        # NumPy string type, e.g. NaN --> '-1#IND'.
+        if issubclass(subarr.dtype.type, basestring):
+            subarr = np.array(data, dtype=object, copy=copy)
+
+        # Change the class of the array to be the subclass type.
+        subarr = subarr.view(cls)
+        subarr.index = index
+
+        if subarr.index._allDates:
+            subarr = subarr.view(TimeSeries)
+
+        return subarr
+
+    def __hash__(self):
+        raise TypeError('unhashable type')
+
+    _index = None
+    def _get_index(self):
+        return self._index
+
+    def _set_index(self, index):
+        indexTypes = ndarray, Index, list, tuple
+        if not isinstance(index, indexTypes):
+            raise TypeError("Expected index to be in %s; was %s."
+                            % (indexTypes, type(index)))
+
+        if len(self) != len(index):
+            raise AssertionError('Lengths of index and values did not match!')
+
+        if not isinstance(index, Index):
+            index = Index(index)
+
+        self._index = index
+
+    index = property(fget=_get_index, fset=_set_index)
+
+    def __array_finalize__(self, obj):
+        """
+        Gets called after any ufunc or other array operations, necessary
+        to pass on the index.
+        """
+        self._index = getattr(obj, '_index', None)
+
+    def toDict(self):
+        return dict(self.iteritems())
+
+    @classmethod
+    def fromValue(cls, value=np.NaN, index=None, dtype=None): # pragma: no cover
+        warnings.warn("'fromValue', can call Series(value, index=index) now",
+                      FutureWarning)
+
+        return Series(value, index=index, dtype=dtype)
+
+    def __contains__(self, key):
+        return key in self.index
+
+    def __reduce__(self):
+        """Necessary for making this object picklable"""
+        object_state = list(ndarray.__reduce__(self))
+        subclass_state = (self.index, )
+        object_state[2] = (object_state[2], subclass_state)
+        return tuple(object_state)
+
+    def __setstate__(self, state):
+        """Necessary for making this object picklable"""
+        nd_state, own_state = state
+        ndarray.__setstate__(self, nd_state)
+        index, = own_state
+        self.index = index
+
+    def __getitem__(self, key):
+        """
+        Returns item(s) for requested index/sequence, overrides default behavior
+        for series[key].
+
+        Logic is as follows:
+            - If key is in the index, return the value corresponding
+              to that index
+            - Otherwise, use key (presumably one integer or a sequence
+              of integers) to obtain values from the series. In the case
+              of a sequence, a 'slice' of the series (with corresponding dates)
+              will be returned, otherwise a single value.
+        """
+        values = self.values
+
+        try:
+            # Check that we can even look for this in the index
+            return values[self.index.indexMap[key]]
+        except KeyError:
+            if isinstance(key, (int, np.integer)):
+                return values[key]
+            raise Exception('Requested index not in this series!')
+        except TypeError:
+            # Could not hash item
+            pass
+
+        # is there a case where this would NOT be an ndarray?
+        # need to find an example, I took out the case for now
+
+        dataSlice = values[key]
+        indices = Index(self.index.view(ndarray)[key])
+        return Series(dataSlice, index=indices)
+
+    def get(self, key, default=None):
+        """
+        Returns value occupying requested index, default to specified
+        missing value if not present
+
+        Parameters
+        ----------
+        key : object
+            Index value looking for
+        default : object, optional
+            Value to return if key not in index
+
+        Returns
+        -------
+        y : scalar
+        """
+        if key in self.index:
+            return ndarray.__getitem__(self, self.index.indexMap[key])
+        else:
+            return default
+
+    def __getslice__(self, i, j):
+        """
+        Returns a slice of the Series.
+
+        Note that the underlying values are COPIES.
+
+        The reason that the getslice returns copies is that otherwise you
+        will have a reference to the original series which could be
+        inadvertently changed if the slice were altered (made mutable).
+        """
+        newArr = self.values[i:j].copy()
+        newIndex = self.index[i:j]
+
+        return Series(newArr, index=newIndex)
+
+    def __setitem__(self, key, value):
+        """
+        If this series is mutable, set specified indices equal to given values.
+        """
+        try:
+            loc = self.index.indexMap[key]
+            ndarray.__setitem__(self, loc, value)
+        except Exception:
+            values = self.values
+            values[key] = value
+
+    def __setslice__(self, i, j, value):
+        """Set slice equal to given value(s)"""
+        ndarray.__setslice__(self, i, j, value)
+
+    def __repr__(self):
+        """Clean string representation of a Series"""
+        vals = self.values
+        index = self.index
+
+        if len(index) > 500:
+            head = _seriesRepr(index[:50], vals[:50])
+            tail = _seriesRepr(index[-50:], vals[-50:])
+            return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
+        elif len(index) > 0:
+            return _seriesRepr(index, vals)
+        else:
+            return '%s' % ndarray.__repr__(self)
+
+    def toString(self, buffer=sys.stdout, nanRep='NaN'):
+        print >> buffer, _seriesRepr(self.index, self.values,
+                                     nanRep=nanRep)
+
+    def __str__(self):
+        return repr(self)
+
+    def __iter__(self):
+        return iter(self.values)
+
+    def to_dense(self):
+        pass
+
+    def copy(self):
+        vec_copy = self._vector.copy()
+        return SparseSeries(vec_copy, index=self.index)
 
 class SparseDataFrame(DataFrame):
     pass
diff --git a/pandas/lib/src/sparse.pyx b/pandas/lib/src/sparse.pyx
index dc8fe992c..a6f0a220d 100644
--- a/pandas/lib/src/sparse.pyx
+++ b/pandas/lib/src/sparse.pyx
@@ -64,11 +64,46 @@ cdef class IntIndex(SparseIndex):
         output += 'Indices: %s\n' % repr(self.indices)
         return output
 
-    def to_int(self):
+    def equals(self, other):
+        if not isinstance(other, IntIndex):
+            raise Exception('Can only compare with like object')
+
+        same_length = self.length == other.length
+        same_indices = np.array_equal(self.indices, other.indices)
+        return same_length and same_indices
+
+    def to_int_index(self):
         return self
 
-    def to_block(self):
-        pass
+    def to_block_index(self):
+        cdef:
+            pyst i
+            int32_t block, length = 1, cur, prev
+            list locs = [], lens = []
+
+        # just handle the special empty case separately
+        if self.npoints == 0:
+            return BlockIndex(self.length, [], [])
+
+        # TODO: two-pass algorithm faster?
+        prev = block = self.indp[0]
+        for i from 1 <= i < self.npoints:
+            cur = self.indp[i]
+            if cur - prev > 1:
+                # new block
+                locs.append(block)
+                lens.append(length)
+                block = cur
+                length = 1
+            else:
+                # same block, increment length
+                length += 1
+
+            prev = cur
+
+        locs.append(block)
+        lens.append(length)
+        return BlockIndex(self.length, locs, lens)
 
     cpdef intersect(self, SparseIndex y_):
         cdef:
@@ -77,10 +112,8 @@ cdef class IntIndex(SparseIndex):
             list new_list = []
             IntIndex y
 
-        if not isinstance(y_, IntIndex):
-            y_ = y_.to_int()
-
-        y = y_
+        # if is one already, returns self
+        y = y_.to_int_index()
 
         for xi from 0 <= xi < self.npoints:
             xind = self.indp[xi]
@@ -91,6 +124,7 @@ cdef class IntIndex(SparseIndex):
             if yi >= y.npoints:
                 break
 
+            # TODO: would a two-pass algorithm be faster?
             if y.indp[yi] == xind:
                 new_list.append(xind)
 
@@ -169,10 +203,19 @@ cdef class BlockIndex(SparseIndex):
             if self.blengths[i] == 0:
                 raise ValueError('Zero-length block %d' % i)
 
-    def to_block(self):
+    def equals(self, other):
+        if not isinstance(other, BlockIndex):
+            raise Exception('Can only compare with like object')
+
+        same_length = self.length == other.length
+        same_blocks = (np.array_equal(self.blocs, other.blocs) and
+                       np.array_equal(self.blengths, other.blengths))
+        return same_length and same_blocks
+
+    def to_block_index(self):
         return self
 
-    def to_int(self):
+    def to_int_index(self):
         cdef:
             pyst i = 0, j, b
             int32_t offset
@@ -295,6 +338,9 @@ cdef class SparseVector:
         output += '%s\n' % repr(self.index)
         return output
 
+    def copy(self):
+        return SparseVector(self.values.copy(), self.index)
+
     def to_ndarray(self):
         output = np.empty(self.index.length, dtype=np.float64)
         dense_index = self.index.to_dense()
@@ -349,11 +395,11 @@ cdef SparseVector block_op(SparseVector x, SparseVector y, double_func op):
 
         SparseVector out
 
-    xindex = x.index.to_block()
-    yindex = y.index.to_block()
+    xindex = x.index.to_block_index()
+    yindex = y.index.to_block_index()
 
     # need to do this first to know size of result array
-    out_index = x.index.intersect(y.index).to_block()
+    out_index = x.index.intersect(y.index).to_block_index()
 
     outarr = np.empty(out_index.npoints, dtype=np.float64)
     out = SparseVector(outarr, out_index)
@@ -409,11 +455,11 @@ cdef SparseVector dense_op(SparseVector x, SparseVector y, double_func op):
 
         SparseVector out
 
-    xindex = x.index.to_int()
-    yindex = y.index.to_int()
+    xindex = x.index.to_int_index()
+    yindex = y.index.to_int_index()
 
     # need to do this first to know size of result array
-    out_index = x.index.intersect(y.index).to_int()
+    out_index = x.index.intersect(y.index).to_int_index()
     outarr = np.empty(out_index.npoints, dtype=np.float64)
     out = SparseVector(outarr, out_index)
 
diff --git a/pandas/lib/test_sparse.py b/pandas/lib/test_sparse.py
index 5019ecf18..92cc69eb0 100644
--- a/pandas/lib/test_sparse.py
+++ b/pandas/lib/test_sparse.py
@@ -91,20 +91,42 @@ class TestBlockIndex(TestCase):
         _check_case([0], [5], [], [], [], [])
         _check_case([], [], [], [], [], [])
 
-    def test_to_int(self):
+    def test_to_int_index(self):
         locs = [0, 10]
         lengths = [4, 6]
         exp_inds = [0, 1, 2, 3, 10, 11, 12, 13, 14, 15]
 
         block = BlockIndex(20, locs, lengths)
-        dense = block.to_int()
+        dense = block.to_int_index()
 
         assert_equal(dense.indices, exp_inds)
 
 class TestIntIndex(TestCase):
 
-    def test_to_block(self):
-        pass
+    def test_to_block_index(self):
+        def _check_case_dict(case):
+            _check_case(case['xloc'], case['xlen'], case['yloc'], case['ylen'])
+
+        def _check_case(xloc, xlen, yloc, ylen):
+            xindex = BlockIndex(TEST_LENGTH, xloc, xlen)
+            yindex = BlockIndex(TEST_LENGTH, yloc, ylen)
+
+            # see if survive the round trip
+            xbindex = xindex.to_int_index().to_block_index()
+            ybindex = yindex.to_int_index().to_block_index()
+            self.assert_(isinstance(xbindex, BlockIndex))
+            self.assert_(xbindex.equals(xindex))
+            self.assert_(ybindex.equals(yindex))
+
+        _check_case_dict(plain_case)
+        _check_case_dict(delete_blocks)
+        _check_case_dict(split_blocks)
+        _check_case_dict(skip_block)
+        _check_case_dict(no_intersect)
+
+        # one or both is empty
+        _check_case([0], [5], [], [])
+        _check_case([], [], [], [])
 
     def test_intersect(self):
 
@@ -113,10 +135,9 @@ class TestIntIndex(TestCase):
                         case['eloc'], case['elen'])
 
         def _check_case(xloc, xlen, yloc, ylen, eloc, elen):
-            xindex = BlockIndex(TEST_LENGTH, xloc, xlen).to_int()
-            yindex = BlockIndex(TEST_LENGTH, yloc, ylen).to_int()
-
-            expected = BlockIndex(TEST_LENGTH, eloc, elen).to_int()
+            xindex = BlockIndex(TEST_LENGTH, xloc, xlen).to_int_index()
+            yindex = BlockIndex(TEST_LENGTH, yloc, ylen).to_int_index()
+            expected = BlockIndex(TEST_LENGTH, eloc, elen).to_int_index()
 
             result = xindex.intersect(yindex)
             self.assert_(isinstance(result, IntIndex))
@@ -145,8 +166,8 @@ class TestSparseVector(TestCase):
             xindex = BlockIndex(TEST_LENGTH, xloc, xlen)
             yindex = BlockIndex(TEST_LENGTH, yloc, ylen)
 
-            xdindex = xindex.to_int()
-            ydindex = yindex.to_int()
+            xdindex = xindex.to_int_index()
+            ydindex = yindex.to_int_index()
 
             xvals = np.arange(xindex.npoints) * 10 + 1
             yvals = np.arange(yindex.npoints) * 100 + 1
