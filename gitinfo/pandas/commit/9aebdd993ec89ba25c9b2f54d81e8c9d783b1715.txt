commit 9aebdd993ec89ba25c9b2f54d81e8c9d783b1715
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Aug 23 16:15:28 2011 -0400

    DOC: Series docstring cleanup, reorg, deprecations

diff --git a/RELEASE.rst b/RELEASE.rst
index e27b0e5a1..3484e00aa 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -186,6 +186,10 @@ Release notes
   `pandas.core.common`
 * Tacked on `groupName` attribute for groups in GroupBy renamed to `name`
 * WidePanel/LongPanel `dims` attribute renamed to `shape` to be more conformant
+* Slicing a `Series` returns a view now
+* More Series deprecations / renaming: `toCSV` to `to_csv`, `asOf` to `asof`,
+  `merge` to `map`, `applymap` to `apply`, `toDict` to `to_dict`,
+  `combineFirst` to `combine_first`. Will print `FutureWarning`.
 
 **Bug fixes**
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 2097827a6..4014c183e 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -341,7 +341,7 @@ class DataFrame(NDFrame):
     #----------------------------------------------------------------------
     # IO methods (to / from other formats)
 
-    def toDict(self):
+    def to_dict(self):
         """
         Convert DataFrame to nested dictionary (non-pandas)
 
@@ -349,7 +349,7 @@ class DataFrame(NDFrame):
         ------
         nested dict mapping: {column -> index -> value}
         """
-        return dict((k, v.toDict()) for k, v in self.iteritems())
+        return dict((k, v.to_dict()) for k, v in self.iteritems())
 
     @classmethod
     def from_records(cls, data, indexField=None):
@@ -1481,7 +1481,7 @@ class DataFrame(NDFrame):
 
         return self._constructor(result, index=new_index, columns=new_columns)
 
-    def combineFirst(self, other):
+    def combine_first(self, other):
         """
         Combine two DataFrame objects and default to value
         in frame calling the method.
@@ -1492,7 +1492,7 @@ class DataFrame(NDFrame):
 
         Examples
         --------
-        a.combineFirst(b)
+        a.combine_first(b)
             a's values prioritized, use values from b to fill holes
 
         Returns
@@ -2683,6 +2683,11 @@ class DataFrame(NDFrame):
         """
         return self.mul(other, fill_value=1.)
 
+    def combineFirst(self, other):  # pragma: no cover
+        warnings.warn("combineFirst is deprecated. Use combine_first",
+                      FutureWarning)
+        return self.combine_first(other)
+
     def toDataMatrix(self):  # pragma: no cover
         warnings.warn("toDataMatrix will disappear in next release "
                       "as there is no longer a DataMatrix class",
@@ -2721,6 +2726,11 @@ class DataFrame(NDFrame):
                       "instead", FutureWarning)
         return self.to_records(*args, **kwargs)
 
+    def toDict(self):  # pragma: no cover
+        warnings.warn("toDict is deprecated. Use 'to_dic' instead",
+                      FutureWarning)
+        return dict((k, v.to_dict()) for k, v in self.iteritems())
+
     @classmethod
     def fromRecords(cls, *args, **kwargs):  # pragma: no cover
         warnings.warn("fromRecords is deprecated. Use 'from_records' "
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 5dbf31221..84b37e7ee 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -19,6 +19,7 @@ from pandas.core.daterange import DateRange
 from pandas.core.generic import PandasObject
 from pandas.core.index import Index, MultiIndex
 from pandas.core.indexing import _SeriesIndexer, _maybe_droplevels
+from pandas.util.decorators import deprecate
 import pandas.core.datetools as datetools
 import pandas._tseries as _tseries
 
@@ -65,7 +66,7 @@ def _flex_method(op, name):
     Parameters
     ----------
     other: Series or scalar value
-    fill_value : None or float value, default None
+    fill_value : None or float value, default None (NaN)
         Fill missing (NaN) values with this value. If both Series are
         missing, the result will be missing
 
@@ -81,39 +82,29 @@ def _flex_method(op, name):
 
 class Series(np.ndarray, PandasObject):
     """
-    Generic indexed (labeled) vector, including time series
+    One-dimensional ndarray with axis labels (including time series). Labels
+    must be unique and can any hashable type. The object supports both integer-
+    and label-based indexing and provides a host of methods for performing
+    operations involving the index. Statistical methods from ndarray have been
+    overridden to automatically exclude missing data (currently represented as
+    NaN)
 
-    Contains values in a numpy-ndarray with an optional bound index
-    (also an array of dates, strings, or whatever you want the 'row
-    names' of your series to be)
-
-    Rows can be retrieved by index value (date, string, etc.) or
-    relative position in the underlying array.
-
-    Operations between Series (+, -, /, *, **) align values based on
-    their associated index values-- they need not be the same length.
+    Operations between Series (+, -, /, *, **) align values based on their
+    associated index values-- they need not be the same length. The result
+    index will be the sorted union of the two indexes.
 
     Parameters
     ----------
     data : array-like, dict, or scalar value
         Contains data stored in Series
-    index : array-like
-        Index object (or other iterable of same length as data)
-        Must be input if first argument is not a dict. If both a dict
-        and index sequence are used, the index will override the keys
-        found in the dict.
+    index : array-like or Index (1d)
+        Values must be unique and hashable, same length as data. Index object
+        (or other iterable of same length as data) Will default to
+        np.arange(len(data)) if not provided. If both a dict and index sequence
+        are used, the index will override the keys found in the dict.
     dtype : numpy.dtype or None
-        If None, dtype will be inferred
-    copy : boolean, default False
-        Copy input data
-
-    Notes
-    -----
-    If you combine two series, all values for an index position must
-    be present or the value for that index position will be nan. The
-    new index is the sorted union of the two Series indices.
-
-    Data is *not* copied from input arrays by default
+        If None, dtype will be inferred copy : boolean, default False Copy
+        input data
     """
     _AXIS_NUMBERS = {
         'index' : 0
@@ -140,7 +131,7 @@ class Series(np.ndarray, PandasObject):
             subarr = np.array(data, dtype=object)
 
         if subarr.ndim == 0:
-            if isinstance(data, list): # pragma: no cover
+            if isinstance(data, list):  # pragma: no cover
                 subarr = np.array(data, dtype=object)
             elif index is not None:
                 value = data
@@ -212,25 +203,6 @@ class Series(np.ndarray, PandasObject):
         """
         self._index = getattr(obj, '_index', None)
 
-    def toDict(self):
-        return dict(self.iteritems())
-
-    def to_sparse(self, kind='block', fill_value=None):
-        """
-        Convert Series to SparseSeries
-
-        Parameters
-        ----------
-        kind : {'block', 'integer'}
-        fill_value : float, defaults to NaN (missing)
-
-        Returns
-        -------
-        sp : SparseSeries
-        """
-        from pandas.core.sparse import SparseSeries
-        return SparseSeries(self, kind=kind, fill_value=fill_value)
-
     def __contains__(self, key):
         return key in self.index
 
@@ -248,19 +220,17 @@ class Series(np.ndarray, PandasObject):
         index, = own_state
         self.index = index
 
-    def __getitem__(self, key):
-        """
-        Returns item(s) for requested index/sequence, overrides default behavior
-        for series[key].
+    _ix = None
 
-        Logic is as follows:
-            - If key is in the index, return the value corresponding
-              to that index
-            - Otherwise, use key (presumably one integer or a sequence
-              of integers) to obtain values from the series. In the case
-              of a sequence, a 'slice' of the series (with corresponding dates)
-              will be returned, otherwise a single value.
-        """
+    @property
+    def ix(self):
+        if self._ix is None:
+            self._ix = _SeriesIndexer(self)
+
+        return self._ix
+
+    def __getitem__(self, key):
+        # Label-based
         try:
             if isinstance(self.index, MultiIndex):
                 return self._multilevel_index(key)
@@ -279,6 +249,8 @@ class Series(np.ndarray, PandasObject):
             return Series(self.values[indexer],
                           index=self.index[indexer])
 
+        # boolean
+
         # special handling of boolean data with NAs stored in object
         # arrays. Sort of an elaborate hack since we can't represent boolean
         # NA. Hmm
@@ -287,6 +259,8 @@ class Series(np.ndarray, PandasObject):
             key = np.asarray(key, dtype=bool)
             return _index_with(key)
 
+        # other: fancy integer or otherwise
+
         # [slice(0, 5, None)] will break if you convert to ndarray,
         # e.g. as requested by np.median
 
@@ -308,41 +282,11 @@ class Series(np.ndarray, PandasObject):
                 return values[key]
             raise KeyError('%s not in this series!' % str(key))
 
-    def get(self, key, default=None):
-        """
-        Returns value occupying requested index, default to specified
-        missing value if not present
-
-        Parameters
-        ----------
-        key : object
-            Index value looking for
-        default : object, optional
-            Value to return if key not in index
-
-        Returns
-        -------
-        y : scalar
-        """
-        if key in self.index:
-            return self._get_val_at(self.index.get_loc(key))
-        else:
-            return default
-
     # help out SparseSeries
     _get_val_at = ndarray.__getitem__
 
     def __getslice__(self, i, j):
-        """
-        Returns a slice of the Series.
-
-        Note that the underlying values are COPIES.
-
-        The reason that the getslice returns copies is that otherwise you
-        will have a reference to the original series which could be
-        inadvertently changed
-        """
-        return Series(self.values[i:j].copy(), index=self.index[i:j])
+        return Series(self.values[i:j], index=self.index[i:j])
 
     def __setitem__(self, key, value):
         values = self.values
@@ -417,11 +361,14 @@ class Series(np.ndarray, PandasObject):
     def __iter__(self):
         return iter(self.values)
 
-    def copy(self):
-        return Series(self.values.copy(), index=self.index)
+    def iteritems(self):
+        """
+        Lazily iterate over (index, value) tuples
+        """
+        return itertools.izip(iter(self.index), iter(self))
 
-#-------------------------------------------------------------------------------
-#   Arithmetic operators
+    #----------------------------------------------------------------------
+    #   Arithmetic operators
 
     __add__ = _arith_method(operator.add, '__add__')
     __sub__ = _arith_method(operator.sub, '__sub__')
@@ -445,105 +392,161 @@ class Series(np.ndarray, PandasObject):
     __idiv__ = __div__
     __ipow__ = __pow__
 
-#-------------------------------------------------------------------------------
-# Statistics, overridden ndarray methods
+    #----------------------------------------------------------------------
+    # Misc public methods
 
-    # TODO: integrate bottleneck
+    def keys(self):
+        "Alias for index"
+        return self.index
 
-    def count(self):
+    @property
+    def values(self):
         """
-        Return number of observations of Series.
+        Return Series as ndarray
 
         Returns
         -------
-        nobs : int
+        arr : numpy.ndarray
         """
-        return notnull(self.values).sum()
+        return self.view(ndarray)
 
-    def sum(self, axis=None, dtype=None, out=None):
-        """
-        Sum of non-null values
+    def copy(self):
         """
-        return self._ndarray_statistic('sum')
+        Return new Series with copy of underlying values
 
-    def mean(self, axis=None, dtype=None, out=None):
-        """
-        Mean of non-null values
+        Returns
+        -------
+        cp : Series
         """
-        return self._ndarray_statistic('mean')
+        return Series(self.values.copy(), index=self.index)
 
-    def prod(self, axis=None, dtype=None, out=None):
+    def to_dict(self):
         """
-        Mean of non-null values
+        Convert Series to {label -> value} dict
+
+        Returns
+        -------
+        value_dict : dict
         """
-        return self._ndarray_statistic('prod')
+        return dict(self.iteritems())
 
-    def _ndarray_statistic(self, funcname):
-        arr = self.values
-        retVal = getattr(arr, funcname)()
+    def to_sparse(self, kind='block', fill_value=None):
+        """
+        Convert Series to SparseSeries
 
-        if isnull(retVal):
-            arr = remove_na(arr)
-            if len(arr) == 0:
-                return np.nan
-            retVal = getattr(arr, funcname)()
+        Parameters
+        ----------
+        kind : {'block', 'integer'}
+        fill_value : float, defaults to NaN (missing)
 
-        return retVal
+        Returns
+        -------
+        sp : SparseSeries
+        """
+        from pandas.core.sparse import SparseSeries
+        return SparseSeries(self, kind=kind, fill_value=fill_value)
 
-    def quantile(self, q=0.5):
+    def get(self, key, default=None):
         """
-        Return value at the given quantile
+        Returns value occupying requested index, default to specified
+        missing value if not present. Analogous to dict.get
 
         Parameters
         ----------
-        q : quantile
-            0 <= q <= 1
+        key : object
+            Index value looking for
+        default : object, optional
+            Value to return if key not in index
 
         Returns
         -------
-        q : float
+        y : scalar
         """
-        from scipy.stats import scoreatpercentile
-        return scoreatpercentile(self.valid().values, q * 100)
+        if key in self.index:
+            return self._get_val_at(self.index.get_loc(key))
+        else:
+            return default
 
-    def describe(self):
+    #----------------------------------------------------------------------
+    # Statistics, overridden ndarray methods
+
+    # TODO: integrate bottleneck
+
+    def count(self):
         """
-        Generate various summary statistics of columns, excluding NaN values
+        Return number of non-NA/null observations in the Series
 
         Returns
         -------
-        DataFrame
+        nobs : int
         """
-        names = ['count', 'mean', 'std', 'min',
-                 '10%', '50%', '90%', 'max']
+        return notnull(self.values).sum()
 
-        data = [self.count(), self.mean(), self.std(), self.min(),
-                self.quantile(.1), self.median(), self.quantile(.9),
-                self.max()]
+    def sum(self, axis=0, dtype=None, out=None):
+        """
+        Sum of non-NA/null values
 
-        return Series(data, index=names)
+        Returns
+        -------
+        sum : float
+        """
+        return self._ndarray_statistic('sum', dtype=dtype)
+
+    def mean(self, axis=0, dtype=None, out=None):
+        """
+        Mean of non-NA/null values
+
+        Returns
+        -------
+        mean : float
+        """
+        return self._ndarray_statistic('mean', dtype=dtype)
+
+    def prod(self, axis=0, dtype=None, out=None):
+        """
+        Product of non-NA/null values
+
+        Returns
+        -------
+        product : float
+        """
+        return self._ndarray_statistic('prod', dtype=dtype)
 
     def min(self, axis=None, out=None):
         """
-        Minimum of non-null values
+        Minimum of non-NA/null values
+
+        Returns
+        -------
+        min : float
         """
         arr = self.values.copy()
         if not issubclass(arr.dtype.type, np.int_):
-            arr[isnull(arr)] = np.inf
+            np.putmask(arr, isnull(arr), np.inf)
         return arr.min()
 
     def max(self, axis=None, out=None):
         """
-        Maximum of non-null values
+        Maximum of non-NA/null values
+
+        Returns
+        -------
+        max : float
         """
         arr = self.values.copy()
         if not issubclass(arr.dtype.type, np.int_):
-            arr[isnull(arr)] = -np.inf
+            np.putmask(arr, isnull(arr), -np.inf)
         return arr.max()
 
     def std(self, axis=None, dtype=None, out=None, ddof=1):
         """
-        Unbiased standard deviation of non-null values
+        Unbiased standard deviation of non-NA/null values
+
+        Extra parameters are to preserve ndarray interface.
+
+        Returns
+        -------
+        stdev : float
         """
         nona = remove_na(self.values)
         if len(nona) < 2:
@@ -552,41 +555,28 @@ class Series(np.ndarray, PandasObject):
 
     def var(self, axis=None, dtype=None, out=None, ddof=1):
         """
-        Unbiased variance of non-null values
-        """
-        nona = remove_na(self.values)
-        if len(nona) < 2:
-            return nan
-        return ndarray.var(nona, axis, dtype, out, ddof)
+        Unbiased variance of non-NA/null values
 
-    def skew(self):
-        """
-        Unbiased skewness of the non-null values
+        Extra parameters are to preserve ndarray interface.
 
         Returns
         -------
-        skew : float
+        var : float
         """
-        y = np.array(self.values)
-        mask = notnull(y)
-        count = mask.sum()
-        np.putmask(y, -mask, 0)
-
-        A = y.sum() / count
-        B = (y**2).sum() / count  - A**2
-        C = (y**3).sum() / count - A**3 - 3*A*B
-
-        return (np.sqrt((count**2-count))*C) / ((count-2)*np.sqrt(B)**3)
+        nona = remove_na(self.values)
+        if len(nona) < 2:
+            return nan
+        return ndarray.var(nona, axis, dtype, out, ddof)
 
     def cumsum(self, axis=0, dtype=None, out=None):
         """
-        Cumulative sum of values. Preserves NaN values
+        Cumulative sum of values. Preserves locations of NaN values
 
         Extra parameters are to preserve ndarray interface.
 
         Returns
         -------
-
+        cumsum : Series
         """
         arr = self.values.copy()
 
@@ -604,7 +594,13 @@ class Series(np.ndarray, PandasObject):
 
     def cumprod(self, axis=0, dtype=None, out=None):
         """
-        Overriding numpy's built-in cumprod functionality
+        Cumulative product of values. Preserves locations of NaN values
+
+        Extra parameters are to preserve ndarray interface.
+
+        Returns
+        -------
+        cumprod : Series
         """
         arr = self.values.copy()
 
@@ -622,7 +618,11 @@ class Series(np.ndarray, PandasObject):
 
     def median(self):
         """
-        Compute median value of non-null values
+        Compute median value of non-NA/null values
+
+        Returns
+        -------
+        median : float
         """
         arr = self.values
 
@@ -632,13 +632,80 @@ class Series(np.ndarray, PandasObject):
         arr = arr[notnull(arr)]
         return _tseries.median(arr)
 
+    def _ndarray_statistic(self, funcname, dtype=None):
+        arr = self.values
+        retVal = getattr(arr, funcname)(dtype=dtype)
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            if len(arr) == 0:
+                return np.nan
+            retVal = getattr(arr, funcname)(dtype=dtype)
+
+        return retVal
+
+    def quantile(self, q=0.5):
+        """
+        Return value at the given quantile, a la scoreatpercentile in
+        scipy.stats
+
+        Parameters
+        ----------
+        q : quantile
+            0 <= q <= 1
+
+        Returns
+        -------
+        quantile : float
+        """
+        from scipy.stats import scoreatpercentile
+        return scoreatpercentile(self.valid().values, q * 100)
+
+    def describe(self):
+        """
+        Generate various summary statistics of columns, excluding NaN
+        values. These include: count, mean, std, min, max, and 10%/50%/90%
+        quantiles
+
+        Returns
+        -------
+        desc : Series
+        """
+        names = ['count', 'mean', 'std', 'min',
+                 '10%', '50%', '90%', 'max']
+
+        data = [self.count(), self.mean(), self.std(), self.min(),
+                self.quantile(.1), self.median(), self.quantile(.9),
+                self.max()]
+
+        return Series(data, index=names)
+
+    def skew(self):
+        """
+        Unbiased skewness of the non-NA/null values
+
+        Returns
+        -------
+        skew : float
+        """
+        y = np.array(self.values)
+        mask = notnull(y)
+        count = mask.sum()
+        np.putmask(y, -mask, 0)
+
+        A = y.sum() / count
+        B = (y**2).sum() / count  - A**2
+        C = (y**3).sum() / count - A**3 - 3*A*B
+
+        return (np.sqrt((count**2-count))*C) / ((count-2)*np.sqrt(B)**3)
+
     def corr(self, other):
         """
         Compute correlation two Series, excluding missing values
 
         Parameters
         ----------
-        other : Series object
+        other : Series
 
         Returns
         -------
@@ -660,7 +727,7 @@ class Series(np.ndarray, PandasObject):
 
         Returns
         -------
-        TimeSeries
+        diffed : Series
         """
         return (self - self.shift(1))
 
@@ -670,7 +737,7 @@ class Series(np.ndarray, PandasObject):
 
         Returns
         -------
-        TimeSeries
+        autocorr : float
         """
         return self.corr(self.shift(1))
 
@@ -685,7 +752,7 @@ class Series(np.ndarray, PandasObject):
 
         Returns
         -------
-        y : Series
+        clipped : Series
         """
         result = self
         if lower is not None:
@@ -696,43 +763,39 @@ class Series(np.ndarray, PandasObject):
         return result
 
     def clip_upper(self, threshold):
-        """Return copy of series with values above given value truncated"""
-        return np.where(self > threshold, threshold, self)
-
-    def clip_lower(self, threshold):
-        """Return copy of series with values below given value truncated"""
-        return np.where(self < threshold, threshold, self)
-
-#-------------------------------------------------------------------------------
-# Iteration
-
-    def keys(self):
-        "Alias for Series index"
-        return self.index
-
-    @property
-    def values(self):
         """
-        Return Series as ndarray
+        Return copy of series with values above given value truncated
+
+        See also
+        --------
+        clip
 
         Returns
         -------
-        arr : numpy.ndarray
+        clipped : Series
         """
-        return self.view(ndarray)
+        return np.where(self > threshold, threshold, self)
 
-    def iteritems(self):
+    def clip_lower(self, threshold):
         """
-        Lazily iterate over (index, value) tuples
+        Return copy of series with values below given value truncated
+
+        See also
+        --------
+        clip
+
+        Returns
+        -------
+        clipped : Series
         """
-        return itertools.izip(iter(self.index), iter(self))
+        return np.where(self < threshold, threshold, self)
 
 #-------------------------------------------------------------------------------
 # Combination
 
     def append(self, other):
         """
-        Concatenate two Series. The indices should not overlap
+        Concatenate two Series. The indexes must not overlap
 
         Parameters
         ----------
@@ -751,16 +814,20 @@ class Series(np.ndarray, PandasObject):
 
     def _binop(self, other, func, fill_value=None):
         """
+        Perform generic binary operation with optional fill value
+
         Parameters
         ----------
         other : Series
+        func : binary operator
+        fill_value : float or object
+            Value to substitute for NA/null values. If both Series are NA in a
+            location, the result will be NA regardless of the passed fill value
 
         Returns
         -------
         combined : Series
         """
-        # TODO: docstring
-
         assert(isinstance(other, Series))
 
         new_index = self.index
@@ -796,8 +863,8 @@ class Series(np.ndarray, PandasObject):
     def combine(self, other, func, fill_value=nan):
         """
         Perform elementwise binary operation on two Series using given function
-        with optional fill value when an index is missing from one Series or the
-        other
+        with optional fill value when an index is missing from one Series or
+        the other
 
         Parameters
         ----------
@@ -815,16 +882,17 @@ class Series(np.ndarray, PandasObject):
             new_values = np.empty(len(new_index), dtype=self.dtype)
             for i, idx in enumerate(new_index):
                 new_values[i] = func(self.get(idx, fill_value),
-                                 other.get(idx, fill_value))
+                                     other.get(idx, fill_value))
         else:
             new_index = self.index
             new_values = func(self.values, other)
 
         return Series(new_values, index=new_index)
 
-    def combineFirst(self, other):
+    def combine_first(self, other):
         """
-        Combine Series values, choosing calling Series's values first.
+        Combine Series values, choosing the calling Series's values
+        first. Result index will be the union of the two indexes
 
         Parameters
         ----------
@@ -833,18 +901,10 @@ class Series(np.ndarray, PandasObject):
         Returns
         -------
         y : Series
-            formed as union of two Series
         """
-        if self.index.equals(other.index):
-            new_index = self.index
-            # save ourselves the copying in this case
-            this = self
-        else:
-            new_index = self.index + other.index
-
-            this = self.reindex(new_index)
-            other = other.reindex(new_index)
-
+        new_index = self.index + other.index
+        this = self.reindex(new_index, copy=False)
+        other = other.reindex(new_index, copy=False)
         result = Series(np.where(isnull(this), other, this), index=new_index)
         return result
 
@@ -853,7 +913,8 @@ class Series(np.ndarray, PandasObject):
 
     def sort(self, axis=0, kind='quicksort', order=None):
         """
-        Overridden NumPy sort, taking care with missing values
+        Sort values and index labels in place, for compatibility with
+        ndarray. No return value
         """
         sortedSeries = self.order(na_last=True)
         self[:] = sortedSeries
@@ -861,7 +922,12 @@ class Series(np.ndarray, PandasObject):
 
     def argsort(self, axis=0, kind='quicksort', order=None):
         """
-        Overriding numpy's built-in cumsum functionality
+        Overrides ndarray.argsort. Argsorts the value, omitting NA/null values,
+        and places the result in the same locations as the non-NA values
+
+        Returns
+        -------
+        argsorted : Series
         """
         values = self.values
         mask = isnull(values)
@@ -876,12 +942,14 @@ class Series(np.ndarray, PandasObject):
 
     def order(self, na_last=True, ascending=True, **kwds):
         """
-        Sorts Series object, by value, maintaining index-value object
+        Sorts Series object, by value, maintaining index-value link
 
         Parameters
         ----------
         na_last : boolean (optional, default=True)
             Put NaN's at beginning or end
+        ascending : boolean, default True
+            Sort ascending. Passing False sorts descending
 
         Returns
         -------
@@ -895,7 +963,7 @@ class Series(np.ndarray, PandasObject):
                 # stable sort not available for object dtype
                 return arr.argsort()
 
-        if 'missingAtEnd' in kwds: # pragma: no cover
+        if 'missingAtEnd' in kwds:  # pragma: no cover
             warnings.warn("missingAtEnd is deprecated, use na_last",
                           FutureWarning)
             na_last = kwds['missingAtEnd']
@@ -926,8 +994,9 @@ class Series(np.ndarray, PandasObject):
 
     def sortlevel(self, level=0, ascending=True):
         """
-        Sort multilevel index by chosen level. Data will be lexicographically
-        sorted by the chosen level followed by the other levels (in order)
+        Sort Series with MultiIndex by chosen level. Data will be
+        lexicographically sorted by the chosen level followed by the other
+        levels (in order)
 
         Parameters
         ----------
@@ -947,12 +1016,12 @@ class Series(np.ndarray, PandasObject):
 
     def unstack(self, level=-1):
         """
-        "Unstack" Series with multi-level index to produce DataFrame
+        Unstack, a.k.a. pivot, Series with MultiIndex to produce DataFrame
 
         Parameters
         ----------
         level : int, default last level
-            Level to "unstack"
+            Level to unstack
 
         Examples
         --------
@@ -985,12 +1054,29 @@ class Series(np.ndarray, PandasObject):
     def map(self, arg):
         """
         Map values of Series using input correspondence (which can be
-        a dict, Series, or function).
+        a dict, Series, or function)
 
         Parameters
         ----------
         arg : function, dict, or Series
 
+        Examples
+        --------
+        >>> x
+        one   1
+        two   2
+        three 3
+
+        >>> y
+        1  foo
+        2  bar
+        3  baz
+
+        >>> x.map(y)
+        one   foo
+        two   bar
+        three baz
+
         Returns
         -------
         y : Series
@@ -1017,11 +1103,9 @@ class Series(np.ndarray, PandasObject):
         else:
             return Series([arg(x) for x in self], index=self.index)
 
-    merge = map
-
     def apply(self, func):
         """
-        Call function on elements on array. Can be ufunc or Python function
+        Invoke function on values of Series. Can be ufunc or Python function
         expecting only single values
 
         Parameters
@@ -1037,18 +1121,20 @@ class Series(np.ndarray, PandasObject):
         except Exception:
             return Series([func(x) for x in self], index=self.index)
 
-    applymap = apply
-
     def reindex(self, index=None, method=None, copy=True):
-        """Conform Series to new Index
+        """Conform Series to new index with optional filling logic, placing
+        NA/NaN in locations having no value in the previous index. A new object
+        is produced unless the new index is equivalent to the current one and
+        copy=False
 
         Parameters
         ----------
-        index : array-like
-            Preferably an Index object (to avoid duplicating data)
+        index : array-like or Index
+            New labels / index to conform to. Preferably an Index object to
+            avoid duplicating data
         method : {'backfill', 'bfill', 'pad', 'ffill', None}
             Method to use for filling holes in reindexed Series
-            pad / ffill: propagate last valid observation forward to next valid
+            pad / ffill: propagate LAST valid observation forward to next valid
             backfill / bfill: use NEXT valid observation to fill gap
         copy : boolean, default True
             Return a new object, even if the passed indexes are the same
@@ -1083,7 +1169,8 @@ class Series(np.ndarray, PandasObject):
 
     def reindex_like(self, other, method=None):
         """
-        Reindex Series to match index of another Series
+        Reindex Series to match index of another Series, optionally with
+        filling logic
 
         Parameters
         ----------
@@ -1093,7 +1180,7 @@ class Series(np.ndarray, PandasObject):
 
         Notes
         -----
-        Like calling s.reindex(other.index)
+        Like calling s.reindex(other.index, method=...)
 
         Returns
         -------
@@ -1120,33 +1207,31 @@ class Series(np.ndarray, PandasObject):
 
     def fillna(self, value=None, method='pad'):
         """
-        Fill NaN values using the specified method.
+        Fill NA/NaN values using the specified method
 
         Parameters
         ----------
         value : any kind (should be same type as array)
             Value to use to fill holes (e.g. 0)
-
         method : {'backfill', 'bfill', 'pad', 'ffill', None}, default 'pad'
             Method to use for filling holes in reindexed Series
-
             pad / ffill: propagate last valid observation forward to next valid
             backfill / bfill: use NEXT valid observation to fill gap
 
-        Returns
-        -------
-        TimeSeries with NaN's filled
-
         See also
         --------
         reindex, asfreq
+
+        Returns
+        -------
+        filled : Series
         """
         if value is not None:
             newSeries = self.copy()
             newSeries[isnull(newSeries)] = value
             return newSeries
-        else: # Using reindex to pad / backfill
-            if method is None: # pragma: no cover
+        else:
+            if method is None:  # pragma: no cover
                 raise ValueError('must specify a fill method')
 
             method = method.lower()
@@ -1158,7 +1243,7 @@ class Series(np.ndarray, PandasObject):
 
             mask = isnull(self.values)
 
-            if _numpy_lt_151(): # pragma: no cover
+            if _numpy_lt_151():  # pragma: no cover
                 mask = mask.astype(np.uint8)
 
             if method == 'pad':
@@ -1173,26 +1258,29 @@ class Series(np.ndarray, PandasObject):
 # Miscellaneous
 
     def plot(self, label=None, kind='line', use_index=True, rot=30, ax=None,
-             style='-', **kwds): # pragma: no cover
+             style='-', **kwds):  # pragma: no cover
         """
-        Plot the input series with the index on the x-axis using
-        matplotlib / pylab.
+        Plot the input series with the index on the x-axis using matplotlib
 
         Parameters
         ----------
         label : label argument to provide to plot
-        kind : {'line', 'bar', 'hist'}
-            Default: line for TimeSeries, hist for Series
-        auto_x : if True, it will use range(len(self)) as x-axis
-        kwds : other plotting keyword arguments
+        kind : {'line', 'bar'}
+        rot : int, default 30
+            Rotation for tick labels
+        use_index : boolean, default True
+            Plot index as axis tick labels
+        ax : matplotlib axis object
+            If not passed, uses gca()
+        style : string, default '-'
+            matplotlib line style to use
+        kwds : keywords
+            To be passed to the actual plotting function
 
         Notes
         -----
         See matplotlib documentation online for more on this subject
-
-        Default plot-types: TimeSeries (line), Series (bar)
-
-        Intended to be used in ipython -pylab mode
+        Intended to be used in ipython --pylab mode
         """
         import matplotlib.pyplot as plt
 
@@ -1215,7 +1303,7 @@ class Series(np.ndarray, PandasObject):
         elif kind == 'bar':
             xinds = np.arange(N) + 0.25
             ax.bar(xinds, self.values.astype(float), 0.5,
-                   bottom=np.zeros(N), linewidth=1)
+                   bottom=np.zeros(N), linewidth=1, **kwds)
 
             if N < 10:
                 fontsize = 12
@@ -1225,7 +1313,7 @@ class Series(np.ndarray, PandasObject):
             ax.set_xticks(xinds + 0.25)
             ax.set_xticklabels(self.index, rotation=rot, fontsize=fontsize)
 
-        # kludge
+        # try to make things prettier
         try:
             fig = plt.gcf()
             fig.autofmt_xdate()
@@ -1234,20 +1322,21 @@ class Series(np.ndarray, PandasObject):
 
         plt.draw_if_interactive()
 
-    def hist(self, ax=None): # pragma: no cover
+    def hist(self, ax=None, **kwds):  # pragma: no cover
         """
-        Draw histogram of the input series using matplotlib / pylab.
+        Draw histogram of the input series using matplotlib
 
         Parameters
         ----------
+        ax : matplotlib axis object
+            If not passed, uses gca()
+        kwds : keywords
+            To be passed to the actual plotting function
 
         Notes
         -----
-        See matplotlib documentation online for more on this subject
-
-        Default plot-types: TimeSeries (line), Series (bar)
+        See matplotlib documentation online for more on this
 
-        Intended to be used in ipython -pylab mode
         """
         import matplotlib.pyplot as plt
 
@@ -1256,7 +1345,7 @@ class Series(np.ndarray, PandasObject):
 
         ax.hist(self.values)
 
-    def toCSV(self, path):
+    def to_csv(self, path):
         """
         Write the Series to a CSV file
 
@@ -1266,23 +1355,24 @@ class Series(np.ndarray, PandasObject):
             Output filepath. If None, write to stdout
         """
         f = open(path, 'wb')
-
         for idx, value in self.iteritems():
             f.write(str(idx) + ',' + str(value) + '\n')
-
         f.close()
 
     def valid(self):
         """
-        Return Series without NaN values
+        Return Series without null values
 
         Returns
         -------
-        Series
+        valid : Series
         """
         return remove_na(self)
 
     def first_valid_index(self):
+        """
+        Return label for first non-NA/null value
+        """
         if len(self) == 0:
             return None
 
@@ -1294,6 +1384,9 @@ class Series(np.ndarray, PandasObject):
             return self.index[i]
 
     def last_valid_index(self):
+        """
+        Return label for last non-NA/null value
+        """
         if len(self) == 0:
             return None
 
@@ -1304,26 +1397,26 @@ class Series(np.ndarray, PandasObject):
         else:
             return self.index[len(self) - i - 1]
 
-#-------------------------------------------------------------------------------
-# Time series-oriented methods
+    #----------------------------------------------------------------------
+    # Time series-oriented methods
 
     def shift(self, periods, offset=None, timeRule=None):
         """
-        Shift the underlying series of the DataFrame and Series objects within
-        by given number (positive or negative) of business/weekdays.
+        Shift the index of the Series by desired number of periods with an
+        optional time offset
 
         Parameters
         ----------
-        periods : int (+ or -)
-            Number of periods to move
-        offset : DateOffset, optional
+        periods : int
+            Number of periods to move, can be positive or negative
+        offset : DateOffset or timedelta, optional
             Increment to use from datetools module
-        timeRule : string
+        timeRule : string, optional
             time rule name to use by name (e.g. 'WEEKDAY')
 
         Returns
         -------
-        TimeSeries
+        shifted : Series
         """
         if periods == 0:
             return self.copy()
@@ -1345,7 +1438,7 @@ class Series(np.ndarray, PandasObject):
         else:
             return Series(self, index=self.index.shift(periods, offset))
 
-    def asOf(self, date):
+    def asof(self, date):
         """
         Return last good (non-NaN) value in TimeSeries if value is NaN for
         requested date.
@@ -1385,8 +1478,8 @@ class Series(np.ndarray, PandasObject):
     def asfreq(self, freq, method=None):
         """
         Convert this TimeSeries to the provided frequency using DateOffset
-        objects. Optionally provide fill method to pad/backfill/interpolate
-        missing values.
+        object or time rule. Optionally provide fill method to
+        pad/backfill/interpolate missing values.
 
         Parameters
         ----------
@@ -1397,7 +1490,7 @@ class Series(np.ndarray, PandasObject):
 
         Returns
         -------
-        TimeSeries
+        converted : TimeSeries
         """
         if isinstance(freq, datetools.DateOffset):
             dateRange = DateRange(self.index[0], self.index[-1], offset=freq)
@@ -1414,13 +1507,12 @@ class Series(np.ndarray, PandasObject):
         ----------
         method : {'linear', 'time'}
             Interpolation method.
-
             Time interpolation works on daily and higher resolution
             data to interpolate given length of interval
 
         Returns
         -------
-        Series with values interpolated
+        interpolated : Series
         """
         if method == 'time':
             if not isinstance(self, TimeSeries):
@@ -1459,6 +1551,23 @@ class Series(np.ndarray, PandasObject):
         -----
         Function / dict values must be unique (1-to-1)
 
+        Examples
+        --------
+        >>> x
+        foo 1
+        bar 2
+        baz 3
+
+        >>> x.rename(str.upper)
+        FOO 1
+        BAR 2
+        BAZ 3
+
+        >>> x.rename({'foo' : 'a', 'bar' : 'b', 'baz' : 'c'})
+        a 1
+        b 2
+        c 3
+
         Returns
         -------
         y : Series (new object)
@@ -1480,29 +1589,19 @@ class Series(np.ndarray, PandasObject):
     # Deprecated stuff
 
     @classmethod
-    def fromValue(cls, value=nan, index=None, dtype=None): # pragma: no cover
+    def fromValue(cls, value=nan, index=None, dtype=None):  # pragma: no cover
         warnings.warn("'fromValue', can call Series(value, index=index) now",
                       FutureWarning)
-
         return Series(value, index=index, dtype=dtype)
 
-    def _firstTimeWithValue(self): # pragma: no cover
-        warnings.warn("_firstTimeWithValue is deprecated. Use "
-                      "first_valid_index instead", FutureWarning)
-        return self.first_valid_index()
-
-    def _lastTimeWithValue(self): # pragma: no cover
-        warnings.warn("_firstTimeWithValue is deprecated. Use "
-                      "last_valid_index instead", FutureWarning)
-        return self.last_valid_index()
-
-    _ix = None
-    @property
-    def ix(self):
-        if self._ix is None:
-            self._ix = _SeriesIndexer(self)
-
-        return self._ix
+    asOf = deprecate('asOf', asof)
+    toDict = deprecate('toDict', to_dict)
+    merge = deprecate('merge', map)
+    applymap = deprecate('applymap', apply)
+    combineFirst = deprecate('combineFirst', combine_first)
+    _firstTimeWithValue = deprecate('_firstTimeWithValue', first_valid_index)
+    _lastTimeWithValue = deprecate('_lastTimeWithValue', last_valid_index)
+    toCSV = deprecate('toCSV', to_csv)
 
 class TimeSeries(Series):
     pass
@@ -1547,7 +1646,7 @@ class _Unstacker(object):
         self.values = values
         self.value_columns = value_columns
 
-        if value_columns is None and values.shape[1] != 1: # pragma: no cover
+        if value_columns is None and values.shape[1] != 1:  # pragma: no cover
             raise ValueError('must pass column labels for multi-column data')
 
         self.index = index
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index d9dc3f939..f30cddbd6 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -956,12 +956,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # buglet
         self.mixed_frame._data.ndim
 
-    def test_toDict(self):
+    def test_to_dict(self):
         test_data = {
                 'A' : {'1' : 1, '2' : 2},
                 'B' : {'1' : '1', '2' : '2', '3' : '3'},
         }
-        recons_data = DataFrame(test_data).toDict()
+        recons_data = DataFrame(test_data).to_dict()
 
         for k, v in test_data.iteritems():
             for k2, v2 in v.iteritems():
@@ -1262,7 +1262,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         for key, s in added.iteritems():
             assert_series_equal(s, self.frame[key] + series[key])
 
-        larger_series = series.toDict()
+        larger_series = series.to_dict()
         larger_series['E'] = 1
         larger_series = Series(larger_series)
         larger_added = self.frame + larger_series
@@ -2006,11 +2006,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         sorted = self.frame.sort(ascending=False)
         sorted_A = self.frame.sort(column='A', ascending=False)
 
-    def test_combineFirst(self):
+    def test_combine_first(self):
         # disjoint
         head, tail = self.frame[:5], self.frame[5:]
 
-        combined = head.combineFirst(tail)
+        combined = head.combine_first(tail)
         reordered_frame = self.frame.reindex(combined.index)
         assert_frame_equal(combined, reordered_frame)
         self.assert_(tm.equalContents(combined.columns, self.frame.columns))
@@ -2025,7 +2025,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         fcopy2['B'] = 0
         del fcopy2['D']
 
-        combined = fcopy.combineFirst(fcopy2)
+        combined = fcopy.combine_first(fcopy2)
 
         self.assert_((combined['A'] == 1).all())
         assert_series_equal(combined['B'], fcopy['B'])
@@ -2036,29 +2036,29 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         head, tail = reordered_frame[:10].copy(), reordered_frame
         head['A'] = 1
 
-        combined = head.combineFirst(tail)
+        combined = head.combine_first(tail)
         self.assert_((combined['A'][:10] == 1).all())
 
         # reverse overlap
         tail['A'][:10] = 0
-        combined = tail.combineFirst(head)
+        combined = tail.combine_first(head)
         self.assert_((combined['A'][:10] == 0).all())
 
         # no overlap
         f = self.frame[:10]
         g = self.frame[10:]
-        combined = f.combineFirst(g)
+        combined = f.combine_first(g)
         assert_series_equal(combined['A'].reindex(f.index), f['A'])
         assert_series_equal(combined['A'].reindex(g.index), g['A'])
 
         # corner cases
-        comb = self.frame.combineFirst(self.empty)
+        comb = self.frame.combine_first(self.empty)
         assert_frame_equal(comb, self.frame)
 
-        comb = self.empty.combineFirst(self.frame)
+        comb = self.empty.combine_first(self.frame)
         assert_frame_equal(comb, self.frame)
 
-    def test_combineFirst_mixed_bug(self):
+    def test_combine_first_mixed_bug(self):
 	idx = Index(['a','b','c','e'])
 	ser1 = Series([5.0,-9.0,4.0,100.],index=idx)
 	ser2 = Series(['a', 'b', 'c', 'e'], index=idx)
@@ -2078,7 +2078,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
                              "col5" : ser3})
 
 
-        combined = frame1.combineFirst(frame2)
+        combined = frame1.combine_first(frame2)
         self.assertEqual(len(combined.columns), 5)
 
     def test_combineAdd(self):
@@ -2479,7 +2479,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assert_(f._get_axis(1) is f.columns)
         self.assertRaises(Exception, f._get_axis_number, 2)
 
-    def test_combineFirst_mixed(self):
+    def test_combine_first_mixed(self):
         a = Series(['a','b'], index=range(2))
         b = Series(range(2), index=range(2))
         f = DataFrame({'A' : a, 'B' : b})
@@ -2488,7 +2488,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         b = Series(range(2), index=range(5, 7))
         g = DataFrame({'A' : a, 'B' : b})
 
-        combined = f.combineFirst(g)
+        combined = f.combine_first(g)
 
     def test_more_asMatrix(self):
         values = self.mixed_frame.as_matrix()
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index a8d748ef7..8d9555470 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -221,6 +221,11 @@ class TestSeries(unittest.TestCase):
         self.assert_(common.equalContents(numSliceEnd,
                                           np.array(self.series)[-10:]))
 
+        # test return view
+        sl = self.series[10:20]
+        sl[:] = 0
+        self.assert_((self.series[10:20] == 0).all())
+
     def test_setitem(self):
         self.ts[self.ts.index[5]] = np.NaN
         self.ts[[1,2,17]] = np.NaN
@@ -545,7 +550,7 @@ class TestSeries(unittest.TestCase):
             assert_series_equal(result, exp)
             _check_fill(op, equiv_op, a, b, fill_value=fv)
 
-    def test_combineFirst(self):
+    def test_combine_first(self):
         series = Series(common.makeIntIndex(20).astype(float),
                         index=common.makeIntIndex(20))
 
@@ -553,12 +558,12 @@ class TestSeries(unittest.TestCase):
         series_copy[::2] = np.NaN
 
         # nothing used from the input
-        combined = series.combineFirst(series_copy)
+        combined = series.combine_first(series_copy)
 
         self.assert_(np.array_equal(combined, series))
 
         # Holes filled from input
-        combined = series_copy.combineFirst(series)
+        combined = series_copy.combine_first(series)
         self.assert_(np.isfinite(combined).all())
 
         self.assert_(np.array_equal(combined[::2], series[::2]))
@@ -569,14 +574,14 @@ class TestSeries(unittest.TestCase):
         floats = Series(common.randn(20), index=index)
         strings = Series(common.makeStringIndex(10), index=index[::2])
 
-        combined = strings.combineFirst(floats)
+        combined = strings.combine_first(floats)
 
         common.assert_dict_equal(strings, combined, compare_keys=False)
         common.assert_dict_equal(floats[1::2], combined, compare_keys=False)
 
         # corner case
         s = Series([1., 2, 3], index=[0, 1, 2])
-        result = s.combineFirst(Series([], index=[]))
+        result = s.combine_first(Series([], index=[]))
         assert_series_equal(s, result)
 
     def test_overloads(self):
@@ -675,12 +680,12 @@ class TestSeries(unittest.TestCase):
 
         self.assert_(np.array_equal(result, self.ts * 2))
 
-    def test_toCSV(self):
-        self.ts.toCSV('_foo')
+    def test_to_csv(self):
+        self.ts.to_csv('_foo')
         os.remove('_foo')
 
-    def test_toDict(self):
-        self.assert_(np.array_equal(Series(self.ts.toDict()), self.ts))
+    def test_to_dict(self):
+        self.assert_(np.array_equal(Series(self.ts.to_dict()), self.ts))
 
     def test_clip(self):
         val = self.ts.median()
@@ -774,52 +779,52 @@ class TestSeries(unittest.TestCase):
                                 after=self.ts.index[0] - offset)
         assert(len(truncated) == 0)
 
-    def test_asOf(self):
+    def test_asof(self):
         self.ts[5:10] = np.NaN
         self.ts[15:20] = np.NaN
 
-        val1 = self.ts.asOf(self.ts.index[7])
-        val2 = self.ts.asOf(self.ts.index[19])
+        val1 = self.ts.asof(self.ts.index[7])
+        val2 = self.ts.asof(self.ts.index[19])
 
         self.assertEqual(val1, self.ts[4])
         self.assertEqual(val2, self.ts[14])
 
         # accepts strings
-        val1 = self.ts.asOf(str(self.ts.index[7]))
+        val1 = self.ts.asof(str(self.ts.index[7]))
         self.assertEqual(val1, self.ts[4])
 
         # in there
-        self.assertEqual(self.ts.asOf(self.ts.index[3]), self.ts[3])
+        self.assertEqual(self.ts.asof(self.ts.index[3]), self.ts[3])
 
         # no as of value
         d = self.ts.index[0] - datetools.bday
-        self.assert_(np.isnan(self.ts.asOf(d)))
+        self.assert_(np.isnan(self.ts.asof(d)))
 
-    def test_merge(self):
+    def test_map(self):
         index, data = common.getMixedTypeDict()
 
         source = Series(data['B'], index=data['C'])
         target = Series(data['C'][:4], index=data['D'][:4])
 
-        merged = target.merge(source)
+        merged = target.map(source)
 
         for k, v in merged.iteritems():
             self.assertEqual(v, source[target[k]])
 
         # input could be a dict
-        merged = target.merge(source.toDict())
+        merged = target.map(source.to_dict())
 
         for k, v in merged.iteritems():
             self.assertEqual(v, source[target[k]])
 
-    def test_merge_int(self):
+    def test_map_int(self):
         left = Series({'a' : 1., 'b' : 2., 'c' : 3., 'd' : 4})
         right = Series({1 : 11, 2 : 22, 3 : 33})
 
         self.assert_(left.dtype == np.float_)
         self.assert_(issubclass(right.dtype.type, np.integer))
 
-        merged = left.merge(right)
+        merged = left.map(right)
         self.assert_(merged.dtype == np.float_)
         self.assert_(isnull(merged['d']))
         self.assert_(not isnull(merged['c']))
@@ -939,11 +944,8 @@ class TestSeries(unittest.TestCase):
         assert_series_equal(renamed, renamed2)
 
     def test_preserveRefs(self):
-        sl = self.ts[5:10]
         seq = self.ts[[5,10,15]]
-        sl[4] = np.NaN
         seq[1] = np.NaN
-        self.assertFalse(np.isnan(self.ts[9]))
         self.assertFalse(np.isnan(self.ts[10]))
 
     def test_ne(self):
diff --git a/pandas/tests/test_sparse.py b/pandas/tests/test_sparse.py
index 9a5093e15..db726c170 100644
--- a/pandas/tests/test_sparse.py
+++ b/pandas/tests/test_sparse.py
@@ -660,7 +660,7 @@ class TestSparseDataFrame(TestCase):
         # construct from nested dict
         data = {}
         for c, s in self.frame.iteritems():
-            data[c] = s.toDict()
+            data[c] = s.to_dict()
 
         sdf = SparseDataFrame(data)
         assert_sp_frame_equal(sdf, self.frame)
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index fe88331ab..ca2182254 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -145,6 +145,13 @@ class cache_writable(_cache_readonly):
                                        cachename=self.cachename,
                                        resetlist=self.resetlist)
 
+def deprecate(name, alternative):
+    alt_name = alternative.func_name
+    def wrapper(*args, **kwargs):
+        warnings.warn("%s is deprecated. Use %s instead" % (name, alt_name),
+                      FutureWarning)
+        return alternative(*args, **kwargs)
+    return wrapper
 
 if __name__ == "__main__":
 ### Tests resettable_cache ----------------------------------------------------
