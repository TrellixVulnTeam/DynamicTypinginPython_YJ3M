commit 6fd65acdab8b029bac6128b7e449492851fe302e
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Nov 20 16:10:50 2009 +0000

    merging latest developments, in particular LongPanel, WidePanel
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@35 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index 2567bd3ea..ebed5f531 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -29,7 +29,7 @@ def to_datetime(input):
         return input
     try:
         return parser.parse(input)
-    except:
+    except Exception:
         return input
 
 def normalize_date(dt):
@@ -41,45 +41,48 @@ def normalize_date(dt):
 class DateOffset(object):
     """
     Standard kind of date increment used for a date range.
-    
-    Works exactly like relativedelta in terms of the keyword args you pass in,
-    use of the keyword n is discouraged-- you would be better off specifying
-    n in the keywords you use, but regardless it is there for you. n is needed
-    for DateOffset subclasses.
-    
-    DateOffets work as follows.  Each offset specify a set of dates that 
-    conform to the DateOffset.  For example, Bday defines this set to be the
-    set of dates that are weekdays (M-F).  To test if a date is in the set
-    of a DateOffset dateOffset we can use the onOffset method:
-    dateOffset.onOffset(date).  
-    
-    If a date is not on a valid date, the rollback and rollforward methods can
-    be used to roll the date to the nearest valid date before/after the date.
-    
-    DateOffsets can be created to move dates forward a given number of valid
-    dates.  For example, Bday(2) can be added to a date to move it two 
-    business days forward.  If the date does not start on a valid date, first
-    it is moved to a valid date.  Thus psedo code is:
-    
+
+    Works exactly like relativedelta in terms of the keyword args you
+    pass in, use of the keyword n is discouraged-- you would be better
+    off specifying n in the keywords you use, but regardless it is
+    there for you. n is needed for DateOffset subclasses.
+
+    DateOffets work as follows.  Each offset specify a set of dates
+    that conform to the DateOffset.  For example, Bday defines this
+    set to be the set of dates that are weekdays (M-F).  To test if a
+    date is in the set of a DateOffset dateOffset we can use the
+    onOffset method: dateOffset.onOffset(date).
+
+    If a date is not on a valid date, the rollback and rollforward
+    methods can be used to roll the date to the nearest valid date
+    before/after the date.
+
+    DateOffsets can be created to move dates forward a given number of
+    valid dates.  For example, Bday(2) can be added to a date to move
+    it two business days forward.  If the date does not start on a
+    valid date, first it is moved to a valid date.  Thus psedo code
+    is:
+
     def __add__(date):
       date = rollback(date) # does nothing is date is valid
       return date + <n number of periods>
 
-    When a date offset is created for a negitive number of periods, the date
-    is first rolled forward.  The psedo code is:
-    
+    When a date offset is created for a negitive number of periods,
+    the date is first rolled forward.  The pseudo code is:
+
     def __add__(date):
       date = rollforward(date) # does nothing is date is valid
-      return date + <n number of periods>      
-      
-    Zero presents a problem.  Should it roll forward or back?  We arbitrarily 
-    have it rollforward:
-    
+      return date + <n number of periods>
+
+    Zero presents a problem.  Should it roll forward or back?  We
+    arbitrarily have it rollforward:
+
     date + BDay(0) == BDay.rollforward(date)
-    
+
     Since 0 is a bit weird, we suggest avoiding its use.
-    """    
-    # For some offsets, want to drop the time information off the first date
+    """
+    # For some offsets, want to drop the time information off the
+    # first date
     _normalizeFirst = False
     def __init__(self, n = 1, **kwds):
         self.n = int(n)
@@ -114,7 +117,8 @@ class DateOffset(object):
         exclude = set(['n', 'inc'])
         attrs = []
         for attr in self.__dict__:
-            if attr == 'kwds' and len(self.kwds) == 0:
+            if ((attr == 'kwds' and len(self.kwds) == 0)
+                or attr.startswith('_')):
                 continue
             if attr not in exclude:
                 attrs.append('='.join((attr, repr(getattr(self, attr)))))
@@ -124,8 +128,8 @@ class DateOffset(object):
         out += '>'
         return out
 
-    def __eq__(self, other):        
-        return self._params() == other._params() 
+    def __eq__(self, other):
+        return self._params() == other._params()
 
     def __hash__(self):
         return hash(self._params())
@@ -134,7 +138,7 @@ class DateOffset(object):
         return self.apply(other)
 
     def __add__(self, other):
-        return self.apply(other)        
+        return self.apply(other)
 
     def __radd__(self, other):
         return self.__add__(other)
@@ -150,10 +154,10 @@ class DateOffset(object):
 
     def __rmul__(self, someInt):
         return self.__class__(n = someInt * self.n, **self.kwds)
-    
+
     def __neg__(self):
         return self.__class__(-self.n, **self.kwds)
-    
+
     def __contains__(self, other):
         return self.onOffset(other)
 
@@ -161,7 +165,7 @@ class DateOffset(object):
         """Roll provided date backward to next offset only if not on offset"""
         if self._normalizeFirst:
             someDate = normalize_date(someDate)
-        
+
         if not self.onOffset(someDate):
             someDate = someDate - self.__class__(1, **self.kwds)
         return someDate
@@ -174,12 +178,12 @@ class DateOffset(object):
         if not self.onOffset(someDate):
             someDate = someDate + self.__class__(1, **self.kwds)
         return someDate
-        
+
     @classmethod
     def onOffset(cls, someDate):
-        # Default (slow) method for determining if some date is a member of 
-        # the DateRange generated by this offset. Subclasses may have this
-        # re-implemented in a nicer way. 
+        # Default (slow) method for determining if some date is a
+        # member of the DateRange generated by this offset. Subclasses
+        # may have this re-implemented in a nicer way.
         obj = cls()
         return someDate == ((someDate + obj) - obj)
 
@@ -190,21 +194,56 @@ class BDay(DateOffset):
     """
     _normalizeFirst = True
     _outputName = 'BusinessDay'
+    def __init__(self, n=1, **kwds):
+        self.n = int(n)
+        self.kwds = kwds
+        self.offset = kwds.get('offset', timedelta(0))
+        self.normalize = kwds.get('normalize', True)
+
+    def __repr__(self):
+        className = getattr(self, '_outputName', self.__class__.__name__)
+        exclude = set(['n', 'inc'])
+        attrs = []
+
+        if self.offset:
+            attrs = ['offset=%s' % self.offset]
+
+        out = '<%s ' % self.n + className + ('s' if abs(self.n) != 1 else '')
+        if attrs:
+            out += ': ' + ', '.join(attrs)
+        out += '>'
+        return out
 
     def isAnchored(self):
         return (self.n == 1)
 
     def apply(self, other):
-        if not isinstance(other, datetime):
-            raise Exception('Only know how to add business day to a datetime!')
-        n = self.n
-        if n == 0 and other.weekday() > 4:
-            n = 1
-        while n != 0:
-            other = other + timedelta(n/abs(n))
-            if other.weekday() < 5: n -= n/abs(n)
-        return datetime(other.year, other.month, other.day)
+        if isinstance(other, datetime):
+            n = self.n
+            if n == 0 and other.weekday() > 4:
+                n = 1
+
+            result = other
 
+            while n != 0:
+                result = result + timedelta(n/abs(n))
+                if result.weekday() < 5:
+                    n -= n/abs(n)
+
+            if self.normalize:
+                result = datetime(result.year, result.month, result.day)
+
+            if self.offset:
+                result = result + self.offset
+
+            return result
+
+        elif isinstance(other, (timedelta, Tick)):
+            return BDay(self.n, offset=self.offset + other,
+                        normalize=self.normalize)
+        else:
+            raise Exception('Only know how to combine business day with '
+                            'datetime or timedelta!')
     @classmethod
     def onOffset(cls, someDate):
         return someDate.weekday() < 5
@@ -227,9 +266,10 @@ class MonthEnd(DateOffset):
 
     @classmethod
     def onOffset(cls, someDate):
-        __junk, nDaysInMonth = calendar.monthrange(someDate.year, someDate.month)
+        __junk, nDaysInMonth = calendar.monthrange(someDate.year,
+                                                   someDate.month)
         return someDate.day == nDaysInMonth
-        
+
 class BMonthEnd(DateOffset):
     """DateOffset increments between business EOM dates"""
     _outputName = 'BusinessMonthEnd'
@@ -240,19 +280,19 @@ class BMonthEnd(DateOffset):
 
     def apply(self, other):
         n = self.n
-        
+
         wkday, nDaysInMonth = calendar.monthrange(other.year, other.month)
         lastBDay = nDaysInMonth - max(((wkday + nDaysInMonth - 1) % 7) - 4, 0)
-        
+
         if n > 0 and not other.day >= lastBDay:
-            n = n - 1      
+            n = n - 1
         elif n <= 0 and other.day > lastBDay:
             n = n + 1
         other = other + relativedelta(months=n, day=31)
-        
+
         if other.weekday() > 4:
-            other = other - BDay()        
-        return other 
+            other = other - BDay()
+        return other
 
 
 class Week(DateOffset):
@@ -270,21 +310,21 @@ class Week(DateOffset):
     def __init__(self, n=1, **kwds):
         self.n = n
         self.dayOfWeek = kwds.get('dayOfWeek', None)
-        
+
         if self.dayOfWeek is not None:
             if self.dayOfWeek < 0 or self.dayOfWeek > 6:
                 raise Exception('Day must be 0<=day<=6, got %d' % self.dayOfWeek)
-            
+
         self.inc = timedelta(weeks=1)
         self.kwds = kwds
 
     def isAnchored(self):
         return (self.n == 1 and self.dayOfWeek is not None)
-        
+
     def apply(self, other):
         if self.dayOfWeek is None:
             return other + self.n * self.inc
-        
+
         if self.n > 0:
             k = self.n
             otherDay = other.weekday()
@@ -301,7 +341,7 @@ class Week(DateOffset):
             for i in xrange(-k):
                 other = other - self.inc
         return other
-    
+
     def onOffset(self, someDate):
         return someDate.weekday() == self.dayOfWeek
 
@@ -318,65 +358,65 @@ class BQuarterEnd(DateOffset):
     def __init__(self, n=1, **kwds):
         self.n = n
         self.startingMonth = kwds.get('startingMonth', 3)
-        
+
         if self.startingMonth < 1 or self.startingMonth > 3:
-            raise Exception('Start month must be 1<=day<=12, got %d' 
+            raise Exception('Start month must be 1<=day<=12, got %d'
                             % self.startingMonth)
-            
+
         self.offset = BMonthEnd(3)
         self.kwds = kwds
 
     def isAnchored(self):
         return (self.n == 1 and self.startingMonth is not None)
-        
+
     def apply(self, other):
         n = self.n
 
         wkday, nDaysInMonth = calendar.monthrange(other.year, other.month)
         lastBDay = nDaysInMonth - max(((wkday + nDaysInMonth - 1) % 7) - 4, 0)
-        
+
         monthsToGo = 3 - ((other.month - self.startingMonth) % 3)
         if monthsToGo == 3:
             monthsToGo = 0
-        
+
         if n > 0 and not (other.day >= lastBDay and monthsToGo == 0):
-            n = n - 1      
+            n = n - 1
         elif n <= 0 and other.day > lastBDay and monthsToGo == 0:
             n = n + 1
 
         other = other + relativedelta(months=monthsToGo + 3*n, day=31)
-        
+
         if other.weekday() > 4:
             other = other - BDay()
-        
-        return other 
+
+        return other
 
     def onOffset(self, someDate):
         modMonth = (someDate.month - self.startingMonth) % 3
         return BMonthEnd().onOffset(someDate) and modMonth == 0
-        
+
 class BYearEnd(DateOffset):
     """DateOffset increments between business EOM dates"""
     _outputName = 'BusinessYearEnd'
     _normalizeFirst = True
-    
+
     def apply(self, other):
         n = self.n
 
         wkday, nDaysInMonth = calendar.monthrange(other.year, 12)
         lastBDay = nDaysInMonth - max(((wkday + nDaysInMonth - 1) % 7) - 4, 0)
-        
+
         if n > 0 and not (other.month == 12 and other.day >= lastBDay):
-            n = n - 1      
+            n = n - 1
         elif n <= 0 and other.month == 12 and other.day > lastBDay:
             n = n + 1
 
         other = other + relativedelta(years=n, month=12, day=31)
-        
+
         if other.weekday() > 4:
             other = other - BDay()
-        
-        return other                
+
+        return other
 
 
 class YearEnd(DateOffset):
@@ -394,7 +434,7 @@ class YearEnd(DateOffset):
 
     @classmethod
     def onOffset(cls, someDate):
-        return someDate.month == 12 and someDate.day == 31    
+        return someDate.month == 12 and someDate.day == 31
 
 
 class YearBegin(DateOffset):
@@ -409,29 +449,29 @@ class YearBegin(DateOffset):
                 n = n + 1
         other = other + relativedelta(years = n, day=1)
         return other
-    
+
     @classmethod
     def onOffset(cls, someDate):
-        return someDate.month == 1 and someDate.day == 1    
+        return someDate.month == 1 and someDate.day == 1
 
 #-------------------------------------------------------------------------------
 # Ticks
-    
+
 class Tick(DateOffset):
     pass
     
 class Hour(Tick):
     _normalizeFirst = False
     _delta = None
-    _inc = timedelta(60)
-    
+    _inc = timedelta(0, 3600)
+
     @property
     def delta(self):
         if self._delta is None:
             self._delta = self.n * self._inc
-            
+
         return self._delta
-    
+
     def apply(self, other):
         return other + self.delta
 
@@ -439,14 +479,14 @@ class Minute(Tick):
     _normalizeFirst = False
     _delta = None
     _inc = timedelta(0, 60)
-    
+
     @property
     def delta(self):
         if self._delta is None:
             self._delta = self.n * self._inc
-            
+
         return self._delta
-    
+
     def apply(self, other):
         return other + self.delta
 
@@ -454,19 +494,19 @@ class Second(Tick):
     _normalizeFirst = False
     _delta = None
     _inc = timedelta(0, 1)
-    
+
     @property
     def delta(self):
         if self._delta is None:
             self._delta = self.n * self._inc
-            
+
         return self._delta
-    
+
     def apply(self, other):
         return other + self.delta
-    
+
 day = DateOffset()
-bday = BDay()
+bday = BDay(normalize=True)
 businessDay = bday
 monthEnd = MonthEnd()
 yearEnd = YearEnd()
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 8bbe7bbdc..f9b2cd13c 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1,3 +1,7 @@
+# pylint: disable-msg=E1101
+# pylint: disable-msg=E1103
+# pylint: disable-msg=W0212
+
 import operator
 
 from numpy import NaN
@@ -10,6 +14,8 @@ from pandas.core.mixins import Picklable, Groupable
 from pandas.core.series import Series, remove_na
 from pandas.lib.tseries import isnull, notnull
 import pandas.lib.tseries as tseries
+#-------------------------------------------------------------------------------
+# Factory helper methods
 
 def arith_method(func, name):
     def f(self, other):
@@ -39,9 +45,9 @@ class DataFrame(Picklable, Groupable):
 
     Notes
     -----
-    Data contained within is COPIED from input arrays, this is to prevent silly
-    behavior like altering the original arrays and having those changes
-    reflected in the frame.
+    Data contained within is COPIED from input arrays, this is to
+    prevent silly behavior like altering the original arrays and
+    having those changes reflected in the frame.
 
     See also
     --------
@@ -84,7 +90,7 @@ class DataFrame(Picklable, Groupable):
 
     # Alternate constructors
     @classmethod
-    def fromDict(cls, inputDict={}, castFloat=True, **kwds):
+    def fromDict(cls, inputDict=None, castFloat=True, **kwds):
         """
         Convert a two-level tree representation of a series or time series
         to a DataFrame.
@@ -113,34 +119,87 @@ class DataFrame(Picklable, Groupable):
         df1 = DataFrame.fromDict(myDict)
         df2 = DataFrame.fromDict(A=seriesA, B=seriesB)
         """
-        if not hasattr(inputDict, 'iteritems'):
-            raise Exception('Input must be dict or dict-like!')
+        if inputDict is None:
+            inputDict = {}
+        else:
+            if not hasattr(inputDict, 'iteritems'):
+                raise Exception('Input must be dict or dict-like!')
+            inputDict = inputDict.copy()
 
-        inputDict = inputDict.copy()
         inputDict.update(kwds)
 
         if len(inputDict) == 0:
             return DataFrame(index=NULL_INDEX)
+        elif len(inputDict) == 1:
+            index = inputDict.values()[0].keys()
+            if not isinstance(index, Index):
+                index = Index(sorted(index))
 
-        # Get set of indices
-        indices = set([])
-        for key, branch in inputDict.iteritems():
-            indices = indices | set(branch.keys())
-        index = Index(sorted(indices))
+        else:
+            # GET set of indices
+            indices = set([])
+            for key, branch in inputDict.iteritems():
+                indices = indices | set(branch.keys())
+            index = Index(sorted(indices))
 
         columns = {}
         for key, branch in inputDict.iteritems():
-            tmp = [branch.get(i, NaN) for i in index]
+            if isinstance(branch, Series):
+                tmp = branch.reindex(index)
+            else:
+                tmp = [branch.get(i, NaN) for i in index]
+
             try:
                 if castFloat:
                     columns[key] = Series(tmp, dtype=float, index=index)
                 else:
                     columns[key] = Series(tmp, index=index)
-            except:
+            except Exception, e:
                 columns[key] = Series(tmp, index=index)
 
         return DataFrame(data=columns, index=index)
 
+    @classmethod
+    def fromRecords(cls, data, indexField=None):
+        """
+        Convert structured or record ndarray to DataFrame
+
+        Parameters
+        ----------
+        input: NumPy structured array
+
+        Returns
+        -------
+        DataFrame
+        """
+        # Dtype when you have records
+        if data.dtype.type != np.void:
+            raise Exception('Input was not a structured array!')
+
+        columns = data.dtype.names
+        dataDict = dict((k, data[k]) for k in columns)
+
+        if indexField is not None:
+            index = dataDict.pop(indexField)
+        else:
+            index = np.arange(len(data))
+
+        return cls(dataDict, index=index)
+
+    def toRecords(self):
+        """
+        Convert DataFrame to record array. Index will be put in the
+        'index' field of the record array.
+
+        Returns
+        -------
+        recarray
+        """
+        arrays = [self.index] + [self[c] for c in self.cols()]
+        names = ['index'] + list(self.cols())
+
+        return np.rec.fromarrays(arrays, names=names)
+
     @classmethod
     def fromMatrix(cls, mat, colNames, rowNames):
         """
@@ -230,28 +289,31 @@ class DataFrame(Picklable, Groupable):
         """
         Retrieve column or slice from DataFrame
         """
-        if isinstance(item, slice):
-            start, stop = item.start, item.stop
-            start = 0 if start is None else start
-            stop = len(self) if stop is None else stop
-            if start < 0:
-                start += len(self)
-            if stop < 0:
-                stop += len(self)
-
-            dateRange = self.index[start:stop]
-            newColumns = {}
-            for col, series in self.iteritems():
-                newColumns[col] = series[start:stop]
-            return DataFrame(data=newColumns, index=dateRange)
-        elif isinstance(item, np.ndarray):
-            if len(item) != len(self.index):
-                raise Exception('Item wrong length %d instead of %d!' %
-                                (len(item), len(self.index)))
-            newIndex = self.index[item]
-            return self.reindex(newIndex)
-        else:
+        try:
             return self._series[item]
+        except (TypeError, KeyError):
+            if isinstance(item, slice):
+                start, stop = item.start, item.stop
+                start = 0 if start is None else start
+                stop = len(self) if stop is None else stop
+                if start < 0:
+                    start += len(self)
+                if stop < 0:
+                    stop += len(self)
+
+                dateRange = self.index[start:stop]
+                newColumns = {}
+                for col, series in self.iteritems():
+                    newColumns[col] = series[start:stop]
+                return DataFrame(data=newColumns, index=dateRange)
+            elif isinstance(item, np.ndarray):
+                if len(item) != len(self.index):
+                    raise Exception('Item wrong length %d instead of %d!' %
+                                    (len(item), len(self.index)))
+                newIndex = self.index[item]
+                return self.reindex(newIndex)
+            else:
+                raise
 
     def __setitem__(self, key, value):
         """
@@ -278,7 +340,7 @@ class DataFrame(Picklable, Groupable):
                 self._series[key] = Series.fromValue(value, index=self.index)
         except AssertionError:
             raise
-        except:
+        except Exception, e:
             raise Exception('Could not put key, value pair in Frame!')
 
     def __delitem__(self, key):
@@ -347,7 +409,7 @@ class DataFrame(Picklable, Groupable):
         newColumns = {}
         newIndex = self.index
 
-        if self.index is other.index:
+        if self.index.equals(other.index):
             newIndex = self.index
         else:
             newIndex = self.index + other.index
@@ -388,7 +450,7 @@ class DataFrame(Picklable, Groupable):
             if not self:
                 return DataFrame(index=other.index)
 
-            if self.index is other.index:
+            if self.index.equals(other.index):
                 newIndex = self.index
             else:
                 newIndex = self.index + other.index
@@ -441,7 +503,7 @@ class DataFrame(Picklable, Groupable):
 # Public methods
 
     def toCSV(self, path=None, nanRep='', cols=None, inclHeader=True,
-              inclIndex=True):
+              inclIndex=True, verbose=False):
         """
         Write the DataFrame to a CSV file
         """
@@ -470,7 +532,9 @@ class DataFrame(Picklable, Groupable):
             f.write('\n')
         if path is not None:
             f.close()
-        print 'CSV file written successfully: %s' % path
+
+        if verbose:
+            print 'CSV file written successfully: %s' % path
 
     def toDict(self):
         """
@@ -496,7 +560,7 @@ class DataFrame(Picklable, Groupable):
     def toString(self, to_stdout=True, verbose=False, colSpace=15, nanRep=None):
         """Output a tab-separated version of this DataFrame"""
         series = self._series
-        skeys = sorted(self.cols())
+        skeys = sorted(series.keys())
         if len(skeys) == 0 or len(self.index) == 0:
             output = 'Empty DataFrame\n'
             output += self.index.__repr__()
@@ -530,7 +594,7 @@ class DataFrame(Picklable, Groupable):
                                                     max(self.index))
         output += 'Columns:\n'
         series = self._series
-        skeys = sorted(series.keys())
+        skeys = sorted(self.cols())
         space = max([len(str(k)) for k in skeys]) + 4
         for k in skeys:
             out = _pfixed(k, space)
@@ -689,7 +753,7 @@ class DataFrame(Picklable, Groupable):
 
         if specificColumns:
             colSet = set(specificColumns)
-            intersection= set(self.cols()) & colSet
+            intersection = set(self.cols()) & colSet
 
             N = len(intersection)
 
@@ -862,15 +926,9 @@ class DataFrame(Picklable, Groupable):
         values: string or object
             Column name to use for populating new frame's values
         """
-        from itertools import izip
-        tree = {}
-        for i, (idx, col) in enumerate(izip(self[index], self[columns])):
-            if col not in tree:
-                tree[col] = {}
-            branch = tree[col]
-            branch[idx] = self[values][i]
+        from pandas.core.panel import pivot, _slow_pivot
 
-        return self.fromDict(tree)
+        return _slow_pivot(self[index], self[columns], self[values])
 
     def reindex(self, newIndex, fillMethod = None):
         """
@@ -884,7 +942,7 @@ class DataFrame(Picklable, Groupable):
             Method to use for filling holes in reindexed DataFrame
         """
         if newIndex is self.index:
-            return self
+            return self.copy()
 
         if len(newIndex) == 0:
             return DataFrame(index=NULL_INDEX)
@@ -926,7 +984,7 @@ class DataFrame(Picklable, Groupable):
             series = series.view(np.ndarray)
             for type, dest in typeHierarchy:
                 if issubclass(series.dtype.type, type):
-                    new = series[fillVec].astype(dest)
+                    new = series.take(fillVec).astype(dest)
                     new[-mask] = missingValue[dest]
                     newSeries[col] = new
                     break
@@ -1047,6 +1105,12 @@ class DataFrame(Picklable, Groupable):
             results[col] = map(func, series)
         return DataFrame(data=results, index=self.index)
 
+    def tgroupby(self, keyfunc, applyfunc):
+        """
+        Call groupby on transposed frame
+        """
+        return self.T.groupby(keyfunc).aggregate(applyfunc).T
+
     def filterItems(self, items):
         """
         Restrict frame's columns to input set of items.
@@ -1063,29 +1127,6 @@ class DataFrame(Picklable, Groupable):
         data = dict([(r, self[r]) for r in items if r in self])
         return DataFrame(data=data, index=self.index)
 
-    def stack(self, indexCombineFunc= (lambda x, y: str(y.toordinal())+';'+x)):
-        """
-        Converts a DataFrame object with columns [col1, col2, ..., colN] and
-        indices [idx1, ... idxT] into a series with indices [col1:idx1,
-        col1:idx2, ... colN:idxT]
-
-        For doing pooled cross-sectional regressions.
-        """
-        cols = self.cols()
-        mat = self.asMatrix()
-
-        newIndices = {}
-        for i, index in enumerate(self.index):
-            theOrd = str(index.toordinal()) + ';'
-            newIndices[i] = [theOrd + col for col in cols]
-
-        N = len(self.index)
-
-        newIndex = np.concatenate([newIndices[i] for i in xrange(N)])
-        newValues = np.concatenate([mat[i, :] for i in xrange(N)])
-
-        return Series(newValues, index=newIndex)
-
     def sortUp(self, column=None):
         """
         Sort DataFrame in ascending order according to specified column,
@@ -1148,7 +1189,7 @@ class DataFrame(Picklable, Groupable):
 
         Returns
         -------
-        DataFrmae
+        DataFrame
         """
         if not otherFrame:
             return self
@@ -1224,7 +1265,7 @@ class DataFrame(Picklable, Groupable):
             elif col in frame:
                 result[col] = frame[col]
             elif col in otherFrame:
-                result[col]= otherFrame[col]
+                result[col] = otherFrame[col]
             else:
                 raise Exception('Phantom column, be very afraid')
 
@@ -1274,13 +1315,13 @@ class DataFrame(Picklable, Groupable):
 
         return mergedSeries
 
-    def merge(self, otherFrame, on=None):
+    def merge(self, other, on=None):
         """
         Merge DataFrame or DataMatrix with this one on some many-to-one index
 
         Parameters
         ----------
-        otherFrame: DataFrame
+        other: DataFrame
             Index should be similar to one of the columns in this one
         on: string
             Column name to use
@@ -1294,26 +1335,31 @@ class DataFrame(Picklable, Groupable):
         c   1
         d   0
         """
-        if len(otherFrame.index) == 0:
+        if len(other.index) == 0:
             return self
 
         if on not in self:
             raise Exception('%s column not contained in this frame!' % on)
 
-        otherM = otherFrame.asMatrix()
-        indexMap = otherFrame.index.indexMap
+        # Check for column overlap
+        overlap = set(self.cols()) & set(other.cols())
+
+        if any(overlap):
+            raise Exception('Columns overlap: %s' % sorted(overlap))
+
+        fillVec, mask = tseries.getMergeVec(self[on], other.index.indexMap)
 
-        fillVec, mask = tseries.getMergeVec(self[on], indexMap)
+        newSeries = {}
 
-        tmpMatrix = otherM[fillVec]
-        tmpMatrix[-mask] = NaN
+        for col, series in other.iteritems():
+            arr = series.view(ndarray).take(fillVec)
+            arr[-mask] = NaN
 
-        seriesDict = dict((col, tmpMatrix[:, j])
-                           for j, col in enumerate(otherFrame.cols()))
+            newSeries[col] = arr
 
-        filledFrame = DataFrame(data=seriesDict, index=self.index)
+        newSeries.update(self._series)
 
-        return self.leftJoin(filledFrame)
+        return DataFrame(newSeries, index=self.index)
 
     def plot(self, kind='line', **kwds):
         """
@@ -1332,7 +1378,7 @@ class DataFrame(Picklable, Groupable):
         """
         try:
             plot
-        except:
+        except Exception, e:
             from pylab import plot
 
         for col in sorted(self.columns):
@@ -1355,7 +1401,15 @@ class DataFrame(Picklable, Groupable):
         -------
         Series or TimeSeries
         """
-        theCount = np.isfinite(self.values).sum(axis)
+        try:
+            theCount = np.isfinite(self.values).sum(axis)
+        except Exception, e:
+            f = lambda s: notnull(s).sum()
+            if axis == 0:
+                theCount = self.apply(f)
+            elif axis == 1:
+                theCount = self.tapply(f)
+
         if asarray:
             return theCount
         else:
@@ -1402,8 +1456,8 @@ class DataFrame(Picklable, Groupable):
                 y[np.isnan(y)] = 0
             theSum = y.sum(axis)
             theCount = self.count(axis)
-            theSum[theCount==0] = NaN
-        except:
+            theSum[theCount == 0] = NaN
+        except Exception, e:
             if axis == 0:
                 theSum = self.apply(np.sum)
             else:
@@ -1440,8 +1494,8 @@ class DataFrame(Picklable, Groupable):
                 y[np.isnan(y)] = 1
             theProd = y.prod(axis)
             theCount = self.count(axis)
-            theProd[theCount==0] = NaN
-        except:
+            theProd[theCount == 0] = NaN
+        except Exception, e:
             if axis == 0:
                 theProd = self.apply(np.prod)
             else:
@@ -1464,8 +1518,6 @@ class DataFrame(Picklable, Groupable):
         ----------
         axis: {0, 1}
             0 for row-wise, 1 for column-wise
-        asarray: boolean, default False
-            Choose to return as ndarray or have index attached
 
         Returns
         -------
@@ -1481,8 +1533,6 @@ class DataFrame(Picklable, Groupable):
         ----------
         axis: {0, 1}
             0 for row-wise, 1 for column-wise
-        asarray: boolean, default False
-            Choose to return as ndarray or have index attached
 
         Returns
         -------
@@ -1497,6 +1547,82 @@ class DataFrame(Picklable, Groupable):
         else:
             raise Exception('Must have 0<= axis <= 1')
 
+    def min(self, axis=0):
+        """
+        Return array or Series of minimums over requested axis.
+
+        Parameters
+        ----------
+        axis: {0, 1}
+            0 for row-wise, 1 for column-wise
+
+        Returns
+        -------
+        Series or TimeSeries
+        """
+        if axis == 0:
+            med = [np.min(remove_na(self[col])) for col in self.columns]
+            return Series(med, index=self.columns)
+        elif axis == 1:
+            med = [np.min(remove_na(self.getXS(k))) for k in self.index]
+            return Series(med, index=self.index)
+        else:
+            raise Exception('Must have 0<= axis <= 1')
+
+    def max(self, axis=0):
+        """
+        Return array or Series of maximums over requested axis.
+
+        Parameters
+        ----------
+        axis: {0, 1}
+            0 for row-wise, 1 for column-wise
+
+        Returns
+        -------
+        Series or TimeSeries
+        """
+        if axis == 0:
+            med = [np.max(remove_na(self[col])) for col in self.columns]
+            return Series(med, index=self.columns)
+        elif axis == 1:
+            med = [np.max(remove_na(self.getXS(k))) for k in self.index]
+            return Series(med, index=self.index)
+        else:
+            raise Exception('Must have 0<= axis <= 1')
+
+    def mad(self, axis=0, asarray=False):
+        """
+        Return array or Series of mean absolute deviation over
+        requested axis.
+
+        Parameters
+        ----------
+        axis: {0, 1}
+            0 for row-wise, 1 for column-wise
+        asarray: boolean, default False
+            Choose to return as ndarray or have index attached
+
+        Returns
+        -------
+        Series or TimeSeries
+        """
+        if axis == 0:
+            demeaned = self-self.mean(axis=axis)
+        else:
+            demeaned = (self.T-self.mean(axis=axis)).T
+        y = np.array(demeaned.values, subok=True)
+        if not issubclass(y.dtype.type, np.int_):
+            y[np.isnan(y)] = 0
+
+        if asarray:
+            return np.sum(np.abs(y), axis)
+
+        if axis == 0:
+            return Series(np.sum(np.abs(y), axis), self.cols())
+        else:
+            return Series(np.sum(np.abs(y), axis), self.index)
+
     def var(self, axis=0, asarray=False):
         """
         Return array or Series of unbiased variance over requested axis.
@@ -1600,6 +1726,21 @@ class DataFrame(Picklable, Groupable):
         """
         raise Exception('Not implemented yet!')
 
+    def _withColumns(self, newCols):
+        """
+        Utility method, force values matrix to have particular columns
+        Can make this as cute as we like
+        """
+        if len(newCols) == 0:
+            return DataFrame(index=self.index)
+
+        newFrame = self.filterItems(newCols)
+
+        for col in newCols:
+            if col not in newFrame:
+                newFrame[col] = NaN
+
+        return newFrame
 def _pfixed(s, space, nanRep=None):
     if isinstance(s, float):
         fstring = '%-' + str(space-4) + 'g'
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index ba677a012..50315fa77 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -100,7 +100,13 @@ class GroupBy(object):
         ------
         Sequence of (groupName, subsetted object) for each group
         """
-        for groupName, groupList in self.groups.iteritems():
+        try:
+            groupNames = sorted(self.groups)
+        except Exception, e:
+            groupNames = self.groups.keys()
+
+        for groupName in groupNames:
+            groupList = self.groups[groupName]
             yield groupName, self.getGroup(groupList)
 
     def aggregate(self, func):
@@ -115,6 +121,8 @@ class GroupBy(object):
     def apply(self, func):
         return self.transform(func)
 
+    def __getitem__(self, key):
+        return self.getGroup(self.groups[key])
 
 class SeriesGroupBy(GroupBy):
 
@@ -156,7 +164,7 @@ class SeriesGroupBy(GroupBy):
             try:
                 result = groupby(self.obj.index, self.obj,
                                  self.grouper, applyfunc)
-            except:
+            except Exception:
                 result = {}
                 theUnion = set([])
                 for groupName, groupList in self.groups.iteritems():
@@ -219,7 +227,6 @@ class SeriesGroupBy(GroupBy):
 
         return Series.fromDict(allSeries)
 
-
 class DataFrameGroupBy(GroupBy):
     def __init__(self, obj, grouper):
         self.obj = obj
@@ -378,4 +385,3 @@ class DataMatrixGroupBy(DataFrameGroupBy):
             allSeries.update(frame._series)
 
         return DataMatrix(data = allSeries).T
-
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 2367c152f..ccb71b5ae 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1,6 +1,15 @@
 import numpy as np
 from pandas.lib.tdates import isAllDates
 from pandas.lib.tseries import map_indices
+def _indexOp(opname):
+    """
+    Wrapper function for Series arithmetic operations, to avoid
+    code duplication.
+    """
+    def wrapper(self, other):
+        func = getattr(self.view(np.ndarray), opname)
+        return func(other)
+    return wrapper
 
 
 class Index(np.ndarray):
@@ -27,16 +36,29 @@ class Index(np.ndarray):
         if self.ndim == 0:
             return self.item()
 
-        if len(self) > 0:
+        # New instance creation
+        if obj is None:
             self.indexMap = map_indices(self)
+            self._allDates = isAllDates(self)
 
-            if hasattr(obj, '_allDates'):
-                self._allDates = obj._allDates
-            else:
-                self._allDates = isAllDates(self)
+        # New from template / slicing
+        elif isinstance(obj, type(self)) and len(self) != len(obj.indexMap):
+            self.indexMap = map_indices(self)
+            self._allDates = isAllDates(self)
+
+        # View casting
         else:
-            self.indexMap = {}
-            self._allDates = False
+            self.indexMap = getattr(obj, 'indexMap', map_indices(self))
+            self._allDates = getattr(obj, '_allDates', isAllDates(self))
+
+        self._checkForDuplicates()
+
+    def _checkForDuplicates(self):
+        if len(self.indexMap) < len(self):
+            raise Exception('Index cannot contain duplicate values!')
+
+    def __iter__(self):
+        return iter(self.view(np.ndarray))
 
     def __setstate__(self,state):
         """Necessary for making this object picklable"""
@@ -59,11 +81,10 @@ class Index(np.ndarray):
 
     def __getitem__(self, key):
         """Override numpy.ndarray's __getitem__ method to work as desired"""
-        result = self.view(np.ndarray)[key]
-        if isinstance(result, np.ndarray):
-            return Index(result)
+        if np.isscalar(key):
+            return np.ndarray.__getitem__(self, key)
         else:
-            return result
+            return Index(self.view(np.ndarray)[key])
 
     def equals(self, other):
         """
@@ -78,15 +99,11 @@ class Index(np.ndarray):
         if not isinstance(other, Index):
             return False
 
-        if len(self) != len(other):
-            return False
-
-        return self._md5 == other._md5
+        return np.array_equal(self, other)
 
     def _computeMD5(self):
         import hashlib
-        m = hashlib.md5(self.tostring())
-        return m.hexdigest()
+        return hashlib.md5(self.data).hexdigest()
 
     @property
     def _md5(self):
@@ -113,12 +130,21 @@ class Index(np.ndarray):
     def sort(self, *args, **kwargs):
         raise Exception('Tried to sort an Index object, too dangerous to be OK!')
 
+    def argsort(self, *args, **kwargs):
+        return self.view(np.ndarray).argsort(*args, **kwargs)
+
     def __add__(self, other):
         if isinstance(other, Index):
             return self.union(other)
         else:
             return np.ndarray.__add__(self, other)
 
+    __eq__ = _indexOp('__eq__')
+    __lt__ = _indexOp('__lt__')
+    __gt__ = _indexOp('__gt__')
+    __le__ = _indexOp('__le__')
+    __ge__ = _indexOp('__ge__')
+
     def union(self, other):
         """
         Form the union of two Index objects and sorts if possible
@@ -136,12 +162,18 @@ class Index(np.ndarray):
 
         if other is self:
             return self
-        newElts = filter(lambda x: x not in self.indexMap, other)
+
+        if isinstance(other, Index):
+            if self.equals(other):
+                return self
+
+        f = self.indexMap.__contains__
+        newElts = [x for x in other if not f(x)]
         if len(newElts) > 0:
             newSeq = np.concatenate((self, newElts))
             try:
                 newSeq = np.unique(newSeq)
-            except:
+            except Exception, e:
                 # Not sortable / multiple types
                 pass
             return Index(newSeq)
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index f8cd1d9e4..8e4655e24 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -1,7 +1,10 @@
+# pylint: disable-msg=E1101
+# pylint: disable-msg=E1103
+# pylint: disable-msg=W0212
+# pylint: disable-msg=W0231
 from cStringIO import StringIO
 
-from numpy import NaN
-from numpy.lib.format import write_array, read_array
+from numpy import isfinite, NaN
 import numpy as np
 
 from pandas.core.datetools import DateOffset
@@ -260,8 +263,6 @@ class DataMatrix(DataFrame):
         index = Index(rowNames)
         colIndex = Index(colNames)
 
-        idxMap = colIndex.indexMap
-
         return DataMatrix(mat, index=index, columns=colIndex)
 
     @classmethod
@@ -315,7 +316,7 @@ class DataMatrix(DataFrame):
 # Outputting
 
     def toCSV(self, path=None, nanRep='', writeMode='wb', index=True,
-              header=True, cols=None):
+              header=True, cols=None, verbose=False):
         """
         Write the DataMatrix to a CSV file
 
@@ -360,10 +361,11 @@ class DataMatrix(DataFrame):
             f.write('\n')
         if path is not None:
             f.close()
-        print 'CSV file written successfully: %s' % path
 
-    def toString(self, to_stdout=True, verbose=False,
-                 colSpace=15, formatters=None):
+        if verbose:
+            print 'CSV file written successfully: %s' % path
+
+    def toString(self, to_stdout=True, verbose=False, colSpace=15):
         """
         Output a tab-separated version of this DataMatrix
         """
@@ -371,9 +373,6 @@ class DataMatrix(DataFrame):
 
         output = StringIO()
 
-        if formatters is not None:
-            return self._toStringFormatted(formatters)
-
         mat = self.values
         cols = self.columns
         jinds = range(len(cols))
@@ -433,12 +432,12 @@ class DataMatrix(DataFrame):
             output += '\n'
 
         output += 'Data columns:\n'
-        space = max([len(str(k)) for k in self.columns]) + 4
+        space = max([len(str(k)) for k in self.cols()]) + 4
 
         isObjects = False
         try:
             counts = isfinite(self.values).sum(0)
-        except:
+        except Exception, e:
             counts = np.repeat(self.values.shape[0], len(self.columns))
             isObjects = True
 
@@ -551,6 +550,7 @@ class DataMatrix(DataFrame):
         return mycopy
 
     def __repr__(self):
+        """Return a string representation for a particular DataMatrix"""
         if self.values is None or len(self.columns) == 0:
             output = 'Empty DataMatrix\nIndex: %s' % repr(self.index)
         elif 0 < len(self.index) < 1000 and self.values.shape[1] < 10:
@@ -641,7 +641,7 @@ class DataMatrix(DataFrame):
         else:
             try:
                 value = np.repeat(value, len(self.index))
-            except:
+            except Exception, e:
                 raise Exception('Could not put %s in the matrix!' % value)
 
         if value.dtype not in self._dataTypes:
@@ -667,7 +667,10 @@ class DataMatrix(DataFrame):
                 self.values = value.reshape((len(value), 1))
                 self.columns = Index([key])
             else:
-                loc = bisect.bisect_right(self.columns, key)
+                try:
+                    loc = bisect.bisect_right(self.columns, key)
+                except TypeError:
+                    loc = len(self.columns)
                 if loc == self.values.shape[1]:
                     newValues = np.c_[self.values, value]
                     newColumns = Index(np.concatenate((self.columns, [key])))
@@ -695,7 +698,11 @@ class DataMatrix(DataFrame):
                 self.values = value.reshape((len(value), 1)).astype(np.float)
                 self.columns = Index([key])
             else:
-                loc = bisect.bisect_right(self.columns, key)
+                try:
+                    loc = bisect.bisect_right(self.columns, key)
+                except TypeError:
+                    loc = len(self.columns)
+
                 if loc == self.values.shape[1]:
                     newValues = np.c_[self.values, value]
                     newColumns = Index(np.concatenate((self.columns, [key])))
@@ -817,7 +824,7 @@ class DataMatrix(DataFrame):
 
         Could probably deal with some Cython action in here at some point
         """
-        if self.index is other.index:
+        if self.index.equals(other.index):
             newIndex = self.index
             myReindex = self
             hisReindex = other
@@ -834,7 +841,7 @@ class DataMatrix(DataFrame):
             return self * NaN
 
         myValues = myReindex.values
-        if self.columns is other.columns:
+        if self.columns.equals(other.columns):
             newCols = self.columns
             commonCols = self.columns
         else:
@@ -865,7 +872,7 @@ class DataMatrix(DataFrame):
         newCols = self.columns
         if self.index._allDates and other.index._allDates:
             # Operate row-wise
-            if self.index is other.index:
+            if self.index.equals(other.index):
                 newIndex = self.index
             else:
                 newIndex = self.index + other.index
@@ -918,7 +925,7 @@ class DataMatrix(DataFrame):
             newCols = self.columns
             try:
                 resultMatrix = func(self.values, other)
-            except:
+            except Exception, e:
                 raise Exception('Bad operator value: %s' % other)
 
         # TODO: deal with objects
@@ -979,7 +986,7 @@ class DataMatrix(DataFrame):
         asarray: boolean, default False
             Choose to return as ndarray or have index attached
         """
-        y = array(self.values, subok=True)
+        y = np.array(self.values, subok=True)
         if not issubclass(y.dtype.type, np.int_):
             y[np.isnan(self.values)] = 0
         theSum = y.cumsum(axis)
@@ -1004,8 +1011,6 @@ class DataMatrix(DataFrame):
         -------
         DataMatrix with rows containing any NaN values deleted
         """
-        T, N = self.values.shape
-
         if specificColumns:
             theCount = self.filterItems(specificColumns).count(axis=1,
                                                                asarray=True)
@@ -1207,7 +1212,7 @@ class DataMatrix(DataFrame):
         loc = self.index.indexMap[key]
 
         if subset:
-            subset = np.unique(subset)
+            subset = sorted(set(subset))
             indexer = [self.columns.indexMap[col] for col in subset]
             theSlice = self.values[loc, indexer].copy()
             xsIndex = subset
@@ -1253,7 +1258,7 @@ class DataMatrix(DataFrame):
 
         fillVec, mask = tseries.getMergeVec(self[on], indexMap)
 
-        tmpMatrix = otherM[fillVec]
+        tmpMatrix = otherM.take(fillVec, axis=0)
         tmpMatrix[-mask] = NaN
 
         seriesDict = dict((col, tmpMatrix[:, j])
@@ -1263,9 +1268,8 @@ class DataMatrix(DataFrame):
             objects = otherFrame.objects
 
             objM = objects.asMatrix()
-            cols = objects.columns
 
-            tmpMat = objM[fillVec]
+            tmpMat = objM.take(fillVec, axis=0)
             tmpMat[-mask] = NaN
             objDict = dict((col, tmpMat[:, j])
                            for j, col in enumerate(objects.columns))
@@ -1292,7 +1296,7 @@ class DataMatrix(DataFrame):
         DataMatrix
         """
         if newIndex is self.index:
-            return self
+            return self.copy()
 
         if len(newIndex) == 0:
             return DataMatrix(index=NULL_INDEX)
@@ -1318,7 +1322,7 @@ class DataMatrix(DataFrame):
         fillVec, mask = tseries.getFillVec(self.index, newIndex, oldMap,
                                            newMap, fillMethod)
 
-        tmpMatrix = selfM[fillVec]
+        tmpMatrix = selfM.take(fillVec, axis=0)
         tmpMatrix[-mask] = NaN
 
         if self.objects is not None and len(self.objects.columns) > 0:
@@ -1416,7 +1420,8 @@ class DataMatrix(DataFrame):
                               columns=self.columns, objects=self.objects)
         elif isinstance(results, dict):
             if isinstance(results.values()[0], np.ndarray):
-                return DataMatrix(results, objects=self.objects)
+                return DataMatrix(results, index=self.index,
+                                  objects=self.objects)
             else:
                 return Series.fromDict(results)
         else:
@@ -1445,7 +1450,7 @@ class DataMatrix(DataFrame):
         results = npfunc(self.values)
         try:
             results = results.astype(self.values.dtype)
-        except:
+        except Exception, e:
             return DataFrame.fromMatrix(results, self.columns, self.index)
         return DataMatrix(data=results, index=self.index, columns=self.columns)
 
@@ -1488,6 +1493,27 @@ class DataMatrix(DataFrame):
         newCols = Index([c for c in self.columns if arg in c])
         return self._withColumns(newCols)
 
+    def append(self, otherFrame):
+        if not otherFrame:
+            return self
+        if not self:
+            return otherFrame
+        if (isinstance(otherFrame, DataMatrix) and
+            list(self.columns) == list(otherFrame.columns)):
+
+            idx = Index(np.concatenate([self.index, otherFrame.index]))
+            mat = np.vstack((self.values, otherFrame.values))
+            dm = DataMatrix(mat, idx, self.columns)
+            if otherFrame.objects is None:
+                dm.objects = self.objects
+            elif self.objects is None:
+                dm.objects = otherFrame.objects
+            else:
+                dm.objects = self.objects.append(otherFrame.objects)
+            return dm
+        else:
+            return super(DataMatrix, self).append(otherFrame)
+
     def combineFirst(self, otherFrame):
         """
         Combine two DataFrame / DataMatrix objects and default to value
@@ -1567,8 +1593,8 @@ class DataMatrix(DataFrame):
         result = {}
         for col in unionCols:
             if col in frame and col in otherFrame:
-                series = frame[col].view(ndarray)
-                otherSeries = otherFrame[col].view(ndarray)
+                series = frame[col].view(np.ndarray)
+                otherSeries = otherFrame[col].view(np.ndarray)
                 sok = np.isfinite(series)
                 ook = np.isfinite(otherSeries)
 
@@ -1578,7 +1604,7 @@ class DataMatrix(DataFrame):
             elif col in frame:
                 result[col] = frame[col]
             elif col in otherFrame:
-                result[col]= otherFrame[col]
+                result[col] = otherFrame[col]
             else:
                 raise Exception('Phantom column, be very afraid')
 
@@ -1614,7 +1640,7 @@ class DataMatrix(DataFrame):
 
         return DataMatrix.fromDict(mergedSeries)
 
-    def leftJoin(self, *frames, **kwds):
+    def leftJoin(self, *frames):
         """
         Insert columns of input DataFrames / dicts into this one.
 
@@ -1643,7 +1669,6 @@ class DataMatrix(DataFrame):
                 raise Exception('Overlapping columns!')
             unionCols |= cols
 
-        newColumns = Index(sorted(unionCols))
         seriesDict = self._series
 
         for frame in frames:
@@ -1651,25 +1676,3 @@ class DataMatrix(DataFrame):
             seriesDict.update(frame._series)
 
         return DataMatrix(seriesDict, index=self.index)
-
-    def append(self, otherFrame):
-        if not otherFrame:
-            return self
-        if not self:
-            return otherFrame
-        if (isinstance(otherFrame, DataMatrix) and
-            list(self.columns) == list(otherFrame.columns)):
-            #if len(self.index.diff(otherFrame.index)) != len(self.index):
-            #    raise ValueError('Index cannot overlap')
-            idx = Index(np.concatenate([self.index, otherFrame.index]))
-            mat = np.vstack((self.values, otherFrame.values))
-            dm = DataMatrix(mat, idx, self.columns)
-            if otherFrame.objects is None:
-                dm.objects = self.objects
-            elif self.objects is None:
-                dm.objects = otherFrame.objects
-            else:
-                dm.objects = self.objects.append(otherFrame.objects)
-            return dm
-        else:
-            return super(DataMatrix, self).append(otherFrame)
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index e05ec9d21..7cb2c20d2 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1,11 +1,41 @@
 """
 Contains data structures designed for manipulating panel (3-dimensional) data
 """
+# pylint: disable-msg=E1103
+# pylint: disable-msg=W0231
+# pylint: disable-msg=W0212
+# pylint: disable-msg=W0621
 
+from cStringIO import StringIO
+from functools import partial
+import operator
+
+import numpy as np
+from numpy.lib.format import write_array, read_array
+
+from pandas.core.groupby import GroupBy
 from pandas.core.index import Index
-from pandas.core.frame import _pfixed
+from pandas.core.frame import DataFrame
 from pandas.core.matrix import DataMatrix
 
+class PanelError(Exception):
+    pass
+
+
+def _pickle(arr):
+    "Render text representation of array"
+
+    io = StringIO()
+    write_array(io, arr)
+
+    return io.getvalue()
+
+
+def _interpret(s):
+    "Read text representation of ndarray"
+    arr = read_array(StringIO(s))
+    return arr
+
 class Panel(object):
     """
     Abstract superclass for LongPanel and WidePanel data structures
@@ -15,14 +45,11 @@ class Panel(object):
     _minor_axis = None
     _values = None
 
-    def __init__(self, *args, **kwargs):
-        raise NotImplementedError()
-    
     def __repr__(self):
         class_name = str(self.__class__)
 
         I, N, K = len(self.items), len(self.major_axis), len(self.minor_axis)
-        
+
         dims = 'Dimensions: %d (items) x %d (major) x %d (minor)' % (I, N, K)
 
         major = 'Major axis: %s to %s' % (self.major_axis[0],
@@ -30,11 +57,11 @@ class Panel(object):
 
         minor = 'Minor axis: %s to %s' % (self.minor_axis[0],
                                           self.minor_axis[-1])
-        
-        items = 'Items: %s to %s' % (self.items[0], self.items[-1]) 
-        
-        return ('%(class_name)s\n%(dims)s\n%(items)s\n'
-                '%(major)s\n%(minor)s' % locals())
+
+        items = 'Items: %s to %s' % (self.items[0], self.items[-1])
+
+        return '%s\n%s\n%s\n%s\n%s' % (class_name, dims,
+                                       items, major, minor)
 
     def _get_items(self):
         return self._items
@@ -44,7 +71,7 @@ class Panel(object):
             items = Index(items)
 
         self._items = items
-        
+
     items = property(fget=_get_items, fset=_set_items)
 
     def _get_major_axis(self):
@@ -55,7 +82,7 @@ class Panel(object):
             major_axis = Index(major_axis)
 
         self._major_axis = major_axis
-        
+
     major_axis = property(fget=_get_major_axis, fset=_set_major_axis)
 
     def _get_minor_axis(self):
@@ -66,7 +93,7 @@ class Panel(object):
             minor_axis = Index(minor_axis)
 
         self._minor_axis = minor_axis
-        
+
     minor_axis = property(fget=_get_minor_axis, fset=_set_minor_axis)
 
     def _get_values(self):
@@ -74,16 +101,23 @@ class Panel(object):
 
     def _set_values(self, values):
         if not values.flags.contiguous:
-            raise Exception('Values must be C-contiguous!')
+            values = values.copy()
 
         self._values = values
-        
+
     values = property(fget=_get_values, fset=_set_values)
 
     @property
     def dims(self):
         return len(self.items), len(self.major_axis), len(self.minor_axis)
-    
+
+_WIDE_AXIS_NUMBERS = {
+    'items' : 0,
+    'major' : 1,
+    'minor' : 2
+}
+_WIDE_AXIS_NAMES = dict((v, k) for k, v in _WIDE_AXIS_NUMBERS.iteritems())
+
 
 class WidePanel(Panel):
     """
@@ -98,22 +132,57 @@ class WidePanel(Panel):
     """
     def __init__(self, values, items, major_axis, minor_axis):
         self.items = items
-        self.values = values
         self.major_axis = major_axis
         self.minor_axis = minor_axis
-    
-    def __getitem__(self, key):
-        loc = self.items.indexMap[key]
 
-        mat = self.values[loc]
+        self.values = values
+
+    @classmethod
+    def _wide_axis_number(cls, axis):
+        if axis in (0, 1, 2):
+            return axis
+        else:
+            return _WIDE_AXIS_NUMBERS[axis]
+
+    @classmethod
+    def _wide_axis_name(cls, axis):
+        if axis in _WIDE_AXIS_NUMBERS:
+            return axis
+        else:
+            return _WIDE_AXIS_NAMES[axis]
+
+    def _get_axis(self, axis):
+        results = {
+            0 : self.items,
+            1 : self.major_axis,
+            2 : self.minor_axis
+        }
+
+        return results[self._wide_axis_number(axis)]
+
+    def _get_plane_axes(self, axis):
+        """
+
+        """
+        axis = self._wide_axis_name(axis)
+
+        if axis == 'major':
+            index = self.minor_axis
+            columns = self.items
+        if axis == 'minor':
+            index = self.major_axis
+            columns = self.items
+        elif axis == 'items':
+            index = self.major_axis
+            columns = self.minor_axis
+
+        return index, columns
 
-        return DataMatrix(mat, index=self.major_axis, columns=self.minor_axis)
-        
     @classmethod
     def fromDict(cls, data, intersect=True):
         """
         Construct WidePanel from dict of DataFrame objects
-        
+
         Parameters
         ----------
         data: dict
@@ -128,22 +197,276 @@ class WidePanel(Panel):
         items = Index(sorted(data.keys()))
 
         values = np.array([data[k].values for k in items], dtype=float)
-        
+
         return cls(values, items, index, columns)
-        
+
+    def keys(self):
+        return list(self.items)
+
+    def iteritems(self):
+        for item in self.items:
+            yield item, self[item]
+
+    def _get_values(self):
+        return self._values
+
+    def _set_values(self, values):
+        if not values.flags.contiguous:
+            values = values.copy()
+
+        if self.dims != values.shape:
+            raise PanelError('Values shape %s did not match axes / items %s' %
+                             (values.shape, self.dims))
+
+        self._values = values
+
+    values = property(fget=_get_values, fset=_set_values)
+
+    def __getitem__(self, key):
+        try:
+            loc = self.items.indexMap[key]
+        except KeyError:
+            raise KeyError('%s not contained in panel data items!' % key)
+
+        mat = self.values[loc]
+
+        return DataMatrix(mat, index=self.major_axis, columns=self.minor_axis)
+
+    def __setitem__(self, key, value):
+        """
+        Insert item at end of items for now
+        """
+        _, N, K = self.dims
+
+        # XXX
+        if isinstance(value, LongPanel):
+            if len(value.items) != 1:
+                raise Exception('Input panel must have only one item!')
+
+            value = value.toWide()[value.items[0]]
+
+        if isinstance(value, DataFrame):
+            value = value.reindex(self.major_axis)
+            value = value._withColumns(self.minor_axis)
+
+            mat = value.values.reshape((1, N, K))
+
+        elif np.isscalar(value):
+            mat = np.empty((1, N, K), dtype=float)
+            mat.fill(value)
+
+        self.items = Index(list(self.items) + [key])
+        self.values = np.row_stack((self.values, mat))
+
+    def __getstate__(self):
+        "Returned pickled representation of the panel"
+
+        return (_pickle(self.values),
+                _pickle(self.items),
+                _pickle(self.major_axis),
+                _pickle(self.minor_axis))
+
+    def __setstate__(self, state):
+        "Unpickle the panel"
+        vals, items, major, minor = state
+
+        self.values = _interpret(vals)
+        self.items = _interpret(items)
+        self.major_axis = _interpret(major)
+        self.minor_axis = _interpret(minor)
+
+    def conform(self, frame, axis='items'):
+        """
+        Conform input DataFrame to align with chosen axis pair.
+
+        Parameters
+        ----------
+        frame: DataFrame
+        axis: {'items', 'major', 'minor'}
+            Axis the input corresponds to. E.g., if axis='major', then
+            the frame's columns would be items, and the index would be
+            values of the minor axis
+
+        Returns
+        -------
+        DataFrame (or DataMatrix)
+        """
+        index, columns = self._get_plane_axes(axis)
+
+        return frame.reindex(index)._withColumns(columns)
+
+    def reindex(self, new_index, axis='major', fill_method=None):
+        """
+        Conform
+
+        Parameters
+        ----------
+        new_index: Index or sequence
+        axis: {'items', 'major', 'minor'}
+            Axis to reindex
+        fill_method: {'backfill', 'pad', 'interpolate', None}
+            Method to use for filling holes in reindexed panel
+
+        Returns
+        -------
+        WidePanel (new object)
+        """
+        import pandas.lib.tseries as tseries
+
+        axis_i = self._wide_axis_number(axis)
+        current_axis = self._get_axis(axis)
+
+        if new_index is current_axis:
+            return self.copy()
+
+        if not isinstance(new_index, Index):
+            new_index = Index(new_index)
+
+        if not fill_method:
+            fill_method = ''
+
+        fill_method = fill_method.upper()
+
+        if fill_method not in ['BACKFILL', 'PAD', '']:
+            raise Exception("Don't recognize fill_method: %s" % fill_method)
+
+        indexer, mask = tseries.getFillVec(current_axis, new_index,
+                                           current_axis.indexMap,
+                                           new_index.indexMap, fill_method)
+
+        new_values = self.values.take(indexer, axis=axis_i)
+
+        new_items = self.items
+        new_major = self.major_axis
+        new_minor = self.minor_axis
+
+        if axis_i == 0:
+            new_values[-mask] = np.NaN
+            new_items = new_index
+        elif axis_i == 1:
+            new_values[:, -mask, :] = np.NaN
+            new_major = new_index
+        else:
+            new_values[:, :, -mask] = np.NaN
+            new_minor = new_index
+
+        return WidePanel(new_values, new_items, new_major, new_minor)
+
+    def _combine(self, other, func, axis=0):
+        if isinstance(other, DataFrame):
+            return self._combineFrame(other, func, axis=axis)
+        elif isinstance(other, Panel):
+            return self._combinePanel(other, func)
+        elif np.isscalar(other):
+            pass
+
+    def _combineFrame(self, other, func, axis=0):
+        index, columns = self._get_plane_axes(axis)
+        axis = self._wide_axis_number(axis)
+
+        other = other.reindex(index)._withColumns(columns)
+
+        if axis == 0:
+            newValues = func(self.values, other.values)
+        elif axis == 1:
+            newValues = func(self.values.swapaxes(0, 1), other.values.T)
+            newValues = newValues.swapaxes(0, 1)
+        elif axis == 2:
+            newValues = func(self.values.swapaxes(0, 2), other.values)
+            newValues = newValues.swapaxes(0, 2)
+
+        return WidePanel(newValues, self.items, self.major_axis,
+                         self.minor_axis)
+
+    def _combinePanel(self, other, func):
+        pass
+
+    def add(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.add, axis=axis)
+
+    def subtract(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.sub, axis=axis)
+
+    def multiply(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.mul, axis=axis)
+
+    def divide(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.div, axis=axis)
+
+    def getMajorXS(self, key):
+        """
+        Parameters
+        ----------
+
+        Returns
+        -------
+        DataMatrix: index -> minor axis, columns -> items
+        """
+        try:
+            loc = self.major_axis.indexMap[key]
+        except KeyError:
+            raise KeyError('%s not contained in major axis!' % key)
+
+        mat = np.array(self.values[:, loc, :].T)
+        return DataMatrix(mat, index=self.minor_axis, columns=self.items)
+
+    def getMinorXS(self, key):
+        """
+        Parameters
+        ----------
+
+        Returns
+        -------
+        DataMatrix: index -> major axis, columns -> items
+        """
+        try:
+            loc = self.minor_axis.indexMap[key]
+        except KeyError:
+            raise KeyError('%s not contained in minor axis!' % key)
+
+        mat = np.array(self.values[:, :, loc].T)
+        return DataMatrix(mat, index=self.major_axis, columns=self.items)
+
+    def groupby(self, function, axis='major'):
+        """
+        Parameters
+        ----------
+        function: callable
+            Mapping function for chosen access
+        axis: {'major', 'minor', 'items'}, default 'major'
+
+        Returns
+        -------
+        WidePanelGroupBy
+        """
+        return WidePanelGroupBy(self, function, axis=axis)
+
     def swapaxes(self):
         """
         Switch minor and major axes (and transpose values to reflect
         the change)
-        
+
         Returns
         -------
         WidePanel (new object)
         """
         new_values = self.values.swapaxes(1, 2)
-        
-        return cls(new_values, self.items, self.minor_axis, self.major_axis)
-        
+
+        return WidePanel(new_values, self.items,
+                         self.minor_axis, self.major_axis)
+
     def toLong(self, filter_observations=True):
         """
         Transform wide format into long (stacked) format
@@ -153,7 +476,7 @@ class WidePanel(Panel):
         filter_observations: boolean, default True
             Drop (major, minor) pairs without a complete set of observations
             across all the items
-        
+
         Returns
         -------
         LongPanel
@@ -161,18 +484,18 @@ class WidePanel(Panel):
         I, N, K = self.dims
 
         if filter_observations:
-            mask = np.isfinite(self.values).sum(axis=0) == I
+            mask = np.isfinite(self.values).all(axis=0)
             size = mask.sum()
             selector = mask.ravel()
         else:
             size = N * K
             selector = slice(None, None)
-            
-        values = np.empty((size, I), dtype=float)        
-            
-        for i, field in enumerate(self.items):
+
+        values = np.empty((size, I), dtype=float)
+
+        for i in xrange(len(self.items)):
             values[:, i] = self.values[i].ravel()[selector]
-            
+
         major_labels = np.arange(N).repeat(K)[selector]
 
         # Anyone think of a better way to do this? np.repeat does not
@@ -181,12 +504,17 @@ class WidePanel(Panel):
         minor_labels = minor_labels.ravel()[selector]
 
         if filter_observations:
-            return LongPanel(values, self.items, self.major_axis,
-                             self.minor_axis, major_labels, minor_labels,
-                             mask=selector)
+            mask = selector
         else:
-            return LongPanel(values, self.items, self.major_axis,
-                             self.minor_axis, major_labels, minor_labels)
+            mask = None
+
+        index = LongPanelIndex(self.major_axis,
+                               self.minor_axis,
+                               major_labels,
+                               minor_labels,
+                               mask=mask)
+
+        return LongPanel(values, self.items, index)
 
     def filterItems(self, items):
         """
@@ -195,7 +523,7 @@ class WidePanel(Panel):
         Parameters
         ----------
         items: sequence
-        
+
         Returns
         -------
         WidePanel
@@ -207,102 +535,110 @@ class WidePanel(Panel):
         return WidePanel(new_values, intersection, self.major_axis,
                          self.minor_axis)
 
-class LongPanel(Panel):
-    """
-    Represents long or "stacked" format panel data
+    def _apply(self, func, axis='major', fill_na=True):
+        """
+        Parameters
+        ----------
+        func: numpy function
+            Signature should match numpy.{sum, mean, var, std} etc.
+        axis: {'major', 'minor', 'items'}
+        fill_na: boolean, default True
+            Replace NaN values with 0 first
+
+        Returns
+        -------
+        DataMatrix
+        """
+
+        i = self._wide_axis_number(axis)
+        index, columns = self._get_plane_axes(axis)
+
+        values = self.values
+        if fill_na:
+            values = values.copy()
+            values[-np.isfinite(values)] = 0
+
+        result = func(values, axis=i)
+
+        if axis != 'items':
+            result = result.T
+
+        if not result.ndim == 2:
+            raise Exception('function %s incompatible' % func)
+
+        return DataMatrix(result, index=index, columns=columns)
+
+    def sum(self, axis='major'):
+        return self._apply(np.sum, axis=axis)
+
+    def mean(self, axis='major'):
+        return self._apply(np.mean, axis=axis)
+
+    def var(self, axis='major'):
+        def _var(arr, axis=0):
+            return np.std(arr, axis=axis, ddof=1)
+
+        return self._apply(_var, axis=axis)
+
+    def std(self, axis='major'):
+        def _std(arr, axis=0):
+            return np.std(arr, axis=axis, ddof=1)
+
+        return self._apply(_std, axis=axis)
+
+class LongPanelIndex(object):
     """
+    Parameters
+    ----------
 
-    def __init__(self, values, items, major_axis, minor_axis, major_labels,
+    """
+    def __init__(self, major_axis, minor_axis, major_labels,
                  minor_labels, mask=None):
 
-        self.items = items
-        self.values = values
         self.major_axis = major_axis
         self.minor_axis = minor_axis
 
         self.major_labels = major_labels
         self.minor_labels = minor_labels
 
-        self.__mask = mask
-
-    def toWide(self):
-        """
-        Transform long (stacked) format into wide format
-
-        Returns
-        -------
-        WidePanel
-        """
-        I, N, K = self.dims
-
-        values = np.empty((I, N, K), dtype=float)
-
-        mask = self._mask
-        notmask = -mask
-        
-        for i in xrange(len(self.items)):
-            values[i].flat[mask] = self.values[:, i]
-            values[i].flat[notmask] = np.NaN
-            
-        return WidePanel(values, self.items, self.major_axis, self.minor_axis)
-
-    def toString(self, col_space=15, return_=False):
-        """
-        Output a screen-friendly version of this Panel
-        """
-        from cStringIO import StringIO
+        self._mask = mask
 
-        output = StringIO()
+    def __getstate__(self):
+        return (_pickle(self.major_axis),
+                _pickle(self.minor_axis),
+                _pickle(self.major_labels),
+                _pickle(self.minor_labels))
 
-        major_space = max([len(str(idx)) for idx in self.major_axis]) + 4
-        minor_space = max([len(str(idx)) for idx in self.minor_axis]) + 4
-        
-        for h in ['Major', 'Minor'] + list(self.items):
-             output.write(_pfixed(h, col_space))
+    def __setstate__(self, state):
+        major, minor, major_labels, minor_labels = state
 
-        output.write('\n')
+        self.major_axis = _interpret(major)
+        self.minor_axis = _interpret(minor)
 
-        label_pairs = zip(self.major_labels, self.minor_labels)
-        for i, (major_i, minor_i) in enumerate(label_pairs):
-            vals = ''.join(_pfixed(v, col_space) for v in self.values[i])
+        self.major_axis = _interpret(major_labels)
+        self.minor_axis = _interpret(minor_labels)
 
-            row = '%s%s%s\n' % (_pfixed(self.major_axis[major_i], col_space),
-                                _pfixed(self.minor_axis[minor_i], col_space),
-                                vals)
+    def isConsistent(self):
+        offset = max(len(self.major_axis), len(self.minor_axis))
 
-            output.write(row)
-        
-        if return_:
-            return output.getvalue()
+        # overflow risk
+        if (offset + 1) ** 2 > 2**32:
+            keys = (self.major_labels.astype(np.int64) * offset +
+                    self.minor_labels.astype(np.int64))
         else:
-            print output.getvalue()
+            keys = self.major_labels * offset + self.minor_labels
 
-    def swapaxes(self):
-        """
-        Swap major and minor axes and reorder values to be grouped by
-        minor axis values
+        unique_keys = np.unique(keys)
 
-        Returns
-        -------
-        LongPanel (new object)
-        """
-        # Order everything by minor labels. Have to use mergesort
-        # because NumPy quicksort is not stable. Here of course I'm
-        # using the invariant that the major labels are ordered.
-        indexer = self.minor_labels.argsort(kind='mergesort')
+        if len(unique_keys) < len(keys):
+            return False
 
-        new_major = self.minor_labels.take(indexer)
-        new_minor = self.major_labels.take(indexer)
-        new_values = self.values.take(indexer, axis=0)
-        
-        return LongPanel(new_values, self.items, self.minor_axis,
-                         self.major_axis, new_major, new_minor,
-                         mask=self._mask)
+        return True
 
     def getSlice(self, begin=None, end=None):
         """
-        Slice panel between two major axis values, return complete LongPanel
-        
+        Slice index between two major axis values, return complete LongPanel
+
         Parameters
         ----------
         begin: type of major_axis values or None, default None
@@ -317,57 +653,22 @@ class LongPanel(Panel):
         """
         i, j = self._getAxisBounds(begin, end)
         left, right = self._getLabelBounds(i, j)
-        
-        return LongPanel(self.values[left : right],
-                         self.items,
-                         self.major_axis[i : j],
-                         self.minor_axis,
-                         self.major_labels[left : right] - i,
-                         self.minor_labels[left : right])
 
-    def getValueSlice(self, begin=None, end=None):
-        """
-        Slice panel between two major axis values and return only
-        values array
-        
-        Parameters
-        ----------
-        begin: type of major_axis values or None, default None
-            None defaults to start of panel
+        return LongPanelIndex(self.major_axis[i : j],
+                              self.minor_axis,
+                              self.major_labels[left : right] - i,
+                              self.minor_labels[left : right])
 
-        end: type of major_axis values or None, default None
-            None defaults to end of panel
+    def getMajorBounds(self, begin=None, end=None):
+        """
 
-        Returns
-        -------
-        ndarray
         """
         i, j = self._getAxisBounds(begin, end)
         left, right = self._getLabelBounds(i, j)
 
-        return self.values[left : right]
-    
-    def filterItems(self, items):
-        """
-        Restrict items in panel to input list
+        return left, right
 
-        Parameters
-        ----------
-        items: sequence
-        
-        Returns
-        -------
-        WidePanel
-        """
-        intersection = self.items.intersection(items)
-        indexer = [self.items.indexMap[col] for col in intersection]
-
-        new_values = self.values.take(indexer, axis=1)
-        return LongPanel(new_values, intersection, self.major_axis,
-                         self.minor_axis, self.major_labels,
-                         self.minor_labels, mask=self._mask)
-
-    def _getAxisBounds(self, begin, end):
+    def _getAxisBounds(self, begin, end):
         """
         Return major axis locations corresponding to interval values
         """
@@ -377,7 +678,7 @@ class LongPanel(Panel):
                 i = self.major_axis.searchsorted(begin, side='right')
         else:
             i = 0
-            
+
         if end is not None:
             j = self.major_axis.indexMap.get(end)
             if j is None:
@@ -386,7 +687,7 @@ class LongPanel(Panel):
                 j = j + 1
         else:
             j = len(self.major_axis)
-            
+
         if i > j:
             raise Exception('Must have begin <= end!')
 
@@ -394,50 +695,720 @@ class LongPanel(Panel):
 
     def _getLabelBounds(self, i, j):
         "Return slice points between two major axis locations"
-        
+
         left = self._bounds[i]
 
         if j >= len(self.major_axis):
-            right = len(self.values)
+            right = len(self.major_labels)
         else:
             right = self._bounds[j]
-        
+
         return left, right
 
     __bounds = None
     @property
     def _bounds(self):
+        "Return or compute and return slice points for major axis"
         if self.__bounds is None:
             inds = np.arange(len(self.major_axis))
             self.__bounds = self.major_labels.searchsorted(inds)
-            
+
         return self.__bounds
-    
+
     @property
-    def _mask(self):
+    def mask(self):
         """
-        
+
         """
-        if self.__mask is None:
-            self.__mask = self._makeMask()
+        if self._mask is None:
+            self._mask = self._makeMask()
+
+        return self._mask
 
-        return self.__mask
-        
     def _makeMask(self):
         """
         Create observation selection vector using major and minor
         labels, for converting to wide format.
         """
-        _, N, K = self.dims
+        N, K = self.dims
         selector = self.minor_labels + K * self.major_labels
-        
+
         mask = np.zeros(N * K, dtype=bool)
         mask[selector] = True
-        
+
         return mask
 
+    @property
+    def dims(self):
+        return len(self.major_axis), len(self.minor_axis)
+
+
+class LongPanel(Panel):
+    """
+    Represents long or "stacked" format panel data
+    """
+
+    def __init__(self, values, items, index, factors=None):
+        self.values = values
+        self.items = items
+        self.index = index
+
+        self.factors = factors or {}
+
+    @classmethod
+    def fromRecords(cls, data, major_field, minor_field,
+                    factor_list=None, exclude=None):
+        """
+
+        Parameters
+        ----------
+        data: DataFrame, structured or record array, or dict
+        major_field: string
+        minor_field: string
+            Name of field
+        factor_list: list-like, default None
+        exclude: list-like, default None
+        Returns
+        -------
+        LongPanel
+        """
+        from pandas.lib.tseries import getMergeVec
+
+        if isinstance(data, np.ndarray):
+            # Dtype when you have data
+            if data.dtype.type != np.void:
+                raise Exception('Input was not a structured array!')
+
+            columns = data.dtype.names
+            data = dict((k, data[k]) for k in columns)
+        elif isinstance(data, DataFrame):
+            data = data._series
+
+        if major_field in data:
+            major_vec = data.pop(major_field)
+        else:
+            raise Exception('No field named %s' % major_field)
+
+        if minor_field in data:
+            minor_vec = data.pop(minor_field)
+        else:
+            raise Exception('No field named %s' % minor_field)
+
+        major_axis = Index(sorted(set(major_vec)))
+        minor_axis = Index(sorted(set(minor_vec)))
+
+        major_labels = getMergeVec(major_vec, major_axis.indexMap)
+        minor_labels = getMergeVec(minor_vec, minor_axis.indexMap)
+
+        index = LongPanelIndex(major_axis, minor_axis,
+                               major_labels, minor_labels)
+
+        items = sorted(data)
+        values, factors = _convert(data, items, factors=factor_list)
+
+        return LongPanel(values, items, index, factors=factors)
+
+    def copy(self):
+        values = self.values.copy()
+        items = self.items
+        index = self.index
+        return LongPanel(values, items, index)
+
+    def _get_major_axis(self):
+        return self.index.major_axis
+
+    major_axis = property(fget=_get_major_axis)
+
+    def _get_minor_axis(self):
+        return self.index.minor_axis
+
+    minor_axis = property(fget=_get_minor_axis)
+
+    def _get_values(self):
+        return self._values
+
+    def _set_values(self, values):
+        if not values.flags.contiguous:
+            values = values.copy()
+
+        self._values = values
+
+    values = property(fget=_get_values, fset=_set_values)
+
+    def __getitem__(self, key):
+        "Return column of panel as LongPanel"
+
+        loc = self.items.indexMap[key]
+
+        return LongPanel(self.values[:, loc : loc + 1].copy(),
+                        [key], self.index)
+
+    def __setitem__(self, key, value):
+        """
+        Insert item at end of items for now
+        """
+        if np.isscalar(value):
+            mat = np.empty((len(self.values), 1), dtype=float)
+            mat.fill(value)
+
+        self.items = Index(list(self.items) + [key])
+        self.values = np.column_stack((self.values, mat))
+
+    def __getstate__(self):
+        "Returned pickled representation of the panel"
+
+        return (_pickle(self.values),
+                _pickle(self.items),
+                self.index)
+
+    def __setstate__(self, state):
+        "Unpickle the panel"
+        (vals, items, index) = state
+
+        self.values = _interpret(vals)
+        self.items = _interpret(items)
+        self.index = index
+
+    def _combine(self, other, func, axis=0):
+        if isinstance(other, DataFrame):
+            return self._combineFrame(other, func, axis=axis)
+        elif isinstance(other, Panel):
+            return self._combinePanel(other, func)
+        elif np.isscalar(other):
+            pass
+
+    def _combineFrame(self, other, axis=0):
+        pass
+
+    def _combinePanel(self, other, func):
+        """
+        Arithmetic operation between panels
+        """
+        if self.index is not other.index:
+            raise Exception("Can only combine identically-indexed "
+                            "panels for now")
+
+        if len(other.items) == 1:
+            new_values = func(self.values, other.values)
+        else:
+            new_values = func(self.values, other.values)
+
+        return LongPanel(new_values, self.items, self.index)
+
+    def add(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.add, axis=axis)
+
+    def subtract(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.sub, axis=axis)
+
+    def multiply(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.mul, axis=axis)
+
+    def divide(self, other, axis='major'):
+        """
+
+        """
+        return self._combine(other, operator.div, axis=axis)
+
+    def sort(self, axis='major'):
+        """
+        Sort value by chosen axis (break ties using other axis)
+
+        Note
+        ----
+        A LongPanel must be sorted to convert to a WidePanel
+
+        Returns
+        -------
+        LongPanel (in sorted order)
+        """
+        if axis == 'major':
+            first = self.index.major_labels
+            second = self.index.minor_labels
+
+        elif axis == 'minor':
+            first = self.index.minor_labels
+            second = self.index.major_labels
+
+        # Lexsort starts from END
+        indexer = np.lexsort((second, first))
+
+        new_major = self.index.major_labels[indexer]
+        new_minor = self.index.minor_labels[indexer]
+        new_values = self.values[indexer]
+
+        new_index = LongPanelIndex(self.major_axis, self.minor_axis,
+                                   new_major, new_minor)
+
+        return LongPanel(new_values, self.items, new_index)
+
+    def toWide(self):
+        """
+        Transform long (stacked) format into wide format
+
+        Returns
+        -------
+        WidePanel
+        """
+        if not self.index.isConsistent():
+            raise PanelError('Panel has duplicate (major, minor) pairs, '
+                             'cannot be reliably converted to wide format.')
+
+        I, N, K = self.dims
+
+        values = np.empty((I, N, K), dtype=float)
+
+        mask = self.index.mask
+        notmask = -mask
+
+        for i in xrange(len(self.items)):
+            values[i].flat[mask] = self.values[:, i]
+            values[i].flat[notmask] = np.NaN
+
+        return WidePanel(values, self.items, self.major_axis, self.minor_axis)
+
+    def toCSV(self, path):
+        def format_cols(items):
+            cols = ['Major', 'Minor'] + list(items)
+            return '"%s"' % '","'.join(cols)
+
+        def format_row(major, minor, values):
+            vals = ','.join('%.12f' % val for val in values)
+            return '%s,%s,%s' % (major, minor, vals)
+
+        output = self._textConvert(format_cols, format_row)
+
+        f = open(path, 'w')
+        f.write(output)
+        f.close()
+
+    def toString(self, col_space=15, return_=False):
+        """
+        Output a screen-friendly version of this Panel
+        """
+        from pandas.core.series import _pfixed
+
+        major_space = max(max([len(str(idx))
+                               for idx in self.major_axis]) + 4, 9)
+        minor_space = max(max([len(str(idx))
+                               for idx in self.minor_axis]) + 4, 9)
+
+        def format_cols(items):
+            return '%s%s%s' % (_pfixed('Major', major_space),
+                               _pfixed('Minor', minor_space),
+                               ''.join(_pfixed(h, col_space) for h in items))
+
+        def format_row(major, minor, values):
+            return '%s%s%s' % (_pfixed(major, major_space),
+                               _pfixed(minor, minor_space),
+                               ''.join(_pfixed(v, col_space) for v in values))
+
+        output = self._textConvert(format_cols, format_row)
+
+        if return_:
+            return output
+        else:
+            print output
+
+    def _textConvert(self, format_cols, format_row):
+        output = StringIO()
+        print >> output, format_cols(self.items)
+
+        label_pairs = zip(self.index.major_labels,
+                          self.index.minor_labels)
+        major, minor = self.major_axis, self.minor_axis
+        for i, (major_i, minor_i) in enumerate(label_pairs):
+            row = format_row(major[major_i], minor[minor_i], self.values[i])
+            print >> output, row
+
+        return output.getvalue()
+
+    def swapaxes(self):
+        """
+        Swap major and minor axes and reorder values to be grouped by
+        minor axis values
+
+        Returns
+        -------
+        LongPanel (new object)
+        """
+        # Order everything by minor labels. Have to use mergesort
+        # because NumPy quicksort is not stable. Here of course I'm
+        # using the invariant that the major labels are ordered.
+        indexer = self.index.minor_labels.argsort(kind='mergesort')
+
+        new_major = self.index.minor_labels.take(indexer)
+        new_minor = self.index.major_labels.take(indexer)
+
+        new_values = self.values.take(indexer, axis=0)
+
+        new_index = LongPanelIndex(self.minor_axis,
+                                   self.major_axis,
+                                   new_major,
+                                   new_minor,
+                                   mask=self.index.mask)
+
+        return LongPanel(new_values, self.items, new_index)
+
+    def getSlice(self, begin=None, end=None):
+        """
+        Slice panel between two major axis values, return complete LongPanel
+
+        Parameters
+        ----------
+        begin: type of major_axis values or None, default None
+            None defaults to start of panel
+
+        end: type of major_axis values or None, default None
+            None defaults to end of panel
+
+        Returns
+        -------
+        LongPanel
+        """
+        left, right = self.index.getMajorBounds(begin, end)
+        new_index = self.index.getSlice(begin, end)
+
+        return LongPanel(self.values[left : right],
+                         self.items,
+                         new_index)
+
+    def getSliceAtIndices(self, begin, end):
+        return self.getSlice(
+            self.index.major_axis[begin], self.index.major_axis[end])
+
+    def getValueSlice(self, begin=None, end=None):
+        """
+        Slice panel between two major axis values and return only
+        values array
+
+        Parameters
+        ----------
+        begin: type of major_axis values or None, default None
+            None defaults to start of panel
+
+        end: type of major_axis values or None, default None
+            None defaults to end of panel
+
+        Returns
+        -------
+        ndarray
+        """
+        left, right = self.index.getMajorBounds(begin, end)
+
+        return self.values[left : right]
+
+    def getValueSliceAtIndices(self, begin, end):
+        return self.getValueSlice(
+            self.index.major_axis[begin], self.index.major_axis[end])
+
+    def filterItems(self, items):
+        """
+        Restrict items in panel to input list
+
+        Parameters
+        ----------
+        items: sequence
+
+        Returns
+        -------
+        WidePanel
+        """
+        intersection = self.items.intersection(items)
+        indexer = [self.items.indexMap[col] for col in intersection]
+
+        new_values = self.values.take(indexer, axis=1)
+        return LongPanel(new_values, intersection, self.index)
+
+    def getAxisDummies(self, axis='minor'):
+        """
+        Construct 1-0 dummy variables corresponding to designated axis
+        labels
+
+        Parameters
+        ----------
+        axis: {'major', 'minor'}, default 'minor'
+
+        Returns
+        -------
+        LongPanel, item names taken from chosen axis
+        """
+        if axis == 'minor':
+            dim = len(self.minor_axis)
+            items = self.minor_axis
+        elif axis == 'major':
+            dim = len(self.major_axis)
+            items = self.major_axis
+        else:
+            raise Exception('Do not recognize axis %s' % axis)
+
+        vals = np.eye(dim, dtype=float)
+
+        return self._makeDummyPanel(vals, items, axis=axis)
+
+    def getFrameDummies(self, dataFrame, axis='minor', prefix=None):
+        if axis == 'minor':
+            dataFrame = dataFrame.reindex(self.minor_axis)
+        elif axis == 'major':
+            dataFrame = dataFrame.reindex(self.major_axis)
+
+        items = dataFrame.columns
+
+        return self._makeDummyPanel(dataFrame.values, items, axis=axis,
+                                    prefix=prefix)
+
+    def getItemDummies(self, item):
+        """
+        Use unique values in column of panel to construct LongPanel
+        containing dummy
+
+        Parameters
+        ----------
+        item: object
+            Value in panel items Index
+
+        Returns
+        -------
+        LongPanel
+        """
+        idx = self.items.indexMap[item]
+        values = self.values[:, idx]
+
+        distinct_values = np.array(sorted(set(values)))
+        mapping = distinct_values.searchsorted(values)
+
+        values = np.eye(len(distinct_values))
+
+        dummy_mat = values.take(mapping, axis=0)
+
+        return LongPanel(dummy_mat, distinct_values, self.index)
+
+    def _makeDummyPanel(self, values, items, axis='minor'):
+        """
+        Construct 1-0 dummy variables corresponding to designated axis
+        labels
+
+        Parameters
+        ----------
+        axis: {'major', 'minor'}, default 'minor'
+
+        Returns
+        -------
+        LongPanel, item names taken from chosen axis
+        """
+
+        N, K = values.shape
+
+        if len(items) != K:
+            raise Exception('items length does not match values matrix')
+
+        if axis == 'minor':
+            if len(self.minor_axis) != N:
+                raise Exception('Axis length does not match values matrix')
+            dummy_mat = values.take(self.index.minor_labels, axis=0)
+
+        elif axis == 'major':
+            if len(self.major_axis) != N:
+                raise Exception('Axis length does not match values matrix')
+            dummy_mat = values.take(self.index.major_labels, axis=0)
+        else:
+            raise Exception('Do not recognize axis %s' % axis)
+
+        return LongPanel(dummy_mat, items, self.index)
+
+    def applyToAxis(self, f, axis='major', broadcast=False):
+        """
+        Aggregate over a particular axis
+
+        Parameters
+        ----------
+        f: function
+            NumPy function to apply to each group
+        axis: {'major', 'minor'}
+
+        broadcast: boolean
+
+        Returns
+        -------
+        broadcast=True  -> LongPanel
+        broadcast=False -> DataMatrix
+        """
+        if axis == 'minor':
+            panel = self.swapaxes()
+            result = panel.applyToAxis(f, axis='major', broadcast=broadcast)
+            if broadcast:
+                result = result.swapaxes()
+
+            return result
+
+        bounds = self.index._bounds
+        values = self.values
+        N, _ = values.shape
+        result = group_agg(values, bounds, f)
+
+        if broadcast:
+            repeater = np.concatenate((np.diff(bounds), [N - bounds[-1]]))
+            panel = LongPanel(result.repeat(repeater, axis=0),
+                              self.items, self.index)
+        else:
+            panel = DataMatrix(result, index=self.major_axis,
+                               columns=self.items)
+
+        return panel
+
+    def mean(self, axis='major', broadcast=False):
+        return self.applyToAxis(partial(np.mean, axis=0), axis, broadcast)
+
+    def sum(self, axis='major', broadcast=False):
+        return self.applyToAxis(partial(np.sum, axis=0), axis, broadcast)
+
+    def apply(self, f):
+        return LongPanel(f(self.values), self.items, self.index)
+
+    def square(self):
+        return self.apply(np.square)
+
+    def count(self, axis=0):
+        if axis == 0:
+            lp = self
+        else:
+            lp = self.swapaxes()
+
+        N = len(lp.values)
+        bounds = lp.index._bounds
+
+        return np.concatenate((np.diff(bounds), [N - bounds[-1]]))
+
+    def leftJoin(self, other):
+        """
+
+        Parameters
+        ----------
+        other: LongPanel
+        """
+        if other.index is self.index:
+            pass
+
+    def merge(self, other):
+        """
+
+        Parameters
+        ----------
+        other: LongPanel
+
+        Returns
+        -------
+        LongPanel
+        """
+        assert(self.index is other.index)
+
+        values = np.concatenate((self.values, other.values), axis=1).copy()
+        items = self.items.tolist() + other.items.tolist()
+
+        return LongPanel(values, items, self.index)
+
+    def addPrefix(self, prefix):
+        """
+        Concatenate prefix string with panel items names.
+
+        Parameters
+        ----------
+        prefix: string
+
+        Returns
+        -------
+        LongPanel
+
+        Note: does *not* copy values matrix
+        """
+        new_items = [_makeItemName(item, prefix) for item in self.items]
+
+        return LongPanel(self.values, new_items, self.index)
+
+
+class Factor(np.ndarray):
+    """
+    Represents a categorical variable in classic R / S+ fashion
+    """
+    def __new__(cls, values):
+        values = np.array(values, dtype=object)
+        values = values.view(cls)
+        return values
+
+    def __array_finalize__(self, obj):
+        if obj is None:
+            self.levels = np.array(sorted(set(self)), dtype=object)
+            self.labels = self.levels.searchsorted(self)
+        elif isinstance(obj, Factor):
+            self.levels = getattr(obj, 'levels')
+            self.labels = getattr(obj, 'labels')
+        else:
+            self.levels = np.array(sorted(set(obj)), dtype=object)
+            self.labels = self.levels.searchsorted(obj)
+
+
+    def __repr__(self):
+        return '%s\nLevels (%d): %s' % (np.ndarray.__repr__(self),
+                                        len(self.levels), self.levels)
+
+def _makeItemName(item, prefix=None):
+    if prefix is None:
+        return item
+
+    template = '%g%s' if isinstance(item, float) else '%s%s'
+    return template % (prefix, item)
+
+def _makePrefixedLongPanel(values, items, index, prefix):
+    items = [_makeItemName(item, prefix) for item in items]
+
+    return LongPanel(values, items, index)
+
+def _convert(data, order, factors=None):
+    """
+
+    TODO: make more efficient
+    """
+    N = len(data.values()[0])
+    index = np.arange(N)
+
+    factorSet = set() if factors is None else set(factors)
+
+    frame = DataFrame(data, index=index)
+
+    factors = {}
+    for col, series in frame.iteritems():
+        # Is it a factor?
+        if not np.issctype(series.dtype) and col in factorSet:
+            factors[col] = fac = Factor(series)
+            frame[col] = fac.labels
+
+    values = frame.asMatrix(order)
+
+    return values, factors
 
 def _homogenize(frames, intersect=True):
+    """
+    Conform set of DataFrame-like objects to either an intersection
+    of indices / columns or a union.
+
+    Parameters
+    ----------
+    frames: dict
+    intersect: boolean, default True
+
+    Returns
+    -------
+    dict of aligned frames, index, columns
+    """
     result = {}
 
     index = None
@@ -454,7 +1425,7 @@ def _homogenize(frames, intersect=True):
                 columns = set(frame.cols())
             else:
                 columns &= set(frame.cols())
-    else: 
+    else:
         for key, frame in frames.iteritems():
             if index is None:
                 index = frame.index
@@ -465,7 +1436,7 @@ def _homogenize(frames, intersect=True):
                 columns = set(frame.cols())
             else:
                 columns |= set(frame.cols())
-    
+
     columns = sorted(columns)
 
     if intersect:
@@ -475,11 +1446,113 @@ def _homogenize(frames, intersect=True):
         for key, frame in frames.iteritems():
             if not isinstance(frame, DataMatrix):
                 frame = frame.toDataMatrix()
-    
+
             result[key] = frame._withColumns(columns).reindex(index)
 
     return result, index, columns
 
+def pivot(index, columns, values):
+    """
+    Produce 'pivot' table based on 3 columns of this DataFrame.
+    Uses unique values from index / columns and fills with values.
+
+    Parameters
+    ----------
+    index: ndarray
+        Labels to use to make new frame's index
+    columns: ndarray
+        Labels to use to make new frame's columns
+    values: ndarray
+        Values to use for populating new frame's values
+
+    Note
+    ----
+    Obviously, all 3 of the input arguments must have the same length
+
+    Returns
+    -------
+    DataMatrix
+    """
+    import pandas.lib.tseries as tseries
+
+    if not (len(index) == len(columns) == len(values)):
+        raise Exception('Pivot inputs must all be same length!')
+
+    major_axis = Index(sorted(set(index)))
+    minor_axis = Index(sorted(set(columns)))
+
+    major_labels, _ = tseries.getMergeVec(index, major_axis.indexMap)
+    minor_labels, _ = tseries.getMergeVec(columns, minor_axis.indexMap)
+
+    valueMat = values.view(np.ndarray).reshape(len(values), 1)
+
+    longIndex = LongPanelIndex(major_axis, minor_axis,
+                               major_labels, minor_labels)
+
+    longPanel = LongPanel(valueMat, ['foo'], longIndex)
+    longPanel = longPanel.sort()
+
+    try:
+        return longPanel.toWide()['foo']
+    except PanelError:
+        return _slow_pivot(index, columns, values)
+
+def _slow_pivot(index, columns, values):
+    """
+    Produce 'pivot' table based on 3 columns of this DataFrame.
+    Uses unique values from index / columns and fills with values.
+
+    Parameters
+    ----------
+    index: string or object
+        Column name to use to make new frame's index
+    columns: string or object
+        Column name to use to make new frame's columns
+    values: string or object
+        Column name to use for populating new frame's values
+
+    Could benefit from some Cython here.
+    """
+    from itertools import izip
+    tree = {}
+    for i, (idx, col) in enumerate(izip(index, columns)):
+        if col not in tree:
+            tree[col] = {}
+        branch = tree[col]
+        branch[idx] = values[i]
+
+    return DataFrame.fromDict(tree)
+
+def test():
+    return pivot(np.array([1, 2, 3, 4, 4]),
+                 np.array(['a', 'a', 'a', 'a', 'a']),
+                 np.array([1, 2, 3, 5, 4]))
+
+def _monotonic(arr):
+    return not (arr[1:] < arr[:-1]).any()
+
+def group_agg(values, bounds, f):
+    """
+    R-style aggregator
+    """
+    N, K = values.shape
+    result = np.empty((len(bounds), K), dtype=float)
+
+    for i, left_bound in enumerate(bounds):
+        if i == len(bounds) - 1:
+            right_bound = N
+        else:
+            right_bound = bounds[i + 1]
+
+        result[i] = f(values[left_bound : right_bound])
+
+    return result
+
+class WidePanelGroupBy(GroupBy):
+    pass
+
+class LongPanelGroupBy(GroupBy):
+    pass
 
 if __name__ == '__main__':
     from datetime import datetime
@@ -488,30 +1561,41 @@ if __name__ == '__main__':
     import numpy as np
 
     from pandas.core.api import DataMatrix, DateRange
-    from pandas.stats.linmodel import LinearModel, XSLinearModel
 
-    N = 5000
+    N = 50
     K = 4
 
     start = datetime(2009, 9, 2)
     dateRange = DateRange(start, periods=N)
 
+    cols = ['Col' + c for c in string.ascii_uppercase[:K]]
+
     def makeDataMatrix():
         data = DataMatrix(np.random.randn(N, K),
-                          columns=list(string.ascii_uppercase[:K]),
+                          columns=cols,
+                          index=dateRange)
+
+        return data
+
+    def makeDataMatrixForWeekday():
+        values = [d.weekday() for d in dateRange]
+        data = DataMatrix(dict((k, values) for k in cols),
                           index=dateRange)
 
         return data
 
     data = {
-        'A' : makeDataMatrix(),
-        'B' : makeDataMatrix(),
-        'C' : makeDataMatrix()
+        'ItemA' : makeDataMatrix(),
+        'ItemB' : makeDataMatrix(),
+        'ItemC' : makeDataMatrix(),
+#        'ItemD' : makeDataMatrixForWeekday(),
     }
 
-    data['A']['A'][:10] = np.NaN
-    
+    Y = makeDataMatrix()
+
+    data['ItemA']['ColA'][:10] = np.NaN
+
     panel = WidePanel.fromDict(data)
 
-    long = panel.toLong(filter_observations=True)
-    wide = long.toWide()
+    longPanel = panel.toLong(filter_observations=True)
+    widePanel = longPanel.toWide()
diff --git a/pandas/core/pytools.py b/pandas/core/pytools.py
index f675ae080..60d80c84c 100644
--- a/pandas/core/pytools.py
+++ b/pandas/core/pytools.py
@@ -1,6 +1,7 @@
 """A collection of tools for various purely Python operations"""
 from random import Random
 import base64
+import functools
 import os
 import string
 
@@ -28,11 +29,45 @@ def adjoin(space, *lists):
         outLines.append(''.join(lines))
     return '\n'.join(outLines)
 
+
+def iterpairs(seq):
+    """
+    Parameters
+    ----------
+    seq: sequence
+
+    Returns
+    -------
+    iterator returning overlapping pairs of elements
+
+    Example
+    -------
+    >>> iterpairs([1, 2, 3, 4])
+    [(1, 2), (2, 3), (3, 4)
+    """
+    if len(seq) < 2:
+        raise Exception('Only works on sequences length 2 or greater!')
+
+    seqiter = iter(seq)
+    current = seqiter.next()
+    while True:
+        try:
+            next = seqiter.next()
+            yield current, next
+
+            current = next
+
+        except StopIteration:
+            break
+
 def indent(string, spaces=4):
     dent = ' ' * spaces
     return '\n'.join([dent + x for x in string.split('\n')])
 
 def banner(message):
+    """
+    Return 80-char width message declaration with = bars on top and bottom.
+    """
     bar = '=' * 80
     return '%s\n%s\n%s' % (bar, message, bar)
 
@@ -40,9 +75,9 @@ def banner(message):
 class groupby(dict):
     """
     A simple groupby different from the one in itertools.
-    
+
     Does not require the sequence elements to be sorted by keys,
-    however it is slower. 
+    however it is slower.
     """
     def __init__(self, seq, key=lambda x:x):
         for value in seq:
@@ -58,3 +93,25 @@ def map_indices_py(arr):
     """
     return dict([(x, i) for i, x in enumerate(arr)])
 
+#===============================================================================
+# Set operations
+#===============================================================================
+
+def union(*seqs):
+    result = set([])
+    for seq in seqs:
+        if not isinstance(seq, set):
+            seq = set(seq)
+        result |= seq
+    return type(seqs[0])(list(result))
+
+def difference(a, b):
+    return type(a)(list(set(a) - set(b)))
+
+def intersection(*seqs):
+    result = set(seqs[0])
+    for seq in seqs:
+        if not isinstance(seq, set):
+            seq = set(seq)
+        result &= seq
+    return type(seqs[0])(list(result))
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 9dfb428c1..237a20c8d 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1,12 +1,18 @@
+"""
+Data structure for 1-dimensional cross-sectional and time series data
+"""
+
+# pylint: disable-msg=E1101
+# pylint: disable-msg=E1103
+
 from datetime import datetime
 from itertools import izip
-import operator
 
-from numpy import NaN, ndarray
+from numpy import array, NaN, ndarray
 import numpy as np
 
 from pandas.core.daterange import DateRange
-from pandas.core.datetools import DateOffset, to_datetime
+from pandas.core.datetools import to_datetime
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.mixins import Picklable, Groupable
 
@@ -33,8 +39,8 @@ def _seriesOpWrap(opname, comp=False):
         func = getattr(self.view(ndarray), opname)
         cls = self.__class__
         if isinstance(other, Series):
-            if self.index is other.index:
-                return cls(func(other), index=self.index)
+            if self.index.equals(other.index):
+                return cls(func(other.view(ndarray)), index=self.index)
             if len(self.index) + len(other.index) > 0:
                 newIndex = self.index + other.index
             else:
@@ -43,7 +49,7 @@ def _seriesOpWrap(opname, comp=False):
                 arr = tseries.combineFunc(opname, newIndex, self, other,
                                           self.index.indexMap,
                                           other.index.indexMap)
-            except:
+            except Exception, e:
                 arr = Series.combineFunc(self, other,
                                          getattr(type(self[0]), opname))
             result = cls(arr, index=newIndex)
@@ -74,23 +80,25 @@ class Series(np.ndarray, Picklable, Groupable):
     index: array-like, optional
         Index object (or other iterable of same length as data)
 
-    Contains values in a numpy-ndarray with an optional bound index (also
-    an array of dates, strings, or whatever you want the 'row names' of
-    your series to be)
+    Contains values in a numpy-ndarray with an optional bound index
+    (also an array of dates, strings, or whatever you want the 'row
+    names' of your series to be)
 
     Rows can be retrieved by index value (date, string, etc.) or
     relative position in the underlying array.
 
-    Operations between Series (+, -, /, *, **) objects are *index-safe*,
-    meaning that values will be combined by their respective index positions
-    rather than relative positions in the underlying ndarray. In other words,
-    there is no 'matching' or 'aligning' to do, it's all taken care of for you.
+    Operations between Series (+, -, /, *, **) objects are
+    *index-safe*, meaning that values will be combined by their
+    respective index positions rather than relative positions in the
+    underlying ndarray. In other words, there is no 'matching' or
+    'aligning' to do, it's all taken care of for you.
 
-    NOTE: If you combine two series, all values for an index position must
-    be present or the value for that index position will be nan. The new index
-    is the sorted union of the two Series indices.
+    NOTE: If you combine two series, all values for an index position
+    must be present or the value for that index position will be
+    nan. The new index is the sorted union of the two Series indices.
 
-    ALSO NOTE: There is currently no restriction on what can be in the index.
+    ALSO NOTE: There is currently no restriction on what can be in the
+    index.
 
     Example usage:
         >>> s = Series(arr, index=Index(dates))
@@ -113,10 +121,9 @@ class Series(np.ndarray, Picklable, Groupable):
         if subarr.ndim == 0:
             return subarr.item()
 
-        """
-        This is to prevent mixed-type Series getting all casted
-        to NumPy string type, e.g. NaN --> '-1#IND'.
-        """
+        # This is to prevent mixed-type Series getting all casted to
+        # NumPy string type, e.g. NaN --> '-1#IND'.
+
         if issubclass(subarr.dtype.type, basestring):
             subarr = array(data, dtype=object, copy=copy)
 
@@ -178,7 +185,7 @@ class Series(np.ndarray, Picklable, Groupable):
         if castFloat:
             try:
                 useData = [float(input[idx]) for idx in index]
-            except:
+            except Exception, e:
                 useData = [input[idx] for idx in index]
         else:
             useData = [input[idx] for idx in index]
@@ -291,10 +298,11 @@ class Series(np.ndarray, Picklable, Groupable):
         if not hasattr(key, '__iter__'):
             try:
                 # Check that we can even look for this in the index
-                if key in self.index:
-                    return self.get(key)
-                if not isinstance(key, int):
-                    raise Exception('Requested index not in this series!')
+                return ndarray.__getitem__(self, self.index.indexMap[key])
+            except KeyError:
+                if isinstance(key, int):
+                    return ndarray.__getitem__(self, key)
+                raise Exception('Requested index not in this series!')
             except TypeError:
                 # Could not hash item
                 pass
@@ -334,16 +342,10 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         If this series is mutable, set specified indices equal to given values.
         """
-        if isinstance(key, int):
-            ndarray.__setitem__(self, key, value)
-        else:
-            try:
-                # Check that we can even look for this in the index
-                if key in self.index:
-                    ndarray.__setitem__(self, self.index.indexMap[key], value)
-                    return
-            except:
-                pass
+        try:
+            loc = self.index.indexMap[key]
+            ndarray.__setitem__(self, loc, value)
+        except Exception, e:
             ndarray.__setitem__(self, key, value)
 
     def __setslice__(self, i, j, value):
@@ -368,7 +370,7 @@ class Series(np.ndarray, Picklable, Groupable):
         return self.__repr__()
 
     def __iter__(self):
-        return self.view(ndarray).__iter__()
+        return iter(self.view(ndarray))
 
 #-------------------------------------------------------------------------------
 #   Arithmetic operators
@@ -390,6 +392,10 @@ class Series(np.ndarray, Picklable, Groupable):
 # Overridden ndarray methods
 
     def sum(self, axis=None, dtype=None, out=None):
+        """
+        Overridden version of ndarray.sum for Series which excludes
+        NaN automatically
+        """
         arr = self.view(ndarray)
         retVal = arr.sum(axis, dtype, out)
 
@@ -400,6 +406,10 @@ class Series(np.ndarray, Picklable, Groupable):
         return retVal
 
     def mean(self, axis=None, dtype=None, out=None):
+        """
+        Overridden version of ndarray.mean for Series which excludes
+        NaN automatically
+        """
         arr = self.view(ndarray)
         retVal = arr.mean(axis, dtype, out)
 
@@ -409,13 +419,49 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return retVal
 
+    def min(self, axis=None, out=None):
+        """
+        Overridden version of ndarray.min for Series which excludes
+        NaN automatically
+        """
+        arr = self.view(ndarray)
+        retVal = arr.min(axis, out)
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            retVal = arr.min(axis, out)
+
+        return retVal
+
+    def max(self, axis=None, out=None):
+        """
+        Overridden version of ndarray.max for Series which excludes
+        NaN automatically
+        """
+        arr = self.view(ndarray)
+        retVal = arr.max(axis, out)
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            retVal = arr.max(axis, out)
+
+        return retVal
+
     def std(self, axis=None, dtype=None, out=None, ddof=1):
+        """
+        Overridden version of ndarray.std for Series which excludes
+        NaN automatically
+        """
         nona = remove_na(self.view(ndarray))
         if len(nona) < 2:
             return NaN
         return ndarray.std(nona, axis, dtype, out, ddof)
 
     def var(self, axis=None, dtype=None, out=None, ddof=1):
+        """
+        Overridden version of ndarray.var for Series which excludes
+        NaN automatically
+        """
         nona = remove_na(self.view(ndarray))
         if len(nona) < 2:
             return NaN
@@ -468,7 +514,7 @@ class Series(np.ndarray, Picklable, Groupable):
         Iterate over (index, value) tuples
         """
         if self.index is not None:
-            return izip(self.index.__iter__(), self.__iter__())
+            return izip(iter(self.index), iter(self))
         else:
             raise Exception('This series has no index!')
 
@@ -517,7 +563,7 @@ class Series(np.ndarray, Picklable, Groupable):
             raise Exception('Argument must be a Series!')
         fillVec, mask = tseries.getMergeVec(self, other.index.indexMap)
 
-        newValues = other.view(np.ndarray)[fillVec]
+        newValues = other.view(np.ndarray).take(fillVec)
         newValues[-mask] = np.nan
 
         newSer = Series(newValues, index=self.index)
@@ -528,7 +574,7 @@ class Series(np.ndarray, Picklable, Groupable):
         Combines this Series with another Series index by index using
         the given function.
         """
-        if self.index is other.index:
+        if self.index.equals(other.index):
             newIndex = self.index
         else:
             newIndex = self.index + other.index
@@ -549,7 +595,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         Series formed as union of
         """
-        if self.index is other.index:
+        if self.index.equals(other.index):
             newIndex = self.index
         else:
             newIndex = self.index + other.index
@@ -615,19 +661,26 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return np.corrcoef(this, that)[0, 1]
 
-    def median(self):
+    def count(self):
         """
-        Return median of Series.
+        Return number of observations of Series.
 
         Returns
         -------
-        The median value
+        int (# obs)
+        """
+        return np.isfinite(self.view(ndarray)).sum()
+
+    def median(self):
+        """
+        Return median value of Series
         """
         selfExNaN = remove_na(self.view(ndarray))
-        return np.median(selfExNaN)
+        med = np.median(selfExNaN)
+        return med
 
     def sort(self, axis=0, kind='quicksort', order=None):
-        sortedSeries = self.order(missingAtEnd = True)
+        sortedSeries = self.order(missingAtEnd=True)
         self[:] = sortedSeries
         self.index = sortedSeries.index
 
@@ -725,9 +778,6 @@ class Series(np.ndarray, Picklable, Groupable):
 
         pylab.plot(self.index, self, **kwds)
 
-    def remapIndex(self, mapping):
-        raise Exception('Not implemented!')
-
     def unstack(self):
         """
         Inverse operator for *stack*
@@ -738,7 +788,7 @@ class Series(np.ndarray, Picklable, Groupable):
             row, col = idx.split(';')
             try:
                 row = datetime.fromordinal(int(row))
-            except:
+            except Exception, e:
                 pass
             data.setdefault(row, {})[col] = value
         return DataFrame.fromDict(data)
@@ -777,6 +827,16 @@ class Series(np.ndarray, Picklable, Groupable):
         myCopy[notnull(myCopy) & (myCopy < value)] = value
         return myCopy
 
+    def valid(self):
+        """
+        Return Series without NaN values
+
+        Returns
+        -------
+        Series
+        """
+        return remove_na(self)
+
 #-------------------------------------------------------------------------------
 # TimeSeries methods
 
@@ -933,7 +993,8 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         if fillMethod is None:
             if self.index is newIndex:
-                return self
+                return self.copy()
+
             if not isinstance(newIndex, Index):
                 newIndex = Index(newIndex)
 
@@ -976,7 +1037,7 @@ class Series(np.ndarray, Picklable, Groupable):
         fillVec, mask = tseries.getFillVec(self.index, newIndex, oldMap,
                                            newMap, kind=fillMethod)
 
-        newValues = self.view(ndarray)[fillVec]
+        newValues = self.view(ndarray).take(fillVec)
         newValues[-mask] = NaN
 
         return self.__class__(newValues, index = newIndex)
@@ -986,7 +1047,7 @@ class Series(np.ndarray, Picklable, Groupable):
         return self.__class__([d.weekday() for d in self.index],
                               index = self.index)
 
-    def truncate(self, before = None, after = None):
+    def truncate(self, before=None, after=None):
         """Function truncate a TimeSeries before and/or after some
         particular dates.
 
@@ -1015,6 +1076,16 @@ class Series(np.ndarray, Picklable, Groupable):
             after = max(self.index)
         return self.slice(before, after)
 
+    def diff(self):
+        """
+        1st discrete difference of object
+
+        Returns
+        -------
+        TimeSeries
+        """
+        return (self - self.shift(1))
+
     def autocorr(self):
         """
         1st period autocorrelation coefficient
diff --git a/pandas/lib/include/wirth.h b/pandas/lib/include/wirth.h
new file mode 100644
index 000000000..cd8fb99d4
--- /dev/null
+++ b/pandas/lib/include/wirth.h
@@ -0,0 +1 @@
+double kth_smallest(double *a, int n, int k);
diff --git a/pandas/lib/src/tseries.pyx b/pandas/lib/src/tseries.pyx
index 171f2ee03..aabc8a2d2 100644
--- a/pandas/lib/src/tseries.pyx
+++ b/pandas/lib/src/tseries.pyx
@@ -1,5 +1,4 @@
 include "numpy.pxi"
-include "datetime.pxi"
 include "Python.pxi"
 
 # initialize numpy
@@ -11,8 +10,6 @@ cimport numpy as np
 isnan = np.isnan
 cdef double NaN = <double> np.NaN
 
-from datetime import datetime as pydatetime
-
 from python_dict cimport *
 from numpy cimport ndarray, npy_float64, npy_int32, npy_int8, npy_float128
 
@@ -29,42 +26,80 @@ cdef inline object trycall(object func, object arg):
 cdef inline int int_max(int a, int b): return a if a >= b else b
 cdef inline int int_min(int a, int b): return a if a >= b else b
 
+cdef extern from "wirth.h":
+    double kth_smallest(double *a, int n, int k)
+
+def median(ndarray arr):
+    cdef double *values
+    cdef int n = len(arr)
+
+    if len(arr) == 0:
+        return np.NaN
+
+    if not np.PyArray_CHKFLAGS(arr, np.NPY_C_CONTIGUOUS):
+        arr = np.array(arr)
+
+    values = <double *> arr.data
+
+    if n % 2:
+        return kth_smallest(values, n, n / 2)
+    else:
+        return (kth_smallest(values, n, n / 2) +
+                kth_smallest(values, n, n / 2 - 1)) / 2
+
+def roll_median(ndarray[npy_float64, ndim=1] arr, int window, int minp):
+    cdef char *mask_data
+    cdef ndarray mask
+    cdef ndarray[npy_float64, ndim=1] result
+    cdef int i, n
+
+    n = len(arr)
+    arr = arr.copy()
+
+    mask = <ndarray> np.isfinite(arr)
+    mask_data = <char *> mask.data
+
+    result = np.empty(len(arr), dtype=float)
+
+    for i from minp <= i <= n:
+        pass
+
 def map_indices(ndarray index):
     '''
     Produce a dict mapping the values of the input array to their respective
     locations.
-    
+
     Example:
         array(['hi', 'there']) --> {'hi' : 0 , 'there' : 1}
-        
+
     Better to do this with Cython because of the enormous speed boost.
     '''
     cdef int i, length
     cdef flatiter iter
     cdef dict result
     cdef object idx
-        
+
     result = {}
-    
+
     iter = PyArray_IterNew(index)
 
     length = PyArray_SIZE(index)
-        
+
     for i from 0 <= i < length:
         idx = PyArray_GETITEM(index, <void *> iter.dataptr)
         result[idx] = i
         PyArray_ITER_NEXT(iter)
-        
+
     return result
 
 def match(ndarray A, ndarray B):
     '''
     --> match(a, b)
-    
+
     Close equivalent of R's match function.
-    
+
     For given input index A, find matching locations for values of A in B.
-    
+
     Example:
     >>> b
     array([[ 0.        ,  0.26929312],
@@ -79,9 +114,9 @@ def match(ndarray A, ndarray B):
            [ 9.        ,  0.18337242]])
     >>> a
         array([1, 3, 6, 8, 4, 5, 7, 0, 2, 9])
-    
+
     # Now with match we can realign b based on a
-    
+
     >>> b[match(a, b[:,0]),:]
     array([[ 1.        ,  0.49540359],
            [ 3.        ,  0.66235806],
@@ -93,9 +128,9 @@ def match(ndarray A, ndarray B):
            [ 0.        ,  0.26929312],
            [ 2.        ,  0.66389941],
            [ 9.        ,  0.18337242]])
-   
+
     '''
-    
+
     cdef int i, length
     cdef flatiter itera
     cdef dict bmap
@@ -105,33 +140,33 @@ def match(ndarray A, ndarray B):
     cdef ndarray result
 
     nan = <double> np.NaN
-    
+
     bmap = map_indices(B)
-        
+
     itera = PyArray_IterNew(A)
     length = PyArray_SIZE(A)
-    
+
     result = <ndarray> np.empty(length, np.float64)
 
-    result_data = <double *> result.data    
-    
+    result_data = <double *> result.data
+
     for i from 0 <= i < length:
         idx = PyArray_GETITEM(A, <void *> itera.dataptr)
         if idx in bmap:
             result_data[i] = <double> bmap[idx]
         else:
             result_data[i] = nan
-            
+
         PyArray_ITER_NEXT(itera)
-    
+
     return result.astype(int)
-    
+
 def reindex(ndarray index, ndarray arr, dict idxMap):
     '''
     Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to 
+    correpondences in the value array, return a new ndarray conforming to
     the new index.
-    
+
     This is significantly faster than doing it in pure Python.
     '''
     cdef ndarray result
@@ -140,11 +175,11 @@ def reindex(ndarray index, ndarray arr, dict idxMap):
     cdef flatiter itera, iteridx
     cdef double nan
     cdef object idx
-    
+
     nan = <double> np.NaN
 
     length = PyArray_SIZE(index)
-    
+
     result = <ndarray> np.empty(length, np.float64)
 
     result_data = <double *> result.data
@@ -166,9 +201,9 @@ def reindex(ndarray index, ndarray arr, dict idxMap):
 def reindexObj(ndarray index, ndarray arr, dict idxMap):
     '''
     Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to 
+    correpondences in the value array, return a new ndarray conforming to
     the new index.
-    
+
     This is significantly faster than doing it in pure Python.
     '''
     cdef ndarray result
@@ -179,7 +214,7 @@ def reindexObj(ndarray index, ndarray arr, dict idxMap):
     nan = np.NaN
     length = PyArray_SIZE(index)
 
-    result = <ndarray> np.empty(length, dtype=np.object_)    
+    result = <ndarray> np.empty(length, dtype=np.object_)
 
     itera = PyArray_IterNew(arr)
     iteridx = PyArray_IterNew(index)
@@ -190,27 +225,27 @@ def reindexObj(ndarray index, ndarray arr, dict idxMap):
     for i from 0 <= i < length:
         idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
         PyArray_ITER_NEXT(iteridx)
-        
+
         if idx not in idxMap:
             PyArray_SETITEM(result, <void *> iterresult.dataptr, nan)
             PyArray_ITER_NEXT(iterresult)
             continue
-            
+
         PyArray_ITER_GOTO1D(itera, idxMap[idx])
-        obj = PyArray_GETITEM(arr, <void *> itera.dataptr)        
-        
+        obj = PyArray_GETITEM(arr, <void *> itera.dataptr)
+
         res = PyArray_SETITEM(result, <void *> iterresult.dataptr, obj)
         PyArray_ITER_NEXT(iterresult)
-        
+
     return result
 
 @cython.boundscheck(False)
-def reindexObject(ndarray[object, ndim=1] index, 
+def reindexObject(ndarray[object, ndim=1] index,
                   ndarray[object, ndim=1] arr,
                   dict idxMap):
     '''
     Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to 
+    correpondences in the value array, return a new ndarray conforming to
     the new index.
     '''
     cdef int j, loc, length
@@ -219,7 +254,7 @@ def reindexObject(ndarray[object, ndim=1] index,
 
     length = index.shape[0]
     cdef ndarray[object, ndim = 1] result = np.empty(length, dtype=object)
-    
+
     loc = 0
     cdef int i = 0
     for i from 0 <= i < length:
@@ -240,15 +275,15 @@ cdef tuple _nofill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap)
     cdef object idx
     cdef ndarray fillVec
     cdef ndarray maskVec
-    
+
     fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
     maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
 
     fillLocs = <int *> fillVec.data
     mask = <char *> maskVec.data
-    
-    newLength = PyArray_SIZE(fillVec)    
-    
+
+    newLength = PyArray_SIZE(fillVec)
+
     length = PyArray_SIZE(oldIndex)
     iterold = PyArray_IterNew(oldIndex)
 
@@ -270,7 +305,7 @@ cdef tuple _nofill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap)
 cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
     '''
     Backfilling logic for generating fill vector
-    
+
     Diagram of what's going on
 
     Old      New    Fill vector    Mask
@@ -292,54 +327,54 @@ cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMa
              .                        0
     D
     '''
-    cdef int i, j, oldLength, newLength, curLoc 
+    cdef int i, j, oldLength, newLength, curLoc
     # Make empty vectors
     cdef ndarray fillVec
     cdef ndarray maskVec
     fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
     maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
-    
+
     # Get references
     cdef int *fillLocs
     cdef char *mask
     fillLocs = <int *> fillVec.data
     mask = <char *> maskVec.data
-    
+
     # Create the iterators
     cdef flatiter iterold, iternew
     iterold = PyArray_IterNew(oldIndex)
     iternew = PyArray_IterNew(newIndex)
-    
+
     # Get the size
     oldLength = PyArray_SIZE(oldIndex)
     newLength = PyArray_SIZE(newIndex)
-    
+
     # Current positions
     cdef int newPos, oldPos
     oldPos = oldLength - 1
     newPos = newLength - 1
-    
+
     # References holding indices
     cdef object prevOld, curOld
-    
+
     while newPos >= 0:
         # Move to the current position
         PyArray_ITER_GOTO1D(iternew, newPos)
         PyArray_ITER_GOTO1D(iterold, oldPos)
-        
+
         # Get the current index
         curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-        
+
         # Until we reach a point where we are before the curOld point
         while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > curOld:
             newPos -= 1
             if newPos < 0:
                 break
             PyArray_ITER_GOTO1D(iternew, newPos)
-        
+
         # Get the location in the old index
         curLoc = oldMap[curOld]
-        
+
         # At the beginning of the old index
         if oldPos == 0:
 
@@ -347,31 +382,31 @@ cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMa
             if PyArray_GETITEM(newIndex, <void *> iternew.dataptr) <= curOld:
                 fillVec[:newPos + 1] = curLoc
                 maskVec[:newPos + 1] = 1
-            
+
             # Exit the main loop
             break
 
         else:
             # Move one position back
             PyArray_ITER_GOTO1D(iterold, oldPos - 1)
-            
+
             # Get the index there
             prevOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
-            
+
             # Until we reach the previous index
             while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) > prevOld:
 
                 # Set the current fill location
                 fillLocs[newPos] = curLoc
                 mask[newPos] = 1
-                
+
                 newPos -= 1
                 if newPos < 0:
                     break
-                
+
                 # Move the iterator back
                 PyArray_ITER_GOTO1D(iternew, newPos)
-        
+
         # Move one period back
         oldPos -= 1
 
@@ -385,7 +420,7 @@ cdef tuple _backfill(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMa
 cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
     '''
     Padding logic for generating fill vector
-    
+
     Diagram of what's going on
 
     Old      New    Fill vector    Mask
@@ -414,19 +449,19 @@ cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
     cdef flatiter iterold, iternew
     cdef object nextOld, curOld
     cdef char done
-    
+
     # Make empty fill vector and mask vector, cast to ndarray
     fillVec = <ndarray> np.empty(len(newIndex), dtype = np.int32)
     maskVec = <ndarray> np.zeros(len(newIndex), dtype = np.int8)
-    
+
     # Get reference to the arrays inside
     fillLocs = <int *> fillVec.data
     mask = <char *> maskVec.data
-    
+
     # Create simple ndarray iterators using C API
     iterold = PyArray_IterNew(oldIndex)
     iternew = PyArray_IterNew(newIndex)
-    
+
     # Length of each index
     oldLength = PyArray_SIZE(oldIndex)
     newLength = PyArray_SIZE(newIndex)
@@ -436,7 +471,7 @@ cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
     while newPos < newLength:
         curOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
 
-        # At beginning, keep going until we go exceed the 
+        # At beginning, keep going until we go exceed the
         # first OLD index in the NEW index
         while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < curOld:
             newPos += 1
@@ -461,34 +496,34 @@ cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
             nextOld = PyArray_GETITEM(oldIndex, <void *> iterold.dataptr)
 
             done = 0
-            
+
             # Until we reach the next OLD value in the NEW index
             while PyArray_GETITEM(newIndex, <void *> iternew.dataptr) < nextOld:
-                
+
                 # Use this location to fill
                 fillLocs[newPos] = curLoc
 
                 # Set mask to be 1 so will not be NaN'd
                 mask[newPos] = 1
                 newPos += 1
-                
+
                 # We got to the end of the new index
                 if newPos > newLength - 1:
                     done = 1
                     break
-                
+
                 # Advance the pointer
                 PyArray_ITER_NEXT(iternew)
 
             # We got to the end of the new index
             if done:
                 break
-            
-        # We already advanced the iterold pointer to the next value, 
+
+        # We already advanced the iterold pointer to the next value,
         # inc the count
         oldPos += 1
 
-    # Places where the mask is 0, fill with an arbitrary value 
+    # Places where the mask is 0, fill with an arbitrary value
     # (will be NA'd out)
     for i from 0 <= i < newLength:
         if mask[i] == 0:
@@ -496,7 +531,7 @@ cdef tuple _pad(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap):
 
     return fillVec, maskVec
 
-def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap, 
+def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
                object kind):
 
     if kind == '':
@@ -505,27 +540,27 @@ def getFillVec(ndarray oldIndex, ndarray newIndex, dict oldMap, dict newMap,
         fillVec, maskVec = _pad(oldIndex, newIndex, oldMap, newMap)
     elif kind == 'BACKFILL':
         fillVec, maskVec = _backfill(oldIndex, newIndex, oldMap, newMap)
-    
+
     return fillVec, maskVec.astype(np.bool)
 
 def getMergeVec(ndarray values, dict indexMap):
-    cdef int *fillLocs    
+    cdef int *fillLocs
     cdef char *mask
     cdef int i, j, length
-    
+
     cdef flatiter itervals
     cdef object val
     cdef ndarray fillVec
     cdef ndarray maskVec
-    
+
     cdef int newLength = len(values)
-    
+
     fillVec = <ndarray> np.empty(newLength, dtype = np.int32)
     maskVec = <ndarray> np.zeros(newLength, dtype = np.int8)
 
     fillLocs = <int *> fillVec.data
     mask = <char *> maskVec.data
-        
+
     length = PyArray_SIZE(values)
     itervals = PyArray_IterNew(values)
 
@@ -537,7 +572,7 @@ def getMergeVec(ndarray values, dict indexMap):
             mask[i] = 1
 
         PyArray_ITER_NEXT(itervals)
-            
+
     for i from 0 <= i < newLength:
         if mask[i] == 0:
             fillLocs[i] = -1
@@ -548,31 +583,31 @@ cdef double INF = <double> np.inf
 cdef double NEGINF = -INF
 
 cdef inline _checknull(object val):
-    return val is None or val != val or val == INF or val == NEGINF    
+    return val is None or val != val or val == INF or val == NEGINF
 
 cdef ndarray _isnullobj(input):
     cdef int i, length
     cdef object val
-    cdef ndarray[npy_int8, ndim=1] result    
-    cdef flatiter iter 
+    cdef ndarray[npy_int8, ndim=1] result
+    cdef flatiter iter
 
     length = PyArray_SIZE(input)
-    
+
     result = <ndarray> np.zeros(length, dtype=np.int8)
-    
+
     iter= PyArray_IterNew(input)
-            
+
     for i from 0 <= i < length:
         val = PyArray_GETITEM(input, <void *> iter.dataptr)
-        
+
         if _checknull(val):
             result[i] = 1
 
         PyArray_ITER_NEXT(iter)
-            
+
     return result
-    
-def isnull(input):    
+
+def isnull(input):
     '''
     Replacement for numpy.isnan / -numpy.isfinite which is suitable
     for use on object arrays.
@@ -580,32 +615,32 @@ def isnull(input):
     Parameters
     ----------
     arr: ndarray or object value
-    
+
     Returns
     -------
     boolean ndarray or boolean
     '''
     cdef ndarray[npy_int8, ndim=1] result
-    
+
     if isinstance(input, np.ndarray):
         if input.dtype.kind in ('O', 'S'):
             result = _isnullobj(input)
-            
+
             return result.astype(np.bool)
         else:
             return -np.isfinite(input)
     else:
         return _checknull(input)
-    
-def notnull(input):    
+
+def notnull(input):
     '''
     Replacement for numpy.isfinite / -numpy.isnan which is suitable
     for use on object arrays.
-    
+
     Parameters
     ----------
     arr: ndarray or object value
-    
+
     Returns
     -------
     boolean ndarray or boolean
@@ -614,13 +649,13 @@ def notnull(input):
         return -isnull(input)
     else:
         return not bool(_checknull(input))
-    
+
 def reindexNew(ndarray index, ndarray arr, dict idxMap):
     '''
     Using the provided new index, a given array, and a mapping of index-value
-    correpondences in the value array, return a new ndarray conforming to 
+    correpondences in the value array, return a new ndarray conforming to
     the new index.
-    
+
     This is significantly faster than doing it in pure Python.
     '''
     cdef ndarray result
@@ -629,11 +664,11 @@ def reindexNew(ndarray index, ndarray arr, dict idxMap):
     cdef flatiter itera, iteridx
     cdef double nan
     cdef object idx
-    
+
     nan = <double> np.NaN
 
     length = PyArray_SIZE(index)
-    
+
     result = <ndarray> np.empty(length, np.float64)
 
     result_data = <double *> result.data
@@ -651,7 +686,7 @@ def reindexNew(ndarray index, ndarray arr, dict idxMap):
         result_data[i] = (<double *>(itera.dataptr))[0]
 
     return result
-    
+
 cdef double __add(double a, double b):
     return a + b
 cdef double __sub(double a, double b):
@@ -673,7 +708,7 @@ cdef double __pow(double a, double b):
 
 ctypedef double (* double_func)(double a, double b)
 
-cdef ndarray _applyFunc(double_func func, ndarray index, object ao, 
+cdef ndarray _applyFunc(double_func func, ndarray index, object ao,
                         object bo, dict aMap, dict bMap):
     '''
     C function taking a function pointer for quickly adding two Series objects.
@@ -684,39 +719,39 @@ cdef ndarray _applyFunc(double_func func, ndarray index, object ao,
     cdef flatiter itera, iterb, iteridx
     cdef double nan
     cdef object idx
-    
-    # This is EXTREMELY important, otherwise you will get very 
+
+    # This is EXTREMELY important, otherwise you will get very
     # undesired results
     A = PyArray_ContiguousFromAny(ao, NPY_DOUBLE, 1, 1)
     B = PyArray_ContiguousFromAny(bo, NPY_DOUBLE, 1, 1)
 
     nan = <double> np.NaN
     length = PyArray_SIZE(index)
-    
+
     result = <ndarray> np.empty(length, np.float64)
     result_data = <double *>result.data
-    
+
     itera = <flatiter> PyArray_IterNew(A)
     iterb = <flatiter> PyArray_IterNew(B)
     iteridx = PyArray_IterNew(index)
-    
+
     for i from 0 <= i < length:
         idx = PyArray_GETITEM(index, <void *> iteridx.dataptr)
         PyArray_ITER_NEXT(iteridx)
-        
+
         if idx not in aMap or idx not in bMap:
             result_data[i] = nan
             continue
 
-        result_data[i] = func((<double *>A.data)[aMap[idx]], 
+        result_data[i] = func((<double *>A.data)[aMap[idx]],
                             (<double *>B.data)[bMap[idx]])
-                                         
+
     return result
-    
-def combineFunc(object name, ndarray index, object ao, 
+
+def combineFunc(object name, ndarray index, object ao,
                 object bo, dict aMap, dict bMap):
     '''
-    Combine two series (values and index maps for each passed in) using the 
+    Combine two series (values and index maps for each passed in) using the
     indicated function.
     '''
     if name == "__add__":
@@ -739,7 +774,7 @@ def combineFunc(object name, ndarray index, object ao,
         return _applyFunc(__pow, index, ao, bo, aMap, bMap)
     else:
         raise Exception('bad funcname requested of Cython code')
-        
+
 #-------------------------------------------------------------------------------
 # Groupby-related functions
 
@@ -749,10 +784,10 @@ def arrmap(ndarray[object, ndim=1] index, object func):
     cdef int i = 0
 
     cdef ndarray[object, ndim=1] result = np.empty(length, dtype=np.object_)
-    
+
     for i from 0 <= i < length:
         result[i] = func(index[i])
-    
+
     return result
 
 @cython.boundscheck(False)
@@ -762,42 +797,42 @@ def groupby_withnull_old(ndarray[object, ndim = 1] index, object keyfunc):
     cdef object idx
     cdef object curKey, key
     cdef list members
-    
+
     groups = PyDict_New()
-    
+
     if length != index.shape[0]:
         raise Exception('Dates and values were not the same length!')
 
     cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
 
     cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
-    
-    bool_mask = null_mask.astype(bool)    
-    
+
+    bool_mask = null_mask.astype(bool)
+
     null_values = np.asarray(index)[bool_mask]
-    
+
     if null_values.any():
         PyDict_SetItem(groups, np.NaN, null_values)
-    
+
     cdef int i = 0
-    idx = index[0]    
+    idx = index[0]
     key = mapped_index[0]
-    
+
     # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem, 
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
     #   'lazily' evaluates
-    
-    while i < length:    
+
+    while i < length:
         if not PyDict_Contains(groups, key):
             members = [idx]
             PyDict_SetItem(groups, key, members)
             i += 1
-            curKey = key            
+            curKey = key
             while i < length:
                 if null_mask[i]:
                     i += 1
                     continue
-                    
+
                 idx = index[i]
                 key = mapped_index[i]
                 if key == curKey:
@@ -825,8 +860,8 @@ def groupby_withnull_old(ndarray[object, ndim = 1] index, object keyfunc):
                     i += 1
                 else:
                     break
-    
-    return groups 
+
+    return groups
 
 @cython.boundscheck(False)
 def groupby_withnull(ndarray[object, ndim = 1] index, object keyfunc):
@@ -835,42 +870,42 @@ def groupby_withnull(ndarray[object, ndim = 1] index, object keyfunc):
     cdef object idx
     cdef object curKey, key
     cdef list members
-    
+
     groups = PyDict_New()
-    
+
     if length != index.shape[0]:
         raise Exception('Dates and values were not the same length!')
 
     cdef ndarray[object, ndim=1] mapped_index = arrmap(index, keyfunc)
 
     cdef ndarray[npy_int8, ndim=1] null_mask = _isnullobj(mapped_index)
-    
-    bool_mask = null_mask.astype(bool)    
-    
+
+    bool_mask = null_mask.astype(bool)
+
     null_values = np.asarray(index)[bool_mask]
-    
+
     if null_values.any():
         PyDict_SetItem(groups, np.NaN, null_values)
-    
+
     cdef int i = 0
-    idx = index[0]    
+    idx = index[0]
     key = mapped_index[0]
 
     # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem, 
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
     #   'lazily' evaluates
-    
-    while i < length:    
+
+    while i < length:
         if key not in groups:
             members = [idx]
             groups[key] = members
             i += 1
-            curKey = key            
+            curKey = key
             while i < length:
                 if null_mask[i]:
                     i += 1
                     continue
-                    
+
                 idx = index[i]
                 key = mapped_index[i]
                 if key == curKey:
@@ -898,9 +933,9 @@ def groupby_withnull(ndarray[object, ndim = 1] index, object keyfunc):
                     i += 1
                 else:
                     break
-    
-    return groups 
-    
+
+    return groups
+
 @cython.boundscheck(False)
 def groupby(ndarray[object, ndim = 1] index, object keyfunc):
     cdef dict groups
@@ -908,9 +943,9 @@ def groupby(ndarray[object, ndim = 1] index, object keyfunc):
     cdef object idx
     cdef object curKey, key
     cdef list members
-    
+
     groups = PyDict_New()
-    
+
     if length != index.shape[0]:
         raise Exception('Dates and values were not the same length!')
 
@@ -920,7 +955,7 @@ def groupby(ndarray[object, ndim = 1] index, object keyfunc):
 
     # Algorithm notes
     #   - Tries to reduce the number of calls to PyDict_GetItem, 'lazily' evaluates
-    
+
     while i < length:
         if not PyDict_Contains(groups, key):
             members = [idx]
@@ -948,12 +983,12 @@ def groupby(ndarray[object, ndim = 1] index, object keyfunc):
                     i += 1
                 else:
                     break
-    
+
     return groups
-    
+
 @cython.boundscheck(False)
-def groupbyfunc(ndarray[object, ndim = 1] index, 
-                ndarray[npy_float64, ndim = 1] values, 
+def groupbyfunc(ndarray[object, ndim = 1] index,
+                ndarray[npy_float64, ndim = 1] values,
                 object keyfunc, object applyfunc):
     '''
     Doing this proper in Cython
@@ -964,9 +999,9 @@ def groupbyfunc(ndarray[object, ndim = 1] index,
     cdef object idx
     cdef object curKey, key
     cdef list members, grouplist
-    
+
     groups = PyDict_New()
-    
+
     if length != index.shape[0]:
         raise Exception('Dates and values were not the same length!')
 
@@ -975,10 +1010,10 @@ def groupbyfunc(ndarray[object, ndim = 1] index,
     key = trycall(keyfunc, idx)
 
     # Algorithm notes
-    #   - Tries to reduce the number of calls to PyDict_GetItem, 
+    #   - Tries to reduce the number of calls to PyDict_GetItem,
     #   'lazily' evaluates
-    
-    while i < length:        
+
+    while i < length:
         if not PyDict_Contains(groups, key):
             members = [values[i]]
             PyDict_SetItem(groups, key, members)
@@ -1007,13 +1042,12 @@ def groupbyfunc(ndarray[object, ndim = 1] index,
                     break
 
     grouplist = PyDict_Keys(groups)
-    
+
     i = 0
     length = len(grouplist)
     for i from 0 <= i < length:
         key = grouplist[i]
         members = <list> PyDict_GetItem(groups, key)
         PyDict_SetItem(groups, key, applyfunc(np.asarray(members)))
-    
-    return groups
 
+    return groups
diff --git a/pandas/lib/src/wirth.c b/pandas/lib/src/wirth.c
new file mode 100644
index 000000000..23841d3b1
--- /dev/null
+++ b/pandas/lib/src/wirth.c
@@ -0,0 +1,54 @@
+/*
+ * Algorithm from N. Wirth's book, implementation by N. Devillard.
+ * This code in public domain.
+ */
+
+#include <wirth.h>
+
+#define ELEM_SWAP(a,b) { register double t=(a);(a)=(b);(b)=t; }
+
+
+/*---------------------------------------------------------------------------
+   Function :   kth_smallest()
+   In       :   array of elements, # of elements in the array, rank k
+   Out      :   one element
+   Job      :   find the kth smallest element in the array
+   Notice   :   use the median() macro defined below to get the median.
+
+                Reference:
+
+                  Author: Wirth, Niklaus
+                   Title: Algorithms + data structures = programs
+               Publisher: Englewood Cliffs: Prentice-Hall, 1976
+    Physical description: 366 p.
+                  Series: Prentice-Hall Series in Automatic Computation
+
+ ---------------------------------------------------------------------------*/
+
+
+double kth_smallest(double a[], int n, int k)
+{
+    register int i,j,l,m ;
+    register double x ;
+
+    l=0 ; m=n-1 ;
+    while (l<m) {
+        x=a[k] ;
+        i=l ;
+        j=m ;
+        do {
+            while (a[i] < x) i++ ;
+            while (x < a[j]) j-- ;
+            if (i<=j) {
+                ELEM_SWAP(a[i], a[j]) ;
+                i++ ; j-- ;
+            }
+        } while (i<=j) ;
+        if (j<k) l=i ;
+        if (k<i) m=j ;
+    }
+    return a[k] ;
+}
+
+
+#define median(a,n) kth_smallest(a,n,(((n)&1)?((n)/2):(((n)/2)-1)))
diff --git a/pandas/stats/linmodel.py b/pandas/stats/linmodel.py
index 4b9751ffa..3068ba1e2 100644
--- a/pandas/stats/linmodel.py
+++ b/pandas/stats/linmodel.py
@@ -496,7 +496,7 @@ class XSLinearModel(LinearModel):
 
         try:
             end = self.endSlice[period2]
-        except:
+        except Exception, e:
             period2 = max((k for k in self.endSlice.keys() if k < period2))
             end = self.endSlice[period2]
 
@@ -571,7 +571,7 @@ class XSLinearModel(LinearModel):
                 oneDaySlice = self.getDataSlice(period, period)
                 unstacked = resid.reindex(oneDaySlice.index).unstack()
                 self._resid[period] = unstacked[period]
-            except:
+            except Exception, e:
                 raise
 
     def _calcNWTstats(self, panelSlice, design, beta, resids):
