commit f151973d489fd4b497a836a67725187ad792ed6b
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Sep 1 20:03:54 2012 -0400

    ENH: structured array conversion and support code

diff --git a/pandas/src/datetime.pxd b/pandas/src/datetime.pxd
index 2147c2676..d1b5a861f 100644
--- a/pandas/src/datetime.pxd
+++ b/pandas/src/datetime.pxd
@@ -1,6 +1,8 @@
 from numpy cimport int64_t, int32_t, npy_int64, npy_int32
 from cpython cimport PyObject
 
+from cpython cimport PyUnicode_Check, PyUnicode_AsASCIIString
+
 
 cdef extern from "stdint.h":
     enum: INT64_MIN
@@ -113,3 +115,28 @@ cdef extern from "datetime/np_datetime_strings.h":
     int get_datetime_iso_8601_strlen(int local, PANDAS_DATETIMEUNIT base)
 
     # int parse_python_string(object obj, pandas_datetimestruct *out) except -1
+
+cdef inline _string_to_dts(object val, pandas_datetimestruct* dts):
+    cdef int result
+    cdef char *tmp
+
+    if PyUnicode_Check(val):
+        val = PyUnicode_AsASCIIString(val);
+
+    tmp = val
+    result = _cstring_to_dts(tmp, len(val), dts)
+
+    if result == -1:
+        raise ValueError('Unable to parse %s' % str(val))
+
+cdef inline int _cstring_to_dts(char *val, int length,
+                                pandas_datetimestruct* dts):
+    cdef:
+        npy_bool islocal, special
+        PANDAS_DATETIMEUNIT out_bestunit
+        int result
+
+    result = parse_iso_8601_datetime(val, length, PANDAS_FR_ns,
+                                     NPY_UNSAFE_CASTING,
+                                     dts, &islocal, &out_bestunit, &special)
+    return result
diff --git a/pandas/src/datetime.pyx b/pandas/src/datetime.pyx
index b6e0b9eb4..426892b80 100644
--- a/pandas/src/datetime.pyx
+++ b/pandas/src/datetime.pyx
@@ -639,21 +639,6 @@ cdef inline int64_t _date_to_datetime64(object val,
     return pandas_datetimestruct_to_datetime(PANDAS_FR_ns, dts)
 
 
-cdef inline _string_to_dts(object val, pandas_datetimestruct* dts):
-    cdef:
-        npy_bool islocal, special
-        PANDAS_DATETIMEUNIT out_bestunit
-        int result
-
-    if PyUnicode_Check(val):
-        val = PyUnicode_AsASCIIString(val);
-
-    result = parse_iso_8601_datetime(val, len(val), PANDAS_FR_ns,
-                                     NPY_UNSAFE_CASTING,
-                                     dts, &islocal, &out_bestunit, &special)
-    if result == -1:
-        raise ValueError('Unable to parse %s' % str(val))
-
 def datetime_to_datetime64(ndarray[object] values):
     cdef:
         Py_ssize_t i, n = len(values)
diff --git a/pandas/src/numpy_helper.h b/pandas/src/numpy_helper.h
index 053cd8aea..9ae0a047c 100644
--- a/pandas/src/numpy_helper.h
+++ b/pandas/src/numpy_helper.h
@@ -143,6 +143,31 @@ PANDAS_INLINE PyObject* floatify(PyObject* str) {
 
 }
 
+PyObject* sarr_from_data(PyArray_Descr *descr, int length, void* data) {
+	npy_intp dims[1] = {length};
+	Py_INCREF(descr);
+	return (PyObject*) PyArray_NewFromDescr(&PyArray_Type, descr, 1, dims,
+											NULL, data, 0, NULL);
+}
+
+void transfer_object_column(char *dst, char *src, size_t stride,
+							size_t length) {
+	int i;
+	size_t sz = sizeof(PyObject*);
+
+	for (i = 0; i < length; ++i)
+	{
+		// uninitialized data
+
+		// Py_XDECREF(*((PyObject**) dst));
+
+		memcpy(dst, src, sz);
+		Py_INCREF(*((PyObject**) dst));
+		src += sz;
+		dst += stride;
+	}
+}
+
 
 // PANDAS_INLINE PyObject*
 // get_base_ndarray(PyObject* ap) {
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index 4c15890b2..0f4407147 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -1,21 +1,31 @@
-from libc.stdlib cimport free
+from libc.stdlib cimport malloc, free
+
+from cpython cimport (PyObject, PyString_FromString,
+                      PyString_AsString, PyString_Check)
+
+cdef extern from "stdlib.h":
+    void memcpy(void *dst, void *src, size_t n)
+
+cimport numpy as cnp
+
+from numpy cimport ndarray, uint8_t, uint64_t
 
-from numpy cimport *
 import numpy as np
 
+cdef extern from "Python.h":
+    void Py_INCREF(PyObject*)
+    void Py_XDECREF(PyObject*)
+
 cimport util
 
 import pandas.lib as lib
 
 import time
 
-import_array()
+cnp.import_array()
 
 from khash cimport *
 
-from cpython cimport (PyString_FromString, Py_INCREF, PyString_AsString,
-                      PyString_Check)
-
 cdef extern from "stdint.h":
     enum: UINT8_MAX
     enum: INT8_MIN
@@ -50,7 +60,6 @@ cdef extern from "parser/parser.h":
         QUOTE_IN_QUOTED_FIELD
         EAT_CRNL
         EAT_WHITESPACE
-        FINISHED
 
     ctypedef struct table_chunk:
         void **columns
@@ -139,8 +148,8 @@ cdef extern from "parser/parser.h":
 
     parser_t* parser_new()
 
-    int parser_init(parser_t *self)
-    void parser_free(parser_t *self)
+    int parser_init(parser_t *self) nogil
+    void parser_free(parser_t *self) nogil
 
     void parser_set_default_options(parser_t *self)
 
@@ -150,8 +159,8 @@ cdef extern from "parser/parser.h":
 
     void debug_print_parser(parser_t *self)
 
-    int tokenize_all_rows(parser_t *self)
-    int tokenize_nrows(parser_t *self, size_t nrows)
+    int tokenize_all_rows(parser_t *self) nogil
+    int tokenize_nrows(parser_t *self, size_t nrows) nogil
 
     int64_t str_to_int64(char *p_item, int64_t int_min,
                          int64_t int_max, int *error)
@@ -171,11 +180,12 @@ cdef class TextReader:
     cdef:
         parser_t *parser
         object file_handle, should_close
-        bint factorize
+        bint factorize, na_filter
 
     cdef public:
         object delimiter, na_values, converters, thousands, delim_whitespace
         object memory_map
+        object as_recarray
 
     def __cinit__(self, source, delimiter=',', header=0,
                   memory_map=False,
@@ -185,7 +195,9 @@ cdef class TextReader:
                   converters=None,
                   thousands=None,
                   factorize=True,
-                  skipinitialspace=False):
+                  as_recarray=False,
+                  skipinitialspace=False,
+                  na_filter=True):
         self.parser = parser_new()
         self.parser.chunksize = tokenize_chunksize
 
@@ -218,6 +230,9 @@ cdef class TextReader:
         self.converters = converters
         self.thousands = thousands
 
+        self.na_filter = na_filter
+        self.as_recarray = as_recarray
+
     def __dealloc__(self):
         parser_free(self.parser)
 
@@ -278,7 +293,8 @@ cdef class TextReader:
         if rows is not None:
             raise NotImplementedError
         else:
-            status = tokenize_all_rows(self.parser)
+            with nogil:
+                status = tokenize_all_rows(self.parser)
 
         # end = time.clock()
         # print 'Tokenization took %.4f sec' % (end - start)
@@ -286,10 +302,22 @@ cdef class TextReader:
         if status < 0:
             raise_parser_error('Error tokenizing data', self.parser)
 
-        result = self._convert_column_data()
+        # start = time.clock()
+        columns, names = self._convert_column_data()
+        # end = time.clock()
+        # print 'Type conversion took %.4f sec' % (end - start)
 
         # debug_print_parser(self.parser)
-        return result
+
+        if self.as_recarray:
+            # start = time.clock()
+            result = _to_structured_array(columns, names)
+            # end = time.clock()
+            # print 'to_structured_array took %.4f sec' % (end - start)
+
+            return result
+        else:
+            return columns
 
     def _convert_column_data(self):
         cdef:
@@ -306,10 +334,15 @@ cdef class TextReader:
         start = 0
         end = self.parser.lines
 
+        names = []
+
         results = {}
         for i in range(ncols):
-            na_mask = _get_na_mask(self.parser, i, start, end, table)
-            na_filter = 1
+            # XXX
+            if self.na_filter:
+                na_mask = _get_na_mask(self.parser, i, start, end, table)
+            else:
+                na_mask = None
 
             conv = self._get_converter(i)
 
@@ -321,7 +354,7 @@ cdef class TextReader:
             col_res = None
             for func in cast_func_order:
                 col_res = func(self.parser, i, start, end,
-                               na_mask, na_filter)
+                               na_mask, self.na_filter)
                 if col_res is not None:
                     results[i] = col_res
                     break
@@ -329,12 +362,13 @@ cdef class TextReader:
             if col_res is None:
                 raise Exception('Unable to parse column %d' % i)
 
+            names.append(i)
             results[i] = col_res
 
         # XXX: needs to be done elsewhere
         kh_destroy_str(table)
 
-        return results
+        return results, names
 
     def _get_converter(self, col):
         if self.converters is None:
@@ -430,12 +464,10 @@ cdef _try_double(parser_t *parser, int col, int line_start, int line_end,
         na_mask = _na_mask
 
     lines = line_end - line_start
-
     result = np.empty(lines, dtype=np.float64)
-
     data = <double *> result.data
-
     coliter_setup(&it, parser, col)
+
     if na_filter:
         for i in range(lines):
             word = COLITER_NEXT(it)
@@ -518,13 +550,9 @@ cdef _try_bool(parser_t *parser, int col, int line_start, int line_end,
         na_mask = _na_mask
 
     na_count = 0
-
     lines = line_end - line_start
-
     result = np.empty(lines, dtype=np.uint8)
-
     data = <uint8_t *> result.data
-
     coliter_setup(&it, parser, col)
 
     if na_filter:
@@ -658,3 +686,68 @@ cdef _apply_converter(object f, parser_t *parser, int col,
         result[i] = f(val)
 
     return lib.maybe_convert_objects(result)
+
+def _to_structured_array(dict columns, object colnames):
+    cdef:
+        ndarray recs, column
+        cnp.dtype dt
+        dict fields
+
+        object name, fnames, field_type
+        Py_ssize_t i, offset, nfields, length
+        int stride, elsize
+        char *buf
+
+    dt = np.dtype([(str(name), columns[name].dtype) for name in colnames])
+    fnames = dt.names
+    fields = dt.fields
+
+    nfields = len(fields)
+
+    length = len(columns.values()[0])
+    stride = dt.itemsize
+
+    # start = time.clock()
+
+    # we own the data
+    buf = <char*> malloc(length * stride)
+
+    recs = util.sarr_from_data(dt, length, buf)
+
+    # buf = <char*> recs.data
+    # end = time.clock()
+    # print 'took %.4f' % (end - start)
+
+    for i in range(nfields):
+        # start = time.clock()
+        name = colnames[i]
+
+        # XXX
+        field_type = fields[fnames[i]]
+
+        # (dtype, stride) tuple
+        offset = field_type[1]
+        elsize = field_type[0].itemsize
+        column = columns[name]
+
+        _fill_structured_column(buf + offset, <char*> column.data,
+                                elsize, stride, length,
+                                field_type[0] == np.object_)
+
+        # print 'Transfer of %s took %.4f' % (str(field_type),
+        #                                     time.clock() - start)
+
+    return recs
+
+cdef _fill_structured_column(char *dst, char* src, int elsize,
+                             int stride, int length, bint incref):
+    cdef:
+        size_t i
+
+    if incref:
+        util.transfer_object_column(dst, src, stride, length)
+    else:
+        for i in range(length):
+            memcpy(dst, src, elsize)
+            dst += stride
+            src += elsize
diff --git a/pandas/src/parser/parser.h b/pandas/src/parser/parser.h
index 1635fa85d..374699e9d 100644
--- a/pandas/src/parser/parser.h
+++ b/pandas/src/parser/parser.h
@@ -87,8 +87,7 @@ typedef enum {
     ESCAPE_IN_QUOTED_FIELD,
     QUOTE_IN_QUOTED_FIELD,
     EAT_CRNL,
-    EAT_WHITESPACE,
-    FINISHED
+    EAT_WHITESPACE
 } ParserState;
 
 typedef enum {
diff --git a/pandas/src/util.pxd b/pandas/src/util.pxd
index f25f7b55c..a9922e461 100644
--- a/pandas/src/util.pxd
+++ b/pandas/src/util.pxd
@@ -14,6 +14,9 @@ cdef extern from "numpy_helper.h":
     inline char *get_c_string(object)
     inline object floatify(object)
     inline object char_to_string(char*)
+    inline void transfer_object_column(char *dst, char *src, size_t stride,
+                                       size_t length)
+    object sarr_from_data(cnp.dtype, int length, void* data)
 
 cdef inline object get_value_at(ndarray arr, object loc):
     cdef:
