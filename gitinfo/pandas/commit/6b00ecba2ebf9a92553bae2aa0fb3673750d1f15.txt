commit 6b00ecba2ebf9a92553bae2aa0fb3673750d1f15
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Dec 30 19:03:07 2011 -0500

    ENH: use factorizer methodology to speedup many-to-use joins, 30% speedup

diff --git a/pandas/src/hashtable.pyx b/pandas/src/hashtable.pyx
index 8c3e70389..28d513d9a 100644
--- a/pandas/src/hashtable.pyx
+++ b/pandas/src/hashtable.pyx
@@ -669,6 +669,74 @@ cdef class Int64Factorizer:
         self.count = len(counts)
         return labels, counts
 
+cdef class DictFactorizer:
+
+    cdef public:
+        dict table
+        list uniques
+        Py_ssize_t count
+
+    def __init__(self, table=None, uniques=None):
+        if table is None:
+            self.table = {}
+        else:
+            self.table = table
+
+        if uniques is None:
+            self.uniques = []
+            self.count = 0
+        else:
+            self.uniques = uniques
+            self.count = len(uniques)
+
+    def get_count(self):
+        return self.count
+
+    def get_labels(self, ndarray[object] values):
+        cdef:
+            Py_ssize_t i, n = len(values)
+            ndarray[int32_t] labels
+            ndarray[int32_t] counts
+            Py_ssize_t idx, count = self.count
+            int ret
+            object val
+            khiter_t k
+
+        labels = np.empty(n, dtype=np.int32)
+        counts = np.empty(count + n, dtype=np.int32)
+
+        for i in range(n):
+            val = values[i]
+
+            if val in self.table:
+                idx = self.table[val]
+                labels[i] = idx
+                counts[idx] = counts[idx] + 1
+            else:
+                self.table[val] = count
+                self.uniques.append(val)
+                labels[i] = count
+                counts[count] = 1
+                count += 1
+
+        return labels, counts[:count].copy()
+
+    def factorize(self, ndarray[object] values, sort=False):
+        labels, counts = self.get_labels(values)
+
+        # sort on
+        if sort:
+            sorter = list_to_object_array(self.uniques).argsort()
+            reverse_indexer = np.empty(len(sorter), dtype=np.int32)
+            reverse_indexer.put(sorter, np.arange(len(sorter)))
+
+            labels = reverse_indexer.take(labels)
+            counts = counts.take(sorter)
+
+        self.count = len(counts)
+        return labels, counts
+
+
 def lookup_locations2(ndarray[object] values):
     cdef:
         Py_ssize_t i, n = len(values)
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 3fae971e5..222d4a520 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -5,7 +5,8 @@ SQL-style merge routines
 import numpy as np
 
 from pandas.core.frame import DataFrame
-from pandas.core.index import Index
+from pandas.core.groupby import get_group_index
+from pandas.core.index import Index, MultiIndex
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
                                    make_block, _consolidate)
 from pandas.util.decorators import cache_readonly
@@ -146,22 +147,26 @@ class _MergeOperation(object):
 
             # oh this is odious
             if len(self.left_join_keys) > 1:
-                join_key = lib.fast_zip(self.left_join_keys)
+                assert(isinstance(right_ax, MultiIndex) and
+                       len(self.left_join_keys) == right_ax.nlevels)
+
+                right_indexer = _get_multiindex_indexer(self.left_join_keys,
+                                                        right_ax)
             else:
-                join_key = self.left_join_keys[0]
+                right_indexer = right_ax.get_indexer(self.left_join_keys[0])
 
-            right_indexer = right_ax.get_indexer(join_key)
         elif self.left_index and self.how == 'right':
             join_index = right_ax
             right_indexer = None
 
             # oh this is odious
             if len(self.right_join_keys) > 1:
-                join_key = lib.fast_zip(self.right_join_keys)
+                assert(isinstance(left_ax, MultiIndex) and
+                       len(self.right_join_keys) == left_ax.nlevels)
+                left_indexer = _get_multiindex_indexer(self.right_join_keys,
+                                                       left_ax)
             else:
-                join_key = self.right_join_keys[0]
-
-            left_indexer = left_ax.get_indexer(join_key)
+                left_indexer = left_ax.get_indexer(self.right_join_keys[0])
         else:
             # max groups = largest possible number of distinct groups
             left_key, right_key, max_groups = \
@@ -283,8 +288,6 @@ def _get_group_keys(left_keys, right_keys, sort=True):
     -------
 
     """
-    from pandas.core.groupby import get_group_index
-
     assert(len(left_keys) == len(right_keys))
 
     left_labels = []
@@ -310,6 +313,25 @@ def _get_group_keys(left_keys, right_keys, sort=True):
 
     return left_group_key, right_group_key, max_groups
 
+
+def _get_multiindex_indexer(join_keys, index):
+    shape = []
+    labels = []
+    for level, key in zip(index.levels, join_keys):
+        rizer = lib.DictFactorizer(level.indexMap, list(level))
+        lab, _ = rizer.factorize(key)
+        labels.append(lab)
+        shape.append(len(rizer.uniques))
+
+    left_group_key = get_group_index(labels, shape).astype('i4')
+    right_group_key = get_group_index(index.labels, shape).astype('i4')
+    left_indexer, right_indexer = \
+        lib.left_outer_join(left_group_key, right_group_key,
+                            np.prod(shape))
+
+    # NOW! reorder
+    return right_indexer.take(left_indexer.argsort())
+
 def _maybe_make_list(obj):
     if obj is not None and not isinstance(obj, (tuple, list)):
         return [obj]
