commit 4093cd9d01d50be2a89b0aaf926839d01e3d99ff
Author: Phillip Cloud <cpcloud@gmail.com>
Date:   Mon Jul 22 16:48:54 2013 -0400

    ENH: add chained comparisons

diff --git a/doc/source/api.rst b/doc/source/api.rst
index 837afb899..affa84078 100644
--- a/doc/source/api.rst
+++ b/doc/source/api.rst
@@ -158,7 +158,7 @@ Top-level dealing with datetimes
 Top-level evaluation
 ~~~~~~~~~~~~~~~~~~~~
 
-.. currentmodule:: pandas.computation.eval
+.. currentmodule:: pandas
 
 .. autosummary::
    :toctree: generated/
diff --git a/doc/source/enhancingperf.rst b/doc/source/enhancingperf.rst
index 3f3a31879..47d2acc57 100644
--- a/doc/source/enhancingperf.rst
+++ b/doc/source/enhancingperf.rst
@@ -292,53 +292,53 @@ Read more in the `cython docs <http://docs.cython.org/>`__.
 
 .. _enhancingperf.eval:
 
-Expression Evaluation via :func:`~pandas.computation.eval.eval`
----------------------------------------------------------------
+.. versionadded:: 0.13
 
-New in pandas v0.13 a top-level function :func:`~pandas.computation.eval.eval`
-implements expression evaluation of expressions containing
-:class:`~pandas.core.series.Series` and :class:`~pandas.core.frame.DataFrame`
-objects.
+Expression Evaluation via :func:`~pandas.eval`
+----------------------------------------------
+
+New in pandas v0.13 a top-level function :func:`~pandas.eval` implements
+expression evaluation of expressions containing :class:`~pandas.Series` and
+:class:`~pandas.DataFrame` objects.
 
 .. note::
 
-   To benefit from using :func:`~pandas.computation.eval.eval` you need to
+   To benefit from using :func:`~pandas.eval` you need to
    install ``numexpr``. See the :ref:`recommended dependencies section
    <install.recommended_dependencies>` for more details.
 
-The major benefit of using :func:`~pandas.computation.eval.eval` for expression
-evaluation rather than just straight-up Python is two-fold: large
-:class:`~pandas.core.frame.DataFrame` objects are evaluated more efficiently
-and large expressions are evaluated all at once by the underlying engine (by
-default ``numexpr`` is used for evaluation).
+The major benefit of using :func:`~pandas.eval` for expression evaluation
+rather than just straight-up Python is two-fold: large
+:class:`~pandas.DataFrame` objects are evaluated more efficiently and large
+expressions are evaluated all at once by the underlying engine (by default
+``numexpr`` is used for evaluation).
 
 .. note::
 
-   You should not use :func:`~pandas.computation.eval.eval` for simple
+   You should not use :func:`~pandas.eval` for simple
    expressions or for expressions involving small DataFrames. In fact,
-   :func:`~pandas.computation.eval.eval` is many orders of magnitude slower for
-   smaller expressions/objects than plain ole' Python. A good rule of thumb is
-   to only use :func:`~pandas.computation.eval.eval` when you have a
+   :func:`~pandas.eval` is many orders of magnitude slower for
+   smaller expressions/objects than plain ol' Python. A good rule of thumb is
+   to only use :func:`~pandas.eval` when you have a
    :class:`~pandas.core.frame.DataFrame` with more than 10,000 rows.
 
 
-:func:`~pandas.computation.eval.eval` supports all arithmetic expressions
-supported by the engine (by default the engine is ``numexpr``). The ``numexpr``
-engine uses ``numexpr`` under the hood to evaluate expressions efficiently,
-while allowing a slightly modified, and we think more intuitive syntax for
-expressions.
+:func:`~pandas.eval` supports all arithmetic expressions
+supported by the engine. The ``numexpr`` engine uses ``numexpr`` under the hood
+to evaluate expressions efficiently, while allowing a slightly modified--and we
+think more intuitive--syntax for expressions.
 
 
 .. note::
 
    The larger the frame and the larger the expression the more speedup you will
-   see from using :func:`~pandas.computation.eval.eval`.
+   see from using :func:`~pandas.eval`.
 
 
-:func:`~pandas.computation.eval.eval` Examples
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+:func:`~pandas.eval` Examples
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-:func:`~pandas.computation.eval.eval` works wonders for expressions containing
+:func:`~pandas.eval` works wonders for expressions containing
 large arrays
 
 First let's create 4 decent-sized arrays to play with:
@@ -354,7 +354,7 @@ First let's create 4 decent-sized arrays to play with:
 
 
 Now let's compare adding them together using plain ol' Python versus
-:func:`~pandas.computation.eval.eval`:
+:func:`~pandas.eval`:
 
 
 .. ipython:: python
@@ -377,8 +377,7 @@ Now let's do the same thing but with comparisons:
    %timeit pd.eval('(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)')
 
 
-:func:`~pandas.computation.eval.eval` also works with "unaligned" pandas
-objects:
+:func:`~pandas.eval` also works with "unaligned" pandas objects:
 
 
 .. ipython:: python
@@ -393,18 +392,17 @@ objects:
 There are also two different flavors of parsers and and two different engines
 to use as the backend.
 
-:func:`~pandas.computation.eval.eval` Parsers
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+:func:`~pandas.eval` Parsers
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-The default ``"pandas"`` parser allows a bit more intuitive (we think) syntax
-for expressing query-like operations (comparisons, conjunctions and
-disjunctions). In particular, the precedence of the ``&`` and ``|`` operators
-is made equal to the precedence of the corresponding boolean operations ``and``
-and ``or``.
+The default ``"pandas"`` parser allows a more intuitive syntax for expressing
+query-like operations (comparisons, conjunctions and disjunctions). In
+particular, the precedence of the ``&`` and ``|`` operators is made equal to
+the precedence of the corresponding boolean operations ``and`` and ``or``.
 
-For example, the above conjunction can be written without
-parentheses. Alternatively, you can use the ``'python'`` parser to enforce
-strict Python semantics.
+For example, the above conjunction can be written without parentheses.
+Alternatively, you can use the ``'python'`` parser to enforce strict Python
+semantics.
 
 .. ipython:: python
 
@@ -415,23 +413,34 @@ strict Python semantics.
    np.all(x == y)
 
 
-:func:`~pandas.computation.eval.eval` Backends
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+The same expression can be "anded" with the word :keyword:`and` as well:
+
+.. ipython:: python
+
+   expr = '(df1 > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)'
+   x = pd.eval(expr, parser='python')
+   expr_with_ands = 'df1 > 0 and df2 > 0 and df3 > 0 and df4 > 0'
+   y = pd.eval(expr_with_ands, parser='pandas')
+   np.all(x == y)
+
+
+:func:`~pandas.eval` Backends
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-There's also the option to make :func:`~pandas.computation.eval.eval` operate
-identical to plain ol' Python.
+There's also the option to make :func:`~pandas.eval` operate identical to plain
+ol' Python.
 
 .. note::
 
    Using the ``'python'`` engine is generally *not* useful, except for
    comparing performance and testing other
-   :func:`~pandas.computation.eval.eval` engines against it. You will acheive
-   **no** performance benefits using :func:`~pandas.computation.eval.eval` with
+   :func:`~pandas.eval` engines against it. You will acheive
+   **no** performance benefits using :func:`~pandas.eval` with
    ``engine='python'``.
 
-You can see this by using :func:`~pandas.computation.eval.eval` with the
-``'python'`` engine is actually a bit slower (not by much) than evaluating the
-same expression in Python:
+You can see this by using :func:`~pandas.eval` with the ``'python'`` engine is
+actually a bit slower (not by much) than evaluating the same expression in
+Python:
 
 .. ipython:: python
 
diff --git a/doc/source/io.rst b/doc/source/io.rst
index a20d2a7aa..dff1b4836 100644
--- a/doc/source/io.rst
+++ b/doc/source/io.rst
@@ -2003,8 +2003,9 @@ These rules are similar to how boolean expressions are used in pandas for indexi
 .. note::
 
    - ``=`` will be automatically expanded to the comparison operator ``==``
-   - ``~`` is the not operator, but can only be used in very limited circumstances
-   - If a list/tuple of expressions are passed they will be combined via ``&``.
+   - ``~`` is the not operator, but can only be used in very limited
+     circumstances
+   - If a list/tuple of expressions is passed they will be combined via ``&``
 
 The following are valid expressions:
 
@@ -2022,7 +2023,7 @@ The ``indexers`` are on the left-hand side of the sub-expression:
 
    - ``columns``, ``major_axis``, ``ts``
 
-The right-hand side of the sub-expression (after a comparsion operator), can be:
+The right-hand side of the sub-expression (after a comparsion operator) can be:
 
    - functions that will be evaluated, e.g. ``Timestamp('2012-02-01')``
    - strings, e.g. ``"bar"``
@@ -2038,8 +2039,9 @@ Here is an example:
    store
    store.select('wp', "major_axis>Timestamp('20000102') & minor_axis=['A', 'B']")
 
-The ``columns`` keyword can be supplied to select a list of columns to be returned,
-this is equivalent to passing a ``'columns=list_of_columns_to_filter'``:
+The ``columns`` keyword can be supplied to select a list of columns to be
+returned, this is equivalent to passing a
+``'columns=list_of_columns_to_filter'``:
 
 .. ipython:: python
 
diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index 09606fc41..fcc1dd1b0 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -1,3 +1,4 @@
+import warnings
 from functools import partial, wraps
 from itertools import izip
 
@@ -6,7 +7,6 @@ import numpy as np
 import pandas as pd
 import pandas.core.common as com
 from pandas.computation.ops import is_const
-from pandas.computation.common import flatten
 
 
 def _align_core_single_unary_op(term):
@@ -123,11 +123,23 @@ def _align_core(terms):
 
             if hasattr(ti, 'reindex_axis'):
                 transpose = com.is_series(ti) and naxes > 1
+                reindexer = axes[naxes - 1] if transpose else items
+
+                term_axis_size = len(ti.axes[axis])
+                reindexer_size = len(reindexer)
+
+                if (np.log10(abs(reindexer_size - term_axis_size)) >= 1 and
+                    reindexer_size >= 10000):
+                    warnings.warn("Alignment difference on axis {0} is larger"
+                                  " than an order of magnitude on term {1!r}, "
+                                  "performance may suffer".format(axis, term),
+                                  category=pd.io.common.PerformanceWarning)
 
                 if transpose:
-                    f = partial(ti.reindex, index=axes[naxes - 1], copy=False)
+                    f = partial(ti.reindex, index=reindexer, copy=False)
                 else:
-                    f = partial(ti.reindex_axis, items, axis=axis, copy=False)
+                    f = partial(ti.reindex_axis, reindexer, axis=axis,
+                                copy=False)
 
                 if pd.lib.is_bool_array(ti.values):
                     r = f(fill_value=True)
@@ -168,7 +180,7 @@ def _align(terms):
     """Align a set of terms"""
     try:
         # flatten the parse tree (a nested list, really)
-        terms = list(flatten(terms))
+        terms = list(com.flatten(terms))
     except TypeError:
         # can't iterate so it must just be a constant or single variable
         if isinstance(terms.value, (pd.Series, pd.core.generic.NDFrame)):
diff --git a/pandas/computation/common.py b/pandas/computation/common.py
index 4061984dd..e69de29bb 100644
--- a/pandas/computation/common.py
+++ b/pandas/computation/common.py
@@ -1,11 +0,0 @@
-import collections
-from pandas.core.common import is_string
-
-
-def flatten(l):
-    for el in l:
-        if isinstance(el, collections.Iterable) and not is_string(el):
-            for s in flatten(el):
-                yield s
-        else:
-            yield el
diff --git a/pandas/computation/eval.py b/pandas/computation/eval.py
index 5f234b786..abd4785cb 100644
--- a/pandas/computation/eval.py
+++ b/pandas/computation/eval.py
@@ -4,11 +4,12 @@ import numbers
 
 import numpy as np
 
-from pandas.computation.expr import Expr, Scope, _parsers
+from pandas.computation.expr import Expr, _parsers, _ensure_scope
 from pandas.computation.engines import _engines
 
 
 def _check_engine(engine):
+    """make sure a valid engine is passed"""
     if engine not in _engines:
         raise KeyError('Invalid engine {0!r} passed, valid engines are'
                        ' {1}'.format(engine, _engines.keys()))
@@ -21,79 +22,96 @@ def _check_engine(engine):
 
 
 def _check_parser(parser):
+    """make sure a valid parser is passed"""
     if parser not in _parsers:
         raise KeyError('Invalid parser {0!r} passed, valid parsers are'
                        ' {1}'.format(parser, _parsers.keys()))
 
-
-
 def eval(expr, parser='pandas', engine='numexpr', truediv=True,
          local_dict=None, global_dict=None, resolvers=None):
     """Evaluate a Python expression as a string using various backends.
 
-    The following arithmetic operations are supported: +, -, *, /, **, %, //
-    (python engine only) along with the following boolean operations: | (or), &
-    (and), and ~ (not). Series and DataFrame objects are supported and behave
-    as they would with in-Python evaluation.
+    The following arithmetic operations are supported: ``+``, ``-``, ``*``,
+    ``/``, ``**``, ``%``, ``//`` (python engine only) along with the following
+    boolean operations: ``|`` (or), ``&`` (and), and ``~`` (not).
+    Additionally, the ``'pandas'`` parser allows the use of :keyword:`and`,
+    :keyword:`or`, and :keyword:`not` with the same semantics as the
+    corresponding bitwise operators.  :class:`~pandas.Series` and
+    :class:`~pandas.DataFrame` objects are supported and behave as they would
+    with plain ol' Python evaluation.
 
     Parameters
     ----------
-    expr : string or Expr object
-        The expression to evaluate. This can be either a string or an ``Expr``
-        object.
-    parser : str, optional, default 'pandas', {'pandas', 'python'}
+    expr : string
+        The expression to evaluate.
+    parser : string, optional, default 'pandas', {'pandas', 'python'}
         The parser to use to construct the syntax tree from the expression. The
         default of 'pandas' parses code slightly different than standard
         Python. See the :ref:`enhancing performance <enhancingperf.eval>`
         documentation for more details.
     engine : string, optional, default 'numexpr', {'python', 'numexpr'}
+
         The engine used to evaluate the expression. Supported engines are
 
-        - 'numexpr': This default engine evaluates pandas objects using numexpr
-                     for large speed ups in complex expressions with large
-                     frames.
-        - 'python': Performs operations as if you had eval'd in top level
-                    python
+        - ``'numexpr'``: This default engine evaluates pandas objects using
+                         numexpr for large speed ups in complex expressions
+                         with large frames.
+        - ``'python'``: Performs operations as if you had ``eval``'d in top
+                        level python. This engine is generally not that useful.
+
     truediv : bool, optional, default True
         Whether to use true division, like in Python >= 3
     local_dict : dict or None, optional, default None
         A dictionary of local variables, taken from locals() by default.
     global_dict : dict or None, optional, default None
         A dictionary of global variables, taken from globals() by default.
+    resolvers : dict of dict-like or None, default None
+        A dictionary of dict-like object (specifically they must implement the
+        ``get`` method) that you can use to inject an additional collection of
+        namespaces to use for variable lookup. This is used in the
+        :meth:`~pandas.DataFrame.query` method to inject the
+        :attr:`~pandas.DataFrame.index` and :attr:`~pandas.DataFrame.columns`
+        variables that refer to their respective :class:`~pandas.DataFrame`
+        instance attributes.
 
     Returns
     -------
-    obj : ndarray, scalar, DataFrame, Series
+    ret : ndarray, numeric scalar, :class:`~pandas.DataFrame`, :class:`~pandas.Series`
 
     Notes
     -----
-    See :ref:`Enhancing performance <enhancingperf.eval>` for more details.
+    The ``dtype`` of any objects involved in an arithmetic ``%`` operation are
+    recursively cast to ``float64``.
+
+    See the :ref:`enhancing performance <enhancingperf.eval>` documentation for
+    more details.
+
+    See Also
+    --------
+    pandas.DataFrame.query
     """
-    # make sure we're passed a valid engine
+    # make sure we're passed a valid engine and parser
     _check_engine(engine)
     _check_parser(parser)
 
-    eng = _engines[engine]
+    env = _ensure_scope(global_dict=global_dict, local_dict=local_dict,
+                        resolvers=resolvers)
 
     if isinstance(expr, basestring):
-        # need to go 2 up in the call stack from the constructor
-        env = Scope(global_dict, local_dict, frame_level=2,
-                    resolvers=resolvers)
-        parsed_expr = Expr(expr, engine, parser, env, truediv)
-    elif isinstance(expr, Expr):
-        parsed_expr = expr
+        parsed_expr = Expr(expr, engine=engine, parser=parser, env=env,
+                           truediv=truediv)
     else:
-        raise TypeError("eval only accepts strings and Expr objects, you "
-                        "passed a {0!r}".format(expr.__class__.__name__))
-
+        raise TypeError("eval only accepts strings, you passed an object of "
+                        "type {0!r}".format(expr.__class__.__name__))
 
     # construct the engine and evaluate
+    eng = _engines[engine]
     ret = eng(parsed_expr).evaluate()
 
-    # sanity check for a number
+    # sanity check for a number if it's a scalar result
     # TODO: eventually take out
     if np.isscalar(ret):
         if not isinstance(ret, (np.number, np.bool_, numbers.Number)):
-            raise TypeError('scalar result must be numeric or bool, passed '
-                            'type is {0!r}'.format(ret.__class__.__name__))
+            raise TypeError('scalar result must be numeric or bool, return'
+                            ' type is {0!r}'.format(ret.__class__.__name__))
     return ret
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index 47f879f21..abcf8cc38 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -18,16 +18,33 @@ import pandas.lib as lib
 import datetime
 
 
-class Scope(object):
+def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
+                  **kwargs):
+    """ ensure that we are grabbing the correct scope """
+    return Scope(global_dict, local_dict, level=level, resolvers=resolvers)
+
+
+class Scope(StringMixin):
     __slots__ = ('globals', 'locals', 'resolvers', '_global_resolvers',
-                 'resolver_keys', '_resolver')
+                 'resolver_keys', '_resolver', 'level')
+
+    def __init__(self, gbls=None, lcls=None, level=1, resolvers=None):
+        self.level = level
+        self.resolvers = resolvers or []
+        self.globals = dict()
+        self.locals = dict()
 
-    def __init__(self, gbls=None, lcls=None, frame_level=1, resolvers=None):
-        frame = sys._getframe(frame_level)
+        if isinstance(lcls, Scope):
+            ld, lcls = lcls, dict()
+            self.locals.update(ld.locals)
+            self.globals.update(ld.globals)
+            self.resolvers.extend(ld.resolvers)
+            self.update(ld.level)
 
+        frame = sys._getframe(level)
         try:
-            self.globals = gbls or frame.f_globals.copy()
-            self.locals = lcls or frame.f_locals.copy()
+            self.globals.update(gbls or frame.f_globals.copy())
+            self.locals.update(lcls or frame.f_locals.copy())
         finally:
             del frame
 
@@ -39,12 +56,19 @@ class Scope(object):
         self.globals['True'] = True
         self.globals['False'] = False
 
-        self.resolvers = resolvers or []
         self.resolver_keys = set(reduce(operator.add, (list(o.keys()) for o in
                                                        self.resolvers), []))
         self._global_resolvers = self.resolvers + [self.locals, self.globals]
         self._resolver = None
 
+    def __unicode__(self):
+        return "locals: {0}\nglobals: {0}\nresolvers: {0}".format(self.locals.keys(),
+                                                                  self.globals.keys(),
+                                                                  self.resolver_keys)
+
+    def __getitem__(self, key):
+        return self.locals.get(key,self.globals[key])
+
     @property
     def resolver(self):
         if self._resolver is None:
@@ -58,14 +82,14 @@ class Scope(object):
 
         return self._resolver
 
-    def update(self, scope_level=None):
+    def update(self, level=None):
 
         # we are always 2 levels below the caller
         # plus the caller maybe below the env level
         # in which case we need addtl levels
         sl = 2
-        if scope_level is not None:
-            sl += scope_level
+        if level is not None:
+            sl += level
 
         # add sl frames to the scope starting with the
         # most distant and overwritting with more current
@@ -79,6 +103,7 @@ class Scope(object):
                 frames.append(frame)
             for f in frames[::-1]:
                 self.locals.update(f.f_locals)
+                self.globals.update(f.f_globals)
         finally:
             del frame
             del frames
@@ -312,7 +337,15 @@ class BaseExprVisitor(ast.NodeVisitor):
         ctx = node.ctx.__class__
         if ctx == ast.Load:
             # resolve the value
-            return getattr(self.visit(value).value, attr)
+            resolved = self.visit(value).value
+            try:
+                return getattr(resolved, attr)
+            except (AttributeError):
+
+                # something like datetime.datetime where scope is overriden
+                if isinstance(value, ast.Name) and value.id == attr:
+                    return resolved
+
         raise ValueError("Invalid Attribute context {0}".format(ctx.__name__))
 
     def visit_Call(self, node, **kwargs):
@@ -348,11 +381,17 @@ class BaseExprVisitor(ast.NodeVisitor):
     def visit_Compare(self, node, **kwargs):
         ops = node.ops
         comps = node.comparators
+        if len(comps) == 1:
+            return self.visit(ops[0])(self.visit(node.left, side='left'),
+                                      self.visit(comps[0], side='right'))
+        left = node.left
+        values = []
         for op, comp in itertools.izip(ops, comps):
-            vop = self.visit(op)
-            node = vop(self.visit(node.left, side='left'),
-                       self.visit(comp, side='right'))
-        return node
+            new_node = self.visit(ast.Compare(comparators=[comp], left=left,
+                                              ops=[op]))
+            left = comp
+            values.append(new_node)
+        return self.visit(ast.BoolOp(op=ast.And(), values=values))
 
     def visit_BoolOp(self, node, **kwargs):
         op = self.visit(node.op)
@@ -396,7 +435,7 @@ class Expr(StringMixin):
     def __init__(self, expr, engine='numexpr', parser='pandas', env=None,
                  truediv=True):
         self.expr = expr
-        self.env = env or Scope(frame_level=2)
+        self.env = _ensure_scope(level=2,local_dict=env)
         self._visitor = _parsers[parser](self.env)
         self.terms = self.parse()
         self.engine = engine
@@ -421,21 +460,25 @@ class Expr(StringMixin):
         return self.terms.align(self.env)
 
 
-def maybe_expression(s, kind='python'):
+_needs_filter = frozenset(['and', 'or', 'not'])
+
+
+def maybe_expression(s, kind='pandas'):
     """ loose checking if s is an expression """
     if not isinstance(s, basestring):
         return False
-    try:
-        visitor = _parsers[kind]
-        # make sure we have an op at least
-        return any(op in s for op in visitor.binary_ops)
-    except:
-        return False
+    visitor = _parsers[kind]
+    ops = visitor.binary_ops + visitor.unary_ops
+    filtered = frozenset(ops) - _needs_filter
+    # make sure we have an op at least
+    return any(op in s or ' and ' in s or ' or ' in s or ' not ' in s
+               for op in filtered)
 
 
 def isexpr(s, check_names=True):
+    env = _ensure_scope()
     try:
-        Expr(s)
+        Expr(s,env=env)
     except SyntaxError:
         return False
     except NameError:
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index 2a8ef0277..9a1a96cec 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -5,7 +5,6 @@ import numpy as np
 from pandas.util.py3compat import PY3
 import pandas.core.common as com
 from pandas.core.base import StringMixin
-from pandas.computation.common import flatten
 
 
 _reductions = 'sum', 'prod'
@@ -134,7 +133,7 @@ class Op(StringMixin):
         # clobber types to bool if the op is a boolean operator
         if self.op in (_cmp_ops_syms + _bool_ops_syms):
             return np.bool_
-        return np.result_type(*(term.type for term in flatten(self)))
+        return np.result_type(*(term.type for term in com.flatten(self)))
 
 
 _cmp_ops_syms = '>', '<', '>=', '<=', '==', '!='
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index ddebbc625..2819a63f3 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -27,12 +27,12 @@ def _ensure_decoded(s):
 class Scope(expr.Scope):
     __slots__ = 'globals', 'locals', 'queryables'
 
-    def __init__(self, gbls=None, lcls=None, queryables=None, frame_level=1):
+    def __init__(self, gbls=None, lcls=None, queryables=None, level=1):
         super(
             Scope,
             self).__init__(gbls=gbls,
                            lcls=lcls,
-                           frame_level=frame_level)
+                           level=level)
         self.queryables = queryables or dict()
 
 
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index cbabf2897..7a2704a32 100755
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -23,19 +23,19 @@ from pandas.computation.engines import _engines
 from pandas.computation.expr import PythonExprVisitor, PandasExprVisitor
 from pandas.computation.ops import (_binary_ops_dict, _unary_ops_dict,
                                     _special_case_arith_ops_syms,
-                                    _arith_ops_syms, Constant)
+                                    _arith_ops_syms)
 import pandas.computation.expr as expr
 from pandas.computation import pytables
 from pandas.computation.expressions import _USE_NUMEXPR
-from pandas.computation.eval import Scope
 from pandas.util.testing import (assert_frame_equal, randbool,
-                                 assertRaisesRegexp)
+                                 assertRaisesRegexp,
+                                 assert_produces_warning)
 from pandas.util.py3compat import PY3
 
 
 def skip_numexpr_engine(engine):
     if not _USE_NUMEXPR and engine == 'numexpr':
-        raise nose.SkipTest
+        raise nose.SkipTest("not using numexpr")
 
 
 def engine_has_neg_frac(engine):
@@ -46,12 +46,13 @@ def _eval_single_bin(lhs, cmp1, rhs, engine):
     c = _binary_ops_dict[cmp1]
     if engine_has_neg_frac(engine):
         try:
-            result = c(lhs, rhs)
-        except ValueError:
-            result = np.nan
-    else:
-        result = c(lhs, rhs)
-    return result
+            return c(lhs, rhs)
+        except ValueError as e:
+            if e.message == ('negative number cannot be raised to a '
+                             'fractional power'):
+                return np.nan
+            raise
+    return c(lhs, rhs)
 
 
 def _series_and_2d_ndarray(lhs, rhs):
@@ -60,6 +61,10 @@ def _series_and_2d_ndarray(lhs, rhs):
             > 1)
 
 
+def _bool_and_frame(lhs, rhs):
+    return isinstance(lhs, bool) and com.is_frame(rhs)
+
+
 def skip_incompatible_operand(f):
     @functools.wraps(f)
     def wrapper(self, lhs, arith1, rhs, *args, **kwargs):
@@ -75,7 +80,6 @@ def skip_incompatible_operand(f):
 _good_arith_ops = tuple(set(_arith_ops_syms) -
                         set(_special_case_arith_ops_syms))
 
-
 class TestEvalPandas(unittest.TestCase):
 
     @classmethod
@@ -87,6 +91,11 @@ class TestEvalPandas(unittest.TestCase):
         cls.arith_ops = _good_arith_ops
         cls.unary_ops = '+', '-'
 
+    @classmethod
+    def tearDownClass(cls):
+        del cls.cmp_ops, cls.cmp2_ops, cls.bin_ops, cls.special_case_ops
+        del cls.arith_ops, cls.unary_ops
+
     def set_current_engine(self):
         self.engine = 'numexpr'
 
@@ -103,8 +112,10 @@ class TestEvalPandas(unittest.TestCase):
         self.scalar_lhses = randn(), np.float64(randn()), np.nan
         self.scalar_rhses = randn(), np.float64(randn()), np.nan
 
-        self.lhses = self.pandas_lhses + self.scalar_lhses
-        self.rhses = self.pandas_rhses + self.scalar_rhses
+        self.lhses = self.pandas_lhses + self.scalar_lhses + (randn(10, 5),
+                                                              randn(5))
+        self.rhses = self.pandas_rhses + self.scalar_rhses + (randn(10, 5),
+                                                              randn(5))
 
     def setUp(self):
         try:
@@ -114,8 +125,12 @@ class TestEvalPandas(unittest.TestCase):
             raise nose.SkipTest
         self.set_current_engine()
         self.setup_data()
-        self.current_engines = filter(lambda x: x != self.engine,
-                                      _engines.iterkeys())
+        self.current_engines = filter(lambda x: x != self.engine, _engines)
+
+    def tearDown(self):
+        del self.lhses, self.rhses, self.scalar_rhses, self.scalar_lhses
+        del self.pandas_rhses, self.pandas_lhses, self.current_engines, self.ne
+        del self.engine
 
     @slow
     def test_complex_cmp_ops(self):
@@ -166,6 +181,14 @@ class TestEvalPandas(unittest.TestCase):
         for lhs, op, rhs in product(self.lhses, self.cmp_ops, self.rhses):
             self.check_compound_invert_op(lhs, op, rhs)
 
+    @slow
+    def test_chained_cmp_op(self):
+        mids = self.lhses
+        cmp_ops = tuple(set(self.cmp_ops) - set(['==', '!=', '<=', '>=']))
+        for lhs, cmp1, mid, cmp2, rhs in product(self.lhses, self.cmp_ops,
+                                                 mids, cmp_ops, self.rhses):
+            self.check_chained_cmp_op(lhs, cmp1, mid, cmp2, rhs)
+
     @skip_incompatible_operand
     def check_complex_cmp_op(self, lhs, cmp1, rhs, binop, cmp2):
         ex = '(lhs {cmp1} rhs) {binop} (lhs {cmp2} rhs)'.format(cmp1=cmp1,
@@ -177,6 +200,46 @@ class TestEvalPandas(unittest.TestCase):
         result = pd.eval(ex, engine=self.engine)
         assert_array_equal(result, expected)
 
+    def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
+        # these are not compatible operands
+        if _series_and_2d_ndarray(lhs, mid):
+            self.assertRaises(ValueError, _eval_single_bin, lhs, cmp2, mid,
+                              self.engine)
+        else:
+            lhs_new = _eval_single_bin(lhs, cmp1, mid, self.engine)
+
+        if _series_and_2d_ndarray(mid, rhs):
+            self.assertRaises(ValueError, _eval_single_bin, mid, cmp2, rhs,
+                              self.engine)
+        else:
+            rhs_new = _eval_single_bin(mid, cmp2, rhs, self.engine)
+
+        try:
+            lhs_new
+            rhs_new
+        except NameError:
+            pass
+        else:
+            # these are not compatible operands
+            if (com.is_series(lhs_new) and com.is_frame(rhs_new) or
+                _bool_and_frame(lhs_new, rhs_new)):
+                self.assertRaises(TypeError, _eval_single_bin, lhs_new, '&',
+                                  rhs_new, self.engine)
+            elif _series_and_2d_ndarray(lhs_new, rhs_new):
+                # TODO: once #4319 is fixed add this test back in
+                #self.assertRaises(Exception, _eval_single_bin, lhs_new, '&',
+                                  #rhs_new, self.engine)
+                pass
+            else:
+                ex1 = 'lhs {0} mid {1} rhs'.format(cmp1, cmp2)
+                ex2 = 'lhs {0} mid and mid {1} rhs'.format(cmp1, cmp2)
+                ex3 = '(lhs {0} mid) & (mid {1} rhs)'.format(cmp1, cmp2)
+                expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
+
+                for ex in (ex1, ex2, ex3):
+                    result = pd.eval(ex, engine=self.engine)
+                    assert_array_equal(result, expected)
+
     @skip_incompatible_operand
     def check_simple_cmp_op(self, lhs, cmp1, rhs):
         ex = 'lhs {0} rhs'.format(cmp1)
@@ -321,267 +384,351 @@ class TestEvalPython(TestEvalPandas):
         self.engine = 'python'
 
 
-class TestEvalPandasWithMixedTypeOperands(TestEvalPandas):
-    def setup_data(self):
-        super(TestEvalPandasWithMixedTypeOperands, self).setup_data()
-        self.lhses += randn(10, 5), randn(5)
-        self.rhses += randn(10, 5), randn(5)
-
-
-class TestEvalPythonWithMixedTypeOperands(TestEvalPandasWithMixedTypeOperands):
-    def set_current_engine(self):
-        self.engine = 'python'
-
-
-def test_syntax_error_exprs():
-    for engine in _engines:
-        e = 's +'
-        assert_raises(SyntaxError, pd.eval, e, engine=engine)
-
-
-def test_name_error_exprs():
-    for engine in _engines:
-        e = 's + t'
-        assert_raises(NameError, pd.eval, e, engine=engine)
-
-
-def test_align_nested_unary_op():
-    for engine in _engines:
-        yield check_align_nested_unary_op, engine
-
-
 f = lambda *args, **kwargs: np.random.randn()
 
 
-def check_align_nested_unary_op(engine):
-    skip_numexpr_engine(engine)
-    s = 'df * ~2'
-    df = mkdf(10, 10, data_gen_f=f)
-    res = pd.eval(s, engine=engine)
-    assert_frame_equal(res, df * ~2)
-
-
-def check_basic_frame_alignment(engine):
-    df = mkdf(10, 10, data_gen_f=f)
-    df2 = mkdf(20, 10, data_gen_f=f)
-    res = pd.eval('df + df2', engine=engine)
-    assert_frame_equal(res, df + df2)
-
-
-def test_basic_frame_alignment():
-    for engine in _engines:
-        yield check_basic_frame_alignment, engine
-
-
-def check_medium_complex_frame_alignment(engine, r1, r2, c1, c2):
-    skip_numexpr_engine(engine)
-    df = mkdf(5, 2, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
-    df2 = mkdf(10, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-    df3 = mkdf(15, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-    res = pd.eval('df + df2 + df3', engine=engine)
-    assert_frame_equal(res, df + df2 + df3)
-
-
-@slow
-def test_medium_complex_frame_alignment():
-    args = product(_engines, *([INDEX_TYPES[:4]] * 4))
-    for engine, r1, r2, c1, c2 in args:
-        check_medium_complex_frame_alignment(engine, r1, r2, c1, c2)
-
-
-def check_basic_frame_series_alignment(engine, r_idx_type, c_idx_type,
-                                       index_name):
-    skip_numexpr_engine(engine)
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-              c_idx_type=c_idx_type)
-    index = getattr(df, index_name)
-    s = Series(np.random.randn(5), index[:5])
-
-    if r_idx_type != 'p' and c_idx_type == 'p' and index_name == 'index':
-        assert_raises(ValueError, pd.eval, 'df + s', local_dict=locals())
-        assert_raises(ValueError, df.add, s, axis=1)
-    else:
-        res = pd.eval('df + s', engine=engine)
-        expected = df + s
-        assert_frame_equal(res, expected)
-
-
-def check_not_both_period_fails_otherwise_succeeds(lhs, rhs, r_idx_type,
-                                                   c_idx_type, index_name, s,
-                                                   df, *terms):
-    if r_idx_type != 'p' and c_idx_type == 'p' and index_name == 'index':
-        assert_raises(ValueError, pd.eval, lhs, local_dict=locals())
-        assert_raises(ValueError, pd.eval, rhs, local_dict=locals())
-    else:
-        a, b = pd.eval(lhs), pd.eval(rhs)
-        assert_frame_equal(a, b)
-
-
-def check_basic_series_frame_alignment(engine, r_idx_type, c_idx_type,
-                                       index_name):
-    skip_numexpr_engine(engine)
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-              c_idx_type=c_idx_type)
-    index = getattr(df, index_name)
-    s = Series(np.random.randn(5), index[:5])
-
-    if r_idx_type != 'p' and c_idx_type == 'p' and index_name == 'index':
-        assert_raises(ValueError, pd.eval, 's + df', local_dict=locals())
-        assert_raises(ValueError, df.add, s, axis=1)
-    else:
-        res = pd.eval('s + df', engine=engine)
-        expected = s + df
-        assert_frame_equal(res, expected)
-
+class TestAlignment(unittest.TestCase):
 
-def check_basic_series_frame_alignment_datetime(engine, r_idx_type, c_idx_type,
-                                                index_name):
-    skip_numexpr_engine(engine)
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-              c_idx_type=c_idx_type)
-    index = getattr(df, index_name)
-    s = Series(np.random.randn(5), index[:5])
-    if r_idx_type != 'p' and c_idx_type == 'p' and index_name == 'index':
-        assert_raises(ValueError, pd.eval, 's + df', local_dict=locals())
-        assert_raises(ValueError, df.add, s, axis=1)
-    else:
-        res = pd.eval('s + df', engine=engine)
-        expected = s + df
-        assert_frame_equal(res, expected)
-
-    if r_idx_type != 'p' and c_idx_type == 'p' and index_name == 'index':
-        assert_raises(ValueError, pd.eval, 'df + s', local_dict=locals())
-        assert_raises(ValueError, df.add, s, axis=1)
-    else:
-        res = pd.eval('df + s', engine=engine)
-        expected = df + s
-        assert_frame_equal(res, expected)
+    @classmethod
+    def setUpClass(cls):
+        cls.INDEX_TYPES = 'i', 'f', 's', 'u', 'dt', # 'p'
 
+    @classmethod
+    def tearDownClass(cls):
+        del cls.INDEX_TYPES
+
+    def check_align_nested_unary_op(self, engine):
+        skip_numexpr_engine(engine)
+        s = 'df * ~2'
+        df = mkdf(10, 10, data_gen_f=f)
+        res = pd.eval(s, engine=engine)
+        assert_frame_equal(res, df * ~2)
+
+    def test_align_nested_unary_op(self):
+        for engine in _engines:
+            self.check_align_nested_unary_op(engine)
+
+    def check_basic_frame_alignment(self, engine):
+        df = mkdf(10, 10, data_gen_f=f)
+        df2 = mkdf(20, 10, data_gen_f=f)
+        res = pd.eval('df + df2', engine=engine)
+        assert_frame_equal(res, df + df2)
+
+    def test_basic_frame_alignment(self):
+        for engine in _engines:
+            self.check_basic_frame_alignment(engine)
+
+    def check_medium_complex_frame_alignment(self, engine, r1, r2, c1, c2):
+        skip_numexpr_engine(engine)
+        df = mkdf(5, 2, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
+        df2 = mkdf(10, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+        df3 = mkdf(15, 2, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+        res = pd.eval('df + df2 + df3', engine=engine)
+        assert_frame_equal(res, df + df2 + df3)
 
-def check_series_frame_commutativity(engine, r_idx_type, c_idx_type, op,
-                                     index_name):
-    skip_numexpr_engine(engine)
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
-              c_idx_type=c_idx_type)
-    index = getattr(df, index_name)
-    s = Series(np.random.randn(5), index[:5])
+    @slow
+    def test_medium_complex_frame_alignment(self):
+        args = product(_engines, *([self.INDEX_TYPES[:4]] * 4))
+        for engine, r1, r2, c1, c2 in args:
+            self.check_medium_complex_frame_alignment(engine, r1, r2, c1, c2)
+
+    def check_basic_frame_series_alignment(self, engine, r_idx_type,
+                                           c_idx_type, index_name):
+        def testit():
+            skip_numexpr_engine(engine)
+            df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            index = getattr(df, index_name)
+            s = Series(np.random.randn(5), index[:5])
+
+            res = pd.eval('df + s', engine=engine)
+            if r_idx_type == 'dt' or c_idx_type == 'dt':
+                if engine == 'numexpr':
+                    expected = df.add(s)
+                else:
+                    expected = df + s
+            else:
+                expected = df + s
+            assert_frame_equal(res, expected)
 
-    lhs = 's {0} df'.format(op)
-    rhs = 'df {0} s'.format(op)
-    check_not_both_period_fails_otherwise_succeeds(lhs, rhs, r_idx_type,
-                                                   c_idx_type, index_name, s,
-                                                   df)
+        testit()
 
+    @slow
+    def test_basic_frame_series_alignment(self):
+        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES,
+                       ('index', 'columns'))
+        for engine, r_idx_type, c_idx_type, index_name in args:
+            self.check_basic_frame_series_alignment(engine, r_idx_type,
+                                                    c_idx_type, index_name)
 
-INDEX_TYPES = 'i', 'f', 's', 'u', # 'dt',  # 'p'
+    def check_basic_series_frame_alignment(self, engine, r_idx_type,
+                                           c_idx_type, index_name):
+        def testit():
+            skip_numexpr_engine(engine)
+            df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                    c_idx_type=c_idx_type)
+            index = getattr(df, index_name)
+            s = Series(np.random.randn(5), index[:5])
+
+            res = pd.eval('s + df', engine=engine)
+            if r_idx_type == 'dt' or c_idx_type == 'dt':
+                if engine == 'numexpr':
+                    expected = df.add(s)
+                else:
+                    expected = s + df
+            else:
+                expected = s + df
+            assert_frame_equal(res, expected)
 
+        testit()
 
-@slow
-def test_series_frame_commutativity():
-    args = product(_engines, INDEX_TYPES, INDEX_TYPES, ('+', '*'), ('index',
-                                                                    'columns'))
-    for engine, r_idx_type, c_idx_type, op, index_name in args:
-        check_series_frame_commutativity(engine, r_idx_type, c_idx_type, op,
-                                         index_name)
+    @slow
+    def test_basic_series_frame_alignment(self):
+        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES,
+                       ('index', 'columns'))
+        for engine, r_idx_type, c_idx_type, index_name in args:
+            self.check_basic_series_frame_alignment(engine, r_idx_type,
+                                                    c_idx_type, index_name)
 
+    def check_series_frame_commutativity(self, engine, r_idx_type, c_idx_type,
+                                         op, index_name):
+        skip_numexpr_engine(engine)
+        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                  c_idx_type=c_idx_type)
+        index = getattr(df, index_name)
+        s = Series(np.random.randn(5), index[:5])
 
-@slow
-def test_basic_frame_series_alignment():
-    args = product(_engines, INDEX_TYPES, INDEX_TYPES, ('index', 'columns'))
-    for engine, r_idx_type, c_idx_type, index_name in args:
-        check_basic_frame_series_alignment(engine, r_idx_type, c_idx_type,
-                                           index_name)
+        lhs = 's {0} df'.format(op)
+        rhs = 'df {0} s'.format(op)
+        a = pd.eval(lhs, engine=engine)
+        b = pd.eval(rhs, engine=engine)
 
+        if r_idx_type != 'dt' and c_idx_type != 'dt':
+            if engine == 'numexpr':
+                assert_frame_equal(a, b)
 
-@slow
-def test_basic_series_frame_alignment_datetime():
-    idx_types = INDEX_TYPES
-    args = product(_engines, idx_types, idx_types, ('index', 'columns'))
-    for engine, r_idx_type, c_idx_type, index_name in args:
-        check_basic_series_frame_alignment_datetime(engine, r_idx_type,
-                                                    c_idx_type, index_name)
+    @slow
+    def test_series_frame_commutativity(self):
+        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES, ('+',
+                                                                      '*'),
+                       ('index', 'columns'))
+        for engine, r_idx_type, c_idx_type, op, index_name in args:
+            self.check_series_frame_commutativity(engine, r_idx_type,
+                                                  c_idx_type, op, index_name)
+
+    def check_complex_series_frame_alignment(self, engine, index_name, obj, r1,
+                                             r2, c1, c2):
+        skip_numexpr_engine(engine)
+        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
+        df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+        index = getattr(locals()[obj], index_name)
+        s = Series(np.random.randn(5), index[:5])
+        if engine != 'python':
+            expected = df2.add(s, axis=1).add(df)
+        else:
+            expected = df2 + s + df
+        res = pd.eval('df2 + s + df', engine=engine)
+        expected = df2 + s + df
+        assert_tuple_equal(res.shape, expected.shape)
+        assert_frame_equal(res, expected)
 
+    @slow
+    def test_complex_series_frame_alignment(self):
+        args = product(_engines, ('index', 'columns'), ('df', 'df2'),
+                    *([self.INDEX_TYPES[:4]] * 4))
+        for engine, index_name, obj, r1, r2, c1, c2 in args:
+            self.check_complex_series_frame_alignment(engine, index_name, obj,
+                                                      r1, r2, c1, c2)
+
+    def test_performance_warning_for_asenine_alignment(self):
+        df = DataFrame(randn(1000, 10))
+        s = Series(randn(10000))
+        with assert_produces_warning(pd.io.common.PerformanceWarning):
+            pd.eval('df + s')
+
+        s = Series(randn(1000))
+        with assert_produces_warning(False):
+            pd.eval('df + s')
+
+        df = DataFrame(randn(10, 10000))
+        s = Series(randn(10000))
+        with assert_produces_warning(False):
+            pd.eval('df + s')
+
+class TestOperations(unittest.TestCase):
+
+    def check_simple_arith_ops(self, engine):
+        ops = expr._arith_ops_syms + expr._cmp_ops_syms
+
+        for op in filter(lambda x: x != '//', ops):
+            expec = _eval_single_bin(1, op, 1, engine)
+            x = pd.eval('1 {0} 1'.format(op), engine=engine)
+            assert_equal(x, expec)
+
+            expec = _eval_single_bin(x, op, 1, engine)
+            y = pd.eval('x {0} 1'.format(op), engine=engine)
+            assert_equal(y, expec)
+
+            expec = _eval_single_bin(1, op, x + 1, engine)
+            y = pd.eval('1 {0} (x + 1)'.format(op), engine=engine)
+            assert_equal(y, expec)
+
+    def check_simple_bool_ops(self, engine):
+        for op, lhs, rhs in product(expr._bool_ops_syms, (True, False), (True,
+                                                                        False)):
+            expec = _eval_single_bin(lhs, op, rhs, engine)
+            x = pd.eval('lhs {0} rhs'.format(op), engine=engine)
+            assert_equal(x, expec)
+
+    def check_bool_ops_with_constants(self, engine):
+        asteval = ast.literal_eval
+        for op, lhs, rhs in product(expr._bool_ops_syms, ('True', 'False'),
+                                    ('True', 'False')):
+            expec = _eval_single_bin(asteval(lhs), op, asteval(rhs), engine)
+            x = pd.eval('{0} {1} {2}'.format(lhs, op, rhs), engine=engine)
+            assert_equal(x, expec)
+
+    def test_simple_arith_ops(self):
+        for engine in _engines:
+            self.check_simple_arith_ops(engine)
+
+    def test_simple_bool_ops(self):
+        for engine in _engines:
+            self.check_simple_bool_ops(engine)
+
+    def test_bool_ops_with_constants(self):
+        for engine in _engines:
+            self.check_bool_ops_with_constants(engine)
+
+    def check_panel_fails(self, engine):
+        x = Panel(randn(3, 4, 5))
+        y = Series(randn(10))
+        assert_raises(NotImplementedError, pd.eval, 'x + y',
+                      local_dict={'x': x, 'y': y}, engine=engine)
+
+    def test_panel_fails(self):
+        for engine in _engines:
+            self.check_panel_fails(engine)
+
+    def check_4d_ndarray_fails(self, engine):
+        x = randn(3, 4, 5, 6)
+        y = Series(randn(10))
+        assert_raises(NotImplementedError, pd.eval, 'x + y', local_dict={'x': x,
+                                                                        'y': y},
+                    engine=engine)
+
+    def test_4d_ndarray_fails(self):
+        for engine in _engines:
+            self.check_4d_ndarray_fails(engine)
+
+    def check_constant(self, engine):
+        x = pd.eval('1', engine=engine)
+        assert_equal(x, 1)
+
+    def test_constant(self):
+        for engine in _engines:
+            self.check_constant(engine)
+
+    def check_single_variable(self, engine):
+        df = DataFrame(randn(10, 2))
+        df2 = pd.eval('df', engine=engine)
+        assert_frame_equal(df, df2)
+
+    def test_single_variable(self):
+        for engine in _engines:
+            self.check_single_variable(engine)
+
+    def test_truediv(self):
+        for engine in _engines:
+            self.check_truediv(engine)
+
+    def check_truediv(self, engine):
+        s = np.array([1])
+        ex = 's / 1'
+
+        if PY3:
+            res = pd.eval(ex, truediv=False)
+            assert_array_equal(res, np.array([1.0]))
+
+            res = pd.eval(ex, truediv=True)
+            assert_array_equal(res, np.array([1.0]))
+        else:
+            res = pd.eval(ex, truediv=False)
+            assert_array_equal(res, np.array([1]))
 
-@slow
-def test_basic_series_frame_alignment():
-    args = product(_engines, INDEX_TYPES, INDEX_TYPES, ('index', 'columns'))
-    for engine, r_idx_type, c_idx_type, index_name in args:
-        check_basic_series_frame_alignment(engine, r_idx_type, c_idx_type,
-                                           index_name)
-
-
-def check_complex_series_frame_alignment(engine, index_name, obj, r1, r2, c1,
-                                         c2):
-    skip_numexpr_engine(engine)
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
-    df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
-    index = getattr(locals()[obj], index_name)
-    s = Series(np.random.randn(5), index[:5])
-    if engine != 'python':
-        expected = df2.add(s, axis=1).add(df)
-    else:
-        expected = df2 + s + df
-    res = pd.eval('df2 + s + df', engine=engine)
-    expected = df2 + s + df
-    assert_tuple_equal(res.shape, expected.shape)
-    assert_frame_equal(res, expected)
+            res = pd.eval(ex, truediv=True)
+            assert_array_equal(res, np.array([1.0]))
 
 
-@slow
-def test_complex_series_frame_alignment():
-    args = product(_engines, ('index', 'columns'), ('df', 'df2'),
-                   *([INDEX_TYPES[:4]] * 4))
-    for engine, index_name, obj, r1, r2, c1, c2 in args:
-        check_complex_series_frame_alignment(engine, index_name, obj, r1, r2,
-                                             c1, c2)
+_var_s = randn(10)
 
+class TestScope(unittest.TestCase):
 
-def check_datetime_index_rows_punts_to_python(engine):
-    df = mkdf(10, 10, data_gen_f=f, r_idx_type='dt', c_idx_type='dt')
-    index = getattr(df, 'index')
-    s = Series(np.random.randn(5), index[:5])
-    env = Scope(globals(), locals())
+    def check_global_scope(self, engine):
+        e = '_var_s * 2'
+        assert_array_equal(_var_s * 2, pd.eval(e, engine=engine))
 
+    def test_global_scope(self):
+        for engine in _engines:
+            self.check_global_scope(engine)
 
-def test_datetime_index_rows_punts_to_python():
-    for engine in _engines:
-        check_datetime_index_rows_punts_to_python(engine)
+    def check_no_new_locals(self, engine):
+        x = 1
+        lcls = locals().copy()
+        pd.eval('x + 1', local_dict=lcls)
+        lcls2 = locals().copy()
+        lcls2.pop('lcls')
+        assert_equal(lcls, lcls2)
 
+    def test_no_new_locals(self):
+        for engine in _engines:
+            self.check_no_new_locals(engine)
 
-def test_truediv():
-    for engine in _engines:
-        check_truediv(engine)
+    def check_no_new_globals(self, engine):
+        x = 1
+        gbls = globals().copy()
+        pd.eval('x + 1')
+        gbls2 = globals().copy()
+        assert_equal(gbls, gbls2)
 
+    def test_no_new_globals(self):
+        for engine in _engines:
+            self.check_no_new_globals(engine)
 
-def check_truediv(engine):
-    s = np.array([1])
-    ex = 's / 1'
+    def test_nested_scope(self):
+        x = 1
+        result = pd.eval('x + 1')
+        self.assertEqual(result, 2)
 
-    if PY3:
-        res = pd.eval(ex, truediv=False)
-        assert_array_equal(res, np.array([1.0]))
+        df  = DataFrame(np.random.randn(2000, 10))
+        df2 = DataFrame(np.random.randn(2000, 10))
+        expected = df[(df>0) & (df2>0)]
 
-        res = pd.eval(ex, truediv=True)
-        assert_array_equal(res, np.array([1.0]))
-    else:
-        res = pd.eval(ex, truediv=False)
-        assert_array_equal(res, np.array([1]))
+        result = df['(df>0) & (df2>0)']
+        assert_frame_equal(result,expected)
 
-        res = pd.eval(ex, truediv=True)
-        assert_array_equal(res, np.array([1.0]))
+        result = df.query('(df>0) & (df2>0)')
+        assert_frame_equal(result,expected)
 
+        ##### this fails ####
+        #result = pd.eval('df[(df>0) & (df2>0)]')
+        #assert_frame_equal(result,expected)
 
-__var_s = randn(10)
+        #### also fails ####
+        #self.assertRaises(NotImplementedError, pd.eval,
+                          #'df[(df > 0) & (df2 > 0)]')
 
 
-def check_global_scope(engine):
-    e = '__var_s * 2'
-    assert_array_equal(__var_s * 2, pd.eval(e, engine=engine))
+def test_invalid_engine():
+    assertRaisesRegexp(KeyError, 'Invalid engine \'asdf\' passed',
+                       pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
+                       engine='asdf')
 
 
-def test_global_scope():
-    for engine in _engines:
-        yield check_global_scope, engine
+def test_invalid_parser():
+    assertRaisesRegexp(KeyError, 'Invalid parser \'asdf\' passed',
+                       pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
+                       parser='asdf')
 
 
 def check_is_expr(engine):
@@ -600,8 +747,7 @@ def test_is_expr():
 
 
 _parsers = {'python': PythonExprVisitor, 'pytables': pytables.ExprVisitor,
-             'pandas': PandasExprVisitor}
-
+            'pandas': PandasExprVisitor}
 
 def check_disallowed_nodes(visitor):
     """make sure the disallowed decorator works"""
@@ -618,139 +764,16 @@ def test_disallowed_nodes():
         check_disallowed_nodes(visitor)
 
 
-def check_simple_arith_ops(engine):
-    ops = expr._arith_ops_syms + expr._cmp_ops_syms
-
-    for op in filter(lambda x: x != '//', ops):
-        expec = _eval_single_bin(1, op, 1, engine)
-        x = pd.eval('1 {0} 1'.format(op), engine=engine)
-        assert_equal(x, expec)
-
-        expec = _eval_single_bin(x, op, 1, engine)
-        y = pd.eval('x {0} 1'.format(op), engine=engine)
-        assert_equal(y, expec)
-
-        expec = _eval_single_bin(1, op, x + 1, engine)
-        y = pd.eval('1 {0} (x + 1)'.format(op), engine=engine)
-        assert_equal(y, expec)
-
-
-def check_simple_bool_ops(engine):
-    for op, lhs, rhs in product(expr._bool_ops_syms, (True, False), (True,
-                                                                     False)):
-        expec = _eval_single_bin(lhs, op, rhs, engine)
-        x = pd.eval('lhs {0} rhs'.format(op), engine=engine)
-        assert_equal(x, expec)
-
-
-def check_bool_ops_with_constants(engine):
-    asteval = ast.literal_eval
-    for op, lhs, rhs in product(expr._bool_ops_syms, ('True', 'False'),
-                                ('True', 'False')):
-        expec = _eval_single_bin(asteval(lhs), op, asteval(rhs), engine)
-        x = pd.eval('{0} {1} {2}'.format(lhs, op, rhs), engine=engine)
-        assert_equal(x, expec)
-
-
-def test_simple_arith_ops():
-    for engine in _engines:
-        check_simple_arith_ops(engine)
-
-
-def test_simple_bool_ops():
-    for engine in _engines:
-        check_simple_bool_ops(engine)
-
-
-def test_bool_ops_with_constants():
-    for engine in _engines:
-        check_bool_ops_with_constants(engine)
-
-
-def check_no_new_locals(engine):
-    x = 1
-    lcls = locals().copy()
-    pd.eval('x + 1', local_dict=lcls)
-    lcls2 = locals().copy()
-    lcls2.pop('lcls')
-    assert_equal(lcls, lcls2)
-
-
-def test_no_new_locals():
-    for engine in _engines:
-        check_no_new_locals(engine)
-
-
-def check_no_new_globals(engine):
-    x = 1
-    gbls = globals().copy()
-    pd.eval('x + 1')
-    gbls2 = globals().copy()
-    assert_equal(gbls, gbls2)
-
-
-def test_no_new_globals():
-    for engine in _engines:
-        check_no_new_globals(engine)
-
-
-def check_panel_fails(engine):
-    x = Panel(randn(3, 4, 5))
-    y = Series(randn(10))
-    assert_raises(NotImplementedError, pd.eval, 'x + y', local_dict={'x': x,
-                                                                     'y': y},
-                  engine=engine)
-
-
-def test_panel_fails():
-    for engine in _engines:
-        check_panel_fails(engine)
-
-
-def check_4d_ndarray_fails(engine):
-    x = randn(3, 4, 5, 6)
-    y = Series(randn(10))
-    assert_raises(NotImplementedError, pd.eval, 'x + y', local_dict={'x': x,
-                                                                     'y': y},
-                  engine=engine)
-
-
-def test_4d_ndarray_fails():
-    for engine in _engines:
-        check_4d_ndarray_fails(engine)
-
-
-def check_constant(engine):
-    x = pd.eval('1', engine=engine)
-    assert_equal(x, 1)
-
-
-def test_constant():
+def test_syntax_error_exprs():
     for engine in _engines:
-        check_constant(engine)
-
-
-def check_single_variable(engine):
-    df = DataFrame(randn(10, 2))
-    df2 = pd.eval('df', engine=engine)
-    assert_frame_equal(df, df2)
+        e = 's +'
+        assert_raises(SyntaxError, pd.eval, e, engine=engine)
 
 
-def test_single_variable():
+def test_name_error_exprs():
     for engine in _engines:
-        check_single_variable(engine)
-
-
-def test_invalid_engine():
-    assertRaisesRegexp(KeyError, 'Invalid engine \'asdf\' passed',
-                       pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
-                       engine='asdf')
-
-
-def test_invalid_parser():
-    assertRaisesRegexp(KeyError, 'Invalid parser \'asdf\' passed',
-                       pd.eval, 'x + y', local_dict={'x': 1, 'y': 2},
-                       parser='asdf')
+        e = 's + t'
+        assert_raises(NameError, pd.eval, e, engine=engine)
 
 
 if __name__ == '__main__':
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 89407121f..74f41355c 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -3,6 +3,7 @@ Misc tools for implementing data structures
 """
 
 import re
+import collections
 import codecs
 import csv
 import sys
@@ -224,6 +225,15 @@ def notnull(obj):
     return -res
 
 
+def flatten(l):
+    for el in l:
+        if isinstance(el, collections.Iterable) and not is_string(el):
+            for s in flatten(el):
+                yield s
+        else:
+            yield el
+
+
 def mask_missing(arr, values_to_mask):
     """
     Return a masking array of same size/shape as arr
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 3f4b283f5..dd92dfa23 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -38,7 +38,7 @@ from pandas.core.series import Series, _radd_compat
 from pandas.sparse.array import SparseArray
 import pandas.computation.expressions as expressions
 from pandas.computation.eval import eval as _eval
-from pandas.computation.expr import maybe_expression
+from pandas.computation.expr import maybe_expression, _ensure_scope
 from pandas.compat.scipy import scoreatpercentile as _quantile
 from pandas.compat import(range, zip, lrange, lmap, lzip, StringIO, u,
                           OrderedDict, raise_with_traceback)
@@ -1837,7 +1837,8 @@ class DataFrame(NDFrame):
                 return self._getitem_column(key)
             except KeyError:
                 if maybe_expression(key):
-                    return self.query(key)
+                    env = _ensure_scope(level=2)
+                    return self.query(key, local_dict=env)
                 raise
 
     def _getitem_column(self, key):
@@ -1912,11 +1913,11 @@ class DataFrame(NDFrame):
         expr : string
             The query string to evaluate. The result of the evaluation of this
             expression is passed to
-            :meth:`~pandas.core.frame.DataFrame.__getitem__`.
+            :meth:`~pandas.DataFrame.__getitem__`.
         kwargs : dict
-            See the documentation for :func:`~pandas.computation.eval.eval` for
-            complete details on the keyword arguments accepted by
-            :meth:`~pandas.core.frame.DataFrame.query`.
+            See the documentation for :func:`~pandas.eval` for complete details
+            on the keyword arguments accepted by
+            :meth:`~pandas.DataFrame.query`.
 
         Returns
         -------
@@ -1924,30 +1925,32 @@ class DataFrame(NDFrame):
 
         Notes
         -----
-        This method uses the top-level :func:`~pandas.computation.eval.eval`
-        function to evaluate the passed query.
+        This method uses the top-level :func:`~pandas.eval` function to
+        evaluate the passed query.
 
-        The :meth:`~pandas.core.frame.DataFrame.query` method uses a slightly
+        The :meth:`~pandas.DataFrame.query` method uses a slightly
         modified Python syntax by default. For example, the ``&`` and ``|``
         (bitwise) operators have the precedence of their boolean cousins,
-        ``and`` and ``or``. This *is* syntactically valid Python, however the
-        semantics are different.
+        :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,
+        however the semantics are different.
 
         You can use a syntax that is semantically identical to Python by
-        passing the keyword argument ``parser='numexpr'``.
+        passing the keyword argument ``parser='python'``.
 
-        The ``index`` of the :class:`~pandas.core.frame.DataFrame` instance is
-        placed in the namespace by default, which allows you to treat the index
-        as a column in the frame. The identifier ``index`` is used for this
-        variable, and you can also use the name of the index to identify it in
-        a query.
+        The :attr:`~pandas.DataFrame.index` and
+        :attr:`~pandas.DataFrame.columns` attributes of the
+        :class:`~pandas.DataFrame` instance is placed in the namespace by
+        default, which allows you to treat both the index and columns of the
+        frame as a column in the frame.
+        The identifier ``index`` is used for this variable, and you can also
+        use the name of the index to identify it in a query.
 
         Raises
         ------
         NameError
-          * if not all identifiers in the query can be found
+          * If not all identifiers in the query can be found
         SyntaxError
-          * if a syntactically *invalid* Python expression is passed
+          * If a syntactically invalid Python expression is passed
 
         Examples
         --------
@@ -1986,9 +1989,9 @@ class DataFrame(NDFrame):
 
         See Also
         --------
-        pandas.computation.eval.eval
+        pandas.eval
         """
-        resolvers = kwargs.get('resolvers', None)
+        resolvers = kwargs.pop('resolvers', None)
         if resolvers is None:
             index_resolvers = {}
             if self.index.name is not None:
@@ -1996,7 +1999,7 @@ class DataFrame(NDFrame):
             index_resolvers.update({'index': self.index,
                                     'columns': self.columns})
             resolvers = [self, index_resolvers]
-            kwargs.update({'resolvers': resolvers})
+        kwargs['local_dict'] = _ensure_scope(resolvers=resolvers, **kwargs)
         return self[_eval(expr, **kwargs)]
 
     def _slice(self, slobj, axis=0, raise_on_error=False):
diff --git a/pandas/io/tests/test_data.py b/pandas/io/tests/test_data.py
index 34b281187..1cffccea2 100644
--- a/pandas/io/tests/test_data.py
+++ b/pandas/io/tests/test_data.py
@@ -277,7 +277,7 @@ class TestOptionsWarnings(unittest.TestCase):
         except ImportError:
             raise nose.SkipTest
 
-        with assert_produces_warning():
+        with assert_produces_warning(FutureWarning):
             cls.aapl = web.Options('aapl')
 
         today = datetime.today()
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index 88173c001..dfcbf0a98 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -2126,6 +2126,28 @@ class TestHDFStore(unittest.TestCase):
             for t in terms:
                 store.select('p4d', t)
 
+    def test_same_name_scoping(self):
+
+        with ensure_clean(self.path) as store:
+
+            import pandas as pd
+            df  = DataFrame(np.random.randn(20, 2),index=pd.date_range('20130101',periods=20))
+            store.put('df', df, table=True)
+            expected = df[df.index>pd.Timestamp('20130105')]
+
+            import datetime
+            result = store.select('df','index>datetime.datetime(2013,1,5)')
+            assert_frame_equal(result,expected)
+
+            from datetime import datetime
+
+            # technically an error, but allow it
+            result = store.select('df','index>datetime.datetime(2013,1,5)')
+            assert_frame_equal(result,expected)
+
+            result = store.select('df','index>datetime(2013,1,5)')
+            assert_frame_equal(result,expected)
+
     def test_series(self):
 
         s = tm.makeStringSeries()
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index d53d966c6..dccd7a8d1 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -8097,6 +8097,25 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         expec = DataFrame([[nan, 2]])
         assert_frame_equal(res, expec)
 
+    def test_query_expressions_correct_failure(self):
+        try:
+            import numexpr as ne
+        except ImportError:
+            raise nose.SkipTest("cannot query engine numexpr when numexpr not installed")
+        df = self.frame
+        exprs = 'and', 'or', 'not'
+        exprs += tuple(x + tm.rands(5) for x in exprs)
+        exprs += tuple(tm.rands(5) + x for x in exprs)
+
+        for e in exprs:
+            self.assertRaises(KeyError, df.__getitem__, e)
+
+        for e in (' and ', ' or ', ' not '):
+            self.assertRaises(SyntaxError, df.__getitem__, e)
+
+        x = tm.randbool(size=(self.frame.shape[0],))
+        self.assertRaises(KeyError, df.__getitem__, 'x')
+
     def test_query_expressions(self):
         try:
             import numexpr as ne
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index a070fa7ca..461f5ab0f 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -20,7 +20,7 @@ from distutils.version import LooseVersion
 from numpy.random import randn, rand
 import numpy as np
 
-from pandas.core.common import isnull, _is_sequence, is_list_like
+from pandas.core.common import isnull, _is_sequence
 import pandas.core.index as index
 import pandas.core.series as series
 import pandas.core.frame as frame
@@ -1138,7 +1138,7 @@ class _AssertRaisesContextmanager(object):
 
 
 @contextmanager
-def assert_produces_warning(expected_warning=None, filter_level="always"):
+def assert_produces_warning(expected_warning=Warning, filter_level="always"):
     """
     Context manager for running code that expects to raise (or not raise)
     warnings.  Checks that code raises the expected warning and only the
@@ -1164,25 +1164,19 @@ def assert_produces_warning(expected_warning=None, filter_level="always"):
 
     ..warn:: This is *not* thread-safe.
     """
-    if expected_warning is None:
-        expected_warning = [Warning]
-    elif not is_list_like(expected_warning):
-        expected_warning = [expected_warning]
     with warnings.catch_warnings(record=True) as w:
         saw_warning = False
         warnings.simplefilter(filter_level)
         yield w
         extra_warnings = []
         for actual_warning in w:
-            if (expected_warning and any(issubclass(actual_warning.category,
-                                                    ew) for ew in
-                                         expected_warning)):
+            if (expected_warning and issubclass(actual_warning.category,
+                                                expected_warning)):
                 saw_warning = True
             else:
                 extra_warnings.append(actual_warning.category.__name__)
         if expected_warning:
-            msg = ', '.join(ew.__name__ for ew in expected_warning)
-            assert saw_warning, ("Did not see expected warning(s) of "
-                                 "class(es): %s." % msg)
+            assert saw_warning, ("Did not see expected warning of class %r."
+                                 % expected_warning.__name__)
         assert not extra_warnings, ("Caused unexpected warning(s): %r."
                                     % extra_warnings)
