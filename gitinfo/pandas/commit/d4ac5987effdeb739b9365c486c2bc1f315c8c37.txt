commit d4ac5987effdeb739b9365c486c2bc1f315c8c37
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Apr 17 22:53:44 2011 -0400

    broke something. sigh

diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index c0029e4a1..d34d9dbc4 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -2,9 +2,11 @@ import numpy as np
 
 import operator
 
-from pandas.core.series import Series
+from pandas.core.index import Index, NULL_INDEX
+from pandas.core.series import Series, TimeSeries
 from pandas.core.frame import DataFrame
 
+from pandas.lib.sparse import BlockIndex, IntIndex, SparseVector
 import pandas.lib.sparse as splib
 
 def make_sparse(series, kind='block', sparse_value=np.NaN):
@@ -12,54 +14,43 @@ def make_sparse(series, kind='block', sparse_value=np.NaN):
 
     kind : {'block', 'integer'}
     """
+    assert(isinstance(series, Series))
+
+    if kind == 'block':
+        pass
+    elif kind == 'integer':
+        pass
+    else:
+        raise ValueError('must be block or integer type')
 
 class SparseSeries(Series):
     """
     Data structure for labeled, sparse floating point data
+
+    Parameters
+    ----------
+
     """
 
-    def __new__(cls, data, index=None, copy=False):
-        if isinstance(data, Series):
+    def __new__(cls, data, index=None, copy=False, kind='block',
+                sparse_value=np.NaN):
+
+        if isinstance(data, SparseVector):
+            if index is not None:
+                assert(len(index) == data.length)
+        elif isinstance(data, (Series, dict)):
+            data = Series(data)
+
             if index is None:
                 index = data.index
-        elif isinstance(data, dict):
-            if index is None:
-                index = Index(sorted(data.keys()))
-            data = [data[idx] for idx in index]
 
-        # Create array, do *not* copy data by default, infer type
-        try:
-            subarr = np.array(data, dtype=dtype, copy=copy)
-        except ValueError:
-            if dtype:
-                raise
-
-            subarr = np.array(data, dtype=object)
-
-        if subarr.ndim == 0:
-            if isinstance(data, list): # pragma: no cover
-                subarr = np.array(data, dtype=object)
-            elif index is not None:
-                value = data
-
-                # If we create an empty array using a string to infer
-                # the dtype, NumPy will only allocate one character per entry
-                # so this is kind of bad. Alternately we could use np.repeat
-                # instead of np.empty (but then you still don't want things
-                # coming out as np.str_!
-                if isinstance(value, basestring) and dtype is None:
-                    dtype = np.object_
-
-                if dtype is None:
-                    subarr = np.empty(len(index), dtype=type(value))
-                else:
-                    subarr = np.empty(len(index), dtype=dtype)
-                subarr.fill(value)
-            else:
-                return subarr.item()
+            data = make_sparse(data, kind=kind)
 
-        elif subarr.ndim > 1:
-            raise Exception('Data must be 1-dimensional')
+        if index is None:
+            index = Index(np.arange(data.length))
+
+        # Create array, do *not* copy data by default, infer type
+        subarr = np.array(data.values, dtype=np.float64, copy=False)
 
         if index is None:
             raise Exception('Index cannot be None!')
@@ -69,37 +60,48 @@ class SparseSeries(Series):
         if issubclass(subarr.dtype.type, basestring):
             subarr = np.array(data, dtype=object, copy=copy)
 
+        if subarr.index._allDates:
+            cls = SparseTimeSeries
+
         # Change the class of the array to be the subclass type.
         subarr = subarr.view(cls)
         subarr.index = index
-
-        if subarr.index._allDates:
-            subarr = subarr.view(TimeSeries)
-
+        subarr._vector = data
+        subarr._sparse_value = sparse_value
         return subarr
 
     def __hash__(self):
         raise TypeError('unhashable type')
 
-    _index = None
-    def _get_index(self):
-        return self._index
+    def __setslice__(self, i, j, value):
+        """Set slice equal to given value(s)"""
+        ndarray.__setslice__(self, i, j, value)
 
-    def _set_index(self, index):
-        indexTypes = ndarray, Index, list, tuple
-        if not isinstance(index, indexTypes):
-            raise TypeError("Expected index to be in %s; was %s."
-                            % (indexTypes, type(index)))
+    def __repr__(self):
+        """Clean string representation of a Series"""
+        vals = self.values
+        index = self.index
+
+        if len(index) > 500:
+            head = _seriesRepr(index[:50], vals[:50])
+            tail = _seriesRepr(index[-50:], vals[-50:])
+            return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
+        elif len(index) > 0:
+            return _seriesRepr(index, vals)
+        else:
+            return '%s' % ndarray.__repr__(self)
 
-        if len(self) != len(index):
-            raise AssertionError('Lengths of index and values did not match!')
+    def __contains__(self, key):
+        return key in self.index
 
-        if not isinstance(index, Index):
-            index = Index(index)
+    def __len__(self):
+        return self._vector.length
 
-        self._index = index
+    def __str__(self):
+        return repr(self)
 
-    index = property(fget=_get_index, fset=_set_index)
+    def __iter__(self):
+        return iter(self.values)
 
     def __array_finalize__(self, obj):
         """
@@ -107,6 +109,8 @@ class SparseSeries(Series):
         to pass on the index.
         """
         self._index = getattr(obj, '_index', None)
+        self._vector = getattr(obj, '_vector', None)
+        self._sparse_value = getattr(obj, '_sparse_value', None)
 
     def toDict(self):
         return dict(self.iteritems())
@@ -118,23 +122,6 @@ class SparseSeries(Series):
 
         return Series(value, index=index, dtype=dtype)
 
-    def __contains__(self, key):
-        return key in self.index
-
-    def __reduce__(self):
-        """Necessary for making this object picklable"""
-        object_state = list(ndarray.__reduce__(self))
-        subclass_state = (self.index, )
-        object_state[2] = (object_state[2], subclass_state)
-        return tuple(object_state)
-
-    def __setstate__(self, state):
-        """Necessary for making this object picklable"""
-        nd_state, own_state = state
-        ndarray.__setstate__(self, nd_state)
-        index, = own_state
-        self.index = index
-
     def __getitem__(self, key):
         """
         Returns item(s) for requested index/sequence, overrides default behavior
@@ -189,66 +176,114 @@ class SparseSeries(Series):
         else:
             return default
 
-    def __getslice__(self, i, j):
+    @property
+    def values(self):
+        return self._vector.to_ndarray()
+
+    def to_dense(self):
+        """
+        Convert SparseSeries to (dense) Series
         """
-        Returns a slice of the Series.
+        return Series(self.values, index=self.index)
 
-        Note that the underlying values are COPIES.
+    def copy(self):
+        vec_copy = self._vector.copy()
+        return SparseSeries(vec_copy, index=self.index)
 
-        The reason that the getslice returns copies is that otherwise you
-        will have a reference to the original series which could be
-        inadvertently changed if the slice were altered (made mutable).
-        """
-        newArr = self.values[i:j].copy()
-        newIndex = self.index[i:j]
+class SparseTimeSeries(SparseSeries, TimeSeries):
+    pass
 
-        return Series(newArr, index=newIndex)
+class SparseDataFrame(DataFrame):
+    _columns = None
+
+    def __init__(self, data=None, index=None, columns=None, dtype=None):
+        if isinstance(data, dict):
+            sdict, columns, index = self._init_dict(data, index, columns, dtype)
+        elif isinstance(data, (np.ndarray, list)):
+            sdict, columns, index = self._init_matrix(data, index, columns,
+                                                      dtype)
+        elif isinstance(data, DataFrame):
+            sdict = data._series.copy()
+
+            if dtype is not None:
+                sdict = dict((k, v.astype(dtype)) for k, v in data.iteritems())
+            index = data.index
+            columns = data.columns
+        elif data is None:
+            sdict = {}
 
-    def __setitem__(self, key, value):
-        """
-        If this series is mutable, set specified indices equal to given values.
-        """
-        try:
-            loc = self.index.indexMap[key]
-            ndarray.__setitem__(self, loc, value)
-        except Exception:
-            values = self.values
-            values[key] = value
+            if index is None:
+                index = NULL_INDEX
 
-    def __setslice__(self, i, j, value):
-        """Set slice equal to given value(s)"""
-        ndarray.__setslice__(self, i, j, value)
+            if columns is None:
+                columns = NULL_INDEX
+            else:
+                for c in columns:
+                    sdict[c] = Series(np.NaN, index=index)
 
-    def __repr__(self):
-        """Clean string representation of a Series"""
-        vals = self.values
-        index = self.index
+        self._series = sdict
+        self.columns = columns
+        self.index = index
 
-        if len(index) > 500:
-            head = _seriesRepr(index[:50], vals[:50])
-            tail = _seriesRepr(index[-50:], vals[-50:])
-            return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
-        elif len(index) > 0:
-            return _seriesRepr(index, vals)
+    def _init_dict(self, data, index, columns, dtype):
+        # pre-filter out columns if we passed it
+        if columns is not None:
+            if not isinstance(columns, Index):
+                columns = Index(columns)
+
+            data = dict((k, v) for k, v in data.iteritems() if k in columns)
         else:
-            return '%s' % ndarray.__repr__(self)
+            columns = Index(_try_sort(data.keys()))
 
-    def toString(self, buffer=sys.stdout, nanRep='NaN'):
-        print >> buffer, _seriesRepr(self.index, self.values,
-                                     nanRep=nanRep)
+        index = _extract_index(data, index)
 
-    def __str__(self):
-        return repr(self)
+        sdict = {}
+        for k, v in data.iteritems():
+            if isinstance(v, Series):
+                # Forces alignment and copies data
+                sdict[k] = v.reindex(index)
+            else:
+                if isinstance(v, dict):
+                    v = [v.get(i, NaN) for i in index]
 
-    def __iter__(self):
-        return iter(self.values)
+                try:
+                    v = Series(v, dtype=dtype, index=index)
+                except Exception:
+                    v = Series(v, index=index)
 
-    def to_dense(self):
-        pass
+                sdict[k] = v.copy()
 
-    def copy(self):
-        vec_copy = self._vector.copy()
-        return SparseSeries(vec_copy, index=self.index)
+        # add in any other columns we want to have (completeness)
+        for c in columns:
+            if c not in sdict:
+                sdict[c] = Series(np.NaN, index=index)
 
-class SparseDataFrame(DataFrame):
-    pass
+        return sdict, columns, index
+
+    def _init_matrix(self, data, index, columns, dtype):
+        if not isinstance(data, np.ndarray):
+            arr = np.array(data)
+            if issubclass(arr.dtype.type, basestring):
+                arr = np.array(data, dtype=object, copy=True)
+
+            data = arr
+
+        if data.ndim == 1:
+            data = data.reshape((len(data), 1))
+        elif data.ndim != 2:
+            raise Exception('Must pass 2-d input!')
+
+        N, K = data.shape
+
+        if index is None:
+            index = _default_index(N)
+
+        if columns is None:
+            columns = _default_index(K)
+
+        if len(columns) != K:
+            raise Exception('Column length mismatch: %d vs. %d' %
+                            (len(columns), K))
+
+        data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
+        return self._init_dict(data, index, columns, dtype)
diff --git a/pandas/lib/Makefile b/pandas/lib/Makefile
index ecfea00ff..d3d58c8ab 100644
--- a/pandas/lib/Makefile
+++ b/pandas/lib/Makefile
@@ -3,4 +3,4 @@ sparse: src/sparse.pyx
 	-python build.py build_ext --inplace
 
 test: sparse
-	-python test_sparse.py
\ No newline at end of file
+	-python tests/test_sparse.py
\ No newline at end of file
diff --git a/pandas/lib/src/sparse.pyx b/pandas/lib/src/sparse.pyx
index bdd20d4a6..fdfefecbc 100644
--- a/pandas/lib/src/sparse.pyx
+++ b/pandas/lib/src/sparse.pyx
@@ -106,6 +106,10 @@ cdef class IntIndex(SparseIndex):
         lens.append(length)
         return BlockIndex(self.length, locs, lens)
 
+    # def to_block_index(self):
+    #     locs, lens = get_blocks(self.indices)
+    #     return BlockIndex(self.length, locs, lens)
+
     cpdef intersect(self, SparseIndex y_):
         cdef:
             pyst i, xi, yi = 0
@@ -131,6 +135,39 @@ cdef class IntIndex(SparseIndex):
 
         return IntIndex(self.length, new_list)
 
+
+cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
+    cdef:
+        pyst i, npoints
+        int32_t block, length = 1, cur, prev
+        list locs = [], lens = []
+
+    npoints = len(indices)
+
+    # just handle the special empty case separately
+    if npoints == 0:
+        return [], []
+
+    # TODO: two-pass algorithm faster?
+    prev = block = indices[0]
+    for i from 1 <= i < npoints:
+        cur = indices[i]
+        if cur - prev > 1:
+            # new block
+            locs.append(block)
+            lens.append(length)
+            block = cur
+            length = 1
+        else:
+            # same block, increment length
+            length += 1
+
+        prev = cur
+
+    locs.append(block)
+    lens.append(length)
+    return locs, lens
+
 #-------------------------------------------------------------------------------
 # BlockIndex
 
@@ -329,7 +366,7 @@ cdef class SparseVector:
         self.index = index
         self.vbuf = <float64_t*> self.values.data
 
-        self.length = len(values)
+        self.length = index.length
         self.fill_value = fill_value
 
     def __repr__(self):
diff --git a/pandas/lib/tests/test_sparse.py b/pandas/lib/tests/test_sparse.py
index f587eff37..71998abee 100644
--- a/pandas/lib/tests/test_sparse.py
+++ b/pandas/lib/tests/test_sparse.py
@@ -7,8 +7,8 @@ import numpy as np
 import operator
 from numpy.testing import assert_almost_equal, assert_equal
 
-from sparse import IntIndex, BlockIndex, SparseVector
-import sparse
+from pandas.lib.sparse import IntIndex, BlockIndex, SparseVector
+import pandas.lib.sparse as sparse
 
 TEST_LENGTH = 20
 
