commit 307137ce95869fe636d99d38059827e8c063d430
Author: MomIsBestFriend <50263213+MomIsBestFriend@users.noreply.github.com>
Date:   Tue Jan 14 00:01:38 2020 +0200

    STY: concat strings (#30979)

diff --git a/pandas/__init__.py b/pandas/__init__.py
index 491bcb21f..d526531b1 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -35,8 +35,7 @@ except ImportError as e:  # pragma: no cover
     raise ImportError(
         f"C extension: {module} not built. If you want to import "
         "pandas from the source directory, you may need to run "
-        "'python setup.py build_ext --inplace --force' to build "
-        "the C extensions first."
+        "'python setup.py build_ext --inplace --force' to build the C extensions first."
     )
 
 from pandas._config import (
@@ -198,8 +197,7 @@ if pandas.compat.PY37:
 
             warnings.warn(
                 "The Panel class is removed from pandas. Accessing it "
-                "from the top-level namespace will also be removed in "
-                "the next version",
+                "from the top-level namespace will also be removed in the next version",
                 FutureWarning,
                 stacklevel=2,
             )
@@ -238,8 +236,7 @@ if pandas.compat.PY37:
         elif name in {"SparseSeries", "SparseDataFrame"}:
             warnings.warn(
                 f"The {name} class is removed from pandas. Accessing it from "
-                "the top-level namespace will also be removed in the next "
-                "version",
+                "the top-level namespace will also be removed in the next version",
                 FutureWarning,
                 stacklevel=2,
             )
diff --git a/pandas/_config/config.py b/pandas/_config/config.py
index 0a3009f74..42df8a84a 100644
--- a/pandas/_config/config.py
+++ b/pandas/_config/config.py
@@ -165,8 +165,7 @@ def _reset_option(pat, silent=False):
         raise ValueError(
             "You must specify at least 4 characters when "
             "resetting multiple keys, use the special keyword "
-            '"all" to reset all the options to their default '
-            "value"
+            '"all" to reset all the options to their default value'
         )
 
     for k in keys:
diff --git a/pandas/core/ops/__init__.py b/pandas/core/ops/__init__.py
index f51d71d55..1355060ef 100644
--- a/pandas/core/ops/__init__.py
+++ b/pandas/core/ops/__init__.py
@@ -664,8 +664,7 @@ def _align_method_FRAME(left, right, axis):
 
         elif right.ndim > 2:
             raise ValueError(
-                "Unable to coerce to Series/DataFrame, dim "
-                f"must be <= 2: {right.shape}"
+                f"Unable to coerce to Series/DataFrame, dim must be <= 2: {right.shape}"
             )
 
     elif is_list_like(right) and not isinstance(right, (ABCSeries, ABCDataFrame)):
diff --git a/pandas/core/reshape/melt.py b/pandas/core/reshape/melt.py
index d4ccb19fc..d04287e1e 100644
--- a/pandas/core/reshape/melt.py
+++ b/pandas/core/reshape/melt.py
@@ -52,8 +52,7 @@ def melt(
             if not missing.empty:
                 raise KeyError(
                     "The following 'id_vars' are not present "
-                    "in the DataFrame: {missing}"
-                    "".format(missing=list(missing))
+                    f"in the DataFrame: {list(missing)}"
                 )
     else:
         id_vars = []
@@ -74,8 +73,7 @@ def melt(
             if not missing.empty:
                 raise KeyError(
                     "The following 'value_vars' are not present in "
-                    "the DataFrame: {missing}"
-                    "".format(missing=list(missing))
+                    f"the DataFrame: {list(missing)}"
                 )
         frame = frame.loc[:, id_vars + value_vars]
     else:
diff --git a/pandas/core/reshape/merge.py b/pandas/core/reshape/merge.py
index 5f92e4a88..acb53ff6c 100644
--- a/pandas/core/reshape/merge.py
+++ b/pandas/core/reshape/merge.py
@@ -600,13 +600,11 @@ class _MergeOperation:
 
         if not is_bool(left_index):
             raise ValueError(
-                "left_index parameter must be of type bool, not "
-                "{left_index}".format(left_index=type(left_index))
+                f"left_index parameter must be of type bool, not {type(left_index)}"
             )
         if not is_bool(right_index):
             raise ValueError(
-                "right_index parameter must be of type bool, not "
-                "{right_index}".format(right_index=type(right_index))
+                f"right_index parameter must be of type bool, not {type(right_index)}"
             )
 
         # warn user when merging between different levels
@@ -1092,8 +1090,7 @@ class _MergeOperation:
                         warnings.warn(
                             "You are merging on int and float "
                             "columns where the float values "
-                            "are not equal to their int "
-                            "representation",
+                            "are not equal to their int representation",
                             UserWarning,
                         )
                     continue
@@ -1103,8 +1100,7 @@ class _MergeOperation:
                         warnings.warn(
                             "You are merging on int and float "
                             "columns where the float values "
-                            "are not equal to their int "
-                            "representation",
+                            "are not equal to their int representation",
                             UserWarning,
                         )
                     continue
@@ -1251,20 +1247,17 @@ class _MergeOperation:
                 )
             elif not left_unique:
                 raise MergeError(
-                    "Merge keys are not unique in left dataset; "
-                    "not a one-to-one merge"
+                    "Merge keys are not unique in left dataset; not a one-to-one merge"
                 )
             elif not right_unique:
                 raise MergeError(
-                    "Merge keys are not unique in right dataset; "
-                    "not a one-to-one merge"
+                    "Merge keys are not unique in right dataset; not a one-to-one merge"
                 )
 
         elif validate in ["one_to_many", "1:m"]:
             if not left_unique:
                 raise MergeError(
-                    "Merge keys are not unique in left dataset; "
-                    "not a one-to-many merge"
+                    "Merge keys are not unique in left dataset; not a one-to-many merge"
                 )
 
         elif validate in ["many_to_one", "m:1"]:
@@ -1833,8 +1826,7 @@ def _left_join_on_index(left_ax: Index, right_ax: Index, join_keys, sort: bool =
             raise AssertionError(
                 "If more than one join key is given then "
                 "'right_ax' must be a MultiIndex and the "
-                "number of join keys must be the number of "
-                "levels in right_ax"
+                "number of join keys must be the number of levels in right_ax"
             )
 
         left_indexer, right_indexer = _get_multiindex_indexer(
@@ -2004,8 +1996,7 @@ def _validate_operand(obj: FrameOrSeries) -> "DataFrame":
             return obj.to_frame()
     else:
         raise TypeError(
-            "Can only merge Series or DataFrame objects, "
-            "a {obj} was passed".format(obj=type(obj))
+            f"Can only merge Series or DataFrame objects, a {type(obj)} was passed"
         )
 
 
@@ -2021,10 +2012,7 @@ def _items_overlap_with_suffix(left: Index, lsuffix, right: Index, rsuffix):
         return left, right
 
     if not lsuffix and not rsuffix:
-        raise ValueError(
-            "columns overlap but no suffix specified: "
-            "{rename}".format(rename=to_rename)
-        )
+        raise ValueError(f"columns overlap but no suffix specified: {to_rename}")
 
     def renamer(x, suffix):
         """
@@ -2043,7 +2031,7 @@ def _items_overlap_with_suffix(left: Index, lsuffix, right: Index, rsuffix):
         x : renamed column name
         """
         if x in to_rename and suffix is not None:
-            return "{x}{suffix}".format(x=x, suffix=suffix)
+            return f"{x}{suffix}"
         return x
 
     lrenamer = partial(renamer, suffix=lsuffix)
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index 2e3eb9170..5a444d908 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -363,8 +363,7 @@ def _bins_to_cuts(
 
     if duplicates not in ["raise", "drop"]:
         raise ValueError(
-            "invalid value for 'duplicates' parameter, "
-            "valid options are: raise, drop"
+            "invalid value for 'duplicates' parameter, valid options are: raise, drop"
         )
 
     if isinstance(bins, IntervalIndex):
diff --git a/pandas/core/tools/datetimes.py b/pandas/core/tools/datetimes.py
index cfa42d764..898fbc6f8 100644
--- a/pandas/core/tools/datetimes.py
+++ b/pandas/core/tools/datetimes.py
@@ -231,9 +231,7 @@ def _return_parsed_timezone_results(result, timezones, tz, name):
     """
     if tz is not None:
         raise ValueError(
-            "Cannot pass a tz argument when "
-            "parsing strings with timezone "
-            "information."
+            "Cannot pass a tz argument when parsing strings with timezone information."
         )
     tz_results = np.array(
         [Timestamp(res).tz_localize(zone) for res, zone in zip(result, timezones)]
@@ -817,8 +815,7 @@ def _assemble_from_unit_mappings(arg, errors, tz):
         required = ",".join(req)
         raise ValueError(
             "to assemble mappings requires at least that "
-            f"[year, month, day] be specified: [{required}] "
-            "is missing"
+            f"[year, month, day] be specified: [{required}] is missing"
         )
 
     # keys we don't recognize
diff --git a/pandas/core/window/common.py b/pandas/core/window/common.py
index 64ec0e68e..ed0b816f6 100644
--- a/pandas/core/window/common.py
+++ b/pandas/core/window/common.py
@@ -98,8 +98,7 @@ def _flex_binary_moment(arg1, arg2, f, pairwise=False):
         and isinstance(arg2, (np.ndarray, ABCSeries, ABCDataFrame))
     ):
         raise TypeError(
-            "arguments to moment function must be of type "
-            "np.ndarray/Series/DataFrame"
+            "arguments to moment function must be of type np.ndarray/Series/DataFrame"
         )
 
     if isinstance(arg1, (np.ndarray, ABCSeries)) and isinstance(
diff --git a/pandas/core/window/rolling.py b/pandas/core/window/rolling.py
index f61282613..bdc94c740 100644
--- a/pandas/core/window/rolling.py
+++ b/pandas/core/window/rolling.py
@@ -1820,8 +1820,7 @@ class Rolling(_Rolling_and_Expanding):
         else:
             raise ValueError(
                 f"invalid on specified as {self.on}, "
-                "must be a column (of DataFrame), an Index "
-                "or None"
+                "must be a column (of DataFrame), an Index or None"
             )
 
     def validate(self):
@@ -1838,9 +1837,8 @@ class Rolling(_Rolling_and_Expanding):
             # we don't allow center
             if self.center:
                 raise NotImplementedError(
-                    "center is not implemented "
-                    "for datetimelike and offset "
-                    "based windows"
+                    "center is not implemented for "
+                    "datetimelike and offset based windows"
                 )
 
             # this will raise ValueError on non-fixed freqs
@@ -1886,8 +1884,7 @@ class Rolling(_Rolling_and_Expanding):
         except (TypeError, ValueError):
             raise ValueError(
                 f"passed window {self.window} is not "
-                "compatible with a datetimelike "
-                "index"
+                "compatible with a datetimelike index"
             )
 
     _agg_see_also_doc = dedent(
diff --git a/pandas/io/excel/_util.py b/pandas/io/excel/_util.py
index a084be54d..9d284c803 100644
--- a/pandas/io/excel/_util.py
+++ b/pandas/io/excel/_util.py
@@ -136,8 +136,7 @@ def _maybe_convert_usecols(usecols):
     if is_integer(usecols):
         raise ValueError(
             "Passing an integer for `usecols` is no longer supported.  "
-            "Please pass in a list of int from 0 to `usecols` "
-            "inclusive instead."
+            "Please pass in a list of int from 0 to `usecols` inclusive instead."
         )
 
     if isinstance(usecols, str):
diff --git a/pandas/io/formats/format.py b/pandas/io/formats/format.py
index 6adf69a92..296b305f4 100644
--- a/pandas/io/formats/format.py
+++ b/pandas/io/formats/format.py
@@ -737,12 +737,8 @@ class DataFrameFormatter(TableFormatter):
                 self.header = cast(List[str], self.header)
                 if len(self.header) != len(self.columns):
                     raise ValueError(
-                        (
-                            "Writing {ncols} cols but got {nalias} "
-                            "aliases".format(
-                                ncols=len(self.columns), nalias=len(self.header)
-                            )
-                        )
+                        f"Writing {len(self.columns)} cols "
+                        f"but got {len(self.header)} aliases"
                     )
                 str_columns = [[label] for label in self.header]
             else:
diff --git a/pandas/io/formats/html.py b/pandas/io/formats/html.py
index b46b2f6c6..e3161415f 100644
--- a/pandas/io/formats/html.py
+++ b/pandas/io/formats/html.py
@@ -216,8 +216,8 @@ class HTMLFormatter(TableFormatter):
                 self.classes = self.classes.split()
             if not isinstance(self.classes, (list, tuple)):
                 raise TypeError(
-                    "classes must be a string, list, or tuple, "
-                    "not {typ}".format(typ=type(self.classes))
+                    "classes must be a string, list, "
+                    f"or tuple, not {type(self.classes)}"
                 )
             _classes.extend(self.classes)
 
diff --git a/pandas/io/formats/latex.py b/pandas/io/formats/latex.py
index 008a99427..8ab56437d 100644
--- a/pandas/io/formats/latex.py
+++ b/pandas/io/formats/latex.py
@@ -114,8 +114,7 @@ class LatexFormatter(TableFormatter):
                 column_format = index_format + column_format
         elif not isinstance(self.column_format, str):  # pragma: no cover
             raise AssertionError(
-                "column_format must be str or unicode, "
-                "not {typ}".format(typ=type(column_format))
+                f"column_format must be str or unicode, not {type(column_format)}"
             )
         else:
             column_format = self.column_format
diff --git a/pandas/io/sas/sas.pyx b/pandas/io/sas/sas.pyx
index bb5bce96b..211935009 100644
--- a/pandas/io/sas/sas.pyx
+++ b/pandas/io/sas/sas.pyx
@@ -267,8 +267,9 @@ cdef class Parser:
             elif column_types[j] == b's':
                 self.column_types[j] = column_type_string
             else:
-                raise ValueError("unknown column type: "
-                                 f"{self.parser.columns[j].ctype}")
+                raise ValueError(
+                    f"unknown column type: {self.parser.columns[j].ctype}"
+                )
 
         # compression
         if parser.compression == const.rle_compression:
diff --git a/pandas/io/sas/sas7bdat.py b/pandas/io/sas/sas7bdat.py
index f917477b8..9b40778db 100644
--- a/pandas/io/sas/sas7bdat.py
+++ b/pandas/io/sas/sas7bdat.py
@@ -459,8 +459,7 @@ class SAS7BDATReader(abc.Iterator):
         if self.col_count_p1 + self.col_count_p2 != self.column_count:
             print(
                 f"Warning: column count mismatch ({self.col_count_p1} + "
-                f"{self.col_count_p2} != "
-                f"{self.column_count})\n"
+                f"{self.col_count_p2} != {self.column_count})\n"
             )
 
     # Unknown purpose
@@ -672,8 +671,7 @@ class SAS7BDATReader(abc.Iterator):
             self.close()
             msg = (
                 "failed to read complete page from file (read "
-                f"{len(self._cached_page):d} of "
-                f"{self._page_length:d} bytes)"
+                f"{len(self._cached_page):d} of {self._page_length:d} bytes)"
             )
             raise ValueError(msg)
 
diff --git a/pandas/io/sas/sasreader.py b/pandas/io/sas/sasreader.py
index 56ebb583b..27d56d4ed 100644
--- a/pandas/io/sas/sasreader.py
+++ b/pandas/io/sas/sasreader.py
@@ -49,8 +49,7 @@ def read_sas(
     if format is None:
         buffer_error_msg = (
             "If this is a buffer object rather "
-            "than a string name, you must specify "
-            "a format string"
+            "than a string name, you must specify a format string"
         )
         filepath_or_buffer = stringify_path(filepath_or_buffer)
         if not isinstance(filepath_or_buffer, str):
diff --git a/scripts/generate_pip_deps_from_conda.py b/scripts/generate_pip_deps_from_conda.py
index 53a27e878..9e0ec4df0 100755
--- a/scripts/generate_pip_deps_from_conda.py
+++ b/scripts/generate_pip_deps_from_conda.py
@@ -132,8 +132,7 @@ if __name__ == "__main__":
         )
         if args.azure:
             msg = (
-                "##vso[task.logissue type=error;"
-                f"sourcepath=requirements-dev.txt]{msg}"
+                f"##vso[task.logissue type=error;sourcepath=requirements-dev.txt]{msg}"
             )
         sys.stderr.write(msg)
     sys.exit(res)
