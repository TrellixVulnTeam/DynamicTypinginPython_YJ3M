commit d1a1fa27e520c0d196981df58edb1bd5d3cc3161
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Dec 10 19:51:46 2012 -0500

    ENH: improve value_counts performance on non-integer data. close #2480

diff --git a/RELEASE.rst b/RELEASE.rst
index 38605530b..c691d92f4 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -143,6 +143,7 @@ pandas 0.10.0
   - The DataFrame ctor now respects column ordering when given
     an OrderedDict (#2455)
   - Assigning DatetimeIndex to Series changes the class to TimeSeries (#2139)
+  - Improve performance of .value_counts method on non-integer data (#2480)
 
 **Bug fixes**
 
diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 2e7d8731a..052dbcfc8 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -161,20 +161,18 @@ def value_counts(values, sort=True, ascending=False):
     value_counts : Series
     """
     from pandas.core.series import Series
-    from collections import defaultdict
 
     values = np.asarray(values)
 
     if com.is_integer_dtype(values.dtype):
         values = com._ensure_int64(values)
         keys, counts = htable.value_count_int64(values)
-        result = Series(counts, index=keys)
     else:
-        counter = defaultdict(lambda: 0)
-        values = values[com.notnull(values)]
-        for value in values:
-            counter[value] += 1
-        result = Series(counter)
+        mask = com.isnull(values)
+        values = com._ensure_object(values)
+        keys, counts = htable.value_count_object(values, mask)
+
+    result = Series(counts, index=keys)
 
     if sort:
         result.sort()
diff --git a/pandas/hashtable.pyx b/pandas/hashtable.pyx
index 2e799bdd5..f20462405 100644
--- a/pandas/hashtable.pyx
+++ b/pandas/hashtable.pyx
@@ -913,3 +913,39 @@ def value_count_int64(ndarray[int64_t] values):
     kh_destroy_int64(table)
 
     return result_keys, result_counts
+
+def value_count_object(ndarray[object] values,
+                       ndarray[uint8_t, cast=True] mask):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        kh_pymap_t *table
+        int ret = 0
+        list uniques = []
+
+    table = kh_init_pymap()
+    kh_resize_pymap(table, n // 10)
+
+    for i in range(n):
+        if mask[i]:
+            continue
+
+        val = values[i]
+        k = kh_get_pymap(table, <PyObject*> val)
+        if k != table.n_buckets:
+            table.vals[k] += 1
+        else:
+            k = kh_put_pymap(table, <PyObject*> val, &ret)
+            table.vals[k] = 1
+
+    i = 0
+    result_keys = np.empty(table.n_occupied, dtype=object)
+    result_counts = np.zeros(table.n_occupied, dtype=np.int64)
+    for k in range(table.n_buckets):
+        if kh_exist_pymap(table, k):
+            result_keys[i] = <object> table.keys[k]
+            result_counts[i] = table.vals[k]
+            i += 1
+    kh_destroy_pymap(table)
+
+    return result_keys, result_counts
+
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index a8bc82860..8b82d45ce 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -2001,7 +2001,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         s = Series({})
         hist = s.value_counts()
-        expected = Series([])
+        expected = Series([], dtype=np.int64)
         assert_series_equal(hist, expected)
 
     def test_unique(self):
diff --git a/vb_suite/groupby.py b/vb_suite/groupby.py
index b95e1e65e..61bf7aa07 100644
--- a/vb_suite/groupby.py
+++ b/vb_suite/groupby.py
@@ -122,6 +122,18 @@ s = Series(np.random.randint(0, 1000, size=100000))
 series_value_counts_int64 = Benchmark('s.value_counts()', setup,
                                       start_date=datetime(2011, 10, 21))
 
+# value_counts on lots of strings
+
+setup = common_setup + """
+K = 1000
+N = 100000
+uniques = np.array([rands(10) for x in xrange(K)], dtype='O')
+s = Series(np.tile(uniques, N // K))
+"""
+
+series_value_counts_strings = Benchmark('s.value_counts()', setup,
+                                        start_date=datetime(2011, 10, 21))
+
 #----------------------------------------------------------------------
 # pivot_table
 
