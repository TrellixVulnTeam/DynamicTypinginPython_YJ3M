commit 5568670ff1ecc23577825ae3c56d1a4ac40f93f1
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Nov 26 17:23:56 2012 -0500

    BUG: route warning messages from tokenizer to sys.stderr. close #2361

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 9648077ea..04c3f80df 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1116,8 +1116,7 @@ class Grouping(object):
         if self._was_factor:  # pragma: no cover
             raise Exception('Should not call this method grouping by level')
         else:
-            labs, uniques = algos.factorize(self.grouper,
-                                                    sort=self.sort)
+            labs, uniques = algos.factorize(self.grouper, sort=self.sort)
             uniques = Index(uniques, name=self.name)
             self._labels = labs
             self._group_index = uniques
diff --git a/pandas/io/tests/test_cparser.py b/pandas/io/tests/test_cparser.py
index e0b58f67c..725bb6636 100644
--- a/pandas/io/tests/test_cparser.py
+++ b/pandas/io/tests/test_cparser.py
@@ -141,7 +141,8 @@ class TestCParser(unittest.TestCase):
                 'd:e:f\n'
                 'g:h:i\n'
                 'j:k\n'
-                'l:m:n')
+                'l:m:n\n'
+                'o:p')
 
         reader = TextReader(StringIO(data), delimiter=':',
                             header=None)
@@ -157,6 +158,20 @@ class TestCParser(unittest.TestCase):
                     2: ['c', 'f', 'i', 'n']}
         assert_array_dicts_equal(result, expected)
 
+        stderr = sys.stderr
+        sys.stderr = StringIO()
+        try:
+            reader = TextReader(StringIO(data), delimiter=':',
+                                header=None,
+                                error_bad_lines=False,
+                                warn_bad_lines=True)
+            reader.read()
+            val = sys.stderr.getvalue()
+            self.assertTrue('Skipping line 4' in val)
+            self.assertTrue('Skipping line 6' in val)
+        finally:
+            sys.stderr = stderr
+
     def test_header_not_enough_lines(self):
         data = ('skip this\n'
                 'skip this\n'
diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index 8b1ce1b89..0bc10df59 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -142,6 +142,7 @@ cdef extern from "parser/tokenizer.h":
         int skip_footer
 
         #  error handling
+        char *warn_msg
         char *error_msg
 
     ctypedef struct coliter_t:
@@ -651,6 +652,11 @@ cdef class TextReader:
         with nogil:
             status = tokenize_nrows(self.parser, nrows)
 
+        if self.parser.warn_msg != NULL:
+            print >> sys.stderr, self.parser.warn_msg
+            free(self.parser.warn_msg)
+            self.parser.warn_msg = NULL
+
         if status < 0:
             raise_parser_error('Error tokenizing data', self.parser)
 
@@ -673,6 +679,12 @@ cdef class TextReader:
         else:
             with nogil:
                 status = tokenize_all_rows(self.parser)
+
+            if self.parser.warn_msg != NULL:
+                print >> sys.stderr, self.parser.warn_msg
+                free(self.parser.warn_msg)
+                self.parser.warn_msg = NULL
+
             if status < 0:
                 raise_parser_error('Error tokenizing data', self.parser)
             footer = self.skip_footer
diff --git a/pandas/src/parser/tokenizer.c b/pandas/src/parser/tokenizer.c
index 6f396a2df..488ffb895 100644
--- a/pandas/src/parser/tokenizer.c
+++ b/pandas/src/parser/tokenizer.c
@@ -183,6 +183,7 @@ int parser_cleanup(parser_t *self) {
 
     // XXX where to put this
     free_if_not_null(self->error_msg);
+    free_if_not_null(self->warn_msg);
 
     if (self->skipset != NULL)
         kh_destroy_int64((kh_int64_t*) self->skipset);
@@ -252,6 +253,7 @@ int parser_init(parser_t *self) {
     self->state = START_RECORD;
 
     self->error_msg = NULL;
+    self->warn_msg = NULL;
 
     return 0;
 }
@@ -395,10 +397,27 @@ static int P_INLINE end_field(parser_t *self) {
     return 0;
 }
 
+
+static void append_warning(parser_t *self, const char *msg) {
+    int ex_length;
+    int length = strlen(msg);
+
+    if (self->warn_msg == NULL) {
+        self->warn_msg = (char*) malloc(length + 1);
+        strcpy(self->warn_msg, msg);
+    } else {
+        ex_length = strlen(self->warn_msg);
+        self->warn_msg = (char*) safe_realloc(self->warn_msg,
+                                              ex_length + length + 1);
+        strcpy(self->warn_msg + ex_length, msg);
+    }
+}
+
 static int end_line(parser_t *self) {
     int fields;
     khiter_t k;  /* for hash set detection */
     int ex_fields = -1;
+    char *msg;
 
     fields = self->line_fields[self->lines];
 
@@ -449,9 +468,12 @@ static int end_line(parser_t *self) {
         } else {
             // simply skip bad lines
             if (self->warn_bad_lines) {
-                // print error message
-                printf("Skipping line %d: expected %d fields, saw %d\n",
-                       self->file_lines, ex_fields, fields);
+                // pass up error message
+                msg = (char*) malloc(100);
+                sprintf(msg, "Skipping line %d: expected %d fields, saw %d\n",
+                        self->file_lines, ex_fields, fields);
+                append_warning(self, msg);
+                free(msg);
             }
         }
     } else {
@@ -1277,7 +1299,6 @@ int tokenize_all_rows(parser_t *self) {
     return status;
 }
 
-
 void test_count_lines(char *fname) {
     clock_t start = clock();
 
diff --git a/pandas/src/parser/tokenizer.h b/pandas/src/parser/tokenizer.h
index ef63f4fb3..698236570 100644
--- a/pandas/src/parser/tokenizer.h
+++ b/pandas/src/parser/tokenizer.h
@@ -194,6 +194,7 @@ typedef struct parser_t {
     int skip_footer;
 
     // error handling
+    char *warn_msg;
     char *error_msg;
 } parser_t;
 
