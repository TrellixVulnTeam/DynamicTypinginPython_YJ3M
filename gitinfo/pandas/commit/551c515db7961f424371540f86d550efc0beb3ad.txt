commit 551c515db7961f424371540f86d550efc0beb3ad
Author: Kaiqi Dong <kaiqi@kth.se>
Date:   Sat May 2 17:33:13 2020 +0200

    TST/REF: Move static methods out of consistency classes (#33927)

diff --git a/pandas/tests/window/moments/test_moments_ewm.py b/pandas/tests/window/moments/test_moments_ewm.py
index 370482652..99f1842ba 100644
--- a/pandas/tests/window/moments/test_moments_ewm.py
+++ b/pandas/tests/window/moments/test_moments_ewm.py
@@ -281,24 +281,26 @@ class TestEwmMomentsConsistency(ConsistencyBase):
     def test_ewmcov_pairwise(self):
         self._check_pairwise_moment("ewm", "cov", span=10, min_periods=5)
 
-    @pytest.mark.parametrize("name", ["cov", "corr"])
-    def test_ewm_corr_cov(self, name, min_periods, binary_ew_data):
-        A, B = binary_ew_data
-
-        check_binary_ew(name="corr", A=A, B=B)
-        check_binary_ew_min_periods("corr", min_periods, A, B)
-
     def test_ewmcorr_pairwise(self):
         self._check_pairwise_moment("ewm", "corr", span=10, min_periods=5)
 
-    @pytest.mark.parametrize("name", ["cov", "corr"])
-    def test_different_input_array_raise_exception(self, name, binary_ew_data):
 
-        A, _ = binary_ew_data
-        msg = "Input arrays must be of the same type!"
-        # exception raised is Exception
-        with pytest.raises(Exception, match=msg):
-            ew_func(A, randn(50), 20, name=name, min_periods=5)
+@pytest.mark.parametrize("name", ["cov", "corr"])
+def test_ewm_corr_cov(name, min_periods, binary_ew_data):
+    A, B = binary_ew_data
+
+    check_binary_ew(name="corr", A=A, B=B)
+    check_binary_ew_min_periods("corr", min_periods, A, B)
+
+
+@pytest.mark.parametrize("name", ["cov", "corr"])
+def test_different_input_array_raise_exception(name, binary_ew_data):
+
+    A, _ = binary_ew_data
+    msg = "Input arrays must be of the same type!"
+    # exception raised is Exception
+    with pytest.raises(Exception, match=msg):
+        ew_func(A, randn(50), 20, name=name, min_periods=5)
 
 
 @pytest.mark.slow
diff --git a/pandas/tests/window/moments/test_moments_expanding.py b/pandas/tests/window/moments/test_moments_expanding.py
index e97383823..d20ab5131 100644
--- a/pandas/tests/window/moments/test_moments_expanding.py
+++ b/pandas/tests/window/moments/test_moments_expanding.py
@@ -22,22 +22,6 @@ class TestExpandingMomentsConsistency(ConsistencyBase):
     def setup_method(self, method):
         self._create_data()
 
-    def test_expanding_apply_args_kwargs(self, engine_and_raw):
-        def mean_w_arg(x, const):
-            return np.mean(x) + const
-
-        engine, raw = engine_and_raw
-
-        df = DataFrame(np.random.rand(20, 3))
-
-        expected = df.expanding().apply(np.mean, engine=engine, raw=raw) + 20.0
-
-        result = df.expanding().apply(mean_w_arg, engine=engine, raw=raw, args=(20,))
-        tm.assert_frame_equal(result, expected)
-
-        result = df.expanding().apply(mean_w_arg, raw=raw, kwargs={"const": 20})
-        tm.assert_frame_equal(result, expected)
-
     def test_expanding_corr(self):
         A = self.series.dropna()
         B = (A + randn(len(A)))[:-5]
@@ -90,100 +74,6 @@ class TestExpandingMomentsConsistency(ConsistencyBase):
         ).corr()
         tm.assert_frame_equal(result, rolling_result)
 
-    def test_expanding_cov_diff_index(self):
-        # GH 7512
-        s1 = Series([1, 2, 3], index=[0, 1, 2])
-        s2 = Series([1, 3], index=[0, 2])
-        result = s1.expanding().cov(s2)
-        expected = Series([None, None, 2.0])
-        tm.assert_series_equal(result, expected)
-
-        s2a = Series([1, None, 3], index=[0, 1, 2])
-        result = s1.expanding().cov(s2a)
-        tm.assert_series_equal(result, expected)
-
-        s1 = Series([7, 8, 10], index=[0, 1, 3])
-        s2 = Series([7, 9, 10], index=[0, 2, 3])
-        result = s1.expanding().cov(s2)
-        expected = Series([None, None, None, 4.5])
-        tm.assert_series_equal(result, expected)
-
-    def test_expanding_corr_diff_index(self):
-        # GH 7512
-        s1 = Series([1, 2, 3], index=[0, 1, 2])
-        s2 = Series([1, 3], index=[0, 2])
-        result = s1.expanding().corr(s2)
-        expected = Series([None, None, 1.0])
-        tm.assert_series_equal(result, expected)
-
-        s2a = Series([1, None, 3], index=[0, 1, 2])
-        result = s1.expanding().corr(s2a)
-        tm.assert_series_equal(result, expected)
-
-        s1 = Series([7, 8, 10], index=[0, 1, 3])
-        s2 = Series([7, 9, 10], index=[0, 2, 3])
-        result = s1.expanding().corr(s2)
-        expected = Series([None, None, None, 1.0])
-        tm.assert_series_equal(result, expected)
-
-    def test_expanding_cov_pairwise_diff_length(self):
-        # GH 7512
-        df1 = DataFrame([[1, 5], [3, 2], [3, 9]], columns=Index(["A", "B"], name="foo"))
-        df1a = DataFrame(
-            [[1, 5], [3, 9]], index=[0, 2], columns=Index(["A", "B"], name="foo")
-        )
-        df2 = DataFrame(
-            [[5, 6], [None, None], [2, 1]], columns=Index(["X", "Y"], name="foo")
-        )
-        df2a = DataFrame(
-            [[5, 6], [2, 1]], index=[0, 2], columns=Index(["X", "Y"], name="foo")
-        )
-        # TODO: xref gh-15826
-        # .loc is not preserving the names
-        result1 = df1.expanding().cov(df2, pairwise=True).loc[2]
-        result2 = df1.expanding().cov(df2a, pairwise=True).loc[2]
-        result3 = df1a.expanding().cov(df2, pairwise=True).loc[2]
-        result4 = df1a.expanding().cov(df2a, pairwise=True).loc[2]
-        expected = DataFrame(
-            [[-3.0, -6.0], [-5.0, -10.0]],
-            columns=Index(["A", "B"], name="foo"),
-            index=Index(["X", "Y"], name="foo"),
-        )
-        tm.assert_frame_equal(result1, expected)
-        tm.assert_frame_equal(result2, expected)
-        tm.assert_frame_equal(result3, expected)
-        tm.assert_frame_equal(result4, expected)
-
-    def test_expanding_corr_pairwise_diff_length(self):
-        # GH 7512
-        df1 = DataFrame(
-            [[1, 2], [3, 2], [3, 4]],
-            columns=["A", "B"],
-            index=Index(range(3), name="bar"),
-        )
-        df1a = DataFrame(
-            [[1, 2], [3, 4]], index=Index([0, 2], name="bar"), columns=["A", "B"]
-        )
-        df2 = DataFrame(
-            [[5, 6], [None, None], [2, 1]],
-            columns=["X", "Y"],
-            index=Index(range(3), name="bar"),
-        )
-        df2a = DataFrame(
-            [[5, 6], [2, 1]], index=Index([0, 2], name="bar"), columns=["X", "Y"]
-        )
-        result1 = df1.expanding().corr(df2, pairwise=True).loc[2]
-        result2 = df1.expanding().corr(df2a, pairwise=True).loc[2]
-        result3 = df1a.expanding().corr(df2, pairwise=True).loc[2]
-        result4 = df1a.expanding().corr(df2a, pairwise=True).loc[2]
-        expected = DataFrame(
-            [[-1.0, -1.0], [-1.0, -1.0]], columns=["A", "B"], index=Index(["X", "Y"])
-        )
-        tm.assert_frame_equal(result1, expected)
-        tm.assert_frame_equal(result2, expected)
-        tm.assert_frame_equal(result3, expected)
-        tm.assert_frame_equal(result4, expected)
-
     @pytest.mark.parametrize("has_min_periods", [True, False])
     @pytest.mark.parametrize(
         "func,static_comp",
@@ -216,23 +106,6 @@ class TestExpandingMomentsConsistency(ConsistencyBase):
         self._check_expanding(expanding_mean, np.mean, preserve_nan=False)
         self._check_expanding_has_min_periods(expanding_mean, np.mean, has_min_periods)
 
-    def test_expanding_apply_empty_series(self, engine_and_raw):
-        engine, raw = engine_and_raw
-        ser = Series([], dtype=np.float64)
-        tm.assert_series_equal(
-            ser, ser.expanding().apply(lambda x: x.mean(), raw=raw, engine=engine)
-        )
-
-    def test_expanding_apply_min_periods_0(self, engine_and_raw):
-        # GH 8080
-        engine, raw = engine_and_raw
-        s = Series([None, None, None])
-        result = s.expanding(min_periods=0).apply(
-            lambda x: len(x), raw=raw, engine=engine
-        )
-        expected = Series([1.0, 2.0, 3.0])
-        tm.assert_series_equal(result, expected)
-
     def _check_expanding(self, func, static_comp, preserve_nan=True):
 
         series_result = func(self.series)
@@ -272,115 +145,6 @@ class TestExpandingMomentsConsistency(ConsistencyBase):
             result = func(ser)
             tm.assert_almost_equal(result.iloc[-1], static_comp(ser[:50]))
 
-    @pytest.mark.parametrize(
-        "f",
-        [
-            lambda x: x.expanding().count(),
-            lambda x: x.expanding(min_periods=5).cov(x, pairwise=False),
-            lambda x: x.expanding(min_periods=5).corr(x, pairwise=False),
-            lambda x: x.expanding(min_periods=5).max(),
-            lambda x: x.expanding(min_periods=5).min(),
-            lambda x: x.expanding(min_periods=5).sum(),
-            lambda x: x.expanding(min_periods=5).mean(),
-            lambda x: x.expanding(min_periods=5).std(),
-            lambda x: x.expanding(min_periods=5).var(),
-            lambda x: x.expanding(min_periods=5).skew(),
-            lambda x: x.expanding(min_periods=5).kurt(),
-            lambda x: x.expanding(min_periods=5).quantile(0.5),
-            lambda x: x.expanding(min_periods=5).median(),
-            lambda x: x.expanding(min_periods=5).apply(sum, raw=False),
-            lambda x: x.expanding(min_periods=5).apply(sum, raw=True),
-        ],
-    )
-    def test_moment_functions_zero_length(self, f):
-        # GH 8056
-        s = Series(dtype=np.float64)
-        s_expected = s
-        df1 = DataFrame()
-        df1_expected = df1
-        df2 = DataFrame(columns=["a"])
-        df2["a"] = df2["a"].astype("float64")
-        df2_expected = df2
-
-        s_result = f(s)
-        tm.assert_series_equal(s_result, s_expected)
-
-        df1_result = f(df1)
-        tm.assert_frame_equal(df1_result, df1_expected)
-
-        df2_result = f(df2)
-        tm.assert_frame_equal(df2_result, df2_expected)
-
-    @pytest.mark.parametrize(
-        "f",
-        [
-            lambda x: (x.expanding(min_periods=5).cov(x, pairwise=True)),
-            lambda x: (x.expanding(min_periods=5).corr(x, pairwise=True)),
-        ],
-    )
-    def test_moment_functions_zero_length_pairwise(self, f):
-
-        df1 = DataFrame()
-        df2 = DataFrame(columns=Index(["a"], name="foo"), index=Index([], name="bar"))
-        df2["a"] = df2["a"].astype("float64")
-
-        df1_expected = DataFrame(
-            index=MultiIndex.from_product([df1.index, df1.columns]), columns=Index([])
-        )
-        df2_expected = DataFrame(
-            index=MultiIndex.from_product(
-                [df2.index, df2.columns], names=["bar", "foo"]
-            ),
-            columns=Index(["a"], name="foo"),
-            dtype="float64",
-        )
-
-        df1_result = f(df1)
-        tm.assert_frame_equal(df1_result, df1_expected)
-
-        df2_result = f(df2)
-        tm.assert_frame_equal(df2_result, df2_expected)
-
-    @pytest.mark.slow
-    @pytest.mark.parametrize("min_periods", [0, 1, 2, 3, 4])
-    def test_expanding_consistency(self, consistency_data, min_periods):
-        x, is_constant, no_nans = consistency_data
-        # suppress warnings about empty slices, as we are deliberately testing
-        # with empty/0-length Series/DataFrames
-        with warnings.catch_warnings():
-            warnings.filterwarnings(
-                "ignore",
-                message=".*(empty slice|0 for slice).*",
-                category=RuntimeWarning,
-            )
-
-            # test consistency between different expanding_* moments
-            moments_consistency_mock_mean(
-                x=x,
-                mean=lambda x: x.expanding(min_periods=min_periods).mean(),
-                mock_mean=lambda x: x.expanding(min_periods=min_periods).sum()
-                / x.expanding().count(),
-            )
-
-            moments_consistency_is_constant(
-                x=x,
-                is_constant=is_constant,
-                min_periods=min_periods,
-                count=lambda x: x.expanding().count(),
-                mean=lambda x: x.expanding(min_periods=min_periods).mean(),
-                corr=lambda x, y: x.expanding(min_periods=min_periods).corr(y),
-            )
-
-            moments_consistency_var_debiasing_factors(
-                x=x,
-                var_unbiased=lambda x: x.expanding(min_periods=min_periods).var(),
-                var_biased=lambda x: x.expanding(min_periods=min_periods).var(ddof=0),
-                var_debiasing_factors=lambda x: (
-                    x.expanding().count()
-                    / (x.expanding().count() - 1.0).replace(0.0, np.nan)
-                ),
-            )
-
     @pytest.mark.parametrize("min_periods", [0, 1, 2, 3, 4])
     def test_expanding_apply_consistency(self, consistency_data, min_periods):
         x, is_constant, no_nans = consistency_data
@@ -479,3 +243,241 @@ def test_expanding_consistency_series(consistency_data, min_periods):
         std_biased=lambda x: x.expanding(min_periods=min_periods).std(ddof=0),
         cov_biased=lambda x, y: x.expanding(min_periods=min_periods).cov(y, ddof=0),
     )
+
+
+@pytest.mark.slow
+@pytest.mark.parametrize("min_periods", [0, 1, 2, 3, 4])
+def test_expanding_consistency(consistency_data, min_periods):
+    x, is_constant, no_nans = consistency_data
+    # suppress warnings about empty slices, as we are deliberately testing
+    # with empty/0-length Series/DataFrames
+    with warnings.catch_warnings():
+        warnings.filterwarnings(
+            "ignore", message=".*(empty slice|0 for slice).*", category=RuntimeWarning,
+        )
+
+        # test consistency between different expanding_* moments
+        moments_consistency_mock_mean(
+            x=x,
+            mean=lambda x: x.expanding(min_periods=min_periods).mean(),
+            mock_mean=lambda x: x.expanding(min_periods=min_periods).sum()
+            / x.expanding().count(),
+        )
+
+        moments_consistency_is_constant(
+            x=x,
+            is_constant=is_constant,
+            min_periods=min_periods,
+            count=lambda x: x.expanding().count(),
+            mean=lambda x: x.expanding(min_periods=min_periods).mean(),
+            corr=lambda x, y: x.expanding(min_periods=min_periods).corr(y),
+        )
+
+        moments_consistency_var_debiasing_factors(
+            x=x,
+            var_unbiased=lambda x: x.expanding(min_periods=min_periods).var(),
+            var_biased=lambda x: x.expanding(min_periods=min_periods).var(ddof=0),
+            var_debiasing_factors=lambda x: (
+                x.expanding().count()
+                / (x.expanding().count() - 1.0).replace(0.0, np.nan)
+            ),
+        )
+
+
+@pytest.mark.parametrize(
+    "f",
+    [
+        lambda x: (x.expanding(min_periods=5).cov(x, pairwise=True)),
+        lambda x: (x.expanding(min_periods=5).corr(x, pairwise=True)),
+    ],
+)
+def test_moment_functions_zero_length_pairwise(f):
+
+    df1 = DataFrame()
+    df2 = DataFrame(columns=Index(["a"], name="foo"), index=Index([], name="bar"))
+    df2["a"] = df2["a"].astype("float64")
+
+    df1_expected = DataFrame(
+        index=MultiIndex.from_product([df1.index, df1.columns]), columns=Index([])
+    )
+    df2_expected = DataFrame(
+        index=MultiIndex.from_product([df2.index, df2.columns], names=["bar", "foo"]),
+        columns=Index(["a"], name="foo"),
+        dtype="float64",
+    )
+
+    df1_result = f(df1)
+    tm.assert_frame_equal(df1_result, df1_expected)
+
+    df2_result = f(df2)
+    tm.assert_frame_equal(df2_result, df2_expected)
+
+
+@pytest.mark.parametrize(
+    "f",
+    [
+        lambda x: x.expanding().count(),
+        lambda x: x.expanding(min_periods=5).cov(x, pairwise=False),
+        lambda x: x.expanding(min_periods=5).corr(x, pairwise=False),
+        lambda x: x.expanding(min_periods=5).max(),
+        lambda x: x.expanding(min_periods=5).min(),
+        lambda x: x.expanding(min_periods=5).sum(),
+        lambda x: x.expanding(min_periods=5).mean(),
+        lambda x: x.expanding(min_periods=5).std(),
+        lambda x: x.expanding(min_periods=5).var(),
+        lambda x: x.expanding(min_periods=5).skew(),
+        lambda x: x.expanding(min_periods=5).kurt(),
+        lambda x: x.expanding(min_periods=5).quantile(0.5),
+        lambda x: x.expanding(min_periods=5).median(),
+        lambda x: x.expanding(min_periods=5).apply(sum, raw=False),
+        lambda x: x.expanding(min_periods=5).apply(sum, raw=True),
+    ],
+)
+def test_moment_functions_zero_length(f):
+    # GH 8056
+    s = Series(dtype=np.float64)
+    s_expected = s
+    df1 = DataFrame()
+    df1_expected = df1
+    df2 = DataFrame(columns=["a"])
+    df2["a"] = df2["a"].astype("float64")
+    df2_expected = df2
+
+    s_result = f(s)
+    tm.assert_series_equal(s_result, s_expected)
+
+    df1_result = f(df1)
+    tm.assert_frame_equal(df1_result, df1_expected)
+
+    df2_result = f(df2)
+    tm.assert_frame_equal(df2_result, df2_expected)
+
+
+def test_expanding_apply_empty_series(engine_and_raw):
+    engine, raw = engine_and_raw
+    ser = Series([], dtype=np.float64)
+    tm.assert_series_equal(
+        ser, ser.expanding().apply(lambda x: x.mean(), raw=raw, engine=engine)
+    )
+
+
+def test_expanding_apply_min_periods_0(engine_and_raw):
+    # GH 8080
+    engine, raw = engine_and_raw
+    s = Series([None, None, None])
+    result = s.expanding(min_periods=0).apply(lambda x: len(x), raw=raw, engine=engine)
+    expected = Series([1.0, 2.0, 3.0])
+    tm.assert_series_equal(result, expected)
+
+
+def test_expanding_cov_diff_index():
+    # GH 7512
+    s1 = Series([1, 2, 3], index=[0, 1, 2])
+    s2 = Series([1, 3], index=[0, 2])
+    result = s1.expanding().cov(s2)
+    expected = Series([None, None, 2.0])
+    tm.assert_series_equal(result, expected)
+
+    s2a = Series([1, None, 3], index=[0, 1, 2])
+    result = s1.expanding().cov(s2a)
+    tm.assert_series_equal(result, expected)
+
+    s1 = Series([7, 8, 10], index=[0, 1, 3])
+    s2 = Series([7, 9, 10], index=[0, 2, 3])
+    result = s1.expanding().cov(s2)
+    expected = Series([None, None, None, 4.5])
+    tm.assert_series_equal(result, expected)
+
+
+def test_expanding_corr_diff_index():
+    # GH 7512
+    s1 = Series([1, 2, 3], index=[0, 1, 2])
+    s2 = Series([1, 3], index=[0, 2])
+    result = s1.expanding().corr(s2)
+    expected = Series([None, None, 1.0])
+    tm.assert_series_equal(result, expected)
+
+    s2a = Series([1, None, 3], index=[0, 1, 2])
+    result = s1.expanding().corr(s2a)
+    tm.assert_series_equal(result, expected)
+
+    s1 = Series([7, 8, 10], index=[0, 1, 3])
+    s2 = Series([7, 9, 10], index=[0, 2, 3])
+    result = s1.expanding().corr(s2)
+    expected = Series([None, None, None, 1.0])
+    tm.assert_series_equal(result, expected)
+
+
+def test_expanding_cov_pairwise_diff_length():
+    # GH 7512
+    df1 = DataFrame([[1, 5], [3, 2], [3, 9]], columns=Index(["A", "B"], name="foo"))
+    df1a = DataFrame(
+        [[1, 5], [3, 9]], index=[0, 2], columns=Index(["A", "B"], name="foo")
+    )
+    df2 = DataFrame(
+        [[5, 6], [None, None], [2, 1]], columns=Index(["X", "Y"], name="foo")
+    )
+    df2a = DataFrame(
+        [[5, 6], [2, 1]], index=[0, 2], columns=Index(["X", "Y"], name="foo")
+    )
+    # TODO: xref gh-15826
+    # .loc is not preserving the names
+    result1 = df1.expanding().cov(df2, pairwise=True).loc[2]
+    result2 = df1.expanding().cov(df2a, pairwise=True).loc[2]
+    result3 = df1a.expanding().cov(df2, pairwise=True).loc[2]
+    result4 = df1a.expanding().cov(df2a, pairwise=True).loc[2]
+    expected = DataFrame(
+        [[-3.0, -6.0], [-5.0, -10.0]],
+        columns=Index(["A", "B"], name="foo"),
+        index=Index(["X", "Y"], name="foo"),
+    )
+    tm.assert_frame_equal(result1, expected)
+    tm.assert_frame_equal(result2, expected)
+    tm.assert_frame_equal(result3, expected)
+    tm.assert_frame_equal(result4, expected)
+
+
+def test_expanding_corr_pairwise_diff_length():
+    # GH 7512
+    df1 = DataFrame(
+        [[1, 2], [3, 2], [3, 4]], columns=["A", "B"], index=Index(range(3), name="bar"),
+    )
+    df1a = DataFrame(
+        [[1, 2], [3, 4]], index=Index([0, 2], name="bar"), columns=["A", "B"]
+    )
+    df2 = DataFrame(
+        [[5, 6], [None, None], [2, 1]],
+        columns=["X", "Y"],
+        index=Index(range(3), name="bar"),
+    )
+    df2a = DataFrame(
+        [[5, 6], [2, 1]], index=Index([0, 2], name="bar"), columns=["X", "Y"]
+    )
+    result1 = df1.expanding().corr(df2, pairwise=True).loc[2]
+    result2 = df1.expanding().corr(df2a, pairwise=True).loc[2]
+    result3 = df1a.expanding().corr(df2, pairwise=True).loc[2]
+    result4 = df1a.expanding().corr(df2a, pairwise=True).loc[2]
+    expected = DataFrame(
+        [[-1.0, -1.0], [-1.0, -1.0]], columns=["A", "B"], index=Index(["X", "Y"])
+    )
+    tm.assert_frame_equal(result1, expected)
+    tm.assert_frame_equal(result2, expected)
+    tm.assert_frame_equal(result3, expected)
+    tm.assert_frame_equal(result4, expected)
+
+
+def test_expanding_apply_args_kwargs(engine_and_raw):
+    def mean_w_arg(x, const):
+        return np.mean(x) + const
+
+    engine, raw = engine_and_raw
+
+    df = DataFrame(np.random.rand(20, 3))
+
+    expected = df.expanding().apply(np.mean, engine=engine, raw=raw) + 20.0
+
+    result = df.expanding().apply(mean_w_arg, engine=engine, raw=raw, args=(20,))
+    tm.assert_frame_equal(result, expected)
+
+    result = df.expanding().apply(mean_w_arg, raw=raw, kwargs={"const": 20})
+    tm.assert_frame_equal(result, expected)
diff --git a/pandas/tests/window/moments/test_moments_rolling.py b/pandas/tests/window/moments/test_moments_rolling.py
index c15b7ed00..c7d3a50ec 100644
--- a/pandas/tests/window/moments/test_moments_rolling.py
+++ b/pandas/tests/window/moments/test_moments_rolling.py
@@ -1028,51 +1028,6 @@ class TestRollingMomentsConsistency(ConsistencyBase):
     def test_rolling_corr_pairwise(self):
         self._check_pairwise_moment("rolling", "corr", window=10, min_periods=5)
 
-    @pytest.mark.parametrize("window", range(7))
-    def test_rolling_corr_with_zero_variance(self, window):
-        # GH 18430
-        s = pd.Series(np.zeros(20))
-        other = pd.Series(np.arange(20))
-
-        assert s.rolling(window=window).corr(other=other).isna().all()
-
-    def test_flex_binary_moment(self):
-        # GH3155
-        # don't blow the stack
-        msg = (
-            "arguments to moment function must be of type "
-            "np.ndarray/Series/DataFrame"
-        )
-        with pytest.raises(TypeError, match=msg):
-            _flex_binary_moment(5, 6, None)
-
-    def test_corr_sanity(self):
-        # GH 3155
-        df = DataFrame(
-            np.array(
-                [
-                    [0.87024726, 0.18505595],
-                    [0.64355431, 0.3091617],
-                    [0.92372966, 0.50552513],
-                    [0.00203756, 0.04520709],
-                    [0.84780328, 0.33394331],
-                    [0.78369152, 0.63919667],
-                ]
-            )
-        )
-
-        res = df[0].rolling(5, center=True).corr(df[1])
-        assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
-
-        # and some fuzzing
-        for _ in range(10):
-            df = DataFrame(np.random.rand(30, 2))
-            res = df[0].rolling(5, center=True).corr(df[1])
-            try:
-                assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
-            except AssertionError:
-                print(res)
-
     @pytest.mark.parametrize("method", ["corr", "cov"])
     def test_flex_binary_frame(self, method):
         series = self.frame[1]
@@ -1096,338 +1051,384 @@ class TestRollingMomentsConsistency(ConsistencyBase):
         )
         tm.assert_frame_equal(res3, exp)
 
-    def test_rolling_cov_diff_length(self):
-        # GH 7512
-        s1 = Series([1, 2, 3], index=[0, 1, 2])
-        s2 = Series([1, 3], index=[0, 2])
-        result = s1.rolling(window=3, min_periods=2).cov(s2)
-        expected = Series([None, None, 2.0])
-        tm.assert_series_equal(result, expected)
 
-        s2a = Series([1, None, 3], index=[0, 1, 2])
-        result = s1.rolling(window=3, min_periods=2).cov(s2a)
-        tm.assert_series_equal(result, expected)
+@pytest.mark.parametrize("window", range(7))
+def test_rolling_corr_with_zero_variance(window):
+    # GH 18430
+    s = pd.Series(np.zeros(20))
+    other = pd.Series(np.arange(20))
 
-    def test_rolling_corr_diff_length(self):
-        # GH 7512
-        s1 = Series([1, 2, 3], index=[0, 1, 2])
-        s2 = Series([1, 3], index=[0, 2])
-        result = s1.rolling(window=3, min_periods=2).corr(s2)
-        expected = Series([None, None, 1.0])
-        tm.assert_series_equal(result, expected)
+    assert s.rolling(window=window).corr(other=other).isna().all()
 
-        s2a = Series([1, None, 3], index=[0, 1, 2])
-        result = s1.rolling(window=3, min_periods=2).corr(s2a)
-        tm.assert_series_equal(result, expected)
 
-    @pytest.mark.parametrize(
-        "f",
-        [
-            lambda x: x.rolling(window=10, min_periods=5).cov(x, pairwise=False),
-            lambda x: x.rolling(window=10, min_periods=5).corr(x, pairwise=False),
-            lambda x: x.rolling(window=10, min_periods=5).max(),
-            lambda x: x.rolling(window=10, min_periods=5).min(),
-            lambda x: x.rolling(window=10, min_periods=5).sum(),
-            lambda x: x.rolling(window=10, min_periods=5).mean(),
-            lambda x: x.rolling(window=10, min_periods=5).std(),
-            lambda x: x.rolling(window=10, min_periods=5).var(),
-            lambda x: x.rolling(window=10, min_periods=5).skew(),
-            lambda x: x.rolling(window=10, min_periods=5).kurt(),
-            lambda x: x.rolling(window=10, min_periods=5).quantile(quantile=0.5),
-            lambda x: x.rolling(window=10, min_periods=5).median(),
-            lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=False),
-            lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=True),
-            lambda x: x.rolling(win_type="boxcar", window=10, min_periods=5).mean(),
-        ],
+def test_flex_binary_moment():
+    # GH3155
+    # don't blow the stack
+    msg = "arguments to moment function must be of type np.ndarray/Series/DataFrame"
+    with pytest.raises(TypeError, match=msg):
+        _flex_binary_moment(5, 6, None)
+
+
+def test_corr_sanity():
+    # GH 3155
+    df = DataFrame(
+        np.array(
+            [
+                [0.87024726, 0.18505595],
+                [0.64355431, 0.3091617],
+                [0.92372966, 0.50552513],
+                [0.00203756, 0.04520709],
+                [0.84780328, 0.33394331],
+                [0.78369152, 0.63919667],
+            ]
+        )
     )
-    @td.skip_if_no_scipy
-    def test_rolling_functions_window_non_shrinkage(self, f):
-        # GH 7764
-        s = Series(range(4))
-        s_expected = Series(np.nan, index=s.index)
-        df = DataFrame([[1, 5], [3, 2], [3, 9], [-1, 0]], columns=["A", "B"])
-        df_expected = DataFrame(np.nan, index=df.index, columns=df.columns)
 
-        s_result = f(s)
-        tm.assert_series_equal(s_result, s_expected)
+    res = df[0].rolling(5, center=True).corr(df[1])
+    assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
 
+    # and some fuzzing
+    for _ in range(10):
+        df = DataFrame(np.random.rand(30, 2))
+        res = df[0].rolling(5, center=True).corr(df[1])
+        try:
+            assert all(np.abs(np.nan_to_num(x)) <= 1 for x in res)
+        except AssertionError:
+            print(res)
+
+
+def test_rolling_cov_diff_length():
+    # GH 7512
+    s1 = Series([1, 2, 3], index=[0, 1, 2])
+    s2 = Series([1, 3], index=[0, 2])
+    result = s1.rolling(window=3, min_periods=2).cov(s2)
+    expected = Series([None, None, 2.0])
+    tm.assert_series_equal(result, expected)
+
+    s2a = Series([1, None, 3], index=[0, 1, 2])
+    result = s1.rolling(window=3, min_periods=2).cov(s2a)
+    tm.assert_series_equal(result, expected)
+
+
+def test_rolling_corr_diff_length():
+    # GH 7512
+    s1 = Series([1, 2, 3], index=[0, 1, 2])
+    s2 = Series([1, 3], index=[0, 2])
+    result = s1.rolling(window=3, min_periods=2).corr(s2)
+    expected = Series([None, None, 1.0])
+    tm.assert_series_equal(result, expected)
+
+    s2a = Series([1, None, 3], index=[0, 1, 2])
+    result = s1.rolling(window=3, min_periods=2).corr(s2a)
+    tm.assert_series_equal(result, expected)
+
+
+@pytest.mark.parametrize(
+    "f",
+    [
+        lambda x: x.rolling(window=10, min_periods=5).cov(x, pairwise=False),
+        lambda x: x.rolling(window=10, min_periods=5).corr(x, pairwise=False),
+        lambda x: x.rolling(window=10, min_periods=5).max(),
+        lambda x: x.rolling(window=10, min_periods=5).min(),
+        lambda x: x.rolling(window=10, min_periods=5).sum(),
+        lambda x: x.rolling(window=10, min_periods=5).mean(),
+        lambda x: x.rolling(window=10, min_periods=5).std(),
+        lambda x: x.rolling(window=10, min_periods=5).var(),
+        lambda x: x.rolling(window=10, min_periods=5).skew(),
+        lambda x: x.rolling(window=10, min_periods=5).kurt(),
+        lambda x: x.rolling(window=10, min_periods=5).quantile(quantile=0.5),
+        lambda x: x.rolling(window=10, min_periods=5).median(),
+        lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=False),
+        lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=True),
+        lambda x: x.rolling(win_type="boxcar", window=10, min_periods=5).mean(),
+    ],
+)
+@td.skip_if_no_scipy
+def test_rolling_functions_window_non_shrinkage(f):
+    # GH 7764
+    s = Series(range(4))
+    s_expected = Series(np.nan, index=s.index)
+    df = DataFrame([[1, 5], [3, 2], [3, 9], [-1, 0]], columns=["A", "B"])
+    df_expected = DataFrame(np.nan, index=df.index, columns=df.columns)
+
+    s_result = f(s)
+    tm.assert_series_equal(s_result, s_expected)
+
+    df_result = f(df)
+    tm.assert_frame_equal(df_result, df_expected)
+
+
+def test_rolling_functions_window_non_shrinkage_binary():
+
+    # corr/cov return a MI DataFrame
+    df = DataFrame(
+        [[1, 5], [3, 2], [3, 9], [-1, 0]],
+        columns=Index(["A", "B"], name="foo"),
+        index=Index(range(4), name="bar"),
+    )
+    df_expected = DataFrame(
+        columns=Index(["A", "B"], name="foo"),
+        index=pd.MultiIndex.from_product([df.index, df.columns], names=["bar", "foo"]),
+        dtype="float64",
+    )
+    functions = [
+        lambda x: (x.rolling(window=10, min_periods=5).cov(x, pairwise=True)),
+        lambda x: (x.rolling(window=10, min_periods=5).corr(x, pairwise=True)),
+    ]
+    for f in functions:
         df_result = f(df)
         tm.assert_frame_equal(df_result, df_expected)
 
-    def test_rolling_functions_window_non_shrinkage_binary(self):
 
-        # corr/cov return a MI DataFrame
-        df = DataFrame(
-            [[1, 5], [3, 2], [3, 9], [-1, 0]],
-            columns=Index(["A", "B"], name="foo"),
-            index=Index(range(4), name="bar"),
-        )
-        df_expected = DataFrame(
-            columns=Index(["A", "B"], name="foo"),
-            index=pd.MultiIndex.from_product(
-                [df.index, df.columns], names=["bar", "foo"]
-            ),
-            dtype="float64",
-        )
-        functions = [
-            lambda x: (x.rolling(window=10, min_periods=5).cov(x, pairwise=True)),
-            lambda x: (x.rolling(window=10, min_periods=5).corr(x, pairwise=True)),
-        ]
-        for f in functions:
-            df_result = f(df)
-            tm.assert_frame_equal(df_result, df_expected)
-
-    def test_rolling_skew_edge_cases(self):
-
-        all_nan = Series([np.NaN] * 5)
-
-        # yields all NaN (0 variance)
-        d = Series([1] * 5)
-        x = d.rolling(window=5).skew()
-        tm.assert_series_equal(all_nan, x)
-
-        # yields all NaN (window too small)
-        d = Series(np.random.randn(5))
-        x = d.rolling(window=2).skew()
-        tm.assert_series_equal(all_nan, x)
-
-        # yields [NaN, NaN, NaN, 0.177994, 1.548824]
-        d = Series([-1.50837035, -0.1297039, 0.19501095, 1.73508164, 0.41941401])
-        expected = Series([np.NaN, np.NaN, np.NaN, 0.177994, 1.548824])
-        x = d.rolling(window=4).skew()
-        tm.assert_series_equal(expected, x)
-
-    def test_rolling_kurt_edge_cases(self):
-
-        all_nan = Series([np.NaN] * 5)
-
-        # yields all NaN (0 variance)
-        d = Series([1] * 5)
-        x = d.rolling(window=5).kurt()
-        tm.assert_series_equal(all_nan, x)
-
-        # yields all NaN (window too small)
-        d = Series(np.random.randn(5))
-        x = d.rolling(window=3).kurt()
-        tm.assert_series_equal(all_nan, x)
-
-        # yields [NaN, NaN, NaN, 1.224307, 2.671499]
-        d = Series([-1.50837035, -0.1297039, 0.19501095, 1.73508164, 0.41941401])
-        expected = Series([np.NaN, np.NaN, np.NaN, 1.224307, 2.671499])
-        x = d.rolling(window=4).kurt()
-        tm.assert_series_equal(expected, x)
-
-    def test_rolling_skew_eq_value_fperr(self):
-        # #18804 all rolling skew for all equal values should return Nan
-        a = Series([1.1] * 15).rolling(window=10).skew()
-        assert np.isnan(a).all()
-
-    def test_rolling_kurt_eq_value_fperr(self):
-        # #18804 all rolling kurt for all equal values should return Nan
-        a = Series([1.1] * 15).rolling(window=10).kurt()
-        assert np.isnan(a).all()
-
-    def test_rolling_max_gh6297(self):
-        """Replicate result expected in GH #6297"""
-        indices = [datetime(1975, 1, i) for i in range(1, 6)]
-        # So that we can have 2 datapoints on one of the days
-        indices.append(datetime(1975, 1, 3, 6, 0))
-        series = Series(range(1, 7), index=indices)
-        # Use floats instead of ints as values
-        series = series.map(lambda x: float(x))
-        # Sort chronologically
-        series = series.sort_index()
+def test_rolling_skew_edge_cases():
 
-        expected = Series(
-            [1.0, 2.0, 6.0, 4.0, 5.0],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        x = series.resample("D").max().rolling(window=1).max()
-        tm.assert_series_equal(expected, x)
-
-    def test_rolling_max_resample(self):
-
-        indices = [datetime(1975, 1, i) for i in range(1, 6)]
-        # So that we can have 3 datapoints on last day (4, 10, and 20)
-        indices.append(datetime(1975, 1, 5, 1))
-        indices.append(datetime(1975, 1, 5, 2))
-        series = Series(list(range(0, 5)) + [10, 20], index=indices)
-        # Use floats instead of ints as values
-        series = series.map(lambda x: float(x))
-        # Sort chronologically
-        series = series.sort_index()
-
-        # Default how should be max
-        expected = Series(
-            [0.0, 1.0, 2.0, 3.0, 20.0],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        x = series.resample("D").max().rolling(window=1).max()
-        tm.assert_series_equal(expected, x)
+    all_nan = Series([np.NaN] * 5)
 
-        # Now specify median (10.0)
-        expected = Series(
-            [0.0, 1.0, 2.0, 3.0, 10.0],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        x = series.resample("D").median().rolling(window=1).max()
-        tm.assert_series_equal(expected, x)
+    # yields all NaN (0 variance)
+    d = Series([1] * 5)
+    x = d.rolling(window=5).skew()
+    tm.assert_series_equal(all_nan, x)
 
-        # Now specify mean (4+10+20)/3
-        v = (4.0 + 10.0 + 20.0) / 3.0
-        expected = Series(
-            [0.0, 1.0, 2.0, 3.0, v],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        x = series.resample("D").mean().rolling(window=1).max()
-        tm.assert_series_equal(expected, x)
-
-    def test_rolling_min_resample(self):
-
-        indices = [datetime(1975, 1, i) for i in range(1, 6)]
-        # So that we can have 3 datapoints on last day (4, 10, and 20)
-        indices.append(datetime(1975, 1, 5, 1))
-        indices.append(datetime(1975, 1, 5, 2))
-        series = Series(list(range(0, 5)) + [10, 20], index=indices)
-        # Use floats instead of ints as values
-        series = series.map(lambda x: float(x))
-        # Sort chronologically
-        series = series.sort_index()
-
-        # Default how should be min
-        expected = Series(
-            [0.0, 1.0, 2.0, 3.0, 4.0],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        r = series.resample("D").min().rolling(window=1)
-        tm.assert_series_equal(expected, r.min())
-
-    def test_rolling_median_resample(self):
-
-        indices = [datetime(1975, 1, i) for i in range(1, 6)]
-        # So that we can have 3 datapoints on last day (4, 10, and 20)
-        indices.append(datetime(1975, 1, 5, 1))
-        indices.append(datetime(1975, 1, 5, 2))
-        series = Series(list(range(0, 5)) + [10, 20], index=indices)
-        # Use floats instead of ints as values
-        series = series.map(lambda x: float(x))
-        # Sort chronologically
-        series = series.sort_index()
-
-        # Default how should be median
-        expected = Series(
-            [0.0, 1.0, 2.0, 3.0, 10],
-            index=DatetimeIndex(
-                [datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"
-            ),
-        )
-        x = series.resample("D").median().rolling(window=1).median()
-        tm.assert_series_equal(expected, x)
+    # yields all NaN (window too small)
+    d = Series(np.random.randn(5))
+    x = d.rolling(window=2).skew()
+    tm.assert_series_equal(all_nan, x)
 
-    def test_rolling_median_memory_error(self):
-        # GH11722
-        n = 20000
-        Series(np.random.randn(n)).rolling(window=2, center=False).median()
-        Series(np.random.randn(n)).rolling(window=2, center=False).median()
+    # yields [NaN, NaN, NaN, 0.177994, 1.548824]
+    d = Series([-1.50837035, -0.1297039, 0.19501095, 1.73508164, 0.41941401])
+    expected = Series([np.NaN, np.NaN, np.NaN, 0.177994, 1.548824])
+    x = d.rolling(window=4).skew()
+    tm.assert_series_equal(expected, x)
 
-    def test_rolling_min_max_numeric_types(self):
 
-        # GH12373
-        types_test = [np.dtype(f"f{width}") for width in [4, 8]]
-        types_test.extend(
-            [np.dtype(f"{sign}{width}") for width in [1, 2, 4, 8] for sign in "ui"]
-        )
-        for data_type in types_test:
-            # Just testing that these don't throw exceptions and that
-            # the return type is float64. Other tests will cover quantitative
-            # correctness
-            result = DataFrame(np.arange(20, dtype=data_type)).rolling(window=5).max()
-            assert result.dtypes[0] == np.dtype("f8")
-            result = DataFrame(np.arange(20, dtype=data_type)).rolling(window=5).min()
-            assert result.dtypes[0] == np.dtype("f8")
-
-    def test_moment_functions_zero_length(self):
-        # GH 8056
-        s = Series(dtype=np.float64)
-        s_expected = s
-        df1 = DataFrame()
-        df1_expected = df1
-        df2 = DataFrame(columns=["a"])
-        df2["a"] = df2["a"].astype("float64")
-        df2_expected = df2
-
-        functions = [
-            lambda x: x.rolling(window=10).count(),
-            lambda x: x.rolling(window=10, min_periods=5).cov(x, pairwise=False),
-            lambda x: x.rolling(window=10, min_periods=5).corr(x, pairwise=False),
-            lambda x: x.rolling(window=10, min_periods=5).max(),
-            lambda x: x.rolling(window=10, min_periods=5).min(),
-            lambda x: x.rolling(window=10, min_periods=5).sum(),
-            lambda x: x.rolling(window=10, min_periods=5).mean(),
-            lambda x: x.rolling(window=10, min_periods=5).std(),
-            lambda x: x.rolling(window=10, min_periods=5).var(),
-            lambda x: x.rolling(window=10, min_periods=5).skew(),
-            lambda x: x.rolling(window=10, min_periods=5).kurt(),
-            lambda x: x.rolling(window=10, min_periods=5).quantile(0.5),
-            lambda x: x.rolling(window=10, min_periods=5).median(),
-            lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=False),
-            lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=True),
-            lambda x: x.rolling(win_type="boxcar", window=10, min_periods=5).mean(),
-        ]
-        for f in functions:
-            try:
-                s_result = f(s)
-                tm.assert_series_equal(s_result, s_expected)
-
-                df1_result = f(df1)
-                tm.assert_frame_equal(df1_result, df1_expected)
-
-                df2_result = f(df2)
-                tm.assert_frame_equal(df2_result, df2_expected)
-            except (ImportError):
-
-                # scipy needed for rolling_window
-                continue
+def test_rolling_kurt_edge_cases():
 
-    def test_moment_functions_zero_length_pairwise(self):
+    all_nan = Series([np.NaN] * 5)
 
-        df1 = DataFrame()
-        df2 = DataFrame(columns=Index(["a"], name="foo"), index=Index([], name="bar"))
-        df2["a"] = df2["a"].astype("float64")
+    # yields all NaN (0 variance)
+    d = Series([1] * 5)
+    x = d.rolling(window=5).kurt()
+    tm.assert_series_equal(all_nan, x)
+
+    # yields all NaN (window too small)
+    d = Series(np.random.randn(5))
+    x = d.rolling(window=3).kurt()
+    tm.assert_series_equal(all_nan, x)
+
+    # yields [NaN, NaN, NaN, 1.224307, 2.671499]
+    d = Series([-1.50837035, -0.1297039, 0.19501095, 1.73508164, 0.41941401])
+    expected = Series([np.NaN, np.NaN, np.NaN, 1.224307, 2.671499])
+    x = d.rolling(window=4).kurt()
+    tm.assert_series_equal(expected, x)
+
+
+def test_rolling_skew_eq_value_fperr():
+    # #18804 all rolling skew for all equal values should return Nan
+    a = Series([1.1] * 15).rolling(window=10).skew()
+    assert np.isnan(a).all()
+
+
+def test_rolling_kurt_eq_value_fperr():
+    # #18804 all rolling kurt for all equal values should return Nan
+    a = Series([1.1] * 15).rolling(window=10).kurt()
+    assert np.isnan(a).all()
 
-        df1_expected = DataFrame(
-            index=pd.MultiIndex.from_product([df1.index, df1.columns]),
-            columns=Index([]),
-        )
-        df2_expected = DataFrame(
-            index=pd.MultiIndex.from_product(
-                [df2.index, df2.columns], names=["bar", "foo"]
-            ),
-            columns=Index(["a"], name="foo"),
-            dtype="float64",
-        )
 
-        functions = [
-            lambda x: (x.rolling(window=10, min_periods=5).cov(x, pairwise=True)),
-            lambda x: (x.rolling(window=10, min_periods=5).corr(x, pairwise=True)),
-        ]
+def test_rolling_max_gh6297():
+    """Replicate result expected in GH #6297"""
+    indices = [datetime(1975, 1, i) for i in range(1, 6)]
+    # So that we can have 2 datapoints on one of the days
+    indices.append(datetime(1975, 1, 3, 6, 0))
+    series = Series(range(1, 7), index=indices)
+    # Use floats instead of ints as values
+    series = series.map(lambda x: float(x))
+    # Sort chronologically
+    series = series.sort_index()
+
+    expected = Series(
+        [1.0, 2.0, 6.0, 4.0, 5.0],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    x = series.resample("D").max().rolling(window=1).max()
+    tm.assert_series_equal(expected, x)
+
+
+def test_rolling_max_resample():
+
+    indices = [datetime(1975, 1, i) for i in range(1, 6)]
+    # So that we can have 3 datapoints on last day (4, 10, and 20)
+    indices.append(datetime(1975, 1, 5, 1))
+    indices.append(datetime(1975, 1, 5, 2))
+    series = Series(list(range(0, 5)) + [10, 20], index=indices)
+    # Use floats instead of ints as values
+    series = series.map(lambda x: float(x))
+    # Sort chronologically
+    series = series.sort_index()
+
+    # Default how should be max
+    expected = Series(
+        [0.0, 1.0, 2.0, 3.0, 20.0],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    x = series.resample("D").max().rolling(window=1).max()
+    tm.assert_series_equal(expected, x)
+
+    # Now specify median (10.0)
+    expected = Series(
+        [0.0, 1.0, 2.0, 3.0, 10.0],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    x = series.resample("D").median().rolling(window=1).max()
+    tm.assert_series_equal(expected, x)
+
+    # Now specify mean (4+10+20)/3
+    v = (4.0 + 10.0 + 20.0) / 3.0
+    expected = Series(
+        [0.0, 1.0, 2.0, 3.0, v],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    x = series.resample("D").mean().rolling(window=1).max()
+    tm.assert_series_equal(expected, x)
+
+
+def test_rolling_min_resample():
+
+    indices = [datetime(1975, 1, i) for i in range(1, 6)]
+    # So that we can have 3 datapoints on last day (4, 10, and 20)
+    indices.append(datetime(1975, 1, 5, 1))
+    indices.append(datetime(1975, 1, 5, 2))
+    series = Series(list(range(0, 5)) + [10, 20], index=indices)
+    # Use floats instead of ints as values
+    series = series.map(lambda x: float(x))
+    # Sort chronologically
+    series = series.sort_index()
+
+    # Default how should be min
+    expected = Series(
+        [0.0, 1.0, 2.0, 3.0, 4.0],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    r = series.resample("D").min().rolling(window=1)
+    tm.assert_series_equal(expected, r.min())
+
+
+def test_rolling_median_resample():
+
+    indices = [datetime(1975, 1, i) for i in range(1, 6)]
+    # So that we can have 3 datapoints on last day (4, 10, and 20)
+    indices.append(datetime(1975, 1, 5, 1))
+    indices.append(datetime(1975, 1, 5, 2))
+    series = Series(list(range(0, 5)) + [10, 20], index=indices)
+    # Use floats instead of ints as values
+    series = series.map(lambda x: float(x))
+    # Sort chronologically
+    series = series.sort_index()
+
+    # Default how should be median
+    expected = Series(
+        [0.0, 1.0, 2.0, 3.0, 10],
+        index=DatetimeIndex([datetime(1975, 1, i, 0) for i in range(1, 6)], freq="D"),
+    )
+    x = series.resample("D").median().rolling(window=1).median()
+    tm.assert_series_equal(expected, x)
+
+
+def test_rolling_median_memory_error():
+    # GH11722
+    n = 20000
+    Series(np.random.randn(n)).rolling(window=2, center=False).median()
+    Series(np.random.randn(n)).rolling(window=2, center=False).median()
+
+
+def test_rolling_min_max_numeric_types():
+
+    # GH12373
+    types_test = [np.dtype(f"f{width}") for width in [4, 8]]
+    types_test.extend(
+        [np.dtype(f"{sign}{width}") for width in [1, 2, 4, 8] for sign in "ui"]
+    )
+    for data_type in types_test:
+        # Just testing that these don't throw exceptions and that
+        # the return type is float64. Other tests will cover quantitative
+        # correctness
+        result = DataFrame(np.arange(20, dtype=data_type)).rolling(window=5).max()
+        assert result.dtypes[0] == np.dtype("f8")
+        result = DataFrame(np.arange(20, dtype=data_type)).rolling(window=5).min()
+        assert result.dtypes[0] == np.dtype("f8")
+
+
+def test_moment_functions_zero_length():
+    # GH 8056
+    s = Series(dtype=np.float64)
+    s_expected = s
+    df1 = DataFrame()
+    df1_expected = df1
+    df2 = DataFrame(columns=["a"])
+    df2["a"] = df2["a"].astype("float64")
+    df2_expected = df2
+
+    functions = [
+        lambda x: x.rolling(window=10).count(),
+        lambda x: x.rolling(window=10, min_periods=5).cov(x, pairwise=False),
+        lambda x: x.rolling(window=10, min_periods=5).corr(x, pairwise=False),
+        lambda x: x.rolling(window=10, min_periods=5).max(),
+        lambda x: x.rolling(window=10, min_periods=5).min(),
+        lambda x: x.rolling(window=10, min_periods=5).sum(),
+        lambda x: x.rolling(window=10, min_periods=5).mean(),
+        lambda x: x.rolling(window=10, min_periods=5).std(),
+        lambda x: x.rolling(window=10, min_periods=5).var(),
+        lambda x: x.rolling(window=10, min_periods=5).skew(),
+        lambda x: x.rolling(window=10, min_periods=5).kurt(),
+        lambda x: x.rolling(window=10, min_periods=5).quantile(0.5),
+        lambda x: x.rolling(window=10, min_periods=5).median(),
+        lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=False),
+        lambda x: x.rolling(window=10, min_periods=5).apply(sum, raw=True),
+        lambda x: x.rolling(win_type="boxcar", window=10, min_periods=5).mean(),
+    ]
+    for f in functions:
+        try:
+            s_result = f(s)
+            tm.assert_series_equal(s_result, s_expected)
 
-        for f in functions:
             df1_result = f(df1)
             tm.assert_frame_equal(df1_result, df1_expected)
 
             df2_result = f(df2)
             tm.assert_frame_equal(df2_result, df2_expected)
+        except (ImportError):
+
+            # scipy needed for rolling_window
+            continue
+
+
+def test_moment_functions_zero_length_pairwise():
+
+    df1 = DataFrame()
+    df2 = DataFrame(columns=Index(["a"], name="foo"), index=Index([], name="bar"))
+    df2["a"] = df2["a"].astype("float64")
+
+    df1_expected = DataFrame(
+        index=pd.MultiIndex.from_product([df1.index, df1.columns]), columns=Index([]),
+    )
+    df2_expected = DataFrame(
+        index=pd.MultiIndex.from_product(
+            [df2.index, df2.columns], names=["bar", "foo"]
+        ),
+        columns=Index(["a"], name="foo"),
+        dtype="float64",
+    )
+
+    functions = [
+        lambda x: (x.rolling(window=10, min_periods=5).cov(x, pairwise=True)),
+        lambda x: (x.rolling(window=10, min_periods=5).corr(x, pairwise=True)),
+    ]
+
+    for f in functions:
+        df1_result = f(df1)
+        tm.assert_frame_equal(df1_result, df1_expected)
+
+        df2_result = f(df2)
+        tm.assert_frame_equal(df2_result, df2_expected)
 
 
 @pytest.mark.parametrize(
