commit 2842a43800f326b790bd8d6cbecddbbab1ddfae2
Author: Wes McKinney <wes@cloudera.com>
Date:   Fri Jan 22 10:56:08 2016 -0500

    CLN: fix flake8 warnings in pandas/stats
    
    Author: Wes McKinney <wes@cloudera.com>
    
    Closes #12114 from wesm/style/stats and squashes the following commits:
    
    a3f8508 [Wes McKinney] CLN: fix flake8 warnings in pandas/stats

diff --git a/pandas/stats/api.py b/pandas/stats/api.py
index 3732f9ed3..fd81b875f 100644
--- a/pandas/stats/api.py
+++ b/pandas/stats/api.py
@@ -4,6 +4,8 @@ Common namespace of statistical functions
 
 # pylint: disable-msg=W0611,W0614,W0401
 
+# flake8: noqa
+
 from pandas.stats.moments import *
 from pandas.stats.interface import ols
 from pandas.stats.fama_macbeth import fama_macbeth
diff --git a/pandas/stats/common.py b/pandas/stats/common.py
index c30b3e7a4..be3b842e9 100644
--- a/pandas/stats/common.py
+++ b/pandas/stats/common.py
@@ -5,9 +5,10 @@ _WINDOW_TYPES = {
     2: 'expanding'
 }
 # also allow 'rolling' as key
-_WINDOW_TYPES.update((v, v) for k,v in list(_WINDOW_TYPES.items()))
+_WINDOW_TYPES.update((v, v) for k, v in list(_WINDOW_TYPES.items()))
 _ADDITIONAL_CLUSTER_TYPES = set(("entity", "time"))
 
+
 def _get_cluster_type(cluster_type):
     # this was previous behavior
     if cluster_type is None:
@@ -20,15 +21,18 @@ def _get_cluster_type(cluster_type):
             return final_type
         raise ValueError('Unrecognized cluster type: %s' % cluster_type)
 
+
 def _get_window_type(window_type):
     # e.g., 0, 1, 2
     final_type = _WINDOW_TYPES.get(window_type)
     # e.g., 'full_sample'
-    final_type = final_type or _WINDOW_TYPES.get(str(window_type).lower().replace(" ", "_"))
+    final_type = final_type or _WINDOW_TYPES.get(
+        str(window_type).lower().replace(" ", "_"))
     if final_type is None:
         raise ValueError('Unrecognized window type: %s' % window_type)
     return final_type
 
+
 def banner(text, width=80):
     """
 
diff --git a/pandas/stats/fama_macbeth.py b/pandas/stats/fama_macbeth.py
index 01e68be27..caad53df2 100644
--- a/pandas/stats/fama_macbeth.py
+++ b/pandas/stats/fama_macbeth.py
@@ -7,6 +7,7 @@ from pandas.core.api import Series, DataFrame
 import pandas.stats.common as common
 from pandas.util.decorators import cache_readonly
 
+# flake8: noqa
 
 def fama_macbeth(**kwargs):
     """Runs Fama-MacBeth regression.
@@ -28,6 +29,7 @@ def fama_macbeth(**kwargs):
 
 
 class FamaMacBeth(StringMixin):
+
     def __init__(self, y, x, intercept=True, nw_lags=None,
                  nw_lags_beta=None,
                  entity_effects=False, time_effects=False, x_effects=None,
@@ -39,7 +41,7 @@ class FamaMacBeth(StringMixin):
                       FutureWarning, stacklevel=4)
 
         if dropped_dummies is None:
-                dropped_dummies = {}
+            dropped_dummies = {}
         self._nw_lags_beta = nw_lags_beta
 
         from pandas.stats.plm import MovingPanelOLS
@@ -99,7 +101,7 @@ class FamaMacBeth(StringMixin):
     def _coef_table(self):
         buffer = StringIO()
         buffer.write('%13s %13s %13s %13s %13s %13s\n' %
-                    ('Variable', 'Beta', 'Std Err', 't-stat', 'CI 2.5%', 'CI 97.5%'))
+                     ('Variable', 'Beta', 'Std Err', 't-stat', 'CI 2.5%', 'CI 97.5%'))
         template = '%13s %13.4f %13.4f %13.2f %13.4f %13.4f\n'
 
         for i, name in enumerate(self._cols):
@@ -148,12 +150,13 @@ Formula: Y ~ %(formulaRHS)s
 
 
 class MovingFamaMacBeth(FamaMacBeth):
+
     def __init__(self, y, x, window_type='rolling', window=10,
                  intercept=True, nw_lags=None, nw_lags_beta=None,
                  entity_effects=False, time_effects=False, x_effects=None,
                  cluster=None, dropped_dummies=None, verbose=False):
         if dropped_dummies is None:
-                dropped_dummies = {}
+            dropped_dummies = {}
         self._window_type = common._get_window_type(window_type)
         self._window = window
 
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
index 96b2b3e32..caf468b4f 100644
--- a/pandas/stats/interface.py
+++ b/pandas/stats/interface.py
@@ -76,7 +76,8 @@ def ols(**kwargs):
     result = ols(y=y, x=x)
 
     # Run expanding panel OLS with window 10 and entity clustering.
-    result = ols(y=y, x=x, cluster='entity', window_type='expanding', window=10)
+    result = ols(y=y, x=x, cluster='entity', window_type='expanding',
+                 window=10)
 
     Returns
     -------
@@ -85,12 +86,11 @@ def ols(**kwargs):
     """
 
     if (kwargs.get('cluster') is not None and
-        kwargs.get('nw_lags') is not None):
+            kwargs.get('nw_lags') is not None):
         raise ValueError(
             'Pandas OLS does not work with Newey-West correction '
             'and clustering.')
 
-
     pool = kwargs.get('pool')
     if 'pool' in kwargs:
         del kwargs['pool']
diff --git a/pandas/stats/misc.py b/pandas/stats/misc.py
index ef663b25e..1a077dcb6 100644
--- a/pandas/stats/misc.py
+++ b/pandas/stats/misc.py
@@ -2,9 +2,10 @@ from numpy import NaN
 from pandas import compat
 import numpy as np
 
-from pandas.core.api import Series, DataFrame, isnull, notnull
+from pandas.core.api import Series, DataFrame
 from pandas.core.series import remove_na
-from pandas.compat import zip
+from pandas.compat import zip, lrange
+import pandas.core.common as com
 
 
 def zscore(series):
@@ -42,6 +43,7 @@ def correl_ts(frame1, frame2):
 def correl_xs(frame1, frame2):
     return correl_ts(frame1.T, frame2.T)
 
+
 def percentileofscore(a, score, kind='rank'):
     """The percentile rank of a score relative to a list of scores.
 
@@ -131,6 +133,7 @@ def percentileofscore(a, score, kind='rank'):
     else:
         raise ValueError("kind can only be 'rank', 'strict', 'weak' or 'mean'")
 
+
 def percentileRank(frame, column=None, kind='mean'):
     """
     Return score at percentile for each point in time (cross-section)
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 28f35cf26..c875a9d49 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -20,9 +20,9 @@ __all__ = ['rolling_count', 'rolling_max', 'rolling_min',
            'expanding_sum', 'expanding_mean', 'expanding_std',
            'expanding_cov', 'expanding_corr', 'expanding_var',
            'expanding_skew', 'expanding_kurt', 'expanding_quantile',
-           'expanding_median', 'expanding_apply' ]
+           'expanding_median', 'expanding_apply']
 
-#------------------------------------------------------------------------------
+# -----------------------------------------------------------------------------
 # Docs
 
 # The order of arguments for the _doc_template is:
@@ -72,7 +72,8 @@ _ewm_kw = r"""com : float. optional
 span : float, optional
     Specify decay in terms of span, :math:`\alpha = 2 / (span + 1)`
 halflife : float, optional
-    Specify decay in terms of halflife, :math:`\alpha = 1 - exp(log(0.5) / halflife)`
+    Specify decay in terms of halflife,
+    :math:`\alpha = 1 - exp(log(0.5) / halflife)`
 min_periods : int, default 0
     Minimum number of observations in window required to have a value
     (otherwise result is NA).
@@ -173,6 +174,7 @@ _bias_kw = r"""bias : boolean, default False
     Use a standard estimation bias correction
 """
 
+
 def ensure_compat(dispatch, name, arg, func_kw=None, *args, **kwargs):
     """
     wrapper function to dispatch to the appropriate window functions
@@ -189,8 +191,10 @@ def ensure_compat(dispatch, name, arg, func_kw=None, *args, **kwargs):
         else:
             raise AssertionError("cannot support ndim > 2 for ndarray compat")
 
-        warnings.warn("pd.{dispatch}_{name} is deprecated for ndarrays and will be removed "
-                      "in a future version".format(dispatch=dispatch,name=name),
+        warnings.warn("pd.{dispatch}_{name} is deprecated for ndarrays and "
+                      "will be removed "
+                      "in a future version"
+                      .format(dispatch=dispatch, name=name),
                       FutureWarning, stacklevel=3)
 
     # get the functional keywords here
@@ -198,46 +202,46 @@ def ensure_compat(dispatch, name, arg, func_kw=None, *args, **kwargs):
         func_kw = []
     kwds = {}
     for k in func_kw:
-        value = kwargs.pop(k,None)
+        value = kwargs.pop(k, None)
         if value is not None:
             kwds[k] = value
 
     # how is a keyword that if not-None should be in kwds
-    how = kwargs.pop('how',None)
+    how = kwargs.pop('how', None)
     if how is not None:
         kwds['how'] = how
 
-    r = getattr(arg,dispatch)(**kwargs)
+    r = getattr(arg, dispatch)(**kwargs)
 
     if not is_ndarray:
 
         # give a helpful deprecation message
         # with copy-pastable arguments
-        pargs = ','.join([ "{a}={b}".format(a=a,b=b) for a,b in kwargs.items() if b is not None ])
+        pargs = ','.join(["{a}={b}".format(a=a, b=b)
+                          for a, b in kwargs.items() if b is not None])
         aargs = ','.join(args)
         if len(aargs):
             aargs += ','
 
-        def f(a,b):
+        def f(a, b):
             if lib.isscalar(b):
-                return "{a}={b}".format(a=a,b=b)
-            return "{a}=<{b}>".format(a=a,b=type(b).__name__)
-        aargs = ','.join([ f(a,b) for a,b in kwds.items() if b is not None ])
+                return "{a}={b}".format(a=a, b=b)
+            return "{a}=<{b}>".format(a=a, b=type(b).__name__)
+        aargs = ','.join([f(a, b) for a, b in kwds.items() if b is not None])
         warnings.warn("pd.{dispatch}_{name} is deprecated for {klass} "
                       "and will be removed in a future version, replace with "
-                      "\n\t{klass}.{dispatch}({pargs}).{name}({aargs})".format(klass=type(arg).__name__,
-                                                                               pargs=pargs,
-                                                                               aargs=aargs,
-                                                                               dispatch=dispatch,
-                                                                               name=name),
+                      "\n\t{klass}.{dispatch}({pargs}).{name}({aargs})"
+                      .format(klass=type(arg).__name__, pargs=pargs,
+                              aargs=aargs, dispatch=dispatch, name=name),
                       FutureWarning, stacklevel=3)
 
-    result = getattr(r,name)(*args, **kwds)
+    result = getattr(r, name)(*args, **kwds)
 
     if is_ndarray:
         result = result.values
     return result
 
+
 def rolling_count(arg, window, **kwargs):
     """
     Rolling count of number of non-NaN observations inside provided window.
@@ -249,8 +253,8 @@ def rolling_count(arg, window, **kwargs):
         Size of the moving window. This is the number of observations used for
         calculating the statistic.
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
     center : boolean, default False
         Whether the label should correspond with center of window
     how : string, default 'mean'
@@ -268,8 +272,10 @@ def rolling_count(arg, window, **kwargs):
     """
     return ensure_compat('rolling', 'count', arg, window=window, **kwargs)
 
+
 @Substitution("Unbiased moving covariance.", _binary_arg_flex,
-              _roll_kw%'None'+_pairwise_kw+_ddof_kw, _flex_retval, _roll_notes)
+              _roll_kw % 'None' + _pairwise_kw + _ddof_kw, _flex_retval,
+              _roll_notes)
 @Appender(_doc_template)
 def rolling_cov(arg1, arg2=None, window=None, pairwise=None, **kwargs):
     if window is None and isinstance(arg2, (int, float)):
@@ -285,11 +291,12 @@ def rolling_cov(arg1, arg2=None, window=None, pairwise=None, **kwargs):
                          other=arg2,
                          window=window,
                          pairwise=pairwise,
-                         func_kw=['other','pairwise','ddof'],
+                         func_kw=['other', 'pairwise', 'ddof'],
                          **kwargs)
 
+
 @Substitution("Moving sample correlation.", _binary_arg_flex,
-              _roll_kw%'None'+_pairwise_kw, _flex_retval, _roll_notes)
+              _roll_kw % 'None' + _pairwise_kw, _flex_retval, _roll_notes)
 @Appender(_doc_template)
 def rolling_corr(arg1, arg2=None, window=None, pairwise=None, **kwargs):
     if window is None and isinstance(arg2, (int, float)):
@@ -305,11 +312,11 @@ def rolling_corr(arg1, arg2=None, window=None, pairwise=None, **kwargs):
                          other=arg2,
                          window=window,
                          pairwise=pairwise,
-                         func_kw=['other','pairwise'],
+                         func_kw=['other', 'pairwise'],
                          **kwargs)
 
 
-#------------------------------------------------------------------------------
+# -----------------------------------------------------------------------------
 # Exponential moving moments
 
 
@@ -330,8 +337,9 @@ def ewma(arg, com=None, span=None, halflife=None, min_periods=0, freq=None,
                          how=how,
                          ignore_na=ignore_na)
 
+
 @Substitution("Exponentially-weighted moving variance", _unary_arg,
-              _ewm_kw+_bias_kw, _type_of_input_retval, _ewm_notes)
+              _ewm_kw + _bias_kw, _type_of_input_retval, _ewm_notes)
 @Appender(_doc_template)
 def ewmvar(arg, com=None, span=None, halflife=None, min_periods=0, bias=False,
            freq=None, how=None, ignore_na=False, adjust=True):
@@ -349,8 +357,9 @@ def ewmvar(arg, com=None, span=None, halflife=None, min_periods=0, bias=False,
                          bias=bias,
                          func_kw=['bias'])
 
+
 @Substitution("Exponentially-weighted moving std", _unary_arg,
-              _ewm_kw+_bias_kw, _type_of_input_retval, _ewm_notes)
+              _ewm_kw + _bias_kw, _type_of_input_retval, _ewm_notes)
 @Appender(_doc_template)
 def ewmstd(arg, com=None, span=None, halflife=None, min_periods=0, bias=False,
            freq=None, how=None, ignore_na=False, adjust=True):
@@ -372,10 +381,11 @@ ewmvol = ewmstd
 
 
 @Substitution("Exponentially-weighted moving covariance", _binary_arg_flex,
-              _ewm_kw+_pairwise_kw, _type_of_input_retval, _ewm_notes)
+              _ewm_kw + _pairwise_kw, _type_of_input_retval, _ewm_notes)
 @Appender(_doc_template)
 def ewmcov(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,
-           bias=False, freq=None, pairwise=None, how=None, ignore_na=False, adjust=True):
+           bias=False, freq=None, pairwise=None, how=None, ignore_na=False,
+           adjust=True):
     if arg2 is None:
         arg2 = arg1
         pairwise = True if pairwise is None else pairwise
@@ -398,10 +408,11 @@ def ewmcov(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,
                          ignore_na=ignore_na,
                          adjust=adjust,
                          pairwise=pairwise,
-                         func_kw=['other','pairwise','bias'])
+                         func_kw=['other', 'pairwise', 'bias'])
+
 
 @Substitution("Exponentially-weighted moving correlation", _binary_arg_flex,
-              _ewm_kw+_pairwise_kw, _type_of_input_retval, _ewm_notes)
+              _ewm_kw + _pairwise_kw, _type_of_input_retval, _ewm_notes)
 @Appender(_doc_template)
 def ewmcorr(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,
             freq=None, pairwise=None, how=None, ignore_na=False, adjust=True):
@@ -425,9 +436,9 @@ def ewmcorr(arg1, arg2=None, com=None, span=None, halflife=None, min_periods=0,
                          ignore_na=ignore_na,
                          adjust=adjust,
                          pairwise=pairwise,
-                         func_kw=['other','pairwise'])
+                         func_kw=['other', 'pairwise'])
 
-#----------------------------------------------------------------------
+# ---------------------------------------------------------------------
 # Python interface to Cython functions
 
 
@@ -435,9 +446,9 @@ def _rolling_func(name, desc, how=None, func_kw=None, additional_kw=''):
     if how is None:
         how_arg_str = 'None'
     else:
-        how_arg_str = "'%s"%how
+        how_arg_str = "'%s" % how
 
-    @Substitution(desc, _unary_arg, _roll_kw%how_arg_str + additional_kw,
+    @Substitution(desc, _unary_arg, _roll_kw % how_arg_str + additional_kw,
                   _type_of_input_retval, _roll_notes)
     @Appender(_doc_template)
     def f(arg, window, min_periods=None, freq=None, center=False,
@@ -468,6 +479,7 @@ rolling_var = _rolling_func('var', 'Moving variance.',
 rolling_skew = _rolling_func('skew', 'Unbiased moving skewness.')
 rolling_kurt = _rolling_func('kurt', 'Unbiased moving kurtosis.')
 
+
 def rolling_quantile(arg, window, quantile, min_periods=None, freq=None,
                      center=False):
     """Moving quantile.
@@ -484,8 +496,8 @@ def rolling_quantile(arg, window, quantile, min_periods=None, freq=None,
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
     center : boolean, default False
         Whether the label should correspond with center of window
 
@@ -529,8 +541,8 @@ def rolling_apply(arg, window, func, min_periods=None, freq=None,
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
     center : boolean, default False
         Whether the label should correspond with center of window
     args : tuple
@@ -558,7 +570,7 @@ def rolling_apply(arg, window, func, min_periods=None, freq=None,
                          freq=freq,
                          center=center,
                          min_periods=min_periods,
-                         func_kw=['func','args','kwargs'],
+                         func_kw=['func', 'args', 'kwargs'],
                          func=func,
                          args=args,
                          kwargs=kwargs)
@@ -583,8 +595,8 @@ def rolling_window(arg, window=None, win_type=None, min_periods=None,
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
     center : boolean, default False
         Whether the label should correspond with center of window
     mean : boolean, default True
@@ -636,6 +648,7 @@ def rolling_window(arg, window=None, win_type=None, min_periods=None,
                          func_kw=kwargs.keys(),
                          **kwargs)
 
+
 def _expanding_func(name, desc, func_kw=None, additional_kw=''):
     @Substitution(desc, _unary_arg, _expanding_kw + additional_kw,
                   _type_of_input_retval, "")
@@ -674,8 +687,8 @@ def expanding_count(arg, freq=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
 
     Returns
     -------
@@ -702,8 +715,8 @@ def expanding_quantile(arg, quantile, min_periods=1, freq=None):
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
 
     Returns
     -------
@@ -723,10 +736,12 @@ def expanding_quantile(arg, quantile, min_periods=1, freq=None):
                          func_kw=['quantile'],
                          quantile=quantile)
 
+
 @Substitution("Unbiased expanding covariance.", _binary_arg_flex,
-              _expanding_kw+_pairwise_kw+_ddof_kw, _flex_retval, "")
+              _expanding_kw + _pairwise_kw + _ddof_kw, _flex_retval, "")
 @Appender(_doc_template)
-def expanding_cov(arg1, arg2=None, min_periods=1, freq=None, pairwise=None, ddof=1):
+def expanding_cov(arg1, arg2=None, min_periods=1, freq=None,
+                  pairwise=None, ddof=1):
     if arg2 is None:
         arg2 = arg1
         pairwise = True if pairwise is None else pairwise
@@ -742,11 +757,11 @@ def expanding_cov(arg1, arg2=None, min_periods=1, freq=None, pairwise=None, ddof
                          pairwise=pairwise,
                          freq=freq,
                          ddof=ddof,
-                         func_kw=['other','pairwise','ddof'])
+                         func_kw=['other', 'pairwise', 'ddof'])
 
 
 @Substitution("Expanding sample correlation.", _binary_arg_flex,
-              _expanding_kw+_pairwise_kw, _flex_retval, "")
+              _expanding_kw + _pairwise_kw, _flex_retval, "")
 @Appender(_doc_template)
 def expanding_corr(arg1, arg2=None, min_periods=1, freq=None, pairwise=None):
     if arg2 is None:
@@ -763,7 +778,8 @@ def expanding_corr(arg1, arg2=None, min_periods=1, freq=None, pairwise=None):
                          min_periods=min_periods,
                          pairwise=pairwise,
                          freq=freq,
-                         func_kw=['other','pairwise','ddof'])
+                         func_kw=['other', 'pairwise', 'ddof'])
+
 
 def expanding_apply(arg, func, min_periods=1, freq=None,
                     args=(), kwargs={}):
@@ -778,8 +794,8 @@ def expanding_apply(arg, func, min_periods=1, freq=None,
         Minimum number of observations in window required to have a value
         (otherwise result is NA).
     freq : string or DateOffset object, optional (default None)
-        Frequency to conform the data to before computing the statistic. Specified
-        as a frequency string or DateOffset object.
+        Frequency to conform the data to before computing the
+        statistic. Specified as a frequency string or DateOffset object.
     args : tuple
         Passed on to func
     kwargs : dict
@@ -800,7 +816,7 @@ def expanding_apply(arg, func, min_periods=1, freq=None,
                          arg,
                          freq=freq,
                          min_periods=min_periods,
-                         func_kw=['func','args','kwargs'],
+                         func_kw=['func', 'args', 'kwargs'],
                          func=func,
                          args=args,
                          kwargs=kwargs)
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index 7031d55c0..e2375ea18 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -4,6 +4,8 @@ Ordinary least squares regression
 
 # pylint: disable-msg=W0201
 
+# flake8: noqa
+
 from pandas.compat import zip, range, StringIO
 from itertools import starmap
 from pandas import compat
@@ -22,7 +24,6 @@ import pandas.stats.moments as moments
 
 _FP_ERR = 1e-8
 
-
 class OLS(StringMixin):
     """
     Runs a full sample ordinary least squares regression.
@@ -103,7 +104,7 @@ class OLS(StringMixin):
             filt_rhs['intercept'] = 1.
             pre_filt_rhs['intercept'] = 1.
 
-        if hasattr(filt_weights,'to_dense'):
+        if hasattr(filt_weights, 'to_dense'):
             filt_weights = filt_weights.to_dense()
 
         return (filt_lhs, filt_rhs, filt_weights,
@@ -630,6 +631,7 @@ class MovingOLS(OLS):
         Assume data is overlapping when computing Newey-West estimator
 
     """
+
     def __init__(self, y, x, weights=None, window_type='expanding',
                  window=None, min_periods=None, intercept=True,
                  nw_lags=None, nw_overlap=False):
@@ -989,7 +991,7 @@ class MovingOLS(OLS):
 
         result = [2 * t.sf(a, b)
                   for a, b in zip(np.fabs(self._t_stat_raw),
-                                   self._df_resid_raw)]
+                                  self._df_resid_raw)]
 
         return np.array(result)
 
@@ -1220,7 +1222,8 @@ class MovingOLS(OLS):
             # expanding case
             window = len(self._index)
 
-        result = Series(self._time_obs_count).rolling(window, min_periods=1).sum().values
+        result = Series(self._time_obs_count).rolling(
+            window, min_periods=1).sum().values
 
         return result.astype(int)
 
@@ -1314,7 +1317,7 @@ def _filter_data(lhs, rhs, weights=None):
     filt_lhs = combined.pop('__y__')
     filt_rhs = combined
 
-    if hasattr(filt_weights,'to_dense'):
+    if hasattr(filt_weights, 'to_dense'):
         filt_weights = filt_weights.to_dense()
 
     return (filt_lhs.to_dense(), filt_rhs.to_dense(), filt_weights,
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 177452476..dca1977fb 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -5,6 +5,8 @@ Linear regression objects for panel data
 # pylint: disable-msg=W0231
 # pylint: disable-msg=E1101,E1103
 
+# flake8: noqa
+
 from __future__ import division
 from pandas.compat import range
 from pandas import compat
@@ -291,7 +293,8 @@ class PanelOLS(OLS):
                 self.log(
                     '-- Excluding dummy for %s: %s' % (effect, to_exclude))
 
-                dummies = dummies.filter(dummies.columns.difference([mapped_name]))
+                dummies = dummies.filter(
+                    dummies.columns.difference([mapped_name]))
                 dropped_dummy = True
 
             dummies = _convertDummies(dummies, cat_mappings.get(effect))
@@ -793,7 +796,7 @@ def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
             resid = resid.swaplevel(0, 1).sortlevel(0)
 
         m = _group_agg(x.values * resid.values, x.index._bounds,
-                      lambda x: np.sum(x, axis=0))
+                       lambda x: np.sum(x, axis=0))
 
         if nw_lags is None:
             nw_lags = 0
@@ -805,6 +808,7 @@ def _var_beta_panel(y, x, beta, xx, rmse, cluster_axis,
 
         return np.dot(xx_inv, np.dot(xox, xx_inv))
 
+
 def _group_agg(values, bounds, f):
     """
     R-style aggregator
@@ -840,6 +844,7 @@ def _group_agg(values, bounds, f):
 
     return result
 
+
 def _xx_time_effects(x, y):
     """
     Returns X'X - (X'T) (T'T)^-1 (T'X)
diff --git a/pandas/stats/tests/common.py b/pandas/stats/tests/common.py
index 717eb5129..0ce4b20a4 100644
--- a/pandas/stats/tests/common.py
+++ b/pandas/stats/tests/common.py
@@ -1,4 +1,5 @@
 # pylint: disable-msg=W0611,W0402
+# flake8: noqa
 
 from datetime import datetime
 import string
@@ -54,6 +55,7 @@ def check_for_statsmodels():
 
 
 class BaseTest(tm.TestCase):
+
     def setUp(self):
         check_for_scipy()
         check_for_statsmodels()
diff --git a/pandas/stats/tests/test_fama_macbeth.py b/pandas/stats/tests/test_fama_macbeth.py
index 05849bd80..deff392d6 100644
--- a/pandas/stats/tests/test_fama_macbeth.py
+++ b/pandas/stats/tests/test_fama_macbeth.py
@@ -1,3 +1,5 @@
+# flake8: noqa
+
 from pandas import DataFrame, Panel
 from pandas.stats.api import fama_macbeth
 from .common import assert_almost_equal, BaseTest
@@ -9,6 +11,7 @@ import numpy as np
 
 
 class TestFamaMacBeth(BaseTest):
+
     def testFamaMacBethRolling(self):
         # self.checkFamaMacBethExtended('rolling', self.panel_x, self.panel_y,
         #                               nw_lags_beta=2)
diff --git a/pandas/stats/tests/test_math.py b/pandas/stats/tests/test_math.py
index 628a37006..bc09f33d2 100644
--- a/pandas/stats/tests/test_math.py
+++ b/pandas/stats/tests/test_math.py
@@ -5,12 +5,8 @@ from numpy.random import randn
 import numpy as np
 
 from pandas.core.api import Series, DataFrame, date_range
-from pandas.util.testing import assert_almost_equal
-import pandas.core.datetools as datetools
-import pandas.stats.moments as mom
 import pandas.util.testing as tm
 import pandas.stats.math as pmath
-import pandas.tests.test_series as ts
 from pandas import ols
 
 N, K = 100, 10
@@ -20,7 +16,7 @@ try:
     import statsmodels.api as sm
 except ImportError:
     try:
-        import scikits.statsmodels.api as sm
+        import scikits.statsmodels.api as sm  # noqa
     except ImportError:
         _have_statsmodels = False
 
@@ -63,6 +59,5 @@ class TestMath(tm.TestCase):
         self.assertTrue(np.allclose(rs, expected))
 
 if __name__ == '__main__':
-    import nose
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index 01095ab23..175ad9dc3 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -4,6 +4,8 @@ Unit test suite for OLS and PanelOLS classes
 
 # pylint: disable-msg=W0212
 
+# flake8: noqa
+
 from __future__ import division
 
 from datetime import datetime
@@ -425,6 +427,7 @@ class TestOLSMisc(tm.TestCase):
         y = tm.makeTimeSeries()
 
         data = {'foo': df1, 'bar': df2}
+
         def f():
             with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):
                 ols(y=y, x=data)
@@ -655,7 +658,8 @@ class TestPanelOLS(BaseTest):
 
     def testWithXEffectsAndConversion(self):
         with tm.assert_produces_warning(FutureWarning, check_stacklevel=False):
-            result = ols(y=self.panel_y3, x=self.panel_x3, x_effects=['x1', 'x2'])
+            result = ols(y=self.panel_y3, x=self.panel_x3,
+                         x_effects=['x1', 'x2'])
 
         assert_almost_equal(result._y.values.flat, [1, 2, 3, 4])
         exp_x = [[0, 0, 0, 1, 1], [1, 0, 0, 0, 1], [0, 1, 1, 0, 1],
@@ -713,10 +717,12 @@ class TestPanelOLS(BaseTest):
     def testRollingWithEntityCluster(self):
         self.checkMovingOLS(self.panel_x, self.panel_y,
                             cluster='entity')
+
     def testUnknownClusterRaisesValueError(self):
         assertRaisesRegexp(ValueError, "Unrecognized cluster.*ridiculous",
                            self.checkMovingOLS, self.panel_x, self.panel_y,
-                                               cluster='ridiculous')
+                           cluster='ridiculous')
+
     def testRollingWithTimeEffectsAndEntityCluster(self):
         self.checkMovingOLS(self.panel_x, self.panel_y,
                             time_effects=True, cluster='entity')
@@ -744,6 +750,7 @@ class TestPanelOLS(BaseTest):
         self.checkNonPooled(y=self.panel_y, x=self.panel_x)
         self.checkNonPooled(y=self.panel_y, x=self.panel_x,
                             window_type='rolling', window=25, min_periods=10)
+
     def testUnknownWindowType(self):
         assertRaisesRegexp(ValueError, "window.*ridiculous",
                            self.checkNonPooled, y=self.panel_y, x=self.panel_x,
@@ -856,6 +863,7 @@ class TestPanelOLS(BaseTest):
         f2 = lambda x: np.zeros((2, 2))
         self.assertRaises(Exception, _group_agg, values, bounds, f2)
 
+
 def _check_non_raw_results(model):
     _check_repr(model)
     _check_repr(model.resid)
diff --git a/pandas/stats/tests/test_var.py b/pandas/stats/tests/test_var.py
index c6eca4041..9bcd070dc 100644
--- a/pandas/stats/tests/test_var.py
+++ b/pandas/stats/tests/test_var.py
@@ -1,3 +1,5 @@
+# flake8: noqa
+
 from __future__ import print_function
 from numpy.testing import run_module_suite, assert_equal, TestCase
 
@@ -29,6 +31,7 @@ DECIMAL_2 = 2
 
 
 class CheckVAR(object):
+
     def test_params(self):
         assert_almost_equal(self.res1.params, self.res2.params, DECIMAL_3)
 
@@ -80,6 +83,7 @@ class CheckVAR(object):
 
 
 class Foo(object):
+
     def __init__(self):
         data = sm.datasets.macrodata.load()
         data = data.data[['realinv', 'realgdp', 'realcons']].view((float, 3))
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index b06e2f318..cc78ca288 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -1,3 +1,5 @@
+# flake8: noqa
+
 from __future__ import division
 
 from pandas.compat import range, lrange, zip, reduce
@@ -517,6 +519,7 @@ class PanelVAR(VAR):
     data: Panel or dict of DataFrame
     lags: int
     """
+
     def __init__(self, data, lags, intercept=True):
         self._data = _prep_panel_data(data)
         self._p = lags
