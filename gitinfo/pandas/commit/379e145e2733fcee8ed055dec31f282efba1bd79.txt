commit 379e145e2733fcee8ed055dec31f282efba1bd79
Author: Jeff Reback <jeff@reback.net>
Date:   Fri Feb 13 22:38:12 2015 -0500

    promote consistency among type typetesting routines
    now all are is_*

diff --git a/pandas/core/categorical.py b/pandas/core/categorical.py
index a06ff5b49..4032a8e55 100644
--- a/pandas/core/categorical.py
+++ b/pandas/core/categorical.py
@@ -78,10 +78,6 @@ def _cat_compare_op(op):
 
     return f
 
-def _is_categorical(array):
-    """ return if we are a categorical possibility """
-    return isinstance(array, Categorical) or isinstance(array.dtype, CategoricalDtype)
-
 def _maybe_to_categorical(array):
     """ coerce to a categorical if a series is given """
     if isinstance(array, ABCSeries):
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 581ed31b9..05739a11c 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -368,7 +368,7 @@ def notnull(obj):
         return not res
     return ~res
 
-def _is_null_datelike_scalar(other):
+def is_null_datelike_scalar(other):
     """ test whether the object is a null datelike, e.g. Nat
     but guard against passing a non-scalar """
     if other is pd.NaT or other is None:
@@ -2084,7 +2084,7 @@ def _possibly_infer_to_datetimelike(value, convert_dates=False):
     return value
 
 
-def _is_bool_indexer(key):
+def is_bool_indexer(key):
     if isinstance(key, (ABCSeries, np.ndarray)):
         if key.dtype == np.object_:
             key = np.asarray(_values_from_object(key))
@@ -2363,6 +2363,9 @@ def _maybe_make_list(obj):
         return [obj]
     return obj
 
+########################
+##### TYPE TESTING #####
+########################
 
 is_bool = lib.is_bool
 
@@ -2431,7 +2434,7 @@ def _get_dtype_type(arr_or_dtype):
     return arr_or_dtype.dtype.type
 
 
-def _is_any_int_dtype(arr_or_dtype):
+def is_any_int_dtype(arr_or_dtype):
     tipo = _get_dtype_type(arr_or_dtype)
     return issubclass(tipo, np.integer)
 
@@ -2442,7 +2445,7 @@ def is_integer_dtype(arr_or_dtype):
             not issubclass(tipo, (np.datetime64, np.timedelta64)))
 
 
-def _is_int_or_datetime_dtype(arr_or_dtype):
+def is_int_or_datetime_dtype(arr_or_dtype):
     tipo = _get_dtype_type(arr_or_dtype)
     return (issubclass(tipo, np.integer) or
             issubclass(tipo, (np.datetime64, np.timedelta64)))
@@ -2467,12 +2470,12 @@ def is_timedelta64_ns_dtype(arr_or_dtype):
     return tipo == _TD_DTYPE
 
 
-def _is_datetime_or_timedelta_dtype(arr_or_dtype):
+def is_datetime_or_timedelta_dtype(arr_or_dtype):
     tipo = _get_dtype_type(arr_or_dtype)
     return issubclass(tipo, (np.datetime64, np.timedelta64))
 
 
-needs_i8_conversion = _is_datetime_or_timedelta_dtype
+needs_i8_conversion = is_datetime_or_timedelta_dtype
 
 def i8_boxer(arr_or_dtype):
     """ return the scalar boxer for the dtype """
@@ -2493,7 +2496,7 @@ def is_float_dtype(arr_or_dtype):
     return issubclass(tipo, np.floating)
 
 
-def _is_floating_dtype(arr_or_dtype):
+def is_floating_dtype(arr_or_dtype):
     tipo = _get_dtype_type(arr_or_dtype)
     return isinstance(tipo, np.floating)
 
@@ -2502,6 +2505,10 @@ def is_bool_dtype(arr_or_dtype):
     tipo = _get_dtype_type(arr_or_dtype)
     return issubclass(tipo, np.bool_)
 
+def is_categorical(array):
+    """ return if we are a categorical possibility """
+    return isinstance(array, ABCCategorical) or isinstance(array.dtype, CategoricalDtype)
+
 def is_categorical_dtype(arr_or_dtype):
     if hasattr(arr_or_dtype,'dtype'):
         arr_or_dtype = arr_or_dtype.dtype
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 46f284f22..dbb4e83ed 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1798,7 +1798,7 @@ class DataFrame(NDFrame):
 
     def _getitem_array(self, key):
         # also raises Exception if object array with NA values
-        if com._is_bool_indexer(key):
+        if com.is_bool_indexer(key):
             # warning here just in case -- previously __setitem__ was
             # reindexing but __getitem__ was not; it seems more reasonable to
             # go with the __setitem__ behavior since that is more consistent
@@ -2115,7 +2115,7 @@ class DataFrame(NDFrame):
 
     def _setitem_array(self, key, value):
         # also raises Exception if object array with NA values
-        if com._is_bool_indexer(key):
+        if com.is_bool_indexer(key):
             if len(key) != len(self.index):
                 raise ValueError('Item wrong length %d instead of %d!' %
                                  (len(key), len(self.index)))
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 9d5fde560..7c5a75d86 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -25,7 +25,7 @@ from pandas.core.common import(_possibly_downcast_to_dtype, isnull,
                                notnull, _DATELIKE_DTYPES, is_numeric_dtype,
                                is_timedelta64_dtype, is_datetime64_dtype,
                                is_categorical_dtype, _values_from_object,
-                               _is_datetime_or_timedelta_dtype, is_bool_dtype)
+                               is_datetime_or_timedelta_dtype, is_bool_dtype)
 from pandas.core.config import option_context
 import pandas.lib as lib
 from pandas.lib import Timestamp
@@ -1491,7 +1491,7 @@ class BaseGrouper(object):
 
         is_numeric = is_numeric_dtype(values.dtype)
 
-        if _is_datetime_or_timedelta_dtype(values.dtype):
+        if is_datetime_or_timedelta_dtype(values.dtype):
             values = values.view('int64')
         elif is_bool_dtype(values.dtype):
             values = _algos.ensure_float64(values)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 75a4e0c96..c62f18f24 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -19,7 +19,8 @@ from pandas.util.decorators import (Appender, Substitution, cache_readonly,
 from pandas.core.common import isnull, array_equivalent
 import pandas.core.common as com
 from pandas.core.common import (_values_from_object, is_float, is_integer,
-                                ABCSeries, _ensure_object, _ensure_int64)
+                                ABCSeries, _ensure_object, _ensure_int64, is_bool_indexer,
+                                is_list_like, is_bool_dtype, is_integer_dtype)
 from pandas.core.config import get_option
 from pandas.io.common import PerformanceWarning
 
@@ -55,7 +56,7 @@ def _indexOp(opname):
 
         # technically we could support bool dtyped Index
         # for now just return the indexing array directly
-        if com.is_bool_dtype(result):
+        if is_bool_dtype(result):
             return result
         try:
             return Index(result)
@@ -160,7 +161,7 @@ class Index(IndexOpsMixin, PandasObject):
                 return Int64Index(data, copy=copy, dtype=dtype, name=name)
             elif issubclass(data.dtype.type, np.floating):
                 return Float64Index(data, copy=copy, dtype=dtype, name=name)
-            elif issubclass(data.dtype.type, np.bool) or com.is_bool_dtype(data):
+            elif issubclass(data.dtype.type, np.bool) or is_bool_dtype(data):
                 subarr = data.astype('object')
             else:
                 subarr = com._asarray_tuplesafe(data, dtype=object)
@@ -510,15 +511,15 @@ class Index(IndexOpsMixin, PandasObject):
         if level is not None and self.nlevels == 1:
             raise ValueError('Level must be None for non-MultiIndex')
 
-        if level is not None and not com.is_list_like(level) and com.is_list_like(names):
+        if level is not None and not is_list_like(level) and is_list_like(names):
             raise TypeError("Names must be a string")
 
-        if not com.is_list_like(names) and level is None and self.nlevels > 1:
+        if not is_list_like(names) and level is None and self.nlevels > 1:
             raise TypeError("Must pass list-like as `names`.")
 
-        if not com.is_list_like(names):
+        if not is_list_like(names):
             names = [names]
-        if level is not None and not com.is_list_like(level):
+        if level is not None and not is_list_like(level):
             level = [level]
 
         if inplace:
@@ -768,7 +769,7 @@ class Index(IndexOpsMixin, PandasObject):
             and we have a mixed index (e.g. number/labels). figure out
             the indexer. return None if we can't help
         """
-        if (typ is None or typ in ['iloc','ix']) and (com.is_integer_dtype(keyarr) and not self.is_floating()):
+        if (typ is None or typ in ['iloc','ix']) and (is_integer_dtype(keyarr) and not self.is_floating()):
             if self.inferred_type != 'integer':
                 keyarr = np.where(keyarr < 0,
                                   len(self) + keyarr, keyarr)
@@ -929,7 +930,7 @@ class Index(IndexOpsMixin, PandasObject):
             # pessimization of basic indexing.
             return promote(getitem(key))
 
-        if com._is_bool_indexer(key):
+        if is_bool_indexer(key):
             key = np.asarray(key)
 
         key = _values_from_object(key)
@@ -2104,7 +2105,7 @@ class Index(IndexOpsMixin, PandasObject):
         if isinstance(slc, np.ndarray):
             # get_loc may return a boolean array or an array of indices, which
             # is OK as long as they are representable by a slice.
-            if com.is_bool_dtype(slc):
+            if is_bool_dtype(slc):
                 slc = lib.maybe_booleans_to_slice(slc.view('u1'))
             else:
                 slc = lib.maybe_indices_to_slice(slc.astype('i8'))
@@ -2882,15 +2883,15 @@ class MultiIndex(Index):
                    labels=[[0, 0, 1, 1], [0, 1, 0, 1]],
                    names=[u'foo', u'bar'])
         """
-        if level is not None and not com.is_list_like(level):
-            if not com.is_list_like(levels):
+        if level is not None and not is_list_like(level):
+            if not is_list_like(levels):
                 raise TypeError("Levels must be list-like")
-            if com.is_list_like(levels[0]):
+            if is_list_like(levels[0]):
                 raise TypeError("Levels must be list-like")
             level = [level]
             levels = [levels]
-        elif level is None or com.is_list_like(level):
-            if not com.is_list_like(levels) or not com.is_list_like(levels[0]):
+        elif level is None or is_list_like(level):
+            if not is_list_like(levels) or not is_list_like(levels[0]):
                 raise TypeError("Levels must be list of lists-like")
 
         if inplace:
@@ -2980,15 +2981,15 @@ class MultiIndex(Index):
                    labels=[[1, 0, 1, 0], [0, 0, 1, 1]],
                    names=[u'foo', u'bar'])
         """
-        if level is not None and not com.is_list_like(level):
-            if not com.is_list_like(labels):
+        if level is not None and not is_list_like(level):
+            if not is_list_like(labels):
                 raise TypeError("Labels must be list-like")
-            if com.is_list_like(labels[0]):
+            if is_list_like(labels[0]):
                 raise TypeError("Labels must be list-like")
             level = [level]
             labels = [labels]
-        elif level is None or com.is_list_like(level):
-            if not com.is_list_like(labels) or not com.is_list_like(labels[0]):
+        elif level is None or is_list_like(level):
+            if not is_list_like(labels) or not is_list_like(labels[0]):
                 raise TypeError("Labels must be list of lists-like")
 
         if inplace:
@@ -3642,7 +3643,7 @@ class MultiIndex(Index):
 
             return tuple(retval)
         else:
-            if com._is_bool_indexer(key):
+            if is_bool_indexer(key):
                 key = np.asarray(key)
                 sortorder = self.sortorder
             else:
@@ -4404,14 +4405,14 @@ class MultiIndex(Index):
         ranges = []
         for i,k in enumerate(tup):
 
-            if com._is_bool_indexer(k):
+            if is_bool_indexer(k):
                 # a boolean indexer, must be the same length!
                 k = np.asarray(k)
                 if len(k) != len(self):
                     raise ValueError("cannot index with a boolean indexer that is"
                                      " not the same length as the index")
                 ranges.append(k)
-            elif com.is_list_like(k):
+            elif is_list_like(k):
                 # a collection of labels to include from this level (these are or'd)
                 indexers = []
                 for x in k:
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 1ce9decd1..56446d056 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -5,10 +5,10 @@ from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.compat import range, zip
 import pandas.compat as compat
 import pandas.core.common as com
-from pandas.core.common import (_is_bool_indexer, is_integer_dtype,
+from pandas.core.common import (is_bool_indexer, is_integer_dtype,
                                 _asarray_tuplesafe, is_list_like, isnull,
                                 ABCSeries, ABCDataFrame, ABCPanel, is_float,
-                                _values_from_object, _infer_fill_value)
+                                _values_from_object, _infer_fill_value, is_integer)
 import pandas.lib as lib
 
 import numpy as np
@@ -188,7 +188,7 @@ class _NDFrameIndexer(object):
                 elif is_list_like(i):
                     # should check the elements?
                     pass
-                elif com.is_integer(i):
+                elif is_integer(i):
                     if i >= len(ax):
                         raise IndexError("{0} cannot enlarge its target object"
                                          .format(self.name))
@@ -342,7 +342,7 @@ class _NDFrameIndexer(object):
                 value = self._align_series(indexer, value)
 
             info_idx = indexer[info_axis]
-            if com.is_integer(info_idx):
+            if is_integer(info_idx):
                 info_idx = [info_idx]
             labels = item_labels[info_idx]
 
@@ -479,7 +479,7 @@ class _NDFrameIndexer(object):
                 # if we are setting on the info axis ONLY
                 # set using those methods to avoid block-splitting
                 # logic here
-                if len(indexer) > info_axis and com.is_integer(indexer[info_axis]) and all(
+                if len(indexer) > info_axis and is_integer(indexer[info_axis]) and all(
                     _is_null_slice(idx) for i, idx in enumerate(indexer) if i != info_axis):
                     self.obj[item_labels[indexer[info_axis]]] = value
                     return
@@ -728,7 +728,7 @@ class _NDFrameIndexer(object):
         for indexer, ax in zip(tup, self.obj._data.axes):
             if isinstance(ax, MultiIndex):
                 return False
-            elif com._is_bool_indexer(indexer):
+            elif is_bool_indexer(indexer):
                 return False
             elif not ax.is_unique:
                 return False
@@ -752,7 +752,7 @@ class _NDFrameIndexer(object):
     def _convert_for_reindex(self, key, axis=0):
         labels = self.obj._get_axis(axis)
 
-        if com._is_bool_indexer(key):
+        if is_bool_indexer(key):
             key = _check_bool_indexer(labels, key)
             return labels[key]
         else:
@@ -907,7 +907,7 @@ class _NDFrameIndexer(object):
 
             return self._getitem_iterable(key, axis=axis)
         else:
-            if com.is_integer(key):
+            if is_integer(key):
                 if axis == 0 and isinstance(labels, MultiIndex):
                     try:
                         return self._get_label(key, axis=axis)
@@ -945,7 +945,7 @@ class _NDFrameIndexer(object):
 
             return result
 
-        if com._is_bool_indexer(key):
+        if is_bool_indexer(key):
             key = _check_bool_indexer(labels, key)
             inds, = key.nonzero()
             return self.obj.take(inds, axis=axis, convert=False)
@@ -1053,7 +1053,7 @@ class _NDFrameIndexer(object):
 
         # see if we are positional in nature
         is_int_index = labels.is_integer()
-        is_int_positional = com.is_integer(obj) and not is_int_index
+        is_int_positional = is_integer(obj) and not is_int_index
 
         # if we are a label return me
         try:
@@ -1094,7 +1094,7 @@ class _NDFrameIndexer(object):
         elif _is_nested_tuple(obj, labels):
             return labels.get_locs(obj)
         elif _is_list_like(obj):
-            if com._is_bool_indexer(obj):
+            if is_bool_indexer(obj):
                 obj = _check_bool_indexer(labels, obj)
                 inds, = obj.nonzero()
                 return inds
@@ -1174,7 +1174,7 @@ class _IXIndexer(_NDFrameIndexer):
         if isinstance(key, slice):
             return True
 
-        elif com._is_bool_indexer(key):
+        elif is_bool_indexer(key):
             return True
 
         elif _is_list_like(key):
@@ -1261,7 +1261,7 @@ class _LocIndexer(_LocationIndexer):
                             (key.stop, self.obj._get_axis_name(axis))
                         )
 
-        elif com._is_bool_indexer(key):
+        elif is_bool_indexer(key):
             return True
 
         elif _is_list_like(key):
@@ -1308,7 +1308,7 @@ class _LocIndexer(_LocationIndexer):
         if isinstance(key, slice):
             self._has_valid_type(key, axis)
             return self._get_slice_axis(key, axis=axis)
-        elif com._is_bool_indexer(key):
+        elif is_bool_indexer(key):
             return self._getbool_axis(key, axis=axis)
         elif _is_list_like(key):
 
@@ -1348,7 +1348,7 @@ class _iLocIndexer(_LocationIndexer):
     _exception = IndexError
 
     def _has_valid_type(self, key, axis):
-        if com._is_bool_indexer(key):
+        if is_bool_indexer(key):
             if hasattr(key, 'index') and isinstance(key.index, Index):
                 if key.index.inferred_type == 'integer':
                     raise NotImplementedError(
@@ -1361,9 +1361,9 @@ class _iLocIndexer(_LocationIndexer):
 
         if isinstance(key, slice):
             return True
-        elif com.is_integer(key):
+        elif is_integer(key):
             return self._is_valid_integer(key, axis)
-        elif (_is_list_like(key)):
+        elif _is_list_like(key):
             return self._is_valid_list_like(key, axis)
         return False
 
@@ -1438,7 +1438,7 @@ class _iLocIndexer(_LocationIndexer):
             self._has_valid_type(key, axis)
             return self._get_slice_axis(key, axis=axis)
 
-        elif com._is_bool_indexer(key):
+        elif is_bool_indexer(key):
             self._has_valid_type(key, axis)
             return self._getbool_axis(key, axis=axis)
 
@@ -1456,7 +1456,7 @@ class _iLocIndexer(_LocationIndexer):
             else:
                 key = self._convert_scalar_indexer(key, axis)
 
-                if not com.is_integer(key):
+                if not is_integer(key):
                     raise TypeError("Cannot index by location index with a "
                                     "non-integer key")
 
@@ -1526,11 +1526,11 @@ class _AtIndexer(_ScalarAccessIndexer):
 
         for ax, i in zip(self.obj.axes, key):
             if ax.is_integer():
-                if not com.is_integer(i):
+                if not is_integer(i):
                     raise ValueError("At based indexing on an integer index can only have integer "
                                      "indexers")
             else:
-                if com.is_integer(i):
+                if is_integer(i):
                     raise ValueError("At based indexing on an non-integer index can only have non-integer "
                                      "indexers")
         return key
@@ -1546,7 +1546,7 @@ class _iAtIndexer(_ScalarAccessIndexer):
     def _convert_key(self, key, is_setter=False):
         """ require  integer args (and convert to label arguments) """
         for a, i in zip(self.obj.axes, key):
-            if not com.is_integer(i):
+            if not is_integer(i):
                 raise ValueError("iAt based indexing can only have integer "
                                  "indexers")
         return key
@@ -1608,7 +1608,7 @@ def _convert_to_index_sliceable(obj, key):
 
 def _is_index_slice(obj):
     def _is_valid_index(x):
-        return (com.is_integer(x) or com.is_float(x)
+        return (is_integer(x) or is_float(x)
                 and np.allclose(x, int(x), rtol=_eps, atol=0))
 
     def _crit(v):
@@ -1623,7 +1623,7 @@ def _check_bool_indexer(ax, key):
     # boolean indexing, need to check that the data are aligned, otherwise
     # disallowed
 
-    # this function assumes that com._is_bool_indexer(key) == True
+    # this function assumes that is_bool_indexer(key) == True
 
     result = key
     if isinstance(key, ABCSeries) and not key.index.equals(ax):
@@ -1635,7 +1635,7 @@ def _check_bool_indexer(ax, key):
         result = result.astype(bool).values
 
     else:
-        # com._is_bool_indexer has already checked for nulls in the case of an
+        # is_bool_indexer has already checked for nulls in the case of an
         # object array key, so no check needed here
         result = np.asarray(result, dtype=bool)
 
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 6cf7fa588..6c0b8f5ec 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -11,13 +11,13 @@ from pandas.core.base import PandasObject
 from pandas.core.common import (_possibly_downcast_to_dtype, isnull,
                                 _NS_DTYPE, _TD_DTYPE, ABCSeries, is_list_like,
                                 ABCSparseSeries, _infer_dtype_from_scalar,
-                                _is_null_datelike_scalar, _maybe_promote,
+                                is_null_datelike_scalar, _maybe_promote,
                                 is_timedelta64_dtype, is_datetime64_dtype,
                                 _possibly_infer_to_datetimelike, array_equivalent,
-                                _maybe_convert_string_to_object)
+                                _maybe_convert_string_to_object, is_categorical)
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.core.indexing import (_maybe_convert_indices, _length_of_indexer)
-from pandas.core.categorical import Categorical, _maybe_to_categorical, _is_categorical
+from pandas.core.categorical import Categorical, _maybe_to_categorical
 import pandas.core.common as com
 from pandas.sparse.array import _maybe_to_sparse, SparseArray
 import pandas.lib as lib
@@ -1324,7 +1324,7 @@ class TimeDeltaBlock(IntBlock):
 
         values = masker(values)
 
-        if _is_null_datelike_scalar(other):
+        if is_null_datelike_scalar(other):
             other = np.nan
         elif isinstance(other, (np.timedelta64, Timedelta, timedelta)):
             other = _coerce_scalar_to_timedelta_type(other, unit='s', box=False).item()
@@ -1799,7 +1799,7 @@ class DatetimeBlock(Block):
             we are going to compare vs i8, so coerce to integer
             values is always ndarra like, other may not be """
         values = values.view('i8')
-        if _is_null_datelike_scalar(other):
+        if is_null_datelike_scalar(other):
             other = tslib.iNaT
         elif isinstance(other, datetime):
             other = lib.Timestamp(other).asm8.view('i8')
@@ -2072,7 +2072,7 @@ def make_block(values, placement, klass=None, ndim=None,
             klass = DatetimeBlock
         elif issubclass(vtype, np.complexfloating):
             klass = ComplexBlock
-        elif _is_categorical(values):
+        elif is_categorical(values):
             klass = CategoricalBlock
 
         else:
@@ -2947,7 +2947,7 @@ class BlockManager(PandasObject):
         #        can prob also fix the various if tests for sparse/categorical
 
         value_is_sparse = isinstance(value, SparseArray)
-        value_is_cat = _is_categorical(value)
+        value_is_cat = is_categorical(value)
         value_is_nonconsolidatable = value_is_sparse or value_is_cat
 
         if value_is_sparse:
@@ -3594,7 +3594,7 @@ def form_blocks(arrays, names, axes):
             int_items.append((i, k, v))
         elif v.dtype == np.bool_:
             bool_items.append((i, k, v))
-        elif _is_categorical(v):
+        elif is_categorical(v):
             cat_items.append((i, k, v))
         else:
             object_items.append((i, k, v))
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 9587d0d4a..602850d85 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -19,12 +19,12 @@ from pandas.core.common import (isnull, notnull, _values_from_object,
                                 ensure_float, _ensure_float64,
                                 _ensure_int64, _ensure_object,
                                 is_float, is_integer, is_complex,
-                                is_float_dtype, _is_floating_dtype,
+                                is_float_dtype, is_floating_dtype,
                                 is_complex_dtype, is_integer_dtype,
                                 is_bool_dtype, is_object_dtype,
                                 is_datetime64_dtype, is_timedelta64_dtype,
-                                _is_datetime_or_timedelta_dtype,
-                                _is_int_or_datetime_dtype, _is_any_int_dtype)
+                                is_datetime_or_timedelta_dtype,
+                                is_int_or_datetime_dtype, is_any_int_dtype)
 
 
 class disallow(object):
@@ -105,7 +105,7 @@ class bottleneck_switch(object):
 def _bn_ok_dtype(dt, name):
     # Bottleneck chokes on datetime64
     if (not is_object_dtype(dt) and
-            not _is_datetime_or_timedelta_dtype(dt)):
+            not is_datetime_or_timedelta_dtype(dt)):
 
         # bottleneck does not properly upcast during the sum
         # so can overflow
@@ -198,7 +198,7 @@ def _get_values(values, skipna, fill_value=None, fill_value_typ=None,
 
 
 def _isfinite(values):
-    if _is_datetime_or_timedelta_dtype(values):
+    if is_datetime_or_timedelta_dtype(values):
         return isnull(values)
     if (is_complex_dtype(values) or is_float_dtype(values) or
             is_integer_dtype(values) or is_bool_dtype(values)):
@@ -207,11 +207,11 @@ def _isfinite(values):
 
 
 def _na_ok_dtype(dtype):
-    return not _is_int_or_datetime_dtype(dtype)
+    return not is_int_or_datetime_dtype(dtype)
 
 
 def _view_if_needed(values):
-    if _is_datetime_or_timedelta_dtype(values):
+    if is_datetime_or_timedelta_dtype(values):
         return values.view(np.int64)
     return values
 
@@ -332,7 +332,7 @@ def _get_counts_nanvar(mask, axis, ddof):
 def _nanvar(values, axis=None, skipna=True, ddof=1):
     # private nanvar calculator
     mask = isnull(values)
-    if not _is_floating_dtype(values):
+    if not is_floating_dtype(values):
         values = values.astype('f8')
 
     count, d = _get_counts_nanvar(mask, axis, ddof)
@@ -367,7 +367,7 @@ def nansem(values, axis=None, skipna=True, ddof=1):
     var = nanvar(values, axis, skipna, ddof=ddof)
 
     mask = isnull(values)
-    if not _is_floating_dtype(values):
+    if not is_floating_dtype(values):
         values = values.astype('f8')
     count, _ = _get_counts_nanvar(mask, axis, ddof)
 
@@ -461,7 +461,7 @@ def nanargmin(values, axis=None, skipna=True):
 def nanskew(values, axis=None, skipna=True):
 
     mask = isnull(values)
-    if not _is_floating_dtype(values):
+    if not is_floating_dtype(values):
         values = values.astype('f8')
 
     count = _get_counts(mask, axis)
@@ -496,7 +496,7 @@ def nanskew(values, axis=None, skipna=True):
 def nankurt(values, axis=None, skipna=True):
 
     mask = isnull(values)
-    if not _is_floating_dtype(values):
+    if not is_floating_dtype(values):
         values = values.astype('f8')
 
     count = _get_counts(mask, axis)
@@ -533,7 +533,7 @@ def nankurt(values, axis=None, skipna=True):
 @disallow('M8','m8')
 def nanprod(values, axis=None, skipna=True):
     mask = isnull(values)
-    if skipna and not _is_any_int_dtype(values):
+    if skipna and not is_any_int_dtype(values):
         values = values.copy()
         values[mask] = 1
     result = values.prod(axis)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index e3129f181..8e859c06c 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -13,7 +13,7 @@ from numpy import nan, ndarray
 import numpy as np
 import numpy.ma as ma
 
-from pandas.core.common import (isnull, notnull, _is_bool_indexer,
+from pandas.core.common import (isnull, notnull, is_bool_indexer,
                                 _default_index, _maybe_upcast,
                                 _asarray_tuplesafe, _infer_dtype_from_scalar,
                                 is_list_like, _values_from_object,
@@ -531,7 +531,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
                 pass
             elif key is Ellipsis:
                 return self
-            elif _is_bool_indexer(key):
+            elif is_bool_indexer(key):
                 pass
             else:
 
@@ -547,7 +547,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
         if com.is_iterator(key):
             key = list(key)
 
-        if _is_bool_indexer(key):
+        if is_bool_indexer(key):
             key = _check_bool_indexer(self.index, key)
 
         return self._get_with(key)
@@ -640,7 +640,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
                 elif key is Ellipsis:
                     self[:] = value
                     return
-                elif _is_bool_indexer(key):
+                elif is_bool_indexer(key):
                     pass
                 elif com.is_timedelta64_dtype(self.dtype):
                     # reassign a null value to iNaT
@@ -665,7 +665,7 @@ class Series(base.IndexOpsMixin, generic.NDFrame):
                 if 'unorderable' in str(e):  # pragma: no cover
                     raise IndexError(key)
 
-            if _is_bool_indexer(key):
+            if is_bool_indexer(key):
                 key = _check_bool_indexer(self.index, key)
                 try:
                     self.where(~key, value, inplace=True)
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 27e4845e3..454b0f793 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -609,7 +609,7 @@ _join_functions = {
 
 
 def _factorize_keys(lk, rk, sort=True):
-    if com._is_int_or_datetime_dtype(lk) and com._is_int_or_datetime_dtype(rk):
+    if com.is_int_or_datetime_dtype(lk) and com.is_int_or_datetime_dtype(rk):
         klass = _hash.Int64Factorizer
         lk = com._ensure_int64(lk)
         rk = com._ensure_int64(rk)
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 65414fe39..34cbfe0a3 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -1348,7 +1348,7 @@ class DatetimeIndex(DatetimeIndexOpsMixin, Int64Index):
             val = getitem(key)
             return Timestamp(val, offset=self.offset, tz=self.tz)
         else:
-            if com._is_bool_indexer(key):
+            if com.is_bool_indexer(key):
                 key = np.asarray(key)
                 if key.all():
                     key = slice(0,None,None)
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index fbea7a3e1..58d2606ec 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -112,7 +112,7 @@ class Period(PandasObject):
                 converted = other.asfreq(freq)
                 self.ordinal = converted.ordinal
 
-        elif com._is_null_datelike_scalar(value) or value in tslib._nat_strings:
+        elif com.is_null_datelike_scalar(value) or value in tslib._nat_strings:
             self.ordinal = tslib.iNaT
             if freq is None:
                 raise ValueError("If value is NaT, freq cannot be None "
@@ -1113,7 +1113,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index):
             val = getitem(key)
             return Period(ordinal=val, freq=self.freq)
         else:
-            if com._is_bool_indexer(key):
+            if com.is_bool_indexer(key):
                 key = np.asarray(key)
 
             result = getitem(key)
diff --git a/pandas/tseries/tdi.py b/pandas/tseries/tdi.py
index db23c4229..cf32d4ccc 100644
--- a/pandas/tseries/tdi.py
+++ b/pandas/tseries/tdi.py
@@ -752,7 +752,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, Int64Index):
             val = getitem(key)
             return Timedelta(val)
         else:
-            if com._is_bool_indexer(key):
+            if com.is_bool_indexer(key):
                 key = np.asarray(key)
                 if key.all():
                     key = slice(0,None,None)
