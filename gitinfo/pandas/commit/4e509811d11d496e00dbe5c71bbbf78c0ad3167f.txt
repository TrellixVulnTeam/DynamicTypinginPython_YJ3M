commit 4e509811d11d496e00dbe5c71bbbf78c0ad3167f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Sep 5 15:07:29 2011 -0400

    ENH: can do as_index=False in groupby. removed dummy 'index' column from DataFrame.to_csv output and added index_label option

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 2ad184d8a..0b94a9b74 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -454,7 +454,7 @@ class DataFrame(NDFrame):
                                default_fill_value=fill_value)
 
     def to_csv(self, path, nanRep='', cols=None, header=True,
-              index=True, mode='wb'):
+              index=True, index_label=None, mode='wb'):
         """
         Write DataFrame to a comma-separated values (csv) file
 
@@ -469,6 +469,8 @@ class DataFrame(NDFrame):
             Write out column names
         index : boolean, default True
             Write row names (index)
+        index_label : string, default None
+            Column label for index column if desired
         mode : Python write mode, default 'wb'
         """
         f = open(path, mode)
@@ -479,11 +481,9 @@ class DataFrame(NDFrame):
         series = self._series
         if header:
             joined_cols = ','.join([str(c) for c in cols])
-            if index:
-                # this could be dangerous
-                f.write('index,%s' % joined_cols)
-            else:
-                f.write(joined_cols)
+            if index and index_label:
+                f.write('%s,%s' % (index_label, joined_cols))
+            f.write(joined_cols)
             f.write('\n')
 
         for idx in self.index:
@@ -1724,10 +1724,11 @@ class DataFrame(NDFrame):
             raise Exception('this DataFrame does not have a multi-level index')
 
         new_obj = self.copy()
+        names = self.index.names
 
         zipped = zip(self.index.levels, self.index.labels)
         for i, (lev, lab) in reversed(list(enumerate(zipped))):
-            new_obj.insert(0, 'label_%d' % i, np.asarray(lev).take(lab))
+            new_obj.insert(0, names[i], np.asarray(lev).take(lab))
 
         new_obj.index = np.arange(len(new_obj))
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index c993de75c..18df2a2be 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -80,7 +80,7 @@ class PandasObject(Picklable):
         name = self._get_axis_name(axis)
         return getattr(self, name)
 
-    def groupby(self, by=None, axis=0, level=None):
+    def groupby(self, by=None, axis=0, level=None, as_index=True):
         """
         Group series using mapper (dict or key function, apply given function
         to group, return result as series) or by a series of columns
@@ -96,6 +96,10 @@ class PandasObject(Picklable):
         level : int, default None
             If the axis is a MultiIndex (hierarchical), group by a particular
             level
+        as_index : boolean, default True
+            For aggregated output, return object with group labels as the
+            index. Only relevant for DataFrame input. as_index=False is
+            effectively "SQL-style" grouped output
 
         Examples
         --------
@@ -113,7 +117,7 @@ class PandasObject(Picklable):
         GroupBy object
         """
         from pandas.core.groupby import groupby
-        return groupby(self, by, axis=axis, level=level)
+        return groupby(self, by, axis=axis, level=level, as_index=as_index)
 
     def truncate(self, before=None, after=None):
         """Function truncate a sorted DataFrame / Series before and/or after
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index dd6b09998..5811ad0e6 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -81,12 +81,17 @@ class GroupBy(object):
     """
 
     def __init__(self, obj, grouper=None, axis=0, level=None,
-                 groupings=None, exclusions=None, name=None):
+                 groupings=None, exclusions=None, name=None, as_index=True):
         self._name = name
         self.obj = obj
         self.axis = axis
         self.level = level
 
+        if not as_index:
+            assert(isinstance(obj, DataFrame))
+            assert(axis == 0)
+        self.as_index = as_index
+
         if groupings is None:
             groupings, exclusions = _get_groupings(obj, grouper, axis=axis,
                                                    level=level)
@@ -317,9 +322,13 @@ class GroupBy(object):
         return self._wrap_aggregated_output(output, mask)
 
     def _get_multi_index(self, mask):
+        masked = [labels for _, labels in self._get_group_levels(mask)]
+        names = [ping.name for ping in self.groupings]
+        return MultiIndex.from_arrays(masked, names=names)
+
+    def _get_group_levels(self, mask):
         name_list = self._get_names()
-        masked = [raveled[mask] for _, raveled in name_list]
-        return MultiIndex.from_arrays(masked)
+        return [(name, raveled[mask]) for name, raveled in name_list]
 
     def _python_agg_general(self, arg):
         group_shape = self._group_shape
@@ -670,12 +679,14 @@ class SeriesGroupBy(GroupBy):
         if len(keys) == 0:
             return Series([])
 
+        key_names = [ping.name for ping in self.groupings]
+
         if isinstance(values[0], Series):
             if not_indexed_same:
                 data_dict = dict(zip(keys, values))
                 result = DataFrame(data_dict).T
                 if len(self.groupings) > 1:
-                    result.index = MultiIndex.from_tuples(keys)
+                    result.index = MultiIndex.from_tuples(keys, names=key_names)
                 return result
             else:
                 cat_values = np.concatenate([x.values for x in values])
@@ -688,7 +699,7 @@ class SeriesGroupBy(GroupBy):
                                      not_indexed_same=not_indexed_same)
         else:
             if len(self.groupings) > 1:
-                index = MultiIndex.from_tuples(keys)
+                index = MultiIndex.from_tuples(keys, names=key_names)
                 return Series(values, index)
             else:
                 return Series(values, keys)
@@ -879,8 +890,15 @@ class DataFrameGroupBy(GroupBy):
 
     def _wrap_aggregated_output(self, output, mask):
         if len(self.groupings) > 1:
-            index = self._get_multi_index(mask)
-            result = DataFrame(output, index=index)
+            if not self.as_index:
+                result = DataFrame(output)
+                group_levels = self._get_group_levels(mask)
+                for i, (name, labels) in enumerate(group_levels):
+                    result.insert(i, name, labels)
+                result = result.consolidate()
+            else:
+                index = self._get_multi_index(mask)
+                result = DataFrame(output, index=index)
         else:
             name_list = self._get_names()
             result = DataFrame(output, index=name_list[0][1])
@@ -895,12 +913,14 @@ class DataFrameGroupBy(GroupBy):
             # XXX
             return DataFrame({})
 
+        key_names = [ping.name for ping in self.groupings]
+
         if isinstance(values[0], DataFrame):
             return self._wrap_frames(keys, values,
                                      not_indexed_same=not_indexed_same)
         else:
             if len(self.groupings) > 1:
-                keys = MultiIndex.from_tuples(keys)
+                keys = MultiIndex.from_tuples(keys, names=key_names)
 
             # obj = self._obj_with_exclusions
 
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 3874461a5..b69ec8047 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -24,6 +24,8 @@ def _indexOp(opname):
         return func(other)
     return wrapper
 
+__DEBUG__ = False
+
 class Index(np.ndarray):
     """
     Immutable ndarray implementing an ordered, sliceable set. The basic object
@@ -41,6 +43,10 @@ class Index(np.ndarray):
     An Index instance can **only** contain hashable objects
     """
     def __new__(cls, data, dtype=object, copy=False):
+        if __DEBUG__:
+            import pandas.util.testing as t
+            t.set_trace()
+
         if isinstance(data, np.ndarray):
             subarr = np.array(data, dtype=dtype, copy=copy)
         elif np.isscalar(data):
@@ -288,6 +294,7 @@ class Index(np.ndarray):
         -------
         loc : int
         """
+        self._verify_integrity()
         return self.indexMap[key]
 
     def get_indexer(self, target, method=None):
@@ -503,13 +510,19 @@ class MultiIndex(Index):
     labels : list or tuple of arrays
         Integers for each level designating which label at each location
     """
-    def __new__(cls, levels=None, labels=None, sortorder=None):
+    def __new__(cls, levels=None, labels=None, sortorder=None, names=None):
         return np.arange(len(labels[0]), dtype=object).view(cls)
 
-    def __init__(self, levels, labels, sortorder=None):
+    def __init__(self, levels, labels, sortorder=None, names=None):
         self.levels = [_ensure_index(lev) for lev in levels]
         self.labels = [np.asarray(labs, dtype=np.int32) for labs in labels]
 
+        if names is None:
+            self.names = ['level_%d' % i for i in range(self.nlevels)]
+        else:
+            assert(len(names) == self.nlevels)
+            self.names = list(names)
+
         if sortorder is not None:
             self.sortorder = int(sortorder)
         else:
@@ -576,7 +589,7 @@ class MultiIndex(Index):
         return 0
 
     @classmethod
-    def from_arrays(cls, arrays, sortorder=None):
+    def from_arrays(cls, arrays, sortorder=None, names=None):
         """
         Convert arrays to MultiIndex
 
@@ -597,10 +610,11 @@ class MultiIndex(Index):
             levels.append(factor.levels)
             labels.append(factor.labels)
 
-        return MultiIndex(levels=levels, labels=labels, sortorder=sortorder)
+        return MultiIndex(levels=levels, labels=labels, sortorder=sortorder,
+                          names=names)
 
     @classmethod
-    def from_tuples(cls, tuples, sortorder=None):
+    def from_tuples(cls, tuples, sortorder=None, names=None):
         """
         Convert list of tuples to MultiIndex
 
@@ -615,7 +629,8 @@ class MultiIndex(Index):
         index : MultiIndex
         """
         arrays = zip(*tuples)
-        return MultiIndex.from_arrays(arrays, sortorder=sortorder)
+        return MultiIndex.from_arrays(arrays, sortorder=sortorder,
+                                      names=names)
 
     @property
     def indexMap(self):
@@ -671,6 +686,7 @@ class MultiIndex(Index):
             result.levels = self.levels
             result.labels = new_labels
             result.sortorder = sortorder
+            result.names = self.names
 
             return result
 
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 8bf65afff..af0222089 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -205,8 +205,14 @@ class _DataFrameIndexer(object):
             is_int_index = _is_integer_index(self.frame.index)
 
             idx = key
-            if _is_int_like(key) and not is_int_index:
-                idx = self.frame.index[key]
+            if _is_int_like(key):
+                if isinstance(self.frame.index, MultiIndex):
+                    try:
+                        return self.frame.xs(key)
+                    except (KeyError, TypeError):
+                        pass
+                elif not is_int_index:
+                    idx = self.frame.index[key]
 
             if self.frame._is_mixed_type:
                 return self.frame.xs(idx)
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 108d5f262..fc93190f3 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -312,7 +312,7 @@ class BlockManager(object):
         return tuple(len(ax) for ax in self.axes)
 
     def _verify_integrity(self):
-        _union_block_items(self.blocks)
+        union_items = _union_block_items(self.blocks)
 
         mgr_shape = self.shape
         for block in self.blocks:
@@ -697,7 +697,11 @@ _data_types = [np.float_, np.int_]
 def form_blocks(data, axes):
     # pre-filter out items if we passed it
     items = axes[0]
-    extra_items = items - Index(data.keys())
+
+    if len(data) < len(items):
+        extra_items = items - Index(data.keys())
+    else:
+        extra_items = []
 
     # put "leftover" items in float bucket, where else?
     # generalize?
@@ -821,14 +825,29 @@ def _merge_blocks(blocks, items):
     return new_block.reindex_items_from(items)
 
 def _union_block_items(blocks):
+    tot_len = 0
+    all_items = []
+    slow = False
+    for b in blocks:
+        tot_len += len(b.items)
+        if type(b.items) != Index:
+            slow = True
+        all_items.append(b.items)
+
+    if slow:
+        the_union = _union_items_slow(all_items)
+    else:
+        the_union = _tseries.fast_unique_multiple(all_items)
+
+    if tot_len > len(the_union):
+        raise Exception('item names overlap')
+    return the_union
+
+def _union_items_slow(all_items):
     seen = None
-    for block in blocks:
-        len_before = 0 if seen is None else len(seen)
+    for items in all_items:
         if seen is None:
-            seen = block.items
+            seen = items
         else:
-            seen = seen.union(block.items)
-        if len(seen) != len_before + len(block.items):
-            raise Exception('item names overlap')
-
+            seen = seen.union(items)
     return seen
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 85e6a4fa0..06a0aae63 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -165,6 +165,9 @@ def _simple_parser(lines, colNames=None, header=0, indexCol=0,
     else:
         index = np.arange(len(content))
 
+    if len(columns) != len(zipped_content):
+        raise Exception('wrong number of columns')
+
     data = dict(izip(columns, zipped_content))
     data = _floatify(data, na_values=na_values)
     data = _convert_to_ndarrays(data)
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 0404f329f..172cff528 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1361,9 +1361,9 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         assert_frame_equal(self.tsframe, recons)
 
-        recons = DataFrame.from_csv(path, index_col=None)
-        assert(len(recons.columns) == len(self.tsframe.columns) + 1)
-
+        # not sure if this ever should have worked
+        # recons = DataFrame.from_csv(path, index_col=None)
+        # assert(len(recons.columns) == len(self.tsframe.columns) + 1)
 
         # no index
         self.tsframe.to_csv(path, index=False)
@@ -2636,7 +2636,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         for i, (lev, lab) in enumerate(zip(stacked.index.levels,
                                            stacked.index.labels)):
             values = lev.take(lab)
-            assert_almost_equal(values, deleveled['label_%d' % i])
+            assert_almost_equal(values, deleveled['level_%d' % i])
 
         self.assertRaises(Exception, self.frame.delevel)
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index d8ea2c873..7997d38f6 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -588,7 +588,7 @@ class TestGroupBy(unittest.TestCase):
 
     def test_grouping_attrs(self):
         deleveled = self.mframe.delevel()
-        grouped = deleveled.groupby(['label_0', 'label_1'])
+        grouped = deleveled.groupby(['level_0', 'level_1'])
 
         for i, ping in enumerate(grouped.groupings):
             the_counts = self.mframe.groupby(level=i).count()['A']
@@ -601,8 +601,8 @@ class TestGroupBy(unittest.TestCase):
         result0 = frame.groupby(level=0).sum()
         result1 = frame.groupby(level=1).sum()
 
-        expected0 = frame.groupby(deleveled['label_0']).sum()
-        expected1 = frame.groupby(deleveled['label_1']).sum()
+        expected0 = frame.groupby(deleveled['level_0']).sum()
+        expected1 = frame.groupby(deleveled['level_1']).sum()
 
         assert_frame_equal(result0, expected0)
         assert_frame_equal(result1, expected1)
@@ -626,10 +626,10 @@ class TestGroupBy(unittest.TestCase):
         result0 = frame.groupby(mapper0, level=0).sum()
         result1 = frame.groupby(mapper1, level=1).sum()
 
-        mapped_label0 = np.array([mapper0.get(x) for x in deleveled['label_0']])
-        mapped_label1 = np.array([mapper1.get(x) for x in deleveled['label_1']])
-        expected0 = frame.groupby(mapped_label0).sum()
-        expected1 = frame.groupby(mapped_label1).sum()
+        mapped_level0 = np.array([mapper0.get(x) for x in deleveled['level_0']])
+        mapped_level1 = np.array([mapper1.get(x) for x in deleveled['level_1']])
+        expected0 = frame.groupby(mapped_level0).sum()
+        expected1 = frame.groupby(mapped_level1).sum()
 
         assert_frame_equal(result0, expected0)
         assert_frame_equal(result1, expected1)
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index 9d3107b4e..29f188537 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -145,6 +145,18 @@ class TestMultiLevel(unittest.TestCase):
         assert_frame_equal(result, expected)
         assert_frame_equal(result, result2)
 
+    def test_getitem_int(self):
+        levels = [[0, 1], [0, 1, 2]]
+        labels = [[0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 1, 2]]
+        index = MultiIndex(levels=levels, labels=labels)
+
+        frame = DataFrame(np.random.randn(6, 2), index=index)
+
+        result = frame.ix[1]
+        expected = frame[-3:]
+        expected.index = expected.index.droplevel(0)
+        assert_frame_equal(result, expected)
+
     def test_getitem_partial(self):
         ymd = self.ymd.T
         result = ymd[2000, 2]
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 0cae721ca..b34504849 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -112,6 +112,8 @@ def assert_series_equal(left, right):
     assert(left.index.equals(right.index))
 
 def assert_frame_equal(left, right):
+    assert(isinstance(left, DataFrame))
+    assert(isinstance(right, DataFrame))
     for col, series in left.iteritems():
         assert(col in right)
         assert_series_equal(series, right[col])
