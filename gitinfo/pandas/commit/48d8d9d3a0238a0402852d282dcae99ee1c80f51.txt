commit 48d8d9d3a0238a0402852d282dcae99ee1c80f51
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jun 19 20:18:38 2012 -0400

    BUG: fix closed='left' resample bug. test coverage #1245

diff --git a/pandas/core/index.py b/pandas/core/index.py
index 927885cde..93aee0fd0 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -858,8 +858,11 @@ class Index(np.ndarray):
                 return self._join_non_unique(other, how=how,
                                              return_indexers=return_indexers)
         elif self.is_monotonic and other.is_monotonic:
-            return self._join_monotonic(other, how=how,
-                                        return_indexers=return_indexers)
+            try:
+                return self._join_monotonic(other, how=how,
+                                            return_indexers=return_indexers)
+            except TypeError:
+                pass
 
         if how == 'left':
             join_index = self
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index af6c5e4d1..736a64e48 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -401,24 +401,6 @@ class DatetimeIndex(Int64Index):
             self.offset = own_state[1]
             self.tz = own_state[2]
             np.ndarray.__setstate__(self, nd_state)
-        elif len(state) == 3:
-            # legacy format: daterange
-            offset = state[1]
-
-            if len(state) > 2:
-                tzinfo = state[2]
-            else: # pragma: no cover
-                tzinfo = None
-
-            self.offset = offset
-            self.tzinfo = tzinfo
-
-            # extract the raw datetime data, turn into datetime64
-            index_state = state[0]
-            raw_data = index_state[0][4]
-            raw_data = np.array(raw_data, dtype=_NS_DTYPE)
-            new_state = raw_data.__reduce__()
-            np.ndarray.__setstate__(self, new_state[2])
         else:  # pragma: no cover
             np.ndarray.__setstate__(self, state)
 
@@ -427,20 +409,24 @@ class DatetimeIndex(Int64Index):
             return self.union(other)
         elif isinstance(other, (DateOffset, timedelta)):
             return self._add_delta(other)
+        elif isinstance(other, np.timedelta64):
+            raise NotImplementedError
         elif com.is_integer(other):
             return self.shift(other)
-        else:
-            return Index(self.view(np.ndarray) + other)
+        else:  # pragma: no cover
+            raise TypeError(other)
 
     def __sub__(self, other):
         if isinstance(other, Index):
             return self.diff(other)
         elif isinstance(other, (DateOffset, timedelta)):
             return self._add_delta(-other)
+        elif isinstance(other, np.timedelta64):
+            raise NotImplementedError
         elif com.is_integer(other):
             return self.shift(-other)
-        else:
-            return Index(self.view(np.ndarray) - other)
+        else:  # pragma: no cover
+            raise TypeError(other)
 
     def _add_delta(self, delta):
         if isinstance(delta, (Tick, timedelta)):
@@ -510,25 +496,23 @@ class DatetimeIndex(Int64Index):
 
         if dtype == np.object_:
             return self.asobject
-        return Index.astype(self, dtype)
+        elif dtype == _INT64_DTYPE:
+            return self.asi8.copy()
+        else:  # pragma: no cover
+            raise ValueError('Cannot cast DatetimeIndex to dtype %s' % dtype)
 
     @property
     def asi8(self):
         # do not cache or you'll create a memory leak
         return self.values.view('i8')
 
-    @property
-    def asstruct(self):
-        if self._sarr_cache is None:
-            self._sarr_cache = self._get_field_sarr()
-        return self._sarr_cache
-
-    def _get_field_sarr(self):
-        utc = _utc()
-        values = self.asi8
-        if self.tz is not None and self.tz is not utc:
-            values = lib.tz_convert(values, utc, self.tz)
-        return lib.build_field_sarray(values)
+    # @property
+    # def asstruct(self):
+    #     utc = _utc()
+    #     values = self.asi8
+    #     if self.tz is not None and self.tz is not utc:
+    #         values = lib.tz_convert(values, utc, self.tz)
+    #     return lib.build_field_sarray(values)
 
     def _get_time_micros(self):
         utc = _utc()
@@ -594,6 +578,8 @@ class DatetimeIndex(Int64Index):
             return sorted_index, _as
         else:
             sorted_values = np.sort(self.values)
+            if not ascending:
+                sorted_values = sorted_values[::-1]
             return self._simple_new(sorted_values, self.name, None,
                                     self.tz)
 
@@ -709,7 +695,7 @@ class DatetimeIndex(Int64Index):
         if not isinstance(other, DatetimeIndex) and len(other) > 0:
             try:
                 other = DatetimeIndex(other)
-            except ValueError:
+            except TypeError:
                 pass
 
         this, other = self._maybe_utc_convert(other)
diff --git a/pandas/tseries/resample.py b/pandas/tseries/resample.py
index 0d9ad3157..41fac33d9 100644
--- a/pandas/tseries/resample.py
+++ b/pandas/tseries/resample.py
@@ -100,7 +100,7 @@ class TimeGrouper(CustomGrouper):
 
         # a little hack
         trimmed = False
-        if len(binner) > 2 and binner[-2] == axis[-1]:
+        if len(binner) > 2 and binner[-2] == axis[-1] and self.closed == 'right':
             binner = binner[:-1]
             trimmed = True
 
diff --git a/pandas/tseries/tests/data/daterange_073.pickle b/pandas/tseries/tests/data/daterange_073.pickle
new file mode 100644
index 000000000..0214a023e
Binary files /dev/null and b/pandas/tseries/tests/data/daterange_073.pickle differ
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index ad5b68fee..a7ccee941 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -714,6 +714,10 @@ class TestResamplePeriodIndex(unittest.TestCase):
 
         result = s.resample('10min', how='mean',closed='left', label='left')
         exp = s[1:].resample('10min', how='mean',closed='left', label='left')
+
+        ex_index = date_range(start='1/1/2012 9:30', freq='10min', periods=3)
+
+        self.assert_(result.index.equals(ex_index))
         assert_series_equal(result, exp)
 
 class TestTimeGrouper(unittest.TestCase):
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 1aca15c60..a0d863a49 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -924,6 +924,14 @@ class TestTimeSeries(unittest.TestCase):
         ex_index = DatetimeIndex(np.tile(rng.values, 3))
         self.assert_(appended.equals(ex_index))
 
+        # different index names
+        rng1 = rng.copy()
+        rng2 = rng.copy()
+        rng1.name = 'foo'
+        rng2.name = 'bar'
+        self.assert_(rng1.append(rng1).name == 'foo')
+        self.assert_(rng1.append(rng2).name is None)
+
     def test_set_dataframe_column_ns_dtype(self):
         x = DataFrame([datetime.now(), datetime.now()])
         self.assert_(x[0].dtype == object)
@@ -953,13 +961,30 @@ def _simple_ts(start, end, freq='D'):
 
 class TestDatetimeIndex(unittest.TestCase):
 
-    def test_append_nondatetimeindex(self):
+    def test_append_join_nondatetimeindex(self):
         rng = date_range('1/1/2000', periods=10)
         idx = Index(['a', 'b', 'c', 'd'])
 
         result = rng.append(idx)
         self.assert_(isinstance(result[0], Timestamp))
 
+        # it works
+        rng.join(idx, how='outer')
+
+    def test_astype(self):
+        rng = date_range('1/1/2000', periods=10)
+
+        result = rng.astype('i8')
+        self.assert_(np.array_equal(result, rng.asi8))
+
+    def test_to_period_nofreq(self):
+        idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-04'])
+        self.assertRaises(ValueError, idx.to_period)
+
+        idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-03'],
+                            freq='infer')
+        idx.to_period()
+
     def test_constructor_coverage(self):
         rng = date_range('1/1/2000', periods=10.5)
         exp = date_range('1/1/2000', periods=10)
@@ -1018,6 +1043,62 @@ class TestDatetimeIndex(unittest.TestCase):
         exp = [f(x) for x in rng]
         self.assert_(np.array_equal(result, exp))
 
+    def test_add_union(self):
+        rng = date_range('1/1/2000', periods=5)
+        rng2 = date_range('1/6/2000', periods=5)
+
+        result = rng + rng2
+        expected = rng.union(rng2)
+        self.assert_(result.equals(expected))
+
+    def test_misc_coverage(self):
+        rng = date_range('1/1/2000', periods=5)
+        result = rng.groupby(rng.day)
+        self.assert_(isinstance(result.values()[0][0], Timestamp))
+
+    def test_union_coverage(self):
+        idx = DatetimeIndex(['2000-01-03', '2000-01-01', '2000-01-02'])
+        ordered = DatetimeIndex(idx.order(), freq='infer')
+        result = ordered.union(idx)
+        self.assert_(result.equals(ordered))
+
+        result = ordered[:0].union(ordered)
+        self.assert_(result.equals(ordered))
+        self.assert_(result.freq == ordered.freq)
+
+    # def test_add_timedelta64(self):
+    #     rng = date_range('1/1/2000', periods=5)
+    #     delta = rng.values[3] - rng.values[1]
+
+    #     result = rng + delta
+    #     expected = rng + timedelta(2)
+    #     self.assert_(result.equals(expected))
+
+    def test_get_duplicates(self):
+        idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-02',
+                             '2000-01-03', '2000-01-03', '2000-01-04'])
+
+        result = idx.get_duplicates()
+        ex = DatetimeIndex(['2000-01-02', '2000-01-03'])
+        self.assert_(result.equals(ex))
+
+    def test_order(self):
+        idx = DatetimeIndex(['2000-01-04', '2000-01-01', '2000-01-02'])
+
+        ordered = idx.order()
+        self.assert_(ordered.is_monotonic)
+
+        ordered = idx.order(ascending=False)
+        self.assert_(ordered[::-1].is_monotonic)
+
+        ordered, dexer = idx.order(return_indexer=True)
+        self.assert_(ordered.is_monotonic)
+        self.assert_(np.array_equal(dexer, [1, 2, 0]))
+
+        ordered, dexer = idx.order(return_indexer=True, ascending=False)
+        self.assert_(ordered[::-1].is_monotonic)
+        self.assert_(np.array_equal(dexer, [0, 2, 1]))
+
 
 class TestLegacySupport(unittest.TestCase):
 
@@ -1119,6 +1200,15 @@ class TestLegacySupport(unittest.TestCase):
         _check_join(index[:15], obj_index[5:], how='right')
         _check_join(index[:15], obj_index[5:], how='left')
 
+    def test_unpickle_daterange(self):
+        pth, _ = os.path.split(os.path.abspath(__file__))
+        filepath = os.path.join(pth, 'data', 'daterange_073.pickle')
+
+        rng = com.load(filepath)
+        self.assert_(type(rng[0]) == datetime)
+        self.assert_(isinstance(rng.offset, offsets.BDay))
+        self.assert_(rng.values.dtype == object)
+
     def test_setops(self):
         index = self.frame.index
         obj_index = index.asobject
@@ -1290,17 +1380,26 @@ class TestLegacySupport(unittest.TestCase):
         self.assertEqual(shifted.freq, index.freq)
         self.assertEqual(shifted.freq, back.freq)
 
-    def test_shift_multiple_of_same_base(self):
-        # GH #1063
+        result = index - timedelta(1)
+        expected = index + timedelta(-1)
+        self.assert_(result.equals(expected))
+
+    def test_shift(self):
         ts = Series(np.random.randn(5),
                     index=date_range('1/1/2000', periods=5, freq='H'))
 
-        result = ts.shift(1, freq='4H')
+        result = ts.shift(1, freq='5T')
+        exp_index = ts.index.shift(1, freq='5T')
+        self.assert_(result.index.equals(exp_index))
 
+        # GH #1063, multiple of same base
+        result = ts.shift(1, freq='4H')
         exp_index = ts.index + datetools.Hour(4)
-
         self.assert_(result.index.equals(exp_index))
 
+        idx = DatetimeIndex(['2000-01-01', '2000-01-02', '2000-01-04'])
+        self.assertRaises(ValueError, idx.shift, 1)
+
     def test_setops_preserve_freq(self):
         rng = date_range('1/1/2000', '1/1/2002')
 
