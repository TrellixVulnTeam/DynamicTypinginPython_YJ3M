commit 3bed38328927d472e546e045c5b3fc3e5f2f99ba
Author: Viktor Kerkez <alefnula@gmail.com>
Date:   Tue Sep 24 22:58:08 2013 +0200

    General print statement cleanup.

diff --git a/bench/io_roundtrip.py b/bench/io_roundtrip.py
index e389481d1..fa4e0755f 100644
--- a/bench/io_roundtrip.py
+++ b/bench/io_roundtrip.py
@@ -62,8 +62,8 @@ def rountrip_archive(N, K=50, iterations=10):
     pickle_time = timeit(pickle_f, iterations) / iterations
     print('pandas (pickle) %7.4f seconds' % pickle_time)
 
-    # print 'Numpy (npz)   %7.4f seconds' % numpy_time
-    # print 'larry (HDF5)  %7.4f seconds' % larry_time
+    # print('Numpy (npz)   %7.4f seconds' % numpy_time)
+    # print('larry (HDF5)  %7.4f seconds' % larry_time)
 
     # Delete old files
     try:
diff --git a/doc/sphinxext/docscrape.py b/doc/sphinxext/docscrape.py
index a6a42ac40..9a8ac59b3 100755
--- a/doc/sphinxext/docscrape.py
+++ b/doc/sphinxext/docscrape.py
@@ -463,7 +463,7 @@ class FunctionDoc(NumpyDocString):
 
         if self._role:
             if not roles.has_key(self._role):
-                print "Warning: invalid role %s" % self._role
+                print("Warning: invalid role %s" % self._role)
             out += '.. %s:: %s\n    \n\n' % (roles.get(self._role, ''),
                                              func_name)
 
diff --git a/doc/sphinxext/ipython_console_highlighting.py b/doc/sphinxext/ipython_console_highlighting.py
index 569335311..dfb489e49 100644
--- a/doc/sphinxext/ipython_console_highlighting.py
+++ b/doc/sphinxext/ipython_console_highlighting.py
@@ -39,7 +39,7 @@ class IPythonConsoleLexer(Lexer):
       In [2]: a
       Out[2]: 'foo'
 
-      In [3]: print a
+      In [3]: print(a)
       foo
 
       In [4]: 1 / 0
diff --git a/doc/sphinxext/ipython_directive.py b/doc/sphinxext/ipython_directive.py
index f05330c37..114a3d56f 100644
--- a/doc/sphinxext/ipython_directive.py
+++ b/doc/sphinxext/ipython_directive.py
@@ -158,8 +158,8 @@ def block_parser(part, rgxin, rgxout, fmtin, fmtout):
 
                 nextline = lines[i]
                 matchout = rgxout.match(nextline)
-                # print "nextline=%s, continuation=%s, starts=%s"%(nextline,
-                # continuation, nextline.startswith(continuation))
+                # print("nextline=%s, continuation=%s, starts=%s"%(nextline,
+                # continuation, nextline.startswith(continuation)))
                 if matchout or nextline.startswith('#'):
                     break
                 elif nextline.startswith(continuation):
@@ -245,7 +245,7 @@ class EmbeddedSphinxShell(object):
 
     def process_input_line(self, line, store_history=True):
         """process the input, capturing stdout"""
-        # print "input='%s'"%self.input
+        # print("input='%s'"%self.input)
         stdout = sys.stdout
         splitter = self.IP.input_splitter
         try:
@@ -293,7 +293,7 @@ class EmbeddedSphinxShell(object):
         decorator, input, rest = data
         image_file = None
         image_directive = None
-        # print 'INPUT:', data  # dbg
+        # print('INPUT:', data)  # dbg
         is_verbatim = decorator == '@verbatim' or self.is_verbatim
         is_doctest = decorator == '@doctest' or self.is_doctest
         is_suppress = decorator == '@suppress' or self.is_suppress
@@ -361,7 +361,7 @@ class EmbeddedSphinxShell(object):
         self.cout.truncate(0)
         return (ret, input_lines, output, is_doctest, image_file,
                 image_directive)
-        # print 'OUTPUT', output  # dbg
+        # print('OUTPUT', output)  # dbg
 
     def process_output(self, data, output_prompt,
                        input_lines, output, is_doctest, image_file):
@@ -390,9 +390,9 @@ class EmbeddedSphinxShell(object):
                          'found_output="%s" and submitted output="%s"' %
                          (input_lines, found, submitted))
                     raise RuntimeError(e)
-                # print 'doctest PASSED for input_lines="%s" with
-                # found_output="%s" and submitted output="%s"'%(input_lines,
-                # found, submitted)
+                # print('''doctest PASSED for input_lines="%s" with
+                # found_output="%s" and submitted output="%s"''' % (input_lines,
+                # found, submitted))
 
     def process_comment(self, data):
         """Process data fPblock for COMMENT token."""
@@ -406,7 +406,7 @@ class EmbeddedSphinxShell(object):
         self.ensure_pyplot()
         command = ('plt.gcf().savefig("%s", bbox_inches="tight", '
                    'dpi=100)' % image_file)
-        # print 'SAVEFIG', command  # dbg
+        # print('SAVEFIG', command)  # dbg
         self.process_input_line('bookmark ipy_thisdir', store_history=False)
         self.process_input_line('cd -b ipy_savedir', store_history=False)
         self.process_input_line(command, store_history=False)
@@ -737,12 +737,12 @@ class IpythonDirective(Directive):
             lines.extend(figure.split('\n'))
             lines.append('')
 
-        # print lines
+        # print(lines)
         if len(lines) > 2:
             if debug:
-                print '\n'.join(lines)
+                print('\n'.join(lines))
             else:  # NOTE: this raises some errors, what's it for?
-                # print 'INSERTING %d lines'%len(lines)
+                # print('INSERTING %d lines' % len(lines))
                 self.state_machine.insert_input(
                     lines, self.state_machine.input_lines.source(0))
 
@@ -813,7 +813,7 @@ x.startswith  x.strip
 In [130]: url = 'http://ichart.finance.yahoo.com/table.csv?s=CROX\
    .....: &d=9&e=22&f=2009&g=d&a=1&br=8&c=2006&ignore=.csv'
 
-In [131]: print url.split('&')
+In [131]: print(url.split('&'))
 ['http://ichart.finance.yahoo.com/table.csv?s=CROX', 'd=9', 'e=22', 'f=2009', 'g=d', 'a=1', 'b=8', 'c=2006', 'ignore=.csv']
 
 In [60]: import urllib
@@ -843,12 +843,12 @@ array([[ 0.64524308,  0.59943846],
 """,
 
         r"""
-In [106]: print x
+In [106]: print(x)
 jdh
 
 In [109]: for i in range(10):
    n
-.....:     print i
+.....:     print(i)
    .....:
    .....:
 0
@@ -920,4 +920,4 @@ if __name__ == '__main__':
     if not os.path.isdir('_static'):
         os.mkdir('_static')
     test()
-    print 'All OK? Check figures in _static/'
+    print('All OK? Check figures in _static/')
diff --git a/doc/sphinxext/phantom_import.py b/doc/sphinxext/phantom_import.py
index 926641827..b69f09ea6 100755
--- a/doc/sphinxext/phantom_import.py
+++ b/doc/sphinxext/phantom_import.py
@@ -31,7 +31,7 @@ def setup(app):
 def initialize(app):
     fn = app.config.phantom_import_file
     if (fn and os.path.isfile(fn)):
-        print "[numpydoc] Phantom importing modules from", fn, "..."
+        print("[numpydoc] Phantom importing modules from", fn, "...")
         import_phantom_module(fn)
 
 #------------------------------------------------------------------------------
diff --git a/doc/sphinxext/tests/test_docscrape.py b/doc/sphinxext/tests/test_docscrape.py
index 96c9d5639..a66e4222b 100755
--- a/doc/sphinxext/tests/test_docscrape.py
+++ b/doc/sphinxext/tests/test_docscrape.py
@@ -85,13 +85,13 @@ doc_txt = '''\
   >>> mean = (1,2)
   >>> cov = [[1,0],[1,0]]
   >>> x = multivariate_normal(mean,cov,(3,3))
-  >>> print x.shape
+  >>> print(x.shape)
   (3, 3, 2)
 
   The following is probably true, given that 0.6 is roughly twice the
   standard deviation:
 
-  >>> print list( (x[0,0,:] - mean) < 0.6 )
+  >>> print(list( (x[0,0,:] - mean) < 0.6 ))
   [True, True]
 
   .. index:: random
@@ -153,7 +153,7 @@ def test_examples():
 
 def test_index():
     assert_equal(doc['index']['default'], 'random')
-    print doc['index']
+    print(doc['index'])
     assert_equal(len(doc['index']), 2)
     assert_equal(len(doc['index']['refguide']), 2)
 
@@ -247,13 +247,13 @@ Examples
 >>> mean = (1,2)
 >>> cov = [[1,0],[1,0]]
 >>> x = multivariate_normal(mean,cov,(3,3))
->>> print x.shape
+>>> print(x.shape)
 (3, 3, 2)
 
 The following is probably true, given that 0.6 is roughly twice the
 standard deviation:
 
->>> print list( (x[0,0,:] - mean) < 0.6 )
+>>> print(list( (x[0,0,:] - mean) < 0.6 ))
 [True, True]
 
 .. index:: random
@@ -351,13 +351,13 @@ definite.
 >>> mean = (1,2)
 >>> cov = [[1,0],[1,0]]
 >>> x = multivariate_normal(mean,cov,(3,3))
->>> print x.shape
+>>> print(x.shape)
 (3, 3, 2)
 
 The following is probably true, given that 0.6 is roughly twice the
 standard deviation:
 
->>> print list( (x[0,0,:] - mean) < 0.6 )
+>>> print(list( (x[0,0,:] - mean) < 0.6 ))
 [True, True]
 """)
 
diff --git a/examples/regressions.py b/examples/regressions.py
index 220316582..6351c6730 100644
--- a/examples/regressions.py
+++ b/examples/regressions.py
@@ -31,7 +31,7 @@ Y = makeSeries()
 
 model = ols(y=Y, x=X)
 
-print (model)
+print(model)
 
 #-------------------------------------------------------------------------------
 # Panel regression
@@ -48,4 +48,4 @@ panelModel = ols(y=Y, x=data, window=50)
 
 model = ols(y=Y, x=data)
 
-print (panelModel)
+print(panelModel)
diff --git a/pandas/__init__.py b/pandas/__init__.py
index c4c012d6c..ddd4cd49e 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -7,7 +7,7 @@ try:
 except Exception:  # pragma: no cover
     import sys
     e = sys.exc_info()[1]  # Py25 and Py3 current exception syntax conflict
-    print (e)
+    print(e)
     if 'No module named lib' in str(e):
         raise ImportError('C extensions not built: if you installed already '
                           'verify that you are not importing from the source '
diff --git a/pandas/core/config.py b/pandas/core/config.py
index f81958a0e..9f864e720 100644
--- a/pandas/core/config.py
+++ b/pandas/core/config.py
@@ -154,7 +154,7 @@ def _describe_option(pat='', _print_desc=True):
         s += _build_option_description(k)
 
     if _print_desc:
-        print (s)
+        print(s)
     else:
         return s
 
@@ -631,7 +631,7 @@ def pp_options_list(keys, width=80, _print=False):
         ls += pp(k, ks)
     s = '\n'.join(ls)
     if _print:
-        print (s)
+        print(s)
     else:
         return s
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 799d96f46..0fd02c2bd 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -724,9 +724,9 @@ class DataFrame(NDFrame):
 
             >>> df = DataFrame([[1, 1.0]], columns=['x', 'y'])
             >>> row = next(df.iterrows())[1]
-            >>> print row['x'].dtype
+            >>> print(row['x'].dtype)
             float64
-            >>> print df['x'].dtype
+            >>> print(df['x'].dtype)
             int64
 
         Returns
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index ce0798179..186277777 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1432,7 +1432,7 @@ class SeriesGroupBy(GroupBy):
             ret = Series(result, index=index)
 
         if not self.as_index:  # pragma: no cover
-            print ('Warning, ignoring as_index=True')
+            print('Warning, ignoring as_index=True')
 
         return ret
 
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 7b9347a82..aac8bd089 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -516,7 +516,7 @@ class TextFileReader(object):
         sep = options['delimiter']
         if (sep is None and not options['delim_whitespace']):
             if engine == 'c':
-                print ('Using Python parser to sniff delimiter')
+                print('Using Python parser to sniff delimiter')
                 engine = 'python'
         elif sep is not None and len(sep) > 1:
             # wait until regex engine integrated
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 491e090ca..42a434c00 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -503,7 +503,7 @@ class HDFStore(StringMixin):
             self._handle = h5_open(self._path, self._mode)
         except IOError as e:  # pragma: no cover
             if 'can not be written' in str(e):
-                print ('Opening %s in read-only mode' % self._path)
+                print('Opening %s in read-only mode' % self._path)
                 self._handle = h5_open(self._path, 'r')
             else:
                 raise
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index b65c35e6b..e269d14f7 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -97,7 +97,7 @@ def tquery(sql, con=None, cur=None, retry=True):
         except Exception as e:
             excName = e.__class__.__name__
             if excName == 'OperationalError':  # pragma: no cover
-                print ('Failed to commit, may need to restart interpreter')
+                print('Failed to commit, may need to restart interpreter')
             else:
                 raise
 
@@ -131,7 +131,7 @@ def uquery(sql, con=None, cur=None, retry=True, params=None):
 
         traceback.print_exc()
         if retry:
-            print ('Looks like your connection failed, reconnecting...')
+            print('Looks like your connection failed, reconnecting...')
             return uquery(sql, con, retry=False)
     return result
 
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index a79ac9d3f..35b9dfbdb 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1328,7 +1328,7 @@ class TestHDFStore(unittest.TestCase):
             recons = store.select('df')
             assert isinstance(recons, DataFrame)
 
-        print ("\nbig_table frame [%s] -> %5.2f" % (rows, time.time() - x))
+        print("\nbig_table frame [%s] -> %5.2f" % (rows, time.time() - x))
 
     def test_big_table2_frame(self):
         # this is a really big table: 1m rows x 60 float columns, 20 string, 20 datetime
@@ -1336,7 +1336,7 @@ class TestHDFStore(unittest.TestCase):
         raise nose.SkipTest('no big table2 frame')
 
         # create and write a big table
-        print ("\nbig_table2 start")
+        print("\nbig_table2 start")
         import time
         start_time = time.time()
         df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
@@ -1346,8 +1346,8 @@ class TestHDFStore(unittest.TestCase):
         for x in range(20):
             df['datetime%03d' % x] = datetime.datetime(2001, 1, 2, 0, 0)
 
-        print ("\nbig_table2 frame (creation of df) [rows->%s] -> %5.2f"
-                    % (len(df.index), time.time() - start_time))
+        print("\nbig_table2 frame (creation of df) [rows->%s] -> %5.2f"
+              % (len(df.index), time.time() - start_time))
 
         def f(chunksize):
             with ensure_clean(self.path,mode='w') as store:
@@ -1357,15 +1357,15 @@ class TestHDFStore(unittest.TestCase):
 
         for c in [10000, 50000, 250000]:
             start_time = time.time()
-            print ("big_table2 frame [chunk->%s]" % c)
+            print("big_table2 frame [chunk->%s]" % c)
             rows = f(c)
-            print ("big_table2 frame [rows->%s,chunk->%s] -> %5.2f"
-                    % (rows, c, time.time() - start_time))
+            print("big_table2 frame [rows->%s,chunk->%s] -> %5.2f"
+                  % (rows, c, time.time() - start_time))
 
     def test_big_put_frame(self):
         raise nose.SkipTest('no big put frame')
 
-        print ("\nbig_put start")
+        print("\nbig_put start")
         import time
         start_time = time.time()
         df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
@@ -1375,17 +1375,17 @@ class TestHDFStore(unittest.TestCase):
         for x in range(20):
             df['datetime%03d' % x] = datetime.datetime(2001, 1, 2, 0, 0)
 
-        print ("\nbig_put frame (creation of df) [rows->%s] -> %5.2f"
-                % (len(df.index), time.time() - start_time))
+        print("\nbig_put frame (creation of df) [rows->%s] -> %5.2f"
+              % (len(df.index), time.time() - start_time))
 
         with ensure_clean(self.path, mode='w') as store:
             start_time = time.time()
             store = HDFStore(self.path, mode='w')
             store.put('df', df)
 
-            print (df.get_dtype_counts())
-            print ("big_put frame [shape->%s] -> %5.2f"
-                    % (df.shape, time.time() - start_time))
+            print(df.get_dtype_counts())
+            print("big_put frame [shape->%s] -> %5.2f"
+                  % (df.shape, time.time() - start_time))
 
     def test_big_table_panel(self):
         raise nose.SkipTest('no big table panel')
@@ -1410,7 +1410,7 @@ class TestHDFStore(unittest.TestCase):
             recons = store.select('wp')
             assert isinstance(recons, Panel)
 
-        print ("\nbig_table panel [%s] -> %5.2f" % (rows, time.time() - x))
+        print("\nbig_table panel [%s] -> %5.2f" % (rows, time.time() - x))
 
     def test_append_diff_item_order(self):
 
diff --git a/pandas/io/wb.py b/pandas/io/wb.py
index 7c50c0b41..a585cb9ad 100644
--- a/pandas/io/wb.py
+++ b/pandas/io/wb.py
@@ -68,7 +68,7 @@ def download(country=['MX', 'CA', 'US'], indicator=['GDPPCKD', 'GDPPCKN'],
     # Warn
     if len(bad_indicators) > 0:
         print('Failed to obtain indicator(s): %s' % '; '.join(bad_indicators))
-        print ('The data may still be available for download at http://data.worldbank.org')
+        print('The data may still be available for download at http://data.worldbank.org')
     if len(bad_countries) > 0:
         print('Invalid ISO-2 codes: %s' % ' '.join(bad_countries))
     # Merge WDI series
diff --git a/pandas/stats/interface.py b/pandas/stats/interface.py
index d93eb8382..6d7bf329b 100644
--- a/pandas/stats/interface.py
+++ b/pandas/stats/interface.py
@@ -64,7 +64,7 @@ def ols(**kwargs):
 
     # Run rolling simple OLS with window of size 10.
     result = ols(y=y, x=x, window_type='rolling', window=10)
-    print result.beta
+    print(result.beta)
 
     result = ols(y=y, x=x, nw_lags=1)
 
diff --git a/pandas/stats/math.py b/pandas/stats/math.py
index 64548b90d..505415beb 100644
--- a/pandas/stats/math.py
+++ b/pandas/stats/math.py
@@ -84,9 +84,9 @@ def newey_west(m, max_lags, nobs, df, nw_overlap=False):
 
     if nw_overlap and not is_psd(Xeps):
         new_max_lags = int(np.ceil(max_lags * 1.5))
-#         print ('nw_overlap is True and newey_west generated a non positive '
-#                'semidefinite matrix, so using newey_west with max_lags of %d.'
-#                % new_max_lags)
+#         print('nw_overlap is True and newey_west generated a non positive '
+#               'semidefinite matrix, so using newey_west with max_lags of %d.'
+#               % new_max_lags)
         return newey_west(m, new_max_lags, nobs, df)
 
     return Xeps
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 2c4e4c47c..450ddac78 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -58,7 +58,7 @@ class PanelOLS(OLS):
 
     def log(self, msg):
         if self._verbose:  # pragma: no cover
-            print (msg)
+            print(msg)
 
     def _prepare_data(self):
         """Cleans and stacks input data into DataFrame objects
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 7b753f5d6..cc8f8e91b 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -9600,7 +9600,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         if not ('max' in name or 'min' in name or 'count' in name):
             df = DataFrame({'b': date_range('1/1/2001', periods=2)})
             _f = getattr(df, name)
-            print (df)
+            print(df)
             self.assertFalse(len(_f()))
 
             df['a'] = lrange(len(df))
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 4bd44fcf2..02eb4015c 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -504,9 +504,9 @@ class TestGroupBy(unittest.TestCase):
         df = DataFrame(randint(10, size=(20, 10)))
 
         def raiseException(df):
-          print ('----------------------------------------')
-          print(df.to_string())
-          raise TypeError
+            print('----------------------------------------')
+            print(df.to_string())
+            raise TypeError
 
         self.assertRaises(TypeError, df.groupby(0).agg,
                           raiseException)
diff --git a/pandas/tseries/resample.py b/pandas/tseries/resample.py
index be0c5dfad..20d42f721 100644
--- a/pandas/tseries/resample.py
+++ b/pandas/tseries/resample.py
@@ -86,7 +86,7 @@ class TimeGrouper(CustomGrouper):
             offset = to_offset(self.freq)
             if offset.n > 1:
                 if self.kind == 'period':  # pragma: no cover
-                    print ('Warning: multiple of frequency -> timestamps')
+                    print('Warning: multiple of frequency -> timestamps')
                 # Cannot have multiple of periods, convert to timestamp
                 self.kind = 'timestamp'
 
diff --git a/pandas/tseries/tools.py b/pandas/tseries/tools.py
index dd78bea38..5dda1a9b3 100644
--- a/pandas/tseries/tools.py
+++ b/pandas/tseries/tools.py
@@ -21,7 +21,7 @@ try:
         raise Exception('dateutil 2.0 incompatible with Python 2.x, you must '
                         'install version 1.5 or 2.1+!')
 except ImportError:  # pragma: no cover
-    print ('Please install python-dateutil via easy_install or some method!')
+    print('Please install python-dateutil via easy_install or some method!')
     raise  # otherwise a 2nd import won't show the message
 
 
diff --git a/scripts/bench_join.py b/scripts/bench_join.py
index 5e50e8da6..c9f247556 100644
--- a/scripts/bench_join.py
+++ b/scripts/bench_join.py
@@ -133,7 +133,7 @@ def do_left_join_frame(a, b):
 
 # a = np.array([1, 2, 3, 4, 5], dtype=np.int64)
 # b = np.array([0, 3, 5, 7, 9], dtype=np.int64)
-# print lib.inner_join_indexer(a, b)
+# print(lib.inner_join_indexer(a, b))
 
 out = np.empty((10, 120000))
 
diff --git a/scripts/git-mrb b/scripts/git-mrb
index 5b48cd9c5..c15e6dbf9 100644
--- a/scripts/git-mrb
+++ b/scripts/git-mrb
@@ -26,7 +26,7 @@ import sys
 
 def sh(cmd):
     cmd = cmd.format(**shvars)
-    print '$', cmd
+    print('$', cmd)
     check_call(cmd, shell=True)
 
 #-----------------------------------------------------------------------------
@@ -46,7 +46,7 @@ try:
 except:
     import traceback as tb
     tb.print_exc()
-    print __doc__
+    print(__doc__)
     sys.exit(1)
 
 onto = argv[1] if narg >= 2 else 'master'
@@ -65,7 +65,7 @@ sh('git fetch {remote}')
 sh('git checkout -b {branch_spec} {onto}')
 sh('git merge {remote}/{branch}')
 
-print """
+print("""
 *************************************************************
  Run test suite.  If tests pass, run the following to merge:
 
@@ -74,7 +74,7 @@ git merge {branch_spec}
 git push {upstream} {onto}
 
 *************************************************************
-""".format(**shvars)
+""".format(**shvars))
 
 ans = raw_input("Revert to master and delete temporary branch? [Y/n]: ")
 if ans.strip().lower() in ('', 'y', 'yes'):
diff --git a/scripts/groupby_test.py b/scripts/groupby_test.py
index 3425f0cd9..5acf7da75 100644
--- a/scripts/groupby_test.py
+++ b/scripts/groupby_test.py
@@ -21,15 +21,15 @@ key2 = np.array(['b', 'b', 'b', 'b', 'a', 'a', 'a', 'a' ] * k,
                 dtype=object)
 shape, labels, idicts = gp.labelize(key1, key2)
 
-print tseries.group_labels(key1)
+print(tseries.group_labels(key1))
 
-# print shape
-# print labels
-# print idicts
+# print(shape)
+# print(labels)
+# print(idicts)
 
 result = tseries.group_aggregate(values, labels, shape)
 
-print tseries.groupby_indices(key2)
+print(tseries.groupby_indices(key2))
 
 df = DataFrame({'key1' : key1,
                 'key2' : key2,
@@ -43,7 +43,7 @@ k2 = df['key2']
 
 # r2 = gp.multi_groupby(df, np.sum, k1, k2)
 
-# print result
+# print(result)
 
 gen = gp.generate_groups(df['v1'], labels, shape, axis=1,
                          factory=DataFrame)
@@ -51,8 +51,8 @@ gen = gp.generate_groups(df['v1'], labels, shape, axis=1,
 res = defaultdict(dict)
 for a, gen1 in gen:
     for b, group in gen1:
-        print a, b
-        print group
+        print(a, b)
+        print(group)
         # res[b][a] = group['values'].sum()
         res[b][a] = group.sum()
 
@@ -82,10 +82,10 @@ grouped = df.groupby(['key1', 'key2'])
 # exp = DataFrame(expd).T.stack()
 # result = grouped.sum()['C']
 
-# print 'wanted'
-# print exp
-# print 'got'
-# print result
+# print('wanted')
+# print(exp)
+# print('got')
+# print(result)
 
 # tm.N = 10000
 
diff --git a/scripts/json_manip.py b/scripts/json_manip.py
index 72d0bbb34..7ff454782 100644
--- a/scripts/json_manip.py
+++ b/scripts/json_manip.py
@@ -205,9 +205,9 @@ def denorm(queries,iterable_of_things,default=None):
         fields = []
         results = []
         for q in queries:
-            #print q
+            #print(q)
             r = Ql(q,thing)
-            #print "-- result: ", r
+            #print("-- result: ", r)
             if not r:
                 r = [default]
             if isinstance(r[0], type({})):
@@ -217,15 +217,15 @@ def denorm(queries,iterable_of_things,default=None):
 
             results.append(r)
 
-        #print results
-        #print fields
+        #print(results)
+        #print(fields)
         flist =  list(flatten(*map(iter,fields)))
 
         prod = itertools.product(*results)
         for p in prod:
             U = dict()
             for (ii,thing) in enumerate(p):
-                #print ii,thing
+                #print(ii,thing)
                 if isinstance(thing, type({})):
                     U.update(thing)
                 else:
@@ -285,7 +285,7 @@ def _Q(filter_, thing):
     T = type(thing)
     if isinstance({}, T):
         for k,v in compat.iteritems(thing):
-            #print k,v
+            #print(k,v)
             if filter_ == k:
                 if isinstance(v, type([])):
                     yield iter(v)
@@ -297,7 +297,7 @@ def _Q(filter_, thing):
 
     elif isinstance([], T):
         for k in thing:
-            #print k
+            #print(k)
             yield Q(filter_,k)
 
     else:
@@ -321,9 +321,9 @@ def Q(filter_,thing):
         return flatten(*[_Q(x,thing) for x in filter_])
     elif isinstance(filter_, type({})):
         d = dict.fromkeys(list(filter_.keys()))
-        #print d
+        #print(d)
         for k in d:
-            #print flatten(Q(k,thing))
+            #print(flatten(Q(k,thing)))
             d[k] = Q(k,thing)
 
         return d
@@ -380,32 +380,32 @@ def printout(queries,things,default=None, f=sys.stdout, **kwargs):
     fields = set(itertools.chain(*(x.keys() for x in results)))
 
     W = csv.DictWriter(f=f,fieldnames=fields,**kwargs)
-    #print "---prod---"
-    #print list(prod)
+    #print("---prod---")
+    #print(list(prod))
     W.writeheader()
     for r in results:
         W.writerow(r)
 
 
 def test_run():
-    print("\n>>> print list(Q('url',ex1))")
+    print("\n>>> print(list(Q('url',ex1)))")
     print(list(Q('url',ex1)))
     assert  list(Q('url',ex1)) == ['url1','url2','url3']
     assert Ql('url',ex1) == ['url1','url2','url3']
 
-    print("\n>>>  print list(Q(['name','id'],ex1))")
+    print("\n>>>  print(list(Q(['name','id'],ex1)))")
     print(list(Q(['name','id'],ex1)))
     assert Ql(['name','id'],ex1) == ['Gregg','hello','gbye']
 
 
-    print("\n>>> print Ql('more url',ex1)")
+    print("\n>>> print(Ql('more url',ex1))")
     print(Ql('more url',ex1))
 
 
     print("\n>>> list(Q('extensions',ex1))")
     print(list(Q('extensions',ex1)))
 
-    print("\n>>> print Ql('extensions',ex1)")
+    print("\n>>> print(Ql('extensions',ex1))")
     print(Ql('extensions',ex1))
 
     print("\n>>> printout(['name','extensions'],[ex1,], extrasaction='ignore')")
diff --git a/scripts/use_build_cache.py b/scripts/use_build_cache.py
index 361ac59e5..f8c2df2a8 100755
--- a/scripts/use_build_cache.py
+++ b/scripts/use_build_cache.py
@@ -39,7 +39,7 @@ except:
 
     args = Foo() # for 2.6, no argparse
 
-#print args.accumulate(args.integers)
+#print(args.accumulate(args.integers))
 
 shim="""
 import os
diff --git a/vb_suite/suite.py b/vb_suite/suite.py
index f3c8dfe30..57920fcbf 100644
--- a/vb_suite/suite.py
+++ b/vb_suite/suite.py
@@ -92,15 +92,15 @@ def generate_rst_files(benchmarks):
     fig_base_path = os.path.join(vb_path, 'figures')
 
     if not os.path.exists(vb_path):
-        print 'creating %s' % vb_path
+        print('creating %s' % vb_path)
         os.makedirs(vb_path)
 
     if not os.path.exists(fig_base_path):
-        print 'creating %s' % fig_base_path
+        print('creating %s' % fig_base_path)
         os.makedirs(fig_base_path)
 
     for bmk in benchmarks:
-        print 'Generating rst file for %s' % bmk.name
+        print('Generating rst file for %s' % bmk.name)
         rst_path = os.path.join(RST_BASE, 'vbench/%s.txt' % bmk.name)
 
         fig_full_path = os.path.join(fig_base_path, '%s.png' % bmk.name)
diff --git a/vb_suite/test_perf.py b/vb_suite/test_perf.py
index c1a91786a..bb3a0d123 100755
--- a/vb_suite/test_perf.py
+++ b/vb_suite/test_perf.py
@@ -216,7 +216,7 @@ def profile_comparative(benchmarks):
 
         # ARGH. reparse the repo, without discarding any commits,
         # then overwrite the previous parse results
-        # prprint ("Slaughtering kittens..." )
+        # prprint("Slaughtering kittens...")
         (repo.shas, repo.messages,
          repo.timestamps, repo.authors) = _parse_commit_log(None,REPO_PATH,
                                                                 args.base_commit)
