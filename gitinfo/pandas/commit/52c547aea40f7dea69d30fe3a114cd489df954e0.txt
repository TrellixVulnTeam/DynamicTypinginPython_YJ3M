commit 52c547aea40f7dea69d30fe3a114cd489df954e0
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Feb 2 11:25:15 2016 -0600

    STYLE: final flake8 fixes, add back check for travis-ci
    
    closes #11928
    closes #12208

diff --git a/.travis.yml b/.travis.yml
index 7dbc2fb82..565d52184 100644
--- a/.travis.yml
+++ b/.travis.yml
@@ -164,11 +164,10 @@ script:
   - echo "script"
   - ci/run_build_docs.sh
   - ci/script.sh
+  - ci/lint.sh
 # nothing here, or failed tests won't fail travis
 
 after_script:
   - ci/install_test.sh
   - source activate pandas && ci/print_versions.py
   - ci/print_skipped.py /tmp/nosetests.xml
-  - ci/lint.sh
-  - ci/lint_ok_for_now.sh
diff --git a/ci/lint.sh b/ci/lint.sh
index 97d318b48..4350ecd8b 100755
--- a/ci/lint.sh
+++ b/ci/lint.sh
@@ -4,17 +4,14 @@ echo "inside $0"
 
 source activate pandas
 
-for path in 'core'
+RET=0
+for path in 'core' 'io' 'stats' 'compat' 'sparse' 'tools' 'tseries' 'tests' 'computation' 'util'
 do
     echo "linting -> pandas/$path"
-    flake8 pandas/$path --filename '*.py' --statistics -q
+    flake8 pandas/$path --filename '*.py'
+    if [ $? -ne "0" ]; then
+        RET=1
+    fi
 done
 
-RET="$?"
-
-# we are disabling the return code for now
-# to have Travis-CI pass. When the code
-# passes linting, re-enable
-#exit "$RET"
-
-exit 0
+exit $RET
diff --git a/ci/lint_ok_for_now.sh b/ci/lint_ok_for_now.sh
deleted file mode 100755
index eba667fad..000000000
--- a/ci/lint_ok_for_now.sh
+++ /dev/null
@@ -1,20 +0,0 @@
-#!/bin/bash
-
-echo "inside $0"
-
-source activate pandas
-
-for path in 'io' 'stats' 'computation' 'tseries' 'util' 'compat' 'tools' 'sparse' 'tests'
-do
-    echo "linting [ok_for_now] -> pandas/$path"
-    flake8 pandas/$path --filename '*.py' --statistics -q
-done
-
-RET="$?"
-
-# we are disabling the return code for now
-# to have Travis-CI pass. When the code
-# passes linting, re-enable
-#exit "$RET"
-
-exit 0
diff --git a/pandas/compat/numpy_compat.py b/pandas/compat/numpy_compat.py
index f7f5da40d..e4aeb0517 100644
--- a/pandas/compat/numpy_compat.py
+++ b/pandas/compat/numpy_compat.py
@@ -19,7 +19,8 @@ _np_version_under1p10 = LooseVersion(_np_version) < '1.10'
 _np_version_under1p11 = LooseVersion(_np_version) < '1.11'
 
 if LooseVersion(_np_version) < '1.7.0':
-    raise ImportError('this version of pandas is incompatible with numpy < 1.7.0\n'
+    raise ImportError('this version of pandas is incompatible with '
+                      'numpy < 1.7.0\n'
                       'your numpy version is {0}.\n'
                       'Please upgrade numpy to >= 1.7.0 to use '
                       'this pandas version'.format(_np_version))
@@ -61,7 +62,7 @@ def np_array_datetime64_compat(arr, *args, **kwargs):
            isinstance(arr, string_and_binary_types):
             arr = [tz_replacer(s) for s in arr]
         else:
-            arr = tz_replacer(s)
+            arr = tz_replacer(arr)
 
     return np.array(arr, *args, **kwargs)
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 33c3a3638..27e932cb5 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -51,7 +51,6 @@ from pandas.tseries.period import PeriodIndex
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.tdi import TimedeltaIndex
 
-import pandas.core.algorithms as algos
 import pandas.core.base as base
 import pandas.core.common as com
 import pandas.core.format as fmt
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index fbc25e7fd..698bbcb25 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -2310,10 +2310,9 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
     except Exception:
         all_in_columns = False
 
-    if (not any_callable and not all_in_columns
-        and not any_arraylike and not any_groupers
-            and match_axis_length
-            and level is None):
+    if not any_callable and not all_in_columns and \
+       not any_arraylike and not any_groupers and \
+       match_axis_length and level is None:
         keys = [com._asarray_tuplesafe(keys)]
 
     if isinstance(level, (tuple, list)):
@@ -3695,7 +3694,7 @@ class DataFrameGroupBy(NDFrameGroupBy):
         return self._wrap_agged_blocks(data.items, list(blk))
 
 
-from pandas.tools.plotting import boxplot_frame_groupby
+from pandas.tools.plotting import boxplot_frame_groupby  # noqa
 DataFrameGroupBy.boxplot = boxplot_frame_groupby
 
 
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 6e9005395..10053d33d 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -3981,7 +3981,7 @@ def form_blocks(arrays, names, axes):
                                   klass=DatetimeTZBlock,
                                   fastpath=True,
                                   placement=[i], )
-                       for i, names, array in datetime_tz_items]
+                       for i, _, array in datetime_tz_items]
         blocks.extend(dttz_blocks)
 
     if len(bool_items):
@@ -3999,7 +3999,7 @@ def form_blocks(arrays, names, axes):
     if len(cat_items) > 0:
         cat_blocks = [make_block(array, klass=CategoricalBlock, fastpath=True,
                                  placement=[i])
-                      for i, names, array in cat_items]
+                      for i, _, array in cat_items]
         blocks.extend(cat_blocks)
 
     if len(extra_locs):
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index 05257dd0a..a31efc632 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -282,7 +282,7 @@ def _unstack_multiple(data, clocs):
             for i in range(len(clocs)):
                 val = clocs[i]
                 result = result.unstack(val)
-                clocs = [val if i > val else val - 1 for val in clocs]
+                clocs = [v if i > v else v - 1 for v in clocs]
 
             return result
 
diff --git a/pandas/sparse/panel.py b/pandas/sparse/panel.py
index 4bacaadd9..524508b82 100644
--- a/pandas/sparse/panel.py
+++ b/pandas/sparse/panel.py
@@ -520,10 +520,10 @@ def _convert_frames(frames, index, columns, fill_value=np.nan, kind='block'):
         output[item] = df
 
     if index is None:
-        all_indexes = [df.index for df in output.values()]
+        all_indexes = [x.index for x in output.values()]
         index = _get_combined_index(all_indexes)
     if columns is None:
-        all_columns = [df.columns for df in output.values()]
+        all_columns = [x.columns for x in output.values()]
         columns = _get_combined_index(all_columns)
 
     index = _ensure_index(index)
diff --git a/pandas/tests/frame/test_apply.py b/pandas/tests/frame/test_apply.py
index 818e2fb89..e68b94342 100644
--- a/pandas/tests/frame/test_apply.py
+++ b/pandas/tests/frame/test_apply.py
@@ -262,8 +262,8 @@ class TestDataFrameApply(tm.TestCase, TestData):
             return row
 
         def transform2(row):
-            if (notnull(row['C']) and row['C'].startswith('shin')
-                    and row['A'] == 'foo'):
+            if (notnull(row['C']) and row['C'].startswith('shin') and
+                    row['A'] == 'foo'):
                 row['D'] = 7
             return row
 
diff --git a/pandas/tests/frame/test_indexing.py b/pandas/tests/frame/test_indexing.py
index ff9567c8a..6077c8e6f 100644
--- a/pandas/tests/frame/test_indexing.py
+++ b/pandas/tests/frame/test_indexing.py
@@ -2178,8 +2178,8 @@ class TestDataFrameIndexing(tm.TestCase, TestData):
         def _safe_add(df):
             # only add to the numeric items
             def is_ok(s):
-                return (issubclass(s.dtype.type, (np.integer, np.floating))
-                        and s.dtype != 'uint8')
+                return (issubclass(s.dtype.type, (np.integer, np.floating)) and
+                        s.dtype != 'uint8')
 
             return DataFrame(dict([(c, s + 1) if is_ok(s) else (c, s)
                                    for c, s in compat.iteritems(df)]))
diff --git a/pandas/tests/frame/test_query_eval.py b/pandas/tests/frame/test_query_eval.py
index 52594b982..6db507f0e 100644
--- a/pandas/tests/frame/test_query_eval.py
+++ b/pandas/tests/frame/test_query_eval.py
@@ -581,8 +581,7 @@ class TestDataFrameQueryNumExprPandas(tm.TestCase):
         df = DataFrame(randn(100, len(cols)), columns=cols)
         res = df.query('a < b < c and a not in b not in c', engine=engine,
                        parser=parser)
-        ind = ((df.a < df.b) & (df.b < df.c) & ~df.b.isin(df.a) &
-               ~df.c.isin(df.b))
+        ind = (df.a < df.b) & (df.b < df.c) & ~df.b.isin(df.a) & ~df.c.isin(df.b)  # noqa
         expec = df[ind]
         assert_frame_equal(res, expec)
 
diff --git a/pandas/tests/frame/test_repr_info.py b/pandas/tests/frame/test_repr_info.py
index c5c005bee..2dda4a37e 100644
--- a/pandas/tests/frame/test_repr_info.py
+++ b/pandas/tests/frame/test_repr_info.py
@@ -328,13 +328,13 @@ class TestDataFrameReprInfoEtc(tm.TestCase, TestData):
         res = buf.getvalue().splitlines()
         self.assertTrue(re.match(r"memory usage: [^+]+$", res[-1]))
 
-        self.assertTrue(df_with_object_index.memory_usage(index=True,
-                                                          deep=True).sum()
-                        > df_with_object_index.memory_usage(index=True).sum())
+        self.assertGreater(df_with_object_index.memory_usage(index=True,
+                                                             deep=True).sum(),
+                           df_with_object_index.memory_usage(index=True).sum())
 
         df_object = pd.DataFrame({'a': ['a']})
-        self.assertTrue(df_object.memory_usage(deep=True).sum()
-                        > df_object.memory_usage().sum())
+        self.assertGreater(df_object.memory_usage(deep=True).sum(),
+                           df_object.memory_usage().sum())
 
         # Test a DataFrame with duplicate columns
         dtypes = ['int64', 'int64', 'int64', 'float64']
diff --git a/pandas/tests/frame/test_reshape.py b/pandas/tests/frame/test_reshape.py
index c0963d885..e7d64324e 100644
--- a/pandas/tests/frame/test_reshape.py
+++ b/pandas/tests/frame/test_reshape.py
@@ -10,7 +10,8 @@ from numpy import nan
 import numpy as np
 
 from pandas.compat import u
-from pandas import DataFrame, Index, Series, MultiIndex, date_range, Timedelta, Period
+from pandas import (DataFrame, Index, Series, MultiIndex, date_range,
+                    Timedelta, Period)
 import pandas as pd
 
 from pandas.util.testing import (assert_series_equal,
diff --git a/pandas/tests/test_base.py b/pandas/tests/test_base.py
index 10a5b9dbe..99f894bfd 100644
--- a/pandas/tests/test_base.py
+++ b/pandas/tests/test_base.py
@@ -332,7 +332,7 @@ class TestIndexOps(Ops):
                 self.assertTrue(result.iat[0])
                 self.assertTrue(result.iat[1])
 
-                result = None == o
+                result = None == o  # noqa
                 self.assertFalse(result.iat[0])
                 self.assertFalse(result.iat[1])
 
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 0f99d367d..c17563074 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -3858,8 +3858,8 @@ class TestGroupBy(tm.TestCase):
             np.arange(4).repeat(8), levels, ordered=True)
         exp = CategoricalIndex(expc)
         self.assert_index_equal(desc_result.index.get_level_values(0), exp)
-        exp = Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']
-                    * 4)
+        exp = Index(['count', 'mean', 'std', 'min', '25%', '50%',
+                     '75%', 'max'] * 4)
         self.assert_index_equal(desc_result.index.get_level_values(1), exp)
 
     def test_groupby_datetime_categorical(self):
@@ -3899,8 +3899,8 @@ class TestGroupBy(tm.TestCase):
             np.arange(4).repeat(8), levels, ordered=True)
         exp = CategoricalIndex(expc)
         self.assert_index_equal(desc_result.index.get_level_values(0), exp)
-        exp = Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']
-                    * 4)
+        exp = Index(['count', 'mean', 'std', 'min', '25%', '50%',
+                     '75%', 'max'] * 4)
         self.assert_index_equal(desc_result.index.get_level_values(1), exp)
 
     def test_groupby_categorical_index(self):
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index cd9f44317..9f8d67272 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -105,8 +105,8 @@ class TestMultiLevel(tm.TestCase):
         expected = Index._simple_new(
             np.array([(1.1, datetime.datetime(2011, 1, 1, tzinfo=tz), 'A'),
                       (1.2, datetime.datetime(2011, 1, 2, tzinfo=tz), 'B'),
-                      (1.3, datetime.datetime(2011, 1, 3, tzinfo=tz), 'C')]
-                     + expected_tuples), None)
+                      (1.3, datetime.datetime(2011, 1, 3, tzinfo=tz), 'C')] +
+                     expected_tuples), None)
         self.assertTrue(result.equals(expected))
 
     def test_dataframe_constructor(self):
diff --git a/pandas/tests/test_style.py b/pandas/tests/test_style.py
index b9ca3f331..9a427cb26 100644
--- a/pandas/tests/test_style.py
+++ b/pandas/tests/test_style.py
@@ -1,6 +1,13 @@
 import os
 from nose import SkipTest
 
+import copy
+import numpy as np
+import pandas as pd
+from pandas import DataFrame
+from pandas.util.testing import TestCase
+import pandas.util.testing as tm
+
 # this is a mess. Getting failures on a python 2.7 build with
 # whenever we try to import jinja, whether it's installed or not.
 # so we're explicitly skipping that one *before* we try to import
@@ -14,14 +21,6 @@ try:
 except ImportError:
     raise SkipTest("No Jinja2")
 
-import copy
-
-import numpy as np
-import pandas as pd
-from pandas import DataFrame
-from pandas.util.testing import TestCase
-import pandas.util.testing as tm
-
 
 class TestStyler(TestCase):
 
@@ -196,8 +195,8 @@ class TestStyler(TestCase):
                 expected = dict(((r, c), ['color: baz'])
                                 for r, row in enumerate(self.df.index)
                                 for c, col in enumerate(self.df.columns)
-                                if row in self.df.loc[slice_].index
-                                and col in self.df.loc[slice_].columns)
+                                if row in self.df.loc[slice_].index and
+                                col in self.df.loc[slice_].columns)
                 self.assertEqual(result, expected)
 
     def test_applymap_subset(self):
@@ -213,8 +212,8 @@ class TestStyler(TestCase):
             expected = dict(((r, c), ['foo: bar'])
                             for r, row in enumerate(self.df.index)
                             for c, col in enumerate(self.df.columns)
-                            if row in self.df.loc[slice_].index
-                            and col in self.df.loc[slice_].columns)
+                            if row in self.df.loc[slice_].index and
+                            col in self.df.loc[slice_].columns)
             self.assertEqual(result, expected)
 
     def test_empty(self):
diff --git a/pandas/tests/test_window.py b/pandas/tests/test_window.py
index 65f90c320..0b8de24a1 100644
--- a/pandas/tests/test_window.py
+++ b/pandas/tests/test_window.py
@@ -1002,32 +1002,31 @@ class TestMoments(Base):
             return (s.multiply(w).cumsum() / w.cumsum()).fillna(method='ffill')
 
         for (s, adjust, ignore_na, w) in [
-                (s0, True, False, [np.nan, (1. - alpha), 1.]),
-                (s0, True, True, [np.nan, (1. - alpha), 1.]),
-                (s0, False, False, [np.nan, (1. - alpha), alpha]),
-                (s0, False, True, [np.nan, (1. - alpha), alpha]),
-                (s1, True, False, [(1. - alpha) ** 2, np.nan, 1.]),
-                (s1, True, True, [(1. - alpha), np.nan, 1.]),
-                (s1, False, False, [(1. - alpha) ** 2, np.nan, alpha]),
-                (s1, False, True, [(1. - alpha), np.nan, alpha]),
-                (s2, True, False, [np.nan, (1. - alpha)
-                                   ** 3, np.nan, np.nan, 1., np.nan]),
-                (s2, True, True, [np.nan, (1. - alpha),
-                                  np.nan, np.nan, 1., np.nan]),
-                (s2, False, False, [np.nan, (1. - alpha)
-                                    ** 3, np.nan, np.nan, alpha, np.nan]),
-                (s2, False, True, [np.nan, (1. - alpha),
-                                   np.nan, np.nan, alpha, np.nan]),
-                (s3, True, False, [(1. - alpha)
-                                   ** 3, np.nan, (1. - alpha), 1.]),
-                (s3, True, True, [(1. - alpha) **
-                                  2, np.nan, (1. - alpha), 1.]),
-                (s3, False, False, [(1. - alpha) ** 3, np.nan,
-                                    (1. - alpha) * alpha,
-                                    alpha * ((1. - alpha) ** 2 + alpha)]),
-                (s3, False, True, [(1. - alpha) ** 2,
-                                   np.nan, (1. - alpha) * alpha, alpha]),
-        ]:
+            (s0, True, False, [np.nan, (1. - alpha), 1.]),
+            (s0, True, True, [np.nan, (1. - alpha), 1.]),
+            (s0, False, False, [np.nan, (1. - alpha), alpha]),
+            (s0, False, True, [np.nan, (1. - alpha), alpha]),
+            (s1, True, False, [(1. - alpha) ** 2, np.nan, 1.]),
+            (s1, True, True, [(1. - alpha), np.nan, 1.]),
+            (s1, False, False, [(1. - alpha) ** 2, np.nan, alpha]),
+            (s1, False, True, [(1. - alpha), np.nan, alpha]),
+            (s2, True, False, [np.nan, (1. - alpha) **
+                               3, np.nan, np.nan, 1., np.nan]),
+            (s2, True, True, [np.nan, (1. - alpha),
+                              np.nan, np.nan, 1., np.nan]),
+            (s2, False, False, [np.nan, (1. - alpha) **
+                                3, np.nan, np.nan, alpha, np.nan]),
+            (s2, False, True, [np.nan, (1. - alpha),
+                               np.nan, np.nan, alpha, np.nan]),
+            (s3, True, False, [(1. - alpha) **
+                               3, np.nan, (1. - alpha), 1.]),
+            (s3, True, True, [(1. - alpha) **
+                              2, np.nan, (1. - alpha), 1.]),
+            (s3, False, False, [(1. - alpha) ** 3, np.nan,
+                                (1. - alpha) * alpha,
+                                alpha * ((1. - alpha) ** 2 + alpha)]),
+            (s3, False, True, [(1. - alpha) ** 2,
+                               np.nan, (1. - alpha) * alpha, alpha])]:
             expected = simple_wma(s, Series(w))
             result = s.ewm(com=com, adjust=adjust, ignore_na=ignore_na).mean()
 
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index cac5d8ae3..82fdf0a3d 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -470,8 +470,7 @@ class _MergeOperation(object):
 
     def _validate_specification(self):
         # Hm, any way to make this logic less complicated??
-        if (self.on is None and self.left_on is None
-                and self.right_on is None):
+        if self.on is None and self.left_on is None and self.right_on is None:
 
             if self.left_index and self.right_index:
                 self.left_on, self.right_on = (), ()
@@ -1185,7 +1184,7 @@ def _make_concat_multiindex(indexes, keys, levels=None, names=None):
             names = list(names)
         else:
             # make sure that all of the passed indices have the same nlevels
-            if not len(set([i.nlevels for i in indexes])) == 1:
+            if not len(set([idx.nlevels for idx in indexes])) == 1:
                 raise AssertionError("Cannot concat indices that do"
                                      " not have the same number of levels")
 
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index 120a30199..8e920e0a9 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -357,8 +357,8 @@ def _convert_by(by):
     if by is None:
         by = []
     elif (np.isscalar(by) or isinstance(by, (np.ndarray, Index,
-                                             Series, Grouper))
-          or hasattr(by, '__call__')):
+                                             Series, Grouper)) or
+          hasattr(by, '__call__')):
         by = [by]
     else:
         by = list(by)
diff --git a/pandas/tools/plotting.py b/pandas/tools/plotting.py
index 8f7c0a2b1..03d9fe75d 100644
--- a/pandas/tools/plotting.py
+++ b/pandas/tools/plotting.py
@@ -108,8 +108,8 @@ def _mpl_ge_1_3_1():
         import matplotlib
         # The or v[0] == '0' is because their versioneer is
         # messed up on dev
-        return (matplotlib.__version__ >= LooseVersion('1.3.1')
-                or matplotlib.__version__[0] == '0')
+        return (matplotlib.__version__ >= LooseVersion('1.3.1') or
+                matplotlib.__version__[0] == '0')
     except ImportError:
         return False
 
@@ -117,8 +117,8 @@ def _mpl_ge_1_3_1():
 def _mpl_ge_1_4_0():
     try:
         import matplotlib
-        return (matplotlib.__version__ >= LooseVersion('1.4')
-                or matplotlib.__version__[0] == '0')
+        return (matplotlib.__version__ >= LooseVersion('1.4') or
+                matplotlib.__version__[0] == '0')
     except ImportError:
         return False
 
@@ -126,8 +126,8 @@ def _mpl_ge_1_4_0():
 def _mpl_ge_1_5_0():
     try:
         import matplotlib
-        return (matplotlib.__version__ >= LooseVersion('1.5')
-                or matplotlib.__version__[0] == '0')
+        return (matplotlib.__version__ >= LooseVersion('1.5') or
+                matplotlib.__version__[0] == '0')
     except ImportError:
         return False
 
@@ -1789,10 +1789,10 @@ class LinePlot(MPLPlot):
             ax._stacker_neg_prior[stacking_id] += values
 
     def _post_plot_logic(self, ax, data):
-        condition = (not self._use_dynamic_x()
-                     and data.index.is_all_dates
-                     and not self.subplots
-                     or (self.subplots and self.sharex))
+        condition = (not self._use_dynamic_x() and
+                     data.index.is_all_dates and
+                     not self.subplots or
+                     (self.subplots and self.sharex))
 
         index_name = self._get_index_name()
 
@@ -2186,8 +2186,8 @@ class PiePlot(MPLPlot):
             # Blank out labels for values of 0 so they don't overlap
             # with nonzero wedges
             if labels is not None:
-                blabels = [blank_labeler(label, value) for
-                           label, value in zip(labels, y)]
+                blabels = [blank_labeler(l, value) for
+                           l, value in zip(labels, y)]
             else:
                 blabels = None
             results = ax.pie(y, labels=blabels, **kwds)
@@ -2331,7 +2331,7 @@ class BoxPlot(LinePlot):
             self.maybe_color_bp(bp)
             self._return_obj = ret
 
-            labels = [l for l, y in self._iter_data()]
+            labels = [l for l, _ in self._iter_data()]
             labels = [com.pprint_thing(l) for l in labels]
             if not self.use_index:
                 labels = [com.pprint_thing(key) for key in range(len(labels))]
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index d83b0e3f2..a150e55b0 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -6,6 +6,7 @@ import warnings
 
 import numpy as np
 
+import pandas.core.algorithms as algos
 from pandas.core.algorithms import unique
 from pandas.tseries.offsets import DateOffset
 from pandas.util.decorators import cache_readonly
@@ -1100,8 +1101,6 @@ class _FrequencyInferer(object):
 
         return 'WOM-%d%s' % (week, wd)
 
-import pandas.core.algorithms as algos
-
 
 class _TimedeltaFrequencyInferer(_FrequencyInferer):
 
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index a632913fb..77aa05bc1 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -1079,9 +1079,9 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
 
     def _wrap_joined_index(self, joined, other):
         name = self.name if self.name == other.name else None
-        if (isinstance(other, DatetimeIndex)
-            and self.offset == other.offset
-                and self._can_fast_union(other)):
+        if (isinstance(other, DatetimeIndex) and
+                self.offset == other.offset and
+                self._can_fast_union(other)):
             joined = self._shallow_copy(joined)
             joined.name = name
             return joined
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 50c0a1ab7..1a666f5ed 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -13,6 +13,7 @@ import pandas.tslib as tslib
 from pandas.tslib import Timestamp, OutOfBoundsDatetime, Timedelta
 
 import functools
+import operator
 
 __all__ = ['Day', 'BusinessDay', 'BDay', 'CustomBusinessDay', 'CDay',
            'CBMonthEnd', 'CBMonthBegin',
@@ -111,8 +112,8 @@ def apply_index_wraps(func):
 
 
 def _is_normalized(dt):
-    if (dt.hour != 0 or dt.minute != 0 or dt.second != 0
-            or dt.microsecond != 0 or getattr(dt, 'nanosecond', 0) != 0):
+    if (dt.hour != 0 or dt.minute != 0 or dt.second != 0 or
+            dt.microsecond != 0 or getattr(dt, 'nanosecond', 0) != 0):
         return False
     return True
 
@@ -268,8 +269,8 @@ class DateOffset(object):
         if (self._use_relativedelta and
                 set(self.kwds).issubset(relativedelta_fast)):
 
-            months = ((self.kwds.get('years', 0) * 12
-                       + self.kwds.get('months', 0)) * self.n)
+            months = ((self.kwds.get('years', 0) * 12 +
+                       self.kwds.get('months', 0)) * self.n)
             if months:
                 shifted = tslib.shift_months(i.asi8, months)
                 i = i._shallow_copy(shifted)
@@ -321,8 +322,8 @@ class DateOffset(object):
         exclude = set(['n', 'inc', 'normalize'])
         attrs = []
         for attr in sorted(self.__dict__):
-            if ((attr == 'kwds' and len(self.kwds) == 0)
-                    or attr.startswith('_')):
+            if ((attr == 'kwds' and len(self.kwds) == 0) or
+                    attr.startswith('_')):
                 continue
             elif attr == 'kwds':
                 kwds_new = {}
@@ -2437,8 +2438,6 @@ class Easter(DateOffset):
 # ---------------------------------------------------------------------
 # Ticks
 
-import operator
-
 
 def _tick_comp(op):
     def f(self, other):
diff --git a/pandas/tseries/tdi.py b/pandas/tseries/tdi.py
index fafe13e1f..9129a1568 100644
--- a/pandas/tseries/tdi.py
+++ b/pandas/tseries/tdi.py
@@ -522,8 +522,8 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
 
     def _wrap_joined_index(self, joined, other):
         name = self.name if self.name == other.name else None
-        if (isinstance(other, TimedeltaIndex) and self.freq == other.freq
-                and self._can_fast_union(other)):
+        if (isinstance(other, TimedeltaIndex) and self.freq == other.freq and
+                self._can_fast_union(other)):
             joined = self._shallow_copy(joined, name=name)
             return joined
         else:
diff --git a/pandas/tseries/tests/test_offsets.py b/pandas/tseries/tests/test_offsets.py
index c46d21d2a..901d9f41e 100644
--- a/pandas/tseries/tests/test_offsets.py
+++ b/pandas/tseries/tests/test_offsets.py
@@ -4209,8 +4209,9 @@ class TestDST(tm.TestCase):
             self.assertTrue(timedelta(offset.kwds['days']) + tstart.date() ==
                             t.date())
             # expect the same hour of day, minute, second, ...
-            self.assertTrue(t.hour == tstart.hour and t.minute == tstart.minute
-                            and t.second == tstart.second)
+            self.assertTrue(t.hour == tstart.hour and
+                            t.minute == tstart.minute and
+                            t.second == tstart.second)
         elif offset_name in self.valid_date_offsets_singular:
             # expect the signular offset value to match between tstart and t
             datepart_offset = getattr(t, offset_name
@@ -4223,8 +4224,10 @@ class TestDST(tm.TestCase):
                                   ).tz_convert('US/Pacific'))
 
     def _make_timestamp(self, string, hrs_offset, tz):
-        offset_string = '{hrs:02d}00'.format(hrs=hrs_offset) if hrs_offset >= 0 else \
-            '-{hrs:02d}00'.format(hrs=-1 * hrs_offset)
+        if hrs_offset >= 0:
+            offset_string = '{hrs:02d}00'.format(hrs=hrs_offset)
+        else:
+            offset_string = '-{hrs:02d}00'.format(hrs=-1 * hrs_offset)
         return Timestamp(string + offset_string).tz_convert(tz)
 
     def test_fallback_plural(self):
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index b9326aa8e..c761a3564 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -1276,9 +1276,9 @@ class TestResample(tm.TestCase):
 
         s = pd.Series(np.random.randn(5),
                       index=pd.date_range('2014-10-14 23:06:23.206',
-                                          periods=3, freq='400L')
-                      | pd.date_range('2014-10-15 23:00:00',
-                                      periods=2, freq='2200L'))
+                                          periods=3, freq='400L') |
+                      pd.date_range('2014-10-15 23:00:00',
+                                    periods=2, freq='2200L'))
 
         # Ensure left closing works
         result = s.resample('2200L').mean()
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 9d8048990..5665e502b 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -2451,7 +2451,7 @@ class TestDatetimeIndex(tm.TestCase):
             self.assert_numpy_array_equal(idx.asi8, expected_i8.asi8)
 
         tm._skip_if_no_dateutil()
-        from dateutil.tz import tzoffset
+
         # Non ISO 8601 format results in dateutil.tz.tzoffset
         for freq in ['AS', 'W-SUN']:
             idx = date_range('2013/1/1 0:00:00-5:00', '2016/1/1 23:59:59-5:00',
diff --git a/pandas/tseries/tests/test_timeseries_legacy.py b/pandas/tseries/tests/test_timeseries_legacy.py
index 96a9fd677..086f23cd2 100644
--- a/pandas/tseries/tests/test_timeseries_legacy.py
+++ b/pandas/tseries/tests/test_timeseries_legacy.py
@@ -2,11 +2,8 @@
 from datetime import datetime
 import sys
 import os
-
 import nose
-
 import numpy as np
-randn = np.random.randn
 
 from pandas import (Index, Series, date_range, Timestamp,
                     DatetimeIndex, Int64Index, to_datetime)
@@ -24,6 +21,8 @@ from numpy.random import rand
 import pandas.compat as compat
 from pandas.core.datetools import BDay
 
+randn = np.random.randn
+
 
 # infortunately, too much has changed to handle these legacy pickles
 # class TestLegacySupport(unittest.TestCase):
diff --git a/pandas/tseries/tests/test_tslib.py b/pandas/tseries/tests/test_tslib.py
index 5f3f1f097..4c6ec91ad 100644
--- a/pandas/tseries/tests/test_tslib.py
+++ b/pandas/tseries/tests/test_tslib.py
@@ -29,8 +29,8 @@ class TestTimestamp(tm.TestCase):
 
         # confirm base representation is correct
         import calendar
-        self.assertEqual(calendar.timegm(base_dt.timetuple())
-                         * 1000000000, base_expected)
+        self.assertEqual(calendar.timegm(base_dt.timetuple()) * 1000000000,
+                         base_expected)
 
         tests = [(base_str, base_dt, base_expected),
                  ('2014-07-01 10:00', datetime.datetime(2014, 7, 1, 10),
@@ -89,8 +89,8 @@ class TestTimestamp(tm.TestCase):
 
         # confirm base representation is correct
         import calendar
-        self.assertEqual(calendar.timegm(base_dt.timetuple())
-                         * 1000000000, base_expected)
+        self.assertEqual(calendar.timegm(base_dt.timetuple()) * 1000000000,
+                         base_expected)
 
         tests = [(base_str, base_expected),
                  ('2014-07-01 12:00:00+02:00',
diff --git a/pandas/util/nosetester.py b/pandas/util/nosetester.py
index fdee9be20..445cb7997 100644
--- a/pandas/util/nosetester.py
+++ b/pandas/util/nosetester.py
@@ -138,7 +138,8 @@ class NoseTester(nosetester.NoseTester):
             * 'full' - fast (as above) and slow tests as in the
               'no -A' option to nosetests - this is the same as ''.
             * None or '' - run all tests.
-            * attribute_identifier - string passed directly to nosetests as '-A'.
+            * attribute_identifier - string passed directly to nosetests
+              as '-A'.
         verbose : int, optional
             Verbosity value for test outputs, in the range 1-10. Default is 1.
         extra_argv : list, optional
@@ -200,8 +201,9 @@ class NoseTester(nosetester.NoseTester):
                 # Reset the warning filters to the default state,
                 # so that running the tests is more repeatable.
                 warnings.resetwarnings()
-                # Set all warnings to 'warn', this is because the default 'once'
-                # has the bad property of possibly shadowing later warnings.
+                # Set all warnings to 'warn', this is because the default
+                # 'once' has the bad property of possibly shadowing later
+                # warnings.
                 warnings.filterwarnings('always')
                 # Force the requested warnings to raise
                 for warningtype in raise_warnings:
