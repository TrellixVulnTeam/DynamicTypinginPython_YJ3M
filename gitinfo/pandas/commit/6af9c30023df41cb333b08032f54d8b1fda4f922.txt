commit 6af9c30023df41cb333b08032f54d8b1fda4f922
Author: h-vetinari <33685575+h-vetinari@users.noreply.github.com>
Date:   Tue Nov 27 03:50:22 2018 +0100

    CLN/DEPS: Clean up post numpy bump to 1.12 (#23796)

diff --git a/README.md b/README.md
index b4dedecb4..1993b1ecb 100644
--- a/README.md
+++ b/README.md
@@ -171,7 +171,7 @@ pip install pandas
 ```
 
 ## Dependencies
-- [NumPy](https://www.numpy.org): 1.9.0 or higher
+- [NumPy](https://www.numpy.org): 1.12.0 or higher
 - [python-dateutil](https://labix.org/python-dateutil): 2.5.0 or higher
 - [pytz](https://pythonhosted.org/pytz): 2011k or higher
 
diff --git a/ci/azure/linux.yml b/ci/azure/linux.yml
index a773a06c1..7fa8a9a17 100644
--- a/ci/azure/linux.yml
+++ b/ci/azure/linux.yml
@@ -9,7 +9,7 @@ jobs:
   strategy:
     maxParallel: 11
     matrix:
-      py27_np_19:
+      py27_np_120:
         ENV_FILE: ci/deps/azure-27-compat.yaml
         CONDA_PY: "27"
         TEST_ARGS: "--skip-slow --skip-network"
diff --git a/pandas/_libs/algos_rank_helper.pxi.in b/pandas/_libs/algos_rank_helper.pxi.in
index 5ffc6dd57..5dac94394 100644
--- a/pandas/_libs/algos_rank_helper.pxi.in
+++ b/pandas/_libs/algos_rank_helper.pxi.in
@@ -102,15 +102,7 @@ def rank_1d_{{dtype}}(object in_arr, ties_method='average',
     ranks = np.empty(n, dtype='f8')
 
     {{if dtype == 'object'}}
-
-    try:
-        _as = np.lexsort(keys=order)
-    except TypeError:
-        # lexsort on object array will raise TypeError for numpy version
-        # earlier than 1.11.0. Use argsort with order argument instead.
-        _dt = [('values', 'O'), ('mask', '?')]
-        _values = np.asarray(list(zip(order[0], order[1])), dtype=_dt)
-        _as = np.argsort(_values, kind='mergesort', order=('mask', 'values'))
+    _as = np.lexsort(keys=order)
     {{else}}
     if tiebreak == TIEBREAK_FIRST:
         # need to use a stable sort here
diff --git a/pandas/_libs/lib.pyx b/pandas/_libs/lib.pyx
index ad538ff10..874206378 100644
--- a/pandas/_libs/lib.pyx
+++ b/pandas/_libs/lib.pyx
@@ -518,9 +518,7 @@ def astype_intsafe(ndarray[object] arr, new_dtype):
         bint is_datelike
         ndarray result
 
-    # on 32-bit, 1.6.2 numpy M8[ns] is a subdtype of integer, which is weird
-    is_datelike = new_dtype in ['M8[ns]', 'm8[ns]']
-
+    is_datelike = new_dtype == 'm8[ns]'
     result = np.empty(n, dtype=new_dtype)
     for i in range(n):
         val = arr[i]
diff --git a/pandas/_libs/sparse.pyx b/pandas/_libs/sparse.pyx
index 668bd0ae6..f5980998f 100644
--- a/pandas/_libs/sparse.pyx
+++ b/pandas/_libs/sparse.pyx
@@ -8,14 +8,6 @@ from numpy cimport (ndarray, uint8_t, int64_t, int32_t, int16_t, int8_t,
 cnp.import_array()
 
 
-from distutils.version import LooseVersion
-
-# numpy versioning
-_np_version = np.version.short_version
-_np_version_under1p10 = LooseVersion(_np_version) < LooseVersion('1.10')
-_np_version_under1p11 = LooseVersion(_np_version) < LooseVersion('1.11')
-
-
 # -----------------------------------------------------------------------------
 # Preamble stuff
 
diff --git a/pandas/_libs/sparse_op_helper.pxi.in b/pandas/_libs/sparse_op_helper.pxi.in
index 1f41096a3..c6621ab59 100644
--- a/pandas/_libs/sparse_op_helper.pxi.in
+++ b/pandas/_libs/sparse_op_helper.pxi.in
@@ -42,13 +42,6 @@ cdef inline sparse_t __mod__(sparse_t a, sparse_t b):
 cdef inline sparse_t __floordiv__(sparse_t a, sparse_t b):
     if b == 0:
         if sparse_t is float64_t:
-            # numpy >= 1.11 returns NaN
-            # for a // 0, rather than +-inf
-            if _np_version_under1p11:
-                if a > 0:
-                    return INF
-                elif a < 0:
-                    return -INF
             return NaN
         else:
             return 0
diff --git a/pandas/core/arrays/categorical.py b/pandas/core/arrays/categorical.py
index 6dc3a960d..24df4c7a9 100644
--- a/pandas/core/arrays/categorical.py
+++ b/pandas/core/arrays/categorical.py
@@ -98,7 +98,7 @@ def _cat_compare_op(op):
                 ret[na_mask] = False
             return ret
 
-        # Numpy-1.9 and earlier may convert a scalar to a zerodim array during
+        # Numpy < 1.13 may convert a scalar to a zerodim array during
         # comparison operation when second arg has higher priority, e.g.
         #
         #     cat[0] < cat
@@ -2038,15 +2038,7 @@ class Categorical(ExtensionArray, PandasObject):
         elif isinstance(key, slice):
             pass
 
-        # Array of True/False in Series or Categorical
-        else:
-            # There is a bug in numpy, which does not accept a Series as a
-            # indexer
-            # https://github.com/pandas-dev/pandas/issues/6168
-            # https://github.com/numpy/numpy/issues/4240 -> fixed in numpy 1.9
-            # FIXME: remove when numpy 1.9 is the lowest numpy version pandas
-            # accepts...
-            key = np.asarray(key)
+        # else: array of True/False in Series or Categorical
 
         lindexer = self.categories.get_indexer(rvalue)
         lindexer = self._maybe_coerce_indexer(lindexer)
diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index 4e784d9c8..83ee335aa 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -835,8 +835,7 @@ class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin):
     def _evaluate_compare(self, other, op):
         """
         We have been called because a comparison between
-        8 aware arrays. numpy >= 1.11 will
-        now warn about NaT comparisons
+        8 aware arrays. numpy will warn about NaT comparisons
         """
         # Called by comparison methods when comparing datetimelike
         # with datetimelike
diff --git a/pandas/core/arrays/sparse.py b/pandas/core/arrays/sparse.py
index 24e33c32d..9a5ef3b3a 100644
--- a/pandas/core/arrays/sparse.py
+++ b/pandas/core/arrays/sparse.py
@@ -1015,9 +1015,6 @@ class SparseArray(PandasObject, ExtensionArray, ExtensionOpsMixin):
                     key = np.asarray(key)
 
             if com.is_bool_indexer(key) and len(self) == len(key):
-                # TODO(numpy 1.11): Remove this asarray.
-                # Old NumPy didn't treat array-like as boolean masks.
-                key = np.asarray(key)
                 return self.take(np.arange(len(key), dtype=np.int32)[key])
             elif hasattr(key, '__len__'):
                 return self.take(key)
diff --git a/pandas/core/dtypes/cast.py b/pandas/core/dtypes/cast.py
index 3c5f88304..afe6ba45b 100644
--- a/pandas/core/dtypes/cast.py
+++ b/pandas/core/dtypes/cast.py
@@ -263,28 +263,10 @@ def maybe_promote(dtype, fill_value=np.nan):
             fill_value = np.nan
 
     # returns tuple of (dtype, fill_value)
-    if issubclass(dtype.type, (np.datetime64, np.timedelta64)):
-        # for now: refuse to upcast datetime64
-        # (this is because datetime64 will not implicitly upconvert
-        #  to object correctly as of numpy 1.6.1)
-        if isna(fill_value):
-            fill_value = iNaT
-        else:
-            if issubclass(dtype.type, np.datetime64):
-                try:
-                    fill_value = tslibs.Timestamp(fill_value).value
-                except Exception:
-                    # the proper thing to do here would probably be to upcast
-                    # to object (but numpy 1.6.1 doesn't do this properly)
-                    fill_value = iNaT
-            elif issubclass(dtype.type, np.timedelta64):
-                try:
-                    fill_value = tslibs.Timedelta(fill_value).value
-                except Exception:
-                    # as for datetimes, cannot upcast to object
-                    fill_value = iNaT
-            else:
-                fill_value = iNaT
+    if issubclass(dtype.type, np.datetime64):
+        fill_value = tslibs.Timestamp(fill_value).value
+    elif issubclass(dtype.type, np.timedelta64):
+        fill_value = tslibs.Timedelta(fill_value).value
     elif is_datetimetz(dtype):
         if isna(fill_value):
             fill_value = iNaT
diff --git a/pandas/core/dtypes/dtypes.py b/pandas/core/dtypes/dtypes.py
index bd7c6630c..fee983f96 100644
--- a/pandas/core/dtypes/dtypes.py
+++ b/pandas/core/dtypes/dtypes.py
@@ -338,12 +338,7 @@ class CategoricalDtype(PandasExtensionDtype, ExtensionDtype):
             cat_array = [cat_array]
         hashed = _combine_hash_arrays(iter(cat_array),
                                       num_items=len(cat_array))
-        if len(hashed) == 0:
-            # bug in Numpy<1.12 for length 0 arrays. Just return the correct
-            # value of 0
-            return 0
-        else:
-            return np.bitwise_xor.reduce(hashed)
+        return np.bitwise_xor.reduce(hashed)
 
     @classmethod
     def construct_array_type(cls):
diff --git a/pandas/core/indexes/datetimes.py b/pandas/core/indexes/datetimes.py
index 72bfefaf3..61e8d6344 100644
--- a/pandas/core/indexes/datetimes.py
+++ b/pandas/core/indexes/datetimes.py
@@ -415,11 +415,6 @@ class DatetimeIndex(DatetimeArray, DatelikeOps, TimelikeOps,
                 self._freq = own_state[1]
                 self._tz = timezones.tz_standardize(own_state[2])
 
-                # provide numpy < 1.7 compat
-                if nd_state[2] == 'M8[us]':
-                    new_state = np.ndarray.__reduce__(data.astype('M8[ns]'))
-                    np.ndarray.__setstate__(data, new_state[2])
-
             else:  # pragma: no cover
                 data = np.empty(state)
                 np.ndarray.__setstate__(data, state)
diff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py
index 857bf18c5..21dae455c 100644
--- a/pandas/core/internals/blocks.py
+++ b/pandas/core/internals/blocks.py
@@ -1458,11 +1458,6 @@ class Block(PandasObject):
 
         def _nanpercentile1D(values, mask, q, **kw):
             # mask is Union[ExtensionArray, ndarray]
-            # we convert to an ndarray for NumPy 1.9 compat, which didn't
-            # treat boolean-like arrays as boolean. This conversion would have
-            # been done inside ndarray.__getitem__ anyway, since values is
-            # an ndarray at this point.
-            mask = np.asarray(mask)
             values = values[~mask]
 
             if len(values) == 0:
@@ -2781,9 +2776,7 @@ class DatetimeBlock(DatetimeLikeBlockMixin, Block):
         -------
         None
         """
-        if values.dtype != _NS_DTYPE:
-            # Workaround for numpy 1.6 bug
-            values = conversion.ensure_datetime64ns(values)
+        values = conversion.ensure_datetime64ns(values, copy=False)
 
         self.values[locs] = values
 
@@ -3102,7 +3095,7 @@ def _merge_blocks(blocks, dtype=None, _can_consolidate=True):
         # FIXME: optimization potential in case all mgrs contain slices and
         # combination of those slices is a slice, too.
         new_mgr_locs = np.concatenate([b.mgr_locs.as_array for b in blocks])
-        new_values = _vstack([b.values for b in blocks], dtype)
+        new_values = np.vstack([b.values for b in blocks])
 
         argsort = np.argsort(new_mgr_locs)
         new_values = new_values[argsort]
@@ -3114,17 +3107,6 @@ def _merge_blocks(blocks, dtype=None, _can_consolidate=True):
     return blocks
 
 
-def _vstack(to_stack, dtype):
-
-    # work around NumPy 1.6 bug
-    if dtype == _NS_DTYPE or dtype == _TD_DTYPE:
-        new_values = np.vstack([x.view('i8') for x in to_stack])
-        return new_values.view(dtype)
-
-    else:
-        return np.vstack(to_stack)
-
-
 def _block2d_to_blocknd(values, placement, shape, labels, ref_items):
     """ pivot to the labels shape """
     panel_shape = (len(placement),) + shape
diff --git a/pandas/core/internals/managers.py b/pandas/core/internals/managers.py
index c3762d981..5f9860ce9 100644
--- a/pandas/core/internals/managers.py
+++ b/pandas/core/internals/managers.py
@@ -248,9 +248,6 @@ class BlockManager(PandasObject):
 
     def __setstate__(self, state):
         def unpickle_block(values, mgr_locs):
-            # numpy < 1.7 pickle compat
-            if values.dtype == 'M8[us]':
-                values = values.astype('M8[ns]')
             return make_block(values, placement=mgr_locs)
 
         if (isinstance(state, tuple) and len(state) >= 4 and
@@ -776,18 +773,6 @@ class BlockManager(PandasObject):
 
         result = np.empty(self.shape, dtype=dtype)
 
-        if result.shape[0] == 0:
-            # Workaround for numpy 1.7 bug:
-            #
-            #     >>> a = np.empty((0,10))
-            #     >>> a[slice(0,0)]
-            #     array([], shape=(0, 10), dtype=float64)
-            #     >>> a[[]]
-            #     Traceback (most recent call last):
-            #       File "<stdin>", line 1, in <module>
-            #     IndexError: index 0 is out of bounds for axis 0 with size 0
-            return result
-
         itemmask = np.zeros(self.shape[0])
 
         for blk in self.blocks:
@@ -1170,8 +1155,7 @@ class BlockManager(PandasObject):
                 blk.mgr_locs = new_mgr_locs
 
         if loc == self._blklocs.shape[0]:
-            # np.append is a lot faster (at least in numpy 1.7.1), let's use it
-            # if we can.
+            # np.append is a lot faster, let's use it if we can.
             self._blklocs = np.append(self._blklocs, 0)
             self._blknos = np.append(self._blknos, len(self.blocks))
         else:
@@ -1995,13 +1979,9 @@ def _transform_index(index, func, level=None):
 
 def _fast_count_smallints(arr):
     """Faster version of set(arr) for sequences of small numbers."""
-    if len(arr) == 0:
-        # Handle empty arr case separately: numpy 1.6 chokes on that.
-        return np.empty((0, 2), dtype=arr.dtype)
-    else:
-        counts = np.bincount(arr.astype(np.int_))
-        nz = counts.nonzero()[0]
-        return np.c_[nz, counts[nz]]
+    counts = np.bincount(arr.astype(np.int_))
+    nz = counts.nonzero()[0]
+    return np.c_[nz, counts[nz]]
 
 
 def _preprocess_slice_or_indexer(slice_or_indexer, length, allow_fill):
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index 4a863372e..8ad2a48e8 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -334,8 +334,7 @@ def _bins_to_cuts(x, bins, right=True, labels=None,
     ids = ensure_int64(bins.searchsorted(x, side=side))
 
     if include_lowest:
-        # Numpy 1.9 support: ensure this mask is a Numpy array
-        ids[np.asarray(x == bins[0])] = 1
+        ids[x == bins[0]] = 1
 
     na_mask = isna(x) | (ids == len(bins)) | (ids == 0)
     has_nas = na_mask.any()
diff --git a/pandas/io/packers.py b/pandas/io/packers.py
index cec7908f1..7fc770efb 100644
--- a/pandas/io/packers.py
+++ b/pandas/io/packers.py
@@ -250,7 +250,7 @@ c2f_dict = {'complex': np.float64,
             'complex128': np.float64,
             'complex64': np.float32}
 
-# numpy 1.6.1 compat
+# windows (32 bit) compat
 if hasattr(np, 'float128'):
     c2f_dict['complex256'] = np.float128
 
diff --git a/pandas/io/pickle.py b/pandas/io/pickle.py
index c89d1df8e..789f55a62 100644
--- a/pandas/io/pickle.py
+++ b/pandas/io/pickle.py
@@ -6,8 +6,6 @@ from numpy.lib.format import read_array, write_array
 
 from pandas.compat import PY3, BytesIO, cPickle as pkl, pickle_compat as pc
 
-from pandas.core.dtypes.common import _NS_DTYPE, is_datetime64_dtype
-
 from pandas.io.common import _get_handle, _stringify_path
 
 
@@ -200,10 +198,4 @@ def _pickle_array(arr):
 def _unpickle_array(bytes):
     arr = read_array(BytesIO(bytes))
 
-    # All datetimes should be stored as M8[ns].  When unpickling with
-    # numpy1.6, it will read these as M8[us].  So this ensures all
-    # datetime64 types are read as MS[ns]
-    if is_datetime64_dtype(arr):
-        arr = arr.view(_NS_DTYPE)
-
     return arr
diff --git a/pandas/plotting/_misc.py b/pandas/plotting/_misc.py
index aeb97a84e..dbad5a041 100644
--- a/pandas/plotting/_misc.py
+++ b/pandas/plotting/_misc.py
@@ -138,9 +138,6 @@ def scatter_matrix(frame, alpha=0.5, figsize=None, ax=None, grid=False,
 
 def _get_marker_compat(marker):
     import matplotlib.lines as mlines
-    import matplotlib as mpl
-    if mpl.__version__ < '1.1.0' and marker == '.':
-        return 'o'
     if marker not in mlines.lineMarkers:
         return 'o'
     return marker
diff --git a/pandas/tests/arrays/categorical/test_repr.py b/pandas/tests/arrays/categorical/test_repr.py
index 5f71d0148..227edf609 100644
--- a/pandas/tests/arrays/categorical/test_repr.py
+++ b/pandas/tests/arrays/categorical/test_repr.py
@@ -37,7 +37,6 @@ class TestCategoricalRepr(object):
     def test_empty_print(self):
         factor = Categorical([], ["a", "b", "c"])
         expected = ("[], Categories (3, object): [a, b, c]")
-        # hack because array_repr changed in numpy > 1.6.x
         actual = repr(factor)
         assert actual == expected
 
diff --git a/pandas/tests/dtypes/test_inference.py b/pandas/tests/dtypes/test_inference.py
index fd3222cd1..20ad39e13 100644
--- a/pandas/tests/dtypes/test_inference.py
+++ b/pandas/tests/dtypes/test_inference.py
@@ -1272,10 +1272,7 @@ def test_nan_to_nat_conversions():
     s._data = s._data.setitem(indexer=tuple([slice(8, 9)]), value=np.nan)
     assert (isna(s[8]))
 
-    # numpy < 1.7.0 is wrong
-    from distutils.version import LooseVersion
-    if LooseVersion(np.__version__) >= LooseVersion('1.7.0'):
-        assert (s[8].value == np.datetime64('NaT').astype(np.int64))
+    assert (s[8].value == np.datetime64('NaT').astype(np.int64))
 
 
 @td.skip_if_no_scipy
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index c71d5d9f9..76e92042c 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -15,7 +15,7 @@ import numpy.ma.mrecords as mrecords
 
 from pandas.core.dtypes.common import is_integer_dtype
 from pandas.compat import (lmap, long, zip, range, lrange, lzip,
-                           OrderedDict, is_platform_little_endian, PY36)
+                           OrderedDict, is_platform_little_endian, PY3, PY36)
 from pandas import compat
 from pandas import (DataFrame, Index, Series, isna,
                     MultiIndex, Timedelta, Timestamp,
@@ -164,9 +164,9 @@ class TestDataFrameConstructors(TestData):
 
     def test_constructor_rec(self):
         rec = self.frame.to_records(index=False)
-
-        # Assigning causes segfault in NumPy < 1.5.1
-        # rec.dtype.names = list(rec.dtype.names)[::-1]
+        if PY3:
+            # unicode error under PY2
+            rec.dtype.names = list(rec.dtype.names)[::-1]
 
         index = self.frame.index
 
diff --git a/pandas/tests/frame/test_operators.py b/pandas/tests/frame/test_operators.py
index bbe4914b5..88c64bf9e 100644
--- a/pandas/tests/frame/test_operators.py
+++ b/pandas/tests/frame/test_operators.py
@@ -190,7 +190,6 @@ class TestDataFrameLogicalOperators(object):
         _check_bin_op(operator.or_)
         _check_bin_op(operator.xor)
 
-        # operator.neg is deprecated in numpy >= 1.9
         _check_unary_op(operator.inv)  # TODO: belongs elsewhere
 
     def test_logical_with_nas(self):
diff --git a/pandas/tests/indexes/common.py b/pandas/tests/indexes/common.py
index 9f5885fb8..0c886b9fd 100644
--- a/pandas/tests/indexes/common.py
+++ b/pandas/tests/indexes/common.py
@@ -663,12 +663,9 @@ class Base(object):
             tm.assert_series_equal(series_a == item, Series(expected3))
 
     def test_numpy_ufuncs(self):
-        # test ufuncs of numpy 1.9.2. see:
+        # test ufuncs of numpy, see:
         # http://docs.scipy.org/doc/numpy/reference/ufuncs.html
 
-        # some functions are skipped because it may return different result
-        # for unicode input depending on numpy version
-
         for name, idx in compat.iteritems(self.indices):
             for func in [np.exp, np.exp2, np.expm1, np.log, np.log2, np.log10,
                          np.log1p, np.sqrt, np.sin, np.cos, np.tan, np.arcsin,
diff --git a/pandas/tests/indexes/multi/test_analytics.py b/pandas/tests/indexes/multi/test_analytics.py
index 05adaada0..3b40b2afe 100644
--- a/pandas/tests/indexes/multi/test_analytics.py
+++ b/pandas/tests/indexes/multi/test_analytics.py
@@ -275,12 +275,9 @@ def test_map_dictlike(idx, mapper):
     np.rad2deg
 ])
 def test_numpy_ufuncs(func):
-    # test ufuncs of numpy 1.9.2. see:
+    # test ufuncs of numpy. see:
     # http://docs.scipy.org/doc/numpy/reference/ufuncs.html
 
-    # some functions are skipped because it may return different result
-    # for unicode input depending on numpy version
-
     # copy and paste from idx fixture as pytest doesn't support
     # parameters and fixtures at the same time.
     major_axis = Index(['foo', 'bar', 'baz', 'qux'])
diff --git a/pandas/tests/indexing/test_chaining_and_caching.py b/pandas/tests/indexing/test_chaining_and_caching.py
index 8bc8cb3fb..f012c9c25 100644
--- a/pandas/tests/indexing/test_chaining_and_caching.py
+++ b/pandas/tests/indexing/test_chaining_and_caching.py
@@ -94,7 +94,6 @@ class TestChaining(object):
     def test_setitem_chained_setfault(self):
 
         # GH6026
-        # setfaults under numpy 1.7.1 (ok on 1.8)
         data = ['right', 'left', 'left', 'left', 'right', 'left', 'timeout']
         mdata = ['right', 'left', 'left', 'left', 'right', 'left', 'none']
 
diff --git a/pandas/tests/indexing/test_iloc.py b/pandas/tests/indexing/test_iloc.py
index 53d07aeef..85b06001c 100644
--- a/pandas/tests/indexing/test_iloc.py
+++ b/pandas/tests/indexing/test_iloc.py
@@ -337,7 +337,7 @@ class TestiLoc(Base):
         tm.assert_frame_equal(df, expected)
 
     def test_iloc_setitem_pandas_object(self):
-        # GH 17193, affecting old numpy (1.7 and 1.8)
+        # GH 17193
         s_orig = Series([0, 1, 2, 3])
         expected = Series([0, -1, -2, 3])
 
diff --git a/pandas/tests/io/test_pytables.py b/pandas/tests/io/test_pytables.py
index 4a68719ee..84a0e3d86 100644
--- a/pandas/tests/io/test_pytables.py
+++ b/pandas/tests/io/test_pytables.py
@@ -199,8 +199,6 @@ class TestHDFStore(Base):
     def test_long_strings(self):
 
         # GH6166
-        # unconversion of long strings was being chopped in earlier
-        # versions of numpy < 1.7.2
         df = DataFrame({'a': tm.rands_array(100, size=10)},
                        index=tm.rands_array(100, size=10))
 
diff --git a/pandas/tests/plotting/test_datetimelike.py b/pandas/tests/plotting/test_datetimelike.py
index 486563867..2e204f6d1 100644
--- a/pandas/tests/plotting/test_datetimelike.py
+++ b/pandas/tests/plotting/test_datetimelike.py
@@ -1075,7 +1075,6 @@ class TestTSPlot(TestPlotBase):
         _, ax = self.plt.subplots()
         _check_plot_works(df.plot, ax=ax)
 
-    @pytest.mark.xfail(not PY3, reason="failing on mpl 1.4.3 on PY2")
     @pytest.mark.slow
     def test_time(self):
         t = datetime(1, 1, 1, 3, 30, 0)
diff --git a/pandas/tests/plotting/test_frame.py b/pandas/tests/plotting/test_frame.py
index 25dfbaba7..f5708b24d 100644
--- a/pandas/tests/plotting/test_frame.py
+++ b/pandas/tests/plotting/test_frame.py
@@ -69,8 +69,7 @@ class TestDataFramePlots(TestPlotBase):
         self._check_axes_shape(axes, axes_num=4, layout=(4, 1))
 
         df = DataFrame({'x': [1, 2], 'y': [3, 4]})
-        # mpl >= 1.5.2 (or slightly below) throw AttributError
-        with pytest.raises((TypeError, AttributeError)):
+        with pytest.raises(AttributeError, match='Unknown property blarg'):
             df.plot.line(blarg=True)
 
         df = DataFrame(np.random.rand(10, 3),
@@ -2967,13 +2966,9 @@ class TestDataFramePlots(TestPlotBase):
     def test_rcParams_bar_colors(self):
         import matplotlib as mpl
         color_tuples = [(0.9, 0, 0, 1), (0, 0.9, 0, 1), (0, 0, 0.9, 1)]
-        try:  # mpl 1.5
-            with mpl.rc_context(
-                    rc={'axes.prop_cycle': mpl.cycler("color", color_tuples)}):
-                barplot = pd.DataFrame([[1, 2, 3]]).plot(kind="bar")
-        except (AttributeError, KeyError):  # mpl 1.4
-            with mpl.rc_context(rc={'axes.color_cycle': color_tuples}):
-                barplot = pd.DataFrame([[1, 2, 3]]).plot(kind="bar")
+        with mpl.rc_context(
+                rc={'axes.prop_cycle': mpl.cycler("color", color_tuples)}):
+            barplot = pd.DataFrame([[1, 2, 3]]).plot(kind="bar")
         assert color_tuples == [c.get_facecolor() for c in barplot.patches]
 
     @pytest.mark.parametrize('method', ['line', 'barh', 'bar'])
diff --git a/pandas/tests/plotting/test_series.py b/pandas/tests/plotting/test_series.py
index dc7082788..e6519c7db 100644
--- a/pandas/tests/plotting/test_series.py
+++ b/pandas/tests/plotting/test_series.py
@@ -767,8 +767,8 @@ class TestSeriesPlots(TestPlotBase):
             s.plot(yerr=np.arange(11))
 
         s_err = ['zzz'] * 10
-        # in mpl 1.5+ this is a TypeError
-        with pytest.raises((ValueError, TypeError)):
+        # MPL > 2.0.0 will most likely use TypeError here
+        with pytest.raises((TypeError, ValueError)):
             s.plot(yerr=s_err)
 
     @td.xfail_if_mpl_2_2
diff --git a/pandas/tests/series/test_analytics.py b/pandas/tests/series/test_analytics.py
index 0ce9f885e..89d76abaf 100644
--- a/pandas/tests/series/test_analytics.py
+++ b/pandas/tests/series/test_analytics.py
@@ -1015,12 +1015,6 @@ class TestSeriesAnalytics(object):
 
     def test_cummethods_bool(self):
         # GH 6270
-        # looks like a buggy np.maximum.accumulate for numpy 1.6.1, py 3.2
-        def cummin(x):
-            return np.minimum.accumulate(x)
-
-        def cummax(x):
-            return np.maximum.accumulate(x)
 
         a = pd.Series([False, False, False, True, True, False, False])
         b = ~a
@@ -1028,8 +1022,8 @@ class TestSeriesAnalytics(object):
         d = ~c
         methods = {'cumsum': np.cumsum,
                    'cumprod': np.cumprod,
-                   'cummin': cummin,
-                   'cummax': cummax}
+                   'cummin': np.minimum.accumulate,
+                   'cummax': np.maximum.accumulate}
         args = product((a, b, c, d), methods)
         for s, method in args:
             expected = Series(methods[method](s.values))
diff --git a/pandas/tests/test_base.py b/pandas/tests/test_base.py
index 084477d82..c7efc1efa 100644
--- a/pandas/tests/test_base.py
+++ b/pandas/tests/test_base.py
@@ -292,11 +292,10 @@ class TestIndexOps(Ops):
                 assert not result.iat[0]
                 assert not result.iat[1]
 
-                # this fails for numpy < 1.9
-                # and oddly for *some* platforms
-                # result = None != o  # noqa
-                # assert result.iat[0]
-                # assert result.iat[1]
+                result = None != o  # noqa
+                assert result.iat[0]
+                assert result.iat[1]
+
                 if (is_datetime64_dtype(o) or is_datetimetz(o)):
                     # Following DatetimeIndex (and Timestamp) convention,
                     # inequality comparisons with Series[datetime64] raise
diff --git a/pandas/tests/test_nanops.py b/pandas/tests/test_nanops.py
index 49dbccb82..e214d4c19 100644
--- a/pandas/tests/test_nanops.py
+++ b/pandas/tests/test_nanops.py
@@ -464,7 +464,6 @@ class TestnanopsDataFrame(object):
                             allow_str=False, allow_date=False,
                             allow_tdelta=False)
 
-    @td.skip_if_no("numpy", min_version="1.10.0")
     def test_nanprod(self):
         self.check_funs(nanops.nanprod, np.prod, allow_str=False,
                         allow_date=False, allow_tdelta=False,
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 6d5d07b00..c0c4e627b 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -85,7 +85,6 @@ class SafeForLongAndSparse(object):
     def test_mean(self):
         self._check_stat_op('mean', np.mean)
 
-    @td.skip_if_no("numpy", min_version="1.10.0")
     def test_prod(self):
         self._check_stat_op('prod', np.prod, skipna_alternative=np.nanprod)
 
diff --git a/pandas/tests/test_sorting.py b/pandas/tests/test_sorting.py
index 22e758a0e..333b93dbd 100644
--- a/pandas/tests/test_sorting.py
+++ b/pandas/tests/test_sorting.py
@@ -127,13 +127,6 @@ class TestSorting(object):
         # np.argsort(items2) may not place NaNs first
         items2 = np.array(items, dtype='O')
 
-        try:
-            # GH 2785; due to a regression in NumPy1.6.2
-            np.argsort(np.array([[1, 2], [1, 3], [1, 2]], dtype='i'))
-            np.argsort(items2, kind='mergesort')
-        except TypeError:
-            pytest.skip('requested sort not available for type')
-
         # mergesort is the most difficult to get right because we want it to be
         # stable.
 
