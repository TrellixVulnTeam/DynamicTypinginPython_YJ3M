commit d3ffc915bdee59658db433a4bf5a17b09d389fa6
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Tue Mar 24 12:41:34 2020 -0700

    REF: .values -> ._values (#32947)

diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 5b324bc57..9afdb8246 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -700,7 +700,7 @@ def value_counts(
         result = result.sort_index()
 
         # if we are dropna and we have NO values
-        if dropna and (result.values == 0).all():
+        if dropna and (result._values == 0).all():
             result = result.iloc[0:0]
 
         # normalizing is by len of all (regardless of dropna)
@@ -713,7 +713,7 @@ def value_counts(
             # handle Categorical and sparse,
             result = Series(values)._values.value_counts(dropna=dropna)
             result.name = name
-            counts = result.values
+            counts = result._values
 
         else:
             keys, counts = _value_counts_arraylike(values, dropna)
@@ -823,7 +823,7 @@ def mode(values, dropna: bool = True) -> "Series":
     # categorical is a fast-path
     if is_categorical_dtype(values):
         if isinstance(values, Series):
-            return Series(values.values.mode(dropna=dropna), name=values.name)
+            return Series(values._values.mode(dropna=dropna), name=values.name)
         return values.mode(dropna=dropna)
 
     if dropna and needs_i8_conversion(values.dtype):
diff --git a/pandas/core/arrays/datetimelike.py b/pandas/core/arrays/datetimelike.py
index c3e79f40e..9cde636f6 100644
--- a/pandas/core/arrays/datetimelike.py
+++ b/pandas/core/arrays/datetimelike.py
@@ -905,7 +905,7 @@ class DatetimeLikeArrayMixin(ExtensionOpsMixin, AttributesMixin, ExtensionArray)
         index = Index(
             cls(result.index.view("i8"), dtype=self.dtype), name=result.index.name
         )
-        return Series(result.values, index=index, name=result.name)
+        return Series(result._values, index=index, name=result.name)
 
     def map(self, mapper):
         # TODO(GH-23179): Add ExtensionArray.map
diff --git a/pandas/core/arrays/interval.py b/pandas/core/arrays/interval.py
index d852ea4f5..22ce5a6f8 100644
--- a/pandas/core/arrays/interval.py
+++ b/pandas/core/arrays/interval.py
@@ -152,7 +152,7 @@ class IntervalArray(IntervalMixin, ExtensionArray):
     def __new__(cls, data, closed=None, dtype=None, copy=False, verify_integrity=True):
 
         if isinstance(data, ABCSeries) and is_interval_dtype(data):
-            data = data.values
+            data = data._values
 
         if isinstance(data, (cls, ABCIntervalIndex)):
             left = data.left
diff --git a/pandas/core/arrays/masked.py b/pandas/core/arrays/masked.py
index 47892b55b..cf6c16d4c 100644
--- a/pandas/core/arrays/masked.py
+++ b/pandas/core/arrays/masked.py
@@ -244,11 +244,11 @@ class BaseMaskedArray(ExtensionArray, ExtensionOpsMixin):
         # TODO(extension)
         # if we have allow Index to hold an ExtensionArray
         # this is easier
-        index = value_counts.index.values.astype(object)
+        index = value_counts.index._values.astype(object)
 
         # if we want nans, count the mask
         if dropna:
-            counts = value_counts.values
+            counts = value_counts._values
         else:
             counts = np.empty(len(value_counts) + 1, dtype="int64")
             counts[:-1] = value_counts
diff --git a/pandas/core/base.py b/pandas/core/base.py
index 2d8a41f77..9ff0d60b9 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -656,7 +656,7 @@ class IndexOpsMixin:
         ):
             # numpy returns ints instead of datetime64/timedelta64 objects,
             #  which we need to wrap in Timestamp/Timedelta/Period regardless.
-            return self.values.item()
+            return self._values.item()
 
         if len(self) == 1:
             return next(iter(self))
@@ -1128,10 +1128,8 @@ class IndexOpsMixin:
                 # use the built in categorical series mapper which saves
                 # time by mapping the categories instead of all values
                 return self._values.map(mapper)
-            if is_extension_array_dtype(self.dtype):
-                values = self._values
-            else:
-                values = self.values
+
+            values = self._values
 
             indexer = mapper.index.get_indexer(values)
             new_values = algorithms.take_1d(mapper._values, indexer)
diff --git a/pandas/core/common.py b/pandas/core/common.py
index fd7b4fd80..4ff1a9373 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -213,7 +213,7 @@ def asarray_tuplesafe(values, dtype=None):
     if not (isinstance(values, (list, tuple)) or hasattr(values, "__array__")):
         values = list(values)
     elif isinstance(values, ABCIndexClass):
-        return values.values
+        return values._values
 
     if isinstance(values, list) and dtype in [np.object_, object]:
         return construct_1d_object_array_from_listlike(values)
diff --git a/pandas/core/dtypes/cast.py b/pandas/core/dtypes/cast.py
index 97c02428c..8173e95c9 100644
--- a/pandas/core/dtypes/cast.py
+++ b/pandas/core/dtypes/cast.py
@@ -888,7 +888,7 @@ def astype_nansafe(arr, dtype, copy: bool = True, skipna: bool = False):
         elif is_timedelta64_dtype(dtype):
             from pandas import to_timedelta
 
-            return astype_nansafe(to_timedelta(arr).values, dtype, copy=copy)
+            return astype_nansafe(to_timedelta(arr)._values, dtype, copy=copy)
 
     if dtype.name in ("datetime64", "timedelta64"):
         msg = (
diff --git a/pandas/core/dtypes/missing.py b/pandas/core/dtypes/missing.py
index 682a0722d..581067b65 100644
--- a/pandas/core/dtypes/missing.py
+++ b/pandas/core/dtypes/missing.py
@@ -229,7 +229,7 @@ def _isna_ndarraylike(obj):
     if not is_extension:
         # Avoid accessing `.values` on things like
         # PeriodIndex, which may be expensive.
-        values = getattr(obj, "values", obj)
+        values = getattr(obj, "_values", obj)
     else:
         values = obj
 
@@ -270,7 +270,7 @@ def _isna_ndarraylike(obj):
 
 
 def _isna_ndarraylike_old(obj):
-    values = getattr(obj, "values", obj)
+    values = getattr(obj, "_values", obj)
     dtype = values.dtype
 
     if is_string_dtype(dtype):
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 8c6a5c9d0..9c1cfda7d 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -7071,7 +7071,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
 
                 return Series(np.nan, index=self.columns, name=where[0])
 
-        locs = self.index.asof_locs(where, ~(nulls.values))
+        locs = self.index.asof_locs(where, ~(nulls._values))
 
         # mask the missing
         missing = locs == -1
@@ -7230,7 +7230,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
             raise ValueError("Cannot use an NA value as a clip threshold")
 
         result = self
-        mask = isna(self.values)
+        mask = isna(self._values)
 
         with np.errstate(all="ignore"):
             if upper is not None:
@@ -8604,7 +8604,7 @@ class NDFrame(PandasObject, SelectionMixin, indexing.IndexingMixin):
 
                 if self.ndim == 1:
 
-                    icond = cond.values
+                    icond = cond._values
 
                     # GH 2745 / GH 4192
                     # treat like a scalar
diff --git a/pandas/core/indexes/accessors.py b/pandas/core/indexes/accessors.py
index 8cfe1f4ac..feb9881ff 100644
--- a/pandas/core/indexes/accessors.py
+++ b/pandas/core/indexes/accessors.py
@@ -321,7 +321,7 @@ class CombinedDatetimelikeProperties(
                 orig.array,
                 name=orig.name,
                 copy=False,
-                dtype=orig.values.categories.dtype,
+                dtype=orig._values.categories.dtype,
             )
 
         if is_datetime64_dtype(data.dtype):
diff --git a/pandas/core/indexes/datetimes.py b/pandas/core/indexes/datetimes.py
index ca1995adc..ad6a36007 100644
--- a/pandas/core/indexes/datetimes.py
+++ b/pandas/core/indexes/datetimes.py
@@ -287,7 +287,7 @@ class DatetimeIndex(DatetimeTimedeltaMixin):
         """
         from pandas.io.formats.format import _is_dates_only
 
-        return _is_dates_only(self.values) and self.tz is None
+        return self.tz is None and _is_dates_only(self._values)
 
     def __reduce__(self):
 
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index f4942b72a..d5df661ef 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -1104,9 +1104,9 @@ class IntervalIndex(IntervalMixin, ExtensionIndex):
 
             # GH 19101: ensure empty results have correct dtype
             if result.empty:
-                result = result.values.astype(self.dtype.subtype)
+                result = result._values.astype(self.dtype.subtype)
             else:
-                result = result.values
+                result = result._values
 
             return type(self).from_tuples(result, closed=self.closed, name=result_name)
 
diff --git a/pandas/core/indexes/period.py b/pandas/core/indexes/period.py
index f6bf02b6d..0a906c878 100644
--- a/pandas/core/indexes/period.py
+++ b/pandas/core/indexes/period.py
@@ -312,7 +312,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index):
 
     def _mpl_repr(self):
         # how to represent ourselves to matplotlib
-        return self.astype(object).values
+        return self.astype(object)._values
 
     @property
     def _formatter_func(self):
@@ -389,7 +389,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index):
         """
         where_idx = where
         if isinstance(where_idx, DatetimeIndex):
-            where_idx = PeriodIndex(where_idx.values, freq=self.freq)
+            where_idx = PeriodIndex(where_idx._values, freq=self.freq)
         elif not isinstance(where_idx, PeriodIndex):
             raise TypeError("asof_locs `where` must be DatetimeIndex or PeriodIndex")
         elif where_idx.freq != self.freq:
diff --git a/pandas/core/ops/array_ops.py b/pandas/core/ops/array_ops.py
index c7f58d738..5dd7af454 100644
--- a/pandas/core/ops/array_ops.py
+++ b/pandas/core/ops/array_ops.py
@@ -45,7 +45,7 @@ def comp_method_OBJECT_ARRAY(op, x, y):
             y = y.astype(np.object_)
 
         if isinstance(y, (ABCSeries, ABCIndex)):
-            y = y.values
+            y = y._values
 
         if x.shape != y.shape:
             raise ValueError("Shapes must match", x.shape, y.shape)
diff --git a/pandas/core/resample.py b/pandas/core/resample.py
index f19a82ab6..a9b46a9fd 100644
--- a/pandas/core/resample.py
+++ b/pandas/core/resample.py
@@ -1596,7 +1596,7 @@ class TimeGrouper(Grouper):
 def _take_new_index(obj, indexer, new_index, axis=0):
 
     if isinstance(obj, ABCSeries):
-        new_values = algos.take_1d(obj.values, indexer)
+        new_values = algos.take_1d(obj._values, indexer)
         return obj._constructor(new_values, index=new_index, name=obj.name)
     elif isinstance(obj, ABCDataFrame):
         if axis == 1:
diff --git a/pandas/core/reshape/melt.py b/pandas/core/reshape/melt.py
index 782b80434..c3e170b0e 100644
--- a/pandas/core/reshape/melt.py
+++ b/pandas/core/reshape/melt.py
@@ -105,12 +105,12 @@ def melt(
         if is_extension_array_dtype(id_data):
             id_data = concat([id_data] * K, ignore_index=True)
         else:
-            id_data = np.tile(id_data.values, K)
+            id_data = np.tile(id_data._values, K)
         mdata[col] = id_data
 
     mcolumns = id_vars + var_name + [value_name]
 
-    mdata[value_name] = frame.values.ravel("F")
+    mdata[value_name] = frame._values.ravel("F")
     for i, col in enumerate(var_name):
         # asanyarray will keep the columns as an Index
         mdata[col] = np.asanyarray(frame.columns._get_level_values(i)).repeat(N)
@@ -170,13 +170,13 @@ def lreshape(data: DataFrame, groups, dropna: bool = True, label=None) -> DataFr
     pivot_cols = []
 
     for target, names in zip(keys, values):
-        to_concat = [data[col].values for col in names]
+        to_concat = [data[col]._values for col in names]
 
         mdata[target] = concat_compat(to_concat)
         pivot_cols.append(target)
 
     for col in id_cols:
-        mdata[col] = np.tile(data[col].values, K)
+        mdata[col] = np.tile(data[col]._values, K)
 
     if dropna:
         mask = np.ones(len(mdata[pivot_cols[0]]), dtype=bool)
diff --git a/pandas/core/reshape/merge.py b/pandas/core/reshape/merge.py
index acd4a68e3..3b3802875 100644
--- a/pandas/core/reshape/merge.py
+++ b/pandas/core/reshape/merge.py
@@ -1347,7 +1347,7 @@ def _restore_dropped_levels_multijoin(
         if isinstance(index, MultiIndex):
             return index
         else:
-            return MultiIndex.from_arrays([index.values], names=[index.name])
+            return MultiIndex.from_arrays([index._values], names=[index.name])
 
     # For multi-multi joins with one overlapping level,
     # the returned index if of type Index
@@ -1672,10 +1672,10 @@ class _AsOfMerge(_OrderedMerge):
 
         # values to compare
         left_values = (
-            self.left.index.values if self.left_index else self.left_join_keys[-1]
+            self.left.index._values if self.left_index else self.left_join_keys[-1]
         )
         right_values = (
-            self.right.index.values if self.right_index else self.right_join_keys[-1]
+            self.right.index._values if self.right_index else self.right_join_keys[-1]
         )
         tolerance = self.tolerance
 
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index a8801d8ab..b3b016633 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -456,10 +456,10 @@ def pivot(data: "DataFrame", index=None, columns=None, values=None) -> "DataFram
         if is_list_like(values) and not isinstance(values, tuple):
             # Exclude tuple because it is seen as a single column name
             indexed = data._constructor(
-                data[values].values, index=index, columns=values
+                data[values]._values, index=index, columns=values
             )
         else:
-            indexed = data._constructor_sliced(data[values].values, index=index)
+            indexed = data._constructor_sliced(data[values]._values, index=index)
     return indexed.unstack(columns)
 
 
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index 145cf4311..14c2a05e5 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -541,9 +541,9 @@ def stack(frame, level=-1, dropna=True):
         )
 
     if frame._is_homogeneous_type:
-        # For homogeneous EAs, frame.values will coerce to object. So
+        # For homogeneous EAs, frame._values will coerce to object. So
         # we concatenate instead.
-        dtypes = list(frame.dtypes.values)
+        dtypes = list(frame.dtypes._values)
         dtype = dtypes[0]
 
         if is_extension_array_dtype(dtype):
@@ -554,11 +554,11 @@ def stack(frame, level=-1, dropna=True):
             new_values = _reorder_for_extension_array_stack(new_values, N, K)
         else:
             # homogeneous, non-EA
-            new_values = frame.values.ravel()
+            new_values = frame._values.ravel()
 
     else:
         # non-homogeneous
-        new_values = frame.values.ravel()
+        new_values = frame._values.ravel()
 
     if dropna:
         mask = notna(new_values)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 1e1c9963a..dfca19b7a 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1716,7 +1716,7 @@ Name: Max Speed, dtype: float64
             level_codes[mask] = cnt = len(lev)
             lev = lev.insert(cnt, lev._na_value)
 
-        obs = level_codes[notna(self.values)]
+        obs = level_codes[notna(self._values)]
         out = np.bincount(obs, minlength=len(lev) or None)
         return self._constructor(out, index=lev, dtype="int64").__finalize__(self)
 
@@ -2718,6 +2718,7 @@ Name: Max Speed, dtype: float64
         if is_categorical_dtype(self.dtype):
             pass
         elif is_extension_array_dtype(self.dtype):
+            # TODO: can we do this for only SparseDtype?
             # The function can return something of any type, so check
             # if the type is compatible with the calling EA.
             new_values = try_cast_to_ea(self._values, new_values)
@@ -3852,7 +3853,7 @@ Name: Max Speed, dtype: float64
                 # GH#23179 some EAs do not have `map`
                 mapped = self._values.map(f)
             else:
-                values = self.astype(object).values
+                values = self.astype(object)._values
                 mapped = lib.map_infer(values, f, convert=convert_dtype)
 
         if len(mapped) and isinstance(mapped[0], Series):
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index 7f26c7a26..fb07926ab 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -205,7 +205,7 @@ def _map_object(f, arr, na_mask=False, na_value=np.nan, dtype=object):
         return np.ndarray(0, dtype=dtype)
 
     if isinstance(arr, ABCSeries):
-        arr = arr.values
+        arr = arr._values  # TODO: extract_array?
     if not isinstance(arr, np.ndarray):
         arr = np.asarray(arr, dtype=object)
     if na_mask:
@@ -2034,8 +2034,8 @@ class StringMethods(NoNewAttributesMixin):
         self._is_categorical = is_categorical_dtype(data)
         self._is_string = data.dtype.name == "string"
 
-        # .values.categories works for both Series/Index
-        self._parent = data.values.categories if self._is_categorical else data
+        # ._values.categories works for both Series/Index
+        self._parent = data._values.categories if self._is_categorical else data
         # save orig to blow up categoricals to the right type
         self._orig = data
         self._freeze()
@@ -2236,7 +2236,7 @@ class StringMethods(NoNewAttributesMixin):
         if isinstance(others, ABCSeries):
             return [others]
         elif isinstance(others, ABCIndexClass):
-            return [Series(others.values, index=others)]
+            return [Series(others._values, index=others)]
         elif isinstance(others, ABCDataFrame):
             return [others[x] for x in others]
         elif isinstance(others, np.ndarray) and others.ndim == 2:
diff --git a/pandas/core/window/common.py b/pandas/core/window/common.py
index ed0b816f6..fcde494f7 100644
--- a/pandas/core/window/common.py
+++ b/pandas/core/window/common.py
@@ -296,7 +296,7 @@ def zsqrt(x):
         mask = x < 0
 
     if isinstance(x, ABCDataFrame):
-        if mask.values.any():
+        if mask._values.any():
             result[mask] = 0
     else:
         if mask.any():
