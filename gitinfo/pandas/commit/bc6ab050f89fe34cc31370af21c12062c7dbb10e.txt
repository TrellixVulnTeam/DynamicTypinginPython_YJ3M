commit bc6ab050f89fe34cc31370af21c12062c7dbb10e
Author: MomIsBestFriend <50263213+MomIsBestFriend@users.noreply.github.com>
Date:   Wed Feb 12 18:09:00 2020 +0200

    CLN: Some code cleanups (#31792)

diff --git a/pandas/core/internals/blocks.py b/pandas/core/internals/blocks.py
index 536aa53c9..736db6b96 100644
--- a/pandas/core/internals/blocks.py
+++ b/pandas/core/internals/blocks.py
@@ -85,8 +85,6 @@ from pandas.core.indexers import (
 import pandas.core.missing as missing
 from pandas.core.nanops import nanpercentile
 
-from pandas.io.formats.printing import pprint_thing
-
 
 class Block(PandasObject):
     """
@@ -159,7 +157,8 @@ class Block(PandasObject):
 
     @property
     def _holder(self):
-        """The array-like that can hold the underlying values.
+        """
+        The array-like that can hold the underlying values.
 
         None for 'Block', overridden by subclasses that don't
         use an ndarray.
@@ -284,16 +283,11 @@ class Block(PandasObject):
         # don't want to print out all of the items here
         name = type(self).__name__
         if self._is_single_block:
-
             result = f"{name}: {len(self)} dtype: {self.dtype}"
-
         else:
 
-            shape = " x ".join(pprint_thing(s) for s in self.shape)
-            result = (
-                f"{name}: {pprint_thing(self.mgr_locs.indexer)}, "
-                f"{shape}, dtype: {self.dtype}"
-            )
+            shape = " x ".join(str(s) for s in self.shape)
+            result = f"{name}: {self.mgr_locs.indexer}, {shape}, dtype: {self.dtype}"
 
         return result
 
@@ -319,10 +313,7 @@ class Block(PandasObject):
         As of now, only supports slices that preserve dimensionality.
         """
         if new_mgr_locs is None:
-            if isinstance(slicer, tuple):
-                axis0_slicer = slicer[0]
-            else:
-                axis0_slicer = slicer
+            axis0_slicer = slicer[0] if isinstance(slicer, tuple) else slicer
             new_mgr_locs = self.mgr_locs[axis0_slicer]
 
         new_values = self._slice(slicer)
diff --git a/pandas/core/internals/concat.py b/pandas/core/internals/concat.py
index c75373b82..9fd7ff073 100644
--- a/pandas/core/internals/concat.py
+++ b/pandas/core/internals/concat.py
@@ -204,10 +204,9 @@ class JoinUnit:
                     missing_arr.fill(fill_value)
                     return missing_arr
 
-            if not self.indexers:
-                if not self.block._can_consolidate:
-                    # preserve these for validation in concat_compat
-                    return self.block.values
+            if (not self.indexers) and (not self.block._can_consolidate):
+                # preserve these for validation in concat_compat
+                return self.block.values
 
             if self.block.is_bool and not self.block.is_categorical:
                 # External code requested filling/upcasting, bool values must
@@ -372,7 +371,7 @@ def _get_empty_dtype_and_na(join_units):
     raise AssertionError(msg)
 
 
-def is_uniform_join_units(join_units):
+def is_uniform_join_units(join_units) -> bool:
     """
     Check if the join units consist of blocks of uniform type that can
     be concatenated using Block.concat_same_type instead of the generic
diff --git a/pandas/core/internals/managers.py b/pandas/core/internals/managers.py
index 08ae0b021..0ec471cf3 100644
--- a/pandas/core/internals/managers.py
+++ b/pandas/core/internals/managers.py
@@ -589,7 +589,7 @@ class BlockManager(PandasObject):
                 )
             return _compare_or_regex_search(values, s, regex)
 
-        masks = [comp(s, regex) for i, s in enumerate(src_list)]
+        masks = [comp(s, regex) for s in src_list]
 
         result_blocks = []
         src_len = len(src_list) - 1
@@ -755,10 +755,7 @@ class BlockManager(PandasObject):
             # hit in e.g. tests.io.json.test_pandas
 
             def copy_func(ax):
-                if deep == "all":
-                    return ax.copy(deep=True)
-                else:
-                    return ax.view()
+                return ax.copy(deep=True) if deep == "all" else ax.view()
 
             new_axes = [copy_func(ax) for ax in self.axes]
         else:
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 5f754aa07..0173a25b0 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -1493,11 +1493,10 @@ class ParserBase:
         # level, then our header was too long.
         for n in range(len(columns[0])):
             if all(ensure_str(col[n]) in self.unnamed_cols for col in columns):
+                header = ",".join(str(x) for x in self.header)
                 raise ParserError(
-                    "Passed header=[{header}] are too many rows for this "
-                    "multi_index of columns".format(
-                        header=",".join(str(x) for x in self.header)
-                    )
+                    f"Passed header=[{header}] are too many rows "
+                    "for this multi_index of columns"
                 )
 
         # Clean the column names (if we have an index_col).
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 570d1f9a8..ccd581428 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -3095,9 +3095,8 @@ class BlockManagerFixed(GenericFixed):
 
         self.attrs.ndim = data.ndim
         for i, ax in enumerate(data.axes):
-            if i == 0:
-                if not ax.is_unique:
-                    raise ValueError("Columns index has to be unique for fixed format")
+            if i == 0 and (not ax.is_unique):
+                raise ValueError("Columns index has to be unique for fixed format")
             self.write_index(f"axis{i}", ax)
 
         # Supporting mixed-type DataFrame objects...nontrivial
@@ -4230,7 +4229,7 @@ class AppendableTable(Table):
             chunksize = 100000
 
         rows = np.empty(min(chunksize, nrows), dtype=self.dtype)
-        chunks = int(nrows / chunksize) + 1
+        chunks = nrows // chunksize + 1
         for i in range(chunks):
             start_i = i * chunksize
             end_i = min((i + 1) * chunksize, nrows)
