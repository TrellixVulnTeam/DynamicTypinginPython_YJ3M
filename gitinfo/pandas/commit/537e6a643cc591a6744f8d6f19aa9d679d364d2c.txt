commit 537e6a643cc591a6744f8d6f19aa9d679d364d2c
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Nov 27 22:25:59 2012 -0500

    ENH: add duplicated/drop_duplicates functions to Series. close #1923

diff --git a/RELEASE.rst b/RELEASE.rst
index e9f31c092..7bcd711ca 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -34,6 +34,7 @@ pandas 0.10.0
   - Grouped histogram via `by` keyword in Series/DataFrame.hist (#2186)
   - Support optional ``min_periods`` keyword in ``corr`` and ``cov``
     for both Series and DataFrame (#2002)
+  - Add ``duplicated`` and ``drop_duplicates`` functions to Series (#1923)
 
 **API Changes**
 
@@ -74,6 +75,8 @@ pandas 0.10.0
   - pop(...) and del works with DataFrame with duplicate columns (#2349)
   - Treat empty strings as NA in date parsing (rather than let dateutil do
     something weird) (#2263)
+  - Prevent uint64 -> int64 overflows (#2355)
+  - Enable joins between MultiIndex and regular Index (#2024)
 
 pandas 0.9.1
 ============
diff --git a/pandas/core/series.py b/pandas/core/series.py
index c7a61f67c..4f840ef1a 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1248,6 +1248,39 @@ copy : boolean, default False
         """
         return len(self.value_counts())
 
+    def drop_duplicates(self, take_last=False):
+        """
+        Return Series with duplicate values removed
+
+        Parameters
+        ----------
+        take_last : boolean, default False
+            Take the last observed index in a group. Default first
+
+        Returns
+        -------
+        deduplicated : Series
+        """
+        duplicated = self.duplicated(take_last=take_last)
+        return self[-duplicated]
+
+    def duplicated(self, take_last=False):
+        """
+        Return boolean Series denoting duplicate values
+
+        Parameters
+        ----------
+        take_last : boolean, default False
+            Take the last observed index in a group. Default first
+
+        Returns
+        -------
+        duplicated : Series
+        """
+        keys = com._ensure_object(self.values)
+        duplicated = lib.duplicated(keys, take_last=take_last)
+        return Series(duplicated, index=self.index, name=self.name)
+
     sum = _make_stat_func(nanops.nansum, 'sum', 'sum')
     mean = _make_stat_func(nanops.nanmean, 'mean', 'mean')
     median = _make_stat_func(nanops.nanmedian, 'median', 'median', extras='')
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index c34e4bb12..401cc45cb 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -2036,6 +2036,25 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         expected = np.array([1, 2, 3, None], dtype=object)
         self.assert_(np.array_equal(result, expected))
 
+    def test_drop_duplicates(self):
+        s = Series([1, 2, 3, 3])
+
+        result = s.duplicated()
+        expected = Series([False, False, False, True])
+        assert_series_equal(result, expected)
+
+        result = s.duplicated(take_last=True)
+        expected = Series([False, False, True, False])
+        assert_series_equal(result, expected)
+
+        result = s.drop_duplicates()
+        expected = s[[True, True, True, False]]
+        assert_series_equal(result, expected)
+
+        result = s.drop_duplicates(take_last=True)
+        expected = s[[True, True, False, True]]
+        assert_series_equal(result, expected)
+
     def test_sort(self):
         ts = self.ts.copy()
         ts.sort()
diff --git a/vb_suite/reindex.py b/vb_suite/reindex.py
index 589ba1667..ece1e6c15 100644
--- a/vb_suite/reindex.py
+++ b/vb_suite/reindex.py
@@ -164,6 +164,18 @@ frame_drop_dup_na_inplace = Benchmark(statement2, setup,
                                   name='frame_drop_dup_na_inplace',
                                   start_date=datetime(2012, 5, 16))
 
+setup = common_setup + """
+s = Series(np.random.randint(0, 1000, size=10000))
+s2 = Series(np.tile([rands(10) for i in xrange(1000)], 10))
+"""
+
+series_drop_duplicates_int = Benchmark('s.drop_duplicates()', setup,
+                                       start_date=datetime(2012, 11, 27))
+
+series_drop_duplicates_string = \
+    Benchmark('s2.drop_duplicates()', setup,
+              start_date=datetime(2012, 11, 27))
+
 #----------------------------------------------------------------------
 # fillna, many columns
 
