commit 7d636b015c7ebc97265941ca45e73a09af9a2a5c
Author: jreback <jeff@reback.net>
Date:   Thu Aug 22 16:54:01 2013 -0400

    BUG/API: (GH4584) to_hdf was raising when passing both arguments append and table

diff --git a/doc/source/release.rst b/doc/source/release.rst
index 261bbd424..8400dab2a 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -200,6 +200,7 @@ See :ref:`Internal Refactoring<whatsnew_0130.refactoring>`
       with a different block ordering (:issue:`4096`)
     - ``read_hdf`` was not respecting as passed ``mode`` (:issue:`4504`)
     - appending a 0-len table will work correctly (:issue:`4273`)
+    - ``to_hdf`` was raising when passing both arguments ``append`` and ``table`` (:issue:`4584`)
   - Fixed bug in tslib.tz_convert(vals, tz1, tz2): it could raise IndexError exception while
     trying to access trans[pos + 1] (:issue:`4496`)
   - The ``by`` argument now works correctly with the ``layout`` argument
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 608bbe470..4064f97ae 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -690,7 +690,7 @@ class HDFStore(StringMixin):
                 raise ValueError('can only remove with where on objects written as tables')
             return s.delete(where = where, start=start, stop=stop)
 
-    def append(self, key, value, columns=None, **kwargs):
+    def append(self, key, value, columns=None, append=True, **kwargs):
         """
         Append to Table in file. Node must already exist and be Table
         format.
@@ -699,6 +699,7 @@ class HDFStore(StringMixin):
         ----------
         key : object
         value : {Series, DataFrame, Panel, Panel4D}
+        append   : boolean, default True, append the input data to the existing
         data_columns : list of columns to create as data columns, or True to use all columns
         min_itemsize : dict of columns that specify minimum string sizes
         nan_rep      : string to use as string nan represenation
@@ -714,7 +715,8 @@ class HDFStore(StringMixin):
         if columns is not None:
             raise Exception("columns is not a supported keyword in append, try data_columns")
 
-        self._write_to_group(key, value, table=True, append=True, **kwargs)
+        kwargs['table'] = True
+        self._write_to_group(key, value, append=append, **kwargs)
 
     def append_to_multiple(self, d, value, selector, data_columns=None, axes=None, **kwargs):
         """
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index cfe162c88..0de509601 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -147,6 +147,40 @@ class TestHDFStore(unittest.TestCase):
         finally:
             safe_remove(self.path)
 
+    def test_api(self):
+
+        # GH4584
+        # API issue when to_hdf doesn't acdept append AND table args
+        with tm.ensure_clean(self.path) as path:
+
+            df = tm.makeDataFrame()
+            df.iloc[:10].to_hdf(path,'df',append=True,table=True)
+            df.iloc[10:].to_hdf(path,'df',append=True,table=True)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            # append to False
+            df.iloc[:10].to_hdf(path,'df',append=False,table=True)
+            df.iloc[10:].to_hdf(path,'df',append=True,table=True)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+        with tm.ensure_clean(self.path) as path:
+
+            df = tm.makeDataFrame()
+            df.to_hdf(path,'df',append=False,table=False)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+        with ensure_clean(self.path) as store:
+
+            df = tm.makeDataFrame()
+            store.append('df',df.iloc[:10],append=True,table=True)
+            store.append('df',df.iloc[10:],append=True,table=True)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
+            # append to False
+            store.append('df',df.iloc[:10],append=False,table=True)
+            store.append('df',df.iloc[10:],append=True,table=True)
+            assert_frame_equal(read_hdf(path,'df'),df)
+
     def test_keys(self):
 
         with ensure_clean(self.path) as store:
