commit ddab99ff0e047dcaf27b204652d1e31b9de6b0ab
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Nov 17 13:29:53 2012 -0500

    BLD: fix build after renaming files to tokenizer*

diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
index f685bfb17..e0dc32c7e 100644
--- a/pandas/src/parser.pyx
+++ b/pandas/src/parser.pyx
@@ -66,7 +66,7 @@ try:
 except NameError:
     basestring = str
 
-cdef extern from "parser/parser.h":
+cdef extern from "parser/tokenizer.h":
 
     ctypedef enum ParserState:
         START_RECORD
diff --git a/pandas/src/parser/io.h b/pandas/src/parser/io.h
index 3fa25ce94..f5831ad99 100644
--- a/pandas/src/parser/io.h
+++ b/pandas/src/parser/io.h
@@ -1,5 +1,5 @@
 #include "Python.h"
-#include "parser.h"
+#include "tokenizer.h"
 
 
 typedef struct _file_source {
diff --git a/pandas/src/parser/tokenizer.c b/pandas/src/parser/tokenizer.c
index 00cf4779d..48cc193d4 100644
--- a/pandas/src/parser/tokenizer.c
+++ b/pandas/src/parser/tokenizer.c
@@ -14,7 +14,7 @@ n   Low-level ascii-file processing for pandas. Combines some elements from
   */
 
 
-#include "parser.h"
+#include "tokenizer.h"
 
 #include <ctype.h>
 #include <math.h>
@@ -330,9 +330,9 @@ int make_stream_space(parser_t *self, size_t nbytes) {
       LINE VECTORS
     */
     /*
-    printf("Line_start: "); 
-    
-    for (j = 0; j < self->lines + 1; ++j) { 
+    printf("Line_start: ");
+
+    for (j = 0; j < self->lines + 1; ++j) {
          printf("%d ", self->line_fields[j]);
      }
     printf("\n");
@@ -347,7 +347,7 @@ int make_stream_space(parser_t *self, size_t nbytes) {
     if (status != 0) {
         return PARSER_OUT_OF_MEMORY;
     }
-    
+
     // realloc took place
     if (cap != self->lines_cap) {
         self->line_fields = (int*) safe_realloc((void *) self->line_fields,
@@ -572,7 +572,7 @@ int tokenize_delimited(parser_t *self, size_t line_limit)
     char *stream;
     char *buf = self->data + self->datapos;
 
-    
+
     start_lines = self->lines;
 
     if (make_stream_space(self, self->datalen - self->datapos) < 0) {
@@ -1082,8 +1082,8 @@ int parser_consume_rows(parser_t *self, size_t nrows) {
     self->pword_start -= char_count;
     self->word_start -= char_count;
     /*
-    printf("Line_start: "); 
-    for (i = 0; i < self->lines + 1; ++i) { 
+    printf("Line_start: ");
+    for (i = 0; i < self->lines + 1; ++i) {
          printf("%d ", self->line_fields[i]);
      }
     printf("\n");
@@ -1212,8 +1212,8 @@ int _tokenize_helper(parser_t *self, size_t nrows, int all) {
         }
 
         TRACE(("Trying to process %d bytes\n", self->datalen - self->datapos));
-        /* TRACE(("sourcetype: %c, status: %d\n", self->sourcetype, status)); */   
-        
+        /* TRACE(("sourcetype: %c, status: %d\n", self->sourcetype, status)); */
+
         status = tokenize_bytes(self, nrows);
 
         if (status < 0) {
diff --git a/setup.py b/setup.py
index 240b19315..6c1b94def 100755
--- a/setup.py
+++ b/setup.py
@@ -258,7 +258,7 @@ class CleanCommand(Command):
         self._clean_exclude = ['np_datetime.c',
                                'np_datetime_strings.c',
                                'period.c',
-                               'parser.c',
+                               'tokenizer.c',
                                'io.c']
 
         for root, dirs, files in list(os.walk('pandas')):
@@ -605,11 +605,11 @@ period_ext = Extension('pandas._period',
                        include_dirs=[np.get_include()])
 
 parser_ext = Extension('pandas._parser',
-                       depends=['pandas/src/parser/parser.h',
+                       depends=['pandas/src/parser/tokenizer.h',
                                 'pandas/src/parser/io.h',
                                 'pandas/src/numpy_helper.h'],
                        sources=[srcpath('parser', suffix=suffix),
-                                'pandas/src/parser/parser.c',
+                                'pandas/src/parser/tokenizer.c',
                                 'pandas/src/parser/io.c',
                                 ],
                        #extra_compile_args=['-O3'],
