commit f49a37198676d46e230b965734000c08b271a46e
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Jun 4 17:21:44 2010 +0000

    code reorg in Series, miscellaneous groupby refactoring. Changed Series.values() to be a property so the interface is consistent with DataMatrix and WidePanel
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@186 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/__init__.py b/pandas/__init__.py
index f290baba1..d20be9170 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -6,7 +6,7 @@ from datetime import datetime
 
 import numpy as np
 
-from pandas.version import __version__
+from pandas.version import version as __version__
 from pandas.info import __doc__
 
 from pandas.core.api import *
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index eefbe9d8d..f323b3503 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -128,16 +128,20 @@ class DataFrame(Picklable, Groupable):
         elif data.ndim != 2:
             raise Exception('Must pass 2-d input!')
 
-        if columns is None:
-            raise Exception('Must pass column names')
+        N, K = data.shape
+
         if index is None:
-            raise Exception('Must pass index')
+            if N == 0:
+                index = NULL_INDEX
+            else:
+                index = np.arange(N)
 
-        N, K = data.shape
+        if columns is None:
+            if K == 0:
+                columns = NULL_INDEX
+            else:
+                columns = np.arange(K)
 
-        if len(index) != N:
-            raise Exception('Index length mismatch: %d vs. %d' %
-                            (len(index), N))
         if len(columns) != K:
             raise Exception('Index length mismatch: %d vs. %d' %
                             (len(columns), K))
@@ -150,7 +154,7 @@ class DataFrame(Picklable, Groupable):
         return DataFrame
 
     def __getstate__(self):
-        series = dict((k, v.values()) for k, v in self.iteritems())
+        series = dict((k, v.values) for k, v in self.iteritems())
         index = _pickle_array(self.index)
 
         return series, index
@@ -228,6 +232,9 @@ class DataFrame(Picklable, Groupable):
 
         return np.rec.fromarrays(arrays, names=names)
 
+    def fromcsv(self, path, header=0):
+        pass
+
 #-------------------------------------------------------------------------------
 # Magic methods
 
@@ -791,7 +798,7 @@ class DataFrame(Picklable, Groupable):
 
         return beg_slice, end_slice
 
-    def getXS(self, key):
+    def xs(self, key):
         """
         Returns a row from the DataFrame as a Series object.
 
@@ -814,6 +821,8 @@ class DataFrame(Picklable, Groupable):
         else:
             return Series(np.array(rowValues), index=subset)
 
+    getXS = lambda self, key: self.xs(key)
+
     def pivot(self, index=None, columns=None, values=None):
         """
         Produce 'pivot' table based on 3 columns of this DataFrame.
@@ -1079,8 +1088,8 @@ class DataFrame(Picklable, Groupable):
             >>> df.apply(numpy.sqrt) --> DataFrame
             >>> df.apply(numpy.sum) --> Series
 
-        Note
-        ----
+        Notes
+        -----
         Functions altering the index are not supported (yet)
         """
         if not len(self.cols()):
@@ -1221,8 +1230,8 @@ class DataFrame(Picklable, Groupable):
         result = {}
         for col in unionCols:
             if col in frame and col in other:
-                series = frame[col].values()
-                otherSeries = other[col].values()
+                series = frame[col].values
+                otherSeries = other[col].values
 
                 if do_fill:
                     this_mask = isnull(series)
@@ -1406,7 +1415,7 @@ class DataFrame(Picklable, Groupable):
         from pylab import plot
 
         for col in _try_sort(self.columns):
-            plot(self.index, self[col].values(), label=col)
+            plot(self.index, self[col].values, label=col)
 
     def _get_agg_axis(self, axis_num):
         if axis_num == 0:
@@ -1623,10 +1632,10 @@ class DataFrame(Picklable, Groupable):
             return tseries.median(arr[notnull(arr)])
 
         if axis == 0:
-            med = [f(self[col].values()) for col in self.columns]
+            med = [f(self[col].values) for col in self.columns]
             return Series(med, index=self.columns)
         elif axis == 1:
-            med = [f(self.getXS(k).values()) for k in self.index]
+            med = [f(self.getXS(k).values) for k in self.index]
             return Series(med, index=self.index)
         else:
             raise Exception('Must have 0<= axis <= 1')
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index f02119f9a..06b8fad8a 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -101,6 +101,18 @@ class GroupBy(object):
     def agg(self, func):
         return self.aggregate(func)
 
+    def _aggregate_generic(self, getter, agger, axis=0):
+        result = {}
+        for name, group in self.groups.iteritems():
+            data = getter(self.obj, group)
+
+            try:
+                result[name] = agger(data)
+            except Exception:
+                result[name] = data.apply(agger, axis=axis)
+
+        return result
+
     def transform(self, func):
         raise NotImplementedError
 
@@ -262,37 +274,17 @@ class DataFrameGroupBy(GroupBy):
 
         Optional: provide set mapping as dictionary
         """
-        if self.axis == 0:
-            return self._aggregate_index(applyfunc)
-        else:
-            return self._aggregate_columns(applyfunc)
+        axis_name = 'columns' if self.axis else 'index'
+        getter = lambda df, group: df.reindex(**{axis_name : group})
+        result_d = self._aggregate_generic(getter, applyfunc,
+                                           axis=self.axis)
 
-    def _aggregate_index(self, func):
-        result = {}
-        for name in self.groups:
-            data = self[name]
-            try:
-                result[name] = func(data)
-            except Exception:
-                result[name] = data.apply(func)
-
-            assert(isinstance(result[name], Series))
-
-        return self._klass(data=result).T
-
-    def _aggregate_columns(self, func):
-        result = {}
-        for name, group in self.groups.iteritems():
-            data = self.obj.reindex(columns=group)
+        result = DataMatrix(result_d)
 
-            try:
-                result[name] = func(data)
-            except Exception:
-                result[name] = data.apply(func, axis=1)
-
-            assert(isinstance(result[name], Series))
+        if self.axis == 0:
+            result = result.T
 
-        return self._klass(data=result)
+        return result
 
     def getGroup(self, groupList):
         if self.axis == 0:
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index ff25cbbc2..893e448bc 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -199,17 +199,19 @@ class DataMatrix(DataFrame):
             except Exception:
                 pass
 
+        N, K = values.shape
+
         if index is None:
-            if values.shape[0] == 0:
+            if N == 0:
                 index = NULL_INDEX
             else:
-                raise Exception('Must pass index!')
+                index = np.arange(N)
 
         if columns is None:
-            if values.shape[1] == 0:
+            if K == 0:
                 columns = NULL_INDEX
             else:
-                raise Exception('Must pass columns!')
+                columns = np.arange(K)
 
         return index, columns, values
 
@@ -413,7 +415,7 @@ class DataMatrix(DataFrame):
 
             # Operate column-wise
             this = self.reindex(columns=newCols)
-            other = other.reindex(newCols).values()
+            other = other.reindex(newCols).values
 
             resultMatrix = func(this.values, other)
 
@@ -1128,7 +1130,7 @@ class DataMatrix(DataFrame):
 
                 return myCopy
 
-    def getXS(self, key):
+    def xs(self, key):
         """
         Returns a row from the DataMatrix as a Series object.
 
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index fcddcb5e3..c1b665b67 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -544,6 +544,7 @@ class WidePanel(Panel):
         -------
         WidePanelGroupBy
         """
+        axis = self._get_axis_number(axis)
         return WidePanelGroupBy(self, function, axis=axis)
 
     def swapaxes(self, axis1='major', axis2='minor'):
@@ -1776,6 +1777,61 @@ class Factor(object):
             new_labels = self.labels[key]
             return Factor(new_labels, self.levels)
 
+def factor_agg(factor, vec, func):
+    """
+    Parameters
+    ----------
+    factor : Factor
+        length n
+    vec : sequence
+        length n
+    func : function
+        1D array aggregation function
+
+    Returns
+    -------
+    ndarray corresponding to Factor levels
+    """
+    indexer = np.argsort(factor.labels)
+    unique_labels = np.arange(len(factor.levels))
+
+    ordered_labels = factor.labels.take(indexer)
+    ordered_vec = np.asarray(vec).take(indexer)
+    bounds = ordered_labels.searchsorted(unique_labels)
+
+    return group_agg(ordered_vec, bounds, func)
+
+def group_agg(values, bounds, f):
+    """
+    R-style aggregator
+
+    Parameters
+    ----------
+    values : N-length or N x K ndarray
+    bounds : B-length ndarray
+    f : ndarray aggregation function
+
+    Returns
+    -------
+    ndarray with same length as bounds array
+    """
+    if values.ndim == 1:
+        N = len(values)
+        result = np.empty(len(bounds), dtype=float)
+    elif values.ndim == 2:
+        N, K = values.shape
+        result = np.empty((len(bounds), K), dtype=float)
+
+    for i, left_bound in enumerate(bounds):
+        if i == len(bounds) - 1:
+            right_bound = N
+        else:
+            right_bound = bounds[i + 1]
+
+        result[i] = f(values[left_bound : right_bound])
+
+    return result
+
 def _get_indexer(source, target, fill_method):
     if fill_method:
         fill_method = fill_method.upper()
@@ -1935,35 +1991,51 @@ def _slow_pivot(index, columns, values):
 def _monotonic(arr):
     return not (arr[1:] < arr[:-1]).any()
 
-def group_agg(values, bounds, f):
-    """
-    R-style aggregator
+class WidePanelGroupBy(GroupBy):
 
-    Parameters
-    ----------
-    values : N x K ndarray
-    bounds : B-length ndarray
-    f : ndarray aggregation function
+    def __init__(self, obj, grouper, axis=0):
+        self.axis = axis
 
-    Returns
-    -------
-    ndarray with same length as bounds array
-    """
-    N, K = values.shape
-    result = np.empty((len(bounds), K), dtype=float)
+        if axis not in (0, 1, 2): # pragma: no cover
+            raise Exception('invalid axis')
 
-    for i, left_bound in enumerate(bounds):
-        if i == len(bounds) - 1:
-            right_bound = N
-        else:
-            right_bound = bounds[i + 1]
+        GroupBy.__init__(self, obj, grouper)
 
-        result[i] = f(values[left_bound : right_bound])
+    @property
+    def _group_axis(self):
+        return self.obj._get_axis(self.axis)
 
-    return result
+    def aggregate(self, applyfunc):
+        """
+        For given DataFrame, group index by given mapper function or dict, take
+        the sub-DataFrame (reindex) for this group and call apply(applyfunc)
+        on this sub-DataFrame. Return a DataFrame of the results for each
+        key.
 
-class WidePanelGroupBy(GroupBy):
-    pass
+        Parameters
+        ----------
+        mapper : function, dict-like, or string
+            Mapping or mapping function. If string given, must be a column
+            name in the frame
+        applyfunc : function
+            Function to use for aggregating groups
+
+        N.B.: applyfunc must produce one value from a Series, otherwise
+        an error will occur.
+
+        Optional: provide set mapping as dictionary
+        """
+        axis_name = self.obj._get_axis_name(self.axis)
+        getter = lambda p, group: p.reindex(**{axis_name : group})
+        result_d = self._aggregate_generic(getter, applyfunc,
+                                           axis=self.axis)
+
+        result = WidePanel.fromDict(result_d, intersect=False)
+
+        if self.axis > 0:
+            result = result.swapaxes(0, self.axis)
+
+        return result
 
 class LongPanelGroupBy(GroupBy):
     pass
diff --git a/pandas/core/series.py b/pandas/core/series.py
index fdf40971a..11bbaff9b 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -36,10 +36,10 @@ def _seriesOpWrap(opname):
     def wrapper(self, other):
         from pandas.core.frame import DataFrame
 
-        func = getattr(self.values(), opname)
+        func = getattr(self.values, opname)
         if isinstance(other, Series):
             if self.index.equals(other.index):
-                return Series(func(other.values()), index=self.index)
+                return Series(func(other.values), index=self.index)
 
             newIndex = self.index + other.index
 
@@ -246,7 +246,7 @@ class Series(np.ndarray, Picklable, Groupable):
               of a sequence, a 'slice' of the series (with corresponding dates)
               will be returned, otherwise a single value.
         """
-        values = self.values()
+        values = self.values
 
         try:
             # Check that we can even look for this in the index
@@ -297,7 +297,7 @@ class Series(np.ndarray, Picklable, Groupable):
         will have a reference to the original series which could be
         inadvertently changed if the slice were altered (made mutable).
         """
-        newArr = self.values()[i:j].copy()
+        newArr = self.values[i:j].copy()
         newIndex = self.index[i:j]
 
         return Series(newArr, index=newIndex)
@@ -310,7 +310,7 @@ class Series(np.ndarray, Picklable, Groupable):
             loc = self.index.indexMap[key]
             ndarray.__setitem__(self, loc, value)
         except Exception:
-            values = self.values()
+            values = self.values
             values[key] = value
 
     def __setslice__(self, i, j, value):
@@ -319,7 +319,7 @@ class Series(np.ndarray, Picklable, Groupable):
 
     def __repr__(self):
         """Clean string representation of a Series"""
-        vals = self.values()
+        vals = self.values
         index = self.index
 
         if len(index) > 500:
@@ -332,14 +332,17 @@ class Series(np.ndarray, Picklable, Groupable):
             return '%s' % ndarray.__repr__(self)
 
     def toString(self, buffer=sys.stdout, nanRep='NaN'):
-        print >> buffer, _seriesRepr(self.index, self.values(),
+        print >> buffer, _seriesRepr(self.index, self.values,
                                      nanRep=nanRep)
 
     def __str__(self):
         return repr(self)
 
     def __iter__(self):
-        return iter(self.values())
+        return iter(self.values)
+
+    def copy(self):
+        return Series(self.values.copy(), index=self.index)
 
 #-------------------------------------------------------------------------------
 #   Arithmetic operators
@@ -358,7 +361,7 @@ class Series(np.ndarray, Picklable, Groupable):
     __ipow__ = __pow__
 
 #-------------------------------------------------------------------------------
-# Overridden ndarray methods
+# Statistics, overridden ndarray methods
 
     def count(self):
         """
@@ -368,17 +371,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         nobs : int
         """
-        return notnull(self.values()).sum()
-
-    def _ndarray_statistic(self, funcname):
-        arr = self.values()
-        retVal = getattr(arr, funcname)()
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = getattr(arr, funcname)()
-
-        return retVal
+        return notnull(self.values).sum()
 
     def sum(self, axis=None, dtype=None, out=None):
         """
@@ -392,11 +385,21 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         return self._ndarray_statistic('mean')
 
+    def _ndarray_statistic(self, funcname):
+        arr = self.values
+        retVal = getattr(arr, funcname)()
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            retVal = getattr(arr, funcname)()
+
+        return retVal
+
     def min(self, axis=None, out=None):
         """
         Compute minimum of non-null values
         """
-        arr = self.values().copy()
+        arr = self.values.copy()
         if not issubclass(arr.dtype.type, np.int_):
             arr[isnull(arr)] = np.inf
         return arr.min()
@@ -405,7 +408,7 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         Compute maximum of non-null values
         """
-        arr = self.values().copy()
+        arr = self.values.copy()
         if not issubclass(arr.dtype.type, np.int_):
             arr[isnull(arr)] = -np.inf
         return arr.max()
@@ -414,7 +417,7 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         Compute unbiased standard deviation of non-null values
         """
-        nona = remove_na(self.values())
+        nona = remove_na(self.values)
         if len(nona) < 2:
             return NaN
         return ndarray.std(nona, axis, dtype, out, ddof)
@@ -423,7 +426,7 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         Compute unbiased variance of non-null values
         """
-        nona = remove_na(self.values())
+        nona = remove_na(self.values)
         if len(nona) < 2:
             return NaN
         return ndarray.var(nona, axis, dtype, out, ddof)
@@ -436,7 +439,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         skew : float
         """
-        y = np.array(self.values())
+        y = np.array(self.values)
         mask = notnull(y)
         count = mask.sum()
         np.putmask(y, -mask, 0)
@@ -447,16 +450,92 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return (np.sqrt((count**2-count))*C) / ((count-2)*np.sqrt(B)**3)
 
-    def keys(self):
+    def cumsum(self, axis=0, dtype=None, out=None):
+        """
+        Overriding numpy's built-in cumsum functionality
+        """
+        arr = self.copy()
+        okLocs = notnull(arr)
+        result = np.cumsum(arr.view(ndarray)[okLocs])
+        arr = arr.astype(result.dtype)
+        arr[okLocs] = result
+        return arr
+
+    def cumprod(self, axis=0, dtype=None, out=None):
+        """
+        Overriding numpy's built-in cumprod functionality
+        """
+        arr = self.copy()
+        okLocs = notnull(arr)
+        arr[okLocs] = np.cumprod(arr.view(ndarray)[okLocs])
+        return arr
+
+    def median(self):
+        """
+        Compute median value of non-null values
+        """
+        arr = self.values
+        arr = arr[notnull(arr)]
+        return tseries.median(arr)
+
+    def corr(self, other):
         """
-        Return Series index
+        Compute correlation two Series, excluding missing values
+
+        Parameters
+        ----------
+        other : Series object
 
         Returns
         -------
-        index : Index
+        correlation : float
         """
+        commonIdx = remove_na(self).index.intersection(remove_na(other).index)
+
+        if len(commonIdx) == 0:
+            return NaN
+
+        this = self.reindex(commonIdx)
+        that = other.reindex(commonIdx)
+
+        return np.corrcoef(this, that)[0, 1]
+
+    def diff(self):
+        """
+        1st discrete difference of object
+
+        Returns
+        -------
+        TimeSeries
+        """
+        return (self - self.shift(1))
+
+    def autocorr(self):
+        """
+        Lag-1 autocorrelation
+
+        Returns
+        -------
+        TimeSeries
+        """
+        return self.corr(self.shift(1))
+
+    def cap(self, threshold):
+        """Return copy of series with values above given value truncated"""
+        return np.where(self > threshold, threshold, self)
+
+    def floor(self, threshold):
+        """Return copy of series with values below given value truncated"""
+        return np.where(self < threshold, threshold, self)
+
+#-------------------------------------------------------------------------------
+# Iteration
+
+    def keys(self):
+        "Alias for Series index"
         return self.index
 
+    @property
     def values(self):
         """
         Return Series as ndarray
@@ -473,6 +552,9 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         return itertools.izip(iter(self.index), iter(self))
 
+#-------------------------------------------------------------------------------
+# Combination
+
     def append(self, other):
         """
         Concatenate two Series. The indices should not overlap
@@ -521,7 +603,7 @@ class Series(np.ndarray, Picklable, Groupable):
                 newArr[i] = func(self.get(idx, NaN), other.get(idx, NaN))
         else:
             newIndex = self.index
-            newArr = func(self.values(), other)
+            newArr = func(self.values, other)
 
         return Series(newArr, index=newIndex)
 
@@ -551,58 +633,8 @@ class Series(np.ndarray, Picklable, Groupable):
         result = Series(np.where(isnull(this), other, this), index=newIndex)
         return result
 
-    def cumsum(self, axis=0, dtype=None, out=None):
-        """
-        Overriding numpy's built-in cumsum functionality
-        """
-        arr = self.copy()
-        okLocs = notnull(arr)
-        result = np.cumsum(arr.view(ndarray)[okLocs])
-        arr = arr.astype(result.dtype)
-        arr[okLocs] = result
-        return arr
-
-    def cumprod(self, axis=0, dtype=None, out=None):
-        """
-        Overriding numpy's built-in cumprod functionality
-        """
-        arr = self.copy()
-        okLocs = notnull(arr)
-        arr[okLocs] = np.cumprod(arr.view(ndarray)[okLocs])
-        return arr
-
-    def median(self):
-        """
-        Compute median value of non-null values
-        """
-        arr = self.values()
-        arr = arr[notnull(arr)]
-        return tseries.median(arr)
-
-    def copy(self):
-        return Series(self.values().copy(), index=self.index)
-
-    def corr(self, other):
-        """
-        Compute correlation two Series, excluding missing values
-
-        Parameters
-        ----------
-        other : Series object
-
-        Returns
-        -------
-        correlation : float
-        """
-        commonIdx = remove_na(self).index.intersection(remove_na(other).index)
-
-        if len(commonIdx) == 0:
-            return NaN
-
-        this = self.reindex(commonIdx)
-        that = other.reindex(commonIdx)
-
-        return np.corrcoef(this, that)[0, 1]
+#-------------------------------------------------------------------------------
+# Reindexing, sorting
 
     def sort(self, axis=0, kind='quicksort', order=None):
         """
@@ -616,7 +648,7 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         Overriding numpy's built-in cumsum functionality
         """
-        values = self.values()
+        values = self.values
         mask = isnull(values)
 
         if mask.any():
@@ -643,7 +675,7 @@ class Series(np.ndarray, Picklable, Groupable):
         y : Series
             sorted by values
         """
-        arr = self.values()
+        arr = self.values
         sortedIdx = np.empty(len(self), dtype=np.int32)
 
         bad = isnull(arr)
@@ -678,6 +710,114 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         return Series([func(x) for x in self], index=self.index)
 
+    def merge(self, other):
+        """
+        If self is {A}->{B} and other is another mapping of {B}->{C}
+        then returns a new Series that is {A}->{C}
+
+        Parameters
+        ----------
+        other : dict or Series
+
+        Returns
+        -------
+        Series having same index as calling instance, with values from
+        input Series
+        """
+        if isinstance(other, dict):
+            other = Series(other)
+
+        if not isinstance(other, Series): # pragma: no cover
+            raise Exception('Argument must be a Series!')
+
+        fillVec, mask = tseries.getMergeVec(self, other.index.indexMap)
+
+        newValues = other.view(np.ndarray).take(fillVec)
+        np.putmask(newValues, -mask, np.nan)
+
+        newSer = Series(newValues, index=self.index)
+        return newSer
+
+    def reindex(self, newIndex, fillMethod=None):
+        """Overloaded version of reindex for TimeSeries. Supports filling
+        with values based on new index.
+
+        See analogous method for DataFrame, will be faster for multiple
+        TimeSeries
+
+        Parameters
+        ----------
+        newIndex :   array-like, preferably an Index object (to avoid
+                    duplicating data)
+        fillMethod : {'backfill', 'pad', 'interpolate', None}
+                    Method to use for filling holes in reindexed Series
+
+        Returns
+        -------
+        TimeSeries
+        """
+        if self.index is newIndex:
+            return self.copy()
+
+        if not isinstance(newIndex, Index):
+            newIndex = Index(newIndex)
+
+        if len(self.index) == 0:
+            return Series.fromValue(NaN, index=newIndex)
+
+        if fillMethod is not None:
+            fillMethod = fillMethod.upper()
+
+        # Cython for blazing speed
+        fillVec, mask = tseries.getFillVec(self.index, newIndex,
+                                           self.index.indexMap,
+                                           newIndex.indexMap,
+                                           kind=fillMethod)
+
+        newValues = self.values.take(fillVec)
+
+        notmask = -mask
+        if notmask.any():
+            if issubclass(newValues.dtype.type, np.int_):
+                newValues = newValues.astype(float)
+            elif issubclass(newValues.dtype.type, np.bool_):
+                newValues = newValues.astype(object)
+
+            np.putmask(newValues, notmask, NaN)
+
+        return Series(newValues, index=newIndex)
+
+    def fill(self, value=None, method='pad'):
+        """
+        Fill NaN values using the specified method.
+
+        Parameters
+        ----------
+        value : any kind (should be same type as array)
+            Value to use to fill holes (e.g. 0)
+
+        method : {'backfill', 'pad', None}
+            Method to use for filling holes in new inde
+
+        Returns
+        -------
+        TimeSeries with NaN's filled
+
+        See also
+        --------
+        reindex, asfreq
+        """
+        if value is not None:
+            newSeries = self.copy()
+            newSeries[isnull(newSeries)] = value
+            return newSeries
+        else: # Using reindex to pad / backfill
+            withoutna = remove_na(self)
+            return withoutna.reindex(self.index, fillMethod=method)
+
+#-------------------------------------------------------------------------------
+# Miscellaneous
+
     def plot(self, label=None, kind='line', rot=30, **kwds): # pragma: no cover
         """
         Plot the input series with the index on the x-axis using
@@ -713,18 +853,10 @@ class Series(np.ndarray, Picklable, Groupable):
         N = len(self)
 
         if kind == 'line':
-            plt.plot(self.index, self.values(), **kwds)
-
-#             ax = plt.gca()
-#             ax.autoscale_view(scalex=True, scaley=True)
-
-#             locs, labels = plt.xticks()
-#             new_locs = locs[::len(locs) // 8]
-#             plt.xticks(new_locs, rotation=20)
-
+            plt.plot(self.index, self.values, **kwds)
         elif kind == 'bar':
             xinds = np.arange(N) + 0.25
-            plt.bar(xinds, self.values(), 0.5, bottom=np.zeros(N), linewidth=1)
+            plt.bar(xinds, self.values, 0.5, bottom=np.zeros(N), linewidth=1)
 
             if N < 10:
                 fontsize = 12
@@ -750,14 +882,6 @@ class Series(np.ndarray, Picklable, Groupable):
 
         f.close()
 
-    def cap(self, threshold):
-        """Return copy of series with values above given value truncated"""
-        return np.where(self > threshold, threshold, self)
-
-    def floor(self, threshold):
-        """Return copy of series with values below given value truncated"""
-        return np.where(self < threshold, threshold, self)
-
     def valid(self):
         """
         Return Series without NaN values
@@ -785,7 +909,7 @@ class Series(np.ndarray, Picklable, Groupable):
             return None
 
 #-------------------------------------------------------------------------------
-# TimeSeries methods
+# Time series-oriented methods
 
     def shift(self, periods, offset=None, timeRule=None):
         """
@@ -815,10 +939,10 @@ class Series(np.ndarray, Picklable, Groupable):
             newValues = np.empty(len(self), dtype=self.dtype)
 
             if periods > 0:
-                newValues[periods:] = self.values()[:-periods]
+                newValues[periods:] = self.values[:-periods]
                 newValues[:periods] = np.NaN
             elif periods < 0:
-                newValues[:periods] = self.values()[-periods:]
+                newValues[:periods] = self.values[-periods:]
                 newValues[periods:] = np.NaN
 
             return Series(newValues, index=self.index)
@@ -908,34 +1032,6 @@ class Series(np.ndarray, Picklable, Groupable):
         else:
             return v
 
-    def fill(self, value=None, method='pad'):
-        """
-        Fill NaN values using the specified method.
-
-        Parameters
-        ----------
-        value : any kind (should be same type as array)
-            Value to use to fill holes (e.g. 0)
-
-        method : {'backfill', 'pad', None}
-            Method to use for filling holes in new inde
-
-        Returns
-        -------
-        TimeSeries with NaN's filled
-
-        See also
-        --------
-        reindex, asfreq
-        """
-        if value is not None:
-            newSeries = self.copy()
-            newSeries[isnull(newSeries)] = value
-            return newSeries
-        else: # Using reindex to pad / backfill
-            withoutna = remove_na(self)
-            return withoutna.reindex(self.index, fillMethod=method)
-
     def asfreq(self, freq, fillMethod=None):
         """
         Convert this TimeSeries to the provided frequency using DateOffset
@@ -985,7 +1081,7 @@ class Series(np.ndarray, Picklable, Groupable):
         else:
             inds = np.arange(len(self))
 
-        values = self.values()
+        values = self.values
 
         invalid = isnull(values)
         valid = -invalid
@@ -1001,83 +1097,6 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return Series(result, index=self.index)
 
-    def merge(self, other):
-        """
-        If self is {A}->{B} and other is another mapping of {B}->{C}
-        then returns a new Series that is {A}->{C}
-
-        Parameters
-        ----------
-        other : dict or Series
-
-        Returns
-        -------
-        Series having same index as calling instance, with values from
-        input Series
-        """
-        if isinstance(other, dict):
-            other = Series(other)
-
-        if not isinstance(other, Series): # pragma: no cover
-            raise Exception('Argument must be a Series!')
-
-        fillVec, mask = tseries.getMergeVec(self, other.index.indexMap)
-
-        newValues = other.view(np.ndarray).take(fillVec)
-        np.putmask(newValues, -mask, np.nan)
-
-        newSer = Series(newValues, index=self.index)
-        return newSer
-
-    def reindex(self, newIndex, fillMethod=None):
-        """Overloaded version of reindex for TimeSeries. Supports filling
-        with values based on new index.
-
-        See analogous method for DataFrame, will be faster for multiple
-        TimeSeries
-
-        Parameters
-        ----------
-        newIndex :   array-like, preferably an Index object (to avoid
-                    duplicating data)
-        fillMethod : {'backfill', 'pad', 'interpolate', None}
-                    Method to use for filling holes in reindexed Series
-
-        Returns
-        -------
-        TimeSeries
-        """
-        if self.index is newIndex:
-            return self.copy()
-
-        if not isinstance(newIndex, Index):
-            newIndex = Index(newIndex)
-
-        if len(self.index) == 0:
-            return Series.fromValue(NaN, index=newIndex)
-
-        if fillMethod is not None:
-            fillMethod = fillMethod.upper()
-
-        # Cython for blazing speed
-        fillVec, mask = tseries.getFillVec(self.index, newIndex,
-                                           self.index.indexMap,
-                                           newIndex.indexMap,
-                                           kind=fillMethod)
-
-        newValues = self.values().take(fillVec)
-
-        notmask = -mask
-        if notmask.any():
-            if issubclass(newValues.dtype.type, np.int_):
-                newValues = newValues.astype(float)
-            elif issubclass(newValues.dtype.type, np.bool_):
-                newValues = newValues.astype(object)
-
-            np.putmask(newValues, notmask, NaN)
-
-        return Series(newValues, index=newIndex)
-
     def rename(self, mapper):
         """
         Alter Series index using dict or function
@@ -1108,26 +1127,6 @@ class Series(np.ndarray, Picklable, Groupable):
         return Series([d.weekday() for d in self.index],
                       index=self.index)
 
-    def diff(self):
-        """
-        1st discrete difference of object
-
-        Returns
-        -------
-        TimeSeries
-        """
-        return (self - self.shift(1))
-
-    def autocorr(self):
-        """
-        Lag-1 autocorrelation
-
-        Returns
-        -------
-        TimeSeries
-        """
-        return self.corr(self.shift(1))
-
 
 class TimeSeries(Series):
     pass
diff --git a/pandas/core/tests/test_panel.py b/pandas/core/tests/test_panel.py
index d044cbd0b..477b52544 100644
--- a/pandas/core/tests/test_panel.py
+++ b/pandas/core/tests/test_panel.py
@@ -12,6 +12,7 @@ from pandas.util.testing import (assert_panel_equal,
                                  assert_frame_equal,
                                  assert_series_equal,
                                  assert_almost_equal)
+import pandas.core.panel as panelm
 import pandas.util.testing as common
 
 class PanelTests(object):
@@ -406,7 +407,20 @@ class TestWidePanel(unittest.TestCase, PanelTests):
         self.assertRaises(Exception, self.panel.getMinorXS, 'E')
 
     def test_groupby(self):
-        pass
+        grouped = self.panel.groupby({'ItemA' : 0, 'ItemB' : 0, 'ItemC' : 1},
+                                     axis='items')
+        agged = grouped.agg(np.mean)
+        self.assert_(np.array_equal(agged.items, [0, 1]))
+
+        grouped = self.panel.groupby(lambda x: x.month, axis='major')
+        agged = grouped.agg(np.mean)
+
+        self.assert_(np.array_equal(agged.major_axis, [1, 2]))
+
+        grouped = self.panel.groupby({'A' : 0, 'B' : 0, 'C' : 1, 'D' : 1},
+                                     axis='minor')
+        agged = grouped.agg(np.mean)
+        self.assert_(np.array_equal(agged.minor_axis, [0, 1]))
 
     def test_swapaxes(self):
         result = self.panel.swapaxes('items', 'minor')
@@ -775,6 +789,19 @@ def test_group_agg():
     assert(agged[1][0] == 2.5)
     assert(agged[2][0] == 4.5)
 
+def test_monotonic():
+    pos = np.array([1, 2, 3, 5])
+
+    assert panelm._monotonic(pos)
+
+    neg = np.array([1, 2, 3, 4, 3])
+
+    assert not panelm._monotonic(neg)
+
+    neg2 = np.array([5, 1, 2, 3, 4, 5])
+
+    assert not panelm._monotonic(neg2)
+
 class TestFactor(unittest.TestCase):
 
     def test_constructor(self):
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index 04af386d1..3ad25fafe 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -210,7 +210,7 @@ class TestSeries(unittest.TestCase):
         self.assert_(self.ts.keys() is self.ts.index)
 
     def test_values(self):
-        self.assert_(np.array_equal(self.ts, self.ts.values()))
+        self.assert_(np.array_equal(self.ts, self.ts.values))
 
     def test_iteritems(self):
         for idx, val in self.series.iteritems():
@@ -323,7 +323,7 @@ class TestSeries(unittest.TestCase):
         # float + int
         int_ts = self.ts.astype(int)[:-5]
         added = self.ts + int_ts
-        expected = self.ts.values()[:-5] + int_ts.values()
+        expected = self.ts.values[:-5] + int_ts.values
         self.assert_(np.array_equal(added[:-5], expected))
 
     def test_operators_frame(self):
@@ -433,7 +433,7 @@ class TestSeries(unittest.TestCase):
 
         ts = self.ts.copy()
         ts[:5] = np.NaN
-        vals = ts.values()
+        vals = ts.values
 
         result = ts.order()
         self.assert_(np.isnan(result[-5:]).all())
diff --git a/pandas/lib/setup.py b/pandas/lib/setup.py
index a29988a6c..e1ac8b029 100644
--- a/pandas/lib/setup.py
+++ b/pandas/lib/setup.py
@@ -7,8 +7,7 @@ def get_cython_ext():
     from Cython.Distutils import build_ext
 
     pyx_ext = Extension('tseries', ['pandas/lib/src/tseries.pyx'],
-                        include_dirs=[numpy.get_include(),
-                                      'pandas/lib/include/'])
+                        include_dirs=[numpy.get_include()])
 
 
     setup(name='pandas.lib.tseries', description='Nothing',
@@ -23,8 +22,6 @@ def configuration(parent_package='', top_path=None):
     config = Configuration('lib', parent_package, top_path)
     config.add_extension('tseries',
                          sources=['src/tseries.c'],
-                         include_dirs=[numpy.get_include(),
-                                       'include/'])
-    config.add_data_dir('include')
+                         include_dirs=[numpy.get_include()])
 
     return config
diff --git a/pandas/rpy/__init__.py b/pandas/rpy/__init__.py
new file mode 100644
index 000000000..8b1378917
--- /dev/null
+++ b/pandas/rpy/__init__.py
@@ -0,0 +1 @@
+
diff --git a/pandas/rpy/base.py b/pandas/rpy/base.py
new file mode 100644
index 000000000..070d457ed
--- /dev/null
+++ b/pandas/rpy/base.py
@@ -0,0 +1,13 @@
+import pandas.rpy.util as util
+
+class lm(object):
+    """
+    Examples
+    --------
+    >>> model = lm('x ~ y + z', data)
+    >>> model.coef
+    """
+    def __init__(self, formula, data):
+        pass
+
+
diff --git a/pandas/rpy/common.py b/pandas/rpy/common.py
new file mode 100644
index 000000000..a3042a06a
--- /dev/null
+++ b/pandas/rpy/common.py
@@ -0,0 +1,37 @@
+import numpy as np
+
+from pandas import DataFrame, DataMatrix
+
+from rpy2.robjects.packages import importr
+import rpy2.robjects as robjects
+
+r = robjects.r
+
+def load_data(name, package=None):
+    if package:
+        importr(package)
+
+    r.data(name)
+    return _convert_robj(r[name])
+
+def _convert_robj(robj):
+    if isinstance(robj, robjects.DataFrame):
+        return _from_DataFrame(robj)
+    elif isinstance(robj, robjects.Matrix):
+        return _from_Matrix(robj)
+
+def _from_DataFrame(rdf):
+    columns = list(rdf.colnames)
+
+    data = {}
+    for i, col in enumerate(columns):
+        vec = rdf.rx2(i + 1)
+        data[col] = list(vec)
+
+    return DataFrame(data)
+
+def _from_Matrix(mat):
+    columns = list(mat.colnames)
+
+    return DataMatrix(np.array(mat), columns=columns)
+
diff --git a/pandas/rpy/mass.py b/pandas/rpy/mass.py
new file mode 100644
index 000000000..1a663e572
--- /dev/null
+++ b/pandas/rpy/mass.py
@@ -0,0 +1,4 @@
+
+class rlm(object):
+    pass
+
diff --git a/pandas/rpy/vars.py b/pandas/rpy/vars.py
new file mode 100644
index 000000000..3993423b3
--- /dev/null
+++ b/pandas/rpy/vars.py
@@ -0,0 +1,20 @@
+import pandas.rpy.util as util
+
+class VAR(object):
+    """
+
+    Parameters
+    ----------
+    y :
+    p :
+    type : {"const", "trend", "both", "none"}
+    season :
+    exogen :
+    lag_max :
+    ic : {"AIC", "HQ", "SC", "FPE"}
+        Information criterion to use, if lag_max is not None
+    """
+    def __init__(y, p=1, type="none", season=None, exogen=None,
+                 lag_max=None, ic=None):
+        pass
+
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index 46ff9dbce..f57b42f09 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -771,7 +771,7 @@ class MovingOLS(OLS):
 
         if isinstance(y, Series):
             _y_indexMap = y.index.indexMap
-            _values = y.values()
+            _values = y.values
             def y_slicer(df, dt):
                 i = _y_indexMap[dt]
                 return _values[i:i+1]
@@ -1190,7 +1190,7 @@ def _filter_data(lhs, rhs):
 
         rhs_valid = np.isfinite(rhs.values).sum(1) == len(rhs.columns)
 
-    lhs_valid = np.isfinite(lhs.values())
+    lhs_valid = np.isfinite(lhs.values)
     valid = rhs_valid & lhs_valid
 
     if not valid.all():
diff --git a/pandas/version.py b/pandas/version.py
index e12f3e031..dc4075dc6 100644
--- a/pandas/version.py
+++ b/pandas/version.py
@@ -1,4 +1,17 @@
-# from pkg_resources import require
-# __version__ = require('pandas')[0].version
+# THIS FILE IS GENERATED FROM PANDAS setup.py
+short_version='0.3.0'
+version='0.3.0'
+release=False
 
-__version__ = 0.2
+if not release:
+    version += '.dev'
+    import os
+    svn_version_file = os.path.join(os.path.dirname(__file__),
+                                    '__svn_version__.py')
+    if os.path.isfile(svn_version_file):
+        import imp
+        svn = imp.load_module('pandas.__svn_version__',
+                              open(svn_version_file),
+                              svn_version_file,
+                              ('.py','U',1))
+        version += svn.version
