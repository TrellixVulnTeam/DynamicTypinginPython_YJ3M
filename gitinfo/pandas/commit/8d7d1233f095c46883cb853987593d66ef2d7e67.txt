commit 8d7d1233f095c46883cb853987593d66ef2d7e67
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Jun 9 20:37:58 2011 -0400

    entire unit test suite passes

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 3f0e5de84..afb178b6b 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -124,9 +124,10 @@ class DataFrame(PandasGeneric):
 
     def __init__(self, data=None, index=None, columns=None, dtype=None):
         if isinstance(data, dict):
-            sdict, columns, index = _init_dict(data, index, columns, dtype)
+            sdict, columns, index = self._init_dict(data, index, columns, dtype)
         elif isinstance(data, (np.ndarray, list)):
-            sdict, columns, index = _init_matrix(data, index, columns, dtype)
+            sdict, columns, index = self._init_matrix(data, index, columns,
+                                                      dtype)
         elif isinstance(data, DataFrame):
             sdict = data._series.copy()
 
@@ -150,6 +151,47 @@ class DataFrame(PandasGeneric):
         self.columns = columns
         self.index = index
 
+    def _init_dict(self, data, index, columns, dtype):
+        # pre-filter out columns if we passed it
+        if columns is not None:
+            columns = _ensure_index(columns)
+            data = dict((k, v) for k, v in data.iteritems() if k in columns)
+        else:
+            columns = Index(_try_sort(data.keys()))
+
+        if index is None:
+            index = extract_index(data)
+
+        sdict = _homogenize_series(data, index, dtype, force_copy=True)
+        # add in any other columns we want to have (completeness)
+        for c in columns:
+            if c not in sdict:
+                sdict[c] = Series(np.NaN, index=index)
+
+        return sdict, columns, index
+
+    def _init_matrix(self, data, index, columns, dtype):
+        data = _prep_ndarray(data)
+        if data.ndim == 1:
+            data = data.reshape((len(data), 1))
+        elif data.ndim != 2:
+            raise Exception('Must pass 2-d input!')
+
+        N, K = data.shape
+
+        if index is None:
+            index = _default_index(N)
+
+        if columns is None:
+            columns = _default_index(K)
+
+        if len(columns) != K:
+            raise Exception('Column length mismatch: %d vs. %d' %
+                            (len(columns), K))
+
+        data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
+        return self._init_dict(data, index, columns, dtype)
+
     @property
     def _constructor(self):
         return DataFrame
@@ -2420,47 +2462,6 @@ def _prep_ndarray(values):
             values = np.array(values, dtype=object, copy=True)
     return values
 
-def _init_matrix(data, index, columns, dtype):
-    data = _prep_ndarray(data)
-    if data.ndim == 1:
-        data = data.reshape((len(data), 1))
-    elif data.ndim != 2:
-        raise Exception('Must pass 2-d input!')
-
-    N, K = data.shape
-
-    if index is None:
-        index = _default_index(N)
-
-    if columns is None:
-        columns = _default_index(K)
-
-    if len(columns) != K:
-        raise Exception('Column length mismatch: %d vs. %d' %
-                        (len(columns), K))
-
-    data = dict([(idx, data[:, i]) for i, idx in enumerate(columns)])
-    return _init_dict(data, index, columns, dtype)
-
-def _init_dict(data, index, columns, dtype):
-    # pre-filter out columns if we passed it
-    if columns is not None:
-        columns = _ensure_index(columns)
-        data = dict((k, v) for k, v in data.iteritems() if k in columns)
-    else:
-        columns = Index(_try_sort(data.keys()))
-
-    if index is None:
-        index = extract_index(data)
-
-    sdict = _homogenize_series(data, index, dtype, force_copy=True)
-    # add in any other columns we want to have (completeness)
-    for c in columns:
-        if c not in sdict:
-            sdict[c] = Series(np.NaN, index=index)
-
-    return sdict, columns, index
-
 def _homogenize_series(data, index, dtype=None, force_copy=True):
     homogenized = {}
 
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 058cf6436..3c20e4049 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -1,13 +1,10 @@
-# pylint: disable=E1101,E1103
+# pylint: disable=E1101,E1103,E0202
 # pylint: disable=W0212,W0703,W0231,W0622
 
-from cStringIO import StringIO
-import sys
-
 from numpy import nan
 import numpy as np
 
-from pandas.core.common import (_pickle_array, _unpickle_array, _try_sort)
+from pandas.core.common import (_unpickle_array, _try_sort)
 from pandas.core.frame import (DataFrame, extract_index, _homogenize_series,
                                _default_index, _ensure_index, _prep_ndarray)
 from pandas.core.index import Index, NULL_INDEX
@@ -15,7 +12,6 @@ from pandas.core.internals import BlockManager, make_block
 from pandas.core.series import Series
 import pandas.core.common as common
 import pandas.core.datetools as datetools
-import pandas.lib.tseries as tseries
 
 #-------------------------------------------------------------------------------
 # DataMatrix class
@@ -56,16 +52,70 @@ class DataMatrix(DataFrame):
                 mgr = mgr.cast(dtype)
         # HACK
         elif isinstance(data, DataFrame):
-            mgr = _init_dict(data._series, index, columns, dtype)
+            mgr = self._init_dict(data._series, index, columns, dtype)
         elif isinstance(data, dict):
-            mgr = _init_dict(data, index, columns, dtype)
+            mgr = self._init_dict(data, index, columns, dtype)
         elif isinstance(data, (np.ndarray, list)):
-            mgr = _init_matrix(data, index, columns, dtype)
+            mgr = self._init_matrix(data, index, columns, dtype)
         else:
             raise Exception('DataMatrix constructor not properly called!')
 
         self._data = mgr
 
+    def _init_dict(self, data, index, columns, dtype):
+        """
+        Segregate Series based on type and coerce into matrices.
+
+        Needs to handle a lot of exceptional cases.
+
+        Somehow this got outrageously complicated
+        """
+        # TODO: deal with emptiness!
+        # TODO: dtype casting?
+
+        # prefilter if columns passed
+        if columns is not None:
+            columns = _ensure_index(columns)
+            data = dict((k, v) for k, v in data.iteritems() if k in columns)
+
+        # figure out the index, if necessary
+        if index is None:
+            index = extract_index(data)
+
+        # don't force copy because getting jammed in an ndarray anyway
+        homogenized = _homogenize_series(data, index, dtype, force_copy=False)
+        # segregates dtypes and forms blocks matching to columns
+        blocks, columns = _form_blocks(homogenized, index, columns)
+        return BlockManager(blocks, index, columns)
+
+    def _init_matrix(self, values, index, columns, dtype):
+        values = _prep_ndarray(values)
+
+        if values.ndim == 1:
+            N = values.shape[0]
+            if N == 0:
+                values = values.reshape((values.shape[0], 0))
+            else:
+                values = values.reshape((values.shape[0], 1))
+
+        if dtype is not None:
+            try:
+                values = values.astype(dtype)
+            except Exception:
+                pass
+
+        N, K = values.shape
+
+        if index is None:
+            index = _default_index(N)
+
+        if columns is None:
+            columns = _default_index(K)
+
+        columns = _ensure_index(columns)
+        block = make_block(values, columns)
+        return BlockManager([block], index, columns)
+
     def _set_columns(self, cols):
         if len(cols) != self.values.shape[1]:
             raise Exception('Columns length %d did not match values %d!' %
@@ -616,7 +666,8 @@ def _group_dtypes(data, columns):
 
     chunk_cols = []
     chunks = []
-    for dtype, gp_cols in itertools.groupby(columns, lambda x: data[x].dtype):
+    grouper = lambda x: data[x].dtype
+    for _, gp_cols in itertools.groupby(columns, grouper):
         chunk = np.vstack([data[k] for k in gp_cols]).T
 
         chunks.append(chunk)
@@ -624,32 +675,6 @@ def _group_dtypes(data, columns):
 
     return chunks, chunk_cols
 
-def _init_dict(data, index, columns, dtype):
-    """
-    Segregate Series based on type and coerce into matrices.
-
-    Needs to handle a lot of exceptional cases.
-
-    Somehow this got outrageously complicated
-    """
-    # TODO: deal with emptiness!
-    # TODO: dtype casting?
-
-    # prefilter if columns passed
-    if columns is not None:
-        columns = _ensure_index(columns)
-        data = dict((k, v) for k, v in data.iteritems() if k in columns)
-
-    # figure out the index, if necessary
-    if index is None:
-        index = extract_index(data)
-
-    # don't force copy because getting jammed in an ndarray anyway
-    homogenized = _homogenize_series(data, index, dtype, force_copy=False)
-    # segregates dtypes and forms blocks matching to columns
-    blocks, columns = _form_blocks(homogenized, index, columns)
-    return BlockManager(blocks, index, columns)
-
 def _form_blocks(data, index, columns):
     from pandas.core.internals import add_na_columns
 
@@ -706,7 +731,7 @@ def _simple_blockify(dct, dtype):
 
 def _stack_dict(dct):
     columns = Index(_try_sort(dct))
-    stacked = np.vstack([dct[k] for k in columns]).T
+    stacked = np.vstack([dct[k].values for k in columns]).T
     return columns, stacked
 
 def _float_blockify(dct, index, columns):
@@ -724,34 +749,6 @@ def _float_blockify(dct, index, columns):
     # do something with dtype?
     return make_block(values, columns)
 
-def _init_matrix(values, index, columns, dtype):
-    values = _prep_ndarray(values)
-
-    if values.ndim == 1:
-        N = values.shape[0]
-        if N == 0:
-            values = values.reshape((values.shape[0], 0))
-        else:
-            values = values.reshape((values.shape[0], 1))
-
-    if dtype is not None:
-        try:
-            values = values.astype(dtype)
-        except Exception:
-            pass
-
-    N, K = values.shape
-
-    if index is None:
-        index = _default_index(N)
-
-    if columns is None:
-        columns = _default_index(K)
-
-    columns = _ensure_index(columns)
-    block = make_block(values, columns)
-    return BlockManager([block], index, columns)
-
 def _reorder_columns(mat, current, desired):
     indexer, mask = common.get_indexer(current, desired, None)
     return mat.take(indexer[mask], axis=1)
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 5482f55a1..ebb5c64fc 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1932,7 +1932,7 @@ def _get_combined_columns(frames, intersect=False):
         combine = set.union
 
     for _, frame in frames.iteritems():
-        this_cols = set(frame.cols())
+        this_cols = set(frame.columns)
 
         if columns is None:
             columns = this_cols
diff --git a/pandas/core/sparse.py b/pandas/core/sparse.py
index 303f121e4..bf2ab60cc 100644
--- a/pandas/core/sparse.py
+++ b/pandas/core/sparse.py
@@ -574,9 +574,10 @@ class SparseDataFrame(DataFrame):
             columns = _ensure_index(columns)
             data = dict((k, v) for k, v in data.iteritems() if k in columns)
         else:
-            columns = Index(try_sort(data.keys()))
+            columns = Index(_try_sort(data.keys()))
 
-        index = extract_index(data, index)
+        if index is None:
+            index = extract_index(data)
 
         sp_maker = lambda x: SparseSeries(x, index=index,
                                           kind=self.default_kind,
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 3bb48c04c..0b4111507 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -387,7 +387,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         frame = self.klass(mat, columns=['A', 'B', 'C'], index=[1, 2])
 
         self.assertEqual(len(frame.index), 2)
-        self.assertEqual(len(frame.cols()), 3)
+        self.assertEqual(len(frame.columns), 3)
 
         # cast type
         frame = self.klass(mat, columns=['A', 'B', 'C'],
@@ -397,7 +397,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # 1-D input
         frame = self.klass(np.zeros(3), columns=['A'], index=[1, 2, 3])
         self.assertEqual(len(frame.index), 3)
-        self.assertEqual(len(frame.cols()), 1)
+        self.assertEqual(len(frame.columns), 1)
 
         frame = self.klass(['foo', 'bar'], index=[0, 1], columns=['A'])
         self.assertEqual(len(frame), 2)
@@ -416,10 +416,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # automatic labeling
         frame = self.klass(mat)
         self.assert_(np.array_equal(frame.index, range(2)))
-        self.assert_(np.array_equal(frame.cols(), range(3)))
+        self.assert_(np.array_equal(frame.columns, range(3)))
 
         frame = self.klass(mat, index=[1, 2])
-        self.assert_(np.array_equal(frame.cols(), range(3)))
+        self.assert_(np.array_equal(frame.columns, range(3)))
 
         frame = self.klass(mat, columns=['A', 'B', 'C'])
         self.assert_(np.array_equal(frame.index, range(2)))
@@ -429,7 +429,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assert_(frame.index is NULL_INDEX)
 
         frame = self.klass(np.empty((3, 0)))
-        self.assert_(len(frame.cols()) == 0)
+        self.assert_(len(frame.columns) == 0)
 
     def test_constructor_corner(self):
         df = self.klass(index=[])
@@ -603,14 +603,14 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assert_('foo' not in self.frame)
 
     def test_iter(self):
-        self.assert_(common.equalContents(list(self.frame), self.frame.cols()))
+        self.assert_(common.equalContents(list(self.frame), self.frame.columns))
 
     def test_len(self):
         self.assertEqual(len(self.frame), len(self.frame.index))
 
     def test_operators(self):
         garbage = random.random(4)
-        colSeries = Series(garbage, index=np.array(self.frame.cols()))
+        colSeries = Series(garbage, index=np.array(self.frame.columns))
 
         idSum = self.frame + self.frame
         seriesSum = self.frame + colSeries
@@ -823,7 +823,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         assert_frame_equal(self.tsframe, recons)
 
         recons = self.klass.fromcsv(path, index_col=None)
-        assert(len(recons.cols()) == len(self.tsframe.cols()) + 1)
+        assert(len(recons.columns) == len(self.tsframe.columns) + 1)
 
 
         # no index
@@ -846,19 +846,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
     def test_rows(self):
         self.assert_(self.tsframe.rows() is self.tsframe.index)
 
-    def test_cols(self):
-        cols = self.tsframe.cols()
-        self.assert_(isinstance(cols, list))
-        self.assert_(np.array_equal(self.tsframe.columns, cols))
-
-        mcols = self.mixed_frame.cols()
-
-        if hasattr(self.mixed_frame, 'objects'):
-            self.assert_(not np.array_equal(self.mixed_frame.columns,
-                                            mcols))
-        else:
-            self.assert_(np.array_equal(self.mixed_frame.columns, mcols))
-
     def test_columns(self):
         pass
 
@@ -925,7 +912,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         mat = frame.asMatrix()
         smallerCols = ['C', 'A']
 
-        frameCols = frame.cols()
+        frameCols = frame.columns
         for i, row in enumerate(mat):
             for j, value in enumerate(row):
                 col = frameCols[j]
@@ -1115,7 +1102,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
     def test_reindex(self):
         newFrame = self.frame.reindex(self.ts1.index)
 
-        for col in newFrame.cols():
+        for col in newFrame.columns:
             for idx, val in newFrame[col].iteritems():
                 if idx in self.frame.index:
                     if np.isnan(val):
@@ -1133,7 +1120,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # Cython code should be unit-tested directly
         nonContigFrame = self.frame.reindex(self.ts1.index[::2])
 
-        for col in nonContigFrame.cols():
+        for col in nonContigFrame.columns:
             for idx, val in nonContigFrame[col].iteritems():
                 if idx in self.frame.index:
                     if np.isnan(val):
@@ -1156,7 +1143,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # length zero
         newFrame = self.frame.reindex([])
         self.assert_(not newFrame)
-        self.assertEqual(len(newFrame.cols()), len(self.frame.cols()))
+        self.assertEqual(len(newFrame.columns), len(self.frame.columns))
 
         # pass non-Index
         newFrame = self.frame.reindex(list(self.ts1.index))
@@ -1342,7 +1329,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # aggregate
         aggregated = grouped.aggregate(np.mean)
         self.assertEqual(len(aggregated), 5)
-        self.assertEqual(len(aggregated.cols()), 4)
+        self.assertEqual(len(aggregated.columns), 4)
 
         # by string
         tscopy = self.tsframe.copy()
@@ -1354,7 +1341,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # transform
         transformed = grouped.transform(lambda x: x - x.mean())
         self.assertEqual(len(transformed), 30)
-        self.assertEqual(len(transformed.cols()), 4)
+        self.assertEqual(len(transformed.columns), 4)
 
         # transform propagate
         transformed = grouped.transform(lambda x: x.mean())
@@ -1384,7 +1371,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         # aggregate
         aggregated = grouped.aggregate(np.mean)
         self.assertEqual(len(aggregated), len(self.tsframe))
-        self.assertEqual(len(aggregated.cols()), 2)
+        self.assertEqual(len(aggregated.columns), 2)
 
         # transform
         tf = lambda x: x - x.mean()
@@ -1393,7 +1380,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         # iterate
         for k, v in grouped:
-            self.assertEqual(len(v.cols()), 2)
+            self.assertEqual(len(v.columns), 2)
 
         # tgroupby
         grouping = {
@@ -1405,13 +1392,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         grouped = self.frame.tgroupby(grouping.get, np.mean)
         self.assertEqual(len(grouped), len(self.frame.index))
-        self.assertEqual(len(grouped.cols()), 2)
+        self.assertEqual(len(grouped.columns), 2)
 
     def test_filter(self):
         # items
 
         filtered = self.frame.filter(['A', 'B', 'E'])
-        self.assertEqual(len(filtered.cols()), 2)
+        self.assertEqual(len(filtered.columns), 2)
         self.assert_('E' not in filtered)
 
         # like
@@ -1419,12 +1406,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         fcopy['AA'] = 1
 
         filtered = fcopy.filter(like='A')
-        self.assertEqual(len(filtered.cols()), 2)
+        self.assertEqual(len(filtered.columns), 2)
         self.assert_('AA' in filtered)
 
         # regex
         filtered = fcopy.filter(regex='[A]+')
-        self.assertEqual(len(filtered.cols()), 2)
+        self.assertEqual(len(filtered.columns), 2)
         self.assert_('AA' in filtered)
 
         # pass in None
@@ -1445,7 +1432,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         combined = head.combineFirst(tail)
         reordered_frame = self.frame.reindex(combined.index)
         assert_frame_equal(combined, reordered_frame)
-        self.assert_(common.equalContents(combined.cols(), self.frame.cols()))
+        self.assert_(common.equalContents(combined.columns, self.frame.columns))
         assert_series_equal(combined['A'], reordered_frame['A'])
 
         # same index
@@ -1511,7 +1498,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
 
         combined = frame1.combineFirst(frame2)
-        self.assertEqual(len(combined.cols()), 5)
+        self.assertEqual(len(combined.columns), 5)
 
     def test_combineAdd(self):
         # trivial
@@ -1554,15 +1541,15 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         joined = f.join(f2)
         self.assert_(f.index.equals(joined.index))
-        self.assertEqual(len(joined.cols()), 4)
+        self.assertEqual(len(joined.columns), 4)
 
         joined = f.join(f2, how='left')
         self.assert_(joined.index.equals(f.index))
-        self.assertEqual(len(joined.cols()), 4)
+        self.assertEqual(len(joined.columns), 4)
 
         joined = f.join(f2, how='right')
         self.assert_(joined.index.equals(f2.index))
-        self.assertEqual(len(joined.cols()), 4)
+        self.assertEqual(len(joined.columns), 4)
 
         # corner case
         self.assertRaises(Exception, self.frame.join, self.frame,
@@ -1575,7 +1562,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         joined = f.join(f2, how='inner')
         self.assert_(joined.index.equals(f.index.intersection(f2.index)))
-        self.assertEqual(len(joined.cols()), 4)
+        self.assertEqual(len(joined.columns), 4)
 
         # corner case
         self.assertRaises(Exception, self.frame.join, self.frame,
@@ -1588,7 +1575,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
 
         joined = f.join(f2, how='outer')
         self.assert_(common.equalContents(self.frame.index, joined.index))
-        self.assertEqual(len(joined.cols()), 4)
+        self.assertEqual(len(joined.columns), 4)
 
         # corner case
         self.assertRaises(Exception, self.frame.join, self.frame,
@@ -1704,7 +1691,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
     def test_sum_object(self):
         values = self.frame.values.astype(int)
         frame = self.klass(values, index=self.frame.index,
-                           columns=self.frame.cols())
+                           columns=self.frame.columns)
         deltas = frame * timedelta(1)
         deltas.sum()
 
@@ -1726,7 +1713,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         the_mean = self.mixed_frame.mean(axis=0)
         the_sum = self.mixed_frame.sum(axis=0, numeric_only=True)
         self.assert_(the_sum.index.equals(the_mean.index))
-        self.assert_(len(the_mean.index) < len(self.mixed_frame.cols()))
+        self.assert_(len(the_mean.index) < len(self.mixed_frame.columns))
 
     def test_median(self):
         def f(x):
diff --git a/pandas/core/tests/test_matrix.py b/pandas/core/tests/test_matrix.py
index ea8b18038..5c31ed358 100644
--- a/pandas/core/tests/test_matrix.py
+++ b/pandas/core/tests/test_matrix.py
@@ -202,15 +202,15 @@ class TestDataMatrix(test_frame.TestDataFrame):
         uncoercable_series = Series(['foo', 'bzr', 'baz'], index=range(3))
 
         dm[0] = np.ones(3)
-        self.assertEqual(len(dm.cols()), 3)
+        self.assertEqual(len(dm.columns), 3)
         # self.assert_(dm.objects is None)
 
         dm[1] = coercable_series
-        self.assertEqual(len(dm.cols()), 3)
+        self.assertEqual(len(dm.columns), 3)
         # self.assert_(dm.objects is None)
 
         dm[2] = uncoercable_series
-        self.assertEqual(len(dm.cols()), 3)
+        self.assertEqual(len(dm.columns), 3)
         # self.assert_(dm.objects is not None)
         self.assert_(dm[2].dtype == np.object_)
 
@@ -232,7 +232,7 @@ class TestDataMatrix(test_frame.TestDataFrame):
 
     def test_more_asMatrix(self):
         values = self.mixed_frame.asMatrix()
-        self.assertEqual(values.shape[1], len(self.mixed_frame.cols()))
+        self.assertEqual(values.shape[1], len(self.mixed_frame.columns))
 
     def test_reindex_boolean(self):
         frame = DataMatrix(np.ones((10, 2), dtype=bool),
diff --git a/pandas/core/tests/test_panel.py b/pandas/core/tests/test_panel.py
index a57c0d85b..2387504e2 100644
--- a/pandas/core/tests/test_panel.py
+++ b/pandas/core/tests/test_panel.py
@@ -706,7 +706,6 @@ class TestLongPanel(unittest.TestCase):
 
     def test_columns(self):
         self.assert_(np.array_equal(self.panel.items, self.panel.columns))
-        self.assert_(np.array_equal(self.panel.items, self.panel.cols()))
 
     def test_copy(self):
         thecopy = self.panel.copy()
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index bf9790bfd..4c8f08e86 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -86,8 +86,7 @@ def _process_data_structure(arg, kill_inf=True):
     if isinstance(arg, DataFrame):
         if isinstance(arg, DataMatrix):
             return_hook = lambda v: DataMatrix(v, index=arg.index,
-                                               columns=arg.columns,
-                                               objects=arg.objects)
+                                               columns=arg.columns)
         else:
             return_hook = lambda v: DataFrame(v, index=arg.index,
                                               columns=arg.columns)
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index 27609d70e..a57bea92f 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -101,7 +101,7 @@ class OLS(object):
     @cache_readonly
     def beta(self):
         """Returns the betas in Series form."""
-        return Series(self._beta_raw, index=self._x.cols())
+        return Series(self._beta_raw, index=self._x.columns)
 
     @cache_readonly
     def _df_raw(self):
@@ -547,7 +547,7 @@ class MovingOLS(OLS):
         """Returns the betas in Series/DataMatrix form."""
         return DataMatrix(self._beta_raw,
                           index=self._result_index,
-                          columns=self._x.cols())
+                          columns=self._x.columns)
 
     @cache_readonly
     def rank(self):
@@ -591,7 +591,7 @@ class MovingOLS(OLS):
     @cache_readonly
     def p_value(self):
         """Returns the p values."""
-        cols = self.beta.cols()
+        cols = self.beta.columns
         return DataMatrix(self._p_value_raw, columns=cols,
                           index=self._result_index)
 
@@ -621,13 +621,13 @@ class MovingOLS(OLS):
     @cache_readonly
     def std_err(self):
         """Returns the standard err values."""
-        return DataMatrix(self._std_err_raw, columns=self.beta.cols(),
+        return DataMatrix(self._std_err_raw, columns=self.beta.columns,
                           index=self._result_index)
 
     @cache_readonly
     def t_stat(self):
         """Returns the t-stat value."""
-        return DataMatrix(self._t_stat_raw, columns=self.beta.cols(),
+        return DataMatrix(self._t_stat_raw, columns=self.beta.columns,
                           index=self._result_index)
 
     @cache_readonly
@@ -636,8 +636,8 @@ class MovingOLS(OLS):
         result = {}
         result_index = self._result_index
         for i in xrange(len(self._var_beta_raw)):
-            dm = DataMatrix(self._var_beta_raw[i], columns=self.beta.cols(),
-                            index=self.beta.cols())
+            dm = DataMatrix(self._var_beta_raw[i], columns=self.beta.columns,
+                            index=self.beta.columns)
             result[result_index[i]] = dm
 
         return WidePanel.fromDict(result, intersect=False)
@@ -682,7 +682,7 @@ class MovingOLS(OLS):
 
     def _calc_betas(self, x, y):
         N = len(self._index)
-        K = len(self._x.cols())
+        K = len(self._x.columns)
 
         betas = np.empty((N, K), dtype=float)
         betas[:] = np.NaN
@@ -735,7 +735,7 @@ class MovingOLS(OLS):
 
     def _cum_xx(self, x):
         dates = self._index
-        K = len(x.cols())
+        K = len(x.columns)
         valid = self._time_has_obs
         cum_xx = []
 
@@ -782,7 +782,7 @@ class MovingOLS(OLS):
         else:
             y_slicer = lambda s, dt: _y_converter(s.truncate(dt, dt))
 
-        last = np.zeros(len(x.cols()))
+        last = np.zeros(len(x.columns))
         for i, date in enumerate(dates):
             if not valid[i]:
                 cum_xy.append(last)
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index 3833854eb..7ea486197 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -334,9 +334,12 @@ class TestPanelOLS(BaseTest):
                             nw_overlap=True)
 
     def testRollingWithWeights(self):
-        weights = self.panel_y.copy()
+        idx = self.panel_y.index
+        cols = self.panel_y.columns
 
-        weights.values = np.random.standard_normal(weights.values.shape)
+
+        weights = DataMatrix(np.random.standard_normal((len(idx), len(cols))),
+                             index=idx, columns=cols)
         self.checkMovingOLS(self.panel_x,
                             self.panel_y, weights=weights)
 
diff --git a/refactor_notes.txt b/refactor_notes.txt
index d268dc91f..20b9d9620 100644
--- a/refactor_notes.txt
+++ b/refactor_notes.txt
@@ -1,3 +1,4 @@
+
 - Do blocks care about dtype?
   - No, I guess
 - C-contiguousness
@@ -9,6 +10,7 @@
 - Casting, want to continue to support?
 - Column ordering during consolidation
 - Different index passed with BlockManager
+- Set values attribute? Way to hack it? Should I?
 
 - Need sparse internal data structure
 
@@ -28,6 +30,8 @@ TODO
 - transpose with blocks
 - pickling w/ backwards compat
 
+extract_index--pass index! sparse breaking
+
 Mixed type handling
 -------------------
 
