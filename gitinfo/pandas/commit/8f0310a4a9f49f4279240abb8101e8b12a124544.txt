commit 8f0310a4a9f49f4279240abb8101e8b12a124544
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Wed Dec 4 06:06:39 2019 -0800

    Make kwargs explicit in put, append (#29957)

diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 1144a1f7d..ea73241e5 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -2413,9 +2413,13 @@ class NDFrame(PandasObject, SelectionMixin):
         complib: Optional[str] = None,
         append: bool_t = False,
         format: Optional[str] = None,
+        index: bool_t = True,
+        min_itemsize: Optional[Union[int, Dict[str, int]]] = None,
+        nan_rep=None,
+        dropna: Optional[bool_t] = None,
+        data_columns: Optional[List[str]] = None,
         errors: str = "strict",
         encoding: str = "UTF-8",
-        **kwargs,
     ):
         """
         Write the contained data to an HDF5 file using HDFStore.
@@ -2472,15 +2476,16 @@ class NDFrame(PandasObject, SelectionMixin):
             See the errors argument for :func:`open` for a full list
             of options.
         encoding : str, default "UTF-8"
+        min_itemsize : dict or int, optional
+            Map column names to minimum string sizes for columns.
+        nan_rep : Any, optional
+            How to represent null values as str.
+            Not allowed with append=True.
         data_columns : list of columns or True, optional
             List of columns to create as indexed data columns for on-disk
             queries, or True to use all columns. By default only the axes
             of the object are indexed. See :ref:`io.hdf5-query-data-columns`.
             Applicable only to format='table'.
-        fletcher32 : bool, default False
-            If applying compression use the fletcher32 checksum.
-        dropna : bool, default False
-            If true, ALL nan rows will not be written to store.
 
         See Also
         --------
@@ -2531,9 +2536,13 @@ class NDFrame(PandasObject, SelectionMixin):
             complib=complib,
             append=append,
             format=format,
+            index=index,
+            min_itemsize=min_itemsize,
+            nan_rep=nan_rep,
+            dropna=dropna,
+            data_columns=data_columns,
             errors=errors,
             encoding=encoding,
-            **kwargs,
         )
 
     def to_msgpack(self, path_or_buf=None, encoding="utf-8", **kwargs):
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 37196c54d..fca1d3265 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -260,19 +260,41 @@ def to_hdf(
     complib: Optional[str] = None,
     append: bool = False,
     format: Optional[str] = None,
+    index: bool = True,
+    min_itemsize: Optional[Union[int, Dict[str, int]]] = None,
+    nan_rep=None,
+    dropna: Optional[bool] = None,
+    data_columns: Optional[List[str]] = None,
     errors: str = "strict",
     encoding: str = "UTF-8",
-    **kwargs,
 ):
     """ store this object, close it if we opened it """
 
     if append:
         f = lambda store: store.append(
-            key, value, format=format, errors=errors, encoding=encoding, **kwargs
+            key,
+            value,
+            format=format,
+            index=index,
+            min_itemsize=min_itemsize,
+            nan_rep=nan_rep,
+            dropna=dropna,
+            data_columns=data_columns,
+            errors=errors,
+            encoding=encoding,
         )
     else:
+        # NB: dropna is not passed to `put`
         f = lambda store: store.put(
-            key, value, format=format, errors=errors, encoding=encoding, **kwargs
+            key,
+            value,
+            format=format,
+            index=index,
+            min_itemsize=min_itemsize,
+            nan_rep=nan_rep,
+            data_columns=data_columns,
+            errors=errors,
+            encoding=encoding,
         )
 
     path_or_buf = _stringify_path(path_or_buf)
@@ -984,7 +1006,21 @@ class HDFStore:
 
         return it.get_result(coordinates=True)
 
-    def put(self, key: str, value: FrameOrSeries, format=None, append=False, **kwargs):
+    def put(
+        self,
+        key: str,
+        value: FrameOrSeries,
+        format=None,
+        index=True,
+        append=False,
+        complib=None,
+        complevel: Optional[int] = None,
+        min_itemsize: Optional[Union[int, Dict[str, int]]] = None,
+        nan_rep=None,
+        data_columns: Optional[List[str]] = None,
+        encoding=None,
+        errors: str = "strict",
+    ):
         """
         Store object in HDFStore.
 
@@ -1014,7 +1050,20 @@ class HDFStore:
         if format is None:
             format = get_option("io.hdf.default_format") or "fixed"
         format = self._validate_format(format)
-        self._write_to_group(key, value, format=format, append=append, **kwargs)
+        self._write_to_group(
+            key,
+            value,
+            format=format,
+            index=index,
+            append=append,
+            complib=complib,
+            complevel=complevel,
+            min_itemsize=min_itemsize,
+            nan_rep=nan_rep,
+            data_columns=data_columns,
+            encoding=encoding,
+            errors=errors,
+        )
 
     def remove(self, key: str, where=None, start=None, stop=None):
         """
@@ -1075,10 +1124,20 @@ class HDFStore:
         key: str,
         value: FrameOrSeries,
         format=None,
+        axes=None,
+        index=True,
         append=True,
+        complib=None,
+        complevel: Optional[int] = None,
         columns=None,
+        min_itemsize: Optional[Union[int, Dict[str, int]]] = None,
+        nan_rep=None,
+        chunksize=None,
+        expectedrows=None,
         dropna: Optional[bool] = None,
-        **kwargs,
+        data_columns: Optional[List[str]] = None,
+        encoding=None,
+        errors: str = "strict",
     ):
         """
         Append to Table in file. Node must already exist and be Table
@@ -1125,7 +1184,22 @@ class HDFStore:
             format = get_option("io.hdf.default_format") or "table"
         format = self._validate_format(format)
         self._write_to_group(
-            key, value, format=format, append=append, dropna=dropna, **kwargs
+            key,
+            value,
+            format=format,
+            axes=axes,
+            index=index,
+            append=append,
+            complib=complib,
+            complevel=complevel,
+            min_itemsize=min_itemsize,
+            nan_rep=nan_rep,
+            chunksize=chunksize,
+            expectedrows=expectedrows,
+            dropna=dropna,
+            data_columns=data_columns,
+            encoding=encoding,
+            errors=errors,
         )
 
     def append_to_multiple(
@@ -1586,7 +1660,7 @@ class HDFStore:
         complib=None,
         complevel: Optional[int] = None,
         fletcher32=None,
-        min_itemsize=None,
+        min_itemsize: Optional[Union[int, Dict[str, int]]] = None,
         chunksize=None,
         expectedrows=None,
         dropna=False,
