commit 099520871736ad741904d9f65c255831e526e9db
Author: jreback <jeff@reback.net>
Date:   Sun Mar 17 18:47:20 2013 +0200

    CLN: csv refactor

diff --git a/pandas/core/common.py b/pandas/core/common.py
index aff9001f2..207ed2eda 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -101,29 +101,6 @@ def _isnull_old(obj):
 
 _isnull = _isnull_new
 
-# float format is a bit of out of place here,
-# but we'd like to reuse the mask.
-def _ndarray_to_native_types(v,na_rep='',float_format=None):
-    mask = isnull(v)
-    imask = -mask
-
-    if v.dtype == 'datetime64[ns]' or v.dtype == 'timedelta64[ns]':
-        values = np.empty(len(v),dtype=object)
-        values[mask] = 'NaT'
-        if v.dtype == 'datetime64[ns]':
-            values[imask] = np.array([ val._repr_base for val in v[imask] ],dtype=object)
-        elif v.dtype == 'timedelta64[ns]':
-            values[imask] = np.array([ lib.repr_timedelta64(val) for val in v[imask] ],dtype=object)
-    else:
-        if hasattr(v,"values"):
-            v= v.values
-        values = np.array(v,dtype=object)
-        values[mask] = na_rep
-        if issubclass(v.dtype.type,np.floating):
-            if float_format:
-                values[imask] = np.array([ float_format % val for val in v[imask] ])
-    return values.tolist()
-
 def _use_inf_as_null(key):
     '''Option change callback for null/inf behaviour
     Choose which replacement for numpy.isnan / -numpy.isfinite is used.
diff --git a/pandas/core/format.py b/pandas/core/format.py
index 003b1fefd..644c08b6b 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -9,7 +9,7 @@ except:
     from io import StringIO
 
 from pandas.core.common import adjoin, isnull, notnull
-from pandas.core.index import MultiIndex, _ensure_index
+from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.util import py3compat
 from pandas.core.config import get_option, set_option, reset_option
 import pandas.core.common as com
@@ -18,6 +18,7 @@ import pandas.lib as lib
 import numpy as np
 
 import itertools
+import csv
 
 from pandas.tseries.period import PeriodIndex
 
@@ -763,6 +764,164 @@ def _get_level_lengths(levels):
     return result
 
 
+class CSVFormatter(object):
+
+    def __init__(self, obj, path_or_buf, sep=",", na_rep='', float_format=None,
+               cols=None, header=True, index=True, index_label=None,
+               mode='w', nanRep=None, encoding=None, quoting=None,
+               line_terminator='\n', chunksize=None):
+
+        self.obj = obj
+        self.path_or_buf = path_or_buf
+        self.sep = sep
+        self.na_rep = na_rep
+        self.float_format = float_format
+
+        self.header = header
+        self.index = index
+        self.index_label = index_label
+        self.mode = mode
+        self.encoding = encoding
+
+        if quoting is None:
+            quoting = csv.QUOTE_MINIMAL
+        self.quoting = quoting
+
+        self.line_terminator = line_terminator
+
+        if cols is None:
+            cols = obj.columns
+
+        if isinstance(cols,Index):
+            cols = cols.to_native_types(na_rep=na_rep,float_format=float_format)
+        else:
+            cols=list(cols)
+        self.cols = cols
+        self.colname_map = dict((k,i) for i,k in  enumerate(obj.columns))
+
+        if chunksize is None:
+            chunksize = (100000/ (len(self.cols) or 1)) or 1
+        self.chunksize = chunksize
+
+        self.data_index = obj.index
+        if isinstance(obj.index, PeriodIndex):
+            self.data_index = obj.index.to_timestamp()
+
+        self.nlevels = getattr(self.data_index, 'nlevels', 1)
+        if not index:
+            self.nlevels = 0
+
+    def save(self):
+
+        # create the writer & save
+        if hasattr(self.path_or_buf, 'read'):
+            f = self.path_or_buf
+            close = False
+        else:
+            f = com._get_handle(self.path_or_buf, self.mode, encoding=self.encoding)
+            close = True
+
+        try:
+            if self.encoding is not None:
+                self.writer = com.UnicodeWriter(f, lineterminator=self.line_terminator,
+                                                delimiter=self.sep, encoding=self.encoding,
+                                                quoting=self.quoting)
+            else:
+                self.writer = csv.writer(f, lineterminator=self.line_terminator,
+                                         delimiter=self.sep, quoting=self.quoting)
+                
+            self._save()
+
+        finally:
+            if close:
+                f.close()
+
+    def _save_header(self):
+
+        writer = self.writer
+        obj = self.obj
+        index_label = self.index_label
+        cols = self.cols
+        header = self.header
+
+        has_aliases = isinstance(header, (tuple, list, np.ndarray))
+        if has_aliases or self.header:
+            if self.index:
+                # should write something for index label
+                if index_label is not False:
+                    if index_label is None:
+                        if isinstance(obj.index, MultiIndex):
+                            index_label = []
+                            for i, name in enumerate(obj.index.names):
+                                if name is None:
+                                    name = ''
+                                index_label.append(name)
+                        else:
+                            index_label = obj.index.name
+                            if index_label is None:
+                                index_label = ['']
+                            else:
+                                index_label = [index_label]
+                    elif not isinstance(index_label, (list, tuple, np.ndarray)):
+                        # given a string for a DF with Index
+                        index_label = [index_label]
+
+                    encoded_labels = list(index_label)
+                else:
+                    encoded_labels = []
+
+                if has_aliases:
+                    if len(header) != len(cols):
+                        raise ValueError(('Writing %d cols but got %d aliases'
+                                          % (len(cols), len(header))))
+                    else:
+                        write_cols = header
+                else:
+                    write_cols = cols
+                encoded_cols = list(write_cols)
+
+                writer.writerow(encoded_labels + encoded_cols)
+            else:
+                encoded_cols = list(cols)
+                writer.writerow(encoded_cols)
+
+    def _save(self):
+
+        self._save_header()
+
+        nrows = len(self.data_index)
+
+        # write in chunksize bites
+        chunksize = self.chunksize
+        chunks = int(nrows / chunksize)+1
+
+        for i in xrange(chunks):
+            start_i = i * chunksize
+            end_i = min((i + 1) * chunksize, nrows)
+            if start_i >= end_i:
+                break
+
+            self._save_chunk(start_i, end_i)
+
+    def _save_chunk(self, start_i, end_i):
+
+        colname_map = self.colname_map
+        data_index  = self.data_index
+
+        # create the data for a chunk
+        blocks = self.obj._data.blocks
+        data =[None] * sum(len(b.items) for b in blocks)
+        slicer = slice(start_i,end_i)
+        for i in range(len(blocks)):
+            b = blocks[i]
+            d = b.to_native_types(slicer=slicer, na_rep=self.na_rep, float_format=self.float_format)
+            for j, k in enumerate(b.items):
+                data[colname_map[k]] = d[j]
+
+        ix = data_index.to_native_types(slicer=slicer, na_rep=self.na_rep, float_format=self.float_format)
+
+        lib.write_csv_rows(data, ix, self.nlevels, self.cols, self.writer)
+
 # from collections import namedtuple
 # ExcelCell = namedtuple("ExcelCell",
 #                        'row, col, val, style, mergestart, mergeend')
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index e2c053f53..b2dc6715b 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -14,7 +14,6 @@ labeling information
 
 from itertools import izip
 from StringIO import StringIO
-import csv
 import operator
 import sys
 
@@ -24,7 +23,7 @@ import numpy.ma as ma
 
 from pandas.core.common import (isnull, notnull, PandasError, _try_sort,
                                 _default_index, _maybe_upcast, _is_sequence,
-                                _infer_dtype_from_scalar, _ndarray_to_native_types)
+                                _infer_dtype_from_scalar)
 from pandas.core.generic import NDFrame
 from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.core.indexing import (_NDFrameIndexer, _maybe_droplevels,
@@ -1289,101 +1288,6 @@ class DataFrame(NDFrame):
 
     to_wide = deprecate('to_wide', to_panel)
 
-    def _helper_csv(self, writer, na_rep=None, cols=None,
-                    header=True, index=True,
-                    index_label=None, float_format=None,
-                    chunksize=None):
-        if cols is None:
-            cols = self.columns
-
-        if isinstance(cols,np.ndarray):
-            cols = _ndarray_to_native_types(cols,na_rep,float_format)
-        else:
-            cols=list(cols)
-
-        has_aliases = isinstance(header, (tuple, list, np.ndarray))
-        if has_aliases or header:
-            if index:
-                # should write something for index label
-                if index_label is not False:
-                    if index_label is None:
-                        if isinstance(self.index, MultiIndex):
-                            index_label = []
-                            for i, name in enumerate(self.index.names):
-                                if name is None:
-                                    name = ''
-                                index_label.append(name)
-                        else:
-                            index_label = self.index.name
-                            if index_label is None:
-                                index_label = ['']
-                            else:
-                                index_label = [index_label]
-                    elif not isinstance(index_label, (list, tuple, np.ndarray)):
-                        # given a string for a DF with Index
-                        index_label = [index_label]
-
-                    encoded_labels = list(index_label)
-                else:
-                    encoded_labels = []
-
-                if has_aliases:
-                    if len(header) != len(cols):
-                        raise ValueError(('Writing %d cols but got %d aliases'
-                                          % (len(cols), len(header))))
-                    else:
-                        write_cols = header
-                else:
-                    write_cols = cols
-                encoded_cols = list(write_cols)
-
-                writer.writerow(encoded_labels + encoded_cols)
-            else:
-                encoded_cols = list(cols)
-                writer.writerow(encoded_cols)
-
-        data_index = self.index
-        if isinstance(self.index, PeriodIndex):
-            data_index = self.index.to_timestamp()
-
-        nlevels = getattr(data_index, 'nlevels', 1)
-        if not index:
-            nlevels = 0
-
-        nrows = len(data_index)
-
-        # write in chunksize bites
-        if chunksize is None:
-            chunksize = (100000/ (len(cols) or 1)) or 1
-        chunks = int(nrows / chunksize)+1
-
-        for i in xrange(chunks):
-            start_i = i * chunksize
-            end_i = min((i + 1) * chunksize, nrows)
-            if start_i >= end_i:
-                break
-
-            # create the data for a chunk
-            blocks = self._data.blocks
-            data =[None] * sum(len(b.items) for b in blocks)
-            for i in range(len(blocks)):
-                b = blocks[i]
-                v = b.values
-                colname_map = dict((k,i) for i,k in  enumerate(self.columns))
-                if v.dtype == 'datetime64[ns]' or v.dtype == 'timedelta64[ns]':
-                    d = blocks[i].values[:,start_i:end_i]
-                    for j, k in enumerate(b.items):
-                        data[colname_map[k]] = d[j]
-                else:
-                    d = _ndarray_to_native_types(b.values[:,start_i:end_i],  na_rep,float_format)
-                    for j, k in enumerate(b.items):
-                        data[colname_map[k]] = d[j]
-
-            ix = _ndarray_to_native_types(data_index[start_i:end_i],
-                                          na_rep,float_format)
-
-            lib.write_csv_rows(data, ix, nlevels, cols, writer)
-
     def to_csv(self, path_or_buf, sep=",", na_rep='', float_format=None,
                cols=None, header=True, index=True, index_label=None,
                mode='w', nanRep=None, encoding=None, quoting=None,
@@ -1432,33 +1336,15 @@ class DataFrame(NDFrame):
                           FutureWarning)
             na_rep = nanRep
 
-        if hasattr(path_or_buf, 'read'):
-            f = path_or_buf
-            close = False
-        else:
-            f = com._get_handle(path_or_buf, mode, encoding=encoding)
-            close = True
-
-        if quoting is None:
-            quoting = csv.QUOTE_MINIMAL
-
-        try:
-            if encoding is not None:
-                csvout = com.UnicodeWriter(f, lineterminator=line_terminator,
-                                           delimiter=sep, encoding=encoding,
-                                           quoting=quoting)
-            else:
-                csvout = csv.writer(f, lineterminator=line_terminator,
-                                    delimiter=sep, quoting=quoting)
-            self._helper_csv(csvout, na_rep=na_rep,
-                             float_format=float_format, cols=cols,
-                             header=header, index=index,
-                             index_label=index_label,
-                             chunksize=chunksize)
-
-        finally:
-            if close:
-                f.close()
+        formatter = fmt.CSVFormatter(self, path_or_buf, 
+                                     line_terminator=line_terminator,
+                                     sep=sep, encoding=encoding,
+                                     quoting=quoting,na_rep=na_rep,
+                                     float_format=float_format, cols=cols,
+                                     header=header, index=index,
+                                     index_label=index_label,
+                                     chunksize=chunksize)
+        formatter.save()
 
     def to_excel(self, excel_writer, sheet_name='sheet1', na_rep='',
                  float_format=None, cols=None, header=True, index=True,
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 0f9776e20..95e6c40a9 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -441,16 +441,7 @@ class Index(np.ndarray):
             return header + list(self.map(formatter))
 
         if self.is_all_dates:
-            zero_time = time(0, 0)
-            result = []
-            for dt in self:
-                if isnull(dt):
-                    result.append(u'NaT')
-                else:
-                    if dt.time() != zero_time or dt.tzinfo is not None:
-                        return header + [u'%s' % x for x in self]
-                    result.append(u'%d-%.2d-%.2d' % (dt.year, dt.month, dt.day))
-            return header + result
+            return header + _date_formatter(self)
 
         values = self.values
 
@@ -472,6 +463,20 @@ class Index(np.ndarray):
             result = _trim_front(format_array(values, None, justify='left'))
         return header + result
 
+    def to_native_types(self, slicer=None, na_rep='', float_format=None):
+        values = self
+        if slicer is not None:
+            values = values[slicer]
+        mask = isnull(values)
+        values = np.array(values,dtype=object)
+
+        if self.is_all_dates:
+            return _date_formatter(self)
+        else:
+            values[mask] = na_rep
+
+        return values.tolist()
+
     def equals(self, other):
         """
         Determines if two Index objects contain the same elements.
@@ -1481,6 +1486,9 @@ class MultiIndex(Index):
     def __len__(self):
         return len(self.labels[0])
 
+    def to_native_types(self, slicer=None, na_rep='', float_format=None):
+        return self.tolist()
+
     @property
     def _constructor(self):
         return MultiIndex.from_tuples
@@ -2578,6 +2586,22 @@ class MultiIndex(Index):
 
 # For utility purposes
 
+def _date_formatter(obj, na_rep=u'NaT'):
+    data = list(obj)
+
+    # tz formatter or time formatter
+    zero_time = time(0, 0)
+    for d in data:
+        if d.time() != zero_time or d.tzinfo is not None:
+            return [u'%s' % x for x in data ]
+
+    values = np.array(data,dtype=object)
+    mask = isnull(obj.values)
+    values[mask] = na_rep
+
+    imask = -mask
+    values[imask] = np.array([ u'%d-%.2d-%.2d' % (dt.year, dt.month, dt.day) for dt in values[imask] ])
+    return values.tolist()
 
 def _sparsify(label_list, start=0):
     pivoted = zip(*label_list)
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 2a41bbffa..3467b7254 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -4,13 +4,14 @@ from datetime import datetime
 from numpy import nan
 import numpy as np
 
-from pandas.core.common import _possibly_downcast_to_dtype
+from pandas.core.common import isnull, _possibly_downcast_to_dtype
 from pandas.core.index import Index, _ensure_index, _handle_legacy_indexes
 from pandas.core.indexing import _check_slice_bounds, _maybe_convert_indices
 import pandas.core.common as com
 import pandas.lib as lib
 import pandas.tslib as tslib
 
+from pandas.tslib import Timestamp
 from pandas.util import py3compat
 
 
@@ -259,6 +260,17 @@ class Block(object):
         we may have roundtripped thru object in the mean-time """
         return result
 
+    def to_native_types(self, slicer=None, na_rep='', **kwargs):
+        """ convert to our native types format, slicing if desired """
+
+        values = self.values
+        if slicer is not None:
+            values = values[:,slicer]
+        values = np.array(values,dtype=object)
+        mask = isnull(values)
+        values[mask] = na_rep
+        return values.tolist()
+
     def replace(self, to_replace, value, inplace=False):
         new_values = self.values if inplace else self.values.copy()
         if self._can_hold_element(value):
@@ -577,6 +589,20 @@ class FloatBlock(NumericBlock):
         except:  # pragma: no cover
             return element
 
+    def to_native_types(self, slicer=None, na_rep='', float_format=None, **kwargs):
+        """ convert to our native types format, slicing if desired """
+
+        values = self.values
+        if slicer is not None:
+            values = values[:,slicer]
+        values = np.array(values,dtype=object)
+        mask = isnull(values)
+        values[mask] = na_rep
+        if float_format:
+            imask = (-mask).ravel()
+            values.flat[imask] = np.array([ float_format % val for val in values.ravel()[imask] ])
+        return values.tolist()
+
     def should_store(self, value):
         # when inserting a column should not coerce integers to floats
         # unnecessarily
@@ -701,6 +727,25 @@ class DatetimeBlock(Block):
         except:
             return element
 
+    def to_native_types(self, slicer=None, na_rep=None, **kwargs):
+        """ convert to our native types format, slicing if desired """
+
+        values = self.values
+        if slicer is not None:
+            values = values[:,slicer]
+        mask = isnull(values)
+
+        rvalues = np.empty(self.shape,dtype=object)
+        if na_rep is None:
+            na_rep = 'NaT'
+        rvalues[mask] = na_rep
+        imask = (-mask).ravel()
+        if self.dtype == 'datetime64[ns]':
+            rvalues.flat[imask] = np.array([ Timestamp(val)._repr_base for val in values.ravel()[imask] ],dtype=object)
+        elif self.dtype == 'timedelta64[ns]':
+            rvalues.flat[imask] = np.array([ lib.repr_timedelta64(val) for val in values.ravel()[imask] ],dtype=object)
+        return rvalues.tolist()
+
     def should_store(self, value):
         return issubclass(value.dtype.type, np.datetime64)
 
