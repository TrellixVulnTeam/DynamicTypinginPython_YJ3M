commit cca01738ace059964c9a8b9855c2c8a7901d5080
Author: Phillip Cloud <cpcloud@gmail.com>
Date:   Mon Aug 5 14:30:36 2013 -0400

    ENH: add DataFrame.eval method

diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index 794a209b5..ec51887ff 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -11,7 +11,7 @@ from pandas.computation.ops import is_const
 
 
 def _align_core_single_unary_op(term):
-    if isinstance(term.value, np.ndarray) and not com.is_series(term.value):
+    if isinstance(term.value, np.ndarray):
         typ = partial(np.asanyarray, dtype=term.value.dtype)
     else:
         typ = type(term.value)
@@ -67,7 +67,8 @@ def _maybe_promote_shape(values, naxes):
 
 def _any_pandas_objects(terms):
     """Check a sequence of terms for instances of PandasObject."""
-    return any(com.is_pd_obj(term.value) for term in terms)
+    return any(isinstance(term.value, pd.core.generic.PandasObject)
+               for term in terms)
 
 
 def _filter_special_cases(f):
@@ -111,7 +112,7 @@ def _align_core(terms):
 
     for term in (terms[i] for i in term_index):
         for axis, items in enumerate(term.value.axes):
-            if com.is_series(term.value) and naxes > 1:
+            if isinstance(term.value, pd.Series) and naxes > 1:
                 ax, itm = naxes - 1, term.value.index
             else:
                 ax, itm = axis, items
@@ -122,7 +123,7 @@ def _align_core(terms):
             ti = terms[i].value
 
             if hasattr(ti, 'reindex_axis'):
-                transpose = com.is_series(ti) and naxes > 1
+                transpose = isinstance(ti, pd.Series) and naxes > 1
                 reindexer = axes[naxes - 1] if transpose else items
 
                 term_axis_size = len(ti.axes[axis])
@@ -183,7 +184,7 @@ def _align(terms):
         terms = list(com.flatten(terms))
     except TypeError:
         # can't iterate so it must just be a constant or single variable
-        if isinstance(terms.value, (pd.Series, pd.core.generic.NDFrame)):
+        if isinstance(terms.value, pd.core.generic.NDFrame):
             typ = type(terms.value)
             return typ, _zip_axes_from_type(typ, terms.value.axes)
         return np.result_type(terms.type), None
diff --git a/pandas/computation/eval.py b/pandas/computation/eval.py
index cb8af9892..ff0738893 100644
--- a/pandas/computation/eval.py
+++ b/pandas/computation/eval.py
@@ -3,10 +3,8 @@
 import numbers
 import numpy as np
 
-from pandas import compat
 from pandas.compat import string_types
-from pandas.computation.expr import (Expr, _parsers, _ensure_scope,
-                                     _check_syntax)
+from pandas.computation.expr import Expr, _parsers, _ensure_scope
 from pandas.computation.engines import _engines
 
 
@@ -47,12 +45,12 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
     ----------
     expr : string
         The expression to evaluate.
-    parser : string, optional, default 'pandas', {'pandas', 'python'}
+    parser : string, default 'pandas', {'pandas', 'python'}
         The parser to use to construct the syntax tree from the expression. The
         default of 'pandas' parses code slightly different than standard
         Python. See the :ref:`enhancing performance <enhancingperf.eval>`
         documentation for more details.
-    engine : string, optional, default 'numexpr', {'python', 'numexpr'}
+    engine : string, default 'numexpr', {'python', 'numexpr'}
 
         The engine used to evaluate the expression. Supported engines are
 
@@ -62,11 +60,11 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
         - ``'python'``: Performs operations as if you had ``eval``'d in top
                         level python. This engine is generally not that useful.
 
-    truediv : bool, optional, default True
+    truediv : bool, default True
         Whether to use true division, like in Python >= 3
-    local_dict : dict or None, optional, default None
+    local_dict : dict or None, default None
         A dictionary of local variables, taken from locals() by default.
-    global_dict : dict or None, optional, default None
+    global_dict : dict or None, default None
         A dictionary of global variables, taken from globals() by default.
     resolvers : dict of dict-like or None, default None
         A dictionary of dict-like object (specifically they must implement the
@@ -76,7 +74,7 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
         :attr:`~pandas.DataFrame.index` and :attr:`~pandas.DataFrame.columns`
         variables that refer to their respective :class:`~pandas.DataFrame`
         instance attributes.
-    level : int, optional, default 2
+    level : int, default 2
         The number of prior stack frames to traverse and add to the current
         scope.
 
@@ -112,7 +110,8 @@ def eval(expr, parser='pandas', engine='numexpr', truediv=True,
 
     # construct the engine and evaluate
     eng = _engines[engine]
-    ret = eng(parsed_expr).evaluate()
+    eng_inst = eng(parsed_expr)
+    ret = eng_inst.evaluate()
 
     # sanity check for a number if it's a scalar result
     # TODO: eventually take out
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index 5cff96872..1fbc0b722 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -26,12 +26,12 @@ def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
 
 
 def _check_disjoint_resolver_names(resolver_keys, local_keys, global_keys):
-    res_locals = com.intersection(resolver_keys, local_keys)
+    res_locals = list(com.intersection(resolver_keys, local_keys))
     if res_locals:
         msg = "resolvers and locals overlap on names {0}".format(res_locals)
         raise NameResolutionError(msg)
 
-    res_globals = com.intersection(resolver_keys, global_keys)
+    res_globals = list(com.intersection(resolver_keys, global_keys))
     if res_globals:
         msg = "resolvers and globals overlap on names {0}".format(res_globals)
         raise NameResolutionError(msg)
@@ -172,7 +172,9 @@ class Scope(StringMixin):
             raise TypeError("Cannot add value to object of type {0!r}, "
                             "scope must be a dictionary"
                             "".format(d.__class__.__name__))
-        name = 'tmp_var_{0}_{1}'.format(self.ntemps, pd.util.testing.rands(10))
+        name = 'tmp_var_{0}_{1}_{2}'.format(value.__class__.__name__,
+                                            self.ntemps,
+                                            pd.util.testing.rands(10))
         d[name] = value
 
         # only increment if the variable gets put in the scope
@@ -320,18 +322,15 @@ class BaseExprVisitor(ast.NodeVisitor):
         self.preparser = preparser
 
     def visit(self, node, **kwargs):
-        parse = ast.parse
         if isinstance(node, string_types):
             clean = self.preparser(node)
-        elif isinstance(node, ast.AST):
-            clean = node
-        else:
+            node = ast.fix_missing_locations(ast.parse(clean))
+        elif not isinstance(node, ast.AST):
             raise TypeError("Cannot visit objects of type {0!r}"
                             "".format(node.__class__.__name__))
-        node = parse(clean)
 
         method = 'visit_' + node.__class__.__name__
-        visitor = getattr(self, method, None)
+        visitor = getattr(self, method)
         return visitor(node, **kwargs)
 
     def visit_Module(self, node, **kwargs):
@@ -365,11 +364,12 @@ class BaseExprVisitor(ast.NodeVisitor):
         return self.const_type(node.n, self.env)
 
     def visit_Str(self, node, **kwargs):
-        return self.const_type(node.s, self.env)
+        name = self.env.add_tmp(node.s)
+        return self.term_type(name, self.env)
 
     def visit_List(self, node, **kwargs):
-        return self.const_type([self.visit(e).value for e in node.elts],
-                               self.env)
+        name = self.env.add_tmp([self.visit(e).value for e in node.elts])
+        return self.term_type(name, self.env)
 
     visit_Tuple = visit_List
 
@@ -467,7 +467,7 @@ class BaseExprVisitor(ast.NodeVisitor):
         comps = node.comparators
 
         def translate(op):
-            if isinstance(op,ast.In):
+            if isinstance(op, ast.In):
                 return ast.Eq()
             return op
 
@@ -502,8 +502,8 @@ class BaseExprVisitor(ast.NodeVisitor):
         return reduce(visitor, operands)
 
 
-_python_not_supported = frozenset(['Assign', 'Str', 'Tuple', 'List', 'Dict',
-                                   'Call', 'BoolOp'])
+_python_not_supported = frozenset(['Assign', 'Tuple', 'Dict', 'Call',
+                                   'BoolOp'])
 _numexpr_supported_calls = frozenset(_reductions + _mathops)
 
 
@@ -572,9 +572,9 @@ class Expr(StringMixin):
     def check_name_clashes(self):
         env = self.env
         names = self.names
-        res_keys = frozenset(env.resolver_dict.iterkeys()) & names
-        lcl_keys = frozenset(env.locals.iterkeys()) & names
-        gbl_keys = frozenset(env.globals.iterkeys()) & names
+        res_keys = frozenset(env.resolver_dict.keys()) & names
+        lcl_keys = frozenset(env.locals.keys()) & names
+        gbl_keys = frozenset(env.globals.keys()) & names
         _check_disjoint_resolver_names(res_keys, lcl_keys, gbl_keys)
 
     def add_resolvers_to_locals(self):
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index cd59ab292..0ae2d2f28 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -1,6 +1,7 @@
 import re
 import operator as op
 from functools import partial
+from itertools import product, islice, chain
 
 import numpy as np
 
@@ -23,8 +24,12 @@ _TAG_RE = re.compile('^{0}'.format(_LOCAL_TAG))
 
 class UndefinedVariableError(NameError):
     def __init__(self, *args):
-        super(UndefinedVariableError,
-              self).__init__('name {0!r} is not defined'.format(args[0]))
+        msg = 'name {0!r} is not defined'
+        subbed = _TAG_RE.sub('', args[0])
+        if subbed != args[0]:
+            subbed = '@' + subbed
+            msg = 'local variable {0!r} is not defined'
+        super(UndefinedVariableError, self).__init__(msg.format(subbed))
 
 
 class OperatorError(Exception):
@@ -39,6 +44,19 @@ class BinaryOperatorError(OperatorError):
     pass
 
 
+def _possibly_update_key(d, value, old_key, new_key=None):
+    if new_key is None:
+        new_key = old_key
+
+    try:
+        del d[old_key]
+    except KeyError:
+        return False
+    else:
+        d[new_key] = value
+        return True
+
+
 class Term(StringMixin):
     def __init__(self, name, env, side=None, encoding=None):
         self._name = name
@@ -76,37 +94,40 @@ class Term(StringMixin):
         return res
 
     def update(self, value):
+        """
+        search order for local (i.e., @variable) variables:
+
+        scope, key_variable
+        [('locals', 'local_name'),
+         ('globals', 'local_name'),
+         ('locals', 'key'),
+         ('globals', 'key')]
+        """
         env = self.env
         key = self.name
+
+        # if it's a variable name (otherwise a constant)
         if isinstance(key, string_types):
             if self.local:
+                # get it's name WITHOUT the local tag (defined above)
                 local_name = self.local_name
 
-                try:
-                    del env.locals[local_name]
-                    env.locals[key] = value
-                except KeyError:
-                    try:
-                        del env.globals[local_name]
-                        env.globals[key] = value
-                    except KeyError:
-                        try:
-                            del env.locals[key]
-                            env.locals[key] = value
-                        except KeyError:
-                            try:
-                                del env.globals[key]
-                                env.globals[key] = value
-                            except KeyError:
-                                raise UndefinedVariableError(key)
+                # search for the local in the above specified order
+                scope_pairs = product([env.locals, env.globals],
+                                      [local_name, key])
+
+                # a[::2] + a[1::2] but iterators
+                scope_iter = chain(islice(scope_pairs, None, None, 2),
+                                   islice(scope_pairs, 1, None, 2))
+                for d, k in scope_iter:
+                    if _possibly_update_key(d, value, k, key):
+                        break
+                else:
+                    raise UndefinedVariableError(key)
             else:
+                # otherwise we look in resolvers -> locals -> globals
                 for r in (env.resolver_dict, env.locals, env.globals):
-                    try:
-                        del r[key]
-                    except KeyError:
-                        pass
-                    else:
-                        r[key] = value
+                    if _possibly_update_key(r, value, key):
                         break
                 else:
                     raise UndefinedVariableError(key)
@@ -332,7 +353,7 @@ class BinOp(Op):
         lhs, rhs = self.lhs, self.rhs
 
         if (is_term(lhs) and lhs.kind.startswith('datetime') and is_term(rhs)
-            and rhs.isscalar):
+                and rhs.isscalar):
             v = rhs.value
             if isinstance(v, (int, float)):
                 v = stringify(v)
@@ -343,7 +364,7 @@ class BinOp(Op):
             self.rhs.update(v)
 
         if (is_term(rhs) and rhs.kind.startswith('datetime') and
-            is_term(lhs) and lhs.isscalar):
+                is_term(lhs) and lhs.isscalar):
             v = lhs.value
             if isinstance(v, (int, float)):
                 v = stringify(v)
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index 2d9839736..4067c22be 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -348,7 +348,6 @@ class UnaryOp(ops.UnaryOp):
         return None
 
 
-
 _op_classes = {'unary': UnaryOp}
 
 class ExprVisitor(BaseExprVisitor):
@@ -403,6 +402,9 @@ class ExprVisitor(BaseExprVisitor):
 
         raise ValueError("Invalid Attribute context {0}".format(ctx.__name__))
 
+    def translate_In(self, op):
+        return ast.Eq() if isinstance(op, ast.In) else op
+
 
 class Expr(expr.Expr):
 
@@ -449,7 +451,7 @@ class Expr(expr.Expr):
         if isinstance(where, Expr):
 
             lcls.update(where.env.locals)
-            where = str(where)
+            where = where.expr
 
         elif isinstance(where, (list, tuple)):
 
@@ -465,7 +467,7 @@ class Expr(expr.Expr):
         self.env = Scope(lcls=lcls)
         self.env.update(scope_level)
 
-        if queryables is not None:
+        if queryables is not None and isinstance(self.expr, string_types):
             self.env.queryables.update(queryables)
             self._visitor = ExprVisitor(self.env, queryables=queryables,
                                         parser='pytables', engine='pytables',
@@ -506,7 +508,7 @@ class Expr(expr.Expr):
     def __unicode__(self):
         if self.terms is not None:
             return com.pprint_thing(self.terms)
-        return self.expr
+        return com.pprint_thing(self.expr)
 
     def evaluate(self):
         """ create and return the numexpr condition and filter """
@@ -542,3 +544,15 @@ class TermValue(object):
                 return self.converted
             return '"%s"' % self.converted
         return self.converted
+
+
+def maybe_expression(s):
+    """ loose checking if s is a pytables-acceptable expression """
+    if not isinstance(s, string_types):
+        return False
+    ops = ExprVisitor.binary_ops + ExprVisitor.unary_ops + ('=',)
+
+    # make sure we have an op at least
+    return any(op in s for op in ops)
+
+
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index 8a8a04824..df60ce427 100755
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -18,19 +18,23 @@ import pandas as pd
 from pandas.core import common as com
 from pandas import DataFrame, Series, Panel, date_range
 from pandas.util.testing import makeCustomDataframe as mkdf
+
+from pandas.computation import pytables
+from pandas.computation.expressions import _USE_NUMEXPR
 from pandas.computation.engines import _engines
 from pandas.computation.expr import PythonExprVisitor, PandasExprVisitor
 from pandas.computation.ops import (_binary_ops_dict, _unary_ops_dict,
                                     _special_case_arith_ops_syms,
-                                    _arith_ops_syms)
+                                    _arith_ops_syms, _bool_ops_syms)
 import pandas.computation.expr as expr
-from pandas.computation import pytables
-from pandas.computation.expressions import _USE_NUMEXPR
 from pandas.util.testing import (assert_frame_equal, randbool,
                                  assertRaisesRegexp,
                                  assert_produces_warning, assert_series_equal)
 from pandas.compat import PY3, u
 
+_series_frame_incompatible = _bool_ops_syms
+_scalar_skip = 'in', 'not in'
+
 def skip_if_no_ne(engine='numexpr'):
     if not _USE_NUMEXPR and engine == 'numexpr':
         raise nose.SkipTest("numexpr engine not installed or disabled")
@@ -59,13 +63,19 @@ def _eval_single_bin(lhs, cmp1, rhs, engine):
 
 
 def _series_and_2d_ndarray(lhs, rhs):
-    return (com.is_series(lhs) and isinstance(rhs, np.ndarray) and rhs.ndim > 1
-            or com.is_series(rhs) and isinstance(lhs, np.ndarray) and lhs.ndim
-            > 1)
+    return ((isinstance(lhs, Series) and
+             isinstance(rhs, np.ndarray) and rhs.ndim > 1)
+            or (isinstance(rhs, Series) and
+                isinstance(lhs, np.ndarray) and lhs.ndim > 1))
+
+
+def _series_and_frame(lhs, rhs):
+    return ((isinstance(lhs, Series) and isinstance(rhs, DataFrame))
+            or (isinstance(rhs, Series) and isinstance(lhs, DataFrame)))
 
 
 def _bool_and_frame(lhs, rhs):
-    return isinstance(lhs, bool) and com.is_frame(rhs)
+    return isinstance(lhs, bool) and isinstance(rhs, pd.core.generic.NDFrame)
 
 
 def skip_incompatible_operand(f):
@@ -87,6 +97,7 @@ def _is_py3_complex_incompat(result, expected):
 
 _good_arith_ops = com.difference(_arith_ops_syms, _special_case_arith_ops_syms)
 
+
 class TestEvalNumexprPandas(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
@@ -115,10 +126,8 @@ class TestEvalNumexprPandas(unittest.TestCase):
         self.scalar_lhses = randn(), np.float64(randn()), np.nan
         self.scalar_rhses = randn(), np.float64(randn()), np.nan
 
-        self.lhses = self.pandas_lhses + self.scalar_lhses + (randn(10, 5),
-                                                              randn(5))
-        self.rhses = self.pandas_rhses + self.scalar_rhses + (randn(10, 5),
-                                                              randn(5))
+        self.lhses = self.pandas_lhses + self.scalar_lhses
+        self.rhses = self.pandas_rhses + self.scalar_rhses
 
     def setup_ops(self):
         self.cmp_ops = expr._cmp_ops_syms
@@ -191,44 +200,79 @@ class TestEvalNumexprPandas(unittest.TestCase):
     def test_chained_cmp_op(self):
         mids = self.lhses
         cmp_ops = tuple(set(self.cmp_ops) - set(['==', '!=', '<=', '>=']))
-        for lhs, cmp1, mid, cmp2, rhs in product(self.lhses, self.cmp_ops,
+        for lhs, cmp1, mid, cmp2, rhs in product(self.lhses, cmp_ops,
                                                  mids, cmp_ops, self.rhses):
             self.check_chained_cmp_op(lhs, cmp1, mid, cmp2, rhs)
 
-    @skip_incompatible_operand
     def check_complex_cmp_op(self, lhs, cmp1, rhs, binop, cmp2):
+        skip_these = 'in', 'not in'
         ex = '(lhs {cmp1} rhs) {binop} (lhs {cmp2} rhs)'.format(cmp1=cmp1,
                                                                 binop=binop,
                                                                 cmp2=cmp2)
-        lhs_new = _eval_single_bin(lhs, cmp1, rhs, self.engine)
-        rhs_new = _eval_single_bin(lhs, cmp2, rhs, self.engine)
-        expected = _eval_single_bin(lhs_new, binop, rhs_new, self.engine)
-        result = pd.eval(ex, engine=self.engine, parser=self.parser)
-        assert_array_equal(result, expected)
+        scalar_with_in_notin = (np.isscalar(rhs) and (cmp1 in skip_these or
+                                cmp2 in skip_these))
+        if scalar_with_in_notin:
+            self.assertRaises(TypeError, pd.eval, ex, engine=self.engine,
+                              parser=self.parser, local_dict={'lhs': lhs,
+                                                              'rhs': rhs})
+        elif (_series_and_frame(lhs, rhs) and (cmp1 in
+              _series_frame_incompatible or
+              cmp2 in _series_frame_incompatible)):
+            self.assertRaises(TypeError, pd.eval, ex,
+                              local_dict={'lhs': lhs, 'rhs': rhs},
+                              engine=self.engine, parser=self.parser)
+        else:
+            lhs_new = _eval_single_bin(lhs, cmp1, rhs, self.engine)
+            rhs_new = _eval_single_bin(lhs, cmp2, rhs, self.engine)
+            if (isinstance(lhs_new, Series) and isinstance(rhs_new, DataFrame)
+                    and binop in _series_frame_incompatible):
+                pass
+                # TODO: the code below should be added back when left and right
+                # hand side bool ops are fixed.
+
+                #try:
+                    #self.assertRaises(Exception, pd.eval, ex,
+                                    #local_dict={'lhs': lhs, 'rhs': rhs},
+                                    #engine=self.engine, parser=self.parser)
+                #except AssertionError:
+                    #import ipdb; ipdb.set_trace()
+                    #raise
+
+            else:
+                expected = _eval_single_bin(lhs_new, binop, rhs_new, self.engine)
+                result = pd.eval(ex, engine=self.engine, parser=self.parser)
+                assert_array_equal(result, expected)
 
+    @skip_incompatible_operand
     def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
-        # these are not compatible operands
-        if _series_and_2d_ndarray(lhs, mid):
-            self.assertRaises(ValueError, _eval_single_bin, lhs, cmp2, mid,
-                              self.engine)
-        else:
-            lhs_new = _eval_single_bin(lhs, cmp1, mid, self.engine)
+        skip_these = 'in', 'not in'
+
+        def check_operands(left, right, cmp_op):
+            if (np.isscalar(right) and not np.isscalar(left) and cmp_op in
+                    skip_these):
+                self.assertRaises(Exception, _eval_single_bin, left, cmp_op,
+                                  right, self.engine)
+            elif _series_and_2d_ndarray(right, left):
+                self.assertRaises(Exception, _eval_single_bin, right, cmp_op,
+                                  left, self.engine)
+            elif (np.isscalar(right) and np.isscalar(left) and cmp_op in
+                    skip_these):
+                self.assertRaises(Exception, _eval_single_bin, right, cmp_op,
+                                  left, self.engine)
+            else:
+                new = _eval_single_bin(left, cmp_op, right, self.engine)
+                return new
+            return
 
-        if _series_and_2d_ndarray(mid, rhs):
-            self.assertRaises(ValueError, _eval_single_bin, mid, cmp2, rhs,
-                              self.engine)
-        else:
-            rhs_new = _eval_single_bin(mid, cmp2, rhs, self.engine)
+        lhs_new = check_operands(lhs, mid, cmp1)
+        rhs_new = check_operands(mid, rhs, cmp2)
 
-        try:
-            lhs_new
-            rhs_new
-        except NameError:
-            pass
-        else:
+        if lhs_new is not None and rhs_new is not None:
             # these are not compatible operands
-            if (com.is_series(lhs_new) and com.is_frame(rhs_new) or
-                _bool_and_frame(lhs_new, rhs_new)):
+            if isinstance(lhs_new, Series) and isinstance(rhs_new, DataFrame):
+                self.assertRaises(TypeError, _eval_single_bin, lhs_new, '&',
+                                  rhs_new, self.engine)
+            elif (_bool_and_frame(lhs_new, rhs_new)):
                 self.assertRaises(TypeError, _eval_single_bin, lhs_new, '&',
                                   rhs_new, self.engine)
             elif _series_and_2d_ndarray(lhs_new, rhs_new):
@@ -240,7 +284,11 @@ class TestEvalNumexprPandas(unittest.TestCase):
                 ex1 = 'lhs {0} mid {1} rhs'.format(cmp1, cmp2)
                 ex2 = 'lhs {0} mid and mid {1} rhs'.format(cmp1, cmp2)
                 ex3 = '(lhs {0} mid) & (mid {1} rhs)'.format(cmp1, cmp2)
-                expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
+                try:
+                    expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
+                except TypeError:
+                    import ipdb; ipdb.set_trace()
+                    raise
 
                 for ex in (ex1, ex2, ex3):
                     result = pd.eval(ex, engine=self.engine,
@@ -250,9 +298,14 @@ class TestEvalNumexprPandas(unittest.TestCase):
     @skip_incompatible_operand
     def check_simple_cmp_op(self, lhs, cmp1, rhs):
         ex = 'lhs {0} rhs'.format(cmp1)
-        expected = _eval_single_bin(lhs, cmp1, rhs, self.engine)
-        result = pd.eval(ex, engine=self.engine, parser=self.parser)
-        assert_array_equal(result, expected)
+        if cmp1 in ('in', 'not in') and not com.is_list_like(rhs):
+            self.assertRaises(TypeError, pd.eval, ex, engine=self.engine,
+                              parser=self.parser, local_dict={'lhs': lhs,
+                                                              'rhs': rhs})
+        else:
+            expected = _eval_single_bin(lhs, cmp1, rhs, self.engine)
+            result = pd.eval(ex, engine=self.engine, parser=self.parser)
+            assert_array_equal(result, expected)
 
     @skip_incompatible_operand
     def check_binary_arith_op(self, lhs, arith1, rhs):
@@ -360,19 +413,26 @@ class TestEvalNumexprPandas(unittest.TestCase):
 
     @skip_incompatible_operand
     def check_compound_invert_op(self, lhs, cmp1, rhs):
-        # compound
+        skip_these = 'in', 'not in'
         ex = '~(lhs {0} rhs)'.format(cmp1)
-        if np.isscalar(lhs) and np.isscalar(rhs):
-            lhs, rhs = map(lambda x: np.array([x]), (lhs, rhs))
-        expected = ~_eval_single_bin(lhs, cmp1, rhs, self.engine)
-        result = pd.eval(ex, engine=self.engine, parser=self.parser)
-        assert_array_equal(expected, result)
 
-        # make sure the other engines work the same as this one
-        for engine in self.current_engines:
-            skip_if_no_ne(engine)
-            ev = pd.eval(ex, engine=self.engine, parser=self.parser)
-            assert_array_equal(ev, result)
+        if np.isscalar(rhs) and cmp1 in skip_these:
+            self.assertRaises(TypeError, pd.eval, ex, engine=self.engine,
+                              parser=self.parser, local_dict={'lhs': lhs,
+                                                              'rhs': rhs})
+        else:
+            # compound
+            if np.isscalar(lhs) and np.isscalar(rhs):
+                lhs, rhs = map(lambda x: np.array([x]), (lhs, rhs))
+            expected = ~_eval_single_bin(lhs, cmp1, rhs, self.engine)
+            result = pd.eval(ex, engine=self.engine, parser=self.parser)
+            assert_array_equal(expected, result)
+
+            # make sure the other engines work the same as this one
+            for engine in self.current_engines:
+                skip_if_no_ne(engine)
+                ev = pd.eval(ex, engine=self.engine, parser=self.parser)
+                assert_array_equal(ev, result)
 
     @skip_incompatible_operand
     def check_unary_arith_op(self, lhs, arith1, rhs, unary_op):
@@ -461,46 +521,8 @@ class TestEvalPythonPandas(TestEvalPythonPython):
         cls.parser = 'pandas'
 
     def check_chained_cmp_op(self, lhs, cmp1, mid, cmp2, rhs):
-        # these are not compatible operands
-        if _series_and_2d_ndarray(lhs, mid):
-            self.assertRaises(ValueError, _eval_single_bin, lhs, cmp2, mid,
-                              self.engine)
-        else:
-            lhs_new = _eval_single_bin(lhs, cmp1, mid, self.engine)
-
-        if _series_and_2d_ndarray(mid, rhs):
-            self.assertRaises(ValueError, _eval_single_bin, mid, cmp2, rhs,
-                              self.engine)
-        else:
-            rhs_new = _eval_single_bin(mid, cmp2, rhs, self.engine)
-
-        try:
-            lhs_new
-            rhs_new
-        except NameError:
-            pass
-        else:
-            # these are not compatible operands
-            if (com.is_series(lhs_new) and com.is_frame(rhs_new) or
-                _bool_and_frame(lhs_new, rhs_new)):
-                self.assertRaises(TypeError, _eval_single_bin, lhs_new, '&',
-                                  rhs_new, self.engine)
-            elif _series_and_2d_ndarray(lhs_new, rhs_new):
-                # TODO: once #4319 is fixed add this test back in
-                #self.assertRaises(Exception, _eval_single_bin, lhs_new, '&',
-                                  #rhs_new, self.engine)
-                pass
-            else:
-                ex1 = 'lhs {0} mid {1} rhs'.format(cmp1, cmp2)
-                ex2 = 'lhs {0} mid and mid {1} rhs'.format(cmp1, cmp2)
-                ex3 = '(lhs {0} mid) & (mid {1} rhs)'.format(cmp1, cmp2)
-                expected = _eval_single_bin(lhs_new, '&', rhs_new, self.engine)
-
-                for ex in (ex1, ex2, ex3):
-                    result = pd.eval(ex, engine=self.engine,
-                                     parser=self.parser)
-                    assert_array_equal(result, expected)
-
+        TestEvalNumexprPandas.check_chained_cmp_op(self, lhs, cmp1, mid, cmp2,
+                                                   rhs)
 
 
 f = lambda *args, **kwargs: np.random.randn()
@@ -741,24 +763,35 @@ class TestOperationsNumExprPandas(unittest.TestCase):
         ops = expr._arith_ops_syms + expr._cmp_ops_syms
 
         for op in filter(lambda x: x != '//', ops):
-            expec = _eval_single_bin(1, op, 1, self.engine)
-            x = self.eval('1 {0} 1'.format(op))
-            assert_equal(x, expec)
+            ex = '1 {0} 1'.format(op)
+            ex2 = 'x {0} 1'.format(op)
+            ex3 = '1 {0} (x + 1)'.format(op)
 
-            expec = _eval_single_bin(x, op, 1, self.engine)
-            y = self.eval('x {0} 1'.format(op), local_dict={'x': x})
-            assert_equal(y, expec)
+            if op in ('in', 'not in'):
+                self.assertRaises(TypeError, pd.eval, ex,
+                                  engine=self.engine, parser=self.parser)
+            else:
+                expec = _eval_single_bin(1, op, 1, self.engine)
+                x = self.eval(ex, engine=self.engine, parser=self.parser)
+                assert_equal(x, expec)
 
-            expec = _eval_single_bin(1, op, x + 1, self.engine)
-            y = self.eval('1 {0} (x + 1)'.format(op), local_dict={'x': x})
-            assert_equal(y, expec)
+                expec = _eval_single_bin(x, op, 1, self.engine)
+                y = self.eval(ex2, local_dict={'x': x}, engine=self.engine,
+                              parser=self.parser)
+                assert_equal(y, expec)
+
+                expec = _eval_single_bin(1, op, x + 1, self.engine)
+                y = self.eval(ex3, local_dict={'x': x},
+                              engine=self.engine, parser=self.parser)
+                assert_equal(y, expec)
 
     def test_simple_bool_ops(self):
-        for op, lhs, rhs in product(expr._bool_ops_syms, (True, False), (True,
-                                                                        False)):
+        for op, lhs, rhs in product(expr._bool_ops_syms, (True, False),
+                                    (True, False)):
             expec = _eval_single_bin(lhs, op, rhs, self.engine)
             x = self.eval('lhs {0} rhs'.format(op), local_dict={'lhs': lhs,
-                                                                'rhs': rhs})
+                                                                'rhs': rhs},
+                          engine=self.engine, parser=self.parser)
             assert_equal(x, expec)
 
     def test_bool_ops_with_constants(self):
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 8ada14485..c1ff6a220 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -18,12 +18,12 @@ import pandas.algos as algos
 import pandas.lib as lib
 import pandas.tslib as tslib
 from pandas import compat
-from pandas.compat import StringIO, BytesIO, range, long, u, zip, map
+from pandas.compat import (StringIO, BytesIO, range, long, u, zip, map,
+                           string_types)
 from datetime import timedelta
 
 from pandas.core.config import get_option
 from pandas.core import array as pa
-import pandas as pd
 
 class PandasError(Exception):
     pass
@@ -33,14 +33,18 @@ class AmbiguousIndexError(PandasError, KeyError):
     pass
 
 _POSSIBLY_CAST_DTYPES = set([np.dtype(t)
-                            for t in ['M8[ns]', 'm8[ns]', 'O', 'int8', 'uint8', 'int16', 'uint16', 'int32', 'uint32', 'int64', 'uint64']])
+                            for t in ['M8[ns]', 'm8[ns]', 'O', 'int8',
+                                      'uint8', 'int16', 'uint16', 'int32',
+                                      'uint32', 'int64', 'uint64']])
 
 _NS_DTYPE = np.dtype('M8[ns]')
 _TD_DTYPE = np.dtype('m8[ns]')
 _INT64_DTYPE = np.dtype(np.int64)
 _DATELIKE_DTYPES = set([np.dtype(t) for t in ['M8[ns]', 'm8[ns]']])
 
-# define abstract base classes to enable isinstance type checking on our objects
+
+# define abstract base classes to enable isinstance type checking on our
+# objects
 def create_pandas_abc_type(name, attr, comp):
     @classmethod
     def _check(cls, inst):
@@ -50,15 +54,22 @@ def create_pandas_abc_type(name, attr, comp):
     meta = type("ABCBase", (type,), dct)
     return meta(name, tuple(), dct)
 
+
 ABCSeries = create_pandas_abc_type("ABCSeries", "_typ", ("series",))
 ABCDataFrame = create_pandas_abc_type("ABCDataFrame", "_typ", ("dataframe",))
 ABCPanel = create_pandas_abc_type("ABCPanel", "_typ", ("panel",))
-ABCSparseSeries = create_pandas_abc_type("ABCSparseSeries", "_subtyp", ('sparse_series', 'sparse_time_series'))
-ABCSparseArray = create_pandas_abc_type("ABCSparseArray", "_subtyp", ('sparse_array', 'sparse_series'))
+ABCSparseSeries = create_pandas_abc_type("ABCSparseSeries", "_subtyp",
+                                         ('sparse_series',
+                                          'sparse_time_series'))
+ABCSparseArray = create_pandas_abc_type("ABCSparseArray", "_subtyp",
+                                        ('sparse_array', 'sparse_series'))
+
 
 class _ABCGeneric(type):
     def __instancecheck__(cls, inst):
         return hasattr(inst, "_data")
+
+
 ABCGeneric = _ABCGeneric("ABCGeneric", tuple(), {})
 
 def isnull(obj):
@@ -229,6 +240,11 @@ def notnull(obj):
     return -res
 
 
+def _iterable_not_string(x):
+    return (isinstance(x, collections.Iterable) and
+            not isinstance(x, compat.string_types))
+
+
 def flatten(l):
     """Flatten an arbitrarily nested sequence.
 
@@ -246,7 +262,7 @@ def flatten(l):
     flattened : generator
     """
     for el in l:
-        if isinstance(el, collections.Iterable) and not is_string(el):
+        if _iterable_not_string(el):
             for s in flatten(el):
                 yield s
         else:
@@ -1686,30 +1702,6 @@ def is_bool(obj):
     return isinstance(obj, (bool, np.bool_))
 
 
-def is_string(obj):
-    return isinstance(obj, string_types)
-
-
-def is_series(obj):
-    return isinstance(obj, pd.Series)
-
-
-def is_frame(obj):
-    return isinstance(obj, pd.DataFrame)
-
-
-def is_panel(obj):
-    return isinstance(obj, pd.Panel)
-
-
-def is_pd_obj(obj):
-    return isinstance(obj, pd.core.generic.PandasObject)
-
-
-def is_ndframe(obj):
-    return isinstance(obj, pd.core.generic.NDFrame)
-
-
 def is_integer(obj):
     return isinstance(obj, (numbers.Integral, np.integer))
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 5f4c283d6..ed3ecd370 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -35,7 +35,6 @@ from pandas.core.internals import (BlockManager,
                                    create_block_manager_from_arrays,
                                    create_block_manager_from_blocks)
 from pandas.core.series import Series, _radd_compat
-from pandas.sparse.array import SparseArray
 import pandas.computation.expressions as expressions
 from pandas.computation.eval import eval as _eval
 from pandas.computation.expr import maybe_expression, _ensure_scope
@@ -53,13 +52,12 @@ import pandas.core.algorithms as algos
 import pandas.core.datetools as datetools
 import pandas.core.common as com
 import pandas.core.format as fmt
-import pandas.core.generic as generic
 import pandas.core.nanops as nanops
 
 import pandas.lib as lib
 import pandas.algos as _algos
 
-from pandas.core.config import get_option, set_option
+from pandas.core.config import get_option
 
 #----------------------------------------------------------------------
 # Docstring templates
@@ -1963,6 +1961,20 @@ class DataFrame(NDFrame):
         --------
         pandas.eval
         """
+        # need to go up at least 4 stack frames
+        # 4 expr.Scope
+        # 3 expr._ensure_scope
+        # 2 self.eval
+        # 1 self.query
+        # 0 self.query caller (implicit)
+        level = kwargs.setdefault('level', 4)
+        if level < 4:
+            raise ValueError("Going up fewer than 4 stack frames will not"
+                             " capture the necessary variable scope for a "
+                             "query expression")
+        return self[self.eval(expr, **kwargs)]
+
+    def eval(self, expr, **kwargs):
         resolvers = kwargs.pop('resolvers', None)
         if resolvers is None:
             index_resolvers = {}
@@ -1970,9 +1982,9 @@ class DataFrame(NDFrame):
                 index_resolvers[self.index.name] = self.index
             index_resolvers.update({'index': self.index,
                                     'columns': self.columns})
-            resolvers = [self, index_resolvers]
+            resolvers = [index_resolvers, self]
         kwargs['local_dict'] = _ensure_scope(resolvers=resolvers, **kwargs)
-        return self[_eval(expr, **kwargs)]
+        return _eval(expr, **kwargs)
 
     def _slice(self, slobj, axis=0, raise_on_error=False):
         axis = self._get_block_manager_axis(axis)
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 893483f0f..beb398dfe 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -8,7 +8,6 @@ Data structure for 1-dimensional cross-sectional and time series data
 import operator
 from distutils.version import LooseVersion
 import types
-import warnings
 
 from numpy import nan, ndarray
 import numpy as np
@@ -18,8 +17,10 @@ from pandas.core.common import (isnull, notnull, _is_bool_indexer,
                                 _default_index, _maybe_promote, _maybe_upcast,
                                 _asarray_tuplesafe, is_integer_dtype,
                                 _NS_DTYPE, _TD_DTYPE,
-                                _infer_dtype_from_scalar, is_list_like, _values_from_object,
-                                _possibly_cast_to_datetime, _possibly_castable, _possibly_convert_platform,
+                                _infer_dtype_from_scalar, is_list_like,
+                                _values_from_object,
+                                _possibly_cast_to_datetime, _possibly_castable,
+                                _possibly_convert_platform,
                                 ABCSparseArray)
 from pandas.core.index import (Index, MultiIndex, InvalidIndexError,
                                _ensure_index, _handle_legacy_indexes)
@@ -29,7 +30,6 @@ from pandas.core.indexing import (
 from pandas.core import generic
 from pandas.core.internals import SingleBlockManager
 from pandas.core.categorical import Categorical
-import pandas.core.expressions as expressions
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
 from pandas.tseries.offsets import DateOffset
@@ -775,12 +775,9 @@ class Series(generic.NDFrame):
     def __len__(self):
         return len(self._data)
 
-    @property
-    def size(self):
-        return self.__len__()
-
     def view(self, dtype=None):
-        return self._constructor(self.values.view(dtype), index=self.index, name=self.name)
+        return self._constructor(self.values.view(dtype), index=self.index,
+                                 name=self.name)
 
     def __array__(self, result=None):
         """ the array interface, return my values """
@@ -790,7 +787,8 @@ class Series(generic.NDFrame):
         """
         Gets called prior to a ufunc (and after)
         """
-        return self._constructor(result, index=self.index, name=self.name, copy=False)
+        return self._constructor(result, index=self.index, name=self.name,
+                                 copy=False)
 
     def __contains__(self, key):
         return key in self.index
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 374436313..a4491a87b 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -12,7 +12,6 @@ import itertools
 import warnings
 
 import numpy as np
-import pandas
 from pandas import (Series, TimeSeries, DataFrame, Panel, Panel4D, Index,
                     MultiIndex, Int64Index, Timestamp, _np_version_under1p7)
 from pandas.sparse.api import SparseSeries, SparseDataFrame, SparsePanel
@@ -30,10 +29,10 @@ from pandas.tseries.timedeltas import _coerce_scalar_to_timedelta_type
 import pandas.core.common as com
 from pandas.tools.merge import concat
 from pandas import compat
-from pandas.compat import u, PY3, range
+from pandas.compat import u, PY3, range, lrange
 from pandas.io.common import PerformanceWarning
 from pandas.core.config import get_option
-from pandas.computation.pytables import Expr
+from pandas.computation.pytables import Expr, maybe_expression
 
 import pandas.lib as lib
 import pandas.algos as algos
@@ -62,22 +61,27 @@ def _ensure_encoding(encoding):
             encoding = _default_encoding
     return encoding
 
+
 Term = Expr
 
+
 def _ensure_term(where):
-    """ ensure that the where is a Term or a list of Term
-        this makes sure that we are capturing the scope of variables
-        that are passed """
-
-    # create the terms here with a frame_level=2 (we are 2 levels down)
-    if isinstance(where, (list, tuple)):
-        where = [ w if isinstance(w, Term) else Term(w, scope_level=2) for w in where if w is not None ]
-    elif where is None or isinstance(where, Coordinates):
-        pass
-    elif not isinstance(where, Term):
+    """
+    ensure that the where is a Term or a list of Term
+    this makes sure that we are capturing the scope of variables
+    that are passed
+    create the terms here with a frame_level=2 (we are 2 levels down)
+    """
+
+    # only consider list/tuple here as an ndarray is automaticaly a coordinate list
+    if isinstance(where, (list,tuple)):
+        where = [w if not maybe_expression(w) else Term(w, scope_level=2)
+                 for w in where if w is not None ]
+    elif maybe_expression(where):
         where = Term(where, scope_level=2)
     return where
 
+
 class PossibleDataLossError(Exception):
     pass
 
@@ -2438,7 +2442,7 @@ class SparsePanelFixed(GenericFixed):
         sdict = {}
         for name in items:
             key = 'sparse_frame_%s' % name
-            s = SparseFrameStorer(self.parent, getattr(self.group, key))
+            s = SparseFrameFixed(self.parent, getattr(self.group, key))
             s.infer_axes()
             sdict[name] = s.read()
         return SparsePanel(sdict, items=items, default_kind=self.default_kind,
@@ -3527,7 +3531,7 @@ class AppendableTable(LegacyTable):
             # we must remove in reverse order!
             pg = groups.pop()
             for g in reversed(groups):
-                rows = l.take(range(g, pg))
+                rows = l.take(lrange(g, pg))
                 table.removeRows(start=rows[rows.index[0]
                                             ], stop=rows[rows.index[-1]] + 1)
                 pg = g
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index b13c8e83d..ee42a58a3 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1931,8 +1931,8 @@ class TestHDFStore(unittest.TestCase):
             # try to remove non-table (with crit)
             # non-table ok (where = None)
             wp = tm.makePanel()
-            store.put('wp', wp, fmt='t')
-            store.remove('wp', [("minor_axis=['A', 'D']")])
+            store.put('wp', wp, format='table')
+            store.remove('wp', ["minor_axis=['A', 'D']"])
             rs = store.select('wp')
             expected = wp.reindex(minor_axis=['B', 'C'])
             assert_panel_equal(rs, expected)
@@ -2031,6 +2031,7 @@ class TestHDFStore(unittest.TestCase):
             df.ix[0:4,'string'] = 'bar'
             wp = tm.makePanel()
             p4d = tm.makePanel4D()
+            store.put('df', df, format='table')
             store.put('wp', wp, format='table')
             store.put('p4d', p4d, format='table')
 
diff --git a/pandas/tests/test_common.py b/pandas/tests/test_common.py
index 5fc02d97b..8c5764a3f 100644
--- a/pandas/tests/test_common.py
+++ b/pandas/tests/test_common.py
@@ -7,18 +7,14 @@ from nose.tools import assert_equal
 import numpy as np
 from pandas.tslib import iNaT
 
-from pandas import (Series, DataFrame, date_range, DatetimeIndex, Timestamp,
-                    Panel)
+from pandas import Series, DataFrame, date_range, DatetimeIndex, Timestamp
 from pandas import compat
 from pandas.compat import range, long, lrange, lmap, u
 from pandas.core.common import notnull, isnull
-import pandas.compat as compat
 import pandas.core.common as com
 import pandas.util.testing as tm
 import pandas.core.config as cf
 
-from numpy.random import randn
-
 _multiprocess_can_split_ = True
 
 
@@ -110,64 +106,6 @@ def test_isnull_lists():
     assert(not result.any())
 
 
-def test_is_string():
-    class MyUnicode(compat.text_type):
-        pass
-
-    if not compat.PY3:
-        class MyString(str):
-            pass
-    else:
-        MyString = MyUnicode
-
-    strings = ('s', np.str_('a'), np.unicode_('unicode_string'),
-               MyString('asdfasdfasdf'), u('asdf'), MyUnicode(u('asdf')))
-    not_strings = [], 1, {}, set(), np.array(['1']), np.array([u('1')])
-
-    for string in strings:
-        assert com.is_string(string), '{0} is not a string'.format(string)
-
-    for not_string in not_strings:
-        assert not com.is_string(not_string), ('{0} is a '
-                                               'string'.format(not_string))
-
-
-def test_is_frame():
-    df = DataFrame(randn(2, 1))
-    assert com.is_frame(df)
-    assert not com.is_frame('s')
-
-
-def test_is_series():
-    s = Series(randn(2))
-    assert com.is_series(s)
-    assert not com.is_series(s.values)
-
-
-def test_is_panel():
-    p = Panel(randn(2, 3, 4))
-    assert com.is_panel(p)
-    assert not com.is_panel(2)
-
-
-def test_is_pd_obj():
-    df = DataFrame(randn(2, 1))
-    s = Series(randn(2))
-    p = Panel(randn(2, 3, 4))
-    for obj in (df, s, p):
-        assert com.is_pd_obj(obj)
-        assert not com.is_pd_obj(obj.values)
-
-
-def test_is_ndframe():
-    df = DataFrame(randn(2, 1))
-    p = Panel(randn(2, 3, 4))
-    # should add series after @jreback's ndframe to series pr
-    for obj in (df, p):
-        assert com.is_ndframe(obj)
-        assert not com.is_ndframe(obj.values)
-
-
 def test_isnull_datetime():
     assert (not isnull(datetime.now()))
     assert notnull(datetime.now())
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 7ba62a75a..8145fd9c5 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -11,6 +11,8 @@ import unittest
 import nose
 import functools
 import itertools
+from itertools import product
+
 from pandas.compat import(
     map, zip, range, long, lrange, lmap, lzip,
     OrderedDict, cPickle as pickle, u, StringIO
@@ -84,6 +86,7 @@ def _check_mixed_float(df, dtype = None):
     if dtypes.get('D'):
         assert(df.dtypes['D'] == dtypes['D'])
 
+
 def _check_mixed_int(df, dtype = None):
     dtypes = dict(A = 'int32', B = 'uint64', C = 'uint8', D = 'int64')
     if isinstance(dtype, compat.string_types):
@@ -100,8 +103,6 @@ def _check_mixed_int(df, dtype = None):
         assert(df.dtypes['D'] == dtypes['D'])
 
 
-
-
 class CheckIndexing(object):
 
     _multiprocess_can_split_ = True
@@ -125,6 +126,14 @@ class CheckIndexing(object):
         with assertRaisesRegexp(KeyError, 'no item named random'):
             self.frame['random']
 
+        df = self.frame.copy()
+        df['$10'] = randn(len(df))
+        ad = randn(len(df))
+        df['@awesome_domain'] = ad
+        self.assertRaises(KeyError, df.__getitem__, 'df["$10"]')
+        res = df['@awesome_domain']
+        assert_array_equal(ad, res.values)
+
     def test_getitem_dupe_cols(self):
         df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=['a', 'a', 'b'])
         try:
@@ -11113,17 +11122,21 @@ def skip_if_no_ne(engine='numexpr'):
                                 "installed")
 
 
+def skip_if_no_pandas_parser(parser):
+    if parser != 'pandas':
+        raise nose.SkipTest("cannot evaluate with parser {0!r}".format(parser))
+
+
 class TestDataFrameQueryNumExprPandas(unittest.TestCase):
     @classmethod
     def setUpClass(cls):
         cls.engine = 'numexpr'
         cls.parser = 'pandas'
-        skip_if_no_ne(cls.engine)
-        cls.frame = _frame.copy()
+        skip_if_no_ne()
 
     @classmethod
     def tearDownClass(cls):
-        del cls.frame, cls.engine, cls.parser
+        del cls.engine, cls.parser
 
     def test_date_query_method(self):
         engine, parser = self.engine, self.parser
@@ -11140,28 +11153,37 @@ class TestDataFrameQueryNumExprPandas(unittest.TestCase):
         engine, parser = self.engine, self.parser
         from pandas.computation.common import NameResolutionError
 
-        df = DataFrame({"i": lrange(10),
-                        "+": lrange(3, 13), "r": lrange(4, 14)})
+        df = DataFrame({"i": lrange(10), "+": lrange(3, 13),
+                        "r": lrange(4, 14)})
         i, s = 5, 6
         self.assertRaises(NameResolutionError, df.query, 'i < 5',
-                          local_dict=locals(), global_dict=globals(),
-                          engine=engine, parser=parser)
-        self.assertRaises(NameResolutionError, df.query, 'i - +', engine=engine,
-                          local_dict=locals(), global_dict=globals(),
+                          engine=engine, parser=parser, local_dict={'i': i})
+        self.assertRaises(SyntaxError, df.query, 'i - +', engine=engine,
                           parser=parser)
         self.assertRaises(NameResolutionError, df.query, 'i == s',
-                          engine=engine, local_dict=locals(),
-                          global_dict=globals(), parser=parser)
+                          engine=engine, parser=parser, local_dict={'i': i,
+                                                                    's': s})
+
+    def test_query_scope_index(self):
+        engine, parser = self.engine, self.parser
+        from pandas.computation.common import NameResolutionError
+        df = DataFrame(np.random.randint(10, size=(10, 3)),
+                       index=Index(range(10), name='blob'),
+                       columns=['a', 'b', 'c'])
+        from numpy import sin
         df.index.name = 'sin'
         self.assertRaises(NameResolutionError, df.query, 'sin > 5',
-                          engine=engine, parser=parser, local_dict=locals(),
-                          global_dict=globals())
+                          engine=engine, parser=parser, local_dict={'sin':
+                                                                    sin})
 
     def test_query(self):
         engine, parser = self.engine, self.parser
         df = DataFrame(np.random.randn(10, 3), columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('a < b', engine=engine, parser=parser), df[df.a < df.b])
-        assert_frame_equal(df.query('a + b > b * c', engine=engine, parser=parser),
+
+        assert_frame_equal(df.query('a < b', engine=engine, parser=parser),
+                           df[df.a < df.b])
+        assert_frame_equal(df.query('a + b > b * c', engine=engine,
+                                    parser=parser),
                            df[df.a + df.b > df.b * df.c])
 
         local_dict = dict(df.iteritems())
@@ -11174,20 +11196,34 @@ class TestDataFrameQueryNumExprPandas(unittest.TestCase):
                           df.query, 'a < b', local_dict={'df': df},
                           engine=engine, parser=parser)
 
-    def test_query_index(self):
+    def test_query_index_with_name(self):
         engine, parser = self.engine, self.parser
         df = DataFrame(np.random.randint(10, size=(10, 3)),
                        index=Index(range(10), name='blob'),
                        columns=['a', 'b', 'c'])
-        assert_frame_equal(df.query('index < b', engine=engine, parser=parser),
-                           df[df.index < df.b])
-        assert_frame_equal(df.query('index < 5', engine=engine, parser=parser),
-                           df[df.index < 5])
-        assert_frame_equal(df.query('(blob < 5) & (a < b)', engine=engine,
-                                    parser=parser),
-                           df[(df.index < 5) & (df.a < df.b)])
-        assert_frame_equal(df.query('blob < b', engine=engine, parser=parser),
-                           df[df.index < df.b])
+        res = df.query('(blob < 5) & (a < b)', engine=engine, parser=parser)
+        expec = df[(df.index < 5) & (df.a < df.b)]
+        assert_frame_equal(res, expec)
+
+        res = df.query('blob < b', engine=engine, parser=parser)
+        expec = df[df.index < df.b]
+
+        assert_frame_equal(res, expec)
+
+    def test_query_index_without_name(self):
+        engine, parser = self.engine, self.parser
+        df = DataFrame(np.random.randint(10, size=(10, 3)),
+                       index=range(10), columns=['a', 'b', 'c'])
+
+        # "index" should refer to the index
+        res = df.query('index < b', engine=engine, parser=parser)
+        expec = df[df.index < df.b]
+        assert_frame_equal(res, expec)
+
+        # test against a scalar
+        res = df.query('index < 5', engine=engine, parser=parser)
+        expec = df[df.index < 5]
+        assert_frame_equal(res, expec)
 
     def test_nested_scope(self):
         engine = self.engine
@@ -11217,6 +11253,40 @@ class TestDataFrameQueryNumExprPandas(unittest.TestCase):
         expected = df.query('(df>0) & (df2>0)', engine=engine, parser=parser)
         assert_frame_equal(result, expected)
 
+    def test_local_syntax(self):
+        skip_if_no_pandas_parser(self.parser)
+
+        from pandas.computation.common import NameResolutionError
+
+        engine, parser = self.engine, self.parser
+        df = DataFrame(randn(100, 10), columns=list('abcdefghij'))
+        b = 1
+        expect = df[df.a < b]
+        result = df.query('a < @b', engine=engine, parser=parser)
+        assert_frame_equal(result, expect)
+
+        # scope issue with self.assertRaises so just catch it and let it pass
+        try:
+            df.query('a < @b', engine=engine, parser=parser)
+        except NameResolutionError:
+            pass
+
+        del b
+        expect = df[df.a < df.b]
+        result = df.query('a < b', engine=engine, parser=parser)
+        assert_frame_equal(result, expect)
+
+    def test_chained_cmp_and_in(self):
+        skip_if_no_pandas_parser(self.parser)
+        engine, parser = self.engine, self.parser
+        cols = list('abc')
+        df = DataFrame(randn(100, len(cols)), columns=cols)
+        res = df.query('a < b < c and a not in b not in c', engine=engine,
+                       parser=parser)
+        ind = (df.a < df.b) & (df.b < df.c) & ~df.b.isin(df.a) & ~df.c.isin(df.b)
+        expec = df[ind]
+        assert_frame_equal(res, expec)
+
 
 class TestDataFrameQueryNumExprPython(TestDataFrameQueryNumExprPandas):
     @classmethod
@@ -11304,9 +11374,9 @@ class TestDataFrameQueryGetitem(unittest.TestCase):
         del cls.frame
 
     def test_nested_scope(self):
-        df  = DataFrame(np.random.randn(5, 3))
+        df = DataFrame(np.random.randn(5, 3))
         df2 = DataFrame(np.random.randn(5, 3))
-        expected = df[(df>0) & (df2>0)]
+        expected = df[(df > 0) & (df2 > 0)]
 
         result = df['(df>0) & (df2>0)']
         assert_frame_equal(result, expected)
@@ -11367,6 +11437,139 @@ class TestDataFrameQueryGetitem(unittest.TestCase):
         expec = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
         assert_frame_equal(res, expec)
 
+    def test_local_syntax(self):
+        from pandas.computation.common import NameResolutionError
+        df = DataFrame(randn(1000, 10), columns=list('abcdefghij'))
+        b = 1
+        expect = df[df.a < b]
+        result = df['a < @b']
+        assert_frame_equal(result, expect)
+
+        # scope issue with self.assertRaises so just catch it and let it pass
+        try:
+            df['a < b']
+        except NameResolutionError:
+            pass
+
+        del b
+        expect = df[df.a < df.b]
+        result = df['a < b']
+        assert_frame_equal(result, expect)
+
+
+PARSERS = 'python', 'pandas'
+ENGINES = 'python', 'numexpr'
+
+
+class TestDataFrameQueryStrings(object):
+    def check_str_query_method(self, parser, engine):
+        skip_if_no_pandas_parser(parser)
+        df = DataFrame(randn(10, 1), columns=['b'])
+        df['strings'] = Series(list('aabbccddee'))
+        expect = df[df.strings == 'a']
+        res = df.query('strings == "a"', engine=engine, parser=parser)
+        assert_frame_equal(res, expect)
+        assert_frame_equal(res, df[df.strings.isin(['a'])])
+
+    def test_str_query_method(self):
+        for parser, engine in product(PARSERS, ENGINES):
+            yield self.check_str_query_method, parser, engine
+
+    def test_str_list_query_method(self):
+        for parser, engine in product(PARSERS, ENGINES):
+            yield self.check_str_list_query_method, parser, engine
+
+    def check_str_list_query_method(self, parser, engine):
+        skip_if_no_pandas_parser(parser)
+        df = DataFrame(randn(10, 1), columns=['b'])
+        df['strings'] = Series(list('aabbccddee'))
+        expect = df[df.strings.isin(['a', 'b'])]
+        res = df.query('strings == ["a", "b"]', engine=engine, parser=parser)
+        assert_frame_equal(res, expect)
+
+    def test_str_query(self):
+        skip_if_no_ne()
+        df = DataFrame(randn(10, 1), columns=['b'])
+        df['strings'] = Series(list('aabbccddee'))
+        expect = df[df.strings == 'a']
+        res = df['strings == "a"']
+        assert_frame_equal(res, expect)
+
+        res = df['"a" == strings']
+        assert_frame_equal(res, expect)
+
+    def test_str_query_list(self):
+        skip_if_no_ne()
+        df = DataFrame(randn(10, 1), columns=['b'])
+        df['strings'] = Series(list('aabbccddee'))
+        expect = df[df.strings.isin(['a', 'b'])]
+        res = df['strings == ["a", "b"]']
+        assert_frame_equal(res, expect)
+
+        res = df['["a", "b"] == strings']
+        assert_frame_equal(res, expect)
+
+class TestDataFrameEvalNumExprPandas(unittest.TestCase):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'numexpr'
+        cls.parser = 'pandas'
+        skip_if_no_ne()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.engine, cls.parser
+
+    def setUp(self):
+        self.frame = DataFrame(randn(10, 3), columns=list('abc'))
+
+    def tearDown(self):
+        del self.frame
+
+    def test_simple_expr(self):
+        res = self.frame.eval('a + b', engine=self.engine, parser=self.parser)
+        expect = self.frame.a + self.frame.b
+        assert_series_equal(res, expect)
+
+    def test_bool_arith_expr(self):
+        res = self.frame.eval('a[a < 1] + b', engine=self.engine,
+                              parser=self.parser)
+        expect = self.frame.a[self.frame.a < 1] + self.frame.b
+        assert_series_equal(res, expect)
+
+
+class TestDataFrameEvalNumExprPython(TestDataFrameEvalNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'numexpr'
+        cls.parser = 'python'
+        skip_if_no_ne()
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.engine, cls.parser
+
+
+class TestDataFrameEvalPythonPandas(TestDataFrameEvalNumExprPandas):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = 'python'
+        cls.parser = 'pandas'
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.engine, cls.parser
+
+
+class TestDataFrameEvalPythonPython(TestDataFrameEvalNumExprPython):
+    @classmethod
+    def setUpClass(cls):
+        cls.engine = cls.parser = 'python'
+
+    @classmethod
+    def tearDownClass(cls):
+        del cls.engine, cls.parser
+
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
diff --git a/vb_suite/indexing.py b/vb_suite/indexing.py
index 2fb5a22ce..beefec256 100644
--- a/vb_suite/indexing.py
+++ b/vb_suite/indexing.py
@@ -106,7 +106,7 @@ indexing_dataframe_boolean = \
               start_date=datetime(2012, 1, 1))
 
 setup = common_setup + """
-import pandas.core.expressions as expr
+import pandas.computation.expressions as expr
 df  = DataFrame(np.random.randn(50000, 100))
 df2 = DataFrame(np.random.randn(50000, 100))
 expr.set_numexpr_threads(1)
