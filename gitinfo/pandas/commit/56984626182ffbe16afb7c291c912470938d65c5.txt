commit 56984626182ffbe16afb7c291c912470938d65c5
Author: Lucas Scarlato Astur <lucas.astur.96@gmail.com>
Date:   Thu Nov 21 10:04:13 2019 -0300

    format replaced with f-strings (#29701)

diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index 7d3bf3d3d..b62f28889 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -301,8 +301,7 @@ class SeriesGroupBy(GroupBy):
             obj = self
             if name in results:
                 raise SpecificationError(
-                    "Function names must be unique, found multiple named "
-                    "{name}".format(name=name)
+                    f"Function names must be unique, found multiple named {name}"
                 )
 
             # reset the cache so that we
@@ -588,7 +587,7 @@ class SeriesGroupBy(GroupBy):
         try:
             sorter = np.lexsort((val, ids))
         except TypeError:  # catches object dtypes
-            msg = "val.dtype must be object, got {}".format(val.dtype)
+            msg = f"val.dtype must be object, got {val.dtype}"
             assert val.dtype == object, msg
             val, _ = algorithms.factorize(val, sort=False)
             sorter = np.lexsort((val, ids))
@@ -1550,8 +1549,8 @@ class DataFrameGroupBy(GroupBy):
             else:
                 # non scalars aren't allowed
                 raise TypeError(
-                    "filter function returned a {typ}, "
-                    "but expected a scalar bool".format(typ=type(res).__name__)
+                    f"filter function returned a {type(res).__name__}, "
+                    "but expected a scalar bool"
                 )
 
         return self._apply_filter(indices, dropna)
@@ -1950,7 +1949,7 @@ def _managle_lambda_list(aggfuncs: Sequence[Any]) -> Sequence[Any]:
     for aggfunc in aggfuncs:
         if com.get_callable_name(aggfunc) == "<lambda>":
             aggfunc = partial(aggfunc)
-            aggfunc.__name__ = "<lambda_{}>".format(i)
+            aggfunc.__name__ = f"<lambda_{i}>"
             i += 1
         mangled_aggfuncs.append(aggfunc)
 
diff --git a/pandas/core/groupby/groupby.py b/pandas/core/groupby/groupby.py
index f72829504..21c085c77 100644
--- a/pandas/core/groupby/groupby.py
+++ b/pandas/core/groupby/groupby.py
@@ -566,9 +566,7 @@ class _GroupBy(PandasObject, SelectionMixin):
             return self[attr]
 
         raise AttributeError(
-            "'{typ}' object has no attribute '{attr}'".format(
-                typ=type(self).__name__, attr=attr
-            )
+            f"'{type(self).__name__}' object has no attribute '{attr}'"
         )
 
     @Substitution(
@@ -1783,7 +1781,7 @@ class GroupBy(_GroupBy):
             raise ValueError(
                 "For a DataFrame groupby, dropna must be "
                 "either None, 'any' or 'all', "
-                "(was passed {dropna}).".format(dropna=dropna)
+                f"(was passed {dropna})."
             )
 
         # old behaviour, but with all and any support for DataFrames.
@@ -2531,7 +2529,7 @@ def get_groupby(
 
         klass = DataFrameGroupBy
     else:
-        raise TypeError("invalid type: {obj}".format(obj=obj))
+        raise TypeError(f"invalid type: {obj}")
 
     return klass(
         obj=obj,
diff --git a/pandas/core/groupby/grouper.py b/pandas/core/groupby/grouper.py
index c37617b1f..2b946d1ff 100644
--- a/pandas/core/groupby/grouper.py
+++ b/pandas/core/groupby/grouper.py
@@ -173,9 +173,7 @@ class Grouper:
                 ax = self._grouper.take(obj.index)
             else:
                 if key not in obj._info_axis:
-                    raise KeyError(
-                        "The grouper name {key} is not found".format(key=key)
-                    )
+                    raise KeyError(f"The grouper name {key} is not found")
                 ax = Index(obj[key], name=key)
 
         else:
@@ -191,9 +189,7 @@ class Grouper:
 
                 else:
                     if level not in (0, ax.name):
-                        raise ValueError(
-                            "The level {level} is not valid".format(level=level)
-                        )
+                        raise ValueError(f"The level {level} is not valid")
 
         # possibly sort
         if (self.sort or sort) and not ax.is_monotonic:
@@ -212,13 +208,13 @@ class Grouper:
 
     def __repr__(self) -> str:
         attrs_list = (
-            "{name}={val!r}".format(name=attr_name, val=getattr(self, attr_name))
+            f"{attr_name}={getattr(self, attr_name)!r}"
             for attr_name in self._attributes
             if getattr(self, attr_name) is not None
         )
         attrs = ", ".join(attrs_list)
         cls_name = self.__class__.__name__
-        return "{cls}({attrs})".format(cls=cls_name, attrs=attrs)
+        return f"{cls_name}({attrs})"
 
 
 class Grouping:
@@ -280,9 +276,7 @@ class Grouping:
         if level is not None:
             if not isinstance(level, int):
                 if level not in index.names:
-                    raise AssertionError(
-                        "Level {level} not in index".format(level=level)
-                    )
+                    raise AssertionError(f"Level {level} not in index")
                 level = index.names.index(level)
 
             if self.name is None:
@@ -350,17 +344,16 @@ class Grouping:
             ):
                 if getattr(self.grouper, "ndim", 1) != 1:
                     t = self.name or str(type(self.grouper))
-                    raise ValueError("Grouper for '{t}' not 1-dimensional".format(t=t))
+                    raise ValueError(f"Grouper for '{t}' not 1-dimensional")
                 self.grouper = self.index.map(self.grouper)
                 if not (
                     hasattr(self.grouper, "__len__")
                     and len(self.grouper) == len(self.index)
                 ):
+                    grper = pprint_thing(self.grouper)
                     errmsg = (
                         "Grouper result violates len(labels) == "
-                        "len(data)\nresult: {grper}".format(
-                            grper=pprint_thing(self.grouper)
-                        )
+                        f"len(data)\nresult: {grper}"
                     )
                     self.grouper = None  # Try for sanity
                     raise AssertionError(errmsg)
@@ -375,7 +368,7 @@ class Grouping:
                 self.grouper = self.grouper.astype("timedelta64[ns]")
 
     def __repr__(self) -> str:
-        return "Grouping({name})".format(name=self.name)
+        return f"Grouping({self.name})"
 
     def __iter__(self):
         return iter(self.indices)
@@ -500,11 +493,7 @@ def get_grouper(
 
             if isinstance(level, str):
                 if obj.index.name != level:
-                    raise ValueError(
-                        "level name {level} is not the name of the index".format(
-                            level=level
-                        )
-                    )
+                    raise ValueError(f"level name {level} is not the name of the index")
             elif level > 0 or level < -1:
                 raise ValueError("level > 0 or level < -1 only valid with MultiIndex")
 
@@ -636,12 +625,8 @@ def get_grouper(
 
         if is_categorical_dtype(gpr) and len(gpr) != obj.shape[axis]:
             raise ValueError(
-                (
-                    "Length of grouper ({len_gpr}) and axis ({len_axis})"
-                    " must be same length".format(
-                        len_gpr=len(gpr), len_axis=obj.shape[axis]
-                    )
-                )
+                f"Length of grouper ({len(gpr)}) and axis ({obj.shape[axis]})"
+                " must be same length"
             )
 
         # create the Grouping
diff --git a/pandas/core/groupby/ops.py b/pandas/core/groupby/ops.py
index 7fd9fb8f5..a7e0a901a 100644
--- a/pandas/core/groupby/ops.py
+++ b/pandas/core/groupby/ops.py
@@ -452,18 +452,16 @@ class BaseGrouper:
         # categoricals are only 1d, so we
         # are not setup for dim transforming
         if is_categorical_dtype(values) or is_sparse(values):
-            raise NotImplementedError(
-                "{dtype} dtype not supported".format(dtype=values.dtype)
-            )
+            raise NotImplementedError(f"{values.dtype} dtype not supported")
         elif is_datetime64_any_dtype(values):
             if how in ["add", "prod", "cumsum", "cumprod"]:
                 raise NotImplementedError(
-                    "datetime64 type does not support {how} operations".format(how=how)
+                    f"datetime64 type does not support {how} operations"
                 )
         elif is_timedelta64_dtype(values):
             if how in ["prod", "cumprod"]:
                 raise NotImplementedError(
-                    "timedelta64 type does not support {how} operations".format(how=how)
+                    f"timedelta64 type does not support {how} operations"
                 )
 
         if is_datetime64tz_dtype(values.dtype):
@@ -516,9 +514,7 @@ class BaseGrouper:
             out_dtype = "float"
         else:
             if is_numeric:
-                out_dtype = "{kind}{itemsize}".format(
-                    kind=values.dtype.kind, itemsize=values.dtype.itemsize
-                )
+                out_dtype = f"{values.dtype.kind}{values.dtype.itemsize}"
             else:
                 out_dtype = "object"
 
