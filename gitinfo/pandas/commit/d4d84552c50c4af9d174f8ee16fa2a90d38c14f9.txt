commit d4d84552c50c4af9d174f8ee16fa2a90d38c14f9
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Jun 20 21:15:25 2011 -0400

    WeekOfMonth enhancement w/ unit tests

diff --git a/RELEASE.rst b/RELEASE.rst
index ae5fb8c7b..bb6886f25 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -49,13 +49,17 @@ Release notes
 * Added `select` function in all data structures: reindex axis based on
   arbitrary criterion (function returning boolean value),
   e.g. frame.select(lambda x: 'foo' in x, axis=1)
+* `DataFrame.consolidate` method, API function relating to redesigned internals
 
 **Improvements to existing features**
 
 * The 2-dimensional `DataFrame` and `DataMatrix` classes have been extensively
-  refactored internally into a single class `DataFrame`, preserving where
+  redesigned internally into a single class `DataFrame`, preserving where
   possible their optimal performance characteristics. This should reduce
-  confusion from users about which class to use
+  confusion from users about which class to use.
+  * Note that under ther hood there is a new essentially "lazy evaluation"
+    scheme within respect to adding columns to DataFrame. During some
+    operations, like-typed blocks will be "consolidated" but not before.
 * Column ordering for mixed type data is now completely consistent in
   `DataFrame`. In prior releases, there was inconsistent column ordering in
   `DataMatrix`
diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index 51131e2f1..bec577b29 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -373,7 +373,6 @@ class Week(DateOffset, CacheableOffset):
         return someDate.weekday() == self.weekday
 
 
-
 class WeekOfMonth(DateOffset, CacheableOffset):
     """
     Describes monthly dates like "the Tuesday of the 2nd week of each month"
@@ -398,8 +397,8 @@ class WeekOfMonth(DateOffset, CacheableOffset):
         self.weekday = kwds['weekday']
         self.week = kwds['week']
 
-        if self.n != 1 and self.n != -1:
-            raise Exception('N must be -1 or 1, got %d' % self.n)
+        if self.n == 0:
+            raise Exception('N cannot be 0')
 
         if self.weekday < 0 or self.weekday > 6:
             raise Exception('Day must be 0<=day<=6, got %d' %
@@ -414,22 +413,21 @@ class WeekOfMonth(DateOffset, CacheableOffset):
         offsetOfMonth = self.getOffsetOfMonth(other)
 
         one_month = relativedelta(months=1, day=1)
-        offsetOfPrevMonth = self.getOffsetOfMonth(other - one_month)
-        offsetOfNextMonth = self.getOffsetOfMonth(other + one_month)
 
         if other < offsetOfMonth:
-            if self.n == 1:
-                return offsetOfMonth
-            elif self.n == -1:
-                return offsetOfPrevMonth
+            if self.n > 0:
+                months = self.n - 1
+            else:
+                months = self.n
         elif other == offsetOfMonth:
-            delta = relativedelta(months=self.n, day=1)
-            return self.getOffsetOfMonth(other + delta)
+            months = self.n
         else:
-            if self.n == 1:
-                return offsetOfNextMonth
+            if self.n > 0:
+                months = self.n
             else:
-                return offsetOfMonth
+                months = self.n + 1
+
+        return self.getOffsetOfMonth(other + relativedelta(months=months, day=1))
 
     def getOffsetOfMonth(self, someDate):
         w = Week(weekday=self.weekday)
diff --git a/pandas/core/tests/test_datetools.py b/pandas/core/tests/test_datetools.py
index 24a6daa2b..c088e18c8 100644
--- a/pandas/core/tests/test_datetools.py
+++ b/pandas/core/tests/test_datetools.py
@@ -253,44 +253,60 @@ class TestWeek(unittest.TestCase):
                     expected = False
             assertOnOffset(offset, date, expected)
 
+
 class TestWeekOfMonth(unittest.TestCase):
 
     def test_constructor(self):
-        self.assertRaises(Exception, WeekOfMonth, n=2, week=0, weekday=0)
+        self.assertRaises(Exception, WeekOfMonth, n=0, week=1, weekday=1)
         self.assertRaises(Exception, WeekOfMonth, n=1, week=4, weekday=0)
         self.assertRaises(Exception, WeekOfMonth, n=1, week=-1, weekday=0)
         self.assertRaises(Exception, WeekOfMonth, n=1, week=0, weekday=-1)
         self.assertRaises(Exception, WeekOfMonth, n=1, week=0, weekday=7)
 
     def test_offset(self):
-        date1 = datetime(2011, 1, 11) # 1st Tuesday of Month
+        date1 = datetime(2011, 1, 4) # 1st Tuesday of Month
         date2 = datetime(2011, 1, 11) # 2nd Tuesday of Month
         date3 = datetime(2011, 1, 18) # 3rd Tuesday of Month
-        date4 = datetime(2011, 1, 25) # 3rd Tuesday of Month
+        date4 = datetime(2011, 1, 25) # 4th Tuesday of Month
 
         # see for loop for structure
         test_cases = [
-            (0, 0, date1, datetime(2011, 2, 7)),
-            (0, 0, date2, datetime(2011, 2, 7)),
-            (0, 0, date3, datetime(2011, 2, 7)),
-            (0, 0, date4, datetime(2011, 2, 7)),
-            (0, 1, date1, datetime(2011, 2, 1)),
-            (0, 1, date2, datetime(2011, 2, 1)),
-            (0, 1, date3, datetime(2011, 2, 1)),
-            (0, 1, date4, datetime(2011, 2, 1)),
-            (0, 2, date1, datetime(2011, 2, 2)),
-            (0, 2, date2, datetime(2011, 2, 2)),
-            (0, 2, date3, datetime(2011, 2, 2)),
-            (0, 2, date4, datetime(2011, 2, 2)),
-
-            (2, 1, date1, datetime(2011, 1, 18)),
-            (2, 1, date2, datetime(2011, 1, 18)),
-            (2, 1, date3, datetime(2011, 2, 15)),
-            (2, 1, date4, datetime(2011, 2, 15)),
+            (-2, 2, 1, date1, datetime(2010, 11, 16)),
+            (-2, 2, 1, date2, datetime(2010, 11, 16)),
+            (-2, 2, 1, date3, datetime(2010, 11, 16)),
+            (-2, 2, 1, date4, datetime(2010, 12, 21)),
+
+            (-1, 2, 1, date1, datetime(2010, 12, 21)),
+            (-1, 2, 1, date2, datetime(2010, 12, 21)),
+            (-1, 2, 1, date3, datetime(2010, 12, 21)),
+            (-1, 2, 1, date4, datetime(2011, 1, 18)),
+
+            (1, 0, 0, date1, datetime(2011, 2, 7)),
+            (1, 0, 0, date2, datetime(2011, 2, 7)),
+            (1, 0, 0, date3, datetime(2011, 2, 7)),
+            (1, 0, 0, date4, datetime(2011, 2, 7)),
+            (1, 0, 1, date1, datetime(2011, 2, 1)),
+            (1, 0, 1, date2, datetime(2011, 2, 1)),
+            (1, 0, 1, date3, datetime(2011, 2, 1)),
+            (1, 0, 1, date4, datetime(2011, 2, 1)),
+            (1, 0, 2, date1, datetime(2011, 1, 5)),
+            (1, 0, 2, date2, datetime(2011, 2, 2)),
+            (1, 0, 2, date3, datetime(2011, 2, 2)),
+            (1, 0, 2, date4, datetime(2011, 2, 2)),
+
+            (1, 2, 1, date1, datetime(2011, 1, 18)),
+            (1, 2, 1, date2, datetime(2011, 1, 18)),
+            (1, 2, 1, date3, datetime(2011, 2, 15)),
+            (1, 2, 1, date4, datetime(2011, 2, 15)),
+
+            (2, 2, 1, date1, datetime(2011, 2, 15)),
+            (2, 2, 1, date2, datetime(2011, 2, 15)),
+            (2, 2, 1, date3, datetime(2011, 3, 15)),
+            (2, 2, 1, date4, datetime(2011, 3, 15)),
         ]
 
-        for week, weekday, date, expected in test_cases:
-            offset = WeekOfMonth(week=week, weekday=weekday)
+        for n, week, weekday, date, expected in test_cases:
+            offset = WeekOfMonth(n, week=week, weekday=weekday)
             assertEq(offset, date, expected)
 
         # try subtracting
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index 62f80b87d..918a26ce3 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -1,573 +1,573 @@
-from __future__ import division
-
-import numpy as np
-
-from pandas.util.decorators import cache_readonly
-from pandas.core.frame import DataFrame
-from pandas.core.panel import WidePanel
-from pandas.core.series import Series
-import pandas.stats.common as common
-from pandas.stats.math import chain_dot, inv
-from pandas.stats.ols import _combine_rhs
-
-class VAR(object):
-    """
-    Estimates VAR(p) regression on multivariate time series data
-    presented in pandas data structures.
-
-    Parameters
-    ----------
-    data : DataFrame or dict of Series
-    p : lags to include
-
-    """
-
-    def __init__(self, data, p=1, intercept=True):
-        import scikits.statsmodels.tsa.var as sm_var
-
-        self._data = DataFrame(_combine_rhs(data))
-        self._p = p
-
-        self._columns = self._data.columns
-        self._index = self._data.index
-
-        self._intercept = intercept
-
-    @cache_readonly
-    def aic(self):
-        """Returns the Akaike information criterion."""
-        return self._ic['aic']
-
-    @cache_readonly
-    def bic(self):
-        """Returns the Bayesian information criterion."""
-        return self._ic['bic']
-
-    @cache_readonly
-    def beta(self):
-        """
-        Returns a DataFrame, where each column x1 contains the betas
-        calculated by regressing the x1 column of the VAR input with
-        the lagged input.
-
-        Returns
-        -------
-        DataFrame
-        """
-        d = dict([(key, value.beta)
-                  for (key, value) in self.ols_results.iteritems()])
-        return DataFrame(d)
-
-    def forecast(self, h):
-        """
-        Returns a DataFrame containing the forecasts for 1, 2, ..., n time
-        steps.  Each column x1 contains the forecasts of the x1 column.
-
-        Parameters
-        ----------
-        n: int
-            Number of time steps ahead to forecast.
-
-        Returns
-        -------
-        DataFrame
-        """
-        forecast = self._forecast_raw(h)[:, 0, :]
-        return DataFrame(forecast, index=xrange(1, 1 + h),
-                         columns=self._columns)
-
-    def forecast_cov(self, h):
-        """
-        Returns the covariance of the forecast residuals.
-
-        Returns
-        -------
-        DataFrame
-        """
-        return [DataFrame(value, index=self._columns, columns=self._columns)
-                for value in self._forecast_cov_raw(h)]
-
-    def forecast_std_err(self, h):
-        """
-        Returns the standard errors of the forecast residuals.
-
-        Returns
-        -------
-        DataFrame
-        """
-        return DataFrame(self._forecast_std_err_raw(h),
-                         index=xrange(1, 1 + h), columns=self._columns)
-
-    @cache_readonly
-    def granger_causality(self):
-        """Returns the f-stats and p-values from the Granger Causality Test.
-
-        If the data consists of columns x1, x2, x3, then we perform the
-        following regressions:
-
-        x1 ~ L(x2, x3)
-        x1 ~ L(x1, x3)
-        x1 ~ L(x1, x2)
-
-        The f-stats of these results are placed in the 'x1' column of the
-        returned DataFrame.  We then repeat for x2, x3.
-
-        Returns
-        -------
-        Dict, where 'f-stat' returns the DataFrame containing the f-stats,
-        and 'p-value' returns the DataFrame containing the corresponding
-        p-values of the f-stats.
-        """
-        from pandas.stats.api import ols
-        from scipy.stats import f
-
-        d = {}
-        for col in self._columns:
-            d[col] = {}
-            for i in xrange(1, 1 + self._p):
-                lagged_data = self._lagged_data[i].filter(self._columns - [col])
-
-                for key, value in lagged_data.iteritems():
-                    d[col][_make_param_name(i, key)] = value
-
-        f_stat_dict = {}
-        p_value_dict = {}
-
-        for col, y in self._data.iteritems():
-            ssr_full = (self.resid[col] ** 2).sum()
-
-            f_stats = []
-            p_values = []
-
-            for col2 in self._columns:
-                result = ols(y=y, x=d[col2])
-
-                resid = result.resid
-                ssr_reduced = (resid ** 2).sum()
-
-                M = self._p
-                N = self._nobs
-                K = self._k * self._p + 1
-                f_stat = ((ssr_reduced - ssr_full) / M) / (ssr_full / (N - K))
-                f_stats.append(f_stat)
-
-                p_value = f.sf(f_stat, M, N - K)
-                p_values.append(p_value)
-
-            f_stat_dict[col] = Series(f_stats, self._columns)
-            p_value_dict[col] = Series(p_values, self._columns)
-
-        f_stat_mat = DataFrame(f_stat_dict)
-        p_value_mat = DataFrame(p_value_dict)
-
-        return {
-            'f-stat' : f_stat_mat,
-            'p-value' : p_value_mat,
-        }
-
-    @cache_readonly
-    def ols_results(self):
-        """
-        Returns the results of the regressions:
-        x_1 ~ L(X)
-        x_2 ~ L(X)
-        ...
-        x_k ~ L(X)
-
-        where X = [x_1, x_2, ..., x_k]
-        and L(X) represents the columns of X lagged 1, 2, ..., n lags
-        (n is the user-provided number of lags).
-
-        Returns
-        -------
-        dict
-        """
-        from pandas.stats.api import ols
-
-        d = {}
-        for i in xrange(1, 1 + self._p):
-            for col, series in self._lagged_data[i].iteritems():
-                d[_make_param_name(i, col)] = series
-
-        result = dict([(col, ols(y=y, x=d, intercept=self._intercept))
-                       for col, y in self._data.iteritems()])
-
-        return result
-
-    @cache_readonly
-    def resid(self):
-        """
-        Returns the DataFrame containing the residuals of the VAR regressions.
-        Each column x1 contains the residuals generated by regressing the x1
-        column of the input against the lagged input.
-
-        Returns
-        -------
-        DataFrame
-        """
-        d = dict([(col, series.resid)
-                  for (col, series) in self.ols_results.iteritems()])
-        return DataFrame(d, index=self._index)
-
-    @cache_readonly
-    def summary(self):
-        template = """
-%(banner_top)s
-
-Number of Observations:         %(nobs)d
-AIC:                            %(aic).3f
-BIC:                            %(bic).3f
-
-%(banner_coef)s
-%(coef_table)s
-%(banner_end)s
-"""
-        params = {
-            'banner_top' : common.banner('Summary of VAR'),
-            'banner_coef' : common.banner('Summary of Estimated Coefficients'),
-            'banner_end' : common.banner('End of Summary'),
-            'coef_table' : self.beta,
-            'aic' : self.aic,
-            'bic' : self.bic,
-            'nobs' : self._nobs,
-        }
-
-        return template % params
-
-    @cache_readonly
-    def _alpha(self):
-        """
-        Returns array where the i-th element contains the intercept
-        when regressing the i-th column of self._data with the lagged data.
-        """
-        if self._intercept:
-            return self._beta_raw[-1]
-        else:
-            return np.zeros(self._k)
-
-    @cache_readonly
-    def _beta_raw(self):
-        return np.array([self.beta[col].values() for col in self._columns]).T
-
-    def _trans_B(self, h):
-        """
-        Returns 0, 1, ..., (h-1)-th power of transpose of B as defined in
-        equation (4) on p. 142 of the Stata 11 Time Series reference book.
-        """
-        result = [np.eye(1 + self._k * self._p)]
-
-        row1 = np.zeros((1, 1 + self._k * self._p))
-        row1[0, 0] = 1
-
-        v = self._alpha.reshape((self._k, 1))
-        row2 = np.hstack(tuple([v] + self._lag_betas))
-
-        m = self._k * (self._p - 1)
-        row3 = np.hstack((
-            np.zeros((m, 1)),
-            np.eye(m),
-            np.zeros((m, self._k))
-        ))
-
-        trans_B = np.vstack((row1, row2, row3)).T
-
-        result.append(trans_B)
-
-        for i in xrange(2, h):
-            result.append(np.dot(trans_B, result[i - 1]))
-
-        return result
-
-    @cache_readonly
-    def _x(self):
-        values = np.array([
-            self._lagged_data[i][col].values()
-            for i in xrange(1, 1 + self._p)
-            for col in self._columns
-        ]).T
-
-        x = np.hstack((np.ones((len(values), 1)), values))[self._p:]
-
-        return x
-
-    @cache_readonly
-    def _cov_beta(self):
-        cov_resid = self._sigma
-
-        x = self._x
-
-        inv_cov_x = inv(np.dot(x.T, x))
-
-        return np.kron(inv_cov_x, cov_resid)
-
-    def _data_xs(self, i):
-        """
-        Returns the cross-section of the data at the given timestep.
-        """
-        return self._data.values[i]
-
-    def _forecast_cov_raw(self, n):
-        resid = self._forecast_cov_resid_raw(n)
-        #beta = self._forecast_cov_beta_raw(n)
-
-        #return [a + b for a, b in izip(resid, beta)]
-        # TODO: ignore the beta forecast std err until it's verified
-
-        return resid
-
-    def _forecast_cov_beta_raw(self, n):
-        """
-        Returns the covariance of the beta errors for the forecast at
-        1, 2, ..., n timesteps.
-        """
-        p = self._p
-
-        values = self._data.values
-        T = len(values) - self._p - 1
-
-        results = []
-
-        for h in xrange(1, n + 1):
-            psi = self._psi(h)
-            trans_B = self._trans_B(h)
-
-            sum = 0
-
-            cov_beta = self._cov_beta
-
-            for t in xrange(T + 1):
-                index = t + p
-                y = values.take(xrange(index, index - p, -1), axis=0).flatten()
-                trans_Z = np.hstack(([1], y))
-                trans_Z = trans_Z.reshape(1, len(trans_Z))
-
-                sum2 = 0
-                for i in xrange(h):
-                    ZB = np.dot(trans_Z, trans_B[h - 1 - i])
-
-                    prod = np.kron(ZB, psi[i])
-                    sum2 = sum2 + prod
-
-                sum = sum + chain_dot(sum2, cov_beta, sum2.T)
-
-            results.append(sum / (T + 1))
-
-        return results
-
-    def _forecast_cov_resid_raw(self, h):
-        """
-        Returns the covariance of the residual errors for the forecast at
-        1, 2, ..., h timesteps.
-        """
-        psi_values = self._psi(h)
-        sum = 0
-        result = []
-        for i in xrange(h):
-            psi = psi_values[i]
-            sum = sum + chain_dot(psi, self._sigma, psi.T)
-            result.append(sum)
-
-        return result
-
-    def _forecast_raw(self, h):
-        """
-        Returns the forecast at 1, 2, ..., h timesteps in the future.
-        """
-        k = self._k
-        result = []
-        for i in xrange(h):
-            sum = self._alpha.reshape(1, k)
-            for j in xrange(self._p):
-                beta = self._lag_betas[j]
-                idx = i - j
-                if idx > 0:
-                    y = result[idx - 1]
-                else:
-                    y = self._data_xs(idx - 1)
-
-                sum = sum + np.dot(beta, y.T).T
-            result.append(sum)
-
-        return np.array(result)
-
-    def _forecast_std_err_raw(self, h):
-        """
-        Returns the standard error of the forecasts
-        at 1, 2, ..., n timesteps.
-        """
-        return np.array([np.sqrt(np.diag(value))
-                         for value in self._forecast_cov_raw(h)])
-
-    @cache_readonly
-    def _ic(self):
-        """
-        Returns the Akaike/Bayesian information criteria.
-        """
-        RSS = self._rss
-        k = self._p * (self._k * self._p + 1)
-        n = self._nobs * self._k
-
-        return {'aic' : 2 * k + n * np.log(RSS / n),
-                'bic' : n * np.log(RSS / n) + k * np.log(n)}
-
-    @cache_readonly
-    def _k(self):
-        return len(self._columns)
-
-    @cache_readonly
-    def _lag_betas(self):
-        """
-        Returns list of B_i, where B_i represents the (k, k) matrix
-        with the j-th row containing the betas of regressing the j-th
-        column of self._data with self._data lagged i time steps.
-        First element is B_1, second element is B_2, etc.
-        """
-        k = self._k
-        b = self._beta_raw
-        return [b[k * i : k * (i + 1)].T for i in xrange(self._p)]
-
-    @cache_readonly
-    def _lagged_data(self):
-        return dict([(i, self._data.shift(i))
-                     for i in xrange(1, 1 + self._p)])
-
-    @cache_readonly
-    def _nobs(self):
-        return len(self._data) - self._p
-
-    def _psi(self, h):
-        """
-        psi value used for calculating standard error.
-
-        Returns [psi_0, psi_1, ..., psi_(h - 1)]
-        """
-        k = self._k
-        result = [np.eye(k)]
-        for i in xrange(1, h):
-            result.append(sum(
-                [np.dot(result[i - j], self._lag_betas[j - 1])
-                 for j in xrange(1, 1 + i)
-                 if j <= self._p]))
-
-        return result
-
-    @cache_readonly
-    def _resid_raw(self):
-        resid = np.array([self.ols_results[col]._resid_raw
-                          for col in self._columns])
-        return resid
-
-    @cache_readonly
-    def _rss(self):
-        """Returns the sum of the squares of the residuals."""
-        return (self._resid_raw ** 2).sum()
-
-    @cache_readonly
-    def _sigma(self):
-        """Returns covariance of resids."""
-        k = self._k
-        n = self._nobs
-
-        resid = self._resid_raw
-
-        return np.dot(resid, resid.T) / (n - k)
-
-    def __repr__(self):
-        return self.summary
-
-def lag_select(data, max_lags=5, ic=None):
-    """
-    Select number of lags based on a variety of information criteria
-
-    Parameters
-    ----------
-    data : DataFrame-like
-    max_lags : int
-        Maximum number of lags to evaluate
-    ic : {None, 'aic', 'bic', ...}
-        Choosing None will just display the results
-
-    Returns
-    -------
-    None
-    """
-    pass
-
-class PanelVAR(VAR):
-    """
-    Performs Vector Autoregression on panel data.
-
-    Parameters
-    ----------
-    data: WidePanel or dict of DataFrame
-    lags: int
-    """
-    def __init__(self, data, lags, intercept=True):
-        self._data = _prep_panel_data(data)
-        self._p = lags
-        self._intercept = intercept
-
-        self._columns = self._data.items
-
-    @cache_readonly
-    def _nobs(self):
-        """Returns the number of observations."""
-        _, timesteps, entities = self._data.values.shape
-        return (timesteps - self._p) * entities
-
-    @cache_readonly
-    def _rss(self):
-        """Returns the sum of the squares of the residuals."""
-        return (self.resid.values ** 2).sum()
-
-    def forecast(self, h):
-        """
-        Returns the forecasts at 1, 2, ..., n timesteps in the future.
-        """
-        forecast = self._forecast_raw(h).T.swapaxes(1, 2)
-        index = xrange(1, 1 + h)
-        w = WidePanel(
-            forecast, self._data.items, index, self._data.minor_axis)
-        return w
-
-    @cache_readonly
-    def resid(self):
-        """
-        Returns the DataFrame containing the residuals of the VAR regressions.
-        Each column x1 contains the residuals generated by regressing the x1
-        column of the input against the lagged input.
-
-        Returns
-        -------
-        DataFrame
-        """
-        d = dict([(key, value.resid)
-                  for (key, value) in self.ols_results.iteritems()])
-        return WidePanel.fromDict(d)
-
-    def _data_xs(self, i):
-        return self._data.values[:, i, :].T
-
-    @cache_readonly
-    def _sigma(self):
-        """Returns covariance of resids."""
-        k = self._k
-        resid = _drop_incomplete_rows(self.resid.toLong().values)
-        n = len(resid)
-        return np.dot(resid.T, resid) / (n - k)
-
-
-def _prep_panel_data(data):
-    """Converts the given data into a WidePanel."""
-    if isinstance(data, WidePanel):
-        return data
-
-    return WidePanel.fromDict(data)
-
-def _drop_incomplete_rows(array):
-    mask = np.isfinite(array).all(1)
-    indices = np.arange(len(array))[mask]
-    return array.take(indices, 0)
-
-def _make_param_name(lag, name):
-    return 'L%d.%s' % (lag, name)
+from __future__ import division
+
+import numpy as np
+
+from pandas.util.decorators import cache_readonly
+from pandas.core.frame import DataFrame
+from pandas.core.panel import WidePanel
+from pandas.core.series import Series
+import pandas.stats.common as common
+from pandas.stats.math import chain_dot, inv
+from pandas.stats.ols import _combine_rhs
+
+class VAR(object):
+    """
+    Estimates VAR(p) regression on multivariate time series data
+    presented in pandas data structures.
+
+    Parameters
+    ----------
+    data : DataFrame or dict of Series
+    p : lags to include
+
+    """
+
+    def __init__(self, data, p=1, intercept=True):
+        import scikits.statsmodels.tsa.var as sm_var
+
+        self._data = DataFrame(_combine_rhs(data))
+        self._p = p
+
+        self._columns = self._data.columns
+        self._index = self._data.index
+
+        self._intercept = intercept
+
+    @cache_readonly
+    def aic(self):
+        """Returns the Akaike information criterion."""
+        return self._ic['aic']
+
+    @cache_readonly
+    def bic(self):
+        """Returns the Bayesian information criterion."""
+        return self._ic['bic']
+
+    @cache_readonly
+    def beta(self):
+        """
+        Returns a DataFrame, where each column x1 contains the betas
+        calculated by regressing the x1 column of the VAR input with
+        the lagged input.
+
+        Returns
+        -------
+        DataFrame
+        """
+        d = dict([(key, value.beta)
+                  for (key, value) in self.ols_results.iteritems()])
+        return DataFrame(d)
+
+    def forecast(self, h):
+        """
+        Returns a DataFrame containing the forecasts for 1, 2, ..., n time
+        steps.  Each column x1 contains the forecasts of the x1 column.
+
+        Parameters
+        ----------
+        n: int
+            Number of time steps ahead to forecast.
+
+        Returns
+        -------
+        DataFrame
+        """
+        forecast = self._forecast_raw(h)[:, 0, :]
+        return DataFrame(forecast, index=xrange(1, 1 + h),
+                         columns=self._columns)
+
+    def forecast_cov(self, h):
+        """
+        Returns the covariance of the forecast residuals.
+
+        Returns
+        -------
+        DataFrame
+        """
+        return [DataFrame(value, index=self._columns, columns=self._columns)
+                for value in self._forecast_cov_raw(h)]
+
+    def forecast_std_err(self, h):
+        """
+        Returns the standard errors of the forecast residuals.
+
+        Returns
+        -------
+        DataFrame
+        """
+        return DataFrame(self._forecast_std_err_raw(h),
+                         index=xrange(1, 1 + h), columns=self._columns)
+
+    @cache_readonly
+    def granger_causality(self):
+        """Returns the f-stats and p-values from the Granger Causality Test.
+
+        If the data consists of columns x1, x2, x3, then we perform the
+        following regressions:
+
+        x1 ~ L(x2, x3)
+        x1 ~ L(x1, x3)
+        x1 ~ L(x1, x2)
+
+        The f-stats of these results are placed in the 'x1' column of the
+        returned DataFrame.  We then repeat for x2, x3.
+
+        Returns
+        -------
+        Dict, where 'f-stat' returns the DataFrame containing the f-stats,
+        and 'p-value' returns the DataFrame containing the corresponding
+        p-values of the f-stats.
+        """
+        from pandas.stats.api import ols
+        from scipy.stats import f
+
+        d = {}
+        for col in self._columns:
+            d[col] = {}
+            for i in xrange(1, 1 + self._p):
+                lagged_data = self._lagged_data[i].filter(self._columns - [col])
+
+                for key, value in lagged_data.iteritems():
+                    d[col][_make_param_name(i, key)] = value
+
+        f_stat_dict = {}
+        p_value_dict = {}
+
+        for col, y in self._data.iteritems():
+            ssr_full = (self.resid[col] ** 2).sum()
+
+            f_stats = []
+            p_values = []
+
+            for col2 in self._columns:
+                result = ols(y=y, x=d[col2])
+
+                resid = result.resid
+                ssr_reduced = (resid ** 2).sum()
+
+                M = self._p
+                N = self._nobs
+                K = self._k * self._p + 1
+                f_stat = ((ssr_reduced - ssr_full) / M) / (ssr_full / (N - K))
+                f_stats.append(f_stat)
+
+                p_value = f.sf(f_stat, M, N - K)
+                p_values.append(p_value)
+
+            f_stat_dict[col] = Series(f_stats, self._columns)
+            p_value_dict[col] = Series(p_values, self._columns)
+
+        f_stat_mat = DataFrame(f_stat_dict)
+        p_value_mat = DataFrame(p_value_dict)
+
+        return {
+            'f-stat' : f_stat_mat,
+            'p-value' : p_value_mat,
+        }
+
+    @cache_readonly
+    def ols_results(self):
+        """
+        Returns the results of the regressions:
+        x_1 ~ L(X)
+        x_2 ~ L(X)
+        ...
+        x_k ~ L(X)
+
+        where X = [x_1, x_2, ..., x_k]
+        and L(X) represents the columns of X lagged 1, 2, ..., n lags
+        (n is the user-provided number of lags).
+
+        Returns
+        -------
+        dict
+        """
+        from pandas.stats.api import ols
+
+        d = {}
+        for i in xrange(1, 1 + self._p):
+            for col, series in self._lagged_data[i].iteritems():
+                d[_make_param_name(i, col)] = series
+
+        result = dict([(col, ols(y=y, x=d, intercept=self._intercept))
+                       for col, y in self._data.iteritems()])
+
+        return result
+
+    @cache_readonly
+    def resid(self):
+        """
+        Returns the DataFrame containing the residuals of the VAR regressions.
+        Each column x1 contains the residuals generated by regressing the x1
+        column of the input against the lagged input.
+
+        Returns
+        -------
+        DataFrame
+        """
+        d = dict([(col, series.resid)
+                  for (col, series) in self.ols_results.iteritems()])
+        return DataFrame(d, index=self._index)
+
+    @cache_readonly
+    def summary(self):
+        template = """
+%(banner_top)s
+
+Number of Observations:         %(nobs)d
+AIC:                            %(aic).3f
+BIC:                            %(bic).3f
+
+%(banner_coef)s
+%(coef_table)s
+%(banner_end)s
+"""
+        params = {
+            'banner_top' : common.banner('Summary of VAR'),
+            'banner_coef' : common.banner('Summary of Estimated Coefficients'),
+            'banner_end' : common.banner('End of Summary'),
+            'coef_table' : self.beta,
+            'aic' : self.aic,
+            'bic' : self.bic,
+            'nobs' : self._nobs,
+        }
+
+        return template % params
+
+    @cache_readonly
+    def _alpha(self):
+        """
+        Returns array where the i-th element contains the intercept
+        when regressing the i-th column of self._data with the lagged data.
+        """
+        if self._intercept:
+            return self._beta_raw[-1]
+        else:
+            return np.zeros(self._k)
+
+    @cache_readonly
+    def _beta_raw(self):
+        return np.array([self.beta[col].values() for col in self._columns]).T
+
+    def _trans_B(self, h):
+        """
+        Returns 0, 1, ..., (h-1)-th power of transpose of B as defined in
+        equation (4) on p. 142 of the Stata 11 Time Series reference book.
+        """
+        result = [np.eye(1 + self._k * self._p)]
+
+        row1 = np.zeros((1, 1 + self._k * self._p))
+        row1[0, 0] = 1
+
+        v = self._alpha.reshape((self._k, 1))
+        row2 = np.hstack(tuple([v] + self._lag_betas))
+
+        m = self._k * (self._p - 1)
+        row3 = np.hstack((
+            np.zeros((m, 1)),
+            np.eye(m),
+            np.zeros((m, self._k))
+        ))
+
+        trans_B = np.vstack((row1, row2, row3)).T
+
+        result.append(trans_B)
+
+        for i in xrange(2, h):
+            result.append(np.dot(trans_B, result[i - 1]))
+
+        return result
+
+    @cache_readonly
+    def _x(self):
+        values = np.array([
+            self._lagged_data[i][col].values()
+            for i in xrange(1, 1 + self._p)
+            for col in self._columns
+        ]).T
+
+        x = np.hstack((np.ones((len(values), 1)), values))[self._p:]
+
+        return x
+
+    @cache_readonly
+    def _cov_beta(self):
+        cov_resid = self._sigma
+
+        x = self._x
+
+        inv_cov_x = inv(np.dot(x.T, x))
+
+        return np.kron(inv_cov_x, cov_resid)
+
+    def _data_xs(self, i):
+        """
+        Returns the cross-section of the data at the given timestep.
+        """
+        return self._data.values[i]
+
+    def _forecast_cov_raw(self, n):
+        resid = self._forecast_cov_resid_raw(n)
+        #beta = self._forecast_cov_beta_raw(n)
+
+        #return [a + b for a, b in izip(resid, beta)]
+        # TODO: ignore the beta forecast std err until it's verified
+
+        return resid
+
+    def _forecast_cov_beta_raw(self, n):
+        """
+        Returns the covariance of the beta errors for the forecast at
+        1, 2, ..., n timesteps.
+        """
+        p = self._p
+
+        values = self._data.values
+        T = len(values) - self._p - 1
+
+        results = []
+
+        for h in xrange(1, n + 1):
+            psi = self._psi(h)
+            trans_B = self._trans_B(h)
+
+            sum = 0
+
+            cov_beta = self._cov_beta
+
+            for t in xrange(T + 1):
+                index = t + p
+                y = values.take(xrange(index, index - p, -1), axis=0).flatten()
+                trans_Z = np.hstack(([1], y))
+                trans_Z = trans_Z.reshape(1, len(trans_Z))
+
+                sum2 = 0
+                for i in xrange(h):
+                    ZB = np.dot(trans_Z, trans_B[h - 1 - i])
+
+                    prod = np.kron(ZB, psi[i])
+                    sum2 = sum2 + prod
+
+                sum = sum + chain_dot(sum2, cov_beta, sum2.T)
+
+            results.append(sum / (T + 1))
+
+        return results
+
+    def _forecast_cov_resid_raw(self, h):
+        """
+        Returns the covariance of the residual errors for the forecast at
+        1, 2, ..., h timesteps.
+        """
+        psi_values = self._psi(h)
+        sum = 0
+        result = []
+        for i in xrange(h):
+            psi = psi_values[i]
+            sum = sum + chain_dot(psi, self._sigma, psi.T)
+            result.append(sum)
+
+        return result
+
+    def _forecast_raw(self, h):
+        """
+        Returns the forecast at 1, 2, ..., h timesteps in the future.
+        """
+        k = self._k
+        result = []
+        for i in xrange(h):
+            sum = self._alpha.reshape(1, k)
+            for j in xrange(self._p):
+                beta = self._lag_betas[j]
+                idx = i - j
+                if idx > 0:
+                    y = result[idx - 1]
+                else:
+                    y = self._data_xs(idx - 1)
+
+                sum = sum + np.dot(beta, y.T).T
+            result.append(sum)
+
+        return np.array(result)
+
+    def _forecast_std_err_raw(self, h):
+        """
+        Returns the standard error of the forecasts
+        at 1, 2, ..., n timesteps.
+        """
+        return np.array([np.sqrt(np.diag(value))
+                         for value in self._forecast_cov_raw(h)])
+
+    @cache_readonly
+    def _ic(self):
+        """
+        Returns the Akaike/Bayesian information criteria.
+        """
+        RSS = self._rss
+        k = self._p * (self._k * self._p + 1)
+        n = self._nobs * self._k
+
+        return {'aic' : 2 * k + n * np.log(RSS / n),
+                'bic' : n * np.log(RSS / n) + k * np.log(n)}
+
+    @cache_readonly
+    def _k(self):
+        return len(self._columns)
+
+    @cache_readonly
+    def _lag_betas(self):
+        """
+        Returns list of B_i, where B_i represents the (k, k) matrix
+        with the j-th row containing the betas of regressing the j-th
+        column of self._data with self._data lagged i time steps.
+        First element is B_1, second element is B_2, etc.
+        """
+        k = self._k
+        b = self._beta_raw
+        return [b[k * i : k * (i + 1)].T for i in xrange(self._p)]
+
+    @cache_readonly
+    def _lagged_data(self):
+        return dict([(i, self._data.shift(i))
+                     for i in xrange(1, 1 + self._p)])
+
+    @cache_readonly
+    def _nobs(self):
+        return len(self._data) - self._p
+
+    def _psi(self, h):
+        """
+        psi value used for calculating standard error.
+
+        Returns [psi_0, psi_1, ..., psi_(h - 1)]
+        """
+        k = self._k
+        result = [np.eye(k)]
+        for i in xrange(1, h):
+            result.append(sum(
+                [np.dot(result[i - j], self._lag_betas[j - 1])
+                 for j in xrange(1, 1 + i)
+                 if j <= self._p]))
+
+        return result
+
+    @cache_readonly
+    def _resid_raw(self):
+        resid = np.array([self.ols_results[col]._resid_raw
+                          for col in self._columns])
+        return resid
+
+    @cache_readonly
+    def _rss(self):
+        """Returns the sum of the squares of the residuals."""
+        return (self._resid_raw ** 2).sum()
+
+    @cache_readonly
+    def _sigma(self):
+        """Returns covariance of resids."""
+        k = self._k
+        n = self._nobs
+
+        resid = self._resid_raw
+
+        return np.dot(resid, resid.T) / (n - k)
+
+    def __repr__(self):
+        return self.summary
+
+def lag_select(data, max_lags=5, ic=None):
+    """
+    Select number of lags based on a variety of information criteria
+
+    Parameters
+    ----------
+    data : DataFrame-like
+    max_lags : int
+        Maximum number of lags to evaluate
+    ic : {None, 'aic', 'bic', ...}
+        Choosing None will just display the results
+
+    Returns
+    -------
+    None
+    """
+    pass
+
+class PanelVAR(VAR):
+    """
+    Performs Vector Autoregression on panel data.
+
+    Parameters
+    ----------
+    data: WidePanel or dict of DataFrame
+    lags: int
+    """
+    def __init__(self, data, lags, intercept=True):
+        self._data = _prep_panel_data(data)
+        self._p = lags
+        self._intercept = intercept
+
+        self._columns = self._data.items
+
+    @cache_readonly
+    def _nobs(self):
+        """Returns the number of observations."""
+        _, timesteps, entities = self._data.values.shape
+        return (timesteps - self._p) * entities
+
+    @cache_readonly
+    def _rss(self):
+        """Returns the sum of the squares of the residuals."""
+        return (self.resid.values ** 2).sum()
+
+    def forecast(self, h):
+        """
+        Returns the forecasts at 1, 2, ..., n timesteps in the future.
+        """
+        forecast = self._forecast_raw(h).T.swapaxes(1, 2)
+        index = xrange(1, 1 + h)
+        w = WidePanel(
+            forecast, self._data.items, index, self._data.minor_axis)
+        return w
+
+    @cache_readonly
+    def resid(self):
+        """
+        Returns the DataFrame containing the residuals of the VAR regressions.
+        Each column x1 contains the residuals generated by regressing the x1
+        column of the input against the lagged input.
+
+        Returns
+        -------
+        DataFrame
+        """
+        d = dict([(key, value.resid)
+                  for (key, value) in self.ols_results.iteritems()])
+        return WidePanel.fromDict(d)
+
+    def _data_xs(self, i):
+        return self._data.values[:, i, :].T
+
+    @cache_readonly
+    def _sigma(self):
+        """Returns covariance of resids."""
+        k = self._k
+        resid = _drop_incomplete_rows(self.resid.toLong().values)
+        n = len(resid)
+        return np.dot(resid.T, resid) / (n - k)
+
+
+def _prep_panel_data(data):
+    """Converts the given data into a WidePanel."""
+    if isinstance(data, WidePanel):
+        return data
+
+    return WidePanel.fromDict(data)
+
+def _drop_incomplete_rows(array):
+    mask = np.isfinite(array).all(1)
+    indices = np.arange(len(array))[mask]
+    return array.take(indices, 0)
+
+def _make_param_name(lag, name):
+    return 'L%d.%s' % (lag, name)
