commit bd94b257aeda4b86f8e808e2896fea15ea7bd8cc
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Sep 1 16:23:00 2011 -0400

    DOC: more reorg, deleted old series and dataframe rst files. starting on indexing docs

diff --git a/doc/source/basics.rst b/doc/source/basics.rst
index 8b67d5cfa..6d04c552b 100644
--- a/doc/source/basics.rst
+++ b/doc/source/basics.rst
@@ -1,9 +1,9 @@
 .. currentmodule:: pandas
 .. _basics:
 
-*********************
-Data structure basics
-*********************
+*************
+pandas basics
+*************
 
 We'll start with a quick, non-comprehensive overview of the fundamental data
 structures in pandas to get you started. The fundamental behavior about data
@@ -14,6 +14,7 @@ objects. To get started, import numpy and load pandas into your namespace:
    :suppress:
 
    import numpy as np
+   from pandas import *
    randn = np.random.randn
    np.set_printoptions(precision=4, suppress=True)
 
@@ -114,6 +115,8 @@ the index.
     s[[4, 3, 1]]
     np.exp(s)
 
+We will address array-based indexing in a separate :ref:`section <indexing>`.
+
 Series is dict-like
 ~~~~~~~~~~~~~~~~~~~
 
@@ -731,6 +734,14 @@ Here is a quick reference summary table of common functions
     ``cumsum``, Cumulative sum
     ``cumprod``, Cumulative product
 
+Note that by chance some NumPy methods, like ``mean``, ``std``, and ``sum``,
+will exclude NAs on Series input:
+
+.. ipython:: python
+
+   np.mean(df['one'])
+   np.mean(df['one'].values)
+
 Summarizing data: describe
 ~~~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -743,7 +754,7 @@ DataFrame (excluding NAs of course):
     series = Series(randn(1000))
     series[::2] = np.nan
     series.describe()
-    frame = DataFrame(randn(1000, 5))
+    frame = DataFrame(randn(1000, 5), columns=['a', 'b', 'c', 'd', 'e'])
     frame.ix[::2] = np.nan
     frame.describe()
 
@@ -759,7 +770,7 @@ over the labels with valid data in both objects.
 .. ipython:: python
 
    # Series with Series
-   frame[0].corr(frame[0])
+   frame['a'].corr(frame['b'])
 
    # Pairwise correlation of DataFrame columns
    frame.corr()
@@ -797,6 +808,33 @@ take an optional ``axis`` argument:
 Depending on the return type of the function passed to ``apply``, the result
 will either be of lower dimension or the same dimension.
 
+``apply`` combined with some cleverness can be used to answer many questions
+about a data set. For example, suppose we wanted to extract the date where the
+maximum value for each column occurred:
+
+
+.. ipython:: python
+
+   tsdf = DataFrame(randn(1000, 3), columns=['A', 'B', 'C'],
+                    index=DateRange('1/1/2000', periods=1000))
+   tsdf.apply(lambda x: x.index[x.dropna().argmax()])
+
+
+Another useful feature is the ability to pass Series methods to carry out some
+Series operation on each column or row:
+
+.. ipython:: python
+   :suppress:
+
+   tsdf = DataFrame(randn(10, 3), columns=['A', 'B', 'C'],
+                    index=DateRange('1/1/2000', periods=10))
+   tsdf.values[3:7] = np.nan
+
+.. ipython:: python
+
+   tsdf
+   tsdf.apply(Series.interpolate)
+
 .. seealso::
 
    The section on :ref:`GroupBy <groupby>` demonstrates related, flexible
@@ -1092,8 +1130,48 @@ Some other sorting notes / nuances:
 Copying, type casting
 ---------------------
 
+The ``copy`` method on pandas objects copies the underlying data (though not
+the axis indexes, since they are immutable) and returns a new object. Note that
+**it is seldom necessary to copy objects**. For example, there are only a
+handful of ways to alter a DataFrame *in-place*:
+
+  * Inserting, deleting, or modifying a column
+  * Assigning to the ``index`` or ``columns`` attributes
+  * For homogeneous data, directly modifying the values via the ``values``
+    attribute or fancy indexing
+
+To be clear, no pandas methods have the side effect of modifying your data;
+almost all methods return new objects, leaving the original object
+untouched. If data is modified, it is because you did so explicitly.
+
+Data can be explicitly cast to a NumPy dtype by using the ``astype`` method or
+alternately passing the ``dtype`` keyword argument to the object constructor.
+
+.. ipython:: python
+
+   df = DataFrame(np.arange(12).reshape((4, 3)))
+   df[0].dtype
+   df.astype(float)[0].dtype
+   df = DataFrame(np.arange(12).reshape((4, 3)), dtype=float)
+   df[0].dtype
+
 .. _basics.serialize:
 
 Pickling and serialization
 --------------------------
 
+All pandas objects are equipped with ``save`` and ``load`` methods which use
+Python's ``cPickle`` module to save and load data structures to disk using the
+pickle format.
+
+.. ipython:: python
+
+   df
+   df.save('foo.pickle')
+   DataFrame.load('foo.pickle')
+
+.. ipython:: python
+   :suppress:
+
+   import os
+   os.remove('foo.pickle')
diff --git a/doc/source/dataframe.rst b/doc/source/dataframe.rst
deleted file mode 100644
index fb0cc21b4..000000000
--- a/doc/source/dataframe.rst
+++ /dev/null
@@ -1,337 +0,0 @@
-.. _dataframe:
-
-.. currentmodule:: pandas
-
-*********
-DataFrame
-*********
-
-
-Slicing ranges
-~~~~~~~~~~~~~~
-
-Similar to Python lists and ndarrays, for convenience DataFrame
-supports slicing:
-
-.. ipython:: python
-
-    df[:2]
-    df[::-1]
-    df[-3:].T
-
-Boolean indexing
-~~~~~~~~~~~~~~~~
-
-As another indexing convenience, it is possible to use boolean
-indexing to select rows of a DataFrame:
-
-.. ipython:: python
-
-    df[df['A'] > 0.5]
-
-As we will see later on, the same operation could be accomplished by
-reindexing. However, the syntax would be more verbose; hence, the
-inclusion of this indexing method.
-
-Basic statistical functions
----------------------------
-
-.. seealso:: :ref:`Series statistical methods <series.statistics>`
-
-Being used to working with ndarrays, we would like to have the same
-sorts of basic descriptive statistics implemented for
-DataFrame. Additionally, and similar to NumPy MaskedArray objects,
-these should be able to handle missing data.
-
-An analogous set of methods to those in Series are provided to compute
-common moments and other aggregate statistics. These come with the
-addition that the aggregation can be over either axis of the
-DataFrame. By default the statistic will be computed for each column
-(axis 0):
-
-.. ipython:: python
-
-    >>> df
-               A              B              C              D
-    2009-01-30 00:00:00    -0.173487      -0.330054      2.45767        -0.173487
-    2009-02-27 00:00:00    -1.70517       -1.34422       0.45781        -1.70517
-    2009-03-31 00:00:00    0.517951       0.437294       0.625021       0.517951
-    2009-04-30 00:00:00    1.13914        0.976763       0.871074       1.13914
-    2009-05-29 00:00:00    -0.263249      -1.55445       0.386744       -0.263249
-    2009-06-30 00:00:00    0.994217       -0.15012       -0.444482      nan
-    2009-07-31 00:00:00    1.51264        -1.13902       0.846015       nan
-    2009-08-31 00:00:00    0.323804       -0.793455      -1.97154       nan
-    2009-09-30 00:00:00    -0.0450052     0.404083       0.588554       nan
-    2009-10-30 00:00:00    0.268981       -0.20756       -0.328061      nan
-    2009-11-30 00:00:00    0.471714       -0.0450022     -0.280202      nan
-
-    >>> df.mean()
-    A   0.27650301895
-    B   -0.340521353823
-    C   0.291691664865
-    D   -0.0969634747505
-
-    >>> df.mean(axis=1)
-    2009-01-30 00:00:00 0.445160910434
-    2009-02-27 00:00:00 -1.07419006997
-    2009-03-31 00:00:00 0.524554413383
-    2009-04-30 00:00:00 1.03152984415
-    2009-05-29 00:00:00 -0.42354987732
-    2009-06-30 00:00:00 0.133204894302
-    2009-07-31 00:00:00 0.406546724596
-    2009-08-31 00:00:00 -0.813729414124
-    2009-09-30 00:00:00 0.315877288659
-    2009-10-30 00:00:00 -0.088879865383
-    2009-11-30 00:00:00 0.048836496438
-
-The other methods listed function similarly. Combining these methods
-with the arithmetic functionality, we can very easily do things like
-computing the cross-sectional or time series z-score:
-
-::
-
-    >>> (df - df.mean(1)) / df.std(1)    # cross-sectional
-               A              B              C              D
-    2009-01-30 00:00:00    -0.839662      0.539768       1.13956        -0.839662
-    2009-02-27 00:00:00    -0.615664      1.47701        -0.245682      -0.615664
-    ...
-
-    >>> (df - df.mean()) / df.std()      # time series
-               A              B              C              D
-    2009-01-30 00:00:00    -1.79314       -0.173077      0.156054       -0.96237
-    2009-02-27 00:00:00    -1.16502       1.7612         -1.15894       -0.437405
-    ...
-
-Correlation
-~~~~~~~~~~~
-
-One related method computes the pairwise correlation of the columns,
-taking care to compute the variances over the intersection of data:
-
-::
-
-    >>> df.corr()
-     A              B              C              D
-    A    1              0.423766       -0.0985818     1
-    B    0.423766       1              0.134803       0.839771
-    C    -0.0985818     0.134803       1              0.129427
-    D    1              0.839771       0.129427       1
-
-Obviously other estimators of pairwise relationships could be computed
-in the same way.
-
-.. autosummary::
-   :toctree: generated/
-
-   DataFrame.corr
-
-Function application
---------------------
-
-You will often want to perform some other computation with the
-DataFrame other than the statistical operators above. Likewise, you
-may want to transform the data in some way (like taking the square
-root or natural logarithm). In most cases, you will want to use the
-**apply** function. In short, **apply** will call a function that you
-pass on each row or column of the DataFrame and, depending on the
-return type of the function, return a Series or DataFrame.
-
-::
-
-    >>> df.apply(np.log)
-               A              B              C
-    2009-01-30 00:00:00    nan            nan            -0.573389
-    2009-02-27 00:00:00    nan            -0.0123289     nan
-    2009-03-31 00:00:00    0.0324552      -0.982897      -1.85985
-    2009-04-30 00:00:00    nan            nan            nan
-    2009-05-29 00:00:00    nan            nan            -0.70761
-    2009-06-30 00:00:00    -1.01969       -0.598632      1.01358
-    2009-07-31 00:00:00    -2.73689       nan            -0.051959
-    2009-08-31 00:00:00    -1.90946       nan            -1.59065
-    2009-09-30 00:00:00    -0.193634      -0.87138       -0.103805
-    2009-10-30 00:00:00    -1.50367       -2.91441       -0.139465
-    2009-11-30 00:00:00    -2.08095       nan            nan
-
-    >>> df.apply(lambda x: np.sort(x)[-5:].mean())
-    A   0.517625676559
-    B   0.47682898773
-    C   1.2079285542
-
-    >>> df.apply(np.sum, axis=1)
-    2009-01-30 00:00:00    -1.35501374903
-    2009-02-27 00:00:00    -1.05605622659
-    2009-03-31 00:00:00    1.56290932477
-    2009-04-30 00:00:00    -2.1465835771
-    2009-05-29 00:00:00    -1.14076063095
-    2009-06-30 00:00:00    3.66570960365
-    2009-07-31 00:00:00    0.328066060924
-    2009-08-31 00:00:00    -0.130326883911
-    2009-09-30 00:00:00    2.14373419389
-    2009-10-30 00:00:00    1.14637153907
-    2009-11-30 00:00:00    -1.12947529696
-
-**apply** combined with some cleverness can be used to answer many
-questions about a data set. For example, suppose we wanted to extract
-the date where the maximum value for each column occurred:
-
-::
-
-    >>> df.apply(lambda x: df.index[x.valid().argmax()])
-    A    2009-03-31 00:00:00
-    B    2009-02-27 00:00:00
-    C    2009-06-30 00:00:00
-
-DataFrame also implements the ndarray *array interface* which allows you to call
-ufuncs (like sqrt, exp, log, etc.) directly on the object. So the following two
-expressions would be equivalent:
-
-::
-
-    >>> np.sqrt(df)
-    >>> df.apply(np.sqrt)
-
-Another useful feature is the ability to pass Series methods to carry
-out some Series operation on each column or row:
-
-::
-
-    >>> df.apply(Series.interpolate)
-    ...
-
-applymap
-~~~~~~~~
-
-Since we don't always have vectorized functions to **apply**,
-DataFrame has the method **applymap** which takes an elementwise
-function. Obviously this will be fairly slow but can be useful:
-
-::
-
-    >>> df.applymap(lambda x: x if x > 0 else 0)
-               A              B              C              D
-    2009-01-30 00:00:00    0              0              0.563612       0
-    2009-02-27 00:00:00    0              0.987747       0              0
-    2009-03-31 00:00:00    1.03299        0.374225       0.155696       1.03299
-    2009-04-30 00:00:00    0              0              0              0
-    2009-05-29 00:00:00    0              0              0.492821       0
-    2009-06-30 00:00:00    0.360708       0.549563       2.75544        0
-    2009-07-31 00:00:00    0.0647715      0              0.949368       0
-    2009-08-31 00:00:00    0.148161       0              0.203793       0
-    2009-09-30 00:00:00    0.82396        0.418374       0.901401       0
-    2009-10-30 00:00:00    0.222313       0.0542359      0.869823       0
-    2009-11-30 00:00:00    0.124812       0              0              0
-
-Of course you could have accomplished this using a vectorized NumPy
-function:
-
-::
-
-    >>> df.apply(lambda x: np.where(x > 0, x, 0))
-    ...
-
-Reindexing and filling / padding values
----------------------------------------
-
-.. seealso:: :ref:`Series reindexing <series.reindexing>`
-
-Similar to Series, the **reindex** method conforms a DataFrame to a
-new index or list of columns.
-
-::
-
-    >>> reindexed = df.reindex(index=new_index,
-                               columns=new_columns)
-
-For time series data, if the new index is higher frequency than the
-old one, you may wish to "fill" holes with the values as of each date:
-
-::
-
-    >>> filled = df.reindex(new_index, fillMethod='pad')
-
-Joining / merging DataFrames
-----------------------------
-
-The **join** method provides effectively SQL-like semantic for
-combining related data sets. The basic join consists of two DataFrame
-arguments and
-
-::
-
-    >>> df1
-               A              B
-    2000-01-03 00:00:00    -0.1174        -0.941
-    2000-01-04 00:00:00    -0.6034        -0.008094
-    2000-01-05 00:00:00    -0.3816        -0.9338
-    2000-01-06 00:00:00    -0.3298        -0.9548
-    2000-01-07 00:00:00    0.9576         0.4652
-    2000-01-10 00:00:00    -0.7208        -1.131
-    2000-01-11 00:00:00    1.568          0.8498
-    2000-01-12 00:00:00    0.3717         -0.2323
-    2000-01-13 00:00:00    -1.428         -1.997
-    2000-01-14 00:00:00    -1.084         -0.271
-
-    >>> df2
-               C              D
-    2000-01-03 00:00:00    0.2833         -0.1937
-    2000-01-05 00:00:00    1.868          1.207
-    2000-01-07 00:00:00    -0.8586        -0.7367
-    2000-01-11 00:00:00    2.121          0.9104
-    2000-01-13 00:00:00    0.7856         0.9063
-
-
-    df1.join(df2)
-               A              B              C              D
-    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
-    2000-01-04 00:00:00    -0.6034        -0.008094      NaN            NaN
-    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
-    2000-01-06 00:00:00    -0.3298        -0.9548        NaN            NaN
-    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
-    2000-01-10 00:00:00    -0.7208        -1.131         NaN            NaN
-    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
-    2000-01-12 00:00:00    0.3717         -0.2323        NaN            NaN
-    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
-    2000-01-14 00:00:00    -1.084         -0.271         NaN            NaN
-
-::
-
-    >>> df1.join(df2, how='inner')
-               A              B              C              D
-    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
-    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
-    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
-    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
-    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
-
-The index (row labels) are the default key for joining, but a column
-can also be used for a similar SQL-like join: It is also frequently
-necessary to join (or *merge*) data sets based on some other key
-mapping.
-
-::
-
-    >>> df2
-               C              D              key
-    2000-01-03 00:00:00    0.2833         -0.1937        0
-    2000-01-05 00:00:00    1.868          1.207          1
-    2000-01-07 00:00:00    -0.8586        -0.7367        0
-    2000-01-11 00:00:00    2.121          0.9104         1
-    2000-01-13 00:00:00    0.7856         0.9063         0
-
-    >>> df3
-     code
-    0    foo
-    1    bar
-
-    >>> df2.join(df3, on='key')
-               C              D              code           key
-    2000-01-03 00:00:00    0.2833         -0.1937        foo            0
-    2000-01-05 00:00:00    1.868          1.207          bar            1
-    2000-01-07 00:00:00    -0.8586        -0.7367        foo            0
-    2000-01-11 00:00:00    2.121          0.9104         bar            1
-    2000-01-13 00:00:00    0.7856         0.9063         foo            0
-
-.. autosummary::
-   :toctree: generated/
-
-   DataFrame.join
diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 6c7570985..6fc384025 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -2,23 +2,186 @@
 
 .. currentmodule:: pandas
 
+.. ipython:: python
+   :suppress:
+
+   import numpy as np
+   from pandas import *
+   randn = np.random.randn
+   np.set_printoptions(precision=4, suppress=True)
+
 ***************************
 Indexing and selecting data
 ***************************
 
+The axis labeling information in pandas objects serves many purposes:
+
+  - Identifies data (i.e. provides *metadata*) using known indicators,
+    important for for analysis, visualization, and interactive console display
+  - Enables automatic and explicit data alignment
+  - Allows intuitive getting and setting of subsets of the data set
+
+In this section / chapter, we will focus on the latter set of functionality,
+namely how to slice, dice, and generally get and set subsets of pandas
+objects. The primary focus will be on Series and DataFrame as they have
+received more development attention in this area. More work will be invested in
+WidePanel and future higher-dimensional data structures in the future,
+especially in label-based "fancy" indexing.
+
 .. _indexing.basics:
 
 Basics
 ------
 
-Indexing with boolean arrays
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+As mentioned when introducing the data structures in the :ref:`last section
+<basics>`, the primary function of indexing with ``[]`` (a.k.a. *__getitem__*
+for those familiar with implementing class behavior in Python) is selecting out
+lower-dimensional slices. Thus,
+
+  - **Series**: ``series[label]`` returns a scalar value
+  - **DataFrame**: ``frame[colname]`` returns a Series corresponding to the
+    passed column name
+  - **WidePanel**: ``panel[itemname]`` returns a DataFrame corresponding to the
+    passed item name
+
+Here we construct a simple time series data set to use for illustrating the
+indexing functionality:
+
+.. ipython:: python
+
+   dates = np.asarray(DateRange('1/1/2000', periods=8))
+   df = DataFrame(randn(8, 4), index=dates, columns=['A', 'B', 'C', 'D'])
+   df
+   panel = WidePanel({'one' : df, 'two' : df - df.mean()})
+   panel
+
+.. note::
+
+   None of the indexing functionality is time series specific unless
+   specifically stated.
+
+Thus, as per above, we have the most basic indexing using ``[]``:
+
+.. ipython:: python
+
+   s = df['A']
+   s[dates[5]]
+   panel['two']
+
+Data slices on other axes
+~~~~~~~~~~~~~~~~~~~~~~~~~
+
+It's certainly possible to retrieve data slices along the other axes of a
+DataFrame or WidePanel. We tend to refer to these slices as
+*cross-sections*. DataFrame has the ``xs`` function for retrieving rows as
+Series and WidePanel has the analogous ``major_xs`` and ``minor_xs`` functions
+for retrieving slices as DataFrames for a given ``major_axis`` or
+``minor_axis`` label, respectively.
+
+.. ipython:: python
+
+   date = dates[5]
+   df.xs(date)
+   panel.major_xs(date)
+   panel.minor_xs('A')
+
+.. note::
+
+   See :ref:`fancy indexing <indexing.fancy>` below for an alternate and more
+   concise way of doing the same thing.
+
+Slicing ranges
+~~~~~~~~~~~~~~
+
+:ref:`Fancy indexing <indexing.fancy>` detailed below is the most robust and
+consistent way of slicing integer ranges, e.g. ``obj[5:10]``, across all of the
+data structures and their axes. On Series, this syntax works exactly as
+expected as with an ndarray, returning a slice of the values and the
+corresponding labels:
+
+.. ipython:: python
+
+   s[:5]
+   s[::2]
+   s[::-1]
+
+Note that setting works as well:
+
+.. ipython:: python
+
+   s2 = s.copy()
+   s2[:5] = 0
+   s2
+
+With DataFrame, slicing inside of ``[]`` **slices the rows**. This is provided
+largely as a convenience since it is such a common operation.
+
+.. ipython:: python
+
+   df[:3]
+   df[::-1]
+
+Boolean indexing
+~~~~~~~~~~~~~~~~
+
+Using a boolean vector to index a Series works exactly like an ndarray:
+
+.. ipython:: python
+
+   s[s > 0]
+   s[(s < 0) & (s > -0.5)]
+
+Again as a convenience, selecting rows from a DataFrame using a boolean vector
+the same length as the DataFrame's index (for example, something derived from
+one of the columns of the DataFrame) is supported:
+
+.. ipython:: python
+
+   df[df['A'] > 0]
+
+With the fancy indexing capabilities discussed later, you are able to do
+boolean indexing in any of axes or combine a boolean vector with an indexing
+expression on one of the other axes
+
+Indexing a DataFrame with a boolean DataFrame
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+
+
+Slicing ranges
+~~~~~~~~~~~~~~
+
+Similar to Python lists and ndarrays, for convenience DataFrame
+supports slicing:
+
+.. ipython:: python
+
+    df[:2]
+    df[::-1]
+    df[-3:].T
+
+Boolean indexing
+~~~~~~~~~~~~~~~~
+
+As another indexing convenience, it is possible to use boolean
+indexing to select rows of a DataFrame:
+
+.. ipython:: python
+
+    df[df['A'] > 0.5]
+
+As we will see later on, the same operation could be accomplished by
+reindexing. However, the syntax would be more verbose; hence, the
+inclusion of this indexing method.
 
 .. _indexing.fancy:
 
 Fancy ndarray-like indexing with labels
 ---------------------------------------
 
+Fancy indexing with integer labels
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
 .. _indexing.hierarchical:
 
 Hierarchical indexing (MultiIndex)
diff --git a/doc/source/merging.rst b/doc/source/merging.rst
index e78f0d387..dd22318d3 100644
--- a/doc/source/merging.rst
+++ b/doc/source/merging.rst
@@ -40,3 +40,86 @@ the 2- and 3-D cases, but the basic concept is the same:
    :toctree: generated/
 
    Series.merge
+
+
+Joining / merging DataFrames
+----------------------------
+
+The **join** method provides effectively SQL-like semantic for
+combining related data sets. The basic join consists of two DataFrame
+arguments and
+
+::
+
+    >>> df1
+               A              B
+    2000-01-03 00:00:00    -0.1174        -0.941
+    2000-01-04 00:00:00    -0.6034        -0.008094
+    2000-01-05 00:00:00    -0.3816        -0.9338
+    2000-01-06 00:00:00    -0.3298        -0.9548
+    2000-01-07 00:00:00    0.9576         0.4652
+    2000-01-10 00:00:00    -0.7208        -1.131
+    2000-01-11 00:00:00    1.568          0.8498
+    2000-01-12 00:00:00    0.3717         -0.2323
+    2000-01-13 00:00:00    -1.428         -1.997
+    2000-01-14 00:00:00    -1.084         -0.271
+
+    >>> df2
+               C              D
+    2000-01-03 00:00:00    0.2833         -0.1937
+    2000-01-05 00:00:00    1.868          1.207
+    2000-01-07 00:00:00    -0.8586        -0.7367
+    2000-01-11 00:00:00    2.121          0.9104
+    2000-01-13 00:00:00    0.7856         0.9063
+
+
+    df1.join(df2)
+               A              B              C              D
+    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
+    2000-01-04 00:00:00    -0.6034        -0.008094      NaN            NaN
+    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
+    2000-01-06 00:00:00    -0.3298        -0.9548        NaN            NaN
+    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
+    2000-01-10 00:00:00    -0.7208        -1.131         NaN            NaN
+    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
+    2000-01-12 00:00:00    0.3717         -0.2323        NaN            NaN
+    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
+    2000-01-14 00:00:00    -1.084         -0.271         NaN            NaN
+
+::
+
+    >>> df1.join(df2, how='inner')
+               A              B              C              D
+    2000-01-03 00:00:00    -0.1174        -0.941         0.2833         -0.1937
+    2000-01-05 00:00:00    -0.3816        -0.9338        1.868          1.207
+    2000-01-07 00:00:00    0.9576         0.4652         -0.8586        -0.7367
+    2000-01-11 00:00:00    1.568          0.8498         2.121          0.9104
+    2000-01-13 00:00:00    -1.428         -1.997         0.7856         0.9063
+
+The index (row labels) are the default key for joining, but a column
+can also be used for a similar SQL-like join: It is also frequently
+necessary to join (or *merge*) data sets based on some other key
+mapping.
+
+::
+
+    >>> df2
+               C              D              key
+    2000-01-03 00:00:00    0.2833         -0.1937        0
+    2000-01-05 00:00:00    1.868          1.207          1
+    2000-01-07 00:00:00    -0.8586        -0.7367        0
+    2000-01-11 00:00:00    2.121          0.9104         1
+    2000-01-13 00:00:00    0.7856         0.9063         0
+
+    >>> df3
+     code
+    0    foo
+    1    bar
+
+    >>> df2.join(df3, on='key')
+               C              D              code           key
+    2000-01-03 00:00:00    0.2833         -0.1937        foo            0
+    2000-01-05 00:00:00    1.868          1.207          bar            1
+    2000-01-07 00:00:00    -0.8586        -0.7367        foo            0
+    2000-01-11 00:00:00    2.121          0.9104         bar            1
+    2000-01-13 00:00:00    0.7856         0.9063         foo            0
diff --git a/doc/source/series.rst b/doc/source/series.rst
deleted file mode 100644
index e3652b70d..000000000
--- a/doc/source/series.rst
+++ /dev/null
@@ -1,167 +0,0 @@
-.. currentmodule:: pandas
-.. _series:
-
-Iterating
----------
-
-Series iterates by default over its values as though it were a regular
-ndarray.
-
-Otherwise, methods providing dict-like iteration are available:
-
-::
-
-    >>> for x in ts:
-            print x
-    0.0
-    1.0
-    2.0
-    3.0
-    4.0
-
-    >>> for index, value in ts.iteritems():
-            print index, value
-    2009-01-01 00:00:00 0.0
-    2009-01-02 00:00:00 1.0
-    2009-01-05 00:00:00 2.0
-    2009-01-06 00:00:00 3.0
-    2009-01-07 00:00:00 4.0
-
-
-.. autosummary::
-   :toctree: generated/
-
-   Series.values
-   Series.iteritems
-
-.. _series.statistics:
-
-Basic statistical functions
----------------------------
-
-There are many built-in ndarray methods providing basic descriptive
-statistics. Since these do not handle missing observations (which are
-represented in our case as NaN), we've overridden these methods to do
-the appropriate handling.
-
-For example:
-
-::
-
-    >>> s
-    a    0.0
-    b    1.0
-    c    nan
-    d    3.0
-    e    4.0
-
-    >>> s.count()
-    4
-
-    >>> s.std()
-    1.8257418583505536
-
-    >>> s.cumsum()
-    a    0.0
-    b    1.0
-    c    nan
-    d    4.0
-    e    8.0
-
-Due to the way the numpy.{sum, mean, var, std} are implemented, they
-can be used safely:
-
-::
-
-    >>> np.mean(s)
-    2.0
-
-
-TimeSeries-oriented methods
----------------------------
-
-.. seealso::
-    :ref:`Reindexing methods <series.reindexing>`;
-    :ref:`DateRange and date offsets / time rules <datetools>`
-
-.. note::
-
-    While pandas does not force you to sort your dates, many of these
-    methods may have unexpected or incorrect behavior in that case. In
-    other words, *be careful*.
-
-When working with time series data, a number of different
-time-oriented operations may be useful. The first is **frequency
-conversion**, which has similar options to :func:`Series.reindex`:
-
-::
-
-    >>> dr = DateRange('1/1/2010', periods=10,
-                       offset=datetools.BMonthEnd())
-    >>> ts = Series(np.arange(10.), index=dr)
-    >>> ts
-    2010-01-29 00:00:00    0.0
-    2010-02-26 00:00:00    1.0
-    2010-03-31 00:00:00    2.0
-    2010-04-30 00:00:00    3.0
-    2010-05-31 00:00:00    4.0
-    2010-06-30 00:00:00    5.0
-    2010-07-30 00:00:00    6.0
-    2010-08-31 00:00:00    7.0
-    2010-09-30 00:00:00    8.0
-    2010-10-29 00:00:00    9.0
-
-    >>> ts.asfreq('WEEKDAY', method='pad')
-    2010-01-29 00:00:00    0.0
-    2010-02-01 00:00:00    0.0
-    2010-02-02 00:00:00    0.0
-    2010-02-03 00:00:00    0.0
-    2010-02-04 00:00:00    0.0
-    <snip>
-    2010-10-22 00:00:00    8.0
-    2010-10-25 00:00:00    8.0
-    2010-10-26 00:00:00    8.0
-    2010-10-27 00:00:00    8.0
-    2010-10-28 00:00:00    8.0
-    2010-10-29 00:00:00    9.0
-
-We often will also want to **shift** or *lag* a TimeSeries:
-
-::
-
-    >>> ts.shift(1)
-    2010-01-29 00:00:00    NaN
-    2010-02-26 00:00:00    0.0
-    2010-03-31 00:00:00    1.0
-    2010-04-30 00:00:00    2.0
-    2010-05-31 00:00:00    3.0
-    2010-06-30 00:00:00    4.0
-    2010-07-30 00:00:00    5.0
-    2010-08-31 00:00:00    6.0
-    2010-09-30 00:00:00    7.0
-    2010-10-29 00:00:00    8.0
-
-    >>> ts.shift(5, offset=datetools.bday)
-    2010-02-05 00:00:00    0.0
-    2010-03-05 00:00:00    1.0
-    2010-04-07 00:00:00    2.0
-    2010-05-07 00:00:00    3.0
-    2010-06-07 00:00:00    4.0
-    2010-07-07 00:00:00    5.0
-    2010-08-06 00:00:00    6.0
-    2010-09-07 00:00:00    7.0
-    2010-10-07 00:00:00    8.0
-    2010-11-05 00:00:00    9.0
-
-In the presence of missing data with sorted dates
-
-A convenience method for selecting weekdays, similar to
-:mod:`scikits.timeseries` is also provided:
-
-::
-
-    >>> dr = DateRange('1/1/2010', periods=10, offset=datetools.bday)
-    >>> ts = Series(np.arange(10.), index=dr)
-    >>> ts[ts.weekday == 2]
-    2010-01-06 00:00:00    3.0
-    2010-01-13 00:00:00    8.0
diff --git a/doc/source/timeseries.rst b/doc/source/timeseries.rst
index eb045f710..71b6ced69 100644
--- a/doc/source/timeseries.rst
+++ b/doc/source/timeseries.rst
@@ -6,4 +6,91 @@ Time Series / Date functionality
 ********************************
 
 
+TimeSeries-oriented methods
+---------------------------
 
+.. seealso::
+    :ref:`Reindexing methods <series.reindexing>`;
+    :ref:`DateRange and date offsets / time rules <datetools>`
+
+.. note::
+
+    While pandas does not force you to sort your dates, many of these
+    methods may have unexpected or incorrect behavior in that case. In
+    other words, *be careful*.
+
+When working with time series data, a number of different
+time-oriented operations may be useful. The first is **frequency
+conversion**, which has similar options to :func:`Series.reindex`:
+
+::
+
+    >>> dr = DateRange('1/1/2010', periods=10,
+                       offset=datetools.BMonthEnd())
+    >>> ts = Series(np.arange(10.), index=dr)
+    >>> ts
+    2010-01-29 00:00:00    0.0
+    2010-02-26 00:00:00    1.0
+    2010-03-31 00:00:00    2.0
+    2010-04-30 00:00:00    3.0
+    2010-05-31 00:00:00    4.0
+    2010-06-30 00:00:00    5.0
+    2010-07-30 00:00:00    6.0
+    2010-08-31 00:00:00    7.0
+    2010-09-30 00:00:00    8.0
+    2010-10-29 00:00:00    9.0
+
+    >>> ts.asfreq('WEEKDAY', method='pad')
+    2010-01-29 00:00:00    0.0
+    2010-02-01 00:00:00    0.0
+    2010-02-02 00:00:00    0.0
+    2010-02-03 00:00:00    0.0
+    2010-02-04 00:00:00    0.0
+    <snip>
+    2010-10-22 00:00:00    8.0
+    2010-10-25 00:00:00    8.0
+    2010-10-26 00:00:00    8.0
+    2010-10-27 00:00:00    8.0
+    2010-10-28 00:00:00    8.0
+    2010-10-29 00:00:00    9.0
+
+We often will also want to **shift** or *lag* a TimeSeries:
+
+::
+
+    >>> ts.shift(1)
+    2010-01-29 00:00:00    NaN
+    2010-02-26 00:00:00    0.0
+    2010-03-31 00:00:00    1.0
+    2010-04-30 00:00:00    2.0
+    2010-05-31 00:00:00    3.0
+    2010-06-30 00:00:00    4.0
+    2010-07-30 00:00:00    5.0
+    2010-08-31 00:00:00    6.0
+    2010-09-30 00:00:00    7.0
+    2010-10-29 00:00:00    8.0
+
+    >>> ts.shift(5, offset=datetools.bday)
+    2010-02-05 00:00:00    0.0
+    2010-03-05 00:00:00    1.0
+    2010-04-07 00:00:00    2.0
+    2010-05-07 00:00:00    3.0
+    2010-06-07 00:00:00    4.0
+    2010-07-07 00:00:00    5.0
+    2010-08-06 00:00:00    6.0
+    2010-09-07 00:00:00    7.0
+    2010-10-07 00:00:00    8.0
+    2010-11-05 00:00:00    9.0
+
+In the presence of missing data with sorted dates
+
+A convenience method for selecting weekdays, similar to
+:mod:`scikits.timeseries` is also provided:
+
+::
+
+    >>> dr = DateRange('1/1/2010', periods=10, offset=datetools.bday)
+    >>> ts = Series(np.arange(10.), index=dr)
+    >>> ts[ts.weekday == 2]
+    2010-01-06 00:00:00    3.0
+    2010-01-13 00:00:00    8.0
