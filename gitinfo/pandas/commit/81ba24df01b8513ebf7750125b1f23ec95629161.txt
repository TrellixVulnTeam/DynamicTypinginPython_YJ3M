commit 81ba24df01b8513ebf7750125b1f23ec95629161
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jan 17 14:34:37 2012 -0500

    BUG: fix multi-iter bug and pure Python aggregation given compressed ids re: GH #618

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index b3e00e50a..17a8e29da 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -222,18 +222,16 @@ class GroupBy(object):
 
     def _multi_iter(self):
         data = self.obj
-        if (isinstance(self.obj, NDFrame) and
-            not isinstance(self.obj, DataFrame)):
-            data = self.obj._data
-
-        id_list = [ping.ids for ping in self.groupings]
-        shape = tuple(len(ids) for ids in id_list)
+        group_index = self._group_index
+        comp_ids, _, ngroups = _compress_group_index(group_index)
+        label_list = [ping.labels for ping in self.groupings]
+        level_list = [ping.group_index for ping in self.groupings]
+        mapper = _KeyMapper(comp_ids, ngroups, label_list, level_list)
 
-        for label, group in self._generator_factory(data):
+        for label, group in self._generate_groups(data, comp_ids, ngroups):
             if group is None:
                 continue
-            unraveled = np.unravel_index(label, shape)
-            key = tuple(id_list[i][j] for i, j in enumerate(unraveled))
+            key = mapper.get_key(label)
             yield key, group
 
     def apply(self, func, *args, **kwargs):
@@ -409,15 +407,30 @@ class GroupBy(object):
 
     def _aggregate_series(self, obj, func, group_index, ngroups):
         try:
-            return _aggregate_series_fast(obj, func, group_index, ngroups)
+            return self._aggregate_series_fast(obj, func, group_index, ngroups)
         except Exception:
-            return self._aggregate_series_pure_python(obj, func, ngroups)
+            return self._aggregate_series_pure_python(obj, func, group_index,
+                                                      ngroups)
+
+    def _aggregate_series_fast(self, obj, func, group_index, ngroups):
+        if obj.index._has_complex_internals:
+            raise TypeError('Incompatible index for Cython grouper')
+
+        # avoids object / Series creation overhead
+        dummy = obj[:0].copy()
+        indexer = lib.groupsort_indexer(group_index, ngroups)[0]
+        obj = obj.take(indexer)
+        group_index = group_index.take(indexer)
+        grouper = lib.SeriesGrouper(obj, func, group_index, ngroups,
+                                    dummy)
+        result, counts = grouper.get_result()
+        return result, counts
 
-    def _aggregate_series_pure_python(self, obj, func, ngroups):
+    def _aggregate_series_pure_python(self, obj, func, group_index, ngroups):
         counts = np.zeros(ngroups, dtype=int)
         result = None
 
-        for label, group in self._generator_factory(obj):
+        for label, group in self._generate_groups(obj, group_index, ngroups):
             if group is None:
                 continue
             res = func(group)
@@ -478,19 +491,15 @@ class GroupBy(object):
 
         return result
 
-    @property
-    def _generator_factory(self):
-        labels = [ping.labels for ping in self.groupings]
-        shape = self._group_shape
-
-        if isinstance(self.obj, NDFrame):
-            factory = self.obj._constructor
+    def _generate_groups(self, obj, group_index, ngroups):
+        if isinstance(obj, NDFrame) and not isinstance(obj, DataFrame):
+            factory = obj._constructor
+            obj = obj._data
         else:
             factory = None
 
-        return lambda obj: generate_groups(obj, labels, shape,
-                                           axis=self.axis,
-                                           factory=factory)
+        return generate_groups(obj, group_index, ngroups,
+                               axis=self.axis, factory=factory)
 
 @Appender(GroupBy.__doc__)
 def groupby(obj, by, **kwds):
@@ -1244,7 +1253,7 @@ class NDArrayGroupBy(GroupBy):
 #----------------------------------------------------------------------
 # Grouping generator for BlockManager
 
-def generate_groups(data, label_list, shape, axis=0, factory=lambda x: x):
+def generate_groups(data, group_index, ngroups, axis=0, factory=lambda x: x):
     """
     Parameters
     ----------
@@ -1254,13 +1263,8 @@ def generate_groups(data, label_list, shape, axis=0, factory=lambda x: x):
     -------
     generator
     """
-    group_index = get_group_index(label_list, shape)
-    na_mask = np.zeros(len(label_list[0]), dtype=bool)
-    for arr in label_list:
-        na_mask |= arr == -1
-    group_index[na_mask] = -1
     indexer = lib.groupsort_indexer(group_index.astype('i4'),
-                                    np.prod(shape))[0]
+                                    ngroups)[0]
     group_index = group_index.take(indexer)
 
     if isinstance(data, BlockManager):
@@ -1290,7 +1294,7 @@ def generate_groups(data, label_list, shape, axis=0, factory=lambda x: x):
             return sorted_data[slob]
 
     starts, ends = lib.generate_slices(group_index.astype('i4'),
-                                       np.prod(shape))
+                                       ngroups)
 
     for i, (start, end) in enumerate(zip(starts, ends)):
         if start == end:
@@ -1327,20 +1331,28 @@ def decons_group_index(comp_labels, shape):
         factor *= shape[i]
     return label_list[::-1]
 
-def _aggregate_series_fast(obj, func, group_index, ngroups):
-    if obj.index._has_complex_internals:
-        raise TypeError('Incompatible index for Cython grouper')
 
-    # avoids object / Series creation overhead
-    dummy = obj[:0].copy()
-    indexer = lib.groupsort_indexer(group_index, ngroups)[0]
-    obj = obj.take(indexer)
-    group_index = group_index.take(indexer)
-    grouper = lib.SeriesGrouper(obj, func, group_index, ngroups,
-                                dummy)
-    result, counts = grouper.get_result()
-    return result, counts
+class _KeyMapper(object):
+    """
+    Ease my suffering. Map compressed group id -> key tuple
+    """
+    def __init__(self, comp_ids, ngroups, labels, levels):
+        self.levels = levels
+        self.labels = labels
+        self.comp_ids = comp_ids.astype('i8')
+
+        self.k = len(labels)
+        self.tables = [lib.Int64HashTable(ngroups) for _ in range(self.k)]
+
+        self._populate_tables()
+
+    def _populate_tables(self):
+        for labs, table in zip(self.labels, self.tables):
+            table.map(self.comp_ids, labs.astype('i8'))
 
+    def get_key(self, comp_id):
+        return tuple(level[table.get_item(comp_id)]
+                     for table, level in zip(self.tables, self.levels))
 
 #----------------------------------------------------------------------
 # Group aggregations in Cython
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 32f489b71..81e75d5c2 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -157,10 +157,18 @@ class TestGroupBy(unittest.TestCase):
 
         # DataFrame
         grouped = self.tsframe.groupby(self.tsframe['A'] * np.nan)
-        assert_frame_equal(grouped.sum(), DataFrame(columns=self.tsframe.columns))
+        assert_frame_equal(grouped.sum(),
+                           DataFrame(columns=self.tsframe.columns))
         assert_frame_equal(grouped.agg(np.sum), DataFrame({}))
         assert_frame_equal(grouped.apply(np.sum), DataFrame({}))
 
+    def test_agg_python_multiindex(self):
+        grouped = self.mframe.groupby(['A', 'B'])
+
+        result = grouped.agg(np.mean)
+        expected = grouped.mean()
+        tm.assert_frame_equal(result, expected)
+
     def test_apply_describe_bug(self):
         grouped = self.mframe.groupby(level='first')
         result = grouped.describe() # it works!
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index 63bda01a8..be864cf7a 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -5,7 +5,7 @@ from pandas.tools.merge import concat
 import pandas.core.common as com
 import numpy as np
 
-def pivot_table(data, values=None, rows=None, cols=None, aggfunc=np.mean,
+def pivot_table(data, values=None, rows=None, cols=None, aggfunc='mean',
                 fill_value=None, margins=False):
     """
     Create a spreadsheet-style pivot table as a DataFrame. The levels in the
