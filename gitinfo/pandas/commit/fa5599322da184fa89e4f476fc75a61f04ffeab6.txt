commit fa5599322da184fa89e4f476fc75a61f04ffeab6
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Oct 16 11:09:22 2011 -0400

    ENH: parsers: fast zip(*args), made everything ndarray-based, faster

diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 5208f30c0..6d869a0f0 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -148,8 +148,6 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
             columns = colNames
         content = lines
 
-    zipped_content = zip(*content)
-
     if len(content) == 0: # pragma: no cover
         if index_col is not None:
             if np.isscalar(index_col):
@@ -181,18 +179,21 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
         na_values = set(list(na_values)) | NA_VALUES
 
 
+    zipped_content = list(lib.to_object_array(content).T)
+
     if index_col is None and len(content[0]) == len(columns) + 1:
         index_col = 0
 
     # no index column specified, so infer that's what is wanted
     if index_col is not None:
         if np.isscalar(index_col):
-            if index_col == 0 and len(content[0]) == len(columns) + 1:
-                index = zipped_content[0]
-                zipped_content = zipped_content[1:]
+            index = zipped_content.pop(index_col)
+
+            if len(content[0]) == len(columns) + 1:
+                name = None
             else:
-                index = zipped_content.pop(index_col)
-                columns.pop(index_col)
+                name = columns.pop(index_col)
+
         else: # given a list of index
             idx_names = []
             index = []
@@ -204,11 +205,10 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
                 columns.remove(idx_names[i])
                 zipped_content.remove(index[i])
 
-
         if np.isscalar(index_col):
             if parse_dates:
-                index = _try_parse_dates(index, parser=date_parser)
-            index = Index(_convert_ndarray(index, na_values))
+                index = lib.try_parse_dates(index, parser=date_parser)
+            index = Index(_convert_types(index, na_values), name=name)
         else:
             arrays = _maybe_convert_int_mindex(index, parse_dates,
                                                date_parser)
@@ -224,28 +224,11 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
     if len(columns) != len(zipped_content):
         raise Exception('wrong number of columns')
 
-    data = dict(izip(columns, zipped_content))
+    data = dict((k, v) for k, v in zip(columns, zipped_content))
     data = _convert_to_ndarrays(data, na_values)
-
     return DataFrame(data=data, columns=columns, index=index)
 
 
-
-def _floatify(tup, na_values):
-    """
-
-    """
-    try:
-        if isinstance(tup, tuple):
-            return lib.maybe_convert_numeric(tup, na_values)
-        else:
-            return lib.maybe_convert_float_list(tup, na_values)
-    except Exception:
-        if isinstance(tup, tuple):
-            return lib.string_to_ndarray_tuple(tup)
-        else:
-            return lib.string_to_ndarray_list(tup)
-
 def _maybe_convert_int(arr):
     if len(arr) == 0: # pragma: no cover
         return arr
@@ -259,11 +242,6 @@ def _maybe_convert_int(arr):
 
     return arr
 
-def _maybe_convert_bool(arr):
-    if arr.dtype == np.object_:
-        return lib.maybe_convert_bool_object(arr)
-    return arr
-
 def _maybe_convert_int_mindex(index, parse_dates, date_parser):
     for i in range(len(index)):
         try:
@@ -271,41 +249,25 @@ def _maybe_convert_int_mindex(index, parse_dates, date_parser):
             index[i] = map(int, index[i])
         except ValueError:
             if parse_dates:
-                index[i] = _try_parse_dates(index[i], date_parser)
+                index[i] = lib.try_parse_dates(index[i], date_parser)
 
     return index
 
 def _convert_to_ndarrays(dct, na_values):
     result = {}
     for c, values in dct.iteritems():
-        result[c] = _convert_ndarray(values, na_values)
+        result[c] = _convert_types(values, na_values)
     return result
 
-def _convert_ndarray(tup, na_values):
-    values = _floatify(tup, na_values)
-    values = _maybe_convert_bool(values)
-    return values
-
-def _try_parse_dates(values, parser=None):
-    if parser is None:
-        try:
-            from dateutil import parser
-            parse_date = parser.parse
-        except ImportError: # pragma: no cover
-            def parse_date(s):
-                try:
-                    return datetime.strptime(s, '%m/%d/%Y')
-                except Exception:
-                    return s
-    else:
-        parse_date = parser
-
-    # EAFP
+def _convert_types(values, na_values):
     try:
-        return [parse_date(val) for val in values]
+        values = lib.maybe_convert_numeric(values, na_values)
     except Exception:
-        # failed
-        return values
+        lib.sanitize_objects(values)
+
+    if values.dtype == np.object_:
+        return lib.maybe_convert_bool(values)
+    return values
 
 #-------------------------------------------------------------------------------
 # ExcelFile class
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index cd1a57847..4a84d2129 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -8,7 +8,7 @@ import nose
 from numpy import nan
 import numpy as np
 
-from pandas import DataFrame
+from pandas import DataFrame, Index
 from pandas.io.parsers import read_csv, read_table, ExcelFile
 from pandas.util.testing import assert_almost_equal, assert_frame_equal
 
@@ -76,7 +76,7 @@ d,,f
 6,7,8,9,10
 11,12,13,14,15
 """
-        df = read_table(StringIO(data), sep=',', index_col=None)
+        df = read_table(StringIO(data), sep=',')
         self.assert_(np.array_equal(df.columns,
                                     ['A', 'A.1', 'B', 'B.1', 'B.2']))
 
@@ -86,7 +86,7 @@ a,1,2
 b,3,4
 c,4,5
 """
-        df = read_csv(StringIO(data), index_col=None)
+        df = read_csv(StringIO(data))
         # TODO
 
     def test_csv_custom_parser(self):
@@ -120,6 +120,7 @@ c,4,5
         df = read_csv(self.csv1, index_col=0, parse_dates=True)
         df2 = read_table(self.csv1, sep=',', index_col=0, parse_dates=True)
         self.assert_(np.array_equal(df.columns, ['A', 'B', 'C', 'D']))
+        self.assert_(df.index.name == 'index')
         self.assert_(isinstance(df.index[0], datetime))
         self.assert_(df.values.dtype == np.float64)
         assert_frame_equal(df, df2)
@@ -184,6 +185,15 @@ True,3
         self.assert_(data['A'].dtype == np.float_)
         self.assert_(data['B'].dtype == np.int_)
 
+    def test_infer_index_col(self):
+        data = """A,B,C
+foo,1,2,3
+bar,4,5,6
+baz,7,8,9
+"""
+        data = read_csv(StringIO(data))
+        self.assert_(data.index.equals(Index(['foo', 'bar', 'baz'])))
+
 def curpath():
     pth, _ = os.path.split(os.path.abspath(__file__))
     return pth
diff --git a/pandas/src/parsing.pyx b/pandas/src/parsing.pyx
index e792342d1..8a67b90d4 100644
--- a/pandas/src/parsing.pyx
+++ b/pandas/src/parsing.pyx
@@ -3,65 +3,31 @@ cimport cpython
 cdef extern from "math.h":
     double fabs(double)
 
-def maybe_convert_float_list(tuple values):
+def to_object_array(list rows):
     cdef:
-        Py_ssize_t i, n
-        ndarray[float64_t] result
-        object val
+        Py_ssize_t i, j, n, k, tmp
+        ndarray[object, ndim=2] result
+        list row
 
-    n = len(values)
-    result = np.empty(n, dtype='f8')
+    n = len(rows)
 
+    k = 0
     for i from 0 <= i < n:
-        val = values[i]
-        result[i] = <float64_t> val
-
-    return val
-
-def maybe_convert_numeric(tuple values, set na_values):
-    cdef:
-        Py_ssize_t i, n
-        ndarray[float64_t] floats
-        ndarray[int64_t] ints
-        bint seen_float = 0
-        object val
-        float64_t fval
-
-    n = len(values)
+        tmp = len(rows[i])
+        if tmp > k:
+            k = tmp
 
-    floats = np.empty(n, dtype='f8')
-    ints = np.empty(n, dtype='i8')
+    result = np.empty((n, k), dtype=object)
 
     for i from 0 <= i < n:
-        val = values[i]
+        row = rows[i]
 
-        if cpython.PyFloat_Check(val):
-            floats[i] = val
-            seen_float = 1
-        elif val in na_values:
-            floats[i] = nan
-            seen_float = 1
-        elif val is None:
-            floats[i] = nan
-            seen_float = 1
-        elif len(val) == 0:
-            floats[i] = nan
-            seen_float = 1
-        else:
-            fval = float(val)
-            floats[i] = fval
-            if not seen_float:
-                if '.' in val:
-                    seen_float = 1
-                else:
-                    ints[i] = <int64_t> fval
+        for j from 0 <= j < len(row):
+            result[i, j] = row[j]
 
-    if seen_float:
-        return floats
-    else:
-        return ints
+    return result
 
-def maybe_convert_numeric_list(list values, set na_values):
+def maybe_convert_numeric(ndarray[object] values, set na_values):
     cdef:
         Py_ssize_t i, n
         ndarray[float64_t] floats
@@ -104,47 +70,53 @@ def maybe_convert_numeric_list(list values, set na_values):
     else:
         return ints
 
-def string_to_ndarray_tuple(tuple values):
+def try_parse_dates(ndarray[object] values, parser=None):
     cdef:
         Py_ssize_t i, n
         ndarray[object] result
-        object val, onan
 
-    n = len(values)
-    result = np.empty(n, dtype=object)
-    onan = np.nan
+    from datetime import datetime
 
-    for i from 0 <= i < n:
-        val = values[i]
+    n = len(values)
+    result = np.empty(n, dtype='O')
+
+    if parser is None:
+        try:
+            from dateutil import parser
+            parse_date = parser.parse
+        except ImportError: # pragma: no cover
+            def parse_date(s):
+                try:
+                    return datetime.strptime(s, '%m/%d/%Y')
+                except Exception:
+                    return s
+    else:
+        parse_date = parser
 
-        if val == '':
-            result[i] = onan
-        else:
-            result[i] = val
+    # EAFP
+    try:
+        for i from 0 <= i < n:
+            result[i] = parse_date(values[i])
+    except Exception:
+        # failed
+        return values
 
     return result
 
-def string_to_ndarray_list(list values):
+def sanitize_objects(ndarray[object] values):
     cdef:
         Py_ssize_t i, n
-        ndarray[object] result
         object val, onan
 
     n = len(values)
-    result = np.empty(n, dtype=object)
     onan = np.nan
 
     for i from 0 <= i < n:
         val = values[i]
-
         if val == '':
-            result[i] = onan
-        else:
-            result[i] = val
-
-    return result
+            values[i] = onan
 
-def maybe_convert_bool_object(ndarray[object] arr):
+def maybe_convert_bool(ndarray[object] arr):
     cdef:
         Py_ssize_t i, n
         ndarray[uint8_t, cast=True] result
@@ -164,48 +136,3 @@ def maybe_convert_bool_object(ndarray[object] arr):
             return arr
 
     return result
-
-cdef float64_t FP_ERR = 1e-10
-
-def maybe_convert_int(ndarray[float64_t] arr):
-    cdef:
-        Py_ssize_t i, n
-        ndarray[int64_t] result
-        float64_t val
-
-    n = len(arr)
-    result = np.empty(n, dtype='i8')
-    for i from 0 <= i < n:
-        val = arr[i]
-        result[i] = <int64_t> val
-
-        # NA
-        if val != val:
-            return arr
-
-        if fabs(result[i] - val) > FP_ERR:
-            return arr
-
-    return result
-
-def maybe_convert_int_object(ndarray[object] arr):
-    cdef:
-        Py_ssize_t i, n
-        ndarray[int64_t] result
-        object val
-
-    n = len(arr)
-    result = np.empty(n, dtype='i8')
-    for i from 0 <= i < n:
-        val = arr[i]
-        result[i] = <int64_t> val
-
-        # NA
-        if val != val:
-            return arr
-
-        if fabs(result[i] - val) > FP_ERR:
-            return arr
-
-    return result
-
