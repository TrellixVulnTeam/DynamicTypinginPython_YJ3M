commit 32f51c42e751b33ff357fa7275a8f6fa15964a56
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Jun 8 18:38:50 2011 -0400

    brought back dtype casting. making progress

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 5b03ab127..1a33513e2 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1349,25 +1349,6 @@ class DataFrame(PandasGeneric):
         return self._constructor(data=self.values.T, index=self.columns,
                                  columns=self.index)
 
-    # @property
-    # def T(self):
-    #     """
-    #     Returns a DataFrame with the rows/columns switched.
-    #     """
-    #     # Need to do some 'type inference' to avoid casting
-    #     # float to string in weird cases
-    #     dtypes = list(set([x.dtype for x in self._series.values()]))
-    #     if len(dtypes) > 1:
-    #         theDtype = np.object_
-    #     else:
-    #         theDtype = dtypes[0]
-
-    #     valuesT = np.array([self[col] for col in self.columns],
-    #                        dtype=theDtype).T
-
-    #     return DataFrame(data=dict(zip(self.index, valuesT)),
-    #                      index=self.columns, columns=self.index)
-
     def diff(self, periods=1):
         return self - self.shift(periods)
 
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index c03daa42b..24faaa8e5 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -187,6 +187,15 @@ class BlockManager(object):
         for block in self.blocks:
             assert(len(block) == length)
 
+    def cast(self, dtype):
+        new_blocks = []
+        for block in self.blocks:
+            newb = Block(block.values.astype(dtype), block.columns)
+            new_blocks.append(newb)
+
+        new_mgr = BlockManager(new_blocks, self.index, self.columns)
+        return new_mgr.consolidate()
+
     def is_consolidated(self):
         """
         Return True if more than one block with the same dtype
@@ -225,16 +234,16 @@ class BlockManager(object):
 
     def as_matrix(self, columns=None):
         if columns is None:
-            if len(self.blocks) == 0:
-                return np.empty((len(self.index), 0), dtype=float)
-            elif len(self.blocks) == 1:
-                blk = self.blocks[0]
-                if blk.columns.equals(self.columns):
-                    # if not, then just call interleave per below
-                    return blk.values
-            return _interleave(self.blocks, self.columns)
-        else:
-            return _interleave(self.blocks, columns)
+            columns = self.columns
+
+        if len(self.blocks) == 0:
+            return np.empty((len(self.index), 0), dtype=float)
+        elif len(self.blocks) == 1:
+            blk = self.blocks[0]
+            if blk.columns.equals(columns):
+                # if not, then just call interleave per below
+                return blk.values
+        return _interleave(self.blocks, columns)
 
     def xs(self, i, copy=True):
         if len(self.blocks) > 1:
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index ea16a3a01..dd56a1de0 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -4,7 +4,7 @@
 from cStringIO import StringIO
 import sys
 
-from numpy import NaN
+from numpy import nan
 import numpy as np
 
 from pandas.core.common import (_pickle_array, _unpickle_array, _try_sort)
@@ -44,18 +44,22 @@ class DataMatrix(DataFrame):
     unless you are doing a lot of column insertion / deletion (which causes the
     underlying ndarray to have to be reallocated!).
     """
-    def __init__(self, data=None, index=None, columns=None):
+    def __init__(self, data=None, index=None, columns=None, dtype=None):
         if data is None:
             data = {}
 
         if isinstance(data, BlockManager):
             mgr = data
-            index = data.index
-            columns = data.columns
+        elif isinstance(data, DataMatrix):
+            mgr = data._data.copy()
+
+            if dtype is not None:
+                mgr = mgr.cast(dtype)
+
         elif isinstance(data, dict):
-            index, columns, mgr = _init_dict(data, index, columns)
+            mgr = _init_dict(data, index, columns, dtype)
         elif isinstance(data, (np.ndarray, list)):
-            index, columns, mgr = _init_matrix(data, index, columns)
+            mgr = _init_matrix(data, index, columns, dtype)
         else:
             raise Exception('DataMatrix constructor not properly called!')
 
@@ -123,7 +127,7 @@ class DataMatrix(DataFrame):
         notmask = -mask
 
         tmpMatrix = other.values.take(fillVec, axis=0)
-        tmpMatrix[notmask] = NaN
+        tmpMatrix[notmask] = nan
 
         seriesDict = dict((col, tmpMatrix[:, j])
                            for j, col in enumerate(other.columns))
@@ -132,7 +136,7 @@ class DataMatrix(DataFrame):
             objects = other.objects
 
             tmpMat = objects.values.take(fillVec, axis=0)
-            tmpMat[notmask] = NaN
+            tmpMat[notmask] = nan
             objDict = dict((col, tmpMat[:, j])
                            for j, col in enumerate(objects.columns))
 
@@ -197,9 +201,9 @@ class DataMatrix(DataFrame):
         if not self and not other:
             return DataMatrix(index=new_index)
         elif not self:
-            return other * NaN
+            return other * nan
         elif not other:
-            return self * NaN
+            return self * nan
 
         need_reindex = False
         new_columns = self._union_columns(other)
@@ -287,6 +291,44 @@ class DataMatrix(DataFrame):
         else:
             self.objects = None
 
+    """
+    def __getstate__(self):
+        if self.objects is not None:
+            objects = self.objects._matrix_state(pickle_index=False)
+        else:
+            objects = None
+
+        state = self._matrix_state()
+
+        return (state, objects)
+
+    def _matrix_state(self, pickle_index=True):
+        columns = _pickle_array(self.columns)
+
+        if pickle_index:
+            index = _pickle_array(self.index)
+        else:
+            index = None
+
+        return self.values, index, columns
+
+    def __setstate__(self, state):
+        (vals, idx, cols), object_state = state
+
+        self.values = vals
+        self.index = _unpickle_array(idx)
+        self.columns = _unpickle_array(cols)
+
+        if object_state:
+            ovals, _, ocols = object_state
+            self.objects = DataMatrix(ovals,
+                                      index=self.index,
+                                      columns=_unpickle_array(ocols))
+        else:
+            self.objects = None
+
+    """
+
     def __getitem__(self, item):
         """
         Retrieve column, slice, or subset from DataMatrix.
@@ -492,12 +534,11 @@ class DataMatrix(DataFrame):
             y[mask] = 0
             result = y.cumsum(axis)
             has_obs = (-mask).astype(int).cumsum(axis) > 0
-            result[-has_obs] = np.NaN
+            result[-has_obs] = np.nan
         else:
             result = y.cumsum(axis)
-
         return DataMatrix(result, index=self.index,
-                          columns=self.columns, objects=self.objects)
+                          columns=self.columns)
 
     def min(self, axis=0):
         """
@@ -535,7 +576,7 @@ class DataMatrix(DataFrame):
 
     def fillna(self, value=None, method='pad'):
         """
-        Fill NaN values using the specified method.
+        Fill nan values using the specified method.
 
         Member Series / TimeSeries are filled separately.
 
@@ -639,9 +680,9 @@ class DataMatrix(DataFrame):
             new_values = common.ensure_float(new_values)
 
             if periods > 0:
-                new_values[:periods] = NaN
+                new_values[:periods] = nan
             else:
-                new_values[periods:] = NaN
+                new_values[periods:] = nan
         else:
             new_index = self.index.shift(periods, offset)
             new_values = self.values.copy()
@@ -680,7 +721,7 @@ def _group_dtypes(data, columns):
 
     return chunks, chunk_cols
 
-def _init_dict(data, index, columns):
+def _init_dict(data, index, columns, dtype):
     """
     Segregate Series based on type and coerce into matrices.
 
@@ -688,21 +729,25 @@ def _init_dict(data, index, columns):
 
     Somehow this got outrageously complicated
     """
+    # TODO: deal with emptiness!
+    # TODO: dtype casting?
+
+    # prefilter if columns passed
+    if columns is not None:
+        columns = _ensure_index(columns)
+        data = dict((k, v) for k, v in data.iteritems() if k in columns)
+
     # figure out the index, if necessary
     if index is None:
         index = extract_index(data)
 
-    # TODO: deal with emptiness!
-    # TODO: dtype casting?
-
     # don't force copy because getting jammed in an ndarray anyway
-    homogenized = _homogenize_series(data, index, force_copy=False)
+    homogenized = _homogenize_series(data, index, dtype, force_copy=False)
     # segregates dtypes and forms blocks matching to columns
-    blocks, columns = _form_blocks(homogenized, columns)
-    mgr = BlockManager(blocks, index, columns)
-    return index, columns, mgr
+    blocks, columns = _form_blocks(homogenized, index, columns)
+    return BlockManager(blocks, index, columns)
 
-def _form_blocks(data, columns):
+def _form_blocks(data, index, columns):
     # pre-filter out columns if we passed it
     if columns is None:
         columns = Index(_try_sort(data.keys()))
@@ -711,9 +756,6 @@ def _form_blocks(data, columns):
         columns = _ensure_index(columns)
         extra_columns = columns - Index(data.keys())
 
-    # prefilter
-    data = dict((k, v) for k, v in data.iteritems() if k in columns)
-
     # put "leftover" columns in float bucket, where else?
     # generalize?
     float_dict = {}
@@ -726,42 +768,46 @@ def _form_blocks(data, columns):
 
     blocks = []
 
-    # oof
-    if len(float_dict) > 0 or len(extra_columns) > 0:
-        if len(extra_columns):
-            bcolumns = extra_columns.union(float_dict.keys())
-            float_block = _blockify(float_dict, np.float64,
-                                    columns=bcolumns)
-        else:
-            float_block = _blockify(float_dict, np.float64)
+    # oof, this sucks
+    fcolumns = extra_columns.union(float_dict.keys())
+    if len(fcolumns) > 0:
+        float_block = _float_blockify(float_dict, index, fcolumns)
         blocks.append(float_block)
 
     if len(object_dict) > 0:
-        object_block = _blockify(object_dict, np.object_)
+        object_block = _simple_blockify(object_dict, np.object_)
         blocks.append(object_block)
 
     return blocks, columns
 
-def _blockify(dct, dtype, columns=None):
-    dict_columns = Index(_try_sort(dct))
-    stacked_series = np.vstack([dct[k] for k in dict_columns]).T
-    if columns is None:
-        columns = dict_columns
-        values = stacked_series
-        # CHECK DTYPE
-    else:
-        n = len(dct.values()[0])
-        k = len(columns)
-        values = np.empty((n, k), dtype=dtype)
+def _simple_blockify(dct, dtype):
+    columns, values = _stack_dict(dct)
+    # CHECK DTYPE?
+    if values.dtype != dtype:
+        values = values.astype(dtype)
+    return Block(values, columns)
+
+def _stack_dict(dct):
+    columns = Index(_try_sort(dct))
+    stacked = np.vstack([dct[k] for k in columns]).T
+    return columns, stacked
 
+def _float_blockify(dct, index, columns):
+    n = len(index)
+    k = len(columns)
+    values = np.empty((n, k), dtype=np.float64)
+    values.fill(nan)
+
+    if len(dct) > 0:
+        dict_columns, stacked = _stack_dict(dct)
         indexer, mask = columns.get_indexer(dict_columns)
         assert(mask.all())
-        values[:, indexer] = stacked_series
+        values[:, indexer] = stacked
 
     # do something with dtype?
     return Block(values, columns)
 
-def _init_matrix(values, index, columns):
+def _init_matrix(values, index, columns, dtype):
     values = _prep_ndarray(values)
 
     if values.ndim == 1:
@@ -771,12 +817,11 @@ def _init_matrix(values, index, columns):
         else:
             values = values.reshape((values.shape[0], 1))
 
-    # address this can of worms later
-    # if dtype is not None:
-    #     try:
-    #         values = values.astype(dtype)
-    #     except Exception:
-    #         pass
+    if dtype is not None:
+        try:
+            values = values.astype(dtype)
+        except Exception:
+            pass
 
     N, K = values.shape
 
@@ -788,9 +833,7 @@ def _init_matrix(values, index, columns):
 
     columns = _ensure_index(columns)
     block = Block(values, columns)
-    mgr = BlockManager([block], index, columns)
-
-    return index, columns, mgr
+    return BlockManager([block], index, columns)
 
 def _reorder_columns(mat, current, desired):
     indexer, mask = common.get_indexer(current, desired, None)
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 3f27eec20..ffa5aa4dd 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -1849,3 +1849,4 @@ if __name__ == '__main__':
     #                exit=False)
     nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
                    exit=False)
+    frame = self.klass({'col1' : self.ts1, 'col2' : self.ts2}, columns=['col2', 'col3', 'col4'])
diff --git a/pandas/core/tests/test_matrix.py b/pandas/core/tests/test_matrix.py
index 4fdc5141d..922f08853 100644
--- a/pandas/core/tests/test_matrix.py
+++ b/pandas/core/tests/test_matrix.py
@@ -56,6 +56,8 @@ class TestDataMatrix(test_frame.TestDataFrame):
         self.assertEqual(len(dm.columns), 2)
         self.assert_(dm.values.dtype == np.float_)
 
+    # TODO: adapt ALL these unit tests
+    """
     def test_constructor_with_objects(self):
         index = self.mixed_frame.index[:5]
 
@@ -116,10 +118,26 @@ class TestDataMatrix(test_frame.TestDataFrame):
         dm = DataMatrix(index=[1, 2, 3], objects=obj_dm)
         dm = DataMatrix(index=[1, 2, 3], objects=obj)
 
+    """
+    # def test_constructor_objects_corner(self):
+    #     obj = {'A' : {1 : '1', 2 : '2'}}
+    #     obj_dm = DataMatrix(obj)
+    #     mat = np.zeros((3, 3), dtype=float)
+
+    #     dm = DataMatrix(mat, index=[1, 2, 3], columns=['B', 'C', 'D'],
+    #                     objects=obj_dm)
+    #     assert dm.index is not obj_dm.index
+
+    #     dm = DataMatrix(mat, index=[1, 2, 3], columns=['B', 'C', 'D'],
+    #                     objects=obj)
+
+    #     dm = DataMatrix(index=[1, 2, 3], objects=obj_dm)
+    #     dm = DataMatrix(index=[1, 2, 3], objects=obj)
+
     def test_copy(self):
         # copy objects
         copy = self.mixed_frame.copy()
-        self.assert_(copy.objects is not self.mixed_frame.objects)
+        self.assert_(copy._data is not self.mixed_frame._data)
 
     def test_combineFirst_mixed(self):
         a = Series(['a','b'], index=range(2))
diff --git a/refactor_notes.txt b/refactor_notes.txt
index 4403869c1..2c931b896 100644
--- a/refactor_notes.txt
+++ b/refactor_notes.txt
@@ -5,6 +5,8 @@
 - Series homogenization
   - when does casting fail?
 - Deal with emptiness: empty index and / or columns
+- Transpose: float casted to string??
+- Casting, want to continue to support?
 
 - Need sparse internal data structure
 
