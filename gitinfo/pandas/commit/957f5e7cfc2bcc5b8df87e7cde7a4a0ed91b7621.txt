commit 957f5e7cfc2bcc5b8df87e7cde7a4a0ed91b7621
Author: Michael P. Moran <30704827+mpmoran@users.noreply.github.com>
Date:   Wed Jul 17 15:33:48 2019 -0500

    DOC: cleanup docstring for read_json and fix error in contribution guide (#27280)
    
    * DOC: cleanup docstring for read_json and fix error in contribution guide

diff --git a/doc/source/development/contributing.rst b/doc/source/development/contributing.rst
index 92d7cf1a7..80dc8b0d8 100644
--- a/doc/source/development/contributing.rst
+++ b/doc/source/development/contributing.rst
@@ -288,7 +288,7 @@ complex changes to the documentation as well.
 Some other important things to know about the docs:
 
 * The *pandas* documentation consists of two parts: the docstrings in the code
-  itself and the docs in this folder ``pandas/doc/``.
+  itself and the docs in this folder ``doc/``.
 
   The docstrings provide a clear explanation of the usage of the individual
   functions, while the documentation in this folder consists of tutorial-like
@@ -404,11 +404,11 @@ Building the documentation
 ~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 So how do you build the docs? Navigate to your local
-``pandas/doc/`` directory in the console and run::
+``doc/`` directory in the console and run::
 
     python make.py html
 
-Then you can find the HTML output in the folder ``pandas/doc/build/html/``.
+Then you can find the HTML output in the folder ``doc/build/html/``.
 
 The first time you build the docs, it will take quite a while because it has to run
 all the code examples and build all the generated docstring pages. In subsequent
@@ -448,7 +448,7 @@ You can also specify to use multiple cores to speed up the documentation build::
 Open the following file in a web browser to see the full documentation you
 just built::
 
-    pandas/docs/build/html/index.html
+    doc/build/html/index.html
 
 And you'll have the satisfaction of seeing your new and improved documentation!
 
diff --git a/pandas/io/json/_json.py b/pandas/io/json/_json.py
index 24d41b510..ada7e6f43 100644
--- a/pandas/io/json/_json.py
+++ b/pandas/io/json/_json.py
@@ -400,8 +400,10 @@ def read_json(
         .. versionadded:: 0.23.0
            'table' as an allowed value for the ``orient`` argument
 
-    typ : type of object to recover (series or frame), default 'frame'
-    dtype : boolean or dict, default None
+    typ : {'frame', 'series'}, default 'frame'
+        The type of object to recover.
+
+    dtype : bool or dict, default None
         If True, infer dtypes; if a dict of column to dtype, then use those;
         if False, then don't infer dtypes at all, applies only to the data.
 
@@ -411,7 +413,7 @@ def read_json(
 
            Not applicable for ``orient='table'``.
 
-    convert_axes : boolean, default None
+    convert_axes : bool, default None
         Try to convert the axes to the proper dtypes.
 
         For all ``orient`` values except ``'table'``, default is True.
@@ -420,9 +422,9 @@ def read_json(
 
            Not applicable for ``orient='table'``.
 
-    convert_dates : boolean, default True
-        List of columns to parse for dates; If True, then try to parse
-        datelike columns default is True; a column label is datelike if
+    convert_dates : bool or list of str, default True
+        List of columns to parse for dates. If True, then try to parse
+        datelike columns. A column label is datelike if
 
         * it ends with ``'_at'``,
 
@@ -432,34 +434,38 @@ def read_json(
 
         * it is ``'modified'``, or
 
-        * it is ``'date'``
+        * it is ``'date'``.
+
+    keep_default_dates : bool, default True
+        If parsing dates, then parse the default datelike columns.
 
-    keep_default_dates : boolean, default True
-        If parsing dates, then parse the default datelike columns
-    numpy : boolean, default False
+    numpy : bool, default False
         Direct decoding to numpy arrays. Supports numeric data only, but
         non-numeric column and index labels are supported. Note also that the
         JSON ordering MUST be the same for each term if numpy=True.
-    precise_float : boolean, default False
+
+    precise_float : bool, default False
         Set to enable usage of higher precision (strtod) function when
         decoding string to double values. Default (False) is to use fast but
-        less precise builtin functionality
-    date_unit : string, default None
+        less precise builtin functionality.
+
+    date_unit : str, default None
         The timestamp unit to detect if converting dates. The default behaviour
         is to try and detect the correct precision, but if this is not desired
         then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,
         milliseconds, microseconds or nanoseconds respectively.
+
     encoding : str, default is 'utf-8'
         The encoding to use to decode py3 bytes.
 
         .. versionadded:: 0.19.0
 
-    lines : boolean, default False
+    lines : bool, default False
         Read the file as a json object per line.
 
         .. versionadded:: 0.19.0
 
-    chunksize : integer, default None
+    chunksize : int, optional
         Return JsonReader object for iteration.
         See the `line-delimited json docs
         <http://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#line-delimited-json>`_
@@ -480,11 +486,13 @@ def read_json(
 
     Returns
     -------
-    result : Series or DataFrame, depending on the value of `typ`.
+    Series or DataFrame
+        The type returned depends on the value of `typ`.
 
     See Also
     --------
-    DataFrame.to_json
+    DataFrame.to_json : Convert a DataFrame to a JSON string.
+    Series.to_json : Convert a Series to a JSON string.
 
     Notes
     -----
