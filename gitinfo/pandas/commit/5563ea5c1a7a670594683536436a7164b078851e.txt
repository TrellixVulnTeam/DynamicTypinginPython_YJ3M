commit 5563ea5c1a7a670594683536436a7164b078851e
Author: Phillip Cloud <cpcloud@gmail.com>
Date:   Thu May 1 21:52:43 2014 -0400

    BUG: numeric_only must be False for count

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 39ee7f1a5..dec3178e8 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -723,7 +723,8 @@ class GroupBy(PandasObject):
                              _convert=True)
 
     _count = _groupby_function('_count', 'count',
-                               lambda x, axis=0: notnull(x).sum(axis=axis))
+                               lambda x, axis=0: notnull(x).sum(axis=axis),
+                               numeric_only=False)
 
     def count(self, axis=0):
         return self._count().astype('int64')
@@ -1387,14 +1388,16 @@ class BaseGrouper(object):
             values = com.ensure_float(values)
             is_numeric = True
         else:
-            if issubclass(values.dtype.type, np.datetime64):
-                raise Exception('Cython not able to handle this case')
-
-            values = values.astype(object)
-            is_numeric = False
+            is_numeric = issubclass(values.dtype.type, (np.datetime64,
+                                                        np.timedelta64))
+            if is_numeric:
+                values = values.view('int64')
+            else:
+                values = values.astype(object)
 
         # will be filled in Cython function
-        result = np.empty(out_shape, dtype=values.dtype)
+        result = np.empty(out_shape,
+                          dtype=np.dtype('f%d' % values.dtype.itemsize))
         result.fill(np.nan)
         counts = np.zeros(self.ngroups, dtype=np.int64)
 
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index f76314cb2..53754a899 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -33,7 +33,9 @@ from khash cimport *
 ctypedef unsigned char UChar
 
 cimport util
-from util cimport is_array, _checknull, _checknan
+from util cimport is_array, _checknull, _checknan, get_nat
+
+cdef int64_t iNaT = get_nat()
 
 # import datetime C API
 PyDateTime_IMPORT
@@ -1159,16 +1161,15 @@ def group_count_%(name)s(ndarray[%(dest_type2)s, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
-        %(dest_type2)s val
-        ndarray[%(dest_type2)s, ndim=2] nobs = np.zeros_like(out)
-
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        %(c_type)s val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -1179,7 +1180,7 @@ def group_count_%(name)s(ndarray[%(dest_type2)s, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -1198,20 +1199,14 @@ def group_count_bin_%(name)s(ndarray[%(dest_type2)s, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        %(dest_type2)s val, count
-        ndarray[%(dest_type2)s, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        %(c_type)s val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    N, K = (<object> values).shape
-
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -1221,7 +1216,7 @@ def group_count_bin_%(name)s(ndarray[%(dest_type2)s, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -2224,7 +2219,8 @@ def put2d_%(name)s_%(dest_type)s(ndarray[%(c_type)s, ndim=2, cast=True] values,
 #-------------------------------------------------------------------------
 # Generators
 
-def generate_put_template(template, use_ints = True, use_floats = True):
+def generate_put_template(template, use_ints = True, use_floats = True,
+                          use_objects=False):
     floats_list = [
         ('float64', 'float64_t', 'float64_t', 'np.float64'),
         ('float32', 'float32_t', 'float32_t', 'np.float32'),
@@ -2235,11 +2231,14 @@ def generate_put_template(template, use_ints = True, use_floats = True):
         ('int32', 'int32_t', 'float64_t', 'np.float64'),
         ('int64', 'int64_t', 'float64_t', 'np.float64'),
         ]
+    object_list = [('object', 'object', 'float64_t', 'np.float64')]
     function_list = []
     if use_floats:
         function_list.extend(floats_list)
     if use_ints:
         function_list.extend(ints_list)
+    if use_objects:
+        function_list.extend(object_list)
 
     output = StringIO()
     for name, c_type, dest_type, dest_dtype in function_list:
@@ -2373,7 +2372,7 @@ def generate_take_cython_file(path='generated.pyx'):
             print(generate_put_template(template, use_ints=False), file=f)
 
         for template in groupby_count:
-            print(generate_put_template(template), file=f)
+            print(generate_put_template(template, use_objects=True), file=f)
 
         # for template in templates_1d_datetime:
         #     print >> f, generate_from_template_datetime(template)
diff --git a/pandas/src/generated.pyx b/pandas/src/generated.pyx
index 247a7e24c..26c6f3daf 100644
--- a/pandas/src/generated.pyx
+++ b/pandas/src/generated.pyx
@@ -27,7 +27,9 @@ from khash cimport *
 ctypedef unsigned char UChar
 
 cimport util
-from util cimport is_array, _checknull, _checknan
+from util cimport is_array, _checknull, _checknan, get_nat
+
+cdef int64_t iNaT = get_nat()
 
 # import datetime C API
 PyDateTime_IMPORT
@@ -6631,16 +6633,15 @@ def group_count_float64(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
         float64_t val
-        ndarray[float64_t, ndim=2] nobs = np.zeros_like(out)
-
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -6651,7 +6652,7 @@ def group_count_float64(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6668,16 +6669,15 @@ def group_count_float32(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
         float32_t val
-        ndarray[float32_t, ndim=2] nobs = np.zeros_like(out)
-
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -6688,7 +6688,7 @@ def group_count_float32(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6705,16 +6705,15 @@ def group_count_int8(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
-        float32_t val
-        ndarray[float32_t, ndim=2] nobs = np.zeros_like(out)
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        int8_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -6725,7 +6724,7 @@ def group_count_int8(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6742,16 +6741,15 @@ def group_count_int16(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
-        float32_t val
-        ndarray[float32_t, ndim=2] nobs = np.zeros_like(out)
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        int16_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -6762,7 +6760,7 @@ def group_count_int16(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6779,16 +6777,15 @@ def group_count_int32(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
-        float64_t val
-        ndarray[float64_t, ndim=2] nobs = np.zeros_like(out)
-
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        int32_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
-
     for i in range(N):
         lab = labels[i]
         if lab < 0:
@@ -6799,7 +6796,7 @@ def group_count_int32(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6816,15 +6813,50 @@ def group_count_int64(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, lab
-        float64_t val
-        ndarray[float64_t, ndim=2] nobs = np.zeros_like(out)
-
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        int64_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if not len(values) == len(labels):
+    if len(values) != len(labels):
        raise AssertionError("len(index) != len(labels)")
 
-    N, K = (<object> values).shape
+    for i in range(N):
+        lab = labels[i]
+        if lab < 0:
+            continue
+
+        counts[lab] += 1
+        for j in range(K):
+            val = values[i, j]
+
+            # not nan
+            nobs[lab, j] += val == val and val != iNaT
+
+    for i in range(len(counts)):
+        for j in range(K):
+            out[i, j] = nobs[i, j]
+
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_count_object(ndarray[float64_t, ndim=2] out,
+                         ndarray[int64_t] counts,
+                         ndarray[object, ndim=2] values,
+                         ndarray[int64_t] labels):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, lab
+        Py_ssize_t N = values.shape[0], K = values.shape[1]
+        object val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
+
+    if len(values) != len(labels):
+       raise AssertionError("len(index) != len(labels)")
 
     for i in range(N):
         lab = labels[i]
@@ -6836,7 +6868,7 @@ def group_count_int64(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[lab, j] += val == val
+            nobs[lab, j] += val == val and val != iNaT
 
     for i in range(len(counts)):
         for j in range(K):
@@ -6854,20 +6886,14 @@ def group_count_bin_float64(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float64_t val, count
-        ndarray[float64_t, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
-
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        float64_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    N, K = (<object> values).shape
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -6877,7 +6903,7 @@ def group_count_bin_float64(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -6894,20 +6920,14 @@ def group_count_bin_float32(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float32_t val, count
-        ndarray[float32_t, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
-
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        float32_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    N, K = (<object> values).shape
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -6917,7 +6937,7 @@ def group_count_bin_float32(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -6934,20 +6954,14 @@ def group_count_bin_int8(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float32_t val, count
-        ndarray[float32_t, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        int8_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
-
-    N, K = (<object> values).shape
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -6957,7 +6971,7 @@ def group_count_bin_int8(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -6974,20 +6988,14 @@ def group_count_bin_int16(ndarray[float32_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float32_t val, count
-        ndarray[float32_t, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
-
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        int16_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    N, K = (<object> values).shape
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -6997,7 +7005,7 @@ def group_count_bin_int16(ndarray[float32_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -7014,20 +7022,14 @@ def group_count_bin_int32(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float64_t val, count
-        ndarray[float64_t, ndim=2] nobs
-
-    nobs = np.zeros_like(out)
-
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        int32_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    N, K = (<object> values).shape
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -7037,7 +7039,7 @@ def group_count_bin_int32(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
@@ -7054,20 +7056,48 @@ def group_count_bin_int64(ndarray[float64_t, ndim=2] out,
     Only aggregates on axis=0
     '''
     cdef:
-        Py_ssize_t i, j, N, K, ngroups, b
-        float64_t val, count
-        ndarray[float64_t, ndim=2] nobs
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        int64_t val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
 
-    nobs = np.zeros_like(out)
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    if bins[len(bins) - 1] == len(values):
-        ngroups = len(bins)
-    else:
-        ngroups = len(bins) + 1
+    for i in range(N):
+        while b < ngroups - 1 and i >= bins[b]:
+            b += 1
 
-    N, K = (<object> values).shape
+        counts[b] += 1
+        for j in range(K):
+            val = values[i, j]
+
+            # not nan
+            nobs[b, j] += val == val and val != iNaT
+
+    for i in range(ngroups):
+        for j in range(K):
+            out[i, j] = nobs[i, j]
+
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_count_bin_object(ndarray[float64_t, ndim=2] out,
+                             ndarray[int64_t] counts,
+                             ndarray[object, ndim=2] values,
+                             ndarray[int64_t] bins):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, ngroups
+        Py_ssize_t N = values.shape[0], K = values.shape[1], b = 0
+        object val
+        ndarray[int64_t, ndim=2] nobs = np.zeros((out.shape[0], out.shape[1]),
+                                                 dtype=np.int64)
+
+    ngroups = len(bins) + (bins[len(bins) - 1] != N)
 
-    b = 0
     for i in range(N):
         while b < ngroups - 1 and i >= bins[b]:
             b += 1
@@ -7077,7 +7107,7 @@ def group_count_bin_int64(ndarray[float64_t, ndim=2] out,
             val = values[i, j]
 
             # not nan
-            nobs[b, j] += val == val
+            nobs[b, j] += val == val and val != iNaT
 
     for i in range(ngroups):
         for j in range(K):
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 1b70ae030..eb3c28b67 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1451,7 +1451,6 @@ class TestGroupBy(tm.TestCase):
         assert_frame_equal(g_not_as[['B']].head(1), df_as.loc[[0,2], ['B']])
         assert_frame_equal(g_not_as[['A', 'B']].head(1), df_as.loc[[0,2]])
 
-
     def test_groupby_multiple_key(self):
         df = tm.makeTimeDataFrame()
         grouped = df.groupby([lambda x: x.year,
@@ -1629,6 +1628,21 @@ class TestGroupBy(tm.TestCase):
                            'b': ['foo', 'bar'] * 25})
         self.assertRaises(DataError, frame[['b']].groupby(frame['a']).mean)
 
+    def test_cython_agg_nothing_to_agg_with_dates(self):
+        frame = DataFrame({'a': np.random.randint(0, 5, 50),
+                           'b': ['foo', 'bar'] * 25,
+                           'dates': pd.date_range('now', periods=50,
+                                                  freq='T')})
+        with tm.assertRaisesRegexp(DataError, "No numeric types to aggregate"):
+            frame.groupby('b').dates.mean()
+
+    def test_groupby_timedelta_cython_count(self):
+        df = DataFrame({'g': list('ab' * 2),
+                        'delt': np.arange(4).astype('timedelta64[ns]')})
+        expected = Series([2, 2], index=['a', 'b'], name='delt')
+        result = df.groupby('g').delt.count()
+        tm.assert_series_equal(expected, result)
+
     def test_cython_agg_frame_columns(self):
         # #2113
         df = DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})
@@ -1992,7 +2006,8 @@ class TestGroupBy(tm.TestCase):
 
         # GH5610
         # count counts non-nulls
-        df = pd.DataFrame([[1, 2, 'foo'], [1, nan, 'bar'], [3, nan, nan]], columns=['A', 'B', 'C'])
+        df = pd.DataFrame([[1, 2, 'foo'], [1, nan, 'bar'], [3, nan, nan]],
+                          columns=['A', 'B', 'C'])
 
         count_as = df.groupby('A').count()
         count_not_as = df.groupby('A', as_index=False).count()
@@ -2005,6 +2020,19 @@ class TestGroupBy(tm.TestCase):
         count_B = df.groupby('A')['B'].count()
         assert_series_equal(count_B, expected['B'])
 
+    def test_count_object(self):
+        df = pd.DataFrame({'a': ['a'] * 3 + ['b'] * 3,
+                           'c': [2] * 3 + [3] * 3})
+        result = df.groupby('c').a.count()
+        expected = pd.Series([3, 3], index=[2, 3], name='a')
+        tm.assert_series_equal(result, expected)
+
+        df = pd.DataFrame({'a': ['a', np.nan, np.nan] + ['b'] * 3,
+                           'c': [2] * 3 + [3] * 3})
+        result = df.groupby('c').a.count()
+        expected = pd.Series([1, 3], index=[2, 3], name='a')
+        tm.assert_series_equal(result, expected)
+
     def test_non_cython_api(self):
 
         # GH5610
@@ -2354,7 +2382,6 @@ class TestGroupBy(tm.TestCase):
         result = g[['v1','v2']].mean()
         assert_frame_equal(result,expected)
 
-
     def test_groupby_dtype_inference_empty(self):
         # GH 6733
         df = DataFrame({'x': [], 'range': np.arange(0,dtype='int64')})
@@ -3325,7 +3352,6 @@ class TestGroupBy(tm.TestCase):
         assert_series_equal(expected, g.cumcount())
         assert_series_equal(expected, sg.cumcount())
 
-
     def test_filter_series(self):
         import pandas as pd
         s = pd.Series([1, 3, 20, 5, 22, 24, 7])
@@ -4168,6 +4194,14 @@ class TestGroupBy(tm.TestCase):
         expected = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
         assert_equal(result, expected)
 
+    def test_datetime_count(self):
+        df = DataFrame({'a': [1,2,3] * 2,
+                        'dates': pd.date_range('now', periods=6, freq='T')})
+        result = df.groupby('a').dates.count()
+        expected = Series([2, 2, 2], index=Index([1, 2, 3], name='a'),
+                          name='dates')
+        tm.assert_series_equal(result, expected)
+
 def assert_fp_equal(a, b):
     assert (np.abs(a - b) < 1e-12).all()
 
diff --git a/pandas/tslib.pyx b/pandas/tslib.pyx
index 6d99d3804..df9c465c3 100644
--- a/pandas/tslib.pyx
+++ b/pandas/tslib.pyx
@@ -462,6 +462,12 @@ class NaTType(_NaT):
     def __hash__(self):
         return iNaT
 
+    def __int__(self):
+        return NPY_NAT
+
+    def __long__(self):
+        return NPY_NAT
+
     def weekday(self):
         return -1
 
diff --git a/vb_suite/groupby.py b/vb_suite/groupby.py
index ed9a1429b..f35a0f886 100644
--- a/vb_suite/groupby.py
+++ b/vb_suite/groupby.py
@@ -122,15 +122,31 @@ groupby_multi_size = Benchmark("df.groupby(['key1', 'key2']).size()",
 # count() speed
 
 setup = common_setup + """
-df = DataFrame({'key1': np.random.randint(0, 500, size=100000),
-                'key2': np.random.randint(0, 100, size=100000),
-                'value1' : np.random.randn(100000),
-                'value2' : np.random.randn(100000),
-                'value3' : np.random.randn(100000)})
+n = 10000
+offsets = np.random.randint(n, size=n).astype('timedelta64[ns]')
+
+dates = np.datetime64('now') + offsets
+dates[np.random.rand(n) > 0.5] = np.datetime64('nat')
+
+offsets[np.random.rand(n) > 0.5] = np.timedelta64('nat')
+
+value2 = np.random.randn(n)
+value2[np.random.rand(n) > 0.5] = np.nan
+
+obj = pd.util.testing.choice(['a', 'b'], size=n).astype(object)
+obj[np.random.randn(n) > 0.5] = np.nan
+
+df = DataFrame({'key1': np.random.randint(0, 500, size=n),
+                'key2': np.random.randint(0, 100, size=n),
+                'dates': dates,
+                'value2' : value2,
+                'value3' : np.random.randn(n),
+                'obj': obj,
+                'offsets': offsets})
 """
 
 groupby_multi_count = Benchmark("df.groupby(['key1', 'key2']).count()",
-                                setup, start_date=datetime(2014, 5, 1))
+                                setup, start_date=datetime(2014, 5, 5))
 #----------------------------------------------------------------------
 # Series.value_counts
 
