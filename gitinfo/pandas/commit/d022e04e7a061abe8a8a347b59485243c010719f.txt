commit d022e04e7a061abe8a8a347b59485243c010719f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Apr 14 17:57:10 2012 -0400

    ENH: group_max/min and bin versions, close #1019

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index d84ee1d6c..02c2fd21c 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -320,6 +320,28 @@ class GroupBy(object):
         except Exception:
             return self.aggregate(lambda x: np.prod(x, axis=self.axis))
 
+    def min(self):
+        """
+        Compute minimum of values, excluding missing values
+
+        For multiple groupings, the result index will be a MultiIndex
+        """
+        try:
+            return self._cython_agg_general('min')
+        except Exception:
+            return self.aggregate(lambda x: np.min(x, axis=self.axis))
+
+    def max(self):
+        """
+        Compute maximum of values, excluding missing values
+
+        For multiple groupings, the result index will be a MultiIndex
+        """
+        try:
+            return self._cython_agg_general('max')
+        except Exception:
+            return self.aggregate(lambda x: np.max(x, axis=self.axis))
+
     def ohlc(self):
         """
         Compute sum of values, excluding missing values
@@ -604,6 +626,8 @@ class Grouper(object):
     _cython_functions = {
         'add' : lib.group_add,
         'prod' : lib.group_prod,
+        'min' : lib.group_min,
+        'max' : lib.group_max,
         'mean' : lib.group_mean,
         'var' : lib.group_var,
         'std' : lib.group_var
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 59bda9a4a..aacf82466 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -279,9 +279,9 @@ def group_add(ndarray[float64_t, ndim=2] out,
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_prod(ndarray[float64_t, ndim=2] out,
-              ndarray[int32_t] counts,
-              ndarray[float64_t, ndim=2] values,
-              ndarray[int32_t] labels):
+               ndarray[int32_t] counts,
+               ndarray[float64_t, ndim=2] values,
+               ndarray[int32_t] labels):
     '''
     Only aggregates on axis=0
     '''
@@ -331,6 +331,124 @@ def group_prod(ndarray[float64_t, ndim=2] out,
                 out[i, j] = prodx[i, j]
 
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_min(ndarray[float64_t, ndim=2] out,
+              ndarray[int32_t] counts,
+              ndarray[float64_t, ndim=2] values,
+              ndarray[int32_t] labels):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, N, K, lab
+        float64_t val, count
+        ndarray[float64_t, ndim=2] minx, nobs
+
+    nobs = np.zeros_like(out)
+
+    minx = np.empty_like(out)
+    minx.fill(np.inf)
+
+    N, K = (<object> values).shape
+
+    if K > 1:
+        for i in range(N):
+            lab = labels[i]
+            if lab < 0:
+                continue
+
+            counts[lab] += 1
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[lab, j] += 1
+                    if val < minx[lab, j]:
+                        minx[lab, j] = val
+    else:
+        for i in range(N):
+            lab = labels[i]
+            if lab < 0:
+                continue
+
+            counts[lab] += 1
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[lab, 0] += 1
+                if val < minx[lab, 0]:
+                    minx[lab, 0] = val
+
+    for i in range(len(counts)):
+        for j in range(K):
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = minx[i, j]
+
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_max(ndarray[float64_t, ndim=2] out,
+              ndarray[int32_t] counts,
+              ndarray[float64_t, ndim=2] values,
+              ndarray[int32_t] labels):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, N, K, lab
+        float64_t val, count
+        ndarray[float64_t, ndim=2] maxx, nobs
+
+    nobs = np.zeros_like(out)
+
+    maxx = np.empty_like(out)
+    maxx.fill(-np.inf)
+
+    N, K = (<object> values).shape
+
+    if K > 1:
+        for i in range(N):
+            lab = labels[i]
+            if lab < 0:
+                continue
+
+            counts[lab] += 1
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[lab, j] += 1
+                    if val > maxx[lab, j]:
+                        maxx[lab, j] = val
+    else:
+        for i in range(N):
+            lab = labels[i]
+            if lab < 0:
+                continue
+
+            counts[lab] += 1
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[lab, 0] += 1
+                if val > maxx[lab, 0]:
+                    maxx[lab, 0] = val
+
+    for i in range(len(counts)):
+        for j in range(K):
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = maxx[i, j]
+
+
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_mean(ndarray[float64_t, ndim=2] out,
@@ -621,6 +739,122 @@ def group_prod_bin(ndarray[float64_t, ndim=2] out,
             else:
                 out[i, j] = prodx[i, j]
 
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_min_bin(ndarray[float64_t, ndim=2] out,
+                   ndarray[int32_t] counts,
+                   ndarray[float64_t, ndim=2] values,
+                   ndarray[int32_t] bins):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, N, K, ngroups, b
+        float64_t val, count
+        ndarray[float64_t, ndim=2] minx, nobs
+
+    nobs = np.zeros_like(out)
+
+    minx = np.empty_like(out)
+    minx.fill(np.inf)
+
+
+    ngroups = len(bins) + 1
+    N, K = (<object> values).shape
+
+    b = 0
+    if K > 1:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            counts[b] += 1
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[b, j] += 1
+                    if val < minx[b, j]:
+                        minx[b, j] = val
+    else:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            counts[b] += 1
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[b, 0] += 1
+                if val < minx[b, 0]:
+                    minx[b, 0] = val
+
+    for i in range(ngroups):
+        for j in range(K):
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = minx[i, j]
+
+@cython.boundscheck(False)
+@cython.wraparound(False)
+def group_max_bin(ndarray[float64_t, ndim=2] out,
+                  ndarray[int32_t] counts,
+                  ndarray[float64_t, ndim=2] values,
+                  ndarray[int32_t] bins):
+    '''
+    Only aggregates on axis=0
+    '''
+    cdef:
+        Py_ssize_t i, j, N, K, ngroups, b
+        float64_t val, count
+        ndarray[float64_t, ndim=2] maxx, nobs
+
+    nobs = np.zeros_like(out)
+    maxx = np.empty_like(out)
+    maxx.fill(-np.inf)
+
+    ngroups = len(bins) + 1
+    N, K = (<object> values).shape
+
+    b = 0
+    if K > 1:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            counts[b] += 1
+            for j in range(K):
+                val = values[i, j]
+
+                # not nan
+                if val == val:
+                    nobs[b, j] += 1
+                    if val > maxx[b, j]:
+                        maxx[b, j] = val
+    else:
+        for i in range(N):
+            if b < ngroups - 1 and i >= bins[b]:
+                b += 1
+
+            counts[b] += 1
+            val = values[i, 0]
+
+            # not nan
+            if val == val:
+                nobs[b, 0] += 1
+                if val > maxx[b, 0]:
+                    maxx[b, 0] = val
+
+    for i in range(ngroups):
+        for j in range(K):
+            if nobs[i, j] == 0:
+                out[i, j] = nan
+            else:
+                out[i, j] = maxx[i, j]
+
 
 @cython.boundscheck(False)
 @cython.wraparound(False)
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 07ee2d70d..fcf40b490 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -990,6 +990,8 @@ class TestGroupBy(unittest.TestCase):
         _testit(lambda x: x.sum())
         _testit(lambda x: x.mean())
         _testit(lambda x: x.prod())
+        _testit(lambda x: x.min())
+        _testit(lambda x: x.max())
 
     def test_cython_agg_boolean(self):
         frame = DataFrame({'a': np.random.randint(0, 5, 50),
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 2ae6b0b8e..a48dc22d3 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -356,6 +356,40 @@ def test_group_prod_bin():
 
     assert_almost_equal(out, exp)
 
+def test_group_min_bin():
+    # original group_min
+    obj = np.random.randn(10, 1)
+
+    lab = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
+    cts = np.array([3, 3, 4], dtype=np.int32)
+    exp = np.zeros((3, 1), np.float64)
+    lib.group_min(exp, cts, obj, lab)
+
+    # bin-based group_min
+    bins = np.array([3, 6], dtype=np.int32)
+    out  = np.zeros((3, 1), np.float64)
+    counts = np.zeros(len(out), dtype=np.int32)
+    lib.group_min_bin(out, counts, obj, bins)
+
+    assert_almost_equal(out, exp)
+
+def test_group_max_bin():
+    # original group_max
+    obj = np.random.randn(10, 1)
+
+    lab = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 2], dtype=np.int32)
+    cts = np.array([3, 3, 4], dtype=np.int32)
+    exp = np.zeros((3, 1), np.float64)
+    lib.group_max(exp, cts, obj, lab)
+
+    # bin-based group_max
+    bins = np.array([3, 6], dtype=np.int32)
+    out  = np.zeros((3, 1), np.float64)
+    counts = np.zeros(len(out), dtype=np.int32)
+    lib.group_max_bin(out, counts, obj, bins)
+
+    assert_almost_equal(out, exp)
+
 def test_group_var_bin():
     # original group_var
     obj = np.random.randn(10, 1)
