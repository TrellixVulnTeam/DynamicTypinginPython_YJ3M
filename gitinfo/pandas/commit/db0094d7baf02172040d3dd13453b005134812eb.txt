commit db0094d7baf02172040d3dd13453b005134812eb
Author: Wes McKinney <wes@cloudera.com>
Date:   Fri Jan 22 10:57:16 2016 -0500

    CLN: grab bag of flake8 fixes
    
    Author: Wes McKinney <wes@cloudera.com>
    
    Closes #12115 from wesm/style/flake8-misc and squashes the following commits:
    
    017ca16 [Wes McKinney] CLN: grab bag of flake8 fixes

diff --git a/pandas/__init__.py b/pandas/__init__.py
index c2ead16b6..ca304fa8f 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -1,5 +1,6 @@
 # pylint: disable-msg=W0614,W0401,W0611,W0622
 
+# flake8: noqa
 
 __docformat__ = 'restructuredtext'
 
diff --git a/pandas/_version.py b/pandas/_version.py
index 61e9f3ff1..77b2fdca5 100644
--- a/pandas/_version.py
+++ b/pandas/_version.py
@@ -8,6 +8,8 @@
 # This file is released into the public domain. Generated by
 # versioneer-0.15 (https://github.com/warner/python-versioneer)
 
+# flake8: noqa
+
 import errno
 import os
 import re
diff --git a/pandas/compat/__init__.py b/pandas/compat/__init__.py
index 2da4427af..f69cd4ef4 100644
--- a/pandas/compat/__init__.py
+++ b/pandas/compat/__init__.py
@@ -25,6 +25,8 @@ Other items:
 * platform checker
 """
 # pylint disable=W0611
+# flake8: noqa
+
 import functools
 import itertools
 from distutils.version import LooseVersion
diff --git a/pandas/compat/chainmap_impl.py b/pandas/compat/chainmap_impl.py
index 92d242405..c059ad08d 100644
--- a/pandas/compat/chainmap_impl.py
+++ b/pandas/compat/chainmap_impl.py
@@ -58,16 +58,19 @@ class ChainMap(MutableMapping):
     def __getitem__(self, key):
         for mapping in self.maps:
             try:
-                return mapping[key]             # can't use 'key in mapping' with defaultdict
+                # can't use 'key in mapping' with defaultdict
+                return mapping[key]
             except KeyError:
                 pass
-        return self.__missing__(key)            # support subclasses that define __missing__
+        # support subclasses that define __missing__
+        return self.__missing__(key)
 
     def get(self, key, default=None):
         return self[key] if key in self else default
 
     def __len__(self):
-        return len(set().union(*self.maps))     # reuses stored hash values if possible
+        # reuses stored hash values if possible
+        return len(set().union(*self.maps))
 
     def __iter__(self):
         return iter(set().union(*self.maps))
@@ -89,7 +92,10 @@ class ChainMap(MutableMapping):
         return cls(dict.fromkeys(iterable, *args))
 
     def copy(self):
-        'New ChainMap or subclass with a new copy of maps[0] and refs to maps[1:]'
+        """
+        New ChainMap or subclass with a new copy of maps[0] and refs to
+        maps[1:]
+        """
         return self.__class__(self.maps[0].copy(), *self.maps[1:])
 
     __copy__ = copy
@@ -115,21 +121,29 @@ class ChainMap(MutableMapping):
         try:
             del self.maps[0][key]
         except KeyError:
-            raise KeyError('Key not found in the first mapping: {!r}'.format(key))
+            raise KeyError('Key not found in the first mapping: {!r}'
+                           .format(key))
 
     def popitem(self):
-        'Remove and return an item pair from maps[0]. Raise KeyError is maps[0] is empty.'
+        """
+        Remove and return an item pair from maps[0]. Raise KeyError is maps[0]
+        is empty.
+        """
         try:
             return self.maps[0].popitem()
         except KeyError:
             raise KeyError('No keys found in the first mapping.')
 
     def pop(self, key, *args):
-        'Remove *key* from maps[0] and return its value. Raise KeyError if *key* not in maps[0].'
+        """
+        Remove *key* from maps[0] and return its value. Raise KeyError if
+        *key* not in maps[0].
+        """
         try:
             return self.maps[0].pop(key, *args)
         except KeyError:
-            raise KeyError('Key not found in the first mapping: {!r}'.format(key))
+            raise KeyError('Key not found in the first mapping: {!r}'
+                           .format(key))
 
     def clear(self):
         'Clear maps[0], leaving maps[1:] intact.'
diff --git a/pandas/compat/openpyxl_compat.py b/pandas/compat/openpyxl_compat.py
index 266aded20..87cf52cf0 100644
--- a/pandas/compat/openpyxl_compat.py
+++ b/pandas/compat/openpyxl_compat.py
@@ -32,4 +32,4 @@ def is_compat(major_ver=1):
         return LooseVersion(stop_ver) <= ver
     else:
         raise ValueError('cannot test for openpyxl compatibility with ver {0}'
-                .format(major_ver))
+                         .format(major_ver))
diff --git a/pandas/compat/pickle_compat.py b/pandas/compat/pickle_compat.py
index e79472557..3059c39c2 100644
--- a/pandas/compat/pickle_compat.py
+++ b/pandas/compat/pickle_compat.py
@@ -1,5 +1,7 @@
 """ support pre 0.12 series pickle compatibility """
 
+# flake8: noqa
+
 import sys
 import numpy as np
 import pandas
diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index b5f730378..ab7c72e74 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -173,8 +173,8 @@ def _reconstruct_object(typ, obj, axes, dtype):
         ret_value = res_t.type(obj)
     else:
         ret_value = typ(obj).astype(res_t)
-        # The condition is to distinguish 0-dim array (returned in case of scalar)
-        # and 1 element array
+        # The condition is to distinguish 0-dim array (returned in case of
+        # scalar) and 1 element array
         # e.g. np.array(0) and np.array([0])
         if len(obj.shape) == 1 and len(obj) == 1:
             if not isinstance(ret_value, np.ndarray):
diff --git a/pandas/computation/api.py b/pandas/computation/api.py
index db8269a49..e5814e08c 100644
--- a/pandas/computation/api.py
+++ b/pandas/computation/api.py
@@ -1,2 +1,4 @@
+# flake8: noqa
+
 from pandas.computation.eval import eval
 from pandas.computation.expr import Expr
diff --git a/pandas/computation/engines.py b/pandas/computation/engines.py
index 58b822af5..532921035 100644
--- a/pandas/computation/engines.py
+++ b/pandas/computation/engines.py
@@ -1,13 +1,16 @@
 """Engine classes for :func:`~pandas.eval`
 """
 
+# flake8: noqa
+
 import abc
 
 from pandas import compat
 from pandas.compat import DeepChainMap, map
 from pandas.core import common as com
 from pandas.computation.align import _align, _reconstruct_object
-from pandas.computation.ops import UndefinedVariableError, _mathops, _reductions
+from pandas.computation.ops import (UndefinedVariableError,
+                                    _mathops, _reductions)
 
 
 _ne_builtins = frozenset(_mathops + _reductions)
@@ -30,8 +33,8 @@ def _check_ne_builtin_clash(expr):
 
     if overlap:
         s = ', '.join(map(repr, overlap))
-        raise NumExprClobberingError('Variables in expression "%s" overlap with '
-                                     'numexpr builtins: (%s)' % (expr, s))
+        raise NumExprClobberingError('Variables in expression "%s" '
+                                     'overlap with builtins: (%s)' % (expr, s))
 
 
 class AbstractEngine(object):
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index 6da5cf475..61a3c9991 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -2,11 +2,7 @@
 """
 
 import ast
-import operator
-import sys
-import inspect
 import tokenize
-import datetime
 
 from functools import partial
 
@@ -21,7 +17,7 @@ from pandas.computation.ops import (_cmp_ops_syms, _bool_ops_syms,
 from pandas.computation.ops import _reductions, _mathops, _LOCAL_TAG
 from pandas.computation.ops import Op, BinOp, UnaryOp, Term, Constant, Div
 from pandas.computation.ops import UndefinedVariableError, FuncNode
-from pandas.computation.scope import Scope, _ensure_scope
+from pandas.computation.scope import Scope
 
 
 def tokenize_string(source):
@@ -381,9 +377,9 @@ class BaseExprVisitor(ast.NodeVisitor):
                                                       rhs.type))
 
         if self.engine != 'pytables':
-            if (res.op in _cmp_ops_syms
-                    and getattr(lhs, 'is_datetime', False)
-                    or getattr(rhs, 'is_datetime', False)):
+            if (res.op in _cmp_ops_syms and
+                    getattr(lhs, 'is_datetime', False) or
+                    getattr(rhs, 'is_datetime', False)):
                 # all date ops must be done in python bc numexpr doesn't work
                 # well with NaT
                 return self._possibly_eval(res, self.binary_ops)
@@ -392,8 +388,8 @@ class BaseExprVisitor(ast.NodeVisitor):
             # "in"/"not in" ops are always evaluated in python
             return self._possibly_eval(res, eval_in_python)
         elif self.engine != 'pytables':
-            if (getattr(lhs, 'return_type', None) == object
-                    or getattr(rhs, 'return_type', None) == object):
+            if (getattr(lhs, 'return_type', None) == object or
+                    getattr(rhs, 'return_type', None) == object):
                 # evaluate "==" and "!=" in python if either of our operands
                 # has an object return type
                 return self._possibly_eval(res, eval_in_python +
@@ -517,7 +513,8 @@ class BaseExprVisitor(ast.NodeVisitor):
         raise ValueError("Invalid Attribute context {0}".format(ctx.__name__))
 
     def visit_Call_35(self, node, side=None, **kwargs):
-        """ in 3.5 the starargs attribute was changed to be more flexible, #11097 """
+        """ in 3.5 the starargs attribute was changed to be more flexible,
+        #11097 """
 
         if isinstance(node.func, ast.Attribute):
             res = self.visit_Attribute(node.func)
@@ -541,7 +538,7 @@ class BaseExprVisitor(ast.NodeVisitor):
 
         if isinstance(res, FuncNode):
 
-            new_args = [ self.visit(arg) for arg in node.args ]
+            new_args = [self.visit(arg) for arg in node.args]
 
             if node.keywords:
                 raise TypeError("Function \"{0}\" does not support keyword "
@@ -551,7 +548,7 @@ class BaseExprVisitor(ast.NodeVisitor):
 
         else:
 
-            new_args = [ self.visit(arg).value for arg in node.args ]
+            new_args = [self.visit(arg).value for arg in node.args]
 
             for key in node.keywords:
                 if not isinstance(key, ast.keyword):
@@ -559,7 +556,9 @@ class BaseExprVisitor(ast.NodeVisitor):
                                      "'{0}'".format(node.func.id))
 
                 if key.arg:
-                    kwargs.append(ast.keyword(keyword.arg, self.visit(keyword.value)))
+                    # TODO: bug?
+                    kwargs.append(ast.keyword(
+                        keyword.arg, self.visit(keyword.value)))  # noqa
 
             return self.const_type(res(*new_args, **kwargs), self.env)
 
diff --git a/pandas/computation/expressions.py b/pandas/computation/expressions.py
index 70541c94b..6e3325001 100644
--- a/pandas/computation/expressions.py
+++ b/pandas/computation/expressions.py
@@ -16,9 +16,10 @@ try:
     ver = ne.__version__
     _NUMEXPR_INSTALLED = ver >= LooseVersion('2.1')
     if not _NUMEXPR_INSTALLED:
-        warnings.warn("The installed version of numexpr {ver} is not supported "
-                      "in pandas and will be not be used\nThe minimum supported "
-                      "version is 2.1\n".format(ver=ver), UserWarning)
+        warnings.warn(
+            "The installed version of numexpr {ver} is not supported "
+            "in pandas and will be not be used\nThe minimum supported "
+            "version is 2.1\n".format(ver=ver), UserWarning)
 
 except ImportError:  # pragma: no cover
     _NUMEXPR_INSTALLED = False
@@ -96,8 +97,8 @@ def _can_use_numexpr(op, op_str, a, b, dtype_check):
     return False
 
 
-def _evaluate_numexpr(op, op_str, a, b, raise_on_error=False, truediv=True, reversed=False,
-                      **eval_kwargs):
+def _evaluate_numexpr(op, op_str, a, b, raise_on_error=False, truediv=True,
+                      reversed=False, **eval_kwargs):
     result = None
 
     if _can_use_numexpr(op, op_str, a, b, 'evaluate'):
@@ -106,7 +107,7 @@ def _evaluate_numexpr(op, op_str, a, b, raise_on_error=False, truediv=True, reve
             # we were originally called by a reversed op
             # method
             if reversed:
-                a,b = b,a
+                a, b = b, a
 
             a_value = getattr(a, "values", a)
             b_value = getattr(b, "values", b)
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index f6d5f1710..0d528de9f 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -498,12 +498,13 @@ class UnaryOp(Op):
         if operand.return_type == np.dtype('bool'):
             return np.dtype('bool')
         if (isinstance(operand, Op) and
-            (operand.op in _cmp_ops_dict or operand.op in _bool_ops_dict)):
+                (operand.op in _cmp_ops_dict or operand.op in _bool_ops_dict)):
             return np.dtype('bool')
         return np.dtype('int')
 
 
 class MathCall(Op):
+
     def __init__(self, func, args):
         super(MathCall, self).__init__(func.name, args)
         self.func = func
@@ -518,9 +519,11 @@ class MathCall(Op):
 
 
 class FuncNode(object):
+
     def __init__(self, name):
         if name not in _mathops:
-            raise ValueError("\"{0}\" is not a supported function".format(name))
+            raise ValueError(
+                "\"{0}\" is not a supported function".format(name))
         self.name = name
         self.func = getattr(np, name)
 
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index 58359a815..3b3a0a8ab 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -7,12 +7,11 @@ from functools import partial
 from datetime import datetime, timedelta
 import numpy as np
 import pandas as pd
-from pandas.compat import u, string_types, PY3, DeepChainMap
+from pandas.compat import u, string_types, DeepChainMap
 from pandas.core.base import StringMixin
 import pandas.core.common as com
 from pandas.computation import expr, ops
 from pandas.computation.ops import is_term, UndefinedVariableError
-from pandas.computation.scope import _ensure_scope
 from pandas.computation.expr import BaseExprVisitor
 from pandas.computation.common import _ensure_decoded
 from pandas.tseries.timedeltas import _coerce_scalar_to_timedelta_type
@@ -147,17 +146,17 @@ class BinOp(ops.BinOp):
     @property
     def kind(self):
         """ the kind of my field """
-        return getattr(self.queryables.get(self.lhs),'kind',None)
+        return getattr(self.queryables.get(self.lhs), 'kind', None)
 
     @property
     def meta(self):
         """ the meta of my field """
-        return getattr(self.queryables.get(self.lhs),'meta',None)
+        return getattr(self.queryables.get(self.lhs), 'meta', None)
 
     @property
     def metadata(self):
         """ the metadata of my field """
-        return getattr(self.queryables.get(self.lhs),'metadata',None)
+        return getattr(self.queryables.get(self.lhs), 'metadata', None)
 
     def generate(self, v):
         """ create and return the op string for this TermValue """
@@ -195,7 +194,7 @@ class BinOp(ops.BinOp):
             return TermValue(int(v), v, kind)
         elif meta == u('category'):
             metadata = com._values_from_object(self.metadata)
-            result = metadata.searchsorted(v,side='left')
+            result = metadata.searchsorted(v, side='left')
             return TermValue(result, result, u('integer'))
         elif kind == u('integer'):
             v = int(float(v))
@@ -504,7 +503,7 @@ class Expr(expr.Expr):
                 else:
                     w = self.parse_back_compat(w)
                     where[idx] = w
-            where = ' & ' .join(["(%s)" % w for w in where])
+            where = ' & ' .join(["(%s)" % w for w in where])  # noqa
 
         self.expr = where
         self.env = Scope(scope_level + 1, local_dict=local_dict)
@@ -551,12 +550,14 @@ class Expr(expr.Expr):
 
                 # stringify with quotes these values
                 def convert(v):
-                    if isinstance(v, (datetime,np.datetime64,timedelta,np.timedelta64)) or hasattr(v, 'timetuple'):
+                    if (isinstance(v, (datetime, np.datetime64,
+                                       timedelta, np.timedelta64)) or
+                            hasattr(v, 'timetuple')):
                         return "'{0}'".format(v)
                     return v
 
-                if isinstance(value, (list,tuple)):
-                    value = [ convert(v) for v in value ]
+                if isinstance(value, (list, tuple)):
+                    value = [convert(v) for v in value]
                 else:
                     value = convert(value)
 
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index b085232a1..82da9cacd 100644
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -1,5 +1,7 @@
 #!/usr/bin/env python
 
+# flake8: noqa
+
 import warnings
 import operator
 from itertools import product
@@ -82,6 +84,7 @@ def _is_py3_complex_incompat(result, expected):
 
 _good_arith_ops = com.difference(_arith_ops_syms, _special_case_arith_ops_syms)
 
+
 class TestEvalNumexprPandas(tm.TestCase):
 
     @classmethod
@@ -194,7 +197,7 @@ class TestEvalNumexprPandas(tm.TestCase):
                                                                 binop=binop,
                                                                 cmp2=cmp2)
         scalar_with_in_notin = (np.isscalar(rhs) and (cmp1 in skip_these or
-                                cmp2 in skip_these))
+                                                      cmp2 in skip_these))
         if scalar_with_in_notin:
             with tm.assertRaises(TypeError):
                 pd.eval(ex, engine=self.engine, parser=self.parser)
@@ -211,12 +214,12 @@ class TestEvalNumexprPandas(tm.TestCase):
                 # hand side bool ops are fixed.
 
                 # try:
-                    # self.assertRaises(Exception, pd.eval, ex,
-                                    #local_dict={'lhs': lhs, 'rhs': rhs},
-                                    # engine=self.engine, parser=self.parser)
+                # self.assertRaises(Exception, pd.eval, ex,
+                #local_dict={'lhs': lhs, 'rhs': rhs},
+                # engine=self.engine, parser=self.parser)
                 # except AssertionError:
-                    #import ipdb; ipdb.set_trace()
-                    # raise
+                #import ipdb; ipdb.set_trace()
+                # raise
             else:
                 expected = _eval_single_bin(
                     lhs_new, binop, rhs_new, self.engine)
@@ -351,7 +354,7 @@ class TestEvalNumexprPandas(tm.TestCase):
             for engine in self.current_engines:
                 tm.skip_if_no_ne(engine)
                 tm.assert_numpy_array_equal(result, pd.eval('~elb', engine=engine,
-                                            parser=self.parser))
+                                                            parser=self.parser))
 
     def check_compound_invert_op(self, lhs, cmp1, rhs):
         skip_these = 'in', 'not in'
@@ -616,8 +619,8 @@ class TestEvalNumexprPandas(tm.TestCase):
                     '-False, False, ~False, +False,'
                     '-37, 37, ~37, +37]'),
             np.array([-True, True, ~True, +True,
-             -False, False, ~False, +False,
-             -37, 37, ~37, +37]))
+                      -False, False, ~False, +False,
+                      -37, 37, ~37, +37]))
 
     def test_disallow_scalar_bool_ops(self):
         exprs = '1 or 2', '1 and 2'
@@ -834,7 +837,8 @@ class TestAlignment(object):
                         res = pd.eval('df + df2 + df3', engine=engine,
                                       parser=parser)
                 else:
-                    res = pd.eval('df + df2 + df3', engine=engine, parser=parser)
+                    res = pd.eval('df + df2 + df3',
+                                  engine=engine, parser=parser)
                 assert_frame_equal(res, df + df2 + df3)
 
     @slow
@@ -1549,6 +1553,7 @@ class TestOperationsPythonPandas(TestOperationsNumExprPandas):
 
 
 class TestMathPythonPython(tm.TestCase):
+
     @classmethod
     def setUpClass(cls):
         super(TestMathPythonPython, cls).setUpClass()
@@ -1648,6 +1653,7 @@ class TestMathPythonPython(tm.TestCase):
 
 
 class TestMathPythonPandas(TestMathPythonPython):
+
     @classmethod
     def setUpClass(cls):
         super(TestMathPythonPandas, cls).setUpClass()
@@ -1656,6 +1662,7 @@ class TestMathPythonPandas(TestMathPythonPython):
 
 
 class TestMathNumExprPandas(TestMathPythonPython):
+
     @classmethod
     def setUpClass(cls):
         super(TestMathNumExprPandas, cls).setUpClass()
@@ -1664,6 +1671,7 @@ class TestMathNumExprPandas(TestMathPythonPython):
 
 
 class TestMathNumExprPython(TestMathPythonPython):
+
     @classmethod
     def setUpClass(cls):
         super(TestMathNumExprPython, cls).setUpClass()
@@ -1679,7 +1687,7 @@ class TestScope(object):
     def check_global_scope(self, e, engine, parser):
         tm.skip_if_no_ne(engine)
         tm.assert_numpy_array_equal(_var_s * 2, pd.eval(e, engine=engine,
-                                    parser=parser))
+                                                        parser=parser))
 
     def test_global_scope(self):
         e = '_var_s * 2'
@@ -1819,7 +1827,7 @@ def check_numexpr_builtin_raises(engine, parser):
     sin, dotted_line = 1, 2
     if engine == 'numexpr':
         with tm.assertRaisesRegexp(NumExprClobberingError,
-                                'Variables in expression .+'):
+                                   'Variables in expression .+'):
             pd.eval('sin + dotted_line', engine=engine, parser=parser)
     else:
         res = pd.eval('sin + dotted_line', engine=engine, parser=parser)
@@ -1906,6 +1914,7 @@ def check_negate_lt_eq_le(engine, parser):
         result = df.query('not (cat > 0)', engine=engine, parser=parser)
         tm.assert_frame_equal(result, expected)
 
+
 def test_negate_lt_eq_le():
     for engine, parser in product(_engines, expr._parsers):
         yield check_negate_lt_eq_le, engine, parser
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index f06ad927b..65d853f92 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -2211,7 +2211,7 @@ def _clean_na_values(na_values, keep_default_na=True):
                 v = set(list(v)) | _NA_VALUES
                 na_values[k] = v
         na_fvalues = dict([
-            (k, _floatify_na_values(v)) for k, v in na_values.items()
+            (k, _floatify_na_values(v)) for k, v in na_values.items()  # noqa
         ])
     else:
         if not com.is_list_like(na_values):
diff --git a/pandas/msgpack/__init__.py b/pandas/msgpack/__init__.py
index bf0e2853a..0c2370df9 100644
--- a/pandas/msgpack/__init__.py
+++ b/pandas/msgpack/__init__.py
@@ -1,4 +1,6 @@
 # coding: utf-8
+# flake8: noqa
+
 from pandas.msgpack._version import version
 from pandas.msgpack.exceptions import *
 
diff --git a/pandas/msgpack/exceptions.py b/pandas/msgpack/exceptions.py
index f7678f135..40f5a8af8 100644
--- a/pandas/msgpack/exceptions.py
+++ b/pandas/msgpack/exceptions.py
@@ -22,8 +22,10 @@ class ExtraData(ValueError):
     def __str__(self):
         return "unpack(b) received extra data."
 
+
 class PackException(Exception):
     pass
 
+
 class PackValueError(PackException, ValueError):
     pass
diff --git a/pandas/src/generate_code.py b/pandas/src/generate_code.py
index cf42279c8..053e69b7f 100644
--- a/pandas/src/generate_code.py
+++ b/pandas/src/generate_code.py
@@ -6,6 +6,8 @@ during building.  To regenerate `generated.pyx`, just run:
 
 """
 
+# flake8: noqa
+
 from __future__ import print_function
 import os
 from pandas.compat import StringIO
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index 5c3cb5737..c2d25b30c 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -1,5 +1,5 @@
 from pandas.compat import StringIO, callable
-from pandas.lib import cache_readonly
+from pandas.lib import cache_readonly  # noqa
 import sys
 import warnings
 from textwrap import dedent
@@ -60,6 +60,7 @@ def deprecate_kwarg(old_arg_name, new_arg_name, mapping=None, stacklevel=2):
             not callable(mapping):
         raise TypeError("mapping from old to new argument values "
                         "must be dict or callable!")
+
     def _deprecate_kwarg(func):
         @wraps(func)
         def wrapper(*args, **kwargs):
@@ -82,8 +83,8 @@ def deprecate_kwarg(old_arg_name, new_arg_name, mapping=None, stacklevel=2):
 
                 warnings.warn(msg, FutureWarning, stacklevel=stacklevel)
                 if kwargs.get(new_arg_name, None) is not None:
-                    msg = "Can only specify '%s' or '%s', not both" % \
-                      (old_arg_name, new_arg_name)
+                    msg = ("Can only specify '%s' or '%s', not both" %
+                           (old_arg_name, new_arg_name))
                     raise TypeError(msg)
                 else:
                     kwargs[new_arg_name] = new_arg_value
@@ -126,7 +127,7 @@ class Substitution(object):
     """
     def __init__(self, *args, **kwargs):
         if (args and kwargs):
-            raise AssertionError( "Only positional or keyword args are allowed")
+            raise AssertionError("Only positional or keyword args are allowed")
 
         self.params = args or kwargs
 
@@ -261,7 +262,8 @@ def knownfailureif(fail_condition, msg=None):
 
     return knownfail_decorator
 
-def make_signature(func) :
+
+def make_signature(func):
     """
     Returns a string repr of the arg list of a func call, with any defaults
 
@@ -275,15 +277,15 @@ def make_signature(func) :
     """
     from inspect import getargspec
     spec = getargspec(func)
-    if spec.defaults is None :
+    if spec.defaults is None:
         n_wo_defaults = len(spec.args)
         defaults = ('',) * n_wo_defaults
-    else :
+    else:
         n_wo_defaults = len(spec.args) - len(spec.defaults)
         defaults = ('',) * n_wo_defaults + spec.defaults
     args = []
-    for i, (var, default) in enumerate(zip(spec.args, defaults)) :
-        args.append(var if default=='' else var+'='+repr(default))
+    for i, (var, default) in enumerate(zip(spec.args, defaults)):
+        args.append(var if default == '' else var + '=' + repr(default))
     if spec.varargs:
         args.append('*' + spec.varargs)
     if spec.keywords:
diff --git a/pandas/util/doctools.py b/pandas/util/doctools.py
index 20a2a68ce..62dcba140 100644
--- a/pandas/util/doctools.py
+++ b/pandas/util/doctools.py
@@ -23,11 +23,15 @@ class TablePlotter(object):
         """Calcurate appropriate figure size based on left and right data"""
         if vertical:
             # calcurate required number of cells
-            vcells = max(sum([self._shape(l)[0] for l in left]), self._shape(right)[0])
-            hcells = max([self._shape(l)[1] for l in left]) + self._shape(right)[1]
+            vcells = max(sum([self._shape(l)[0] for l in left]),
+                         self._shape(right)[0])
+            hcells = (max([self._shape(l)[1] for l in left]) +
+                      self._shape(right)[1])
         else:
-            vcells = max([self._shape(l)[0] for l in left] + [self._shape(right)[0]])
-            hcells = sum([self._shape(l)[1] for l in left] + [self._shape(right)[1]])
+            vcells = max([self._shape(l)[0] for l in left] +
+                         [self._shape(right)[0]])
+            hcells = sum([self._shape(l)[1] for l in left] +
+                         [self._shape(right)[1]])
         return hcells, vcells
 
     def plot(self, left, right, labels=None, vertical=True):
@@ -66,10 +70,11 @@ class TablePlotter(object):
             max_left_rows = max([self._shape(l)[0] for l in left])
             for i, (l, label) in enumerate(zip(left, labels)):
                 ax = fig.add_subplot(gs[i, 0:max_left_cols])
-                self._make_table(ax, l, title=label, height=1.0/max_left_rows)
+                self._make_table(ax, l, title=label,
+                                 height=1.0 / max_left_rows)
             # right
             ax = plt.subplot(gs[:, max_left_cols:])
-            self._make_table(ax, right, title='Result', height=1.05/vcells)
+            self._make_table(ax, right, title='Result', height=1.05 / vcells)
             fig.subplots_adjust(top=0.9, bottom=0.05, left=0.05, right=0.95)
         else:
             max_rows = max([self._shape(df)[0] for df in left + [right]])
@@ -79,7 +84,7 @@ class TablePlotter(object):
             i = 0
             for l, label in zip(left, labels):
                 sp = self._shape(l)
-                ax = fig.add_subplot(gs[0, i:i+sp[1]])
+                ax = fig.add_subplot(gs[0, i:i + sp[1]])
                 self._make_table(ax, l, title=label, height=height)
                 i += sp[1]
             # right
@@ -107,12 +112,14 @@ class TablePlotter(object):
             data.insert(0, 'Index', data.index)
         else:
             for i in range(idx_nlevels):
-                data.insert(i, 'Index{0}'.format(i), data.index.get_level_values(i))
+                data.insert(i, 'Index{0}'.format(i),
+                            data.index.get_level_values(i))
 
         col_nlevels = data.columns.nlevels
         if col_nlevels > 1:
             col = data.columns.get_level_values(0)
-            values = [data.columns.get_level_values(i).values for i in range(1, col_nlevels)]
+            values = [data.columns.get_level_values(i).values
+                      for i in range(1, col_nlevels)]
             col_df = pd.DataFrame(values)
             data.columns = col_df.columns
             data = pd.concat([col_df, data])
@@ -151,7 +158,6 @@ class TablePlotter(object):
 
 
 if __name__ == "__main__":
-    import pandas as pd
     import matplotlib.pyplot as plt
 
     p = TablePlotter()
@@ -174,11 +180,11 @@ if __name__ == "__main__":
     plt.show()
 
     idx = pd.MultiIndex.from_tuples([(1, 'A'), (1, 'B'), (1, 'C'),
-                                 (2, 'A'), (2, 'B'), (2, 'C')])
+                                     (2, 'A'), (2, 'B'), (2, 'C')])
     col = pd.MultiIndex.from_tuples([(1, 'A'), (1, 'B')])
     df3 = pd.DataFrame({'v1': [1, 2, 3, 4, 5, 6],
                         'v2': [5, 6, 7, 8, 9, 10]},
-                        index=idx)
+                       index=idx)
     df3.columns = col
     p.plot(df3, df3, labels=['df3'])
     plt.show()
diff --git a/pandas/util/misc.py b/pandas/util/misc.py
index 15492cde5..2dd59043b 100644
--- a/pandas/util/misc.py
+++ b/pandas/util/misc.py
@@ -1,10 +1,12 @@
 """ various miscellaneous utilities """
 
+
 def is_little_endian():
     """ am I little endian """
     import sys
     return sys.byteorder == 'little'
 
+
 def exclusive(*args):
     count = sum([arg is not None for arg in args])
     return count == 1
diff --git a/pandas/util/print_versions.py b/pandas/util/print_versions.py
index a4cb84d53..5c09f877d 100644
--- a/pandas/util/print_versions.py
+++ b/pandas/util/print_versions.py
@@ -16,7 +16,8 @@ def get_sys_info():
     if os.path.isdir(".git") and os.path.isdir("pandas"):
         try:
             pipe = subprocess.Popen('git log --format="%H" -n 1'.split(" "),
-                                    stdout=subprocess.PIPE, stderr=subprocess.PIPE)
+                                    stdout=subprocess.PIPE,
+                                    stderr=subprocess.PIPE)
             so, serr = pipe.communicate()
         except:
             pass
@@ -32,8 +33,8 @@ def get_sys_info():
     blob.append(('commit', commit))
 
     try:
-        sysname, nodename, release, version, machine, processor = platform.uname(
-        )
+        (sysname, nodename, release,
+         version, machine, processor) = platform.uname()
         blob.extend([
             ("python", "%d.%d.%d.%s.%s" % sys.version_info[:]),
             ("python-bits", struct.calcsize("P") * 8),
@@ -113,7 +114,7 @@ def show_versions(as_json=False):
 
         j = dict(system=dict(sys_info), dependencies=dict(deps_blob))
 
-        if as_json == True:
+        if as_json is True:
             print(j)
         else:
             with codecs.open(as_json, "wb", encoding='utf8') as f:
@@ -136,7 +137,8 @@ def main():
     from optparse import OptionParser
     parser = OptionParser()
     parser.add_option("-j", "--json", metavar="FILE", nargs=1,
-                      help="Save output as JSON into file, pass in '-' to output to stdout")
+                      help="Save output as JSON into file, pass in "
+                      "'-' to output to stdout")
 
     (options, args) = parser.parse_args()
 
diff --git a/pandas/util/terminal.py b/pandas/util/terminal.py
index fc985855d..6b8428ff7 100644
--- a/pandas/util/terminal.py
+++ b/pandas/util/terminal.py
@@ -94,7 +94,6 @@ def _get_terminal_size_linux():
             import fcntl
             import termios
             import struct
-            import os
             cr = struct.unpack(
                 'hh', fcntl.ioctl(fd, termios.TIOCGWINSZ, '1234'))
         except:
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 685d89fee..b78ba9294 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -1,6 +1,8 @@
 from __future__ import division
 # pylint: disable-msg=W0402
 
+# flake8: noqa
+
 import random
 import re
 import string
