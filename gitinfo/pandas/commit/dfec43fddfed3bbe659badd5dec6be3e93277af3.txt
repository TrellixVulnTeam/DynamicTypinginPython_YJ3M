commit dfec43fddfed3bbe659badd5dec6be3e93277af3
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jun 19 18:26:28 2012 -0400

    TST: test coverage #1245

diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 0a9b7bd90..af6c5e4d1 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -25,12 +25,6 @@ def _utc():
 
 # -------- some conversion wrapper functions
 
-def _as_i8(arg):
-    if isinstance(arg, np.ndarray) and arg.dtype == np.datetime64:
-        return arg.view('i8', type=np.ndarray)
-    else:
-        return arg
-
 
 def _field_accessor(name, field):
     def f(self):
@@ -43,19 +37,6 @@ def _field_accessor(name, field):
     f.__name__ = name
     return property(f)
 
-def _wrap_i8_function(f):
-    @staticmethod
-    def wrapper(*args, **kwargs):
-        view_args = [_as_i8(arg) for arg in args]
-        return f(*view_args, **kwargs)
-    return wrapper
-
-def _wrap_dt_function(f):
-    @staticmethod
-    def wrapper(*args, **kwargs):
-        view_args = [_dt_box_array(_as_i8(arg)) for arg in args]
-        return f(*view_args, **kwargs)
-    return wrapper
 
 def _join_i8_wrapper(joinf, with_indexers=True):
     @staticmethod
@@ -72,6 +53,7 @@ def _join_i8_wrapper(joinf, with_indexers=True):
         return results
     return wrapper
 
+
 def _dt_index_cmp(opname):
     """
     Wrap comparison operations to convert datetime-like to datetime64
@@ -87,32 +69,14 @@ def _dt_index_cmp(opname):
             other = _ensure_datetime64(other)
         result = func(other)
 
-        try:
-            return result.view(np.ndarray)
-        except:
-            return result
+        return result.view(np.ndarray)
+
     return wrapper
 
 def _ensure_datetime64(other):
     if isinstance(other, np.datetime64):
         return other
-    elif com.is_integer(other):
-        return np.int64(other).view('M8[us]')
-    else:
-        raise TypeError(other)
-
-def _dt_index_op(opname):
-    """
-    Wrap arithmetic operations to convert timedelta to a timedelta64.
-    """
-    def wrapper(self, other):
-        if isinstance(other, timedelta):
-            func = getattr(self, opname)
-            return func(np.timedelta64(other))
-        else:
-            func = getattr(super(DatetimeIndex, self), opname)
-            return func(other)
-    return wrapper
+    raise TypeError('%s type object %s' % (type(other), str(other)))
 
 
 class TimeSeriesError(Exception):
@@ -154,8 +118,7 @@ class DatetimeIndex(Int64Index):
     _left_indexer  = _join_i8_wrapper(_algos.left_join_indexer_int64)
     _left_indexer_unique  = _join_i8_wrapper(
         _algos.left_join_indexer_unique_int64, with_indexers=False)
-
-    _arrmap = _wrap_dt_function(_algos.arrmap_object)
+    _arrmap = None
 
     __eq__ = _dt_index_cmp('__eq__')
     __ne__ = _dt_index_cmp('__ne__')
@@ -194,11 +157,6 @@ class DatetimeIndex(Int64Index):
             warnings.warn("parameter 'offset' is deprecated, "
                           "please use 'freq' instead",
                           FutureWarning)
-            if isinstance(freq, basestring):
-                freq = to_offset(freq)
-        else:
-            if isinstance(freq, basestring):
-                freq = to_offset(freq)
 
         offset = freq
 
@@ -223,9 +181,6 @@ class DatetimeIndex(Int64Index):
                                  'collection of some kind, %s was passed'
                                  % repr(data))
 
-            if isinstance(data, datetime):
-                data = [data]
-
             # other iterable of some kind
             if not isinstance(data, (list, tuple)):
                 data = list(data)
@@ -244,17 +199,16 @@ class DatetimeIndex(Int64Index):
         elif issubclass(data.dtype.type, np.datetime64):
             if isinstance(data, DatetimeIndex):
                 subarr = data.values
-                offset = data.offset
-                verify_integrity = False
+                if offset is None:
+                    offset = data.offset
+                    verify_integrity = False
             else:
                 if data.dtype != _NS_DTYPE:
                     subarr = lib.cast_to_nanoseconds(data)
                 else:
                     subarr = data
         elif data.dtype == _INT64_DTYPE:
-            subarr = data.view(_NS_DTYPE)
-        elif issubclass(data.dtype.type, np.integer):
-            subarr = np.array(data, dtype=_NS_DTYPE, copy=copy)
+            subarr = np.asarray(data, dtype=_NS_DTYPE)
         else:
             subarr = tools.to_datetime(data)
             if not np.issubdtype(subarr.dtype, np.datetime64):
@@ -295,10 +249,6 @@ class DatetimeIndex(Int64Index):
 
         if start is not None:
             start = Timestamp(start)
-            if not isinstance(start, Timestamp):
-                raise ValueError('Failed to convert %s to timestamp'
-                                 % start)
-
             if normalize:
                 start = normalize_date(start)
                 _normalized = True
@@ -307,9 +257,6 @@ class DatetimeIndex(Int64Index):
 
         if end is not None:
             end = Timestamp(end)
-            if not isinstance(end, Timestamp):
-                raise ValueError('Failed to convert %s to timestamp'
-                                 % end)
 
             if normalize:
                 end = normalize_date(end)
@@ -319,6 +266,9 @@ class DatetimeIndex(Int64Index):
 
         start, end, tz = tools._figure_out_timezone(start, end, tz)
 
+        if com._count_not_none(start, end, periods) < 2:
+            raise ValueError('Must specify two of start, end, or periods')
+
         if (offset._should_cache() and
             not (offset._normalize_cache and not _normalized) and
             _naive_in_cache_range(start, end)):
@@ -329,7 +279,7 @@ class DatetimeIndex(Int64Index):
 
         if tz is not None:
             # Convert local to UTC
-            ints = index.view('i8')
+            ints = index.view('i8', type=np.ndarray)
             index = lib.tz_localize_to_utc(ints, tz)
             index = index.view(_NS_DTYPE)
 
@@ -384,11 +334,6 @@ class DatetimeIndex(Int64Index):
             cachedRange = drc[offset]
 
         if start is None:
-            if end is None:
-                raise Exception('Must provide start or end date!')
-            if periods is None:
-                raise Exception('Must provide number of periods!')
-
             assert(isinstance(end, Timestamp))
 
             end = offset.rollback(end)
@@ -400,9 +345,6 @@ class DatetimeIndex(Int64Index):
             start = offset.rollforward(start)
 
             startLoc = cachedRange.get_loc(start)
-            if periods is None:
-                raise Exception('Must provide number of periods!')
-
             endLoc = startLoc + periods
         else:
             if not offset.onOffset(start):
@@ -1050,7 +992,7 @@ class DatetimeIndex(Int64Index):
         try:
             return f(self)
         except:
-            return Index.map(self, f)
+            return _algos.arrmap_object(self.asobject, f)
 
     # alias to offset
     @property
@@ -1330,9 +1272,6 @@ class DatetimeIndex(Int64Index):
         return mask.nonzero()[0]
 
 def _generate_regular_range(start, end, periods, offset):
-    if com._count_not_none(start, end, periods) < 2:
-        raise ValueError('Must specify two of start, end, or periods')
-
     if isinstance(offset, Tick):
         stride = offset.nanos
         if periods is None:
@@ -1461,9 +1400,9 @@ def _str_to_dt_array(arr, offset=None):
         result = parse_time_string(x, offset)
         return result[0]
 
-    p_ufunc = np.frompyfunc(parser, 1, 1)
-    data = p_ufunc(arr)
-    return np.array(data, dtype=_NS_DTYPE)
+    arr = np.asarray(arr, dtype=object)
+    data = _algos.arrmap_object(arr, parser)
+    return tools.to_datetime(data)
 
 
 _CACHE_START = Timestamp(datetime(1950, 1, 1))
@@ -1481,9 +1420,6 @@ def _naive_in_cache_range(start, end):
 def _in_range(start, end, rng_start, rng_end):
     return start > rng_start and end < rng_end
 
-def _time_to_nanosecond(time):
-    return _time_to_micros(time) * 1000
-
 def _time_to_micros(time):
     seconds = time.hour * 60 * 60 + 60 * time.minute + time.second
     return 1000000 * seconds + time.microsecond
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index c381e210c..aede31eaa 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -228,7 +228,7 @@ class DateOffset(object):
             return code
 
 
-class BusinessDay(DateOffset, CacheableOffset):
+class BusinessDay(CacheableOffset, DateOffset):
     """
     DateOffset subclass representing possibly n business days
     """
@@ -348,7 +348,7 @@ class MonthBegin(DateOffset, CacheableOffset):
         return 'MS'
 
 
-class BusinessMonthEnd(DateOffset, CacheableOffset):
+class BusinessMonthEnd(CacheableOffset, DateOffset):
     """DateOffset increments between business EOM dates"""
 
     def isAnchored(self):
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 536c91786..1aca15c60 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -951,6 +951,74 @@ def _simple_ts(start, end, freq='D'):
     return Series(np.random.randn(len(rng)), index=rng)
 
 
+class TestDatetimeIndex(unittest.TestCase):
+
+    def test_append_nondatetimeindex(self):
+        rng = date_range('1/1/2000', periods=10)
+        idx = Index(['a', 'b', 'c', 'd'])
+
+        result = rng.append(idx)
+        self.assert_(isinstance(result[0], Timestamp))
+
+    def test_constructor_coverage(self):
+        rng = date_range('1/1/2000', periods=10.5)
+        exp = date_range('1/1/2000', periods=10)
+        self.assert_(rng.equals(exp))
+
+        self.assertRaises(ValueError, DatetimeIndex, start='1/1/2000',
+                          periods='foo', freq='D')
+
+        self.assertRaises(ValueError, DatetimeIndex, start='1/1/2000',
+                          end='1/10/2000')
+
+        self.assertRaises(ValueError, DatetimeIndex, '1/1/2000')
+
+        # generator expression
+        gen = (datetime(2000, 1, 1) + timedelta(i) for i in range(10))
+        result = DatetimeIndex(gen)
+        expected = DatetimeIndex([datetime(2000, 1, 1) + timedelta(i)
+                                  for i in range(10)])
+        self.assert_(result.equals(expected))
+
+        # NumPy string array
+        strings = np.array(['2000-01-01', '2000-01-02', '2000-01-03'])
+        result = DatetimeIndex(strings)
+        expected = DatetimeIndex(strings.astype('O'))
+        self.assert_(result.equals(expected))
+
+        from_ints = DatetimeIndex(expected.asi8)
+        self.assert_(from_ints.equals(expected))
+
+        # non-conforming
+        self.assertRaises(ValueError, DatetimeIndex,
+                          ['2000-01-01', '2000-01-02', '2000-01-04'],
+                          freq='D')
+
+        self.assertRaises(ValueError, DatetimeIndex,
+                          start='2011-01-01', freq='b')
+        self.assertRaises(ValueError, DatetimeIndex,
+                          end='2011-01-01', freq='B')
+        self.assertRaises(ValueError, DatetimeIndex, periods=10, freq='D')
+
+    def test_comparisons_coverage(self):
+        rng = date_range('1/1/2000', periods=10)
+
+        # raise TypeError for now
+        self.assertRaises(TypeError, rng.__lt__, rng[3].value)
+
+        result = rng == list(rng)
+        exp = rng == rng
+        self.assert_(np.array_equal(result, exp))
+
+    def test_map(self):
+        rng = date_range('1/1/2000', periods=10)
+
+        f = lambda x: x.strftime('%Y%m%d')
+        result = rng.map(f)
+        exp = [f(x) for x in rng]
+        self.assert_(np.array_equal(result, exp))
+
+
 class TestLegacySupport(unittest.TestCase):
 
     @classmethod
@@ -968,6 +1036,15 @@ class TestLegacySupport(unittest.TestCase):
         with open(filepath, 'rb') as f:
             cls.series = pickle.load(f)
 
+    def test_pass_offset_warn(self):
+        from StringIO import StringIO
+        import sys
+        buf = StringIO()
+
+        sys.stderr = buf
+        DatetimeIndex(start='1/1/2000', periods=10, offset='H')
+        sys.stderr = sys.__stderr__
+
     def test_unpickle_legacy_frame(self):
         dtindex = DatetimeIndex(start='1/3/2005', end='1/14/2005',
                                 freq=BDay(1))
diff --git a/test.sh b/test.sh
index bd2cad440..3f378fd86 100755
--- a/test.sh
+++ b/test.sh
@@ -2,7 +2,7 @@
 coverage erase
 # nosetests pandas/tests/test_index.py --with-coverage --cover-package=pandas.core --pdb-failure --pdb
 #nosetests -w pandas --with-coverage --cover-package=pandas --pdb-failure --pdb #--cover-inclusive
-nosetests -w pandas --with-coverage --cover-package=pandas $* #--cover-inclusive
+nosetests -A "not slow" -w pandas/tseries --with-coverage --cover-package=pandas.tseries $* #--cover-inclusive
 # nosetests -w pandas/io --with-coverage --cover-package=pandas.io --pdb-failure --pdb
 # nosetests -w pandas/core --with-coverage --cover-package=pandas.core --pdb-failure --pdb
 # nosetests -w pandas/stats --with-coverage --cover-package=pandas.stats
