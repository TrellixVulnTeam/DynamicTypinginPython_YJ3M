commit 894d6b2a8ce1bf88f4bc0ee4479f063246f16fef
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Dec 20 23:45:12 2011 -0500

    BUG: handle rows skipped at beginning of CSV file, GH #505

diff --git a/RELEASE.rst b/RELEASE.rst
index 95ff7b793..8378acb15 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -67,9 +67,20 @@ pandas 0.6.2
     #488)
   - Fix exception passing empty list to DataFrame.from_records
   - Fix Index.format bug (excluding name field) with datetimes with time info
+  - Fix scalar value access in Series to always return NumPy scalars,
+    regression from prior versions (GH #510)
 
 Thanks
 ------
+- Craig Austin
+- Andreas Hilboll
+- Adam Klein
+- Wouter Overmeire
+- Christian Prinoth
+- Sam Reckoner
+- Craig Reeson
+- Jan Schulz
+- Dieter Vandenbussche
 
 pandas 0.6.1
 ============
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index d13897a7c..464a9576f 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -15,8 +15,6 @@ def read_csv(filepath_or_buffer, sep=None, header=0, index_col=None, names=None,
              skiprows=None, na_values=None, parse_dates=False,
              date_parser=None, nrows=None, iterator=False, chunksize=None,
              skip_footer=0, converters=None):
-    import csv
-
     if hasattr(filepath_or_buffer, 'read'):
         f = filepath_or_buffer
     else:
@@ -26,33 +24,16 @@ def read_csv(filepath_or_buffer, sep=None, header=0, index_col=None, names=None,
         except Exception: # pragma: no cover
             f = open(filepath_or_buffer, 'r')
 
-    buf = []
-    if sep is None or len(sep) == 1:
-        sniff_sep = True
-        # default dialect
-        dia = csv.excel
-        if sep is not None:
-            sniff_sep = False
-            dia.delimiter = sep
-        # attempt to sniff the delimiter
-        if sniff_sep:
-            line = f.readline()
-            sniffed = csv.Sniffer().sniff(line)
-            dia.delimiter = sniffed.delimiter
-            buf.extend(list(csv.reader(StringIO(line), dialect=dia)))
-        reader = csv.reader(f, dialect=dia)
-    else:
-        reader = (re.split(sep, line.strip()) for line in f)
-
     if date_parser is not None:
         parse_dates = True
 
-    parser = TextParser(reader, header=header, index_col=index_col,
+    parser = TextParser(f, header=header, index_col=index_col,
                         names=names, na_values=na_values,
                         parse_dates=parse_dates,
                         date_parser=date_parser,
                         skiprows=skiprows,
-                        chunksize=chunksize, buf=buf,
+                        delimiter=sep,
+                        chunksize=chunksize,
                         skip_footer=skip_footer,
                         converters=converters)
 
@@ -176,7 +157,7 @@ class TextParser(object):
 
     Parameters
     ----------
-    data : list or csv reader-like object
+    data : file-like object or list
     names : sequence, default
     header : int, default 0
         Row to use to parse column labels. Defaults to the first row. Prior
@@ -200,21 +181,18 @@ class TextParser(object):
                      '#N/A N/A', 'NA', '#NA', 'NULL', 'NaN',
                      'nan', ''])
 
-    def __init__(self, data, names=None, header=0, index_col=None,
-                 na_values=None, parse_dates=False, date_parser=None,
-                 chunksize=None, skiprows=None, skip_footer=0,
-                 converters=None, buf=None):
+    def __init__(self, f, delimiter=None, names=None, header=0,
+                 index_col=None, na_values=None, parse_dates=False,
+                 date_parser=None, chunksize=None, skiprows=None,
+                 skip_footer=0, converters=None):
         """
         Workhorse function for processing nested list into DataFrame
 
         Should be replaced by np.genfromtxt eventually?
         """
-        self.data = data
-
-        # can pass rows read so far
-        self.buf = [] if buf is None else buf
-        self.pos = len(self.buf)
-
+        self.data = None
+        self.buf = []
+        self.pos = 0
         self.names = list(names) if names is not None else names
         self.header = header
         self.index_col = index_col
@@ -224,6 +202,7 @@ class TextParser(object):
         self.passed_names = names is not None
         self.skiprows = set() if skiprows is None else set(skiprows)
         self.skip_footer = skip_footer
+        self.delimiter = delimiter
 
         if converters is not None:
             assert(isinstance(converters, dict))
@@ -238,10 +217,43 @@ class TextParser(object):
         else:
             self.na_values = set(list(na_values)) | self.NA_VALUES
 
+        if hasattr(f, 'readline'):
+            self._make_reader(f)
+        else:
+            self.data = f
         self.columns = self._infer_columns()
         self.index_name = self._get_index_name()
         self._first_chunk = True
 
+    def _make_reader(self, f):
+        import csv
+
+        sep = self.delimiter
+
+        if sep is None or len(sep) == 1:
+            sniff_sep = True
+            # default dialect
+            dia = csv.excel
+            if sep is not None:
+                sniff_sep = False
+                dia.delimiter = sep
+            # attempt to sniff the delimiter
+            if sniff_sep:
+                line = f.readline()
+                while self.pos in self.skiprows:
+                    self.pos += 1
+                    line = f.readline()
+
+                self.pos += 1
+                sniffed = csv.Sniffer().sniff(line)
+                dia.delimiter = sniffed.delimiter
+                self.buf.extend(list(csv.reader(StringIO(line), dialect=dia)))
+            reader = csv.reader(f, dialect=dia)
+        else:
+            reader = (re.split(sep, line.strip()) for line in f)
+
+        self.data = reader
+
     def _infer_columns(self):
         names = self.names
         passed_names = self.names is not None
@@ -284,12 +296,12 @@ class TextParser(object):
 
     def _next_line(self):
         if isinstance(self.data, list):
-            if self.pos in self.skiprows:
+            while self.pos in self.skiprows:
                 self.pos += 1
 
             line = self.data[self.pos]
         else:
-            if self.pos in self.skiprows:
+            while self.pos in self.skiprows:
                 self.data.next()
                 self.pos += 1
             line = self.data.next()
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index abf089baa..d07b7b777 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -52,6 +52,28 @@ ignore,this,row
                          skiprows=[1])
         assert_almost_equal(df2.values, expected)
 
+    def test_skiprows_bug(self):
+        # GH #505
+        text = """#foo,a,b,c
+#foo,a,b,c
+#foo,a,b,c
+#foo,a,b,c
+#foo,a,b,c
+#foo,a,b,c
+1/1/2000,1.,2.,3.
+1/2/2000,4,5,6
+1/3/2000,7,8,9
+"""
+        data = read_csv(StringIO(text), skiprows=range(6), header=None,
+                        index_col=0, parse_dates=True)
+
+        expected = DataFrame(np.arange(1., 10.).reshape((3,3)),
+                             columns=['X.2', 'X.3', 'X.4'],
+                             index=[datetime(2000, 1, 1), datetime(2000, 1, 2),
+                                    datetime(2000, 1, 3)])
+        assert_frame_equal(data, expected)
+
+
     def test_detect_string_na(self):
         data = """A,B
 foo,bar
