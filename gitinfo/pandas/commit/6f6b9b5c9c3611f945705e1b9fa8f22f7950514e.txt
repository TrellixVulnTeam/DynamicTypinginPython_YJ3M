commit 6f6b9b5c9c3611f945705e1b9fa8f22f7950514e
Author: Adam Klein <adamklein@gmail.com>
Date:   Fri Feb 17 17:57:07 2012 -0500

    ENH: added SeriesBinGrouper, takes bin edges instead of labels

diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 652f379b7..991ceafaf 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -219,6 +219,8 @@ def groupsort_indexer(ndarray[int32_t] index, Py_ssize_t ngroups):
 
 # TODO: aggregate multiple columns in single pass
 
+# TODO: add passing bin edges, instead of labels
+
 @cython.boundscheck(False)
 @cython.wraparound(False)
 def group_add(ndarray[float64_t, ndim=2] out,
diff --git a/pandas/src/reduce.pyx b/pandas/src/reduce.pyx
index 588cd1161..a0f18dbab 100644
--- a/pandas/src/reduce.pyx
+++ b/pandas/src/reduce.pyx
@@ -88,6 +88,109 @@ cdef class Reducer:
             raise ValueError('function does not reduce')
         return result
 
+# TODO: Series grouper that takes bin edges instead of labels
+
+cdef class SeriesBinGrouper:
+    '''
+    Performs grouping operation according to bin edges, rather than labels
+    '''
+    cdef:
+        Py_ssize_t nresults, ngroups
+        bint passed_dummy
+
+    cdef public:
+        object arr, index, dummy, f, bins
+
+    def __init__(self, object series, object f, object bins, object dummy):
+        n = len(series)
+
+        self.bins = bins
+        self.f = f
+        if not series.flags.c_contiguous:
+            series = series.copy('C')
+        self.arr = series
+        self.index = series.index
+
+        self.dummy = self._check_dummy(dummy)
+        self.passed_dummy = dummy is not None
+        self.ngroups = len(bins) + 1
+
+    def _check_dummy(self, dummy=None):
+        if dummy is None:
+            dummy = np.empty(0, dtype=self.arr.dtype)
+        else:
+            if dummy.dtype != self.arr.dtype:
+                raise ValueError('Dummy array must be same dtype')
+            if not dummy.flags.contiguous:
+                dummy = dummy.copy()
+
+        return dummy
+
+    def get_result(self):
+        cdef:
+            ndarray arr, result
+            ndarray[int32_t] counts
+            Py_ssize_t i, n, group_size, lab
+            object res, chunk
+            bint initialized = 0
+            Slider vslider, islider
+
+        counts = np.zeros(self.ngroups, dtype='i4')
+
+        if self.ngroups > 0:
+            counts[0] = self.bins[0]
+            for i in range(1, self.ngroups):
+                if i == self.ngroups - 1:
+                    counts[i] = len(self.arr) - self.bins[i-1]
+                else:
+                    counts[i] = self.bins[i] - self.bins[i-1]
+
+        chunk = self.dummy
+        group_size = 0
+        n = len(self.arr)
+
+        vslider = Slider(self.arr, self.dummy)
+        islider = Slider(self.index, self.dummy.index)
+
+        try:
+            for i in range(self.ngroups):
+                group_size = counts[i]
+
+                islider.set_length(group_size)
+                vslider.set_length(group_size)
+
+                res = self.f(chunk)
+
+                if not initialized:
+                    result = self._get_result_array(res)
+                    initialized = 1
+
+                util.assign_value_1d(result, i, res)
+
+                islider.advance(group_size)
+                vslider.advance(group_size)
+        except:
+            raise
+        finally:
+            # so we don't free the wrong memory
+            islider.cleanup()
+            vslider.cleanup()
+
+        if result.dtype == np.object_:
+            result = maybe_convert_objects(result)
+
+        return result, counts
+
+    def _get_result_array(self, object res):
+        try:
+            assert(not isinstance(res, np.ndarray))
+            assert(not (isinstance(res, list) and len(res) == len(self.dummy)))
+
+            result = np.empty(self.ngroups, dtype='O')
+        except Exception:
+            raise ValueError('function does not reduce')
+        return result
+
 cdef class SeriesGrouper:
     '''
     Performs generic grouping operation while avoiding ndarray construction
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 86102b6bf..a5f254ec7 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -283,6 +283,22 @@ def test_series_grouper():
     exp_counts = np.array([3, 4], dtype=np.int32)
     assert_almost_equal(counts, exp_counts)
 
+def test_series_bin_grouper():
+    from pandas import Series
+    obj = Series(np.random.randn(10))
+    dummy = obj[:0]
+
+    bins = np.array([3, 6])
+
+    grouper = lib.SeriesBinGrouper(obj, np.mean, bins, dummy)
+    result, counts = grouper.get_result()
+
+    expected = np.array([obj[:3].mean(), obj[3:6].mean(), obj[6:].mean()])
+    assert_almost_equal(result, expected)
+
+    exp_counts = np.array([3, 3, 4], dtype=np.int32)
+    assert_almost_equal(counts, exp_counts)
+
 class TestTypeInference(unittest.TestCase):
 
     def test_length_zero(self):
