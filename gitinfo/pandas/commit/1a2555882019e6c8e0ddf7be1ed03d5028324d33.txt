commit 1a2555882019e6c8e0ddf7be1ed03d5028324d33
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Dec 6 02:42:05 2009 +0000

    unit test coverage for Series and Index, various reorganization in release prep
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@75 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/pandas/__init__.py b/pandas/__init__.py
index a062faffd..f8f0912cc 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -1,39 +1,56 @@
-"""
-Pandas - a library for panel, time series, or cross-sectional data analysis
-===========================================================================
-
-Main data structures (see docstrings for detailed documentation)
---------------------
-Index
-    Represent row or column labels in Series / DataFrame structures
-
-Series / TimeSeries
-    Represents standard 1-dimensional cross-section (resp. time series)
-    As an numpy.ndarray subclass, compatible with ufuncs and other NumPy
-    functions
-
-DataFrame / DataMatrix
-    Represent collections of Series objects, enable easy management
-    of multiple time series / cross-sections
-
-DateRange
-    Index subclass for generating arrays of fixed frequency dates
-
-Subpackages
------------
-core
-    Implementations of core data structures, basic building blocks. Most of
-    the user-relevant code is accessible through the top-level namespace
-io
-    Persistence, parsing, and data loading tools
-lib
-    C, Cython, and Fortran extensions for other components
-stats
-    Statistical and econometric functions
-"""
-
 # pylint: disable-msg=W0614,W0401,W0611
 
+__docformat__ = 'restructuredtext'
+
+from pandas.version import __version__
+from pandas.info import __doc__
+
 from pandas.core.api import *
 from pandas.io.parsers import parseCSV, parseText, parseExcel
 from pandas.stats.api import *
+
+# Same NoseWrapper used in scikits.statsmodels
+
+from numpy.testing import Tester
+class NoseWrapper(Tester):
+    '''
+    This is simply a monkey patch for numpy.testing.Tester, so
+    that extra_argv can be changed from its default None to ['--exe']
+    so that the tests can be run the same across platforms.
+    '''
+    def test(self, label='fast', verbose=1, extra_argv=['--exe'], doctests=False,
+             coverage=False):
+        ''' Run tests for module using nose
+
+        %(test_header)s
+        doctests : boolean
+            If True, run doctests in module, default False
+        coverage : boolean
+            If True, report coverage of NumPy code, default False
+            (Requires the coverage module:
+             http://nedbatchelder.com/code/modules/coverage.html)
+        '''
+
+        # cap verbosity at 3 because nose becomes *very* verbose beyond that
+        verbose = min(verbose, 3)
+
+        from numpy.testing import utils
+        utils.verbose = verbose
+
+        if doctests:
+            print "Running unit tests and doctests for %s" % self.package_name
+        else:
+            print "Running unit tests for %s" % self.package_name
+
+        self._show_system_info()
+
+        # reset doctest state on every run
+        import doctest
+        doctest.master = None
+
+        argv, plugins = self.prepare_test_args(label, verbose, extra_argv,
+                                               doctests, coverage)
+        from numpy.testing.noseclasses import NumpyTestProgram
+        t = NumpyTestProgram(argv=argv, exit=False, plugins=plugins)
+        return t.result
+test = NoseWrapper().test
diff --git a/pandas/core/index.py b/pandas/core/index.py
index bc42e21a7..ca96c84ca 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -1,5 +1,6 @@
 # pylint: disable-msg=E1101
 # pylint: disable-msg=E1103
+# pylint: disable-msg=W0232
 
 import numpy as np
 from pandas.lib.tdates import isAllDates
@@ -38,7 +39,7 @@ class Index(np.ndarray):
 
     def __array_finalize__(self, obj):
         if self.ndim == 0:
-            return self.item()
+            raise Exception('Cannot create 0-dimensional Index!')
 
         # New instance creation
         if obj is None:
@@ -121,10 +122,8 @@ class Index(np.ndarray):
         return self.__md5
 
     def asOfDate(self, date):
-        import bisect
-
         if date not in self.indexMap:
-            loc = bisect.bisect(self, date)
+            loc = self.searchsorted(date, side='left')
             if loc > 0:
                 return self[loc-1]
             else:
@@ -178,7 +177,7 @@ class Index(np.ndarray):
             newSeq = np.concatenate((self, newElts))
             try:
                 newSeq = np.unique(newSeq)
-            except Exception, e:
+            except Exception:
                 # Not sortable / multiple types
                 pass
             return Index(newSeq)
@@ -202,7 +201,7 @@ class Index(np.ndarray):
 
         if other is self:
             return self
-        otherArr = np.asarray(other)
+
         theIntersection = sorted(set(self) & set(other))
         return Index(theIntersection)
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 335ceebe8..309552945 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -4,8 +4,8 @@ Data structure for 1-dimensional cross-sectional and time series data
 
 # pylint: disable-msg=E1101
 # pylint: disable-msg=E1103
+# pylint: disable-msg=W0703
 
-from datetime import datetime
 from itertools import izip
 
 from numpy import array, NaN, ndarray
@@ -22,7 +22,7 @@ import pandas.lib.tseries as tseries
 #-------------------------------------------------------------------------------
 # Wrapper function for Series arithmetic methods
 
-def _seriesOpWrap(opname, comp=False):
+def _seriesOpWrap(opname):
     """
     Wrapper function for Series arithmetic operations, to avoid
     code duplication.
@@ -31,37 +31,38 @@ def _seriesOpWrap(opname, comp=False):
         '__add__' : '__radd__',
         '__sub__' : '__rsub__',
         '__div__' : '__rdiv__',
-        '__mul__' : '__rmul__'
+        '__mul__' : '__rmul__',
     }
     def wrapper(self, other):
         from pandas.core.frame import DataFrame
 
-        func = getattr(self.view(ndarray), opname)
+        func = getattr(self.values(), opname)
         cls = self.__class__
         if isinstance(other, Series):
             if self.index.equals(other.index):
-                return cls(func(other.view(ndarray)), index=self.index)
+                return cls(func(other.values()), index=self.index)
+
             if len(self.index) + len(other.index) > 0:
                 newIndex = self.index + other.index
             else:
                 newIndex = NULL_INDEX
+
             try:
                 arr = tseries.combineFunc(opname, newIndex, self, other,
                                           self.index.indexMap,
                                           other.index.indexMap)
-            except Exception, e:
-                arr = Series.combineFunc(self, other,
+            except Exception:
+                arr = Series._combineFunc(self, other,
                                          getattr(type(self[0]), opname))
             result = cls(arr, index=newIndex)
-            if comp:
-                result[isnull(result)] = 0
-                return result.astype(np.bool)
-            else:
-                return result
+            return result
+
         elif isinstance(other, DataFrame):
             reverse_op = MIRROR_OPS.get(opname)
+
             if reverse_op is None:
                 raise Exception('Cannot do %s op, sorry!')
+
             return getattr(other, reverse_op)(self)
         else:
             return cls(func(other), index=self.index)
@@ -71,7 +72,8 @@ def _seriesOpWrap(opname, comp=False):
 # Series class
 
 class Series(np.ndarray, Picklable, Groupable):
-    """Generic indexed series (time series or otherwise) object.
+    """
+    Generic indexed series (time series or otherwise) object.
 
     Contains values in a numpy-ndarray with an optional bound index
     (also an array of dates, strings, or whatever you want the 'row
@@ -86,6 +88,13 @@ class Series(np.ndarray, Picklable, Groupable):
     underlying ndarray. In other words, there is no 'matching' or
     'aligning' to do, it's all taken care of for you.
 
+    Parameters
+    ----------
+    data:  array-like
+        Underlying values of Series, preferably as numpy ndarray
+    index: array-like, optional
+        Index object (or other iterable of same length as data)
+
     Note
     ----
     If you combine two series, all values for an index position must
@@ -95,14 +104,6 @@ class Series(np.ndarray, Picklable, Groupable):
     ALSO NOTE: There is currently no restriction on what can be in the
     index.
 
-    Parameters
-    ----------
-    data:  array-like
-        Underlying values of Series, preferably as numpy ndarray
-    index: array-like, optional
-        Index object (or other iterable of same length as data)
-
-
     Example usage:
         >>> s = Series(arr, index=Index(dates))
         >>> t = Series(otherArr, index=Index(otherDates))
@@ -111,19 +112,19 @@ class Series(np.ndarray, Picklable, Groupable):
         >>> s[5]
         >>> s[d]    # Valid
     """
-    def __new__(cls, data, index=None, dtype=None, copy=False):
+    def __new__(cls, data, index=None, dtype=None, copy=True):
         if index is None and isinstance(data, Series):
             index = data.index
 
-        if index is None:
-            raise Exception('Index cannot be None!')
-
         # Make a copy of the data, infer type
         subarr = array(data, dtype=dtype, copy=copy)
 
         if subarr.ndim == 0:
             return subarr.item()
 
+        if index is None:
+            raise Exception('Index cannot be None!')
+
         # This is to prevent mixed-type Series getting all casted to
         # NumPy string type, e.g. NaN --> '-1#IND'.
 
@@ -139,6 +140,9 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return subarr
 
+    def __hash__(self):
+        raise TypeError('unhashable type')
+
     def _get_index(self):
         return self._index
 
@@ -167,7 +171,7 @@ class Series(np.ndarray, Picklable, Groupable):
         self._index = getattr(obj, '_index', None)
 
     @classmethod
-    def fromDict(cls, input={}, castFloat=True, **kwds):
+    def fromDict(cls, input, castFloat=True, **kwds):
         """
         Analogous to asDataFrame, but turns dict into Series
 
@@ -188,12 +192,15 @@ class Series(np.ndarray, Picklable, Groupable):
         if castFloat:
             try:
                 useData = [float(input[idx]) for idx in index]
-            except Exception, e:
+            except Exception:
                 useData = [input[idx] for idx in index]
         else:
             useData = [input[idx] for idx in index]
         return Series(useData, index=index)
 
+    def toDict(self):
+        return dict(self.iteritems())
+
     @classmethod
     def fromValue(cls, value=np.NaN, index=None, dtype=None):
         """
@@ -209,9 +216,6 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         Series
         """
-        if not isinstance(index, Index):
-            index = Index(index)
-
         # If we create an empty array using a string to infer
         # the dtype, NumPy will only allocate one character per entry
         # so this is kind of bad. Alternately we could use np.repeat
@@ -258,32 +262,42 @@ class Series(np.ndarray, Picklable, Groupable):
               of a sequence, a 'slice' of the series (with corresponding dates)
               will be returned, otherwise a single value.
         """
-        if key is None and key not in self.index:
-            raise Exception('None/Null object requested of Series!')
-        if not hasattr(key, '__iter__'):
-            try:
-                # Check that we can even look for this in the index
-                return ndarray.__getitem__(self, self.index.indexMap[key])
-            except KeyError:
-                if isinstance(key, int):
-                    return ndarray.__getitem__(self, key)
-                raise Exception('Requested index not in this series!')
-            except TypeError:
-                # Could not hash item
-                pass
-        dataSlice = self.view(ndarray)[key]
-        if self.index is not None:
-            indices = self.index.view(ndarray)[key]
-            if isinstance(indices, ndarray):
-                indexSlice = Index(indices)
-                return self.__class__(dataSlice, index=indexSlice)
-            else:
-                return dataSlice
+        values = self.values()
+
+        try:
+            # Check that we can even look for this in the index
+            return values[self.index.indexMap[key]]
+        except KeyError:
+            if isinstance(key, int):
+                return values[key]
+            raise Exception('Requested index not in this series!')
+        except TypeError:
+            # Could not hash item
+            pass
+
+        # is there a case where this would NOT be an ndarray?
+        # need to find an example, I took out the case for now
+
+        dataSlice = values[key]
+        indices = Index(self.index.view(ndarray)[key])
+        return self.__class__(dataSlice, index=indices)
+
+    def get(self, key, missingVal=None):
+        """
+        Returns value occupying requested index, and
+        return missingVal if not in Index
+
+        Parameters
+        ----------
+        key: object
+            Index value looking for
+        missingVal: object, optional
+            Value to return if key not in index
+        """
+        if key in self.index:
+            return ndarray.__getitem__(self, self.index.indexMap[key])
         else:
-            if isinstance(dataSlice, ndarray):
-                return self.__class__(dataSlice)
-            else:
-                return dataSlice    # Just one element
+            return missingVal
 
     def __getslice__(self, i, j):
         """
@@ -295,13 +309,10 @@ class Series(np.ndarray, Picklable, Groupable):
         will have a reference to the original series which could be
         inadvertently changed if the slice were altered (made mutable).
         """
-        newArr = self.view(ndarray)[i:j].copy()
+        newArr = self.values()[i:j].copy()
+        newIndex = self.index[i:j]
 
-        if self.index is not None:
-            newIndex = self.index[i:j]
-            return self.__class__(newArr, index = newIndex)
-        else:
-            return self.__class__(newArr)
+        return self.__class__(newArr, index=newIndex)
 
     def __setitem__(self, key, value):
         """
@@ -310,8 +321,9 @@ class Series(np.ndarray, Picklable, Groupable):
         try:
             loc = self.index.indexMap[key]
             ndarray.__setitem__(self, loc, value)
-        except Exception, e:
-            ndarray.__setitem__(self, key, value)
+        except Exception:
+            values = self.values()
+            values[key] = value
 
     def __setslice__(self, i, j, value):
         """Set slice equal to given value(s)"""
@@ -319,23 +331,21 @@ class Series(np.ndarray, Picklable, Groupable):
 
     def __repr__(self):
         """Clean string representation of a Series"""
-        vals = self.view(ndarray)
+        vals = self.values()
         index = self.index
-        if index is not None and len(index) > 0:
-            if len(index) > 500:
-                head = _seriesRepr(index[:50], vals[:50])
-                tail = _seriesRepr(index[-50:], vals[-50:])
-                return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
-            else:
-                return _seriesRepr(index, vals)
+
+        if len(index) > 500:
+            head = _seriesRepr(index[:50], vals[:50])
+            tail = _seriesRepr(index[-50:], vals[-50:])
+            return head + '\n...\n' + tail + '\nlength: %d' % len(vals)
         else:
-            return 'No index!\n' + ndarray.__repr__(self)
+            return _seriesRepr(index, vals)
 
     def __str__(self):
         return self.__repr__()
 
     def __iter__(self):
-        return iter(self.view(ndarray))
+        return iter(self.values())
 
 #-------------------------------------------------------------------------------
 #   Arithmetic operators
@@ -355,69 +365,50 @@ class Series(np.ndarray, Picklable, Groupable):
 
 #-------------------------------------------------------------------------------
 # Overridden ndarray methods
+    def _ndarray_statistic(self, funcname):
+        arr = self.values()
+        retVal = getattr(arr, funcname)()
+
+        if isnull(retVal):
+            arr = remove_na(arr)
+            retVal = getattr(arr, funcname)()
+
+        return retVal
 
     def sum(self, axis=None, dtype=None, out=None):
         """
         Overridden version of ndarray.sum for Series which excludes
         NaN automatically
         """
-        arr = self.view(ndarray)
-        retVal = arr.sum(axis, dtype, out)
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = arr.sum(axis, dtype, out)
-
-        return retVal
+        return self._ndarray_statistic('sum')
 
     def mean(self, axis=None, dtype=None, out=None):
         """
         Overridden version of ndarray.mean for Series which excludes
         NaN automatically
         """
-        arr = self.view(ndarray)
-        retVal = arr.mean(axis, dtype, out)
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = arr.mean(axis, dtype, out)
-
-        return retVal
+        return self._ndarray_statistic('mean')
 
     def min(self, axis=None, out=None):
         """
         Overridden version of ndarray.min for Series which excludes
         NaN automatically
         """
-        arr = self.view(ndarray)
-        retVal = arr.min(axis, out)
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = arr.min(axis, out)
-
-        return retVal
+        return self._ndarray_statistic('min')
 
     def max(self, axis=None, out=None):
         """
         Overridden version of ndarray.max for Series which excludes
         NaN automatically
         """
-        arr = self.view(ndarray)
-        retVal = arr.max(axis, out)
-
-        if isnull(retVal):
-            arr = remove_na(arr)
-            retVal = arr.max(axis, out)
-
-        return retVal
+        return self._ndarray_statistic('max')
 
     def std(self, axis=None, dtype=None, out=None, ddof=1):
         """
         Overridden version of ndarray.std for Series which excludes
         NaN automatically
         """
-        nona = remove_na(self.view(ndarray))
+        nona = remove_na(self.values())
         if len(nona) < 2:
             return NaN
         return ndarray.std(nona, axis, dtype, out, ddof)
@@ -427,7 +418,7 @@ class Series(np.ndarray, Picklable, Groupable):
         Overridden version of ndarray.var for Series which excludes
         NaN automatically
         """
-        nona = remove_na(self.view(ndarray))
+        nona = remove_na(self.values())
         if len(nona) < 2:
             return NaN
         return ndarray.var(nona, axis, dtype, out, ddof)
@@ -448,11 +439,14 @@ class Series(np.ndarray, Picklable, Groupable):
         """
 
         from scipy.stats import skew
-        nona = remove_na(self.view(ndarray))
+        nona = remove_na(self.values())
+
         if len(nona) < 3:
             return NaN
+
         theSkew = skew(nona, bias=bias)
 
+        # Hack for SciPy < 0.8
         if isinstance(theSkew, ndarray):
             theSkew = theSkew.item()
 
@@ -478,74 +472,40 @@ class Series(np.ndarray, Picklable, Groupable):
         """
         Iterate over (index, value) tuples
         """
-        if self.index is not None:
-            return izip(iter(self.index), iter(self))
-        else:
-            raise Exception('This series has no index!')
-
-    def get(self, key, missingVal=None):
-        """
-        Returns value occupying requested index, and
-        return missingVal if not in Index
-
-        Parameters
-        ----------
-        key: object
-            Index value looking for
-        missingVal: object, optional
-            Value to return if key not in index
-        """
-        if key in self.index:
-            return ndarray.__getitem__(self, self.index.indexMap[key])
-        else:
-            return missingVal
+        return izip(iter(self.index), iter(self))
 
     def append(self, other):
         """
         Concatenate two Series
         """
         newIndex = np.concatenate((self.index, other.index))
-        newValues = np.concatenate((self, other))
-        return self.__class__(newValues, index = newIndex)
 
-    def merge(self, other):
-        """
-        If self is {A}->{B} and other is another mapping of {B}->{C}
-        then returns a new Series that is {A}->{C}
-
-        Parameters
-        ----------
-        other: dict or Series
-
-        Returns
-        -------
-        Series having same index as calling instance, with values from
-        input Series
-        """
-        if isinstance(other, dict):
-            other = Series.fromDict(other)
-        if not isinstance(other, Series):
-            raise Exception('Argument must be a Series!')
-        fillVec, mask = tseries.getMergeVec(self, other.index.indexMap)
-
-        newValues = other.view(np.ndarray).take(fillVec)
-        newValues[-mask] = np.nan
+        # Force overlap check
+        try:
+            newIndex = Index(newIndex)
+        except Exception:
+            raise
 
-        newSer = Series(newValues, index=self.index)
-        return newSer
+        newValues = np.concatenate((self, other))
+        return self.__class__(newValues, index=newIndex)
 
-    def combineFunc(self, other, func):
+    def _combineFunc(self, other, func):
         """
-        Combines this Series with another Series index by index using
-        the given function.
+        Combines this Series using the given function with either
+          * another Series index by index
+          * a scalar value
+          * DataFrame
         """
-        if self.index.equals(other.index):
-            newIndex = self.index
-        else:
+        if isinstance(other, Series):
             newIndex = self.index + other.index
-        newArr = np.empty(len(newIndex), dtype = self.dtype)
-        for i, idx in enumerate(newIndex):
-            newArr[i] = func(self.get(idx, NaN), other.get(idx, NaN))
+
+            newArr = np.empty(len(newIndex), dtype=self.dtype)
+            for i, idx in enumerate(newIndex):
+                newArr[i] = func(self.get(idx, NaN), other.get(idx, NaN))
+        else:
+            newIndex = self.index
+            newArr = func(self.values(), other)
+
         return self.__class__(newArr, index=newIndex)
 
     def combineFirst(self, other):
@@ -560,27 +520,28 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         Series formed as union of
         """
-        if self.index.equals(other.index):
-            newIndex = self.index
-        else:
-            newIndex = self.index + other.index
+        newIndex = self.index + other.index
 
-        this = self.reindex(newIndex)
-        other = other.reindex(newIndex)
-        result = Series(np.where(isnull(this), other, this), index=newIndex)
+        this = self
+        if newIndex is not self.index:
+            # save ourselves the copying in this case
 
+            this = self.reindex(newIndex)
+            other = other.reindex(newIndex)
+
+        result = Series(np.where(isnull(this), other, this), index=newIndex)
         return result
 
-    def argsort(self, axis = 0, kind='quicksort', order=None):
+    def argsort(self, axis=0, kind='quicksort', order=None):
         """
         Overriding numpy's built-in cumsum functionality
         """
-        arr = self.view(ndarray).copy()
+        arr = self.values().copy()
         okLocs = notnull(arr)
         arr[okLocs] = np.argsort(arr[okLocs])
         return self.__class__(arr, index=self.index)
 
-    def cumsum(self, axis = 0, dtype = None, out = None):
+    def cumsum(self, axis=0, dtype=None, out=None):
         """
         Overriding numpy's built-in cumsum functionality
         """
@@ -591,7 +552,7 @@ class Series(np.ndarray, Picklable, Groupable):
         arr[okLocs] = result
         return arr
 
-    def cumprod(self, axis = 0, dtype = None, out = None):
+    def cumprod(self, axis=0, dtype=None, out=None):
         """
         Overriding numpy's built-in cumprod functionality
         """
@@ -600,8 +561,14 @@ class Series(np.ndarray, Picklable, Groupable):
         arr[okLocs] = np.cumprod(arr.view(ndarray)[okLocs])
         return arr
 
+    def median(self):
+        """
+        Return median value of Series
+        """
+        return tseries.median(self.valid())
+
     def copy(self):
-        return self.__class__(self.view(ndarray).copy(), index=self.index)
+        return self.__class__(self.values().copy(), index=self.index)
 
     def corr(self, other):
         """
@@ -615,8 +582,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         float (the correlation coefficient)
         """
-        commonIdx = list(set(remove_na(self).index) &
-                         set(remove_na(other).index))
+        commonIdx = remove_na(self).index.intersection(remove_na(other).index)
 
         if len(commonIdx) == 0:
             return NaN
@@ -634,22 +600,17 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         int (# obs)
         """
-        return np.isfinite(self.view(ndarray)).sum()
+        return notnull(self.values()).sum()
 
-    def median(self):
+    def sort(self, axis=0, kind='quicksort', order=None):
         """
-        Return median value of Series
+        Overridden NumPy sort, taking care with missing values
         """
-        selfExNaN = remove_na(self.view(ndarray))
-        med = np.median(selfExNaN)
-        return med
-
-    def sort(self, axis=0, kind='quicksort', order=None):
         sortedSeries = self.order(missingAtEnd=True)
         self[:] = sortedSeries
         self.index = sortedSeries.index
 
-    def order(self, missingAtEnd = True):
+    def order(self, missingAtEnd=True):
         """
         Sorts Series object, by value, maintaining index-value object
 
@@ -664,7 +625,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         SORTED series by values (indices correspond to the appropriate values)
         """
-        arr = self.view(ndarray)
+        arr = self.values()
         sortedIdx = np.empty(len(self), dtype=np.int32)
 
         bad = isnull(arr)
@@ -696,7 +657,7 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         Series with same index
         """
-        return Series([func(x) for x in self], index = self.index)
+        return Series([func(x) for x in self], index=self.index)
 
     def plot(self, label=None, kind='line', **kwds):
         """
@@ -730,20 +691,9 @@ class Series(np.ndarray, Picklable, Groupable):
             kwds = kwds.copy()
             kwds['label'] = label
 
-        # I can't get this to work
-
-        #fig = pylab.gcf()
-        #fig.autofmt_xdate(bottom=0.1)
-
-        #ax = fig.gca()
-        #if not ax.has_data():
-            #ax = fig.add_subplot(111)
-
-        #ax.plot(self.index, self, **kwds)
-
         pylab.plot(self.index, self, **kwds)
 
-    def toCSV(self, path=None):
+    def toCSV(self, path):
         """
         Write the Series to a CSV file
 
@@ -752,18 +702,12 @@ class Series(np.ndarray, Picklable, Groupable):
         path: string or None
             Output filepath. If None, write to stdout
         """
-        if not path:
-            import sys
-            f = sys.stdout
-        else:
-            f = open(path, 'wb')
+        f = open(path, 'wb')
+
         for idx, value in self.iteritems():
             f.write(str(idx) + ',' + str(value) + ',\n')
-        if path is not None:
-            f.close()
 
-    def toDict(self):
-        return dict(self.iteritems())
+        f.close()
 
     def cap(self, value):
         """Return copy of series with values above given value truncated"""
@@ -834,49 +778,23 @@ class Series(np.ndarray, Picklable, Groupable):
             if periods > 0:
                 newIndex = self.index[periods:]
                 newValues = np.array(self)[:-periods]
-            else:
+            elif periods < 0:
                 newIndex = self.index[:periods]
                 newValues = np.array(self)[-periods:]
+            else:
+                newValues = self.values().copy()
+                newIndex = self.index
+
             return self.__class__(newValues, index=newIndex)
         else:
             offset = periods * offset
             newIndex = Index([idx + offset for idx in self.index])
-            return self.__class__(self, index=newIndex)
-
-    def slice(self, before, after):
-        """
-
-        """
-
-        import bisect
 
-        if before is not None:
-            binsearch = bisect.bisect_left(self.index, before)
-            cur = self.index[binsearch]
-            next = self.index[min(binsearch + 1, len(self.index) - 1)]
-            leftDate = cur if cur >= before else next
-        else:
-            leftDate = self.index[0]
-
-        if after is not None:
-            if after < self.index[-1]:
-                binsearch = bisect.bisect_right(self.index, after)
-                cur = self.index[binsearch]
-                prior = self.index[max(binsearch - 1, 0)]
-                rightDate = cur if cur <= after else prior
-            else:
-                rightDate = self.index[-1]
-        else:
-            rightDate = self.index[-1]
-
-        beg_slice = max(0, self.index.indexMap[leftDate])
-        end_slice = min(len(self.index), self.index.indexMap[rightDate] + 1)
-
-        return self[beg_slice:end_slice]
+            return self.__class__(self, index=newIndex)
 
     def truncate(self, before=None, after=None):
-        """Function truncate a TimeSeries before and/or after some
-        particular dates.
+        """Function truncate a sorted TimeSeries before and/or after
+        some particular dates.
 
         Parameters
         ----------
@@ -894,14 +812,29 @@ class Series(np.ndarray, Picklable, Groupable):
         -------
         TimeSeries
         """
-        before = datetools.to_datetime(before)
-        after = datetools.to_datetime(after)
+        before = arg_before = datetools.to_datetime(before)
+        after = arg_after = datetools.to_datetime(after)
 
         if before is None:
-            before = min(self.index)
+            before = self.index[0]
+        elif before not in self.index:
+            loc = self.index.searchsorted(before, side='left')
+            before = self.index[loc]
+
         if after is None:
-            after = max(self.index)
-        return self.slice(before, after)
+            after = self.index[-1]
+        elif after not in self.index:
+            loc = self.index.searchsorted(after, side='right') - 1
+            loc = loc if loc < len(self.index) else -1
+            after = self.index[loc]
+
+        beg_slice = self.index.indexMap[before]
+        end_slice = self.index.indexMap[after] + 1
+
+        return self[beg_slice:end_slice]
+
+    def slice(self, before, after):
+        return self.truncate(before=before, after=after)
 
     def asOf(self, date):
         """
@@ -1009,7 +942,7 @@ class Series(np.ndarray, Picklable, Groupable):
         else:
             inds = np.arange(len(self))
 
-        values = self.view(np.ndarray)
+        values = self.values()
 
         invalid = isnull(values)
         valid = -invalid
@@ -1025,6 +958,32 @@ class Series(np.ndarray, Picklable, Groupable):
 
         return Series(result, index=self.index)
 
+    def merge(self, other):
+        """
+        If self is {A}->{B} and other is another mapping of {B}->{C}
+        then returns a new Series that is {A}->{C}
+
+        Parameters
+        ----------
+        other: dict or Series
+
+        Returns
+        -------
+        Series having same index as calling instance, with values from
+        input Series
+        """
+        if isinstance(other, dict):
+            other = Series.fromDict(other)
+        if not isinstance(other, Series):
+            raise Exception('Argument must be a Series!')
+        fillVec, mask = tseries.getMergeVec(self, other.index.indexMap)
+
+        newValues = other.view(np.ndarray).take(fillVec)
+        newValues[-mask] = np.nan
+
+        newSer = Series(newValues, index=self.index)
+        return newSer
+
     def reindex(self, newIndex, fillMethod=None):
         """Overloaded version of reindex for TimeSeries. Supports filling
         with values based on new index.
@@ -1087,7 +1046,7 @@ class Series(np.ndarray, Picklable, Groupable):
         fillVec, mask = tseries.getFillVec(self.index, newIndex, oldMap,
                                            newMap, kind=fillMethod)
 
-        newValues = self.view(ndarray).take(fillVec)
+        newValues = self.values().take(fillVec)
         newValues[-mask] = NaN
 
         return self.__class__(newValues, index = newIndex)
diff --git a/pandas/core/tests/common.py b/pandas/core/tests/common.py
index c47aa4a8a..d227eba6c 100644
--- a/pandas/core/tests/common.py
+++ b/pandas/core/tests/common.py
@@ -30,7 +30,7 @@ def assert_almost_equal(a, b):
         np.testing.assert_equal(len(a), len(b))
         for i in xrange(len(a)):
             assert_almost_equal(a[i], b[i])
-        return
+        return True
 
     err_msg = lambda a, b: 'expected %.5f but got %.5f' % (a, b)
 
@@ -46,15 +46,23 @@ def assert_almost_equal(a, b):
         np.testing.assert_almost_equal(
             1, a/b, decimal=5, err_msg=err_msg(a, b), verbose=False)
 
-def assert_dict_equal(a, b):
+def is_sorted(seq):
+    return assert_almost_equal(seq, np.sort(np.array(seq)))
+
+def assert_dict_equal(a, b, compare_keys=True):
     a_keys = frozenset(a.keys())
     b_keys = frozenset(b.keys())
 
-    assert(a_keys == b_keys)
+    if compare_keys:
+        assert(a_keys == b_keys)
 
     for k in a_keys:
         assert_almost_equal(a[k], b[k])
 
+def assert_series_equal(left, right):
+    assert(np.array_equal(left, right))
+    assert(np.array_equal(left.index, right.index))
+
 def assert_contains_all(iterable, dic):
     for k in iterable:
         assert(k in dic)
diff --git a/pandas/core/tests/test_datetools.py b/pandas/core/tests/test_datetools.py
index 4f05a671e..6146b5f87 100644
--- a/pandas/core/tests/test_datetools.py
+++ b/pandas/core/tests/test_datetools.py
@@ -18,7 +18,7 @@ def testOle2datetime():
 def testTto_datetime1():
     actual = datetools.to_datetime(datetime(2008, 1, 15))
     assert actual == datetime(2008, 1, 15)
-    
+
 def testTto_datetime2():
     actual = datetools.to_datetime('20080115')
     assert actual == datetime(2008, 1, 15)
@@ -26,7 +26,7 @@ def testTto_datetime2():
 def testNormalize_date():
     actual = datetools.normalize_date(datetime(2007, 10, 1, 1, 12, 5, 10))
     assert actual == datetime(2007, 10, 1)
-    
+
 #####
 ### DateOffset Tests
 #####
@@ -36,122 +36,122 @@ def myAssert(actual, expected):
 
 def testEQ():
     myAssert(datetools.BDay(2), datetools.BDay(2))
-    
+
 def testHash():
     myAssert(datetools.BDay(2).__hash__(), datetools.BDay(2).__hash__())
-    
+
 def testCall():
     myAssert(BDay(2)(datetime(2008, 1, 1)), datetime(2008, 1, 3))
-    
+
 def testRAdd():
     myAssert(datetime(2008, 1, 1) + BDay(2), BDay(2) + datetime(2008, 1, 1))
 
 def testSub():
     myAssert(datetime(2008, 1, 1) - BDay(2),  datetime(2008, 1, 1) + BDay(-2))
-    
+
 def testRSub():
     myAssert(datetime(2008, 1, 1) - BDay(2), BDay(2) - datetime(2008, 1, 1))
-    
+
 def testMult1():
     myAssert(datetime(2008, 1, 1) + 10*BDay(), datetime(2008, 1, 1) + BDay(10))
 
-def testMult2():    
-    myAssert(datetime(2008, 1, 1) + (-5*BDay(-10)), 
+def testMult2():
+    myAssert(datetime(2008, 1, 1) + (-5*BDay(-10)),
              datetime(2008, 1, 1) + BDay(50))
 
-    
+
 def testRollback1():
     myAssert(BDay(10).rollback(datetime(2008, 1, 1)), datetime(2008, 1, 1))
-    
+
 def testRollback2():
     myAssert(BDay(10).rollback(datetime(2008, 1, 5)), datetime(2008, 1, 4))
-    
+
 def testRollforward1():
     myAssert(BDay(10).rollforward(datetime(2008, 1, 1)), datetime(2008, 1, 1))
-    
+
 def testRollforward2():
     myAssert(BDay(10).rollforward(datetime(2008, 1, 5)), datetime(2008, 1, 7))
 
 def assertOnOffset(offset, date, expected):
     actual = offset.onOffset(date)
     assert actual == expected
-    
+
 def testOnOffset():
-    
+
     tests = [(BDay(), datetime(2008, 1, 1), True),
              (BDay(), datetime(2008, 1, 5), False),
-         
+
              (BMonthEnd(), datetime(2007, 12, 31), True),
              (BMonthEnd(), datetime(2008, 1, 1), False),
-         
+
              (BQuarterEnd(1, startingMonth=1), datetime(2008, 1, 31), True),
              (BQuarterEnd(1, startingMonth=1), datetime(2007, 12, 31), False),
              (BQuarterEnd(1, startingMonth=1), datetime(2008, 2, 29), False),
-             (BQuarterEnd(1, startingMonth=1), datetime(2007, 3, 30), False), 
-             (BQuarterEnd(1, startingMonth=1), datetime(2007, 3, 31), False), 
-             (BQuarterEnd(1, startingMonth=1), datetime(2008, 4, 30), True), 
-             (BQuarterEnd(1, startingMonth=1), datetime(2008, 5, 30), False), 
-             (BQuarterEnd(1, startingMonth=1), datetime(2007, 6, 29), False), 
-             (BQuarterEnd(1, startingMonth=1), datetime(2007, 6, 30), False), 
-             
+             (BQuarterEnd(1, startingMonth=1), datetime(2007, 3, 30), False),
+             (BQuarterEnd(1, startingMonth=1), datetime(2007, 3, 31), False),
+             (BQuarterEnd(1, startingMonth=1), datetime(2008, 4, 30), True),
+             (BQuarterEnd(1, startingMonth=1), datetime(2008, 5, 30), False),
+             (BQuarterEnd(1, startingMonth=1), datetime(2007, 6, 29), False),
+             (BQuarterEnd(1, startingMonth=1), datetime(2007, 6, 30), False),
+
              (BQuarterEnd(1, startingMonth=2), datetime(2008, 1, 31), False),
              (BQuarterEnd(1, startingMonth=2), datetime(2007, 12, 31), False),
-             (BQuarterEnd(1, startingMonth=2), datetime(2008, 2, 29), True), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2007, 3, 30), False), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2007, 3, 31), False), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2008, 4, 30), False), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), True), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2007, 6, 29), False), 
-             (BQuarterEnd(1, startingMonth=2), datetime(2007, 6, 30), False), 
-         
+             (BQuarterEnd(1, startingMonth=2), datetime(2008, 2, 29), True),
+             (BQuarterEnd(1, startingMonth=2), datetime(2007, 3, 30), False),
+             (BQuarterEnd(1, startingMonth=2), datetime(2007, 3, 31), False),
+             (BQuarterEnd(1, startingMonth=2), datetime(2008, 4, 30), False),
+             (BQuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), True),
+             (BQuarterEnd(1, startingMonth=2), datetime(2007, 6, 29), False),
+             (BQuarterEnd(1, startingMonth=2), datetime(2007, 6, 30), False),
+
              (BQuarterEnd(1, startingMonth=3), datetime(2008, 1, 31), False),
              (BQuarterEnd(1, startingMonth=3), datetime(2007, 12, 31), True),
              (BQuarterEnd(1, startingMonth=3), datetime(2008, 2, 29), False),
-             (BQuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), True), 
-             (BQuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False), 
-             (BQuarterEnd(1, startingMonth=3), datetime(2008, 4, 30), False), 
+             (BQuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), True),
+             (BQuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False),
+             (BQuarterEnd(1, startingMonth=3), datetime(2008, 4, 30), False),
              (BQuarterEnd(1, startingMonth=3), datetime(2008, 5, 30), False),
-             (BQuarterEnd(1, startingMonth=3), datetime(2007, 6, 29), True), 
-             (BQuarterEnd(1, startingMonth=3), datetime(2007, 6, 30), False), 
-             
+             (BQuarterEnd(1, startingMonth=3), datetime(2007, 6, 29), True),
+             (BQuarterEnd(1, startingMonth=3), datetime(2007, 6, 30), False),
+
              (BYearEnd(), datetime(2007, 12, 31), True),
              (BYearEnd(), datetime(2008, 1, 1), False),
              (BYearEnd(), datetime(2006, 12, 31), False),
              (BYearEnd(), datetime(2006, 12, 29), True),
-             
+
              (MonthEnd(), datetime(2007, 3, 30), False),
              (MonthEnd(), datetime(2007, 3, 31), True),
 
              #(QuarterEnd(1, startingMonth=1), datetime(2008, 1, 31), True),
              #(QuarterEnd(1, startingMonth=1), datetime(2007, 12, 31), False),
              #(QuarterEnd(1, startingMonth=1), datetime(2008, 2, 29), False),
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False), 
-             #(QuarterEnd(1, startingMonth=1), datetime(2008, 4, 30), True), 
-             #(QuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), False), 
-             
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False),
+             #(QuarterEnd(1, startingMonth=1), datetime(2008, 4, 30), True),
+             #(QuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), False),
+
              #(QuarterEnd(1, startingMonth=2), datetime(2008, 1, 31), False),
              #(QuarterEnd(1, startingMonth=2), datetime(2007, 12, 31), False),
-             #(QuarterEnd(1, startingMonth=2), datetime(2008, 2, 29), True), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False), 
-             #(QuarterEnd(1, startingMonth=2), datetime(2008, 4, 30), False), 
-             #(QuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), True), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), False), 
-         
+             #(QuarterEnd(1, startingMonth=2), datetime(2008, 2, 29), True),
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), False),
+             #(QuarterEnd(1, startingMonth=2), datetime(2008, 4, 30), False),
+             #(QuarterEnd(1, startingMonth=2), datetime(2008, 5, 30), True),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), False),
+
              #(QuarterEnd(1, startingMonth=3), datetime(2008, 1, 31), False),
              #(QuarterEnd(1, startingMonth=3), datetime(2007, 12, 31), False),
              #(QuarterEnd(1, startingMonth=3), datetime(2008, 2, 29), False),
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), True), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 4, 30), False), 
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 30), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2007, 3, 31), True),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 4, 30), False),
              #(QuarterEnd(1, startingMonth=3), datetime(2008, 5, 30), False),
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False), 
-             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), True), 
-             
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 29), False),
+             #(QuarterEnd(1, startingMonth=3), datetime(2008, 6, 30), True),
+
              (datetools.Week(dayOfWeek=0), datetime(2008, 1, 1), False),
              (datetools.Week(dayOfWeek=0), datetime(2008, 1, 2), False),
              (datetools.Week(dayOfWeek=0), datetime(2008, 1, 3), False),
@@ -183,7 +183,7 @@ def testOnOffset():
              (datetools.Week(dayOfWeek=3), datetime(2008, 1, 5), False),
              (datetools.Week(dayOfWeek=3), datetime(2008, 1, 6), False),
              (datetools.Week(dayOfWeek=3), datetime(2008, 1, 7), False),
-             
+
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 1), False),
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 2), False),
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 3), False),
@@ -191,7 +191,7 @@ def testOnOffset():
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 5), False),
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 6), False),
              (datetools.Week(dayOfWeek=4), datetime(2008, 1, 7), False),
-             
+
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 1), False),
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 2), False),
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 3), False),
@@ -199,7 +199,7 @@ def testOnOffset():
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 5), True),
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 6), False),
              (datetools.Week(dayOfWeek=5), datetime(2008, 1, 7), False),
-             
+
              (datetools.Week(dayOfWeek=6), datetime(2008, 1, 1), False),
              (datetools.Week(dayOfWeek=6), datetime(2008, 1, 2), False),
              (datetools.Week(dayOfWeek=6), datetime(2008, 1, 3), False),
@@ -210,8 +210,7 @@ def testOnOffset():
          ]
 
     for offset, date, expected in tests:
-        yield assertOnOffset, offset, date, expected
-
+        assertOnOffset(offset, date, expected)
 
 def assertEq(dateOffset, baseDate, expected):
     actual = dateOffset + baseDate
@@ -219,21 +218,21 @@ def assertEq(dateOffset, baseDate, expected):
 
 def testBday():
     tests = []
-    
+
     tests.append((datetools.bday,
                   {datetime(2008, 1, 1): datetime(2008, 1, 2),
                    datetime(2008, 1, 4): datetime(2008, 1, 7),
                    datetime(2008, 1, 5): datetime(2008, 1, 7),
                    datetime(2008, 1, 6): datetime(2008, 1, 7),
                    datetime(2008, 1, 7): datetime(2008, 1, 8)}))
-    
+
     tests.append((2*datetools.bday,
                   {datetime(2008, 1, 1): datetime(2008, 1, 3),
                    datetime(2008, 1, 4): datetime(2008, 1, 8),
                    datetime(2008, 1, 5): datetime(2008, 1, 8),
                    datetime(2008, 1, 6): datetime(2008, 1, 8),
                    datetime(2008, 1, 7): datetime(2008, 1, 9)}))
-    
+
     tests.append((-datetools.bday,
                   {datetime(2008, 1, 1): datetime(2007, 12, 31),
                    datetime(2008, 1, 4): datetime(2008, 1, 3),
@@ -260,54 +259,54 @@ def testBday():
 
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
-    
+            assertEq(dateOffset, baseDate, expected)
+
 def testWeek():
     tests = []
-    
+
     tests.append((datetools.week, # not business week
                   {datetime(2008, 1, 1): datetime(2008, 1, 8),
                    datetime(2008, 1, 4): datetime(2008, 1, 11),
                    datetime(2008, 1, 5): datetime(2008, 1, 12),
                    datetime(2008, 1, 6): datetime(2008, 1, 13),
                    datetime(2008, 1, 7): datetime(2008, 1, 14)}))
-    
+
     tests.append((datetools.Week(dayOfWeek=0), # Mon
                   {datetime(2007, 12, 31): datetime(2008, 1, 7),
                    datetime(2008, 1, 4): datetime(2008, 1, 7),
                    datetime(2008, 1, 5): datetime(2008, 1, 7),
                    datetime(2008, 1, 6): datetime(2008, 1, 7),
                    datetime(2008, 1, 7): datetime(2008, 1, 14)}))
-    
+
     tests.append((datetools.Week(0, dayOfWeek=0), # n=0 -> roll forward. Mon
                   {datetime(2007, 12, 31): datetime(2007, 12, 31),
                    datetime(2008, 1, 4): datetime(2008, 1, 7),
                    datetime(2008, 1, 5): datetime(2008, 1, 7),
                    datetime(2008, 1, 6): datetime(2008, 1, 7),
                    datetime(2008, 1, 7): datetime(2008, 1, 7)}))
-    
+
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
-            
-def testBMonthEnd():        
+            assertEq(dateOffset, baseDate, expected)
+
+def testBMonthEnd():
     tests = []
-    
-    tests.append((datetools.BMonthEnd(), 
-                 {datetime(2008, 1, 1): datetime(2008, 1, 31), 
+
+    tests.append((datetools.BMonthEnd(),
+                 {datetime(2008, 1, 1): datetime(2008, 1, 31),
                   datetime(2008, 1, 31): datetime(2008, 2, 29),
-                  datetime(2006, 12, 29): datetime(2007, 1, 31), 
+                  datetime(2006, 12, 29): datetime(2007, 1, 31),
                   datetime(2006, 12, 31): datetime(2007, 1, 31),
-                  datetime(2007, 1, 1): datetime(2007, 1, 31), 
+                  datetime(2007, 1, 1): datetime(2007, 1, 31),
                   datetime(2006, 12, 1): datetime(2006, 12, 29)}))
-        
-    tests.append((datetools.BMonthEnd(0), 
+
+    tests.append((datetools.BMonthEnd(0),
                   {datetime(2008, 1, 1): datetime(2008, 1, 31),
                    datetime(2008, 1, 31): datetime(2008, 1, 31),
                    datetime(2006, 12, 29): datetime(2006, 12, 29),
                    datetime(2006, 12, 31): datetime(2007, 1, 31),
                    datetime(2007, 1, 1): datetime(2007, 1, 31)}))
-    
+
     tests.append((datetools.BMonthEnd(2),
                  {datetime(2008, 1, 1): datetime(2008, 2, 29),
                   datetime(2008, 1, 31): datetime(2008, 3, 31),
@@ -323,15 +322,15 @@ def testBMonthEnd():
                   datetime(2006, 12, 29): datetime(2006, 11, 30),
                   datetime(2006, 12, 30): datetime(2006, 12, 29),
                   datetime(2007, 1, 1): datetime(2006, 12, 29)}))
-        
+
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
-  
+            assertEq(dateOffset, baseDate, expected)
+
 
 def testBYearEnd():
     tests = []
-    
+
     tests.append((datetools.BYearEnd(),
                   {datetime(2008, 1, 1): datetime(2008, 12, 31),
                    datetime(2008, 6, 30): datetime(2008, 12, 31),
@@ -357,14 +356,14 @@ def testBYearEnd():
                   {datetime(2007, 1, 1): datetime(2005, 12, 30),
                    datetime(2008, 6, 30): datetime(2006, 12, 29),
                    datetime(2008, 12, 31): datetime(2006, 12, 29),}))
-    
+
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
+            assertEq(dateOffset, baseDate, expected)
 
 def testYearBegin():
     tests = []
-    
+
     tests.append((datetools.YearBegin(),
                   {datetime(2008, 1, 1): datetime(2009, 1, 1),
                    datetime(2008, 6, 30): datetime(2009, 1, 1),
@@ -392,67 +391,67 @@ def testYearBegin():
                   {datetime(2007, 1, 1): datetime(2005, 1, 1),
                    datetime(2008, 6, 30): datetime(2007, 1, 1),
                    datetime(2008, 12, 31): datetime(2007, 1, 1),}))
-    
+
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected            
-            
-            
+            assertEq(dateOffset, baseDate, expected)
+
+
 def testBQuarterEnd():
     tests = []
-    
+
     tests.append((datetools.BQuarterEnd(),
                   {datetime(2008, 1, 1): datetime(2008, 3, 31),
                    datetime(2008, 1, 31): datetime(2008, 3, 31),
                    datetime(2008, 2, 15): datetime(2008, 3, 31),
-                   datetime(2008, 2, 29): datetime(2008, 3, 31),        
+                   datetime(2008, 2, 29): datetime(2008, 3, 31),
                    datetime(2008, 3, 15): datetime(2008, 3, 31),
                    datetime(2008, 3, 31): datetime(2008, 6, 30),
                    datetime(2008, 4, 15): datetime(2008, 6, 30),
                    datetime(2008, 4, 30): datetime(2008, 6, 30),}))
-    
+
     tests.append((datetools.BQuarterEnd(n = 0),
                   {datetime(2008, 1, 1): datetime(2008, 3, 31),
                    datetime(2008, 1, 31): datetime(2008, 3, 31),
                    datetime(2008, 2, 15): datetime(2008, 3, 31),
-                   datetime(2008, 2, 29): datetime(2008, 3, 31),        
+                   datetime(2008, 2, 29): datetime(2008, 3, 31),
                    datetime(2008, 3, 15): datetime(2008, 3, 31),
                    datetime(2008, 3, 31): datetime(2008, 3, 31),
                    datetime(2008, 4, 15): datetime(2008, 6, 30),
                    datetime(2008, 4, 30): datetime(2008, 6, 30),}))
-    
+
     tests.append((datetools.BQuarterEnd(n = -1),
                   {datetime(2008, 1, 1): datetime(2007, 12, 31),
                    datetime(2008, 1, 31): datetime(2007, 12, 31),
                    datetime(2008, 2, 15): datetime(2007, 12, 31),
-                   datetime(2008, 2, 29): datetime(2007, 12, 31),        
+                   datetime(2008, 2, 29): datetime(2007, 12, 31),
                    datetime(2008, 3, 15): datetime(2007, 12, 31),
                    datetime(2008, 3, 31): datetime(2007, 12, 31),
                    datetime(2008, 4, 15): datetime(2008, 3, 31),
                   datetime(2008, 4, 30): datetime(2008, 3, 31),}))
-    
+
     tests.append((datetools.BQuarterEnd(n = 2),
                   {datetime(2008, 1, 1): datetime(2008, 6, 30),
                    datetime(2008, 1, 31): datetime(2008, 6, 30),
                    datetime(2008, 2, 15): datetime(2008, 6, 30),
-                   datetime(2008, 2, 29): datetime(2008, 6, 30),        
+                   datetime(2008, 2, 29): datetime(2008, 6, 30),
                    datetime(2008, 3, 15): datetime(2008, 6, 30),
                    datetime(2008, 3, 31): datetime(2008, 9, 30),
                    datetime(2008, 4, 15): datetime(2008, 9, 30),
                    datetime(2008, 4, 30): datetime(2008, 9, 30),}))
-    
+
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
+            assertEq(dateOffset, baseDate, expected)
 
 def testBQuarterEndOffsets():
     tests = []
-    
+
     tests.append((datetools.BQuarterEnd(startingMonth=1),
                   {datetime(2008, 1, 1): datetime(2008, 1, 31),
                    datetime(2008, 1, 31): datetime(2008, 4, 30),
                    datetime(2008, 2, 15): datetime(2008, 4, 30),
-                   datetime(2008, 2, 29): datetime(2008, 4, 30),        
+                   datetime(2008, 2, 29): datetime(2008, 4, 30),
                    datetime(2008, 3, 15): datetime(2008, 4, 30),
                    datetime(2008, 3, 31): datetime(2008, 4, 30),
                    datetime(2008, 4, 15): datetime(2008, 4, 30),
@@ -462,36 +461,36 @@ def testBQuarterEndOffsets():
                   {datetime(2008, 1, 1): datetime(2008, 2, 29),
                    datetime(2008, 1, 31): datetime(2008, 2, 29),
                    datetime(2008, 2, 15): datetime(2008, 2, 29),
-                   datetime(2008, 2, 29): datetime(2008, 5, 30),        
+                   datetime(2008, 2, 29): datetime(2008, 5, 30),
                    datetime(2008, 3, 15): datetime(2008, 5, 30),
                    datetime(2008, 3, 31): datetime(2008, 5, 30),
                    datetime(2008, 4, 15): datetime(2008, 5, 30),
                    datetime(2008, 4, 30): datetime(2008, 5, 30),}))
-    
+
     tests.append((datetools.BQuarterEnd(startingMonth=1, n=0),
                   {datetime(2008, 1, 1): datetime(2008, 1, 31),
                    datetime(2008, 1, 31): datetime(2008, 1, 31),
                    datetime(2008, 2, 15): datetime(2008, 4, 30),
-                   datetime(2008, 2, 29): datetime(2008, 4, 30),        
+                   datetime(2008, 2, 29): datetime(2008, 4, 30),
                    datetime(2008, 3, 15): datetime(2008, 4, 30),
                    datetime(2008, 3, 31): datetime(2008, 4, 30),
                    datetime(2008, 4, 15): datetime(2008, 4, 30),
                    datetime(2008, 4, 30): datetime(2008, 4, 30),}))
-     
+
     tests.append((datetools.BQuarterEnd(startingMonth=1, n=-1),
                   {datetime(2008, 1, 1): datetime(2007, 10, 31),
                    datetime(2008, 1, 31): datetime(2007, 10, 31),
                    datetime(2008, 2, 15): datetime(2008, 1, 31),
-                   datetime(2008, 2, 29): datetime(2008, 1, 31),        
+                   datetime(2008, 2, 29): datetime(2008, 1, 31),
                    datetime(2008, 3, 15): datetime(2008, 1, 31),
                    datetime(2008, 3, 31): datetime(2008, 1, 31),
                    datetime(2008, 4, 15): datetime(2008, 1, 31),
                    datetime(2008, 4, 30): datetime(2008, 1, 31),}))
-    
+
     tests.append((datetools.BQuarterEnd(startingMonth=1, n=2),
                   {datetime(2008, 1, 31): datetime(2008, 7, 31),
                    datetime(2008, 2, 15): datetime(2008, 7, 31),
-                   datetime(2008, 2, 29): datetime(2008, 7, 31),        
+                   datetime(2008, 2, 29): datetime(2008, 7, 31),
                    datetime(2008, 3, 15): datetime(2008, 7, 31),
                    datetime(2008, 3, 31): datetime(2008, 7, 31),
                    datetime(2008, 4, 15): datetime(2008, 7, 31),
@@ -499,36 +498,34 @@ def testBQuarterEndOffsets():
 
     for dateOffset, cases in tests:
         for baseDate, expected in cases.iteritems():
-            yield assertEq, dateOffset, baseDate, expected
-
+            assertEq(dateOffset, baseDate, expected)
 
-        
 ####
 ## XDateRange Tests
 ####
 def eqXDateRange(kwargs, expected):
     actual = list(XDateRange(**kwargs))
     assert actual == expected
-    
-def testXDateRange1():    
+
+def testXDateRange1():
     eqXDateRange(dict(fromDate = datetime(2009, 3, 25),
-                      nPeriods = 2), 
+                      nPeriods = 2),
                  [datetime(2009, 3, 25), datetime(2009, 3, 26)])
 
-def testXDateRange2():    
+def testXDateRange2():
     eqXDateRange(dict(fromDate = datetime(2008, 1, 1),
                       toDate = datetime(2008, 1, 3)),
                  [datetime(2008, 1, 1),
                   datetime(2008, 1, 2),
                   datetime(2008, 1, 3)])
-    
-def testXDateRange3():    
+
+def testXDateRange3():
     eqXDateRange(dict(fromDate = datetime(2008, 1, 5),
                       toDate = datetime(2008, 1, 6)),
                  [])
-    
 
-    
+
+
 # DateRange test
 
 def assertEqual(a, b):
@@ -539,7 +536,7 @@ def testDateRange1():
     toDate = datetime(2009, 5, 13)
     dr = DateRange(toDate=toDate, periods=20)
     firstDate = toDate - 19 * datetools.bday
-    
+
     assert len(dr) == 20
     assert dr[0] == firstDate
     assert dr[-1] == toDate
diff --git a/pandas/core/tests/test_index.py b/pandas/core/tests/test_index.py
index 846385921..babd1570c 100644
--- a/pandas/core/tests/test_index.py
+++ b/pandas/core/tests/test_index.py
@@ -1,4 +1,4 @@
-from datetime import datetime
+from datetime import datetime, timedelta
 from pandas.core.index import Index
 import pandas.core.tests.common as common
 import pandas.lib.tseries as tseries
@@ -10,7 +10,7 @@ import unittest
 class TestIndex(unittest.TestCase):
     def setUp(self):
         self.strIndex = common.makeStringIndex(100)
-        self.dateIndex = common.makeStringIndex(100)
+        self.dateIndex = common.makeDateIndex(100)
         self.intIndex = common.makeIntIndex(100)
 
     def test_duplicates(self):
@@ -34,6 +34,12 @@ class TestIndex(unittest.TestCase):
         common.assert_contains_all(arr, index)
         self.assert_(np.array_equal(self.strIndex, index))
 
+        # corner case
+        self.assertRaises(Exception, Index, 0)
+
+        arr = np.array(5.)
+        self.assertRaises(Exception, arr.view, Index)
+
     def test_equals(self):
         # same
         self.assert_(Index(['a', 'b', 'c']).equals(Index(['a', 'b', 'c'])))
@@ -44,8 +50,21 @@ class TestIndex(unittest.TestCase):
         # same length, different values
         self.assertFalse(Index(['a', 'b', 'c']).equals(Index(['a', 'b', 'd'])))
 
+        # Must also be an Index
+        self.assertFalse(Index(['a', 'b', 'c']).equals(['a', 'b', 'c']))
+
+    def test_md5(self):
+        self.strIndex._md5
+        self.dateIndex._md5
+        self.intIndex._md5
+
     def test_asOfDate(self):
-        pass
+        d = self.dateIndex[0]
+        self.assert_(self.dateIndex.asOfDate(d) is d)
+        self.assert_(self.dateIndex.asOfDate(d - timedelta(1)) is None)
+
+        d = self.dateIndex[-1]
+        self.assert_(self.dateIndex.asOfDate(d + timedelta(1)) is d)
 
     def test_argsort(self):
         result = self.strIndex.argsort()
@@ -91,6 +110,9 @@ class TestIndex(unittest.TestCase):
         common.assert_contains_all(self.strIndex, secondCat.indexMap)
         common.assert_contains_all(self.dateIndex, firstCat.indexMap)
 
+        # this is valid too
+        shifted = self.dateIndex + timedelta(1)
+
     def test_intersection(self):
         first = self.strIndex[:20]
         second = self.strIndex[:10]
@@ -98,6 +120,13 @@ class TestIndex(unittest.TestCase):
 
         self.assert_(common.equalContents(intersect, second))
 
+        # Corner cases
+        inter = first.intersection(first)
+        self.assert_(inter is first)
+
+        # non-iterable input
+        self.assertRaises(Exception, first.intersection, 0.5)
+
     def test_union(self):
         first = self.strIndex[5:20]
         second = self.strIndex[:10]
@@ -105,6 +134,16 @@ class TestIndex(unittest.TestCase):
         union = first.union(second)
         self.assert_(common.equalContents(union, everything))
 
+        # Corner cases
+        union = first.union(first)
+        self.assert_(union is first)
+
+        union = first.union([])
+        self.assert_(union is first)
+
+        # non-iterable input
+        self.assertRaises(Exception, first.union, 0.5)
+
     def test_diff(self):
         first = self.strIndex[5:20]
         second = self.strIndex[:10]
@@ -113,6 +152,12 @@ class TestIndex(unittest.TestCase):
 
         self.assert_(common.equalContents(result, answer))
 
+        diff = first.diff(first)
+        self.assert_(len(diff) == 0)
+
+        # non-iterable input
+        self.assertRaises(Exception, first.diff, 0.5)
+
     def test_pickle(self):
         def testit(index):
             f = open('tmp', 'wb')
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index 74632b4de..093a61c10 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -1,11 +1,17 @@
+# pylint: disable-msg=E1101,W0612
+
 from copy import deepcopy
+from cStringIO import StringIO
+from datetime import datetime, timedelta
 import cPickle as pickle
 import os
+import operator
 import unittest
 
 import numpy as np
 
-from pandas.core.series import Series
+from pandas.core.api import Index, Series, TimeSeries, DataFrame
+import pandas.core.datetools as datetools
 import pandas.core.tests.common as common
 
 #-------------------------------------------------------------------------------
@@ -18,20 +24,113 @@ class TestSeries(unittest.TestCase):
         self.objSeries = common.makeObjectSeries()
 
     def test_constructor(self):
+        # Recognize TimeSeries
+        self.assert_(isinstance(self.ts, TimeSeries))
+
+        # Pass in Series
+        derived = Series(self.ts)
+        self.assert_(isinstance(derived, TimeSeries))
+
+        self.assert_(common.equalContents(derived.index, self.ts.index))
+        # Ensure new index is not created
+        self.assertEquals(id(self.ts.index), id(derived.index))
+
+        # Pass in scalar
+        scalar = Series(0.5)
+        self.assert_(isinstance(scalar, float))
+
+        # Mixed type Series
+        mixed = Series(['hello', np.NaN], index=[0, 1])
+        self.assert_(mixed.dtype == np.object_)
+        self.assert_(mixed[1] is np.NaN)
+
+        self.assertRaises(Exception, Series, [0, 1, 2], index=None)
+
+    def test_setindex(self):
+        # wrong type
+        series = self.series.copy()
+        self.assertRaises(TypeError, series._set_index, None)
+
+        # wrong length
+        series = self.series.copy()
+        self.assertRaises(AssertionError, series._set_index,
+                          np.arange(len(series) - 1))
+
+        # works
+        series = self.series.copy()
+        series.index = np.arange(len(series))
+        self.assert_(isinstance(series.index, Index))
+
+    def test_array_finalize(self):
         pass
 
     def test_fromDict(self):
-        pass
+        data = {'a' : 0, 'b' : 1, 'c' : 2, 'd' : 3}
+
+        series = Series.fromDict(data)
+        self.assert_(common.is_sorted(series.index))
+
+        data = {'a' : 0, 'b' : '1', 'c' : '2', 'd' : datetime.now()}
+        series = Series.fromDict(data)
+        self.assert_(series.dtype == np.object_)
+
+        data = {'a' : 0, 'b' : '1', 'c' : '2', 'd' : '3'}
+        series = Series.fromDict(data, castFloat=False)
+        self.assert_(series.dtype == np.object_)
 
     def test_fromValue(self):
-        pass
+        nans = Series.fromValue(np.NaN, index=self.ts.index)
+        self.assert_(nans.dtype == np.float_)
+
+        strings = Series.fromValue('foo', index=self.ts.index)
+        self.assert_(strings.dtype == np.object_)
+
+        d = datetime.now()
+        dates = Series.fromValue(d, index=self.ts.index)
+        self.assert_(dates.dtype == np.object_)
+
+    def test_contains(self):
+        common.assert_contains_all(self.ts.index, self.ts)
 
-    def test_getitem(self):
+    def test_pickle(self):
+        f = open('tmp1', 'wb')
+        h = open('tmp3', 'wb')
+        pickle.dump(self.series, f)
+        pickle.dump(self.ts, h)
+        f.close()
+        h.close()
+        f = open('tmp1', 'rb')
+        h = open('tmp3', 'rb')
+        unPickledf = pickle.load(f)
+        unPickledh = pickle.load(h)
+        f.close()
+        h.close()
+        os.remove('tmp1')
+        os.remove('tmp3')
+        self.assert_(isinstance(unPickledf, Series))
+        self.assert_(isinstance(unPickledh, Series))
+        self.assert_(common.equalContents(unPickledf, self.series))
+        self.assert_(common.equalContents(unPickledh, self.ts))
+        for idx in self.series.index:
+            self.assert_(idx in unPickledf.index)
+            self.assertEqual(unPickledf[idx], self.series[idx])
+        for idx in self.ts.index:
+            self.assert_(idx in unPickledh.index)
+            self.assertEqual(unPickledh[idx], self.ts[idx])
+
+    def test_getitem_get(self):
         idx1 = self.series.index[5]
         idx2 = self.objSeries.index[5]
+
         self.assertEqual(self.series[idx1], self.series.get(idx1))
         self.assertEqual(self.objSeries[idx2], self.objSeries.get(idx2))
 
+        self.assertEqual(self.series[idx1], self.series[5])
+        self.assertEqual(self.objSeries[idx2], self.objSeries[5])
+
+        self.assert_(self.series.get(-1) is None)
+        self.assertEqual(self.series[5], self.series.get(self.series.index[5]))
+
     def test_fancy(self):
         slice1 = self.series[[1,2,3]]
         slice2 = self.objSeries[[1,2,3]]
@@ -40,6 +139,23 @@ class TestSeries(unittest.TestCase):
         self.assertEqual(self.series[2], slice1[1])
         self.assertEqual(self.objSeries[2], slice2[1])
 
+    def test_slice(self):
+        numSlice = self.series[10:20]
+        numSliceEnd = self.series[-10:]
+        objSlice = self.objSeries[10:20]
+
+        self.assert_(self.series.index[9] not in numSlice.index)
+        self.assert_(self.objSeries.index[9] not in objSlice.index)
+
+        self.assertEqual(len(numSlice), len(numSlice.index))
+        self.assertEqual(self.series[numSlice.index[0]],
+                         numSlice[numSlice.index[0]])
+
+        self.assertEqual(numSlice.index[1], self.series.index[11])
+
+        self.assert_(common.equalContents(numSliceEnd,
+                                          np.array(self.series)[-10:]))
+
     def test_setitem(self):
         self.ts[self.ts.index[5]] = np.NaN
         self.ts[[1,2,17]] = np.NaN
@@ -49,49 +165,65 @@ class TestSeries(unittest.TestCase):
         self.ts[np.isnan(self.ts)] = 5
         self.assert_(not np.isnan(self.ts[2]))
 
+        # caught this bug when writing tests
+        series = Series(common.makeIntIndex(20).astype(float),
+                        index=common.makeIntIndex(20))
+
+        series[::2] = 0
+        self.assert_((series[::2] == 0).all())
+
     def test_setslice(self):
-        slice = self.ts[5:20]
-        self.assertEqual(len(slice), len(slice.index))
-        self.assertEqual(len(slice.index.indexMap), len(slice.index))
+        sl = self.ts[5:20]
+        self.assertEqual(len(sl), len(sl.index))
+        self.assertEqual(len(sl.index.indexMap), len(sl.index))
 
     def test_repr(self):
-        pass
+        str(self.ts)
+        str(self.series)
+        str(self.objSeries)
 
     def test_iter(self):
         for i, val in enumerate(self.series):
             self.assertEqual(val, self.series[i])
+
         for i, val in enumerate(self.ts):
             self.assertEqual(val, self.ts[i])
+
+    def test_keys(self):
+        self.assert_(self.ts.keys() is self.ts.index)
+
+    def test_values(self):
+        self.assert_(np.array_equal(self.ts, self.ts.values()))
+
+    def test_iteritems(self):
         for idx, val in self.series.iteritems():
             self.assertEqual(val, self.series[idx])
+
         for idx, val in self.ts.iteritems():
             self.assertEqual(val, self.ts[idx])
 
     def test_stats(self):
+        from scipy.stats import skew
+
         self.series[5:15] = np.NaN
 
         s1 = np.array(self.series)
         s1 = s1[-np.isnan(s1)]
+
+        self.assertEquals(np.min(s1), self.series.min())
+        self.assertEquals(np.max(s1), self.series.max())
+        self.assertEquals(np.sum(s1), self.series.sum())
         self.assertEquals(np.mean(s1), self.series.mean())
         self.assertEquals(np.std(s1, ddof=1), self.series.std())
         self.assertEquals(np.var(s1, ddof=1), self.series.var())
-        self.assertEquals(np.sum(s1), self.series.sum())
+        self.assertEquals(skew(s1, bias=False), self.series.skew())
+
         self.assert_(not np.isnan(np.sum(self.series)))
         self.assert_(not np.isnan(np.mean(self.series)))
         self.assert_(not np.isnan(np.std(self.series)))
         self.assert_(not np.isnan(np.var(self.series)))
-
-    def test_keys(self):
-        pass
-
-    def test_values(self):
-        pass
-
-    def test_iteritems(self):
-        pass
-
-    def test_get(self):
-        self.assertEqual(self.series[5], self.series.get(self.series.index[5]))
+        self.assert_(not np.isnan(np.min(self.series)))
+        self.assert_(not np.isnan(np.max(self.series)))
 
     def test_append(self):
         appendedSeries = self.series.append(self.ts)
@@ -103,72 +235,264 @@ class TestSeries(unittest.TestCase):
             else:
                 self.fail("orphaned index!")
 
-    def test_combineFunc(self):
-        shiftedSum = self.ts + self.ts.shift(5)
-        idSum = self.ts + self.ts
-        self.assert_(np.isnan(shiftedSum[0]))
-        for idx, val in idSum.iteritems():
-            self.assertAlmostEqual(self.ts[idx] + self.ts[idx], val)
-        multiplied = self.ts * 5
-        for idx, val in multiplied.iteritems():
-            self.assertEqual(self.ts[idx] * 5, val)
+        self.assertRaises(Exception, self.ts.append, self.ts)
+
+    def test_operators(self):
+        series = self.ts
+        other = self.ts[::2]
+
+        def _check_op(other, op):
+            cython_or_numpy = op(series, other)
+            python = series._combineFunc(other, op)
+
+            common.assert_almost_equal(cython_or_numpy, python)
+
+        def check(other):
+            _check_op(other, operator.add)
+            _check_op(other, operator.sub)
+            _check_op(other, operator.div)
+            _check_op(other, operator.mul)
+            _check_op(other, operator.pow)
+
+            _check_op(other, lambda x, y: operator.add(y, x))
+            _check_op(other, lambda x, y: operator.sub(y, x))
+            _check_op(other, lambda x, y: operator.div(y, x))
+            _check_op(other, lambda x, y: operator.mul(y, x))
+            _check_op(other, lambda x, y: operator.pow(y, x))
+
+        check(self.ts * 2)
+        check(self.ts[::2])
+        check(5)
+
+        def check_comparators(other):
+            _check_op(other, operator.gt)
+            _check_op(other, operator.ge)
+            _check_op(other, operator.eq)
+            _check_op(other, operator.lt)
+            _check_op(other, operator.le)
+
+        check_comparators(5)
+        check_comparators(self.ts + 1)
+
+    def test_operators_date(self):
+        result = self.objSeries + timedelta(1)
+        result = self.objSeries - timedelta(1)
+
+    def test_operators_corner(self):
+        series = self.ts
+
+        empty = Series([], index=Index([]))
+
+        result = series + empty
+        self.assert_(np.isnan(result).all())
+
+        result = empty + Series([], index=Index([]))
+        self.assert_(len(result) == 0)
+
+        deltas = Series([timedelta(1)] * 5, index=np.arange(5))
+        sub_deltas = deltas[::2]
+
+        deltas5 = deltas * 5
+        deltas = deltas + sub_deltas
+
+    def test_operators_frame(self):
+        # rpow does not work with DataFrame
+        df = DataFrame({'A' : self.ts})
+
+        common.assert_almost_equal(self.ts + self.ts, (self.ts + df)['A'])
+        self.assertRaises(Exception, self.ts.__pow__, df)
 
     def test_combineFirst(self):
-        pass
+        series = Series(common.makeIntIndex(20).astype(float),
+                        index=common.makeIntIndex(20))
 
-    def test_argsort(self):
-        pass
+        series_copy = series * 2
+        series_copy[::2] = np.NaN
 
-    def test_cumsum(self):
-        pass
+        # nothing used from the input
+        combined = series.combineFirst(series_copy)
 
-    def test_cumprod(self):
-        pass
+        self.assert_(np.array_equal(combined, series))
 
-    def test_copy(self):
-        pass
+        # Holes filled from input
+        combined = series_copy.combineFirst(series)
+        self.assert_(np.isfinite(combined).all())
+
+        self.assert_(np.array_equal(combined[::2], series[::2]))
+        self.assert_(np.array_equal(combined[1::2], series_copy[1::2]))
+
+        # mixed types
+        index = common.makeStringIndex(20)
+        floats = Series(common.randn(20), index=index)
+        strings = Series(common.makeStringIndex(10), index=index[::2])
+
+        combined = strings.combineFirst(floats)
+
+        common.assert_dict_equal(strings, combined, compare_keys=False)
+        common.assert_dict_equal(floats[1::2], combined, compare_keys=False)
+
+    def test_overloads(self):
+        methods = ['argsort', 'cumsum', 'cumprod']
+
+        for method in methods:
+            func = getattr(np, method)
+
+            self.assert_(np.array_equal(func(self.ts), func(np.array(self.ts))))
+
+            # with missing values
+            ts = self.ts.copy()
+            ts[::2] = np.NaN
+
+            result = func(ts)[1::2]
+            expected = func(np.array(ts.valid()))
+
+            self.assert_(np.array_equal(result, expected))
+
+    def test_median(self):
+        self.assertAlmostEqual(np.median(self.ts), self.ts.median())
+
+        ts = self.ts.copy()
+        ts[::2] = np.NaN
+
+        self.assertAlmostEqual(np.median(ts.valid()), ts.median())
 
     def test_corr(self):
-        pass
+        # full overlap
+        self.assertAlmostEqual(self.ts.corr(self.ts), 1)
+
+        # partial overlap
+        self.assertAlmostEqual(self.ts[:15].corr(self.ts[5:]), 1)
+
+        # No overlap
+        self.assert_(np.isnan(self.ts[::2].corr(self.ts[1::2])))
+
+        # additional checks?
+
+    def test_copy(self):
+        ts = self.ts.copy()
+
+        ts[::2] = np.NaN
+
+        # Did not modify original Series
+        self.assertFalse(np.isnan(self.ts[0]))
 
     def test_count(self):
-        pass
+        self.assertEqual(self.ts.count(), len(self.ts))
 
-    def test_median(self):
-        pass
+        self.ts[::2] = np.NaN
+
+        self.assertEqual(self.ts.count(), np.isfinite(self.ts).sum())
 
     def test_sort(self):
-        pass
+        ts = self.ts.copy()
+        ts.sort()
+
+        self.assert_(np.array_equal(ts, self.ts.order()))
+        self.assert_(np.array_equal(ts.index, self.ts.order().index))
 
     def test_order(self):
-        pass
+
+        ts = self.ts.copy()
+        ts[:5] = np.NaN
+        vals = ts.values()
+
+        result = ts.order()
+        self.assert_(np.isnan(result[-5:]).all())
+        self.assert_(np.array_equal(result[:-5], np.sort(vals[5:])))
+
+        result = ts.order(missingAtEnd=False)
+        self.assert_(np.isnan(result[:5]).all())
+        self.assert_(np.array_equal(result[5:], np.sort(vals[5:])))
 
     def test_map(self):
-        pass
+        result = self.ts.map(lambda x: x * 2)
+
+        self.assert_(np.array_equal(result, self.ts * 2))
 
     def test_toCSV(self):
-        pass
+        self.ts.toCSV('_foo')
+        os.remove('_foo')
 
     def test_toDict(self):
-        pass
+        self.assert_(np.array_equal(Series.fromDict(self.ts.toDict()), self.ts))
 
     def test_cap(self):
-        pass
+        val = self.ts.median()
+
+        self.assertEqual(self.ts.cap(val).max(), val)
 
     def test_floor(self):
-        pass
+        val = self.ts.median()
+
+        self.assertEqual(self.ts.floor(val).min(), val)
 
     def test_valid(self):
-        pass
+        ts = self.ts.copy()
+        ts[::2] = np.NaN
+
+        result = ts.valid()
+        self.assertEqual(len(result), ts.count())
+
+        common.assert_dict_equal(result, ts, compare_keys=False)
+
+    def test_shift(self):
+        shifted = self.ts.shift(1)
+        unshifted = shifted.shift(-1)
+
+        common.assert_dict_equal(unshifted, self.ts, compare_keys=False)
+
+        offset = datetools.bday
+        shifted = self.ts.shift(1, offset=offset)
+        unshifted = shifted.shift(-1, offset=offset)
+
+        common.assert_series_equal(unshifted, self.ts)
+
+        unshifted = self.ts.shift(0, offset=offset)
+        common.assert_series_equal(unshifted, self.ts)
+
+        shifted = self.ts.shift(1, timeRule='WEEKDAY')
+        unshifted = shifted.shift(-1, timeRule='WEEKDAY')
+
+        common.assert_series_equal(unshifted, self.ts)
 
     def test_truncate(self):
-        pass
+        offset = datetools.bday
 
-    def test_meta(self):
-        wrapped = Series(self.series)
-        self.assert_(common.equalContents(wrapped.index, self.series.index))
-        # Ensure new index is not created
-        self.assertEquals(id(self.series.index), id(wrapped.index))
+        ts = self.ts[::3]
+
+        start, end = self.ts.index[3], self.ts.index[6]
+        start_missing, end_missing = self.ts.index[2], self.ts.index[7]
+
+        # neither specified
+        truncated = ts.truncate()
+        common.assert_series_equal(truncated, ts)
+
+        # both specified
+        expected = ts[1:3]
+
+        truncated = ts.truncate(start, end)
+        common.assert_series_equal(truncated, expected)
+
+        truncated = ts.truncate(start_missing, end_missing)
+        common.assert_series_equal(truncated, expected)
+
+        # start specified
+        expected = ts[1:]
+
+        truncated = ts.truncate(before=start)
+        common.assert_series_equal(truncated, expected)
+
+        truncated = ts.truncate(before=start_missing)
+        common.assert_series_equal(truncated, expected)
+
+        # end specified
+        expected = ts[:3]
+
+        truncated = ts.truncate(after=end)
+        common.assert_series_equal(truncated, expected)
+
+        truncated = ts.truncate(after=end_missing)
+        common.assert_series_equal(truncated, expected)
 
     def test_asOf(self):
         self.ts[5:10] = np.NaN
@@ -178,31 +502,16 @@ class TestSeries(unittest.TestCase):
         self.assertEqual(val1, self.ts[4])
         self.assertEqual(val2, self.ts[14])
 
-    def test_pickle(self):
-        f = open('tmp1', 'wb')
-        h = open('tmp3', 'wb')
-        pickle.dump(self.series, f)
-        pickle.dump(self.ts, h)
-        f.close()
-        h.close()
-        f = open('tmp1', 'rb')
-        h = open('tmp3', 'rb')
-        unPickledf = pickle.load(f)
-        unPickledh = pickle.load(h)
-        f.close()
-        h.close()
-        os.remove('tmp1')
-        os.remove('tmp3')
-        self.assert_(isinstance(unPickledf, Series))
-        self.assert_(isinstance(unPickledh, Series))
-        self.assert_(common.equalContents(unPickledf, self.series))
-        self.assert_(common.equalContents(unPickledh, self.ts))
-        for idx in self.series.index:
-            self.assert_(idx in unPickledf.index)
-            self.assertEqual(unPickledf[idx], self.series[idx])
-        for idx in self.ts.index:
-            self.assert_(idx in unPickledh.index)
-            self.assertEqual(unPickledh[idx], self.ts[idx])
+    def test_merge(self):
+        index, data = common.getMixedTypeDict()
+
+        source = Series(data['B'], index=data['C'])
+        target = Series(data['C'][:4], index=data['D'][:4])
+
+        merged = target.merge(source)
+
+        for k, v in merged.iteritems():
+            self.assertEqual(v, source[target[k]])
 
     def test_reindex(self):
         identity = self.series.reindex(self.series.index)
@@ -224,50 +533,16 @@ class TestSeries(unittest.TestCase):
         for idx, val in subNonContig.iteritems():
             self.assertEqual(val, self.ts[idx])
 
-    def test_operators(self):
-        newSeries = deepcopy(self.series)
-        newSeries[5:10] = np.NaN
-        newSeries[10:20] = newSeries[10:20] + 1
-        newSeries[20:30] = newSeries[20:30] - 1
-        eqSeries = (newSeries == self.series)
-        ltSeries = (newSeries < self.series)
-        gtSeries = (newSeries > self.series)
-        self.assertTrue(ltSeries[20])
-        self.assertFalse(ltSeries[10])
-        self.assertTrue(gtSeries[10])
-        self.assertFalse(gtSeries[20])
-
     def test_preserveRefs(self):
-        slice = self.ts[5:10]
+        sl = self.ts[5:10]
         seq = self.ts[[5,10,15]]
-        slice[4] = np.NaN
+        sl[4] = np.NaN
         seq[1] = np.NaN
         self.assertFalse(np.isnan(self.ts[9]))
         self.assertFalse(np.isnan(self.ts[10]))
 
-class TestTimeSeries(unittest.TestCase):
-    def setUp(self):
-        self.ts = common.makeTimeSeries()
-        self.series = common.makeStringSeries()
-        self.objSeries = common.makeObjectSeries()
-
-    def test_shift(self):
-        shifted = self.ts.shift(1)
-        unshifted = shifted.shift(-1)
-        idxMap = self.ts.index.indexMap
-        for k, v in unshifted.iteritems():
-            self.assertEqual(self.ts[idxMap[k]], v)
-
-    def test_slice(self):
-        numSlice = self.series[10:20]
-        numSliceEnd = self.series[-10:]
-        objSlice = self.objSeries[10:20]
-        self.assert_(self.series.index[9] not in numSlice.index)
-        self.assert_(self.objSeries.index[9] not in objSlice.index)
-        self.assertEqual(len(numSlice), len(numSlice.index))
-        self.assertEqual(self.series[numSlice.index[0]], numSlice[numSlice.index[0]])
-        self.assertEqual(numSlice.index[1], self.series.index[11])
-        self.assert_(common.equalContents(numSliceEnd, np.array(self.series)[-10:]))
+#-------------------------------------------------------------------------------
+# TimeSeries-specific
 
     def test_fill(self):
         pass
@@ -276,7 +551,22 @@ class TestTimeSeries(unittest.TestCase):
         pass
 
     def test_interpolate(self):
-        pass
+        ts = Series(np.arange(len(self.ts), dtype=float), self.ts.index)
+
+        ts_copy = ts.copy()
+        ts_copy[5:10] = np.NaN
+
+        linear_interp = ts_copy.interpolate(method='linear')
+        self.assert_(np.array_equal(linear_interp, ts))
+
+        ord_ts = Series([d.toordinal() for d in self.ts.index],
+                        index=self.ts.index).astype(float)
+
+        ord_ts_copy = ord_ts.copy()
+        ord_ts_copy[5:10] = np.NaN
+
+        time_interp = ord_ts_copy.interpolate(method='time')
+        self.assert_(np.array_equal(time_interp, ord_ts))
 
     def test_weekday(self):
         pass
@@ -293,8 +583,5 @@ class TestTimeSeries(unittest.TestCase):
     def test_lastValid(self):
         pass
 
-    def test_reindex(self):
-        pass
-
 if __name__ == '__main__':
     unittest.main()
diff --git a/pandas/info.py b/pandas/info.py
new file mode 100644
index 000000000..0d5515f81
--- /dev/null
+++ b/pandas/info.py
@@ -0,0 +1,34 @@
+"""
+Pandas - a library for panel, time series, or cross-sectional data analysis
+===========================================================================
+
+Main data structures (see docstrings for detailed documentation)
+--------------------
+Index
+    Represent row or column labels in Series / DataFrame structures
+
+Series / TimeSeries
+    Represents standard 1-dimensional cross-section (resp. time series)
+    As an numpy.ndarray subclass, compatible with ufuncs and other NumPy
+    functions
+
+DataFrame / DataMatrix
+    Represent collections of Series objects, enable easy management
+    of multiple time series / cross-sections
+
+DateRange
+    Index subclass for generating arrays of fixed frequency dates
+
+Subpackages
+-----------
+core
+    Implementations of core data structures, basic building blocks. Most of
+    the user-relevant code is accessible through the top-level namespace
+io
+    Persistence, parsing, and data loading tools
+lib
+    C, Cython, and Fortran extensions for other components
+stats
+    Statistical and econometric functions
+"""
+
diff --git a/pandas/version.py b/pandas/version.py
new file mode 100644
index 000000000..7c6d5c6ce
--- /dev/null
+++ b/pandas/version.py
@@ -0,0 +1,2 @@
+from pkg_resources import require
+__version__ = require('pandas')[0].version
