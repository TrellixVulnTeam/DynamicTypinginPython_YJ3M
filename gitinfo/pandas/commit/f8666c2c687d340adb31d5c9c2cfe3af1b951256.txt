commit f8666c2c687d340adb31d5c9c2cfe3af1b951256
Author: jreback <jeff@reback.net>
Date:   Tue Sep 17 07:35:46 2013 -0400

    DOC: v0.13.0 HDFStore corrections

diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index 4d7a3da8a..b46e2d4b5 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -36,77 +36,6 @@ API changes
     an alias of iteritems used to get around ``2to3``'s changes).
     (:issue:`4384`, :issue:`4375`, :issue:`4372`)
   - ``Series.get`` with negative indexers now returns the same as ``[]`` (:issue:`4390`)
-  - ``HDFStore``
-
-    - Significant table writing performance improvements
-    - handle a passed ``Series`` in table format (:issue:`4330`)
-    - added an ``is_open`` property to indicate if the underlying file handle is_open;
-      a closed store will now report 'CLOSED' when viewing the store (rather than raising an error)
-      (:issue:`4409`)
-    - a close of a ``HDFStore`` now will close that instance of the ``HDFStore``
-      but will only close the actual file if the ref count (by ``PyTables``) w.r.t. all of the open handles
-      are 0. Essentially you have a local instance of ``HDFStore`` referenced by a variable. Once you
-      close it, it will report closed. Other references (to the same file) will continue to operate
-      until they themselves are closed. Performing an action on a closed file will raise
-      ``ClosedFileError``
-
-      .. ipython:: python
-
-         path = 'test.h5'
-         df = DataFrame(randn(10,2))
-         store1 = HDFStore(path)
-         store2 = HDFStore(path)
-         store1.append('df',df)
-         store2.append('df2',df)
-
-         store1
-         store2
-         store1.close()
-         store2
-         store2.close()
-         store2
-
-      .. ipython:: python
-         :suppress:
-
-         import os
-         os.remove(path)
-
-    - removed the ``_quiet`` attribute, replace by a ``DuplicateWarning`` if retrieving
-      duplicate rows from a table (:issue:`4367`)
-    - removed the ``warn`` argument from ``open``. Instead a ``PossibleDataLossError`` exception will
-      be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)
-    - ``select_as_coordinates`` will now return an ``Int64Index`` of the resultant selection set
-      See :ref:`here<io.hdf5-selecting_coordinates>` for an example.
-    - allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).
-      See :ref:`here<io.hdf5-where_mask>` for an example.
-    - support ``timedelta64[ns]`` as a serialization type (:issue:`3577`). See :ref:`here<io.hdf5-timedelta>` for an example.
-
-    - the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``
-      the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies 'fixed` or 'f' (Fixed) format
-      and ``append`` imples 'table' or 't' (Table) format
-
-      .. ipython:: python
-
-         path = 'test.h5'
-         df = DataFrame(randn(10,2))
-         df.to_hdf(path,'df_table',format='table')
-         df.to_hdf(path,'df_table2',append=True)
-         df.to_hdf(path,'df_fixed')
-         with get_store(path) as store:
-            print store
-
-      .. ipython:: python
-         :suppress:
-
-         import os
-         os.remove(path)
-    - add the keyword ``dropna=True`` to ``append`` to change whether ALL nan rows are not written
-      to the store (default is ``True``, ALL nan rows are NOT written), also settable
-      via the option ``io.hdf.dropna_table`` (:issue:`4625`)
-    - store `datetime.date` objects as ordinals rather then timetuples to avoid timezone issues (:issue:`2852`),
-      thanks @tavistmorph and @numpand
-
   - Changes to how ``Index`` and ``MultiIndex`` handle metadata (``levels``,
     ``labels``, and ``names``) (:issue:`4039`):
 
@@ -190,27 +119,55 @@ Indexing API Changes
 HDFStore API Changes
 ~~~~~~~~~~~~~~~~~~~~
 
-  - Query Format Changes. A much more string-like query format is now supported.
+  - Query Format Changes. A much more string-like query format is now supported. See :ref:`the docs<io.hdf5-query>`.
 
     .. ipython:: python
 
-       path = 'test_query.h5'
-       dfq = DataFrame(randn(10,4),columns=list('ABCD'),index=date_range('20130101',periods=10))
+       path = 'test.h5'
+       dfq = DataFrame(randn(10,4),
+                columns=list('ABCD'),
+                index=date_range('20130101',periods=10))
        dfq.to_hdf(path,'dfq',format='table',data_columns=True)
 
     Use boolean expressions, with in-line function evaluation.
 
     .. ipython:: python
 
-       read_hdf(path,'dfq',where="index>Timestamp('20130104') & columns=['A', 'B']")
+       read_hdf(path,'dfq',
+           where="index>Timestamp('20130104') & columns=['A', 'B']")
 
     Use an inline column reference
 
     .. ipython:: python
 
-       read_hdf(path,'dfq',where="A>0 or C>0")
+       read_hdf(path,'dfq',
+           where="A>0 or C>0")
 
-    See :ref:`the docs<io.hdf5-query>`.
+    .. ipython:: python
+       :suppress:
+
+       import os
+       os.remove(path)
+
+  - the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``
+    the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies ``fixed`` format
+    and ``append`` imples ``table`` format. This default format can be set as an option by setting ``io.hdf.default_format``.
+
+    .. ipython:: python
+
+       path = 'test.h5'
+       df = DataFrame(randn(10,2))
+       df.to_hdf(path,'df_table',format='table')
+       df.to_hdf(path,'df_table2',append=True)
+       df.to_hdf(path,'df_fixed')
+       with get_store(path) as store:
+          print store
+
+    .. ipython:: python
+       :suppress:
+
+       import os
+       os.remove(path)
 
   - Significant table writing performance improvements
   - handle a passed ``Series`` in table format (:issue:`4330`)
@@ -252,27 +209,6 @@ HDFStore API Changes
     be raised if you try to use ``mode='w'`` with an OPEN file handle (:issue:`4367`)
   - allow a passed locations array or mask as a ``where`` condition (:issue:`4467`).
     See :ref:`here<io.hdf5-where_mask>` for an example.
-
-  - the ``format`` keyword now replaces the ``table`` keyword; allowed values are ``fixed(f)`` or ``table(t)``
-    the same defaults as prior < 0.13.0 remain, e.g. ``put`` implies 'fixed` or 'f' (Fixed) format
-    and ``append`` imples 'table' or 't' (Table) format
-
-    .. ipython:: python
-
-       path = 'test.h5'
-       df = DataFrame(randn(10,2))
-       df.to_hdf(path,'df_table',format='table')
-       df.to_hdf(path,'df_table2',append=True)
-       df.to_hdf(path,'df_fixed')
-       with get_store(path) as store:
-          print store
-
-    .. ipython:: python
-       :suppress:
-
-       import os
-       os.remove('test.h5')
-       os.remove('test_query.h5')
   - add the keyword ``dropna=True`` to ``append`` to change whether ALL nan rows are not written
     to the store (default is ``True``, ALL nan rows are NOT written), also settable
     via the option ``io.hdf.dropna_table`` (:issue:`4625`)
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 5c1dd408f..65edaed89 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -731,7 +731,7 @@ class HDFStore(StringMixin):
                        allow more flexible operations like searching / selecting subsets
                        of the data
         append   : boolean, default False
-            For Table format, append the input data to the existing
+            This will force Table format, append the input data to the existing.
         encoding : default None, provide an encoding for strings
         """
         if format is None:
@@ -803,7 +803,7 @@ class HDFStore(StringMixin):
                        Write as a PyTables Table structure which may perform worse but
                        allow more flexible operations like searching / selecting subsets
                        of the data
-        append   : boolean, default True, append the input data to the existing
+        append       : boolean, default True, append the input data to the existing
         data_columns : list of columns to create as data columns, or True to use all columns
         min_itemsize : dict of columns that specify minimum string sizes
         nan_rep      : string to use as string nan represenation
