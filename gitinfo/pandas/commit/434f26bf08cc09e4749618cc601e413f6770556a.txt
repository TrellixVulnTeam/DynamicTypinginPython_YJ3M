commit 434f26bf08cc09e4749618cc601e413f6770556a
Author: Jeffrey Tratner <jeffrey.tratner@gmail.com>
Date:   Sat Jul 27 10:27:54 2013 -0400

    TST/ENH: Add assert_isinstance util to util/testing + better type checking
    
    cleanup instance checks in pandas/tests, add assert_isinstance method
    
    CLN: assert_(isinstance --> assert_isinstace
    
    Make is_instance_factory cleaner + basestring --> (str, bytes)
    
    use list(range in pytables tests
    
    make _WINDOW_TYPES update 2/3 compatible

diff --git a/pandas/core/config.py b/pandas/core/config.py
index c66911c12..725f86958 100644
--- a/pandas/core/config.py
+++ b/pandas/core/config.py
@@ -729,15 +729,16 @@ def is_instance_factory(_type):
                 True if x is an instance of `_type`
 
     """
+    if isinstance(_type, (tuple, list)):
+        _type = tuple(_type)
+        from pandas.core.common import pprint_thing
+        type_repr = "|".join(map(pprint_thing, _type))
+    else:
+        type_repr = "'%s'" % _type
 
     def inner(x):
-        if isinstance(_type,(tuple,list)) :
-            if not any([isinstance(x,t) for t in _type]):
-                from pandas.core.common import pprint_thing as pp
-                pp_values = list(map(pp, _type))
-                raise ValueError("Value must be an instance of %s" % pp("|".join(pp_values)))
-        elif not isinstance(x, _type):
-            raise ValueError("Value must be an instance of '%s'" % str(_type))
+        if not isinstance(x, _type):
+            raise ValueError("Value must be an instance of %s" % type_repr)
 
     return inner
 
@@ -757,4 +758,4 @@ is_bool = is_type_factory(bool)
 is_float = is_type_factory(float)
 is_str = is_type_factory(str)
 is_unicode = is_type_factory(six.text_type)
-is_text = is_instance_factory(basestring)
+is_text = is_instance_factory((str, bytes))
diff --git a/pandas/core/format.py b/pandas/core/format.py
index 1b78b501b..8676d9a54 100644
--- a/pandas/core/format.py
+++ b/pandas/core/format.py
@@ -872,7 +872,7 @@ class CSVFormatter(object):
             cols = self.columns
 
         series = {}
-        for k, v in self.obj._series.iteritems():
+        for k, v in compat.iteritems(self.obj._series):
             series[k] = v.values
 
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 94b36ffed..07def64b2 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -384,7 +384,7 @@ class DataFrame(NDFrame):
         'columns': 1
     }
 
-    _AXIS_NAMES = dict((v, k) for k, v in _AXIS_NUMBERS.iteritems())
+    _AXIS_NAMES = dict((v, k) for k, v in compat.iteritems(_AXIS_NUMBERS))
 
     def __init__(self, data=None, index=None, columns=None, dtype=None,
                  copy=False):
@@ -493,7 +493,7 @@ class DataFrame(NDFrame):
 
             # prefilter if columns passed
 
-            data = dict((k, v) for k, v in data.iteritems() if k in columns)
+            data = dict((k, v) for k, v in compat.iteritems(data) if k in columns)
 
             if index is None:
                 index = extract_index(data.values())
@@ -986,11 +986,11 @@ class DataFrame(NDFrame):
             warnings.warn("DataFrame columns are not unique, some "
                           "columns will be omitted.", UserWarning)
         if outtype.lower().startswith('d'):
-            return dict((k, v.to_dict()) for k, v in self.iteritems())
+            return dict((k, v.to_dict()) for k, v in compat.iteritems(self))
         elif outtype.lower().startswith('l'):
-            return dict((k, v.tolist()) for k, v in self.iteritems())
+            return dict((k, v.tolist()) for k, v in compat.iteritems(self))
         elif outtype.lower().startswith('s'):
-            return dict((k, v) for k, v in self.iteritems())
+            return dict((k, v) for k, v in compat.iteritems(self))
         else:  # pragma: no cover
             raise ValueError("outtype %s not understood" % outtype)
 
@@ -1063,7 +1063,7 @@ class DataFrame(NDFrame):
             else:
                 arrays = []
                 arr_columns = []
-                for k, v in data.iteritems():
+                for k, v in compat.iteritems(data):
                     if k in columns:
                         arr_columns.append(k)
                         arrays.append(v)
@@ -1682,7 +1682,7 @@ class DataFrame(NDFrame):
             counts = self.count()
             if len(cols) != len(counts):
                 raise AssertionError('Columns must equal counts')
-            for col, count in counts.iteritems():
+            for col, count in compat.iteritems(counts):
                 col = com.pprint_thing(col)
                 lines.append(_put_str(col, space) +
                              '%d  non-null values' % count)
@@ -1690,7 +1690,7 @@ class DataFrame(NDFrame):
             lines.append(self.columns.summary(name='Columns'))
 
         counts = self.get_dtype_counts()
-        dtypes = ['%s(%d)' % k for k in sorted(counts.iteritems())]
+        dtypes = ['%s(%d)' % k for k in sorted(compat.iteritems(counts))]
         lines.append('dtypes: %s' % ', '.join(dtypes))
         _put_lines(buf, lines)
 
@@ -3457,7 +3457,7 @@ class DataFrame(NDFrame):
                                               'by column')
 
                 result = self if inplace else self.copy()
-                for k, v in value.iteritems():
+                for k, v in compat.iteritems(value):
                     if k not in result:
                         continue
                     result[k].fillna(v, inplace=True)
@@ -3632,7 +3632,7 @@ class DataFrame(NDFrame):
             if isinstance(to_replace, (dict, Series)):
                 if isinstance(value, (dict, Series)):  # {'A' : NA} -> {'A' : 0}
                     new_data = self._data
-                    for c, src in to_replace.iteritems():
+                    for c, src in compat.iteritems(to_replace):
                         if c in value and c in self:
                             new_data = new_data.replace(src, value[c],
                                                         filter=[c],
@@ -3641,7 +3641,7 @@ class DataFrame(NDFrame):
 
                 elif not isinstance(value, (list, np.ndarray)):  # {'A': NA} -> 0
                     new_data = self._data
-                    for k, src in to_replace.iteritems():
+                    for k, src in compat.iteritems(to_replace):
                         if k in self:
                             new_data = new_data.replace(src, value,
                                                         filter=[k],
@@ -3681,7 +3681,7 @@ class DataFrame(NDFrame):
                 if isinstance(value, (dict, Series)):  # NA -> {'A' : 0, 'B' : -1}
                     new_data = self._data
 
-                    for k, v in value.iteritems():
+                    for k, v in compat.iteritems(value):
                         if k in self:
                             new_data = new_data.replace(to_replace, v,
                                                         filter=[k],
@@ -4864,7 +4864,7 @@ class DataFrame(NDFrame):
 
         if len(numdata.columns) == 0:
             return DataFrame(dict((k, v.describe())
-                                  for k, v in self.iteritems()),
+                                  for k, v in compat.iteritems(self)),
                              columns=self.columns)
 
         lb = .5 * (1. - percentile_width / 100.)
@@ -5803,7 +5803,7 @@ def _rec_to_dict(arr):
         sdict = dict((k, arr[k]) for k in columns)
     elif isinstance(arr, DataFrame):
         columns = list(arr.columns)
-        sdict = dict((k, v.values) for k, v in arr.iteritems())
+        sdict = dict((k, v.values) for k, v in compat.iteritems(arr))
     elif isinstance(arr, dict):
         columns = sorted(arr)
         sdict = arr.copy()
@@ -5978,8 +5978,8 @@ def _homogenize(data, index, dtype=None):
 def _from_nested_dict(data):
     # TODO: this should be seriously cythonized
     new_data = OrderedDict()
-    for index, s in data.iteritems():
-        for col, v in s.iteritems():
+    for index, s in compat.iteritems(data):
+        for col, v in compat.iteritems(s):
             new_data[col] = new_data.get(col, OrderedDict())
             new_data[col][index] = v
     return new_data
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 528d7baca..9bd4f24ee 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1,9 +1,11 @@
 import types
 import numpy as np
-from pandas.util.py3compat import range, long
+
 import six
-from six.moves import zip
+from pandas.util.py3compat import range, long
+from pandas.util.compat import OrderedDict
 from pandas.util import compat
+from six.moves import zip, builtins
 
 from pandas.core.base import PandasObject
 from pandas.core.categorical import Categorical
@@ -14,7 +16,6 @@ from pandas.core.internals import BlockManager, make_block
 from pandas.core.series import Series
 from pandas.core.panel import Panel
 from pandas.util.decorators import cache_readonly, Appender
-from pandas.util.compat import OrderedDict
 import pandas.core.algorithms as algos
 import pandas.core.common as com
 from pandas.core.common import _possibly_downcast_to_dtype, notnull
@@ -487,7 +488,7 @@ class GroupBy(PandasObject):
         if self.grouper._filter_empty_groups:
 
             mask = counts.ravel() > 0
-            for name, result in output.iteritems():
+            for name, result in compat.iteritems(output):
 
                 # since we are masking, make sure that we have a float object
                 values = result
@@ -1705,7 +1706,7 @@ class NDFrameGroupBy(GroupBy):
 
             if any(isinstance(x, (list, tuple, dict)) for x in arg.values()):
                 new_arg = OrderedDict()
-                for k, v in arg.iteritems():
+                for k, v in compat.iteritems(arg):
                     if not isinstance(v, (tuple, list, dict)):
                         new_arg[k] = [v]
                     else:
@@ -1718,13 +1719,13 @@ class NDFrameGroupBy(GroupBy):
                 if isinstance(subset, DataFrame):
                     raise NotImplementedError
 
-                for fname, agg_how in arg.iteritems():
+                for fname, agg_how in compat.iteritems(arg):
                     colg = SeriesGroupBy(subset, selection=self._selection,
                                          grouper=self.grouper)
                     result[fname] = colg.aggregate(agg_how)
                     keys.append(fname)
             else:
-                for col, agg_how in arg.iteritems():
+                for col, agg_how in compat.iteritems(arg):
                     colg = SeriesGroupBy(obj[col], selection=col,
                                          grouper=self.grouper)
                     result[col] = colg.aggregate(agg_how)
@@ -2606,14 +2607,14 @@ def _reorder_by_uniques(uniques, labels):
 
     return uniques, labels
 
-import __builtin__
 
 _func_table = {
-    __builtin__.sum: np.sum
+    builtins.sum: np.sum
 }
 
+
 _cython_table = {
-    __builtin__.sum: 'sum',
+    builtins.sum: 'sum',
     np.sum: 'sum',
     np.mean: 'mean',
     np.prod: 'prod',
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 7cff2e51a..c46e61271 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -261,7 +261,7 @@ class Index(PandasObject, np.ndarray):
         counter = defaultdict(lambda: 0)
         for k in self.values:
             counter[k] += 1
-        return sorted(k for k, v in counter.iteritems() if v > 1)
+        return sorted(k for k, v in compat.iteritems(counter) if v > 1)
 
     _get_duplicates = get_duplicates
 
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 72ba4364c..699d0ac21 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -11,8 +11,11 @@ import pandas.lib as lib
 import pandas.algos as algos
 import pandas.hashtable as _hash
 import pandas.tslib as tslib
+
+from six.moves import builtins
 import six
 
+
 try:
     import bottleneck as bn
     _USE_BOTTLENECK = True
@@ -286,12 +289,11 @@ def nanmin(values, axis=None, skipna=True):
     # numpy 1.6.1 workaround in Python 3.x
     if (values.dtype == np.object_
             and sys.version_info[0] >= 3):  # pragma: no cover
-        import __builtin__
         if values.ndim > 1:
             apply_ax = axis if axis is not None else 0
-            result = np.apply_along_axis(__builtin__.min, apply_ax, values)
+            result = np.apply_along_axis(builtins.min, apply_ax, values)
         else:
-            result = __builtin__.min(values)
+            result = builtins.min(values)
     else:
         if ((axis is not None and values.shape[axis] == 0)
                 or values.size == 0):
@@ -311,13 +313,12 @@ def nanmax(values, axis=None, skipna=True):
     # numpy 1.6.1 workaround in Python 3.x
     if (values.dtype == np.object_
             and sys.version_info[0] >= 3):  # pragma: no cover
-        import __builtin__
 
         if values.ndim > 1:
             apply_ax = axis if axis is not None else 0
-            result = np.apply_along_axis(__builtin__.max, apply_ax, values)
+            result = np.apply_along_axis(builtins.max, apply_ax, values)
         else:
-            result = __builtin__.max(values)
+            result = builtins.max(values)
     else:
         if ((axis is not None and values.shape[axis] == 0)
                 or values.size == 0):
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 739ffc6f3..f2fb213f8 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -282,14 +282,14 @@ class Panel(NDFrame):
         if haxis is not None:
             haxis = _ensure_index(haxis)
             data = OrderedDict((k, v) for k, v
-                               in data.iteritems() if k in haxis)
+                               in compat.iteritems(data) if k in haxis)
         else:
             ks = data.keys()
             if not isinstance(data,OrderedDict):
                 ks = _try_sort(ks)
             haxis = Index(ks)
 
-        for k, v in data.iteritems():
+        for k, v in compat.iteritems(data):
             if isinstance(v, dict):
                 data[k] = self._constructor_sliced(v)
 
@@ -352,8 +352,8 @@ class Panel(NDFrame):
         orient = orient.lower()
         if orient == 'minor':
             new_data = OrderedDefaultdict(dict)
-            for col, df in data.iteritems():
-                for item, s in df.iteritems():
+            for col, df in compat.iteritems(data):
+                for item, s in compat.iteritems(df):
                     new_data[item][col] = s
             data = new_data
         elif orient != 'items':  # pragma: no cover
@@ -544,7 +544,7 @@ class Panel(NDFrame):
         y : SparseDataFrame
         """
         from pandas.core.sparse import SparsePanel
-        frames = dict(self.iteritems())
+        frames = dict(compat.iteritems(self))
         return SparsePanel(frames, items=self.items,
                            major_axis=self.major_axis,
                            minor_axis=self.minor_axis,
@@ -564,7 +564,7 @@ class Panel(NDFrame):
         """
         from pandas.io.excel import ExcelWriter
         writer = ExcelWriter(path)
-        for item, df in self.iteritems():
+        for item, df in compat.iteritems(self):
             name = str(item)
             df.to_excel(writer, name, na_rep=na_rep)
         writer.save()
@@ -980,7 +980,7 @@ class Panel(NDFrame):
             if method is None:
                 raise ValueError('must specify a fill method or value')
             result = {}
-            for col, s in self.iteritems():
+            for col, s in compat.iteritems(self):
                 result[col] = s.fillna(method=method, value=value)
 
             return self._constructor.from_dict(result)
@@ -1137,7 +1137,7 @@ class Panel(NDFrame):
         """
         # construct the args
         args = list(args)
-        aliases = tuple(kwargs.iterkeys())
+        aliases = tuple(six.iterkeys(kwargs))
 
         for a in self._AXIS_ORDERS:
             if not a in kwargs:
@@ -1518,7 +1518,7 @@ class Panel(NDFrame):
             result = OrderedDict()
 
         adj_frames = OrderedDict()
-        for k, v in frames.iteritems():
+        for k, v in compat.iteritems(frames):
             if isinstance(v, dict):
                 adj_frames[k] = self._constructor_sliced(v)
             else:
@@ -1531,7 +1531,7 @@ class Panel(NDFrame):
         reindex_dict = dict(
             [(self._AXIS_SLICEMAP[a], axes_dict[a]) for a in axes])
         reindex_dict['copy'] = False
-        for key, frame in adj_frames.iteritems():
+        for key, frame in compat.iteritems(adj_frames):
             if frame is not None:
                 result[key] = frame.reindex(**reindex_dict)
             else:
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index 436c22981..3e6e4ea36 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -776,7 +776,7 @@ def lreshape(data, groups, dropna=True, label=None):
         for c in pivot_cols:
             mask &= notnull(mdata[c])
         if not mask.all():
-            mdata = dict((k, v[mask]) for k, v in mdata.iteritems())
+            mdata = dict((k, v[mask]) for k, v in compat.iteritems(mdata))
 
     return DataFrame(mdata, columns=id_cols + pivot_cols)
 
diff --git a/pandas/io/__init__.py b/pandas/io/__init__.py
index a984c40cd..e69de29bb 100644
--- a/pandas/io/__init__.py
+++ b/pandas/io/__init__.py
@@ -1,2 +0,0 @@
-import sql
-import stata
diff --git a/pandas/io/data.py b/pandas/io/data.py
index 74268241d..afec82627 100644
--- a/pandas/io/data.py
+++ b/pandas/io/data.py
@@ -811,7 +811,7 @@ class Options(object):
         data : dict of str, DataFrame
         """
         warnings.warn("get_forward_data() is deprecated", FutureWarning)
-        in_months = range(CUR_MONTH, CUR_MONTH + months + 1)
+        in_months = list(range(CUR_MONTH, CUR_MONTH + months + 1))
         in_years = [CUR_YEAR] * (months + 1)
 
         # Figure out how many items in in_months go past 12
diff --git a/pandas/io/html.py b/pandas/io/html.py
index bcecc6244..3fee071cd 100644
--- a/pandas/io/html.py
+++ b/pandas/io/html.py
@@ -454,7 +454,7 @@ def _build_node_xpath_expr(attrs):
     if 'class_' in attrs:
         attrs['class'] = attrs.pop('class_')
 
-    s = (six.u("@{k}='{v}'").format(k=k, v=v) for k, v in attrs.iteritems())
+    s = (six.u("@{k}='{v}'").format(k=k, v=v) for k, v in compat.iteritems(attrs))
     return six.u('[{0}]').format(' and '.join(s))
 
 
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 57f1daa62..760d14467 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -486,7 +486,7 @@ class TextFileReader(object):
         kwds = self.orig_options
 
         options = {}
-        for argname, default in _parser_defaults.iteritems():
+        for argname, default in compat.iteritems(_parser_defaults):
             if argname in kwds:
                 value = kwds[argname]
             else:
@@ -494,7 +494,7 @@ class TextFileReader(object):
 
             options[argname] = value
 
-        for argname, default in _c_parser_defaults.iteritems():
+        for argname, default in compat.iteritems(_c_parser_defaults):
             if argname in kwds:
                 value = kwds[argname]
                 if engine != 'c' and value != default:
@@ -503,7 +503,7 @@ class TextFileReader(object):
             options[argname] = value
 
         if engine == 'python-fwf':
-            for argname, default in _fwf_defaults.iteritems():
+            for argname, default in compat.iteritems(_fwf_defaults):
                 if argname in kwds:
                     value = kwds[argname]
                 options[argname] = value
@@ -866,7 +866,7 @@ class ParserBase(object):
     def _convert_to_ndarrays(self, dct, na_values, na_fvalues, verbose=False,
                              converters=None):
         result = {}
-        for c, values in dct.iteritems():
+        for c, values in compat.iteritems(dct):
             conv_f = None if converters is None else converters.get(c, None)
             col_na_values, col_na_fvalues = _get_na_values(c, na_values, na_fvalues)
             coerce_type = True
@@ -1379,7 +1379,7 @@ class PythonParser(ParserBase):
         # apply converters
         clean_conv = {}
 
-        for col, f in self.converters.iteritems():
+        for col, f in compat.iteritems(self.converters):
             if isinstance(col, int) and col not in self.orig_names:
                 col = self.orig_names[col]
             clean_conv[col] = f
@@ -1733,7 +1733,7 @@ def _process_date_conversion(data_dict, converter, parse_spec,
 
     elif isinstance(parse_spec, dict):
         # dict of new name to column list
-        for new_name, colspec in parse_spec.iteritems():
+        for new_name, colspec in compat.iteritems(parse_spec):
             if new_name in data_dict:
                 raise ValueError('Date column %s already in dict' %
                                  new_name)
@@ -1782,7 +1782,7 @@ def _clean_na_values(na_values, keep_default_na=True):
         na_fvalues = set()
     elif isinstance(na_values, dict):
         if keep_default_na:
-            for k, v in na_values.iteritems():
+            for k, v in compat.iteritems(na_values):
                 v = set(list(v)) | _NA_VALUES
                 na_values[k] = v
         na_fvalues = dict([ (k, _floatify_na_values(v)) for k, v in na_values.items() ])
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 52cc7dc24..e18cd2d8c 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -1729,7 +1729,7 @@ class GenericStorer(Storer):
     """ a generified storer version """
     _index_type_map    = { DatetimeIndex: 'datetime',
                            PeriodIndex: 'period'}
-    _reverse_index_map = dict([ (v,k) for k, v in _index_type_map.iteritems() ])
+    _reverse_index_map = dict([ (v,k) for k, v in compat.iteritems(_index_type_map) ])
     attributes = []
 
     # indexer helpders
@@ -2104,7 +2104,7 @@ class SparseFrameStorer(GenericStorer):
     def write(self, obj, **kwargs):
         """ write it as a collection of individual sparse series """
         super(SparseFrameStorer, self).write(obj, **kwargs)
-        for name, ss in obj.iteritems():
+        for name, ss in compat.iteritems(obj):
             key = 'sparse_series_%s' % name
             if key not in self.group._v_children:
                 node = self._handle.createGroup(self.group, key)
@@ -2140,7 +2140,7 @@ class SparsePanelStorer(GenericStorer):
         self.attrs.default_kind       = obj.default_kind
         self.write_index('items', obj.items)
 
-        for name, sdf in obj.iteritems():
+        for name, sdf in compat.iteritems(obj):
             key = 'sparse_frame_%s' % name
             if key not in self.group._v_children:
                 node = self._handle.createGroup(self.group, key)
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 50b3d63cb..033f0cf0e 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -22,6 +22,7 @@ from pandas.core.series import Series
 from pandas.core.categorical import Categorical
 import datetime
 from pandas.util import py3compat
+from pandas.util import compat
 from pandas.util.py3compat import long
 from pandas import isnull
 from pandas.io.parsers import _parser_params, Appender
@@ -546,12 +547,12 @@ class StataReader(StataParser):
                 data[col] = data[col].apply(_stata_elapsed_date_to_datetime, args=(self.fmtlist[i],))
 
         if convert_categoricals:
-            cols = np.where(map(lambda x: x in self.value_label_dict.iterkeys(), self.lbllist))[0]
+            cols = np.where(map(lambda x: x in six.iterkeys(self.value_label_dict), self.lbllist))[0]
             for i in cols:
                 col = data.columns[i]
                 labeled_data = np.copy(data[col])
                 labeled_data = labeled_data.astype(object)
-                for k, v in self.value_label_dict[self.lbllist[i]].iteritems():
+                for k, v in compat.iteritems(self.value_label_dict[self.lbllist[i]]):
                     labeled_data[data[col] == k] = v
                 data[col] = Categorical.from_array(labeled_data)
 
diff --git a/pandas/io/tests/test_json/test_pandas.py b/pandas/io/tests/test_json/test_pandas.py
index 2aaffe404..b739181b7 100644
--- a/pandas/io/tests/test_json/test_pandas.py
+++ b/pandas/io/tests/test_json/test_pandas.py
@@ -29,7 +29,7 @@ _tsd = tm.getTimeSeriesData()
 _frame = DataFrame(_seriesd)
 _frame2 = DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])
 _intframe = DataFrame(dict((k, v.astype(np.int64))
-                           for k, v in _seriesd.iteritems()))
+                           for k, v in compat.iteritems(_seriesd)))
 
 _tsframe = DataFrame(_tsd)
 
@@ -95,7 +95,7 @@ class TestPandasContainer(unittest.TestCase):
                                   numpy=numpy, convert_axes=convert_axes)
             except (Exception) as detail:
                 if raise_ok is not None:
-                    if type(detail) == raise_ok:
+                    if isinstance(detail, raise_ok):
                         return
                     raise
 
diff --git a/pandas/io/tests/test_json/test_ujson.py b/pandas/io/tests/test_json/test_ujson.py
index a8f6ddffe..1e5e455dd 100644
--- a/pandas/io/tests/test_json/test_ujson.py
+++ b/pandas/io/tests/test_json/test_ujson.py
@@ -1471,7 +1471,7 @@ raise NotImplementedError("Implement this test!")
 """
 
 def _clean_dict(d):
-    return dict((str(k), v) for k, v in d.iteritems())
+    return dict((str(k), v) for k, v in compat.iteritems(d))
 
 if __name__ == '__main__':
     # unittest.main()
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 198de5d0f..08b6a40df 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -163,7 +163,7 @@ c,3
         expected = Series([1, 2, 3], ['a', 'b', 'c'])
         result = self.read_table(StringIO(data), sep=',', index_col=0,
                                  header=None, squeeze=True)
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_series_equal(result, expected)
 
     def test_inf_parsing(self):
@@ -802,7 +802,7 @@ c,4,5
         expected['aux_date'] = to_datetime(expected['aux_date'],
                                            dayfirst=True)
         expected['aux_date'] = list(map(Timestamp, expected['aux_date']))
-        self.assert_(isinstance(expected['aux_date'][0], datetime))
+        tm.assert_isinstance(expected['aux_date'][0], datetime)
 
         df = self.read_csv(StringIO(data), sep=";", index_col=list(range(4)),
                            parse_dates=[0, 5], dayfirst=True)
@@ -874,7 +874,7 @@ baz,7,8,9
     def test_read_table_unicode(self):
         fin = BytesIO(six.u('\u0141aski, Jan;1').encode('utf-8'))
         df1 = read_table(fin, sep=";", encoding="utf-8", header=None)
-        self.assert_(isinstance(df1[0].values[0], unicode))
+        tm.assert_isinstance(df1[0].values[0], six.text_type)
 
     def test_read_table_wrong_num_columns(self):
         # too few!
@@ -1051,7 +1051,7 @@ baz,7,8,9
 
         treader = self.read_table(StringIO(self.data1), sep=',', index_col=0,
                                   iterator=True)
-        self.assert_(isinstance(treader, TextFileReader))
+        tm.assert_isinstance(treader, TextFileReader)
 
         # stopping iteration when on chunksize is specified, GH 3967
         data = """A,B,C
@@ -1265,7 +1265,7 @@ c,4,5,01/03/2009
         expected = self.read_csv(StringIO(data))
         expected['D'] = expected['D'].map(parser.parse)
 
-        self.assert_(isinstance(result['D'][0], (datetime, Timestamp)))
+        tm.assert_isinstance(result['D'][0], (datetime, Timestamp))
         tm.assert_frame_equal(result, expected)
         tm.assert_frame_equal(result2, expected)
 
diff --git a/pandas/io/tests/test_pytables.py b/pandas/io/tests/test_pytables.py
index aff43cc91..ba5886ba1 100644
--- a/pandas/io/tests/test_pytables.py
+++ b/pandas/io/tests/test_pytables.py
@@ -1041,8 +1041,9 @@ class TestHDFStore(unittest.TestCase):
         print ("\nbig_table2 start")
         import time
         start_time = time.time()
-        df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
-            1000 * 1000)), columns=['E%03d' % i for i in range(60)])
+        df = DataFrame(np.random.randn(1000 * 1000, 60),
+                       index=list(range(int(1000 * 1000))),
+                       columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
         for x in range(20):
@@ -1070,8 +1071,8 @@ class TestHDFStore(unittest.TestCase):
         print ("\nbig_put start")
         import time
         start_time = time.time()
-        df = DataFrame(np.random.randn(1000 * 1000, 60), index=range(int(
-            1000 * 1000)), columns=['E%03d' % i for i in range(60)])
+        df = DataFrame(np.random.randn(1000 * 1000, 60), index=list(range(int(
+            1000 * 1000))), columns=['E%03d' % i for i in range(60)])
         for x in range(20):
             df['String%03d' % x] = 'string%03d' % x
         for x in range(20):
@@ -1405,7 +1406,7 @@ class TestHDFStore(unittest.TestCase):
         with ensure_clean(self.path) as store:
 
             # GH 4098 example
-            df = DataFrame(dict(A = Series(range(3), index=date_range('2000-1-1',periods=3,freq='H', tz='US/Eastern'))))
+            df = DataFrame(dict(A = Series(list(range(3)), index=date_range('2000-1-1',periods=3,freq='H', tz='US/Eastern'))))
 
             _maybe_remove(store, 'df')
             store.put('df',df)
@@ -2214,7 +2215,7 @@ class TestHDFStore(unittest.TestCase):
     def test_retain_index_attributes(self):
 
         # GH 3499, losing frequency info on index recreation
-        df = DataFrame(dict(A = Series(range(3),
+        df = DataFrame(dict(A = Series(list(range(3)),
                                        index=date_range('2000-1-1',periods=3,freq='H'))))
 
         with ensure_clean(self.path) as store:
@@ -2231,7 +2232,7 @@ class TestHDFStore(unittest.TestCase):
 
             # try to append a table with a different frequency
             warnings.filterwarnings('ignore', category=AttributeConflictWarning)
-            df2 = DataFrame(dict(A = Series(range(3),
+            df2 = DataFrame(dict(A = Series(list(range(3)),
                                             index=date_range('2002-1-1',periods=3,freq='D'))))
             store.append('data',df2)
             warnings.filterwarnings('always', category=AttributeConflictWarning)
@@ -2240,10 +2241,10 @@ class TestHDFStore(unittest.TestCase):
 
             # this is ok
             _maybe_remove(store,'df2')
-            df2 = DataFrame(dict(A = Series(range(3),
+            df2 = DataFrame(dict(A = Series(list(range(3)),
                                             index=[Timestamp('20010101'),Timestamp('20010102'),Timestamp('20020101')])))
             store.append('df2',df2)
-            df3 = DataFrame(dict(A = Series(range(3),index=date_range('2002-1-1',periods=3,freq='D'))))
+            df3 = DataFrame(dict(A = Series(list(range(3)),index=date_range('2002-1-1',periods=3,freq='D'))))
             store.append('df2',df3)
 
     def test_retain_index_attributes2(self):
@@ -2252,20 +2253,20 @@ class TestHDFStore(unittest.TestCase):
 
             warnings.filterwarnings('ignore', category=AttributeConflictWarning)
 
-            df  = DataFrame(dict(A = Series(range(3), index=date_range('2000-1-1',periods=3,freq='H'))))
+            df  = DataFrame(dict(A = Series(list(range(3)), index=date_range('2000-1-1',periods=3,freq='H'))))
             df.to_hdf(path,'data',mode='w',append=True)
-            df2 = DataFrame(dict(A = Series(range(3), index=date_range('2002-1-1',periods=3,freq='D'))))
+            df2 = DataFrame(dict(A = Series(list(range(3)), index=date_range('2002-1-1',periods=3,freq='D'))))
             df2.to_hdf(path,'data',append=True)
 
             idx = date_range('2000-1-1',periods=3,freq='H')
             idx.name = 'foo'
-            df  = DataFrame(dict(A = Series(range(3), index=idx)))
+            df  = DataFrame(dict(A = Series(list(range(3)), index=idx)))
             df.to_hdf(path,'data',mode='w',append=True)
             self.assert_(read_hdf(path,'data').index.name == 'foo')
 
             idx2 = date_range('2001-1-1',periods=3,freq='H')
             idx2.name = 'bar'
-            df2 = DataFrame(dict(A = Series(range(3), index=idx2)))
+            df2 = DataFrame(dict(A = Series(list(range(3)), index=idx2)))
             df2.to_hdf(path,'data',append=True)
             self.assert_(read_hdf(path,'data').index.name is None)
 
@@ -2389,7 +2390,7 @@ class TestHDFStore(unittest.TestCase):
             # valid
             result = store.select_column('df', 'index')
             tm.assert_almost_equal(result.values, Series(df.index).values)
-            self.assert_(isinstance(result,Series))
+            tm.assert_isinstance(result,Series)
 
             # not a data indexable column
             self.assertRaises(
@@ -2558,7 +2559,7 @@ class TestHDFStore(unittest.TestCase):
             result = store.select(
                 'df', [Term("columns", "=", ["A"])], start=30, stop=40)
             assert(len(result) == 0)
-            assert(type(result) == DataFrame)
+            tm.assert_isinstance(result, DataFrame)
 
     def test_select_filter_corner(self):
 
diff --git a/pandas/io/tests/test_stata.py b/pandas/io/tests/test_stata.py
index d75de149d..3f2115052 100644
--- a/pandas/io/tests/test_stata.py
+++ b/pandas/io/tests/test_stata.py
@@ -13,6 +13,7 @@ from pandas.io.parsers import read_csv
 from pandas.io.stata import read_stata, StataReader
 import pandas.util.testing as tm
 from pandas.util.misc import is_little_endian
+import six
 
 
 class StataTests(unittest.TestCase):
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 7bc6f818c..09e8bdb57 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -151,7 +151,7 @@ class SparseDataFrame(DataFrame):
         # pre-filter out columns if we passed it
         if columns is not None:
             columns = _ensure_index(columns)
-            data = dict((k, v) for k, v in data.iteritems() if k in columns)
+            data = dict((k, v) for k, v in compat.iteritems(data) if k in columns)
         else:
             columns = Index(_try_sort(data.keys()))
 
@@ -164,7 +164,7 @@ class SparseDataFrame(DataFrame):
                                           copy=True)
 
         sdict = {}
-        for k, v in data.iteritems():
+        for k, v in compat.iteritems(data):
             if isinstance(v, Series):
                 # Force alignment, no copy necessary
                 if not v.index.equals(index):
@@ -214,7 +214,7 @@ class SparseDataFrame(DataFrame):
 
     def __getstate__(self):
         series = dict((k, (v.sp_index, v.sp_values))
-                      for k, v in self.iteritems())
+                      for k, v in compat.iteritems(self))
         columns = self.columns
         index = self.index
 
@@ -235,7 +235,7 @@ class SparseDataFrame(DataFrame):
             index = idx
 
         series_dict = {}
-        for col, (sp_index, sp_values) in series.iteritems():
+        for col, (sp_index, sp_values) in compat.iteritems(series):
             series_dict[col] = SparseSeries(sp_values, sparse_index=sp_index,
                                             fill_value=fv)
 
@@ -253,13 +253,13 @@ class SparseDataFrame(DataFrame):
         -------
         df : DataFrame
         """
-        data = dict((k, v.to_dense()) for k, v in self.iteritems())
+        data = dict((k, v.to_dense()) for k, v in compat.iteritems(self))
         return DataFrame(data, index=self.index)
 
     def get_dtype_counts(self):
         from collections import defaultdict
         d = defaultdict(int)
-        for k, v in self.iteritems():
+        for k, v in compat.iteritems(self):
             d[v.dtype.name] += 1
         return Series(d)
 
@@ -270,7 +270,7 @@ class SparseDataFrame(DataFrame):
         """
         Make a copy of this SparseDataFrame
         """
-        series = dict((k, v.copy()) for k, v in self.iteritems())
+        series = dict((k, v.copy()) for k, v in compat.iteritems(self))
         return SparseDataFrame(series, index=self.index, columns=self.columns,
                                default_fill_value=self.default_fill_value,
                                default_kind=self.default_kind)
@@ -282,7 +282,7 @@ class SparseDataFrame(DataFrame):
         represented in the frame
         """
         tot_nonsparse = sum([ser.sp_index.npoints
-                             for _, ser in self.iteritems()])
+                             for _, ser in compat.iteritems(self)])
         tot = len(self.index) * len(self.columns)
         return tot_nonsparse / float(tot)
 
@@ -548,7 +548,7 @@ class SparseDataFrame(DataFrame):
         if other.index is not new_index:
             other = other.reindex(new_index)
 
-        for col, series in this.iteritems():
+        for col, series in compat.iteritems(this):
             new_data[col] = func(series.values, other.values)
 
         return self._constructor(new_data, index=new_index,
@@ -579,7 +579,7 @@ class SparseDataFrame(DataFrame):
 
     def _combine_const(self, other, func):
         new_data = {}
-        for col, series in self.iteritems():
+        for col, series in compat.iteritems(self):
             new_data[col] = func(series, other)
 
         return self._constructor(data=new_data, index=self.index,
@@ -605,7 +605,7 @@ class SparseDataFrame(DataFrame):
         need_mask = mask.any()
 
         new_series = {}
-        for col, series in self.iteritems():
+        for col, series in compat.iteritems(self):
             values = series.values
             new = values.take(indexer)
 
@@ -629,7 +629,7 @@ class SparseDataFrame(DataFrame):
             raise NotImplementedError
 
         # TODO: fill value handling
-        sdict = dict((k, v) for k, v in self.iteritems() if k in columns)
+        sdict = dict((k, v) for k, v in compat.iteritems(self) if k in columns)
         return SparseDataFrame(sdict, index=self.index, columns=columns,
                                default_fill_value=self.default_fill_value)
 
@@ -800,11 +800,11 @@ class SparseDataFrame(DataFrame):
         new_series = {}
         if offset is None:
             new_index = self.index
-            for col, s in self.iteritems():
+            for col, s in compat.iteritems(self):
                 new_series[col] = s.shift(periods)
         else:
             new_index = self.index.shift(periods, offset)
-            for col, s in self.iteritems():
+            for col, s in compat.iteritems(self):
                 new_series[col] = SparseSeries(s.sp_values, index=new_index,
                                                sparse_index=s.sp_index,
                                                fill_value=s.fill_value)
@@ -836,7 +836,7 @@ class SparseDataFrame(DataFrame):
 
         if isinstance(func, np.ufunc):
             new_series = {}
-            for k, v in self.iteritems():
+            for k, v in compat.iteritems(self):
                 applied = func(v)
                 applied.fill_value = func(applied.fill_value)
                 new_series[k] = applied
@@ -870,7 +870,7 @@ class SparseDataFrame(DataFrame):
     @Appender(DataFrame.fillna.__doc__)
     def fillna(self, value=None, method=None, inplace=False, limit=None):
         new_series = {}
-        for k, v in self.iteritems():
+        for k, v in compat.iteritems(self):
             new_series[k] = v.fillna(value=value, method=method, limit=limit)
 
         if inplace:
@@ -885,7 +885,7 @@ def stack_sparse_frame(frame):
     """
     Only makes sense when fill_value is NaN
     """
-    lengths = [s.sp_index.npoints for _, s in frame.iteritems()]
+    lengths = [s.sp_index.npoints for _, s in compat.iteritems(frame)]
     nobs = sum(lengths)
 
     # this is pretty fast
@@ -896,7 +896,7 @@ def stack_sparse_frame(frame):
     # TODO: Figure out whether this can be reached.
     # I think this currently can't be reached because you can't build a SparseDataFrame
     # with a non-np.NaN fill value (fails earlier).
-    for _, series in frame.iteritems():
+    for _, series in compat.iteritems(frame):
         if not np.isnan(series.fill_value):
             raise TypeError('This routine assumes NaN fill value')
 
@@ -936,7 +936,7 @@ def homogenize(series_dict):
 
     need_reindex = False
 
-    for _, series in series_dict.iteritems():
+    for _, series in compat.iteritems(series_dict):
         if not np.isnan(series.fill_value):
             raise TypeError('this method is only valid with NaN fill values')
 
@@ -948,7 +948,7 @@ def homogenize(series_dict):
 
     if need_reindex:
         output = {}
-        for name, series in series_dict.iteritems():
+        for name, series in compat.iteritems(series_dict):
             if not series.sp_index.equals(index):
                 series = series.sparse_reindex(index)
 
diff --git a/pandas/sparse/panel.py b/pandas/sparse/panel.py
index 746b91a89..494cbaf83 100644
--- a/pandas/sparse/panel.py
+++ b/pandas/sparse/panel.py
@@ -17,6 +17,7 @@ from pandas.sparse.frame import SparseDataFrame
 from pandas.util.decorators import deprecate
 
 import pandas.core.common as com
+import six
 
 
 class SparsePanelAxis(object):
@@ -34,7 +35,7 @@ class SparsePanelAxis(object):
         if isinstance(value, MultiIndex):
             raise NotImplementedError
 
-        for v in obj._frames.itervalues():
+        for v in six.itervalues(obj._frames):
             setattr(v, self.frame_attr, value)
 
         setattr(obj, self.cache_field, value)
@@ -334,7 +335,7 @@ class SparsePanel(Panel):
             new_frames = self._frames
 
         if copy:
-            new_frames = dict((k, v.copy()) for k, v in new_frames.iteritems())
+            new_frames = dict((k, v.copy()) for k, v in compat.iteritems(new_frames))
 
         return SparsePanel(new_frames, items=items,
                            major_axis=major,
@@ -349,7 +350,7 @@ class SparsePanel(Panel):
             return self._combinePanel(other, func)
         elif np.isscalar(other):
             new_frames = dict((k, func(v, other))
-                              for k, v in self.iteritems())
+                              for k, v in compat.iteritems(self))
             return self._new_like(new_frames)
 
     def _combineFrame(self, other, func, axis=0):
@@ -426,7 +427,7 @@ class SparsePanel(Panel):
         y : DataFrame
             index -> minor axis, columns -> items
         """
-        slices = dict((k, v.xs(key)) for k, v in self.iteritems())
+        slices = dict((k, v.xs(key)) for k, v in compat.iteritems(self))
         return DataFrame(slices, index=self.minor_axis, columns=self.items)
 
     def minor_xs(self, key):
@@ -443,7 +444,7 @@ class SparsePanel(Panel):
         y : SparseDataFrame
             index -> major axis, columns -> items
         """
-        slices = dict((k, v[key]) for k, v in self.iteritems())
+        slices = dict((k, v[key]) for k, v in compat.iteritems(self))
         return SparseDataFrame(slices, index=self.major_axis,
                                columns=self.items,
                                default_fill_value=self.default_fill_value,
@@ -455,7 +456,7 @@ SparseWidePanel = SparsePanel
 def _convert_frames(frames, index, columns, fill_value=np.nan, kind='block'):
     from pandas.core.panel import _get_combined_index
     output = {}
-    for item, df in frames.iteritems():
+    for item, df in compat.iteritems(frames):
         if not isinstance(df, SparseDataFrame):
             df = SparseDataFrame(df, default_kind=kind,
                                  default_fill_value=fill_value)
@@ -472,7 +473,7 @@ def _convert_frames(frames, index, columns, fill_value=np.nan, kind='block'):
     index = _ensure_index(index)
     columns = _ensure_index(columns)
 
-    for item, df in output.iteritems():
+    for item, df in compat.iteritems(output):
         if not (df.index.equals(index) and df.columns.equals(columns)):
             output[item] = df.reindex(index=index, columns=columns)
 
@@ -480,7 +481,7 @@ def _convert_frames(frames, index, columns, fill_value=np.nan, kind='block'):
 
 
 def _stack_sparse_info(frame):
-    lengths = [s.sp_index.npoints for _, s in frame.iteritems()]
+    lengths = [s.sp_index.npoints for _, s in compat.iteritems(frame)]
 
     # this is pretty fast
     minor_labels = np.repeat(np.arange(len(frame.columns)), lengths)
diff --git a/pandas/sparse/tests/test_array.py b/pandas/sparse/tests/test_array.py
index 96edc71d1..178f8ea8c 100644
--- a/pandas/sparse/tests/test_array.py
+++ b/pandas/sparse/tests/test_array.py
@@ -11,6 +11,7 @@ from pandas.core.series import Series
 from pandas.core.common import notnull
 from pandas.sparse.api import SparseArray
 from pandas.util.testing import assert_almost_equal, assertRaisesRegexp
+import pandas.util.testing as tm
 
 
 def assert_sp_array_equal(left, right):
@@ -129,19 +130,19 @@ class TestSparseArray(unittest.TestCase):
             res = op(first, second)
             exp = SparseArray(op(first.values, second.values),
                               fill_value=first.fill_value)
-            self.assert_(isinstance(res, SparseArray))
+            tm.assert_isinstance(res, SparseArray)
             assert_almost_equal(res.values, exp.values)
 
             res2 = op(first, second.values)
-            self.assert_(isinstance(res2, SparseArray))
+            tm.assert_isinstance(res2, SparseArray)
             assert_sp_array_equal(res, res2)
 
             res3 = op(first.values, second)
-            self.assert_(isinstance(res3, SparseArray))
+            tm.assert_isinstance(res3, SparseArray)
             assert_sp_array_equal(res, res3)
 
             res4 = op(first, 4)
-            self.assert_(isinstance(res4, SparseArray))
+            tm.assert_isinstance(res4, SparseArray)
             exp = op(first.values, 4)
             exp_fv = op(first.fill_value, 4)
             assert_almost_equal(res4.fill_value, exp_fv)
diff --git a/pandas/sparse/tests/test_libsparse.py b/pandas/sparse/tests/test_libsparse.py
index d31f919e2..f820142a6 100644
--- a/pandas/sparse/tests/test_libsparse.py
+++ b/pandas/sparse/tests/test_libsparse.py
@@ -7,6 +7,7 @@ from numpy import nan
 import numpy as np
 import operator
 from numpy.testing import assert_almost_equal, assert_equal
+import pandas.util.testing as tm
 
 from pandas.core.sparse import SparseSeries
 from pandas import DataFrame
@@ -288,7 +289,7 @@ class TestIntIndex(TestCase):
             # see if survive the round trip
             xbindex = xindex.to_int_index().to_block_index()
             ybindex = yindex.to_int_index().to_block_index()
-            self.assert_(isinstance(xbindex, BlockIndex))
+            tm.assert_isinstance(xbindex, BlockIndex)
             self.assert_(xbindex.equals(xindex))
             self.assert_(ybindex.equals(yindex))
         check_cases(_check_case)
diff --git a/pandas/sparse/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
index 75d58f483..5be3703dd 100644
--- a/pandas/sparse/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -87,7 +87,7 @@ def assert_sp_frame_equal(left, right, exact_indices=True):
     exact: Series SparseIndex objects must be exactly the same, otherwise just
     compare dense representations
     """
-    for col, series in left.iteritems():
+    for col, series in compat.iteritems(left):
         assert(col in right)
         # trade-off?
 
@@ -107,7 +107,7 @@ def assert_sp_frame_equal(left, right, exact_indices=True):
 
 
 def assert_sp_panel_equal(left, right, exact_indices=True):
-    for item, frame in left.iteritems():
+    for item, frame in compat.iteritems(left):
         assert(item in right)
         # trade-off?
         assert_sp_frame_equal(frame, right[item], exact_indices=exact_indices)
@@ -206,9 +206,9 @@ class TestSparseSeries(TestCase,
     def test_constructor(self):
         # test setup guys
         self.assert_(np.isnan(self.bseries.fill_value))
-        self.assert_(isinstance(self.bseries.sp_index, BlockIndex))
+        tm.assert_isinstance(self.bseries.sp_index, BlockIndex)
         self.assert_(np.isnan(self.iseries.fill_value))
-        self.assert_(isinstance(self.iseries.sp_index, IntIndex))
+        tm.assert_isinstance(self.iseries.sp_index, IntIndex)
 
         self.assertEquals(self.zbseries.fill_value, 0)
         assert_equal(self.zbseries.values, self.bseries.to_dense().fillna(0))
@@ -224,7 +224,7 @@ class TestSparseSeries(TestCase,
         # Sparse time series works
         date_index = bdate_range('1/1/2000', periods=len(self.bseries))
         s5 = SparseSeries(self.bseries, index=date_index)
-        self.assert_(isinstance(s5, SparseTimeSeries))
+        tm.assert_isinstance(s5, SparseTimeSeries)
 
         # pass Series
         bseries2 = SparseSeries(self.bseries.to_dense())
@@ -314,7 +314,7 @@ class TestSparseSeries(TestCase,
 
     def test_getitem(self):
         def _check_getitem(sp, dense):
-            for idx, val in dense.iteritems():
+            for idx, val in compat.iteritems(dense):
                 assert_almost_equal(val, sp[idx])
 
             for i in range(len(dense)):
@@ -367,11 +367,11 @@ class TestSparseSeries(TestCase,
     def test_getitem_slice(self):
         idx = self.bseries.index
         res = self.bseries[::2]
-        self.assert_(isinstance(res, SparseSeries))
+        tm.assert_isinstance(res, SparseSeries)
         assert_sp_series_equal(res, self.bseries.reindex(idx[::2]))
 
         res = self.bseries[:5]
-        self.assert_(isinstance(res, SparseSeries))
+        tm.assert_isinstance(res, SparseSeries)
         assert_sp_series_equal(res, self.bseries.reindex(idx[:5]))
 
         res = self.bseries[5:]
@@ -388,7 +388,7 @@ class TestSparseSeries(TestCase,
             def _compare(idx):
                 dense_result = dense.take(idx).values
                 sparse_result = sp.take(idx)
-                self.assert_(isinstance(sparse_result, SparseSeries))
+                tm.assert_isinstance(sparse_result, SparseSeries)
                 assert_almost_equal(dense_result, sparse_result.values)
 
             _compare([1., 2., 3., 4., 5., 0.])
@@ -626,7 +626,7 @@ class TestSparseSeries(TestCase,
                                        sparse_index=idx)
             homogenized = spf.homogenize(data)
 
-            for k, v in homogenized.iteritems():
+            for k, v in compat.iteritems(homogenized):
                 assert(v.sp_index.equals(expected))
 
         indices1 = [BlockIndex(10, [2], [7]),
@@ -682,13 +682,13 @@ class TestSparseSeries(TestCase,
     def test_cumsum(self):
         result = self.bseries.cumsum()
         expected = self.bseries.to_dense().cumsum()
-        self.assert_(isinstance(result, SparseSeries))
+        tm.assert_isinstance(result, SparseSeries)
         self.assertEquals(result.name, self.bseries.name)
         assert_series_equal(result.to_dense(), expected)
 
         result = self.zbseries.cumsum()
         expected = self.zbseries.to_dense().cumsum()
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_series_equal(result, expected)
 
     def test_combine_first(self):
@@ -753,15 +753,15 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
     def test_copy(self):
         cp = self.frame.copy()
-        self.assert_(isinstance(cp, SparseDataFrame))
+        tm.assert_isinstance(cp, SparseDataFrame)
         assert_sp_frame_equal(cp, self.frame)
         self.assert_(cp.index is self.frame.index)
 
     def test_constructor(self):
-        for col, series in self.frame.iteritems():
-            self.assert_(isinstance(series, SparseSeries))
+        for col, series in compat.iteritems(self.frame):
+            tm.assert_isinstance(series, SparseSeries)
 
-        self.assert_(isinstance(self.iframe['A'].sp_index, IntIndex))
+        tm.assert_isinstance(self.iframe['A'].sp_index, IntIndex)
 
         # constructed zframe from matrix above
         self.assertEquals(self.zframe['A'].fill_value, 0)
@@ -770,12 +770,12 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
         # construct no data
         sdf = SparseDataFrame(columns=np.arange(10), index=np.arange(10))
-        for col, series in sdf.iteritems():
-            self.assert_(isinstance(series, SparseSeries))
+        for col, series in compat.iteritems(sdf):
+            tm.assert_isinstance(series, SparseSeries)
 
         # construct from nested dict
         data = {}
-        for c, s in self.frame.iteritems():
+        for c, s in compat.iteritems(self.frame):
             data[c] = s.to_dict()
 
         sdf = SparseDataFrame(data)
@@ -836,9 +836,9 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         # GH 2873
         x = Series(np.random.randn(10000), name='a')
         x = x.to_sparse(fill_value=0)
-        self.assert_(isinstance(x,SparseSeries))
+        tm.assert_isinstance(x,SparseSeries)
         df = SparseDataFrame(x)
-        self.assert_(isinstance(df,SparseDataFrame))
+        tm.assert_isinstance(df,SparseDataFrame)
 
         x = Series(np.random.randn(10000), name ='a')
         y = Series(np.random.randn(10000), name ='b')
@@ -888,13 +888,13 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         df = DataFrame({'A': [nan, nan, nan, 1, 2],
                         'B': [1, 2, nan, nan, nan]})
         sdf = df.to_sparse()
-        self.assert_(isinstance(sdf, SparseDataFrame))
+        tm.assert_isinstance(sdf, SparseDataFrame)
         self.assert_(np.isnan(sdf.default_fill_value))
-        self.assert_(isinstance(sdf['A'].sp_index, BlockIndex))
+        tm.assert_isinstance(sdf['A'].sp_index, BlockIndex)
         tm.assert_frame_equal(sdf.to_dense(), df)
 
         sdf = df.to_sparse(kind='integer')
-        self.assert_(isinstance(sdf['A'].sp_index, IntIndex))
+        tm.assert_isinstance(sdf['A'].sp_index, IntIndex)
 
         df = DataFrame({'A': [0, 0, 0, 1, 2],
                         'B': [1, 2, 0, 0, 0]}, dtype=float)
@@ -962,7 +962,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
             if isinstance(a, DataFrame) and isinstance(db, DataFrame):
                 mixed_result = op(a, db)
-                self.assert_(isinstance(mixed_result, SparseDataFrame))
+                tm.assert_isinstance(mixed_result, SparseDataFrame)
                 assert_sp_frame_equal(mixed_result, sparse_result,
                                       exact_indices=False)
 
@@ -1010,7 +1010,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
         self.assert_(empty.empty)
 
         foo = self.frame + self.empty
-        self.assert_(isinstance(foo.index, DatetimeIndex))
+        tm.assert_isinstance(foo.index, DatetimeIndex)
         assert_frame_equal(foo, self.frame * np.nan)
 
         foo = self.empty + self.frame
@@ -1085,7 +1085,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
             # insert SparseSeries
             frame['E'] = frame['A']
-            self.assert_(isinstance(frame['E'], SparseSeries))
+            tm.assert_isinstance(frame['E'], SparseSeries)
             assert_sp_series_equal(frame['E'], frame['A'])
 
             # insert SparseSeries differently-indexed
@@ -1096,7 +1096,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
             # insert Series
             frame['F'] = frame['A'].to_dense()
-            self.assert_(isinstance(frame['F'], SparseSeries))
+            tm.assert_isinstance(frame['F'], SparseSeries)
             assert_sp_series_equal(frame['F'], frame['A'])
 
             # insert Series differently-indexed
@@ -1107,7 +1107,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
             # insert ndarray
             frame['H'] = np.random.randn(N)
-            self.assert_(isinstance(frame['H'], SparseSeries))
+            tm.assert_isinstance(frame['H'], SparseSeries)
 
             to_sparsify = np.random.randn(N)
             to_sparsify[N // 2:] = frame.default_fill_value
@@ -1178,7 +1178,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
 
     def test_apply(self):
         applied = self.frame.apply(np.sqrt)
-        self.assert_(isinstance(applied, SparseDataFrame))
+        tm.assert_isinstance(applied, SparseDataFrame)
         assert_almost_equal(applied.values, np.sqrt(self.frame.values))
 
         applied = self.fill_frame.apply(np.sqrt)
@@ -1190,7 +1190,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
                             self.frame.to_dense().apply(np.sum))
 
         broadcasted = self.frame.apply(np.sum, broadcast=True)
-        self.assert_(isinstance(broadcasted, SparseDataFrame))
+        tm.assert_isinstance(broadcasted, SparseDataFrame)
         assert_frame_equal(broadcasted.to_dense(),
                            self.frame.to_dense().apply(np.sum, broadcast=True))
 
@@ -1213,7 +1213,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
     def test_applymap(self):
         # just test that it works
         result = self.frame.applymap(lambda x: x * 2)
-        self.assert_(isinstance(result, SparseDataFrame))
+        tm.assert_isinstance(result, SparseDataFrame)
 
     def test_astype(self):
         self.assertRaises(Exception, self.frame.astype, np.int64)
@@ -1399,7 +1399,7 @@ class TestSparseDataFrame(TestCase, test_frame.SafeForSparse):
     def test_cumsum(self):
         result = self.frame.cumsum()
         expected = self.frame.to_dense().cumsum()
-        self.assert_(isinstance(result, SparseDataFrame))
+        tm.assert_isinstance(result, SparseDataFrame)
         assert_frame_equal(result.to_dense(), expected)
 
     def _check_all(self, check_func):
@@ -1535,9 +1535,9 @@ class TestSparsePanel(TestCase,
         def _test_roundtrip(panel):
             pickled = pickle.dumps(panel, protocol=pickle.HIGHEST_PROTOCOL)
             unpickled = pickle.loads(pickled)
-            self.assert_(isinstance(unpickled.items, Index))
-            self.assert_(isinstance(unpickled.major_axis, Index))
-            self.assert_(isinstance(unpickled.minor_axis, Index))
+            tm.assert_isinstance(unpickled.items, Index)
+            tm.assert_isinstance(unpickled.major_axis, Index)
+            tm.assert_isinstance(unpickled.minor_axis, Index)
             assert_sp_panel_equal(panel, unpickled)
 
         _test_roundtrip(self.panel)
@@ -1545,7 +1545,7 @@ class TestSparsePanel(TestCase,
     def test_dense_to_sparse(self):
         wp = Panel.from_dict(self.data_dict)
         dwp = wp.to_sparse()
-        self.assert_(isinstance(dwp['ItemA']['A'], SparseSeries))
+        tm.assert_isinstance(dwp['ItemA']['A'], SparseSeries)
 
     def test_to_dense(self):
         dwp = self.panel.to_dense()
diff --git a/pandas/stats/common.py b/pandas/stats/common.py
index 75ebc9284..c30b3e7a4 100644
--- a/pandas/stats/common.py
+++ b/pandas/stats/common.py
@@ -5,7 +5,7 @@ _WINDOW_TYPES = {
     2: 'expanding'
 }
 # also allow 'rolling' as key
-_WINDOW_TYPES.update((v, v) for k,v in _WINDOW_TYPES.items())
+_WINDOW_TYPES.update((v, v) for k,v in list(_WINDOW_TYPES.items()))
 _ADDITIONAL_CLUSTER_TYPES = set(("entity", "time"))
 
 def _get_cluster_type(cluster_type):
diff --git a/pandas/stats/ols.py b/pandas/stats/ols.py
index e9563dcd1..f1ac35cad 100644
--- a/pandas/stats/ols.py
+++ b/pandas/stats/ols.py
@@ -1254,7 +1254,7 @@ def _safe_update(d, other):
     """
     Combine dictionaries with non-overlapping keys
     """
-    for k, v in other.iteritems():
+    for k, v in compat.iteritems(other):
         if k in d:
             raise Exception('Duplicate regressor: %s' % k)
 
@@ -1320,7 +1320,7 @@ def _combine_rhs(rhs):
     elif isinstance(rhs, DataFrame):
         series = rhs.copy()
     elif isinstance(rhs, dict):
-        for name, value in rhs.iteritems():
+        for name, value in compat.iteritems(rhs):
             if isinstance(value, Series):
                 _safe_update(series, {name: value})
             elif isinstance(value, (dict, DataFrame)):
diff --git a/pandas/stats/plm.py b/pandas/stats/plm.py
index 44f0dcf2b..fb9f3aadc 100644
--- a/pandas/stats/plm.py
+++ b/pandas/stats/plm.py
@@ -263,7 +263,7 @@ class PanelOLS(OLS):
 
             val_map = cat_mappings.get(effect)
             if val_map:
-                val_map = dict((v, k) for k, v in val_map.iteritems())
+                val_map = dict((v, k) for k, v in compat.iteritems(val_map))
 
             if dropped_dummy or not self._use_all_dummies:
                 if effect in self._dropped_dummies:
@@ -672,7 +672,7 @@ class MovingPanelOLS(MovingOLS, PanelOLS):
 def create_ols_dict(attr):
     def attr_getter(self):
         d = {}
-        for k, v in self.results.iteritems():
+        for k, v in compat.iteritems(self.results):
             result = getattr(v, attr)
             d[k] = result
 
diff --git a/pandas/stats/tests/test_fama_macbeth.py b/pandas/stats/tests/test_fama_macbeth.py
index 593d6ab5e..2e55c3d5a 100644
--- a/pandas/stats/tests/test_fama_macbeth.py
+++ b/pandas/stats/tests/test_fama_macbeth.py
@@ -3,6 +3,7 @@ from pandas.stats.api import fama_macbeth
 from .common import assert_almost_equal, BaseTest
 
 from pandas.util.py3compat import range
+from pandas.util import compat
 import numpy as np
 
 
@@ -38,7 +39,7 @@ class TestFamaMacBeth(BaseTest):
             end = index[i + window - 1]
 
             x2 = {}
-            for k, v in x.iteritems():
+            for k, v in compat.iteritems(x):
                 x2[k] = v.truncate(start, end)
             y2 = y.truncate(start, end)
 
diff --git a/pandas/stats/tests/test_moments.py b/pandas/stats/tests/test_moments.py
index c948d2aba..3780455c0 100644
--- a/pandas/stats/tests/test_moments.py
+++ b/pandas/stats/tests/test_moments.py
@@ -434,7 +434,7 @@ class TestMoments(unittest.TestCase):
                           fill_value=None):
 
         series_result = func(self.series, 50)
-        self.assert_(isinstance(series_result, Series))
+        tm.assert_isinstance(series_result, Series)
 
         frame_result = func(self.frame, 50)
         self.assertEquals(type(frame_result), DataFrame)
@@ -568,7 +568,7 @@ class TestMoments(unittest.TestCase):
 
     def _check_ew_structures(self, func):
         series_result = func(self.series, com=10)
-        self.assert_(isinstance(series_result, Series))
+        tm.assert_isinstance(series_result, Series)
         frame_result = func(self.frame, com=10)
         self.assertEquals(type(frame_result), DataFrame)
 
@@ -769,7 +769,7 @@ class TestMoments(unittest.TestCase):
 
     def _check_expanding_structures(self, func):
         series_result = func(self.series)
-        self.assert_(isinstance(series_result, Series))
+        tm.assert_isinstance(series_result, Series)
         frame_result = func(self.frame)
         self.assertEquals(type(frame_result), DataFrame)
 
diff --git a/pandas/stats/tests/test_ols.py b/pandas/stats/tests/test_ols.py
index cbfbc0ad1..f9bcb6fab 100644
--- a/pandas/stats/tests/test_ols.py
+++ b/pandas/stats/tests/test_ols.py
@@ -22,9 +22,8 @@ from pandas.stats.plm import NonPooledPanelOLS, PanelOLS
 from pandas.util.testing import (assert_almost_equal, assert_series_equal,
                                  assert_frame_equal, assertRaisesRegexp)
 import pandas.util.testing as tm
-
-from common import BaseTest
-import six
+import pandas.util.compat as compat
+from .common import BaseTest
 
 _have_statsmodels = True
 try:
@@ -42,7 +41,7 @@ def _check_repr(obj):
 
 
 def _compare_ols_results(model1, model2):
-    assert(type(model1) == type(model2))
+    tm.assert_isinstance(model1, type(model2))
 
     if hasattr(model1, '_window_type'):
         _compare_moving_ols(model1, model2)
@@ -369,7 +368,7 @@ class TestOLSMisc(unittest.TestCase):
         y = lp.pop('ItemA')
         model = ols(y=y, x=lp, entity_effects=True, window=20)
         self.assert_(notnull(model.beta.values).all())
-        self.assert_(isinstance(model, PanelOLS))
+        tm.assert_isinstance(model, PanelOLS)
         model.summary
 
     def test_series_rhs(self):
@@ -390,7 +389,7 @@ class TestOLSMisc(unittest.TestCase):
 
         for attr in series_attrs:
             value = getattr(model, attr)
-            self.assert_(isinstance(value, Series))
+            tm.assert_isinstance(value, Series)
 
         # works
         model._results
@@ -531,7 +530,7 @@ class TestPanelOLS(BaseTest):
 
         stack_y = y.stack()
         stack_x = DataFrame(dict((k, v.stack())
-                                 for k, v in x.iteritems()))
+                                 for k, v in compat.iteritems(x)))
 
         weights = x.std('items')
         stack_weights = weights.stack()
diff --git a/pandas/stats/var.py b/pandas/stats/var.py
index b10d6b9fa..0aa7a50d8 100644
--- a/pandas/stats/var.py
+++ b/pandas/stats/var.py
@@ -62,7 +62,7 @@ class VAR(StringMixin):
         DataFrame
         """
         d = dict([(key, value.beta)
-                  for (key, value) in self.ols_results.iteritems()])
+                  for (key, value) in compat.iteritems(self.ols_results)])
         return DataFrame(d)
 
     def forecast(self, h):
@@ -80,7 +80,7 @@ class VAR(StringMixin):
         DataFrame
         """
         forecast = self._forecast_raw(h)[:, 0, :]
-        return DataFrame(forecast, index=range(1, 1 + h),
+        return DataFrame(forecast, index=list(range(1, 1 + h)),
                          columns=self._columns)
 
     def forecast_cov(self, h):
@@ -103,7 +103,7 @@ class VAR(StringMixin):
         DataFrame
         """
         return DataFrame(self._forecast_std_err_raw(h),
-                         index=range(1, 1 + h), columns=self._columns)
+                         index=list(range(1, 1 + h)), columns=self._columns)
 
     @cache_readonly
     def granger_causality(self):
@@ -135,13 +135,13 @@ class VAR(StringMixin):
                 lagged_data = self._lagged_data[i].filter(
                     self._columns - [col])
 
-                for key, value in lagged_data.iteritems():
+                for key, value in compat.iteritems(lagged_data):
                     d[col][_make_param_name(i, key)] = value
 
         f_stat_dict = {}
         p_value_dict = {}
 
-        for col, y in self._data.iteritems():
+        for col, y in compat.iteritems(self._data):
             ssr_full = (self.resid[col] ** 2).sum()
 
             f_stats = []
@@ -194,11 +194,11 @@ class VAR(StringMixin):
 
         d = {}
         for i in range(1, 1 + self._p):
-            for col, series in self._lagged_data[i].iteritems():
+            for col, series in compat.iteritems(self._lagged_data[i]):
                 d[_make_param_name(i, col)] = series
 
         result = dict([(col, ols(y=y, x=d, intercept=self._intercept))
-                       for col, y in self._data.iteritems()])
+                       for col, y in compat.iteritems(self._data)])
 
         return result
 
@@ -214,7 +214,7 @@ class VAR(StringMixin):
         DataFrame
         """
         d = dict([(col, series.resid)
-                  for (col, series) in self.ols_results.iteritems()])
+                  for (col, series) in compat.iteritems(self.ols_results)])
         return DataFrame(d, index=self._index)
 
     @cache_readonly
@@ -345,7 +345,7 @@ BIC:                            %(bic).3f
 
             for t in range(T + 1):
                 index = t + p
-                y = values.take(range(index, index - p, -1), axis=0).ravel()
+                y = values.take(list(range(index, index - p, -1)), axis=0).ravel()
                 trans_Z = np.hstack(([1], y))
                 trans_Z = trans_Z.reshape(1, len(trans_Z))
 
@@ -535,7 +535,7 @@ class PanelVAR(VAR):
         Returns the forecasts at 1, 2, ..., n timesteps in the future.
         """
         forecast = self._forecast_raw(h).T.swapaxes(1, 2)
-        index = range(1, 1 + h)
+        index = list(range(1, 1 + h))
         w = Panel(forecast, items=self._data.items, major_axis=index,
                   minor_axis=self._data.minor_axis)
         return w
@@ -552,7 +552,7 @@ class PanelVAR(VAR):
         DataFrame
         """
         d = dict([(key, value.resid)
-                  for (key, value) in self.ols_results.iteritems()])
+                  for (key, value) in compat.iteritems(self.ols_results)])
         return Panel.fromDict(d)
 
     def _data_xs(self, i):
diff --git a/pandas/tests/test_algos.py b/pandas/tests/test_algos.py
index 1e04403b3..4c832f785 100644
--- a/pandas/tests/test_algos.py
+++ b/pandas/tests/test_algos.py
@@ -37,13 +37,13 @@ class TestUnique(unittest.TestCase):
         arr = np.random.randint(0, 100, size=50)
 
         result = algos.unique(arr)
-        self.assert_(isinstance(result, np.ndarray))
+        tm.assert_isinstance(result, np.ndarray)
 
     def test_objects(self):
         arr = np.random.randint(0, 100, size=50).astype('O')
 
         result = algos.unique(arr)
-        self.assert_(isinstance(result, np.ndarray))
+        tm.assert_isinstance(result, np.ndarray)
 
     def test_object_refcount_bug(self):
         lst = ['A', 'B', 'C', 'D', 'E']
diff --git a/pandas/tests/test_categorical.py b/pandas/tests/test_categorical.py
index 2b70fbcff..9bab218e7 100644
--- a/pandas/tests/test_categorical.py
+++ b/pandas/tests/test_categorical.py
@@ -95,7 +95,7 @@ class TestCategorical(unittest.TestCase):
         arr = np.random.randn(4)
         factor = cut(arr, 4)
 
-        self.assert_(isinstance(factor, Categorical))
+        tm.assert_isinstance(factor, Categorical)
 
         result = value_counts(factor)
         expected = value_counts(np.asarray(factor))
diff --git a/pandas/tests/test_config.py b/pandas/tests/test_config.py
index a2b1ea437..ed6f641cb 100644
--- a/pandas/tests/test_config.py
+++ b/pandas/tests/test_config.py
@@ -1,6 +1,5 @@
 #!/usr/bin/python
 # -*- coding: utf-8 -*-
-from __future__ import with_statement  # support python 2.5
 import pandas as pd
 import unittest
 import warnings
diff --git a/pandas/tests/test_format.py b/pandas/tests/test_format.py
index 4b7ca2c70..50cf5a0d5 100644
--- a/pandas/tests/test_format.py
+++ b/pandas/tests/test_format.py
@@ -292,7 +292,7 @@ class TestDataFrameFormatting(unittest.TestCase):
         buf.getvalue()
 
         result = self.frame.to_string()
-        self.assert_(isinstance(result, unicode))
+        tm.assert_isinstance(result, six.text_type)
 
     def test_to_string_utf8_columns(self):
         n = six.u("\u05d0").encode('utf-8')
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index a3a799279..cd894ce2e 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -2,15 +2,19 @@ from __future__ import print_function
 # pylint: disable-msg=W0612,E1101
 from copy import deepcopy
 from datetime import datetime, timedelta, time
-from pandas.util.py3compat import StringIO
-from pandas.util.py3compat import range, long
-from pandas.util import compat
 import cPickle as pickle
 import operator
 import re
 import unittest
 import nose
 
+from pandas.util import py3compat
+from pandas.util.py3compat import StringIO, range, long
+from pandas.util.compat import OrderedDict
+from pandas.util import compat
+import six
+from six.moves import map, zip
+
 from numpy import random, nan
 from numpy.random import randn
 import numpy as np
@@ -35,16 +39,11 @@ from pandas.util.testing import (assert_almost_equal,
                                  assertRaisesRegexp,
                                  makeCustomDataframe as mkdf,
                                  ensure_clean)
-from pandas.util import py3compat
-from pandas.util.compat import OrderedDict
 
 import pandas.util.testing as tm
 import pandas.lib as lib
 
 from numpy.testing.decorators import slow
-import six
-from six.moves import map
-from six.moves import zip
 
 def _skip_if_no_scipy():
     try:
@@ -107,11 +106,11 @@ class CheckIndexing(object):
 
         # column access
 
-        for _, series in sl.iteritems():
+        for _, series in compat.iteritems(sl):
             self.assertEqual(20, len(series.index))
             self.assert_(tm.equalContents(series.index, sl.index))
 
-        for key, _ in self.frame._series.iteritems():
+        for key, _ in compat.iteritems(self.frame._series):
             self.assert_(self.frame[key] is not None)
 
         self.assert_('random' not in self.frame)
@@ -1428,7 +1427,7 @@ class CheckIndexing(object):
 
     def test_iteritems(self):
         df = DataFrame([[1, 2, 3], [4, 5, 6]], columns=['a', 'a', 'b'])
-        for k, v in df.iteritems():
+        for k, v in compat.iteritems(df):
             self.assertEqual(type(v), Series)
 
     def test_lookup(self):
@@ -1571,13 +1570,13 @@ class CheckIndexing(object):
 
         result = df.irow(0)
         result2 = df.ix[0]
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_almost_equal(result.values, df.values[0])
         assert_series_equal(result, result2)
 
         result = df.T.icol(0)
         result2 = df.T.ix[:, 0]
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_almost_equal(result.values, df.values[0])
         assert_series_equal(result, result2)
 
@@ -1637,7 +1636,7 @@ _tsd = tm.getTimeSeriesData()
 _frame = DataFrame(_seriesd)
 _frame2 = DataFrame(_seriesd, columns=['D', 'C', 'B', 'A'])
 _intframe = DataFrame(dict((k, v.astype(int))
-                           for k, v in _seriesd.iteritems()))
+                           for k, v in compat.iteritems(_seriesd)))
 
 _tsframe = DataFrame(_tsd)
 
@@ -1783,7 +1782,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.frame2 = _frame2.copy()
 
         # force these all to int64 to avoid platform testing issues
-        self.intframe = DataFrame(dict([ (c,s) for c,s in _intframe.iteritems() ]), dtype = np.int64)
+        self.intframe = DataFrame(dict([ (c,s) for c,s in compat.iteritems(_intframe) ]), dtype = np.int64)
         self.tsframe = _tsframe.copy()
         self.mixed_frame = _mixed_frame.copy()
         self.mixed_float  = DataFrame({ 'A': _frame['A'].copy().astype('float32'),
@@ -1979,7 +1978,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': np.random.randn(1000)})
 
         idf = df.set_index('A')
-        self.assert_(isinstance(idf.index, DatetimeIndex))
+        tm.assert_isinstance(idf.index, DatetimeIndex)
 
     def test_set_index_multiindexcolumns(self):
         columns = MultiIndex.from_tuples([('foo', 1), ('foo', 2), ('bar', 1)])
@@ -2074,7 +2073,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_(result.shape == (1,0))
 
         result = DataFrame([DataFrame(dict(A = list(range(5))))])
-        self.assert_(type(result.iloc[0,0]) == DataFrame)
+        tm.assert_isinstance(result.iloc[0,0], DataFrame)
 
     def test_constructor_mixed_dtypes(self):
 
@@ -2261,11 +2260,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         data = {'col1': tm.TestSubDict((x, 10.0 * x) for x in range(10)),
                 'col2': tm.TestSubDict((x, 20.0 * x) for x in range(10))}
         df = DataFrame(data)
-        refdf = DataFrame(dict((col, dict(val.iteritems()))
-                               for col, val in data.iteritems()))
+        refdf = DataFrame(dict((col, dict(compat.iteritems(val)))
+                               for col, val in compat.iteritems(data)))
         assert_frame_equal(refdf, df)
 
-        data = tm.TestSubDict(data.iteritems())
+        data = tm.TestSubDict(compat.iteritems(data))
         df = DataFrame(data)
         assert_frame_equal(refdf, df)
 
@@ -2273,7 +2272,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         from collections import defaultdict
         data = {}
         self.frame['B'][:10] = np.nan
-        for k, v in self.frame.iteritems():
+        for k, v in compat.iteritems(self.frame):
             dct = defaultdict(dict)
             dct.update(v.to_dict())
             data[k] = dct
@@ -2315,17 +2314,17 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_constructor_dict_dont_upcast(self):
         d = {'Col1': {'Row1': 'A String', 'Row2': np.nan}}
         df = DataFrame(d)
-        self.assert_(isinstance(df['Col1']['Row2'], float))
+        tm.assert_isinstance(df['Col1']['Row2'], float)
 
         dm = DataFrame([[1, 2], ['a', 'b']], index=[1, 2], columns=[1, 2])
-        self.assert_(isinstance(dm[1][1], int))
+        tm.assert_isinstance(dm[1][1], int)
 
     def test_constructor_dict_of_tuples(self):
         # GH #1491
         data = {'a': (1, 2, 3), 'b': (4, 5, 6)}
 
         result = DataFrame(data)
-        expected = DataFrame(dict((k, list(v)) for k, v in data.iteritems()))
+        expected = DataFrame(dict((k, list(v)) for k, v in compat.iteritems(data)))
         assert_frame_equal(result, expected, check_dtype=False)
 
     def test_constructor_ndarray(self):
@@ -2806,7 +2805,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                                       columns=self.mixed_frame.columns,
                                       orient='index')
         assert_frame_equal(recons, self.mixed_frame)
-        self.assert_(isinstance(recons['foo'][0], tuple))
+        tm.assert_isinstance(recons['foo'][0], tuple)
 
         rs = DataFrame.from_items([('A', [1, 2, 3]), ('B', [4, 5, 6])],
                                   orient='index', columns=['one', 'two', 'three'])
@@ -3251,7 +3250,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # mixed casting
         def _check_cast(df, v):
-            self.assert_(list(set([ s.dtype.name for _, s in df.iteritems() ]))[0] == v)
+            self.assert_(list(set([ s.dtype.name for _, s in compat.iteritems(df) ]))[0] == v)
 
         mn = self.all_mixed._get_numeric_data().copy()
         mn['little_float'] = np.array(12345.,dtype='float16')
@@ -3330,7 +3329,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
     def test_array_interface(self):
         result = np.sqrt(self.frame)
-        self.assert_(type(result) is type(self.frame))
+        tm.assert_isinstance(result, type(self.frame))
         self.assert_(result.index is self.frame.index)
         self.assert_(result.columns is self.frame.columns)
 
@@ -3354,20 +3353,20 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         }
         recons_data = DataFrame(test_data).to_dict()
 
-        for k, v in test_data.iteritems():
-            for k2, v2 in v.iteritems():
+        for k, v in compat.iteritems(test_data):
+            for k2, v2 in compat.iteritems(v):
                 self.assertEqual(v2, recons_data[k][k2])
 
         recons_data = DataFrame(test_data).to_dict("l")
 
-        for k, v in test_data.iteritems():
-            for k2, v2 in v.iteritems():
+        for k, v in compat.iteritems(test_data):
+            for k2, v2 in compat.iteritems(v):
                 self.assertEqual(v2, recons_data[k][int(k2) - 1])
 
         recons_data = DataFrame(test_data).to_dict("s")
 
-        for k, v in test_data.iteritems():
-            for k2, v2 in v.iteritems():
+        for k, v in compat.iteritems(test_data):
+            for k2, v2 in compat.iteritems(v):
                 self.assertEqual(v2, recons_data[k][k2])
 
     def test_to_records_dt64(self):
@@ -3602,12 +3601,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         tuples = []
         columns = []
         dtypes  = []
-        for dtype, b in blocks.iteritems():
+        for dtype, b in compat.iteritems(blocks):
             columns.extend(b.columns)
             dtypes.extend([ (c,np.dtype(dtype).descr[0][1]) for c in b.columns ])
         for i in range(len(df.index)):
             tup = []
-            for _, b in blocks.iteritems():
+            for _, b in compat.iteritems(blocks):
                 tup.extend(b.irow(i).values)
             tuples.append(tuple(tup))
 
@@ -3666,11 +3665,11 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # columns is in a different order here than the actual items iterated from the dict
         columns = []
-        for dtype, b in df.blocks.iteritems():
+        for dtype, b in compat.iteritems(df.blocks):
             columns.extend(b.columns)
 
-        asdict    = dict((x, y) for x, y in df.iteritems())
-        asdict2   = dict((x, y.values) for x, y in df.iteritems())
+        asdict    = dict((x, y) for x, y in compat.iteritems(df))
+        asdict2   = dict((x, y.values) for x, y in compat.iteritems(df))
 
         # dict of series & dict of ndarrays (have dtype info)
         results = []
@@ -3981,7 +3980,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'ints': list(range(5))}, columns=['floats', 'ints'])
 
         for tup in df.itertuples(index=False):
-            self.assert_(isinstance(tup[1], np.integer))
+            tm.assert_isinstance(tup[1], np.integer)
 
         df = DataFrame(data={"a": [1, 2, 3], "b": [4, 5, 6]})
         dfaa = df[['a', 'a']]
@@ -3997,16 +3996,16 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         idSum = self.frame + self.frame
         seriesSum = self.frame + colSeries
 
-        for col, series in idSum.iteritems():
-            for idx, val in series.iteritems():
+        for col, series in compat.iteritems(idSum):
+            for idx, val in compat.iteritems(series):
                 origVal = self.frame[col][idx] * 2
                 if not np.isnan(val):
                     self.assertEqual(val, origVal)
                 else:
                     self.assert_(np.isnan(origVal))
 
-        for col, series in seriesSum.iteritems():
-            for idx, val in series.iteritems():
+        for col, series in compat.iteritems(seriesSum):
+            for idx, val in compat.iteritems(series):
                 origVal = self.frame[col][idx] + colSeries[col]
                 if not np.isnan(val):
                     self.assertEqual(val, origVal)
@@ -4525,7 +4524,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         added = self.frame + series
 
-        for key, s in added.iteritems():
+        for key, s in compat.iteritems(added):
             assert_series_equal(s, self.frame[key] + series[key])
 
         larger_series = series.to_dict()
@@ -4533,7 +4532,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         larger_series = Series(larger_series)
         larger_added = self.frame + larger_series
 
-        for key, s in self.frame.iteritems():
+        for key, s in compat.iteritems(self.frame):
             assert_series_equal(larger_added[key], s + series[key])
         self.assert_('E' in larger_added)
         self.assert_(np.isnan(larger_added['E']).all())
@@ -4564,7 +4563,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             ts = self.tsframe['A']
             added = self.tsframe + ts
 
-            for key, col in self.tsframe.iteritems():
+            for key, col in compat.iteritems(self.tsframe):
                 assert_series_equal(added[key], col + ts)
 
             smaller_frame = self.tsframe[:-5]
@@ -4596,7 +4595,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # vs mix
         result = self.mixed_float * 2
-        for c, s in result.iteritems():
+        for c, s in compat.iteritems(result):
             self.assert_(np.array_equal(s.values, self.mixed_float[c].values * 2))
         _check_mixed_float(result, dtype = dict(C = None))
 
@@ -4824,7 +4823,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                        recons = DataFrame.from_csv(path,header=0,parse_dates=False)
 
                def _to_uni(x):
-                   if not isinstance(x,unicode):
+                   if not isinstance(x, six.text_type):
                        return x.decode('utf8')
                    return x
                if dupe_col:
@@ -5449,7 +5448,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.mixed_frame['bool'] = self.mixed_frame['A'] > 0
         result = self.mixed_frame.dtypes
         expected = Series(dict((k, v.dtype)
-                               for k, v in self.mixed_frame.iteritems()),
+                               for k, v in compat.iteritems(self.mixed_frame)),
                           index=result.index)
         assert_series_equal(result, expected)
 
@@ -5599,10 +5598,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                        index=[datetime(2011, 11, 1), datetime(2011, 11, 2),
                               datetime(2011, 11, 3)])
         df = df.asfreq('B')
-        self.assert_(isinstance(df.index, DatetimeIndex))
+        tm.assert_isinstance(df.index, DatetimeIndex)
 
         ts = df['A'].asfreq('B')
-        self.assert_(isinstance(ts.index, DatetimeIndex))
+        tm.assert_isinstance(ts.index, DatetimeIndex)
 
     def test_at_time_between_time_datetimeindex(self):
         index = pan.date_range("2012-01-01", "2012-01-05", freq='30min')
@@ -5700,7 +5699,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         cp = deepcopy(self.frame)
         series = cp['A']
         series[:] = 10
-        for idx, value in series.iteritems():
+        for idx, value in compat.iteritems(series):
             self.assertNotEqual(self.frame['A'][idx], value)
 
     def test_copy(self):
@@ -6158,8 +6157,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                   ['', '', '', 'OD'],
                   ['', '', '', 'wx']]
 
-        tuples = list(zip(*arrays))
-        tuples.sort()
+        tuples = sorted(zip(*arrays))
         index = MultiIndex.from_tuples(tuples)
 
         df = DataFrame(randn(3, 4), columns=index)
@@ -7018,7 +7016,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'C': ['', 'asdf', 'fd']})
         filled = df.replace(to_rep, values)
         expected = {}
-        for k, v in df.iteritems():
+        for k, v in compat.iteritems(df):
             expected[k] = v.replace(to_rep[k], values[k])
         assert_frame_equal(filled, DataFrame(expected))
 
@@ -7030,7 +7028,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # dict to scalar
         filled = df.replace(to_rep, 0)
         expected = {}
-        for k, v in df.iteritems():
+        for k, v in compat.iteritems(df):
             expected[k] = v.replace(to_rep[k], 0)
         assert_frame_equal(filled, DataFrame(expected))
 
@@ -7042,7 +7040,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'C': ['', 'asdf', 'fd']})
         filled = df.replace(np.nan, values)
         expected = {}
-        for k, v in df.iteritems():
+        for k, v in compat.iteritems(df):
             expected[k] = v.replace(np.nan, values[k])
         assert_frame_equal(filled, DataFrame(expected))
 
@@ -7128,7 +7126,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_xs(self):
         idx = self.frame.index[5]
         xs = self.frame.xs(idx)
-        for item, value in xs.iteritems():
+        for item, value in compat.iteritems(xs):
             if np.isnan(value):
                 self.assert_(np.isnan(self.frame[item][idx]))
             else:
@@ -7244,7 +7242,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         newFrame = self.frame.reindex(self.ts1.index)
 
         for col in newFrame.columns:
-            for idx, val in newFrame[col].iteritems():
+            for idx, val in compat.iteritems(newFrame[col]):
                 if idx in self.frame.index:
                     if np.isnan(val):
                         self.assert_(np.isnan(self.frame[col][idx]))
@@ -7253,7 +7251,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                 else:
                     self.assert_(np.isnan(val))
 
-        for col, series in newFrame.iteritems():
+        for col, series in compat.iteritems(newFrame):
             self.assert_(tm.equalContents(series.index, newFrame.index))
         emptyFrame = self.frame.reindex(Index([]))
         self.assert_(len(emptyFrame.index) == 0)
@@ -7262,7 +7260,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         nonContigFrame = self.frame.reindex(self.ts1.index[::2])
 
         for col in nonContigFrame.columns:
-            for idx, val in nonContigFrame[col].iteritems():
+            for idx, val in compat.iteritems(nonContigFrame[col]):
                 if idx in self.frame.index:
                     if np.isnan(val):
                         self.assert_(np.isnan(self.frame[col][idx]))
@@ -7271,7 +7269,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                 else:
                     self.assert_(np.isnan(val))
 
-        for col, series in nonContigFrame.iteritems():
+        for col, series in compat.iteritems(nonContigFrame):
             self.assert_(tm.equalContents(series.index,
                                           nonContigFrame.index))
 
@@ -7552,13 +7550,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             # only add to the numeric items
             def is_ok(s):
                 return issubclass(s.dtype.type, (np.integer,np.floating)) and s.dtype != 'uint8'
-            return DataFrame(dict([ (c,s+1) if is_ok(s) else (c,s) for c, s in df.iteritems() ]))
+            return DataFrame(dict([ (c,s+1) if is_ok(s) else (c,s) for c, s in compat.iteritems(df) ]))
 
         def _check_get(df, cond, check_dtypes = True):
             other1 = _safe_add(df)
             rs = df.where(cond, other1)
             rs2 = df.where(cond.values, other1)
-            for k, v in rs.iteritems():
+            for k, v in compat.iteritems(rs):
                 assert_series_equal(v, np.where(cond[k], df[k], other1[k]))
             assert_frame_equal(rs, rs2)
 
@@ -7652,7 +7650,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
             # dtypes (and confirm upcasts)x
             if check_dtypes:
-                for k, v in df.dtypes.iteritems():
+                for k, v in compat.iteritems(df.dtypes):
                     if issubclass(v.type,np.integer) and not cond[k].all():
                         v = np.dtype('float64')
                     self.assert_(dfi[k].dtype == v)
@@ -7726,8 +7724,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_transpose(self):
         frame = self.frame
         dft = frame.T
-        for idx, series in dft.iteritems():
-            for col, value in series.iteritems():
+        for idx, series in compat.iteritems(dft):
+            for col, value in compat.iteritems(series):
                 if np.isnan(value):
                     self.assert_(np.isnan(frame[col][idx]))
                 else:
@@ -7738,7 +7736,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         mixed = DataFrame(data, index=index)
 
         mixed_T = mixed.T
-        for col, s in mixed_T.iteritems():
+        for col, s in compat.iteritems(mixed_T):
             self.assert_(s.dtype == np.object_)
 
     def test_transpose_get_view(self):
@@ -8045,7 +8043,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         broadcasted = self.frame.apply(np.mean, broadcast=True)
         agged = self.frame.apply(np.mean)
 
-        for col, ts in broadcasted.iteritems():
+        for col, ts in compat.iteritems(broadcasted):
             self.assert_((ts == agged[col]).all())
 
         broadcasted = self.frame.apply(np.mean, axis=1, broadcast=True)
@@ -8102,10 +8100,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                 res = df.apply(f, axis=axis, raw=raw)
                 if is_reduction:
                     agg_axis = df._get_agg_axis(axis)
-                    self.assert_(isinstance(res, Series))
+                    tm.assert_isinstance(res, Series)
                     self.assert_(res.index is agg_axis)
                 else:
-                    self.assert_(isinstance(res, DataFrame))
+                    tm.assert_isinstance(res, DataFrame)
 
             _checkit()
             _checkit(axis=1)
@@ -8118,7 +8116,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         _check(no_index, lambda x: x.mean())
 
         result = no_cols.apply(lambda x: x.mean(), broadcast=True)
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
 
     def test_apply_with_args_kwds(self):
         def add_some(x, howmuch=0):
@@ -8157,13 +8155,13 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         result0 = df.apply(Series.describe, axis=0)
         expected0 = DataFrame(dict((i, v.describe())
-                                   for i, v in df.iteritems()),
+                                   for i, v in compat.iteritems(df)),
                               columns=df.columns)
         assert_frame_equal(result0, expected0)
 
         result1 = df.apply(Series.describe, axis=1)
         expected1 = DataFrame(dict((i, v.describe())
-                                   for i, v in df.T.iteritems()),
+                                   for i, v in compat.iteritems(df.T)),
                               columns=df.index).T
         assert_frame_equal(result1, expected1)
 
@@ -8254,7 +8252,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         s.index = MultiIndex.from_arrays([['a','a','b'], ['c','d','d']])
         s.columns = ['col1','col2']
         res = s.apply(lambda x: Series({'min': min(x), 'max': max(x)}), 1)
-        self.assert_(isinstance(res.index, MultiIndex))
+        tm.assert_isinstance(res.index, MultiIndex)
 
     def test_applymap(self):
         applied = self.frame.applymap(lambda x: x * 2)
@@ -8263,7 +8261,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
 
         # GH #465, function returning tuples
         result = self.frame.applymap(lambda x: (x, x))
-        self.assert_(isinstance(result['A'][0], tuple))
+        tm.assert_isinstance(result['A'][0], tuple)
 
         # GH 2909, object conversion to float in constructor?
         df = DataFrame(data=[1,'a'])
@@ -8550,7 +8548,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assertRaises(Exception, s.sort)
 
         cp = s.copy()
-        cp.sort()  # it works!
+        cp.sort() # it works!
 
     def test_combine_first(self):
         # disjoint
@@ -8960,10 +8958,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         # corner case
         frame = DataFrame()
         ct1 = frame.count(1)
-        self.assert_(isinstance(ct1, Series))
+        tm.assert_isinstance(ct1, Series)
 
         ct2 = frame.count(0)
-        self.assert_(isinstance(ct2, Series))
+        tm.assert_isinstance(ct2, Series)
 
         # GH #423
         df = DataFrame(index=list(range(10)))
@@ -9215,8 +9213,8 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
     def test_sum_corner(self):
         axis0 = self.empty.sum(0)
         axis1 = self.empty.sum(1)
-        self.assert_(isinstance(axis0, Series))
-        self.assert_(isinstance(axis1, Series))
+        tm.assert_isinstance(axis0, Series)
+        tm.assert_isinstance(axis1, Series)
         self.assertEquals(len(axis0), 0)
         self.assertEquals(len(axis1), 0)
 
@@ -9492,7 +9490,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
                         'B': ['a', 'b', 'c', 'd'] * 6})
         desc = df.describe()
         expected = DataFrame(dict((k, v.describe())
-                                  for k, v in df.iteritems()),
+                                  for k, v in compat.iteritems(df)),
                              columns=df.columns)
         assert_frame_equal(desc, expected)
 
@@ -10310,12 +10308,12 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
             assert_frame_equal(result, expected)
 
     def test_iterkv_names(self):
-        for k, v in self.mixed_frame.iteritems():
+        for k, v in compat.iteritems(self.mixed_frame):
             self.assertEqual(v.name, k)
 
     def test_series_put_names(self):
         series = self.mixed_frame._series
-        for k, v in series.iteritems():
+        for k, v in compat.iteritems(series):
             self.assertEqual(v.name, k)
 
     def test_dot(self):
diff --git a/pandas/tests/test_graphics.py b/pandas/tests/test_graphics.py
index 53c169a7a..ebc00bb7c 100644
--- a/pandas/tests/test_graphics.py
+++ b/pandas/tests/test_graphics.py
@@ -425,7 +425,7 @@ class TestDataFramePlots(unittest.TestCase):
         pd.plot_params['x_compat'] = False
         ax = df.plot()
         lines = ax.get_lines()
-        self.assert_(isinstance(lines[0].get_xdata(), PeriodIndex))
+        tm.assert_isinstance(lines[0].get_xdata(), PeriodIndex)
 
         plt.close('all')
         # useful if you're plotting a bunch together
@@ -437,7 +437,7 @@ class TestDataFramePlots(unittest.TestCase):
         plt.close('all')
         ax = df.plot()
         lines = ax.get_lines()
-        self.assert_(isinstance(lines[0].get_xdata(), PeriodIndex))
+        tm.assert_isinstance(lines[0].get_xdata(), PeriodIndex)
 
     def test_unsorted_index(self):
         df = DataFrame({'y': np.arange(100)},
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 28756a1c0..a0ec25ab1 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -1,6 +1,7 @@
 from __future__ import print_function
 from pandas.util.py3compat import range, long
 from pandas.util import compat
+from six.moves import map, zip, builtins
 import nose
 import unittest
 
@@ -26,8 +27,6 @@ from numpy.testing import assert_equal
 import pandas.core.nanops as nanops
 
 import pandas.util.testing as tm
-from six.moves import map
-from six.moves import zip
 
 
 def commonSetUp(self):
@@ -36,7 +35,7 @@ def commonSetUp(self):
 
     self.groupId = Series([x[0] for x in self.stringIndex],
                           index=self.stringIndex)
-    self.groupDict = dict((k, v) for k, v in self.groupId.iteritems())
+    self.groupDict = dict((k, v) for k, v in compat.iteritems(self.groupId))
 
     self.columnIndex = Index(['A', 'B', 'C', 'D', 'E'])
 
@@ -290,7 +289,7 @@ class TestGroupBy(unittest.TestCase):
             return dataf["val2"]  - dataf["val2"].mean()
 
         result = df1.groupby("val1", squeeze=True).apply(func)
-        self.assert_(isinstance(result,Series))
+        tm.assert_isinstance(result,Series)
 
         df2 = DataFrame([{"val1": 1, "val2" : 20}, {"val1":1, "val2": 19},
                          {"val1":1, "val2": 27}, {"val1":1, "val2": 12}])
@@ -298,12 +297,12 @@ class TestGroupBy(unittest.TestCase):
             return dataf["val2"]  - dataf["val2"].mean()
 
         result = df2.groupby("val1", squeeze=True).apply(func)
-        self.assert_(isinstance(result,Series))
+        tm.assert_isinstance(result,Series)
 
         # GH3596, return a consistent type (regression in 0.11 from 0.10.1)
         df = DataFrame([[1,1],[1,1]],columns=['X','Y'])
         result = df.groupby('X',squeeze=False).count()
-        self.assert_(isinstance(result,DataFrame))
+        tm.assert_isinstance(result,DataFrame)
 
     def test_agg_regression1(self):
         grouped = self.tsframe.groupby([lambda x: x.year, lambda x: x.month])
@@ -340,7 +339,7 @@ class TestGroupBy(unittest.TestCase):
         prng = period_range('2012-1-1', freq='M', periods=3)
         df = DataFrame(np.random.randn(3, 2), index=prng)
         rs = df.groupby(level=0).sum()
-        self.assert_(isinstance(rs.index, PeriodIndex))
+        tm.assert_isinstance(rs.index, PeriodIndex)
 
         # GH 3579
         index = period_range(start='1999-01', periods=5, freq='M')
@@ -433,13 +432,13 @@ class TestGroupBy(unittest.TestCase):
         groups = grouped.groups
         self.assert_(groups is grouped.groups)  # caching works
 
-        for k, v in grouped.groups.iteritems():
+        for k, v in compat.iteritems(grouped.groups):
             self.assert_((self.df.ix[v]['A'] == k).all())
 
         grouped = self.df.groupby(['A', 'B'])
         groups = grouped.groups
         self.assert_(groups is grouped.groups)  # caching works
-        for k, v in grouped.groups.iteritems():
+        for k, v in compat.iteritems(grouped.groups):
             self.assert_((self.df.ix[v]['A'] == k[0]).all())
             self.assert_((self.df.ix[v]['B'] == k[1]).all())
 
@@ -495,7 +494,7 @@ class TestGroupBy(unittest.TestCase):
         def aggfun(ser):
             return ser.size
         result = DataFrame().groupby(self.df.A).agg(aggfun)
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
         self.assertEqual(len(result), 0)
 
     def test_agg_item_by_item_raise_typeerror(self):
@@ -855,7 +854,7 @@ class TestGroupBy(unittest.TestCase):
         groups = grouped.groups
         indices = grouped.indices
 
-        for k, v in groups.iteritems():
+        for k, v in compat.iteritems(groups):
             samething = self.tsframe.index.take(indices[k])
             self.assertTrue((samething == v).all())
 
@@ -1046,7 +1045,7 @@ class TestGroupBy(unittest.TestCase):
             for n1, gp1 in data.groupby('A'):
                 for n2, gp2 in gp1.groupby('B'):
                     expected[n1][n2] = op(gp2.ix[:, ['C', 'D']])
-            expected = dict((k, DataFrame(v)) for k, v in expected.iteritems())
+            expected = dict((k, DataFrame(v)) for k, v in compat.iteritems(expected))
             expected = Panel.fromDict(expected).swapaxes(0, 1)
             expected.major_axis.name, expected.minor_axis.name = 'A', 'B'
 
@@ -1120,22 +1119,22 @@ class TestGroupBy(unittest.TestCase):
 
         result = grouped['C'].agg(np.sum)
         expected = grouped.agg(np.sum).ix[:, ['A', 'C']]
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
         assert_frame_equal(result, expected)
 
         result2 = grouped2['C'].agg(np.sum)
         expected2 = grouped2.agg(np.sum).ix[:, ['A', 'B', 'C']]
-        self.assert_(isinstance(result2, DataFrame))
+        tm.assert_isinstance(result2, DataFrame)
         assert_frame_equal(result2, expected2)
 
         result = grouped['C'].sum()
         expected = grouped.sum().ix[:, ['A', 'C']]
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
         assert_frame_equal(result, expected)
 
         result2 = grouped2['C'].sum()
         expected2 = grouped2.sum().ix[:, ['A', 'B', 'C']]
-        self.assert_(isinstance(result2, DataFrame))
+        tm.assert_isinstance(result2, DataFrame)
         assert_frame_equal(result2, expected2)
 
         # corner case
@@ -1372,7 +1371,7 @@ class TestGroupBy(unittest.TestCase):
 
         keys = [np.array([0, 0, 1]), np.array([0, 0, 1])]
         agged = df.groupby(keys).agg(np.mean)
-        self.assert_(isinstance(agged.columns, MultiIndex))
+        tm.assert_isinstance(agged.columns, MultiIndex)
 
         def aggfun(ser):
             if ser.name == ('foo', 'one'):
@@ -1516,7 +1515,7 @@ class TestGroupBy(unittest.TestCase):
         grouped = ts.groupby(lambda x: x.month)
         result = grouped.apply(f)
 
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
         self.assert_(result.index.equals(ts.index))
 
     def test_apply_series_yield_constant(self):
@@ -1892,11 +1891,11 @@ class TestGroupBy(unittest.TestCase):
 
         result = grouped.agg(convert_fast)
         self.assert_(result.dtype == np.object_)
-        self.assert_(isinstance(result[0], Decimal))
+        tm.assert_isinstance(result[0], Decimal)
 
         result = grouped.agg(convert_force_pure)
         self.assert_(result.dtype == np.object_)
-        self.assert_(isinstance(result[0], Decimal))
+        tm.assert_isinstance(result[0], Decimal)
 
     def test_apply_with_mixed_dtype(self):
         # GH3480, apply with mixed dtype on axis=1 breaks in 0.11
@@ -2041,7 +2040,7 @@ class TestGroupBy(unittest.TestCase):
         tups = com._asarray_tuplesafe(tups)
         expected = df.groupby(tups).sum()['values']
 
-        for k, v in expected.iteritems():
+        for k, v in compat.iteritems(expected):
             self.assert_(left[k] == right[k[::-1]] == v)
         self.assert_(len(left) == len(right))
 
@@ -2076,12 +2075,11 @@ class TestGroupBy(unittest.TestCase):
         _check_groupby(df, result, ['a', 'b'], 'd')
 
     def test_intercept_builtin_sum(self):
-        import __builtin__
         s = Series([1., 2., np.nan, 3.])
         grouped = s.groupby([0, 1, 2, 2])
 
-        result = grouped.agg(__builtin__.sum)
-        result2 = grouped.apply(__builtin__.sum)
+        result = grouped.agg(builtins.sum)
+        result2 = grouped.apply(builtins.sum)
         expected = grouped.sum()
         assert_series_equal(result, expected)
         assert_series_equal(result2, expected)
@@ -2189,7 +2187,7 @@ class TestGroupBy(unittest.TestCase):
         result = self.df.groupby('A')['C'].apply(f)
         expected = self.df.groupby('A')['C'].apply(g)
 
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_series_equal(result, expected)
 
     def test_getitem_list_of_columns(self):
@@ -2378,7 +2376,7 @@ class TestGroupBy(unittest.TestCase):
 
         # it works!
         groups = grouped.groups
-        self.assert_(isinstance(groups.keys()[0], datetime))
+        tm.assert_isinstance(groups.keys()[0], datetime)
 
     def test_groupby_reindex_inside_function(self):
         from pandas.tseries.api import DatetimeIndex
@@ -2681,7 +2679,7 @@ def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
     tups = list(map(tuple, df[keys].values))
     tups = com._asarray_tuplesafe(tups)
     expected = f(df.groupby(tups)[field])
-    for k, v in expected.iteritems():
+    for k, v in compat.iteritems(expected):
         assert(result[k] == v)
 
 
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 2141a6fc9..d77c60ecb 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -45,7 +45,7 @@ class TestIndex(unittest.TestCase):
     def test_new_axis(self):
         new_index = self.dateIndex[None, :]
         self.assert_(new_index.ndim == 2)
-        self.assert_(type(new_index) == np.ndarray)
+        tm.assert_isinstance(new_index, np.ndarray)
 
     def test_deepcopy(self):
         from copy import deepcopy
@@ -77,7 +77,7 @@ class TestIndex(unittest.TestCase):
         # copy
         arr = np.array(self.strIndex)
         index = Index(arr, copy=True, name='name')
-        self.assert_(isinstance(index, Index))
+        tm.assert_isinstance(index, Index)
         self.assert_(index.name == 'name')
         assert_array_equal(arr, index)
 
@@ -94,7 +94,7 @@ class TestIndex(unittest.TestCase):
         xp = period_range('2012-1-1', freq='M', periods=3)
         rs = Index(xp)
         assert_array_equal(rs, xp)
-        self.assert_(isinstance(rs, PeriodIndex))
+        tm.assert_isinstance(rs, PeriodIndex)
 
     def test_copy(self):
         i = Index([], name='Foo')
@@ -142,7 +142,7 @@ class TestIndex(unittest.TestCase):
         self.assert_(self.dateIndex.asof(d + timedelta(1)) == d)
 
         d = self.dateIndex[0].to_datetime()
-        self.assert_(isinstance(self.dateIndex.asof(d), Timestamp))
+        tm.assert_isinstance(self.dateIndex.asof(d), Timestamp)
 
     def test_argsort(self):
         result = self.strIndex.argsort()
@@ -160,7 +160,7 @@ class TestIndex(unittest.TestCase):
             arr_result = op(arr, element)
             index_result = op(index, element)
 
-            self.assert_(isinstance(index_result, np.ndarray))
+            tm.assert_isinstance(index_result, np.ndarray)
             self.assert_(not isinstance(index_result, Index))
             self.assert_(np.array_equal(arr_result, index_result))
 
@@ -334,7 +334,7 @@ class TestIndex(unittest.TestCase):
             pickled = pickle.dumps(index)
             unpickled = pickle.loads(pickled)
 
-            self.assert_(isinstance(unpickled, Index))
+            tm.assert_isinstance(unpickled, Index)
             self.assert_(np.array_equal(unpickled, index))
             self.assertEquals(unpickled.name, index.name)
 
@@ -600,11 +600,11 @@ class TestInt64Index(unittest.TestCase):
     def test_coerce_list(self):
         # coerce things
         arr = Index([1, 2, 3, 4])
-        self.assert_(type(arr) == Int64Index)
+        tm.assert_isinstance(arr, Int64Index)
 
         # but not if explicit dtype passed
         arr = Index([1, 2, 3, 4], dtype=object)
-        self.assert_(type(arr) == Index)
+        tm.assert_isinstance(arr, Index)
 
     def test_dtype(self):
         self.assert_(self.index.dtype == np.int64)
@@ -655,7 +655,7 @@ class TestInt64Index(unittest.TestCase):
         eridx = np.array([-1, 3, 4, -1, 5, -1, 0, -1, -1, 1, -1, -1, -1, 2],
                          dtype=np.int64)
 
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(np.array_equal(ridx, eridx))
@@ -668,7 +668,7 @@ class TestInt64Index(unittest.TestCase):
 
         eridx = np.array([-1, 0, 1, -1, 2, -1, 3, -1, -1, 4, -1, -1, -1, 5],
                          dtype=np.int64)
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(np.array_equal(ridx, eridx))
@@ -691,7 +691,7 @@ class TestInt64Index(unittest.TestCase):
         elidx = np.array([1, 6])
         eridx = np.array([4, 1])
 
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(np.array_equal(ridx, eridx))
@@ -704,7 +704,7 @@ class TestInt64Index(unittest.TestCase):
         self.assert_(res.equals(res2))
 
         eridx = np.array([1, 4])
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(np.array_equal(ridx, eridx))
@@ -720,7 +720,7 @@ class TestInt64Index(unittest.TestCase):
         eridx = np.array([-1, 4, -1, -1, -1, -1, 1, -1, -1, -1],
                          dtype=np.int64)
 
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(lidx is None)
         self.assert_(np.array_equal(ridx, eridx))
@@ -730,7 +730,7 @@ class TestInt64Index(unittest.TestCase):
                                           return_indexers=True)
         eridx = np.array([-1, 1, -1, -1, -1, -1, 4, -1, -1, -1],
                          dtype=np.int64)
-        self.assert_(isinstance(res, Int64Index))
+        tm.assert_isinstance(res, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(lidx is None)
         self.assert_(np.array_equal(ridx, eridx))
@@ -759,7 +759,7 @@ class TestInt64Index(unittest.TestCase):
         elidx = np.array([-1, 6, -1, -1, 1, -1],
                          dtype=np.int64)
 
-        self.assert_(isinstance(other, Int64Index))
+        tm.assert_isinstance(other, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(ridx is None)
@@ -770,7 +770,7 @@ class TestInt64Index(unittest.TestCase):
         eres = other_mono
         elidx = np.array([-1, 1, -1, -1, 6, -1],
                          dtype=np.int64)
-        self.assert_(isinstance(other, Int64Index))
+        tm.assert_isinstance(other, Int64Index)
         self.assert_(res.equals(eres))
         self.assert_(np.array_equal(lidx, elidx))
         self.assert_(ridx is None)
@@ -947,7 +947,7 @@ class TestMultiIndex(unittest.TestCase):
         single_level = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux']],
                                   labels=[[0, 1, 2, 3]],
                                   names=['first'])
-        self.assert_(isinstance(single_level, Index))
+        tm.assert_isinstance(single_level, Index)
         self.assert_(not isinstance(single_level, MultiIndex))
         self.assert_(single_level.name == 'first')
 
@@ -1504,7 +1504,7 @@ class TestMultiIndex(unittest.TestCase):
                                           sortorder=0,
                                           names=self.index.names)
 
-        self.assert_(isinstance(result, MultiIndex))
+        tm.assert_isinstance(result, MultiIndex)
         self.assert_(result.equals(expected))
         self.assertEqual(result.names, self.index.names)
 
@@ -1725,16 +1725,16 @@ class TestMultiIndex(unittest.TestCase):
         # some corner cases
         idx = Index(['three', 'one', 'two'])
         result = idx.join(self.index, level='second')
-        self.assert_(isinstance(result, MultiIndex))
+        tm.assert_isinstance(result, MultiIndex)
 
         self.assertRaises(Exception, self.index.join, self.index, level=1)
 
     def test_reindex(self):
         result, indexer = self.index.reindex(list(self.index[:4]))
-        self.assert_(isinstance(result, MultiIndex))
+        tm.assert_isinstance(result, MultiIndex)
 
         result, indexer = self.index.reindex(list(self.index))
-        self.assert_(isinstance(result, MultiIndex))
+        tm.assert_isinstance(result, MultiIndex)
         self.assert_(indexer is None)
 
     def test_reindex_level(self):
diff --git a/pandas/tests/test_indexing.py b/pandas/tests/test_indexing.py
index b72b1f387..b7297fc86 100644
--- a/pandas/tests/test_indexing.py
+++ b/pandas/tests/test_indexing.py
@@ -211,7 +211,7 @@ class TestIndexing(unittest.TestCase):
 
                 # if we are in fails, the ok, otherwise raise it
                 if fails is not None:
-                    if fails == type(detail):
+                    if isinstance(detail, fails):
                         result = 'ok (%s)' % type(detail).__name__
                         _print(result)
                         return
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index d152e6ed1..5d3171365 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -75,26 +75,26 @@ class TestMultiLevel(unittest.TestCase):
         multi = DataFrame(np.random.randn(4, 4),
                           index=[np.array(['a', 'a', 'b', 'b']),
                                  np.array(['x', 'y', 'x', 'y'])])
-        self.assert_(isinstance(multi.index, MultiIndex))
+        tm.assert_isinstance(multi.index, MultiIndex)
         self.assert_(not isinstance(multi.columns, MultiIndex))
 
         multi = DataFrame(np.random.randn(4, 4),
                           columns=[['a', 'a', 'b', 'b'],
                                    ['x', 'y', 'x', 'y']])
-        self.assert_(isinstance(multi.columns, MultiIndex))
+        tm.assert_isinstance(multi.columns, MultiIndex)
 
     def test_series_constructor(self):
         multi = Series(1., index=[np.array(['a', 'a', 'b', 'b']),
                                   np.array(['x', 'y', 'x', 'y'])])
-        self.assert_(isinstance(multi.index, MultiIndex))
+        tm.assert_isinstance(multi.index, MultiIndex)
 
         multi = Series(1., index=[['a', 'a', 'b', 'b'],
                                   ['x', 'y', 'x', 'y']])
-        self.assert_(isinstance(multi.index, MultiIndex))
+        tm.assert_isinstance(multi.index, MultiIndex)
 
         multi = Series(list(range(4)), index=[['a', 'a', 'b', 'b'],
                                         ['x', 'y', 'x', 'y']])
-        self.assert_(isinstance(multi.index, MultiIndex))
+        tm.assert_isinstance(multi.index, MultiIndex)
 
     def test_reindex_level(self):
         # axis=0
@@ -580,7 +580,7 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
         s = dft['foo', 'two']
         dft['foo', 'two'] = s > s.median()
         assert_series_equal(dft['foo', 'two'], s > s.median())
-        self.assert_(isinstance(dft._data.blocks[1].items, MultiIndex))
+        tm.assert_isinstance(dft._data.blocks[1].items, MultiIndex)
 
         reindexed = dft.reindex(columns=[('foo', 'two')])
         assert_series_equal(reindexed['foo', 'two'], s > s.median())
@@ -676,12 +676,12 @@ x   q   30      3    -0.6662 -0.5243 -0.3580  0.89145  2.5838"""
         self.assertEquals(len(deleveled.columns), len(self.ymd.columns))
 
         deleveled = self.series.reset_index()
-        self.assert_(isinstance(deleveled, DataFrame))
+        tm.assert_isinstance(deleveled, DataFrame)
         self.assert_(
             len(deleveled.columns) == len(self.series.index.levels) + 1)
 
         deleveled = self.series.reset_index(drop=True)
-        self.assert_(isinstance(deleveled, Series))
+        tm.assert_isinstance(deleveled, Series)
 
     def test_sortlevel_by_name(self):
         self.frame.index.names = ['first', 'second']
@@ -1095,7 +1095,7 @@ Thur,Lunch,Yes,51.51,17"""
     def test_insert_index(self):
         df = self.ymd[:5].T
         df[2000, 1, 10] = df[2000, 1, 7]
-        self.assert_(isinstance(df.columns, MultiIndex))
+        tm.assert_isinstance(df.columns, MultiIndex)
         self.assert_((df[2000, 1, 10] == df[2000, 1, 7]).all())
 
     def test_alignment(self):
@@ -1499,8 +1499,7 @@ Thur,Lunch,Yes,51.51,17"""
                   ['', 'OD', 'OD', 'result1', 'result2', 'result1'],
                   ['', 'wx', 'wy', '', '', '']]
 
-        tuples = list(zip(*arrays))
-        tuples.sort()
+        tuples = sorted(zip(*arrays))
         index = MultiIndex.from_tuples(tuples)
         df = DataFrame(randn(4, 6), columns=index)
 
@@ -1519,8 +1518,7 @@ Thur,Lunch,Yes,51.51,17"""
                   ['', 'OD', 'OD', 'result1', 'result2', 'result1'],
                   ['', 'wx', 'wy', '', '', '']]
 
-        tuples = list(zip(*arrays))
-        tuples.sort()
+        tuples = sorted(zip(*arrays))
         index = MultiIndex.from_tuples(tuples)
         df = DataFrame(randn(4, 6), columns=index)
 
@@ -1535,8 +1533,7 @@ Thur,Lunch,Yes,51.51,17"""
                   ['', 'OD', 'OD', 'result1', 'result2', 'result1'],
                   ['', 'wx', 'wy', '', '', '']]
 
-        tuples = list(zip(*arrays))
-        tuples.sort()
+        tuples = sorted(zip(*arrays))
         index = MultiIndex.from_tuples(tuples)
         df = DataFrame(randn(4, 6), columns=index)
 
@@ -1587,8 +1584,7 @@ Thur,Lunch,Yes,51.51,17"""
                   ['', 'OD', 'OD', 'result1', 'result2', 'result1'],
                   ['', 'wx', 'wy', '', '', '']]
 
-        tuples = list(zip(*arrays))
-        tuples.sort()
+        tuples = sorted(zip(*arrays))
         index = MultiIndex.from_tuples(tuples)
         df = DataFrame(randn(4, 6), columns=index)
 
@@ -1750,7 +1746,7 @@ Thur,Lunch,Yes,51.51,17"""
 
         result = frame.ix[:, 1]
         exp = frame.icol(1)
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         assert_series_equal(result, exp)
 
     def test_nonunique_assignment_1750(self):
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index d8c45ed65..69fae70bd 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -273,10 +273,10 @@ class SafeForSparse(object):
     def test_iteritems(self):
         # Test panel.iteritems(), aka panel.iteritems()
         # just test that it works
-        for k, v in self.panel.iteritems():
+        for k, v in compat.iteritems(self.panel):
             pass
 
-        self.assertEqual(len(list(self.panel.iteritems())),
+        self.assertEqual(len(list(compat.iteritems(self.panel))),
                          len(self.panel.items))
 
     def test_combineFrame(self):
@@ -731,7 +731,7 @@ class CheckIndexing(object):
 
         # resize
         res = self.panel.set_value('ItemE', 'foo', 'bar', 1.5)
-        self.assert_(isinstance(res, Panel))
+        tm.assert_isinstance(res, Panel)
         self.assert_(res is not self.panel)
         self.assertEqual(res.get_value('ItemE', 'foo', 'bar'), 1.5)
 
@@ -882,19 +882,19 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
 
         # cast
         dcasted = dict((k, v.reindex(wp.major_axis).fillna(0))
-                       for k, v in d.iteritems())
+                       for k, v in compat.iteritems(d))
         result = Panel(dcasted, dtype=int)
         expected = Panel(dict((k, v.astype(int))
-                              for k, v in dcasted.iteritems()))
+                              for k, v in compat.iteritems(dcasted)))
         assert_panel_equal(result, expected)
 
         result = Panel(dcasted, dtype=np.int32)
         expected = Panel(dict((k, v.astype(np.int32))
-                              for k, v in dcasted.iteritems()))
+                              for k, v in compat.iteritems(dcasted)))
         assert_panel_equal(result, expected)
 
     def test_constructor_dict_mixed(self):
-        data = dict((k, v.values) for k, v in self.panel.iteritems())
+        data = dict((k, v.values) for k, v in compat.iteritems(self.panel))
         result = Panel(data)
         exp_major = Index(np.arange(len(self.panel.major_axis)))
         self.assert_(result.major_axis.equals(exp_major))
@@ -1284,7 +1284,7 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
         # negative numbers, #2164
         result = self.panel.shift(-1)
         expected = Panel(dict((i, f.shift(-1)[:-1])
-                              for i, f in self.panel.iteritems()))
+                              for i, f in compat.iteritems(self.panel)))
         assert_panel_equal(result, expected)
 
     def test_multiindex_get(self):
@@ -1383,7 +1383,7 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
                 except ImportError:
                     raise nose.SkipTest
 
-                for item, df in self.panel.iteritems():
+                for item, df in compat.iteritems(self.panel):
                     recdf = reader.parse(str(item), index_col=0)
                     assert_frame_equal(df, recdf)
 
diff --git a/pandas/tests/test_panel4d.py b/pandas/tests/test_panel4d.py
index 4119d2b5a..31f5bc64a 100644
--- a/pandas/tests/test_panel4d.py
+++ b/pandas/tests/test_panel4d.py
@@ -23,6 +23,7 @@ from pandas.util.testing import (assert_panel_equal,
                                  assert_series_equal,
                                  assert_almost_equal)
 import pandas.util.testing as tm
+import pandas.util.compat as compat
 
 
 def add_nans(panel4d):
@@ -221,7 +222,7 @@ class SafeForSparse(object):
     def test_iteritems(self):
         """Test panel4d.iteritems()"""
 
-        self.assertEqual(len(list(self.panel4d.iteritems())),
+        self.assertEqual(len(list(compat.iteritems(self.panel4d))),
                          len(self.panel4d.labels))
 
     def test_combinePanel4d(self):
@@ -534,7 +535,7 @@ class CheckIndexing(object):
 
         # resize
         res = self.panel4d.set_value('l4', 'ItemE', 'foo', 'bar', 1.5)
-        self.assert_(isinstance(res, Panel4D))
+        tm.assert_isinstance(res, Panel4D)
         self.assert_(res is not self.panel4d)
         self.assertEqual(res.get_value('l4', 'ItemE', 'foo', 'bar'), 1.5)
 
@@ -656,7 +657,7 @@ class TestPanel4d(unittest.TestCase, CheckIndexing, SafeForSparse,
         # assert_panel_equal(result, expected)
 
     def test_constructor_dict_mixed(self):
-        data = dict((k, v.values) for k, v in self.panel4d.iteritems())
+        data = dict((k, v.values) for k, v in compat.iteritems(self.panel4d))
         result = Panel4D(data)
         exp_major = Index(np.arange(len(self.panel4d.major_axis)))
         self.assert_(result.major_axis.equals(exp_major))
diff --git a/pandas/tests/test_rplot.py b/pandas/tests/test_rplot.py
index 18f0c76b4..0dfae47dd 100644
--- a/pandas/tests/test_rplot.py
+++ b/pandas/tests/test_rplot.py
@@ -1,6 +1,7 @@
 from pandas.util.py3compat import range
 import unittest
 import pandas.tools.rplot as rplot
+import pandas.util.testing as tm
 from pandas import read_csv
 import os
 
@@ -51,7 +52,7 @@ class TestUtilityFunctions(unittest.TestCase):
         self.assertTrue(aes['colour'] is None)
         self.assertTrue(aes['shape'] is None)
         self.assertTrue(aes['alpha'] is None)
-        self.assertTrue(type(aes) is dict)
+        self.assertTrue(isinstance(aes, dict))
 
     def test_make_aes2(self):
         self.assertRaises(ValueError, rplot.make_aes,
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index f53b62474..84fbc4397 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -285,11 +285,11 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_constructor(self):
         # Recognize TimeSeries
-        self.assert_(isinstance(self.ts, TimeSeries))
+        tm.assert_isinstance(self.ts, TimeSeries)
 
         # Pass in Series
         derived = Series(self.ts)
-        self.assert_(isinstance(derived, TimeSeries))
+        tm.assert_isinstance(derived, TimeSeries)
 
         self.assert_(tm.equalContents(derived.index, self.ts.index))
         # Ensure new index is not created
@@ -297,7 +297,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         # Pass in scalar
         scalar = Series(0.5)
-        self.assert_(isinstance(scalar, float))
+        tm.assert_isinstance(scalar, float)
 
         # Mixed type Series
         mixed = Series(['hello', np.NaN], index=[0, 1])
@@ -428,7 +428,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         df = tm.makeTimeDataFrame()
         objs = [df, df]
         s = Series(objs, index=[0, 1])
-        self.assert_(isinstance(s, Series))
+        tm.assert_isinstance(s, Series)
 
     def test_constructor_sanitize(self):
         s = Series(np.array([1., 1., 8.]), dtype='i8')
@@ -516,7 +516,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
     def test_constructor_subclass_dict(self):
         data = tm.TestSubDict((x, 10.0 * x) for x in range(10))
         series = Series(data)
-        refseries = Series(dict(data.iteritems()))
+        refseries = Series(dict(compat.iteritems(data)))
         assert_series_equal(refseries, series)
 
     def test_orderedDict_ctor(self):
@@ -583,7 +583,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         # works
         series = self.series.copy()
         series.index = np.arange(len(series))
-        self.assert_(isinstance(series.index, Index))
+        tm.assert_isinstance(series.index, Index)
 
     def test_array_finalize(self):
         pass
@@ -780,7 +780,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_getitem_box_float64(self):
         value = self.ts[5]
-        self.assert_(isinstance(value, np.float64))
+        tm.assert_isinstance(value, np.float64)
 
     def test_getitem_ambiguous_keyerror(self):
         s = Series(list(range(10)), index=list(range(0, 20, 2)))
@@ -1415,10 +1415,10 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assert_(np.array_equal(self.ts, self.ts.values))
 
     def test_iteritems(self):
-        for idx, val in self.series.iteritems():
+        for idx, val in compat.iteritems(self.series):
             self.assertEqual(val, self.series[idx])
 
-        for idx, val in self.ts.iteritems():
+        for idx, val in compat.iteritems(self.ts):
             self.assertEqual(val, self.ts[idx])
 
     def test_sum(self):
@@ -1703,7 +1703,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
     def test_append(self):
         appendedSeries = self.series.append(self.objSeries)
-        for idx, value in appendedSeries.iteritems():
+        for idx, value in compat.iteritems(appendedSeries):
             if idx in self.series.index:
                 self.assertEqual(value, self.series[idx])
             elif idx in self.objSeries.index:
@@ -1907,7 +1907,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         # scalar Timestamp on rhs
         maxa = df['A'].max()
-        self.assert_(isinstance(maxa,Timestamp))
+        tm.assert_isinstance(maxa,Timestamp)
 
         resultb = df['A']- df['A'].max()
         self.assert_(resultb.dtype=='timedelta64[ns]')
@@ -2038,7 +2038,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
     def test_sub_of_datetime_from_TimeSeries(self):
         from pandas.core import common as com
         from datetime import datetime
-        a = Timestamp(datetime(1993,01,07,13,30,00))
+        a = Timestamp(datetime(1993,0o1,0o7,13,30,00))
         b = datetime(1993, 6, 22, 13, 30)
         a = Series([a])
         result = com._possibly_cast_to_timedelta(np.abs(a - b))
@@ -2875,7 +2875,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         result = self.ts.clip(-0.5, 0.5)
         expected = np.clip(self.ts, -0.5, 0.5)
         assert_series_equal(result, expected)
-        self.assert_(isinstance(expected, Series))
+        tm.assert_isinstance(expected, Series)
 
     def test_clip_types_and_nulls(self):
 
@@ -3369,13 +3369,13 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         merged = target.map(source)
 
-        for k, v in merged.iteritems():
+        for k, v in compat.iteritems(merged):
             self.assertEqual(v, source[target[k]])
 
         # input could be a dict
         merged = target.map(source.to_dict())
 
-        for k, v in merged.iteritems():
+        for k, v in compat.iteritems(merged):
             self.assertEqual(v, source[target[k]])
 
         # function
@@ -3404,7 +3404,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         result = self.series.map(lambda x: Decimal(str(x)))
         self.assert_(result.dtype == np.object_)
-        self.assert_(isinstance(result[0], Decimal))
+        tm.assert_isinstance(result[0], Decimal)
 
     def test_map_na_exclusion(self):
         s = Series([1.5, np.nan, 3, np.nan, 5])
@@ -3655,13 +3655,13 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         subIndex = self.series.index[10:20]
         subSeries = self.series.reindex(subIndex)
 
-        for idx, val in subSeries.iteritems():
+        for idx, val in compat.iteritems(subSeries):
             self.assertEqual(val, self.series[idx])
 
         subIndex2 = self.ts.index[10:20]
         subTS = self.ts.reindex(subIndex2)
 
-        for idx, val in subTS.iteritems():
+        for idx, val in compat.iteritems(subTS):
             self.assertEqual(val, self.ts[idx])
         stuffSeries = self.ts.reindex(subIndex)
 
@@ -3670,7 +3670,7 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         # This is extremely important for the Cython code to not screw up
         nonContigIndex = self.ts.index[::2]
         subNonContig = self.ts.reindex(nonContigIndex)
-        for idx, val in subNonContig.iteritems():
+        for idx, val in compat.iteritems(subNonContig):
             self.assertEqual(val, self.ts[idx])
 
         self.assertRaises(ValueError, self.ts.reindex)
@@ -4301,7 +4301,7 @@ class TestSeriesNonUnique(unittest.TestCase):
 
         rs = s.reset_index(level=[0, 2], drop=True)
         self.assert_(rs.index.equals(Index(index.get_level_values(1))))
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
 
     def test_set_index_makes_timeseries(self):
         idx = tm.makeDateIndex(10)
@@ -4314,8 +4314,8 @@ class TestSeriesNonUnique(unittest.TestCase):
     def test_timeseries_coercion(self):
         idx = tm.makeDateIndex(10000)
         ser = Series(np.random.randn(len(idx)), idx.astype(object))
-        self.assert_(isinstance(ser, TimeSeries))
-        self.assert_(isinstance(ser.index, DatetimeIndex))
+        tm.assert_isinstance(ser, TimeSeries)
+        tm.assert_isinstance(ser.index, DatetimeIndex)
 
     def test_replace(self):
         N = 100
diff --git a/pandas/tests/test_strings.py b/pandas/tests/test_strings.py
index 9a1d3bc71..d54aedc43 100644
--- a/pandas/tests/test_strings.py
+++ b/pandas/tests/test_strings.py
@@ -36,14 +36,14 @@ class TestStringMethods(unittest.TestCase):
 
         for s in ds.str:
             # iter must yield a Series
-            self.assert_(isinstance(s, Series))
+            tm.assert_isinstance(s, Series)
 
             # indices of each yielded Series should be equal to the index of
             # the original Series
             assert_array_equal(s.index, ds.index)
 
             for el in s:
-                # each element of the series is either a six.string_types or nan
+                # each element of the series is either a basestring/str or nan
                 self.assert_(isinstance(el, six.string_types) or isnull(el))
 
         # desired behavior is to iterate until everything would be nan on the
@@ -142,7 +142,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(result, exp)
 
         result = Series(values).str.count('f[o]+')
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         tm.assert_almost_equal(result, exp)
 
         # mixed
@@ -152,7 +152,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.count('a')
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -163,7 +163,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(result, exp)
 
         result = Series(values).str.count('f[o]+')
-        self.assert_(isinstance(result, Series))
+        tm.assert_isinstance(result, Series)
         tm.assert_almost_equal(result, exp)
 
     def test_contains(self):
@@ -187,7 +187,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.contains('o')
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -227,7 +227,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.startswith('f')
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -255,7 +255,7 @@ class TestStringMethods(unittest.TestCase):
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.endswith('f')
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -307,7 +307,7 @@ class TestStringMethods(unittest.TestCase):
         mixed = mixed.str.upper()
         rs = Series(mixed).str.lower()
         xp = ['a', NA, 'b', NA, NA, 'foo', NA, NA, NA]
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -337,7 +337,7 @@ class TestStringMethods(unittest.TestCase):
 
         rs = Series(mixed).str.replace('BAD[_]*', '')
         xp = ['a', NA, 'b', NA, NA, 'foo', NA, NA, NA]
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -375,7 +375,7 @@ class TestStringMethods(unittest.TestCase):
 
         rs = Series(mixed).str.repeat(3)
         xp = ['aaa', NA, 'bbb', NA, NA, 'foofoofoo', NA, NA, NA]
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -405,7 +405,7 @@ class TestStringMethods(unittest.TestCase):
 
         rs = Series(mixed).str.match('.*(BAD[_]+).*(BAD)')
         xp = [('BAD_', 'BAD'), NA, ('BAD_', 'BAD'), NA, NA, [], NA, NA, NA]
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -427,7 +427,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.split('_').str.join('_')
         xp = Series(['a_b', NA, 'asdf_cas_asdf', NA, NA, 'foo', NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -450,7 +450,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.len()
         xp = Series([3, NA, 13, NA, NA, 3, NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -475,7 +475,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.findall('BAD[_]*')
         xp = Series([['BAD__', 'BAD'], NA, [], NA, NA, ['BAD'], NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -508,7 +508,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.pad(5, side='left')
         xp = Series(['    a', NA, '    b', NA, NA, '   ee', NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         mixed = Series(['a', NA, 'b', True, datetime.today(),
@@ -517,7 +517,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.pad(5, side='right')
         xp = Series(['a    ', NA, 'b    ', NA, NA, 'ee   ', NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         mixed = Series(['a', NA, 'b', True, datetime.today(),
@@ -526,7 +526,7 @@ class TestStringMethods(unittest.TestCase):
         rs = Series(mixed).str.pad(5, side='both')
         xp = Series(['  a  ', NA, '  b  ', NA, NA, '  ee ', NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -563,7 +563,7 @@ class TestStringMethods(unittest.TestCase):
         xp = Series(['  a  ', NA, '  b  ', NA, NA, '  c  ', ' eee ', NA, NA,
                      NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -595,7 +595,7 @@ class TestStringMethods(unittest.TestCase):
         xp = Series([['a', 'b', 'c'], NA, ['d', 'e', 'f'], NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -661,7 +661,7 @@ class TestStringMethods(unittest.TestCase):
         xp = Series(['foo', NA, 'bar', NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
@@ -699,21 +699,21 @@ class TestStringMethods(unittest.TestCase):
         xp = Series(['aa', NA, 'bb', NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.lstrip()
         xp = Series(['aa  ', NA, 'bb \t\n', NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         rs = Series(mixed).str.rstrip()
         xp = Series(['  aa', NA, ' bb', NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
     def test_strip_lstrip_rstrip_unicode(self):
@@ -782,7 +782,7 @@ class TestStringMethods(unittest.TestCase):
         xp = Series(['b', NA, 'd', NA, NA,
                      NA, NA, NA])
 
-        self.assert_(isinstance(rs, Series))
+        tm.assert_isinstance(rs, Series)
         tm.assert_almost_equal(rs, xp)
 
         # unicode
diff --git a/pandas/tests/test_tests.py b/pandas/tests/test_tests.py
index 89238187c..b52ab61f7 100644
--- a/pandas/tests/test_tests.py
+++ b/pandas/tests/test_tests.py
@@ -1,6 +1,5 @@
 #!/usr/bin/python
 # -*- coding: utf-8 -*-
-from __future__ import with_statement  # support python 2.5
 import pandas as pd
 import unittest
 import warnings
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index bc1ebd375..f1d1ba322 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -153,7 +153,7 @@ DataFrame.pivot_table = pivot_table
 
 def _add_margins(table, data, values, rows=None, cols=None, aggfunc=np.mean):
     grand_margin = {}
-    for k, v in data[values].iteritems():
+    for k, v in compat.iteritems(data[values]):
         try:
             if isinstance(aggfunc, six.string_types):
                 grand_margin[k] = getattr(v, aggfunc)()
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 0e6235438..ea57fc752 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -1,8 +1,5 @@
 # pylint: disable=E1103
 
-from pandas.util.py3compat import range
-from six.moves import zip
-from pandas.util import compat
 import nose
 import unittest
 
@@ -12,12 +9,15 @@ from numpy import nan
 import numpy as np
 import random
 
-from pandas import *
+from pandas.util.py3compat import range
+from six.moves import zip
+from pandas.util import compat
 from pandas.tseries.index import DatetimeIndex
 from pandas.tools.merge import merge, concat, ordered_merge, MergeError
 from pandas.util.testing import (assert_frame_equal, assert_series_equal,
                                  assert_almost_equal, rands,
                                  makeCustomDataframe as mkdf)
+from pandas import isnull, DataFrame, Index, MultiIndex, Panel, Series, date_range
 import pandas.algos as algos
 import pandas.util.testing as tm
 
@@ -1025,7 +1025,7 @@ def _join_by_hand(a, b, how='left'):
 
     result_columns = a.columns.append(b.columns)
 
-    for col, s in b_re.iteritems():
+    for col, s in compat.iteritems(b_re):
         a_re[col] = s
     return a_re.reindex(columns=result_columns)
 
@@ -1472,7 +1472,7 @@ class TestConcatenate(unittest.TestCase):
 
         data_dict = {}
         for p in panels:
-            data_dict.update(p.iteritems())
+            data_dict.update(compat.iteritems(p))
 
         joined = panels[0].join(panels[1:], how='inner')
         expected = Panel.from_dict(data_dict, intersect=True)
@@ -1766,6 +1766,5 @@ class TestOrderedMerge(unittest.TestCase):
         self.assert_(result['group'].notnull().all())
 
 if __name__ == '__main__':
-    import nose
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/tools/tests/test_pivot.py b/pandas/tools/tests/test_pivot.py
index 11a9fef9a..084715291 100644
--- a/pandas/tools/tests/test_pivot.py
+++ b/pandas/tools/tests/test_pivot.py
@@ -210,7 +210,7 @@ class TestPivotTable(unittest.TestCase):
         # no rows
         rtable = self.data.pivot_table(cols=['AA', 'BB'], margins=True,
                                        aggfunc=np.mean)
-        self.assert_(isinstance(rtable, Series))
+        tm.assert_isinstance(rtable, Series)
         for item in ['DD', 'EE', 'FF']:
             gmarg = table[item]['All', '']
             self.assertEqual(gmarg, self.data[item].mean())
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index 20caf150c..3157c694b 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -376,12 +376,12 @@ for _i, _weekday in enumerate(['MON', 'TUE', 'WED', 'THU', 'FRI']):
 # Note that _rule_aliases is not 1:1 (d[BA]==d[A@DEC]), and so traversal
 # order matters when constructing an inverse. we pick one. #2331
 _legacy_reverse_map = dict((v, k) for k, v in
-                           reversed(sorted(_rule_aliases.iteritems())))
+                           reversed(sorted(compat.iteritems(_rule_aliases))))
 
 # for helping out with pretty-printing and name-lookups
 
 _offset_names = {}
-for name, offset in _offset_map.iteritems():
+for name, offset in compat.iteritems(_offset_map):
     if offset is None:
         continue
     offset.name = name
@@ -614,7 +614,7 @@ _period_code_map = {
 }
 
 _reverse_period_code_map = {}
-for _k, _v in _period_code_map.iteritems():
+for _k, _v in compat.iteritems(_period_code_map):
     _reverse_period_code_map[_v] = _k
 
 # Additional aliases
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index ce63fa7db..3bcf93464 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -102,7 +102,7 @@ class DateOffset(object):
         return self.isAnchored() and self._cacheable
 
     def _params(self):
-        attrs = [(k, v) for k, v in vars(self).iteritems()
+        attrs = [(k, v) for k, v in compat.iteritems(vars(self))
                  if k not in ['kwds', '_offset', 'name', 'normalize',
                  'busdaycalendar']]
         attrs.extend(self.kwds.items())
diff --git a/pandas/tseries/tests/test_daterange.py b/pandas/tseries/tests/test_daterange.py
index 4f4df38af..b9f5e7315 100644
--- a/pandas/tseries/tests/test_daterange.py
+++ b/pandas/tseries/tests/test_daterange.py
@@ -16,6 +16,7 @@ import pandas.tseries.tools as tools
 
 import pandas.core.datetools as datetools
 from pandas.util.testing import assertRaisesRegexp
+import pandas.util.testing as tm
 
 
 def _skip_if_no_pytz():
@@ -147,7 +148,7 @@ class TestDateRange(unittest.TestCase):
 
         fancy_indexed = self.rng[[4, 3, 2, 1, 0]]
         self.assertEquals(len(fancy_indexed), 5)
-        self.assert_(isinstance(fancy_indexed, DatetimeIndex))
+        tm.assert_isinstance(fancy_indexed, DatetimeIndex)
         self.assert_(fancy_indexed.freq is None)
 
         # 32-bit vs. 64-bit platforms
@@ -187,21 +188,21 @@ class TestDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
         right = self.rng[10:]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, Index))
+        tm.assert_isinstance(the_union, Index)
 
         # non-overlapping, no gap
         left = self.rng[:5]
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
         # order does not matter
         self.assert_(np.array_equal(right.union(left), the_union))
@@ -210,7 +211,7 @@ class TestDateRange(unittest.TestCase):
         rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_union = self.rng.union(rng)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
     def test_outer_join(self):
         # should just behave as union
@@ -220,14 +221,14 @@ class TestDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
         right = self.rng[10:]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
         self.assert_(the_join.freq is None)
 
         # non-overlapping, no gap
@@ -235,13 +236,13 @@ class TestDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
 
         # overlapping, but different offset
         rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_join = self.rng.join(rng, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
         self.assert_(the_join.freq is None)
 
     def test_union_not_cacheable(self):
@@ -264,7 +265,7 @@ class TestDateRange(unittest.TestCase):
         the_int = rng1.intersection(rng2)
         expected = rng[10:25]
         self.assert_(the_int.equals(expected))
-        self.assert_(isinstance(the_int, DatetimeIndex))
+        tm.assert_isinstance(the_int, DatetimeIndex)
         self.assert_(the_int.offset == rng.offset)
 
         the_int = rng1.intersection(rng2.view(DatetimeIndex))
@@ -322,7 +323,7 @@ class TestDateRange(unittest.TestCase):
         rng2.offset = datetools.BDay()
 
         result = rng1.union(rng2)
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
 
     def test_error_with_zero_monthends(self):
         self.assertRaises(ValueError, date_range, '1/1/2000', '1/1/2001',
@@ -367,13 +368,13 @@ class TestDateRange(unittest.TestCase):
 
         early_start = datetime(2011, 1, 1)
         early_end = datetime(2011, 3, 1)
-        
+
         late_start = datetime(2011, 3, 1)
         late_end = datetime(2011, 5, 1)
 
         early_dr = date_range(start=early_start, end=early_end, tz=tz, freq=datetools.monthEnd)
         late_dr = date_range(start=late_start, end=late_end, tz=tz, freq=datetools.monthEnd)
-        
+
         early_dr.union(late_dr)
 
 
@@ -435,7 +436,7 @@ class TestCustomDateRange(unittest.TestCase):
 
         fancy_indexed = self.rng[[4, 3, 2, 1, 0]]
         self.assertEquals(len(fancy_indexed), 5)
-        self.assert_(isinstance(fancy_indexed, DatetimeIndex))
+        tm.assert_isinstance(fancy_indexed, DatetimeIndex)
         self.assert_(fancy_indexed.freq is None)
 
         # 32-bit vs. 64-bit platforms
@@ -475,21 +476,21 @@ class TestCustomDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
         right = self.rng[10:]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, Index))
+        tm.assert_isinstance(the_union, Index)
 
         # non-overlapping, no gap
         left = self.rng[:5]
         right = self.rng[5:10]
 
         the_union = left.union(right)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
         # order does not matter
         self.assert_(np.array_equal(right.union(left), the_union))
@@ -498,7 +499,7 @@ class TestCustomDateRange(unittest.TestCase):
         rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_union = self.rng.union(rng)
-        self.assert_(isinstance(the_union, DatetimeIndex))
+        tm.assert_isinstance(the_union, DatetimeIndex)
 
     def test_outer_join(self):
         # should just behave as union
@@ -508,14 +509,14 @@ class TestCustomDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
 
         # non-overlapping, gap in middle
         left = self.rng[:5]
         right = self.rng[10:]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
         self.assert_(the_join.freq is None)
 
         # non-overlapping, no gap
@@ -523,13 +524,13 @@ class TestCustomDateRange(unittest.TestCase):
         right = self.rng[5:10]
 
         the_join = left.join(right, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
 
         # overlapping, but different offset
         rng = date_range(START, END, freq=datetools.bmonthEnd)
 
         the_join = self.rng.join(rng, how='outer')
-        self.assert_(isinstance(the_join, DatetimeIndex))
+        tm.assert_isinstance(the_join, DatetimeIndex)
         self.assert_(the_join.freq is None)
 
     def test_intersection_bug(self):
@@ -579,7 +580,7 @@ class TestCustomDateRange(unittest.TestCase):
         rng2.offset = datetools.CDay()
 
         result = rng1.union(rng2)
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
 
     def test_cdaterange(self):
         rng = cdate_range('2013-05-01', periods=3)
diff --git a/pandas/tseries/tests/test_offsets.py b/pandas/tseries/tests/test_offsets.py
index 9cc7383ed..3f4960520 100644
--- a/pandas/tseries/tests/test_offsets.py
+++ b/pandas/tseries/tests/test_offsets.py
@@ -24,6 +24,7 @@ import pandas.tseries.offsets as offsets
 from pandas.tslib import monthrange
 from pandas.lib import Timestamp
 from pandas.util.testing import assertRaisesRegexp
+import pandas.util.testing as tm
 
 _multiprocess_can_split_ = True
 
@@ -77,7 +78,7 @@ def test_normalize_date():
 def test_to_m8():
     valb = datetime(2007, 10, 1)
     valu = _to_m8(valb)
-    assert type(valu) == np.datetime64
+    tm.assert_isinstance(valu, np.datetime64)
     # assert valu == np.datetime64(datetime(2007,10,1))
 
 # def test_datetime64_box():
@@ -272,7 +273,7 @@ class TestBusinessDay(unittest.TestCase):
                        datetime(2008, 1, 7): datetime(2008, 1, 7)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_apply_large_n(self):
@@ -447,7 +448,7 @@ class TestCustomBusinessDay(unittest.TestCase):
                        datetime(2008, 1, 7): datetime(2008, 1, 7)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_apply_large_n(self):
@@ -564,7 +565,7 @@ class TestWeek(unittest.TestCase):
                        datetime(2010, 4, 5): datetime(2010, 3, 23)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -703,7 +704,7 @@ class TestBMonthBegin(unittest.TestCase):
                       datetime(2007, 1, 1): datetime(2006, 12, 1)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -760,7 +761,7 @@ class TestBMonthEnd(unittest.TestCase):
                       datetime(2007, 1, 1): datetime(2006, 12, 29)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_normalize(self):
@@ -821,7 +822,7 @@ class TestMonthBegin(unittest.TestCase):
                       datetime(2006, 1, 2): datetime(2006, 1, 1)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
 
@@ -862,7 +863,7 @@ class TestMonthEnd(unittest.TestCase):
                       datetime(2007, 1, 1): datetime(2006, 12, 31)}))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     # def test_day_of_month(self):
@@ -969,7 +970,7 @@ class TestBQuarterBegin(unittest.TestCase):
                        datetime(2008, 4, 30): datetime(2008, 10, 1), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
         # corner
@@ -1037,7 +1038,7 @@ class TestBQuarterEnd(unittest.TestCase):
                        datetime(2008, 4, 30): datetime(2008, 10, 31), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
         # corner
@@ -1141,7 +1142,7 @@ class TestQuarterBegin(unittest.TestCase):
                        datetime(2008, 4, 1): datetime(2008, 10, 1), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
         # corner
@@ -1210,7 +1211,7 @@ class TestQuarterEnd(unittest.TestCase):
                        datetime(2008, 4, 30): datetime(2008, 10, 31), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
         # corner
@@ -1324,7 +1325,7 @@ class TestBYearBegin(unittest.TestCase):
                        datetime(2008, 12, 31): datetime(2007, 1, 1), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
 
@@ -1384,7 +1385,7 @@ class TestYearBegin(unittest.TestCase):
                        datetime(2012, 1, 31): datetime(2011, 4, 1), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -1420,7 +1421,7 @@ class TestBYearEndLagged(unittest.TestCase):
                       ))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 self.assertEqual(base + offset, expected)
 
     def test_roll(self):
@@ -1473,7 +1474,7 @@ class TestBYearEnd(unittest.TestCase):
                        datetime(2008, 12, 31): datetime(2006, 12, 29), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -1524,7 +1525,7 @@ class TestYearEnd(unittest.TestCase):
                        datetime(2008, 12, 31): datetime(2006, 12, 31), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -1573,7 +1574,7 @@ class TestYearEndDiffMonth(unittest.TestCase):
                        datetime(2008, 3, 31): datetime(2006, 3, 31), }))
 
         for offset, cases in tests:
-            for base, expected in cases.iteritems():
+            for base, expected in compat.iteritems(cases):
                 assertEq(offset, base, expected)
 
     def test_onOffset(self):
@@ -1733,7 +1734,7 @@ class TestOffsetAliases(unittest.TestCase):
     def test_alias_equality(self):
         from pandas.tseries.frequencies import _offset_map
 
-        for k, v in _offset_map.iteritems():
+        for k, v in compat.iteritems(_offset_map):
             if v is None:
                 continue
             self.assertEqual(k, v.copy())
diff --git a/pandas/tseries/tests/test_period.py b/pandas/tseries/tests/test_period.py
index 8058d1202..053ff8af2 100644
--- a/pandas/tseries/tests/test_period.py
+++ b/pandas/tseries/tests/test_period.py
@@ -1064,7 +1064,7 @@ class TestPeriodIndex(TestCase):
     def test_make_time_series(self):
         index = PeriodIndex(freq='A', start='1/1/2001', end='12/1/2009')
         series = Series(1, index=index)
-        self.assert_(isinstance(series, TimeSeries))
+        tm.assert_isinstance(series, TimeSeries)
 
     def test_astype(self):
         idx = period_range('1990', '2009', freq='A')
@@ -1181,7 +1181,7 @@ class TestPeriodIndex(TestCase):
 
         result = idx[:, None]
         # MPL kludge
-        self.assert_(type(result) == PeriodIndex)
+        tm.assert_isinstance(result, PeriodIndex)
 
     def test_getitem_partial(self):
         rng = period_range('2007-01', periods=50, freq='M')
@@ -1238,7 +1238,7 @@ class TestPeriodIndex(TestCase):
     def test_tolist(self):
         index = PeriodIndex(freq='A', start='1/1/2001', end='12/1/2009')
         rs = index.tolist()
-        [self.assert_(isinstance(x, Period)) for x in rs]
+        [tm.assert_isinstance(x, Period) for x in rs]
 
         recon = PeriodIndex(rs)
         self.assert_(index.equals(recon))
@@ -1335,7 +1335,7 @@ class TestPeriodIndex(TestCase):
         self.assert_(rs.equals(rng))
 
         rs = df.reset_index().set_index('index')
-        self.assert_(isinstance(rs.index, PeriodIndex))
+        tm.assert_isinstance(rs.index, PeriodIndex)
         self.assert_(rs.index.equals(rng))
 
     def test_nested_dict_frame_constructor(self):
@@ -1835,7 +1835,7 @@ class TestPeriodIndex(TestCase):
         index = PeriodIndex(start='1/1/10', periods=4, freq='B')
 
         result = list(index)
-        self.assert_(isinstance(result[0], Period))
+        tm.assert_isinstance(result[0], Period)
         self.assert_(result[0].freq == index.freq)
 
     def test_take(self):
@@ -1843,9 +1843,9 @@ class TestPeriodIndex(TestCase):
 
         taken = index.take([5, 6, 8, 12])
         taken2 = index[[5, 6, 8, 12]]
-        self.assert_(isinstance(taken, PeriodIndex))
+        tm.assert_isinstance(taken, PeriodIndex)
         self.assert_(taken.freq == index.freq)
-        self.assert_(isinstance(taken2, PeriodIndex))
+        tm.assert_isinstance(taken2, PeriodIndex)
         self.assert_(taken2.freq == index.freq)
 
     def test_joins(self):
@@ -1854,7 +1854,7 @@ class TestPeriodIndex(TestCase):
         for kind in ['inner', 'outer', 'left', 'right']:
             joined = index.join(index[:-5], how=kind)
 
-            self.assert_(isinstance(joined, PeriodIndex))
+            tm.assert_isinstance(joined, PeriodIndex)
             self.assert_(joined.freq == index.freq)
 
     def test_align_series(self):
@@ -2008,7 +2008,7 @@ class TestPeriodIndex(TestCase):
             res = index.map(t)
 
             # should return an array
-            self.assert_(isinstance(res, np.ndarray))
+            tm.assert_isinstance(res, np.ndarray)
 
             # preserve element types
             self.assert_(all(isinstance(resi, t) for resi in res))
@@ -2024,7 +2024,7 @@ class TestPeriodIndex(TestCase):
         periods = list(rng)
 
         result = pd.Index(periods)
-        self.assert_(isinstance(result, PeriodIndex))
+        tm.assert_isinstance(result, PeriodIndex)
 
     def test_with_multi_index(self):
         # #1705
@@ -2033,9 +2033,9 @@ class TestPeriodIndex(TestCase):
 
         s = Series([0, 1, 2, 3], index_as_arrays)
 
-        self.assert_(isinstance(s.index.levels[0], PeriodIndex))
+        tm.assert_isinstance(s.index.levels[0], PeriodIndex)
 
-        self.assert_(isinstance(s.index.values[0][0], Period))
+        tm.assert_isinstance(s.index.values[0][0], Period)
 
     def test_to_datetime_1703(self):
         index = period_range('1/1/2012', periods=4, freq='D')
@@ -2066,7 +2066,7 @@ class TestPeriodIndex(TestCase):
 
         # drops index
         result = pd.concat([s1, s2])
-        self.assert_(isinstance(result.index, PeriodIndex))
+        tm.assert_isinstance(result.index, PeriodIndex)
         self.assertEquals(result.index[0], s1.index[0])
 
     def test_pickle_freq(self):
diff --git a/pandas/tseries/tests/test_plotting.py b/pandas/tseries/tests/test_plotting.py
index 2bb70e6ef..f6242139e 100644
--- a/pandas/tseries/tests/test_plotting.py
+++ b/pandas/tseries/tests/test_plotting.py
@@ -484,7 +484,7 @@ class TestTSPlot(unittest.TestCase):
         self.assert_(len(lines) == 1)
         l = lines[0]
         data = l.get_xydata()
-        self.assert_(isinstance(data, np.ma.core.MaskedArray))
+        tm.assert_isinstance(data, np.ma.core.MaskedArray)
         mask = data.mask
         self.assert_(mask[5:25, 1].all())
 
@@ -498,7 +498,7 @@ class TestTSPlot(unittest.TestCase):
         self.assert_(len(lines) == 1)
         l = lines[0]
         data = l.get_xydata()
-        self.assert_(isinstance(data, np.ma.core.MaskedArray))
+        tm.assert_isinstance(data, np.ma.core.MaskedArray)
         mask = data.mask
         self.assert_(mask[2:5, 1].all())
 
@@ -512,7 +512,7 @@ class TestTSPlot(unittest.TestCase):
         self.assert_(len(lines) == 1)
         l = lines[0]
         data = l.get_xydata()
-        self.assert_(isinstance(data, np.ma.core.MaskedArray))
+        tm.assert_isinstance(data, np.ma.core.MaskedArray)
         mask = data.mask
         self.assert_(mask[2:5, 1].all())
 
@@ -532,7 +532,7 @@ class TestTSPlot(unittest.TestCase):
         self.assert_(len(ax.right_ax.get_lines()) == 1)
         l = lines[0]
         data = l.get_xydata()
-        self.assert_(isinstance(data, np.ma.core.MaskedArray))
+        tm.assert_isinstance(data, np.ma.core.MaskedArray)
         mask = data.mask
         self.assert_(mask[5:25, 1].all())
 
diff --git a/pandas/tseries/tests/test_resample.py b/pandas/tseries/tests/test_resample.py
index 22e103e54..b5e6d9de4 100644
--- a/pandas/tseries/tests/test_resample.py
+++ b/pandas/tseries/tests/test_resample.py
@@ -268,7 +268,7 @@ class TestResample(unittest.TestCase):
         bs = s.resample('B', closed='right', label='right')
         result = bs.resample('8H')
         self.assertEquals(len(result), 22)
-        self.assert_(isinstance(result.index.freq, offsets.DateOffset))
+        tm.assert_isinstance(result.index.freq, offsets.DateOffset)
         self.assert_(result.index.freq == offsets.Hour(8))
 
     def test_resample_timestamp_to_period(self):
@@ -537,7 +537,7 @@ class TestResample(unittest.TestCase):
         ts = Series(np.random.randn(len(rng)), index=rng)
 
         result = ts.resample('20min', how=['mean', 'sum'])
-        self.assert_(isinstance(result, DataFrame))
+        tm.assert_isinstance(result, DataFrame)
 
     def test_resample_not_monotonic(self):
         rng = pd.date_range('2012-06-12', periods=200, freq='h')
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 4b87dd295..0336f659f 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -65,8 +65,8 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
         self.dups = Series(np.random.randn(len(dates)), index=dates)
 
     def test_constructor(self):
-        self.assert_(isinstance(self.dups, TimeSeries))
-        self.assert_(isinstance(self.dups.index, DatetimeIndex))
+        tm.assert_isinstance(self.dups, TimeSeries)
+        tm.assert_isinstance(self.dups.index, DatetimeIndex)
 
     def test_is_unique_monotonic(self):
         self.assert_(not self.dups.index.is_unique)
@@ -325,13 +325,13 @@ class TestTimeSeries(unittest.TestCase):
         rng = date_range('20090415', '20090519', freq='B')
         s = Series(rng)
 
-        self.assert_(isinstance(s[5], Timestamp))
+        tm.assert_isinstance(s[5], Timestamp)
 
         rng = date_range('20090415', '20090519', freq='B')
         s = Series(rng, index=rng)
-        self.assert_(isinstance(s[5], Timestamp))
+        tm.assert_isinstance(s[5], Timestamp)
 
-        self.assert_(isinstance(s.iget_value(5), Timestamp))
+        tm.assert_isinstance(s.iget_value(5), Timestamp)
 
     def test_date_range_ambiguous_arguments(self):
         # #2538
@@ -356,9 +356,9 @@ class TestTimeSeries(unittest.TestCase):
 
         def _check_rng(rng):
             converted = rng.to_pydatetime()
-            self.assert_(isinstance(converted, np.ndarray))
+            tm.assert_isinstance(converted, np.ndarray)
             for x, stamp in zip(converted, rng):
-                self.assert_(type(x) is datetime)
+                tm.assert_isinstance(x, datetime)
                 self.assertEquals(x, stamp.to_pydatetime())
                 self.assertEquals(x.tzinfo, stamp.tzinfo)
 
@@ -657,7 +657,7 @@ class TestTimeSeries(unittest.TestCase):
 
         casted = idx.astype(np.dtype('M8[D]'))
         expected = DatetimeIndex(idx.values)
-        self.assert_(isinstance(casted, DatetimeIndex))
+        tm.assert_isinstance(casted, DatetimeIndex)
         self.assert_(casted.equals(expected))
 
     def test_reindex_series_add_nat(self):
@@ -749,7 +749,7 @@ class TestTimeSeries(unittest.TestCase):
         assert_almost_equal(result, expected)
 
         result2 = to_datetime(strings)
-        self.assert_(isinstance(result2, DatetimeIndex))
+        tm.assert_isinstance(result2, DatetimeIndex)
         assert_almost_equal(result, result2)
 
         malformed = np.array(['1/100/2000', np.nan], dtype=object)
@@ -1695,7 +1695,7 @@ class TestDatetimeIndex(unittest.TestCase):
         idx = Index(['a', 'b', 'c', 'd'])
 
         result = rng.append(idx)
-        self.assert_(isinstance(result[0], Timestamp))
+        tm.assert_isinstance(result[0], Timestamp)
 
         # it works
         rng.join(idx, how='outer')
@@ -1790,7 +1790,7 @@ class TestDatetimeIndex(unittest.TestCase):
     def test_misc_coverage(self):
         rng = date_range('1/1/2000', periods=5)
         result = rng.groupby(rng.day)
-        self.assert_(isinstance(result.values()[0][0], Timestamp))
+        tm.assert_isinstance(result.values()[0][0], Timestamp)
 
         idx = DatetimeIndex(['2000-01-03', '2000-01-01', '2000-01-02'])
         self.assert_(idx.equals(list(idx)))
@@ -1898,7 +1898,7 @@ class TestDatetimeIndex(unittest.TestCase):
         monthly_group = df.groupby(lambda x: (x.year, x.month))
 
         result = monthly_group.mean()
-        self.assert_(isinstance(result.index[0], tuple))
+        tm.assert_isinstance(result.index[0], tuple)
 
     def test_append_numpy_bug_1681(self):
         # another datetime64 bug
@@ -2022,7 +2022,7 @@ class TestLegacySupport(unittest.TestCase):
         ex_index = DatetimeIndex([], freq='B')
 
         self.assert_(result.index.equals(ex_index))
-        self.assert_(isinstance(result.index.freq, offsets.BDay))
+        tm.assert_isinstance(result.index.freq, offsets.BDay)
         self.assert_(len(result) == 0)
 
     def test_arithmetic_interaction(self):
@@ -2034,12 +2034,12 @@ class TestLegacySupport(unittest.TestCase):
 
         result = dseries + oseries
         expected = dseries * 2
-        self.assert_(isinstance(result.index, DatetimeIndex))
+        tm.assert_isinstance(result.index, DatetimeIndex)
         assert_series_equal(result, expected)
 
         result = dseries + oseries[:5]
         expected = dseries + dseries[:5]
-        self.assert_(isinstance(result.index, DatetimeIndex))
+        tm.assert_isinstance(result.index, DatetimeIndex)
         assert_series_equal(result, expected)
 
     def test_join_interaction(self):
@@ -2051,7 +2051,7 @@ class TestLegacySupport(unittest.TestCase):
             ea, eb, ec = left.join(DatetimeIndex(right), how=how,
                                    return_indexers=True)
 
-            self.assert_(isinstance(ra, DatetimeIndex))
+            tm.assert_isinstance(ra, DatetimeIndex)
             self.assert_(ra.equals(ea))
 
             assert_almost_equal(rb, eb)
@@ -2075,8 +2075,8 @@ class TestLegacySupport(unittest.TestCase):
         filepath = os.path.join(pth, 'data', 'daterange_073.pickle')
 
         rng = read_pickle(filepath)
-        self.assert_(type(rng[0]) == datetime)
-        self.assert_(isinstance(rng.offset, offsets.BDay))
+        tm.assert_isinstance(rng[0], datetime)
+        tm.assert_isinstance(rng.offset, offsets.BDay)
         self.assert_(rng.values.dtype == object)
 
     def test_setops(self):
@@ -2085,17 +2085,17 @@ class TestLegacySupport(unittest.TestCase):
 
         result = index[:5].union(obj_index[5:])
         expected = index
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
         self.assert_(result.equals(expected))
 
         result = index[:10].intersection(obj_index[5:])
         expected = index[5:10]
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
         self.assert_(result.equals(expected))
 
         result = index[:10] - obj_index[5:]
         expected = index[:5]
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
         self.assert_(result.equals(expected))
 
     def test_index_conversion(self):
@@ -2111,7 +2111,7 @@ class TestLegacySupport(unittest.TestCase):
         rng = date_range('1/1/2000', periods=10)
 
         result = rng.tolist()
-        self.assert_(isinstance(result[0], Timestamp))
+        tm.assert_isinstance(result[0], Timestamp)
 
     def test_object_convert_fail(self):
         idx = DatetimeIndex([NaT])
@@ -2336,8 +2336,8 @@ class TestLegacySupport(unittest.TestCase):
 
         the_min = rng2.min()
         the_max = rng2.max()
-        self.assert_(isinstance(the_min, Timestamp))
-        self.assert_(isinstance(the_max, Timestamp))
+        tm.assert_isinstance(the_min, Timestamp)
+        tm.assert_isinstance(the_max, Timestamp)
         self.assertEqual(the_min, rng[0])
         self.assertEqual(the_max, rng[-1])
 
@@ -2623,11 +2623,11 @@ class TestDatetime64(unittest.TestCase):
         empty = Index([])
 
         result = dti.union(empty)
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
         self.assert_(result is result)
 
         result = dti.join(empty)
-        self.assert_(isinstance(result, DatetimeIndex))
+        tm.assert_isinstance(result, DatetimeIndex)
 
     def test_series_set_value(self):
         # #1561
diff --git a/pandas/tseries/tests/test_timezones.py b/pandas/tseries/tests/test_timezones.py
index bf441a970..1f3e80dc0 100644
--- a/pandas/tseries/tests/test_timezones.py
+++ b/pandas/tseries/tests/test_timezones.py
@@ -182,7 +182,7 @@ class TestTimeZoneSupport(unittest.TestCase):
         expected = utc.tz_convert('US/Eastern')
         result = utc.astimezone('US/Eastern')
         self.assertEquals(expected, result)
-        self.assert_(isinstance(result, Timestamp))
+        tm.assert_isinstance(result, Timestamp)
 
     def test_create_with_tz(self):
         stamp = Timestamp('3/11/2012 05:00', tz='US/Eastern')
@@ -726,11 +726,11 @@ class TestTimeZones(unittest.TestCase):
 
         for how in ['inner', 'outer', 'left', 'right']:
             result = left.join(left[:-5], how=how)
-            self.assert_(isinstance(result, DatetimeIndex))
+            tm.assert_isinstance(result, DatetimeIndex)
             self.assert_(result.tz == left.tz)
 
             result = left.join(right[:-5], how=how)
-            self.assert_(isinstance(result, DatetimeIndex))
+            tm.assert_isinstance(result, DatetimeIndex)
             self.assert_(result.tz.zone == 'UTC')
 
     def test_join_aware(self):
diff --git a/pandas/util/compat.py b/pandas/util/compat.py
index a42b9218a..10fb2b107 100644
--- a/pandas/util/compat.py
+++ b/pandas/util/compat.py
@@ -1,20 +1,8 @@
-# itertools.product not in Python 2.5
-
 import sys
 import six
-from six.moves import map
-try:
-    from itertools import product
-except ImportError:  # python 2.5
-    def product(*args, **kwds):
-        # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
-        # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
-        pools = list(map(tuple, args) * kwds.get('repeat', 1))
-        result = [[]]
-        for pool in pools:
-            result = [x + [y] for x in result for y in pool]
-        for prod in result:
-            yield tuple(prod)
+from six.moves import map, filter
+from pandas.util.py3compat import range
+from itertools import product
 
 
 # OrderedDict Shim from  Raymond Hettinger, python core dev
@@ -31,12 +19,15 @@ except ImportError:
     pass
 
 
-def iteritems(obj):
-    """replacement for six's iteritems to use iteritems on PandasObjects"""
+def iteritems(obj, **kwargs):
+    """replacement for six's iteritems for Python2/3 compat
+       uses 'iteritems' if available and otherwise uses 'items'.
+
+       Passes kwargs to method."""
     if hasattr(obj, "iteritems"):
-        return obj.iteritems()
+        return obj.iteritems(**kwargs)
     else:
-        return obj.items()
+        return obj.items(**kwargs)
 
 
 class _OrderedDict(dict):
@@ -293,7 +284,6 @@ class _OrderedDict(dict):
 try:
     from operator import itemgetter
     from heapq import nlargest
-    from itertools import repeat, ifilter
 except ImportError:
     pass
 
@@ -348,7 +338,7 @@ class _Counter(dict):
 
         '''
         for elem, count in iteritems(self):
-            for _ in repeat(None, count):
+            for _ in range(count):
                 yield elem
 
     # Override dict methods where the meaning changes for Counter objects.
@@ -375,7 +365,7 @@ class _Counter(dict):
             if hasattr(iterable, 'iteritems'):
                 if self:
                     self_get = self.get
-                    for elem, count in iterable.iteritems():
+                    for elem, count in iteritems(iterable):
                         self[elem] = self_get(elem, 0) + count
                 else:
                     dict.update(
@@ -474,7 +464,7 @@ class _Counter(dict):
         result = Counter()
         if len(self) < len(other):
             self, other = other, self
-        for elem in ifilter(self.__contains__, other):
+        for elem in filter(self.__contains__, other):
             newcount = _min(self[elem], other[elem])
             if newcount > 0:
                 result[elem] = newcount
diff --git a/pandas/util/py3compat.py b/pandas/util/py3compat.py
index 240f8c0fc..ad13d913b 100644
--- a/pandas/util/py3compat.py
+++ b/pandas/util/py3compat.py
@@ -14,6 +14,7 @@ if PY3:
 
     range = range
     long = int
+    unichr = chr
 else:
     # Python 2
     import re
@@ -30,6 +31,7 @@ else:
 
     range = xrange
     long = long
+    unichr = unichr
 
 try:
     # not writeable if instantiated with string, not good with unicode
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 6b710b442..16e8c649e 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -123,10 +123,23 @@ def equalContents(arr1, arr2):
     return frozenset(arr1) == frozenset(arr2)
 
 
+def assert_isinstance(obj, class_type_or_tuple):
+    """asserts that obj is an instance of class_type_or_tuple"""
+    assert isinstance(obj, class_type_or_tuple), (
+        "Expected object to be of type %r, found %r instead" % (
+            type(obj), class_type_or_tuple))
+
+
 def isiterable(obj):
     return hasattr(obj, '__iter__')
 
 
+def assert_isinstance(obj, class_type_or_tuple):
+    """asserts that obj is an instance of class_type_or_tuple"""
+    assert isinstance(obj, class_type_or_tuple), (
+        "Expected object to be of type %r, found %r instead" % (type(obj), class_type_or_tuple))
+
+
 def assert_almost_equal(a, b, check_less_precise = False):
     if isinstance(a, dict) or isinstance(b, dict):
         return assert_dict_equal(a, b)
@@ -199,7 +212,7 @@ def assert_series_equal(left, right, check_dtype=True,
                         check_series_type=False,
                         check_less_precise=False):
     if check_series_type:
-        assert(type(left) == type(right))
+        assert_isinstance(left, type(right))
     assert_almost_equal(left.values, right.values, check_less_precise)
     if check_dtype:
         assert(left.dtype == right.dtype)
@@ -208,7 +221,7 @@ def assert_series_equal(left, right, check_dtype=True,
     else:
         assert(left.index.equals(right.index))
     if check_index_type:
-        assert(type(left.index) == type(right.index))
+        assert_isinstance(left.index, type(right.index))
         assert(left.index.dtype == right.index.dtype)
         assert(left.index.inferred_type == right.index.inferred_type)
     if check_index_freq:
@@ -223,9 +236,9 @@ def assert_frame_equal(left, right, check_dtype=True,
                        check_less_precise=False,
                        check_names=True):
     if check_frame_type:
-        assert(type(left) == type(right))
-    assert(isinstance(left, DataFrame))
-    assert(isinstance(right, DataFrame))
+        assert_isinstance(left, type(right))
+    assert_isinstance(left, DataFrame)
+    assert_isinstance(right, DataFrame)
 
     if check_less_precise:
         assert_almost_equal(left.columns,right.columns)
@@ -244,11 +257,11 @@ def assert_frame_equal(left, right, check_dtype=True,
                             check_less_precise=check_less_precise)
 
     if check_index_type:
-        assert(type(left.index) == type(right.index))
+        assert_isinstance(left.index, type(right.index))
         assert(left.index.dtype == right.index.dtype)
         assert(left.index.inferred_type == right.index.inferred_type)
     if check_column_type:
-        assert(type(left.columns) == type(right.columns))
+        assert_isinstance(left.columns, type(right.columns))
         assert(left.columns.dtype == right.columns.dtype)
         assert(left.columns.inferred_type == right.columns.inferred_type)
     if check_names:
@@ -260,7 +273,7 @@ def assert_panel_equal(left, right,
                        check_panel_type=False,
                        check_less_precise=False):
     if check_panel_type:
-        assert(type(left) == type(right))
+        assert_isinstance(left, type(right))
 
     assert(left.items.equals(right.items))
     assert(left.major_axis.equals(right.major_axis))
diff --git a/scripts/json_manip.py b/scripts/json_manip.py
index 29c2d88aa..0b2ac8ff6 100644
--- a/scripts/json_manip.py
+++ b/scripts/json_manip.py
@@ -211,7 +211,7 @@ def denorm(queries,iterable_of_things,default=None):
             #print "-- result: ", r
             if not r:
                 r = [default]
-            if type(r[0]) is type({}):
+            if isinstance(r[0], type({})):
                 fields.append(sorted(r[0].keys()))  # dicty answers
             else:
                 fields.append([q])  # stringy answer
@@ -227,7 +227,7 @@ def denorm(queries,iterable_of_things,default=None):
             U = dict()
             for (ii,thing) in enumerate(p):
                 #print ii,thing
-                if type(thing) is type({}):
+                if isinstance(thing, type({})):
                     U.update(thing)
                 else:
                     U[fields[ii][0]] = thing
@@ -284,11 +284,11 @@ def flatten(*stack):
 def _Q(filter_, thing):
     """ underlying machinery for Q function recursion """
     T = type(thing)
-    if T is type({}):
+    if isinstance({}, T):
         for k,v in compat.iteritems(thing):
             #print k,v
             if filter_ == k:
-                if type(v) is type([]):
+                if isinstance(v, type([])):
                     yield iter(v)
                 else:
                     yield v
@@ -296,7 +296,7 @@ def _Q(filter_, thing):
             if type(v)  in (type({}),type([])):
                 yield Q(filter_,v)
 
-    elif T is type([]):
+    elif isinstance([], T):
         for k in thing:
             #print k
             yield Q(filter_,k)
@@ -318,9 +318,9 @@ def Q(filter_,thing):
     [3] returns a generator.  Use ``Ql`` if you want a list.
 
     """
-    if type(filter_) is type([]):
+    if isinstance(filter_, type([])):
         return flatten(*[_Q(x,thing) for x in filter_])
-    elif type(filter_) is type({}):
+    elif isinstance(filter_, type({})):
         d = dict.fromkeys(filter_.keys())
         #print d
         for k in d:
@@ -346,7 +346,7 @@ def Ql(filter_,thing):
     """ same as Q, but returns a list, not a generator """
     res = Q(filter_,thing)
 
-    if type(filter_) is type({}):
+    if isinstance(filter_, type({})):
         for k in res:
             res[k] = list(res[k])
         return res
diff --git a/vb_suite/perf_HEAD.py b/vb_suite/perf_HEAD.py
index 0f2adf41d..cd0a51d02 100755
--- a/vb_suite/perf_HEAD.py
+++ b/vb_suite/perf_HEAD.py
@@ -105,7 +105,7 @@ def main():
 
         except Exception as e:
             exit_code = 1
-            if (type(e) == KeyboardInterrupt or
+            if (isinstance(e, KeyboardInterrupt) or
                     'KeyboardInterrupt' in str(d)):
                 raise KeyboardInterrupt()
 
