commit 370f8c8e243043a99be1d9e3118a98a3aa7ab43a
Author: Jeffrey Tratner <jeffrey.tratner@gmail.com>
Date:   Thu Jul 25 19:50:05 2013 -0400

    CLN: Add abstract base classes for certain objects
    
    Instead of the `is_series`, `is_generic`, etc methods, can use the ABC*
    methods to check for certain pandas types. This is useful because it
    helps decrease issues with circular imports (since they can be easily
    imported from core/common).
    
    The checks take advantage of the `_typ` and `_subtyp` attributes to
    handle checks. (e.g. `DataFrame` now has `_typ` of `"dataframe"`, etc.
    See the code for specifics.
    
    PERF: register _cacher as an internal name
    
    BUG: fixed abstract base class type checking bug in py2.6
    
    DOC: updates for abc type checking
    
    PERF: small perf gains in _get_item_cache

diff --git a/doc/source/release.rst b/doc/source/release.rst
index 61fd51570..19d92352e 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -127,12 +127,13 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
   - added _setup_axes to created generic NDFrame structures
   - moved methods
 
-    - from_axes,_wrap_array,axes,ix,shape,empty,swapaxes,transpose,pop
+    - from_axes,_wrap_array,axes,ix,loc,iloc,shape,empty,swapaxes,transpose,pop
     - __iter__,keys,__contains__,__len__,__neg__,__invert__
     - convert_objects,as_blocks,as_matrix,values
     - __getstate__,__setstate__ (though compat remains in frame/panel)
     - __getattr__,__setattr__
     - _indexed_same,reindex_like,reindex,align,where,mask
+    - fillna,replace
     - filter (also added axis argument to selectively filter on a different axis)
     - reindex,reindex_axis (which was the biggest change to make generic)
     - truncate (moved to become part of ``NDFrame``)
@@ -177,6 +178,9 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
   values to propogate to a new object from an existing (e.g. name in ``Series`` will follow
   more automatically now)
 
+- Internal type checking is now done via a suite of generated classes, allowing ``isinstance(value, klass)``
+  without having to directly import the klass, courtesy of @jtratner
+
 - Bug in Series update where the parent frame is not updating its cache based on
   changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)
 
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index b38e6e2c5..db1ffd75a 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -151,6 +151,7 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
     - __getstate__,__setstate__ (though compat remains in frame/panel)
     - __getattr__,__setattr__
     - _indexed_same,reindex_like,reindex,align,where,mask
+    - fillna,replace
     - filter (also added axis argument to selectively filter on a different axis)
     - reindex,reindex_axis (which was the biggest change to make generic)
     - truncate (moved to become part of ``NDFrame``)
@@ -195,6 +196,9 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
   values to propogate to a new object from an existing (e.g. name in ``Series`` will follow
   more automatically now)
 
+- Internal type checking is now done via a suite of generated classes, allowing ``isinstance(value, klass)``
+  without having to directly import the klass, courtesy of @jtratner
+
 - Bug in Series update where the parent frame is not updating its cached based on
   changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)
 
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 7af4be1c3..5765340f2 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -48,30 +48,26 @@ _TD_DTYPE = np.dtype('m8[ns]')
 _INT64_DTYPE = np.dtype(np.int64)
 _DATELIKE_DTYPES = set([np.dtype(t) for t in ['M8[ns]', 'm8[ns]']])
 
-
-def is_series(obj):
-    return getattr(obj, '_typ', None) == 'series'
-
-
-def is_sparse_series(obj):
-    return getattr(obj, '_subtyp', None) in ('sparse_series', 'sparse_time_series')
-
-
-def is_sparse_array_like(obj):
-    return getattr(obj, '_subtyp', None) in ['sparse_array', 'sparse_series', 'sparse_array']
-
-
-def is_dataframe(obj):
-    return getattr(obj, '_typ', None) == 'dataframe'
-
-
-def is_panel(obj):
-    return getattr(obj, '_typ', None) == 'panel'
-
-
-def is_generic(obj):
-    return getattr(obj, '_data', None) is not None
-
+# define abstract base classes to enable isinstance type checking on our objects
+def create_pandas_abc_type(name, attr, comp):
+    @classmethod
+    def _check(cls, inst):
+        return getattr(inst, attr, None) in comp
+    dct = dict(__instancecheck__=_check,
+               __subclasscheck__=_check)
+    meta = type("ABCBase", (type,), dct)
+    return meta(name, tuple(), dct)
+
+ABCSeries = create_pandas_abc_type("ABCSeries", "_typ", ("series",))
+ABCDataFrame = create_pandas_abc_type("ABCDataFrame", "_typ", ("dataframe",))
+ABCPanel = create_pandas_abc_type("ABCPanel", "_typ", ("panel",))
+ABCSparseSeries = create_pandas_abc_type("ABCSparseSeries", "_subtyp", ('sparse_series', 'sparse_time_series'))
+ABCSparseArray = create_pandas_abc_type("ABCSparseArray", "_subtyp", ('sparse_array', 'sparse_series'))
+
+class _ABCGeneric(type):
+    def __instancecheck__(cls, inst):
+        return hasattr(inst, "_data")
+ABCGeneric = _ABCGeneric("ABCGeneric", tuple(), {})
 
 def isnull(obj):
     """Detect missing values (NaN in numeric arrays, None/NaN in object arrays)
@@ -94,9 +90,9 @@ def _isnull_new(obj):
     if lib.isscalar(obj):
         return lib.checknull(obj)
 
-    if is_series(obj) or isinstance(obj, np.ndarray):
+    if isinstance(obj, (ABCSeries, np.ndarray)):
         return _isnull_ndarraylike(obj)
-    elif is_generic(obj):
+    elif isinstance(obj, ABCGeneric):
         return obj.apply(isnull)
     elif isinstance(obj, list) or hasattr(obj, '__array__'):
         return _isnull_ndarraylike(np.asarray(obj))
@@ -119,9 +115,9 @@ def _isnull_old(obj):
     if lib.isscalar(obj):
         return lib.checknull_old(obj)
 
-    if is_series(obj) or isinstance(obj, np.ndarray):
+    if isinstance(obj, (ABCSeries, np.ndarray)):
         return _isnull_ndarraylike_old(obj)
-    elif is_generic(obj):
+    elif isinstance(obj, ABCGeneric):
         return obj.apply(_isnull_old)
     elif isinstance(obj, list) or hasattr(obj, '__array__'):
         return _isnull_ndarraylike_old(np.asarray(obj))
@@ -182,7 +178,7 @@ def _isnull_ndarraylike(obj):
     else:
         result = np.isnan(obj)
 
-    if is_series(obj):
+    if isinstance(obj, ABCSeries):
         from pandas import Series
         result = Series(result, index=obj.index, copy=False)
 
@@ -213,7 +209,7 @@ def _isnull_ndarraylike_old(obj):
     else:
         result = -np.isfinite(obj)
 
-    if is_series(obj):
+    if isinstance(obj, ABCSeries):
         from pandas import Series
         result = Series(result, index=obj.index, copy=False)
 
@@ -1300,7 +1296,7 @@ def _possibly_cast_to_timedelta(value, coerce=True):
         return np.array([ convert(v,dtype) for v in value ], dtype='m8[ns]')
 
     # deal with numpy not being able to handle certain timedelta operations
-    if (isinstance(value, np.ndarray) or is_series(value)) and value.dtype.kind == 'm':
+    if isinstance(value, (ABCSeries, np.ndarray)) and value.dtype.kind == 'm':
         if value.dtype != 'timedelta64[ns]':
             value = value.astype('timedelta64[ns]')
         return value
@@ -1384,7 +1380,7 @@ def _possibly_cast_to_datetime(value, dtype, coerce=False):
 
 
 def _is_bool_indexer(key):
-    if isinstance(key, np.ndarray) or is_series(key):
+    if isinstance(key, (ABCSeries, np.ndarray)):
         if key.dtype == np.object_:
             key = np.asarray(_values_from_object(key))
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 75c034b38..8670827ba 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -36,7 +36,7 @@ class NDFrame(PandasObject):
     copy : boolean, default False
     """
     _internal_names = [
-        '_data', 'name', '_subtyp', '_index', '_default_kind', '_default_fill_value']
+        '_data', 'name', '_cacher', '_subtyp', '_index', '_default_kind', '_default_fill_value']
     _internal_names_set = set(_internal_names)
     _prop_attributes = []
 
@@ -697,14 +697,13 @@ class NDFrame(PandasObject):
 
     def _get_item_cache(self, item):
         cache = self._item_cache
-        try:
-            return cache[item]
-        except Exception:
+        res = cache.get(item)
+        if res is None:
             values = self._data.get(item)
             res = self._box_item_values(item, values)
             cache[item] = res
             res._cacher = (item,weakref.ref(self))
-            return res
+        return res
 
     def _box_item_values(self, key, values):
         raise NotImplementedError
@@ -1440,7 +1439,7 @@ class NDFrame(PandasObject):
 
             if len(self._get_axis(axis)) == 0:
                 return self
-            if isinstance(value, dict) or com.is_series(value):
+            if isinstance(value, (dict, com.ABCSeries)):
                 if axis == 1:
                     raise NotImplementedError('Currently only can fill '
                                               'with dict/Series column '
@@ -1585,7 +1584,7 @@ class NDFrame(PandasObject):
         self._consolidate_inplace()
 
         def is_dictlike(x):
-            return isinstance(x, dict) or com.is_series(x)
+            return isinstance(x, (dict, com.ABCSeries))
 
         if value is None:
             if not is_dictlike(to_replace):
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index b7c05bd09..b93777802 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -6,7 +6,7 @@ from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.compat import range, zip
 import pandas.compat as compat
 import pandas.core.common as com
-from pandas.core.common import _is_bool_indexer, is_series, is_dataframe
+from pandas.core.common import _is_bool_indexer, ABCSeries, ABCDataFrame
 import pandas.lib as lib
 
 import numpy as np
@@ -111,7 +111,7 @@ class _NDFrameIndexer(object):
             if not isinstance(indexer, tuple):
                 indexer = self._tuplify(indexer)
 
-            if is_series(value):
+            if isinstance(value, ABCSeries):
                 value = self._align_series(indexer, value)
 
             info_axis = self.obj._info_axis_number
@@ -135,7 +135,7 @@ class _NDFrameIndexer(object):
             if _is_list_like(value):
 
                 # we have an equal len Frame
-                if is_dataframe(value) and value.ndim > 1:
+                if isinstance(value, ABCDataFrame) and value.ndim > 1:
 
                     for item in labels:
 
@@ -176,10 +176,10 @@ class _NDFrameIndexer(object):
             if isinstance(indexer, tuple):
                 indexer = _maybe_convert_ix(*indexer)
 
-            if is_series(value):
+            if isinstance(value, ABCSeries):
                 value = self._align_series(indexer, value)
 
-            elif is_dataframe(value):
+            elif isinstance(value, ABCDataFrame):
                 value = self._align_frame(indexer, value)
 
             if isinstance(value, Panel):
@@ -396,7 +396,7 @@ class _NDFrameIndexer(object):
 
                     # unfortunately need an odious kludge here because of
                     # DataFrame transposing convention
-                    if (is_dataframe(section) and i > 0
+                    if (isinstance(section, ABCDataFrame) and i > 0
                             and len(new_key) == 2):
                         a, b = new_key
                         new_key = b, a
@@ -1027,7 +1027,7 @@ def _check_bool_indexer(ax, key):
     # this function assumes that com._is_bool_indexer(key) == True
 
     result = key
-    if is_series(key) and not key.index.equals(ax):
+    if isinstance(key, ABCSeries) and not key.index.equals(ax):
         result = result.reindex(ax)
         mask = com.isnull(result.values)
         if mask.any():
@@ -1042,6 +1042,7 @@ def _check_bool_indexer(ax, key):
 
     return result
 
+
 def _maybe_convert_indices(indices, n):
     """ if we have negative indicies, translate to postive here
         if have indicies that are out-of-bounds, raise an IndexError """
@@ -1063,7 +1064,7 @@ def _maybe_convert_ix(*args):
 
     ixify = True
     for arg in args:
-        if not (isinstance(arg, (np.ndarray, list)) or is_series(arg)):
+        if not isinstance(arg, (np.ndarray, list, ABCSeries)):
             ixify = False
 
     if ixify:
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 224c0b243..35d185b48 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -8,7 +8,7 @@ import numpy as np
 from pandas.core.base import PandasObject
 
 from pandas.core.common import (_possibly_downcast_to_dtype, isnull, _NS_DTYPE,
-                                _TD_DTYPE, is_series, is_sparse_series)
+                                _TD_DTYPE, ABCSeries, ABCSparseSeries)
 from pandas.core.index import (Index, MultiIndex, _ensure_index,
                                _handle_legacy_indexes)
 from pandas.core.indexing import _check_slice_bounds, _maybe_convert_indices
@@ -2945,7 +2945,7 @@ def form_blocks(arrays, names, axes):
     datetime_items = []
 
     for i, (k, v) in enumerate(zip(names, arrays)):
-        if isinstance(v, SparseArray) or is_sparse_series(v):
+        if isinstance(v, (SparseArray, ABCSparseSeries)):
             sparse_items.append((i, k, v))
         elif issubclass(v.dtype.type, np.floating):
             float_items.append((i, k, v))
@@ -3075,13 +3075,13 @@ def _stack_arrays(tuples, ref_items, dtype):
 
     # fml
     def _asarray_compat(x):
-        if is_series(x):
+        if isinstance(x, ABCSeries):
             return x.values
         else:
             return np.asarray(x)
 
     def _shape_compat(x):
-        if is_series(x):
+        if isinstance(x, ABCSeries):
             return len(x),
         else:
             return x.shape
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 7b3bc21fd..33d964da3 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -19,7 +19,7 @@ from pandas.core.common import (isnull, notnull, _is_bool_indexer,
                                 _asarray_tuplesafe, is_integer_dtype,
                                 _NS_DTYPE, _TD_DTYPE,
                                 _infer_dtype_from_scalar, is_list_like, _values_from_object,
-                                is_sparse_array_like)
+                                ABCSparseArray)
 from pandas.core.index import (Index, MultiIndex, InvalidIndexError,
                                _ensure_index, _handle_legacy_indexes)
 from pandas.core.indexing import (
@@ -584,7 +584,7 @@ class Series(generic.NDFrame):
             else:
 
                 # handle sparse passed here (and force conversion)
-                if is_sparse_array_like(data):
+                if isinstance(data, ABCSparseArray):
                     data = data.to_dense()
 
             if index is None:
@@ -613,7 +613,7 @@ class Series(generic.NDFrame):
     def from_array(cls, arr, index=None, name=None, copy=False, fastpath=False):
 
         # return a sparse series here
-        if is_sparse_array_like(arr):
+        if isinstance(arr, ABCSparseArray):
             from pandas.sparse.series import SparseSeries
             cls = SparseSeries
 
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index 336dcc004..592546992 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -489,7 +489,7 @@ def _maybe_to_dense(obj):
 
 
 def _maybe_to_sparse(array):
-    if com.is_sparse_series(array):
+    if isinstance(array, com.ABCSparseSeries):
         array = SparseArray(
             array.values, sparse_index=array.sp_index, fill_value=array.fill_value, copy=True)
     if not isinstance(array, SparseArray):
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index c4d8609b9..765dbc07b 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -17,7 +17,7 @@ from pandas.core.index import (Index, MultiIndex, _get_combined_index,
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
                                    make_block, _consolidate)
 from pandas.util.decorators import cache_readonly, Appender, Substitution
-from pandas.core.common import PandasError
+from pandas.core.common import PandasError, ABCSeries
 import pandas.core.common as com
 
 import pandas.lib as lib
@@ -304,8 +304,8 @@ class _MergeOperation(object):
         left_drop = []
         left, right = self.left, self.right
 
-        is_lkey = lambda x: isinstance(x, (np.ndarray, Series)) and len(x) == len(left)
-        is_rkey = lambda x: isinstance(x, (np.ndarray, Series)) and len(x) == len(right)
+        is_lkey = lambda x: isinstance(x, (np.ndarray, ABCSeries)) and len(x) == len(left)
+        is_rkey = lambda x: isinstance(x, (np.ndarray, ABCSeries)) and len(x) == len(right)
 
         # ugh, spaghetti re #733
         if _any(self.left_on) and _any(self.right_on):
@@ -941,7 +941,7 @@ class _Concatenator(object):
         if isinstance(sample, DataFrame):
             axis = 1 if axis == 0 else 0
 
-        self._is_series = isinstance(sample, Series)
+        self._is_series = isinstance(sample, ABCSeries)
         if not ((0 <= axis <= sample.ndim)):
             raise AssertionError()
 
diff --git a/vb_suite/frame_methods.py b/vb_suite/frame_methods.py
index 3bf69e602..f6909802f 100644
--- a/vb_suite/frame_methods.py
+++ b/vb_suite/frame_methods.py
@@ -83,7 +83,7 @@ frame_boolean_row_select = Benchmark('df[bool_arr]', setup,
 # iteritems (monitor no-copying behaviour)
 
 setup = common_setup + """
-df = DataFrame(randn(10000, 100))
+df = DataFrame(randn(10000, 1000))
 
 def f():
     if hasattr(df, '_item_cache'):
