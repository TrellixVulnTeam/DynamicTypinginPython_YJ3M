commit 83b216c9efb439c1d19690feff1dcba58c6a2f88
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Aug 18 20:42:46 2011 -0400

    ENH: groupby refactoring, testing, and perf opt. Series, DataFrame take functions

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index c5d4987bb..86ed20745 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -253,6 +253,10 @@ class DataFrame(NDFrame):
 
         return self._ix
 
+    @property
+    def shape(self):
+        return (len(self.index), len(self.columns))
+
     #----------------------------------------------------------------------
     # Class behavior
 
@@ -997,6 +1001,34 @@ class DataFrame(NDFrame):
         return self.reindex(index=other.index, columns=other.columns,
                             method=method)
 
+    def take(self, indices, axis=0):
+        """
+        Analogous to ndarray.take, return DataFrame corresponding to requested
+        indices along an axis
+
+        Parameters
+        ----------
+        indices : list / array of ints
+        axis : {0, 1}
+
+        Returns
+        -------
+        taken : DataFrame
+        """
+        if axis == 0:
+            new_index = self.index.take(indices)
+            new_columns = self.columns
+        else:
+            new_index = self.index
+            new_columns = self.columns.take(indices)
+
+        # TODO: implement take on BlockManager
+        if self._data.is_mixed_dtype():
+            return self.reindex(index=new_index, columns=new_columns)
+
+        new_values = self.values.take(indices, axis=axis)
+        return DataFrame(new_values, index=new_index, columns=new_columns)
+
     #----------------------------------------------------------------------
     # Reindex-based selection methods
 
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index c50d84f37..d082e04fa 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -5,13 +5,14 @@ import types
 import numpy as np
 
 from pandas.core.frame import DataFrame
-from pandas.core.generic import NDFrame
-from pandas.core.index import Factor, MultiIndex
+from pandas.core.generic import NDFrame, PandasObject
+from pandas.core.index import Factor, Index, MultiIndex
 from pandas.core.internals import BlockManager
 from pandas.core.series import Series
 from pandas.core.panel import WidePanel
 import pandas._tseries as _tseries
 
+
 def groupby(obj, grouper, **kwds):
     """
     Intercepts creation and dispatches to the appropriate class based
@@ -34,7 +35,7 @@ class GroupBy(object):
     """
     def __init__(self, obj, grouper=None, axis=0, level=None,
                  groupings=None, exclusions=None, name=None):
-        self.name = name
+        self._name = name
         self.obj = obj
         self.axis = axis
         self.level = level
@@ -46,13 +47,31 @@ class GroupBy(object):
         self.groupings = groupings
         self.exclusions = set(exclusions)
 
+    @property
+    def groups(self):
+        if len(self.groupings) == 1:
+            return self.primary.groups
+        else:
+            raise NotImplementedError
+
+    @property
+    def name(self):
+        if self._name is None:
+            return 'result'
+        else:
+            return self._name
+
     def _get_obj_with_exclusions(self):
         return self.obj
 
     @property
-    def _result_shape(self):
+    def _group_shape(self):
         return tuple(len(ping.ids) for ping in self.groupings)
 
+    @property
+    def _agg_stride_shape(self):
+        raise NotImplementedError
+
     def __getattribute__(self, attr):
         try:
             return object.__getattribute__(self, attr)
@@ -111,12 +130,13 @@ class GroupBy(object):
                 yield it
 
     def _multi_iter(self):
-        if isinstance(self.obj, NDFrame):
+        tipo = type(self.obj)
+        if isinstance(self.obj, DataFrame):
+            data = self.obj
+        elif isinstance(self.obj, NDFrame):
             data = self.obj._data
-            tipo = type(self.obj)
         else:
             data = self.obj
-            tipo = type(self.obj)
 
         def flatten(gen, level=0):
             ids = self.groupings[level].ids
@@ -143,15 +163,11 @@ class GroupBy(object):
     def _get_names(self):
         axes = [ping.levels for ping in self.groupings]
         grouping_names = [ping.name for ping in self.groupings]
-        shape = self._result_shape
+        shape = self._group_shape
         return zip(grouping_names, _ravel_names(axes, shape))
 
     def _iterate_slices(self):
-        name = self.name
-        if name is None:
-            name = 'result'
-
-        yield name, self.obj
+        yield self.name, self.obj
 
     def transform(self, func):
         raise NotImplementedError
@@ -161,7 +177,7 @@ class GroupBy(object):
         Compute mean of groups, excluding missing values
         """
         try:
-            return self._cython_aggregate('mean')
+            return self._cython_agg_general('mean')
         except Exception:
             return self.aggregate(np.mean)
 
@@ -170,16 +186,16 @@ class GroupBy(object):
         Compute sum of values, excluding missing values
         """
         try:
-            return self._cython_aggregate('add')
+            return self._cython_agg_general('add')
         except Exception:
             return self.aggregate(np.sum)
 
-    def _cython_aggregate_dict(self, how):
+    def _cython_agg_general(self, how):
         label_list = [ping.labels for ping in self.groupings]
-        shape = self._result_shape
+        shape = self._group_shape
 
         # TODO: address inefficiencies, like duplicating effort (should
-        # aggregate all the columns at once)
+        # aggregate all the columns at once?)
 
         output = {}
         cannot_agg = []
@@ -196,76 +212,73 @@ class GroupBy(object):
             mask = counts.ravel() > 0
             output[name] = result[mask]
 
-        return output, mask
+        return self._wrap_aggregated_output(output, mask)
 
     def _get_multi_index(self, mask):
         name_list = self._get_names()
         masked = [raveled[mask] for _, raveled in name_list]
         return MultiIndex.from_arrays(masked)
 
-    def _aggregate_multi_group(self, arg):
-        # want to cythonize?
-        shape = self._result_shape
-        result = np.empty(shape, dtype=float)
-        result.fill(np.nan)
-        counts = np.zeros(shape, dtype=int)
+    def _python_agg_general(self, arg):
+        group_shape = self._group_shape
+        counts = np.zeros(group_shape, dtype=int)
 
-        def _doit(reschunk, ctchunk, gen):
+        # want to cythonize?
+        def _doit(reschunk, ctchunk, gen, shape_axis=0):
             for i, (_, subgen) in enumerate(gen):
-                if isinstance(subgen, Series):
-                    ctchunk[i] = len(subgen)
-                    if len(subgen) == 0:
+                if isinstance(subgen, PandasObject):
+                    size = subgen.shape[shape_axis]
+                    ctchunk[i] = size
+                    if size == 0:
                         continue
                     reschunk[i] = arg(subgen)
                 else:
-                    _doit(reschunk[i], ctchunk[i], subgen)
+                    _doit(reschunk[i], ctchunk[i], subgen,
+                          shape_axis=shape_axis)
 
         gen_factory = self._generator_factory
 
-        output = {}
+        try:
+            stride_shape = self._agg_stride_shape
+            output = np.empty(group_shape + stride_shape,
+                              dtype=float)
+            output.fill(np.nan)
+            obj = self._get_obj_with_exclusions()
+            _doit(output, counts, gen_factory(obj),
+                  shape_axis=self.axis)
 
-        # iterate through "columns" ex exclusions to populate output dict
-        for name, obj in self._iterate_slices():
-            _doit(result, counts, gen_factory(obj))
-            # TODO: same mask for every column...
             mask = counts.ravel() > 0
-            output[name] = result.ravel()[mask]
-
+            output = output.reshape((np.prod(group_shape),) + stride_shape)
+            output = output[mask]
+        except TypeError:
+            result = np.empty(group_shape, dtype=float)
             result.fill(np.nan)
+            # iterate through "columns" ex exclusions to populate output dict
+            output = {}
+            for name, obj in self._iterate_slices():
+                _doit(result, counts, gen_factory(obj))
+                # TODO: same mask for every column...
+                result.fill(np.nan)
+                output[name] = result.ravel()
 
-        name_list = self._get_names()
-
-        if len(self.groupings) > 1:
-            masked = [raveled[mask] for _, raveled in name_list]
-            index = MultiIndex.from_arrays(masked)
-            result = DataFrame(output, index=index)
-        else:
-            result = DataFrame(output, index=name_list[0][1])
+            mask = counts.ravel() > 0
+            for name, result in output.iteritems():
+                output[name] = result[mask]
 
-        if self.axis == 1:
-            result = result.T
-
-        return result
+        return self._wrap_aggregated_output(output, mask)
 
     @property
     def _generator_factory(self):
         labels = [ping.labels for ping in self.groupings]
-        shape = self._result_shape
+        shape = self._group_shape
 
-        # XXX: HACK! need to do something about all this...
         if isinstance(self.obj, NDFrame):
             factory = self.obj._constructor
         else:
             factory = None
 
+        factory = None
         axis = self.axis
-
-        if isinstance(self.obj, DataFrame):
-            if axis == 0:
-                axis = 1
-            elif axis == 1:
-                axis = 0
-
         return lambda obj: generate_groups(obj, labels, shape, axis=axis,
                                            factory=factory)
 
@@ -386,29 +399,21 @@ def _convert_grouper(axis, grouper):
     else:
         return grouper
 
-def multi_groupby(obj, op, *columns):
-    cur = columns[0]
-    grouped = obj.groupby(cur)
-    if len(columns) == 1:
-        return grouped.aggregate(op)
-    else:
-        result = {}
-        for key, value in grouped:
-            result[key] = multi_groupby(value, op, columns[1:])
-    return result
-
 class SeriesGroupBy(GroupBy):
 
     _cythonized_methods = set(['add', 'mean'])
 
+    @property
+    def _agg_stride_shape(self):
+        return ()
+
     def get_group(self, name, obj=None):
+        # faster get_group for Series
         if obj is None:
             obj = self.obj
 
         inds = self.primary.indices[name]
-        new_values = obj.values.take(inds)
-        new_index = obj.index.take(inds)
-        return Series(new_values, index=new_index)
+        return obj.take(inds)
 
     def aggregate(self, arg):
         """
@@ -429,16 +434,15 @@ class SeriesGroupBy(GroupBy):
         -------
         Series or DataFrame
         """
+        if isinstance(arg, basestring):
+            return getattr(self, arg)()
+
         if len(self.groupings) > 1:
-            # HACK for now
-            return self._aggregate_multi_group(arg)
+            return self._python_agg_general(arg)
 
         if hasattr(arg,'__iter__'):
             ret = self._aggregate_multiple_funcs(arg)
         else:
-            if isinstance(arg, basestring):
-                return getattr(self, arg)()
-
             try:
                 result = self._aggregate_simple(arg)
             except Exception:
@@ -454,11 +458,10 @@ class SeriesGroupBy(GroupBy):
 
         return ret
 
-    def _cython_aggregate(self, how):
-        output, mask = self._cython_aggregate_dict(how)
-
-        # sort of a kludge
-        output = output['result']
+    def _wrap_aggregated_output(self, output, mask):
+        if isinstance(output, dict):
+            # sort of a kludge
+            output = output[self.name]
 
         if len(self.groupings) > 1:
             index = self._get_multi_index(mask)
@@ -558,6 +561,25 @@ def _ravel_names(axes, shape):
 
 class DataFrameGroupBy(GroupBy):
 
+    def get_group(self, name, obj=None):
+        # faster get_group for Series
+        if obj is None:
+            obj = self.obj
+
+        inds = self.primary.indices[name]
+        return obj.take(inds, axis=self.axis)
+
+    @property
+    def _agg_stride_shape(self):
+        if self.axis == 0:
+            n = len(self.obj.columns)
+        else:
+            n = len(self.obj.index)
+
+        n -= len(self.exclusions)
+
+        return n,
+
     def __getitem__(self, key):
         if key not in self.obj:
             raise KeyError('column %s not found' % key)
@@ -579,7 +601,10 @@ class DataFrameGroupBy(GroupBy):
             yield val, slicer(val)
 
     def _get_obj_with_exclusions(self):
-        return self.obj.drop(self.exclusions, axis=1)
+        if len(self.exclusions) > 0:
+            return self.obj.drop(self.exclusions, axis=1)
+        else:
+            return self.obj
 
     def aggregate(self, arg):
         """
@@ -597,9 +622,8 @@ class DataFrameGroupBy(GroupBy):
         -------
         aggregated : DataFrame
         """
-        if len(self.groupings) > 1:
-            # HACK for now
-            return self._aggregate_multi_group(arg)
+        if isinstance(arg, basestring):
+            return getattr(self, arg)()
 
         result = {}
         if isinstance(arg, dict):
@@ -608,25 +632,12 @@ class DataFrameGroupBy(GroupBy):
 
             result = DataFrame(result)
         else:
+            if len(self.groupings) > 1:
+                return self._python_agg_general(arg)
             result = self._aggregate_generic(arg, axis=self.axis)
 
         return result
 
-    def _cython_aggregate(self, how):
-        output, mask = self._cython_aggregate_dict(how)
-
-        if len(self.groupings) > 1:
-            index = self._get_multi_index(mask)
-            result = DataFrame(output, index=index)
-        else:
-            name_list = self._get_names()
-            result = DataFrame(output, index=name_list[0][1])
-
-        if self.axis == 1:
-            result = result.T
-
-        return result
-
     def _aggregate_generic(self, agger, axis=0):
         result = {}
 
@@ -670,6 +681,19 @@ class DataFrameGroupBy(GroupBy):
 
         return DataFrame(result)
 
+    def _wrap_aggregated_output(self, output, mask):
+        if len(self.groupings) > 1:
+            index = self._get_multi_index(mask)
+            result = DataFrame(output, index=index)
+        else:
+            name_list = self._get_names()
+            result = DataFrame(output, index=name_list[0][1])
+
+        if self.axis == 1:
+            result = result.T
+
+        return result
+
     def transform(self, func):
         """
         For given DataFrame, group index by given mapper function or dict, take
@@ -699,26 +723,11 @@ class DataFrameGroupBy(GroupBy):
         >>> grouped = df.groupby(lambda x: mapping[x])
         >>> grouped.transform(lambda x: (x - x.mean()) / x.std())
         """
-        # DataFrame objects?
-        result_values = np.empty_like(self.obj.values)
-
-        if self.axis == 0:
-            trans = lambda x: x
-        elif self.axis == 1:
-            trans = lambda x: x.T
-
-        result_values = trans(result_values)
-
-        for val, group in self.primary.groups.iteritems():
-            if not isinstance(group, list): # pragma: no cover
-                group = list(group)
+        applied = []
 
-            if self.axis == 0:
-                subframe = self.obj.reindex(group)
-                indexer, _ = self.obj.index.get_indexer(subframe.index)
-            else:
-                subframe = self.obj.reindex(columns=group)
-                indexer, _ = self.obj.columns.get_indexer(subframe.columns)
+        obj = self._get_obj_with_exclusions()
+        for val, inds in self.primary.indices.iteritems():
+            subframe = obj.take(inds, axis=self.axis)
             subframe.groupName = val
 
             try:
@@ -726,12 +735,30 @@ class DataFrameGroupBy(GroupBy):
             except Exception: # pragma: no cover
                 res = func(subframe)
 
-            result_values[indexer] = trans(res.values)
+            # broadcasting
+            if isinstance(res, Series):
+                if res.index is obj.index:
+                    subframe.T.values[:] = res
+                else:
+                    subframe.values[:] = res
+
+                applied.append(subframe)
+            else:
+                applied.append(res)
 
-        result_values = trans(result_values)
+        if self.axis == 0:
+            all_index = [np.asarray(x.index) for x in applied]
+            new_index = Index(np.concatenate(all_index))
+            new_columns = obj.columns
+        else:
+            all_columns = [np.asarray(x.columns) for x in applied]
+            new_columns = Index(np.concatenate(all_columns))
+            new_index = obj.index
 
-        return DataFrame(result_values, index=self.obj.index,
-                         columns=self.obj.columns)
+        new_values = np.concatenate([x.values for x in applied],
+                                    axis=self.axis)
+        result = DataFrame(new_values, index=new_index, columns=new_columns)
+        return result.reindex(index=obj.index, columns=obj.columns)
 
 
 class WidePanelGroupBy(GroupBy):
@@ -809,11 +836,11 @@ def _group_reorder(data, label_list, axis=0):
         # this is sort of wasteful but...
         sorted_axis = data.axes[axis].take(indexer)
         sorted_data = data.reindex_axis(sorted_axis, axis=axis)
-    elif isinstance(data, Series):
+    if isinstance(data, Series):
         sorted_axis = data.index.take(indexer)
         sorted_data = data.reindex(sorted_axis)
-    else:
-        sorted_data = data.take(indexer)
+    elif isinstance(data, DataFrame):
+        sorted_data = data.take(indexer, axis=axis)
 
     return sorted_data, sorted_labels
 
@@ -823,7 +850,13 @@ def _generate_groups(data, labels, shape, start, end, axis=0, which=0,
     edges = axis_labels.searchsorted(np.arange(1, shape[which] + 1),
                                      side='left')
 
-    if isinstance(data, BlockManager):
+    if isinstance(data, DataFrame):
+        def slicer(data, slob):
+            if axis == 0:
+                return data[slob]
+            else:
+                return data.ix[:, slob]
+    elif isinstance(data, BlockManager):
         def slicer(data, slob):
             return factory(data.get_slice(slob, axis=axis))
     else:
diff --git a/pandas/core/series.py b/pandas/core/series.py
index aafa7a336..8a751a5d8 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1094,6 +1094,23 @@ class Series(np.ndarray, PandasObject):
         """
         return self.reindex(other.index, method=method)
 
+    def take(self, indices):
+        """
+        Analogous to ndarray.take, return Series corresponding to requested
+        indices
+
+        Parameters
+        ----------
+        indices : list / array of ints
+
+        Returns
+        -------
+        taken : Series
+        """
+        new_index = self.index.take(indices)
+        new_values = self.values.take(indices)
+        return Series(new_values, index=new_index)
+
     def fillna(self, value=None, method='pad'):
         """
         Fill NaN values using the specified method.
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 6e70d6b13..39307aec9 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -66,6 +66,13 @@ class TestGroupBy(unittest.TestCase):
                              'C' : np.random.randn(8),
                              'D' : np.random.randn(8)})
 
+        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
+                                   ['one', 'two', 'three']],
+                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
+                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]])
+        self.mframe = DataFrame(np.random.randn(10, 3), index=index,
+                                columns=['A', 'B', 'C'])
+
     def test_basic(self):
         data = Series(np.arange(9) / 3, index=np.arange(9))
 
@@ -110,6 +117,37 @@ class TestGroupBy(unittest.TestCase):
         # corner cases
         self.assertRaises(Exception, grouped.aggregate, lambda x: x * 2)
 
+    def test_series_agg_corner(self):
+        # nothing to group, all NA
+        result = self.ts.groupby(self.ts * np.nan).sum()
+        assert_series_equal(result, Series([]))
+
+    def test_aggregate_str_func(self):
+        def _check_results(grouped):
+            # single series
+            result = grouped['A'].agg('std')
+            expected = grouped['A'].std()
+            assert_series_equal(result, expected)
+
+            # group frame by function name
+            result = grouped.aggregate('var')
+            expected = grouped.var()
+            assert_frame_equal(result, expected)
+
+            # group frame by function dict
+            result = grouped.agg({'A' : 'var', 'B' : 'std', 'C' : 'mean'})
+            expected = DataFrame({'A' : grouped['A'].var(),
+                                  'B' : grouped['B'].std(),
+                                  'C' : grouped['C'].mean()})
+            assert_frame_equal(result, expected)
+
+        by_weekday = self.tsframe.groupby(lambda x: x.weekday())
+        _check_results(by_weekday)
+
+        by_mwkday = self.tsframe.groupby([lambda x: x.month,
+                                          lambda x: x.weekday()])
+        _check_results(by_mwkday)
+
     def test_basic_regression(self):
         # regression
         T = [1.0*x for x in range(1,10) *10][:1095]
@@ -139,6 +177,15 @@ class TestGroupBy(unittest.TestCase):
             for idx in group.index:
                 self.assertEqual(transformed[idx], mean)
 
+    def test_dispatch_transform(self):
+        df = self.tsframe[::5].reindex(self.tsframe.index)
+
+        filled = df.groupby(lambda x: x.month).fillna(method='pad')
+
+        fillit = lambda x: x.fillna(method='pad')
+        expected = df.groupby(lambda x: x.month).transform(fillit)
+        assert_frame_equal(filled, expected)
+
     def test_with_na(self):
         index = Index(np.arange(10))
         values = Series(np.ones(10), index)
@@ -338,7 +385,7 @@ class TestGroupBy(unittest.TestCase):
                 result_col = op(grouped[col])
                 exp = expected[col]
                 pivoted = result1[col].unstack()
-                pivoted2 = result_col[col].unstack()
+                pivoted2 = result_col.unstack()
                 assert_frame_equal(pivoted.reindex_like(exp), exp)
                 assert_frame_equal(pivoted2.reindex_like(exp), exp)
 
@@ -362,8 +409,10 @@ class TestGroupBy(unittest.TestCase):
         grouped = df.T.groupby([lambda x: x.year,
                                 lambda x: x.month,
                                 lambda x: x.day], axis=1)
+        agged = grouped.agg(lambda x: x.sum(1))
+        assert_almost_equal(df.T.values, agged.values)
 
-        agged = grouped.agg(np.sum)
+        agged = grouped.agg(lambda x: x.sum(1))
         assert_almost_equal(df.T.values, agged.values)
 
     def test_groupby_multi_corner(self):
@@ -416,13 +465,16 @@ class TestGroupBy(unittest.TestCase):
         _testit(lambda x: x.sum())
         _testit(lambda x: x.mean())
 
+    def test_grouping_attrs(self):
+        deleveled = self.mframe.delevel()
+        grouped = deleveled.groupby(['label_0', 'label_1'])
+
+        for i, ping in enumerate(grouped.groupings):
+            the_counts = self.mframe.groupby(level=i).count()['A']
+            assert_almost_equal(ping.counts, the_counts)
+
     def test_groupby_level(self):
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
-                                   ['one', 'two', 'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]])
-        frame = DataFrame(np.random.randn(10, 3), index=index,
-                          columns=['A', 'B', 'C'])
+        frame = self.mframe
         deleveled = frame.delevel()
 
         result0 = frame.groupby(level=0).sum()
@@ -439,29 +491,28 @@ class TestGroupBy(unittest.TestCase):
         assert_frame_equal(result0, expected0.T)
         assert_frame_equal(result1, expected1.T)
 
+        # raise exception for non-MultiIndex
+        self.assertRaises(ValueError, self.df.groupby, level=0)
+
     def test_groupby_level_mapper(self):
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
-                                   ['one', 'two', 'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]])
-        frame = DataFrame(np.random.randn(10, 3), index=index,
-                          columns=['A', 'B', 'C'])
+        frame = self.mframe
         deleveled = frame.delevel()
 
-        result0 = frame.groupby(level=0).sum()
-        result1 = frame.groupby(level=1).sum()
+        mapper0 = {'foo' : 0, 'bar' : 0,
+                   'baz' : 1, 'qux' : 1}
+        mapper1 = {'one' : 0, 'two' : 0, 'three' : 1}
 
-        expected0 = frame.groupby(deleveled['label_0']).sum()
-        expected1 = frame.groupby(deleveled['label_1']).sum()
+        result0 = frame.groupby(mapper0, level=0).sum()
+        result1 = frame.groupby(mapper1, level=1).sum()
+
+        mapped_label0 = np.array([mapper0.get(x) for x in deleveled['label_0']])
+        mapped_label1 = np.array([mapper1.get(x) for x in deleveled['label_1']])
+        expected0 = frame.groupby(mapped_label0).sum()
+        expected1 = frame.groupby(mapped_label1).sum()
 
         assert_frame_equal(result0, expected0)
         assert_frame_equal(result1, expected1)
 
-        result0 = frame.T.groupby(level=0, axis=1).sum()
-        result1 = frame.T.groupby(level=1, axis=1).sum()
-        assert_frame_equal(result0, expected0.T)
-        assert_frame_equal(result1, expected1.T)
-
 class TestPanelGroupBy(unittest.TestCase):
 
     def setUp(self):
diff --git a/scripts/groupby_test.py b/scripts/groupby_test.py
index c539b1444..708079f72 100644
--- a/scripts/groupby_test.py
+++ b/scripts/groupby_test.py
@@ -7,6 +7,7 @@ from pandas import *
 
 import pandas._tseries as tseries
 import pandas.core.groupby as gp
+import pandas.util.testing as tm
 reload(gp)
 
 """
@@ -59,11 +60,11 @@ res = DataFrame(res)
 grouped = df.groupby(['key1', 'key2'])
 """
 
-data = {'A' : [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
-        'B' : ['A', 'B'] * 6,
-        'C' : np.random.randn(12)}
-df = DataFrame(data)
-df['C'][2:10:2] = nan
+# data = {'A' : [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
+#         'B' : ['A', 'B'] * 6,
+#         'C' : np.random.randn(12)}
+# df = DataFrame(data)
+# df['C'][2:10:2] = nan
 
 # single column
 # grouped = df.drop(['B'], axis=1).groupby('A')
@@ -73,14 +74,34 @@ df['C'][2:10:2] = nan
 # exp = DataFrame({'C' : exp})
 # result = grouped.sum()
 
-grouped = df.groupby(['A', 'B'])
-expd = {}
-for cat1, cat2, group in grouped:
-    expd.setdefault(cat1, {})[cat2] = group['C'].sum()
-exp = DataFrame(expd).T.stack()
-result = grouped.sum()['C']
-
-print 'wanted'
-print exp
-print 'got'
-print result
+# grouped = df.groupby(['A', 'B'])
+# expd = {}
+# for cat1, cat2, group in grouped:
+#     expd.setdefault(cat1, {})[cat2] = group['C'].sum()
+# exp = DataFrame(expd).T.stack()
+# result = grouped.sum()['C']
+
+# print 'wanted'
+# print exp
+# print 'got'
+# print result
+
+# tm.N = 10000
+
+mapping = {'A': 0, 'C': 1, 'B': 0, 'D': 1}
+tf = lambda x: x - x.mean()
+
+df = tm.makeTimeDataFrame()
+
+# grouped = df.groupby(lambda x: x.strftime('%m/%y'))
+grouped = df.groupby(mapping, axis=1)
+groupedT = df.T.groupby(mapping, axis=0)
+
+r1 = groupedT.transform(tf).T
+r2 = grouped.transform(tf)
+
+fillit = lambda x: x.fillna(method='pad')
+
+f = lambda x: x
+
+transformed = df.groupby(lambda x: x.strftime('%m/%y')).transform(lambda x: x)
