commit a1dba2c6d6140896cdb23d9c9f094d8c71094ccf
Author: Samyak Jain <samyak.jn11@gmail.com>
Date:   Mon Oct 7 06:02:05 2019 +0530

    DOC: Fixed PR06 docstring errors in pandas.interval_range & pandas.util.hash_array (#28760)

diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index 29e297cb2..2cc15f765 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -1410,7 +1410,7 @@ def interval_range(
         Left bound for generating intervals
     end : numeric or datetime-like, default None
         Right bound for generating intervals
-    periods : integer, default None
+    periods : int, default None
         Number of periods to generate
     freq : numeric, string, or DateOffset, default None
         The length of each interval. Must be consistent with the type of start
diff --git a/pandas/core/util/hashing.py b/pandas/core/util/hashing.py
index 4bcc53606..ca5279e93 100644
--- a/pandas/core/util/hashing.py
+++ b/pandas/core/util/hashing.py
@@ -66,11 +66,12 @@ def hash_pandas_object(
 
     Parameters
     ----------
-    index : boolean, default True
+    index : bool, default True
         include the index in the hash (if Series/DataFrame)
-    encoding : string, default 'utf8'
+    encoding : str, default 'utf8'
         encoding for data & key when strings
-    hash_key : string key to encode, default to _default_hash_key
+    hash_key : str, default '_default_hash_key'
+        hash_key for string key to encode
     categorize : bool, default True
         Whether to first categorize object arrays before hashing. This is more
         efficient when the array contains duplicate values.
@@ -150,8 +151,8 @@ def hash_tuples(vals, encoding="utf8", hash_key=None):
     Parameters
     ----------
     vals : MultiIndex, list-of-tuples, or single tuple
-    encoding : string, default 'utf8'
-    hash_key : string key to encode, default to _default_hash_key
+    encoding : str, default 'utf8'
+    hash_key : str, default '_default_hash_key'
 
     Returns
     -------
@@ -193,8 +194,8 @@ def hash_tuple(val, encoding: str = "utf8", hash_key=None):
     Parameters
     ----------
     val : single tuple
-    encoding : string, default 'utf8'
-    hash_key : string key to encode, default to _default_hash_key
+    encoding : str, default 'utf8'
+    hash_key : str, default '_default_hash_key'
 
     Returns
     -------
@@ -216,8 +217,8 @@ def _hash_categorical(c, encoding: str, hash_key: str):
     Parameters
     ----------
     c : Categorical
-    encoding : string, default 'utf8'
-    hash_key : string key to encode, default to _default_hash_key
+    encoding : str, default 'utf8'
+    hash_key : str, default '_default_hash_key'
 
     Returns
     -------
@@ -253,9 +254,10 @@ def hash_array(vals, encoding: str = "utf8", hash_key=None, categorize: bool = T
     Parameters
     ----------
     vals : ndarray, Categorical
-    encoding : string, default 'utf8'
+    encoding : str, default 'utf8'
         encoding for data & key when strings
-    hash_key : string key to encode, default to _default_hash_key
+    hash_key : str, default '_default_hash_key'
+        hash_key for string key to encode
     categorize : bool, default True
         Whether to first categorize object arrays before hashing. This is more
         efficient when the array contains duplicate values.
