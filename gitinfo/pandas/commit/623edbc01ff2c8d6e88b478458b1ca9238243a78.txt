commit 623edbc01ff2c8d6e88b478458b1ca9238243a78
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Jul 13 11:17:00 2011 -0400

    starting on fast cythonized multi-groupby

diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 93227e9f1..bbb58e813 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -130,6 +130,17 @@ class GroupBy(object):
     def __getitem__(self, key):
         return self.getGroup(self.grouping.indices[key])
 
+def multi_groupby(obj, op, *columns):
+    cur = columns[0]
+    grouped = obj.groupby(cur)
+    if len(columns) == 1:
+        return grouped.aggregate(op)
+    else:
+        result = {}
+        for key, value in grouped:
+            result[key] = multi_groupby(value, op, columns[1:])
+    return result
+
 class SeriesGroupBy(GroupBy):
 
     def aggregate(self, applyfunc):
@@ -277,7 +288,8 @@ class DataFrameGroupBy(GroupBy):
     def __getitem__(self, key):
         if key not in self.obj:
             raise KeyError('column %s not found' % key)
-        return MetaGroupBy(self, key)
+        return DataFrameGroupBy(self.obj, groupings=self.groupings,
+                                column=key)
 
     def aggregate(self, applyfunc):
         """
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 6a2ac77c1..86e893f34 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -1235,14 +1235,14 @@ class LongPanel(Panel, Picklable):
         # Lexsort starts from END
         indexer = np.lexsort((second, first))
 
-        new_major = self.index.major_labels[indexer]
-        new_minor = self.index.minor_labels[indexer]
-        new_values = self.values[indexer]
+        new_major = self.index.major_labels.take(indexer)
+        new_minor = self.index.minor_labels.take(indexer)
+        new_values = self.values.take(indexer)
 
         new_index = LongPanelIndex(self.major_axis, self.minor_axis,
                                    new_major, new_minor)
 
-        new_factors = dict((k, v[indexer])
+        new_factors = dict((k, v.take(indexer))
                            for k, v in self.factors.iteritems())
 
         return LongPanel(new_values, self.items, new_index,
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 02cbde4b7..8c666e3da 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -83,6 +83,94 @@ def groupby_indices(object index, object mapper):
 
     return result
 
+def group_labels(ndarray[object] values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
+        dict ids = {}
+        object val
+        int32_t count = 0
+
+    for i from 0 <= i < n:
+        val = values[i]
+        try:
+            labels[i] = ids[val]
+        except KeyError:
+            ids[val] = count
+            labels[i] = count
+            count += 1
+
+    return labels
+
+ctypedef double_t (* agg_func)(double_t *out, double_t *values,
+                               int32_t *labels, int start, int end)
+
+cdef agg_func get_agg_func(object how):
+    pass
+
+def group_aggregate(ndarray[double_t] values, list label_list,
+                    how='add'):
+    cdef:
+        list sorted_labels
+        ndarray[double_t] result
+        double_t *resbuf
+        double_t *valbuf
+        Py_ssize_t i
+        agg_func func
+
+    values, sorted_labels = _group_reorder(values, label_list)
+    result = np.empty(_result_shape(sorted_labels), dtype=np.float64)
+
+    resbuf = <double_t*> result.data
+    valbuf = <double_t*> values.data
+
+    _aggregate_group(resbuf, valbuf, sorted_labels, 0, len(values),
+                     func)
+
+    return result, sorted_labels
+
+cdef _aggregate_group(double_t *out, double_t *values, list labels,
+                      int start, int end, agg_func func):
+    cdef:
+        ndarray[int32_t] axis0
+        int32_t label_end
+
+    axis0 = sorted_labels[0]
+    label_end = axis0[0]
+    if len(labels) == 1:
+        func(out, values, axis0, start, end)
+    else:
+        # get group counts on axis
+        edges = axis0.searchsorted(np.arange(1, label_end + 1), side='left')
+        start = 0
+        for end in edges:
+            _aggregate_group(resbuf, valbuf, sorted_labels[1:],
+                             start, end, func)
+            start = end
+
+cdef _group_add(double_t *out, double_t *values, int32_t *labels,
+                int start, int end):
+    cdef:
+        int i
+        int32_t lab
+        double_t val
+
+    for i from start <= i < end:
+
+
+def _group_reorder(values, label_list)
+    indexer = np.lexsort(label_list[::-1])
+    sorted_labels = [labels.take(indexer) for labels in label_list]
+    sorted_values = values.take(indexer)
+    return sorted_values, sorted_labels
+
+def _result_shape(label_list):
+    # assumed sorted
+    shape = []
+    for labels in label_list:
+        size.append(1 + labels[-1])
+    return tuple(shape)
+
 def reduce_mean(ndarray[object, ndim=1] indices,
                 ndarray[object, ndim=1] buckets,
                 ndarray[double_t, ndim=1] values,
