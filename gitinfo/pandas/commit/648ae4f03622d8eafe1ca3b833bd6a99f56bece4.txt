commit 648ae4f03622d8eafe1ca3b833bd6a99f56bece4
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Mar 7 18:21:18 2017 -0500

    BLD: consolidate remaining extensions
    
    moves extensions to pandas/_libs, which holds the extension code
    and also the generated builds (as its importable).
    
    pandas/_libs/src is now almost an includes dir, holding low-frequency changing code.
    This consolidates the import process making it more uniform and
    consistent throughout the codebase.
    
    Finally this cleans up the remaining top-level namespace (with some deprecations in place for
    example pandas.lib, pandas.tslib, pandas.json, pandas.parser.
    
    I listed all of the changes in the whatsnew, but I
    don't think worthwhile deprecating anything else.
    
    Author: Jeff Reback <jeff@reback.net>
    
    Closes #15537 from jreback/extensions3 and squashes the following commits:
    
    a6d6cfa [Jeff Reback] BLD: rename / move some extensions

diff --git a/Makefile b/Makefile
index 9a768932b..90dcd16d9 100644
--- a/Makefile
+++ b/Makefile
@@ -1,4 +1,4 @@
-tseries: pandas/lib.pyx pandas/tslib.pyx pandas/hashtable.pyx
+tseries: pandas/_libs/lib.pyx pandas/_libs/tslib.pyx pandas/_libs/hashtable.pyx
 	python setup.py build_ext --inplace
 
 .PHONY : develop build clean clean_pyc tseries doc
diff --git a/asv_bench/benchmarks/binary_ops.py b/asv_bench/benchmarks/binary_ops.py
index 53cb1cf46..72700c3de 100644
--- a/asv_bench/benchmarks/binary_ops.py
+++ b/asv_bench/benchmarks/binary_ops.py
@@ -107,4 +107,4 @@ class TimeseriesTZ(Timeseries):
         self.s = Series(date_range('20010101', periods=self.N, freq='T', tz='US/Eastern'))
         self.ts = self.s[self.halfway]
 
-        self.s2 = Series(date_range('20010101', periods=self.N, freq='s',  tz='US/Eastern'))
\ No newline at end of file
+        self.s2 = Series(date_range('20010101', periods=self.N, freq='s',  tz='US/Eastern'))
diff --git a/asv_bench/benchmarks/pandas_vb_common.py b/asv_bench/benchmarks/pandas_vb_common.py
index 25b0b5dd4..56ccc94c4 100644
--- a/asv_bench/benchmarks/pandas_vb_common.py
+++ b/asv_bench/benchmarks/pandas_vb_common.py
@@ -8,16 +8,22 @@ import pandas.util.testing as tm
 import random
 import numpy as np
 import threading
+from importlib import import_module
+
 try:
     from pandas.compat import range
 except ImportError:
     pass
 
 np.random.seed(1234)
-try:
-    import pandas._tseries as lib
-except:
-    import pandas.lib as lib
+
+# try em until it works!
+for imp in ['pandas_tseries', 'pandas.lib', 'pandas._libs.lib']:
+    try:
+        lib = import_module(imp)
+        break
+    except:
+        pass
 
 try:
     Panel = Panel
diff --git a/asv_bench/benchmarks/panel_methods.py b/asv_bench/benchmarks/panel_methods.py
index ebe278f6e..660930550 100644
--- a/asv_bench/benchmarks/panel_methods.py
+++ b/asv_bench/benchmarks/panel_methods.py
@@ -21,4 +21,4 @@ class PanelMethods(object):
         self.panel.shift(1)
 
     def time_shift_minor(self):
-        self.panel.shift(1, axis='minor')
\ No newline at end of file
+        self.panel.shift(1, axis='minor')
diff --git a/doc/source/whatsnew/v0.20.0.txt b/doc/source/whatsnew/v0.20.0.txt
index ece9ff4a1..8f2033de6 100644
--- a/doc/source/whatsnew/v0.20.0.txt
+++ b/doc/source/whatsnew/v0.20.0.txt
@@ -484,6 +484,35 @@ New Behavior:
    In [11]: index.memory_usage(deep=True)
    Out[11]: 260
 
+.. _whatsnew_0200.api_breaking.extensions:
+
+Extension Modules Moved
+^^^^^^^^^^^^^^^^^^^^^^^
+
+Some formerly public c/c++/cython extension modules have been moved and/or renamed. These are all removed from the public API.
+If indicated, a deprecation warning will be issued if you reference that module. (:issue:`12588`)
+
+.. csv-table::
+    :header: "Previous Location", "New Location", "Deprecated"
+    :widths: 30, 30, 4
+
+    "pandas.lib", "pandas._libs.lib", "X"
+    "pandas.tslib", "pandas._libs.tslib", "X"
+    "pandas._join", "pandas._libs.join", ""
+    "pandas._period", "pandas._libs.period", ""
+    "pandas.msgpack", "pandas.io.msgpack", ""
+    "pandas.index", "pandas._libs.index", ""
+    "pandas.algos", "pandas._libs.algos", ""
+    "pandas.hashtable", "pandas._libs.hashtable", ""
+    "pandas.json", "pandas.io.json.libjson", "X"
+    "pandas.parser", "pandas.io.libparsers", "X"
+    "pandas.io.sas.saslib", "pandas.io.sas.libsas", ""
+    "pandas._testing", "pandas.util.libtesting", ""
+    "pandas._sparse", "pandas.sparse.libsparse", ""
+    "pandas._hash", "pandas.tools.libhash", ""
+    "pandas._window", "pandas.core.libwindow", ""
+
+
 .. _whatsnew_0200.api_breaking.groupby_describe:
 
 Groupby Describe Formatting
diff --git a/pandas/__init__.py b/pandas/__init__.py
index 3bded89e6..5c7c9d44c 100644
--- a/pandas/__init__.py
+++ b/pandas/__init__.py
@@ -23,7 +23,9 @@ del hard_dependencies, dependency, missing_dependencies
 from pandas.compat.numpy import *
 
 try:
-    from pandas import hashtable, tslib, lib
+    from pandas._libs import (hashtable as _hashtable,
+                             lib as _lib,
+                             tslib as _tslib)
 except ImportError as e:  # pragma: no cover
     # hack but overkill to use re
     module = str(e).lstrip('cannot import name ')
@@ -52,11 +54,17 @@ from pandas.tools.tile import cut, qcut
 from pandas.tools.util import to_numeric
 from pandas.core.reshape import melt
 from pandas.util.print_versions import show_versions
-
 from pandas.io.api import *
-
 from pandas.util._tester import test
 
+# extension module deprecations
+from pandas.util.depr_module import _DeprecatedModule
+
+json = _DeprecatedModule(deprmod='pandas.json', deprmodto='pandas.io.json.libjson')
+parser = _DeprecatedModule(deprmod='pandas.parser', deprmodto='pandas.io.libparsers')
+lib = _DeprecatedModule(deprmod='pandas.lib', deprmodto='pandas._libs.lib')
+tslib = _DeprecatedModule(deprmod='pandas.tslib', deprmodto='pandas._libs.tslib')
+
 # use the closest tagged version if possible
 from ._version import get_versions
 v = get_versions()
diff --git a/pandas/_libs/__init__.py b/pandas/_libs/__init__.py
new file mode 100644
index 000000000..ab3832d02
--- /dev/null
+++ b/pandas/_libs/__init__.py
@@ -0,0 +1,8 @@
+# flake8: noqa
+
+from .tslib import iNaT, NaT, Timestamp, Timedelta, OutOfBoundsDatetime
+
+# TODO
+# period is directly dependent on tslib and imports python
+# modules, so exposing Period as an alias is currently not possible
+# from period import Period
diff --git a/pandas/algos.pyx b/pandas/_libs/algos.pyx
similarity index 99%
rename from pandas/algos.pyx
rename to pandas/_libs/algos.pyx
index 32955fd0f..7d3ce3280 100644
--- a/pandas/algos.pyx
+++ b/pandas/_libs/algos.pyx
@@ -37,7 +37,7 @@ float64 = np.dtype(np.float64)
 cdef double NaN = <double> np.NaN
 cdef double nan = NaN
 
-cdef extern from "src/headers/math.h":
+cdef extern from "../src/headers/math.h":
     double sqrt(double x) nogil
     double fabs(double) nogil
 
@@ -46,7 +46,7 @@ from util cimport numeric, get_nat
 
 cimport lib
 from lib cimport is_null_datetimelike
-from pandas import lib
+from pandas._libs import lib
 
 cdef int64_t iNaT = get_nat()
 
diff --git a/pandas/src/algos_common_helper.pxi.in b/pandas/_libs/algos_common_helper.pxi.in
similarity index 99%
rename from pandas/src/algos_common_helper.pxi.in
rename to pandas/_libs/algos_common_helper.pxi.in
index b83dec1d2..336dd77ea 100644
--- a/pandas/src/algos_common_helper.pxi.in
+++ b/pandas/_libs/algos_common_helper.pxi.in
@@ -433,7 +433,7 @@ def arrmap_{{name}}(ndarray[{{c_type}}] index, object func):
 
     cdef ndarray[object] result = np.empty(length, dtype=np.object_)
 
-    from pandas.lib import maybe_convert_objects
+    from pandas._libs.lib import maybe_convert_objects
 
     for i in range(length):
         result[i] = func(index[i])
diff --git a/pandas/src/algos_groupby_helper.pxi.in b/pandas/_libs/algos_groupby_helper.pxi.in
similarity index 100%
rename from pandas/src/algos_groupby_helper.pxi.in
rename to pandas/_libs/algos_groupby_helper.pxi.in
diff --git a/pandas/src/algos_rank_helper.pxi.in b/pandas/_libs/algos_rank_helper.pxi.in
similarity index 100%
rename from pandas/src/algos_rank_helper.pxi.in
rename to pandas/_libs/algos_rank_helper.pxi.in
diff --git a/pandas/src/algos_take_helper.pxi.in b/pandas/_libs/algos_take_helper.pxi.in
similarity index 100%
rename from pandas/src/algos_take_helper.pxi.in
rename to pandas/_libs/algos_take_helper.pxi.in
diff --git a/pandas/hashtable.pxd b/pandas/_libs/hashtable.pxd
similarity index 100%
rename from pandas/hashtable.pxd
rename to pandas/_libs/hashtable.pxd
diff --git a/pandas/hashtable.pyx b/pandas/_libs/hashtable.pyx
similarity index 99%
rename from pandas/hashtable.pyx
rename to pandas/_libs/hashtable.pyx
index 276b06790..eee287b2c 100644
--- a/pandas/hashtable.pyx
+++ b/pandas/_libs/hashtable.pyx
@@ -22,7 +22,7 @@ cdef extern from "numpy/npy_math.h":
 cimport cython
 cimport numpy as cnp
 
-from pandas.lib import checknull
+from pandas._libs.lib import checknull
 
 cnp.import_array()
 cnp.import_ufunc()
diff --git a/pandas/src/hashtable_class_helper.pxi.in b/pandas/_libs/hashtable_class_helper.pxi.in
similarity index 100%
rename from pandas/src/hashtable_class_helper.pxi.in
rename to pandas/_libs/hashtable_class_helper.pxi.in
diff --git a/pandas/src/hashtable_func_helper.pxi.in b/pandas/_libs/hashtable_func_helper.pxi.in
similarity index 100%
rename from pandas/src/hashtable_func_helper.pxi.in
rename to pandas/_libs/hashtable_func_helper.pxi.in
diff --git a/pandas/index.pyx b/pandas/_libs/index.pyx
similarity index 99%
rename from pandas/index.pyx
rename to pandas/_libs/index.pyx
index 37fe7d90b..c7a537acf 100644
--- a/pandas/index.pyx
+++ b/pandas/_libs/index.pyx
@@ -17,8 +17,8 @@ import numpy as np
 
 cimport tslib
 from hashtable cimport *
-from pandas import algos, tslib, hashtable as _hash
-from pandas.tslib import Timestamp, Timedelta
+from pandas._libs import tslib, algos, hashtable as _hash
+from pandas._libs.tslib import Timestamp, Timedelta
 
 from datetime cimport (get_datetime64_value, _pydatetime_to_dts,
                        pandas_datetimestruct)
diff --git a/pandas/src/index_class_helper.pxi.in b/pandas/_libs/index_class_helper.pxi.in
similarity index 100%
rename from pandas/src/index_class_helper.pxi.in
rename to pandas/_libs/index_class_helper.pxi.in
diff --git a/pandas/src/join.pyx b/pandas/_libs/join.pyx
similarity index 98%
rename from pandas/src/join.pyx
rename to pandas/_libs/join.pyx
index 65c790beb..385a9762e 100644
--- a/pandas/src/join.pyx
+++ b/pandas/_libs/join.pyx
@@ -32,10 +32,10 @@ float64 = np.dtype(np.float64)
 cdef double NaN = <double> np.NaN
 cdef double nan = NaN
 
-from pandas.algos import groupsort_indexer, ensure_platform_int
+from pandas._libs.algos import groupsort_indexer, ensure_platform_int
 from pandas.core.algorithms import take_nd
 
-include "joins_func_helper.pxi"
+include "join_func_helper.pxi"
 
 
 def inner_join(ndarray[int64_t] left, ndarray[int64_t] right,
diff --git a/pandas/src/joins_func_helper.pxi.in b/pandas/_libs/join_func_helper.pxi.in
similarity index 100%
rename from pandas/src/joins_func_helper.pxi.in
rename to pandas/_libs/join_func_helper.pxi.in
diff --git a/pandas/src/join_helper.pxi.in b/pandas/_libs/join_helper.pxi.in
similarity index 100%
rename from pandas/src/join_helper.pxi.in
rename to pandas/_libs/join_helper.pxi.in
diff --git a/pandas/lib.pxd b/pandas/_libs/lib.pxd
similarity index 100%
rename from pandas/lib.pxd
rename to pandas/_libs/lib.pxd
diff --git a/pandas/lib.pyx b/pandas/_libs/lib.pyx
similarity index 100%
rename from pandas/lib.pyx
rename to pandas/_libs/lib.pyx
diff --git a/pandas/src/period.pyx b/pandas/_libs/period.pyx
similarity index 98%
rename from pandas/src/period.pyx
rename to pandas/_libs/period.pyx
index 2d92b9f19..f30035910 100644
--- a/pandas/src/period.pyx
+++ b/pandas/_libs/period.pyx
@@ -16,19 +16,15 @@ cdef extern from "datetime_helper.h":
 from libc.stdlib cimport free
 
 from pandas import compat
-
-from pandas.tseries import offsets
-from pandas.tseries.tools import parse_time_string
+from pandas.compat import PY2
 
 cimport cython
 from datetime cimport *
-cimport util
-cimport lib
+cimport util, lib
 from lib cimport is_null_datetimelike, is_period
-import lib
-from pandas import tslib
-from tslib import Timedelta, Timestamp, iNaT, NaT
-from tslib import have_pytz, _get_utcoffset
+from pandas._libs import tslib, lib
+from pandas._libs.tslib import (Timedelta, Timestamp, iNaT,
+                                NaT, have_pytz, _get_utcoffset)
 from tslib cimport (
     maybe_get_tz,
     _is_utc,
@@ -37,12 +33,10 @@ from tslib cimport (
     _nat_scalar_rules,
 )
 
+from pandas.tseries import offsets
+from pandas.tseries.tools import parse_time_string
 from pandas.tseries import frequencies
 
-from sys import version_info
-
-cdef bint PY2 = version_info[0] == 2
-
 cdef int64_t NPY_NAT = util.get_nat()
 
 cdef int RESO_US = frequencies.RESO_US
@@ -474,7 +468,7 @@ def extract_ordinals(ndarray[object] values, freq):
         p = values[i]
 
         if is_null_datetimelike(p):
-            ordinals[i] = tslib.iNaT
+            ordinals[i] = iNaT
         else:
             try:
                 ordinals[i] = p.ordinal
@@ -485,9 +479,9 @@ def extract_ordinals(ndarray[object] values, freq):
 
             except AttributeError:
                 p = Period(p, freq=freq)
-                if p is tslib.NaT:
+                if p is NaT:
                     # input may contain NaT-like string
-                    ordinals[i] = tslib.iNaT
+                    ordinals[i] = iNaT
                 else:
                     ordinals[i] = p.ordinal
 
@@ -716,8 +710,8 @@ cdef class _Period(object):
         """
         Fast creation from an ordinal and freq that are already validated!
         """
-        if ordinal == tslib.iNaT:
-            return tslib.NaT
+        if ordinal == iNaT:
+            return NaT
         else:
             self = _Period.__new__(cls)
             self.ordinal = ordinal
@@ -730,7 +724,7 @@ cdef class _Period(object):
                 msg = _DIFFERENT_FREQ.format(self.freqstr, other.freqstr)
                 raise IncompatibleFrequency(msg)
             return PyObject_RichCompareBool(self.ordinal, other.ordinal, op)
-        elif other is tslib.NaT:
+        elif other is NaT:
             return _nat_scalar_rules[op]
         # index/series like
         elif hasattr(other, '_typ'):
@@ -776,8 +770,8 @@ cdef class _Period(object):
                                   offsets.Tick, offsets.DateOffset,
                                   Timedelta)):
                 return self._add_delta(other)
-            elif other is tslib.NaT:
-                return tslib.NaT
+            elif other is NaT:
+                return NaT
             elif lib.is_integer(other):
                 ordinal = self.ordinal + other * self.freq.n
                 return Period(ordinal=ordinal, freq=self.freq)
@@ -808,8 +802,8 @@ cdef class _Period(object):
             else:  # pragma: no cover
                 return NotImplemented
         elif isinstance(other, Period):
-            if self is tslib.NaT:
-                return tslib.NaT
+            if self is NaT:
+                return NaT
             return NotImplemented
         else:
             return NotImplemented
@@ -1164,7 +1158,7 @@ class Period(_Period):
             if (year is None and month is None and
                         quarter is None and day is None and
                         hour is None and minute is None and second is None):
-                ordinal = tslib.iNaT
+                ordinal = iNaT
             else:
                 if freq is None:
                     raise ValueError("If value is None, freq cannot be None")
@@ -1190,7 +1184,7 @@ class Period(_Period):
                 ordinal = converted.ordinal
 
         elif is_null_datetimelike(value) or value in tslib._nat_strings:
-            ordinal = tslib.iNaT
+            ordinal = iNaT
 
         elif isinstance(value, compat.string_types) or lib.is_integer(value):
             if lib.is_integer(value):
diff --git a/pandas/src/reshape.pyx b/pandas/_libs/reshape.pyx
similarity index 100%
rename from pandas/src/reshape.pyx
rename to pandas/_libs/reshape.pyx
diff --git a/pandas/src/reshape_helper.pxi.in b/pandas/_libs/reshape_helper.pxi.in
similarity index 100%
rename from pandas/src/reshape_helper.pxi.in
rename to pandas/_libs/reshape_helper.pxi.in
diff --git a/pandas/src/datetime.pxd b/pandas/_libs/src/datetime.pxd
similarity index 100%
rename from pandas/src/datetime.pxd
rename to pandas/_libs/src/datetime.pxd
diff --git a/pandas/src/datetime/np_datetime.c b/pandas/_libs/src/datetime/np_datetime.c
similarity index 100%
rename from pandas/src/datetime/np_datetime.c
rename to pandas/_libs/src/datetime/np_datetime.c
diff --git a/pandas/src/datetime/np_datetime.h b/pandas/_libs/src/datetime/np_datetime.h
similarity index 100%
rename from pandas/src/datetime/np_datetime.h
rename to pandas/_libs/src/datetime/np_datetime.h
diff --git a/pandas/src/datetime/np_datetime_strings.c b/pandas/_libs/src/datetime/np_datetime_strings.c
similarity index 100%
rename from pandas/src/datetime/np_datetime_strings.c
rename to pandas/_libs/src/datetime/np_datetime_strings.c
diff --git a/pandas/src/datetime/np_datetime_strings.h b/pandas/_libs/src/datetime/np_datetime_strings.h
similarity index 100%
rename from pandas/src/datetime/np_datetime_strings.h
rename to pandas/_libs/src/datetime/np_datetime_strings.h
diff --git a/pandas/src/datetime_helper.h b/pandas/_libs/src/datetime_helper.h
similarity index 100%
rename from pandas/src/datetime_helper.h
rename to pandas/_libs/src/datetime_helper.h
diff --git a/pandas/src/headers/math.h b/pandas/_libs/src/headers/math.h
similarity index 100%
rename from pandas/src/headers/math.h
rename to pandas/_libs/src/headers/math.h
diff --git a/pandas/src/headers/ms_inttypes.h b/pandas/_libs/src/headers/ms_inttypes.h
similarity index 100%
rename from pandas/src/headers/ms_inttypes.h
rename to pandas/_libs/src/headers/ms_inttypes.h
diff --git a/pandas/src/headers/ms_stdint.h b/pandas/_libs/src/headers/ms_stdint.h
similarity index 100%
rename from pandas/src/headers/ms_stdint.h
rename to pandas/_libs/src/headers/ms_stdint.h
diff --git a/pandas/src/headers/portable.h b/pandas/_libs/src/headers/portable.h
similarity index 100%
rename from pandas/src/headers/portable.h
rename to pandas/_libs/src/headers/portable.h
diff --git a/pandas/src/headers/stdint.h b/pandas/_libs/src/headers/stdint.h
similarity index 100%
rename from pandas/src/headers/stdint.h
rename to pandas/_libs/src/headers/stdint.h
diff --git a/pandas/src/helper.h b/pandas/_libs/src/helper.h
similarity index 100%
rename from pandas/src/helper.h
rename to pandas/_libs/src/helper.h
diff --git a/pandas/src/inference.pyx b/pandas/_libs/src/inference.pyx
similarity index 100%
rename from pandas/src/inference.pyx
rename to pandas/_libs/src/inference.pyx
diff --git a/pandas/src/khash.pxd b/pandas/_libs/src/khash.pxd
similarity index 100%
rename from pandas/src/khash.pxd
rename to pandas/_libs/src/khash.pxd
diff --git a/pandas/src/klib/khash.h b/pandas/_libs/src/klib/khash.h
similarity index 100%
rename from pandas/src/klib/khash.h
rename to pandas/_libs/src/klib/khash.h
diff --git a/pandas/src/klib/khash_python.h b/pandas/_libs/src/klib/khash_python.h
similarity index 100%
rename from pandas/src/klib/khash_python.h
rename to pandas/_libs/src/klib/khash_python.h
diff --git a/pandas/src/klib/ktypes.h b/pandas/_libs/src/klib/ktypes.h
similarity index 100%
rename from pandas/src/klib/ktypes.h
rename to pandas/_libs/src/klib/ktypes.h
diff --git a/pandas/src/klib/kvec.h b/pandas/_libs/src/klib/kvec.h
similarity index 100%
rename from pandas/src/klib/kvec.h
rename to pandas/_libs/src/klib/kvec.h
diff --git a/pandas/src/msgpack/pack.h b/pandas/_libs/src/msgpack/pack.h
similarity index 100%
rename from pandas/src/msgpack/pack.h
rename to pandas/_libs/src/msgpack/pack.h
diff --git a/pandas/src/msgpack/pack_template.h b/pandas/_libs/src/msgpack/pack_template.h
similarity index 100%
rename from pandas/src/msgpack/pack_template.h
rename to pandas/_libs/src/msgpack/pack_template.h
diff --git a/pandas/src/msgpack/sysdep.h b/pandas/_libs/src/msgpack/sysdep.h
similarity index 100%
rename from pandas/src/msgpack/sysdep.h
rename to pandas/_libs/src/msgpack/sysdep.h
diff --git a/pandas/src/msgpack/unpack.h b/pandas/_libs/src/msgpack/unpack.h
similarity index 100%
rename from pandas/src/msgpack/unpack.h
rename to pandas/_libs/src/msgpack/unpack.h
diff --git a/pandas/src/msgpack/unpack_define.h b/pandas/_libs/src/msgpack/unpack_define.h
similarity index 100%
rename from pandas/src/msgpack/unpack_define.h
rename to pandas/_libs/src/msgpack/unpack_define.h
diff --git a/pandas/src/msgpack/unpack_template.h b/pandas/_libs/src/msgpack/unpack_template.h
similarity index 100%
rename from pandas/src/msgpack/unpack_template.h
rename to pandas/_libs/src/msgpack/unpack_template.h
diff --git a/pandas/src/numpy.pxd b/pandas/_libs/src/numpy.pxd
similarity index 100%
rename from pandas/src/numpy.pxd
rename to pandas/_libs/src/numpy.pxd
diff --git a/pandas/src/numpy_helper.h b/pandas/_libs/src/numpy_helper.h
similarity index 100%
rename from pandas/src/numpy_helper.h
rename to pandas/_libs/src/numpy_helper.h
diff --git a/pandas/src/offsets.pyx b/pandas/_libs/src/offsets.pyx
similarity index 100%
rename from pandas/src/offsets.pyx
rename to pandas/_libs/src/offsets.pyx
diff --git a/pandas/src/parse_helper.h b/pandas/_libs/src/parse_helper.h
similarity index 100%
rename from pandas/src/parse_helper.h
rename to pandas/_libs/src/parse_helper.h
diff --git a/pandas/src/parser/.gitignore b/pandas/_libs/src/parser/.gitignore
similarity index 100%
rename from pandas/src/parser/.gitignore
rename to pandas/_libs/src/parser/.gitignore
diff --git a/pandas/src/parser/Makefile b/pandas/_libs/src/parser/Makefile
similarity index 100%
rename from pandas/src/parser/Makefile
rename to pandas/_libs/src/parser/Makefile
diff --git a/pandas/src/parser/io.c b/pandas/_libs/src/parser/io.c
similarity index 100%
rename from pandas/src/parser/io.c
rename to pandas/_libs/src/parser/io.c
diff --git a/pandas/src/parser/io.h b/pandas/_libs/src/parser/io.h
similarity index 100%
rename from pandas/src/parser/io.h
rename to pandas/_libs/src/parser/io.h
diff --git a/pandas/src/parser/tokenizer.c b/pandas/_libs/src/parser/tokenizer.c
similarity index 100%
rename from pandas/src/parser/tokenizer.c
rename to pandas/_libs/src/parser/tokenizer.c
diff --git a/pandas/src/parser/tokenizer.h b/pandas/_libs/src/parser/tokenizer.h
similarity index 100%
rename from pandas/src/parser/tokenizer.h
rename to pandas/_libs/src/parser/tokenizer.h
diff --git a/pandas/src/period_helper.c b/pandas/_libs/src/period_helper.c
similarity index 100%
rename from pandas/src/period_helper.c
rename to pandas/_libs/src/period_helper.c
diff --git a/pandas/src/period_helper.h b/pandas/_libs/src/period_helper.h
similarity index 100%
rename from pandas/src/period_helper.h
rename to pandas/_libs/src/period_helper.h
diff --git a/pandas/src/properties.pyx b/pandas/_libs/src/properties.pyx
similarity index 100%
rename from pandas/src/properties.pyx
rename to pandas/_libs/src/properties.pyx
diff --git a/pandas/src/reduce.pyx b/pandas/_libs/src/reduce.pyx
similarity index 100%
rename from pandas/src/reduce.pyx
rename to pandas/_libs/src/reduce.pyx
diff --git a/pandas/src/skiplist.h b/pandas/_libs/src/skiplist.h
similarity index 100%
rename from pandas/src/skiplist.h
rename to pandas/_libs/src/skiplist.h
diff --git a/pandas/src/skiplist.pxd b/pandas/_libs/src/skiplist.pxd
similarity index 100%
rename from pandas/src/skiplist.pxd
rename to pandas/_libs/src/skiplist.pxd
diff --git a/pandas/src/skiplist.pyx b/pandas/_libs/src/skiplist.pyx
similarity index 100%
rename from pandas/src/skiplist.pyx
rename to pandas/_libs/src/skiplist.pyx
diff --git a/pandas/src/ujson/lib/ultrajson.h b/pandas/_libs/src/ujson/lib/ultrajson.h
similarity index 100%
rename from pandas/src/ujson/lib/ultrajson.h
rename to pandas/_libs/src/ujson/lib/ultrajson.h
diff --git a/pandas/src/ujson/lib/ultrajsondec.c b/pandas/_libs/src/ujson/lib/ultrajsondec.c
similarity index 100%
rename from pandas/src/ujson/lib/ultrajsondec.c
rename to pandas/_libs/src/ujson/lib/ultrajsondec.c
diff --git a/pandas/src/ujson/lib/ultrajsonenc.c b/pandas/_libs/src/ujson/lib/ultrajsonenc.c
similarity index 100%
rename from pandas/src/ujson/lib/ultrajsonenc.c
rename to pandas/_libs/src/ujson/lib/ultrajsonenc.c
diff --git a/pandas/src/ujson/python/JSONtoObj.c b/pandas/_libs/src/ujson/python/JSONtoObj.c
similarity index 100%
rename from pandas/src/ujson/python/JSONtoObj.c
rename to pandas/_libs/src/ujson/python/JSONtoObj.c
diff --git a/pandas/src/ujson/python/objToJSON.c b/pandas/_libs/src/ujson/python/objToJSON.c
similarity index 99%
rename from pandas/src/ujson/python/objToJSON.c
rename to pandas/_libs/src/ujson/python/objToJSON.c
index e3c75d3b6..26a68b8a9 100644
--- a/pandas/src/ujson/python/objToJSON.c
+++ b/pandas/_libs/src/ujson/python/objToJSON.c
@@ -180,7 +180,7 @@ void initObjToJSON(void)
         Py_DECREF(mod_pandas);
     }
 
-    mod_tslib = PyImport_ImportModule("pandas.tslib");
+    mod_tslib = PyImport_ImportModule("pandas._libs.tslib");
     if (mod_tslib) {
         cls_nat = (PyTypeObject *)PyObject_GetAttrString(mod_tslib, "NaTType");
         Py_DECREF(mod_tslib);
diff --git a/pandas/src/ujson/python/py_defines.h b/pandas/_libs/src/ujson/python/py_defines.h
similarity index 100%
rename from pandas/src/ujson/python/py_defines.h
rename to pandas/_libs/src/ujson/python/py_defines.h
diff --git a/pandas/src/ujson/python/ujson.c b/pandas/_libs/src/ujson/python/ujson.c
similarity index 95%
rename from pandas/src/ujson/python/ujson.c
rename to pandas/_libs/src/ujson/python/ujson.c
index 8c25975f1..ec6720f16 100644
--- a/pandas/src/ujson/python/ujson.c
+++ b/pandas/_libs/src/ujson/python/ujson.c
@@ -80,7 +80,7 @@ static PyMethodDef ujsonMethods[] = {
 
 static struct PyModuleDef moduledef = {
     PyModuleDef_HEAD_INIT,
-    "_pandasujson",
+    "_libjson",
     0,            /* m_doc */
     -1,           /* m_size */
     ujsonMethods, /* m_methods */
@@ -90,14 +90,14 @@ static struct PyModuleDef moduledef = {
     NULL          /* m_free */
 };
 
-#define PYMODINITFUNC PyMODINIT_FUNC PyInit_json(void)
+#define PYMODINITFUNC PyMODINIT_FUNC PyInit_libjson(void)
 #define PYMODULE_CREATE() PyModule_Create(&moduledef)
 #define MODINITERROR return NULL
 
 #else
 
-#define PYMODINITFUNC PyMODINIT_FUNC initjson(void)
-#define PYMODULE_CREATE() Py_InitModule("json", ujsonMethods)
+#define PYMODINITFUNC PyMODINIT_FUNC initlibjson(void)
+#define PYMODULE_CREATE() Py_InitModule("libjson", ujsonMethods)
 #define MODINITERROR return
 
 #endif
diff --git a/pandas/src/ujson/python/version.h b/pandas/_libs/src/ujson/python/version.h
similarity index 100%
rename from pandas/src/ujson/python/version.h
rename to pandas/_libs/src/ujson/python/version.h
diff --git a/pandas/src/util.pxd b/pandas/_libs/src/util.pxd
similarity index 100%
rename from pandas/src/util.pxd
rename to pandas/_libs/src/util.pxd
diff --git a/pandas/tslib.pxd b/pandas/_libs/tslib.pxd
similarity index 100%
rename from pandas/tslib.pxd
rename to pandas/_libs/tslib.pxd
diff --git a/pandas/tslib.pyx b/pandas/_libs/tslib.pyx
similarity index 100%
rename from pandas/tslib.pyx
rename to pandas/_libs/tslib.pyx
diff --git a/pandas/compat/pickle_compat.py b/pandas/compat/pickle_compat.py
index 25a170c3e..279a82fea 100644
--- a/pandas/compat/pickle_compat.py
+++ b/pandas/compat/pickle_compat.py
@@ -62,7 +62,13 @@ _class_locations_map = {
 
     # 10890
     ('pandas.core.series', 'TimeSeries'): ('pandas.core.series', 'Series'),
-    ('pandas.sparse.series', 'SparseTimeSeries'): ('pandas.sparse.series', 'SparseSeries')
+    ('pandas.sparse.series', 'SparseTimeSeries'): ('pandas.sparse.series', 'SparseSeries'),
+
+    # 12588, extensions moving
+    ('pandas._sparse', 'BlockIndex'): ('pandas.sparse.libsparse', 'BlockIndex'),
+    ('pandas.tslib', 'Timestamp'): ('pandas._libs.tslib', 'Timestamp'),
+    ('pandas.tslib', '__nat_unpickle'): ('pandas._libs.tslib', '__nat_unpickle'),
+    ('pandas._period', 'Period'): ('pandas._libs.period', 'Period')
     }
 
 
diff --git a/pandas/computation/scope.py b/pandas/computation/scope.py
index 875aaa959..9ade755e0 100644
--- a/pandas/computation/scope.py
+++ b/pandas/computation/scope.py
@@ -1,4 +1,5 @@
-"""Module for scope operations
+"""
+Module for scope operations
 """
 
 import sys
@@ -10,7 +11,8 @@ import pprint
 
 import numpy as np
 
-import pandas as pd
+import pandas
+import pandas as pd  # noqa
 from pandas.compat import DeepChainMap, map, StringIO
 from pandas.core.base import StringMixin
 import pandas.computation as compu
@@ -46,7 +48,7 @@ def _raw_hex_id(obj):
 
 
 _DEFAULT_GLOBALS = {
-    'Timestamp': pd.lib.Timestamp,
+    'Timestamp': pandas._libs.lib.Timestamp,
     'datetime': datetime.datetime,
     'True': True,
     'False': False,
diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index d37c98c9b..693767560 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -6,7 +6,7 @@ from __future__ import division
 from warnings import warn
 import numpy as np
 
-from pandas import compat, lib, tslib, _np_version_under1p8
+from pandas import compat, _np_version_under1p8
 from pandas.types.cast import _maybe_promote
 from pandas.types.generic import ABCSeries, ABCIndex
 from pandas.types.common import (is_unsigned_integer_dtype,
@@ -34,10 +34,9 @@ from pandas.compat.numpy import _np_version_under1p10
 from pandas.types.missing import isnull
 
 import pandas.core.common as com
-import pandas.algos as algos
-import pandas.hashtable as htable
 from pandas.compat import string_types
-from pandas.tslib import iNaT
+from pandas._libs import algos, lib, hashtable as htable
+from pandas._libs.tslib import iNaT
 
 
 # --------------- #
@@ -1412,7 +1411,7 @@ def diff(arr, n, axis=0):
     if needs_i8_conversion(arr):
         dtype = np.float64
         arr = arr.view('i8')
-        na = tslib.iNaT
+        na = iNaT
         is_timedelta = True
     elif issubclass(dtype.type, np.integer):
         dtype = np.float64
diff --git a/pandas/core/base.py b/pandas/core/base.py
index 55149198b..d7c9e35ab 100644
--- a/pandas/core/base.py
+++ b/pandas/core/base.py
@@ -12,7 +12,7 @@ from pandas.util.validators import validate_bool_kwarg
 
 from pandas.core import common as com
 import pandas.core.nanops as nanops
-import pandas.lib as lib
+import pandas._libs.lib as lib
 from pandas.compat.numpy import function as nv
 from pandas.util.decorators import (Appender, cache_readonly,
                                     deprecate_kwarg, Substitution)
diff --git a/pandas/core/categorical.py b/pandas/core/categorical.py
index d5dce2502..47db86ce1 100644
--- a/pandas/core/categorical.py
+++ b/pandas/core/categorical.py
@@ -4,9 +4,9 @@ import numpy as np
 from warnings import warn
 import types
 
-from pandas import compat, lib
+from pandas import compat
 from pandas.compat import u, lzip
-import pandas.algos as _algos
+from pandas._libs import lib, algos as libalgos
 
 from pandas.types.generic import ABCSeries, ABCIndexClass, ABCCategoricalIndex
 from pandas.types.missing import isnull, notnull
@@ -1817,8 +1817,8 @@ class Categorical(PandasObject):
 
         """
         categories = self.categories
-        r, counts = _algos.groupsort_indexer(self.codes.astype('int64'),
-                                             categories.size)
+        r, counts = libalgos.groupsort_indexer(self.codes.astype('int64'),
+                                               categories.size)
         counts = counts.cumsum()
         result = [r[counts[indexer]:counts[indexer + 1]]
                   for indexer in range(len(counts) - 1)]
@@ -1897,7 +1897,7 @@ class Categorical(PandasObject):
         modes : `Categorical` (sorted)
         """
 
-        import pandas.hashtable as htable
+        import pandas._libs.hashtable as htable
         good = self._codes != -1
         values = sorted(htable.mode_int64(_ensure_int64(self._codes[good])))
         result = self._constructor(values=values, categories=self.categories,
diff --git a/pandas/core/common.py b/pandas/core/common.py
index fddac1f29..93e24dce8 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -8,8 +8,8 @@ from datetime import datetime, timedelta
 from functools import partial
 
 import numpy as np
-import pandas.lib as lib
-import pandas.tslib as tslib
+from pandas._libs import lib, tslib
+
 from pandas import compat
 from pandas.compat import long, zip, iteritems
 from pandas.core.config import get_option
@@ -476,7 +476,6 @@ def _where_compat(mask, arr1, arr2):
         new_vals = np.where(mask, arr1.view('i8'), arr2.view('i8'))
         return new_vals.view(_NS_DTYPE)
 
-    import pandas.tslib as tslib
     if arr1.dtype == _NS_DTYPE:
         arr1 = tslib.ints_to_pydatetime(arr1.view('i8'))
     if arr2.dtype == _NS_DTYPE:
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 15179ac32..4e7a5ebdf 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -71,7 +71,7 @@ from pandas.core.internals import (BlockManager,
 from pandas.core.series import Series
 from pandas.core.categorical import Categorical
 import pandas.computation.expressions as expressions
-import pandas.core.algorithms as algos
+import pandas.core.algorithms as algorithms
 from pandas.computation.eval import eval as _eval
 from pandas.compat import (range, map, zip, lrange, lmap, lzip, StringIO, u,
                            OrderedDict, raise_with_traceback)
@@ -93,8 +93,7 @@ import pandas.formats.format as fmt
 from pandas.formats.printing import pprint_thing
 import pandas.tools.plotting as gfx
 
-import pandas.lib as lib
-import pandas.algos as _algos
+from pandas._libs import lib, algos as libalgos
 
 from pandas.core.config import get_option
 
@@ -2794,8 +2793,8 @@ class DataFrame(NDFrame):
 
         if row_indexer is not None and col_indexer is not None:
             indexer = row_indexer, col_indexer
-            new_values = algos.take_2d_multi(self.values, indexer,
-                                             fill_value=fill_value)
+            new_values = algorithms.take_2d_multi(self.values, indexer,
+                                                  fill_value=fill_value)
             return self._constructor(new_values, index=new_index,
                                      columns=new_columns)
         else:
@@ -3180,12 +3179,11 @@ class DataFrame(NDFrame):
         duplicated : Series
         """
         from pandas.core.sorting import get_group_index
-        from pandas.hashtable import duplicated_int64, _SIZE_HINT_LIMIT
+        from pandas._libs.hashtable import duplicated_int64, _SIZE_HINT_LIMIT
 
         def f(vals):
-            labels, shape = algos.factorize(vals,
-                                            size_hint=min(len(self),
-                                                          _SIZE_HINT_LIMIT))
+            labels, shape = algorithms.factorize(
+                vals, size_hint=min(len(self), _SIZE_HINT_LIMIT))
             return labels.astype('i8', copy=False), len(shape)
 
         if subset is None:
@@ -3437,7 +3435,7 @@ class DataFrame(NDFrame):
         1  10  b   2
         2   8  d NaN
         """
-        return algos.select_n_frame(self, columns, n, 'nlargest', keep)
+        return algorithms.select_n_frame(self, columns, n, 'nlargest', keep)
 
     def nsmallest(self, n, columns, keep='first'):
         """Get the rows of a DataFrame sorted by the `n` smallest
@@ -3471,7 +3469,7 @@ class DataFrame(NDFrame):
         0  1  a   1
         2  8  d NaN
         """
-        return algos.select_n_frame(self, columns, n, 'nsmallest', keep)
+        return algorithms.select_n_frame(self, columns, n, 'nsmallest', keep)
 
     def swaplevel(self, i=-2, j=-1, axis=0):
         """
@@ -4739,10 +4737,10 @@ class DataFrame(NDFrame):
         mat = numeric_df.values
 
         if method == 'pearson':
-            correl = _algos.nancorr(_ensure_float64(mat), minp=min_periods)
+            correl = libalgos.nancorr(_ensure_float64(mat), minp=min_periods)
         elif method == 'spearman':
-            correl = _algos.nancorr_spearman(_ensure_float64(mat),
-                                             minp=min_periods)
+            correl = libalgos.nancorr_spearman(_ensure_float64(mat),
+                                               minp=min_periods)
         else:
             if min_periods is None:
                 min_periods = 1
@@ -4802,8 +4800,8 @@ class DataFrame(NDFrame):
                 baseCov = np.cov(mat.T)
             baseCov = baseCov.reshape((len(cols), len(cols)))
         else:
-            baseCov = _algos.nancorr(_ensure_float64(mat), cov=True,
-                                     minp=min_periods)
+            baseCov = libalgos.nancorr(_ensure_float64(mat), cov=True,
+                                       minp=min_periods)
 
         return self._constructor(baseCov, index=idx, columns=cols)
 
@@ -5669,7 +5667,7 @@ def _list_of_series_to_arrays(data, columns, coerce_float=False, dtype=None):
             indexer = indexer_cache[id(index)] = index.get_indexer(columns)
 
         values = _values_from_object(s)
-        aligned_values.append(algos.take_1d(values, indexer))
+        aligned_values.append(algorithms.take_1d(values, indexer))
 
     values = np.vstack(aligned_values)
 
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 298fa7577..ff58a2aa7 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -7,11 +7,9 @@ import gc
 import json
 
 import numpy as np
-import pandas.lib as lib
-
 import pandas as pd
 
-
+from pandas._libs import tslib, lib
 from pandas.types.common import (_coerce_to_dtype,
                                  _ensure_int64,
                                  needs_i8_conversion,
@@ -6115,7 +6113,7 @@ def _make_cum_function(cls, name, name1, name2, axis_descr, desc,
                 issubclass(y.dtype.type, (np.datetime64, np.timedelta64))):
             result = accum_func(y, axis)
             mask = isnull(self)
-            np.putmask(result, mask, pd.tslib.iNaT)
+            np.putmask(result, mask, tslib.iNaT)
         elif skipna and not issubclass(y.dtype.type, (np.integer, np.bool_)):
             mask = isnull(self)
             np.putmask(y, mask, mask_a)
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 43c57a88b..a10be078a 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -55,13 +55,12 @@ from pandas.util.decorators import (cache_readonly, Substitution, Appender,
 from pandas.formats.printing import pprint_thing
 from pandas.util.validators import validate_kwargs
 
-import pandas.core.algorithms as algos
+import pandas.core.algorithms as algorithms
 import pandas.core.common as com
 from pandas.core.config import option_context
-import pandas.lib as lib
-from pandas.lib import Timestamp
-import pandas.tslib as tslib
-import pandas.algos as _algos
+
+from pandas._libs import lib, algos as libalgos, Timestamp, NaT, iNaT
+from pandas._libs.lib import count_level_2d
 
 _doc_template = """
 
@@ -1474,11 +1473,11 @@ class GroupBy(_GroupBy):
 
         # filled in by Cython
         indexer = np.zeros_like(labels)
-        _algos.group_shift_indexer(indexer, labels, ngroups, periods)
+        libalgos.group_shift_indexer(indexer, labels, ngroups, periods)
 
         output = {}
         for name, obj in self._iterate_slices():
-            output[name] = algos.take_nd(obj.values, indexer)
+            output[name] = algorithms.take_nd(obj.values, indexer)
 
         return self._wrap_transformed_output(output)
 
@@ -1815,13 +1814,13 @@ class BaseGrouper(object):
         def get_func(fname):
             # see if there is a fused-type version of function
             # only valid for numeric
-            f = getattr(_algos, fname, None)
+            f = getattr(libalgos, fname, None)
             if f is not None and is_numeric:
                 return f
 
             # otherwise find dtype-specific version, falling back to object
             for dt in [dtype_str, 'object']:
-                f = getattr(_algos, "%s_%s" % (fname, dtype_str), None)
+                f = getattr(libalgos, "%s_%s" % (fname, dtype_str), None)
                 if f is not None:
                     return f
 
@@ -1901,7 +1900,7 @@ class BaseGrouper(object):
         elif is_integer_dtype(values):
             # we use iNaT for the missing value on ints
             # so pre-convert to guard this condition
-            if (values == tslib.iNaT).any():
+            if (values == iNaT).any():
                 values = _ensure_float64(values)
             else:
                 values = values.astype('int64', copy=False)
@@ -1943,7 +1942,7 @@ class BaseGrouper(object):
                 result, values, labels, func, is_numeric, is_datetimelike)
 
         if is_integer_dtype(result):
-            mask = result == tslib.iNaT
+            mask = result == iNaT
             if mask.any():
                 result = result.astype('float64')
                 result[mask] = np.nan
@@ -2034,7 +2033,8 @@ class BaseGrouper(object):
         dummy = obj._get_values(slice(None, 0)).to_dense()
         indexer = get_group_index_sorter(group_index, ngroups)
         obj = obj.take(indexer, convert=False)
-        group_index = algos.take_nd(group_index, indexer, allow_fill=False)
+        group_index = algorithms.take_nd(
+            group_index, indexer, allow_fill=False)
         grouper = lib.SeriesGrouper(obj, func, group_index, ngroups,
                                     dummy)
         result, counts = grouper.get_result()
@@ -2132,7 +2132,7 @@ class BinGrouper(BaseGrouper):
         # GH 3881
         result = {}
         for key, value in zip(self.binlabels, self.bins):
-            if key is not tslib.NaT:
+            if key is not NaT:
                 result[key] = value
         return result
 
@@ -2159,7 +2159,7 @@ class BinGrouper(BaseGrouper):
 
         start = 0
         for edge, label in zip(self.bins, self.binlabels):
-            if label is not tslib.NaT:
+            if label is not NaT:
                 yield label, slicer(start, edge)
             start = edge
 
@@ -2173,7 +2173,7 @@ class BinGrouper(BaseGrouper):
         i = 0
         for label, bin in zip(self.binlabels, self.bins):
             if i < bin:
-                if label is not tslib.NaT:
+                if label is not NaT:
                     indices[label] = list(range(i, bin))
                 i = bin
         return indices
@@ -2383,7 +2383,8 @@ class Grouping(object):
 
     def _make_labels(self):
         if self._labels is None or self._group_index is None:
-            labels, uniques = algos.factorize(self.grouper, sort=self.sort)
+            labels, uniques = algorithms.factorize(
+                self.grouper, sort=self.sort)
             uniques = Index(uniques, name=self.name)
             self._labels = labels
             self._group_index = uniques
@@ -2928,7 +2929,7 @@ class SeriesGroupBy(GroupBy):
 
         ids, _, ngroup = self.grouper.group_info
         cast = (self.size().fillna(0) > 0).any()
-        out = algos.take_1d(func().values, ids)
+        out = algorithms.take_1d(func().values, ids)
         if cast:
             out = self._try_cast(out, self.obj)
         return Series(out, index=self.obj.index, name=self.obj.name)
@@ -2985,7 +2986,7 @@ class SeriesGroupBy(GroupBy):
         except TypeError:  # catches object dtypes
             assert val.dtype == object, \
                 'val.dtype must be object, got %s' % val.dtype
-            val, _ = algos.factorize(val, sort=False)
+            val, _ = algorithms.factorize(val, sort=False)
             sorter = np.lexsort((val, ids))
             _isnull = lambda a: a == -1
         else:
@@ -3069,7 +3070,7 @@ class SeriesGroupBy(GroupBy):
         ids, val = ids[mask], val[mask]
 
         if bins is None:
-            lab, lev = algos.factorize(val, sort=True)
+            lab, lev = algorithms.factorize(val, sort=True)
         else:
             cat, bins = cut(val, bins, retbins=True)
             # bins[:-1] for backward compat;
@@ -3108,7 +3109,7 @@ class SeriesGroupBy(GroupBy):
             if dropna:
                 m = ids[lab == -1]
                 if _np_version_under1p8:
-                    mi, ml = algos.factorize(m)
+                    mi, ml = algorithms.factorize(m)
                     d[ml] = d[ml] - np.bincount(mi)
                 else:
                     np.add.at(d, m, -1)
@@ -3130,7 +3131,7 @@ class SeriesGroupBy(GroupBy):
                 out = _ensure_int64(out)
             return Series(out, index=mi, name=self.name)
 
-        # for compat. with algos.value_counts need to ensure every
+        # for compat. with libalgos.value_counts need to ensure every
         # bin is present at every index level, null filled with zeros
         diff = np.zeros(len(out), dtype='bool')
         for lab in labels[:-1]:
@@ -3701,7 +3702,7 @@ class NDFrameGroupBy(GroupBy):
         ids, _, ngroup = self.grouper.group_info
         output = []
         for i, _ in enumerate(result.columns):
-            res = algos.take_1d(result.iloc[:, i].values, ids)
+            res = algorithms.take_1d(result.iloc[:, i].values, ids)
             if cast:
                 res = self._try_cast(res, obj.iloc[:, i])
             output.append(res)
@@ -3995,7 +3996,6 @@ class DataFrameGroupBy(NDFrameGroupBy):
     def count(self):
         """ Compute count of group, excluding missing values """
         from functools import partial
-        from pandas.lib import count_level_2d
         from pandas.types.missing import _isnull_ndarraylike as isnull
 
         data, _ = self._get_data_to_aggregate()
@@ -4190,7 +4190,7 @@ class DataSplitter(object):
     @cache_readonly
     def slabels(self):
         # Sorted labels
-        return algos.take_nd(self.labels, self.sort_idx, allow_fill=False)
+        return algorithms.take_nd(self.labels, self.sort_idx, allow_fill=False)
 
     @cache_readonly
     def sort_idx(self):
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 6cd5eceed..4b43574f4 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -53,18 +53,17 @@ from pandas.formats.printing import pprint_thing
 
 import pandas.core.missing as missing
 from pandas.sparse.array import _maybe_to_sparse, SparseArray
-import pandas.lib as lib
-import pandas.tslib as tslib
+from pandas._libs import lib, tslib
+from pandas._libs.tslib import Timedelta
+from pandas._libs.lib import BlockPlacement
+
 import pandas.computation.expressions as expressions
 from pandas.util.decorators import cache_readonly
 from pandas.util.validators import validate_bool_kwarg
 
-from pandas.tslib import Timedelta
 from pandas import compat, _np_version_under1p9
 from pandas.compat import range, map, zip, u
 
-from pandas.lib import BlockPlacement
-
 
 class Block(PandasObject):
     """
diff --git a/pandas/core/missing.py b/pandas/core/missing.py
index ffd042357..3b9bfe1de 100644
--- a/pandas/core/missing.py
+++ b/pandas/core/missing.py
@@ -5,8 +5,8 @@ Routines for filling missing data
 import numpy as np
 from distutils.version import LooseVersion
 
-import pandas.algos as algos
-import pandas.lib as lib
+from pandas._libs import algos, lib
+
 from pandas.compat import range, string_types
 from pandas.types.common import (is_numeric_v_string_like,
                                  is_float_dtype, is_datetime64_dtype,
diff --git a/pandas/core/nanops.py b/pandas/core/nanops.py
index 0cc3a2d03..bb6c9b454 100644
--- a/pandas/core/nanops.py
+++ b/pandas/core/nanops.py
@@ -9,7 +9,8 @@ try:
 except ImportError:  # pragma: no cover
     _USE_BOTTLENECK = False
 
-from pandas import compat, lib, algos, tslib
+from pandas import compat
+from pandas._libs import tslib, algos, lib
 from pandas.types.common import (_get_dtype,
                                  is_float, is_scalar,
                                  is_integer, is_complex, is_float_dtype,
diff --git a/pandas/core/ops.py b/pandas/core/ops.py
index 6cc43cd92..fe83f8a35 100644
--- a/pandas/core/ops.py
+++ b/pandas/core/ops.py
@@ -10,15 +10,17 @@ import warnings
 import numpy as np
 import pandas as pd
 import datetime
-from pandas import compat, lib, tslib
-import pandas.index as _index
+
+from pandas._libs import (lib, index as libindex,
+                          tslib as libts, algos as libalgos, iNaT)
+
+from pandas import compat
 from pandas.util.decorators import Appender
 import pandas.computation.expressions as expressions
-from pandas.lib import isscalar
-from pandas.tslib import iNaT
+
 from pandas.compat import bind_method
 import pandas.core.missing as missing
-import pandas.algos as _algos
+
 from pandas.core.common import (_values_from_object, _maybe_match_name,
                                 PerformanceWarning)
 from pandas.types.missing import notnull, isnull
@@ -29,6 +31,7 @@ from pandas.types.common import (needs_i8_conversion,
                                  is_datetime64_dtype, is_datetime64tz_dtype,
                                  is_bool_dtype, is_datetimetz,
                                  is_list_like,
+                                 is_scalar,
                                  _ensure_object)
 from pandas.types.cast import _maybe_upcast_putmask, _find_common_type
 from pandas.types.generic import ABCSeries, ABCIndex, ABCPeriodIndex
@@ -476,7 +479,7 @@ class _TimeOp(_Op):
                     values = values._values
             elif not (isinstance(values, (np.ndarray, ABCSeries)) and
                       is_datetime64_dtype(values)):
-                values = tslib.array_to_datetime(values)
+                values = libts.array_to_datetime(values)
         elif inferred_type in ('timedelta', 'timedelta64'):
             # have a timedelta, convert to to ns here
             values = to_timedelta(values, errors='coerce', box=False)
@@ -680,12 +683,12 @@ def _arith_method_SERIES(op, name, str_rep, fill_zeros=None, default_axis=None,
             if isinstance(rvalues, ABCSeries):
                 if is_object_dtype(rvalues):
                     # if dtype is object, try elementwise op
-                    return _algos.arrmap_object(rvalues,
-                                                lambda x: op(lvalues, x))
+                    return libalgos.arrmap_object(rvalues,
+                                                  lambda x: op(lvalues, x))
             else:
                 if is_object_dtype(lvalues):
-                    return _algos.arrmap_object(lvalues,
-                                                lambda x: op(x, rvalues))
+                    return libalgos.arrmap_object(lvalues,
+                                                  lambda x: op(x, rvalues))
             raise
 
     def wrapper(left, right, name=name, na_op=na_op):
@@ -754,7 +757,7 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
         # in either operand
         if is_categorical_dtype(x):
             return op(x, y)
-        elif is_categorical_dtype(y) and not isscalar(y):
+        elif is_categorical_dtype(y) and not is_scalar(y):
             return op(y, x)
 
         if is_object_dtype(x.dtype):
@@ -770,7 +773,7 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
                 raise TypeError("invalid type comparison")
 
             # numpy does not like comparisons vs None
-            if isscalar(y) and isnull(y):
+            if is_scalar(y) and isnull(y):
                 if name == '__ne__':
                     return np.ones(len(x), dtype=bool)
                 else:
@@ -779,11 +782,11 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
             # we have a datetime/timedelta and may need to convert
             mask = None
             if (needs_i8_conversion(x) or
-                    (not isscalar(y) and needs_i8_conversion(y))):
+                    (not is_scalar(y) and needs_i8_conversion(y))):
 
-                if isscalar(y):
+                if is_scalar(y):
                     mask = isnull(x)
-                    y = _index.convert_scalar(x, _values_from_object(y))
+                    y = libindex.convert_scalar(x, _values_from_object(y))
                 else:
                     mask = isnull(x) | isnull(y)
                     y = y.view('i8')
@@ -819,7 +822,7 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
         elif isinstance(other, (np.ndarray, pd.Index)):
             # do not check length of zerodim array
             # as it will broadcast
-            if (not lib.isscalar(lib.item_from_zerodim(other)) and
+            if (not is_scalar(lib.item_from_zerodim(other)) and
                     len(self) != len(other)):
                 raise ValueError('Lengths must match to compare')
 
@@ -855,7 +858,7 @@ def _comp_method_SERIES(op, name, str_rep, masker=False):
 
             with np.errstate(all='ignore'):
                 res = na_op(values, other)
-            if isscalar(res):
+            if is_scalar(res):
                 raise TypeError('Could not compare %s type with Series' %
                                 type(other))
 
@@ -1333,7 +1336,7 @@ def _arith_method_PANEL(op, name, str_rep=None, fill_zeros=None,
 
     # work only for scalars
     def f(self, other):
-        if not isscalar(other):
+        if not is_scalar(other):
             raise ValueError('Simple arithmetic with %s can only be '
                              'done with scalar values' %
                              self._constructor.__name__)
diff --git a/pandas/core/reshape.py b/pandas/core/reshape.py
index 7bcd9f2d3..3279a8f2b 100644
--- a/pandas/core/reshape.py
+++ b/pandas/core/reshape.py
@@ -19,15 +19,14 @@ from pandas.core.frame import DataFrame
 
 from pandas.core.sparse import SparseDataFrame, SparseSeries
 from pandas.sparse.array import SparseArray
-from pandas._sparse import IntIndex
+from pandas.sparse.libsparse import IntIndex
 
 from pandas.core.categorical import Categorical, _factorize_from_iterable
 from pandas.core.sorting import (get_group_index, compress_group_index,
                                  decons_obs_group_ids)
 
 import pandas.core.algorithms as algos
-import pandas.algos as _algos
-import pandas._reshape as _reshape
+from pandas._libs import algos as _algos, reshape as _reshape
 
 from pandas.core.index import MultiIndex, _get_na_value
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 626a4a811..83036ffef 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -60,7 +60,7 @@ from pandas.compat import zip, u, OrderedDict, StringIO
 from pandas.compat.numpy import function as nv
 
 import pandas.core.ops as ops
-import pandas.core.algorithms as algos
+import pandas.core.algorithms as algorithms
 
 import pandas.core.common as com
 import pandas.core.nanops as nanops
@@ -68,10 +68,7 @@ import pandas.formats.format as fmt
 from pandas.util.decorators import Appender, deprecate_kwarg, Substitution
 from pandas.util.validators import validate_bool_kwarg
 
-import pandas.lib as lib
-import pandas.tslib as tslib
-import pandas.index as _index
-
+from pandas._libs import index as libindex, tslib as libts, lib, iNaT
 from pandas.core.config import get_option
 
 __all__ = ['Series']
@@ -294,7 +291,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                     # need to set here becuase we changed the index
                     if fastpath:
                         self._data.set_axis(axis, labels)
-                except (tslib.OutOfBoundsDatetime, ValueError):
+                except (libts.OutOfBoundsDatetime, ValueError):
                     # labels may exceeds datetime bounds,
                     # or not be a DatetimeIndex
                     pass
@@ -568,7 +565,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
             # dispatch to the values if we need
             values = self._values
             if isinstance(values, np.ndarray):
-                return _index.get_value_at(values, i)
+                return libindex.get_value_at(values, i)
             else:
                 return values[i]
         except IndexError:
@@ -582,7 +579,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                 if isinstance(label, Index):
                     return self.take(i, axis=axis, convert=True)
                 else:
-                    return _index.get_value_at(self, i)
+                    return libindex.get_value_at(self, i)
 
     @property
     def _is_mixed_type(self):
@@ -733,7 +730,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                 elif is_timedelta64_dtype(self.dtype):
                     # reassign a null value to iNaT
                     if isnull(value):
-                        value = tslib.iNaT
+                        value = iNaT
 
                         try:
                             self.index._engine.set_value(self._values, key,
@@ -1202,7 +1199,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         modes : Series (sorted)
         """
         # TODO: Add option for bins like value_counts()
-        return algos.mode(self)
+        return algorithms.mode(self)
 
     @Appender(base._shared_docs['unique'] % _shared_doc_kwargs)
     def unique(self):
@@ -1424,7 +1421,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         -------
         diffed : Series
         """
-        result = algos.diff(_values_from_object(self), periods)
+        result = algorithms.diff(_values_from_object(self), periods)
         return self._constructor(result, index=self.index).__finalize__(self)
 
     def autocorr(self, lag=1):
@@ -1915,7 +1912,8 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         >>> s = pd.Series(np.random.randn(1e6))
         >>> s.nlargest(10)  # only sorts up to the N requested
         """
-        return algos.select_n_series(self, n=n, keep=keep, method='nlargest')
+        return algorithms.select_n_series(self, n=n, keep=keep,
+                                          method='nlargest')
 
     @deprecate_kwarg('take_last', 'keep', mapping={True: 'last',
                                                    False: 'first'})
@@ -1953,7 +1951,8 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         >>> s = pd.Series(np.random.randn(1e6))
         >>> s.nsmallest(10)  # only sorts up to the N requested
         """
-        return algos.select_n_series(self, n=n, keep=keep, method='nsmallest')
+        return algorithms.select_n_series(self, n=n, keep=keep,
+                                          method='nsmallest')
 
     def sortlevel(self, level=0, ascending=True, sort_remaining=True):
         """
@@ -2166,7 +2165,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
                 arg = self._constructor(arg, index=arg.keys())
 
             indexer = arg.index.get_indexer(values)
-            new_values = algos.take_1d(arg._values, indexer)
+            new_values = algorithms.take_1d(arg._values, indexer)
         else:
             new_values = map_f(values, arg)
 
@@ -2324,7 +2323,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
             return self
 
         # be subclass-friendly
-        new_values = algos.take_1d(self.get_values(), indexer)
+        new_values = algorithms.take_1d(self.get_values(), indexer)
         return self._constructor(new_values, index=new_index)
 
     def _needs_reindex_multi(self, axes, method, level):
@@ -2484,7 +2483,7 @@ class Series(base.IndexOpsMixin, strings.StringAccessorMixin,
         dtype: bool
 
         """
-        result = algos.isin(_values_from_object(self), values)
+        result = algorithms.isin(_values_from_object(self), values)
         return self._constructor(result, index=self.index).__finalize__(self)
 
     def between(self, left, right, inclusive=True):
diff --git a/pandas/core/sorting.py b/pandas/core/sorting.py
index 71314da77..205d0d94d 100644
--- a/pandas/core/sorting.py
+++ b/pandas/core/sorting.py
@@ -7,10 +7,9 @@ from pandas.types.common import (_ensure_platform_int,
                                  _ensure_int64,
                                  is_categorical_dtype)
 from pandas.types.missing import isnull
-import pandas.core.algorithms as algos
-import pandas.algos as _algos
-import pandas.hashtable as _hash
-from pandas import lib
+import pandas.core.algorithms as algorithms
+from pandas._libs import lib, algos, hashtable
+from pandas._libs.hashtable import unique_label_indices
 
 
 _INT64_MAX = np.iinfo(np.int64).max
@@ -131,7 +130,6 @@ def decons_obs_group_ids(comp_ids, obs_ids, shape, labels, xnull):
     xnull: boolean,
         if nulls are excluded; i.e. -1 labels are passed through
     """
-    from pandas.hashtable import unique_label_indices
 
     if not xnull:
         lift = np.fromiter(((a == -1).any() for a in labels), dtype='i8')
@@ -250,7 +248,8 @@ class _KeyMapper(object):
         self.comp_ids = comp_ids.astype(np.int64)
 
         self.k = len(labels)
-        self.tables = [_hash.Int64HashTable(ngroups) for _ in range(self.k)]
+        self.tables = [hashtable.Int64HashTable(ngroups)
+                       for _ in range(self.k)]
 
         self._populate_tables()
 
@@ -291,7 +290,7 @@ def get_indexer_dict(label_list, keys):
 
 def get_group_index_sorter(group_index, ngroups):
     """
-    _algos.groupsort_indexer implements `counting sort` and it is at least
+    algos.groupsort_indexer implements `counting sort` and it is at least
     O(ngroups), where
         ngroups = prod(shape)
         shape = map(len, keys)
@@ -309,8 +308,8 @@ def get_group_index_sorter(group_index, ngroups):
     do_groupsort = (count > 0 and ((alpha + beta * ngroups) <
                                    (count * np.log(count))))
     if do_groupsort:
-        sorter, _ = _algos.groupsort_indexer(_ensure_int64(group_index),
-                                             ngroups)
+        sorter, _ = algos.groupsort_indexer(_ensure_int64(group_index),
+                                            ngroups)
         return _ensure_platform_int(sorter)
     else:
         return group_index.argsort(kind='mergesort')
@@ -323,8 +322,8 @@ def compress_group_index(group_index, sort=True):
     (comp_ids) into the list of unique labels (obs_group_ids).
     """
 
-    size_hint = min(len(group_index), _hash._SIZE_HINT_LIMIT)
-    table = _hash.Int64HashTable(size_hint)
+    size_hint = min(len(group_index), hashtable._SIZE_HINT_LIMIT)
+    table = hashtable.Int64HashTable(size_hint)
 
     group_index = _ensure_int64(group_index)
 
@@ -348,10 +347,10 @@ def _reorder_by_uniques(uniques, labels):
     mask = labels < 0
 
     # move labels to right locations (ie, unsort ascending labels)
-    labels = algos.take_nd(reverse_indexer, labels, allow_fill=False)
+    labels = algorithms.take_nd(reverse_indexer, labels, allow_fill=False)
     np.putmask(labels, mask, -1)
 
     # sort observed ids
-    uniques = algos.take_nd(uniques, sorter, allow_fill=False)
+    uniques = algorithms.take_nd(uniques, sorter, allow_fill=False)
 
     return uniques, labels
diff --git a/pandas/core/strings.py b/pandas/core/strings.py
index 46ba48b4c..b5b5d5823 100644
--- a/pandas/core/strings.py
+++ b/pandas/core/strings.py
@@ -18,7 +18,7 @@ import pandas.compat as compat
 from pandas.core.base import AccessorProperty, NoNewAttributesMixin
 from pandas.util.decorators import Appender
 import re
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import warnings
 import textwrap
 import codecs
diff --git a/pandas/core/window.py b/pandas/core/window.py
index 3f9aa2b0f..6fda60c44 100644
--- a/pandas/core/window.py
+++ b/pandas/core/window.py
@@ -24,13 +24,14 @@ from pandas.types.common import (is_integer,
                                  needs_i8_conversion,
                                  is_timedelta64_dtype,
                                  is_list_like,
-                                 _ensure_float64)
+                                 _ensure_float64,
+                                 is_scalar)
 import pandas as pd
-from pandas.lib import isscalar
+
 from pandas.core.base import (PandasObject, SelectionMixin,
                               GroupByMixin)
 import pandas.core.common as com
-import pandas._window as _window
+import pandas.core.libwindow as _window
 from pandas.tseries.offsets import DateOffset
 from pandas import compat
 from pandas.compat.numpy import function as nv
@@ -154,7 +155,7 @@ class _Window(PandasObject, SelectionMixin):
         self = self._shallow_copy(subset)
         self._reset_cache()
         if subset.ndim == 2:
-            if isscalar(key) and key in subset or is_list_like(key):
+            if is_scalar(key) and key in subset or is_list_like(key):
                 self._selection = key
         return self
 
diff --git a/pandas/window.pyx b/pandas/core/window.pyx
similarity index 99%
rename from pandas/window.pyx
rename to pandas/core/window.pyx
index 005d42c9f..a06e61600 100644
--- a/pandas/window.pyx
+++ b/pandas/core/window.pyx
@@ -58,7 +58,7 @@ from util cimport numeric
 
 from skiplist cimport *
 
-cdef extern from "src/headers/math.h":
+cdef extern from "../src/headers/math.h":
     double sqrt(double x) nogil
     int signbit(double) nogil
 
diff --git a/pandas/formats/format.py b/pandas/formats/format.py
index 622c4cd3b..d354911a8 100644
--- a/pandas/formats/format.py
+++ b/pandas/formats/format.py
@@ -33,8 +33,9 @@ from pandas.core.config import get_option, set_option
 from pandas.io.common import _get_handle, UnicodeWriter, _expand_user
 from pandas.formats.printing import adjoin, justify, pprint_thing
 import pandas.core.common as com
-import pandas.lib as lib
-from pandas.tslib import iNaT, Timestamp, Timedelta, format_array_from_datetime
+import pandas._libs.lib as lib
+from pandas._libs.tslib import (iNaT, Timestamp, Timedelta,
+                                format_array_from_datetime)
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex
 import pandas as pd
diff --git a/pandas/indexes/api.py b/pandas/indexes/api.py
index 64992e466..a38453e0d 100644
--- a/pandas/indexes/api.py
+++ b/pandas/indexes/api.py
@@ -8,7 +8,7 @@ from pandas.indexes.numeric import (NumericIndex, Float64Index,  # noqa
 from pandas.indexes.range import RangeIndex  # noqa
 
 import pandas.core.common as com
-import pandas.lib as lib
+import pandas._libs.lib as lib
 
 # TODO: there are many places that rely on these private methods existing in
 # pandas.core.index
diff --git a/pandas/indexes/base.py b/pandas/indexes/base.py
index e441d9a88..607a46308 100644
--- a/pandas/indexes/base.py
+++ b/pandas/indexes/base.py
@@ -3,12 +3,10 @@ import warnings
 import operator
 
 import numpy as np
-import pandas.tslib as tslib
-import pandas.lib as lib
-import pandas._join as _join
-import pandas.algos as _algos
-import pandas.index as _index
-from pandas.lib import Timestamp, Timedelta, is_datetime_array
+from pandas._libs import (lib, index as libindex, tslib as libts,
+                          algos as libalgos, join as libjoin,
+                          Timestamp, Timedelta, )
+from pandas._libs.lib import is_datetime_array
 
 from pandas.compat import range, u
 from pandas.compat.numpy import function as nv
@@ -120,11 +118,11 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
     _join_precedence = 1
 
     # Cython methods
-    _arrmap = _algos.arrmap_object
-    _left_indexer_unique = _join.left_join_indexer_unique_object
-    _left_indexer = _join.left_join_indexer_object
-    _inner_indexer = _join.inner_join_indexer_object
-    _outer_indexer = _join.outer_join_indexer_object
+    _arrmap = libalgos.arrmap_object
+    _left_indexer_unique = libjoin.left_join_indexer_unique_object
+    _left_indexer = libjoin.left_join_indexer_object
+    _inner_indexer = libjoin.inner_join_indexer_object
+    _outer_indexer = libjoin.outer_join_indexer_object
     _box_scalars = False
 
     _typ = 'index'
@@ -144,7 +142,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
     # used to infer integers as datetime-likes
     _infer_as_myclass = False
 
-    _engine_type = _index.ObjectEngine
+    _engine_type = libindex.ObjectEngine
 
     def __new__(cls, data=None, dtype=None, copy=False, name=None,
                 fastpath=False, tupleize_cols=True, **kwargs):
@@ -285,7 +283,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
                             try:
                                 return DatetimeIndex(subarr, copy=copy,
                                                      name=name, **kwargs)
-                            except tslib.OutOfBoundsDatetime:
+                            except libts.OutOfBoundsDatetime:
                                 pass
 
                     elif inferred.startswith('timedelta'):
@@ -2314,7 +2312,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
                 raise
 
             try:
-                return tslib.get_value_box(s, key)
+                return libts.get_value_box(s, key)
             except IndexError:
                 raise
             except TypeError:
@@ -2972,7 +2970,6 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
         order of the data indexed by the MultiIndex will not be changed;
         otherwise, it will tie out with `other`.
         """
-        from pandas.algos import groupsort_indexer
         from .multi import MultiIndex
 
         def _get_leaf_sorter(labels):
@@ -2985,7 +2982,7 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
 
             if len(labels) == 1:
                 lab = _ensure_int64(labels[0])
-                sorter, _ = groupsort_indexer(lab, 1 + lab.max())
+                sorter, _ = libalgos.groupsort_indexer(lab, 1 + lab.max())
                 return sorter
 
             # find indexers of begining of each set of
@@ -3051,8 +3048,9 @@ class Index(IndexOpsMixin, StringAccessorMixin, PandasObject):
             else:  # tie out the order with other
                 if level == 0:  # outer most level, take the fast route
                     ngroups = 1 + new_lev_labels.max()
-                    left_indexer, counts = groupsort_indexer(new_lev_labels,
-                                                             ngroups)
+                    left_indexer, counts = libalgos.groupsort_indexer(
+                        new_lev_labels, ngroups)
+
                     # missing values are placed first; drop them!
                     left_indexer = left_indexer[counts[0]:]
                     new_labels = [lab[left_indexer] for lab in new_labels]
@@ -3846,8 +3844,8 @@ def _ensure_index(index_like, copy=False):
 
 
 def _get_na_value(dtype):
-    return {np.datetime64: tslib.NaT,
-            np.timedelta64: tslib.NaT}.get(dtype, np.nan)
+    return {np.datetime64: libts.NaT,
+            np.timedelta64: libts.NaT}.get(dtype, np.nan)
 
 
 def _ensure_has_len(seq):
diff --git a/pandas/indexes/category.py b/pandas/indexes/category.py
index 5299a0941..3d8f76fc5 100644
--- a/pandas/indexes/category.py
+++ b/pandas/indexes/category.py
@@ -1,5 +1,5 @@
 import numpy as np
-import pandas.index as _index
+from pandas._libs import index as libindex
 
 from pandas import compat
 from pandas.compat.numpy import function as nv
@@ -45,7 +45,7 @@ class CategoricalIndex(Index, base.PandasDelegate):
     """
 
     _typ = 'categoricalindex'
-    _engine_type = _index.Int64Engine
+    _engine_type = libindex.Int64Engine
     _attributes = ['name']
 
     def __new__(cls, data=None, categories=None, ordered=None, dtype=None,
@@ -303,7 +303,7 @@ class CategoricalIndex(Index, base.PandasDelegate):
                                                    False: 'first'})
     @Appender(base._shared_docs['duplicated'] % _index_doc_kwargs)
     def duplicated(self, keep='first'):
-        from pandas.hashtable import duplicated_int64
+        from pandas._libs.hashtable import duplicated_int64
         codes = self.codes.astype('i8')
         return duplicated_int64(codes, keep)
 
diff --git a/pandas/indexes/multi.py b/pandas/indexes/multi.py
index 23a42265a..bca1db83b 100644
--- a/pandas/indexes/multi.py
+++ b/pandas/indexes/multi.py
@@ -6,9 +6,7 @@ from functools import partial
 from sys import getsizeof
 
 import numpy as np
-import pandas.lib as lib
-import pandas.index as _index
-from pandas.lib import Timestamp
+from pandas._libs import index as libindex, lib, Timestamp
 
 from pandas.compat import range, zip, lrange, lzip, map
 from pandas.compat.numpy import function as nv
@@ -76,7 +74,7 @@ class MultiIndex(Index):
     _levels = FrozenList()
     _labels = FrozenList()
     _comparables = ['names']
-    _engine_type = _index.MultiIndexEngine
+    _engine_type = libindex.MultiIndexEngine
     rename = Index.set_names
 
     def __new__(cls, levels=None, labels=None, sortorder=None, names=None,
@@ -762,7 +760,7 @@ class MultiIndex(Index):
     @Appender(base._shared_docs['duplicated'] % _index_doc_kwargs)
     def duplicated(self, keep='first'):
         from pandas.core.sorting import get_group_index
-        from pandas.hashtable import duplicated_int64
+        from pandas._libs.hashtable import duplicated_int64
 
         shape = map(len, self.levels)
         ids = get_group_index(self.labels, shape, sort=False, xnull=False)
@@ -813,7 +811,7 @@ class MultiIndex(Index):
                 pass
 
             try:
-                return _index.get_value_at(s, k)
+                return libindex.get_value_at(s, k)
             except IndexError:
                 raise
             except TypeError:
diff --git a/pandas/indexes/numeric.py b/pandas/indexes/numeric.py
index 00ddf5b0c..9bb70feb2 100644
--- a/pandas/indexes/numeric.py
+++ b/pandas/indexes/numeric.py
@@ -1,9 +1,6 @@
 import numpy as np
-import pandas.lib as lib
-import pandas._join as _join
-import pandas.algos as _algos
-import pandas.index as _index
-
+from pandas._libs import (lib, index as libindex,
+                          algos as libalgos, join as libjoin)
 from pandas.types.common import (is_dtype_equal, pandas_dtype,
                                  is_float_dtype, is_object_dtype,
                                  is_integer_dtype, is_scalar)
@@ -114,16 +111,13 @@ class Int64Index(NumericIndex):
     __doc__ = _num_index_shared_docs['class_descr'] % _int64_descr_args
 
     _typ = 'int64index'
-    _arrmap = _algos.arrmap_int64
-    _left_indexer_unique = _join.left_join_indexer_unique_int64
-    _left_indexer = _join.left_join_indexer_int64
-    _inner_indexer = _join.inner_join_indexer_int64
-    _outer_indexer = _join.outer_join_indexer_int64
-
+    _arrmap = libalgos.arrmap_int64
+    _left_indexer_unique = libjoin.left_join_indexer_unique_int64
+    _left_indexer = libjoin.left_join_indexer_int64
+    _inner_indexer = libjoin.inner_join_indexer_int64
+    _outer_indexer = libjoin.outer_join_indexer_int64
     _can_hold_na = False
-
-    _engine_type = _index.Int64Engine
-
+    _engine_type = libindex.Int64Engine
     _default_dtype = np.int64
 
     @property
@@ -175,17 +169,14 @@ class UInt64Index(NumericIndex):
     __doc__ = _num_index_shared_docs['class_descr'] % _uint64_descr_args
 
     _typ = 'uint64index'
-    _arrmap = _algos.arrmap_uint64
-    _left_indexer_unique = _join.left_join_indexer_unique_uint64
-    _left_indexer = _join.left_join_indexer_uint64
-    _inner_indexer = _join.inner_join_indexer_uint64
-    _outer_indexer = _join.outer_join_indexer_uint64
-
+    _arrmap = libalgos.arrmap_uint64
+    _left_indexer_unique = libjoin.left_join_indexer_unique_uint64
+    _left_indexer = libjoin.left_join_indexer_uint64
+    _inner_indexer = libjoin.inner_join_indexer_uint64
+    _outer_indexer = libjoin.outer_join_indexer_uint64
     _can_hold_na = False
     _na_value = 0
-
-    _engine_type = _index.UInt64Engine
-
+    _engine_type = libindex.UInt64Engine
     _default_dtype = np.uint64
 
     @property
@@ -255,12 +246,12 @@ class Float64Index(NumericIndex):
     __doc__ = _num_index_shared_docs['class_descr'] % _float64_descr_args
 
     _typ = 'float64index'
-    _engine_type = _index.Float64Engine
-    _arrmap = _algos.arrmap_float64
-    _left_indexer_unique = _join.left_join_indexer_unique_float64
-    _left_indexer = _join.left_join_indexer_float64
-    _inner_indexer = _join.inner_join_indexer_float64
-    _outer_indexer = _join.outer_join_indexer_float64
+    _engine_type = libindex.Float64Engine
+    _arrmap = libalgos.arrmap_float64
+    _left_indexer_unique = libjoin.left_join_indexer_unique_float64
+    _left_indexer = libjoin.left_join_indexer_float64
+    _inner_indexer = libjoin.inner_join_indexer_float64
+    _outer_indexer = libjoin.outer_join_indexer_float64
 
     _default_dtype = np.float64
 
diff --git a/pandas/indexes/range.py b/pandas/indexes/range.py
index cc78361f8..103a3ac2f 100644
--- a/pandas/indexes/range.py
+++ b/pandas/indexes/range.py
@@ -2,7 +2,7 @@ from sys import getsizeof
 import operator
 
 import numpy as np
-import pandas.index as _index
+from pandas._libs import index as libindex
 
 from pandas.types.common import (is_integer,
                                  is_scalar,
@@ -39,7 +39,7 @@ class RangeIndex(Int64Index):
     """
 
     _typ = 'rangeindex'
-    _engine_type = _index.Int64Engine
+    _engine_type = libindex.Int64Engine
 
     def __new__(cls, start=None, stop=None, step=None, name=None, dtype=None,
                 fastpath=False, copy=False, **kwargs):
diff --git a/pandas/io/api.py b/pandas/io/api.py
index 1284b3cb2..e312e7bc2 100644
--- a/pandas/io/api.py
+++ b/pandas/io/api.py
@@ -11,7 +11,7 @@ from pandas.io.pytables import HDFStore, get_store, read_hdf
 from pandas.io.json import read_json
 from pandas.io.html import read_html
 from pandas.io.sql import read_sql, read_sql_table, read_sql_query
-from pandas.io.sas.sasreader import read_sas
+from pandas.io.sas import read_sas
 from pandas.io.feather_format import read_feather
 from pandas.io.stata import read_stata
 from pandas.io.pickle import read_pickle, to_pickle
diff --git a/pandas/io/date_converters.py b/pandas/io/date_converters.py
index 3ffcef4b2..080d6c3e2 100644
--- a/pandas/io/date_converters.py
+++ b/pandas/io/date_converters.py
@@ -1,7 +1,7 @@
 """This module is designed for community supported date conversion functions"""
 from pandas.compat import range, map
 import numpy as np
-import pandas.lib as lib
+import pandas._libs.lib as lib
 
 
 def parse_date_time(date_col, time_col):
diff --git a/pandas/io/excel.py b/pandas/io/excel.py
index 00ec8bcf0..82ea2e8a4 100644
--- a/pandas/io/excel.py
+++ b/pandas/io/excel.py
@@ -19,7 +19,7 @@ from pandas.io.common import (_is_url, _urlopen, _validate_header_arg,
                               EmptyDataError, get_filepath_or_buffer,
                               _NA_VALUES)
 from pandas.tseries.period import Period
-from pandas import json
+from pandas.io.json import libjson
 from pandas.compat import (map, zip, reduce, range, lrange, u, add_metaclass,
                            string_types, OrderedDict)
 from pandas.core import config
@@ -1450,7 +1450,7 @@ class _XlwtWriter(ExcelWriter):
             elif isinstance(cell.val, date):
                 num_format_str = self.date_format
 
-            stylekey = json.dumps(cell.style)
+            stylekey = libjson.dumps(cell.style)
             if num_format_str:
                 stylekey += num_format_str
 
@@ -1578,7 +1578,7 @@ class _XlsxWriter(ExcelWriter):
             elif isinstance(cell.val, date):
                 num_format_str = self.date_format
 
-            stylekey = json.dumps(cell.style)
+            stylekey = libjson.dumps(cell.style)
             if num_format_str:
                 stylekey += num_format_str
 
diff --git a/pandas/io/json/json.py b/pandas/io/json/json.py
index a00d3492e..114ec4bb2 100644
--- a/pandas/io/json/json.py
+++ b/pandas/io/json/json.py
@@ -2,8 +2,8 @@
 import os
 import numpy as np
 
-import pandas.json as _json
-from pandas.tslib import iNaT
+from pandas.io.json import libjson
+from pandas._libs.tslib import iNaT
 from pandas.compat import StringIO, long, u
 from pandas import compat, isnull
 from pandas import Series, DataFrame, to_datetime
@@ -14,8 +14,8 @@ from .normalize import _convert_to_line_delimits
 from .table_schema import build_table_schema
 from pandas.types.common import is_period_dtype
 
-loads = _json.loads
-dumps = _json.dumps
+loads = libjson.loads
+dumps = libjson.dumps
 
 TABLE_SCHEMA_VERSION = '0.20.0'
 
diff --git a/pandas/io/json/normalize.py b/pandas/io/json/normalize.py
index 0e7d025e8..4da4a6ad5 100644
--- a/pandas/io/json/normalize.py
+++ b/pandas/io/json/normalize.py
@@ -5,7 +5,7 @@ import copy
 from collections import defaultdict
 import numpy as np
 
-from pandas.lib import convert_json_to_lines
+from pandas._libs.lib import convert_json_to_lines
 from pandas import compat, DataFrame
 
 
diff --git a/pandas/msgpack/__init__.py b/pandas/io/msgpack/__init__.py
similarity index 81%
rename from pandas/msgpack/__init__.py
rename to pandas/io/msgpack/__init__.py
index 4d6e24117..984e90ee0 100644
--- a/pandas/msgpack/__init__.py
+++ b/pandas/io/msgpack/__init__.py
@@ -2,8 +2,8 @@
 
 from collections import namedtuple
 
-from pandas.msgpack.exceptions import *  # noqa
-from pandas.msgpack._version import version  # noqa
+from pandas.io.msgpack.exceptions import *  # noqa
+from pandas.io.msgpack._version import version  # noqa
 
 
 class ExtType(namedtuple('ExtType', 'code data')):
@@ -19,8 +19,8 @@ class ExtType(namedtuple('ExtType', 'code data')):
 
 import os  # noqa
 
-from pandas.msgpack._packer import Packer  # noqa
-from pandas.msgpack._unpacker import unpack, unpackb, Unpacker  # noqa
+from pandas.io.msgpack._packer import Packer  # noqa
+from pandas.io.msgpack._unpacker import unpack, unpackb, Unpacker  # noqa
 
 
 def pack(o, stream, **kwargs):
diff --git a/pandas/msgpack/_packer.pyx b/pandas/io/msgpack/_packer.pyx
similarity index 98%
rename from pandas/msgpack/_packer.pyx
rename to pandas/io/msgpack/_packer.pyx
index 008dbe554..ad7ce1fb2 100644
--- a/pandas/msgpack/_packer.pyx
+++ b/pandas/io/msgpack/_packer.pyx
@@ -6,11 +6,11 @@ from libc.stdlib cimport *
 from libc.string cimport *
 from libc.limits cimport *
 
-from pandas.msgpack.exceptions import PackValueError
-from pandas.msgpack import ExtType
+from pandas.io.msgpack.exceptions import PackValueError
+from pandas.io.msgpack import ExtType
 
 
-cdef extern from "../src/msgpack/pack.h":
+cdef extern from "../../src/msgpack/pack.h":
     struct msgpack_packer:
         char* buf
         size_t length
diff --git a/pandas/msgpack/_unpacker.pyx b/pandas/io/msgpack/_unpacker.pyx
similarity index 98%
rename from pandas/msgpack/_unpacker.pyx
rename to pandas/io/msgpack/_unpacker.pyx
index 6f23a24ad..504bfed48 100644
--- a/pandas/msgpack/_unpacker.pyx
+++ b/pandas/io/msgpack/_unpacker.pyx
@@ -11,12 +11,12 @@ from libc.stdlib cimport *
 from libc.string cimport *
 from libc.limits cimport *
 
-from pandas.msgpack.exceptions import (BufferFull, OutOfData,
-                                       UnpackValueError, ExtraData)
-from pandas.msgpack import ExtType
+from pandas.io.msgpack.exceptions import (BufferFull, OutOfData,
+                                          UnpackValueError, ExtraData)
+from pandas.io.msgpack import ExtType
 
 
-cdef extern from "../src/msgpack/unpack.h":
+cdef extern from "../../src/msgpack/unpack.h":
     ctypedef struct msgpack_user:
         bint use_list
         PyObject* object_hook
diff --git a/pandas/msgpack/_version.py b/pandas/io/msgpack/_version.py
similarity index 100%
rename from pandas/msgpack/_version.py
rename to pandas/io/msgpack/_version.py
diff --git a/pandas/msgpack/exceptions.py b/pandas/io/msgpack/exceptions.py
similarity index 100%
rename from pandas/msgpack/exceptions.py
rename to pandas/io/msgpack/exceptions.py
diff --git a/pandas/io/packers.py b/pandas/io/packers.py
index 39bc1a4ec..404be758a 100644
--- a/pandas/io/packers.py
+++ b/pandas/io/packers.py
@@ -55,7 +55,7 @@ from pandas import (Timestamp, Period, Series, DataFrame,  # noqa
                     Index, MultiIndex, Float64Index, Int64Index,
                     Panel, RangeIndex, PeriodIndex, DatetimeIndex, NaT,
                     Categorical, CategoricalIndex)
-from pandas.tslib import NaTType
+from pandas._libs.tslib import NaTType
 from pandas.sparse.api import SparseSeries, SparseDataFrame
 from pandas.sparse.array import BlockIndex, IntIndex
 from pandas.core.generic import NDFrame
@@ -64,7 +64,7 @@ from pandas.io.common import get_filepath_or_buffer
 from pandas.core.internals import BlockManager, make_block, _safe_reshape
 import pandas.core.internals as internals
 
-from pandas.msgpack import Unpacker as _Unpacker, Packer as _Packer, ExtType
+from pandas.io.msgpack import Unpacker as _Unpacker, Packer as _Packer, ExtType
 from pandas.util._move import (
     BadMove as _BadMove,
     move_into_mutable_buffer as _move_into_mutable_buffer,
diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 811844ec3..9aedddc81 100755
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -36,8 +36,8 @@ from pandas.tseries import tools
 
 from pandas.util.decorators import Appender
 
-import pandas.lib as lib
-import pandas.parser as _parser
+import pandas._libs.lib as lib
+import pandas.io.libparsers as libparsers
 
 
 # BOM character (byte order mark)
@@ -1415,7 +1415,7 @@ class ParserBase(object):
 
             if issubclass(cvals.dtype.type, np.integer) and self.compact_ints:
                 cvals = lib.downcast_int64(
-                    cvals, _parser.na_values,
+                    cvals, libparsers.na_values,
                     self.use_unsigned)
 
             result[c] = cvals
@@ -1533,7 +1533,7 @@ class CParserWrapper(ParserBase):
         # #2442
         kwds['allow_leading_cols'] = self.index_col is not False
 
-        self._reader = _parser.TextReader(src, **kwds)
+        self._reader = libparsers.TextReader(src, **kwds)
 
         # XXX
         self.usecols, self.usecols_dtype = _validate_usecols_arg(
diff --git a/pandas/parser.pyx b/pandas/io/parsers.pyx
similarity index 99%
rename from pandas/parser.pyx
rename to pandas/io/parsers.pyx
index 23aee860b..a5858accb 100644
--- a/pandas/parser.pyx
+++ b/pandas/io/parsers.pyx
@@ -13,11 +13,12 @@ from cpython cimport (PyObject, PyBytes_FromString,
                       PyUnicode_Check, PyUnicode_AsUTF8String,
                       PyErr_Occurred, PyErr_Fetch)
 from cpython.ref cimport PyObject, Py_XDECREF
-from io.common import ParserError, DtypeWarning, EmptyDataError, ParserWarning
+from pandas.io.common import (ParserError, DtypeWarning,
+                              EmptyDataError, ParserWarning)
 
 # Import CParserError as alias of ParserError for backwards compatibility.
 # Ultimately, we want to remove this import. See gh-12665 and gh-14479.
-from io.common import CParserError
+from pandas.io.common import CParserError
 
 cdef extern from "Python.h":
     object PyUnicode_FromString(char *v)
@@ -36,7 +37,7 @@ from numpy cimport ndarray, uint8_t, uint64_t
 import numpy as np
 cimport util
 
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.compat as compat
 from pandas.types.common import (is_categorical_dtype, CategoricalDtype,
                                  is_integer_dtype, is_float_dtype,
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 9ad53db30..72efc47a3 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -44,9 +44,7 @@ from pandas.compat import u_safe as u, PY3, range, lrange, string_types, filter
 from pandas.core.config import get_option
 from pandas.computation.pytables import Expr, maybe_expression
 
-import pandas.lib as lib
-import pandas.algos as algos
-import pandas.tslib as tslib
+from pandas._libs import tslib, algos, lib
 
 from distutils.version import LooseVersion
 
diff --git a/pandas/io/sas/__init__.py b/pandas/io/sas/__init__.py
index e69de29bb..fa6b29a1a 100644
--- a/pandas/io/sas/__init__.py
+++ b/pandas/io/sas/__init__.py
@@ -0,0 +1 @@
+from .sasreader import read_sas  # noqa
diff --git a/pandas/io/sas/saslib.pyx b/pandas/io/sas/sas.pyx
similarity index 100%
rename from pandas/io/sas/saslib.pyx
rename to pandas/io/sas/sas.pyx
diff --git a/pandas/io/sas/sas7bdat.py b/pandas/io/sas/sas7bdat.py
index 91f417abc..d33cee2c5 100644
--- a/pandas/io/sas/sas7bdat.py
+++ b/pandas/io/sas/sas7bdat.py
@@ -20,7 +20,7 @@ from pandas.io.common import get_filepath_or_buffer, BaseIterator
 import numpy as np
 import struct
 import pandas.io.sas.sas_constants as const
-from pandas.io.sas.saslib import Parser
+from pandas.io.sas.libsas import Parser
 
 
 class _subheader_pointer(object):
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 2ab642b3a..b210baeda 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -11,7 +11,7 @@ import warnings
 import re
 import numpy as np
 
-import pandas.lib as lib
+import pandas._libs.lib as lib
 from pandas.types.missing import isnull
 from pandas.types.dtypes import DatetimeTZDtype
 from pandas.types.common import (is_list_like, is_dict_like,
diff --git a/pandas/io/stata.py b/pandas/io/stata.py
index 1698ade4c..af4bc6a6b 100644
--- a/pandas/io/stata.py
+++ b/pandas/io/stata.py
@@ -30,8 +30,8 @@ from pandas.util.decorators import Appender
 import pandas as pd
 
 from pandas.io.common import get_filepath_or_buffer, BaseIterator
-from pandas.lib import max_len_string_array, infer_dtype
-from pandas.tslib import NaT, Timestamp
+from pandas._libs.lib import max_len_string_array, infer_dtype
+from pandas._libs.tslib import NaT, Timestamp
 
 _version_error = ("Version of given Stata file is not 104, 105, 108, "
                   "111 (Stata 7SE), 113 (Stata 8/9), 114 (Stata 10/11), "
diff --git a/pandas/json.py b/pandas/json.py
new file mode 100644
index 000000000..5b1e395fa
--- /dev/null
+++ b/pandas/json.py
@@ -0,0 +1,7 @@
+# flake8: noqa
+
+import warnings
+warnings.warn("The pandas.json module is deprecated and will be "
+              "removed in a future version. Please import from "
+              "the pandas.io.json instead", FutureWarning, stacklevel=2)
+from pandas.io.json.libjson import dumps, loads
diff --git a/pandas/lib.py b/pandas/lib.py
new file mode 100644
index 000000000..6c26627a9
--- /dev/null
+++ b/pandas/lib.py
@@ -0,0 +1,7 @@
+# flake8: noqa
+
+import warnings
+warnings.warn("The pandas.lib module is deprecated and will be "
+              "removed in a future version. Please import from "
+              "the pandas._libs.lib instead", FutureWarning, stacklevel=2)
+from pandas._libs.lib import *
diff --git a/pandas/parser.py b/pandas/parser.py
new file mode 100644
index 000000000..af203c3df
--- /dev/null
+++ b/pandas/parser.py
@@ -0,0 +1,8 @@
+# flake8: noqa
+
+import warnings
+warnings.warn("The pandas.parser module is deprecated and will be "
+              "removed in a future version. Please import from "
+              "the pandas.io.parser instead", FutureWarning, stacklevel=2)
+from pandas.io.libparsers import na_values
+from pandas.io.common import CParserError
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index c65e0dd5c..762b6d869 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -25,9 +25,9 @@ from pandas.types.cast import (_possibly_convert_platform, _maybe_promote,
                                _astype_nansafe, _find_common_type)
 from pandas.types.missing import isnull, notnull, na_value_for_dtype
 
-from pandas._sparse import SparseIndex, BlockIndex, IntIndex
-import pandas._sparse as splib
-import pandas.index as _index
+from pandas.sparse import libsparse as splib
+from pandas.sparse.libsparse import SparseIndex, BlockIndex, IntIndex
+from pandas._libs import index as libindex
 import pandas.core.algorithms as algos
 import pandas.core.ops as ops
 import pandas.formats.printing as printing
@@ -447,7 +447,7 @@ class SparseArray(PandasObject, np.ndarray):
         if sp_loc == -1:
             return self.fill_value
         else:
-            return _index.get_value_at(self, sp_loc)
+            return libindex.get_value_at(self, sp_loc)
 
     @Appender(_index_shared_docs['take'] % _sparray_doc_kwargs)
     def take(self, indices, axis=0, allow_fill=True,
diff --git a/pandas/sparse/list.py b/pandas/sparse/list.py
index d294e65bb..54ebf5e51 100644
--- a/pandas/sparse/list.py
+++ b/pandas/sparse/list.py
@@ -6,7 +6,7 @@ from pandas.formats.printing import pprint_thing
 from pandas.types.common import is_scalar
 from pandas.sparse.array import SparseArray
 from pandas.util.validators import validate_bool_kwarg
-import pandas._sparse as splib
+import pandas.sparse.libsparse as splib
 
 
 class SparseList(PandasObject):
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index c3dd089e8..7ec42f02c 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -20,13 +20,13 @@ from pandas.core.internals import SingleBlockManager
 from pandas.core import generic
 import pandas.core.common as com
 import pandas.core.ops as ops
-import pandas.index as _index
+import pandas._libs.index as _index
 from pandas.util.decorators import Appender
 
 from pandas.sparse.array import (make_sparse, _sparse_array_op, SparseArray,
                                  _make_index)
-from pandas._sparse import BlockIndex, IntIndex
-import pandas._sparse as splib
+from pandas.sparse.libsparse import BlockIndex, IntIndex
+import pandas.sparse.libsparse as splib
 
 from pandas.sparse.scipy_sparse import (_sparse_series_to_coo,
                                         _coo_to_sparse_series)
diff --git a/pandas/src/sparse.pyx b/pandas/sparse/sparse.pyx
similarity index 100%
rename from pandas/src/sparse.pyx
rename to pandas/sparse/sparse.pyx
diff --git a/pandas/src/sparse_op_helper.pxi.in b/pandas/sparse/sparse_op_helper.pxi.in
similarity index 100%
rename from pandas/src/sparse_op_helper.pxi.in
rename to pandas/sparse/sparse_op_helper.pxi.in
diff --git a/pandas/tests/api/test_api.py b/pandas/tests/api/test_api.py
index 2f8ebc4cc..db9221047 100644
--- a/pandas/tests/api/test_api.py
+++ b/pandas/tests/api/test_api.py
@@ -1,5 +1,6 @@
 # -*- coding: utf-8 -*-
 
+from warnings import catch_warnings
 import numpy as np
 
 import pandas as pd
@@ -33,16 +34,12 @@ class TestPDApi(Base, tm.TestCase):
     # top-level sub-packages
     lib = ['api', 'compat', 'computation', 'core',
            'indexes', 'formats', 'pandas',
-           'test', 'tools', 'tseries',
+           'test', 'tools', 'tseries', 'sparse',
            'types', 'util', 'options', 'io']
 
-    # top-level packages that are c-imports, should rename to _*
-    # to avoid naming conflicts
-    lib_to_rename = ['algos', 'hashtable', 'tslib', 'msgpack', 'sparse',
-                     'json', 'lib', 'index', 'parser']
-
     # these are already deprecated; awaiting removal
-    deprecated_modules = ['stats', 'datetools']
+    deprecated_modules = ['stats', 'datetools', 'parser',
+                          'json', 'lib', 'tslib']
 
     # misc
     misc = ['IndexSlice', 'NaT']
@@ -113,7 +110,7 @@ class TestPDApi(Base, tm.TestCase):
     def test_api(self):
 
         self.check(pd,
-                   self.lib + self.lib_to_rename + self.misc +
+                   self.lib + self.misc +
                    self.modules + self.deprecated_modules +
                    self.classes + self.deprecated_classes +
                    self.deprecated_classes_in_future +
@@ -206,7 +203,7 @@ class TestTypes(Base, tm.TestCase):
             self.assertRaises(AttributeError, lambda: getattr(com, t))
 
 
-class TestDatetools(tm.TestCase):
+class TestDatetoolsDeprecation(tm.TestCase):
 
     def test_deprecation_access_func(self):
         with tm.assert_produces_warning(FutureWarning,
@@ -247,3 +244,36 @@ class TestTopLevelDeprecations(tm.TestCase):
         with tm.assert_produces_warning(FutureWarning,
                                         check_stacklevel=False):
             pd.groupby(pd.Series([1, 2, 3]), [1, 1, 1])
+
+
+class TestJson(tm.TestCase):
+
+    def test_deprecation_access_func(self):
+        with tm.assert_produces_warning(FutureWarning,
+                                        check_stacklevel=False):
+            pd.json.dumps([])
+
+
+class TestParser(tm.TestCase):
+
+    def test_deprecation_access_func(self):
+        with tm.assert_produces_warning(FutureWarning,
+                                        check_stacklevel=False):
+            pd.parser.na_values
+
+
+class TestLib(tm.TestCase):
+
+    def test_deprecation_access_func(self):
+        with tm.assert_produces_warning(FutureWarning,
+                                        check_stacklevel=False):
+            pd.lib.infer_dtype
+
+
+class TestTSLib(tm.TestCase):
+
+    def test_deprecation_access_func(self):
+        # some libraries may be imported before we
+        # test and could show the warning
+        with catch_warnings(record=True):
+            pd.tslib.Timestamp
diff --git a/pandas/tests/computation/test_eval.py b/pandas/tests/computation/test_eval.py
index b42f79fe5..ed6006440 100644
--- a/pandas/tests/computation/test_eval.py
+++ b/pandas/tests/computation/test_eval.py
@@ -28,7 +28,7 @@ from pandas.computation.ops import (_binary_ops_dict,
 
 import pandas.computation.expr as expr
 import pandas.util.testing as tm
-import pandas.lib as lib
+import pandas._libs.lib as lib
 from pandas.util.testing import (assert_frame_equal, randbool,
                                  assertRaisesRegexp, assert_numpy_array_equal,
                                  assert_produces_warning, assert_series_equal,
diff --git a/pandas/tests/frame/test_constructors.py b/pandas/tests/frame/test_constructors.py
index 76eb61bd8..ba7e45d7e 100644
--- a/pandas/tests/frame/test_constructors.py
+++ b/pandas/tests/frame/test_constructors.py
@@ -23,7 +23,7 @@ from pandas import (DataFrame, Index, Series, isnull,
 from pandas.core.common import PandasError
 import pandas as pd
 import pandas.core.common as com
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.util.testing as tm
 
 from pandas.tests.frame.common import TestData
diff --git a/pandas/tests/frame/test_indexing.py b/pandas/tests/frame/test_indexing.py
index 36c39ffba..f0dfc4553 100644
--- a/pandas/tests/frame/test_indexing.py
+++ b/pandas/tests/frame/test_indexing.py
@@ -18,6 +18,7 @@ from pandas import (DataFrame, Index, Series, notnull, isnull,
                     date_range)
 import pandas as pd
 
+from pandas._libs.tslib import iNaT
 from pandas.tseries.offsets import BDay
 from pandas.types.common import (is_float_dtype,
                                  is_integer,
@@ -1491,8 +1492,7 @@ class TestDataFrameIndexing(tm.TestCase, TestData):
         assert_series_equal(result, expected)
 
         # set an allowable datetime64 type
-        from pandas import tslib
-        df.loc['b', 'timestamp'] = tslib.iNaT
+        df.loc['b', 'timestamp'] = iNaT
         self.assertTrue(isnull(df.loc['b', 'timestamp']))
 
         # allow this syntax
diff --git a/pandas/tests/frame/test_to_csv.py b/pandas/tests/frame/test_to_csv.py
index 471fc536a..e49dfffc4 100644
--- a/pandas/tests/frame/test_to_csv.py
+++ b/pandas/tests/frame/test_to_csv.py
@@ -8,7 +8,7 @@ from numpy import nan
 import numpy as np
 
 from pandas.compat import (lmap, range, lrange, StringIO, u)
-from pandas.parser import ParserError
+from pandas.io.common import ParserError
 from pandas import (DataFrame, Index, Series, MultiIndex, Timestamp,
                     date_range, read_csv, compat, to_datetime)
 import pandas as pd
diff --git a/pandas/tests/groupby/test_bin_groupby.py b/pandas/tests/groupby/test_bin_groupby.py
index 51a10f414..77c5bde33 100644
--- a/pandas/tests/groupby/test_bin_groupby.py
+++ b/pandas/tests/groupby/test_bin_groupby.py
@@ -7,8 +7,8 @@ from pandas.types.common import _ensure_int64
 from pandas import Index, isnull
 from pandas.util.testing import assert_almost_equal
 import pandas.util.testing as tm
-import pandas.lib as lib
-import pandas.algos as algos
+import pandas._libs.lib as lib
+import pandas._libs.algos as algos
 
 
 def test_series_grouper():
diff --git a/pandas/tests/groupby/test_transform.py b/pandas/tests/groupby/test_transform.py
index 2d21eab58..4acf9dd47 100644
--- a/pandas/tests/groupby/test_transform.py
+++ b/pandas/tests/groupby/test_transform.py
@@ -6,6 +6,7 @@ from pandas.util import testing as tm
 from pandas import Series, DataFrame, Timestamp, MultiIndex, concat, date_range
 from pandas.types.common import _ensure_platform_int, is_timedelta64_dtype
 from pandas.compat import StringIO
+from pandas._libs import algos
 from .common import MixIn, assert_fp_equal
 
 from pandas.util.testing import assert_frame_equal, assert_series_equal
@@ -417,8 +418,8 @@ class TestGroupBy(MixIn, tm.TestCase):
         dtypes = [np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint32,
                   np.uint64, np.float32, np.float64]
 
-        ops = [(pd.algos.group_cumprod_float64, np.cumproduct, [np.float64]),
-               (pd.algos.group_cumsum, np.cumsum, dtypes)]
+        ops = [(algos.group_cumprod_float64, np.cumproduct, [np.float64]),
+               (algos.group_cumsum, np.cumsum, dtypes)]
 
         is_datetimelike = False
         for pd_op, np_op, dtypes in ops:
@@ -436,13 +437,13 @@ class TestGroupBy(MixIn, tm.TestCase):
         data = np.array([[1], [2], [3], [np.nan], [4]], dtype='float64')
         actual = np.zeros_like(data)
         actual.fill(np.nan)
-        pd.algos.group_cumprod_float64(actual, data, labels, is_datetimelike)
+        algos.group_cumprod_float64(actual, data, labels, is_datetimelike)
         expected = np.array([1, 2, 6, np.nan, 24], dtype='float64')
         self.assert_numpy_array_equal(actual[:, 0], expected)
 
         actual = np.zeros_like(data)
         actual.fill(np.nan)
-        pd.algos.group_cumsum(actual, data, labels, is_datetimelike)
+        algos.group_cumsum(actual, data, labels, is_datetimelike)
         expected = np.array([1, 3, 6, np.nan, 10], dtype='float64')
         self.assert_numpy_array_equal(actual[:, 0], expected)
 
@@ -450,8 +451,8 @@ class TestGroupBy(MixIn, tm.TestCase):
         is_datetimelike = True
         data = np.array([np.timedelta64(1, 'ns')] * 5, dtype='m8[ns]')[:, None]
         actual = np.zeros_like(data, dtype='int64')
-        pd.algos.group_cumsum(actual, data.view('int64'), labels,
-                              is_datetimelike)
+        algos.group_cumsum(actual, data.view('int64'), labels,
+                           is_datetimelike)
         expected = np.array([np.timedelta64(1, 'ns'), np.timedelta64(
             2, 'ns'), np.timedelta64(3, 'ns'), np.timedelta64(4, 'ns'),
             np.timedelta64(5, 'ns')])
diff --git a/pandas/tests/indexes/common.py b/pandas/tests/indexes/common.py
index 7b39a3326..3581f894e 100644
--- a/pandas/tests/indexes/common.py
+++ b/pandas/tests/indexes/common.py
@@ -10,6 +10,7 @@ from pandas import (Series, Index, Float64Index, Int64Index, UInt64Index,
                     TimedeltaIndex, PeriodIndex, notnull, isnull)
 from pandas.types.common import needs_i8_conversion
 from pandas.util.testing import assertRaisesRegexp
+from pandas._libs.tslib import iNaT
 
 import pandas.util.testing as tm
 
@@ -322,7 +323,7 @@ class Base(object):
 
             if needs_i8_conversion(ind):
                 vals = ind.asi8[[0] * 5]
-                vals[0] = pd.tslib.iNaT
+                vals[0] = iNaT
             else:
                 vals = ind.values[[0] * 5]
                 vals[0] = np.nan
@@ -407,7 +408,7 @@ class Base(object):
             # pandas compatibility input validation - the
             # rest already perform separate (or no) such
             # validation via their 'values' attribute as
-            # defined in pandas/indexes/base.py - they
+            # defined in pandas.indexes/base.py - they
             # cannot be changed at the moment due to
             # backwards compatibility concerns
             if isinstance(type(ind), (CategoricalIndex, RangeIndex)):
@@ -836,7 +837,7 @@ class Base(object):
                 if len(index) == 0:
                     continue
                 elif isinstance(index, pd.tseries.base.DatetimeIndexOpsMixin):
-                    values[1] = pd.tslib.iNaT
+                    values[1] = iNaT
                 elif isinstance(index, (Int64Index, UInt64Index)):
                     continue
                 else:
@@ -876,7 +877,7 @@ class Base(object):
                 values = idx.values
 
                 if isinstance(index, pd.tseries.base.DatetimeIndexOpsMixin):
-                    values[1] = pd.tslib.iNaT
+                    values[1] = iNaT
                 elif isinstance(index, (Int64Index, UInt64Index)):
                     continue
                 else:
diff --git a/pandas/tests/indexes/datetimes/test_construction.py b/pandas/tests/indexes/datetimes/test_construction.py
index 772d76305..16881de6e 100644
--- a/pandas/tests/indexes/datetimes/test_construction.py
+++ b/pandas/tests/indexes/datetimes/test_construction.py
@@ -2,9 +2,10 @@ import numpy as np
 from datetime import timedelta
 
 import pandas as pd
-from pandas import tslib, offsets, lib
+from pandas import offsets
 import pandas.util.testing as tm
-from pandas.tslib import OutOfBoundsDatetime
+from pandas._libs import tslib, lib
+from pandas._libs.tslib import OutOfBoundsDatetime
 from pandas import (DatetimeIndex, Index, Timestamp, datetime, date_range,
                     to_datetime)
 
diff --git a/pandas/tests/indexes/datetimes/test_date_range.py b/pandas/tests/indexes/datetimes/test_date_range.py
index 80664ce24..67e82e5c7 100644
--- a/pandas/tests/indexes/datetimes/test_date_range.py
+++ b/pandas/tests/indexes/datetimes/test_date_range.py
@@ -350,7 +350,7 @@ class TestBusinessDateRange(tm.TestCase):
         # GH 2906
         tm._skip_if_no_dateutil()
         # Use maybe_get_tz to fix filename in tz under dateutil.
-        from pandas.tslib import maybe_get_tz
+        from pandas._libs.tslib import maybe_get_tz
         tz = lambda x: maybe_get_tz('dateutil/' + x)
 
         start = datetime(2011, 1, 1, tzinfo=tz('US/Eastern'))
diff --git a/pandas/tests/indexes/datetimes/test_datetime.py b/pandas/tests/indexes/datetimes/test_datetime.py
index 2c87c48bc..78c37f773 100644
--- a/pandas/tests/indexes/datetimes/test_datetime.py
+++ b/pandas/tests/indexes/datetimes/test_datetime.py
@@ -117,7 +117,7 @@ class TestDatetimeIndex(tm.TestCase):
 
     def test_time_loc(self):  # GH8667
         from datetime import time
-        from pandas.index import _SIZE_CUTOFF
+        from pandas._libs.index import _SIZE_CUTOFF
 
         ns = _SIZE_CUTOFF + np.array([-100, 100], dtype=np.int64)
         key = time(15, 11, 30)
diff --git a/pandas/tests/indexes/datetimes/test_ops.py b/pandas/tests/indexes/datetimes/test_ops.py
index 312017eef..4abc28225 100644
--- a/pandas/tests/indexes/datetimes/test_ops.py
+++ b/pandas/tests/indexes/datetimes/test_ops.py
@@ -5,7 +5,7 @@ from datetime import timedelta
 
 from itertools import product
 import pandas as pd
-import pandas.tslib as tslib
+import pandas._libs.tslib as tslib
 import pandas.util.testing as tm
 from pandas.core.common import PerformanceWarning
 from pandas.tseries.index import cdate_range
diff --git a/pandas/tests/indexes/datetimes/test_setops.py b/pandas/tests/indexes/datetimes/test_setops.py
index 8d05a4016..a1ad147f8 100644
--- a/pandas/tests/indexes/datetimes/test_setops.py
+++ b/pandas/tests/indexes/datetimes/test_setops.py
@@ -326,7 +326,7 @@ class TestBusinessDatetimeIndex(tm.TestCase):
     def test_month_range_union_tz_dateutil(self):
         tm._skip_if_windows_python_3()
         tm._skip_if_no_dateutil()
-        from pandas.tslib import _dateutil_gettz as timezone
+        from pandas._libs.tslib import _dateutil_gettz as timezone
         tz = timezone('US/Eastern')
 
         early_start = datetime(2011, 1, 1)
diff --git a/pandas/tests/indexes/datetimes/test_tools.py b/pandas/tests/indexes/datetimes/test_tools.py
index 1b67ffce6..512a3e1c3 100644
--- a/pandas/tests/indexes/datetimes/test_tools.py
+++ b/pandas/tests/indexes/datetimes/test_tools.py
@@ -9,7 +9,7 @@ from datetime import datetime, date, time
 from distutils.version import LooseVersion
 
 import pandas as pd
-from pandas import tslib
+from pandas._libs import tslib, lib
 from pandas.tseries import tools
 from pandas.tseries.tools import normalize_date
 from pandas.compat import lmap
@@ -19,7 +19,7 @@ from pandas.util import testing as tm
 from pandas.util.testing import assert_series_equal, _skip_if_has_locale
 from pandas import (isnull, to_datetime, Timestamp, Series, DataFrame,
                     Index, DatetimeIndex, NaT, date_range, bdate_range,
-                    compat, lib)
+                    compat)
 
 
 class TimeConversionFormats(tm.TestCase):
diff --git a/pandas/tests/indexes/period/test_indexing.py b/pandas/tests/indexes/period/test_indexing.py
index 8d9e26406..ff83b50a2 100644
--- a/pandas/tests/indexes/period/test_indexing.py
+++ b/pandas/tests/indexes/period/test_indexing.py
@@ -4,8 +4,9 @@ import numpy as np
 import pandas as pd
 from pandas.util import testing as tm
 from pandas.compat import lrange
+from pandas._libs import tslib
 from pandas import (PeriodIndex, Series, DatetimeIndex,
-                    period_range, Period, tslib, _np_version_under1p9)
+                    period_range, Period, _np_version_under1p9)
 
 
 class TestGetItem(tm.TestCase):
diff --git a/pandas/tests/indexes/period/test_ops.py b/pandas/tests/indexes/period/test_ops.py
index 82a881d7c..4533428cf 100644
--- a/pandas/tests/indexes/period/test_ops.py
+++ b/pandas/tests/indexes/period/test_ops.py
@@ -2,7 +2,7 @@ import numpy as np
 from datetime import timedelta
 
 import pandas as pd
-import pandas.tslib as tslib
+import pandas._libs.tslib as tslib
 import pandas.util.testing as tm
 import pandas.tseries.period as period
 from pandas import (DatetimeIndex, PeriodIndex, period_range, Series, Period,
diff --git a/pandas/tests/indexes/period/test_tools.py b/pandas/tests/indexes/period/test_tools.py
index e09d405af..f9a1df3d8 100644
--- a/pandas/tests/indexes/period/test_tools.py
+++ b/pandas/tests/indexes/period/test_tools.py
@@ -6,7 +6,7 @@ import pandas.util.testing as tm
 import pandas.tseries.period as period
 from pandas.compat import lrange
 from pandas.tseries.frequencies import get_freq, MONTHS
-from pandas._period import period_ordinal, period_asfreq
+from pandas._libs.period import period_ordinal, period_asfreq
 from pandas import (PeriodIndex, Period, DatetimeIndex, Timestamp, Series,
                     date_range, to_datetime, period_range)
 
diff --git a/pandas/tests/indexes/test_base.py b/pandas/tests/indexes/test_base.py
index 79d10cbda..8c0a399cb 100644
--- a/pandas/tests/indexes/test_base.py
+++ b/pandas/tests/indexes/test_base.py
@@ -24,7 +24,7 @@ import pandas.core.config as cf
 from pandas.tseries.index import _to_m8
 
 import pandas as pd
-from pandas.lib import Timestamp
+from pandas._libs.lib import Timestamp
 
 
 class TestIndex(Base, tm.TestCase):
diff --git a/pandas/tests/indexes/test_multi.py b/pandas/tests/indexes/test_multi.py
index 80ff67ab3..f67231e78 100644
--- a/pandas/tests/indexes/test_multi.py
+++ b/pandas/tests/indexes/test_multi.py
@@ -17,7 +17,8 @@ from pandas import (CategoricalIndex, DataFrame, Index, MultiIndex,
 from pandas.compat import PY3, long, lrange, lzip, range, u
 from pandas.core.common import PerformanceWarning, UnsortedIndexError
 from pandas.indexes.base import InvalidIndexError
-from pandas.lib import Timestamp
+from pandas._libs import lib
+from pandas._libs.lib import Timestamp
 
 import pandas.util.testing as tm
 
@@ -851,7 +852,7 @@ class TestMultiIndex(Base, tm.TestCase):
     def test_from_product_datetimeindex(self):
         dt_index = date_range('2000-01-01', periods=2)
         mi = pd.MultiIndex.from_product([[1, 2], dt_index])
-        etalon = pd.lib.list_to_object_array([(1, pd.Timestamp(
+        etalon = lib.list_to_object_array([(1, pd.Timestamp(
             '2000-01-01')), (1, pd.Timestamp('2000-01-02')), (2, pd.Timestamp(
                 '2000-01-01')), (2, pd.Timestamp('2000-01-02'))])
         tm.assert_numpy_array_equal(mi.values, etalon)
@@ -878,7 +879,7 @@ class TestMultiIndex(Base, tm.TestCase):
                   (3, pd.Timestamp('2000-01-03'))]
         mi = pd.MultiIndex.from_tuples(tuples)
         tm.assert_numpy_array_equal(mi.values,
-                                    pd.lib.list_to_object_array(tuples))
+                                    lib.list_to_object_array(tuples))
         # Check that code branches for boxed values produce identical results
         tm.assert_numpy_array_equal(mi.values[:4], mi[:4].values)
 
@@ -2181,7 +2182,7 @@ class TestMultiIndex(Base, tm.TestCase):
 
         for keep in ['first', 'last', False]:
             left = mi.duplicated(keep=keep)
-            right = pd.hashtable.duplicated_object(mi.values, keep=keep)
+            right = pd._libs.hashtable.duplicated_object(mi.values, keep=keep)
             tm.assert_numpy_array_equal(left, right)
 
         # GH5873
diff --git a/pandas/tests/indexes/test_numeric.py b/pandas/tests/indexes/test_numeric.py
index 1bf9a1062..e23e7c19e 100644
--- a/pandas/tests/indexes/test_numeric.py
+++ b/pandas/tests/indexes/test_numeric.py
@@ -11,7 +11,7 @@ from pandas import (date_range, Series, Index, Float64Index,
 import pandas.util.testing as tm
 
 import pandas as pd
-from pandas.lib import Timestamp
+from pandas._libs.lib import Timestamp
 
 from pandas.tests.indexes.common import Base
 
diff --git a/pandas/tests/indexes/timedeltas/test_construction.py b/pandas/tests/indexes/timedeltas/test_construction.py
index 0810b13eb..9a3dd1c6b 100644
--- a/pandas/tests/indexes/timedeltas/test_construction.py
+++ b/pandas/tests/indexes/timedeltas/test_construction.py
@@ -3,9 +3,7 @@ from datetime import timedelta
 
 import pandas as pd
 import pandas.util.testing as tm
-from pandas import TimedeltaIndex, timedelta_range, tslib, to_timedelta
-
-iNaT = tslib.iNaT
+from pandas import TimedeltaIndex, timedelta_range, to_timedelta
 
 
 class TestTimedeltaIndex(tm.TestCase):
diff --git a/pandas/tests/indexes/timedeltas/test_ops.py b/pandas/tests/indexes/timedeltas/test_ops.py
index 406a5bdbf..8c7b88a9c 100644
--- a/pandas/tests/indexes/timedeltas/test_ops.py
+++ b/pandas/tests/indexes/timedeltas/test_ops.py
@@ -8,8 +8,8 @@ from pandas import to_timedelta
 from pandas.util.testing import assert_series_equal, assert_frame_equal
 from pandas import (Series, Timedelta, DataFrame, Timestamp, TimedeltaIndex,
                     timedelta_range, date_range, DatetimeIndex, Int64Index,
-                    _np_version_under1p10, Float64Index, Index, tslib)
-
+                    _np_version_under1p10, Float64Index, Index)
+from pandas._libs.tslib import iNaT
 from pandas.tests.test_base import Ops
 
 
@@ -772,7 +772,7 @@ Freq: D"""
         tm.assert_index_equal(result, exp)
 
         result = idx._nat_new(box=False)
-        exp = np.array([tslib.iNaT] * 5, dtype=np.int64)
+        exp = np.array([iNaT] * 5, dtype=np.int64)
         tm.assert_numpy_array_equal(result, exp)
 
     def test_shift(self):
diff --git a/pandas/tests/indexes/timedeltas/test_tools.py b/pandas/tests/indexes/timedeltas/test_tools.py
index 244205154..ade9366c7 100644
--- a/pandas/tests/indexes/timedeltas/test_tools.py
+++ b/pandas/tests/indexes/timedeltas/test_tools.py
@@ -4,8 +4,9 @@ import numpy as np
 import pandas as pd
 import pandas.util.testing as tm
 from pandas.util.testing import assert_series_equal
-from pandas import (Series, Timedelta, to_timedelta, tslib, isnull,
+from pandas import (Series, Timedelta, to_timedelta, isnull,
                     TimedeltaIndex)
+from pandas._libs.tslib import iNaT
 
 
 class TestTimedeltas(tm.TestCase):
@@ -26,7 +27,7 @@ class TestTimedeltas(tm.TestCase):
 
         # empty string
         result = to_timedelta('', box=False)
-        self.assertEqual(result.astype('int64'), tslib.iNaT)
+        self.assertEqual(result.astype('int64'), iNaT)
 
         result = to_timedelta(['', ''])
         self.assertTrue(isnull(result).all())
diff --git a/pandas/tests/indexing/test_indexing.py b/pandas/tests/indexing/test_indexing.py
index f7a4af711..4502e0171 100644
--- a/pandas/tests/indexing/test_indexing.py
+++ b/pandas/tests/indexing/test_indexing.py
@@ -9,7 +9,7 @@ from pandas.types.common import (is_integer_dtype,
                                  is_float_dtype,
                                  is_scalar)
 from pandas.compat import range, lrange, lzip, StringIO, lmap
-from pandas.tslib import NaT
+from pandas._libs.tslib import NaT
 from numpy import nan
 from numpy.random import randn
 import numpy as np
diff --git a/pandas/tests/io/json/test_pandas.py b/pandas/tests/io/json/test_pandas.py
index c298b3841..7dbcf25c6 100644
--- a/pandas/tests/io/json/test_pandas.py
+++ b/pandas/tests/io/json/test_pandas.py
@@ -637,13 +637,14 @@ class TestPandasContainer(tm.TestCase):
 
     def test_convert_dates_infer(self):
         # GH10747
+        from pandas.io.json import dumps
         infer_words = ['trade_time', 'date', 'datetime', 'sold_at',
                        'modified', 'timestamp', 'timestamps']
         for infer_word in infer_words:
             data = [{'id': 1, infer_word: 1036713600000}, {'id': 2}]
             expected = DataFrame([[1, Timestamp('2002-11-08')], [2, pd.NaT]],
                                  columns=['id', infer_word])
-            result = read_json(pd.json.dumps(data))[['id', infer_word]]
+            result = read_json(dumps(data))[['id', infer_word]]
             assert_frame_equal(result, expected)
 
     def test_date_format_frame(self):
@@ -910,50 +911,53 @@ DataFrame\\.index values are different \\(100\\.0 %\\)
         self.assertEqual(expected, ss.to_json())
 
     def test_tz_is_utc(self):
+        from pandas.io.json import dumps
         exp = '"2013-01-10T05:00:00.000Z"'
 
         ts = Timestamp('2013-01-10 05:00:00Z')
-        self.assertEqual(exp, pd.json.dumps(ts, iso_dates=True))
+        self.assertEqual(exp, dumps(ts, iso_dates=True))
         dt = ts.to_pydatetime()
-        self.assertEqual(exp, pd.json.dumps(dt, iso_dates=True))
+        self.assertEqual(exp, dumps(dt, iso_dates=True))
 
         ts = Timestamp('2013-01-10 00:00:00', tz='US/Eastern')
-        self.assertEqual(exp, pd.json.dumps(ts, iso_dates=True))
+        self.assertEqual(exp, dumps(ts, iso_dates=True))
         dt = ts.to_pydatetime()
-        self.assertEqual(exp, pd.json.dumps(dt, iso_dates=True))
+        self.assertEqual(exp, dumps(dt, iso_dates=True))
 
         ts = Timestamp('2013-01-10 00:00:00-0500')
-        self.assertEqual(exp, pd.json.dumps(ts, iso_dates=True))
+        self.assertEqual(exp, dumps(ts, iso_dates=True))
         dt = ts.to_pydatetime()
-        self.assertEqual(exp, pd.json.dumps(dt, iso_dates=True))
+        self.assertEqual(exp, dumps(dt, iso_dates=True))
 
     def test_tz_range_is_utc(self):
+        from pandas.io.json import dumps
+
         exp = '["2013-01-01T05:00:00.000Z","2013-01-02T05:00:00.000Z"]'
         dfexp = ('{"DT":{'
                  '"0":"2013-01-01T05:00:00.000Z",'
                  '"1":"2013-01-02T05:00:00.000Z"}}')
 
         tz_range = pd.date_range('2013-01-01 05:00:00Z', periods=2)
-        self.assertEqual(exp, pd.json.dumps(tz_range, iso_dates=True))
+        self.assertEqual(exp, dumps(tz_range, iso_dates=True))
         dti = pd.DatetimeIndex(tz_range)
-        self.assertEqual(exp, pd.json.dumps(dti, iso_dates=True))
+        self.assertEqual(exp, dumps(dti, iso_dates=True))
         df = DataFrame({'DT': dti})
-        self.assertEqual(dfexp, pd.json.dumps(df, iso_dates=True))
+        self.assertEqual(dfexp, dumps(df, iso_dates=True))
 
         tz_range = pd.date_range('2013-01-01 00:00:00', periods=2,
                                  tz='US/Eastern')
-        self.assertEqual(exp, pd.json.dumps(tz_range, iso_dates=True))
+        self.assertEqual(exp, dumps(tz_range, iso_dates=True))
         dti = pd.DatetimeIndex(tz_range)
-        self.assertEqual(exp, pd.json.dumps(dti, iso_dates=True))
+        self.assertEqual(exp, dumps(dti, iso_dates=True))
         df = DataFrame({'DT': dti})
-        self.assertEqual(dfexp, pd.json.dumps(df, iso_dates=True))
+        self.assertEqual(dfexp, dumps(df, iso_dates=True))
 
         tz_range = pd.date_range('2013-01-01 00:00:00-0500', periods=2)
-        self.assertEqual(exp, pd.json.dumps(tz_range, iso_dates=True))
+        self.assertEqual(exp, dumps(tz_range, iso_dates=True))
         dti = pd.DatetimeIndex(tz_range)
-        self.assertEqual(exp, pd.json.dumps(dti, iso_dates=True))
+        self.assertEqual(exp, dumps(dti, iso_dates=True))
         df = DataFrame({'DT': dti})
-        self.assertEqual(dfexp, pd.json.dumps(df, iso_dates=True))
+        self.assertEqual(dfexp, dumps(df, iso_dates=True))
 
     def test_read_jsonl(self):
         # GH9180
diff --git a/pandas/tests/io/json/test_ujson.py b/pandas/tests/io/json/test_ujson.py
index 6a986710a..e66721bee 100644
--- a/pandas/tests/io/json/test_ujson.py
+++ b/pandas/tests/io/json/test_ujson.py
@@ -17,7 +17,7 @@ import re
 import decimal
 from functools import partial
 from pandas.compat import range, zip, StringIO, u
-import pandas.json as ujson
+import pandas.io.json.libjson as ujson
 import pandas.compat as compat
 
 import numpy as np
@@ -400,7 +400,7 @@ class UltraJSONTests(TestCase):
         assert ujson.encode(input) == 'null', "Expected null"
 
     def test_datetime_units(self):
-        from pandas.lib import Timestamp
+        from pandas._libs.lib import Timestamp
 
         val = datetime.datetime(2013, 8, 17, 21, 17, 12, 215504)
         stamp = Timestamp(val)
diff --git a/pandas/tests/msgpack/__init__.py b/pandas/tests/io/msgpack/__init__.py
similarity index 100%
rename from pandas/tests/msgpack/__init__.py
rename to pandas/tests/io/msgpack/__init__.py
diff --git a/pandas/tests/msgpack/test_buffer.py b/pandas/tests/io/msgpack/test_buffer.py
similarity index 90%
rename from pandas/tests/msgpack/test_buffer.py
rename to pandas/tests/io/msgpack/test_buffer.py
index caaa22bfd..5a2dc3dba 100644
--- a/pandas/tests/msgpack/test_buffer.py
+++ b/pandas/tests/io/msgpack/test_buffer.py
@@ -1,6 +1,6 @@
 # coding: utf-8
 
-from pandas.msgpack import packb, unpackb
+from pandas.io.msgpack import packb, unpackb
 
 
 def test_unpack_buffer():
diff --git a/pandas/tests/msgpack/test_case.py b/pandas/tests/io/msgpack/test_case.py
similarity index 98%
rename from pandas/tests/msgpack/test_case.py
rename to pandas/tests/io/msgpack/test_case.py
index a8a45b5b3..3927693a9 100644
--- a/pandas/tests/msgpack/test_case.py
+++ b/pandas/tests/io/msgpack/test_case.py
@@ -1,6 +1,6 @@
 # coding: utf-8
 
-from pandas.msgpack import packb, unpackb
+from pandas.io.msgpack import packb, unpackb
 
 
 def check(length, obj):
diff --git a/pandas/tests/msgpack/test_except.py b/pandas/tests/io/msgpack/test_except.py
similarity index 96%
rename from pandas/tests/msgpack/test_except.py
rename to pandas/tests/io/msgpack/test_except.py
index 76b91bb37..4bcef3607 100644
--- a/pandas/tests/msgpack/test_except.py
+++ b/pandas/tests/io/msgpack/test_except.py
@@ -1,7 +1,7 @@
 # coding: utf-8
 
 import unittest
-from pandas.msgpack import packb, unpackb
+from pandas.io.msgpack import packb, unpackb
 
 
 class DummyException(Exception):
diff --git a/pandas/tests/msgpack/test_extension.py b/pandas/tests/io/msgpack/test_extension.py
similarity index 96%
rename from pandas/tests/msgpack/test_extension.py
rename to pandas/tests/io/msgpack/test_extension.py
index 97f0962a7..a5a111efb 100644
--- a/pandas/tests/msgpack/test_extension.py
+++ b/pandas/tests/io/msgpack/test_extension.py
@@ -1,7 +1,7 @@
 from __future__ import print_function
 import array
-import pandas.msgpack as msgpack
-from pandas.msgpack import ExtType
+import pandas.io.msgpack as msgpack
+from pandas.io.msgpack import ExtType
 
 
 def test_pack_ext_type():
diff --git a/pandas/tests/msgpack/test_format.py b/pandas/tests/io/msgpack/test_format.py
similarity index 98%
rename from pandas/tests/msgpack/test_format.py
rename to pandas/tests/io/msgpack/test_format.py
index a4b309ebb..3659602e1 100644
--- a/pandas/tests/msgpack/test_format.py
+++ b/pandas/tests/io/msgpack/test_format.py
@@ -1,6 +1,6 @@
 # coding: utf-8
 
-from pandas.msgpack import unpackb
+from pandas.io.msgpack import unpackb
 
 
 def check(src, should, use_list=0):
diff --git a/pandas/tests/msgpack/test_limits.py b/pandas/tests/io/msgpack/test_limits.py
similarity index 97%
rename from pandas/tests/msgpack/test_limits.py
rename to pandas/tests/io/msgpack/test_limits.py
index 9c08f328b..a908ee354 100644
--- a/pandas/tests/msgpack/test_limits.py
+++ b/pandas/tests/io/msgpack/test_limits.py
@@ -3,7 +3,7 @@ from __future__ import (absolute_import, division, print_function,
                         unicode_literals)
 import pandas.util.testing as tm
 
-from pandas.msgpack import packb, unpackb, Packer, Unpacker, ExtType
+from pandas.io.msgpack import packb, unpackb, Packer, Unpacker, ExtType
 
 
 class TestLimits(tm.TestCase):
diff --git a/pandas/tests/msgpack/test_newspec.py b/pandas/tests/io/msgpack/test_newspec.py
similarity index 97%
rename from pandas/tests/msgpack/test_newspec.py
rename to pandas/tests/io/msgpack/test_newspec.py
index 4eb9a0425..783bfc1b3 100644
--- a/pandas/tests/msgpack/test_newspec.py
+++ b/pandas/tests/io/msgpack/test_newspec.py
@@ -1,6 +1,6 @@
 # coding: utf-8
 
-from pandas.msgpack import packb, unpackb, ExtType
+from pandas.io.msgpack import packb, unpackb, ExtType
 
 
 def test_str8():
diff --git a/pandas/tests/msgpack/test_obj.py b/pandas/tests/io/msgpack/test_obj.py
similarity index 98%
rename from pandas/tests/msgpack/test_obj.py
rename to pandas/tests/io/msgpack/test_obj.py
index bcc76929f..b067dacb8 100644
--- a/pandas/tests/msgpack/test_obj.py
+++ b/pandas/tests/io/msgpack/test_obj.py
@@ -1,7 +1,7 @@
 # coding: utf-8
 
 import unittest
-from pandas.msgpack import packb, unpackb
+from pandas.io.msgpack import packb, unpackb
 
 
 class DecodeError(Exception):
diff --git a/pandas/tests/msgpack/test_pack.py b/pandas/tests/io/msgpack/test_pack.py
similarity index 98%
rename from pandas/tests/msgpack/test_pack.py
rename to pandas/tests/io/msgpack/test_pack.py
index 005352691..6f9a271cb 100644
--- a/pandas/tests/msgpack/test_pack.py
+++ b/pandas/tests/io/msgpack/test_pack.py
@@ -5,7 +5,7 @@ import unittest
 import struct
 from pandas import compat
 from pandas.compat import u, OrderedDict
-from pandas.msgpack import packb, unpackb, Unpacker, Packer
+from pandas.io.msgpack import packb, unpackb, Unpacker, Packer
 
 
 class TestPack(unittest.TestCase):
diff --git a/pandas/tests/msgpack/test_read_size.py b/pandas/tests/io/msgpack/test_read_size.py
similarity index 96%
rename from pandas/tests/msgpack/test_read_size.py
rename to pandas/tests/io/msgpack/test_read_size.py
index 965e97a70..ef521fa34 100644
--- a/pandas/tests/msgpack/test_read_size.py
+++ b/pandas/tests/io/msgpack/test_read_size.py
@@ -1,5 +1,5 @@
 """Test Unpacker's read_array_header and read_map_header methods"""
-from pandas.msgpack import packb, Unpacker, OutOfData
+from pandas.io.msgpack import packb, Unpacker, OutOfData
 UnexpectedTypeException = ValueError
 
 
diff --git a/pandas/tests/msgpack/test_seq.py b/pandas/tests/io/msgpack/test_seq.py
similarity index 96%
rename from pandas/tests/msgpack/test_seq.py
rename to pandas/tests/io/msgpack/test_seq.py
index 927c26224..5f203e899 100644
--- a/pandas/tests/msgpack/test_seq.py
+++ b/pandas/tests/io/msgpack/test_seq.py
@@ -1,7 +1,7 @@
 # coding: utf-8
 
 import io
-import pandas.msgpack as msgpack
+import pandas.io.msgpack as msgpack
 
 binarydata = bytes(bytearray(range(256)))
 
diff --git a/pandas/tests/msgpack/test_sequnpack.py b/pandas/tests/io/msgpack/test_sequnpack.py
similarity index 97%
rename from pandas/tests/msgpack/test_sequnpack.py
rename to pandas/tests/io/msgpack/test_sequnpack.py
index fe089ccda..c9c979c4e 100644
--- a/pandas/tests/msgpack/test_sequnpack.py
+++ b/pandas/tests/io/msgpack/test_sequnpack.py
@@ -3,8 +3,8 @@
 import unittest
 
 from pandas import compat
-from pandas.msgpack import Unpacker, BufferFull
-from pandas.msgpack import OutOfData
+from pandas.io.msgpack import Unpacker, BufferFull
+from pandas.io.msgpack import OutOfData
 
 
 class TestPack(unittest.TestCase):
diff --git a/pandas/tests/msgpack/test_subtype.py b/pandas/tests/io/msgpack/test_subtype.py
similarity index 90%
rename from pandas/tests/msgpack/test_subtype.py
rename to pandas/tests/io/msgpack/test_subtype.py
index d6dd72c4d..e27ec66c6 100644
--- a/pandas/tests/msgpack/test_subtype.py
+++ b/pandas/tests/io/msgpack/test_subtype.py
@@ -1,6 +1,6 @@
 # coding: utf-8
 
-from pandas.msgpack import packb
+from pandas.io.msgpack import packb
 from collections import namedtuple
 
 
diff --git a/pandas/tests/msgpack/test_unpack.py b/pandas/tests/io/msgpack/test_unpack.py
similarity index 96%
rename from pandas/tests/msgpack/test_unpack.py
rename to pandas/tests/io/msgpack/test_unpack.py
index ae8227ab2..24a8e885d 100644
--- a/pandas/tests/msgpack/test_unpack.py
+++ b/pandas/tests/io/msgpack/test_unpack.py
@@ -1,6 +1,6 @@
 from io import BytesIO
 import sys
-from pandas.msgpack import Unpacker, packb, OutOfData, ExtType
+from pandas.io.msgpack import Unpacker, packb, OutOfData, ExtType
 import pandas.util.testing as tm
 import pytest
 
diff --git a/pandas/tests/msgpack/test_unpack_raw.py b/pandas/tests/io/msgpack/test_unpack_raw.py
similarity index 94%
rename from pandas/tests/msgpack/test_unpack_raw.py
rename to pandas/tests/io/msgpack/test_unpack_raw.py
index c6bf747c8..a261bf4cb 100644
--- a/pandas/tests/msgpack/test_unpack_raw.py
+++ b/pandas/tests/io/msgpack/test_unpack_raw.py
@@ -1,7 +1,7 @@
 """Tests for cases where the user seeks to obtain packed msgpack objects"""
 
 import io
-from pandas.msgpack import Unpacker, packb
+from pandas.io.msgpack import Unpacker, packb
 
 
 def test_write_bytes():
diff --git a/pandas/tests/io/parser/common.py b/pandas/tests/io/parser/common.py
index b667eed34..df75d14e9 100644
--- a/pandas/tests/io/parser/common.py
+++ b/pandas/tests/io/parser/common.py
@@ -11,7 +11,7 @@ from datetime import datetime
 
 import pytest
 import numpy as np
-from pandas.lib import Timestamp
+from pandas._libs.lib import Timestamp
 
 import pandas as pd
 import pandas.util.testing as tm
diff --git a/pandas/tests/io/parser/converters.py b/pandas/tests/io/parser/converters.py
index 859d2e19b..2659d977e 100644
--- a/pandas/tests/io/parser/converters.py
+++ b/pandas/tests/io/parser/converters.py
@@ -13,7 +13,7 @@ import numpy as np
 import pandas as pd
 import pandas.util.testing as tm
 
-from pandas.lib import Timestamp
+from pandas._libs.lib import Timestamp
 from pandas import DataFrame, Index
 from pandas.compat import parse_date, StringIO, lmap
 
diff --git a/pandas/tests/io/parser/parse_dates.py b/pandas/tests/io/parser/parse_dates.py
index b1960159b..4cba9276a 100644
--- a/pandas/tests/io/parser/parse_dates.py
+++ b/pandas/tests/io/parser/parse_dates.py
@@ -10,8 +10,8 @@ from datetime import datetime
 
 import pytest
 import numpy as np
-import pandas.lib as lib
-from pandas.lib import Timestamp
+import pandas._libs.lib as lib
+from pandas._libs.lib import Timestamp
 
 import pandas as pd
 import pandas.io.parsers as parsers
diff --git a/pandas/tests/io/parser/test_textreader.py b/pandas/tests/io/parser/test_textreader.py
index 0e91ca806..b6a9900b0 100644
--- a/pandas/tests/io/parser/test_textreader.py
+++ b/pandas/tests/io/parser/test_textreader.py
@@ -20,8 +20,8 @@ from pandas.util.testing import assert_frame_equal
 
 import pandas.util.testing as tm
 
-from pandas.parser import TextReader
-import pandas.parser as parser
+from pandas.io.libparsers import TextReader
+import pandas.io.libparsers as parser
 
 
 class TestTextReader(tm.TestCase):
diff --git a/pandas/tests/io/parser/usecols.py b/pandas/tests/io/parser/usecols.py
index 95df077da..0cf642983 100644
--- a/pandas/tests/io/parser/usecols.py
+++ b/pandas/tests/io/parser/usecols.py
@@ -11,7 +11,7 @@ import numpy as np
 import pandas.util.testing as tm
 
 from pandas import DataFrame, Index
-from pandas.lib import Timestamp
+from pandas._libs.lib import Timestamp
 from pandas.compat import StringIO
 
 
diff --git a/pandas/tests/io/test_html.py b/pandas/tests/io/test_html.py
index 232e68a87..c1a2a4545 100644
--- a/pandas/tests/io/test_html.py
+++ b/pandas/tests/io/test_html.py
@@ -23,7 +23,7 @@ from pandas.compat import (map, zip, StringIO, string_types, BytesIO,
                            is_platform_windows)
 from pandas.io.common import URLError, urlopen, file_path_to_url
 from pandas.io.html import read_html
-from pandas.parser import ParserError
+from pandas.io.libparsers import ParserError
 
 import pandas.util.testing as tm
 from pandas.util.testing import makeCustomDataframe as mkdf, network
diff --git a/pandas/tests/io/test_packers.py b/pandas/tests/io/test_packers.py
index 251c6ae8b..efa8587d6 100644
--- a/pandas/tests/io/test_packers.py
+++ b/pandas/tests/io/test_packers.py
@@ -22,7 +22,8 @@ from pandas.util.testing import (ensure_clean,
 from pandas.tests.test_panel import assert_panel_equal
 
 import pandas
-from pandas import Timestamp, NaT, tslib
+from pandas import Timestamp, NaT
+from pandas._libs.tslib import iNaT
 
 nan = np.nan
 
@@ -373,7 +374,7 @@ class TestSeries(TestPackers):
         s.name = 'object'
         self.d['object'] = s
 
-        s = Series(tslib.iNaT, dtype='M8[ns]', index=range(5))
+        s = Series(iNaT, dtype='M8[ns]', index=range(5))
         self.d['date'] = s
 
         data = {
diff --git a/pandas/tests/io/test_pytables.py b/pandas/tests/io/test_pytables.py
index 9f1dea209..5592c564e 100644
--- a/pandas/tests/io/test_pytables.py
+++ b/pandas/tests/io/test_pytables.py
@@ -5282,7 +5282,7 @@ class TestTimezones(Base, tm.TestCase):
 
         # use maybe_get_tz instead of dateutil.tz.gettz to handle the windows
         # filename issues.
-        from pandas.tslib import maybe_get_tz
+        from pandas._libs.tslib import maybe_get_tz
         gettz = lambda x: maybe_get_tz('dateutil/' + x)
 
         # as columns
diff --git a/pandas/tests/io/test_stata.py b/pandas/tests/io/test_stata.py
index ae09e671d..5188adf54 100644
--- a/pandas/tests/io/test_stata.py
+++ b/pandas/tests/io/test_stata.py
@@ -19,7 +19,7 @@ from pandas.core.frame import DataFrame, Series
 from pandas.io.parsers import read_csv
 from pandas.io.stata import (read_stata, StataReader, InvalidColumnName,
                              PossiblePrecisionLoss, StataMissingValue)
-from pandas.tslib import NaT
+from pandas._libs.tslib import NaT
 from pandas.types.common import is_categorical_dtype
 
 
diff --git a/pandas/tests/scalar/test_period.py b/pandas/tests/scalar/test_period.py
index 49aa44492..3128e9069 100644
--- a/pandas/tests/scalar/test_period.py
+++ b/pandas/tests/scalar/test_period.py
@@ -6,7 +6,9 @@ import pandas.util.testing as tm
 import pandas.tseries.period as period
 from pandas.compat import text_type, iteritems
 from pandas.compat.numpy import np_datetime64_compat
-from pandas import Period, Timestamp, tslib, offsets, _period
+
+from pandas._libs import tslib, period as libperiod
+from pandas import Period, Timestamp, offsets
 from pandas.tseries.frequencies import DAYS, MONTHS
 
 
@@ -256,8 +258,8 @@ class TestPeriodProperties(tm.TestCase):
             self.assertEqual(p.tz, exp.tz)
 
     def test_timestamp_tz_arg_dateutil(self):
-        from pandas.tslib import _dateutil_gettz as gettz
-        from pandas.tslib import maybe_get_tz
+        from pandas._libs.tslib import _dateutil_gettz as gettz
+        from pandas._libs.tslib import maybe_get_tz
         for case in ['dateutil/Europe/Brussels', 'dateutil/Asia/Tokyo',
                      'dateutil/US/Pacific']:
             p = Period('1/1/2005', freq='M').to_timestamp(
@@ -275,7 +277,7 @@ class TestPeriodProperties(tm.TestCase):
             self.assertEqual(p.tz, exp.tz)
 
     def test_timestamp_tz_arg_dateutil_from_string(self):
-        from pandas.tslib import _dateutil_gettz as gettz
+        from pandas._libs.tslib import _dateutil_gettz as gettz
         p = Period('1/1/2005',
                    freq='M').to_timestamp(tz='dateutil/Europe/Brussels')
         self.assertEqual(p.tz, gettz('Europe/Brussels'))
@@ -939,10 +941,10 @@ class TestPeriodProperties(tm.TestCase):
 class TestPeriodField(tm.TestCase):
 
     def test_get_period_field_raises_on_out_of_range(self):
-        self.assertRaises(ValueError, _period.get_period_field, -1, 0, 0)
+        self.assertRaises(ValueError, libperiod.get_period_field, -1, 0, 0)
 
     def test_get_period_field_array_raises_on_out_of_range(self):
-        self.assertRaises(ValueError, _period.get_period_field_arr, -1,
+        self.assertRaises(ValueError, libperiod.get_period_field_arr, -1,
                           np.empty(1), 0)
 
 
diff --git a/pandas/tests/scalar/test_timedelta.py b/pandas/tests/scalar/test_timedelta.py
index c5a828bf2..7c5caa950 100644
--- a/pandas/tests/scalar/test_timedelta.py
+++ b/pandas/tests/scalar/test_timedelta.py
@@ -6,9 +6,8 @@ import pandas as pd
 import pandas.util.testing as tm
 from pandas.tseries.timedeltas import _coerce_scalar_to_timedelta_type as ct
 from pandas import (Timedelta, TimedeltaIndex, timedelta_range, Series,
-                    to_timedelta, tslib, compat, isnull)
-
-iNaT = tslib.iNaT
+                    to_timedelta, compat, isnull)
+from pandas._libs.tslib import iNaT, NaTType
 
 
 class TestTimedeltas(tm.TestCase):
@@ -301,9 +300,9 @@ class TestTimedeltas(tm.TestCase):
 
     def test_nat_converters(self):
         self.assertEqual(to_timedelta(
-            'nat', box=False).astype('int64'), tslib.iNaT)
+            'nat', box=False).astype('int64'), iNaT)
         self.assertEqual(to_timedelta(
-            'nan', box=False).astype('int64'), tslib.iNaT)
+            'nan', box=False).astype('int64'), iNaT)
 
         def testit(unit, transform):
 
@@ -589,7 +588,7 @@ class TestTimedeltas(tm.TestCase):
 
         # Beyond lower limit, a NAT before the Overflow
         self.assertIsInstance(min_td - Timedelta(1, 'ns'),
-                              pd.tslib.NaTType)
+                              NaTType)
 
         with tm.assertRaises(OverflowError):
             min_td - Timedelta(2, 'ns')
@@ -599,7 +598,7 @@ class TestTimedeltas(tm.TestCase):
 
         # Same tests using the internal nanosecond values
         td = Timedelta(min_td.value - 1, 'ns')
-        self.assertIsInstance(td, pd.tslib.NaTType)
+        self.assertIsInstance(td, NaTType)
 
         with tm.assertRaises(OverflowError):
             Timedelta(min_td.value - 2, 'ns')
diff --git a/pandas/tests/scalar/test_timestamp.py b/pandas/tests/scalar/test_timestamp.py
index bbcdce922..d5d92dcf9 100644
--- a/pandas/tests/scalar/test_timestamp.py
+++ b/pandas/tests/scalar/test_timestamp.py
@@ -9,13 +9,15 @@ from distutils.version import LooseVersion
 
 import pandas as pd
 import pandas.util.testing as tm
-import pandas._period as period
+
 from pandas.tseries import offsets, frequencies
-from pandas.tslib import get_timezone, iNaT
+from pandas._libs import tslib, period
+from pandas._libs.tslib import get_timezone, iNaT
+
 from pandas.compat import lrange, long
 from pandas.util.testing import assert_series_equal
 from pandas.compat.numpy import np_datetime64_compat
-from pandas import (Timestamp, date_range, Period, Timedelta, tslib, compat,
+from pandas import (Timestamp, date_range, Period, Timedelta, compat,
                     Series, NaT, isnull, DataFrame, DatetimeIndex)
 from pandas.tseries.frequencies import (RESO_DAY, RESO_HR, RESO_MIN, RESO_US,
                                         RESO_MS, RESO_SEC)
@@ -1482,7 +1484,7 @@ class TestTimeSeries(tm.TestCase):
     def test_timestamp_to_datetime_explicit_dateutil(self):
         tm._skip_if_windows_python_3()
         tm._skip_if_no_dateutil()
-        from pandas.tslib import _dateutil_gettz as gettz
+        from pandas._libs.tslib import _dateutil_gettz as gettz
         rng = date_range('20090415', '20090519', tz=gettz('US/Eastern'))
 
         stamp = rng[0]
diff --git a/pandas/tests/series/test_constructors.py b/pandas/tests/series/test_constructors.py
index c15171f33..24e4355fa 100644
--- a/pandas/tests/series/test_constructors.py
+++ b/pandas/tests/series/test_constructors.py
@@ -14,7 +14,8 @@ from pandas import (Index, Series, isnull, date_range,
 from pandas.core.index import MultiIndex
 from pandas.tseries.index import Timestamp, DatetimeIndex
 
-from pandas import lib, tslib
+from pandas._libs import lib
+from pandas._libs.tslib import iNaT
 
 from pandas.compat import lrange, range, zip, OrderedDict, long
 from pandas import compat
@@ -200,14 +201,14 @@ class TestSeriesConstructors(TestData, tm.TestCase):
 
         data = ma.masked_all((3, ), dtype='M8[ns]')
         result = Series(data)
-        expected = Series([tslib.iNaT, tslib.iNaT, tslib.iNaT], dtype='M8[ns]')
+        expected = Series([iNaT, iNaT, iNaT], dtype='M8[ns]')
         assert_series_equal(result, expected)
 
         data[0] = datetime(2001, 1, 1)
         data[2] = datetime(2001, 1, 3)
         index = ['a', 'b', 'c']
         result = Series(data, index=index)
-        expected = Series([datetime(2001, 1, 1), tslib.iNaT,
+        expected = Series([datetime(2001, 1, 1), iNaT,
                            datetime(2001, 1, 3)], index=index, dtype='M8[ns]')
         assert_series_equal(result, expected)
 
@@ -327,20 +328,19 @@ class TestSeriesConstructors(TestData, tm.TestCase):
         self.assertTrue(result.dtype == object)
 
     def test_constructor_dtype_datetime64(self):
-        import pandas.tslib as tslib
 
-        s = Series(tslib.iNaT, dtype='M8[ns]', index=lrange(5))
+        s = Series(iNaT, dtype='M8[ns]', index=lrange(5))
         self.assertTrue(isnull(s).all())
 
         # in theory this should be all nulls, but since
         # we are not specifying a dtype is ambiguous
-        s = Series(tslib.iNaT, index=lrange(5))
+        s = Series(iNaT, index=lrange(5))
         self.assertFalse(isnull(s).all())
 
         s = Series(nan, dtype='M8[ns]', index=lrange(5))
         self.assertTrue(isnull(s).all())
 
-        s = Series([datetime(2001, 1, 2, 0, 0), tslib.iNaT], dtype='M8[ns]')
+        s = Series([datetime(2001, 1, 2, 0, 0), iNaT], dtype='M8[ns]')
         self.assertTrue(isnull(s[1]))
         self.assertEqual(s.dtype, 'M8[ns]')
 
@@ -732,8 +732,7 @@ class TestSeriesConstructors(TestData, tm.TestCase):
         self.assertEqual(td.dtype, 'timedelta64[ns]')
 
         # mixed with NaT
-        from pandas import tslib
-        td = Series([timedelta(days=1), tslib.NaT], dtype='m8[ns]')
+        td = Series([timedelta(days=1), NaT], dtype='m8[ns]')
         self.assertEqual(td.dtype, 'timedelta64[ns]')
 
         td = Series([timedelta(days=1), np.nan], dtype='m8[ns]')
@@ -744,11 +743,11 @@ class TestSeriesConstructors(TestData, tm.TestCase):
 
         # improved inference
         # GH5689
-        td = Series([np.timedelta64(300000000), pd.NaT])
+        td = Series([np.timedelta64(300000000), NaT])
         self.assertEqual(td.dtype, 'timedelta64[ns]')
 
         # because iNaT is int, not coerced to timedelta
-        td = Series([np.timedelta64(300000000), tslib.iNaT])
+        td = Series([np.timedelta64(300000000), iNaT])
         self.assertEqual(td.dtype, 'object')
 
         td = Series([np.timedelta64(300000000), np.nan])
@@ -791,7 +790,7 @@ class TestSeriesConstructors(TestData, tm.TestCase):
         self.assertEqual(s.dtype, 'timedelta64[ns]')
 
     def test_NaT_scalar(self):
-        series = Series([0, 1000, 2000, tslib.iNaT], dtype='M8[ns]')
+        series = Series([0, 1000, 2000, iNaT], dtype='M8[ns]')
 
         val = series[3]
         self.assertTrue(isnull(val))
diff --git a/pandas/tests/series/test_dtypes.py b/pandas/tests/series/test_dtypes.py
index 13375ab88..a2aaff255 100644
--- a/pandas/tests/series/test_dtypes.py
+++ b/pandas/tests/series/test_dtypes.py
@@ -62,7 +62,7 @@ class TestSeriesDtypes(TestData, tm.TestCase):
         self.assert_series_equal(result, Series(np.arange(1, 5)))
 
     def test_astype_datetimes(self):
-        import pandas.tslib as tslib
+        import pandas._libs.tslib as tslib
 
         s = Series(tslib.iNaT, dtype='M8[ns]', index=lrange(5))
         s = s.astype('O')
diff --git a/pandas/tests/series/test_indexing.py b/pandas/tests/series/test_indexing.py
index bb77550e0..9d93d9f01 100644
--- a/pandas/tests/series/test_indexing.py
+++ b/pandas/tests/series/test_indexing.py
@@ -7,14 +7,14 @@ from numpy import nan
 import numpy as np
 import pandas as pd
 
-import pandas.index as _index
+import pandas._libs.index as _index
 from pandas.types.common import is_integer, is_scalar
 from pandas import (Index, Series, DataFrame, isnull,
                     date_range, NaT, MultiIndex,
                     Timestamp, DatetimeIndex, Timedelta)
 from pandas.core.indexing import IndexingError
 from pandas.tseries.offsets import BDay
-from pandas import lib, tslib
+from pandas._libs import tslib, lib
 
 from pandas.compat import lrange, range
 from pandas import compat
@@ -375,7 +375,7 @@ class TestSeriesIndexing(TestData, tm.TestCase):
     def test_getitem_setitem_datetime_tz_dateutil(self):
         tm._skip_if_no_dateutil()
         from dateutil.tz import tzutc
-        from pandas.tslib import _dateutil_gettz as gettz
+        from pandas._libs.tslib import _dateutil_gettz as gettz
 
         tz = lambda x: tzutc() if x == 'UTC' else gettz(
             x)  # handle special case for utc in dateutil
diff --git a/pandas/tests/series/test_internals.py b/pandas/tests/series/test_internals.py
index a3b13ba9b..4b1c30320 100644
--- a/pandas/tests/series/test_internals.py
+++ b/pandas/tests/series/test_internals.py
@@ -8,7 +8,7 @@ import numpy as np
 
 from pandas import Series
 from pandas.tseries.index import Timestamp
-import pandas.lib as lib
+import pandas._libs.lib as lib
 
 from pandas.util.testing import assert_series_equal
 import pandas.util.testing as tm
diff --git a/pandas/tests/series/test_missing.py b/pandas/tests/series/test_missing.py
index 23eb6a40f..87cfcf322 100644
--- a/pandas/tests/series/test_missing.py
+++ b/pandas/tests/series/test_missing.py
@@ -9,9 +9,9 @@ import numpy as np
 import pandas as pd
 
 from pandas import (Series, DataFrame, isnull, date_range,
-                    MultiIndex, Index, Timestamp)
+                    MultiIndex, Index, Timestamp, NaT)
 from pandas.compat import range
-from pandas import tslib
+from pandas._libs.tslib import iNaT
 from pandas.util.testing import assert_series_equal, assert_frame_equal
 import pandas.util.testing as tm
 
@@ -69,9 +69,8 @@ class TestSeriesMissingData(TestData, tm.TestCase):
                            timedelta(days=1, seconds=9 * 3600 + 60 + 1)])
         assert_series_equal(result, expected)
 
-        from pandas import tslib
-        result = td.fillna(tslib.NaT)
-        expected = Series([tslib.NaT, timedelta(0), timedelta(1),
+        result = td.fillna(NaT)
+        expected = Series([NaT, timedelta(0), timedelta(1),
                            timedelta(days=1, seconds=9 * 3600 + 60 + 1)],
                           dtype='m8[ns]')
         assert_series_equal(result, expected)
@@ -102,8 +101,7 @@ class TestSeriesMissingData(TestData, tm.TestCase):
             '20130101'), Timestamp('20130104'), Timestamp('20130103 9:01:01')])
         assert_series_equal(result, expected)
 
-        from pandas import tslib
-        result = s.fillna(tslib.NaT)
+        result = s.fillna(NaT)
         expected = s
         assert_series_equal(result, expected)
 
@@ -303,7 +301,7 @@ class TestSeriesMissingData(TestData, tm.TestCase):
                     s.fillna(1, limit=limit, method=method)
 
     def test_fillna_nat(self):
-        series = Series([0, 1, 2, tslib.iNaT], dtype='M8[ns]')
+        series = Series([0, 1, 2, iNaT], dtype='M8[ns]')
 
         filled = series.fillna(method='pad')
         filled2 = series.fillna(value=series.values[2])
@@ -321,7 +319,7 @@ class TestSeriesMissingData(TestData, tm.TestCase):
         assert_frame_equal(filled, expected)
         assert_frame_equal(filled2, expected)
 
-        series = Series([tslib.iNaT, 0, 1, 2], dtype='M8[ns]')
+        series = Series([iNaT, 0, 1, 2], dtype='M8[ns]')
 
         filled = series.fillna(method='bfill')
         filled2 = series.fillna(value=series[1])
@@ -460,26 +458,25 @@ class TestSeriesMissingData(TestData, tm.TestCase):
 
     def test_timedelta64_nan(self):
 
-        from pandas import tslib
         td = Series([timedelta(days=i) for i in range(10)])
 
         # nan ops on timedeltas
         td1 = td.copy()
         td1[0] = np.nan
         self.assertTrue(isnull(td1[0]))
-        self.assertEqual(td1[0].value, tslib.iNaT)
+        self.assertEqual(td1[0].value, iNaT)
         td1[0] = td[0]
         self.assertFalse(isnull(td1[0]))
 
-        td1[1] = tslib.iNaT
+        td1[1] = iNaT
         self.assertTrue(isnull(td1[1]))
-        self.assertEqual(td1[1].value, tslib.iNaT)
+        self.assertEqual(td1[1].value, iNaT)
         td1[1] = td[1]
         self.assertFalse(isnull(td1[1]))
 
-        td1[2] = tslib.NaT
+        td1[2] = NaT
         self.assertTrue(isnull(td1[2]))
-        self.assertEqual(td1[2].value, tslib.iNaT)
+        self.assertEqual(td1[2].value, iNaT)
         td1[2] = td[2]
         self.assertFalse(isnull(td1[2]))
 
diff --git a/pandas/tests/series/test_replace.py b/pandas/tests/series/test_replace.py
index 7fe31bab8..0acd03316 100644
--- a/pandas/tests/series/test_replace.py
+++ b/pandas/tests/series/test_replace.py
@@ -3,7 +3,7 @@
 
 import numpy as np
 import pandas as pd
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.util.testing as tm
 
 from .common import TestData
diff --git a/pandas/tests/series/test_timeseries.py b/pandas/tests/series/test_timeseries.py
index d384460c3..ce7d5a573 100644
--- a/pandas/tests/series/test_timeseries.py
+++ b/pandas/tests/series/test_timeseries.py
@@ -6,7 +6,7 @@ from datetime import datetime, timedelta, time
 
 import pandas as pd
 import pandas.util.testing as tm
-from pandas.tslib import iNaT
+from pandas._libs.tslib import iNaT
 from pandas.compat import lrange, StringIO, product
 from pandas.tseries.tdi import TimedeltaIndex
 from pandas.tseries.index import DatetimeIndex
diff --git a/pandas/tests/sparse/test_array.py b/pandas/tests/sparse/test_array.py
index 70aaea5b5..15531cecf 100644
--- a/pandas/tests/sparse/test_array.py
+++ b/pandas/tests/sparse/test_array.py
@@ -8,7 +8,7 @@ import numpy as np
 
 from pandas import _np_version_under1p8
 from pandas.sparse.api import SparseArray, SparseSeries
-from pandas._sparse import IntIndex
+from pandas.sparse.libsparse import IntIndex
 from pandas.util.testing import assert_almost_equal, assertRaisesRegexp
 import pandas.util.testing as tm
 
diff --git a/pandas/tests/sparse/test_frame.py b/pandas/tests/sparse/test_frame.py
index b2283364a..a7dd7f2e8 100644
--- a/pandas/tests/sparse/test_frame.py
+++ b/pandas/tests/sparse/test_frame.py
@@ -14,7 +14,7 @@ from pandas.compat import lrange
 from pandas import compat
 import pandas.sparse.frame as spf
 
-from pandas._sparse import BlockIndex, IntIndex
+from pandas.sparse.libsparse import BlockIndex, IntIndex
 from pandas.sparse.api import SparseSeries, SparseDataFrame, SparseArray
 from pandas.tests.frame.test_misc_api import SharedWithSparse
 
diff --git a/pandas/tests/sparse/test_libsparse.py b/pandas/tests/sparse/test_libsparse.py
index 0435b7329..b6ab99dc6 100644
--- a/pandas/tests/sparse/test_libsparse.py
+++ b/pandas/tests/sparse/test_libsparse.py
@@ -8,7 +8,7 @@ import pandas.util.testing as tm
 from pandas import compat
 
 from pandas.sparse.array import IntIndex, BlockIndex, _make_index
-import pandas._sparse as splib
+import pandas.sparse.libsparse as splib
 
 TEST_LENGTH = 20
 
diff --git a/pandas/tests/sparse/test_series.py b/pandas/tests/sparse/test_series.py
index de6636162..8aa85a5b7 100644
--- a/pandas/tests/sparse/test_series.py
+++ b/pandas/tests/sparse/test_series.py
@@ -16,7 +16,7 @@ from pandas.tools.util import cartesian_product
 
 import pandas.sparse.frame as spf
 
-from pandas._sparse import BlockIndex, IntIndex
+from pandas.sparse.libsparse import BlockIndex, IntIndex
 from pandas.sparse.api import SparseSeries
 from pandas.tests.series.test_misc_api import SharedWithSparse
 
diff --git a/pandas/tests/test_algos.py b/pandas/tests/test_algos.py
index fab04f7fa..7a3cc3e2c 100644
--- a/pandas/tests/test_algos.py
+++ b/pandas/tests/test_algos.py
@@ -10,11 +10,11 @@ from pandas import Series, Categorical, CategoricalIndex, Index
 import pandas as pd
 
 from pandas import compat
-import pandas.algos as _algos
+from pandas._libs import algos as libalgos, hashtable
+from pandas._libs.hashtable import unique_label_indices
 from pandas.compat import lrange
 import pandas.core.algorithms as algos
 import pandas.util.testing as tm
-import pandas.hashtable as hashtable
 from pandas.compat.numpy import np_array_datetime64_compat
 from pandas.util.testing import assert_almost_equal
 
@@ -972,7 +972,6 @@ def test_quantile():
 
 
 def test_unique_label_indices():
-    from pandas.hashtable import unique_label_indices
 
     a = np.random.randint(1, 1 << 10, 1 << 15).astype('i8')
 
@@ -998,7 +997,7 @@ class TestRank(tm.TestCase):
         def _check(arr):
             mask = ~np.isfinite(arr)
             arr = arr.copy()
-            result = _algos.rank_1d_float64(arr)
+            result = libalgos.rank_1d_float64(arr)
             arr[mask] = np.inf
             exp = rankdata(arr)
             exp[mask] = nan
@@ -1034,26 +1033,26 @@ def test_pad_backfill_object_segfault():
     old = np.array([], dtype='O')
     new = np.array([datetime(2010, 12, 31)], dtype='O')
 
-    result = _algos.pad_object(old, new)
+    result = libalgos.pad_object(old, new)
     expected = np.array([-1], dtype=np.int64)
     assert (np.array_equal(result, expected))
 
-    result = _algos.pad_object(new, old)
+    result = libalgos.pad_object(new, old)
     expected = np.array([], dtype=np.int64)
     assert (np.array_equal(result, expected))
 
-    result = _algos.backfill_object(old, new)
+    result = libalgos.backfill_object(old, new)
     expected = np.array([-1], dtype=np.int64)
     assert (np.array_equal(result, expected))
 
-    result = _algos.backfill_object(new, old)
+    result = libalgos.backfill_object(new, old)
     expected = np.array([], dtype=np.int64)
     assert (np.array_equal(result, expected))
 
 
 def test_arrmap():
     values = np.array(['foo', 'foo', 'bar', 'bar', 'baz', 'qux'], dtype='O')
-    result = _algos.arrmap_object(values, lambda x: x in ['foo', 'bar'])
+    result = libalgos.arrmap_object(values, lambda x: x in ['foo', 'bar'])
     assert (result.dtype == np.bool_)
 
 
@@ -1078,7 +1077,7 @@ class TestTseriesUtil(tm.TestCase):
         old = Index([1, 5, 10])
         new = Index(lrange(12))
 
-        filler = _algos.backfill_int64(old.values, new.values)
+        filler = libalgos.backfill_int64(old.values, new.values)
 
         expect_filler = np.array([0, 0, 1, 1, 1, 1,
                                   2, 2, 2, 2, 2, -1], dtype=np.int64)
@@ -1087,7 +1086,7 @@ class TestTseriesUtil(tm.TestCase):
         # corner case
         old = Index([1, 4])
         new = Index(lrange(5, 10))
-        filler = _algos.backfill_int64(old.values, new.values)
+        filler = libalgos.backfill_int64(old.values, new.values)
 
         expect_filler = np.array([-1, -1, -1, -1, -1], dtype=np.int64)
         self.assert_numpy_array_equal(filler, expect_filler)
@@ -1096,7 +1095,7 @@ class TestTseriesUtil(tm.TestCase):
         old = Index([1, 5, 10])
         new = Index(lrange(12))
 
-        filler = _algos.pad_int64(old.values, new.values)
+        filler = libalgos.pad_int64(old.values, new.values)
 
         expect_filler = np.array([-1, 0, 0, 0, 0, 1,
                                   1, 1, 1, 1, 2, 2], dtype=np.int64)
@@ -1105,7 +1104,7 @@ class TestTseriesUtil(tm.TestCase):
         # corner case
         old = Index([5, 10])
         new = Index(lrange(5))
-        filler = _algos.pad_int64(old.values, new.values)
+        filler = libalgos.pad_int64(old.values, new.values)
         expect_filler = np.array([-1, -1, -1, -1, -1], dtype=np.int64)
         self.assert_numpy_array_equal(filler, expect_filler)
 
@@ -1137,7 +1136,7 @@ def test_is_lexsorted():
                   6, 5,
                   4, 3, 2, 1, 0])]
 
-    assert (not _algos.is_lexsorted(failure))
+    assert (not libalgos.is_lexsorted(failure))
 
 # def test_get_group_index():
 #     a = np.array([0, 1, 2, 0, 2, 1, 0, 0], dtype=np.int64)
@@ -1153,7 +1152,7 @@ def test_groupsort_indexer():
     a = np.random.randint(0, 1000, 100).astype(np.int64)
     b = np.random.randint(0, 1000, 100).astype(np.int64)
 
-    result = _algos.groupsort_indexer(a, 1000)[0]
+    result = libalgos.groupsort_indexer(a, 1000)[0]
 
     # need to use a stable sort
     expected = np.argsort(a, kind='mergesort')
@@ -1161,7 +1160,7 @@ def test_groupsort_indexer():
 
     # compare with lexsort
     key = a * 1000 + b
-    result = _algos.groupsort_indexer(key, 1000000)[0]
+    result = libalgos.groupsort_indexer(key, 1000000)[0]
     expected = np.lexsort((b, a))
     assert (np.array_equal(result, expected))
 
@@ -1172,8 +1171,8 @@ def test_infinity_sort():
     # itself.  Instead, let's give our infinities a self-consistent
     # ordering, but outside the float extended real line.
 
-    Inf = _algos.Infinity()
-    NegInf = _algos.NegInfinity()
+    Inf = libalgos.Infinity()
+    NegInf = libalgos.NegInfinity()
 
     ref_nums = [NegInf, float("-inf"), -1e100, 0, 1e100, float("inf"), Inf]
 
@@ -1191,14 +1190,14 @@ def test_infinity_sort():
         assert sorted(perm) == ref_nums
 
     # smoke tests
-    np.array([_algos.Infinity()] * 32).argsort()
-    np.array([_algos.NegInfinity()] * 32).argsort()
+    np.array([libalgos.Infinity()] * 32).argsort()
+    np.array([libalgos.NegInfinity()] * 32).argsort()
 
 
 def test_ensure_platform_int():
     arr = np.arange(100, dtype=np.intp)
 
-    result = _algos.ensure_platform_int(arr)
+    result = libalgos.ensure_platform_int(arr)
     assert (result is arr)
 
 
diff --git a/pandas/tests/test_base.py b/pandas/tests/test_base.py
index 8264ad339..1d4dddf64 100644
--- a/pandas/tests/test_base.py
+++ b/pandas/tests/test_base.py
@@ -18,6 +18,7 @@ from pandas.compat import StringIO
 from pandas.compat.numpy import np_array_datetime64_compat
 from pandas.core.base import PandasDelegate, NoNewAttributesMixin
 from pandas.tseries.base import DatetimeIndexOpsMixin
+from pandas._libs.tslib import iNaT
 
 
 class CheckStringMixin(object):
@@ -451,15 +452,15 @@ class TestIndexOps(Ops):
                 if is_datetimetz(o):
                     if isinstance(o, DatetimeIndex):
                         v = o.asi8
-                        v[0:2] = pd.tslib.iNaT
+                        v[0:2] = iNaT
                         values = o._shallow_copy(v)
                     else:
                         o = o.copy()
-                        o[0:2] = pd.tslib.iNaT
+                        o[0:2] = iNaT
                         values = o._values
 
                 elif needs_i8_conversion(o):
-                    values[0:2] = pd.tslib.iNaT
+                    values[0:2] = iNaT
                     values = o._shallow_copy(values)
                 else:
                     values[0:2] = null_obj
diff --git a/pandas/tests/test_internals.py b/pandas/tests/test_internals.py
index f086935df..5ab2bbc4a 100644
--- a/pandas/tests/test_internals.py
+++ b/pandas/tests/test_internals.py
@@ -17,7 +17,7 @@ from pandas.core.internals import (BlockPlacement, SingleBlockManager,
 import pandas.core.algorithms as algos
 import pandas.util.testing as tm
 import pandas as pd
-from pandas import lib
+from pandas._libs import lib
 from pandas.util.testing import (assert_almost_equal, assert_frame_equal,
                                  randn, assert_series_equal)
 from pandas.compat import zip, u
diff --git a/pandas/tests/test_join.py b/pandas/tests/test_join.py
index 2a16d7663..6723494d1 100644
--- a/pandas/tests/test_join.py
+++ b/pandas/tests/test_join.py
@@ -3,7 +3,7 @@
 import numpy as np
 from pandas import Index
 
-import pandas._join as _join
+from pandas._libs import join as _join
 import pandas.util.testing as tm
 from pandas.util.testing import assert_almost_equal
 
diff --git a/pandas/tests/test_lib.py b/pandas/tests/test_lib.py
index 2381c52ef..a925cf139 100644
--- a/pandas/tests/test_lib.py
+++ b/pandas/tests/test_lib.py
@@ -2,7 +2,7 @@
 
 import numpy as np
 import pandas as pd
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.util.testing as tm
 
 
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index c809b39bb..d1b7fdadc 100755
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -20,7 +20,7 @@ from pandas.compat import (range, lrange, StringIO, lzip, u, product as
                            cart_product, zip)
 import pandas as pd
 
-import pandas.index as _index
+import pandas._libs.index as _index
 
 
 class TestMultiLevel(tm.TestCase):
diff --git a/pandas/tests/test_take.py b/pandas/tests/test_take.py
index 3aed22c14..0bc1d0dcd 100644
--- a/pandas/tests/test_take.py
+++ b/pandas/tests/test_take.py
@@ -6,7 +6,7 @@ import numpy as np
 from pandas.compat import long
 import pandas.core.algorithms as algos
 import pandas.util.testing as tm
-from pandas.tslib import iNaT
+from pandas._libs.tslib import iNaT
 
 
 class TestTake(tm.TestCase):
diff --git a/pandas/tests/tools/test_join.py b/pandas/tests/tools/test_join.py
index ee6b3d57b..b65f80080 100644
--- a/pandas/tests/tools/test_join.py
+++ b/pandas/tests/tools/test_join.py
@@ -9,7 +9,7 @@ import pandas.compat as compat
 from pandas.util.testing import assert_frame_equal
 from pandas import DataFrame, MultiIndex, Series, Index, merge, concat
 
-import pandas._join as _join
+from pandas._libs import join as libjoin
 import pandas.util.testing as tm
 from pandas.tests.tools.test_merge import get_test_data, N, NGROUPS
 
@@ -46,7 +46,7 @@ class TestJoin(tm.TestCase):
         right = a_([1, 1, 0, 4, 2, 2, 1], dtype=np.int64)
         max_group = 5
 
-        ls, rs = _join.left_outer_join(left, right, max_group)
+        ls, rs = libjoin.left_outer_join(left, right, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
@@ -70,7 +70,7 @@ class TestJoin(tm.TestCase):
         right = a_([1, 1, 0, 4, 2, 2, 1], dtype=np.int64)
         max_group = 5
 
-        rs, ls = _join.left_outer_join(right, left, max_group)
+        rs, ls = libjoin.left_outer_join(right, left, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
@@ -96,7 +96,7 @@ class TestJoin(tm.TestCase):
         right = a_([1, 1, 0, 4, 2, 2, 1, 4], dtype=np.int64)
         max_group = 5
 
-        ls, rs = _join.inner_join(left, right, max_group)
+        ls, rs = libjoin.inner_join(left, right, max_group)
 
         exp_ls = left.argsort(kind='mergesort')
         exp_rs = right.argsort(kind='mergesort')
diff --git a/pandas/tests/tseries/test_offsets.py b/pandas/tests/tseries/test_offsets.py
index dfa1e94e4..f644c3539 100644
--- a/pandas/tests/tseries/test_offsets.py
+++ b/pandas/tests/tseries/test_offsets.py
@@ -31,8 +31,8 @@ from pandas.tseries.tools import (format, ole2datetime, parse_time_string,
                                   to_datetime, DateParseError)
 import pandas.tseries.offsets as offsets
 from pandas.io.pickle import read_pickle
-from pandas.tslib import normalize_date, NaT, Timestamp, Timedelta
-import pandas.tslib as tslib
+from pandas._libs.tslib import normalize_date, NaT, Timestamp, Timedelta
+import pandas._libs.tslib as tslib
 from pandas.util.testing import assertRaisesRegexp
 import pandas.util.testing as tm
 from pandas.tseries.holiday import USFederalHolidayCalendar
diff --git a/pandas/tests/tseries/test_resample.py b/pandas/tests/tseries/test_resample.py
index 1535bd665..57a655b0b 100755
--- a/pandas/tests/tseries/test_resample.py
+++ b/pandas/tests/tseries/test_resample.py
@@ -26,7 +26,7 @@ from pandas.tseries.resample import (DatetimeIndex, TimeGrouper,
 from pandas.tseries.tdi import timedelta_range, TimedeltaIndex
 from pandas.util.testing import (assert_series_equal, assert_almost_equal,
                                  assert_frame_equal, assert_index_equal)
-from pandas._period import IncompatibleFrequency
+from pandas._libs.period import IncompatibleFrequency
 
 bday = BDay()
 
diff --git a/pandas/tests/tseries/test_timezones.py b/pandas/tests/tseries/test_timezones.py
index 771fb2f50..1ccc1652d 100644
--- a/pandas/tests/tseries/test_timezones.py
+++ b/pandas/tests/tseries/test_timezones.py
@@ -11,7 +11,8 @@ import pandas.tseries.offsets as offsets
 from pandas.compat import lrange, zip
 from pandas.tseries.index import bdate_range, date_range
 from pandas.types.dtypes import DatetimeTZDtype
-from pandas import (Index, Series, DataFrame, isnull, Timestamp, tslib, NaT,
+from pandas._libs import tslib
+from pandas import (Index, Series, DataFrame, isnull, Timestamp, NaT,
                     DatetimeIndex, to_datetime)
 from pandas.util.testing import (assert_frame_equal, assert_series_equal,
                                  set_timezone)
@@ -924,7 +925,7 @@ class TestTimeZoneSupportDateutil(TestTimeZoneSupportPytz):
         # Skipped on win32 due to dateutil bug
         tm._skip_if_windows()
 
-        from pandas.tslib import maybe_get_tz
+        from pandas._libs.tslib import maybe_get_tz
 
         # from system utc to real utc
         ts = Timestamp('2001-01-05 11:56', tz=maybe_get_tz('dateutil/UTC'))
diff --git a/pandas/tests/types/test_inference.py b/pandas/tests/types/test_inference.py
index 629aa63f4..a36a77a70 100644
--- a/pandas/tests/types/test_inference.py
+++ b/pandas/tests/types/test_inference.py
@@ -13,7 +13,7 @@ import numpy as np
 import pytz
 
 import pandas as pd
-from pandas import lib, tslib
+from pandas._libs import tslib, lib
 from pandas import (Series, Index, DataFrame, Timedelta,
                     DatetimeIndex, TimedeltaIndex, Timestamp,
                     Panel, Period, Categorical)
@@ -517,28 +517,28 @@ class TestTypeInference(tm.TestCase):
         # GH 13664
         arr = np.array([pd.Period('2011-01', freq='D'),
                         pd.Period('2011-02', freq='D')])
-        self.assertEqual(pd.lib.infer_dtype(arr), 'period')
+        self.assertEqual(lib.infer_dtype(arr), 'period')
 
         arr = np.array([pd.Period('2011-01', freq='D'),
                         pd.Period('2011-02', freq='M')])
-        self.assertEqual(pd.lib.infer_dtype(arr), 'period')
+        self.assertEqual(lib.infer_dtype(arr), 'period')
 
         # starts with nan
         for n in [pd.NaT, np.nan]:
             arr = np.array([n, pd.Period('2011-01', freq='D')])
-            self.assertEqual(pd.lib.infer_dtype(arr), 'period')
+            self.assertEqual(lib.infer_dtype(arr), 'period')
 
             arr = np.array([n, pd.Period('2011-01', freq='D'), n])
-            self.assertEqual(pd.lib.infer_dtype(arr), 'period')
+            self.assertEqual(lib.infer_dtype(arr), 'period')
 
         # different type of nat
         arr = np.array([np.datetime64('nat'), pd.Period('2011-01', freq='M')],
                        dtype=object)
-        self.assertEqual(pd.lib.infer_dtype(arr), 'mixed')
+        self.assertEqual(lib.infer_dtype(arr), 'mixed')
 
         arr = np.array([pd.Period('2011-01', freq='M'), np.datetime64('nat')],
                        dtype=object)
-        self.assertEqual(pd.lib.infer_dtype(arr), 'mixed')
+        self.assertEqual(lib.infer_dtype(arr), 'mixed')
 
     def test_infer_dtype_all_nan_nat_like(self):
         arr = np.array([np.nan, np.nan])
diff --git a/pandas/tests/types/test_io.py b/pandas/tests/types/test_io.py
index ce8e23342..b6c10394d 100644
--- a/pandas/tests/types/test_io.py
+++ b/pandas/tests/types/test_io.py
@@ -1,7 +1,7 @@
 # -*- coding: utf-8 -*-
 
 import numpy as np
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.util.testing as tm
 
 from pandas.compat import long, u
@@ -73,7 +73,7 @@ class TestParseSQL(tm.TestCase):
         self.assert_numpy_array_equal(result, expected)
 
     def test_convert_downcast_int64(self):
-        from pandas.parser import na_values
+        from pandas.io.libparsers import na_values
 
         arr = np.array([1, 2, 7, 8, 10], dtype=np.int64)
         expected = np.array([1, 2, 7, 8, 10], dtype=np.int8)
diff --git a/pandas/tests/types/test_missing.py b/pandas/tests/types/test_missing.py
index cab44f112..2e35f5c1b 100644
--- a/pandas/tests/types/test_missing.py
+++ b/pandas/tests/types/test_missing.py
@@ -7,7 +7,7 @@ from pandas.util import testing as tm
 import pandas as pd
 from pandas.core import config as cf
 from pandas.compat import u
-from pandas.tslib import iNaT
+from pandas._libs.tslib import iNaT
 from pandas import (NaT, Float64Index, Series,
                     DatetimeIndex, TimedeltaIndex, date_range)
 from pandas.types.dtypes import DatetimeTZDtype
diff --git a/pandas/tools/hashing.py b/pandas/tools/hashing.py
index ef863510c..85ceb4394 100644
--- a/pandas/tools/hashing.py
+++ b/pandas/tools/hashing.py
@@ -4,8 +4,9 @@ data hash pandas / numpy objects
 import itertools
 
 import numpy as np
-from pandas import _hash, Series, factorize, Categorical, Index, MultiIndex
-from pandas.lib import is_bool_array
+from pandas import Series, factorize, Categorical, Index, MultiIndex
+from pandas.tools import libhashing as _hash
+from pandas._libs.lib import is_bool_array
 from pandas.types.generic import ABCIndexClass, ABCSeries, ABCDataFrame
 from pandas.types.common import (is_categorical_dtype, is_numeric_dtype,
                                  is_datetime64_dtype, is_timedelta64_dtype,
diff --git a/pandas/src/hash.pyx b/pandas/tools/hashing.pyx
similarity index 100%
rename from pandas/src/hash.pyx
rename to pandas/tools/hashing.pyx
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index ba53d42fc..3f1e7640b 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -37,9 +37,7 @@ from pandas.util.decorators import Appender, Substitution
 from pandas.core.sorting import is_int64_overflow_possible
 import pandas.core.algorithms as algos
 import pandas.core.common as com
-
-import pandas._join as _join
-import pandas.hashtable as _hash
+from pandas._libs import hashtable as libhashtable, join as libjoin
 
 
 # back-compat of pseudo-public API
@@ -1005,8 +1003,8 @@ class _OrderedMerge(_MergeOperation):
                                                      rdata.items, rsuf)
 
         if self.fill_method == 'ffill':
-            left_join_indexer = _join.ffill_indexer(left_indexer)
-            right_join_indexer = _join.ffill_indexer(right_indexer)
+            left_join_indexer = libjoin.ffill_indexer(left_indexer)
+            right_join_indexer = libjoin.ffill_indexer(right_indexer)
         else:
             left_join_indexer = left_indexer
             right_join_indexer = right_indexer
@@ -1030,11 +1028,11 @@ class _OrderedMerge(_MergeOperation):
 
 
 def _asof_function(direction, on_type):
-    return getattr(_join, 'asof_join_%s_%s' % (direction, on_type), None)
+    return getattr(libjoin, 'asof_join_%s_%s' % (direction, on_type), None)
 
 
 def _asof_by_function(direction, on_type, by_type):
-    return getattr(_join, 'asof_join_%s_%s_by_%s' %
+    return getattr(libjoin, 'asof_join_%s_%s_by_%s' %
                    (direction, on_type, by_type), None)
 
 
@@ -1294,13 +1292,13 @@ def _get_multiindex_indexer(join_keys, index, sort):
     # factorize keys to a dense i8 space
     lkey, rkey, count = fkeys(lkey, rkey)
 
-    return _join.left_outer_join(lkey, rkey, count, sort=sort)
+    return libjoin.left_outer_join(lkey, rkey, count, sort=sort)
 
 
 def _get_single_indexer(join_key, index, sort=False):
     left_key, right_key, count = _factorize_keys(join_key, index, sort=sort)
 
-    left_indexer, right_indexer = _join.left_outer_join(
+    left_indexer, right_indexer = libjoin.left_outer_join(
         _ensure_int64(left_key),
         _ensure_int64(right_key),
         count, sort=sort)
@@ -1335,15 +1333,15 @@ def _left_join_on_index(left_ax, right_ax, join_keys, sort=False):
 
 
 def _right_outer_join(x, y, max_groups):
-    right_indexer, left_indexer = _join.left_outer_join(y, x, max_groups)
+    right_indexer, left_indexer = libjoin.left_outer_join(y, x, max_groups)
     return left_indexer, right_indexer
 
 
 _join_functions = {
-    'inner': _join.inner_join,
-    'left': _join.left_outer_join,
+    'inner': libjoin.inner_join,
+    'left': libjoin.left_outer_join,
     'right': _right_outer_join,
-    'outer': _join.full_outer_join,
+    'outer': libjoin.full_outer_join,
 }
 
 
@@ -1352,11 +1350,11 @@ def _factorize_keys(lk, rk, sort=True):
         lk = lk.values
         rk = rk.values
     if is_int_or_datetime_dtype(lk) and is_int_or_datetime_dtype(rk):
-        klass = _hash.Int64Factorizer
+        klass = libhashtable.Int64Factorizer
         lk = _ensure_int64(com._values_from_object(lk))
         rk = _ensure_int64(com._values_from_object(rk))
     else:
-        klass = _hash.Factorizer
+        klass = libhashtable.Factorizer
         lk = _ensure_object(lk)
         rk = _ensure_object(rk)
 
diff --git a/pandas/tools/tile.py b/pandas/tools/tile.py
index feb4d4bfd..9b21e542f 100644
--- a/pandas/tools/tile.py
+++ b/pandas/tools/tile.py
@@ -13,7 +13,7 @@ import pandas.core.nanops as nanops
 from pandas.compat import zip
 from pandas import to_timedelta, to_datetime
 from pandas.types.common import is_datetime64_dtype, is_timedelta64_dtype
-from pandas.lib import infer_dtype
+from pandas._libs.lib import infer_dtype
 
 import numpy as np
 
diff --git a/pandas/tools/util.py b/pandas/tools/util.py
index 8ec074fbf..bf78a9dfb 100644
--- a/pandas/tools/util.py
+++ b/pandas/tools/util.py
@@ -1,5 +1,5 @@
 import numpy as np
-import pandas.lib as lib
+import pandas._libs.lib as lib
 
 from pandas.types.common import (is_number,
                                  is_numeric_dtype,
diff --git a/pandas/tseries/api.py b/pandas/tseries/api.py
index 9a07983b4..a00ccf99e 100644
--- a/pandas/tseries/api.py
+++ b/pandas/tseries/api.py
@@ -10,5 +10,5 @@ from pandas.tseries.tdi import Timedelta, TimedeltaIndex, timedelta_range
 from pandas.tseries.period import Period, PeriodIndex, period_range, pnow
 from pandas.tseries.resample import TimeGrouper
 from pandas.tseries.timedeltas import to_timedelta
-from pandas.lib import NaT
+from pandas._libs.lib import NaT
 import pandas.tseries.offsets as offsets
diff --git a/pandas/tseries/base.py b/pandas/tseries/base.py
index 2e22c3586..ae40c2f66 100644
--- a/pandas/tseries/base.py
+++ b/pandas/tseries/base.py
@@ -21,9 +21,10 @@ from pandas.core.algorithms import checked_add_with_arr
 from pandas.core.common import AbstractMethodError
 
 import pandas.formats.printing as printing
-import pandas.tslib as tslib
-import pandas._period as prlib
-import pandas.lib as lib
+from pandas._libs import (tslib as libts, lib,
+                          Timedelta, Timestamp, iNaT, NaT)
+from pandas._libs.period import Period
+
 from pandas.core.index import Index
 from pandas.indexes.base import _index_shared_docs
 from pandas.util.decorators import Appender, cache_readonly
@@ -94,7 +95,8 @@ class TimelikeOps(object):
             result = (unit * rounder(values / float(unit)).astype('i8'))
         else:
             result = (unit * rounder(values / float(unit)).astype('i8'))
-        result = self._maybe_mask_results(result, fill_value=tslib.NaT)
+        result = self._maybe_mask_results(result, fill_value=NaT)
+
         attribs = self._get_attributes_dict()
         if 'freq' in attribs:
             attribs['freq'] = None
@@ -196,7 +198,7 @@ class DatetimeIndexOpsMixin(object):
             result[mask] = False
             return result
         try:
-            result[mask] = tslib.iNaT
+            result[mask] = iNaT
             return Index(result)
         except TypeError:
             return result
@@ -327,7 +329,7 @@ class DatetimeIndexOpsMixin(object):
             - If False returns ndarray of np.int64.
         """
         result = np.zeros(len(self), dtype=np.int64)
-        result.fill(tslib.iNaT)
+        result.fill(iNaT)
         if not box:
             return result
 
@@ -392,7 +394,7 @@ class DatetimeIndexOpsMixin(object):
         taken = self._assert_take_fillable(self.asi8, indices,
                                            allow_fill=allow_fill,
                                            fill_value=fill_value,
-                                           na_value=tslib.iNaT)
+                                           na_value=iNaT)
 
         # keep freq in PeriodIndex, reset otherwise
         freq = self.freq if isinstance(self, ABCPeriodIndex) else None
@@ -404,13 +406,13 @@ class DatetimeIndexOpsMixin(object):
 
     _can_hold_na = True
 
-    _na_value = tslib.NaT
+    _na_value = NaT
     """The expected NA value to use with this index."""
 
     @cache_readonly
     def _isnan(self):
         """ return if each value is nan"""
-        return (self.asi8 == tslib.iNaT)
+        return (self.asi8 == iNaT)
 
     @property
     def asobject(self):
@@ -424,7 +426,7 @@ class DatetimeIndexOpsMixin(object):
 
     def _convert_tolerance(self, tolerance):
         try:
-            return tslib.Timedelta(tolerance).to_timedelta64()
+            return Timedelta(tolerance).to_timedelta64()
         except ValueError:
             raise ValueError('tolerance argument for %s must be convertible '
                              'to Timedelta: %r'
@@ -477,7 +479,7 @@ class DatetimeIndexOpsMixin(object):
 
             # quick check
             if len(i8) and self.is_monotonic:
-                if i8[0] != tslib.iNaT:
+                if i8[0] != iNaT:
                     return self._box_func(i8[0])
 
             if self.hasnans:
@@ -525,7 +527,7 @@ class DatetimeIndexOpsMixin(object):
 
             # quick check
             if len(i8) and self.is_monotonic:
-                if i8[-1] != tslib.iNaT:
+                if i8[-1] != iNaT:
                     return self._box_func(i8[-1])
 
             if self.hasnans:
@@ -643,11 +645,11 @@ class DatetimeIndexOpsMixin(object):
                                 .format(typ1=type(self).__name__,
                                         typ2=type(other).__name__))
             elif isinstance(other, (DateOffset, timedelta, np.timedelta64,
-                                    tslib.Timedelta)):
+                                    Timedelta)):
                 return self._add_delta(other)
             elif is_integer(other):
                 return self.shift(other)
-            elif isinstance(other, (tslib.Timestamp, datetime)):
+            elif isinstance(other, (Timestamp, datetime)):
                 return self._add_datelike(other)
             else:  # pragma: no cover
                 return NotImplemented
@@ -673,13 +675,13 @@ class DatetimeIndexOpsMixin(object):
                                 .format(typ1=type(self).__name__,
                                         typ2=type(other).__name__))
             elif isinstance(other, (DateOffset, timedelta, np.timedelta64,
-                                    tslib.Timedelta)):
+                                    Timedelta)):
                 return self._add_delta(-other)
             elif is_integer(other):
                 return self.shift(-other)
-            elif isinstance(other, (tslib.Timestamp, datetime)):
+            elif isinstance(other, (Timestamp, datetime)):
                 return self._sub_datelike(other)
-            elif isinstance(other, prlib.Period):
+            elif isinstance(other, Period):
                 return self._sub_period(other)
             else:  # pragma: no cover
                 return NotImplemented
@@ -699,11 +701,11 @@ class DatetimeIndexOpsMixin(object):
         # add a delta of a timedeltalike
         # return the i8 result view
 
-        inc = tslib._delta_to_nanoseconds(other)
+        inc = libts._delta_to_nanoseconds(other)
         new_values = checked_add_with_arr(self.asi8, inc,
                                           arr_mask=self._isnan).view('i8')
         if self.hasnans:
-            new_values[self._isnan] = tslib.iNaT
+            new_values[self._isnan] = iNaT
         return new_values.view('i8')
 
     def _add_delta_tdi(self, other):
@@ -721,7 +723,7 @@ class DatetimeIndexOpsMixin(object):
                                           b_mask=other._isnan)
         if self.hasnans or other.hasnans:
             mask = (self._isnan) | (other._isnan)
-            new_values[mask] = tslib.iNaT
+            new_values[mask] = iNaT
         return new_values.view(self.dtype)
 
     def isin(self, values):
@@ -849,7 +851,7 @@ class DatetimeIndexOpsMixin(object):
 def _ensure_datetimelike_to_i8(other):
     """ helper for coercing an input scalar or array to i8 """
     if lib.isscalar(other) and isnull(other):
-        other = tslib.iNaT
+        other = iNaT
     elif isinstance(other, ABCIndexClass):
         # convert tz if needed
         if getattr(other, 'tz', None) is not None:
diff --git a/pandas/tseries/common.py b/pandas/tseries/common.py
index 46e8bd43e..82fcdbcd0 100644
--- a/pandas/tseries/common.py
+++ b/pandas/tseries/common.py
@@ -13,10 +13,9 @@ from pandas.types.common import (_NS_DTYPE, _TD_DTYPE,
 
 from pandas.core.base import PandasDelegate, NoNewAttributesMixin
 from pandas.tseries.index import DatetimeIndex
-from pandas._period import IncompatibleFrequency    # flake8: noqa
+from pandas._libs.period import IncompatibleFrequency    # flake8: noqa
 from pandas.tseries.period import PeriodIndex
 from pandas.tseries.tdi import TimedeltaIndex
-from pandas import tslib
 from pandas.core.algorithms import take_1d
 
 
diff --git a/pandas/tseries/converter.py b/pandas/tseries/converter.py
index db7049ebc..1f99e88ce 100644
--- a/pandas/tseries/converter.py
+++ b/pandas/tseries/converter.py
@@ -20,7 +20,7 @@ from pandas.types.common import (is_float, is_integer,
 
 from pandas.compat import lrange
 import pandas.compat as compat
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas.core.common as com
 from pandas.core.index import Index
 
diff --git a/pandas/tseries/frequencies.py b/pandas/tseries/frequencies.py
index 957a934d1..8013947ba 100644
--- a/pandas/tseries/frequencies.py
+++ b/pandas/tseries/frequencies.py
@@ -17,9 +17,9 @@ from pandas.core.algorithms import unique
 from pandas.tseries.offsets import DateOffset
 from pandas.util.decorators import cache_readonly, deprecate_kwarg
 import pandas.tseries.offsets as offsets
-import pandas.lib as lib
-import pandas.tslib as tslib
-from pandas.tslib import Timedelta
+
+from pandas._libs import lib, tslib
+from pandas._libs.tslib import Timedelta
 from pytz import AmbiguousTimeError
 
 
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 5f00e8b64..f80618ef3 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -44,13 +44,9 @@ import pandas.core.common as com
 import pandas.tseries.offsets as offsets
 import pandas.tseries.tools as tools
 
-from pandas.lib import Timestamp
-import pandas.lib as lib
-import pandas.tslib as tslib
-import pandas._period as period
-import pandas._join as _join
-import pandas.algos as _algos
-import pandas.index as _index
+from pandas._libs import (lib, index as libindex, tslib as libts,
+                          algos as libalgos, join as libjoin,
+                          Timestamp, period as libperiod)
 
 
 def _utc():
@@ -75,16 +71,16 @@ def _field_accessor(name, field, docstring=None):
                                            self.freq.kwds.get('month', 12))
                         if self.freq else 12)
 
-            result = tslib.get_start_end_field(values, field, self.freqstr,
+            result = libts.get_start_end_field(values, field, self.freqstr,
                                                month_kw)
         elif field in ['weekday_name']:
-            result = tslib.get_date_name_field(values, field)
+            result = libts.get_date_name_field(values, field)
             return self._maybe_mask_results(result)
         elif field in ['is_leap_year']:
             # no need to mask NaT
-            return tslib.get_date_field(values, field)
+            return libts.get_date_field(values, field)
         else:
-            result = tslib.get_date_field(values, field)
+            result = libts.get_date_field(values, field)
 
         return self._maybe_mask_results(result, convert='float64')
 
@@ -115,9 +111,9 @@ def _dt_index_cmp(opname, nat_result=False):
             result = _values_from_object(result)
 
             if isinstance(other, Index):
-                o_mask = other.values.view('i8') == tslib.iNaT
+                o_mask = other.values.view('i8') == libts.iNaT
             else:
-                o_mask = other.view('i8') == tslib.iNaT
+                o_mask = other.view('i8') == libts.iNaT
 
             if o_mask.any():
                 result[o_mask] = nat_result
@@ -211,11 +207,11 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         return DatetimeIndexOpsMixin._join_i8_wrapper(joinf, dtype='M8[ns]',
                                                       **kwargs)
 
-    _inner_indexer = _join_i8_wrapper(_join.inner_join_indexer_int64)
-    _outer_indexer = _join_i8_wrapper(_join.outer_join_indexer_int64)
-    _left_indexer = _join_i8_wrapper(_join.left_join_indexer_int64)
+    _inner_indexer = _join_i8_wrapper(libjoin.inner_join_indexer_int64)
+    _outer_indexer = _join_i8_wrapper(libjoin.outer_join_indexer_int64)
+    _left_indexer = _join_i8_wrapper(libjoin.left_join_indexer_int64)
     _left_indexer_unique = _join_i8_wrapper(
-        _join.left_join_indexer_unique_int64, with_indexers=False)
+        libjoin.left_join_indexer_unique_int64, with_indexers=False)
     _arrmap = None
 
     __eq__ = _dt_index_cmp('__eq__')
@@ -225,7 +221,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
     __le__ = _dt_index_cmp('__le__')
     __ge__ = _dt_index_cmp('__ge__')
 
-    _engine_type = _index.DatetimeEngine
+    _engine_type = libindex.DatetimeEngine
 
     tz = None
     offset = None
@@ -340,7 +336,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                     verify_integrity = False
             else:
                 if data.dtype != _NS_DTYPE:
-                    subarr = tslib.cast_to_nanoseconds(data)
+                    subarr = libts.cast_to_nanoseconds(data)
                 else:
                     subarr = data
         else:
@@ -356,13 +352,13 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                 tz = subarr.tz
         else:
             if tz is not None:
-                tz = tslib.maybe_get_tz(tz)
+                tz = libts.maybe_get_tz(tz)
 
                 if (not isinstance(data, DatetimeIndex) or
                         getattr(data, 'tz', None) is None):
                     # Convert tz-naive to UTC
                     ints = subarr.view('i8')
-                    subarr = tslib.tz_localize_to_utc(ints, tz,
+                    subarr = libts.tz_localize_to_utc(ints, tz,
                                                       ambiguous=ambiguous)
                 subarr = subarr.view(_NS_DTYPE)
 
@@ -430,17 +426,17 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
             raise TypeError('Start and end cannot both be tz-aware with '
                             'different timezones')
 
-        inferred_tz = tslib.maybe_get_tz(inferred_tz)
+        inferred_tz = libts.maybe_get_tz(inferred_tz)
 
         # these may need to be localized
-        tz = tslib.maybe_get_tz(tz)
+        tz = libts.maybe_get_tz(tz)
         if tz is not None:
             date = start or end
             if date.tzinfo is not None and hasattr(tz, 'localize'):
                 tz = tz.localize(date.replace(tzinfo=None)).tzinfo
 
         if tz is not None and inferred_tz is not None:
-            if not tslib.get_timezone(inferred_tz) == tslib.get_timezone(tz):
+            if not libts.get_timezone(inferred_tz) == libts.get_timezone(tz):
                 raise AssertionError("Inferred time zone not equal to passed "
                                      "time zone")
 
@@ -507,7 +503,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                 index = _generate_regular_range(start, end, periods, offset)
 
             if tz is not None and getattr(index, 'tz', None) is None:
-                index = tslib.tz_localize_to_utc(_ensure_int64(index), tz,
+                index = libts.tz_localize_to_utc(_ensure_int64(index), tz,
                                                  ambiguous=ambiguous)
                 index = index.view(_NS_DTYPE)
 
@@ -539,11 +535,11 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         utc = _utc()
 
         if self.is_monotonic:
-            return tslib.tz_convert(self.asi8, utc, self.tz)
+            return libts.tz_convert(self.asi8, utc, self.tz)
         else:
             values = self.asi8
             indexer = values.argsort()
-            result = tslib.tz_convert(values.take(indexer), utc, self.tz)
+            result = libts.tz_convert(values.take(indexer), utc, self.tz)
 
             n = len(indexer)
             reverse = np.empty(n, dtype=np.int_)
@@ -576,7 +572,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         result._data = values
         result.name = name
         result.offset = freq
-        result.tz = tslib.maybe_get_tz(tz)
+        result.tz = libts.maybe_get_tz(tz)
         result._reset_identity()
         return result
 
@@ -590,7 +586,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
     @cache_readonly
     def _timezone(self):
         """ Comparable timezone both for pytz / dateutil"""
-        return tslib.get_timezone(self.tzinfo)
+        return libts.get_timezone(self.tzinfo)
 
     def _has_same_tz(self, other):
         zzone = self._timezone
@@ -599,7 +595,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         if isinstance(other, np.datetime64):
             # convert to Timestamp as np.datetime64 doesn't have tz attr
             other = Timestamp(other)
-        vzone = tslib.get_timezone(getattr(other, 'tzinfo', '__no_tz__'))
+        vzone = libts.get_timezone(getattr(other, 'tzinfo', '__no_tz__'))
         return zzone == vzone
 
     @classmethod
@@ -671,7 +667,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
 
     def _mpl_repr(self):
         # how to represent ourselves to matplotlib
-        return tslib.ints_to_pydatetime(self.asi8, self.tz)
+        return libts.ints_to_pydatetime(self.asi8, self.tz)
 
     @cache_readonly
     def _is_dates_only(self):
@@ -728,7 +724,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
 
     def _add_datelike(self, other):
         # adding a timedeltaindex to a datetimelike
-        if other is tslib.NaT:
+        if other is libts.NaT:
             return self._nat_new(box=True)
         raise TypeError("cannot add a datelike to a DatetimeIndex")
 
@@ -741,9 +737,9 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                 raise TypeError("DatetimeIndex subtraction must have the same "
                                 "timezones or no timezones")
             result = self._sub_datelike_dti(other)
-        elif isinstance(other, (tslib.Timestamp, datetime)):
+        elif isinstance(other, (libts.Timestamp, datetime)):
             other = Timestamp(other)
-            if other is tslib.NaT:
+            if other is libts.NaT:
                 result = self._nat_new(box=False)
             # require tz compat
             elif not self._has_same_tz(other):
@@ -753,7 +749,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                 i8 = self.asi8
                 result = i8 - other.value
                 result = self._maybe_mask_results(result,
-                                                  fill_value=tslib.iNaT)
+                                                  fill_value=libts.iNaT)
         else:
             raise TypeError("cannot subtract DatetimeIndex and {typ}"
                             .format(typ=type(other).__name__))
@@ -769,7 +765,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         new_values = self_i8 - other_i8
         if self.hasnans or other.hasnans:
             mask = (self._isnan) | (other._isnan)
-            new_values[mask] = tslib.iNaT
+            new_values[mask] = libts.iNaT
         return new_values.view('i8')
 
     def _maybe_update_attributes(self, attrs):
@@ -822,7 +818,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         from pandas.formats.format import _get_format_datetime64_from_values
         format = _get_format_datetime64_from_values(self, date_format)
 
-        return tslib.format_array_from_datetime(self.asi8,
+        return libts.format_array_from_datetime(self.asi8,
                                                 tz=self.tz,
                                                 format=format,
                                                 na_rep=na_rep)
@@ -855,7 +851,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         values = self.asi8
         if self.tz is not None and self.tz is not utc:
             values = self._local_timestamps()
-        return tslib.get_time_micros(values)
+        return libts.get_time_micros(values)
 
     def to_series(self, keep_tz=False):
         """
@@ -908,7 +904,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         -------
         datetimes : ndarray
         """
-        return tslib.ints_to_pydatetime(self.asi8, tz=self.tz)
+        return libts.ints_to_pydatetime(self.asi8, tz=self.tz)
 
     def to_period(self, freq=None):
         """
@@ -1160,7 +1156,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         for i in range(chunks):
             start_i = i * chunksize
             end_i = min((i + 1) * chunksize, l)
-            converted = tslib.ints_to_pydatetime(data[start_i:end_i],
+            converted = libts.ints_to_pydatetime(data[start_i:end_i],
                                                  tz=self.tz, freq=self.freq,
                                                  box=True)
             for v in converted:
@@ -1248,14 +1244,14 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                     Timestamp(datetime(parsed.year, 12, 31, 23,
                                        59, 59, 999999), tz=self.tz))
         elif reso == 'month':
-            d = tslib.monthrange(parsed.year, parsed.month)[1]
+            d = libts.monthrange(parsed.year, parsed.month)[1]
             return (Timestamp(datetime(parsed.year, parsed.month, 1),
                               tz=self.tz),
                     Timestamp(datetime(parsed.year, parsed.month, d, 23,
                                        59, 59, 999999), tz=self.tz))
         elif reso == 'quarter':
             qe = (((parsed.month - 1) + 2) % 12) + 1  # two months ahead
-            d = tslib.monthrange(parsed.year, qe)[1]   # at end of month
+            d = libts.monthrange(parsed.year, qe)[1]   # at end of month
             return (Timestamp(datetime(parsed.year, parsed.month, 1),
                               tz=self.tz),
                     Timestamp(datetime(parsed.year, qe, d, 23, 59,
@@ -1594,9 +1590,9 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         """
         Returns numpy array of datetime.time. The time part of the Timestamps.
         """
-        return self._maybe_mask_results(_algos.arrmap_object(
+        return self._maybe_mask_results(libalgos.arrmap_object(
             self.asobject.values,
-            lambda x: np.nan if x is tslib.NaT else x.time()))
+            lambda x: np.nan if x is libts.NaT else x.time()))
 
     @property
     def date(self):
@@ -1604,7 +1600,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         Returns numpy array of python datetime.date objects (namely, the date
         part of Timestamps without timezone information).
         """
-        return self._maybe_mask_results(_algos.arrmap_object(
+        return self._maybe_mask_results(libalgos.arrmap_object(
             self.asobject.values, lambda x: x.date()))
 
     def normalize(self):
@@ -1615,7 +1611,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         -------
         normalized : DatetimeIndex
         """
-        new_values = tslib.date_normalize(self.asi8, self.tz)
+        new_values = libts.date_normalize(self.asi8, self.tz)
         return DatetimeIndex(new_values, freq='infer', name=self.name,
                              tz=self.tz)
 
@@ -1654,11 +1650,11 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         """
         Returns True if all of the dates are at midnight ("no time")
         """
-        return tslib.dates_normalized(self.asi8, self.tz)
+        return libts.dates_normalized(self.asi8, self.tz)
 
     @cache_readonly
     def _resolution(self):
-        return period.resolution(self.asi8, self.tz)
+        return libperiod.resolution(self.asi8, self.tz)
 
     def insert(self, loc, item):
         """
@@ -1695,7 +1691,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
             new_dates = np.concatenate((self[:loc].asi8, [item.view(np.int64)],
                                         self[loc:].asi8))
             if self.tz is not None:
-                new_dates = tslib.tz_convert(new_dates, 'UTC', self.tz)
+                new_dates = libts.tz_convert(new_dates, 'UTC', self.tz)
             return DatetimeIndex(new_dates, name=self.name, freq=freq,
                                  tz=self.tz)
 
@@ -1735,7 +1731,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
                     freq = self.freq
 
         if self.tz is not None:
-            new_dates = tslib.tz_convert(new_dates, 'UTC', self.tz)
+            new_dates = libts.tz_convert(new_dates, 'UTC', self.tz)
         return DatetimeIndex(new_dates, name=self.name, freq=freq, tz=self.tz)
 
     def tz_convert(self, tz):
@@ -1759,7 +1755,7 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         TypeError
             If DatetimeIndex is tz-naive.
         """
-        tz = tslib.maybe_get_tz(tz)
+        tz = libts.maybe_get_tz(tz)
 
         if self.tz is None:
             # tz naive, use tz_localize
@@ -1814,14 +1810,14 @@ class DatetimeIndex(DatelikeOps, TimelikeOps, DatetimeIndexOpsMixin,
         """
         if self.tz is not None:
             if tz is None:
-                new_dates = tslib.tz_convert(self.asi8, 'UTC', self.tz)
+                new_dates = libts.tz_convert(self.asi8, 'UTC', self.tz)
             else:
                 raise TypeError("Already tz-aware, use tz_convert to convert.")
         else:
-            tz = tslib.maybe_get_tz(tz)
+            tz = libts.maybe_get_tz(tz)
             # Convert to UTC
 
-            new_dates = tslib.tz_localize_to_utc(self.asi8, tz,
+            new_dates = libts.tz_localize_to_utc(self.asi8, tz,
                                                  ambiguous=ambiguous,
                                                  errors=errors)
         new_dates = new_dates.view(_NS_DTYPE)
@@ -2134,7 +2130,7 @@ def _to_m8(key, tz=None):
         # this also converts strings
         key = Timestamp(key, tz=tz)
 
-    return np.int64(tslib.pydt_to_i8(key)).view(_NS_DTYPE)
+    return np.int64(libts.pydt_to_i8(key)).view(_NS_DTYPE)
 
 
 _CACHE_START = Timestamp(datetime(1950, 1, 1))
diff --git a/pandas/tseries/offsets.py b/pandas/tseries/offsets.py
index 79227f6de..2b6a684fc 100644
--- a/pandas/tseries/offsets.py
+++ b/pandas/tseries/offsets.py
@@ -10,8 +10,7 @@ from pandas.core.common import AbstractMethodError
 # import after tools, dateutil check
 from dateutil.relativedelta import relativedelta, weekday
 from dateutil.easter import easter
-import pandas.tslib as tslib
-from pandas.tslib import Timestamp, OutOfBoundsDatetime, Timedelta
+from pandas._libs import tslib, Timestamp, OutOfBoundsDatetime, Timedelta
 
 import functools
 import operator
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index bfe7724a1..f7e9ba9ea 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -29,10 +29,11 @@ from pandas.tseries.base import DatelikeOps, DatetimeIndexOpsMixin
 from pandas.tseries.tools import parse_time_string
 import pandas.tseries.offsets as offsets
 
-import pandas._period as period
-from pandas._period import (Period, IncompatibleFrequency,
-                            get_period_field_arr, _validate_end_alias,
-                            _quarter_to_myear)
+from pandas._libs.lib import infer_dtype
+from pandas._libs import tslib, period
+from pandas._libs.period import (Period, IncompatibleFrequency,
+                                 get_period_field_arr, _validate_end_alias,
+                                 _quarter_to_myear)
 
 from pandas.core.base import _shared_docs
 from pandas.indexes.base import _index_shared_docs, _ensure_index
@@ -40,9 +41,8 @@ from pandas.indexes.base import _index_shared_docs, _ensure_index
 from pandas import compat
 from pandas.util.decorators import (Appender, Substitution, cache_readonly,
                                     deprecate_kwarg)
-from pandas.lib import infer_dtype
-import pandas.tslib as tslib
 from pandas.compat import zip, u
+
 import pandas.indexes.base as ibase
 _index_doc_kwargs = dict(ibase._index_doc_kwargs)
 _index_doc_kwargs.update(
diff --git a/pandas/tseries/resample.py b/pandas/tseries/resample.py
index 21d7dc0c1..2856b54ad 100755
--- a/pandas/tseries/resample.py
+++ b/pandas/tseries/resample.py
@@ -20,10 +20,9 @@ import pandas.core.algorithms as algos
 import pandas.compat as compat
 from pandas.compat.numpy import function as nv
 
-from pandas.lib import Timestamp
-from pandas._period import IncompatibleFrequency
-import pandas.lib as lib
-import pandas.tslib as tslib
+from pandas._libs import lib, tslib
+from pandas._libs.lib import Timestamp
+from pandas._libs.period import IncompatibleFrequency
 
 from pandas.util.decorators import Appender
 from pandas.core.generic import _shared_docs
diff --git a/pandas/tseries/tdi.py b/pandas/tseries/tdi.py
index c62e3fc40..f47d80a31 100644
--- a/pandas/tseries/tdi.py
+++ b/pandas/tseries/tdi.py
@@ -30,13 +30,8 @@ from pandas.tseries.base import TimelikeOps, DatetimeIndexOpsMixin
 from pandas.tseries.timedeltas import (to_timedelta,
                                        _coerce_scalar_to_timedelta_type)
 from pandas.tseries.offsets import Tick, DateOffset
-
-import pandas.lib as lib
-import pandas.tslib as tslib
-import pandas._join as _join
-import pandas.index as _index
-
-Timedelta = tslib.Timedelta
+from pandas._libs import (lib, index as libindex, tslib as libts,
+                          join as libjoin, Timedelta, NaT, iNaT)
 
 
 def _td_index_cmp(opname, nat_result=False):
@@ -47,7 +42,7 @@ def _td_index_cmp(opname, nat_result=False):
     def wrapper(self, other):
         msg = "cannot compare a TimedeltaIndex with type {0}"
         func = getattr(super(TimedeltaIndex, self), opname)
-        if _is_convertible_to_td(other) or other is tslib.NaT:
+        if _is_convertible_to_td(other) or other is NaT:
             try:
                 other = _to_m8(other)
             except ValueError:
@@ -65,9 +60,9 @@ def _td_index_cmp(opname, nat_result=False):
             result = _values_from_object(result)
 
             if isinstance(other, Index):
-                o_mask = other.values.view('i8') == tslib.iNaT
+                o_mask = other.values.view('i8') == iNaT
             else:
-                o_mask = other.view('i8') == tslib.iNaT
+                o_mask = other.view('i8') == iNaT
 
             if o_mask.any():
                 result[o_mask] = nat_result
@@ -126,11 +121,11 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         return DatetimeIndexOpsMixin._join_i8_wrapper(
             joinf, dtype='m8[ns]', **kwargs)
 
-    _inner_indexer = _join_i8_wrapper(_join.inner_join_indexer_int64)
-    _outer_indexer = _join_i8_wrapper(_join.outer_join_indexer_int64)
-    _left_indexer = _join_i8_wrapper(_join.left_join_indexer_int64)
+    _inner_indexer = _join_i8_wrapper(libjoin.inner_join_indexer_int64)
+    _outer_indexer = _join_i8_wrapper(libjoin.outer_join_indexer_int64)
+    _left_indexer = _join_i8_wrapper(libjoin.left_join_indexer_int64)
     _left_indexer_unique = _join_i8_wrapper(
-        _join.left_join_indexer_unique_int64, with_indexers=False)
+        libjoin.left_join_indexer_unique_int64, with_indexers=False)
     _arrmap = None
     _datetimelike_ops = ['days', 'seconds', 'microseconds', 'nanoseconds',
                          'freq', 'components']
@@ -142,7 +137,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     __le__ = _td_index_cmp('__le__')
     __ge__ = _td_index_cmp('__ge__')
 
-    _engine_type = _index.TimedeltaEngine
+    _engine_type = libindex.TimedeltaEngine
 
     _comparables = ['name', 'freq']
     _attributes = ['name', 'freq']
@@ -274,7 +269,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     def _simple_new(cls, values, name=None, freq=None, **kwargs):
         values = np.array(values, copy=False)
         if values.dtype == np.object_:
-            values = tslib.array_to_timedelta64(values)
+            values = libts.array_to_timedelta64(values)
         if values.dtype != _TD_DTYPE:
             values = _ensure_int64(values).view(_TD_DTYPE)
 
@@ -341,18 +336,18 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     def _add_datelike(self, other):
         # adding a timedeltaindex to a datetimelike
         from pandas import Timestamp, DatetimeIndex
-        if other is tslib.NaT:
+        if other is NaT:
             result = self._nat_new(box=False)
         else:
             other = Timestamp(other)
             i8 = self.asi8
             result = checked_add_with_arr(i8, other.value)
-            result = self._maybe_mask_results(result, fill_value=tslib.iNaT)
+            result = self._maybe_mask_results(result, fill_value=iNaT)
         return DatetimeIndex(result, name=self.name, copy=False)
 
     def _sub_datelike(self, other):
         from pandas import DatetimeIndex
-        if other is tslib.NaT:
+        if other is NaT:
             result = self._nat_new(box=False)
         else:
             raise TypeError("cannot subtract a datelike from a TimedeltaIndex")
@@ -452,7 +447,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
         -------
         datetimes : ndarray
         """
-        return tslib.ints_to_pytimedelta(self.asi8)
+        return libts.ints_to_pytimedelta(self.asi8)
 
     @Appender(_index_shared_docs['astype'])
     def astype(self, dtype, copy=True):
@@ -677,7 +672,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
             raise TypeError
 
         if isnull(key):
-            key = tslib.NaT
+            key = NaT
 
         if tolerance is not None:
             # try converting tolerance now, so errors don't get swallowed by
@@ -736,7 +731,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
     def _get_string_slice(self, key, use_lhs=True, use_rhs=True):
         freq = getattr(self, 'freqstr',
                        getattr(self, 'inferred_freq', None))
-        if is_integer(key) or is_float(key) or key is tslib.NaT:
+        if is_integer(key) or is_float(key) or key is NaT:
             self._invalid_indexer('slice', key)
         loc = self._partial_td_slice(key, freq, use_lhs=use_lhs,
                                      use_rhs=use_rhs)
@@ -837,7 +832,7 @@ class TimedeltaIndex(DatetimeIndexOpsMixin, TimelikeOps, Int64Index):
                 pass
 
         freq = None
-        if isinstance(item, (Timedelta, tslib.NaTType)):
+        if isinstance(item, (Timedelta, libts.NaTType)):
 
             # check freq can be preserved on edge cases
             if self.freq is not None:
diff --git a/pandas/tseries/timedeltas.py b/pandas/tseries/timedeltas.py
index 5a5d1533b..ead602ee8 100644
--- a/pandas/tseries/timedeltas.py
+++ b/pandas/tseries/timedeltas.py
@@ -4,7 +4,7 @@ timedelta support tools
 
 import numpy as np
 import pandas as pd
-import pandas.tslib as tslib
+import pandas._libs.tslib as tslib
 
 from pandas.types.common import (_ensure_object,
                                  is_integer_dtype,
diff --git a/pandas/tseries/tools.py b/pandas/tseries/tools.py
index f746409aa..093331e86 100644
--- a/pandas/tseries/tools.py
+++ b/pandas/tseries/tools.py
@@ -2,8 +2,7 @@ from datetime import datetime, timedelta, time
 import numpy as np
 from collections import MutableMapping
 
-import pandas.lib as lib
-import pandas.tslib as tslib
+from pandas._libs import lib, tslib
 
 from pandas.types.common import (_ensure_object,
                                  is_datetime64_ns_dtype,
diff --git a/pandas/tslib.py b/pandas/tslib.py
new file mode 100644
index 000000000..3ecbffa20
--- /dev/null
+++ b/pandas/tslib.py
@@ -0,0 +1,8 @@
+# flake8: noqa
+
+import warnings
+warnings.warn("The pandas.tslib module is deprecated and will be "
+              "removed in a future version. Please import from "
+              "the pandas._libs.tslib instead", FutureWarning, stacklevel=2)
+from pandas._libs.tslib import (Timestamp, Timedelta,
+                               NaT, OutOfBoundsDatetime)
diff --git a/pandas/types/cast.py b/pandas/types/cast.py
index 8cc3fe41f..1cd55274b 100644
--- a/pandas/types/cast.py
+++ b/pandas/types/cast.py
@@ -2,8 +2,8 @@
 
 from datetime import datetime, timedelta
 import numpy as np
-from pandas import lib, tslib
-from pandas.tslib import iNaT
+from pandas._libs import tslib, lib
+from pandas._libs.tslib import iNaT
 from pandas.compat import string_types, text_type, PY3
 from .common import (_ensure_object, is_bool, is_integer, is_float,
                      is_complex, is_datetimetz, is_categorical_dtype,
@@ -807,14 +807,14 @@ def _possibly_cast_to_datetime(value, dtype, errors='raise'):
                                     "dtype [%s]" % dtype)
 
             if is_scalar(value):
-                if value == tslib.iNaT or isnull(value):
-                    value = tslib.iNaT
+                if value == iNaT or isnull(value):
+                    value = iNaT
             else:
                 value = np.array(value, copy=False)
 
                 # have a scalar array-like (e.g. NaT)
                 if value.ndim == 0:
-                    value = tslib.iNaT
+                    value = iNaT
 
                 # we have an array of datetime or timedeltas & nulls
                 elif np.prod(value.shape) or not is_dtype_equal(value.dtype,
diff --git a/pandas/types/common.py b/pandas/types/common.py
index e58e0826e..1be5b5f6f 100644
--- a/pandas/types/common.py
+++ b/pandas/types/common.py
@@ -3,7 +3,7 @@
 import numpy as np
 from pandas.compat import (string_types, text_type, binary_type,
                            PY3, PY36)
-from pandas import lib, algos
+from pandas._libs import algos, lib
 from .dtypes import (CategoricalDtype, CategoricalDtypeType,
                      DatetimeTZDtype, DatetimeTZDtypeType,
                      PeriodDtype, PeriodDtypeType,
diff --git a/pandas/types/concat.py b/pandas/types/concat.py
index 9e47a97dd..b098bbb75 100644
--- a/pandas/types/concat.py
+++ b/pandas/types/concat.py
@@ -3,7 +3,7 @@ Utility functions related to concat
 """
 
 import numpy as np
-import pandas.tslib as tslib
+import pandas._libs.tslib as tslib
 from pandas import compat
 from pandas.core.algorithms import take_1d
 from .common import (is_categorical_dtype,
diff --git a/pandas/types/inference.py b/pandas/types/inference.py
index d2a2924b2..d8e3b3ee7 100644
--- a/pandas/types/inference.py
+++ b/pandas/types/inference.py
@@ -6,7 +6,7 @@ import numpy as np
 from numbers import Number
 from pandas.compat import (string_types, text_type,
                            string_and_binary_types)
-from pandas import lib
+from pandas._libs import lib
 
 is_bool = lib.is_bool
 
diff --git a/pandas/types/missing.py b/pandas/types/missing.py
index e6791b79b..cc8b5edc2 100644
--- a/pandas/types/missing.py
+++ b/pandas/types/missing.py
@@ -2,8 +2,8 @@
 missing types & inference
 """
 import numpy as np
-from pandas import lib
-from pandas.tslib import NaT, iNaT
+from pandas._libs import lib
+from pandas._libs.tslib import NaT, iNaT
 from .generic import (ABCMultiIndex, ABCSeries,
                       ABCIndexClass, ABCGeneric)
 from .common import (is_string_dtype, is_datetimelike,
diff --git a/pandas/util/decorators.py b/pandas/util/decorators.py
index 62ff6ef14..4e1719958 100644
--- a/pandas/util/decorators.py
+++ b/pandas/util/decorators.py
@@ -1,5 +1,5 @@
 from pandas.compat import StringIO, callable, signature
-from pandas.lib import cache_readonly  # noqa
+from pandas._libs.lib import cache_readonly  # noqa
 import types
 import sys
 import warnings
diff --git a/pandas/util/depr_module.py b/pandas/util/depr_module.py
index cf8b0f796..b181c4627 100644
--- a/pandas/util/depr_module.py
+++ b/pandas/util/depr_module.py
@@ -13,12 +13,15 @@ class _DeprecatedModule(object):
     Parameters
     ----------
     deprmod : name of module to be deprecated.
+    deprmodto : name of module as a replacement, optional
+        if not givent will __module__
     removals : objects or methods in module that will no longer be
                accessible once module is removed.
     """
 
-    def __init__(self, deprmod, removals=None):
+    def __init__(self, deprmod, deprmodto=None, removals=None):
         self.deprmod = deprmod
+        self.deprmodto = deprmodto
         self.removals = removals
         if self.removals is not None:
             self.removals = frozenset(self.removals)
@@ -40,7 +43,15 @@ class _DeprecatedModule(object):
         if name in self.self_dir:
             return object.__getattribute__(self, name)
 
-        deprmodule = self._import_deprmod()
+        try:
+            deprmodule = self._import_deprmod(self.deprmod)
+        except ImportError:
+            if self.deprmodto is None:
+                raise
+
+            # a rename
+            deprmodule = self._import_deprmod(self.deprmodto)
+
         obj = getattr(deprmodule, name)
 
         if self.removals is not None and name in self.removals:
@@ -49,17 +60,24 @@ class _DeprecatedModule(object):
                 "a future version.".format(deprmod=self.deprmod, name=name),
                 FutureWarning, stacklevel=2)
         else:
+            deprmodto = self.deprmodto
+            if deprmodto is None:
+                deprmodto = "{modname}.{name}".format(
+                    modname=obj.__module__, name=name)
             # The object is actually located in another module.
             warnings.warn(
                 "{deprmod}.{name} is deprecated. Please use "
-                "{modname}.{name} instead.".format(
-                    deprmod=self.deprmod, modname=obj.__module__, name=name),
+                "{deprmodto}.{name} instead.".format(
+                    deprmod=self.deprmod, name=name, deprmodto=deprmodto),
                 FutureWarning, stacklevel=2)
 
         return obj
 
-    def _import_deprmod(self):
+    def _import_deprmod(self, mod=None):
+        if mod is None:
+            mod = self.deprmod
+
         with warnings.catch_warnings():
             warnings.filterwarnings('ignore', category=FutureWarning)
-            deprmodule = importlib.import_module(self.deprmod)
+            deprmodule = importlib.import_module(mod)
             return deprmodule
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index c5e5df903..b68bf55a3 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -47,7 +47,7 @@ from pandas import (bdate_range, CategoricalIndex, Categorical, DatetimeIndex,
                     TimedeltaIndex, PeriodIndex, RangeIndex, Index, MultiIndex,
                     Series, DataFrame, Panel, Panel4D)
 from pandas.util.decorators import deprecate
-from pandas import _testing
+from pandas.util import libtesting
 from pandas.io.common import urlopen
 slow = pytest.mark.slow
 
@@ -173,7 +173,7 @@ def assert_almost_equal(left, right, check_exact=False,
                 else:
                     obj = 'Input'
                 assert_class_equal(left, right, obj=obj)
-        return _testing.assert_almost_equal(
+        return libtesting.assert_almost_equal(
             left, right,
             check_dtype=check_dtype,
             check_less_precise=check_less_precise,
@@ -185,7 +185,7 @@ def assert_dict_equal(left, right, compare_keys=True):
     assertIsInstance(left, dict, '[dict] ')
     assertIsInstance(right, dict, '[dict] ')
 
-    return _testing.assert_dict_equal(left, right, compare_keys=compare_keys)
+    return libtesting.assert_dict_equal(left, right, compare_keys=compare_keys)
 
 
 def randbool(size=(), p=0.5):
@@ -833,10 +833,10 @@ def assert_index_equal(left, right, exact='equiv', check_names=True,
                 .format(obj, np.round(diff, 5))
             raise_assert_detail(obj, msg, left, right)
     else:
-        _testing.assert_almost_equal(left.values, right.values,
-                                     check_less_precise=check_less_precise,
-                                     check_dtype=exact,
-                                     obj=obj, lobj=left, robj=right)
+        libtesting.assert_almost_equal(left.values, right.values,
+                                       check_less_precise=check_less_precise,
+                                       check_dtype=exact,
+                                       obj=obj, lobj=left, robj=right)
 
     # metadata comparison
     if check_names:
@@ -1213,10 +1213,10 @@ def assert_series_equal(left, right, check_dtype=True,
             assert_numpy_array_equal(left.get_values(), right.get_values(),
                                      check_dtype=check_dtype)
     else:
-        _testing.assert_almost_equal(left.get_values(), right.get_values(),
-                                     check_less_precise=check_less_precise,
-                                     check_dtype=check_dtype,
-                                     obj='{0}'.format(obj))
+        libtesting.assert_almost_equal(left.get_values(), right.get_values(),
+                                       check_less_precise=check_less_precise,
+                                       check_dtype=check_dtype,
+                                       obj='{0}'.format(obj))
 
     # metadata comparison
     if check_names:
@@ -1432,8 +1432,10 @@ def assert_sp_array_equal(left, right, check_dtype=True):
                              check_dtype=check_dtype)
 
     # SparseIndex comparison
-    assertIsInstance(left.sp_index, pd._sparse.SparseIndex, '[SparseIndex]')
-    assertIsInstance(right.sp_index, pd._sparse.SparseIndex, '[SparseIndex]')
+    assertIsInstance(left.sp_index,
+                     pd.sparse.libsparse.SparseIndex, '[SparseIndex]')
+    assertIsInstance(right.sp_index,
+                     pd.sparse.libsparse.SparseIndex, '[SparseIndex]')
 
     if not left.sp_index.equals(right.sp_index):
         raise_assert_detail('SparseArray.index', 'index are not equal',
diff --git a/pandas/src/testing.pyx b/pandas/util/testing.pyx
similarity index 100%
rename from pandas/src/testing.pyx
rename to pandas/util/testing.pyx
diff --git a/scripts/bench_join.py b/scripts/bench_join.py
index 1ce5c9413..f9d437727 100644
--- a/scripts/bench_join.py
+++ b/scripts/bench_join.py
@@ -1,6 +1,6 @@
 from pandas.compat import range, lrange
 import numpy as np
-import pandas.lib as lib
+import pandas._libs.lib as lib
 from pandas import *
 from copy import deepcopy
 import time
diff --git a/scripts/bench_join_multi.py b/scripts/bench_join_multi.py
index 7b93112b7..b19da6a2c 100644
--- a/scripts/bench_join_multi.py
+++ b/scripts/bench_join_multi.py
@@ -3,7 +3,7 @@ from pandas import *
 import numpy as np
 from pandas.compat import zip, range, lzip
 from pandas.util.testing import rands
-import pandas.lib as lib
+import pandas._libs.lib as lib
 
 N = 100000
 
diff --git a/scripts/groupby_test.py b/scripts/groupby_test.py
index 5acf7da75..f640a6ed7 100644
--- a/scripts/groupby_test.py
+++ b/scripts/groupby_test.py
@@ -5,7 +5,7 @@ import numpy as np
 
 from pandas import *
 
-import pandas.lib as tseries
+import pandas._libs.lib as tseries
 import pandas.core.groupby as gp
 import pandas.util.testing as tm
 from pandas.compat import range
diff --git a/scripts/roll_median_leak.py b/scripts/roll_median_leak.py
index 07161cc64..03f39e2b1 100644
--- a/scripts/roll_median_leak.py
+++ b/scripts/roll_median_leak.py
@@ -7,7 +7,7 @@ import os
 from vbench.api import Benchmark
 from pandas.util.testing import rands
 from pandas.compat import range
-import pandas.lib as lib
+import pandas._libs.lib as lib
 import pandas._sandbox as sbx
 import time
 
diff --git a/setup.py b/setup.py
index 525cbdf60..e257b2376 100755
--- a/setup.py
+++ b/setup.py
@@ -109,21 +109,21 @@ if cython:
 from os.path import join as pjoin
 
 
-_pxipath = pjoin('pandas', 'src')
 _pxi_dep_template = {
-    'algos': ['algos_common_helper.pxi.in', 'algos_groupby_helper.pxi.in',
-              'algos_take_helper.pxi.in', 'algos_rank_helper.pxi.in'],
-    '_reshape': ['reshape_helper.pxi.in'],
-    '_join': ['join_helper.pxi.in', 'joins_func_helper.pxi.in'],
-    'hashtable': ['hashtable_class_helper.pxi.in',
-                  'hashtable_func_helper.pxi.in'],
-    'index': ['index_class_helper.pxi.in'],
-    '_sparse': ['sparse_op_helper.pxi.in']
+    'algos': ['_libs/algos_common_helper.pxi.in', '_libs/algos_groupby_helper.pxi.in',
+              '_libs/algos_take_helper.pxi.in', '_libs/algos_rank_helper.pxi.in'],
+    'join': ['_libs/join_helper.pxi.in', '_libs/join_func_helper.pxi.in'],
+    'reshape': ['_libs/reshape_helper.pxi.in'],
+    'hashtable': ['_libs/hashtable_class_helper.pxi.in',
+                   '_libs/hashtable_func_helper.pxi.in'],
+    'index': ['_libs/index_class_helper.pxi.in'],
+    'sparse': ['sparse/sparse_op_helper.pxi.in'],
 }
+
 _pxifiles = []
 _pxi_dep = {}
 for module, files in _pxi_dep_template.items():
-    pxi_files = [pjoin(_pxipath, x) for x in files]
+    pxi_files = [pjoin('pandas', x) for x in files]
     _pxifiles.extend(pxi_files)
     _pxi_dep[module] = pxi_files
 
@@ -261,7 +261,7 @@ class CleanCommand(Command):
         self._clean_me = []
         self._clean_trees = []
 
-        base = pjoin('pandas','src')
+        base = pjoin('pandas','_libs', 'src')
         dt = pjoin(base,'datetime')
         src = base
         util = pjoin('pandas','util')
@@ -327,19 +327,19 @@ sdist_class = cmdclass['sdist']
 class CheckSDist(sdist_class):
     """Custom sdist that ensures Cython has compiled all pyx files to c."""
 
-    _pyxfiles = ['pandas/lib.pyx',
-                 'pandas/hashtable.pyx',
-                 'pandas/tslib.pyx',
-                 'pandas/index.pyx',
-                 'pandas/algos.pyx',
-                 'pandas/join.pyx',
-                 'pandas/window.pyx',
-                 'pandas/parser.pyx',
-                 'pandas/src/period.pyx',
-                 'pandas/src/sparse.pyx',
-                 'pandas/src/testing.pyx',
-                 'pandas/src/hash.pyx',
-                 'pandas/io/sas/saslib.pyx']
+    _pyxfiles = ['pandas/_libs/lib.pyx',
+                 'pandas/_libs/hashtable.pyx',
+                 'pandas/_libs/tslib.pyx',
+                 'pandas/_libs/period.pyx',
+                 'pandas/_libs/index.pyx',
+                 'pandas/_libs/algos.pyx',
+                 'pandas/_libs/join.pyx',
+                 'pandas/core/window.pyx',
+                 'pandas/sparse/sparse.pyx',
+                 'pandas/util/testing.pyx',
+                 'pandas/tools/hash.pyx',
+                 'pandas/io/parsers.pyx',
+                 'pandas/io/sas/sas.pyx']
 
     def initialize_options(self):
         sdist_class.initialize_options(self)
@@ -374,6 +374,7 @@ class CheckingBuildExt(build_ext):
         for ext in extensions:
             for src in ext.sources:
                 if not os.path.exists(src):
+                    print("{}: -> [{}]".format(ext.name, ext.sources))
                     raise Exception("""Cython-generated file '%s' not found.
                 Cython is required to compile pandas from a development branch.
                 Please install Cython or download a release package of pandas.
@@ -440,12 +441,12 @@ def srcpath(name=None, suffix='.pyx', subdir='src'):
 
 if suffix == '.pyx':
     lib_depends = [srcpath(f, suffix='.pyx') for f in lib_depends]
-    lib_depends.append('pandas/src/util.pxd')
+    lib_depends.append('pandas/_libs/src/util.pxd')
 else:
     lib_depends = []
     plib_depends = []
 
-common_include = ['pandas/src/klib', 'pandas/src']
+common_include = ['pandas/_libs/src/klib', 'pandas/_libs/src']
 
 
 def pxd(name):
@@ -457,71 +458,70 @@ if is_platform_windows():
 else:
     extra_compile_args=['-Wno-unused-function']
 
-lib_depends = lib_depends + ['pandas/src/numpy_helper.h',
-                             'pandas/src/parse_helper.h']
+lib_depends = lib_depends + ['pandas/_libs/src/numpy_helper.h',
+                             'pandas/_libs/src/parse_helper.h']
 
 
-tseries_depends = ['pandas/src/datetime/np_datetime.h',
-                   'pandas/src/datetime/np_datetime_strings.h',
-                   'pandas/src/datetime_helper.h',
-                   'pandas/src/period_helper.h',
-                   'pandas/src/datetime.pxd']
+tseries_depends = ['pandas/_libs/src/datetime/np_datetime.h',
+                   'pandas/_libs/src/datetime/np_datetime_strings.h',
+                   'pandas/_libs/src/datetime_helper.h',
+                   'pandas/_libs/src/period_helper.h',
+                   'pandas/_libs/src/datetime.pxd']
 
 
 # some linux distros require it
 libraries = ['m'] if not is_platform_windows() else []
 
-ext_data = dict(
-    lib={'pyxfile': 'lib',
-         'pxdfiles': [],
-         'depends': lib_depends},
-    hashtable={'pyxfile': 'hashtable',
-               'pxdfiles': ['hashtable'],
-               'depends': (['pandas/src/klib/khash_python.h']
-                           + _pxi_dep['hashtable'])},
-    tslib={'pyxfile': 'tslib',
-           'depends': tseries_depends,
-           'sources': ['pandas/src/datetime/np_datetime.c',
-                       'pandas/src/datetime/np_datetime_strings.c',
-                       'pandas/src/period_helper.c']},
-    _period={'pyxfile': 'src/period',
-             'depends': tseries_depends,
-             'sources': ['pandas/src/datetime/np_datetime.c',
-                         'pandas/src/datetime/np_datetime_strings.c',
-                         'pandas/src/period_helper.c']},
-    index={'pyxfile': 'index',
-           'sources': ['pandas/src/datetime/np_datetime.c',
-                       'pandas/src/datetime/np_datetime_strings.c'],
-           'pxdfiles': ['src/util', 'hashtable'],
-           'depends': _pxi_dep['index']},
-    algos={'pyxfile': 'algos',
-           'pxdfiles': ['src/util', 'hashtable'],
-           'depends': _pxi_dep['algos']},
-    _reshape={'pyxfile': 'src/reshape',
-              'depends': _pxi_dep['_reshape']},
-    _join={'pyxfile': 'src/join',
-           'pxdfiles': ['src/util', 'hashtable'],
-           'depends': _pxi_dep['_join']},
-    _window={'pyxfile': 'window',
-             'pxdfiles': ['src/skiplist', 'src/util'],
-             'depends': ['pandas/src/skiplist.pyx',
-                         'pandas/src/skiplist.h']},
-    parser={'pyxfile': 'parser',
-            'depends': ['pandas/src/parser/tokenizer.h',
-                        'pandas/src/parser/io.h',
-                        'pandas/src/numpy_helper.h'],
-            'sources': ['pandas/src/parser/tokenizer.c',
-                        'pandas/src/parser/io.c']},
-    _sparse={'pyxfile': 'src/sparse',
-             'depends': ([srcpath('sparse', suffix='.pyx')] +
-                         _pxi_dep['_sparse'])},
-    _testing={'pyxfile': 'src/testing',
-              'depends': [srcpath('testing', suffix='.pyx')]},
-    _hash={'pyxfile': 'src/hash',
-           'depends': [srcpath('hash', suffix='.pyx')]},
-)
-
-ext_data["io.sas.saslib"] = {'pyxfile': 'io/sas/saslib'}
+ext_data = {
+    '_libs.lib': {'pyxfile': '_libs/lib',
+                  'pxdfiles': [],
+                  'depends': lib_depends},
+    '_libs.hashtable': {'pyxfile': '_libs/hashtable',
+                        'pxdfiles': ['_libs/hashtable'],
+                        'depends': (['pandas/_libs/src/klib/khash_python.h']
+                                    + _pxi_dep['hashtable'])},
+    '_libs.tslib': {'pyxfile': '_libs/tslib',
+                    'depends': tseries_depends,
+                    'sources': ['pandas/_libs/src/datetime/np_datetime.c',
+                                'pandas/_libs/src/datetime/np_datetime_strings.c',
+                                'pandas/_libs/src/period_helper.c']},
+    '_libs.period': {'pyxfile': '_libs/period',
+                     'depends': tseries_depends,
+                     'sources': ['pandas/_libs/src/datetime/np_datetime.c',
+                                 'pandas/_libs/src/datetime/np_datetime_strings.c',
+                                 'pandas/_libs/src/period_helper.c']},
+    '_libs.index': {'pyxfile': '_libs/index',
+                    'sources': ['pandas/_libs/src/datetime/np_datetime.c',
+                                'pandas/_libs/src/datetime/np_datetime_strings.c'],
+                    'pxdfiles': ['_libs/src/util', '_libs/hashtable'],
+                    'depends': _pxi_dep['index']},
+    '_libs.algos': {'pyxfile': '_libs/algos',
+                    'pxdfiles': ['_libs/src/util', '_libs/hashtable'],
+                    'depends': _pxi_dep['algos']},
+    '_libs.join': {'pyxfile': '_libs/join',
+                   'pxdfiles': ['_libs/src/util', '_libs/hashtable'],
+                   'depends': _pxi_dep['join']},
+    '_libs.reshape': {'pyxfile': '_libs/reshape',
+                      'depends': _pxi_dep['reshape']},
+    'core.libwindow': {'pyxfile': 'core/window',
+                       'pxdfiles': ['_libs/src/skiplist', '_libs/src/util'],
+                       'depends': ['pandas/_libs/src/skiplist.pyx',
+                                   'pandas/_libs/src/skiplist.h']},
+    'io.libparsers': {'pyxfile': 'io/parsers',
+                      'depends': ['pandas/_libs/src/parser/tokenizer.h',
+                                  'pandas/_libs/src/parser/io.h',
+                                  'pandas/_libs/src/numpy_helper.h'],
+                      'sources': ['pandas/_libs/src/parser/tokenizer.c',
+                                  'pandas/_libs/src/parser/io.c']},
+    'sparse.libsparse': {'pyxfile': 'sparse/sparse',
+                         'depends': (['pandas/sparse/sparse.pyx'] +
+                                     _pxi_dep['sparse'])},
+    'util.libtesting': {'pyxfile': 'util/testing',
+                        'depends': ['pandas/util/testing.pyx']},
+    'tools.libhashing': {'pyxfile': 'tools/hashing',
+                         'depends': ['pandas/tools/hashing.pyx']},
+    'io.sas.libsas': {'pyxfile': 'io/sas/sas'},
+    }
 
 extensions = []
 
@@ -552,25 +552,25 @@ if sys.byteorder == 'big':
 else:
     macros = [('__LITTLE_ENDIAN__', '1')]
 
-packer_ext = Extension('pandas.msgpack._packer',
-                        depends=['pandas/src/msgpack/pack.h',
-                                 'pandas/src/msgpack/pack_template.h'],
+packer_ext = Extension('pandas.io.msgpack._packer',
+                        depends=['pandas/_libs/src/msgpack/pack.h',
+                                 'pandas/_libs/src/msgpack/pack_template.h'],
                         sources = [srcpath('_packer',
                                    suffix=suffix if suffix == '.pyx' else '.cpp',
-                                   subdir='msgpack')],
+                                   subdir='io/msgpack')],
                         language='c++',
-                        include_dirs=['pandas/src/msgpack'] + common_include,
+                        include_dirs=['pandas/_libs/src/msgpack'] + common_include,
                         define_macros=macros,
                         extra_compile_args=extra_compile_args)
-unpacker_ext = Extension('pandas.msgpack._unpacker',
-                        depends=['pandas/src/msgpack/unpack.h',
-                                 'pandas/src/msgpack/unpack_define.h',
-                                 'pandas/src/msgpack/unpack_template.h'],
+unpacker_ext = Extension('pandas.io.msgpack._unpacker',
+                        depends=['pandas/_libs/src/msgpack/unpack.h',
+                                 'pandas/_libs/src/msgpack/unpack_define.h',
+                                 'pandas/_libs/src/msgpack/unpack_template.h'],
                         sources = [srcpath('_unpacker',
                                    suffix=suffix if suffix == '.pyx' else '.cpp',
-                                   subdir='msgpack')],
+                                   subdir='io/msgpack')],
                         language='c++',
-                        include_dirs=['pandas/src/msgpack'] + common_include,
+                        include_dirs=['pandas/_libs/src/msgpack'] + common_include,
                         define_macros=macros,
                         extra_compile_args=extra_compile_args)
 extensions.append(packer_ext)
@@ -586,20 +586,20 @@ if suffix == '.pyx' and 'setuptools' in sys.modules:
             root, _ = os.path.splitext(ext.sources[0])
             ext.sources[0] = root + suffix
 
-ujson_ext = Extension('pandas.json',
-                      depends=['pandas/src/ujson/lib/ultrajson.h',
-                               'pandas/src/datetime_helper.h',
-                               'pandas/src/numpy_helper.h'],
-                      sources=['pandas/src/ujson/python/ujson.c',
-                               'pandas/src/ujson/python/objToJSON.c',
-                               'pandas/src/ujson/python/JSONtoObj.c',
-                               'pandas/src/ujson/lib/ultrajsonenc.c',
-                               'pandas/src/ujson/lib/ultrajsondec.c',
-                               'pandas/src/datetime/np_datetime.c',
-                               'pandas/src/datetime/np_datetime_strings.c'],
-                      include_dirs=['pandas/src/ujson/python',
-                                    'pandas/src/ujson/lib',
-                                    'pandas/src/datetime'] + common_include,
+ujson_ext = Extension('pandas.io.json.libjson',
+                      depends=['pandas/_libs/src/ujson/lib/ultrajson.h',
+                               'pandas/_libs/src/datetime_helper.h',
+                               'pandas/_libs/src/numpy_helper.h'],
+                      sources=['pandas/_libs/src/ujson/python/ujson.c',
+                               'pandas/_libs/src/ujson/python/objToJSON.c',
+                               'pandas/_libs/src/ujson/python/JSONtoObj.c',
+                               'pandas/_libs/src/ujson/lib/ultrajsonenc.c',
+                               'pandas/_libs/src/ujson/lib/ultrajsondec.c',
+                               'pandas/_libs/src/datetime/np_datetime.c',
+                               'pandas/_libs/src/datetime/np_datetime_strings.c'],
+                      include_dirs=['pandas/_libs/src/ujson/python',
+                                    'pandas/_libs/src/ujson/lib',
+                                    'pandas/_libs/src/datetime'] + common_include,
                       extra_compile_args=['-D_GNU_SOURCE'] + extra_compile_args)
 
 
@@ -634,6 +634,8 @@ setup(name=DISTNAME,
                 'pandas.io',
                 'pandas.io.json',
                 'pandas.io.sas',
+                'pandas.io.msgpack',
+                'pandas._libs',
                 'pandas.formats',
                 'pandas.sparse',
                 'pandas.stats',
@@ -650,10 +652,10 @@ setup(name=DISTNAME,
                 'pandas.tests.io.json',
                 'pandas.tests.io.parser',
                 'pandas.tests.io.sas',
+                'pandas.tests.io.msgpack',
                 'pandas.tests.groupby',
                 'pandas.tests.series',
                 'pandas.tests.formats',
-                'pandas.tests.msgpack',
                 'pandas.tests.scalar',
                 'pandas.tests.sparse',
                 'pandas.tests.tseries',
@@ -663,7 +665,6 @@ setup(name=DISTNAME,
                 'pandas.tools',
                 'pandas.tseries',
                 'pandas.types',
-                'pandas.msgpack',
                 'pandas.util.clipboard'
                 ],
       package_data={'pandas.tests': ['data/*.csv'],
diff --git a/vb_suite/pandas_vb_common.py b/vb_suite/pandas_vb_common.py
index a1326d63a..bd2e8a1c1 100644
--- a/vb_suite/pandas_vb_common.py
+++ b/vb_suite/pandas_vb_common.py
@@ -16,7 +16,7 @@ np.random.seed(1234)
 try:
     import pandas._tseries as lib
 except:
-    import pandas.lib as lib
+    import pandas._libs.lib as lib
 
 try:
     Panel = WidePanel
