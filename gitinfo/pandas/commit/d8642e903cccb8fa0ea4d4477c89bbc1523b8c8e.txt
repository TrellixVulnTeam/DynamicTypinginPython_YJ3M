commit d8642e903cccb8fa0ea4d4477c89bbc1523b8c8e
Author: Jeremy Schendel <jschendel@users.noreply.github.com>
Date:   Mon Mar 25 05:36:44 2019 -0600

    CLN: Remove unicode u string prefix (#25864)

diff --git a/doc/source/conf.py b/doc/source/conf.py
index 8693a97bc..3e639b887 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -134,8 +134,8 @@ source_encoding = 'utf-8'
 master_doc = 'index'
 
 # General information about the project.
-project = u'pandas'
-copyright = u'2008-2014, the pandas development team'
+project = 'pandas'
+copyright = '2008-2014, the pandas development team'
 
 # The version info for the project you're documenting, acts as replacement for
 # |version| and |release|, also used in various other places throughout the
diff --git a/doc/source/user_guide/advanced.rst b/doc/source/user_guide/advanced.rst
index 68f17a687..0e68cddde 100644
--- a/doc/source/user_guide/advanced.rst
+++ b/doc/source/user_guide/advanced.rst
@@ -797,7 +797,7 @@ values **not** in the categories, similarly to how you can reindex **any** panda
     In [11]: df3 = df3.set_index('B')
 
     In [11]: df3.index
-    Out[11]: CategoricalIndex([u'a', u'a', u'b', u'b', u'c', u'a'], categories=[u'a', u'b', u'c'], ordered=False, name=u'B', dtype='category')
+    Out[11]: CategoricalIndex(['a', 'a', 'b', 'b', 'c', 'a'], categories=['a', 'b', 'c'], ordered=False, name='B', dtype='category')
 
     In [12]: pd.concat([df2, df3])
     TypeError: categories must match existing categories when appending
diff --git a/doc/source/user_guide/options.rst b/doc/source/user_guide/options.rst
index d640d8b11..4b466c2c4 100644
--- a/doc/source/user_guide/options.rst
+++ b/doc/source/user_guide/options.rst
@@ -484,7 +484,7 @@ If a DataFrame or Series contains these characters, the default output mode may
 
 .. ipython:: python
 
-   df = pd.DataFrame({u'国籍': ['UK', u'日本'], u'名前': ['Alice', u'しのぶ']})
+   df = pd.DataFrame({'国籍': ['UK', '日本'], '名前': ['Alice', 'しのぶ']})
    df
 
 .. image:: ../_static/option_unicode01.png
@@ -507,7 +507,7 @@ By default, an "Ambiguous" character's width, such as "¡" (inverted exclamation
 
 .. ipython:: python
 
-   df = pd.DataFrame({'a': ['xxx', u'¡¡'], 'b': ['yyy', u'¡¡']})
+   df = pd.DataFrame({'a': ['xxx', '¡¡'], 'b': ['yyy', '¡¡']})
    df
 
 .. image:: ../_static/option_unicode03.png
diff --git a/doc/source/user_guide/reshaping.rst b/doc/source/user_guide/reshaping.rst
index 5c11be34e..28bf46cd4 100644
--- a/doc/source/user_guide/reshaping.rst
+++ b/doc/source/user_guide/reshaping.rst
@@ -695,7 +695,7 @@ handling of NaN:
     In [2]: pd.factorize(x, sort=True)
     Out[2]:
     (array([ 2,  2, -1,  3,  0,  1]),
-     Index([3.14, inf, u'A', u'B'], dtype='object'))
+     Index([3.14, inf, 'A', 'B'], dtype='object'))
 
     In [3]: np.unique(x, return_inverse=True)[::-1]
     Out[3]: (array([3, 3, 0, 4, 1, 2]), array([nan, 3.14, inf, 'A', 'B'], dtype=object))
diff --git a/doc/sphinxext/announce.py b/doc/sphinxext/announce.py
index 6bc53d3e9..c61db6935 100755
--- a/doc/sphinxext/announce.py
+++ b/doc/sphinxext/announce.py
@@ -56,7 +56,7 @@ A total of %d pull requests were merged for this release.
 
 
 def get_authors(revision_range):
-    pat = u'^.*\\t(.*)$'
+    pat = '^.*\\t(.*)$'
     lst_release, cur_release = [r.strip() for r in revision_range.split('..')]
 
     # authors, in current release and previous to current release.
@@ -70,7 +70,7 @@ def get_authors(revision_range):
     pre.discard('Homu')
 
     # Append '+' to new authors.
-    authors = [s + u' +' for s in cur - pre] + [s for s in cur & pre]
+    authors = [s + ' +' for s in cur - pre] + [s for s in cur & pre]
     authors.sort()
     return authors
 
@@ -81,17 +81,17 @@ def get_pull_requests(repo, revision_range):
     # From regular merges
     merges = this_repo.git.log(
         '--oneline', '--merges', revision_range)
-    issues = re.findall(u"Merge pull request \\#(\\d*)", merges)
+    issues = re.findall("Merge pull request \\#(\\d*)", merges)
     prnums.extend(int(s) for s in issues)
 
     # From Homu merges (Auto merges)
-    issues = re. findall(u"Auto merge of \\#(\\d*)", merges)
+    issues = re. findall("Auto merge of \\#(\\d*)", merges)
     prnums.extend(int(s) for s in issues)
 
     # From fast forward squash-merges
     commits = this_repo.git.log(
         '--oneline', '--no-merges', '--first-parent', revision_range)
-    issues = re.findall(u'^.*\\(\\#(\\d+)\\)$', commits, re.M)
+    issues = re.findall('^.*\\(\\#(\\d+)\\)$', commits, re.M)
     prnums.extend(int(s) for s in issues)
 
     # get PR data from github repo
diff --git a/pandas/core/arrays/base.py b/pandas/core/arrays/base.py
index f7d427ce2..79ccdb3a3 100644
--- a/pandas/core/arrays/base.py
+++ b/pandas/core/arrays/base.py
@@ -839,16 +839,16 @@ class ExtensionArray(object):
         from pandas.io.formats.printing import format_object_summary
 
         template = (
-            u'{class_name}'
-            u'{data}\n'
-            u'Length: {length}, dtype: {dtype}'
+            '{class_name}'
+            '{data}\n'
+            'Length: {length}, dtype: {dtype}'
         )
         # the short repr has no trailing newline, while the truncated
         # repr does. So we include a newline in our template, and strip
         # any trailing newlines from format_object_summary
         data = format_object_summary(self, self._formatter(),
                                      indent_for_name=False).rstrip(', \n')
-        class_name = u'<{}>\n'.format(self.__class__.__name__)
+        class_name = '<{}>\n'.format(self.__class__.__name__)
         return template.format(class_name=class_name, data=data,
                                length=len(self),
                                dtype=self.dtype)
diff --git a/pandas/core/arrays/categorical.py b/pandas/core/arrays/categorical.py
index 2a6cc6c74..75b64a06f 100644
--- a/pandas/core/arrays/categorical.py
+++ b/pandas/core/arrays/categorical.py
@@ -2147,7 +2147,7 @@ class Categorical(ExtensionArray, PandasObject):
         Categories (3, object): [a, b, c]
 
         In [3]: c.categories
-        Out[3]: Index([u'a', u'b', u'c'], dtype='object')
+        Out[3]: Index(['a', 'b', 'c'], dtype='object')
 
         In [4]: c.codes
         Out[4]: array([0, 0, 1, 2, 0], dtype=int8)
diff --git a/pandas/core/arrays/period.py b/pandas/core/arrays/period.py
index 400d4c9b9..a48621d8f 100644
--- a/pandas/core/arrays/period.py
+++ b/pandas/core/arrays/period.py
@@ -476,7 +476,7 @@ class PeriodArray(dtl.DatetimeLikeArrayMixin, dtl.DatelikeOps):
     # ------------------------------------------------------------------
     # Rendering Methods
 
-    def _format_native_types(self, na_rep=u'NaT', date_format=None, **kwargs):
+    def _format_native_types(self, na_rep='NaT', date_format=None, **kwargs):
         """
         actually format my specific types
         """
@@ -485,7 +485,7 @@ class PeriodArray(dtl.DatetimeLikeArrayMixin, dtl.DatelikeOps):
         if date_format:
             formatter = lambda dt: dt.strftime(date_format)
         else:
-            formatter = lambda dt: u'%s' % dt
+            formatter = lambda dt: '%s' % dt
 
         if self._hasnans:
             mask = self._isnan
diff --git a/pandas/core/computation/pytables.py b/pandas/core/computation/pytables.py
index 833650fb6..070d116e2 100644
--- a/pandas/core/computation/pytables.py
+++ b/pandas/core/computation/pytables.py
@@ -584,11 +584,11 @@ class TermValue(object):
     def tostring(self, encoding):
         """ quote the string if not encoded
             else encode and return """
-        if self.kind == u'string':
+        if self.kind == 'string':
             if encoding is not None:
                 return self.converted
             return '"{converted}"'.format(converted=self.converted)
-        elif self.kind == u'float':
+        elif self.kind == 'float':
             # python 2 str(float) is not always
             # round-trippable so use repr()
             return repr(self.converted)
diff --git a/pandas/core/dtypes/dtypes.py b/pandas/core/dtypes/dtypes.py
index b1fe2940f..34b4c3eac 100644
--- a/pandas/core/dtypes/dtypes.py
+++ b/pandas/core/dtypes/dtypes.py
@@ -393,9 +393,9 @@ class CategoricalDtype(PandasExtensionDtype, ExtensionDtype):
             return hash(self) == hash(other)
 
     def __repr__(self):
-        tpl = u'CategoricalDtype(categories={}ordered={})'
+        tpl = 'CategoricalDtype(categories={}ordered={})'
         if self.categories is None:
-            data = u"None, "
+            data = "None, "
         else:
             data = self.categories._format_data(name=self.__class__.__name__)
         return tpl.format(data, self.ordered)
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 8aa294d42..92db10254 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -8063,4 +8063,4 @@ def _from_nested_dict(data):
 
 
 def _put_str(s, space):
-    return u'{s}'.format(s=s)[:space].ljust(space)
+    return '{s}'.format(s=s)[:space].ljust(space)
diff --git a/pandas/core/indexes/multi.py b/pandas/core/indexes/multi.py
index e9373c914..e046ebaed 100644
--- a/pandas/core/indexes/multi.py
+++ b/pandas/core/indexes/multi.py
@@ -379,8 +379,8 @@ class MultiIndex(Index):
 
         Examples
         --------
-        >>> tuples = [(1, u'red'), (1, u'blue'),
-        ...           (2, u'red'), (2, u'blue')]
+        >>> tuples = [(1, 'red'), (1, 'blue'),
+        ...           (2, 'red'), (2, 'blue')]
         >>> pd.MultiIndex.from_tuples(tuples, names=('number', 'color'))
         MultiIndex(levels=[[1, 2], ['blue', 'red']],
                    codes=[[0, 0, 1, 1], [1, 0, 1, 0]],
@@ -621,25 +621,25 @@ class MultiIndex(Index):
 
         Examples
         --------
-        >>> idx = pd.MultiIndex.from_tuples([(1, u'one'), (1, u'two'),
-                                            (2, u'one'), (2, u'two')],
+        >>> idx = pd.MultiIndex.from_tuples([(1, 'one'), (1, 'two'),
+                                            (2, 'one'), (2, 'two')],
                                             names=['foo', 'bar'])
         >>> idx.set_levels([['a','b'], [1,2]])
-        MultiIndex(levels=[[u'a', u'b'], [1, 2]],
+        MultiIndex(levels=[['a', 'b'], [1, 2]],
                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_levels(['a','b'], level=0)
-        MultiIndex(levels=[[u'a', u'b'], [u'one', u'two']],
+        MultiIndex(levels=[['a', 'b'], ['one', 'two']],
                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_levels(['a','b'], level='bar')
-        MultiIndex(levels=[[1, 2], [u'a', u'b']],
+        MultiIndex(levels=[[1, 2], ['a', 'b']],
                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_levels([['a','b'], [1,2]], level=[0,1])
-        MultiIndex(levels=[[u'a', u'b'], [1, 2]],
+        MultiIndex(levels=[['a', 'b'], [1, 2]],
                    codes=[[0, 0, 1, 1], [0, 1, 0, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         """
         if is_list_like(levels) and not isinstance(levels, Index):
             levels = list(levels)
@@ -740,25 +740,25 @@ class MultiIndex(Index):
 
         Examples
         --------
-        >>> idx = pd.MultiIndex.from_tuples([(1, u'one'), (1, u'two'),
-                                            (2, u'one'), (2, u'two')],
+        >>> idx = pd.MultiIndex.from_tuples([(1, 'one'), (1, 'two'),
+                                            (2, 'one'), (2, 'two')],
                                             names=['foo', 'bar'])
         >>> idx.set_codes([[1,0,1,0], [0,0,1,1]])
-        MultiIndex(levels=[[1, 2], [u'one', u'two']],
+        MultiIndex(levels=[[1, 2], ['one', 'two']],
                    codes=[[1, 0, 1, 0], [0, 0, 1, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_codes([1,0,1,0], level=0)
-        MultiIndex(levels=[[1, 2], [u'one', u'two']],
+        MultiIndex(levels=[[1, 2], ['one', 'two']],
                    codes=[[1, 0, 1, 0], [0, 1, 0, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_codes([0,0,1,1], level='bar')
-        MultiIndex(levels=[[1, 2], [u'one', u'two']],
+        MultiIndex(levels=[[1, 2], ['one', 'two']],
                    codes=[[0, 0, 1, 1], [0, 0, 1, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         >>> idx.set_codes([[1,0,1,0], [0,0,1,1]], level=[0,1])
-        MultiIndex(levels=[[1, 2], [u'one', u'two']],
+        MultiIndex(levels=[[1, 2], ['one', 'two']],
                    codes=[[1, 0, 1, 0], [0, 0, 1, 1]],
-                   names=[u'foo', u'bar'])
+                   names=['foo', 'bar'])
         """
         if level is not None and not is_list_like(level):
             if not is_list_like(codes):
@@ -1512,10 +1512,10 @@ class MultiIndex(Index):
 
         Examples
         --------
-        >>> idx = pd.MultiIndex.from_tuples([(1, u'one'), (1, u'two'),
-                                            (2, u'one'), (2, u'two')])
+        >>> idx = pd.MultiIndex.from_tuples([(1, 'one'), (1, 'two'),
+                                            (2, 'one'), (2, 'two')])
         >>> idx.to_hierarchical(3)
-        MultiIndex(levels=[[1, 2], [u'one', u'two']],
+        MultiIndex(levels=[[1, 2], ['one', 'two']],
                    codes=[[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1],
                           [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]])
         """
diff --git a/pandas/core/indexes/period.py b/pandas/core/indexes/period.py
index a4bd7f901..fb3d4f09c 100644
--- a/pandas/core/indexes/period.py
+++ b/pandas/core/indexes/period.py
@@ -400,7 +400,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):
     # ------------------------------------------------------------------------
     # Rendering Methods
 
-    def _format_native_types(self, na_rep=u'NaT', quoting=None, **kwargs):
+    def _format_native_types(self, na_rep='NaT', quoting=None, **kwargs):
         # just dispatch, return ndarray
         return self._data._format_native_types(na_rep=na_rep,
                                                quoting=quoting,
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index ebec8b91a..7a87e8dc5 100755
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -1242,7 +1242,7 @@ class _NDFrameIndexer(_NDFrameIndexerBase):
         if missing:
             if missing == len(indexer):
                 raise KeyError(
-                    u"None of [{key}] are in the [{axis}]".format(
+                    "None of [{key}] are in the [{axis}]".format(
                         key=key, axis=self.obj._get_axis_name(axis)))
 
             # We (temporarily) allow for some missing keys with .loc, except in
diff --git a/pandas/core/internals/managers.py b/pandas/core/internals/managers.py
index 3ea810f44..be2b56881 100644
--- a/pandas/core/internals/managers.py
+++ b/pandas/core/internals/managers.py
@@ -296,12 +296,12 @@ class BlockManager(PandasObject):
         output = pprint_thing(self.__class__.__name__)
         for i, ax in enumerate(self.axes):
             if i == 0:
-                output += u'\nItems: {ax}'.format(ax=ax)
+                output += '\nItems: {ax}'.format(ax=ax)
             else:
-                output += u'\nAxis {i}: {ax}'.format(i=i, ax=ax)
+                output += '\nAxis {i}: {ax}'.format(i=i, ax=ax)
 
         for block in self.blocks:
-            output += u'\n{block}'.format(block=pprint_thing(block))
+            output += '\n{block}'.format(block=pprint_thing(block))
         return output
 
     def _verify_integrity(self):
diff --git a/pandas/core/reshape/pivot.py b/pandas/core/reshape/pivot.py
index dbff2a069..4bfb27c6f 100644
--- a/pandas/core/reshape/pivot.py
+++ b/pandas/core/reshape/pivot.py
@@ -154,7 +154,7 @@ def _add_margins(table, data, values, rows, cols, aggfunc,
     if not isinstance(margins_name, compat.string_types):
         raise ValueError('margins_name argument must be a string')
 
-    msg = u'Conflicting name "{name}" in margins'.format(name=margins_name)
+    msg = 'Conflicting name "{name}" in margins'.format(name=margins_name)
     for level in table.index.names:
         if margins_name in table.index.get_level_values(level):
             raise ValueError(msg)
diff --git a/pandas/errors/__init__.py b/pandas/errors/__init__.py
index 7d5a7f1a9..3b8904f4c 100644
--- a/pandas/errors/__init__.py
+++ b/pandas/errors/__init__.py
@@ -138,7 +138,7 @@ class ParserWarning(Warning):
     Using a `sep` in `pd.read_csv` other than a single character:
 
     >>> import io
-    >>> csv = u'''a;b;c
+    >>> csv = '''a;b;c
     ...           1;1,8
     ...           1;2,1'''
     >>> df = pd.read_csv(io.StringIO(csv), sep='[;,]')  # doctest: +SKIP
diff --git a/pandas/io/formats/format.py b/pandas/io/formats/format.py
index f69678ca0..8d7116388 100644
--- a/pandas/io/formats/format.py
+++ b/pandas/io/formats/format.py
@@ -213,7 +213,7 @@ class SeriesFormatter(object):
 
             series_name = pprint_thing(name,
                                        escape_chars=('\t', '\r', '\n'))
-            footer += ((u"Name: {sname}".format(sname=series_name))
+            footer += (("Name: {sname}".format(sname=series_name))
                        if name is not None else "")
 
         if (self.length is True or
@@ -227,7 +227,7 @@ class SeriesFormatter(object):
             if name:
                 if footer:
                     footer += ', '
-                footer += u'dtype: {typ}'.format(typ=pprint_thing(name))
+                footer += 'dtype: {typ}'.format(typ=pprint_thing(name))
 
         # level infos are added to the end and in a new line, like it is done
         # for Categoricals
@@ -949,10 +949,10 @@ class GenericArrayFormatter(object):
                     return 'NaT'
                 return self.na_rep
             elif isinstance(x, PandasObject):
-                return u'{x}'.format(x=x)
+                return '{x}'.format(x=x)
             else:
                 # object dtype
-                return u'{x}'.format(x=formatter(x))
+                return '{x}'.format(x=formatter(x))
 
         vals = self.values
         if isinstance(vals, Index):
@@ -968,16 +968,16 @@ class GenericArrayFormatter(object):
         fmt_values = []
         for i, v in enumerate(vals):
             if not is_float_type[i] and leading_space:
-                fmt_values.append(u' {v}'.format(v=_format(v)))
+                fmt_values.append(' {v}'.format(v=_format(v)))
             elif is_float_type[i]:
                 fmt_values.append(float_format(v))
             else:
                 if leading_space is False:
                     # False specifically, so that the default is
                     # to include a space if we get here.
-                    tpl = u'{v}'
+                    tpl = '{v}'
                 else:
-                    tpl = u' {v}'
+                    tpl = ' {v}'
                 fmt_values.append(tpl.format(v=_format(v)))
 
         return fmt_values
diff --git a/pandas/io/formats/html.py b/pandas/io/formats/html.py
index 4c235fed3..982e51ae8 100644
--- a/pandas/io/formats/html.py
+++ b/pandas/io/formats/html.py
@@ -118,7 +118,7 @@ class HTMLFormatter(TableFormatter):
         else:
             end_a = ''
 
-        self.write(u'{start}{rs}{end_a}</{kind}>'.format(
+        self.write('{start}{rs}{end_a}</{kind}>'.format(
             start=start_tag, rs=rs, end_a=end_a, kind=kind), indent)
 
     def write_tr(self, line, indent=0, indent_delta=0, header=False,
diff --git a/pandas/io/formats/printing.py b/pandas/io/formats/printing.py
index 70457e0bf..90013148a 100644
--- a/pandas/io/formats/printing.py
+++ b/pandas/io/formats/printing.py
@@ -336,17 +336,17 @@ def format_object_summary(obj, formatter, is_justify=True, name=None,
         else:
             return 0
 
-    close = u', '
+    close = ', '
 
     if n == 0:
-        summary = u'[]{}'.format(close)
+        summary = '[]{}'.format(close)
     elif n == 1:
         first = formatter(obj[0])
-        summary = u'[{}]{}'.format(first, close)
+        summary = '[{}]{}'.format(first, close)
     elif n == 2:
         first = formatter(obj[0])
         last = formatter(obj[-1])
-        summary = u'[{}, {}]{}'.format(first, last, close)
+        summary = '[{}, {}]{}'.format(first, last, close)
     else:
 
         if n > max_seq_items:
diff --git a/pandas/io/packers.py b/pandas/io/packers.py
index 57e941bbb..4a71338bf 100644
--- a/pandas/io/packers.py
+++ b/pandas/io/packers.py
@@ -322,10 +322,10 @@ def unconvert(values, dtype, compress=None):
         values = values.encode('latin1')
 
     if compress:
-        if compress == u'zlib':
+        if compress == 'zlib':
             _check_zlib()
             decompress = zlib.decompress
-        elif compress == u'blosc':
+        elif compress == 'blosc':
             _check_blosc()
             decompress = blosc.decompress
         else:
@@ -368,20 +368,20 @@ def encode(obj):
     tobj = type(obj)
     if isinstance(obj, Index):
         if isinstance(obj, RangeIndex):
-            return {u'typ': u'range_index',
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'start': getattr(obj, '_start', None),
-                    u'stop': getattr(obj, '_stop', None),
-                    u'step': getattr(obj, '_step', None)}
+            return {'typ': 'range_index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'start': getattr(obj, '_start', None),
+                    'stop': getattr(obj, '_stop', None),
+                    'step': getattr(obj, '_step', None)}
         elif isinstance(obj, PeriodIndex):
-            return {u'typ': u'period_index',
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'freq': getattr(obj, 'freqstr', None),
-                    u'dtype': obj.dtype.name,
-                    u'data': convert(obj.asi8),
-                    u'compress': compressor}
+            return {'typ': 'period_index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'freq': getattr(obj, 'freqstr', None),
+                    'dtype': obj.dtype.name,
+                    'data': convert(obj.asi8),
+                    'compress': compressor}
         elif isinstance(obj, DatetimeIndex):
             tz = getattr(obj, 'tz', None)
 
@@ -389,48 +389,48 @@ def encode(obj):
             if tz is not None:
                 tz = tz.zone
                 obj = obj.tz_convert('UTC')
-            return {u'typ': u'datetime_index',
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'dtype': obj.dtype.name,
-                    u'data': convert(obj.asi8),
-                    u'freq': getattr(obj, 'freqstr', None),
-                    u'tz': tz,
-                    u'compress': compressor}
+            return {'typ': 'datetime_index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'dtype': obj.dtype.name,
+                    'data': convert(obj.asi8),
+                    'freq': getattr(obj, 'freqstr', None),
+                    'tz': tz,
+                    'compress': compressor}
         elif isinstance(obj, (IntervalIndex, IntervalArray)):
             if isinstance(obj, IntervalIndex):
-                typ = u'interval_index'
+                typ = 'interval_index'
             else:
-                typ = u'interval_array'
-            return {u'typ': typ,
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'left': getattr(obj, 'left', None),
-                    u'right': getattr(obj, 'right', None),
-                    u'closed': getattr(obj, 'closed', None)}
+                typ = 'interval_array'
+            return {'typ': typ,
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'left': getattr(obj, 'left', None),
+                    'right': getattr(obj, 'right', None),
+                    'closed': getattr(obj, 'closed', None)}
         elif isinstance(obj, MultiIndex):
-            return {u'typ': u'multi_index',
-                    u'klass': obj.__class__.__name__,
-                    u'names': getattr(obj, 'names', None),
-                    u'dtype': obj.dtype.name,
-                    u'data': convert(obj.values),
-                    u'compress': compressor}
+            return {'typ': 'multi_index',
+                    'klass': obj.__class__.__name__,
+                    'names': getattr(obj, 'names', None),
+                    'dtype': obj.dtype.name,
+                    'data': convert(obj.values),
+                    'compress': compressor}
         else:
-            return {u'typ': u'index',
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'dtype': obj.dtype.name,
-                    u'data': convert(obj.values),
-                    u'compress': compressor}
+            return {'typ': 'index',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'dtype': obj.dtype.name,
+                    'data': convert(obj.values),
+                    'compress': compressor}
 
     elif isinstance(obj, Categorical):
-        return {u'typ': u'category',
-                u'klass': obj.__class__.__name__,
-                u'name': getattr(obj, 'name', None),
-                u'codes': obj.codes,
-                u'categories': obj.categories,
-                u'ordered': obj.ordered,
-                u'compress': compressor}
+        return {'typ': 'category',
+                'klass': obj.__class__.__name__,
+                'name': getattr(obj, 'name', None),
+                'codes': obj.codes,
+                'categories': obj.categories,
+                'ordered': obj.ordered,
+                'compress': compressor}
 
     elif isinstance(obj, Series):
         if isinstance(obj, SparseSeries):
@@ -448,13 +448,13 @@ def encode(obj):
             #    d[f] = getattr(obj, f, None)
             # return d
         else:
-            return {u'typ': u'series',
-                    u'klass': obj.__class__.__name__,
-                    u'name': getattr(obj, 'name', None),
-                    u'index': obj.index,
-                    u'dtype': obj.dtype.name,
-                    u'data': convert(obj.values),
-                    u'compress': compressor}
+            return {'typ': 'series',
+                    'klass': obj.__class__.__name__,
+                    'name': getattr(obj, 'name', None),
+                    'index': obj.index,
+                    'dtype': obj.dtype.name,
+                    'data': convert(obj.values),
+                    'compress': compressor}
     elif issubclass(tobj, NDFrame):
         if isinstance(obj, SparseDataFrame):
             raise NotImplementedError(
@@ -475,15 +475,15 @@ def encode(obj):
                 data = data.consolidate()
 
             # the block manager
-            return {u'typ': u'block_manager',
-                    u'klass': obj.__class__.__name__,
-                    u'axes': data.axes,
-                    u'blocks': [{u'locs': b.mgr_locs.as_array,
-                                 u'values': convert(b.values),
-                                 u'shape': b.values.shape,
-                                 u'dtype': b.dtype.name,
-                                 u'klass': b.__class__.__name__,
-                                 u'compress': compressor} for b in data.blocks]
+            return {'typ': 'block_manager',
+                    'klass': obj.__class__.__name__,
+                    'axes': data.axes,
+                    'blocks': [{'locs': b.mgr_locs.as_array,
+                                'values': convert(b.values),
+                                'shape': b.values.shape,
+                                'dtype': b.dtype.name,
+                                'klass': b.__class__.__name__,
+                                'compress': compressor} for b in data.blocks]
                     }
 
     elif isinstance(obj, (datetime, date, np.datetime64, timedelta,
@@ -495,71 +495,71 @@ def encode(obj):
             freq = obj.freq
             if freq is not None:
                 freq = freq.freqstr
-            return {u'typ': u'timestamp',
-                    u'value': obj.value,
-                    u'freq': freq,
-                    u'tz': tz}
+            return {'typ': 'timestamp',
+                    'value': obj.value,
+                    'freq': freq,
+                    'tz': tz}
         if obj is NaT:
-            return {u'typ': u'nat'}
+            return {'typ': 'nat'}
         elif isinstance(obj, np.timedelta64):
-            return {u'typ': u'timedelta64',
-                    u'data': obj.view('i8')}
+            return {'typ': 'timedelta64',
+                    'data': obj.view('i8')}
         elif isinstance(obj, timedelta):
-            return {u'typ': u'timedelta',
-                    u'data': (obj.days, obj.seconds, obj.microseconds)}
+            return {'typ': 'timedelta',
+                    'data': (obj.days, obj.seconds, obj.microseconds)}
         elif isinstance(obj, np.datetime64):
-            return {u'typ': u'datetime64',
-                    u'data': str(obj)}
+            return {'typ': 'datetime64',
+                    'data': str(obj)}
         elif isinstance(obj, datetime):
-            return {u'typ': u'datetime',
-                    u'data': obj.isoformat()}
+            return {'typ': 'datetime',
+                    'data': obj.isoformat()}
         elif isinstance(obj, date):
-            return {u'typ': u'date',
-                    u'data': obj.isoformat()}
+            return {'typ': 'date',
+                    'data': obj.isoformat()}
         raise Exception(
             "cannot encode this datetimelike object: {obj}".format(obj=obj))
     elif isinstance(obj, Period):
-        return {u'typ': u'period',
-                u'ordinal': obj.ordinal,
-                u'freq': obj.freqstr}
+        return {'typ': 'period',
+                'ordinal': obj.ordinal,
+                'freq': obj.freqstr}
     elif isinstance(obj, Interval):
-        return {u'typ': u'interval',
-                u'left': obj.left,
-                u'right': obj.right,
-                u'closed': obj.closed}
+        return {'typ': 'interval',
+                'left': obj.left,
+                'right': obj.right,
+                'closed': obj.closed}
     elif isinstance(obj, BlockIndex):
-        return {u'typ': u'block_index',
-                u'klass': obj.__class__.__name__,
-                u'blocs': obj.blocs,
-                u'blengths': obj.blengths,
-                u'length': obj.length}
+        return {'typ': 'block_index',
+                'klass': obj.__class__.__name__,
+                'blocs': obj.blocs,
+                'blengths': obj.blengths,
+                'length': obj.length}
     elif isinstance(obj, IntIndex):
-        return {u'typ': u'int_index',
-                u'klass': obj.__class__.__name__,
-                u'indices': obj.indices,
-                u'length': obj.length}
+        return {'typ': 'int_index',
+                'klass': obj.__class__.__name__,
+                'indices': obj.indices,
+                'length': obj.length}
     elif isinstance(obj, np.ndarray):
-        return {u'typ': u'ndarray',
-                u'shape': obj.shape,
-                u'ndim': obj.ndim,
-                u'dtype': obj.dtype.name,
-                u'data': convert(obj),
-                u'compress': compressor}
+        return {'typ': 'ndarray',
+                'shape': obj.shape,
+                'ndim': obj.ndim,
+                'dtype': obj.dtype.name,
+                'data': convert(obj),
+                'compress': compressor}
     elif isinstance(obj, np.number):
         if np.iscomplexobj(obj):
-            return {u'typ': u'np_scalar',
-                    u'sub_typ': u'np_complex',
-                    u'dtype': obj.dtype.name,
-                    u'real': obj.real.__repr__(),
-                    u'imag': obj.imag.__repr__()}
+            return {'typ': 'np_scalar',
+                    'sub_typ': 'np_complex',
+                    'dtype': obj.dtype.name,
+                    'real': obj.real.__repr__(),
+                    'imag': obj.imag.__repr__()}
         else:
-            return {u'typ': u'np_scalar',
-                    u'dtype': obj.dtype.name,
-                    u'data': obj.__repr__()}
+            return {'typ': 'np_scalar',
+                    'dtype': obj.dtype.name,
+                    'data': obj.__repr__()}
     elif isinstance(obj, complex):
-        return {u'typ': u'np_complex',
-                u'real': obj.real.__repr__(),
-                u'imag': obj.imag.__repr__()}
+        return {'typ': 'np_complex',
+                'real': obj.real.__repr__(),
+                'imag': obj.imag.__repr__()}
 
     return obj
 
@@ -569,110 +569,110 @@ def decode(obj):
     Decoder for deserializing numpy data types.
     """
 
-    typ = obj.get(u'typ')
+    typ = obj.get('typ')
     if typ is None:
         return obj
-    elif typ == u'timestamp':
-        freq = obj[u'freq'] if 'freq' in obj else obj[u'offset']
-        return Timestamp(obj[u'value'], tz=obj[u'tz'], freq=freq)
-    elif typ == u'nat':
+    elif typ == 'timestamp':
+        freq = obj['freq'] if 'freq' in obj else obj['offset']
+        return Timestamp(obj['value'], tz=obj['tz'], freq=freq)
+    elif typ == 'nat':
         return NaT
-    elif typ == u'period':
-        return Period(ordinal=obj[u'ordinal'], freq=obj[u'freq'])
-    elif typ == u'index':
-        dtype = dtype_for(obj[u'dtype'])
-        data = unconvert(obj[u'data'], dtype,
-                         obj.get(u'compress'))
-        return Index(data, dtype=dtype, name=obj[u'name'])
-    elif typ == u'range_index':
-        return RangeIndex(obj[u'start'],
-                          obj[u'stop'],
-                          obj[u'step'],
-                          name=obj[u'name'])
-    elif typ == u'multi_index':
-        dtype = dtype_for(obj[u'dtype'])
-        data = unconvert(obj[u'data'], dtype,
-                         obj.get(u'compress'))
+    elif typ == 'period':
+        return Period(ordinal=obj['ordinal'], freq=obj['freq'])
+    elif typ == 'index':
+        dtype = dtype_for(obj['dtype'])
+        data = unconvert(obj['data'], dtype,
+                         obj.get('compress'))
+        return Index(data, dtype=dtype, name=obj['name'])
+    elif typ == 'range_index':
+        return RangeIndex(obj['start'],
+                          obj['stop'],
+                          obj['step'],
+                          name=obj['name'])
+    elif typ == 'multi_index':
+        dtype = dtype_for(obj['dtype'])
+        data = unconvert(obj['data'], dtype,
+                         obj.get('compress'))
         data = [tuple(x) for x in data]
-        return MultiIndex.from_tuples(data, names=obj[u'names'])
-    elif typ == u'period_index':
-        data = unconvert(obj[u'data'], np.int64, obj.get(u'compress'))
-        d = dict(name=obj[u'name'], freq=obj[u'freq'])
+        return MultiIndex.from_tuples(data, names=obj['names'])
+    elif typ == 'period_index':
+        data = unconvert(obj['data'], np.int64, obj.get('compress'))
+        d = dict(name=obj['name'], freq=obj['freq'])
         freq = d.pop('freq', None)
         return PeriodIndex(PeriodArray(data, freq), **d)
 
-    elif typ == u'datetime_index':
-        data = unconvert(obj[u'data'], np.int64, obj.get(u'compress'))
-        d = dict(name=obj[u'name'], freq=obj[u'freq'])
+    elif typ == 'datetime_index':
+        data = unconvert(obj['data'], np.int64, obj.get('compress'))
+        d = dict(name=obj['name'], freq=obj['freq'])
         result = DatetimeIndex(data, **d)
-        tz = obj[u'tz']
+        tz = obj['tz']
 
         # reverse tz conversion
         if tz is not None:
             result = result.tz_localize('UTC').tz_convert(tz)
         return result
 
-    elif typ in (u'interval_index', 'interval_array'):
-        return globals()[obj[u'klass']].from_arrays(obj[u'left'],
-                                                    obj[u'right'],
-                                                    obj[u'closed'],
-                                                    name=obj[u'name'])
-    elif typ == u'category':
-        from_codes = globals()[obj[u'klass']].from_codes
-        return from_codes(codes=obj[u'codes'],
-                          categories=obj[u'categories'],
-                          ordered=obj[u'ordered'])
-
-    elif typ == u'interval':
-        return Interval(obj[u'left'], obj[u'right'], obj[u'closed'])
-    elif typ == u'series':
-        dtype = dtype_for(obj[u'dtype'])
+    elif typ in ('interval_index', 'interval_array'):
+        return globals()[obj['klass']].from_arrays(obj['left'],
+                                                   obj['right'],
+                                                   obj['closed'],
+                                                   name=obj['name'])
+    elif typ == 'category':
+        from_codes = globals()[obj['klass']].from_codes
+        return from_codes(codes=obj['codes'],
+                          categories=obj['categories'],
+                          ordered=obj['ordered'])
+
+    elif typ == 'interval':
+        return Interval(obj['left'], obj['right'], obj['closed'])
+    elif typ == 'series':
+        dtype = dtype_for(obj['dtype'])
         pd_dtype = pandas_dtype(dtype)
 
-        index = obj[u'index']
-        result = Series(unconvert(obj[u'data'], dtype, obj[u'compress']),
+        index = obj['index']
+        result = Series(unconvert(obj['data'], dtype, obj['compress']),
                         index=index,
                         dtype=pd_dtype,
-                        name=obj[u'name'])
+                        name=obj['name'])
         return result
 
-    elif typ == u'block_manager':
-        axes = obj[u'axes']
+    elif typ == 'block_manager':
+        axes = obj['axes']
 
         def create_block(b):
             values = _safe_reshape(unconvert(
-                b[u'values'], dtype_for(b[u'dtype']),
-                b[u'compress']), b[u'shape'])
+                b['values'], dtype_for(b['dtype']),
+                b['compress']), b['shape'])
 
             # locs handles duplicate column names, and should be used instead
             # of items; see GH 9618
-            if u'locs' in b:
-                placement = b[u'locs']
+            if 'locs' in b:
+                placement = b['locs']
             else:
-                placement = axes[0].get_indexer(b[u'items'])
+                placement = axes[0].get_indexer(b['items'])
 
-            if is_datetime64tz_dtype(b[u'dtype']):
+            if is_datetime64tz_dtype(b['dtype']):
                 assert isinstance(values, np.ndarray), type(values)
                 assert values.dtype == 'M8[ns]', values.dtype
-                values = DatetimeArray(values, dtype=b[u'dtype'])
+                values = DatetimeArray(values, dtype=b['dtype'])
 
             return make_block(values=values,
-                              klass=getattr(internals, b[u'klass']),
+                              klass=getattr(internals, b['klass']),
                               placement=placement,
-                              dtype=b[u'dtype'])
-
-        blocks = [create_block(b) for b in obj[u'blocks']]
-        return globals()[obj[u'klass']](BlockManager(blocks, axes))
-    elif typ == u'datetime':
-        return parse(obj[u'data'])
-    elif typ == u'datetime64':
-        return np.datetime64(parse(obj[u'data']))
-    elif typ == u'date':
-        return parse(obj[u'data']).date()
-    elif typ == u'timedelta':
-        return timedelta(*obj[u'data'])
-    elif typ == u'timedelta64':
-        return np.timedelta64(int(obj[u'data']))
+                              dtype=b['dtype'])
+
+        blocks = [create_block(b) for b in obj['blocks']]
+        return globals()[obj['klass']](BlockManager(blocks, axes))
+    elif typ == 'datetime':
+        return parse(obj['data'])
+    elif typ == 'datetime64':
+        return np.datetime64(parse(obj['data']))
+    elif typ == 'date':
+        return parse(obj['data']).date()
+    elif typ == 'timedelta':
+        return timedelta(*obj['data'])
+    elif typ == 'timedelta64':
+        return np.timedelta64(int(obj['data']))
     # elif typ == 'sparse_series':
     #    dtype = dtype_for(obj['dtype'])
     #    return SparseSeries(
@@ -690,25 +690,25 @@ def decode(obj):
     #        obj['data'], items=obj['items'],
     #        default_fill_value=obj['default_fill_value'],
     #        default_kind=obj['default_kind'])
-    elif typ == u'block_index':
-        return globals()[obj[u'klass']](obj[u'length'], obj[u'blocs'],
-                                        obj[u'blengths'])
-    elif typ == u'int_index':
-        return globals()[obj[u'klass']](obj[u'length'], obj[u'indices'])
-    elif typ == u'ndarray':
-        return unconvert(obj[u'data'], np.typeDict[obj[u'dtype']],
-                         obj.get(u'compress')).reshape(obj[u'shape'])
-    elif typ == u'np_scalar':
-        if obj.get(u'sub_typ') == u'np_complex':
-            return c2f(obj[u'real'], obj[u'imag'], obj[u'dtype'])
+    elif typ == 'block_index':
+        return globals()[obj['klass']](obj['length'], obj['blocs'],
+                                       obj['blengths'])
+    elif typ == 'int_index':
+        return globals()[obj['klass']](obj['length'], obj['indices'])
+    elif typ == 'ndarray':
+        return unconvert(obj['data'], np.typeDict[obj['dtype']],
+                         obj.get('compress')).reshape(obj['shape'])
+    elif typ == 'np_scalar':
+        if obj.get('sub_typ') == 'np_complex':
+            return c2f(obj['real'], obj['imag'], obj['dtype'])
         else:
-            dtype = dtype_for(obj[u'dtype'])
+            dtype = dtype_for(obj['dtype'])
             try:
-                return dtype(obj[u'data'])
+                return dtype(obj['data'])
             except (ValueError, TypeError):
-                return dtype.type(obj[u'data'])
-    elif typ == u'np_complex':
-        return complex(obj[u'real'] + u'+' + obj[u'imag'] + u'j')
+                return dtype.type(obj['data'])
+    elif typ == 'np_complex':
+        return complex(obj['real'] + '+' + obj['imag'] + 'j')
     elif isinstance(obj, (dict, list, set)):
         return obj
     else:
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index b0c0727c6..fadb9a5c6 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -148,10 +148,10 @@ map directly to c-types [inferred_type->%s,key->%s] [items->%s]
 
 # formats
 _FORMAT_MAP = {
-    u'f': 'fixed',
-    u'fixed': 'fixed',
-    u't': 'table',
-    u'table': 'table',
+    'f': 'fixed',
+    'fixed': 'fixed',
+    't': 'table',
+    'table': 'table',
 }
 
 format_deprecate_doc = """
@@ -166,31 +166,31 @@ use the format='fixed(f)|table(t)' keyword instead
 # map object types
 _TYPE_MAP = {
 
-    Series: u'series',
-    SparseSeries: u'sparse_series',
-    DataFrame: u'frame',
-    SparseDataFrame: u'sparse_frame',
+    Series: 'series',
+    SparseSeries: 'sparse_series',
+    DataFrame: 'frame',
+    SparseDataFrame: 'sparse_frame',
 }
 
 # storer class map
 _STORER_MAP = {
-    u'Series': 'LegacySeriesFixed',
-    u'DataFrame': 'LegacyFrameFixed',
-    u'DataMatrix': 'LegacyFrameFixed',
-    u'series': 'SeriesFixed',
-    u'sparse_series': 'SparseSeriesFixed',
-    u'frame': 'FrameFixed',
-    u'sparse_frame': 'SparseFrameFixed',
+    'Series': 'LegacySeriesFixed',
+    'DataFrame': 'LegacyFrameFixed',
+    'DataMatrix': 'LegacyFrameFixed',
+    'series': 'SeriesFixed',
+    'sparse_series': 'SparseSeriesFixed',
+    'frame': 'FrameFixed',
+    'sparse_frame': 'SparseFrameFixed',
 }
 
 # table class map
 _TABLE_MAP = {
-    u'generic_table': 'GenericTable',
-    u'appendable_series': 'AppendableSeriesTable',
-    u'appendable_multiseries': 'AppendableMultiSeriesTable',
-    u'appendable_frame': 'AppendableFrameTable',
-    u'appendable_multiframe': 'AppendableMultiFrameTable',
-    u'worm': 'WORMTable',
+    'generic_table': 'GenericTable',
+    'appendable_series': 'AppendableSeriesTable',
+    'appendable_multiseries': 'AppendableMultiSeriesTable',
+    'appendable_frame': 'AppendableFrameTable',
+    'appendable_multiframe': 'AppendableMultiFrameTable',
+    'worm': 'WORMTable',
 }
 
 # axes map
@@ -1091,7 +1091,7 @@ class HDFStore(StringMixin):
                 (getattr(g._v_attrs, 'pandas_type', None) or
                  getattr(g, 'table', None) or
                 (isinstance(g, _table_mod.table.Table) and
-                 g._v_name != u'table')))
+                 g._v_name != 'table')))
         ]
 
     def walk(self, where="/"):
@@ -1286,8 +1286,8 @@ class HDFStore(StringMixin):
                 _tables()
                 if (getattr(group, 'table', None) or
                         isinstance(group, _table_mod.table.Table)):
-                    pt = u'frame_table'
-                    tt = u'generic_table'
+                    pt = 'frame_table'
+                    tt = 'generic_table'
                 else:
                     raise TypeError(
                         "cannot create a storer if the object is not existing "
@@ -1301,10 +1301,10 @@ class HDFStore(StringMixin):
 
                 # we are actually a table
                 if format == 'table':
-                    pt += u'_table'
+                    pt += '_table'
 
         # a storer node
-        if u'table' not in pt:
+        if 'table' not in pt:
             try:
                 return globals()[_STORER_MAP[pt]](self, group, **kwargs)
             except KeyError:
@@ -1316,33 +1316,33 @@ class HDFStore(StringMixin):
             # if we are a writer, determine the tt
             if value is not None:
 
-                if pt == u'series_table':
+                if pt == 'series_table':
                     index = getattr(value, 'index', None)
                     if index is not None:
                         if index.nlevels == 1:
-                            tt = u'appendable_series'
+                            tt = 'appendable_series'
                         elif index.nlevels > 1:
-                            tt = u'appendable_multiseries'
-                elif pt == u'frame_table':
+                            tt = 'appendable_multiseries'
+                elif pt == 'frame_table':
                     index = getattr(value, 'index', None)
                     if index is not None:
                         if index.nlevels == 1:
-                            tt = u'appendable_frame'
+                            tt = 'appendable_frame'
                         elif index.nlevels > 1:
-                            tt = u'appendable_multiframe'
-                elif pt == u'wide_table':
-                    tt = u'appendable_panel'
-                elif pt == u'ndim_table':
-                    tt = u'appendable_ndim'
+                            tt = 'appendable_multiframe'
+                elif pt == 'wide_table':
+                    tt = 'appendable_panel'
+                elif pt == 'ndim_table':
+                    tt = 'appendable_ndim'
 
             else:
 
                 # distiguish between a frame/table
-                tt = u'legacy_panel'
+                tt = 'legacy_panel'
                 try:
                     fields = group.table._v_attrs.fields
-                    if len(fields) == 1 and fields[0] == u'value':
-                        tt = u'legacy_frame'
+                    if len(fields) == 1 and fields[0] == 'value':
+                        tt = 'legacy_frame'
                 except IndexError:
                     pass
 
@@ -1677,7 +1677,7 @@ class IndexCol(StringMixin):
         """ maybe set a string col itemsize:
                min_itemsize can be an integer or a dict with this columns name
                with an integer size """
-        if _ensure_decoded(self.kind) == u'string':
+        if _ensure_decoded(self.kind) == 'string':
 
             if isinstance(min_itemsize, dict):
                 min_itemsize = min_itemsize.get(self.name)
@@ -1704,7 +1704,7 @@ class IndexCol(StringMixin):
         """ validate this column: return the compared against itemsize """
 
         # validate this column for string truncation (or reset to the max size)
-        if _ensure_decoded(self.kind) == u'string':
+        if _ensure_decoded(self.kind) == 'string':
             c = self.col
             if c is not None:
                 if itemsize is None:
@@ -1865,9 +1865,9 @@ class DataCol(IndexCol):
         super(DataCol, self).__init__(values=values, kind=kind, typ=typ,
                                       cname=cname, **kwargs)
         self.dtype = None
-        self.dtype_attr = u'{name}_dtype'.format(name=self.name)
+        self.dtype_attr = '{name}_dtype'.format(name=self.name)
         self.meta = meta
-        self.meta_attr = u'{name}_meta'.format(name=self.name)
+        self.meta_attr = '{name}_meta'.format(name=self.name)
         self.set_data(data)
         self.set_metadata(metadata)
 
@@ -1915,19 +1915,19 @@ class DataCol(IndexCol):
         if self.dtype is not None:
             dtype = _ensure_decoded(self.dtype)
 
-            if dtype.startswith(u'string') or dtype.startswith(u'bytes'):
+            if dtype.startswith('string') or dtype.startswith('bytes'):
                 self.kind = 'string'
-            elif dtype.startswith(u'float'):
+            elif dtype.startswith('float'):
                 self.kind = 'float'
-            elif dtype.startswith(u'complex'):
+            elif dtype.startswith('complex'):
                 self.kind = 'complex'
-            elif dtype.startswith(u'int') or dtype.startswith(u'uint'):
+            elif dtype.startswith('int') or dtype.startswith('uint'):
                 self.kind = 'integer'
-            elif dtype.startswith(u'date'):
+            elif dtype.startswith('date'):
                 self.kind = 'datetime'
-            elif dtype.startswith(u'timedelta'):
+            elif dtype.startswith('timedelta'):
                 self.kind = 'timedelta'
-            elif dtype.startswith(u'bool'):
+            elif dtype.startswith('bool'):
                 self.kind = 'bool'
             else:
                 raise AssertionError(
@@ -2172,14 +2172,14 @@ class DataCol(IndexCol):
             dtype = _ensure_decoded(self.dtype)
 
             # reverse converts
-            if dtype == u'datetime64':
+            if dtype == 'datetime64':
 
                 # recreate with tz if indicated
                 self.data = _set_tz(self.data, self.tz, coerce=True)
 
-            elif dtype == u'timedelta64':
+            elif dtype == 'timedelta64':
                 self.data = np.asarray(self.data, dtype='m8[ns]')
-            elif dtype == u'date':
+            elif dtype == 'date':
                 try:
                     self.data = np.asarray(
                         [date.fromordinal(v) for v in self.data], dtype=object)
@@ -2187,12 +2187,12 @@ class DataCol(IndexCol):
                     self.data = np.asarray(
                         [date.fromtimestamp(v) for v in self.data],
                         dtype=object)
-            elif dtype == u'datetime':
+            elif dtype == 'datetime':
                 self.data = np.asarray(
                     [datetime.fromtimestamp(v) for v in self.data],
                     dtype=object)
 
-            elif meta == u'category':
+            elif meta == 'category':
 
                 # we have a categorical
                 categories = self.metadata
@@ -2225,7 +2225,7 @@ class DataCol(IndexCol):
                     self.data = self.data.astype('O', copy=False)
 
         # convert nans / decode
-        if _ensure_decoded(self.kind) == u'string':
+        if _ensure_decoded(self.kind) == 'string':
             self.data = _unconvert_string_array(
                 self.data, nan_rep=nan_rep, encoding=encoding, errors=errors)
 
@@ -2537,12 +2537,12 @@ class GenericFixed(Fixed):
             else:
                 ret = node[start:stop]
 
-            if dtype == u'datetime64':
+            if dtype == 'datetime64':
 
                 # reconstruct a timezone if indicated
                 ret = _set_tz(ret, getattr(attrs, 'tz', None), coerce=True)
 
-            elif dtype == u'timedelta64':
+            elif dtype == 'timedelta64':
                 ret = np.asarray(ret, dtype='m8[ns]')
 
         if transposed:
@@ -2554,13 +2554,13 @@ class GenericFixed(Fixed):
         variety = _ensure_decoded(
             getattr(self.attrs, '{key}_variety'.format(key=key)))
 
-        if variety == u'multi':
+        if variety == 'multi':
             return self.read_multi_index(key, **kwargs)
-        elif variety == u'block':
+        elif variety == 'block':
             return self.read_block_index(key, **kwargs)
-        elif variety == u'sparseint':
+        elif variety == 'sparseint':
             return self.read_sparse_intindex(key, **kwargs)
-        elif variety == u'regular':
+        elif variety == 'regular':
             _, index = self.read_index_node(getattr(self.group, key), **kwargs)
             return index
         else:  # pragma: no cover
@@ -2681,13 +2681,13 @@ class GenericFixed(Fixed):
         factory = self._get_index_factory(index_class)
 
         kwargs = {}
-        if u'freq' in node._v_attrs:
+        if 'freq' in node._v_attrs:
             kwargs['freq'] = node._v_attrs['freq']
 
-        if u'tz' in node._v_attrs:
+        if 'tz' in node._v_attrs:
             kwargs['tz'] = node._v_attrs['tz']
 
-        if kind in (u'date', u'datetime'):
+        if kind in ('date', 'datetime'):
             index = factory(_unconvert_index(data, kind,
                                              encoding=self.encoding,
                                              errors=self.errors),
@@ -2833,7 +2833,7 @@ class LegacyFrameFixed(LegacyFixed):
 
 
 class SeriesFixed(GenericFixed):
-    pandas_kind = u'series'
+    pandas_kind = 'series'
     attributes = ['name']
 
     @property
@@ -2870,7 +2870,7 @@ class SparseFixed(GenericFixed):
 
 
 class SparseSeriesFixed(SparseFixed):
-    pandas_kind = u'sparse_series'
+    pandas_kind = 'sparse_series'
     attributes = ['name', 'fill_value', 'kind']
 
     def read(self, **kwargs):
@@ -2879,7 +2879,7 @@ class SparseSeriesFixed(SparseFixed):
         sp_values = self.read_array('sp_values')
         sp_index = self.read_index('sp_index')
         return SparseSeries(sp_values, index=index, sparse_index=sp_index,
-                            kind=self.kind or u'block',
+                            kind=self.kind or 'block',
                             fill_value=self.fill_value,
                             name=self.name)
 
@@ -2894,7 +2894,7 @@ class SparseSeriesFixed(SparseFixed):
 
 
 class SparseFrameFixed(SparseFixed):
-    pandas_kind = u'sparse_frame'
+    pandas_kind = 'sparse_frame'
     attributes = ['default_kind', 'default_fill_value']
 
     def read(self, **kwargs):
@@ -3013,7 +3013,7 @@ class BlockManagerFixed(GenericFixed):
 
 
 class FrameFixed(BlockManagerFixed):
-    pandas_kind = u'frame'
+    pandas_kind = 'frame'
     obj_type = DataFrame
 
 
@@ -3042,7 +3042,7 @@ class Table(Fixed):
         metadata      : the names of the metadata columns
 
         """
-    pandas_kind = u'wide_table'
+    pandas_kind = 'wide_table'
     table_type = None
     levels = 1
     is_table = True
@@ -3154,7 +3154,7 @@ class Table(Fixed):
     @property
     def is_exists(self):
         """ has this table been created """
-        return u'table' in self.group
+        return 'table' in self.group
 
     @property
     def storable(self):
@@ -3837,7 +3837,7 @@ class WORMTable(Table):
          table. writing is a one-time operation the data are stored in a format
          that allows for searching the data on disk
          """
-    table_type = u'worm'
+    table_type = 'worm'
 
     def read(self, **kwargs):
         """ read the indices and the indexing array, calculate offset rows and
@@ -3865,7 +3865,7 @@ class LegacyTable(Table):
         IndexCol(name='column', axis=2, pos=1, index_kind='columns_kind'),
         DataCol(name='fields', cname='values', kind_attr='fields', pos=2)
     ]
-    table_type = u'legacy'
+    table_type = 'legacy'
     ndim = 3
 
     def write(self, **kwargs):
@@ -3885,7 +3885,7 @@ class LegacyTable(Table):
 class AppendableTable(LegacyTable):
     """ support the new appendable table formats """
     _indexables = None
-    table_type = u'appendable'
+    table_type = 'appendable'
 
     def write(self, obj, axes=None, append=False, complib=None,
               complevel=None, fletcher32=None, min_itemsize=None,
@@ -4116,8 +4116,8 @@ class AppendableTable(LegacyTable):
 
 class AppendableFrameTable(AppendableTable):
     """ support the new appendable table formats """
-    pandas_kind = u'frame_table'
-    table_type = u'appendable_frame'
+    pandas_kind = 'frame_table'
+    table_type = 'appendable_frame'
     ndim = 2
     obj_type = DataFrame
 
@@ -4182,8 +4182,8 @@ class AppendableFrameTable(AppendableTable):
 
 class AppendableSeriesTable(AppendableFrameTable):
     """ support the new appendable table formats """
-    pandas_kind = u'series_table'
-    table_type = u'appendable_series'
+    pandas_kind = 'series_table'
+    table_type = 'appendable_series'
     ndim = 2
     obj_type = Series
     storage_obj_type = DataFrame
@@ -4225,8 +4225,8 @@ class AppendableSeriesTable(AppendableFrameTable):
 
 class AppendableMultiSeriesTable(AppendableSeriesTable):
     """ support the new appendable table formats """
-    pandas_kind = u'series_table'
-    table_type = u'appendable_multiseries'
+    pandas_kind = 'series_table'
+    table_type = 'appendable_multiseries'
 
     def write(self, obj, **kwargs):
         """ we are going to write this as a frame table """
@@ -4240,8 +4240,8 @@ class AppendableMultiSeriesTable(AppendableSeriesTable):
 
 class GenericTable(AppendableFrameTable):
     """ a table that read/writes the generic pytables table format """
-    pandas_kind = u'frame_table'
-    table_type = u'generic_table'
+    pandas_kind = 'frame_table'
+    table_type = 'generic_table'
     ndim = 2
     obj_type = DataFrame
 
@@ -4290,14 +4290,14 @@ class GenericTable(AppendableFrameTable):
 class AppendableMultiFrameTable(AppendableFrameTable):
 
     """ a frame with a multi-index """
-    table_type = u'appendable_multiframe'
+    table_type = 'appendable_multiframe'
     obj_type = DataFrame
     ndim = 2
     _re_levels = re.compile(r"^level_\d+$")
 
     @property
     def table_type_short(self):
-        return u'appendable_multi'
+        return 'appendable_multi'
 
     def write(self, obj, data_columns=None, **kwargs):
         if data_columns is None:
@@ -4480,26 +4480,26 @@ def _convert_index(index, encoding=None, errors='strict', format_type=None):
 
 def _unconvert_index(data, kind, encoding=None, errors='strict'):
     kind = _ensure_decoded(kind)
-    if kind == u'datetime64':
+    if kind == 'datetime64':
         index = DatetimeIndex(data)
-    elif kind == u'timedelta64':
+    elif kind == 'timedelta64':
         index = TimedeltaIndex(data)
-    elif kind == u'datetime':
+    elif kind == 'datetime':
         index = np.asarray([datetime.fromtimestamp(v) for v in data],
                            dtype=object)
-    elif kind == u'date':
+    elif kind == 'date':
         try:
             index = np.asarray(
                 [date.fromordinal(v) for v in data], dtype=object)
         except (ValueError):
             index = np.asarray(
                 [date.fromtimestamp(v) for v in data], dtype=object)
-    elif kind in (u'integer', u'float'):
+    elif kind in ('integer', 'float'):
         index = np.asarray(data)
-    elif kind in (u'string'):
+    elif kind in ('string'):
         index = _unconvert_string_array(data, nan_rep=None, encoding=encoding,
                                         errors=errors)
-    elif kind == u'object':
+    elif kind == 'object':
         index = np.asarray(data[0])
     else:  # pragma: no cover
         raise ValueError('unrecognized index type {kind}'.format(kind=kind))
@@ -4509,11 +4509,11 @@ def _unconvert_index(data, kind, encoding=None, errors='strict'):
 def _unconvert_index_legacy(data, kind, legacy=False, encoding=None,
                             errors='strict'):
     kind = _ensure_decoded(kind)
-    if kind == u'datetime':
+    if kind == 'datetime':
         index = to_datetime(data)
-    elif kind in (u'integer'):
+    elif kind in ('integer'):
         index = np.asarray(data, dtype=object)
-    elif kind in (u'string'):
+    elif kind in ('string'):
         index = _unconvert_string_array(data, nan_rep=None, encoding=encoding,
                                         errors=errors)
     else:  # pragma: no cover
@@ -4618,7 +4618,7 @@ def _get_converter(kind, encoding, errors):
 
 def _need_convert(kind):
     kind = _ensure_decoded(kind)
-    if kind in (u'datetime', u'datetime64', u'string'):
+    if kind in ('datetime', 'datetime64', 'string'):
         return True
     return False
 
diff --git a/pandas/io/sql.py b/pandas/io/sql.py
index 3540daab1..09d86ef4a 100644
--- a/pandas/io/sql.py
+++ b/pandas/io/sql.py
@@ -1318,7 +1318,7 @@ class SQLiteTable(SQLTable):
         col_names = ','.join(bracketed_names)
         wildcards = ','.join([wld] * len(names))
         insert_statement = \
-            u'INSERT INTO {table} ({columns}) VALUES ({wld})'.format(
+            'INSERT INTO {table} ({columns}) VALUES ({wld})'.format(
                 table=escape(self.name), columns=col_names, wld=wildcards)
         return insert_statement
 
diff --git a/pandas/tests/arrays/categorical/test_repr.py b/pandas/tests/arrays/categorical/test_repr.py
index e9ff0f1a7..98e255692 100644
--- a/pandas/tests/arrays/categorical/test_repr.py
+++ b/pandas/tests/arrays/categorical/test_repr.py
@@ -58,15 +58,15 @@ class TestCategoricalRepr(object):
 
     def test_unicode_print(self):
         c = Categorical(['aaaaa', 'bb', 'cccc'] * 20)
-        expected = u"""\
+        expected = """\
 [aaaaa, bb, cccc, aaaaa, bb, ..., bb, cccc, aaaaa, bb, cccc]
 Length: 60
 Categories (3, object): [aaaaa, bb, cccc]"""
 
         assert repr(c) == expected
 
-        c = Categorical([u'ああああ', u'いいいいい', u'ううううううう'] * 20)
-        expected = u"""\
+        c = Categorical(['ああああ', 'いいいいい', 'ううううううう'] * 20)
+        expected = """\
 [ああああ, いいいいい, ううううううう, ああああ, いいいいい, ..., いいいいい, ううううううう, ああああ, いいいいい, ううううううう]
 Length: 60
 Categories (3, object): [ああああ, いいいいい, ううううううう]"""  # noqa
@@ -77,8 +77,8 @@ Categories (3, object): [ああああ, いいいいい, ううううううう]""
         # the repr width
         with option_context('display.unicode.east_asian_width', True):
 
-            c = Categorical([u'ああああ', u'いいいいい', u'ううううううう'] * 20)
-            expected = u"""[ああああ, いいいいい, ううううううう, ああああ, いいいいい, ..., いいいいい, ううううううう, ああああ, いいいいい, ううううううう]
+            c = Categorical(['ああああ', 'いいいいい', 'ううううううう'] * 20)
+            expected = """[ああああ, いいいいい, ううううううう, ああああ, いいいいい, ..., いいいいい, ううううううう, ああああ, いいいいい, ううううううう]
 Length: 60
 Categories (3, object): [ああああ, いいいいい, ううううううう]"""  # noqa
 
diff --git a/pandas/tests/dtypes/test_inference.py b/pandas/tests/dtypes/test_inference.py
index b534e38d6..9731b9b63 100644
--- a/pandas/tests/dtypes/test_inference.py
+++ b/pandas/tests/dtypes/test_inference.py
@@ -639,11 +639,11 @@ class TestTypeInference(object):
         pass
 
     def test_unicode(self):
-        arr = [u'a', np.nan, u'c']
+        arr = ['a', np.nan, 'c']
         result = lib.infer_dtype(arr, skipna=False)
         assert result == 'mixed'
 
-        arr = [u'a', np.nan, u'c']
+        arr = ['a', np.nan, 'c']
         result = lib.infer_dtype(arr, skipna=True)
         expected = 'string'
         assert result == expected
diff --git a/pandas/tests/frame/test_axis_select_reindex.py b/pandas/tests/frame/test_axis_select_reindex.py
index 560fb8dfa..f0ffa7f31 100644
--- a/pandas/tests/frame/test_axis_select_reindex.py
+++ b/pandas/tests/frame/test_axis_select_reindex.py
@@ -872,18 +872,18 @@ class TestDataFrameSelectReindex(TestData):
         assert_frame_equal(result, exp)
 
     @pytest.mark.parametrize('name,expected', [
-        ('a', DataFrame({u'a': [1, 2]})),
-        (u'a', DataFrame({u'a': [1, 2]})),
-        (u'あ', DataFrame({u'あ': [3, 4]}))
+        ('a', DataFrame({'a': [1, 2]})),
+        ('a', DataFrame({'a': [1, 2]})),
+        ('あ', DataFrame({'あ': [3, 4]}))
     ])
     def test_filter_unicode(self, name, expected):
         # GH13101
-        df = DataFrame({u'a': [1, 2], u'あ': [3, 4]})
+        df = DataFrame({'a': [1, 2], 'あ': [3, 4]})
 
         assert_frame_equal(df.filter(like=name), expected)
         assert_frame_equal(df.filter(regex=name), expected)
 
-    @pytest.mark.parametrize('name', ['a', u'a'])
+    @pytest.mark.parametrize('name', ['a', 'a'])
     def test_filter_bytestring(self, name):
         # GH13101
         df = DataFrame({b'a': [1, 2], b'b': [3, 4]})
diff --git a/pandas/tests/frame/test_convert_to.py b/pandas/tests/frame/test_convert_to.py
index baebdb903..43bc925ab 100644
--- a/pandas/tests/frame/test_convert_to.py
+++ b/pandas/tests/frame/test_convert_to.py
@@ -152,7 +152,7 @@ class TestDataFrameConvertTo(TestData):
     def test_to_records_with_unicode_index(self):
         # GH13172
         # unicode_literals conflict with to_records
-        result = DataFrame([{u'a': u'x', u'b': 'y'}]).set_index(u'a') \
+        result = DataFrame([{'a': 'x', 'b': 'y'}]).set_index('a') \
             .to_records()
         expected = np.rec.array([('x', 'y')], dtype=[('a', 'O'), ('b', 'O')])
         tm.assert_almost_equal(result, expected)
@@ -161,13 +161,13 @@ class TestDataFrameConvertTo(TestData):
         # xref issue: https://github.com/numpy/numpy/issues/2407
         # Issue #11879. to_records used to raise an exception when used
         # with column names containing non-ascii characters in Python 2
-        result = DataFrame(data={u"accented_name_é": [1.0]}).to_records()
+        result = DataFrame(data={"accented_name_é": [1.0]}).to_records()
 
         # Note that numpy allows for unicode field names but dtypes need
         # to be specified using dictionary instead of list of tuples.
         expected = np.rec.array(
             [(0, 1.0)],
-            dtype={"names": ["index", u"accented_name_é"],
+            dtype={"names": ["index", "accented_name_é"],
                    "formats": ['=i8', '=f8']}
         )
         tm.assert_almost_equal(result, expected)
@@ -312,8 +312,8 @@ class TestDataFrameConvertTo(TestData):
                    columns=MultiIndex.from_tuples([("a", "d"), ("b", "e"),
                                                    ("c", "f")])),
          dict(column_dtypes={0: "<U1", 2: "float32"}, index_dtypes="float32"),
-         np.rec.array([(0., u"1", 2, 3.), (1., u"4", 5, 6.),
-                       (2., u"7", 8, 9.)],
+         np.rec.array([(0., "1", 2, 3.), (1., "4", 5, 6.),
+                       (2., "7", 8, 9.)],
                       dtype=[("index", "<f4"),
                              ("('a', 'd')", "<U1"),
                              ("('b', 'e')", "<i8"),
diff --git a/pandas/tests/frame/test_to_csv.py b/pandas/tests/frame/test_to_csv.py
index 917cd9a04..385b70842 100644
--- a/pandas/tests/frame/test_to_csv.py
+++ b/pandas/tests/frame/test_to_csv.py
@@ -947,9 +947,9 @@ class TestDataFrameToCSV(TestData):
                    index=['A', 'B'], columns=['X', 'Y', 'Z']), None),
         # GH 21241, 21118
         (DataFrame([['abc', 'def', 'ghi']], columns=['X', 'Y', 'Z']), 'ascii'),
-        (DataFrame(5 * [[123, u"你好", u"世界"]],
+        (DataFrame(5 * [[123, "你好", "世界"]],
                    columns=['X', 'Y', 'Z']), 'gb2312'),
-        (DataFrame(5 * [[123, u"Γειά σου", u"Κόσμε"]],
+        (DataFrame(5 * [[123, "Γειά σου", "Κόσμε"]],
                    columns=['X', 'Y', 'Z']), 'cp737')
     ])
     def test_to_csv_compression(self, df, encoding, compression):
diff --git a/pandas/tests/groupby/test_function.py b/pandas/tests/groupby/test_function.py
index b5e328ef6..32437916d 100644
--- a/pandas/tests/groupby/test_function.py
+++ b/pandas/tests/groupby/test_function.py
@@ -1145,7 +1145,7 @@ def test_pipe():
     # NDFrame.pipe methods
     result = df.groupby('A').pipe(f).pipe(square)
 
-    index = Index([u'bar', u'foo'], dtype='object', name=u'A')
+    index = Index(['bar', 'foo'], dtype='object', name='A')
     expected = pd.Series([8.99110003361, 8.17516964785], name='B',
                          index=index)
 
diff --git a/pandas/tests/indexes/datetimes/test_tools.py b/pandas/tests/indexes/datetimes/test_tools.py
index 6c41119b1..4d4ad1511 100644
--- a/pandas/tests/indexes/datetimes/test_tools.py
+++ b/pandas/tests/indexes/datetimes/test_tools.py
@@ -384,8 +384,8 @@ class TestToDatetime(object):
             assert pdtoday2.tzinfo is None
 
     def test_to_datetime_today_now_unicode_bytes(self):
-        to_datetime([u'now'])
-        to_datetime([u'today'])
+        to_datetime(['now'])
+        to_datetime(['today'])
 
     @pytest.mark.parametrize('cache', [True, False])
     def test_to_datetime_dt64s(self, cache):
diff --git a/pandas/tests/indexes/multi/test_constructor.py b/pandas/tests/indexes/multi/test_constructor.py
index dfbf46b85..8cbeb3617 100644
--- a/pandas/tests/indexes/multi/test_constructor.py
+++ b/pandas/tests/indexes/multi/test_constructor.py
@@ -38,7 +38,7 @@ def test_constructor_no_levels():
 
 def test_constructor_nonhashable_names():
     # GH 20527
-    levels = [[1, 2], [u'one', u'two']]
+    levels = [[1, 2], ['one', 'two']]
     codes = [[0, 0, 1, 1], [0, 1, 0, 1]]
     names = (['foo'], ['bar'])
     msg = r"MultiIndex\.name must be a hashable type"
@@ -46,7 +46,7 @@ def test_constructor_nonhashable_names():
         MultiIndex(levels=levels, codes=codes, names=names)
 
     # With .rename()
-    mi = MultiIndex(levels=[[1, 2], [u'one', u'two']],
+    mi = MultiIndex(levels=[[1, 2], ['one', 'two']],
                     codes=[[0, 0, 1, 1], [0, 1, 0, 1]],
                     names=('foo', 'bar'))
     renamed = [['foor'], ['barr']]
diff --git a/pandas/tests/indexes/multi/test_format.py b/pandas/tests/indexes/multi/test_format.py
index 922ee87c8..d4244da1b 100644
--- a/pandas/tests/indexes/multi/test_format.py
+++ b/pandas/tests/indexes/multi/test_format.py
@@ -55,7 +55,7 @@ def test_repr_with_unicode_data():
     with pd.option_context("display.encoding", 'UTF-8'):
         d = {"a": ["\u05d0", 2, 3], "b": [4, 5, 6], "c": [7, 8, 9]}
         index = pd.DataFrame(d).set_index(["a", "b"]).index
-        assert "\\u" not in repr(index)  # we don't want unicode-escaped
+        assert "\\" not in repr(index)  # we don't want unicode-escaped
 
 
 @pytest.mark.skip(reason="#22511 will remove this test")
@@ -68,7 +68,7 @@ def test_repr_roundtrip():
     tm.assert_index_equal(eval(repr(mi)), mi, exact=True)
 
     mi_u = MultiIndex.from_product(
-        [list(u'ab'), range(3)], names=['first', 'second'])
+        [list('ab'), range(3)], names=['first', 'second'])
     result = eval(repr(mi_u))
     tm.assert_index_equal(result, mi_u, exact=True)
 
diff --git a/pandas/tests/indexes/test_base.py b/pandas/tests/indexes/test_base.py
index e937e55d3..61d3a3cb6 100644
--- a/pandas/tests/indexes/test_base.py
+++ b/pandas/tests/indexes/test_base.py
@@ -2066,17 +2066,17 @@ class TestIndex(Base):
         # ASCII
         # short
         (pd.Index(['a', 'bb', 'ccc']),
-         u"""Index(['a', 'bb', 'ccc'], dtype='object')"""),
+         """Index(['a', 'bb', 'ccc'], dtype='object')"""),
         # multiple lines
         (pd.Index(['a', 'bb', 'ccc'] * 10),
-         u"""\
+         """\
 Index(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc',
        'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc',
        'a', 'bb', 'ccc', 'a', 'bb', 'ccc'],
       dtype='object')"""),
         # truncated
         (pd.Index(['a', 'bb', 'ccc'] * 100),
-         u"""\
+         """\
 Index(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
        ...
        'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc'],
@@ -2084,54 +2084,54 @@ Index(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
 
         # Non-ASCII
         # short
-        (pd.Index([u'あ', u'いい', u'ううう']),
-         u"""Index(['あ', 'いい', 'ううう'], dtype='object')"""),
+        (pd.Index(['あ', 'いい', 'ううう']),
+         """Index(['あ', 'いい', 'ううう'], dtype='object')"""),
         # multiple lines
-        (pd.Index([u'あ', u'いい', u'ううう'] * 10),
-         (u"Index(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
-          u"'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
-          u"'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう'],\n"
-          u"      dtype='object')")),
+        (pd.Index(['あ', 'いい', 'ううう'] * 10),
+         ("Index(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
+          "'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
+          "'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう'],\n"
+          "      dtype='object')")),
         # truncated
-        (pd.Index([u'あ', u'いい', u'ううう'] * 100),
-         (u"Index(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
-          u"'あ', 'いい', 'ううう', 'あ',\n"
-          u"       ...\n"
-          u"       'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう', 'あ', 'いい', 'ううう'],\n"
-          u"      dtype='object', length=300)"))])
+        (pd.Index(['あ', 'いい', 'ううう'] * 100),
+         ("Index(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', "
+          "'あ', 'いい', 'ううう', 'あ',\n"
+          "       ...\n"
+          "       'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう', 'あ', 'いい', 'ううう'],\n"
+          "      dtype='object', length=300)"))])
     def test_string_index_repr(self, index, expected):
         result = repr(index)
         assert result == expected
 
     @pytest.mark.parametrize("index,expected", [
         # short
-        (pd.Index([u'あ', u'いい', u'ううう']),
-         (u"Index(['あ', 'いい', 'ううう'], "
-          u"dtype='object')")),
+        (pd.Index(['あ', 'いい', 'ううう']),
+         ("Index(['あ', 'いい', 'ううう'], "
+          "dtype='object')")),
         # multiple lines
-        (pd.Index([u'あ', u'いい', u'ううう'] * 10),
-         (u"Index(['あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ', 'いい', 'ううう'],\n"
-          u"      dtype='object')""")),
+        (pd.Index(['あ', 'いい', 'ううう'] * 10),
+         ("Index(['あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ', 'いい', 'ううう'],\n"
+          "      dtype='object')""")),
         # truncated
-        (pd.Index([u'あ', u'いい', u'ううう'] * 100),
-         (u"Index(['あ', 'いい', 'ううう', 'あ', 'いい', "
-          u"'ううう', 'あ', 'いい', 'ううう',\n"
-          u"       'あ',\n"
-          u"       ...\n"
-          u"       'ううう', 'あ', 'いい', 'ううう', 'あ', "
-          u"'いい', 'ううう', 'あ', 'いい',\n"
-          u"       'ううう'],\n"
-          u"      dtype='object', length=300)"))])
+        (pd.Index(['あ', 'いい', 'ううう'] * 100),
+         ("Index(['あ', 'いい', 'ううう', 'あ', 'いい', "
+          "'ううう', 'あ', 'いい', 'ううう',\n"
+          "       'あ',\n"
+          "       ...\n"
+          "       'ううう', 'あ', 'いい', 'ううう', 'あ', "
+          "'いい', 'ううう', 'あ', 'いい',\n"
+          "       'ううう'],\n"
+          "      dtype='object', length=300)"))])
     def test_string_index_repr_with_unicode_option(self, index, expected):
         # Enable Unicode option -----------------------------------------
         with cf.option_context('display.unicode.east_asian_width', True):
diff --git a/pandas/tests/indexes/test_category.py b/pandas/tests/indexes/test_category.py
index 3058b6f1a..e6a66802d 100644
--- a/pandas/tests/indexes/test_category.py
+++ b/pandas/tests/indexes/test_category.py
@@ -833,12 +833,12 @@ class TestCategoricalIndex(Base):
     def test_string_categorical_index_repr(self):
         # short
         idx = pd.CategoricalIndex(['a', 'bb', 'ccc'])
-        expected = u"""CategoricalIndex(['a', 'bb', 'ccc'], categories=['a', 'bb', 'ccc'], ordered=False, dtype='category')"""  # noqa
+        expected = """CategoricalIndex(['a', 'bb', 'ccc'], categories=['a', 'bb', 'ccc'], ordered=False, dtype='category')"""  # noqa
         assert repr(idx) == expected
 
         # multiple lines
         idx = pd.CategoricalIndex(['a', 'bb', 'ccc'] * 10)
-        expected = u"""CategoricalIndex(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
+        expected = """CategoricalIndex(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
                   'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb',
                   'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc'],
                  categories=['a', 'bb', 'ccc'], ordered=False, dtype='category')"""  # noqa
@@ -847,7 +847,7 @@ class TestCategoricalIndex(Base):
 
         # truncated
         idx = pd.CategoricalIndex(['a', 'bb', 'ccc'] * 100)
-        expected = u"""CategoricalIndex(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
+        expected = """CategoricalIndex(['a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a',
                   ...
                   'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc', 'a', 'bb', 'ccc'],
                  categories=['a', 'bb', 'ccc'], ordered=False, dtype='category', length=300)"""  # noqa
@@ -856,20 +856,20 @@ class TestCategoricalIndex(Base):
 
         # larger categories
         idx = pd.CategoricalIndex(list('abcdefghijklmmo'))
-        expected = u"""CategoricalIndex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
+        expected = """CategoricalIndex(['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',
                   'm', 'm', 'o'],
                  categories=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', ...], ordered=False, dtype='category')"""  # noqa
 
         assert repr(idx) == expected
 
         # short
-        idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'])
-        expected = u"""CategoricalIndex(['あ', 'いい', 'ううう'], categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category')"""  # noqa
+        idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'])
+        expected = """CategoricalIndex(['あ', 'いい', 'ううう'], categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category')"""  # noqa
         assert repr(idx) == expected
 
         # multiple lines
-        idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'] * 10)
-        expected = u"""CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ',
+        idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'] * 10)
+        expected = """CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ',
                   'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
                   'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう'],
                  categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category')"""  # noqa
@@ -877,8 +877,8 @@ class TestCategoricalIndex(Base):
         assert repr(idx) == expected
 
         # truncated
-        idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'] * 100)
-        expected = u"""CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ',
+        idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'] * 100)
+        expected = """CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ',
                   ...
                   'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう'],
                  categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category', length=300)"""  # noqa
@@ -886,8 +886,8 @@ class TestCategoricalIndex(Base):
         assert repr(idx) == expected
 
         # larger categories
-        idx = pd.CategoricalIndex(list(u'あいうえおかきくけこさしすせそ'))
-        expected = u"""CategoricalIndex(['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', 'け', 'こ', 'さ', 'し',
+        idx = pd.CategoricalIndex(list('あいうえおかきくけこさしすせそ'))
+        expected = """CategoricalIndex(['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', 'け', 'こ', 'さ', 'し',
                   'す', 'せ', 'そ'],
                  categories=['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', ...], ordered=False, dtype='category')"""  # noqa
 
@@ -897,13 +897,13 @@ class TestCategoricalIndex(Base):
         with cf.option_context('display.unicode.east_asian_width', True):
 
             # short
-            idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'])
-            expected = u"""CategoricalIndex(['あ', 'いい', 'ううう'], categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category')"""  # noqa
+            idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'])
+            expected = """CategoricalIndex(['あ', 'いい', 'ううう'], categories=['あ', 'いい', 'ううう'], ordered=False, dtype='category')"""  # noqa
             assert repr(idx) == expected
 
             # multiple lines
-            idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'] * 10)
-            expected = u"""CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
+            idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'] * 10)
+            expected = """CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
                   'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',
                   'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
                   'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう'],
@@ -912,8 +912,8 @@ class TestCategoricalIndex(Base):
             assert repr(idx) == expected
 
             # truncated
-            idx = pd.CategoricalIndex([u'あ', u'いい', u'ううう'] * 100)
-            expected = u"""CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
+            idx = pd.CategoricalIndex(['あ', 'いい', 'ううう'] * 100)
+            expected = """CategoricalIndex(['あ', 'いい', 'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい',
                   'ううう', 'あ',
                   ...
                   'ううう', 'あ', 'いい', 'ううう', 'あ', 'いい', 'ううう',
@@ -923,8 +923,8 @@ class TestCategoricalIndex(Base):
             assert repr(idx) == expected
 
             # larger categories
-            idx = pd.CategoricalIndex(list(u'あいうえおかきくけこさしすせそ'))
-            expected = u"""CategoricalIndex(['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', 'け', 'こ',
+            idx = pd.CategoricalIndex(list('あいうえおかきくけこさしすせそ'))
+            expected = """CategoricalIndex(['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', 'け', 'こ',
                   'さ', 'し', 'す', 'せ', 'そ'],
                  categories=['あ', 'い', 'う', 'え', 'お', 'か', 'き', 'く', ...], ordered=False, dtype='category')"""  # noqa
 
diff --git a/pandas/tests/indexes/timedeltas/test_construction.py b/pandas/tests/indexes/timedeltas/test_construction.py
index 0028f1e2e..6eaffe4c6 100644
--- a/pandas/tests/indexes/timedeltas/test_construction.py
+++ b/pandas/tests/indexes/timedeltas/test_construction.py
@@ -114,7 +114,7 @@ class TestTimedeltaIndex(object):
         tm.assert_index_equal(result, expected)
 
         # unicode
-        result = TimedeltaIndex([u'1 days', '1 days, 00:00:05', np.timedelta64(
+        result = TimedeltaIndex(['1 days', '1 days, 00:00:05', np.timedelta64(
             2, 'D'), timedelta(days=2, seconds=2), pd.offsets.Second(3)])
 
         expected = TimedeltaIndex(['0 days 00:00:00', '0 days 00:00:01',
diff --git a/pandas/tests/indexing/test_categorical.py b/pandas/tests/indexing/test_categorical.py
index 317aac176..bb065e7da 100644
--- a/pandas/tests/indexing/test_categorical.py
+++ b/pandas/tests/indexing/test_categorical.py
@@ -668,7 +668,7 @@ class TestCategoricalIndex(object):
         # CategoricalIndex([1, 1, 2, 1, 3, 2],
         #         categories=[3, 2, 1],
         #         ordered=True,
-        #         name=u'B')
+        #         name='B')
         result = df3[df3.index < 2]
         expected = df3.iloc[[4]]
         assert_frame_equal(result, expected)
@@ -683,7 +683,7 @@ class TestCategoricalIndex(object):
         # CategoricalIndex([1, 1, 2, 1, 3, 2],
         #         categories=[3, 2, 1],
         #         ordered=False,
-        #         name=u'B')
+        #         name='B')
         msg = "Unordered Categoricals can only compare equality or not"
         with pytest.raises(TypeError, match=msg):
             df4[df4.index < 2]
diff --git a/pandas/tests/io/data/gbq_fake_job.txt b/pandas/tests/io/data/gbq_fake_job.txt
index 2a0f09bc6..b09952222 100644
--- a/pandas/tests/io/data/gbq_fake_job.txt
+++ b/pandas/tests/io/data/gbq_fake_job.txt
@@ -1 +1 @@
-{u'status': {u'state': u'DONE'}, u'kind': u'bigquery#job', u'statistics': {u'query': {u'cacheHit': True, u'totalBytesProcessed': u'0'}, u'endTime': u'1377668744674', u'totalBytesProcessed': u'0', u'startTime': u'1377668744466'}, u'jobReference': {u'projectId': u'57288129629', u'jobId': u'bqjob_r5f956972f0190bdf_00000140c374bf42_2'}, u'etag': u'"4PTsVxg68bQkQs1RJ1Ndewqkgg4/oO4VmgFrAku4N6FWci9s7iFIftc"', u'configuration': {u'query': {u'createDisposition': u'CREATE_IF_NEEDED', u'query': u'SELECT * FROM [publicdata:samples.shakespeare]', u'writeDisposition': u'WRITE_TRUNCATE', u'destinationTable': {u'projectId': u'57288129629', u'tableId': u'anonb5ec450da88eeeb78a27784ea482ee75a146d442', u'datasetId': u'_d0b4f5f0d50dc68a3eb0fa6cba66a9a8687d9253'}}}, u'id': u'57288129629:bqjob_r5f956972f0190bdf_00000140c374bf42_2', u'selfLink': u'https://www.googleapis.com/bigquery/v2/projects/57288129629/jobs/bqjob_r5f956972f0190bdf_00000140c374bf42_2'}
\ No newline at end of file
+{'status': {'state': 'DONE'}, 'kind': 'bigquery#job', 'statistics': {'query': {'cacheHit': True, 'totalBytesProcessed': '0'}, 'endTime': '1377668744674', 'totalBytesProcessed': '0', 'startTime': '1377668744466'}, 'jobReference': {'projectId': '57288129629', 'jobId': 'bqjob_r5f956972f0190bdf_00000140c374bf42_2'}, 'etag': '"4PTsVxg68bQkQs1RJ1Ndewqkgg4/oO4VmgFrAku4N6FWci9s7iFIftc"', 'configuration': {'query': {'createDisposition': 'CREATE_IF_NEEDED', 'query': 'SELECT * FROM [publicdata:samples.shakespeare]', 'writeDisposition': 'WRITE_TRUNCATE', 'destinationTable': {'projectId': '57288129629', 'tableId': 'anonb5ec450da88eeeb78a27784ea482ee75a146d442', 'datasetId': '_d0b4f5f0d50dc68a3eb0fa6cba66a9a8687d9253'}}}, 'id': '57288129629:bqjob_r5f956972f0190bdf_00000140c374bf42_2', 'selfLink': 'https://www.googleapis.com/bigquery/v2/projects/57288129629/jobs/bqjob_r5f956972f0190bdf_00000140c374bf42_2'}
\ No newline at end of file
diff --git a/pandas/tests/io/formats/test_format.py b/pandas/tests/io/formats/test_format.py
index 309b653e1..34c2fb1ce 100644
--- a/pandas/tests/io/formats/test_format.py
+++ b/pandas/tests/io/formats/test_format.py
@@ -555,106 +555,106 @@ class TestDataFrameFormatting(object):
         # not alighned properly because of east asian width
 
         # mid col
-        df = DataFrame({'a': [u'あ', u'いいい', u'う', u'ええええええ'],
+        df = DataFrame({'a': ['あ', 'いいい', 'う', 'ええええええ'],
                         'b': [1, 222, 33333, 4]},
                        index=['a', 'bb', 'c', 'ddd'])
-        expected = (u"          a      b\na         あ      1\n"
-                    u"bb      いいい    222\nc         う  33333\n"
-                    u"ddd  ええええええ      4")
+        expected = ("          a      b\na         あ      1\n"
+                    "bb      いいい    222\nc         う  33333\n"
+                    "ddd  ええええええ      4")
         assert repr(df) == expected
 
         # last col
         df = DataFrame({'a': [1, 222, 33333, 4],
-                        'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+                        'b': ['あ', 'いいい', 'う', 'ええええええ']},
                        index=['a', 'bb', 'c', 'ddd'])
-        expected = (u"         a       b\na        1       あ\n"
-                    u"bb     222     いいい\nc    33333       う\n"
-                    u"ddd      4  ええええええ")
+        expected = ("         a       b\na        1       あ\n"
+                    "bb     222     いいい\nc    33333       う\n"
+                    "ddd      4  ええええええ")
         assert repr(df) == expected
 
         # all col
-        df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                        'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+        df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                        'b': ['あ', 'いいい', 'う', 'ええええええ']},
                        index=['a', 'bb', 'c', 'ddd'])
-        expected = (u"         a       b\na    あああああ       あ\n"
-                    u"bb       い     いいい\nc        う       う\n"
-                    u"ddd    えええ  ええええええ")
+        expected = ("         a       b\na    あああああ       あ\n"
+                    "bb       い     いいい\nc        う       う\n"
+                    "ddd    えええ  ええええええ")
         assert repr(df) == expected
 
         # column name
-        df = DataFrame({'b': [u'あ', u'いいい', u'う', u'ええええええ'],
-                        u'あああああ': [1, 222, 33333, 4]},
+        df = DataFrame({'b': ['あ', 'いいい', 'う', 'ええええええ'],
+                        'あああああ': [1, 222, 33333, 4]},
                        index=['a', 'bb', 'c', 'ddd'])
-        expected = (u"          b  あああああ\na         あ      1\n"
-                    u"bb      いいい    222\nc         う  33333\n"
-                    u"ddd  ええええええ      4")
+        expected = ("          b  あああああ\na         あ      1\n"
+                    "bb      いいい    222\nc         う  33333\n"
+                    "ddd  ええええええ      4")
         assert repr(df) == expected
 
         # index
-        df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                        'b': [u'あ', u'いいい', u'う', u'ええええええ']},
-                       index=[u'あああ', u'いいいいいい', u'うう', u'え'])
-        expected = (u"            a       b\nあああ     あああああ       あ\n"
-                    u"いいいいいい      い     いいい\nうう          う       う\n"
-                    u"え         えええ  ええええええ")
+        df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                        'b': ['あ', 'いいい', 'う', 'ええええええ']},
+                       index=['あああ', 'いいいいいい', 'うう', 'え'])
+        expected = ("            a       b\nあああ     あああああ       あ\n"
+                    "いいいいいい      い     いいい\nうう          う       う\n"
+                    "え         えええ  ええええええ")
         assert repr(df) == expected
 
         # index name
-        df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                        'b': [u'あ', u'いいい', u'う', u'ええええええ']},
-                       index=pd.Index([u'あ', u'い', u'うう', u'え'],
-                                      name=u'おおおお'))
-        expected = (u"          a       b\n"
-                    u"おおおお               \n"
-                    u"あ     あああああ       あ\n"
-                    u"い         い     いいい\n"
-                    u"うう        う       う\n"
-                    u"え       えええ  ええええええ")
+        df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                        'b': ['あ', 'いいい', 'う', 'ええええええ']},
+                       index=pd.Index(['あ', 'い', 'うう', 'え'],
+                                      name='おおおお'))
+        expected = ("          a       b\n"
+                    "おおおお               \n"
+                    "あ     あああああ       あ\n"
+                    "い         い     いいい\n"
+                    "うう        う       う\n"
+                    "え       えええ  ええええええ")
         assert repr(df) == expected
 
         # all
-        df = DataFrame({u'あああ': [u'あああ', u'い', u'う', u'えええええ'],
-                        u'いいいいい': [u'あ', u'いいい', u'う', u'ええ']},
-                       index=pd.Index([u'あ', u'いいい', u'うう', u'え'],
-                                      name=u'お'))
-        expected = (u"       あああ いいいいい\n"
-                    u"お               \n"
-                    u"あ      あああ     あ\n"
-                    u"いいい      い   いいい\n"
-                    u"うう       う     う\n"
-                    u"え    えええええ    ええ")
+        df = DataFrame({'あああ': ['あああ', 'い', 'う', 'えええええ'],
+                        'いいいいい': ['あ', 'いいい', 'う', 'ええ']},
+                       index=pd.Index(['あ', 'いいい', 'うう', 'え'],
+                                      name='お'))
+        expected = ("       あああ いいいいい\n"
+                    "お               \n"
+                    "あ      あああ     あ\n"
+                    "いいい      い   いいい\n"
+                    "うう       う     う\n"
+                    "え    えええええ    ええ")
         assert repr(df) == expected
 
         # MultiIndex
-        idx = pd.MultiIndex.from_tuples([(u'あ', u'いい'), (u'う', u'え'), (
-            u'おおお', u'かかかか'), (u'き', u'くく')])
-        df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                        'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+        idx = pd.MultiIndex.from_tuples([('あ', 'いい'), ('う', 'え'), (
+            'おおお', 'かかかか'), ('き', 'くく')])
+        df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                        'b': ['あ', 'いいい', 'う', 'ええええええ']},
                        index=idx)
-        expected = (u"              a       b\n"
-                    u"あ   いい    あああああ       あ\n"
-                    u"う   え         い     いいい\n"
-                    u"おおお かかかか      う       う\n"
-                    u"き   くく      えええ  ええええええ")
+        expected = ("              a       b\n"
+                    "あ   いい    あああああ       あ\n"
+                    "う   え         い     いいい\n"
+                    "おおお かかかか      う       う\n"
+                    "き   くく      えええ  ええええええ")
         assert repr(df) == expected
 
         # truncate
         with option_context('display.max_rows', 3, 'display.max_columns', 3):
-            df = pd.DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                               'b': [u'あ', u'いいい', u'う', u'ええええええ'],
-                               'c': [u'お', u'か', u'ききき', u'くくくくくく'],
-                               u'ああああ': [u'さ', u'し', u'す', u'せ']},
-                              columns=['a', 'b', 'c', u'ああああ'])
-
-            expected = (u"        a  ... ああああ\n0   あああああ  ...    さ\n"
-                        u"..    ...  ...  ...\n3     えええ  ...    せ\n"
-                        u"\n[4 rows x 4 columns]")
+            df = pd.DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                               'b': ['あ', 'いいい', 'う', 'ええええええ'],
+                               'c': ['お', 'か', 'ききき', 'くくくくくく'],
+                               'ああああ': ['さ', 'し', 'す', 'せ']},
+                              columns=['a', 'b', 'c', 'ああああ'])
+
+            expected = ("        a  ... ああああ\n0   あああああ  ...    さ\n"
+                        "..    ...  ...  ...\n3     えええ  ...    せ\n"
+                        "\n[4 rows x 4 columns]")
             assert repr(df) == expected
 
-            df.index = [u'あああ', u'いいいい', u'う', 'aaa']
-            expected = (u"         a  ... ああああ\nあああ  あああああ  ...    さ\n"
-                        u"..     ...  ...  ...\naaa    えええ  ...    せ\n"
-                        u"\n[4 rows x 4 columns]")
+            df.index = ['あああ', 'いいいい', 'う', 'aaa']
+            expected = ("         a  ... ああああ\nあああ  あああああ  ...    さ\n"
+                        "..     ...  ...  ...\naaa    えええ  ...    せ\n"
+                        "\n[4 rows x 4 columns]")
             assert repr(df) == expected
 
     def test_east_asian_unicode_true(self):
@@ -662,129 +662,129 @@ class TestDataFrameFormatting(object):
         with option_context('display.unicode.east_asian_width', True):
 
             # mid col
-            df = DataFrame({'a': [u'あ', u'いいい', u'う', u'ええええええ'],
+            df = DataFrame({'a': ['あ', 'いいい', 'う', 'ええええええ'],
                             'b': [1, 222, 33333, 4]},
                            index=['a', 'bb', 'c', 'ddd'])
-            expected = (u"                a      b\na              あ      1\n"
-                        u"bb         いいい    222\nc              う  33333\n"
-                        u"ddd  ええええええ      4")
+            expected = ("                a      b\na              あ      1\n"
+                        "bb         いいい    222\nc              う  33333\n"
+                        "ddd  ええええええ      4")
             assert repr(df) == expected
 
             # last col
             df = DataFrame({'a': [1, 222, 33333, 4],
-                            'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+                            'b': ['あ', 'いいい', 'う', 'ええええええ']},
                            index=['a', 'bb', 'c', 'ddd'])
-            expected = (u"         a             b\na        1            あ\n"
-                        u"bb     222        いいい\nc    33333            う\n"
-                        u"ddd      4  ええええええ")
+            expected = ("         a             b\na        1            あ\n"
+                        "bb     222        いいい\nc    33333            う\n"
+                        "ddd      4  ええええええ")
             assert repr(df) == expected
 
             # all col
-            df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                            'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+            df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                            'b': ['あ', 'いいい', 'う', 'ええええええ']},
                            index=['a', 'bb', 'c', 'ddd'])
-            expected = (u"              a             b\n"
-                        u"a    あああああ            あ\n"
-                        u"bb           い        いいい\n"
-                        u"c            う            う\n"
-                        u"ddd      えええ  ええええええ")
+            expected = ("              a             b\n"
+                        "a    あああああ            あ\n"
+                        "bb           い        いいい\n"
+                        "c            う            う\n"
+                        "ddd      えええ  ええええええ")
             assert repr(df) == expected
 
             # column name
-            df = DataFrame({'b': [u'あ', u'いいい', u'う', u'ええええええ'],
-                            u'あああああ': [1, 222, 33333, 4]},
+            df = DataFrame({'b': ['あ', 'いいい', 'う', 'ええええええ'],
+                            'あああああ': [1, 222, 33333, 4]},
                            index=['a', 'bb', 'c', 'ddd'])
-            expected = (u"                b  あああああ\n"
-                        u"a              あ           1\n"
-                        u"bb         いいい         222\n"
-                        u"c              う       33333\n"
-                        u"ddd  ええええええ           4")
+            expected = ("                b  あああああ\n"
+                        "a              あ           1\n"
+                        "bb         いいい         222\n"
+                        "c              う       33333\n"
+                        "ddd  ええええええ           4")
             assert repr(df) == expected
 
             # index
-            df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                            'b': [u'あ', u'いいい', u'う', u'ええええええ']},
-                           index=[u'あああ', u'いいいいいい', u'うう', u'え'])
-            expected = (u"                       a             b\n"
-                        u"あああ        あああああ            あ\n"
-                        u"いいいいいい          い        いいい\n"
-                        u"うう                  う            う\n"
-                        u"え                えええ  ええええええ")
+            df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                            'b': ['あ', 'いいい', 'う', 'ええええええ']},
+                           index=['あああ', 'いいいいいい', 'うう', 'え'])
+            expected = ("                       a             b\n"
+                        "あああ        あああああ            あ\n"
+                        "いいいいいい          い        いいい\n"
+                        "うう                  う            う\n"
+                        "え                えええ  ええええええ")
             assert repr(df) == expected
 
             # index name
-            df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                            'b': [u'あ', u'いいい', u'う', u'ええええええ']},
-                           index=pd.Index([u'あ', u'い', u'うう', u'え'],
-                                          name=u'おおおお'))
-            expected = (u"                   a             b\n"
-                        u"おおおお                          \n"
-                        u"あ        あああああ            あ\n"
-                        u"い                い        いいい\n"
-                        u"うう              う            う\n"
-                        u"え            えええ  ええええええ")
+            df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                            'b': ['あ', 'いいい', 'う', 'ええええええ']},
+                           index=pd.Index(['あ', 'い', 'うう', 'え'],
+                                          name='おおおお'))
+            expected = ("                   a             b\n"
+                        "おおおお                          \n"
+                        "あ        あああああ            あ\n"
+                        "い                い        いいい\n"
+                        "うう              う            う\n"
+                        "え            えええ  ええええええ")
             assert repr(df) == expected
 
             # all
-            df = DataFrame({u'あああ': [u'あああ', u'い', u'う', u'えええええ'],
-                            u'いいいいい': [u'あ', u'いいい', u'う', u'ええ']},
-                           index=pd.Index([u'あ', u'いいい', u'うう', u'え'],
-                                          name=u'お'))
-            expected = (u"            あああ いいいいい\n"
-                        u"お                           \n"
-                        u"あ          あああ         あ\n"
-                        u"いいい          い     いいい\n"
-                        u"うう            う         う\n"
-                        u"え      えええええ       ええ")
+            df = DataFrame({'あああ': ['あああ', 'い', 'う', 'えええええ'],
+                            'いいいいい': ['あ', 'いいい', 'う', 'ええ']},
+                           index=pd.Index(['あ', 'いいい', 'うう', 'え'],
+                                          name='お'))
+            expected = ("            あああ いいいいい\n"
+                        "お                           \n"
+                        "あ          あああ         あ\n"
+                        "いいい          い     いいい\n"
+                        "うう            う         う\n"
+                        "え      えええええ       ええ")
             assert repr(df) == expected
 
             # MultiIndex
-            idx = pd.MultiIndex.from_tuples([(u'あ', u'いい'), (u'う', u'え'), (
-                u'おおお', u'かかかか'), (u'き', u'くく')])
-            df = DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                            'b': [u'あ', u'いいい', u'う', u'ええええええ']},
+            idx = pd.MultiIndex.from_tuples([('あ', 'いい'), ('う', 'え'), (
+                'おおお', 'かかかか'), ('き', 'くく')])
+            df = DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                            'b': ['あ', 'いいい', 'う', 'ええええええ']},
                            index=idx)
-            expected = (u"                          a             b\n"
-                        u"あ     いい      あああああ            あ\n"
-                        u"う     え                い        いいい\n"
-                        u"おおお かかかか          う            う\n"
-                        u"き     くく          えええ  ええええええ")
+            expected = ("                          a             b\n"
+                        "あ     いい      あああああ            あ\n"
+                        "う     え                い        いいい\n"
+                        "おおお かかかか          う            う\n"
+                        "き     くく          えええ  ええええええ")
             assert repr(df) == expected
 
             # truncate
             with option_context('display.max_rows', 3, 'display.max_columns',
                                 3):
 
-                df = pd.DataFrame({'a': [u'あああああ', u'い', u'う', u'えええ'],
-                                   'b': [u'あ', u'いいい', u'う', u'ええええええ'],
-                                   'c': [u'お', u'か', u'ききき', u'くくくくくく'],
-                                   u'ああああ': [u'さ', u'し', u'す', u'せ']},
-                                  columns=['a', 'b', 'c', u'ああああ'])
-
-                expected = (u"             a  ... ああああ\n"
-                            u"0   あああああ  ...       さ\n"
-                            u"..         ...  ...      ...\n"
-                            u"3       えええ  ...       せ\n"
-                            u"\n[4 rows x 4 columns]")
+                df = pd.DataFrame({'a': ['あああああ', 'い', 'う', 'えええ'],
+                                   'b': ['あ', 'いいい', 'う', 'ええええええ'],
+                                   'c': ['お', 'か', 'ききき', 'くくくくくく'],
+                                   'ああああ': ['さ', 'し', 'す', 'せ']},
+                                  columns=['a', 'b', 'c', 'ああああ'])
+
+                expected = ("             a  ... ああああ\n"
+                            "0   あああああ  ...       さ\n"
+                            "..         ...  ...      ...\n"
+                            "3       えええ  ...       せ\n"
+                            "\n[4 rows x 4 columns]")
                 assert repr(df) == expected
 
-                df.index = [u'あああ', u'いいいい', u'う', 'aaa']
-                expected = (u"                 a  ... ああああ\n"
-                            u"あああ  あああああ  ...       さ\n"
-                            u"...            ...  ...      ...\n"
-                            u"aaa         えええ  ...       せ\n"
-                            u"\n[4 rows x 4 columns]")
+                df.index = ['あああ', 'いいいい', 'う', 'aaa']
+                expected = ("                 a  ... ああああ\n"
+                            "あああ  あああああ  ...       さ\n"
+                            "...            ...  ...      ...\n"
+                            "aaa         えええ  ...       せ\n"
+                            "\n[4 rows x 4 columns]")
                 assert repr(df) == expected
 
             # ambiguous unicode
-            df = DataFrame({'b': [u'あ', u'いいい', u'¡¡', u'ええええええ'],
-                            u'あああああ': [1, 222, 33333, 4]},
+            df = DataFrame({'b': ['あ', 'いいい', '¡¡', 'ええええええ'],
+                            'あああああ': [1, 222, 33333, 4]},
                            index=['a', 'bb', 'c', '¡¡¡'])
-            expected = (u"                b  あああああ\n"
-                        u"a              あ           1\n"
-                        u"bb         いいい         222\n"
-                        u"c              ¡¡       33333\n"
-                        u"¡¡¡  ええええええ           4")
+            expected = ("                b  あああああ\n"
+                        "a              あ           1\n"
+                        "bb         いいい         222\n"
+                        "c              ¡¡       33333\n"
+                        "¡¡¡  ええええええ           4")
             assert repr(df) == expected
 
     def test_to_string_buffer_all_unicode(self):
@@ -1860,72 +1860,72 @@ class TestSeriesFormatting(object):
 
         # unicode index
         s = Series(['a', 'bb', 'CCC', 'D'],
-                   index=[u'あ', u'いい', u'ううう', u'ええええ'])
-        expected = (u"あ         a\nいい       bb\nううう     CCC\n"
-                    u"ええええ      D\ndtype: object")
+                   index=['あ', 'いい', 'ううう', 'ええええ'])
+        expected = ("あ         a\nいい       bb\nううう     CCC\n"
+                    "ええええ      D\ndtype: object")
         assert repr(s) == expected
 
         # unicode values
-        s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
+        s = Series(['あ', 'いい', 'ううう', 'ええええ'],
                    index=['a', 'bb', 'c', 'ddd'])
-        expected = (u"a         あ\nbb       いい\nc       ううう\n"
-                    u"ddd    ええええ\ndtype: object")
+        expected = ("a         あ\nbb       いい\nc       ううう\n"
+                    "ddd    ええええ\ndtype: object")
         assert repr(s) == expected
 
         # both
-        s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                   index=[u'ああ', u'いいいい', u'う', u'えええ'])
-        expected = (u"ああ         あ\nいいいい      いい\nう        ううう\n"
-                    u"えええ     ええええ\ndtype: object")
+        s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                   index=['ああ', 'いいいい', 'う', 'えええ'])
+        expected = ("ああ         あ\nいいいい      いい\nう        ううう\n"
+                    "えええ     ええええ\ndtype: object")
         assert repr(s) == expected
 
         # unicode footer
-        s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                   index=[u'ああ', u'いいいい', u'う', u'えええ'],
-                   name=u'おおおおおおお')
-        expected = (u"ああ         あ\nいいいい      いい\nう        ううう\n"
-                    u"えええ     ええええ\nName: おおおおおおお, dtype: object")
+        s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                   index=['ああ', 'いいいい', 'う', 'えええ'],
+                   name='おおおおおおお')
+        expected = ("ああ         あ\nいいいい      いい\nう        ううう\n"
+                    "えええ     ええええ\nName: おおおおおおお, dtype: object")
         assert repr(s) == expected
 
         # MultiIndex
-        idx = pd.MultiIndex.from_tuples([(u'あ', u'いい'), (u'う', u'え'), (
-            u'おおお', u'かかかか'), (u'き', u'くく')])
+        idx = pd.MultiIndex.from_tuples([('あ', 'いい'), ('う', 'え'), (
+            'おおお', 'かかかか'), ('き', 'くく')])
         s = Series([1, 22, 3333, 44444], index=idx)
-        expected = (u"あ    いい          1\n"
-                    u"う    え          22\n"
-                    u"おおお  かかかか     3333\n"
-                    u"き    くく      44444\ndtype: int64")
+        expected = ("あ    いい          1\n"
+                    "う    え          22\n"
+                    "おおお  かかかか     3333\n"
+                    "き    くく      44444\ndtype: int64")
         assert repr(s) == expected
 
         # object dtype, shorter than unicode repr
-        s = Series([1, 22, 3333, 44444], index=[1, 'AB', np.nan, u'あああ'])
-        expected = (u"1          1\nAB        22\nNaN     3333\n"
-                    u"あああ    44444\ndtype: int64")
+        s = Series([1, 22, 3333, 44444], index=[1, 'AB', np.nan, 'あああ'])
+        expected = ("1          1\nAB        22\nNaN     3333\n"
+                    "あああ    44444\ndtype: int64")
         assert repr(s) == expected
 
         # object dtype, longer than unicode repr
         s = Series([1, 22, 3333, 44444],
-                   index=[1, 'AB', pd.Timestamp('2011-01-01'), u'あああ'])
-        expected = (u"1                          1\n"
-                    u"AB                        22\n"
-                    u"2011-01-01 00:00:00     3333\n"
-                    u"あああ                    44444\ndtype: int64")
+                   index=[1, 'AB', pd.Timestamp('2011-01-01'), 'あああ'])
+        expected = ("1                          1\n"
+                    "AB                        22\n"
+                    "2011-01-01 00:00:00     3333\n"
+                    "あああ                    44444\ndtype: int64")
         assert repr(s) == expected
 
         # truncate
         with option_context('display.max_rows', 3):
-            s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                       name=u'おおおおおおお')
+            s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                       name='おおおおおおお')
 
-            expected = (u"0       あ\n     ... \n"
-                        u"3    ええええ\n"
-                        u"Name: おおおおおおお, Length: 4, dtype: object")
+            expected = ("0       あ\n     ... \n"
+                        "3    ええええ\n"
+                        "Name: おおおおおおお, Length: 4, dtype: object")
             assert repr(s) == expected
 
-            s.index = [u'ああ', u'いいいい', u'う', u'えええ']
-            expected = (u"ああ        あ\n       ... \n"
-                        u"えええ    ええええ\n"
-                        u"Name: おおおおおおお, Length: 4, dtype: object")
+            s.index = ['ああ', 'いいいい', 'う', 'えええ']
+            expected = ("ああ        あ\n       ... \n"
+                        "えええ    ええええ\n"
+                        "Name: おおおおおおお, Length: 4, dtype: object")
             assert repr(s) == expected
 
         # Emable Unicode option -----------------------------------------
@@ -1933,87 +1933,87 @@ class TestSeriesFormatting(object):
 
             # unicode index
             s = Series(['a', 'bb', 'CCC', 'D'],
-                       index=[u'あ', u'いい', u'ううう', u'ええええ'])
-            expected = (u"あ            a\nいい         bb\nううう      CCC\n"
-                        u"ええええ      D\ndtype: object")
+                       index=['あ', 'いい', 'ううう', 'ええええ'])
+            expected = ("あ            a\nいい         bb\nううう      CCC\n"
+                        "ええええ      D\ndtype: object")
             assert repr(s) == expected
 
             # unicode values
-            s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
+            s = Series(['あ', 'いい', 'ううう', 'ええええ'],
                        index=['a', 'bb', 'c', 'ddd'])
-            expected = (u"a            あ\nbb         いい\nc        ううう\n"
-                        u"ddd    ええええ\ndtype: object")
+            expected = ("a            あ\nbb         いい\nc        ううう\n"
+                        "ddd    ええええ\ndtype: object")
             assert repr(s) == expected
 
             # both
-            s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                       index=[u'ああ', u'いいいい', u'う', u'えええ'])
-            expected = (u"ああ              あ\n"
-                        u"いいいい        いい\n"
-                        u"う            ううう\n"
-                        u"えええ      ええええ\ndtype: object")
+            s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                       index=['ああ', 'いいいい', 'う', 'えええ'])
+            expected = ("ああ              あ\n"
+                        "いいいい        いい\n"
+                        "う            ううう\n"
+                        "えええ      ええええ\ndtype: object")
             assert repr(s) == expected
 
             # unicode footer
-            s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                       index=[u'ああ', u'いいいい', u'う', u'えええ'],
-                       name=u'おおおおおおお')
-            expected = (u"ああ              あ\n"
-                        u"いいいい        いい\n"
-                        u"う            ううう\n"
-                        u"えええ      ええええ\n"
-                        u"Name: おおおおおおお, dtype: object")
+            s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                       index=['ああ', 'いいいい', 'う', 'えええ'],
+                       name='おおおおおおお')
+            expected = ("ああ              あ\n"
+                        "いいいい        いい\n"
+                        "う            ううう\n"
+                        "えええ      ええええ\n"
+                        "Name: おおおおおおお, dtype: object")
             assert repr(s) == expected
 
             # MultiIndex
-            idx = pd.MultiIndex.from_tuples([(u'あ', u'いい'), (u'う', u'え'), (
-                u'おおお', u'かかかか'), (u'き', u'くく')])
+            idx = pd.MultiIndex.from_tuples([('あ', 'いい'), ('う', 'え'), (
+                'おおお', 'かかかか'), ('き', 'くく')])
             s = Series([1, 22, 3333, 44444], index=idx)
-            expected = (u"あ      いい            1\n"
-                        u"う      え             22\n"
-                        u"おおお  かかかか     3333\n"
-                        u"き      くく        44444\n"
-                        u"dtype: int64")
+            expected = ("あ      いい            1\n"
+                        "う      え             22\n"
+                        "おおお  かかかか     3333\n"
+                        "き      くく        44444\n"
+                        "dtype: int64")
             assert repr(s) == expected
 
             # object dtype, shorter than unicode repr
-            s = Series([1, 22, 3333, 44444], index=[1, 'AB', np.nan, u'あああ'])
-            expected = (u"1             1\nAB           22\nNaN        3333\n"
-                        u"あああ    44444\ndtype: int64")
+            s = Series([1, 22, 3333, 44444], index=[1, 'AB', np.nan, 'あああ'])
+            expected = ("1             1\nAB           22\nNaN        3333\n"
+                        "あああ    44444\ndtype: int64")
             assert repr(s) == expected
 
             # object dtype, longer than unicode repr
             s = Series([1, 22, 3333, 44444],
-                       index=[1, 'AB', pd.Timestamp('2011-01-01'), u'あああ'])
-            expected = (u"1                          1\n"
-                        u"AB                        22\n"
-                        u"2011-01-01 00:00:00     3333\n"
-                        u"あああ                 44444\ndtype: int64")
+                       index=[1, 'AB', pd.Timestamp('2011-01-01'), 'あああ'])
+            expected = ("1                          1\n"
+                        "AB                        22\n"
+                        "2011-01-01 00:00:00     3333\n"
+                        "あああ                 44444\ndtype: int64")
             assert repr(s) == expected
 
             # truncate
             with option_context('display.max_rows', 3):
-                s = Series([u'あ', u'いい', u'ううう', u'ええええ'],
-                           name=u'おおおおおおお')
-                expected = (u"0          あ\n       ...   \n"
-                            u"3    ええええ\n"
-                            u"Name: おおおおおおお, Length: 4, dtype: object")
+                s = Series(['あ', 'いい', 'ううう', 'ええええ'],
+                           name='おおおおおおお')
+                expected = ("0          あ\n       ...   \n"
+                            "3    ええええ\n"
+                            "Name: おおおおおおお, Length: 4, dtype: object")
                 assert repr(s) == expected
 
-                s.index = [u'ああ', u'いいいい', u'う', u'えええ']
-                expected = (u"ああ            あ\n"
-                            u"            ...   \n"
-                            u"えええ    ええええ\n"
-                            u"Name: おおおおおおお, Length: 4, dtype: object")
+                s.index = ['ああ', 'いいいい', 'う', 'えええ']
+                expected = ("ああ            あ\n"
+                            "            ...   \n"
+                            "えええ    ええええ\n"
+                            "Name: おおおおおおお, Length: 4, dtype: object")
                 assert repr(s) == expected
 
             # ambiguous unicode
-            s = Series([u'¡¡', u'い¡¡', u'ううう', u'ええええ'],
-                       index=[u'ああ', u'¡¡¡¡いい', u'¡¡', u'えええ'])
-            expected = (u"ああ              ¡¡\n"
-                        u"¡¡¡¡いい        い¡¡\n"
-                        u"¡¡            ううう\n"
-                        u"えええ      ええええ\ndtype: object")
+            s = Series(['¡¡', 'い¡¡', 'ううう', 'ええええ'],
+                       index=['ああ', '¡¡¡¡いい', '¡¡', 'えええ'])
+            expected = ("ああ              ¡¡\n"
+                        "¡¡¡¡いい        い¡¡\n"
+                        "¡¡            ううう\n"
+                        "えええ      ええええ\ndtype: object")
             assert repr(s) == expected
 
     def test_float_trim_zeros(self):
diff --git a/pandas/tests/io/formats/test_printing.py b/pandas/tests/io/formats/test_printing.py
index a8de784da..ac99dbb8d 100644
--- a/pandas/tests/io/formats/test_printing.py
+++ b/pandas/tests/io/formats/test_printing.py
@@ -46,14 +46,14 @@ class TestFormattBase(object):
         assert adjoined == expected
 
     def test_adjoin_unicode(self):
-        data = [[u'あ', 'b', 'c'], ['dd', u'ええ', 'ff'], ['ggg', 'hhh', u'いいい']]
-        expected = u'あ  dd  ggg\nb  ええ  hhh\nc  ff  いいい'
+        data = [['あ', 'b', 'c'], ['dd', 'ええ', 'ff'], ['ggg', 'hhh', 'いいい']]
+        expected = 'あ  dd  ggg\nb  ええ  hhh\nc  ff  いいい'
         adjoined = printing.adjoin(2, *data)
         assert adjoined == expected
 
         adj = fmt.EastAsianTextAdjustment()
 
-        expected = u"""あ  dd    ggg
+        expected = """あ  dd    ggg
 b   ええ  hhh
 c   ff    いいい"""
 
@@ -64,7 +64,7 @@ c   ff    いいい"""
         assert adj.len(cols[1]) == 13
         assert adj.len(cols[2]) == 16
 
-        expected = u"""あ       dd         ggg
+        expected = """あ       dd         ggg
 b        ええ       hhh
 c        ff         いいい"""
 
@@ -85,40 +85,40 @@ c        ff         いいい"""
         assert just('abc', 5, mode='left') == 'abc  '
         assert just('abc', 5, mode='center') == ' abc '
         assert just('abc', 5, mode='right') == '  abc'
-        assert just(u'abc', 5, mode='left') == 'abc  '
-        assert just(u'abc', 5, mode='center') == ' abc '
-        assert just(u'abc', 5, mode='right') == '  abc'
+        assert just('abc', 5, mode='left') == 'abc  '
+        assert just('abc', 5, mode='center') == ' abc '
+        assert just('abc', 5, mode='right') == '  abc'
 
-        assert just(u'パンダ', 5, mode='left') == u'パンダ'
-        assert just(u'パンダ', 5, mode='center') == u'パンダ'
-        assert just(u'パンダ', 5, mode='right') == u'パンダ'
+        assert just('パンダ', 5, mode='left') == 'パンダ'
+        assert just('パンダ', 5, mode='center') == 'パンダ'
+        assert just('パンダ', 5, mode='right') == 'パンダ'
 
-        assert just(u'パンダ', 10, mode='left') == u'パンダ    '
-        assert just(u'パンダ', 10, mode='center') == u'  パンダ  '
-        assert just(u'パンダ', 10, mode='right') == u'    パンダ'
+        assert just('パンダ', 10, mode='left') == 'パンダ    '
+        assert just('パンダ', 10, mode='center') == '  パンダ  '
+        assert just('パンダ', 10, mode='right') == '    パンダ'
 
     def test_east_asian_len(self):
         adj = fmt.EastAsianTextAdjustment()
 
         assert adj.len('abc') == 3
-        assert adj.len(u'abc') == 3
+        assert adj.len('abc') == 3
 
-        assert adj.len(u'パンダ') == 6
-        assert adj.len(u'ﾊﾟﾝﾀﾞ') == 5
-        assert adj.len(u'パンダpanda') == 11
-        assert adj.len(u'ﾊﾟﾝﾀﾞpanda') == 10
+        assert adj.len('パンダ') == 6
+        assert adj.len('ﾊﾟﾝﾀﾞ') == 5
+        assert adj.len('パンダpanda') == 11
+        assert adj.len('ﾊﾟﾝﾀﾞpanda') == 10
 
     def test_ambiguous_width(self):
         adj = fmt.EastAsianTextAdjustment()
-        assert adj.len(u'¡¡ab') == 4
+        assert adj.len('¡¡ab') == 4
 
         with cf.option_context('display.unicode.ambiguous_as_wide', True):
             adj = fmt.EastAsianTextAdjustment()
-            assert adj.len(u'¡¡ab') == 6
+            assert adj.len('¡¡ab') == 6
 
-        data = [[u'あ', 'b', 'c'], ['dd', u'ええ', 'ff'],
-                ['ggg', u'¡¡ab', u'いいい']]
-        expected = u'あ  dd    ggg \nb   ええ  ¡¡ab\nc   ff    いいい'
+        data = [['あ', 'b', 'c'], ['dd', 'ええ', 'ff'],
+                ['ggg', '¡¡ab', 'いいい']]
+        expected = 'あ  dd    ggg \nb   ええ  ¡¡ab\nc   ff    いいい'
         adjoined = adj.adjoin(2, *data)
         assert adjoined == expected
 
diff --git a/pandas/tests/io/formats/test_to_csv.py b/pandas/tests/io/formats/test_to_csv.py
index 1a28cafa2..fbd71dfa8 100644
--- a/pandas/tests/io/formats/test_to_csv.py
+++ b/pandas/tests/io/formats/test_to_csv.py
@@ -46,7 +46,7 @@ class TestToCSV(object):
 
     def test_to_csv_defualt_encoding(self):
         # GH17097
-        df = DataFrame({'col': [u"AAAAA", u"ÄÄÄÄÄ", u"ßßßßß", u"聞聞聞聞聞"]})
+        df = DataFrame({'col': ["AAAAA", "ÄÄÄÄÄ", "ßßßßß", "聞聞聞聞聞"]})
 
         with tm.ensure_clean('test.csv') as path:
             # the default to_csv encoding in Python 2 is ascii, and that in
@@ -352,15 +352,15 @@ $1$,$2$
             with open(path, 'r') as f:
                 assert f.read() == expected_ascii
 
-    @pytest.mark.xfail
+    @pytest.mark.xfail(strict=False)
     def test_to_csv_string_array_utf8(self):
         # GH 10813
         str_array = [{'names': ['foo', 'bar']}, {'names': ['baz', 'qux']}]
         df = pd.DataFrame(str_array)
         expected_utf8 = '''\
 ,names
-0,"[u'foo', u'bar']"
-1,"[u'baz', u'qux']"
+0,"['foo', 'bar']"
+1,"['baz', 'qux']"
 '''
         with tm.ensure_clean('unicode_test.csv') as path:
             df.to_csv(path, encoding='utf-8')
diff --git a/pandas/tests/io/formats/test_to_latex.py b/pandas/tests/io/formats/test_to_latex.py
index 8a7cb2d9a..a2b65dab9 100644
--- a/pandas/tests/io/formats/test_to_latex.py
+++ b/pandas/tests/io/formats/test_to_latex.py
@@ -23,7 +23,7 @@ class TestToLatex(object):
                 assert frame.to_latex() == f.read()
 
         # test with utf-8 and encoding option (GH 7061)
-        df = DataFrame([[u'au\xdfgangen']])
+        df = DataFrame([['au\xdfgangen']])
         with tm.ensure_clean('test.tex') as path:
             df.to_latex(path, encoding='utf-8')
             with codecs.open(path, 'r', encoding='utf-8') as f:
diff --git a/pandas/tests/io/generate_legacy_storage_files.py b/pandas/tests/io/generate_legacy_storage_files.py
index 5cb443651..1f8cdabb3 100755
--- a/pandas/tests/io/generate_legacy_storage_files.py
+++ b/pandas/tests/io/generate_legacy_storage_files.py
@@ -68,7 +68,7 @@ def _create_sp_series():
     arr[-1:] = nan
 
     bseries = SparseSeries(arr, kind='block')
-    bseries.name = u'bseries'
+    bseries.name = 'bseries'
     return bseries
 
 
@@ -82,17 +82,17 @@ def _create_sp_tsseries():
 
     date_index = bdate_range('1/1/2011', periods=len(arr))
     bseries = SparseSeries(arr, index=date_index, kind='block')
-    bseries.name = u'btsseries'
+    bseries.name = 'btsseries'
     return bseries
 
 
 def _create_sp_frame():
     nan = np.nan
 
-    data = {u'A': [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],
-            u'B': [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],
-            u'C': np.arange(10).astype(np.int64),
-            u'D': [0, 1, 2, 3, 4, 5, nan, nan, nan, nan]}
+    data = {'A': [nan, nan, nan, 0, 1, 2, 3, 4, 5, 6],
+            'B': [0, 1, 2, nan, nan, nan, 3, 4, 5, 6],
+            'C': np.arange(10).astype(np.int64),
+            'D': [0, 1, 2, 3, 4, 5, nan, nan, nan, nan]}
 
     dates = bdate_range('1/1/2011', periods=10)
     return SparseDataFrame(data, index=dates)
@@ -102,11 +102,11 @@ def create_data():
     """ create the pickle/msgpack data """
 
     data = {
-        u'A': [0., 1., 2., 3., np.nan],
-        u'B': [0, 1, 0, 1, 0],
-        u'C': [u'foo1', u'foo2', u'foo3', u'foo4', u'foo5'],
-        u'D': date_range('1/1/2009', periods=5),
-        u'E': [0., 1, Timestamp('20100101'), u'foo', 2.]
+        'A': [0., 1., 2., 3., np.nan],
+        'B': [0, 1, 0, 1, 0],
+        'C': ['foo1', 'foo2', 'foo3', 'foo4', 'foo5'],
+        'D': date_range('1/1/2009', periods=5),
+        'E': [0., 1, Timestamp('20100101'), 'foo', 2.]
     }
 
     scalars = dict(timestamp=Timestamp('20130101'),
@@ -128,60 +128,60 @@ def create_data():
         index['interval'] = interval_range(0, periods=10)
 
     mi = dict(reg2=MultiIndex.from_tuples(
-        tuple(zip(*[[u'bar', u'bar', u'baz', u'baz', u'foo',
-                     u'foo', u'qux', u'qux'],
-                    [u'one', u'two', u'one', u'two', u'one',
-                     u'two', u'one', u'two']])),
-        names=[u'first', u'second']))
-
-    series = dict(float=Series(data[u'A']),
-                  int=Series(data[u'B']),
-                  mixed=Series(data[u'E']),
+        tuple(zip(*[['bar', 'bar', 'baz', 'baz', 'foo',
+                     'foo', 'qux', 'qux'],
+                    ['one', 'two', 'one', 'two', 'one',
+                     'two', 'one', 'two']])),
+        names=['first', 'second']))
+
+    series = dict(float=Series(data['A']),
+                  int=Series(data['B']),
+                  mixed=Series(data['E']),
                   ts=Series(np.arange(10).astype(np.int64),
                             index=date_range('20130101', periods=10)),
                   mi=Series(np.arange(5).astype(np.float64),
                             index=MultiIndex.from_tuples(
                                 tuple(zip(*[[1, 1, 2, 2, 2],
                                             [3, 4, 3, 4, 5]])),
-                                names=[u'one', u'two'])),
+                                names=['one', 'two'])),
                   dup=Series(np.arange(5).astype(np.float64),
-                             index=[u'A', u'B', u'C', u'D', u'A']),
-                  cat=Series(Categorical([u'foo', u'bar', u'baz'])),
+                             index=['A', 'B', 'C', 'D', 'A']),
+                  cat=Series(Categorical(['foo', 'bar', 'baz'])),
                   dt=Series(date_range('20130101', periods=5)),
                   dt_tz=Series(date_range('20130101', periods=5,
                                           tz='US/Eastern')),
                   period=Series([Period('2000Q1')] * 5))
 
     mixed_dup_df = DataFrame(data)
-    mixed_dup_df.columns = list(u"ABCDA")
-    frame = dict(float=DataFrame({u'A': series[u'float'],
-                                  u'B': series[u'float'] + 1}),
-                 int=DataFrame({u'A': series[u'int'],
-                                u'B': series[u'int'] + 1}),
+    mixed_dup_df.columns = list("ABCDA")
+    frame = dict(float=DataFrame({'A': series['float'],
+                                  'B': series['float'] + 1}),
+                 int=DataFrame({'A': series['int'],
+                                'B': series['int'] + 1}),
                  mixed=DataFrame({k: data[k]
-                                  for k in [u'A', u'B', u'C', u'D']}),
-                 mi=DataFrame({u'A': np.arange(5).astype(np.float64),
-                               u'B': np.arange(5).astype(np.int64)},
+                                  for k in ['A', 'B', 'C', 'D']}),
+                 mi=DataFrame({'A': np.arange(5).astype(np.float64),
+                               'B': np.arange(5).astype(np.int64)},
                               index=MultiIndex.from_tuples(
-                                  tuple(zip(*[[u'bar', u'bar', u'baz',
-                                               u'baz', u'baz'],
-                                              [u'one', u'two', u'one',
-                                               u'two', u'three']])),
-                                  names=[u'first', u'second'])),
+                                  tuple(zip(*[['bar', 'bar', 'baz',
+                                               'baz', 'baz'],
+                                              ['one', 'two', 'one',
+                                               'two', 'three']])),
+                                  names=['first', 'second'])),
                  dup=DataFrame(np.arange(15).reshape(5, 3).astype(np.float64),
-                               columns=[u'A', u'B', u'A']),
-                 cat_onecol=DataFrame({u'A': Categorical([u'foo', u'bar'])}),
+                               columns=['A', 'B', 'A']),
+                 cat_onecol=DataFrame({'A': Categorical(['foo', 'bar'])}),
                  cat_and_float=DataFrame({
-                     u'A': Categorical([u'foo', u'bar', u'baz']),
-                     u'B': np.arange(3).astype(np.int64)}),
+                     'A': Categorical(['foo', 'bar', 'baz']),
+                     'B': np.arange(3).astype(np.int64)}),
                  mixed_dup=mixed_dup_df,
                  dt_mixed_tzs=DataFrame({
-                     u'A': Timestamp('20130102', tz='US/Eastern'),
-                     u'B': Timestamp('20130603', tz='CET')}, index=range(5)),
+                     'A': Timestamp('20130102', tz='US/Eastern'),
+                     'B': Timestamp('20130603', tz='CET')}, index=range(5)),
                  dt_mixed2_tzs=DataFrame({
-                     u'A': Timestamp('20130102', tz='US/Eastern'),
-                     u'B': Timestamp('20130603', tz='CET'),
-                     u'C': Timestamp('20130603', tz='UTC')}, index=range(5))
+                     'A': Timestamp('20130102', tz='US/Eastern'),
+                     'B': Timestamp('20130603', tz='CET'),
+                     'C': Timestamp('20130603', tz='UTC')}, index=range(5))
                  )
 
     cat = dict(int8=Categorical(list('abcdefg')),
diff --git a/pandas/tests/io/json/test_normalize.py b/pandas/tests/io/json/test_normalize.py
index f034d52b8..6c4bbffe2 100644
--- a/pandas/tests/io/json/test_normalize.py
+++ b/pandas/tests/io/json/test_normalize.py
@@ -132,8 +132,8 @@ class TestJSONNormalize(object):
         expected = DataFrame([[1, 2]], columns=['A_A', 'A_B'])
         tm.assert_frame_equal(result.reindex_like(expected), expected)
 
-        result = json_normalize({'A': {'A': 1, 'B': 2}}, sep=u'\u03c3')
-        expected = DataFrame([[1, 2]], columns=[u'A\u03c3A', u'A\u03c3B'])
+        result = json_normalize({'A': {'A': 1, 'B': 2}}, sep='\u03c3')
+        expected = DataFrame([[1, 2]], columns=['A\u03c3A', 'A\u03c3B'])
         tm.assert_frame_equal(result.reindex_like(expected), expected)
 
         result = json_normalize(deep_nested, ['states', 'cities'],
@@ -267,8 +267,8 @@ class TestJSONNormalize(object):
         ).decode('utf8')
 
         testdata = {
-            u'sub.A': [1, 3],
-            u'sub.B': [2, 4],
+            'sub.A': [1, 3],
+            'sub.B': [2, 4],
             b"\xc3\x9cnic\xc3\xb8de".decode('utf8'): [0, 1]
         }
         expected = DataFrame(testdata)
diff --git a/pandas/tests/io/json/test_pandas.py b/pandas/tests/io/json/test_pandas.py
index a804c1a79..4ca8ea11a 100644
--- a/pandas/tests/io/json/test_pandas.py
+++ b/pandas/tests/io/json/test_pandas.py
@@ -1101,14 +1101,14 @@ DataFrame\\.index values are different \\(100\\.0 %\\)
         json = '{"a": "foo”", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
         json = StringIO(json)
         result = read_json(json, lines=True)
-        expected = DataFrame([[u"foo\u201d", "bar"], ["foo", "bar"]],
+        expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]],
                              columns=['a', 'b'])
         assert_frame_equal(result, expected)
 
         # simulate string
         json = '{"a": "foo”", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
         result = read_json(json, lines=True)
-        expected = DataFrame([[u"foo\u201d", "bar"], ["foo", "bar"]],
+        expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]],
                              columns=['a', 'b'])
         assert_frame_equal(result, expected)
 
diff --git a/pandas/tests/io/json/test_readlines.py b/pandas/tests/io/json/test_readlines.py
index 25e78526b..0cbbe81e5 100644
--- a/pandas/tests/io/json/test_readlines.py
+++ b/pandas/tests/io/json/test_readlines.py
@@ -33,14 +33,14 @@ def test_read_jsonl_unicode_chars():
     json = '{"a": "foo”", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
     json = StringIO(json)
     result = read_json(json, lines=True)
-    expected = DataFrame([[u"foo\u201d", "bar"], ["foo", "bar"]],
+    expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]],
                          columns=['a', 'b'])
     assert_frame_equal(result, expected)
 
     # simulate string
     json = '{"a": "foo”", "b": "bar"}\n{"a": "foo", "b": "bar"}\n'
     result = read_json(json, lines=True)
-    expected = DataFrame([[u"foo\u201d", "bar"], ["foo", "bar"]],
+    expected = DataFrame([["foo\u201d", "bar"], ["foo", "bar"]],
                          columns=['a', 'b'])
     assert_frame_equal(result, expected)
 
diff --git a/pandas/tests/io/parser/test_compression.py b/pandas/tests/io/parser/test_compression.py
index 6e615e795..9fdc18dfe 100644
--- a/pandas/tests/io/parser/test_compression.py
+++ b/pandas/tests/io/parser/test_compression.py
@@ -135,8 +135,8 @@ def test_compression_utf16_encoding(all_parsers, csv_dir_path):
     result = parser.read_csv(path, encoding="utf-16",
                              compression="zip", sep="\t")
     expected = pd.DataFrame({
-        u"Country": [u"Venezuela", u"Venezuela"],
-        u"Twitter": [u"Hugo Chávez Frías", u"Henrique Capriles R."]
+        "Country": ["Venezuela", "Venezuela"],
+        "Twitter": ["Hugo Chávez Frías", "Henrique Capriles R."]
     })
 
     tm.assert_frame_equal(result, expected)
diff --git a/pandas/tests/io/parser/test_usecols.py b/pandas/tests/io/parser/test_usecols.py
index 652f78d19..5804740fe 100644
--- a/pandas/tests/io/parser/test_usecols.py
+++ b/pandas/tests/io/parser/test_usecols.py
@@ -347,7 +347,7 @@ def test_usecols_with_unicode_strings(all_parsers):
     }
     expected = DataFrame(exp_data)
 
-    result = parser.read_csv(StringIO(data), usecols=[u"AAA", u"BBB"])
+    result = parser.read_csv(StringIO(data), usecols=["AAA", "BBB"])
     tm.assert_frame_equal(result, expected)
 
 
@@ -369,11 +369,11 @@ def test_usecols_with_single_byte_unicode_strings(all_parsers):
     }
     expected = DataFrame(exp_data)
 
-    result = parser.read_csv(StringIO(data), usecols=[u"A", u"B"])
+    result = parser.read_csv(StringIO(data), usecols=["A", "B"])
     tm.assert_frame_equal(result, expected)
 
 
-@pytest.mark.parametrize("usecols", [[u"AAA", b"BBB"], [b"AAA", u"BBB"]])
+@pytest.mark.parametrize("usecols", [["AAA", b"BBB"], [b"AAA", "BBB"]])
 def test_usecols_with_mixed_encoding_strings(all_parsers, usecols):
     data = """AAA,BBB,CCC,DDD
 0.056674973,8,True,a
@@ -387,7 +387,7 @@ def test_usecols_with_mixed_encoding_strings(all_parsers, usecols):
 
 @pytest.mark.parametrize("usecols", [
     ["あああ", "いい"],
-    [u"あああ", u"いい"]
+    ["あああ", "いい"]
 ])
 def test_usecols_with_multi_byte_characters(all_parsers, usecols):
     data = """あああ,いい,ううう,ええええ
diff --git a/pandas/tests/io/test_clipboard.py b/pandas/tests/io/test_clipboard.py
index ae9a8300f..d9168da6a 100644
--- a/pandas/tests/io/test_clipboard.py
+++ b/pandas/tests/io/test_clipboard.py
@@ -227,7 +227,7 @@ class TestClipboard(object):
 @pytest.mark.clipboard
 @pytest.mark.skipif(not _DEPS_INSTALLED,
                     reason="clipboard primitives not installed")
-@pytest.mark.parametrize('data', [u'\U0001f44d...', u'Ωœ∑´...', 'abcd...'])
+@pytest.mark.parametrize('data', ['\U0001f44d...', 'Ωœ∑´...', 'abcd...'])
 def test_raw_roundtrip(data):
     # PR #25040 wide unicode wasn't copied correctly on PY3 on windows
     clipboard_set(data)
diff --git a/pandas/tests/io/test_excel.py b/pandas/tests/io/test_excel.py
index 75b84bf17..e02fa1d5e 100644
--- a/pandas/tests/io/test_excel.py
+++ b/pandas/tests/io/test_excel.py
@@ -1694,10 +1694,10 @@ class TestExcelWriter(_WriterBase):
 
     def test_to_excel_output_encoding(self, merge_cells, engine, ext):
         # Avoid mixed inferred_type.
-        df = DataFrame([[u"\u0192", u"\u0193", u"\u0194"],
-                        [u"\u0195", u"\u0196", u"\u0197"]],
-                       index=[u"A\u0192", u"B"],
-                       columns=[u"X\u0193", u"Y", u"Z"])
+        df = DataFrame([["\u0192", "\u0193", "\u0194"],
+                        ["\u0195", "\u0196", "\u0197"]],
+                       index=["A\u0192", "B"],
+                       columns=["X\u0193", "Y", "Z"])
 
         with ensure_clean("__tmp_to_excel_float_format__." + ext) as filename:
             df.to_excel(filename, sheet_name="TestSheet", encoding="utf8")
diff --git a/pandas/tests/io/test_packers.py b/pandas/tests/io/test_packers.py
index 4a17cb321..90fb2b151 100644
--- a/pandas/tests/io/test_packers.py
+++ b/pandas/tests/io/test_packers.py
@@ -731,10 +731,10 @@ class TestCompression(TestPackers):
         # bad state where b'a' points to 98 == ord(b'b').
         char_unpacked[0] = ord(b'b')
 
-        # we compare the ord of bytes b'a' with unicode u'a' because the should
+        # we compare the ord of bytes b'a' with unicode 'a' because the should
         # always be the same (unless we were able to mutate the shared
         # character singleton in which case ord(b'a') == ord(b'b').
-        assert ord(b'a') == ord(u'a')
+        assert ord(b'a') == ord('a')
         tm.assert_numpy_array_equal(
             char_unpacked,
             np.array([ord(b'b')], dtype='uint8'),
diff --git a/pandas/tests/io/test_parquet.py b/pandas/tests/io/test_parquet.py
index df0281140..b8e22de89 100644
--- a/pandas/tests/io/test_parquet.py
+++ b/pandas/tests/io/test_parquet.py
@@ -83,7 +83,7 @@ def df_full():
          'string_with_nan': ['a', np.nan, 'c'],
          'string_with_none': ['a', None, 'c'],
          'bytes': [b'foo', b'bar', b'baz'],
-         'unicode': [u'foo', u'bar', u'baz'],
+         'unicode': ['foo', 'bar', 'baz'],
          'int': list(range(1, 4)),
          'uint': np.arange(3, 6).astype('u1'),
          'float': np.arange(4.0, 7.0, dtype='float64'),
@@ -241,7 +241,7 @@ class TestBasic(Base):
                            'int': list(range(1, 4))})
 
         # unicode
-        df.columns = [u'foo', u'bar']
+        df.columns = ['foo', 'bar']
         check_round_trip(df, engine)
 
     def test_columns_dtypes_invalid(self, engine):
diff --git a/pandas/tests/io/test_pickle.py b/pandas/tests/io/test_pickle.py
index dde7b15bf..8718de453 100644
--- a/pandas/tests/io/test_pickle.py
+++ b/pandas/tests/io/test_pickle.py
@@ -313,7 +313,7 @@ def test_pickle_path_localpath():
 
 @pytest.fixture
 def get_random_path():
-    return u'__%s__.pickle' % tm.rands(10)
+    return '__%s__.pickle' % tm.rands(10)
 
 
 class TestCompression(object):
diff --git a/pandas/tests/io/test_sql.py b/pandas/tests/io/test_sql.py
index 0adef349e..f9fcf58fb 100644
--- a/pandas/tests/io/test_sql.py
+++ b/pandas/tests/io/test_sql.py
@@ -857,7 +857,7 @@ class _TestSQLApi(PandasSQLTest):
 
     def test_unicode_column_name(self):
         # GH 11431
-        df = DataFrame([[1, 2], [3, 4]], columns=[u'\xe9', u'b'])
+        df = DataFrame([[1, 2], [3, 4]], columns=['\xe9', 'b'])
         df.to_sql('test_unicode', self.conn, index=False)
 
     def test_escaped_table_name(self):
@@ -1704,7 +1704,7 @@ class _TestSQLAlchemy(SQLAlchemyMixIn, PandasSQLTest):
         main(self.conn)
 
     def test_temporary_table(self):
-        test_data = u'Hello, World!'
+        test_data = 'Hello, World!'
         expected = DataFrame({'spam': [test_data]})
         Base = declarative.declarative_base()
 
@@ -2171,7 +2171,7 @@ class TestSQLiteFallback(SQLiteMixIn, PandasSQLTest):
                 ['test_weird_name]', 'test_weird_name[',
                  'test_weird_name`', 'test_weird_name"', 'test_weird_name\'',
                  '_b.test_weird_name_01-30', '"_b.test_weird_name_01-30"',
-                 '99beginswithnumber', '12345', u'\xe9']):
+                 '99beginswithnumber', '12345', '\xe9']):
             df.to_sql(weird_name, self.conn)
             sql.table_exists(weird_name, self.conn)
 
diff --git a/pandas/tests/io/test_stata.py b/pandas/tests/io/test_stata.py
index 8410eb61f..f29d592d3 100644
--- a/pandas/tests/io/test_stata.py
+++ b/pandas/tests/io/test_stata.py
@@ -277,10 +277,10 @@ class TestStata(object):
         parsed_118 = self.read_dta(self.dta22_118)
         parsed_118["Bytes"] = parsed_118["Bytes"].astype('O')
         expected = DataFrame.from_records(
-            [['Cat', 'Bogota', u'Bogotá', 1, 1.0, u'option b Ünicode', 1.0],
-             ['Dog', 'Boston', u'Uzunköprü', np.nan, np.nan, np.nan, np.nan],
-             ['Plane', 'Rome', u'Tromsø', 0, 0.0, 'option a', 0.0],
-             ['Potato', 'Tokyo', u'Elâzığ', -4, 4.0, 4, 4],
+            [['Cat', 'Bogota', 'Bogotá', 1, 1.0, 'option b Ünicode', 1.0],
+             ['Dog', 'Boston', 'Uzunköprü', np.nan, np.nan, np.nan, np.nan],
+             ['Plane', 'Rome', 'Tromsø', 0, 0.0, 'option a', 0.0],
+             ['Potato', 'Tokyo', 'Elâzığ', -4, 4.0, 4, 4],
              ['', '', '', 0, 0.3332999, 'option a', 1 / 3.]
              ],
             columns=['Things', 'Cities', 'Unicode_Cities_Strl',
@@ -291,17 +291,17 @@ class TestStata(object):
 
         with StataReader(self.dta22_118) as rdr:
             vl = rdr.variable_labels()
-            vl_expected = {u'Unicode_Cities_Strl':
-                           u'Here are some strls with Ünicode chars',
-                           u'Longs': u'long data',
-                           u'Things': u'Here are some things',
-                           u'Bytes': u'byte data',
-                           u'Ints': u'int data',
-                           u'Cities': u'Here are some cities',
-                           u'Floats': u'float data'}
+            vl_expected = {'Unicode_Cities_Strl':
+                           'Here are some strls with Ünicode chars',
+                           'Longs': 'long data',
+                           'Things': 'Here are some things',
+                           'Bytes': 'byte data',
+                           'Ints': 'int data',
+                           'Cities': 'Here are some cities',
+                           'Floats': 'float data'}
             tm.assert_dict_equal(vl, vl_expected)
 
-            assert rdr.data_label == u'This is a  Ünicode data label'
+            assert rdr.data_label == 'This is a  Ünicode data label'
 
     def test_read_write_dta5(self):
         original = DataFrame([(np.nan, np.nan, np.nan, np.nan, np.nan)],
@@ -1213,7 +1213,7 @@ class TestStata(object):
                                   variable_labels=variable_labels,
                                   version=version)
 
-        variable_labels['a'] = u'invalid character Œ'
+        variable_labels['a'] = 'invalid character Œ'
         with tm.ensure_clean() as path:
             msg = ("Variable labels must contain only characters that can be"
                    " encoded in Latin-1")
@@ -1227,13 +1227,13 @@ class TestStata(object):
                                  'b': [1.0, 3.0, 27.0, 81.0],
                                  'c': ['Atlanta', 'Birmingham',
                                        'Cincinnati', 'Detroit']})
-        values = [u'\u03A1', u'\u0391',
-                  u'\u039D', u'\u0394',
-                  u'\u0391', u'\u03A3']
+        values = ['\u03A1', '\u0391',
+                  '\u039D', '\u0394',
+                  '\u0391', '\u03A3']
 
         variable_labels_utf8 = {'a': 'City Rank',
                                 'b': 'City Exponent',
-                                'c': u''.join(values)}
+                                'c': ''.join(values)}
 
         msg = ("Variable labels must contain only characters that can be"
                " encoded in Latin-1")
@@ -1521,9 +1521,9 @@ class TestStata(object):
         unicode_df = self.read_dta(self.dta25_118)
 
         columns = ['utf8', 'latin1', 'ascii', 'utf8_strl', 'ascii_strl']
-        values = [[u'ραηδας', u'PÄNDÄS', 'p', u'ραηδας', 'p'],
-                  [u'ƤĀńĐąŜ', u'Ö', 'a', u'ƤĀńĐąŜ', 'a'],
-                  [u'ᴘᴀᴎᴅᴀS', u'Ü', 'n', u'ᴘᴀᴎᴅᴀS', 'n'],
+        values = [['ραηδας', 'PÄNDÄS', 'p', 'ραηδας', 'p'],
+                  ['ƤĀńĐąŜ', 'Ö', 'a', 'ƤĀńĐąŜ', 'a'],
+                  ['ᴘᴀᴎᴅᴀS', 'Ü', 'n', 'ᴘᴀᴎᴅᴀS', 'n'],
                   ['      ', '      ', 'd', '      ', 'd'],
                   [' ', '', 'a', ' ', 'a'],
                   ['', '', 's', '', 's'],
@@ -1593,14 +1593,14 @@ class TestStata(object):
 
     def test_strl_latin1(self):
         # GH 23573, correct GSO data to reflect correct size
-        output = DataFrame([[u'pandas'] * 2, [u'þâÑÐÅ§'] * 2],
+        output = DataFrame([['pandas'] * 2, ['þâÑÐÅ§'] * 2],
                            columns=['var_str', 'var_strl'])
 
         with tm.ensure_clean() as path:
             output.to_stata(path, version=117, convert_strl=['var_strl'])
             with open(path, 'rb') as reread:
                 content = reread.read()
-                expected = u'þâÑÐÅ§'
+                expected = 'þâÑÐÅ§'
                 assert expected.encode('latin-1') in content
                 assert expected.encode('utf-8') in content
                 gsos = content.split(b'strls')[1][1:-2]
diff --git a/pandas/tests/reshape/merge/test_merge.py b/pandas/tests/reshape/merge/test_merge.py
index 7a9736850..621ae1393 100644
--- a/pandas/tests/reshape/merge/test_merge.py
+++ b/pandas/tests/reshape/merge/test_merge.py
@@ -1230,7 +1230,7 @@ class TestMergeDtypes(object):
         (Series([1, 2], dtype='int32'), ["a", "b", "c"]),
         ([0, 1, 2], ["0", "1", "2"]),
         ([0.0, 1.0, 2.0], ["0", "1", "2"]),
-        ([0, 1, 2], [u"0", u"1", u"2"]),
+        ([0, 1, 2], ["0", "1", "2"]),
         (pd.date_range('1/1/2011', periods=2, freq='D'), ['2011-01-01',
                                                           '2011-01-02']),
         (pd.date_range('1/1/2011', periods=2, freq='D'), [0, 1]),
diff --git a/pandas/tests/reshape/test_concat.py b/pandas/tests/reshape/test_concat.py
index ad80d8093..08d80a24c 100644
--- a/pandas/tests/reshape/test_concat.py
+++ b/pandas/tests/reshape/test_concat.py
@@ -1401,8 +1401,8 @@ class TestConcatenate(ConcatenateBase):
     def test_with_mixed_tuples(self, sort):
         # 10697
         # columns have mixed tuples, so handle properly
-        df1 = DataFrame({u'A': 'foo', (u'B', 1): 'bar'}, index=range(2))
-        df2 = DataFrame({u'B': 'foo', (u'B', 1): 'bar'}, index=range(2))
+        df1 = DataFrame({'A': 'foo', ('B', 1): 'bar'}, index=range(2))
+        df2 = DataFrame({'B': 'foo', ('B', 1): 'bar'}, index=range(2))
 
         # it works
         concat([df1, df2], sort=sort)
diff --git a/pandas/tests/reshape/test_pivot.py b/pandas/tests/reshape/test_pivot.py
index dd5e53927..1e77cbbb1 100644
--- a/pandas/tests/reshape/test_pivot.py
+++ b/pandas/tests/reshape/test_pivot.py
@@ -1224,7 +1224,7 @@ class TestPivotTable(object):
 
     def test_pivot_margins_name_unicode(self):
         # issue #13292
-        greek = u'\u0394\u03bf\u03ba\u03b9\u03bc\u03ae'
+        greek = '\u0394\u03bf\u03ba\u03b9\u03bc\u03ae'
         frame = pd.DataFrame({'foo': [1, 2, 3]})
         table = pd.pivot_table(frame, index=['foo'], aggfunc=len, margins=True,
                                margins_name=greek)
diff --git a/pandas/tests/reshape/test_reshape.py b/pandas/tests/reshape/test_reshape.py
index 9b399b58a..c6e025324 100644
--- a/pandas/tests/reshape/test_reshape.py
+++ b/pandas/tests/reshape/test_reshape.py
@@ -364,17 +364,17 @@ class TestGetDummies(object):
         assert_frame_equal(result, expected)
 
     @pytest.mark.parametrize('get_dummies_kwargs,expected', [
-        ({'data': pd.DataFrame(({u'ä': ['a']}))},
-         pd.DataFrame({u'ä_a': [1]}, dtype=np.uint8)),
+        ({'data': pd.DataFrame(({'ä': ['a']}))},
+         pd.DataFrame({'ä_a': [1]}, dtype=np.uint8)),
 
-        ({'data': pd.DataFrame({'x': [u'ä']})},
-         pd.DataFrame({u'x_ä': [1]}, dtype=np.uint8)),
+        ({'data': pd.DataFrame({'x': ['ä']})},
+         pd.DataFrame({'x_ä': [1]}, dtype=np.uint8)),
 
-        ({'data': pd.DataFrame({'x': [u'a']}), 'prefix':u'ä'},
-         pd.DataFrame({u'ä_a': [1]}, dtype=np.uint8)),
+        ({'data': pd.DataFrame({'x': ['a']}), 'prefix':'ä'},
+         pd.DataFrame({'ä_a': [1]}, dtype=np.uint8)),
 
-        ({'data': pd.DataFrame({'x': [u'a']}), 'prefix_sep':u'ä'},
-         pd.DataFrame({u'xäa': [1]}, dtype=np.uint8))])
+        ({'data': pd.DataFrame({'x': ['a']}), 'prefix_sep':'ä'},
+         pd.DataFrame({'xäa': [1]}, dtype=np.uint8))])
     def test_dataframe_dummies_unicode(self, get_dummies_kwargs, expected):
         # GH22084 pd.get_dummies incorrectly encodes unicode characters
         # in dataframe column names
diff --git a/pandas/tests/scalar/timedelta/test_construction.py b/pandas/tests/scalar/timedelta/test_construction.py
index 880eca914..5fbd4bcd6 100644
--- a/pandas/tests/scalar/timedelta/test_construction.py
+++ b/pandas/tests/scalar/timedelta/test_construction.py
@@ -112,12 +112,12 @@ def test_construction():
 
     # GH#11995: unicode
     expected = Timedelta('1H')
-    result = Timedelta(u'1H')
+    result = Timedelta('1H')
     assert result == expected
-    assert to_timedelta(offsets.Hour(2)) == Timedelta(u'0 days, 02:00:00')
+    assert to_timedelta(offsets.Hour(2)) == Timedelta('0 days, 02:00:00')
 
     with pytest.raises(ValueError):
-        Timedelta(u'foo bar')
+        Timedelta('foo bar')
 
 
 @pytest.mark.parametrize('item', list({'days': 'D',
diff --git a/pandas/tests/series/test_alter_axes.py b/pandas/tests/series/test_alter_axes.py
index bdd551c98..264297fae 100644
--- a/pandas/tests/series/test_alter_axes.py
+++ b/pandas/tests/series/test_alter_axes.py
@@ -91,7 +91,7 @@ class TestSeriesAlterAxes(object):
     def test_set_name_attribute(self):
         s = Series([1, 2, 3])
         s2 = Series([1, 2, 3], name='bar')
-        for name in [7, 7., 'name', datetime(2001, 1, 1), (1,), u"\u05D0"]:
+        for name in [7, 7., 'name', datetime(2001, 1, 1), (1,), "\u05D0"]:
             s.name = name
             assert s.name == name
             s2.name = name
diff --git a/pandas/tests/series/test_constructors.py b/pandas/tests/series/test_constructors.py
index 029924597..2f9733a7a 100644
--- a/pandas/tests/series/test_constructors.py
+++ b/pandas/tests/series/test_constructors.py
@@ -1173,7 +1173,7 @@ class TestSeriesConstructors():
         assert_series_equal(result, expected)
 
     def test_constructor_name_hashable(self):
-        for n in [777, 777., 'name', datetime(2001, 11, 11), (1, ), u"\u05D0"]:
+        for n in [777, 777., 'name', datetime(2001, 11, 11), (1, ), "\u05D0"]:
             for data in [[1, 2, 3], np.ones(3), {'a': 0, 'b': 1}]:
                 s = Series(data, name=n)
                 assert s.name == n
diff --git a/pandas/tests/series/test_io.py b/pandas/tests/series/test_io.py
index 4458cf788..fbf34dbde 100644
--- a/pandas/tests/series/test_io.py
+++ b/pandas/tests/series/test_io.py
@@ -160,8 +160,8 @@ class TestSeriesToCSV():
                 name='X'), None),
         # GH 21241, 21118
         (Series(['abc', 'def', 'ghi'], name='X'), 'ascii'),
-        (Series(["123", u"你好", u"世界"], name=u"中文"), 'gb2312'),
-        (Series(["123", u"Γειά σου", u"Κόσμε"], name=u"Ελληνικά"), 'cp737')
+        (Series(["123", "你好", "世界"], name="中文"), 'gb2312'),
+        (Series(["123", "Γειά σου", "Κόσμε"], name="Ελληνικά"), 'cp737')
     ])
     def test_to_csv_compression(self, s, encoding, compression):
 
diff --git a/pandas/tests/series/test_replace.py b/pandas/tests/series/test_replace.py
index d59927993..f71877dab 100644
--- a/pandas/tests/series/test_replace.py
+++ b/pandas/tests/series/test_replace.py
@@ -270,7 +270,7 @@ class TestSeriesReplace(TestData):
     def test_replace_unicode_with_number(self):
         # GH 15743
         s = pd.Series([1, 2, 3])
-        result = s.replace(u'2', np.nan)
+        result = s.replace('2', np.nan)
         expected = pd.Series([1, 2, 3])
         tm.assert_series_equal(expected, result)
 
diff --git a/pandas/tests/series/test_repr.py b/pandas/tests/series/test_repr.py
index 63c787179..9ed7e7e0e 100644
--- a/pandas/tests/series/test_repr.py
+++ b/pandas/tests/series/test_repr.py
@@ -206,11 +206,11 @@ class TestCategoricalRepr(object):
         # see gh-21002
 
         class County(StringMixin):
-            name = u'San Sebastián'
-            state = u'PR'
+            name = 'San Sebastián'
+            state = 'PR'
 
             def __unicode__(self):
-                return self.name + u', ' + self.state
+                return self.name + ', ' + self.state
 
         cat = pd.Categorical([County() for _ in range(61)])
         idx = pd.Index(cat)
diff --git a/pandas/tests/test_strings.py b/pandas/tests/test_strings.py
index 025cdf205..a1c3dbddd 100644
--- a/pandas/tests/test_strings.py
+++ b/pandas/tests/test_strings.py
@@ -748,7 +748,7 @@ class TestStringMethods(object):
         tm.assert_series_equal(rs, xp)
 
         # unicode
-        values = np.array([u'foo', NA, u'fooommm__foo', u'mmm_'],
+        values = np.array(['foo', NA, 'fooommm__foo', 'mmm_'],
                           dtype=np.object_)
         pat = 'mmm[_]+'
 
@@ -1840,18 +1840,18 @@ class TestStringMethods(object):
         # 0x2605: ★ not number
         # 0x1378: ፸ ETHIOPIC NUMBER SEVENTY
         # 0xFF13: ３ Em 3
-        values = ['A', '3', u'¼', u'★', u'፸', u'３', 'four']
+        values = ['A', '3', '¼', '★', '፸', '３', 'four']
         s = Series(values)
         numeric_e = [False, True, True, False, True, True, False]
         decimal_e = [False, True, False, False, False, True, False]
         tm.assert_series_equal(s.str.isnumeric(), Series(numeric_e))
         tm.assert_series_equal(s.str.isdecimal(), Series(decimal_e))
 
-        unicodes = [u'A', u'3', u'¼', u'★', u'፸', u'３', u'four']
+        unicodes = ['A', '3', '¼', '★', '፸', '３', 'four']
         assert s.str.isnumeric().tolist() == [v.isnumeric() for v in unicodes]
         assert s.str.isdecimal().tolist() == [v.isdecimal() for v in unicodes]
 
-        values = ['A', np.nan, u'¼', u'★', np.nan, u'３', 'four']
+        values = ['A', np.nan, '¼', '★', np.nan, '３', 'four']
         s = Series(values)
         numeric_e = [False, np.nan, True, False, np.nan, True, False]
         decimal_e = [False, np.nan, False, False, np.nan, True, False]
@@ -2604,16 +2604,16 @@ class TestStringMethods(object):
         tm.assert_series_equal(result, exp)
 
         # unicode
-        values = Series([u'a_b_c', u'c_d_e', NA, u'f_g_h'])
+        values = Series(['a_b_c', 'c_d_e', NA, 'f_g_h'])
 
         result = values.str.partition('_', expand=False)
-        exp = Series([(u'a', u'_', u'b_c'), (u'c', u'_', u'd_e'),
-                      NA, (u'f', u'_', u'g_h')])
+        exp = Series([('a', '_', 'b_c'), ('c', '_', 'd_e'),
+                      NA, ('f', '_', 'g_h')])
         tm.assert_series_equal(result, exp)
 
         result = values.str.rpartition('_', expand=False)
-        exp = Series([(u'a_b', u'_', u'c'), (u'c_d', u'_', u'e'),
-                      NA, (u'f_g', u'_', u'h')])
+        exp = Series([('a_b', '_', 'c'), ('c_d', '_', 'e'),
+                      NA, ('f_g', '_', 'h')])
         tm.assert_series_equal(result, exp)
 
         # compare to standard lib
@@ -3104,16 +3104,16 @@ class TestStringMethods(object):
         tm.assert_series_equal(result, exp)
 
     def test_normalize(self):
-        values = ['ABC', u'ＡＢＣ', u'１２３', np.nan, u'ｱｲｴ']
+        values = ['ABC', 'ＡＢＣ', '１２３', np.nan, 'ｱｲｴ']
         s = Series(values, index=['a', 'b', 'c', 'd', 'e'])
 
-        normed = [u'ABC', u'ABC', u'123', np.nan, u'アイエ']
+        normed = ['ABC', 'ABC', '123', np.nan, 'アイエ']
         expected = Series(normed, index=['a', 'b', 'c', 'd', 'e'])
 
         result = s.str.normalize('NFKC')
         tm.assert_series_equal(result, expected)
 
-        expected = Series([u'ABC', u'ＡＢＣ', u'１２３', np.nan, u'ｱｲｴ'],
+        expected = Series(['ABC', 'ＡＢＣ', '１２３', np.nan, 'ｱｲｴ'],
                           index=['a', 'b', 'c', 'd', 'e'])
 
         result = s.str.normalize('NFC')
@@ -3122,8 +3122,8 @@ class TestStringMethods(object):
         with pytest.raises(ValueError, match="invalid normalization form"):
             s.str.normalize('xxx')
 
-        s = Index([u'ＡＢＣ', u'１２３', u'ｱｲｴ'])
-        expected = Index([u'ABC', u'123', u'アイエ'])
+        s = Index(['ＡＢＣ', '１２３', 'ｱｲｴ'])
+        expected = Index(['ABC', '123', 'アイエ'])
         result = s.str.normalize('NFKC')
         tm.assert_index_equal(result, expected)
 
diff --git a/pandas/tests/util/test_assert_almost_equal.py b/pandas/tests/util/test_assert_almost_equal.py
index afee9c008..8c6b401f9 100644
--- a/pandas/tests/util/test_assert_almost_equal.py
+++ b/pandas/tests/util/test_assert_almost_equal.py
@@ -310,8 +310,8 @@ numpy array values are different \\(33\\.33333 %\\)
 \\[right\\]: \\[á, à, å\\]"""
 
     with pytest.raises(AssertionError, match=msg):
-        assert_almost_equal(np.array([u"á", u"à", u"ä"]),
-                            np.array([u"á", u"à", u"å"]))
+        assert_almost_equal(np.array(["á", "à", "ä"]),
+                            np.array(["á", "à", "å"]))
 
 
 def test_assert_almost_equal_timestamp():
diff --git a/pandas/tests/util/test_assert_frame_equal.py b/pandas/tests/util/test_assert_frame_equal.py
index 1a941c0f0..f61a31e10 100644
--- a/pandas/tests/util/test_assert_frame_equal.py
+++ b/pandas/tests/util/test_assert_frame_equal.py
@@ -185,14 +185,14 @@ DataFrame\\.iloc\\[:, 1\\] values are different \\(33\\.33333 %\\)
 
 
 @pytest.mark.parametrize("df1,df2,msg", [
-    (DataFrame({"A": [u"á", u"à", u"ä"], "E": [u"é", u"è", u"ë"]}),
-     DataFrame({"A": [u"á", u"à", u"ä"], "E": [u"é", u"è", u"e̊"]}),
+    (DataFrame({"A": ["á", "à", "ä"], "E": ["é", "è", "ë"]}),
+     DataFrame({"A": ["á", "à", "ä"], "E": ["é", "è", "e̊"]}),
      """DataFrame\\.iloc\\[:, 1\\] are different
 
 DataFrame\\.iloc\\[:, 1\\] values are different \\(33\\.33333 %\\)
 \\[left\\]:  \\[é, è, ë\\]
 \\[right\\]: \\[é, è, e̊\\]"""),
-    (DataFrame({"A": [u"á", u"à", u"ä"], "E": [u"é", u"è", u"ë"]}),
+    (DataFrame({"A": ["á", "à", "ä"], "E": ["é", "è", "ë"]}),
      DataFrame({"A": ["a", "a", "a"], "E": ["e", "e", "e"]}),
      """DataFrame\\.iloc\\[:, 0\\] are different
 
diff --git a/pandas/tests/util/test_assert_numpy_array_equal.py b/pandas/tests/util/test_assert_numpy_array_equal.py
index 99037fcf9..544759a2d 100644
--- a/pandas/tests/util/test_assert_numpy_array_equal.py
+++ b/pandas/tests/util/test_assert_numpy_array_equal.py
@@ -136,8 +136,8 @@ numpy array values are different \\(33\\.33333 %\\)
 \\[right\\]: \\[á, à, å\\]"""
 
     with pytest.raises(AssertionError, match=msg):
-        assert_numpy_array_equal(np.array([u"á", u"à", u"ä"]),
-                                 np.array([u"á", u"à", u"å"]))
+        assert_numpy_array_equal(np.array(["á", "à", "ä"]),
+                                 np.array(["á", "à", "å"]))
 
 
 def test_numpy_array_equal_object():
diff --git a/pandas/tests/util/test_assert_series_equal.py b/pandas/tests/util/test_assert_series_equal.py
index 537a0e01f..6b5f3f8b9 100644
--- a/pandas/tests/util/test_assert_series_equal.py
+++ b/pandas/tests/util/test_assert_series_equal.py
@@ -67,7 +67,7 @@ def _assert_not_series_equal_both(a, b, **kwargs):
 
 
 @pytest.mark.parametrize("data", [
-    range(3), list("abc"), list(u"áàä"),
+    range(3), list("abc"), list("áàä"),
 ])
 def test_series_equal(data):
     _assert_series_equal_both(Series(data), Series(data))
@@ -76,8 +76,8 @@ def test_series_equal(data):
 @pytest.mark.parametrize("data1,data2", [
     (range(3), range(1, 4)),
     (list("abc"), list("xyz")),
-    (list(u"áàä"), list(u"éèë")),
-    (list(u"áàä"), list(b"aaa")),
+    (list("áàä"), list("éèë")),
+    (list("áàä"), list(b"aaa")),
     (range(3), range(4)),
 ])
 def test_series_not_equal_value_mismatch(data1, data2):
diff --git a/pandas/tests/util/test_hashing.py b/pandas/tests/util/test_hashing.py
index c80b4483c..31468a40f 100644
--- a/pandas/tests/util/test_hashing.py
+++ b/pandas/tests/util/test_hashing.py
@@ -118,7 +118,7 @@ def test_hash_tuple(tup):
 
 
 @pytest.mark.parametrize("val", [
-    1, 1.4, "A", b"A", u"A", pd.Timestamp("2012-01-01"),
+    1, 1.4, "A", b"A", pd.Timestamp("2012-01-01"),
     pd.Timestamp("2012-01-01", tz="Europe/Brussels"),
     datetime.datetime(2012, 1, 1),
     pd.Timestamp("2012-01-01", tz="EST").to_pydatetime(),
