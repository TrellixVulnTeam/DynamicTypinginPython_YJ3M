commit 1f04b91dbc41265a9507e7cf124c2cc24f872804
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Mon Aug 22 00:34:27 2011 -0400

    ENH: use new fast_unique in Index.union

diff --git a/bench/better_unique.py b/bench/better_unique.py
index 57f647f13..d90208e3a 100644
--- a/bench/better_unique.py
+++ b/bench/better_unique.py
@@ -49,9 +49,12 @@ numpy = []
 wes = []
 
 for sz, n in zip(group_sizes, numbers):
-    wes_timer =  timeit.Timer(stmt='better_unique(arr)',
+    # wes_timer =  timeit.Timer(stmt='better_unique(arr)',
+    #                           setup=setup % sz)
+    wes_timer =  timeit.Timer(stmt='_tseries.fast_unique(arr)',
                               setup=setup % sz)
-    numpy_timer =  timeit.Timer(stmt='np.unique(arr, return_inverse=True)',
+
+    numpy_timer =  timeit.Timer(stmt='np.unique(arr)',
                                 setup=setup % sz)
 
     print n
@@ -67,3 +70,16 @@ result = DataFrame({'wes' : wes, 'numpy' : numpy}, index=group_sizes)
 
 def make_plot(numpy, wes):
     pass
+
+def get_test_data(ngroups=100, n=100000):
+    unique_groups = range(ngroups)
+    random.shuffle(unique_groups)
+    arr = np.asarray(np.tile(unique_groups, n / ngroups), dtype=object)
+
+    if len(arr) < n:
+        arr = np.asarray(list(arr) + unique_groups[:n - len(arr)],
+                         dtype=object)
+
+    return arr
+
+arr = get_test_data(ngroups=1000)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index e6498026c..2c350f0dd 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -206,13 +206,7 @@ class Index(np.ndarray):
         if len(self) == 0:
             return _ensure_index(other)
 
-        new_seq = np.concatenate((self, other))
-        try:
-            new_seq = np.unique(new_seq)
-        except Exception:
-            # Not sortable / multiple types
-            pass
-        return Index(new_seq)
+        return Index(_tseries.fast_unique_multiple([self, other]))
 
     def intersection(self, other):
         """
@@ -821,7 +815,9 @@ class MultiIndex(Index):
         # TODO: optimize / make less wasteful
         self_tuples = self.get_tuple_index()
         other_tuples = other.get_tuple_index()
-        uniq_tuples = np.unique(np.concatenate((self_tuples, other_tuples)))
+
+        uniq_tuples = _tseries.fast_unique_multiple([self_tuples,
+                                                     other_tuples])
         return MultiIndex.from_arrays(zip(*uniq_tuples), sortorder=0)
 
     def intersection(self, other):
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index aeece8645..7af3a2fc1 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -225,8 +225,12 @@ def fast_unique(ndarray[object] values):
         if val not in table:
             table[val] = stub
             uniques.append(val)
+    try:
+        uniques = sorted(uniques)
+    except Exception:
+        pass
 
-    return np.asarray(sorted(uniques), dtype=object)
+    return np.asarray(uniques, dtype=object)
 
 @cython.wraparound(False)
 @cython.boundscheck(False)
@@ -247,7 +251,32 @@ def fast_unique_multiple(list arrays):
             if val not in table:
                 table[val] = stub
                 uniques.append(val)
-    return np.asarray(sorted(uniques), dtype=object)
+    try:
+        uniques = sorted(uniques)
+    except Exception:
+        pass
+
+    return np.asarray(uniques, dtype=object)
+
+# from libcpp.set cimport set as stlset
+
+# cdef fast_unique_int32(ndarray arr):
+#     cdef:
+#         cdef stlset[int] table
+
+#         Py_ssize_t i, n = len(arr)
+#         int32_t* values
+#         list uniques = []
+#         int32_t val
+
+#     values = <int32_t*> arr.data
+
+#     for i from 0 <= i < n:
+#         val = values[i]
+#         if table.count(val) == 0:
+#             table.insert(val)
+#             uniques.append(val)
+#     return np.asarray(sorted(uniques), dtype=object)
 
 ctypedef double_t (* agg_func)(double_t *out, int32_t *counts, double_t *values,
                                int32_t *labels, int start, int end,
