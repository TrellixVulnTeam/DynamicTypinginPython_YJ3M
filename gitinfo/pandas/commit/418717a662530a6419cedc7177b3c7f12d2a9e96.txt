commit 418717a662530a6419cedc7177b3c7f12d2a9e96
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri Jan 6 17:20:22 2012 -0500

    ENH: type inference internals toward #328, update R merge benchmarks

diff --git a/RELEASE.rst b/RELEASE.rst
index ec2c6804e..2f5f4d840 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -153,6 +153,7 @@ pandas 0.7.0
   - Fix error in monotonic many-to-one left joins
   - Fix __eq__ comparison between DateOffsets with different relativedelta
     keywords passed
+  - Fix exception caused by parser converter returning strings (GH #583)
 
 Thanks
 ------
@@ -161,6 +162,7 @@ Thanks
 - Arthur Gerigk
 - Matt Harrison
 - Andreas Hilboll
+- Luc Kesters
 - Adam Klein
 - Gregg Lind
 - Solomon Negusse
diff --git a/bench/bench_merge.R b/bench/bench_merge.R
index eef56b7d9..f5a4c3159 100644
--- a/bench/bench_merge.R
+++ b/bench/bench_merge.R
@@ -58,11 +58,11 @@ inner.join <- function(sort=FALSE) {
 }
 
 left.join.dt <- function(sort=FALSE) {
-  result <- merge(left.dt, right.dt, all.x=TRUE, sort=sort)
+  result <- right.dt[left.dt]
 }
 
 right.join.dt <- function(sort=FALSE) {
-  result <- merge(left.dt, right.dt, all.y=TRUE, sort=sort)
+  result <- left.dt[right.dt]
 }
 
 outer.join.dt <- function(sort=FALSE) {
@@ -84,14 +84,15 @@ sort.options <- c(FALSE, TRUE)
 
 results <- matrix(nrow=3, ncol=3)
 colnames(results) <- c("base::merge", "plyr", "data.table")
-rownames(results) <- c("inner", "outer", "left")
+rownames(results) <- c("inner", "outer", "left", "right")
 
-base.functions <- c(inner.join, outer.join, left.join)
+base.functions <- c(inner.join, outer.join, left.join, right.join)
 plyr.functions <- c(function() plyr.join("inner"),
                     function() plyr.join("full"),
-                    function() plyr.join("left"))
-dt.functions <- c(inner.join.dt, outer.join.dt, left.join.dt)
-for (i in 1:3) {
+                    function() plyr.join("left"),
+					function() plyr.join("right"))
+dt.functions <- c(inner.join.dt, outer.join.dt, left.join.dt, right.join.dt)
+for (i in 1:4) {
   base.func <- base.functions[[i]]
   plyr.func <- plyr.functions[[i]]
   dt.func <- dt.functions[[i]]
diff --git a/bench/bench_merge.py b/bench/bench_merge.py
index 9f58f418c..b2c613fb9 100644
--- a/bench/bench_merge.py
+++ b/bench/bench_merge.py
@@ -46,7 +46,7 @@ right = DataFrame({'key': indices[2000:], 'key2':indices2[2000:],
 right2 = right.append(right, ignore_index=True)
 
 
-join_methods = ['inner', 'outer', 'left'] #, 'right']
+join_methods = ['inner', 'outer', 'left', 'right']
 results = DataFrame(index=join_methods, columns=[False])
 niter = 10
 for sort in [False]:
@@ -66,16 +66,19 @@ results.columns = ['pandas']
 # R results
 from StringIO import StringIO
 # many to one
-r_results = read_table(StringIO("""base::merge   plyr data.table
-inner      0.2172 0.1197     0.1035
-outer      0.3362 0.1658     0.1930
-left       0.2559 0.1217     0.1559
+r_results = read_table(StringIO("""      base::merge   plyr data.table
+inner      0.2475 0.1183     0.1100
+outer      0.4213 0.1916     0.2090
+left       0.2998 0.1188     0.0572
+right      0.3102 0.0536     0.0376
 """), sep='\s+')
 
 all_results = results.join(r_results)
 
 all_results = all_results.div(all_results['pandas'], axis=0)
 
+all_results = all_results.ix[:, ['pandas', 'data.table', 'plyr', 'base::merge']]
+
 sort_results = DataFrame.from_items([('pandas', results['sort']),
                                      ('R', r_results['sort'])])
 sort_results['Ratio'] = sort_results['R'] / sort_results['pandas']
@@ -89,11 +92,13 @@ nosort_results['Ratio'] = sort_results['R'] / sort_results['pandas']
 
 from StringIO import StringIO
 # many to one
-r_results = read_table(StringIO("""base::merge data.table
-inner      0.4503     0.1278
-outer      0.7973     0.2347
-left       0.5433     0.1877
+r_results = read_table(StringIO("""base::merge   plyr data.table
+inner      0.4610 0.1276     0.1269
+outer      0.9195 0.1881     0.2725
+left       0.6559 0.1257     0.0678
+right      0.6425 0.0522     0.0428
 """), sep='\s+')
 
 all_results = results.join(r_results)
 all_results = all_results.div(all_results['pandas'], axis=0)
+all_results = all_results.ix[:, ['pandas', 'data.table', 'plyr', 'base::merge']]
diff --git a/pandas/core/daterange.py b/pandas/core/daterange.py
index a55e2eb59..bb2270697 100644
--- a/pandas/core/daterange.py
+++ b/pandas/core/daterange.py
@@ -130,6 +130,7 @@ class DateRange(Index):
 
         return Index.equals(self.view(Index), other)
 
+    @property
     def is_all_dates(self):
         return True
 
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index d3700ebde..a86a96d4f 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -2190,7 +2190,7 @@ class DataFrame(NDFrame):
                                      columns=self.columns)
 
         # teeny hack because one does DataFrame + TimeSeries all the time
-        if self.index.is_all_dates() and other.index.is_all_dates():
+        if self.index.is_all_dates and other.index.is_all_dates:
             return self._combine_match_index(other, func, fill_value)
         else:
             return self._combine_match_columns(other, func, fill_value)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 5a8f7f2c1..565c82e20 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -74,7 +74,7 @@ class Index(np.ndarray):
         self.name = getattr(obj, 'name', None)
 
     def astype(self, dtype):
-        return Index(self.values.astype(dtype))
+        return Index(self.values.astype(dtype), name=self.name)
 
     @property
     def dtype(self):
@@ -152,15 +152,13 @@ class Index(np.ndarray):
     def _verify_integrity(self):
         return self._engine.has_integrity
 
-    _allDates = None
-    def is_all_dates(self):
-        """
-        Checks that all the labels are datetime objects
-        """
-        if self._allDates is None:
-            self._allDates = lib.isAllDates(self)
+    @cache_readonly
+    def inferred_type(self):
+        return lib.infer_dtype(self)
 
-        return self._allDates
+    @cache_readonly
+    def is_all_dates(self):
+        return self.inferred_type == 'datetime'
 
     def __iter__(self):
         return iter(self.values)
@@ -242,7 +240,7 @@ class Index(np.ndarray):
         if name:
             result.append(str(self.name) if self.name is not None else '')
 
-        if self.is_all_dates():
+        if self.is_all_dates:
             zero_time = time(0, 0)
             for dt in self:
                 if dt.time() != zero_time or dt.tzinfo is not None:
@@ -870,6 +868,7 @@ class Int64Index(Index):
     def dtype(self):
         return np.dtype('int64')
 
+    @property
     def is_all_dates(self):
         """
         Checks that all the labels are datetime objects
@@ -1115,6 +1114,7 @@ class MultiIndex(Index):
         else:
             return result_levels
 
+    @property
     def is_all_dates(self):
         return False
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 9e29244e4..e9c3e81b9 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -164,7 +164,7 @@ class Series(np.ndarray, generic.PandasObject):
         subarr.index = index
         subarr.name = name
 
-        if subarr.index.is_all_dates():
+        if subarr.index.is_all_dates:
             subarr = subarr.view(TimeSeries)
 
         return subarr
diff --git a/pandas/sparse/series.py b/pandas/sparse/series.py
index eedc82da2..71eeef547 100644
--- a/pandas/sparse/series.py
+++ b/pandas/sparse/series.py
@@ -128,7 +128,7 @@ class SparseSeries(SparseArray, Series):
         else:
             subarr = np.asarray(values, dtype=np.float64)
 
-        if index.is_all_dates():
+        if index.is_all_dates:
             cls = SparseTimeSeries
 
         # Change the class of the array to be the subclass type.
diff --git a/pandas/src/inference.pyx b/pandas/src/inference.pyx
index b64e88607..9a8d2ae1e 100644
--- a/pandas/src/inference.pyx
+++ b/pandas/src/inference.pyx
@@ -1,27 +1,454 @@
+cimport util
+
+_TYPE_MAP = {
+    np.int8: 'integer',
+    np.int16: 'integer',
+    np.int32: 'integer',
+    np.int64: 'integer',
+    np.uint8: 'integer',
+    np.uint16: 'integer',
+    np.uint32: 'integer',
+    np.uint64: 'integer',
+    np.float16: 'floating',
+    np.float32: 'floating',
+    np.float64: 'floating',
+    np.float128: 'floating',
+    np.complex64: 'complex',
+    np.complex128: 'complex',
+    np.complex256: 'complex',
+    np.string_: 'string',
+    np.unicode_: 'unicode',
+    np.bool_: 'boolean'
+}
+
+try:
+    _TYPE_MAP[np.datetime64] = 'datetime64'
+except AttributeError:
+    pass
+
+def infer_dtype(ndarray values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        object test_val
+
+    val_kind = values.dtype.type
+    if val_kind in _TYPE_MAP:
+        return _TYPE_MAP[val_kind]
+
+    if values.dtype != np.object_:
+        values = values.astype('O')
+
+    test_val = util.get_value_1d(values, 0)
+
+    if util.is_integer_object(test_val):
+        if is_integer_array(values):
+            return 'integer'
+
+    elif is_datetime(test_val):
+        if is_datetime_array(values):
+            return 'datetime'
+
+    elif util.is_float_object(test_val):
+        if is_float_array(values):
+
+            return 'floating'
+
+    elif util.is_bool_object(test_val):
+        if is_bool_array(values):
+            return 'boolean'
+
+    elif util.is_string_object(test_val):
+        if is_string_array(values):
+            return 'string'
+
+    return 'mixed'
+
+def infer_dtype_list(list values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+    pass
+
+cdef inline bint is_datetime(object o):
+    return PyDateTime_Check(o)
+
 cpdef is_array(object o):
     return np.PyArray_Check(o)
 
 
-def is_bool_array(ndarray[object] values):
-    cdef Py_ssize_t i, n = len(values)
-    for i in range(n):
-        if not util.is_bool_object(values[i]):
+def is_bool_array(ndarray values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[object] objbuf
+        object obj
+
+    if issubclass(values.dtype.type, np.bool_):
+        return True
+    elif values.dtype == np.object_:
+        objbuf = values
+
+        if n == 0:
             return False
-    return True
 
+        for i in range(n):
+            if not util.is_bool_object(objbuf[i]):
+                return False
+        return True
+    else:
+        return False
+
+def is_integer_array(ndarray values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[object] objbuf
+        object obj
+
+    if issubclass(values.dtype.type, np.integer):
+        return True
+    elif values.dtype == np.object_:
+        objbuf = values
 
+        if n == 0:
+            return False
+
+        for i in range(n):
+            if not util.is_integer_object(objbuf[i]):
+                return False
+        return True
+    else:
+        return False
 
-def isAllDates(ndarray[object, ndim=1] arr):
-    cdef int i, size = len(arr)
-    cdef object date
+def is_float_array(ndarray values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[object] objbuf
+        object obj
+
+    if issubclass(values.dtype.type, np.floating):
+        return True
+    elif values.dtype == np.object_:
+        objbuf = values
+
+        if n == 0:
+            return False
 
-    if size == 0:
+        for i in range(n):
+            if not util.is_float_object(objbuf[i]):
+                return False
+        return True
+    else:
         return False
 
-    for i from 0 <= i < size:
-        date = arr[i]
+def is_string_array(ndarray values):
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[object] objbuf
+        object obj
 
-        if not PyDateTime_Check(date):
+    if issubclass(values.dtype.type, (np.string_, np.unicode_)):
+        return True
+    elif values.dtype == np.object_:
+        objbuf = values
+
+        if n == 0:
             return False
 
+        for i in range(n):
+            if not util.is_string_object(objbuf[i]):
+                return False
+        return True
+    else:
+        return False
+
+def is_datetime_array(ndarray[object] values):
+    cdef int i, n = len(values)
+    if n == 0:
+        return False
+    for i in range(n):
+        if not is_datetime(values[i]):
+            return False
     return True
+
+
+def maybe_convert_numeric(ndarray[object] values, set na_values):
+    '''
+    Type inference function-- convert strings to numeric (potentially) and
+    convert to proper dtype array
+    '''
+    cdef:
+        Py_ssize_t i, n
+        ndarray[float64_t] floats
+        ndarray[int64_t] ints
+        bint seen_float = 0
+        object val
+        float64_t fval
+
+    n = len(values)
+
+    floats = np.empty(n, dtype='f8')
+    ints = np.empty(n, dtype='i8')
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        if util.is_float_object(val):
+            floats[i] = val
+            seen_float = 1
+        elif val in na_values:
+            floats[i] = nan
+            seen_float = 1
+        elif val is None:
+            floats[i] = nan
+            seen_float = 1
+        elif len(val) == 0:
+            floats[i] = nan
+            seen_float = 1
+        else:
+            fval = float(val)
+            floats[i] = fval
+            if not seen_float:
+                if '.' in val:
+                    seen_float = 1
+                else:
+                    ints[i] = <int64_t> fval
+
+    if seen_float:
+        return floats
+    else:
+        return ints
+
+def maybe_convert_objects(ndarray[object] objects):
+    '''
+    Type inference function-- convert object array to proper dtype
+    '''
+    cdef:
+        Py_ssize_t i, n
+        ndarray[float64_t] floats
+        ndarray[int64_t] ints
+        ndarray[uint8_t] bools
+        bint seen_float = 0
+        bint seen_int = 0
+        bint seen_bool = 0
+        bint seen_object = 0
+        bint seen_null = 0
+        object val, onan
+        float64_t fval, fnan
+
+    n = len(objects)
+
+    floats = np.empty(n, dtype='f8')
+    ints = np.empty(n, dtype='i8')
+    bools = np.empty(n, dtype=np.uint8)
+
+    onan = np.nan
+    fnan = np.nan
+
+    for i from 0 <= i < n:
+        val = objects[i]
+
+        if val is None:
+            seen_null = 1
+            objects[i] = onan
+            floats[i] = fnan
+        elif util.is_bool_object(val):
+            seen_bool = 1
+            bools[i] = val
+        elif util.is_integer_object(val):
+            seen_int = 1
+            floats[i] = <float64_t> val
+            if not seen_null:
+                ints[i] = val
+        elif util.is_float_object(val):
+            floats[i] = val
+            seen_float = 1
+        elif not util.is_string_object(val):
+            # this will convert Decimal objects
+            try:
+                floats[i] = float(val)
+                seen_float = 1
+            except Exception:
+                pass
+        else:
+            seen_object = 1
+
+    if seen_null:
+        if (seen_float or seen_int) and not seen_object:
+            return floats
+        else:
+            return objects
+    else:
+        if seen_object:
+            return objects
+        elif not seen_bool:
+            if seen_float:
+                return floats
+            elif seen_int:
+                return ints
+        else:
+            if not seen_float and not seen_int:
+                return bools.view(np.bool_)
+
+        return objects
+
+convert_sql_column = maybe_convert_objects
+
+def try_parse_dates(ndarray[object] values, parser=None):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[object] result
+
+    from datetime import datetime
+
+    n = len(values)
+    result = np.empty(n, dtype='O')
+
+    if parser is None:
+        try:
+            from dateutil import parser
+            parse_date = parser.parse
+        except ImportError: # pragma: no cover
+            def parse_date(s):
+                try:
+                    return datetime.strptime(s, '%m/%d/%Y')
+                except Exception:
+                    return s
+    else:
+        parse_date = parser
+
+    # EAFP
+    try:
+        for i from 0 <= i < n:
+            result[i] = parse_date(values[i])
+    except Exception:
+        # failed
+        return values
+
+    return result
+
+def sanitize_objects(ndarray[object] values, set na_values):
+    cdef:
+        Py_ssize_t i, n
+        object val, onan
+
+    n = len(values)
+    onan = np.nan
+
+    for i from 0 <= i < n:
+        val = values[i]
+        if val == '' or val in na_values:
+            values[i] = onan
+
+def maybe_convert_bool(ndarray[object] arr):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[uint8_t] result
+        object val
+
+    n = len(arr)
+    result = np.empty(n, dtype=np.uint8)
+
+    for i from 0 <= i < n:
+        val = arr[i]
+
+        if val == 'True':
+            result[i] = 1
+        elif val == 'False':
+            result[i] = 0
+        else:
+            return arr
+
+    return result.view(np.bool_)
+
+
+def map_infer(ndarray arr, object f):
+    '''
+    Substitute for np.vectorize with pandas-friendly dtype inference
+
+    Parameters
+    ----------
+    arr : ndarray
+    f : function
+
+    Returns
+    -------
+    mapped : ndarray
+    '''
+    cdef:
+        Py_ssize_t i, n
+        flatiter it
+        ndarray[object] result
+        object val
+
+    it = <flatiter> PyArray_IterNew(arr)
+    n = len(arr)
+    result = np.empty(n, dtype=object)
+    for i in range(n):
+        val = PyArray_GETITEM(arr, PyArray_ITER_DATA(it))
+        result[i] = f(val)
+        PyArray_ITER_NEXT(it)
+
+    return maybe_convert_objects(result)
+
+def to_object_array(list rows):
+    cdef:
+        Py_ssize_t i, j, n, k, tmp
+        ndarray[object, ndim=2] result
+        list row
+
+    n = len(rows)
+
+    k = 0
+    for i from 0 <= i < n:
+        tmp = len(rows[i])
+        if tmp > k:
+            k = tmp
+
+    result = np.empty((n, k), dtype=object)
+
+    for i from 0 <= i < n:
+        row = rows[i]
+
+        for j from 0 <= j < len(row):
+            result[i, j] = row[j]
+
+    return result
+
+def tuples_to_object_array(ndarray[object] tuples):
+    cdef:
+        Py_ssize_t i, j, n, k, tmp
+        ndarray[object, ndim=2] result
+        tuple tup
+
+    n = len(tuples)
+    k = len(tuples[0])
+    result = np.empty((n, k), dtype=object)
+    for i in range(n):
+        tup = tuples[i]
+        for j in range(k):
+            result[i, j] = tup[j]
+
+    return result
+
+def to_object_array_tuples(list rows):
+    cdef:
+        Py_ssize_t i, j, n, k, tmp
+        ndarray[object, ndim=2] result
+        tuple row
+
+    n = len(rows)
+
+    k = 0
+    for i from 0 <= i < n:
+        tmp = len(rows[i])
+        if tmp > k:
+            k = tmp
+
+    result = np.empty((n, k), dtype=object)
+
+    for i from 0 <= i < n:
+        row = rows[i]
+
+        for j from 0 <= j < len(row):
+            result[i, j] = row[j]
+
+    return result
+
diff --git a/pandas/src/numpy_helper.h b/pandas/src/numpy_helper.h
index 5023a8b78..6c123bfa5 100644
--- a/pandas/src/numpy_helper.h
+++ b/pandas/src/numpy_helper.h
@@ -13,9 +13,35 @@
   #endif
 #endif
 
+#define PANDAS_FLOAT 0
+#define PANDAS_INT 1
+#define PANDAS_BOOL 2
+#define PANDAS_STRING 3
+#define PANDAS_OBJECT 4
+
+PANDAS_INLINE int
+infer_type(PyObject* obj) {
+  if (PyBool_Check(obj)) {
+    return PANDAS_BOOL;
+  }
+  else if (PyArray_IsIntegerScalar(obj)) {
+    return PANDAS_INT;
+  }
+  else if (PyFloat_Check(obj) || PyArray_IsScalar(obj, Floating)) {
+    return PANDAS_FLOAT;
+  }
+  else if (PyString_Check(obj) || PyUnicode_Check(obj)) {
+    return PANDAS_STRING;
+  }
+  else {
+    return PANDAS_OBJECT;
+  }
+}
+
 PANDAS_INLINE int
 is_integer_object(PyObject* obj) {
-  return PyArray_IsIntegerScalar(obj);
+  return (!PyBool_Check(obj)) && PyArray_IsIntegerScalar(obj);
+//  return PyArray_IsIntegerScalar(obj);
 }
 
 PANDAS_INLINE int
diff --git a/pandas/src/parsing.pyx b/pandas/src/parsing.pyx
deleted file mode 100644
index bf1fa458c..000000000
--- a/pandas/src/parsing.pyx
+++ /dev/null
@@ -1,254 +0,0 @@
-cimport cpython
-
-def to_object_array(list rows):
-    cdef:
-        Py_ssize_t i, j, n, k, tmp
-        ndarray[object, ndim=2] result
-        list row
-
-    n = len(rows)
-
-    k = 0
-    for i from 0 <= i < n:
-        tmp = len(rows[i])
-        if tmp > k:
-            k = tmp
-
-    result = np.empty((n, k), dtype=object)
-
-    for i from 0 <= i < n:
-        row = rows[i]
-
-        for j from 0 <= j < len(row):
-            result[i, j] = row[j]
-
-    return result
-
-def tuples_to_object_array(ndarray[object] tuples):
-    cdef:
-        Py_ssize_t i, j, n, k, tmp
-        ndarray[object, ndim=2] result
-        tuple tup
-
-    n = len(tuples)
-    k = len(tuples[0])
-    result = np.empty((n, k), dtype=object)
-    for i in range(n):
-        tup = tuples[i]
-        for j in range(k):
-            result[i, j] = tup[j]
-
-    return result
-
-def to_object_array_tuples(list rows):
-    cdef:
-        Py_ssize_t i, j, n, k, tmp
-        ndarray[object, ndim=2] result
-        tuple row
-
-    n = len(rows)
-
-    k = 0
-    for i from 0 <= i < n:
-        tmp = len(rows[i])
-        if tmp > k:
-            k = tmp
-
-    result = np.empty((n, k), dtype=object)
-
-    for i from 0 <= i < n:
-        row = rows[i]
-
-        for j from 0 <= j < len(row):
-            result[i, j] = row[j]
-
-    return result
-
-def maybe_convert_numeric(ndarray[object] values, set na_values):
-    '''
-    Type inference function-- convert strings to numeric (potentially) and
-    convert to proper dtype array
-    '''
-    cdef:
-        Py_ssize_t i, n
-        ndarray[float64_t] floats
-        ndarray[int64_t] ints
-        bint seen_float = 0
-        object val
-        float64_t fval
-
-    n = len(values)
-
-    floats = np.empty(n, dtype='f8')
-    ints = np.empty(n, dtype='i8')
-
-    for i from 0 <= i < n:
-        val = values[i]
-
-        if util.is_float_object(val):
-            floats[i] = val
-            seen_float = 1
-        elif val in na_values:
-            floats[i] = nan
-            seen_float = 1
-        elif val is None:
-            floats[i] = nan
-            seen_float = 1
-        elif len(val) == 0:
-            floats[i] = nan
-            seen_float = 1
-        else:
-            fval = float(val)
-            floats[i] = fval
-            if not seen_float:
-                if '.' in val:
-                    seen_float = 1
-                else:
-                    ints[i] = <int64_t> fval
-
-    if seen_float:
-        return floats
-    else:
-        return ints
-
-def maybe_convert_objects(ndarray[object] objects):
-    '''
-    Type inference function-- convert object array to proper dtype
-    '''
-    cdef:
-        Py_ssize_t i, n
-        ndarray[float64_t] floats
-        ndarray[int64_t] ints
-        ndarray[uint8_t] bools
-        bint seen_float = 0
-        bint seen_int = 0
-        bint seen_bool = 0
-        bint seen_object = 0
-        bint seen_null = 0
-        object val, onan
-        float64_t fval, fnan
-
-    n = len(objects)
-
-    floats = np.empty(n, dtype='f8')
-    ints = np.empty(n, dtype='i8')
-    bools = np.empty(n, dtype=np.uint8)
-
-    onan = np.nan
-    fnan = np.nan
-
-    for i from 0 <= i < n:
-        val = objects[i]
-
-        if val is None:
-            seen_null = 1
-            objects[i] = onan
-            floats[i] = fnan
-        elif util.is_bool_object(val):
-            seen_bool = 1
-            bools[i] = val
-        elif util.is_integer_object(val):
-            seen_int = 1
-            floats[i] = <float64_t> val
-            if not seen_null:
-                ints[i] = val
-        elif util.is_float_object(val):
-            floats[i] = val
-            seen_float = 1
-        elif not util.is_string_object(val):
-            # this will convert Decimal objects
-            try:
-                floats[i] = float(val)
-                seen_float = 1
-            except Exception:
-                pass
-        else:
-            seen_object = 1
-
-    if seen_null:
-        if (seen_float or seen_int) and not seen_object:
-            return floats
-        else:
-            return objects
-    else:
-        if seen_object:
-            return objects
-        elif not seen_bool:
-            if seen_float:
-                return floats
-            elif seen_int:
-                return ints
-        else:
-            if not seen_float and not seen_int:
-                return bools.view(np.bool_)
-
-        return objects
-
-convert_sql_column = maybe_convert_objects
-
-def try_parse_dates(ndarray[object] values, parser=None):
-    cdef:
-        Py_ssize_t i, n
-        ndarray[object] result
-
-    from datetime import datetime
-
-    n = len(values)
-    result = np.empty(n, dtype='O')
-
-    if parser is None:
-        try:
-            from dateutil import parser
-            parse_date = parser.parse
-        except ImportError: # pragma: no cover
-            def parse_date(s):
-                try:
-                    return datetime.strptime(s, '%m/%d/%Y')
-                except Exception:
-                    return s
-    else:
-        parse_date = parser
-
-    # EAFP
-    try:
-        for i from 0 <= i < n:
-            result[i] = parse_date(values[i])
-    except Exception:
-        # failed
-        return values
-
-    return result
-
-def sanitize_objects(ndarray[object] values, set na_values):
-    cdef:
-        Py_ssize_t i, n
-        object val, onan
-
-    n = len(values)
-    onan = np.nan
-
-    for i from 0 <= i < n:
-        val = values[i]
-        if val == '' or val in na_values:
-            values[i] = onan
-
-def maybe_convert_bool(ndarray[object] arr):
-    cdef:
-        Py_ssize_t i, n
-        ndarray[uint8_t] result
-        object val
-
-    n = len(arr)
-    result = np.empty(n, dtype=np.uint8)
-
-    for i from 0 <= i < n:
-        val = arr[i]
-
-        if val == 'True':
-            result[i] = 1
-        elif val == 'False':
-            result[i] = 0
-        else:
-            return arr
-
-    return result.view(np.bool_)
diff --git a/pandas/src/sandbox.pyx b/pandas/src/sandbox.pyx
index b72a53425..a4ee34b50 100644
--- a/pandas/src/sandbox.pyx
+++ b/pandas/src/sandbox.pyx
@@ -144,3 +144,8 @@ def get_indexer(ndarray values, dict mapping):
         else:
             resbuf[i] = -1
     return fill_vec
+
+cimport util
+
+def foo2(o):
+    return util.is_integer_object(o)
diff --git a/pandas/src/skiplist.h b/pandas/src/skiplist.h
index 0188d5921..bb0fec94a 100644
--- a/pandas/src/skiplist.h
+++ b/pandas/src/skiplist.h
@@ -28,12 +28,12 @@
   #endif
 #endif
 
-PANDAS_INLINE static float __npy_nanf(void)
+PANDAS_INLINE static float __skiplist_nanf(void)
 {
     const union { int __i; float __f;} __bint = {0x7fc00000UL};
     return __bint.__f;
 }
-#define PANDAS_NAN ((double) __npy_nanf())
+#define PANDAS_NAN ((double) __skiplist_nanf())
 
 
 static PANDAS_INLINE double Log2(double val) {
diff --git a/pandas/tests/test_index.py b/pandas/tests/test_index.py
index 82b223369..601ff9788 100644
--- a/pandas/tests/test_index.py
+++ b/pandas/tests/test_index.py
@@ -67,6 +67,11 @@ class TestIndex(unittest.TestCase):
         # it works!
         casted.get_loc(5)
 
+        # pass on name
+        self.intIndex.name = 'foobar'
+        casted = self.intIndex.astype('i8')
+        self.assertEqual(casted.name, 'foobar')
+
     def test_compat(self):
         self.strIndex.tolist()
 
@@ -255,9 +260,9 @@ class TestIndex(unittest.TestCase):
     #     self.assert_(self.dateIndex[15:15] is NULL_INDEX)
 
     def test_is_all_dates(self):
-        self.assert_(self.dateIndex.is_all_dates())
-        self.assert_(not self.strIndex.is_all_dates())
-        self.assert_(not self.intIndex.is_all_dates())
+        self.assert_(self.dateIndex.is_all_dates)
+        self.assert_(not self.strIndex.is_all_dates)
+        self.assert_(not self.intIndex.is_all_dates)
 
     def test_summary(self):
         self._check_method_works(Index.summary)
@@ -737,7 +742,7 @@ class TestMultiIndex(unittest.TestCase):
         self.assert_(None not in self.index)
 
     def test_is_all_dates(self):
-        self.assert_(not self.index.is_all_dates())
+        self.assert_(not self.index.is_all_dates)
 
     def test_getitem(self):
         # scalar
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 109ae3d5e..a6f727d54 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -215,6 +215,67 @@ def test_get_reverse_indexer():
     expected = np.array([4, 2, 3, 6, 7], dtype='i4')
     assert(np.array_equal(result, expected))
 
+class TestTypeInference(unittest.TestCase):
+
+    def test_integers(self):
+        arr = np.array([1, 2, 3, np.int64(4), np.int32(5)], dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'integer')
+
+        arr = np.array([1, 2, 3, np.int64(4), np.int32(5), 'foo'],
+                       dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'mixed')
+
+        arr = np.array([1, 2, 3, 4, 5], dtype='i4')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'integer')
+
+    def test_bools(self):
+        arr = np.array([True, False, True, True, True], dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'boolean')
+
+        arr = np.array([np.bool_(True), np.bool_(False)], dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'boolean')
+
+        arr = np.array([True, False, True, 'foo'], dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'mixed')
+
+        arr = np.array([True, False, True], dtype=bool)
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'boolean')
+
+    def test_floats(self):
+        arr = np.array([1., 2., 3., np.float64(4), np.float32(5)], dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'floating')
+
+        arr = np.array([1, 2, 3, np.float64(4), np.float32(5), 'foo'],
+                       dtype='O')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'mixed')
+
+        arr = np.array([1, 2, 3, 4, 5], dtype='f4')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'floating')
+
+        arr = np.array([1, 2, 3, 4, 5], dtype='f8')
+        result = lib.infer_dtype(arr)
+        self.assertEqual(result, 'floating')
+
+    def test_string(self):
+        pass
+
+    def test_unicode(self):
+        pass
+
+    def test_datetime(self):
+        pass
+
+
 class TestMoments(unittest.TestCase):
     pass
 
diff --git a/setup.py b/setup.py
index 314e59c67..449c1496c 100755
--- a/setup.py
+++ b/setup.py
@@ -319,7 +319,7 @@ else:
     cmdclass['sdist'] =  CheckSDist
 
 tseries_depends = ['reindex', 'groupby', 'skiplist', 'moments',
-                   'generated', 'parsing', 'reduce', 'stats',
+                   'generated', 'reduce', 'stats',
                    'inference', 'properties', 'internals',
                    'hashtable', 'join']
 def srcpath(name=None, suffix='.pyx', subdir='src'):
