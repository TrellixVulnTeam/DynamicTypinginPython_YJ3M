commit 17151cac5811f136e5c6f94e222921a312ace20e
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Dec 11 15:41:59 2011 -0500

    ENH: first cut at SparseList data structure, #436

diff --git a/pandas/sparse/api.py b/pandas/sparse/api.py
index b8df3be2a..8ba509291 100644
--- a/pandas/sparse/api.py
+++ b/pandas/sparse/api.py
@@ -1,4 +1,5 @@
 from pandas.sparse.array import SparseArray
+from pandas.sparse.list import SparseList
 from pandas.sparse.series import SparseSeries
 from pandas.sparse.frame import SparseDataFrame
 from pandas.sparse.panel import SparsePanel
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index 2f9ce9faf..d311b1e85 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -105,7 +105,7 @@ to sparse
     sp_index = None
     fill_value = None
 
-    def __new__(cls, data, sparse_index=None, kind='block', fill_value=None,
+    def __new__(cls, data, sparse_index=None, kind='integer', fill_value=None,
                 copy=False):
 
         is_sparse_array = isinstance(data, SparseArray)
diff --git a/pandas/sparse/list.py b/pandas/sparse/list.py
new file mode 100644
index 000000000..8082b16bd
--- /dev/null
+++ b/pandas/sparse/list.py
@@ -0,0 +1,126 @@
+import numpy as np
+
+from pandas.sparse.array import SparseArray
+import pandas._sparse as splib
+
+class SparseList(object):
+    """
+    Data structure for accumulating data to be converted into a
+    SparseArray. Has similar API to the standard Python list
+    """
+
+    def __init__(self, data=None, fill_value=np.nan):
+        self.fill_value = fill_value
+        self._chunks = []
+
+        if data is not None:
+            self.append(data)
+
+    def __repr__(self):
+        contents = '\n'.join(repr(c) for c in self._chunks)
+        return '%s\n%s' % (object.__repr__(self), contents)
+
+    def __len__(self):
+        return sum(len(c) for c in self._chunks)
+
+    def __getitem__(self, i):
+        if i < 0:
+            if i + len(self) < 0:  # pragma: no cover
+                raise ValueError('%d out of range' % i)
+            i += len(self)
+
+        passed = 0
+        j = 0
+        while i >= passed + len(self._chunks[j]):
+            passed += len(self._chunks[j])
+            j += 1
+        return self._chunks[j][i - passed]
+
+    def __setitem__(self, i, value):
+        raise NotImplementedError
+
+    @property
+    def nchunks(self):
+        return len(self._chunks)
+
+    @property
+    def is_consolidated(self):
+        return self.nchunks == 1
+
+    def consolidate(self, inplace=True):
+        """
+        Internally consolidate chunks of data
+
+        Parameters
+        ----------
+        inplace : boolean, default True
+            Modify the calling object instead of constructing a new one
+
+        Returns
+        -------
+        splist : SparseList
+            If inplace=False, new object, otherwise reference to existing
+            object
+        """
+        if not inplace:
+            result = self.copy()
+        else:
+            result = self
+
+        if result.is_consolidated:
+            return result
+
+        result._consolidate_inplace()
+        return result
+
+    def _consolidate_inplace(self):
+        new_values = np.concatenate([c.sp_values for c in self._chunks])
+        new_index = _concat_sparse_indexes([c.sp_index for c in self._chunks])
+        new_arr = SparseArray(new_values, sparse_index=new_index,
+                              fill_value=self.fill_value)
+        self._chunks = [new_arr]
+
+    def copy(self):
+        """
+        Return copy of the list
+
+        Returns
+        -------
+        new_list : SparseList
+        """
+        new_splist = SparseList(fill_value=self.fill_value)
+        new_splist._chunks = list(self._chunks)
+        return new_splist
+
+    def to_array(self):
+        """
+        Return SparseArray from data stored in the SparseList
+
+        Returns
+        -------
+        sparr : SparseArray
+        """
+        self.consolidate(inplace=True)
+        return self._chunks[0]
+
+    def append(self, value):
+        if np.isscalar(value):
+            value = [value]
+
+        sparr = SparseArray(value, fill_value=self.fill_value)
+        self._chunks.append(sparr)
+        self._consolidated = False
+
+
+def _concat_sparse_indexes(indexes):
+    all_indices = []
+    total_length = 0
+
+    for index in indexes:
+        # increment by offset
+        inds = index.to_int_index().indices + total_length
+
+        all_indices.append(inds)
+        total_length += index.length
+
+    return splib.IntIndex(total_length, np.concatenate(all_indices))
diff --git a/pandas/sparse/tests/test_list.py b/pandas/sparse/tests/test_list.py
new file mode 100644
index 000000000..6761f5d33
--- /dev/null
+++ b/pandas/sparse/tests/test_list.py
@@ -0,0 +1,82 @@
+import unittest
+
+from numpy import nan
+import numpy as np
+
+from pandas.sparse.api import SparseList, SparseArray
+from pandas.util.testing import assert_almost_equal
+
+from test_sparse import assert_sp_array_equal
+
+
+class TestSparseList(unittest.TestCase):
+
+    def setUp(self):
+        self.na_data = np.array([nan, nan, 1, 2, 3, nan, 4, 5, nan, 6])
+        self.zero_data = np.array([0, 0, 1, 2, 3, 0, 4, 5, 0, 6])
+
+    def test_append_na(self):
+        arr = self.na_data
+        splist = SparseList()
+        splist.append(arr[:5])
+        splist.append(arr[5])
+        splist.append(arr[6:])
+
+        sparr = splist.to_array()
+        assert_sp_array_equal(sparr, SparseArray(arr))
+
+    def test_append_zero(self):
+        arr = self.zero_data
+        splist = SparseList(fill_value=0)
+        splist.append(arr[:5])
+        splist.append(arr[5])
+        splist.append(arr[6:])
+
+        sparr = splist.to_array()
+        assert_sp_array_equal(sparr, SparseArray(arr, fill_value=0))
+
+    def test_consolidate(self):
+        arr = self.na_data
+        exp_sparr = SparseArray(arr)
+
+        splist = SparseList()
+        splist.append(arr[:5])
+        splist.append(arr[5])
+        splist.append(arr[6:])
+
+        consol = splist.consolidate(inplace=False)
+        self.assert_(consol.nchunks == 1)
+        self.assert_(splist.nchunks == 3)
+        assert_sp_array_equal(consol.to_array(), exp_sparr)
+
+        splist.consolidate()
+        self.assert_(splist.nchunks == 1)
+        assert_sp_array_equal(splist.to_array(), exp_sparr)
+
+    def test_copy(self):
+        arr = self.na_data
+        exp_sparr = SparseArray(arr)
+
+        splist = SparseList()
+        splist.append(arr[:5])
+        splist.append(arr[5])
+
+        cp = splist.copy()
+        cp.append(arr[6:])
+        self.assertEquals(splist.nchunks, 2)
+        assert_sp_array_equal(cp.to_array(), exp_sparr)
+
+    def test_getitem(self):
+        arr = self.na_data
+        splist = SparseList()
+        splist.append(arr[:5])
+        splist.append(arr[5])
+        splist.append(arr[6:])
+
+        for i in range(len(arr)):
+            assert_almost_equal(splist[i], arr[i])
+
+if __name__ == '__main__':
+    import nose
+    nose.runmodule(argv=[__file__,'-vvs','-x','--pdb', '--pdb-failure'],
+                   exit=False)
diff --git a/pandas/sparse/tests/test_sparse.py b/pandas/sparse/tests/test_sparse.py
index fd2db872b..68f838359 100644
--- a/pandas/sparse/tests/test_sparse.py
+++ b/pandas/sparse/tests/test_sparse.py
@@ -60,12 +60,17 @@ def _test_data2_zero():
     return arr, index
 
 def assert_sp_series_equal(a, b):
-    assert_equal(a.sp_values, b.sp_values)
-    assert(a.sp_index.equals(b.sp_index))
-    if np.isnan(a.fill_value):
-        assert(np.isnan(b.fill_value))
+    assert(a.index.equals(b.index))
+    assert_sp_array_equal(a, b)
+
+def assert_sp_array_equal(left, right):
+    assert_almost_equal(left.sp_values, right.sp_values)
+    assert(left.sp_index.equals(right.sp_index))
+    if np.isnan(left.fill_value):
+        assert(np.isnan(right.fill_value))
     else:
-        assert(a.fill_value == b.fill_value)
+        assert(left.fill_value == right.fill_value)
+
 
 def assert_sp_frame_equal(left, right, exact_indices=True):
     """
diff --git a/pandas/src/sparse.pyx b/pandas/src/sparse.pyx
index 3b5bab7d8..a08e58694 100644
--- a/pandas/src/sparse.pyx
+++ b/pandas/src/sparse.pyx
@@ -7,8 +7,6 @@ import numpy as np
 import operator
 import sys
 
-ctypedef Py_ssize_t pyst
-
 #-------------------------------------------------------------------------------
 # Preamble stuff
 
@@ -61,6 +59,7 @@ ctypedef float64_t (* double_func)(float64_t a, float64_t b)
 
 #-------------------------------------------------------------------------------
 
+
 cdef class SparseIndex:
     '''
     Abstract superclass for sparse index types
@@ -68,6 +67,7 @@ cdef class SparseIndex:
     def __init__(self):
         raise NotImplementedError
 
+
 cdef class IntIndex(SparseIndex):
     '''
     Object for holding exact integer sparse indexing information
@@ -79,10 +79,10 @@ cdef class IntIndex(SparseIndex):
         Contains integers corresponding to
     '''
     cdef readonly:
-        pyst length, npoints
+        Py_ssize_t length, npoints
         ndarray indices
 
-    def __init__(self, pyst length, indices):
+    def __init__(self, Py_ssize_t length, indices):
         self.length = length
         self.indices = np.ascontiguousarray(indices, dtype=np.int32)
         self.npoints = len(self.indices)
@@ -123,7 +123,7 @@ cdef class IntIndex(SparseIndex):
 
     cpdef IntIndex intersect(self, SparseIndex y_):
         cdef:
-            pyst out_length, xi, yi = 0
+            Py_ssize_t out_length, xi, yi = 0
             int32_t xind
             ndarray[int32_t, ndim=1] xindices, yindices
             list new_list = []
@@ -155,7 +155,7 @@ cdef class IntIndex(SparseIndex):
 
     cpdef IntIndex make_union(self, SparseIndex y_):
         cdef:
-            pyst out_length, i, xi, yi
+            Py_ssize_t out_length, i, xi, yi
             int32_t xind
             ndarray[int32_t, ndim=1] xindices, yindices
             list new_list = []
@@ -202,9 +202,9 @@ cdef class IntIndex(SparseIndex):
         return IntIndex(x.length, new_list)
 
     @cython.wraparound(False)
-    cpdef lookup(self, pyst index):
+    cpdef lookup(self, Py_ssize_t index):
         cdef:
-            pyst res, n, cum_len = 0
+            Py_ssize_t res, n, cum_len = 0
             ndarray[int32_t, ndim=1] inds
 
         inds = self.indices
@@ -219,7 +219,7 @@ cdef class IntIndex(SparseIndex):
     cpdef ndarray reindex(self, ndarray[float64_t, ndim=1] values,
                           float64_t fill_value, SparseIndex other_):
         cdef:
-            pyst i = 0, j = 0
+            Py_ssize_t i = 0, j = 0
             IntIndex other
             ndarray[float64_t, ndim=1] result
             ndarray[int32_t, ndim=1] sinds, oinds
@@ -257,7 +257,7 @@ cdef class IntIndex(SparseIndex):
 
 cpdef get_blocks(ndarray[int32_t, ndim=1] indices):
     cdef:
-        pyst i, npoints
+        Py_ssize_t i, npoints
         int32_t block, length = 1, cur, prev
         list locs = [], lens = []
 
@@ -298,7 +298,7 @@ cdef class BlockIndex(SparseIndex):
     ----------
     '''
     cdef readonly:
-        pyst nblocks, npoints, length
+        Py_ssize_t nblocks, npoints, length
         ndarray blocs, blengths
 
     cdef:
@@ -342,7 +342,7 @@ cdef class BlockIndex(SparseIndex):
         - Blocks to not start after end of index, nor extend beyond end
         '''
         cdef:
-            pyst i
+            Py_ssize_t i
             ndarray[int32_t, ndim=1] blocs, blengths
 
         blocs = self.blocs
@@ -384,7 +384,7 @@ cdef class BlockIndex(SparseIndex):
 
     def to_int_index(self):
         cdef:
-            pyst i = 0, j, b
+            Py_ssize_t i = 0, j, b
             int32_t offset
             ndarray[int32_t, ndim=1] indices
 
@@ -417,7 +417,7 @@ cdef class BlockIndex(SparseIndex):
             list out_blocs = []
             list out_blengths = []
 
-            pyst xi = 0, yi = 0
+            Py_ssize_t xi = 0, yi = 0
             int32_t cur_loc, cur_length, diff
 
         y = other.to_block_index()
@@ -496,13 +496,13 @@ cdef class BlockIndex(SparseIndex):
         '''
         return BlockUnion(self, y.to_block_index()).result
 
-    cpdef lookup(self, pyst index):
+    cpdef lookup(self, Py_ssize_t index):
         '''
 
         Returns -1 if not found
         '''
         cdef:
-            pyst i, cum_len
+            Py_ssize_t i, cum_len
             ndarray[int32_t, ndim=1] locs, lens
 
         locs = self.blocs
@@ -524,7 +524,7 @@ cdef class BlockIndex(SparseIndex):
     cpdef ndarray reindex(self, ndarray[float64_t, ndim=1] values,
                           float64_t fill_value, SparseIndex other_):
         cdef:
-            pyst i = 0, j = 0, ocur, ocurlen
+            Py_ssize_t i = 0, j = 0, ocur, ocurlen
             BlockIndex other
             ndarray[float64_t, ndim=1] result
             ndarray[int32_t, ndim=1] slocs, slens, olocs, olens
@@ -810,7 +810,7 @@ cdef inline tuple block_nanop(ndarray x_, BlockIndex xindex,
         BlockIndex out_index
         int xi = 0, yi = 0, out_i = 0 # fp buf indices
         int xbp = 0, ybp = 0, obp = 0 # block positions
-        pyst xblock = 0, yblock = 0, outblock = 0 # block numbers
+        Py_ssize_t xblock = 0, yblock = 0, outblock = 0 # block numbers
 
         ndarray[float64_t, ndim=1] x, y
         ndarray[float64_t, ndim=1] out
@@ -922,7 +922,7 @@ cdef inline tuple block_op(ndarray x_, BlockIndex xindex, float64_t xfill,
         int xi = 0, yi = 0, out_i = 0 # fp buf indices
         int xbp = 0, ybp = 0 # block positions
         int32_t xloc, yloc
-        pyst xblock = 0, yblock = 0 # block numbers
+        Py_ssize_t xblock = 0, yblock = 0 # block numbers
 
         ndarray[float64_t, ndim=1] x, y
         ndarray[float64_t, ndim=1] out
@@ -1087,7 +1087,7 @@ def get_reindexer(ndarray[object, ndim=1] values, dict index_map):
 #                   BlockIndex sparse_index,
 #                   ndarray[int32_t, ndim=1] indexer):
 #     cdef:
-#         pyst i, length
+#         Py_ssize_t i, length
 #         ndarray[float64_t, ndim=1] out
 
 #     out = np.empty(length, dtype=np.float64)
