commit 153da508a536a3ef203d9cd315c67b5fd3022a51
Author: Jeff Reback <jeff@reback.net>
Date:   Tue Feb 7 20:24:09 2017 -0500

    TST/CLN: reorg groupby tests (#15336)

diff --git a/pandas/tests/groupby/common.py b/pandas/tests/groupby/common.py
new file mode 100644
index 000000000..8a70777d0
--- /dev/null
+++ b/pandas/tests/groupby/common.py
@@ -0,0 +1,52 @@
+""" Base setup """
+
+import numpy as np
+from pandas.util import testing as tm
+from pandas import DataFrame, MultiIndex
+
+
+class MixIn(object):
+
+    def setUp(self):
+        self.ts = tm.makeTimeSeries()
+
+        self.seriesd = tm.getSeriesData()
+        self.tsd = tm.getTimeSeriesData()
+        self.frame = DataFrame(self.seriesd)
+        self.tsframe = DataFrame(self.tsd)
+
+        self.df = DataFrame(
+            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
+             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
+             'C': np.random.randn(8),
+             'D': np.random.randn(8)})
+
+        self.df_mixed_floats = DataFrame(
+            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
+             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
+             'C': np.random.randn(8),
+             'D': np.array(
+                 np.random.randn(8), dtype='float32')})
+
+        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'], ['one', 'two',
+                                                                  'three']],
+                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
+                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
+                           names=['first', 'second'])
+        self.mframe = DataFrame(np.random.randn(10, 3), index=index,
+                                columns=['A', 'B', 'C'])
+
+        self.three_group = DataFrame(
+            {'A': ['foo', 'foo', 'foo', 'foo', 'bar', 'bar', 'bar', 'bar',
+                   'foo', 'foo', 'foo'],
+             'B': ['one', 'one', 'one', 'two', 'one', 'one', 'one', 'two',
+                   'two', 'two', 'one'],
+             'C': ['dull', 'dull', 'shiny', 'dull', 'dull', 'shiny', 'shiny',
+                   'dull', 'shiny', 'shiny', 'shiny'],
+             'D': np.random.randn(11),
+             'E': np.random.randn(11),
+             'F': np.random.randn(11)})
+
+
+def assert_fp_equal(a, b):
+    assert (np.abs(a - b) < 1e-12).all()
diff --git a/pandas/tests/groupby/test_aggregate.py b/pandas/tests/groupby/test_aggregate.py
index 00ddd293f..a1fc97eb8 100644
--- a/pandas/tests/groupby/test_aggregate.py
+++ b/pandas/tests/groupby/test_aggregate.py
@@ -1,28 +1,25 @@
 # -*- coding: utf-8 -*-
-from __future__ import print_function
-from datetime import datetime
-
-
-from pandas import date_range
-from pandas.core.index import MultiIndex
-from pandas.core.api import DataFrame
 
-from pandas.core.series import Series
-
-from pandas.util.testing import (assert_frame_equal, assert_series_equal
-                                 )
-
-from pandas.core.groupby import (SpecificationError)
-from pandas.compat import (lmap, OrderedDict)
-from pandas.formats.printing import pprint_thing
+"""
+we test .agg behavior / note that .apply is tested
+generally in test_groupby.py
+"""
 
-from pandas import compat
+from __future__ import print_function
+from datetime import datetime
+from functools import partial
 
-import pandas.core.common as com
 import numpy as np
+from numpy import nan
+import pandas as pd
 
+from pandas import (date_range, MultiIndex, DataFrame,
+                    Series, Index, bdate_range)
+from pandas.util.testing import assert_frame_equal, assert_series_equal
+from pandas.core.groupby import SpecificationError, DataError
+from pandas.compat import OrderedDict
+from pandas.formats.printing import pprint_thing
 import pandas.util.testing as tm
-import pandas as pd
 
 
 class TestGroupByAggregate(tm.TestCase):
@@ -452,35 +449,292 @@ class TestGroupByAggregate(tm.TestCase):
         expected = data.groupby(['A', 'B']).agg(lambda x: 'foo')
         assert_frame_equal(result, expected)
 
+    def test_cythonized_aggers(self):
+        data = {'A': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
+                'B': ['A', 'B'] * 6,
+                'C': np.random.randn(12)}
+        df = DataFrame(data)
+        df.loc[2:10:2, 'C'] = nan
+
+        def _testit(name):
+
+            op = lambda x: getattr(x, name)()
+
+            # single column
+            grouped = df.drop(['B'], axis=1).groupby('A')
+            exp = {}
+            for cat, group in grouped:
+                exp[cat] = op(group['C'])
+            exp = DataFrame({'C': exp})
+            exp.index.name = 'A'
+            result = op(grouped)
+            assert_frame_equal(result, exp)
+
+            # multiple columns
+            grouped = df.groupby(['A', 'B'])
+            expd = {}
+            for (cat1, cat2), group in grouped:
+                expd.setdefault(cat1, {})[cat2] = op(group['C'])
+            exp = DataFrame(expd).T.stack(dropna=False)
+            exp.index.names = ['A', 'B']
+            exp.name = 'C'
+
+            result = op(grouped)['C']
+            if not tm._incompat_bottleneck_version(name):
+                assert_series_equal(result, exp)
+
+        _testit('count')
+        _testit('sum')
+        _testit('std')
+        _testit('var')
+        _testit('sem')
+        _testit('mean')
+        _testit('median')
+        _testit('prod')
+        _testit('min')
+        _testit('max')
+
+    def test_cython_agg_boolean(self):
+        frame = DataFrame({'a': np.random.randint(0, 5, 50),
+                           'b': np.random.randint(0, 2, 50).astype('bool')})
+        result = frame.groupby('a')['b'].mean()
+        expected = frame.groupby('a')['b'].agg(np.mean)
 
-def assert_fp_equal(a, b):
-    assert (np.abs(a - b) < 1e-12).all()
+        assert_series_equal(result, expected)
 
+    def test_cython_agg_nothing_to_agg(self):
+        frame = DataFrame({'a': np.random.randint(0, 5, 50),
+                           'b': ['foo', 'bar'] * 25})
+        self.assertRaises(DataError, frame.groupby('a')['b'].mean)
+
+        frame = DataFrame({'a': np.random.randint(0, 5, 50),
+                           'b': ['foo', 'bar'] * 25})
+        self.assertRaises(DataError, frame[['b']].groupby(frame['a']).mean)
+
+    def test_cython_agg_nothing_to_agg_with_dates(self):
+        frame = DataFrame({'a': np.random.randint(0, 5, 50),
+                           'b': ['foo', 'bar'] * 25,
+                           'dates': pd.date_range('now', periods=50,
+                                                  freq='T')})
+        with tm.assertRaisesRegexp(DataError, "No numeric types to aggregate"):
+            frame.groupby('b').dates.mean()
+
+    def test_cython_agg_frame_columns(self):
+        # #2113
+        df = DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})
+
+        df.groupby(level=0, axis='columns').mean()
+        df.groupby(level=0, axis='columns').mean()
+        df.groupby(level=0, axis='columns').mean()
+        df.groupby(level=0, axis='columns').mean()
+
+    def test_cython_fail_agg(self):
+        dr = bdate_range('1/1/2000', periods=50)
+        ts = Series(['A', 'B', 'C', 'D', 'E'] * 10, index=dr)
+
+        grouped = ts.groupby(lambda x: x.month)
+        summed = grouped.sum()
+        expected = grouped.agg(np.sum)
+        assert_series_equal(summed, expected)
+
+    def test_agg_consistency(self):
+        # agg with ([]) and () not consistent
+        # GH 6715
+
+        def P1(a):
+            try:
+                return np.percentile(a.dropna(), q=1)
+            except:
+                return np.nan
+
+        import datetime as dt
+        df = DataFrame({'col1': [1, 2, 3, 4],
+                        'col2': [10, 25, 26, 31],
+                        'date': [dt.date(2013, 2, 10), dt.date(2013, 2, 10),
+                                 dt.date(2013, 2, 11), dt.date(2013, 2, 11)]})
+
+        g = df.groupby('date')
+
+        expected = g.agg([P1])
+        expected.columns = expected.columns.levels[0]
+
+        result = g.agg(P1)
+        assert_frame_equal(result, expected)
 
-def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
-    tups = lmap(tuple, df[keys].values)
-    tups = com._asarray_tuplesafe(tups)
-    expected = f(df.groupby(tups)[field])
-    for k, v in compat.iteritems(expected):
-        assert (result[k] == v)
+    def test_wrap_agg_out(self):
+        grouped = self.three_group.groupby(['A', 'B'])
 
+        def func(ser):
+            if ser.dtype == np.object:
+                raise TypeError
+            else:
+                return ser.sum()
 
-def test_decons():
-    from pandas.core.groupby import decons_group_index, get_group_index
+        result = grouped.aggregate(func)
+        exp_grouped = self.three_group.loc[:, self.three_group.columns != 'C']
+        expected = exp_grouped.groupby(['A', 'B']).aggregate(func)
+        assert_frame_equal(result, expected)
+
+    def test_agg_multiple_functions_maintain_order(self):
+        # GH #610
+        funcs = [('mean', np.mean), ('max', np.max), ('min', np.min)]
+        result = self.df.groupby('A')['C'].agg(funcs)
+        exp_cols = Index(['mean', 'max', 'min'])
+
+        self.assert_index_equal(result.columns, exp_cols)
+
+    def test_multiple_functions_tuples_and_non_tuples(self):
+        # #1359
 
-    def testit(label_list, shape):
-        group_index = get_group_index(label_list, shape, sort=True, xnull=True)
-        label_list2 = decons_group_index(group_index, shape)
+        funcs = [('foo', 'mean'), 'std']
+        ex_funcs = [('foo', 'mean'), ('std', 'std')]
 
-        for a, b in zip(label_list, label_list2):
-            assert (np.array_equal(a, b))
+        result = self.df.groupby('A')['C'].agg(funcs)
+        expected = self.df.groupby('A')['C'].agg(ex_funcs)
+        assert_frame_equal(result, expected)
+
+        result = self.df.groupby('A').agg(funcs)
+        expected = self.df.groupby('A').agg(ex_funcs)
+        assert_frame_equal(result, expected)
+
+    def test_agg_multiple_functions_too_many_lambdas(self):
+        grouped = self.df.groupby('A')
+        funcs = ['mean', lambda x: x.mean(), lambda x: x.std()]
+
+        self.assertRaises(SpecificationError, grouped.agg, funcs)
+
+    def test_more_flexible_frame_multi_function(self):
+        from pandas import concat
+
+        grouped = self.df.groupby('A')
 
-    shape = (4, 5, 6)
-    label_list = [np.tile([0, 1, 2, 3, 0, 1, 2, 3], 100), np.tile(
-        [0, 2, 4, 3, 0, 1, 2, 3], 100), np.tile(
-            [5, 1, 0, 2, 3, 0, 5, 4], 100)]
-    testit(label_list, shape)
+        exmean = grouped.agg(OrderedDict([['C', np.mean], ['D', np.mean]]))
+        exstd = grouped.agg(OrderedDict([['C', np.std], ['D', np.std]]))
 
-    shape = (10000, 10000)
-    label_list = [np.tile(np.arange(10000), 5), np.tile(np.arange(10000), 5)]
-    testit(label_list, shape)
+        expected = concat([exmean, exstd], keys=['mean', 'std'], axis=1)
+        expected = expected.swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)
+
+        d = OrderedDict([['C', [np.mean, np.std]], ['D', [np.mean, np.std]]])
+        result = grouped.aggregate(d)
+
+        assert_frame_equal(result, expected)
+
+        # be careful
+        result = grouped.aggregate(OrderedDict([['C', np.mean],
+                                                ['D', [np.mean, np.std]]]))
+        expected = grouped.aggregate(OrderedDict([['C', np.mean],
+                                                  ['D', [np.mean, np.std]]]))
+        assert_frame_equal(result, expected)
+
+        def foo(x):
+            return np.mean(x)
+
+        def bar(x):
+            return np.std(x, ddof=1)
+
+        d = OrderedDict([['C', np.mean], ['D', OrderedDict(
+            [['foo', np.mean], ['bar', np.std]])]])
+        result = grouped.aggregate(d)
+
+        d = OrderedDict([['C', [np.mean]], ['D', [foo, bar]]])
+        expected = grouped.aggregate(d)
+
+        assert_frame_equal(result, expected)
+
+    def test_multi_function_flexible_mix(self):
+        # GH #1268
+        grouped = self.df.groupby('A')
+
+        d = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
+            'bar', 'std'
+        ]])], ['D', 'sum']])
+        result = grouped.aggregate(d)
+        d2 = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
+            'bar', 'std'
+        ]])], ['D', ['sum']]])
+        result2 = grouped.aggregate(d2)
+
+        d3 = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
+            'bar', 'std'
+        ]])], ['D', {'sum': 'sum'}]])
+        expected = grouped.aggregate(d3)
+
+        assert_frame_equal(result, expected)
+        assert_frame_equal(result2, expected)
+
+    def test_agg_callables(self):
+        # GH 7929
+        df = DataFrame({'foo': [1, 2], 'bar': [3, 4]}).astype(np.int64)
+
+        class fn_class(object):
+
+            def __call__(self, x):
+                return sum(x)
+
+        equiv_callables = [sum, np.sum, lambda x: sum(x), lambda x: x.sum(),
+                           partial(sum), fn_class()]
+
+        expected = df.groupby("foo").agg(sum)
+        for ecall in equiv_callables:
+            result = df.groupby('foo').agg(ecall)
+            assert_frame_equal(result, expected)
+
+    def test__cython_agg_general(self):
+        ops = [('mean', np.mean),
+               ('median', np.median),
+               ('var', np.var),
+               ('add', np.sum),
+               ('prod', np.prod),
+               ('min', np.min),
+               ('max', np.max),
+               ('first', lambda x: x.iloc[0]),
+               ('last', lambda x: x.iloc[-1]), ]
+        df = DataFrame(np.random.randn(1000))
+        labels = np.random.randint(0, 50, size=1000).astype(float)
+
+        for op, targop in ops:
+            result = df.groupby(labels)._cython_agg_general(op)
+            expected = df.groupby(labels).agg(targop)
+            try:
+                tm.assert_frame_equal(result, expected)
+            except BaseException as exc:
+                exc.args += ('operation: %s' % op, )
+                raise
+
+    def test_cython_agg_empty_buckets(self):
+        ops = [('mean', np.mean),
+               ('median', lambda x: np.median(x) if len(x) > 0 else np.nan),
+               ('var', lambda x: np.var(x, ddof=1)),
+               ('add', lambda x: np.sum(x) if len(x) > 0 else np.nan),
+               ('prod', np.prod),
+               ('min', np.min),
+               ('max', np.max), ]
+
+        df = pd.DataFrame([11, 12, 13])
+        grps = range(0, 55, 5)
+
+        for op, targop in ops:
+            result = df.groupby(pd.cut(df[0], grps))._cython_agg_general(op)
+            expected = df.groupby(pd.cut(df[0], grps)).agg(lambda x: targop(x))
+            try:
+                tm.assert_frame_equal(result, expected)
+            except BaseException as exc:
+                exc.args += ('operation: %s' % op,)
+                raise
+
+    def test_agg_over_numpy_arrays(self):
+        # GH 3788
+        df = pd.DataFrame([[1, np.array([10, 20, 30])],
+                           [1, np.array([40, 50, 60])],
+                           [2, np.array([20, 30, 40])]],
+                          columns=['category', 'arraydata'])
+        result = df.groupby('category').agg(sum)
+
+        expected_data = [[np.array([50, 70, 90])], [np.array([20, 30, 40])]]
+        expected_index = pd.Index([1, 2], name='category')
+        expected_column = ['arraydata']
+        expected = pd.DataFrame(expected_data,
+                                index=expected_index,
+                                columns=expected_column)
+
+        assert_frame_equal(result, expected)
diff --git a/pandas/tests/groupby/test_categorical.py b/pandas/tests/groupby/test_categorical.py
index 605b32720..8952b520f 100644
--- a/pandas/tests/groupby/test_categorical.py
+++ b/pandas/tests/groupby/test_categorical.py
@@ -1,67 +1,19 @@
 # -*- coding: utf-8 -*-
 from __future__ import print_function
-from numpy import nan
-
-from pandas.core.index import Index, MultiIndex, CategoricalIndex
-from pandas.core.api import DataFrame, Categorical
-
-from pandas.core.series import Series
-
-from pandas.util.testing import (assert_frame_equal, assert_series_equal
-                                 )
+from datetime import datetime
 
-from pandas.compat import (lmap)
-
-from pandas import compat
-
-import pandas.core.common as com
 import numpy as np
+from numpy import nan
 
-import pandas.util.testing as tm
 import pandas as pd
+from pandas import (Index, MultiIndex, CategoricalIndex,
+                    DataFrame, Categorical, Series)
+from pandas.util.testing import assert_frame_equal, assert_series_equal
+import pandas.util.testing as tm
+from .common import MixIn
 
 
-class TestGroupByCategorical(tm.TestCase):
-
-    def setUp(self):
-        self.ts = tm.makeTimeSeries()
-
-        self.seriesd = tm.getSeriesData()
-        self.tsd = tm.getTimeSeriesData()
-        self.frame = DataFrame(self.seriesd)
-        self.tsframe = DataFrame(self.tsd)
-
-        self.df = DataFrame(
-            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
-             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
-             'C': np.random.randn(8),
-             'D': np.random.randn(8)})
-
-        self.df_mixed_floats = DataFrame(
-            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
-             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
-             'C': np.random.randn(8),
-             'D': np.array(
-                 np.random.randn(8), dtype='float32')})
-
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'], ['one', 'two',
-                                                                  'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
-                           names=['first', 'second'])
-        self.mframe = DataFrame(np.random.randn(10, 3), index=index,
-                                columns=['A', 'B', 'C'])
-
-        self.three_group = DataFrame(
-            {'A': ['foo', 'foo', 'foo', 'foo', 'bar', 'bar', 'bar', 'bar',
-                   'foo', 'foo', 'foo'],
-             'B': ['one', 'one', 'one', 'two', 'one', 'one', 'one', 'two',
-                   'two', 'two', 'one'],
-             'C': ['dull', 'dull', 'shiny', 'dull', 'dull', 'shiny', 'shiny',
-                   'dull', 'shiny', 'shiny', 'shiny'],
-             'D': np.random.randn(11),
-             'E': np.random.randn(11),
-             'F': np.random.randn(11)})
+class TestGroupByCategorical(MixIn, tm.TestCase):
 
     def test_level_groupby_get_group(self):
         # GH15155
@@ -210,8 +162,9 @@ class TestGroupByCategorical(tm.TestCase):
 
     def test_groupby_categorical_index(self):
 
+        s = np.random.RandomState(12345)
         levels = ['foo', 'bar', 'baz', 'qux']
-        codes = np.random.randint(0, 4, size=20)
+        codes = s.randint(0, 4, size=20)
         cats = Categorical.from_codes(codes, levels, ordered=True)
         df = DataFrame(
             np.repeat(
@@ -264,70 +217,15 @@ class TestGroupByCategorical(tm.TestCase):
         expected = pd.Series([6, 4], index=pd.Index(['X', 'Y'], name='artist'))
         tm.assert_series_equal(result, expected)
 
-    def test_groupby_categorical_unequal_len(self):
+    def test_groupby_bins_unequal_len(self):
         # GH3011
         series = Series([np.nan, np.nan, 1, 1, 2, 2, 3, 3, 4, 4])
-        # The raises only happens with categorical, not with series of types
-        # category
         bins = pd.cut(series.dropna().values, 4)
 
         # len(bins) != len(series) here
-        self.assertRaises(ValueError, lambda: series.groupby(bins).mean())
-
-    def test_groupby_categorical_two_columns(self):
-
-        # https://github.com/pandas-dev/pandas/issues/8138
-        d = {'cat':
-             pd.Categorical(["a", "b", "a", "b"], categories=["a", "b", "c"],
-                            ordered=True),
-             'ints': [1, 1, 2, 2],
-             'val': [10, 20, 30, 40]}
-        test = pd.DataFrame(d)
-
-        # Grouping on a single column
-        groups_single_key = test.groupby("cat")
-        res = groups_single_key.agg('mean')
-
-        exp_index = pd.CategoricalIndex(["a", "b", "c"], name="cat",
-                                        ordered=True)
-        exp = DataFrame({"ints": [1.5, 1.5, np.nan], "val": [20, 30, np.nan]},
-                        index=exp_index)
-        tm.assert_frame_equal(res, exp)
-
-        # Grouping on two columns
-        groups_double_key = test.groupby(["cat", "ints"])
-        res = groups_double_key.agg('mean')
-        exp = DataFrame({"val": [10, 30, 20, 40, np.nan, np.nan],
-                         "cat": pd.Categorical(["a", "a", "b", "b", "c", "c"],
-                                               ordered=True),
-                         "ints": [1, 2, 1, 2, 1, 2]}).set_index(["cat", "ints"
-                                                                 ])
-        tm.assert_frame_equal(res, exp)
-
-        # GH 10132
-        for key in [('a', 1), ('b', 2), ('b', 1), ('a', 2)]:
-            c, i = key
-            result = groups_double_key.get_group(key)
-            expected = test[(test.cat == c) & (test.ints == i)]
-            assert_frame_equal(result, expected)
-
-        d = {'C1': [3, 3, 4, 5], 'C2': [1, 2, 3, 4], 'C3': [10, 100, 200, 34]}
-        test = pd.DataFrame(d)
-        values = pd.cut(test['C1'], [1, 2, 3, 6])
-        values.name = "cat"
-        groups_double_key = test.groupby([values, 'C2'])
-
-        res = groups_double_key.agg('mean')
-        nan = np.nan
-        idx = MultiIndex.from_product(
-            [Categorical(["(1, 2]", "(2, 3]", "(3, 6]"], ordered=True),
-             [1, 2, 3, 4]],
-            names=["cat", "C2"])
-        exp = DataFrame({"C1": [nan, nan, nan, nan, 3, 3,
-                                nan, nan, nan, nan, 4, 5],
-                         "C3": [nan, nan, nan, nan, 10, 100,
-                                nan, nan, nan, nan, 200, 34]}, index=idx)
-        tm.assert_frame_equal(res, exp)
+        def f():
+            series.groupby(bins).mean()
+        self.assertRaises(ValueError, f)
 
     def test_groupby_multi_categorical_as_index(self):
         # GH13204
@@ -454,35 +352,148 @@ class TestGroupByCategorical(tm.TestCase):
         exp = np.array([1, 2, 4, np.nan])
         self.assert_numpy_array_equal(result, exp)
 
+    def test_groupby_sort_categorical(self):
+        # dataframe groupby sort was being ignored # GH 8868
+        df = DataFrame([['(7.5, 10]', 10, 10],
+                        ['(7.5, 10]', 8, 20],
+                        ['(2.5, 5]', 5, 30],
+                        ['(5, 7.5]', 6, 40],
+                        ['(2.5, 5]', 4, 50],
+                        ['(0, 2.5]', 1, 60],
+                        ['(5, 7.5]', 7, 70]], columns=['range', 'foo', 'bar'])
+        df['range'] = Categorical(df['range'], ordered=True)
+        index = CategoricalIndex(['(0, 2.5]', '(2.5, 5]', '(5, 7.5]',
+                                  '(7.5, 10]'], name='range', ordered=True)
+        result_sort = DataFrame([[1, 60], [5, 30], [6, 40], [10, 10]],
+                                columns=['foo', 'bar'], index=index)
+
+        col = 'range'
+        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
+        # when categories is ordered, group is ordered by category's order
+        assert_frame_equal(result_sort, df.groupby(col, sort=False).first())
+
+        df['range'] = Categorical(df['range'], ordered=False)
+        index = CategoricalIndex(['(0, 2.5]', '(2.5, 5]', '(5, 7.5]',
+                                  '(7.5, 10]'], name='range')
+        result_sort = DataFrame([[1, 60], [5, 30], [6, 40], [10, 10]],
+                                columns=['foo', 'bar'], index=index)
+
+        index = CategoricalIndex(['(7.5, 10]', '(2.5, 5]', '(5, 7.5]',
+                                  '(0, 2.5]'],
+                                 categories=['(7.5, 10]', '(2.5, 5]',
+                                             '(5, 7.5]', '(0, 2.5]'],
+                                 name='range')
+        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
+                                  index=index, columns=['foo', 'bar'])
+
+        col = 'range'
+        # this is an unordered categorical, but we allow this ####
+        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
+        assert_frame_equal(result_nosort, df.groupby(col, sort=False).first())
+
+    def test_groupby_sort_categorical_datetimelike(self):
+        # GH10505
+
+        # use same data as test_groupby_sort_categorical, which category is
+        # corresponding to datetime.month
+        df = DataFrame({'dt': [datetime(2011, 7, 1), datetime(2011, 7, 1),
+                               datetime(2011, 2, 1), datetime(2011, 5, 1),
+                               datetime(2011, 2, 1), datetime(2011, 1, 1),
+                               datetime(2011, 5, 1)],
+                        'foo': [10, 8, 5, 6, 4, 1, 7],
+                        'bar': [10, 20, 30, 40, 50, 60, 70]},
+                       columns=['dt', 'foo', 'bar'])
+
+        # ordered=True
+        df['dt'] = Categorical(df['dt'], ordered=True)
+        index = [datetime(2011, 1, 1), datetime(2011, 2, 1),
+                 datetime(2011, 5, 1), datetime(2011, 7, 1)]
+        result_sort = DataFrame(
+            [[1, 60], [5, 30], [6, 40], [10, 10]], columns=['foo', 'bar'])
+        result_sort.index = CategoricalIndex(index, name='dt', ordered=True)
+
+        index = [datetime(2011, 7, 1), datetime(2011, 2, 1),
+                 datetime(2011, 5, 1), datetime(2011, 1, 1)]
+        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
+                                  columns=['foo', 'bar'])
+        result_nosort.index = CategoricalIndex(index, categories=index,
+                                               name='dt', ordered=True)
+
+        col = 'dt'
+        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
+        # when categories is ordered, group is ordered by category's order
+        assert_frame_equal(result_sort, df.groupby(col, sort=False).first())
+
+        # ordered = False
+        df['dt'] = Categorical(df['dt'], ordered=False)
+        index = [datetime(2011, 1, 1), datetime(2011, 2, 1),
+                 datetime(2011, 5, 1), datetime(2011, 7, 1)]
+        result_sort = DataFrame(
+            [[1, 60], [5, 30], [6, 40], [10, 10]], columns=['foo', 'bar'])
+        result_sort.index = CategoricalIndex(index, name='dt')
+
+        index = [datetime(2011, 7, 1), datetime(2011, 2, 1),
+                 datetime(2011, 5, 1), datetime(2011, 1, 1)]
+        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
+                                  columns=['foo', 'bar'])
+        result_nosort.index = CategoricalIndex(index, categories=index,
+                                               name='dt')
+
+        col = 'dt'
+        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
+        assert_frame_equal(result_nosort, df.groupby(col, sort=False).first())
 
-def assert_fp_equal(a, b):
-    assert (np.abs(a - b) < 1e-12).all()
-
+    def test_groupby_categorical_two_columns(self):
 
-def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
-    tups = lmap(tuple, df[keys].values)
-    tups = com._asarray_tuplesafe(tups)
-    expected = f(df.groupby(tups)[field])
-    for k, v in compat.iteritems(expected):
-        assert (result[k] == v)
+        # https://github.com/pandas-dev/pandas/issues/8138
+        d = {'cat':
+             pd.Categorical(["a", "b", "a", "b"], categories=["a", "b", "c"],
+                            ordered=True),
+             'ints': [1, 1, 2, 2],
+             'val': [10, 20, 30, 40]}
+        test = pd.DataFrame(d)
 
+        # Grouping on a single column
+        groups_single_key = test.groupby("cat")
+        res = groups_single_key.agg('mean')
 
-def test_decons():
-    from pandas.core.groupby import decons_group_index, get_group_index
+        exp_index = pd.CategoricalIndex(["a", "b", "c"], name="cat",
+                                        ordered=True)
+        exp = DataFrame({"ints": [1.5, 1.5, np.nan], "val": [20, 30, np.nan]},
+                        index=exp_index)
+        tm.assert_frame_equal(res, exp)
 
-    def testit(label_list, shape):
-        group_index = get_group_index(label_list, shape, sort=True, xnull=True)
-        label_list2 = decons_group_index(group_index, shape)
+        # Grouping on two columns
+        groups_double_key = test.groupby(["cat", "ints"])
+        res = groups_double_key.agg('mean')
+        exp = DataFrame({"val": [10, 30, 20, 40, np.nan, np.nan],
+                         "cat": pd.Categorical(["a", "a", "b", "b", "c", "c"],
+                                               ordered=True),
+                         "ints": [1, 2, 1, 2, 1, 2]}).set_index(["cat", "ints"
+                                                                 ])
+        tm.assert_frame_equal(res, exp)
 
-        for a, b in zip(label_list, label_list2):
-            assert (np.array_equal(a, b))
+        # GH 10132
+        for key in [('a', 1), ('b', 2), ('b', 1), ('a', 2)]:
+            c, i = key
+            result = groups_double_key.get_group(key)
+            expected = test[(test.cat == c) & (test.ints == i)]
+            assert_frame_equal(result, expected)
 
-    shape = (4, 5, 6)
-    label_list = [np.tile([0, 1, 2, 3, 0, 1, 2, 3], 100), np.tile(
-        [0, 2, 4, 3, 0, 1, 2, 3], 100), np.tile(
-            [5, 1, 0, 2, 3, 0, 5, 4], 100)]
-    testit(label_list, shape)
+        d = {'C1': [3, 3, 4, 5], 'C2': [1, 2, 3, 4], 'C3': [10, 100, 200, 34]}
+        test = pd.DataFrame(d)
+        values = pd.cut(test['C1'], [1, 2, 3, 6])
+        values.name = "cat"
+        groups_double_key = test.groupby([values, 'C2'])
 
-    shape = (10000, 10000)
-    label_list = [np.tile(np.arange(10000), 5), np.tile(np.arange(10000), 5)]
-    testit(label_list, shape)
+        res = groups_double_key.agg('mean')
+        nan = np.nan
+        idx = MultiIndex.from_product(
+            [Categorical(["(1, 2]", "(2, 3]", "(3, 6]"], ordered=True),
+             [1, 2, 3, 4]],
+            names=["cat", "C2"])
+        exp = DataFrame({"C1": [nan, nan, nan, nan, 3, 3,
+                                nan, nan, nan, nan, 4, 5],
+                         "C3": [nan, nan, nan, nan, 10, 100,
+                                nan, nan, nan, nan, 200, 34]}, index=idx)
+        tm.assert_frame_equal(res, exp)
diff --git a/pandas/tests/groupby/test_groupby.py b/pandas/tests/groupby/test_groupby.py
index df4707fce..458e86913 100644
--- a/pandas/tests/groupby/test_groupby.py
+++ b/pandas/tests/groupby/test_groupby.py
@@ -1,20 +1,13 @@
 # -*- coding: utf-8 -*-
 from __future__ import print_function
-import nose
 
 from string import ascii_lowercase
 from datetime import datetime
 from numpy import nan
 
-from pandas.types.common import _ensure_platform_int
-from pandas import date_range, bdate_range, Timestamp, isnull
-from pandas.core.index import Index, MultiIndex, CategoricalIndex
-from pandas.core.api import Categorical, DataFrame
+from pandas import (date_range, bdate_range, Timestamp,
+                    isnull, Index, MultiIndex, DataFrame, Series)
 from pandas.core.common import UnsupportedFunctionCall
-from pandas.core.groupby import (SpecificationError, DataError, _nargsort,
-                                 _lexsort_indexer)
-from pandas.core.series import Series
-from pandas.core.config import option_context
 from pandas.util.testing import (assert_panel_equal, assert_frame_equal,
                                  assert_series_equal, assert_almost_equal,
                                  assert_index_equal, assertRaisesRegexp)
@@ -24,57 +17,16 @@ from pandas import compat
 from pandas.core.panel import Panel
 from pandas.tools.merge import concat
 from collections import defaultdict
-from functools import partial
 import pandas.core.common as com
 import numpy as np
 
 import pandas.core.nanops as nanops
-
 import pandas.util.testing as tm
 import pandas as pd
+from .common import MixIn
 
 
-class TestGroupBy(tm.TestCase):
-
-    def setUp(self):
-        self.ts = tm.makeTimeSeries()
-
-        self.seriesd = tm.getSeriesData()
-        self.tsd = tm.getTimeSeriesData()
-        self.frame = DataFrame(self.seriesd)
-        self.tsframe = DataFrame(self.tsd)
-
-        self.df = DataFrame(
-            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
-             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
-             'C': np.random.randn(8),
-             'D': np.random.randn(8)})
-
-        self.df_mixed_floats = DataFrame(
-            {'A': ['foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'foo'],
-             'B': ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
-             'C': np.random.randn(8),
-             'D': np.array(
-                 np.random.randn(8), dtype='float32')})
-
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'], ['one', 'two',
-                                                                  'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
-                           names=['first', 'second'])
-        self.mframe = DataFrame(np.random.randn(10, 3), index=index,
-                                columns=['A', 'B', 'C'])
-
-        self.three_group = DataFrame(
-            {'A': ['foo', 'foo', 'foo', 'foo', 'bar', 'bar', 'bar', 'bar',
-                   'foo', 'foo', 'foo'],
-             'B': ['one', 'one', 'one', 'two', 'one', 'one', 'one', 'two',
-                   'two', 'two', 'one'],
-             'C': ['dull', 'dull', 'shiny', 'dull', 'dull', 'shiny', 'shiny',
-                   'dull', 'shiny', 'shiny', 'shiny'],
-             'D': np.random.randn(11),
-             'E': np.random.randn(11),
-             'F': np.random.randn(11)})
+class TestGroupBy(MixIn, tm.TestCase):
 
     def test_basic(self):
         def checkit(dtype):
@@ -774,12 +726,12 @@ class TestGroupBy(tm.TestCase):
     def test_groupby_return_type(self):
 
         # GH2893, return a reduced type
-        df1 = DataFrame([{"val1": 1,
-                          "val2": 20}, {"val1": 1,
-                                        "val2": 19}, {"val1": 2,
-                                                      "val2": 27}, {"val1": 2,
-                                                                    "val2": 12}
-                         ])
+        df1 = DataFrame(
+            [{"val1": 1, "val2": 20},
+             {"val1": 1, "val2": 19},
+             {"val1": 2, "val2": 27},
+             {"val1": 2, "val2": 12}
+             ])
 
         def func(dataf):
             return dataf["val2"] - dataf["val2"].mean()
@@ -787,12 +739,12 @@ class TestGroupBy(tm.TestCase):
         result = df1.groupby("val1", squeeze=True).apply(func)
         tm.assertIsInstance(result, Series)
 
-        df2 = DataFrame([{"val1": 1,
-                          "val2": 20}, {"val1": 1,
-                                        "val2": 19}, {"val1": 1,
-                                                      "val2": 27}, {"val1": 1,
-                                                                    "val2": 12}
-                         ])
+        df2 = DataFrame(
+            [{"val1": 1, "val2": 20},
+             {"val1": 1, "val2": 19},
+             {"val1": 1, "val2": 27},
+             {"val1": 1, "val2": 12}
+             ])
 
         def func(dataf):
             return dataf["val2"] - dataf["val2"].mean()
@@ -902,6 +854,7 @@ class TestGroupBy(tm.TestCase):
                           lambda: g.get_group(('foo', 'bar', 'baz')))
 
     def test_get_group_empty_bins(self):
+
         d = pd.DataFrame([3, 1, 7, 6])
         bins = [0, 5, 10, 15]
         g = d.groupby(pd.cut(d[0], bins))
@@ -1043,266 +996,6 @@ class TestGroupBy(tm.TestCase):
         grouped = result.groupby(groupings)
         grouped.mean()
 
-    def test_transform(self):
-        data = Series(np.arange(9) // 3, index=np.arange(9))
-
-        index = np.arange(9)
-        np.random.shuffle(index)
-        data = data.reindex(index)
-
-        grouped = data.groupby(lambda x: x // 3)
-
-        transformed = grouped.transform(lambda x: x * x.sum())
-        self.assertEqual(transformed[7], 12)
-
-        # GH 8046
-        # make sure that we preserve the input order
-
-        df = DataFrame(
-            np.arange(6, dtype='int64').reshape(
-                3, 2), columns=["a", "b"], index=[0, 2, 1])
-        key = [0, 0, 1]
-        expected = df.sort_index().groupby(key).transform(
-            lambda x: x - x.mean()).groupby(key).mean()
-        result = df.groupby(key).transform(lambda x: x - x.mean()).groupby(
-            key).mean()
-        assert_frame_equal(result, expected)
-
-        def demean(arr):
-            return arr - arr.mean()
-
-        people = DataFrame(np.random.randn(5, 5),
-                           columns=['a', 'b', 'c', 'd', 'e'],
-                           index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])
-        key = ['one', 'two', 'one', 'two', 'one']
-        result = people.groupby(key).transform(demean).groupby(key).mean()
-        expected = people.groupby(key).apply(demean).groupby(key).mean()
-        assert_frame_equal(result, expected)
-
-        # GH 8430
-        df = tm.makeTimeDataFrame()
-        g = df.groupby(pd.TimeGrouper('M'))
-        g.transform(lambda x: x - 1)
-
-        # GH 9700
-        df = DataFrame({'a': range(5, 10), 'b': range(5)})
-        result = df.groupby('a').transform(max)
-        expected = DataFrame({'b': range(5)})
-        tm.assert_frame_equal(result, expected)
-
-    def test_transform_fast(self):
-
-        df = DataFrame({'id': np.arange(100000) / 3,
-                        'val': np.random.randn(100000)})
-
-        grp = df.groupby('id')['val']
-
-        values = np.repeat(grp.mean().values,
-                           _ensure_platform_int(grp.count().values))
-        expected = pd.Series(values, index=df.index, name='val')
-
-        result = grp.transform(np.mean)
-        assert_series_equal(result, expected)
-
-        result = grp.transform('mean')
-        assert_series_equal(result, expected)
-
-        # GH 12737
-        df = pd.DataFrame({'grouping': [0, 1, 1, 3], 'f': [1.1, 2.1, 3.1, 4.5],
-                           'd': pd.date_range('2014-1-1', '2014-1-4'),
-                           'i': [1, 2, 3, 4]},
-                          columns=['grouping', 'f', 'i', 'd'])
-        result = df.groupby('grouping').transform('first')
-
-        dates = [pd.Timestamp('2014-1-1'), pd.Timestamp('2014-1-2'),
-                 pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-4')]
-        expected = pd.DataFrame({'f': [1.1, 2.1, 2.1, 4.5],
-                                 'd': dates,
-                                 'i': [1, 2, 2, 4]},
-                                columns=['f', 'i', 'd'])
-        assert_frame_equal(result, expected)
-
-        # selection
-        result = df.groupby('grouping')[['f', 'i']].transform('first')
-        expected = expected[['f', 'i']]
-        assert_frame_equal(result, expected)
-
-        # dup columns
-        df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['g', 'a', 'a'])
-        result = df.groupby('g').transform('first')
-        expected = df.drop('g', axis=1)
-        assert_frame_equal(result, expected)
-
-    def test_transform_broadcast(self):
-        grouped = self.ts.groupby(lambda x: x.month)
-        result = grouped.transform(np.mean)
-
-        self.assert_index_equal(result.index, self.ts.index)
-        for _, gp in grouped:
-            assert_fp_equal(result.reindex(gp.index), gp.mean())
-
-        grouped = self.tsframe.groupby(lambda x: x.month)
-        result = grouped.transform(np.mean)
-        self.assert_index_equal(result.index, self.tsframe.index)
-        for _, gp in grouped:
-            agged = gp.mean()
-            res = result.reindex(gp.index)
-            for col in self.tsframe:
-                assert_fp_equal(res[col], agged[col])
-
-        # group columns
-        grouped = self.tsframe.groupby({'A': 0, 'B': 0, 'C': 1, 'D': 1},
-                                       axis=1)
-        result = grouped.transform(np.mean)
-        self.assert_index_equal(result.index, self.tsframe.index)
-        self.assert_index_equal(result.columns, self.tsframe.columns)
-        for _, gp in grouped:
-            agged = gp.mean(1)
-            res = result.reindex(columns=gp.columns)
-            for idx in gp.index:
-                assert_fp_equal(res.xs(idx), agged[idx])
-
-    def test_transform_axis(self):
-
-        # make sure that we are setting the axes
-        # correctly when on axis=0 or 1
-        # in the presence of a non-monotonic indexer
-        # GH12713
-
-        base = self.tsframe.iloc[0:5]
-        r = len(base.index)
-        c = len(base.columns)
-        tso = DataFrame(np.random.randn(r, c),
-                        index=base.index,
-                        columns=base.columns,
-                        dtype='float64')
-        # monotonic
-        ts = tso
-        grouped = ts.groupby(lambda x: x.weekday())
-        result = ts - grouped.transform('mean')
-        expected = grouped.apply(lambda x: x - x.mean())
-        assert_frame_equal(result, expected)
-
-        ts = ts.T
-        grouped = ts.groupby(lambda x: x.weekday(), axis=1)
-        result = ts - grouped.transform('mean')
-        expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
-        assert_frame_equal(result, expected)
-
-        # non-monotonic
-        ts = tso.iloc[[1, 0] + list(range(2, len(base)))]
-        grouped = ts.groupby(lambda x: x.weekday())
-        result = ts - grouped.transform('mean')
-        expected = grouped.apply(lambda x: x - x.mean())
-        assert_frame_equal(result, expected)
-
-        ts = ts.T
-        grouped = ts.groupby(lambda x: x.weekday(), axis=1)
-        result = ts - grouped.transform('mean')
-        expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
-        assert_frame_equal(result, expected)
-
-    def test_transform_dtype(self):
-        # GH 9807
-        # Check transform dtype output is preserved
-        df = DataFrame([[1, 3], [2, 3]])
-        result = df.groupby(1).transform('mean')
-        expected = DataFrame([[1.5], [1.5]])
-        assert_frame_equal(result, expected)
-
-    def test_transform_bug(self):
-        # GH 5712
-        # transforming on a datetime column
-        df = DataFrame(dict(A=Timestamp('20130101'), B=np.arange(5)))
-        result = df.groupby('A')['B'].transform(
-            lambda x: x.rank(ascending=False))
-        expected = Series(np.arange(5, 0, step=-1), name='B')
-        assert_series_equal(result, expected)
-
-    def test_transform_multiple(self):
-        grouped = self.ts.groupby([lambda x: x.year, lambda x: x.month])
-
-        grouped.transform(lambda x: x * 2)
-        grouped.transform(np.mean)
-
-    def test_dispatch_transform(self):
-        df = self.tsframe[::5].reindex(self.tsframe.index)
-
-        grouped = df.groupby(lambda x: x.month)
-
-        filled = grouped.fillna(method='pad')
-        fillit = lambda x: x.fillna(method='pad')
-        expected = df.groupby(lambda x: x.month).transform(fillit)
-        assert_frame_equal(filled, expected)
-
-    def test_transform_select_columns(self):
-        f = lambda x: x.mean()
-        result = self.df.groupby('A')['C', 'D'].transform(f)
-
-        selection = self.df[['C', 'D']]
-        expected = selection.groupby(self.df['A']).transform(f)
-
-        assert_frame_equal(result, expected)
-
-    def test_transform_exclude_nuisance(self):
-
-        # this also tests orderings in transform between
-        # series/frame to make sure it's consistent
-        expected = {}
-        grouped = self.df.groupby('A')
-        expected['C'] = grouped['C'].transform(np.mean)
-        expected['D'] = grouped['D'].transform(np.mean)
-        expected = DataFrame(expected)
-        result = self.df.groupby('A').transform(np.mean)
-
-        assert_frame_equal(result, expected)
-
-    def test_transform_function_aliases(self):
-        result = self.df.groupby('A').transform('mean')
-        expected = self.df.groupby('A').transform(np.mean)
-        assert_frame_equal(result, expected)
-
-        result = self.df.groupby('A')['C'].transform('mean')
-        expected = self.df.groupby('A')['C'].transform(np.mean)
-        assert_series_equal(result, expected)
-
-    def test_series_fast_transform_date(self):
-        # GH 13191
-        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],
-                           'd': pd.date_range('2014-1-1', '2014-1-4')})
-        result = df.groupby('grouping')['d'].transform('first')
-        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),
-                 pd.Timestamp('2014-1-4')]
-        expected = pd.Series(dates, name='d')
-        assert_series_equal(result, expected)
-
-    def test_transform_length(self):
-        # GH 9697
-        df = pd.DataFrame({'col1': [1, 1, 2, 2], 'col2': [1, 2, 3, np.nan]})
-        expected = pd.Series([3.0] * 4)
-
-        def nsum(x):
-            return np.nansum(x)
-
-        results = [df.groupby('col1').transform(sum)['col2'],
-                   df.groupby('col1')['col2'].transform(sum),
-                   df.groupby('col1').transform(nsum)['col2'],
-                   df.groupby('col1')['col2'].transform(nsum)]
-        for result in results:
-            assert_series_equal(result, expected, check_names=False)
-
-    def test_transform_coercion(self):
-
-        # 14457
-        # when we are transforming be sure to not coerce
-        # via assignment
-        df = pd.DataFrame(dict(A=['a', 'a'], B=[0, 1]))
-        g = df.groupby('A')
-
-        expected = g.transform(np.mean)
-        result = g.transform(lambda x: np.mean(x))
-        assert_frame_equal(result, expected)
-
     def test_with_na(self):
         index = Index(np.arange(10))
 
@@ -1330,58 +1023,6 @@ class TestGroupBy(tm.TestCase):
             assert_series_equal(agged, expected, check_dtype=False)
             self.assertTrue(issubclass(agged.dtype.type, np.dtype(dtype).type))
 
-    def test_groupby_transform_with_int(self):
-
-        # GH 3740, make sure that we might upcast on item-by-item transform
-
-        # floats
-        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=Series(1, dtype='float64'),
-                            C=Series(
-                                [1, 2, 3, 1, 2, 3], dtype='float64'), D='foo'))
-        with np.errstate(all='ignore'):
-            result = df.groupby('A').transform(
-                lambda x: (x - x.mean()) / x.std())
-        expected = DataFrame(dict(B=np.nan, C=Series(
-            [-1, 0, 1, -1, 0, 1], dtype='float64')))
-        assert_frame_equal(result, expected)
-
-        # int case
-        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=1,
-                            C=[1, 2, 3, 1, 2, 3], D='foo'))
-        with np.errstate(all='ignore'):
-            result = df.groupby('A').transform(
-                lambda x: (x - x.mean()) / x.std())
-        expected = DataFrame(dict(B=np.nan, C=[-1, 0, 1, -1, 0, 1]))
-        assert_frame_equal(result, expected)
-
-        # int that needs float conversion
-        s = Series([2, 3, 4, 10, 5, -1])
-        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=1, C=s, D='foo'))
-        with np.errstate(all='ignore'):
-            result = df.groupby('A').transform(
-                lambda x: (x - x.mean()) / x.std())
-
-        s1 = s.iloc[0:3]
-        s1 = (s1 - s1.mean()) / s1.std()
-        s2 = s.iloc[3:6]
-        s2 = (s2 - s2.mean()) / s2.std()
-        expected = DataFrame(dict(B=np.nan, C=concat([s1, s2])))
-        assert_frame_equal(result, expected)
-
-        # int downcasting
-        result = df.groupby('A').transform(lambda x: x * 2 / 2)
-        expected = DataFrame(dict(B=1, C=[2, 3, 4, 10, 5, -1]))
-        assert_frame_equal(result, expected)
-
-    def test_groupby_transform_with_nan_group(self):
-        # GH 9941
-        df = pd.DataFrame({'a': range(10),
-                           'b': [1, 1, 2, 3, np.nan, 4, 4, 5, 5, 5]})
-        result = df.groupby(df.b)['a'].transform(max)
-        expected = pd.Series([1., 1., 2., 3., np.nan, 6., 6., 9., 9., 9.],
-                             name='a')
-        assert_series_equal(result, expected)
-
     def test_indices_concatenation_order(self):
 
         # GH 2808
@@ -1845,6 +1486,7 @@ class TestGroupBy(tm.TestCase):
 
     def test_series_groupby_value_counts(self):
         from itertools import product
+        np.random.seed(1234)
 
         def rebuild_index(df):
             arr = list(map(df.index.get_level_values, range(df.index.nlevels)))
@@ -2220,51 +1862,6 @@ class TestGroupBy(tm.TestCase):
                 assert_series_equal(getattr(result, fname)(),
                                     getattr(df, fname)())
 
-    def test_cythonized_aggers(self):
-        data = {'A': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
-                'B': ['A', 'B'] * 6,
-                'C': np.random.randn(12)}
-        df = DataFrame(data)
-        df.loc[2:10:2, 'C'] = nan
-
-        def _testit(name):
-
-            op = lambda x: getattr(x, name)()
-
-            # single column
-            grouped = df.drop(['B'], axis=1).groupby('A')
-            exp = {}
-            for cat, group in grouped:
-                exp[cat] = op(group['C'])
-            exp = DataFrame({'C': exp})
-            exp.index.name = 'A'
-            result = op(grouped)
-            assert_frame_equal(result, exp)
-
-            # multiple columns
-            grouped = df.groupby(['A', 'B'])
-            expd = {}
-            for (cat1, cat2), group in grouped:
-                expd.setdefault(cat1, {})[cat2] = op(group['C'])
-            exp = DataFrame(expd).T.stack(dropna=False)
-            exp.index.names = ['A', 'B']
-            exp.name = 'C'
-
-            result = op(grouped)['C']
-            if not tm._incompat_bottleneck_version(name):
-                assert_series_equal(result, exp)
-
-        _testit('count')
-        _testit('sum')
-        _testit('std')
-        _testit('var')
-        _testit('sem')
-        _testit('mean')
-        _testit('median')
-        _testit('prod')
-        _testit('min')
-        _testit('max')
-
     def test_max_min_non_numeric(self):
         # #2700
         aa = DataFrame({'nn': [11, 11, 22, 22],
@@ -2399,31 +1996,6 @@ class TestGroupBy(tm.TestCase):
             result = f(numeric_only=False)
             tm.assert_index_equal(result.columns, expected_columns)
 
-    def test_cython_agg_boolean(self):
-        frame = DataFrame({'a': np.random.randint(0, 5, 50),
-                           'b': np.random.randint(0, 2, 50).astype('bool')})
-        result = frame.groupby('a')['b'].mean()
-        expected = frame.groupby('a')['b'].agg(np.mean)
-
-        assert_series_equal(result, expected)
-
-    def test_cython_agg_nothing_to_agg(self):
-        frame = DataFrame({'a': np.random.randint(0, 5, 50),
-                           'b': ['foo', 'bar'] * 25})
-        self.assertRaises(DataError, frame.groupby('a')['b'].mean)
-
-        frame = DataFrame({'a': np.random.randint(0, 5, 50),
-                           'b': ['foo', 'bar'] * 25})
-        self.assertRaises(DataError, frame[['b']].groupby(frame['a']).mean)
-
-    def test_cython_agg_nothing_to_agg_with_dates(self):
-        frame = DataFrame({'a': np.random.randint(0, 5, 50),
-                           'b': ['foo', 'bar'] * 25,
-                           'dates': pd.date_range('now', periods=50,
-                                                  freq='T')})
-        with tm.assertRaisesRegexp(DataError, "No numeric types to aggregate"):
-            frame.groupby('b').dates.mean()
-
     def test_groupby_timedelta_cython_count(self):
         df = DataFrame({'g': list('ab' * 2),
                         'delt': np.arange(4).astype('timedelta64[ns]')})
@@ -2433,15 +2005,6 @@ class TestGroupBy(tm.TestCase):
         result = df.groupby('g').delt.count()
         tm.assert_series_equal(expected, result)
 
-    def test_cython_agg_frame_columns(self):
-        # #2113
-        df = DataFrame({'x': [1, 2, 3], 'y': [3, 4, 5]})
-
-        df.groupby(level=0, axis='columns').mean()
-        df.groupby(level=0, axis='columns').mean()
-        df.groupby(level=0, axis='columns').mean()
-        df.groupby(level=0, axis='columns').mean()
-
     def test_wrap_aggregated_output_multindex(self):
         df = self.mframe.T
         df['baz', 'two'] = 'peekaboo'
@@ -2616,15 +2179,6 @@ class TestGroupBy(tm.TestCase):
         exp_labels = np.array([2, 2, 2, 0, 0, 1, 1, 3, 3, 3], dtype=np.intp)
         assert_almost_equal(grouped.grouper.labels[0], exp_labels)
 
-    def test_cython_fail_agg(self):
-        dr = bdate_range('1/1/2000', periods=50)
-        ts = Series(['A', 'B', 'C', 'D', 'E'] * 10, index=dr)
-
-        grouped = ts.groupby(lambda x: x.month)
-        summed = grouped.sum()
-        expected = grouped.agg(np.sum)
-        assert_series_equal(summed, expected)
-
     def test_apply_series_to_frame(self):
         def f(piece):
             with np.errstate(invalid='ignore'):
@@ -3051,30 +2605,6 @@ class TestGroupBy(tm.TestCase):
         assert_frame_equal(result, expected, check_names=False
                            )  # Note: no names when grouping by value
 
-    def test_agg_consistency(self):
-        # agg with ([]) and () not consistent
-        # GH 6715
-
-        def P1(a):
-            try:
-                return np.percentile(a.dropna(), q=1)
-            except:
-                return np.nan
-
-        import datetime as dt
-        df = DataFrame({'col1': [1, 2, 3, 4],
-                        'col2': [10, 25, 26, 31],
-                        'date': [dt.date(2013, 2, 10), dt.date(2013, 2, 10),
-                                 dt.date(2013, 2, 11), dt.date(2013, 2, 11)]})
-
-        g = df.groupby('date')
-
-        expected = g.agg([P1])
-        expected.columns = expected.columns.levels[0]
-
-        result = g.agg(P1)
-        assert_frame_equal(result, expected)
-
     def test_apply_typecast_fail(self):
         df = DataFrame({'d': [1., 1., 1., 2., 2., 2.],
                         'c': np.tile(
@@ -3159,28 +2689,6 @@ class TestGroupBy(tm.TestCase):
         result = grouped.apply(f)
         self.assertTrue('value3' in result)
 
-    def test_transform_mixed_type(self):
-        index = MultiIndex.from_arrays([[0, 0, 0, 1, 1, 1], [1, 2, 3, 1, 2, 3]
-                                        ])
-        df = DataFrame({'d': [1., 1., 1., 2., 2., 2.],
-                        'c': np.tile(['a', 'b', 'c'], 2),
-                        'v': np.arange(1., 7.)}, index=index)
-
-        def f(group):
-            group['g'] = group['d'] * 2
-            return group[:1]
-
-        grouped = df.groupby('c')
-        result = grouped.apply(f)
-
-        self.assertEqual(result['d'].dtype, np.float64)
-
-        # this is by definition a mutating operation!
-        with option_context('mode.chained_assignment', None):
-            for key, group in grouped:
-                res = f(group)
-                assert_frame_equal(res, result.loc[key])
-
     def test_groupby_wrong_multi_labels(self):
         from pandas import read_csv
         data = """index,foo,bar,baz,spam,data
@@ -3768,20 +3276,6 @@ class TestGroupBy(tm.TestCase):
         result = s.groupby(self.frame['A']).agg(np.sum)
         self.assertIsNone(result.name)
 
-    def test_wrap_agg_out(self):
-        grouped = self.three_group.groupby(['A', 'B'])
-
-        def func(ser):
-            if ser.dtype == np.object:
-                raise TypeError
-            else:
-                return ser.sum()
-
-        result = grouped.aggregate(func)
-        exp_grouped = self.three_group.loc[:, self.three_group.columns != 'C']
-        expected = exp_grouped.groupby(['A', 'B']).aggregate(func)
-        assert_frame_equal(result, expected)
-
     def test_multifunc_sum_bug(self):
         # GH #1065
         x = DataFrame(np.arange(9).reshape(3, 3))
@@ -3839,110 +3333,6 @@ class TestGroupBy(tm.TestCase):
         assert_frame_equal(result2, expected)
         assert_frame_equal(result3, expected)
 
-    def test_agg_multiple_functions_maintain_order(self):
-        # GH #610
-        funcs = [('mean', np.mean), ('max', np.max), ('min', np.min)]
-        result = self.df.groupby('A')['C'].agg(funcs)
-        exp_cols = Index(['mean', 'max', 'min'])
-
-        self.assert_index_equal(result.columns, exp_cols)
-
-    def test_multiple_functions_tuples_and_non_tuples(self):
-        # #1359
-
-        funcs = [('foo', 'mean'), 'std']
-        ex_funcs = [('foo', 'mean'), ('std', 'std')]
-
-        result = self.df.groupby('A')['C'].agg(funcs)
-        expected = self.df.groupby('A')['C'].agg(ex_funcs)
-        assert_frame_equal(result, expected)
-
-        result = self.df.groupby('A').agg(funcs)
-        expected = self.df.groupby('A').agg(ex_funcs)
-        assert_frame_equal(result, expected)
-
-    def test_agg_multiple_functions_too_many_lambdas(self):
-        grouped = self.df.groupby('A')
-        funcs = ['mean', lambda x: x.mean(), lambda x: x.std()]
-
-        self.assertRaises(SpecificationError, grouped.agg, funcs)
-
-    def test_more_flexible_frame_multi_function(self):
-        from pandas import concat
-
-        grouped = self.df.groupby('A')
-
-        exmean = grouped.agg(OrderedDict([['C', np.mean], ['D', np.mean]]))
-        exstd = grouped.agg(OrderedDict([['C', np.std], ['D', np.std]]))
-
-        expected = concat([exmean, exstd], keys=['mean', 'std'], axis=1)
-        expected = expected.swaplevel(0, 1, axis=1).sort_index(level=0, axis=1)
-
-        d = OrderedDict([['C', [np.mean, np.std]], ['D', [np.mean, np.std]]])
-        result = grouped.aggregate(d)
-
-        assert_frame_equal(result, expected)
-
-        # be careful
-        result = grouped.aggregate(OrderedDict([['C', np.mean],
-                                                ['D', [np.mean, np.std]]]))
-        expected = grouped.aggregate(OrderedDict([['C', np.mean],
-                                                  ['D', [np.mean, np.std]]]))
-        assert_frame_equal(result, expected)
-
-        def foo(x):
-            return np.mean(x)
-
-        def bar(x):
-            return np.std(x, ddof=1)
-
-        d = OrderedDict([['C', np.mean], ['D', OrderedDict(
-            [['foo', np.mean], ['bar', np.std]])]])
-        result = grouped.aggregate(d)
-
-        d = OrderedDict([['C', [np.mean]], ['D', [foo, bar]]])
-        expected = grouped.aggregate(d)
-
-        assert_frame_equal(result, expected)
-
-    def test_multi_function_flexible_mix(self):
-        # GH #1268
-        grouped = self.df.groupby('A')
-
-        d = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
-            'bar', 'std'
-        ]])], ['D', 'sum']])
-        result = grouped.aggregate(d)
-        d2 = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
-            'bar', 'std'
-        ]])], ['D', ['sum']]])
-        result2 = grouped.aggregate(d2)
-
-        d3 = OrderedDict([['C', OrderedDict([['foo', 'mean'], [
-            'bar', 'std'
-        ]])], ['D', {'sum': 'sum'}]])
-        expected = grouped.aggregate(d3)
-
-        assert_frame_equal(result, expected)
-        assert_frame_equal(result2, expected)
-
-    def test_agg_callables(self):
-        # GH 7929
-        df = DataFrame({'foo': [1, 2], 'bar': [3, 4]}).astype(np.int64)
-
-        class fn_class(object):
-
-            def __call__(self, x):
-                return sum(x)
-
-        equiv_callables = [sum, np.sum, lambda x: sum(x), lambda x: x.sum(),
-                           partial(sum), fn_class()]
-
-        expected = df.groupby("foo").agg(sum)
-        for ecall in equiv_callables:
-            result = df.groupby('foo').agg(ecall)
-            assert_frame_equal(result, expected)
-
     def test_set_group_name(self):
         def f(group):
             assert group.name is not None
@@ -3980,97 +3370,6 @@ class TestGroupBy(tm.TestCase):
                                   ]).sum()
         self.assertEqual(result.index.names, (None, None))
 
-    def test_groupby_sort_categorical(self):
-        # dataframe groupby sort was being ignored # GH 8868
-        df = DataFrame([['(7.5, 10]', 10, 10],
-                        ['(7.5, 10]', 8, 20],
-                        ['(2.5, 5]', 5, 30],
-                        ['(5, 7.5]', 6, 40],
-                        ['(2.5, 5]', 4, 50],
-                        ['(0, 2.5]', 1, 60],
-                        ['(5, 7.5]', 7, 70]], columns=['range', 'foo', 'bar'])
-        df['range'] = Categorical(df['range'], ordered=True)
-        index = CategoricalIndex(['(0, 2.5]', '(2.5, 5]', '(5, 7.5]',
-                                  '(7.5, 10]'], name='range', ordered=True)
-        result_sort = DataFrame([[1, 60], [5, 30], [6, 40], [10, 10]],
-                                columns=['foo', 'bar'], index=index)
-
-        col = 'range'
-        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
-        # when categories is ordered, group is ordered by category's order
-        assert_frame_equal(result_sort, df.groupby(col, sort=False).first())
-
-        df['range'] = Categorical(df['range'], ordered=False)
-        index = CategoricalIndex(['(0, 2.5]', '(2.5, 5]', '(5, 7.5]',
-                                  '(7.5, 10]'], name='range')
-        result_sort = DataFrame([[1, 60], [5, 30], [6, 40], [10, 10]],
-                                columns=['foo', 'bar'], index=index)
-
-        index = CategoricalIndex(['(7.5, 10]', '(2.5, 5]', '(5, 7.5]',
-                                  '(0, 2.5]'],
-                                 categories=['(7.5, 10]', '(2.5, 5]',
-                                             '(5, 7.5]', '(0, 2.5]'],
-                                 name='range')
-        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
-                                  index=index, columns=['foo', 'bar'])
-
-        col = 'range'
-        # this is an unordered categorical, but we allow this ####
-        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
-        assert_frame_equal(result_nosort, df.groupby(col, sort=False).first())
-
-    def test_groupby_sort_categorical_datetimelike(self):
-        # GH10505
-
-        # use same data as test_groupby_sort_categorical, which category is
-        # corresponding to datetime.month
-        df = DataFrame({'dt': [datetime(2011, 7, 1), datetime(2011, 7, 1),
-                               datetime(2011, 2, 1), datetime(2011, 5, 1),
-                               datetime(2011, 2, 1), datetime(2011, 1, 1),
-                               datetime(2011, 5, 1)],
-                        'foo': [10, 8, 5, 6, 4, 1, 7],
-                        'bar': [10, 20, 30, 40, 50, 60, 70]},
-                       columns=['dt', 'foo', 'bar'])
-
-        # ordered=True
-        df['dt'] = Categorical(df['dt'], ordered=True)
-        index = [datetime(2011, 1, 1), datetime(2011, 2, 1),
-                 datetime(2011, 5, 1), datetime(2011, 7, 1)]
-        result_sort = DataFrame(
-            [[1, 60], [5, 30], [6, 40], [10, 10]], columns=['foo', 'bar'])
-        result_sort.index = CategoricalIndex(index, name='dt', ordered=True)
-
-        index = [datetime(2011, 7, 1), datetime(2011, 2, 1),
-                 datetime(2011, 5, 1), datetime(2011, 1, 1)]
-        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
-                                  columns=['foo', 'bar'])
-        result_nosort.index = CategoricalIndex(index, categories=index,
-                                               name='dt', ordered=True)
-
-        col = 'dt'
-        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
-        # when categories is ordered, group is ordered by category's order
-        assert_frame_equal(result_sort, df.groupby(col, sort=False).first())
-
-        # ordered = False
-        df['dt'] = Categorical(df['dt'], ordered=False)
-        index = [datetime(2011, 1, 1), datetime(2011, 2, 1),
-                 datetime(2011, 5, 1), datetime(2011, 7, 1)]
-        result_sort = DataFrame(
-            [[1, 60], [5, 30], [6, 40], [10, 10]], columns=['foo', 'bar'])
-        result_sort.index = CategoricalIndex(index, name='dt')
-
-        index = [datetime(2011, 7, 1), datetime(2011, 2, 1),
-                 datetime(2011, 5, 1), datetime(2011, 1, 1)]
-        result_nosort = DataFrame([[10, 10], [5, 30], [6, 40], [1, 60]],
-                                  columns=['foo', 'bar'])
-        result_nosort.index = CategoricalIndex(index, categories=index,
-                                               name='dt')
-
-        col = 'dt'
-        assert_frame_equal(result_sort, df.groupby(col, sort=True).first())
-        assert_frame_equal(result_nosort, df.groupby(col, sort=False).first())
-
     def test_groupby_sort_multiindex_series(self):
         # series multiindex groupby sort argument was not being passed through
         # _compress_group_index
@@ -4088,169 +3387,6 @@ class TestGroupBy(tm.TestCase):
         result = mseries.groupby(level=['a', 'b'], sort=True).first()
         assert_series_equal(result, mseries_result.sort_index())
 
-    def test_groupby_groups_datetimeindex(self):
-        # #1430
-        from pandas.tseries.api import DatetimeIndex
-        periods = 1000
-        ind = DatetimeIndex(start='2012/1/1', freq='5min', periods=periods)
-        df = DataFrame({'high': np.arange(periods),
-                        'low': np.arange(periods)}, index=ind)
-        grouped = df.groupby(lambda x: datetime(x.year, x.month, x.day))
-
-        # it works!
-        groups = grouped.groups
-        tm.assertIsInstance(list(groups.keys())[0], datetime)
-
-        # GH 11442
-        index = pd.date_range('2015/01/01', periods=5, name='date')
-        df = pd.DataFrame({'A': [5, 6, 7, 8, 9],
-                           'B': [1, 2, 3, 4, 5]}, index=index)
-        result = df.groupby(level='date').groups
-        dates = ['2015-01-05', '2015-01-04', '2015-01-03',
-                 '2015-01-02', '2015-01-01']
-        expected = {pd.Timestamp(date): pd.DatetimeIndex([date], name='date')
-                    for date in dates}
-        tm.assert_dict_equal(result, expected)
-
-        grouped = df.groupby(level='date')
-        for date in dates:
-            result = grouped.get_group(date)
-            data = [[df.loc[date, 'A'], df.loc[date, 'B']]]
-            expected_index = pd.DatetimeIndex([date], name='date')
-            expected = pd.DataFrame(data,
-                                    columns=list('AB'),
-                                    index=expected_index)
-            tm.assert_frame_equal(result, expected)
-
-    def test_groupby_groups_datetimeindex_tz(self):
-        # GH 3950
-        dates = ['2011-07-19 07:00:00', '2011-07-19 08:00:00',
-                 '2011-07-19 09:00:00', '2011-07-19 07:00:00',
-                 '2011-07-19 08:00:00', '2011-07-19 09:00:00']
-        df = DataFrame({'label': ['a', 'a', 'a', 'b', 'b', 'b'],
-                        'datetime': dates,
-                        'value1': np.arange(6, dtype='int64'),
-                        'value2': [1, 2] * 3})
-        df['datetime'] = df['datetime'].apply(
-            lambda d: Timestamp(d, tz='US/Pacific'))
-
-        exp_idx1 = pd.DatetimeIndex(['2011-07-19 07:00:00',
-                                     '2011-07-19 07:00:00',
-                                     '2011-07-19 08:00:00',
-                                     '2011-07-19 08:00:00',
-                                     '2011-07-19 09:00:00',
-                                     '2011-07-19 09:00:00'],
-                                    tz='US/Pacific', name='datetime')
-        exp_idx2 = Index(['a', 'b'] * 3, name='label')
-        exp_idx = MultiIndex.from_arrays([exp_idx1, exp_idx2])
-        expected = DataFrame({'value1': [0, 3, 1, 4, 2, 5],
-                              'value2': [1, 2, 2, 1, 1, 2]},
-                             index=exp_idx, columns=['value1', 'value2'])
-
-        result = df.groupby(['datetime', 'label']).sum()
-        assert_frame_equal(result, expected)
-
-        # by level
-        didx = pd.DatetimeIndex(dates, tz='Asia/Tokyo')
-        df = DataFrame({'value1': np.arange(6, dtype='int64'),
-                        'value2': [1, 2, 3, 1, 2, 3]},
-                       index=didx)
-
-        exp_idx = pd.DatetimeIndex(['2011-07-19 07:00:00',
-                                    '2011-07-19 08:00:00',
-                                    '2011-07-19 09:00:00'], tz='Asia/Tokyo')
-        expected = DataFrame({'value1': [3, 5, 7], 'value2': [2, 4, 6]},
-                             index=exp_idx, columns=['value1', 'value2'])
-
-        result = df.groupby(level=0).sum()
-        assert_frame_equal(result, expected)
-
-    def test_frame_datetime64_handling_groupby(self):
-        # it works!
-        df = DataFrame([(3, np.datetime64('2012-07-03')),
-                        (3, np.datetime64('2012-07-04'))],
-                       columns=['a', 'date'])
-        result = df.groupby('a').first()
-        self.assertEqual(result['date'][3], Timestamp('2012-07-03'))
-
-    def test_groupby_multi_timezone(self):
-
-        # combining multiple / different timezones yields UTC
-
-        data = """0,2000-01-28 16:47:00,America/Chicago
-1,2000-01-29 16:48:00,America/Chicago
-2,2000-01-30 16:49:00,America/Los_Angeles
-3,2000-01-31 16:50:00,America/Chicago
-4,2000-01-01 16:50:00,America/New_York"""
-
-        df = pd.read_csv(StringIO(data), header=None,
-                         names=['value', 'date', 'tz'])
-        result = df.groupby('tz').date.apply(
-            lambda x: pd.to_datetime(x).dt.tz_localize(x.name))
-
-        expected = Series([Timestamp('2000-01-28 16:47:00-0600',
-                                     tz='America/Chicago'),
-                           Timestamp('2000-01-29 16:48:00-0600',
-                                     tz='America/Chicago'),
-                           Timestamp('2000-01-30 16:49:00-0800',
-                                     tz='America/Los_Angeles'),
-                           Timestamp('2000-01-31 16:50:00-0600',
-                                     tz='America/Chicago'),
-                           Timestamp('2000-01-01 16:50:00-0500',
-                                     tz='America/New_York')],
-                          name='date',
-                          dtype=object)
-        assert_series_equal(result, expected)
-
-        tz = 'America/Chicago'
-        res_values = df.groupby('tz').date.get_group(tz)
-        result = pd.to_datetime(res_values).dt.tz_localize(tz)
-        exp_values = Series(['2000-01-28 16:47:00', '2000-01-29 16:48:00',
-                             '2000-01-31 16:50:00'],
-                            index=[0, 1, 3], name='date')
-        expected = pd.to_datetime(exp_values).dt.tz_localize(tz)
-        assert_series_equal(result, expected)
-
-    def test_groupby_groups_periods(self):
-        dates = ['2011-07-19 07:00:00', '2011-07-19 08:00:00',
-                 '2011-07-19 09:00:00', '2011-07-19 07:00:00',
-                 '2011-07-19 08:00:00', '2011-07-19 09:00:00']
-        df = DataFrame({'label': ['a', 'a', 'a', 'b', 'b', 'b'],
-                        'period': [pd.Period(d, freq='H') for d in dates],
-                        'value1': np.arange(6, dtype='int64'),
-                        'value2': [1, 2] * 3})
-
-        exp_idx1 = pd.PeriodIndex(['2011-07-19 07:00:00',
-                                   '2011-07-19 07:00:00',
-                                   '2011-07-19 08:00:00',
-                                   '2011-07-19 08:00:00',
-                                   '2011-07-19 09:00:00',
-                                   '2011-07-19 09:00:00'],
-                                  freq='H', name='period')
-        exp_idx2 = Index(['a', 'b'] * 3, name='label')
-        exp_idx = MultiIndex.from_arrays([exp_idx1, exp_idx2])
-        expected = DataFrame({'value1': [0, 3, 1, 4, 2, 5],
-                              'value2': [1, 2, 2, 1, 1, 2]},
-                             index=exp_idx, columns=['value1', 'value2'])
-
-        result = df.groupby(['period', 'label']).sum()
-        assert_frame_equal(result, expected)
-
-        # by level
-        didx = pd.PeriodIndex(dates, freq='H')
-        df = DataFrame({'value1': np.arange(6, dtype='int64'),
-                        'value2': [1, 2, 3, 1, 2, 3]},
-                       index=didx)
-
-        exp_idx = pd.PeriodIndex(['2011-07-19 07:00:00',
-                                  '2011-07-19 08:00:00',
-                                  '2011-07-19 09:00:00'], freq='H')
-        expected = DataFrame({'value1': [3, 5, 7], 'value2': [2, 4, 6]},
-                             index=exp_idx, columns=['value1', 'value2'])
-
-        result = df.groupby(level=0).sum()
-        assert_frame_equal(result, expected)
-
     def test_groupby_reindex_inside_function(self):
         from pandas.tseries.api import DatetimeIndex
 
@@ -4336,33 +3472,21 @@ class TestGroupBy(tm.TestCase):
 
     def test_groupby_non_arithmetic_agg_types(self):
         # GH9311, GH6620
-        df = pd.DataFrame([{'a': 1,
-                            'b': 1}, {'a': 1,
-                                      'b': 2}, {'a': 2,
-                                                'b': 3}, {'a': 2,
-                                                          'b': 4}])
+        df = pd.DataFrame(
+            [{'a': 1, 'b': 1},
+             {'a': 1, 'b': 2},
+             {'a': 2, 'b': 3},
+             {'a': 2, 'b': 4}])
 
         dtypes = ['int8', 'int16', 'int32', 'int64', 'float32', 'float64']
 
-        grp_exp = {'first': {'df': [{'a': 1,
-                                     'b': 1}, {'a': 2,
-                                               'b': 3}]},
-                   'last': {'df': [{'a': 1,
-                                    'b': 2}, {'a': 2,
-                                              'b': 4}]},
-                   'min': {'df': [{'a': 1,
-                                   'b': 1}, {'a': 2,
-                                             'b': 3}]},
-                   'max': {'df': [{'a': 1,
-                                   'b': 2}, {'a': 2,
-                                             'b': 4}]},
-                   'nth': {'df': [{'a': 1,
-                                   'b': 2}, {'a': 2,
-                                             'b': 4}],
+        grp_exp = {'first': {'df': [{'a': 1, 'b': 1}, {'a': 2, 'b': 3}]},
+                   'last': {'df': [{'a': 1, 'b': 2}, {'a': 2, 'b': 4}]},
+                   'min': {'df': [{'a': 1, 'b': 1}, {'a': 2, 'b': 3}]},
+                   'max': {'df': [{'a': 1, 'b': 2}, {'a': 2, 'b': 4}]},
+                   'nth': {'df': [{'a': 1, 'b': 2}, {'a': 2, 'b': 4}],
                            'args': [1]},
-                   'count': {'df': [{'a': 1,
-                                     'b': 2}, {'a': 2,
-                                               'b': 2}],
+                   'count': {'df': [{'a': 1, 'b': 2}, {'a': 2, 'b': 2}],
                              'out_type': 'int64'}}
 
         for dtype in dtypes:
@@ -4414,37 +3538,6 @@ class TestGroupBy(tm.TestCase):
                 res = getattr(grpd, method)(*data['args'])
                 self.assertEqual(res.iloc[0].b, data['expected'])
 
-    def test_groupby_first_datetime64(self):
-        df = DataFrame([(1, 1351036800000000000), (2, 1351036800000000000)])
-        df[1] = df[1].view('M8[ns]')
-
-        self.assertTrue(issubclass(df[1].dtype.type, np.datetime64))
-
-        result = df.groupby(level=0).first()
-        got_dt = result[1].dtype
-        self.assertTrue(issubclass(got_dt.type, np.datetime64))
-
-        result = df[1].groupby(level=0).first()
-        got_dt = result.dtype
-        self.assertTrue(issubclass(got_dt.type, np.datetime64))
-
-    def test_groupby_max_datetime64(self):
-        # GH 5869
-        # datetimelike dtype conversion from int
-        df = DataFrame(dict(A=Timestamp('20130101'), B=np.arange(5)))
-        expected = df.groupby('A')['A'].apply(lambda x: x.max())
-        result = df.groupby('A')['A'].max()
-        assert_series_equal(result, expected)
-
-    def test_groupby_datetime64_32_bit(self):
-        # GH 6410 / numpy 4328
-        # 32-bit under 1.9-dev indexing issue
-
-        df = DataFrame({"A": range(2), "B": [pd.Timestamp('2000-01-1')] * 2})
-        result = df.groupby("A")["B"].transform(min)
-        expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')
-        assert_series_equal(result, expected)
-
     def test_groupby_multiindex_missing_pair(self):
         # GH9049
         df = DataFrame({'group1': ['a', 'a', 'a', 'b'],
@@ -4613,381 +3706,6 @@ class TestGroupBy(tm.TestCase):
         res = grouped.get_group((pd.Timestamp('2014-08-31'), 'start'))
         tm.assert_frame_equal(res, df.iloc[[2], :])
 
-    def test_groupby_with_timezone_selection(self):
-        # GH 11616
-        # Test that column selection returns output in correct timezone.
-        np.random.seed(42)
-        df = pd.DataFrame({
-            'factor': np.random.randint(0, 3, size=60),
-            'time': pd.date_range('01/01/2000 00:00', periods=60,
-                                  freq='s', tz='UTC')
-        })
-        df1 = df.groupby('factor').max()['time']
-        df2 = df.groupby('factor')['time'].max()
-        tm.assert_series_equal(df1, df2)
-
-    def test_timezone_info(self):
-        # GH 11682
-        # Timezone info lost when broadcasting scalar datetime to DataFrame
-        tm._skip_if_no_pytz()
-        import pytz
-
-        df = pd.DataFrame({'a': [1], 'b': [datetime.now(pytz.utc)]})
-        self.assertEqual(df['b'][0].tzinfo, pytz.utc)
-        df = pd.DataFrame({'a': [1, 2, 3]})
-        df['b'] = datetime.now(pytz.utc)
-        self.assertEqual(df['b'][0].tzinfo, pytz.utc)
-
-    def test_groupby_with_timegrouper(self):
-        # GH 4161
-        # TimeGrouper requires a sorted index
-        # also verifies that the resultant index has the correct name
-        import datetime as DT
-        df_original = DataFrame({
-            'Buyer': 'Carl Carl Carl Carl Joe Carl'.split(),
-            'Quantity': [18, 3, 5, 1, 9, 3],
-            'Date': [
-                DT.datetime(2013, 9, 1, 13, 0),
-                DT.datetime(2013, 9, 1, 13, 5),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 3, 10, 0),
-                DT.datetime(2013, 12, 2, 12, 0),
-                DT.datetime(2013, 9, 2, 14, 0),
-            ]
-        })
-
-        # GH 6908 change target column's order
-        df_reordered = df_original.sort_values(by='Quantity')
-
-        for df in [df_original, df_reordered]:
-            df = df.set_index(['Date'])
-
-            expected = DataFrame(
-                {'Quantity': np.nan},
-                index=date_range('20130901 13:00:00',
-                                 '20131205 13:00:00', freq='5D',
-                                 name='Date', closed='left'))
-            expected.iloc[[0, 6, 18], 0] = np.array(
-                [24., 6., 9.], dtype='float64')
-
-            result1 = df.resample('5D') .sum()
-            assert_frame_equal(result1, expected)
-
-            df_sorted = df.sort_index()
-            result2 = df_sorted.groupby(pd.TimeGrouper(freq='5D')).sum()
-            assert_frame_equal(result2, expected)
-
-            result3 = df.groupby(pd.TimeGrouper(freq='5D')).sum()
-            assert_frame_equal(result3, expected)
-
-    def test_groupby_with_timegrouper_methods(self):
-        # GH 3881
-        # make sure API of timegrouper conforms
-
-        import datetime as DT
-        df_original = pd.DataFrame({
-            'Branch': 'A A A A A B'.split(),
-            'Buyer': 'Carl Mark Carl Joe Joe Carl'.split(),
-            'Quantity': [1, 3, 5, 8, 9, 3],
-            'Date': [
-                DT.datetime(2013, 1, 1, 13, 0),
-                DT.datetime(2013, 1, 1, 13, 5),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 2, 10, 0),
-                DT.datetime(2013, 12, 2, 12, 0),
-                DT.datetime(2013, 12, 2, 14, 0),
-            ]
-        })
-
-        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
-
-        for df in [df_original, df_sorted]:
-            df = df.set_index('Date', drop=False)
-            g = df.groupby(pd.TimeGrouper('6M'))
-            self.assertTrue(g.group_keys)
-            self.assertTrue(isinstance(g.grouper, pd.core.groupby.BinGrouper))
-            groups = g.groups
-            self.assertTrue(isinstance(groups, dict))
-            self.assertTrue(len(groups) == 3)
-
-    def test_timegrouper_with_reg_groups(self):
-
-        # GH 3794
-        # allow combinateion of timegrouper/reg groups
-
-        import datetime as DT
-
-        df_original = DataFrame({
-            'Branch': 'A A A A A A A B'.split(),
-            'Buyer': 'Carl Mark Carl Carl Joe Joe Joe Carl'.split(),
-            'Quantity': [1, 3, 5, 1, 8, 1, 9, 3],
-            'Date': [
-                DT.datetime(2013, 1, 1, 13, 0),
-                DT.datetime(2013, 1, 1, 13, 5),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 2, 10, 0),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 2, 10, 0),
-                DT.datetime(2013, 12, 2, 12, 0),
-                DT.datetime(2013, 12, 2, 14, 0),
-            ]
-        }).set_index('Date')
-
-        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
-
-        for df in [df_original, df_sorted]:
-            expected = DataFrame({
-                'Buyer': 'Carl Joe Mark'.split(),
-                'Quantity': [10, 18, 3],
-                'Date': [
-                    DT.datetime(2013, 12, 31, 0, 0),
-                    DT.datetime(2013, 12, 31, 0, 0),
-                    DT.datetime(2013, 12, 31, 0, 0),
-                ]
-            }).set_index(['Date', 'Buyer'])
-
-            result = df.groupby([pd.Grouper(freq='A'), 'Buyer']).sum()
-            assert_frame_equal(result, expected)
-
-            expected = DataFrame({
-                'Buyer': 'Carl Mark Carl Joe'.split(),
-                'Quantity': [1, 3, 9, 18],
-                'Date': [
-                    DT.datetime(2013, 1, 1, 0, 0),
-                    DT.datetime(2013, 1, 1, 0, 0),
-                    DT.datetime(2013, 7, 1, 0, 0),
-                    DT.datetime(2013, 7, 1, 0, 0),
-                ]
-            }).set_index(['Date', 'Buyer'])
-            result = df.groupby([pd.Grouper(freq='6MS'), 'Buyer']).sum()
-            assert_frame_equal(result, expected)
-
-        df_original = DataFrame({
-            'Branch': 'A A A A A A A B'.split(),
-            'Buyer': 'Carl Mark Carl Carl Joe Joe Joe Carl'.split(),
-            'Quantity': [1, 3, 5, 1, 8, 1, 9, 3],
-            'Date': [
-                DT.datetime(2013, 10, 1, 13, 0),
-                DT.datetime(2013, 10, 1, 13, 5),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 2, 10, 0),
-                DT.datetime(2013, 10, 1, 20, 0),
-                DT.datetime(2013, 10, 2, 10, 0),
-                DT.datetime(2013, 10, 2, 12, 0),
-                DT.datetime(2013, 10, 2, 14, 0),
-            ]
-        }).set_index('Date')
-
-        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
-        for df in [df_original, df_sorted]:
-
-            expected = DataFrame({
-                'Buyer': 'Carl Joe Mark Carl Joe'.split(),
-                'Quantity': [6, 8, 3, 4, 10],
-                'Date': [
-                    DT.datetime(2013, 10, 1, 0, 0),
-                    DT.datetime(2013, 10, 1, 0, 0),
-                    DT.datetime(2013, 10, 1, 0, 0),
-                    DT.datetime(2013, 10, 2, 0, 0),
-                    DT.datetime(2013, 10, 2, 0, 0),
-                ]
-            }).set_index(['Date', 'Buyer'])
-
-            result = df.groupby([pd.Grouper(freq='1D'), 'Buyer']).sum()
-            assert_frame_equal(result, expected)
-
-            result = df.groupby([pd.Grouper(freq='1M'), 'Buyer']).sum()
-            expected = DataFrame({
-                'Buyer': 'Carl Joe Mark'.split(),
-                'Quantity': [10, 18, 3],
-                'Date': [
-                    DT.datetime(2013, 10, 31, 0, 0),
-                    DT.datetime(2013, 10, 31, 0, 0),
-                    DT.datetime(2013, 10, 31, 0, 0),
-                ]
-            }).set_index(['Date', 'Buyer'])
-            assert_frame_equal(result, expected)
-
-            # passing the name
-            df = df.reset_index()
-            result = df.groupby([pd.Grouper(freq='1M', key='Date'), 'Buyer'
-                                 ]).sum()
-            assert_frame_equal(result, expected)
-
-            with self.assertRaises(KeyError):
-                df.groupby([pd.Grouper(freq='1M', key='foo'), 'Buyer']).sum()
-
-            # passing the level
-            df = df.set_index('Date')
-            result = df.groupby([pd.Grouper(freq='1M', level='Date'), 'Buyer'
-                                 ]).sum()
-            assert_frame_equal(result, expected)
-            result = df.groupby([pd.Grouper(freq='1M', level=0), 'Buyer']).sum(
-            )
-            assert_frame_equal(result, expected)
-
-            with self.assertRaises(ValueError):
-                df.groupby([pd.Grouper(freq='1M', level='foo'),
-                            'Buyer']).sum()
-
-            # multi names
-            df = df.copy()
-            df['Date'] = df.index + pd.offsets.MonthEnd(2)
-            result = df.groupby([pd.Grouper(freq='1M', key='Date'), 'Buyer'
-                                 ]).sum()
-            expected = DataFrame({
-                'Buyer': 'Carl Joe Mark'.split(),
-                'Quantity': [10, 18, 3],
-                'Date': [
-                    DT.datetime(2013, 11, 30, 0, 0),
-                    DT.datetime(2013, 11, 30, 0, 0),
-                    DT.datetime(2013, 11, 30, 0, 0),
-                ]
-            }).set_index(['Date', 'Buyer'])
-            assert_frame_equal(result, expected)
-
-            # error as we have both a level and a name!
-            with self.assertRaises(ValueError):
-                df.groupby([pd.Grouper(freq='1M', key='Date',
-                                       level='Date'), 'Buyer']).sum()
-
-            # single groupers
-            expected = DataFrame({'Quantity': [31],
-                                  'Date': [DT.datetime(2013, 10, 31, 0, 0)
-                                           ]}).set_index('Date')
-            result = df.groupby(pd.Grouper(freq='1M')).sum()
-            assert_frame_equal(result, expected)
-
-            result = df.groupby([pd.Grouper(freq='1M')]).sum()
-            assert_frame_equal(result, expected)
-
-            expected = DataFrame({'Quantity': [31],
-                                  'Date': [DT.datetime(2013, 11, 30, 0, 0)
-                                           ]}).set_index('Date')
-            result = df.groupby(pd.Grouper(freq='1M', key='Date')).sum()
-            assert_frame_equal(result, expected)
-
-            result = df.groupby([pd.Grouper(freq='1M', key='Date')]).sum()
-            assert_frame_equal(result, expected)
-
-        # GH 6764 multiple grouping with/without sort
-        df = DataFrame({
-            'date': pd.to_datetime([
-                '20121002', '20121007', '20130130', '20130202', '20130305',
-                '20121002', '20121207', '20130130', '20130202', '20130305',
-                '20130202', '20130305'
-            ]),
-            'user_id': [1, 1, 1, 1, 1, 3, 3, 3, 5, 5, 5, 5],
-            'whole_cost': [1790, 364, 280, 259, 201, 623, 90, 312, 359, 301,
-                           359, 801],
-            'cost1': [12, 15, 10, 24, 39, 1, 0, 90, 45, 34, 1, 12]
-        }).set_index('date')
-
-        for freq in ['D', 'M', 'A', 'Q-APR']:
-            expected = df.groupby('user_id')[
-                'whole_cost'].resample(
-                    freq).sum().dropna().reorder_levels(
-                        ['date', 'user_id']).sort_index().astype('int64')
-            expected.name = 'whole_cost'
-
-            result1 = df.sort_index().groupby([pd.TimeGrouper(freq=freq),
-                                               'user_id'])['whole_cost'].sum()
-            assert_series_equal(result1, expected)
-
-            result2 = df.groupby([pd.TimeGrouper(freq=freq), 'user_id'])[
-                'whole_cost'].sum()
-            assert_series_equal(result2, expected)
-
-    def test_timegrouper_get_group(self):
-        # GH 6914
-
-        df_original = DataFrame({
-            'Buyer': 'Carl Joe Joe Carl Joe Carl'.split(),
-            'Quantity': [18, 3, 5, 1, 9, 3],
-            'Date': [datetime(2013, 9, 1, 13, 0),
-                     datetime(2013, 9, 1, 13, 5),
-                     datetime(2013, 10, 1, 20, 0),
-                     datetime(2013, 10, 3, 10, 0),
-                     datetime(2013, 12, 2, 12, 0),
-                     datetime(2013, 9, 2, 14, 0), ]
-        })
-        df_reordered = df_original.sort_values(by='Quantity')
-
-        # single grouping
-        expected_list = [df_original.iloc[[0, 1, 5]], df_original.iloc[[2, 3]],
-                         df_original.iloc[[4]]]
-        dt_list = ['2013-09-30', '2013-10-31', '2013-12-31']
-
-        for df in [df_original, df_reordered]:
-            grouped = df.groupby(pd.Grouper(freq='M', key='Date'))
-            for t, expected in zip(dt_list, expected_list):
-                dt = pd.Timestamp(t)
-                result = grouped.get_group(dt)
-                assert_frame_equal(result, expected)
-
-        # multiple grouping
-        expected_list = [df_original.iloc[[1]], df_original.iloc[[3]],
-                         df_original.iloc[[4]]]
-        g_list = [('Joe', '2013-09-30'), ('Carl', '2013-10-31'),
-                  ('Joe', '2013-12-31')]
-
-        for df in [df_original, df_reordered]:
-            grouped = df.groupby(['Buyer', pd.Grouper(freq='M', key='Date')])
-            for (b, t), expected in zip(g_list, expected_list):
-                dt = pd.Timestamp(t)
-                result = grouped.get_group((b, dt))
-                assert_frame_equal(result, expected)
-
-        # with index
-        df_original = df_original.set_index('Date')
-        df_reordered = df_original.sort_values(by='Quantity')
-
-        expected_list = [df_original.iloc[[0, 1, 5]], df_original.iloc[[2, 3]],
-                         df_original.iloc[[4]]]
-
-        for df in [df_original, df_reordered]:
-            grouped = df.groupby(pd.Grouper(freq='M'))
-            for t, expected in zip(dt_list, expected_list):
-                dt = pd.Timestamp(t)
-                result = grouped.get_group(dt)
-                assert_frame_equal(result, expected)
-
-    def test_timegrouper_apply_return_type_series(self):
-        # Using `apply` with the `TimeGrouper` should give the
-        # same return type as an `apply` with a `Grouper`.
-        # Issue #11742
-        df = pd.DataFrame({'date': ['10/10/2000', '11/10/2000'],
-                           'value': [10, 13]})
-        df_dt = df.copy()
-        df_dt['date'] = pd.to_datetime(df_dt['date'])
-
-        def sumfunc_series(x):
-            return pd.Series([x['value'].sum()], ('sum',))
-
-        expected = df.groupby(pd.Grouper(key='date')).apply(sumfunc_series)
-        result = (df_dt.groupby(pd.TimeGrouper(freq='M', key='date'))
-                  .apply(sumfunc_series))
-        assert_frame_equal(result.reset_index(drop=True),
-                           expected.reset_index(drop=True))
-
-    def test_timegrouper_apply_return_type_value(self):
-        # Using `apply` with the `TimeGrouper` should give the
-        # same return type as an `apply` with a `Grouper`.
-        # Issue #11742
-        df = pd.DataFrame({'date': ['10/10/2000', '11/10/2000'],
-                           'value': [10, 13]})
-        df_dt = df.copy()
-        df_dt['date'] = pd.to_datetime(df_dt['date'])
-
-        def sumfunc_value(x):
-            return x.value.sum()
-
-        expected = df.groupby(pd.Grouper(key='date')).apply(sumfunc_value)
-        result = (df_dt.groupby(pd.TimeGrouper(freq='M', key='date'))
-                  .apply(sumfunc_value))
-        assert_series_equal(result.reset_index(drop=True),
-                            expected.reset_index(drop=True))
-
     def test_cumcount(self):
         df = DataFrame([['a'], ['a'], ['a'], ['b'], ['a']], columns=['A'])
         g = df.groupby('A')
@@ -5326,106 +4044,6 @@ class TestGroupBy(tm.TestCase):
              'ffill', 'bfill', 'pad', 'backfill', 'rolling', 'expanding'])
         self.assertEqual(results, expected)
 
-    def test_lexsort_indexer(self):
-        keys = [[nan] * 5 + list(range(100)) + [nan] * 5]
-        # orders=True, na_position='last'
-        result = _lexsort_indexer(keys, orders=True, na_position='last')
-        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
-
-        # orders=True, na_position='first'
-        result = _lexsort_indexer(keys, orders=True, na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
-        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
-
-        # orders=False, na_position='last'
-        result = _lexsort_indexer(keys, orders=False, na_position='last')
-        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
-
-        # orders=False, na_position='first'
-        result = _lexsort_indexer(keys, orders=False, na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
-        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
-
-    def test_nargsort(self):
-        # np.argsort(items) places NaNs last
-        items = [nan] * 5 + list(range(100)) + [nan] * 5
-        # np.argsort(items2) may not place NaNs first
-        items2 = np.array(items, dtype='O')
-
-        try:
-            # GH 2785; due to a regression in NumPy1.6.2
-            np.argsort(np.array([[1, 2], [1, 3], [1, 2]], dtype='i'))
-            np.argsort(items2, kind='mergesort')
-        except TypeError:
-            raise nose.SkipTest('requested sort not available for type')
-
-        # mergesort is the most difficult to get right because we want it to be
-        # stable.
-
-        # According to numpy/core/tests/test_multiarray, """The number of
-        # sorted items must be greater than ~50 to check the actual algorithm
-        # because quick and merge sort fall over to insertion sort for small
-        # arrays."""
-
-        # mergesort, ascending=True, na_position='last'
-        result = _nargsort(items, kind='mergesort', ascending=True,
-                           na_position='last')
-        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=True, na_position='first'
-        result = _nargsort(items, kind='mergesort', ascending=True,
-                           na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=False, na_position='last'
-        result = _nargsort(items, kind='mergesort', ascending=False,
-                           na_position='last')
-        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=False, na_position='first'
-        result = _nargsort(items, kind='mergesort', ascending=False,
-                           na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=True, na_position='last'
-        result = _nargsort(items2, kind='mergesort', ascending=True,
-                           na_position='last')
-        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=True, na_position='first'
-        result = _nargsort(items2, kind='mergesort', ascending=True,
-                           na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=False, na_position='last'
-        result = _nargsort(items2, kind='mergesort', ascending=False,
-                           na_position='last')
-        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-        # mergesort, ascending=False, na_position='first'
-        result = _nargsort(items2, kind='mergesort', ascending=False,
-                           na_position='first')
-        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
-        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
-
-    def test_datetime_count(self):
-        df = DataFrame({'a': [1, 2, 3] * 2,
-                        'dates': pd.date_range('now', periods=6, freq='T')})
-        result = df.groupby('a').dates.count()
-        expected = Series([
-            2, 2, 2
-        ], index=Index([1, 2, 3], name='a'), name='dates')
-        tm.assert_series_equal(result, expected)
-
     def test_lower_int_prec_count(self):
         df = DataFrame({'a': np.array(
             [0, 1, 2, 100], np.int8),
@@ -5462,179 +4080,6 @@ class TestGroupBy(tm.TestCase):
             list('ab'), name='grp'))
         tm.assert_frame_equal(result, expected)
 
-    def test__cython_agg_general(self):
-        ops = [('mean', np.mean),
-               ('median', np.median),
-               ('var', np.var),
-               ('add', np.sum),
-               ('prod', np.prod),
-               ('min', np.min),
-               ('max', np.max),
-               ('first', lambda x: x.iloc[0]),
-               ('last', lambda x: x.iloc[-1]), ]
-        df = DataFrame(np.random.randn(1000))
-        labels = np.random.randint(0, 50, size=1000).astype(float)
-
-        for op, targop in ops:
-            result = df.groupby(labels)._cython_agg_general(op)
-            expected = df.groupby(labels).agg(targop)
-            try:
-                tm.assert_frame_equal(result, expected)
-            except BaseException as exc:
-                exc.args += ('operation: %s' % op, )
-                raise
-
-    def test_cython_agg_empty_buckets(self):
-        ops = [('mean', np.mean),
-               ('median', lambda x: np.median(x) if len(x) > 0 else np.nan),
-               ('var', lambda x: np.var(x, ddof=1)),
-               ('add', lambda x: np.sum(x) if len(x) > 0 else np.nan),
-               ('prod', np.prod),
-               ('min', np.min),
-               ('max', np.max), ]
-
-        df = pd.DataFrame([11, 12, 13])
-        grps = range(0, 55, 5)
-
-        for op, targop in ops:
-            result = df.groupby(pd.cut(df[0], grps))._cython_agg_general(op)
-            expected = df.groupby(pd.cut(df[0], grps)).agg(lambda x: targop(x))
-            try:
-                tm.assert_frame_equal(result, expected)
-            except BaseException as exc:
-                exc.args += ('operation: %s' % op,)
-                raise
-
-    def test_cython_group_transform_algos(self):
-        # GH 4095
-        dtypes = [np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint32,
-                  np.uint64, np.float32, np.float64]
-
-        ops = [(pd.algos.group_cumprod_float64, np.cumproduct, [np.float64]),
-               (pd.algos.group_cumsum, np.cumsum, dtypes)]
-
-        is_datetimelike = False
-        for pd_op, np_op, dtypes in ops:
-            for dtype in dtypes:
-                data = np.array([[1], [2], [3], [4]], dtype=dtype)
-                ans = np.zeros_like(data)
-                labels = np.array([0, 0, 0, 0], dtype=np.int64)
-                pd_op(ans, data, labels, is_datetimelike)
-                self.assert_numpy_array_equal(np_op(data), ans[:, 0],
-                                              check_dtype=False)
-
-        # with nans
-        labels = np.array([0, 0, 0, 0, 0], dtype=np.int64)
-
-        data = np.array([[1], [2], [3], [np.nan], [4]], dtype='float64')
-        actual = np.zeros_like(data)
-        actual.fill(np.nan)
-        pd.algos.group_cumprod_float64(actual, data, labels, is_datetimelike)
-        expected = np.array([1, 2, 6, np.nan, 24], dtype='float64')
-        self.assert_numpy_array_equal(actual[:, 0], expected)
-
-        actual = np.zeros_like(data)
-        actual.fill(np.nan)
-        pd.algos.group_cumsum(actual, data, labels, is_datetimelike)
-        expected = np.array([1, 3, 6, np.nan, 10], dtype='float64')
-        self.assert_numpy_array_equal(actual[:, 0], expected)
-
-        # timedelta
-        is_datetimelike = True
-        data = np.array([np.timedelta64(1, 'ns')] * 5, dtype='m8[ns]')[:, None]
-        actual = np.zeros_like(data, dtype='int64')
-        pd.algos.group_cumsum(actual, data.view('int64'), labels,
-                              is_datetimelike)
-        expected = np.array([np.timedelta64(1, 'ns'), np.timedelta64(
-            2, 'ns'), np.timedelta64(3, 'ns'), np.timedelta64(4, 'ns'),
-            np.timedelta64(5, 'ns')])
-        self.assert_numpy_array_equal(actual[:, 0].view('m8[ns]'), expected)
-
-    def test_cython_transform(self):
-        # GH 4095
-        ops = [(('cumprod',
-                 ()), lambda x: x.cumprod()), (('cumsum', ()),
-                                               lambda x: x.cumsum()),
-               (('shift', (-1, )),
-                lambda x: x.shift(-1)), (('shift',
-                                          (1, )), lambda x: x.shift())]
-
-        s = Series(np.random.randn(1000))
-        s_missing = s.copy()
-        s_missing.iloc[2:10] = np.nan
-        labels = np.random.randint(0, 50, size=1000).astype(float)
-
-        # series
-        for (op, args), targop in ops:
-            for data in [s, s_missing]:
-                # print(data.head())
-                expected = data.groupby(labels).transform(targop)
-
-                tm.assert_series_equal(expected,
-                                       data.groupby(labels).transform(op,
-                                                                      *args))
-                tm.assert_series_equal(expected, getattr(
-                    data.groupby(labels), op)(*args))
-
-        strings = list('qwertyuiopasdfghjklz')
-        strings_missing = strings[:]
-        strings_missing[5] = np.nan
-        df = DataFrame({'float': s,
-                        'float_missing': s_missing,
-                        'int': [1, 1, 1, 1, 2] * 200,
-                        'datetime': pd.date_range('1990-1-1', periods=1000),
-                        'timedelta': pd.timedelta_range(1, freq='s',
-                                                        periods=1000),
-                        'string': strings * 50,
-                        'string_missing': strings_missing * 50})
-        df['cat'] = df['string'].astype('category')
-
-        df2 = df.copy()
-        df2.index = pd.MultiIndex.from_product([range(100), range(10)])
-
-        # DataFrame - Single and MultiIndex,
-        # group by values, index level, columns
-        for df in [df, df2]:
-            for gb_target in [dict(by=labels), dict(level=0), dict(by='string')
-                              ]:  # dict(by='string_missing')]:
-                # dict(by=['int','string'])]:
-
-                gb = df.groupby(**gb_target)
-                # whitelisted methods set the selection before applying
-                # bit a of hack to make sure the cythonized shift
-                # is equivalent to pre 0.17.1 behavior
-                if op == 'shift':
-                    gb._set_group_selection()
-
-                for (op, args), targop in ops:
-                    if op != 'shift' and 'int' not in gb_target:
-                        # numeric apply fastpath promotes dtype so have
-                        # to apply seperately and concat
-                        i = gb[['int']].apply(targop)
-                        f = gb[['float', 'float_missing']].apply(targop)
-                        expected = pd.concat([f, i], axis=1)
-                    else:
-                        expected = gb.apply(targop)
-
-                    expected = expected.sort_index(axis=1)
-                    tm.assert_frame_equal(expected,
-                                          gb.transform(op, *args).sort_index(
-                                              axis=1))
-                    tm.assert_frame_equal(expected, getattr(gb, op)(*args))
-                    # individual columns
-                    for c in df:
-                        if c not in ['float', 'int', 'float_missing'
-                                     ] and op != 'shift':
-                            self.assertRaises(DataError, gb[c].transform, op)
-                            self.assertRaises(DataError, getattr(gb[c], op))
-                        else:
-                            expected = gb[c].apply(targop)
-                            expected.name = c
-                            tm.assert_series_equal(expected,
-                                                   gb[c].transform(op, *args))
-                            tm.assert_series_equal(expected,
-                                                   getattr(gb[c], op)(*args))
-
     def test_groupby_cumprod(self):
         # GH 4095
         df = pd.DataFrame({'key': ['b'] * 10, 'value': 2})
@@ -5784,27 +4229,6 @@ class TestGroupBy(tm.TestCase):
         tm.assert_frame_equal(result1, expected1)
         tm.assert_frame_equal(result2, expected2)
 
-    def test_first_last_max_min_on_time_data(self):
-        # GH 10295
-        # Verify that NaT is not in the result of max, min, first and last on
-        # Dataframe with datetime or timedelta values.
-        from datetime import timedelta as td
-        df_test = DataFrame(
-            {'dt': [nan, '2015-07-24 10:10', '2015-07-25 11:11',
-                    '2015-07-23 12:12', nan],
-             'td': [nan, td(days=1), td(days=2), td(days=3), nan]})
-        df_test.dt = pd.to_datetime(df_test.dt)
-        df_test['group'] = 'A'
-        df_ref = df_test[df_test.dt.notnull()]
-
-        grouped_test = df_test.groupby('group')
-        grouped_ref = df_ref.groupby('group')
-
-        assert_frame_equal(grouped_ref.max(), grouped_test.max())
-        assert_frame_equal(grouped_ref.min(), grouped_test.min())
-        assert_frame_equal(grouped_ref.first(), grouped_test.first())
-        assert_frame_equal(grouped_ref.last(), grouped_test.last())
-
     def test_groupby_preserves_sort(self):
         # Test to ensure that groupby always preserves sort order of original
         # object. Issue #8588 and #9651
@@ -5854,21 +4278,6 @@ class TestGroupBy(tm.TestCase):
         expected = pd.Series(name='name', dtype='int64')
         tm.assert_series_equal(result, expected)
 
-    def test_transform_with_non_scalar_group(self):
-        # GH 10165
-        cols = pd.MultiIndex.from_tuples([
-            ('syn', 'A'), ('mis', 'A'), ('non', 'A'),
-            ('syn', 'C'), ('mis', 'C'), ('non', 'C'),
-            ('syn', 'T'), ('mis', 'T'), ('non', 'T'),
-            ('syn', 'G'), ('mis', 'G'), ('non', 'G')])
-        df = pd.DataFrame(np.random.randint(1, 10, (4, 12)),
-                          columns=cols,
-                          index=['A', 'C', 'G', 'T'])
-        self.assertRaisesRegexp(ValueError, 'transform must return a scalar '
-                                'value for each group.*', df.groupby
-                                (axis=1, level=1).transform,
-                                lambda z: z.div(z.sum(axis=1), axis=0))
-
     def test_numpy_compat(self):
         # see gh-12811
         df = pd.DataFrame({'A': [1, 2, 1], 'B': [1, 2, 3]})
@@ -5927,23 +4336,6 @@ class TestGroupBy(tm.TestCase):
             df.reset_index().pivot_table(index='year', columns='month',
                                          values='badname', aggfunc='count')
 
-    def test_agg_over_numpy_arrays(self):
-        # GH 3788
-        df = pd.DataFrame([[1, np.array([10, 20, 30])],
-                           [1, np.array([40, 50, 60])],
-                           [2, np.array([20, 30, 40])]],
-                          columns=['category', 'arraydata'])
-        result = df.groupby('category').agg(sum)
-
-        expected_data = [[np.array([50, 70, 90])], [np.array([20, 30, 40])]]
-        expected_index = pd.Index([1, 2], name='category')
-        expected_column = ['arraydata']
-        expected = pd.DataFrame(expected_data,
-                                index=expected_index,
-                                columns=expected_column)
-
-        assert_frame_equal(result, expected)
-
     def test_cummin_cummax(self):
         # GH 15048
         num_types = [np.int32, np.int64, np.float32, np.float64]
@@ -6024,10 +4416,6 @@ class TestGroupBy(tm.TestCase):
         tm.assert_frame_equal(expected, result)
 
 
-def assert_fp_equal(a, b):
-    assert (np.abs(a - b) < 1e-12).all()
-
-
 def _check_groupby(df, result, keys, field, f=lambda x: x.sum()):
     tups = lmap(tuple, df[keys].values)
     tups = com._asarray_tuplesafe(tups)
diff --git a/pandas/tests/groupby/test_misc.py b/pandas/tests/groupby/test_misc.py
new file mode 100644
index 000000000..c9d8ad423
--- /dev/null
+++ b/pandas/tests/groupby/test_misc.py
@@ -0,0 +1,101 @@
+""" misc non-groupby routines, as they are defined in core/groupby.py """
+
+import nose
+import numpy as np
+from numpy import nan
+from pandas.util import testing as tm
+from pandas.core.groupby import _nargsort, _lexsort_indexer
+
+
+class TestSorting(tm.TestCase):
+
+    def test_lexsort_indexer(self):
+        keys = [[nan] * 5 + list(range(100)) + [nan] * 5]
+        # orders=True, na_position='last'
+        result = _lexsort_indexer(keys, orders=True, na_position='last')
+        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
+
+        # orders=True, na_position='first'
+        result = _lexsort_indexer(keys, orders=True, na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
+        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
+
+        # orders=False, na_position='last'
+        result = _lexsort_indexer(keys, orders=False, na_position='last')
+        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
+
+        # orders=False, na_position='first'
+        result = _lexsort_indexer(keys, orders=False, na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
+        tm.assert_numpy_array_equal(result, np.array(exp, dtype=np.intp))
+
+    def test_nargsort(self):
+        # np.argsort(items) places NaNs last
+        items = [nan] * 5 + list(range(100)) + [nan] * 5
+        # np.argsort(items2) may not place NaNs first
+        items2 = np.array(items, dtype='O')
+
+        try:
+            # GH 2785; due to a regression in NumPy1.6.2
+            np.argsort(np.array([[1, 2], [1, 3], [1, 2]], dtype='i'))
+            np.argsort(items2, kind='mergesort')
+        except TypeError:
+            raise nose.SkipTest('requested sort not available for type')
+
+        # mergesort is the most difficult to get right because we want it to be
+        # stable.
+
+        # According to numpy/core/tests/test_multiarray, """The number of
+        # sorted items must be greater than ~50 to check the actual algorithm
+        # because quick and merge sort fall over to insertion sort for small
+        # arrays."""
+
+        # mergesort, ascending=True, na_position='last'
+        result = _nargsort(items, kind='mergesort', ascending=True,
+                           na_position='last')
+        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=True, na_position='first'
+        result = _nargsort(items, kind='mergesort', ascending=True,
+                           na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=False, na_position='last'
+        result = _nargsort(items, kind='mergesort', ascending=False,
+                           na_position='last')
+        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=False, na_position='first'
+        result = _nargsort(items, kind='mergesort', ascending=False,
+                           na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=True, na_position='last'
+        result = _nargsort(items2, kind='mergesort', ascending=True,
+                           na_position='last')
+        exp = list(range(5, 105)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=True, na_position='first'
+        result = _nargsort(items2, kind='mergesort', ascending=True,
+                           na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(5, 105))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=False, na_position='last'
+        result = _nargsort(items2, kind='mergesort', ascending=False,
+                           na_position='last')
+        exp = list(range(104, 4, -1)) + list(range(5)) + list(range(105, 110))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
+
+        # mergesort, ascending=False, na_position='first'
+        result = _nargsort(items2, kind='mergesort', ascending=False,
+                           na_position='first')
+        exp = list(range(5)) + list(range(105, 110)) + list(range(104, 4, -1))
+        tm.assert_numpy_array_equal(result, np.array(exp), check_dtype=False)
diff --git a/pandas/tests/groupby/test_timegrouper.py b/pandas/tests/groupby/test_timegrouper.py
new file mode 100644
index 000000000..3142b74b5
--- /dev/null
+++ b/pandas/tests/groupby/test_timegrouper.py
@@ -0,0 +1,609 @@
+""" test with the TimeGrouper / grouping with datetimes """
+
+from datetime import datetime
+import numpy as np
+from numpy import nan
+
+import pandas as pd
+from pandas import DataFrame, date_range, Index, Series, MultiIndex, Timestamp
+from pandas.compat import StringIO
+from pandas.util import testing as tm
+from pandas.util.testing import assert_frame_equal, assert_series_equal
+
+
+class TestGroupBy(tm.TestCase):
+
+    def test_groupby_with_timegrouper(self):
+        # GH 4161
+        # TimeGrouper requires a sorted index
+        # also verifies that the resultant index has the correct name
+        df_original = DataFrame({
+            'Buyer': 'Carl Carl Carl Carl Joe Carl'.split(),
+            'Quantity': [18, 3, 5, 1, 9, 3],
+            'Date': [
+                datetime(2013, 9, 1, 13, 0),
+                datetime(2013, 9, 1, 13, 5),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 3, 10, 0),
+                datetime(2013, 12, 2, 12, 0),
+                datetime(2013, 9, 2, 14, 0),
+            ]
+        })
+
+        # GH 6908 change target column's order
+        df_reordered = df_original.sort_values(by='Quantity')
+
+        for df in [df_original, df_reordered]:
+            df = df.set_index(['Date'])
+
+            expected = DataFrame(
+                {'Quantity': np.nan},
+                index=date_range('20130901 13:00:00',
+                                 '20131205 13:00:00', freq='5D',
+                                 name='Date', closed='left'))
+            expected.iloc[[0, 6, 18], 0] = np.array(
+                [24., 6., 9.], dtype='float64')
+
+            result1 = df.resample('5D') .sum()
+            assert_frame_equal(result1, expected)
+
+            df_sorted = df.sort_index()
+            result2 = df_sorted.groupby(pd.TimeGrouper(freq='5D')).sum()
+            assert_frame_equal(result2, expected)
+
+            result3 = df.groupby(pd.TimeGrouper(freq='5D')).sum()
+            assert_frame_equal(result3, expected)
+
+    def test_groupby_with_timegrouper_methods(self):
+        # GH 3881
+        # make sure API of timegrouper conforms
+
+        df_original = pd.DataFrame({
+            'Branch': 'A A A A A B'.split(),
+            'Buyer': 'Carl Mark Carl Joe Joe Carl'.split(),
+            'Quantity': [1, 3, 5, 8, 9, 3],
+            'Date': [
+                datetime(2013, 1, 1, 13, 0),
+                datetime(2013, 1, 1, 13, 5),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 2, 10, 0),
+                datetime(2013, 12, 2, 12, 0),
+                datetime(2013, 12, 2, 14, 0),
+            ]
+        })
+
+        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
+
+        for df in [df_original, df_sorted]:
+            df = df.set_index('Date', drop=False)
+            g = df.groupby(pd.TimeGrouper('6M'))
+            self.assertTrue(g.group_keys)
+            self.assertTrue(isinstance(g.grouper, pd.core.groupby.BinGrouper))
+            groups = g.groups
+            self.assertTrue(isinstance(groups, dict))
+            self.assertTrue(len(groups) == 3)
+
+    def test_timegrouper_with_reg_groups(self):
+
+        # GH 3794
+        # allow combinateion of timegrouper/reg groups
+
+        df_original = DataFrame({
+            'Branch': 'A A A A A A A B'.split(),
+            'Buyer': 'Carl Mark Carl Carl Joe Joe Joe Carl'.split(),
+            'Quantity': [1, 3, 5, 1, 8, 1, 9, 3],
+            'Date': [
+                datetime(2013, 1, 1, 13, 0),
+                datetime(2013, 1, 1, 13, 5),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 2, 10, 0),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 2, 10, 0),
+                datetime(2013, 12, 2, 12, 0),
+                datetime(2013, 12, 2, 14, 0),
+            ]
+        }).set_index('Date')
+
+        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
+
+        for df in [df_original, df_sorted]:
+            expected = DataFrame({
+                'Buyer': 'Carl Joe Mark'.split(),
+                'Quantity': [10, 18, 3],
+                'Date': [
+                    datetime(2013, 12, 31, 0, 0),
+                    datetime(2013, 12, 31, 0, 0),
+                    datetime(2013, 12, 31, 0, 0),
+                ]
+            }).set_index(['Date', 'Buyer'])
+
+            result = df.groupby([pd.Grouper(freq='A'), 'Buyer']).sum()
+            assert_frame_equal(result, expected)
+
+            expected = DataFrame({
+                'Buyer': 'Carl Mark Carl Joe'.split(),
+                'Quantity': [1, 3, 9, 18],
+                'Date': [
+                    datetime(2013, 1, 1, 0, 0),
+                    datetime(2013, 1, 1, 0, 0),
+                    datetime(2013, 7, 1, 0, 0),
+                    datetime(2013, 7, 1, 0, 0),
+                ]
+            }).set_index(['Date', 'Buyer'])
+            result = df.groupby([pd.Grouper(freq='6MS'), 'Buyer']).sum()
+            assert_frame_equal(result, expected)
+
+        df_original = DataFrame({
+            'Branch': 'A A A A A A A B'.split(),
+            'Buyer': 'Carl Mark Carl Carl Joe Joe Joe Carl'.split(),
+            'Quantity': [1, 3, 5, 1, 8, 1, 9, 3],
+            'Date': [
+                datetime(2013, 10, 1, 13, 0),
+                datetime(2013, 10, 1, 13, 5),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 2, 10, 0),
+                datetime(2013, 10, 1, 20, 0),
+                datetime(2013, 10, 2, 10, 0),
+                datetime(2013, 10, 2, 12, 0),
+                datetime(2013, 10, 2, 14, 0),
+            ]
+        }).set_index('Date')
+
+        df_sorted = df_original.sort_values(by='Quantity', ascending=False)
+        for df in [df_original, df_sorted]:
+
+            expected = DataFrame({
+                'Buyer': 'Carl Joe Mark Carl Joe'.split(),
+                'Quantity': [6, 8, 3, 4, 10],
+                'Date': [
+                    datetime(2013, 10, 1, 0, 0),
+                    datetime(2013, 10, 1, 0, 0),
+                    datetime(2013, 10, 1, 0, 0),
+                    datetime(2013, 10, 2, 0, 0),
+                    datetime(2013, 10, 2, 0, 0),
+                ]
+            }).set_index(['Date', 'Buyer'])
+
+            result = df.groupby([pd.Grouper(freq='1D'), 'Buyer']).sum()
+            assert_frame_equal(result, expected)
+
+            result = df.groupby([pd.Grouper(freq='1M'), 'Buyer']).sum()
+            expected = DataFrame({
+                'Buyer': 'Carl Joe Mark'.split(),
+                'Quantity': [10, 18, 3],
+                'Date': [
+                    datetime(2013, 10, 31, 0, 0),
+                    datetime(2013, 10, 31, 0, 0),
+                    datetime(2013, 10, 31, 0, 0),
+                ]
+            }).set_index(['Date', 'Buyer'])
+            assert_frame_equal(result, expected)
+
+            # passing the name
+            df = df.reset_index()
+            result = df.groupby([pd.Grouper(freq='1M', key='Date'), 'Buyer'
+                                 ]).sum()
+            assert_frame_equal(result, expected)
+
+            with self.assertRaises(KeyError):
+                df.groupby([pd.Grouper(freq='1M', key='foo'), 'Buyer']).sum()
+
+            # passing the level
+            df = df.set_index('Date')
+            result = df.groupby([pd.Grouper(freq='1M', level='Date'), 'Buyer'
+                                 ]).sum()
+            assert_frame_equal(result, expected)
+            result = df.groupby([pd.Grouper(freq='1M', level=0), 'Buyer']).sum(
+            )
+            assert_frame_equal(result, expected)
+
+            with self.assertRaises(ValueError):
+                df.groupby([pd.Grouper(freq='1M', level='foo'),
+                            'Buyer']).sum()
+
+            # multi names
+            df = df.copy()
+            df['Date'] = df.index + pd.offsets.MonthEnd(2)
+            result = df.groupby([pd.Grouper(freq='1M', key='Date'), 'Buyer'
+                                 ]).sum()
+            expected = DataFrame({
+                'Buyer': 'Carl Joe Mark'.split(),
+                'Quantity': [10, 18, 3],
+                'Date': [
+                    datetime(2013, 11, 30, 0, 0),
+                    datetime(2013, 11, 30, 0, 0),
+                    datetime(2013, 11, 30, 0, 0),
+                ]
+            }).set_index(['Date', 'Buyer'])
+            assert_frame_equal(result, expected)
+
+            # error as we have both a level and a name!
+            with self.assertRaises(ValueError):
+                df.groupby([pd.Grouper(freq='1M', key='Date',
+                                       level='Date'), 'Buyer']).sum()
+
+            # single groupers
+            expected = DataFrame({'Quantity': [31],
+                                  'Date': [datetime(2013, 10, 31, 0, 0)
+                                           ]}).set_index('Date')
+            result = df.groupby(pd.Grouper(freq='1M')).sum()
+            assert_frame_equal(result, expected)
+
+            result = df.groupby([pd.Grouper(freq='1M')]).sum()
+            assert_frame_equal(result, expected)
+
+            expected = DataFrame({'Quantity': [31],
+                                  'Date': [datetime(2013, 11, 30, 0, 0)
+                                           ]}).set_index('Date')
+            result = df.groupby(pd.Grouper(freq='1M', key='Date')).sum()
+            assert_frame_equal(result, expected)
+
+            result = df.groupby([pd.Grouper(freq='1M', key='Date')]).sum()
+            assert_frame_equal(result, expected)
+
+        # GH 6764 multiple grouping with/without sort
+        df = DataFrame({
+            'date': pd.to_datetime([
+                '20121002', '20121007', '20130130', '20130202', '20130305',
+                '20121002', '20121207', '20130130', '20130202', '20130305',
+                '20130202', '20130305'
+            ]),
+            'user_id': [1, 1, 1, 1, 1, 3, 3, 3, 5, 5, 5, 5],
+            'whole_cost': [1790, 364, 280, 259, 201, 623, 90, 312, 359, 301,
+                           359, 801],
+            'cost1': [12, 15, 10, 24, 39, 1, 0, 90, 45, 34, 1, 12]
+        }).set_index('date')
+
+        for freq in ['D', 'M', 'A', 'Q-APR']:
+            expected = df.groupby('user_id')[
+                'whole_cost'].resample(
+                    freq).sum().dropna().reorder_levels(
+                        ['date', 'user_id']).sort_index().astype('int64')
+            expected.name = 'whole_cost'
+
+            result1 = df.sort_index().groupby([pd.TimeGrouper(freq=freq),
+                                               'user_id'])['whole_cost'].sum()
+            assert_series_equal(result1, expected)
+
+            result2 = df.groupby([pd.TimeGrouper(freq=freq), 'user_id'])[
+                'whole_cost'].sum()
+            assert_series_equal(result2, expected)
+
+    def test_timegrouper_get_group(self):
+        # GH 6914
+
+        df_original = DataFrame({
+            'Buyer': 'Carl Joe Joe Carl Joe Carl'.split(),
+            'Quantity': [18, 3, 5, 1, 9, 3],
+            'Date': [datetime(2013, 9, 1, 13, 0),
+                     datetime(2013, 9, 1, 13, 5),
+                     datetime(2013, 10, 1, 20, 0),
+                     datetime(2013, 10, 3, 10, 0),
+                     datetime(2013, 12, 2, 12, 0),
+                     datetime(2013, 9, 2, 14, 0), ]
+        })
+        df_reordered = df_original.sort_values(by='Quantity')
+
+        # single grouping
+        expected_list = [df_original.iloc[[0, 1, 5]], df_original.iloc[[2, 3]],
+                         df_original.iloc[[4]]]
+        dt_list = ['2013-09-30', '2013-10-31', '2013-12-31']
+
+        for df in [df_original, df_reordered]:
+            grouped = df.groupby(pd.Grouper(freq='M', key='Date'))
+            for t, expected in zip(dt_list, expected_list):
+                dt = pd.Timestamp(t)
+                result = grouped.get_group(dt)
+                assert_frame_equal(result, expected)
+
+        # multiple grouping
+        expected_list = [df_original.iloc[[1]], df_original.iloc[[3]],
+                         df_original.iloc[[4]]]
+        g_list = [('Joe', '2013-09-30'), ('Carl', '2013-10-31'),
+                  ('Joe', '2013-12-31')]
+
+        for df in [df_original, df_reordered]:
+            grouped = df.groupby(['Buyer', pd.Grouper(freq='M', key='Date')])
+            for (b, t), expected in zip(g_list, expected_list):
+                dt = pd.Timestamp(t)
+                result = grouped.get_group((b, dt))
+                assert_frame_equal(result, expected)
+
+        # with index
+        df_original = df_original.set_index('Date')
+        df_reordered = df_original.sort_values(by='Quantity')
+
+        expected_list = [df_original.iloc[[0, 1, 5]], df_original.iloc[[2, 3]],
+                         df_original.iloc[[4]]]
+
+        for df in [df_original, df_reordered]:
+            grouped = df.groupby(pd.Grouper(freq='M'))
+            for t, expected in zip(dt_list, expected_list):
+                dt = pd.Timestamp(t)
+                result = grouped.get_group(dt)
+                assert_frame_equal(result, expected)
+
+    def test_timegrouper_apply_return_type_series(self):
+        # Using `apply` with the `TimeGrouper` should give the
+        # same return type as an `apply` with a `Grouper`.
+        # Issue #11742
+        df = pd.DataFrame({'date': ['10/10/2000', '11/10/2000'],
+                           'value': [10, 13]})
+        df_dt = df.copy()
+        df_dt['date'] = pd.to_datetime(df_dt['date'])
+
+        def sumfunc_series(x):
+            return pd.Series([x['value'].sum()], ('sum',))
+
+        expected = df.groupby(pd.Grouper(key='date')).apply(sumfunc_series)
+        result = (df_dt.groupby(pd.TimeGrouper(freq='M', key='date'))
+                  .apply(sumfunc_series))
+        assert_frame_equal(result.reset_index(drop=True),
+                           expected.reset_index(drop=True))
+
+    def test_timegrouper_apply_return_type_value(self):
+        # Using `apply` with the `TimeGrouper` should give the
+        # same return type as an `apply` with a `Grouper`.
+        # Issue #11742
+        df = pd.DataFrame({'date': ['10/10/2000', '11/10/2000'],
+                           'value': [10, 13]})
+        df_dt = df.copy()
+        df_dt['date'] = pd.to_datetime(df_dt['date'])
+
+        def sumfunc_value(x):
+            return x.value.sum()
+
+        expected = df.groupby(pd.Grouper(key='date')).apply(sumfunc_value)
+        result = (df_dt.groupby(pd.TimeGrouper(freq='M', key='date'))
+                  .apply(sumfunc_value))
+        assert_series_equal(result.reset_index(drop=True),
+                            expected.reset_index(drop=True))
+
+    def test_groupby_groups_datetimeindex(self):
+        # #1430
+        from pandas.tseries.api import DatetimeIndex
+        periods = 1000
+        ind = DatetimeIndex(start='2012/1/1', freq='5min', periods=periods)
+        df = DataFrame({'high': np.arange(periods),
+                        'low': np.arange(periods)}, index=ind)
+        grouped = df.groupby(lambda x: datetime(x.year, x.month, x.day))
+
+        # it works!
+        groups = grouped.groups
+        tm.assertIsInstance(list(groups.keys())[0], datetime)
+
+        # GH 11442
+        index = pd.date_range('2015/01/01', periods=5, name='date')
+        df = pd.DataFrame({'A': [5, 6, 7, 8, 9],
+                           'B': [1, 2, 3, 4, 5]}, index=index)
+        result = df.groupby(level='date').groups
+        dates = ['2015-01-05', '2015-01-04', '2015-01-03',
+                 '2015-01-02', '2015-01-01']
+        expected = {pd.Timestamp(date): pd.DatetimeIndex([date], name='date')
+                    for date in dates}
+        tm.assert_dict_equal(result, expected)
+
+        grouped = df.groupby(level='date')
+        for date in dates:
+            result = grouped.get_group(date)
+            data = [[df.loc[date, 'A'], df.loc[date, 'B']]]
+            expected_index = pd.DatetimeIndex([date], name='date')
+            expected = pd.DataFrame(data,
+                                    columns=list('AB'),
+                                    index=expected_index)
+            tm.assert_frame_equal(result, expected)
+
+    def test_groupby_groups_datetimeindex_tz(self):
+        # GH 3950
+        dates = ['2011-07-19 07:00:00', '2011-07-19 08:00:00',
+                 '2011-07-19 09:00:00', '2011-07-19 07:00:00',
+                 '2011-07-19 08:00:00', '2011-07-19 09:00:00']
+        df = DataFrame({'label': ['a', 'a', 'a', 'b', 'b', 'b'],
+                        'datetime': dates,
+                        'value1': np.arange(6, dtype='int64'),
+                        'value2': [1, 2] * 3})
+        df['datetime'] = df['datetime'].apply(
+            lambda d: Timestamp(d, tz='US/Pacific'))
+
+        exp_idx1 = pd.DatetimeIndex(['2011-07-19 07:00:00',
+                                     '2011-07-19 07:00:00',
+                                     '2011-07-19 08:00:00',
+                                     '2011-07-19 08:00:00',
+                                     '2011-07-19 09:00:00',
+                                     '2011-07-19 09:00:00'],
+                                    tz='US/Pacific', name='datetime')
+        exp_idx2 = Index(['a', 'b'] * 3, name='label')
+        exp_idx = MultiIndex.from_arrays([exp_idx1, exp_idx2])
+        expected = DataFrame({'value1': [0, 3, 1, 4, 2, 5],
+                              'value2': [1, 2, 2, 1, 1, 2]},
+                             index=exp_idx, columns=['value1', 'value2'])
+
+        result = df.groupby(['datetime', 'label']).sum()
+        assert_frame_equal(result, expected)
+
+        # by level
+        didx = pd.DatetimeIndex(dates, tz='Asia/Tokyo')
+        df = DataFrame({'value1': np.arange(6, dtype='int64'),
+                        'value2': [1, 2, 3, 1, 2, 3]},
+                       index=didx)
+
+        exp_idx = pd.DatetimeIndex(['2011-07-19 07:00:00',
+                                    '2011-07-19 08:00:00',
+                                    '2011-07-19 09:00:00'], tz='Asia/Tokyo')
+        expected = DataFrame({'value1': [3, 5, 7], 'value2': [2, 4, 6]},
+                             index=exp_idx, columns=['value1', 'value2'])
+
+        result = df.groupby(level=0).sum()
+        assert_frame_equal(result, expected)
+
+    def test_frame_datetime64_handling_groupby(self):
+        # it works!
+        df = DataFrame([(3, np.datetime64('2012-07-03')),
+                        (3, np.datetime64('2012-07-04'))],
+                       columns=['a', 'date'])
+        result = df.groupby('a').first()
+        self.assertEqual(result['date'][3], Timestamp('2012-07-03'))
+
+    def test_groupby_multi_timezone(self):
+
+        # combining multiple / different timezones yields UTC
+
+        data = """0,2000-01-28 16:47:00,America/Chicago
+1,2000-01-29 16:48:00,America/Chicago
+2,2000-01-30 16:49:00,America/Los_Angeles
+3,2000-01-31 16:50:00,America/Chicago
+4,2000-01-01 16:50:00,America/New_York"""
+
+        df = pd.read_csv(StringIO(data), header=None,
+                         names=['value', 'date', 'tz'])
+        result = df.groupby('tz').date.apply(
+            lambda x: pd.to_datetime(x).dt.tz_localize(x.name))
+
+        expected = Series([Timestamp('2000-01-28 16:47:00-0600',
+                                     tz='America/Chicago'),
+                           Timestamp('2000-01-29 16:48:00-0600',
+                                     tz='America/Chicago'),
+                           Timestamp('2000-01-30 16:49:00-0800',
+                                     tz='America/Los_Angeles'),
+                           Timestamp('2000-01-31 16:50:00-0600',
+                                     tz='America/Chicago'),
+                           Timestamp('2000-01-01 16:50:00-0500',
+                                     tz='America/New_York')],
+                          name='date',
+                          dtype=object)
+        assert_series_equal(result, expected)
+
+        tz = 'America/Chicago'
+        res_values = df.groupby('tz').date.get_group(tz)
+        result = pd.to_datetime(res_values).dt.tz_localize(tz)
+        exp_values = Series(['2000-01-28 16:47:00', '2000-01-29 16:48:00',
+                             '2000-01-31 16:50:00'],
+                            index=[0, 1, 3], name='date')
+        expected = pd.to_datetime(exp_values).dt.tz_localize(tz)
+        assert_series_equal(result, expected)
+
+    def test_groupby_groups_periods(self):
+        dates = ['2011-07-19 07:00:00', '2011-07-19 08:00:00',
+                 '2011-07-19 09:00:00', '2011-07-19 07:00:00',
+                 '2011-07-19 08:00:00', '2011-07-19 09:00:00']
+        df = DataFrame({'label': ['a', 'a', 'a', 'b', 'b', 'b'],
+                        'period': [pd.Period(d, freq='H') for d in dates],
+                        'value1': np.arange(6, dtype='int64'),
+                        'value2': [1, 2] * 3})
+
+        exp_idx1 = pd.PeriodIndex(['2011-07-19 07:00:00',
+                                   '2011-07-19 07:00:00',
+                                   '2011-07-19 08:00:00',
+                                   '2011-07-19 08:00:00',
+                                   '2011-07-19 09:00:00',
+                                   '2011-07-19 09:00:00'],
+                                  freq='H', name='period')
+        exp_idx2 = Index(['a', 'b'] * 3, name='label')
+        exp_idx = MultiIndex.from_arrays([exp_idx1, exp_idx2])
+        expected = DataFrame({'value1': [0, 3, 1, 4, 2, 5],
+                              'value2': [1, 2, 2, 1, 1, 2]},
+                             index=exp_idx, columns=['value1', 'value2'])
+
+        result = df.groupby(['period', 'label']).sum()
+        assert_frame_equal(result, expected)
+
+        # by level
+        didx = pd.PeriodIndex(dates, freq='H')
+        df = DataFrame({'value1': np.arange(6, dtype='int64'),
+                        'value2': [1, 2, 3, 1, 2, 3]},
+                       index=didx)
+
+        exp_idx = pd.PeriodIndex(['2011-07-19 07:00:00',
+                                  '2011-07-19 08:00:00',
+                                  '2011-07-19 09:00:00'], freq='H')
+        expected = DataFrame({'value1': [3, 5, 7], 'value2': [2, 4, 6]},
+                             index=exp_idx, columns=['value1', 'value2'])
+
+        result = df.groupby(level=0).sum()
+        assert_frame_equal(result, expected)
+
+    def test_groupby_first_datetime64(self):
+        df = DataFrame([(1, 1351036800000000000), (2, 1351036800000000000)])
+        df[1] = df[1].view('M8[ns]')
+
+        self.assertTrue(issubclass(df[1].dtype.type, np.datetime64))
+
+        result = df.groupby(level=0).first()
+        got_dt = result[1].dtype
+        self.assertTrue(issubclass(got_dt.type, np.datetime64))
+
+        result = df[1].groupby(level=0).first()
+        got_dt = result.dtype
+        self.assertTrue(issubclass(got_dt.type, np.datetime64))
+
+    def test_groupby_max_datetime64(self):
+        # GH 5869
+        # datetimelike dtype conversion from int
+        df = DataFrame(dict(A=Timestamp('20130101'), B=np.arange(5)))
+        expected = df.groupby('A')['A'].apply(lambda x: x.max())
+        result = df.groupby('A')['A'].max()
+        assert_series_equal(result, expected)
+
+    def test_groupby_datetime64_32_bit(self):
+        # GH 6410 / numpy 4328
+        # 32-bit under 1.9-dev indexing issue
+
+        df = DataFrame({"A": range(2), "B": [pd.Timestamp('2000-01-1')] * 2})
+        result = df.groupby("A")["B"].transform(min)
+        expected = Series([pd.Timestamp('2000-01-1')] * 2, name='B')
+        assert_series_equal(result, expected)
+
+    def test_groupby_with_timezone_selection(self):
+        # GH 11616
+        # Test that column selection returns output in correct timezone.
+        np.random.seed(42)
+        df = pd.DataFrame({
+            'factor': np.random.randint(0, 3, size=60),
+            'time': pd.date_range('01/01/2000 00:00', periods=60,
+                                  freq='s', tz='UTC')
+        })
+        df1 = df.groupby('factor').max()['time']
+        df2 = df.groupby('factor')['time'].max()
+        tm.assert_series_equal(df1, df2)
+
+    def test_timezone_info(self):
+        # GH 11682
+        # Timezone info lost when broadcasting scalar datetime to DataFrame
+        tm._skip_if_no_pytz()
+        import pytz
+
+        df = pd.DataFrame({'a': [1], 'b': [datetime.now(pytz.utc)]})
+        self.assertEqual(df['b'][0].tzinfo, pytz.utc)
+        df = pd.DataFrame({'a': [1, 2, 3]})
+        df['b'] = datetime.now(pytz.utc)
+        self.assertEqual(df['b'][0].tzinfo, pytz.utc)
+
+    def test_datetime_count(self):
+        df = DataFrame({'a': [1, 2, 3] * 2,
+                        'dates': pd.date_range('now', periods=6, freq='T')})
+        result = df.groupby('a').dates.count()
+        expected = Series([
+            2, 2, 2
+        ], index=Index([1, 2, 3], name='a'), name='dates')
+        tm.assert_series_equal(result, expected)
+
+    def test_first_last_max_min_on_time_data(self):
+        # GH 10295
+        # Verify that NaT is not in the result of max, min, first and last on
+        # Dataframe with datetime or timedelta values.
+        from datetime import timedelta as td
+        df_test = DataFrame(
+            {'dt': [nan, '2015-07-24 10:10', '2015-07-25 11:11',
+                    '2015-07-23 12:12', nan],
+             'td': [nan, td(days=1), td(days=2), td(days=3), nan]})
+        df_test.dt = pd.to_datetime(df_test.dt)
+        df_test['group'] = 'A'
+        df_ref = df_test[df_test.dt.notnull()]
+
+        grouped_test = df_test.groupby('group')
+        grouped_ref = df_ref.groupby('group')
+
+        assert_frame_equal(grouped_ref.max(), grouped_test.max())
+        assert_frame_equal(grouped_ref.min(), grouped_test.min())
+        assert_frame_equal(grouped_ref.first(), grouped_test.first())
+        assert_frame_equal(grouped_ref.last(), grouped_test.last())
diff --git a/pandas/tests/groupby/test_transform.py b/pandas/tests/groupby/test_transform.py
new file mode 100644
index 000000000..cf5e9eb26
--- /dev/null
+++ b/pandas/tests/groupby/test_transform.py
@@ -0,0 +1,494 @@
+""" test with the .transform """
+
+import numpy as np
+import pandas as pd
+from pandas.util import testing as tm
+from pandas import Series, DataFrame, Timestamp, MultiIndex, concat
+from pandas.types.common import _ensure_platform_int
+from .common import MixIn, assert_fp_equal
+
+from pandas.util.testing import assert_frame_equal, assert_series_equal
+from pandas.core.groupby import DataError
+from pandas.core.config import option_context
+
+
+class TestGroupBy(MixIn, tm.TestCase):
+
+    def test_transform(self):
+        data = Series(np.arange(9) // 3, index=np.arange(9))
+
+        index = np.arange(9)
+        np.random.shuffle(index)
+        data = data.reindex(index)
+
+        grouped = data.groupby(lambda x: x // 3)
+
+        transformed = grouped.transform(lambda x: x * x.sum())
+        self.assertEqual(transformed[7], 12)
+
+        # GH 8046
+        # make sure that we preserve the input order
+
+        df = DataFrame(
+            np.arange(6, dtype='int64').reshape(
+                3, 2), columns=["a", "b"], index=[0, 2, 1])
+        key = [0, 0, 1]
+        expected = df.sort_index().groupby(key).transform(
+            lambda x: x - x.mean()).groupby(key).mean()
+        result = df.groupby(key).transform(lambda x: x - x.mean()).groupby(
+            key).mean()
+        assert_frame_equal(result, expected)
+
+        def demean(arr):
+            return arr - arr.mean()
+
+        people = DataFrame(np.random.randn(5, 5),
+                           columns=['a', 'b', 'c', 'd', 'e'],
+                           index=['Joe', 'Steve', 'Wes', 'Jim', 'Travis'])
+        key = ['one', 'two', 'one', 'two', 'one']
+        result = people.groupby(key).transform(demean).groupby(key).mean()
+        expected = people.groupby(key).apply(demean).groupby(key).mean()
+        assert_frame_equal(result, expected)
+
+        # GH 8430
+        df = tm.makeTimeDataFrame()
+        g = df.groupby(pd.TimeGrouper('M'))
+        g.transform(lambda x: x - 1)
+
+        # GH 9700
+        df = DataFrame({'a': range(5, 10), 'b': range(5)})
+        result = df.groupby('a').transform(max)
+        expected = DataFrame({'b': range(5)})
+        tm.assert_frame_equal(result, expected)
+
+    def test_transform_fast(self):
+
+        df = DataFrame({'id': np.arange(100000) / 3,
+                        'val': np.random.randn(100000)})
+
+        grp = df.groupby('id')['val']
+
+        values = np.repeat(grp.mean().values,
+                           _ensure_platform_int(grp.count().values))
+        expected = pd.Series(values, index=df.index, name='val')
+
+        result = grp.transform(np.mean)
+        assert_series_equal(result, expected)
+
+        result = grp.transform('mean')
+        assert_series_equal(result, expected)
+
+        # GH 12737
+        df = pd.DataFrame({'grouping': [0, 1, 1, 3], 'f': [1.1, 2.1, 3.1, 4.5],
+                           'd': pd.date_range('2014-1-1', '2014-1-4'),
+                           'i': [1, 2, 3, 4]},
+                          columns=['grouping', 'f', 'i', 'd'])
+        result = df.groupby('grouping').transform('first')
+
+        dates = [pd.Timestamp('2014-1-1'), pd.Timestamp('2014-1-2'),
+                 pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-4')]
+        expected = pd.DataFrame({'f': [1.1, 2.1, 2.1, 4.5],
+                                 'd': dates,
+                                 'i': [1, 2, 2, 4]},
+                                columns=['f', 'i', 'd'])
+        assert_frame_equal(result, expected)
+
+        # selection
+        result = df.groupby('grouping')[['f', 'i']].transform('first')
+        expected = expected[['f', 'i']]
+        assert_frame_equal(result, expected)
+
+        # dup columns
+        df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=['g', 'a', 'a'])
+        result = df.groupby('g').transform('first')
+        expected = df.drop('g', axis=1)
+        assert_frame_equal(result, expected)
+
+    def test_transform_broadcast(self):
+        grouped = self.ts.groupby(lambda x: x.month)
+        result = grouped.transform(np.mean)
+
+        self.assert_index_equal(result.index, self.ts.index)
+        for _, gp in grouped:
+            assert_fp_equal(result.reindex(gp.index), gp.mean())
+
+        grouped = self.tsframe.groupby(lambda x: x.month)
+        result = grouped.transform(np.mean)
+        self.assert_index_equal(result.index, self.tsframe.index)
+        for _, gp in grouped:
+            agged = gp.mean()
+            res = result.reindex(gp.index)
+            for col in self.tsframe:
+                assert_fp_equal(res[col], agged[col])
+
+        # group columns
+        grouped = self.tsframe.groupby({'A': 0, 'B': 0, 'C': 1, 'D': 1},
+                                       axis=1)
+        result = grouped.transform(np.mean)
+        self.assert_index_equal(result.index, self.tsframe.index)
+        self.assert_index_equal(result.columns, self.tsframe.columns)
+        for _, gp in grouped:
+            agged = gp.mean(1)
+            res = result.reindex(columns=gp.columns)
+            for idx in gp.index:
+                assert_fp_equal(res.xs(idx), agged[idx])
+
+    def test_transform_axis(self):
+
+        # make sure that we are setting the axes
+        # correctly when on axis=0 or 1
+        # in the presence of a non-monotonic indexer
+        # GH12713
+
+        base = self.tsframe.iloc[0:5]
+        r = len(base.index)
+        c = len(base.columns)
+        tso = DataFrame(np.random.randn(r, c),
+                        index=base.index,
+                        columns=base.columns,
+                        dtype='float64')
+        # monotonic
+        ts = tso
+        grouped = ts.groupby(lambda x: x.weekday())
+        result = ts - grouped.transform('mean')
+        expected = grouped.apply(lambda x: x - x.mean())
+        assert_frame_equal(result, expected)
+
+        ts = ts.T
+        grouped = ts.groupby(lambda x: x.weekday(), axis=1)
+        result = ts - grouped.transform('mean')
+        expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
+        assert_frame_equal(result, expected)
+
+        # non-monotonic
+        ts = tso.iloc[[1, 0] + list(range(2, len(base)))]
+        grouped = ts.groupby(lambda x: x.weekday())
+        result = ts - grouped.transform('mean')
+        expected = grouped.apply(lambda x: x - x.mean())
+        assert_frame_equal(result, expected)
+
+        ts = ts.T
+        grouped = ts.groupby(lambda x: x.weekday(), axis=1)
+        result = ts - grouped.transform('mean')
+        expected = grouped.apply(lambda x: (x.T - x.mean(1)).T)
+        assert_frame_equal(result, expected)
+
+    def test_transform_dtype(self):
+        # GH 9807
+        # Check transform dtype output is preserved
+        df = DataFrame([[1, 3], [2, 3]])
+        result = df.groupby(1).transform('mean')
+        expected = DataFrame([[1.5], [1.5]])
+        assert_frame_equal(result, expected)
+
+    def test_transform_bug(self):
+        # GH 5712
+        # transforming on a datetime column
+        df = DataFrame(dict(A=Timestamp('20130101'), B=np.arange(5)))
+        result = df.groupby('A')['B'].transform(
+            lambda x: x.rank(ascending=False))
+        expected = Series(np.arange(5, 0, step=-1), name='B')
+        assert_series_equal(result, expected)
+
+    def test_transform_multiple(self):
+        grouped = self.ts.groupby([lambda x: x.year, lambda x: x.month])
+
+        grouped.transform(lambda x: x * 2)
+        grouped.transform(np.mean)
+
+    def test_dispatch_transform(self):
+        df = self.tsframe[::5].reindex(self.tsframe.index)
+
+        grouped = df.groupby(lambda x: x.month)
+
+        filled = grouped.fillna(method='pad')
+        fillit = lambda x: x.fillna(method='pad')
+        expected = df.groupby(lambda x: x.month).transform(fillit)
+        assert_frame_equal(filled, expected)
+
+    def test_transform_select_columns(self):
+        f = lambda x: x.mean()
+        result = self.df.groupby('A')['C', 'D'].transform(f)
+
+        selection = self.df[['C', 'D']]
+        expected = selection.groupby(self.df['A']).transform(f)
+
+        assert_frame_equal(result, expected)
+
+    def test_transform_exclude_nuisance(self):
+
+        # this also tests orderings in transform between
+        # series/frame to make sure it's consistent
+        expected = {}
+        grouped = self.df.groupby('A')
+        expected['C'] = grouped['C'].transform(np.mean)
+        expected['D'] = grouped['D'].transform(np.mean)
+        expected = DataFrame(expected)
+        result = self.df.groupby('A').transform(np.mean)
+
+        assert_frame_equal(result, expected)
+
+    def test_transform_function_aliases(self):
+        result = self.df.groupby('A').transform('mean')
+        expected = self.df.groupby('A').transform(np.mean)
+        assert_frame_equal(result, expected)
+
+        result = self.df.groupby('A')['C'].transform('mean')
+        expected = self.df.groupby('A')['C'].transform(np.mean)
+        assert_series_equal(result, expected)
+
+    def test_series_fast_transform_date(self):
+        # GH 13191
+        df = pd.DataFrame({'grouping': [np.nan, 1, 1, 3],
+                           'd': pd.date_range('2014-1-1', '2014-1-4')})
+        result = df.groupby('grouping')['d'].transform('first')
+        dates = [pd.NaT, pd.Timestamp('2014-1-2'), pd.Timestamp('2014-1-2'),
+                 pd.Timestamp('2014-1-4')]
+        expected = pd.Series(dates, name='d')
+        assert_series_equal(result, expected)
+
+    def test_transform_length(self):
+        # GH 9697
+        df = pd.DataFrame({'col1': [1, 1, 2, 2], 'col2': [1, 2, 3, np.nan]})
+        expected = pd.Series([3.0] * 4)
+
+        def nsum(x):
+            return np.nansum(x)
+
+        results = [df.groupby('col1').transform(sum)['col2'],
+                   df.groupby('col1')['col2'].transform(sum),
+                   df.groupby('col1').transform(nsum)['col2'],
+                   df.groupby('col1')['col2'].transform(nsum)]
+        for result in results:
+            assert_series_equal(result, expected, check_names=False)
+
+    def test_transform_coercion(self):
+
+        # 14457
+        # when we are transforming be sure to not coerce
+        # via assignment
+        df = pd.DataFrame(dict(A=['a', 'a'], B=[0, 1]))
+        g = df.groupby('A')
+
+        expected = g.transform(np.mean)
+        result = g.transform(lambda x: np.mean(x))
+        assert_frame_equal(result, expected)
+
+    def test_groupby_transform_with_int(self):
+
+        # GH 3740, make sure that we might upcast on item-by-item transform
+
+        # floats
+        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=Series(1, dtype='float64'),
+                            C=Series(
+                                [1, 2, 3, 1, 2, 3], dtype='float64'), D='foo'))
+        with np.errstate(all='ignore'):
+            result = df.groupby('A').transform(
+                lambda x: (x - x.mean()) / x.std())
+        expected = DataFrame(dict(B=np.nan, C=Series(
+            [-1, 0, 1, -1, 0, 1], dtype='float64')))
+        assert_frame_equal(result, expected)
+
+        # int case
+        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=1,
+                            C=[1, 2, 3, 1, 2, 3], D='foo'))
+        with np.errstate(all='ignore'):
+            result = df.groupby('A').transform(
+                lambda x: (x - x.mean()) / x.std())
+        expected = DataFrame(dict(B=np.nan, C=[-1, 0, 1, -1, 0, 1]))
+        assert_frame_equal(result, expected)
+
+        # int that needs float conversion
+        s = Series([2, 3, 4, 10, 5, -1])
+        df = DataFrame(dict(A=[1, 1, 1, 2, 2, 2], B=1, C=s, D='foo'))
+        with np.errstate(all='ignore'):
+            result = df.groupby('A').transform(
+                lambda x: (x - x.mean()) / x.std())
+
+        s1 = s.iloc[0:3]
+        s1 = (s1 - s1.mean()) / s1.std()
+        s2 = s.iloc[3:6]
+        s2 = (s2 - s2.mean()) / s2.std()
+        expected = DataFrame(dict(B=np.nan, C=concat([s1, s2])))
+        assert_frame_equal(result, expected)
+
+        # int downcasting
+        result = df.groupby('A').transform(lambda x: x * 2 / 2)
+        expected = DataFrame(dict(B=1, C=[2, 3, 4, 10, 5, -1]))
+        assert_frame_equal(result, expected)
+
+    def test_groupby_transform_with_nan_group(self):
+        # GH 9941
+        df = pd.DataFrame({'a': range(10),
+                           'b': [1, 1, 2, 3, np.nan, 4, 4, 5, 5, 5]})
+        result = df.groupby(df.b)['a'].transform(max)
+        expected = pd.Series([1., 1., 2., 3., np.nan, 6., 6., 9., 9., 9.],
+                             name='a')
+        assert_series_equal(result, expected)
+
+    def test_transform_mixed_type(self):
+        index = MultiIndex.from_arrays([[0, 0, 0, 1, 1, 1], [1, 2, 3, 1, 2, 3]
+                                        ])
+        df = DataFrame({'d': [1., 1., 1., 2., 2., 2.],
+                        'c': np.tile(['a', 'b', 'c'], 2),
+                        'v': np.arange(1., 7.)}, index=index)
+
+        def f(group):
+            group['g'] = group['d'] * 2
+            return group[:1]
+
+        grouped = df.groupby('c')
+        result = grouped.apply(f)
+
+        self.assertEqual(result['d'].dtype, np.float64)
+
+        # this is by definition a mutating operation!
+        with option_context('mode.chained_assignment', None):
+            for key, group in grouped:
+                res = f(group)
+                assert_frame_equal(res, result.loc[key])
+
+    def test_cython_group_transform_algos(self):
+        # GH 4095
+        dtypes = [np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint32,
+                  np.uint64, np.float32, np.float64]
+
+        ops = [(pd.algos.group_cumprod_float64, np.cumproduct, [np.float64]),
+               (pd.algos.group_cumsum, np.cumsum, dtypes)]
+
+        is_datetimelike = False
+        for pd_op, np_op, dtypes in ops:
+            for dtype in dtypes:
+                data = np.array([[1], [2], [3], [4]], dtype=dtype)
+                ans = np.zeros_like(data)
+                labels = np.array([0, 0, 0, 0], dtype=np.int64)
+                pd_op(ans, data, labels, is_datetimelike)
+                self.assert_numpy_array_equal(np_op(data), ans[:, 0],
+                                              check_dtype=False)
+
+        # with nans
+        labels = np.array([0, 0, 0, 0, 0], dtype=np.int64)
+
+        data = np.array([[1], [2], [3], [np.nan], [4]], dtype='float64')
+        actual = np.zeros_like(data)
+        actual.fill(np.nan)
+        pd.algos.group_cumprod_float64(actual, data, labels, is_datetimelike)
+        expected = np.array([1, 2, 6, np.nan, 24], dtype='float64')
+        self.assert_numpy_array_equal(actual[:, 0], expected)
+
+        actual = np.zeros_like(data)
+        actual.fill(np.nan)
+        pd.algos.group_cumsum(actual, data, labels, is_datetimelike)
+        expected = np.array([1, 3, 6, np.nan, 10], dtype='float64')
+        self.assert_numpy_array_equal(actual[:, 0], expected)
+
+        # timedelta
+        is_datetimelike = True
+        data = np.array([np.timedelta64(1, 'ns')] * 5, dtype='m8[ns]')[:, None]
+        actual = np.zeros_like(data, dtype='int64')
+        pd.algos.group_cumsum(actual, data.view('int64'), labels,
+                              is_datetimelike)
+        expected = np.array([np.timedelta64(1, 'ns'), np.timedelta64(
+            2, 'ns'), np.timedelta64(3, 'ns'), np.timedelta64(4, 'ns'),
+            np.timedelta64(5, 'ns')])
+        self.assert_numpy_array_equal(actual[:, 0].view('m8[ns]'), expected)
+
+    def test_cython_transform(self):
+        # GH 4095
+        ops = [(('cumprod',
+                 ()), lambda x: x.cumprod()), (('cumsum', ()),
+                                               lambda x: x.cumsum()),
+               (('shift', (-1, )),
+                lambda x: x.shift(-1)), (('shift',
+                                          (1, )), lambda x: x.shift())]
+
+        s = Series(np.random.randn(1000))
+        s_missing = s.copy()
+        s_missing.iloc[2:10] = np.nan
+        labels = np.random.randint(0, 50, size=1000).astype(float)
+
+        # series
+        for (op, args), targop in ops:
+            for data in [s, s_missing]:
+                # print(data.head())
+                expected = data.groupby(labels).transform(targop)
+
+                tm.assert_series_equal(expected,
+                                       data.groupby(labels).transform(op,
+                                                                      *args))
+                tm.assert_series_equal(expected, getattr(
+                    data.groupby(labels), op)(*args))
+
+        strings = list('qwertyuiopasdfghjklz')
+        strings_missing = strings[:]
+        strings_missing[5] = np.nan
+        df = DataFrame({'float': s,
+                        'float_missing': s_missing,
+                        'int': [1, 1, 1, 1, 2] * 200,
+                        'datetime': pd.date_range('1990-1-1', periods=1000),
+                        'timedelta': pd.timedelta_range(1, freq='s',
+                                                        periods=1000),
+                        'string': strings * 50,
+                        'string_missing': strings_missing * 50})
+        df['cat'] = df['string'].astype('category')
+
+        df2 = df.copy()
+        df2.index = pd.MultiIndex.from_product([range(100), range(10)])
+
+        # DataFrame - Single and MultiIndex,
+        # group by values, index level, columns
+        for df in [df, df2]:
+            for gb_target in [dict(by=labels), dict(level=0), dict(by='string')
+                              ]:  # dict(by='string_missing')]:
+                # dict(by=['int','string'])]:
+
+                gb = df.groupby(**gb_target)
+                # whitelisted methods set the selection before applying
+                # bit a of hack to make sure the cythonized shift
+                # is equivalent to pre 0.17.1 behavior
+                if op == 'shift':
+                    gb._set_group_selection()
+
+                for (op, args), targop in ops:
+                    if op != 'shift' and 'int' not in gb_target:
+                        # numeric apply fastpath promotes dtype so have
+                        # to apply seperately and concat
+                        i = gb[['int']].apply(targop)
+                        f = gb[['float', 'float_missing']].apply(targop)
+                        expected = pd.concat([f, i], axis=1)
+                    else:
+                        expected = gb.apply(targop)
+
+                    expected = expected.sort_index(axis=1)
+                    tm.assert_frame_equal(expected,
+                                          gb.transform(op, *args).sort_index(
+                                              axis=1))
+                    tm.assert_frame_equal(expected, getattr(gb, op)(*args))
+                    # individual columns
+                    for c in df:
+                        if c not in ['float', 'int', 'float_missing'
+                                     ] and op != 'shift':
+                            self.assertRaises(DataError, gb[c].transform, op)
+                            self.assertRaises(DataError, getattr(gb[c], op))
+                        else:
+                            expected = gb[c].apply(targop)
+                            expected.name = c
+                            tm.assert_series_equal(expected,
+                                                   gb[c].transform(op, *args))
+                            tm.assert_series_equal(expected,
+                                                   getattr(gb[c], op)(*args))
+
+    def test_transform_with_non_scalar_group(self):
+        # GH 10165
+        cols = pd.MultiIndex.from_tuples([
+            ('syn', 'A'), ('mis', 'A'), ('non', 'A'),
+            ('syn', 'C'), ('mis', 'C'), ('non', 'C'),
+            ('syn', 'T'), ('mis', 'T'), ('non', 'T'),
+            ('syn', 'G'), ('mis', 'G'), ('non', 'G')])
+        df = pd.DataFrame(np.random.randint(1, 10, (4, 12)),
+                          columns=cols,
+                          index=['A', 'C', 'G', 'T'])
+        self.assertRaisesRegexp(ValueError, 'transform must return a scalar '
+                                'value for each group.*', df.groupby
+                                (axis=1, level=1).transform,
+                                lambda z: z.div(z.sum(axis=1), axis=0))
