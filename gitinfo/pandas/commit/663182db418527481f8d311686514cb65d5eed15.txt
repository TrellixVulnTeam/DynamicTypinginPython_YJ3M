commit 663182db418527481f8d311686514cb65d5eed15
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Aug 30 16:38:32 2012 -0400

    ENH: getting started on new C file parser engine

diff --git a/pandas/src/parser.pyx b/pandas/src/parser.pyx
new file mode 100644
index 000000000..4fe52dfb1
--- /dev/null
+++ b/pandas/src/parser.pyx
@@ -0,0 +1,211 @@
+cdef extern from "Python.h":
+    ctypedef struct FILE
+    FILE* PyFile_AsFile(object)
+
+
+cdef extern from "parser/common.h":
+
+    ctypedef enum ParserState:
+        START_RECORD
+        START_FIELD
+        ESCAPED_CHAR
+        IN_FIELD
+        IN_QUOTED_FIELD
+        ESCAPE_IN_QUOTED_FIELD
+        QUOTE_IN_QUOTED_FIELD
+        EAT_CRNL
+        FINISHED
+
+    ctypedef struct table_chunk:
+        void **columns
+        int ncols
+
+    ctypedef struct parser_t:
+        void *source
+        char sourcetype   # 'M' for mmap, 'F' for FILE, 'A' for array
+
+        int chunksize  # Number of bytes to prepare for each chunk
+        char *data     # pointer to data to be processed
+        int datalen    # amount of data available
+
+        # where to write out tokenized data
+        char *stream
+        int stream_len
+        int stream_cap
+
+        # Store words in (potentially ragged) matrix for now, hmm
+        char **words
+        int *word_starts # where we are in the stream
+        int words_len
+        int words_cap
+
+        char *pword_start    # pointer to stream start of current field
+        int word_start       # position start of current field
+
+        int *line_start      # position in words for start of line
+        int *line_fields     # Number of fields in each line
+        int lines            # Number of lines observed
+        int lines_cap        # Vector capacity
+
+        # Tokenizing stuff
+        ParserState state
+        int doublequote            # is " represented by ""? */
+        char delimiter             # field separator */
+        char quotechar             # quote character */
+        char escapechar            # escape character */
+        int skipinitialspace       # ignore spaces following delimiter? */
+        int quoting                # style of quoting to write */
+
+        # hmm =/
+        int numeric_field
+
+        char commentchar
+        int allow_embedded_newline
+        int strict                 # raise exception on bad CSV */
+
+        int error_bad_lines
+        int warn_bad_lines
+
+        int infer_types
+
+        # floating point options
+        char decimal
+        char sci
+
+        # thousands separator (comma, period)
+        char thousands
+
+        int header # Boolean: 1: has header, 0: no header
+
+        int skiprows
+        int skip_footer
+
+        table_chunk *chunks
+        int nchunks
+
+        void **columns
+        int ncols
+
+        # PyObject *converters
+
+        #  error handling
+        char *error_msg
+
+    parser_t* parser_new()
+
+    int parser_init(parser_t *self)
+    void parser_free(parser_t *self)
+
+    void set_parser_default_options(parser_t *self)
+
+    int parser_file_source_init(parser_t *self, FILE* fp)
+    int parser_mmap_init(parser_t *self, FILE* fp)
+    int parser_array_source_init(parser_t *self, char *bytes, size_t length)
+
+    void debug_print_parser(parser_t *self)
+
+    int tokenize_all_rows(parser_t *self)
+    int tokenize_nrows(parser_t *self, size_t nrows)
+
+cdef class TextReader:
+    '''
+
+    # source: StringIO or file object
+
+    '''
+
+    cdef:
+        parser_t *parser
+        object file_handle, should_close
+
+    def __cinit__(self, source, delimiter=',', header=0, memory_map=False,
+                  delim_whitespace=False,
+                  na_values=None,
+                  converters=None,
+                  thousands=None):
+        self.parser = parser_new()
+
+        self._setup_parser_source(source)
+
+        if delim_whitespace:
+            raise NotImplementedError
+        else:
+            if len(delimiter) > 1:
+                raise ValueError('only length-1 separators excluded right now')
+            self.parser.delimiter = delimiter
+
+        # TODO: no header vs. header is not the first row
+        self.parser.header = header
+
+        self.should_close = False
+
+        self.delimiter = delimiter
+        self.delim_whitespace = delim_whitespace
+
+        self.na_values
+        self.converters = converters
+        self.thousands = thousands
+
+    def __dealloc__(self):
+        parser_free(self.parser)
+
+    def __del__(self):
+        if self.should_close:
+            self.file_handle.close()
+
+    cdef _setup_parser_source(self, source):
+        cdef int status
+
+        if isinstance(source, (basestring, file)):
+            if isinstance(source, basestring):
+                self.file_handle = open(source, 'rb')
+                self.should_close = True
+                source = self.file_handle
+
+            status = parser_file_source_init(self.parser,
+                                             PyFile_AsFile(source))
+            if status != 0:
+                raise Exception('Initializing from file failed')
+
+        elif hasattr(source, 'read'):
+            # e.g., StringIO
+
+            bytes = source.read()
+
+            # TODO: unicode
+            if isinstance(bytes, unicode):
+                raise ValueError('Only ascii/bytes supported at the moment')
+
+            status = parser_array_source_init(self.parser,
+                                              <char*> bytes, len(bytes))
+            if status != 0:
+                raise Exception('Initializing parser from file-like '
+                                'object failed')
+
+    def _parse_table_header(self):
+        pass
+
+    def read(self, rows=None):
+        """
+        rows=None --> read all rows
+        """
+        cdef int status
+
+        if rows is not None:
+            raise NotImplementedError
+        else:
+            status = tokenize_all_rows(self.parser)
+
+
+class CParserError(Exception):
+    pass
+
+
+cdef raise_parser_error(object base, parser_t *parser):
+    message = '%s. C error: '
+    if parser.error_msg != NULL:
+        message += parser.error_msg
+    else:
+        message += 'no error message set'
+
+    raise CParserError(message)
diff --git a/pandas/src/parser/Makefile b/pandas/src/parser/Makefile
new file mode 100644
index 000000000..f23da130a
--- /dev/null
+++ b/pandas/src/parser/Makefile
@@ -0,0 +1,13 @@
+PYTHONBASE = /Library/Frameworks/EPD64.framework/Versions/Current
+NUMPY_INC = /Library/Frameworks/EPD64.framework/Versions/7.1/lib/python2.7/site-packages/numpy/core/include
+PYTHON_INC = -I$(PYTHONBASE)/include/python2.7 -I$(NUMPY_INC)
+PYTHON_LINK = -L$(PYTHONBASE)/lib -lpython
+
+SOURCES = common.c conversions.c rows.c str_to.c
+
+check-syntax:
+	gcc -g $(PYTHON_INC) -o /dev/null -S ${CHK_SOURCES}
+
+test: $(SOURCES)
+	gcc $(PYTHON_INC) -o test $(SOURCES)
+	./test
\ No newline at end of file
diff --git a/pandas/src/parser/common.h b/pandas/src/parser/common.h
new file mode 100644
index 000000000..b558ce9dd
--- /dev/null
+++ b/pandas/src/parser/common.h
@@ -0,0 +1,216 @@
+#ifndef _PARSER_COMMON_H_
+#define _PARSER_COMMON_H_
+
+
+#include <stdio.h>
+#include <string.h>
+#include <stdlib.h>
+#include <stdint.h>
+#include <time.h>
+#include <errno.h>
+
+// #include "Python.h"
+// #include "structmember.h"
+
+#define CHUNKSIZE 1024*256
+#define KB 1024
+#define MB 1024 * KB
+#define STREAM_INIT_SIZE 32
+
+
+/*
+
+  C flat file parsing low level code for pandas / NumPy
+
+ */
+
+#define FALSE 0
+#define TRUE  1
+
+// Maximum number of columns in a file.
+#define MAX_NUM_COLUMNS    2000
+
+// Maximum number of characters in single field.
+#define FIELD_BUFFER_SIZE  2000
+
+
+/*
+ *  Common set of error types for the read_rows() and tokenize()
+ *  functions.
+ */
+
+#define ERROR_OUT_OF_MEMORY             1
+#define ERROR_INVALID_COLUMN_INDEX     10
+#define ERROR_CHANGED_NUMBER_OF_FIELDS 12
+#define ERROR_TOO_MANY_CHARS           21
+#define ERROR_TOO_MANY_FIELDS          22
+#define ERROR_NO_DATA                  23
+
+
+// #define VERBOSE
+
+#if defined(VERBOSE)
+#define TRACE(X) printf X;
+#else
+#define TRACE(X)
+#endif
+
+
+#define PARSER_OUT_OF_MEMORY -1
+
+
+/*
+ *  XXX Might want to couple count_rows() with read_rows() to avoid duplication
+ *      of some file I/O.
+ */
+
+/*
+ *  WORD_BUFFER_SIZE determines the maximum amount of non-delimiter
+ *  text in a row.
+ */
+#define WORD_BUFFER_SIZE 4000
+
+
+typedef enum {
+    START_RECORD,
+    START_FIELD,
+    ESCAPED_CHAR,
+    IN_FIELD,
+    IN_QUOTED_FIELD,
+    ESCAPE_IN_QUOTED_FIELD,
+    QUOTE_IN_QUOTED_FIELD,
+    EAT_CRNL,
+    FINISHED
+} ParserState;
+
+typedef enum {
+    QUOTE_MINIMAL, QUOTE_ALL, QUOTE_NONNUMERIC, QUOTE_NONE
+} QuoteStyle;
+
+typedef struct _table_chunk {
+    void **columns;
+    int ncols;
+} table_chunk;
+
+
+
+
+typedef struct parser_t {
+    void *source;
+    char sourcetype;   // 'M' for mmap, 'F' for FILE, 'A' for array
+
+    int chunksize;  // Number of bytes to prepare for each chunk
+    char *data;     // pointer to data to be processed
+    int datalen;    // amount of data available
+
+    // where to write out tokenized data
+    char *stream;
+    int stream_len;
+    int stream_cap;
+
+    // Store words in (potentially ragged) matrix for now, hmm
+    char **words;
+    int *word_starts; // where we are in the stream
+    int words_len;
+    int words_cap;
+
+    char *pword_start;    // pointer to stream start of current field
+    int word_start;       // position start of current field
+
+    int *line_start;      // position in words for start of line
+    int *line_fields;     // Number of fields in each line
+    int lines;            // Number of lines observed
+    int lines_cap;        // Vector capacity
+
+    // Tokenizing stuff
+    ParserState state;
+    int doublequote;            /* is " represented by ""? */
+    char delimiter;             /* field separator */
+    char quotechar;             /* quote character */
+    char escapechar;            /* escape character */
+    int skipinitialspace;       /* ignore spaces following delimiter? */
+    int quoting;                /* style of quoting to write */
+
+    // hmm =/
+    int numeric_field;
+
+    char commentchar;
+    int allow_embedded_newline;
+    int strict;                 /* raise exception on bad CSV */
+
+    int error_bad_lines;
+    int warn_bad_lines;
+
+    int infer_types;
+
+    // floating point options
+    char decimal;
+    char sci;
+
+    // thousands separator (comma, period)
+    char thousands;
+
+    int header; // Boolean: 1: has header, 0: no header
+
+    int skiprows;
+    int skip_footer;
+
+    table_chunk *chunks;
+    int nchunks;
+
+    void **columns;
+    int ncols;
+
+    // PyObject *converters;
+
+    // error handling
+    char *error_msg;
+} parser_t;
+
+
+void *safe_realloc(void *buffer, size_t size);
+
+
+typedef struct coliter_t {
+    char **words;
+    int *line_start;
+    int col;
+    int line;
+} coliter_t;
+
+
+
+/* #define COLITER_NEXT(iter) iter->words[iter->line_start[iter->line++] + iter->col] */
+#define COLITER_NEXT(iter) iter.words[iter.line_start[iter.line++] + iter.col]
+
+parser_t* parser_new();
+
+int parser_init(parser_t *self);
+
+int parser_file_source_init(parser_t *self, FILE *fp);
+
+int parser_mmap_init(parser_t *self, FILE *fp);
+
+int parser_array_source_init(parser_t *self, char *bytes, size_t length);
+
+int parser_gzip_source_init(parser_t *self, FILE *fp);
+
+void parser_free(parser_t *self);
+
+void set_parser_default_options(parser_t *self);
+
+void debug_print_parser(parser_t *self);
+
+int tokenize_nrows(parser_t *self, size_t nrows);
+
+int tokenize_all_rows(parser_t *self);
+
+/*
+
+  Have parsed / type-converted a chunk of data and want to free memory from the
+  token stream
+
+ */
+int clear_parsed_lines(parser_t *self, size_t nlines);
+
+#endif // _PARSER_COMMON_H_
diff --git a/pandas/src/parser/constants.h b/pandas/src/parser/constants.h
new file mode 100644
index 000000000..79695af83
--- /dev/null
+++ b/pandas/src/parser/constants.h
@@ -0,0 +1,3 @@
+
+#define FALSE 0
+#define TRUE  1
diff --git a/pandas/src/parser/conversions.h b/pandas/src/parser/conversions.h
new file mode 100644
index 000000000..4e9864456
--- /dev/null
+++ b/pandas/src/parser/conversions.h
@@ -0,0 +1,3 @@
+int inline to_double(char *item, double *p_value, char sci, char decimal);
+int to_complex(char *item, double *p_real, double *p_imag, char sci, char decimal);
+int to_longlong(char *item, long long *p_value);
diff --git a/pandas/src/parser/rows.h b/pandas/src/parser/rows.h
new file mode 100644
index 000000000..4b00706ff
--- /dev/null
+++ b/pandas/src/parser/rows.h
@@ -0,0 +1,20 @@
+
+#define READ_ERROR_OUT_OF_MEMORY   1
+
+int count_rows(FILE *f, char delimiter, char quote, char comment,
+               int allow_embedded_newline);
+
+int count_fields(FILE *f, char delimiter, char quote, char comment,
+                 int allow_embedded_newline);
+
+
+void *read_rows(FILE *f, int *nrows, char *fmt,
+                char delimiter, char quote, char comment,
+                char sci, char decimal,
+                int allow_embedded_newline,
+                char *datetime_fmt,
+                int tz_offset,
+                int *usecols, int num_usecols,
+                int skiprows,
+                void *data_array,
+                int *p_error_type, int *p_error_lineno);
diff --git a/setup.py b/setup.py
index 5e9d07098..183441fcb 100755
--- a/setup.py
+++ b/setup.py
@@ -384,6 +384,15 @@ period_ext = Extension('pandas._period',
                                 'pandas/src/period.c'],
                        include_dirs=[np.get_include()])
 
+parser_ext = Extension('pandas._parser',
+                       depends=['pandas/src/parser/common.h'],
+                       sources=[srcpath('parser', suffix=suffix),
+                                'pandas/src/parser/rows.c',
+                                'pandas/src/parser/conversions.c',
+                                'pandas/src/parser/common.c',
+                                'pandas/src/parser/str_to.c',
+                                ],
+                       include_dirs=[np.get_include()])
 
 sparse_ext = Extension('pandas._sparse',
                        sources=[srcpath('sparse', suffix=suffix)],
@@ -398,7 +407,8 @@ cppsandbox_ext = Extension('pandas._cppsandbox',
                            sources=[srcpath('cppsandbox', suffix=suffix)],
                            include_dirs=[np.get_include()])
 
-extensions = [algos_ext, lib_ext, period_ext, sparse_ext]
+extensions = [algos_ext, lib_ext, period_ext, sparse_ext,
+              parser_ext]
 
 if not ISRELEASED:
     extensions.extend([sandbox_ext])
