commit 5cf2f121d96a01907763d201b40c0473b3cc79f5
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Aug 16 18:57:46 2011 -0400

    ENH: switch to Cython agg for sum/mean for 1 group.
    BUG: fix Cython code to handle NA labels

diff --git a/bench/better_unique.py b/bench/better_unique.py
new file mode 100644
index 000000000..57f647f13
--- /dev/null
+++ b/bench/better_unique.py
@@ -0,0 +1,69 @@
+from pandas import DataFrame
+import timeit
+
+setup = """
+from pandas import Series
+import pandas._tseries as _tseries
+import random
+import numpy as np
+
+def better_unique(values):
+    ids, labels = _tseries.group_labels2(values)
+
+    n = len(ids)
+    values = Series(ids, index=np.arange(n)).values
+    indexer = values.argsort()
+
+    reverse_indexer = np.empty(n, dtype=np.int32)
+    reverse_indexer.put(indexer, np.arange(n))
+
+    new_labels = reverse_indexer.take(labels)
+    new_values = values.take(indexer)
+
+    return new_values, new_labels
+
+tot = 100000
+
+def get_test_data(ngroups=100, n=tot):
+    unique_groups = range(ngroups)
+    random.shuffle(unique_groups)
+    arr = np.asarray(np.tile(unique_groups, n / ngroups), dtype=object)
+
+    if len(arr) < n:
+        arr = np.asarray(list(arr) + unique_groups[:n - len(arr)],
+                         dtype=object)
+
+    return arr
+
+arr = get_test_data(ngroups=%d)
+"""
+
+group_sizes = [10, 100, 1000, 10000,
+               20000, 30000, 40000,
+               50000, 60000, 70000,
+               80000, 90000, 100000]
+
+numbers = [100, 100, 50] + [10] * 10
+
+numpy = []
+wes = []
+
+for sz, n in zip(group_sizes, numbers):
+    wes_timer =  timeit.Timer(stmt='better_unique(arr)',
+                              setup=setup % sz)
+    numpy_timer =  timeit.Timer(stmt='np.unique(arr, return_inverse=True)',
+                                setup=setup % sz)
+
+    print n
+    numpy_result = numpy_timer.timeit(number=n) / n
+    wes_result = wes_timer.timeit(number=n) / n
+
+    print 'Groups: %d, NumPy: %s, Wes: %s' % (sz, numpy_result, wes_result)
+
+    wes.append(wes_result)
+    numpy.append(numpy_result)
+
+result = DataFrame({'wes' : wes, 'numpy' : numpy}, index=group_sizes)
+
+def make_plot(numpy, wes):
+    pass
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 651d3a4a1..113da4316 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -265,7 +265,7 @@ class DataFrame(NDFrame):
         Return a string representation for a particular DataFrame
         """
         buf = StringIO()
-        if len(self.index) < 500 and len(self.columns) < 10:
+        if len(self.index) < 500 and len(self.columns) <= 10:
             self.toString(buf=buf)
         else:
             self.info(buf=buf)
@@ -2136,11 +2136,7 @@ class DataFrame(NDFrame):
     def _count_level(self, level, axis=0, numeric_only=False):
         # TODO: deal with sortedness??
         obj = self.sortlevel(level, axis=axis)
-
         axis_index = obj._get_axis(axis)
-        if not isinstance(axis_index, MultiIndex):
-            raise TypeError('can only pass level with multi-level index')
-
         y, _ = self._get_agg_data(axis, numeric_only=numeric_only)
         mask = notnull(y)
 
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 758f17ea1..9b7f4b9d6 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1,3 +1,4 @@
+from itertools import izip
 import types
 
 import numpy as np
@@ -158,26 +159,26 @@ class GroupBy(object):
         """
         Compute mean of groups, excluding missing values
         """
-        if len(self.groupings) > 1:
+        try:
             return self._cython_aggregate('mean')
-        else:
+        except Exception:
             return self.aggregate(np.mean)
 
     def sum(self):
         """
         Compute sum of values, excluding missing values
         """
-        if len(self.groupings) > 1:
+        try:
             return self._cython_aggregate('add')
-        else:
+        except Exception:
             return self.aggregate(np.sum)
 
-    def _cython_aggregate(self, how):
+    def _cython_aggregate_dict(self, how):
         label_list = [ping.labels for ping in self.groupings]
         shape = self._result_shape
 
-        # TODO: address inefficiency
-        # TODO: get counts in cython
+        # TODO: address inefficiencies, like duplicating effort (should
+        # aggregate all the columns at once)
 
         output = {}
         cannot_agg = []
@@ -194,14 +195,12 @@ class GroupBy(object):
             mask = counts.ravel() > 0
             output[name] = result[mask]
 
-        name_list = self._get_names()
+        return output, mask
 
-        if len(self.groupings) > 1:
-            masked = [raveled[mask] for _, raveled in name_list]
-            index = MultiIndex.from_arrays(masked)
-            return DataFrame(output, index=index)
-        else:
-            return DataFrame(output, index=name_list[0][1])
+    def _get_multi_index(self, mask):
+        name_list = self._get_names()
+        masked = [raveled[mask] for _, raveled in name_list]
+        return MultiIndex.from_arrays(masked)
 
     def _aggregate_multi_group(self, arg):
         # want to cythonize?
@@ -327,9 +326,10 @@ class Grouping(object):
 
     def _make_labels(self):
         ids, labels, counts  = _tseries.group_labels(self.grouper)
-        self._labels = labels
-        self._ids = ids
-        self._counts = counts
+        sids, slabels, scounts = sort_group_labels(ids, labels, counts)
+        self._labels = slabels
+        self._ids = sids
+        self._counts = scounts
 
     _groups = None
     @property
@@ -338,18 +338,6 @@ class Grouping(object):
             self._groups = _tseries.groupby(self.index, self.grouper)
         return self._groups
 
-def labelize(*key_arrays):
-    idicts = []
-    shape = []
-    labels = []
-    for arr in key_arrays:
-        ids, lab, counts  = _tseries.group_labels(arr)
-        shape.append(len(ids))
-        labels.append(lab)
-        idicts.append(ids)
-
-    return tuple(shape), labels, idicts
-
 def _get_groupings(obj, grouper=None, axis=0, level=None):
     group_axis = obj._get_axis(axis)
 
@@ -379,11 +367,6 @@ def _get_groupings(obj, grouper=None, axis=0, level=None):
             grouper = obj[grouper]
         ping = Grouping(group_axis, grouper, name=name, level=level)
         groupings.append(ping)
-    # else:
-    #     labels = group_axis.labels[level]
-    #     grouper = np.asarray(group_axis.levels[level]).take(labels)
-    #     ping = Grouping(group_axis, grouper, name=name)
-    #     groupings.append(ping)
 
     return groupings, exclusions
 
@@ -457,6 +440,19 @@ class SeriesGroupBy(GroupBy):
 
         return ret
 
+    def _cython_aggregate(self, how):
+        output, mask = self._cython_aggregate_dict(how)
+
+        # sort of a kludge
+        output = output['result']
+
+        if len(self.groupings) > 1:
+            index = self._get_multi_index(mask)
+            return Series(output, index=index)
+        else:
+            name_list = self._get_names()
+            return Series(output, index=name_list[0][1])
+
     def _aggregate_multiple_funcs(self, arg):
         if not isinstance(arg, dict):
             arg = dict((func.__name__, func) for func in arg)
@@ -592,6 +588,16 @@ class DataFrameGroupBy(GroupBy):
 
         return result
 
+    def _cython_aggregate(self, how):
+        output, mask = self._cython_aggregate_dict(how)
+
+        if len(self.groupings) > 1:
+            index = self._get_multi_index(mask)
+            return DataFrame(output, index=index)
+        else:
+            name_list = self._get_names()
+            return DataFrame(output, index=name_list[0][1])
+
     def _aggregate_generic(self, agger, axis=0):
         result = {}
 
@@ -810,3 +816,23 @@ def _generate_groups(data, labels, shape, start, end, axis=0, which=0,
                                       which=which + 1, factory=factory)
 
         left = right
+
+#----------------------------------------------------------------------
+# sorting levels...cleverly?
+
+def sort_group_labels(ids, labels, counts):
+    n = len(ids)
+    rng = np.arange(n)
+    values = Series(ids, index=rng, dtype=object).values
+    indexer = values.argsort()
+
+    reverse_indexer = np.empty(n, dtype=np.int32)
+    reverse_indexer.put(indexer, np.arange(n))
+
+    new_labels = reverse_indexer.take(labels)
+    np.putmask(new_labels, labels == -1, -1)
+
+    new_ids = dict(izip(rng, values.take(indexer)))
+    new_counts = counts.take(indexer)
+
+    return new_ids, new_labels, new_counts
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index 2b0c90e1c..b791b1f11 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -133,6 +133,7 @@ def groupby_indices(ndarray values):
     return result
 
 
+@cython.wraparound(False)
 @cython.boundscheck(False)
 def group_labels(ndarray[object] values):
     '''
@@ -158,11 +159,13 @@ def group_labels(ndarray[object] values):
             labels[i] = -1
             continue
 
-        try:
+        # for large number of groups, not doing try: except: makes a big
+        # difference
+        if val in ids:
             idx = ids[val]
             labels[i] = idx
             counts[idx] = counts[idx] + 1
-        except KeyError:
+        else:
             ids[val] = count
             reverse[count] = val
             labels[i] = count
@@ -171,6 +174,43 @@ def group_labels(ndarray[object] values):
 
     return reverse, labels, counts[:count].copy()
 
+@cython.wraparound(False)
+@cython.boundscheck(False)
+def group_labels2(ndarray[object] values):
+    '''
+    Compute label vector from input values and associated useful data
+
+    Returns
+    -------
+    '''
+    cdef:
+        Py_ssize_t i, n = len(values)
+        ndarray[int32_t] labels = np.empty(n, dtype=np.int32)
+        dict ids = {}
+        dict reverse = {}
+        int32_t idx
+        object val
+        int32_t count = 0
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        # is NaN
+        if val != val:
+            labels[i] = -1
+            continue
+
+        if val in ids:
+            idx = ids[val]
+            labels[i] = idx
+        else:
+            ids[val] = count
+            reverse[count] = val
+            labels[i] = count
+            count += 1
+
+    return reverse, labels
+
 ctypedef double_t (* agg_func)(double_t *out, int32_t *counts, double_t *values,
                                int32_t *labels, int start, int end,
                                Py_ssize_t offset)
@@ -252,6 +292,13 @@ cdef double_t _group_add(double_t *out, int32_t *counts, double_t *values,
         double_t val, cum = 0
 
     while it < end:
+        i = labels[it]
+
+        # mapping was NaN
+        if i == -1:
+            it += 1
+            continue
+
         val = values[it]
         tot += 1
 
@@ -260,7 +307,6 @@ cdef double_t _group_add(double_t *out, int32_t *counts, double_t *values,
             count += 1
             cum += val
 
-        i = labels[it]
         if it == end - 1 or labels[it + 1] > i:
             if count == 0:
                 out[offset + i] = nan
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 74f1ff78a..7cf708542 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -903,6 +903,17 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assertEqual(len(dm.columns), 2)
         self.assert_(dm.values.dtype == np.float_)
 
+    def test_constructor_ragged(self):
+        data = {'A' : randn(10),
+                'B' : randn(8)}
+        self.assertRaises(Exception, DataFrame, data)
+
+    def test_constructor_scalar(self):
+        idx = Index(range(3))
+        df = DataFrame({"a" : 0}, index=idx)
+        expected = DataFrame({"a" : [0, 0, 0]}, index=idx)
+        assert_frame_equal(df, expected)
+
     def test_astype(self):
         casted = self.frame.astype(int)
         expected = DataFrame(self.frame.values.astype(int),
@@ -2673,10 +2684,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         df1[df1 > 2.0 * df2] = -1
         assert_frame_equal(df1, expected)
 
-    def test_groupby_nonsense_func(self):
-        df = DataFrame([0])
-        self.assertRaises(Exception, df.groupby, lambda x: donkey)
-
     def test_sum_bools(self):
         df = DataFrame(index=range(1), columns=range(10))
         bools = np.isnan(df)
@@ -2689,12 +2696,6 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         df = DataFrame(index=range(20), columns=cols, data=data)
         self.assert_(df.columns.tolist() == df.fillna().columns.tolist())
 
-    def test_scalar_ctor(self):
-        idx = Index(range(3))
-        df = DataFrame({"a" : 0}, index=idx)
-        expected = DataFrame({"a" : [0, 0, 0]}, index=idx)
-        assert_frame_equal(df, expected)
-
 
 if __name__ == '__main__':
     # unittest.main()
diff --git a/pandas/tests/test_groupby.py b/pandas/tests/test_groupby.py
index 5bd69b583..16ef85405 100644
--- a/pandas/tests/test_groupby.py
+++ b/pandas/tests/test_groupby.py
@@ -83,7 +83,10 @@ class TestGroupBy(unittest.TestCase):
 
         assert_series_equal(agged, grouped.agg(np.mean)) # shorthand
         assert_series_equal(agged, grouped.mean())
-        assert_series_equal(grouped.agg(np.sum), grouped.sum())
+
+        # Cython only returning floating point for now...
+        assert_series_equal(grouped.agg(np.sum).astype(float),
+                            grouped.sum())
 
         transformed = grouped.transform(lambda x: x * x.sum())
         self.assertEqual(transformed[7], 12)
@@ -273,18 +276,28 @@ class TestGroupBy(unittest.TestCase):
 
         grouped = df.groupby(['k1', 'k2'])
 
+        # things get sorted!
         iterated = list(grouped)
         idx = df.index
-        expected = [('b', '1', df.ix[idx[[0, 2]]]),
-                    ('b', '2', df.ix[idx[[1]]]),
-                    ('a', '1', df.ix[idx[[4]]]),
-                    ('a', '2', df.ix[idx[[3, 5]]])]
+        expected = [('a', '1', df.ix[idx[[4]]]),
+                    ('a', '2', df.ix[idx[[3, 5]]]),
+                    ('b', '1', df.ix[idx[[0, 2]]]),
+                    ('b', '2', df.ix[idx[[1]]])]
         for i, (one, two, three) in enumerate(iterated):
             e1, e2, e3 = expected[i]
             self.assert_(e1 == one)
             self.assert_(e2 == two)
             assert_frame_equal(three, e3)
 
+        # don't iterate through groups with no data
+        df['k1'] = np.array(['b', 'b', 'b', 'a', 'a', 'a'])
+        df['k2'] = np.array(['1', '1', '1', '2', '2', '2'])
+        grouped = df.groupby(['k1', 'k2'])
+        groups = {}
+        for a, b, gp in grouped:
+            groups[a, b] = gp
+        self.assertEquals(len(groups), 2)
+
     def test_multi_func(self):
         col1 = self.df['A']
         col2 = self.df['B']
@@ -326,9 +339,7 @@ class TestGroupBy(unittest.TestCase):
         result = data['C'].groupby([data['A'], data['B']]).mean()
         expected = data.groupby(['A', 'B']).mean()['C']
 
-        # choice of "result" is pretty arbitrary, should eventually return a
-        # hierarchical index
-        assert_series_equal(result['result'], expected)
+        assert_series_equal(result, expected)
 
     def test_groupby_multiple_key(self):
         df = tm.makeTimeDataFrame()
@@ -355,6 +366,28 @@ class TestGroupBy(unittest.TestCase):
         expected = self.df.ix[:, ['A', 'C', 'D']].groupby('A').mean()
         assert_frame_equal(result, expected)
 
+    def test_nonsense_func(self):
+        df = DataFrame([0])
+        self.assertRaises(Exception, df.groupby, lambda x: x + 'foo')
+
+    def test_sum(self):
+        data = {'A' : [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
+                'B' : ['A', 'B'] * 6,
+                'C' : np.random.randn(12)}
+        df = DataFrame(data)
+        df['C'][2:10:2] = nan
+
+        # single column
+        grouped = df.drop(['B'], axis=1).groupby('A')
+        exp = {}
+        for cat, group in grouped:
+            exp[cat] = group['C'].sum()
+        exp = DataFrame({'C' : exp})
+        result = grouped.sum()
+        assert_frame_equal(result, exp)
+
+        # multiple columns
+
 class TestPanelGroupBy(unittest.TestCase):
 
     def setUp(self):
diff --git a/pandas/tests/test_multilevel.py b/pandas/tests/test_multilevel.py
index d08745c5b..5d6836ac7 100644
--- a/pandas/tests/test_multilevel.py
+++ b/pandas/tests/test_multilevel.py
@@ -173,6 +173,12 @@ class TestDataFrameMultiLevel(unittest.TestCase):
 
         _check_counts(self.frame)
         _check_counts(self.ymd)
+        _check_counts(self.frame.T, axis=1)
+        _check_counts(self.ymd.T, axis=1)
+
+        # can't call with level on regular DataFrame
+        df = tm.makeTimeDataFrame()
+        self.assertRaises(Exception, df.count, level=0)
 
     def test_alignment(self):
         pass
diff --git a/scripts/groupby_test.py b/scripts/groupby_test.py
index 15b00f5a9..0dfd7d4a1 100644
--- a/scripts/groupby_test.py
+++ b/scripts/groupby_test.py
@@ -1,5 +1,6 @@
 from collections import defaultdict
 
+from numpy import nan
 import numpy as np
 
 from pandas import *
@@ -8,6 +9,8 @@ import pandas._tseries as tseries
 import pandas.core.groupby as gp
 reload(gp)
 
+"""
+
 k = 1000
 values = np.random.randn(8 * k)
 key1 = np.array(['foo', 'bar', 'baz', 'bar', 'foo', 'baz', 'bar', 'baz'] * k,
@@ -54,3 +57,19 @@ for a, gen1 in gen:
 res = DataFrame(res)
 
 grouped = df.groupby(['key1', 'key2'])
+"""
+
+data = {'A' : [0, 0, 0, 0, 1, 1, 1, 1, 1, 1., nan, nan],
+        'B' : ['A', 'B'] * 6,
+        'C' : np.random.randn(12)}
+df = DataFrame(data)
+df['C'][2:10:2] = nan
+
+# single column
+grouped = df.drop(['B'], axis=1).groupby('A')
+exp = {}
+for cat, group in grouped:
+    exp[cat] = group['C'].sum()
+exp = DataFrame({'C' : exp})
+result = grouped.sum()
+
