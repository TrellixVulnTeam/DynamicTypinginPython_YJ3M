commit 4cbfdc25bd4d71c4debc02aaa6425d37ccdfba94
Author: Phillip Cloud <cpcloud@gmail.com>
Date:   Wed Jul 24 20:56:53 2013 -0400

    ENH: add subscripting to eval expressions

diff --git a/doc/source/indexing.rst b/doc/source/indexing.rst
index 47bf5fe29..9f68934f6 100644
--- a/doc/source/indexing.rst
+++ b/doc/source/indexing.rst
@@ -1008,14 +1008,121 @@ convert to an integer index:
 
 .. _indexing.query:
 
-The ``query`` Method
-~~~~~~~~~~~~~~~~~~~~
-New in pandas v0.13, :class:`~pandas.core.frame.DataFrame` objects have a
-:meth:`~pandas.core.frame.DataFrame.query` method that allows selection using a
-string consisting of columns of the calling
-:class:`~pandas.core.frame.DataFrame`.
+.. versionadded:: 0.13
+
+The :meth:`~pandas.DataFrame.query` Method
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+:class:`~pandas.DataFrame` objects have a :meth:`~pandas.DataFrame.query`
+method that allows selection using a string consisting of columns of the
+calling :class:`~pandas.DataFrame`.
+
+You can get the value of the frame where column ``b`` has values
+between the values of columns ``a`` and ``c``.
+
+.. ipython:: python
+   :suppress:
+
+   from numpy.random import randint, rand
+
+.. ipython:: python
+
+   n = 20
+   df = DataFrame(rand(n, 3), columns=list('abc'))
+   df
+   df[(df.a < df.b) & (df.b < df.c)]
+   df.query('(a < b) & (b < c)')
+
+Do the same thing but fallback on a named index if there is no column
+with the name ``a``.
+
+.. ipython:: python
+
+   index = Index(np.arange(n), name='a')
+   df = DataFrame(randint(n, size=(n, 2)), index=index, columns=list('bc'))
+   df
+   df.query('a < b and b < c')
+
+A use case for :meth:`~pandas.DataFrame.query` is when you have a collection of
+:class:`~pandas.DataFrame` s that have a subset of column names (or index
+names) in common. You can pass the same query to both frames *without* having
+to specify which frame you're interested in querying
+
+.. ipython:: python
+
+   df2 = DataFrame(randint(n + 10, size=(n + 10, 3)), columns=list('abc'))
+   df2
+   expr = 'a < b & b < c'
+   map(lambda frame: frame.query(expr), [df, df2])
+
+A chained comparison would also work in this situation, yielding slightly
+cleaner syntax
+
+.. ipython:: python
+
+   expr = 'a < b < c'
+   map(lambda frame: frame.query(expr), [df, df2])
+
+One neat feature of :meth:`~pandas.DataFrame.query` is that you can pass an
+expression ``expr`` into ``df[]``, e.g., ``df[expr]``.
+
+This functionality can of course be combined with a slightly modified and more
+readable Python syntax implemented in the workhorse function that underlies
+:meth:`~pandas.DataFrame.query`--:func:`~pandas.eval`.
+
+Full numpy-like syntax
+
+.. ipython:: python
+
+   df['(a < b) & (b < c)']
+
+Slightly nicer by removing the parentheses
+
+.. ipython:: python
+
+   df['a < b & b < c']
+
+Use English instead of symbols
+
+.. ipython:: python
+
+   df['a < b and b < c']
+
+Pretty close to how you might write it on paper
+
+.. ipython:: python
+
+   df['a < b < c']
+
+As you can see, these are all equivalent ways to express the same operation (in
+fact, they are all ultimately parsed into something very similar to the first
+example of the indexing syntax above).
+
+You can also negate boolean expressions with the word ``not`` or the ``~``
+operator.
+
+.. ipython:: python
+
+   df = DataFrame(rand(n, 3), columns=list('abc'))
+   df['bools'] = rand(len(df)) > 0.5
+   df['~bools']
+   df['not bools']
+   df['not bools'] == df['~bools']
+   df['not bools'] == df[~df.bools]
+
+Of course, expressions can be arbitrarily complex too
+
+.. ipython:: python
+
+   # nice short query syntax
+   pretty = df['a < b < c and (not bools) or bools > 2']
+
+   # equivalent in pure Python, yuck!
+   yuck = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
 
+   pretty
+   yuck
 
+   yuck == pretty
 
 .. _indexing.class:
 
diff --git a/pandas/computation/align.py b/pandas/computation/align.py
index fcc1dd1b0..5f81fcd60 100644
--- a/pandas/computation/align.py
+++ b/pandas/computation/align.py
@@ -42,13 +42,12 @@ def _maybe_promote_shape(values, naxes):
     if ndims == naxes:
         return values
 
-    ndim = set(xrange(ndims))
-    nax = set(xrange(naxes))
+    ndim, nax = range(ndims), range(naxes)
 
     axes_slice = [slice(None)] * naxes
 
-    # symmetric difference of numaxes and ndims
-    slices = nax - ndim
+    # set difference of numaxes and ndims
+    slices = com.difference(nax, ndim)
 
     if ndims == naxes:
         if slices:
@@ -78,7 +77,7 @@ def _filter_special_cases(f):
             return _align_core_single_unary_op(terms[0])
 
         term_values = (term.value for term in terms)
-        # only scalars
+        # only scalars or indexes
         if all(isinstance(term.value, pd.Index) or term.isscalar for term in
                terms):
             return np.result_type(*term_values), None
@@ -88,7 +87,7 @@ def _filter_special_cases(f):
         if all_has_size and all(term.value.size == 1 for term in terms):
             return np.result_type(*term_values), None
 
-        # no pandas so just punt to the evaluator
+        # no pandas objects
         if not _any_pandas_objects(terms):
             return np.result_type(*term_values), None
 
@@ -101,7 +100,7 @@ def _align_core(terms):
     term_index = [i for i, term in enumerate(terms) if hasattr(term.value,
                                                                'axes')]
     term_dims = [terms[i].value.ndim for i in term_index]
-    ndims = pd.Series(dict(zip(term_index, term_dims)))
+    ndims = pd.Series(dict(izip(term_index, term_dims)))
 
     # initial axes are the axes of the largest-axis'd term
     biggest = terms[ndims.idxmax()].value
@@ -115,7 +114,8 @@ def _align_core(terms):
                 ax, itm = naxes - 1, term.value.index
             else:
                 ax, itm = axis, items
-            axes[ax] = axes[ax].join(itm, how='outer')
+            if not axes[ax].equals(itm):
+                axes[ax] = axes[ax].join(itm, how='outer')
 
     for i, ndim in ndims.iteritems():
         for axis, items in izip(xrange(ndim), axes):
@@ -163,10 +163,10 @@ def _align_core(terms):
 
 def _filter_terms(flat):
     # numeric literals
-    literals = set(filter(is_const, flat))
+    literals = frozenset(filter(is_const, flat))
 
     # these are strings which are variable names
-    names = set(flat) - literals
+    names = frozenset(flat) - literals
 
     # literals are not names and names are not literals, so intersection should
     # be empty
diff --git a/pandas/computation/engines.py b/pandas/computation/engines.py
index d4f23324b..cd161352b 100644
--- a/pandas/computation/engines.py
+++ b/pandas/computation/engines.py
@@ -1,10 +1,11 @@
 import abc
 
+from pandas.core import common as com
 from pandas.computation.align import _align, _reconstruct_object
 
 
 class AbstractEngine(object):
-    """"""
+    """AbstractEngine object serving as a base class for all engines."""
     __metaclass__ = abc.ABCMeta
 
     has_neg_frac = False
@@ -14,12 +15,24 @@ class AbstractEngine(object):
         self.aligned_axes = None
         self.result_type = None
 
-    @abc.abstractmethod
     def convert(self):
-        """Convert an expression for evaluation."""
-        pass
+        """Convert an expression for evaluation.
+
+        Defaults to return the expression as a string.
+        """
+        return com.pprint_thing(self.expr)
 
     def evaluate(self):
+        """Run the engine on the expression
+
+        This method performs alignment which is necessary no matter what engine
+        is being used, thus its implementation is in the base class.
+
+        Returns
+        -------
+        obj : object
+            The result of the passed expression.
+        """
         if not self._is_aligned:
             self.result_type, self.aligned_axes = _align(self.expr.terms)
 
@@ -33,7 +46,18 @@ class AbstractEngine(object):
 
     @abc.abstractmethod
     def _evaluate(self, env):
-        """Return an evaluated expression."""
+        """Return an evaluated expression.
+
+        Parameters
+        ----------
+        env : Scope
+            The local and global environment in which to evaluate an
+            expression.
+
+        Notes
+        -----
+        This method must be implemented by any class the subclasses this class.
+        """
         pass
 
 
@@ -44,15 +68,12 @@ class NumExprEngine(AbstractEngine):
     def __init__(self, expr):
         super(NumExprEngine, self).__init__(expr)
 
-    def convert(self):
-        """Return a string"""
-        return '%s' % self.expr
-
     def _evaluate(self, env):
         import numexpr as ne
 
         try:
-            return ne.evaluate(self.convert(), local_dict=env.locals,
+            s = self.convert()
+            return ne.evaluate(s, local_dict=env.locals,
                                global_dict=env.globals,
                                truediv=self.expr.truediv)
         except KeyError as e:
@@ -60,15 +81,15 @@ class NumExprEngine(AbstractEngine):
 
 
 class PythonEngine(AbstractEngine):
-    """Use NumPy even if numexpr is installed"""
+    """Evaluate an expression in Python space.
+
+    Mostly for testing purposes.
+    """
     has_neg_frac = False
 
     def __init__(self, expr):
         super(PythonEngine, self).__init__(expr)
 
-    def convert(self):
-        pass
-
     def evaluate(self):
         return self.expr(self.expr.env)
 
diff --git a/pandas/computation/eval.py b/pandas/computation/eval.py
index abd4785cb..072bd3feb 100644
--- a/pandas/computation/eval.py
+++ b/pandas/computation/eval.py
@@ -27,6 +27,7 @@ def _check_parser(parser):
         raise KeyError('Invalid parser {0!r} passed, valid parsers are'
                        ' {1}'.format(parser, _parsers.keys()))
 
+
 def eval(expr, parser='pandas', engine='numexpr', truediv=True,
          local_dict=None, global_dict=None, resolvers=None):
     """Evaluate a Python expression as a string using various backends.
diff --git a/pandas/computation/expr.py b/pandas/computation/expr.py
index abcf8cc38..f968a6d3f 100644
--- a/pandas/computation/expr.py
+++ b/pandas/computation/expr.py
@@ -4,18 +4,18 @@ import sys
 import inspect
 import itertools
 import tokenize
+import datetime
+
 from cStringIO import StringIO
 from functools import partial
 
+import pandas as pd
 from pandas.core.base import StringMixin
 from pandas.core import common as com
-from pandas.computation.ops import (BinOp, UnaryOp, _reductions, _mathops,
-                                    _cmp_ops_syms, _bool_ops_syms,
-                                    _arith_ops_syms, _unary_ops_syms, Term,
-                                    Constant)
-
-import pandas.lib as lib
-import datetime
+from pandas.computation.ops import (_cmp_ops_syms, _bool_ops_syms,
+                                    _arith_ops_syms, _unary_ops_syms)
+from pandas.computation.ops import _reductions, _mathops
+from pandas.computation.ops import BinOp, UnaryOp, Term, Constant
 
 
 def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
@@ -25,49 +25,71 @@ def _ensure_scope(level=2, global_dict=None, local_dict=None, resolvers=None,
 
 
 class Scope(StringMixin):
+    """Object to hold scope, with a few bells to deal with some custom syntax
+    added by pandas.
+
+    Parameters
+    ----------
+    gbls : dict or None, optional, default None
+    lcls : dict or Scope or None, optional, default None
+    level : int, optional, default 1
+    resolvers : list-like or None, optional, default None
+
+    Attributes
+    ----------
+    globals : dict
+    locals : dict
+    level : int
+    resolvers : tuple
+    resolver_keys : frozenset
+    """
     __slots__ = ('globals', 'locals', 'resolvers', '_global_resolvers',
                  'resolver_keys', '_resolver', 'level')
 
     def __init__(self, gbls=None, lcls=None, level=1, resolvers=None):
         self.level = level
-        self.resolvers = resolvers or []
+        self.resolvers = tuple(resolvers or [])
         self.globals = dict()
         self.locals = dict()
+        self.ntemps = 0  # number of temporary variables in this scope
 
         if isinstance(lcls, Scope):
             ld, lcls = lcls, dict()
-            self.locals.update(ld.locals)
-            self.globals.update(ld.globals)
-            self.resolvers.extend(ld.resolvers)
+            self.locals.update(ld.locals.copy())
+            self.globals.update(ld.globals.copy())
+            self.resolvers += ld.resolvers
             self.update(ld.level)
 
         frame = sys._getframe(level)
         try:
-            self.globals.update(gbls or frame.f_globals.copy())
-            self.locals.update(lcls or frame.f_locals.copy())
+            self.globals.update(gbls or frame.f_globals)
+            self.locals.update(lcls or frame.f_locals)
         finally:
             del frame
 
         # add some useful defaults
-        self.globals['Timestamp'] = lib.Timestamp
+        self.globals['Timestamp'] = pd.lib.Timestamp
         self.globals['datetime'] = datetime
 
         # SUCH a hack
         self.globals['True'] = True
         self.globals['False'] = False
 
-        self.resolver_keys = set(reduce(operator.add, (list(o.keys()) for o in
-                                                       self.resolvers), []))
-        self._global_resolvers = self.resolvers + [self.locals, self.globals]
+        self.resolver_keys = frozenset(reduce(operator.add, (list(o.keys()) for
+                                                             o in
+                                                             self.resolvers),
+                                              []))
+        self._global_resolvers = self.resolvers + (self.locals, self.globals)
         self._resolver = None
 
     def __unicode__(self):
-        return "locals: {0}\nglobals: {0}\nresolvers: {0}".format(self.locals.keys(),
-                                                                  self.globals.keys(),
-                                                                  self.resolver_keys)
+        return com.pprint_thing("locals: {0}\nglobals: {0}\nresolvers: "
+                                "{0}".format(self.locals.keys(),
+                                             self.globals.keys(),
+                                             self.resolver_keys))
 
     def __getitem__(self, key):
-        return self.locals.get(key,self.globals[key])
+        return self.resolver(key)
 
     @property
     def resolver(self):
@@ -83,9 +105,14 @@ class Scope(StringMixin):
         return self._resolver
 
     def update(self, level=None):
+        """Update the current scope by going back `level` levels.
 
+        Parameters
+        ----------
+        level : int or None, optional, default None
+        """
         # we are always 2 levels below the caller
-        # plus the caller maybe below the env level
+        # plus the caller may be below the env level
         # in which case we need addtl levels
         sl = 2
         if level is not None:
@@ -105,8 +132,38 @@ class Scope(StringMixin):
                 self.locals.update(f.f_locals)
                 self.globals.update(f.f_globals)
         finally:
-            del frame
-            del frames
+            del frame, frames
+
+    def add_tmp(self, value, where='locals'):
+        """Add a temporary variable to the scope.
+
+        Parameters
+        ----------
+        value : object
+            An arbitrary object to be assigned to a temporary variable.
+        where : basestring, optional, default 'locals', {'locals', 'globals'}
+            What scope to add the value to.
+
+        Returns
+        -------
+        name : basestring
+            The name of the temporary variable created.
+        """
+        d = getattr(self, where, None)
+
+        if d is None:
+            raise AttributeError("Cannot add value to non-existent scope "
+                                 "{0!r}".format(where))
+        if not isinstance(d, dict):
+            raise TypeError("Cannot add value to object of type {0!r}, "
+                            "scope must be a dictionary"
+                            "".format(d.__class__.__name__))
+        name = 'tmp_var_{0}_{1}'.format(self.ntemps, pd.util.testing.rands(10))
+        d[name] = value
+
+        # only increment if the variable gets put in the scope
+        self.ntemps += 1
+        return name
 
 
 def _rewrite_assign(source):
@@ -117,21 +174,12 @@ def _rewrite_assign(source):
     return tokenize.untokenize(res)
 
 
-def _parenthesize_booleans(source, ops='|&'):
-    res = source
-    for op in ops:
-        terms = res.split(op)
-
-        t = []
-        for term in terms:
-            t.append('({0})'.format(term))
-
-        res = op.join(t)
-    return res
+def _replace_booleans(source):
+    return source.replace('|', ' or ').replace('&', ' and ')
 
 
 def _preparse(source):
-    return _parenthesize_booleans(_rewrite_assign(source))
+    return _replace_booleans(_rewrite_assign(source))
 
 
 
@@ -168,16 +216,15 @@ _alias_nodes = _filter_nodes(ast.alias)
 _hacked_nodes = frozenset(['Assign', 'Module', 'Expr'])
 
 
+_unsupported_expr_nodes = frozenset(['Yield', 'GeneratorExp', 'IfExp',
+                                     'DictComp', 'SetComp', 'Repr', 'Lambda',
+                                     'Set', 'In', 'NotIn', 'AST', 'Is',
+                                     'IsNot'])
+
 # these nodes are low priority or won't ever be supported (e.g., AST)
 _unsupported_nodes = ((_stmt_nodes | _mod_nodes | _handler_nodes |
                        _arguments_nodes | _keyword_nodes | _alias_nodes |
-                       _expr_context_nodes | frozenset(['Yield',
-                                                        'GeneratorExp',
-                                                        'IfExp', 'DictComp',
-                                                        'SetComp', 'Repr',
-                                                        'Lambda', 'Set', 'In',
-                                                        'NotIn', 'AST', 'Is',
-                                                        'IsNot'])) -
+                       _expr_context_nodes | _unsupported_expr_nodes) -
                       _hacked_nodes)
 
 # we're adding a different assignment in some cases to be equality comparison
@@ -249,7 +296,7 @@ class BaseExprVisitor(ast.NodeVisitor):
         self.preparser = preparser
 
     def visit(self, node, **kwargs):
-        parse = lambda x: ast.fix_missing_locations(ast.parse(x))
+        parse = ast.parse
         if isinstance(node, basestring):
             clean = self.preparser(node)
         elif isinstance(node, ast.AST):
@@ -301,15 +348,23 @@ class BaseExprVisitor(ast.NodeVisitor):
         return self.visit(node.value)
 
     def visit_Subscript(self, node, **kwargs):
-        """ df.index[4:6] """
         value = self.visit(node.value)
         slobj = self.visit(node.slice)
-
+        expr = com.pprint_thing(slobj)
+        result = pd.eval(expr, local_dict=self.env.locals,
+                         global_dict=self.env.globals,
+                         resolvers=self.env.resolvers)
         try:
-            return Constant(value[slobj], self.env)
-        except TypeError:
-            raise ValueError("cannot subscript [{0}] with "
-                             "[{1}]".format(value, slobj))
+            # a Term instance
+            v = value.value[result]
+        except AttributeError:
+            # an Op instance
+            lhs = pd.eval(com.pprint_thing(value), local_dict=self.env.locals,
+                          global_dict=self.env.globals,
+                          resolvers=self.env.resolvers)
+            v = lhs[result]
+        name = self.env.add_tmp(v)
+        return Term(name, env=self.env)
 
     def visit_Slice(self, node, **kwargs):
         """ df.index[slice(4,6)] """
@@ -334,14 +389,15 @@ class BaseExprVisitor(ast.NodeVisitor):
         attr = node.attr
         value = node.value
 
-        ctx = node.ctx.__class__
-        if ctx == ast.Load:
+        ctx = node.ctx
+        if isinstance(ctx, ast.Load):
             # resolve the value
             resolved = self.visit(value).value
             try:
-                return getattr(resolved, attr)
-            except (AttributeError):
-
+                v = getattr(resolved, attr)
+                name = self.env.add_tmp(v)
+                return Term(name, self.env)
+            except AttributeError:
                 # something like datetime.datetime where scope is overriden
                 if isinstance(value, ast.Name) and value.id == attr:
                     return resolved
@@ -412,20 +468,22 @@ class BaseExprVisitor(ast.NodeVisitor):
         return reduce(visitor, operands)
 
 
-_python_not_supported = frozenset(['Assign', 'Str', 'Slice', 'Index',
-                                   'Subscript', 'Tuple', 'List', 'Dict',
-                                   'Call'])
+_python_not_supported = frozenset(['Assign', 'Str', 'Tuple', 'List', 'Dict',
+                                   'Call', 'BoolOp'])
 _numexpr_supported_calls = frozenset(_reductions + _mathops)
 
-@disallow((_unsupported_nodes | _python_not_supported) - _boolop_nodes)
+
+@disallow((_unsupported_nodes | _python_not_supported) -
+          (_boolop_nodes | frozenset(['BoolOp', 'Attribute'])))
 class PandasExprVisitor(BaseExprVisitor):
-    def __init__(self, env, preparser=_preparse):
+    def __init__(self, env, preparser=_replace_booleans):
         super(PandasExprVisitor, self).__init__(env, preparser)
 
 
-@disallow(_unsupported_nodes | _python_not_supported)
+@disallow(_unsupported_nodes | _python_not_supported | frozenset(['Not']))
 class PythonExprVisitor(BaseExprVisitor):
-    pass
+    def __init__(self, env, preparser=lambda x: x):
+        super(PythonExprVisitor, self).__init__(env, preparser=preparser)
 
 
 class Expr(StringMixin):
@@ -471,8 +529,8 @@ def maybe_expression(s, kind='pandas'):
     ops = visitor.binary_ops + visitor.unary_ops
     filtered = frozenset(ops) - _needs_filter
     # make sure we have an op at least
-    return any(op in s or ' and ' in s or ' or ' in s or ' not ' in s
-               for op in filtered)
+    return any(op in s or ' and ' in s or ' or ' in s or 'not ' in s for op in
+               filtered)
 
 
 def isexpr(s, check_names=True):
diff --git a/pandas/computation/ops.py b/pandas/computation/ops.py
index 9a1a96cec..d1c8484cb 100644
--- a/pandas/computation/ops.py
+++ b/pandas/computation/ops.py
@@ -93,6 +93,12 @@ class Term(StringMixin):
 
     return_type = type
 
+    @property
+    def raw(self):
+        return com.pprint_thing('{0}(name={1!r}, type={2})'
+                                ''.format(self.__class__.__name__, self.name,
+                                          self.type))
+
 
 class Constant(Term):
     def __init__(self, value, env):
@@ -103,7 +109,7 @@ class Constant(Term):
 
 
 def _print_operand(opr):
-    return opr.name if is_term(opr) else unicode(opr)
+    return opr.name if is_term(opr) else com.pprint_thing(opr)
 
 
 def _get_op(op):
@@ -135,6 +141,12 @@ class Op(StringMixin):
             return np.bool_
         return np.result_type(*(term.type for term in com.flatten(self)))
 
+    @property
+    def raw(self):
+        parened = ('{0}({1!r}, {2})'.format(self.__class__.__name__, self.op,
+                                            ', '.join('{0}'.format(opr.raw) for
+                                                      opr in self.operands)))
+        return parened
 
 _cmp_ops_syms = '>', '<', '>=', '<=', '==', '!='
 _cmp_ops_funcs = op.gt, op.lt, op.ge, op.le, op.eq, op.ne
@@ -279,4 +291,3 @@ class UnaryOp(Op):
 
     def __unicode__(self):
         return com.pprint_thing('{0}({1})'.format(self.op, self.operand))
-
diff --git a/pandas/computation/pytables.py b/pandas/computation/pytables.py
index 2819a63f3..7a4ab6e1b 100644
--- a/pandas/computation/pytables.py
+++ b/pandas/computation/pytables.py
@@ -365,6 +365,33 @@ class ExprVisitor(BaseExprVisitor):
     def visit_Index(self, node, **kwargs):
         return self.visit(node.value).value
 
+    def visit_Subscript(self, node, **kwargs):
+        value = self.visit(node.value)
+        slobj = self.visit(node.slice)
+        try:
+            return Constant(value[slobj], self.env)
+        except TypeError:
+            raise ValueError("cannot subscript {0!r} with "
+                            "{1!r}".format(value, slobj))
+
+    def visit_Attribute(self, node, **kwargs):
+        attr = node.attr
+        value = node.value
+
+        ctx = node.ctx.__class__
+        if ctx == ast.Load:
+            # resolve the value
+            resolved = self.visit(value).value
+            try:
+                return getattr(resolved, attr)
+            except AttributeError:
+
+                # something like datetime.datetime where scope is overriden
+                if isinstance(value, ast.Name) and value.id == attr:
+                    return resolved
+
+        raise ValueError("Invalid Attribute context {0}".format(ctx.__name__))
+
 
 class Expr(expr.Expr):
 
diff --git a/pandas/computation/tests/test_eval.py b/pandas/computation/tests/test_eval.py
index 7a2704a32..1881b4716 100755
--- a/pandas/computation/tests/test_eval.py
+++ b/pandas/computation/tests/test_eval.py
@@ -7,8 +7,7 @@ from itertools import product
 import ast
 
 import nose
-from nose.tools import assert_raises, assert_tuple_equal
-from nose.tools import assert_true, assert_false, assert_equal
+from nose.tools import assert_raises, assert_true, assert_false, assert_equal
 
 from numpy.random import randn, rand
 import numpy as np
@@ -29,7 +28,7 @@ from pandas.computation import pytables
 from pandas.computation.expressions import _USE_NUMEXPR
 from pandas.util.testing import (assert_frame_equal, randbool,
                                  assertRaisesRegexp,
-                                 assert_produces_warning)
+                                 assert_produces_warning, assert_series_equal)
 from pandas.util.py3compat import PY3
 
 
@@ -77,8 +76,7 @@ def skip_incompatible_operand(f):
     return wrapper
 
 
-_good_arith_ops = tuple(set(_arith_ops_syms) -
-                        set(_special_case_arith_ops_syms))
+_good_arith_ops = com.difference(_arith_ops_syms, _special_case_arith_ops_syms)
 
 class TestEvalPandas(unittest.TestCase):
 
@@ -160,6 +158,7 @@ class TestEvalPandas(unittest.TestCase):
         for lhs, rhs in product(self.lhses, self.rhses):
             self.check_floor_division(lhs, '//', rhs)
 
+    @slow
     def test_pow(self):
         for lhs, rhs in product(self.lhses, self.rhses):
             self.check_pow(lhs, '**', rhs)
@@ -391,11 +390,11 @@ class TestAlignment(unittest.TestCase):
 
     @classmethod
     def setUpClass(cls):
-        cls.INDEX_TYPES = 'i', 'f', 's', 'u', 'dt', # 'p'
+        cls.index_types = 'i', 'f', 's', 'u', 'dt', # 'p'
 
     @classmethod
     def tearDownClass(cls):
-        del cls.INDEX_TYPES
+        del cls.index_types
 
     def check_align_nested_unary_op(self, engine):
         skip_numexpr_engine(engine)
@@ -408,15 +407,35 @@ class TestAlignment(unittest.TestCase):
         for engine in _engines:
             self.check_align_nested_unary_op(engine)
 
-    def check_basic_frame_alignment(self, engine):
-        df = mkdf(10, 10, data_gen_f=f)
-        df2 = mkdf(20, 10, data_gen_f=f)
+    def check_basic_frame_alignment(self, engine, r_idx_type, c_idx_type):
+        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                  c_idx_type=c_idx_type)
+        df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                   c_idx_type=c_idx_type)
         res = pd.eval('df + df2', engine=engine)
         assert_frame_equal(res, df + df2)
 
+    @slow
     def test_basic_frame_alignment(self):
-        for engine in _engines:
-            self.check_basic_frame_alignment(engine)
+        args = product(_engines, self.index_types, self.index_types)
+        for engine, r, c in args:
+            self.check_basic_frame_alignment(engine, r, c)
+
+    def check_frame_comparison(self, engine, r_idx_type, c_idx_type):
+        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r_idx_type,
+                  c_idx_type=c_idx_type)
+        res = pd.eval('df < 2', engine=engine)
+        assert_frame_equal(res, df < 2)
+
+        df3 = DataFrame(randn(*df.shape), index=df.index, columns=df.columns)
+        res = pd.eval('df < df3', engine=engine)
+        assert_frame_equal(res, df < df3)
+
+    @slow
+    def test_frame_comparison(self):
+        args = product(_engines, self.index_types, self.index_types)
+        for engine, r, c in args:
+            self.check_frame_comparison(engine, r, c)
 
     def check_medium_complex_frame_alignment(self, engine, r1, r2, c1, c2):
         skip_numexpr_engine(engine)
@@ -428,7 +447,7 @@ class TestAlignment(unittest.TestCase):
 
     @slow
     def test_medium_complex_frame_alignment(self):
-        args = product(_engines, *([self.INDEX_TYPES[:4]] * 4))
+        args = product(_engines, *([self.index_types] * 4))
         for engine, r1, r2, c1, c2 in args:
             self.check_medium_complex_frame_alignment(engine, r1, r2, c1, c2)
 
@@ -455,7 +474,7 @@ class TestAlignment(unittest.TestCase):
 
     @slow
     def test_basic_frame_series_alignment(self):
-        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES,
+        args = product(_engines, self.index_types, self.index_types,
                        ('index', 'columns'))
         for engine, r_idx_type, c_idx_type, index_name in args:
             self.check_basic_frame_series_alignment(engine, r_idx_type,
@@ -484,7 +503,7 @@ class TestAlignment(unittest.TestCase):
 
     @slow
     def test_basic_series_frame_alignment(self):
-        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES,
+        args = product(_engines, self.index_types, self.index_types,
                        ('index', 'columns'))
         for engine, r_idx_type, c_idx_type, index_name in args:
             self.check_basic_series_frame_alignment(engine, r_idx_type,
@@ -509,7 +528,7 @@ class TestAlignment(unittest.TestCase):
 
     @slow
     def test_series_frame_commutativity(self):
-        args = product(_engines, self.INDEX_TYPES, self.INDEX_TYPES, ('+',
+        args = product(_engines, self.index_types, self.index_types, ('+',
                                                                       '*'),
                        ('index', 'columns'))
         for engine, r_idx_type, c_idx_type, op, index_name in args:
@@ -519,27 +538,41 @@ class TestAlignment(unittest.TestCase):
     def check_complex_series_frame_alignment(self, engine, index_name, obj, r1,
                                              r2, c1, c2):
         skip_numexpr_engine(engine)
-        df = mkdf(10, 10, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
-        df2 = mkdf(20, 10, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
+        df = mkdf(10, 5, data_gen_f=f, r_idx_type=r1, c_idx_type=c1)
+        df2 = mkdf(20, 5, data_gen_f=f, r_idx_type=r2, c_idx_type=c2)
         index = getattr(locals()[obj], index_name)
         s = Series(np.random.randn(5), index[:5])
-        if engine != 'python':
-            expected = df2.add(s, axis=1).add(df)
+
+        if r2 == 'dt' or c2 == 'dt':
+            if engine == 'numexpr':
+                expected2 = df2.add(s)
+            else:
+                expected2 = df2 + s
         else:
-            expected = df2 + s + df
+            expected2 = df2 + s
+
+        if r1 == 'dt' or c1 == 'dt':
+            if engine == 'numexpr':
+                expected = expected2.add(df)
+            else:
+                expected = expected2 + df
+        else:
+            expected = expected2 + df
+
         res = pd.eval('df2 + s + df', engine=engine)
-        expected = df2 + s + df
-        assert_tuple_equal(res.shape, expected.shape)
+        self.assertEqual(res.shape, expected.shape)
         assert_frame_equal(res, expected)
 
     @slow
     def test_complex_series_frame_alignment(self):
+        index_types = [self.index_types] * 4
         args = product(_engines, ('index', 'columns'), ('df', 'df2'),
-                    *([self.INDEX_TYPES[:4]] * 4))
+                       *index_types)
         for engine, index_name, obj, r1, r2, c1, c2 in args:
             self.check_complex_series_frame_alignment(engine, index_name, obj,
                                                       r1, r2, c1, c2)
 
+    @slow
     def test_performance_warning_for_asenine_alignment(self):
         df = DataFrame(randn(1000, 10))
         s = Series(randn(10000))
@@ -555,6 +588,7 @@ class TestAlignment(unittest.TestCase):
         with assert_produces_warning(False):
             pd.eval('df + s')
 
+
 class TestOperations(unittest.TestCase):
 
     def check_simple_arith_ops(self, engine):
@@ -659,6 +693,131 @@ class TestOperations(unittest.TestCase):
             res = pd.eval(ex, truediv=True)
             assert_array_equal(res, np.array([1.0]))
 
+    def test_python_fails_and(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 and df > 3',
+                          local_dict={'df': df}, parser='python')
+
+    def test_python_fails_or(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'df > 2 or df > 3',
+                          local_dict={'df': df}, parser='python')
+
+    def test_python_fails_not(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NotImplementedError, pd.eval, 'not df > 2',
+                          local_dict={'df': df}, parser='python')
+
+    def test_python_fails_ampersand(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 & (df > 0)',
+                          local_dict={'df': df}, parser='python')
+
+    def test_python_fails_pipe(self):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(TypeError, pd.eval,
+                          '(df + 2)[df > 1] > 0 | (df > 0)',
+                          local_dict={'df': df}, parser='python')
+
+    def check_failing_subscript_with_name_error(self, engine):
+        df = DataFrame(np.random.randn(5, 3))
+        self.assertRaises(NameError, pd.eval, 'df[x > 2] > 2',
+                          local_dict={'df': df}, engine=engine)
+
+    def test_failing_subscript_with_name_error(self):
+        for engine in _engines:
+            self.check_failing_subscript_with_name_error(engine)
+
+    def check_lhs_expression_subscript(self, engine):
+        df = DataFrame(np.random.randn(5, 3))
+        result = pd.eval('(df + 1)[df > 2]', engine=engine)
+        expected = (df + 1)[df > 2]
+        assert_frame_equal(result, expected)
+
+    def test_lhs_expression_subscript(self):
+        for engine in _engines:
+            self.check_lhs_expression_subscript(engine)
+
+    def check_attr_expression(self, engine):
+        df = DataFrame(np.random.randn(5, 3), columns=list('abc'))
+        expr1 = 'df.a < df.b'
+        expec1 = df.a < df.b
+        expr2 = 'df.a + df.b + df.c'
+        expec2 = df.a + df.b + df.c
+        expr3 = 'df.a + df.b + df.c[df.b < 0]'
+        expec3 = df.a + df.b + df.c[df.b < 0]
+        exprs = expr1, expr2, expr3
+        expecs = expec1, expec2, expec3
+        for e, expec in zip(exprs, expecs):
+            assert_series_equal(expec, pd.eval(e, engine=engine))
+
+    def test_attr_expression(self):
+        for engine in _engines:
+            self.check_attr_expression(engine)
+
+    def check_assignment_fails(self, engine, parser):
+        df = DataFrame(np.random.randn(5, 3), columns=list('abc'))
+        df2 = DataFrame(np.random.randn(5, 3))
+        expr1 = 'df = df2'
+        self.assertRaises(NotImplementedError, pd.eval, expr1,
+                          local_dict={'df': df, 'df2': df2}, engine=engine,
+                          parser=parser)
+
+    def test_assignment_fails(self):
+        for engine, parser in product(_engines.iterkeys(), ('pandas',
+                                                            'python')):
+            self.check_assignment_fails(engine, parser)
+
+    def check_basic_period_index_boolean_expression(self, engine):
+        df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
+
+        e = df < 2
+        r = pd.eval('df < 2', engine=engine)
+        x = df < 2
+
+        assert_frame_equal(r, e)
+        assert_frame_equal(x, e)
+
+    def test_basic_period_index_expression_python(self):
+        for engine in _engines:
+            self.check_basic_period_index_boolean_expression(engine)
+
+    def check_basic_period_index_subscript_expression(self, engine):
+        df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
+        r = pd.eval('df[df < 2 + 3]', engine=engine)
+        e = df[df < 2 + 3]
+        assert_frame_equal(r, e)
+
+    def test_basic_period_index_subscript_expression(self):
+        for engine in _engines:
+            self.check_basic_period_index_subscript_expression(engine)
+
+    def check_nested_period_index_subscript_expression(self, engine):
+        df = mkdf(2, 2, data_gen_f=f, c_idx_type='p', r_idx_type='i')
+        r = pd.eval('df[df[df < 2] < 2] + df * 2', engine=engine)
+        e = df[df[df < 2] < 2] + df * 2
+        assert_frame_equal(r, e)
+
+    def test_nested_period_index_subscript_expression(self):
+        for engine in _engines:
+            self.check_nested_period_index_subscript_expression(engine)
+
+    def test_simple_not_expression(self):
+        df = DataFrame(randn(10, 3), columns=list('abc'))
+        df['bools'] = rand(len(df)) > 0.5
+        res = df['not bools']
+        res2 = df['~bools']
+        expec = df[~df.bools]
+        assert_frame_equal(res, expec)
+        assert_frame_equal(res2, expec)
+
+    def test_complex_boolean_expression(self):
+        df = DataFrame(randn(10, 3), columns=list('abc'))
+        df['bools'] = rand(len(df)) > 0.5
+        res = df['a < b < c and (not bools) or bools > 2']
+        expec = df[(df.a < df.b) & (df.b < df.c) & (~df.bools) | (df.bools > 2)]
+        assert_frame_equal(res, expec)
 
 _var_s = randn(10)
 
@@ -695,28 +854,36 @@ class TestScope(unittest.TestCase):
         for engine in _engines:
             self.check_no_new_globals(engine)
 
-    def test_nested_scope(self):
+    def check_nested_scope(self, engine):
+        # smoke test
         x = 1
-        result = pd.eval('x + 1')
+        result = pd.eval('x + 1', engine=engine)
         self.assertEqual(result, 2)
 
-        df  = DataFrame(np.random.randn(2000, 10))
-        df2 = DataFrame(np.random.randn(2000, 10))
+        df  = DataFrame(np.random.randn(5, 3))
+        df2 = DataFrame(np.random.randn(5, 3))
         expected = df[(df>0) & (df2>0)]
 
         result = df['(df>0) & (df2>0)']
-        assert_frame_equal(result,expected)
+        assert_frame_equal(result, expected)
+
+        result = df.query('(df>0) & (df2>0)', engine=engine)
+        assert_frame_equal(result, expected)
+
+        result = pd.eval('df[(df > 0) and (df2 > 0)]', engine=engine)
+        assert_frame_equal(result, expected)
 
-        result = df.query('(df>0) & (df2>0)')
-        assert_frame_equal(result,expected)
+        result = pd.eval('df[(df > 0) and (df2 > 0) and df[df > 0] > 0]', engine=engine)
+        expected = df[(df > 0) & (df2 > 0) & (df[df > 0] > 0)]
+        assert_frame_equal(result, expected)
 
-        ##### this fails ####
-        #result = pd.eval('df[(df>0) & (df2>0)]')
-        #assert_frame_equal(result,expected)
+        result = pd.eval('df[(df>0) & (df2>0)]',engine=engine)
+        expected = df.query('(df>0) & (df2>0)', engine=engine)
+        assert_frame_equal(result, expected)
 
-        #### also fails ####
-        #self.assertRaises(NotImplementedError, pd.eval,
-                          #'df[(df > 0) & (df2 > 0)]')
+    def test_nested_scope(self):
+        for engine in _engines:
+            self.check_nested_scope(engine)
 
 
 def test_invalid_engine():
diff --git a/pandas/core/common.py b/pandas/core/common.py
index 74f41355c..757d3eb6f 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -4,6 +4,7 @@ Misc tools for implementing data structures
 
 import re
 import collections
+import numbers
 import codecs
 import csv
 import sys
@@ -1668,7 +1669,7 @@ def is_bool(obj):
 
 
 def is_string(obj):
-    return isinstance(obj, (basestring, np.str_, np.unicode_))
+    return isinstance(obj, basestring)
 
 
 def is_series(obj):
@@ -1690,8 +1691,9 @@ def is_pd_obj(obj):
 def is_ndframe(obj):
     return isinstance(obj, pd.core.generic.NDFrame)
 
+
 def is_integer(obj):
-    return isinstance(obj, (int, long, np.integer))
+    return isinstance(obj, (numbers.Integral, np.integer))
 
 
 def is_float(obj):
@@ -1699,7 +1701,7 @@ def is_float(obj):
 
 
 def is_complex(obj):
-    return isinstance(obj, (complex, np.complexfloating))
+    return isinstance(obj, (numbers.Complex, np.complexfloating))
 
 
 def is_iterator(obj):
@@ -1708,7 +1710,7 @@ def is_iterator(obj):
 
 
 def is_number(obj):
-    return isinstance(obj, (np.number, int, long, float, complex))
+    return isinstance(obj, (numbers.Number, np.number))
 
 
 def is_integer_dtype(arr_or_dtype):
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index dd92dfa23..5f4c283d6 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1934,8 +1934,12 @@ class DataFrame(NDFrame):
         :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,
         however the semantics are different.
 
-        You can use a syntax that is semantically identical to Python by
-        passing the keyword argument ``parser='python'``.
+        You can change the semantics of the expression by passing the keyword
+        argument ``parser='python'``. This enforces the same semantics as
+        evaluation in Python space. Likewise, you can pass ``engine='python'``
+        to evaluate an expression using Python itself as a backend. This is not
+        recommended as it is inefficient compared to using ``numexpr`` as the
+        engine.
 
         The :attr:`~pandas.DataFrame.index` and
         :attr:`~pandas.DataFrame.columns` attributes of the
@@ -1945,6 +1949,9 @@ class DataFrame(NDFrame):
         The identifier ``index`` is used for this variable, and you can also
         use the name of the index to identify it in a query.
 
+        For further details and examples see the ``query`` documentation in
+        :ref:`indexing <indexing.query>`.
+
         Raises
         ------
         NameError
@@ -1952,41 +1959,6 @@ class DataFrame(NDFrame):
         SyntaxError
           * If a syntactically invalid Python expression is passed
 
-        Examples
-        --------
-        Get the value of the frame where column ``b`` has values between the
-        values of columns ``a`` and ``c``.
-
-            >>> from pandas import DataFrame
-            >>> from numpy.random import randn
-            >>> df = DataFrame(randn(100, 3), columns=list('abc'))
-            >>> result = df.query('a < b & b < c')
-
-        Do the same thing but fallback on a named index if there is no column
-        with the name ``a``.
-
-            >>> from pandas import DataFrame, Index
-            >>> from numpy.random import randn
-            >>> n = 10
-            >>> index = Index(randn(n), name='a')
-            >>> df = DataFrame(randn(n, 2), index=index, columns=list('bc'))
-            >>> result = df.query('a < b & b < c')
-
-        A use case for :meth:`~pandas.core.frame.DataFrame.query` is when you
-        have a collection of :class:`~pandas.core.frame.DataFrame` s that have
-        a subset of column names in common. You can pass the same query to both
-        frames *without* having to specify which frame you're interested in
-        querying
-
-            >>> from pandas import DataFrame, Index
-            >>> from numpy.random import randn
-            >>> n = 100
-            >>> index = Index(randn(n), name='a')
-            >>> df = DataFrame(randn(n, 2), index=index, columns=list('bc'))
-            >>> df2 = DataFrame(randn(n + 10, 3))
-            >>> expr = 'a < b & b < c'
-            >>> results = map(lambda frame: frame.query(expr), [df, df2])
-
         See Also
         --------
         pandas.eval
diff --git a/pandas/util/testing.py b/pandas/util/testing.py
index 461f5ab0f..e82aef137 100644
--- a/pandas/util/testing.py
+++ b/pandas/util/testing.py
@@ -14,7 +14,6 @@ from datetime import datetime
 from functools import wraps, partial
 from contextlib import contextmanager
 from httplib import HTTPException
-from urllib2 import urlopen
 from distutils.version import LooseVersion
 
 from numpy.random import randn, rand
@@ -36,7 +35,7 @@ from pandas import bdate_range
 from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex
 
-from pandas.io.common import urlopen, HTTPException
+from pandas.io.common import urlopen
 
 Index = index.Index
 MultiIndex = index.MultiIndex
diff --git a/vb_suite/eval.py b/vb_suite/eval.py
index c0c983862..c666cd431 100644
--- a/vb_suite/eval.py
+++ b/vb_suite/eval.py
@@ -1,7 +1,7 @@
 from vbench.benchmark import Benchmark
 from datetime import datetime
 
-setup = """from pandas_vb_common import *
+common_setup = """from pandas_vb_common import *
 import pandas as pd
 df  = DataFrame(np.random.randn(20000, 100))
 df2 = DataFrame(np.random.randn(20000, 100))
@@ -9,6 +9,11 @@ df3 = DataFrame(np.random.randn(20000, 100))
 df4 = DataFrame(np.random.randn(20000, 100))
 """
 
+setup = common_setup + """
+import pandas.computation.expressions as expr
+expr.set_numexpr_threads(1)
+"""
+
 SECTION = 'Eval'
 
 #----------------------------------------------------------------------
@@ -16,34 +21,94 @@ SECTION = 'Eval'
 
 #----------------------------------------------------------------------
 # add
-
-frame_add_eval = \
-    Benchmark("pd.eval('df + df2 + df3 + df4')", setup, name='frame_add_eval',
+eval_frame_add_all_threads = \
+    Benchmark("pd.eval('df + df2 + df3 + df4')", common_setup,
+              name='eval_frame_add_all_threads',
               start_date=datetime(2013, 7, 21))
 
-frame_add_python = \
-    Benchmark("pd.eval('df + df2 + df3 + df4', engine='python')", setup,
-              name='frame_add_python', start_date=datetime(2013, 7, 21))
 
+
+eval_frame_add_one_thread = \
+    Benchmark("pd.eval('df + df2 + df3 + df4')", setup,
+              name='eval_frame_add_one_thread',
+              start_date=datetime(2013, 7, 26))
+
+eval_frame_add_python = \
+    Benchmark("pd.eval('df + df2 + df3 + df4', engine='python')", common_setup,
+              name='eval_frame_add_python', start_date=datetime(2013, 7, 21))
+
+eval_frame_add_python_one_thread = \
+    Benchmark("pd.eval('df + df2 + df3 + df4', engine='python')", setup,
+              name='eval_frame_add_python_one_thread',
+              start_date=datetime(2013, 7, 26))
 #----------------------------------------------------------------------
 # mult
 
-frame_mult_eval = \
-    Benchmark("pd.eval('df * df2 * df3 * df4')", setup, name='frame_mult_eval',
+eval_frame_mult_all_threads = \
+    Benchmark("pd.eval('df * df2 * df3 * df4')", common_setup,
+              name='eval_frame_mult_all_threads',
               start_date=datetime(2012, 7, 21))
 
-frame_mult_python = \
-    Benchmark("pdl.eval('df * df2 * df3 * df4', engine='python')", setup,
-              name='frame_mult_python', start_date=datetime(2013, 7, 21))
+eval_frame_mult_one_thread = \
+    Benchmark("pd.eval('df * df2 * df3 * df4')", setup,
+              name='eval_frame_mult_one_thread',
+              start_date=datetime(2012, 7, 26))
+
+eval_frame_mult_python = \
+    Benchmark("pdl.eval('df * df2 * df3 * df4', engine='python')",
+              common_setup,
+              name='eval_frame_mult_python', start_date=datetime(2013, 7, 21))
+
+eval_frame_mult_python_one_thread = \
+    Benchmark("pd.eval('df * df2 * df3 * df4', engine='python')", setup,
+              name='eval_frame_mult_python_one_thread',
+              start_date=datetime(2012, 7, 26))
 
 #----------------------------------------------------------------------
 # multi and
 
-frame_and_eval = \
+eval_frame_and_all_threads = \
+    Benchmark("pd.eval('(df > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)')",
+              common_setup,
+              name='eval_frame_and_all_threads',
+              start_date=datetime(2012, 7, 21))
+
+eval_frame_and_one_thread = \
     Benchmark("pd.eval('(df > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)')", setup,
-              name='frame_and_eval', start_date=datetime(2012, 7, 21))
+              name='eval_frame_and_one_thread',
+              start_date=datetime(2012, 7, 26))
 
-frame_and_python = \
-    Benchmark("pd.eval('(df > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)', "
-              "engine='python')", setup, name='frame_and_python',
+setup = common_setup
+eval_frame_and_python = \
+    Benchmark("pd.eval('(df > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)', engine='python')",
+              common_setup, name='eval_frame_and_python',
               start_date=datetime(2013, 7, 21))
+
+eval_frame_and_one_thread = \
+    Benchmark("pd.eval('(df > 0) & (df2 > 0) & (df3 > 0) & (df4 > 0)', engine='python')",
+              setup,
+              name='eval_frame_and_python_one_thread',
+              start_date=datetime(2012, 7, 26))
+
+#--------------------------------------------------------------------
+# chained comp
+eval_frame_chained_cmp_all_threads = \
+    Benchmark("pd.eval('df < df2 < df3 < df4')", common_setup,
+              name='eval_frame_chained_cmp_all_threads',
+              start_date=datetime(2012, 7, 21))
+
+eval_frame_chained_cmp_one_thread = \
+    Benchmark("pd.eval('df < df2 < df3 < df4')", setup,
+              name='eval_frame_chained_cmp_one_thread',
+              start_date=datetime(2012, 7, 26))
+
+setup = common_setup
+eval_frame_chained_cmp_python = \
+    Benchmark("pd.eval('df < df2 < df3 < df4', engine='python')",
+              common_setup, name='eval_frame_chained_cmp_python',
+              start_date=datetime(2013, 7, 26))
+
+eval_frame_chained_cmp_one_thread = \
+    Benchmark("pd.eval('df < df2 < df3 < df4', engine='python')", setup,
+              name='eval_frame_chained_cmp_python_one_thread',
+              start_date=datetime(2012, 7, 26))
