commit 2246fb32d6c72b5df796af77b50229302aceaa95
Author: Adam Klein <adamklein@gmail.com>
Date:   Tue Feb 28 12:03:28 2012 -0500

    ENH: cleaned up time/groupby API, expanded tests

diff --git a/pandas/core/datetools.py b/pandas/core/datetools.py
index b2c80b392..1fef9bdf1 100644
--- a/pandas/core/datetools.py
+++ b/pandas/core/datetools.py
@@ -892,6 +892,11 @@ class Tick(DateOffset):
 
         return self._delta
 
+    def us_stride(self):
+        return (self._delta.days * 24 * 60 * 60 * 1000000
+                + self._delta.seconds * 1000000
+                + self._delta.microseconds)
+
     def apply(self, other):
         if isinstance(other, (datetime, timedelta, Timestamp)):
             return other + self.delta
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 40b259298..50931df15 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -90,8 +90,7 @@ class PandasObject(Picklable):
         except KeyError:
             return default
 
-    def groupby(self, by=None, axis=0, level=None, as_index=True, sort=True,
-                grouper=None):
+    def groupby(self, by=None, axis=0, level=None, as_index=True, sort=True):
         """
         Group series using mapper (dict or key function, apply given function
         to group, return result as series) or by a series of columns
@@ -131,7 +130,7 @@ class PandasObject(Picklable):
         """
         from pandas.core.groupby import groupby
         return groupby(self, by, axis=axis, level=level, as_index=as_index,
-                       sort=sort, grouper=grouper)
+                       sort=sort)
 
     def select(self, crit, axis=0):
         """
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index cccf6ff64..460c239fd 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1,17 +1,17 @@
-from itertools import izip
 import types
 
 import numpy as np
 
 from pandas.core.frame import DataFrame
 from pandas.core.generic import NDFrame
-from pandas.core.index import Index, MultiIndex
+from pandas.core.index import Index, MultiIndex, DatetimeIndex
 from pandas.core.internals import BlockManager, make_block
 from pandas.core.series import Series
 from pandas.core.panel import Panel
 from pandas.util.decorators import cache_readonly, Appender
 import pandas.core.algorithms as algos
 import pandas.core.common as com
+import pandas.core.datetools as dt
 import pandas._tseries as lib
 
 
@@ -95,8 +95,6 @@ class GroupBy(object):
             obj._consolidate_inplace()
 
         self.obj = obj
-
-
         self.axis = axis
         self.level = level
 
@@ -622,7 +620,7 @@ class Grouper(object):
 
         return name_list
 
-def generate_bins_generic(index, binner, closed, label):
+def generate_bins_generic(values, binner, closed, label):
     """
     Generate bin edge offsets and bin labels for one array using another array
     which has bin edge values. Both arrays must be sorted.
@@ -643,25 +641,29 @@ def generate_bins_generic(index, binner, closed, label):
         bin is values[0:bin[0]] and the last is values[bin[-1]:]
     labels : array of labels of bins
     """
-    lenidx = len(index)
+    lenidx = len(values)
     lenbin = len(binner)
 
+    if lenidx <= 0 or lenbin <= 0:
+        raise ValueError("Invalid length for values or for binner")
+
     # check binner fits data
-    if index[0] < binner[0]:
-        raise ValueError("Index overlaps first bin")
+    if values[0] < binner[0]:
+        raise ValueError("Values falls before first bin")
 
-    if index[-1] > binner[-1]:
-        raise ValueError("Index overlaps last bin")
+    if values[lenidx-1] > binner[lenbin-1]:
+        raise ValueError("Values falls after last bin")
 
-    labels = np.empty(lenbin, dtype='O')
-    bins = np.empty(lenbin, dtype='i4')
+    labels = np.empty(lenbin, dtype=np.int64)
+    bins   = np.empty(lenbin, dtype=np.int32)
 
-    j = 0
+    j  = 0 # index into values
     bc = 0 # bin count
     vc = 0 # value count
 
-    # linear scan, presume nothing about index/binner
-    for i in range(0, len(binner)-1):
+    # linear scan, presume nothing about values/binner except that it
+    # fits ok
+    for i in range(0, lenbin-1):
         l_bin = binner[i]
         r_bin = binner[i+1]
 
@@ -671,34 +673,23 @@ def generate_bins_generic(index, binner, closed, label):
         else:
             labels[bc] = r_bin
 
-        # check still within possible bins
-        if index[lenidx-1] < r_bin:
-            vc = lenidx - j
-            break
+        # count values in current bin, advance to next bin
+        while values[j] < r_bin or closed == 'right' and values[j] == r_bin:
+            j += 1
+            vc += 1
+            if j >= lenidx:
+                break
 
-        # advance until in correct bin
-        if closed == 'left':
-            while r_bin > index[j]:
-                j += 1
-                vc += 1
-                if j >= lenidx:
-                    break
-        else:
-            while r_bin >= index[j]:
-                j += 1
-                vc += 1
-                if j >= lenidx:
-                    break
-
-        # check we have more data to scan
-        if j < lenidx:
-            if vc != 0:
-                bins[bc] = j 
-                bc += 1
-                vc = 0
-        else:
+        # check we have data left to scan
+        if j >= lenidx:
             break
 
+        # if we've seen some values, mark bin
+        if vc != 0:
+            bins[bc] = j 
+            bc += 1
+            vc = 0
+
     labels = np.resize(labels, bc + 1)
     bins = np.resize(bins, bc)
 
@@ -707,54 +698,110 @@ def generate_bins_generic(index, binner, closed, label):
 class CustomGrouper:
     pass
 
-class Binner(Grouper, CustomGrouper):
+def _generate_time_binner(dtindex, offset,
+                          begin=None, end=None, nperiods=None):
+
+    if isinstance(offset, basestring):
+        offset = dt.getOffset(offset)
+
+    if begin is None:
+        first = lib.Timestamp(dtindex[0] - offset)
+    else:
+        first = lib.Timestamp(begin)
+
+    if end is None:
+        last = lib.Timestamp(dtindex[-1] + offset)
+    else:
+        last = lib.Timestamp(end)
+
+    if isinstance(offset, dt.Tick):
+        return np.arange(first.value, last.value+1, offset.us_stride(),
+                         dtype=np.int64)
+
+    return DatetimeIndex(offset=offset, 
+                         start=first, end=last, periods=nperiods)
+
+class Tinterval(Grouper, CustomGrouper):
     """
-    Custom binner class (for grouping into bins)
+    Custom groupby class for time-interval grouping 
 
     Parameters
     ----------
-    index : index object to bin
-    binner : index object containing bin edges 
+    interval : pandas offset string or object for identifying bin edges 
     closed : closed end of interval; left (default) or right
     label : interval boundary to use for labeling; left (default) or right
+    begin : optional, timestamp-like
+    end : optional, timestamp-like
+    nperiods : optional, integer
+
+    Notes
+    -----
+    Use begin, end, nperiods to generate intervals that cannot be derived 
+    directly from the associated object
     """
-    index = None
+
+    obj = None
     bins = None
     binlabels = None
+    begin = None
+    end = None
+    nperiods = None
+
+    def __init__(self, interval='Min', closed='left', label='left',
+                 begin=None, end=None, nperiods=None):
+        self.offset = interval
+        self.closed = closed
+        self.label = label
+        self.begin = begin
+        self.end = end
+        self.nperiods = None
+
+    def set_obj(self, obj):
+        """
+        Injects the object we'll act on, which we use to initialize grouper
+        """
+        self.obj = obj
 
-    def __init__(self, index, binner, closed='left', label='left'):
-        from pandas.core.index import DatetimeIndex
+        if not isinstance(obj.index, DatetimeIndex):
+            raise ValueError("Cannot apply Tinterval to non-DatetimeIndex")
 
-        if isinstance(index, DatetimeIndex):
-            # we know nothing about frequencies
-            bins, labels = lib.generate_bins_dt64(index.asi8, binner.asi8,
-                                                  closed, label)
-            labels = labels.view('M8[us]')
-            # TODO: more speedup using freq info
-        else:
-            bins, labels = generate_bins_generic(index, binner, closed, label)
+        index = obj.index
+
+        if len(obj.index) < 1:
+            self.bins = []
+            self.binlabels = []
+            return
+
+        binner = _generate_time_binner(obj.index, self.offset, self.begin,
+                                       self.end, self.nperiods)
+
+        if isinstance(binner, DatetimeIndex):
+            binner = binner.asi8
+
+        # general version, knowing nothing about relative frequencies
+        bins, labels = lib.generate_bins_dt64(index.asi8, binner,
+                                              self.closed, self.label)
 
-        self.index = index
         self.bins = bins
-        self.binlabels = labels
+        self.binlabels = labels.view('M8[us]')
 
     @cache_readonly
     def groupings(self):
-        return [Grouping(self.index, self, name="Binner")]
+        return [Grouping(self.obj.index, self, name="Binner")]
 
     @cache_readonly
     def ngroups(self):
         return len(self.binlabels)
 
+    @cache_readonly
+    def result_index(self):
+        return self.binlabels
+
     def agg_series(self, obj, func):
         dummy = obj[:0]
         grouper = lib.SeriesBinGrouper(obj, func, self.bins, dummy)
         return grouper.get_result()
 
-    @cache_readonly
-    def result_index(self):
-        return self.binlabels
-
 class Grouping(object):
     """
     Holds the grouping information for a single key
@@ -889,6 +936,10 @@ def _get_grouper(obj, key=None, axis=0, level=None, sort=True):
     if level is not None and not isinstance(group_axis, MultiIndex):
         raise ValueError('can only specify level with multi-level index')
 
+    if isinstance(key, CustomGrouper):
+        key.set_obj(obj)
+        return key, []
+
     if not isinstance(key, (tuple, list)):
         keys = [key]
     else:
diff --git a/pandas/src/datetime.pyx b/pandas/src/datetime.pyx
index bd89a093f..cb5144c7c 100644
--- a/pandas/src/datetime.pyx
+++ b/pandas/src/datetime.pyx
@@ -63,7 +63,7 @@ class Timestamp(_Timestamp):
         self.value = state[0]
         self.offset = state[1]
         self.tzinfo = state[2]
-            
+
     def __reduce__(self):
         object_state = self.value, self.offset, self.tzinfo
         return (Timestamp, object_state)
diff --git a/pandas/src/groupby.pyx b/pandas/src/groupby.pyx
index c0292dfa6..e5038524a 100644
--- a/pandas/src/groupby.pyx
+++ b/pandas/src/groupby.pyx
@@ -430,34 +430,23 @@ def generate_bins_dt64(ndarray[int64_t] values, ndarray[int64_t] binner,
         else:
             labels[bc] = r_bin
 
-        # check still within possible bins
-        if values[lenidx-1] < r_bin:
-            break
+        # count values in current bin, advance to next bin
+        while values[j] < r_bin or closed == 'right' and values[j] == r_bin:
+            j += 1
+            vc += 1
+            if j >= lenidx:
+                break
 
-        # advance until in correct bin
-        if closed == 'left':
-            while r_bin > values[j]:
-                j += 1
-                vc += 1
-                if j >= lenidx:
-                    break
-        else:
-            while r_bin >= values[j]:
-                j += 1
-                vc += 1
-                if j >= lenidx:
-                    break
-
-        # if we haven't fallen off
-        if j < lenidx:
-            # and we've seen some values
-            if vc != 0:
-                bins[bc] = j 
-                bc += 1
-                vc = 0
-        else:
+        # check we have data left to scan
+        if j >= lenidx:
             break
 
+        # if we've seen some values, mark bin
+        if vc != 0:
+            bins[bc] = j 
+            bc += 1
+            vc = 0
+
     labels = np.resize(labels, bc + 1)
     bins = np.resize(bins, bc)
 
diff --git a/pandas/tests/test_datetime64.py b/pandas/tests/test_datetime64.py
index 988ac56b9..6f29747a8 100644
--- a/pandas/tests/test_datetime64.py
+++ b/pandas/tests/test_datetime64.py
@@ -296,7 +296,7 @@ class TestDatetime64(unittest.TestCase):
 
     def test_custom_grouper(self):
         from pandas.core.datetools import Minute 
-        from pandas.core.groupby import Binner
+        from pandas.core.groupby import Tinterval
         from pandas.core.frame import DataFrame
 
         dti = DatetimeIndex(offset='Min', start=datetime(2005,1,1),
@@ -305,28 +305,25 @@ class TestDatetime64(unittest.TestCase):
         data = np.array([1]*len(dti))
         s = Series(data, index=dti) 
 
-        dti2 = DatetimeIndex(offset=Minute(5), 
-                             start=datetime(2005,1,1) - Minute(5),
-                             end=datetime(2005,1,10) + Minute(5))
-
-        b = Binner(dti, dti2, closed='left', label='left')
-        g = s.groupby(grouper=b)
+        b = Tinterval(Minute(5))
+        g = s.groupby(b)
 
         self.assertEquals(g.ngroups, 2593)
+
+        # construct expected val
         arr = [5] * 2592
         arr.append(1)
-
         idx = dti[0:-1:5]
         idx = idx.append(DatetimeIndex([np.datetime64(dti[-1])]))
+        expect = Series(arr, index=idx)
 
-        e = Series(arr, index=idx)
-        r = g.agg(np.sum)
+        result = g.agg(np.sum)
         
-        assert_series_equal(r, e)
+        assert_series_equal(result, expect)
 
         data = np.random.rand(len(dti), 10) 
         df = DataFrame(data, index=dti)
-        r = df.groupby(grouper=b).agg(np.sum)
+        r = df.groupby(b).agg(np.sum)
 
         self.assertEquals(len(r.columns), 10)
         self.assertEquals(len(r.index), 2593)
diff --git a/pandas/tests/test_tseries.py b/pandas/tests/test_tseries.py
index 7b0dff7ca..e656cba00 100644
--- a/pandas/tests/test_tseries.py
+++ b/pandas/tests/test_tseries.py
@@ -300,33 +300,30 @@ def test_series_bin_grouper():
     assert_almost_equal(counts, exp_counts)
 
 def test_generate_bins():
+    from pandas.core.groupby import generate_bins_generic
     values = np.array([1,2,3,4,5,6])
     binner = np.array([0,3,6,9])
 
-    bins, labels = lib.generate_bins_dt64(values, binner,
-                                          closed='left', label='left')
+    for func in [lib.generate_bins_dt64, generate_bins_generic]:
+        bins, labels = func(values, binner, closed='left', label='left')
 
-    assert((bins == np.array([2, 5])).all())
-    assert((labels == np.array([0, 3, 6])).all())
+        assert((bins == np.array([2, 5])).all())
+        assert((labels == np.array([0, 3, 6])).all())
 
-    bins, labels = lib.generate_bins_dt64(values, binner,
-                                          closed='left', label='right')
+        bins, labels = func(values, binner, closed='left', label='right')
 
-    assert((bins == np.array([2, 5])).all())
-    assert((labels == np.array([3, 6, 9])).all())
+        assert((bins == np.array([2, 5])).all())
+        assert((labels == np.array([3, 6, 9])).all())
 
-    bins, labels = lib.generate_bins_dt64(values, binner,
-                                          closed='right', label='left')
+        bins, labels = func(values, binner, closed='right', label='left')
 
-    assert((bins == np.array([3])).all())
-    assert((labels == np.array([0, 3])).all())
+        assert((bins == np.array([3])).all())
+        assert((labels == np.array([0, 3])).all())
 
-    bins, labels = lib.generate_bins_dt64(values, binner,
-                                          closed='right', label='right')
-
-    assert((bins == np.array([3])).all())
-    assert((labels == np.array([3, 6])).all())
+        bins, labels = func(values, binner, closed='right', label='right')
 
+        assert((bins == np.array([3])).all())
+        assert((labels == np.array([3, 6])).all())
 
 def test_group_add_bin():
     # original group_add
