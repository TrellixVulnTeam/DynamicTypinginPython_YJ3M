commit 99f80cb88608e0332a7bff7321b41bba821a7fd3
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Wed Jul 13 13:20:26 2011 -0400

    contributed patches

diff --git a/pandas/core/common.py b/pandas/core/common.py
index be325fd69..666e7abcd 100644
--- a/pandas/core/common.py
+++ b/pandas/core/common.py
@@ -85,6 +85,16 @@ def null_out_axis(arr, mask, axis):
 #-------------------------------------------------------------------------------
 # Lots of little utilities
 
+def _infer_dtype(value):
+    if isinstance(value, (float, np.floating)):
+        return float
+    elif isinstance(value, (int, np.integer)):
+        return int
+    elif isinstance(value, (bool, np.bool_)):
+        return bool
+    else:
+        return object
+
 def _default_index(n):
     from pandas.core.index import NULL_INDEX
     if n == 0:
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index e4cdd6969..749196d6f 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -22,7 +22,7 @@ from numpy import nan
 import numpy as np
 
 from pandas.core.common import (isnull, notnull, PandasError, _ensure_index,
-                                _try_sort, _pfixed, _default_index)
+                                _try_sort, _pfixed, _default_index, _infer_dtype)
 from pandas.core.daterange import DateRange
 from pandas.core.generic import AxisProperty, PandasGeneric
 from pandas.core.index import Index, NULL_INDEX
@@ -1050,14 +1050,14 @@ class DataFrame(PandasGeneric):
             series = self._series
             for col, s in series.iteritems():
                 result[col] = s.fillna(method=method, value=value)
-            return DataFrame(result, index=self.index)
+            return DataFrame(result, index=self.index, columns=self.columns)
         else:
             # Float type values
             if len(self.columns) == 0:
                 return self
 
             new_data = self._data.fillna(value)
-            return DataFrame(new_data)
+            return DataFrame(new_data, index=self.index, columns=self.columns)
 
     #----------------------------------------------------------------------
     # Rename
@@ -2547,6 +2547,10 @@ def _homogenize_series(data, index, dtype=None):
         else:
             if isinstance(v, dict):
                 v = [v.get(i, nan) for i in index]
+            elif np.isscalar(v):
+                _v = np.empty(len(index), dtype=_infer_dtype(v))
+                _v.fill(v)
+                v = _v
             else:
                 assert(len(v) == len(index))
 
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 0a8be5518..e803ea10c 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -10,7 +10,7 @@ import warnings
 import numpy as np
 
 from pandas.core.common import (PandasError, _mut_exclusive, _ensure_index,
-                                _pfixed, _default_index)
+                                _pfixed, _default_index, _infer_dtype)
 from pandas.core.index import Index
 from pandas.core.internals import BlockManager, make_block
 from pandas.core.frame import DataFrame
@@ -1803,16 +1803,6 @@ def _prep_ndarray(values, copy=True):
     assert(values.ndim == 3)
     return values
 
-def _infer_dtype(value):
-    if isinstance(value, (float, np.floating)):
-        return float
-    elif isinstance(value, (int, np.integer)):
-        return int
-    elif isinstance(value, (bool, np.bool_)):
-        return bool
-    else:
-        return object
-
 class Factor(object):
     """
     Represents a categorical variable in classic R / S-plus fashion
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index 2e62cd251..b709ffcc1 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -83,6 +83,17 @@ class HDFStore(object):
         ``'r+'``
             It is similar to ``'a'``, but the file must already exist.
 
+    complevel : int, 1-9, default 0
+            If a complib is specified compression will be applied
+            where possible
+
+    complib : {'zlib', 'bzip2', 'lzo', 'blosc', None}, default None
+            If complevel is > 0 apply compression to objects written
+            in the store wherever possible
+
+    fletcher32 : bool, default False
+            If applying compression use the fletcher32 checksum
+
     Examples
     --------
     >>> store = HDFStore('test.h5')
@@ -90,7 +101,7 @@ class HDFStore(object):
     >>> bar = store['foo']   # retrieve
     >>> store.close()
     """
-    def __init__(self, path, mode='a'):
+    def __init__(self, path, mode='a', complevel=0, complib=None, fletcher32=False):
         try:
             import tables as _
         except ImportError: # pragma: no cover
@@ -99,6 +110,10 @@ class HDFStore(object):
         self.path = path
         self.mode = mode
         self.handle = None
+        self.complevel = complevel
+        self.complib = complib
+        self.fletcher32 = fletcher32
+        self.filters = None
         self.open(mode=mode, warn=False)
 
     def __getitem__(self, key):
@@ -148,6 +163,12 @@ class HDFStore(object):
                     return
         if self.handle is not None and self.handle.isopen:
             self.handle.close()
+
+        if self.complevel > 0 and self.complib is not None:
+            self.filters = _tables().Filters(self.complevel,
+                                             self.complib,
+                                             fletcher32=self.fletcher32)
+
         self.handle = _tables().openFile(self.path, self.mode)
 
     def close(self):
@@ -231,6 +252,8 @@ class HDFStore(object):
             table
         compression : {None, 'blosc', 'lzo', 'zlib'}, default None
             Use a compression algorithm to compress the data
+            If None, the compression settings specified in the ctor will
+            be used.
         """
         self._write_to_group(key, value, table=table, append=append,
                              comp=compression)
@@ -410,6 +433,22 @@ class HDFStore(object):
         if key in group:
             self.handle.removeNode(group, key)
 
+        if self.filters is not None:
+            atom = None
+            try:
+                # get the atom for this datatype
+                atom = _tables().Atom.from_dtype(value.dtype)
+            except ValueError:
+                pass
+
+            if atom is not None:
+                # create an empty chunked array and fill it from value
+                ca = self.handle.createCArray(group, key, atom,
+                                                value.shape,
+                                                filters=self.filters)
+                ca[:] = value
+                return
+
         if value.dtype == np.object_:
             vlarr = self.handle.createVLArray(group, key,
                                               _tables().ObjectAtom())
@@ -440,8 +479,14 @@ class HDFStore(object):
                        'description' : desc}
 
             if compression:
-                options['filters'] = _tables().Filters(complevel=9,
-                                                    complib=compression)
+                complevel = self.complevel
+                if complevel is None:
+                    complevel = 9
+                options['filters'] = _tables().Filters(complevel=complevel,
+                                                       complib=compression,
+                                                       fletcher32=self.fletcher32)
+            elif self.filters is not None:
+                options['filters'] = self.filters
 
             table = self.handle.createTable(group, **options)
         else:
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index e5892c4b5..3aa987b50 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -2348,7 +2348,7 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         self.assert_((filled['foo'][5:20] == 0).all())
         del self.mixed_frame['foo']
 
-	empty_float = self.frame.reindex(columns=[])
+        empty_float = self.frame.reindex(columns=[])
         result = empty_float.fillna(value=0)
 
     def test_count_objects(self):
@@ -2466,6 +2466,45 @@ class TestDataFrame(unittest.TestCase, CheckIndexing):
         dm.xs(3, copy=False)[:] = 10
         self.assert_((dm.xs(3) == 10).all())
 
+    def test_boolean_indexing(self):
+        idx = range(3)
+        cols = range(3)
+        df1 = DataFrame(index=idx, columns=cols, \
+                           data=np.array([[0.0, 0.5, 1.0],
+                                          [1.5, 2.0, 2.5],
+                                          [3.0, 3.5, 4.0]], dtype=float))
+        df2 = DataFrame(index=idx, columns=cols, data=np.ones((len(idx), len(cols))))
+
+        expected = DataFrame(index=idx, columns=cols, \
+                           data=np.array([[0.0, 0.5, 1.0],
+                                          [1.5, 2.0, -1],
+                                          [-1,  -1,  -1]], dtype=float))
+
+        df1[df1 > 2.0 * df2] = -1
+        assert_frame_equal(df1, expected)
+
+    def test_groupby_nonsense_func(self):
+        df = DataFrame([0])
+        self.assertRaises(Exception, df.groupby, lambda x: donkey)
+
+    def test_sum_bools(self):
+        df = DataFrame(index=range(1), columns=range(10))
+        bools = np.isnan(df)
+        self.assert_(bools.sum(axis=1)[0] == 10)
+
+    def test_fillna_col_reordering(self):
+        idx = range(20)
+        cols = ["COL." + str(i) for i in range(5, 0, -1)]
+        data = np.random.rand(20, 5)
+        df = DataFrame(index=range(20), columns=cols, data=data)
+        self.assert_(df.columns.tolist() == df.fillna().columns.tolist())
+
+    def test_scalar_ctor(self):
+        idx = Index(range(3))
+        df = DataFrame({"a" : 0}, index=idx)
+        expected = DataFrame({"a" : [0, 0, 0]}, index=idx)
+        assert_frame_equal(df, expected)
+
 if __name__ == '__main__':
     # unittest.main()
     import nose
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index 5e4bf6eea..470667350 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -921,6 +921,21 @@ class TestSeries(unittest.TestCase):
         self.assertFalse(np.isnan(self.ts[9]))
         self.assertFalse(np.isnan(self.ts[10]))
 
+    def test_ne(self):
+        ts = TimeSeries([3, 4, 5, 6, 7], [3, 4, 5, 6, 7], dtype=float)
+        expected = [True, True, False, True, True]
+        self.assert_(common.equalContents(ts.index != 5, expected))
+        self.assert_(common.equalContents(~(ts.index == 5), expected))
+
+    def test_pad_nan(self):
+        x = TimeSeries([np.nan, 1., np.nan, 3., np.nan],
+                       ['z', 'a', 'b', 'c', 'd'], dtype=float)
+        x = x.fillna(method='pad')
+        expected = TimeSeries([np.nan, 1.0, 1.0, 3.0, 3.0],
+                                ['z', 'a', 'b', 'c', 'd'], dtype=float)
+        assert_series_equal(x[1:], expected[1:])
+        self.assert_(np.isnan(x[0]), np.isnan(expected[0]))
+
 #-------------------------------------------------------------------------------
 # TimeSeries-specific
 
diff --git a/setup.py b/setup.py
old mode 100644
new mode 100755
index 1d7f460fd..23224e9b4
--- a/setup.py
+++ b/setup.py
@@ -5,6 +5,12 @@ Parts of this file were taken from the pyzmq project
 (https://github.com/zeromq/pyzmq) and hence are subject to the terms of the
 Lesser GPU General Public License.
 """
+# use setuptools if available
+try:
+    from setuptools import setup
+    _have_setuptools = True
+except ImportError:
+    _have_setuptools = False
 
 from datetime import datetime
 from glob import glob
@@ -75,6 +81,14 @@ VERSION = '%d.%d.%d' % (MAJOR, MINOR, MICRO)
 FULLVERSION = VERSION
 if not ISRELEASED:
     FULLVERSION += '.dev' + datetime.today().strftime('%Y%m%d')
+    try:
+        import subprocess
+        pipe = subprocess.Popen(["git", "rev-parse", "--short", "HEAD"],
+                                stdout=subprocess.PIPE).stdout
+        rev = pipe.read().strip()
+        FULLVERSION += "_%s" % rev
+    except:
+        print "WARNING: Couldn't get git revision"
 
 def write_version_py(filename='pandas/version.py'):
     cnt = """\
@@ -88,7 +102,6 @@ version = '%s'
     finally:
         a.close()
 
-
 class CleanCommand(Command):
     """Custom distutils command to clean the .so and .pyc files."""
 
@@ -212,6 +225,11 @@ sparse_ext = Extension('pandas._sparse',
 extensions = [tseries_ext,
               sparse_ext]
 
+setuptools_args = {}
+
+if _have_setuptools:
+    setuptools_args["test_suite"] = "nose.collector"
+
 setup(name=DISTNAME,
       version=FULLVERSION,
       maintainer=MAINTAINER,
@@ -234,4 +252,4 @@ setup(name=DISTNAME,
       long_description=LONG_DESCRIPTION,
       classifiers=CLASSIFIERS,
       platforms='any',
-      )
+      **setuptools_args)
