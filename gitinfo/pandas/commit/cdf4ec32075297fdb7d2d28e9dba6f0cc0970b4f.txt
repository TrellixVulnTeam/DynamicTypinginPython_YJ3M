commit cdf4ec32075297fdb7d2d28e9dba6f0cc0970b4f
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue May 31 23:34:39 2011 +0100

    broken, but want to commit new branch

diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index 5acb485e7..1cbfe18dc 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -100,11 +100,22 @@ class DataMatrix(DataFrame):
         else:
             raise Exception('DataMatrix constructor not properly called!')
 
-        self.values = values
+        self._values_dict = {}
+        self._columns_dict = {}
+
+        self._float_values = values
         self.index = index
         self.columns = columns
         self.objects = objects
 
+    def _get_values(self):
+        return self._float_values
+
+    def _set_values(self, values):
+        raise Exception('Values cannot be assigned to')
+
+    values = property(fget=_get_values)
+
     def _init_dict(self, data, index, columns, objects, dtype):
         """
         Segregate Series based on type and coerce into matrices.
@@ -221,9 +232,6 @@ class DataMatrix(DataFrame):
     def _constructor(self):
         return DataMatrix
 
-    # Because of DataFrame property
-    values = None
-
     def __array__(self):
         return self.values
 
@@ -510,8 +518,8 @@ class DataMatrix(DataFrame):
             if len(item) != len(self.index):
                 raise Exception('Item wrong length %d instead of %d!' %
                                 (len(item), len(self.index)))
-            newIndex = self.index[item]
-            return self.reindex(newIndex)
+            new_index = self.index[item]
+            return self.reindex(new_index)
         else:
             if self.objects is not None and item in self.objects:
                 return self.objects[item]
@@ -626,14 +634,17 @@ class DataMatrix(DataFrame):
         else:
             values = np.hstack((mat[:, :loc], column, mat[:, loc:]))
 
-        self.values = values
+        self._float_values = values
 
     def _delete_column(self, loc):
-        if loc == self.values.shape[1] - 1:
-            newValues = self.values[:, :loc]
+        values = self._float_values
+
+        if loc == values.shape[1] - 1:
+            new_values = values[:, :loc]
         else:
-            newValues = np.c_[self.values[:, :loc], self.values[:, loc+1:]]
-        self.values = newValues
+            new_values = np.c_[values[:, :loc], values[:, loc+1:]]
+
+        self._float_values = new_values
 
     def __iter__(self):
         """Iterate over columns of the frame."""
@@ -983,11 +994,11 @@ class DataMatrix(DataFrame):
         if self.objects is not None:
             objectsT = self.objects.values.T
             valuesT = self.values.T
-            newValues = np.concatenate((valuesT, objectsT), axis=0)
-            newIndex = Index(np.concatenate((self.columns,
-                                             self.objects.columns)))
+            new_values = np.concatenate((valuesT, objectsT), axis=0)
+            new_index = Index(np.concatenate((self.columns,
+                                              self.objects.columns)))
 
-            return DataMatrix(newValues, index=newIndex, columns=self.index)
+            return DataMatrix(new_values, index=new_index, columns=self.index)
         else:
             return DataMatrix(data=self.values.T, index=self.columns,
                               columns=self.index)
diff --git a/pandas/lib/src/groupby.pyx b/pandas/lib/src/groupby.pyx
index c34c4fd26..93707611b 100644
--- a/pandas/lib/src/groupby.pyx
+++ b/pandas/lib/src/groupby.pyx
@@ -86,3 +86,200 @@ def groupby_indices(object index, object mapper):
             result[key] = [i]
 
     return result
+
+def reduce_mean(ndarray[object, ndim=1] indices,
+                ndarray[object, ndim=1] buckets,
+                ndarray[double_t, ndim=1] values,
+                inclusive=False):
+    cdef:
+        Py_ssize_t i, j, nbuckets, nvalues
+        ndarray[double_t, ndim=1] output
+        double_t the_sum, val, nobs
+
+
+
+    nbuckets = len(buckets)
+    nvalues = len(indices)
+
+    assert(len(values) == len(indices))
+
+    output = np.empty(nbuckets, dtype=float)
+    output.fill(np.NaN)
+
+    j = 0
+    for i from 0 <= i < nbuckets:
+        next_bound = buckets[i]
+        the_sum = 0
+        nobs = 0
+        if inclusive:
+            while j < nvalues and indices[j] <= next_bound:
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+        else:
+            while j < nvalues and indices[j] < next_bound:
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+
+        if nobs > 0:
+            output[i] = the_sum / nobs
+
+        if j >= nvalues:
+            break
+
+    return output
+
+def _bucket_locs(index, buckets, inclusive=False):
+    if inclusive:
+        locs = index.searchsorted(buckets, side='left')
+    else:
+        locs = index.searchsorted(buckets, side='right')
+
+    return locs
+
+
+def ts_upsample_mean(ndarray[object, ndim=1] indices,
+                     ndarray[object, ndim=1] buckets,
+                     ndarray[double_t, ndim=1] values,
+                     inclusive=False):
+    '''
+    put something here
+    '''
+    cdef:
+        Py_ssize_t i, j, nbuckets, nvalues
+        ndarray[double_t, ndim=1] output
+        object next_bound
+        double_t the_sum, val, nobs
+
+    nbuckets = len(buckets)
+    nvalues = len(indices)
+
+    assert(len(values) == len(indices))
+
+    output = np.empty(nbuckets, dtype=float)
+    output.fill(np.NaN)
+
+    j = 0
+    for i from 0 <= i < nbuckets:
+        next_bound = buckets[i]
+        the_sum = 0
+        nobs = 0
+        if inclusive:
+            while j < nvalues and indices[j] <= next_bound:
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+        else:
+            while j < nvalues and indices[j] < next_bound:
+    cdef:
+        Py_ssize_t i, j, nbuckets, nvalues
+        ndarray[double_t, ndim=1] output
+        object next_bound
+        double_t the_sum, val, nobs
+
+    nbuckets = len(buckets)
+    nvalues = len(indices)
+
+    assert(len(values) == len(indices))
+
+    output = np.empty(nbuckets, dtype=float)
+    output.fill(np.NaN)
+
+    j = 0
+    for i from 0 <= i < nbuckets:
+        next_bound = buckets[i]
+        the_sum = 0
+        nobs = 0
+        if inclusive:
+            while j < nvalues and indices[j] <= next_bound:
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+        else:
+            while j < nvalues and indices[j] < next_bound:
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+
+        if nobs > 0:
+            output[i] = the_sum / nobs
+
+        if j >= nvalues:
+            break
+
+    return output
+                val = values[j]
+                # not NaN
+                if val == val:
+                    the_sum += val
+                    nobs += 1
+                j += 1
+
+        if nobs > 0:
+            output[i] = the_sum / nobs
+
+        if j >= nvalues:
+            break
+
+    return output
+
+def ts_upsample_generic(ndarray[object, ndim=1] indices,
+                        ndarray[object, ndim=1] buckets,
+                        ndarray[double_t, ndim=1] values,
+                        object aggfunc,
+                        inclusive=False):
+    '''
+    put something here
+    '''
+    cdef:
+        Py_ssize_t i, j, jstart, nbuckets, nvalues
+        ndarray[double_t, ndim=1] output
+        object next_bound
+        double_t the_sum, val, nobs
+
+    nbuckets = len(buckets)
+    nvalues = len(indices)
+
+    assert(len(values) == len(indices))
+
+    output = np.empty(nbuckets, dtype=float)
+    output.fill(np.NaN)
+
+    j = 0
+    for i from 0 <= i < nbuckets:
+        next_bound = buckets[i]
+        the_sum = 0
+        nobs = 0
+
+        jstart = j
+        if inclusive:
+            while j < nvalues and indices[j] <= next_bound:
+                j += 1
+        else:
+            while j < nvalues and indices[j] < next_bound:
+                j += 1
+
+        if nobs > 0:
+            output[i] = aggfunc(values[jstart:j])
+
+        if j >= nvalues:
+            break
+
+    return output
+
