commit 68fc0147f5127b25ed6b7263c21980a36a126924
Author: Jeffrey Tratner <jeffrey.tratner@gmail.com>
Date:   Fri Jun 14 22:34:17 2013 -0400

    TST: Remove explicit connectivity checks in test cases.
    
    Instead, network decorator in pandas.util.testing checks
    for that instead. You have to opt into failing on tests
    by setting `pandas.util.testing._FORCE_NETWORK_ERROR` to `True`.
    
    CLN: Move imports and test skip to top of file

diff --git a/pandas/io/tests/test_fred.py b/pandas/io/tests/test_fred.py
index 00a90ec3d..c1b59f782 100644
--- a/pandas/io/tests/test_fred.py
+++ b/pandas/io/tests/test_fred.py
@@ -26,22 +26,14 @@ class TestFred(unittest.TestCase):
         start = datetime(2010, 1, 1)
         end = datetime(2013, 01, 27)
 
-        try:
-            self.assertEquals(
-                web.DataReader("GDP", "fred", start, end)['GDP'].tail(1),
-                16004.5)
+        self.assertEquals(
+            web.DataReader("GDP", "fred", start, end)['GDP'].tail(1),
+            16004.5)
 
-            self.assertRaises(
-                Exception,
-                lambda: web.DataReader("NON EXISTENT SERIES", 'fred',
-                                       start, end))
-        except urllib2.URLError:
-            try:
-                urllib2.urlopen('http://google.com')
-            except urllib2.URLError:
-                raise nose.SkipTest
-            else:
-                raise
+        self.assertRaises(
+            Exception,
+            lambda: web.DataReader("NON EXISTENT SERIES", 'fred',
+                                   start, end))
 
     @slow
     @network
diff --git a/pandas/io/tests/test_ga.py b/pandas/io/tests/test_ga.py
index 5fa212009..05f767b99 100644
--- a/pandas/io/tests/test_ga.py
+++ b/pandas/io/tests/test_ga.py
@@ -1,26 +1,26 @@
+import os
 import unittest
-import nose
 from datetime import datetime
 
+import nose
 import pandas as pd
-import pandas.core.common as com
 from pandas import DataFrame
 from pandas.util.testing import network, assert_frame_equal
 from numpy.testing.decorators import slow
 
+try:
+    import httplib2
+    from pandas.io.ga import GAnalytics, read_ga
+    from pandas.io.auth import AuthenticationConfigError, reset_token_store
+    from pandas.io import auth
+except ImportError:
+    raise nose.SkipTest
 
 class TestGoogle(unittest.TestCase):
 
     _multiprocess_can_split_ = True
 
     def test_remove_token_store(self):
-        import os
-        try:
-            import pandas.io.auth as auth
-            from pandas.io.ga import reset_token_store
-        except ImportError:
-            raise nose.SkipTest
-
         auth.DEFAULT_TOKEN_FILE = 'test.dat'
         with open(auth.DEFAULT_TOKEN_FILE, 'w') as fh:
             fh.write('test')
@@ -31,13 +31,6 @@ class TestGoogle(unittest.TestCase):
     @slow
     @network
     def test_getdata(self):
-        try:
-            import httplib2
-            from pandas.io.ga import GAnalytics, read_ga
-            from pandas.io.auth import AuthenticationConfigError
-        except ImportError:
-            raise nose.SkipTest
-
         try:
             end_date = datetime.now()
             start_date = end_date - pd.offsets.Day() * 5
@@ -76,24 +69,10 @@ class TestGoogle(unittest.TestCase):
 
         except AuthenticationConfigError:
             raise nose.SkipTest
-        except httplib2.ServerNotFoundError:
-            try:
-                h = httplib2.Http()
-                response, content = h.request("http://www.google.com")
-                raise
-            except httplib2.ServerNotFoundError:
-                raise nose.SkipTest
 
     @slow
     @network
     def test_iterator(self):
-        try:
-            import httplib2
-            from pandas.io.ga import GAnalytics, read_ga
-            from pandas.io.auth import AuthenticationConfigError
-        except ImportError:
-            raise nose.SkipTest
-
         try:
             reader = GAnalytics()
 
@@ -129,13 +108,6 @@ class TestGoogle(unittest.TestCase):
     @slow
     @network
     def test_segment(self):
-        try:
-            import httplib2
-            from pandas.io.ga import GAnalytics, read_ga
-            from pandas.io.auth import AuthenticationConfigError
-        except ImportError:
-            raise nose.SkipTest
-
         try:
             end_date = datetime.now()
             start_date = end_date - pd.offsets.Day() * 5
@@ -186,16 +158,7 @@ class TestGoogle(unittest.TestCase):
 
         except AuthenticationConfigError:
             raise nose.SkipTest
-        except httplib2.ServerNotFoundError:
-            try:
-                h = httplib2.Http()
-                response, content = h.request("http://www.google.com")
-                raise
-            except httplib2.ServerNotFoundError:
-                raise nose.SkipTest
-
 
 if __name__ == '__main__':
-    import nose
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
                    exit=False)
diff --git a/pandas/io/tests/test_google.py b/pandas/io/tests/test_google.py
index 8c16c60ac..18ddf06d3 100644
--- a/pandas/io/tests/test_google.py
+++ b/pandas/io/tests/test_google.py
@@ -13,46 +13,22 @@ import urllib2
 
 class TestGoogle(unittest.TestCase):
 
-    @network
+    @with_connectivity_check('http://www.google.com')
     def test_google(self):
         # asserts that google is minimally working and that it throws
-        # an excecption when DataReader can't get a 200 response from
+        # an exception when DataReader can't get a 200 response from
         # google
         start = datetime(2010, 1, 1)
         end = datetime(2013, 01, 27)
 
-        try:
-            self.assertEquals(
-                web.DataReader("F", 'google', start, end)['Close'][-1],
-                13.68)
-        except urllib2.URLError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except urllib2.URLError:
-                raise nose.SkipTest
-            else:
-                raise
-
-    @network
-    def test_google_non_existent(self):
-        # asserts that google is minimally working and that it throws
-        # an excecption when DataReader can't get a 200 response from
-        # google
-        start = datetime(2010, 1, 1)
-        end = datetime(2013, 01, 27)
+        self.assertEquals(
+            web.DataReader("F", 'google', start, end)['Close'][-1],
+            13.68)
 
-        try:
-            self.assertRaises(
-                Exception,
-                lambda: web.DataReader("NON EXISTENT TICKER", 'google',
-                                      start, end))
-        except urllib2.URLError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except urllib2.URLError:
-                raise nose.SkipTest
-            else:
-                raise
+        self.assertRaises(
+            Exception,
+            lambda: web.DataReader("NON EXISTENT TICKER", 'google',
+                                start, end))
 
 
     @network
@@ -60,64 +36,40 @@ class TestGoogle(unittest.TestCase):
         self.assertRaises(NotImplementedError,
                 lambda: web.get_quote_google(pd.Series(['GOOG', 'AAPL', 'GOOG'])))
 
-    @network
+    @with_connectivity_check('http://www.google.com')
     def test_get_goog_volume(self):
-        try:
-            df = web.get_data_google('GOOG')
-            assert df.Volume.ix['OCT-08-2010'] == 2863473
-        except IOError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except IOError:
-                raise nose.SkipTest
-            else:
-                raise
+        df = web.get_data_google('GOOG')
+        assert df.Volume.ix['OCT-08-2010'] == 2863473
 
-    @network
+    @with_connectivity_check('http://www.google.com')
     def test_get_multi1(self):
-        try:
-            sl = ['AAPL', 'AMZN', 'GOOG']
-            pan = web.get_data_google(sl, '2012')
-            ts = pan.Close.GOOG.index[pan.Close.AAPL > pan.Close.GOOG]
-            assert ts[0].dayofyear == 96
-        except IOError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except IOError:
-                raise nose.SkipTest
-            else:
-                raise
+        sl = ['AAPL', 'AMZN', 'GOOG']
+        pan = web.get_data_google(sl, '2012')
+        ts = pan.Close.GOOG.index[pan.Close.AAPL > pan.Close.GOOG]
+        assert ts[0].dayofyear == 96
 
-    @network
+    @with_connectivity_check('http://www.google.com')
     def test_get_multi2(self):
-        try:
-            pan = web.get_data_google(['GE', 'MSFT', 'INTC'], 'JAN-01-12', 'JAN-31-12')
-            expected = [19.02, 28.23, 25.39]
-            result = pan.Close.ix['01-18-12'][['GE', 'MSFT', 'INTC']].tolist()
-            assert result == expected
-
-            # sanity checking
-            t= np.array(result)
-            assert     np.issubdtype(t.dtype, np.floating)
-            assert     t.shape == (3,)
-
-            expected = [[ 18.99,  28.4 ,  25.18],
-                        [ 18.58,  28.31,  25.13],
-                        [ 19.03,  28.16,  25.52],
-                        [ 18.81,  28.82,  25.87]]
-            result = pan.Open.ix['Jan-15-12':'Jan-20-12'][['GE', 'MSFT', 'INTC']].values
-            assert (result == expected).all()
-
-            # sanity checking
-            t= np.array(pan)
-            assert     np.issubdtype(t.dtype, np.floating)
-        except IOError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except IOError:
-                raise nose.SkipTest
-            else:
-                raise
+        pan = web.get_data_google(['GE', 'MSFT', 'INTC'], 'JAN-01-12', 'JAN-31-12')
+        expected = [19.02, 28.23, 25.39]
+        result = pan.Close.ix['01-18-12'][['GE', 'MSFT', 'INTC']].tolist()
+        assert result == expected
+
+        # sanity checking
+        t= np.array(result)
+        assert     np.issubdtype(t.dtype, np.floating)
+        assert     t.shape == (3,)
+
+        expected = [[ 18.99,  28.4 ,  25.18],
+                    [ 18.58,  28.31,  25.13],
+                    [ 19.03,  28.16,  25.52],
+                    [ 18.81,  28.82,  25.87]]
+        result = pan.Open.ix['Jan-15-12':'Jan-20-12'][['GE', 'MSFT', 'INTC']].values
+        assert (result == expected).all()
+
+        # sanity checking
+        t= np.array(pan)
+        assert np.issubdtype(t.dtype, np.floating)
 
 if __name__ == '__main__':
     nose.runmodule(argv=[__file__, '-vvs', '-x', '--pdb', '--pdb-failure'],
diff --git a/pandas/io/tests/test_yahoo.py b/pandas/io/tests/test_yahoo.py
index 0e2c2022a..3cf800c88 100644
--- a/pandas/io/tests/test_yahoo.py
+++ b/pandas/io/tests/test_yahoo.py
@@ -4,12 +4,7 @@ from datetime import datetime
 
 import pandas as pd
 import pandas.io.data as web
-from pandas.util.testing import (network, assert_frame_equal,
-                                 assert_series_equal,
-                                 assert_almost_equal)
-from numpy.testing.decorators import slow
-
-import urllib2
+from pandas.util.testing import network, assert_series_equal
 
 
 class TestYahoo(unittest.TestCase):
@@ -22,23 +17,14 @@ class TestYahoo(unittest.TestCase):
         start = datetime(2010, 1, 1)
         end = datetime(2013, 01, 27)
 
-        try:
-            self.assertEquals(
-                web.DataReader("F", 'yahoo', start, end)['Close'][-1],
-                13.68)
+        self.assertEquals(
+            web.DataReader("F", 'yahoo', start, end)['Close'][-1],
+            13.68)
 
-            self.assertRaises(
-                Exception,
-                lambda: web.DataReader("NON EXISTENT TICKER", 'yahoo',
+        self.assertRaises(
+            Exception,
+            lambda: web.DataReader("NON EXISTENT TICKER", 'yahoo',
                                       start, end))
-        except urllib2.URLError:
-            try:
-                urllib2.urlopen('http://www.google.com')
-            except urllib2.URLError:
-                raise nose.SkipTest
-            else:
-                raise
-
 
     @network
     def test_get_quote(self):
