commit 604273c8aa3ecdae112d4ecf086375aa6d926cab
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Dec 31 15:59:08 2011 -0500

    ENH: perf opt, don't take when indexes are equivalent, merge unit testing / bugfix

diff --git a/RELEASE.rst b/RELEASE.rst
index 4cbb174de..c686bf0d0 100644
--- a/RELEASE.rst
+++ b/RELEASE.rst
@@ -22,21 +22,11 @@ Where to get it
 * Binary installers on PyPI: http://pypi.python.org/pypi/pandas
 * Documentation: http://pandas.sourceforge.net
 
-pandas 0.6.2
+pandas 0.7.0
 ============
 
 **Release date:** NOT YET RELEASED
 
-**API Changes**
-
-  - Rename ``DataFrame.delevel`` to ``DataFrame.reset_index`` and add
-    deprecation warning
-  - `Series.sort` (an in-place operation) called on a Series which is a view on
-    a larger array (e.g. a column in a DataFrame) will generate an Exception to
-    prevent accidentally modifying the data source (GH #316)
-  - Refactor to remove deprecated ``LongPanel`` class (PR #552)
-  - Deprecated ``Panel.to_long``, renamed to ``to_frame``
-
 **New features / modules**
 
   - New ``merge`` function for efficiently performing full gamut of database /
@@ -57,6 +47,16 @@ pandas 0.6.2
   - Add ``level`` option to the ``reindex`` and ``align`` methods on Series and
     DataFrame for broadcasting values across a level (GH #542, PR #552, others)
 
+**API Changes**
+
+  - Rename ``DataFrame.delevel`` to ``DataFrame.reset_index`` and add
+    deprecation warning
+  - `Series.sort` (an in-place operation) called on a Series which is a view on
+    a larger array (e.g. a column in a DataFrame) will generate an Exception to
+    prevent accidentally modifying the data source (GH #316)
+  - Refactor to remove deprecated ``LongPanel`` class (PR #552)
+  - Deprecated ``Panel.to_long``, renamed to ``to_frame``
+
 **Improvements to existing features**
 
   - Better error message in DataFrame constructor when passed column labels
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index c83fdc216..5132f3040 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -41,7 +41,7 @@ import pandas.core.datetools as datetools
 import pandas._tseries as lib
 
 #----------------------------------------------------------------------
-# Factory helper methods
+# Docstring templates
 
 _arith_doc = """
 Binary operator %s with support to substitute a fill_value for missing data in
@@ -95,6 +95,65 @@ _numeric_only_doc = """numeric_only : boolean, default None
     everything, then use only numeric data
 """
 
+_merge_doc = """
+Merge DataFrame objects by performing a database-style join operation by
+columns or indexes.
+
+If joining columns on columns, the DataFrame indexes *will be
+ignored*. Otherwise if joining indexes on indexes or indexes on a column or
+columns, the index will be passed on.
+
+Parameters
+----------%s
+right : DataFrame
+how : {'left', 'right', 'outer', 'inner'}, default 'left'
+    * left: use only keys from left frame (SQL: left outer join)
+    * right: use only keys from right frame (SQL: right outer join)
+    * outer: use union of keys from both frames (SQL: full outer join)
+    * inner: use intersection of keys from both frames (SQL: inner join)
+on : label or list
+    Field names to join on. Must be found in both DataFrames.
+left_on : label or list, or array-like
+    Field names to join on in left DataFrame. Can be a vector or list of
+    vectors of the length of the DataFrame to use a particular vector as
+    the join key instead of columns
+right_on : label or list, or array-like
+    Field names to join on in right DataFrame or vector/list of vectors per
+    left_on docs
+left_index : boolean, default True
+    Use the index from the left DataFrame as the join key(s). If it is a
+    MultiIndex, the number of keys in the other DataFrame (either the index
+    or a number of columns) must match the number of levels
+right_index : boolean, default True
+    Use the index from the right DataFrame as the join key. Same caveats as
+    left_index
+sort : boolean, default True
+    Sort the join keys lexicographically in the result DataFrame
+suffixes : 2-length sequence (tuple, list, ...)
+    Suffix to apply to overlapping column names in the left and right
+    side, respectively
+copy : boolean, default True
+    If False, do not copy data unnecessarily
+
+Examples
+--------
+
+A                  B
+
+    lkey value         rkey value
+0   foo  1         0   foo  5
+1   bar  2         1   bar  6
+2   baz  3         2   qux  7
+3   foo  4
+
+merge(A, B, left_on='lkey', right_on='rkey', how='outer')
+
+
+Returns
+-------
+merged : DataFrame
+"""
+
 def _add_stat_doc(f, name, shortname, na_action=_doc_exclude_na,
                   extras=''):
     doc = _stat_doc % {'name' : name,
@@ -103,6 +162,10 @@ def _add_stat_doc(f, name, shortname, na_action=_doc_exclude_na,
                        'extras' : extras}
     f.__doc__ = doc
 
+
+#----------------------------------------------------------------------
+# Factory helper methods
+
 def _arith_method(func, name, default_axis='columns'):
     def f(self, other, axis=default_axis, level=None, fill_value=None):
         if isinstance(other, DataFrame):    # Another DataFrame
@@ -1350,8 +1413,8 @@ class DataFrame(NDFrame):
 
         Returns
         -------
-        (left, right) : (Series, Series)
-            Aligned Series
+        (left, right) : (DataFrame, type of other)
+            Aligned objects
         """
         if isinstance(other, DataFrame):
             return self._align_frame(other, join=join, axis=axis, level=level,
@@ -2777,33 +2840,15 @@ class DataFrame(NDFrame):
                      left_index=on is None, right_index=True,
                      suffixes=(lsuffix, rsuffix))
 
-    # def _join_on(self, other, on, how, lsuffix, rsuffix):
-    #     if how not in ('left', 'inner'):  # pragma: no cover
-    #         raise Exception('Only inner / left joins currently supported')
-
-    #     if isinstance(on, (list, tuple)):
-    #         if len(on) == 1:
-    #             join_key = self[on[0]].values
-    #         else:
-    #             join_key = lib.fast_zip([self[k] for k in on])
-    #     elif isinstance(on, np.ndarray) and len(on) == len(self):
-    #         join_key = on
-    #     else:
-    #         join_key = self[on].values
-
-    #     new_data = self._data.join_on(other._data, join_key, how=how, axis=1,
-    #                                   lsuffix=lsuffix, rsuffix=rsuffix)
-    #     return self._constructor(new_data)
-
-    # def _join_index(self, other, how, lsuffix, rsuffix):
-    #     from pandas.tools.merge import join_managers
-
-    #     thisdata, otherdata = self._data._maybe_rename_join(
-    #         other._data, lsuffix, rsuffix, copydata=False)
-
-    #     # this will always ensure copied data
-    #     merged_data = join_managers(thisdata, otherdata, axis=1, how=how)
-    #     return self._constructor(merged_data)
+    def merge(self, right, how='left', on=None, left_on=None, right_on=None,
+              left_index=False, right_index=False, sort=True,
+              suffixes=('.x', '.y'), copy=True):
+        from pandas.tools.merge import merge
+        return merge(self, right, how=how, on=on,
+                     left_on=left_on, right_on=right_on,
+                     left_index=left_index, right_index=right_index, sort=sort,
+                     suffixes=suffixes, copy=copy)
+    if __debug__: merge.__doc__ = _merge_doc % ''
 
     #----------------------------------------------------------------------
     # Statistical methods, etc.
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 57bcd6579..301beae24 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -561,7 +561,10 @@ class Index(np.ndarray):
             _, indexer, _ = self._join_level(target, level, how='left',
                                                   return_indexers=True)
         else:
-            indexer = self.get_indexer(target, method=method)
+            if self.equals(target):
+                indexer = None
+            else:
+                indexer = self.get_indexer(target, method=method)
         return target, indexer
 
     def join(self, other, how='left', level=None, return_indexers=False):
@@ -1481,10 +1484,15 @@ class MultiIndex(Index):
             target, _, indexer = self._join_level(target, level, how='left',
                                                   return_indexers=True)
         else:
-            indexer = self.get_indexer(target, method=method)
+            if self.equals(target):
+                indexer = None
+            else:
+                indexer = self.get_indexer(target, method=method)
 
         if not isinstance(target, MultiIndex):
-            if (indexer >= 0).all():
+            if indexer is None:
+                target = self
+            elif (indexer >= 0).all():
                 target = self.take(indexer)
             else:
                 # hopefully?
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index ff96bf4ec..342c7fba6 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -127,16 +127,20 @@ class Block(object):
         reindexed : Block
         """
         new_ref_items, indexer = self.items.reindex(new_ref_items)
-        mask = indexer != -1
-        masked_idx = indexer[mask]
-
-        if self.values.ndim == 2:
-            new_values = com.take_2d(self.values, masked_idx, axis=0,
-                                     needs_masking=False)
+        if indexer is None:
+            new_items = new_ref_items
+            new_values = self.values.copy()
         else:
-            new_values = self.values.take(masked_idx, axis=0)
+            mask = indexer != -1
+            masked_idx = indexer[mask]
+
+            if self.values.ndim == 2:
+                new_values = com.take_2d(self.values, masked_idx, axis=0,
+                                         needs_masking=False)
+            else:
+                new_values = self.values.take(masked_idx, axis=0)
 
-        new_items = self.items.take(masked_idx)
+            new_items = self.items.take(masked_idx)
         return make_block(new_values, new_items, new_ref_items)
 
     def get(self, item):
@@ -727,7 +731,6 @@ class BlockManager(object):
 
         # TODO: this part could be faster (!)
         new_items, indexer = self.items.reindex(new_items)
-        mask = indexer == -1
 
         new_blocks = []
         for block in self.blocks:
@@ -735,11 +738,13 @@ class BlockManager(object):
             if len(newb.items) > 0:
                 new_blocks.append(newb)
 
-        if mask.any():
-            extra_items = new_items[mask]
-            na_block = self._make_na_block(extra_items, new_items)
-            new_blocks.append(na_block)
-            new_blocks = _consolidate(new_blocks, new_items)
+        if indexer is not None:
+            mask = indexer == -1
+            if mask.any():
+                extra_items = new_items[mask]
+                na_block = self._make_na_block(extra_items, new_items)
+                new_blocks.append(na_block)
+                new_blocks = _consolidate(new_blocks, new_items)
 
         return BlockManager(new_blocks, [new_items] + self.axes[1:])
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 4d4d245f5..40c458513 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -1555,7 +1555,10 @@ copy : boolean, default False
 
         new_index, fill_vec = self.index.reindex(index, method=method,
                                                  level=level)
-        new_values = com.take_1d(self.values, fill_vec)
+        if fill_vec is None:
+            new_values = self.values.copy() if copy else self.values
+        else:
+            new_values = com.take_1d(self.values, fill_vec)
         return Series(new_values, index=new_index, name=self.name)
 
     def reindex_like(self, other, method=None):
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index 647e919a7..52ce29b4d 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -4,7 +4,7 @@ SQL-style merge routines
 
 import numpy as np
 
-from pandas.core.frame import DataFrame
+from pandas.core.frame import DataFrame, _merge_doc
 from pandas.core.groupby import get_group_index
 from pandas.core.index import Index, MultiIndex
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
@@ -17,53 +17,12 @@ import pandas._tseries as lib
 def merge(left, right, how='left', on=None, left_on=None, right_on=None,
           left_index=False, right_index=False, sort=True,
           suffixes=('.x', '.y'), copy=True):
-    """
-    Merge DataFrame objects by performing a database-style join operation by
-    columns or indexes
-
-    Parameters
-    ----------
-    left : DataFrame
-    right : DataFrame
-    how : {'left', 'right', 'outer', 'inner'}, default 'left'
-        * left: use only keys from left frame (SQL: left outer join)
-        * right: use only keys from right frame (SQL: right outer join)
-        * outer: use union of keys from both frames (SQL: full outer join)
-        * inner: use intersection of keys from both frames (SQL: inner join)
-    on : label or list
-        Field names to join on. Must be found in both DataFrames.
-    left_on : label or list, or array-like
-        Field names to join on in left DataFrame. Can be a vector or list of
-        vectors of the length of the DataFrame to use a particular vector as
-        the join key instead of columns
-    right_on : label or list, or array-like
-        Field names to join on in right DataFrame or vector/list of vectors per
-        left_on docs
-    left_index : boolean, default True
-        Use the index from the left DataFrame as the join key(s). If it is a
-        MultiIndex, the number of keys in the other DataFrame (either the index
-        or a number of columns) must match the number of levels
-    right_index : boolean, default True
-        Use the index from the right DataFrame as the join key. Same caveats as
-        left_index
-    sort : boolean, default True
-        Sort the join keys lexicographically in the result DataFrame
-    suffixes : 2-length sequence (tuple, list, ...)
-        Suffix to apply to overlapping column names in the left and right
-        side, respectively
-    copy : boolean, default True
-        If False, do not copy data unnecessarily
-
-    Returns
-    -------
-    merged : DataFrame
-    """
     op = _MergeOperation(left, right, how=how, on=on, left_on=left_on,
                          right_on=right_on, left_index=left_index,
                          right_index=right_index, sort=sort, suffixes=suffixes,
                          copy=copy)
     return op.get_result()
-
+if __debug__: merge.__doc__ = _merge_doc % '\nleft : DataFrame'
 
 # TODO: NA group handling
 # TODO: transformations??
@@ -87,6 +46,8 @@ class _MergeOperation(object):
         self.left_on = _maybe_make_list(left_on)
         self.right_on = _maybe_make_list(right_on)
 
+        self.drop_keys = False # set this later...kludge
+
         self.copy = copy
 
         self.suffixes = suffixes
@@ -119,7 +80,7 @@ class _MergeOperation(object):
         return result
 
     def _maybe_add_join_keys(self, result, left_indexer, right_indexer):
-        if self.left_index or self.right_index:
+        if not self.drop_keys:
             # do nothing, already found in one of the DataFrames
             return
 
@@ -143,7 +104,6 @@ class _MergeOperation(object):
             join_index = left_ax
             left_indexer = None
 
-            # oh this is odious
             if len(self.left_join_keys) > 1:
                 assert(isinstance(right_ax, MultiIndex) and
                        len(self.left_join_keys) == right_ax.nlevels)
@@ -157,7 +117,6 @@ class _MergeOperation(object):
             join_index = right_ax
             right_indexer = None
 
-            # oh this is odious
             if len(self.right_join_keys) > 1:
                 assert(isinstance(left_ax, MultiIndex) and
                        len(self.right_join_keys) == left_ax.nlevels)
@@ -215,8 +174,6 @@ class _MergeOperation(object):
         # Hm, any way to make this logic less complicated??
         join_names = []
 
-        drop = False
-
         if (self.on is None and self.left_on is None
             and self.right_on is None):
 
@@ -232,26 +189,26 @@ class _MergeOperation(object):
                 # use the common columns
                 common_cols = self.left.columns.intersection(self.right.columns)
                 self.left_on = self.right_on = common_cols
-                drop = True
+                self.drop_keys = True
 
         elif self.on is not None:
             if self.left_on is not None or self.right_on is not None:
                 raise Exception('Can only pass on OR left_on and '
                                 'right_on')
             self.left_on = self.right_on = self.on
-            drop = True
+            self.drop_keys = True
 
         # this is a touch kludgy, but accomplishes the goal
         if self.right_on is not None:
             self.right, right_keys, right_names = \
-                _get_keys(self.right, self.right_on, drop=drop)
+                _get_keys(self.right, self.right_on, drop=self.drop_keys)
             join_names = right_names
         else:
             right_keys = [self.right.index.values]
 
         if self.left_on is not None:
             self.left, left_keys, left_names = \
-                _get_keys(self.left, self.left_on, drop=drop)
+                _get_keys(self.left, self.left_on, drop=self.drop_keys)
             join_names = left_names
         else:
             left_keys = [self.left.index.values]
@@ -316,7 +273,7 @@ def _get_multiindex_indexer(join_keys, index):
     shape = []
     labels = []
     for level, key in zip(index.levels, join_keys):
-        rizer = lib.DictFactorizer(level.indexMap, list(level))
+        rizer = lib.DictFactorizer(level.indexMap.copy(), list(level))
         lab, _ = rizer.factorize(key)
         labels.append(lab)
         shape.append(len(rizer.uniques))
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 385621029..8f06954f7 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -7,7 +7,8 @@ import random
 
 from pandas import *
 from pandas.tools.merge import merge
-from pandas.util.testing import assert_frame_equal, assert_series_equal
+from pandas.util.testing import (assert_frame_equal, assert_series_equal,
+                                 assert_almost_equal)
 import pandas._tseries as lib
 import pandas.util.testing as tm
 
@@ -46,6 +47,18 @@ class TestMerge(unittest.TestCase):
                                                       n=N//5),
                               'value' : np.random.randn(N // 5)})
 
+        index, data = tm.getMixedTypeDict()
+        self.target = DataFrame(data, index=index)
+
+        # Join on string value
+        self.source = DataFrame({'MergedA' : data['A'], 'MergedD' : data['D']},
+                                index=data['C'])
+
+        self.left = DataFrame({'key' : ['a', 'b', 'c', 'd', 'e', 'e', 'a'],
+                          'v1' : np.random.randn(7)})
+        self.right = DataFrame({'v2' : np.random.randn(4)},
+                           index=['d', 'b', 'c', 'a'])
+
     def test_cython_left_outer_join(self):
         left = a_([0, 1, 2, 1, 2, 0, 0, 1, 2, 3, 3], dtype='i4')
         right = a_([1, 1, 0, 4, 2, 2, 1], dtype='i4')
@@ -167,88 +180,6 @@ class TestMerge(unittest.TestCase):
         exp = merge(self.df, self.df2, on=['key1', 'key2'])
         tm.assert_frame_equal(joined, exp)
 
-    def test_merge_index(self):
-        pass
-
-def _check_join(left, right, result, join_col, how='left',
-                lsuffix='.x', rsuffix='.y'):
-
-    # some smoke tests
-    for c in join_col:
-        assert(result[c].notnull().all())
-
-    left_grouped = left.groupby(join_col)
-    right_grouped = right.groupby(join_col)
-
-    for group_key, group in result.groupby(join_col):
-        l_joined = _restrict_to_columns(group, left.columns, lsuffix)
-        r_joined = _restrict_to_columns(group, right.columns, rsuffix)
-
-        try:
-            lgroup = left_grouped.get_group(group_key)
-        except KeyError:
-            if how in ('left', 'inner'):
-                raise AssertionError('key %s should not have been in the join'
-                                     % str(group_key))
-
-            _assert_all_na(l_joined, left.columns, join_col)
-        else:
-            _assert_same_contents(l_joined, lgroup)
-
-        try:
-            rgroup = right_grouped.get_group(group_key)
-        except KeyError:
-            if how in ('right', 'inner'):
-                raise AssertionError('key %s should not have been in the join'
-                                     % str(group_key))
-
-            _assert_all_na(r_joined, right.columns, join_col)
-        else:
-            _assert_same_contents(r_joined, rgroup)
-
-
-def _restrict_to_columns(group, columns, suffix):
-    found = [c for c in group.columns
-             if c in columns or c.replace(suffix, '') in columns]
-
-     # filter
-    group = group.ix[:, found]
-
-    # get rid of suffixes, if any
-    group = group.rename(columns=lambda x: x.replace(suffix, ''))
-
-    # put in the right order...
-    group = group.ix[:, columns]
-
-    return group
-
-def _assert_same_contents(join_chunk, source):
-    NA_SENTINEL = -1234567 # drop_duplicates not so NA-friendly...
-
-    jvalues = join_chunk.fillna(NA_SENTINEL).drop_duplicates().values
-    svalues = source.fillna(NA_SENTINEL).drop_duplicates().values
-
-    rows = set(tuple(row) for row in jvalues)
-    assert(len(rows) == len(source))
-    assert(all(tuple(row) in rows for row in svalues))
-
-def _assert_all_na(join_chunk, source_columns, join_col):
-    for c in source_columns:
-        if c in join_col:
-            continue
-        assert(join_chunk[c].isnull().all())
-
-
-class TestDataFrameJoin(unittest.TestCase):
-
-    def setUp(self):
-        index, data = tm.getMixedTypeDict()
-        self.target = DataFrame(data, index=index)
-
-        # Join on string value
-        self.source = DataFrame({'MergedA' : data['A'], 'MergedD' : data['D']},
-                                index=data['C'])
-
     def test_join_on(self):
         target = self.target
         source = self.source
@@ -327,36 +258,6 @@ class TestDataFrameJoin(unittest.TestCase):
 
         assert_frame_equal(joined, expected)
 
-    def test_join_on_multikey(self):
-        index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
-                                   ['one', 'two', 'three']],
-                           labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
-                                   [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
-                           names=['first', 'second'])
-        to_join = DataFrame(np.random.randn(10, 3), index=index,
-                            columns=['j_one', 'j_two', 'j_three'])
-
-        # a little relevant example with NAs
-        key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux',
-                'qux', 'snap']
-        key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',
-                'three', 'one']
-
-        data = np.random.randn(len(key1))
-        data = DataFrame({'key1' : key1, 'key2' : key2,
-                          'data' : data})
-
-        joined = data.join(to_join, on=['key1', 'key2'])
-
-        join_key = Index(zip(key1, key2))
-        indexer = to_join.index.get_indexer(join_key)
-        ex_values = to_join.values.take(indexer, axis=0)
-        ex_values[indexer == -1] = np.nan
-        expected = data.join(DataFrame(ex_values, columns=to_join.columns))
-
-        # TODO: columns aren't in the same order yet
-        assert_frame_equal(joined, expected.ix[:, joined.columns])
-
     def test_join_on_series(self):
         result = self.target.join(self.source['MergedA'], on='C')
         expected = self.target.join(self.source[['MergedA']], on='C')
@@ -456,6 +357,176 @@ class TestDataFrameJoin(unittest.TestCase):
         expected = a.join(b.astype('f8'))
         assert_frame_equal(joined, expected)
 
+    def test_merge_index_singlekey_right_vs_left(self):
+        left = DataFrame({'key' : ['a', 'b', 'c', 'd', 'e', 'e', 'a'],
+                          'v1' : np.random.randn(7)})
+        right = DataFrame({'v2' : np.random.randn(4)},
+                           index=['d', 'b', 'c', 'a'])
+
+        merged1 = merge(left, right, left_on='key',
+                        right_index=True, how='left')
+        merged2 = merge(right, left, right_on='key',
+                        left_index=True, how='right')
+        assert_frame_equal(merged1, merged2.ix[:, merged1.columns])
+
+    def test_merge_index_singlekey_inner(self):
+        left = DataFrame({'key' : ['a', 'b', 'c', 'd', 'e', 'e', 'a'],
+                          'v1' : np.random.randn(7)})
+        right = DataFrame({'v2' : np.random.randn(4)},
+                           index=['d', 'b', 'c', 'a'])
+
+        # inner join
+        result = merge(left, right, left_on='key', right_index=True,
+                       how='inner')
+        expected = left.join(right, on='key').ix[result.index]
+        assert_frame_equal(result, expected)
+
+        result = merge(right, left, right_on='key', left_index=True,
+                       how='inner')
+        expected = left.join(right, on='key').ix[result.index]
+        assert_frame_equal(result, expected.ix[:, result.columns])
+
+    def test_merge_misspecified(self):
+        self.assertRaises(Exception, merge, self.left,
+                          self.right, left_index=True)
+        self.assertRaises(Exception, merge, self.left,
+                          self.right, right_index=True)
+
+    def test_merge_overlap(self):
+        merged = merge(self.left, self.left, on='key')
+        exp_len = (self.left['key'].value_counts() ** 2).sum()
+        self.assertEqual(len(merged), exp_len)
+        self.assert_('v1.x' in merged)
+        self.assert_('v1.y' in merged)
+
+    def test_merge_different_column_key_names(self):
+        left = DataFrame({'lkey' : ['foo', 'bar', 'baz', 'foo'],
+                          'value' : [1, 2, 3, 4]})
+        right = DataFrame({'rkey' : ['foo', 'bar', 'qux', 'foo'],
+                           'value' : [5, 6, 7, 8]})
+
+        merged = left.merge(right, left_on='lkey', right_on='rkey',
+                            how='outer')
+
+        assert_almost_equal(merged['lkey'],
+                            ['bar', 'baz', 'foo', 'foo', 'foo', 'foo', np.nan])
+        assert_almost_equal(merged['rkey'],
+                            ['bar', np.nan, 'foo', 'foo', 'foo', 'foo', 'qux'])
+        assert_almost_equal(merged['value.x'], [2, 3, 1, 1, 4, 4, np.nan])
+        assert_almost_equal(merged['value.y'], [6, np.nan, 5, 8, 5, 8, 7])
+
+class TestMergeMulti(unittest.TestCase):
+
+    def setUp(self):
+        self.index = MultiIndex(levels=[['foo', 'bar', 'baz', 'qux'],
+                                        ['one', 'two', 'three']],
+                                labels=[[0, 0, 0, 1, 1, 2, 2, 3, 3, 3],
+                                        [0, 1, 2, 0, 1, 1, 2, 0, 1, 2]],
+                                names=['first', 'second'])
+        self.to_join = DataFrame(np.random.randn(10, 3), index=self.index,
+                                 columns=['j_one', 'j_two', 'j_three'])
+
+        # a little relevant example with NAs
+        key1 = ['bar', 'bar', 'bar', 'foo', 'foo', 'baz', 'baz', 'qux',
+                'qux', 'snap']
+        key2 = ['two', 'one', 'three', 'one', 'two', 'one', 'two', 'two',
+                'three', 'one']
+
+        data = np.random.randn(len(key1))
+        self.data = DataFrame({'key1' : key1, 'key2' : key2,
+                               'data' : data})
+
+    def test_merge_on_multikey(self):
+        joined = self.data.join(self.to_join, on=['key1', 'key2'])
+
+        join_key = Index(zip(self.data['key1'], self.data['key2']))
+        indexer = self.to_join.index.get_indexer(join_key)
+        ex_values = self.to_join.values.take(indexer, axis=0)
+        ex_values[indexer == -1] = np.nan
+        expected = self.data.join(DataFrame(ex_values,
+                                            columns=self.to_join.columns))
+
+        # TODO: columns aren't in the same order yet
+        assert_frame_equal(joined, expected.ix[:, joined.columns])
+
+    def test_merge_right_vs_left(self):
+        # compare left vs right merge with multikey
+        merged1 = self.data.merge(self.to_join, left_on=['key1', 'key2'],
+                                  right_index=True, how='left')
+        merged2 = self.to_join.merge(self.data, right_on=['key1', 'key2'],
+                                     left_index=True, how='right')
+        merged2 = merged2.ix[:, merged1.columns]
+        assert_frame_equal(merged1, merged2)
+
+def _check_join(left, right, result, join_col, how='left',
+                lsuffix='.x', rsuffix='.y'):
+
+    # some smoke tests
+    for c in join_col:
+        assert(result[c].notnull().all())
+
+    left_grouped = left.groupby(join_col)
+    right_grouped = right.groupby(join_col)
+
+    for group_key, group in result.groupby(join_col):
+        l_joined = _restrict_to_columns(group, left.columns, lsuffix)
+        r_joined = _restrict_to_columns(group, right.columns, rsuffix)
+
+        try:
+            lgroup = left_grouped.get_group(group_key)
+        except KeyError:
+            if how in ('left', 'inner'):
+                raise AssertionError('key %s should not have been in the join'
+                                     % str(group_key))
+
+            _assert_all_na(l_joined, left.columns, join_col)
+        else:
+            _assert_same_contents(l_joined, lgroup)
+
+        try:
+            rgroup = right_grouped.get_group(group_key)
+        except KeyError:
+            if how in ('right', 'inner'):
+                raise AssertionError('key %s should not have been in the join'
+                                     % str(group_key))
+
+            _assert_all_na(r_joined, right.columns, join_col)
+        else:
+            _assert_same_contents(r_joined, rgroup)
+
+
+def _restrict_to_columns(group, columns, suffix):
+    found = [c for c in group.columns
+             if c in columns or c.replace(suffix, '') in columns]
+
+     # filter
+    group = group.ix[:, found]
+
+    # get rid of suffixes, if any
+    group = group.rename(columns=lambda x: x.replace(suffix, ''))
+
+    # put in the right order...
+    group = group.ix[:, columns]
+
+    return group
+
+def _assert_same_contents(join_chunk, source):
+    NA_SENTINEL = -1234567 # drop_duplicates not so NA-friendly...
+
+    jvalues = join_chunk.fillna(NA_SENTINEL).drop_duplicates().values
+    svalues = source.fillna(NA_SENTINEL).drop_duplicates().values
+
+    rows = set(tuple(row) for row in jvalues)
+    assert(len(rows) == len(source))
+    assert(all(tuple(row) in rows for row in svalues))
+
+def _assert_all_na(join_chunk, source_columns, join_col):
+    for c in source_columns:
+        if c in join_col:
+            continue
+        assert(join_chunk[c].isnull().all())
+
+
 def _join_by_hand(a, b, how='left'):
     join_index = a.index.join(b.index, how=how)
 
