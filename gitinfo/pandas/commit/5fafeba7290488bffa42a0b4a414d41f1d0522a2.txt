commit 5fafeba7290488bffa42a0b4a414d41f1d0522a2
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Fri May 4 10:04:43 2012 -0400

    ENH: speed up Series.__getitem__ with timestamps, much more efficient implementation of Series.asof, close #1168

diff --git a/pandas/core/algorithms.py b/pandas/core/algorithms.py
index 4aec37144..a91e38fda 100644
--- a/pandas/core/algorithms.py
+++ b/pandas/core/algorithms.py
@@ -140,6 +140,7 @@ def value_counts(values, sort=True, ascending=False):
 
     return result
 
+
 def rank(values, axis=0, method='average', na_option='keep',
          ascending=True):
     """
diff --git a/pandas/core/daterange.py b/pandas/core/daterange.py
index 74d4f6790..4bf6ee5a1 100644
--- a/pandas/core/daterange.py
+++ b/pandas/core/daterange.py
@@ -43,8 +43,3 @@ class DateRange(Index):
         self.offset = offset
         self.tzinfo = tzinfo
         Index.__setstate__(self, *index_state)
-
-def interval_range():
-    """
-    Return a fixed frequency interval index
-    """
diff --git a/pandas/core/index.py b/pandas/core/index.py
index e4496772f..411421be7 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -11,7 +11,6 @@ from pandas.util.decorators import cache_readonly
 from pandas.util import py3compat
 import pandas.core.common as com
 import pandas._tseries as lib
-import pandas._engines as _gin
 
 
 __all__ = ['Index']
@@ -65,7 +64,7 @@ class Index(np.ndarray):
     name = None
     asi8 = None
 
-    _engine_type = _gin.ObjectEngine
+    _engine_type = lib.ObjectEngine
 
     def __new__(cls, data, dtype=None, copy=False, name=None):
         if isinstance(data, np.ndarray):
@@ -385,6 +384,20 @@ class Index(np.ndarray):
 
         return label
 
+    def asof_locs(self, where, mask):
+        """
+
+        """
+        locs = self.values[mask].searchsorted(where.values, side='right')
+        locs = np.where(locs > 0, locs - 1, 0)
+
+        result = np.arange(len(self))[mask].take(locs)
+
+        first = mask.argmax()
+        result[(locs == 0) & (where < self.values[first])] = -1
+
+        return result
+
     def order(self, return_indexer=False, ascending=True):
         """
         Return sorted copy of Index
@@ -611,7 +624,7 @@ class Index(np.ndarray):
                 raise
 
             try:
-                return _gin.get_value_at(series, key)
+                return lib.get_value_at(series, key)
             except IndexError:
                 raise
             except TypeError:
@@ -1053,7 +1066,7 @@ class Int64Index(Index):
     _inner_indexer = lib.inner_join_indexer_int64
     _outer_indexer = lib.outer_join_indexer_int64
 
-    _engine_type = _gin.Int64Engine
+    _engine_type = lib.Int64Engine
 
     def __new__(cls, data, dtype=None, copy=False, name=None):
         if not isinstance(data, np.ndarray):
@@ -1283,7 +1296,7 @@ class MultiIndex(Index):
                 pass
 
             try:
-                return _gin.get_value_at(series, key)
+                return lib.get_value_at(series, key)
             except IndexError:
                 raise
             except TypeError:
@@ -2340,3 +2353,4 @@ def _maybe_box_dtindex(idx):
     if isinstance(idx, DatetimeIndex):
         return Index(_dt_box_array(idx.asi8), dtype='object')
     return idx
+
diff --git a/pandas/core/series.py b/pandas/core/series.py
index db995165d..d266707ae 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -219,7 +219,7 @@ def _unbox(func):
     return f
 
 _stat_doc = """
-Return %(name)s  of values
+Return %(name)s of values
 %(na_action)s
 
 Parameters
@@ -238,7 +238,21 @@ _doc_exclude_na = "NA/null values are excluded"
 _doc_ndarray_interface = ("Extra parameters are to preserve ndarray"
                           "interface.\n")
 
-#-------------------------------------------------------------------------------
+
+def _make_stat_func(nanop, name, shortname, na_action=_doc_exclude_na,
+                    extras=_doc_ndarray_interface):
+
+    @Substitution(name=name, shortname=shortname,
+                  na_action=na_action, extras=extras)
+    @Appender(_stat_doc)
+    def f(self, axis=0, dtype=None, out=None, skipna=True, level=None):
+        if level is not None:
+            return self._agg_by_level(shortname, level=level, skipna=skipna)
+        return nanop(self.values, skipna=skipna)
+    f.__name__ = shortname
+    return f
+
+#----------------------------------------------------------------------
 # Series class
 
 class Series(np.ndarray, generic.PandasObject):
@@ -985,21 +999,10 @@ copy : boolean, default False
         """
         return len(self.value_counts())
 
-    @Substitution(name='sum', shortname='sum', na_action=_doc_exclude_na,
-                  extras=_doc_ndarray_interface)
-    @Appender(_stat_doc)
-    def sum(self, axis=0, dtype=None, out=None, skipna=True, level=None):
-        if level is not None:
-            return self._agg_by_level('sum', level=level, skipna=skipna)
-        return nanops.nansum(self.values, skipna=skipna)
-
-    @Substitution(name='mean', shortname='mean', na_action=_doc_exclude_na,
-                  extras=_doc_ndarray_interface)
-    @Appender(_stat_doc)
-    def mean(self, axis=0, dtype=None, out=None, skipna=True, level=None):
-        if level is not None:
-            return self._agg_by_level('mean', level=level, skipna=skipna)
-        return nanops.nanmean(self.values, skipna=skipna)
+    sum = _make_stat_func(nanops.nansum, 'sum', 'sum')
+    mean = _make_stat_func(nanops.nanmean, 'mean', 'mean')
+    median = _make_stat_func(nanops.nanmedian, 'median', 'median', extras='')
+    prod = _make_stat_func(nanops.nanprod, 'product', 'prod', extras='')
 
     @Substitution(name='mean absolute deviation', shortname='mad',
                   na_action=_doc_exclude_na, extras='')
@@ -1011,22 +1014,6 @@ copy : boolean, default False
         demeaned = self - self.mean(skipna=skipna)
         return np.abs(demeaned).mean(skipna=skipna)
 
-    @Substitution(name='median', shortname='median',
-                  na_action=_doc_exclude_na, extras='')
-    @Appender(_stat_doc)
-    def median(self, skipna=True, level=None):
-        if level is not None:
-            return self._agg_by_level('median', level=level, skipna=skipna)
-        return nanops.nanmedian(self.values, skipna=skipna)
-
-    @Substitution(name='product', shortname='product',
-                  na_action=_doc_exclude_na, extras='')
-    @Appender(_stat_doc)
-    def prod(self, axis=None, dtype=None, out=None, skipna=True, level=None):
-        if level is not None:
-            return self._agg_by_level('prod', level=level, skipna=skipna)
-        return nanops.nanprod(self.values, skipna=skipna)
-
     @Substitution(name='minimum', shortname='min',
                   na_action=_doc_exclude_na, extras='')
     @Appender(_stat_doc)
@@ -2278,7 +2265,7 @@ copy : boolean, default False
             return Series(self, index=self.index.shift(periods, offset),
                           name=self.name)
 
-    def asof(self, date):
+    def asof(self, where):
         """
         Return last good (non-NaN) value in TimeSeries if value is NaN for
         requested date.
@@ -2287,7 +2274,7 @@ copy : boolean, default False
 
         Parameters
         ----------
-        date : datetime or similar value
+        wehre : date or array of dates
 
         Notes
         -----
@@ -2297,46 +2284,27 @@ copy : boolean, default False
         -------
         value or NaN
         """
-        if isinstance(date, basestring):
-            date = datetools.to_datetime(date)
-
-        if not isinstance(date, (list, tuple, np.ndarray, Index)):
-            # treat scalar values differently
-            v = self.get(date)
-            if isnull(v):
-                candidates = self.index[notnull(self)]
-                index = candidates.searchsorted(lib.Timestamp(date))
-                if index > 0:
-                    asOfDate = candidates[index - 1]
-                    return self.get(asOfDate)
-                return nan
-            return v
+        if isinstance(where, basestring):
+            where = datetools.to_datetime(where)
 
-        if not isinstance(date, Index):
-            date = Index(date)
-
-        candidates = self.index[notnull(self)]
-
-        mask = date.isin(candidates)
-
-        there = self[date[mask]]
-        todo = date[-mask]
-
-        if len(there) == len(date):
-            if len(there) == 1:
-                return there[0]
-            return there
-
-        index = candidates.searchsorted(todo)
-        index = index - 1
-        asof_mask = index >= 0
-        asof = self.ix[candidates[index[asof_mask]]]
-        asof.index = todo[asof_mask]
-
-        if len(date) == 1 and len(asof) > 0:
-            return asof[0]
+        values = self.values
 
-        return there.combine_first(asof).reindex(date)
+        if not hasattr(where, '__iter__'):
+            if where < self.index[0]:
+                return np.nan
+            loc = self.index.searchsorted(where, side='right')
+            if loc > 0:
+                loc -= 1
+            while isnull(values[loc]) and loc > 0:
+                loc -= 1
+            return values[loc]
+
+        if not isinstance(where, Index):
+            where = Index(where)
+
+        locs = self.index.asof_locs(where, notnull(values))
+        new_values = com.take_1d(values, locs)
+        return Series(new_values, index=where, name=self.name)
 
     def interpolate(self, method='linear'):
         """
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index 8b8fcf616..06d1710f6 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -14,7 +14,7 @@ from pandas.util import py3compat
 
 from pandas._sparse import BlockIndex, IntIndex
 import pandas._sparse as splib
-import pandas._engines as _gin
+import pandas._tseries as lib
 
 
 def _sparse_op_wrap(op, name):
@@ -261,7 +261,7 @@ to sparse
         if sp_loc == -1:
             return self.fill_value
         else:
-            return _gin.get_value_at(self, sp_loc)
+            return lib.get_value_at(self, sp_loc)
 
     def take(self, indices, axis=0):
         """
diff --git a/pandas/src/engines.pyx b/pandas/src/engines.pyx
index 3de282b26..07a547de8 100644
--- a/pandas/src/engines.pyx
+++ b/pandas/src/engines.pyx
@@ -1,7 +1,5 @@
 from numpy cimport ndarray
 
-
-
 from numpy cimport float64_t, int32_t, int64_t, uint8_t
 cimport cython
 
@@ -14,9 +12,9 @@ cimport util
 
 import numpy as np
 
-import _tseries
+# import _tseries
 
-include "hashtable.pyx"
+# include "hashtable.pyx"
 
 cdef extern from "datetime.h":
     bint PyDateTime_Check(object o)
@@ -26,8 +24,9 @@ PyDateTime_IMPORT
 
 cdef extern from "Python.h":
     int PySlice_Check(object)
-    int PyList_Check(object)
-    int PyTuple_Check(object)
+
+#     int PyList_Check(object)
+#     int PyTuple_Check(object)
 
 cdef inline is_definitely_invalid_key(object val):
     if PyTuple_Check(val):
@@ -244,14 +243,14 @@ cdef class Int64Engine(IndexEngine):
         return Int64HashTable(n)
 
     def _call_monotonic(self, values):
-        return _tseries.is_monotonic_int64(values)
+        return is_monotonic_int64(values)
 
     def get_pad_indexer(self, other, limit=None):
-        return _tseries.pad_int64(self._get_index_values(), other,
+        return pad_int64(self._get_index_values(), other,
                                   limit=limit)
 
     def get_backfill_indexer(self, other, limit=None):
-        return _tseries.backfill_int64(self._get_index_values(), other,
+        return backfill_int64(self._get_index_values(), other,
                                        limit=limit)
 
     cdef _get_bool_indexer(self, object val):
@@ -293,26 +292,26 @@ cdef class Float64Engine(IndexEngine):
         return Float64HashTable(n)
 
     def _call_monotonic(self, values):
-        return _tseries.is_monotonic_float64(values)
+        return is_monotonic_float64(values)
 
     def get_pad_indexer(self, other, limit=None):
-        return _tseries.pad_float64(self._get_index_values(), other,
+        return pad_float64(self._get_index_values(), other,
                                     limit=limit)
 
     def get_backfill_indexer(self, other, limit=None):
-        return _tseries.backfill_float64(self._get_index_values(), other,
+        return backfill_float64(self._get_index_values(), other,
                                          limit=limit)
 
 _pad_functions = {
-    'object' : _tseries.pad_object,
-    'int64' : _tseries.pad_int64,
-    'float64' : _tseries.pad_float64
+    'object' : pad_object,
+    'int64' : pad_int64,
+    'float64' : pad_float64
 }
 
 _backfill_functions = {
-    'object': _tseries.backfill_object,
-    'int64': _tseries.backfill_int64,
-    'float64': _tseries.backfill_float64
+    'object': backfill_object,
+    'int64': backfill_int64,
+    'float64': backfill_float64
 }
 
 cdef class ObjectEngine(IndexEngine):
@@ -323,14 +322,14 @@ cdef class ObjectEngine(IndexEngine):
         return PyObjectHashTable(n)
 
     def _call_monotonic(self, values):
-        return _tseries.is_monotonic_object(values)
+        return is_monotonic_object(values)
 
     def get_pad_indexer(self, other, limit=None):
-        return _tseries.pad_object(self._get_index_values(), other,
+        return pad_object(self._get_index_values(), other,
                                    limit=limit)
 
     def get_backfill_indexer(self, other, limit=None):
-        return _tseries.backfill_object(self._get_index_values(), other,
+        return backfill_object(self._get_index_values(), other,
                                         limit=limit)
 
 
@@ -354,23 +353,36 @@ cdef class DatetimeEngine(Int64Engine):
         return self.index_weakref().values.view('i8')
 
     def _call_monotonic(self, values):
-        return _tseries.is_monotonic_int64(values)
+        return is_monotonic_int64(values)
 
     cpdef get_loc(self, object val):
         if is_definitely_invalid_key(val):
             raise TypeError
 
-        if util.is_datetime64_object(val):
-            val = val.view('i8')
-        elif PyDateTime_Check(val):
-            val = np.datetime64(val)
-            val = val.view('i8')
+        # Welcome to the spaghetti factory
 
         self._ensure_mapping_populated()
         if not self.unique:
+            if util.is_datetime64_object(val):
+                val = val.view('i8')
+            elif PyDateTime_Check(val):
+                val = np.datetime64(val)
+                val = val.view('i8')
             return self._get_loc_duplicates(val)
 
         try:
+            return self.mapping.get_item(val.value)
+        except KeyError:
+            raise KeyError(val)
+        except AttributeError:
+            pass
+
+        try:
+            if util.is_datetime64_object(val):
+                val = val.view('i8')
+            elif PyDateTime_Check(val):
+                val = np.datetime64(val)
+                val = val.view('i8')
             return self.mapping.get_item(val)
         except TypeError:
             self._date_check_type(val)
@@ -392,14 +404,14 @@ cdef class DatetimeEngine(Int64Engine):
         if other.dtype != 'M8':
             return np.repeat(-1, len(other)).astype('i4')
         other = np.asarray(other).view('i8')
-        return _tseries.pad_int64(self._get_index_values(), other,
+        return pad_int64(self._get_index_values(), other,
                                   limit=limit)
 
     def get_backfill_indexer(self, other, limit=None):
         if other.dtype != 'M8':
             return np.repeat(-1, len(other)).astype('i4')
         other = np.asarray(other).view('i8')
-        return _tseries.backfill_int64(self._get_index_values(), other,
+        return backfill_int64(self._get_index_values(), other,
                                        limit=limit)
 
 
diff --git a/pandas/src/tseries.pyx b/pandas/src/tseries.pyx
index 33f6f0722..cec19493a 100644
--- a/pandas/src/tseries.pyx
+++ b/pandas/src/tseries.pyx
@@ -661,3 +661,4 @@ include "properties.pyx"
 include "inference.pyx"
 include "internals.pyx"
 include "join.pyx"
+include "engines.pyx"
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index f364ddbe6..94059fc12 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -1968,6 +1968,22 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         d = self.ts.index[0] - datetools.bday
         self.assert_(np.isnan(self.ts.asof(d)))
 
+    def test_asof_more(self):
+        from pandas import date_range
+        s = Series([nan, nan, 1, 2, nan, nan, 3, 4, 5],
+                   index=date_range('1/1/2000', periods=9))
+
+        dates = s.index[[4, 5, 6, 2, 1]]
+
+        result = s.asof(dates)
+        expected = Series([2, 2, 3, 1, np.nan], index=dates)
+
+        assert_series_equal(result, expected)
+
+        s = Series([1.5, 2.5, 1, 2, nan, nan, 3, 4, 5],
+                   index=date_range('1/1/2000', periods=9))
+        result = s.asof(s.index[0])
+        self.assertEqual(result, s[0])
 
     def test_astype_cast_nan_int(self):
         df = Series([1.0, 2.0, 3.0, np.nan])
diff --git a/pandas/tseries/index.py b/pandas/tseries/index.py
index 2ee02d22b..2c8b3bb0a 100644
--- a/pandas/tseries/index.py
+++ b/pandas/tseries/index.py
@@ -12,7 +12,6 @@ import pandas.core.common as com
 import pandas.tseries.offsets as offsets
 import pandas.tseries.tools as tools
 
-from pandas._engines import DatetimeEngine
 from pandas._tseries import Timestamp
 import pandas._tseries as lib
 
@@ -156,7 +155,7 @@ class DatetimeIndex(Int64Index):
     # structured array cache for datetime fields
     _sarr_cache = None
 
-    _engine_type = DatetimeEngine
+    _engine_type = lib.DatetimeEngine
 
     offset = None
 
diff --git a/pandas/tseries/tests/test_timeseries.py b/pandas/tseries/tests/test_timeseries.py
index 04733f2f6..ae8665ddb 100644
--- a/pandas/tseries/tests/test_timeseries.py
+++ b/pandas/tseries/tests/test_timeseries.py
@@ -64,7 +64,6 @@ class TestTimeSeriesDuplicates(unittest.TestCase):
         ts = self.dups
 
         uniques = ts.index.unique()
-
         for date in uniques:
             result = ts[date]
 
diff --git a/setup.py b/setup.py
index 190ea2399..e969ed708 100755
--- a/setup.py
+++ b/setup.py
@@ -334,7 +334,7 @@ else:
 tseries_depends = ['reindex', 'groupby', 'skiplist', 'moments',
                    'generated', 'reduce', 'stats', 'datetime',
                    'inference', 'properties', 'internals',
-                   'join']
+                   'join', 'engines']
 
 def srcpath(name=None, suffix='.pyx', subdir='src'):
     return pjoin('pandas', subdir, name+suffix)
@@ -357,24 +357,10 @@ tseries_ext = Extension('pandas._tseries',
                         # extra_compile_args=['-Wconversion']
                         )
 
-# hashtable_ext = Extension('pandas._hashtable',
-#                        sources=[srcpath('hashtable', suffix=suffix)],
-#                        depends=['pandas/src/khash.pxd',
-#                                 'pandas/src/util.pxd',
-#                                 'pandas/src/khash.h'],
-#                        include_dirs=[np.get_include()])
-
 sparse_ext = Extension('pandas._sparse',
                        sources=[srcpath('sparse', suffix=suffix)],
                        include_dirs=[np.get_include()])
 
-engines_ext = Extension('pandas._engines',
-                        depends=['pandas/src/numpy_helper.h',
-                                 'pandas/src/hashtable.pyx',
-                                 'pandas/src/util.pxd'],
-                        sources=[srcpath('engines', suffix=suffix)],
-                        include_dirs=[np.get_include()])
-
 sandbox_ext = Extension('pandas._sandbox',
                         sources=[srcpath('sandbox', suffix=suffix),
                                  'pandas/src/period.c',
@@ -386,11 +372,7 @@ cppsandbox_ext = Extension('pandas._cppsandbox',
                            sources=[srcpath('cppsandbox', suffix=suffix)],
                            include_dirs=[np.get_include()])
 
-extensions = [tseries_ext,
-              engines_ext,
-              sparse_ext,
-              # hashtable_ext
-              ]
+extensions = [tseries_ext, sparse_ext]
 
 if not ISRELEASED:
     extensions.extend([sandbox_ext])
