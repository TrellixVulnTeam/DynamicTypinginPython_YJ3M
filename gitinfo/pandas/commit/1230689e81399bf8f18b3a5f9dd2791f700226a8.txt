commit 1230689e81399bf8f18b3a5f9dd2791f700226a8
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sun Feb 10 22:42:11 2013 -0500

    ENH: create array core module

diff --git a/pandas/core/array.py b/pandas/core/array.py
new file mode 100644
index 000000000..0026dfcec
--- /dev/null
+++ b/pandas/core/array.py
@@ -0,0 +1,36 @@
+"""
+Isolate pandas's exposure to NumPy
+"""
+
+import numpy as np
+
+Array = np.ndarray
+
+bool = np.bool_
+
+_dtypes = {
+    'int': [8, 16, 32, 64],
+    'uint': [8, 16, 32, 64],
+    'float': [16, 32, 64]
+}
+
+_lift_types = []
+
+for _k, _v in _dtypes.iteritems():
+    for _i in _v:
+        _lift_types.append(_k + str(_i))
+
+for _t in _lift_types:
+    globals()[_t] = getattr(np, _t)
+
+_lift_function = ['empty', 'arange', 'array', 'putmask', 'where']
+
+for _f in _lift_function:
+    globals()[_f] = getattr(np, _f)
+
+_lift_random = ['randn', 'rand']
+
+for _f in _lift_random:
+    globals()[_f] = getattr(np.random, _f)
+
+NA = np.nan
diff --git a/pandas/core/series.py b/pandas/core/series.py
index def3184b0..bb1548966 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -24,6 +24,9 @@ from pandas.tseries.index import DatetimeIndex
 from pandas.tseries.period import PeriodIndex, Period
 from pandas.util import py3compat
 from pandas.util.terminal import get_terminal_size
+
+import pandas.core.array as pa
+
 import pandas.core.common as com
 import pandas.core.datetools as datetools
 import pandas.core.format as fmt
@@ -59,14 +62,14 @@ def _arith_method(op, name):
         try:
             result = op(x, y)
         except TypeError:
-            result = np.empty(len(x), dtype=x.dtype)
-            if isinstance(y, np.ndarray):
+            result = pa.empty(len(x), dtype=x.dtype)
+            if isinstance(y, pa.Array):
                 mask = notnull(x) & notnull(y)
                 result[mask] = op(x[mask], y[mask])
             else:
                 mask = notnull(x)
                 result[mask] = op(x[mask], y)
-            np.putmask(result, -mask, np.nan)
+            np.putmask(result, -mask, pa.NA)
 
         return result
 
@@ -79,12 +82,12 @@ def _arith_method(op, name):
 
         if com.is_datetime64_dtype(self):
 
-            if not isinstance(rvalues, np.ndarray):
-                rvalues = np.array([rvalues])
+            if not isinstance(rvalues, pa.Array):
+                rvalues = pa.array([rvalues])
 
             # rhs is either a timedelta or a series/ndarray
             if lib.is_timedelta_array(rvalues):
-                rvalues = np.array([ np.timedelta64(v) for v in rvalues ],dtype='timedelta64[ns]')
+                rvalues = pa.array([ np.timedelta64(v) for v in rvalues ],dtype='timedelta64[ns]')
                 dtype = 'M8[ns]'
             elif com.is_datetime64_dtype(rvalues):
                 dtype = 'timedelta64[ns]'
@@ -136,7 +139,7 @@ def _comp_method(op, name):
             if isinstance(y, list):
                 y = lib.list_to_object_array(y)
 
-            if isinstance(y, np.ndarray):
+            if isinstance(y, pa.Array):
                 if y.dtype != np.object_:
                     result = lib.vec_compare(x, y.astype(np.object_), op)
                 else:
@@ -159,7 +162,7 @@ def _comp_method(op, name):
                           index=self.index, name=name)
         elif isinstance(other, DataFrame):  # pragma: no cover
             return NotImplemented
-        elif isinstance(other, np.ndarray):
+        elif isinstance(other, pa.Array):
             if len(self) != len(other):
                 raise ValueError('Lengths must match to compare')
             return Series(na_op(self.values, np.asarray(other)),
@@ -193,7 +196,7 @@ def _bool_method(op, name):
             if isinstance(y, list):
                 y = lib.list_to_object_array(y)
 
-            if isinstance(y, np.ndarray):
+            if isinstance(y, pa.Array):
                 if (x.dtype == np.bool_ and
                         y.dtype == np.bool_):  # pragma: no cover
                     result = op(x, y)  # when would this be hit?
@@ -270,7 +273,7 @@ def _flex_method(op, name):
     def f(self, other, level=None, fill_value=None):
         if isinstance(other, Series):
             return self._binop(other, op, level=level, fill_value=fill_value)
-        elif isinstance(other, (np.ndarray, list, tuple)):
+        elif isinstance(other, (pa.Array, list, tuple)):
             if len(other) != len(self):
                 raise ValueError('Lengths must be equal')
             return self._binop(Series(other, self.index), op,
@@ -287,7 +290,7 @@ def _unbox(func):
     @Appender(func.__doc__)
     def f(self, *args, **kwargs):
         result = func(self, *args, **kwargs)
-        if isinstance(result, np.ndarray) and result.ndim == 0:
+        if isinstance(result, pa.Array) and result.ndim == 0:
             # return NumPy type
             return result.dtype.type(result.item())
         else:  # pragma: no cover
@@ -333,7 +336,7 @@ def _make_stat_func(nanop, name, shortname, na_action=_doc_exclude_na,
 # Series class
 
 
-class Series(np.ndarray, generic.PandasObject):
+class Series(pa.Array, generic.PandasObject):
     _AXIS_NUMBERS = {
         'index': 0
     }
@@ -363,12 +366,12 @@ class Series(np.ndarray, generic.PandasObject):
                 if isinstance(index, DatetimeIndex):
                     # coerce back to datetime objects for lookup
                     data = lib.fast_multiget(data, index.astype('O'),
-                                             default=np.nan)
+                                             default=pa.NA)
                 elif isinstance(index, PeriodIndex):
                     data = [data.get(i, nan) for i in index]
                 else:
                     data = lib.fast_multiget(data, index.values,
-                                             default=np.nan)
+                                             default=pa.NA)
             except TypeError:
                 data = [data.get(i, nan) for i in index]
         elif isinstance(data, types.GeneratorType):
@@ -382,7 +385,7 @@ class Series(np.ndarray, generic.PandasObject):
         subarr = _sanitize_array(data, index, dtype, copy,
                                  raise_cast_failure=True)
 
-        if not isinstance(subarr, np.ndarray):
+        if not isinstance(subarr, pa.Array):
             return subarr
 
         if index is None:
@@ -560,7 +563,7 @@ copy : boolean, default False
                             return self._get_values(key)
                     raise
 
-            if not isinstance(key, (list, np.ndarray)):  # pragma: no cover
+            if not isinstance(key, (list, pa.Array)):  # pragma: no cover
                 key = list(key)
 
             if isinstance(key, Index):
@@ -630,7 +633,7 @@ copy : boolean, default False
             cond = cond.astype(np.bool_)
 
         ser = self if inplace else self.copy()
-        if not isinstance(other, (list, tuple, np.ndarray)):
+        if not isinstance(other, (list, tuple, pa.Array)):
             ser._set_with(~cond, other)
             return None if inplace else ser
 
@@ -706,7 +709,7 @@ copy : boolean, default False
                 except Exception:
                     pass
 
-            if not isinstance(key, (list, np.ndarray)):
+            if not isinstance(key, (list, pa.Array)):
                 key = list(key)
 
             if isinstance(key, Index):
@@ -920,7 +923,7 @@ copy : boolean, default False
         resetted : DataFrame, or Series if drop == True
         """
         if drop:
-            new_index = np.arange(len(self))
+            new_index = pa.arange(len(self))
             if level is not None and isinstance(self.index, MultiIndex):
                 if not isinstance(level, (tuple, list)):
                     level = [level]
@@ -1150,8 +1153,8 @@ copy : boolean, default False
     #----------------------------------------------------------------------
     # unbox reductions
 
-    all = _unbox(np.ndarray.all)
-    any = _unbox(np.ndarray.any)
+    all = _unbox(pa.Array.all)
+    any = _unbox(pa.Array.any)
 
     #----------------------------------------------------------------------
     # Misc public methods
@@ -1264,7 +1267,7 @@ copy : boolean, default False
             # call cython function
             max_bin = len(level_index)
             labels = com._ensure_int64(self.index.labels[level])
-            counts = lib.count_level_1d(mask.view(np.uint8),
+            counts = lib.count_level_1d(mask.view(pa.uint8),
                                         labels, max_bin)
             return Series(counts, index=level_index)
 
@@ -1435,7 +1438,7 @@ copy : boolean, default False
         """
         i = nanops.nanargmin(self.values, skipna=skipna)
         if i == -1:
-            return np.nan
+            return pa.NA
         return self.index[i]
 
     def idxmax(self, axis=None, out=None, skipna=True):
@@ -1453,7 +1456,7 @@ copy : boolean, default False
         """
         i = nanops.nanargmax(self.values, skipna=skipna)
         if i == -1:
-            return np.nan
+            return pa.NA
         return self.index[i]
 
     def cumsum(self, axis=0, dtype=None, out=None, skipna=True):
@@ -1481,7 +1484,7 @@ copy : boolean, default False
         result = arr.cumsum()
 
         if do_mask:
-            np.putmask(result, mask, np.nan)
+            np.putmask(result, mask, pa.NA)
 
         return Series(result, index=self.index)
 
@@ -1510,7 +1513,7 @@ copy : boolean, default False
         result = arr.cumprod()
 
         if do_mask:
-            np.putmask(result, mask, np.nan)
+            np.putmask(result, mask, pa.NA)
 
         return Series(result, index=self.index)
 
@@ -1539,7 +1542,7 @@ copy : boolean, default False
         result = np.maximum.accumulate(arr)
 
         if do_mask:
-            np.putmask(result, mask, np.nan)
+            np.putmask(result, mask, pa.NA)
 
         return Series(result, index=self.index)
 
@@ -1568,11 +1571,11 @@ copy : boolean, default False
         result = np.minimum.accumulate(arr)
 
         if do_mask:
-            np.putmask(result, mask, np.nan)
+            np.putmask(result, mask, pa.NA)
 
         return Series(result, index=self.index)
 
-    @Appender(np.ndarray.round.__doc__)
+    @Appender(pa.Array.round.__doc__)
     def round(self, decimals=0, out=None):
         """
 
@@ -1599,7 +1602,7 @@ copy : boolean, default False
         """
         valid_values = self.dropna().values
         if len(valid_values) == 0:
-            return np.nan
+            return pa.NA
         return _quantile(valid_values, q * 100)
 
     def ptp(self, axis=None, out=None):
@@ -1692,7 +1695,7 @@ copy : boolean, default False
         """
         this, other = self.align(other, join='inner', copy=False)
         if len(this) == 0:
-            return np.nan
+            return pa.NA
         return nanops.nancorr(this.values, other.values, method=method,
                               min_periods=min_periods)
 
@@ -1714,7 +1717,7 @@ copy : boolean, default False
         """
         this, other = self.align(other, join='inner')
         if len(this) == 0:
-            return np.nan
+            return pa.NA
         return nanops.nancov(this.values, other.values,
                              min_periods=min_periods)
 
@@ -1780,7 +1783,7 @@ copy : boolean, default False
         -------
         clipped : Series
         """
-        return np.where(self > threshold, threshold, self)
+        return pa.where(self > threshold, threshold, self)
 
     def clip_lower(self, threshold):
         """
@@ -1794,7 +1797,7 @@ copy : boolean, default False
         -------
         clipped : Series
         """
-        return np.where(self < threshold, threshold, self)
+        return pa.where(self < threshold, threshold, self)
 
 #------------------------------------------------------------------------------
 # Combination
@@ -1896,7 +1899,7 @@ copy : boolean, default False
         if isinstance(other, Series):
             new_index = self.index + other.index
             new_name = _maybe_match_name(self, other)
-            new_values = np.empty(len(new_index), dtype=self.dtype)
+            new_values = pa.empty(len(new_index), dtype=self.dtype)
             for i, idx in enumerate(new_index):
                 lv = self.get(idx, fill_value)
                 rv = other.get(idx, fill_value)
@@ -2084,12 +2087,12 @@ copy : boolean, default False
                 return arr.argsort()
 
         arr = self.values
-        sortedIdx = np.empty(len(self), dtype=np.int32)
+        sortedIdx = pa.empty(len(self), dtype=np.int32)
 
         bad = isnull(arr)
 
         good = -bad
-        idx = np.arange(len(self))
+        idx = pa.arange(len(self))
 
         argsorted = _try_mergesort(arr[good])
 
@@ -2246,7 +2249,7 @@ copy : boolean, default False
             mask = isnull(values)
 
             def map_f(values, f):
-                return lib.map_infer_mask(values, f, mask.view(np.uint8))
+                return lib.map_infer_mask(values, f, mask.view(pa.uint8))
         else:
             map_f = lib.map_infer
 
@@ -2355,7 +2358,7 @@ copy : boolean, default False
         # be subclass-friendly
         return self._constructor(new_values, new_index, name=self.name)
 
-    def reindex(self, index=None, method=None, level=None, fill_value=np.nan,
+    def reindex(self, index=None, method=None, level=None, fill_value=pa.NA,
                 limit=None, copy=True):
         """Conform Series to new index with optional filling logic, placing
         NA/NaN in locations having no value in the previous index. A new object
@@ -2376,7 +2379,7 @@ copy : boolean, default False
         level : int or name
             Broadcast across a level, matching Index values on the
             passed MultiIndex level
-        fill_value : scalar, default np.NaN
+        fill_value : scalar, default NaN
             Value to use for missing values. Defaults to NaN, but can be any
             "compatible" value
         limit : int, default None
@@ -2591,9 +2594,9 @@ copy : boolean, default False
 
         if isinstance(to_replace, dict):
             _rep_dict(result, to_replace)
-        elif isinstance(to_replace, (list, np.ndarray)):
+        elif isinstance(to_replace, (list, pa.Array)):
 
-            if isinstance(value, (list, np.ndarray)):  # check same length
+            if isinstance(value, (list, pa.Array)):  # check same length
                 vl, rl = len(value), len(to_replace)
                 if vl == rl:
                     _rep_dict(result, dict(zip(to_replace, value)))
@@ -2814,7 +2817,7 @@ copy : boolean, default False
             return values
 
         if offset is None:
-            new_values = np.empty(len(self), dtype=self.dtype)
+            new_values = pa.empty(len(self), dtype=self.dtype)
             new_values = _maybe_upcast(new_values)
 
             if periods > 0:
@@ -2869,7 +2872,7 @@ copy : boolean, default False
                 start = start.ordinal
 
             if where < start:
-                return np.nan
+                return pa.NA
             loc = self.index.searchsorted(where, side='right')
             if loc > 0:
                 loc -= 1
@@ -2905,18 +2908,18 @@ copy : boolean, default False
                 raise Exception('time-weighted interpolation only works'
                                 'on TimeSeries')
             method = 'values'
-            # inds = np.array([d.toordinal() for d in self.index])
+            # inds = pa.array([d.toordinal() for d in self.index])
 
         if method == 'values':
             inds = self.index.values
             # hack for DatetimeIndex, #1646
             if issubclass(inds.dtype.type, np.datetime64):
-                inds = inds.view(np.int64)
+                inds = inds.view(pa.int64)
 
             if inds.dtype == np.object_:
                 inds = lib.maybe_convert_objects(inds)
         else:
-            inds = np.arange(len(self))
+            inds = pa.arange(len(self))
 
         values = self.values
 
@@ -3059,21 +3062,21 @@ def _sanitize_array(data, index, dtype=None, copy=False,
     if isinstance(data, ma.MaskedArray):
         mask = ma.getmaskarray(data)
         data = ma.copy(data)
-        data[mask] = np.nan
+        data[mask] = pa.NA
 
     def _try_cast(arr):
         try:
             arr = com._possibly_cast_to_datetime(arr, dtype)
-            subarr = np.array(arr, dtype=dtype, copy=copy)
+            subarr = pa.array(arr, dtype=dtype, copy=copy)
         except (ValueError, TypeError):
             if dtype is not None and raise_cast_failure:
                 raise
             else:  # pragma: no cover
-                subarr = np.array(arr, dtype=object, copy=copy)
+                subarr = pa.array(arr, dtype=object, copy=copy)
         return subarr
 
     # GH #846
-    if isinstance(data, np.ndarray):
+    if isinstance(data, pa.Array):
         subarr = data
         if dtype is not None:
 
@@ -3106,7 +3109,7 @@ def _sanitize_array(data, index, dtype=None, copy=False,
             except Exception:
                 if raise_cast_failure:  # pragma: no cover
                     raise
-                subarr = np.array(data, dtype=object, copy=copy)
+                subarr = pa.array(data, dtype=object, copy=copy)
                 subarr = lib.maybe_convert_objects(subarr)
                 subarr = com._possibly_cast_to_datetime(subarr, dtype)
         else:
@@ -3119,7 +3122,7 @@ def _sanitize_array(data, index, dtype=None, copy=False,
     # scalar like
     if subarr.ndim == 0:
         if isinstance(data, list):  # pragma: no cover
-            subarr = np.array(data, dtype=object)
+            subarr = pa.array(data, dtype=object)
         elif index is not None:
             value = data
 
@@ -3134,17 +3137,17 @@ def _sanitize_array(data, index, dtype=None, copy=False,
             if dtype is None:
 
                 # a 1-element ndarray
-                if isinstance(value, np.ndarray):
+                if isinstance(value, pa.Array):
                     dtype = value.dtype
                     value = value.item()
                 else:
                     value, dtype = _dtype_from_scalar(value)
 
-                subarr = np.empty(len(index), dtype=dtype)
+                subarr = pa.empty(len(index), dtype=dtype)
             else:
                 # need to possibly convert the value here
                 value = com._possibly_cast_to_datetime(value, dtype)
-                subarr = np.empty(len(index), dtype=dtype)
+                subarr = pa.empty(len(index), dtype=dtype)
             subarr.fill(value)
         else:
             return subarr.item()
@@ -3156,11 +3159,11 @@ def _sanitize_array(data, index, dtype=None, copy=False,
             # a 1-element ndarray
             if len(subarr) != len(index) and len(subarr) == 1:
                 value = subarr[0]
-                subarr = np.empty(len(index), dtype=subarr.dtype)
+                subarr = pa.empty(len(index), dtype=subarr.dtype)
                 subarr.fill(value)
 
     elif subarr.ndim > 1:
-        if isinstance(data, np.ndarray):
+        if isinstance(data, pa.Array):
             raise Exception('Data must be 1-dimensional')
         else:
             subarr = _asarray_tuplesafe(data, dtype=dtype)
@@ -3168,7 +3171,7 @@ def _sanitize_array(data, index, dtype=None, copy=False,
     # This is to prevent mixed-type Series getting all casted to
     # NumPy string type, e.g. NaN --> '-1#IND'.
     if issubclass(subarr.dtype.type, basestring):
-        subarr = np.array(data, dtype=object, copy=copy)
+        subarr = pa.array(data, dtype=object, copy=copy)
 
     return subarr
 
