commit d5213b0c872cb950c9315989ebfd2f358cbb59f8
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Sat Oct 15 20:50:41 2011 -0400

    ENH: starting Cython parser infrastructure. add boolean handling. speed up read_csv by a lot

diff --git a/pandas/io/parsers.py b/pandas/io/parsers.py
index 4124cfc74..d0f7b0133 100644
--- a/pandas/io/parsers.py
+++ b/pandas/io/parsers.py
@@ -9,6 +9,7 @@ import numpy as np
 from pandas.core.index import Index, MultiIndex
 from pandas.core.frame import DataFrame
 
+import pandas._tseries as lib
 
 def read_csv(filepath_or_buffer, sep=None, header=0, index_col=None, names=None,
              skiprows=None, na_values=None, parse_dates=False,
@@ -167,6 +168,19 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
 
         return DataFrame(index=index, columns=columns)
 
+
+    # common NA values
+    # no longer excluding inf representations
+    # '1.#INF','-1.#INF', '1.#INF000000',
+    NA_VALUES = set(['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN',
+                     '#N/A N/A', 'NA', '#NA', 'NULL', 'NaN',
+                     'nan', ''])
+    if na_values is None:
+        na_values = NA_VALUES
+    else:
+        na_values = set(list(na_values)) | NA_VALUES
+
+
     if index_col is None and len(content[0]) == len(columns) + 1:
         index_col = 0
 
@@ -194,7 +208,7 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
         if np.isscalar(index_col):
             if parse_dates:
                 index = _try_parse_dates(index, parser=date_parser)
-            index = Index(_maybe_convert_int(np.array(index, dtype=object)))
+            index = Index(_convert_ndarray(index, na_values))
         else:
             arrays = _maybe_convert_int_mindex(index, parse_dates,
                                                date_parser)
@@ -211,39 +225,26 @@ def _simple_parser(lines, colNames=None, header=0, index_col=0,
         raise Exception('wrong number of columns')
 
     data = dict(izip(columns, zipped_content))
-    data = _floatify(data, na_values=na_values)
-    data = _convert_to_ndarrays(data)
+    data = _convert_to_ndarrays(data, na_values)
+
     return DataFrame(data=data, columns=columns, index=index)
 
-def _floatify(data_dict, na_values=None):
-    """
 
+
+def _floatify(tup, na_values):
     """
-    # common NA values
-    # no longer excluding inf representations
-    # '1.#INF','-1.#INF', '1.#INF000000',
-    NA_VALUES = set(['-1.#IND', '1.#QNAN', '1.#IND', '-1.#QNAN',
-                     '#N/A N/A', 'NA', '#NA', 'NULL', 'NaN',
-                     'nan', ''])
-    if na_values is None:
-        na_values = NA_VALUES
-    else:
-        na_values = set(list(na_values)) | NA_VALUES
 
-    def _convert_float(val):
-        if val in na_values:
-            return np.nan
+    """
+    try:
+        if isinstance(tup, tuple):
+            return lib.maybe_convert_float_tuple(tup, na_values)
         else:
-            try:
-                return np.float64(val)
-            except Exception:
-                return val
-
-    result = {}
-    for col, values in data_dict.iteritems():
-        result[col] = [_convert_float(val) for val in values]
-
-    return result
+            return lib.maybe_convert_float_list(tup, na_values)
+    except Exception:
+        if isinstance(tup, tuple):
+            return lib.string_to_ndarray_tuple(tup)
+        else:
+            return lib.string_to_ndarray_list(tup)
 
 def _maybe_convert_int(arr):
     if len(arr) == 0: # pragma: no cover
@@ -251,17 +252,18 @@ def _maybe_convert_int(arr):
 
     try:
         if arr.dtype == np.object_:
-            return arr.astype(int)
-
-        if abs(arr[0] - int(arr[0])) < 1e-10:
-            casted = arr.astype(int)
-            if (np.abs(casted - arr) < 1e-10).all():
-                return casted
+            return lib.maybe_convert_int_object(arr)
+        return lib.maybe_convert_int(arr)
     except (TypeError, ValueError):
         pass
 
     return arr
 
+def _maybe_convert_bool(arr):
+    if arr.dtype == np.object_:
+        return lib.maybe_convert_bool_object(arr)
+    return arr
+
 def _maybe_convert_int_mindex(index, parse_dates, date_parser):
     for i in range(len(index)):
         try:
@@ -273,16 +275,18 @@ def _maybe_convert_int_mindex(index, parse_dates, date_parser):
 
     return index
 
-def _convert_to_ndarrays(dct):
+def _convert_to_ndarrays(dct, na_values):
     result = {}
     for c, values in dct.iteritems():
-        try:
-            values = np.array(values, dtype=float)
-        except Exception:
-            values = np.array(values, dtype=object)
-        result[c] = _maybe_convert_int(values)
+        result[c] = _convert_ndarray(values, na_values)
     return result
 
+def _convert_ndarray(tup, na_values):
+    values = _floatify(tup, na_values)
+    values = _maybe_convert_int(values)
+    values = _maybe_convert_bool(values)
+    return values
+
 def _try_parse_dates(values, parser=None):
     if parser is None:
         try:
diff --git a/pandas/io/tests/test_parsers.py b/pandas/io/tests/test_parsers.py
index 5f71f793f..8dca1a738 100644
--- a/pandas/io/tests/test_parsers.py
+++ b/pandas/io/tests/test_parsers.py
@@ -56,6 +56,20 @@ ignore,this,row
                                     ['A', 'B', 'C', 'Unnamed: 3',
                                      'Unnamed: 4']))
 
+    def test_string_nas(self):
+        data = """A,B,C
+a,b,c
+d,,f
+,g,h
+"""
+        result = read_csv(StringIO(data))
+        expected = DataFrame([['a', 'b', 'c'],
+                              ['d', np.nan, 'f'],
+                              [np.nan, 'g', 'h']],
+                             columns=['A', 'B', 'C'])
+
+        assert_frame_equal(result, expected)
+
     def test_duplicate_columns(self):
         data = """A,A,B,B,B
 1,2,3,4,5
@@ -151,6 +165,15 @@ bar,12,13,14,15
 """
         self.assertRaises(Exception, read_csv, StringIO(data), index_col=0)
 
+    def test_parse_bools(self):
+        data = """A,B
+True,1
+False,2
+True,3
+"""
+        data = read_csv(StringIO(data))
+        self.assert_(data['A'].dtype == np.bool_)
+
 def curpath():
     pth, _ = os.path.split(os.path.abspath(__file__))
     return pth
diff --git a/pandas/src/parsing.pyx b/pandas/src/parsing.pyx
new file mode 100644
index 000000000..715c7fc83
--- /dev/null
+++ b/pandas/src/parsing.pyx
@@ -0,0 +1,175 @@
+cimport cpython
+
+cdef extern from "math.h":
+    double fabs(double)
+
+def maybe_convert_float_list(tuple values):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[float64_t] result
+        object val
+
+    n = len(values)
+    result = np.empty(n, dtype='f8')
+
+    for i from 0 <= i < n:
+        val = values[i]
+        result[i] = <float64_t> val
+
+    return val
+
+def maybe_convert_float_tuple(tuple values, set na_values):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[float64_t] result
+        object val
+
+    n = len(values)
+    result = np.empty(n, dtype='f8')
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        if cpython.PyFloat_Check(val):
+            result[i] = val
+        elif val in na_values:
+            result[i] = nan
+        elif val is None:
+            result[i] = nan
+        elif len(val) == 0:
+            result[i] = nan
+        else:
+            result[i] = float(val)
+
+    return result
+
+def maybe_convert_float_list(list values, set na_values):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[float64_t] result
+        object val
+
+    n = len(values)
+    result = np.empty(n, dtype='f8')
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        if cpython.PyFloat_Check(val):
+            result[i] = val
+        elif val in na_values:
+            result[i] = nan
+        elif val is None:
+            result[i] = nan
+        elif len(val) == 0:
+            result[i] = nan
+        else:
+            result[i] = float(val)
+
+    return result
+
+def string_to_ndarray_tuple(tuple values):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[object] result
+        object val, onan
+
+    n = len(values)
+    result = np.empty(n, dtype=object)
+    onan = np.nan
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        if val == '':
+            result[i] = onan
+        else:
+            result[i] = val
+
+    return result
+
+def string_to_ndarray_list(list values):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[object] result
+        object val, onan
+
+    n = len(values)
+    result = np.empty(n, dtype=object)
+    onan = np.nan
+
+    for i from 0 <= i < n:
+        val = values[i]
+
+        if val == '':
+            result[i] = onan
+        else:
+            result[i] = val
+
+    return result
+
+def maybe_convert_bool_object(ndarray[object] arr):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[uint8_t, cast=True] result
+        object val
+
+    n = len(arr)
+    result = np.empty(n, dtype=bool)
+
+    for i from 0 <= i < n:
+        val = arr[i]
+
+        if val == 'True':
+            result[i] = 1
+        elif val == 'False':
+            result[i] = 0
+        else:
+            return arr
+
+    return result
+
+cdef float64_t FP_ERR = 1e-10
+
+def maybe_convert_int(ndarray[float64_t] arr):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[int64_t] result
+        float64_t val
+
+    n = len(arr)
+    result = np.empty(n, dtype='i8')
+    for i from 0 <= i < n:
+        val = arr[i]
+        result[i] = <int64_t> val
+
+        # NA
+        if val != val:
+            return arr
+
+        if fabs(result[i] - val) > FP_ERR:
+            return arr
+
+    return result
+
+def maybe_convert_int_object(ndarray[object] arr):
+    cdef:
+        Py_ssize_t i, n
+        ndarray[int64_t] result
+        object val
+
+    n = len(arr)
+    result = np.empty(n, dtype='i8')
+    for i from 0 <= i < n:
+        val = arr[i]
+        result[i] = <int64_t> val
+
+        # NA
+        if val != val:
+            return arr
+
+        if fabs(result[i] - val) > FP_ERR:
+            return arr
+
+    return result
+
diff --git a/pandas/src/tseries.pyx b/pandas/src/tseries.pyx
index ceccc3c15..765c5c7eb 100644
--- a/pandas/src/tseries.pyx
+++ b/pandas/src/tseries.pyx
@@ -353,3 +353,4 @@ include "groupby.pyx"
 include "moments.pyx"
 include "reindex.pyx"
 include "generated.pyx"
+include "parsing.pyx"
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index 70d1bc05e..92ba3c343 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -1616,8 +1616,10 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         os.remove(pth)
 
     def test_to_csv_withcommas(self):
-        "Commas inside fields should be correctly escaped when saving as CSV."
+
         path = '__tmp__'
+        # Commas inside fields should be correctly escaped when saving as CSV.
+
         df = DataFrame({'A':[1,2,3], 'B':['5,6','7,8','9,0']})
         df.to_csv(path)
         df2 = DataFrame.from_csv(path)
diff --git a/pandas/tools/pivot.py b/pandas/tools/pivot.py
index 5d2eba93e..cb235f5b0 100644
--- a/pandas/tools/pivot.py
+++ b/pandas/tools/pivot.py
@@ -50,5 +50,6 @@ if __name__ == '__main__':
     data['values'] = np.random.randn(n)
     data = DataFrame(data)
 
-    table = pivot_table(data, values='values', xby=['k1', 'k2'], yby=['k3', 'k4'])
+    table = pivot_table(data, values='values',
+                        xby=['k1', 'k2'], yby=['k3', 'k4'])
 
