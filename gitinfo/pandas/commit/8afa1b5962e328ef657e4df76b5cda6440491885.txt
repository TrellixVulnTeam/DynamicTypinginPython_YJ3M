commit 8afa1b5962e328ef657e4df76b5cda6440491885
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Thu Jan 5 16:55:37 2012 -0500

    ENH: refactor Concatenator to work for ndim > 2, add join-multiple to Panel, #115

diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index 96749bc83..4d7fc50dc 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -299,6 +299,15 @@ class DataFrame(NDFrame):
 
         NDFrame.__init__(self, mgr)
 
+    @classmethod
+    def _from_axes(cls, data, axes):
+        # for construction from BlockManager
+        if isinstance(data, BlockManager):
+            return cls(data)
+        else:
+            columns, index = axes
+            return cls(data, index=index, columns=columns, copy=False)
+
     def _init_mgr(self, mgr, index, columns, dtype=None, copy=False):
         if columns is not None:
             mgr = mgr.reindex_axis(columns, axis=0, copy=False)
@@ -2751,9 +2760,6 @@ class DataFrame(NDFrame):
         return concat(to_concat, ignore_index=ignore_index,
                       verify_integrity=verify_integrity)
 
-    def _get_raw_column(self, col):
-        return self._data.get(col)
-
     def join(self, other, on=None, how='left', lsuffix='', rsuffix=''):
         """
         Join columns with other DataFrame either on index or on a key
@@ -2815,12 +2821,12 @@ class DataFrame(NDFrame):
             # join indexes only using concat
             if how == 'left':
                 how = 'outer'
-                join_index = self.index
+                join_axes = [self.index]
             else:
-                join_index = None
+                join_axes = None
 
             return concat([self] + list(other), axis=1, join=how,
-                          join_index=join_index, verify_integrity=True)
+                          join_axes=join_axes, verify_integrity=True)
 
     def merge(self, right, how='inner', on=None, left_on=None, right_on=None,
               left_index=False, right_index=False, sort=True,
diff --git a/pandas/core/groupby.py b/pandas/core/groupby.py
index 9d5c0088e..f42599c9e 100644
--- a/pandas/core/groupby.py
+++ b/pandas/core/groupby.py
@@ -1144,7 +1144,7 @@ class DataFrameGroupBy(GroupBy):
                 applied.append(res)
 
         concat_index = obj.columns if self.axis == 0 else obj.index
-        concatenated = concat(applied, join_index=concat_index,
+        concatenated = concat(applied, join_axes=[concat_index],
                               axis=self.axis, verify_integrity=False)
         return concatenated.reindex_like(obj)
 
diff --git a/pandas/core/panel.py b/pandas/core/panel.py
index 541bea187..3c1ae9364 100644
--- a/pandas/core/panel.py
+++ b/pandas/core/panel.py
@@ -232,6 +232,16 @@ class Panel(NDFrame):
 
         NDFrame.__init__(self, mgr, axes=axes, copy=copy, dtype=dtype)
 
+    @classmethod
+    def _from_axes(cls, data, axes):
+        # for construction from BlockManager
+        if isinstance(data, BlockManager):
+            return cls(data)
+        else:
+            items, major, minor = axes
+            return cls(data, items=items, major_axis=major,
+                       minor_axis=minor, copy=False)
+
     def _init_dict(self, data, axes, dtype=None):
         items, major, minor = axes
 
@@ -1067,13 +1077,13 @@ class Panel(NDFrame):
 
         return self.reindex(**{axis : new_index})
 
-    def join(self, other, how=None, lsuffix='', rsuffix=''):
+    def join(self, other, how='left', lsuffix='', rsuffix=''):
         """
         Join items with other Panel either on major and minor axes column
 
         Parameters
         ----------
-        other : Panel
+        other : Panel or list of Panels
             Index should be similar to one of the columns in this one
         how : {'left', 'right', 'outer', 'inner'}
             How to handle indexes of the two objects. Default: 'left'
@@ -1091,16 +1101,30 @@ class Panel(NDFrame):
         -------
         joined : Panel
         """
-        if how is None:
-            how = 'left'
-        return self._join_index(other, how, lsuffix, rsuffix)
-
-    def _join_index(self, other, how, lsuffix, rsuffix):
-        join_major, join_minor = self._get_join_index(other, how)
-        this = self.reindex(major=join_major, minor=join_minor)
-        other = other.reindex(major=join_major, minor=join_minor)
-        merged_data = this._data.merge(other._data, lsuffix, rsuffix)
-        return self._constructor(merged_data)
+        from pandas.tools.merge import concat
+
+        if isinstance(other, Panel):
+            join_major, join_minor = self._get_join_index(other, how)
+            this = self.reindex(major=join_major, minor=join_minor)
+            other = other.reindex(major=join_major, minor=join_minor)
+            merged_data = this._data.merge(other._data, lsuffix, rsuffix)
+            return self._constructor(merged_data)
+        else:
+            if lsuffix or rsuffix:
+                raise ValueError('Suffixes not supported when passing multiple '
+                                 'panels')
+
+            if how == 'left':
+                how = 'outer'
+                join_axes = [self.major_axis, self.minor_axis]
+            elif how == 'right':
+                raise ValueError('Right join not supported with multiple '
+                                 'panels')
+            else:
+                join_axes = None
+
+            return concat([self] + list(other), axis=0, join=how,
+                          join_axes=join_axes, verify_integrity=True)
 
     def _get_join_index(self, other, how):
         if how == 'left':
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index 7d598752a..1d724e005 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -3,7 +3,7 @@ Data structures for sparse float data. Life is made simpler by dealing only with
 float64 data
 """
 
-# pylint: disable=E1101,E1103,W0231
+# pylint: disable=E1101,E1103,W0231,E0202
 
 from numpy import nan
 import numpy as np
@@ -13,10 +13,24 @@ from pandas.core.index import Index, MultiIndex, NULL_INDEX, _ensure_index
 from pandas.core.series import Series
 from pandas.core.frame import (DataFrame, extract_index, _prep_ndarray,
                                _default_index)
+from pandas.util.decorators import cache_readonly
 import pandas.core.datetools as datetools
 
 from pandas.sparse.series import SparseSeries
 
+
+class _SparseMockBlockManager(object):
+
+    def __init__(self, sp_frame):
+        self.sp_frame = sp_frame
+
+    def get(self, item):
+        return self.sp_frame[item].values
+
+    @property
+    def axes(self):
+        return [self.sp_frame.columns, self.sp_frame.index]
+
 class SparseDataFrame(DataFrame):
     """
     DataFrame containing sparse floating point data in the form of SparseSeries
@@ -71,6 +85,14 @@ class SparseDataFrame(DataFrame):
         self.columns = columns
         self.index = index
 
+    def _from_axes(self, data, axes):
+        columns, index = axes
+        return self._constructor(data, index=index, columns=columns)
+
+    @cache_readonly
+    def _data(self):
+        return _SparseMockBlockManager(self)
+
     def _get_numeric_columns(self):
         # everything is necessarily float64
         return self.columns
@@ -512,9 +534,6 @@ class SparseDataFrame(DataFrame):
         self.columns = new_columns
         self._series = new_series
 
-    def _get_raw_column(self, col):
-        return self._series[col].values
-
     def add_prefix(self, prefix):
         f = (('%s' % prefix) + '%s').__mod__
         return self.rename(columns=f)
diff --git a/pandas/tests/test_panel.py b/pandas/tests/test_panel.py
index 1cdfdd0e1..9a248525f 100644
--- a/pandas/tests/test_panel.py
+++ b/pandas/tests/test_panel.py
@@ -902,48 +902,6 @@ class TestPanel(unittest.TestCase, PanelTests, CheckIndexing,
 
         self.assertRaises(Exception, self.panel.shift, 1, axis='items')
 
-    def test_join(self):
-        p1 = self.panel.ix[:2, :10, :3]
-        p2 = self.panel.ix[2:, 5:, 2:]
-
-        # left join
-        result = p1.join(p2)
-        expected = p1.copy()
-        expected['ItemC'] = p2['ItemC']
-        assert_panel_equal(result, expected)
-
-        # right join
-        result = p1.join(p2, how='right')
-        expected = p2.copy()
-        expected['ItemA'] = p1['ItemA']
-        expected['ItemB'] = p1['ItemB']
-        expected = expected.reindex(items=['ItemA', 'ItemB', 'ItemC'])
-        assert_panel_equal(result, expected)
-
-        # inner join
-        result = p1.join(p2, how='inner')
-        expected = self.panel.ix[:, 5:10, 2:3]
-        assert_panel_equal(result, expected)
-
-        # outer join
-        result = p1.join(p2, how='outer')
-        expected = p1.reindex(major=self.panel.major_axis,
-                              minor=self.panel.minor_axis)
-        expected = expected.join(p2.reindex(major=self.panel.major_axis,
-                                            minor=self.panel.minor_axis))
-        assert_panel_equal(result, expected)
-
-    def test_join_overlap(self):
-        p1 = self.panel.ix[['ItemA', 'ItemB', 'ItemC']]
-        p2 = self.panel.ix[['ItemB', 'ItemC']]
-
-        joined = p1.join(p2, lsuffix='_p1', rsuffix='_p2')
-        p1_suf = p1.ix[['ItemB', 'ItemC']].add_suffix('_p1')
-        p2_suf = p2.ix[['ItemB', 'ItemC']].add_suffix('_p2')
-        no_overlap = self.panel.ix[['ItemA']]
-        expected = p1_suf.join(p2_suf).join(no_overlap)
-        assert_panel_equal(joined, expected)
-
     def test_repr_empty(self):
         empty = Panel()
         repr(empty)
diff --git a/pandas/tools/merge.py b/pandas/tools/merge.py
index f6315f803..47c4b679f 100644
--- a/pandas/tools/merge.py
+++ b/pandas/tools/merge.py
@@ -9,6 +9,7 @@ from pandas.core.groupby import get_group_index
 from pandas.core.index import Index, MultiIndex, _get_combined_index
 from pandas.core.internals import (IntBlock, BoolBlock, BlockManager,
                                    make_block, _consolidate)
+from pandas.sparse.frame import SparseDataFrame
 from pandas.util.decorators import cache_readonly
 import pandas.core.common as com
 
@@ -24,6 +25,35 @@ def merge(left, right, how='inner', on=None, left_on=None, right_on=None,
     return op.get_result()
 if __debug__: merge.__doc__ = _merge_doc % '\nleft : DataFrame'
 
+
+def concat(objs, axis=0, join='outer', join_axes=None,
+           ignore_index=False, verify_integrity=False):
+    """
+    Concatenate DataFrame objects row or column wise
+
+    Parameters
+    ----------
+    objs : list of DataFrame objects
+    axis : {0, 1}, default 0
+        The axis to concatenate along
+    join : {'inner', 'outer'}, default 'outer'
+        How to handle indexes on other axis(es)
+    join_index : index-like
+    verify_integrity : boolean, default False
+        Check whether the new concatenated axis contains duplicates. This can
+        be very expensive relative to the actual data concatenation
+
+    Returns
+    -------
+    concatenated : DataFrame
+    """
+    op = Concatenator(objs, axis=axis, join_axes=join_axes,
+                      ignore_index=ignore_index, join=join,
+                      verify_integrity=verify_integrity)
+    return op.get_result()
+
+
+
 # TODO: NA group handling
 # TODO: transformations??
 # TODO: only copy DataFrames when modification necessary
@@ -580,39 +610,14 @@ def _get_all_block_kinds(blockmaps):
 #----------------------------------------------------------------------
 # Concatenate DataFrame objects
 
-def concat(frames, axis=0, join='outer', join_index=None,
-           ignore_index=False, verify_integrity=False):
-    """
-    Concatenate DataFrame objects row or column wise
-
-    Parameters
-    ----------
-    frames : list of DataFrame objects
-    axis : {0, 1}, default 0
-        The axis to concatenate along
-    join : {'inner', 'outer'}, default 'outer'
-        How to handle indexes on other axis
-    join_index : index-like
-    verify_integrity : boolean, default False
-        Check whether the new concatenated axis contains duplicates. This can
-        be very expensive relative to the actual data concatenation
-
-    Returns
-    -------
-    concatenated : DataFrame
-    """
-    op = Concatenator(frames, axis=axis, join_index=join_index,
-                      ignore_index=ignore_index, join=join,
-                      verify_integrity=verify_integrity)
-    return op.get_result()
-
 
 class Concatenator(object):
     """
-    Orchestrates a concatenation operation with a list of DataFrame objects
+    Orchestrates a concatenation operation for BlockManagers, with little hacks
+    to support sparse data structures, etc.
     """
 
-    def __init__(self, frames, axis=0, join='outer', join_index=None,
+    def __init__(self, objs, axis=0, join='outer', join_axes=None,
                  ignore_index=False, verify_integrity=False):
         if join == 'outer':
             self.intersect = False
@@ -623,32 +628,41 @@ class Concatenator(object):
                              'the other axis')
 
         # consolidate data
-        for frame in frames:
-            frame.consolidate(inplace=True)
+        for obj in objs:
+            obj.consolidate(inplace=True)
+        self.objs = objs
 
-        self.frames = frames
+        # Need to flip BlockManager axis in the DataFrame special case
+        if isinstance(objs[0], DataFrame):
+            axis = 1 if axis == 0 else 0
+
+        # note: this is the BlockManager axis (since DataFrame is transposed)
         self.axis = axis
-        self.join_index = join_index
+
+        self.join_axes = join_axes
 
         self.ignore_index = ignore_index
         self.verify_integrity = verify_integrity
-        self.new_index, self.new_columns = self._get_new_axes()
+
+        self.new_axes = self._get_new_axes()
 
     def get_result(self):
-        if len(self.frames) == 1:
-            return self.frames[0]
+        first = self.objs[0]
 
-        new_data = self._get_concatenated_data()
-        constructor = self._get_frame_constructor()
+        if len(self.objs) == 1:
+            return first
 
-        return constructor(new_data, index=self.new_index,
-                           columns=self.new_columns)
+        new_data = self._get_concatenated_data()
+        return first._from_axes(new_data, self.new_axes)
 
     def _get_concatenated_data(self):
         try:
+            # need to conform to same other (joined) axes for block join
+            reindexed_data = self._get_reindexed_data()
+
             blockmaps = []
-            for frame in self.frames:
-                type_map = dict((type(blk), blk) for blk in frame._data.blocks)
+            for data in reindexed_data:
+                type_map = dict((type(blk), blk) for blk in data.blocks)
                 blockmaps.append(type_map)
             kinds = _get_all_block_kinds(blockmaps)
 
@@ -657,43 +671,60 @@ class Concatenator(object):
                 klass_blocks = [mapping.get(kind) for mapping in blockmaps]
                 stacked_block = self._concat_blocks(klass_blocks)
                 new_blocks.append(stacked_block)
-            new_axes = [self.new_columns, self.new_index]
-            new_data = BlockManager(new_blocks, new_axes)
+            new_data = BlockManager(new_blocks, self.new_axes)
         except Exception:  # EAFP
             # should not be possible to fail here for the expected reason with
-            # axis=1
-            if self.axis == 1:  # pragma: no cover
+            # axis = 0
+            if self.axis == 0:  # pragma: no cover
                 raise
 
             new_data = {}
-            for column in self.new_columns:
-                new_data[column] = self._concat_single_column(column)
+            for item in self.new_axes[0]:
+                new_data[item] = self._concat_single_item(item)
 
         return new_data
 
+    def _get_reindexed_data(self):
+        # HACK: ugh
+
+        reindexed_data = []
+        if isinstance(self.objs[0], SparseDataFrame):
+            pass
+        else:
+            axes_to_reindex = list(enumerate(self.new_axes))
+            axes_to_reindex.pop(self.axis)
+
+            for obj in self.objs:
+                data = obj._data
+                for i, ax in axes_to_reindex:
+                    data = data.reindex_axis(ax, axis=i, copy=False)
+                reindexed_data.append(data)
+
+        return reindexed_data
+
     def _concat_blocks(self, blocks):
-        cat_axis = 0 if self.axis == 1 else 1
         concat_values = np.concatenate([b.values for b in blocks],
-                                       axis=cat_axis)
-        if self.axis == 0:
+                                       axis=self.axis)
+
+        if self.axis > 0:
             # Not safe to remove this check, need to profile
             if not _all_indexes_same([b.items for b in blocks]):
                 raise Exception('dtypes are not consistent throughout '
                                 'DataFrames')
-            return make_block(concat_values, blocks[0].items, self.new_columns)
+            return make_block(concat_values, blocks[0].items, self.new_axes[0])
         else:
             concat_items = _concat_indexes([b.items for b in blocks])
             # TODO: maybe want to "take" from the new columns?
-            return make_block(concat_values, concat_items, self.new_columns)
+            return make_block(concat_values, concat_items, self.new_axes[0])
 
-    def _concat_single_column(self, col):
+    def _concat_single_item(self, item):
         all_values = []
         dtypes = set()
-        for frame in self.frames:
-            if len(frame) == 0:
+        for obj in self.objs:
+            if len(obj) == 0:
                 continue
             try:
-                values = frame._get_raw_column(col)
+                values = obj._data.get(item)
                 dtypes.add(values.dtype)
                 all_values.append(values)
             except KeyError:
@@ -710,7 +741,7 @@ class Concatenator(object):
             empty_dtype = np.float64
 
         to_concat = []
-        for df, col_values in zip(self.frames, all_values):
+        for df, col_values in zip(self.objs, all_values):
             if col_values is None:
                 missing_arr = np.empty(len(df), dtype=empty_dtype)
                 missing_arr.fill(np.nan)
@@ -721,52 +752,49 @@ class Concatenator(object):
         return np.concatenate(to_concat)
 
     def _get_new_axes(self):
-        if self.axis == 0:
-            if self.ignore_index:
-                new_index = None
-            else:
-                new_index = _concat_indexes([x.index for x in self.frames])
-                self._maybe_check_integrity(new_index)
+        ndim = self.objs[0].ndim
+        new_axes = [None] * ndim
 
-            if self.join_index is None:
-                all_cols = [df.columns for df in self.frames]
-                new_columns = _get_combined_index(all_cols,
-                                                  intersect=self.intersect)
-            else:
-                new_columns = self.join_index
-
-            self.frames = [df.reindex(columns=new_columns, copy=False)
-                           for df in self.frames]
+        if self.ignore_index:
+            concat_axis = None
         else:
-            new_columns = _concat_indexes([df.columns for df in self.frames])
-            self._maybe_check_integrity(new_columns)
+            concat_axis = _concat_indexes([x._data.axes[self.axis]
+                                           for x in self.objs])
+            self._maybe_check_integrity(concat_axis)
+
+        new_axes[self.axis] = concat_axis
+
+        if self.join_axes is None:
+            for i in range(ndim):
+                if i == self.axis:
+                    continue
+                all_indexes = [x._data.axes[i] for x in self.objs]
+                comb_axis = _get_combined_index(all_indexes,
+                                                intersect=self.intersect)
+                new_axes[i] = comb_axis
 
-            if self.verify_integrity:
-                if not new_columns._verify_integrity():
-                    raise Exception('Indexes overlap!')
+        else:
+            assert(len(self.join_axes) == ndim - 1)
 
-            if self.join_index is None:
-                all_indexes = [df.index for df in self.frames]
-                new_index = _get_combined_index(all_indexes,
-                                                intersect=self.intersect)
-            else:
-                new_index = self.join_index
+            # ufff...
+            indices = range(ndim)
+            indices.remove(self.axis)
 
-            self.frames = [df.reindex(new_index, copy=False)
-                           for df in self.frames]
+            for i, ax in zip(indices, self.join_axes):
+                new_axes[i] = ax
 
-        return new_index, new_columns
+        return new_axes
 
-    def _get_frame_constructor(self):
+    def _get_obj_constructor(self):
         # SparseDataFrame causes us some headache here
 
         # check that there's only one type present
-        frame_types = set(type(df) for df in self.frames)
-        if len(frame_types) > 1:
+        obj_types = set(type(df) for df in self.objs)
+        if len(obj_types) > 1:
             raise Exception('Can only concatenate like-typed objects, found %s'
-                            % frame_types)
+                            % obj_types)
 
-        return self.frames[0]._constructor
+        return self.objs[0]._constructor
 
     def _maybe_check_integrity(self, concat_index):
         if self.verify_integrity:
@@ -777,7 +805,7 @@ class Concatenator(object):
 
     @cache_readonly
     def _all_indexes_same(self):
-        return _all_indexes_same([df.columns for df in self.frames])
+        return _all_indexes_same([df.columns for df in self.objs])
 
 def _concat_frames_hierarchical(frames, keys, groupings, axis=0):
     names = [ping.name for ping in groupings]
@@ -875,11 +903,3 @@ def _all_indexes_same(indexes):
             return False
     return True
 
-
-class _SparseMockBlockManager(object):
-
-    def __init__(self, sp_frame):
-        self.sp_frame = sp_frame
-
-    def get(self, item):
-        return self.sp_frame[item].values
diff --git a/pandas/tools/tests/test_merge.py b/pandas/tools/tests/test_merge.py
index 83b38100a..adb3f4b2f 100644
--- a/pandas/tools/tests/test_merge.py
+++ b/pandas/tools/tests/test_merge.py
@@ -733,7 +733,72 @@ class TestConcatenate(unittest.TestCase):
         self.assertRaises(ValueError, df_list[0].join, df_list[1:], on='a')
 
     def test_append_missing_column_proper_upcast(self):
-        pass
+        df1 = DataFrame({'A' : np.array([1,2, 3, 4], dtype='i8')})
+        df2 = DataFrame({'B' : np.array([True,False, True, False],
+                                        dtype=bool)})
+
+        appended = df1.append(df2, ignore_index=True)
+        self.assert_(appended['A'].dtype == 'f8')
+        self.assert_(appended['B'].dtype == 'O')
+
+
+    def test_panel_join(self):
+        panel = tm.makePanel()
+        tm.add_nans(panel)
+
+        p1 = panel.ix[:2, :10, :3]
+        p2 = panel.ix[2:, 5:, 2:]
+
+        # left join
+        result = p1.join(p2)
+        expected = p1.copy()
+        expected['ItemC'] = p2['ItemC']
+        tm.assert_panel_equal(result, expected)
+
+        # right join
+        result = p1.join(p2, how='right')
+        expected = p2.copy()
+        expected['ItemA'] = p1['ItemA']
+        expected['ItemB'] = p1['ItemB']
+        expected = expected.reindex(items=['ItemA', 'ItemB', 'ItemC'])
+        tm.assert_panel_equal(result, expected)
+
+        # inner join
+        result = p1.join(p2, how='inner')
+        expected = panel.ix[:, 5:10, 2:3]
+        tm.assert_panel_equal(result, expected)
+
+        # outer join
+        result = p1.join(p2, how='outer')
+        expected = p1.reindex(major=panel.major_axis,
+                              minor=panel.minor_axis)
+        expected = expected.join(p2.reindex(major=panel.major_axis,
+                                            minor=panel.minor_axis))
+        tm.assert_panel_equal(result, expected)
+
+    def test_panel_join_overlap(self):
+        panel = tm.makePanel()
+        tm.add_nans(panel)
+
+        p1 = panel.ix[['ItemA', 'ItemB', 'ItemC']]
+        p2 = panel.ix[['ItemB', 'ItemC']]
+
+        joined = p1.join(p2, lsuffix='_p1', rsuffix='_p2')
+        p1_suf = p1.ix[['ItemB', 'ItemC']].add_suffix('_p1')
+        p2_suf = p2.ix[['ItemB', 'ItemC']].add_suffix('_p2')
+        no_overlap = panel.ix[['ItemA']]
+        expected = p1_suf.join(p2_suf).join(no_overlap)
+        tm.assert_panel_equal(joined, expected)
+
+    def test_panel_join_many(self):
+        tm.K = 10
+        panel = tm.makePanel()
+        tm.K = 4
+
+        panels = [panel.ix[:2], panel.ix[2:6], panel.ix[6:]]
+
+        joined = panels[0].join(panels[1:])
+        tm.assert_panel_equal(joined, panel)
 
 if __name__ == '__main__':
     import nose
