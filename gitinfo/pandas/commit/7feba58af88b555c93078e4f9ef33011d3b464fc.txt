commit 7feba58af88b555c93078e4f9ef33011d3b464fc
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Tue Jan 23 17:03:40 2018 -0800

    Remove unused functions, cimports (#19360)

diff --git a/pandas/_libs/index.pyx b/pandas/_libs/index.pyx
index f8371d485..15aef867b 100644
--- a/pandas/_libs/index.pyx
+++ b/pandas/_libs/index.pyx
@@ -73,10 +73,6 @@ cpdef object get_value_box(ndarray arr, object loc):
         return util.get_value_1d(arr, i)
 
 
-def set_value_at(ndarray arr, object loc, object val):
-    return util.set_value_at(arr, loc, val)
-
-
 # Don't populate hash tables in monotonic indexes larger than this
 _SIZE_CUTOFF = 1000000
 
@@ -404,18 +400,6 @@ cdef Py_ssize_t _bin_search(ndarray values, object val) except -1:
     else:
         return mid + 1
 
-_pad_functions = {
-    'object': algos.pad_object,
-    'int64': algos.pad_int64,
-    'float64': algos.pad_float64
-}
-
-_backfill_functions = {
-    'object': algos.backfill_object,
-    'int64': algos.backfill_int64,
-    'float64': algos.backfill_float64
-}
-
 
 cdef class DatetimeEngine(Int64Engine):
 
@@ -566,7 +550,7 @@ cpdef convert_scalar(ndarray arr, object value):
     # we don't turn bools into int/float/complex
 
     if arr.descr.type_num == NPY_DATETIME:
-        if isinstance(value, np.ndarray):
+        if util.is_array(value):
             pass
         elif isinstance(value, (datetime, np.datetime64, date)):
             return Timestamp(value).value
@@ -577,7 +561,7 @@ cpdef convert_scalar(ndarray arr, object value):
         raise ValueError("cannot set a Timestamp with a non-timestamp")
 
     elif arr.descr.type_num == NPY_TIMEDELTA:
-        if isinstance(value, np.ndarray):
+        if util.is_array(value):
             pass
         elif isinstance(value, timedelta):
             return Timedelta(value).value
diff --git a/pandas/_libs/internals.pyx b/pandas/_libs/internals.pyx
index 93a45335e..a5abe3242 100644
--- a/pandas/_libs/internals.pyx
+++ b/pandas/_libs/internals.pyx
@@ -4,6 +4,7 @@ cimport cython
 from cython cimport Py_ssize_t
 
 from cpython cimport PyObject
+from cpython.slice cimport PySlice_Check
 
 cdef extern from "Python.h":
     Py_ssize_t PY_SSIZE_T_MAX
@@ -32,7 +33,7 @@ cdef class BlockPlacement:
         self._has_slice = False
         self._has_array = False
 
-        if isinstance(val, slice):
+        if PySlice_Check(val):
             slc = slice_canonize(val)
 
             if slc.start != slc.stop:
@@ -118,7 +119,7 @@ cdef class BlockPlacement:
         else:
             val = self._as_array[loc]
 
-        if not isinstance(val, slice) and val.ndim == 0:
+        if not PySlice_Check(val) and val.ndim == 0:
             return val
 
         return BlockPlacement(val)
@@ -288,7 +289,7 @@ def slice_getitem(slice slc not None, ind):
 
     s_start, s_stop, s_step, s_len = slice_get_indices_ex(slc)
 
-    if isinstance(ind, slice):
+    if PySlice_Check(ind):
         ind_start, ind_stop, ind_step, ind_len = slice_get_indices_ex(ind,
                                                                       s_len)
 
diff --git a/pandas/_libs/lib.pyx b/pandas/_libs/lib.pyx
index 1632f5d01..e337c2b25 100644
--- a/pandas/_libs/lib.pyx
+++ b/pandas/_libs/lib.pyx
@@ -17,8 +17,6 @@ from numpy cimport (ndarray, PyArray_NDIM, PyArray_GETITEM,
 np.import_array()
 np.import_ufunc()
 
-from libc.stdlib cimport malloc, free
-
 from cpython cimport (Py_INCREF, PyTuple_SET_ITEM,
                       PyList_Check, PyFloat_Check,
                       PyString_Check,
@@ -27,8 +25,7 @@ from cpython cimport (Py_INCREF, PyTuple_SET_ITEM,
                       PyTuple_New,
                       PyObject_RichCompareBool,
                       PyBytes_GET_SIZE,
-                      PyUnicode_GET_SIZE,
-                      PyObject)
+                      PyUnicode_GET_SIZE)
 
 try:
     from cpython cimport PyString_GET_SIZE
@@ -37,17 +34,12 @@ except ImportError:
 
 cimport cpython
 
-isnan = np.isnan
-cdef double NaN = <double> np.NaN
-cdef double nan = NaN
 
 from cpython.datetime cimport (PyDateTime_Check, PyDate_Check,
                                PyTime_Check, PyDelta_Check,
                                PyDateTime_IMPORT)
 PyDateTime_IMPORT
 
-from tslibs.np_datetime cimport get_timedelta64_value, get_datetime64_value
-
 from tslib import NaT, Timestamp, Timedelta, array_to_datetime
 from interval import Interval
 from missing cimport checknull
diff --git a/pandas/_libs/reduction.pyx b/pandas/_libs/reduction.pyx
index d51583c7a..4ca87a777 100644
--- a/pandas/_libs/reduction.pyx
+++ b/pandas/_libs/reduction.pyx
@@ -24,9 +24,9 @@ is_numpy_prior_1_6_2 = LooseVersion(np.__version__) < '1.6.2'
 
 cdef _get_result_array(object obj, Py_ssize_t size, Py_ssize_t cnt):
 
-    if isinstance(obj, np.ndarray) \
-            or isinstance(obj, list) and len(obj) == cnt \
-            or getattr(obj, 'shape', None) == (cnt,):
+    if (util.is_array(obj) or
+            isinstance(obj, list) and len(obj) == cnt or
+            getattr(obj, 'shape', None) == (cnt,)):
         raise ValueError('function does not reduce')
 
     return np.empty(size, dtype='O')
@@ -150,8 +150,7 @@ cdef class Reducer:
                 else:
                     res = self.f(chunk)
 
-                if hasattr(res, 'values') and isinstance(
-                        res.values, np.ndarray):
+                if hasattr(res, 'values') and util.is_array(res.values):
                     res = res.values
                 if i == 0:
                     result = _get_result_array(res,
@@ -433,10 +432,10 @@ cdef class SeriesGrouper:
 cdef inline _extract_result(object res):
     """ extract the result object, it might be a 0-dim ndarray
         or a len-1 0-dim, or a scalar """
-    if hasattr(res, 'values') and isinstance(res.values, np.ndarray):
+    if hasattr(res, 'values') and util.is_array(res.values):
         res = res.values
     if not np.isscalar(res):
-        if isinstance(res, np.ndarray):
+        if util.is_array(res):
             if res.ndim == 0:
                 res = res.item()
             elif res.ndim == 1 and len(res) == 1:
diff --git a/pandas/_libs/src/inference.pyx b/pandas/_libs/src/inference.pyx
index e15f276b3..52ae32023 100644
--- a/pandas/_libs/src/inference.pyx
+++ b/pandas/_libs/src/inference.pyx
@@ -10,10 +10,9 @@ from datetime import datetime, timedelta
 iNaT = util.get_nat()
 
 cdef bint PY2 = sys.version_info[0] == 2
+cdef double nan = <double> np.NaN
 
-from util cimport (UINT8_MAX, UINT16_MAX, UINT32_MAX, UINT64_MAX,
-                   INT8_MIN, INT8_MAX, INT16_MIN, INT16_MAX,
-                   INT32_MAX, INT32_MIN, INT64_MAX, INT64_MIN)
+from util cimport UINT8_MAX, UINT64_MAX, INT64_MAX, INT64_MIN
 
 # core.common import for fast inference checks
 
@@ -331,7 +330,7 @@ def infer_dtype(object value, bint skipna=False):
         bint seen_pdnat = False
         bint seen_val = False
 
-    if isinstance(value, np.ndarray):
+    if util.is_array(value):
         values = value
     elif hasattr(value, 'dtype'):
 
@@ -349,7 +348,7 @@ def infer_dtype(object value, bint skipna=False):
             raise ValueError("cannot infer type for {0}".format(type(value)))
 
     else:
-        if not isinstance(value, list):
+        if not PyList_Check(value):
             value = list(value)
         from pandas.core.dtypes.cast import (
             construct_1d_object_array_from_listlike)
diff --git a/pandas/_libs/tslibs/offsets.pyx b/pandas/_libs/tslibs/offsets.pyx
index 700ba5b6e..a0ac6389c 100644
--- a/pandas/_libs/tslibs/offsets.pyx
+++ b/pandas/_libs/tslibs/offsets.pyx
@@ -306,8 +306,8 @@ class _BaseOffset(object):
     def __call__(self, other):
         return self.apply(other)
 
-    def __mul__(self, someInt):
-        return self.__class__(n=someInt * self.n, normalize=self.normalize,
+    def __mul__(self, other):
+        return self.__class__(n=other * self.n, normalize=self.normalize,
                               **self.kwds)
 
     def __neg__(self):
@@ -374,8 +374,8 @@ class _BaseOffset(object):
 
 class BaseOffset(_BaseOffset):
     # Here we add __rfoo__ methods that don't play well with cdef classes
-    def __rmul__(self, someInt):
-        return self.__mul__(someInt)
+    def __rmul__(self, other):
+        return self.__mul__(other)
 
     def __radd__(self, other):
         return self.__add__(other)
@@ -840,6 +840,8 @@ cpdef int roll_qtrday(datetime other, int n, int month, object day_opt,
     -------
     n : int number of periods to increment
     """
+    cdef:
+        int months_since
     # TODO: Merge this with roll_yearday by setting modby=12 there?
     #       code de-duplication versus perf hit?
     # TODO: with small adjustments this could be used in shift_quarters
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index 3ca150cda..9463512ac 100755
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -1936,10 +1936,6 @@ class _iAtIndexer(_ScalarAccessIndexer):
         return key
 
 
-# 32-bit floating point machine epsilon
-_eps = 1.1920929e-07
-
-
 def length_of_indexer(indexer, target=None):
     """return the length of a single non-tuple indexer which could be a slice
     """
@@ -1992,19 +1988,6 @@ def convert_to_index_sliceable(obj, key):
     return None
 
 
-def is_index_slice(obj):
-    def _is_valid_index(x):
-        return (is_integer(x) or is_float(x) and
-                np.allclose(x, int(x), rtol=_eps, atol=0))
-
-    def _crit(v):
-        return v is None or _is_valid_index(v)
-
-    both_none = obj.start is None and obj.stop is None
-
-    return not both_none and (_crit(obj.start) and _crit(obj.stop))
-
-
 def check_bool_indexer(ax, key):
     # boolean indexing, need to check that the data are aligned, otherwise
     # disallowed
diff --git a/pandas/core/sparse/series.py b/pandas/core/sparse/series.py
index 4b649927f..257b0791e 100644
--- a/pandas/core/sparse/series.py
+++ b/pandas/core/sparse/series.py
@@ -19,7 +19,7 @@ from pandas.core.internals import SingleBlockManager
 from pandas.core import generic
 import pandas.core.common as com
 import pandas.core.ops as ops
-import pandas._libs.index as _index
+import pandas._libs.index as libindex
 from pandas.util._decorators import Appender
 
 from pandas.core.sparse.array import (
@@ -560,7 +560,7 @@ class SparseSeries(Series):
             key = key.values
 
         values = self.values.to_dense()
-        values[key] = _index.convert_scalar(values, value)
+        values[key] = libindex.convert_scalar(values, value)
         values = SparseArray(values, fill_value=self.fill_value,
                              kind=self.kind)
         self._data = SingleBlockManager(values, self.index)
