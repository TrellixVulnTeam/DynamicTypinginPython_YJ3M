commit 698ee4504b6bac00ee42ec626228a973d61315e2
Author: Wes McKinney <wesmckinn@gmail.com>
Date:   Tue Jun 1 21:47:17 2010 +0000

    working on docs + unit tests
    
    git-svn-id: http://pandas.googlecode.com/svn/trunk@185 d5231056-7de3-11de-ac95-d976489f1ece

diff --git a/doc/Makefile b/doc/Makefile
deleted file mode 100644
index 7ce3d3a1b..000000000
--- a/doc/Makefile
+++ /dev/null
@@ -1,104 +0,0 @@
-# Makefile for Sphinx documentation
-#
-
-PYVER = 2.5
-PYTHON = python$(PYVER)
-
-# You can set these variables from the command line.
-SPHINXOPTS    =
-SPHINXBUILD   = sphinx-build
-PAPER         =
-
-NEED_AUTOSUMMARY = $(shell $(PYTHON) -c 'import sphinx; print sphinx.__version__ < "0.7" and "1" or ""')
-
-# Internal variables.
-PAPEROPT_a4     = -D latex_paper_size=a4
-PAPEROPT_letter = -D latex_paper_size=letter
-ALLSPHINXOPTS   = -d build/doctrees $(PAPEROPT_$(PAPER)) $(SPHINXOPTS) source
-
-.PHONY: help clean html dirhtml pickle json htmlhelp qthelp latex changes linkcheck doctest
-
-help:
-	@echo "Please use \`make <target>' where <target> is one of"
-	@echo "  html      to make standalone HTML files"
-	@echo "  dirhtml   to make HTML files named index.html in directories"
-	@echo "  pickle    to make pickle files"
-	@echo "  json      to make JSON files"
-	@echo "  htmlhelp  to make HTML files and a HTML help project"
-	@echo "  qthelp    to make HTML files and a qthelp project"
-	@echo "  latex     to make LaTeX files, you can set PAPER=a4 or PAPER=letter"
-	@echo "  changes   to make an overview of all changed/added/deprecated items"
-	@echo "  linkcheck to check all external links for integrity"
-	@echo "  doctest   to run all doctests embedded in the documentation (if enabled)"
-
-clean:
-	-rm -rf build/* source/generated
-
-
-generate: build/generate-stamp
-build/generate-stamp: $(wildcard source/*.rst)
-	mkdir -p build
-ifeq ($(NEED_AUTOSUMMARY),1)
-	$(PYTHON) \
-		./sphinxext/autosummary_generate.py source/*.rst \
-		-p dump.xml -o source/generated
-endif
-	touch build/generate-stamp
-
-html:
-	$(SPHINXBUILD) -b html $(ALLSPHINXOPTS) build/html
-	@echo
-	@echo "Build finished. The HTML pages are in build/html."
-
-dirhtml:
-	$(SPHINXBUILD) -b dirhtml $(ALLSPHINXOPTS) build/dirhtml
-	@echo
-	@echo "Build finished. The HTML pages are in build/dirhtml."
-
-pickle:
-	$(SPHINXBUILD) -b pickle $(ALLSPHINXOPTS) build/pickle
-	@echo
-	@echo "Build finished; now you can process the pickle files."
-
-json:
-	$(SPHINXBUILD) -b json $(ALLSPHINXOPTS) build/json
-	@echo
-	@echo "Build finished; now you can process the JSON files."
-
-htmlhelp:
-	$(SPHINXBUILD) -b htmlhelp $(ALLSPHINXOPTS) build/htmlhelp
-	@echo
-	@echo "Build finished; now you can run HTML Help Workshop with the" \
-	      ".hhp project file in build/htmlhelp."
-
-qthelp:
-	$(SPHINXBUILD) -b qthelp $(ALLSPHINXOPTS) build/qthelp
-	@echo
-	@echo "Build finished; now you can run "qcollectiongenerator" with the" \
-	      ".qhcp project file in build/qthelp, like this:"
-	@echo "# qcollectiongenerator build/qthelp/pandas.qhcp"
-	@echo "To view the help file:"
-	@echo "# assistant -collectionFile build/qthelp/pandas.qhc"
-
-latex:
-	$(SPHINXBUILD) -b latex $(ALLSPHINXOPTS) build/latex
-	@echo
-	@echo "Build finished; the LaTeX files are in build/latex."
-	@echo "Run \`make all-pdf' or \`make all-ps' in that directory to" \
-	      "run these through (pdf)latex."
-
-changes:
-	$(SPHINXBUILD) -b changes $(ALLSPHINXOPTS) build/changes
-	@echo
-	@echo "The overview file is in build/changes."
-
-linkcheck:
-	$(SPHINXBUILD) -b linkcheck $(ALLSPHINXOPTS) build/linkcheck
-	@echo
-	@echo "Link check complete; look for any errors in the above output " \
-	      "or in build/linkcheck/output.txt."
-
-doctest:
-	$(SPHINXBUILD) -b doctest $(ALLSPHINXOPTS) build/doctest
-	@echo "Testing of doctests in the sources finished, look at the " \
-	      "results in build/doctest/output.txt."
diff --git a/doc/make.py b/doc/make.py
index 57ba09d24..032f6c76d 100755
--- a/doc/make.py
+++ b/doc/make.py
@@ -1,3 +1,5 @@
+#!/usr/bin/env python
+
 """
 Python script for building documentation.
 
@@ -19,6 +21,8 @@ import shutil
 import sys
 import sphinx
 
+os.environ['PYTHONPATH'] = '..'
+
 SPHINX_BUILD = 'sphinxbuild'
 NEED_AUTOSUMMARY = sphinx.__version__ < 0.7
 
diff --git a/doc/source/conf.py b/doc/source/conf.py
index ec2f51df7..ffb51ef97 100644
--- a/doc/source/conf.py
+++ b/doc/source/conf.py
@@ -30,9 +30,15 @@ sys.path.extend([
 # Add any Sphinx extension module names here, as strings. They can be extensions
 # coming with Sphinx (named 'sphinx.ext.*') or your custom ones.  sphinxext.
 
-extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest','numpydoc',
-'sphinx.ext.intersphinx', 'sphinx.ext.todo', 'sphinx.ext.coverage',
-'sphinx.ext.pngmath', 'sphinx.ext.ifconfig', 'sphinx.ext.autosummary']
+extensions = ['sphinx.ext.autodoc',
+              'sphinx.ext.doctest',
+              'numpydoc',
+              'sphinx.ext.intersphinx',
+              'sphinx.ext.todo',
+              'sphinx.ext.coverage',
+              'sphinx.ext.pngmath',
+              'sphinx.ext.ifconfig',
+              'sphinx.ext.autosummary']
 
 # Add any paths that contain templates here, relative to this directory.
 templates_path = ['_templates', '_templates/autosummary']
diff --git a/doc/source/dataframe.rst b/doc/source/dataframe.rst
index 53f6772f6..4b9a6e270 100644
--- a/doc/source/dataframe.rst
+++ b/doc/source/dataframe.rst
@@ -38,6 +38,7 @@ multiple time series or cross sections with ease.
 
 :class:`~pandas.DataMatrix` has a similar constructor and can be used interchangeably.
 
+
 Basics
 ------
 
@@ -731,8 +732,7 @@ new index or list of columns.
    DataFrame.dropIncompleteRows
    DataFrame.merge
    DataFrame.fill
-   DataFrame.filterItems
-   DataFrame.filterLike
+   DataFrame.filter
 
 Sorting
 -------
@@ -742,28 +742,22 @@ TODO
 .. autosummary::
    :toctree: generated/
 
-   DataFrame.reindex
-   DataFrame.dropEmptyRows
-   DataFrame.dropIncompleteRows
-   DataFrame.merge
-   DataFrame.fill
-   DataFrame.filterItems
-   DataFrame.filterLike
+   DataFrame.sort
 
 Converting to ndarray
 ---------------------
 
 TODO
 
-Merging DataFrames based on key
--------------------------------
+Joining / merging DataFrames
+----------------------------
 
 TODO
 
 .. autosummary::
    :toctree: generated/
 
-   DataFrame.merge
+   DataFrame.join
 
 TimeSeries-oriented methods
 ---------------------------
@@ -833,12 +827,10 @@ TODO
    DataFrame.apply
    DataFrame.tapply
    DataFrame.applymap
-   DataFrame.sortUp
-   DataFrame.sortDown
+   DataFrame.sort
    DataFrame.combineFirst
    DataFrame.combineAdd
    DataFrame.combineMult
-   DataFrame.join
    DataFrame.plot
 
 DataFrame vs. DataMatrix
diff --git a/doc/source/datetools.rst b/doc/source/datetools.rst
index 706686ce5..8d99951d2 100644
--- a/doc/source/datetools.rst
+++ b/doc/source/datetools.rst
@@ -154,3 +154,8 @@ by some amount:
     2008-05-07 00:00:00     0.095594
     2008-06-06 00:00:00     0.031957
     2008-07-07 00:00:00     -0.058455
+
+.. _datetools.timerules:
+
+Time rules
+----------
\ No newline at end of file
diff --git a/doc/source/groupby.rst b/doc/source/groupby.rst
index e747bb9f9..30e71ff97 100644
--- a/doc/source/groupby.rst
+++ b/doc/source/groupby.rst
@@ -6,4 +6,3 @@ GroupBy operations
 
 .. currentmodule:: pandas
 
-
diff --git a/doc/source/index.rst b/doc/source/index.rst
index bb2263bc9..b5964780d 100755
--- a/doc/source/index.rst
+++ b/doc/source/index.rst
@@ -37,6 +37,18 @@ such as :mod:`scikits.statsmodels`.
    haven't used NumPy much or at all, please check out the `NumPy
    documentation <http://docs.scipy.org>`__ first.
 
+Who is pandas for?
+------------------
+
+ * Users of R or MATLAB who wish to switch to Python for interactive
+   data analysis and implementation of statistical models
+
+ * NumPy users who are looking for richer data structures for working
+   with time series and cross-sectional data.
+
+ * System developers who wish to have a robust and well-tested library
+   for building production applications involving such data sets.
+
 User manual
 -----------
 
@@ -55,27 +67,15 @@ User manual
 .. toctree::
     :maxdepth: 2
 
-    installation
+    overview
     core
     groupby
     datetools
     stats
+    r_interface
     examples
     missing_data
-
-.. Quick Reference
-.. ---------------
-
-.. .. autosummary::
-..    :toctree: generated/
-
-..    Index
-..    Series
-..    TimeSeries
-..    DataFrame
-..    DataMatrix
-..    WidePanel
-..    LongPanel
+    related
 
 Indices and tables
 ------------------
diff --git a/doc/source/indexobj.rst b/doc/source/indexobj.rst
index 571fcb33c..8e6e0dd92 100644
--- a/doc/source/indexobj.rst
+++ b/doc/source/indexobj.rst
@@ -86,3 +86,29 @@ To prevent undesired behavior, Index instances are immutable:
 
 	Exception: <class 'pandas.core.index.Index'> object is immutable
 
+Convenience methods
+-------------------
+
+A number of methods are provided for performing common set-like
+operations and comparisons:
+
+::
+
+    >>> index1 = Index(['a', 'b', 'c'])
+    >>> index2 = Index(['c', 'd', 'e'])
+
+    >>> index1.intersection(index2)
+    Index([c], dtype=object)
+
+    >>> index1.union(index2)
+    Index([a, b, c, d, e], dtype=object)
+
+    >>> index1.equals(index2)
+    False
+
+.. autosummary::
+   :toctree: generated/
+
+   Index.equals
+   Index.intersection
+   Index.union
diff --git a/doc/source/installation.rst b/doc/source/installation.rst
deleted file mode 100644
index 5b6cac12d..000000000
--- a/doc/source/installation.rst
+++ /dev/null
@@ -1,54 +0,0 @@
-************
-Installation
-************
-
-You have the option to install an official release or to build from
-source. If you choose to install from source and are on Windows, you
-will have to ensure that you have a compatible C compiler (gcc)
-installed (see below).
-
-Binary installers
------------------
-
-Available from the Google Code website and PyPI.
-
-Dependencies
-------------
-  * `NumPy <http://www.numpy.org>`__: 1.3.0 or higher
-  * `dateutil <http://labix.org/python-dateutil>`__
-
-Optional dependencies
----------------------
-
-  * `SciPy <http://www.scipy.org>`__: miscellaneous statistical functions
-  * `matplotlib <http://matplotlib.sourceforge.net/>`__: for plotting
-  * `scikits.statsmodels <http://statsmodels.sourceforge.net/>`__
-     * Needed for many parts of :mod:`pandas.stats`
-
-.. note::
-
-   Without the optional dependencies, many useful features will not
-   work. Hence, it is highly recommended that you install these.
-
-Installing from source
-----------------------
-
-The source code is hosted at http://pandas.googlecode.com, it can be
-checked out using SVN and compiled / installed like so:
-
-::
-
-  svn co http://pandas.googlecode.com/svn/trunk/ pandas
-
-  cd pandas
-
-  python setup.py install
-
-On Windows, you will need to download and install `gcc / MinGW
-<http://www.mingw.org/wiki/HOWTO_Install_the_MinGW_GCC_Compiler_Suite>`__.
-After adding it to your system path , you can install pandas by typing
-instead:
-
-::
-
-  python setup.py install --compiler=mingw32
diff --git a/doc/source/intro.rst b/doc/source/intro.rst
deleted file mode 100644
index dfa475188..000000000
--- a/doc/source/intro.rst
+++ /dev/null
@@ -1,9 +0,0 @@
-************
-Introduction
-************
-
-About
------
-
-History
--------
\ No newline at end of file
diff --git a/doc/source/overview.rst b/doc/source/overview.rst
new file mode 100644
index 000000000..2c5798c73
--- /dev/null
+++ b/doc/source/overview.rst
@@ -0,0 +1,101 @@
+.. _overview:
+
+.. currentmodule:: pandas
+
+****************
+Package overview
+****************
+
+:mod:`pandas` is a library providing a set of convenient and powerful
+data structures for working with labeled statistical (financial,
+economic, econometric) data sets. We will refer to this data as *time
+series* and *cross-sectional* (or *longitudinal*) which are common
+terms in statistics and econometrics. It has multiple target audiences:
+
+  * Non-developers who wish to be able to easily manipulate data sets
+in an interactive research environment.
+
+History
+-------
+
+Data structures at a glance
+---------------------------
+
+.. csv-table::
+    :header: "Dimensions", "Name", "Description"
+    :widths: 10, 15, 50
+
+    1, Series, "Most generic 1D structure"
+    1, TimeSeries, "Series indexed by datetimes"
+    2, DataFrame, "General 2D indexed tabular structure"
+    2, DataMatrix, "Same API as DataFrame but faster (for most operations)"
+    3, WidePanel, "General 3D panel data"
+    3, LongPanel, "Stacked (2D) format panel data"
+
+Why more than 1 data structure?
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+
+
+A quick note on mutation
+~~~~~~~~~~~~~~~~~~~~~~~~
+
+You will find that very few methods are capable of mutating a pandas
+data structure like DataFrame. In general, the result of method calls
+will return a new object (protecting the underlying data in the
+calling object). So we like to "favor immutability" where sensible.
+
+Installation
+------------
+
+You have the option to install an official release or to build from
+source. If you choose to install from source and are on Windows, you
+will have to ensure that you have a compatible C compiler (gcc)
+installed (see below).
+
+Binary installers
+~~~~~~~~~~~~~~~~~
+
+Available from the Google Code website and PyPI.
+
+Dependencies
+~~~~~~~~~~~~
+
+  * `NumPy <http://www.numpy.org>`__: 1.3.0 or higher
+  * `dateutil <http://labix.org/python-dateutil>`__
+
+Optional dependencies
+~~~~~~~~~~~~~~~~~~~~~
+
+  * `SciPy <http://www.scipy.org>`__: miscellaneous statistical functions
+  * `matplotlib <http://matplotlib.sourceforge.net/>`__: for plotting
+  * `scikits.statsmodels <http://statsmodels.sourceforge.net/>`__
+     * Needed for many parts of :mod:`pandas.stats`
+
+.. note::
+
+   Without the optional dependencies, many useful features will not
+   work. Hence, it is highly recommended that you install these.
+
+Installing from source
+~~~~~~~~~~~~~~~~~~~~~~
+
+The source code is hosted at http://pandas.googlecode.com, it can be
+checked out using SVN and compiled / installed like so:
+
+::
+
+  svn co http://pandas.googlecode.com/svn/trunk/ pandas
+
+  cd pandas
+
+  python setup.py install
+
+On Windows, you will need to download and install `gcc / MinGW
+<http://www.mingw.org/wiki/HOWTO_Install_the_MinGW_GCC_Compiler_Suite>`__.
+After adding it to your system path , you can install pandas by typing
+instead:
+
+::
+
+  python setup.py install --compiler=mingw32
diff --git a/doc/source/r_interface.rst b/doc/source/r_interface.rst
new file mode 100644
index 000000000..2112ec46b
--- /dev/null
+++ b/doc/source/r_interface.rst
@@ -0,0 +1,8 @@
+.. currentmodule:: pandas.io.rpy
+
+.. _rpy:
+
+***************************
+pandas interface to rpy / R
+***************************
+
diff --git a/doc/source/stats.rst b/doc/source/stats.rst
index ead411a5a..931b1da23 100755
--- a/doc/source/stats.rst
+++ b/doc/source/stats.rst
@@ -6,8 +6,100 @@
 Statistical functionality
 *************************
 
-Least-squares entry-point
--------------------------
+Moving statistical statistics / moments
+---------------------------------------
+
+For TimeSeries-oriented operations, a number of functions are provided
+for computing common *moving* or *rolling* statistics. Among these are
+count, sum, mean, median, correlation, variance, covariance, standard
+deviation, skewness, and kurtosis. All of these methods are in the
+:mod:`pandas` namespace, but otherwise they can be found in
+:mod:`pandas.stats.moments`.
+
+Each of these methods observes the same interface (with relevant
+methods accepting two Series arguments instead of one):
+
+::
+
+    >>> ts
+    2000-01-31 00:00:00    -0.550139282247
+    2000-02-01 00:00:00    0.0950636484432
+    2000-02-02 00:00:00    0.0621763420914
+    2000-02-03 00:00:00    0.125698607137
+    2000-02-04 00:00:00    0.222288320816
+    2000-02-07 00:00:00    0.903314747152
+    2000-02-08 00:00:00    -0.391449402196
+    2000-02-09 00:00:00    -0.726137553115
+    2000-02-10 00:00:00    -0.89302167539
+    2000-02-11 00:00:00    0.228509179513
+
+    >>> rolling_sum(ts, 5, min_periods=3)
+    2000-01-31 00:00:00    NaN
+    2000-02-01 00:00:00    NaN
+    2000-02-02 00:00:00    -0.0913037710365
+    2000-02-03 00:00:00    0.798752592168
+    2000-02-04 00:00:00    1.39432346651
+    2000-02-07 00:00:00    2.44074916551
+    2000-02-08 00:00:00    2.77458564938
+    2000-02-09 00:00:00    1.87181399193
+    2000-02-10 00:00:00    2.48549563273
+    2000-02-11 00:00:00    1.81285272663
+
+If passed a DataFrame or DataMatrix argument, the statistics will be
+applied independently to the columns:
+
+::
+
+    >>> df
+			   A              B              C              D
+    2000-01-31 00:00:00    NaN            NaN            0.03752        -0.3952
+    2000-02-01 00:00:00    NaN            NaN            -1.511         -0.1126
+    2000-02-02 00:00:00    1.136          NaN            0.777          -0.3502
+    2000-02-03 00:00:00    0.8901         NaN            1.196          0.7456
+    2000-02-04 00:00:00    0.5956         0.7684         0.9042         0.4984
+    2000-02-07 00:00:00    -0.3502        1.015          0.5366         0.6628
+    2000-02-08 00:00:00    0.5036         1.825          0.8682         -1.69
+    2000-02-09 00:00:00    0.2327         -0.3899        0.4493         -0.1267
+    2000-02-10 00:00:00    1.504          0.3904         -0.06148       1.717
+    2000-02-11 00:00:00    -0.07707       0.2286         -1.039         0.1438
+
+    >>> rolling_mean(df, 5, min_periods=3)
+			   A              B              C              D
+    2000-01-31 00:00:00    NaN            NaN            NaN            NaN
+    2000-02-01 00:00:00    NaN            NaN            NaN            NaN
+    2000-02-02 00:00:00    NaN            NaN            -0.2321        -0.286
+    2000-02-03 00:00:00    NaN            NaN            0.125          -0.02811
+    2000-02-04 00:00:00    0.8737         NaN            0.2809         0.07718
+    2000-02-07 00:00:00    0.5677         NaN            0.3807         0.2888
+    2000-02-08 00:00:00    0.5549         1.203          0.8565         -0.0267
+    2000-02-09 00:00:00    0.3744         0.8047         0.7909         0.018
+    2000-02-10 00:00:00    0.4971         0.7219         0.5394         0.2123
+    2000-02-11 00:00:00    0.3626         0.6139         0.1507         0.1414
+
+Each of these methods can optionally accept a **time_rule** argument
+(see :ref:`time rules <datetools.timerules>`) which is provided as a
+convenience when the user wishes to guarantee that the window of the
+statistic
+
+.. autosummary::
+   :toctree: generated/
+
+   rolling_count
+   rolling_sum
+   rolling_mean
+   rolling_median
+   rolling_var
+   rolling_std
+   rolling_corr
+   rolling_cov
+   rolling_skew
+   rolling_kurt
+
+Exponentially weighted moving average
+-------------------------------------
+
+Linear and panel regression
+---------------------------
 
 .. autosummary::
    :toctree: generated/
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index f0ea1160c..eefbe9d8d 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -1173,35 +1173,19 @@ class DataFrame(Picklable, Groupable):
 
         return self.reindex(columns=columns)
 
-    def sortUp(self, column=None):
-        """
-        Sort DataFrame in ascending order according to specified column,
-        otherwise by the index.
-        """
-        if column:
-            series = self[column].order(missingAtEnd=True)
-            return self.reindex(series.index)
-        else:
-            idx = np.array(np.argsort(self.index))
-            newIndex = self.index[idx.astype(int)]
-            return self.reindex(newIndex)
-
-    def sortDown(self, column=None):
-        """
-        Sort DataFrame in ascending order according to specified column,
-        otherwise by the index.
-        """
+    def sort(self, column=None, ascending=True):
         if column:
             series = self[column].order(missingAtEnd=False)
-            return self.reindex(series.index[::-1])
+            sort_index = series.index
         else:
-            idx = np.array(np.argsort(self.index))
-            idx = idx[::-1]  # Reverses array
-            newIndex = self.index[idx.astype(int)]
-            return self.reindex(newIndex)
+            index = np.asarray(self.index)
+            argsorted = np.argsort(index)
+            sort_index = index[argsorted.astype(int)]
 
-    def sort(self, column=None, ascending=True):
-        pass
+        if not ascending:
+            sort_index = sort_index[::-1]
+
+        return self.reindex(sort_index)
 
     def combine(self, other, func, fill_value=None):
         """
diff --git a/pandas/core/matrix.py b/pandas/core/matrix.py
index e846e09b2..ff25cbbc2 100644
--- a/pandas/core/matrix.py
+++ b/pandas/core/matrix.py
@@ -8,7 +8,6 @@ from numpy import NaN
 import numpy as np
 
 from pandas.core.common import _pfixed, _pickle_array, _unpickle_array
-from pandas.core.daterange import DateRange
 from pandas.core.frame import DataFrame, _try_sort, _extract_index
 from pandas.core.index import Index, NULL_INDEX
 from pandas.core.series import Series
diff --git a/pandas/core/tests/test_frame.py b/pandas/core/tests/test_frame.py
index 8d741896e..6f275c29a 100644
--- a/pandas/core/tests/test_frame.py
+++ b/pandas/core/tests/test_frame.py
@@ -1023,23 +1023,20 @@ class TestDataFrame(unittest.TestCase):
         self.assert_('AA' in filtered)
 
         # regex
-        filterd = fcopy.filter(regex='[A]+')
+        filtered = fcopy.filter(regex='[A]+')
         self.assertEqual(len(filtered.cols()), 2)
         self.assert_('AA' in filtered)
 
         # pass in None
         self.assertRaises(Exception, self.frame.filter, items=None)
 
-    def test_sortUp(self):
-        # what to do?
-        sorted = self.frame.sortUp()
-
-        sorted_A = self.frame.sortUp(column='A')
-
-    def test_sortDown(self):
-        sorted = self.frame.sortDown()
+    def test_sort(self):
+        # what to test?
+        sorted = self.frame.sort()
+        sorted_A = self.frame.sort(column='A')
 
-        sorted_A = self.frame.sortDown(column='A')
+        sorted = self.frame.sort(ascending=False)
+        sorted_A = self.frame.sort(column='A', ascending=False)
 
     def test_combineFirst(self):
         # disjoint
diff --git a/pandas/core/tests/test_matrix.py b/pandas/core/tests/test_matrix.py
index 5088c261e..513a301c5 100644
--- a/pandas/core/tests/test_matrix.py
+++ b/pandas/core/tests/test_matrix.py
@@ -6,7 +6,7 @@ import unittest
 from numpy.random import randn
 import numpy as np
 
-from pandas.core.api import Index, Series, DataMatrix, DataFrame
+from pandas.core.api import Index, Series, DataMatrix, DataFrame, isnull
 
 import pandas.util.testing as common
 import test_frame
@@ -188,6 +188,19 @@ class TestDataMatrix(test_frame.TestDataFrame):
         values = self.mixed_frame.asMatrix()
         self.assertEqual(values.shape[1], len(self.mixed_frame.cols()))
 
+    def test_reindex_bool(self):
+        frame = DataMatrix(np.ones((10, 2), dtype=bool),
+                           index=np.arange(0, 20, 2),
+                           columns=[0, 2])
+
+        reindexed = frame.reindex(np.arange(10))
+        self.assert_(reindexed.values.dtype == np.object_)
+        self.assert_(np.isnan(reindexed[0][1]))
+
+        reindexed = frame.reindex(columns=range(3))
+        self.assert_(reindexed.values.dtype == np.object_)
+        self.assert_(isnull(reindexed[1]).all())
+
     def test_reindex_objects(self):
         reindexed = self.mixed_frame.reindex(columns=['foo', 'A', 'B'])
         self.assert_('foo' in reindexed)
@@ -206,6 +219,11 @@ class TestDataMatrix(test_frame.TestDataFrame):
         smaller = self.intframe.reindex(columns=['A', 'B', 'E'])
         self.assert_(smaller['E'].dtype == np.float_)
 
+    def test_rename_objects(self):
+        renamed = self.mixed_frame.rename(columns=str.upper)
+        self.assert_('FOO' in renamed)
+        self.assert_('foo' not in renamed)
+
     def test_fill_corner(self):
         self.mixed_frame['foo'][5:20] = np.NaN
         self.mixed_frame['A'][-10:] = np.NaN
diff --git a/pandas/core/tests/test_series.py b/pandas/core/tests/test_series.py
index 631a6d77d..04af386d1 100644
--- a/pandas/core/tests/test_series.py
+++ b/pandas/core/tests/test_series.py
@@ -320,6 +320,12 @@ class TestSeries(unittest.TestCase):
         deltas5 = deltas * 5
         deltas = deltas + sub_deltas
 
+        # float + int
+        int_ts = self.ts.astype(int)[:-5]
+        added = self.ts + int_ts
+        expected = self.ts.values()[:-5] + int_ts.values()
+        self.assert_(np.array_equal(added[:-5], expected))
+
     def test_operators_frame(self):
         # rpow does not work with DataFrame
         df = DataFrame({'A' : self.ts})
@@ -653,6 +659,16 @@ class TestSeries(unittest.TestCase):
         filled_bool = bool_ts.reindex(self.ts.index, fillMethod='pad')
         self.assert_(isnull(filled_bool[:5]).all())
 
+    def test_rename(self):
+        renamer = lambda x: x.strftime('%Y%m%d')
+        renamed = self.ts.rename(renamer)
+        self.assertEqual(renamed.index[0], renamer(self.ts.index[0]))
+
+        # dict
+        rename_dict = dict(zip(self.ts.index, renamed.index))
+        renamed2 = self.ts.rename(rename_dict)
+        assert_series_equal(renamed, renamed2)
+
     def test_preserveRefs(self):
         sl = self.ts[5:10]
         seq = self.ts[[5,10,15]]
diff --git a/pandas/stats/moments.py b/pandas/stats/moments.py
index 46ed1217b..896aba685 100644
--- a/pandas/stats/moments.py
+++ b/pandas/stats/moments.py
@@ -18,7 +18,7 @@ __all__ = ['rolling_count', 'rolling_sum', 'rolling_mean',
 #-------------------------------------------------------------------------------
 # Rolling statistics
 
-def rolling_count(arg, window, timeRule=None):
+def rolling_count(arg, window, time_rule=None):
     """
     Rolling count of number of observations inside provided window.
 
@@ -32,28 +32,28 @@ def rolling_count(arg, window, timeRule=None):
     Uses Cython
     """
     types = (DataFrame, DataMatrix, TimeSeries)
-    if timeRule is not None and isinstance(arg, types):
+    if time_rule is not None and isinstance(arg, types):
         # Conform to whatever frequency needed.
-        arg = arg.asfreq(timeRule)
+        arg = arg.asfreq(time_rule)
 
     window = min(window, len(arg))
     if isinstance(arg, DataMatrix):
         arg = arg.copy()
         arg.values = np.isfinite(arg.values).astype(float)
-        result = rolling_sum(arg, window, minPeriods=1, timeRule=timeRule)
+        result = rolling_sum(arg, window, min_periods=1, time_rule=time_rule)
         result.values[np.isnan(result.values)] = 0
     elif isinstance(arg, DataFrame):
         converter = lambda x: np.isfinite(x).astype(float)
         arg = arg.apply(converter)
-        result = rolling_sum(arg, window, minPeriods=1, timeRule=timeRule)
+        result = rolling_sum(arg, window, min_periods=1, time_rule=time_rule)
         result = result.fill(value=0)
     else:
         arg = np.isfinite(arg).astype(float)
-        result = rolling_sum(arg, window, minPeriods=1, timeRule=timeRule)
+        result = rolling_sum(arg, window, min_periods=1, time_rule=time_rule)
         result[np.isnan(result)] = 0
     return result
 
-def rolling_sum(arg, window=0, minPeriods=None, timeRule=None):
+def rolling_sum(arg, window=0, min_periods=None, time_rule=None):
     """
     Rolling sum of observations inside provided window.
 
@@ -62,10 +62,10 @@ def rolling_sum(arg, window=0, minPeriods=None, timeRule=None):
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
     """
-    return _rollingMoment(arg, window, tseries.rolling_sum, minp=minPeriods,
-                          timeRule=timeRule)
+    return _rollingMoment(arg, window, tseries.rolling_sum, minp=min_periods,
+                          time_rule=time_rule)
 
-def _rollingMoment(arg, window, func, minp=None, timeRule=None):
+def _rollingMoment(arg, window, func, minp=None, time_rule=None):
     """
     Rolling statistical measure using supplied function. Designed to be
     used with passed-in Cython array-based functions.
@@ -82,9 +82,9 @@ def _rollingMoment(arg, window, func, minp=None, timeRule=None):
         minp = window
 
     types = (DataFrame, DataMatrix, TimeSeries)
-    if timeRule is not None and isinstance(arg, types):
+    if time_rule is not None and isinstance(arg, types):
         # Conform to whatever frequency needed.
-        arg = arg.asfreq(timeRule)
+        arg = arg.asfreq(time_rule)
 
     if isinstance(arg, DataMatrix):
         T, N = arg.values.shape
@@ -113,7 +113,7 @@ def _rollingMoment(arg, window, func, minp=None, timeRule=None):
         output = func(arg, window, minp=minp)
     return output
 
-def rolling_cov(arg1, arg2, window, minPeriods=None, timeRule=None):
+def rolling_cov(arg1, arg2, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Covariance
 
@@ -121,17 +121,17 @@ def rolling_cov(arg1, arg2, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
-    num1 = rolling_mean(arg1*arg2, window, minPeriods, timeRule) #E(XY)
-    num2 = (rolling_mean(arg1, window, minPeriods, timeRule) *
-            rolling_mean(arg2, window, minPeriods, timeRule)) #E(X)E(Y)
+    num1 = rolling_mean(arg1*arg2, window, min_periods, time_rule) #E(XY)
+    num2 = (rolling_mean(arg1, window, min_periods, time_rule) *
+            rolling_mean(arg2, window, min_periods, time_rule)) #E(X)E(Y)
     return (num1-num2)*window/(window-1)
 
-def rolling_corr(arg1, arg2, window, minPeriods=None, timeRule=None):
+def rolling_corr(arg1, arg2, window, min_periods=None, time_rule=None):
     """
     Rolling Correl
 
@@ -139,17 +139,17 @@ def rolling_corr(arg1, arg2, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
-    num = rolling_cov(arg1, arg2, window, minPeriods, timeRule) #Cov(X,Y)
-    den  = (rolling_std(arg1, window, minPeriods, timeRule) *
-            rolling_std(arg2, window, minPeriods, timeRule)) #STDEV(X)STDEV(Y)
+    num = rolling_cov(arg1, arg2, window, min_periods, time_rule) #Cov(X,Y)
+    den  = (rolling_std(arg1, window, min_periods, time_rule) *
+            rolling_std(arg2, window, min_periods, time_rule)) #STDEV(X)STDEV(Y)
     return (num/den)
 
-def rolling_mean(arg, window, minPeriods=None, timeRule=None):
+def rolling_mean(arg, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Mean
 
@@ -157,15 +157,15 @@ def rolling_mean(arg, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
     return _rollingMoment(arg, window, tseries.rolling_mean,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
-def rolling_std(arg, window, minPeriods=None, timeRule=None):
+def rolling_std(arg, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Volatility
 
@@ -173,15 +173,15 @@ def rolling_std(arg, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
     return _rollingMoment(arg, window, tseries.rolling_std,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
-def rolling_var(arg, window, minPeriods=None, timeRule=None):
+def rolling_var(arg, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Variance
 
@@ -189,15 +189,15 @@ def rolling_var(arg, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
     return _rollingMoment(arg, window, tseries.rolling_var,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
-def rolling_skew(arg, window, minPeriods=None, timeRule=None):
+def rolling_skew(arg, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Skewness
 
@@ -205,15 +205,15 @@ def rolling_skew(arg, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
     return _rollingMoment(arg, window, tseries.rolling_skew,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
-def rolling_kurt(arg, window, minPeriods=None, timeRule=None):
+def rolling_kurt(arg, window, min_periods=None, time_rule=None):
     """
     Unbiased Rolling Kurtosis
 
@@ -221,17 +221,17 @@ def rolling_kurt(arg, window, minPeriods=None, timeRule=None):
     ----------
     arg :  DataFrame or numpy ndarray-like
     window : Number of observations used for calculating statistic
-    minPeriods : int
+    min_periods : int
         Minimum number of observations in window required to have a value
-    timeRule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
+    time_rule : {None, 'WEEKDAY', 'EOM', 'W@MON', ...}, default=None
         Name of time rule to conform to before computing statistic
     """
     return _rollingMoment(arg, window, tseries.rolling_kurt,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
-def rolling_median(arg, window, minPeriods=None, timeRule=None):
+def rolling_median(arg, window, min_periods=None, time_rule=None):
     return _rollingMoment(arg, window, tseries.rolling_median,
-                          minp=minPeriods, timeRule=timeRule)
+                          minp=min_periods, time_rule=time_rule)
 
 def test_rolling_median():
     arr = np.random.randn(100)
@@ -261,7 +261,7 @@ def _getMinPeriods(minPct, rho):
 
     return int(np.ceil(np.log(minPct) / np.log(rho)))
 
-def _ewmoment(values, func, minPeriods=None, minPct=0.95,
+def _ewmoment(values, func, min_periods=None, minPct=0.95,
               biasCorrection=None):
     """
     Generic rolling exponential moment function using blended accumulator
@@ -280,7 +280,7 @@ def _ewmoment(values, func, minPeriods=None, minPct=0.95,
 
     minPct : float
         Minimum percentage of weight "in window" to require to have a value
-    minPeriods : int, optional
+    min_periods : int, optional
         require a particular number of periods "in window" to compute statistic
         If provided, overrides the minPct argument
 
@@ -299,11 +299,11 @@ def _ewmoment(values, func, minPeriods=None, minPct=0.95,
     result = np.frompyfunc(func, 2, 1).accumulate(cleanValues)
     result = result.astype(float)
 
-    if minPeriods is not None:
-        if minPeriods < 0:
-            raise Exception('minPeriods cannot be less than 0!')
+    if min_periods is not None:
+        if min_periods < 0:
+            raise Exception('min_periods cannot be less than 0!')
 
-        result[:minPeriods] = np.NaN
+        result[:min_periods] = np.NaN
 
     output = values.copy()
     output[okLocs] = result
diff --git a/setup.py b/setup.py
index 1d1b3be7f..2aeb562e2 100644
--- a/setup.py
+++ b/setup.py
@@ -41,7 +41,7 @@ CLASSIFIERS = [
 ]
 
 MAJOR = 0
-MINOR = '2beta'
+MINOR = 2
 
 def get_version():
     return '%s.%s' % (MAJOR, MINOR)
diff --git a/setupegg.py b/setupegg.py
index 53c1b3dab..592a255b3 100644
--- a/setupegg.py
+++ b/setupegg.py
@@ -3,5 +3,17 @@
 A setup.py script to use setuptools.
 """
 
-from setuptools import setup
-execfile('setup.py')
+from setup import *
+# execfile('setup.py')
+setup(name=DISTNAME,
+      maintainer=MAINTAINER,
+      maintainer_email=MAINTAINER_EMAIL,
+      description=DESCRIPTION,
+      license=LICENSE,
+      url=URL,
+      download_url=DOWNLOAD_URL,
+      long_description=LONG_DESCRIPTION,
+      classifiers=CLASSIFIERS,
+      zip_safe=False,
+      platforms='any',
+      configuration=configuration)
