commit ee37443fa6c54f552434dda705fbc86062a944f9
Author: jbrockmendel <jbrockmendel@gmail.com>
Date:   Tue Jul 30 00:20:24 2019 -0700

    CLN: all the things (#27647)
    
    Thanks, @jbrockmendel.

diff --git a/pandas/_config/config.py b/pandas/_config/config.py
index 61e926035..4f0720abd 100644
--- a/pandas/_config/config.py
+++ b/pandas/_config/config.py
@@ -110,7 +110,7 @@ def _set_option(*args, **kwargs):
     # must at least 1 arg deal with constraints later
     nargs = len(args)
     if not nargs or nargs % 2 != 0:
-        raise ValueError("Must provide an even number of non-keyword " "arguments")
+        raise ValueError("Must provide an even number of non-keyword arguments")
 
     # default to false
     silent = kwargs.pop("silent", False)
@@ -395,7 +395,7 @@ class option_context:
     def __init__(self, *args):
         if not (len(args) % 2 == 0 and len(args) >= 2):
             raise ValueError(
-                "Need to invoke as" " option_context(pat, val, [(pat, val), ...])."
+                "Need to invoke as option_context(pat, val, [(pat, val), ...])."
             )
 
         self.ops = list(zip(args[::2], args[1::2]))
diff --git a/pandas/compat/numpy/function.py b/pandas/compat/numpy/function.py
index 89f7d71e2..c2fe7d1dd 100644
--- a/pandas/compat/numpy/function.py
+++ b/pandas/compat/numpy/function.py
@@ -59,7 +59,7 @@ class CompatValidator:
                 )
             else:
                 raise ValueError(
-                    "invalid validation method " "'{method}'".format(method=method)
+                    "invalid validation method '{method}'".format(method=method)
                 )
 
 
diff --git a/pandas/core/arrays/datetimes.py b/pandas/core/arrays/datetimes.py
index 8e76ad8a3..2e086c8ce 100644
--- a/pandas/core/arrays/datetimes.py
+++ b/pandas/core/arrays/datetimes.py
@@ -496,7 +496,7 @@ class DatetimeArray(dtl.DatetimeLikeArrayMixin, dtl.TimelikeOps, dtl.DatelikeOps
         if start is None and end is None:
             if closed is not None:
                 raise ValueError(
-                    "Closed has to be None if not both of startand end are defined"
+                    "Closed has to be None if not both of start and end are defined"
                 )
         if start is NaT or end is NaT:
             raise ValueError("Neither `start` nor `end` can be NaT")
diff --git a/pandas/core/groupby/generic.py b/pandas/core/groupby/generic.py
index 4dc1dfcae..da3db1c18 100644
--- a/pandas/core/groupby/generic.py
+++ b/pandas/core/groupby/generic.py
@@ -227,7 +227,7 @@ class NDFrameGroupBy(GroupBy):
             kwargs = {}
         elif func is None:
             # nicer error message
-            raise TypeError("Must provide 'func' or tuples of " "'(column, aggfunc).")
+            raise TypeError("Must provide 'func' or tuples of '(column, aggfunc).")
 
         func = _maybe_mangle_lambdas(func)
 
@@ -836,9 +836,7 @@ class SeriesGroupBy(GroupBy):
 
         relabeling = func_or_funcs is None
         columns = None
-        no_arg_message = (
-            "Must provide 'func_or_funcs' or named " "aggregation **kwargs."
-        )
+        no_arg_message = "Must provide 'func_or_funcs' or named aggregation **kwargs."
         if relabeling:
             columns = list(kwargs)
             if not PY36:
diff --git a/pandas/core/groupby/groupby.py b/pandas/core/groupby/groupby.py
index 5961a7ff7..15b94e59c 100644
--- a/pandas/core/groupby/groupby.py
+++ b/pandas/core/groupby/groupby.py
@@ -462,7 +462,7 @@ class _GroupBy(PandasObject, SelectionMixin):
         name_sample = names[0]
         if isinstance(index_sample, tuple):
             if not isinstance(name_sample, tuple):
-                msg = "must supply a tuple to get_group with multiple" " grouping keys"
+                msg = "must supply a tuple to get_group with multiple grouping keys"
                 raise ValueError(msg)
             if not len(name_sample) == len(index_sample):
                 try:
@@ -715,7 +715,7 @@ b  2""",
 
             else:
                 raise ValueError(
-                    "func must be a callable if args or " "kwargs are supplied"
+                    "func must be a callable if args or kwargs are supplied"
                 )
         else:
             f = func
@@ -1872,7 +1872,7 @@ class GroupBy(_GroupBy):
         def pre_processor(vals: np.ndarray) -> Tuple[np.ndarray, Optional[Type]]:
             if is_object_dtype(vals):
                 raise TypeError(
-                    "'quantile' cannot be performed against " "'object' dtypes!"
+                    "'quantile' cannot be performed against 'object' dtypes!"
                 )
 
             inference = None
@@ -2201,9 +2201,7 @@ class GroupBy(_GroupBy):
         `Series` or `DataFrame`  with filled values
         """
         if result_is_index and aggregate:
-            raise ValueError(
-                "'result_is_index' and 'aggregate' cannot both " "be True!"
-            )
+            raise ValueError("'result_is_index' and 'aggregate' cannot both be True!")
         if post_processing:
             if not callable(pre_processing):
                 raise ValueError("'post_processing' must be a callable!")
@@ -2212,7 +2210,7 @@ class GroupBy(_GroupBy):
                 raise ValueError("'pre_processing' must be a callable!")
             if not needs_values:
                 raise ValueError(
-                    "Cannot use 'pre_processing' without " "specifying 'needs_values'!"
+                    "Cannot use 'pre_processing' without specifying 'needs_values'!"
                 )
 
         labels, _, ngroups = grouper.group_info
diff --git a/pandas/core/groupby/grouper.py b/pandas/core/groupby/grouper.py
index f8417c3f0..1d88ebd26 100644
--- a/pandas/core/groupby/grouper.py
+++ b/pandas/core/groupby/grouper.py
@@ -25,6 +25,7 @@ import pandas.core.algorithms as algorithms
 from pandas.core.arrays import Categorical, ExtensionArray
 import pandas.core.common as com
 from pandas.core.frame import DataFrame
+from pandas.core.groupby.categorical import recode_for_groupby, recode_from_groupby
 from pandas.core.groupby.ops import BaseGrouper
 from pandas.core.index import CategoricalIndex, Index, MultiIndex
 from pandas.core.series import Series
@@ -310,8 +311,6 @@ class Grouping:
             # a passed Categorical
             elif is_categorical_dtype(self.grouper):
 
-                from pandas.core.groupby.categorical import recode_for_groupby
-
                 self.grouper, self.all_grouper = recode_for_groupby(
                     self.grouper, self.sort, observed
                 )
@@ -361,13 +360,10 @@ class Grouping:
         # Timestamps like
         if getattr(self.grouper, "dtype", None) is not None:
             if is_datetime64_dtype(self.grouper):
-                from pandas import to_datetime
-
-                self.grouper = to_datetime(self.grouper)
+                self.grouper = self.grouper.astype("datetime64[ns]")
             elif is_timedelta64_dtype(self.grouper):
-                from pandas import to_timedelta
 
-                self.grouper = to_timedelta(self.grouper)
+                self.grouper = self.grouper.astype("timedelta64[ns]")
 
     def __repr__(self):
         return "Grouping({0})".format(self.name)
@@ -400,8 +396,6 @@ class Grouping:
     @cache_readonly
     def result_index(self):
         if self.all_grouper is not None:
-            from pandas.core.groupby.categorical import recode_from_groupby
-
             return recode_from_groupby(self.all_grouper, self.sort, self.group_index)
         return self.group_index
 
@@ -493,12 +487,12 @@ def _get_grouper(
                 elif nlevels == 0:
                     raise ValueError("No group keys passed!")
                 else:
-                    raise ValueError("multiple levels only valid with " "MultiIndex")
+                    raise ValueError("multiple levels only valid with MultiIndex")
 
             if isinstance(level, str):
                 if obj.index.name != level:
                     raise ValueError(
-                        "level name {} is not the name of the " "index".format(level)
+                        "level name {} is not the name of the index".format(level)
                     )
             elif level > 0 or level < -1:
                 raise ValueError("level > 0 or level < -1 only valid with MultiIndex")
diff --git a/pandas/core/groupby/ops.py b/pandas/core/groupby/ops.py
index cc8aec4cc..1484feeea 100644
--- a/pandas/core/groupby/ops.py
+++ b/pandas/core/groupby/ops.py
@@ -467,12 +467,12 @@ class BaseGrouper:
         elif is_datetime64_any_dtype(values):
             if how in ["add", "prod", "cumsum", "cumprod"]:
                 raise NotImplementedError(
-                    "datetime64 type does not support {} " "operations".format(how)
+                    "datetime64 type does not support {} operations".format(how)
                 )
         elif is_timedelta64_dtype(values):
             if how in ["prod", "cumprod"]:
                 raise NotImplementedError(
-                    "timedelta64 type does not support {} " "operations".format(how)
+                    "timedelta64 type does not support {} operations".format(how)
                 )
 
         arity = self._cython_arity.get(how, 1)
@@ -489,7 +489,7 @@ class BaseGrouper:
                 values = values.T
             if arity > 1:
                 raise NotImplementedError(
-                    "arity of more than 1 is not " "supported for the 'how' argument"
+                    "arity of more than 1 is not supported for the 'how' argument"
                 )
             out_shape = (self.ngroups,) + values.shape[1:]
 
@@ -604,9 +604,7 @@ class BaseGrouper:
     ):
         if values.ndim > 3:
             # punting for now
-            raise NotImplementedError(
-                "number of dimensions is currently " "limited to 3"
-            )
+            raise NotImplementedError("number of dimensions is currently limited to 3")
         elif values.ndim > 2:
             for i, chunk in enumerate(values.transpose(2, 0, 1)):
 
@@ -631,9 +629,7 @@ class BaseGrouper:
         comp_ids, _, ngroups = self.group_info
         if values.ndim > 3:
             # punting for now
-            raise NotImplementedError(
-                "number of dimensions is currently " "limited to 3"
-            )
+            raise NotImplementedError("number of dimensions is currently limited to 3")
         elif values.ndim > 2:
             for i, chunk in enumerate(values.transpose(2, 0, 1)):
 
diff --git a/pandas/core/indexes/accessors.py b/pandas/core/indexes/accessors.py
index 5ba23990c..2036728e7 100644
--- a/pandas/core/indexes/accessors.py
+++ b/pandas/core/indexes/accessors.py
@@ -340,4 +340,4 @@ class CombinedDatetimelikeProperties(
         except Exception:
             pass  # we raise an attribute error anyway
 
-        raise AttributeError("Can only use .dt accessor with datetimelike " "values")
+        raise AttributeError("Can only use .dt accessor with datetimelike values")
diff --git a/pandas/core/indexes/base.py b/pandas/core/indexes/base.py
index 745f8f3c9..8cacd22fb 100644
--- a/pandas/core/indexes/base.py
+++ b/pandas/core/indexes/base.py
@@ -376,9 +376,7 @@ class Index(IndexOpsMixin, PandasObject):
                             data = maybe_cast_to_integer_array(data, dtype, copy=copy)
                         elif inferred in ["floating", "mixed-integer-float"]:
                             if isna(data).any():
-                                raise ValueError(
-                                    "cannot convert float " "NaN to integer"
-                                )
+                                raise ValueError("cannot convert float NaN to integer")
 
                             if inferred == "mixed-integer-float":
                                 data = maybe_cast_to_integer_array(data, dtype)
@@ -1182,7 +1180,7 @@ class Index(IndexOpsMixin, PandasObject):
         .. deprecated:: 0.23.0
         """
         warnings.warn(
-            "'summary' is deprecated and will be removed in a " "future version.",
+            "'summary' is deprecated and will be removed in a future version.",
             FutureWarning,
             stacklevel=2,
         )
@@ -1521,7 +1519,7 @@ class Index(IndexOpsMixin, PandasObject):
                 )
             elif level > 0:
                 raise IndexError(
-                    "Too many levels:" " Index has only 1 level, not %d" % (level + 1)
+                    "Too many levels: Index has only 1 level, not %d" % (level + 1)
                 )
         elif level != self.name:
             raise KeyError(
@@ -2953,7 +2951,7 @@ class Index(IndexOpsMixin, PandasObject):
 
         if not self.is_unique:
             raise InvalidIndexError(
-                "Reindexing only valid with uniquely" " valued Index objects"
+                "Reindexing only valid with uniquely valued Index objects"
             )
 
         if method == "pad" or method == "backfill":
@@ -2980,7 +2978,7 @@ class Index(IndexOpsMixin, PandasObject):
         # override this method on subclasses
         tolerance = np.asarray(tolerance)
         if target.size != tolerance.size and tolerance.size > 1:
-            raise ValueError("list-like tolerance size must match " "target index size")
+            raise ValueError("list-like tolerance size must match target index size")
         return tolerance
 
     def _get_fill_indexer(self, target, method, limit=None, tolerance=None):
@@ -3712,9 +3710,7 @@ class Index(IndexOpsMixin, PandasObject):
             return lib.get_level_sorter(lab, ensure_int64(starts))
 
         if isinstance(self, MultiIndex) and isinstance(other, MultiIndex):
-            raise TypeError(
-                "Join on level between two MultiIndex objects " "is ambiguous"
-            )
+            raise TypeError("Join on level between two MultiIndex objects is ambiguous")
 
         left, right = self, other
 
@@ -3728,7 +3724,7 @@ class Index(IndexOpsMixin, PandasObject):
 
         if not right.is_unique:
             raise NotImplementedError(
-                "Index._join_level on non-unique index " "is not implemented"
+                "Index._join_level on non-unique index is not implemented"
             )
 
         new_level, left_lev_indexer, right_lev_indexer = old_level.join(
@@ -4554,9 +4550,7 @@ class Index(IndexOpsMixin, PandasObject):
         """
         Use sort_values instead.
         """
-        raise TypeError(
-            "cannot sort an Index object in-place, use " "sort_values instead"
-        )
+        raise TypeError("cannot sort an Index object in-place, use sort_values instead")
 
     def shift(self, periods=1, freq=None):
         """
@@ -5205,7 +5199,7 @@ class Index(IndexOpsMixin, PandasObject):
                 pass
             else:
                 if not tz_compare(ts_start.tzinfo, ts_end.tzinfo):
-                    raise ValueError("Both dates must have the " "same UTC offset")
+                    raise ValueError("Both dates must have the same UTC offset")
 
         start_slice = None
         if start is not None:
@@ -5397,12 +5391,10 @@ class Index(IndexOpsMixin, PandasObject):
 
         if isinstance(other, (Index, ABCSeries, np.ndarray)):
             if len(self) != len(other):
-                raise ValueError("cannot evaluate a numeric op with " "unequal lengths")
+                raise ValueError("cannot evaluate a numeric op with unequal lengths")
             other = com.values_from_object(other)
             if other.dtype.kind not in ["f", "i", "u"]:
-                raise TypeError(
-                    "cannot evaluate a numeric op " "with a non-numeric dtype"
-                )
+                raise TypeError("cannot evaluate a numeric op with a non-numeric dtype")
         elif isinstance(other, (ABCDateOffset, np.timedelta64, timedelta)):
             # higher up to handle
             pass
@@ -5571,7 +5563,7 @@ class Index(IndexOpsMixin, PandasObject):
             return logical_func
 
         cls.all = _make_logical_function(
-            "all", "Return whether all elements " "are True.", np.all
+            "all", "Return whether all elements are True.", np.all
         )
         cls.any = _make_logical_function(
             "any", "Return whether any element is True.", np.any
diff --git a/pandas/core/indexes/category.py b/pandas/core/indexes/category.py
index e14bf7f86..0f6aa711a 100644
--- a/pandas/core/indexes/category.py
+++ b/pandas/core/indexes/category.py
@@ -7,6 +7,7 @@ import numpy as np
 from pandas._config import get_option
 
 from pandas._libs import index as libindex
+from pandas._libs.hashtable import duplicated_int64
 import pandas.compat as compat
 from pandas.compat.numpy import function as nv
 from pandas.util._decorators import Appender, cache_readonly
@@ -25,7 +26,7 @@ from pandas.core.dtypes.missing import isna
 from pandas._typing import AnyArrayLike
 from pandas.core import accessor
 from pandas.core.algorithms import take_1d
-from pandas.core.arrays.categorical import Categorical, contains
+from pandas.core.arrays.categorical import Categorical, _recode_for_categories, contains
 import pandas.core.common as com
 import pandas.core.indexes.base as ibase
 from pandas.core.indexes.base import Index, _index_shared_docs
@@ -290,7 +291,7 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
                 other = other._values
             if not other.is_dtype_equal(self):
                 raise TypeError(
-                    "categories must match existing categories " "when appending"
+                    "categories must match existing categories when appending"
                 )
         else:
             values = other
@@ -299,7 +300,7 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
             other = CategoricalIndex(self._create_categorical(other, dtype=self.dtype))
             if not other.isin(values).all():
                 raise TypeError(
-                    "cannot append a non-category item to a " "CategoricalIndex"
+                    "cannot append a non-category item to a CategoricalIndex"
                 )
 
         return other
@@ -473,8 +474,6 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
 
     @Appender(Index.duplicated.__doc__)
     def duplicated(self, keep="first"):
-        from pandas._libs.hashtable import duplicated_int64
-
         codes = self.codes.astype("i8")
         return duplicated_int64(codes, keep)
 
@@ -581,15 +580,15 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
 
         if method is not None:
             raise NotImplementedError(
-                "argument method is not implemented for " "CategoricalIndex.reindex"
+                "argument method is not implemented for CategoricalIndex.reindex"
             )
         if level is not None:
             raise NotImplementedError(
-                "argument level is not implemented for " "CategoricalIndex.reindex"
+                "argument level is not implemented for CategoricalIndex.reindex"
             )
         if limit is not None:
             raise NotImplementedError(
-                "argument limit is not implemented for " "CategoricalIndex.reindex"
+                "argument limit is not implemented for CategoricalIndex.reindex"
             )
 
         target = ibase.ensure_index(target)
@@ -657,8 +656,6 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
 
     @Appender(_index_shared_docs["get_indexer"] % _index_doc_kwargs)
     def get_indexer(self, target, method=None, limit=None, tolerance=None):
-        from pandas.core.arrays.categorical import _recode_for_categories
-
         method = missing.clean_reindex_fill_method(method)
         target = ibase.ensure_index(target)
 
@@ -672,7 +669,7 @@ class CategoricalIndex(Index, accessor.PandasDelegate):
             )
         elif method == "nearest":
             raise NotImplementedError(
-                "method='nearest' not implemented yet " "for CategoricalIndex"
+                "method='nearest' not implemented yet for CategoricalIndex"
             )
 
         if isinstance(target, CategoricalIndex) and self.values.is_dtype_equal(target):
diff --git a/pandas/core/indexes/datetimelike.py b/pandas/core/indexes/datetimelike.py
index 0fb8f6823..af99c7a27 100644
--- a/pandas/core/indexes/datetimelike.py
+++ b/pandas/core/indexes/datetimelike.py
@@ -325,7 +325,7 @@ class DatetimeIndexOpsMixin(ExtensionOpsMixin):
         *this is an internal non-public method*
         """
         warnings.warn(
-            "'asobject' is deprecated. Use 'astype(object)'" " instead",
+            "'asobject' is deprecated. Use 'astype(object)' instead",
             FutureWarning,
             stacklevel=2,
         )
@@ -335,7 +335,7 @@ class DatetimeIndexOpsMixin(ExtensionOpsMixin):
         tolerance = np.asarray(to_timedelta(tolerance).to_numpy())
 
         if target.size != tolerance.size and tolerance.size > 1:
-            raise ValueError("list-like tolerance size must match " "target index size")
+            raise ValueError("list-like tolerance size must match target index size")
         return tolerance
 
     def tolist(self):
diff --git a/pandas/core/indexes/datetimes.py b/pandas/core/indexes/datetimes.py
index e9296eea2..04522fde4 100644
--- a/pandas/core/indexes/datetimes.py
+++ b/pandas/core/indexes/datetimes.py
@@ -803,11 +803,9 @@ class DatetimeIndex(DatetimeIndexOpsMixin, Int64Index, DatetimeDelegateMixin):
         if isinstance(other, DatetimeIndex):
             if self.tz is not None:
                 if other.tz is None:
-                    raise TypeError(
-                        "Cannot join tz-naive with tz-aware " "DatetimeIndex"
-                    )
+                    raise TypeError("Cannot join tz-naive with tz-aware DatetimeIndex")
             elif other.tz is not None:
-                raise TypeError("Cannot join tz-naive with tz-aware " "DatetimeIndex")
+                raise TypeError("Cannot join tz-naive with tz-aware DatetimeIndex")
 
             if not timezones.tz_compare(self.tz, other.tz):
                 this = self.tz_convert("UTC")
@@ -1048,7 +1046,7 @@ class DatetimeIndex(DatetimeIndexOpsMixin, Int64Index, DatetimeDelegateMixin):
         if isinstance(key, time):
             if method is not None:
                 raise NotImplementedError(
-                    "cannot yet lookup inexact labels " "when key is a time object"
+                    "cannot yet lookup inexact labels when key is a time object"
                 )
             return self.indexer_at_time(key)
 
diff --git a/pandas/core/indexes/interval.py b/pandas/core/indexes/interval.py
index 66290ae54..d941dc547 100644
--- a/pandas/core/indexes/interval.py
+++ b/pandas/core/indexes/interval.py
@@ -1058,7 +1058,7 @@ class IntervalIndex(IntervalMixin, Index):
         if isinstance(item, Interval):
             if item.closed != self.closed:
                 raise ValueError(
-                    "inserted item must be closed on the same " "side as the index"
+                    "inserted item must be closed on the same side as the index"
                 )
             left_insert = item.left
             right_insert = item.right
@@ -1067,7 +1067,7 @@ class IntervalIndex(IntervalMixin, Index):
             left_insert = right_insert = item
         else:
             raise ValueError(
-                "can only insert Interval objects and NA into " "an IntervalIndex"
+                "can only insert Interval objects and NA into an IntervalIndex"
             )
 
         new_left = self.left.insert(loc, left_insert)
diff --git a/pandas/core/indexes/multi.py b/pandas/core/indexes/multi.py
index a7c344961..488107690 100644
--- a/pandas/core/indexes/multi.py
+++ b/pandas/core/indexes/multi.py
@@ -8,6 +8,7 @@ import numpy as np
 from pandas._config import get_option
 
 from pandas._libs import Timestamp, algos as libalgos, index as libindex, lib, tslibs
+from pandas._libs.hashtable import duplicated_int64
 from pandas.compat.numpy import function as nv
 from pandas.errors import PerformanceWarning, UnsortedIndexError
 from pandas.util._decorators import Appender, cache_readonly, deprecate_kwarg
@@ -29,6 +30,8 @@ from pandas.core.dtypes.generic import ABCDataFrame
 from pandas.core.dtypes.missing import array_equivalent, isna
 
 import pandas.core.algorithms as algos
+from pandas.core.arrays import Categorical
+from pandas.core.arrays.categorical import _factorize_from_iterables
 import pandas.core.common as com
 import pandas.core.indexes.base as ibase
 from pandas.core.indexes.base import (
@@ -39,6 +42,12 @@ from pandas.core.indexes.base import (
 )
 from pandas.core.indexes.frozen import FrozenList, _ensure_frozen
 import pandas.core.missing as missing
+from pandas.core.sorting import (
+    get_group_index,
+    indexer_from_factorized,
+    lexsort_indexer,
+)
+from pandas.core.util.hashing import hash_tuple, hash_tuples
 
 from pandas.io.formats.printing import (
     format_object_attrs,
@@ -415,8 +424,6 @@ class MultiIndex(Index):
             if len(arrays[i]) != len(arrays[i - 1]):
                 raise ValueError("all arrays must be same length")
 
-        from pandas.core.arrays.categorical import _factorize_from_iterables
-
         codes, levels = _factorize_from_iterables(arrays)
         if names is None:
             names = [getattr(arr, "name", None) for arr in arrays]
@@ -527,7 +534,6 @@ class MultiIndex(Index):
                     (2, 'purple')],
                    names=['number', 'color'])
         """
-        from pandas.core.arrays.categorical import _factorize_from_iterables
         from pandas.core.reshape.util import cartesian_product
 
         if not is_list_like(iterables):
@@ -772,7 +778,7 @@ class MultiIndex(Index):
     @property
     def labels(self):
         warnings.warn(
-            (".labels was deprecated in version 0.24.0. " "Use .codes instead."),
+            (".labels was deprecated in version 0.24.0. Use .codes instead."),
             FutureWarning,
             stacklevel=2,
         )
@@ -1213,7 +1219,7 @@ class MultiIndex(Index):
             raise ValueError("Length of names must match length of level.")
         if validate and level is None and len(names) != self.nlevels:
             raise ValueError(
-                "Length of names must match number of levels in " "MultiIndex."
+                "Length of names must match number of levels in MultiIndex."
             )
 
         if level is None:
@@ -1280,7 +1286,7 @@ class MultiIndex(Index):
         count = self.names.count(level)
         if (count > 1) and not is_integer(level):
             raise ValueError(
-                "The name %s occurs multiple times, use a " "level number" % level
+                "The name %s occurs multiple times, use a level number" % level
             )
         try:
             level = self.names.index(level)
@@ -1399,8 +1405,6 @@ class MultiIndex(Index):
     @cache_readonly
     def _hashed_values(self):
         """ return a uint64 ndarray of my hashed values """
-        from pandas.core.util.hashing import hash_tuples
-
         return hash_tuples(self)
 
     def _hashed_indexing_key(self, key):
@@ -1420,9 +1424,7 @@ class MultiIndex(Index):
         Notes
         -----
         we need to stringify if we have mixed levels
-
         """
-        from pandas.core.util.hashing import hash_tuples, hash_tuple
 
         if not isinstance(key, tuple):
             return hash_tuples(key)
@@ -1442,9 +1444,6 @@ class MultiIndex(Index):
 
     @Appender(Index.duplicated.__doc__)
     def duplicated(self, keep="first"):
-        from pandas.core.sorting import get_group_index
-        from pandas._libs.hashtable import duplicated_int64
-
         shape = map(len, self.levels)
         ids = get_group_index(self.codes, shape, sort=False, xnull=False)
 
@@ -1636,11 +1635,11 @@ class MultiIndex(Index):
 
         if name is not None:
             if not is_list_like(name):
-                raise TypeError("'name' must be a list / sequence " "of column names.")
+                raise TypeError("'name' must be a list / sequence of column names.")
 
             if len(name) != len(self.levels):
                 raise ValueError(
-                    "'name' should have same length as " "number of levels on index."
+                    "'name' should have same length as number of levels on index."
                 )
             idx_names = name
         else:
@@ -2107,9 +2106,7 @@ class MultiIndex(Index):
         )
 
     def where(self, cond, other=None):
-        raise NotImplementedError(
-            ".where is not supported for " "MultiIndex operations"
-        )
+        raise NotImplementedError(".where is not supported for MultiIndex operations")
 
     @deprecate_kwarg(old_arg_name="labels", new_arg_name="codes")
     def drop(self, codes, level=None, errors="raise"):
@@ -2274,7 +2271,6 @@ class MultiIndex(Index):
         for sorting, where we need to disambiguate that -1 is not
         a valid valid
         """
-        from pandas.core.arrays import Categorical
 
         def cats(level_codes):
             return np.arange(
@@ -2309,8 +2305,6 @@ class MultiIndex(Index):
         indexer : np.ndarray
             Indices of output values in original index.
         """
-        from pandas.core.sorting import indexer_from_factorized
-
         if isinstance(level, (str, int)):
             level = [level]
         level = [self._get_level_number(lev) for lev in level]
@@ -2321,8 +2315,6 @@ class MultiIndex(Index):
             if not len(level) == len(ascending):
                 raise ValueError("level must have same length as ascending")
 
-            from pandas.core.sorting import lexsort_indexer
-
             indexer = lexsort_indexer(
                 [self.codes[lev] for lev in level], orders=ascending
             )
@@ -2419,14 +2411,12 @@ class MultiIndex(Index):
                     )
 
         if not self.is_unique:
-            raise ValueError(
-                "Reindexing only valid with uniquely valued " "Index objects"
-            )
+            raise ValueError("Reindexing only valid with uniquely valued Index objects")
 
         if method == "pad" or method == "backfill":
             if tolerance is not None:
                 raise NotImplementedError(
-                    "tolerance not implemented yet " "for MultiIndex"
+                    "tolerance not implemented yet for MultiIndex"
                 )
             indexer = self._engine.get_indexer(target, method, limit)
         elif method == "nearest":
@@ -2766,7 +2756,7 @@ class MultiIndex(Index):
         if isinstance(level, (tuple, list)):
             if len(key) != len(level):
                 raise AssertionError(
-                    "Key for location must have same " "length as number of levels"
+                    "Key for location must have same length as number of levels"
                 )
             result = None
             for lev, k in zip(level, key):
@@ -3323,7 +3313,7 @@ class MultiIndex(Index):
             raise NotImplementedError(msg)
         elif not is_object_dtype(dtype):
             msg = (
-                "Setting {cls} dtype to anything other than object " "is not supported"
+                "Setting {cls} dtype to anything other than object is not supported"
             ).format(cls=self.__class__)
             raise TypeError(msg)
         elif copy is True:
@@ -3369,7 +3359,7 @@ class MultiIndex(Index):
         if not isinstance(item, tuple):
             item = (item,) + ("",) * (self.nlevels - 1)
         elif len(item) != self.nlevels:
-            raise ValueError("Item must have length equal to number of " "levels.")
+            raise ValueError("Item must have length equal to number of levels.")
 
         new_levels = []
         new_codes = []
diff --git a/pandas/core/indexes/numeric.py b/pandas/core/indexes/numeric.py
index daf26d53a..1a1f8ae82 100644
--- a/pandas/core/indexes/numeric.py
+++ b/pandas/core/indexes/numeric.py
@@ -99,7 +99,7 @@ class NumericIndex(Index):
     def _convert_tolerance(self, tolerance, target):
         tolerance = np.asarray(tolerance)
         if target.size != tolerance.size and tolerance.size > 1:
-            raise ValueError("list-like tolerance size must match " "target index size")
+            raise ValueError("list-like tolerance size must match target index size")
         if not np.issubdtype(tolerance.dtype, np.number):
             if tolerance.ndim > 0:
                 raise ValueError(
@@ -255,7 +255,7 @@ class Int64Index(IntegerIndex):
         """
         if not issubclass(data.dtype.type, np.signedinteger):
             if not np.array_equal(data, subarr):
-                raise TypeError("Unsafe NumPy casting, you must " "explicitly cast")
+                raise TypeError("Unsafe NumPy casting, you must explicitly cast")
 
     def _is_compatible_with_other(self, other):
         return super()._is_compatible_with_other(other) or all(
@@ -329,7 +329,7 @@ class UInt64Index(IntegerIndex):
         """
         if not issubclass(data.dtype.type, np.unsignedinteger):
             if not np.array_equal(data, subarr):
-                raise TypeError("Unsafe NumPy casting, you must " "explicitly cast")
+                raise TypeError("Unsafe NumPy casting, you must explicitly cast")
 
     def _is_compatible_with_other(self, other):
         return super()._is_compatible_with_other(other) or all(
diff --git a/pandas/core/indexes/period.py b/pandas/core/indexes/period.py
index 04a858c8b..19fe1eb89 100644
--- a/pandas/core/indexes/period.py
+++ b/pandas/core/indexes/period.py
@@ -805,7 +805,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):
 
     def _get_string_slice(self, key):
         if not self.is_monotonic:
-            raise ValueError("Partial indexing only valid for " "ordered time series")
+            raise ValueError("Partial indexing only valid for ordered time series")
 
         key, parsed, reso = parse_time_string(key, self.freq)
         grp = resolution.Resolution.get_freq_group(reso)
@@ -822,7 +822,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):
     def _convert_tolerance(self, tolerance, target):
         tolerance = DatetimeIndexOpsMixin._convert_tolerance(self, tolerance, target)
         if target.size != tolerance.size and tolerance.size > 1:
-            raise ValueError("list-like tolerance size must match " "target index size")
+            raise ValueError("list-like tolerance size must match target index size")
         return self._maybe_convert_timedelta(tolerance)
 
     def insert(self, loc, item):
@@ -935,7 +935,7 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):
 
         """
         warnings.warn(
-            "`item` has been deprecated and will be removed in a " "future version",
+            "`item` has been deprecated and will be removed in a future version",
             FutureWarning,
             stacklevel=2,
         )
@@ -943,10 +943,9 @@ class PeriodIndex(DatetimeIndexOpsMixin, Int64Index, PeriodDelegateMixin):
         if len(self) == 1:
             return self[0]
         else:
+            # TODO: is this still necessary?
             # copy numpy's message here because Py26 raises an IndexError
-            raise ValueError(
-                "can only convert an array of size 1 to a " "Python scalar"
-            )
+            raise ValueError("can only convert an array of size 1 to a Python scalar")
 
     @property
     def data(self):
diff --git a/pandas/core/reshape/melt.py b/pandas/core/reshape/melt.py
index 413132db1..6f2e264f1 100644
--- a/pandas/core/reshape/melt.py
+++ b/pandas/core/reshape/melt.py
@@ -5,6 +5,7 @@ import numpy as np
 from pandas.util._decorators import Appender
 
 from pandas.core.dtypes.common import is_extension_type, is_list_like
+from pandas.core.dtypes.concat import concat_compat
 from pandas.core.dtypes.generic import ABCMultiIndex
 from pandas.core.dtypes.missing import notna
 
@@ -171,8 +172,6 @@ def lreshape(data, groups, dropna=True, label=None):
     for target, names in zip(keys, values):
         to_concat = [data[col].values for col in names]
 
-        from pandas.core.dtypes.concat import concat_compat
-
         mdata[target] = concat_compat(to_concat)
         pivot_cols.append(target)
 
diff --git a/pandas/core/reshape/reshape.py b/pandas/core/reshape/reshape.py
index 456f99a80..374de6156 100644
--- a/pandas/core/reshape/reshape.py
+++ b/pandas/core/reshape/reshape.py
@@ -3,8 +3,8 @@ import itertools
 
 import numpy as np
 
-import pandas._libs.algos as _algos
-import pandas._libs.reshape as _reshape
+import pandas._libs.algos as libalgos
+import pandas._libs.reshape as libreshape
 from pandas._libs.sparse import IntIndex
 
 from pandas.core.dtypes.cast import maybe_promote
@@ -150,7 +150,7 @@ class _Unstacker:
         comp_index, obs_ids = get_compressed_ids(to_sort, sizes)
         ngroups = len(obs_ids)
 
-        indexer = _algos.groupsort_indexer(comp_index, ngroups)[0]
+        indexer = libalgos.groupsort_indexer(comp_index, ngroups)[0]
         indexer = ensure_platform_int(indexer)
 
         self.sorted_values = algos.take_nd(self.values, indexer, axis=0)
@@ -239,7 +239,7 @@ class _Unstacker:
             sorted_values = sorted_values.astype(name, copy=False)
 
         # fill in our values & mask
-        f = getattr(_reshape, "unstack_{name}".format(name=name))
+        f = getattr(libreshape, "unstack_{name}".format(name=name))
         f(
             sorted_values,
             mask.view("u1"),
diff --git a/pandas/core/reshape/tile.py b/pandas/core/reshape/tile.py
index d1bdbdf51..949cad607 100644
--- a/pandas/core/reshape/tile.py
+++ b/pandas/core/reshape/tile.py
@@ -5,6 +5,7 @@ from functools import partial
 
 import numpy as np
 
+from pandas._libs import Timedelta, Timestamp
 from pandas._libs.lib import infer_dtype
 
 from pandas.core.dtypes.common import (
@@ -26,8 +27,6 @@ from pandas import (
     Interval,
     IntervalIndex,
     Series,
-    Timedelta,
-    Timestamp,
     to_datetime,
     to_timedelta,
 )
