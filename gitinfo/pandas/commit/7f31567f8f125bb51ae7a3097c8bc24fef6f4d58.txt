commit 7f31567f8f125bb51ae7a3097c8bc24fef6f4d58
Author: jreback <jeff@reback.net>
Date:   Mon Jul 29 21:30:24 2013 -0400

    BLD: py3 compat
    
    TST/BUG: test/bugfix for GH4463
    
    BUG: fix core/internals/setitem to work for boolean types (weird numpy bug!)
    
    BUG: partial frame setting with dtype change (GH4204)
    
    BUG: Indexing with dtype conversions fixed GH4463 (int->float), GH4204(boolean->float)
    
    BUG: provide better ndarray compat
    
    CLN: removed some duped methods
    
    MERGE: fix an issue cropping up on the rebase

diff --git a/doc/source/release.rst b/doc/source/release.rst
index 19d92352e..e0a48c552 100644
--- a/doc/source/release.rst
+++ b/doc/source/release.rst
@@ -184,6 +184,8 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
 - Bug in Series update where the parent frame is not updating its cache based on
   changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)
 
+- Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)
+
 **Experimental Features**
 
 **Bug Fixes**
diff --git a/doc/source/v0.13.0.txt b/doc/source/v0.13.0.txt
index db1ffd75a..d834fb9a0 100644
--- a/doc/source/v0.13.0.txt
+++ b/doc/source/v0.13.0.txt
@@ -202,6 +202,8 @@ and behaviors. Series formerly subclassed directly from ``ndarray``. (:issue:`40
 - Bug in Series update where the parent frame is not updating its cached based on
   changes (:issue:`4080`) or types (:issue:`3217`), fillna (:issue:`3386`)
 
+- Indexing with dtype conversions fixed (:issue:`4463`, :issue:`4204`)
+
 Bug Fixes
 ~~~~~~~~~
 
diff --git a/pandas/compat/pickle_compat.py b/pandas/compat/pickle_compat.py
index b2e183ddc..58bbf70c0 100644
--- a/pandas/compat/pickle_compat.py
+++ b/pandas/compat/pickle_compat.py
@@ -4,7 +4,7 @@ import sys
 import pickle
 import numpy as np
 import pandas
-from pandas.util import py3compat
+from pandas import compat
 from pandas.core.series import Series
 from pandas.sparse.series import SparseSeries
 
@@ -20,7 +20,7 @@ def load_reduce(self):
         elif n == 'DeprecatedSparseSeries':
             stack[-1] = object.__new__(SparseSeries)
             return
-            
+
     try:
         value = func(*args)
     except:
@@ -30,7 +30,7 @@ def load_reduce(self):
 
     stack[-1] = value
 
-if py3compat.PY3:
+if compat.PY3:
     class Unpickler(pickle._Unpickler):
         pass
 else:
diff --git a/pandas/core/frame.py b/pandas/core/frame.py
index aa730ce1e..200e4ce93 100644
--- a/pandas/core/frame.py
+++ b/pandas/core/frame.py
@@ -410,6 +410,8 @@ class DataFrame(NDFrame):
                 if columns is None:
                     columns = data_columns
                 mgr = self._init_dict(data, index, columns, dtype=dtype)
+            elif getattr(data,'name',None):
+                mgr = self._init_dict({ data.name : data }, index, columns, dtype=dtype)
             else:
                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,
                                          copy=copy)
@@ -4853,9 +4855,12 @@ def _prep_ndarray(values, copy=True):
         # we could have a 1-dim or 2-dim list here
         # this is equiv of np.asarray, but does object conversion
         # and platform dtype preservation
-        if com.is_list_like(values[0]) or hasattr(values[0], 'len'):
-            values = np.array([convert(v) for v in values])
-        else:
+        try:
+            if com.is_list_like(values[0]) or hasattr(values[0], 'len'):
+                values = np.array([convert(v) for v in values])
+            else:
+                values = convert(values)
+        except:
             values = convert(values)
 
     else:
@@ -4945,18 +4950,23 @@ def _list_of_series_to_arrays(data, columns, coerce_float=False, dtype=None):
     from pandas.core.index import _get_combined_index
 
     if columns is None:
-        columns = _get_combined_index([s.index for s in data])
+        columns = _get_combined_index([s.index for s in data if getattr(s,'index',None) is not None ])
 
     indexer_cache = {}
 
     aligned_values = []
     for s in data:
-        index = s.index
+        index = getattr(s,'index',None)
+        if index is None:
+            index = _default_index(len(s))
+
         if id(index) in indexer_cache:
             indexer = indexer_cache[id(index)]
         else:
             indexer = indexer_cache[id(index)] = index.get_indexer(columns)
-        aligned_values.append(com.take_1d(s.values, indexer))
+
+        values = _values_from_object(s)
+        aligned_values.append(com.take_1d(values, indexer))
 
     values = np.vstack(aligned_values)
 
@@ -5000,13 +5010,13 @@ def _convert_object_array(content, columns, coerce_float=False, dtype=None):
 
 def _get_names_from_index(data):
     index = lrange(len(data))
-    has_some_name = any([s.name is not None for s in data])
+    has_some_name = any([getattr(s,'name',None) is not None for s in data])
     if not has_some_name:
         return index
 
     count = 0
     for i, s in enumerate(data):
-        n = s.name
+        n = getattr(s,'name',None)
         if n is not None:
             index[i] = n
         else:
diff --git a/pandas/core/generic.py b/pandas/core/generic.py
index 8670827ba..ab8cab011 100644
--- a/pandas/core/generic.py
+++ b/pandas/core/generic.py
@@ -1,27 +1,22 @@
 # pylint: disable=W0231,E1101
 import warnings
-from pandas import compat
-import itertools
 import operator
 import weakref
 import numpy as np
 import pandas.lib as lib
-from pandas.core.base import PandasObject
 
+from pandas.core.base import PandasObject
 from pandas.core.index import Index, MultiIndex, _ensure_index
 import pandas.core.indexing as indexing
 from pandas.core.indexing import _maybe_convert_indices
 from pandas.tseries.index import DatetimeIndex
 from pandas.core.internals import BlockManager
-import pandas.lib as lib
-from pandas.util import py3compat
 import pandas.core.common as com
+from pandas import compat
 from pandas.compat import map, zip
 from pandas.core.common import (isnull, notnull, is_list_like,
                                 _values_from_object,
                                 _infer_dtype_from_scalar, _maybe_promote)
-from pandas.core.base import PandasObject
-
 
 class NDFrame(PandasObject):
 
@@ -78,10 +73,6 @@ class NDFrame(PandasObject):
     def _constructor(self):
         raise NotImplementedError
 
-    def __hash__(self):
-        raise TypeError('{0!r} objects are mutable, thus they cannot be'
-                        ' hashed'.format(self.__class__.__name__))
-
     def __unicode__(self):
         # unicode representation based upon iterating over self
         # (since, by definition, `PandasContainers` are iterable)
@@ -111,12 +102,12 @@ class NDFrame(PandasObject):
             """
 
         cls._AXIS_ORDERS = axes
-        cls._AXIS_NUMBERS = dict([(a, i) for i, a in enumerate(axes)])
+        cls._AXIS_NUMBERS = dict((a, i) for i, a in enumerate(axes))
         cls._AXIS_LEN = len(axes)
         cls._AXIS_ALIASES = aliases or dict()
-        cls._AXIS_IALIASES = dict([(v, k)
-                                  for k, v in cls._AXIS_ALIASES.items()])
-        cls._AXIS_NAMES = dict([(i, a) for i, a in enumerate(axes)])
+        cls._AXIS_IALIASES = dict((v, k)
+                                  for k, v in cls._AXIS_ALIASES.items())
+        cls._AXIS_NAMES = dict(enumerate(axes))
         cls._AXIS_SLICEMAP = slicers or None
         cls._AXIS_REVERSED = axes_are_reversed
 
@@ -271,23 +262,6 @@ class NDFrame(PandasObject):
         the block manager shows then reversed """
         return [self._get_axis(a) for a in self._AXIS_ORDERS]
 
-    def _construct_axes_dict(self, axes=None, **kwargs):
-        """ return an axes dictionary for myself """
-        d = dict([(a, getattr(self, a)) for a in (axes or self._AXIS_ORDERS)])
-        d.update(kwargs)
-        return d
-
-    @staticmethod
-    def _construct_axes_dict_from(self, axes, **kwargs):
-        """ return an axes dictionary for the passed axes """
-        d = dict([(a, ax) for a, ax in zip(self._AXIS_ORDERS, axes)])
-        d.update(kwargs)
-        return d
-
-    @property
-    def values(self):
-        return self._data.as_matrix()
-
     @property
     def ndim(self):
         return self._data.ndim
@@ -445,9 +419,6 @@ class NDFrame(PandasObject):
     def _indexed_same(self, other):
         return all([self._get_axis(a).equals(other._get_axis(a)) for a in self._AXIS_ORDERS])
 
-    def reindex(self, *args, **kwds):
-        raise NotImplementedError
-
     def __neg__(self):
         arr = operator.neg(_values_from_object(self))
         return self._wrap_array(arr, self.axes, copy=False)
@@ -460,7 +431,8 @@ class NDFrame(PandasObject):
     # Iteration
 
     def __hash__(self):
-        raise TypeError
+        raise TypeError('{0!r} objects are mutable, thus they cannot be'
+                        ' hashed'.format(self.__class__.__name__))
 
     def __iter__(self):
         """
@@ -483,7 +455,6 @@ class NDFrame(PandasObject):
                       "release, use ``iteritems`` instead.", DeprecationWarning)
         return self.iteritems(*args, **kwargs)
 
-
     def __len__(self):
         """Returns length of info axis """
         return len(self._info_axis)
@@ -1142,7 +1113,7 @@ class NDFrame(PandasObject):
         if items is not None:
             return self.reindex(**{axis_name: [r for r in items if r in axis_values]})
         elif like:
-            matchf = lambda x: (like in x if isinstance(x, basestring)
+            matchf = lambda x: (like in x if isinstance(x, compat.string_types)
                                 else like in str(x))
             return self.select(matchf, axis=axis_name)
         elif regex:
@@ -1285,6 +1256,7 @@ class NDFrame(PandasObject):
 
     def get_ftype_counts(self):
         """ return the counts of ftypes in this frame """
+        from pandas import Series
         return Series(self._data.get_ftype_counts())
 
     def as_blocks(self, columns=None):
@@ -1446,7 +1418,7 @@ class NDFrame(PandasObject):
                                               'by column')
 
                 result = self if inplace else self.copy()
-                for k, v in value.iteritems():
+                for k, v in compat.iteritems(value):
                     if k not in result:
                         continue
                     obj = result[k]
@@ -1595,7 +1567,7 @@ class NDFrame(PandasObject):
                 regex = True
 
             items = to_replace.items()
-            keys, values = itertools.izip(*items)
+            keys, values = zip(*items)
 
             are_mappings = [is_dictlike(v) for v in values]
 
@@ -1629,7 +1601,7 @@ class NDFrame(PandasObject):
             if is_dictlike(to_replace):
                 if is_dictlike(value):  # {'A' : NA} -> {'A' : 0}
                     new_data = self._data
-                    for c, src in to_replace.iteritems():
+                    for c, src in compat.iteritems(to_replace):
                         if c in value and c in self:
                             new_data = new_data.replace(src, value[c],
                                                         filter=[c],
@@ -1639,7 +1611,7 @@ class NDFrame(PandasObject):
                 # {'A': NA} -> 0
                 elif not isinstance(value, (list, np.ndarray)):
                     new_data = self._data
-                    for k, src in to_replace.iteritems():
+                    for k, src in compat.iteritems(to_replace):
                         if k in self:
                             new_data = new_data.replace(src, value,
                                                         filter=[k],
@@ -1679,7 +1651,7 @@ class NDFrame(PandasObject):
                 if is_dictlike(value):  # NA -> {'A' : 0, 'B' : -1}
                     new_data = self._data
 
-                    for k, v in value.iteritems():
+                    for k, v in compat.iteritems(value):
                         if k in self:
                             new_data = new_data.replace(to_replace, v,
                                                         filter=[k],
@@ -1729,7 +1701,7 @@ class NDFrame(PandasObject):
 
         method = com._clean_fill_method(method)
 
-        if isinstance(to_replace, (dict, Series)):
+        if isinstance(to_replace, (dict, com.ABCSeries)):
             if axis == 0:
                 return self.replace(to_replace, method=method, inplace=inplace,
                                     limit=limit, axis=axis)
diff --git a/pandas/core/index.py b/pandas/core/index.py
index 698af6804..73aff7bca 100644
--- a/pandas/core/index.py
+++ b/pandas/core/index.py
@@ -15,7 +15,6 @@ from pandas.util.decorators import cache_readonly, deprecate
 from pandas.core.common import isnull
 import pandas.core.common as com
 from pandas.core.common import _values_from_object
-from pandas.util import py3compat
 from pandas.core.config import get_option
 import warnings
 
@@ -808,7 +807,7 @@ class Index(FrozenNDArray):
         k = _values_from_object(key)
         try:
             return self._engine.get_value(s, k)
-        except KeyError, e1:
+        except KeyError as e1:
             if len(self) > 0 and self.inferred_type == 'integer':
                 raise
 
@@ -1447,7 +1446,7 @@ class Int64Index(Index):
                     data = list(data)
                 data = np.asarray(data)
 
-            if issubclass(data.dtype.type, basestring):
+            if issubclass(data.dtype.type, compat.string_types):
                 raise TypeError('String dtype not supported, you may need '
                                 'to explicitly cast to int')
             elif issubclass(data.dtype.type, np.integer):
@@ -1865,7 +1864,7 @@ class MultiIndex(Index):
         k = _values_from_object(key)
         try:
             return self._engine.get_value(s, k)
-        except KeyError, e1:
+        except KeyError as e1:
             try:
                 # TODO: what if a level contains tuples??
                 loc = self.get_loc(key)
diff --git a/pandas/core/indexing.py b/pandas/core/indexing.py
index b93777802..11818a4fe 100644
--- a/pandas/core/indexing.py
+++ b/pandas/core/indexing.py
@@ -6,7 +6,8 @@ from pandas.core.index import Index, MultiIndex, _ensure_index
 from pandas.compat import range, zip
 import pandas.compat as compat
 import pandas.core.common as com
-from pandas.core.common import _is_bool_indexer, ABCSeries, ABCDataFrame
+from pandas.core.common import (_is_bool_indexer,
+                                ABCSeries, ABCDataFrame, ABCPanel)
 import pandas.lib as lib
 
 import numpy as np
@@ -104,7 +105,6 @@ class _NDFrameIndexer(object):
     def _setitem_with_indexer(self, indexer, value):
 
         # also has the side effect of consolidating in-place
-
         # mmm, spaghetti
 
         if self.obj._is_mixed_type:
@@ -182,13 +182,10 @@ class _NDFrameIndexer(object):
             elif isinstance(value, ABCDataFrame):
                 value = self._align_frame(indexer, value)
 
-            if isinstance(value, Panel):
+            if isinstance(value, ABCPanel):
                 value = self._align_panel(indexer, value)
 
-            # 2096
-            values = self.obj.values
-            if np.prod(values.shape):
-                values[indexer] = value
+            self.obj._data = self.obj._data.setitem(indexer,value)
 
     def _align_series(self, indexer, ser):
         # indexer to assign Series can be tuple or scalar
diff --git a/pandas/core/internals.py b/pandas/core/internals.py
index 35d185b48..675b2f5e1 100644
--- a/pandas/core/internals.py
+++ b/pandas/core/internals.py
@@ -8,7 +8,8 @@ import numpy as np
 from pandas.core.base import PandasObject
 
 from pandas.core.common import (_possibly_downcast_to_dtype, isnull, _NS_DTYPE,
-                                _TD_DTYPE, ABCSeries, ABCSparseSeries)
+                                _TD_DTYPE, ABCSeries, ABCSparseSeries,
+                                is_list_like)
 from pandas.core.index import (Index, MultiIndex, _ensure_index,
                                _handle_legacy_indexes)
 from pandas.core.indexing import _check_slice_bounds, _maybe_convert_indices
@@ -453,6 +454,32 @@ class Block(PandasObject):
             return [self.copy()]
         return self.putmask(mask, value, inplace=inplace)
 
+    def setitem(self, indexer, value):
+        """ set the value inplace; return a new block (of a possibly different dtype)
+            indexer is a direct slice/positional indexer; value must be a compaitable shape """
+
+        values = self.values
+        if self.ndim == 2:
+            values = values.T
+
+        # 2-d (DataFrame) are represented as a transposed array
+        if self._can_hold_element(value):
+            try:
+                values[indexer] = value
+                return [ self ]
+            except (IndexError):
+                return [ self ]
+            except:
+                pass
+
+        # create an indexing mask, the putmask which potentially changes the dtype
+        indices = np.arange(np.prod(values.shape)).reshape(values.shape)
+        mask = indices[indexer] == indices
+        if self.ndim == 2:
+            mask = mask.T
+
+        return self.putmask(mask, value, inplace=True)
+
     def putmask(self, mask, new, inplace=False):
         """ putmask the data to the block; it is possible that we may create a new dtype of block
             return the resulting block(s) """
@@ -764,7 +791,8 @@ class FloatBlock(NumericBlock):
     _downcast_dtype = 'int64'
 
     def _can_hold_element(self, element):
-        if isinstance(element, np.ndarray):
+        if is_list_like(element):
+            element = np.array(element)
             return issubclass(element.dtype.type, (np.floating, np.integer))
         return isinstance(element, (float, int))
 
@@ -814,7 +842,8 @@ class IntBlock(NumericBlock):
     _can_hold_na = False
 
     def _can_hold_element(self, element):
-        if isinstance(element, np.ndarray):
+        if is_list_like(element):
+            element = np.array(element)
             return issubclass(element.dtype.type, np.integer)
         return com.is_integer(element)
 
@@ -833,6 +862,9 @@ class BoolBlock(NumericBlock):
     _can_hold_na = False
 
     def _can_hold_element(self, element):
+        if is_list_like(element):
+            element = np.array(element)
+            return issubclass(element.dtype.type, np.integer)
         return isinstance(element, (int, bool))
 
     def _try_cast(self, element):
@@ -1023,6 +1055,9 @@ class DatetimeBlock(Block):
         return lib.Timestamp(self.values[arg])
 
     def _can_hold_element(self, element):
+        if is_list_like(element):
+            element = np.array(element)
+            return element.dtype == _NS_DTYPE
         return com.is_integer(element) or isinstance(element, datetime)
 
     def _try_cast(self, element):
@@ -1720,6 +1755,9 @@ class BlockManager(PandasObject):
     def eval(self, *args, **kwargs):
         return self.apply('eval', *args, **kwargs)
 
+    def setitem(self, *args, **kwargs):
+        return self.apply('setitem', *args, **kwargs)
+
     def putmask(self, *args, **kwargs):
         return self.apply('putmask', *args, **kwargs)
 
diff --git a/pandas/core/series.py b/pandas/core/series.py
index 33d964da3..4f9c1e430 100644
--- a/pandas/core/series.py
+++ b/pandas/core/series.py
@@ -109,7 +109,7 @@ def _arith_method(op, name, fill_zeros=None):
                 inferred_type = lib.infer_dtype(values)
                 if inferred_type in set(['datetime64','datetime','date','time']):
                     # a datetlike
-                    if not (isinstance(values, pa.Array) and com.is_datetime64_dtype(values)):
+                    if not (isinstance(values, (pa.Array, Series)) and com.is_datetime64_dtype(values)):
                         values = tslib.array_to_datetime(values)
                 elif inferred_type in set(['timedelta']):
                     # have a timedelta, convert to to ns here
@@ -553,7 +553,6 @@ class Series(generic.NDFrame):
                 data = data._data
             elif isinstance(data, dict):
                 if index is None:
-                    from pandas.util.compat import OrderedDict
                     if isinstance(data, OrderedDict):
                         index = Index(data)
                     else:
@@ -663,6 +662,21 @@ class Series(generic.NDFrame):
             object.__setattr__(self, '_subtyp', 'series')
 
     # ndarray compatibility
+    def item(self):
+        return self.values.item()
+
+    @property
+    def data(self):
+        return self.values.data
+
+    @property
+    def strides(self):
+        return self.values.strides
+
+    @property
+    def size(self):
+        return self.values.size
+
     @property
     def flags(self):
         return self.values.flags
@@ -730,13 +744,13 @@ class Series(generic.NDFrame):
     __float__ = _coerce_method(float)
     __long__ = _coerce_method(int)
     __int__ = _coerce_method(int)
-    __bool__ = _coerce_method(bool)
 
     def __nonzero__(self):
         # special case of a single element bool series degenerating to a scalar
         if self.dtype == np.bool_ and len(self) == 1:
             return bool(self.iloc[0])
         return not self.empty
+    __bool__ = __nonzero__
 
     # we are preserving name here
     def __getstate__(self):
@@ -966,9 +980,10 @@ class Series(generic.NDFrame):
                     except (TypeError):
                         pass
 
-            raise KeyError('%s not in this series!' % str(key))
+            self.loc[key] = value
+            return
 
-        except TypeError, e:
+        except TypeError as e:
             # python 3 type errors should be raised
             if 'unorderable' in str(e):  # pragma: no cover
                 raise IndexError(key)
@@ -1245,19 +1260,20 @@ class Series(generic.NDFrame):
         # time series
         if self.is_time_series:
             if self.index.freq is not None:
-                freqstr = 'Freq: %s, ' % self.index.freqstr
+                freqstr = u('Freq: %s, ') % self.index.freqstr
             else:
-                freqstr = ''
+                freqstr = u('')
 
-            namestr = "Name: %s, " % str(
+            namestr = u("Name: %s, ") % com.prrint_thing(
                 self.name) if self.name is not None else ""
-            return '%s%sLength: %d' % (freqstr, namestr, len(self))
+            return u('%s%sLength: %d') % (freqstr, namestr, len(self))
 
         # reg series
-        namestr = u"Name: %s, " % com.pprint_thing(
+        namestr = u("Name: %s, ") % com.pprint_thing(
             self.name) if self.name is not None else ""
-        return u('%sLength: %d, dtype: %s') % (namestr, len(self),
-                                             str(self.dtype.name))
+        return u('%sLength: %d, dtype: %s') % (namestr,
+                                               len(self),
+                                               str(self.dtype.name))
 
     def to_string(self, buf=None, na_rep='NaN', float_format=None,
                   nanRep=None, length=False, dtype=False, name=False):
@@ -1334,11 +1350,6 @@ class Series(generic.NDFrame):
         """
         return lzip(iter(self.index), iter(self))
 
-    def iterkv(self):
-        warnings.warn("iterkv is deprecated and will be removed in a future "
-                      "release. Use ``iteritems`` instead", DeprecationWarning)
-        return self.iteritems()
-
     if compat.PY3:  # pragma: no cover
         items = iteritems
 
diff --git a/pandas/io/pytables.py b/pandas/io/pytables.py
index c12c50757..8a98bb6c1 100644
--- a/pandas/io/pytables.py
+++ b/pandas/io/pytables.py
@@ -2673,13 +2673,9 @@ class Table(Storer):
 
         # reindex by our non_index_axes & compute data_columns
         for a in self.non_index_axes:
-<<<<<<< HEAD
-            obj = obj.reindex_axis(a[1], axis=a[0])
-=======
             labels = _ensure_index(a[1])
             if not labels.equals(obj._get_axis(a[0])):
                 obj = obj.reindex_axis(labels, axis=a[0])
->>>>>>> ENH/CLN: refactor of common code from frame/panel to generic.py
 
         # figure out data_columns and get out blocks
         block_obj = self.get_object(obj).consolidate()
diff --git a/pandas/io/tests/test_pickle.py b/pandas/io/tests/test_pickle.py
index ac5297857..f2ddce7fa 100644
--- a/pandas/io/tests/test_pickle.py
+++ b/pandas/io/tests/test_pickle.py
@@ -31,13 +31,13 @@ class TestPickle(unittest.TestCase):
         try:
             with open(vf,'rb') as fh:
                 data = pickle.load(fh)
-        except (ValueError), detail:
+        except ValueError as detail:
 
             # we are trying to read a py3 pickle in py2.....
             return
 
         # we have a deprecated klass
-        except (TypeError), detail:
+        except TypeError as detail:
 
             from pandas.compat.pickle_compat import load
             data = load(vf)
diff --git a/pandas/sparse/array.py b/pandas/sparse/array.py
index 592546992..34823c052 100644
--- a/pandas/sparse/array.py
+++ b/pandas/sparse/array.py
@@ -12,6 +12,7 @@ from pandas.core.base import PandasObject
 import pandas.core.common as com
 
 from pandas import compat
+from pandas.compat import range
 
 from pandas._sparse import BlockIndex, IntIndex
 import pandas._sparse as splib
@@ -284,7 +285,7 @@ to sparse
         return values
 
     def __iter__(self):
-        for i in xrange(len(self)):
+        for i in range(len(self)):
             yield self._get_val_at(i)
         raise StopIteration
 
diff --git a/pandas/sparse/frame.py b/pandas/sparse/frame.py
index e3968c540..00a9d4111 100644
--- a/pandas/sparse/frame.py
+++ b/pandas/sparse/frame.py
@@ -269,7 +269,6 @@ class SparseDataFrame(DataFrame):
     @property
     def default_kind(self):
         return self._default_kind
->>>>>>> ENH/CLN: refactor of common code from frame/panel to generic.py
 
     @property
     def density(self):
diff --git a/pandas/tests/test_frame.py b/pandas/tests/test_frame.py
index ed207148f..b84115bd3 100644
--- a/pandas/tests/test_frame.py
+++ b/pandas/tests/test_frame.py
@@ -407,6 +407,16 @@ class CheckIndexing(object):
             self.frame[dtype] = np.array(arr,dtype=dtype)
             self.assert_(self.frame[dtype].dtype.name == dtype)
 
+        # dtype changing GH4204
+        df = DataFrame([[0,0]])
+        df.iloc[0] = np.nan
+        expected = DataFrame([[np.nan,np.nan]])
+        assert_frame_equal(df,expected)
+
+        df = DataFrame([[0,0]])
+        df.loc[0] = np.nan
+        assert_frame_equal(df,expected)
+
     def test_setitem_tuple(self):
         self.frame['A', 'B'] = self.frame['A']
         assert_series_equal(self.frame['A', 'B'], self.frame['A'])
@@ -2739,11 +2749,36 @@ class TestDataFrame(unittest.TestCase, CheckIndexing,
         self.assert_(df.columns[0] == 'x')
         self.assert_(df.index.equals(a.index))
 
+        # ndarray like
+        arr = np.random.randn(10)
+        s = Series(arr,name='x')
+        df = DataFrame(s)
+        expected = DataFrame(dict(x = s))
+        assert_frame_equal(df,expected)
+
+        s = Series(arr,index=range(3,13))
+        df = DataFrame(s)
+        expected = DataFrame({ 0 : s })
+        assert_frame_equal(df,expected)
+
+        self.assertRaises(ValueError, DataFrame, s, columns=[1,2])
+
         # #2234
         a = Series([], name='x')
         df = DataFrame(a)
         self.assert_(df.columns[0] == 'x')
 
+        # series with name and w/o
+        s1 = Series(arr,name='x')
+        df = DataFrame([s1, arr]).T
+        expected = DataFrame({ 'x' : s1, 'Unnamed 0' : arr },columns=['x','Unnamed 0'])
+        assert_frame_equal(df,expected)
+
+        # this is a bit non-intuitive here; the series collapse down to arrays
+        df = DataFrame([arr, s1]).T
+        expected = DataFrame({ 1 : s1, 0 : arr },columns=[0,1])
+        assert_frame_equal(df,expected)
+
     def test_constructor_Series_differently_indexed(self):
         # name
         s1 = Series([1, 2, 3], index=['a', 'b', 'c'], name='x')
diff --git a/pandas/tests/test_series.py b/pandas/tests/test_series.py
index e023e680e..7ee432416 100644
--- a/pandas/tests/test_series.py
+++ b/pandas/tests/test_series.py
@@ -25,7 +25,7 @@ import pandas.core.common as com
 import pandas.core.datetools as datetools
 import pandas.core.nanops as nanops
 
-from pandas.compat import StringIO, lrange, range, zip, u, OrderedDict
+from pandas.compat import StringIO, lrange, range, zip, u, OrderedDict, long
 from pandas import compat
 from pandas.util.testing import (assert_series_equal,
                                  assert_almost_equal,
@@ -943,6 +943,32 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         self.assertRaises(Exception, self.series.__setitem__,
                           'foobar', 1)
 
+    def test_setitem_dtypes(self):
+
+        # change dtypes
+        # GH 4463
+        expected = Series([np.nan,2,3])
+
+        s = Series([1,2,3])
+        s.iloc[0] = np.nan
+        assert_series_equal(s,expected)
+
+        s = Series([1,2,3])
+        s.loc[0] = np.nan
+        assert_series_equal(s,expected)
+
+        s = Series([1,2,3])
+        s[0] = np.nan
+        assert_series_equal(s,expected)
+
+        s = Series([False])
+        s.loc[0] = np.nan
+        assert_series_equal(s,Series([np.nan]))
+
+        s = Series([False,True])
+        s.loc[0] = np.nan
+        assert_series_equal(s,Series([np.nan,1.0]))
+
     def test_set_value(self):
         idx = self.ts.index[10]
         res = self.ts.set_value(idx, 0)
@@ -1200,7 +1226,12 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
 
         s = Series(np.arange(10))
         mask = s > 5
-        self.assertRaises(ValueError, s.__setitem__, mask, ([0] * 5,))
+        def f():
+            s[mask] = [5,4,3,2,1]
+        self.assertRaises(ValueError, f)
+        def f():
+            s[mask] = [0] * 5
+        self.assertRaises(ValueError, f)
 
     def test_where_broadcast(self):
         # Test a variety of differently sized series
@@ -2550,6 +2581,18 @@ class TestSeries(unittest.TestCase, CheckNameIntegration):
         expected = tsdf.max()
         assert_series_equal(result,expected)
 
+        # .item()
+        s = Series([1])
+        result = s.item()
+        self.assert_(result == 1)
+        self.assert_(s.item() == s.iloc[0])
+
+        # using an ndarray like function
+        s = Series(np.random.randn(10))
+        result = np.ones_like(s)
+        expected = Series(1,index=range(10),dtype='float64')
+        #assert_series_equal(result,expected)
+
     def test_underlying_data_conversion(self):
 
         # GH 4080
diff --git a/pandas/tseries/period.py b/pandas/tseries/period.py
index cac389f04..bf9d7b2cf 100644
--- a/pandas/tseries/period.py
+++ b/pandas/tseries/period.py
@@ -13,7 +13,7 @@ from pandas.tseries.tools import parse_time_string
 import pandas.tseries.frequencies as _freq_mod
 
 import pandas.core.common as com
-from pandas.core.common import (isnull, _NS_DTYPE, _INT64_DTYPE
+from pandas.core.common import (isnull, _NS_DTYPE, _INT64_DTYPE,
                                 _maybe_box, _values_from_object)
 from pandas import compat
 from pandas.lib import Timestamp
